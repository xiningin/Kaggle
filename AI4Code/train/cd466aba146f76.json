{"cell_type":{"93c1bd05":"code","f2f3badc":"code","3391c81c":"code","eb064809":"code","f72b39d0":"code","1d787de1":"code","66687060":"code","b7884cd4":"code","e492c1d8":"code","0048344f":"code","6206d2b2":"code","4e53f10f":"code","26bbae25":"code","f53940a5":"code","77fb3ca3":"code","a281108f":"code","be08d187":"code","d9d37ff5":"code","a4c226af":"code","7419db6d":"code","00e2d35b":"code","32e542fd":"code","21eb7e8e":"code","13fbc86f":"code","cfce313f":"code","4ab40269":"code","eac18a71":"code","2cf25ec8":"code","d517567e":"code","7e58bc80":"code","434e56f3":"code","1af4afb8":"code","4dac18f6":"code","d7f728a3":"code","77195941":"code","b71e3713":"code","914c01af":"code","3a7bdd21":"code","ce607077":"code","0a4411d8":"code","32e7a341":"code","8674d263":"code","2c6528cf":"code","f3584017":"code","a755682b":"code","74fc7057":"code","e256d3ca":"code","9cacc4c0":"code","fdafd6c0":"code","290a6935":"code","fb88b0cc":"code","d592acd5":"code","0f013ac4":"code","aabaf3c5":"code","f0f44f5b":"code","a1cc369e":"code","4c69d443":"code","1c1fbd99":"code","6bb3fc2f":"code","2a510871":"code","c146e6ce":"code","2fbe988e":"code","49719a08":"code","88a5bf65":"code","4b091316":"code","9b16e356":"code","e20f10f4":"code","4a26cc28":"code","208b0fb8":"code","9abf5297":"code","8e27464e":"code","e6ae6bbd":"code","a340fc72":"code","50f2de5c":"code","aaf46d77":"markdown","624433fc":"markdown","2c59f7b0":"markdown","1a60bf95":"markdown","8b34a215":"markdown","cb6ea4a3":"markdown","6574e3b9":"markdown","8712335d":"markdown","df8dde51":"markdown","85f78a48":"markdown","6b9683b9":"markdown","35d6781a":"markdown","643638db":"markdown"},"source":{"93c1bd05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib_venn as venn\nfrom math import pi\n\nimport plotly.graph_objs as go\n\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f2f3badc":"#This line showing us our options for plot\nplt.style.available","3391c81c":"#Seaborn example, seaborn-whitegrid this line adding grid to our plot \na = [1,2,3,4] \nplt.plot(a)\nplt.show()","eb064809":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\",index=False)\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\",index=False)\ntest_PassengerId = test_df[\"PassengerId\",index=False]\ngender_submission_df = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\",index=False)","f72b39d0":"train_df.columns","1d787de1":"# pandas.plotting import parallel coordinates","66687060":"\nplt.figure(figsize=(15,10))\nparallel_coordinates(data, 'Pclass', colormap=plt.get_cmap(\"Set1\"))\nplt.title(\"Iris data class visualization according to features (setosa, versicolor, virginica)\")\nplt.xlabel(\"Features of data set\")\nplt.ylabel(\"cm\")\nplt.savefig('graph.png')\nplt.show()","b7884cd4":"train_df.head()","e492c1d8":"train_df.describe()","0048344f":"gender_submission_df.columns","6206d2b2":"train_df['Survived'].value_counts().plot(kind=\"bar\")\n","4e53f10f":"gender_submission_df.head()","26bbae25":"train_df.info()","f53940a5":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: bar plot & value count\n    \"\"\"\n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","77fb3ca3":"category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","a281108f":"category2 = [\"Cabin\", \"Name\", \"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","be08d187":"def plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(train_df[variable],bins=50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distrubition with hist\".format(variable))\n    plt.show()","d9d37ff5":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\nfor i in numericVar:\n    plot_hist(i)","a4c226af":"#Analysis Pclass with survived\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","7419db6d":"#Sex vs Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","00e2d35b":"#Sibsp vs Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"],as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","32e542fd":"#Parch vs Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"],as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","21eb7e8e":"#Age vs Survived that's show us a positive correlation with childs and elder people by survived\ntrain_df[[\"Age\",\"Survived\"]].groupby([\"Age\"],as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","13fbc86f":"#Fare vs Survived that's showing us high and low cost of ticket has positive correlation by survived\ntrain_df[[\"Fare\",\"Survived\"]].groupby([\"Fare\"],as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","cfce313f":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        Q1 = np.percentile(df[c],25)\n        Q3 = np.percentile(df[c],75)\n        IQR = Q3 - Q1\n        outlier_step = IQR * 1.5\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        outlier_indices.extend(outlier_list_col)\n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers\n        ","4ab40269":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]\n","eac18a71":"train_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)\n","2cf25ec8":"trainf_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)","d517567e":"train_df.head()","7e58bc80":"train_df.columns[train_df.isnull().any()]","434e56f3":"train_df.isnull().sum()","1af4afb8":"train_df[train_df[\"Embarked\"].isnull()]","4dac18f6":"train_df.boxplot(column=\"Fare\",by = \"Embarked\")\nplt.show()","d7f728a3":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")","77195941":"train_df[train_df[\"Fare\"].isnull()]","b71e3713":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"]==3][\"Fare\"]))","914c01af":"train_df[train_df[\"Fare\"].isnull()]","3a7bdd21":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","ce607077":"titanic = sns.load_dataset('titanic')\n#Print the first 10 rows of data\ntitanic.head(10)","0a4411d8":"titanic.shape","32e7a341":"titanic.describe().T","8674d263":"titanic['survived'].value_counts()","2c6528cf":"sns.countplot(titanic['survived'],label=\"Count\")","f3584017":"titanic = sns.load_dataset('titanic')","a755682b":"cols = ['who', 'sex', 'pclass', 'sibsp', 'parch', 'embarked']\n\nn_rows = 2\nn_cols = 3\n\n# The subplot grid and the figure size of each graph\n# This returns a Figure (fig) and an Axes Object (axs)\nfig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.2,n_rows*3.2))\n\nfor r in range(0,n_rows):\n    for c in range(0,n_cols):  \n        \n        i = r*n_cols+ c #index to go through the number of columns       \n        ax = axs[r][c] #Show where to position each subplot\n        sns.countplot(titanic[cols[i]], hue=titanic[\"survived\"], ax=ax)\n        ax.set_title(cols[i])\n        ax.legend(title=\"survived\", loc='upper right') \n        \nplt.tight_layout()   #tight_layout\n","74fc7057":"titanic.groupby('sex')[['survived']].mean()","e256d3ca":"titanic.pivot_table('survived', index='sex', columns='class')","9cacc4c0":"titanic.pivot_table('survived', index='sex', columns='class').plot()","fdafd6c0":"\nsns.barplot(x='class', y='survived', data=titanic)","290a6935":"age = pd.cut(titanic['age'], [0, 18, 80])\ntitanic.pivot_table('survived', ['sex', age], 'class')","fb88b0cc":"  plt.scatter(titanic['fare'], titanic['class'],  color = 'purple', label='Passenger Paid')\n  plt.ylabel('Class')\n  plt.xlabel('Price \/ Fare')\n  plt.title('Price Of Each Class')\n  plt.legend()\n  plt.show()","d592acd5":"import missingno as msno","0f013ac4":"titanic.isna().sum()","aabaf3c5":"msno.bar(titanic)","f0f44f5b":"msno.matrix(titanic)","a1cc369e":"for val in titanic:\n    print(titanic[val].value_counts())\n    print()","4c69d443":"titanic = titanic.drop(['deck', 'embark_town', 'alive', 'class', 'alone', 'adult_male', 'who'], axis=1)\n\n#Remove the rows with missing values\ntitanic = titanic.dropna(subset =['embarked', 'age'])","1c1fbd99":"titanic.shape","6bb3fc2f":"titanic.dtypes","2a510871":"print(titanic[\"sex\"].unique())\nprint(titanic[\"embarked\"].unique())\n","c146e6ce":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ntitanic.iloc[:,2] = labelencoder.fit_transform(titanic.iloc[:,2].values)\ntitanic.iloc[:,7] = labelencoder.fit_transform(titanic.iloc[:,7].values)","2fbe988e":"print(titanic[\"sex\"].unique())\nprint(titanic[\"embarked\"].unique())","49719a08":"titanic.dtypes","88a5bf65":"X = titanic.iloc[:,1:8].values\nY = titanic.iloc[:,0].values","4b091316":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2,random_state = 42)","9b16e356":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","e20f10f4":"def models(X_train,Y_train):\n    \n    from sklearn.linear_model import LogisticRegression\n    log = LogisticRegression(random_state = 42)\n    log.fit(X_train,Y_train)\n    \n    from sklearn.neighbors import KNeighborsClassifier\n    knn = KNeighborsClassifier(n_neighbors = 5,metric = \"minkowski\",p = 2)\n    knn.fit(X_train,Y_train)\n    \n    from sklearn.svm import SVC\n    svc_lin = SVC(kernel=\"linear\",random_state = 42)\n    svc_lin.fit(X_train,Y_train)\n    \n    from sklearn.svm import SVC\n    svc_rbf = SVC(kernel=\"rbf\",random_state = 42)\n    svc_rbf.fit(X_train,Y_train)\n    \n    from sklearn.naive_bayes import GaussianNB\n    gauss = GaussianNB()\n    gauss.fit(X_train,Y_train)\n    \n    from sklearn.tree import DecisionTreeClassifier\n    tree = DecisionTreeClassifier(criterion = \"entropy\",random_state = 42)\n    tree.fit(X_train,Y_train)\n    \n    from sklearn.ensemble import RandomForestClassifier\n    forest = RandomForestClassifier(n_estimators = 10, criterion = \"entropy\", random_state = 42)\n    forest.fit(X_train,Y_train)\n    \n    print(\"[0]Logistic Regression Training Accuracy: \",log.score(X_train,Y_train))\n    print(\"[1]K neighbors  Training Accuracy: \",knn.score(X_train,Y_train))\n    print(\"[2]Support Vector Classifier Training Accuracy: \",svc_lin.score(X_train,Y_train))\n    print(\"[3]SVC Rbf Training Accuracy: \",svc_rbf.score(X_train,Y_train))\n    print(\"[4]Gaussian NB Training Accuracy: \",gauss.score(X_train,Y_train))\n    print(\"[5]Decision Tree Training Accuracy: \",tree.score(X_train,Y_train))\n    print(\"[6]Random Forest Training Accuracy: \",forest.score(X_train,Y_train))\n    \n    return log,knn,svc_lin,svc_rbf,gauss,tree,forest\n","4a26cc28":"model = models(X_train,Y_train)","208b0fb8":"from sklearn.metrics import confusion_matrix \nfor i in range(len(model)):\n   cm = confusion_matrix(Y_test, model[i].predict(X_test)) \n   #extracting TN, FP, FN, TP\n   TN, FP, FN, TP = confusion_matrix(Y_test, model[i].predict(X_test)).ravel()\n   print(cm)\n   print('Model[{}] Testing Accuracy = \"{} !\"'.format(i,  (TP + TN) \/ (TP + TN + FN + FP)))\n   print()# Print a new line","9abf5297":"forest = model[6]\nimportances = pd.DataFrame({'feature':titanic.iloc[:, 1:8].columns,'importance':np.round(forest.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances","8e27464e":"\nimportances.plot.bar();","e6ae6bbd":"pred = model[6].predict(X_test)\nprint(pred)\n\n#Print a space\nprint()\n\n#Print the actual values\nprint(Y_test)","a340fc72":"my_survival = [[1,0,22,1, 0, 0, 1]]\n#  pclass sex age sibsp parch fare embarked\npred = model[6].predict(my_survival)\nprint(pred)\n\nif pred == 0:\n  print('Oh no! You didnt make it')\nelse:\n  print('Nice! You survived')","50f2de5c":"my_survival = [[1, 0, 22, 0, 0, 150, 0 ]]\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nmy_survival_scaled = sc.fit_transform(my_survival)\npred = model[6].predict(my_survival_scaled)\nprint(pred)\nif pred == 0:\n  print('Oh no! You didnt make it')\nelse:\n  print('Nice! You survived')","aaf46d77":" <a id = \"2\"><\/a>\n \n # Variable Description\n 1. PassengerId : unique id number to each passenger\n 1. Survived  : passenger survive(1) or died(0)\n 1. Pclass  : passenger class (1,2,3)\n 1. Name : passenger name\n 1. Sex : gender of passenger \n 1. Age : age of passenger \n 1. SibSp : number of  siblings\/spouses\n 1. Parch : number of  parents\/children\n 1. Ticket : ticket number\n 1. Fare :  amount of money spent of ticket\n 1. Cabin : cabin category\n 1. Embarked : port where passenger embarked\n ","624433fc":"* float64(2) = Age,Fare\n* int64(5) = PassengerId,Survived,Pclass,SibSp,Parch,\n* object(5) = Name,Sex,Ticket,Cabin,Embarked","2c59f7b0":"<a id = \"5\"><\/a>\n### Numerical Variable Analysis","1a60bf95":"<a id = \"11\"><\/a><br>\n\n\n# Machine Learning Part","8b34a215":"<a id = \"3\"><\/a>\n\n# Univariate Variable Analysis\n\n*Categorical Variable Analysis\n\n*Numerical Variable Analysis","cb6ea4a3":"<a id = \"4\"><\/a>\n\n### Categorical Variable Analysis","6574e3b9":"<a id = \"7\"><\/a><br>\n\n# Outlier Detection","8712335d":"<a id = \"10\"><\/a><br>\n\n## Fill Missing Value\n* Embarked has 2 missing value\n* Survived has 418 missing value\n* Age has 156 missing value\n* Cabin has 1007 missing value\n* Fare has 1 missing value ","df8dde51":"<a id = \"1\"><\/a>\n\n# Load and Check Data","85f78a48":"<a id = \"9\"><\/a><br>\n\n## Find Missing Value","6b9683b9":"<a id = \"8\"><\/a><br>\n\n# Non-Missing Value\n    * Find Missing Value\n    * Fill Missing Value","35d6781a":"# Introduction\n\n<font color = \"pink\">\nThe sinking of Titanic is one of the most notorious  shipwrecsk in the history. In 1912, during her voyage, the Titanic sank after colliding with an iceberg, 1502 people died out of 2224 passengers and crew.\n\n\n    \n    \n    \n  \n<font color = \"blue\">\nContent:\n    \n    \n    \n    \n1. [Load and Check Data](#1)\n1. [Variable Description](#2)\n    * [Univeriate Variable Analysis](#3)\n    * [Categorical Variable Analysis](#4)\n    * [Numerical Variable Analysis](#5)\n1. [Basic Data Analysis](#6)\n1. [Outlier Detection](#7)\n1. [Non-Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n1. [Machine Learning part](#11)\n    \n    \n    \n","643638db":"<a id=\"6\"><\/a><br>\n\n\n# Basic Data Analysis\n\n\n* Pclass - Survived\n\n* Sex - Survived\n\n* Sibsp - Survived\n\n* Parch - Survived\n"}}