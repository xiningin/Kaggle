{"cell_type":{"1d61697e":"code","823f5c76":"code","c304fb56":"code","9006666d":"code","bc755efa":"code","806a9ab5":"code","d87d26a2":"code","5c922bac":"code","38a1bece":"code","123c436c":"code","4778ecc7":"code","932244da":"code","c424d9b8":"code","39fb4d7a":"code","297fa71e":"code","393ffa14":"code","8d3a5ddb":"code","0ff20fef":"code","fdbdc338":"code","083eb558":"code","a36b570c":"code","3bb7ff51":"code","ac5c4daf":"code","4e795812":"markdown","72f3a8e3":"markdown"},"source":{"1d61697e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport string\nimport re\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom scipy import stats\nfrom sklearn.metrics.pairwise import linear_kernel # for cosine similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer","823f5c76":"# load data\n\ndata = pd.read_csv('..\/input\/top-video-games-19952021-metacritic\/all_games.csv')\n\ndata\n\n#len(data['title'].unique())","c304fb56":"# drop duplicates\n\ndata.drop_duplicates('name',keep='first', inplace=True)\n\ndata.reset_index(drop=True, inplace=True)\n\ndata","9006666d":"# summary stats\n\ndata.describe()","bc755efa":"# check for nulls\n\ndata.isnull().sum()\n\n# 101 null summary entries","806a9ab5":"# drop nulls\n\nnull_rows = data[data['summary'].isnull()].index\n\ndata.drop(index=null_rows, inplace=True)\n\ndata","d87d26a2":"# get info about dataframe\n\ndata.info()","5c922bac":"# clean\/process corpus\n\n# Function to streamline NLP Process\n\ndef nlp(df, text):\n    # Load string\n    # raw_data = pd.read_csv(file + '.csv')\n    \n    df['dummy'] = df[text].astype(str)\n    # Convert to lowercase\n    dummy = (post.lower() for post in df['dummy'])\n    df['dummy'] = [i for i in dummy]\n\n    # Word & Sentence Tokenization\n    token_post = (word_tokenize(post) for post in df['dummy'])\n    token_post = [i for i in token_post]\n\n    #sent_token = [sent_tokenize(post) for post in df['text']]\n    \n    # Remove Punctuation\n    reg = re.compile('(@[a-z0-9]+)|([^0-9a-z \\t])|(\\w+:\\\/\\\/\\S+)')\n\n    no_punc = []\n\n    for filt in token_post:\n        review = []\n        for token in filt:\n            new_token = reg.sub(u'', token)\n            if not new_token == u'':\n                review.append(new_token)\n        no_punc.append(review)\n        \n    # Remove Stopwords\n    no_stop = []\n\n    for post in no_punc:\n        new_term_vector = []\n        for word in post:\n            if not word in stopwords.words('english'):\n                new_term_vector.append(word)\n\n        no_stop.append(new_term_vector)\n        \n    # Stemming & Lemmatization\n    pstem = PorterStemmer()\n    wlem = WordNetLemmatizer()\n\n    preproc_text = []\n\n    for text in no_stop:\n        final_text = []\n        for word in text:\n            pstem.stem(word)\n            final_text.append(wlem.lemmatize(word))\n\n        preproc_text.append(final_text)\n        \n    # create final data set\n    #data = df.copy()\n\n    new_col = pd.Series(preproc_text)\n    df['proc_summary'] = new_col\n    df.drop('dummy', axis=1, inplace=True)\n    return df\n\nproc_data = nlp(data, 'summary')","38a1bece":"proc_data.head(10)","123c436c":"# reset proc_data index\n\nproc_data.reset_index(drop=True, inplace=True)\n\nproc_data.index","4778ecc7":"#Define TF-IDF Vectorizer Object\ntfidf = TfidfVectorizer()\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform([str(i) for i in proc_data['proc_summary']])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","932244da":"# list of feature integer indices to feature name\n\ntfidf.get_feature_names()[3000:3050]","c424d9b8":"# compute cosine similarity matrix\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n\ncosine_sim","39fb4d7a":"# reverse mapping of indices and video game titles\n\nindices = pd.Series(proc_data.index, index=proc_data['name'])#.drop_duplicates()\n\nindices","297fa71e":"# Recommendation function that takes video game title \n# as input and outputs most similar video games\n\ndef recommender_system(title, cosine_sim=cosine_sim):\n    \n    # get index of video game that matches title\n    \n    idx = indices[title]\n    \n    # get pairwise similarity scores of all video games with the given title\n    \n    sim_scores = list(enumerate(cosine_sim[idx]))\n    \n    # sort games based on similarity scores\n    \n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    \n    # get scores of 10 most similar video games\n    \n    sim_scores = sim_scores[1:11]\n    \n    # get movie indices\n    \n    game_indices = [i[0] for i in sim_scores]\n    \n    # return top 10 most similar video games\n    \n    recs = proc_data['name'].iloc[game_indices]\n    \n    return recs","393ffa14":"# test run\n\n# open-world action game\n\nrecommender_system('Grand Theft Auto V')","8d3a5ddb":"# nintendo game\n\nrecommender_system('Super Mario Galaxy')","0ff20fef":"# zombie survival game\n\nrecommender_system('Chernobylite')","fdbdc338":"# shooter game\n\nrecommender_system('Halo 2')","083eb558":"# anime fighting game\n\nrecommender_system('Naruto Shippuden: Ultimate Ninja Storm 4')","a36b570c":"# superhero game\n\nrecommender_system('X-Men: Mutant Academy')","3bb7ff51":"# sport game\n\nrecommender_system('NBA 2K2')","ac5c4daf":"# for fun\n\nrecommender_system('Heavenly Sword')","4e795812":"My original dataset, which I webscraped from the same website, consisted of the first 100 pages of the Metacritic All Time Game Scores, ordered by MetaScore.\n\nAfter finding this more expansive dataset, I've decided to implement a content-based recommender system with this dataset, mostly guided the Data camp tutorial here:\nhttps:\/\/www.datacamp.com\/community\/tutorials\/recommender-systems-python\n\nLink to the origin page of the dataset is provided here: https:\/\/www.metacritic.com\/browse\/games\/score\/metascore\/all\/all\/filtered?sort=desc","72f3a8e3":"If anybody has any ideas on how the recommendations could be improved, don't hesitate to comment!"}}