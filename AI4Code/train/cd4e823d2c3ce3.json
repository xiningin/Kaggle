{"cell_type":{"d2843d6e":"code","14761f10":"code","2faf2bf2":"code","a7f8b7f3":"code","2810ed23":"code","bfdd6013":"code","151725bf":"code","9a4e4348":"code","71df1484":"code","498c9b40":"code","e1c12877":"code","f0f3e0f9":"code","d82acb8c":"code","f42147a2":"code","32e8ee56":"code","63216bcf":"code","fe82c457":"code","51158891":"markdown","9c5395fd":"markdown","72351dd8":"markdown","c46ab2dc":"markdown","eab150b8":"markdown","8f82b026":"markdown","8eb93104":"markdown","c9a1a3c3":"markdown","a851141f":"markdown","345d425c":"markdown","000433e4":"markdown","a431aaf6":"markdown"},"source":{"d2843d6e":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb # classifiers using boosted trees\n\nfrom bokeh.plotting import figure, show\nfrom bokeh.layouts import gridplot\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, ColorBar\nfrom bokeh.transform import linear_cmap\nfrom bokeh.palettes import viridis","14761f10":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","2faf2bf2":"train['SexNumerical'] = train.apply(lambda x: 0.0 if x['Sex']=='male' else 1.0, axis = 1)\ntest['SexNumerical'] = test.apply(lambda x: 0.0 if x['Sex']=='male' else 1.0, axis = 1)\nmask = [False if np.isnan(xi) == True else True for xi in train['Age'].values.tolist()]\ntrain = train[mask]\ntrain_male = train[train['Sex']=='male']\ntrain_female = train[train['Sex']=='female']\ntrain_male_age_1 = train_male[train_male['Survived']==1]['Age'].values\ntrain_male_age_0 = train_male[train_male['Survived']==0]['Age'].values\ntrain_female_age_1 = train_female[train_female['Survived']==1]['Age'].values\ntrain_female_age_0 = train_female[train_female['Survived']==0]['Age'].values\n\nhist_male_1, edges_male_1 = np.histogram(train_male_age_1, density = False, bins = range(0,80,5))\nhist_male_0, edges_male_0 = np.histogram(train_male_age_0, density = False, bins = range(0,80,5))\nhist_female_1, edges_female_1 = np.histogram(train_female_age_1, density = False, bins = range(0,80,5))\nhist_female_0, edges_female_0 = np.histogram(train_female_age_0, density = False, bins = range(0,80,5))\nxm = np.linspace(min(min(train_male_age_1), min(train_male_age_0)), max(max(train_male_age_0), max(train_male_age_1)), 100)\nxm = np.linspace(min(min(train_female_age_1), min(train_female_age_0)), max(max(train_female_age_0), max(train_female_age_1)), 100)","a7f8b7f3":"male_survivability = len(train_male_age_1)\/len(train_male)\nfemale_survivability = len(train_female_age_1)\/len(train_female)\nprint('Survivability Rates')\nprint('Males: ' + str(np.round(male_survivability*100., decimals=2)) + '%, Females: '+ str(np.round(female_survivability*100., decimals=2)) + '%')","2810ed23":"output_notebook()\npm = figure(title = 'Male Survivability with Age', x_range = (0, 85), y_range = (0, 80))\npm.quad(top = hist_male_1, bottom = 0, left = edges_male_1[:-1], right = edges_male_1[1:], fill_color = 'navy', alpha = 0.5, legend = 'Survived')\npm.quad(top = hist_male_0, bottom = 0, left = edges_male_0[:-1], right = edges_male_0[1:], fill_color = 'red', alpha = 0.5, legend = 'Perished')\npm.legend.location = 'center_right'\npm.xaxis.axis_label = 'Age'\npm.yaxis.axis_label = 'Individuals'\npf = figure(title = 'Female Survivability with Age', x_range = (0, 85), y_range = (0, 80))\npf.quad(top = hist_female_1, bottom = 0, left = edges_female_1[:-1], right = edges_female_1[1:], fill_color = 'navy', alpha = 0.5, legend = 'Survived')\npf.quad(top = hist_female_0, bottom = 0, left = edges_female_0[:-1], right = edges_female_0[1:], fill_color = 'red', alpha = 0.5, legend = 'Perished')\npf.legend.location = 'center_right'\npf.xaxis.axis_label = 'Age'\npf.yaxis.axis_label = 'Individuals'\nshow(gridplot([pm,pf], ncols = 2, plot_width = 400, plot_height = 400, toolbar_location = None))","bfdd6013":"train_fare_1 = train[train['Survived']==1]['Fare'].dropna()\ntrain_fare_0 = train[train['Survived']==0]['Fare'].dropna()\nhist_fare_1, edges_fare_1 = np.histogram(train_fare_1, density = False, bins = range(0,300,10))\nhist_fare_0, edges_fare_0 = np.histogram(train_fare_0, density = False, bins = range(0,300,10))\n\nclasses = sorted(train['Pclass'].unique())\nclass_df = pd.DataFrame(index = classes, columns = ['Survivability'])\nfor c in classes:\n    c_tot = train[train['Pclass']==c]\n    c_1 = c_tot[c_tot['Survived']==1]\n    class_df.at[c, 'Survivability'] = float(len(c_1))\/float(len(c_tot))*100","151725bf":"output_notebook()\np1 = figure(title = 'Survivability with Fare Amount', x_range = (0, 300), y_range = (0, 200))\np1.quad(top = hist_fare_1, bottom = 0, left = edges_fare_1[:-1], right = edges_fare_1[1:], fill_color = 'navy', alpha = 0.5, legend = 'Survived')\np1.quad(top = hist_fare_0, bottom = 0, left = edges_fare_0[:-1], right = edges_fare_0[1:], fill_color = 'red', alpha = 0.5, legend = 'Perished')\np1.xaxis.axis_label = 'Fare Amount'\np1.yaxis.axis_label = 'Individuals'\np1.legend.location = 'center_right'\ncats = ['Class ' + str(x) for x in class_df.index.values.tolist()]\n\nmapper = linear_cmap(field_name='counts', palette=viridis(256) ,low=0. ,high=100.)\ncolor_bar = ColorBar(color_mapper=mapper['transform'], width=8,  location=(0,0))\n\nsource = ColumnDataSource(data = dict(cats=cats, counts = class_df['Survivability']))\np2 = figure(title = 'Survivability Rate and Fare Class', x_range = cats, y_range = (0, 100))\np2.vbar(x = 'cats', top = 'counts', color = mapper, width = 0.9, source = source)\np2.yaxis.axis_label = 'Chance of Survival (%)'\np2.add_layout(color_bar, 'right')\nshow(gridplot([p1,p2], ncols = 2, plot_width = 400, plot_height = 400, toolbar_location = None))\n","9a4e4348":"\ntrain['Family Size']= train['SibSp']+train['Parch']+1\ntrain['Family Size']= train.apply(lambda x: str(x['Family Size']), axis = 1)\ntest['Family Size']= test['SibSp']+train['Parch']+1\ntest['Family Size']= test.apply(lambda x: str(x['Family Size']), axis = 1)\ntrain_fs_1 = train[train['Survived'] == 1][['PassengerId','Family Size']].groupby('Family Size').count().reset_index()\ntrain_fs_totals = train[['PassengerId', 'Family Size']].groupby('Family Size').count().reset_index()\ntrain_fs_1 = pd.merge(train_fs_1, train_fs_totals, on = 'Family Size')\ntrain_fs_1['Chance'] = train_fs_1['PassengerId_x']\/train_fs_1['PassengerId_y']*100.\nsource = ColumnDataSource(train_fs_1)\n\nmapper = linear_cmap(field_name='Chance', palette=viridis(256) ,low=0 ,high=100.)\ncolor_bar = ColorBar(color_mapper=mapper['transform'], width=8,  location=(0,0))\n\noutput_notebook()\np = figure(title = 'Survivability with Family Size', x_range = train_fs_1['Family Size'], y_range = (0, 100))\np.vbar(x = 'Family Size', top = 'Chance', color = mapper, width = 0.9, source = source)\np.xaxis.axis_label = 'Family Size'\np.yaxis.axis_label = 'Chance of Survival (%)'\np.add_layout(color_bar, 'right')\nshow(gridplot([p], ncols = 1, plot_width = 400, plot_height = 400, toolbar_location = None))\n","71df1484":"def train_test_split(X,y, perc):\n    '''Performs a simple random sample of the training data returning a training and testing set'''\n    trainx = X.sample(frac=perc, replace = False, random_state = 0)\n    sel = trainx.index.values.tolist()\n    trainy = y.loc[sel]\n    notsel = []\n    for i in X.index.values.tolist():\n        if i not in sel:\n            notsel.append(i)\n    testx = X.loc[notsel]\n    testy = y.loc[notsel]\n    return trainx, trainy, testx, testy","498c9b40":"\ntrainx = train[['Pclass','Fare','SexNumerical','Age','Family Size']].copy()\ntrainx['Family Size'] = trainx.apply(lambda x: float(x['Family Size']), axis=1)\ntrainy = train['Survived']\ntrainx, trainy, testx, testy = train_test_split(trainx, trainy, 0.8)\nparam = {'max_depth':5, 'eta': 0.5, 'silent': 1, 'booster': 'gbtree', 'objective': 'binary:logistic', 'eval_metric':'error'}\nnum_round = 10\nDtrain = xgb.DMatrix(trainx, label = trainy)\nDtest = xgb.DMatrix(testx, label = testy)\nwatchlist = [(Dtest, 'eval'), (Dtrain, 'train')]","e1c12877":"bst = xgb.train(param, Dtrain, num_round, watchlist)","f0f3e0f9":"ypred = bst.predict(Dtest)\nlabels = Dtest.get_label()\nprint('error=%f' % (sum(1 for i in range(len(ypred)) if int(ypred[i] > 0.5) != labels[i]) \/ float(len(ypred))))","d82acb8c":"trainx = train[['Pclass','Fare','SexNumerical','Age','Family Size']].copy()\ntrainx['Family Size'] = trainx.apply(lambda x: float(x['Family Size']), axis=1)\ntrainy = train['Survived']\nDtrain = xgb.DMatrix(trainx, label = trainy )\nbst = xgb.train(param, Dtrain, num_round, watchlist)","f42147a2":"xeval = test[['Pclass','Fare','SexNumerical','Age','Family Size']].copy()\nxeval['Age']=xeval['Age'].fillna(np.nanmean(xeval['Age']))\nxeval['Family Size']=xeval.apply(lambda x: float(x['Family Size']), axis = 1)\nxeval['Family Size']=xeval['Family Size'].fillna(np.nanmean(xeval['Family Size']))\nxeval['Fare']=xeval['Fare'].fillna(np.nanmean(xeval['Fare']))\nDeval = xgb.DMatrix(xeval)\nypred_eval = bst.predict(Deval)\nypred_eval_out = np.hstack([test['PassengerId'].values.reshape(-1,1), ypred_eval.reshape(-1,1)])\nypred_eval_out = pd.DataFrame(ypred_eval_out, columns=['PassengerId', 'Score'])\nypred_eval_out['Survived']=ypred_eval_out.apply(lambda x: 1 if x['Score']>=0.5 else 0, axis =1)\nypred_eval_out['PassengerId']=ypred_eval_out.apply(lambda x: int(x['PassengerId']), axis =1 )\nypred_eval_out = ypred_eval_out[['PassengerId', 'Survived']].set_index('PassengerId')\nypred_eval_out.to_csv('output.csv')","32e8ee56":"ypred_eval.shape","63216bcf":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\npipe = Pipeline(steps = [('minmax',MinMaxScaler()), ('svc',SVC(C=1., kernel = 'rbf', gamma = 'auto'))])\n\nparams = {'svc__C':[0.1,1.0,10.,100., 1000.]}\n\nclf = GridSearchCV(pipe, params, cv=4).fit(trainx, trainy)\nprint(clf.best_score_, clf.best_params_)\n","fe82c457":"svm_predictions = pd.DataFrame(columns = ['PassengerId', 'Survived'], data = np.hstack([test['PassengerId'].values.reshape(-1,1), clf.predict(xeval).reshape(-1,1)])).set_index('PassengerId')\nsvm_predictions.to_csv('outputsvm.csv')","51158891":"## Make Predictions on the Evaluation Set","9c5395fd":"# 1 Exploration of Titanic Dataset w\/ Bokeh Visuals\n\nFirst we explore the dataset to see what features we might want to use for our classifier.  To help with our exploration we practice using the Bokeh visualization module. ","72351dd8":"## 1.4 Family Size\n\nWe will now move on to the effects of family size.  Some have speculated that by travelling alone, or not travelling alone, one might somehow derive an advantage over others in terms of survivability.  We will add the number of siblings\/spouses and the number of parents on board for each passenger into one family size variable and compare survivability rates.","c46ab2dc":"From this information, we can clearly see that lower fares are associated with lower survivability.   Taking only fare information as an input, we can estimate that passengers who paid less than 50 for their ticket were more likely than not to perish.  Meanwhile passengers who paid more than 50 for their ticket were likely to survive.  This trend can also be seen when looking at the fare class, where first class passengers are nearly three times as likely to survive as third class passengers.","eab150b8":"From the age distributions we can immediately see several key takeaways:\n\n- There were many more males on board than females. \n- Males had a much lower survivability rate above age 15 than females did.\n- Males aged 15-25 had the lowest survivability rates.  Less than 10% of males in these age groups survived.\n- Females aged 50+ had the highest survivability rates.  Only 10% of females above 50 perished.","8f82b026":"## 1.2 Survivability of Males and Females with Age\n\nFor our first explorations we take a look at whether males or females have a better chance of surviving in the training set, and whether or not age seems to make a difference. ","8eb93104":"Calculate survivability overall survivability statistics for males and females.","c9a1a3c3":"## 2. Model Building Using XGBoost","a851141f":"## 1.3 Effects of Affluence - Ticket Prices and Fare Class\n\n* First we will look at the price distributions for those that survived and did not. ","345d425c":"# Titanic Survivability Predictions\n\nIn this notebook we will explore the titanic dataset, visualize some important features of the data using the Bokeh module, do some data cleaning and formatting of the data for use in some common classifiers, and finally we will build and evaluate those classifiers on our dataset. ","000433e4":"From the above we can see that there is a significant preference for average sized families.  Members of families comprising 4 persons fared the best, with a better than a 75% survival rate. Both large families and individuals without families fared poorly.  It's unclear why this relationship exists, but some have speculated that individuals disproportionately perished because families were chosen for lifeboats ahead of individuals.  At the high end, its possible that larger families took longer to organize and therefore experienced lower survival rates.  An alternate theory is that there is a strong correlation between social class and large family sizes.  Its additionally likely that the smaller sample sizes for the higher family sizes play an important role.","a431aaf6":"## 1.1 Import Packages and Load Data"}}