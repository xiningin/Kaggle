{"cell_type":{"59c87e8c":"code","02175f0a":"code","b6816c9a":"code","c10a1d8e":"code","024ea51c":"code","7c229c4d":"code","191e779f":"code","f49aa8d2":"code","2e0ef367":"code","6561e55e":"code","4a25edaa":"code","15971dc4":"markdown","4470b225":"markdown","f6a35681":"markdown","e5f72aa9":"markdown","6aafba60":"markdown"},"source":{"59c87e8c":"# Import necessary libraries\nfrom copy import deepcopy #for keeping original values unchanged\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt","02175f0a":"# Set three centers, the model should predict similar results\ncenter_1 = np.array([1,1])\ncenter_2 = np.array([5,5])\ncenter_3 = np.array([8,1])\n\n# Generate random data and center it to the three centers\ndata_1 = np.random.randn(200, 2) + center_1\ndata_2 = np.random.randn(200,2) + center_2\ndata_3 = np.random.randn(200,2) + center_3\n\ndata = np.concatenate((data_1, data_2, data_3), axis = 0)\n\nplt.scatter(data[:,0], data[:,1], s=7)","b6816c9a":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","c10a1d8e":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\nprint(centers_new)    ","024ea51c":"# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","7c229c4d":"df = pd.read_csv(\"..\/input\/Iris.csv\") #load the dataset\ndf.drop('Id',axis=1,inplace=True) ","191e779f":"df.head()","f49aa8d2":"# Change categorical data to number 0-2\ndf[\"Species\"] = pd.Categorical(df[\"Species\"])\ndf[\"Species\"] = df[\"Species\"].cat.codes\n# Change dataframe to numpy matrix\ndata = df.values[:, 0:4]\ncategory = df.values[:, 4]","2e0ef367":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","6561e55e":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\nprint(centers_new)   ","4a25edaa":"# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","15971dc4":"# Generate Random Data\nGenerate random data normally distributed around 3 centers, with a noise.","4470b225":"# K-Means Clustering\n\nA description of the algorithm can be found:\nhttps:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/cs229-notes7a%202.pdf\n\n![](https:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/k4XcapI.gif?raw=true)","f6a35681":"# Test on Iris Dataset","e5f72aa9":"*Thanks everyone *\n\n-Gaurav Saha-","6aafba60":"# Create K-Means Algorithm\nGenerate random data normally distributed around 3 centers, with a noise."}}