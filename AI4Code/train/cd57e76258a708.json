{"cell_type":{"829a6dee":"code","6fe1687f":"code","60bfa7fa":"code","2714ac59":"code","76364338":"code","43b65636":"code","6c1f7c57":"code","46fa7b76":"code","a4a46a12":"code","bdda51fa":"code","578379a3":"code","9bf1b1e2":"code","26693e1b":"code","df7534ca":"code","7ef15901":"code","cebc2be1":"code","30e82138":"code","250f2045":"code","e7562e80":"code","53838521":"code","479e296c":"code","11d54009":"code","87f61897":"code","c185e197":"markdown","c158567a":"markdown","9e046f35":"markdown","1c72192d":"markdown","4581ffc6":"markdown","850dd0a9":"markdown","cce15478":"markdown","7089f7b8":"markdown","88b29f16":"markdown","760985a0":"markdown","fcbc12ee":"markdown"},"source":{"829a6dee":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport os\nfrom distutils.dir_util import copy_tree, remove_tree\n\nfrom PIL import Image\nfrom random import randint\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow_addons as tfa\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n\n\nprint(\"TensorFlow Version:\", tf.__version__)","6fe1687f":"base_dir = \"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/\"\nroot_dir = \".\/\"\ntest_dir = base_dir + \"test\/\"\ntrain_dir = base_dir + \"train\/\"\nwork_dir = root_dir + \"dataset\/\"\n\nif os.path.exists(work_dir):\n    remove_tree(work_dir)\n    \n\nos.mkdir(work_dir)\ncopy_tree(train_dir, work_dir)\ncopy_tree(test_dir, work_dir)\nprint(\"Working Directory Contents:\", os.listdir(work_dir))","60bfa7fa":"WORK_DIR = '.\/dataset\/'\n\nCLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']\n\nIMG_SIZE = 176\nIMAGE_SIZE = [176, 176]\nDIM = (IMG_SIZE, IMG_SIZE)","2714ac59":"#Performing Image Augmentation to have more data samples\n\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\n\nwork_dr = IDG(rescale = 1.\/255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)","76364338":"def show_images(generator,y_pred=None):\n    \"\"\"\n    Input: An image generator,predicted labels (optional)\n    Output: Displays a grid of 9 images with lables\n    \"\"\"\n    \n    # get image lables\n    labels =dict(zip([0,1,2,3], CLASSES))\n    \n    # get a batch of images\n    x,y = generator.next()\n    \n    # display a grid of 9 images\n    plt.figure(figsize=(10, 10))\n    if y_pred is None:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            idx = randint(0, 6400)\n            plt.imshow(x[idx])\n            plt.axis(\"off\")\n            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n                                                     \n    else:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n    \n# Display Train Images\nshow_images(train_data_gen)","43b65636":"#Retrieving the data from the ImageDataGenerator iterator\n\ntrain_data, train_labels = train_data_gen.next()","6c1f7c57":"#Getting to know the dimensions of our dataset\n\nprint(train_data.shape, train_labels.shape)","46fa7b76":"#Performing over-sampling of the data, since the classes are imbalanced\n\nsm = SMOTE(random_state=42)\n\ntrain_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(train_data.shape, train_labels.shape)","a4a46a12":"#Splitting the data into train, test, and validation sets\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)","bdda51fa":"inception_model = InceptionV3(input_shape=(176, 176, 3), include_top=False, weights=\"imagenet\")","578379a3":"for layer in inception_model.layers:\n    layer.trainable=False","9bf1b1e2":"custom_inception_model = Sequential([\n        inception_model,\n        Dropout(0.5),\n        GlobalAveragePooling2D(),\n        Flatten(),\n        BatchNormalization(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        BatchNormalization(),\n        Dense(4, activation='softmax')        \n    ], name = \"inception_cnn_model\")","26693e1b":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \nmy_callback = MyCallback()\n\n#ReduceLROnPlateau to stabilize the training process of the model\nrop_callback = ReduceLROnPlateau(monitor=\"val_loss\", patience=3)","df7534ca":"METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'),\n           tfa.metrics.F1Score(num_classes=4)]\n\nCALLBACKS = [my_callback, rop_callback]\n    \ncustom_inception_model.compile(optimizer='rmsprop',\n                              loss=tf.losses.CategoricalCrossentropy(),\n                              metrics=METRICS)\n\ncustom_inception_model.summary()","7ef15901":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 100\n\nhistory = custom_inception_model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","cebc2be1":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","30e82138":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n#val_scores = model.evaluate(val_data, val_labels)\ntest_scores = custom_inception_model.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","250f2045":"#Predicting the test data\n\npred_labels = custom_inception_model.predict(test_data)","e7562e80":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","53838521":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels= CLASSES,\n                yticklabels=CLASSES)\n\nplt.title('Alzheimer\\'s Disease Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","479e296c":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","11d54009":"#Saving the model for future use\n\ncustom_inception_model_dir = work_dir + \"alzheimer_inception_cnn_model\"\ncustom_inception_model.save(custom_inception_model_dir, save_format='h5')\nos.listdir(work_dir)","87f61897":"pretrained_model = tf.keras.models.load_model(custom_inception_model_dir)\n\n#Check its architecture\nplot_model(pretrained_model, to_file=work_dir + \"model_plot.png\", show_shapes=True, show_layer_names=True)","c185e197":"**Please check out the notebook here: \n[Custom CNN Model Notebook](https:\/\/www.kaggle.com\/vishakansubramanian\/alzheimer-s-disease-classification-notebook)**","c158567a":"\ud83d\udd78\ufe0f A Convolutional Neural Network (CNN) model is used here to classify brain MRIs into normal, very-mild, mild and moderate Alzheimer classes. The data in total consists of 6400 images.","9e046f35":"Developed as part of a project work for the **UCS 1603 Introduction to Machine Learning** Course. \ud83d\udcd6","1c72192d":"### Using the InceptionV3 model as a base model for the task","4581ffc6":"### Importing the necessary libraries","850dd0a9":"Authors:\n* Shashanka Venkatesh  - 18 5001 145\n* Suraj Jain           - 18 5001 177\n* Vishakan Subramanian - 18 5001 196\n* Vishnu Krishnan      - 18 5001 200","cce15478":"### Data Pre-Processing","7089f7b8":"### Tabulating the Results of our custom InceptionV3 model","88b29f16":"### Using a custom CNN model for the task","760985a0":"**We recommend the use of a GPU Accelerator to reduce the load on the CPU and to run the notebook faster.**","fcbc12ee":"# \ud83e\udde0 Alzheimer's Disease Classification"}}