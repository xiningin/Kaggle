{"cell_type":{"18a05811":"code","916efba4":"code","b53f2ae7":"code","942c3985":"code","f82b93fe":"code","f914b331":"code","0cfa2144":"code","f6ba64e4":"code","fd436c09":"code","f0b698ab":"code","56f8a418":"code","486dc4f4":"code","deea3a75":"code","b3c8d645":"code","38e3862b":"markdown","8c50c363":"markdown","85882b2b":"markdown","312441cc":"markdown","0dbe287f":"markdown","341feeb9":"markdown","268b5de2":"markdown","70342f5f":"markdown","d3ee3a13":"markdown","5064e8d9":"markdown","49e34c16":"markdown","e395bf65":"markdown","5853ac62":"markdown","5ac3ab9c":"markdown"},"source":{"18a05811":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread","916efba4":"def rgb_to_gray(rgb):\n# Convert rgb images to gray images\n    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\n# Create a list with the shape of the images (circles, squares or triangles)\n# and the images\nlst_images = []\n\ndirectories = os.listdir(\"..\/input\/basicshapes\/shapes\")\ndirectories.remove(\"shapes\")\n\nfor d in directories:\n    for i in os.listdir(\"..\/input\/basicshapes\/shapes\/\"+d):\n        img = plt.imread(\"..\/input\/basicshapes\/shapes\/\"+d+\"\/\"+i)\n        img = rgb_to_gray(img)\n        # Reshape the images to 28x28x1 for the neural network\n        img = np.array(img).reshape(28,28,1)\n        lst_images.append([d,img])","b53f2ae7":"# Shuffle the list to make the training more effective\nimport random\nrandom.shuffle(lst_images)","942c3985":"# Separate the images from the labels\n# Rename the labels into:\n# squares => 0\n# circles => 1\n# triangles => 2\nX = []\ny = []\nfor i in range(len(lst_images)):\n    X.append(lst_images[i][1])\n    \n    yi = lst_images[i][0]\n    if yi == \"squares\":\n        y.append(0)\n    elif yi == \"circles\":\n        y.append(1)\n    else:\n        y.append(2)","f82b93fe":"# Show a few images of the dataset with labels\nfor i in range(3):\n    plt.imshow(X[i].reshape(28,28))\n    plt.title(lst_images[i][0], fontsize =18)\n    plt.show()","f914b331":"# Convert the labels y with to_categorical for the neural network\n# Example: [2,1] => [[0,0,1],[0,1,0]]\nfrom tensorflow.keras.utils import to_categorical\ny = to_categorical(y)","0cfa2144":"# Split the dataset into a train-set and a test-set\nfrom sklearn.model_selection import train_test_split\nX = np.array(X)\ny = np.array(y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","f6ba64e4":"import tensorflow.keras\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D, BatchNormalization, AveragePooling2D\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ndef from_categorical(lst):\n    \"\"\"\n    Inverse of to_categorical\n    Example: [[0,0,0,1,0], [1,0,0,0,0]] => [3,0]\n    \"\"\"\n    \n    lst = lst.tolist()\n    lst2 = []\n    for x in lst:\n        lst2.append(x.index(max(x)))\n    return lst2\n","fd436c09":"def LeNet(Conv2D_filters = 128, \n          validation_split = 0.2,\n          X_train = X_train, \n          X_test = X_test, \n          y_train = y_train, \n          y_test = y_test):\n    \n    # Create the LeNet model \n    model = Sequential()\n    model.add(Conv2D(filters=Conv2D_filters, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n    model.add(MaxPooling2D())\n    model.add(Conv2D(filters=Conv2D_filters*2, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D())\n    model.add(Flatten())\n    model.add(Dense(units=120, activation='relu'))\n    model.add(Dense(units=84, activation='relu'))\n    model.add(Dense(units=3, activation = 'softmax'))\n    \n    # Compile and train the model\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n    model.fit(x = X_train, y = y_train, batch_size = 128, epochs = 100, verbose = 0, validation_split = validation_split)\n    \n    # Display the results\n    # print(\"################### New model ###################\")\n    length = len(model.history.history[\"accuracy\"])\n    plt.plot(np.arange(0, length), model.history.history[\"accuracy\"], label=\"accuracy\")\n    \n    # Display the validation results only if there is a validation split\n    if validation_split > 0:\n        plt.plot(np.arange(0, length), model.history.history[\"val_accuracy\"], label=\"val_accuracy\")\n        plt.title(f\"Accuracy & Validation accuracy\\nNumber of Conv. filters: {Conv2D_filters}\")\n    else:\n        plt.title(f\"Accuracy\\nNumber of Conv. filters: {Conv2D_filters}\")\n        \n    plt.xlabel(\"Epoch #\")\n    plt.show()\n\n    y_test2 = from_categorical(y_test)\n    pred = model.predict_classes(X_test)\n\n    print(\"### Test-set ###\\n\\nConfusion Matrix:\\n\")\n    print(confusion_matrix(y_test2,pred))\n    print(f\"\\nAccuracy: {accuracy_score(y_test2,pred)}\")\n    \n    return model","f0b698ab":"for f in [2**x for x in range(4,8)]:\n    LeNet(f)","56f8a418":"model = LeNet(64, 0)","486dc4f4":"# Rotating an image\nimg = X_train[2]\nfor i in range(0,4):\n    plt.figure(figsize = (3,3))\n    plt.title(f\"Rotate image by {i*90} degree\")\n    plt.imshow(np.rot90(img,i).reshape(28,28))\n    plt.show()","deea3a75":"# Generate new data\n# Create a list with the original train data and the new ones\nX_train_gener = []\ny_train_gener = []\nfor i in range(len(X_train)):\n    img = X_train[i]\n    for r in range(4):\n        img = np.rot90(img,r)\n        X_train_gener.append(img)\n        y_train_gener.append(y_train[i])\n\n# Shuffle the picture and the label on a deterministic way\nrandom.Random(0).shuffle(X_train_gener) \nrandom.Random(0).shuffle(y_train_gener) \n\nX_train_gener = np.array(X_train_gener)\ny_train_gener = np.array(y_train_gener)\n\nprint(f\"Total number of training data: {len(X_train_gener)}\")","b3c8d645":"model = LeNet(64, 0.2, X_train=X_train_gener, y_train = y_train_gener)","38e3862b":"Now a days, the LeNet-5 architecture usually isn't very good anymore, but it is simple, and it is quite fast to train, because it has \"only\" around 60.000 parameters. It isn't a lot in comparison to VGG16 (138.000.000). Back to 1998, the computers didn't have the brute computing force to calculate millions of parameters in a short time, therefore this architecture was well fit. Let's see how it will perform on this dataset.\n\nIn the following we will change a bit the original architecture. Among the changes we will reduce the output from 10 to 3, because we have only 3 different classes. In Addition, we will try different numbers of filters for the convolutional layers to see which one work the best.\n","8c50c363":"# 1. Charge and transform the dataset<a class=\"anchor\" id=\"1\"><\/a>","85882b2b":"<img src=\"https:\/\/i.imgur.com\/84xH8Go.png\" alt=\"neuron\" align = \"left\">","312441cc":"The number of filters doesn't seem to a have a big influence on the results. In the following we will train a LeNet-5 model without validation split to let it train with more data and take a look at the predictions.  ","0dbe287f":"The dataset consists of pictures of 100 triangles, 100 squares and 100 circles, each PNG-image has a size of 28x28 px and the images are in 3 folders.","341feeb9":"We will try different number of filters [16, 32, 64, 128] for the conventional layer to see which one gives the best results. ","268b5de2":"We will use a comprehensible technic to generate more data using the available ones. Rotating each image 3 times will make it possible to multiple the train set by 4.","70342f5f":"LeNet is a convolutional neural network structure proposed by Yann LeCun et al. in 1998. In general, LeNet refers to lenet-5 and is a simple convolutional neural network. Convolutional neural networks are a kind of feed-forward neural network whose artificial neurons can respond to a part of the surrounding cells in the coverage range and perform well in large-scale image processing.\n \nLeNet5 was one of the earliest convolutional neural networks and promoted the development of deep learning. Since 1988, after years of research and many successful iterations, the pioneering work has been named LeNet5. (<a href=\"https:\/\/en.wikipedia.org\/wiki\/LeNet\">Source<\/a>)\n\n<img src = \"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/2\/22\/Yann_LeCun_-_2018_%28cropped%29.jpg\/220px-Yann_LeCun_-_2018_%28cropped%29.jpg\">\n<center><i>Yann LeCun - the creator of this architecture<\/i><\/center>","d3ee3a13":"# Table of contents\n\n[<h3>1. Content of the dataset & cleaning<\/h3>](#1)\n\n[<h3>2. Create and train the LeNet-5 Architecture<\/h3>](#2)\n\n[<h3>3. Generate artificial data to improve the accuracy of the predictions<\/h3>](#3)","5064e8d9":"<strong>With this simple way of generating artificial data the prediction accuracy was improved by around 10%!<\/strong> We could even generate more data by moving the figures in the picture, increasing their sides etc. \n\n<img src=\"https:\/\/i.imgur.com\/aFYJXdH.png\" alt = \"improve\" align = \"left\">","49e34c16":"# Shape recognition using LeNet-5 (around 93% accuracy)\n","e395bf65":"# 2. Create and train the LeNet-5 Architecture<a class=\"anchor\" id=\"2\"><\/a>\n<img src=\"https:\/\/i.imgur.com\/PNyzJWo.png\">\nOriginal Image published in [LeCun et al., 1998]","5853ac62":"# 3. Generate artificial data to improve the accuracy of the predictions<a class=\"anchor\" id=\"3\"><\/a>","5ac3ab9c":"Taking in account that the model isn't deterministic, the result differs a bit each time, but in general, is slightly better, because the model had more data to train on. Another way of improving the result, would be to give even more data to train on to the model, this can be done generating artificially new data from the old ones."}}