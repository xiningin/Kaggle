{"cell_type":{"56ecf585":"code","2661ea4e":"code","d2c9c037":"code","fc4131b5":"code","6d273966":"code","6a34d194":"code","6cdcb4d9":"code","f38b9771":"code","f81a11fb":"code","bc7abdf6":"code","19aaae39":"code","da699107":"code","1db76052":"code","3a69f654":"code","0dd7e171":"code","4770d1b4":"code","3bb4e4c9":"code","1b2d6a02":"code","d22bcffa":"code","9e9b362e":"code","daef8cfb":"code","15cfc241":"code","8ca02afa":"code","e4b6e117":"code","2656c0ea":"code","e64fa5e9":"markdown"},"source":{"56ecf585":"from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom mlxtend.classifier import StackingClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport re","2661ea4e":"path = \"\/kaggle\/input\/titanic\/\"\ndf_tr = pd.read_csv(f\"{path}train.csv\").set_index(\"PassengerId\", drop=True)\ndf_ts = pd.read_csv(f\"{path}test.csv\").set_index(\"PassengerId\", drop=True)\ndf = pd.concat([df_tr, df_ts], axis=0)\ndf","d2c9c037":"df[\"Deck\"] = df[\"Cabin\"].str[:1]\ndf[\"Deck\"] = df[\"Deck\"].replace(np.nan,\"N\/A\")\ndf.loc[df[\"Deck\"]=='T',\"Deck\"] = 'N\/A'","fc4131b5":"replaces = {'B51 B53 B55': 'B55', 'B52 B54 B56': 'B56', 'B57 B59 B63 B66': 'B66', 'B58 B60': 'B60', \n            'B82 B84': 'B84', 'B96 B98': 'B98', 'C22 C26': 'C26', 'C23 C25 C27': 'C27', 'C55 C57': 'C57',\n            'C62 C64': 'C64', 'D10 D12': 'D12', 'E39 E41': 'E41', 'F E46': 'E46', 'F E57': 'E57',\n            'F E69': 'E69', 'F G63': 'G63', 'F G73': 'G73', 'F': None, 'D': None, ' ': None, 'T': None, np.nan: None}\ndf[\"Cabin\"] = df[\"Cabin\"].replace(replaces)\ndf[\"Cabin\"] = df.fillna(np.nan)[\"Cabin\"].str[1:].astype(float)","6d273966":"df[\"Side\"] = df[\"Cabin\"]\ndf.loc[df[\"Side\"]!=0,\"Side\"] = (df[\"Cabin\"][df[\"Cabin\"]!=0]%2-0.5)*2","6a34d194":"for i in set(df[\"Deck\"].values):\n    v = df[df[\"Deck\"]==i][\"Cabin\"]\/\/2\n    df.loc[df[\"Deck\"]==i, \"Cabin\"]= v\n    df.loc[(df[\"Deck\"]==i) & (df[\"Cabin\"]==0),\"Cabin\"] = np.median(v)\n    \ndf.loc[df[\"Cabin\"].isna(),\"Cabin\"]=-1\ndf[\"Cabin\"] = df[\"Cabin\"].astype(int)\ndf","6cdcb4d9":"df[\"Side\"] = df[\"Side\"].fillna(0)","f38b9771":"lin_rep = lambda x: x.replace({'LINE':\"370160\"})\ndf = lin_rep(df)","f81a11fb":"prefixes = []\nnums, prefs = [],[]\nfor i in df[\"Ticket\"].values:   \n    if not i.isdigit():\n        nums.append(int(re.search('.* {1}([0-9]+)', i).groups()[0]))\n        prefix = re.search('(.*)( {1})[0-9]+', i).groups()[0]\n        prefs.append(prefix.replace(\".\",\"\").replace(\" \", \"\").replace(\"\/\",\"\")) # Needed to put in one group such prefixes as \"A\/5\", \"A\/5.\", \"A.5\" etc.\n    else:\n        nums.append(int(i))\n        prefs.append(\"\")\ndf[\"Ticket\"] = nums\ndf[\"Ticket_p\"] = prefs\ndf","bc7abdf6":"drop = [\"SP\", \"SOP\", \"Fa\", \"SCOW\", \"PPP\", \"AS\", \"CASOTON\", \"SWPP\", \"SCAHBasle\", \"SCA3\", \"STONOQ\", \"AQ4\", \"A2\", \"LP\", \"AQ3\", \"\"]\ndf = df.replace(drop, 'N\/A')\ndf","19aaae39":"df[[\"Surname\",\"Name\"]] = [i.split(\",\") for i in df[\"Name\"].values]\ndf","da699107":"df[\"Title\"] = pd.DataFrame(df[\"Name\"].str.strip().str.split(\".\").tolist()).set_index(df.index).iloc[:,0]\ndf[\"Title\"] = df[\"Title\"].fillna(\"Others\")","1db76052":"rename = {\"Miss\":\"Ms\",\n          \"Mrs\": \"Mme\",\n          \"Others\": [\"Don\",\"Rev\",\"Dr\",\"Lady\",\"Sir\",\"Mlle\",\"Col\",\"the Countess\",\"Mme\",\"Major\",\"Capt\",\"Jonkheer\",\"Dona\"]}\nfor k in rename:\n    df[\"Title\"] = df[\"Title\"].replace(rename[k],k)","3a69f654":"df[\"Kid\"]=0\ndf.loc[(df[\"Age\"]<18),\"Kid\"]=1","0dd7e171":"df[\"Old\"]=0\ndf.loc[(df[\"Age\"]>60),\"Old\"]=1","4770d1b4":"df[\"Alone\"] = 0\ndf.loc[(df[\"Parch\"]==0) & (df[\"SibSp\"]==0),\"Alone\"]=1\ndf","3bb4e4c9":"from itertools import *\nl1, l2 = [1,2,3], [\"female\",\"male\"]\nfor c,s in product(l1,l2):\n    msk = (df[\"Pclass\"]==c) & (df[\"Sex\"]==s)    \n    df.loc[msk,\"Age\"] = df[msk][\"Age\"].fillna(df[msk][\"Age\"].median())","1b2d6a02":"df.loc[1044,\"Fare\"] = df[df[\"Pclass\"]==3][\"Fare\"].mean()\ndf[\"Fare\"] = df[\"Fare\"].rank(method='max')\ndf.loc[df[\"Embarked\"].isna(),\"Embarked\"] = \"S\"\nset(df[\"Deck\"].values)","d22bcffa":"onehot_df = pd.DataFrame(index=df.index)\nfor c in [\"Pclass\",\"Sex\",\"Embarked\",\"Deck\",\"Ticket_p\",\"Title\"]:\n    encoded = OneHotEncoder().fit_transform(df[c].to_numpy().reshape(-1,1)).toarray()\n    columns = [f\"{c}_{i}\" for i in range(encoded.shape[1])]\n    _df =pd.DataFrame(data=encoded, columns=columns, index=df.index)\n    onehot_df = pd.concat([_df,onehot_df], axis=1)\n    \nonehot_df = pd.concat([onehot_df,df[[\"Survived\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Cabin\",\"Kid\",\"Alone\",\"Side\"]]], axis=1)\n\nfor c in [\"Age\",\"Fare\",\"Cabin\",\"SibSp\",\"Parch\"]:\n    onehot_df[c] = MinMaxScaler().fit_transform(onehot_df[c].to_numpy().reshape(-1,1))\nonehot_df.head(10).style.background_gradient(cmap=\"Blues\")","9e9b362e":"df_train = onehot_df.copy(deep=True)\nmask = df_train[\"Survived\"].isna()\ntrain, x_pred = df_train[~mask], df_train[mask]\nx_pred = x_pred.drop(\"Survived\", axis=1)\ntrain.loc[:,\"Survived\"] = train.loc[:,\"Survived\"].astype(bool)\nx_train, y_train = train.drop(\"Survived\", axis=1), train[\"Survived\"].astype(int)\nx_pred","daef8cfb":"#train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n#train_data.head()","15cfc241":"from sklearn.ensemble import RandomForestClassifier\n# make predictions using adaboost for classification\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\n\n#model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1) #0.78468\n#model = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=1) #0.78708\n#model = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=1) #0.78708 \n#model = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=1) #0.78947 \n#model = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=1) #0.77033\n#model = RandomForestClassifier(n_estimators=200, max_depth=7, random_state=1) #0.78708\n#model = RandomForestClassifier(n_estimators=1000, max_depth=7, random_state=1) #0.77751\n#model = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=1) #0.78947\nmodel = AdaBoostClassifier()\nmodel.fit(x_train,y_train)\npredictions = model.predict(x_pred)\nsubmition = pd.DataFrame({\"PassengerId\":x_pred.index,\"Survived\":predictions}).astype(int)\nsubmition.to_csv('submission.csv', index=False)\nsubmition","8ca02afa":"#test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n#test_data.head()","e4b6e117":"#women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n#rate_women = sum(women)\/len(women)\n\n#print(\"% of women who survived:\", rate_women)","2656c0ea":"#men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n#rate_men = sum(men)\/len(men)\n\n#print(\"% of men who survived:\", rate_men)","e64fa5e9":"\u0412\u0437\u044f\u043b \u0412\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435, \u043d\u043e \u0440\u0435\u0448\u0438\u043b, \u0447\u0442\u043e \u0444\u0430\u043c\u0438\u043b\u0438\u0438 \u0438 \u0438\u043c\u0435\u043d\u0430 \u043b\u044e\u0434\u0435\u0439 \u043d\u0435 \u0434\u043e\u043b\u0436\u043d\u044b \u0432\u043b\u0438\u044f\u0442\u044c \u043d\u0430 \u0442\u043e, \u0432\u044b\u0436\u0438\u043b\u0438 \u043e\u043d\u0438 \u0438\u043b\u0438 \u043d\u0435\u0442, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043d\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u043b \u0438\u0445"}}