{"cell_type":{"9849c287":"code","da3c00db":"code","db744225":"code","f3f77d87":"code","13d5f0b7":"code","599c7d46":"code","ee999ff8":"code","2af5ae83":"code","267c39e7":"code","29c310c5":"code","9fd83412":"code","2c9ceeb1":"code","e30ce448":"code","27a17ce1":"code","e0b3a4e2":"code","e32dbe45":"code","17bf3ee7":"code","da9d2879":"code","51abe15f":"code","e95907da":"code","07685d38":"code","39990d8b":"code","be0f2752":"code","f40f7781":"code","bb0ec550":"code","d64ebc9b":"code","a5a20082":"code","b7865349":"code","5bcc33c8":"code","a9022f61":"code","830fbc9f":"code","0ee1596c":"code","1307581e":"markdown","9e44ce11":"markdown","61bbc403":"markdown","534cb264":"markdown","9145caf1":"markdown","73a26db3":"markdown","8d225e0c":"markdown","dcbd3a33":"markdown","3a036bd5":"markdown","b67b4953":"markdown","4427d0b4":"markdown","6612ecd8":"markdown","fd1dc34d":"markdown","f6db0c94":"markdown","c56de2fc":"markdown","154cc1d7":"markdown","eed6b19a":"markdown","5067e6fd":"markdown","69184256":"markdown","8f456e0c":"markdown"},"source":{"9849c287":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da3c00db":"import matplotlib.pyplot as plt\nimport seaborn as sns","db744225":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","f3f77d87":"train_data.info()","13d5f0b7":"train_data.isnull().sum()","599c7d46":"(train_data.isnull().sum()\/len(train_data)) * 100","ee999ff8":"plt.figure(figsize=(12,6))\nsns.set_style('whitegrid')\nsns.boxplot(data = train_data, x = 'Pclass', y = 'Age', palette = 'coolwarm', hue = 'Sex')\nplt.show()","2af5ae83":"train_data.groupby(['Pclass', 'Sex'])['Age'].median()","267c39e7":"train_data['Age'] = train_data.groupby(['Pclass','Sex'])['Age'].transform(lambda x: x.fillna(x.median()))","29c310c5":"train_data.dropna(axis = 0, subset = ['Embarked'], inplace = True)","9fd83412":"train_data['Embarked'].unique()\ntrain_data['Sex'].unique()","2c9ceeb1":"train_data['Embarked'] = train_data['Embarked'].replace({'S':0, 'C':1, 'Q':2})\ntrain_data['Sex'] = train_data['Sex'].replace({'male':0, 'female':1})","e30ce448":"train_data.head()","27a17ce1":"plt.figure(figsize=(12,6))\ncorrelation = train_data.corr()\nsns.heatmap(correlation, cmap = 'Blues', annot = True)\nplt.show()","e0b3a4e2":"train_data.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True)","e32dbe45":"train_data.head()","17bf3ee7":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n#keep PassengerId as we need entries for submission\ntest_data_ids = test_data['PassengerId']","da9d2879":"test_data.info()","51abe15f":"test_data.isnull().sum()","e95907da":"plt.figure(figsize=(12,6))\nsns.boxplot(data=test_data, x = 'Pclass', y = 'Age', hue= 'Sex', palette = 'coolwarm')\nplt.show()","07685d38":"test_data.groupby(['Pclass', 'Sex'])['Age'].median()","39990d8b":"test_data['Age'] = test_data.groupby(['Pclass','Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\ntest_data['Fare'] = test_data.groupby(['Pclass', 'Sex'])['Fare'].transform(lambda x: x.fillna(x.median()))\ntest_data['Sex'] = test_data['Sex'].replace({'male':0, 'female':1})\ntest_data['Embarked'] = test_data['Embarked'].replace({'S':0, 'C':1, 'Q':2})","be0f2752":"test_data.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis = 1, inplace=True)","f40f7781":"test_data.head()","bb0ec550":"from sklearn.model_selection import train_test_split","d64ebc9b":"X = train_data.drop('Survived', axis=1)\ny = train_data['Survived']","a5a20082":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","b7865349":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(X_train, y_train)","5bcc33c8":"from sklearn.metrics import classification_report, confusion_matrix\ny_preds = classifier.predict(X_test)\nprint(confusion_matrix(y_test, y_preds))\nprint('\\n')\nprint(classification_report(y_test, y_preds))","a9022f61":"survival_pred = classifier.predict(test_data)","830fbc9f":"Model_preds = pd.DataFrame({'PassengerId': test_data_ids.values, 'Survived': survival_pred})","0ee1596c":"Model_preds.to_csv(\".\/log_reg_submission.csv\", index=False)","1307581e":"Let's see how many of the values within the dataset are null as well as what percentage of the total entries they account for. ","9e44ce11":"# Exploratory Data Analysis and Preprocessing (Test Data)","61bbc403":"We now have a clean version of the train data, ready to implement in our machine learning model. ","534cb264":"Let's take a look at how our train_data now looks. ","9145caf1":"We still have a number of categorical data points within our dataset. As the main objective is to predict whether a passenger survived or not, let's see how correlated the remaining columns are with the Survived column.","73a26db3":"**Here we have split train_data into a train and test set. 20% of the dataset is separated from train_data and is what model performance will be tested on. The remaining 80% is used to train the model itself.**","8d225e0c":"Have 3 columns containing null values. These are Age, Embarked and Cabin. Lets start with the Age column. \nWe can create a boxplot to visualise how the age of the different passengers is distributed. To better account for who was travelling, we can group the relevant data based on what class the passenger was travelling in (Pclass) and whether they were male or female (Sex). \nOnce grouped, we can calculate the median of each boxplot and use it to assign a value to the entries marked as null. ","dcbd3a33":"Repeat the same process with the test data to later be able to make predictions on this dataset using the conclusions drawn from the train set. ","3a036bd5":"Importing the train.csv dataset","b67b4953":"For the purposes of training our machine learning model, we want to work with numerical values. We can readily do this by assigning dummy variablies to the non-numeric values currently in the data. \nFirstly, let's check what entries are currently being used. \nFor 'Sex', we can replace any entry marked as 'male' with 0 and 'female' with 1.\nSimilarly, we can replace any entry marked as 'S' with 0, 'C' with 1, 'Q', with 2 when cleaning the 'Embarked' column.","4427d0b4":"**Make predictions on the test set of the data and evaluate model performance.** ","6612ecd8":"Drop Survived column from train_data, this is what we want to calculate (y) based on the features found in the dataset (X).","fd1dc34d":"# Exploratory Data Analysis and Preprocessing (Train Data)","f6db0c94":"Embarked had only 2 data entries marked as null. We can drop these values as they account for 0.22% of total entries provided, as calculated previously. ","c56de2fc":"**Now need to make predictions on test_data dataset**","154cc1d7":"**Create a new dataframe and save as .csv file for submission**","eed6b19a":"We will now build our machine learning algorithm. For this example, we will be using a Logistic Regression to classify whether or not a passenger survived the Titanic disaster.","5067e6fd":"Once imported, we can take a look at the type of data included in this dataset","69184256":"A significant amount of data is missing from the Cabin column. Rather than assigning dummy variables, we can completely remove it from the dataset along with the categorical entries.","8f456e0c":"# Applying a Logistic Regression"}}