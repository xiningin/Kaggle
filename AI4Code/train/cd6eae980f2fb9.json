{"cell_type":{"a8fa08e8":"code","b332fbbe":"code","a7e7a1a9":"code","63306f01":"code","a80868d6":"code","a85608dc":"code","6a9036ae":"code","4b014f64":"code","af8fd671":"code","6867e73b":"code","f6a3dff9":"code","13a95645":"code","f9d6fe4a":"code","5c6f9175":"code","36a3aadd":"code","140c0a58":"code","dc2f1fa4":"code","878c58a7":"code","e4b6dfe3":"code","9ba97e10":"code","a764bf7c":"code","65d67a6f":"code","8d6f4136":"code","21793635":"markdown"},"source":{"a8fa08e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b332fbbe":"list1 =[\"European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\",\"The sick childs from Mumbai in the corner need Shyam\",\"I eat a pizza at Pizzahut and Dominos with olives in Chennai\",\"The brown fox is quick and he is jumping over the lazy dog named Rambo\",\"A black television and a white stove were bought for the new apartment of Ram and Shyam\",\"John hit the ball very hard\",\"The little dog Cookie barked at the cat named Kitty\",\"The green dog Rambo ate a large cookie on the table\",\"The cells of Freddie Mercury were previously infected with HIV-AIDS\",\"He is not allowed to appear in the exam of N.Y.C\",\"Economic news had little effect on B.S.E and financial market\"]\nprint(len(list1))","a7e7a1a9":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tag import pos_tag\nfrom nltk import Tree, pos_tag, ne_chunk\nfrom nltk.sem.relextract import NE_CLASSES\n","63306f01":"def preprocess(sent):\n    sent = nltk.word_tokenize(sent)\n    sent = nltk.pos_tag(sent)\n    return sent","a80868d6":"def chunking(sent):\n    pattern = 'NP: {<DT>?<JJ>*<NN>}'\n    cp = nltk.RegexpParser(pattern)\n    cs = cp.parse(sent)\n    return(sent)\n    ","a85608dc":"def parsing_nltk(sent):\n    words = nltk.word_tokenize(sent)\n    tagged = nltk.pos_tag(words)\n    chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n    chunkParser = nltk.RegexpParser(chunkGram)\n    chunked = chunkParser.parse(tagged)\n    print(chunked)","6a9036ae":"def ner(sent):\n    ne_tree = ne_chunk(pos_tag(word_tokenize(sent)))\n    print(ne_tree)","4b014f64":"def namedentity(sent):\n    tagged_sent = ne_chunk(pos_tag(sent.split()))\n    print(tagged_sent)\n    ace_tags = NE_CLASSES['ace']\n    for node in tagged_sent:\n         if type(node) == Tree and node.label() in ace_tags:\n                words, tags = zip(*node.leaves())\n                print (node.label() + '\\t' +  ' '.join(words))\n    #retur(tagged_sent)\n    ","af8fd671":"j=1\nfor i in list1:\n    print(str(j)+\". \"+i)\n    print(\"POS TAG OF USING NLTK \")\n    print(preprocess(i))\n    print(\"\\n\")\n    print(\"SHALLOW PARSING OF SENTENCE USING NLTK\")\n    print(parsing_nltk(i))\n    print(\"\\n\")\n    print(\"NAMED ENTITY RECOGNITION OF SENTENCE USING NLTK\")\n    ner(i)\n    print(\"-----------------------------------------------\")\n    j+=1","6867e73b":"import spacy\nfrom spacy import displacy\nnlp = spacy.load('en_core_web_sm')","f6a3dff9":"\ndef spacyparser(i):\n    print('Original Sentence: %s' % (i))\n    doc = nlp(i)\n    print('POS TAGGING USING SPACY')\n    for token in doc:\n        print(token.text, token.tag_)\n    print(\"\\n\")\n    print('DEPENDECY PARSING USING SPACY')\n    for chunk in doc.noun_chunks:\n        print(chunk.text, chunk.root.text, chunk.root.dep_,chunk.root.head.text)\n    displacy.render(doc, style='dep', jupyter=True, options={'distance': 50})\n    print(\"\\n\")\n    print('\\nNAMED ENTITY RECOGNITION USING SPACY')\n    for ent in doc.ents:\n        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n    #displacy.render(doc, style='ent', jupyter=True)","13a95645":"spacyparser(list1[1])\n    ","f9d6fe4a":"spacyparser(list1[0])\n","5c6f9175":"spacyparser(list1[2])","36a3aadd":"spacyparser(list1[2])","140c0a58":"spacyparser(list1[3])","dc2f1fa4":"spacyparser(list1[4])","878c58a7":"spacyparser(list1[5])","e4b6dfe3":"spacyparser(list1[6])","9ba97e10":"spacyparser(list1[7])","a764bf7c":"spacyparser(list1[8])","65d67a6f":"spacyparser(list1[9])","8d6f4136":"spacyparser(list1[10])","21793635":"**POS TAGGING USING NLTK**"}}