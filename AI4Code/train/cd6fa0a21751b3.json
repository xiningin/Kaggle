{"cell_type":{"ff9077c7":"code","d2bab666":"code","e6ebe1b4":"code","35a3c47f":"code","0fb1f633":"code","b94048e7":"code","4dca6db7":"code","4a845f31":"code","8eac5c69":"code","6c36ed8c":"code","aa14880f":"code","79effa8f":"code","9fc863ee":"code","199736a1":"code","97ef5d1b":"code","61c215e3":"code","da22e60d":"code","24416cff":"code","fc2700ad":"code","87eb6398":"code","a0d69f81":"code","d4e3197a":"code","23b0f4bc":"code","8cc1362c":"code","4adeebe8":"code","7af9c716":"code","00cdcdd0":"code","c9a2f77b":"code","9b34ee72":"code","ea8642f6":"code","33b2562a":"code","823acd28":"code","a3efd7a7":"markdown","89d4c275":"markdown","d26be860":"markdown","43565f31":"markdown","63b85136":"markdown","868172cb":"markdown","009d1bc6":"markdown","728cfd10":"markdown","b1e57581":"markdown","6479b0f4":"markdown","8e82c357":"markdown","c4055ebb":"markdown","bbb2ac81":"markdown","414d527b":"markdown","0c617a81":"markdown"},"source":{"ff9077c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d2bab666":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nimport time\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as s\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n","e6ebe1b4":"df = pd.read_csv('\/kaggle\/input\/unsw-nb15\/UNSW_NB15_training-set.csv')\ndf2 = pd.read_csv('\/kaggle\/input\/unsw-nb15\/UNSW_NB15_testing-set.csv')\n","35a3c47f":"df.isnull()","0fb1f633":"df = pd.read_csv('\/kaggle\/input\/unsw-nb15\/UNSW_NB15_training-set.csv')\ndf.drop(columns='attack_cat', inplace = True )\nAttack= df[df['label'] == 1]\nNonAttack = df[df['label'] == 0]\nclasses = pd.value_counts(df['label'], sort = True)\noutput=df['label']\ndf=df.iloc[:,:-1]\n\nlabels = ['NonAttacks','Attack']\nclasses.plot(kind = 'pie', rot=0)\nplt.title(\"Transaction class distribution\")\nplt.xticks(range(2), labels)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\")","b94048e7":"output.value_counts()","4dca6db7":"df.info()","4a845f31":"#One Hot Encoding\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport numpy as np\nfrom numpy import array\n\nle_service = LabelEncoder()\nle_proto = LabelEncoder()\nle_state= LabelEncoder()\ndf['service_encoded'] = le_service.fit_transform(df.service)\ndf['proto_encoded'] = le_proto.fit_transform(df.proto)\ndf['state_encoded'] = le_state.fit_transform(df.state)\n\n\nservice_ = OneHotEncoder()\nproto_ = OneHotEncoder()\nstate_ = OneHotEncoder()\nX = service_.fit_transform(df.service_encoded.values.reshape(-1,1)).toarray()\nXm = proto_.fit_transform(df.proto_encoded.values.reshape(-1,1)).toarray()\nXmm = state_.fit_transform(df.state_encoded.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"service_\"+str(int(i)) for i in range(X.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\ndfOneHot = pd.DataFrame(Xm, columns = [\"proto_\"+str(int(i)) for i in range(Xm.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\ndfOneHot = pd.DataFrame(Xmm, columns = [\"state_\"+str(int(i)) for i in range(Xmm.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\n\ndf.drop(columns=['proto','service','state'], inplace = True )\ndf.shape\ndf2.drop(columns='attack_cat', inplace = True )","8eac5c69":"df.describe()","6c36ed8c":"# Feature Selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nbestfeatuers=SelectKBest(score_func=chi2,k=100)\ninp=df.iloc[:,0:198]\nfit=bestfeatuers.fit(inp,output)\ndfscores=pd.DataFrame(fit.scores_)\ndfcol=pd.DataFrame(inp.columns)\nfeaturescore=pd.concat([dfcol,dfscores],axis=1)\nfeaturescore.columns=['feature','score']\nk=featurescore['feature']\nt=featurescore.nlargest(100,'score')\nli=list(t['feature'])\nprint(\"Top 100 features:\")\nprint(\"\\n\")\nfor x in li:\n    print(x,end=\" , \")","aa14880f":"x_train=df[li]\ny_train=output\nx_test=df2[li]\ny_test = df2['label']\nval=[]","79effa8f":"#Decision tree\nstart = time.time()\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\nclf.fit(x_train, y_train)\npreds = clf.predict(x_test)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nprint (\"Train Accuracy :: \", accuracy_score(y_train, clf.predict(x_train)))\nprint (\"Test Accuracy  :: \", accuracy_score(y_test, preds))\nval=[]\ndec_tree_f=accuracy_score(y_test, preds)\nval.append(dec_tree_f)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))\nend = time.time()\nprint(end - start)","9fc863ee":"#RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\nstart = time.time()\n\nclf = RandomForestClassifier(n_estimators = 2,random_state=30)\nclf.fit(x_train, y_train)\npreds = clf.predict(x_test)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nprint (\"Train Accuracy :: \", accuracy_score(y_train, clf.predict(x_train)))\nprint (\"Test Accuracy  :: \", accuracy_score(y_test, preds))\nrandom_for_f=accuracy_score(y_test, preds)\nval.append(random_for_f)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))\nend = time.time()\nprint(end - start)\n","199736a1":"#NaiveBayes\nfrom sklearn.naive_bayes import GaussianNB\n\n# create Gaussian Naive Bayes model object and train it with the data\nn = GaussianNB()\n\nn.fit(x_train, y_train)\npreds = n.predict(x_test)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nprint (\"Train Accuracy :: \", accuracy_score(y_train, n.predict(x_train)))\nprint (\"Test Accuracy  :: \", accuracy_score(y_test, preds))\ngnb=accuracy_score(y_test, preds)\nval.append(gnb)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))\nend = time.time()\nprint(end - start)\n","97ef5d1b":"#Model Accuracy Graph\nalg=[\"Decision Tree\",\"Random Forest\",\"Gaussian NB \"] \nfor i in range(len(alg)):\n    print(\"The accuracy acheived using \",alg[i],\" is: \",(val[i])*100,\"%\")","61c215e3":"s.set(rc={'figure.figsize':(8,8)})\nplt.xlabel(\"algorithm\")\nplt.ylabel(\"accuracy\")\ns.barplot(alg,val)","da22e60d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler, Normalizer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if 'csv' in filename:\n            print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","24416cff":"def input_train_test():\n    root = '..\/input\/unsw-nb15\/'\n    train = pd.read_csv(root+'UNSW_NB15_training-set.csv')\n    test = pd.read_csv(root+'UNSW_NB15_testing-set.csv')\n    \n    if train.shape[0] == 82332:\n        print(\"Train and test sets are reversed here. Fixing them.\")\n        train, test = test, train\n    drop_columns = ['attack_cat', 'id']\n    for df in [train, test]:\n        for col in drop_columns:\n            if col in df.columns:\n                print('Dropping '+col)\n                df.drop([col], axis=1, inplace=True)\n    return train, test\n\ndef get_cat_columns(train):\n    categorical = []\n    for col in train.columns:\n        if train[col].dtype == 'object':\n            categorical.append(col)\n    return categorical\n    \ndef label_encode(train, test):\n    for col in get_cat_columns(train):\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))\n    return train, test\n\ndef feature_process(df):\n    df.loc[~df['state'].isin(['FIN', 'INT', 'CON', 'REQ', 'RST']), 'state'] = 'others'\n    df.loc[~df['service'].isin(['-', 'dns', 'http', 'smtp', 'ftp-data', 'ftp', 'ssh', 'pop3']), 'service'] = 'others'\n    df.loc[df['proto'].isin(['igmp', 'icmp', 'rtp']), 'proto'] = 'igmp_icmp_rtp'\n    df.loc[~df['proto'].isin(['tcp', 'udp', 'arp', 'ospf', 'igmp_icmp_rtp']), 'proto'] = 'others'\n    return df\n\ndef get_train_test(train, test, feature_engineer=True, label_encoding=False, scaler=None):\n    x_train, y_train = train.drop(['label'], axis=1), train['label']\n    x_test, y_test = test.drop(['label'], axis=1), test['label']\n    \n    x_train, x_test = feature_process(x_train), feature_process(x_test)\n    if scaler is not None:\n        categorical_columns = get_cat_columns(x_train)\n        non_categorical_columns = [x for x in x_train.columns if x not in categorical_columns]\n        x_train[non_categorical_columns] = scaler.fit_transform(x_train[non_categorical_columns])\n        x_test[non_categorical_columns] = scaler.transform(x_test[non_categorical_columns])\n    \n    if label_encoding:\n        x_train, x_test = label_encode(x_train, x_test)\n        features = x_train.columns\n    else:\n        x_train = pd.get_dummies(x_train)\n        x_test = pd.get_dummies(x_test)\n        print(\"Column mismatch {0}, {1}\".format(set(x_train.columns)- set(x_test.columns),  set(x_test.columns)- set(x_train.columns)))\n        features = list(set(x_train.columns) & set(x_test.columns))\n    print(f\"Number of features {len(features)}\")\n    x_train = x_train[features]\n    x_test = x_test[features]\n\n    return x_train, y_train, x_test, y_test\n\ndef run_lgb(x, y, tr_idx, val_idx, param, num_round=100):\n    lgb_train = lgb.Dataset(x.iloc[tr_idx], y.iloc[tr_idx])\n    x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n    validation = lgb.Dataset(x_val, y_val)\n    clf = lgb.train(param, lgb_train, num_round, valid_sets=[validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n    return clf\n\ndef false_alarm_rate(y_true, y_pred):\n    CM = metrics.confusion_matrix(y_true, y_pred)\n    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n    return (FP+FN)\/(TP+TN+FP+FN)\n\ndef results(y_test, y_prob):\n    threshold = 0.5\n    y_pred = np.where(y_prob >= threshold, 1, 0)\n    \n    acc = metrics.accuracy_score(y_test, y_pred)\n    pre = metrics.precision_score(y_test, y_pred)\n    rec = metrics.recall_score(y_test, y_pred) # it is also called detection rate or true positive rate\n    f1 = metrics.f1_score(y_test, y_pred)\n    print(f\"Acc {acc}, Precision {pre}, Recall {rec}, F1-score {f1}\")\n    \n    CM = metrics.confusion_matrix(y_test, y_pred)\n    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n    # false positive rate\n    FPR = FP\/(FP+TN)\n    # false alarm rate \n    FAR = (FP+FN)\/(TP+TN+FP+FN)\n    AUC = metrics.roc_auc_score(y_test, y_prob)\n    \n    print(\"FPR {0}, FAR {1}, AUC {2}\".format(FPR, FAR, AUC))\n    # print(metrics.classification_report(y_test, y_pred))\n    \ndef test_run(x_train, y_train, x_test, y_test, param, num_round=2000):\n    start = time.clock()\n    \n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_validation = lgb.Dataset(x_test, y_test)\n    clf = lgb.train(param, lgb_train, num_round, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n    # clf = lgb.train(param, lgb_train, 2000, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200)\n    y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\n    \n    print()\n    results(y_test, y_prob)\n    print(\"Time spent {0}\".format(time.clock() - start))\n    return y_prob\n    \ndef cross_validation(X, Y, param, kf, num_round=2000):\n    start = time.clock()\n    y_probs = []\n    y_vals = []\n\n    # for tr_idx, val_idx in tqdm(kf.split(X, Y), total=folds):\n    for tr_idx, val_idx in kf.split(X, Y):\n        clf = run_lgb(X, Y, tr_idx, val_idx, param, num_round)\n        x_val, y_val = X.iloc[val_idx], Y.iloc[val_idx]\n        y_prob = clf.predict(x_val, num_iteration=clf.best_iteration)\n        \n        y_probs.extend(y_prob)\n        y_vals.extend(y_val)\n\n    print()\n    results(y_vals, np.asarray(y_probs))\n    print(\"Time spent {0}\".format(time.clock() - start))","fc2700ad":"train, test = input_train_test()","87eb6398":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook as tqdm\n\ndef lgb_accuracy(preds, data):\n    y_true = data.get_label()\n    y_pred = np.round(preds)\n    return 'acc', metrics.accuracy_score(y_true, y_pred), True\n\ndef lgb_f1_score(preds, data):\n    y_true = data.get_label()\n    y_pred = np.round(preds) # scikits f1 doesn't like probabilities\n    return 'f1', metrics.f1_score(y_true, y_pred), True","a0d69f81":"folds = 10\nseed = 1\nnum_round = 2000\nkf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n\nstart = time.clock() \ndrop_columns = ['is_sm_ips_ports', 'dwin', 'is_ftp_login', 'trans_depth', 'dttl', 'ct_ftp_cmd']\nfor df in [train, test]:\n    df.drop(drop_columns, axis=1, inplace=True)\nx_train, y_train, x_test, y_test = get_train_test(train, test, feature_engineer=True, label_encoding=False, scaler=StandardScaler())\nprint(\"Time spent in total preprocessing {0} s\".format(time.clock() - start))","d4e3197a":"param = {\n    'objective': 'binary', \n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\nstart = time.clock()\n# test_run( x_train, y_train, x_train, y_train, param)\nclf = lgb.train(param, lgb.Dataset(x_train, y_train), 2000, valid_sets=[lgb.Dataset(x_train, y_train)], early_stopping_rounds=50, verbose_eval=200)\ny_prob = clf.predict(x_train, num_iteration=clf.best_iteration)\nprint()\nresults(y_train, y_prob)\nprint(\"Time spent {0}\".format(time.clock() - start))","23b0f4bc":"y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\nprint()\nresults(y_test, y_prob)","8cc1362c":"param = {\n    'objective': 'binary', \n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ncross_validation(x_train, y_train, param, kf)","4adeebe8":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\ncross_validation(x_train, y_train, param, kf)","7af9c716":"param = {\n    'objective': 'binary', \n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ny_prob = test_run(x_test, y_test, x_test, y_test, param)","00cdcdd0":"param = {\n    'objective': 'binary',\n    'learning_rate': 0.05, \n    'boost_from_average':True,\n    'is_unbalance':True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ny_prob = test_run(x_train, y_train, x_test, y_test, param)","c9a2f77b":"y_pred = np.where(y_prob >= 0.5, 1, 0)\nprint(metrics.confusion_matrix(y_test, y_pred))\n\ntarget_names = ['Normal', 'Anomaly']\ncm = metrics.confusion_matrix(y_test, y_pred)\n# Normalize\ncmn = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\nplt.rc('font', size=20) \nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names)\n\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n \nplt.show(block=False)","9b34ee72":"param = {\n    'objective': 'binary',\n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    # 'is_unbalance':True,\n    # \"feature_fraction\":0.5,\n    \"metric\": 'binary_logloss' # 'auc'\n}\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\ncross_validation(x_test, y_test, param, kf, num_round=2000)","ea8642f6":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\ncross_validation(x_test, y_test, param, kf)","33b2562a":"total = pd.concat([train, test], axis=0)\nX, Y = total.drop(['label'], axis=1), total['label']\ncategorical_columns = get_cat_columns(X)\nnon_categorical_columns = [col for col in X.columns if col not in categorical_columns]\nX = feature_process(X)\nX[non_categorical_columns] = StandardScaler().fit_transform(X[non_categorical_columns])\nX = pd.get_dummies(X)","823acd28":"param = {\n    'objective': 'binary',\n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    # 'is_unbalance':True,\n    # \"bagging_fraction\":0.8,\n    \"feature_fraction\":0.5,\n    # \"bagging_freq\":1,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ncross_validation(X, Y, param, kf, num_round=2000)","a3efd7a7":"|Param|Accuracy|F1-score|\n|:---:|:---:|:---:|:---:|\n|learning_rate 0.1 | 87.74 | 89.87\n|learning_rate 0.05 | 87.60 | 89.77\n|learning_rate 0.1, is_unbalance True | 91.87 | 92.9\n|learning_rate 0.05, is_unbalance True | 91.95 | 92.96","89d4c275":"## Ten-fold cross validation","d26be860":"| Param | Accuracy | F1-score\n|:---:|:---:|:---:|\n|learning rate 0.05 | 95.11 | 96.15\n|learning rate 0.01 | 93.69 | 95.07\n|learning rate 0.1 | 95.09 | 96.07\n|learning rate 0.1, is_unbalance True | 95.16 | 96.19\n|learning rate 0.1, bagging_fraction 0.8 | 95.14 | 96.17\n|learning rate 0.1, feature_fraction 0.5 | 95.20 | 96.22\n|learning rate 0.1, feature_fraction 0.5, bagging_fraction 0.8 | 95.05 | 96.11","43565f31":"After dropping irrelevant columns, feature engineering and applying oneHotEncoding. We found among different scaling StandardScaler is performing the best.\n\n|Preprocess| Param | Accuracy |F1-score |\n|:---:|:---:|:---:|:---:|:---:|:---:|\n|RobustScaler|learning rate 0.05|96.11| 97.16|\n||learning rate 0.1|95.19| 97.22|\n||learning rate 0.3|95.73| 96.88|\n|StandardScaler |learning rate 0.05|96.08| 97.14 |\n||learning rate 0.1| 96.20 | 97.23|\n||learning rate 0.3| 95.71 | 96.87|\n|MinMaxScaler |learning rate 0.05|96.08| 97.14\n| |learning rate 0.1|96.20|97.22 ","63b85136":"## Five-fold cross validation","868172cb":"# Utils","009d1bc6":"|Param|Accuracy| F1-score|\n|:---:|:---:|:---:|\n|learning_rate 0.05| 98.07 | 98.24\n|learning_rate 0.1| 98.18 | 98.34\n|learning_rate 0.3| 98.08 | 98.25\n|learning_rate 0.1, feature_fraction 0.5 | 98.14 | 98.30\n|learning_rate 0.05, feature_fraction 0.5| 98.04 | 98.21\n","728cfd10":"# Combined data\nHere we combined both train and test set. Then evaluated their ten-fold cross validation performance.","b1e57581":"# Train data","6479b0f4":"# Introduction\n* [The UNSW-NB15 dataset description](https:\/\/www.unsw.adfa.edu.au\/unsw-canberra-cyber\/cybersecurity\/ADFA-NB15-Datasets\/)\n* [Feature visualization and preprocessing](https:\/\/www.kaggle.com\/khairulislam\/unsw-nb15-eda)\n* [Feature importance using RandomForest classifier](https:\/\/www.kaggle.com\/khairulislam\/unsw-nb15-feature-importance)\n* [Performance with other classifiers](https:\/\/www.kaggle.com\/khairulislam\/unsw-nb15-anomaly-detection)","8e82c357":"## Validate on test data\nHere the model trained on test data is being validated using test data.","c4055ebb":"# Test data","bbb2ac81":"## Five-fold cross validation","414d527b":"## Ten-fold cross validation","0c617a81":"# **Project of other Candidate **"}}