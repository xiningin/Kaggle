{"cell_type":{"84436b76":"code","4fe36052":"code","8b4f9d28":"code","7e55c701":"code","1d8444bd":"code","1c691e8e":"code","119602be":"code","2f12ac92":"code","fdcab692":"code","d59d4c55":"code","ba5ae3a8":"code","b72298b0":"code","126b87f4":"code","e68c23f9":"code","d8b34c60":"code","cb8cd02e":"code","3ddc72cc":"code","5d4262b6":"code","405664bd":"code","9bd04ee0":"code","8e61257b":"code","057ac146":"code","e7d785ba":"code","04481548":"code","62caa7b0":"code","c600da2e":"code","46ee7a5a":"code","4eeb730d":"code","81ec36e6":"code","abba6689":"code","c340dbc2":"code","f7ece2c5":"markdown","5d0ee4f1":"markdown","e8aae0ec":"markdown","ca294623":"markdown","61c7bd54":"markdown","fc163368":"markdown","c6a473a9":"markdown","80d04387":"markdown","76d94f11":"markdown","3e6c68e4":"markdown","341577fd":"markdown","4abc080f":"markdown","fb0a44f2":"markdown","9e655cb5":"markdown","63dfcaf3":"markdown","b9c4b319":"markdown","020175b7":"markdown","8d522b50":"markdown"},"source":{"84436b76":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc","4fe36052":"#engine='c' is used to faster read our .csv files\naisles = pd.read_csv('..\/input\/aisles.csv' , engine='c')\ndepartments = pd.read_csv('..\/input\/departments.csv', engine='c')\nproducts = pd.read_csv('..\/input\/products.csv', engine='c')\n\n#merge info of aisles & departments to products with a single request\ngoods = pd.merge(left=pd.merge(left=products, right=departments, how='left'), right=aisles, how='left')\n\n#fix names to a clear format [replace spaces with underscores]\ngoods.product_name = goods.product_name.str.replace(' ', '_').str.lower()\ngoods.department = goods.department.str.replace(' ', '_').str.lower()\ngoods.aisle= goods.aisle.str.replace(' ', '_').str.lower()\n\ngoods.head()","8b4f9d28":"#load orders\norders = pd.read_csv('..\/input\/orders.csv', engine='c' )\norders.head()","7e55c701":"#load prior\nop_prior = pd.read_csv('..\/input\/order_products__prior.csv', engine='c')\n#load train                       \nop_train = pd.read_csv('..\/input\/order_products__train.csv', engine='c')\n                       \n#concatenate rows of train below prior:           \nlog= pd.concat([op_prior,op_train], ignore_index=1)                \nlog.tail()","1d8444bd":"# !--! runtime: 1m:14s\nlog.sort_values(['order_id', 'add_to_cart_order'], inplace=True)\nlog.reset_index(drop=1, inplace=True)\nlog = pd.merge(log, goods, on='product_id', how='left')\nlog = pd.merge(log, orders, on='order_id', how='left')\nlog['order_number_rev'] = log.groupby('user_id').order_number.transform(np.max) - log.order_number\ngc.collect()\nlog.head()","1c691e8e":"log[log.eval_set == 'test']['order_id'].count()","119602be":"gro= log.groupby('order_id')\norder_size = gro.size().reset_index()\norder_size.columns = ['order_id', 'total_products_of_order']\norder_size.head()","2f12ac92":"log = pd.merge(log, order_size , on='order_id' , how='left')\nlog.head()","fdcab692":"#we indicate our desired groups (in this case, we create info for each product)\n#we will reuse this grouping also in the next features\ngr = log.groupby('product_id')","d59d4c55":"#pro (for products) will be a hyper-DF to store all new features for products\n#.to_frame converts the aggegated values for each product into a DF\npro = gr.product_id.count().to_frame()\npro.columns = ['total_purchases']\n\npro.head()","ba5ae3a8":"#mean position in the add_to_cart of order\n\n#we calculate the mean value of add to cart order for each product\n#we chain .to_frame() to create a DF with info for each product\npro['item_mean_pos_cart'] = gr.add_to_cart_order.mean()\n\n#now we create other metrics for each product [we use all known aggregation functions]:\n\n#sum of orders\npro['item_sum_pos_cart'] = gr.add_to_cart_order.sum()\n#min value [the best place appeared on a cart order]\npro['item_min_pos_cart'] = gr.add_to_cart_order.min()\n#max [the worst place appeared on a cart order]\npro['item_max_pos_cart'] = gr.add_to_cart_order.max()\n#median\npro['item_median_pos_cart'] = gr.add_to_cart_order.median()\n#standard deviation - how dispersed is the order \npro['item_std_pos_cart'] = gr.add_to_cart_order.std()\n\npro.head(10)\n\n","b72298b0":"pro.reset_index(level=0, inplace=True)\npro.head()","126b87f4":"#dropna removes first order of a user\n#runtime : 3m:16s\n#average\ndslo = log.dropna(axis=0).groupby('product_id').days_since_prior_order.mean().to_frame()\ndslo.columns = ['days_since_last_order_product_mean']\n#max\ndslo['days_since_last_order_product_max'] = log.dropna(axis=0).groupby('product_id').days_since_prior_order.max().to_frame()\n#min\ndslo['days_since_last_order_product_min'] = log.dropna(axis=0).groupby('product_id').days_since_prior_order.min().to_frame()\n#sum\ndslo['days_since_last_order_product_sum'] = log.dropna(axis=0).groupby('product_id').days_since_prior_order.sum().to_frame()\n#median\ndslo['days_since_last_order_product_median'] = log.dropna(axis=0).groupby('product_id').days_since_prior_order.median().to_frame()\n#standard deviation\ndslo['days_since_last_order_product_std'] = log.dropna(axis=0).groupby('product_id').days_since_prior_order.std().to_frame()\ndslo.reset_index(level=0, inplace=True)\ndslo.head()","e68c23f9":"#we merge the features with hyper-DF \"pro\"\npro = pd.merge(pro, dslo, on='product_id', how='left')\npro.head()","d8b34c60":"#runtime : 35s\nitem_users = log.groupby(['product_id', 'user_id']).size().reset_index()\nitem_users.columns = ['product_id', 'user_id', 'total']\nitem_users[item_users.total==1].head()","cb8cd02e":"# how many times an item bought and it was the first in the card list\nitem_one = item_users[item_users.total==1].groupby('product_id').size().reset_index()\nitem_one.columns = ['product_id', 'item_only_one_user_total']\nitem_one.head()","3ddc72cc":"#define a ratio by dividing with the total number of purchases [already calculated in the pro hyper-DF]\nitem_one['ratio_firstorder_to_all'] = item_one['item_only_one_user_total']\/ pro['total_purchases']\nitem_one.head()","5d4262b6":"#merge to the hyper-DF\npro = pd.merge(pro, item_one, how='left')\npro.head()","405664bd":"product_hour1 = log.groupby(['product_id', 'order_hour_of_day']).size().reset_index()\nproduct_hour1.columns = ['product_id', 'order_hour_of_day', 'item_hour_cnt']\nproduct_hour1.head(25)","9bd04ee0":"product_hour1['item_hour_ratio'] = product_hour1.item_hour_cnt \/ product_hour1.groupby('product_id').transform(np.sum).item_hour_cnt\nproduct_hour1.head()","8e61257b":"### Total unique orders of a product for a given hour. (drop orders of the same hour from same users)","057ac146":"product_hour2 = log.drop_duplicates(['user_id', 'product_id', 'order_hour_of_day']).groupby(['product_id', 'order_hour_of_day']).size().reset_index()\nproduct_hour2.columns = ['product_id', 'order_hour_of_day', 'item_hour_cnt_unq']\nproduct_hour2['item_hour_ratio_unq'] = product_hour2.item_hour_cnt_unq \/ product_hour2.groupby('product_id').transform(np.sum).item_hour_cnt_unq\nproduct_hour2.head()","e7d785ba":"product_hour= pd.merge(product_hour1, product_hour2)\nproduct_hour.head()","04481548":"product_day1 = log.groupby(['product_id', 'order_dow']).size().reset_index()\nproduct_day1.columns = ['product_id', 'order_dow', 'item_dow_cnt']\nproduct_day1['item_dow_ratio'] = product_day1.item_dow_cnt \/ product_day1.groupby('product_id').transform(np.sum).item_dow_cnt","62caa7b0":"product_day2 = log.drop_duplicates(['user_id', 'product_id', 'order_dow']).groupby(['product_id', 'order_dow']).size().reset_index()\nproduct_day2.columns = ['product_id', 'order_dow', 'item_dow_cnt_unq']\nproduct_day2['item_dow_ratio_unq'] = product_day2.item_dow_cnt_unq \/ product_day2.groupby('product_id').transform(np.sum).item_dow_cnt_unq    ","c600da2e":"product_day= pd.merge(product_day1, product_day2)\nproduct_day.head()","46ee7a5a":"gro= log.groupby('order_id')\norder_size = gro.size().reset_index()\norder_size.columns = ['order_id', 'total_products_of_order']\norder_size.head()","4eeb730d":"order_product= log.groupby(['user_id', 'product_id']).size().reset_index()\norder_product.columns= ['user_id', 'product_id', 'times']","81ec36e6":"order_product.head()","abba6689":"order_product_choice = order_product.groupby('product_id').times.max().to_frame().reset_index()\norder_product_choice.head()","c340dbc2":"#final = log.copy()\n#final = pd.merge(final, pro, how='left', on='product_id')\n#final = pd.merge(final, product_hour, how='left', on=['product_id', 'order_hour_of_day'])\n#final = pd.merge(final, product_day, how='left', on=['product_id', 'order_dow'])\n\n#final = pd.merge(final, order_size, how='left', on='order_id')\n#final = pd.merge(final, order_product, how='left', on=['user_id', 'product_id'])\n#final = pd.merge(final, order_product_choice, how='left', on='product_id')\n\n#final.head(10)","f7ece2c5":"# Import of Datasets & Merging","5d0ee4f1":"## Features of  Products  by   order_hour_of_day features","e8aae0ec":"> log DataFrame will be the main table to use for creating our new features","ca294623":"# Package Import - Review of tables","61c7bd54":"![CSV_NAMES](https:\/\/kaggle2.blob.core.windows.net\/forum-message-attachments\/183176\/6539\/instacartFiles.png)","fc163368":"# Feature Engineering","c6a473a9":"### Total orders of a product for a given hour","80d04387":"### The general groupby statement","76d94f11":"### Calculate one time only bought ratio of a product","3e6c68e4":">  *we can follow the same procedure (cumulative or single) for 2nd to 5th time ordered*","341577fd":"### Days since last order for an item","4abc080f":"# More to explore:\n## Order Features  - groupby('order_id')","fb0a44f2":"### Cart order of a product","9e655cb5":"### Total times a product bought","63dfcaf3":"## Item Features  - groupby('product_id')","b9c4b319":"### Total orders of a product for a given day","020175b7":"# Merge all features to order","8d522b50":"## Features of  Products  by  order_dow (days) features"}}