{"cell_type":{"47749805":"code","8a17ac26":"code","268fb647":"code","897de2c8":"code","550e785c":"code","6902838e":"code","bf8e0c46":"code","6beddd34":"code","e0c97655":"code","e5542c3f":"code","1d2b72c0":"code","3086b3d8":"code","a7723cd6":"code","31e6f71d":"code","6361e303":"code","80ea0125":"code","826c2ba2":"code","b254bb6d":"code","d0e1137e":"code","4b98672a":"code","dacc627f":"code","c81e69ed":"code","6acbaa26":"code","ba14c1d0":"code","f197c3be":"code","95ecde9e":"code","a2d4927b":"code","b47e108d":"code","7b6958cd":"code","97081abb":"code","11b579a3":"code","3bcefbdb":"code","d4266b07":"code","593af79b":"code","284f7080":"code","03e30c6b":"markdown","1ecd9921":"markdown"},"source":{"47749805":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","8a17ac26":"df = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","268fb647":"df.head()","897de2c8":"df.shape","550e785c":"df.columns","6902838e":"df.info()","bf8e0c46":"df.describe()","6beddd34":"df.isnull().sum()","e0c97655":"df['quality'].unique()","e5542c3f":"df.quality.value_counts().sort_index()","1d2b72c0":"sns.countplot(x='quality', data = df)","3086b3d8":"reviews = []\nfor i in df['quality']:\n    if i >= 1 and i <= 4:\n        reviews.append('1')\n    elif i >= 5 and i <= 6:\n        reviews.append('2')\n    elif i >= 7 and i <= 8:\n        reviews.append('3')\ndf['Reviews'] = reviews","a7723cd6":"df.Reviews.value_counts()\n# poor = 1\n# average = 2\n# good = 3","31e6f71d":"corrmat = df.corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(corrmat, annot=True, cmap='coolwarm')","6361e303":"corrmat['quality'].sort_values(ascending = False)","80ea0125":"sns.boxplot('quality', 'alcohol', data = df)","826c2ba2":"sns.boxplot('Reviews', 'sulphates', data = df)","b254bb6d":"sns.boxplot('Reviews', 'citric acid', data = df)","d0e1137e":"sns.boxplot('Reviews', 'fixed acidity', data = df)","4b98672a":"sns.boxplot('Reviews', 'residual sugar', data = df)","dacc627f":"X = df.iloc[:,0:11]\ny = df['Reviews']","c81e69ed":"X.head(10)","6acbaa26":"y.head(10)","ba14c1d0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","f197c3be":"print(X_train.shape)\nprint(X_test.shape)\n#print(y_train.shape)\n#print(y_test.shape)","95ecde9e":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","a2d4927b":"l=[]","b47e108d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Logistic Regression:', acc * 100)\nl.append(acc)","7b6958cd":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 42)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('SVM:', acc * 100)\nl.append(acc)","97081abb":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Decision Tree:', acc * 100)\nl.append(acc)","11b579a3":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Naive Bayes:', acc * 100)\nl.append(acc)","3bcefbdb":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Random Forest:',acc * 100)\nl.append(acc)","d4266b07":"from sklearn.metrics import classification_report as cr\nprint(cr(y_test, y_pred))","593af79b":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 6, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint('Knn:',acc * 100)\nl.append(acc)","284f7080":"y_axis=['Logistic Regression',\n     'Support Vector Classifier',\n      'Decision Tree Classifier',\n       'Gaussian Naive Bayes',\n      'Random Forest Classifier',\n       'K-Neighbors Classifier']\nx_axis=l\nsns.barplot(x=x_axis,y=y_axis)\nplt.xlabel('Accuracy')","03e30c6b":"Random Forest shows the best accuracy (88 %)","1ecd9921":"If you find this notebook useful, **PLEASE UPVOTE!!**"}}