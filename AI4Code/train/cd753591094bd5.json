{"cell_type":{"5ab9f1f6":"code","c4bde318":"code","75760557":"code","7cf94d49":"code","0e83649c":"code","5083d0a7":"code","a927a2f8":"code","ca53a219":"code","14088008":"code","f6407b4b":"code","3a18398e":"code","86c71b8b":"code","066e6c93":"code","36eed9de":"code","ecf0eb7b":"code","c70056ff":"code","c71189f8":"code","f430efec":"code","f108b061":"code","17cdd86b":"code","08ff4e73":"code","b3839553":"code","5a7cf804":"code","4a3b1a75":"code","c92abbef":"code","8a00ac28":"markdown","16b22c41":"markdown","fa0315fb":"markdown","8cc68d2b":"markdown","3e9ea521":"markdown","eee2ed21":"markdown","274a70c1":"markdown","8356fac3":"markdown","19f4412d":"markdown","1cda974c":"markdown","ced5506c":"markdown","138ba7ef":"markdown"},"source":{"5ab9f1f6":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt","c4bde318":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","75760557":"train.head()","7cf94d49":"print(train.shape)","0e83649c":"train.dtypes","5083d0a7":"sns.countplot(x=\"Survived\",data=train)","a927a2f8":"sns.countplot(x=\"Survived\",hue=\"Pclass\",data=train)","ca53a219":"sns.countplot(x=\"Survived\",hue=\"Sex\",data=train)","14088008":"train[\"Age\"].plot.hist()","f6407b4b":"train[\"Fare\"].plot.hist(bins=20,figsize=(10,5))","3a18398e":"df_train=train.drop(['PassengerId', 'Name','Ticket', 'Cabin'], axis=1)\ndf_test=test.drop(['PassengerId', 'Name','Ticket', 'Cabin'], axis=1)","86c71b8b":"df_train.shape, df_test.shape","066e6c93":"X = df_train.drop('Survived', axis=1)\ny = df_train['Survived']","36eed9de":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)","ecf0eb7b":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])","c70056ff":"numeric_features = df_train.select_dtypes(include=['int64', 'float64']).drop(['Survived'], axis=1).columns\ncategorical_features = df_train.select_dtypes(include=['object']).columns","c71189f8":"from sklearn.compose import ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])","f430efec":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression","f108b061":"classifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    NuSVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    LogisticRegression(max_iter=1000)\n]","17cdd86b":"for classifier in classifiers:\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', classifier)])\n    pipe.fit(X_train, y_train)   \n    print(classifier)\n    #print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n    print(f\"{pipe.score(X_test, y_test)}\")","08ff4e73":"pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', RandomForestClassifier())])\nparam_grid = { \n    'classifier__n_estimators': [200, 500],\n    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n    'classifier__max_depth' : [4,5,6,7,8],\n    'classifier__criterion' :['gini', 'entropy']}\nfrom sklearn.model_selection import GridSearchCV\nCV = GridSearchCV(pipe, param_grid, n_jobs= 1)\n                  \nCV.fit(X_train, y_train)  \nprint(CV.best_params_)    \nprint(CV.best_score_)","b3839553":"numeric_features_train = df_train.select_dtypes(include=['int64', 'float64']).drop(['Survived'], axis=1).columns\ncategorical_features_train = df_train.select_dtypes(include=['object']).columns\n\nnumeric_features_test = df_test.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features_test = df_test.select_dtypes(include=['object']).columns\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num_train', numeric_transformer, numeric_features_train),\n        ('cat_train', categorical_transformer, categorical_features_train),\n        ('num_test', numeric_transformer, numeric_features_test),\n        ('cat_test', categorical_transformer, categorical_features_test)])\n\npipe_full = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('classifier', RandomForestClassifier(criterion='entropy',\n                                                                  max_depth = 6,\n                                                                  max_features = 'auto',\n                                                                  n_estimators= 500))] )\npipe_full.fit(X, y)  ","5a7cf804":"predictions=pipe_full.predict(df_test)","4a3b1a75":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})","c92abbef":"output.to_csv('tirendaz_submission.csv', index=False)","8a00ac28":"## Preprocessing the data and Fitting model with pipeline","16b22c41":"![](https:\/\/images.unsplash.com\/photo-1567447431310-05ba4a86f1ce?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=985&q=80)","fa0315fb":"# Importing libraries","8cc68d2b":"### Required commands to read the datasets from the working directory","3e9ea521":"## Full Model","eee2ed21":"# Titanic ML Competition","274a70c1":"## Preprocessing","8356fac3":"# Exploring the datasets","19f4412d":"# Loading datasets","1cda974c":"## Predicting Test Set","ced5506c":"## Tuning The Model","138ba7ef":"## Model Selecetion"}}