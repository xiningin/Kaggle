{"cell_type":{"8c8121c8":"code","c0811514":"code","a0deec2a":"code","ccc05d1c":"code","8af9ff4f":"code","6760db60":"code","390cb1ff":"code","4ddef100":"code","e85b608b":"code","a6cdb363":"code","ecc4b2db":"code","b77a0a78":"code","0c92da4e":"code","da9db48c":"code","3d061714":"code","14ec14c4":"code","59a4ae23":"code","e94eef4b":"code","16c62fd5":"code","5aad1f12":"code","b397d863":"code","2bb7c2e7":"code","03c75abd":"code","ce0e9cbd":"code","12601537":"code","fdeb8099":"code","ea512206":"code","5f337c31":"code","6e0b7019":"code","bd255c48":"code","6c39926a":"code","edcd5409":"code","6b76607b":"code","8593d778":"code","a1c3593c":"code","d8503c97":"code","278cd24b":"code","608a86b3":"code","83b80f49":"markdown","7a10a517":"markdown","bd68508c":"markdown","623b8ab2":"markdown","bea98242":"markdown","33c058aa":"markdown","cedd9bad":"markdown","3a5a47f5":"markdown","551b17c7":"markdown","fb691bb4":"markdown","7d868651":"markdown","4159b76c":"markdown","76aa85cd":"markdown","d10b1b43":"markdown","dcd70d0c":"markdown","14579f22":"markdown","7033626e":"markdown","fed11b0b":"markdown","196a004e":"markdown","f1a0a050":"markdown","9bc907b9":"markdown"},"source":{"8c8121c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.lines as mlines\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c0811514":"mu_df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\nqu_df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/questions_only.csv')\nsu_df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/survey_schema.csv')\not_df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/other_text_responses.csv')\nmu19_df = mu_df.drop(index=0, axis=0)\nmu18_df1 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv')\nmu18_df = mu18_df1.drop(index=0, axis=0)\nmu17_df = pd.read_csv('\/kaggle\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv', encoding=\"ISO-8859-1\")","a0deec2a":"def make_df(df, val, col, year, s ):\n# Count by country\n# df: input DataFrame\n# val: count value_name\n# col: count column_name\n# year: survey year\n# s: age or gen\n    wdf = pd.DataFrame(df[val].groupby(df['country_w']).value_counts())\n    wdf.columns=['count']\n    wdf.reset_index(inplace=True)\n    wdf.columns=['country', col, s+'_count']\n    wdf['year'] = year\n    \n    return wdf\n","ccc05d1c":"#Eliminate the shaking\nmu19_df['country_w'] = mu19_df['Q3']\nmu19_df.loc[mu19_df[mu19_df['country_w']=='Republic of Korea'].index, \n            ['country_w']]='South Korea'\n\nmu18_df['age_class'] = mu18_df['Q2']\nmu18_df.loc[mu18_df[mu18_df['age_class']=='70-79'].index, \n            ['age_class']]='70+'\nmu18_df.loc[mu18_df[mu18_df['age_class']=='80+'].index, \n            ['age_class']]='70+'\n\nmu18_df['country_w'] = mu18_df['Q3']\nmu18_df.loc[mu18_df[mu18_df['country_w']=='Republic of Korea'].index, \n            ['country_w']]='South Korea'\n\nmu17_df['age_class'] = pd.cut(mu17_df['Age'], [18, 22, 25, 30, 35, 40, 45, 50, 55, 60, 70, 100], \n           right=False, labels=['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-69', '70+'])\n\nmu17_df['country_w'] = mu17_df['Country']\nmu17_df.loc[mu17_df[mu17_df['country_w']==\"People 's Republic of China\"].index, \n            ['country_w']]='China'\nmu17_df.loc[mu17_df[mu17_df['country_w']==\"Republic of China\"].index, \n            ['country_w']]='China'\nmu17_df.loc[mu17_df[mu17_df['country_w']==\"United Kingdom\"].index, \n            ['country_w']]='United Kingdom of Great Britain and Northern Ireland'\nmu17_df.loc[mu17_df[mu17_df['country_w']==\"United States\"].index, \n            ['country_w']]='United States of America'\nmu17_df.loc[mu17_df[mu17_df['country_w']==\"Vietnam\"].index, \n            ['country_w']]='Viet Nam'\nmu17_df.loc[mu17_df[mu17_df['country_w']==\"Hong Kong\"].index, \n            ['country_w']]='Hong Kong (S.A.R.)'\n\ncountry_age_19 = make_df(mu19_df, 'Q1', 'age_class', '2019', 'age')\ncountry_gen_19 = make_df(mu19_df, 'Q2', 'gender', '2019', 'gen')\ncountry_age_18 = make_df(mu18_df, 'Q2', 'age_class', '2018', 'age')\ncountry_gen_18 = make_df(mu18_df, 'Q1', 'gender', '2018', 'gen')\ncountry_age_17 = make_df(mu17_df, 'age_class', 'age_class', '2017', 'age')\ncountry_gen_17 = make_df(mu17_df, 'GenderSelect', 'gender', '2017', 'gen')\n\ncountry_age_all = pd.concat([country_age_19, country_age_18, country_age_17], axis=0)\ncountry_gen_all = pd.concat([country_gen_19, country_gen_18, country_gen_17], axis=0)\ncountry_age_all.reset_index(drop=True, inplace=True)\ncountry_gen_all.reset_index(drop=True, inplace=True)\n\nelder_age_lst = ['50-54', '55-59', '60-69', '70+']\ncountry_age_all['s_age']='youth'\ncountry_age_all.loc[country_age_all[country_age_all['age_class'].isin(elder_age_lst)].index, \n                    ['s_age']]='elderly'\n\ncountry_age_all.replace({'United States of America':'USA', \n             'United Kingdom of Great Britain and Northern Ireland':'UK'}, inplace=True)\ncountry_gen_all.replace({'United States of America':'USA', \n             'United Kingdom of Great Britain and Northern Ireland':'UK'}, inplace=True)","8af9ff4f":"def calculate_ratio(df, val):\n# Calculate the ratio\n# df: input DataFrame\n# val: count value_name\n    \n    wdf = pd.DataFrame(df.groupby(['year', 'country', val]).sum()).reset_index()\n    wdf_a = pd.DataFrame(df.groupby(['year', 'country']).sum()).reset_index()\n    wdf = pd.merge(wdf, wdf_a, on=['year', 'country'], how='left')\n    wdf.columns = ['year', 'country', val, 'count', 'total']\n    wdf['rate'] = wdf['count'] \/ wdf['total'] *100\n    \n    return wdf","6760db60":"age_df = calculate_ratio(country_age_all, 's_age')\ngen_df = calculate_ratio(country_gen_all, 'gender')\nranking_2019 = age_df[(age_df['s_age']=='elderly')&(age_df['year']=='2019')].sort_values('total', ascending=False)\ntotal_df = age_df[(age_df['s_age']=='elderly') & (age_df['country'].isin(ranking_2019.iloc[:10, 1]))\n                 ].sort_values(['year','total'], ascending=False)\ngender_df = gen_df[(gen_df['gender']=='Female') & (gen_df['country'].isin(ranking_2019.iloc[:10, 1]))\n                 ].sort_values(['year','total'], ascending=False)","390cb1ff":"fig = plt.figure(figsize=(12,4))\nax = fig.add_subplot(1, 1, 1)\ng = sns.barplot(x='country', y='total', \n            data=total_df, hue='year', palette='inferno_r', alpha=0.7)\n \nplt.ylabel('Total count of respondents')\nplt.title('Top 10 respondents by country',fontsize=14 )\nplt.show()","4ddef100":"plt.figure(figsize=(12,4))\nax = fig.add_subplot(1, 1, 1)\n\nsns.scatterplot(x='country', y='rate', data=total_df[total_df['year']=='2019'], \n                s=350, marker='*', color='cyan', label='Elderly')\n\nsns.scatterplot(x='country', y='rate', data=gender_df[gender_df['year']=='2019'], \n                s=150, marker='o', color='magenta', label='Female')\n\nplt.legend(loc='upper center')\nplt.ylabel('Parcentage(%)')\nplt.title('Parcentage of Elderly or Female in Top10 country',fontsize=14 )\nplt.show()","e85b608b":"def make_1819df(wdf, val, val1):\n# Calculate the Growth rate\n# wdf: input DataFrame\n# val: \n# val1:\n\n    df_19 = wdf[wdf['year']=='2019'].rename(columns={'rate': '19rate'}).loc[:, ['country', val, '19rate']]\n    df_18 = wdf[wdf['year']=='2018'].rename(columns={'rate': '18rate'}).loc[:, ['country', val, '18rate']]\n    df_1819 = pd.merge(df_19, df_18, on=['country', val], how='inner')\n    df_1819['up1819'] = (df_1819['19rate']-df_1819['18rate'])\/df_1819['18rate']\n    up_df = df_1819[df_1819[val]==val1].sort_values('19rate', ascending=False)\n    return up_df","a6cdb363":"age_up_df = make_1819df(age_df, 's_age', 'elderly')\ngen_up_df = make_1819df(gen_df, 'gender', 'Female')","ecc4b2db":"fig = plt.figure(figsize=(12,4))\n\nax1 = fig.add_subplot(1, 1, 1)\nax2 = ax1.twinx()\n\nsns.barplot(ax=ax1, data=age_up_df, x='country', y='19rate', palette='spring')\nsns.scatterplot(ax=ax2, data=age_up_df, x='country', y='up1819', color='blue', \n                label='Growth rate of Elderly(2018->2019)')\n\nax1.set_xticklabels(age_up_df['country'], rotation='vertical')\nax1.set_ylabel('The Parcentage of Elderly(%) 2019')\nax2.set_ylabel('Growth rate(%)')\nplt.legend(loc='upper left')\nplt.title('Change in the proportion of elderly people',fontsize=14 )\nplt.show()","b77a0a78":"age_growth = age_up_df.sort_values('19rate', ascending=False).iloc[:10,:]\nage_growth['rank'] = np.arange(10,0,-1)\nage_growth.reset_index(drop=True, inplace=True)\n\ngen_growth = gen_up_df.sort_values('19rate', ascending=False).iloc[:10,:]\ngen_growth['rank'] = np.arange(10,0,-1)\ngen_growth.reset_index(drop=True, inplace=True)","0c92da4e":"def newline(p1, p2, color='black'):\n    ax = plt.gca()\n    l = mlines.Line2D([p1[0],p2[0]], [p1[1],p2[1]], color='red' if p1[1]-p2[1] > 0 else 'black', alpha=0.3)\n    ax.add_line(l)\n    return l","da9db48c":"def draw_growth(wdf, title_text, ylabel_text, y_min, y_max):\n    fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True, figsize=(7,7))\n    pos = np.arange(y_max-1,y_max-11,-1)\n\n    ax.vlines(x=1, ymin=y_min, ymax=y_max, color='black', alpha=0.7, linewidth=1, linestyles='dotted')\n    ax.vlines(x=3, ymin=y_min, ymax=y_max, color='black', alpha=0.7, linewidth=1, linestyles='dotted')\n    ax.scatter(y=wdf['18rate'], x=np.repeat(1, wdf.shape[0]), s=300, alpha=0.7, vmin=1, vmax=10, c=wdf['rank'], cmap=cm.gist_rainbow)\n    ax.scatter(y=wdf['19rate'], x=np.repeat(3, wdf.shape[0]), s=300, alpha=0.7, vmin=1, vmax=10, c=wdf['rank'], cmap=cm.gist_rainbow)\n    ax.scatter(y=pos, x=np.repeat(4.2, wdf.shape[0]), s=300, alpha=0.7, vmin=1, vmax=10, c=wdf['rank'], cmap=cm.gist_rainbow)\n\n    for p1, p2, p3, c in zip(wdf['18rate'], wdf['19rate'], pos, wdf['country']):\n        newline([1,p1], [3,p2])\n        ax.text(1-0.1, p1, str(round(p1)), horizontalalignment='right', verticalalignment='center', fontdict={'size':8})\n        ax.text(3+0.1, p2, str(round(p2)), horizontalalignment='left', verticalalignment='center', fontdict={'size':8})\n        ax.text(4.2, p3, c, horizontalalignment='left', verticalalignment='center', fontdict={'size':9})\n    \n    ax.text(1, y_max+0.1, '2018', horizontalalignment='center', verticalalignment='center', fontdict={'size':11, 'weight':500})\n    ax.text(3, y_max+0.1, '2019', horizontalalignment='center', verticalalignment='center', fontdict={'size':11, 'weight':500})\n\n    ax.set_title(title_text, fontdict={'size':14})\n    ax.set(xlim=(0,5), ylim=(y_min-2,y_max+2), ylabel=ylabel_text)\n    ax.set_xticks([])\n    #ax.set_xticklabels([\"2018\", \"2019\"])\n    plt.yticks(np.arange(y_min, y_max, 5), fontsize=9)\n\n    plt.gca().spines[\"top\"].set_alpha(.0)\n    plt.gca().spines[\"bottom\"].set_alpha(.0)\n    plt.gca().spines[\"right\"].set_alpha(.0)\n    plt.gca().spines[\"left\"].set_alpha(.0)\n    plt.show()","3d061714":"title_text='Change in ratio of Elderly 2018 -> 2019'\nylabel_text = 'Elderly Ratio'\ndraw_growth(age_growth, title_text, ylabel_text, 4, 25)","14ec14c4":"fig = plt.figure(figsize=(12,4))\n\nax1 = fig.add_subplot(1, 1, 1)\nax2 = ax1.twinx()\n\nsns.barplot(ax=ax1, data=gen_up_df, x='country', y='19rate', palette='summer')\nsns.scatterplot(ax=ax2, data=gen_up_df, x='country', y='up1819', color='red',\n               label='Growth rate of Female(2018->2019)')\n\nax1.set_xticklabels(gen_up_df['country'], rotation='vertical')\nax1.set_ylabel('The Parcentage of Female(%) 2019')\nax2.set_ylabel('Growth rate(%)')\nplt.legend(loc='upper left')\nplt.title('Change in the proportion of female',fontsize=14 )\nplt.show()","59a4ae23":"title_text='Change in ratio of Female 2018 -> 2019'\nylabel_text = 'Female Ratio'\ndraw_growth(gen_growth, title_text, ylabel_text, 13, 50)","e94eef4b":"age_pickup_lst = ['Canada', 'UK', 'Japan', 'Germany', 'Brazil', \n                  'Singapore', 'Egypt', \n                  'Belgium', 'New Zealand', 'Italy', 'Israel', 'Netherlands', 'Australia']\ngen_pickup_lst = ['Canada', 'UK', 'Germany', 'Russia', 'Brazil',\n                  'Czech Republic', 'Ireland', \n                  'Tunisia', 'Phillipines', 'Iran, Islamic Republic of...', 'Malaysia', 'Kenya']\ngen_pickup_lst.extend(age_pickup_lst)\ncountry_list = list(set(gen_pickup_lst))\n\nsample_df = mu19_df[(mu19_df['Q3'].isin(country_list)) &\n                    (mu19_df['Q2']=='Female') & (mu19_df['Q1'].isin(elder_age_lst))]\nusa_df = mu19_df[(mu19_df['Q3']=='United States of America') & \n                 (mu19_df['Q2']=='Female') & (mu19_df['Q1'].isin(elder_age_lst))]\n\ntarget_df = pd.DataFrame(sample_df['Q3'].value_counts())\ntarget_df = pd.concat([target_df,pd.DataFrame(target_df.sum(axis=0),columns=['Grand Total']).T])\ntarget_df = pd.concat([target_df, pd.DataFrame(usa_df['Q3'].value_counts())])\ntarget_df.columns=['Count of Elderly Female Kaggler']\ntarget_df.index.name = 'Country'\n\nxy = [[0.25, 0.55], [0.35, 0.6], [0.25, 0.7], [0.25, 0.8], [0.3, 0.4], [0.4, 0.5], [0.45, 0.6], [0.45, 0.7],\n[0.55, 0.55],[0.6, 0.65], [0.65, 0.75], [0.45, 0.8], [0.75, 0.4]]\n\nxy = pd.DataFrame(xy, columns=['x', 'y'])\ncountry_df = pd.concat([target_df.drop(index='Grand Total').reset_index(), xy], axis=1)","16c62fd5":"plt.figure(figsize=(5,5))\ncmap = sns.cubehelix_palette(dark=.4, light=.7, as_cmap=True)\ng = sns.scatterplot(country_df['x'], country_df['y'], size=country_df['Count of Elderly Female Kaggler'], \n                hue=country_df['Count of Elderly Female Kaggler'], palette=cmap, sizes=(10,5000),\n               legend=False)\nimport matplotlib.patches as patches\npatches.Circle(xy=(0.0, 0.0), radius=0.2, fc='g', ec='r')\n\nfor p1, p2, c, n in zip(country_df['x'], country_df['y'], country_df['Country'], country_df['Count of Elderly Female Kaggler']):\n    plt.text(p1, p2+0.03, c, horizontalalignment='center', verticalalignment='center', fontdict={'size':9})\n    plt.text(p1, p2, str(n), horizontalalignment='left', verticalalignment='center', fontdict={'size':9})\nplt.ylim(0.2, 1.0)\nplt.xlim(0.1, 1.05)\n\nplt.xlabel('')\nplt.ylabel('')\n\ng.set(xticklabels=[])\ng.set(yticklabels=[])\n\nplt.title('Sample Countries & USA')\n    \n#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, fontsize=11)\n\nplt.show()","5aad1f12":"deg_level={'No formal education past high school':0,\n           'Some college\/university study without earning a bachelor\u2019s degree':1,\n           'Bachelor\u2019s degree':2,\n           'Master\u2019s degree':3,\n           'Doctoral degree':4,\n           'Professional degree':5}","b397d863":"def compare_item(val, v_name, val_dic, v_level):\n    s = pd.DataFrame(sample_df[val].value_counts(normalize=True).sort_values(ascending=True)).reset_index()\n    s.columns=[v_name, 'sample']\n    u = pd.DataFrame(usa_df[val].value_counts(normalize=True).sort_values(ascending=True)).reset_index()\n    u.columns=[v_name, 'usa']\n    s_u = pd.merge(s, u, on=v_name, how='outer')\n    s_u[v_level] = 0\n    for k in val_dic.keys():\n        s_u.loc[s_u[s_u[v_name]==k].index, [v_level]] = val_dic[k]\n    s_u_df = s_u.sort_values(v_level, ascending=False)\n    s_u_df.fillna(0, inplace=True)\n                             \n    return s_u_df","2bb7c2e7":"def draw_pie(wdf, labels, titletext, v):\n    \n    fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,5))\n\n    ax.set_aspect('equal')\n    \n    col=cm.Spectral(np.arange(len(wdf))\/float(len(wdf)))\n    (_, textsL, autotextsL) = axL.pie(wdf['sample'], \n        autopct=lambda p: '{:.1f}%'.format(p) if p >= v else '', colors=col,\n        #autopct='%1.1f%%', \n        startangle=90, pctdistance=0.7,radius=1.25, counterclock=False,\n        #textprops={'rotation':0, 'color': \"b\", 'weight': \"bold\"},\n        wedgeprops={'linewidth': 1, 'edgecolor':\"white\"})\n\n    (_, textsR, autotextsR)  = axR.pie(wdf['usa'], \n        autopct=lambda p: '{:.1f}%'.format(p) if p >= v else '', colors=col,\n        #autopct='%1.1f%%', \n        startangle=90, pctdistance=0.7,radius=1.25, counterclock=False,\n        #textprops={'rotation':0, 'color': \"black\", 'weight': \"bold\"},\n        wedgeprops={'linewidth': 1, 'edgecolor':\"white\"})\n\n    box = axR.get_position()\n    axR.set_position([0.5, box.y0, box.width, box.height])\n    axR.legend(labels=labels, loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 12})\n\n    axL.set_title('Sample_Countries')\n    axR.set_title('USA')\n    fig.suptitle(titletext, fontsize=20)\n\n    plt.show()","03c75abd":"s_u_df_Q4 = compare_item('Q4', 'degree', deg_level, 'd_no')\nlabels = s_u_df_Q4['degree']\ntitletext = 'Degree comparison'\ndraw_pie(s_u_df_Q4, labels, titletext, 2)","ce0e9cbd":"role_level={'Statistician':11,'Research Scientist':10,\n'Data Scientist':9,'Data Analyst':8,'Data Engineer':7,'Business Analyst':6,'Product\/Project Manager':5,\n'Software Engineer':4,'DBA\/Database Engineer':3, 'Student':2,'Other':1,'Not employed':0}\ns_u_df_Q5 = compare_item('Q5', 'role', role_level, 'r_no')\nlabels = s_u_df_Q5['role']\ntitletext = 'Role comparison'\ndraw_pie(s_u_df_Q5, labels, titletext, 2)","12601537":"def multiple_ans(wdf, val_n, k, flg):\n    tate_df = pd.DataFrame()\n    for i in range(1,k+1):\n        n = val_n + str(i)\n        tate_df = pd.concat([tate_df, wdf[n]])\n    tate_df.columns = [flg]\n    m_ans = pd.DataFrame(tate_df[flg].value_counts())\n    m_ans.reset_index(inplace=True)\n    m_ans.columns = ['part', flg]\n    \n    return m_ans","fdeb8099":"s_Q9 = multiple_ans(sample_df, 'Q9_Part_', 8, 'sample')\nu_Q9 = multiple_ans(usa_df, 'Q9_Part_', 8, 'usa')\ns_u_df_Q9 = pd.merge(s_Q9, u_Q9, on='part', how='outer')\nlabels=['Build prototypes to explore applying ML to new areas',\n       'Analyze and understand data to influence product or business decisions',\n       'Build\/run a ML service that operationally improvement',\n       'Build\/run the data infrastructure for storing, analyzing, and operationalizing',\n       'Do research that advances the state of the art of ML',\n       'Experimentation and iteration to improve existing ML models',\n       'None of these activities are an important part of my role at work',\n       'Other']\ntitletext='Activities comparison'\ns_u_df_Q9.fillna(0, inplace=True)","ea512206":"draw_pie(s_u_df_Q9, labels, titletext,2)","5f337c31":"s_Q10 = pd.DataFrame(sample_df['Q10'].value_counts(normalize=True).sort_values(ascending=True)).reset_index()\ns_Q10.columns=['money', 'count']\ns_Q10['type'] = 'sample'\nu_Q10 = pd.DataFrame(usa_df['Q10'].value_counts(normalize=True).sort_values(ascending=True)).reset_index()\nu_Q10.columns=['money', 'count']\nu_Q10['type'] = 'usa'\ns_u_Q10 = pd.concat([s_Q10, u_Q10]).reset_index(drop=True)\n\nimport re\ns_u_Q10['level'] = 0\nfor i in range(len(s_u_Q10)):\n    content = s_u_Q10['money'][i]\n    pattern = '[0-9]+,[0-9]{3}'\n    if content == \"$0-999\":\n        s_u_Q10.loc[i, ['level']] = 0\n    else:\n        result = re.match(pattern, content)\n        ss = result.group().replace(\",\", \"\")\n        s_u_Q10.loc[i, ['level']]= ss\ns_u_Q10['level'] = s_u_Q10['level'].astype(int)\ns_u_Q10.sort_values('level', inplace=True)\ns_u_Q10['rate'] = s_u_Q10['count']*100","6e0b7019":"fig = plt.figure(figsize=(15,3))\n\nax = fig.add_subplot(1, 1, 1)\n\nsns.barplot(ax=ax, x='level', y='rate', data=s_u_Q10, hue='type', palette='hot')\n#ax.set_xticklabels(s_u_Q10['level'], rotation='vertical')\nax.set_xlabel('Yearly compensation')\nax.set_ylabel('Parcentage(%)')\nax.set_title('Compensation comparison')\nplt.show()","bd255c48":"spent_level = {'$0 (USD)':0,\n               '$1-$99':1,\n               '$100-$999':2,\n               '$1000-$9,999':3,\n               '$10,000-$99,999':4,\n               '> $100,000 ($USD)':5}\n\ns_u_df_Q11 = compare_item('Q11', 'spend', spent_level, 'sp_no')\nlabels = s_u_df_Q11['spend']\ntitletext = 'Money spent comparison'\ndraw_pie(s_u_df_Q11, labels, titletext,2)","6c39926a":"write_level = {'I have never written code':0, '< 1 years':1, '1-2 years':2, '3-5 years':3,\n'5-10 years':4, '10-20 years':5, '20+ years':6 }\ns_u_df_Q15 = compare_item('Q15', 'time', write_level, 'ti_no')\nlabels = s_u_df_Q15['time']\ntitletext = 'Writing code time comparison'\ndraw_pie(s_u_df_Q15, labels, titletext, 2)","edcd5409":"s_Q13 = multiple_ans(sample_df, 'Q13_Part_', 12, 'sample')\nu_Q13 = multiple_ans(usa_df, 'Q13_Part_', 12, 'usa')\ns_u_df_Q13 = pd.merge(s_Q13, u_Q13, on='part', how='outer')\n\nlabels=s_u_df_Q13['part']\ntitletext='Learning course comparison'\ns_u_df_Q13.fillna(0, inplace=True)\ndraw_pie(s_u_df_Q13, labels, titletext, 2)","6b76607b":"lange_level = {'Python':8, 'R':7, 'C++':6, 'SQL':5, 'MATLAB':4, 'Bash':3, 'Java':2, 'Javascript':1, 'Other':0}\ns_u_df_Q19 = compare_item('Q19', 'lange', lange_level, 'la_no')\nlabels = s_u_df_Q19['lange']\ntitletext = 'Recommended language comparison'\ndraw_pie(s_u_df_Q19, labels, titletext, 3)","8593d778":"s_Q12 = multiple_ans(sample_df, 'Q12_Part_', 12, 'sample')\nu_Q12 = multiple_ans(usa_df, 'Q12_Part_', 12, 'usa')\ns_u_df_Q12 = pd.merge(s_Q12, u_Q12, on='part', how='outer')\n\nlabels=s_u_df_Q12['part']\ntitletext='Media sources comparison'\ns_u_df_Q12.fillna(0, inplace=True)\ndraw_pie(s_u_df_Q12, labels, titletext, 2)","a1c3593c":"s_Q18 = multiple_ans(sample_df, 'Q18_Part_', 12, 'sample')\nu_Q18 = multiple_ans(usa_df, 'Q18_Part_', 12, 'usa')\ns_u_df_Q18 = pd.merge(s_Q18, u_Q18, on='part', how='outer')\nlabels=s_u_df_Q18['part']\n\ntitletext='Programming languages comparison'\ns_u_df_Q18.fillna(0, inplace=True)\ndraw_pie(s_u_df_Q18, labels, titletext, 3)","d8503c97":"s_Q20 = multiple_ans(sample_df, 'Q20_Part_', 12, 'sample')\nu_Q20 = multiple_ans(usa_df, 'Q20_Part_', 12, 'usa')\ns_u_df_Q20 = pd.merge(s_Q20, u_Q20, on='part', how='outer')\n\nlabels=s_u_df_Q20['part']\ntitletext='Visualization libraries or tools'\ns_u_df_Q20.fillna(0, inplace=True)\ndraw_pie(s_u_df_Q20, labels, titletext, 2)","278cd24b":"s_Q24 = multiple_ans(sample_df, 'Q24_Part_', 12, 'sample')\nu_Q24 = multiple_ans(usa_df, 'Q24_Part_', 12, 'usa')\ns_u_df_Q24 = pd.merge(s_Q24, u_Q24, on='part', how='outer')\nlabels=s_u_df_Q24['part']\ntitletext=' ML algorithms  comparison'\ns_u_df_Q24.fillna(0, inplace=True)\ndraw_pie(s_u_df_Q24, labels, titletext, 3)","608a86b3":"s_Q28 = multiple_ans(sample_df, 'Q28_Part_', 12, 'sample')\nu_Q28 = multiple_ans(usa_df, 'Q28_Part_', 12, 'usa')\ns_u_df_Q28 = pd.merge(s_Q28, u_Q28, on='part', how='outer')\n\nlabels=[s_u_df_Q28['part'][i].strip() for i in range(len(s_u_df_Q28))]\ntitletext='ML frameworks  comparison'\ns_u_df_Q28.fillna(0, inplace=True)\ndraw_pie(s_u_df_Q28, labels, titletext, 3)","83b80f49":"The difference between the two is the high proportion of Keras and Carat in the USA. Carat is a package for handling R's many machine learning-related packages in a unified manner, and is a characteristic of USA with many R users.\nKeras is deep learning and will handle advanced algorithms.","7a10a517":"### Pick up a distinctive country\n\nBased on the results so far, I will pick up some countries that is characteristic of the elderly and women.\n\nCountries with many respondents, countries with a high ratio of elderly to women, and countries with large changes in the ratio of elderly to women.\n\nAnd I'm most interested in elder female respondents. Therefore, I extracted respondents who satisfy two conditions(elderly female) from these countries.\nThe final target country is\nGermany, Italy, Netherlands, Ireland, Russia, Tunisia, Australia, New Zealand, Singapore, Japan, Brazil, United States.\n\nHowever, this sample size is very small, only 119. And more than half are in the United States.\nBut I think they are my companions and I want to know what profiles they are and how they work.\nAnd I came up with a comparison between America, the leader of this domain, and other sample countries.\n\nFree answer data(other_text_responses.csv)is not used because it cannot be linked to these sample data. If necessary, I refer to the analysis results for all respondents on the Kaggle team.(https:\/\/www.kaggle.com\/kaggle-survey-2019)","bd68508c":"### At the end\n\nI was encouraged by the fact that very few inexperienced female data analysts are playing an active role. On the other hand, I am able to recognize that some women particularly in the United States are active with highly experienced and highly skilled. I want to make the most of Kaggle (competitive participation and e-learning) and grow.\n","623b8ab2":"Visualization tends to use matplotlib in sample countries where there are many Pythons, and Ggplot in USA where R usage is high. As for the visualization tool, R seems to be excellent, so I would like to expect that the functions will be enhanced in the Python library in the future. ","bea98242":"Basically, the programming language used is not much different, but due to the difference in years of experience, those with long experience tend to use R, those who are new to start tend to use Python I think that.\nThere are about 20% of people who use SQL, and I think that it will be the basis of the concept of data processing.","33c058aa":"### Parcentage of Female(All Country)  \n\nThis is the percentage of female among all respondents in all countries. The red-dot is the rate of change of the proportion of female people from 2018 to 2019.  \nThe second graph shows the percentage of 2018 and 2019 in the top10 countries. You can see the state of change.\n\nCountries in where many female people are active are Tunisia, Philippines, Iran\/Islamic, Malaysia, Kenya and Ireland and so on.\nAnd these countries excluding Egypt, the female ratio has increased since 2018. They are not countries with many respondents.\n\nThe biggest increase was in Ireland, up from 12.9% to 24.7%.","cedd9bad":"## About Kaggler of active elderly woman\n\nI am a woman in my 50s. I started learning data science two years ago. I'm learning a lot about Python programs and Machine Learning algorithms, but it's very difficult.  \nI am interested in the situation of data scientists like me who are active in the world, and I begin to analyze them with this Survey Data.\n\nMy Japan has become an aging society, and there is a need for diversification. And I have heard Japanese data science lags behind the world level.  \nI would be honored if people with various backgrounds could master the technology based on this analysis. I think it will also encourage me.\n","3a5a47f5":"### Top 10 countries surveyed  \n\n In the three-year survey, the number of respondents by country is as follows.  As you know, in 2019, India surpassed the United States and became the best. Japan is 4th without 'Other'.  \n I don't know why, but the number of respondents in 2018 is small and it is decreasing in many countries. However, only Japan is increasing. But the situation is far from India 1st and America 2nd.","551b17c7":"The code writing time was also different between the two.\nAbout 40% of US people have over 20 years of experience.\nMore than 60% of people are over 10 years old.\nOn the other hand, in the sample countries, almost half of the people are less than one year to two years, and there are many inexperienced people. I am one of them, so I feel very familiar with them.\nThis trend is similar to the overall analysis of the Kaggle team.","fb691bb4":"There is no difference in the learning courses used. Cousera, DataCamp, Kaggle, edX are often used.","7d868651":"In the ML algorithm, there is no significant difference between the two, but Linear or Logiostic regression is often used along with decision trees and random forests. Although advanced algorithms are used in score battles in competitions, algorithms that have a higher explanatory power than accuracy are often used in the real world.\nThen the percentage of neural networks is low.","4159b76c":"![](http:\/\/)","76aa85cd":"### Role & Activities\n\nSee the Role and Activities trends. This is a summary of the following questions and answers.\n\nQ5:  Select the title most similar to your current role  \nQ9:  Select any activities that make up an important part of your role at work\n\nIn the sample countries, 13% are researchers and 16.7% are unemployed, which is more than in the United States.\nTherefore, the application of ML to new areas is about 30%.\u3000It may be said that there are many academic environments.\n\nOn the other hand, in the United States, the ratio of people working in companies such as Product\/Project managers 12.9% and DBA\/Database engineers 8.1% seems to be high. In terms of activities, we can see that people working in IT at general companies are also engaged in DS \/ ML activities, such as 18.6% data infrastructure and 14.4% improvement of existing models.","d10b1b43":"### Parcentage of Elderly and Female(Top10 Country)\n\n This is the Parcentage of Elderly or Female in all respondents of each Top10 country. Blue-Star is the parcentage of Elderly and pink-dot is the parcentage of Female.  \n I define elderly is over 50 age, then I separated the survey data to under-50 and over-50. And I focus on elderly(over-50) dataset.\n On the other hand, we selected respondents who answered women as gender questions. Some answers other than male or female were excluded because of the small number. \n \n India and China have similler trand that Female ratio is much higher than Elderly ratio. I think it means that increasing of respondents is depend on younger people. In these countries, young kagler (regardless of gender) is active.  \n It should be noted that Japan's trend is exactly the opposite of other countries. In other words, there are very few women and a high proportion of the elderly in the Japanese Data Science or Data Analysis domain.\n \n It seems to be caused by the aging society and the delay of women's social advancement.","dcd70d0c":"### compensation\n\nSee the yearly compensation. This is a summary of the following questions and answers.\n\nQ10:  What is your current yearly compensation (approximate $USD)?\n\nRegarding income, there is a clear difference between the sample country and the USA.\n\nUSA is clearly high income. This is also seen in the overall analytical trend by the Kaggle team.\nThe USA may have a lot of workers in general high-class companies that are pushing up the overall amount.","14579f22":"Finally, the recommended language is Python, many people say regardless of country\nLooking at the overall trend, recently Python seems to be more popular than R. Since there are people with long experience in USA, it seems that there are some people who advance R. As will be described later, in visualization, the R package is also valid.\n","7033626e":"### Learning situation(spent money, years, learning courses, recommend language)\n\nSee the Learning situation. This is a summary of the following questions and answers.\n\nQ11:  Approximately how much money have you spent on machine learning and\/or cloud computing products at your work in the past 5 years?   \nQ15:  How long have you been writing code to analyze data (at work or at school)?  \nQ13:  On which platforms have you begun or completed data science courses?\nQ19:  What programming language would you recommend an aspiring data scientist to learn first?\n\n\nFirst, the cost of spending in the United States is higher, with more than half of those who spend more than $ 1000. There are quite a few dollars in the sample countries.\nBecause the income is high in the United States, the amount that can be spent may be large.\n\n\n\n\n\n","fed11b0b":"### Parcentage of Elderly(All Country)  \n\nThis is the percentage of elderly among all respondents in all countries. The blue-dot is the rate of change of the proportion of elderly people from 2018 to 2019.  \nThe second graph shows the percentage of 2018 and 2019 in the top 10 countries. You can see the state of change.\n\nCountries in where many elderly people are active are Belgium, New Zealand, Italy, Israel, the Netherlands and Australia and so on.\nAnd in all these countries, the elderly ratio has increased since 2018.  \nAbove all, the rate of increase in Belgium is very large ,from 6.3% in 2018 to 24.3% in 2019.\nThey are not countries with many respondents.\n","196a004e":"### Prepare the data\nI import the data of Kaggle's third annual Machine Learning and Data Science Survey.\nFor comparison, I prepare data for FY2017 and FY2018. Because I want to know the changes over the three years.\n\nIn terms of data cleansing, there ware Shaking in notation by country name and age in the three surveys, so it was necessary to unify them.","f1a0a050":"### Degree\n\nSee the degree trends. This is a summary of the following questions and answers.\n\nQ4:  What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\n\nIn the sample countries, the professional degree is 5.5% and the doctoral degree is 34.5%, which is higher than the USA.\n\nHowever, the proportion of masters is lower than in the United States, and the proportion of bachelors is high.\nThe distribution of USA degrees is similar to the overall analysis trend of the Kaggle team.","9bc907b9":"### activity environment  \n(media source, languages, visualization libraries, ML algorithms, ML frameworks)\n\nSee the activity environment. This is a summary of the following questions and answers.\n\nQ12:  Who\/what are your favorite media sources that report on data science topics?  \nQ18:  What programming languages do you use on a regular basis?  \nQ20:  What data visualization libraries or tools do you use on a regular basis?  \nQ24:  Which of the following ML algorithms do you use on a regular basis?  \nQ28:  Which of the following machine learning frameworks do you use on a regular basis? \n\n\nThere are no major differences in the media sources used, but Kaggle is used more often in the Sample country.\nI think this is because Kaggle is very effective because we can learn a lot of things free of charge and get the wisdom of many Data Scientists and Data Analyst.\n"}}