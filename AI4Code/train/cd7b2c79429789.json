{"cell_type":{"2ca1efda":"code","7706cd8f":"code","7b4719af":"code","3c013850":"code","1b426930":"code","b973ffd3":"code","f43eef94":"code","bb0329b2":"code","2faec111":"code","fb3c8068":"code","b417df87":"code","1056fed1":"code","c3357d9a":"code","bd7df83f":"code","90486cc3":"code","d3c84913":"code","0fadc284":"code","599fc870":"code","92733c60":"code","83ce1c50":"code","c7d9161c":"code","07c2771b":"code","3172a9a2":"code","7775d4c3":"code","1c428354":"code","f66e4f35":"code","52e1c836":"code","bb94368b":"markdown","601fd71f":"markdown","f26dac30":"markdown","22343449":"markdown","53292190":"markdown","54363bd1":"markdown","f3f4feb9":"markdown","b6ef6a89":"markdown","d1fa495b":"markdown","1d686c0d":"markdown","ae33363f":"markdown","2977d37a":"markdown","5a04d51f":"markdown","a2af322c":"markdown","15701c66":"markdown","b16726c8":"markdown","050afd3e":"markdown","e07cf08a":"markdown","c3dd78a9":"markdown","517d7803":"markdown","d974ccc2":"markdown","ef0b937e":"markdown","f9165eda":"markdown"},"source":{"2ca1efda":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.linear_model as lm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler, label_binarize\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc, f1_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.svm import SVC\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","7706cd8f":"#data = pd.read_csv(\"train.csv\",sep=',')\ndata = pd.read_csv(\"..\/input\/nida-competition1\/train.csv\",sep=',')\ndisplay(data.head())\ndisplay('There is {} observations with {} features'.format(data.shape[0], data.shape[1]))","7b4719af":"data.info()","3c013850":"value_counts = data['y'].value_counts()\nvalue_counts.plot.bar(color=['darkred','darkblue'], title = 'Deposit value counts');","1b426930":"# Build a function to show categorical values disribution\ndef plot_bar(column):\n    # temp df \n    temp_1 = pd.DataFrame()\n    # count categorical values\n    temp_1['No_deposit'] = data[data['y'] == 'no'][column].value_counts()\n    temp_1['Yes_deposit'] = data[data['y'] == 'yes'][column].value_counts()\n    temp_1.plot(kind='bar',color=['darkred','darkblue'])\n    plt.xlabel(f'{column}')\n    plt.ylabel('Number of clients')\n    plt.title('Distribution of {} and deposit'.format(column))\n    plt.show();","b973ffd3":"cat_columns = ['job', 'marital', 'education']\n\nfor cat_column in cat_columns:\n    plot_bar(cat_column)","f43eef94":"cat_columns = ['default', 'housing', 'loan']\n\nfor cat_column in cat_columns:\n    plot_bar(cat_column)","bb0329b2":"cat_columns = ['contact','month', 'day_of_week', 'poutcome']\n\nfor cat_column in cat_columns:\n    plot_bar(cat_column)","2faec111":"# Convert target variable into numeric\ndata.y = data.y.map({'no':0, 'yes':1}).astype('uint8')","fb3c8068":"# Build correlation matrix\ncorr = data.corr()\ncorr.style.background_gradient(cmap='BuGn')","b417df87":"#Feature Engineering\n##Handling outliers\nplt.figure(figsize = (20, 10))\nplt.style.use('seaborn-white')\nax=plt.subplot(251)\nplt.boxplot(data['age'])\nax.set_title('age')\nax=plt.subplot(252)\nplt.boxplot(data['duration'])\nax.set_title('duration')\nax=plt.subplot(253)\nplt.boxplot(data['campaign'])\nax.set_title('campaign')\nax=plt.subplot(254)\nplt.boxplot(data['pdays'])\nax.set_title('pdays')\nax=plt.subplot(255)\nplt.boxplot(data['previous'])\nax.set_title('previous')\nax=plt.subplot(256)\nplt.boxplot(data['emp.var.rate'])\nax.set_title('Employee variation rate')\nax=plt.subplot(257)\nplt.boxplot(data['cons.price.idx'])\nax.set_title('Consumer price index')\nax=plt.subplot(258)\nplt.boxplot(data['cons.conf.idx'])\nax.set_title('Consumer confidence index')\nax=plt.subplot(259)\nplt.boxplot(data['euribor3m'])\nax.set_title('euribor3m')\nax=plt.subplot(2,5,10)\nplt.boxplot(data['nr.employed'])\nax.set_title('No of employees');","1056fed1":"#data.info()","c3357d9a":"#Drop the duplicates\ndata.drop_duplicates(inplace=True)","bd7df83f":"data_features=data.copy()\ndata_features['pdays2'] = data_features['pdays']\ndata_features","90486cc3":"#Encoding\njob_dict={'admin.':1,'technician':2,'blue-collar':3,'retired':4,'services':5,'management':6,'student':7\n          ,'self-employed':8,'unemployed':9,'entrepreneur':10,'housemaid':11,'unknown':12}\ndata_features['job']= data_features['job'].map(job_dict)\n\nmarital_dict={'divorced': 0, 'married': 1, 'single': 2, 'unknown': 3}\ndata_features['marital']= data_features['marital'].map(marital_dict)\n\neducation_dict={'unknown':0, 'illiterate':1, 'basic.4y':2, 'basic.6y':3, 'basic.9y':4, 'high.school':5\n                , 'university.degree':6, 'professional.course':7}\ndata_features['education']= data_features['education'].map(education_dict)\n\ndictionary = {'yes':1,'no':0,'unknown':-1}\ndata_features['housing'] = data_features['housing'].map(dictionary).astype('uint8')\ndata_features['default'] = data_features['default'].map(dictionary).astype('uint8')\ndata_features['loan'] = data_features['loan'].map(dictionary).astype('uint8')\n\ncontact_dict = {'cellular':1,'telephone':0}\ndata_features['contact'] = data_features['contact'].map(contact_dict).astype('uint8')\n\nmonth_dict = {'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12}\ndata_features['month'] = data_features['month'].map(month_dict).astype('uint8')\n\nday_dict = {'sun':1,'mon':2,'tue':3, 'wed':4,'thu':5,'fri':6,'sat':7}\ndata_features['day_of_week'] = data_features['day_of_week'].map(day_dict).astype('uint8')\n\npoutcome_dict = {'nonexistent':-1, 'failure':0, 'success':1}\ndata_features['poutcome'] = data_features['poutcome'].map(poutcome_dict).astype('uint8')\n\n\ndata_features.loc[data_features['pdays2'] == 999, 'pdays'] = 0   # replace with 0 if not contact\ndata_features.loc[data_features['pdays2'] != 999, 'pdays'] = 1","d3c84913":"data_features.iloc[15:22]","0fadc284":"#data_features.info()","599fc870":"X = data_features.drop(['y'],axis=1)\ny = data_features.y","92733c60":"model = ExtraTreesClassifier()\nmodel.fit(X,y)\n\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='bar',color='darkblue')\nplt.show()","83ce1c50":"ros = RandomOverSampler(random_state=0)\nX, y = ros.fit_resample(X, y)\ndisplay(pd.Series(y).value_counts())","c7d9161c":"#Model Selection\nlogreg = LogisticRegression()\ndt = DecisionTreeClassifier()\nknn = KNeighborsClassifier()\nforest = RandomForestClassifier()\ngrad_clf = GradientBoostingClassifier()\nxgb_clf = XGBClassifier()\n  \ncv_dict = {0: 'LogisticRegression',1: 'DecisionTreeClassifier', 2:'KNeighborsClassifier'\n           , 3:'RandomForestClassifier', 4:'GradientBoostingClassifier', 5:'XGBClassifier'}    \ncv_models=[logreg, dt, knn, forest, grad_clf, xgb_clf]\n\nfor i,model in enumerate(cv_models):\n    print(\"\\n{} Test Accuracy_CV: {}\".format(cv_dict[i],cross_val_score(model, X, y, cv=10, scoring ='accuracy').mean()))","07c2771b":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=1)\n\nlogreg.fit(X_train, y_train)\nlogreg_pred = logreg.predict(X_test)\nprint('\\n',confusion_matrix(y_test, logreg_pred))\nprint('LogisticRegression Precision Score: ', precision_score(y_test, logreg_pred))\nprint('LogisticRegression Recall Score: ', recall_score(y_test, logreg_pred))\nprint('LogisticRegression f1 Score: ', f1_score(y_test, logreg_pred))\n\n\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test)\nprint('\\n',confusion_matrix(y_test, dt_pred))\nprint('DecisionTreeClassifier Precision Score: ', precision_score(y_test, dt_pred))\nprint('DecisionTreeClassifier Recall Score: ', recall_score(y_test, dt_pred))\nprint('DecisionTreeClassifier f1 Score: ', f1_score(y_test, dt_pred))\n\n\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nprint('\\n',confusion_matrix(y_test, knn_pred))\nprint('KNeighborsClassifier Precision Score: ', precision_score(y_test, knn_pred))\nprint('KNeighborsClassifier Recall Score: ', recall_score(y_test, knn_pred))\nprint('KNeighborsClassifier f1 Score: ', f1_score(y_test, knn_pred))\n\n\nforest.fit(X_train, y_train)\nforest_pred = forest.predict(X_test)\nprint('\\n',confusion_matrix(y_test, forest_pred))\nprint('RandomForestClassifier Precision Score: ', precision_score(y_test, forest_pred))\nprint('RandomForestClassifier Recall Score: ', recall_score(y_test, forest_pred))\nprint('RandomForestClassifier f1 Score: ', f1_score(y_test, forest_pred))\n\ngrad_clf.fit(X_train, y_train)\ngrad_clf_pred = grad_clf.predict(X_test)\nprint('\\n',confusion_matrix(y_test, grad_clf_pred))\nprint('GradientBoostingClassifier Precision Score: ', precision_score(y_test, grad_clf_pred))\nprint('GradientBoostingClassifier Recall Score: ', recall_score(y_test, grad_clf_pred))\nprint('GradientBoostingClassifier f1 Score: ', f1_score(y_test, grad_clf_pred))\n\nxgb_clf.fit(X_train, y_train)\nxgb_clf_pred = xgb_clf.predict(X_test)\nprint('\\n',confusion_matrix(y_test, xgb_clf_pred))\nprint('XGBClassifier Precision Score: ', precision_score(y_test, xgb_clf_pred))\nprint('XGBClassifier Recall Score: ', recall_score(y_test, xgb_clf_pred))\nprint('XGBClassifier f1 Score: ', f1_score(y_test, xgb_clf_pred))","3172a9a2":"#ROC Curve\n\nlogreg.fit(X_train, y_train)\nlogreg_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr_logreg, tpr_logreg, thresholds_logreg = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n\ndt.fit(X_train, y_train)\ndt_roc_auc = roc_auc_score(y_test, dt.predict(X_test))\nfpr_dt, tpr_dt, thresholds_knn = roc_curve(y_test, dt.predict_proba(X_test)[:,1])\n\nknn.fit(X_train, y_train)\nknn_roc_auc = roc_auc_score(y_test, knn.predict(X_test))\nfpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, knn.predict_proba(X_test)[:,1])\n\nforest.fit(X_train, y_train)\nforest_roc_auc = roc_auc_score(y_test, forest.predict(X_test))\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, forest.predict_proba(X_test)[:,1])\n\ngrad_clf.fit(X_train, y_train)\ngrad_clf_roc_auc = roc_auc_score(y_test, grad_clf.predict(X_test))\nfpr_grad_clf, tpr_grad_clf, thresholds_grad_clf = roc_curve(y_test, grad_clf.predict_proba(X_test)[:,1])\n\nxgb_clf.fit(X_train, y_train)\nxgb_clf_roc_auc = roc_auc_score(y_test, xgb_clf.predict(X_test))\nfpr_xgb_clf, tpr_xgb_clf, thresholds_xgb_clf = roc_curve(y_test, xgb_clf.predict_proba(X_test)[:,1])\n\nplt.figure()\nplt.plot(fpr_logreg, tpr_logreg, label='LogisticRegression(area = %0.5f)' % logreg_roc_auc)\nplt.plot(fpr_dt, tpr_dt, label='DecisionTreeClassifier(area = %0.5f)' % dt_roc_auc)\nplt.plot(fpr_knn, tpr_knn, label='KNeighborsClassifier(area = %0.5f)' % knn_roc_auc)\nplt.plot(fpr_forest, tpr_forest, label='RandomForestClassifier(area = %0.5f)' % forest_roc_auc)\nplt.plot(fpr_grad_clf, tpr_grad_clf, label='GradientBoostingClassifier(area = %0.5f)' % grad_clf_roc_auc)\nplt.plot(fpr_xgb_clf, tpr_xgb_clf, label='XGBClassifier(area = %0.5f)' % xgb_clf_roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","7775d4c3":"#data_test = pd.read_csv(\"test.csv\",sep=',')\ndata_test = pd.read_csv(\"..\/input\/nida-competition1\/test.csv\", sep=',')\ndata_test['pdays2'] = data_test['pdays']","1c428354":"#Encoding\njob_dict={'admin.':1,'technician':2,'blue-collar':3,'retired':4,'services':5,'management':6,'student':7,'self-employed':8,'unemployed':9,'entrepreneur':10,'housemaid':11,'unknown':12}\ndata_test['job']= data_test['job'].map(job_dict)\n\nmarital_dict={'divorced': 0, 'married': 1, 'single': 2, 'unknown': 3}\ndata_test['marital']= data_test['marital'].map(marital_dict)\n\neducation_dict={'unknown':0, 'illiterate':1, 'basic.4y':2, 'basic.6y':3, 'basic.9y':4, 'high.school':5, 'university.degree':6, 'professional.course':7}\ndata_test['education']= data_test['education'].map(education_dict)\n\ndictionary = {'yes':1,'no':0,'unknown':-1}\ndata_test['housing'] = data_test['housing'].map(dictionary).astype('uint8')\ndata_test['default'] = data_test['default'].map(dictionary).astype('uint8')\ndata_test['loan'] = data_test['loan'].map(dictionary).astype('uint8')\n\ncontact_dict = {'cellular':1,'telephone':0}\ndata_test['contact'] = data_test['contact'].map(contact_dict).astype('uint8')\n\nmonth_dict = {'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12}\ndata_test['month'] = data_test['month'].map(month_dict).astype('uint8')\n\nday_dict = {'sun':1,'mon':2,'tue':3, 'wed':4,'thu':5,'fri':6,'sat':7}\ndata_test['day_of_week'] = data_test['day_of_week'].map(day_dict).astype('uint8')\n\npoutcome_dict = {'nonexistent':-1, 'failure':0, 'success':1}\ndata_test['poutcome'] = data_test['poutcome'].map(poutcome_dict).astype('uint8')\n\ndata_test.loc[data_test['pdays2'] == 999, 'pdays'] = 0   # replace with 0 if not contact\ndata_test.loc[data_test['pdays2'] != 999, 'pdays'] = 1\n\ndisplay(data_test.head())\ndisplay('There is {} observations with {} features'.format(data_test.shape[0], data_test.shape[1]))\n","f66e4f35":"model = grad_clf.fit(X, y)\nfinal_test_proba = model.predict_proba(data_test)","52e1c836":"final_test_proba_yes = final_test_proba[:,1]\nsubmission = pd.DataFrame(final_test_proba_yes)\nsubmission.index = [x for x in range(1, len(submission.values)+1)]\nsubmission.index.name = 'id'\nsubmission.rename(columns={0: \"y\"} , inplace=True)\nsubmission.to_csv(\"31submission_20201115_grad_clfOS_FixedPdays.csv\", index=True)\nsubmission","bb94368b":"### STEP 3 : TRAIN DATA","601fd71f":"### 4.2) Comparison Model by Precision, Recall, f1 Score","f26dac30":"### 2.2) Create New Variable from Pdays grouping by \n    \n    \"999\" = 0 (Not previously contacted)\n    not \"999\" = 1 (Contacted from last campaign)","22343449":"### STEP 4 : Model Selection\n- LogisticRegression\n- DecisionTreeClassifier\n- KNeighborsClassifier\n- RandomForestClassifier\n- GradientBoostingClassifier\n- XGBClassifier","53292190":"# GROUP : ML4","54363bd1":"### SCORE : 0.94770","f3f4feb9":"# xgb_clfOS_send","b6ef6a89":"model = xgb_clf.fit(X, y)\nfinal_test_proba = model.predict_proba(data_test)","d1fa495b":"# grad_clfOS_send","1d686c0d":"### 4.1) Comparison Model by Accuracy Score","ae33363f":"### 3.2) Random Over Sampling","2977d37a":"final_test_proba_yes = final_test_proba[:,1]\nsubmission = pd.DataFrame(final_test_proba_yes)\nsubmission.index = [x for x in range(1, len(submission.values)+1)]\nsubmission.index.name = 'id'\nsubmission.rename(columns={0: \"y\"} , inplace=True)\nsubmission.to_csv(\"32submission_20201111_xgb_clfOS_FixedPdays.csv\", index=True)\nsubmission","5a04d51f":"###### Team Member\n1. 6220422003 Tanakan Wongleelaseth\n2. 6220422014 Kittisak Suputthorn\n3. 6220422067 Srisuda Wongvoraruj\n4. 6220422068 Sirirat Ekhathaikul","a2af322c":"### STEP 2 : DATA CLEANSING","15701c66":"# Test","b16726c8":"### 4.3) Model Comparison by ROC Curve","050afd3e":"### 1.3.) Outlier Exploration","e07cf08a":"### 2.1) Drop duplicated data","c3dd78a9":"### 3.1) Feature Selection by using ExtraTreesClassifier\n- Rondomized decision trees to the data to ensure the model does not overfit the data.","517d7803":"### Trial and Error : \n- Drop outlier and fail (Age, Duration, Campaign)\n- Transform Data Duration from Seconds to Minutes","d974ccc2":"### 1.1.) Explore Deposit Result (Yes\/No) by category\n\nResulting : No = 88.6% \/ Yes = 11.4%","ef0b937e":"### STEP 1 : DATA EXPLORATION","f9165eda":"### 1.2.) Numeric Exploration\n- Convert Deposit Result (Y) : No => 0 \/ Yes => 1\n- Build Correlation Matrix : Duration is the most positive relation with Deposit Result (Y) "}}