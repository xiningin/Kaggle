{"cell_type":{"8c2e1a74":"code","21b6df4f":"code","e39b4d89":"code","ef8ae744":"code","5c19651b":"code","d835d28a":"code","bc278430":"code","1bd549a0":"code","63c2b670":"code","53f95392":"code","111f0d27":"code","e430e747":"code","34333c8f":"code","82431d98":"code","fab24972":"code","2694de47":"code","9e1c3101":"code","549eeb92":"code","7e07cfc8":"code","ebdc431e":"code","c60f5ed5":"markdown","88658da4":"markdown","cc6b8e4d":"markdown","85ea7979":"markdown","21af0267":"markdown","ad703b17":"markdown","ca044144":"markdown","074c3649":"markdown","41487d05":"markdown","748d71db":"markdown","5bd9ff1b":"markdown","28e626cb":"markdown","2408c1cb":"markdown","b2cfba37":"markdown","a794ccb3":"markdown","f8b688b3":"markdown"},"source":{"8c2e1a74":"import tensorflow as tf\nprint(tf.version)","21b6df4f":"# Import Library\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\nfrom PIL import Image\n\nfrom keras import layers\nfrom tensorflow.keras import applications \nfrom keras.applications import MobileNetV2\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.applications.mobilenet_v2 import preprocess_input\nfrom keras.optimizers import Adam\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n\nfrom tqdm import tqdm\nimport time","e39b4d89":"train_df = pd.read_csv('..\/input\/valid-and-test-ta\/x_train_8.csv')\nvalid_df = pd.read_csv('..\/input\/valid-and-test-ta\/x_valid_8.csv')\nprint(train_df.shape)\nprint(valid_df.shape)\ntrain_df.head()","ef8ae744":"train_df['diagnosis'].value_counts()\ntrain_df['diagnosis'].hist()","5c19651b":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(train_df)","d835d28a":"def preprocess_image(image_path, desired_size=224):\n    im = Image.open(image_path)\n    im = im.resize((desired_size, )*2, resample=Image.BILINEAR)\n    \n    return im\n\nN = train_df.shape[0]\nx_train = np.empty((N, 224, 224, 3), dtype=np.float32)\n\nfor i, image_id in enumerate(tqdm(train_df['id_code'])):\n    x_train[i, :, :, :] = preprocess_image(\n        f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_id}.png'\n    )\n\nN = valid_df.shape[0]\nx_val = np.empty((N, 224, 224, 3), dtype=np.float32)\n\nfor i, image_id in enumerate(tqdm(valid_df['id_code'])):\n    x_val[i, :, :, :] = preprocess_image(\n        f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_id}.png'\n    )","bc278430":"y_train = train_df['diagnosis']\ny_val = valid_df['diagnosis']\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)","1bd549a0":"x_train = preprocess_input(x_train)\nx_val = preprocess_input(x_val)","63c2b670":"BATCH_SIZE = 32\n\ndef create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.1,  # set range for random zoom\n        rotation_range = 360,\n        fill_mode='constant',\n        cval=0.,\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n    )\n\n# Using generator\ndata_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2019)","53f95392":"class Metrics(Callback):\n    def on_train_begin(self, logs={}):\n        self.val_kappas = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val, y_val = self.validation_data[:2]\n        \n        y_pred = self.model.predict(X_val)\n        y_pred = np.clip(y_pred,0,4)\n        y_pred = y_pred.astype(int)\n\n        _val_kappa = cohen_kappa_score(\n            y_val,\n            y_pred, \n            weights='quadratic'\n        )\n\n        self.val_kappas.append(_val_kappa)\n\n        print(f\"val_kappa: {_val_kappa:.4f}\")\n        \n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save('model.h5')\n\n        return\n    \nkappa_metrics = Metrics()","111f0d27":"mobilenet = MobileNetV2(\n    alpha = 1.3,\n    weights=None,\n    include_top=False,\n    input_shape=(224,224,3)\n)\n\ndef build_model():\n    model = Sequential()\n    model.add(mobilenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(256))\n    model.add(layers.Dense(256))\n    model.add(layers.Dense(1))\n    \n    model.load_weights('..\/input\/fork-of-diabetic-retinopathy-mobilenetv2-402b11\/model.h5')\n    \n    model.compile(\n        loss='mse',\n        optimizer=Adam(lr=0.0001),\n        metrics=['accuracy']\n    )\n    \n    return model","e430e747":"model = build_model()\nmodel.summary()","34333c8f":"start_time = time.time()\nhistory = model.fit_generator(\n    data_generator,\n    steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n    epochs=200,\n    validation_data=(x_val, y_val),\n    callbacks=[kappa_metrics]\n)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","82431d98":"#plotting accuracies and loss\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()\nhistory_df.to_csv('history.csv', index = False)","fab24972":"#plotting the QWK score\nplt.plot(kappa_metrics.val_kappas)","2694de47":"model.load_weights('model.h5')\nval_pred = model.predict(x_val)\n#clipping the value to range of 0-4, and round it to the nearest integer\ny_val_pred = np.clip(val_pred,0,4).astype(int)","9e1c3101":"labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\ncnf_matrix = confusion_matrix(valid_df['diagnosis'].astype('int'), y_val_pred)\ndf_cm = pd.DataFrame(cnf_matrix, index=labels, columns=labels)\nplt.figure(figsize=(16, 7))\nsns.heatmap(df_cm, annot=True, cmap=\"Blues\")\nplt.show()","549eeb92":"kappa_val = cohen_kappa_score(\n            valid_df['diagnosis'].astype('int'),\n            y_val_pred, \n            weights='quadratic'\n        )\nprint(kappa_val)","7e07cfc8":"valid_data = pd.DataFrame()\nvalid_data['validLabel'] = valid_df['diagnosis']\nvalid_data['validPred'] = val_pred","ebdc431e":"labels = [0,1,2,3,4]\n\n# Iterate through the five airlines\nfor label in labels:\n    # Subset to the airline\n    subset = valid_data[valid_data['validLabel'] == label]\n    \n    # Draw the density plot\n    sns.distplot(subset['validPred'], hist = False, kde = True,\n                 kde_kws = {'linewidth': 3},\n                 label = label)\n    \n# Plot formatting\nplt.legend(prop={'size': 10}, title = 'Kelas')\nplt.title('Density Plot with Multiple Classes')\nplt.xlabel('Prediksi')\nplt.ylabel('Density')","c60f5ed5":"## Evaluation\n\nAfter training phase and already have the model with highest QWK score, we have to evaluate the model performance using confusion matrix to see whether the model is working properly or not","88658da4":"# Model: MobileNetV2\n\nI am using MobileNetV2 architecture in this project. The architecture is adopted from [1], where they choose 1.3 as the width multiplier\/ alpha (MobileNetV2 hyperparameter). They customize the last layer of the model to become 2 dense layer with 256 nodes and 1 nodes output layer. They use regression approach for this problem because diabetic retinopathy severity is an ordinal variables. Linear activation function is used in the output layer.","cc6b8e4d":"# Quadratic Weighted Kappa\n\nQuadratic Weighted Kappa (QWK, the greek letter $\\kappa$), also known as Cohen's Kappa, is the official evaluation metric. For our kernel, we will use a custom callback to monitor the score, and plot it at the end.\n\n## What is Cohen Kappa?\n\nAccording to the [wikipedia article](https:\/\/en.wikipedia.org\/wiki\/Cohen%27s_kappa), we have\n> The definition of $\\kappa$ is:\n> $$\\kappa \\equiv \\frac{p_o - p_e}{1 - p_e}$$\n> where $p_o$ is the relative observed agreement among raters (identical to accuracy), and $p_e$ is the hypothetical probability of chance agreement, using the observed data to calculate the probabilities of each observer randomly seeing each category.\n\nThis metric is used because if we just using accuracy as the metric, it will give spurious results (because the data is imbalance). The QWK is more fit to the problem.","85ea7979":"# Loading Data and Exploration","21af0267":"# Pre-processing","ad703b17":"# Import Library","ca044144":"## Resize Images \nWe will resize the images to 224x224 pixel (MobileNetV2 default input resolution), then create a single numpy array to hold the data (because the data is not too much).","074c3649":"# Diabetic Retinopathy Classification Using MobileNetV2","41487d05":"# Image Generator\n\nUsing Keras ImageDataGenerator to generate the images (x_train\/valid) and its labels (y_train\/valid)","748d71db":"References:\n\n[1] J. Gao, C. Leung and C. Miao, \"Diabetic Retinopathy Classification Using an Efficient Convolutional Neural Network,\" in 2019 IEEE International Conference on Agents (ICA), Jinan, China, 2019, pp. 80-85.","5bd9ff1b":"## Displaying some Sample Images\n\nDisplay the color retinal images with its label as the title","28e626cb":"# ABSTRACT\n\nDeep learning has been proposed as one of the automated solutions for diabetic retinopathy (DR) severity classification problem. However, most of the successful deep learning models are based on large convolutional neural network (CNN) architectures, requiring a vast volume of training data as well as dedicated computational resources. In this study, we used MobileNetV2 architecture, which was considered a small-scale architecture (4.2 million trainable parameters), to perform DR classification task in APTOS 2019 dataset (3662 color retinal images). We used the generic MobileNetV2 pre-trained weights from ImageNet as initialization and implemented data augmentation.","2408c1cb":"## Loading data\n\nLoading the csv data which contains the images file name and its labels. In this project I am using data that already splitted for training and validation.","b2cfba37":"## Creating keras callback for QWK\n\nBecause our main metric in this problem is QWK, we have to make a function that calculate the QWK for every epoch and also saving the model that got the highest score. ","a794ccb3":"# Training & Evaluation","f8b688b3":"## Training\n\nI trained the model with 100 epoch, mean squared error (mse) as the loss function and Adam as the optimizer"}}