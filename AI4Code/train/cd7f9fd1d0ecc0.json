{"cell_type":{"26a27a09":"code","d8ebe215":"code","bd21824e":"code","6d7a7e2d":"code","deb67b61":"code","0090b0ed":"code","bb4ea284":"code","0a253e4e":"code","4b375608":"code","270ae182":"code","b1d0a911":"code","5e06d77c":"code","044691b4":"code","f98eb4b4":"code","ba3c8cea":"code","bb200c76":"code","21e7813f":"code","0a91b8c9":"code","e99c8f77":"code","207c70c9":"code","7feec2e4":"code","80ce9454":"code","bb62d260":"code","ca9f809e":"code","0c3a6ae1":"code","fe5352e6":"code","2ca621f2":"code","284d67ab":"code","b6dec08f":"code","1ac2d6d6":"code","fb1fb278":"code","28ec1203":"markdown","9bc3603f":"markdown","d9ab2435":"markdown","6544bca9":"markdown","0e52e955":"markdown","b88927a5":"markdown","f650f964":"markdown","ec0b502d":"markdown","68a87334":"markdown","450db85d":"markdown","0cec3fe1":"markdown","9e6ae426":"markdown","4bea6655":"markdown","a8071188":"markdown","ea7d08d4":"markdown","7b81f01a":"markdown","94d731f9":"markdown","fcc251d2":"markdown","c4050876":"markdown","3ce9059c":"markdown","dcb79ccd":"markdown"},"source":{"26a27a09":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8ebe215":"import pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nimport matplotlib as mpl\n\ncolors = ['#05445E','#189AB4','#75E6DA','#9DAFB0', '#4D707E', '#56B66B']\n\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right']= False\nmpl.rcParams['axes.spines.left']= False\nmpl.rcParams['axes.spines.bottom'] = True","bd21824e":"data = pd.read_csv(\"\/kaggle\/input\/marketing-data\/marketing_data.csv\")\ndata.sample(5)","6d7a7e2d":"data.columns","deb67b61":"data.info()","0090b0ed":"data.describe()","bb4ea284":"data = data.rename(columns={' Income ' : \"Income\"})","0a253e4e":"# clean income \ndef clean_income(row) : \n    income = re.findall('\\d+,\\d+', row)\n    income = re.sub('\\W', '', income)\n    print(income)\n\n    return income \n\ndef get_age_group(age) : \n    if 18 <= age <= 35 : \n        return 'Millenial' \n    elif 35 < age <= 50 : \n        return 'Gen X'\n    elif 50 < age <= 70 : \n        return 'Boomer'\n    else : \n        return 'Silent'\n\ndata['Age'] = 2020 - data['Year_Birth']\ndata['Income'] = data['Income'].replace('[\\$,]', '', regex=True).astype(float)\ndata['Age Group'] = data['Age'].apply(get_age_group)\ndata['Dt_Customer'] = pd.to_datetime(data['Dt_Customer'])\ndata['Totalchild'] = data['Kidhome'] + data['Teenhome']","4b375608":"col_behavioral = [\n    'MntWines', \n    'MntFruits', \n    'MntMeatProducts', \n    'MntFishProducts', \n    'MntSweetProducts', \n    'MntGoldProds', \n    'NumDealsPurchases', \n    'NumWebPurchases', \n    'NumCatalogPurchases', \n    'NumStorePurchases', \n    'NumWebVisitsMonth', \n    'Recency'\n]\n\ncol_demographics = [\n    'Year_Birth', \n    'Education', \n    'Marital_Status', \n    'Income', \n    'Kidhome', \n    'Teenhome', \n    'Dt_Customer'\n] \n\ncol_psychographics = [\n'AcceptedCmp1', \n'AcceptedCmp2', \n'AcceptedCmp3', \n'AcceptedCmp4', \n'AcceptedCmp5', \n'Response', \n'Complain'\n\n]\n\ncol_geographics = ['Country']\n\ncol_products = [\n'MntWines', \n'MntFruits', \n'MntMeatProducts', \n'MntFishProducts', \n'MntSweetProducts', \n'MntGoldProds'\n]","270ae182":"data.isnull().sum()\n","b1d0a911":"# drop missing value \ndata = data.dropna()","5e06d77c":"# columns to be investigated\ncol_demographics","044691b4":"data.groupby('Marital_Status').count()['ID']","f98eb4b4":"data = data[~data['Marital_Status'].isin(['Absurd', 'Alone', 'YOLO'])]","ba3c8cea":"df = data['ID'].groupby(data['Education']).count()\n\n# Pie chart\n#colors\nexplode = (0.05,0.05,0.05,0.05,0.05)\n \nfig1, ax1 = plt.subplots(figsize=(8, 5))\npatches, texts, autotexts = ax1.pie(df.values, colors = colors, labels=df.index, autopct='%1.1f%%', startangle=90, pctdistance=0.85, explode = explode)\n#draw circle\ncentre_circle = plt.Circle((0,0),0.50,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nfor text in texts:\n    text.set_color('#131313')\nfor autotext in autotexts:\n    autotext.set_color('#131313')\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","bb200c76":"df = data['ID'].groupby(data['Marital_Status']).count()\ndf = df.sort_values()[-5:]\n\n# Pie chart\n#colors\nexplode = (0.05,0.05,0.05,0.05,0.05)\n \nfig1, ax1 = plt.subplots(figsize=(8, 5))\npatches, texts, autotexts = ax1.pie(df.values, colors = colors, labels=df.index, autopct='%1.1f%%', startangle=90, pctdistance=0.85, explode = explode)\n#draw circle\ncentre_circle = plt.Circle((0,0),0.50,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nfor text in texts:\n    text.set_color('#131313')\nfor autotext in autotexts:\n    autotext.set_color('#131313')\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","21e7813f":"fig1, ax = plt.subplots(1, 2, figsize=(16, 5))\n\nsns.kdeplot(data['Age'], ax=ax[0], shade=True, color=colors[0])\n\nax[0].set_title(\"Age Density\", fontsize=14, fontweight='bold')\nax[0].set_ylabel('Density', fontsize=13)\nax[0].set_xlabel('Age', fontsize=13)\nax[0].yaxis.grid(alpha=0.33)\nax[0].set_axisbelow(True)\n\nsns.kdeplot(data['Income'], ax=ax[1], shade=True, color=colors[0])\n\nax[1].set_title(\"Income Density\", fontsize=14, fontweight='bold')\nax[1].set_ylabel('Density', fontsize=13)\nax[1].set_xlabel('Income', fontsize=13)\nax[1].yaxis.grid(alpha=0.33)\nax[1].set_axisbelow(True)","0a91b8c9":"fig, ax = plt.subplots(figsize=(8,6))\n\nsns.boxplot(data['Age'], ax=ax, palette=colors)\n\nax.xaxis.grid(alpha=0.33)\nax.set_axisbelow(True)\n\nax.set_title(\"Age Boxplot\", fontsize=14, fontweight='bold')\nax.set_xlabel('Age', fontsize=13)","e99c8f77":"# remove Age outlier\ndata = data[data['Age'] < 120]","207c70c9":"fig, ax = plt.subplots(figsize=(8,6))\n\nsns.boxplot(data['Income'], ax=ax, palette=colors)\n\nax.xaxis.grid(alpha=0.33)\nax.set_axisbelow(True)\n\nax.set_title(\"Income Boxplot\", fontsize=14, fontweight='bold')\nax.set_xlabel('Income', fontsize=13)","7feec2e4":"# remove Income outlier\ndata = data[data['Income'] < 200000]","80ce9454":"fig, ax = plt.subplots(1, 2, figsize=(14,6))\n\nsns.boxplot(data['Age'], ax=ax[0], palette=colors)\n\nax[0].xaxis.grid(alpha=0.33)\nax[0].set_axisbelow(True)\n\nax[0].set_title(\"Age Boxplot\", fontsize=14, fontweight='bold')\nax[0].set_xlabel('Age', fontsize=13)\n\nsns.boxplot(data['Income'], ax=ax[1], palette=colors)\n\nax[1].xaxis.grid(alpha=0.33)\nax[1].set_axisbelow(True)\n\nax[1].set_title(\"Income Boxplot\", fontsize=14, fontweight='bold')\nax[1].set_xlabel('Income', fontsize=13)","bb62d260":"df = data[col_products]","ca9f809e":"fig, ax = plt.subplots(figsize=(12, 6))\nsns.boxplot(data=df, palette=colors)\n\nax.set_yscale('log')\nax.set_title(\"Products Boxplot\", fontsize=14, fontweight='bold')\nax.set_xlabel('Products Bought', fontsize=13)\nax.set_ylabel('Ammount of Products Purchased (log scaled)', fontsize=13)\nax.yaxis.grid(alpha=0.33)\nax.set_axisbelow(True)","0c3a6ae1":"df = data[col_products].sum()\n\n# Pie chart\n#colors\nexplode = (0.05,0.05,0.05,0.05,0.05,0.05)\n \nfig1, ax1 = plt.subplots(figsize=(8, 5))\npatches, texts, autotexts = ax1.pie(df.values, colors = colors, labels=df.index, autopct='%1.1f%%', startangle=90, pctdistance=0.85, explode = explode)\n#draw circle\ncentre_circle = plt.Circle((0,0),0.50,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nfor text in texts:\n    text.set_color('#131313')\nfor autotext in autotexts:\n    autotext.set_color('#131313')\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","fe5352e6":"df = data['ID'].groupby(data['Age Group']).count()\n# Pie chart\n#colors\nexplode = (0.05,0.05,0.05,0.05)\n \nfig1, ax1 = plt.subplots(figsize=(8, 5))\npatches, texts, autotexts = ax1.pie(df.values, colors = colors, labels=df.index, autopct='%1.1f%%', startangle=90, pctdistance=0.85, explode = explode)\n#draw circle\ncentre_circle = plt.Circle((0,0),0.50,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nfor text in texts:\n    text.set_color('#131313')\nfor autotext in autotexts:\n    autotext.set_color('#131313')\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","2ca621f2":"fig, ax = plt.subplots(figsize=(15, 6))\n\ndf = data[col_products+['Age']]\n\nbins = [18, 35, 50, 70, 150]\n\nlabels = ['Millenial', 'Gen X', 'Boomer', 'Silent']\ndf['Age_Group'] = pd.cut(df.Age, bins=bins, labels=labels)\ndf = df.groupby('Age_Group').sum().reset_index()\ndf.plot(x='Age_Group', y=col_products, kind='bar', ax=ax, color=colors, width=0.8, edgecolor='#131313')\n\nax.set_title(\"Customer Products Behaviour Per Age Group (Total)\", fontsize=14, fontweight='bold')\nax.set_ylabel('Total Products Purchased', fontsize=13)\nax.set_xlabel('Age Group', fontsize=13)\nax.yaxis.grid(alpha=0.33)\nax.set_axisbelow(True)","284d67ab":"fig, ax = plt.subplots(figsize=(15, 6))\n\ndf = data[col_products+['Age']]\n\nbins = [18, 35, 50, 70, 150]\n\nlabels = ['Millenial', 'Gen X', 'Boomer', 'Silent']\ndf['Age_Group'] = pd.cut(df.Age, bins=bins, labels=labels)\ndf = df.groupby('Age_Group').mean().reset_index()\ndf.plot(x='Age_Group', y=col_products, kind='bar', ax=ax, color=colors, width=0.8, edgecolor='#131313')\n\nax.set_title(\"Customer Products Behaviour Per Age Group (Average)\", fontsize=14, fontweight='bold')\nax.set_ylabel('Average Products Purchased', fontsize=13)\nax.set_xlabel('Age Group', fontsize=13)\nax.yaxis.grid(alpha=0.33)\nax.set_axisbelow(True)","b6dec08f":"fig = plt.figure(figsize=(14, 18))\n\ngs = fig.add_gridspec(3, 2) \n\ndf_columns = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\ndf = data\nax = [None for i in range(len(df_columns))]\ncolors = ['#05445E','#189AB4','#75E6DA','#9DAFB0', '#4D707E']\n\nax[0] = fig.add_subplot(gs[0, 0]) \nsns.scatterplot(data=df, x='Income', y='MntWines', hue='Education', ax=ax[0], palette=colors)\n\nax[1] = fig.add_subplot(gs[0, 1]) \nsns.scatterplot(data=df, x='Income', y='MntFruits', hue='Education', ax=ax[1], palette=colors)\n\nax[2] = fig.add_subplot(gs[1, 0]) \nsns.scatterplot(data=df, x='Income', y='MntMeatProducts', hue='Education', ax=ax[2], palette=colors)\n\nax[3] = fig.add_subplot(gs[1, 1]) \nsns.scatterplot(data=df, x='Income', y='MntFishProducts', hue='Education', ax=ax[3], palette=colors)\n\nax[4] = fig.add_subplot(gs[2, 0]) \nsns.scatterplot(data=df, x='Income', y='MntSweetProducts', hue='Education', ax=ax[4], palette=colors)\n\nax[5] = fig.add_subplot(gs[2, 1]) \nsns.scatterplot(data=df, x='Income', y='MntGoldProds', hue='Education', ax=ax[5], palette=colors)\n\n\nfor ix in range(len(df_columns)) : \n    ax[ix].set_title(f\"Customer Purchase Behaviour based on income\", fontsize=13, fontweight='bold')\n    ax[ix].set_ylabel(f'{df_columns[ix]}')\n    ax[ix].yaxis.grid(alpha=0.33)\n    ax[ix].xaxis.grid(alpha=0.33)\n    ax[ix].set_xlabel('Income (Log Scaled)')\n    ax[ix].set_xscale('log')\n    ax[ix].set_axisbelow(True)\n","1ac2d6d6":"df_columns = ['NumStorePurchases', 'NumWebPurchases']\n\nfig, ax = plt.subplots(figsize=(8,6))\ndf = data[df_columns].sum()\nsns.barplot(df.index, df.values, palette=colors, ax=ax, edgecolor='#131313')\n\nax.set_title(\"Where Customer Purchase Goods\", fontsize=14, fontweight='bold')\nax.set_ylabel('Total Products Purchased', fontsize=13)\nax.set_xlabel('Place of Purchases', fontsize=13)\nax.yaxis.grid(alpha=0.7)\nax.set_axisbelow(True)","fb1fb278":"df_columns = ['NumStorePurchases', 'NumWebPurchases']\n\ndf = data[df_columns].groupby(data['Age Group']).mean()\n\nfig, ax = plt.subplots(figsize=(12,6))\n\ndf.T.plot(kind='bar', color=colors, width=0.8, edgecolor='#131313', ax=ax)\n\nax.set_title(\"Where Customer Purchase Goods per Age Group\", fontsize=14, fontweight='bold')\nax.set_ylabel('Average Products Purchased', fontsize=13)\nax.set_xlabel('Place of Purchases', fontsize=13)\nax.yaxis.grid(alpha=0.7)\nax.set_axisbelow(True)\n\n# Shrink current axis by 20%\nbox = ax.get_position()\nax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n\n# Put a legend to the right of the current axis\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","28ec1203":"we can see that there is an anomaly in Age and an outlier in Income, first we are going to investigate further Age column","9bc3603f":"## Are there any null values or outliers? How will you wrangle\/handle them?\n\nlooking at this data, i found that there are several null values in feature \"Income\"\n\nsince we only have 24 rows with missing value, i will just remove those rows","d9ab2435":"### Products\n\nnow we are going to investigate whether there are outlier\/anomalies on Products columns","6544bca9":"### Customer Income Pattern on Market","0e52e955":"now we are going to investigate further our income columns","b88927a5":"To be continued\n","f650f964":"Here we see two anomalies, person with income on range 100.000 to 200.000 and person with income of  600.000 . \n\nWhile the first one is still possible, the second one however it is highly unlikely a person having an income over 600.000$\n\nto solve this problem i decided to drop the people with income over 600.000$","ec0b502d":"# Section 01","68a87334":"## Feature Engineering\n\nLooking at the data there are several column that can we process to create new column\n\n* Age : can be derived fron Year_Birth\n* Age Group : can be derived from Age\n* Totalchild : sum of kidhome and Teenhome\n\nand there are also column that need to be pre-process that is \n* Income : change into float\n* Dt_Customer : change into pandas Datetime","450db85d":"### Customer Generation pattern on the market","0cec3fe1":"Most of Customer buy the product offline rather than online","9e6ae426":"## Preparing the data","4bea6655":"# Exploratory & Statistical Analysis\n\n\n### Task Details\nYou're a marketing analyst and you've been told by the Chief Marketing Officer that recent marketing campaigns have not been as effective as they were expected to be. You need to analyze the data set to understand this problem and propose data-driven solutions.\n\n### Expected Submission\nSubmit a well documented notebook with these three sections:\n\n### Section 01: Exploratory Data Analysis\n* Are there any null values or outliers? How will you wrangle\/handle them?\n* Are there any variables that warrant transformations?\n* Are there any useful variables that you can engineer with the given data?\n* Do you notice any patterns or anomalies in the data? Can you plot them?\n### Section 02: Statistical Analysis\n\nPlease run statistical tests in the form of regressions to answer these questions & propose data-driven action recommendations to your CMO. Make sure to interpret your results * with non-statistical jargon so your CMO can understand your findings.\n\n* What factors are significantly related to the number of store purchases?\n* Does US fare significantly better than the Rest of the World in terms of total purchases?\n* Your supervisor insists that people who buy gold are more conservative. Therefore, people who spent an above average amount on gold in the last 2 years would have more in store purchases. Justify or refute this statement using an appropriate statistical test\n* Fish has Omega 3 fatty acids which are good for the brain. Accordingly, do \"Married PhD candidates\" have a significant relation with amount spent on fish? What other factors are * significantly related to amount spent on fish? (Hint: use your knowledge of interaction variables\/effects)\n* Is there a significant relationship between geographical regional and success of a campaign?\n### Section 03: Data Visualization\nPlease plot and visualize the answers to the below questions.\n\n* Which marketing campaign is most successful?\n* What does the average customer look like for this company?\n* Which products are performing best?\n* Which channels are underperforming?\nEvaluation\n* This is not a formal competition, so results won't be measured using a strict metric. Rather, what one would like to see is a well-defined process of exploratory and statistical analysis with insightful conclusions.\n","a8071188":"Here we detect that there are 3 people with Age anomalies, those people is over than 120 years old! which is highly unlikely. Since it is only 3 people we will solve this problem by drop those 3 people on our data","ea7d08d4":"To make my exploration easier i divided our data into multiple categories that is \n\n* behavioral \n* demographics \n* psychographics \n* geographics \n* products","7b81f01a":"Although if we look at the chart we can see an outlier for every Products, but in my opinion i think it is not a true outlier. We cannot judge all customers to buy an amount of goods that can be said to be \"normal\", for example: a customer may be a merchant who needs a lot of goods\n\nSo in this case i'll leave it as it is","94d731f9":"From this graph we can see that the more Income a person has, the more products that they will buy, the number of products tends to increase exponentially","fcc251d2":"## Do you notice any patterns or anomalies in the data? Can you plot them?","c4050876":"### Offline vs Online Purchases","3ce9059c":"On Marital Status Column, we can see that we have an anomalies. \"Absurd\", \"Alone\" and \"YOLO\" is not a marital status, at least by my understanding. Since the anomalies is responsible for only 7 rows, i decided to drop those rows","dcb79ccd":"Market is more dominated with person on Boomer Generation (43.2%) and Generation X (42.1%)"}}