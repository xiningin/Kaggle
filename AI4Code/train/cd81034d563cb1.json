{"cell_type":{"9aa5bfe8":"code","c5a95be1":"code","38a2f3c7":"code","f8e6d0c3":"code","abb4b303":"code","5831ccdc":"code","e2ddf64d":"code","00dd6d58":"code","33ece47e":"code","c4102269":"code","deef7a58":"code","27f45085":"code","29f56fe3":"code","bc9202ed":"code","e9bcf71f":"markdown","27b8b2c5":"markdown","296ef756":"markdown","536b8df9":"markdown","d2466132":"markdown","4442a0cd":"markdown","571a5415":"markdown","1cf2fd7d":"markdown","c1fa450a":"markdown","38c9fdf5":"markdown","6822843f":"markdown","de22707d":"markdown","eb04eb91":"markdown","782106a5":"markdown"},"source":{"9aa5bfe8":"import os\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n#os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"10\"\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n\nfrom platform import python_version\nimport warnings\nimport time\nimport datetime as dt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport multiprocessing as mp\nimport shutil\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\n\nfrom PIL import Image\nimport xml.etree.ElementTree as ET\nimport psutil\nimport random\n\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\nprint(\"py\", python_version())\nprint(\"tf\", tf.__version__)\nprint(\"keras\", tf.keras.__version__)\nmem = psutil.virtual_memory()\nprint(\"mem\", mem.total\/1024\/1024)\ncpu = mp.cpu_count()\nprint(\"cpu\", cpu)\n\n%system nvidia-smi\n#%system rocm-smi","c5a95be1":"epochs = 5\nbatch_size = 150\ntestsplit = .2\ntargetx = 224\ntargety = 224\nlearning_rate = 0.0001\nclasses = 120\nseed = random.randint(1, 1000)\n\ndata_dir = \"\/kaggle\/input\/images\/Images\/\"\nannotations_dir = \"\/kaggle\/input\/annotations\/Annotation\/\"\ncropped_dir = \"\/kaggle\/working\/cropped\/\"","38a2f3c7":"%system rm -rf $cropped_dir\n%system mkdir $cropped_dir\n\n#this function adapted from https:\/\/www.kaggle.com\/hengzheng\/dog-breeds-classifier\ndef save_cropped_img(path, annotation, newpath):\n    tree = ET.parse(annotation)\n    xmin = int(tree.getroot().findall('.\/\/xmin')[0].text)\n    xmax = int(tree.getroot().findall('.\/\/xmax')[0].text)\n    ymin = int(tree.getroot().findall('.\/\/ymin')[0].text)\n    ymax = int(tree.getroot().findall('.\/\/ymax')[0].text)\n    image = Image.open(path)\n    image = image.crop((xmin, ymin, xmax, ymax))\n    image = image.convert('RGB')\n    image.save(newpath)\n\ndef crop_images():\n    breeds = os.listdir(data_dir)\n    annotations = os.listdir(annotations_dir)\n\n    print('breeds: ', len(breeds), 'annotations: ', len(annotations))\n\n    total_images = 0\n\n    for breed in breeds:\n        dir_list = os.listdir(data_dir + breed)\n        annotations_dir_list = os.listdir(annotations_dir + breed)\n        img_list = [data_dir + breed + '\/' + i for i in dir_list]\n        os.makedirs(cropped_dir + breed)\n\n        for file in img_list:\n            annotation_path = annotations_dir + breed + '\/' + os.path.basename(file[:-4])\n            newpath = cropped_dir + breed + '\/' + os.path.basename(file)\n            save_cropped_img(file, annotation_path, newpath)\n            total_images += 1\n    \n    print(\"total images cropped\", total_images)\n\ncrop_images()","f8e6d0c3":"datagen = ImageDataGenerator(\n        shear_range=0.1,\n        zoom_range=0.1,\n        brightness_range=[0.9,1.1],\n        horizontal_flip=True,\n        validation_split=testsplit,\n        preprocessing_function=preprocess_input\n)\n\ntrain_generator = datagen.flow_from_directory(\n        cropped_dir,\n        target_size=(targetx, targety),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True,\n        seed=seed,\n        subset=\"training\"\n)\n\ntest_generator = datagen.flow_from_directory(\n        cropped_dir,\n        target_size=(targetx, targety),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False,\n        seed=seed,\n        subset=\"validation\"\n)","abb4b303":"img = train_generator.filepaths[np.random.random_integers(low=0, high=train_generator.samples)]\nprint(img)\nimg = mpimg.imread(img)\nplt.imshow(img)","5831ccdc":"checkpoint = ModelCheckpoint('dog_breed_classifier.h5',\n                             monitor='val_accuracy',\n                             save_best_only=True,\n                             verbose=1,\n                             mode='auto',\n                             save_weights_only=False,\n                             period=1)\n\n#https:\/\/github.com\/keras-team\/keras\/issues\/3358\ntensorboard = TensorBoard(log_dir=\".\/logs-\"+dt.datetime.now().strftime(\"%m%d%Y%H%M%S\"),\n                            histogram_freq=0,\n                            batch_size=batch_size,\n                            write_graph=False,\n                            update_freq='epoch')\n\ndef epoch_end(epoch, logs):\n    message = \"End of epoch \"+str(epoch)+\". Learning rate: \"+str(K.eval(model.optimizer.lr))\n    os.system('echo '+message)\n\ndef epoch_begin(epoch, logs):\n    print(\"Learning rate: \", K.eval(model.optimizer.lr))\n    \ndef train_begin(logs):\n    os.system(\"echo Beginning training\")\n\nearlystop = EarlyStopping(monitor='val_accuracy',\n                          min_delta=.0001,\n                          patience=20,\n                          verbose=1,\n                          mode='auto',\n                          baseline=None,\n                          restore_best_weights=True)\n\nreducelr = ReduceLROnPlateau(monitor='val_accuracy',\n                             factor=np.sqrt(.1),\n                             patience=5,\n                             verbose=1,\n                             mode='auto',\n                             min_delta=.0001,\n                             cooldown=0,\n                             min_lr=0.0000001)\n\nlambdacb = LambdaCallback(on_epoch_begin=epoch_begin,\n                          on_epoch_end=epoch_end,\n                          on_batch_begin=None,\n                          on_batch_end=None,\n                          on_train_begin=train_begin,\n                          on_train_end=None)","e2ddf64d":"base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# x = Dropout(rate = .2)(x)\nx = BatchNormalization()(x)\nx = Dense(1280, activation='relu',  kernel_initializer=glorot_uniform(seed), bias_initializer='zeros')(x)\n# x = Dropout(rate = .2)(x)\nx = BatchNormalization()(x)\npredictions = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\noptimizer = Adam(lr=learning_rate)\n# optimizer = RMSprop(lr=learning_rate)\n\nloss = \"categorical_crossentropy\"\n# loss = \"kullback_leibler_divergence\"\n\n","00dd6d58":"for layer in model.layers:\n    layer.trainable = True\n# for layer in model.layers[-2:]:\n#     layer.trainable = True\n\nmodel.compile(optimizer=optimizer,\n              loss=loss,\n              metrics=[\"accuracy\"])\n\nmodel.summary()\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","33ece47e":"%%time\n\nparams = model.fit_generator(generator=train_generator, \n                                steps_per_epoch=len(train_generator), \n                                validation_data=test_generator, \n                                validation_steps=len(test_generator),\n                                epochs=epochs,\n                                callbacks=[reducelr, earlystop, lambdacb, tensorboard, checkpoint])","c4102269":"plt.subplot(1, 2, 1)\nplt.title('Training and test accuracy')\nplt.plot(params.epoch, params.history['accuracy'], label='Training accuracy')\nplt.plot(params.epoch, params.history['val_accuracy'], label='Test accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.title('Training and test loss')\nplt.plot(params.epoch, params.history['loss'], label='Training loss')\nplt.plot(params.epoch, params.history['val_loss'], label='Test loss')\nplt.legend()\n\nplt.show()","deef7a58":"# Randomly test an image from the test set\n\n# model.load_weights('dog_breed_classifier.h5')\n\nimageno=np.random.random_integers(low=0, high=test_generator.samples)\n\nname = test_generator.filepaths[imageno]\nprint(name)\nplt.imshow(mpimg.imread(name))\n\nimg = Image.open(test_generator.filepaths[imageno]).resize((targetx, targety))\nprobabilities = model.predict(preprocess_input(np.expand_dims(img, axis=0)))\nbreed_list = tuple(zip(test_generator.class_indices.values(), test_generator.class_indices.keys()))\n\nfor i in probabilities[0].argsort()[-5:][::-1]: \n    print(probabilities[0][i], \"  :  \" , breed_list[i])","27f45085":"test_generator.reset()\npredictions = model.predict_generator(test_generator, steps=len(test_generator))\ny = np.argmax(predictions, axis=1)\n\nprint('Classification Report')\ncr = classification_report(y_true=test_generator.classes, y_pred=y, target_names=test_generator.class_indices)\nprint(cr)","29f56fe3":"print('Confusion Matrix')\ncm = confusion_matrix(test_generator.classes, y)\ndf = pd.DataFrame(cm, columns=test_generator.class_indices)\nplt.figure(figsize=(80,80))\nsn.heatmap(df, annot=True)","bc9202ed":"shutil.rmtree(cropped_dir)","e9bcf71f":"# Keras callbacks","27b8b2c5":"# Define new top layers and compile model","296ef756":"# Sample image","536b8df9":"# Changelog\n\n## V36 - Updates, works with TF 2.0\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-mobilenet-v2\n\n## V32 - Updates, added Confusion Matrix\/Classification Report\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-mobilenet-v2?scriptVersionId=19440127\n\n## V24 - First working notebook\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-mobilenet-v2?scriptVersionId=16125907\n","d2466132":"# Crop images using provided annotations","4442a0cd":"# Classification report","571a5415":"# Confusion matrix","1cf2fd7d":"# Fit model","c1fa450a":"# Imports","38c9fdf5":"# Training and test loss\/accuracy graphs","6822843f":"# Keras image data readers","de22707d":"# Sample prediction","eb04eb91":"# Variables","782106a5":"# Keras MobileNet V2 transfer learning for the Stanford dogs dataset"}}