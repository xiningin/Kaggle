{"cell_type":{"89dcb9af":"code","9984cf2e":"code","f7e8ccdc":"code","3d84736b":"code","5f4197ec":"code","3f7e0070":"code","1643c225":"code","a2431da2":"code","6d11d579":"code","2b0a0fe9":"code","81e0becb":"code","fec86994":"code","e20ddd38":"code","42c0605d":"code","0e526663":"code","eeae39e9":"code","36041198":"markdown","bcef1984":"markdown","dcef11f6":"markdown","52c03527":"markdown","8771b115":"markdown","ccb32d08":"markdown","dae707df":"markdown","2600f748":"markdown","8a2c476d":"markdown"},"source":{"89dcb9af":"import gc\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score","9984cf2e":"train_features_path = '..\/input\/baseline-features\/train_features.csv'\ntest_features_path = '..\/input\/baseline-features\/test_features.csv'\n\ntrain = pd.read_csv(train_features_path)\ntest = pd.read_csv(test_features_path)","f7e8ccdc":"train = train.sort_values('TransactionDT')\ntest = test.sort_values('TransactionDT')","3d84736b":"import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(1,2, figsize=(16,4))\ntrain.groupby(['TransactionDT'])['TransactionDT'].size().plot(ax=axs[0])\ntest.groupby(['TransactionDT'])['TransactionDT'].size().plot(ax=axs[1])","5f4197ec":"del test\ngc.collect()","3f7e0070":"split_perc = [p*0.01 for p in range(100)]\ny_means_train, y_means_valid = [],[]\nfor p in split_perc:\n    idx = int(p*len(train))\n    y_means_train.append(train['isFraud'][:idx].mean())\n    y_means_valid.append(train['isFraud'][idx:].mean())","1643c225":"fig, ax = plt.subplots(figsize=(16,4))\nax.plot(split_perc, y_means_train, label='train')\nax.plot(split_perc, y_means_valid, label='valid')","a2431da2":"split_perc_df = pd.DataFrame({'perc':split_perc,'train':y_means_train, 'valid':y_means_valid})\nsplit_perc_df['diff'] = abs(split_perc_df['train']-split_perc_df['valid'])\nsplit_perc_df.sort_values('diff').head()","6d11d579":"0.13*len(train), 0.26*len(train)","2b0a0fe9":"def sample_negative_class(train, perc):\n    train_pos = train[train.isFraud==1]\n    train_neg = train[train.isFraud==0].sample(frac=perc)\n    \n    train = pd.concat([train_pos, train_neg], axis=0)\n    train = train.sort_values('TransactionDT')\n    return train","81e0becb":"def fit_predict(train, valid, model_params, training_params):\n    X_train = train.drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n    y_train = train['isFraud']\n\n    X_valid = valid.drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n    y_valid = valid['isFraud']\n    \n    trn_data = lgb.Dataset(X_train, y_train)\n    val_data = lgb.Dataset(X_valid, y_valid)\n\n    clf = lgb.train(model_params, trn_data, \n                    training_params['num_boosting_rounds'], \n                    valid_sets = [trn_data, val_data], \n                    early_stopping_rounds = training_params['early_stopping_rounds'],\n                    verbose_eval=False\n                   )\n    train_preds = clf.predict(X_train, num_iteration=clf.best_iteration)\n    valid_preds = clf.predict(X_valid, num_iteration=clf.best_iteration)\n    return train_preds, valid_preds","fec86994":"idx_split = int(0.74*len(train))\ntrain_split, valid_split = train[:idx_split], train[idx_split:]","e20ddd38":"model_params = {'num_leaves': 256,\n                  'min_child_samples': 79,\n                  'objective': 'binary',\n                  'max_depth': 15,\n                  'learning_rate': 0.05,\n                  \"boosting_type\": \"gbdt\",\n                  \"subsample_freq\": 3,\n                  \"subsample\": 0.9,\n                  \"bagging_seed\": 11,\n                  \"metric\": 'auc',\n                  \"verbosity\": -1,\n                  'reg_alpha': 0.3,\n                  'reg_lambda': 0.3,\n                  'colsample_bytree': 0.9\n                 }\n\ntraining_params = {'num_boosting_rounds':1000,\n                   'early_stopping_rounds':100,\n               }","42c0605d":"train_sample_perc = [p*0.05 for p in range(1,20,1)]\ntrain_scores, valid_scores = [],[]\nfor perc in train_sample_perc:\n    print('processing for perc {}'.format(perc))\n    train_sample = sample_negative_class(train_split, perc)\n    train_preds, valid_preds = fit_predict(train_sample, valid_split, model_params, training_params)\n    \n    train_score = roc_auc_score(train_sample['isFraud'], train_preds)\n    valid_score = roc_auc_score(valid_split['isFraud'], valid_preds)\n    print(perc, train_score, valid_score)\n    train_scores.append(train_score)\n    valid_scores.append(valid_score)","0e526663":"fig, axs = plt.subplots(2,1, figsize=(16,4))\naxs[0].plot(train_sample_perc, train_scores, label='train')\naxs[1].plot(train_sample_perc, valid_scores, label='valid')","eeae39e9":"sample_perc_df = pd.DataFrame({'perc':train_sample_perc,'train':train_scores, 'valid':valid_scores})\nsample_perc_df.sort_values('valid', ascending=False).head()","36041198":"Let's plot train and test by 'TransactionDT'.","bcef1984":"# Imports","dcef11f6":"We can clearly see the time split.","52c03527":"# Loading features\n\nI am using the features from @artgors [EDA and models kernel](https:\/\/www.kaggle.com\/artgor\/eda-and-models).","8771b115":"# Finding a good time split\nSo let's try to decide what should be the proper time split.","ccb32d08":"Okey, it seems that seems that we have a few candidates that have similiar `isFraud` fraction.\nLet's now see what is the difference row-wise in those `0.74` and `0.87` splits.","dae707df":"Ok, it's quite large and the difference in `isFraud` fraction is not, so I will go with the `0.26` of train as my validation set.\n\n# Finding a good train sample\n\nIn imbalanced problems a lot of the times negative samples do not bringing that much to the table from a certain point.\nI want to explore whether I can subsample negative samples from the train (keeping valid as is) and get a similar score on valid.\nBy doing that I can cut down the training time significantly and experiment faster as a result.\n\nLet's implement a simple sampling function:","2600f748":"Now we can go ahead and train on 20 different sample options.","8a2c476d":"Ok, so we can see that the difference in scores from `0.1` to `1.0` of the negative samples is only `0.002`.\nWhat is interesting is that for those larger samples like `0.75` we get a bump which suggest a lot of noise here. \nThis is more of the reason (in my opinion) to experiment with a smaller sample of negatives and from time to time check it\non the entire dataset.\n\nWhat do you think?\n\n**Note**\n\nI will be adding this to the project that I discuss [here](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/100311#latest-578849)."}}