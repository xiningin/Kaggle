{"cell_type":{"e6f383a1":"code","21c7ac92":"code","17cb75b9":"code","df3735d2":"code","7a7a8892":"code","6bf463ab":"code","33a87582":"code","db76cd0f":"code","eb733416":"code","52d365d7":"code","b4a45976":"code","f2b874b3":"code","c8408721":"code","3148814b":"code","e718cddb":"code","c21cbb52":"code","62260ff6":"code","8699a9cf":"code","dbff7e2d":"code","002cac1f":"code","79af207d":"code","576a0349":"code","362140bb":"code","d3550c2d":"code","626b607a":"code","5119d0df":"code","3644c4f0":"code","49cc9f10":"code","2df0fc82":"code","b0018833":"code","2d519892":"code","a86751c7":"code","7ec8ce11":"code","9bd78be0":"code","8107f528":"code","4dd06f12":"code","071a0edd":"code","c92b51ec":"code","0d5c64db":"code","443ceae9":"code","411ca4ef":"code","7c5d3158":"code","bbf79367":"code","dd4fd822":"code","f0aa9b10":"code","f9655a06":"code","75d9e003":"code","fb7c886b":"code","213eed19":"code","85460537":"code","b059033b":"code","0e103d0f":"code","9212bd0e":"code","328bc9f2":"code","eb42c5e8":"code","eef5db2d":"code","2aada1b6":"code","63f4d84e":"code","8202fd90":"code","0e74e6fb":"code","aa003033":"code","6dbb2774":"code","97905f8a":"code","85aef0ca":"code","4d879460":"code","38b45b47":"markdown","125f2360":"markdown","4d35f035":"markdown","ffc28791":"markdown","e12d0e73":"markdown","066f386a":"markdown","0d2e52fe":"markdown","ea2bc3f1":"markdown","cf015b0e":"markdown","4853f656":"markdown","0038ce27":"markdown","f314300b":"markdown","dfc6a17a":"markdown"},"source":{"e6f383a1":"from fastai.tabular import *","21c7ac92":"path = Path('\/kaggle\/input\/covid19-global-forecasting-week-1\/')\npath.ls()","17cb75b9":"import pandas as pd\nsample_submission = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-1\/submission.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-1\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-1\/train.csv\")","df3735d2":"len(train)","7a7a8892":"sample_submission.head()","6bf463ab":"test.head()","33a87582":"train.head()","db76cd0f":"#merge test set and training set and rename, som columns\nFull_data = pd.merge(test, train, on=['Lat','Long','Date','Country\/Region','Province\/State'])\nFull_data.rename(columns={'Province\/State':'Province'}, inplace=True)\nFull_data.rename(columns={'Country\/Region':'Country'}, inplace=True)\nFull_data.rename(columns={'ConfirmedCases':'Confirmed'}, inplace=True)\nFull_data.head()","eb733416":"len(Full_data)","52d365d7":"#rename therefor the data columns\ntrain.rename(columns={'Province\/State':'Province'}, inplace=True)\ntrain.rename(columns={'Country\/Region':'Country'}, inplace=True)\ntrain.rename(columns={'ConfirmedCases':'Confirmed'}, inplace=True)","b4a45976":"#and we do the same for test set\ntest.rename(columns={'Province\/State':'Province'}, inplace=True)\ntest.rename(columns={'Country\/Region':'Country'}, inplace=True)","f2b874b3":"from sklearn.preprocessing import LabelEncoder\n# creating initial dataframe\nbridge_types = ('Lat', 'Date', 'Province', 'Country', 'Long', 'Confirmed',\n       'ForecastId', 'Id')\ncountries = pd.DataFrame(train, columns=['Country'])\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ntrain['Countries'] = labelencoder.fit_transform(train['Country'])\ntrain['Countries'].head()\n","c8408721":"train[\"Date\"] = train[\"Date\"].apply(lambda x: x.replace(\"-\",\"\"))\ntrain[\"Date\"]  = train[\"Date\"].astype(int)","3148814b":"#do the same for test set\ntest['Countries'] = labelencoder.fit_transform(test['Country'])\n\ntest[\"Date\"] = test[\"Date\"].apply(lambda x: x.replace(\"-\",\"\"))\ntest[\"Date\"]  = test[\"Date\"].astype(int)","e718cddb":"train.head()","c21cbb52":"train.isnull().sum()","62260ff6":"#drop useless columns for train and test set\ntrain.drop(['Country'], axis=1, inplace=True)\ntrain.drop(['Province'], axis=1, inplace=True)","8699a9cf":"test.drop(['Country'], axis=1, inplace=True)\ntest.drop(['Province'], axis=1, inplace=True)","dbff7e2d":"#slpit the data set in to from the merge dataframe called Full_data\ntrain_procent=int(((len(Full_data))\/100)*50)\ntest_procent=int(((len(Full_data))\/100)*50)\n\ntrain_df=Full_data.loc[train_procent:]\ntest_df=Full_data.loc[:test_procent]","002cac1f":"len(test_df)","79af207d":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX = train_df.copy()\nX_test_full = test_df.copy()\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['Fatalities'], inplace=True)\ny = X.Fatalities              \nX.drop(['Fatalities'], axis=1, inplace=True)\n   \n    \n    # Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\nlow_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n                        X_train_full[cname].dtype == \"object\"]\n\n# Select numeric columns\nnumeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n### for cname (every value, one at the time) in dataframe for columns return a value to 'numeric_cols' if the \n### dtype= int64 or float64. \n\n\n\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\n\n# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","576a0349":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom xgboost import XGBRegressor\n\n\n\nmodel2 = RandomForestClassifier(n_estimators=150, max_depth=4, random_state=1)\nmodel = GradientBoostingClassifier(random_state=1)\nmodel3 = DecisionTreeClassifier(random_state=1)\n#model=SGDClassifier(random_state=1)\n#model=ExtraTreesClassifier(random_state=1)\nmodel = XGBRegressor()\n# Define the models\nmodel_1 = RandomForestClassifier(n_estimators=50, random_state=0)\nmodel_2 = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel_3 = RandomForestClassifier(n_estimators=200, min_samples_split=20, random_state=0)\nmodel_4 = RandomForestClassifier(n_estimators=300, max_depth=6, random_state=1)\n\n\n\nmodel.fit(X_train, y_train)\ny_predictions = model.predict(X_valid)\n\nprint('model accuracy score',model.score(X_valid,y_valid))","362140bb":"y_test=y_valid\nX_test=X_valid","d3550c2d":"model2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model2.score(X_test, y_test)*100:.3f}%')\nmodel3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model3.score(X_test, y_test)*100:.3f}%')","626b607a":"model_1.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_1.score(X_test, y_test)*100:.3f}%')\nmodel_2.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_2.score(X_test, y_test)*100:.3f}%')\nmodel_3.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_3.score(X_test, y_test)*100:.3f}%')\nmodel_4.fit(X_train,y_train)\nprint(f'Model test accuracy: {model_4.score(X_test, y_test)*100:.3f}%')","5119d0df":"from sklearn.tree import DecisionTreeRegressor  \nregressor = DecisionTreeRegressor(random_state = 0) ","3644c4f0":"#train part 2, start over for having enought rows for the submussion\nx = train[['Lat', 'Long', 'Date','Countries']]\ny1 = train[['Confirmed']]\ny2 = train[['Fatalities']]\nx_test = test[['Lat', 'Long', 'Date','Countries']]","49cc9f10":"x.head()","2df0fc82":"# import numpy as np\n# y1=np.ravel(y1)\n# y1","b0018833":"regressor.fit(x,y1)\npredict_1 = regressor.predict(x_test)\npredict_1 = pd.DataFrame(predict_1)\npredict_1.columns = [\"Confirmed_predict\"]","2d519892":"predict_1.head()","a86751c7":"# y2=np.ravel(y2)","7ec8ce11":"regressor.fit(x,y2)\npredict_2 = regressor.predict(x_test)\npredict_2 = pd.DataFrame(predict_2)\npredict_2.columns = [\"Death_prediction\"]\npredict_2.head()","9bd78be0":"Samle_submission = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-1\/submission.csv\")\nSamle_submission.columns\nsubmission = Samle_submission[[\"ForecastId\"]]","8107f528":"Final_submission = pd.concat([predict_1,predict_2,submission],axis=1)\nFinal_submission.head()","4dd06f12":"Final_submission.columns = ['ConfirmedCases', 'Fatalities', 'ForecastId']\nFinal_submission = Final_submission[['ForecastId','ConfirmedCases', 'Fatalities']]\n\nFinal_submission[\"ConfirmedCases\"] = Final_submission[\"ConfirmedCases\"].astype(int)\nFinal_submission[\"Fatalities\"] = Final_submission[\"Fatalities\"].astype(int)","071a0edd":"Final_submission.head()","c92b51ec":"Final_submission.to_csv(\"submission.csv\",index=False)\nprint('Model ready for submission!')\n\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-1\/test.csv\")\ncomplete_test= pd.merge(test, Final_submission, how=\"left\", on=\"ForecastId\")\ncomplete_test.to_csv('complete_test.csv',index=False)","0d5c64db":"# procs = [FillMissing, Categorify, Normalize]\n\n# dep_var = 'Fatalities'\n# cat_names = ['Country', 'Province']\n# cont_names = ['Long','Lat', 'ForecastId']\n","443ceae9":"# data = (TabularList.from_df(train_df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n#         .random_split_by_pct(0.2, seed=42)\n#         .label_from_df(cols=dep_var)\n#         .add_test(test_df)\n#         .databunch()\n# )","411ca4ef":"# data.show_batch(rows=10)","7c5d3158":"\n# data = (TabularList.from_df(train_df, procs=procs, cont_names=cont_names, cat_names=cat_names)\n#         .split_by_idx(valid_idx=range(int(len(train_df)*0.9),len(train_df)))\n#         .label_from_df(cols=dep_var)\n#         .add_test(TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names, procs=procs))\n#         .databunch())\n# print(data.train_ds.cont_names)\n# print(data.train_ds.cat_names)","bbf79367":"# WE HAVE TO CHANGE ACC. se below reason and code\n\n# [quote=\"stephenjohnson, post:11, topic:33778\"]\n# targs stands for **t** arget **arg** ument **s** \n# It\u2019s the values that are the truth values (the Y values) that are being compared to your model\u2019s predicted values. \n# The accuracy metric above takes two arguments the input (predicted values) and targs (target values) and calculates the accuracy. \n# The error encountered above was due to the fact that the input had Long values but targs had Float values.\n# [\/quote]\n\n\n# def accuracy_1(input:Tensor, targs:Tensor)->Rank0Tensor:\n# #     \u201cCompute accuracy with targs when input is bs * n_classes.\u201d\n#     targs = targs.view(-1).long()\n#     n = targs.shape[0]\n#     input = input.argmax(dim=-1).view(n,-1)\n#     targs = targs.view(n,-1)\n#     return (input==targs).float().mean()\n\n# # So use metrics=accuracy_1","dd4fd822":"# learn = tabular_learner(data, layers=[1000,500],metrics=accuracy,model_dir=\"\/tmp\/model\/\")","f0aa9b10":"#test = TabularList.from_df(train.iloc[800:1000].copy(), cat_names=cat_names, cont_names=cont_names)","f9655a06":"#data = (TabularList.from_df(train, cat_names=cat_names, cont_names=cont_names, procs=procs)\n#                           .split_by_idx(list(range(800,1000)))\n#                           .label_from_df(cols=dep_var)\n#                           .add_test(X_test)\n#                           .databunch())","75d9e003":"#data.show_batch(rows=2)","fb7c886b":"#learn = tabular_learner(data, layers=[200,100], metrics=accuracy)","213eed19":"# learn.fit(5, 1e-2)","85460537":"# learn.lr_find()\n# learn.recorder.plot()","b059033b":"# learn.unfreeze()","0e103d0f":"# stop- learn.fit_one_cycle(20, slice(1e-3))","9212bd0e":"#output = pd.DataFrame({'id': sample_submission.id, 'target': y_predictions})","328bc9f2":"# preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n# pred_prob, pred_class = preds.max(1)","eb42c5e8":"# submission = pd.DataFrame({'id':sample_submission['id'],'target':pred_class})","eef5db2d":"# submission.to_csv('submission-fastai.csv', index=False)","2aada1b6":"# submission.id = submission.id.astype(int)","63f4d84e":"# submission.head()","8202fd90":"# submission.to_csv('my_submission.csv', index=False)","0e74e6fb":"# sample_submission = pd.read_csv('my_submission.csv')","aa003033":"#row = train.iloc[0]","6dbb2774":"#X_test.isnull().sum()","97905f8a":"#y_predictions=learn.predict(X_test)","85aef0ca":"# X_test['bin_0'].fillna(X_test['bin_0'].median(), inplace = True)\n# X_test['bin_1'].fillna(X_test['bin_1'].median(), inplace = True)\n# # X_test['bin_2'].fillna(X_test['bin_2'].median(), inplace = True)\n# X_test['ord_0'].fillna(X_test['ord_0'].median(), inplace = True)\n# X_test['day'].fillna(X_test['day'].median(), inplace = True)\n# X_test['month'].fillna(X_test['month'].median(), inplace = True)","4d879460":"\n#output.to_csv('my_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","38b45b47":"# Train part 1\nSome of the above code was to try to merge data from to csv files. but this cant be used for submission, so we just to a few features in the submission section. but it gives a good idea of what model will predict well.","125f2360":"### Handling dates ","4d35f035":"## Inference","ffc28791":"the above merge an not be used since the data set went from about 17600 to 3400 and the submission samle is about 12000","e12d0e73":"# Tabular models","066f386a":"## Below code is for later use, when I get the API block to work!","0d2e52fe":"# Data prep","ea2bc3f1":"# Label encoding\nlabel encode Date and country","cf015b0e":"# Submission","4853f656":"# training models and predictions","0038ce27":"# Import data","f314300b":"### test set","dfc6a17a":"# Check data"}}