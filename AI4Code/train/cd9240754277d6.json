{"cell_type":{"1c00ada3":"code","4d6d50da":"code","da617fa2":"code","cb5d0bf0":"code","2e5c87fb":"code","dfdea81f":"code","0ca171ff":"code","8411b5f0":"code","d811cf10":"code","9fd5e13a":"code","f2c14c16":"code","fdf7b866":"code","30ed51e4":"code","42fcf315":"code","6e51aa59":"code","acc737e4":"code","084be305":"code","c938c926":"code","72a592ad":"code","d10bc379":"code","cf541fd7":"code","b35f80be":"code","9c28d07e":"code","f8dfcd6d":"code","28a395f0":"code","03642def":"code","857f50f9":"code","06a97dd9":"code","ac0c6908":"code","a6f102f4":"code","8948563b":"code","7d579edd":"code","f7e0b7c5":"code","391f46ff":"code","38609ca8":"code","c92bb71f":"code","ffa2a407":"code","35f474f7":"code","195c3e80":"code","d1191d25":"code","0078c210":"markdown","6798cf79":"markdown","fa6ac6b8":"markdown","a5b459f2":"markdown","bc967cb6":"markdown","da974d57":"markdown","66a9c54e":"markdown","4cc69844":"markdown","c3f97e88":"markdown","9025ef66":"markdown","d4d0a32a":"markdown","1ff0c1c3":"markdown","206edd27":"markdown","e461140d":"markdown","e7314524":"markdown","a673433e":"markdown","a33123d4":"markdown","33d1e269":"markdown","9914d279":"markdown","2a9e5d81":"markdown","4bb20642":"markdown","90865848":"markdown","b02d5c06":"markdown","9f619325":"markdown","2bdf4722":"markdown","82c05434":"markdown","16bbc321":"markdown","097fdb3e":"markdown","facef0f6":"markdown","8b39a236":"markdown","c3d672f2":"markdown"},"source":{"1c00ada3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4d6d50da":"# Typical imports we might use\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline ","da617fa2":"my_data = pd.read_csv('\/kaggle\/input\/fis-pt012120-mod2-project-warmup\/train.csv')","cb5d0bf0":"my_data.head()","2e5c87fb":"my_data.info()","dfdea81f":"#TODO\n\nX = my_data.iloc[:,:-1]\ny = my_data.iloc[:,-1]","0ca171ff":"from sklearn.model_selection import train_test_split\n\n#TODO\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)","8411b5f0":"X_train.head()","d811cf10":"X_train.head()","9fd5e13a":"def get_needed_features(my_dataframe):\n    '''\n    Only keep the features that are needed (get rid of id)\n    Return dataframe without id column\n    '''\n    return my_dataframe.iloc[:,1:]","f2c14c16":"X_train_features = get_needed_features(X_train)\nX_train_features.head()","fdf7b866":"X_train_features.shape","30ed51e4":"X_train_features.head()","42fcf315":"X_train_features.columns","6e51aa59":"def get_numerical_features(my_dataframe):\n    '''\n    Return dataframe with only numerical features.\n    '''\n    columns_to_keep = ['host_id', 'latitude', 'longitude',\n       'minimum_nights', 'number_of_reviews', \n       'reviews_per_month', 'calculated_host_listings_count',\n       'availability_365'\n    ]\n    return my_dataframe[columns_to_keep]","acc737e4":"X_train_numerics = get_numerical_features(X_train_features)\nX_train_numerics.head()","084be305":"def fill_null_values(my_dataframe, train_dataframe):\n    '''\n    '''\n    # Find the medians for each column\n    values_to_fills = {\n        col: train_dataframe[col].median()\n        for col in train_dataframe.columns\n    }\n    \n    # Fill with the medians\n    return my_dataframe.fillna(values_to_fills)","c938c926":"X_train_numerics_filled = fill_null_values(X_train_numerics, X_train_numerics)\nX_train_numerics_filled.head()","72a592ad":"X_train_numerics_filled.info()","d10bc379":"# Note that labels was fixed to be `y_train` instead of `y`\n\nfeatures = X_train_numerics_filled \nlabels = y_train","cf541fd7":"from sklearn.linear_model import LinearRegression\n\n#TODO\n# Note you can add more parameters to sklearn's LinearRegression function\nmy_model = LinearRegression()\nmy_model.fit(features, labels)","b35f80be":"display(my_model.coef_)\ndisplay(my_model.intercept_)","9c28d07e":"my_model.coef_.reshape(-1,1)","f8dfcd6d":"pd.DataFrame(data=my_model.coef_.reshape(1,-1), columns= features.columns)","28a395f0":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(\n            my_model, \n            features,\n            labels,\n            cv=10,\n            scoring=\"neg_mean_squared_error\"\n)\n\nrmse_scores = np.sqrt(-scores)","03642def":"display(rmse_scores)\ndisplay(rmse_scores.mean())\ndisplay(rmse_scores.std())","857f50f9":"y.std()","06a97dd9":"# Note `get_numerical_features` was corrected from the lecture\ntest_set = pd.read_csv('\/kaggle\/input\/fis-pt012120-mod2-project-warmup\/test.csv')\nX_test_final = fill_null_values(\n    get_numerical_features(\n        get_needed_features(test_set)\n    ),\n    X_train_numerics\n)","ac0c6908":"X_test_final.head()","a6f102f4":"X_test_final.head()","8948563b":"y_hat = my_model.predict(X_test_final)","7d579edd":"ids = test_set.id.values.reshape(-1,1)\nprices = y_hat.reshape(-1,1)\nids","f7e0b7c5":"data = np.concatenate((ids,prices),axis=1)\ndf_final = pd.DataFrame(data=data, columns=['id','price'])\ndf_final = df_final.astype({'id': 'int32'})\ndf_final.head()","391f46ff":"df_final.info()","38609ca8":"# File to be submitted\ndf_final.to_csv('submission.csv', index=False)\n# np.savetxt('example.csv',y_hat)","c92bb71f":"import pickle\n\npickle.dump(my_model, open('my_model_simple_sol.pkl','wb'))","ffa2a407":"# Load the model from earlier\nmodel_loaded = pickle.load(open('my_model_pickle.pkl','rb'))","35f474f7":"model_loaded","195c3e80":"import joblib\n\njoblib.dump(my_model, \"my_model.pkl\")","d1191d25":"# Load the model from earlier\nmy_model_loaded = joblib.load(\"my_model.pkl\")","0078c210":"# Model the Data","6798cf79":"## Working with categorical features","fa6ac6b8":"## Dealing with missing values","a5b459f2":"# Before We Begin, Remember DS Life Cycle ","bc967cb6":"## We would likely want to see how features do in making predictions (p-value)","da974d57":"# Data Preparation","66a9c54e":"# Data Cleaning & Feature Engineering","4cc69844":"## If we're satisfied with our model, we can make predictions on the holdout test set","c3f97e88":"## Finalizing your features (and labels)","9025ef66":"## Working with numerical features","d4d0a32a":"## Split your data into train-test sets","1ff0c1c3":"## Observe how well the model makes predictions","206edd27":"If you haven't already, you likely want to check this out here","e461140d":"### k-fold validation","e7314524":"# Note to Save Your Models!","a673433e":"> This is likely where you'd explore your data and think about what would be good features.","a33123d4":"> We use k-fold validation to see how well our model did using just the \"training set\". This effectively creates a new train-validation set for each fold. We can use the RMSE to compare different models or different variations of our models.","33d1e269":"## It's good to observe the model's coefficients & intercepts","9914d279":"## `joblib`","2a9e5d81":"> Now we'll want to train our model with our features. You'll likely do this multiple times, iterating after evaluating the model. But be sure to document your work ([save your model!](#Note-to-Save-Your-Models!))","4bb20642":"## Getting rid of unnecessary features","90865848":"## Separate features from target","b02d5c06":"## Other frameworks to consider","9f619325":"> This comes from our walkthrough on 2020-04-22: [https:\/\/youtu.be\/c5FAOmTavLs](https:\/\/www.youtube.com\/watch?v=c5FAOmTavLs&list=PLVoXE6pv5LIh9Xl_HG-mMKXPCunNyVKSY&index=42)","2bdf4722":"# Evaluate the Model","82c05434":"> I made this section as one since you might go back and forth between these two sections. Organize it in the way that makes sense to you and your work.\n>\n> We want to make functions to do this cleaning and feature engineering since we'll repeat this process on our holdout test set.\n","16bbc321":"> In the future, we will talk about specific frameworks like CRISP-DM **(CRoss-Industry Standard Process for Data Mining)** & OSEMN **Obtain, Scrub, Explore, Model, and iNterpret)**","097fdb3e":"## `pickle`","facef0f6":"Load your data in so we can do the initial final train-test split. (Note some situations you don't do a holdout since you have a test set ready for you).","8b39a236":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Before-We-Begin,-Remember-DS-Life-Cycle\" data-toc-modified-id=\"Before-We-Begin,-Remember-DS-Life-Cycle-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Before We Begin, Remember DS Life Cycle<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Other-frameworks-to-consider\" data-toc-modified-id=\"Other-frameworks-to-consider-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>Other frameworks to consider<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Data Preparation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Separate-features-from-target\" data-toc-modified-id=\"Separate-features-from-target-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>Separate features from target<\/a><\/span><\/li><li><span><a href=\"#Split-your-data-into-train-test-sets\" data-toc-modified-id=\"Split-your-data-into-train-test-sets-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>Split your data into train-test sets<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Data Exploration<\/a><\/span><\/li><li><span><a href=\"#Data-Cleaning-&amp;-Feature-Engineering\" data-toc-modified-id=\"Data-Cleaning-&amp;-Feature-Engineering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Data Cleaning &amp; Feature Engineering<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Getting-rid-of-unnecessary-features\" data-toc-modified-id=\"Getting-rid-of-unnecessary-features-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;<\/span>Getting rid of unnecessary features<\/a><\/span><\/li><li><span><a href=\"#Working-with-numerical-features\" data-toc-modified-id=\"Working-with-numerical-features-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;<\/span>Working with numerical features<\/a><\/span><\/li><li><span><a href=\"#Dealing-with-missing-values\" data-toc-modified-id=\"Dealing-with-missing-values-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;<\/span>Dealing with missing values<\/a><\/span><\/li><li><span><a href=\"#Working-with-categorical-features\" data-toc-modified-id=\"Working-with-categorical-features-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;<\/span>Working with categorical features<\/a><\/span><\/li><li><span><a href=\"#Finalizing-your-features-(and-labels)\" data-toc-modified-id=\"Finalizing-your-features-(and-labels)-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;<\/span>Finalizing your features (and labels)<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Model-the-Data\" data-toc-modified-id=\"Model-the-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Model the Data<\/a><\/span><\/li><li><span><a href=\"#Evaluate-the-Model\" data-toc-modified-id=\"Evaluate-the-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Evaluate the Model<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#It's-good-to-observe-the-model's-coefficients-&amp;-intercepts\" data-toc-modified-id=\"It's-good-to-observe-the-model's-coefficients-&amp;-intercepts-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>It's good to observe the model's coefficients &amp; intercepts<\/a><\/span><\/li><li><span><a href=\"#We-would-likely-want-to-see-how-features-do-in-making-predictions-(p-value)\" data-toc-modified-id=\"We-would-likely-want-to-see-how-features-do-in-making-predictions-(p-value)-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>We would likely want to see how features do in making predictions (p-value)<\/a><\/span><\/li><li><span><a href=\"#Observe-how-well-the-model-makes-predictions\" data-toc-modified-id=\"Observe-how-well-the-model-makes-predictions-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>Observe how well the model makes predictions<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#k-fold-validation\" data-toc-modified-id=\"k-fold-validation-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;<\/span>k-fold validation<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#If-we're-satisfied-with-our-model,-we-can-observe-how-it-does-with-the-holdout-test-set\" data-toc-modified-id=\"If-we're-satisfied-with-our-model,-we-can-observe-how-it-does-with-the-holdout-test-set-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;<\/span>If we're satisfied with our model, we can observe how it does with the holdout test set<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Note-to-Save-Your-Models!\" data-toc-modified-id=\"Note-to-Save-Your-Models!-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Note to Save Your Models!<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#pickle\" data-toc-modified-id=\"pickle-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;<\/span><code>pickle<\/code><\/a><\/span><\/li><li><span><a href=\"#joblib\" data-toc-modified-id=\"joblib-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;<\/span><code>joblib<\/code><\/a><\/span><\/li><\/ul><\/li><\/ul><\/div>","c3d672f2":"# Data Exploration"}}