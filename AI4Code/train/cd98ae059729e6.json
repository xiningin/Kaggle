{"cell_type":{"afce2df1":"code","a0838988":"code","de1e44dd":"code","0d3b9d2e":"code","44c36178":"code","6a1bf1d9":"code","9b5324af":"code","7c437e08":"code","f704f7e8":"code","1ab199ae":"code","de7dcf57":"code","a77ac0e8":"code","f65541ea":"code","4ad7a58b":"markdown","7482af6e":"markdown","9a3478be":"markdown","87d0fe1f":"markdown","2114142a":"markdown","104262b6":"markdown","bc9b24c9":"markdown","293dfe4e":"markdown","90ab06fa":"markdown"},"source":{"afce2df1":"#\n# Notebook configuration\n#\n\nDEVICE            = \"TPU\"  # Any value in [\"TPU\", \"GPU\"]\nSEED              = 8080\nFOLDS             = 5\nFOLD_WEIGHTS      = [1.\/FOLDS]*FOLDS\nBATCH_SIZE        = 256\nEPOCHS            = 5000\nMONITOR           = \"val_loss\"\nMONITOR_MODE      = \"min\"\nES_PATIENCE       = 5\nLR_PATIENCE       = 0\nLR_FACTOR         = 0.5\nEFF_NET           = 3\nEFF_NET_WEIGHTS   = 'noisy-student'\nLABEL_SMOOTHING   = 0.1\nVERBOSE           = 1","a0838988":"!pip install -q efficientnet >> \/dev\/null","de1e44dd":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\nfrom sklearn.model_selection import KFold\nfrom keras.preprocessing.image import ImageDataGenerator","0d3b9d2e":"if DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","44c36178":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain.describe()","6a1bf1d9":"# Getting X data\nX = train.drop(labels=['label'], axis=1)\nX = X.astype('float32')\n\n# Data normalization\nX = X \/ 255\n\n# 2D, 1 channel reshape\nX = X.values.reshape(X.shape[0],28,28,1)\n\n# Padding image so it fits on EfficientNet minimum size (32x32)\nX = np.pad(X, ((0,0), (2,2), (2,2), (0,0)), mode='constant')\n\n# Copying channel so it becomes a 3-channel image (32x32x3), required by EfficientNet\nX = np.squeeze(X, axis=-1)\nX = stacked_img = np.stack((X,)*3, axis=-1)\n\n# Checking shape, it must be (n_images, 32, 32, 3)\nX.shape","9b5324af":"# Getting labels\ny = train['label'].values.astype('float32')\n\n# One-hot encoding labels\ny = tf.keras.utils.to_categorical(y, 10)\n\ny","7c437e08":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntest.describe()","f704f7e8":"# Getting X data\nX_test = test.astype('float32')\n\n# Data normalization\nX_test = X_test \/ 255\n\n# 2D, 1 channel reshape\nX_test = X_test.values.reshape(X_test.shape[0],28,28,1)\n\n# Padding image so it fits on EfficientNet minimum size (32x32)\nX_test = np.pad(X_test, ((0,0), (2,2), (2,2), (0,0)), mode='constant')\n\n# Copying channel so it becomes a 3-channel image (32x32x3), required by EfficientNet\nX_test = np.squeeze(X_test, axis=-1)\nX_test = stacked_img = np.stack((X_test,)*3, axis=-1)\n\n# Checking shape, it must be (n_images, 32, 32, 3)\nX_test.shape","1ab199ae":"# Got this from https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\ndatagen = ImageDataGenerator(\n    featurewise_center=False,              # set input mean to 0 over the dataset\n    samplewise_center=False,               # set each sample mean to 0\n    featurewise_std_normalization=False,   # divide inputs by std of the dataset\n    samplewise_std_normalization=False,    # divide each input by its std\n    zca_whitening=False,                   # apply ZCA whitening\n    rotation_range=10,                     # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.1,                      # Randomly zoom image \n    width_shift_range=0.1,                 # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,                # randomly shift images vertically (fraction of total height)\n    horizontal_flip=False,                 # randomly flip images\n    vertical_flip=False                    # randomly flip images\n)","de7dcf57":"eff_nets = [\n    efn.EfficientNetB0,\n    efn.EfficientNetB1,\n    efn.EfficientNetB2,\n    efn.EfficientNetB3,\n    efn.EfficientNetB4,\n    efn.EfficientNetB5,\n    efn.EfficientNetB6,\n    efn.EfficientNetB7,\n    efn.EfficientNetL2,\n]\n\ndef build_model ():\n    inp = tf.keras.layers.Input(shape=(X.shape[1], X.shape[2], X.shape[3]))\n    oup = eff_nets[EFF_NET](\n        input_shape=(X.shape[1], X.shape[2], X.shape[3]),\n        weights=EFF_NET_WEIGHTS,\n        include_top=False,\n    )(inp)\n    oup = tf.keras.layers.GlobalAveragePooling2D()(oup)\n    oup = tf.keras.layers.Dense(512, activation='linear')(oup)\n    oup = tf.keras.layers.Activation('relu')(oup)\n    oup = tf.keras.layers.Dropout(0.5)(oup)\n    oup = tf.keras.layers.Dense(10, activation='linear')(oup)\n    oup = tf.keras.layers.Activation('softmax')(oup)\n    \n    model = tf.keras.Model (inputs=[inp], outputs=[oup])\n    \n    loss = tf.keras.losses.CategoricalCrossentropy(\n        from_logits=False,\n        label_smoothing=LABEL_SMOOTHING,\n    )\n    \n    opt = tf.keras.optimizers.Nadam(learning_rate=3e-4)\n    \n    model.compile(optimizer=opt,loss=loss,metrics=['acc'])\n    \n    return model\n\nbuild_model().summary()","a77ac0e8":"%%time\n\n# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\n\noof   = np.zeros((X.shape[0], y.shape[1]))\npreds = np.zeros((X_test.shape[0], y.shape[1]))\n\nskf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n\nfor fold,(idxT,idxV) in enumerate(skf.split(X)):\n\n    if DEVICE=='TPU':\n        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n            \n    print('#'*25)\n    print('### FOLD %i'%(fold+1))\n    print('#'*25)\n    \n    K.clear_session()\n    with strategy.scope():\n        model = build_model()\n        \n    weights_filename='fold-%i.h5'%fold\n        \n    # Save best model for each fold\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        weights_filename, monitor=MONITOR, verbose=VERBOSE, save_best_only=True,\n        save_weights_only=True, mode=MONITOR_MODE, save_freq='epoch')\n\n    # Learning rate reduction\n    lrr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=MONITOR,\n        factor=LR_FACTOR,\n        patience=LR_PATIENCE,\n        verbose=VERBOSE,\n        mode=MONITOR_MODE\n    )\n    \n    # Early stopping\n    es = tf.keras.callbacks.EarlyStopping(\n        monitor=MONITOR,\n        patience=ES_PATIENCE,\n        verbose=VERBOSE,\n        mode=MONITOR_MODE,\n    )\n    \n    # Datagen workaround\n    print ('Generating train data...')\n    i = 0\n    datagen.fit(X[idxT])\n    steps = 2 * (X[idxT].shape[0] \/\/ BATCH_SIZE)\n    X_train = None\n    y_train = None\n    with tqdm(total=steps) as pbar:\n        for arr in datagen.flow(X[idxT], y[idxT], batch_size=BATCH_SIZE):\n            if X_train is None:\n                X_train = arr[0]\n                y_train = arr[1]\n            else:\n                X_train = np.concatenate((X_train, arr[0]))\n                y_train = np.concatenate((y_train, arr[1]))\n            i += 1\n            pbar.update(1)\n            if i >= steps:\n                break\n                \n#     # Class weights\n#     w = 1 \/ np.sum(y_train, axis=0)\n#     w *= 1 \/ np.min(w)\n#     cw = {\n#         np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) : w[0]\n#     }\n    \n    # Train\n    print('Training...')\n    history = model.fit(\n        X_train,\n        y_train,\n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        callbacks = [\n            sv,\n            lrr,\n            es,\n        ],\n        validation_data=(\n            X[idxV], y[idxV]\n        ),\n        verbose=VERBOSE,\n#         class_weight = { 0: 1, 1: 56 }\n    )\n\n    print('Loading best model...')\n    model.load_weights('fold-%i.h5'%fold)\n    \n    print('Predicting OOF...')\n    oof[idxV,] = model.predict([X[idxV]],verbose=VERBOSE)\n    \n    print('Predicting Test...')\n    preds += (model.predict([X_test], verbose=VERBOSE) * FOLD_WEIGHTS[fold])\n\n    acc_sum = 0\n    for k in idxV:\n        if np.argmax(oof[k]) == np.argmax(y[k]):\n            acc_sum += 1\n    print('>>>> FOLD {} Accuracy = {:.4f}%'.format(fold+1,acc_sum\/len(idxV)*100))\n    print()","f65541ea":"# Getting predictions output on the demanded format\nfinal_predictions = pd.Series(np.argmax(preds, axis=1), name=\"Label\")\n\n# Generating dataframe on the demanded format\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),final_predictions], axis=1)\n\n# Saving file\nsubmission.to_csv(\"submission.csv\",index=False)\n\n# Printing few samples\nsubmission.head()","4ad7a58b":"### TODO:\n* Add class_weight","7482af6e":"# Submitting predictions\n\nOn this section, we'll just use `argmax` for getting the predictions from an array `[0.1 0.01 0.3 ... 0.85]` to an integer `0 .. 9` and then generate the CSV file we'll submit.","9a3478be":"# Building model\n\nHere is where you can edit the model to your needs. For this notebook, I'll just use a simple head above the EfficientNet model. In my (very short) experience, adding too much above a pre-trained model tends to underfit the last layers and then get worse results.","87d0fe1f":"# Notebook configuration\n\nOn this section you'll fill the desired configuration as you wish. These are the attributes available:\n\n* DEVICE: \"TPU\" or \"GPU\". If you leave it as \"TPU\", it will check for its availability and, if not available, will switch to GPU. If GPU is not available either, will work with CPU. Please enable your desired Accelerator on your Kaggle notebook settings.\n* SEED: the random seed for K-Fold (can be any integer)\n* FOLDS: number of folds (K)\n* BATCH_SIZE: number of training samples used in one iteration\n* EPOCHS: max number of epochs the model will train\n* MONITOR: which variable to monitor for setting up callbacks\n* MONITOR_MODE: \"min\" will trigger when MONITOR is lower than previous. \"max\" is the opposite. \"auto\" will choose at runtime\n* ES_PATIENCE: number of epochs the EarlyStopping will wait for MONITOR_MODE to trigger. If it doesn't trigger, training will stop\n* LR_PATIENCE: number of epochs the ReduceLROnPlateu will wait for MONITOR_MODE to trigger. If it doesn't trigger, the learning rate will be reduced by LR_FACTOR\n* LR_FACTOR: constant for multiplication of learning rate\n* EFF_NET: which EfficientNet you'd like to use. Choose from 0 to 8. 0 is EfficientNetB0, 1 is EfficientNetB1, and so on. 8 is EfficientNetL2\n* EFF_NET_WEIGHTS: which weights to use for fine tuning. \"imagenet\" and \"noisy-student\" are available\n* LABEL_SMOOTHING: regularization parameter. 0 is default\n* VERBOSE: verbose of printing: 0 for no printing, 1 for debugging, 2 for commiting","2114142a":"# Augmenting data\n\nOne smart move for datasets with low amount of data is to augment it. Here, I'll use keras `ImageDataGenerator`, as shown on one of Chris' notebooks on this competition and [here](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6)","104262b6":"# Training\n\nThis is the training part. Here, for each fold, we'll train the model until EarlyStopping tells us to stop or EPOCHS is reached. Then, we'll predict on the validation set, compute its accuracy (sanity check) and then predict the full test set, multiplying each fold with its weights.\n\nPS: There's a workaround I've implemented because of [this issue](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/34346) with TPUs.","bc9b24c9":"# Initial setup\n\nHere we'll install EfficientNet dependencies and setup our enviroment according to DEVICE chosen","293dfe4e":"# Loading data\n\nHere we'll load train and test data, converting it to a float32 np array and then few pre-processing:\n\n* Normalize X data;\n* Padding the images so they fit EfficientNet minimum size (32x32);\n* Triple X data so it becomes a 3-channel (could be RGB, but our image has a single color) image, required by EfficientNet;\n* Hot-encode y data so we can use a 10-node softmax output layer on our neural network.","90ab06fa":"# Introduction\n\nOn this notebook I'll try to share some things I've learned here on Kaggle, keeping it as simple as possible. Much of my work here is inspired on @cdeotte's notebooks, you can see that very clear.\n\nAnother great inspiration for this was [Alexander's notebook](https:\/\/www.kaggle.com\/ateplyuk\/tpu-tensor-processing-unit-mnist-efficientnet), but I wanted to add few more features as:\n\n* Cross validation (K-Fold)\n* Data augmentation\n* Some kind of ensemble using folds, as Chris does on his public notebooks\n* Keras callbacks (EarlyStopping, ModelCheckpoint, ReduceLROnPlateu)\n* Training with class weights\n* Using EfficientNet models\n* \"Noisy student\" weights\n\nFew of these features are still missing (you can see that on the TODO list below), but I intend to implement it ASAP."}}