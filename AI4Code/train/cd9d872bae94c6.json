{"cell_type":{"cc446aea":"code","63b9219c":"code","f49a9892":"code","98bfbd8f":"code","c4ee0010":"code","c241c179":"code","258811fd":"code","889c5e51":"code","72be4cfa":"code","b114f9cc":"code","c5061ae5":"code","435ce67d":"code","69743464":"code","bea16bd3":"code","ed957d28":"code","1b197840":"code","64ddc6f7":"code","d8a8dcd6":"code","20e643d7":"code","20baafca":"code","bf9abd7a":"code","5ba47fd2":"code","518864d4":"code","7a240997":"code","6a5119ff":"code","f6aa7a8b":"code","9cd8ad30":"code","ad5702d3":"code","872c6ac8":"code","d0d3b230":"code","38d00998":"code","4b3a44d1":"code","62306de0":"code","3e4f93da":"code","14f04f6a":"code","5af8332e":"code","94c71fa0":"code","792b95a7":"code","09852013":"code","07467b5e":"code","26ba7c83":"code","48392596":"code","e8a2db58":"code","421b7f3a":"code","53d0e8ec":"code","92d55951":"code","36a57684":"code","c2e39de8":"code","c405ada6":"code","a35ed949":"markdown","2a026519":"markdown","3690ea76":"markdown","54015483":"markdown","edd6835c":"markdown","59f6d4f8":"markdown","42b2b440":"markdown","3e0435f0":"markdown","c17dfdf7":"markdown","0a504eea":"markdown","baa03eda":"markdown","507de7d2":"markdown"},"source":{"cc446aea":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\n# statistics tools\nimport scipy.stats as stats\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.estimators import H2OGradientBoostingEstimator","63b9219c":"# load data \/ preview\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\ndf_sub = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')","f49a9892":"df_train.describe()","98bfbd8f":"df_test.describe()","c4ee0010":"n_train = df_train.shape[0]\ndf_train.shape","c241c179":"n_test = df_test.shape[0]\ndf_test.shape","258811fd":"# plot target\nplt.figure(figsize=(12,4))\ndf_train.loss.plot(kind='hist', bins=25)\nplt.title('Target - Histogram')\nplt.grid()\nplt.show()","889c5e51":"# categorical plot of target\nplt.figure(figsize=(12,4))\ndf_train.loss.value_counts().sort_index().plot(kind='bar')\nplt.title('Target - Discrete Distribution')\nplt.grid()\nplt.show()","72be4cfa":"# features\nfeatures = df_test.columns\nfeatures = features.drop('id')\nfeatures = features.to_list()","b114f9cc":"# evaluate correlations with target\ncorr_stats = pd.DataFrame(data=features, columns=['feature'])\ncorr_stats['corr_pearson'] = np.zeros(len(features))\ncorr_stats['corr_spearman'] = np.zeros(len(features))\n\ni = 0\nfor f in features:\n    c = df_train[f].corr(df_train.loss, method='pearson')\n    c = np.round(c,4)\n    corr_stats.loc[i,'corr_pearson'] = c\n    c = df_train[f].corr(df_train.loss, method='spearman')\n    c = np.round(c,4)    \n    corr_stats.loc[i,'corr_spearman'] = c\n    i=i+1","c5061ae5":"# show top correlations (positive)\ncorr_stats.nlargest(10, columns='corr_pearson')","435ce67d":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Feature 13': df_train.f13, \n                        'Target': df_train.loss})\nsns.jointplot(data=df_temp, x='Feature 13', y='Target',\n              kind='reg',\n              joint_kws={'line_kws':{'color':'magenta'}, \n                         'scatter_kws': {'alpha': 0.05}})\nplt.show()","69743464":"# show top correlations (negative)\ncorr_stats.nsmallest(10, columns='corr_pearson')","bea16bd3":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Feature 25': df_train.f25, \n                        'Target': df_train.loss})\nsns.jointplot(data=df_temp, x='Feature 25', y='Target',\n              kind='reg',\n              joint_kws={'line_kws':{'color':'magenta'}, \n                         'scatter_kws': {'alpha': 0.05}})\nplt.show()","ed957d28":"# define target\ntarget = 'loss'","1b197840":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","64ddc6f7":"# upload data in H2O environment\nt1 = time.time()\ntrain_hex = h2o.H2OFrame(df_train)\ntest_hex = h2o.H2OFrame(df_test)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","d8a8dcd6":"# define GLM\nn_cv = 5\n\nglm_model = H2OGeneralizedLinearEstimator(family = 'tweedie',\n                                          tweedie_variance_power = 1.5,\n                                          nfolds = n_cv,\n                                          alpha = 0, \n                                          # 0: Ridge (L2), 1: LASSO (L1)                                          \n                                          lambda_search = True,\n                                          score_each_iteration = True,                                          \n                                          seed=12345)","20e643d7":"# train model\nt1 = time.time()\nglm_model.train(features, target, training_frame = train_hex)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","20baafca":"# show model details\nglm_model","bf9abd7a":"# variable importance\nglm_model.varimp_plot(25)","5ba47fd2":"# predict on training data\npred_train_glm = glm_model.predict(train_hex)\ny_train_act = train_hex.as_data_frame()[target].values # actuals\ny_train_pred_glm = pred_train_glm.as_data_frame().predict.values # predictions","518864d4":"# plot distribution of predictions\nplt.hist(y_train_pred_glm, bins=100)\nplt.title('Predictions on Training Data - GLM')\nplt.grid()\nplt.show()","7a240997":"# plot predictions vs actual (training)\nfig = plt.figure(figsize=(6,6))\nax = fig.add_subplot(111)\nax.scatter(x=y_train_act, y=y_train_pred_glm, alpha=0.1)\nax.plot([0,45],[0,45], color='green')\nax.set_aspect(1)\nplt.grid()\nplt.title('Prediction GLM vs Actual - Training Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","6a5119ff":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Actual': y_train_act, \n                        'Prediction GLM': y_train_pred_glm})\nsns.jointplot(data=df_temp, x='Actual', y='Prediction GLM',\n              kind='reg',\n              joint_kws={'line_kws':{'color':'magenta'}, \n                         'scatter_kws': {'alpha': 0.1}})\nplt.show()","f6aa7a8b":"# yet another viz\nsns.jointplot(data=df_temp, x='Actual', y='Prediction GLM',\n              kind='kde')\nplt.show()","9cd8ad30":"# correlations\nprint('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred_glm))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred_glm))","ad5702d3":"# metrics on training data\nprint('MAE (train):', np.round(mean_absolute_error(y_train_act, y_train_pred_glm),4))\nprint('RMSE(train):', np.round(np.sqrt(mean_squared_error(y_train_act, y_train_pred_glm)),4))","872c6ac8":"# trivial benchmark for comparison: use simple mean of target\nm = y_train_act.mean()\nRMSE_train_trivial = np.sqrt(np.dot(y_train_act-m,y_train_act-m)\/n_train)\nprint('RMSE(train,trivial model):', np.round(RMSE_train_trivial,4))","d0d3b230":"# predict on test data\npred_test_glm = glm_model.predict(test_hex).as_data_frame()\ny_test_pred_glm = pred_test_glm.predict.values # predictions","38d00998":"pred_test_glm.predict.describe()","4b3a44d1":"# fill submission\ndf_sub_glm = df_sub.copy()\ndf_sub_glm.loss = y_test_pred_glm\ndf_sub_glm","62306de0":"# and save result\ndf_sub_glm.to_csv('submission_GLM.csv', index=None)","3e4f93da":"n_cv = 5\n\ngbm_model = H2OGradientBoostingEstimator(distribution = 'tweedie',\n                                         tweedie_power = 1.5,\n                                         ntrees = 50,\n                                         nfolds=n_cv,\n                                         max_depth=9,\n                                         min_rows=5,\n                                         learn_rate=0.1, # default: 0.1\n                                         sample_rate=1,\n                                         col_sample_rate=0.7,\n                                         score_each_iteration=True,\n                                         stopping_metric='RMSE',\n                                         stopping_rounds=5,\n                                         stopping_tolerance=0.0001, # default 0.001\n                                         seed=999)","14f04f6a":"# train model\nt1 = time.time()\ngbm_model.train(features, target, training_frame = train_hex)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","5af8332e":"# show cross validation metrics\ngbm_model.cross_validation_metrics_summary()","94c71fa0":"# show scoring history - training vs cross validations\nfor i in range(n_cv):\n    cv_model_temp = gbm_model.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [RMSE]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_rmse, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_rmse, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.legend()\n    plt.grid()\n    plt.show()","792b95a7":"# variable importance\ngbm_model.varimp_plot(25)","09852013":"# predict on training data\npred_train_gbm = gbm_model.predict(train_hex)\ny_train_act = train_hex.as_data_frame()[target].values # actuals\ny_train_pred_gbm = pred_train_gbm.as_data_frame().predict.values # predictions","07467b5e":"# plot distribution of predictions\nplt.hist(y_train_pred_gbm, bins=100)\nplt.title('Predictions on Training Data - GBM')\nplt.grid()\nplt.show()","26ba7c83":"# plot predictions vs actual (training)\nfig = plt.figure(figsize=(6,6))\nax = fig.add_subplot(111)\nax.scatter(x=y_train_act, y=y_train_pred_gbm, alpha=0.1)\nax.plot([0,45],[0,45], color='green')\nax.set_aspect(1)\nplt.grid()\nplt.title('Prediction GBM vs Actual - Training Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","48392596":"# scatter plot with regression line\ndf_temp = pd.DataFrame({'Actual': y_train_act, \n                        'Prediction GBM': y_train_pred_gbm})\nsns.jointplot(data=df_temp, x='Actual', y='Prediction GBM',\n              kind='reg',\n              joint_kws={'line_kws':{'color':'magenta'}, \n                         'scatter_kws': {'alpha': 0.1}})\nplt.show()","e8a2db58":"# yet another viz\nsns.jointplot(data=df_temp, x='Actual', y='Prediction GBM',\n              kind='kde')\nplt.show()","421b7f3a":"# correlations\nprint('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred_gbm))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred_gbm))","53d0e8ec":"# metrics on training data\nprint('MAE (train):', np.round(mean_absolute_error(y_train_act, y_train_pred_gbm),4))\nprint('RMSE(train):', np.round(np.sqrt(mean_squared_error(y_train_act, y_train_pred_gbm)),4))","92d55951":"# predict on test data\npred_test_gbm = gbm_model.predict(test_hex).as_data_frame()\ny_test_pred_gbm = pred_test_gbm.predict.values # predictions","36a57684":"pred_test_gbm.predict.describe()","c2e39de8":"# fill submission\ndf_sub_gbm = df_sub.copy()\ndf_sub_gbm.loss = y_test_pred_gbm\ndf_sub_gbm","c405ada6":"# and save result\ndf_sub_gbm.to_csv('submission_GBM.csv', index=None)","a35ed949":"<a id='3'><\/a>\n# Fit Linear Model","2a026519":"#### Ok, we see pretty weak correlations with the target! We cannot expect a really good model here...","3690ea76":"<a id='5'><\/a>\n# Build GLM Submission","54015483":"<a id='7'><\/a>\n# Evaluate GBM Model on Training Data","edd6835c":"# Tabular Playground August - Regression using Tweedie loss function\n## Table of Contents\n* [Import Data \/ First Glance](#1)\n* [EDA](#2)\n* [Fit Linear Model](#3)\n* [Evaluate GLM Model on Training Data](#4)\n* [Build GLM Submission](#5)\n* [Fit GBM Model](#6)\n* [Evaluate GBM Model on Training Data](#7)\n* [Build GBM Submission](#8)","59f6d4f8":"### GLM\/Tweedie - Public LB: 7.93925","42b2b440":"<a id='8'><\/a>\n# Build GBM Submission","3e0435f0":"<a id='2'><\/a>\n# EDA","c17dfdf7":"#### Well, it seems that there is not really much signal in the data...","0a504eea":"<a id='6'><\/a>\n# Fit GBM Model","baa03eda":"<a id='4'><\/a>\n# Evaluate GLM Model on Training Data","507de7d2":"<a id='1'><\/a>\n# Import Data \/ First Glance"}}