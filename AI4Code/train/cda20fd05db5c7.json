{"cell_type":{"d49352a6":"code","d0fb3cd5":"code","b31adefb":"code","2f18a88c":"code","9a757b9c":"code","57a58cab":"code","d5c99eb6":"code","368d8e84":"code","dd5b7f52":"code","5c9dbd87":"code","fa853f42":"code","c4d68ea3":"code","59497872":"code","b15c7b57":"code","24f57dc9":"code","1be16342":"code","176dd783":"code","630ce635":"code","dd21f8b5":"code","cd1fac11":"code","d4bfacc0":"code","0a5a4392":"code","12aa4c4c":"code","f7dbb697":"code","d656f4da":"code","82bfb170":"code","da8c779f":"code","72d146f0":"code","b55c98e5":"code","440b1e4f":"code","ca5b4270":"code","efa94eff":"code","853d297d":"code","87fe5e8e":"code","9bd03f8f":"code","56a1d48d":"code","d0fc10e3":"code","3bd36344":"code","0303b544":"code","e0838fa0":"code","20549efc":"code","bfb29950":"code","f2b42cf3":"code","a62a44e8":"code","da78df4b":"code","37837860":"code","7e2c559f":"code","b4df57cd":"code","05720661":"code","0ca3cc30":"code","c3f6d027":"code","65483daa":"code","a04a48c4":"code","6380224f":"code","005610ff":"code","0212a3d0":"code","87f4fbda":"code","e647d5e6":"code","b5591a6d":"code","fdd46588":"code","a6a56477":"code","86e70c0c":"code","4f47fcf2":"code","eb7622c4":"code","5d2516b2":"code","d3cc2888":"code","c9187cca":"code","fea19ad7":"code","98ce4463":"code","5e7547a3":"code","da2e8ef5":"code","bfd8ec6f":"code","1fd2f684":"code","30e8c47a":"code","8a40d64d":"code","98146dc3":"code","a9dd1f9d":"code","71fd43a2":"code","6548f46c":"code","fbe0f87a":"code","500a133b":"markdown","8df072c1":"markdown","ed1ee954":"markdown","1eb905c6":"markdown","4da757bf":"markdown","7b56d4d4":"markdown","e41a9be9":"markdown","6a345e1c":"markdown","4947f347":"markdown","45f5193b":"markdown","a4bcf458":"markdown","5690fa64":"markdown","6ba04452":"markdown","37c32250":"markdown","f4ce3ac3":"markdown","44cd7228":"markdown","bdfface8":"markdown","92d402dd":"markdown","225f0a57":"markdown","50f15de4":"markdown","1d71e6ea":"markdown","e2d7733a":"markdown"},"source":{"d49352a6":"import os\nimport zipfile\nimport pandas as pd\nimport numpy as np\n#import time\n#import geopy\n#from geopy import distance\n\nimport random\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport math\nfrom math import sqrt\n\nimport pickle\n\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt\nimport folium","d0fb3cd5":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', -1)\n\npd.set_option('mode.chained_assignment','raise')","b31adefb":"# os.chdir(\"C:\/Users\/...\")\n    ","2f18a88c":"def read_files(chunks = 1100, chunk_no = None):\n    random.seed(42)\n\n    nrows = int( 55423857 \/ chunks )\n\n    def skiprows(x): # This can do true random selection from the dataset. Useful for development if the data set was sorted.\n        if x == 0:\n            return False\n        return chunk_no != random.randrange(chunks)\n\n    df = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/train.csv', nrows = nrows, parse_dates=[\"pickup_datetime\"])\n        \n#    with zipfile.ZipFile('all.zip') as zipf: \n#         with zipf.open('train.csv') as myZip:\n#             if chunk_no == None:\n#                 df = pd.read_csv(myZip,nrows=nrows,parse_dates=[\"pickup_datetime\"])\n#             else:\n#                 df = pd.read_csv(myZip,skiprows=skiprows,parse_dates=[\"pickup_datetime\"])\n\n    random.seed(42)\n    df = df.sample(frac=1).reset_index(drop=True) #Random reshuffle\n    \n    df_test = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/test.csv', nrows = nrows, parse_dates=[\"pickup_datetime\"])\n                \n#    with zipfile.ZipFile('all.zip') as zipf: \n#        with zipf.open('test.csv') as myZip:\n#            df_test = pd.read_csv(myZip,parse_dates=[\"pickup_datetime\"])\n                \n    return df, df_test","9a757b9c":"chunks = 500 # Run chunks = 1 for real, accurate results.  ","57a58cab":"df,df_test = read_files(chunks)\nprint(\"Data loaded...\")","d5c99eb6":"df.head()","368d8e84":"df.describe()","dd5b7f52":"df_test.head()","5c9dbd87":"def calculate_distance(data):\n    \n# https:\/\/stackoverflow.com\/questions\/19412462\/getting-distance-between-two-points-based-on-latitude-longitude\n    for df in data:\n        R=6371.0\n        pi=math.pi\n\n        sa = math.sin(-30.*pi\/360.)\n        ca = math.cos(-30.*pi\/360.)\n\n        # Wikipedia NYC\n        # 40.7127, -74.0059\n\n        df_tmp = df.eval(\"\"\"\n        lat1 = @pi \/ 180. * pickup_latitude\n        lon1 = @pi \/ 180. * pickup_longitude\n        lat2 = @pi \/ 180. * dropoff_latitude\n        lon2 = @pi \/ 180. * dropoff_longitude\n\n        dlon = lon2 - lon1\n        dlat = lat2 - lat1\n\n        a = sin(dlat \/ 2)**2 + cos(lat1) * cos(lat2) * sin(dlon \/ 2)**2\n        c = 2 * arctan2(sqrt(a), sqrt(1 - a))\n\n        distance = @R * c\n        \n        ty1 = (pickup_latitude - 40.7127) * 30.77915051090274   #y\n        tx1 = (pickup_longitude + 74.0059) * 111.60876733592401 #x\n        ty2 = (dropoff_latitude - 40.7127) * 30.77915051090274\n        tx2 = (dropoff_longitude + 74.0059) * 111.60876733592401 \n        \n        x1 = tx1 * @ca - ty1 * @sa\n        y1 = ty1 * @ca + tx1 * @sa\n        x2 = tx2 * @ca - ty2 * @sa\n        y2 = ty2 * @ca + tx2 * @sa\n        \n        \"\"\",inplace=False)\n        df['dist'] = df_tmp['distance']\n        df['dist2'] = df_tmp['distance'] * df_tmp['distance'] \n        df[['x1','y1','x2','y2']] = df_tmp[['x1','y1','x2','y2']]\n    return data","fa853f42":"# geopy.distance.distance((-74.1, 40.),(-74., 40.)).km # 11.160876733592401\n# geopy.distance.distance((-74., 40.1),(-74., 40.)).km # 3.077915051090274\n\ndef is_airport(data):\n    long_km = .1 \/ 11.160876733592401 # one over...\n    lat_km = .1 \/ 3.077915051090274\n\n    for df in data:\n        df[\"is_jfk_pickup\"] = False\n        df.loc[df.eval(\n            '(-73.778889 - 2*@long_km < pickup_longitude < -73.778889 + 2*@long_km)\\\n            &\\\n            (40.639722 - 1*@lat_km < pickup_latitude < 40.639722 + .5*@lat_km)')\n               ,\"is_jfk_pickup\"] = True\n\n        df[\"is_ewr_pickup\"] = False\n        df.loc[df.eval(\n            '(-74.168611 - 2*@long_km < pickup_longitude < -74.168611 + 2*@long_km)\\\n            &\\\n            (40.6925 - 1*@lat_km < pickup_latitude < 40.6925 + 1*@lat_km)')\n               ,\"is_ewr_pickup\"] = True\n\n        df[\"is_lga_pickup\"] = False\n        df.loc[df.eval(\n            '(-73.872611 - 1.4*@long_km < pickup_longitude < -73.872611 + 1.5*@long_km)\\\n            &\\\n            (40.77725 - .3*@lat_km < pickup_latitude < 40.77725 + .3*@lat_km)')\n               ,\"is_lga_pickup\"] = True\n\n        \n        df[\"is_jfk_dropoff\"] = False\n        df.loc[df.eval(\n            '(-73.778889 - 2*@long_km < dropoff_longitude < -73.778889 + 2*@long_km)\\\n            &\\\n            (40.639722 - 1*@lat_km < dropoff_latitude < 40.639722 + .5*@lat_km)')\n               ,\"is_jfk_dropoff\"] = True\n\n        df[\"is_ewr_dropoff\"] = False\n        df.loc[df.eval(\n            '(-74.168611 - 2*@long_km < dropoff_longitude < -74.168611 + 2*@long_km)\\\n            &\\\n            (40.6925 - 1*@lat_km < dropoff_latitude < 40.6925 + 1*@lat_km)')\n               ,\"is_ewr_dropoff\"] = True\n\n        df[\"is_lga_dropoff\"] = False\n        df.loc[df.eval(\n            '(-73.872611 - 1.4*@long_km < dropoff_longitude < -73.872611 + 1.5*@long_km)\\\n            &\\\n            (40.77725 - .3*@lat_km < dropoff_latitude < 40.77725 + .3*@lat_km)')\n               ,\"is_lga_dropoff\"] = True\n    return data\n\n","c4d68ea3":"df,df_test = calculate_distance([df,df_test])","59497872":"df,df_test = is_airport([df,df_test])\nprint(\"Airports defined...\")","b15c7b57":"def is_business_day(date):\n    return bool(len(pd.bdate_range(date, date)))\n\ndef time_related_vars(data):\n    for df in data:\n        # df['bday'] = df['pickup_datetime'].apply(is_business_day) # useful feature, but awefully slow...\n        #df['bday'] = bool(len(pd.bdate_range(df['pickup_datetime'].value(), df['pickup_datetime'].value())))\n        df['weekday'] = df['pickup_datetime'].dt.weekday # The day of the week with Monday=0, Sunday=6\n        df['day'] = df['pickup_datetime'].dt.day\n        df['hour'] = df['pickup_datetime'].dt.hour\n        df['month'] = df['pickup_datetime'].dt.month\n        df['year'] = df['pickup_datetime'].dt.year\n        df['daytime'] = False\n        df.loc[(df.hour >= 8)&(df.hour < 20),'daytime'] = True \n        #df['businesstime'] = False\n        #df.loc[df.daytime&df.bday,'businesstime'] = True \n        #df['time_stamp'] = df['year'].astype('str') + '-' + df['month'].astype('str') + '-' + df['day'].astype('str') # if running on small subset\n        df['time_stamp'] = df['year'].astype('str') + '-' + df['month'].astype('str') + '-' + df['day'].astype('str') + ':' + df['hour'].astype('str')\n    return data","24f57dc9":"df,df_test = time_related_vars((df,df_test))","1be16342":"# Free inspiration from\n# https:\/\/www.kaggle.com\/nicapotato\/taxi-rides-time-analysis-and-oof-lgbm\ngrp = df.groupby('time_stamp',as_index=False)['fare_amount'].agg({'tsum':'sum','tmean':'mean','tstd':'std','tskew':'skew','tcount':'count'}).reset_index()\ndf = df.merge(grp, how='left', on=['time_stamp'])\ndf_test = df_test.merge(grp, how='left', on=['time_stamp'])","176dd783":"#df[df.isnull().any(axis=1)]","630ce635":"def is_business_day(date):\n    return bool(len(pd.bdate_range(date, date)))\n\n# geopy.distance.distance((-74.1, 40.),(-74., 40.)).km # 11.160876733592401\n# geopy.distance.distance((-74., 40.1),(-74., 40.)).km # 3.077915051090274\n\ndef space_related_vars(data): # not used for winning solution.\n    long_km = 111.60876733592401\n    lat_km = 30.77915051090274\n    mult_km = 0.5 \n\n    for df in data:\n        df['space_stamp'] = \\\n        (lat_km*df['pickup_latitude']\/mult_km).astype(\"int\").astype(\"str\") + ':' + \\\n        (long_km*df['pickup_longitude']\/mult_km).astype(\"int\").astype(\"str\") + '-' +\\\n        (lat_km*df['dropoff_latitude']\/mult_km).astype(\"int\").astype(\"str\") + ':' + \\\n        (long_km*df['dropoff_longitude']\/mult_km).astype(\"int\").astype(\"str\") \n    return data\n\ndf,df_test = space_related_vars((df,df_test))","dd21f8b5":"df.head()","cd1fac11":"# Free inspiration from\n# https:\/\/www.kaggle.com\/nicapotato\/taxi-rides-time-analysis-and-oof-lgbm\ngrp = df.groupby('space_stamp',as_index=False)['fare_amount'].agg({'ssum':'sum','smean':'mean','sstd':'std','sskew':'skew','scount':'count'}).reset_index()\n#grp = df.groupby('space_stamp',as_index=False)['fare_amount'].agg({'ssum':'sum','scount':'count'}).reset_index()\ndf = df.merge(grp, how='left', on=['space_stamp'])\ndf_test = df_test.merge(grp, how='left', on=['space_stamp'])","d4bfacc0":"df.head()","0a5a4392":"def basic_fare():\n    df['min_fare'] = 2.5 + 0.5 * 5 * df.dist \/ 1.6\n    df_test['min_fare'] = 2.5 + 0.5 * 5 * df_test.dist \/ 1.6\n    df['min_multiple'] = df['fare_amount'] \/ df['min_fare']","12aa4c4c":"basic_fare()","f7dbb697":"wdf = pd.read_csv('..\/input\/nyc-weather-20092015\/1428442.csv',usecols=['DATE','HOURLYVISIBILITY','HOURLYDRYBULBTEMPC','HOURLYWindSpeed',\n    'HOURLYPrecip','DAILYPrecip','DAILYSnowfall','DAILYSnowDepth'],dtype={'HOURLYVISIBILITY':str,'HOURLYDRYBULBTEMPC':str,\n    'HOURLYPrecip':str,'DAILYPrecip':str,'DAILYSnowfall':str,'DAILYSnowDepth':str})","d656f4da":"wdf.head()","82bfb170":"wdf['HOURLYVISIBILITY'] = wdf['HOURLYVISIBILITY'].str.replace('V','') # see the dataset documentation. T = trace etc.\nwdf['HOURLYDRYBULBTEMPC'] = wdf['HOURLYDRYBULBTEMPC'].str.replace('s','')\nwdf['HOURLYPrecip'] = wdf['HOURLYPrecip'].str.replace('s','')\nwdf['HOURLYPrecip'] = wdf['HOURLYPrecip'].str.replace('T','0')\nwdf['DAILYPrecip'] = wdf['DAILYPrecip'].str.replace('T','0')\nwdf['DAILYSnowfall'] = wdf['DAILYSnowfall'].str.replace('T','0')\nwdf['DAILYSnowDepth'] = wdf['DAILYSnowDepth'].str.replace('T','0')","da8c779f":"wdf[['HOURLYVISIBILITY','HOURLYDRYBULBTEMPC','HOURLYWindSpeed','HOURLYPrecip','DAILYPrecip','DAILYSnowfall','DAILYSnowDepth']]=wdf[['HOURLYVISIBILITY','HOURLYDRYBULBTEMPC','HOURLYWindSpeed','HOURLYPrecip','DAILYPrecip','DAILYSnowfall','DAILYSnowDepth']].astype(np.float)","72d146f0":"wdf['DATE']=pd.to_datetime(wdf['DATE'])\nwdf=wdf.set_index('DATE')\nwdf=wdf.resample('1H').nearest()\nwdf=wdf.fillna(method='ffill')\nwdf=wdf.fillna(method='bfill')","b55c98e5":"wdf.head()","440b1e4f":"wdf=wdf.reset_index()","ca5b4270":"wdf.head()","efa94eff":"wdf['time_stamp'] = wdf['DATE'].dt.year.astype('str') + '-' + wdf['DATE'].dt.month.astype('str') + '-' + wdf['DATE'].dt.day.astype('str') + ':' + wdf['DATE'].dt.hour.astype('str')","853d297d":"wdf.head()","87fe5e8e":"df = df.merge(wdf, how='left', on=['time_stamp'])\ndf_test = df_test.merge(wdf, how='left', on=['time_stamp'])","9bd03f8f":"df.head()","56a1d48d":"print( \"NANs: {}, {}\".format(len(df[df.isnull().any(axis=1)]),len(df_test[df_test.isnull().any(axis=1)])))\ndf[df.isnull().any(axis=1)].head()\n","d0fc10e3":"# df.to_pickle('df.pkl')\n# df_test.to_pickle('df_test.pkl')","3bd36344":"# df = pd.read_pickle('df.pkl')\n# df_test = pd.read_pickle('df_test.pkl')","0303b544":"df.dropna(inplace=True)\n\ndf.drop(df.index[(df.pickup_longitude < -75) | \n           (df.pickup_longitude > -72) | \n           (df.pickup_latitude < 40) | \n           (df.pickup_latitude > 42)],inplace=True)\ndf.drop(df.index[(df.dropoff_longitude < -75) | \n           (df.dropoff_longitude > -72) | \n           (df.dropoff_latitude < 40) | \n           (df.dropoff_latitude > 42)],inplace=True)","e0838fa0":"df.nlargest(10,'fare_amount')","20549efc":"df.nsmallest(20,'fare_amount')","bfb29950":"df[['fare_amount', 'dist']].plot.scatter(x='dist',y='fare_amount')","f2b42cf3":"# drop all x more expensive than it should be. No problem with airports, it easily fits:\n# Initial fare $2.5 + $0.5 per 1\/5 mile\nmax_fare_multiple = 20\nmin_fare_multiple = 0.05","a62a44e8":"drop_too_expensive = df.index[(df.fare_amount > ( max_fare_multiple * ( 2.5 + 0.5 * 5 * df.dist \/ 1.6 )))] \nprint(\"n_dropped={}, {}%\".format(len(drop_too_expensive),len(drop_too_expensive)\/len(df)))\ndf.drop(drop_too_expensive,inplace=True)","da78df4b":"# And of the minimum\ndrop_too_cheap = df.index[df.fare_amount < ( min_fare_multiple * ( 2.5 + 0.5 * 5 * df.dist \/ 1.6 ))] \nprint(\"n_dropped={}, {}%\".format(len(drop_too_cheap),len(drop_too_cheap)\/len(df)))\ndf.drop(drop_too_cheap,inplace=True)","37837860":"df[['fare_amount', 'dist']].plot.scatter(x='dist',y='fare_amount')","7e2c559f":"#from folium.plugins import FastMarkerCluster\n\ndef plot_map(df=df, maxpoints=200,showlines=False):\n    m = folium.Map(\n        location=[df[\"pickup_latitude\"].median(), df[\"pickup_longitude\"].median()],\n        zoom_start=12)\n\n    for index, row in enumerate(list(zip(df[\"pickup_latitude\"].values, df[\"pickup_longitude\"].values))):\n        folium.CircleMarker(location=row, radius=2, weight=1, color='green').add_to(m)\n        if index == maxpoints:\n            break\n\n    for index, row in enumerate(list(zip(df[\"dropoff_latitude\"].values, df[\"dropoff_longitude\"].values))):\n        folium.CircleMarker(location=row, radius=2, weight=1, color='red').add_to(m)\n        if index == maxpoints:\n            break\n\n            \n    if showlines:\n        for index, row in enumerate(list(\n            zip(zip(df[\"dropoff_latitude\"].values, df[\"dropoff_longitude\"].values),\n                zip(df[\"pickup_latitude\"].values, df[\"pickup_longitude\"].values)))):\n            #folium.CircleMarker(location=row, radius=2, weight=1, color='red').add_to(m)\n            #print(index,row)\n            folium.PolyLine(row, color=\"blue\", weight=1, opacity=0.5).add_to(m)\n            if index == maxpoints:\n                break\n            \n    return m\n                ","b4df57cd":"plot_map(df_test,80,True)","05720661":"plt.figure();\ndf.dist.plot.hist(bins=50, range=(0,100))\nplt.figure();\ndf_test.dist.plot.hist(bins=50,range=(0,100))","0ca3cc30":"plt.figure();\ndf.dist.plot.hist(bins=50, range=(0,25))\nplt.figure();\ndf_test.dist.plot.hist(bins=50,range=(0,25))","c3f6d027":"df.pickup_datetime.describe()","65483daa":"df_test.pickup_datetime.describe()","a04a48c4":"df[['fare_amount','weekday']].boxplot(by='weekday',showfliers=False)\n# df[['fare_amount','bday']].boxplot(by='bday',showfliers=False)","6380224f":"# df[['dist','businesstime']].boxplot(by='businesstime',showfliers=False)\n# df[['fare_amount','businesstime']].boxplot(by='businesstime',showfliers=False)","005610ff":"df[['dist','hour']].boxplot(by='hour',showfliers=False)\ndf[['fare_amount','hour']].boxplot(by='hour',showfliers=False)","0212a3d0":"df[['dist','month']].boxplot(by='month',showfliers=False)\ndf[['fare_amount','month']].boxplot(by='month',showfliers=False)","87f4fbda":"df.head()","e647d5e6":"df.describe()","b5591a6d":"# Solver cannot run with time, needs to have the float.\ndf['float_pickup_datetime'] = df['pickup_datetime'].values.astype('float')\ndf_test['float_pickup_datetime'] = df_test['pickup_datetime'].values.astype('float')","fdd46588":"# Random split to train and test\ndftr = df.sample( frac = 0.8, random_state=42)\ndfval = df.drop( dftr.index)","a6a56477":"# This way interativelly trial and error select a good set of features.\nll = ['passenger_count','dist','bday','weekday','hour','daytime','businesstime','month','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','lat_diff','long_diff']\nll = ['dist'] # 4.971843085485664\nll = ['passenger_count','dist'] # 4.978781923333827 -> not important\nll = ['dist','bday'] # 4.938947744089244 -> OK\nll = ['dist','bday','weekday'] # 4.910031675409393 -> OK\nll = ['dist','bday','weekday','hour'] # 4.837025815294643 -> OK\nll = ['dist','bday','weekday','hour','daytime'] # 4.759085591019987 -> OK\nll = ['dist','bday','weekday','hour','businesstime'] # 4.804090429646956 -> Not OK\nll = ['dist','bday','weekday','hour','daytime','businesstime'] # 4.79580778655997 -> OK\nll = ['dist','month'] # 4.955495881088339 -> OK\nll = ['dist','bday','weekday','hour','daytime','month'] # 4.706722506235075 -> OK\n\nll = ['dist','bday','weekday','hour','daytime','month','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'] # 4.284077318471638 -> OK\n\nll = ['dist','bday','weekday','hour','daytime','month','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','lat_diff','long_diff'] # 4.315628577392338 -> Not OK\n\n\nll = ['dist','bday','weekday','hour','daytime','month','lat_avg','long_avg','lat_diff','long_diff']\n\nll = ['dist','bday','weekday','hour','daytime','month','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'] # 4.284077318471638 -> OK\n\nll = ['dist','dist2','weekday','hour','daytime','year','month','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude',\n'is_jfk_pickup', 'is_ewr_pickup', 'is_lga_pickup', 'is_jfk_dropoff', 'is_ewr_dropoff', 'is_lga_dropoff']\n\nll = ['dist','dist2','float_pickup_datetime', 'weekday','hour','daytime','year','month','pickup_longitude',\n      'pickup_latitude','dropoff_longitude','dropoff_latitude','is_jfk_pickup', 'is_ewr_pickup',\n      'is_lga_pickup', 'is_jfk_dropoff', 'is_ewr_dropoff', 'is_lga_dropoff',\n      'sum','mean','std','skew','count']\n\nll = ['dist','dist2','float_pickup_datetime', 'weekday','hour','daytime','year','month','pickup_longitude',\n      'pickup_latitude','dropoff_longitude','dropoff_latitude','is_jfk_pickup', 'is_ewr_pickup',\n      'is_lga_pickup', 'is_jfk_dropoff', 'is_ewr_dropoff', 'is_lga_dropoff',\n      'sum','mean','std','skew','count','x1','y1','x2','y2']\n\nll = ['dist','dist2','float_pickup_datetime', 'weekday','hour','daytime','year','month','pickup_longitude',\n      'pickup_latitude','dropoff_longitude','dropoff_latitude','is_jfk_pickup', 'is_ewr_pickup',\n      'is_lga_pickup', 'is_jfk_dropoff', 'is_ewr_dropoff', 'is_lga_dropoff',\n      'sum','mean','std','skew','count','x1','y1','x2','y2',\n      'HOURLYVISIBILITY','HOURLYDRYBULBTEMPC','HOURLYWindSpeed',\n      'HOURLYPrecip','DAILYPrecip','DAILYSnowfall','DAILYSnowDepth']\n\nll = ['dist','dist2','float_pickup_datetime', 'weekday','hour','daytime','year','month','pickup_longitude',\n      'pickup_latitude','dropoff_longitude','dropoff_latitude','is_jfk_pickup', 'is_ewr_pickup',\n      'is_lga_pickup', 'is_jfk_dropoff', 'is_ewr_dropoff', 'is_lga_dropoff',\n      'tsum','tmean','tstd','tskew','tcount','ssum','smean','sstd','sskew','scount','x1','y1','x2','y2',\n      'HOURLYVISIBILITY','HOURLYDRYBULBTEMPC','HOURLYWindSpeed',\n      'HOURLYPrecip','DAILYPrecip','DAILYSnowfall','DAILYSnowDepth']\n\n# Winning coctail:\nll = ['dist','dist2','float_pickup_datetime', 'weekday','hour','daytime','year','month','pickup_longitude',\n      'pickup_latitude','dropoff_longitude','dropoff_latitude','is_jfk_pickup', 'is_ewr_pickup',\n      'is_lga_pickup', 'is_jfk_dropoff', 'is_ewr_dropoff', 'is_lga_dropoff',\n      'tsum','tmean','tstd','tskew','tcount','x1','y1','x2','y2',\n      'HOURLYVISIBILITY','HOURLYDRYBULBTEMPC','HOURLYWindSpeed',\n      'HOURLYPrecip','DAILYPrecip','DAILYSnowfall','DAILYSnowDepth']","86e70c0c":"ntr = len(dftr['dist'])\nnval = len(dfval['dist'])\nnte = len(df_test['dist'])\n#ntotal = len(df['dist'])\n\nXtr = pd.DataFrame(dftr[ll]).values.reshape(ntr, len(ll))\nXval = pd.DataFrame(dfval[ll]).values.reshape(nval, len(ll))\nXte = pd.DataFrame(df_test[ll]).values.reshape(nte, len(ll))\n#Xtotal = pd.DataFrame(df[ll]).values.reshape(ntotal, len(ll))\n\n# We will actually learn min_multiple, as it is at the first approximaton constant \nYtr = dftr['min_multiple'].values\nYval = dfval['min_multiple'].values","4f47fcf2":"# https:\/\/lightgbm.readthedocs.io\/en\/latest\/Python-API.html\n# Good parameters are data size dependent. Should be found e.g. by grid search\nmax_bin = 2*255\nn_estimators=10000\ngbm = lgb.LGBMRegressor(n_estimators=n_estimators, silent=False, max_bin=max_bin)","eb7622c4":"print(\"Fitting...\")\nparameters = gbm.fit( Xtr, Ytr )\nprint(\"Fitted...\")","5d2516b2":"# pickle.dump(gbm, open('model.pkl', 'wb'))","d3cc2888":"# gbm = pickle.load(open('model.pkl', 'rb'))","c9187cca":"Ytest = gbm.predict(Xte)","fea19ad7":"df_test['fare_amount'] = pd.Series(Ytest) * df_test['min_fare']\ndf_test[['key','fare_amount']].to_csv('submission.csv',index=False)\nprint(\"Submission file created...\")","98ce4463":"# Print some statistics\nprint(\"FARE MULTIPLE, LGBM\")\nprint(parameters)\nprint(ll)\nprint(\"df size: {}\".format(len(df)))\nprint(\"chunks: {}\".format(chunks))\nprint(\"max bin: {}\".format(max_bin))\nprint(\"min,max_fare_multiple {} {}\".format(min_fare_multiple,max_fare_multiple))\nprint(\"n_estimators={}\".format(n_estimators))","5e7547a3":"Ytr_hat = gbm.predict(Xtr)\nYval_hat = gbm.predict(Xval)\n# Ytotal = gbm.predict(Xtotal)","da2e8ef5":"# df['fare_predicted'] = pd.Series(Ytotal) * df['min_fare']\ndftr['fare_predicted'] = pd.Series(Ytr) * dftr['min_fare']\ndfval['fare_predicted'] = pd.Series(Yval) * dfval['min_fare']\n\n\n#df['fare_err'] = (df['fare_amount'] - df['fare_predicted']).abs()\ndftr['fare_err'] = (dftr['fare_amount'] - dftr['fare_predicted']).abs()\ndfval['fare_err'] = (dfval['fare_amount'] - dfval['fare_predicted']).abs()","bfd8ec6f":"rms_tr = (dftr['fare_err']**2).mean()**.5\nprint( \"Accuracy training: \", rms_tr)","1fd2f684":"rms_val = (dfval['fare_err']**2).mean()**.5\nprint( \"Accuracy testing: \", rms_val)","30e8c47a":"err100 = dfval.nlargest(100,'fare_err')\nerr100.to_csv('100errval.csv')","8a40d64d":"err100.head()","98146dc3":"plot_map(err100,100,True)","a9dd1f9d":"plt.figure();\ndftr.fare_err.plot.hist(bins=50, range=(0,25))\nplt.figure();\ndfval.fare_err.plot.hist(bins=50, range=(0,25))","71fd43a2":"dftr[['fare_err', 'dist']].plot.scatter(x='dist',y='fare_err')","6548f46c":"dfval[['fare_err', 'dist']].plot.scatter(x='dist',y='fare_err')","fbe0f87a":"print(\"DONE.\")","500a133b":"Let's get some idea, what the test data are about:","8df072c1":"## Feedback how it went and what was mispredicted...","ed1ee954":"# Look at the data\nFirst, we will need some plotting routine.\n* Green are pick-up locations\n* Red are drop-offs","1eb905c6":"# Remove outliers\n## GPS outliers\nSome data are with mistakes - looking at the test data, interval [40,42] and [-75,-72] should be more than OK. \nAlso remove NaNs.","4da757bf":"## Basic fare\nThis is the very basic fare to be paid: \\$2.5 + \\$0.5 per 1\/5 of the mile","7b56d4d4":"I assume some dependency of the fare on the weather. The data got from www.ncdc.noaa.gov\n* Product: LCD (CSV)\n* Stations: WBAN:94728\n* Begin Date: 2009-01-01 00:00\n* End Date: 2015-12-31 23:59\n* Documentation: https:\/\/www1.ncdc.noaa.gov\/pub\/data\/cdo\/documentation\/LCD_documentation.pdf","e41a9be9":"One more thing - let's plot training and test data histograms","6a345e1c":"## Weather data","4947f347":"## Useful space related statistics","45f5193b":"No NANs for full data set...","a4bcf458":"# Feature development\nHere, we will create some basic features for the dataset. We will visualize them in later section.","5690fa64":"# Feature visualization\nThere must be a dependence of the fare on the feature. Othervise the feature won't have a predictive power... Let's review one by one...","6ba04452":"## Fare amount outliers","37c32250":"## Useful time related statistics\nEsential features of the time dependent data set. Also, create time stamp, which is day + hour, and calculate average (count, median etc) fare for given hour.","f4ce3ac3":"# Read the training file, test file\nFirst, download all the files from the kaggle web site zipped into `all.zip`. \n* We will read only portion of the training file at once, randomly splitting the training file into multiple chunks. The training file will be then randomly reshuffled alowing easy plot of representative samples.  \n* The test file will be read whole. ","44cd7228":"...looks like from 20:00 to 7:00 people tend to take longer rides than during the daytime","bdfface8":"# Numerical method\nWe will not train fare prediction directly, but we will train functon 'a' in 'fare = a * distance'. In this case, even a constant value of 'a' would give a reasonable result.","92d402dd":"# Intro","225f0a57":"Check time: Is the test from the same period as the training data???","50f15de4":"## Distance + flag of ride from\/to airport\nThe distance needs to be calculated in the vector manner - call the function once, do all the math. No calling for each row, as it is very slow. I.e. no .apply() function.","1d71e6ea":"* This kernel assumes fare in form of 'fare = a() * distance', where the function 'a()' is to be fitted\n* Solver uses the gradient boosting tree with LightGBM library\n* Weather influence in considered\n* Visualization of the data and error are provided to get some insights\n* Chunks = 5 (i.e. 20% of the dataset) runs for a few hours (4-6 h) on my windows laptop with 16 GB memory and i5\/2.3 GHz. Result: 2.99287 \/ 153 position on the (top 15%) leaderboard\n* Running on full data set gives at the best RMS 2.90609, i.e. top 6.5% position on the leaderboard. It runs approx. 6 hours on Xeon E5-2630 @ 2.40GHz, utilizing ~110 GB RAM at peak\n* There is a random initialization of the LGBM solver -> The results are not exactly the same and they are approx. 2.90 - 2.92 range.\n* Next steps could be following (family reasons :-):\n  - Double check the choice of the features (automatic testing)\n  - Optimize parameters: cut-off lines of outliers and internal parameters of the solver (grid search)\n  - Train on full data set. As of here, only 80% is used for training, the 20% is for validation...\n","e2d7733a":"...looks roughly the same. Let's zoom in..."}}