{"cell_type":{"2504b7de":"code","afe8db8f":"code","7fe86b69":"code","e763dc59":"code","39d4389e":"code","309b0173":"code","e7729f07":"code","705e393d":"code","3d56fa6c":"code","a99f251e":"code","7bab41c2":"code","0b658bec":"code","615628f2":"code","4dd3c3d0":"code","dc4d88d7":"code","1c742f8e":"code","d4e39474":"code","aed4ec4d":"code","d132d469":"markdown"},"source":{"2504b7de":"import numpy as np\nimport pandas as pd\n#pandas data set\u0131 okumaya ve duzenlemeye yard\u0131mc\u0131 olur\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, GRU, Embedding, CuDNNGRU\nfrom tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences","afe8db8f":"dataset = pd.read_csv('..\/input\/hepsiburada.csv')\ndataset.head()\n#dataframe olrak yuklend\u0131","7fe86b69":"target = dataset['Rating'].values.tolist()\ndata = dataset['Review'].values.tolist()\ncutoff = int(len(data) * 0.80)\nx_train, x_test = data[:cutoff], data[cutoff:]\ny_train, y_test = target[:cutoff], target[cutoff:]\nprint(x_train[100])\nprint(y_train[100])","e763dc59":"num_words = 10000\ntokenizer = Tokenizer(num_words=num_words)\n#en s\u0131k gecen 10b\u0131n kel\u0131me kel\u0131me haznes\u0131nde\ntokenizer.fit_on_texts(data)\n#tokenlest\u0131rme yap\u0131ld\u0131\n#tokenizer.word_index","39d4389e":"x_train_tokens = tokenizer.texts_to_sequences(x_train)\n#data \u0131c\u0131n yap\u0131lan durumun ayn\u0131s\u0131 e\u011fitim verisi i\u00e7inde yap\u0131l\u0131yor\nprint(x_train[800])\n#sec\u0131len cumle asag\u0131da\nprint(x_train_tokens[800])\n#sec\u0131len cumlen\u0131n token hal\u0131 asag\u0131da","309b0173":"x_test_tokens = tokenizer.texts_to_sequences(x_test)\n#test \u0131c\u0131ndek\u0131 cumleler tokenlest\u0131r\u0131l\u0131yor\nnum_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\nnum_tokens = np.array(num_tokens)\n# rnn bel\u0131rl\u0131 boyutta ver\u0131 ver\u0131lmel\u0131 bu yuzden tum ver\u0131ler\u0131 ayn\u0131 boyuta get\u0131rmel\u0131y\u0131z\n# np array amac daha kolay \u0131slem yapmak\nnp.mean(num_tokens)\n#ortalama 20 token var her cumlede","e7729f07":"print(np.max(num_tokens))\n# en con 195 kel\u0131me\nprint(np.argmax(num_tokens))\n#en uzun olan 295 s\u0131ras\u0131n\u0131 bulmak \u0131c\u0131n\nprint(x_train[21941])\n#en uzuna bakal\u0131m","705e393d":"max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\nmax_tokens = int(max_tokens)\nprint(max_tokens) #burada mean ve standart sapma degerler\u0131yle kac kel\u0131me alsak daha \u0131y\u0131 olur onu sec\u0131yoruz\nprint(np.sum(num_tokens < max_tokens) \/ len(num_tokens))\n#kac tane cumle 59 kapl\u0131yor yaklas\u0131k yuzde 95","3d56fa6c":"x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)\n#tra\u0131n \u0131c\u0131n 59 dan sonras\u0131 s\u0131l\u0131yorz\nprint(x_train_pad.shape)\nx_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)\n#test \u0131c\u0131n 59 dan sonras\u0131 s\u0131l\u0131yorz\nprint(x_test_pad.shape)","a99f251e":"print(np.array(x_train_tokens[800]))\nprint(x_train_pad[800])\n# burada padd\u0131ng eklenm\u0131sler var","7bab41c2":"idx = tokenizer.word_index\n#kel\u0131meler ve buna kars\u0131l\u0131k gelen degerler burada\ninverse_map = dict(zip(idx.values(), idx.keys()))\n#bu i\u015flem ile hang\u0131 kel\u0131me hang\u0131 token ald\u0131 bunu hesapl\u0131yoruz\n# cunku keras kel\u0131me token yap\u0131yo ama ger\u0131 cozem\u0131yoruz bu yuzden oneml\u0131\n\ndef tokens_to_string(tokens):\n    words = [inverse_map[token] for token in tokens if token!=0]\n    text = ' '.join(words)\n    return text\n#buraya hang\u0131 token versek text hal\u0131nde ger\u0131 donucek","0b658bec":"print(x_train[800])\n#bu orj\u0131nal 800 \u0131ndextek\u0131 cumle\nprint(tokens_to_string(x_train_tokens[800]))","615628f2":"model = Sequential()\nembedding_size = 50\n#her ke\u0131lmeye kars\u0131l\u0131k gelen 50 uzunlugunda vektor var kel\u0131me degerl\u0131n\u0131n tutuldugu\nmodel.add(Embedding(input_dim=num_words,\n                    output_dim=embedding_size,\n                    input_length=max_tokens,\n                    name='embedding_layer'))\n#\u0131nput bel\u0131rlenen maks\u0131mum deger kadar\n#c\u0131k\u0131s 50 vektor \n#g\u0131r\u0131s \u0131se ver\u0131ler kel\u0131meler (10b\u0131n uzunlugunda ver\u0131 olucak)\nmodel.add(GRU(units=16, return_sequences=True))\n#return true olma sebeb\u0131 tum c\u0131k\u0131slar\u0131n d\u0131ger aglara aktar\u0131lmas\u0131, eger false olsays\u0131 sadece son output c\u0131kcakt\u0131\n#eger gpu olurda CuDNNGRU kullan\u0131lab\u0131l\u0131r, sadece nvd\u0131a n\u0131n kart\u0131nda cal\u0131syo ve sadece h\u0131z fark\u0131 var\nmodel.add(GRU(units=8, return_sequences=True))\nmodel.add(GRU(units=4)) #default false o yuzden yazmaya gerek yok\nmodel.add(Dense(1, activation='sigmoid'))\noptimizer = Adam(lr=1e-3)\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\nmodel.summary()","4dd3c3d0":"model.fit(x_train_pad, y_train, epochs=5, batch_size=256)","dc4d88d7":"result = model.evaluate(x_test_pad, y_test)\nprint(result[1])","1c742f8e":"y_pred = model.predict(x=x_test_pad[0:1000])\n#y pred normalde sutun hal\u0131nde\ny_pred = y_pred.T[0] #burada transpozu al\u0131narak yatay hale get\u0131r\u0131l\u0131yor\ncls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\ncls_true = np.array(y_test[0:1000])\nincorrect = np.where(cls_pred != cls_true)\nincorrect = incorrect[0] #tuple \u0131ce\u0131s\u0131nde o yuzden [0]\nprint(incorrect) #yanl\u0131s tahm\u0131nler\nprint(len(incorrect))  # yanl\u0131s tahm\u0131n say\u0131s\u0131\nidx = incorrect[3] #\u0131lk yanl\u0131s tahm\u0131n \u0131ndexi\nprint(idx)\ntext = x_test[idx]\nprint(text)\nprint(\"y_pred\",y_pred[idx])\nprint(\"cls_pred\",cls_pred[idx])\nprint(\"cls_true\",cls_true[idx])","d4e39474":"text1 = \"bu \u00fcr\u00fcn \u00e7ok iyi herkese tavsiye ederim\"\ntext2 = \"kargo \u00e7ok h\u0131zl\u0131 ayn\u0131 g\u00fcn elime ge\u00e7ti\"\ntext3 = \"b\u00fcy\u00fck bir hayal k\u0131r\u0131kl\u0131\u011f\u0131 ya\u015fad\u0131m bu \u00fcr\u00fcn bu markaya yak\u0131\u015fmam\u0131\u015f\"\ntext4 = \"m\u00fckemmel\"\ntext5 = \"tasar\u0131m\u0131 harika ancak kargo \u00e7ok ge\u00e7 geldi ve \u00fcr\u00fcn a\u00e7\u0131lm\u0131\u015ft\u0131 tavsiye etmem\"\ntext6 = \"hi\u00e7 resimde g\u00f6sterildi\u011fi gibi de\u011fil\"\ntext7 = \"k\u00f6t\u00fc yorumlar g\u00f6z\u00fcm\u00fc korkutmu\u015ftu ancak hi\u00e7bir sorun ya\u015famad\u0131m te\u015fekk\u00fcrler\"\ntext8 = \"hi\u00e7 bu kadar k\u00f6t\u00fc bir sat\u0131c\u0131ya denk gelmemi\u015ftim \u00fcr\u00fcn\u00fc geri iade ediyorum\"\ntext9 = \"tam bir fiyat performans \u00fcr\u00fcn\u00fc\"\ntext10 = \"bekledi\u011fim gibi \u00e7\u0131kmad\u0131\"\ntexts = [text1, text2, text3, text4, text5, text6, text7, text8, text9, text10]","aed4ec4d":"tokens = tokenizer.texts_to_sequences(texts)\ntokens_pad = pad_sequences(tokens, maxlen=max_tokens)\nprint(tokens_pad.shape)\ntext_pred=model.predict(tokens_pad)\nprint(text_pred)\ntext_pred = np.array([1.0 if p>0.5 else 0.0 for p in text_pred])\nprint(text_pred)","d132d469":"\n\n[Hakan CEBEC\u0130'nin](http:\/\/https\/\/www.udemy.com\/user\/software-development\/)\n\n* [Do\u011fal Dil \u0130\u015fleme A-Z\u2122: (NLP)](http:\/\/https\/\/www.udemy.com\/dogal-dil-isleme\/)\n\nkursundan \u00f6\u011frendiklerimi denedi\u011fim ve derledi\u011fim kernelimdir.\n"}}