{"cell_type":{"83ee2b43":"code","b280a721":"code","70a50916":"code","30915d41":"code","65f6559d":"code","98715d56":"code","28e60ff4":"code","f16f2512":"code","91cca0d5":"code","07d9fed6":"code","a94f72f5":"code","7fd5f120":"code","9ee183d8":"code","65d90c8d":"code","c31c88a7":"code","6377eef9":"code","104b07c8":"code","3cf555ae":"code","ec2edf2d":"code","1e31bba3":"code","d9322c42":"code","2c4c6135":"code","6cad1d73":"code","bd9eefd5":"code","2eeee9a9":"code","744d4042":"code","0092d609":"code","a038d873":"code","70453d9c":"code","b3e27cb9":"code","a8b76f6e":"code","8c9a7fbd":"code","85478826":"markdown","b972aec5":"markdown","8ad122cd":"markdown","8441dcbe":"markdown","f15d9a0b":"markdown","9de9ef2c":"markdown","91e8f481":"markdown","cc6c49f2":"markdown","75c03b4d":"markdown","46dbf7d5":"markdown","c49e69c0":"markdown","cee1510e":"markdown","1054390d":"markdown","2654bc04":"markdown","40825590":"markdown","1b6f3633":"markdown","829a42de":"markdown","9a572b92":"markdown"},"source":{"83ee2b43":"# Upload Libraries\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix\nfrom imblearn.over_sampling import SMOTE,ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import StratifiedKFold\nfrom collections import Counter\nimport itertools\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","b280a721":"# Upload Dataset\ndataset = pd.read_csv('..\/input\/hmeq-data\/hmeq.csv')\n# Target variable\ny = dataset.BAD\ndataset.drop(['BAD'], axis=1, inplace=True)","70a50916":"# dimensions of dataset\nprint(dataset.shape)\n","30915d41":"# columns of dataset\ndataset.columns\n","65f6559d":"# list types for each attribute\ndataset.dtypes\n","98715d56":"# take a peek at the first rows of the data\ndataset.head(50)\n","28e60ff4":"# summarize attribute distributions for data frame\nprint(dataset.describe().T)\n","f16f2512":"print(dataset.info())\n","91cca0d5":"def rstr(dataset): return dataset.shape, dataset.apply(lambda x: [x.unique()])\nprint(rstr(dataset))","07d9fed6":"# Look at the level of each feature\nfor column in dataset.columns:\n    print(column, dataset[column].nunique())","a94f72f5":"# check missing values both to numeric features and categorical features \nfeat_missing = []\n\nfor f in dataset.columns:\n    missings = dataset[f].isnull().sum()\n    if missings > 0:\n        feat_missing.append(f)\n        missings_perc = missings\/dataset.shape[0]\n        \n        # printing summary of missing values\n        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n\n# how many variables do present missing values?\nprint()\nprint('In total, there are {} variables with missing values'.format(len(feat_missing)))","7fd5f120":"# imputing missing values \ndataset = dataset.fillna(method='ffill')\ndataset = dataset.fillna(method='bfill')\n\n\n","9ee183d8":"# summarize the class distribution\ny = y.astype(object) \ncount = pd.crosstab(index = y, columns=\"count\")\npercentage = pd.crosstab(index = y, columns=\"frequency\")\/pd.crosstab(index = y, columns=\"frequency\").sum()\npd.concat([count, percentage], axis=1)","65d90c8d":"ax = sns.countplot(x=y, data=dataset).set_title(\"Target Variable Distribution\")","c31c88a7":"# categorical features\ncategorical_cols = [cname for cname in dataset.columns if\n                    dataset[cname].dtype in ['object']]\ncat = dataset[categorical_cols]\ncat.columns","6377eef9":"# Visualizations\nsns.set( rc = {'figure.figsize': (5, 5)})\nfcat = ['REASON','JOB']\n\nfor col in fcat:\n    plt.figure()\n    sns.countplot(x=cat[col], data=cat, palette=\"Set3\")\n    plt.show()","104b07c8":"# One-hot encode the data\nHOX_dataset = pd.get_dummies(dataset)","3cf555ae":"# Numerical features\nnumerical_cols = [cname for cname in dataset.columns if\n                 dataset[cname].dtype in ['float']]\nnum = dataset[numerical_cols]\nnum.columns","ec2edf2d":"# Visualizations\nsns.set( rc = {'figure.figsize': (5, 5)})\nfnum = ['MORTDUE','VALUE','YOJ','DEROG','CLAGE','DEBTINC','DELINQ','NINQ','CLNO']\n\nfor col in fnum:\n    plt.figure()\n    x=num[col]\n    sns.distplot(x, bins=10)\n    plt.xticks(rotation=45)\n    plt.show()","1e31bba3":"y = y.astype('int') \nsmo = SMOTE(random_state=0)\nX_resampled, y_resampled = smo.fit_resample(HOX_dataset, y)\nprint(sorted(Counter(y_resampled).items()))","d9322c42":"# Break off train and validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X_resampled, y_resampled, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","2c4c6135":"# From https:\/\/www.kaggle.com\/ajay1735\/my-credit-scoring-model\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6cad1d73":"# Test options and evaluation metric\n\n# Spot Check Algorithms\nmodels = []\nmodels.append(('LogisticRegression', LogisticRegression(random_state=0)))\nmodels.append(('Bagging', BaggingClassifier(random_state=0)))\nmodels.append(('RandomForest', RandomForestClassifier(random_state=0)))\nmodels.append(('AdaBoost', AdaBoostClassifier(random_state=0)))\nmodels.append(('GBM', GradientBoostingClassifier(random_state=0)))\nmodels.append(('XGB', XGBClassifier(random_state=0)))\nresults_t = []\nresults_v = []\nnames = []\nscore = []\nskf = StratifiedKFold(n_splits=5)\nfor (name, model) in models:\n    param_grid = {}\n    my_model = GridSearchCV(model,param_grid,cv=skf)\n    my_model.fit(X_train, y_train)\n    predictions_t = my_model.predict(X_train) \n    predictions_v = my_model.predict(X_valid)\n    accuracy_train = accuracy_score(y_train, predictions_t) \n    accuracy_valid = accuracy_score(y_valid, predictions_v) \n    results_t.append(accuracy_train)\n    results_v.append(accuracy_valid)\n    names.append(name)\n    f_dict = {\n        'model': name,\n        'accuracy_train': accuracy_train,\n        'accuracy_valid': accuracy_valid,\n    }\n    # Computing Confusion matrix for the above algorithm\n    cnf_matrix = confusion_matrix(y_valid, predictions_v)\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=[\"BAD\"], title=\"Confusion Matrix - \"+str(name))\n    score.append(f_dict)\nplt.show()    \nscore = pd.DataFrame(score, columns = ['model','accuracy_train', 'accuracy_valid'])","bd9eefd5":"print(score)","2eeee9a9":"# Spot Check Algorithms with standardized dataset\npipelines = []\npipelines.append(('Scaled_LogisticRegression', Pipeline([('Scaler', StandardScaler()),('LogisticRegression', LogisticRegression(random_state=0))])))\npipelines.append(('Scaled_Bagging', Pipeline([('Scaler', StandardScaler()),('Bagging', BaggingClassifier(random_state=0))])))\npipelines.append(('Scaled_RandomForest', Pipeline([('Scaler', StandardScaler()),('RandomForest', RandomForestClassifier(random_state=0))])))\npipelines.append(('Scaled_AdaBoost', Pipeline([('Scaler', StandardScaler()),('AdaBoost', AdaBoostClassifier(random_state=0))])))\npipelines.append(('Scaled_GBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingClassifier(random_state=0))])))\npipelines.append(('Scaled_XGB', Pipeline([('Scaler', StandardScaler()),('XGB', XGBClassifier(random_state=0))])))\npipelines.append(('Scaled_NeuralNetwork', Pipeline([('Scaler', StandardScaler()),('NeuralNetwork', MLPClassifier(random_state=0))])))\nresults_t = []\nresults_v = []\nnames = []\nscore_sd = []\nskf = StratifiedKFold(n_splits=5)\nfor (name, model) in pipelines:\n    param_grid = {}\n    my_model = GridSearchCV(model,param_grid,cv=skf)\n    my_model.fit(X_train, y_train)\n    predictions_t = my_model.predict(X_train) \n    predictions_v = my_model.predict(X_valid)\n    accuracy_train = accuracy_score(y_train, predictions_t) \n    accuracy_valid = accuracy_score(y_valid, predictions_v) \n    results_t.append(accuracy_train)\n    results_v.append(accuracy_valid)\n    names.append(name)\n    f_dict = {\n        'model': name,\n        'accuracy_train': accuracy_train,\n        'accuracy_valid': accuracy_valid,\n    }\n    # Computing Confusion matrix for the above algorithm\n    cnf_matrix = confusion_matrix(y_valid, predictions_v)\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=[\"BAD\"], title=\"Confusion Matrix - \"+str(name))\n    score_sd.append(f_dict)\nplt.show()   \nscore_sd = pd.DataFrame(score_sd, columns = ['model','accuracy_train', 'accuracy_valid'])","744d4042":"print(score_sd)","0092d609":"y = y.astype('int') \nada = ADASYN(random_state=0)\nX_resampled_, y_resampled_ = ada.fit_resample(HOX_dataset, y)\nprint(sorted(Counter(y_resampled_).items()))","a038d873":"# Break off train and validation set from training data\nX_train_, X_valid_, y_train_, y_valid_ = train_test_split(X_resampled_, y_resampled_, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","70453d9c":"# Test options and evaluation metric\n\n# Spot Check Algorithms\nmodels = []\nmodels.append(('LogisticRegression', LogisticRegression(random_state=0)))\nmodels.append(('Bagging', BaggingClassifier(random_state=0)))\nmodels.append(('RandomForest', RandomForestClassifier(random_state=0)))\nmodels.append(('AdaBoost', AdaBoostClassifier(random_state=0)))\nmodels.append(('GBM', GradientBoostingClassifier(random_state=0)))\nmodels.append(('XGB', XGBClassifier(random_state=0)))\nresults_t = []\nresults_v = []\nnames = []\nscore = []\nskf = StratifiedKFold(n_splits=5)\nfor (name, model) in models:\n    param_grid = {}\n    my_model = GridSearchCV(model,param_grid,cv=skf)\n    my_model.fit(X_train_, y_train_)\n    predictions_t = my_model.predict(X_train_) \n    predictions_v = my_model.predict(X_valid_)\n    accuracy_train = accuracy_score(y_train_, predictions_t) \n    accuracy_valid = accuracy_score(y_valid_, predictions_v) \n    results_t.append(accuracy_train)\n    results_v.append(accuracy_valid)\n    names.append(name)\n    f_dict = {\n        'model': name,\n        'accuracy_train': accuracy_train,\n        'accuracy_valid': accuracy_valid,\n    }\n    # Computing Confusion matrix for the above algorithm\n    cnf_matrix = confusion_matrix(y_valid_, predictions_v)\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=[\"BAD\"], title=\"Confusion Matrix - \"+str(name))\n    score.append(f_dict)\nplt.show()    \nscore = pd.DataFrame(score, columns = ['model','accuracy_train', 'accuracy_valid'])","b3e27cb9":"print(score)","a8b76f6e":"# Spot Check Algorithms with standardized dataset\npipelines = []\npipelines.append(('Scaled_LogisticRegression', Pipeline([('Scaler', StandardScaler()),('LogisticRegression', LogisticRegression(random_state=0))])))\npipelines.append(('Scaled_Bagging', Pipeline([('Scaler', StandardScaler()),('Bagging', BaggingClassifier(random_state=0))])))\npipelines.append(('Scaled_RandomForest', Pipeline([('Scaler', StandardScaler()),('RandomForest', RandomForestClassifier(random_state=0))])))\npipelines.append(('Scaled_AdaBoost', Pipeline([('Scaler', StandardScaler()),('AdaBoost', AdaBoostClassifier(random_state=0))])))\npipelines.append(('Scaled_GBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingClassifier(random_state=0))])))\npipelines.append(('Scaled_XGB', Pipeline([('Scaler', StandardScaler()),('XGB', XGBClassifier(random_state=0))])))\npipelines.append(('Scaled_NeuralNetwork', Pipeline([('Scaler', StandardScaler()),('NeuralNetwork', MLPClassifier(random_state=0))])))\nresults_t = []\nresults_v = []\nnames = []\nscore_sd = []\nskf = StratifiedKFold(n_splits=5)\nfor (name, model) in pipelines:\n    param_grid = {}\n    my_model = GridSearchCV(model,param_grid,cv=skf)\n    my_model.fit(X_train_, y_train_)\n    predictions_t = my_model.predict(X_train_) \n    predictions_v = my_model.predict(X_valid_)\n    accuracy_train = accuracy_score(y_train_, predictions_t) \n    accuracy_valid = accuracy_score(y_valid_, predictions_v) \n    results_t.append(accuracy_train)\n    results_v.append(accuracy_valid)\n    names.append(name)\n    f_dict = {\n        'model': name,\n        'accuracy_train': accuracy_train,\n        'accuracy_valid': accuracy_valid,\n    }\n    # Computing Confusion matrix for the above algorithm\n    cnf_matrix = confusion_matrix(y_valid_, predictions_v)\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=[\"BAD\"], title=\"Confusion Matrix - \"+str(name))\n    score_sd.append(f_dict)\nplt.show()   \nscore_sd = pd.DataFrame(score_sd, columns = ['model','accuracy_train', 'accuracy_valid'])","8c9a7fbd":"print(score_sd)","85478826":"## Prepare Workspace","b972aec5":"# How to handle Unbalanced Dataset in a Credit Scoring Model\n# Resampling Methods + Stratified Cross-Validation","8ad122cd":"## Baseline Models ","8441dcbe":"## Split Dataset","f15d9a0b":"### Encoding Categorical Variables","9de9ef2c":"## Numerical Variables Visualization","91e8f481":"### SMOTE + Stratified Cross-Validation","cc6c49f2":"## Baseline Models ","75c03b4d":"## Target Variable Analysis","46dbf7d5":"## Handling Missing Values","c49e69c0":"## Scaled Baseline Models ","cee1510e":"## Resampling Techniques + Stratified Cross-Validation","1054390d":"## Split Dataset","2654bc04":"### ADASYN + Stratified Cross-Validation","40825590":"## Confusion Matrix Function","1b6f3633":"## Summarize Dataset","829a42de":"## Scaled Baseline Models","9a572b92":"## Categorical Variables Visualization"}}