{"cell_type":{"0658eb3b":"code","8901305e":"code","ff0c34e0":"code","710778a4":"code","704a4009":"code","aa44d5b0":"code","e015f94c":"code","3a9c40da":"code","5521985b":"code","2fad4a65":"code","9e99ae52":"code","2d886fea":"code","6ce8f348":"code","1ca6860d":"code","eeb7672e":"code","e2af25f2":"code","a4823cc8":"markdown","99897ef1":"markdown","d1addc7b":"markdown","d6a9c864":"markdown","cc75c008":"markdown","86538ec7":"markdown","44fa802d":"markdown","bb0360e8":"markdown","57c150d7":"markdown","57b8fa16":"markdown","d2a12bf6":"markdown"},"source":{"0658eb3b":"import numpy as np\nimport pandas as pd\nimport os\nimport random, re, math\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom kaggle_datasets import KaggleDatasets\n\nprint(tf.__version__)\nprint(tf.keras.__version__)","8901305e":"!pip install efficientnet\nimport efficientnet.tfkeras as efn","ff0c34e0":"AUTO = tf.data.experimental.AUTOTUNE\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n\n# Data access\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","710778a4":"NB_CLASSES = 4\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\nSEED = 420\nEPOCHS = 80","704a4009":"def cutmix(image, label, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with cutmix applied\n    DIM = IMG_SIZE\n    \n    imgs = []; labs = []\n    for j in range(BATCH_SIZE):\n        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast(tf.random.uniform([], 0, 1) <= PROBABILITY, tf.int32)\n        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n        k = tf.cast(tf.random.uniform([], 0, BATCH_SIZE), tf.int32)\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast(tf.random.uniform([], 0, DIM), tf.int32)\n        y = tf.cast(tf.random.uniform([], 0, DIM), tf.int32)\n        b = tf.random.uniform([], 0, 1) # this is beta dist with alpha=1.0\n        WIDTH = tf.cast(DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH\/\/2)\n        yb = tf.math.minimum(DIM,y+WIDTH\/\/2)\n        xa = tf.math.maximum(0,x-WIDTH\/\/2)\n        xb = tf.math.minimum(DIM,x+WIDTH\/\/2)\n        # MAKE CUTMIX IMAGE\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n        # MAKE CUTMIX LABEL\n        a = tf.cast(WIDTH*WIDTH\/DIM\/DIM,tf.float32)\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j], NB_CLASSES)\n            lab2 = tf.one_hot(label[k], NB_CLASSES)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(BATCH_SIZE,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(BATCH_SIZE, NB_CLASSES))\n    return image2,label2","aa44d5b0":"path='..\/input\/plant-pathology-2020-fgvc7\/'\ntrain = pd.read_csv(path + 'train.csv')\ntest = pd.read_csv(path + 'test.csv')\nsub = pd.read_csv(path + 'sample_submission.csv')\n\ntrain_paths = train.image_id.apply(lambda x: GCS_DS_PATH + '\/images\/' + x + '.jpg').values\ntest_paths = test.image_id.apply(lambda x: GCS_DS_PATH + '\/images\/' + x + '.jpg').values\n\ntrain_labels = train.loc[:, 'healthy':].values","e015f94c":"def decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    if label is None:\n        return image\n    else:\n        return image, label\n    \ndef data_augment(image, label=None, seed=2020):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n           \n    if label is None:\n        return image\n    else:\n        return image, label","3a9c40da":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels.astype(np.float32)))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(SEED)\n    .batch(BATCH_SIZE)\n    .map(cutmix, num_parallel_calls=AUTO)\n    .unbatch()\n    .shuffle(SEED)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n)","5521985b":"test_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","2fad4a65":"row = 6; col = 4;\nrow = min(row, BATCH_SIZE\/\/col)\n\nfor (img, label) in train_dataset:\n    plt.figure(figsize=(15,int(15*row\/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        plt.axis('off')\n        plt.imshow(img[j,])\n        plt.title(str(list(label[j,].numpy())))\n    plt.show()\n    break","9e99ae52":"LR_START = 0.00001\nLR_MAX = 0.0001 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = int(0.35 * EPOCHS)\nLR_SUSTAIN_EPOCHS = int(0.075 * EPOCHS)\nLR_EXP_DECAY = .87\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","2d886fea":"def get_model():\n    base_model =  efn.EfficientNetB7(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = base_model.output\n    predictions = Dense(NB_CLASSES, activation=\"softmax\")(x)\n    return Model(inputs=base_model.input, outputs=predictions)","6ce8f348":"with strategy.scope():\n    model = get_model()\n    \nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])","1ca6860d":"%%time\nmodel.fit(\n    train_dataset, \n    steps_per_epoch=train_labels.shape[0] \/\/ BATCH_SIZE,\n    callbacks=[lr_callback],\n    epochs=EPOCHS\n)","eeb7672e":"%%time\nprobs = model.predict(test_dataset)","e2af25f2":"sub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","a4823cc8":"## CutMix","99897ef1":"## TPU Setup","d1addc7b":"## Training","d6a9c864":"## Params","cc75c008":"## Data setup","86538ec7":"As you can see, the images and the labels are interpolated. Note that some are interpolations of images with the same label. In future iterations, we may want to prevent this from happening.","44fa802d":"## Model","bb0360e8":"## Test inference","57c150d7":"## LR Setup","57b8fa16":"# Plant Pathology 2020\n\nThis kernel improves upon the current [highest scoring single model public kernel](https:\/\/www.kaggle.com\/ateplyuk\/fork-of-plant-2020-tpu-915e9c) by introducing CutMix.\n\nThe CutMix implementation is based on [this wonderful kernel](https:\/\/www.kaggle.com\/c\/flower-classification-with-tpus\/discussion\/132935) by [cdeotte](https:\/\/www.kaggle.com\/cdeotte).\n\n## CutMix\n\nCutMix comes from paper [CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features](https:\/\/arxiv.org\/abs\/1905.04899). The idea is to introduce a regularisation strategy that interpolates two images and their labels, similar to [MixUp](https:\/\/arxiv.org\/abs\/1710.09412). However it differs in that it interpolates by \"replacing\nthe image region with a patch from another training image\".\n\n![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F2605845%2Ff29492171d83dfa6b6fcae2af414fcf8%2FCutmix_exmaple.png?generation=1579343294489994&alt=media)\n\nThe major change I've made to the original Plant Pathology kernel is to double the number of epochs as training with higher regularisation tends to require more epochs.\n\nThis kernel can further be extended by trying a combination of MixUp, CutOut and other similar regularisation strategies.","d2a12bf6":"## Visualise"}}