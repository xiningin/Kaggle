{"cell_type":{"69777d75":"code","ddc26c98":"code","1e1ada48":"code","d294e344":"code","a0c433db":"code","99cae37b":"code","ff6f78f7":"code","80829b73":"code","1a2cfffc":"code","ec3b2ccb":"code","858b8d1c":"code","9673df71":"code","efed7f4a":"code","8a1615a9":"code","59499899":"code","bcc143c4":"markdown","0b787865":"markdown","20bf2195":"markdown","076f76d5":"markdown","4fef7a47":"markdown","b35a8623":"markdown","2149e462":"markdown"},"source":{"69777d75":"!pip install -qq pennylane\nimport pennylane as qml\nimport os\nimport cv2\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom pennylane import numpy as np\nfrom pennylane.templates import RandomLayers\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import Subset","ddc26c98":"class MedicatMnist(Dataset):\n    '''\n        Medical MNIST Dataset\n    '''\n    def __init__(self, path, circuit, create_qubits):\n        self.path = path\n        self.main_path = '\/kaggle\/working\/'\n        self.circuit = circuit\n        self.create_qubits = create_qubits\n        \n        paths, categories, qbits_paths = self.absolute_paths(path)\n        self.df = pd.DataFrame.from_dict({'path': paths,\n                                          'category': categories,\n                                          'qbit_path': qbits_paths})\n        self.df = shuffle(self.df)\n        \n    def create_qubits(self, path, save_path):\n        '''\n            Image to qubits\n        '''\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        quanv = self.quanv(image)\n        np.save(save_path, quanv)\n        \n    def absolute_paths(self, path):\n        '''\n            Get absolute paths, qubits_paths and categories\n        '''\n        jpeg_ext = '.jpeg'\n        npy_ext = '.npy'\n        \n        all_cat = list(os.walk(os.path.abspath(path)))[0][1]\n        \n        if(self.create_qubits):\n            for cat in all_cat:\n                try:\n                    os.mkdir(self.main_path + cat)\n                except:\n                    pass\n        \n        self.idx_to_categories = {k:v for k,v in enumerate(all_cat)}\n        self.categories_to_idx = {v:k for k,v in enumerate(all_cat)}\n        \n        paths = []\n        categories = []\n        qbits_paths = []\n        \n        for i, (root, dirs, files) in enumerate(os.walk(os.path.abspath(path))):\n            for file in files:\n                if(jpeg_ext in file):\n                    paths.append(os.path.join(root, file))\n                    categories.append(self.idx_to_categories[i - 1])\n                    \n                if(npy_ext in file):\n                    if(self.create_qubits):\n                        quanv_path = self.main_path + self.idx_to_categories[i - 1] + \\\n                                         '\/' + file.split('.')[0]\n                        qbits_paths.append(quanv_path + '.npy')\n                        self.create_qubits(paths[-1], quanv_path)\n                    else:\n                        qbits_paths.append(os.path.join(root, file))\n            \n        return paths, categories, qbits_paths\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        '''\n            Retrieve image, qubits and label based on idx\n        '''\n        idf = self.df.iloc[idx]\n        \n        path = idf['path']\n        qbit_path = idf['qbit_path']\n        category = idf['category']\n        \n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        qbits = np.load(qbit_path)\n        qbits = torch.tensor(qbits).type(torch.FloatTensor)\n        \n        label = self.categories_to_idx[category]\n        label = torch.tensor(label).type(torch.LongTensor)\n        \n        \n        return image, qbits, label","1e1ada48":"class MedicatMnist_Q(MedicatMnist):\n    def __init__(self, path, circuit, create_qubits=False):\n        super(MedicatMnist_Q, self).__init__(path, circuit, create_qubits)\n    \n    def quanv(self, image):\n        \"\"\"Convolves the input image with many applications of the same quantum circuit.\"\"\"\n        out = np.zeros((14, 14, 4))\n\n        # Loop over the coordinates of the top-left pixel of 2X2 squares\n        for j in range(0, 28, 2):\n            for k in range(0, 28, 2):\n                # Process a squared 2x2 region of the image with a quantum circuit\n                q_results = self.circuit(\n                    [\n                        image[j, k, 0],\n                        image[j, k + 1, 0],\n                        image[j + 1, k, 0],\n                        image[j + 1, k + 1, 0]\n                    ]\n                )\n                # Assign expectation values to different channels of the output pixel (j\/2, k\/2)\n                for c in range(4):\n                    out[j \/\/ 2, k \/\/ 2, c] = q_results[c]\n        return out","d294e344":"dev = qml.device(\"default.qubit\", wires=4)\nn_layers = 1\n# Random circuit parameters\nrand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n\n@qml.qnode(dev)\ndef circuit(phi):\n    # Encoding of 4 classical input values\n    for j in range(4):\n        qml.RY(np.pi * phi[j], wires=j)\n\n    # Random quantum circuit\n    RandomLayers(rand_params, wires=list(range(4)))\n\n    # Measurement producing 4 classical output values\n    return [qml.expval(qml.PauliZ(j)) for j in range(4)]","a0c433db":"path = '..\/input\/medical-mnist-qbits\/'\n\nmm_ds = MedicatMnist_Q(path, circuit)","99cae37b":"plt.imshow(mm_ds[100][0])","ff6f78f7":"train_idx, valid_idx = train_test_split(np.arange(len(mm_ds)), shuffle=False,\n                                        test_size=0.3, random_state=42)","80829b73":"train_subset = Subset(mm_ds, train_idx)\nvalid_subset = Subset(mm_ds, valid_idx)","1a2cfffc":"train_loader = DataLoader(train_subset, batch_size=8,\n                          shuffle=True, num_workers=0)\n\nvalid_loader = DataLoader(valid_subset, batch_size=8,\n                          shuffle=True, num_workers=0)","ec3b2ccb":"model = nn.Sequential(\n          nn.Flatten(),\n          nn.Linear(784, 512),\n          nn.Linear(512, 256),\n          nn.Linear(256, 64),\n          nn.Linear(64, 11),\n          nn.LogSoftmax(1)\n        )\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.0001, momentum=0.9)","858b8d1c":"epochs = 5\naccs_train = np.zeros((epochs, len(train_loader)))\naccs_valid = np.zeros((epochs, len(valid_loader)))\n\nfor e in range(epochs):\n    for i, (images, quvons, labels) in enumerate(train_loader):\n\n        optimizer.zero_grad()\n\n        out = model(quvons)\n        out_hot = torch.max(out, 1)[1]\n\n        loss = criterion(out, labels)\n        loss.backward()\n\n        acc = (out_hot == labels).type(torch.int32).sum().item()\n        acc \/= len(out)\n        accs_train[e][i] = acc\n\n        optimizer.step()\n        \n    with torch.no_grad():\n        for i, (images, quvons, labels) in enumerate(valid_loader):\n            out = model(quvons)\n            out_hot = torch.max(out, 1)[1]\n\n            loss = criterion(out, labels)\n            acc = (out_hot == labels).type(torch.int32).sum().item()\n            acc \/= len(out)\n            accs_valid[e][i] = acc\n            \n    print('epoch:{:2d}\/{:2d}, loss:{:1.3f}, train_acc:{:1.3f}, valid_acc:{:1.3f}'\n            .format(e+1, epochs, loss, \n                    accs_train[e].mean(), accs_valid[e].mean()))","9673df71":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\naxes[0].set_title('Training Accuracy')\naxes[0].plot(accs_train.mean(1))\naxes[0].axes.get_xaxis().set_ticks([])\naxes[1].set_title('Validate Accuracy')\naxes[1].plot(accs_valid.mean(1))\naxes[1].axes.get_xaxis().set_ticks([])\nfig.tight_layout()","efed7f4a":"def predict(image, mm_ds, model):\n    qubits = mm_ds.quanv(image)\n    qubits = torch.tensor(qubits).type(torch.FloatTensor)\n    qubits = qubits.unsqueeze(0)\n    out = model(qubits)\n    out_max = torch.max(out, axis=1)[1].item()\n    label = mm_ds.idx_to_categories[out_max]\n    return label","8a1615a9":"image, _, image_label = mm_ds[10]\nexpt_label = mm_ds.idx_to_categories[image_label.item()]\nplt.title('To Predict: ' + expt_label)\nplt.imshow(image)","59499899":"pred_label = predict(image, mm_ds, model)\nprint(\"Predicted: {} - Expected: {}\"\n         .format(pred_label, expt_label))","bcc143c4":"<h1 id=\"predict\" style=\"color:#b2b2b2; background:#fafafa; border-style:groove;\"> \n    <center>Predict\n        <a class=\"anchor-link\" href=\"#predict\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","0b787865":"<h1 id=\"analyze\" style=\"color:#b2b2b2; background:#fafafa; border-style:groove;\"> \n    <center>Analyze\n        <a class=\"anchor-link\" href=\"#analyze\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","20bf2195":"<div style='width:100%;'>\n    <img style='width:100%;' src='https:\/\/storage.googleapis.com\/kaggle-datasets-images\/1168771\/1958110\/65e4773b360f3e25b8331df57cfd4607\/dataset-cover.jpg' \/>\n<\/div>","076f76d5":"<h1 id=\"training\" style=\"color:#b2b2b2; background:#fafafa; border-style:groove;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","4fef7a47":"![qnn.png](attachment:qnn.png)","b35a8623":"<h1 id=\"circuit\" style=\"color:#b2b2b2; background:#fafafa; border-style:groove;\"> \n    <center>Quantum Implementation\n        <a class=\"anchor-link\" href=\"#circuit\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","2149e462":"<h1 id=\"dataset\" style=\"color:#b2b2b2; background:#fafafa; border-style:groove;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}