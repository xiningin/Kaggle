{"cell_type":{"bebdcc69":"code","12d14444":"code","0901d3d3":"code","8eafcfc6":"code","8aa4d996":"code","7ff92c69":"code","2783896a":"code","95b73b99":"code","76ebddbd":"code","2663e61f":"code","5514d13c":"code","7131ea70":"markdown","874a2a55":"markdown","974aad54":"markdown","bbc979f6":"markdown","eed8da7d":"markdown","2dbd9a18":"markdown"},"source":{"bebdcc69":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","12d14444":"data = pd.read_csv('..\/input\/performance-prediction\/summary.csv')","0901d3d3":"data","8eafcfc6":"data.info()","8aa4d996":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop Name column\n    df = df.drop('Name', axis=1)\n    \n    # Fill missing values\n    df['3PointPercent'] = df['3PointPercent'].fillna(df['3PointPercent'].mean())\n    \n    # Split df into X and y\n    y = df['Target']\n    X = df.drop('Target', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","7ff92c69":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","2783896a":"X_train","95b73b99":"y_train","76ebddbd":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\n\nacc = model.score(X_test, y_test)\n\nprint(\"Test Accuracy: {:.2f}%\".format(acc * 100))","2663e61f":"pca = PCA(n_components=2)\nX_reduced = pd.DataFrame(pca.fit_transform(X_train), index=X_train.index, columns=[\"PC1\", \"PC2\"])\n\nkmeans = KMeans(n_clusters=4)\nkmeans.fit(X_train)\nclusters = pd.Series(kmeans.labels_, name=\"Cluster\", index=X_train.index)\ncentroids = pca.transform(kmeans.cluster_centers_)\n\nX_reduced = pd.concat([X_reduced, y_train, clusters], axis=1)\nX_reduced","5514d13c":"plt.figure(figsize=(10, 10))\nplt.scatter(X_reduced['PC1'], X_reduced['PC2'], c=X_reduced['Cluster'])\nplt.scatter(centroids[:, 0], centroids[:, 1], color='red', s=300)\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.title(\"k-means Clustering\")\nplt.show()","7131ea70":" # Training","874a2a55":"# Clustering (k-means)","974aad54":"# Task for Today  \n\n***\n\n## Basketball Performance Prediction  \n\nGiven *data about basketball players*, let's try to predict the **length of career** for a given player.\n\nWe will use a logistic regression model to make our predictions. ","bbc979f6":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/p3uysBjzoeA","eed8da7d":"# Getting Started","2dbd9a18":"# Preprocessing"}}