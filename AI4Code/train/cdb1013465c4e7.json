{"cell_type":{"33df0d08":"code","10d0a290":"code","785b4607":"code","739c7ded":"code","46ddbe8c":"code","5274b00d":"code","73f52164":"code","a12327df":"code","41d482d7":"code","e0b3ae25":"code","41b011d9":"code","7976cc96":"code","652b8b09":"code","716e9b5c":"code","f7001b49":"code","9822dfe6":"code","f1bf75f0":"code","da872f52":"code","3fbf8132":"code","b69b0ffa":"code","66e50a68":"code","9395cc02":"markdown","57538715":"markdown","9e238c27":"markdown","b4fc4e0c":"markdown","03f73e0b":"markdown","e819002e":"markdown"},"source":{"33df0d08":"### Importar librerias necesarias\nimport numpy as np\nimport pandas as pd\n \nimport xgboost as xgb\nfrom sklearn import metrics, model_selection","10d0a290":"data_path = \"..\/input\/\"\norders_df = pd.read_csv(data_path + \"orders.csv\", usecols=[\"order_id\",\"user_id\",\"order_number\"])","785b4607":"aisles=pd.read_csv('..\/input\/aisles.csv')\ndepartments=pd.read_csv('..\/input\/departments.csv')\norders=pd.read_csv('..\/input\/orders.csv')\norderp=pd.read_csv('..\/input\/order_products__prior.csv')\nordert=pd.read_csv('..\/input\/order_products__train.csv')\nproducts=pd.read_csv('..\/input\/products.csv')","739c7ded":"aisles.head()\nprint('Total pasillos: {}'.format(aisles.shape[0]))","46ddbe8c":"departments.head()\nprint('Total departamentos: {}'.format(departments.shape[0]))","5274b00d":"orders.head()\nprint('Total pedidos: {}'.format(orders.shape[0]))","73f52164":"orderp.head()\nprint('Total pedidosP: {}'.format(orderp.shape[0]))","a12327df":"ordert.head()\nprint('Total pedidosT: {}'.format(ordert.shape[0]))","41d482d7":"products.head()\nprint('Total productos: {}'.format(products.shape[0]))","e0b3ae25":"# Combinanaci\u00f3n pasillos, departamentos y productos (left joined to products)\ngoods = pd.merge(left=pd.merge(left=products, right=departments, how='left'), right=aisles, how='left')\n# para conservar '-' y hacer que los nombres de los productos sean m\u00e1s \"est\u00e1ndar\"\ngoods.product_name = goods.product_name.str.replace(' ', '_').str.lower() \n\ngoods.head()","41b011d9":"import matplotlib.pyplot as plt # plotting\n\n\n# informaci\u00f3n b\u00e1sica del grupo (departamentos)\nplt.figure(figsize=(12, 5))\ngoods.groupby(['department']).count()['product_id'].copy()\\\n.sort_values(ascending=False).plot(kind='bar', \n                                   #figsize=(12, 5), \n                                   title='Departments: Product #')\n\n\n# informaci\u00f3n b\u00e1sica del grupo (top-x aisles)\ntop_aisles_cnt = 15\nplt.figure(figsize=(12, 5))\ngoods.groupby(['aisle']).count()['product_id']\\\n.sort_values(ascending=False)[:top_aisles_cnt].plot(kind='bar', \n                                   #figsize=(12, 5), \n                                   title='Aisles: Product #')\n\n# Volumen de departamentos de parcelas, dividido por pasillos.\nf, axarr = plt.subplots(6, 4, figsize=(12, 30))\nfor i,e in enumerate(departments.department.sort_values(ascending=True)):\n    axarr[i\/\/4, i%4].set_title('Dep: {}'.format(e))\n    goods[goods.department==e].groupby(['aisle']).count()['product_id']\\\n    .sort_values(ascending=False).plot(kind='bar', ax=axarr[i\/\/4, i%4])\nf.subplots_adjust(hspace=2)","7976cc96":"# leer el archivo de pedido anterior #\nprior_df = pd.read_csv(data_path + \"order_products__prior.csv\")\n\n# fusionarse con el archivo de pedidos para obtener el user_id #\nprior_df = pd.merge(prior_df, orders_df, how=\"inner\", on=\"order_id\")\n\n# Obtenga los productos y reordene el estado de la \u00faltima compra de cada usuario.#\nprior_grouped_df = prior_df.groupby(\"user_id\")[\"order_number\"].aggregate(\"max\").reset_index()\nprior_df_latest = pd.merge(prior_df, prior_grouped_df, how=\"inner\", on=[\"user_id\", \"order_number\"])\nprior_df_latest = prior_df_latest[[\"user_id\", \"product_id\", \"reordered\"]]\nprior_df_latest.columns = [\"user_id\", \"product_id\", \"reordered_latest\"]\n\n# Obtenga el recuento de cada producto y el n\u00famero de pedidos por parte del cliente #\nprior_df = prior_df.groupby([\"user_id\",\"product_id\"])[\"reordered\"].aggregate([\"count\", \"sum\"]).reset_index()\nprior_df.columns = [\"user_id\", \"product_id\", \"reordered_count\", \"reordered_sum\"]\n\n# fusionar el df anterior con el \u00faltimo df#\nprior_df = pd.merge(prior_df, prior_df_latest, how=\"left\", on=[\"user_id\",\"product_id\"])\nprior_df.head()","652b8b09":"orders_df.drop([\"order_number\"],axis=1,inplace=True)\n\ntrain_df = pd.read_csv(data_path + \"order_products__train.csv\", usecols=[\"order_id\"])\ntrain_df = train_df.groupby(\"order_id\").aggregate(\"count\").reset_index()\ntest_df = pd.read_csv(data_path + \"sample_submission.csv\", usecols=[\"order_id\"])\ntrain_df = pd.merge(train_df, orders_df, how=\"inner\", on=\"order_id\")\ntest_df = pd.merge(test_df, orders_df, how=\"inner\", on=\"order_id\")\nprint(train_df.shape, test_df.shape)","716e9b5c":"train_df = pd.merge(train_df, prior_df, how=\"inner\", on=\"user_id\")\ntest_df = pd.merge(test_df, prior_df, how=\"inner\", on=\"user_id\")\ndel prior_df, prior_grouped_df, prior_df_latest\nprint(train_df.shape, test_df.shape)","f7001b49":"products_df = pd.read_csv(data_path + \"products.csv\", usecols=[\"product_id\", \"aisle_id\", \"department_id\"])\ntrain_df = pd.merge(train_df, products_df, how=\"inner\", on=\"product_id\")\ntest_df = pd.merge(test_df, products_df, how=\"inner\", on=\"product_id\")\ndel products_df\nprint(train_df.shape, test_df.shape)","9822dfe6":"train_y_df = pd.read_csv(data_path + \"order_products__train.csv\", usecols=[\"order_id\", \"product_id\", \"reordered\"])\ntrain_y_df = pd.merge(train_y_df, orders_df, how=\"inner\", on=\"order_id\")\ntrain_y_df = train_y_df[[\"user_id\", \"product_id\", \"reordered\"]]\n#print(train_y_df.reordered.sum())\ntrain_df = pd.merge(train_df, train_y_df, how=\"left\", on=[\"user_id\", \"product_id\"])\ntrain_df[\"reordered\"].fillna(0, inplace=True)\nprint(train_df.shape)\n#print(train_df.reordered.sum())\ndel train_y_df","f1bf75f0":"# target variable for train set #\ntrain_y = train_df.reordered.values\n\n# marco de datos para las predicciones del conjunto de pruebas #\nout_df = test_df[[\"order_id\", \"product_id\"]]\n\n# soltar las columnas innecesarias #\ntrain_df = np.array(train_df.drop([\"order_id\", \"user_id\", \"reordered\"], axis=1))\ntest_df = np.array(test_df.drop([\"order_id\", \"user_id\"], axis=1))\nprint(train_df.shape, test_df.shape)","da872f52":"# funci\u00f3n para ejecutar el modelo xgboost #\ndef runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0):\n        params = {}\n        params[\"objective\"] = \"binary:logistic\"\n        params['eval_metric'] = 'logloss'\n        params[\"eta\"] = 0.05\n        params[\"subsample\"] = 0.7\n        params[\"min_child_weight\"] = 10\n        params[\"colsample_bytree\"] = 0.7\n        params[\"max_depth\"] = 8\n        params[\"silent\"] = 1\n        params[\"seed\"] = seed_val\n        num_rounds = 100\n        plst = list(params.items())\n        xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n        if test_y is not None:\n                xgtest = xgb.DMatrix(test_X, label=test_y)\n                watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n                model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n        else:\n                xgtest = xgb.DMatrix(test_X)\n                model = xgb.train(plst, xgtrain, num_rounds)\n\n        pred_test_y = model.predict(xgtest)\n        return pred_test_y","3fbf8132":"# ejecuta el modelo xgboost #\npred = runXGB(train_df, train_y, test_df)\ndel train_df, test_df\n\n# Usa valor cut-off para obtener las predicciones #\ncutoff = 0.2\npred[pred>=cutoff] = 1\npred[pred<cutoff] = 0\nout_df[\"Pred\"] = pred\nout_df = out_df.ix[out_df[\"Pred\"].astype('int')==1]","b69b0ffa":"# cuando hay m\u00e1s de 1 producto, fusionarlos en una sola cadena #\ndef merge_products(x):\n    return \" \".join(list(x.astype('str')))\nout_df = out_df.groupby(\"order_id\")[\"product_id\"].aggregate(merge_products).reset_index()\nout_df.columns = [\"order_id\", \"products\"]","66e50a68":"# lea el archivo csv de muestra y rellene los productos de las predicciones #\nsub_df = pd.read_csv(data_path + \"sample_submission.csv\", usecols=[\"order_id\"])\nsub_df = pd.merge(sub_df, out_df, how=\"left\", on=\"order_id\")\n\n# cuando no hay predicciones usa \"ninguna\" #\nsub_df[\"products\"].fillna(\"None\", inplace=True)\nsub_df.to_csv(\"xgb_starter_3450.csv\", index=False)","9395cc02":"El archivo products.csv contiene informaci\u00f3n sobre los productos, como a qu\u00e9 departamento y pasillo pertenece el producto en cuesti\u00f3n. As\u00ed que fusionear el entrenamiento y los datos de prueba con la informaci\u00f3n del producto.","57538715":"* Para predecir qu\u00e9 productos comprados anteriormente estar\u00e1n en el pr\u00f3ximo pedido de un usuario\n\nComenzaremos con la lectura del archivo de pedidos.","9e238c27":"Dado que el objetivo es predecir qu\u00e9 productos comprados anteriormente estar\u00e1n en el pr\u00f3ximo pedido, primero obtengamos la lista de todos los productos comprados por el cliente.","b4fc4e0c":"Ahora tenemos todos los productos que el cliente ha comprado anteriormente, junto con algunas caracter\u00edsticas. Por lo tanto, podemos usar el conjunto de datos del entrenamiento para rellenar la variable objetivo, es decir, el producto se ha reordenado en el siguiente orden.","03f73e0b":"Combinar el entrenamiento y los datos de prueba con prior_df para obtener los productos comprados previamente por el cliente.","e819002e":"Lea el entrenamiento y el conjunto de datos de prueba y luego fusionar con los datos de los pedidos para obtener el user_id para el order_id correspondiente."}}