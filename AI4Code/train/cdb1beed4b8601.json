{"cell_type":{"c891be1d":"code","402918d8":"code","b19143a6":"code","39b17fba":"code","c0c66eda":"code","6cf985c7":"code","4e5c3466":"code","20102e18":"code","a107c460":"code","f4f7ec04":"code","3a0483e3":"code","ae61c60c":"code","79412993":"code","3af029b9":"code","31224db9":"code","ae164ea6":"code","68b81f88":"code","1c421320":"code","e2bdb63b":"code","4e4ba0ab":"code","c0380ca8":"code","73d32311":"code","8f50599b":"code","62bbc17d":"code","4ffaa00f":"code","64af4709":"code","ca080223":"code","cb7b4653":"code","ea700d70":"code","61a3be69":"code","929b3f27":"code","1d5afdb7":"code","c0a2dfff":"code","d4251532":"code","99144650":"code","aa74dca9":"code","24adf68f":"code","7b4782df":"code","f3264d71":"code","141a38ef":"code","b85e7a47":"code","5d3db551":"code","0059b818":"code","43baed05":"code","90674032":"code","483f994a":"code","d372afbd":"code","85296fc1":"code","07c577ca":"markdown","4a7b7ce0":"markdown","a26a9dd8":"markdown","dcf05193":"markdown","e9b849d7":"markdown","854c877a":"markdown","bc8623ea":"markdown","f751aed3":"markdown","fd97b55e":"markdown","c11adf98":"markdown","78d78f9f":"markdown","45a225de":"markdown","f83c3d52":"markdown","3929b7fd":"markdown","7819d9b9":"markdown","8a0f63ce":"markdown","25c1b4a3":"markdown","ef927784":"markdown","9109a298":"markdown","87b6381c":"markdown","af8b536a":"markdown","e76b06f7":"markdown","f637e45e":"markdown","b30c5e2e":"markdown","33e51c2f":"markdown","cc503605":"markdown","cfc8acb6":"markdown","e6f1916a":"markdown","01f080cb":"markdown"},"source":{"c891be1d":"from scipy import stats\nfrom scipy.stats import randint\nfrom time import time \nimport pandas as pd\nimport pandas_profiling as pp\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier \nfrom sklearn.model_selection import cross_validate\nfrom sklearn import metrics  \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV \nimport pickle\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 400)\nfrom matplotlib import pyplot\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import average_precision_score\nfrom xgboost import plot_importance\nimport os","402918d8":"print(os.listdir(\"..\/input\"))","b19143a6":"df = pd.read_csv(\"..\/input\/loandata\/data_assessments_5k.csv\")\ndf1 = pd.read_csv(\"..\/input\/loandata\/data_loans_5k.csv\")","39b17fba":"df = pd.merge(df1,df,how='inner',on='master_user_id')","c0c66eda":"df.shape","6cf985c7":"def quality_report(df):\n \n    dtypes = df.dtypes\n    nuniq = df.T.apply(lambda x: x.nunique(), axis=1)\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = (df.isnull().sum()\/df.isnull().count()*100).sort_values(ascending = False)\n    quality_df = pd.concat([total, percent, nuniq, dtypes], axis=1, keys=['Total', 'Percent','Nunique', 'Dtype'])\n    display(quality_df)","4e5c3466":"quality_report(df)","20102e18":"Report = pp.ProfileReport(df,minimal=True)","a107c460":"df = df.drop([\"assessment_rules\",\n\"bureau\",\n\"cc_kotak_bank_count\",\n\"cibil_salary_date_reported\",\n\"cibil_salary_estimate_type\",\n\"created_at\",\n\"crif_account_purchased_and_restructured_count_52\",\n\"crif_account_purchased_and_restructured_count_52_260\",\n\"crif_account_purchased_and_settled_count_52\",\n\"crif_account_purchased_and_settled_count_52_260\",\n\"crif_account_purchased_count_52\",\n\"crif_account_purchased_count_52_260\",\n\"crif_account_sold_count_52\",\n\"crif_account_sold_count_52_260\",\n\"crif_account_summary\",\n\"crif_accounts_count\",\n\"crif_inquiry_count_9\",\n\"crif_issue_date\",\n\"crif_no_suit_filed_count_52\",\n\"crif_no_suit_filed_count_52_260\",\n\"crif_obligations\",\n\"crif_post_wo_settled_count_52\",\n\"crif_post_wo_settled_count_52_260\",\n\"crif_restructured_due_to_natural_calamity_count_52\",\n\"crif_restructured_due_to_natural_calamity_count_52_260\",\n\"crif_restructured_loan_count_52\",\n\"crif_restructured_loan_count_52_260\",\n\"crif_restructured_loan_govt_mandated_count_52\",\n\"crif_restructured_loan_govt_mandated_count_52_260\",\n\"crif_score\",\n\"crif_settled_count_52\",\n\"crif_settled_count_52_260\",\n\"crif_suit_filed_count_52\",\n\"crif_suit_filed_count_52_260\",\n\"crif_suit_filed_wilful_default_count_52\",\n\"crif_suit_filed_wilful_default_count_52_260\",\n\"crif_sum_overdue_amount_52\",\n\"crif_sum_overdue_amount_52_260\",\n\"crif_sum_overdue_amount_cc_52\",\n\"crif_sum_overdue_amount_cc_52_260\",\n\"crif_sum_overdue_amount_non_cc_52\",\n\"crif_sum_overdue_amount_non_cc_52_260\",\n\"crif_unique_reference_number\",\n\"crif_wilful_default_count_52\",\n\"crif_wilful_default_count_52_260\",\n\"crif_written_off_and_account_sold_count_52\",\n\"crif_written_off_and_account_sold_count_52_260\",\n\"crif_written_off_count_52\",\n\"crif_written_off_count_52_260\",\n\"employer\",\n\"employer_category\",\n\"employer_id\",\n\"is_approved_flexi\",\n\"is_approved_premium\",\n\"network_contacts_in_cibil_score_average\",\n\"network_contacts_in_cibil_score_median\",\n\"network_contacts_in_cibil_score_negative_count\",\n\"network_contacts_in_cibil_wilful_defaults_count\",\n\"network_contacts_in_cibil_write_offs_count\",\n\"network_contacts_in_declined_users_count\",\n\"network_contacts_in_disbursed_users_count\",\n\"network_contacts_in_dpd_30_users_count\",\n\"network_contacts_in_dpd_60_users_count\",\n\"network_contacts_in_dpd_90_users_count\",\n\"network_contacts_in_ps_users_count\",\n\"network_contacts_in_rejected_users_count\",\n\"network_contacts_in_users_count\",\n\"network_contacts_out_cibil_score_average\",\n\"network_contacts_out_cibil_score_median\",\n\"network_contacts_out_cibil_score_negative_count\",\n\"network_contacts_out_cibil_wilful_defaults_count\",\"disbursed_at\",\"perfios_salary_estimate_type\",\"salary_estimate_type\"], axis = 1) ","f4f7ec04":"df.sort_values(\"updated_at\", ascending = False,inplace=True) ","3a0483e3":"df.drop_duplicates(subset =\"master_user_id\", \n                     keep = \"first\", inplace = True)","ae61c60c":"df.drop('updated_at',inplace = True,axis=1)","79412993":"df.select_dtypes('object')","3af029b9":"df.is_non_starter = np.where(df.is_non_starter=='True', 1,df.is_non_starter)\ndf.is_non_starter = np.where(df.is_non_starter=='False', 0,df.is_non_starter)\n\ndf.product_type = np.where(df.product_type=='flexi', 1,df.product_type)\ndf.product_type = np.where(df.product_type=='premium', 0,df.product_type)","31224db9":"df = df.drop(['city','reason_premium','reason_flexi'],axis=1)","ae164ea6":"df = df.fillna(0)","68b81f88":"df['Target'] = np.where(df.max_dpd >= 30, 1, 0)","1c421320":"plt.figure(figsize=(6,3))\nsns.countplot(x='Target',data=df)\nplt.show()\n \n# Checking the event rate : event is when claim is made\ndf['Target'].value_counts()","e2bdb63b":"X = df.iloc[:,0:382]\ny= df.iloc[:,382:383]","4e4ba0ab":"seed=63 ","c0380ca8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nprint(X_train.shape,y_train.shape)","73d32311":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components = 30)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","8f50599b":"param_grid = {'n_estimators': [ 30, 35, 25],\n                    'learning_rate': [ 0.1, 0.15,0.2],\n                    'gamma':  [0.20,0.10, 0.15],\n                    'max_delta_step': [24, 26, 22],\n                    'max_depth':[4, 3, 5],\n             'min_child_weight': [1, 2, 3, 4]}       \n\nclf = RandomizedSearchCV(xgb, n_iter = 50, param_distributions=param_grid, cv=3, n_jobs=-1, verbose=2)","62bbc17d":"clf","4ffaa00f":"xgb = XGBClassifier(n_estimators=30,\n max_depth= 5,\n gamma = 0.2,\nmin_child_weight = 5)","64af4709":"model = xgb.fit(X_train, y_train)","ca080223":"y_pred=model.predict(X_test)\ny_pred = pd.DataFrame(y_pred)","cb7b4653":"y_pred[0].value_counts()","ea700d70":"print('AUPRC = {}'.format(average_precision_score(y_test, y_pred.iloc[:,0])))","61a3be69":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test, y_pred)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))","929b3f27":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\ndisp = plot_precision_recall_curve(xgb, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","1d5afdb7":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","c0a2dfff":"\nfig = plt.figure(figsize = (14, 9))\nax = fig.add_subplot(111)\n\ncolours = plt.cm.Set1(np.linspace(0, 1, 9))\n\nax = plot_importance(xgb, height = 1, color = colours, grid = False, \\\n                     show_values = False, importance_type = 'cover', ax = ax);\nfor axis in ['top','bottom','left','right']:\n            ax.spines[axis].set_linewidth(2)\n        \nax.set_xlabel('importance score', size = 16);\nax.set_ylabel('features', size = 16);\nax.set_yticklabels(ax.get_yticklabels(), size = 12);\nax.set_title('Ordering of features by importance to the model learnt', size = 20);","d4251532":"df = df.drop([\n\"network_contacts_out_cibil_write_offs_count\",\n\"network_contacts_out_declined_users_count\",\n\"network_contacts_out_disbursed_users_count\",\n\"network_contacts_out_dpd_30_users_count\",\n\"network_contacts_out_dpd_60_users_count\",\n\"network_contacts_out_dpd_90_users_count\",\n\"network_contacts_out_ps_users_count\",\n\"network_contacts_out_rejected_users_count\",\n\"network_contacts_out_users_count\",\n\"perfios_salary_day_of_month\",\n\"postal_code\",\n\"rule_engine_output\",\n\"salary_day_of_month\",\n\"scheme\",\n\"state\",\n\"version\"],axis=1)","99144650":"X = df.iloc[:,0:366]\ny= df.iloc[:,366:367]","aa74dca9":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","24adf68f":"from sklearn.decomposition import PCA\n\npca = PCA()\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","7b4782df":"param_grid = {'n_estimators': [ 30, 35, 25],\n                    'learning_rate': [ 0.1, 0.15,0.2],\n                    'gamma':  [0.20,0.10, 0.15],\n                    'max_delta_step': [24, 26, 22],\n                    'max_depth':[4, 3, 5],\n             'min_child_weight': [1, 2, 3, 4]}       \n\nclf = RandomizedSearchCV(xgb, n_iter = 50, param_distributions=param_grid, cv=3, n_jobs=-1, verbose=2)\n","f3264d71":"clf","141a38ef":"xgb = XGBClassifier(n_estimators=35,\n max_depth= 3,\n max_delta_step = 26,\n learning_rate = 0.15,\n gamma = 0.1,\nmin_child_weight = 3)","b85e7a47":"model = xgb.fit(X_train, y_train)","5d3db551":"y_pred=model.predict(X_test)\ny_pred = pd.DataFrame(y_pred)","0059b818":"y_pred[0].value_counts()","43baed05":"print('AUPRC = {}'.format(average_precision_score(y_test, y_pred.iloc[:,0])))","90674032":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test, y_pred)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))","483f994a":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\ndisp = plot_precision_recall_curve(xgb, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","d372afbd":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","85296fc1":"from sklearn.linear_model import RidgeClassifier\nfrom sklearn.model_selection import train_test_split as tts\nfrom yellowbrick.classifier import PrecisionRecallCurve\nfrom yellowbrick.datasets import load_spam\n\n# Load the dataset and split into train\/test splits\n#X, y = load_spam()\n\n#X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, shuffle=True)\n\n# Create the visualizer, fit, score, and show it\nviz = PrecisionRecallCurve(RidgeClassifier())\nviz.fit(X_train, y_train)\nviz.score(X_test, y_test)\nviz.show()","07c577ca":"### Again Applying Machine learning Algorithm with some further fine tunning parameters for improving the accuracy and reducing overfitting","4a7b7ce0":"### Calculating Feature Importance and  dropping the features with less importance from the dataset","a26a9dd8":"for col in df.drop('Target',axis=1).columns:\n    if df[col].dtype == 'object' or df[col].nunique():\n        xx = df.groupby(col)['Target'].value_counts().unstack(1)\n        per_not_promoted = xx.iloc[:, 0] *100\/xx.apply(lambda x: x.sum(), axis=1)\n        per_promoted = xx.iloc[:, 1]*100\/xx.apply(lambda x: x.sum(), axis=1)\n        xx['%_0'] = per_not_promoted\n        xx['%_1'] = per_promoted\n        display(xx)\n ","dcf05193":"### Checking the Accuracy of the model","e9b849d7":"### Creating Dummy Variables","854c877a":"### Average Precision-recall graph","bc8623ea":"# Loan Default Predicition- XG Boost","f751aed3":"### Dropping all the variables which are relevant for the further process of the Modelling","fd97b55e":"### Approach followed:\n1. Import relevant libraries and data : Import data and correct the spelling of original column headers for consistency if required\n2. Feature Selection : Find the relevance and importance of each feature with the dependent variable.(Used Panpas_profiling)\n3. Data Cleaning - Removing unnecessary blank columns,higly correlated columns and various other operations\n4. Imputation of Latent Missing Values\n5. Run Machine Learning (with feature engineering)\n6. Check the AUC-ROC Curve and value\n7. Check the Average precision-recall value (Check if the model is overfitting,underfitting or not)\n8. Plot the Precision-Recall Classes curve.\n9. Further applying feautre Importance function of XG boost, I removed few more variables which were not providing that much value to the model.\n10. Applied few more XG Boost hyperparameter tunning conditions to the model for improving the accuracy and reducing the overfitting.\n11. Comparison of Old Average Precision-Recall(Before tuning) vs the New Average Precision Recall(After tuning) \n12. Accuracy comparison between Old(Before tuning) and New model(After tuning).","c11adf98":"### Sorting the data as per the latest one :                                   Feature used - \"Updated at\" (or latest Disbursal_date can also be used)","78d78f9f":"### Dropping the duplicate records : Subset - \"master_user_id\" and keeping the first one","45a225de":"### Segregation of Dependent variable(y) and Independent variable(X)","f83c3d52":"### AUC value after hyper parameter tuning","3929b7fd":"### Dividing the dataset into training and testing","7819d9b9":"### Improved accuracy after applying feature importance and hyperparameter tuning","8a0f63ce":"### Plot for fit Score","25c1b4a3":"dummies = pd.get_dummies(X, columns=['reason_flexi'])\n\nX= pd.concat([X,dummies], axis=1)      \nX.drop(['reason_flexi'], inplace=True, axis=1)","ef927784":"### Creating the Dependent Variable : max_DPD >= 30 then 1 else 0","9109a298":"### Merge the two provided datasets","87b6381c":"### Checking the AUC value","af8b536a":"### Checking the no. of variables with Datatype : \"Object and Boolean\"  for converting them into dummy variables and avoiding the dummy variable trap as well","e76b06f7":"### Check for missing values in each and every feature","f637e45e":"### Applying Machine learning Algorithm - XG Boost ","b30c5e2e":"### Detailed Analysis of each and every feature using pandas_profiling","33e51c2f":"### Precision-recall plot after tuning","cc503605":"### Import relevant libraries and data","cfc8acb6":"### Distribution of Dependent variable with the data","e6f1916a":"### Average Precision-recall after applying feature importance and few other tuning parameters","01f080cb":"### Checking the Precision-recall value"}}