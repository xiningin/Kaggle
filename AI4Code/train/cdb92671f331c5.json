{"cell_type":{"932ea312":"code","f589e230":"code","4c46bd98":"code","bdadcc4c":"code","d8c2e4a2":"code","5159488a":"code","caa1b34b":"code","9d711820":"code","644b04da":"code","c270fe1a":"code","bd1e4d46":"code","a77559ee":"code","da737fa7":"code","26212227":"code","c1bf3abd":"code","4c0dcecd":"code","61723564":"code","16c15380":"code","a43a9602":"code","f7b35868":"code","2d0779ce":"code","eb99750f":"code","6c61a97f":"code","7db61ca8":"code","8467f9f0":"code","00ed274d":"code","96ae92e3":"code","8f9410f6":"code","fc1916e6":"code","9de31876":"markdown","a439761c":"markdown","24193b59":"markdown","29b79e50":"markdown"},"source":{"932ea312":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f589e230":"datatrain = pd.read_csv(\"\/kaggle\/input\/us-airbnb-open-data\/AB_US_2020.csv\")","4c46bd98":"datatrain.head()","bdadcc4c":"datatrain.describe()","d8c2e4a2":"datatrain.set_index(\"id\")","5159488a":"plt.rcParams['figure.figsize']=12,12\ng = sns.heatmap(datatrain.corr(),annot=True)","caa1b34b":"datatrain[\"neighbourhood\"].nunique()","9d711820":"datatrain[\"neighbourhood\"].unique()","644b04da":"datatrain.drop(\"last_review\",inplace=True,axis=1)\ndatatrain.drop(\"host_name\",inplace=True,axis=1)","c270fe1a":"datatrain.drop(\"name\",inplace=True,axis=1)","bd1e4d46":"datatrain.neighbourhood_group=datatrain.neighbourhood_group.fillna(0)","a77559ee":"datatrain.neighbourhood_group.value_counts(0)","da737fa7":"datatrain.neighbourhood.value_counts()","26212227":"from sklearn.preprocessing import LabelEncoder\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ndatatrain['neighbourhood'] = labelencoder.fit_transform(datatrain[\"neighbourhood\"])\ndatatrain","c1bf3abd":"datatrain.describe()","4c0dcecd":"datatrain.room_type.value_counts()","61723564":"y = pd.get_dummies(datatrain.room_type, prefix='RT')\ndatatrain = datatrain.join(y)","16c15380":"y = pd.get_dummies(datatrain.neighbourhood_group, prefix='NBG')\ndatatrain = datatrain.join(y)","a43a9602":"datatrain.drop(\"neighbourhood_group\",axis=1,inplace=True)","f7b35868":"datatrain[\"reviews_per_month\"].fillna(datatrain.mean(),inplace=True)","2d0779ce":"datatrain[\"reviews_per_month\"].value_counts()","eb99750f":"datatrain.drop(\"room_type\",axis=1,inplace=True)","6c61a97f":"datatrain.describe().columns","7db61ca8":"datatrain.columns","8467f9f0":"y = pd.get_dummies(datatrain.city)\ndatatrain = datatrain.join(y)\ndatatrain.drop(\"city\",axis=1,inplace=True)","00ed274d":"datatrain","96ae92e3":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nX=datatrain.drop(\"price\",axis=1)\ny = datatrain.price\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","8f9410f6":"from sklearn.model_selection import RandomizedSearchCV\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0,2],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\nxgb = XGBRegressor()\nrs = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, n_jobs=4, cv=5, verbose=3, random_state=1001 )\nrs.fit(X_train, y_train)","fc1916e6":"y_pred0 = rs.best_estimator_.predict(X_train)\ny_pred = rs.best_estimator_.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_train, y_pred0)))\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))","9de31876":"We drop attributes like \"last_review\", \"host_name\" and \"name\" as they would not correlate to the prices. \"Host_name\" is dropped as there is already a \"host_id\" column which is used ","a439761c":"We set the index as \"id\"","24193b59":"**Here i have used XGBRegressor to predict the prices. The RMSE values can be improved upon but this just a starter pack for anywhere who wants to work with XGB. I have one hot encoded categorical variables and have also droped some attributes. Ideally, the longtitude and latitude attribute could have been handled better. Also using stacked models may improve results.**","29b79e50":"We create a new class for neighbourhood group with \"null\" and set all of them as 0"}}