{"cell_type":{"b75e9ef7":"code","74579b54":"code","403d2234":"code","5e981c60":"code","aab4aefa":"code","86763e58":"code","8a90ad33":"code","32b2b459":"code","4cc47aa8":"code","cbe47e38":"code","d1ff05cf":"code","b4432174":"code","71f19c03":"code","ba4f4785":"code","36e71166":"code","60dc34d0":"code","23a1e061":"code","fd18e69d":"code","0f85e0c0":"code","21c48a91":"code","626c02a1":"code","823a25f1":"code","20cb5f3a":"code","48cdd1fa":"code","c9a805cb":"code","49b3bdaa":"code","6e1c2aff":"markdown","e2cdf53b":"markdown","01484d0b":"markdown","a23cee57":"markdown","a29dcd35":"markdown","25ecccce":"markdown","5cc190ea":"markdown","5d42e805":"markdown","fcb7f533":"markdown","ad4476ee":"markdown","8f7396d1":"markdown","f2fa1349":"markdown","900daf38":"markdown","50f01c7e":"markdown","35abb310":"markdown","480024bd":"markdown","b97381cd":"markdown","ffe43750":"markdown","e51c98a2":"markdown","da01391f":"markdown","9448a1ee":"markdown","75f82e92":"markdown"},"source":{"b75e9ef7":"import os\nimport cv2\nimport seaborn as sns\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import add\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nnp.random.seed(777)\ntf.random.set_seed(777)","74579b54":"tf.__version__","403d2234":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","5e981c60":"BATCH_SIZE = 32\nIMG_HEIGHT = 240\nIMG_WIDTH = 240\nALPHA = 2e-4","aab4aefa":"labels = ['PNEUMONIA', 'NORMAL']\ndef get_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) \n                resized_arr = cv2.resize(img_arr, (IMG_WIDTH, IMG_HEIGHT))\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                pass\n\n    return np.array(data)","86763e58":"train = get_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\ntest = get_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test')\nval = get_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val')","8a90ad33":"print(f\"{[y for _, y in train].count(1)} PNEUMONIA IMAGES IN TRAINING SET\")\nprint(f\"{[y for _, y in train].count(0)} NORMAL IMAGES IN TRAINING SET\")","32b2b459":"print(f'Images in TRAINING SET: {train.shape[0]}')\nprint(f'Images in VALIDATION SET: {val.shape[0]}')\nprint(f'Images in TEST SET: {test.shape[0]}')","4cc47aa8":"train = np.append(train, val, axis=0)\ntrain, val = train_test_split(train, test_size=.20, random_state=777)","cbe47e38":"plt.figure(figsize=(10, 10))\nfor k, i in np.ndenumerate(np.random.randint(train.shape[0], size=9)):\n    ax = plt.subplot(3, 3, k[0] + 1)\n    plt.imshow(train[i][0], cmap='gray')\n    plt.title(labels[train[i][1]])\n    plt.axis(\"off\")","d1ff05cf":"def prepare_data(data):\n    x = []\n    y = []\n    \n    for feature, label in data:\n        x.append(feature)\n        y.append(label)\n        \n    x = (np.array(x) \/ 255).reshape(-1,IMG_WIDTH, IMG_HEIGHT, 1)\n    y = np.array(y)\n        \n    return x, y\n\nx_train, y_train = prepare_data(train)\nx_val, y_val = prepare_data(val)\nx_test, y_test = prepare_data(test)","b4432174":"datagen = ImageDataGenerator(\n    rotation_range = 20, \n    zoom_range = 0.2, \n    width_shift_range=0.15,  \n    height_shift_range=0.15,\n    horizontal_flip = False,  \n    vertical_flip=False)\n\n\ndatagen.fit(x_train)","71f19c03":"weights = compute_class_weight('balanced', np.unique(y_train), y_train)\nweights = {0: weights[0], 1: weights[1]}\nprint(weights)","ba4f4785":"def block(inputs, filters, stride):\n    conv_0 = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=(stride, stride), padding='same', activation='relu')(inputs)\n    conv_1 = layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=(stride, stride), padding='same', activation='relu')(conv_0)\n    \n    skip = layers.Conv2D(input_shape=input_size, filters=filters, kernel_size=(1, 1), strides=(stride**2, stride**2), padding='same', activation='relu')(inputs)\n    \n    pool = layers.MaxPool2D(pool_size=(3, 3), strides=(2,2), padding='same')(add([conv_1, skip]))\n    \n    return pool","36e71166":"input_size = (IMG_HEIGHT, IMG_WIDTH, 1)\n\ninputs = tf.keras.Input(shape=input_size, name='input')\n\ny_0 = block(inputs, 16, 2)\ny_1 = block(y_0, 32, 1)\ny_2 = block(y_1, 48, 1)\ny_3 = block(y_2, 64, 1)\ny_4 = block(y_3, 80, 1)\n\ngap = layers.GlobalMaxPooling2D()(y_4)\ndense = layers.Dense(2, activation='relu')(gap)\n\noutputs = layers.Dense(1, activation='sigmoid')(dense)","60dc34d0":"model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"pneumonia_wnet\")\nmodel.summary()","23a1e061":"lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.7, min_delta=ALPHA, patience=7, verbose=1)\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)","fd18e69d":"CALLBACKS = [lr_reduce, early_stopping_cb]","0f85e0c0":"METRICS = ['accuracy',\n          tf.keras.metrics.Precision(name='precision'),\n          tf.keras.metrics.Recall(name='recall')]","21c48a91":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(lr=ALPHA),\n    loss='binary_crossentropy', \n    metrics=METRICS\n)","626c02a1":"history = model.fit(datagen.flow(x_train,y_train, batch_size = BATCH_SIZE),\n                    steps_per_epoch=x_train.shape[0]\/BATCH_SIZE, \n                    validation_data = (x_val, y_val),\n                    validation_steps=x_val.shape[0]\/BATCH_SIZE,\n                    callbacks = CALLBACKS,\n                    class_weight = weights,\n                    epochs = 30)","823a25f1":"fig, ax = plt.subplots(1, 2, figsize=(15, 5))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","20cb5f3a":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","48cdd1fa":"predictions = model.predict(x_test)\npredictions = predictions.reshape(1,-1)[0]\npredictions[predictions >= 0.5] = 1\npredictions[predictions < 0.5] = 0","c9a805cb":"print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))","49b3bdaa":"from mlxtend.plotting import plot_confusion_matrix\n\ncm = confusion_matrix(y_test,predictions)\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) \/ total\nsensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n\nfig, ax = plot_confusion_matrix(conf_mat=cm , show_normed=True, figsize=(5, 5))\nplt.show()","6e1c2aff":"# 4. Process the data\n\n\nNow we will create and use a function called a prepare_data() that will normalize the images (dividing each pixel by 255) and reshape the array to the appropriate shape. After that, the function will return separately the X and y arrays of our sets.","e2cdf53b":"As can be seen in the classification report and in the confusion matrix, our model performs well both in the classification of positive cases of pneumonia and in the classification of negative cases. Such a great result!","01484d0b":"Let's take a deep look at the results.","a23cee57":"# 3. Load the data\n\nThis kernel uses the dataset [Chest X-Ray Images (Pneumonia)](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia), wich is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal).\n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\u2019 routine clinical care.\n\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n\nDataset Acknowledgements\nData: https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/2\n\nLicense: CC BY 4.0\n\nCitation: http:\/\/www.cell.com\/cell\/fulltext\/S0092-8674(18)30154-5\n\n---\n\nSo, let's define a function to return an np.array with all the images located in a given directory and use it to load our training, validation and test data.\n","a29dcd35":"Here, we will be using the GPU in order to decrease the training time of our model. So, it is valid before going to the code itself that we check if everything is right about this aspect.","25ecccce":"As can be seen in the output of the two previous cells, we are dealing with an imbalanced data problem and with a somewhat strange proportion between the training and validation sets.\n\nWe will act to correct this first problem later in the processing phase, for now we will only concatenate the training and validation datasets and perform the split again.","5cc190ea":"To end this section, let's look at some examples in our dataset","5d42e805":"One of the most important things to do when it comes to training models is to visualize their performance evolution. In this sense, we will plot the value of accuracy, precision, recall and AUC over the epochs.","fcb7f533":"In order to seek the best performance from our model, it is important to increase the number of samples in our data set and, for that, we will perform the data augumentation process. Note that here we are not going to use flips to generate new images since the lungs are not symmetrical laterally and the vertical flip does not make sense here.","ad4476ee":"# 6. Train the model\n\nWe will define some callbacks like ReduceLROnPlateau and EarlyStopping that will help us to have a faster training. \n\nAs defined at Keras API reference, reduce learning rate when a metric has stopped improving nd it's usefull because models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced. Also, early stopping is a form of regularization and thus will help us in preventing overfitting.\n","8f7396d1":"\nWe also need to see how many images we have of each class in the training set. In addition, let's see how the images are distributed among the training, validation and test set.","f2fa1349":"Well, now we have to solve the previously mentioned problem of data imbalance. There are several possible approaches to be taken but we will choose to simply assign different weights to the classes.\n\nThese weights will be used in the future as a parameter in the fit of our model and, as well described in the official documentation of Keras, assigning this person can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n\n\nWe could perform the calculation of weights manually using the formula but sklearn has a function dedicated to it.","900daf38":"# 7. Evaluate the model\n\nNow, it's time to try to generate predictions from data never seen before and check the performance of our model. \n","50f01c7e":"# 8. Conclusion\n\n\nAnd now, in fact, we have come to an end. Here in this kernel we visit important concepts that are essential for the development of deep learning applications such as \"how to deal with unbalanced data\", \"how to create a non-sequential model in Keras\", \"how to evaluate the model\", among others.\n\nOf course, we could still continue to work on that kernel, among other things, finetuning the parameters or something similar. However, for the chosen goal I think it is enough.\n\nThanks for reading. If you want to follow me or contact me, visit my [website](https:\/\/cin.ufpe.br\/~was4) or my [LinkedIn](https:\/\/www.linkedin.com\/in\/w-alves).","35abb310":"Let's fit our model now. It is important to remember here to use the weights for classes previously found by us.","480024bd":"\nOne of the best practices to be performed when doing a machine learning project is to define the constants together, thus facilitating further changes. Given that, let's define the batch size, the height and width of the images and the learning rate.","b97381cd":"# 2. Set-up\n\nTo start, let's perform the necessary imports.","ffe43750":"# 1. Introduction\n\nWith the exponential growth in the volume of data and the cheaper hardware dedicated to storage, the 21st century has everything to be the century of consolidation of learning based artificial intelligence techniques. In this sense, the use of Deep Learning techniques ends up becoming more and more applied in different areas and one of the most promising is healthcare.\n\nOne of the classic applications of deep learning in health is the use of convolutional neural networks to classify images according to a specific purpose, whether to detect the presence of diseases and tumors or AI-assisted robotic surgeries. \n\n**In this kernel, we will use a neural network almost equal as the one apresented in the paper Efficient Deep Network Architectures for Fast Chest X-Ray Tuberculosis Screening and Visualization [1].**\n\nDetecting pneumonia accurately is important since when you have pneumonia, it's possible for your lungs to fill with fluid. If that happens, they won't be able to transfer enough oxygen to your blood or get rid of the carbon dioxide in your blood. It's a serious condition because your organs need oxygen to work.\n\nBefore going to what matters, it is important to remember that **this kernel and model should also not be used for clinical diagnoses** since it is characterized only as a personal case study.\n\n[1] Pasa, F., Golkov, V., Pfeiffer, F. et al. Efficient Deep Network Architectures for Fast Chest X-Ray Tuberculosis Screening and Visualization. Sci Rep 9, 6268 (2019). https:\/\/doi.org\/10.1038\/s41598-019-42557-4","e51c98a2":"As optimizer we will choose Adam, because it combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems. As loss, since we have just two possible labels, we are going to use binary crossentropy.","da01391f":"# 5. Build the model\n\nFinally we come to the most interesting part for some people: the model creation phase.\n\nAs mentioned at the beginning, we will use a neural network almost equal as the one from the paper Efficient Deep Network Architectures for Fast Chest X-Ray Tuberculosis Screening and Visualization. The presented model has the following architecture:\n\n![](https:\/\/i.imgur.com\/CvzKiWj.png)\n\nThe **almost equal** is due to the fact that we use a sigmoid activation when activating softmax in the last layer of the model (what in turn does not change anything, since the softmax function in the background is a generalization of the sigmoid function but applicable to multilabel problems).\n","9448a1ee":"With these values of accuracy, precision and recall, it is clear that the model used in this kernel presents itself as a solid and extremely efficient architecture for the problem in question.","75f82e92":"For our metrics, we want to use accuracy, precision and recall. This choices were made because:\n* Accuracy, despite being the most widely used metric, give us a quite illusory information about how good our model are performing, since we have the problem of imbalanced data.\n* Precision give us the ratio tp\/(tp+fp) or in a intuitively definiton the ability of the classifier not to label as positive a sample that is negative.\n* Recall give us the ratio tp\/(tp+fn) or in a intuitively the ability of the classifier to find all the positive samples. "}}