{"cell_type":{"99920343":"code","67456942":"code","f0dd2b5e":"code","0c8dab12":"code","771147d7":"code","88882f72":"code","8661d960":"code","14a78962":"code","49fbf03a":"code","90c1172d":"code","5006a8cd":"code","6979b03b":"code","7df6308b":"code","6bdaff35":"code","880ca658":"code","ddb0b7c8":"code","ad6c9519":"code","569114dd":"code","16d28695":"code","6f175237":"code","6c83cab1":"code","24cd276a":"code","48bddf70":"code","a7fe1cfa":"code","550d1396":"code","258b01d3":"code","ec3f0543":"code","85a06215":"code","6c5b3549":"code","34fb6cb3":"code","691ef2c6":"markdown","2dec4cdf":"markdown","805e402a":"markdown","fb1d7877":"markdown","05527762":"markdown","08912818":"markdown","65a10462":"markdown","2d80de50":"markdown","f728d800":"markdown","23674e09":"markdown","f795fc68":"markdown","728299e3":"markdown","e16e7ec8":"markdown","e43f72ae":"markdown","3b6830aa":"markdown","ebc6a08b":"markdown","554fb0f0":"markdown","f9917d5c":"markdown","0d04a5bd":"markdown","5d9bf592":"markdown","9c035f91":"markdown","7d738a0c":"markdown","c10d42a4":"markdown","0c464186":"markdown","4c2f332f":"markdown"},"source":{"99920343":"import pandas as pd \nimport numpy as np\nfrom sklearn.ensemble import  RandomForestRegressor\nimport re\nfrom sklearn.impute import SimpleImputer\nfrom IPython.display import display\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype","67456942":"data_set = pd.read_csv('..\/input\/bluebook-for-bulldozers\/Train.zip', low_memory=False, \n                     parse_dates=[\"saledate\"])\n\ndata_test=pd.read_csv('..\/input\/bluebook-for-bulldozers\/Test.csv', low_memory=False, \n                     parse_dates=[\"saledate\"])","f0dd2b5e":"data_set.info()","0c8dab12":"data_set['saleyear']=data_set.saledate.dt.year\ndata_set['salemonth']=data_set.saledate.dt.month\ndata_set['saleday']=data_set.saledate.dt.day","771147d7":"# Test Data\ndata_test['saleyear']=data_test.saledate.dt.year\ndata_test['salemonth']=data_test.saledate.dt.month\ndata_test['saleday']=data_test.saledate.dt.day","88882f72":"data_set.drop(columns=['saledate'],inplace=True)\ndata_test.drop(columns=['saledate'],inplace=True)","8661d960":"data_set.state.unique()","14a78962":"\nfor col ,val in data_set.items():\n  if pd.api.types.is_string_dtype(val):\n    data_set[col]=val.astype(\"category\").cat.as_ordered()\n","49fbf03a":"#Test Data\nfor col ,val in data_test.items():\n  if pd.api.types.is_string_dtype(val):\n    data_test[col]=val.astype(\"category\").cat.as_ordered()\n","90c1172d":"for col,val in data_set.items():\n  if  not pd.api.types.is_numeric_dtype(val):\n    data_set[col]=pd.Categorical(val).codes+1","5006a8cd":"for col,val in data_test.items():\n  if  not pd.api.types.is_numeric_dtype(val):\n    data_test[col]=pd.Categorical(val).codes+1","6979b03b":"for col,val in data_set.items():\n  if pd.api.types.is_numeric_dtype(val):\n    if pd.isnull(val).sum():\n        data_set[col]=val.fillna(val.median())\n","7df6308b":"#Test Data\nfor col,val in data_test.items():\n  if pd.api.types.is_numeric_dtype(val):\n    if pd.isnull(val).sum():\n        data_test[col]=val.fillna(val.median())\n","6bdaff35":"for col,val in data_set.items():\n  if pd.api.types.is_numeric_dtype(val):\n    if pd.isnull(val).sum():\n        print(col)","880ca658":"y=data_set.SalePrice\ndata_set.drop(columns=['SalePrice'],inplace=True)\nsales_id=data_test.SalesID\ndata_set.drop(columns=['SalesID'],inplace=True)\ndata_test.drop(columns=['SalesID'],inplace=True)\n\n","ddb0b7c8":"from sklearn.preprocessing import  StandardScaler\nSC=StandardScaler()\ndata_set[data_set.columns]=(SC.fit_transform(data_set[data_set.columns]))\ndata_test[data_test.columns]=(SC.fit_transform(data_test[data_set.columns]))\n","ad6c9519":"test_valid_size=data_test.shape[0]\/ (data_set.shape[0]) \n\ntest_valid_size","569114dd":"from sklearn.model_selection import  train_test_split\nx_train,x_valid,y_train,y_valid=train_test_split(data_set,y,test_size=test_valid_size,random_state=44)","16d28695":"from sklearn.metrics import  mean_squared_log_error\ndef rmse(y_test, y_preds):\n    \"\"\"\n    Calculates root mean squared error between predictions and truelabels.\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_test, y_preds))\ndef show_evalution_score (model):\n  print(\"Training score\",model.score(x_train,y_train))\n  print(\"Valid score\",model.score(x_valid,y_valid))\n  print(\"Training RMSLE\",rmse(model.predict(x_train),y_train))\n  print(\"Valid RMSLE\",rmse(model.predict(x_valid),y_valid))\n\n","6f175237":"m = RandomForestRegressor(n_jobs=-1)\nm.fit(x_train, y_train)\n\n\n","6c83cab1":"show_evalution_score(m)","24cd276a":"\nfrom sklearn.model_selection import RandomizedSearchCV\n\n # Different RandomForestRegressor hyperparameters\nrf_grid = {\"n_estimators\": np.arange(20, 100, 20),\n          \"max_depth\": [None, 3, 5, 10],\n          \"min_samples_split\": np.arange(2, 20, 2),\n          \"min_samples_leaf\": np.arange(1, 20, 2),\n          \"max_features\": [0,5, 1, \"sqrt\", \"auto\"],\n          \"max_samples\": [10000]}\n\n # Instantiate RandomizedSearchCV\nscv_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n                                                   random_state=12),\n                             param_distributions=rf_grid,\n                             n_iter=2,\n                             cv=5,\n                             verbose=True)\n\n # Fit the RandomizedSearchCV\nscv_model.fit(x_train, y_train)","48bddf70":"scv_model.best_params_","a7fe1cfa":"show_evalution_score(scv_model)","550d1396":"best_model = RandomForestRegressor(n_estimators=40,\n                                   min_samples_leaf=1,\n                                   min_samples_split=14,\n                                   max_features=.5,\n                                   n_jobs=-1,\n                                   max_samples=None,\n                                   random_state=12)","258b01d3":"best_model.fit(x_train, y_train)","ec3f0543":"show_evalution_score(best_model)","85a06215":"test_pred=best_model.predict(data_test)\ntest_pred","6c5b3549":"df_predict=pd.DataFrame()\ndf_predict[\"SalesID\"] = sales_id\ndf_predict[\"SalesPrice\"] = test_pred\ndf_predict.to_csv(\"submission.csv\", index = False)\n","34fb6cb3":"df_predict","691ef2c6":"**preprocessing Data**\n\nThis dataset contains a mix of continuous and categorical variables , so we will preprocessing it\n","2dec4cdf":"***Scaling the Data***","805e402a":" **Introduction**","fb1d7877":"Spliting The Data \n\n\n1.   Train Data\n2.   Valid Daya\n\n","05527762":"we can't use Labelencoder from Sklearn because it cant handle 'nan' data\n\n","08912818":"we cant use one hot encoding because as we see there are some feature have more than 15 variable .\n","65a10462":"The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and\npredicted auction prices","2d80de50":"**Convert string to categories**\n","f728d800":"***Importing libraries***","23674e09":"**Building an evaluation function**\n","f795fc68":"we will use RandomizedSearchto find the best paramters ","728299e3":" **Data**\n ","e16e7ec8":"**Add datetime parameters for saledate column**\n\nwe know from the description of the problem that \"sale date \" is time series so we convert it into many fields in \"int64\"","e43f72ae":"**Handling missing value**","3b6830aa":"we want here to predict the future sale price of a bulldozer, given its characteristics and previous examples of how much similiar bulldozers have been sold for","ebc6a08b":"**Hyperparameter tunning with GridSearchCV**","554fb0f0":"there is difference between the train and validton score we have here overfitting ","f9917d5c":"**Calculate size of valid data**","0d04a5bd":"**Train the model**","5d9bf592":"check if there is null value","9c035f91":"**Make predictions on test data**","7d738a0c":"We have three main Data:\n\n\n*   Train Data\n*   Valid Data\n*   Test Data\n\n","c10d42a4":"Note: These were found after 100 iterations of RandomizedSearchCV.","0c464186":"**Parsing dates**\n\nWhen we work with time series data, we want to enrich the time & date component as much as possible.\n\nWe can do that by telling pandas which of our columns has dates in it using the parse_dates parameter.","4c2f332f":"**Train a model with the best hyperparameters**"}}