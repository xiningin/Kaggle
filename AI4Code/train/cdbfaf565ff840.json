{"cell_type":{"1780eb89":"code","29adbd40":"code","38a464d6":"markdown","0b1ccf1d":"markdown","d6774299":"markdown","fcfc7b11":"markdown","4a1afb1b":"markdown","e2d224a7":"markdown"},"source":{"1780eb89":"import pandas as pd\n\nlist_files=[\"EPL_\"+str(year)+\".csv\" for year in range(2002,2021)] #name list of files\n#In my case I called the files like:\n#EPL_2001, EPL_2002....EPL_2020\n\n#next lines retrieve the df with Dates of matches\ndf=pd.DataFrame()\nfor i in list_files:\n    dataframe=pd.read_csv(\"filepath\"+i) #read each file changing the year\n    df=pd.concat([df,dataframe],ignore_index=True)\n\n#processing data\ndates_unique=df[\"DATE\"].drop_duplicates() #eliminate the date duplicates\ndates_without_nan=dates_unique.dropna().reset_index(drop=True)\n\ncont=-1\nfor i in dates_without_nan:\n    cont+=1\n    if len(i)<10:\n       dates_without_nan=dates_without_nan.drop(cont) #eliminate any records that aren't dates\n\n#change the date format \ndates=pd.to_datetime(dates_without_nan)\ndates=dates.dt.strftime('%Y%m%d')\nlist_dates=dates.to_list()","29adbd40":"import urllib.request, urllib.parse, urllib.error\nfrom bs4 import BeautifulSoup\n\n#list empty to create records\nlist_home_team=[]\nlist_away_team=[]\nlist_stadium=[]\nlist_attendance=[]\nlist_date_match=[]\n\nfor i in list_dates:\n    try:\n        url = \"https:\/\/global.espn.com\/football\/fixtures\/_\/date\/\"+str(i)+\"\/league\/eng.1\"\n        print(url)\n        #read web site html and transform it to BeautifulSoup object\n        html=urllib.request.urlopen(url).read()\n        soup=BeautifulSoup(html,'html.parser')\n\n        date_round=[date_table.text for date_table in soup.find_all('h2')]\n\n        cont_table=-1\n        for table in soup.find_all('table'):\n            cont_table+=1\n            data=table.tbody\n            date_table=date_round[cont_table]\n            for rows in data.find_all('tr'):\n                cont=0\n                list_date_match.append(date_table)\n                for col in rows.find_all('td'):\n                    cont+=1\n                    if cont==1:\n                        home_team=str(col.a.span.text)\n                        list_home_team.append(home_team)\n                    elif cont==2:\n                        away_team=str(col.a.span.text)\n                        list_away_team.append(away_team)\n                    elif cont==4:\n                        stadium=str(col.text)\n                        list_stadium.append(stadium)\n                    elif cont==5:\n                        attendance=str(col.text)\n                        list_attendance.append(attendance)\n                    elif len(rows.find_all('td'))<5:\n                        attendance=str(0)\n                        list_attendance.append(attendance)                        \n    except:\n        continue \n        \ndictionary_data={'date match':list_date_match,'home team':list_home_team,'away team':list_away_team,'stadium':list_stadium,'attendance':list_attendance}\ndataframe=pd.DataFrame(data=dictionary_data)\ndataframe.to_csv(\"filepath\",index=False)","38a464d6":"# WEB SCRAPING IN ESPN    \n\n<br>\n<br>\n<center>\n    <img src=\"https:\/\/static.dw.com\/image\/3816951_4.jpg\" width=\"300\" alt=\"soccer.logo\"  \/>\n<\/center>\n<br>\n\n<div style=\"text-align: right\"> <b>By David Clavijo<\/b> <\/div>  \n\n\n# About Notebook\n\nIn this notebook, I get records of attendance soccer matches using the beautifulsoup library to extract the data on the ESPN website (**web sites:https:\/\/global.espn.com\/football\/fixtures\/_\/date\/20051026\/league\/eng.1**).\nOn the website of ESPN, it shows the matches played in each round by each season in the championship chose (In this notebook I chose the English Premier League).  \nThe data that we can get to each match are:\n\n*   Name Home Team\n*   Name Away Team\n*   Location of the match (City,Stadium)\n*   Result of the match\n*   attendance\n","0b1ccf1d":"![purple-divider](https:\/\/user-images.githubusercontent.com\/7065401\/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png) ","d6774299":"## Web Scraping\n\nIn the next code, I'll use beautifulsoup to retrieve the data. The code navigates in each link for the dates of the list and then retrieves the records saving them in a dictionary. After, the dictionary is converted to Dataframe for export to a file in CSV format.\n\nYou can notice that in the code, I use `try and except` to avoid errors during the execution of a call. The mean error that can occur is connection server failure. Using this method is possible to lose records that you can need, for this, I print the URL in each execution.","fcfc7b11":"# Retrieve the records  \n  \n## List of the dates\n\nThe first step to get the records in all matches in each round along the years is to create the list of the dates that we want to explore. In the code showed, I use files in format CSV that contains the dates of the matches among other data (you can download them at https:\/\/www.football-data.co.uk\/).\n\nThe next code create the list of the dates:","4a1afb1b":"# Data Collected\n\nYou can notice that website shows the data by round using the date that we want to see. Therefore, if we want to get the data in many rounds and years, we must explore **n** amount of pages on the website. For this, we change the **date** in the link to navigate:    \n\nhttps: \/\/global.espn.com\/football\/fixtures\/_\/date\/ **change it**\/league\/eng.1\n\nThe code that I'll show you run **thousands** of links changing automatically the date from the 2002 year to the 2020 year in the English Premier League. ","e2d224a7":"**NOTE** in the previous code you can notice that the format of the date in the link must be like YYYYMMDD, therefore I create the list in this format."}}