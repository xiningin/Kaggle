{"cell_type":{"2e42bf46":"code","55c77ae0":"code","c5a5d7eb":"code","95eae612":"code","3ea8d0cd":"code","a3358b30":"code","ddb8d1d4":"code","6cbad1a0":"code","f33b3b3f":"code","c5f2193a":"code","cf5f872d":"code","9fbcc24e":"code","64662b48":"code","9bae9aa3":"code","eabde4da":"code","00a370da":"code","558ce37d":"code","8a616e13":"code","1868796d":"code","02b7e036":"code","eda81036":"code","4af6786c":"code","b94bcc05":"code","d2d754bd":"code","ce692abd":"code","6323ea05":"code","8fc9bb7b":"code","c1d4d38a":"code","b9dc8e4c":"code","ecb11a08":"code","eb8a6d2c":"code","a2651283":"code","fdf27d7e":"code","5d084583":"code","993ea8a0":"code","22782bbc":"code","9c27f066":"code","691f3d84":"code","0ebda91e":"code","0e5bca8b":"code","4da04bf8":"code","f5e67d29":"code","587ed759":"code","dc003d4f":"code","7634861b":"code","ec52c248":"code","854221bb":"code","101d6f34":"code","da0599e6":"markdown","031fca22":"markdown","a700fc5a":"markdown","bac60cd5":"markdown","2875d47e":"markdown","b4e4e35d":"markdown","d3f2da22":"markdown","6f67033e":"markdown","ad5d8969":"markdown","989871c4":"markdown","e1f3b106":"markdown","84f7be8e":"markdown","3ffe76bc":"markdown","47f0529b":"markdown","d5cd4981":"markdown","686b74b8":"markdown","5bfa2e64":"markdown","4dd56d8e":"markdown","9f5eed36":"markdown"},"source":{"2e42bf46":"!pip -q install attrdict","55c77ae0":"import warnings\nwarnings.filterwarnings(\"ignore\")","c5a5d7eb":"import os\nfrom glob import glob\nfrom itertools import chain\nimport cv2\nimport random\nfrom tqdm.notebook import tqdm\nimport time","95eae612":"from attrdict import AttrDict\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","3ea8d0cd":"from sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split","a3358b30":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense\nfrom tensorflow.keras.layers import Flatten, Input, Layer, MaxPooling2D\nfrom tensorflow.keras.models import Model","ddb8d1d4":"train = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")","6cbad1a0":"train = train.drop(columns=[\"id\"])\ntest = test.drop(columns=[\"id\"])","f33b3b3f":"print(f\"Train Shape :  {train.shape}\")\nprint(f\"Test Shape :  {test.shape}\")","c5f2193a":"config = dict(SEED = 42,\n              IMG_HEIGHT = 10,\n              IMG_WIDTH = 10,\n              EPOCHS = 100,\n              BATCH_SIZE = 64,\n              LR = 0.01)\nconfig = AttrDict(config)","cf5f872d":"def seed_everything(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)","9fbcc24e":"def plot_hist(hist):\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n    ax[0].plot(hist.history[\"loss\"])\n    ax[0].plot(hist.history[\"val_loss\"])\n    ax[0].set_title(\"Loss Plot\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].set_xlabel(\"Epoch\")\n    ax[0].legend([\"Train\", \"Validation\"], loc=\"upper left\")\n\n    ax[1].plot(hist.history[\"root_mean_squared_error\"])\n    ax[1].plot(hist.history[\"val_root_mean_squared_error\"])\n    ax[1].set_title(\"RMSE Plot\")\n    ax[1].set_ylabel(\"RMSE\")\n    ax[1].set_xlabel(\"Epoch\")\n    ax[1].legend([\"Train\", \"Validation\"], loc=\"upper left\")\n    plt.show()","64662b48":"def plot_metrics(hist):\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n    ax[0].plot(hist.history[\"mean_absolute_error\"])\n    ax[0].plot(hist.history[\"val_mean_absolute_error\"])\n    ax[0].set_title(\"MAE Plot\")\n    ax[0].set_ylabel(\"MAE\")\n    ax[0].set_xlabel(\"Epoch\")\n    ax[0].legend([\"Train\", \"Validation\"], loc=\"upper left\")\n\n    ax[1].plot(hist.history[\"mean_squared_error\"])\n    ax[1].plot(hist.history[\"val_mean_squared_error\"])\n    ax[1].set_title(\"MSE Plot\")\n    ax[1].set_ylabel(\"MSE\")\n    ax[1].set_xlabel(\"Epoch\")\n    ax[1].legend([\"Train\", \"Validation\"], loc=\"upper left\")","9bae9aa3":"def plot_grid(dataset, h=3, w=3, title=\"\"):\n    f, ax = plt.subplots(h, w, figsize=(30, 30))\n    for images, labels in dataset.shuffle(100).take(1):\n        for i in range(h*w):\n            img = (images[i] * 255).numpy().astype(\"uint8\")\n            ax[i \/\/ h, i % w].imshow(img[:, :, 0])\n            ax[i \/\/ h, i % w].axis(\"off\")\n            ax[i \/\/ h, i % w].set_title(labels[i].numpy(), fontdict={\"fontsize\": 20})\n    plt.tight_layout()\n    f.suptitle(title, fontsize=\"large\", fontweight=\"extra bold\")\n    plt.show()","eabde4da":"def print_metrics(stage, y_true, y_pred):\n    mae = metrics.mean_absolute_error(y_true, y_pred)\n    mse = metrics.mean_squared_error(y_true, y_pred)\n    rmse = metrics.mean_squared_error(y_true, y_pred, squared=False)\n    print(f\"{stage} Mean Absolute Error: {mae:.2f}\")\n    print(f\"{stage} Mean Squared Error: {mse:.2f}\")\n    print(f\"{stage} Root Mean Squared Error: {rmse:.2f}\")","00a370da":"X = train[test.columns.tolist()]\ny = train[\"loss\"]","558ce37d":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y)","8a616e13":"print(f\"Train Shape: {X_train.shape, y_train.shape}\")\nprint(f\"Validation Shape: {X_valid.shape, y_valid.shape}\")","1868796d":"total = pd.concat([train[test.columns.tolist()], test])\ntotal.shape","02b7e036":"scaler = preprocessing.MinMaxScaler()\nscaler.fit(total)","eda81036":"X_train = scaler.transform(X_train)\nX_valid = scaler.transform(X_valid)\nX_test = scaler.transform(test)","4af6786c":"X_train = X_train.reshape(-1, 10, 10, 1)\nX_valid = X_valid.reshape(-1, 10, 10, 1)\nX_test = X_test.reshape(-1, 10, 10, 1)","b94bcc05":"X_train.shape, X_valid.shape, X_test.shape","d2d754bd":"train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_dataset = train_dataset.batch(config.BATCH_SIZE)\ntrain_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)","ce692abd":"plot_grid(train_dataset, title=\"Training Images\")","6323ea05":"valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\nvalid_dataset = valid_dataset.batch(config.BATCH_SIZE)\nvalid_dataset = valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)","8fc9bb7b":"plot_grid(valid_dataset, title=\"Validation Images\")","c1d4d38a":"class RootMeanSquaredError(tf.keras.losses.Loss):\n    def call(self, y_true, y_pred):\n        y_pred = tf.convert_to_tensor(y_pred)\n        y_true = tf.cast(y_true, y_pred.dtype)\n        return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true), axis=-1))","b9dc8e4c":"def build_model():\n    # Inputs to the model\n    input_img = Input(\n        shape=(config.IMG_HEIGHT, config.IMG_WIDTH, 1), name=\"image\", dtype=\"float32\"\n    )\n\n    x = Conv2D(8, (2, 2), activation=\"relu\", padding=\"same\", name=\"conv_1\")(input_img)\n    x = Conv2D(16, (2, 2), activation=\"relu\", padding=\"same\", name=\"conv_2\")(x)\n    x = MaxPooling2D((2, 2), name=\"pool_1\")(x)\n    x = Conv2D(32, (2, 2), activation=\"relu\", padding=\"same\", name=\"conv_3\")(x)\n    x = Conv2D(64, (2, 2), activation=\"relu\", padding=\"same\", name=\"conv_4\")(x)\n    x = MaxPooling2D((2, 2), name=\"pool_2\")(x)\n    x = Flatten()(x)\n    x = Dense(256, activation=\"relu\", name=\"dense_1\")(x)\n    x = Dense(128, activation=\"relu\", name=\"dense_2\")(x)\n    x = Dense(64, activation=\"relu\", name=\"dense_3\")(x)\n    x = Dense(16, activation=\"relu\", name=\"dense_4\")(x)\n    output = Dense(1, activation=\"linear\", name=\"output\")(x)\n\n    model = Model(inputs=[input_img], outputs=output, name=\"regression_model\")\n\n    opt = tf.keras.optimizers.Adam(learning_rate=config.LR)\n\n    model.compile(optimizer=opt, \n                  loss=tf.keras.losses.MeanSquaredError(), \n                  metrics=[tf.keras.metrics.RootMeanSquaredError(), \n                           tf.keras.metrics.MeanAbsoluteError(), \n                           tf.keras.metrics.MeanSquaredError()])\n    return model","ecb11a08":"model = build_model()\nmodel.summary()","eb8a6d2c":"tf.keras.utils.plot_model(model)","a2651283":"early_stopping_patience = 10\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=early_stopping_patience, \n    restore_best_weights=True\n)\n\ncheckpoint_filepath = \"model_checkpoint\"\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=False,\n    monitor=\"val_loss\",\n    mode=\"min\",\n    save_best_only=True)","fdf27d7e":"history = model.fit(\n    train_dataset,\n    validation_data=valid_dataset,\n    epochs=config.EPOCHS,\n    callbacks=[early_stopping, model_checkpoint_callback]\n)","5d084583":"plot_hist(history)","993ea8a0":"plot_metrics(history)","22782bbc":"best_model = tf.keras.models.load_model(checkpoint_filepath, compile=False)","9c27f066":"valid_preds = best_model.predict(valid_dataset)\nvalid_preds = list(chain.from_iterable(valid_preds))","691f3d84":"print_metrics(\"Validation\", y_valid, valid_preds)","0ebda91e":"train_preds = best_model.predict(train_dataset)","0e5bca8b":"train_preds = list(chain.from_iterable(train_preds))","4da04bf8":"print_metrics(\"Training\", y_train, train_preds)","f5e67d29":"test_dataset = tf.data.Dataset.from_tensor_slices(X_test)\ntest_dataset = test_dataset.batch(config.BATCH_SIZE)\ntest_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)","587ed759":"test_preds = best_model.predict(test_dataset)","dc003d4f":"test_preds = list(chain.from_iterable(test_preds))","7634861b":"sample_submission[\"loss\"] = test_preds","ec52c248":"sample_submission[\"loss\"].describe()","854221bb":"sample_submission[\"loss\"].quantile(np.linspace(.1, 1, 9, 0))","101d6f34":"sample_submission.to_csv(\"submission.csv\", index=False)","da0599e6":"**Validation Data Evaluation**","031fca22":"Here the validation split is not representative of test data to be honest","a700fc5a":"## Load Data","bac60cd5":"While normalization brings values to 0-1 range, it doesn't keep the shape the same.\n\nOn the other hand standard scaling keeps shape the same but subtracts mean & divides by standard deviation such that mean is 0 & standard deviation is 1","2875d47e":"## Simple CNN - Regression\nRefer my original solution [here](https:\/\/www.kaggle.com\/aditya08\/count-the-boxes-cnn-regression-tensorflow) for reference","b4e4e35d":"**Running a simple 3 layer CNN after converting data to 10x10 matrix**","d3f2da22":"> Somehow the loss value & rmse metric are different - ideally they should be the same. Need checking!","6f67033e":"## Submission","ad5d8969":"## Utility Functions","989871c4":"## Tensorflow doesn't provide RMSE loss function","e1f3b106":"**Reshaping to `10x10x1` matrix**","84f7be8e":"## Normalizing or Standard Scaling","3ffe76bc":"**Training Data Evaluation**","47f0529b":"## Training","d5cd4981":"## Train-Validation Split","686b74b8":"## Import Libraries","5bfa2e64":"## Inference\nAlways load the best model","4dd56d8e":"## Convert to TensorFlow Dataset","9f5eed36":"## Configurations"}}