{"cell_type":{"daee5537":"code","ca0b10e5":"code","1d3d1e7e":"code","84963e3e":"code","27ceee86":"code","d29a8114":"code","8804d7fe":"code","c24564a3":"code","fe0f1dda":"code","d9b437a0":"code","9c0ad97b":"markdown","9583d06b":"markdown","43e01435":"markdown","34ee18f5":"markdown","cf201e50":"markdown","811f06a3":"markdown"},"source":{"daee5537":"import pandas as pd\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\nimport ast, json\n\nfrom datetime import datetime\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n%matplotlib inline","ca0b10e5":"train = pd.read_csv(\"..\/input\/train.csv\")\ntrain.head()","1d3d1e7e":"max_scalar_coupling_constant = train.sort_values(by=\"scalar_coupling_constant\", ascending=False).groupby('type').head(1)\nmin_scalar_coupling_constant = train.sort_values(by=\"scalar_coupling_constant\", ascending=True).groupby('type').head(1)\n\nmin_sc = min_scalar_coupling_constant[['type', 'scalar_coupling_constant']]\nmax_sc = max_scalar_coupling_constant[['type', 'scalar_coupling_constant']]\n\nsc_type = max_sc.join(min_sc.set_index('type'), on='type', lsuffix='_max', rsuffix='_min')\nsc_type = sc_type.assign(delta=sc_type['scalar_coupling_constant_max']-sc_type['scalar_coupling_constant_min'])\nsc_type.rename(columns = {\"scalar_coupling_constant_min\": \"min\", \n                     \"scalar_coupling_constant_max\":\"max\"}, \n                                 inplace = True) \nsc_type","84963e3e":"sc_type.set_index('type')\\\n      .reindex(sc_type.set_index('type').sum().sort_values().index, axis=1)\\\n      .T.plot(kind='bar', stacked=False,\n              colormap=ListedColormap(sns.diverging_palette(145, 280, s=85, l=25, n=7)), \n              figsize=(18,9))\nplt.xticks(rotation='horizontal')\nplt.tick_params(labelsize=20)\nplt.show()","27ceee86":"sc_type['j_number'] = sc_type['type'].astype(str).str[0]\nsc_type.groupby(['j_number']).mean()\nsc_type.groupby(\n    ['j_number']\n).agg(\n    {\n        'delta': ['mean'],\n    }\n)","d29a8114":"train['j_number'] = train['type'].astype(str).str[0]\nj_number_group = train.groupby(\n    ['j_number']\n).agg(\n    {\n        # find the min, max, and sum of the duration column\n        'scalar_coupling_constant': ['mean', 'max', 'min'],\n         # find the number of network type entries\n        'type': [\"count\"],\n        # min, first, and number of unique dates per group\n        'atom_index_1': ['nunique'],\n        'atom_index_0': ['nunique']\n    }\n)\nj_number_group","8804d7fe":"j_number_group['scalar_coupling_constant'].plot(kind='bar',stacked=False,figsize=(8,8))\nplt.xticks(rotation='horizontal')\nplt.show()","c24564a3":"train['atom_0'] = train['type'].astype(str).str[2]\ntrain['atom_1'] = train['type'].astype(str).str[3]\ntrain.head()","fe0f1dda":"train.groupby(\n    ['atom_0', 'atom_1']\n).agg(\n    {\n        'atom_index_0': ['nunique'],\n        'atom_index_1': ['nunique'],\n        'j_number': ['nunique']\n    }\n)","d9b437a0":"n_two_hh = train['type'][train['type']=='2JHH'].count()\nn_three_hh = train['type'][train['type']=='3JHH'].count()\ntwo_j_hh_mean = train['scalar_coupling_constant'][train['type']=='3JHH'].mean()\nthree_j_hh_mean = train['scalar_coupling_constant'][train['type']=='2JHH'].mean()\nall_data = train['type'].count()\nresults = {}\nfor i in train['type'].unique():\n    count = train['type'][train['type']==i].count()\n    perc = (count\/all_data)*100\n    results[i] = perc\nplt.bar(range(len(results)), list(results.values()), align='center')\nplt.xticks(range(len(results)), list(results.keys()))\nplt.figsize=(18,9)\nplt.show()","9c0ad97b":"### Define min, max, delta values\nOur first task in this EDA (Exploratory Data analysis) is to find the max- and min scalar coupling constant values grouped by type.  \nWe have only 8 categorical variables in our Type field:  \n<font color=blue>*['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN']* <\/font>  \n Also we are going to calculate the delta using the equation below:  \n<center>*delta = max - min*\n","9583d06b":"**Great! Let's load out training dataset as DataFrame.**","43e01435":"# Molecular properties EDA\n\n**Hi everyone. So, here I want to share my data exploration of the training dataset.\nFirstly, lets define what is scalar coupling constant:**\n> The coupling constant is defined as nJA,X, where n is the number of chemical bonds between the two coupling atoms A and X. The coupling constant is independent of the field strength, and has a plus or minus prefix and it is mutual to the coupled atoms (nJA,X=nJX,A).\n\n[From: NMR Spectroscopy in Pharmaceutical Analysis, 2008](https:\/\/www.sciencedirect.com\/topics\/neuroscience\/coupling-constant)  \n**Now let's define what kind of problems it helps us to solve:**\n* *Helps in assignment of molecular fragments;*\n* *Conformation and relative stereochemistry;*\n* *J coupling is heavily used in the liquid state NMR (Nuclear magnetic resonance).*  \n**Now we will start with importing the needed libraries:**","34ee18f5":"That helps us conclude that we have 'H' is always the first element, and that we have only 2 possible  \ncombinations of 'HH': *2JHH, 3JHH*. \nNow we will find how many atom types are in our dataset in percentage. That will also allow us to find the most frequent one in the training set.","cf201e50":"**Inresting! We can make such conclusions:  \nThe lower number of couplings we have, the higher is the scalar coupling constant.  \nLet's explore the training dataset**","811f06a3":"**Now I am going to extract number of chemical bonds between the two coupling atoms A and X (J) in the 'type' field.\nPerforming that will help to find out correlationships later in the dataset,**"}}