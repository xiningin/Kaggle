{"cell_type":{"15dba4b8":"code","b33b7498":"code","38239fc4":"code","ed6be1ba":"code","78dd8df1":"code","f9a1550b":"code","3eb9646c":"code","bfb5272e":"code","628a96ad":"code","2278c0b4":"code","7b8d7314":"code","51b8b3bb":"code","70d53989":"code","4f7b2e64":"code","6e936b02":"code","f3813ce8":"code","4b3dfd75":"code","1ad188cc":"code","aa4c5ca7":"code","c54ecda6":"code","72142586":"code","06479f72":"code","9b51f56d":"code","de077057":"code","7b6eed68":"code","6fd731d3":"code","eda75c22":"code","cea764d6":"code","de0bd1b5":"code","05c73d5c":"code","d36ce2f4":"code","a60dd0d7":"code","c301ba1d":"code","9661e135":"code","e5e69f2f":"code","3f797265":"code","14132eb7":"code","5a86d2b2":"code","375029f0":"code","29d5d996":"code","549bc5bb":"code","a87c8293":"code","3639052f":"code","bee06bf0":"code","73b86fe3":"code","dbca6d8b":"code","324624d9":"code","496aa8e9":"code","6f314d99":"code","73625242":"code","85521a9b":"code","2ef0d847":"code","99dbb903":"code","076118ac":"code","d2a6a00e":"code","09b9b92e":"code","4f357a5c":"code","3acc4307":"code","2dd2746d":"code","58497e12":"code","027db269":"code","dd8b8b24":"code","20ad7001":"code","f4f2ecd0":"code","1890555a":"code","c4d645ab":"code","834af59a":"code","c77a7085":"code","64e0b311":"code","64653be9":"code","b6f9d5b5":"code","893c129e":"code","09e06833":"code","15c3586e":"code","8094f395":"code","edf51b91":"code","b25820eb":"code","151e81a9":"code","0b488a93":"code","1755c966":"code","20c9b0ee":"code","de4ecbde":"code","a8f3e1af":"code","da345093":"code","ae833174":"code","2823ea32":"code","869a699b":"code","5d4f5f92":"code","081e5270":"code","c26040b8":"code","f9edca9e":"code","f995e7ee":"code","4a2b557b":"code","6a85f9fa":"code","91f167d3":"code","e5f68328":"code","978980f4":"code","637f35d6":"code","62873b66":"code","fd81efa8":"code","3bf1f23a":"code","9467b719":"code","da78e2a5":"code","4aa78b23":"code","7ff669c5":"code","4ca83ddc":"code","c7fe4a6e":"code","ddb46bfd":"code","6cb0110b":"code","7c128c90":"code","e85b856b":"code","33bb8416":"code","b365a0d3":"code","af4ddcf1":"code","ce2c36a6":"code","81cbc402":"code","2ceaeec1":"code","fa0f11e7":"code","b591d6dd":"code","5bedd626":"code","069afc8d":"code","1d3a7114":"code","377d30ac":"code","e771dd1f":"code","a9dd602f":"code","b98a3d60":"code","67098cdb":"code","05179645":"code","539749ec":"code","f56c82b3":"code","2bfc3bad":"code","9135c9b0":"code","b0be1c64":"code","0669e4da":"code","713c8b68":"code","f3a83fe9":"code","77f8ad94":"code","870cbe04":"code","18663c39":"code","d590e049":"markdown"},"source":{"15dba4b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b33b7498":"train = pd.read_csv('\/kaggle\/input\/course-material-walmart-challenge\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/course-material-walmart-challenge\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/course-material-walmart-challenge\/sample_submission.csv')","38239fc4":"print('Train-----------------------------------------------')\nprint(train.head())\nprint('Test------------------------------------------------')\nprint(test.head())\nprint('SampleSubmission------------------------------------')\nprint(sample_submission.head())","ed6be1ba":"train.shape,test.shape","78dd8df1":"train.head(5)","f9a1550b":"train.describe(include='all')","3eb9646c":"def levels(df):\n    return (pd.DataFrame({'dtype':df.dtypes, \n                         'levels':df.nunique(), \n                         'levels':[df[x].unique() for x in df.columns],\n                         'null_values':df.isna().sum(),\n                         'unique':df.nunique()}))\nlevels(train)","bfb5272e":"train.isnull().sum()","628a96ad":"print(train['MarkDown1'].isnull().sum()\/train.shape[0])\nprint(train['MarkDown2'].isnull().sum()\/train.shape[0])\nprint(train['MarkDown3'].isnull().sum()\/train.shape[0])\nprint(train['MarkDown4'].isnull().sum()\/train.shape[0])\nprint(train['MarkDown5'].isnull().sum()\/train.shape[0])","2278c0b4":"train[(train['Store']==1)&(train['Dept']==1)].sort_values(['Dept','Date'],ascending=True).head(10)","7b8d7314":"train['MarkDown1'][(train['Store']==3)&(train['Dept']==2)].mean()","51b8b3bb":"train['MarkDown1'][(train['Store']==3)&(train['Dept']==2)].median()","70d53989":"store=train['Store'].unique()\ndept=train['Dept'].unique()","4f7b2e64":"tstore=test['Store'].unique()\ntdept=test['Dept'].unique()","6e936b02":"store","f3813ce8":"dept","4b3dfd75":"train['key'] = train['Store'].astype(str)+'_'+train['Dept'].astype(str)+'_'+train['Date'].astype(str)\ntest['key'] = test['Store'].astype(str)+'_'+test['Dept'].astype(str)+'_'+test['Date'].astype(str)","1ad188cc":"train['Date'] = pd.to_datetime(train['Date'])\ntest['Date'] = pd.to_datetime(test['Date'])","aa4c5ca7":"train['WeekNo.'] = train['Date'].dt.strftime('%U')\ntest['WeekNo.'] = test['Date'].dt.strftime('%U')","c54ecda6":"import warnings\nwarnings.filterwarnings(\"ignore\")","72142586":"train['Weekly_Sales'][(train['Store']==1)&(train['Dept']==1)&(train['Date']=='2010-02-12')]","06479f72":"%%time\ntrain['median'] = pd.Series()\ntest['median'] = pd.Series()\ntrain['std'] = pd.Series()\ntest['std'] = pd.Series()\n\nfor i in store:\n    for j in dept:\n        train['median'][(train['Store']==i)&(train['Dept']==j)] = train['Weekly_Sales'][(train['Store']==i)&(train['Dept']==j)].median()\n        test['median'][(test['Store']==i)&(test['Dept']==j)] = train['Weekly_Sales'][(train['Store']==i)&(train['Dept']==j)].median()\n        train['std'][(train['Store']==i)&(train['Dept']==j)] = train['Weekly_Sales'][(train['Store']==i)&(train['Dept']==j)].std()\n        test['std'][(test['Store']==i)&(test['Dept']==j)] = train['Weekly_Sales'][(train['Store']==i)&(train['Dept']==j)].std()","9b51f56d":"for i in store:\n    train['median'][(train['Store']==i)&(train['median'].isnull())] = train['Weekly_Sales'][(train['Store']==i)&(train['Weekly_Sales']<=300)].median()\n    test['median'][(test['Store']==i)&(test['median'].isnull())] = train['Weekly_Sales'][(train['Store']==i)&(train['Weekly_Sales']<=300)].median()\n    train['std'][(train['Store']==i)&(train['std'].isnull())] = train['Weekly_Sales'][(train['Store']==i)&(train['Weekly_Sales']<=300)].std()\n    test['std'][(test['Store']==i)&(test['std'].isnull())] = train['Weekly_Sales'][(train['Store']==i)&(train['Weekly_Sales']<=300)].std()","de077057":"train.head(5)","7b6eed68":"%%time\ntrain['roll_mean'] = (train.groupby(['Store','Dept','Date'],sort=True)['Weekly_Sales']\n                        .rolling(3, min_periods=1).mean()\n                        .reset_index(drop=True))","6fd731d3":"train.head()","eda75c22":"train.isnull().sum()","cea764d6":"train.groupby(['Store','Dept','WeekNo.']).agg({'roll_mean':'mean'}).reset_index()","de0bd1b5":"roll_mean = train.groupby(['Store','Dept','WeekNo.']).agg({'roll_mean':'mean'}).reset_index()","05c73d5c":"test = pd.merge(test,roll_mean, left_on = ['Store','Dept','WeekNo.'], right_on=['Store','Dept','WeekNo.'],how='left')","d36ce2f4":"test.head()","a60dd0d7":"test[test['roll_mean'].isnull()].shape","c301ba1d":"test[test['roll_mean'].notnull()].shape","9661e135":"test1 = test[test['roll_mean'].isnull()]\ntest2 = test[test['roll_mean'].notnull()]\ntest1.drop('roll_mean',axis=1,inplace=True)","e5e69f2f":"roll_mean1 = train.groupby(['Store','WeekNo.']).agg({'roll_mean':'mean'}).reset_index()","3f797265":"roll_mean1.head()","14132eb7":"test1 = pd.merge(test1,roll_mean1, left_on = ['Store','WeekNo.'], right_on=['Store','WeekNo.'],how='left')","5a86d2b2":"test_n = test2.append(test1).sort_index(axis=0)","375029f0":"test_n.head(2)","29d5d996":"test.head(2)","549bc5bb":"test_n.shape,test.shape","a87c8293":"%%time\nfor i in store:\n    for j in dept:\n        train['MarkDown1'][(train['MarkDown1'].isnull())&\n                           (train['Store']==i)&\n                           (train['Dept']==j)] = train['MarkDown1'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        train['MarkDown2'][(train['MarkDown2'].isnull())&\n                           (train['Store']==i)&\n                           (train['Dept']==j)] = train['MarkDown2'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        train['MarkDown3'][(train['MarkDown3'].isnull())&\n                           (train['Store']==i)&\n                           (train['Dept']==j)] = train['MarkDown3'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        train['MarkDown4'][(train['MarkDown4'].isnull())&\n                           (train['Store']==i)&\n                           (train['Dept']==j)] = train['MarkDown4'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        train['MarkDown5'][(train['MarkDown5'].isnull())&\n                           (train['Store']==i)&\n                           (train['Dept']==j)] = train['MarkDown5'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        test_n['MarkDown1'][(test_n['MarkDown1'].isnull())&\n                           (test_n['Store']==i)&\n                           (test_n['Dept']==j)] = train['MarkDown1'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        test_n['MarkDown2'][(test_n['MarkDown2'].isnull())&\n                           (test_n['Store']==i)&\n                           (test_n['Dept']==j)] = train['MarkDown2'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        test_n['MarkDown3'][(test_n['MarkDown3'].isnull())&\n                           (test_n['Store']==i)&\n                           (test_n['Dept']==j)] = train['MarkDown3'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        test_n['MarkDown4'][(test_n['MarkDown4'].isnull())&\n                           (test_n['Store']==i)&\n                           (test_n['Dept']==j)] = train['MarkDown4'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()\n        test_n['MarkDown5'][(test_n['MarkDown5'].isnull())&\n                           (test_n['Store']==i)&\n                           (test_n['Dept']==j)] = train['MarkDown5'][(train['Store']==i)&\n                                                                    (train['Dept']==j)].median()","3639052f":"for i in store:\n    train['MarkDown1'][(train['MarkDown1'].isnull())&\n                           (train['Store']==i)] = train['MarkDown1'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    train['MarkDown2'][(train['MarkDown2'].isnull())&\n                           (train['Store']==i)] = train['MarkDown2'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    train['MarkDown3'][(train['MarkDown3'].isnull())&\n                           (train['Store']==i)] = train['MarkDown3'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    train['MarkDown4'][(train['MarkDown4'].isnull())&\n                           (train['Store']==i)] = train['MarkDown4'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    train['MarkDown5'][(train['MarkDown5'].isnull())&\n                           (train['Store']==i)] = train['MarkDown5'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    test_n['MarkDown1'][(test_n['MarkDown1'].isnull())&\n                           (test_n['Store']==i)] = train['MarkDown1'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    test_n['MarkDown2'][(test_n['MarkDown2'].isnull())&\n                           (test_n['Store']==i)] = train['MarkDown2'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    test_n['MarkDown3'][(test_n['MarkDown3'].isnull())&\n                           (test_n['Store']==i)] = train['MarkDown3'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    test_n['MarkDown4'][(test_n['MarkDown4'].isnull())&\n                           (test_n['Store']==i)] = train['MarkDown4'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()\n    test_n['MarkDown5'][(test_n['MarkDown5'].isnull())&\n                           (test_n['Store']==i)] = train['MarkDown5'][(train['Store']==i)&\n                                                                    (train['Weekly_Sales']<=300)].median()","bee06bf0":"test_n.isnull().sum()","73b86fe3":"import matplotlib.pylab as plt\nimport seaborn as sns\nsns.boxplot(train['MarkDown1'],orient='v')","dbca6d8b":"sns.boxplot(train['MarkDown2'],orient='v')","324624d9":"sns.boxplot(train['MarkDown3'],orient='v')","496aa8e9":"sns.boxplot(train['MarkDown4'],orient='v')","6f314d99":"sns.boxplot(train['MarkDown5'],orient='v')","73625242":"p99 = np.nanpercentile(train['MarkDown1'][(train['Store']==3)&(train['Dept']==2)],99)\nprint(p99)\np01 = np.nanpercentile(train['MarkDown1'][(train['Store']==3)&(train['Dept']==2)],1)\nprint(p01)\nprint(train[(train['Store']==3)&(train['Dept']==2)&(train['MarkDown1']>=p99)].shape)\nprint(train[(train['Store']==3)&(train['Dept']==2)&(train['MarkDown1']<=p01)].shape)","85521a9b":"for i in store:\n    md1_p99 = np.percentile(train['MarkDown1'][(train['Store']==i)],99)\n    md1_p01 = np.percentile(train['MarkDown1'][(train['Store']==i)],1)\n    md2_p99 = np.percentile(train['MarkDown2'][(train['Store']==i)],99)\n    md2_p01 = np.percentile(train['MarkDown2'][(train['Store']==i)],1)\n    md3_p99 = np.percentile(train['MarkDown3'][(train['Store']==i)],99)\n    md3_p01 = np.percentile(train['MarkDown3'][(train['Store']==i)],1)\n    md4_p99 = np.percentile(train['MarkDown4'][(train['Store']==i)],99)\n    md4_p01 = np.percentile(train['MarkDown4'][(train['Store']==i)],1)\n    md5_p99 = np.percentile(train['MarkDown5'][(train['Store']==i)],99)\n    md5_p01 = np.percentile(train['MarkDown5'][(train['Store']==i)],1)\n\n    train['MarkDown1'][(train['MarkDown1']>=md1_p99)&(train['Store']==i)] = md1_p99\n    train['MarkDown1'][(train['MarkDown1']<=md1_p01)&(train['Store']==i)] = md1_p01\n\n    train['MarkDown2'][(train['MarkDown2']>=md2_p99)&(train['Store']==i)] = md2_p99\n    train['MarkDown2'][(train['MarkDown2']<=md2_p01)&(train['Store']==i)] = md2_p01\n\n    train['MarkDown3'][(train['MarkDown3']>=md3_p99)&(train['Store']==i)] = md3_p99\n    train['MarkDown3'][(train['MarkDown3']<=md3_p01)&(train['Store']==i)] = md3_p01\n\n    train['MarkDown4'][(train['MarkDown4']>=md4_p99)&(train['Store']==i)] = md4_p99\n    train['MarkDown4'][(train['MarkDown4']<=md4_p01)&(train['Store']==i)] = md4_p01\n\n    train['MarkDown5'][(train['MarkDown5']>=md5_p99)&(train['Store']==i)] = md5_p99\n    train['MarkDown5'][(train['MarkDown5']<=md5_p01)&(train['Store']==i)] = md5_p01\n    \n    test_n['MarkDown1'][(test_n['MarkDown1']>=md1_p99)&(test_n['Store']==i)] = md1_p99\n    test_n['MarkDown1'][(test_n['MarkDown1']<=md1_p01)&(test_n['Store']==i)] = md1_p01\n    \n    test_n['MarkDown2'][(test_n['MarkDown2']>=md2_p99)&(test_n['Store']==i)] = md2_p99\n    test_n['MarkDown2'][(test_n['MarkDown2']<=md2_p01)&(test_n['Store']==i)] = md2_p01\n    \n    test_n['MarkDown3'][(test_n['MarkDown3']>=md3_p99)&(test_n['Store']==i)] = md3_p99\n    test_n['MarkDown3'][(test_n['MarkDown3']<=md3_p01)&(test_n['Store']==i)] = md3_p01\n    \n    test_n['MarkDown4'][(test_n['MarkDown4']>=md4_p99)&(test_n['Store']==i)] = md4_p99\n    test_n['MarkDown4'][(test_n['MarkDown4']<=md4_p01)&(test_n['Store']==i)] = md4_p01\n    \n    test_n['MarkDown5'][(test_n['MarkDown5']>=md5_p99)&(test_n['Store']==i)] = md5_p99\n    test_n['MarkDown5'][(test_n['MarkDown5']<=md5_p01)&(test_n['Store']==i)] = md5_p01","2ef0d847":"train['cel_week']=pd.Series()\ntest_n['cel_week'] = pd.Series()\ntrain['cel_week'][(train['WeekNo.']==48)|(train['WeekNo.']==52)] = 1\ntrain['cel_week'][(train['WeekNo.']!=48)&(train['WeekNo.']!=52)] = 0\ntest_n['cel_week'][(test_n['WeekNo.']==48)|(test_n['WeekNo.']==52)] = 1\ntest_n['cel_week'][(test_n['WeekNo.']!=48)&(test_n['WeekNo.']!=52)] = 0","99dbb903":"train[train['MarkDown5']>=60000].shape","076118ac":"train['MarkDown5'][train['MarkDown5']>=60000]=60000\ntest_n['MarkDown5'][test_n['MarkDown5']>=60000]=60000","d2a6a00e":"train['MarkDown4'][train['MarkDown4']>=30000]=30000\ntest_n['MarkDown4'][test_n['MarkDown4']>=30000]=30000","09b9b92e":"train['MarkDown3'][train['MarkDown3']>=11000]=11000\ntest_n['MarkDown3'][test_n['MarkDown3']>=11000]=11000","4f357a5c":"train['MarkDown2'][train['MarkDown2']>=40000]=40000\ntest_n['MarkDown2'][test_n['MarkDown2']>=40000]=40000","3acc4307":"train['MarkDown1'][train['MarkDown1']>=40000]=40000\ntest_n['MarkDown1'][test_n['MarkDown1']>=40000]=40000","2dd2746d":"sns.boxplot(train['Weekly_Sales'],orient='v')","58497e12":"train[train['Weekly_Sales']>=200000].shape","027db269":"train[train['Weekly_Sales']<1].shape","dd8b8b24":"train_n = train[(train['Weekly_Sales']>=1)&(train['Weekly_Sales']<=200000)]","20ad7001":"train_n.shape,train.shape","f4f2ecd0":"test_n.shape,test.shape","1890555a":"b = sns.distplot(np.sqrt(train_n['Weekly_Sales']))\nb.set_title('Histogram of WeeklySales',fontsize = 16)\nb.set_xlabel(\"WeeklySales\",fontsize=14)\nplt.show()","c4d645ab":"f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True, figsize =(15,15)) #sharey -> share 'Price' as y\nax1.scatter(train_n['Date'][(train_n['Store']==1)&(train_n['Dept']==1)].sort_values(),\n            train_n['Weekly_Sales'][(train_n['Store']==1)&(train_n['Dept']==1)])\nax1.set_title('WeeklySales and Date for Store1, Dept1')\nax2.scatter(train_n['Date'][(train_n['Store']==1)&(train_n['Dept']==2)].sort_values(),\n            train_n['Weekly_Sales'][(train_n['Store']==1)&(train_n['Dept']==2)])\nax2.set_title('WeeklySales and Date for Store1, Dept2')\nax3.scatter(train_n['Date'][(train_n['Store']==1)&(train_n['Dept']==3)].sort_values(),\n            train_n['Weekly_Sales'][(train_n['Store']==1)&(train_n['Dept']==3)])\nax3.set_title('WeeklySales and Date for Store1, Dept3')\nplt.show()","834af59a":"f, (ax1) = plt.subplots(1, 1, sharey=True, figsize =(15,5))\nax1.scatter(train_n['Date'][train_n['Store']==2].sort_values(),\n            train_n['Weekly_Sales'][train_n['Store']==2])\nplt.show()","c77a7085":"print(train_n.Date.max())\nprint(train_n.Date.min())\nprint(test_n.Date.max())\nprint(test_n.Date.min())","64e0b311":"train_n = train_n.sort_values(['Store','Dept','Date'])\ntest_n = test_n.sort_values(['Store','Dept','Date'])","64653be9":"train_n.head(20)","b6f9d5b5":"test_n.head(20)","893c129e":"print(train_n['Weekly_Sales'].max())\nprint(train_n['Weekly_Sales'].min())\nprint(train_n['Weekly_Sales'].median())","09e06833":"import seaborn as sns\n\nsns.set_style('whitegrid')\n\ntrain_n['Weekly_Sales'].plot(kind='hist')","15c3586e":"plt.figure(figsize=(15,7))\nbins_list = [0,3999,7999,12999,24999,37999,49999,74999,99999,149999,199999]\nplt.hist(train_n['Weekly_Sales'], bins=bins_list, alpha=0.5)","8094f395":"train_n['bin']=pd.Series()\ntrain_n['bin']=pd.cut(train_n['Weekly_Sales'],bins_list)","edf51b91":"train_n['bin'].value_counts()","b25820eb":"bins = train_n.groupby(['Store','Dept']).agg({'bin':lambda x:x.value_counts().index[0]}).reset_index()","151e81a9":"test_n = pd.merge(test_n,bins,left_on=['Store','Dept'],right_on=['Store','Dept'],how='left')","0b488a93":"bins1 = train_n.groupby(['Store']).agg({'bin':lambda x:x.value_counts().index[0]}).reset_index()\nbins1","1755c966":"store = test_n['Store'][test_n['bin'].isnull()].unique()\nstore","20c9b0ee":"test_n['bin'][(test_n['bin'].isnull())&(test_n['Store']==3)]","de4ecbde":"for st in store:\n    #print(bins1['bin'][bins1['Store']==st])\n    test_n['bin'][(test_n['bin'].isnull())&(test_n['Store']==st)] = bins1['bin'][bins1['Store']==st].values","a8f3e1af":"train_n.isnull().sum()","da345093":"test_n.isnull().sum()","ae833174":"%%time\ntr = pd.DataFrame()\nval = pd.DataFrame()\nfor i in store:\n    for j in dept:\n        df = train_n[(train_n['Store']==i)&(train_n['Dept']==j)]\n        #print(df.shape)\n        c = int(df.shape[0]*0.8)\n        tr = tr.append(df.iloc[0:c,:])\n        val = val.append(df.iloc[c:,:])\n        #print(tr.shape,val.shape)","2823ea32":"train_n.shape, tr.shape,val.shape,test_n.shape","869a699b":"tr.set_index('key',inplace = True)\nval.set_index('key', inplace = True)\ntest_n.set_index('key',inplace=True)\ntr.drop('Date',axis=1,inplace=True)\nval.drop('Date',axis=1,inplace=True)\ntest_n.drop('Date',axis=1,inplace=True)","5d4f5f92":"x_train = tr.drop('Weekly_Sales',axis=1)\nx_val = val.drop('Weekly_Sales',axis=1)\ny_train = tr['Weekly_Sales']\ny_val = val['Weekly_Sales']","081e5270":"x_train.columns","c26040b8":"num_cols = ['Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5','CPI','Unemployment','Size','median','std','roll_mean']\ncat_cols = ['Dept', 'IsHoliday', 'Store', 'Type', 'WeekNo.','cel_week','bin']","f9edca9e":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nscale.fit(x_train[num_cols])\nx_train[num_cols] = scale.transform(x_train[num_cols])\nx_val[num_cols] = scale.transform(x_val[num_cols])\ntest_n[num_cols] = scale.transform(test_n[num_cols])","f995e7ee":"for col in cat_cols:\n    x_train[col] = x_train[col].astype('category')\n    x_val[col] = x_val[col].astype('category')\n    test_n[col] = test_n[col].astype('category')","4a2b557b":"x_train = pd.get_dummies(x_train,columns=cat_cols,drop_first=True)\nx_val = pd.get_dummies(x_val,columns=cat_cols,drop_first=True)\ntest_n = pd.get_dummies(test_n,columns=cat_cols,drop_first=True)","6a85f9fa":"x_train.shape,x_val.shape,test_n.shape","91f167d3":"test_n.columns.intersection(x_train.columns)","e5f68328":"x_train.columns.difference(test_n.columns)","978980f4":"set(x_train.columns)-set(test_n.columns)","637f35d6":"set(test_n.columns)-set(x_train.columns)","62873b66":"x_train.head(2)","fd81efa8":"test_n.rename(columns={'bin_(7999.0, 12999.0]':'bin_(7999, 12999]',\n                      'bin_(3999.0, 7999.0]':'bin_(3999, 7999]',\n                      'bin_(12999.0, 24999.0]':'bin_(12999, 24999]',\n                      'bin_(24999.0, 37999.0]':'bin_(24999, 37999]',\n                       'bin_(37999.0, 49999.0]':'bin_(37999, 49999]',\n                      'bin_(49999.0, 74999.0]':'bin_(49999, 74999]',\n                       'bin_(74999.0, 99999.0]':'bin_(74999, 99999]',\n                      'bin_(99999.0, 149999.0]':'bin_(99999, 149999]',\n                      'bin_(149999.0, 199999.0]':'bin_(149999, 199999]'},inplace=True)","3bf1f23a":"test_n.head(2)","9467b719":"test_n.columns.difference(x_train.columns)","da78e2a5":"test_n.drop(test_n.columns.difference(x_train.columns),axis=1,inplace=True)","4aa78b23":"x_train.shape,x_val.shape,test_n.shape,y_train.shape,y_val.shape,test.shape","7ff669c5":"from sklearn.linear_model import LinearRegression\nlinreg = LinearRegression() \nlinreg.fit(x_train, y_train)\ntrain_pred = linreg.predict(x_train)\nval_pred = linreg.predict(x_val)","4ca83ddc":"from sklearn.metrics import mean_squared_error, r2_score\nprint(\"The R2 value on val dataset: {} \\n\".format(r2_score(y_pred=(val_pred), y_true=y_val)))\nprint(\"The R2 value on train dataset: {} \\n\".format(r2_score(y_pred=(train_pred), y_true=y_train)))\nprint(\"The Mean Squared Error on val dataset: {} \\n\".format(mean_squared_error(y_pred=(val_pred),y_true=y_val)))\nprint(\"The Mean Squared Error on train dataset: {} \\n\".format(mean_squared_error(y_pred=(train_pred),y_true=y_train)))","c7fe4a6e":"MAE=np.mean(np.abs(y_train - train_pred))\nprint(MAE)","ddb46bfd":"MAE_val=np.mean(np.abs(y_val - val_pred))\nprint(MAE_val)","6cb0110b":"x_train.columns","7c128c90":"feat = x_train[['Temperature', 'Fuel_Price', 'MarkDown1',\n       'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI',\n       'Unemployment', 'Size','median','std','roll_mean']]","e85b856b":"feat.shape","33bb8416":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nVif = pd.DataFrame()\nVif[\"VIF Factor\"] = [variance_inflation_factor(feat.values,i) for i in range(feat.shape[1])]\nVif[\"features\"] = feat.columns\nVif","b365a0d3":"pd.DataFrame(y_train).shape","af4ddcf1":"from sklearn.preprocessing import MinMaxScaler\ntarget_scaler = MinMaxScaler()\ny_train1 = pd.DataFrame(y_train)\ny_val1 = pd.DataFrame(y_val)\ntarget_scaler.fit(y_train1)\ntrain_y = target_scaler.transform(y_train1)\nval_y = target_scaler.transform(y_val1)","ce2c36a6":"linreg = LinearRegression() \nlinreg.fit(x_train, train_y)\ntrain_pred_t = linreg.predict(x_train)\nval_pred_t = linreg.predict(x_val)","81cbc402":"train_pred_t = target_scaler.inverse_transform(train_pred_t)\nval_pred_t = target_scaler.inverse_transform(val_pred_t)","2ceaeec1":"from sklearn.metrics import mean_squared_error, r2_score\nprint(\"The R2 value on val dataset: {} \\n\".format(r2_score(y_pred=val_pred_t, y_true=y_val)))\nprint(\"The R2 value on train dataset: {} \\n\".format(r2_score(y_pred=train_pred_t, y_true=y_train)))\nprint(\"The Mean Squared Error on val dataset: {} \\n\".format(mean_squared_error(y_pred=val_pred_t,y_true=y_val)))\nprint(\"The Mean Squared Error on train dataset: {} \\n\".format(mean_squared_error(y_pred=train_pred_t,y_true=y_train)))","fa0f11e7":"from sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(max_depth=20,max_features=15,min_samples_split=2,min_samples_leaf=1)\nregressor.fit(x_train,train_y)","b591d6dd":"train_pred_t = regressor.predict(x_train)\nval_pred_t = regressor.predict(x_val)","5bedd626":"train_pred_t.shape","069afc8d":"train_pred_t = target_scaler.inverse_transform(pd.DataFrame(train_pred_t))\nval_pred_t = target_scaler.inverse_transform(pd.DataFrame(val_pred_t))","1d3a7114":"print(\"The R2 value on val dataset: {} \\n\".format(r2_score(y_pred=val_pred_t, y_true=y_val)))\nprint(\"The R2 value on train dataset: {} \\n\".format(r2_score(y_pred=train_pred_t, y_true=y_train)))\nprint(\"The Mean Squared Error on val dataset: {} \\n\".format(mean_squared_error(y_pred=val_pred_t,y_true=y_val)))\nprint(\"The Mean Squared Error on train dataset: {} \\n\".format(mean_squared_error(y_pred=train_pred_t,y_true=y_train)))\nprint(\"The RMSE on val dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=val_pred_t,y_true=y_val))))\nprint(\"The RMSE on train dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=train_pred_t,y_true=y_train))))","377d30ac":"regressor1 = DecisionTreeRegressor(max_depth=14,max_features=40,min_samples_split=2,min_samples_leaf=1)\nregressor1.fit(x_train,y_train)\ntrain_pred = regressor1.predict(x_train)\nval_pred = regressor1.predict(x_val)\nprint(\"The R2 value on val dataset: {} \\n\".format(r2_score(y_pred=val_pred, y_true=y_val)))\nprint(\"The R2 value on train dataset: {} \\n\".format(r2_score(y_pred=train_pred, y_true=y_train)))\nprint(\"The Mean Squared Error on val dataset: {} \\n\".format(mean_squared_error(y_pred=val_pred,y_true=y_val)))\nprint(\"The Mean Squared Error on train dataset: {} \\n\".format(mean_squared_error(y_pred=train_pred,y_true=y_train)))\nprint(\"The RMSE on val dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=val_pred,y_true=y_val))))\nprint(\"The RMSE on train dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=train_pred,y_true=y_train))))\nprint(\"The Mean Absolute Error on val dataset: {} \\n\".format(np.mean(np.abs(val_pred-y_val))))\nprint(\"The Mean Absolute Error on train dataset: {} \\n\".format(np.mean(np.abs(train_pred-y_train))))","e771dd1f":"np.mean(np.abs(val_pred-y_val)\/y_val)*100","a9dd602f":"np.mean(np.abs(train_pred-y_train)\/y_train)*100","b98a3d60":"%%time\nfrom sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor()\nrfr\n\nrfr.fit(X=x_train,y=train_y)","67098cdb":"train_pred_t = rfr.predict(x_train)\nval_pred_t = rfr.predict(x_val)\ntrain_pred_t = target_scaler.inverse_transform(pd.DataFrame(train_pred_t))\nval_pred_t = target_scaler.inverse_transform(pd.DataFrame(val_pred_t))","05179645":"rfr","539749ec":"print(\"The R2 value on val dataset: {} \\n\".format(r2_score(y_pred=val_pred_t, y_true=y_val)))\nprint(\"The R2 value on train dataset: {} \\n\".format(r2_score(y_pred=train_pred_t, y_true=y_train)))\nprint(\"The Mean Squared Error on val dataset: {} \\n\".format(mean_squared_error(y_pred=val_pred_t,y_true=y_val)))\nprint(\"The Mean Squared Error on train dataset: {} \\n\".format(mean_squared_error(y_pred=train_pred_t,y_true=y_train)))\nprint(\"The RMSE on val dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=val_pred_t,y_true=y_val))))\nprint(\"The RMSE on train dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=train_pred_t,y_true=y_train))))","f56c82b3":"%%time\n\nrfr1=RandomForestRegressor(n_estimators=300, max_features='auto',max_depth=9,bootstrap=False)\nrfr1\n\nrfr1.fit(X=x_train,y=y_train)\ntrain_pred = rfr1.predict(x_train)\nval_pred = rfr1.predict(x_val)\n\n\nprint(\"The R2 value on val dataset: {} \\n\".format(r2_score(y_pred=val_pred, y_true=y_val)))\nprint(\"The R2 value on train dataset: {} \\n\".format(r2_score(y_pred=train_pred, y_true=y_train)))\nprint(\"The Mean Squared Error on val dataset: {} \\n\".format(mean_squared_error(y_pred=val_pred,y_true=y_val)))\nprint(\"The Mean Squared Error on train dataset: {} \\n\".format(mean_squared_error(y_pred=train_pred,y_true=y_train)))\nprint(\"The RMSE on val dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=val_pred,y_true=y_val))))\nprint(\"The RMSE on train dataset: {} \\n\".format(np.sqrt(mean_squared_error(y_pred=train_pred,y_true=y_train))))\nprint(\"The Mean Absolute Error on val dataset: {} \\n\".format(np.mean(np.abs(val_pred-y_val))))\nprint(\"The Mean Absolute Error on train dataset: {} \\n\".format(np.mean(np.abs(train_pred-y_train))))","2bfc3bad":"test_pred = rfr1.predict(test_n)","9135c9b0":"test3 = test_n.reset_index()","b0be1c64":"test3['Weekly_Sales'] = test_pred","0669e4da":"test3.head(2)","713c8b68":"sample_submission.drop(['Weekly_Sales'],axis=1,inplace=True)\nsample_submission.head()","f3a83fe9":"test3.shape,sample_submission.shape","77f8ad94":"sample = sample_submission.merge(test3[['key','Weekly_Sales']], left_on='id',right_on='key', how='left')","870cbe04":"sample.drop('key',axis=1,inplace=True)\nsample.head()","18663c39":"sample.to_csv('sample_submission.csv',index=False)","d590e049":"from sklearn.preprocessing import LabelEncoder\ncols = ['Store','Dept','IsHoliday','cel_week']\nimport bisect\nfor col in cols:\n    le = LabelEncoder()\n    x_train[col] = le.fit_transform(x_train[col])\n    x_val[col] = x_val[col].map(lambda s: 'other' if s not in le.classes_ else s)\n    test_n[col] = test_n[col].map(lambda s: 'other' if s not in le.classes_ else s)\n    le_classes = le.classes_.tolist()\n    #bisect.insort_left(le_classes, 'other')\n    le.classes_ = le_classes\n    x_val[col] = le.transform(x_val[col])\n    test_n[col] = le.transform(test_n[col])"}}