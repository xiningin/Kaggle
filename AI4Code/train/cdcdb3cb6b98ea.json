{"cell_type":{"ee883996":"code","4a6b6342":"code","bbbc5454":"code","0d46ab18":"code","51b7e144":"code","ee4c5592":"code","942cd726":"code","07ddb130":"code","6ae0d1b7":"code","b0754d15":"code","be006618":"code","d686e603":"code","d13ceea6":"code","9c4ce111":"code","ea34b421":"code","0d1c21cb":"code","d33f0a0d":"code","e159a631":"code","6c18f97e":"code","4ff00181":"code","583546ba":"code","b2669482":"code","d82153a2":"code","f6aef717":"code","08b42a55":"code","b6423828":"markdown","a3a2fa1e":"markdown","ed3c2642":"markdown","6374338b":"markdown","fd9a4a0c":"markdown"},"source":{"ee883996":"import pandas as pd\nimport numpy as np\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4a6b6342":"pip install keras","bbbc5454":"import tensorflow as tf\nimport keras","0d46ab18":"# base_dir='D:\\Machine Learning\\Emotion Detection\\edu'","51b7e144":"# train_dir = 'D:\/Machine Learning\/Emotion Detection\/edu\/train\/'\n# test_dir = 'D:\/Machine Learning\/Emotion Detection\/edu\/test\/'\ntrain_dir = '..\/input\/fer2013\/train\/'\ntest_dir = '..\/input\/fer2013\/test\/'","ee4c5592":"row=48\ncol=48\nclasses = 7","942cd726":"def count_expression(path,set_):\n    dict_={}\n    for expression in os.listdir(path):\n        dir_ = path + expression\n        dict_[expression]=len(os.listdir(dir_))\n\n    df = pd.DataFrame(dict_,index=[set_])\n    return df","07ddb130":"train_count=count_expression(train_dir,'train_count')\nprint(train_count)","6ae0d1b7":"test_count=count_expression(test_dir,'test')\nprint(test_count)","b0754d15":"train_count.transpose().plot(kind = \"bar\")\nplt.title('Plot of number of images in train dataset')","be006618":"test_count.transpose().plot(kind = \"bar\")\nplt.title('Plot of number of images in test dataset')","d686e603":"plt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(train_dir):\n    img = keras.preprocessing.image.load_img((train_dir + expression +'\/'+ os.listdir(train_dir + expression)[1]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()","d13ceea6":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D,Dense, MaxPooling2D,Flatten,Dropout,Activation, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD\nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint, CSVLogger,TensorBoard,EarlyStopping,ReduceLROnPlateau\nimport datetime\nfrom tensorflow.keras.utils import plot_model","9c4ce111":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                    zoom_range=0.3, \n                                    horizontal_flip=True)\n# rotation_range=40,\n#         width_shift_range=0.2,\n#         height_shift_range=0.2,\n#         shear_range=0.2,\n#         zoom_range=0.2,\n#         horizontal_flip=True,\n#         fill_mode='nearest'\n\ntrain_set=train_datagen.flow_from_directory(train_dir,\n                                            batch_size=64,\n                                            target_size=(48,48),\n                                            shuffle=True,\n                                            color_mode=\"grayscale\",class_mode='categorical')\n\n\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_set = test_datagen.flow_from_directory(test_dir,\n                                            batch_size=64,\n                                            target_size=(48,48),\n                                            shuffle=True,\n                                            color_mode=\"grayscale\",class_mode='categorical')","ea34b421":"train_set.class_indices","0d1c21cb":"#initalising the CNN model\n\ndef get_model(input_size, classes=7):\n     #BUILDING the CNN\n    model = tf.keras.models.Sequential()   \n\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(2, 2))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(classes, activation='softmax'))\n\n    #COMPLILING the CNN\n    model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    return model","d33f0a0d":"our_model = get_model((row,col,1),classes)\nour_model.summary()","e159a631":"# plot_model(our_model,to_file='Our Model Architecture.png',show_shapes=True,show_layer_names=True)","6c18f97e":"\nsteps_per_epoch = train_set.n \/\/ train_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\nmod = our_model.fit(x=train_set,\n                 validation_data=test_set,\n                 epochs=60,\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)\n\n","4ff00181":"model_json=our_model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)","583546ba":"our_model.save_weights('model_best_weights.h5')","b2669482":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,2)\nplt.plot(mod.history['accuracy'])\nplt.plot(mod.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.subplot(1,2,1)\nplt.plot(mod.history['loss'])\nplt.plot(mod.history['val_loss'])\nplt.title('model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","d82153a2":"train_loss, train_accu = our_model.evaluate(train_set)\ntest_loss, test_accu = our_model.evaluate(test_set)\nprint(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))","f6aef717":"#ON TRAINING SET\ny_pred = our_model.predict(train_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm_train = confusion_matrix(train_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_train)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(train_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_train, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","08b42a55":"#ON TESTING SET\ny_pred = our_model.predict(test_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\n#from sklearn.metrics import classification_report, confusion_matrix\ncm_test = confusion_matrix(test_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_test)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(test_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_test, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","b6423828":"### COUNT EXPRESSION FUNCTION TO STORE NO. OF IMAGES IN A EXPRESSION FOLDER","a3a2fa1e":"## MODEL-BUILDING","ed3c2642":"## Preprocessing","6374338b":"## IMPORTING LIBRARIES and Defining our directories where files are stored","fd9a4a0c":"### PERFORMANCE PLOT"}}