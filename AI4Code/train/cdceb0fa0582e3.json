{"cell_type":{"9574a80c":"code","ad16b155":"code","530ee241":"code","018bc884":"code","ff89edbd":"code","6b2929cf":"code","05a0cf99":"code","7947ea0a":"code","80d881a6":"code","15843c39":"code","22188050":"markdown","6826e9cc":"markdown"},"source":{"9574a80c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad16b155":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","530ee241":"dataset = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndataset.head()","018bc884":"X=dataset.iloc[:,3:]\nX.head()","ff89edbd":"X.iloc[:,0].plot(kind = 'hist')\nplt.xlabel('Annual Income')\nplt.show()","6b2929cf":"X.iloc[:,1].plot(kind = 'hist')\nplt.xlabel('Spending score')\nplt.show()","05a0cf99":"#Elbow method\nfrom sklearn.cluster import KMeans\nwcss=[]\nfor i in range (1,11):\n    kmeans=KMeans(n_clusters=i,init='k-means++', random_state = 75)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss)\nplt.title('The elbow method')\nplt.xlabel('The number of Clusters')\nplt.ylabel('Wcss')\nplt.show()","7947ea0a":"#Here the optimal value of k is 5.\nkmeans=KMeans(n_clusters=5,init='k-means++', random_state = 96)\ny_kmeans= kmeans.fit_predict(X)\nprint(y_kmeans)","80d881a6":"#Visualising the clusters\nplt.scatter(X[y_kmeans==0]['Annual Income (k$)'], X[y_kmeans==0]['Spending Score (1-100)'], s = 100,c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans==1]['Annual Income (k$)'], X[y_kmeans==1]['Spending Score (1-100)'], s = 100,c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans==2]['Annual Income (k$)'], X[y_kmeans==2]['Spending Score (1-100)'], s = 100,c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans==3]['Annual Income (k$)'], X[y_kmeans==3]['Spending Score (1-100)'], s = 100,c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans==4]['Annual Income (k$)'], X[y_kmeans==4]['Spending Score (1-100)'], s = 100,c = 'black',label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s = 300, c = 'yellow', label = 'centroids')\nplt.title('Customer Clusters')\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.legend()\nplt.show()","15843c39":"from sklearn import metrics\nprint(metrics.silhouette_score(X,y_kmeans))","22188050":"To Find the Optimal Cluster we will use elbow method","6826e9cc":"**K-Means Clustering**"}}