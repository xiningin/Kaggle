{"cell_type":{"64603600":"code","dc644771":"code","a6f0bbe8":"code","46eaee74":"code","7ae495e0":"code","185eddff":"code","cb6ff99d":"code","335574ad":"code","fdef2a35":"code","eba0d4b4":"code","6ef2a7ed":"code","0d7dd20a":"code","dff33665":"code","9849d2bb":"code","c1da96cc":"code","e70ce729":"code","721d0cdd":"code","93a67b50":"code","6126ad15":"code","ea9c8537":"code","3991e2d5":"markdown","3e5fd101":"markdown","a45fc432":"markdown","98a1f86d":"markdown","670bc42d":"markdown"},"source":{"64603600":"ver = 'nn_bl_20'\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nplt.style.use(['seaborn-darkgrid'])\nplt.rcParams['font.family'] = 'DejaVu Sans'\nimport time\nfrom datetime import datetime\n\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization\nfrom keras import regularizers\nfrom keras.constraints import max_norm\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, Binarizer, KernelCenterer\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\n\nfrom umap import UMAP\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n% matplotlib inline\n\nRANDOM_STATE = 78","dc644771":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntarget = pd.read_csv('..\/input\/sample_submission.csv')\n","a6f0bbe8":"train.head()","46eaee74":"train.describe()","7ae495e0":"train.info()","185eddff":"train['target'].value_counts().sort_index(ascending=False).plot(kind='barh', \n                                                                          figsize=(15,6))\nplt.title('Target', fontsize=18);","cb6ff99d":"X = train.iloc[:,2:].values\ny = train.iloc[:,1].values\ntest = test.iloc[:,1:].values","335574ad":"sc0 = StandardScaler()\nsc1 = RobustScaler()\n","fdef2a35":"X_train0 = sc0.fit_transform(X)\nX_test0 = sc0.transform(test)\nX_train1 = sc1.fit_transform(X)\nX_test1 = sc1.transform(test)\n","eba0d4b4":"fig, ax = plt.subplots(1, 2, figsize = (24, 12))\npca = PCA()\nX_reduced0 = pca.fit_transform(X_train0)\nX_reduced1 = pca.fit_transform(X_train1)\n\n\nax[0].scatter(X_reduced0[:, 0], X_reduced0[:, 1], c=y,\n            edgecolor='none', alpha=0.7, s=40,\n            cmap=plt.cm.get_cmap('bwr', 2))\nax[0].set_title('PCA projection StdScalar')\n\nax[1].scatter(X_reduced1[:, 0], X_reduced1[:, 1], c=y,\n            edgecolor='none', alpha=0.7, s=40,\n            cmap=plt.cm.get_cmap('bwr', 2))\nax[1].set_title('PCA projection Robust')\n\nprint(pca.n_components_)","6ef2a7ed":"def auc(y_true, y_pred):\n    auc = tf.metrics.auc(y_true, y_pred)[1]\n    K.get_session().run(tf.local_variables_initializer())\n    return auc","0d7dd20a":"def modelir():\n    model = Sequential()\n\n    #input \n    model.add(Dense(200, input_dim=200, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint = max_norm(5.)))\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.2))\n\n    #1 \n    model.add(Dense(200, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.1))\n    \n    #2\n    model.add(Dense(100, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.1))\n    \n    #2\n    model.add(Dense(50, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n    model.add(Activation('tanh'))\n    model.add(Dropout(0.1))\n    \n    #output\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", auc])\n    return model\n#print(model.summary())","dff33665":"def simple_blend1(X, y, test):\n    model = modelir()\n    pred = pd.DataFrame()\n    for i in range(1, 10):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = i)\n        earlystopper = EarlyStopping(patience=5, verbose=1)\n        history = model.fit(X_train, y_train, batch_size=16384, epochs=500, validation_split=0.2, verbose=2, callbacks=[earlystopper], shuffle=True)\n        scores = model.evaluate(X_test, y_test, verbose=0)\n        print(\"accuracy for test data: %.2f%%\" % (scores[1]*100))\n        plt.plot(history.history['acc'], label='accuracy for train data')\n        plt.plot(history.history['val_acc'], label='validation data accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.legend()\n        plt.show()\n        y_pred = model.predict(X_test)\n        y_pred = (y_pred > 0.7)\n        cm = confusion_matrix(y_test, y_pred)\n        print(cm)\n        y_pred_t = model.predict(test)\n        print(y_pred_t.T[0])\n        pred[i] = y_pred_t.T[0]\n    return pred","9849d2bb":"pr1 = simple_blend1(X, y, test)","c1da96cc":"pr1['mean'] = pr1.mean(axis=1)\npr1.head()","e70ce729":"def simple_blend2(X, y, test):\n    pred = pd.DataFrame()\n    for i in range(1, 10):\n        model = modelir()\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = i)\n        earlystopper = EarlyStopping(patience=5, verbose=1)\n        history = model.fit(X_train, y_train, batch_size=512, epochs=500, validation_split=0.2, verbose=2, callbacks=[earlystopper], shuffle=True)\n        scores = model.evaluate(X_test, y_test, verbose=0)\n        print(\"accuracy for test data: %.2f%%\" % (scores[1]*100))\n        plt.plot(history.history['acc'], label='accuracy for train data')\n        plt.plot(history.history['val_acc'], label='validation data accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.legend()\n        plt.show()\n        y_pred = model.predict(X_test)\n        y_pred = (y_pred > 0.7)\n        cm = confusion_matrix(y_test, y_pred)\n        print(cm)\n        y_pred_t = model.predict(test)\n        print(y_pred_t.T[0])\n        pred[i] = y_pred_t.T[0]\n    return pred","721d0cdd":"pr2 = simple_blend2(X, y, test)","93a67b50":"pr2['mean'] = pr2.mean(axis=1)\npr2.head()","6126ad15":"filename = 'subm_{}_{}_'.format(ver, datetime.now().strftime('%Y-%m-%d'))\ntarget['target'] = pr1['mean']\ntarget.to_csv(filename+'1'+'.csv', index=False)\ntarget['target'] = pr2['mean']\ntarget.to_csv(filename+'2'+'.csv', index=False)","ea9c8537":"target['target'] = (pr1['mean']+pr2['mean'])\/2\ntarget.to_csv(filename+'3'+'.csv', index=False)","3991e2d5":"**Model**","3e5fd101":"**Submission**","a45fc432":"### PCA","98a1f86d":"**Load datasets**","670bc42d":"**Data preparation**"}}