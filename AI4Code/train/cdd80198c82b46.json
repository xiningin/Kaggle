{"cell_type":{"eda4bb5a":"code","c93fbfdd":"code","0b326fbd":"code","160c43ac":"code","f31b6608":"code","0166f916":"code","1cdc0392":"code","bfa65474":"code","54ac63f5":"code","d85d0442":"code","0e04709f":"code","7b7b166c":"code","8be6c19f":"code","ce532766":"code","950dfa1a":"code","8460e26e":"code","ed238bb8":"code","55e52c4d":"code","ff91e279":"code","867a38ce":"code","43578ec7":"code","76818d37":"code","e7555885":"code","2c73bf6a":"code","761f49ca":"code","2130bf62":"code","aa2ba588":"code","98333256":"code","266d24e4":"code","6eed5b3c":"code","8558d2af":"code","0b6a1914":"code","08ee2376":"code","8353fc35":"code","0ad63d13":"code","5438f520":"code","401a9114":"code","9dd1c464":"code","0adde6a9":"code","3f54dbaa":"code","64676291":"code","27013cd3":"code","97226950":"code","9c299d95":"code","eded2f35":"code","1fc88435":"code","c6fd91e3":"code","160053ea":"code","0b798384":"code","64b6a5a2":"code","c7ade7c2":"code","58fb72e4":"code","ee6ec9b9":"code","19f6ab4d":"code","8f9a302d":"code","fbc2dd91":"code","272d6309":"code","98f1fed3":"code","542ff016":"code","9c58e1f0":"code","7ba4755f":"code","f02ad26e":"code","34a17825":"markdown","61f3b94c":"markdown","e37c89ec":"markdown","31909d04":"markdown","8c293fde":"markdown","a6e45b31":"markdown"},"source":{"eda4bb5a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as snb\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","c93fbfdd":"data=pd.read_csv('\/kaggle\/input\/tour-travels-customer-churn-prediction\/Customertravel.csv')","0b326fbd":"data","160c43ac":"import pandas_profiling\n","f31b6608":"data.profile_report()\n","0166f916":"data","1cdc0392":"income = data.groupby(\"AnnualIncomeClass\")","bfa65474":"income.count()","54ac63f5":"income.ngroup().head(60)","d85d0442":"data.isnull().sum()","0e04709f":"data.value_counts().sort_values()","7b7b166c":"data[\"Age\"].sort_values()","8be6c19f":"age = data.groupby(\"Age\").size()","ce532766":"age","950dfa1a":"plt.pie(age.values , labels = None, autopct='%1.1f%%', radius = 1.5, textprops = {\"fontsize\" : 16}) \nplt.title(\"According to Age\", c=\"b\")\nplt.show()","8460e26e":"plt.hist([data[data.Target==0].Age, data[data.Target==1].Age], bins = 19, alpha =0.5,  align='mid',histtype = \"bar\", orientation='vertical',  label = [\"0\",\"1\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Percentage\")\nplt.legend()\nplt.show()","ed238bb8":"target = data.groupby(\"Target\").size()","55e52c4d":"target","ff91e279":"income = income.size()","867a38ce":"income","43578ec7":"plt.pie(income.values , labels = (\"High Income\", \"Low Income\", \"Middle Income\" ), autopct='%1.1f%%', radius = 1.5, textprops = {\"fontsize\" : 16}) \nplt.title(\"According to income\", c=\"b\")\nplt.show()","76818d37":"data_age = data.groupby([\"Age\", \"Target\"]).size(). head(60)","e7555885":"data_age","2c73bf6a":"data.corr()","761f49ca":"data.describe()","2130bf62":"data","aa2ba588":"data1 = data.drop([\"AnnualIncomeClass\"], axis = 1)","98333256":"data1","266d24e4":"annuall = data.iloc[:,2:3].values","6eed5b3c":"annuall","8558d2af":"le = preprocessing.LabelEncoder()\nannuall[:,0] = le.fit_transform(annuall[:,0])","0b6a1914":"annuall","08ee2376":"ohe = preprocessing.OneHotEncoder()\nannuall =ohe.fit_transform(annuall).toarray()\n","8353fc35":"annuall","0ad63d13":"data2 = pd.DataFrame(data = annuall, index = range(954), columns = [\"High Income\", \"Low Income\", \"Middle Income\"])","5438f520":"data2.head(29)","401a9114":"data3 = pd.concat([data2, data], axis = 1)","9dd1c464":"data = data3.drop([\"AnnualIncomeClass\"],  axis = 1)","0adde6a9":"data","3f54dbaa":"K = data.values","64676291":"K","27013cd3":"le2 = preprocessing.LabelEncoder()\nK[:,4] = le2.fit_transform(K[:,4])","97226950":"K","9c299d95":"le3 = preprocessing.LabelEncoder()\nK[:,6] = le3.fit_transform(K[:,6])","eded2f35":"le4 = preprocessing.LabelEncoder()\nK[:,7] = le4.fit_transform(K[:,7])","1fc88435":"K.shape","c6fd91e3":"myData = pd.DataFrame(data = K, index = range(954), columns = ['High Income', 'Low Income', 'Middle Income', 'Age', 'FrequentFlyer',\n       'ServicesOpted', 'AccountSyncedToSocialMedia', 'BookedHotelOrNot',\n       'Target'])","160053ea":"myData","0b798384":"x = myData.iloc[:,0:8].values","64b6a5a2":"y = myData.iloc[:,-1].values","c7ade7c2":"y=y.astype('int') ","58fb72e4":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.35, random_state=0)\n","ee6ec9b9":"sc = StandardScaler()\nX_train = sc.fit_transform(x_train)\nX_test = sc.transform(x_test)","19f6ab4d":"X_train.shape","8f9a302d":"myList = []\nclass Logistic():\n    def __init__(self,y_pred, cm, accuracy, report):\n        self.y_pred = y_pred \n        self.cm = cm\n        self.accuracy = accuracy\n        self.report = report\n        logr = LogisticRegression()\n        logr.fit(X_train, y_train)\n        y_pred = logr.predict(X_test)\n        print(f' Logistic Regression : \\n{y_pred}')\n        print(\"------------------------------------\")\n        cm = confusion_matrix(y_test, y_pred)\n        print(f'confusion_ matrix: \\n{cm}') \n        print(\"------------------------------------\")\n        accuracy = accuracy_score(y_pred, y_test)\n        print(f'accuracy score: {accuracy}')\n        print(\"------------------------------------\")\n        myList.append(accuracy)\n        report = classification_report(y_test, y_pred)\n        print(f'classification_report: {report}')\nLogistic = Logistic(\"y_pred\",\"cm\", \"accuracy\",\"report\")   \nprint(Logistic)    \n\n     ","fbc2dd91":"myList1 = []\nclass Svc():\n    def __init__(self,y_pred1, cm1, accuracy1, report1, success1):\n        self.y_pred1 = y_pred1\n        self.cm1 = cm1\n        self.accuracy1 = accuracy1\n        self.report1 = report1\n        self.success1 = success1\n        svc = SVC(C = 1, kernel = \"rbf\", gamma = 1, random_state = 0)\n        svc.fit(X_train, y_train)\n        y_pred1 = svc.predict(X_test)\n        print(f' SVC : \\n{y_pred1}')\n        print(\"------------------------------------\")\n        cm1 = confusion_matrix(y_test, y_pred1)\n        print(f'confusion_ matrix: \\n{cm1}') \n        print(\"------------------------------------\")\n        accuracy1 = accuracy_score(y_pred1, y_test)\n        print(f'accuracy score: {accuracy1}')\n        print(\"------------------------------------\")\n        myList1.append(accuracy1)\n        report1 = classification_report(y_test, y_pred1)\n        print(f'classification_report: {report1}')\n        print(\"------------------------------------\")\n        success1 = cross_val_score(estimator = svc, X= X_train, y=y_train, cv=4)\n        print(f'success: {success1}')\n        p = [{'C': [1,2,3,4,5], 'kernel': ['linear']}, {'C': [1,2,3,4,5], 'kernel': ['rbf']}, {'gamma': [1,0.5,0.1,0.01, 0.001]}]\n        gs = GridSearchCV(estimator = svc, param_grid = p, scoring=\"accuracy\", cv = 10, n_jobs = -1)\n        grid_search = gs.fit(X_train, y_train)\n        bestresult = grid_search.best_score_\n        bestparameters = grid_search.best_params_\n        print(f'best result: {bestresult}')\n        print(f'best parameters: {bestparameters}')\nSvc = Svc(\"y_pred1\",\"cm1\", \"accuracy1\",\"report1\",\"success1\")\n         ","272d6309":"myList2 = []\nclass Knn():\n    def __init__(self,y_pred2, cm2, accuracy2, report2,success2):\n        self.y_pred2 = y_pred2\n        self.cm2 = cm2\n        self.accuracy2 = accuracy2\n        self.report2 = report2\n        self.success2 = success2\n        knn = KNeighborsClassifier(n_neighbors=5, metric = \"manhattan\", weights = \"distance\")\n        knn.fit(X_train, y_train)\n        y_pred2 = knn.predict(X_test)\n        print(f' KNN : \\n{y_pred2}')\n        print(\"------------------------------------\")\n        cm2 = confusion_matrix(y_test, y_pred2)\n        print(f'confusion_ matrix: \\n{cm2}') \n        print(\"------------------------------------\")\n        accuracy2 = accuracy_score(y_pred2, y_test)\n        print(f'accuracy score: {accuracy2}')\n        print(\"------------------------------------\")\n        myList2.append(accuracy2)\n        report2 = classification_report(y_test, y_pred2)\n        print(f'classification_report: {report2}')\n        print(\"------------------------------------\")\n        success2 = cross_val_score(estimator = knn, X= X_train, y=y_train, cv=4)\n        print(f'success : {success2}')\n        p1 = [{\"n_neighbors\": [3,5,11,19], \"weights\": ['uniform' ,'distance'], \"metric\": ('minkowski', 'euclidean', 'manhattan')} ]\n        gs = GridSearchCV(estimator = knn, param_grid = p1, scoring=\"accuracy\", cv = 10, n_jobs = -1)\n        grid_search = gs.fit(X_train, y_train)\n        bestresult = grid_search.best_score_\n        bestparameters = grid_search.best_params_\n        print(f'best result: {bestresult}')\n        print(f'best parameters: {bestparameters}')\nKnn(\"y_pred2\",\"cm2\", \"accuracy2\",\"report2\", \"success2\")\n         ","98f1fed3":"myList3 = []\nclass Decisiontree():\n    def __init__(self,y_pred3, cm3, accuracy3, report3):\n        self.y_pred3 = y_pred3\n        self.cm3 = cm3\n        self.accuracy3 = accuracy3\n        self.report3 = report3\n        dt = DecisionTreeClassifier(criterion = 'entropy')\n        dt.fit(X_train, y_train)\n        y_pred3 = dt.predict(X_test)\n        print(f' Decision Tree : \\n{y_pred3}')\n        print(\"------------------------------------\")\n        cm = confusion_matrix(y_test, y_pred3)\n        print(f'confusion_ matrix: \\n{cm}') \n        print(\"------------------------------------\")\n        accuracy3 = accuracy_score(y_pred3, y_test)\n        print(f'accuracy score: {accuracy3}')\n        print(\"------------------------------------\")\n        myList3.append(accuracy3)\n        report3 = classification_report(y_test, y_pred3)\n        print(f'classification_report: {report3}')\n        \nDecisiontree(\"y_pred3\", \"cm3\", \"accuracy3\", \"report3\")\n         ","542ff016":"myList4 = []\nclass Randomforest():\n    def __init__(self,y_pred4, cm4, accuracy4, report4,success4):\n        self.y_pred4 = y_pred4\n        self.cm4= cm4\n        self.accuracy4= accuracy4\n        self.report4= report4\n        self.success4 = success4\n        rfc = RandomForestClassifier(n_estimators=11, criterion = 'entropy', random_state = 0)\n        rfc.fit(X_train, y_train)\n        y_pred4 = rfc.predict(X_test)\n        print(f'Random Forest : \\n{y_pred4}')\n        print(\"------------------------------------\")\n        cm4 = confusion_matrix(y_test, y_pred4)\n        print(f'confusion_ matrix: \\n{cm4}') \n        print(\"------------------------------------\")\n        accuracy4 = accuracy_score(y_pred4, y_test)\n        print(f'accuracy score: {accuracy4}')\n        print(\"------------------------------------\")\n        myList4.append(accuracy4)\n        report4 = classification_report(y_test, y_pred4)\n        print(f'classification_report: {report4}')\n        print(\"------------------------------------\")\n        success4 = cross_val_score(estimator = rfc, X= X_train, y=y_train, cv=4)\n        print(f'success : {success4}')\n        p2 = {'n_estimators': [1,2,3,4,5,6,7,8,9,10,11,12], 'criterion' :['gini', 'entropy']}\n        gs = GridSearchCV(estimator=rfc, param_grid=p2, scoring = \"accuracy\", cv= 10, n_jobs = -1)\n        grid_search = gs.fit(X_train, y_train)\n        bestresult = grid_search.best_score_\n        bestparameters = grid_search.best_params_\n        print(f'best result: {bestresult}')\n        print(f'best parameters: {bestparameters}')\n\nRandomforest(\"y_pred4\",\"cm4\", \"accuracy4\", \"report4\",\"success4\")\n         \n    ","9c58e1f0":"myList5 = []\nclass Naivebayes():\n    def __init__(self,y_pred5, cm5, accuracy5, report5):\n        self.y_pred5 = y_pred5\n        self.cm5= cm5\n        self.accuracy5= accuracy5\n        self.report5= report5\n        gnb = GaussianNB(var_smoothing = 1.0)\n        gnb.fit(X_train, y_train)\n        y_pred5 = gnb.predict(X_test)\n        print(f'Gaussian NB : \\n{y_pred5}')\n        print(\"------------------------------------\")\n        cm5 = confusion_matrix(y_test, y_pred5)\n        print(f'confusion_ matrix: \\n{cm5}') \n        print(\"------------------------------------\")\n        accuracy5 = accuracy_score(y_pred5, y_test)\n        print(f'accuracy score: {accuracy5}')\n        print(\"------------------------------------\")\n        myList5.append(accuracy5)\n        report5 = classification_report(y_test, y_pred5)\n        print(f'classification_report: {report5}')\n        print(\"---------------------------------\")\n        success5 = cross_val_score(estimator = gnb, X= X_train, y=y_train, cv=4)\n        print(f'success : {success5}')\n        p4 = {'var_smoothing': np.logspace(0,9, num=100)}\n        gs = GridSearchCV(estimator=gnb, \n                 param_grid=p4, \n                 cv=10,  \n                 verbose=1, \n                 scoring='accuracy')\n        grid_search = gs.fit(X_train, y_train)\n        bestresult = grid_search.best_score_\n        bestparameters = grid_search.best_params_\n        print(f'best result: {bestresult}')\n        print(f'best parameters: {bestparameters}')\nNaivebayes(\"y_pred5\",\"cm5\", \"accuracy5\", \"report5\")\n         ","7ba4755f":"models = myList + myList1 + myList2 + myList3 + myList4 + myList5\naccuracy_scores = []\nfor model in models:\n    accuracy_scores.append(model)\nprint(accuracy_scores)    ","f02ad26e":"plt.bar(['LG', 'SVC', 'KNN', 'DTC', 'RFC', 'GB'], accuracy_scores)\nplt.ylim(0.6,0.95)\nplt.title('Accuracy comparison for various models', fontsize=15, color='b')\nplt.xlabel('Models', fontsize=15, color='g')\nplt.ylabel('Accuracy Score', fontsize=15, color='m')\nplt.tight_layout()\nplt.show()","34a17825":"**Importing Libraries**","61f3b94c":"\n\n\n![customerrelations_recolored-gif-still-1024x637.gif](attachment:a878ec9c-07d4-4b2a-be57-57f88cfdb7af.gif)\n","e37c89ec":"****\"Predictions and  some transactions\" according to various models:****","31909d04":"****Accuracy comparison for various models:****","8c293fde":"![customer-experience.gif](attachment:5823bb5f-450b-496d-b0f6-5724711e6970.gif)","a6e45b31":"****Travel & Customer & Analysis_and_Predictions****"}}