{"cell_type":{"3a4bcce0":"code","26e20b13":"code","cadda2f4":"code","77ff3ec5":"code","b9e34243":"code","e5fffdac":"code","2c42a48f":"code","a53ae412":"code","222d5ded":"code","f7f9a6c3":"code","9ea7be84":"code","785f0a66":"code","41cfa429":"code","f97f92d6":"code","a93cd85b":"code","ebf7e082":"code","208886dc":"code","1f5a6ad1":"code","33eaebdb":"code","94551b92":"code","0db86b7b":"code","9a400012":"code","ead8f64a":"markdown","6948605a":"markdown","b8bccf5b":"markdown","55ca0fdf":"markdown","0c1b5549":"markdown","3419fca3":"markdown","736f31c7":"markdown","68dee9c7":"markdown","6e519979":"markdown","5de6ae5c":"markdown","b41da906":"markdown","626cdfcc":"markdown","794a3294":"markdown"},"source":{"3a4bcce0":"import os\n# There are two ways to load the data from the PANDA dataset:\n# Option 1: Load images using openslide\nimport openslide\n# Option 2: Load images using skimage (requires that tifffile is installed)\nimport skimage.io\n\nfrom tqdm import tqdm_notebook as tqdm\nimport warnings\n# General packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nfrom IPython.display import Image, display\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils import model_zoo\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim import Adam,SGD\nimport torchvision.models as models\n\n# Plotly for the interactive viewer (see last section)\nimport plotly.graph_objs as go\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nrandom_seed = 644","26e20b13":"import sys\npackage_path = '..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master'\nsys.path.append(package_path)\nfrom efficientnet_pytorch import EfficientNet","cadda2f4":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    # random.seed(seed)\n    # os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(random_seed)","77ff3ec5":"# Location of the training images\ndata_dir = '\/kaggle\/input\/prostate-cancer-grade-assessment\/train_images'\nmask_dir = '\/kaggle\/input\/prostate-cancer-grade-assessment\/train_label_masks'\n\n# Location of training labels\ntrain_labels = pd.read_csv('\/kaggle\/input\/prostate-cancer-grade-assessment\/train.csv')","b9e34243":"label_map = {label : i for i, label in enumerate(train_labels['gleason_score'])}\n\nfor i,label_name in enumerate(label_map):\n    label_map[label_name] =i\n    \nmap_label = {label_map[index] : index for i, index in enumerate(label_map)}\nisup_map = {\"0+0\":0,'negative':0,'3+3':1,'3+4':2,'4+3':3,'4+4':4,'3+5':4,'5+3':4,'4+5':5,'5+4':5,'5+5':5}","e5fffdac":"train_labels['label'] = train_labels['gleason_score'].map(label_map)","2c42a48f":"class prostate_data(Dataset):\n    def __init__(self, anotation, img_dir, mode='train', size=(512,512), transform=None):\n        self.anotation = anotation\n        self.img_dir = img_dir\n        self.size = size\n        self.mode = mode\n        self.transforms = transform\n        \n    def __len__(self):\n        return len(self.anotation)\n    \n    def __getitem__(self, idx):\n        \n        if self.mode == 'test':\n            img_id, provide  = self.anotation.loc[idx,['image_id','data_provider']].values\n        else:\n            img_id, label, provide  = self.anotation.loc[idx,['image_id','label','data_provider']].values\n            \n        img_path = os.path.join(self.img_dir, img_id+'.tiff')\n        \n        image = openslide.OpenSlide(img_path)\n        image = np.array(image.get_thumbnail(size=self.size).resize(self.size))\n        #print (image.shape)\n        \n        image = self.transforms(image=image)['image']\n        #print (image.shape)\n        #image =  np.rollaxis(image, 2, 0) \/ 255\n        \n        if self.mode == 'train' or self.mode == 'valid':\n            return image, torch.tensor(label)\n        else:\n            return image","a53ae412":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nSIZE = 512\ntransforms_train = A.Compose([\n    A.RandomResizedCrop(height=SIZE, width=SIZE, p=1.0),\n    A.Flip(),\n    A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n\n    # Pixels\n    A.OneOf([\n        A.IAAEmboss(p=1.0),\n        A.IAASharpen(p=1.0),\n        A.Blur(p=1.0),\n    ], p=0.5),\n\n    # Affine\n    A.OneOf([\n        A.ElasticTransform(p=1.0),\n        A.IAAPiecewiseAffine(p=1.0)\n    ], p=0.5),\n\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n])\n\ntransforms_valid = A.Compose([\n    A.Resize(height=SIZE, width=SIZE, p=1.0),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n])","222d5ded":"train, valid = train_test_split(train_labels,test_size=0.2,stratify= train_labels['label'])","f7f9a6c3":"train_dataset = prostate_data(train[:1000].reset_index(drop=True),data_dir, transform=transforms_train)\nvalid_dataset = prostate_data(valid[:200].reset_index(drop=True),data_dir, transform=transforms_valid)","9ea7be84":"batch_size=16\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)","785f0a66":"x_train, y = next(iter(valid_loader))","41cfa429":"%matplotlib inline\nimport matplotlib.pyplot as plt\ndef display_imgs(x):\n    cmaps = ['gist_ncar','terrain', 'gnuplot' ,'rainbow','PiYG', 'gist_earth']\n    columns = 2\n    bs = x.shape[0]\n    rows =2\n    fig=plt.figure(figsize=(columns*4, rows*4))\n    for i in range(rows):\n        for j in range(columns):\n            idx = i+j*columns\n            fig.add_subplot(rows, columns, idx+1)\n            plt.axis('off')\n           # x = np.swapaxes(x,1,-1)\n            plt.imshow((np.swapaxes(x,1,-1)[idx,:,:,:]*255).astype(np.int))\n    plt.show()\n    \ndisplay_imgs(np.array(x_train))","f97f92d6":"model_ft = EfficientNet.from_name('efficientnet-b0')\nmodel_ft.load_state_dict(torch.load('..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth'))\nin_features = model_ft._fc.in_features\nmodel_ft._fc = nn.Linear(in_features,len(label_map))\n#model_ft = EfficientNet.from_pretrained('efficientnet-b0', num_classes=len(label_map))\nmodel_ft = model_ft.to(device)","a93cd85b":"from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,classification_report,auc,roc_curve,cohen_kappa_score","ebf7e082":"lr = 0.0005\neta_min = 1e-5\nt_max = 10\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(params=model_ft.parameters(), lr=lr)\n\ntlen = len(train_loader)\ntlen_valid = len(valid_loader)\naccumulation_steps = 2\nvalid_pred = np.zeros((len(valid[:200]),11))\ntrain_pred = np.zeros((len(train[:1000]),11))\ntrain_target = np.zeros((len(train[:1000])))\n\nfor epoch in range(5):\n    batch_i = 0\n    tloss = 0\n    tloss_valid = 0\n    acc = np.zeros(1)\n    acc_valid = np.zeros(1)\n    \n    model_ft.train()\n    optimizer.zero_grad()\n    for i,(x_train, y_train) in enumerate(tqdm(train_loader)): \n        outputs = model_ft(x_train.cuda())\n        \n        loss = criterion(outputs,  y_train.long().cuda())\n        loss.backward()\n        if (batch_i+1) % accumulation_steps == 0:            \n            optimizer.step()                           \n            optimizer.zero_grad()\n        \n        tloss += loss.item()\n        batch_i+=1\n        \n        train_pred[i * batch_size:(i+1) * batch_size] = outputs.detach().cpu().numpy()\n        train_target[i * batch_size:(i+1) * batch_size] = y_train.detach().cpu().numpy()\n\n        del loss, outputs, y_train, x_train\n\n    #Valid acc\n    model_ft.eval()\n    for i,(x_train, y_train) in enumerate(valid_loader):\n        outputs = model_ft(x_train.cuda())\n        loss = criterion(outputs,  y_train.long().cuda())\n        tloss_valid += loss.item()\n        valid_pred[i * batch_size:(i+1) * batch_size] = outputs.detach().cpu().numpy()\n        del loss, outputs, y_train, x_train\n        \n    acc = cohen_kappa_score(train_pred.argmax(axis =1),train_target,weights='quadratic')\n    acc_valid = cohen_kappa_score(valid_pred.argmax(axis =1),valid['label'][:200],weights='quadratic')\n    \n    print('Epoch {} -> Train Loss: {:.4f}, Valid Loss: {:.4f}, ACC_train: {:.2f}%, ACC_valid: {:.2f}%'.format(epoch+1, tloss\/tlen, tloss_valid\/tlen_valid, acc, acc_valid))","208886dc":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","1f5a6ad1":"cmatrix = confusion_matrix(valid_pred.argmax(axis =1),valid['label'][:200])","33eaebdb":"plot_confusion_matrix(cm           = cmatrix, \n                      normalize    = False,\n                      target_names = list(label_map.keys()),\n                      title        = \"Confusion Matrix\")","94551b92":"test_labels = pd.read_csv('\/kaggle\/input\/prostate-cancer-grade-assessment\/test.csv')\ntest_dir = '\/kaggle\/input\/prostate-cancer-grade-assessment\/test_images'\n\nif os.path.exists(test_dir):\n    test_dataset = prostate_data(test_labels,test_dir,mode='test',transform=transforms_valid)\n    test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size, shuffle=False)\n    test_pred = np.zeros((len(test_labels),11))\n    model_ft.eval()\n    for i,(x_train) in enumerate(tqdm(test_loader)):\n        outputs = model_ft(x_train.cuda())\n        test_pred[i * batch_size:(i+1) * batch_size] = outputs.detach().cpu().numpy()\n        del outputs,x_train","0db86b7b":"sub = pd.read_csv('\/kaggle\/input\/prostate-cancer-grade-assessment\/sample_submission.csv')\ntest_dir = '\/kaggle\/input\/prostate-cancer-grade-assessment\/test_images'\nif os.path.exists(test_dir):\n    sub['isup_grade'] = test_pred.argmax(axis=1)\n    sub['isup_grade'] = sub['isup_grade'].map(map_label)\n    sub['isup_grade'] = sub['isup_grade'].map(isup_map)\nsub.to_csv('submission.csv',index=False)","9a400012":"test_labels","ead8f64a":"## Split tran and valid set\n* only using 1000 data as training set to reduce kernel run-time","6948605a":"## Download EfficientNet\n* For training, inference kernel can't turn on internet","b8bccf5b":"## Start training","55ca0fdf":"## Next Step\n* try segmentation on this competition (Should be)\n* This is the simple classifier on this task, but I think this is not the best way to solve this task\n* https:\/\/ai.googleblog.com\/2018\/11\/improved-grading-of-prostate-cancer.html\n* ![image.png](attachment:image.png)","0c1b5549":"## Load train data","3419fca3":"## Data augmentation","736f31c7":"## Inference\n* If you submit your answer, you will find test_image folder","68dee9c7":"## Simple CNN Classifier Starter (Pytorch)\n* Using EfficientNet-B0 as basebone\n* Not do segmentation\n* Only do classification task on gleason_score(then map to isup score****)","6e519979":"## Set map dictionary ","5de6ae5c":"## PANDA Dataset","b41da906":"## Plot confusion matrix","626cdfcc":"## Load model","794a3294":"## Display Image"}}