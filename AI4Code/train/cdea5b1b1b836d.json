{"cell_type":{"4ef943a0":"code","080de84e":"code","d3acd5e3":"code","eda8c0ad":"code","8638e067":"code","4a8d6a85":"code","02388119":"code","bfafad72":"code","31389c13":"code","c6d90235":"code","993d5f74":"code","58f74e96":"code","5ef89996":"code","3272fc71":"code","812fd656":"code","a52f5b60":"code","58441c9e":"code","bbdd3af3":"code","020bed2e":"code","3a85858a":"code","310869eb":"code","1b18e0d2":"code","1db6bcb5":"code","d4354e82":"code","a56f5322":"code","857700cf":"code","0277f40c":"code","46d02bde":"code","3b7927bd":"code","71b248d4":"markdown","08902e2e":"markdown"},"source":{"4ef943a0":"#load in packages\nimport os\nimport pandas as pd\nfrom glob import glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport gc\nfrom tqdm import tqdm\n\n#images\nimport cv2\n\n#modeling\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib\n\n#visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt","080de84e":"#source path\uff08Pawpularity \u6bd4\u8d5b\u6570\u636e\u6240\u5728\u7684\u4f4d\u7f6e\uff09\npath = '..\/input\/petfinder-pawpularity-score\/'\n\n#\u83b7\u53d6\u5143\u6570\u636e\uff08.csv \u6570\u636e\uff09\u5e76\u5c06\u5176\u653e\u5165 DataFrames\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\n\n#\u83b7\u53d6\u56fe\u50cf\u6570\u636e\uff08.jpg \u6570\u636e\uff09\u5e76\u5c06\u5176\u653e\u5165\u6587\u4ef6\u540d\u5217\u8868\u4e2d\ntrain_jpg = glob(path + \"train\/*.jpg\")\ntest_jpg = glob(path + \"test\/*.jpg\")","d3acd5e3":"train_df.shape, len(train_jpg)#\u663e\u793a\u6570\u636e\u5217\u8868\u5927\u5c0f","eda8c0ad":"train_df.head(5)#\u663e\u793a\u524d5\u884c","8638e067":"sns.histplot(train_df['Pawpularity']);#\u7ed8\u5236'Pawpularity'\u7684\u76f4\u65b9\u56fe\n\nplt.axvline(train_df['Pawpularity'].mean(),color='red')\nplt.axvline(train_df['Pawpularity'].median(),color='green')","4a8d6a85":"train_df[['Pawpularity']].describe().T","02388119":"#\u4fee\u6539 Id\uff0c\u4f7f\u6bcf\u4e2a Id \u90fd\u662f\u5b8c\u6574\u7684\u56fe\u50cf\u8def\u5f84\u3002 \ndef train_id_to_path(x):\n    return '..\/input\/petfinder-pawpularity-score\/train\/' + x + \".jpg\"\ndef test_id_to_path(x):\n    return '..\/input\/petfinder-pawpularity-score\/test\/' + x + \".jpg\"\n","bfafad72":"#\u8bfb\u5165\u6570\u636e\u5e76\u5220\u9664\u4e0d\u5fc5\u8981\u7684\u5217\ntrain = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\nprint(train)\ntrain = train.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\nprint(train)\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ntest = test.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)","31389c13":"#\u5c06 .jpg \u6269\u5c55\u540d\u6dfb\u52a0\u5230\u56fe\u50cf\u6587\u4ef6\u540d ID\ntrain[\"img_path\"] = train[\"Id\"].apply(train_id_to_path)\ntest[\"img_path\"] = test[\"Id\"].apply(test_id_to_path)","c6d90235":"#binning columns to test models \u5c06\u5217\u5206\u6863\u4ee5\u6d4b\u8bd5\u6a21\u578b\ntrain['two_bin_pawp'] = pd.qcut(train['Pawpularity'], q=2, labels=False)\ntrain = train.astype({\"two_bin_pawp\": str})\n\ntrain['four_bin_pawp'] = pd.qcut(train['Pawpularity'], q=4, labels=False)\ntrain = train.astype({\"four_bin_pawp\": str})\n\ntrain['ten_bin_pawp'] = pd.qcut(train['Pawpularity'], q=10, labels=False)\ntrain = train.astype({\"ten_bin_pawp\": str})","993d5f74":"#\u8bbe\u7f6e\u4f60\u60f3\u8981\u7684\u56fe\u50cf\u5c3a\u5bf8\nimage_height = 128\nimage_width = 128\n\n#define a function that accepts an image url and outputs an eager tensor \u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\uff0c\u5b83\u63a5\u53d7\u4e00\u4e2a\u56fe\u50cf\u5e76\u8f93\u51fa\u4e00\u4e2a\u5f20\u91cf\ndef path_to_eagertensor(image_path):\n    raw = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(raw, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    #image = tf.image.resize_with_pad(image, image_height, image_width) #\u53ef\u9009\u586b\u5145\u4ee5\u4fdd\u7559\u539f\u59cb\u5c3a\u5bf8\n    image = tf.image.resize(image, (image_height, image_width))\n    return image","58f74e96":"#\u83b7\u53d6train\u6587\u4ef6\u5939\u4e2d\u7684\u6240\u6709\u56fe\u50cf\u5e76\u5c06\u5b83\u4eec\u7684\u5f20\u91cf\u653e\u5728\u4e00\u4e2a\u5217\u8868\u4e2d\nX = []\nfor img in tqdm(train['img_path']):\n    new_img_tensor = path_to_eagertensor(img)\n    X.append(new_img_tensor)\n    \nprint(type(X),len(X))\nX = np.array(X)\nprint(type(X),X.shape)","5ef89996":"#\u83b7\u53d6 test \u6587\u4ef6\u5939\u4e2d\u7684\u6240\u6709\u56fe\u50cf\u5e76\u5c06\u5b83\u4eec\u7684\u5f20\u91cf\u653e\u5728\u4e00\u4e2a\u5217\u8868\u4e2d\nX_submission = []\nfor img in tqdm(test['img_path']):\n    new_img_tensor = path_to_eagertensor(img)\n    X_submission.append(new_img_tensor)\n    \nprint(type(X_submission),len(X_submission))\nX_submission = np.array(X_submission)\nprint(type(X_submission),X_submission.shape)","3272fc71":"# \u83b7\u53d6\u76ee\u6807\u53d8\u91cfPawpularity\ny = train['Pawpularity']\nprint(y)","812fd656":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7) #\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e3a9\uff1a1","a52f5b60":"print(type(x_train),x_train.shape)","58441c9e":"#\u663e\u793a\u6bcf\u4e2a\u65b0\u6570\u7ec4\u7684\u5f62\u72b6\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","bbdd3af3":"Z=train_df.drop(['Id', \"Pawpularity\"], axis=1)\nZ=np.array(Z)\n#print(type(Z),Z.shape)\nz_train, z_test = train_test_split(Z, test_size=0.1, random_state=7) #\u5212\u5206\u5143\u6570\u636e9\uff1a1\nprint(type(z_train),z_train.shape)","020bed2e":"# def get_model():\n#     # image input model\n#     in_put = tf.keras.layers.Input(shape=(X.shape[1],X.shape[2],3),name='in_put')\n#     x = keras.layers.Conv2D(filters = 16, kernel_size=[5,5], activation = 'relu')(in_put)#\u4e8c\u7ef4\u5377\u79ef\n#     x = keras.layers.BatchNormalization()(x)#\u5f52\u4e00\u5316\n#     ####\n#     x = keras.layers.Conv2D(filters = 32, kernel_size=[5,5], activation = 'relu')(x)#\u6fc0\u6d3b\u51fd\u6570\n#     x = keras.layers.BatchNormalization()(x)#\u5f52\u4e00\u5316\n#     x = keras.layers.Dropout(0.25)(x)#\u4e22\u5f03\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n#     ####\n#     x = keras.layers.Conv2D(filters = 64, kernel_size=[3,3],  activation='relu')(x)\n#     x = tf.keras.layers.BatchNormalization()(x)\n#     x = tf.keras.layers.Dropout(0.25)(x)\n#     ####\n#     x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),  activation = 'relu')(x)\n#     x = tf.keras.layers.BatchNormalization()(x)\n#     x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x) #\u6700\u5927\u6c60\u5316\u5c42\uff0c\u51cf\u5c0f\u6570\u636e\u654f\u611f\u7a0b\u5ea6\n#     ####\n#     x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3),activation = 'relu')(x)\n#     x = tf.keras.layers.BatchNormalization()(x)\n#     x = tf.keras.layers.Dropout(0.25)(x)\n#     x = tf.keras.layers.Flatten()(x) #\u6241\u5e73\u5c42\uff0c\u5c06\u4e8c\u7ef4\u6570\u636e\u53d8\u4e3a\u4ee5\u4e00\u7ef4\uff0c\u4f7f\u4e4b\u8f93\u51fa\u5230\u5168\u8fde\u63a5\u5c42\u4e0a\n#     ####\n#     out_put = layers.Dense(512, activation='relu')(x)\n#     in_model = tf.keras.Model(in_put, out_put)\n \n#     # other data Model\n#     meta_input = layers.Input(shape=Z.shape[1], name='meta_input')\n#     x = layers.Dense(64, activation='relu')(meta_input)\n#     x = layers.Dropout(0.25)(x)\n#     meta_output = layers.Dense(32, activation='relu')(x)\n#     meta_model = tf.keras.Model(meta_input, meta_output)\n\n#     # concatinating Model layers\n#     con_layer = layers.Concatenate(name = 'con_layer')([in_model.output, meta_model.output])\n#     combined_dropout = layers.Dropout(0.5)(con_layer)\n#     combined_dence = layers.Dense(128, activation='relu')(combined_dropout)\n#     final_dropout = layers.Dropout(0.5)(combined_dence)\n#     output_layer = layers.Dense(1, activation='relu')(final_dropout)\n#     model = tf.keras.Model(inputs = [in_model.input, meta_model.input], outputs=output_layer)\n    \n#     return model","3a85858a":"def get_model(): #\u5b9a\u4e49\u6a21\u578b\n   \n    in_put = keras.Input(shape=(X.shape[1],X.shape[2],3))\n\n    x = keras.layers.Conv2D(filters = 16, kernel_size=[5,5], activation = 'sigmoid')(in_put)#\u4e8c\u7ef4\u5377\u79ef\n   \n    x = keras.layers.BatchNormalization()(x)#\u5f52\u4e00\u5316\n    ####\n\n    x = keras.layers.Conv2D(filters = 32, kernel_size=[5,5], activation = 'sigmoid')(x)#\u6fc0\u6d3b\u51fd\u6570\n\n    x = keras.layers.BatchNormalization()(x)#\u5f52\u4e00\u5316\n\n    x = keras.layers.Dropout(0.25)(x)#\u4e22\u5f03\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n    ####\n\n    x = keras.layers.Conv2D(filters = 64, kernel_size=[3,3],  activation='sigmoid')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Dropout(0.25)(x)\n    ####\n\n    x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),  activation = 'sigmoid')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n    \n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x) #\u6700\u5927\u6c60\u5316\u5c42\uff0c\u51cf\u5c0f\u6570\u636e\u654f\u611f\u7a0b\u5ea6\n    ####\n\n    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3),activation = 'sigmoid')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Dropout(0.25)(x)\n\n    x = tf.keras.layers.Flatten()(x) #\u6241\u5e73\u5c42\uff0c\u5c06\u4e8c\u7ef4\u6570\u636e\u53d8\u4e3a\u4ee5\u4e00\u7ef4\uff0c\u4f7f\u4e4b\u8f93\u51fa\u5230\u5168\u8fde\u63a5\u5c42\u4e0a\n    ####\n\n    x = tf.keras.layers.Dense(512, activation = \"sigmoid\")(x)#\u5168\u8fde\u63a5\u5c42\uff0c\u8be5\u5c42\u7684\u6548\u679c\u662f\u5c06\u8f93\u5165\u7684\u6700\u9ad8\u7ef4(\u4e5f\u5c31\u662f\u6700\u540e\u4e00\u7ef4)\u8f6c\u6210\u6307\u5b9a\u7684\u7ef4\u5ea6\u6570\n    \n    x = tf.keras.layers.Dense(128, activation = \"sigmoid\")(x)\n    \n    x = tf.keras.layers.Dense(64, activation = \"sigmoid\")(x)\n\n    x = tf.keras.layers.Dropout(0.5)(x)\n\n    out_put = tf.keras.layers.Dense(1)(x)\n\n    model = tf.keras.Model(inputs = in_put, outputs = out_put)\n    \n    return model","310869eb":"model = get_model()\nmodel.summary()","1b18e0d2":"from tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes=True)","1db6bcb5":"#\u7f16\u8bd1\u6a21\u578b \n\nmodel.compile(\n    loss = 'mse', #\u635f\u5931\u51fd\u6570\u4e3amse\n    optimizer = 'Adam', #\u4f18\u5316\u5668\u4e3aAdam\n    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]) #\u8bc4\u4f30\u6807\u51c6\u4e3armse","d4354e82":"#\u6570\u636e\u589e\u5f3a\uff0c\u6269\u5145\u6570\u636e\u96c6\u5927\u5c0f\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\ndata_augmentation = ImageDataGenerator(rotation_range=15, zoom_range=0.15, width_shift_range = 0.2, \n    height_shift_range = 0.2, \n    shear_range = 0.1,\n    horizontal_flip = True, \n    fill_mode = \"nearest\")","a56f5322":"kall = keras.callbacks.EarlyStopping(monitor='val_rmse',patience=10,restore_best_weights=True)#\u63d0\u524d\u505c\u6b62\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\nhistory = model.fit(\n#     x_train,\n#     y_train,\n#     batch_size=32,\n    #data_augmentation.flow({'input_1': x_train, 'input_2': z_train}, {'output': y_train},batch_size=32), \n    data_augmentation.flow(x_train,y_train,batch_size=32),\n    validation_data = (x_test,y_test),\n    steps_per_epoch = len(x_train) \/\/ 32,\n    epochs =600, callbacks=[kall]\n)","857700cf":"plt.figure()\nplt.plot(history.history[\"rmse\"], label=\"train_rmse\")\nplt.plot(history.history[\"val_rmse\"], label=\"val_rmse\")\nplt.title(\"RMSE train\/validation by Epoch\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"RMSE\")\nplt.legend(loc=\"upper right\");","0277f40c":"#predict on the submission data \u5bf9\u63d0\u4ea4\u6570\u636e\u8fdb\u884c\u9884\u6d4b\ncnn_pred = model.predict(X_submission)\nprint(X_submission.shape, type(X_submission))\nprint(cnn_pred.shape, type(cnn_pred))","46d02bde":"#\u5c06\u63d0\u4ea4\u9884\u6d4b\u4e0e\u5176\u5173\u8054\u7684 ID \u653e\u5728\u4e00\u8d77\ncnn = pd.DataFrame()\ncnn['Id'] = test['Id']\ncnn['Pawpularity'] = cnn_pred\ncnn.to_csv('submission.csv',index=False)","3b7927bd":"testing_example_image = plt.imread('..\/input\/petfinder-pawpularity-score\/test\/4128bae22183829d2b5fea10effdb0c3.jpg') \nprint(testing_example_image.shape)\n#then plt.imshow() can display it for you\nplt.imshow(testing_example_image)\nplt.title('First Testing Image \\n Predicted Pawpularity = {}'.format(cnn['Pawpularity'].iloc[0])) \nplt.axis('off') #turns off the gridlines\nplt.show()","71b248d4":"<h1 style=\"color:#8BB065;font-size:50px;\"><strong>My first <strong style=\"color:#974949\"> Convolutional Neural Network<\/strong><\/strong><\/h1>\n\n\n<img src=\"https:\/\/i.ibb.co\/VMSgnJ5\/header.png\" alt=\"header\" border=\"0\">\n\nLearning CNN from this notebook: [Link](https:\/\/www.kaggle.com\/alexteboul\/tutorial-part-3-cnn-image-modeling-1)","08902e2e":"<h1 style=\"color:#189AB4;font-size:20px;\"><strong>EDA<strong style=\"color:black\"><\/strong><\/strong><\/h1>"}}