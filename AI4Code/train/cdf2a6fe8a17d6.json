{"cell_type":{"c54defb0":"code","8750018a":"code","c869b2b6":"code","c7f0cae6":"code","baf52492":"code","3dab4758":"code","c0d7a96f":"code","ebc1ca81":"code","09605f43":"code","f09fe4f0":"code","cc24aec0":"code","44e0ade8":"code","ca745bee":"code","2630848e":"code","e3486110":"code","db5cd40f":"code","d0e772cc":"code","005c22e3":"code","50590f1b":"code","74e381e2":"markdown","ff45d178":"markdown","f94c4fba":"markdown","60ca4951":"markdown","9f036b5a":"markdown","028333bb":"markdown","c4272661":"markdown"},"source":{"c54defb0":"import torch\nimport torch.nn as nn","8750018a":"class Neural_Network(nn.Module):\n    def __init__(self,input_size , hidden_size , num_classes):\n        super(Neural_Network,self).__init__()\n        self.linear1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(hidden_size, 1)\n    \n    def forward(self,x):\n        out = self.linear1(x)\n        out = self.relu(out)\n        out = self.linear2(out)\n        ## if applying nn.BCEloss then involve sigmoid at last\n        y_pred = torch.Sigmoid(out)\n        return y_pred","c869b2b6":"model = Neural_Network(28*28,5,1)","c7f0cae6":"criterion = nn.BCELoss()","baf52492":"import torchvision\nfrom torchvision import transforms","3dab4758":"train_dataset = torchvision.datasets.MNIST(root =\".\/data\",download = True, train = True,transform = transforms.ToTensor())","c0d7a96f":"test_dataset = torchvision.datasets.MNIST(root = '.\/data',train = False,transform = transforms.ToTensor())\n","ebc1ca81":"train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset,batch_size = 100, shuffle = True)","09605f43":"test_dataloader = torch.utils.data.DataLoader(dataset = test_dataset,batch_size = 100)","f09fe4f0":"examples = iter(train_dataloader)\nsamples, labels = examples.next()","cc24aec0":"print(samples.shape,labels.shape)","44e0ade8":"# same as above just sigmoid won't be used","ca745bee":"class Neural_Network2(nn.Module):\n    def __init__(self,input_size,hidden_size , num_classes):\n        super(Neural_Network2, self).__init__()\n        self.l1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.l2 = nn.Linear(hidden_size, num_classes)\n        \n    def forward(self,x):\n        out = self.l1(x)\n        out = self.relu(out)\n        out = self.l2(out)\n        return out","2630848e":"model = Neural_Network2(784,100,10)","e3486110":"loss = nn.CrossEntropyLoss()","db5cd40f":"optimizer = torch.optim.Adam(model.parameters(),lr= 0.01)","d0e772cc":"num_epochs = 10","005c22e3":"for epoch in range(1,num_epochs+1):\n    for i , (images, labels) in enumerate(train_dataloader):\n        ## reshape images\n        images = torch.reshape(images, (-1, 28*28))\n        y_pred = model(images)\n        l = loss(y_pred,labels)\n        l.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    print(f\"[INFO]:  epoch : {epoch}\/{num_epochs}, loss: {l.item():.4f}\")","50590f1b":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for images,labels in test_dataloader:\n        images = torch.reshape(images,(-1,784))\n        outputs = model(images)\n        \n        _, predictions = torch.max(outputs,1)\n        total += labels.shape[0]\n        correct += (predictions==labels).sum().item()\n        \n    acc = 100.0*correct\/total\n    print(f\"Accuracy : {acc:.2f}\")\n        \n        \n        ","74e381e2":"## Load MNIST dataset","ff45d178":"## Condition of training","f94c4fba":"## Training","60ca4951":"## Optimizer","9f036b5a":"## test","028333bb":"## implementing Neural Network for Multiple Classes","c4272661":"## Loss"}}