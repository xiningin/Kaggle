{"cell_type":{"3e359cae":"code","ab3ca357":"code","41baa280":"code","13c490aa":"code","49fa591b":"code","c28e9f49":"code","a7539afe":"code","eb2909de":"code","f27ed2f6":"code","ae1f035b":"code","9ee0b66a":"code","c2e87733":"code","c0c26227":"code","e3109947":"code","992c0af7":"code","7a7f58d4":"code","8ae14d1c":"code","1ede505b":"code","dd46fd7a":"code","ab6ada3d":"code","743cecbc":"code","57758f4a":"code","5e02c39e":"code","0ca92ddc":"code","86e84c53":"code","1e359f69":"code","0419e131":"code","2cefda15":"code","00aefeee":"code","5e9632d4":"code","5165b56b":"code","f7ee2a9b":"code","da4991cf":"code","da360662":"code","a5980299":"markdown","1e822c98":"markdown","34b7db8c":"markdown","8cfb7968":"markdown"},"source":{"3e359cae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ab3ca357":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","41baa280":"#Data acquisition of the movies dataset\ndf_movie=pd.read_csv('..\/input\/movies.dat', sep = '::', engine='python')\ndf_movie.columns =['MovieIDs','MovieName','Category']\ndf_movie.dropna(inplace=True)\ndf_movie.head()","13c490aa":"#Data acquisition of the rating dataset\ndf_rating = pd.read_csv(\"..\/input\/ratings.dat\",sep='::', engine='python')\ndf_rating.columns =['ID','MovieID','Ratings','TimeStamp']\ndf_rating.dropna(inplace=True)\ndf_rating.head()","49fa591b":"#Data acquisition of the users dataset\ndf_user = pd.read_csv(\"..\/input\/users.dat\",sep='::',engine='python')\ndf_user.columns =['UserID','Gender','Age','Occupation','Zip-code']\ndf_user.dropna(inplace=True)\ndf_user.head()","c28e9f49":"df = pd.concat([df_movie, df_rating,df_user], axis=1)\ndf.head()","a7539afe":"#Visualize user age distribution\ndf['Age'].value_counts().plot(kind='barh',alpha=0.7,figsize=(10,10))\nplt.show()","eb2909de":"df.Age.plot.hist(bins=25)\nplt.title(\"Distribution of users' ages\")\nplt.ylabel('count of users')\nplt.xlabel('Age')","f27ed2f6":"labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\ndf['age_group'] = pd.cut(df.Age, range(0, 81, 10), right=False, labels=labels)\ndf[['Age', 'age_group']].drop_duplicates()[:10]","ae1f035b":"#Visualize overall rating by users\ndf['Ratings'].value_counts().plot(kind='bar',alpha=0.7,figsize=(10,10))\nplt.show()","9ee0b66a":"groupedby_movieName = df.groupby('MovieName')\ngroupedby_rating = df.groupby('Ratings')\ngroupedby_uid = df.groupby('UserID')\n#groupedby_age = df.loc[most_50.index].groupby(['MovieName', 'age_group'])","c2e87733":"movies = df.groupby('MovieName').size().sort_values(ascending=True)[:1000]\nprint(movies)","c0c26227":"ToyStory_data = groupedby_movieName.get_group('Toy Story 2 (1999)')\nToyStory_data.shape","e3109947":"#Find and visualize the user rating of the movie \u201cToy Story\u201d\nplt.figure(figsize=(10,10))\nplt.scatter(ToyStory_data['MovieName'],ToyStory_data['Ratings'])\nplt.title('Plot showing  the user rating of the movie \u201cToy Story\u201d')\nplt.show()\n","992c0af7":"#Find and visualize the viewership of the movie \u201cToy Story\u201d by age group\nToyStory_data[['MovieName','age_group']]","7a7f58d4":"#Find and visualize the top 25 movies by viewership rating\ntop_25 = df[25:]\ntop_25['Ratings'].value_counts().plot(kind='barh',alpha=0.6,figsize=(7,7))\nplt.show()","8ae14d1c":"#Visualize the rating data by user of user id = 2696\nuserid_2696 = groupedby_uid.get_group(2696)\nuserid_2696[['UserID','Ratings']]","1ede505b":"#First 500 extracted records\nfirst_500 = df[500:]\nfirst_500.dropna(inplace=True)","dd46fd7a":"#Use the following features:movie id,age,occupation\nfeatures = first_500[['MovieID','Age','Occupation']].values","ab6ada3d":"#Use rating as label\nlabels = first_500[['Ratings']].values","743cecbc":"#Create train and test data set\ntrain, test, train_labels, test_labels = train_test_split(features,labels,test_size=0.33,random_state=42)","57758f4a":"#Create a histogram for movie\ndf.Age.plot.hist(bins=25)\nplt.title(\"Movie & Rating\")\nplt.ylabel('MovieID')\nplt.xlabel('Ratings')","5e02c39e":"#Create a histogram for age\ndf.Age.plot.hist(bins=25)\nplt.title(\"Age & Rating\")\nplt.ylabel('Age')\nplt.xlabel('Ratings')","0ca92ddc":"#Create a histogram for occupation\ndf.Age.plot.hist(bins=25)\nplt.title(\"Occupation & Rating\")\nplt.ylabel('Occupation')\nplt.xlabel('Ratings')","86e84c53":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, train_labels)\nY_pred = logreg.predict(test)\nacc_log = round(logreg.score(train, train_labels) * 100, 2)\nacc_log","1e359f69":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, train_labels)\nY_pred = svc.predict(test)\nacc_svc = round(svc.score(train, train_labels) * 100, 2)\nacc_svc","0419e131":"# K Nearest Neighbors Classifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(train, train_labels)\nY_pred = knn.predict(test)\nacc_knn = round(knn.score(train, train_labels) * 100, 2)\nacc_knn","2cefda15":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, train_labels)\nY_pred = gaussian.predict(test)\nacc_gaussian = round(gaussian.score(train, train_labels) * 100, 2)\nacc_gaussian","00aefeee":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, train_labels)\nY_pred = perceptron.predict(test)\nacc_perceptron = round(perceptron.score(train, train_labels) * 100, 2)\nacc_perceptron","5e9632d4":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(train, train_labels)\nY_pred = linear_svc.predict(test)\nacc_linear_svc = round(linear_svc.score(train, train_labels) * 100, 2)\nacc_linear_svc","5165b56b":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, train_labels)\nY_pred = sgd.predict(test)\nacc_sgd = round(sgd.score(train, train_labels) * 100, 2)\nacc_sgd","f7ee2a9b":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, train_labels)\nY_pred = decision_tree.predict(test)\nacc_decision_tree = round(decision_tree.score(train, train_labels) * 100, 2)\nacc_decision_tree","da4991cf":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(train, train_labels)\nY_pred = random_forest.predict(test)\nrandom_forest.score(train, train_labels)\nacc_random_forest = round(random_forest.score(train, train_labels) * 100, 2)\nacc_random_forest","da360662":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","a5980299":"**1.  Data acquisition of the movielens dataset**","1e822c98":"**Perform the following: **","34b7db8c":"**Perform machine learning on first 500 extracted records**","8cfb7968":"**2.  Perform the Exploratory Data Analysis (EDA) for the users dataset**"}}