{"cell_type":{"31473059":"code","cc7df74c":"code","fe1282d7":"code","8dc968c2":"code","b630a2d4":"code","371d9f96":"code","6c9135fd":"code","76565a9b":"code","7ac4b238":"code","d502e8eb":"code","6b61a03f":"code","45a166b8":"code","f627a4fe":"code","69525097":"code","82a3ba60":"code","cf42bb87":"code","1c0f2fec":"code","64118519":"code","c000941d":"code","469c5fbe":"markdown","2dd56089":"markdown","573a1b57":"markdown","d023618e":"markdown","5350216a":"markdown","56a115c0":"markdown","5f421424":"markdown"},"source":{"31473059":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","cc7df74c":"# try faster\nimport datatable as dt\ntrain = dt.fread(r'\/kaggle\/input\/tabular-playground-series-oct-2021\/train.csv').to_pandas()\ntest = dt.fread(r'\/kaggle\/input\/tabular-playground-series-oct-2021\/test.csv').to_pandas()","fe1282d7":"# do not convert int8 ! \nid = test['id'].copy()\nprint(id[0:5])","8dc968c2":"# Reduce memory usage\n\n# train features\nfor col in train.columns:\n    if train[col].dtype == \"float64\":\n        train[col]=pd.to_numeric(train[col], downcast=\"float\")\n    if train[col].dtype == \"int64\":\n        train[col]=pd.to_numeric(train[col], downcast=\"integer\")\n    \n\n# test features\nfor col in test.columns:\n    if test[col].dtype == \"float64\":\n        test[col]=pd.to_numeric(test[col], downcast=\"float\")\n    if train[col].dtype == \"int64\":\n        test[col]=pd.to_numeric(test[col], downcast=\"integer\")  \n        \ntrain.info(), test.info()","b630a2d4":"# bool to int8\ncol_1 = ['f' + str(i) for i in range(242, 285)] + ['f22','f43'] + ['target']\ntrain[col_1] = train[col_1].astype('int8')\n\n\ncol_2 = ['f' + str(i) for i in range(242, 285)] + ['f22','f43'] \ntest[col_2] = test[col_2].astype('int8')\n\ntrain.info(), test.info()","371d9f96":"train = train.drop('id' ,axis = 1)\ntest = test.drop('id', axis = 1)","6c9135fd":"train.head(), test.head()","76565a9b":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.ensemble import GradientBoostingClassifier # boost for lGB\n\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\n\nfrom sklearn.metrics import roc_curve, auc\n","7ac4b238":"X = train.drop('target' , axis = 1).copy()\ny = train['target'].copy()\nX_test = test.copy()\n\n# memory release\ndel train\ndel test","d502e8eb":"# add features\n\n\nX['std'] = X.std(axis = 1)\nX['min'] = X.min(axis = 1)\nX['max'] = X.max(axis = 1)\n\n\nX_test['std'] = X_test.std(axis = 1)\nX_test['min'] = X_test.min(axis = 1)\nX_test['max'] = X_test.max(axis = 1)","6b61a03f":"#scaler\nfrom sklearn.preprocessing import QuantileTransformer\n\nquantile = QuantileTransformer()\nX = pd.DataFrame(quantile.fit_transform(X))\nX_test = pd.DataFrame(quantile.transform(X_test))\n\n#default n_quantiles = 1000,random_state = None","45a166b8":"# default parameters\nparam = {\n        'objective' : 'binary',\n        'metric' : 'auc',\n        'verbosity': -1,\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0,\n         'boosting_type': 'gbdt',\n        'device' : 'gpu',\n        'feature_pre_filter': False, \n   \n}\n","f627a4fe":"# time counter \u23f3\nimport time\nstart = time.perf_counter()\nprint(\"--------start----------\")\n","69525097":"splits = 5\nseed = 2021\nskf = StratifiedKFold(n_splits = splits, shuffle=True, random_state=seed)\n\nscores = []\npred = []\n\nfor fold, (idx_train, idx_valid) in enumerate(skf.split(X, y)):\n    \n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n    model = LGBMClassifier(**param)                     \n    model.fit( X_train, y_train,  eval_set = [(X_train,y_train),(X_valid, y_valid)], verbose=False)   \n\n    pred_valid = model.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n\n    test_preds = model.predict_proba(X_test)[:,1]\n    pred.append(test_preds)\n    \n    print(\"fold : \", fold , \"   LGB score : \", score)\n    \nprint(scores)","82a3ba60":"# done \u231b\ntime_end = time.perf_counter()\nprocess_time = time_end - start\nprint(\"process_time:{0}\".format(process_time) )","cf42bb87":"predictions = np.mean(np.column_stack(pred), axis = 1)","1c0f2fec":"\nsubmission = pd.DataFrame({'id' : id, 'target' : predictions})\nsubmission.to_csv(\"submission.csv\", index = False)\n\nsubmission","64118519":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","c000941d":"sns.kdeplot(submission['target'],fill=True,  color = \"#20B2AA\")","469c5fbe":"* reference:http:\/\/www.kaggle.com\/m1y7k8\/tps-oct-21-eda \ud83d\udc40","2dd56089":"-------------","573a1b57":"* Tips: \n* using scaler is better than nothing\n","d023618e":"---------------------","5350216a":"# TPS_Oct_21_LGB","56a115c0":"* to find the best param then get a good score but... it is tough\n* Good Luck!","5f421424":"# Sorry but that... I find a big mistake. so I fix it. Let's be careful to use cut & paste. \ud83d\ude05  Thank you!"}}