{"cell_type":{"240f803b":"code","8e12e304":"code","63ee69f0":"code","5be5d6df":"code","9c99fabf":"code","a03a18bf":"code","20fe6c9f":"code","6babfa95":"code","09333437":"code","894c7872":"code","12505578":"code","568741c0":"markdown"},"source":{"240f803b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e12e304":"MAIN_PATH=\"\/kaggle\/input\/pepsico-lab-potato-quality-control\/Pepsico RnD Potato Lab Dataset\/\"\n\nDEFECTIVE_PATH = MAIN_PATH + 'Defective\/'\n\nNON_DEFECTIVE_PATH = MAIN_PATH + 'Non-Defective\/'","63ee69f0":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","5be5d6df":"defective_image = plt.imread(DEFECTIVE_PATH + 'IMG_20210319_015024.jpg')\nplt.imshow(defective_image)","9c99fabf":"defective_image.shape","a03a18bf":"non_defective_image = plt.imread(NON_DEFECTIVE_PATH + 'IMG_20210318_235715.jpg')\nplt.imshow(non_defective_image)","20fe6c9f":"non_defective_image.shape","6babfa95":"training_ds = tf.keras.preprocessing.image_dataset_from_directory(MAIN_PATH, label_mode='binary', \n                                                                  validation_split=0.2, subset='training', seed=1000)\nvalidation_ds = tf.keras.preprocessing.image_dataset_from_directory(MAIN_PATH, label_mode='binary', \n                                                                  validation_split=0.2, subset='validation', seed =1000)","09333437":"data_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.RandomFlip(\"horizontal\"),\n        tf.keras.layers.RandomRotation(0.1),\n    ]\n)","894c7872":"inputs = tf.keras.Input(shape = (256,256,3))\nx = data_augmentation(inputs)\n\nx = tf.keras.layers.Rescaling(1.0 \/ 255)(x)\nx = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Activation(\"relu\")(x)\n\nx = tf.keras.layers.Conv2D(64, 3, padding=\"same\")(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Activation(\"relu\")(x)\n\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n \nx = tf.keras.layers.Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs, outputs)","12505578":"model.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nmodel.fit(\n    training_ds, epochs=5, validation_data=validation_ds\n)","568741c0":"**Import Necessary libraries**"}}