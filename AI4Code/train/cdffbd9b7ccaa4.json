{"cell_type":{"c2a96153":"code","5337e9c8":"code","2cf85376":"code","92a42108":"code","7baa48fe":"code","fe7aa3aa":"code","3aaf7d4a":"code","16c041b2":"code","62966971":"code","5b3b9ee3":"code","e5621069":"code","b8a76dbf":"code","1abcbd37":"code","d5e37184":"code","5baf5675":"code","c3741cc9":"code","3426f314":"code","24ff052e":"code","d09db728":"code","28df9b79":"code","76af11df":"code","eff5144b":"code","1e571e82":"code","1d008ca3":"code","735619b7":"markdown","ffc83911":"markdown","23e13f16":"markdown","ebb77b6d":"markdown","51880fe6":"markdown","baaf1d25":"markdown","cd7d280d":"markdown","8dde800f":"markdown","049b522d":"markdown","7c70d640":"markdown","8c5787b7":"markdown","aa3762e4":"markdown","df8e238f":"markdown","a496a47b":"markdown"},"source":{"c2a96153":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport tensorflow\n# Technically not necessary in newest versions of jupyter\n%matplotlib inline","5337e9c8":"my_data_dir = '..\/input\/plant-seedlings-classification'","2cf85376":"# CONFIRM THAT THIS REPORTS BACK 'test', and 'train'\nos.listdir(my_data_dir) ","92a42108":"test_path = my_data_dir+'\/test\/'\ntrain_path = my_data_dir+'\/train\/'","7baa48fe":"os.listdir(test_path)","fe7aa3aa":"CATEGORIES = os.listdir(train_path)\nCATEGORIES","3aaf7d4a":"len(CATEGORIES)","16c041b2":"train = []\nfor category_id, category in enumerate(CATEGORIES):\n    #count = 0\n    for file in os.listdir(os.path.join(train_path, category)):\n        #renamed_to = category+'.'+str(count)+'.png'\n        train.append(['train\/{}\/{}'.format(category, file),file,category_id, category])\n        #os.rename((train_dir+category+\"\/\"+file),(train_dir+category+\"\/\"+renamed_to))\n        #count = count + 1\n#train = pd.DataFrame(train, columns=['file','filename', 'category_id', 'category','renamed_to'])\ntrain = pd.DataFrame(train, columns=['file','filename', 'category_id', 'category'])\ntrain.shape","62966971":"test = []\n\n#count = 0\nfor file in os.listdir(test_path):\n  #renamed_to = str(count)+'.png'\n  test.append(['test\/{}'.format(file),file])\n  #os.rename((test_dir+file),(test_dir+renamed_to))\n  #count = count + 1\ntest = pd.DataFrame(test, columns=['filepath','file'])\ntest.shape","5b3b9ee3":"train.tail(5)","e5621069":"test.head(5)","b8a76dbf":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import  ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping,ModelCheckpoint\nfrom keras.optimizers import Adam, SGD\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D,Lambda,BatchNormalization\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess_input\n\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 16","1abcbd37":"SEED = 42\nWIDTH = 370\nHEIGHT = 370\nDEPTH = 3\nINPUT_SHAPE = (WIDTH, HEIGHT, DEPTH)","d5e37184":"def freezeLayersVGG(vgg_model):\n    trainable = False\n    for layer in vgg_model.layers:\n        if layer.name in ['block5_conv1', 'block4_conv1']:\n            trainable = True\n            \n        if trainable:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n    return vgg_model","5baf5675":"vgg = VGG19(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n\noutput = vgg.layers[-1].output\noutput = Flatten()(output)\nvgg_model = Model(vgg.input, output)\n\nvgg_model = freezeLayersVGG(vgg_model)\n\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    ","c3741cc9":"def freezeLayersResNet(resnet_model):\n    trainable = False\n    for layer in resnet_model.layers:\n        if layer.name in ['res5c_branch2b', 'res5c_branch2c', 'activation_97']:\n            trainable = True\n            \n        if trainable:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n    return resnet_model","3426f314":"resnet = ResNet50(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n\noutput = resnet.layers[-1].output\noutput = Flatten()(output)\nresnet_model = Model(resnet.input, output)\n\nfreezeLayersResNet(resnet_model)\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in resnet_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) ","24ff052e":"def printHistory(history, title, epochs):\n    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    t = f.suptitle(title, fontsize=12)\n    f.subplots_adjust(top=0.85, wspace=0.3)\n\n    epoch_list = list(range(1,epochs+1))\n    ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n    ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n    ax1.set_xticks(np.arange(0, epochs+1, 5))\n    ax1.set_ylabel('Accuracy Value')\n    ax1.set_xlabel('Epoch')\n    ax1.set_title('Accuracy')\n    l1 = ax1.legend(loc=\"best\")\n\n    ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n    ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n    ax2.set_xticks(np.arange(0, epochs+1, 5))\n    ax2.set_ylabel('Loss Value')\n    ax2.set_xlabel('Epoch')\n    ax2.set_title('Loss')\n    l2 = ax2.legend(loc=\"best\")","d09db728":"def createModel(pretrainedModel, fineTune, number_of_hidden_layers, activation, optimizer, learning_rate, epochs):\n    print(\"Create Model\")\n\n    existing_model = 0 \n    \n    if pretrainedModel == \"ResNet-50\":\n        existing_model = ResNet50(weights='imagenet', input_shape=INPUT_SHAPE, include_top=False)\n        if fineTune == True:\n            existing_model = freezeLayersResNet(existing_model)\n        else:\n            for layer in existing_model.layers:\n                existing_model.trainable = False  # freeze feature extracting layers of ResNet 50\n    elif pretrainedModel == \"VGG-19\":\n        existing_model = VGG19(weights='imagenet', input_shape=INPUT_SHAPE, include_top=False)\n        \n        if fineTune == True:\n            existing_model = freezeLayersVGG(existing_model)\n        else:\n            for layer in existing_model.layers:\n                layer.trainable = False  # freeze feature extracting layers of VGG 19\n\n    output = existing_model.layers[-1].output\n    output = Flatten()(output)\n    transfer_model = Model(existing_model.input, output)\n\n    model = Sequential()\n    model.add(transfer_model)\n    model.add(BatchNormalization()) # Normalize the activations of the previous layer at each batch\n\n    \n    for i in range(0,number_of_hidden_layers):\n        model.add(Dense(512))\n        model.add(Activation(activation))\n        model.add(Dropout(0.5))\n        model.add(BatchNormalization()) # Normalize the activations of the previous layer at each batch\n\n\n    model.add(Dense(12, activation='softmax'))\n\n    if optimizer == 'SGD':\n        opt = SGD(lr=learning_rate, decay=learning_rate \/ epochs)\n    elif optimizer == 'Adam':\n        opt = Adam(lr=learning_rate, decay=learning_rate \/ epochs)\n\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    model.summary()\n    return model","28df9b79":"def trainModel(images, pretrainedModel, fineTune, epochs, batch_size, learning_rate, cross_validation_folds, activation, number_of_hidden_layers, optimizer):\n    print(\"Train Model\")\n     \n    datagen_train = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                            width_shift_range=0.2, # Range for random horizontal shifts\n                            height_shift_range=0.2, # Range for random vertical shifts\n                            zoom_range=0.2, # Range for random zoom\n                            horizontal_flip=True, # Randomly flip inputs horizontally\n                            vertical_flip=True)\n    \n    datagen_valid = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                            width_shift_range=0.2, # Range for random horizontal shifts\n                            height_shift_range=0.2, # Range for random vertical shifts\n                            zoom_range=0.2, # Range for random zoom\n                            horizontal_flip=True, # Randomly flip inputs horizontally\n                            vertical_flip=True)\n    \n        \n    print(\"Cross validation\")\n    kfold = StratifiedKFold(n_splits=cross_validation_folds, shuffle=True)\n    cvscores = []\n    models = []\n    iteration = 1\n    \n    t = images.category_id\n    \n    for train_index, test_index in kfold.split(np.zeros(len(t)), t):\n        annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-5)\n        checkpoint = ModelCheckpoint('\/kaggle\/working\/model.h5', verbose=1, save_best_only=True)\n\n        print(\"======================================\")\n        print(\"Iteration = \", iteration)\n\n        iteration = iteration + 1\n\n        train = images.loc[train_index]\n        test = images.loc[test_index]\n\n        print(\"======================================\")\n        \n        model = createModel(pretrainedModel, fineTune, number_of_hidden_layers, activation, optimizer, learning_rate, epochs)\n\n        print(\"======================================\")\n        \n        train_generator = datagen_train.flow_from_dataframe(dataframe=train,\n                                                  directory=my_data_dir,\n                                                  x_col=\"file\",\n                                                  y_col=\"category\",\n                                                  batch_size=batch_size,\n                                                  seed=SEED,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=(HEIGHT, WIDTH));\n        valid_generator=datagen_valid.flow_from_dataframe(dataframe=test,\n                                                  directory=my_data_dir,\n                                                  x_col=\"file\",\n                                                  y_col=\"category\",\n                                                  batch_size=batch_size,\n                                                  seed=SEED,\n                                                  shuffle=False,\n                                                  class_mode=\"categorical\",\n                                                  target_size=(HEIGHT, WIDTH));\n        \n        STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\n        STEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\n\n        #Trains the model on data generated batch-by-batch by a Python generator\n        history = model.fit_generator(generator=train_generator,\n                            validation_data = valid_generator, \n                            steps_per_epoch=STEP_SIZE_TRAIN, \n                            validation_steps=STEP_SIZE_VALID, \n                            epochs=epochs, \n                            callbacks=[annealer, checkpoint],\n                            verbose=1)\n        \n        scores = model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID)\n        print(\"Accuarcy %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n        cvscores.append(scores[1] * 100)\n        models.append(model)\n        \n        printHistory(history, pretrainedModel, epochs)\n\n    accuracy = np.mean(cvscores);\n    std = np.std(cvscores);\n    print(\"Accuracy: %.2f%% (+\/- %.2f%%)\" % (accuracy, std))\n    # Save best model.\n    best_model_index = np.argmax(scores, axis=0) \n    best_model= models[best_model_index]\n    best_model.save('\/kaggle\/working\/best_model')\n\n    return train_generator.class_indices\n    ","76af11df":"class_indices = trainModel(\n    train,\n    pretrainedModel = \"ResNet-50\", #ResNet-50\n    fineTune = False,\n    batch_size =32,\n    cross_validation_folds = 5,\n    learning_rate = 0.001,\n    activation = 'relu',\n    number_of_hidden_layers = 4,\n    optimizer = 'Adam',\n    epochs = 30\n)","eff5144b":"Train Model\nCross validation\n======================================\nIteration =  1\n======================================\nCreate Model\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nfunctional_5 (Functional)    (None, 294912)            23587712  \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 294912)            1179648   \n_________________________________________________________________\ndense (Dense)                (None, 512)               150995456 \n_________________________________________________________________\nactivation (Activation)      (None, 512)               0         \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nactivation_1 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nactivation_2 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_3 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nactivation_3 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_4 (Dense)              (None, 12)                6156      \n=================================================================\nTotal params: 176,565,132\nTrainable params: 152,383,500\nNon-trainable params: 24,181,632\n_________________________________________________________________\n======================================\nFound 3800 validated image filenames belonging to 12 classes.\nFound 950 validated image filenames belonging to 12 classes.\nEpoch 1\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.8833 - accuracy: 0.1489\nEpoch 00001: val_loss improved from inf to 2.03370, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 281s 2s\/step - loss: 2.8833 - accuracy: 0.1489 - val_loss: 2.0337 - val_accuracy: 0.3341\nEpoch 2\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.3243 - accuracy: 0.2524\nEpoch 00002: val_loss improved from 2.03370 to 1.51770, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 224s 2s\/step - loss: 2.3243 - accuracy: 0.2524 - val_loss: 1.5177 - val_accuracy: 0.4774\nEpoch 3\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.8853 - accuracy: 0.3676\nEpoch 00003: val_loss improved from 1.51770 to 1.17815, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 221s 2s\/step - loss: 1.8853 - accuracy: 0.3676 - val_loss: 1.1781 - val_accuracy: 0.5722\nEpoch 4\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.6065 - accuracy: 0.4445\nEpoch 00004: val_loss improved from 1.17815 to 0.98040, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 224s 2s\/step - loss: 1.6065 - accuracy: 0.4445 - val_loss: 0.9804 - val_accuracy: 0.6789\nEpoch 5\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.3551 - accuracy: 0.5090\nEpoch 00005: val_loss improved from 0.98040 to 0.84665, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 218s 2s\/step - loss: 1.3551 - accuracy: 0.5090 - val_loss: 0.8467 - val_accuracy: 0.7101\nEpoch 6\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.2837 - accuracy: 0.5281\nEpoch 00006: val_loss improved from 0.84665 to 0.76550, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 1.2837 - accuracy: 0.5281 - val_loss: 0.7655 - val_accuracy: 0.7274\nEpoch 7\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.1167 - accuracy: 0.5918\nEpoch 00007: val_loss improved from 0.76550 to 0.71240, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 217s 2s\/step - loss: 1.1167 - accuracy: 0.5918 - val_loss: 0.7124 - val_accuracy: 0.7565\nEpoch 8\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.0327 - accuracy: 0.6285\nEpoch 00008: val_loss improved from 0.71240 to 0.63544, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 211s 2s\/step - loss: 1.0327 - accuracy: 0.6285 - val_loss: 0.6354 - val_accuracy: 0.7877\nEpoch 9\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9950 - accuracy: 0.6433\nEpoch 00009: val_loss improved from 0.63544 to 0.58659, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 0.9950 - accuracy: 0.6433 - val_loss: 0.5866 - val_accuracy: 0.7920\nEpoch 10\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.6789\nEpoch 00010: val_loss improved from 0.58659 to 0.54421, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 0.9227 - accuracy: 0.6789 - val_loss: 0.5442 - val_accuracy: 0.8050\nEpoch 11\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8891 - accuracy: 0.6868\nEpoch 00011: val_loss improved from 0.54421 to 0.50537, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 211s 2s\/step - loss: 0.8891 - accuracy: 0.6868 - val_loss: 0.5054 - val_accuracy: 0.8190\nEpoch 12\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8114 - accuracy: 0.7030\nEpoch 00012: val_loss improved from 0.50537 to 0.49036, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 0.8114 - accuracy: 0.7030 - val_loss: 0.4904 - val_accuracy: 0.8341\nEpoch 13\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7824 - accuracy: 0.7232\nEpoch 00013: val_loss improved from 0.49036 to 0.45483, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 0.7824 - accuracy: 0.7232 - val_loss: 0.4548 - val_accuracy: 0.8373\nEpoch 14\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.7317\nEpoch 00014: val_loss did not improve from 0.45483\n118\/118 [==============================] - 208s 2s\/step - loss: 0.7735 - accuracy: 0.7317 - val_loss: 0.4801 - val_accuracy: 0.8384\nEpoch 15\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7150 - accuracy: 0.7503\nEpoch 00015: val_loss did not improve from 0.45483\n118\/118 [==============================] - 204s 2s\/step - loss: 0.7150 - accuracy: 0.7503 - val_loss: 0.4640 - val_accuracy: 0.8534\nEpoch 16\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.7617\nEpoch 00016: val_loss improved from 0.45483 to 0.43037, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 211s 2s\/step - loss: 0.6957 - accuracy: 0.7617 - val_loss: 0.4304 - val_accuracy: 0.8502\nEpoch 17\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.7646\nEpoch 00017: val_loss did not improve from 0.43037\n118\/118 [==============================] - 206s 2s\/step - loss: 0.6553 - accuracy: 0.7646 - val_loss: 0.4477 - val_accuracy: 0.8448\nEpoch 18\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6790 - accuracy: 0.7553\nEpoch 00018: val_loss improved from 0.43037 to 0.42931, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 0.6790 - accuracy: 0.7553 - val_loss: 0.4293 - val_accuracy: 0.8545\nEpoch 19\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.7749\nEpoch 00019: val_loss did not improve from 0.42931\n118\/118 [==============================] - 209s 2s\/step - loss: 0.6506 - accuracy: 0.7749 - val_loss: 0.4585 - val_accuracy: 0.8438\nEpoch 20\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.7776\nEpoch 00020: val_loss did not improve from 0.42931\n118\/118 [==============================] - 207s 2s\/step - loss: 0.6370 - accuracy: 0.7776 - val_loss: 0.4582 - val_accuracy: 0.8556\nEpoch 21\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.7757\nEpoch 00021: val_loss improved from 0.42931 to 0.39446, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 0.6427 - accuracy: 0.7757 - val_loss: 0.3945 - val_accuracy: 0.8728\nEpoch 22\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.7856\nEpoch 00022: val_loss did not improve from 0.39446\n118\/118 [==============================] - 206s 2s\/step - loss: 0.6175 - accuracy: 0.7856 - val_loss: 0.4239 - val_accuracy: 0.8491\nEpoch 23\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.7845\nEpoch 00023: val_loss did not improve from 0.39446\n118\/118 [==============================] - 203s 2s\/step - loss: 0.6108 - accuracy: 0.7845 - val_loss: 0.3981 - val_accuracy: 0.8653\nEpoch 24\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.7893\nEpoch 00024: val_loss improved from 0.39446 to 0.38516, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.6121 - accuracy: 0.7893 - val_loss: 0.3852 - val_accuracy: 0.8750\nEpoch 25\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.7911\nEpoch 00025: val_loss did not improve from 0.38516\n118\/118 [==============================] - 210s 2s\/step - loss: 0.6038 - accuracy: 0.7911 - val_loss: 0.4009 - val_accuracy: 0.8599\nEpoch 26\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5833 - accuracy: 0.7972\nEpoch 00026: val_loss did not improve from 0.38516\n118\/118 [==============================] - 209s 2s\/step - loss: 0.5833 - accuracy: 0.7972 - val_loss: 0.3992 - val_accuracy: 0.8718\nEpoch 27\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7986\nEpoch 00027: val_loss did not improve from 0.38516\n118\/118 [==============================] - 207s 2s\/step - loss: 0.5637 - accuracy: 0.7986 - val_loss: 0.4176 - val_accuracy: 0.8491\nEpoch 28\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.8063\nEpoch 00028: val_loss improved from 0.38516 to 0.36858, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 221s 2s\/step - loss: 0.5608 - accuracy: 0.8063 - val_loss: 0.3686 - val_accuracy: 0.8653\nEpoch 29\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.8171\nEpoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 00029: val_loss did not improve from 0.36858\n118\/118 [==============================] - 207s 2s\/step - loss: 0.5493 - accuracy: 0.8171 - val_loss: 0.3769 - val_accuracy: 0.8728\nEpoch 30\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8171\nEpoch 00030: val_loss improved from 0.36858 to 0.36376, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 0.5109 - accuracy: 0.8171 - val_loss: 0.3638 - val_accuracy: 0.8858\nAccuarcy accuracy: 88.69%\n======================================\nIteration =  2\n======================================\nCreate Model\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nfunctional_7 (Functional)    (None, 294912)            23587712  \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 294912)            1179648   \n_________________________________________________________________\ndense_5 (Dense)              (None, 512)               150995456 \n_________________________________________________________________\nactivation_4 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_6 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nactivation_5 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_7 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nactivation_6 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_8 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nactivation_7 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_9 (Dense)              (None, 12)                6156      \n=================================================================\nTotal params: 176,565,132\nTrainable params: 152,383,500\nNon-trainable params: 24,181,632\n_________________________________________________________________\n======================================\nFound 3800 validated image filenames belonging to 12 classes.\nFound 950 validated image filenames belonging to 12 classes.\nEpoch 1\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.8636 - accuracy: 0.1457\nEpoch 00001: val_loss improved from inf to 2.08180, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 2.8636 - accuracy: 0.1457 - val_loss: 2.0818 - val_accuracy: 0.3103\nEpoch 2\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.2982 - accuracy: 0.2699\nEpoch 00002: val_loss improved from 2.08180 to 1.46135, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 2.2982 - accuracy: 0.2699 - val_loss: 1.4614 - val_accuracy: 0.4838\nEpoch 3\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.8917 - accuracy: 0.3676\nEpoch 00003: val_loss improved from 1.46135 to 1.16692, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 1.8917 - accuracy: 0.3676 - val_loss: 1.1669 - val_accuracy: 0.5636\nEpoch 4\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.5995 - accuracy: 0.4379\nEpoch 00004: val_loss improved from 1.16692 to 1.00815, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 218s 2s\/step - loss: 1.5995 - accuracy: 0.4379 - val_loss: 1.0081 - val_accuracy: 0.6422\nEpoch 5\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.3721 - accuracy: 0.4960\nEpoch 00005: val_loss improved from 1.00815 to 0.80984, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 1.3721 - accuracy: 0.4960 - val_loss: 0.8098 - val_accuracy: 0.6961\nEpoch 6\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.2639 - accuracy: 0.5483\nEpoch 00006: val_loss improved from 0.80984 to 0.72256, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 1.2639 - accuracy: 0.5483 - val_loss: 0.7226 - val_accuracy: 0.7166\nEpoch 7\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.1594 - accuracy: 0.5804\nEpoch 00007: val_loss improved from 0.72256 to 0.70521, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 1.1594 - accuracy: 0.5804 - val_loss: 0.7052 - val_accuracy: 0.7414\nEpoch 8\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.0365 - accuracy: 0.6287\nEpoch 00008: val_loss improved from 0.70521 to 0.64493, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 1.0365 - accuracy: 0.6287 - val_loss: 0.6449 - val_accuracy: 0.7866\nEpoch 9\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.6521\nEpoch 00009: val_loss improved from 0.64493 to 0.58569, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 0.9709 - accuracy: 0.6521 - val_loss: 0.5857 - val_accuracy: 0.7877\nEpoch 10\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9128 - accuracy: 0.6760\nEpoch 00010: val_loss improved from 0.58569 to 0.57111, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 0.9128 - accuracy: 0.6760 - val_loss: 0.5711 - val_accuracy: 0.8060\nEpoch 11\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8831 - accuracy: 0.6858\nEpoch 00011: val_loss improved from 0.57111 to 0.48898, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.8831 - accuracy: 0.6858 - val_loss: 0.4890 - val_accuracy: 0.8276\nEpoch 12\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8348 - accuracy: 0.6982\nEpoch 00012: val_loss did not improve from 0.48898\n118\/118 [==============================] - 202s 2s\/step - loss: 0.8348 - accuracy: 0.6982 - val_loss: 0.4948 - val_accuracy: 0.8287\nEpoch 13\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7708 - accuracy: 0.7266\nEpoch 00013: val_loss improved from 0.48898 to 0.46688, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 0.7708 - accuracy: 0.7266 - val_loss: 0.4669 - val_accuracy: 0.8341\nEpoch 14\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7694 - accuracy: 0.7362\nEpoch 00014: val_loss improved from 0.46688 to 0.45016, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.7694 - accuracy: 0.7362 - val_loss: 0.4502 - val_accuracy: 0.8330\nEpoch 15\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7424 - accuracy: 0.7328\nEpoch 00015: val_loss improved from 0.45016 to 0.40552, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 0.7424 - accuracy: 0.7328 - val_loss: 0.4055 - val_accuracy: 0.8567\nEpoch 16\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7235 - accuracy: 0.7460\nEpoch 00016: val_loss did not improve from 0.40552\n118\/118 [==============================] - 206s 2s\/step - loss: 0.7235 - accuracy: 0.7460 - val_loss: 0.4331 - val_accuracy: 0.8481\nEpoch 17\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6626 - accuracy: 0.7638\nEpoch 00017: val_loss did not improve from 0.40552\n118\/118 [==============================] - 212s 2s\/step - loss: 0.6626 - accuracy: 0.7638 - val_loss: 0.4207 - val_accuracy: 0.8599\nEpoch 18\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6715 - accuracy: 0.7673\nEpoch 00018: val_loss improved from 0.40552 to 0.39697, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 0.6715 - accuracy: 0.7673 - val_loss: 0.3970 - val_accuracy: 0.8804\nEpoch 19\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6680 - accuracy: 0.7699\nEpoch 00019: val_loss improved from 0.39697 to 0.38919, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 0.6680 - accuracy: 0.7699 - val_loss: 0.3892 - val_accuracy: 0.8588\nEpoch 20\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.7805\nEpoch 00020: val_loss improved from 0.38919 to 0.36122, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 216s 2s\/step - loss: 0.6376 - accuracy: 0.7805 - val_loss: 0.3612 - val_accuracy: 0.8718\nEpoch 21\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.7818\nEpoch 00021: val_loss did not improve from 0.36122\n118\/118 [==============================] - 209s 2s\/step - loss: 0.6363 - accuracy: 0.7818 - val_loss: 0.3891 - val_accuracy: 0.8696\nEpoch 22\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7898\nEpoch 00022: val_loss did not improve from 0.36122\n118\/118 [==============================] - 210s 2s\/step - loss: 0.6042 - accuracy: 0.7898 - val_loss: 0.3885 - val_accuracy: 0.8470\nEpoch 23\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5940 - accuracy: 0.7901\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 00023: val_loss did not improve from 0.36122\n118\/118 [==============================] - 208s 2s\/step - loss: 0.5940 - accuracy: 0.7901 - val_loss: 0.3762 - val_accuracy: 0.8610\nEpoch 24\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5777 - accuracy: 0.7914\nEpoch 00024: val_loss improved from 0.36122 to 0.36109, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.5777 - accuracy: 0.7914 - val_loss: 0.3611 - val_accuracy: 0.8610\nEpoch 25\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.8049\nEpoch 00025: val_loss improved from 0.36109 to 0.33643, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 0.5831 - accuracy: 0.8049 - val_loss: 0.3364 - val_accuracy: 0.8782\nEpoch 26\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.8108\nEpoch 00026: val_loss did not improve from 0.33643\n118\/118 [==============================] - 203s 2s\/step - loss: 0.5466 - accuracy: 0.8108 - val_loss: 0.3645 - val_accuracy: 0.8653\nEpoch 27\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8126\nEpoch 00027: val_loss did not improve from 0.33643\n118\/118 [==============================] - 200s 2s\/step - loss: 0.5424 - accuracy: 0.8126 - val_loss: 0.3588 - val_accuracy: 0.8804\nEpoch 28\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.8063\nEpoch 00028: val_loss improved from 0.33643 to 0.33043, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 217s 2s\/step - loss: 0.5404 - accuracy: 0.8063 - val_loss: 0.3304 - val_accuracy: 0.8944\nEpoch 29\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8190\nEpoch 00029: val_loss improved from 0.33043 to 0.32747, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 207s 2s\/step - loss: 0.5080 - accuracy: 0.8190 - val_loss: 0.3275 - val_accuracy: 0.8944\nEpoch 30\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.8312\nEpoch 00030: val_loss did not improve from 0.32747\n118\/118 [==============================] - 202s 2s\/step - loss: 0.4824 - accuracy: 0.8312 - val_loss: 0.3332 - val_accuracy: 0.8836\nAccuarcy accuracy: 88.04%\n======================================\nIteration =  3\n======================================\nCreate Model\nModel: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nfunctional_9 (Functional)    (None, 294912)            23587712  \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 294912)            1179648   \n_________________________________________________________________\ndense_10 (Dense)             (None, 512)               150995456 \n_________________________________________________________________\nactivation_8 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_11 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_9 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_12 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_10 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_13 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_11 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_14 (Dense)             (None, 12)                6156      \n=================================================================\nTotal params: 176,565,132\nTrainable params: 152,383,500\nNon-trainable params: 24,181,632\n_________________________________________________________________\n======================================\nFound 3800 validated image filenames belonging to 12 classes.\nFound 950 validated image filenames belonging to 12 classes.\nEpoch 1\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.8883 - accuracy: 0.1428\nEpoch 00001: val_loss improved from inf to 1.97444, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 2.8883 - accuracy: 0.1428 - val_loss: 1.9744 - val_accuracy: 0.3481\nEpoch 2\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.3276 - accuracy: 0.2524\nEpoch 00002: val_loss improved from 1.97444 to 1.49830, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 2.3276 - accuracy: 0.2524 - val_loss: 1.4983 - val_accuracy: 0.4806\nEpoch 3\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.8770 - accuracy: 0.3583\nEpoch 00003: val_loss improved from 1.49830 to 1.12829, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 207s 2s\/step - loss: 1.8770 - accuracy: 0.3583 - val_loss: 1.1283 - val_accuracy: 0.5959\nEpoch 4\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.5850 - accuracy: 0.4406\nEpoch 00004: val_loss improved from 1.12829 to 1.01932, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 207s 2s\/step - loss: 1.5850 - accuracy: 0.4406 - val_loss: 1.0193 - val_accuracy: 0.6175\nEpoch 5\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.3572 - accuracy: 0.5088\nEpoch 00005: val_loss improved from 1.01932 to 0.80840, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 207s 2s\/step - loss: 1.3572 - accuracy: 0.5088 - val_loss: 0.8084 - val_accuracy: 0.7058\nEpoch 6\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.2436 - accuracy: 0.5555\nEpoch 00006: val_loss improved from 0.80840 to 0.72287, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 1.2436 - accuracy: 0.5555 - val_loss: 0.7229 - val_accuracy: 0.7457\nEpoch 7\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.0964 - accuracy: 0.6054\nEpoch 00007: val_loss improved from 0.72287 to 0.64388, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 1.0964 - accuracy: 0.6054 - val_loss: 0.6439 - val_accuracy: 0.7683\nEpoch 8\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.0273 - accuracy: 0.6388\nEpoch 00008: val_loss improved from 0.64388 to 0.57681, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 1.0273 - accuracy: 0.6388 - val_loss: 0.5768 - val_accuracy: 0.8017\nEpoch 9\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9516 - accuracy: 0.6571\nEpoch 00009: val_loss improved from 0.57681 to 0.53255, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 0.9516 - accuracy: 0.6571 - val_loss: 0.5325 - val_accuracy: 0.8082\nEpoch 10\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8996 - accuracy: 0.6754\nEpoch 00010: val_loss did not improve from 0.53255\n118\/118 [==============================] - 203s 2s\/step - loss: 0.8996 - accuracy: 0.6754 - val_loss: 0.5730 - val_accuracy: 0.8071\nEpoch 11\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8452 - accuracy: 0.7022\nEpoch 00011: val_loss improved from 0.53255 to 0.48696, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.8452 - accuracy: 0.7022 - val_loss: 0.4870 - val_accuracy: 0.8341\nEpoch 12\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8009 - accuracy: 0.7237\nEpoch 00012: val_loss improved from 0.48696 to 0.44576, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.8009 - accuracy: 0.7237 - val_loss: 0.4458 - val_accuracy: 0.8438\nEpoch 13\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7998 - accuracy: 0.7163\nEpoch 00013: val_loss improved from 0.44576 to 0.43510, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.7998 - accuracy: 0.7163 - val_loss: 0.4351 - val_accuracy: 0.8405\nEpoch 14\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7456 - accuracy: 0.7375\nEpoch 00014: val_loss did not improve from 0.43510\n118\/118 [==============================] - 203s 2s\/step - loss: 0.7456 - accuracy: 0.7375 - val_loss: 0.4458 - val_accuracy: 0.8567\nEpoch 15\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7264 - accuracy: 0.7410\nEpoch 00015: val_loss improved from 0.43510 to 0.39596, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 207s 2s\/step - loss: 0.7264 - accuracy: 0.7410 - val_loss: 0.3960 - val_accuracy: 0.8664\nEpoch 16\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7432 - accuracy: 0.7465\nEpoch 00016: val_loss did not improve from 0.39596\n118\/118 [==============================] - 202s 2s\/step - loss: 0.7432 - accuracy: 0.7465 - val_loss: 0.3964 - val_accuracy: 0.8642\nEpoch 17\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.7760\nEpoch 00017: val_loss improved from 0.39596 to 0.37665, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.6402 - accuracy: 0.7760 - val_loss: 0.3767 - val_accuracy: 0.8642\nEpoch 18\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.7572\nEpoch 00018: val_loss improved from 0.37665 to 0.37270, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.6886 - accuracy: 0.7572 - val_loss: 0.3727 - val_accuracy: 0.8621\nEpoch 19\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.7654\nEpoch 00019: val_loss did not improve from 0.37270\n118\/118 [==============================] - 205s 2s\/step - loss: 0.6670 - accuracy: 0.7654 - val_loss: 0.3847 - val_accuracy: 0.8707\nEpoch 20\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7760\nEpoch 00020: val_loss did not improve from 0.37270\n118\/118 [==============================] - 201s 2s\/step - loss: 0.6241 - accuracy: 0.7760 - val_loss: 0.3769 - val_accuracy: 0.8599\nEpoch 21\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6415 - accuracy: 0.7749\nEpoch 00021: val_loss improved from 0.37270 to 0.35816, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 0.6415 - accuracy: 0.7749 - val_loss: 0.3582 - val_accuracy: 0.8696\nEpoch 22\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.7885\nEpoch 00022: val_loss improved from 0.35816 to 0.34367, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 0.6357 - accuracy: 0.7885 - val_loss: 0.3437 - val_accuracy: 0.8739\nEpoch 23\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.7925\nEpoch 00023: val_loss did not improve from 0.34367\n118\/118 [==============================] - 203s 2s\/step - loss: 0.5984 - accuracy: 0.7925 - val_loss: 0.3652 - val_accuracy: 0.8847\nEpoch 24\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.7845\nEpoch 00024: val_loss improved from 0.34367 to 0.34118, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.6049 - accuracy: 0.7845 - val_loss: 0.3412 - val_accuracy: 0.8761\nEpoch 25\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.7856\nEpoch 00025: val_loss did not improve from 0.34118\n118\/118 [==============================] - 204s 2s\/step - loss: 0.6016 - accuracy: 0.7856 - val_loss: 0.3561 - val_accuracy: 0.8685\nEpoch 26\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.8015\nEpoch 00026: val_loss improved from 0.34118 to 0.31757, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 0.5838 - accuracy: 0.8015 - val_loss: 0.3176 - val_accuracy: 0.8772\nEpoch 27\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.8047\nEpoch 00027: val_loss improved from 0.31757 to 0.31541, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.5886 - accuracy: 0.8047 - val_loss: 0.3154 - val_accuracy: 0.8836\nEpoch 28\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.7959\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 00028: val_loss did not improve from 0.31541\n118\/118 [==============================] - 205s 2s\/step - loss: 0.5598 - accuracy: 0.7959 - val_loss: 0.3524 - val_accuracy: 0.8750\nEpoch 29\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.8044\nEpoch 00029: val_loss did not improve from 0.31541\n118\/118 [==============================] - 204s 2s\/step - loss: 0.5591 - accuracy: 0.8044 - val_loss: 0.3326 - val_accuracy: 0.8750\nEpoch 30\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.8238\nEpoch 00030: val_loss improved from 0.31541 to 0.30786, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.4970 - accuracy: 0.8238 - val_loss: 0.3079 - val_accuracy: 0.8858\nAccuarcy accuracy: 88.69%\n======================================\nIteration =  4\n======================================\nCreate Model\nModel: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nfunctional_11 (Functional)   (None, 294912)            23587712  \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 294912)            1179648   \n_________________________________________________________________\ndense_15 (Dense)             (None, 512)               150995456 \n_________________________________________________________________\nactivation_12 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_16 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_13 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_17 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_14 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_18 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_15 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_19 (Dense)             (None, 12)                6156      \n=================================================================\nTotal params: 176,565,132\nTrainable params: 152,383,500\nNon-trainable params: 24,181,632\n_________________________________________________________________\n======================================\nFound 3800 validated image filenames belonging to 12 classes.\nFound 950 validated image filenames belonging to 12 classes.\nEpoch 1\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.9163 - accuracy: 0.1377\nEpoch 00001: val_loss improved from inf to 2.21694, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 2.9163 - accuracy: 0.1377 - val_loss: 2.2169 - val_accuracy: 0.3200\nEpoch 2\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.3177 - accuracy: 0.2596\nEpoch 00002: val_loss improved from 2.21694 to 1.49622, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 2.3177 - accuracy: 0.2596 - val_loss: 1.4962 - val_accuracy: 0.4720\nEpoch 3\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.8541 - accuracy: 0.3575\nEpoch 00003: val_loss improved from 1.49622 to 1.16451, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 211s 2s\/step - loss: 1.8541 - accuracy: 0.3575 - val_loss: 1.1645 - val_accuracy: 0.5506\nEpoch 4\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.5736 - accuracy: 0.4440\nEpoch 00004: val_loss improved from 1.16451 to 0.99597, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 1.5736 - accuracy: 0.4440 - val_loss: 0.9960 - val_accuracy: 0.6325\nEpoch 5\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.3829 - accuracy: 0.5048\nEpoch 00005: val_loss improved from 0.99597 to 0.81287, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 1.3829 - accuracy: 0.5048 - val_loss: 0.8129 - val_accuracy: 0.6918\nEpoch 6\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.2323 - accuracy: 0.5552\nEpoch 00006: val_loss improved from 0.81287 to 0.73315, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 1.2323 - accuracy: 0.5552 - val_loss: 0.7332 - val_accuracy: 0.7435\nEpoch 7\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.1148 - accuracy: 0.5945\nEpoch 00007: val_loss improved from 0.73315 to 0.72270, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 1.1148 - accuracy: 0.5945 - val_loss: 0.7227 - val_accuracy: 0.7425\nEpoch 8\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.0699 - accuracy: 0.6024\nEpoch 00008: val_loss improved from 0.72270 to 0.60201, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 1.0699 - accuracy: 0.6024 - val_loss: 0.6020 - val_accuracy: 0.7985\nEpoch 9\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.0084 - accuracy: 0.6401\nEpoch 00009: val_loss improved from 0.60201 to 0.53590, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 215s 2s\/step - loss: 1.0084 - accuracy: 0.6401 - val_loss: 0.5359 - val_accuracy: 0.8190\nEpoch 10\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9400 - accuracy: 0.6656\nEpoch 00010: val_loss improved from 0.53590 to 0.51151, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 211s 2s\/step - loss: 0.9400 - accuracy: 0.6656 - val_loss: 0.5115 - val_accuracy: 0.8157\nEpoch 11\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8902 - accuracy: 0.6741\nEpoch 00011: val_loss improved from 0.51151 to 0.49185, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.8902 - accuracy: 0.6741 - val_loss: 0.4919 - val_accuracy: 0.8211\nEpoch 12\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8172 - accuracy: 0.7160\nEpoch 00012: val_loss improved from 0.49185 to 0.43757, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.8172 - accuracy: 0.7160 - val_loss: 0.4376 - val_accuracy: 0.8459\nEpoch 13\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8040 - accuracy: 0.7184\nEpoch 00013: val_loss improved from 0.43757 to 0.41820, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 217s 2s\/step - loss: 0.8040 - accuracy: 0.7184 - val_loss: 0.4182 - val_accuracy: 0.8459\nEpoch 14\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7852 - accuracy: 0.7245\nEpoch 00014: val_loss did not improve from 0.41820\n118\/118 [==============================] - 205s 2s\/step - loss: 0.7852 - accuracy: 0.7245 - val_loss: 0.4242 - val_accuracy: 0.8448\nEpoch 15\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7493 - accuracy: 0.7418\nEpoch 00015: val_loss did not improve from 0.41820\n118\/118 [==============================] - 203s 2s\/step - loss: 0.7493 - accuracy: 0.7418 - val_loss: 0.4217 - val_accuracy: 0.8319\nEpoch 16\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7333 - accuracy: 0.7463\nEpoch 00016: val_loss improved from 0.41820 to 0.39673, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 213s 2s\/step - loss: 0.7333 - accuracy: 0.7463 - val_loss: 0.3967 - val_accuracy: 0.8599\nEpoch 17\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.7513\nEpoch 00017: val_loss did not improve from 0.39673\n118\/118 [==============================] - 202s 2s\/step - loss: 0.6840 - accuracy: 0.7513 - val_loss: 0.4033 - val_accuracy: 0.8545\nEpoch 18\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.7614\nEpoch 00018: val_loss improved from 0.39673 to 0.37921, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.6926 - accuracy: 0.7614 - val_loss: 0.3792 - val_accuracy: 0.8567\nEpoch 19\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.7683\nEpoch 00019: val_loss did not improve from 0.37921\n118\/118 [==============================] - 202s 2s\/step - loss: 0.6780 - accuracy: 0.7683 - val_loss: 0.3937 - val_accuracy: 0.8599\nEpoch 20\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.7763\nEpoch 00020: val_loss did not improve from 0.37921\n118\/118 [==============================] - 203s 2s\/step - loss: 0.6492 - accuracy: 0.7763 - val_loss: 0.3914 - val_accuracy: 0.8631\nEpoch 21\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6615 - accuracy: 0.7691\nEpoch 00021: val_loss did not improve from 0.37921\n118\/118 [==============================] - 202s 2s\/step - loss: 0.6615 - accuracy: 0.7691 - val_loss: 0.3926 - val_accuracy: 0.8642\nEpoch 22\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.7800\nEpoch 00022: val_loss did not improve from 0.37921\n118\/118 [==============================] - 202s 2s\/step - loss: 0.6333 - accuracy: 0.7800 - val_loss: 0.4036 - val_accuracy: 0.8610\nEpoch 23\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.7853\nEpoch 00023: val_loss improved from 0.37921 to 0.33291, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 0.6111 - accuracy: 0.7853 - val_loss: 0.3329 - val_accuracy: 0.8793\nEpoch 24\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.7773\nEpoch 00024: val_loss did not improve from 0.33291\n118\/118 [==============================] - 202s 2s\/step - loss: 0.6231 - accuracy: 0.7773 - val_loss: 0.3625 - val_accuracy: 0.8685\nEpoch 25\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.7880\nEpoch 00025: val_loss did not improve from 0.33291\n118\/118 [==============================] - 203s 2s\/step - loss: 0.6162 - accuracy: 0.7880 - val_loss: 0.3435 - val_accuracy: 0.8782\nEpoch 26\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.7962\nEpoch 00026: val_loss did not improve from 0.33291\n118\/118 [==============================] - 202s 2s\/step - loss: 0.5856 - accuracy: 0.7962 - val_loss: 0.3495 - val_accuracy: 0.8728\nEpoch 27\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5879 - accuracy: 0.7941\nEpoch 00027: val_loss did not improve from 0.33291\n118\/118 [==============================] - 202s 2s\/step - loss: 0.5879 - accuracy: 0.7941 - val_loss: 0.3375 - val_accuracy: 0.8793\nEpoch 28\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.7980\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 00028: val_loss did not improve from 0.33291\n118\/118 [==============================] - 203s 2s\/step - loss: 0.5859 - accuracy: 0.7980 - val_loss: 0.3383 - val_accuracy: 0.8772\nEpoch 29\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.8145\nEpoch 00029: val_loss improved from 0.33291 to 0.32714, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 211s 2s\/step - loss: 0.5376 - accuracy: 0.8145 - val_loss: 0.3271 - val_accuracy: 0.8815\nEpoch 30\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.8198\nEpoch 00030: val_loss did not improve from 0.32714\n118\/118 [==============================] - 208s 2s\/step - loss: 0.5204 - accuracy: 0.8198 - val_loss: 0.3342 - val_accuracy: 0.8761\nAccuarcy accuracy: 88.25%\n======================================\nIteration =  5\n======================================\nCreate Model\nModel: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nfunctional_13 (Functional)   (None, 294912)            23587712  \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 294912)            1179648   \n_________________________________________________________________\ndense_20 (Dense)             (None, 512)               150995456 \n_________________________________________________________________\nactivation_16 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_21 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_17 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_22 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_18 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_23 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_23 (Dense)             (None, 512)               262656    \n_________________________________________________________________\nactivation_19 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_24 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_24 (Dense)             (None, 12)                6156      \n=================================================================\nTotal params: 176,565,132\nTrainable params: 152,383,500\nNon-trainable params: 24,181,632\n_________________________________________________________________\n======================================\nFound 3800 validated image filenames belonging to 12 classes.\nFound 950 validated image filenames belonging to 12 classes.\nEpoch 1\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.8916 - accuracy: 0.1497\nEpoch 00001: val_loss improved from inf to 2.14445, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 2.8916 - accuracy: 0.1497 - val_loss: 2.1444 - val_accuracy: 0.3157\nEpoch 2\/30\n118\/118 [==============================] - ETA: 0s - loss: 2.3703 - accuracy: 0.2508\nEpoch 00002: val_loss improved from 2.14445 to 1.51686, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 2.3703 - accuracy: 0.2508 - val_loss: 1.5169 - val_accuracy: 0.4601\nEpoch 3\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.9075 - accuracy: 0.3588\nEpoch 00003: val_loss improved from 1.51686 to 1.16876, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 1.9075 - accuracy: 0.3588 - val_loss: 1.1688 - val_accuracy: 0.5787\nEpoch 4\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.6141 - accuracy: 0.4408\nEpoch 00004: val_loss improved from 1.16876 to 0.97164, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 1.6141 - accuracy: 0.4408 - val_loss: 0.9716 - val_accuracy: 0.6175\nEpoch 5\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.3812 - accuracy: 0.5003\nEpoch 00005: val_loss improved from 0.97164 to 0.85223, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 1.3812 - accuracy: 0.5003 - val_loss: 0.8522 - val_accuracy: 0.6940\nEpoch 6\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.2621 - accuracy: 0.5438\nEpoch 00006: val_loss improved from 0.85223 to 0.72889, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 210s 2s\/step - loss: 1.2621 - accuracy: 0.5438 - val_loss: 0.7289 - val_accuracy: 0.7295\nEpoch 7\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.1287 - accuracy: 0.5987\nEpoch 00007: val_loss improved from 0.72889 to 0.62893, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 1.1287 - accuracy: 0.5987 - val_loss: 0.6289 - val_accuracy: 0.7694\nEpoch 8\/30\n118\/118 [==============================] - ETA: 0s - loss: 1.0216 - accuracy: 0.6377\nEpoch 00008: val_loss improved from 0.62893 to 0.54511, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 215s 2s\/step - loss: 1.0216 - accuracy: 0.6377 - val_loss: 0.5451 - val_accuracy: 0.7942\nEpoch 9\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9833 - accuracy: 0.6505\nEpoch 00009: val_loss improved from 0.54511 to 0.52871, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 214s 2s\/step - loss: 0.9833 - accuracy: 0.6505 - val_loss: 0.5287 - val_accuracy: 0.7996\nEpoch 10\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.9680 - accuracy: 0.6651\nEpoch 00010: val_loss improved from 0.52871 to 0.51715, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 219s 2s\/step - loss: 0.9680 - accuracy: 0.6651 - val_loss: 0.5171 - val_accuracy: 0.8125\nEpoch 11\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.6868\nEpoch 00011: val_loss improved from 0.51715 to 0.43978, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 222s 2s\/step - loss: 0.8778 - accuracy: 0.6868 - val_loss: 0.4398 - val_accuracy: 0.8470\nEpoch 12\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.8255 - accuracy: 0.7086\nEpoch 00012: val_loss improved from 0.43978 to 0.41241, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 216s 2s\/step - loss: 0.8255 - accuracy: 0.7086 - val_loss: 0.4124 - val_accuracy: 0.8513\nEpoch 13\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.7274\nEpoch 00013: val_loss improved from 0.41241 to 0.37892, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.7879 - accuracy: 0.7274 - val_loss: 0.3789 - val_accuracy: 0.8556\nEpoch 14\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7777 - accuracy: 0.7269\nEpoch 00014: val_loss did not improve from 0.37892\n118\/118 [==============================] - 203s 2s\/step - loss: 0.7777 - accuracy: 0.7269 - val_loss: 0.3939 - val_accuracy: 0.8545\nEpoch 15\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.7455\nEpoch 00015: val_loss did not improve from 0.37892\n118\/118 [==============================] - 203s 2s\/step - loss: 0.7342 - accuracy: 0.7455 - val_loss: 0.4042 - val_accuracy: 0.8534\nEpoch 16\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.7370 - accuracy: 0.7394\nEpoch 00016: val_loss did not improve from 0.37892\n118\/118 [==============================] - 201s 2s\/step - loss: 0.7370 - accuracy: 0.7394 - val_loss: 0.3978 - val_accuracy: 0.8545\nEpoch 17\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6689 - accuracy: 0.7667\nEpoch 00017: val_loss did not improve from 0.37892\n118\/118 [==============================] - 203s 2s\/step - loss: 0.6689 - accuracy: 0.7667 - val_loss: 0.3803 - val_accuracy: 0.8481\nEpoch 18\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.7630\nEpoch 00018: val_loss improved from 0.37892 to 0.35166, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 209s 2s\/step - loss: 0.6934 - accuracy: 0.7630 - val_loss: 0.3517 - val_accuracy: 0.8707\nEpoch 19\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.7641\nEpoch 00019: val_loss did not improve from 0.35166\n118\/118 [==============================] - 203s 2s\/step - loss: 0.6804 - accuracy: 0.7641 - val_loss: 0.3597 - val_accuracy: 0.8728\nEpoch 20\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6537 - accuracy: 0.7696\nEpoch 00020: val_loss improved from 0.35166 to 0.33908, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.6537 - accuracy: 0.7696 - val_loss: 0.3391 - val_accuracy: 0.8664\nEpoch 21\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.7643\nEpoch 00021: val_loss did not improve from 0.33908\n118\/118 [==============================] - 208s 2s\/step - loss: 0.6746 - accuracy: 0.7643 - val_loss: 0.3498 - val_accuracy: 0.8685\nEpoch 22\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7763\nEpoch 00022: val_loss improved from 0.33908 to 0.33536, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 212s 2s\/step - loss: 0.6352 - accuracy: 0.7763 - val_loss: 0.3354 - val_accuracy: 0.8739\nEpoch 23\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.7935\nEpoch 00023: val_loss did not improve from 0.33536\n118\/118 [==============================] - 205s 2s\/step - loss: 0.6149 - accuracy: 0.7935 - val_loss: 0.3442 - val_accuracy: 0.8739\nEpoch 24\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.7872\nEpoch 00024: val_loss did not improve from 0.33536\n118\/118 [==============================] - 202s 2s\/step - loss: 0.6151 - accuracy: 0.7872 - val_loss: 0.3451 - val_accuracy: 0.8685\nEpoch 25\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.7805\nEpoch 00025: val_loss improved from 0.33536 to 0.32856, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 0.6297 - accuracy: 0.7805 - val_loss: 0.3286 - val_accuracy: 0.8858\nEpoch 26\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.7962\nEpoch 00026: val_loss did not improve from 0.32856\n118\/118 [==============================] - 204s 2s\/step - loss: 0.5912 - accuracy: 0.7962 - val_loss: 0.3312 - val_accuracy: 0.8804\nEpoch 27\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.7840\nEpoch 00027: val_loss did not improve from 0.32856\n118\/118 [==============================] - 202s 2s\/step - loss: 0.6107 - accuracy: 0.7840 - val_loss: 0.3348 - val_accuracy: 0.8858\nEpoch 28\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5940 - accuracy: 0.7959\nEpoch 00028: val_loss did not improve from 0.32856\n118\/118 [==============================] - 202s 2s\/step - loss: 0.5940 - accuracy: 0.7959 - val_loss: 0.3307 - val_accuracy: 0.8836\nEpoch 29\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.8039\nEpoch 00029: val_loss improved from 0.32856 to 0.30924, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 207s 2s\/step - loss: 0.5582 - accuracy: 0.8039 - val_loss: 0.3092 - val_accuracy: 0.8804\nEpoch 30\/30\n118\/118 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.7988\nEpoch 00030: val_loss improved from 0.30924 to 0.29169, saving model to \/kaggle\/working\/model.h5\n118\/118 [==============================] - 208s 2s\/step - loss: 0.5697 - accuracy: 0.7988 - val_loss: 0.2917 - val_accuracy: 0.8879\nAccuarcy accuracy: 89.01%\nAccuracy: 88.53% (+\/- 0.34%)\n\n\n\n\n","1e571e82":"class_indices={'Black-grass': 0,\n 'Charlock': 1,\n 'Cleavers': 2,\n 'Common Chickweed': 3,\n 'Common wheat': 4,\n 'Fat Hen': 5,\n 'Loose Silky-bent': 6,\n 'Maize': 7,\n 'Scentless Mayweed': 8,\n 'Shepherds Purse': 9,\n 'Small-flowered Cranesbill': 10,\n 'Sugar beet': 11}\nclass_indices","1d008ca3":"image_datagen_for_test = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                            width_shift_range=0.2, # Range for random horizontal shifts\n                            height_shift_range=0.2, # Range for random vertical shifts\n                            zoom_range=0.2, # Range for random zoom\n                            horizontal_flip=True, # Randomly flip inputs horizontally\n                            vertical_flip=True\n                              )\n\ntest_generator=image_datagen_for_test.flow_from_dataframe(dataframe=test,\n                                                  directory=test_path,\n                                                  x_col=\"file\",\n                                                  y_col=None,\n                                                  batch_size=1,\n                                                  seed=SEED,\n                                                  shuffle=False,\n                                                  class_mode=None,\n                                                  target_size=INPUT_SHAPE[:2],\n                                                  color_mode='rgb');\n\nmodel = load_model('\/kaggle\/working\/best_model\/')\nfilenames = test_generator.filenames\nnb_samples = len(filenames)\nprint(nb_samples)\n\n# Final test predictions\npredictions = model.predict_generator(test_generator,steps = nb_samples) \npredicted_class_indices=np.argmax(predictions,axis=1)\n\nlabels = dict((v,k) for k,v in class_indices.items())\npredicted_labels = [labels[k] for k in predicted_class_indices]\n\nresults=pd.DataFrame({\"file\":filenames,\n                      \"species\":predicted_labels})\nprint (results)\nresults.to_csv(\"submission.csv\",index=False)","735619b7":"Found 794 validated image filenames.\n794\n\/usr\/local\/lib\/python3.6\/dist-packages\/tensorflow\/python\/keras\/engine\/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n  warnings.warn('`Model.predict_generator` is deprecated and '\n              file            species\n0    fea3da57c.png  Sugar beet       \n1    fe9e87b78.png  Scentless Mayweed\n2    fdea6b119.png  Loose Silky-bent \n3    fef2ade8c.png  Sugar beet       \n4    ff65bc002.png  Charlock         \n..             ...       ...         \n789  e4a76885b.png  Maize            \n790  e1abb4ff9.png  Sugar beet       \n791  df521c0c0.png  Loose Silky-bent \n792  dd5ec63d9.png  Sugar beet       \n793  25a4c427e.png  Loose Silky-bent \n\n[794 rows x 2 columns]","ffc83911":"#Training with Resnet50","23e13f16":"Train model function with 5 fold cross validation","ebb77b6d":"![__results___32_1.png](attachment:__results___32_1.png)\n![__results___32_2.png](attachment:__results___32_2.png)\n![__results___32_3.png](attachment:__results___32_3.png)\n![__results___32_4.png](attachment:__results___32_4.png)\n![__results___32_5.png](attachment:__results___32_5.png)","51880fe6":"references \n\nhttps:\/\/www.kaggle.com\/praanj\/transfer-learning-vgg-19-resnet-50-with-kfold\/\nhttps:\/\/www.kaggle.com\/c\/plant-seedlings-classification\/notebooks?competitionId=7880\n\nhttps:\/\/www.kaggle.com\/praanj\/basic-keras-cnn-with-startified-kfold-evaluation\n\nhttps:\/\/www.kaggle.com\/kinsomaz\/plant-seedling-classification-using-keras-0-9726\n\nhttps:\/\/www.kaggle.com\/kaiyungtan\/plant-seedlings-classification\n\nhttps:\/\/www.kaggle.com\/akashwadhwaai\/plant-seedlings-classification\n","baaf1d25":"Identify layers in VGG 19","cd7d280d":"Renaming train set image files (Once done files are renamed so no need to run again)","8dde800f":"Freeze layers in Resnet 50","049b522d":"#Create the model from the scratch","7c70d640":"# Function for printing history","8c5787b7":"Identify layers in Resnet 50","aa3762e4":"# create model","df8e238f":"Renaming train set image files(Once done files are renamed so no need to run again)","a496a47b":"Freeze layers in VGG-19"}}