{"cell_type":{"ed9302f9":"code","e8a7efd3":"code","bb3735f8":"code","1a96b07f":"code","9869d8f3":"code","4f776347":"code","fb090013":"code","6cc7248a":"code","f4c35666":"code","25ca5acd":"code","c8aedf56":"code","db2ee13b":"code","2c20ae79":"code","72d71a13":"markdown","c4861717":"markdown","665b9ee2":"markdown","7705c4e9":"markdown","ec392cbf":"markdown","555fd33e":"markdown","89877ef6":"markdown","ee618635":"markdown","c04f7828":"markdown","df68702f":"markdown","6a9206e0":"markdown"},"source":{"ed9302f9":"import argparse\nimport re\nimport os, time, datetime\n#import PIL.Image as Image\nimport numpy as np\nfrom skimage import img_as_ubyte\nfrom keras.models import load_model, model_from_json\nfrom skimage.metrics import peak_signal_noise_ratio,structural_similarity\n#from google.colab.patches import cv2_imshow\nfrom skimage.io import imread, imsave\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom skimage import img_as_ubyte\nimport os, glob, datetime\nfrom keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract\nfrom keras.models import Model, load_model\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\nfrom keras.optimizers import Adam\n#import data_generator as dg\nimport keras.backend as K","e8a7efd3":"import glob\nimport os\nimport cv2\nimport numpy as np\n#from multiprocessing import Pool\n\n\npatch_size, stride = 40, 10\naug_times = 1\nscales = [1, 0.9, 0.8, 0.7]\nbatch_size = 128\n\n\ndef show(x,title=None,cbar=False,figsize=None):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=figsize)\n    plt.imshow(x,interpolation='INTER_CUBIC',cmap='gray')\n    if title:\n        plt.title(title)\n    if cbar:\n        plt.colorbar()\n    plt.show()\n\ndef data_aug(img, mode=0):\n\n    if mode == 0:\n        return img\n    elif mode == 1:\n        return np.flipud(img)\n    elif mode == 2:\n        return np.rot90(img)\n    elif mode == 3:\n        return np.flipud(np.rot90(img))\n    elif mode == 4:\n        return np.rot90(img, k=2)\n    elif mode == 5:\n        return np.flipud(np.rot90(img, k=2))\n    elif mode == 6:\n        return np.rot90(img, k=3)\n    elif mode == 7:\n        return np.flipud(np.rot90(img, k=3))\n\ndef gen_patches(file_name):\n\n    # read image\n    img = cv2.imread(file_name, 0)  # gray scale\n    h, w = img.shape\n    patches = []\n    for s in scales:\n        h_scaled, w_scaled = int(h*s),int(w*s)\n        img_scaled = cv2.resize(img, (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n        # extract patches\n        for i in range(0, h_scaled-patch_size+1, stride):\n            for j in range(0, w_scaled-patch_size+1, stride):\n                x = img_scaled[i:i+patch_size, j:j+patch_size]\n                #patches.append(x)        \n                # data aug\n                for k in range(0, aug_times):\n                    x_aug = data_aug(x, mode=np.random.randint(0,8))\n                    patches.append(x_aug)\n                \n    return patches\n\ndef datagenerator(data_dir='..\/input\/image-data\/Train400\/Train400',verbose=False):\n    \n    file_list = glob.glob(data_dir+'\/*.png')  # get name list of all .png files\n    # initrialize\n    data = []\n    # generate patches\n    for i in range(len(file_list)):\n        patch = gen_patches(file_list[i])\n        data.append(patch)\n        if verbose:\n            print(str(i+1)+'\/'+ str(len(file_list)) + ' is done ^_^')\n    data = np.array(data, dtype='uint8')\n    data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n    discard_n = len(data)-len(data)\/\/batch_size*batch_size;\n    data = np.delete(data,range(discard_n),axis = 0)\n    print('Training data finished-Good to go!')\n    return data\n\n\ndata = datagenerator(data_dir='..\/input\/image-data\/Train400\/Train400')","bb3735f8":"\n# run this to train the model\n\n# =============================================================================\n# For batch normalization layer, momentum should be a value from [0, 0.9] rather than the default 0.99. \n# The Gaussian noise output helps to stablize the batch normalization, thus a small momentum is preferred.\n# =============================================================================\n\n\n## Params\nparser = argparse.ArgumentParser()\nparser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\nparser.add_argument('--batch_size', default=128, type=int, help='batch size')\nparser.add_argument('--train_data', default='..\/input\/image-data\/Train400\/Train400', type=str, help='path of train data')\nparser.add_argument('--sigma', default=25, type=int, help='noise level')\n\n# epochs = 300 changed to 50\n#parser.add_argument('--epoch', default=300, type=int, help='number of train epoches')\nparser.add_argument('--epoch', default=50, type=int, help='number of train epoches')\n\n\nparser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate for Adam')\n\nparser.add_argument('--save_every', default=500, type=int, help='save model at every x epoches')\nargs = parser.parse_args(args=[])\n\n\nsave_dir = os.path.join('.\/','models',args.model+'_'+'sigma'+str(args.sigma)) \n\nif not os.path.exists(save_dir):\n  os.makedirs(save_dir)","1a96b07f":"def DnCNN(depth,filters=64,image_channels=1, use_bnorm=True):\n    layer_count = 0\n    inpt = Input(shape=(None,None,image_channels),name = 'input'+str(layer_count))\n    # 1st layer, Conv+relu\n    layer_count += 1\n    x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',name = 'conv'+str(layer_count))(inpt)\n    layer_count += 1\n    x = Activation('relu',name = 'relu'+str(layer_count))(x)\n    # depth-2 layers, Conv+BN+relu\n    for i in range(depth-2):\n      layer_count += 1\n      x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n      if use_bnorm:\n        layer_count += 1\n        \n        # momentum changed to 0.9 from 0.0\n        #x = BatchNormalization(axis=3, momentum=0.1,epsilon=0.0001, name = 'bn'+str(layer_count))(x) \n        #x = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n        x = BatchNormalization(axis=3, momentum=0.9,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n          \n      layer_count += 1\n      x = Activation('relu',name = 'relu'+str(layer_count))(x)  \n    # last layer, Conv\n    layer_count += 1\n    x = Conv2D(filters=image_channels, kernel_size=(3,3), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n    layer_count += 1\n    x = Subtract(name = 'subtract' + str(layer_count))([inpt, x])   # input - noise\n    model = Model(inputs=inpt, outputs=x)\n    \n    return model","9869d8f3":"def findLastCheckpoint(save_dir):\n    file_list = glob.glob(os.path.join(save_dir,'model_*.hdf5'))  # get name list of all .hdf5 files\n    #file_list = os.listdir(save_dir)\n    if file_list:\n        epochs_exist = []\n        for file_ in file_list:\n            result = re.findall(\".*model_(.*).hdf5.*\",file_)\n            #print(result[0])\n            epochs_exist.append(int(result[0]))\n        initial_epoch=max(epochs_exist)   \n    else:\n        initial_epoch = 0\n    return initial_epoch","4f776347":"def log(*args,**kwargs):\n     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),*args,**kwargs)\n\ndef lr_schedule(epoch):\n    initial_lr = args.lr\n    if epoch<=30:\n        lr = initial_lr\n    elif epoch<=60:\n        lr = initial_lr\/10\n    elif epoch<=80:\n        lr = initial_lr\/20 \n    else:\n        lr = initial_lr\/20 \n    log('current learning rate is %2.8f' %lr)\n    return lr\n\ndef train_datagen(epoch_iter=2000,epoch_num=5,batch_size=128,data_dir=args.train_data):\n    while(True):\n        n_count = 0\n        if n_count == 0:\n            #print(n_count)\n            xs = datagenerator(data_dir)\n            assert len(xs)%args.batch_size ==0, \\\n            log('make sure the last iteration has a full batchsize, this is important if you use batch normalization!')\n            xs = xs.astype('float32')\/255.0\n            indices = list(range(xs.shape[0]))\n            n_count = 1\n        for _ in range(epoch_num):\n            np.random.shuffle(indices)    # shuffle\n            for i in range(0, len(indices), batch_size):\n                batch_x = xs[indices[i:i+batch_size]]\n                noise =  np.random.normal(0, args.sigma\/255.0, batch_x.shape)    # noise\n                #noise =  K.random_normal(ge_batch_y.shape, mean=0, stddev=args.sigma\/255.0)\n                batch_y = batch_x + noise \n                yield batch_y, batch_x","fb090013":"# define loss\ndef sum_squared_error(y_true, y_pred):\n    #return K.mean(K.square(y_pred - y_true), axis=-1)\n    #return K.sum(K.square(y_pred - y_true), axis=-1)\/2\n    return K.sum(K.square(y_pred - y_true))\/2","6cc7248a":"# model selection\nmodel = DnCNN(depth=17,filters=64,image_channels=1,use_bnorm=True)\nmodel.summary()","f4c35666":"# load the last model in matconvnet style\ninitial_epoch = findLastCheckpoint(save_dir=save_dir)\nif initial_epoch > 0:  \n    print('resuming by loading epoch %03d'%initial_epoch)\n    model = load_model(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch), compile=False)\n\n# compile the model\nmodel.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n\n# use call back functions\ncheckpointer = ModelCheckpoint(os.path.join(save_dir,'model_{epoch:03d}.hdf5'), \n            verbose=1, save_weights_only=False, save_freq=args.save_every)\ncsv_logger = CSVLogger(os.path.join(save_dir,'log.csv'), append=True, separator=',')\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nhistory = model.fit(train_datagen(batch_size=args.batch_size),\n            steps_per_epoch=2000, epochs=args.epoch, verbose=1, initial_epoch=initial_epoch,\n            callbacks=[checkpointer,csv_logger,lr_scheduler])","25ca5acd":"# load the last model in matconvnet style\ninitial_epoch = findLastCheckpoint(save_dir=save_dir)\nif initial_epoch > 0:  \n    print('resuming by loading epoch %03d'%initial_epoch)\n    model = load_model(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch), compile=False)\n\n# compile the model\nmodel.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n\n# use call back functions\ncheckpointer = ModelCheckpoint(os.path.join(save_dir,'model_{epoch:03d}.hdf5'), \n            verbose=1, save_weights_only=False, save_freq=args.save_every)\ncsv_logger = CSVLogger(os.path.join(save_dir,'log.csv'), append=True, separator=',')\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nhistory = model.fit(train_datagen(batch_size=args.batch_size),\n            steps_per_epoch=2000, epochs=args.epoch, verbose=1, initial_epoch=initial_epoch,\n            callbacks=[checkpointer,csv_logger,lr_scheduler])","c8aedf56":"def parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--set_dir', default='..\/input\/image-data\/Test\/Test', type=str, help='directory of test dataset')\n    parser.add_argument('--set_names', default=['Set68','Set12'], type=list, help='name of test dataset')\n    parser.add_argument('--sigma', default=25, type=int, help='noise level')\n    parser.add_argument('--model_dir', default='.\/models\/DnCNN_sigma25\/', type=str, help='directory of the model')\n    parser.add_argument('--model_name', default='model_006.hdf5', type=str, help='the model name')\n    parser.add_argument('--result_dir', default='.\/results', type=str, help='directory of results')\n    parser.add_argument('--save_result', default=1, type=int, help='save the denoised image, 1 or 0')\n    return parser.parse_args(args = [])\n    \ndef to_tensor(img):\n    if img.ndim == 2:\n        return img[np.newaxis,...,np.newaxis]\n    elif img.ndim == 3:\n        return np.moveaxis(img,2,0)[...,np.newaxis]\n\ndef from_tensor(img):\n    return np.squeeze(np.moveaxis(img[...,0],0,-1))\n\ndef log(*args,**kwargs):\n     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),*args,**kwargs)\n\ndef save_result(result,path):\n    path = path if path.find('.') != -1 else path+'.png'\n    ext = os.path.splitext(path)[-1]\n    if ext in ('.txt','.dlm'):\n        np.savetxt(path,result,fmt='%2.4f')\n    else:\n        imsave(path,np.clip(result,0,1))\n\n\ndef show(x,title=None,cbar=False,figsize=None):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=figsize)\n    plt.imshow(x,interpolation='nearest',cmap='gray')\n    if title:\n        plt.title(title)\n    if cbar:\n        plt.colorbar()\n    plt.show()\n\n\n\nargs = parse_args()\n\n\n# =============================================================================\n#     # serialize model to JSON\n#     model_json = model.to_json()\n#     with open(\"model.json\", \"w\") as json_file:\n#         json_file.write(model_json)\n#     # serialize weights to HDF5\n#     model.save_weights(\"model.h5\")\n#     print(\"Saved model\")\n# =============================================================================\n\nif not os.path.exists(os.path.join(args.model_dir, args.model_name)):\n    # load json and create model\n    json_file = open(os.path.join(args.model_dir,'model.json'), 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    model = model_from_json(loaded_model_json)\n    # load weights into new model\n    model.load_weights(os.path.join(args.model_dir,'model.h5'))\n    log('load trained model on Train400 dataset by kai')\nelse:\n    model = load_model(os.path.join(args.model_dir, args.model_name),compile=False)\n    log('load trained model')\n\nif not os.path.exists(args.result_dir):\n    os.mkdir(args.result_dir)\n\nfor set_cur in args.set_names:  \n\n    if not os.path.exists(os.path.join(args.result_dir,set_cur)):\n        os.mkdir(os.path.join(args.result_dir,set_cur))\n    psnrs = []\n    ssims = [] \n\n    for im in os.listdir(os.path.join(args.set_dir,set_cur)): \n        if im.endswith(\".jpg\") or im.endswith(\".bmp\") or im.endswith(\".png\"):\n            #x = np.array(Image.open(os.path.join(args.set_dir,set_cur,im)), dtype='float32') \/ 255.0\n            x = np.array(imread(os.path.join(args.set_dir,set_cur,im)), dtype=np.float32) \/ 255.0\n            np.random.seed(seed=0) # for reproducibility\n            y = x + np.random.normal(0, args.sigma\/255.0, x.shape) # Add Gaussian noise without clipping\n            y = y.astype(np.float32)\n            y_  = to_tensor(y)\n            start_time = time.time()\n            x_ = model.predict(y_) # inference\n            elapsed_time = time.time() - start_time\n            print('%10s : %10s : %2.4f second'%(set_cur,im,elapsed_time))\n            x_=from_tensor(x_)\n            psnr_x_ = peak_signal_noise_ratio(x, x_)\n            ssim_x_ = structural_similarity(x, x_)\n            if args.save_result:\n                name, ext = os.path.splitext(im)\n                show(np.hstack((y,x_)),figsize=(15,20)) # show the image\n                save_result(x_,path=os.path.join(args.result_dir,set_cur,name+'_dncnn'+ext)) # save the denoised image\n            psnrs.append(psnr_x_)\n            ssims.append(ssim_x_)\n\n    psnr_avg = np.mean(psnrs)\n    ssim_avg = np.mean(ssims)\n    psnrs.append(psnr_avg)\n    ssims.append(ssim_avg)\n\n    if args.save_result:\n        save_result(np.hstack((psnrs,ssims)),path=os.path.join(args.result_dir,set_cur,'results.txt'))\n\n    log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))        ","db2ee13b":"import os\nos.remove(\".\/aip_denoise.tar.gz\")","2c20ae79":"!tar -zcvf aip_denoise.tar.gz \/kaggle\/working","72d71a13":"# Resuming Training","c4861717":"# Learning rate, log file, train data generation","665b9ee2":"# Importing required libraries","7705c4e9":"# Testing phase","ec392cbf":"# Model Summary","555fd33e":"# DnCNN model","89877ef6":"# Loss Function","ee618635":"# Training Phase","c04f7828":"# Load model from last Checkpoint","df68702f":"# Preprocessing Training data","6a9206e0":"* > **This implementation removes Gaussian noise from image of sigma=25 using residual mapping and batch normalization technique.**\n* > **Training dataset consists of 400 images.**\n* > **Testing dataset has 2 sub-folders which contains 68 natural images from Berkeley segmentation dataset (BSD68) and the other one contains 12 images.**"}}