{"cell_type":{"cec278d8":"code","2f0010d9":"code","e2b37c6c":"code","e19c74c4":"code","c6d3a067":"code","dd02a5ec":"code","066c90a4":"code","d8b345ee":"code","9c51e4cc":"code","b86114fa":"code","2b794d2f":"code","a8ae3a22":"code","1591acaf":"code","72320820":"code","de39baf3":"code","2ce0943f":"code","d21374c5":"code","e706f829":"code","7850fabb":"code","76f65bac":"code","a89a1138":"code","e9527956":"code","7d775c8d":"code","c903f2d9":"code","55bc658a":"code","6e6f6ce8":"code","8787df39":"code","67f3d46d":"code","58f4d563":"code","ab4d0352":"code","a054a113":"code","9cb80923":"code","7ac14b2b":"code","a5e38b8f":"code","be061715":"code","fe1d9a63":"code","41314650":"code","9dc611fb":"code","d69fcbad":"code","43855cad":"code","cdb91ff4":"code","eb0fd49f":"code","ef560ee7":"code","90fca6f4":"code","4c63386b":"code","8cf1d9c5":"code","aaf16716":"code","53df38ff":"markdown","d438e2cf":"markdown","39073294":"markdown","3129711d":"markdown","fd12ecd8":"markdown","c308de43":"markdown","eb8a7f60":"markdown","735352e3":"markdown","0ea5c27f":"markdown","aa4f3d06":"markdown","55221299":"markdown","6b0c4a08":"markdown","b8e953c6":"markdown","c73b2f71":"markdown","907643e6":"markdown","305b70a1":"markdown","0d9f6185":"markdown","d63c3d5b":"markdown","890408f7":"markdown"},"source":{"cec278d8":"! pip3 install tensorflow==1.14.0","2f0010d9":"import tensorflow as tf\nimport os, subprocess, re\nimport numpy as np\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport shutil\nimport json\nfrom google.protobuf import text_format\nimport pprint\nimport random\nfrom pathlib import Path\nfrom google.protobuf import text_format\n\n%matplotlib inline","e2b37c6c":"print(tf.__version__)","e19c74c4":"# needed to install object_detection library and enlarge labels\n! rm -rf .\/models && git clone --depth 1 https:\/\/github.com\/tensorflow\/models.git -b v1.13.0 \\\n    && sed -i \"s#ImageFont.truetype('arial.ttf', 24)#ImageFont.truetype('arial.ttf', 50)#g\" .\/models\/research\/object_detection\/utils\/visualization_utils.py \\\n    && cp \/usr\/share\/fonts\/truetype\/dejavu\/DejaVuSans.ttf \/usr\/share\/fonts\/truetype\/dejavu\/arial.ttf","c6d3a067":"# install object_detection library\n! pip3 install pycocotools > \/dev\/null\n! cd .\/models\/research && \\\n    protoc object_detection\/protos\/*.proto --python_out=. && \\\n    python3 setup.py build > \/dev\/null && \\\n    python3 setup.py bdist_wheel > \/dev\/null\n! python3 -m pip install --no-cache-dir .\/models\/research\/dist\/object_detection-0.1-py3-none-any.whl > \/dev\/null\n! cd .\/models\/research\/slim && \\\n    python3 setup.py bdist_wheel > \/dev\/null\n! python3 -m pip install --no-cache-dir .\/models\/research\/slim\/dist\/slim-0.1-py3-none-any.whl > \/dev\/null","dd02a5ec":"from object_detection.utils import dataset_util, label_map_util\nfrom object_detection.dataset_tools.create_coco_tf_record import create_tf_example\nfrom object_detection.protos import string_int_label_map_pb2\nfrom object_detection.protos import pipeline_pb2\nfrom object_detection.utils import visualization_utils as vis_util","066c90a4":"MODEL = 'ssd_mobilenet_v2_coco_2018_03_29'\nDATA_DIR = '.\/nn-models'\nMODEL_DIR = os.path.join(DATA_DIR, MODEL)\nURL = 'http:\/\/download.tensorflow.org\/models\/object_detection\/%s.tar.gz' % MODEL\nDOWNLOAD_PATH = '%s\/%s.tar.gz' % (DATA_DIR, MODEL)","d8b345ee":"if not os.path.exists(DATA_DIR):\n    subprocess.run(['mkdir', DATA_DIR])","9c51e4cc":"from tensorflow.python.util import compat\nfrom tensorflow.core.protobuf import saved_model_pb2\n\ndef reconstruct(pb_path):\n    if not os.path.isfile(pb_path):\n        print(\"Error: %s not found\" % pb_path)\n\n    print(\"Reconstructing Tensorflow model\")\n    detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.compat.v1.GraphDef()\n        with tf.io.gfile.GFile(pb_path, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    print(\"Success!\")\n    return detection_graph","b86114fa":"def download():\n    print(\"Downloading %s..\" % MODEL)\n    p = subprocess.run(['wget', '--show-progress', '--progress=bar:force', '-O', DOWNLOAD_PATH, URL])\n\n    print(\"Unpacking..\")\n    p = subprocess.run(['tar', 'zxvf', DOWNLOAD_PATH, '-C', DATA_DIR])\n    p = subprocess.run(['rm', DOWNLOAD_PATH])\n\n    print(\"Checking..\")\n    pbfile = os.path.join(MODEL_DIR, 'frozen_inference_graph.pb')\n    reconstruct(pbfile)","2b794d2f":"if os.path.exists(MODEL_DIR):\n    subprocess.run(['rm', '-r', MODEL_DIR])\n    subprocess.run(['mkdir', MODEL_DIR])\ndownload()","a8ae3a22":"PB_PATH = \".\/nn-models\/ssd_mobilenet_v2_coco_2018_03_29\/frozen_inference_graph.pb\"\nLABEL_PATH = '.\/models\/research\/object_detection\/data\/mscoco_label_map.pbtxt'\nNCLASSES = 60","1591acaf":"def image2np(image):\n    (w, h) = image.size\n    return np.array(image.getdata()).reshape((h, w, 3)).astype(np.uint8)\n\ndef image2tensor(image):\n    npim = image2np(image)\n    return np.expand_dims(npim, axis=0)\n\n%matplotlib inline\ndef detect(detection_graph, test_image_path):\n    with detection_graph.as_default():\n        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.01)\n        with tf.compat.v1.Session(graph=detection_graph,config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)) as sess:\n            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n\n            image = Image.open(test_image_path)\n            (boxes, scores, classes, num) = sess.run(\n                [detection_boxes, detection_scores, detection_classes, num_detections],\n                feed_dict={image_tensor: image2tensor(image)}\n            )\n\n            npim = image2np(image)\n            vis_util.visualize_boxes_and_labels_on_image_array(\n                npim,\n                np.squeeze(boxes),\n                np.squeeze(classes).astype(np.int32),\n                np.squeeze(scores),\n                category_index,\n                use_normalized_coordinates=True,\n                line_thickness=15)\n            plt.figure(figsize=(12, 8))\n            plt.imshow(npim)\n            plt.show()","72320820":"detection_graph = reconstruct(PB_PATH)","de39baf3":"label_map = label_map_util.load_labelmap(LABEL_PATH)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NCLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)","2ce0943f":"detect(detection_graph, '.\/models\/research\/object_detection\/test_images\/image2.jpg')","d21374c5":"TACO_DIR = '.\/data\/garbagedetection\/TACO'\nDATA_DIR = '\/kaggle\/input\/tacotrashdataset\/data'\nIMAGES_SUB_DIR = 'images'\nIMAGES_DIR = os.path.join(TACO_DIR, IMAGES_SUB_DIR)\nANNOTATIONS_FILE = os.path.join(DATA_DIR, 'annotations.json')\n\nTRAIN_PROP = .80\nSEED = 123","e706f829":"if not os.path.exists(IMAGES_DIR):\n    subprocess.run(['mkdir', '-p', IMAGES_DIR])","7850fabb":"with open(ANNOTATIONS_FILE) as json_file:\n    data = json.load(json_file)\n\nimages = data['images']\ncategories = data['categories']\nannotations = data['annotations']\n\nimages_annotations = []\nfor idx, image in enumerate(images):\n    image_id = int(image['id'])\n    random_number = idx\n    file_name = image['file_name']\n\n    # rename files to unique numbers\n    new_file_name = '%s.jpg' % str(random_number)\n    file_location = '%s\/%s' % (DATA_DIR, file_name)\n    new_file_location = '%s\/%s' % (IMAGES_DIR, new_file_name)\n    if os.path.isfile(file_location):\n        # print('renamed: %s to %s' % (file_location, new_file_location))\n        shutil.copy(file_location, new_file_location)\n    image['file_name'] = new_file_name\n    image['folder'] = DATA_DIR\n\n    # get annotations for the image\n    _annotations = [a for a in annotations if int(a['image_id']) == image_id]\n\n    # something wrong with y coordinates in data\n    for a in _annotations:\n        (x,y,w,h) = a['bbox']\n        a['bbox'][1] = image['height'] - y - h\n\n    images_annotations.append((image, _annotations))","76f65bac":"np.random.seed(SEED)\n\nimages_annotations_idx = range(0,len(images_annotations))\n\nimages_annotations_train_idx = np.random.choice(\n    len(images_annotations),\n    size=int(len(images_annotations)*TRAIN_PROP),\n    replace=False\n)\nimages_annotations_train = [images_annotations[i] for i in images_annotations_train_idx]\n\nimages_annotations_val_idx = np.random.choice(\n    list(set(images_annotations_idx)-set(images_annotations_train_idx)),\n    size=int(len(images_annotations_idx)*(1-TRAIN_PROP)\/2),\n    replace=False\n)\nimages_annotations_val = [images_annotations[i] for i in images_annotations_val_idx]\n\nimages_annotations_test_idx = list(set(images_annotations_idx)-set(images_annotations_train_idx)-set(images_annotations_val_idx))\nimages_annotations_test = [images_annotations[i] for i in images_annotations_test_idx]\n\nprint(\n'''\n# TRAIN IMAGES: %d\n# VALIDATION IMAGES: %d\n# TEST IMAGES: %d\n''' % (len(images_annotations_train), len(images_annotations_val), len(images_annotations_test))\n)","a89a1138":"LABEL_PATH = os.path.join(TACO_DIR, 'labelmap.pbtxt')\n\nif not os.path.exists(LABEL_PATH):\n    print('Building label map from examples')\n\n    from object_detection.protos import string_int_label_map_pb2\n    from google.protobuf import text_format\n\n    labelmap = string_int_label_map_pb2.StringIntLabelMap()\n    for category in categories:\n        item = labelmap.item.add()\n        # label map id 0 is reserved for the background label\n        item.id = int(category['id'])+1\n        item.name = category['name']\n\n    with open(LABEL_PATH, 'w') as f:\n        f.write(text_format.MessageToString(labelmap))\n\n    print('Label map witten to labelmap.pbtxt')\nelse:\n    print('Reusing existing labelmap.pbtxt')\n\nwith open(LABEL_PATH, 'r') as f:\n    pprint.pprint(f.readlines())","e9527956":"label_map = label_map_util.load_labelmap(LABEL_PATH)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NCLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)","7d775c8d":"def build_tfrecords(dataset, output_path, images_annotations, category_index):\n    writer = tf.compat.v1.python_io.TFRecordWriter(output_path)\n    label_map_dict = label_map_util.get_label_map_dict(LABEL_PATH)\n\n    print(\"Building TFRecord files for dataset: %s\" % dataset)\n\n    for idx, (image, _annotations) in enumerate(images_annotations):\n        if idx % 100 == 0:\n            print('%d of %d annotations' % (idx, len(images_annotations)))\n\n        _, tf_example, num_annotations_skipped = create_tf_example(\n            image=image,\n            annotations_list=_annotations,\n            image_dir=IMAGES_DIR,\n            category_index=category_index,\n            include_masks=False\n        )\n\n        writer.write(tf_example.SerializeToString())\n\n    writer.close()\n    print(\"Done!\")","c903f2d9":"# need a category_index here 0 based for making tf-records\n_category_index = label_map_util.create_category_index(data['categories'])\n\ndatasets = [('train', images_annotations_train), ('test', images_annotations_test), ('val', images_annotations_val)]\nfor dataset,images_annotations in datasets:\n    output_path = os.path.join(TACO_DIR, '%s.record' % dataset)\n    build_tfrecords(dataset, output_path, images_annotations, _category_index)","55bc658a":"BATCH_SIZE = 12 # 24\nBATCH_NMS_SCORE_THRESHOLD = .1\nTENSORBOARD_NUM_IMAGES = 20","6e6f6ce8":"SRC_CONFIG_TEMPLATE_PATH = '.\/nn-models\/ssd_mobilenet_v2_coco_2018_03_29\/pipeline.config'\nSRC_CHECKPOINT_PATH =  '.\/nn-models\/ssd_mobilenet_v2_coco_2018_03_29\/model.ckpt'\n\nMODEL_DIR = '.\/nn-models\/garbagedetection\/ssd_mobilenet_v2\/'\nDATA_DIR = '.\/data\/garbagedetection\/TACO\/data\/'\n\nCHECKPOINT_PATH_HOST = os.path.join(MODEL_DIR, 'model.ckpt')\nLABEL_MAP_PATH_HOST = os.path.join(TACO_DIR, 'labelmap.pbtxt')\nTRAIN_RECORDS_PATH_HOST = os.path.join(TACO_DIR, 'train.record')\nVAL_RECORDS_PATH_HOST = os.path.join(TACO_DIR, 'val.record')","8787df39":"label_map_dict = label_map_util.get_label_map_dict(os.path.join(TACO_DIR, 'labelmap.pbtxt'))\nNUM_CLASSES = len(label_map_dict.keys())","67f3d46d":"print('''\nConfig parameters:\n\nCHECKPOINT_PATH_HOST = %s\nLABEL_MAP_PATH_HOST = %s\nTRAIN_RECORDS_PATH_HOST = %s\nVAL_RECORDS_PATH_HOST = %s\nBATCH_SIZE = %d\nNUM_CLASSES = %d\nBATCH_NMS_SCORE_THRESHOLD = %f\nTENSORBOARD_NUM_IMAGES = %d\n''' % (\n    CHECKPOINT_PATH_HOST, \n    LABEL_MAP_PATH_HOST,\n    TRAIN_RECORDS_PATH_HOST,\n    VAL_RECORDS_PATH_HOST,\n    BATCH_SIZE,\n    NUM_CLASSES,\n    BATCH_NMS_SCORE_THRESHOLD,\n    TENSORBOARD_NUM_IMAGES\n))","58f4d563":"%%bash\necho \"\ndiff --git a\/models\/ssd_mobilenet_v2_coco_2018_03_29\/pipeline.config b\/pipeline.config\nindex 1853c65..0b459dd 100755\n--- a\/models\/ssd_mobilenet_v2_coco_2018_03_29\/pipeline.config\n+++ b\/pipeline.config\n@@ -32,7 +32,6 @@ model {\n           train: true\n         }\n       }\n-      batch_norm_trainable: true\n       use_depthwise: true\n     }\n     box_coder {\n\" > ssd_mobilenet_v2_coco_2018_03_29_pipeline.config.patch","ab4d0352":"! patch -N '.\/nn-models\/ssd_mobilenet_v2_coco_2018_03_29\/pipeline.config' < .\/ssd_mobilenet_v2_coco_2018_03_29_pipeline.config.patch","a054a113":"pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\nwith tf.compat.v2.io.gfile.GFile(SRC_CONFIG_TEMPLATE_PATH, \"r\") as f:\n    proto_str = f.read()\n    text_format.Merge(proto_str, pipeline_config)","9cb80923":"pipeline_config.model.ssd.num_classes = NUM_CLASSES\npipeline_config.train_config.batch_size = BATCH_SIZE\npipeline_config.train_config.fine_tune_checkpoint = CHECKPOINT_PATH_HOST\npipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = TRAIN_RECORDS_PATH_HOST\npipeline_config.train_input_reader.label_map_path = LABEL_MAP_PATH_HOST\npipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = VAL_RECORDS_PATH_HOST\npipeline_config.eval_input_reader[0].label_map_path = LABEL_MAP_PATH_HOST\npipeline_config.model.ssd.post_processing.batch_non_max_suppression.score_threshold = BATCH_NMS_SCORE_THRESHOLD\npipeline_config.eval_config.num_visualizations = TENSORBOARD_NUM_IMAGES","7ac14b2b":"if not os.path.exists(MODEL_DIR):\n    subprocess.run(['mkdir', '-p', MODEL_DIR])\n\nconfig_text = text_format.MessageToString(pipeline_config)\nwith tf.compat.v2.io.gfile.GFile(os.path.join(MODEL_DIR, 'pipeline.config'), \"wb\") as f:\n    f.write(config_text)","a5e38b8f":"! cp -r $SRC_CHECKPOINT_PATH\\.* $MODEL_DIR","be061715":"MODEL_ROOT_DIR = '.\/nn-models\/garbagedetection\/ssd_mobilenet_v2'\nCONFIG_PATH = os.path.join(MODEL_ROOT_DIR, 'pipeline.config')\nTRAINING_STEPS = 10\nEVAL_STEPS = 10","fe1d9a63":"! python3 .\/models\/research\/object_detection\/model_main.py \\\n    --pipeline_config_path=$CONFIG_PATH \\\n    --model_dir=$MODEL_ROOT_DIR \\\n    --alsologtostderr \\\n    --num_train_steps=$TRAINING_STEPS \\\n    --num_eval_steps=$EVAL_STEPS","41314650":"! python3 .\/models\/research\/object_detection\/export_inference_graph.py --input_type=image_tensor --pipeline_config_path=$MODEL_ROOT_DIR\/pipeline.config --trained_checkpoint_prefix=$MODEL_ROOT_DIR\/model.ckpt-$TRAINING_STEPS --output_directory=$MODEL_ROOT_DIR","9dc611fb":"trained_detection_graph = reconstruct('.\/nn-models\/garbagedetection\/ssd_mobilenet_v2\/frozen_inference_graph.pb')","d69fcbad":"detect(trained_detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_1\/000000.jpg')","43855cad":"trained_detection_graph = reconstruct('\/kaggle\/input\/trained-models-taco-trash-annotations-in-context\/ssd_mobilenet_v2_taco_2018_03_29.pb')","cdb91ff4":"detect(trained_detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_1\/000000.jpg')","eb0fd49f":"detect(trained_detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_2\/000000.JPG')","ef560ee7":"detect(trained_detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_3\/IMG_4852.JPG')","90fca6f4":"detect(trained_detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_4\/000000.JPG')","4c63386b":"detect(trained_detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_5\/000000.JPG')","8cf1d9c5":"detect(trained_detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_6\/000000.JPG')","aaf16716":"! rm -rf .\/models && rm -rf .\/data","53df38ff":"*Note: Below, we patch `ssd_mobilenet_v2_coco_2018_03_29\/pipeline.config\/pipeline.config` since it includes `batch_norm_trainable`, which was removed from `pipeline_pb2` proto (see [here](https:\/\/stackoverflow.com\/questions\/49880939\/tf-object-detection-api-detection-model-retraining-object-detection-protos-ssd)). Alternatively, `\/app\/models\/research\/object_detection\/samples\/configs\/ssd_mobilenet_v2_coco.config` can be used. However, in this version the kernel size of the convolutional_box_predictor is set to 1 instead of 3, which leads to omission of checkpoint loading for this layer*","d438e2cf":"## <center style=\"background-color: #6dc8b5; width:30%;\">Contents<\/center>\n* [Install TensorFlow Components](#tf_components)\n* [Download Model](#download_model)\n* [Reconstruct Model](#reconstruct_model)\n* [Preprocess Data](#preprocess_data)\n* [Construct Pipeline](#construct_pipeline)\n* [Run Pipeline](#run_pipeline)\n* [Export Model](#export_model)\n* [Reconstruct Trained Model](#reconstruct_trained_model)\n* [Cleanup](#cleanup)","39073294":"This section shows how to download a [frozen Tensorflow graph](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/python\/tools\/freeze_graph.py) from the [Tensorflow detection model zoo](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/g3doc\/detection_model_zoo.md).","3129711d":"> It's also possible to convert this trained fronzen graph into uff format and from uff format to TensorRT engine. This engine can then be used in NVIDIA DeepStream to produce realtime trash detection as shown here: https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:6695264486607130624\/. Feel free to ask me about the converters between the formats.","fd12ecd8":"<a class=\"anchor\" id=\"reconstruct_trained_model\"><\/a>\n# Reconstruct Trained Model","c308de43":"<a class=\"anchor\" id=\"tf_components\"><\/a>\n# Install TensorFlow Components","eb8a7f60":"Following image is done with the reconstructed model of 10 training steps to show it reconstructed as a working frozen graph.","735352e3":"# Training SSD MobileNet v2 with TACO dataset","0ea5c27f":"<a class=\"anchor\" id=\"preprocess_data\"><\/a>\n# Preprocess Data","aa4f3d06":"<a class=\"anchor\" id=\"run_pipeline\"><\/a>\n# Run Pipeline","55221299":"<a class=\"anchor\" id=\"download_model\"><\/a>\n# Download Model","6b0c4a08":"> This notebook will demonstrate training an SSD MobileNet v2 with the TACO (Trash Annotations in Context) (http:\/\/tacodataset.org\/) dataset with TensorFlow. I did this a while ago in TensorFlow 1.14. I have not been able to make this work on GPU in this notebook unfortunately, if you can get this running on GPU as is, please let me know.","b8e953c6":"Following images are done with the already trained model of 100000 training steps.","c73b2f71":"<a class=\"anchor\" id=\"export_model\"><\/a>\n# Export Model","907643e6":"<a class=\"anchor\" id=\"reconstruct_model\"><\/a>\n# Reconstruct Model","305b70a1":"This section shows how to reconstruct a Tensorflow model object from a [frozen Tensorflow graph](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/python\/tools\/freeze_graph.py) file.","0d9f6185":"> I trained the models on Google Cloud with several GPU's for 100000 training steps and included the .pb, .uff and .engine file as a dataset. In this notebook I only did 10 training steps for demonstration purposes.","d63c3d5b":"<a class=\"anchor\" id=\"construct_pipeline\"><\/a>\n# Construct Pipeline","890408f7":"<a class=\"anchor\" id=\"cleanup\"><\/a>\n# Cleanup"}}