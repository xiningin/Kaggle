{"cell_type":{"02055bcf":"code","2b88385a":"code","57c2aae3":"code","0cc9ed17":"code","f4d3b0db":"code","6966d0f9":"code","fcdc5658":"code","f4df055e":"code","ca5996be":"code","e84b14d0":"code","c1a2ac93":"code","9d459af7":"code","be8d1cea":"code","5ab74f1d":"code","b9300442":"code","78290021":"code","22675be2":"code","012a7bd8":"code","99dd1504":"code","3e581f15":"code","7e4bed68":"code","c8b875e7":"code","74d40b83":"code","a20b47a2":"markdown","a0a0129b":"markdown","ad68a91e":"markdown","a359dd18":"markdown","66fbf776":"markdown","d5b38354":"markdown","ebe00620":"markdown","a50fb152":"markdown","96276f7f":"markdown","e08dbab5":"markdown","a542e8de":"markdown","cc187de1":"markdown","e4214349":"markdown"},"source":{"02055bcf":"ls","2b88385a":"import os, sys, gc\nimport numpy as np\nimport pandas as pd\nimport random\nimport copy\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision import *\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom random import shuffle \nfrom shutil import copyfile\n%matplotlib inline","57c2aae3":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(21)","0cc9ed17":"# Check if pytorch is imported and if GPU is enabled\nprint(torch.__version__)\nprint(torch.cuda.is_available())","f4d3b0db":"# setup kaggle, so that you can get the dataset directly \n!pip install -q kaggle\n!mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\/ # Make sure you have your kaggle.json file in the notebook directory\n\n# Download dataset from kaggle\n!kaggle competitions download -c ai6-dl-cohort-6-challenge","6966d0f9":"# !wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/80.0.3987.163 Safari\/537.36\" --header=\"Accept: text\/html,application\/xhtml+xml,application\/xml;q=0.9,image\/webp,image\/apng,*\/*;q=0.8,application\/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https:\/\/www.kaggle.com\/\" --header=\"Cookie: _ga=GA1.3.537785780.1578499616\" --header=\"Connection: keep-alive\" \"https:\/\/storage.googleapis.com\/kaggle-competitions-data\/kaggle-v2\/20044\/1102589\/bundle\/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1586856675&Signature=ljuRllMis76P8oRJ5sbSBoQq5NcKbuTYMwBzS9zQ0El5QBwG1oqVrfOUHiJ0NhNd0qBbgpd%2B8FEWRfn4qWtmQV%2FUmkisv2vichGPef%2FsI3SJTvmJMGmBC3sfi4r4WXb3NBYsWVay1%2FPEUPqijQjh4epycA6zTNyP6gdKh11RLAHyVkXQMkg7vTn4SdPiNGtxzfN34Sr2YgFep8kGKY77sG5tZ4dhUOBKtd2cdwF8nJwRQIOK7Z2EfSaL2PQvnt4AqoV8uPFqTipEIr6e%2BOrwOTq2GDEVzKXYNVxYVm5pss%2BtFO8FIpfzI9Zy4Fms0Ym20T6BbQQz%2FnxrahSNq6K0pA%3D%3D&response-content-disposition=attachment%3B+filename%3Dai6-deep-learning-challenge.zip\" -c -O 'ai6-deep-learning-challenge.zip'","fcdc5658":"# !unzip ai6-deep-learning-challenge.zip","f4df055e":"import json\n\nwith open('flower_data\/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)\nprint(cat_to_name)","ca5996be":"# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 16\n# percentage of training set to use as validation\nvalid_size = 0.2\n# specify data directory\ntrain = \"flower_data\/train\/\"","e84b14d0":"from torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n# convert data to a normalized torch.FloatTensor\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.ColorJitter(),\n    transforms.RandomCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])])\n\n# choose the training datasets\ntrain_data = datasets.ImageFolder(train, transform=transform)\n\n# obtain training indices that will be used for validation\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=64, \n    sampler=valid_sampler, num_workers=num_workers)","c1a2ac93":"samples, labels = iter(train_loader).next()\nplt.figure(figsize=(16,24))\ngrid_imgs = torchvision.utils.make_grid(samples[:24])\nnp_grid_imgs = grid_imgs.numpy()\n# in tensor, image is (batch, width, height), so you have to transpose it to (width, height, batch) in numpy to show it.\nplt.imshow(np.transpose(np_grid_imgs, (1,2,0)))","9d459af7":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), \"models\/\"+f\"bestmodel.pt\")\n        self.val_loss_min = val_loss","be8d1cea":"# Load a pretrained model\nmodel = models.resnet50(pretrained=False)\nmodel.fc # Check resnet's fully connected layer","5ab74f1d":"model = models.resnet50(pretrained=True)\n\n# Freeze parameters so we don't backprop through them\n# for param in model.parameters():\n#     param.requires_grad = False\n    \n# Get model Output Size = Number of Categories\noutput_size = len(cat_to_name)\n\n# Input size from current classifier\ninput_size = model.fc.in_features\n\nclassifier = nn.Sequential(nn.Linear(input_size, output_size)\n                          )\n\nmodel.fc = classifier\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\nprint(model)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, amsgrad=True)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.3, verbose=True)\nearly_stopping = EarlyStopping(patience=7, verbose=True)\n\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)","b9300442":"directory = 'models\/'\nepochs = 10\ntrain_loss_list, valid_loss_list = [], []\nvalid_acc_list = []\n\nfor epoch in range(epochs):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    #### TRAIN\n    model.train()\n    train_loss = 0\n    train_counter = 0\n    for bi, (samples, labels) in tqdm(enumerate(train_loader), total=int(len(train_data)\/train_loader.batch_size)):\n        train_counter += 1\n        samples, labels = samples.to(device), labels.to(device)\n        optimizer.zero_grad()\n        output = model(samples)\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n      \n    train_loss = train_loss\/train_counter\n    train_loss_list.append(train_loss)\n\n    #### VALID\n    valid_loss = 0\n    with torch.no_grad():\n        model.eval()\n        total_label, correct = 0, 0\n        samples, labels = iter(valid_loader).next()\n        samples, labels = samples.to(device), labels.to(device)\n        output = model(samples)\n        loss = criterion(output, labels)\n        valid_loss = loss.item()\n        pred = torch.argmax(output, dim=1)\n        total_label = labels.size(0)\n        correct = pred.eq(labels).sum().item()\n\n    valid_acc = (100 * correct) \/\/ total_label\n    valid_loss_list.append(valid_loss)\n    valid_acc_list.append(valid_acc)\n\n    print('[Epoch {}\/{}] -> Train Loss: {:.4f} -> Valid Loss: {:.4f}, Valid Accuracy: {:.3f}%'.format(epoch+1, epochs, train_loss, valid_loss, valid_acc))\n\n    # Early Stopping\n    early_stopping(valid_loss, model)  \n    if early_stopping.early_stop:\n        print(\"Early stopping at {} epoch\".format(epoch))\n        break\n\n    scheduler.step(valid_loss)","78290021":"plt.plot(train_loss_list, label = 'Training loss')\nplt.plot(valid_loss_list, label = 'Validation loss')\nplt.legend(frameon = False)\nplt.title('Training Loss vs Validation Loss')\nplt.show()","22675be2":"def load_checkpoint(model, file=\"models\/\"+f\"bestmodel.pt\"):\n    state_dict = torch.load(file)\n    model.load_state_dict(state_dict)\n    # model.load_state_dict(state_dict, strict=False)\n    return model\n\nchkp_model = load_checkpoint(model)\nchkp_model = chkp_model.to(device)","012a7bd8":"with torch.no_grad():\n    valid_loss = 0.0\n    chkp_model.eval()\n    total_label, correct = 0, 0\n    for samples, labels in valid_loader:\n        samples, labels = samples.to(device), labels.to(device)\n        output = chkp_model(samples)\n        loss = criterion(output, labels)\n        valid_loss += loss.item()*samples.size(0)\n        _, predicted = torch.max(output.data, 1)\n        total_label += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    valid_loss = valid_loss\/len(valid_loader.dataset)\n    valid_acc = (100 * correct) \/\/ total_label\n\nprint('Valid Loss: {:.4f}, Valid Accuracy: {:.3f}%'.format(valid_loss, valid_acc))","99dd1504":"class_to_idx = train_data.class_to_idx\nidx_to_class = {class_to_idx[k]: k for k in class_to_idx}","3e581f15":"samples, _ = iter(valid_loader).next()\nsamples = samples.to(device)\nfig = plt.figure(figsize=(24, 16))\nfig.tight_layout()\noutput = chkp_model(samples[:24])\npred = torch.argmax(output, dim=1)\npred = [p.item() for p in pred]\n\nfor num, sample in enumerate(samples[:24]):\n    plt.subplot(4,6,num+1)\n    plt.title(cat_to_name[idx_to_class[pred[num]]])\n    plt.axis('off')\n    sample = sample.cpu().numpy()\n    plt.imshow(np.transpose(sample, (1,2,0)))","7e4bed68":"class loadTest(Dataset):\n    def __init__(self, dir, df, file_class, transform = None):\n        self.file_list = [x for x in df[file_class]]\n        self.dir = dir\n        self.transform = transform\n            \n    def __len__(self):\n        return len(self.file_list)\n    \n    def __getitem__(self, idx):\n        img = Image.open(os.path.join(self.dir, self.file_list[idx]))\n        if self.transform:\n            img = self.transform(img)\n            img = img.numpy()\n            return img.astype('float32'), self.file_list[idx]","c8b875e7":"test_dir = \"flower_data\/test\"\ndf_test = pd.read_csv('flower_data\/Sample_Sub.csv')\ntest_transform = transforms.Compose([transforms.Resize(256),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\ntestset = loadTest(test_dir, df_test, \"id\", transform = test_transform)\ntestloader = DataLoader(testset, batch_size = 32, shuffle=False)","74d40b83":"chkp_model.eval()\nfn_list = []\npred_list = []\nfor x, fn in testloader:\n    with torch.no_grad():\n        x = x.to(device)\n        output = chkp_model(x)\n        pred = torch.argmax(output, dim=1)\n        fn_list += [n for n in fn]\n        pred_list += [idx_to_class[p.item()] for p in pred]\n\nsubmission = pd.DataFrame({\"id\":fn_list, \"class\":pred_list})\nsubmission.to_csv('submission.csv', index=False)","a20b47a2":"## Load Best Model","a0a0129b":"## Get Data","ad68a91e":"## Label mapping","a359dd18":"## Load Train Data","66fbf776":"## Model Building","d5b38354":"## Testing","ebe00620":"## View Result","a50fb152":"### Alternatively","96276f7f":"## Training","e08dbab5":"## Load Test Data","a542e8de":"## Import Libraries","cc187de1":"## Confirm Validation Accuracy and Error","e4214349":"# Flower Species Classifier"}}