{"cell_type":{"34b9dcfe":"code","48f641c5":"code","bac0a1c0":"code","a81efea8":"code","78989495":"code","957b7895":"code","9e0638cb":"code","744f3edb":"code","1c086482":"code","99a5b010":"code","b5e4faac":"code","e3b2013b":"code","26317d0c":"code","c5daefb7":"code","1948e9bf":"code","ab67683c":"code","39f8d1c0":"code","817d21ef":"code","758e9684":"code","d3d8c1e2":"code","5c4d8d38":"markdown","5c1875d5":"markdown","69c81c39":"markdown"},"source":{"34b9dcfe":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","48f641c5":"import sys\nimport gc\nimport random\npd.options.display.max_columns = None\npd.options.mode.chained_assignment = None\npd.options.display.float_format\n\nfrom sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nsns.set_style( 'white' )\npylab.rcParams[ 'figure.figsize' ] = 8 , 6","bac0a1c0":"def load_properties_data(file_name):\n\n    # Helper function for parsing the flag attributes\n    def convert_true_to_float(df, col):\n        df.loc[df[col] == 'true', col] = '1'\n        df.loc[df[col] == 'Y', col] = '1'\n        df[col] = df[col].astype(float)\n\n    prop = pd.read_csv(file_name, dtype={\n        'propertycountylandusecode': str,\n        'hashottuborspa': str,\n        'propertyzoningdesc': str,\n        'fireplaceflag': str,\n        'taxdelinquencyflag': str\n    })\n\n    for col in ['hashottuborspa', 'fireplaceflag', 'taxdelinquencyflag']:\n        convert_true_to_float(prop, col)\n\n    return prop\n\ntrain_2016 = pd.read_csv('\/kaggle\/input\/zillow-prize-1\/train_2016_v2.csv' , parse_dates=[\"transactiondate\"])\ntrain_2017 = pd.read_csv('\/kaggle\/input\/zillow-prize-1\/train_2017.csv' , parse_dates=[\"transactiondate\"])\nprop_2016 = load_properties_data('\/kaggle\/input\/zillow-prize-1\/properties_2016.csv')\nprop_2017 = load_properties_data('\/kaggle\/input\/zillow-prize-1\/properties_2017.csv')\ntest = pd.read_csv('\/kaggle\/input\/zillow-prize-1\/sample_submission.csv')\nprint(\"Training 2016 transaction: \" + str(train_2016.shape))\nprint(\"Training 2017 transaction: \" + str(train_2017.shape))\nprint(\"Number of Property 2016: \" + str(prop_2016.shape))\nprint(\"Number of Property 2017: \" + str(prop_2017.shape))\nprint(\"Sample Size: \" + str(test.shape))","a81efea8":"# Basic feature engineering + Drop duplicate columns\nfor prop in [prop_2016, prop_2017]:\n    prop['avg_garage_size'] = prop['garagetotalsqft'] \/ prop['garagecarcnt']\n    \n    prop['property_tax_per_sqft'] = prop['taxamount'] \/ prop['calculatedfinishedsquarefeet']\n    \n    # Rotated Coordinates\n    prop['location_1'] = prop['latitude'] + prop['longitude']\n    prop['location_2'] = prop['latitude'] - prop['longitude']\n    prop['location_3'] = prop['latitude'] + 0.5 * prop['longitude']\n    prop['location_4'] = prop['latitude'] - 0.5 * prop['longitude']\n    \n    # finished_area_sqft and 'total_area' cover only a subset of 'calculatedfinishedsquarefeet', when both fields are not null, the values are always the same \n    # So we can probably drop 'finished_area_sqft' and 'total_area' since they are redundant\n    # If there're some patterns in when the values are missing, we can add two isMissing binary features\n    \n    prop['missing_finished_area'] = prop['finishedsquarefeet12'].isnull().astype(np.float32)\n    prop['missing_total_area'] = prop['finishedsquarefeet15'].isnull().astype(np.float32)\n    prop.drop(['finishedsquarefeet12', 'finishedsquarefeet15'], axis=1, inplace=True)\n    \n    # Same as above, 'bathroomcnt' covers everything that 'bathroom_cnt_calc' has\n    # So we can safely drop 'bathroom_cnt_calc' and optionally add an isMissing feature\n    prop['missing_bathroom_cnt_calc'] = prop['calculatedbathnbr'].isnull().astype(np.float32)\n    prop.drop(['calculatedbathnbr'], axis=1, inplace=True)\n    \n    # 'room_cnt' has many zero or missing values\n    # On the other hand, 'bathroom_cnt' and 'bedroom_cnt' have few zero or missing values\n    # Add an derived room_cnt feature by adding bathroom_cnt and bedroom_cnt\n    prop['derived_room_cnt'] = prop['bedroomcnt'] + prop['bathroomcnt']\n    \n    # Average area in sqft per room\n    mask = (prop.roomcnt >= 1)  # avoid dividing by zero\n    prop.loc[mask, 'avg_area_per_room'] = prop.loc[mask, 'calculatedfinishedsquarefeet'] \/ prop.loc[mask, 'roomcnt']\n    \n    # Use the derived room_cnt to calculate the avg area again\n    mask = (prop.derived_room_cnt >= 1)\n    prop.loc[mask,'derived_avg_area_per_room'] = prop.loc[mask,'calculatedfinishedsquarefeet'] \/ prop.loc[mask,'derived_room_cnt']\n    \n\nprop_2017.head()","78989495":"train_2016 = train_2016.merge(prop_2016, how='left', on='parcelid')\ntrain_2017 = train_2017.merge(prop_2017, how='left', on='parcelid')\ntrain = pd.concat([train_2016, train_2017], axis=0, ignore_index=True)","957b7895":"print(\"\\nCombined training set size: {}\".format(len(train)))\ntrain.head()","9e0638cb":"from sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder()\n\nfor c in train.columns:\n    train[c]= train[c].fillna(0)\n    if train[c].dtype == 'object':\n        lbl.fit(list(train[c].values))\n        train[c] = lbl.transform(list(train[c].values))","744f3edb":"def add_simple_datetime_features(df):\n    dt = pd.to_datetime(df.transactiondate).dt\n    df['year'] = (dt.year - 2016).astype(int)\n    df['month'] = (dt.month).astype(int)\n    df['quarter'] = (dt.quarter).astype(int)\n    df.drop(['transactiondate'], axis=1, inplace=True)\nadd_simple_datetime_features(train)\ntrain.head()","1c086482":"\"\"\"\n    Drop id and label columns + Feature selection for Cast Boot\n\"\"\"        \ndef drop_features(features):\n    # id and label (not features)\n    unused_feature_list = ['parcelid', 'logerror']\n\n    # too many missing (LightGBM is robust against bad\/unrelated features, so this step might not be needed)\n    missing_list = ['buildingclasstypeid', 'architecturalstyletypeid', 'storytypeid', 'finishedsquarefeet13', 'basementsqft', 'yardbuildingsqft26']\n    unused_feature_list += missing_list\n\n    # not useful\n    bad_feature_list = ['fireplaceflag', 'decktypeid', 'pooltypeid10', 'typeconstructiontypeid', 'regionidcounty', 'fips']\n    unused_feature_list += bad_feature_list\n\n    # really hurts performance\n    unused_feature_list += ['propertycountylandusecode','propertyzoningdesc', 'taxdelinquencyflag']\n\n    return features.drop(unused_feature_list, axis=1, errors='ignore')","99a5b010":"castboot_features = drop_features(train)\nprint(\"Number of features for CastBoot: {}\".format(len(castboot_features.columns)))\ncastboot_features.head(5)","b5e4faac":"# Prepare training and cross-validation data\ncastboot_label = train.logerror.astype(np.float32)\nprint(castboot_label.head())\n\n# Transform to Numpy matrices\nlgb_X = castboot_features.values\nlgb_y = castboot_label.values\n\n# Perform shuffled train\/test split\nnp.random.seed(42)\nrandom.seed(10)\nX_train, X_val, y_train, y_val = train_test_split(lgb_X, lgb_y, test_size=0.2)\n\n# Remove outlier examples from X_train and y_train; Keep them in X_val and y_val for proper cross-validation\noutlier_threshold = 0.4\nmask = (abs(y_train) <= outlier_threshold)\nX_train = X_train[mask, :]\ny_train = y_train[mask]\n\nprint(\"X_train shape: {}\".format(X_train.shape))\nprint(\"y_train shape: {}\".format(y_train.shape))\nprint(\"X_val shape: {}\".format(X_val.shape))\nprint(\"y_val shape: {}\".format(y_val.shape))","e3b2013b":"feature_names = [s for s in castboot_features.columns]\ncategorical_features = ['airconditioningtypeid', 'heatingorsystemtypeid', 'propertylandusetypeid', 'year', 'month', 'quarter']\n\ncategorical_indices = []\nfor i, n in enumerate(castboot_features.columns):\n    if n in categorical_features:\n        categorical_indices.append(i)\nprint(categorical_indices)","26317d0c":"# CatBoost parameters\nparams = {}\nparams['loss_function'] = 'MAE'\nparams['eval_metric'] = 'MAE'\nparams['nan_mode'] = 'Min'  # Method to handle NaN (set NaN to either Min or Max)\nparams['random_seed'] = 0\n\nparams['iterations'] = 1000  # default 1000, use early stopping during training\nparams['learning_rate'] = 0.015  # default 0.03\n\nparams['border_count'] = 254  # default 254 (alias max_bin, suggested to keep at default for best quality)\n\nparams['max_depth'] = 6  # default 6 (must be <= 16, 6 to 10 is recommended)\nparams['random_strength'] = 1  # default 1 (used during splitting to deal with overfitting, try different values)\nparams['l2_leaf_reg'] = 5  # default 3 (used for leaf value calculation, try different values)\nparams['bagging_temperature'] = 1  # default 1 (higher value -> more aggressive bagging, try different values)","c5daefb7":"%%time\nfrom catboost import CatBoostRegressor, Pool\n# Train CatBoost Regressor with cross-validated early-stopping\nval_pool = Pool(X_val, y_val, cat_features=categorical_indices)\n\nnp.random.seed(42)\nrandom.seed(36)\nmodel = CatBoostRegressor(**params)\nmodel.fit(X_train, y_train,\n          cat_features=categorical_indices,\n          use_best_model=True, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n\n# Evaluate model performance\nprint(\"Train score: {}\".format(abs(model.predict(X_train) - y_train).mean() * 100))\nprint(\"Val score: {}\".format(abs(model.predict(X_val) - y_val).mean() * 100))","1948e9bf":"%%time\nfrom sklearn.model_selection import GridSearchCV\nparams = {'depth': [4, 7, 10],\n          'learning_rate' : [0.03, 0.1, 0.15],\n         'l2_leaf_reg': [1,4,9],\n         'iterations': [300, 1000, 1500],\n         'eval_metric' : ['MAE']}\nmodel = CatBoostRegressor()\ngrid = GridSearchCV(estimator= model, param_grid= params, cv= 3, n_jobs=-1)\ngrid.fit(X_train, y_train)\nprint(\"\\n========================================================\")\nprint(\" Results from Grid Search \" )\nprint(\"========================================================\")    \nprint(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\nprint(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\nprint(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)","ab67683c":"# CatBoost feature importance\nfeature_importance = [(feature_names[i], value) for i, value in enumerate(model.get_feature_importance())]\nfeature_importance.sort(key=lambda x: x[1], reverse=True)\nfor k, v in feature_importance[:10]:\n    print(\"{}: {}\".format(k, v))","39f8d1c0":"def transform_test_features(features_2016, features_2017):\n    test_features_2016 = drop_features(features_2016)\n    test_features_2017 = drop_features(features_2017)\n    \n    test_features_2016['year'] = 0\n    test_features_2017['year'] = 1\n    \n    # 11 & 12 lead to unstable results, probably due to the fact that there are few training examples for them\n    test_features_2016['month'] = 10\n    test_features_2017['month'] = 10\n    \n    test_features_2016['quarter'] = 4\n    test_features_2017['quarter'] = 4\n    \n    return test_features_2016, test_features_2017\n\n\"\"\"\n    Helper method that makes predictions on the test set and exports results to csv file\n    'models' is a list of models for ensemble prediction (len=1 means using just a single model)\n\"\"\"\ndef predict_and_export(models, features_2016, features_2017, file_name):\n    # Construct DataFrame for prediction results\n    submission_2016 = pd.DataFrame()\n    submission_2017 = pd.DataFrame()\n    submission_2016['ParcelId'] = features_2016.parcelid\n    submission_2017['ParcelId'] = features_2017.parcelid\n    \n    test_features_2016, test_features_2017 = transform_test_features(features_2016, features_2017)\n    \n    pred_2016, pred_2017 = [], []\n    for i, model in enumerate(models):\n        print(\"Start model {} (2016)\".format(i))\n        pred_2016.append(model.predict(test_features_2016))\n        print(\"Start model {} (2017)\".format(i))\n        pred_2017.append(model.predict(test_features_2017))\n    \n    # Take average across all models\n    mean_pred_2016 = np.mean(pred_2016, axis=0)\n    mean_pred_2017 = np.mean(pred_2017, axis=0)\n    \n    submission_2016['201610'] = [float(format(x, '.4f')) for x in mean_pred_2016]\n    submission_2016['201611'] = submission_2016['201610']\n    submission_2016['201612'] = submission_2016['201610']\n\n    submission_2017['201710'] = [float(format(x, '.4f')) for x in mean_pred_2017]\n    submission_2017['201711'] = submission_2017['201710']\n    submission_2017['201712'] = submission_2017['201710']\n    \n    submission = submission_2016.merge(how='inner', right=submission_2017, on='ParcelId')\n    \n    print(\"Length of submission DataFrame: {}\".format(len(submission)))\n    print(\"Submission header:\")\n    print(submission.head())\n    submission.to_csv(file_name, index=False)\n    return submission, pred_2016, pred_2017 ","817d21ef":"from sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder()\ndef fillnan(train):    \n    for c in train.columns:\n        train[c]= train[c].fillna(0)\n        if train[c].dtype == 'object':\n            lbl.fit(list(train[c].values))\n            train[c] = lbl.transform(list(train[c].values))\n    return train\nprop2016 = fillnan(prop_2016)\nprop2017 = fillnan(prop_2017)\n        \nfile_name = 'final_castboot_single_21092019.csv'\nsubmission, pred_2016, pred_2017 = predict_and_export([model], prop_2016, prop_2017, file_name)","758e9684":"# Remove outliers (if any) from training data\noutlier_threshold = 0.4\nmask = (abs(lgb_y) <= outlier_threshold)\ncatboost_X = lgb_X[mask, :]\ncatboost_y = lgb_y[mask]\nprint(\"catboost_X: {}\".format(catboost_X.shape))\nprint(\"catboost_y: {}\".format(catboost_y.shape))\n\n####################3\nbags = 8\nmodels = []\nparams['iterations'] = 1000\nfor i in range(bags):\n    print(\"Start training model {}\".format(i))\n    params['random_seed'] = i\n    np.random.seed(42)\n    random.seed(36)\n    model = CatBoostRegressor(**params)\n    model.fit(catboost_X, catboost_y, cat_features=categorical_indices, verbose=False)\n    models.append(model)\n    \n# Sanity check (make sure scores on a small portion of the dataset are reasonable)\nfor i, model in enumerate(models):\n    print(\"model {}: {}\".format(i, abs(model.predict(X_val) - y_val).mean() * 100))","d3d8c1e2":"# Make predictions and export results\nlbl = LabelEncoder()\ndef fillnan(train):    \n    for c in train.columns:\n        train[c]= train[c].fillna(0)\n        if train[c].dtype == 'object':\n            lbl.fit(list(train[c].values))\n            train[c] = lbl.transform(list(train[c].values))\n    return train\nprop2016 = fillnan(prop_2016)\nprop2017 = fillnan(prop_2017)\n\nfile_name = 'final_catboost_ensemble_x8_20192209.csv'\nsubmission, pred_2016, pred_2017 = predict_and_export(models, prop_2016, prop_2017, file_name)","5c4d8d38":"**Ensemble Training & Prediction**","5c1875d5":"**Feature Engineering**","69c81c39":"****Data loading and Preprocessing****"}}