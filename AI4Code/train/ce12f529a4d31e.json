{"cell_type":{"8cfe7298":"code","1aea4726":"code","11517e2b":"code","f57ccd88":"code","c07f5e04":"code","c116db47":"code","247e54c7":"code","c089b209":"code","3f027e32":"code","27c20a5e":"code","2317ce5e":"code","9b46209d":"code","d3884a09":"code","bf068e1f":"code","0724a5d4":"code","0a94cd66":"code","b194b0b3":"code","63d3529d":"code","4e5d1f9b":"code","47e68d02":"code","4cb52c48":"code","b381a932":"code","5cc40b12":"markdown","0f07616f":"markdown","abc69a06":"markdown","554f4da3":"markdown","c7ce34db":"markdown","927b9fa9":"markdown","e879e9c3":"markdown","d9245a98":"markdown","52bada59":"markdown","def25aac":"markdown","8fa43205":"markdown","3817b9d2":"markdown","a555e225":"markdown"},"source":{"8cfe7298":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1aea4726":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","11517e2b":"train_df.head()","f57ccd88":"# Describe continuous features\n# >> Lot of skew in fare\n# >> Rest features seems to be fair enough\ntrain_df.describe()","c07f5e04":"# Describe categorical variables\n# >> Cabin has lot of missing values NaN (Only 204 are present)\n# >> Ticket has too many unique values, and no correlation can be found\ntrain_df.describe(include=['O'])","c116db47":"# To print mean survival wrt Pclass by using groupby >> Rate of survival for Pclass 1 > 2 > 3\n'''\nExample:\n    For \n    Pclass as 1, we take mean of all survived 0 or 1 values for Pclass==1 and get answer as 0.6296..\n    Similary for Pclass as 2 and 3.\n'''\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","247e54c7":"# To print mean survival wrt Sex by using groupby >> if Sex is Female then rate of survival is high\ntrain_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","c089b209":"# To print mean survival wrt SibSp (#siblings) by using groupby >> Although this feature has no correlation with survival directly\ntrain_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","3f027e32":"# To print mean survival wrt Parch (#parents) by using groupby >> Although this feature has no correlation with survival directly\ntrain_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","27c20a5e":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Distribution w.r.t Age for survived 0&1\n# >> The distribution is not completely same\n# >> Children are more likely to survive\n# >> Age 80 people have survived\n\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","2317ce5e":"# Dropping Ticket >> No correlation with survival, Cabin >> lot of NaN\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]","9b46209d":"# Creating new 'Title' feature from 'Name' and then dropping 'Name' feature\n\n# Extracting Title from name\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n    \n# Replacing rare Titles by title 'Rare'\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n                         'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n    \n# Dropping 'Name' from dataset\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\n\n# To print mean survival wrt Title by using groupby\n# >> Again here male\/female, age(Master vs Mr) survival rate is reflected\n# >> This feature is also considered\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","d3884a09":"# Replacing NaN by mode (most frequent port, here its 'S')\nfreq_port = train_df.Embarked.dropna().mode()[0]\nprint(\"Frequent port:\", freq_port)\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n\n# To print mean survival wrt Embarked by using groupby >> C has most survival rate\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","bf068e1f":"# Making 'Title' features ordinal by .map()\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n# Making 'Sex' feature numeric by .map()\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)\n\n# Making 'Embarked' feature numeric by .map()\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)","0724a5d4":"guess_ages = np.zeros((2,3))\n\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            # cond1: (dataset['Sex'] == i) : np array with bool values, will be True where dataset['Sex'] is i\n            # cond2: (dataset['Pclass'] == j+i) : np array with bool values, will be True where dataset['Pclass'] is j+1\n            # cond1&cond2: So for given i and j from dataset we select only rows where Sex is i and Pclass is j+1\n            # We drop all NaN to get a guess_df such that median would be a awesome guess for Age\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    # Assigning guessed values to dataset using .loc[] where (age is null) & (dataset['Sex'] is i) & (dataset['Pclass'] is j+1)\n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)","0a94cd66":"# .loc[cond, 'Age'] can be used **to assign a single value** to all the postion in 'Age' series which satifies the given conditon\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","b194b0b3":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\n# Dropping 'Parch', 'SibSp', 'FamilySize'\ntrain_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\n# To print mean survival wrt IsAlone by using groupby >> if person is alone then he\/she has lower chances of survival\nprint(train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n\n\n# ------\n# Creating new feature 'Age*Class'\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass","63d3529d":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True) # using inplace to replace values is current df (assigning is not needed)\n\n# using .qcut to split 'Fare' in 4 'FareBand' parts based on their count, so we can get ranges to fare values\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\nprint('Four FareBands are:')\nprint(train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True))\n\n# .loc[cond, 'Fare'] can be used **to assign a single value** to all the postion in 'Fare' series which satifies the given range conditon\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\n# Dropping 'FareBand'\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]","4e5d1f9b":"# One hot encoding Embarked and Title\n\ndum_Embarked = pd.get_dummies(train_df['Embarked'], drop_first=True, prefix='Embarked')\ndum_Title = pd.get_dummies(train_df['Title'], drop_first=True, prefix='Title')\ntrain_df.drop(['Embarked', 'Title'], axis=1)\ntrain_df = train_df.join(dum_Embarked) # Due to these assignment operartions for loop can't be used\ntrain_df = train_df.join(dum_Title)\n\ndum_Embarked = pd.get_dummies(test_df['Embarked'], drop_first=True, prefix='Embarked')\ndum_Title = pd.get_dummies(test_df['Title'], drop_first=True, prefix='Title')\ntest_df.drop(['Embarked', 'Title'], axis=1)\ntest_df = test_df.join(dum_Embarked)\ntest_df = test_df.join(dum_Title)\n\ncombine = [train_df, test_df]","47e68d02":"from sklearn.metrics import classification_report","4cb52c48":"# Creating Train and Test data\nX_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","b381a932":"# DECISON TREE CLASSIFIER\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecison_tree = DecisionTreeClassifier()\ndecison_tree.fit(X_train, Y_train)\nY_train_pred = decison_tree.predict(X_train)\nY_test_pred_dt = decison_tree.predict(X_test)\nprint('Decison Tree Report:\\n', classification_report(Y_train, Y_train_pred))\n\n# Save submission.csv\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test_df['PassengerId']\nsubmission['Survived'] = Y_test_pred_dt\nsubmission.to_csv('submission_dt.csv', index=False)\n\n\n# ------\n# RANDOM FOREST CLASSIFIER\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_train_pred = random_forest.predict(X_train)\nY_test_pred_rf = random_forest.predict(X_test)\nprint(\"-\"*70)\nprint('Random Forest Report:\\n', classification_report(Y_train, Y_train_pred))\n\n# Save submission.csv\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test_df['PassengerId']\nsubmission['Survived'] = Y_test_pred_rf\nsubmission.to_csv('submission_rf.csv', index=False)\n\n\n# ------\n## XGBOOST CLASSIFIER\nfrom xgboost import XGBClassifier\n\nxg_boost_classifier = XGBClassifier()\nxg_boost_classifier.fit(X_train, Y_train)\nY_train_pred = random_forest.predict(X_train)\nY_test_pred_xgb = random_forest.predict(X_test)\nprint(\"-\"*70)\nprint('Xgboost Report:\\n', classification_report(Y_train, Y_train_pred))\n\n# Save submission.csv\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test_df['PassengerId']\nsubmission['Survived'] = Y_test_pred_xgb\nsubmission.to_csv('submission_xgb.csv', index=False)","5cc40b12":"## Converting Categorical features to numeric values","0f07616f":"## Create new feature IsAlone by combining existing features\n## And creating new Feature Age*Class","abc69a06":"## Handling NaN Age Values\n\n### Here we guess the **6 Ages** for given Pclass(1,2,3) and Sex(0,1) and fill the guessed age in the Age column","554f4da3":"## Describing Features","c7ce34db":"## This is a Practice Kaggle Notebook with several models referring to [this](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions) Notebook\n<!-- ![Titanic](https:\/\/www.pinclipart.com\/picdir\/big\/4-43090_titanic-clipart-clip-art-titanic-ship-for-art.png =250x) -->\n<img src=\"https:\/\/www.pinclipart.com\/picdir\/big\/4-43090_titanic-clipart-clip-art-titanic-ship-for-art.png\" alt=\"drawing\" width=\"400\"\/>\n\n","927b9fa9":"## Finding Categorical Feature Correlations with survival rate","e879e9c3":"## Finding Numerical Feature Correlations with survival rate","d9245a98":"## Assigning ordinal values to Age Bands with gap of 16 with .loc[]","52bada59":"## Handling missing Fare values in test data by median\nMedian is good approximation for continuous feature\n### And creating fare bands","def25aac":"## Data Wrangling based on Observations","8fa43205":"# ML Modelling","3817b9d2":"## Creating new `'Title'` feature. [reference](https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions)","a555e225":"## Handling missing 'Embarked' values by mode\nMode is good guess for categorical features"}}