{"cell_type":{"e74b24ef":"code","f0135050":"code","6cb18174":"code","dbfb0d36":"code","90c6677d":"code","97b59506":"code","2318f20d":"code","80ccabef":"code","65c038bd":"code","5cbde7d6":"code","14977293":"code","9efd84ad":"code","7ccabdfa":"code","92cad233":"code","1b99acba":"code","b884f2ec":"code","5a2246d0":"code","88ed59ce":"code","ce2b667d":"code","b7e7f7b5":"code","fd73f2b0":"code","7fff6af5":"code","eb776c5b":"code","895bae21":"code","3539d5ad":"code","ffb24fec":"code","f50a110f":"code","55ed3d5a":"code","b96ed6fe":"code","7f14093e":"code","f0c3cb38":"code","5dc1338a":"code","6f42bcdb":"code","6d0aee2f":"code","4f8eaa2b":"code","79b1e34b":"code","98dc5077":"code","87ce8dcc":"code","cf478b61":"code","0aab7e41":"code","6b5c0696":"code","45f982ae":"code","089dd357":"code","eb5c5940":"code","4bf75400":"code","025067c0":"code","ac5b5bef":"code","fbb7a3e5":"code","67b73943":"markdown","fce28d8a":"markdown","524aa4ed":"markdown","a8917eff":"markdown","1b5d4e67":"markdown","6edbc178":"markdown","be468398":"markdown","e43de44a":"markdown","e92b5f69":"markdown","24043735":"markdown","9726e05e":"markdown","504d3cbc":"markdown","d0d017f3":"markdown","3c3f39c0":"markdown","798145f0":"markdown","2b00f1aa":"markdown","231a895a":"markdown","6c98b3f6":"markdown","e8731510":"markdown"},"source":{"e74b24ef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0135050":"#importing basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6cb18174":"#import data\ndata = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","dbfb0d36":"data.head(10)","90c6677d":"data.describe()","97b59506":"#checking number of records and features\ndata.shape","2318f20d":"#checking total NaN values in each column\ndata.isnull().sum()","80ccabef":"data['anaemia'].value_counts()","65c038bd":"#value_count_for_respective_columns\nlist = ['diabetes','ejection_fraction','high_blood_pressure','sex','smoking','DEATH_EVENT']\nfor col in list:\n    print(data[col].value_counts())","5cbde7d6":"sns.countplot(x='DEATH_EVENT',hue='diabetes',data=data,palette='RdBu_r')","14977293":"sns.countplot(x=\"ejection_fraction\", hue=\"DEATH_EVENT\", data=data)","9efd84ad":"data['ejection_fraction'].replace(17,25,inplace=True)\ndata['ejection_fraction'].replace(62,25,inplace=True)\ndata['ejection_fraction'].replace(65,14,inplace=True)\ndata['ejection_fraction'].replace(15,14,inplace=True)\ndata['ejection_fraction'].replace(70,14,inplace=True)\nsns.countplot(x=\"ejection_fraction\", hue=\"DEATH_EVENT\", data=data)","7ccabdfa":"sns.countplot(x='DEATH_EVENT',hue=\"high_blood_pressure\",data=data,palette='RdBu_r')","92cad233":"sns.countplot(x='DEATH_EVENT',hue=\"sex\",data=data,palette='RdBu_r')","1b99acba":"sns.countplot(x='DEATH_EVENT',hue=\"smoking\",data=data,palette='RdBu_r')","b884f2ec":"sns.countplot(x='DEATH_EVENT',hue='anaemia',data=data,palette='RdBu_r')","5a2246d0":"sns.FacetGrid(data,hue='DEATH_EVENT',size=5).map(sns.distplot,\"age\").add_legend()","88ed59ce":"sns.FacetGrid(data,hue='DEATH_EVENT',size=5).map(sns.distplot,\"creatinine_phosphokinase\").add_legend()","ce2b667d":"sns.FacetGrid(data,hue='DEATH_EVENT',size=5).map(sns.distplot,\"serum_creatinine\").add_legend()","b7e7f7b5":"sns.FacetGrid(data,hue='DEATH_EVENT',size=5).map(sns.distplot,\"serum_sodium\").add_legend()","fd73f2b0":"#outliers checking and treatment\ndata.boxplot('serum_sodium')","7fff6af5":"data['serum_sodium'].quantile(np.arange(0,1,0.01))","eb776c5b":"data.loc[(data['serum_sodium']<125),'serum_sodium']=125","895bae21":"data.boxplot('serum_sodium')","3539d5ad":"data.boxplot('serum_creatinine')","ffb24fec":"data.boxplot('creatinine_phosphokinase')","f50a110f":"sns.heatmap(data.corr())","55ed3d5a":"X = data.drop(\"DEATH_EVENT\",axis=1)\ny = data[\"DEATH_EVENT\"]\ncnames = [\"time\",\"serum_sodium\",\"serum_creatinine\",\"platelets\",\"creatinine_phosphokinase\",\"age\"]\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nfor col in cnames:\n    X[col] = sc.fit_transform(X[[col]])","b96ed6fe":"X.shape","7f14093e":"#split into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","f0c3cb38":"from  sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(X_train,y_train)\n","5dc1338a":"y_pred=logreg.predict(X_test)\nfrom sklearn.metrics import accuracy_score,f1_score,confusion_matrix,recall_score,precision_score\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred))\nprint('f1 score', f1_score(y_test, y_pred,\n                              ))","6f42bcdb":"sns.heatmap(confusion_matrix(y_test, y_pred),annot=True)","6d0aee2f":"data.DEATH_EVENT.value_counts()","4f8eaa2b":"df_majority = data[data.DEATH_EVENT==0]\ndf_min = data[data.DEATH_EVENT==1]","79b1e34b":"import sklearn.utils as ut\ndf_minority_upsample = ut.resample(df_min,replace=True,n_samples=203,random_state=1)","98dc5077":"print(df_majority.shape)\nprint(df_minority_upsample.shape)","87ce8dcc":"df_upsampled = pd.concat([df_majority,df_minority_upsample])","cf478b61":"print(df_upsampled.DEATH_EVENT.value_counts())","0aab7e41":"X1=df_upsampled.drop(\"DEATH_EVENT\",axis=1)\nY1=df_upsampled[\"DEATH_EVENT\"]","6b5c0696":"cnames = [\"time\",\"serum_sodium\",\"serum_creatinine\",\"platelets\",\"creatinine_phosphokinase\",\"age\"]\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nfor col in cnames:\n    X1[col] = sc.fit_transform(X1[[col]])","45f982ae":"#split into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X1,Y1, test_size=0.2, random_state=0)","089dd357":"#Random Forst Classifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nrf=RandomForestClassifier(n_estimators=100,random_state=0)\nrf.fit(X_train,y_train)","eb5c5940":"y_pred=rf.predict(X_test)","4bf75400":"print(\"Accuracy by random forest:\",accuracy_score(y_test, y_pred))\nprint('f1 score ', f1_score(y_test, y_pred,\n                              ))","025067c0":"#Applying decision tree\nfrom sklearn.tree import DecisionTreeClassifier\nclf=DecisionTreeClassifier(\"entropy\")\nclf.fit(X_train,y_train)","ac5b5bef":"y_pred=clf.predict(X_test)\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred))\nprint('f1 score', f1_score(y_test, y_pred,\n                              ))","fbb7a3e5":"cf=confusion_matrix(y_test, y_pred)\nsns.heatmap(cf, annot=True)","67b73943":"Ejection_Fraction for 20,25 are the ones where count Death Events are very high.\n\nEjection_Fraction 20 is the category where survived cases is extremely low as compared to death(Critical one)","fce28d8a":"Creatinine_phosphpokinase Between 0 to 1000 have recorded the highest number of death event","524aa4ed":"Since only accuracy was not a good parameter in this case we have to increase our F2 score\n\nThus,I did upsampling technique for treating the imbalance in death event.\n\nI am a beginner and this is my first submission. Thanks!!","a8917eff":"**Upsampling for better F1 Score\u00b6**","1b5d4e67":"Again we have to bring columns to same scale so doing standard scaler","6edbc178":"Male category have high death event","be468398":"Non-Diabetic people died more than non diabetic people due to heart disease which means Death due to heart disease has no relation with Diabetes\n\n","e43de44a":"Applying Logistic Regression","e92b5f69":"There are only 4 unexpected low values so replaced with 125","24043735":"sodium_sodium Between 130 to 140 have recorded the highest number of death event","9726e05e":"Above graph shows count of people who had anaemia and died is almost close to those who survived and had anaemia.","504d3cbc":"Now,Bringing all columns to same scale for our model","d0d017f3":"Replaced some labels with one who were having similar results","3c3f39c0":"High Blood Pressure is not the right parameter to judge the death event","798145f0":"Applying Random forest classifier","2b00f1aa":"sodium_creatinine Between 0.5 to 2 have recorded the highest number of death event","231a895a":"Non smokers have high number of death events thus cannot conclude anything from smoking category","6c98b3f6":"People with age around 60 died the most","e8731510":"**Getting some Insights for Heart Failure DataSet**"}}