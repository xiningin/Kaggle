{"cell_type":{"ab3cfcee":"code","4e5a325f":"code","94e3336d":"code","00d53ff0":"code","6d967f1d":"code","389cc913":"code","1802e2d1":"code","f66cb020":"code","26dbf20a":"code","79951f0f":"code","4dddc28b":"code","f1697200":"code","ba450b80":"code","29740fdd":"code","084699a5":"code","235acabe":"code","8ad73d7a":"code","8e96776a":"code","6d6c5917":"code","f3a4ac78":"code","07c90d7b":"markdown"},"source":{"ab3cfcee":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nimport warnings\n\n# Reading dataset\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\n# Adding a column in each dataset before merging\ntrain['kind'] = 'train'\ntest['kind'] = 'test'\n\n# Merging train and test\ndataset = train.append(test,sort=True).reset_index()\n","4e5a325f":"# Prepare data\nprint('Nan in data:\\n',dataset.isnull().sum())\n\n# clear unneed nan. (Embarked 2 nan, Fare 1 nan)\ndataset['Embarked'].fillna('C', inplace = True)\ndataset['Fare'].fillna(dataset['Fare'].mean(), inplace = True)\n\n\n# Change Cabin to A...P Without the number \ndef changeToLetter(letter,text):\n    if pd.isnull(text):\n        return text\n    isContins = letter in text.lower()\n    return letter if isContins  else text\n        \nfor char in range(ord('a'), ord('p') + 1):\n    dataset['Cabin'] = dataset['Cabin'].apply((lambda x: changeToLetter(chr(char),x)))","94e3336d":"# Analysis data\nsns.set()\n\n# male Vs Female survived plot\ngroupby_sex = dataset.groupby('Sex')['Survived'].sum()\ngroupby_sex.plot.bar(title = \"Male Vs Female Survived\")\nplt.show()\n\nprint(groupby_sex,'\\n')\nprint(\"Much more female was saved than male - more then double\")\n\ndataset = pd.get_dummies(dataset,columns = ['Sex'],drop_first = True)","00d53ff0":"# Age survived plot\ngrid = sns.FacetGrid(train, col=\"Survived\",height=5)\ngrid.map(sns.distplot,'Age',bins = 30);\nplt.show()\nprint(\"The survived and not survived ages is between 20-40\")\nprint(\"But we can see that the survived ages was also in ages 0-10 - children\")","6d967f1d":"# Pclass survived plot\nnot_survived_Pclass= train.loc[(train['Survived'] == False),'Pclass']\nsurvived_Pclass = train.loc[(train['Survived'] == True),'Pclass']\nsns.kdeplot(not_survived_Pclass,shade=True,color='Red', label='Not Survived')\nsns.kdeplot(survived_Pclass,shade=True,color='Green', label='Survived')\nlabels = ['Upper', 'Middle', 'Lower']\nplt.xticks(sorted(train.Pclass.unique()), labels);\n\nplt.show()\nprint(\"Must of the not survivedrs was in the Lower floor\")\nprint(\"Must of the surviveders was in the Upper floor\")\n\n\ndataset = pd.get_dummies(dataset,columns = ['Pclass'])","389cc913":"# cabin survived plot\n\ncabin =  dataset.dropna()\nnot_survived = cabin[cabin['Survived'] == False]\nsurvived = cabin[cabin['Survived'] == True]\n\nnot_survived.groupby('Cabin').size().plot.bar(title = \"Not Survived\",color = 'red')\nplt.show()\n\nsurvived.groupby('Cabin').size().plot.bar(title = \"Survived\",color = 'blue')\nplt.show()","1802e2d1":"# Create Cabin classification model\n\ncabin_dataset= dataset.dropna()\ncabin_dataset = cabin_dataset[['Fare','Cabin','Ticket','Pclass_1','Pclass_2','Pclass_3']] # Feature for Cabin prediction\n# Create PC ticket feature and remove Ticket column\ncabin_dataset['Is_PC_Ticket'] = cabin_dataset['Ticket'].str.contains('PC')\ncabin_dataset.drop('Ticket',inplace = True, axis = 1)\n\nX = cabin_dataset.drop('Cabin',axis = 1)\ny = cabin_dataset['Cabin']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 666)\n\nscoreTest = []\nscoreTrain = []\nfor number in range(1,30):\n    cls = DecisionTreeClassifier(max_depth = number)\n    cls.fit(X_train,y_train)\n    scoreTest.append(accuracy_score(y_true=y_test, y_pred=cls.predict(X_test)))\n    scoreTrain.append(accuracy_score(y_true=y_train, y_pred=cls.predict(X_train)))\npd.DataFrame({'test score':scoreTest,'train score':scoreTrain}).plot(grid = True)\nplt.xlabel('Max depth')\nplt.ylabel('Score')\nplt.show()","f66cb020":"cabin_cls = DecisionTreeClassifier(max_depth = 7)\ncabin_cls.fit(X_train,y_train)\nprint('Train accuracy score:',accuracy_score(y_true=y_train, y_pred=cabin_cls.predict(X_train)))\nprint('Test accuracy score',accuracy_score(y_true=y_test, y_pred=cabin_cls.predict(X_test)))","26dbf20a":"# Add missing cabin data by Cabin classification model\n\ntoPrdicData = dataset[['Fare','Cabin','Ticket','Pclass_1','Pclass_2','Pclass_3']].copy()\nnone_change_data = toPrdicData[pd.isnull(toPrdicData['Cabin']) == False]\ntoPrdicData = toPrdicData[pd.isnull(toPrdicData['Cabin']) == True]\ntoPrdicData['Is_PC_Ticket'] = toPrdicData['Ticket'].str.contains('PC')\ntoPrdicData.drop('Ticket',inplace = True, axis = 1)\ntoPrdicX = toPrdicData.drop('Cabin',axis = 1)\ntoSet = pd.DataFrame(cabin_cls.predict(toPrdicX),index = toPrdicX.index)\ntoSet.rename(columns ={0 :'Cabin'}, inplace=True)\ncabin_prdict_data = pd.concat([toSet,none_change_data],sort=False).sort_index()\ndataset['Cabin'] = cabin_prdict_data['Cabin']\n\ncabin_mapper = {'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7}\ndataset['Cabin'] = dataset['Cabin'].map(cabin_mapper)\ndataset['Cabin'].fillna(0, inplace = True)","79951f0f":"survived_df = dataset[dataset['Survived'] == True]\nsurvived_df_f = dataset[dataset['Survived'] == False]\n\nsurvived_df.groupby('Cabin').size().plot.barh(title = \"survived title count\")\nplt.show()\nsurvived_df_f.groupby('Cabin').size().plot.barh(title = \"survived title count\")\n\ncabin_mapper = {0:0,1:0,2:0,3:0,4:0,5:1,6:1,7:1}\ndataset['Cabin'] = dataset['Cabin'].map(cabin_mapper)","4dddc28b":"# Fare\n\ntrain['FareQ'] = pd.qcut(train['Fare'], 5)\nfare_quarter = train[['FareQ', 'Survived']].groupby(['FareQ'], as_index=False).mean().sort_values(by='FareQ', ascending=True)\nfare_quarter.set_index('FareQ', inplace = True)\nfare_quarter.plot.bar()\nlabels = ['a', 'b', 'c','d','e']\n\n# Change Fare by quarters\n\ndef get_fare_by_quarters(fare):\n    if fare <= 7.285:\n        return 0\n    elif fare <= 10.5:\n        return 1\n    elif fare <= 21.678:\n        return 2\n    elif fare <= 39.988:\n        return 3\n    else:\n        return 4\n\ndataset['Fare'] = dataset['Fare'].apply(get_fare_by_quarters)","f1697200":"# name \n\n# Extract all the titles from name\ndataset['Name_Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nprint(dataset.groupby('Name_Title').size().index)\n\n# Mrage the same title\ndataset['Name_Title'].replace('Mlle', 'Miss', inplace = True)    \ndataset['Name_Title'].replace('Ms', 'Miss', inplace = True)\ndataset['Name_Title'].replace('Mme', 'Mrs', inplace = True)\n\nsurvived_df = dataset[dataset['Survived'] == True]\nnot_survived_df = dataset[dataset['Survived'] == False]\n\nsurvived_df.groupby('Name_Title').size().plot.barh(title = \"survived title count\")\nplt.show()\n\nnot_survived_df.groupby('Name_Title').size().plot.barh(title = \"not survived title count\")\nplt.show()\n\n# Get only the important feature and replace with number ()\ntitle_feature_map = {\"Miss\": 1, \"Mrs\": 2,\"Mr\": 3, \"Master\": 4} \n\n\ndataset['Name_Title'] = dataset['Name_Title'].map(title_feature_map)\ndataset['Name_Title'].fillna(0, inplace = True)\n\n# change check\nprint(dataset['Name_Title'].unique())","ba450b80":"# fill missing age with midain \ndef getAgeIfNeeded(age):\n    if pd.isnull(age):\n        return dataset['Age'].median()\n    return age\n\ndataset['Age'] = dataset['Age'].apply(getAgeIfNeeded)","29740fdd":"# SibSp and Parch\n\ndataset['Family_Count'] = dataset['SibSp'] + dataset['Parch']\ndataset.groupby('Family_Count').mean()['Survived'].plot.bar(title = 'Family count survived')\nplt.show()\n#dataset[['Family_Count', 'Survived']].groupby(['Family_Count'], as_index=False).mean().sort_values(by='Survived', ascending=False).plot.bar()\n\ndef convertCountToGroups(family_count):\n    if family_count == 0:\n        return 'alone'\n    elif family_count < 4:\n        return 'small'\n    else:\n        return 'big'\n    \ndataset['Family_Count'] = dataset['Family_Count'].apply(convertCountToGroups)\ndataset.groupby('Family_Count').mean()['Survived'].plot.bar(title = 'Family count survived')\nplt.show()\n\n\ndataset.drop(['SibSp','Parch'], axis=1, inplace = True)\ndataset = pd.get_dummies(dataset,columns = ['Family_Count'])","084699a5":"dataset = pd.get_dummies(dataset,columns = ['Embarked'])","235acabe":"# remove unneeded feature\ndataset.drop(['Ticket','Name','index'], axis=1, inplace = True)\n\n# set back the train and test\ntrain = dataset[dataset['kind'] == 'train'].copy()\ntest = dataset[dataset['kind'] == 'test'].copy()\n\ntrain.drop(['kind','PassengerId'],axis = 1,inplace = True)\ntest.drop('kind',axis = 1,inplace = True)","8ad73d7a":"# train the modle\n\nX, y  = train.drop('Survived', axis = 1), train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=34)\n\nscoreTest = []\nscoreTrain = []\nfor number in range(1,100):\n    cls = DecisionTreeClassifier(max_depth = number)\n    cls.fit(X_train,y_train)\n    scoreTrain.append(round(cls.score(X_train, y_train) * 100, 2))\n    scoreTest.append(round(cls.score(X_test, y_test) * 100, 2))\npd.DataFrame({'test score':scoreTest,'train score':scoreTrain}).plot(grid = True)\nplt.xlabel('Max depth')\nplt.ylabel('Score')\nplt.show()\n\ncls = DecisionTreeClassifier(max_depth = 4)\ncls.fit(X_train,y_train)\nprint('train score:',round(cls.score(X_train, y_train) * 100, 2))\nprint('test score:',round(cls.score(X_test, y_test) * 100, 2))","8e96776a":"pd.DataFrame(X_train.columns, index = cls.feature_importances_)","6d6c5917":"train = dataset[dataset['kind'] == 'train'].copy()\n\ntrain.drop(['kind','PassengerId','Embarked_C','Embarked_Q','Pclass_2','Cabin'],axis = 1,inplace = True)\n\nX, y  = train.drop('Survived', axis = 1), train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=34)\n\nscoreTest = []\nscoreTrain = []\nfor number in range(1,100):\n    cls = DecisionTreeClassifier(max_depth = number)\n    cls.fit(X_train,y_train)\n    scoreTest.append(round(cls.score(X_train, y_train) * 100, 2))\n    scoreTrain.append(round(cls.score(X_test, y_test) * 100, 2))\npd.DataFrame({'test score':scoreTest,'train score':scoreTrain}).plot(grid = True)\nplt.xlabel('Max depth')\nplt.ylabel('Score')\nplt.show()\n\ncls = DecisionTreeClassifier(max_depth = 4)\ncls.fit(X_train,y_train)\nprint('train score:',round(cls.score(X_train, y_train) * 100, 2))\nprint('test score:',round(cls.score(X_test, y_test) * 100, 2))","f3a4ac78":"test = dataset[dataset['kind'] == 'test'].copy()\nX_test = test.drop(['Survived','PassengerId','kind','PassengerId','Embarked_C','Embarked_Q','Pclass_2','Cabin'], axis = 1)\ny_prdic = cls.predict(X_test)\nsubmission = pd.DataFrame({\n        \"PassengerId\": test['PassengerId'],\n        \"Survived\": y_prdic\n    })\nsubmission.to_csv('submission.csv', index=False)","07c90d7b":"# Cabin \n\n<img src=\"http:\/\/upload.wikimedia.org\/wikipedia\/commons\/5\/5d\/Titanic_side_plan_annotated_English.png\" width=\"1000px\">\n\n \nI want to create a model to predict the Cabin of person, This will help for the Survived model"}}