{"cell_type":{"149a866e":"code","06eb073b":"code","6dd23908":"code","af5b0a6b":"code","0aa12d73":"code","5d76f5bb":"code","0b667fa0":"code","70c739c1":"code","66e4bb6e":"code","dcd28351":"code","c49885e9":"code","3d46df86":"code","c77f45d0":"code","f5e72bf2":"code","243b3dd4":"markdown","687662a4":"markdown","367f6fbe":"markdown","a964f8f7":"markdown","1a1db456":"markdown","c8529dbd":"markdown","aa42034a":"markdown","8c721a9e":"markdown","c1c18809":"markdown","9a011a1c":"markdown","96690267":"markdown","b90cb3fa":"markdown","1128d9a0":"markdown","42e79598":"markdown"},"source":{"149a866e":"import os\nimport cv2\nimport PIL\nimport random\nimport openslide\nimport skimage.io\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display","06eb073b":"train_df = pd.read_csv('..\/input\/prostate-cancer-grade-assessment\/train.csv').sample(n=10, random_state=0).reset_index(drop=True)\n\nimages = list(train_df['image_id'])\nlabels = list(train_df['isup_grade'])","6dd23908":"data_dir = '..\/input\/prostate-cancer-grade-assessment\/train_images\/'","af5b0a6b":"def compute_statistics(image):\n    \"\"\"\n    Args:\n        image                  numpy.array   multi-dimensional array of the form WxHxC\n    \n    Returns:\n        ratio_white_pixels     float         ratio of white pixels over total pixels in the image \n    \"\"\"\n    width, height = image.shape[0], image.shape[1]\n    num_pixels = width * height\n    \n    num_white_pixels = 0\n    \n    summed_matrix = np.sum(image, axis=-1)\n    # Note: A 3-channel white pixel has RGB (255, 255, 255)\n    num_white_pixels = np.count_nonzero(summed_matrix > 620)\n    ratio_white_pixels = num_white_pixels \/ num_pixels\n    \n    green_concentration = np.mean(image[1])\n    blue_concentration = np.mean(image[2])\n    \n    return ratio_white_pixels, green_concentration, blue_concentration","0aa12d73":"def select_k_best_regions(regions, k=20):\n    \"\"\"\n    Args:\n        regions               list           list of 2-component tuples first component the region, \n                                             second component the ratio of white pixels\n                                             \n        k                     int            number of regions to select\n    \"\"\"\n    regions = [x for x in regions if x[3] > 180 and x[4] > 180]\n    k_best_regions = sorted(regions, key=lambda tup: tup[2])[:k]\n    return k_best_regions","5d76f5bb":"def get_k_best_regions(coordinates, image, window_size=512):\n    regions = {}\n    for i, tup in enumerate(coordinates):\n        x, y = tup[0], tup[1]\n        regions[i] = image[x : x+window_size, y : y+window_size, :]\n    \n    return regions","0b667fa0":"def generate_patches(slide_path, window_size=200, stride=128, k=20):\n    \n    image = skimage.io.MultiImage(slide_path)[-2]\n    image = np.array(image)\n    \n    max_width, max_height = image.shape[0], image.shape[1]\n    regions_container = []\n    i = 0\n    \n    while window_size + stride*i <= max_height:\n        j = 0\n        \n        while window_size + stride*j <= max_width:            \n            x_top_left_pixel = j * stride\n            y_top_left_pixel = i * stride\n            \n            patch = image[\n                x_top_left_pixel : x_top_left_pixel + window_size,\n                y_top_left_pixel : y_top_left_pixel + window_size,\n                :\n            ]\n            \n            ratio_white_pixels, green_concentration, blue_concentration = compute_statistics(patch)\n            \n            region_tuple = (x_top_left_pixel, y_top_left_pixel, ratio_white_pixels, green_concentration, blue_concentration)\n            regions_container.append(region_tuple)\n            \n            j += 1\n        \n        i += 1\n    \n    k_best_region_coordinates = select_k_best_regions(regions_container, k=k)\n    k_best_regions = get_k_best_regions(k_best_region_coordinates, image, window_size)\n    \n    return image, k_best_region_coordinates, k_best_regions","70c739c1":"def display_images(regions, title):\n    fig, ax = plt.subplots(5, 4, figsize=(15, 15))\n    \n    for i, region in regions.items():\n        ax[i\/\/4, i%4].imshow(region)\n    \n    fig.suptitle(title)","66e4bb6e":"%%time\n\nex_url = data_dir + images[0] + '.tiff'\n_, best_coordinates, best_regions = generate_patches(ex_url)","dcd28351":"display_images(best_regions, 'Window size: 200, stride: 128')","c49885e9":"%%time\n\nex_url = data_dir + images[0] + '.tiff'\n_, best_coordinates, best_regions = generate_patches(ex_url, window_size=128, stride=64)\ndisplay_images(best_regions, 'Window size: 128, stride: 64')","3d46df86":"def glue_to_one_picture(image_patches, window_size=200, k=16):\n    side = int(np.sqrt(k))\n    image = np.zeros((side*window_size, side*window_size, 3), dtype=np.int16)\n        \n    for i, patch in image_patches.items():\n        x = i \/\/ side\n        y = i % side\n        image[\n            x * window_size : (x+1) * window_size,\n            y * window_size : (y+1) * window_size,\n            :\n        ] = patch\n    \n    return image","c77f45d0":"WINDOW_SIZE = 128\nSTRIDE = 64\nK = 16","f5e72bf2":"fig, ax = plt.subplots(6, 2, figsize=(20, 25))\n\nfor i, img in enumerate(images[:6]):\n    url = data_dir + img + '.tiff'\n    image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n    glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n    \n    ax[i][0].imshow(image)\n    ax[i][0].set_title(f'{img} - Original - Label: {labels[i]}')\n    \n    ax[i][1].imshow(glued_image)\n    ax[i][1].set_title(f'{img} - Glued - Label: {labels[i]}')\n\nfig.suptitle('From biopsy to glued patches')","243b3dd4":"### Window size: 200, stride: 128","687662a4":"# Better image tiles - Simple heuristic to suppress blank regions\n\n![image.png](attachment:image.png)\n\nAs you might know, for this competition, it is critical to come up with an efficient way to pre-process the images. One of the key aspects that I show in my previous notebook https:\/\/www.kaggle.com\/rftexas\/gradcam-comparing-resnet-and-se-resnext is that as expected white regions don't convey any information, hence the need to get rid of them. \n\nActually, one need to zoom enough in the biopsy image to make sure there is **as little white as possible**.\n\nThis is why in this notebook, we will code a **simple heuristic** to generate better images that have no more blank parts.\n\nThe algorithm is pretty simple actually: having a **sliding window moving across the images** and calculating for each region the proporition of white color in the image. Then **select k regions** with the lowest proportion of white.\n\nWe will define the algorithm as follows:\n- Define a sliding window of a fixed size\n- Slide the window with a certain stride\n- For each region on which we slide, compute the amount of white pixels\n- Do this for all the regions in the image\n- Select the top k results where k is a hyperparameter\n\n\n** If you like those kinds of tutorials, upvote this notebook! It encourages me to keep writing some ;) **\n\nV5: I'll try to tackle pen markers now! Stay tuned! \n\n# Contents\n\n- <a href='#1'>1. Importing dependencies<\/a>\n- <a href='#2'>2. Compute statistics<\/a>\n- <a href='#3'>3. Select k-best regions<\/a>\n- <a href='#4'>4. Slide over the image<\/a>\n- <a href='#5'>5. Show the results<\/a>\n\n    - <a href='#5.1.'>5.1. Window size: 200, stride: 128<\/a>\n    - <a href='#5.2.'>5.2. Window size: 128, stride: 64<\/a>\n    - <a href='#5.3.'>5.3. Window size: 512, stride: 256<\/a>","367f6fbe":"## Slide over the image","a964f8f7":"## Compute statistics","1a1db456":"Then we need a function to sort a list of tuples, where one component of the tuple is the proportion of white pixels in the regions. We are sorting in ascending order.","c8529dbd":"## Glue to one picture","aa42034a":"## Show the results","8c721a9e":"## Importing dependencies","c1c18809":"Since we will only store, the coordinates of the top-left pixel, we need a way to retrieve the k best regions, hence the function hereafter...","9a011a1c":"### Window size: 128, stride: 64","96690267":"Now we will show some results. \n\nPlease note:\n1. The smaller the window size, the more precise but the longer.\n2. I would say that a window size of around 200 is a good choice. It is a good trade-off between generality, having enough of the biopsy structure captured as well as enough details.\n3. A too small window size might harm the performance of the model since you might select only a tiny portion of the biopsy. (To counter this, introducing a random choice might be worth trying).","b90cb3fa":"The main function: the two while loops slide over the image (the first one from top to bottom, the second from left to right). The order does not matter actually.\nThen you select the region, compute the statistics of that region, sort the array and select the k-best regions.","1128d9a0":"## Select k-best regions","42e79598":"First we need to write a function to compute the proportion of white pixels in the region."}}