{"cell_type":{"c5ba934e":"code","11a7791c":"code","85e84e98":"code","6ddcb44d":"code","67f43ceb":"code","1f843f88":"code","1e765123":"code","9895097b":"code","ad7a7587":"code","0ed54532":"code","22e50fc9":"code","544ac460":"code","a1b051e1":"code","f91b07f6":"code","a3e7e21b":"code","198b283c":"code","9f660bcd":"code","3a333add":"markdown","2e5502ba":"markdown","04812dbf":"markdown","2c1e3b14":"markdown","ca30eb78":"markdown","665e846e":"markdown","08bc8117":"markdown","3e4c6cc3":"markdown","da9653a7":"markdown","003c2b8c":"markdown","19f5ed36":"markdown","084d53cc":"markdown","2a1f4c1e":"markdown","0fd8ced9":"markdown","21c7aec4":"markdown","9e38cd39":"markdown"},"source":{"c5ba934e":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport numpy as np\nimport seaborn as sns\nimport os\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.feature_selection import RFECV, SelectFromModel, SelectKBest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\n%matplotlib inline\n","11a7791c":"Stock = pd.read_csv('..\/input\/us-stock-market-data-60-extracted-features\/AAPL.csv',  index_col=0)\n\ndf_Stock = Stock\ndf_Stock = df_Stock.rename(columns={'Close(t)':'Close'})\ndf_Stock.head()","85e84e98":"df_Stock.tail(5)","6ddcb44d":"df_Stock.shape","67f43ceb":"df_Stock.columns","1f843f88":"df_Stock['Close'].plot(figsize=(10, 7))\nplt.title(\"Stock Price\", fontsize=17)\nplt.ylabel('Price', fontsize=14)\nplt.xlabel('Time', fontsize=14)\nplt.grid(which=\"major\", color='k', linestyle='-.', linewidth=0.5)\nplt.show()","1e765123":"df_Stock = df_Stock.drop(columns='Date_col')","9895097b":"def create_train_test_set(df_Stock):\n    \n    features = df_Stock.drop(columns=['Close_forcast'], axis=1)\n    target = df_Stock['Close_forcast']\n    \n\n    data_len = df_Stock.shape[0]\n    print('Historical Stock Data length is - ', str(data_len))\n\n    #create a chronological split for train and testing\n    train_split = int(data_len * 0.88)\n    print('Training Set length - ', str(train_split))\n\n    val_split = train_split + int(data_len * 0.1)\n    print('Validation Set length - ', str(int(data_len * 0.1)))\n\n    print('Test Set length - ', str(int(data_len * 0.02)))\n\n    # Splitting features and target into train, validation and test samples \n    X_train, X_val, X_test = features[:train_split], features[train_split:val_split], features[val_split:]\n    Y_train, Y_val, Y_test = target[:train_split], target[train_split:val_split], target[val_split:]\n\n    #print shape of samples\n    print(X_train.shape, X_val.shape, X_test.shape)\n    print(Y_train.shape, Y_val.shape, Y_test.shape)\n    \n    return X_train, X_val, X_test, Y_train, Y_val, Y_test","ad7a7587":"X_train, X_val, X_test, Y_train, Y_val, Y_test = create_train_test_set(df_Stock)","0ed54532":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train, Y_train)","22e50fc9":"print('LR Coefficients: \\n', lr.coef_)\nprint('LR Intercept: \\n', lr.intercept_)","544ac460":"print(\"Performance (R^2): \", lr.score(X_train, Y_train))","a1b051e1":"def get_mape(y_true, y_pred): \n    \"\"\"\n    Compute mean absolute percentage error (MAPE)\n    \"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","f91b07f6":"Y_train_pred = lr.predict(X_train)\nY_val_pred = lr.predict(X_val)\nY_test_pred = lr.predict(X_test)","a3e7e21b":"print(\"Training R-squared: \",round(metrics.r2_score(Y_train,Y_train_pred),2))\nprint(\"Training Explained Variation: \",round(metrics.explained_variance_score(Y_train,Y_train_pred),2))\nprint('Training MAPE:', round(get_mape(Y_train,Y_train_pred), 2)) \nprint('Training Mean Squared Error:', round(metrics.mean_squared_error(Y_train,Y_train_pred), 2)) \nprint(\"Training RMSE: \",round(np.sqrt(metrics.mean_squared_error(Y_train,Y_train_pred)),2))\nprint(\"Training MAE: \",round(metrics.mean_absolute_error(Y_train,Y_train_pred),2))\n\nprint(' ')\n\nprint(\"Validation R-squared: \",round(metrics.r2_score(Y_val,Y_val_pred),2))\nprint(\"Validation Explained Variation: \",round(metrics.explained_variance_score(Y_val,Y_val_pred),2))\nprint('Validation MAPE:', round(get_mape(Y_val,Y_val_pred), 2)) \nprint('Validation Mean Squared Error:', round(metrics.mean_squared_error(Y_train,Y_train_pred), 2)) \nprint(\"Validation RMSE: \",round(np.sqrt(metrics.mean_squared_error(Y_val,Y_val_pred)),2))\nprint(\"Validation MAE: \",round(metrics.mean_absolute_error(Y_val,Y_val_pred),2))\n\nprint(' ')\n\nprint(\"Test R-squared: \",round(metrics.r2_score(Y_test,Y_test_pred),2))\nprint(\"Test Explained Variation: \",round(metrics.explained_variance_score(Y_test,Y_test_pred),2))\nprint('Test MAPE:', round(get_mape(Y_test,Y_test_pred), 2)) \nprint('Test Mean Squared Error:', round(metrics.mean_squared_error(Y_test,Y_test_pred), 2)) \nprint(\"Test RMSE: \",round(np.sqrt(metrics.mean_squared_error(Y_test,Y_test_pred)),2))\nprint(\"Test MAE: \",round(metrics.mean_absolute_error(Y_test,Y_test_pred),2))","198b283c":"df_pred = pd.DataFrame(Y_val.values, columns=['Actual'], index=Y_val.index)\ndf_pred['Predicted'] = Y_val_pred\ndf_pred = df_pred.reset_index()\ndf_pred.loc[:, 'Date'] = pd.to_datetime(df_pred['Date'],format='%Y-%m-%d')\ndf_pred","9f660bcd":"df_pred[['Actual', 'Predicted']].plot()","3a333add":"### Predict for the test dataset","2e5502ba":"Remove some of the columns which are not required","04812dbf":"I will also create a Notebook explaining how I have extracted this data using only OHLC(Open High Low Close) data.","2c1e3b14":"Overall the Predictions looks good for the test data! ","ca30eb78":"### Test Train Set","665e846e":"### Evaluation","08bc8117":"\nIn this notebook, I will analyse the data and create a basic Linear regression model to forecast Stock Prices. \nIn future notebooks, I will use other algorithms like Random Forest, XGBoost and LSTM for this task. \n","3e4c6cc3":"### Load the data\n\nI will use the Apple Stock Data for this notebook","da9653a7":"Close_forecast is the column that we are trying to predict here which is the price for the next day. ","003c2b8c":"### Plot Time Series chart for AAPL","19f5ed36":"### Future Notebooks\n\nI will create a Notebook explaining how I have extracted this data using only OHLC(Open High Low Close) data and a custom pipeline","084d53cc":"### About the Dataset - \nThe dataset has around 60 features which includes features extracted from OHLC, other index prices such as QQQ(Nasdaq-100 ETF) & S&P 500, technical Indicators such as Bollinger bands, EMA(Exponential Moving Averages, Stocastic %K oscillator, RSI etc)\n\nFurthermore, I have created lagged features from previous day price data as we know previous day prices affect the future stock price. \n\nThen, the data has date features which specifies, if its a leap year, if its month start or end, Quarter start or end, etc. \n\n\nAll of these features have something to offer for forcasting. Some tells us about the trend, some gives us a signal if the stock is overbought or oversold, some portrays the strength of the price trend.\n","2a1f4c1e":"### Prediction using Linear Regression","0fd8ced9":"### Plot Predicted vs Actual Prices on Time Series plot","21c7aec4":"We have a decent Mean Absolute error but not great. I will create further tuned models in later notebooks. This is just to get you started with the dataset.","9e38cd39":"### This is a Starter Notebook for Stock Price Prediction using Linear Regression\n\n"}}