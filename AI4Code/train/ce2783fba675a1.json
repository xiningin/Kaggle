{"cell_type":{"6142da24":"code","941dbf7d":"code","d8a092cb":"code","a2398813":"code","476855cb":"code","4311e84f":"code","f5cfda50":"code","debd4b71":"code","75925990":"code","28f4d34f":"code","cd60d83f":"code","78c49018":"code","a196f45d":"code","b318039b":"code","de93952c":"code","80f653f0":"code","c4ca20d3":"code","17b36eef":"code","0b4cc7bc":"code","9b220147":"code","c71048a6":"code","a035849a":"code","f175a0d1":"code","b758f586":"code","2d573185":"markdown","abd8551c":"markdown","9e0ac6da":"markdown","e6a6e739":"markdown","5ebc38ca":"markdown","0ee6f8e7":"markdown","ef5a1c8a":"markdown","f9d57161":"markdown","75db649b":"markdown","2cda4e94":"markdown","fdd9a1f4":"markdown","98238688":"markdown"},"source":{"6142da24":"import pandas as pd\nimport numpy as np\nimport os\nimport glob\n\nimport PIL\nfrom PIL import Image\nimport imageio\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sn\nimport numpy as np\nimport pathlib","941dbf7d":"train_dir = pathlib.Path('..\/input\/brain-image-clean\/train')\ntest_dir = pathlib.Path('..\/input\/brain-image-clean\/test')\n\nimage_count_train = len(list(train_dir.glob('*\/*.jpg')))\nimage_count_test = len(list(test_dir.glob('*\/*.jpg')))\nprint(\"Train Image Count: {} \\n Test Image Count: {}\".format(image_count_train,image_count_test))","d8a092cb":"batch_size = 32\nimg_height = 180\nimg_width = 180","a2398813":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    validation_split=None,\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)","476855cb":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  test_dir,\n  validation_split=None,\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","4311e84f":"class_names = train_ds.class_names\nprint(class_names)","f5cfda50":"normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\n\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))","debd4b71":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","75925990":"num_classes = 2\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(255, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n\nhist = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=8\n)","28f4d34f":"model.summary()","cd60d83f":"tf.keras.utils.plot_model(model,\n                          show_shapes=True,\n                          expand_nested=True)","78c49018":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass","a196f45d":"plot_metrics(hist)","b318039b":"def list_files(dir,full_dir):\n    r = []\n    r1 = []\n    for root, dirs, files in os.walk(dir):\n        for name in files:\n            rr = os.path.join(root, name)\n            r.append(rr)\n    dd = {'local_path':r}\n    df = pd.DataFrame(dd)\n    return df\n\ndef proccess(img1):\n  img = tf.keras.preprocessing.image.load_img(\n      img1, target_size=(img_height, img_width)\n  )\n  img_array = tf.keras.preprocessing.image.img_to_array(img)\n  img_array = tf.expand_dims(img_array, 0) # Create a batch\n\n  predictions = model.predict(img_array)\n  score = tf.nn.softmax(predictions[0])\n\n  pred = class_names[np.argmax(score)]\n  score1 = 100 * np.max(score)\n\n  return pred, score1\n\ndef new_col(col):\n    if col['Pred'] == 'yes' and col['Actual'] == 'yes':\n        return 1\n    elif col['Pred'] == 'no' and col['Actual'] == 'no':\n      return 1\n    else:\n      return 0\n\n\ndef proccess1(df):\n  aa = []\n  bb = []\n  cc = []\n\n  for a,b in df.iterrows():\n    img = b['local_path']\n    pred, value = proccess(img)\n    pat = b['local_path']\n    \n    val = pat.split('\/')[4]\n    \n    aa.append(pred)\n    bb.append(value)\n    cc.append(val)\n  vals = {\"Pred\":aa,\"Accurarcy\":bb,'Actual':cc}\n  df_test1 = pd.DataFrame(vals)\n  df_test1 = pd.concat([df,df_test1], axis=1)\n\n  df_test1['Check'] = df_test1.apply(lambda col: new_col (col),axis=1)\n\n  return df_test1\n","de93952c":"fullpath = '..\/input\/brain-image-clean\/test\/'\npath = \"test\"\n\ndf_test = list_files(fullpath, path)\ndf_test1 = proccess1(df_test)","80f653f0":"def new_col(col):\n    if col['Pred'] == 'yes':\n        return 1\n    else:\n      return 0\ndef new_col2(col):\n    if col['Actual'] == 'yes':\n        return 1\n    else:\n      return 0\ndf_test1['Pred1'] = df_test1.apply(lambda col: new_col (col),axis=1)\ndf_test1['Actual1'] = df_test1.apply(lambda col: new_col2 (col),axis=1)\ndf_test1.head()","c4ca20d3":"df_test1.head()","17b36eef":"form = df_test1.Check.value_counts()[1] \/ df_test1.Check.count()\nprint('Accuracy is : {}'.format(form))","0b4cc7bc":"cm = tf.math.confusion_matrix(labels=df_test1['Actual1'].to_numpy(), predictions=df_test1['Pred1'].to_numpy()).numpy()\nls = ['Non-Tumorous', 'Tumorous'] # your y labels()\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ls)\nfig, ax = plt.subplots(figsize=(10,10))\ndisp.plot(xticks_rotation=50, ax = ax)\nplt.show()","9b220147":"acc = (cm[0][0] + cm[1][1]) \/ (cm[0][0] + cm[0][1]+ cm[1][1] + cm[1][0])\nTPR =  (cm[1][1]) \/ (cm[1][1] + cm[1][0])\nFPR = (cm[0][1]) \/ (cm[0][1] + cm[0][0])\nprint(\"ACC: {}\\nTPR: {}\\n FPR: {}\".format(acc,TPR,FPR))","c71048a6":"df_test1.head()","a035849a":"df_test1[df_test1[\"Check\"] == 0][['Actual',\"Pred\"]].value_counts()","f175a0d1":"for a,b in df_test1[(df_test1['Check'] == 0) & (df_test1['Actual'] == 'yes')].iterrows():\n    img_path = (b['local_path'])\n    im = imageio.imread(img_path)\n\n    print(\"Actual: {} \\nPrediction: {}\".format(b['Actual'], b['Pred']))\n    plt.imshow(im)\n    plt.show()\n    print('==============================================')","b758f586":"for a,b in df_test1[(df_test1['Check'] == 0) & (df_test1['Actual'] == 'no')].iterrows():\n    img_path = (b['local_path'])\n    im = imageio.imread(img_path)\n    print(\"Actual: {} \\nPrediction: {}\".format(b['Actual'], b['Pred']))\n\n    plt.imshow(im)\n    plt.show()\n    print('==============================================')\n ","2d573185":"## False Negative ","abd8551c":"### Test Accurarcy","9e0ac6da":"## False Positves","e6a6e739":"### Confusion Matrix","5ebc38ca":"### Metrics","0ee6f8e7":"## Create DataSet","ef5a1c8a":"### Visualize Results","f9d57161":"## Model Building","75db649b":"# Model Testing on Test Data","2cda4e94":"## Fit, Evaluate Model","fdd9a1f4":"## Accurarcy","98238688":"## Model Summary"}}