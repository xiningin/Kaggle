{"cell_type":{"a5e69852":"code","6a884560":"code","924d69a8":"code","aefc64bd":"code","0ebe2bb6":"code","8cfc7d20":"code","e756f3ec":"code","0122fe81":"code","98e474cd":"code","5601c9ff":"code","a888c4d0":"code","190df18a":"code","421de925":"markdown"},"source":{"a5e69852":"import numpy as np\nimport pandas as pd\nimport sqlite3","6a884560":"iris_data = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')","924d69a8":"iris_data.head(5)","aefc64bd":"'shape of iris data set: {}'.format(iris_data.shape)","0ebe2bb6":"Y = iris_data['Species']\nX = iris_data.drop(columns=['Id', 'Species'], axis=0)","8cfc7d20":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state= 44)","e756f3ec":"print('shape of X_train: {}'.format(X_train.shape))\nprint('shape of X_test: {}'.format(X_test.shape))\nprint('shape of Y_train: {}'.format(Y_train.shape))\nprint('shape of X_test: {}'.format(Y_test.shape))","0122fe81":"from sklearn.preprocessing import StandardScaler\n\nscalar = StandardScaler()\nscalar.fit(X_train)\n\nprint('mean vector: {}'.format(scalar.mean_))\n\nX_train_std = scalar.transform(X_train)","98e474cd":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(X_train_std, Y_train)","5601c9ff":"Y_test = Y_test.to_numpy()\npredicted = gnb.predict(scalar.transform(X_test))\nmatched = 0\nfor i in range(len(Y_test)):\n  print('actual: {}, predicted: {}'.format(Y_test[i], predicted[i]))\n  if predicted[i] == Y_test[i]:\n    matched += 1\nprint('accuracy: {}%'.format((matched*100)\/len(X_test)))","a888c4d0":"from sklearn.metrics import confusion_matrix,classification_report\n\nconfusion_matrix(Y_test,predicted)","190df18a":"print(classification_report(Y_test,predicted))","421de925":"Lets drop the Id feature which is not helpful with the task of classificaiton and divide our data-set into features and labels."}}