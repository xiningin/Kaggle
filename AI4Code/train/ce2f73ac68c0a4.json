{"cell_type":{"f626ba83":"code","b66fc4a9":"code","a27d1d5b":"code","6087fede":"code","b1ac5546":"code","88709da5":"code","6610488c":"code","599d974f":"code","06120f17":"code","549aa7ac":"code","fa0c8579":"code","5c4ddd1e":"code","8dfb9f6b":"code","4a4e66dc":"code","b6d1541b":"code","9dd5d7a9":"code","03c41c9a":"code","f894a49f":"code","0c0a8818":"code","054a7fcf":"code","0aa6d5e8":"code","01b79b9c":"code","8cb41eb8":"code","673bb0b4":"code","aec9cee5":"markdown","84993584":"markdown","469cd194":"markdown","e2a03fb4":"markdown","a48c95b1":"markdown","0a9954bf":"markdown","2cb037bf":"markdown","56e8bdd3":"markdown","442995b1":"markdown","a3fa22c6":"markdown","4b14c601":"markdown","c82f1651":"markdown","aef3abf5":"markdown","d862be3a":"markdown","5d58be23":"markdown","6ce3ca60":"markdown","9c8340b9":"markdown"},"source":{"f626ba83":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport missingno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sys\n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")","b66fc4a9":"source = '\/kaggle\/input\/fraud-detection-bank-dataset-20k-records-binary\/fraud_detection_bank_dataset.csv'\ndata = pd.read_csv(source)","a27d1d5b":"data.columns","6087fede":"data.head()","b1ac5546":"data.describe()","88709da5":"missing_count = data.isnull().any().sum()\nprint(f'Count of features with missing values: {missing_count}')","6610488c":"data.tail()","599d974f":"fig, axes = plt.subplots(7,16,figsize=(28,14))\naxes = axes.flatten()\n\nfor col, ax in enumerate(axes):\n    sns.kdeplot(data=data, x=f'col_{col}', \n                fill=True, \n                ax=ax)\n \n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.set_title(f'col_{col}', loc='center', weight='bold', fontsize=10)\n\nplt.show()","06120f17":"drop_list=['col_8','col_9','col_10','col_11','col_12','col_18','col_19','col_20','col_21','col_35','col_51','col_52','col_53','col_70','col_71']\ndata.drop(drop_list,axis=1,inplace=True)","549aa7ac":"col_list = ['index']\nlast_one = len(data.columns)-1\nfor i in range(last_one):\n    if i != last_one-1:\n        col_list.append(f'col_{i}')\n\ncol_list.append('targets')\n\ndata = data.set_axis(col_list,axis=1)","fa0c8579":"data.head()","5c4ddd1e":"fig, axes = plt.subplots(14,7,figsize=(20,30))\naxes = axes.flatten()\n\ncounter = 0\n\nfor col, ax in enumerate(axes):\n    counter += 1\n    y = f'col_{col}'\n    \n    if counter<98:\n        sns.barplot(data=data, \n                    x='targets',\n                    y=y, \n                    palette='rocket', \n                    ax=ax)\n\n        ax.set_xlabel('')\n        \nplt.title('Features vs Targets')\nplt.tight_layout()\nplt.show()\n","8dfb9f6b":"data['c0'] = [0 if i > 3 else 1 for i in data.col_0]\ndata['c1'] = [0 if i > 200 else 1 for i in data.col_1]\ndata['c2'] = [0 if i > 0.4 else 1 for i in data.col_2]\ndata['c3'] = [0 if i > 2 else 1 for i in data.col_3]\ndata['c5'] = [1 if i > 1 else 0 for i in data.col_5]\ndata['c7'] = [0 if i > 3 else 1 for i in data.col_7]\ndata['c9'] = [0 if i > 0.2 else 1 for i in data.col_9]\n\ndata['c11'] = [0 if i > 0.4 else 1 for i in data.col_11]\ndata['c13'] = [0 if i > 4 else 1 for i in data.col_13]\ndata['c14'] = [0 if i > 30 else 1 for i in data.col_14]\ndata['c15'] = [0 if i > 3 else 1 for i in data.col_15]\ndata['c16'] = [0 if i > 2 else 1 for i in data.col_16]\ndata['c17'] = [0 if i > 1 else 1 for i in data.col_17]\n\ndata['c20'] = [0 if i > 1.5 else 1 for i in data.col_20]\ndata['c21'] = [0 if i > 5 else 1 for i in data.col_21]\ndata['c22'] = [0 if i > 0.2 else 1 for i in data.col_22]\ndata['c23'] = [0 if i > 0.4 else 1 for i in data.col_23]\ndata['c24'] = [0 if i > 0.05 else 1 for i in data.col_24]\ndata['c25'] = [0 if i > 2 else 1 for i in data.col_25]\ndata['c28'] = [0 if i > 150 else 1 for i in data.col_28]\n\ndata['c31'] = [0 if i > 0.5 else 1 for i in data.col_31]\ndata['c32'] = [0 if i > 5 else 1 for i in data.col_32]\ndata['c33'] = [0 if i > 0.3 else 1 for i in data.col_33]\ndata['c35'] = [0 if i > 0.05 else 1 for i in data.col_35]\n\ndata['c41'] = [0 if i > 150 else 1 for i in data.col_41]\ndata['c46'] = [0 if i > 0.2 else 1 for i in data.col_46]\ndata['c47'] = [0 if i > 4 else 1 for i in data.col_47]\ndata['c27'] = [0 if i > 0.4 else 1 for i in data.col_27]\ndata['c48'] = [0 if i > 0.2 else 1 for i in data.col_48]\n\ndata['c54'] = [0 if i > 30000 else 1 for i in data.col_54]\ndata['c55'] = [0 if i > 30 else 1 for i in data.col_55]\ndata['c57'] = [1 if i > 0.005 else 0 for i in data.col_57]\ndata['c58'] = [1 if i > 0.05 else 0 for i in data.col_58]\ndata['c59'] = [1 if i > 0.05 else 0 for i in data.col_59]\n\ndata['c61'] = [1 if i > 0.1 else 0 for i in data.col_61]\ndata['c62'] = [1 if i > 0.02 else 0 for i in data.col_62]\ndata['c66'] = [1 if i > 0.01 else 0 for i in data.col_66]\ndata['c67'] = [1 if i > 0.04 else 0 for i in data.col_67]\ndata['c68'] = [1 if i > 0.1 else 0 for i in data.col_68]\ndata['c69'] = [1 if i > 0.025 else 0 for i in data.col_69]\n\ndata['c70'] = [1 if i > 0.05 else 0 for i in data.col_70]\ndata['c71'] = [1 if i > 0.05 else 0 for i in data.col_71]\ndata['c72'] = [1 if i > 0.025 else 0 for i in data.col_72]\ndata['c73'] = [1 if i > 0.01 else 0 for i in data.col_73]\ndata['c74'] = [1 if i > 0.1 else 0 for i in data.col_74]\ndata['c78'] = [1 if i > 0.05 else 0 for i in data.col_78]\ndata['c79'] = [1 if i > 0.02 else 0 for i in data.col_79]\n\ndata['c83'] = [0 if i > 0.2 else 1 for i in data.col_83]\ndata['c88'] = [0 if i > 0.005 else 1 for i in data.col_88]\n\ndata['c91'] = [0 if i > 0.3 else 1 for i in data.col_91]\ndata['c92'] = [0 if i > 0.2 else 1 for i in data.col_92]\ndata['c94'] = [1 if i > 0.05 else 0 for i in data.col_94]\ndata['c95'] = [1 if i > 0.04 else 0 for i in data.col_95]\n","4a4e66dc":"data.head()","b6d1541b":"from sklearn.model_selection import train_test_split","9dd5d7a9":"X = data.drop(['targets'],axis=1)\ny= data.targets","03c41c9a":"X_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.3,\n                                                    random_state=42)","f894a49f":"#from sklearn.preprocessing import StandardScaler","0c0a8818":"# scaler = StandardScaler()\n# scaler.fit(X_train)\n# X_train_scaled = scaler.transform(X_train)\n# X_test_scaled = scaler.transform(X_test)","054a7fcf":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n        \nknn_params = {'n_neighbors':np.arange(1,50)}\n\nnb_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n\nrf_params =  {'max_features':[1,3,10],\n              'min_samples_split':[2,3,10],\n              'min_samples_leaf':[1,3,10],\n              'bootstrap':[False],\n              'n_estimators':[100,300],\n              'criterion':['gini']}\n\ngb_params = {'learning_rate':[0.001,0.01,0.1,0.05],\n            'n_estimators':[100,500,100],\n            'max_depth':[3,5,10],\n            'min_samples_split':[2,5,10]\n    \n}\n\nparam = [rf_params,knn_params,nb_params,gb_params]","0aa6d5e8":"classifier = [RandomForestClassifier(),\n              KNeighborsClassifier(),\n              GaussianNB(),\n              GradientBoostingClassifier()\n             ]\n\nml_list = ['Random Forest','KNN','Naive Bayes','GradientBoosting']","01b79b9c":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\n\ncv_results = []\nbest_estimators = []\n\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i],\n                            param_grid=[param[i]],\n                            cv = StratifiedKFold(n_splits=5),\n                            scoring = 'roc_auc',\n                             n_jobs= -1,\n                             verbose = 1\n                        \n                            )\n    clf.fit(X_train,y_train)\n    cv_results.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print('Method: {}  Score: {} Best: {}' .format(classifier[i],cv_results[i],clf.best_estimator_))\n    \nresults = pd.DataFrame({'CV Means':cv_results,\n                       'ML Models':ml_list})","8cb41eb8":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ng = sns.barplot('CV Means','ML Models',data=results)\ng.set_title('ROC-AUC Score')\nplt.show()","673bb0b4":"from sklearn.ensemble import VotingClassifier\nvoting_c = VotingClassifier(estimators=[('rf',best_estimators[0]),\n                                        ('knn',best_estimators[1]),\n                                        ('nb',best_estimators[2]),\n                                        ('gb',best_estimators[3])\n                                       ],\n                           voting='soft',\n                           n_jobs=-1)\n\nvoting_c = voting_c.fit(X_train,y_train)\nmy_score = accuracy_score(voting_c.predict(X_test),y_test)\nprint(my_score)","aec9cee5":"<a id='10'><\/a>\n## Scaling","84993584":"<a id='1'><\/a>\n# Import Library","469cd194":"<a id='2'><\/a>\n# Load Data","e2a03fb4":"<a id='8'><\/a>\n### Feature Extraction","a48c95b1":"# Table of Contents\n1. [Import Library](#1)\n1. [Load Data](#2)\n1. [Data Analysis](#3)\n    * [Missing Value](#4)\n    * [Distribution](#5)\n1. [Feature Engineering](#6)\n    * [Analyzing](#7)\n    * [Feature Extraction](#8)\n1. [Modelling](#9)\n    * [Scaling](#10)\n    * [Parameters](#11)\n    * [Classifiers](#12)\n    * [Grid Search Cross Validation and K-Fold](#13)\n    * [Visualization](#14)\n    * [Prediction](#15)\n\n\n","0a9954bf":"<a id='13'><\/a>\n## Grid Search Cross Validation and K-Fold","2cb037bf":"<a id='7'><\/a>\n### Analyzing","56e8bdd3":"<a id='14'><\/a>\n## Visualization","442995b1":"<a id='3'><\/a>\n# Data Analysis","a3fa22c6":"<a id='4'><\/a>\n### Missing Value","4b14c601":"<a id='6'><\/a>\n# Feature Engineering","c82f1651":"<a id='5'><\/a>\n### Distribution","aef3abf5":"<a id='15'><\/a>\n## Prediction","d862be3a":"<a id='12'><\/a>\n## Classifiers","5d58be23":"#### Column List:\n   * 8-9-10-11-12-18-19-20-21-35-51-52-53-70-71 \n   \n   \nAs the features in column list has a single value, we're dropping that from dataset.","6ce3ca60":"<a id='11'><\/a>\n## Parameters","9c8340b9":"<a id='9'><\/a>\n# Modelling"}}