{"cell_type":{"ee2b6983":"code","3881933e":"code","3ff84374":"code","cfe861c5":"code","7386801b":"code","ccf8b694":"code","74b486e3":"code","f6a600fa":"code","0c10a63a":"code","a9e03f69":"code","c78639f8":"code","5f5c22b1":"code","b1a0bb98":"code","b65b1a93":"code","16120ee7":"code","92ae13af":"code","b4d0cf64":"code","2c8a1702":"code","7c5e6cc5":"code","b3d5e43c":"code","54b4d4fe":"code","cdeaa6e9":"code","9bdec2ec":"code","a40bffd0":"code","08017e4e":"code","787d74de":"code","b744ffe0":"code","354f0e12":"code","33551b8a":"code","6558d18e":"code","84699c1e":"code","418e8f4b":"markdown","44d73f31":"markdown","76f55575":"markdown","398fdecc":"markdown"},"source":{"ee2b6983":"#Title: Mrs Mr \/Married, Unmarried\/\n#Siblings\n#Parch: Ger buliin heden gishuun ywj bsn be \n# Gantsaaraa ywj bsn eseh \n#Ticket Ymar torliin tasalbar heden udaa dawtagdj bsn be freq\n# Cabin dugaar ymr negen cabinii dugaargui zorchigch bsn eseh \n#Age, Fare: Nas bolon tasalbariin uneer ni buleg bolgood Age group, Fare group gesen huwisagch uusgh ","3881933e":"import pandas as pd","3ff84374":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head()","cfe861c5":"test=pd.read_csv('..\/input\/titanic\/test.csv')\ntest.head()","7386801b":"import os \nimport warnings\nwarnings.simplefilter(action=\"ignore\")\n\n#data analysis bolon data wrangling\/bolowsruulalt\/\nimport pandas as pd\nimport numpy as np\nimport random \n\n#Data visualization\nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\n#Machine learning\nfrom sklearn import preprocessing\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold \nfrom sklearn.model_selection import train_test_split\n\n#seed everything\nseed=42\nrandom.seed(seed)\nos.environ[\"PHYTHONASHEED\"]= str(seed)\nnp.random.seed(seed)","ccf8b694":"#\u0428\u0438\u043d\u044d \u0445\u0443\u0432\u044c\u0441\u0430\u0433\u0447 \u04af\u04af\u0441\u0433\u044d\u0445 \u0444\u0443\u043d\u043a\u0446\ndef generate_features(train, test):\n\n    #Train \u0431\u043e\u043b\u043e\u043d Test data-\u0433 \u043d\u0438\u0439\u043b\u04af\u04af\u043b\u044d\u0445\n    data=pd.concat([train, test], sort=False)\n\n    #Title: \u0413\u044d\u0440\u043b\u044d\u0441\u044d\u043d \u044d\u0441\u044d\u0445 \n    data['Title']=data[\"Name\"].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n    title_names=data['Title'].value_counts()<10\n    data['Title']=data['Title'].apply(lambda x: 'Other' if title_names.loc[x] == True else x)\n    data\n\n    #Married \n    data['Is_Married']=0\n    data['Is_Married'].loc[data['Title']=='Mrs']=1\n\n    #family size \n    data['FamilySize']=data['Parch']+1\n    data\n\n    #single\n    data['Is_Alone']=1\n    data['Is_Alone'].loc[data['FamilySize']>1]=0\n\n    #Cabin   slice hiih tanigdhgu utguudig ijil nershild oruulh\n    data['Cabin'] = data['Cabin'].str.slice(stop=1).fillna('cabin_na')\n\n    #Ticket \n    data['Ticket_frequency'] = data.groupby('Ticket')['Ticket'].transform('count')\n\n    #Age, fare~ binning grouplene\n    data['Fare_Grouped'] =pd.qcut(data['Fare'],13)\n    data['Age_Grouped'] = pd.qcut(data['Age'],10)\n\n    #Torliig oorchloh~Change data type\n    data['Fare_Grouped'] =pd.qcut(data['Fare'],13)\n    data['Age_Grouped'] = pd.qcut(data['Age'],10)\n    data['Age_Grouped'] = pd.qcut(data['Age'],10).astype('object')\n    data['Fare_Grouped'] =pd.qcut(data['Fare'],13).astype('object')\n\n    #Drop some features zarim neg huwisagch ustgah \n    features_to_drop = ['Name']\n    data.drop(features_to_drop, axis=1, inplace= True)\n\n    train = data[:len(train)]\n    test = data[-len(test):]\n\n    return train, test ","74b486e3":"def preprocess_data(train, test):\n    \n    #train \u0431\u043e\u043b\u043e\u043d test data-\u0433 \u043d\u0438\u0439\u043b\u04af\u04af\u043b\u043d\u044d.\n    data= pd.concat([train, test], sort=False)\n    \n    #missing value~ \u043e\u0440\u0445\u0438\u0433\u0434\u0441\u043e\u043d \u0443\u0442\u0433\u0430 \n    data['Age']= data['Age'].fillna(data['Age'].median())\n    data['Fare']= data['Fare'].fillna(data['Fare'].median())\n    \n    #data types~ turul oorchloh \n    data['Pclass'] = data['Pclass'].astype('object')\n    \n    #one hot encoding\n    ohe_list = ['Pclass', 'Cabin', 'Embarked', 'Title']\n    ohe_features = pd.get_dummies(data[ohe_list], drop_first = True)\n    data = pd.concat([data, ohe_features], axis=1)\n    \n    #label encoding \n    for f in data.columns:\n        if data[f].dtype=='object':\n            lbl = preprocessing.LabelEncoder()\n            data[f]=lbl.fit_transform(list(data[f].astype(str)))\n    \n    train = data[:len(train)]\n    test = data[-len(test):]\n    \n    return train, test","f6a600fa":"train, test = generate_features(train, test)","0c10a63a":"train.info()","a9e03f69":"test.info()","c78639f8":"def plot_swarm_survivors(datasets, feature1, feature2, title, fsize=(155)):\n    fig, ax = plt.subplots(figsize = (18,5))\n    ax.grid(True)\n    plt.xticks(list(range(0, 100, 2)))\n    sns.swarmplot(y=feature1, x=feature2, hue='Survived', data=train).set_title(title)","5f5c22b1":"# sex, age\nplot_swarm_survivors(train, 'Sex', 'Age', 'Survivors Swarmplot Age vs Gender')","b1a0bb98":"# Title Age\nplot_swarm_survivors(train, 'Title', 'Age', 'Survivors Swarmplot Age vs Title')","b65b1a93":"#Age distributtion\ng = sns.FacetGrid(train, col='Survived', height = 6, aspect = 2)\ng = g.map(sns.distplot, 'Age', bins = 20)\n#x ni nas ali nasniihan iluu ih survived hiij bn ","16120ee7":"#Fare distribution\ng = sns.FacetGrid(train, col='Survived', height = 6, aspect = 2)\ng = g.map(sns.distplot, 'Fare', bins = 20)","92ae13af":"#Cabin vs Survival \nsns.barplot(x='Cabin', y='Survived', data=train)\nplt.show","b4d0cf64":"#Family size vs Survival\nsns.barplot(x='FamilySize', y='Survived', data=train)\nplt.show","2c8a1702":"train, test = preprocess_data(train, test)","7c5e6cc5":"train.head()","b3d5e43c":"#Correlation heatmap \ndef correlation_heatmap(df):\n    _, ax = plt.subplots(figsize = (14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(),\n        cmap = colormap, \n        square = True,\n        cbar_kws = {'shrink':.9},\n        ax = ax,\n        annot = True,\n        linewidths = 0.1, vmax = 1.0, linecolor = 'red',\n        annot_kws = {'fontsize':12}\n    )\n    plt.title('Pearson Correlation of Features', y = 1.05, size = 15)\n    \ncorrelation_heatmap(train.iloc[:,1:15])","54b4d4fe":"y=train['Survived']\nX=train.drop(['PassengerId', 'Survived'], axis=1)\nX_test=test.drop(['PassengerId', 'Survived'], axis=1)","cdeaa6e9":"X_test.info()","9bdec2ec":"X_test","a40bffd0":"params = {\n    \"n_estimators\": 500,\n    \"max_leaf_nodes\": 120,\n    \"random_state\": seed\n}","08017e4e":"#Stratified K-Fold\nnum_folds = 5\nskf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n\n#Initialize variables\ny_preds = np.zeros((len(X_test), 2))\nval_scores = []\n\nfor fold_n, (train_index, valid_index), in enumerate(skf.split(X, y)):\n    \n    #Get across validation split\n    X_train = X.iloc[train_index]\n    X_valid = X.iloc[valid_index]\n    \n    y_train = y[train_index]\n    y_valid = y[valid_index]\n    \n    #Train Random Forest model\n    clf = RandomForestClassifier(**params)\n    clf = clf.fit(X_train, y_train)\n    \n    #Validation Prediction\n    y_pred_valid = clf.predict(X_valid)\n    \n    #Importance Score\n    importances = pd.DataFrame({\"feature\": X_train.columns, \"importance\": clf.feature_importances_})\n    \n    #Evaluation the validation score\n    score = accuracy_score(y_valid, y_pred_valid)\n    val_scores.append(score)\n    print(f\"Fold {fold_n}. Accuracy Score: {score:.5f}\\n\")\n    \n    #Prediction on the Kaggle Test Data               \n    y_preds += clf.predict_proba(X_test) \/ num_folds\n    \nprint(\"Overall Accuracy Score: {:.3f}\".format(np.mean(val_scores) + np.std(val_scores)))","787d74de":"importances.sort_values(\"importance\", ascending = False)","b744ffe0":"sns.barplot(data=importances.sort_values(\"importance\", ascending=False).head(10), x=\"importance\", y=\"feature\")","354f0e12":"y_preds = np.argmax(y_preds, axis=1)\ny_preds","33551b8a":"submission = pd.DataFrame(\n{\n    \"PassengerId\": test[\"PassengerId\"],\n    \"Survived\": y_preds.astype(int)\n}\n)","6558d18e":"submission","84699c1e":"submission.to_csv(\"submission.csv\", index=False)","418e8f4b":"\u041c\u043e\u0434\u0435\u043b \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0442\u043e\u0434\u043e\u0440\u0445\u043e\u0439\u043b\u043e\u0445","44d73f31":"     ** 6. Feature engineering, data preprocessing **","76f55575":"K Fold Training & Prediction","398fdecc":"Target \u0431\u043e\u043b\u043e\u043d Features-\u0433 \u0442\u043e\u0434\u043e\u0440\u0445\u043e\u0439\u043b\u043e\u0445"}}