{"cell_type":{"8bd985d7":"code","0fa80b19":"code","d1b6a466":"code","4fc4bf67":"code","d0889fa1":"code","5215e2fc":"code","fdd88db6":"code","61974d9d":"code","62bb0b28":"code","222286f0":"code","019d56ef":"code","3683dcb1":"code","cebb5409":"code","15e7e5b9":"code","0404fa7b":"code","1152f526":"code","802829d1":"code","ff0121de":"code","4a43c37b":"code","5e5a3a3f":"code","a74d49c8":"code","083eb913":"code","5f9c3417":"code","fc703cbf":"code","19932655":"code","16c4ad39":"code","d853d0e3":"code","04801130":"code","e8a39cc7":"code","28c23e7e":"code","6e6eff81":"code","562231f8":"code","03458fb8":"code","c27a74c8":"code","b263d79b":"code","ce48b28a":"code","3573e964":"code","059e9000":"code","fb454f7e":"code","0f41ec99":"code","6d080955":"code","3330778a":"code","2e927272":"code","bf35fc80":"code","f2f74c89":"code","bb7a2e46":"code","236351a4":"code","255ecebc":"code","30037b41":"code","5d4104ba":"code","b16f4650":"code","5c916cae":"code","bb37345b":"code","1d81ac0b":"code","f20ba069":"code","77052052":"code","1f4ab57b":"code","cf0374b8":"code","711949e7":"code","3a9ec2b9":"code","919b8bbc":"code","300eb2de":"code","2cb8b748":"code","90f1050e":"code","e3683666":"code","af1e11b1":"code","e9f0ba06":"code","1eb20c0f":"markdown","e2265062":"markdown","d65088a0":"markdown","85799794":"markdown","ab9f22c0":"markdown","90a03503":"markdown","6a4ef2ad":"markdown","9f0c4998":"markdown","12611ef1":"markdown","0a48cbbd":"markdown","b362da44":"markdown","7075a46c":"markdown","4c8ded23":"markdown","0fdf2161":"markdown","b0fea8bf":"markdown","d409bae9":"markdown","9a85676d":"markdown","e203bd10":"markdown","c6b8dc88":"markdown","13795287":"markdown","75ecced3":"markdown","50a92400":"markdown","ed5f5d47":"markdown","3d1ed4f1":"markdown","df95b7ec":"markdown"},"source":{"8bd985d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0fa80b19":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport missingno as ms","d1b6a466":"train = pd.read_csv('\/kaggle\/input\/ghouls-goblins-and-ghosts-boo\/train.csv.zip')\ntrain.head()","4fc4bf67":"test = pd.read_csv('\/kaggle\/input\/ghouls-goblins-and-ghosts-boo\/test.csv.zip')\ntest.head()","d0889fa1":"sub = pd.read_csv('\/kaggle\/input\/ghouls-goblins-and-ghosts-boo\/sample_submission.csv.zip')\nsub.head()","5215e2fc":"import pandas_profiling as pp","fdd88db6":"train.shape # 371 rows of training data","61974d9d":"test.shape","62bb0b28":"train.describe()","222286f0":"report = pp.ProfileReport(train) # best way in my opinion to get started with analyzing the dataset\nreport.to_file('EDA_ghoul.html')","019d56ef":"train.columns","3683dcb1":"train.isnull().sum() # Number of null values in each column","cebb5409":"ms.matrix(train) # Good way to quickly check which columns have null values","15e7e5b9":"train.info() # gives the number of non null values and the data types of column","0404fa7b":"# Function to find the number of missing values in each column\ndef missing(df):\n    nul = {}\n    for col_i in df.columns:\n        col_nn = df[col_i].value_counts().sum()\n        tot = len(df)\n        null = tot - col_nn\n        nul[col_i] = null\n    return nul\nmissing(train)","1152f526":"# we do not need the id column for our data analysis so we drop it\ndf = train.drop('id', axis = 1)\ndf.head()","802829d1":"missing(train)['bone_length']","ff0121de":"sns.set(style = 'darkgrid')\nsns.distplot(train.bone_length, bins = 10)","4a43c37b":"bl_mean = train.bone_length.mean()\nbl_std = train.bone_length.std()\nll = bl_mean - 3*bl_std\nul = bl_mean + 3*bl_std","5e5a3a3f":"len(train[(train['bone_length'] > ul) | (train['bone_length'] < ll)])","a74d49c8":"sns.boxplot(train.type, train.bone_length)","083eb913":"missing(train)['rotting_flesh']","5f9c3417":"sns.distplot(train.rotting_flesh)","fc703cbf":"sns.boxplot(train.type, train.rotting_flesh)","19932655":"rf_mean = train.rotting_flesh.mean()\nrf_std = train.rotting_flesh.std()\nll = rf_mean - 3*rf_std\nul = rf_mean + 3*rf_std","16c4ad39":"len(train[(train['rotting_flesh'] > ul) | (train['rotting_flesh'] < ll)])","d853d0e3":"missing(train)['hair_length']","04801130":"sns.distplot(train.hair_length)","e8a39cc7":"hl_mean = train.hair_length.mean()\nhl_std = train.hair_length.std()\nll = hl_mean - 3*hl_std\nul = hl_mean + 3*hl_std","28c23e7e":"len(train[(train['hair_length'] > ul) | (train['hair_length'] < ll)])","6e6eff81":"sns.boxplot(train.type, train.hair_length)","562231f8":"missing(train)['has_soul']","03458fb8":"sns.distplot(train.has_soul)","c27a74c8":"hs_mean = train.has_soul.mean()\nhs_std = train.has_soul.std()\nll = hs_mean - 3*hs_std\nul = hs_mean + 3*hs_std","b263d79b":"len(train[(train['has_soul'] > ul) | (train['has_soul'] < ll)])","ce48b28a":"sns.boxplot(train.type, train.has_soul)","3573e964":"missing(train)['color']","059e9000":"train.color.value_counts()","fb454f7e":"train[train.type == 'Ghoul'].color.value_counts(normalize = True)","0f41ec99":"train[train.type == 'Goblin'].color.value_counts(normalize = True)","6d080955":"train[train.type == 'Ghost'].color.value_counts(normalize = True)","3330778a":"sns.countplot(train.color)","2e927272":"sns.countplot(train.color, hue = train.type)","bf35fc80":"train.type.value_counts()","f2f74c89":"c = train.corr()\nsns.heatmap(c, annot = True)","bb7a2e46":"sns.heatmap(c[(c>=0.5) | (c<=-0.4)], annot = True)","236351a4":"df.head()","255ecebc":"color_ohe = pd.get_dummies(df.color)\ncolor_ohe.head()","30037b41":"tg = pd.DataFrame()\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train.type)\ntg['target'] = le.fit_transform(train['type'])\ntg.head()","5d4104ba":"df.drop('color', axis = 1, inplace = True)\ndf.head()","b16f4650":"tr = pd.concat([df, color_ohe], axis = 1)\ntr.drop(['type'], axis = 1, inplace = True)\ntr.head()","5c916cae":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(tr, tg, test_size = 0.2)\n\nX_train.shape, X_test.shape","bb37345b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","1d81ac0b":"params = {\n    'C': [0.25, 0.5, 0.75, 1, 2],\n    'solver': ['liblinear', 'lbfgs'],\n    'penalty': ['l1', 'l2']\n}\n\nlr = LogisticRegression(max_iter = 5000)\nclf = GridSearchCV(lr, params, cv = 5)\nclf.fit(tr, tg)","f20ba069":"print('The best parameters for Logistic Regression are:',clf.best_params_)\nprint('The score is:', clf.best_score_)\n","77052052":"params = {\n    'C': [0.25, 0.5, 0.75, 1, 2],\n    'kernel': ['rbf', 'poly', 'linear']\n}\n\nsvm = SVC()\nclf = GridSearchCV(svm, params, cv = 5)\nclf.fit(tr, tg)","1f4ab57b":"print('The best parameters for svm are:',clf.best_params_)\nprint('The score is:', clf.best_score_)","cf0374b8":"params = {\n    'n_estimators': [10,20,30,50],\n    'criterion': ['gini', 'entropy']\n}\n\nrf = RandomForestClassifier()\nclf = GridSearchCV(rf, params, cv = 5)\nclf.fit(tr, tg)","711949e7":"print('The best parameters for RandomForestClassifier are:',clf.best_params_)\nprint('The score is:', clf.best_score_)","3a9ec2b9":"test.head()","919b8bbc":"t = test.drop('id', axis = 1)","300eb2de":"col_ohe = pd.get_dummies(t['color'])\nt.drop('color', axis = 1, inplace = True)\nte = pd.concat([t,col_ohe], axis = 1)\nte.head()","2cb8b748":"tr.head()","90f1050e":"lr = LogisticRegression(C = 2, solver = 'liblinear', penalty = 'l1')\nlr.fit(tr,tg)\nte_pred = lr.predict(te)","e3683666":"sub = pd.DataFrame({'id': test['id'],\n                   'type': te_pred})","af1e11b1":"sub['type'].replace({ 1: 'Ghoul',\n                    0: 'Ghost',\n                    2: 'Goblin'\n                    }, inplace = True)\nsub.head()","e9f0ba06":"sub.to_csv('submission.csv', index = False)","1eb20c0f":"The above table gives us some idea about how our training data looks like`","e2265062":"We have a nominal type of categorical variable in our dataset(color) which we will need to encode to train models for prediction\n\nas this variable is not ordinal we will use one-hot encoding to do this","d65088a0":"The above box plot shows that the bone length is an important feature to determine the type of creature we are dealing with as:\n\nGhouls tend to have longer bones than goblins which have longer bones than ghosts","85799794":"Looks like the 'bone_length' column has no outliers","ab9f22c0":"We are done with the basic EDA and the insights we obtained are:\n\n1) Ghouls tend to have longer bones than goblins which have longer bones than ghosts\n\n2) Ghosts tend to have a higher percentage of rotting flesh compared to other creatures\n\n3) Ghouls have longer hair than goblins which in turn have longer hair than Ghosts\n\n4) We see that ghost have the least amount of soul in them and Ghouls have a quite high percentage of soul\n\n5) A large proportion of creatures are either White or Transparent","90a03503":"## 1) bone_length","6a4ef2ad":"The boxplot depicts clearly that the ghouls have longer hair than goblins which have longer hair than Ghosts","9f0c4998":"The confusion matrix gives us some idea about how the different features are correlated to each other\n\nHere we do not see much correlation between features.","12611ef1":"Turns out, these beasts aren't soulless after all","0a48cbbd":"## 5) Color (Categorical)","b362da44":"## 4) Has_Soul","7075a46c":"Ghosts tend to have a higher percentage of rotting flesh compared to other creatures","4c8ded23":"## Data fields\n\nid - id of the creature\n\nbone_length - average length of bone in the creature, normalized between 0 and 1\n\nrotting_flesh - percentage of rotting flesh in the creature\n\nhair_length - average hair length, normalized between 0 and 1\n\nhas_soul - percentage of soul in the creature\n\ncolor - dominant color of the creature: 'white','black','clear','blue','green','blood'\n\ntype - target variable: 'Ghost', 'Goblin', and 'Ghoul'","0fdf2161":"The above plot gives us a clear visualization of how the different creatures are distributed across the various color categories.","b0fea8bf":"We see that ghost have the least amount of soul in them and Ghouls have a quite high percentage of soul","d409bae9":"## 3) Hair_length","9a85676d":"A large proportion of creatures are either White or Transparent","e203bd10":"## 2) rotting_flesh","c6b8dc88":"All the datasets have been loaded into their respective dataframes\n\nNow let us get started with the EDA","13795287":"### Creature wise distribution of color","75ecced3":"## 6) Type","50a92400":"No outliers in the 'rotting_flesh' column too","ed5f5d47":"We can see that the bone_length is somewhat normal\n\nmost of the creatures have the normalized length in between 0.4 to 0.6 with  less creatures having very long or very small bone length","3d1ed4f1":"The above analysis suggest that there are no missing values in the training dataset","df95b7ec":"The data was very clean in this case with no null values and no correlation between columns so the analysis was pretty simple\n\nBut that is not the case all the time."}}