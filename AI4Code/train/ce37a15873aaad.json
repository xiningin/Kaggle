{"cell_type":{"5e9c5382":"code","6151a308":"code","dcbd2264":"code","418b2280":"code","d54f0001":"code","b7cfd273":"code","efb886c8":"code","30f48bae":"code","e04f8c87":"code","0db37799":"code","aad947e2":"code","1337401c":"code","e634ea0d":"code","61055e6f":"code","db19fd33":"markdown","7bb7f6ec":"markdown","0da5ebd2":"markdown","a4d4d6ad":"markdown","960c6235":"markdown","6028ce0f":"markdown"},"source":{"5e9c5382":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6151a308":"path_to_train = '..\/input\/train\/'\ndata = pd.read_csv('..\/input\/train.csv')\n\ntrain_dataset_info = []\nfor name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)","dcbd2264":"class data_generator:\n    \n    def create_train(dataset_info, batch_size, shape, augument=True):\n        assert shape[2] == 3\n        while True:\n            random_indexes = np.random.choice(len(dataset_info), batch_size)\n            batch_images = np.empty((batch_size, shape[0], shape[1], shape[2]))\n            batch_labels = np.zeros((batch_size, 28))\n            for i, idx in enumerate(random_indexes):\n                image = data_generator.load_image(\n                    dataset_info[idx]['path'], shape)   \n                if augument:\n                    image = data_generator.augment(image)\n                batch_images[i] = image\n                batch_labels[i][dataset_info[idx]['labels']] = 1\n            yield batch_images, batch_labels\n            \n    \n    def load_image(path, shape):\n        image_red_ch = skimage.io.imread(path+'_red.png')\n        image_yellow_ch = skimage.io.imread(path+'_yellow.png')\n        image_green_ch = skimage.io.imread(path+'_green.png')\n        image_blue_ch = skimage.io.imread(path+'_blue.png')\n\n        image_red_ch += (image_yellow_ch\/2).astype(np.uint8) \n        image_green_ch += (image_yellow_ch\/2).astype(np.uint8)\n\n        image = np.stack((\n            image_red_ch, \n            image_green_ch, \n            image_blue_ch), -1)\n        image = resize(image, (shape[0], shape[1]), mode='reflect')\n        return image\n                \n            \n    def augment(image):\n        augment_img = iaa.Sequential([\n            iaa.OneOf([\n                iaa.Affine(rotate=0),\n                iaa.Affine(rotate=90),\n                iaa.Affine(rotate=180),\n                iaa.Affine(rotate=270),\n                iaa.Fliplr(0.5),\n                iaa.Flipud(0.5),\n            ])], random_order=True)\n        \n        image_aug = augment_img.augment_image(image)\n        return image_aug","418b2280":"# create train datagen\ntrain_datagen = data_generator.create_train(\n    train_dataset_info, 5, (299,299,3), augument=True)","d54f0001":"images, labels = next(train_datagen)\n\nfig, ax = plt.subplots(1,5,figsize=(25,5))\nfor i in range(5):\n    ax[i].imshow(images[i])\nprint('min: {0}, max: {1}'.format(images.min(), images.max()))","b7cfd273":"# -*- coding: utf-8 -*-\n\"\"\"SE-ResNet-50 model for Keras.\nBased on https:\/\/github.com\/fchollet\/keras\/blob\/master\/keras\/applications\/resnet50.py\n\"\"\"\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport warnings\n\nfrom keras.layers import Input\nfrom keras import layers\nfrom keras.layers import Dense\nfrom keras.layers import Activation\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Reshape\nfrom keras.layers import Multiply\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.engine.topology import get_source_inputs\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\n#from keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras_applications.imagenet_utils import _obtain_input_shape\nimport keras\nfrom keras.optimizers import Adam \n\n  \ndef identity_block(input_tensor, kernel_size, filters, stage, block):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    bn_eps = 0.0001\n        \n    block_name = str(stage) + \"_\" + str(block)\n    conv_name_base = \"conv\" + block_name\n    relu_name_base = \"relu\" + block_name\n\n    x = Conv2D(filters1, (1, 1), use_bias=False, name=conv_name_base + '_x1')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x1_bn')(x)\n    x = Activation('relu', name=relu_name_base + '_x1')(x)\n\n    x = Conv2D(filters2, kernel_size, padding='same', use_bias=False, name=conv_name_base + '_x2')(x)\n    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x2_bn')(x)\n    x = Activation('relu', name=relu_name_base + '_x2')(x)\n\n    x = Conv2D(filters3, (1, 1), use_bias=False, name=conv_name_base + '_x3')(x)\n    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x3_bn')(x)\n\n    se = GlobalAveragePooling2D(name='pool' + block_name + '_gap')(x)\n    se = Dense(filters3 \/\/ 16, activation='relu', name = 'fc' + block_name + '_sqz')(se)\n    se = Dense(filters3, activation='sigmoid', name = 'fc' + block_name + '_exc')(se)\n    se = Reshape([1, 1, filters3])(se)\n    x = Multiply(name='scale' + block_name)([x, se])\n\n    x = layers.add([x, input_tensor], name='block_' + block_name)\n    x = Activation('relu', name=relu_name_base)(x)\n    return x\n\n\ndef conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    bn_eps = 0.0001\n    \n    block_name = str(stage) + \"_\" + str(block)\n    conv_name_base = \"conv\" + block_name\n    relu_name_base = \"relu\" + block_name\n\n    x = Conv2D(filters1, (1, 1), use_bias=False, name=conv_name_base + '_x1')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x1_bn')(x)\n    x = Activation('relu', name=relu_name_base + '_x1')(x)\n\n    x = Conv2D(filters2, kernel_size, strides=strides, padding='same', use_bias=False, name=conv_name_base + '_x2')(x)\n    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x2_bn')(x)\n    x = Activation('relu', name=relu_name_base + '_x2')(x)\n\n    x = Conv2D(filters3, (1, 1), use_bias=False, name=conv_name_base + '_x3')(x)\n    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x3_bn')(x)\n    \n    se = GlobalAveragePooling2D(name='pool' + block_name + '_gap')(x)\n    se = Dense(filters3 \/\/ 16, activation='relu', name = 'fc' + block_name + '_sqz')(se)\n    se = Dense(filters3, activation='sigmoid', name = 'fc' + block_name + '_exc')(se)\n    se = Reshape([1, 1, filters3])(se)\n    x = Multiply(name='scale' + block_name)([x, se])\n    \n    shortcut = Conv2D(filters3, (1, 1), strides=strides, use_bias=False, name=conv_name_base + '_prj')(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_prj_bn')(shortcut)\n\n    x = layers.add([x, shortcut], name='block_' + block_name)\n    x = Activation('relu', name=relu_name_base)(x)\n    return x\n\n\ndef SEResNet50(include_top=True, weights='imagenet',\n               input_tensor=None, input_shape=None,\n               pooling=None,\n               classes=1000):\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=299,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    bn_eps = 0.0001\n\n    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', use_bias=False, name='conv1')(img_input)\n    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name='conv1_bn')(x)\n    x = Activation('relu', name='relu1')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n\n    x = Flatten()(x)\n    x = Dense(classes, activation='softmax', name='fc6')(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='se-resnet50')\n    return model  \nkeras.backend.clear_session()\nmodel = SEResNet50(weights=None, input_shape=(299, 299, 3), classes=28)\nmodel.summary()\n","efb886c8":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","30f48bae":"def f1(y_true, y_pred):\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f1 = 2*p*r \/ (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)","e04f8c87":"import tensorflow as tf\nmodel.compile(\n    loss='binary_crossentropy',  \n    optimizer=Adam(1e-4),\n    metrics=['acc', f1])","0db37799":"# define the checkpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom keras.models import Model\nfrom keras.applications import InceptionResNetV2\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import LambdaCallback\nfrom keras.callbacks import Callback\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport tensorflow as tf\nimport keras\n\nepochs = 100; batch_size = 16\ncheckpointer = ModelCheckpoint(\n    '..\/working\/se-resnet50.h5', \n    verbose=2, \n    save_best_only=True)\n\n# split and suffle data \nnp.random.seed(2018)\nindexes = np.arange(train_dataset_info.shape[0])\nnp.random.shuffle(indexes)\ntrain_indexes = indexes[:27500]\nvalid_indexes = indexes[27500:]\n\n# create train and valid datagens\ntrain_generator = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (299,299,3), augument=True)\nvalidation_generator = data_generator.create_train(\n    train_dataset_info[valid_indexes], 100, (299,299,3), augument=False)\n\n# train model\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    validation_data=next(validation_generator),\n    epochs=epochs, \n    verbose=1,\n    callbacks=[checkpointer])","aad947e2":"fig, ax = plt.subplots(1, 2, figsize=(15,5))\nax[0].set_title('loss')\nax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\nax[1].set_title('acc')\nax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\nax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\nax[0].legend()\nax[1].legend()","1337401c":"submit = pd.read_csv('..\/input\/sample_submission.csv')","e634ea0d":"%%time\npredicted = []\nfor name in tqdm(submit['Id']):\n    path = os.path.join('..\/input\/test\/', name)\n    image = data_generator.load_image(path, (299,299,3))\n    score_predict = model.predict(image[np.newaxis])[0]\n    label_predict = np.arange(28)[score_predict>=0.5]\n    str_predict_label = ' '.join(str(l) for l in label_predict)\n    predicted.append(str_predict_label)","61055e6f":"submit['Predicted'] = predicted\nsubmit.to_csv('submission.csv', index=False)","db19fd33":"### Create submit","7bb7f6ec":"### Load dataset info","0da5ebd2":"### Create datagenerator","a4d4d6ad":"### Train model","960c6235":"\n### Show data","6028ce0f":"### Create model"}}