{"cell_type":{"1f65df10":"code","4606f29c":"code","007ad144":"code","acbb27ad":"code","b80077d2":"code","623ae199":"code","c664a55c":"code","a6b1a4f6":"code","eee0be55":"code","fd465ada":"code","a1e78ecf":"code","c70471ec":"code","5f5fa32e":"code","1e3b7f63":"code","5379a2b5":"code","df4a146b":"code","448c7bbd":"code","4806b31f":"code","3162409c":"code","0839c4c0":"code","ed1e00ea":"code","8150998a":"code","5ceaa985":"code","53b9d299":"code","93d72fe5":"code","741abba4":"code","4fdc0a96":"code","aaa3e489":"code","3f83f5c7":"code","89adfdd3":"code","64716591":"markdown","bb97cb41":"markdown","c9104538":"markdown","ca2c489e":"markdown","145c29d5":"markdown","ccdaa0c9":"markdown","01d7f3d4":"markdown","85c96098":"markdown","e4ea1fa8":"markdown","51bf4417":"markdown","662e1f2d":"markdown","ed5e9abb":"markdown","cb358ca1":"markdown","51160630":"markdown","4a9ab54c":"markdown","106facf8":"markdown","2561fef2":"markdown","0942f17f":"markdown","4b12dd5a":"markdown","09b44d80":"markdown"},"source":{"1f65df10":"%%time\n\nimport os\nimport imageio\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nimport matplotlib.pyplot as plt\nfrom IPython import display","4606f29c":"TRAIN_DIR = '..\/input\/sartorius-cell-instance-segmentation\/train\/'\nTRAIN_CSV = '..\/input\/sartorius-cell-instance-segmentation\/train.csv'\n\nTEST_DIR = '..\/input\/sartorius-cell-instance-segmentation\/test\/'","007ad144":"train_df = pd.read_csv(TRAIN_CSV)\n\nTRAIN_IDS = train_df['id'].unique()\nWIDTH, HEIGHT = train_df.loc[0, ['width', 'height']]","acbb27ad":"def get_mask(df: str, idx: str) -> np.ndarray:\n    \"\"\"get mask for image from dataframe\n    \n    params: \n        df:  dataframe from which the mask will be taken\n        idx: mask index from dataframe\"\"\"\n    \n    parts = df[df['id'] == idx]\n    \n    mask = np.zeros(WIDTH * HEIGHT)\n    \n    for part in parts['annotation']:\n        part = part.split()\n        part = np.array(part, dtype=np.uint)\n        part = part.reshape(-1, 2)\n        part[:, 0] -=1\n        \n        for i in range(len(part)):\n            \n            part_row = part[i]\n            part_row = np.arange(part_row[0], part_row[0]+part_row[1])\n            part_row = part_row.astype(np.uint)\n            mask[part_row] = 1\n            \n    mask = mask.reshape(HEIGHT, WIDTH)\n            \n    return mask\n\ndef get_image(path: str) -> np.ndarray:\n    \"\"\"get image from the paved path\n    \n    params:\n        path: path to image\"\"\"\n    \n    img = imageio.imread(path)\n    img = np.array(img)\n    \n    return img","b80077d2":"%%time\n\ntrain_imgs = np.array([get_image(TRAIN_DIR + idx + '.png') for idx in TRAIN_IDS])\ntrain_masks = np.array([get_mask(train_df, idx) for idx in TRAIN_IDS])\n\nprint('train shape:', train_imgs.shape)\nprint('mask shape:', train_masks.shape)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(train_imgs[0], cmap=\"binary\")\nplt.imshow(train_masks[0], cmap=\"gnuplot\", alpha=0.3)","623ae199":"def split_img(img: np.ndarray, \n              size: int = 128, \n              excess: bool = True) -> np.ndarray:\n    \"\"\"get image and split it on size\n    \n    params:\n        img:  original image\n        size: size of results\"\"\"\n    \n    h_offsets = HEIGHT \/\/ size\n    w_offsets = WIDTH \/\/ size\n    \n    if excess:\n        h_excess = HEIGHT % size\n        w_excess = WIDTH % size\n    \n        h_offsets += 1 if h_excess else 0\n        w_offsets += 1 if h_excess else 0\n    \n    arr_imgs = []\n    for i in range(h_offsets):\n        for j in range(w_offsets):\n            \n            w_start, w_end = j*size, (j+1)*size\n            \n            if j == w_offsets-1 and excess:\n                w_start += w_excess - size\n                w_end += w_excess - size\n            \n            h_start, h_end = i*size, (i+1)*size\n            \n            if i == h_offsets-1 and excess:\n                h_start += h_excess - size\n                h_end += h_excess - size\n            \n            piese = img[h_start: h_end,\n                        w_start: w_end]\n        \n            arr_imgs.append(piese)\n    \n    arr_imgs = np.array(arr_imgs)[..., None]\n    \n    return arr_imgs\n\ndef view_splitimg_imgs(pieces: np.ndarray, \n                       masks: np.ndarray = np.array([]), \n                       excess: bool = True) -> None:\n    \"\"\"Show original image from its parts in the form of a grid\n    \n    params:\n        pieces: array of images that are part of a original image\n        masks:  array of masks that are part of a original mask\n        excess: allocate space for excesses\"\"\"\n    \n    size = pieces.shape[1] # 128\n    \n    cols = WIDTH \/\/ size\n    rows = HEIGHT \/\/ size\n    \n    if excess:\n        w_excess = WIDTH % size\n        h_excess = HEIGHT % size\n    \n        cols += 1 if w_excess else 0\n        rows += 1 if h_excess else 0\n\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 10))\n\n    for i in range(rows):\n        for j in range(cols):\n\n            idx = j + i*cols\n\n            ax[i, j].imshow(pieces[idx], cmap=\"binary\")\n            if len(masks) > 0:\n                ax[i, j].imshow(masks[idx], cmap=\"gnuplot\", alpha=0.3)\n            ax[i, j].axis(\"off\")\n\n    plt.subplots_adjust(wspace=0.01, hspace=0.01)","c664a55c":"%%time\n\ntrain_imgs = np.concatenate([split_img(train_imgs[i], excess=False) for i in range(len(train_imgs))], axis=0)\ntrain_masks = np.concatenate([split_img(train_masks[i], excess=False) for i in range(len(train_masks))], axis=0)\n\nprint(train_imgs.shape, train_masks.shape)\n\nview_splitimg_imgs(train_imgs, train_masks, excess=False)","a6b1a4f6":"split_by = len(train_imgs) \/\/ 10\n\ntrain_imgs, valid_imgs = train_imgs[split_by:], train_imgs[:split_by]\ntrain_masks, valid_masks = train_masks[split_by:], train_masks[:split_by]\n\nprint('train_imgs shape:', train_imgs.shape)\nprint('train_masks shape:', train_masks.shape)\n\nprint('valid_imgs shape:', valid_imgs.shape)\nprint('valid_masks shape:', valid_masks.shape)","eee0be55":"%%time\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_imgs, train_masks))\nvalid_ds = tf.data.Dataset.from_tensor_slices((valid_imgs, valid_masks))","fd465ada":"BATCH_SIZE = 1\n\ndef prep_data(img: np.ndarray, \n              mask: np.ndarray) -> tuple:\n    \"\"\"normalize pixel array -> retype pixel array\n    \n    params:\n        img:  image array\n        mask: mask array\"\"\"\n    \n    img \/= 255\n    \n    img = tf.cast(img, tf.float32)\n    mask = tf.cast(mask, tf.float32)\n    \n    return img, mask\n\ndef pipline(ds):\n    \"\"\"cache -> suffle -> preprocess -> split on batchs -> prefetch\n    \n    params:\n        ds: dataset to pipline\"\"\"\n    \n    ds = ds.cache()\n    ds = ds.shuffle(1000)\n    ds = ds.map(prep_data)\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(tf.data.AUTOTUNE)\n    \n    return ds\n\ntrain_ds = pipline(train_ds)\nvalid_ds = valid_ds.map(prep_data).batch(BATCH_SIZE)","a1e78ecf":"class UNet(tf.keras.Model):\n    \n    def __init__(self):\n        super().__init__()\n        \n        # encoder\n        self.conv_enc64_1 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        self.conv_enc64_2 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        \n        self.conv_enc128_1 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        self.conv_enc128_2 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        \n        self.conv_enc256_1 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n        self.conv_enc256_2 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n        \n        self.conv_enc512_1 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n        self.conv_enc512_2 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n        \n        self.maxpool = layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n        \n        # decoder\n        self.conv_dec1024_1 = layers.Conv2D(1024, (3, 3), padding='same', activation='relu')\n        self.conv_dec1024_2 = layers.Conv2D(1024, (3, 3), padding='same', activation='relu')\n        self.conv_transp_512 = layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', activation='relu')\n        \n        self.conv_dec512_1 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n        self.conv_dec512_2 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n        self.conv_transp_256 = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', activation='relu')\n        \n        self.conv_dec256_1 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n        self.conv_dec256_2 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n        self.conv_transp_128 = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')\n        \n        self.conv_dec128_1 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        self.conv_dec128_2 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        self.conv_transp_64 = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')\n        \n        self.conv_dec64_1 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        self.conv_dec64_2 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        \n        self.conv_final = layers.Conv2D(1, (3, 3), padding='same', activation='sigmoid')\n        \n    def call(self, x):\n        \n        # encoder\n        out = self.conv_enc64_1(x)\n        out1 = self.conv_enc64_2(out)\n        out = self.maxpool(out1)\n        \n        out = self.conv_enc128_1(out)\n        out2 = self.conv_enc128_2(out)\n        out = self.maxpool(out2)\n        \n        out = self.conv_enc256_1(out)\n        out3 = self.conv_enc256_2(out)\n        out = self.maxpool(out3)\n        \n        out = self.conv_enc512_1(out)\n        out4 = self.conv_enc512_2(out)\n        out = self.maxpool(out4)\n        \n        # decoder\n        out = self.conv_dec1024_1(out)\n        out = self.conv_dec1024_2(out)\n        out = self.conv_transp_512(out)\n        out = tf.concat([out4, out], axis=3)\n        \n        out = self.conv_dec512_1(out)\n        out = self.conv_dec512_2(out)\n        out = self.conv_transp_256(out)\n        out = tf.concat([out3, out], axis=3)\n        \n        out = self.conv_dec256_1(out)\n        out = self.conv_dec256_2(out)\n        out = self.conv_transp_128(out)\n        out = tf.concat([out2, out], axis=3)\n        \n        out = self.conv_dec128_1(out)\n        out = self.conv_dec128_2(out)\n        out = self.conv_transp_64(out)\n        out = tf.concat([out1, out], axis=3)\n        \n        out = self.conv_dec64_1(out)\n        out = self.conv_dec64_2(out)\n        \n        out = self.conv_final(out)\n        \n        return out","c70471ec":"model = UNet()\n\noptimizer = tf.keras.optimizers.Adam()\naccuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n\nloss_obj = tf.keras.losses.BinaryCrossentropy()\nloss = tf.keras.metrics.Mean()","5f5fa32e":"checkpoint_path = \".\/checkpoints\/trainUnet\"\n\nckpt = tf.train.Checkpoint(\n    model=model,\n    optimizer=optimizer\n)\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n\nif ckpt_manager.latest_checkpoint:\n    ckpt.restore(ckpt_manager.latest_checkpoint)\n    print ('Latest checkpoint restored!')","1e3b7f63":"EPOCHS = 10\n\ntrain_loss, train_accuracy = [], []\nvalid_loss, valid_accuracy = [], []\n\nvalid_batch_img, valid_batch_mask = next(valid_ds.as_numpy_iterator())","5379a2b5":"def plot_process(train_values, valid_values, figsize=(16, 4)):\n    \"\"\"plot loss or accuracy\n    \n    params:\n        train_values: array for train\n        valid_values: array for valid\n        figsize:      size of plots\"\"\"\n    \n    plt.figure(figsize=figsize)\n    plt.plot(train_values, label='train')\n    plt.plot(valid_values, label='valid')\n    plt.legend()\n    plt.show()\n    \ndef view_masks(img, mask, pred_mask, figsize=(14, 8)):\n    \"\"\"view result of training\n    \n    params:\n        img:       array of original image\n        mask:      array of original mask\n        pred_mask: array of predicted mask\n        figsize:   size of image\"\"\"\n    \n    fig, ax = plt.subplots(1, 2, figsize=figsize)\n\n    ax[0].set_title('true')\n    ax[0].imshow(img, cmap='binary')\n    ax[0].imshow(mask, cmap='gnuplot', alpha=0.3)\n\n    ax[1].set_title('pred')\n    ax[1].imshow(img, cmap='binary')\n    ax[1].imshow(pred_mask, cmap='gnuplot', alpha=0.3)\n    \n    plt.show()","df4a146b":"%%time\n\nfor epoch in range(EPOCHS):\n    print(epoch)\n    \n    for i, (train_batch_img, train_batch_mask) in enumerate(train_ds):\n\n        with tf.GradientTape() as tape:\n            train_batch_mask_pred = model(train_batch_img)\n            train_loss_value = loss_obj(train_batch_mask, train_batch_mask_pred)\n\n        gradients = tape.gradient(train_loss_value, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        loss(train_loss_value)\n        accuracy(train_batch_mask, train_batch_mask_pred)\n        \n        if i % 100 == 0:\n            valid_batch_mask_pred = model(valid_batch_img)\n\n            valid_loss_value = loss_obj(valid_batch_mask, valid_batch_mask_pred)\n\n            valid_accuracy_value = accuracy(valid_batch_mask, valid_batch_mask_pred)\n            train_accuracy_value = accuracy(train_batch_mask, train_batch_mask_pred)\n\n            print(f'{i}\\ttrain loss: {train_loss_value:.4f} | train accuracy: {train_accuracy_value:.4f} |',\n                  f'valid loss: {valid_loss_value:.4f} | valid accuracy: {valid_accuracy_value:.4f}')\n\n            train_loss.append(train_loss_value)\n            valid_loss.append(valid_loss_value)\n\n            train_accuracy.append(train_accuracy_value)\n            valid_accuracy.append(valid_accuracy_value)\n            \n        if i % 1000 == 0:\n            display.clear_output(wait=False)\n            \n            plot_process(train_accuracy, valid_accuracy, figsize=(16, 3))\n            plot_process(train_loss, valid_loss, figsize=(16, 3))\n            \n            view_masks(\n                img=valid_batch_img[0, ..., 0],\n                mask=valid_batch_mask[0, ...],\n                pred_mask=(valid_batch_mask_pred[0, ... ,0] > 0.5).numpy().astype(np.float32), \n                figsize=(12, 8)\n            )\n            \n            ckpt_manager.save()\n            print(\"checkpoint was saved\")","448c7bbd":"def prediction_test(img: np.ndarray, \n                    batch: int = 4) -> np.ndarray:\n    \n    \"\"\"predicts masks for image pieces\n    \n    params:\n        img:   array of image pieces\n        batch: number of images in batch\"\"\"\n    \n    batch_excess = len(img) % batch\n    \n    batch_count = len(img) \/\/ batch\n    batch_count += 1 if batch_excess else 0\n    \n    test_mask_preds = []\n    \n    for i in range(batch_count):\n        \n        test_batch_mask_pred = model(img[i*batch: (i+1)*batch] \/ 255)\n        test_batch_mask_pred = test_batch_mask_pred.numpy() > 0.5\n        test_batch_mask_pred = test_batch_mask_pred.astype(np.uint)\n        \n        for mask in test_batch_mask_pred:\n            test_mask_preds.append(mask)\n            \n    test_mask_preds = np.array(test_mask_preds)\n    \n    return test_mask_preds","4806b31f":"test_imgs = os.listdir(TEST_DIR)\n\ntest_img0 = np.array([get_image(TEST_DIR + test_imgs[0])])\ntest_img1 = np.array([get_image(TEST_DIR + test_imgs[1])])\ntest_img2 = np.array([get_image(TEST_DIR + test_imgs[2])])\n\nprint('test_imgs:', test_img0.shape)\n\nfig, ax = plt.subplots(1, 3, figsize=(18, 16))\n\ndef add_imshow(img: np.ndarray, idx: int, name: str) -> None:\n    ax[idx].set_title(name)\n    ax[idx].imshow(img, cmap=\"binary\")\n    ax[idx].axis(\"off\")\n    \nadd_imshow(test_img0[0], 0, test_imgs[0])\nadd_imshow(test_img1[0], 1, test_imgs[1])\nadd_imshow(test_img2[0], 2, test_imgs[2])\n\nplt.subplots_adjust(wspace=0.05, hspace=0.01)","3162409c":"test_img0 = split_img(test_img0[0], excess=True)\ntest_img1 = split_img(test_img1[0], excess=True)\ntest_img2 = split_img(test_img2[0], excess=True)\n\nprint(test_img0.shape)\n\nview_splitimg_imgs(test_img0, excess=True)","0839c4c0":"test_mask_preds0 = prediction_test(test_img0)\n\nprint(test_mask_preds0.shape)\n\nview_splitimg_imgs(test_img0, test_mask_preds0)","ed1e00ea":"test_mask_preds1 = prediction_test(test_img1)\n\nprint(test_mask_preds1.shape)\n\nview_splitimg_imgs(test_img1, test_mask_preds1)","8150998a":"test_mask_preds2 = prediction_test(test_img2)\n\nprint(test_mask_preds2.shape)\n\nview_splitimg_imgs(test_img2, test_mask_preds2)","5ceaa985":"def concat_img(pieces: np.ndarray):\n    \"\"\"Concatinate parts of image into original image\n    \n    params:\n        pieces: array of images that are part of a original image\"\"\"\n    \n    size = pieces.shape[1] # 128\n    \n    w_excess = WIDTH % size\n    h_excess = HEIGHT % size\n    \n    cols = WIDTH \/\/ size\n    rows = HEIGHT \/\/ size\n    \n    cols += 1 if w_excess else 0\n    rows += 1 if h_excess else 0\n    \n    result = []\n    for i in range(rows):\n    \n        row = pieces[i*cols:(i+1)*cols]\n\n        if w_excess:\n            half1 = np.concatenate(row[:cols-1], axis=1)\n            half2 = row[cols-1, :, size-w_excess:]\n            row = np.concatenate([half1, half2], axis=1)\n        \n        if h_excess and i == rows-1:\n            row = row[size-h_excess:]\n        \n        result.append(row)\n        \n    result = np.concatenate(result)\n    \n    return result","53b9d299":"test_img0 = concat_img(test_img0[..., 0])\ntest_mask_preds0 = concat_img(test_mask_preds0[..., 0])\n\nprint(test_img0.shape, test_mask_preds0.shape)\n\nplt.figure(figsize=(13, 11))\nplt.imshow(test_img0, cmap=\"gray\")\nplt.imshow(test_mask_preds0, cmap=\"gnuplot\", alpha=0.3)","93d72fe5":"test_img1 = concat_img(test_img1[..., 0])\ntest_mask_preds1 = concat_img(test_mask_preds1[..., 0])\n\nprint(test_img1.shape, test_mask_preds1.shape)\n\nplt.figure(figsize=(13, 11))\nplt.imshow(test_img1, cmap=\"gray\")\nplt.imshow(test_mask_preds1, cmap=\"gnuplot\", alpha=0.3)","741abba4":"test_img2 = concat_img(test_img2[..., 0])\ntest_mask_preds2 = concat_img(test_mask_preds2[..., 0])\n\nprint(test_img2.shape, test_mask_preds2.shape)\n\nplt.figure(figsize=(13, 11))\nplt.imshow(test_img2, cmap=\"gray\")\nplt.imshow(test_mask_preds2, cmap=\"gnuplot\", alpha=0.3)","4fdc0a96":"def recoding_mask(mask: np.ndarray) -> np.ndarray:\n    \"\"\"params:\n        mask: original mask\"\"\"\n    \n    mask_idx = mask.reshape(1, -1)[0]\n    mask_idx = np.nonzero(mask_idx)[0]\n    \n    result = []\n    \n    idx = 0\n    while idx < len(mask_idx):\n\n        num = mask_idx[idx]\n        lenght = 1\n\n        next_num = num + 1\n        idx += 1\n\n        while idx < len(mask_idx) and next_num == mask_idx[idx]:\n            lenght += 1\n\n            next_num += 1\n            idx += 1\n\n        result.append(num)\n        result.append(lenght)\n        \n    result = np.array(result)\n    \n    return result","aaa3e489":"test_mask_preds0 = recoding_mask(test_mask_preds0)\ntest_mask_preds1 = recoding_mask(test_mask_preds1)\ntest_mask_preds2 = recoding_mask(test_mask_preds2)","3f83f5c7":"submition = pd.DataFrame(columns=[\"id\", \"predicted\"])\nsubmition.loc[0] = [test_imgs[0][:-4], \" \".join(test_mask_preds0.astype(str))]\nsubmition.loc[1] = [test_imgs[1][:-4], \" \".join(test_mask_preds1.astype(str))]\nsubmition.loc[2] = [test_imgs[2][:-4], \" \".join(test_mask_preds2.astype(str))]\nsubmition","89adfdd3":"submition.to_csv(\"submission.csv\", index=False)","64716591":"Total 606 images in 704\u0445520 size.<br>\nLet's break these images into parts, this will increase the number of examples, and will also allow using less video memory when training the model.","bb97cb41":"## Mask encoding","c9104538":"variables from _train_df_","ca2c489e":"# Base variables\n\nPaths to files","145c29d5":"## training","ccdaa0c9":"## Preprocess test\n\nSplit original image on pieces","01d7f3d4":"## checkpoint","85c96098":"## variables for training","e4ea1fa8":"arrays in datasets","51bf4417":"preprocess datasets","662e1f2d":"View test images","ed5e9abb":"# Libs","cb358ca1":"## Concatenate results","51160630":"# Submition","4a9ab54c":"# Get images","106facf8":"# Prepocess data\n\nsplit on train & test","2561fef2":"## init training objects","0942f17f":"## Prediction test mask","4b12dd5a":"# Model","09b44d80":"# Test images\n\n## Get test images"}}