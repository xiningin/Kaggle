{"cell_type":{"c52cc75c":"code","f647d047":"code","85e58117":"code","abb63a12":"code","979d5caa":"code","6b9635da":"code","049b8053":"code","fe4671e7":"code","a6dfe6f7":"code","0c143ad1":"code","9b5d1a10":"code","e3c5aa9c":"code","3fe27a0a":"code","14cf0582":"code","e713b5f8":"markdown","fa244db3":"markdown","b12edf50":"markdown","be8be110":"markdown","efe99c8f":"markdown","720692f5":"markdown","0c6e7d12":"markdown"},"source":{"c52cc75c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f647d047":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","85e58117":"df = pd.read_csv('\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')\ndf.head()","abb63a12":"df = df.drop('Serial No.',axis=1)","979d5caa":"print(f\"Rows:{df.shape[0]}, Columns:{df.shape[1]}\")","6b9635da":"plt.figure(figsize=(16,6))\nsns.countplot(data=df,x=\"GRE Score\",saturation=1,hue='Research')\nplt.xticks(rotation=45,size=12)\nplt.grid()\nplt.tight_layout()\n\nplt.figure(figsize=(16,6))\nsns.countplot(data=df,x=\"TOEFL Score\",saturation=1,hue='Research')\nplt.xticks(rotation=45,size=12)\nplt.grid()\nplt.tight_layout()\n\nplt.figure(figsize=(16,6))\nsns.countplot(data=df,x=\"University Rating\",saturation=1,hue='Research')\nplt.xticks(rotation=45,size=12)\nplt.grid()\nplt.tight_layout()\n\nplt.figure(figsize=(16,6))\nsns.countplot(data=df,x=\"SOP\",saturation=1,hue='Research')\nplt.xticks(rotation=45,size=12)\nplt.grid()\nplt.tight_layout()\n\nplt.figure(figsize=(16,6))\nsns.countplot(data=df,x=\"LOR \",saturation=1,hue='Research')\nplt.xticks(rotation=45,size=12)\nplt.grid()\nplt.tight_layout()","049b8053":"lists = df[[\"GRE Score\",\"TOEFL Score\",\"University Rating\",\"SOP\",'LOR ','CGPA',\"Research\",\"Chance of Admit \"]]\ncorrelation = lists.corr(\"spearman\")\n\nplt.figure(figsize=(12,6))\nplt.plot(correlation[\"Chance of Admit \"][:7])\nplt.title(\"Correlation Values with 'Chance of Admit'\")\nplt.ylabel(\"Correlation\")\nplt.grid()\nplt.tight_layout()\n\nmodel = ExtraTreesRegressor() \nmodel.fit(df.iloc[:,:-1],df.iloc[:,-1])\nfeat_impt = pd.Series(model.feature_importances_, index = df.iloc[:,:-1].columns) \n\nplt.figure(figsize=(12,6))\nfeat_impt.nlargest(7).plot(kind='barh')\nplt.title(\"Feature most Important\")\nplt.grid()\nplt.tight_layout()\nplt.show()","fe4671e7":"y = df['Chance of Admit ']\nX = df.drop('Chance of Admit ', axis=1)","a6dfe6f7":"scaler = MinMaxScaler()\nX =scaler.fit_transform(X)","0c143ad1":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=1)","9b5d1a10":"lr = LinearRegression()\ndtr = DecisionTreeRegressor(random_state=1)\nrf = RandomForestRegressor(n_estimators=300, random_state=1)\n\nlr.fit(X_train,y_train)\ndtr.fit(X_train,y_train)\nrf.fit(X_train,y_train)","e3c5aa9c":"lr_pred = lr.predict(X_test)\ndtr_pred = dtr.predict(X_test)\nrf_pred = rf.predict(X_test)","3fe27a0a":"lr_acc = r2_score(y_test,lr_pred)\nlr_rmse = mean_squared_error(y_test,lr_pred)**0.5\ndtr_acc = r2_score(y_test,dtr_pred)\ndtr_rmse = mean_squared_error(y_test,dtr_pred)**0.5\nrf_acc = r2_score(y_test,rf_pred)\nrf_rmse = mean_squared_error(y_test,rf_pred)**0.5","14cf0582":"print(\"Accuracy for Linear Regression is {:.2%}\".format(lr_acc))\nprint(\"Accuracy for Decision Tree Regression is {:.2%}\".format(dtr_acc))\nprint(\"Accuracy for Random Forest Regression is {:.2%}\".format(rf_acc))\n\nprint()\n\nprint(\"RMSE for Linear Regression is {:.2}\".format(lr_rmse))\nprint(\"RMSE for Decision Tree Regression is {:.2}\".format(dtr_rmse))\nprint(\"RMSE for Random Forest Regression is {:.2}\".format(rf_rmse))","e713b5f8":"## Results","fa244db3":"## Feature Importance","b12edf50":"## Model Building","be8be110":"CGPA is the most important key for getting Admission in college","efe99c8f":"## data Visualization","720692f5":"## Importing Data","0c6e7d12":"The best model is Linear Regression"}}