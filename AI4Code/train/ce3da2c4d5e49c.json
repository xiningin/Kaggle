{"cell_type":{"2051b170":"code","44b26623":"code","882aad6d":"code","3ba809e0":"code","1e1cfc58":"code","3dafe0d3":"code","ca2e97c9":"code","6fb57cbf":"code","fd9bcfbd":"code","26f5fa66":"code","97e0ae2e":"code","c689c1cc":"code","7acbde2d":"code","c631294d":"code","19c72788":"code","1c2c8760":"code","19a839d8":"code","c0d86f47":"code","3781b0d8":"code","74f56a48":"code","b42a08f8":"code","044f5fe3":"code","39c0f348":"code","758916d4":"code","0aa57ec3":"code","3435e0ee":"code","feb30a41":"code","6b624cf0":"code","e919fbbd":"code","d576d527":"code","d714a03e":"code","021b247e":"code","662a8b98":"code","434e74a2":"code","8b66649e":"code","396a9dec":"code","9f033e93":"code","6fd22ac7":"markdown","ebdd419a":"markdown","02c2ea50":"markdown","24ba2bc7":"markdown","83005f6d":"markdown","3cb80650":"markdown","7ecc852f":"markdown","be51b9f6":"markdown","169684ba":"markdown","918a5b71":"markdown","5116962e":"markdown","c6e63612":"markdown","fba7bfc5":"markdown","80a57760":"markdown"},"source":{"2051b170":"# all needed imports here\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nimport tensorflow_addons as tfa\n\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport cv2\nimport itertools\nimport os\nimport shutil\nimport glob\nimport random\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n%matplotlib inline\n\n\n# checking if GPU is enabled in Kaggle notebook\/available\nhardware_list = tf.config.list_physical_devices(\n    device_type=None\n)\n\nprint(hardware_list)\n\ngpu_test = tf.test.is_gpu_available(\n    cuda_only=False, min_cuda_compute_capability=None\n)\nprint(\"GPU Available:\", gpu_test)","44b26623":"# checking how many files\/samples are in each class\npath = '..\/input\/diabetic-retinopathy-resized-arranged\/4'\nnum_files = len([f for f in os.listdir(path)\n                if os.path.isfile(os.path.join(path, f))])\n# print(num_files)\n\n\"\"\"\nNUMBER OF FILES IN EACH CLASS\n\n0 - 25810\n1 - 2443\n2 - 5294\n3 - 873\n4 - 708\n\"\"\"","882aad6d":"# PREPROCESSING PARAMS\nTRAIN_SIZE = 700\nTEST_SIZE = 700\nVALID_SIZE = 700","3ba809e0":"\"\"\"\n- creating the different sets with respective percentages\n- NOTE: dataset is imbalanced, used a fixed size of 700 for each set\n\"\"\"\n\noriginal_data_path = \"..\/input\/diabetic-retinopathy-resized-arranged\"\n# train_pct = 0.7\n# test_pct = 0.1\n# valid_pct = 0.2\n\nos.chdir(\".\/\")\nif os.path.isdir(\"train\/0\") is False:\n    # create folders for the sets\n    os.mkdir(\".\/train\")\n    os.mkdir(\".\/test\")\n    os.mkdir(\".\/valid\")\n    \n    # move X number of instances from original set, to respective sets\n    for i in range(0, 5):\n        # path to inputs with different classes\n        num_folder_path = f'{original_data_path}\/{i}' \n        num_files_in_folder = len(os.listdir(num_folder_path))\n#         train_size = int(num_files_in_folder * train_pct)\n#         test_size = int(num_files_in_folder * test_pct)\n#         valid_size = int(num_files_in_folder * valid_pct)\n        train_size = TRAIN_SIZE\n        test_size = TEST_SIZE\n        valid_size = VALID_SIZE\n        \n        # make classes within set\n        os.mkdir(f'train\/{i}')\n        os.mkdir(f'test\/{i}')\n        os.mkdir(f'valid\/{i}')\n        \n        test_samples = random.sample(os.listdir(num_folder_path), test_size)\n        for file_name in test_samples:\n            shutil.copy((f\"..\/input\/diabetic-retinopathy-resized-arranged\/{i}\/{file_name}\"), f'.\/test\/{i}')\n\n        train_samples = random.sample(os.listdir(num_folder_path), train_size)\n        for file_name in train_samples:\n            shutil.copy((f\"..\/input\/diabetic-retinopathy-resized-arranged\/{i}\/{file_name}\"), f'.\/train\/{i}')\n            \n        valid_samples = random.sample(os.listdir(num_folder_path), valid_size)\n        for file_name in valid_samples:\n            shutil.copy((f\"..\/input\/diabetic-retinopathy-resized-arranged\/{i}\/{file_name}\"), f'.\/valid\/{i}')\n        ","1e1cfc58":"# train,test, and valid set paths\nTRAIN_PATH = \".\/train\"\nTEST_PATH = \".\/test\"\nVALID_PATH = \".\/valid\"","3dafe0d3":"# preprocessing\/augmentation for ImageDataGenerator\ndef preprocesser(image):\n    image= tf.image.adjust_contrast(image, 0.6)\n    image = tfa.image.equalize(image)\n    image = tf.image.rgb_to_grayscale(image)\n    return image","ca2e97c9":"# generating sets\nPREPROCESSING_FUNC = preprocesser\nCLASS_MODE = \"categorical\"\nBATCH_SIZE = 32\n\ntrain_batches = ImageDataGenerator(preprocessing_function = PREPROCESSING_FUNC, rescale=1.\/255, horizontal_flip=True).flow_from_directory(directory = TRAIN_PATH, target_size = (224,224), batch_size = BATCH_SIZE, class_mode=CLASS_MODE)\ntest_batches = ImageDataGenerator(preprocessing_function = PREPROCESSING_FUNC, rescale=1.\/255).flow_from_directory(directory = TEST_PATH, target_size = (224,224), batch_size = BATCH_SIZE, class_mode=CLASS_MODE, shuffle=False)\nvalid_batches = ImageDataGenerator(preprocessing_function = PREPROCESSING_FUNC, rescale=1.\/255).flow_from_directory(directory = VALID_PATH, target_size = (224,224), batch_size = BATCH_SIZE, shuffle = False, class_mode=CLASS_MODE)","6fb57cbf":"# checking if ImageDataGenerator assigned proper labels\ntrain_batches.labels","fd9bcfbd":"# what the inputs\/images look like after augmentation\n\nplt.figure()\nf, axarr = plt.subplots(1,3)\nfor i in range (0,3):\n    random_num = random.randint(0,100)\n    image = train_batches[random_num]\n    axarr[i].imshow(image[0][0])\n    print(np.shape(image[0][0])) # 224x224x3, needed to put into MobileNetV2","26f5fa66":"# MODEL PARAMS - change here\nNUM_EPOCH = 50\nLEARNING_RATE = 0.001\nFREEZE_LAYERS = -6\nLOSS_FUNC = \"categorical_crossentropy\"\nTRAIL_NUM = 1\nSECOND_PASS = False # change to True when fine tuning after training new output layer\nPATIENCE = 25","97e0ae2e":"# importing MobileNetv2 - original, excluding the final\/output layer\nmodel = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(224,224,3), include_top=False)\nmodel.summary()","c689c1cc":"for layer in model.layers: # originally 23\n    layer.trainable = SECOND_PASS # should be False on first run ","7acbde2d":"# adding new output layer to MobileNetV2, specific to our problem\nx = Flatten()(model.output)\noutput = Dense(units=5, activation=\"softmax\")(x) # 5 units for, 1 for each class","c631294d":"model = Model(inputs = model.input, outputs = output)","19c72788":"model.summary()","1c2c8760":"# number of training params in MobileNetV2 model with new output layer\ntrainable_params_freeze = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\nnon_trainable_params_freeze = np.sum([np.prod(v.get_shape()) for v in model.non_trainable_weights])\nprint(f\"trainable params: {trainable_params_freeze}\\nnon trainable params: {non_trainable_params_freeze}\")","19a839d8":"model.compile(optimizer=Adam(lr=LEARNING_RATE), loss=LOSS_FUNC, metrics=[\"accuracy\"])","c0d86f47":"# early stopping enabled, controlled with PATIENCE variable\nmodel.fit_generator(train_batches, validation_data=valid_batches, epochs=NUM_EPOCH, verbose=2, callbacks=EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True))","3781b0d8":"# # MODEL PARAMS - second pass\n# NUM_EPOCH = 5\n# LEARNING_RATE = 0.0001\n# TRAIL_NUM = 2","74f56a48":"# for layer in model.layers[:FREEZE_LAYERS]:\n#     layer.trainable = True","b42a08f8":"# model.compile(optimizer=Adam(lr=0.0001), loss=LOSS_FUNC, metrics=[\"accuracy\"])","044f5fe3":"# model.fit(x=train_batches, validation_data=valid_batches, epochs=5, verbose=2)","39c0f348":"# can save model after first or second run \nSAVE_LOC = f'.\/trial{TRAIL_NUM}'","758916d4":"model.save(SAVE_LOC, save_format=\"h5\")","0aa57ec3":"# only needed if training, use after training\n\nplt.plot(model.history.history['accuracy'])\nplt.plot(model.history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","3435e0ee":"# only needed if training, use after training\n\nplt.plot(model.history.history['loss'])\nplt.plot(model.history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","feb30a41":"# proper labels \nproper_labels = {\n    0: \"no DR\",\n    1: \"Mild\",\n    2: \"Moderate\",\n    3: \"Severe\",\n    4: \"Proliferative DR\"\n}","6b624cf0":"# get actual class of a single instance\n\ndef actual_class(img_path):\n    path = os.path.dirname(img_path)\n    class_num = path[-1]\n    real_class = proper_labels.get(int(class_num))\n    return (real_class, class_num)","e919fbbd":"# loading already trained model via path\ntrained_model_path = \"..\/input\/final-model\/good\"\nloaded_model = keras.models.load_model(trained_model_path)","d576d527":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","d714a03e":"# evaluation -> loss, acc (from keras)\ntest_eval = loaded_model.evaluate(test_batches, verbose=0)\nprint(f'test loss, test acc: {test_eval}')","021b247e":"# prediction -> confusion matrix (custom function)\npredictions = loaded_model.predict(test_batches, verbose=0)","662a8b98":"test_labels = test_batches.classes\ncm = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))","434e74a2":"cm_plot_labels = [\"0\", \"1\", \"2\", \"3\", \"4\"]\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title=\"Confusion Matrix\")","8b66649e":"from sklearn.metrics import accuracy_score, recall_score, precision_score\n\npred_arr = predictions.argmax(1)\n\ntest_acc = accuracy_score(y_true=test_labels, y_pred=pred_arr)\ntest_recall = recall_score(y_true=test_labels, y_pred=pred_arr, average=\"macro\")\ntest_precision = precision_score(y_true=test_labels, y_pred=pred_arr, average=\"macro\")\n\nprint(f'acc: {test_acc}, recall: {test_recall}, precision: {test_precision}')","396a9dec":"from sklearn.metrics import roc_curve, auc, f1_score\ntest_f1_score = f1_score(test_labels, pred_arr, average=\"macro\")\n\nfpr, tpr, thresholds = roc_curve(test_labels, pred_arr, pos_label=0) # auc for class 0\ntest_auc = auc(fpr, tpr)\n\nprint(f'AUC: {test_auc}')","9f033e93":"# removing all models from current kernel\n# keras.backend.clear_session()","6fd22ac7":"## saving model ","ebdd419a":"# Performance Evaluations","02c2ea50":"# Load existing model","24ba2bc7":"trained 30 epoch model, no need to train again. Unless tweaks are made to params","83005f6d":"## preprocessing functions","3cb80650":"## confusion matrix for test set ","7ecc852f":"# EDA","be51b9f6":"must create test set before running the following cells","169684ba":"## SECOND PASS\/FINE TUNING","918a5b71":"# Model Building","5116962e":"* cannot do percentage splits to make training\/valid\/test sets because the original dataset is imbalanced\n    * will be dominated by class 0 instances in all sets\\\n* resort to fixed sizes","c6e63612":"## model training -> train then save","fba7bfc5":"## FIRST PASS\/TRANSFER LEARNING","80a57760":"# Creating train, test, and validation sets + Preprocessing"}}