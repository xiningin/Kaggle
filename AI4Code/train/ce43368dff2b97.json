{"cell_type":{"7010364f":"code","2241a04d":"code","987d6a2a":"code","edbdd516":"code","4c0f087d":"code","eb17409b":"code","c99bc8ee":"code","ae5fa72f":"code","5805c1ec":"code","cd708c8d":"code","3b4b42cd":"code","df4bac35":"code","294b8eec":"code","43f3cb6b":"code","c0c77218":"code","2df68b40":"code","49e2c7c1":"code","491e58d0":"code","a5d5d5a8":"code","fb2049e5":"code","11fe1ecc":"code","43218255":"code","3066d38f":"code","186d7639":"code","bcba8416":"code","f40c3028":"markdown","2db6f11b":"markdown","a8bdc95c":"markdown","5e5c33f2":"markdown","9f636721":"markdown","ff44df99":"markdown","0b840cb8":"markdown","2f8f82d8":"markdown","2d348953":"markdown","e01030f5":"markdown","9d98b8f5":"markdown","069bf9f3":"markdown","945a793a":"markdown","ba751285":"markdown","c78683aa":"markdown","57b7f7e3":"markdown","eb59e230":"markdown","1f78b84c":"markdown","79232a05":"markdown","41ff0de7":"markdown","c7ecb9c9":"markdown","29a4245a":"markdown","dfbff120":"markdown"},"source":{"7010364f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Markdown, Latex\n\nsns.set_style('whitegrid')\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection\nfrom sklearn.cluster import KMeans\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.metrics import f1_score\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2241a04d":"df = pd.read_csv(\"\/kaggle\/input\/german-credit-data-with-risk\/german_credit_data.csv\", index_col=0)\ndf.head()","987d6a2a":"df.info()","edbdd516":"display(Markdown(\"#### Explore the Values of Text Columns:\"))\ncols = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Risk']\nfor col in cols:\n    line = \"**\" + col + \":** \"\n    for v in df[col].unique():\n        line = line + str(v) + \", \"\n    display(Markdown(line))","4c0f087d":"# label encode account quality and fill NaN with 0\ndef SC_LabelEncoder(text):\n    if text == \"little\":\n        return 1\n    elif text == \"moderate\":\n        return 2\n    elif text == \"quite rich\":\n        return 3\n    elif text == \"rich\":\n        return 4\n    else:\n        return 0\n\ndf[\"Saving accounts\"] = df[\"Saving accounts\"].apply(SC_LabelEncoder)\ndf[\"Checking account\"] = df[\"Checking account\"].apply(SC_LabelEncoder)","eb17409b":"# label encode account quality and fill NaN with 0\ndef H_LabelEncoder(text):\n    if text == \"free\":\n        return 0\n    elif text == \"rent\":\n        return 1\n    elif text == \"own\":\n        return 2\n\ndf[\"Housing\"] = df[\"Housing\"].apply(H_LabelEncoder)","c99bc8ee":"fig, ax = plt.subplots(1,2,figsize=(15,5))\nsns.histplot(df, x='Age', bins=30, hue=\"Sex\", ax=ax[0]).set_title(\"Age\/Sex Distribution\");\nsns.boxplot(data=df, x=\"Sex\", y=\"Age\", ax=ax[1]).set_title(\"Age\/Sex Distribution\");\n\nfig, ax = plt.subplots(1,2,figsize=(15,5))\nsns.boxplot(data=df, x='Risk', y='Age', ax=ax[0]).set_title(\"Age Distribution with Risk\");\nsns.countplot(data=df, x=\"Sex\", hue=\"Risk\", ax=ax[1]).set_title(\"Sex Distribution with Risk\");","ae5fa72f":"fig, ax = plt.subplots(1,2,figsize=(15,5))\nsns.histplot(df, x='Credit amount', bins=30, ax=ax[0]).set_title(\"Credit Amount (in Deutsch Mark) Distribution\");\nsns.histplot(df, x='Duration', bins=30, ax=ax[1]).set_title(\"Duration (in month) Distribution\");\n\nfig, ax = plt.subplots(1,2,figsize=(15,5))\nsns.boxplot(data=df, x='Risk', y='Credit amount', ax=ax[0]).set_title(\"Credit Amount (in Deutsch Mark) Distribution with Risk\");\nsns.boxplot(data=df, x='Risk', y='Duration', ax=ax[1]).set_title(\"Duration (in month) Distribution with Risk\");","5805c1ec":"fig, ax = plt.subplots(1,2, figsize=(15,5))\nsns.countplot(data=df, x=\"Job\", hue=\"Risk\", ax=ax[0]).set_title(\"Job Distribution with Risk\");\nsns.countplot(data=df, x=\"Housing\", hue=\"Risk\", ax=ax[1]).set_title(\"Housing Distribution with Risk\");","cd708c8d":"fig, ax = plt.subplots(1,2, figsize=(15,5))\nsns.countplot(data=df, x=\"Saving accounts\", hue=\"Risk\", ax=ax[0]).set_title(\"Saving Account Quality Distribution with Risk\");\nsns.countplot(data=df, x=\"Checking account\", hue=\"Risk\", ax=ax[1]).set_title(\"Checking Account Quality Distribution with Risk\");","3b4b42cd":"sns.pairplot(df[['Age', 'Job', 'Housing', 'Saving accounts', \n                 'Checking account', 'Credit amount', 'Duration', \"Risk\"]], hue=\"Risk\");","df4bac35":"corr = df[['Age', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Credit amount', 'Duration']].corr()\nsns.set(rc={'figure.figsize':(11,7)})\nsns.heatmap(corr,linewidths=.5, annot=True, cmap=\"YlGnBu\",mask=np.triu(np.ones_like(corr, dtype=np.bool)))\\\n    .set_title(\"Pearson Correlations Heatmap\");","294b8eec":"# use LabelEncoder() to encode other categorical columns:\nfor col in [\"Sex\", \"Purpose\", \"Risk\"]:\n    le = LabelEncoder()\n    le.fit(df[col])\n    df[col] = le.transform(df[col])\ndf.head()","43f3cb6b":"cdf = df.drop(\"Risk\", axis=1)","c0c77218":"inertias = []\n\nfor i in range(2,16):\n    kmeans = KMeans(n_clusters=i, random_state=0).fit(cdf)\n    inertias.append(kmeans.inertia_)\n\nplt.figure(figsize=(10,5))\nplt.title('Inertias v.s. N_Clusters')\nplt.plot(np.arange(2,16),inertias, marker='o', lw=2);","2df68b40":"km = KMeans(n_clusters=4, random_state=0)\nclusters = km.fit_predict(cdf)","49e2c7c1":"df_clustered = cdf[['Age', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Credit amount', 'Duration']]\ndf_clustered[\"Cluster\"] = clusters\nsns.pairplot(df_clustered[['Age', 'Job', 'Housing', 'Saving accounts', \n                 'Checking account', 'Credit amount', 'Duration', \"Cluster\"]], hue=\"Cluster\");","491e58d0":"km = KMeans(n_clusters=2, random_state=0)\nclusters = km.fit_predict(cdf)","a5d5d5a8":"display(Markdown(\"In encoded Risk column, good = 1 and bad = 0, but the predicted clusters 0 and 1 does not have the same meaning. Thus, whether the predicted clusters is equal or opposite to the given risk, the higher TRUE percentage will be the accuracy rate.\"))\nacc = max((sum(clusters == df[\"Risk\"]) \/ len(df)), (sum(clusters != df[\"Risk\"]) \/ len(df)))\ndisplay(Markdown(\"The accuracy rate of 2-Means clustering is \" + str(acc)))","fb2049e5":"X, y = df.drop(\"Risk\", axis=1), df[\"Risk\"]\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state=0)","11fe1ecc":"max_score = 0\nmax_k = 0\nfor k in range(1, 100):\n    neigh = KNeighborsClassifier(n_neighbors=k)\n    neigh.fit(X_train,y_train)\n    score = f1_score(y_test, neigh.predict(X_test))\n    if score > max_score:\n        max_k = k\n        max_score = score\n\ndisplay(Markdown(\"If use K-Nearest Neighbors Classification, the k should be \" + str(max_k) + \" to get best prediction, and then the  mean accuracy is \" + str(max_score)))","43218255":"# define models\nModels = {\n    \"SVC\": SVC(),\n    \"DecisionTree\": DecisionTreeClassifier(),\n    \"RandomForest\": RandomForestClassifier(),\n    \"GaussianNaiveBayes\": GaussianNB()\n}","3066d38f":"cv_results = pd.DataFrame(columns=['model', 'train_score', 'test_score'])\nfor key in Models.keys():\n    cv_res = model_selection.cross_validate(Models[key], X_train, y_train, \n                                             return_train_score=True,\n                                             scoring=\"f1\",\n                                             cv=5, n_jobs=-1)\n    res = {\n        'model': key, \n        'train_score': cv_res[\"train_score\"].mean(), \n        'test_score': cv_res[\"test_score\"].mean(),\n        'fit_time': cv_res[\"fit_time\"].mean(),\n        'score_time': cv_res[\"score_time\"].mean(),\n        }\n    cv_results = cv_results.append(res, ignore_index=True)\n    print(\"CV for model:\", key, \"done.\")\ncv_results","186d7639":"rf = Models[\"RandomForest\"].fit(X_train, y_train)\nprint('f1_score:', f1_score(y_test, rf.predict(X_test)))","bcba8416":"feature_importance = pd.DataFrame()\nfeature_importance[\"feature\"] = X_train.columns\nfeature_importance[\"importance\"] = rf.feature_importances_\nfeature_importance = feature_importance.sort_values(\"importance\", ascending=False)\nfeature_importance","f40c3028":"**Analysis:** \n- Most of people in records have job skill level 2, but the job skill level does not affect the risk rating much.\n- People who own a house means low risk and good rating to the bank.","2db6f11b":"### 4.2 Cluster the data to Two Group and Compare with Given Good\/Bad Risk Rating\nUse K-means to cluster people in the records into 2 group and check if the result closed to given two risk groups.","a8bdc95c":"### 5.2 Modeling by Other Classifiers\nSince KNN algorithm cost lots of memory and time for prediction, this section want to try some more classifiers.\n#### Model Selection with Cross Validate","5e5c33f2":"#### Feature Importance Discussion","9f636721":"## 5. Predicting the Risk\n**Based on given Risk column**","ff44df99":"#### Evaluate Model on Testing Set\n- Random Forest Classifier gives a good result on both train_score and test_score.\n- SVC and Gaussian Naive Bayes show the less over-fiting.\n- Gaussian Naive Bayes Classifier has least runtime.\n- Random Forest Classifier would tell feature importances, while SVC only return coef_ in the case of a linear kernel, which will be too slow.\n\n**Taking all this into consideration, Random Forest Classifier is chose to evaluate on testing set:**","0b840cb8":"**Analysis:** Compare the matrix in EDA, this 4-clustered matrix plot show a clearer grouping boundaries than the given Good\/Bad Risk rating.","2f8f82d8":"**Analysis** (since 0 means unknown, only discuss quality level 1 to 4):\n- The person with more saving means less risk to the bank, but most people in the records have little saving (not rich!)\n- About half of people who have little checking account are considered as bad rating in risk.\n- About 20% of people who have moderate checking account are considered as bad rating in risk.","2d348953":"There are missing values in columns \"Saving accounts\" and \"Checking accounts\".","e01030f5":"From above exploration:\n- Columns \"Housing\", \"Saving accounts\" and \"Checking accounts\" are **Ordinal** data.    \n- Columns \"Sex\", \"Purpose\" and \"Risk\" are **Categorical** data.    ","9d98b8f5":"## 0. Loading and Understanding the Dataset","069bf9f3":"**Analysis:** The \"elbow\" in above chart is indicated  at 4. The number of clusters chosen should therefore be 4. \n#### With 4 Clusters:","945a793a":"## 2. EDA","ba751285":"Known from Content in the dataset page, column \"Job\" is **Ordinal** data that:\n- 0 - unskilled and non-resident, \n- 1 - unskilled and resident, \n- 2 - skilled, \n- 3 - highly skilled\n\nSO, apply the save logic to other **Ordinal** columns \"Housing\", \"Saving accounts\" and \"Checking accounts\".\n\nFor \"Saving accounts\" and \"Checking accounts\":\n- 0 - missing value, as UNKNOWN \n- 1 - little\n- 2 - moderate\n- 3 - quite rich\n- 4 - rich\n\nFor \"Housing\":\n- 0 - free\n- 1 - rent\n- 2 - own","c78683aa":"**Analysis:** \n- Age does not affect the risk rating much. \n- Males take more count of credit from Bank.\n- Males have lower percentage of bad rating than woman.","57b7f7e3":"## 4. Clustering","eb59e230":"## 3. Data Pre-processing For Discrete Categorical Columns","1f78b84c":"#### Start with applying Elbow Method.","79232a05":"**Analysis:** The higher credit amount and longer duration means higher risk to the bank.","41ff0de7":"**Analysis:** The Credit Amount is HIGHLY and POSITIVELY related to the Duration.","c7ecb9c9":"### 4.1 Find the Best Number of Clusters for K-Means and Analysis","29a4245a":"### 5.1 K-Nearest Neighbors Classification","dfbff120":"## 1. Data Pre-processing For Ordinal Columns"}}