{"cell_type":{"09acdfbd":"code","a643e91f":"code","e987c879":"code","b713741f":"code","59481016":"code","b365c02f":"code","68491a24":"code","0dd2fb64":"code","f0453817":"code","c464db48":"code","9fe3f3f3":"code","8a441b74":"code","315d51b9":"code","4b78dd1b":"code","38ab33a3":"code","5c5f0ecb":"code","c8c808cd":"code","2a588d5d":"code","09084bfe":"code","28eb5d3a":"code","6af79c55":"code","1fede112":"code","11b9d1c4":"code","ddee0e07":"code","cc14f3a6":"code","11bb4c63":"code","76143c0e":"code","15fc05bd":"code","d5a3e0d9":"code","ef792916":"code","89d4ddd2":"code","9a8a786c":"code","092b0f3e":"code","2529028b":"code","37e9637e":"code","3de1d759":"code","4ea11fc0":"code","68b0478c":"code","55d33e61":"code","43542dd3":"code","b53f1552":"code","99a3dd62":"code","ee40f146":"code","b9420c60":"code","48e3c591":"code","df2eaf54":"code","d8bb4c94":"code","924df984":"code","59145be8":"code","1e3190a7":"code","4629c284":"code","1c568349":"code","48146b5d":"code","a282e427":"code","a896b08f":"code","2b3e02a9":"code","2ec3c3ee":"code","d3b819e0":"code","3612cb00":"code","181b2319":"code","66023ea1":"code","12885250":"code","313c158a":"code","6b0274c4":"code","5b42bf37":"code","4f299ed1":"code","a73f15fd":"code","6430a322":"code","1da9d344":"code","c120612f":"code","6b37c515":"code","c5b70d22":"code","aa345dee":"code","e60d6acf":"code","c394f4b7":"code","8711bf10":"code","4a3686f7":"code","1032ea3e":"code","4c957e6a":"code","256df160":"code","98c99436":"code","e30b1042":"code","53d40d73":"code","f56524b2":"code","d2115620":"code","7df5053e":"markdown","578866a3":"markdown","77209b1a":"markdown","9074f2a3":"markdown"},"source":{"09acdfbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a643e91f":"# !pip install pydotplus","e987c879":"store = pd.read_csv(\"\/kaggle\/input\/rossmann-store-sales\/store.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/rossmann-store-sales\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/rossmann-store-sales\/test.csv\",parse_dates=[3])","b713741f":"train.shape","59481016":"train.head()","b365c02f":"test.shape","68491a24":"test.head()","0dd2fb64":"store.head()","f0453817":"train.info()","c464db48":"train.describe()","9fe3f3f3":"train.describe()[['Sales','Customers']].loc['min']","8a441b74":"train.describe()[['Sales','Customers']].loc['max']","315d51b9":"#  no. of stores\ntrain.Store.nunique()","4b78dd1b":"train['Store'].value_counts().head(50).plot.bar()","38ab33a3":"train.DayOfWeek.value_counts()","5c5f0ecb":"train.Open.value_counts()","c8c808cd":"train.isna().sum()","2a588d5d":"test.isnull().sum()","09084bfe":"#date wise line plot for sales\ntrain['Date'] = pd.to_datetime(train['Date'],format = '%Y-%m-%d')\nstore_id = train.Store.unique()[0]\nprint(store_id)\nstore_rows = train[train['Store'] == store_id]\nprint(store_rows.shape)\nstore_rows.resample('1D',on = 'Date')['Sales'].sum().plot.line(figsize = (18,8))","28eb5d3a":"#missing values on days\nstore_rows[store_rows['Sales']==0]","6af79c55":"# checking the same for test data\ntest['Date'] = pd.to_datetime(test['Date'],format = '%Y-%m-%d')\nstore_test_rows = test[test['Store'] == store_id]\nprint(store_test_rows.shape)\nstore_test_rows['Date'].min(), store_test_rows['Date'].max()","1fede112":"store_rows['Sales'].plot.hist(figsize = (14,8))","11b9d1c4":"## Store data\nstore.isnull().sum()","ddee0e07":"store.head()","cc14f3a6":"store[store['Store']==store_id].T # here store id was 1","11bb4c63":"# checking the non null values in store data to make sure what we can fill in the missing values\nstore[~store['Promo2SinceYear'].isna()].iloc[0]","76143c0e":"#method 1\nstore['Promo2SinceWeek'].fillna(0,inplace = True)\nstore['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode()[0],inplace = True)\nstore['PromoInterval'].fillna(store['PromoInterval'].mode()[0],inplace = True)","15fc05bd":"store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode()[0],inplace = True)\nstore['CompetitionDistance'].fillna(store['CompetitionDistance'].max(),inplace = True)\nstore['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode()[0],inplace = True)\nstore.isnull().sum()","d5a3e0d9":"# merge the data train and store\ndata_merged = train.merge(store,on = 'Store',how = 'left')\nprint(train.shape)\nprint(data_merged.shape)\nprint(data_merged.isnull().sum().sum()) # cross check if there are any missing values","ef792916":"## Encoding\n# 3 categorical columns, 1 date column, rest are numerical\ndata_merged.dtypes","89d4ddd2":"data_merged['day'] = data_merged['Date'].dt.day\ndata_merged['month'] = data_merged['Date'].dt.month\ndata_merged['year'] = data_merged['Date'].dt.year\n#data_merged['weekday'] = data_merged['Date'].dt.strftime(%a)  This is already in data","9a8a786c":"# stateHoliday, StoreType, Assortment, PromoInterval\ndata_merged['StateHoliday'].unique()","092b0f3e":"data_merged['StateHoliday'] = data_merged['StateHoliday'].map({'a':1,'b':2,'c':3,'0':0,0:0})\ndata_merged['StateHoliday'] = data_merged['StateHoliday'].astype(int)","2529028b":"pd.set_option('display.max_columns',None)\ndata_merged.head()","37e9637e":"data_merged['Assortment'] = data_merged['Assortment'].map({'a':1,'b':2,'c':3})\ndata_merged['Assortment'] = data_merged['Assortment'].astype(int)","3de1d759":"data_merged['StoreType'] = data_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ndata_merged['StoreType'] = data_merged['StoreType'].astype(int)","4ea11fc0":"map_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ndata_merged['PromoInterval'] = data_merged['PromoInterval'].map(map_promo)","68b0478c":"from sklearn.model_selection import train_test_split","55d33e61":"features = data_merged.columns.drop(['Sales','Date'])\nX = data_merged[features]\ny = np.log(data_merged['Sales']+1)\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","43542dd3":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error","b53f1552":"model_dt  = DecisionTreeRegressor(max_depth = 20, random_state = 42).fit(X_train,y_train)\ny_pred = model_dt.predict(X_test)","99a3dd62":"r2_score(y_test,y_pred)","ee40f146":"mean_squared_error(y_test,y_pred)","b9420c60":"np.sqrt(mean_squared_error(y_test,y_pred))","48e3c591":"def draw_tree(model, columns):\n    import pydotplus\n    from sklearn.externals.six import StringIO\n    from IPython.display import Image\n    import os\n    from sklearn import tree\n    \n    graphviz_path = 'C:\\Program Files (x86)\\Graphviz2.38\/bin\/'\n    os.environ[\"PATH\"] += os.pathsep + graphviz_path\n\n    dot_data = StringIO()\n    tree.export_graphviz(model,\n                         out_file=dot_data,\n                         feature_names=columns)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n    return Image(graph.create_png())","df2eaf54":"# draw_tree(model_dt,X.columns)y","d8bb4c94":"def ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1.\/(y[ind]**2)\n    return w\n\ndef rmspe(y, yhat):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe","924df984":"y_inv = np.exp(y_test)-1\ny_pred_inv = np.exp(y_pred)-1\nnp.sqrt(mean_squared_error(y_inv,y_pred_inv))","59145be8":"rmspe(y_inv,y_pred_inv)","1e3190a7":"test.head()","4629c284":"# import matplotlib.pyplot as plt\n# plt.figure(figsize = (18,8))\n# plt.bar(X,model_dt.feature_importances_)","1c568349":"train_avg_cust = train.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)\ntest_1 = test.merge(train_avg_cust,on = 'Store',how = 'left')\ntest.shape,test_1.shape","48146b5d":"test_1.head()","a282e427":"test_merged = test_1.merge(store,on = 'Store',how = 'left')\ntest_merged['Open'] = test_merged['Open'].fillna(1)\ntest_merged['Date'] = pd.to_datetime(test_merged['Date'],format = '%Y-%m-%d')\ntest_merged['day'] = test_merged['Date'].dt.day\ntest_merged['month'] = test_merged['Date'].dt.month\ntest_merged['year'] = test_merged['Date'].dt.year\ntest_merged['StateHoliday'] = test_merged['StateHoliday'].map({'0':0,'a':1})\ntest_merged['StateHoliday'] = test_merged['StateHoliday'].astype(int)\ntest_merged['Assortment'] = test_merged['Assortment'].map({'a':1,'b':2,'c':3})\ntest_merged['Assortment'] = test_merged['Assortment'].astype(int)\ntest_merged['StoreType'] = test_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ntest_merged['StoreType'] = test_merged['StoreType'].astype(int)\nmap_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ntest_merged['PromoInterval'] = test_merged['PromoInterval'].map(map_promo)\n\n","a896b08f":"# test_pred = model_dt.predict(test_merged[features])\n# test_pred_inv = np.exp(test_pred)-1\n","2b3e02a9":"'''\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n'''","2ec3c3ee":"# rf = RandomForestRegressor(n_jobs = -1)\n# param_grid = { \n#         \"n_estimators\"      : [10,50,100],\n#         \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n#         \"min_samples_split\" : [2,4],\n#         \"bootstrap\": [True, False],\n#         \"max_depth\" : [5,10,20]\n#         }\n\n# grid = GridSearchCV(estimator = rf,param_grid = param_grid, cv=3)\n\n# grid.fit(X_train, y_train)\n\n# grid.best_score_ , grid.best_params_\n","d3b819e0":"## Hyperparameter Tuning\n\n'''\ndef get_rmspe_score(input_values,y_actual):\n    y_predicted = model.predict(input_values)\n    y_actual = np.exp(y_actual)-1\n    y_predicted = np.exp(y_predicted)-1\n    score = rmspe(y_actual,y_predicted)\n\n\nparams = {'max_depth': list(range(5,40))}\nbase_model = DecisionTreeRegressor()\ncv_model = GridSearchCV(base_model,param_grid = params,cv = 5,return_train_score=True,scoring = get_rmspe_score).fit(X_train,y_train)\n\npd.DataFrame(cv_model.cv_results)\n'''","3612cb00":"# cv_model.best_params_","181b2319":"# df_cv_results = pd.DataFrame(cv_model.cv_results_)","66023ea1":"# df_cv_results","12885250":"# df_cv_results[df_cv_results['param_max_depth']==11].T","313c158a":"# import matplotlib.pyplot as plt\n# df_cv_results = pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score',ascending=False)\n# df_cv_results.set_index('param_max_depth')['mean_test_score'].plot.line()\n# df_cv_results.set_index('param_max_depth')['mean_train_score'].plot.line()\n# plt.show()","6b0274c4":"# rf = RandomForestRegressor()\n# rf.fit(X_train,y_train)\n# y_pred = rf.predict(X_test)\n# y_inv = np.exp(y_test)-1\n# y_pred_inv = np.exp(y_pred)-1\n# np.sqrt(mean_squared_error(y_inv,y_pred_inv))\n# test_pred = rf.predict(test_merged[features])\n# test_pred_inv = np.exp(test_pred)-1\n","5b42bf37":"features = data_merged.columns.drop(['Sales','Customers','Date'])\nX = data_merged[features]\ny = np.log(data_merged['Sales']+1)\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","4f299ed1":"model_dt  = DecisionTreeRegressor(max_depth = 12, random_state = 1).fit(X_train,y_train)\ny_pred = model_dt.predict(X_test)","a73f15fd":"y_inv = np.exp(y_test)-1\ny_pred_inv = np.exp(y_pred)-1\nnp.sqrt(mean_squared_error(y_inv,y_pred_inv))","6430a322":"rmspe(y_inv,y_pred_inv)","1da9d344":"test_pred = model_dt.predict(test_merged[features])\ntest_pred_inv = np.exp(test_pred)-1","c120612f":"# from sklearn.ensemble import AdaBoostRegressor\n# model_ada = AdaBoostRegressor(n_estimators=5).fit(X_train[features],y_train)","6b37c515":"# draw_tree(model_ada.estimators_[3],features)","c5b70d22":"import xgboost as xgb","aa345dee":"dtrain = xgb.DMatrix(X_train[features],y_train)\ndtest = xgb.DMatrix(X_test[features],y_test)\n\nparams = {'max_depth':8,'eta':0.3,'objective':'reg:linear','subsample': 0.7,\"colsample_bytree\": 0.7,\n         \"silent\": 1}\nmodel_xg = xgb.train(params,dtrain, 300)\ny_pred = model_xg.predict(dtest)\n\ny_inv = np.exp(y_test) -1\ny_pred_inv = np.exp(y_pred) - 1\nrmspe_val = rmspe(y_inv, y_pred_inv)\nprint(rmspe_val)","e60d6acf":"# X_train.head()","c394f4b7":"testdmatrix = xgb.DMatrix(test_merged[X_train.columns])","8711bf10":"y_predlog = model_xg.predict(testdmatrix)\n\n\ny_pred_anti = np.exp(y_predlog) - 1","4a3686f7":"y_pred_anti\n","1032ea3e":"# test_merged[features].head()","4c957e6a":"test.head()","256df160":"test['Sales'] = y_pred_anti","98c99436":"sl = []\nfor i in range(len(y_pred_anti)):\n    if i in test[test['Open'] == 0].index:\n        sl.append(0)\n    else:\n        sl.append(test['Sales'][i])\n    ","e30b1042":"test['Sales'] = sl\n# X_train.head()","53d40d73":"# sl\ntest.head()","f56524b2":"submission_predicted = pd.DataFrame({'Id' : test['Id'],'Sales':test['Sales']})\n\nsubmission_predicted.head(10)\n","d2115620":"submission_predicted.to_csv('submission.csv',index = False)","7df5053e":"## taking the test data","578866a3":"### Train and Validate split just to check the accuracy we can get after final model we will make we will use test data","77209b1a":"## Model Building Decision Trees","9074f2a3":"### Missing values treatment"}}