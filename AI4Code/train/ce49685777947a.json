{"cell_type":{"1a7eb577":"code","da7331c1":"code","5010fd53":"code","ca630753":"code","ab26021a":"code","ddb9aa85":"code","525b1a6d":"code","d81b27dd":"code","1ee4a1b1":"code","84ad8d0f":"code","43fa6c7f":"code","770c9ceb":"code","2899adba":"code","88d9591a":"code","c2d8e74d":"code","2fa7cd17":"code","9a6d0e07":"code","a76ce88d":"code","d59890c5":"code","d9865256":"code","293420c6":"code","cb3b3def":"code","25ecff98":"markdown","be6a7f43":"markdown"},"source":{"1a7eb577":"import numpy as np\nimport pandas as pd \nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nimport gc","da7331c1":"df = pd.read_csv('..\/input\/openimagevallabel\/validation-annotations-human-imagelabels.csv', usecols=[0,2,3])\ndf = df[df.Confidence == 1]\nclasses = np.array(['\/m\/01g317', '\/m\/09j2d', '\/m\/04yx4', '\/m\/0dzct', '\/m\/07j7r', '\/m\/05s2s', '\/m\/03bt1vf', '\/m\/07yv9', '\/m\/0cgh4', '\/m\/01prls', \n                    '\/m\/09j5n', '\/m\/0jbk', '\/m\/0k4j', '\/m\/05r655', '\/m\/02wbm', '\/m\/0c9ph5', '\/m\/083wq', '\/m\/0c_jw', '\/m\/03jm5', '\/m\/0d4v4']) \nli = []\nfor i in classes:\n    li.append(df[df.LabelName == i])\ndf = pd.concat(li).sample(frac=1).reset_index(drop=True)\ndel li\ngc.collect()\ndf.head()","5010fd53":"labels = df.LabelName.tolist()\nImageid = df.ImageID.values\nprint(len(df))","ca630753":"from keras.preprocessing.image import load_img, img_to_array\nfrom keras.layers import Dense, Conv2D, PReLU, BatchNormalization, MaxPooling2D, Dropout, Flatten\nimport keras\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras.models import load_model, Sequential\nfrom tqdm import tqdm_notebook\nfrom tqdm import tqdm","ab26021a":"df.head(),gc.collect()","ddb9aa85":"X_train = [np.array(load_img('..\/input\/open-image-val\/validation\/validation\/{}.jpg'.format(i),target_size=(100,100), grayscale=True))\/255 for i in tqdm(Imageid[10000:20000])]","525b1a6d":"X_Val = [np.array(load_img('..\/input\/open-image-val\/validation\/validation\/{}.jpg'.format(i),target_size=(100,100), grayscale=True))\/255 for i in tqdm(Imageid[:2000])]","d81b27dd":"#Y_train = labels[10000:20000]\n#Y_Val = labels[:2000]\nclasses = classes.tolist()\nY_train, Y_Val = [], []\nfor i in tqdm(labels[10000:20000]):\n    temp = np.zeros(20)\n    temp[classes.index(i)] = 1\n    Y_train.append(temp)\n    del temp\nfor i in tqdm(labels[:2000]):\n    temp = np.zeros(20)\n    temp[classes.index(i)] = 1\n    Y_Val.append(temp)\n    del temp\nY_train = np.array(Y_train)\nY_Val = np.array(Y_Val)\ngc.collect(), Y_train[0]","1ee4a1b1":"nn = Sequential()\nnn.add(BatchNormalization(input_shape=(100, 100, 1)))\nnn.add(Conv2D(4, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Conv2D(8, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nnn.add(Conv2D(16, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Conv2D(32, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nnn.add(Conv2D(64, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nnn.add(Conv2D(64, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Flatten())\nnn.add(Dense(2048))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Dense(1024))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Dense(512))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Dense(128))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Dense(50))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Dense(16))\nnn.add(PReLU())\nnn.add(BatchNormalization(momentum=0.94))\nnn.add(Dropout(0.5))\nnn.add(Dense(20, activation='softmax'))","84ad8d0f":"nn.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'], optimizer='adam')\nnn.summary()","43fa6c7f":"X_train = np.array(X_train).reshape((10000,100,100,1))\nX_Val = np.array(X_Val).reshape((2000,100,100,1))","770c9ceb":"gc.collect()","2899adba":"nn.fit(X_train, Y_train, validation_data=(X_Val,Y_Val), batch_size=200, epochs=100, verbose=2)","88d9591a":"del X_train, Y_train, X_Val, Y_Val, df\ngc.collect()","c2d8e74d":"df = pd.read_csv('..\/input\/inclusive-images-challenge\/stage_1_sample_submission.csv', usecols=[0])\nim = df.image_id.tolist()\ndf.head()","2fa7cd17":"X_test = [np.array(load_img('..\/input\/inclusive-images-challenge\/stage_1_test_images\/{}.jpg'.format(i),target_size=(100,100), grayscale=True))\/255 for i in tqdm_notebook(im)]","9a6d0e07":"X_test = np.array(X_test).reshape((32580,100,100,1))","a76ce88d":"pre = nn.predict(X_test).argsort(1)[:,:5]\ndel X_test\ngc.collect()","d59890c5":"p = []\nfor it in tqdm(pre):\n    p.append(' '.join([classes[int(i)] for i in it]))","d9865256":"df['labels'] = p\ndf.head()","293420c6":"df.to_csv('sub.csv', index=False)","cb3b3def":"!cat sub.csv","25ecff98":"## If you find this kernel helpful, please upvote it.\n## If you have any questions or suggestions please let me know.","be6a7f43":"# CNN with 20 Classes trained on Open Image Validation Set"}}