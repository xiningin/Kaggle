{"cell_type":{"d1f42f08":"code","ea36ec46":"code","31a15189":"code","60da10c3":"code","b1bc5fcc":"code","2b41ae83":"code","aa0e0102":"code","be90749d":"code","0067ace8":"code","e7d8fe35":"code","183a669c":"code","cc6eed5d":"code","cf0345a3":"code","08eef963":"code","1b9d2953":"code","f4559aec":"code","9090d4d7":"code","ace2e223":"code","14658a4f":"code","de96e7b4":"code","e5404dd3":"code","1aeb6bc2":"code","dbebdcbf":"code","b16f8df9":"code","6bf54503":"code","921c4de1":"code","8a5e86a5":"code","744af344":"code","ff202456":"code","23ddb490":"code","c3ec41d4":"code","f93a220a":"code","26ec277e":"code","0ace0784":"code","72a905d9":"code","719daf78":"code","6511e65a":"code","05f023f4":"code","a1402623":"code","62cf9736":"code","99057a0d":"code","29c52246":"code","9879edd4":"code","31528b5e":"code","3fa0986b":"code","ca8a0f8a":"code","178eadd2":"code","66e37655":"code","dd14bbf9":"code","c490f3c0":"code","77fc6938":"code","70327879":"code","aca39721":"code","6a89d81a":"markdown","120f5964":"markdown","a28334c1":"markdown","1a785063":"markdown","28704cd2":"markdown","3f17d263":"markdown","0088e94a":"markdown","edf1ff9b":"markdown","b65a8eb8":"markdown","259befe2":"markdown","5753f459":"markdown","3a084db5":"markdown","7b94a11a":"markdown","dacbacb7":"markdown","dbc6f1b9":"markdown","daa4d654":"markdown","922e1e78":"markdown","3df6a76e":"markdown","58a010b2":"markdown","86bc5f30":"markdown","2d151f2d":"markdown","faaaa821":"markdown","4840a8e8":"markdown","3eaae85e":"markdown","d8078164":"markdown","95f84c66":"markdown","e7a03f3d":"markdown","1134d561":"markdown","3a65bba3":"markdown","99a3ae2d":"markdown","49f497d8":"markdown","b360a421":"markdown","30e883f6":"markdown"},"source":{"d1f42f08":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea36ec46":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom scipy.stats import skew, norm, boxcox_normmax\nfrom scipy.special import boxcox1p\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline","31a15189":"# loading train and test data\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","60da10c3":"print(\"Train Shape:\",train.shape)\nprint(\"Test Shape:\",test.shape)","b1bc5fcc":"train.head()","2b41ae83":"train.info()","aa0e0102":"train.describe().T","be90749d":"\nplt.figure(figsize=(20,20))\nsns.heatmap(train.corr(), cmap=\"coolwarm\")\nplt.show()","0067ace8":"#SalePrice\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x=train.SalePrice,color=\"#bf9e7e\")\n\nplt.show()","e7d8fe35":"# YearBuilt and SalePrice\n\nplt.figure(figsize=(12,8))\nsns.regplot(train.YearBuilt , train.SalePrice, \n            scatter_kws={\"color\":\"#824155\"}, \n            line_kws={\"linewidth\":3, \"color\": \"#6ca19e\" ,\"label\":\"Mean Sale Price\"},\n            label=\"Sale Price\")\nplt.style.use(\"fivethirtyeight\")\nplt.title(\"YearBuilt and SalePrice\")\nplt.xlabel(\"YearBuilt\")\nplt.ylabel(\"SalePrice\")\nplt.legend()\nplt.show()","183a669c":"# OverallQual and SalePrice  \n# YearBuily and OverallQual\n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x = train.YearBuilt, y=train.SalePrice , hue=train.OverallQual , palette=\"tab10\", label=\"OverallQual\")\n\nplt.title(\"OverallQual by YearBuilt and SalePrice\")\nplt.legend(loc=\"upper left\")\nplt.show()","cc6eed5d":"# Fireplaces Counts\n\nplt.figure(figsize=(8,8))\n\nplt.pie(train.groupby(\"Fireplaces\")[\"SalePrice\"].count() , \n        colors=[\"#427555\",\"#45A0AD\",\"#C27FBA\",\"#7D1F52\"],\n       labels=train.Fireplaces.unique(),\n       shadow=True, wedgeprops={'edgecolor': 'black'}, autopct='%1.1f%%',explode=(0.1, 0, 0, 0.0))\n\nplt.title(\"Counts of Fireplaces\")\nplt.show()","cf0345a3":"# Fireplaces and SalePrice\n\nplt.figure(figsize=(12,8))\n\nsns.barplot(x = train.Fireplaces , y=train.SalePrice, palette=[\"#427555\",\"#45A0AD\",\"#C27FBA\",\"#7D1F52\"])\n\nplt.title(\"Fireplaces and SalePrice\")\nplt.show()","08eef963":"# GrLivArea and SalePrice\n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x=train.GrLivArea, y=train.SalePrice ,hue=train.OverallQual, palette=\"icefire\")\n\nplt.title(\"GrLivArea and SalePrice\")\nplt.legend()\nplt.show()","1b9d2953":"# GarageArea and SalePrice\n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x=train.GarageArea, y=train.SalePrice, palette=\"icefire\", color=\"#4a8591\")\n\nplt.title(\"GarageArea and SalePrice\")\nplt.show()","f4559aec":"train_num_cols = train.select_dtypes(exclude=[\"object\"]).columns\ntrain_cat_cols = train.select_dtypes(include=[\"object\"]).columns\n\ntest_num_cols = test.select_dtypes(exclude=[\"object\"]).columns\ntest_cat_cols = test.select_dtypes(include=[\"object\"]).columns","9090d4d7":"train[train_num_cols].isnull().sum().sort_values(ascending=False)[:10]","ace2e223":"train[train_num_cols].isnull().sum().sort_values(ascending=False)[:10] \/ len(train[train_num_cols])","14658a4f":"train[\"LotFrontage\"].fillna(train[\"LotFrontage\"].mean(), inplace=True)\n\ntrain[\"GarageYrBlt\"].fillna(train[\"GarageYrBlt\"].mean(), inplace=True)\n\ntrain[\"MasVnrArea\"].fillna(train[\"MasVnrArea\"].mean(), inplace=True)\n\nprint(\"Train num cols missin value:\",train[train_num_cols].isnull().sum().sort_values(ascending=False)[:10])","de96e7b4":"test[test_num_cols].isnull().sum().sort_values(ascending=False)","e5404dd3":"test[test_num_cols].isnull().sum().sort_values(ascending=False) \/ len(test[test_num_cols])","1aeb6bc2":"test[\"LotFrontage\"].fillna(test[\"LotFrontage\"].mean(), inplace=True)\ntest[\"GarageYrBlt\"].fillna(test[\"GarageYrBlt\"].mean(), inplace=True)\ntest[\"MasVnrArea\"].fillna(test[\"MasVnrArea\"].mean(), inplace=True)\ntest[\"BsmtHalfBath\"].fillna(test[\"BsmtHalfBath\"].mean(), inplace=True)\ntest[\"BsmtFullBath\"].fillna(test[\"BsmtFullBath\"].mean(), inplace=True)\ntest[\"BsmtFinSF2\"].fillna(test[\"BsmtFinSF2\"].mean(), inplace=True)\ntest[\"GarageCars\"].fillna(test[\"GarageCars\"].mean(), inplace=True)\ntest[\"GarageArea\"].fillna(test[\"GarageArea\"].mean(), inplace=True)\ntest[\"TotalBsmtSF\"].fillna(test[\"TotalBsmtSF\"].mean(), inplace=True)\ntest[\"BsmtUnfSF\"].fillna(test[\"BsmtUnfSF\"].mean(), inplace=True)\ntest[\"BsmtFinSF1\"].fillna(test[\"BsmtFinSF1\"].mean(), inplace=True)","dbebdcbf":"train[train_cat_cols].isnull().sum().sort_values(ascending=False)[:20] \/ len(train[train_cat_cols])","b16f8df9":"train.drop([\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\"], axis=1, inplace=True)","6bf54503":"train[\"FireplaceQu\"].fillna(\"Gd\", inplace=True)\ntrain[\"GarageCond\"].fillna(\"Ta\", inplace=True)\ntrain[\"GarageQual\"].fillna(\"Ta\", inplace=True)\ntrain[\"GarageFinish\"].fillna(\"Unf\", inplace=True)\ntrain[\"GarageType\"].fillna(\"Attchd\", inplace=True)\ntrain[\"BsmtCond\"].fillna(\"TA\", inplace=True)\ntrain[\"BsmtQual\"].fillna(\"TA\", inplace=True)\ntrain[\"BsmtExposure\"].fillna(\"No\", inplace=True)\ntrain[\"BsmtFinType2\"].fillna(\"Unf\", inplace=True)\ntrain[\"BsmtFinType1\"].fillna(\"Unf\", inplace=True)\ntrain[\"MasVnrType\"].fillna(\"None\", inplace=True)\ntrain[\"MSZoning\"].fillna(\"RL\", inplace=True)\ntrain[\"Utilities\"].fillna(\"AllPub\", inplace=True)\ntrain[\"Functional\"].fillna(\"Typ\", inplace=True)\ntrain[\"Exterior2nd\"].fillna(\"VinylSd\", inplace=True)\ntrain[\"KitchenQual\"].fillna(\"TA\", inplace=True)\ntrain[\"Electrical\"].fillna(\"SBrkr\", inplace=True)","921c4de1":"test[test_cat_cols].isnull().sum().sort_values(ascending=False)[:23]","8a5e86a5":"test.drop([\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\"], axis=1, inplace=True)","744af344":"test[\"Exterior1st\"].value_counts()","ff202456":"test[\"FireplaceQu\"].fillna(\"Gd\", inplace=True)\ntest[\"GarageCond\"].fillna(\"TA\", inplace=True)\ntest[\"GarageQual\"].fillna(\"TA\", inplace=True)\ntest[\"GarageFinish\"].fillna(\"Unf\", inplace=True)\ntest[\"GarageFinish\"].fillna(\"Unf\", inplace=True)\ntest[\"GarageType\"].fillna(\"Attchd\", inplace=True)\ntest[\"BsmtCond\"].fillna(\"TA\", inplace=True)\ntest[\"BsmtQual\"].fillna(\"TA\", inplace=True)\ntest[\"BsmtExposure\"].fillna(\"No\", inplace=True)\ntest[\"BsmtFinType2\"].fillna(\"Unf\", inplace=True)\ntest[\"BsmtFinType1\"].fillna(\"GLQ\", inplace=True)\ntest[\"MasVnrType\"].fillna(\"None\", inplace=True)\ntest[\"MSZoning\"].fillna(\"RL\", inplace=True)\ntest[\"Utilities\"].fillna(\"AllPub\", inplace=True)\ntest[\"Functional\"].fillna(\"Typ\", inplace=True)\ntest[\"Exterior2nd\"].fillna(\"VinylSd\", inplace=True)\ntest[\"KitchenQual\"].fillna(\"TA\", inplace=True)\ntest[\"SaleType\"].fillna(\"WD\", inplace=True)\ntest[\"Exterior1st\"].fillna(\"VinylSd\", inplace=True)","23ddb490":"test.isnull().sum()","c3ec41d4":"train_cat_cols = train.select_dtypes(include=[\"object\"]).columns\ntest_cat_cols = test.select_dtypes(include=[\"object\"]).columns\n\ntrain = pd.get_dummies(train, columns = train_cat_cols, drop_first=True)\ntest = pd.get_dummies(test, columns = test_cat_cols, drop_first=True)","f93a220a":"skew_cols = train[train_num_cols].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_cols[skew_cols > 0.5]\nprint(high_skew)\n\nskew_index = high_skew.index\n\n# Normalize skewed features\ntrain[skew_index] = np.log1p(train[skew_index])","26ec277e":"skew_cols = test[test_num_cols].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_cols[skew_cols > 0.5]\nprint(high_skew)\n\nskew_index = high_skew.index\n\n# Normalize skewed features\ntrain[skew_index] = np.log1p(train[skew_index])","0ace0784":"train.info()","72a905d9":"test.info()","719daf78":"train_id = train[\"Id\"]\ntest_id = test[\"Id\"]\n\ntrain.drop(\"Id\", axis=1, inplace=True)\ntest.drop(\"Id\", axis=1, inplace=True)","6511e65a":"y = train[\"SalePrice\"]\n\nX = train[test.columns]","05f023f4":"from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\n\nX = scaler.fit_transform(X)","a1402623":"scaler=StandardScaler()\n\ntest_cols = test.columns\ntest = scaler.fit_transform(test)\ntest = pd.DataFrame(test, columns=test_cols)\n\ntest.head()","62cf9736":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=9)","99057a0d":"from sklearn.metrics import mean_squared_error","29c52246":"from sklearn.linear_model import LinearRegression\n\n# Linear Regression with Default Parameters\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n\n# Predict values\ny_pred = lr.predict(X_test)\n\nprint(\"RMSE of Linear Regression (Default Parameters): %.2f\"%np.sqrt(mean_squared_error(y_test, y_pred)))","9879edd4":"plt.figure(figsize=(8,8))\nsns.regplot(y_test, y_pred, scatter_kws=dict(color=\"#7583EA\"), line_kws=dict(color=\"#9EA2C1\", linewidth=3))\nplt.title(\"Linear Regression Actual vs Predict Train Data\")\nplt.xlabel(\"Actual Value\")\nplt.ylabel(\"Predicit Value\")\nplt.show()","31528b5e":"from sklearn.tree import DecisionTreeRegressor\n\n# Decision Tree with Default Parameters\ndt_reg = DecisionTreeRegressor()\ndt_reg.fit(X_train, y_train)\n\ny_pred = dt_reg.predict(X_test)\n\nprint(\"RMSE of DT Regressor (Default Parameters): \",np.sqrt(mean_squared_error(y_test, y_pred)))","3fa0986b":"plt.figure(figsize=(8,8))\nsns.regplot(y_test, y_pred, scatter_kws=dict(color=\"#68813C\"), line_kws=dict(color=\"#C7D134\", linewidth=3))\nplt.title(\"DT Regressor Actual vs Predict Train Data\")\nplt.xlabel(\"Actual Value\")\nplt.ylabel(\"Predicit Value\")\nplt.show()","ca8a0f8a":"from sklearn.ensemble import RandomForestRegressor\n\n# RandomForestRegressor with Default Parameters\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train, y_train)\n\ny_pred = rf_reg.predict(X_test)\n\nprint(\"RMSE of RF Regressor (Default Parameters): \",np.sqrt(mean_squared_error(y_test, y_pred)))","178eadd2":"plt.figure(figsize=(8,8))\nsns.regplot(y_test, y_pred, scatter_kws=dict(color=\"#A22F59\"), line_kws=dict(color=\"#9F3C96\", linewidth=3))\nplt.title(\"RF Regressor Actual vs Predict Train Data\")\nplt.xlabel(\"Actual Value\")\nplt.ylabel(\"Predicit Value\")\nplt.show()","66e37655":"from sklearn.ensemble import GradientBoostingRegressor\n\n# RandomForestRegressor with Default Parameters\ngb_reg = GradientBoostingRegressor()\ngb_reg.fit(X_train, y_train)\n\ny_pred = gb_reg.predict(X_test)\n\nprint(\"RMSE of GB Regressor (Default Parameters): \",np.sqrt(mean_squared_error(y_test, y_pred)))","dd14bbf9":"plt.figure(figsize=(8,8))\nsns.regplot(y_test, y_pred, scatter_kws=dict(color=\"#6F2BA7\"), line_kws=dict(color=\"#A590B8\", linewidth=3))\nplt.title(\"GB Regressor Actual vs Predict Train Data\")\nplt.xlabel(\"Actual Value\")\nplt.ylabel(\"Predicit Value\")\nplt.show()","c490f3c0":"import xgboost\n\nxgb_reg = xgboost.XGBRegressor()\n\nxgb_reg.fit(X_train, y_train)\n\ny_pred = xgb_reg.predict(X_test)\n\nprint(\"RMSE of GB Regressor (Default Parameters): \",np.sqrt(mean_squared_error(y_test, y_pred)))","77fc6938":"plt.figure(figsize=(8,8))\nsns.regplot(y_test, y_pred, scatter_kws=dict(color=\"#60C8B6\"), line_kws=dict(color=\"#DCD768\", linewidth=3))\nplt.title(\"XGB Regressor Actual vs Predict Train Data\")\nplt.xlabel(\"Actual Value\")\nplt.ylabel(\"Predicit Value\")\nplt.show()","70327879":"xgb_best= xgboost.XGBRegressor(max_depth=5,\n                      n_estimator=100,\n                      reg_lambda=1)\nxgb_best.fit(X_train, y_train)","aca39721":"predictions = xgb_best.predict(test)\n\nsample_sub = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nfinal_data = {'Id': sample_sub.Id, 'SalePrice': predictions}\nfinal_submission = pd.DataFrame(data=final_data)\nfinal_submission.to_csv('submission_file.csv',index =False)","6a89d81a":"## 3.5 Feature Scaling","120f5964":"## 4.1 Linear Regression","a28334c1":"### 3.2.2 Test Data","1a785063":"### 3.1.2 Test Data\n\n**Count of Missing Values of test_num_cols**","28704cd2":"**These columns have so high missin value ratio  so i will drop them**\n    \n    PoolQC          0.997944\n    MiscFeature     0.965045\n    Alley           0.926662\n    Fence           0.801234","3f17d263":"## 4.5 XGboost","0088e94a":"# <a id=\"2\" ><\/a> 2. Exploratory Data Analysis","edf1ff9b":"# <a id=\"4\"> 4. Modelling and Evaluating","b65a8eb8":"**Correlation coefficients between features. Each cell in the table shows the correlation between two variables. High correlation between 2 features are bad for us because of including same information.**","259befe2":"# Overview \n\n1. [Information about the data](#1)\n2. [Exploratory Data Analysis](#2)\n3. [Feature Selection and Preprocessing](#3)\n4. [Modelling and Evaluating](#4)","5753f459":"## 3.6 Splitting Train Data for Modelling","3a084db5":"***Note :*** **Since working categorical column's missing values , if missing value ratio is so high i prefer the drop this column but column missing value ratio is not high i prefer filling missing values with most frequent value**","7b94a11a":"### 3.5.2 Test Data Scaling","dacbacb7":"## 4.2 Decision Tree","dbc6f1b9":"## 3.4 Numerical Columns Skewness","daa4d654":"**Missing Value Ratio of test_num_cols**","922e1e78":"### 3.2.1 Train Data","3df6a76e":"## 3.1 Numeric columns Missin Values","58a010b2":"## 3.3 Categorical Columns Encode","86bc5f30":"# Creating Submission File","2d151f2d":"## 4.4 Gradient Boosting Regressor","faaaa821":"### 3.1.1 Train Data\n\n**Count of Missing Values of train_num_cols**","4840a8e8":"### 3.5.1 Train data Scaling","3eaae85e":"## 3.2 Categoric columns Missing Values","d8078164":"**There are 81 features and since it will take a long time to evaluate all the features, I will only go through the some features that I am wonder about.**\n\nThese are:\n\n    * SalePrice\n    * YearBuilt and SalePrice\n    * OverallQual and SalePrice\n    * YearBuily and OverallQual\n    * Fireplaces and SalePrice\n    * GrLivArea and SalePrice\n    * GarageArea and SalePrice","95f84c66":"**All columns are Numerical**","e7a03f3d":"**The percentage of missing values is not so high. we can fill the missing values with mean**","1134d561":"**Skewness refers to a distortion or asymmetry that deviates from the symmetrical bell curve, or normal distribution, in a set of data.**\n    \n    skewness = 0 : normally distributed.\n    skewness > 0 : more weight in the left tail of the distribution.\n    skewness < 0 : more weight in the right tail of the distribution. \n    \n    \n**Pozitive skewness Normalization Methods :**\n\n    1. Log Transform (my choice in this case)\n    2. Root Transform\n    3. Reciprocals Transformation\n    \n**Negative skewness Normalization Methods :**\n\n    1. Square Transformation\n    2. Cube Transformation\n    3. Higher Powers","3a65bba3":"**The percentage of missing values is not so high. we can fill the missing values with mean**","99a3ae2d":"### 3.4.1 Train Data","49f497d8":"# 3. <a id=3 ><\/a> Feature Selection and Preprocessing","b360a421":"# <a id=\"1\"><\/a> 1. Information about the data","30e883f6":"## 4.3 Random Forest"}}