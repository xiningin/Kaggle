{"cell_type":{"31b1eb6d":"code","e282b13b":"code","b8afd913":"code","1572dfc6":"code","8923101b":"code","f91ade6f":"code","fae93a85":"code","232101a1":"code","f569b1bf":"code","b29d49c6":"code","81afdfa0":"code","5f05d872":"code","848bc764":"code","c51546f2":"code","07b3e8e7":"code","f6252dab":"code","101538a2":"code","5dfc7419":"code","58ace61c":"code","91dbd493":"code","8a49d2e4":"code","79c39bc9":"code","c15344d7":"code","c4cb662f":"code","5f6ebc62":"code","5a9551b8":"code","fe1fcaf1":"code","a7746d82":"code","aaa931ac":"code","de2a9572":"code","785e8815":"code","32824106":"code","6eed0b0c":"code","de0b2e85":"code","8de9dafe":"code","4623d836":"code","e26840e9":"code","7da7ae61":"code","3cda43c0":"code","2f959774":"code","a17a96d4":"markdown","545c0350":"markdown","ed7e4736":"markdown","3d3b470a":"markdown","32312b36":"markdown","0e3dc864":"markdown","d0750f08":"markdown","3fa70ac0":"markdown","529cd3dc":"markdown","de2c7ae1":"markdown","71d5c9b5":"markdown","f2971896":"markdown","49f3aa58":"markdown","a3b39528":"markdown","7a3f2373":"markdown"},"source":{"31b1eb6d":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport os\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Settings\npd.set_option('display.max_columns', None)\nsns.set_palette(\"RdBu\")\n%matplotlib inline\n\n# warning\nimport warnings\nwarnings.filterwarnings('ignore')","e282b13b":"datapath = \"..\/input\/seoul-bike-rental-ai-pro-iti\/\"\ntrain_df = pd.read_csv(os.path.join(datapath,\"train.csv\"))\ntest_df = pd.read_csv(os.path.join(datapath,\"test.csv\"))","b8afd913":"# get the first five rows of data\ntrain_df.head()","1572dfc6":"# Print DataFrame Schema\ntrain_df.info()","8923101b":"# Change features' Names\ndef change_col_name(df, col_names_dic):\n    df.rename(columns=col_names_dic , inplace=True)","f91ade6f":"# dic of Old\/New column name\ncol_names_dic = {'Temperature(\ufffdC)':'Temperature(C)',\n                 'Dew point temperature(\ufffdC)':'Dew point temperature(C)'}\n\n# call the change function\nchange_col_name(train_df,col_names_dic)","fae93a85":"# check\ntrain_df.columns","232101a1":"def modify_date(df):\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    ","f569b1bf":"modify_date(train_df)","b29d49c6":"# check\ntrain_df.Date","81afdfa0":"# use this encoder to encode\nle = LabelEncoder()\n\ndef encode_columns(dataframe, lst_of_col):\n    for col in lst_of_col:\n        dataframe[col] = le.fit_transform(dataframe[col].values)","5f05d872":"lst_of_col = ['Seasons',\n              'Holiday', \n              'Functioning Day' ]\n\nencode_columns(train_df, lst_of_col)","848bc764":"#  check\ntrain_df.info()","c51546f2":"# Unique items in each feature\ntrain_df.nunique()\n","07b3e8e7":"# dealing with duplicates\ntrain_df.duplicated().sum()","f6252dab":"# dealing with na\ntrain_df.isna().sum()","101538a2":"train_df.describe()","5dfc7419":"sns.set(style=\"ticks\", color_codes=True)\nsns.pairplot(train_df, hue='Seasons');","58ace61c":"sns.set(style=\"ticks\", color_codes=True)\nsns.pairplot(train_df, hue='Functioning Day');","91dbd493":"corr_martix = train_df.drop('ID',axis=1).corr()","8a49d2e4":"plt.subplots(figsize=(20,15))\nplt.title('Correlation of Features', size=18)\nsns.heatmap(corr_martix,linewidths=0.05 ,cmap = plt.cm.BuGn, annot=True)","79c39bc9":"corr_with_y = train_df.drop('ID',axis=1).corr()['y'].drop('y')\ncorr_with_y","c15344d7":"plt.subplots(figsize=(15,10))\nplt.plot((corr_with_y.sort_values()), color=\"purple\", lw=1, ls='--', marker='o', markersize=4)\nplt.xticks(rotation=45)\nplt.axhline(y=0 , c='b')\nplt.xlabel('Features')\nplt.ylabel('Correlation With Features')\nplt.grid();","c4cb662f":"# outliers\nplt.figure(figsize=(20,8))\nsns.boxplot(data=train_df.drop(columns='ID'), palette=\"deep\");","5f6ebc62":"# outliers\nplt.figure(figsize=(20,8))\nsns.boxplot(data=train_df.drop(columns=['ID','y', 'Visibility (10m)']), palette=\"deep\");","5a9551b8":"# Split Data using Sci-kit learn\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify = train_df.Seasons) # Try adding `stratify` here\n\nX_train = train_df.drop(columns=['ID', 'y'])\ny_train = train_df['y']\n\nX_val = val_df.drop(columns=['ID', 'y'])\ny_val = val_df['y']","fe1fcaf1":"# select the training features\nfeatures = ['Hour' ,\n            'Temperature(C)' ,\n            'Humidity(%)' , \n            'Wind speed (m\/s)' , \n            'Visibility (10m)' , \n            'Dew point temperature(C)' , \n            'Solar Radiation (MJ\/m2)' , \n            'Rainfall(mm)' , \n            'Snowfall (cm)' , \n            'Seasons' , \n            'Holiday' , \n            'Functioning Day' , \n            'dayofweek' ]\n\nX_train = X_train[features]\nX_val = X_val[features]","a7746d82":"# using Random forest Regressor from sci-kit learn\n# Create an instance of the Regressor       ---> choose the best hyperparameters\nRegressor = RandomForestRegressor(max_depth=None, random_state=0)\n\n# Train the model\nmodel = Regressor.fit(X_train, y_train)","aaa931ac":"# R^2\nprint(\"The coefficient of determination R^2 of the prediction is \", (model.score(X_val, y_val)))","de2a9572":"# RMSE\nactual = y_val\npredicted = model.predict(X_val)\n\nmse = sklearn.metrics.mean_squared_error(actual, predicted)\nrmse = np.sqrt(mse)\nprint(\"RMSE = \",rmse)","785e8815":"# Root Mean Squared Log Error RMSLE\nactual = y_val\npredicted = np.round(model.predict(X_val))\n\nmsle = sklearn.metrics.mean_squared_log_error(actual, predicted)\nrmsle = np.sqrt(msle)\nprint(\"RMSLE = \",rmsle)","32824106":"importance = model.feature_importances_","6eed0b0c":"for i,v in zip(features,importance):\n    print(f'Feature: {i},           Score: {round(v,5)}')","de0b2e85":"plt.subplots(figsize=(15,7))\nplt.bar(features, importance)\nplt.xticks(rotation=90)\nplt.xlabel('Features')\nplt.ylabel('Importance');\n# plt.savefig('plot3.png', dpi=300 ,bbox_inches='tight');","8de9dafe":"# Data is loaded at get the data section\ntest_df.head()","4623d836":"# clean the test dataset\nchange_col_name(test_df,col_names_dic)\nmodify_date(test_df)\nencode_columns(test_df, lst_of_col)","e26840e9":"# check\ntest_df.head()","7da7ae61":"test_df.info()","3cda43c0":"# predict the number of bikes\n\n# Choose the features used for training\nX_test = test_df[features]\n\ny_test_predicted = model.predict(X_test)\n\ntest_df['y'] = np.round(y_test_predicted)\n\ntest_df[['ID','y']].head()","2f959774":"# Generate the submission file. The submission file needs the columns `ID` and `y` only.\ntest_df[['ID', 'y']].to_csv('submission.csv', index=False)","a17a96d4":" Team Members:\n - A\n - B\n - C","545c0350":"#### Now let's test our Model on the validation dataset and see the accuracy.","ed7e4736":"## Conclusion\n* In this notebook, we have demonstrated the essential steps that one should do in order to get \"slightly\" familiar with the data and the submission process. \n* You're encourged to Fork the notebook, edit it, add your insights and use it to create your submission.","3d3b470a":"#### Dealing with dates","32312b36":"### Data fields\n- ID - an ID for this instance\n- Date - year-month-day\n- Hour - Hour of he day\n- Temperature - Temperature in Celsius\n- Humidity - %\n- Windspeed - m\/s\n- Visibility - 10m\n- Dew point temperature - Celsius\n- Solar radiation - MJ\/m2\n- Rainfall - mm\n- Snowfall - cm\n- Seasons - Winter, Spring, Summer, Autumn\n- Holiday - Holiday\/No holiday\n- Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)\n- y - Rented Bike count (Target), Count of bikes rented at each hour","0e3dc864":"------------------------\n# Get the data \n------------------------\n","d0750f08":"--------------------------\n# Model Training\n--------------------------","3fa70ac0":"## Plot The Features \n---------","529cd3dc":"-------------------------\n# Import Libraries\n------------------------","de2c7ae1":"--------------------------\n# Data Splitting\n--------------------------\n\n> Split the dataset for the training step.\n>> Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio.","71d5c9b5":"--------------------------------------\n# Submission File Generation\n--------------------------------------\n\nWe have built a model and we'd like to submit our predictions on the test set!\n**In order to do that,**\n- load the test set.\n- clean the test set\n- predict the number of bikes\n- save the submission file. ","f2971896":"------------------------------------\n# Exploratory data analysis & Data Cleaning\n------------------------------------","49f3aa58":"#### Encode string data","a3b39528":"<h2><center><b>Team Name<\/b><\/center><\/h2>","7a3f2373":"#### Change features' Names"}}