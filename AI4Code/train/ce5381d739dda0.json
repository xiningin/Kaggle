{"cell_type":{"5a113da4":"code","db572598":"code","74bd42e4":"code","d03d59bd":"code","1adef3d8":"code","97adedc4":"code","4bb331c6":"code","63680454":"code","24903fda":"code","eb179c94":"code","9875af15":"code","00571680":"code","108d0ed3":"code","3a31c7ff":"code","48f2e3ab":"code","523b1196":"code","962b69ec":"code","47df4f76":"code","ddc984f6":"code","77464cb2":"code","726cf6f4":"code","9011793a":"code","3bb9dfa0":"code","a8b8aae7":"code","821d2373":"markdown","17ebc4da":"markdown","397c8fec":"markdown","97230651":"markdown","0a6b4079":"markdown","97c773ec":"markdown","c93ce912":"markdown","385af50c":"markdown","b2dbbc1e":"markdown","3c5a58b2":"markdown","35e82c4d":"markdown","1404f95f":"markdown","33b9c087":"markdown","3bc1cfbd":"markdown","be32ad41":"markdown","391bc91c":"markdown"},"source":{"5a113da4":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\nfrom tqdm import tqdm\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications import xception\nfrom keras.applications import inception_v3\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom sklearn.linear_model import LogisticRegression","db572598":"start = dt.datetime.now()","74bd42e4":"!ls ..\/input\/keras-pretrained-models\/","d03d59bd":"cache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","1adef3d8":"!cp ..\/input\/keras-pretrained-models\/*notop* ~\/.keras\/models\/\n!cp ..\/input\/keras-pretrained-models\/imagenet_class_index.json ~\/.keras\/models\/\n!cp ..\/input\/keras-pretrained-models\/resnet50* ~\/.keras\/models\/","97adedc4":"!ls ~\/.keras\/models","4bb331c6":"!ls ..\/input\/dog-breed-identification","63680454":"INPUT_SIZE = 224\nNUM_CLASSES = 16\nSEED = 1987\ndata_dir = '..\/input\/dog-breed-identification'\nlabels = pd.read_csv(join(data_dir, 'labels.csv'))\nsample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\nprint(len(listdir(join(data_dir, 'train'))), len(labels))\nprint(len(listdir(join(data_dir, 'test'))), len(sample_submission))","24903fda":"selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\nlabels = labels[labels['breed'].isin(selected_breed_list)]\nlabels['target'] = 1\nlabels['rank'] = labels.groupby('breed').rank()['id']\nlabels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\nnp.random.seed(seed=SEED)\nrnd = np.random.random(len(labels))\ntrain_idx = rnd < 0.8\nvalid_idx = rnd >= 0.8\ny_train = labels_pivot[selected_breed_list].values\nytr = y_train[train_idx]\nyv = y_train[valid_idx]","eb179c94":"def read_img(img_id, train_or_test, size):\n    \"\"\"Read and resize image.\n    # Arguments\n        img_id: string\n        train_or_test: string 'train' or 'test'.\n        size: resize the original image.\n    # Returns\n        Image as numpy array.\n    \"\"\"\n    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n    img = image.img_to_array(img)\n    return img","9875af15":"model = ResNet50(weights='imagenet')\nj = int(np.sqrt(NUM_CLASSES))\ni = int(np.ceil(1. * NUM_CLASSES \/ j))\nfig = plt.figure(1, figsize=(16, 16))\ngrid = ImageGrid(fig, 111, nrows_ncols=(i, j), axes_pad=0.05)\nfor i, (img_id, breed) in enumerate(labels.loc[labels['rank'] == 1, ['id', 'breed']].values):\n    ax = grid[i]\n    img = read_img(img_id, 'train', (224, 224))\n    ax.imshow(img \/ 255.)\n    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n    preds = model.predict(x)\n    _, imagenet_class_name, prob = decode_predictions(preds, top=1)[0][0]\n    ax.text(10, 180, 'ResNet50: %s (%.2f)' % (imagenet_class_name , prob), color='w', backgroundcolor='k', alpha=0.8)\n    ax.text(10, 200, 'LABEL: %s' % breed, color='k', backgroundcolor='w', alpha=0.8)\n    ax.axis('off')\nplt.show()","00571680":"INPUT_SIZE = 224\nPOOLING = 'avg'\nx_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, img_id in tqdm(enumerate(labels['id'])):\n    img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_train[i] = x\nprint('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))","108d0ed3":"Xtr = x_train[train_idx]\nXv = x_train[valid_idx]\nprint((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\nvgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)\ntrain_vgg_bf = vgg_bottleneck.predict(Xtr, batch_size=32, verbose=1)\nvalid_vgg_bf = vgg_bottleneck.predict(Xv, batch_size=32, verbose=1)\nprint('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\nprint('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))","3a31c7ff":"logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(train_vgg_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\nvalid_probs = logreg.predict_proba(valid_vgg_bf)\nvalid_preds = logreg.predict(valid_vgg_bf)","48f2e3ab":"print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))\nprint('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))","523b1196":"INPUT_SIZE = 299\nPOOLING = 'avg'\nx_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, img_id in tqdm(enumerate(labels['id'])):\n    img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_train[i] = x\nprint('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))","962b69ec":"Xtr = x_train[train_idx]\nXv = x_train[valid_idx]\nprint((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\nxception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\ntrain_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\nvalid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\nprint('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\nprint('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))","47df4f76":"logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(train_x_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\nvalid_probs = logreg.predict_proba(valid_x_bf)\nvalid_preds = logreg.predict(valid_x_bf)\nprint('Validation Xception LogLoss {}'.format(log_loss(yv, valid_probs)))\nprint('Validation Xception Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))","ddc984f6":"Xtr = x_train[train_idx]\nXv = x_train[valid_idx]\nprint((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\ninception_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling=POOLING)\ntrain_i_bf = inception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\nvalid_i_bf = inception_bottleneck.predict(Xv, batch_size=32, verbose=1)\nprint('InceptionV3 train bottleneck features shape: {} size: {:,}'.format(train_i_bf.shape, train_i_bf.size))\nprint('InceptionV3 valid bottleneck features shape: {} size: {:,}'.format(valid_i_bf.shape, valid_i_bf.size))","77464cb2":"logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(train_i_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\nvalid_probs = logreg.predict_proba(valid_i_bf)\nvalid_preds = logreg.predict(valid_i_bf)","726cf6f4":"print('Validation Inception LogLoss {}'.format(log_loss(yv, valid_probs)))\nprint('Validation Inception Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))","9011793a":"X = np.hstack([train_x_bf, train_i_bf])\nV = np.hstack([valid_x_bf, valid_i_bf])\nprint('Full train bottleneck features shape: {} size: {:,}'.format(X.shape, X.size))\nprint('Full valid bottleneck features shape: {} size: {:,}'.format(V.shape, V.size))\nlogreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(X, (ytr * range(NUM_CLASSES)).sum(axis=1))\nvalid_probs = logreg.predict_proba(V)\nvalid_preds = logreg.predict(V)\nprint('Validation Xception + Inception LogLoss {}'.format(log_loss(yv, valid_probs)))\nprint('Validation Xception + Inception Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))","3bb9dfa0":"valid_breeds = (yv * range(NUM_CLASSES)).sum(axis=1)\nerror_idx = (valid_breeds != valid_preds)\nfor img_id, breed, pred in zip(labels.loc[valid_idx, 'id'].values[error_idx],\n                                [selected_breed_list[int(b)] for b in valid_preds[error_idx]],\n                                [selected_breed_list[int(b)] for b in valid_breeds[error_idx]]):\n    fig, ax = plt.subplots(figsize=(5,5))\n    img = read_img(img_id, 'train', (299, 299))\n    ax.imshow(img \/ 255.)\n    ax.text(10, 250, 'Prediction: %s' % pred, color='w', backgroundcolor='r', alpha=0.8)\n    ax.text(10, 270, 'LABEL: %s' % breed, color='k', backgroundcolor='g', alpha=0.8)\n    ax.axis('off')\n    plt.show()                                                    ","a8b8aae7":"end = dt.datetime.now()\nprint('Total time {} s.'.format((end - start).seconds))\nprint('We almost used the one hour time limit.')","821d2373":"# LogReg on VGG bottleneck features","17ebc4da":"Training this model on the full dataset would give 0.3 LogLoss on LB.","397c8fec":"# Check errors\nWe still have a few misclassification errors.","97230651":"# ResNet50 class predictions for example images","0a6b4079":"Preprocessing and prediction seems to be working. 75% accuracy on these 16 images.","97c773ec":"Not bad, 90% accuracy for the top 16 classes. The multiclass classification with 120 classes is more difficult so these LogLoss\/Accuracy scores does not translate to LB.","c93ce912":"# LogReg on all bottleneck features","385af50c":"# LogReg on Inception bottleneck features","b2dbbc1e":"# Transfer learning with pretrained Keras models\n\nAlthough Kernel resources were increased recently we still can not train useful CNNs without GPU. The original ImageNet set has quite a few different dog classes so we can reuse CNNs with pretrained ImageNet weights. Fortunately prediction is much faster (<1s\/image) making it possible to run meaningful experiments with Kaggle Kernels.","3c5a58b2":"# Use Keras Pretrained Models dataset\n\nKernels can't use network connection to download pretrained keras model weights.\nThis dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \nYou can find more details [here](https:\/\/www.kaggle.com\/gaborfodor\/keras-pretrained-models).\n\nWe have to copy the pretrained models to the cache directory (~\/.keras\/models) where keras is looking for them.\n","35e82c4d":"# Use top 16 classes\nUsing all the images would take more than the 1 hour kernel limit. Let's focus on the most frequent 16 breeds.","1404f95f":"# Extract VGG16 bottleneck features","33b9c087":"# Extract Inception bottleneck features","3bc1cfbd":"![](https:\/\/pics.me.me\/such-wow-much-awesome-many-cool-bestest-thug-life-19337110.png)\n\nMuch better! 98% accuracy 0.07 LogLoss.","be32ad41":"# LogReg on Xception bottleneck features\n","391bc91c":"# Extract Xception bottleneck features"}}