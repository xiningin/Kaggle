{"cell_type":{"532defa7":"code","8831a973":"code","056d8cfb":"code","74e08970":"code","f294444a":"code","4e900dcf":"code","281c3b58":"code","d6975d42":"code","331241be":"code","afc9208a":"code","b49439f8":"code","7cdd3ba5":"code","fc44014b":"code","377ee9b1":"code","d814c76a":"code","e8e0533e":"code","5ab5100e":"code","587bfe50":"code","4810ed9c":"code","564bf321":"code","7ac7d1bf":"code","7a1a0231":"code","f26af3db":"code","3735a70a":"code","1dab6c4b":"code","2f6b470b":"code","3685ce58":"code","31ae6baa":"code","92b89b6f":"code","b4466fea":"code","c989bbff":"code","bc76411c":"code","ab7c99c1":"markdown","58a090f7":"markdown","a42d4d07":"markdown","cdf76a9d":"markdown","8942c1d1":"markdown"},"source":{"532defa7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8831a973":"import warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndata_org = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata = data_org.copy()\ndata.head(3)","056d8cfb":"# target \ubcc0\uc218\ub294 \ub9c8\uc9c0\ub9c9 \uce7c\ub7fc `SalePrice`\n# \ub370\uc774\ud130 \uc815\ubcf4 \uc694\uc57d\nprint('\ub370\uc774\ud130 \uc138\ud2b8\uc758 Shape: ', data.shape)\nprint('\\n\uc804\uccb4 \ud53c\ucc98\uc758 \ud0c0\uc785 \\n', data.dtypes.value_counts())\nisnull_series = data.isnull().sum()\nprint('\\nNull \uce7c\ub7fc\uacfc \uadf8 \uac74\uc218: \\n', isnull_series[isnull_series > 0].sort_values(ascending=False))","74e08970":"# target \ubcc0\uc218 \ubd84\ud3ec \ud655\uc778\ud558\uae30 \nplt.title('Original Sale Price Histogram')\nsns.distplot(data['SalePrice'])","f294444a":"# log transformation\nplt.title('Log Transformation Sale Price Histogram')\nlog_SalePrice = np.log1p(data['SalePrice'])\nsns.distplot(log_SalePrice)","4e900dcf":"# null \uac12\uc774 \ub9ce\uc740 \ud53c\ucc98 \uc0ad\uc81c \n# \ub2e8\uc21c\uc2dd\ubcc4\uc790 `id` \uc0ad\uc81c \n# \ub098\uba38\uc9c0 Null \ud53c\ucc98\ub294 \uc22b\uc790\ud615\uc758 \uacbd\uc6b0 \ud3c9\uade0\uac12\uc73c\ub85c \ub300\uccb4\n\n# SalePrice log transformation\noriginal_SalePrice = data['SalePrice']\ndata['SalePrice'] = np.log1p(data['SalePrice'])\n\n# null\uc774 \ub108\ubb34 \ub9ce\uc740 \uce7c\ub7fc\uacfc \ubd88\ud544\uc694\ud55c \uce7c\ub7fc \uc0ad\uc81c \ndata.drop([\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"Id\"], axis=1, inplace=True)\n\n# drop\ud558\uc9c0 \uc54a\ub294 \uc22b\uc790\ud615 null \uce7c\ub7fc\uc740 \ud3c9\uade0\uac12\uc73c\ub85c \ub300\uccb4 \ndata.fillna(data.mean(), inplace=True)","281c3b58":"# null \uac12\uc774 \uc788\ub294 \ud53c\ucc98\uba85\uacfc \ud0c0\uc785 \ucd94\ucd9c\nnull_column_count = data.isnull().sum()[data.isnull().sum() > 0]\nprint('## Null \ud53c\ucc98\uc758 type :\\n', data.dtypes[null_column_count.index])","d6975d42":"# \uc774\uc81c null \uac12\uc740 \ubb38\uc790\ud615 \ud53c\ucc98\uc5d0\ub9cc \uc874\uc7ac \n# \ubb38\uc790\ud615\uc740 \uc6d0\ud56b\uc778\ucf54\ub529\uc744 \ud558\uba74\uc11c null\uac12 \ub300\uccb4 \ubcc4\ub3c4\ub85c \ud544\uc694 \uc5c6\uc74c(none\uc73c\ub85c \ucc98\ub9ac\ud558\uae30 \ub54c\ubb38\uc5d0)\nprint('get_dummies() \uc218\ud589 \uc804 \ub370\uc774\ud130 shape: ', data.shape)\ndata_ohe = pd.get_dummies(data)\nprint('get_dummies() \uc218\ud589 \ud6c4 \ub370\uc774\ud130 shape: ', data_ohe.shape)\n\nnull_column_count = data_ohe.isnull().sum()[data_ohe.isnull().sum() > 0]\nprint('## Null \ud53c\ucc98\uc758 type :\\n', data_ohe.dtypes[null_column_count.index])","331241be":"def get_rmse(model):\n    pred = model.predict(x_test)\n    mse = mean_squared_error(y_test, pred)\n    rmse = np.sqrt(mse)\n    print(model.__class__.__name__, '\ub85c\uadf8 \ubcc0\ud658\ub41c RMSE:', np.round(rmse, 3))\n    return rmse\n\ndef get_rmses(models):\n    rmses = []\n    for model in models:\n        rmse = get_rmse(model)\n        rmses.append(rmse)\n    return rmses","afc9208a":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\ny_target = data_ohe['SalePrice']\nx_features = data_ohe.drop('SalePrice', axis=1, inplace=False)\nx_train, x_test, y_train, y_test = train_test_split(x_features, y_target,\n                                                   test_size = .3,\n                                                   random_state = 0)\n\n# linear regression, ridge, lasso \uc2e4\ud589\ud558\uae30\nlr = LinearRegression()\nridge = Ridge()\nlasso = Lasso()\n\nlr.fit(x_train, y_train)\nridge.fit(x_train, y_train)\nlasso.fit(x_train, y_train)\n\nmodels = [lr, ridge, lasso]\nget_rmses(models)","b49439f8":"# \ud68c\uadc0 \uacc4\uc218 \uc2dc\uac01\ud654. \ubaa8\ub378\ubcc4\ub85c \uc5b4\ub5a0\ud55c \ud53c\ucc98 \ud68c\uadc0 \uacc4\uc218\ub85c \uad6c\uc131\ub418\ub294 \uc9c0 \ud655\uc778\n# \ud53c\ucc98\uac00 \ub9ce\uc73c\ub2c8 \uc0c1\uc704 10\uac1c, \ud558\uc704 10\uac1c\ub9cc \uc0b4\ud3b4\ubcf4\uae30 \ndef get_top_bottom_coef(model, n=10):\n    coef = pd.Series(model.coef_, index=x_features.columns)\n    \n    coef_high = coef.sort_values(ascending=False).head(n)\n    coef_low = coef.sort_values(ascending=False).tail(n)\n    return coef_high, coef_low","7cdd3ba5":"def visualize_coefficient(models):\n    fig, axs = plt.subplots(figsize=(24, 10), nrows=1, ncols=3)\n    fig.tight_layout()\n    \n    # \uc785\ub825 \uc778\uc790\ub85c \ubc1b\uc740 list \uac1d\uccb4\uc778 models\uc5d0\uc11c \ucc28\ub840\ub85c model\uc744 \ucd94\ucd9c\ud574 \ud68c\uadc0 \uacc4\uc218 \uc2dc\uac01\ud654 \n    for i_num, model in enumerate(models):\n        # \uc0c1\uc704 10\uac1c, \ud558\uc704 10\uac1c \ud68c\uadc0 \uacc4\uc218 \uad6c\ud558\uace0 concat\uc73c\ub85c \uacb0\ud569\n        coef_high, coef_low = get_top_bottom_coef(model)\n        coef_concat = pd.concat([coef_high, coef_low])\n        # ax subplot\uc5d0 barchar\ub85c \ud45c\ud604. \ud55c \ud654\uba74\uc5d0 \ud45c\ud604\ud558\uae30 \uc704\ud574 tick label \uc704\uce58\uc640 font \uc870\uc815\n        axs[i_num].set_title(model.__class__.__name__+ ' Coefficients', size=25)\n        axs[i_num].tick_params(axis='y', direction='in', pad=-120)\n        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n            label.set_fontsize(22)\n        sns.barplot(x=coef_concat.values,\n                   y=coef_concat.index, ax=axs[i_num])\n        \n# \uc55e \uc608\uc81c\uc5d0\uc11c \ud559\uc2b5\ud55c \ubaa8\ub378\uc758 \ud68c\uadc0 \uacc4\uc218 \uc2dc\uac01\ud654 \nmodels = [lr, ridge, lasso]\nvisualize_coefficient(models)","fc44014b":"from sklearn.model_selection import cross_val_score\n\ndef get_avg_rmse_cv(models):\n    \n    for model in models:\n        # \ubd84\ud560\ud558\uc9c0 \uc54a\uace0 \uc804\uccb4 \ub370\uc774\ud130\ub85c cross_val_score() \uc218\ud589.\n        # \ubaa8\ub378\ubcc4 CV RMSE\uac12\uacfc \ud3c9\uade0 RMSE \ucd9c\ub825\n        rmse_list = np.sqrt(-cross_val_score(model, x_features, y_target,\n                                            scoring = 'neg_mean_squared_error',\n                                            cv = 5))\n        rmse_avg = np.mean(rmse_list)\n        print('\\n{0} CV RMSE \uac12 \ub9ac\uc2a4\ud2b8: {1}'.format(model.__class__.__name__, np.round(rmse_list, 3)))\n        print('\\n{0} CV \ud3c9\uade0 RMSE \uac12: {1}'.format(model.__class__.__name__, np.round(rmse_avg, 3)))\n        \n# \uc55e \uc608\uc81c\uc5d0\uc11c \ud559\uc2b5\ud55c lr, ridge, lasso \ubaa8\ub378\uc758 CV RMSE \uac12 \ucd9c\ub825\nmodels = [lr, ridge, lasso]\nget_avg_rmse_cv(models)","377ee9b1":"# lasso\uc758 \uacbd\uc6b0, \ucc98\uc74c \ud68c\uadc0 \uacc4\uc218 \ud615\ud0dc\ub3c4 \ube44\uc774\uc0c1\uc801\uc774\uba70 ols\ub098 \ub9bf\uc9c0\ubcf4\ub2e4 \ud3f4\ub4dc \uc138\ud2b8 \ud559\uc2b5\ub3c4 \uc131\ub2a5\uc774 \ub5a8\uc5b4\uc9c4\ub2e4\n# ridge\uc640 lasso \ubaa8\ub378\uc5d0 \ub300\ud574 alpha \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub97c \ubcc0\ud654\uc2dc\ud0a4\uba70 \ucd5c\uc801\uc758 \uac12 \ub3c4\ucd9c\ud574\ubcf4\uc790\nfrom sklearn.model_selection import GridSearchCV\n\ndef print_best_params(model, params):\n    grid_model = GridSearchCV(model, param_grid=params,\n                             scoring='neg_mean_squared_error', cv=5)\n    grid_model.fit(x_features, y_target)\n    rmse = np.sqrt(-1 * grid_model.best_score_)\n    print('{0} 5 CV \uc2dc \ucd5c\uc801 \ud3c9\uade0 RMSE \uac12: {1}, \ucd5c\uc801 alpha: {2}'.format(model.__class__.__name__,\n                                                              np.round(rmse, 4), grid_model.best_params_))\n    \nridge_params = {'alpha' : [0.05, 0.1, 1, 5, 8, 10, 12, 15, 20]}\nlasso_params = {'alpha' : [0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1, 5, 10]}\nprint_best_params(ridge, ridge_params)\nprint_best_params(lasso, lasso_params)","d814c76a":"# \uc55e\uc758 \ucd5c\uc801\ud654 alpha \uac12\uc73c\ub85c \ud559\uc2b5 \ub370\uc774\ud130\ub85c \ud559\uc2b5, \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub85c \uc608\uce21 \ubc0f \ud3c9\uac00 \uc218\ud589\nlr = LinearRegression()\nridge = Ridge(alpha=12)\nlasso = Lasso(alpha=0.001)\n\nlr.fit(x_train, y_train)\nridge.fit(x_train, y_train)\nlasso.fit(x_train, y_train)\n\n# \ubaa8\ub4e0 \ubaa8\ub378\uc758 RMSE \ucd9c\ub825\nmodels = [lr, ridge, lasso]\nget_rmses(models)\n\n# \ubaa8\ub4e0 \ubaa8\ub378\uc758 \ud68c\uadc0 \uacc4\uc218 \uc2dc\uac01\ud654\nvisualize_coefficient(models)","e8e0533e":"# \ub370\uc774\ud130 \uc138\ud2b8 \ucd94\uac00\uc801\uc73c\ub85c \uac00\uacf5\ud558\uc5ec \ubaa8\ub378 \ud29c\ub2dd\ud558\uae30 \n# 1) \ud53c\ucc98 \ub370\uc774\ud130 \uc138\ud2b8\uc758 \ub370\uc774\ud130 \ubd84\ud3ec\ub3c4 \n# 2) \uc774\uc0c1\uce58 \ud655\uc778\n\nfrom scipy.stats import skew\n\n# object\uac00 \uc544\ub2cc \uc22b\uc790\ud615 \ud53c\ucc98\uc758 \uce7c\ub7fc index \uac1d\uccb4 \ucd94\ucd9c\nfeatures_index = data.dtypes[data.dtypes != 'object'].index\n# data\uc5d0 \uce7c\ub7fc index\ub97c []\ub85c \uc785\ub825\ud558\uba74 \ud574\ub2f9\ud558\ub294 \uce7c\ub7fc \ub370\uc774\ud130 \uc138\ud2b8 \ubc18\ud658, skew \ud638\ucd9c\nskew_features = data[features_index].apply(lambda x: skew(x))\n# skew \uc815\ub3c4\uac00 1 \uc774\uc0c1\uc778 \uce7c\ub7fc\ub9cc \ucd94\ucd9c\nskew_features_top = skew_features[skew_features > 1]\nprint(skew_features_top.sort_values(ascending=False))","5ab5100e":"# \ucd94\ucd9c\ub41c \uc65c\uace1 \uc815\ub3c4\uac00 \ub192\uc740 \ud53c\ucc98\ub4e4 \ub85c\uadf8 \ubcc0\ud658 \uc2e4\uc2dc \ndata[skew_features_top.index] = np.log1p(data[skew_features_top.index])","587bfe50":"# \ubcc0\uc218 \ub85c\uadf8 \ubcc0\ud658\ud558\uc600\uc73c\ubbc0\ub85c \ub2e4\uc2dc \uc6d0\ud56b\uc778\ucf54\ub529 \uc801\uc6a9\ud55c data_ohe \ub9cc\ub4e4\uace0, \ubaa8\ub378\ub9c1\uae4c\uc9c0\ndata_ohe = pd.get_dummies(data)\ny_target = data_ohe['SalePrice']\nx_features = data_ohe.drop('SalePrice', axis=1, inplace=False)\nx_train, x_test, y_train, y_test = train_test_split(y_target, x_features,\n                                                   test_size=.2,\n                                                   random_state=156)\n\n# \ud53c\ucc98\ub97c \ub85c\uadf8 \ubcc0\ud658\ud55c \ud6c4 \ucd5c\uc801 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\uc640 RMSE \ucd9c\ub825\nridge_params = {'alpha' : [0.05, 0.1, 1, 5, 8, 10, 12, 15, 20]}\nlasso_params = {'alpha' : [0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1, 5, 10]}\nprint_best_params(ridge, ridge_params)\nprint_best_params(lasso, lasso_params)","4810ed9c":"visualize_coefficient(models)","564bf321":"# \uc774\uc0c1\uce58 \ud655\uc778\ud558\uae30 \n# `GrLivArea` \uc8fc\uac70 \uacf5\uac04 \ud06c\uae30 \ubcc0\uc218 \ud655\uc778\ud558\uae30 \nplt.scatter(x=data_org['GrLivArea'],\n            y=data_org['SalePrice'])\nplt.ylabel('SalePrice', fontsize=15)\nplt.xlabel('GrLivArea', fontsize=15)\nplt.show()","7ac7d1bf":"# `GrLivArea`\uac00 4000\ud3c9\ubc29\ube44\ud2b8 \uc774\uc0c1\uc784\uc5d0\ub3c4 \uac00\uaca9\uc774 500,000\ub2ec\ub7ec \uc774\ud558\uc778 \ub370\uc774\ud130\ub294 \ubaa8\ub450 \uc774\uc0c1\uce58\ub85c \uac04\uc8fc\ud558\uace0 \uc0ad\uc81c\n# GrLivArea\uc640 SalePrice \ubaa8\ub450 \ub85c\uadf8 \ubcc0\ud658\ub418\uc5c8\uc73c\ubbc0\ub85c \uc774\ub97c \ubc18\uc601\ud55c \uc870\uac74 \uc0dd\uc131\ncond1 = data_ohe['GrLivArea'] > np.log1p(4000)\ncond2 = data_ohe['SalePrice'] < np.log1p(500000)\noutlier_index = data_ohe[cond1 & cond2].index\n\nprint('\uc774\uc0c1\uce58 \ub808\ucf54\ub4dc index :', outlier_index.values)\nprint('\uc774\uc0c1\uce58 \uc0ad\uc81c \uc804 data_ohe shape: ', data_ohe.shape)\n\n# dataframe\uc758 \uc778\ub371\uc2a4\ub97c \uc774\uc6a9\ud574 \uc774\uc0c1\uce58 \ub808\ucf54\ub4dc \uc0ad\uc81c \ndata_ohe.drop(outlier_index, axis=0, inplace=True)\nprint('\uc774\uc0c1\uce58 \uc0ad\uc81c \ud6c4 data_ohe shape: ', data_ohe.shape)","7a1a0231":"y_target = data_ohe['SalePrice']\nx_features = data_ohe.drop('SalePrice', axis=1, inplace=False)\nx_train, x_test, y_train, y_test = train_test_split(x_features, y_target,\n                                                   test_size=.2,\n                                                   random_state=156)\n\n# \ud53c\ucc98\ub97c \ub85c\uadf8 \ubcc0\ud658\ud55c \ud6c4 \ucd5c\uc801 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\uc640 RMSE \ucd9c\ub825\nridge_params = {'alpha' : [0.05, 0.1, 1, 5, 8, 10, 12, 15, 20]}\nlasso_params = {'alpha' : [0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1, 5, 10]}\nprint_best_params(ridge, ridge_params)\nprint_best_params(lasso, lasso_params)","f26af3db":"# \uc55e\uc758 \ucd5c\uc801\ud654 alpha \uac12\uc73c\ub85c \ud559\uc2b5 \ub370\uc774\ud130\ub85c \ud559\uc2b5, \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub85c \uc608\uce21 \ubc0f \ud3c9\uac00 \uc218\ud589\nlr = LinearRegression()\nridge = Ridge(alpha=8)\nlasso = Lasso(alpha=0.001)\n\nlr.fit(x_train, y_train)\nridge.fit(x_train, y_train)\nlasso.fit(x_train, y_train)\n\n# \ubaa8\ub4e0 \ubaa8\ub378\uc758 RMSE \ucd9c\ub825\nmodels = [lr, ridge, lasso]\nget_rmses(models)\n\n# \ubaa8\ub4e0 \ubaa8\ub378\uc758 \ud68c\uadc0 \uacc4\uc218 \uc2dc\uac01\ud654\nvisualize_coefficient(models)","3735a70a":"# xgboost \ud68c\uadc0 \ud2b8\ub9ac\nfrom xgboost import XGBRegressor\n\nxgb_params = {'n_estimators':[1000]}\nxgb = XGBRegressor(n_estimators=1000,\n                  learning_rate = 0.05,\n                  colsample_bytree=0.5,\n                  subsample=0.8,\n                  tree_method='gpu_hist',\n                  random_state=0)\nprint_best_params(xgb, xgb_params)","1dab6c4b":"# lightGBM \ud68c\uadc0 \ud2b8\ub9ac\nfrom lightgbm import LGBMRegressor\n\nlgbm_params = {'n_estimators':[1000]}\nlgbm = LGBMRegressor(n_estimators=1000,\n                    learning_rate=0.05,\n                    num_leaves=4,\n                    subsample=0.6,\n                    colsample_bytree=0.4,\n                    reg_lambda=10,\n                    n_jobs=-1,\n                    tree_method='gpu_hist',\n                    random_state=0)\nprint_best_params(lgbm, lgbm_params)","2f6b470b":"xgb.fit(x_train, y_train)\nlgbm.fit(x_train, y_train)","3685ce58":"# \ubaa8\ub378\uc758 \uc911\uc694\ub3c4 \uc0c1\uc704 20\uac1c\uc758 \ud53c\ucc98\uba85\uacfc \uadf8\ub54c\uc758 \uc911\uc694\ub3c4\uac12\uc744 Series\ub85c \ubc18\ud658.\ndef get_top_features(model):\n    ftr_importances_values = model.feature_importances_\n    ftr_importances = pd.Series(ftr_importances_values, index=x_features.columns  )\n    ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n    return ftr_top20\n\ndef visualize_ftr_importances(models):\n    # 2\uac1c \ud68c\uadc0 \ubaa8\ub378\uc758 \uc2dc\uac01\ud654\ub97c \uc704\ud574 2\uac1c\uc758 \uceec\ub7fc\uc744 \uac00\uc9c0\ub294 subplot \uc0dd\uc131\n    fig, axs = plt.subplots(figsize=(24,10),nrows=1, ncols=2)\n    fig.tight_layout() \n    # \uc785\ub825\uc778\uc790\ub85c \ubc1b\uc740 list\uac1d\uccb4\uc778 models\uc5d0\uc11c \ucc28\ub840\ub85c model\uc744 \ucd94\ucd9c\ud558\uc5ec \ud53c\ucc98 \uc911\uc694\ub3c4 \uc2dc\uac01\ud654. \n    for i_num, model in enumerate(models):\n        # \uc911\uc694\ub3c4 \uc0c1\uc704 20\uac1c\uc758 \ud53c\ucc98\uba85\uacfc \uadf8\ub54c\uc758 \uc911\uc694\ub3c4\uac12 \ucd94\ucd9c \n        ftr_top20 = get_top_features(model)\n        axs[i_num].set_title(model.__class__.__name__+' Feature Importances', size=25)\n        #font \ud06c\uae30 \uc870\uc815.\n        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n            label.set_fontsize(22)\n        sns.barplot(x=ftr_top20.values, y=ftr_top20.index , ax=axs[i_num])\n\n# \uc55e \uc608\uc81c\uc5d0\uc11c print_best_params( )\uac00 \ubc18\ud658\ud55c GridSearchCV\ub85c \ucd5c\uc801\ud654\ub41c \ubaa8\ub378\uc758 \ud53c\ucc98 \uc911\uc694\ub3c4 \uc2dc\uac01\ud654    \nmodels = [xgb, lgbm]\nvisualize_ftr_importances(models)","31ae6baa":"# \uac1c\ubcc4 \ud68c\uadc0 \ubaa8\ub378\uc758 \uc608\uce21 \uacb0\uad0f\uac12\uc744 \ud63c\ud569\ud574 \uc774\ub97c \uae30\ubc18\uc73c\ub85c \ucd5c\uc885 \ud68c\uadc0\uac12 \uc608\uce21\ndef get_rmse_pred(preds):\n    for key in preds.keys():\n        pred_value = preds[key]\n        mse = mean_squared_error(y_test, pred_value)\n        rmse = np.sqrt(mse)\n        print('{0} \ubaa8\ub378\uc758 RMSE: {1}'.format(key, rmse))\n\n# ridge & lasso\n# \uac1c\ubcc4 \ubaa8\ub378\uc758 \ud559\uc2b5\nridge = Ridge(alpha=8)\nlasso = Lasso(alpha=0.001)\n\nridge.fit(x_train, y_train)\nlasso.fit(x_train, y_train)\n\n# \uac1c\ubcc4 \ubaa8\ub378 \uc608\uce21\nridge_pred = ridge.predict(x_test)\nlasso_pred = lasso.predict(x_test)\n\n# \uac1c\ubcc4 \ubaa8\ub378 \uc608\uce21\uac12 \ud63c\ud569\uc73c\ub85c \ucd5c\uc885 \uc608\uce21\uac12 \ub3c4\ucd9c\npred = 0.4 * ridge_pred + 0.6 * lasso_pred\npreds = {'\ucd5c\uc885 \ud63c\ud569': pred,\n        'Ridge': ridge_pred,\n        'Lasso': lasso_pred}\n\n# \ucd5c\uc885 \ud63c\ud569 \ubaa8\ub378, \uac1c\ubcc4 \ubaa8\ub378\uc758 RMSE \uac12 \ucd9c\ub825\nget_rmse_pred(preds)","92b89b6f":"# xgb & lightgbm\nxgb = XGBRegressor(n_estimators=1000,\n                  learning_rate=0.05,\n                  colsample_bytree=0.5,\n                  subsample=0.8,\n                  tree_method='gpu_hist',\n                  random_state=0)\nlgbm = LGBMRegressor(n_estimators=1000,\n                    learning_rate=0.05,\n                    num_leaves=4,\n                    subsample=0.6,\n                    colsample_bytree=0.4,\n                    reg_lambda=10,\n                    n_jobs=-1,\n                    tree_method='gpu_hist',\n                    random_state=0)\n\nxgb.fit(x_train, y_train)\nlgbm.fit(x_train, y_train)\n\nxgb_pred = xgb.predict(x_test)\nlgbm_pred = lgbm.predict(x_test)\n\npred = 0.5 * xgb_pred + 0.5 * lgbm_pred\npreds = {'\ucd5c\uc885 \ud63c\ud569': pred,\n        'XGB' : xgb_pred,\n        'LGBM' : lgbm_pred}\n\nget_rmse_pred(preds)","b4466fea":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\n# \uac1c\ubcc4 \uae30\ubc18 \ubaa8\ub378\uc5d0\uc11c \ucd5c\uc885 \uba54\ud0c0 \ubaa8\ub378\uc774 \uc0ac\uc6a9\ud560 \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8\uc6a9 \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud55c \ud568\uc218\ndef get_stacking_base_datasets(model, x_features_n, y_target_n, x_test_n, n_folds):\n    # \uc9c0\uc815\ub41c n_folds \uac12\uc73c\ub85c KFold \uc0dd\uc131\n    kf = KFold(n_splits=n_folds,\n              shuffle=False,\n              random_state=0)\n    # \ucd94\ud6c4\uc5d0 \uba54\ud0c0 \ubaa8\ub378\uc774 \uc0ac\uc6a9\ud560 \ud559\uc2b5 \ub370\uc774\ud130 \ubc18\ud658\uc744 \uc704\ud55c \ub118\ud30c\uc774 \ubc30\uc5f4 \ucd08\uae30\ud654\n    train_fold_pred = np.zeros((x_train_n.shape[0], 1))\n    test_pred = np.zeros((x_test_n.shape[0], n_folds))\n    print(model.__class__.__name__, 'model \uc2dc\uc791')\n    \n    for folder_counter, (train_index, valid_index) in enumerate(kf.split(x_train_n)):\n        # \uc785\ub825\ub41c \ud559\uc2b5 \ub370\uc774\ud130\uc5d0\uc11c \uae30\ubc18 \ubaa8\ub378\uc774 \ud559\uc2b5\/\uc608\uce21\ud560 \ud3f4\ub4dc \ub370\uc774\ud130 \ucd94\ucd9c\n        print('\\t \ud3f4\ub4dc \uc138\ud2b8: ', folder_counter, '\uc2dc\uc791')\n        x_tr = x_train_n[train_index]\n        y_tr = y_train_n[train_index]\n        x_te = x_train_n[valid_index]\n        \n        # \ud3f4\ub4dc \uc138\ud2b8 \ub0b4\ubd80\uc5d0\uc11c \ub2e4\uc2dc \ub9cc\ub4e4\uc5b4\uc9c4 \ud559\uc2b5 \ub370\uc774\ud130\ub85c \uae30\ubc18 \ubaa8\ub378\uc758 \ud559\uc2b5 \uc218\ud589\n        model.fit(x_tr, y_tr)\n        # \ud3f4\ub4dc \uc138\ud2b8 \ub0b4\ubd80\uc5d0\uc11c \ub2e4\uc2dc \ub9cc\ub4e4\uc5b4\uc9c4 \uac80\uc99d \ub370\uc774\ud130\ub85c \uae30\ubc18 \ubaa8\ub378 \uc608\uce21 \ud6c4 \ub370\uc774\ud130 \uc800\uc7a5\n        train_fold_pred[valid_index, :] = model.predict(x_te).reshape(-1, 1)\n        # \uc785\ub825\ub41c \uc6d0\ubcf8 \ud14d\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \ud3f4\ub4dc \uc138\ud2b8 \ub0b4 \ud559\uc2b5\ub41c \uae30\ubc18 \ubaa8\ub378\uc5d0\uc11c \uc608\uce21 \ud6c4 \ub370\uc774\ud130 \uc800\uc7a5\n        test_pred[:, folder_counter] = model.predict(x_test_n)\n        \n    # \ud3f4\ub4dc \uc138\ud2b8 \ub0b4\uc5d0\uc11c \uc6d0\ubcf8 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \uc608\uce21\ud55c \ub370\uc774\ud130\ub97c \ud3c9\uade0\ud558\uc5ec \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub85c \uc0dd\uc131\n    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n    \n    # train_fold_pred\ub294 \ucd5c\uc885 \uba54\ud0c0 \ubaa8\ub378\uc774 \uc0ac\uc6a9\ud558\ub294 \ud559\uc2b5 \ub370\uc774\ud130, test_pred_mean\uc740 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\n    return train_fold_pred, test_pred_mean","c989bbff":"# get_stacking_base_dataset\uc740 ndarray \uc778\uc790\ub85c \uc0ac\uc6a9\nx_train_n = x_train.values\ny_train_n = y_train.values\nx_test_n = x_test.values\n\n# \uac01 \uac1c\ubcc4 \uae30\ubc18 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ud559\uc2b5\uc6a9\/\ud14c\uc2a4\ud2b8\uc6a9 \ub370\uc774\ud130 \ubc18\ud658\nridge_train, ridge_test = get_stacking_base_datasets(ridge, x_train_n, y_train_n, x_test_n, 5)\nlasso_train, lasso_test = get_stacking_base_datasets(lasso, x_train_n, y_train_n, x_test_n, 5)\nxgb_train, xgb_test = get_stacking_base_datasets(xgb, x_train_n, y_train_n, x_test_n, 5)\nlgbm_train, lgbm_test = get_stacking_base_datasets(lgbm, x_train_n, y_train_n, x_test_n, 5)","bc76411c":"# \uac1c\ubcc4 \ubaa8\ub378\uc774 \ubc18\ud658\ud55c \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8\uc6a9 \ub370\uc774\ud130 \uc138\ud2b8\ub97c \uc2a4\ud0dc\ud0b9 \ud615\ud0dc\ub85c \uacb0\ud569\nstack_final_x_train = np.concatenate((ridge_train, lasso_train, xgb_train, lgbm_train), axis=1)\nstack_final_x_test = np.concatenate((ridge_test, lasso_test, xgb_test, lgbm_test), axis=1)\n\n# \ucd5c\uc885 \uba54\ud0c0 \ubaa8\ub378\uc740 \ub77c\uc3d8 \ubaa8\ub378 \uc801\uc6a9\nmeta_model_lasso = Lasso(alpha=0.0005)\n\n# \uac1c\ubcc4 \ubaa8\ub378 \uc608\uce21\uac12\uc744 \uae30\ubc18\uc73c\ub85c \uc0c8\ub86d\uac8c \ub9cc\ub4e4\uc5b4\uc9c4 \ud559\uc2b5\/\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub85c \uba54\ud0c0 \ubaa8\ub378 \uc608\uce21 \ubc0f RMSE \uce21\uc815\nmeta_model_lasso.fit(stack_final_x_train, y_train)\nfinal = meta_model_lasso.predict(stack_final_x_test)\nmse = mean_squared_error(y_test, final)\nrmse = np.sqrt(mse)\nprint('\uc2a4\ud0dc\ud0b9 \ud68c\uadc0 \ubaa8\ub378\uc758 \ucd5c\uc885 RMSE \uac12\uc740: ', rmse)","ab7c99c1":"## [Tutorial] House Prices: Advanced Regression Techniques\n### \ucc45 <\ud30c\uc774\uc36c \uba38\uc2e0\ub7ec\ub2dd \uc644\ubcbd \uac00\uc774\ub4dc> \ud544\uc0ac \ucf54\ub4dc\uc785\ub2c8\ub2e4.","58a090f7":"---\n#### \uc608\uce21 \uacb0\uacfc \ud63c\ud569\uc744 \ud1b5\ud55c \ucd5c\uc885 \uc608\uce21\uacfc \uc2a4\ud0dc\ud0b9 \uc559\uc0c1\ube14 \ubaa8\ub378\uc744 \ud1b5\ud55c \ud68c\uadc0 \uc608\uce21","a42d4d07":"---\n#### \uc120\ud615 \ud68c\uadc0 \ubaa8\ub378 \ud559\uc2b5\/\uc608\uce21\/\ud3c9\uac00","cdf76a9d":"---","8942c1d1":"---\n#### \ud68c\uadc0 \ud2b8\ub9ac \ubaa8\ub378 \ud559\uc2b5\/\uc608\uce21\/\ud3c9\uac00"}}