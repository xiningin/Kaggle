{"cell_type":{"522394a3":"code","d750f7bc":"code","31cfcf5d":"code","8fbccf70":"code","d0bbfd1d":"code","3a5c8518":"code","46f096ca":"code","099e252c":"code","3c94ed02":"code","7e9e6308":"code","9a8bdf8f":"code","2771e23a":"code","c1ddf55a":"code","54e13d3e":"code","581961c6":"code","94f49892":"code","568a3016":"code","3f39b6f3":"code","4beb7e62":"code","728932a9":"code","aec35794":"code","40508e1d":"code","49ff40d3":"code","89c2791d":"code","5008c902":"code","be59863b":"code","23e208e3":"markdown","0f3d4064":"markdown","abbd49ae":"markdown","dc955356":"markdown","5ce1d7bb":"markdown","2bf538a3":"markdown","29acd3ea":"markdown","756a18a1":"markdown","a4944814":"markdown","10a73120":"markdown","b676fb26":"markdown","0296f3bd":"markdown","813d3e4c":"markdown"},"source":{"522394a3":"import os, sys, warnings, random, time, cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport skimage.io\nfrom PIL import Image\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom IPython.display import display\nfrom tqdm import tqdm_notebook as tqdm\n\nimport torch\nimport albumentations\nfrom albumentations.pytorch import ToTensorV2\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nfrom torch.functional import F \nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n# from efficientnet_pytorch import model as enet\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')","d750f7bc":"pd.plotting.register_matplotlib_converters()\npd.options.display.max_rows=50\npd.options.display.max_columns=100\nplt.rcParams.update({'font.size':18})\nsns.set_style('darkgrid')\nplt.rcParams.update({'font.family':'Humor Sans'})\nplt.xkcd();","31cfcf5d":"SEED = 69\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\npackage_path = '..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master'\nsys.path.append(package_path)\nfrom efficientnet_pytorch import model as enet\n\nProgress_Bar = False\nDEBUG = False\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","8fbccf70":"data_dir = '..\/input\/prostate-cancer-grade-assessment\/'\ntrain_img_dir = os.path.join(data_dir, 'train_images')\ntrain_df = pd.read_csv(data_dir+'train.csv')\ntrain_df = train_df.sample(1000).reset_index(drop=True) if DEBUG else train_df\n\ndisplay(train_df.head())\nlen(train_df)","d0bbfd1d":"skf = StratifiedKFold(5, shuffle=True, random_state=SEED)\ntrain_df['fold'] = -1\nfor i, (tr_idx, val_idx) in enumerate(skf.split(train_df, train_df['isup_grade'])):\n    train_df.loc[val_idx, 'fold'] = i\ntrain_df.head()","3a5c8518":"train_df.drop(columns=['data_provider', 'gleason_score'], inplace=True)\ntrain_df.head()","46f096ca":"class Build_Dataset(Dataset):\n    '''Builds Dataset to be fed to Neural Network\n       :param df: train_df or test_df\n       :param resize: tuple, eg(256, 256)\n       :param mode: string train or test \n       :param: augmentations: Image augmentations\n    '''\n    def __init__(self, df, resize=None, mode='train', augmentations=None):\n        self.df = df\n        self.resize = resize\n        self.mode = mode\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            img_path = os.path.join(train_img_dir, self.df['image_id'].values[idx]) + '.tiff'\n            image = skimage.io.MultiImage(img_path)\n            label = self.df['isup_grade'].values[idx]\n            \n        if self.mode == 'test':\n            img_path = os.path.join(test_img_dir, self.df['image_id'].values[idx]) + '.tiff'\n            image = skimage.io.MultiImage(img_path)\n            label = -1\n            \n        if self.resize is not None:\n            image = cv2.resize(image[-1], (self.resize[0], self.resize[1]))\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            \n        image = np.array(image)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        #pytorch expects CHW instead of HWC\n#         image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        return image, label\n            ","099e252c":"def plot_images(images):\n\n    n_images = len(images)\n\n    rows = int(np.sqrt(n_images))\n    cols = int(np.sqrt(n_images))\n\n    fig = plt.figure(figsize=(20,10))\n    for i in range(rows*cols):\n        ax = fig.add_subplot(rows, cols, i+1)\n        ax.imshow(np.array(images[i][0]))\n        ax.set_title('ISUP: '+str(images[i][1]))\n        ax.axis('off')","3c94ed02":"N_IMAGES = 9\n\ntrain_data = Build_Dataset(train_df, resize=(512, 512), mode='train')\nimages = [(image, label) for image, label in [train_data[i] for i in range(N_IMAGES)]] \nplot_images(images)","7e9e6308":"#Image-net standard mean and std\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\n#Defining train and test transforms\ntrain_transforms = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    albumentations.Normalize(mean=mean, std=std, always_apply=True),\n    albumentations.pytorch.ToTensorV2(),\n])\ntest_transforms = albumentations.Compose([\n    albumentations.Normalize(mean=mean, std=std, always_apply=True),\n    albumentations.pytorch.ToTensorV2(),\n])","9a8bdf8f":"pretrainied_model = {\n    'efficientnet-b0': '..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth',\n    'efficientnet-b4': '..\/input\/efficientnet-pytorch\/efficientnet-b4-e116e8b3.pth'\n}\n\nclass enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrainied_model[backbone]))\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n    \n    def extract(self, x):\n        return self.enet(x)\n    \n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","2771e23a":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time \/ 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","c1ddf55a":"# model = enetv2('efficientnet-b0', 5).to(device)\n# loss_criterion = nn.CrossEntropyLoss().to(device)\n# optimizer=optim.Adam(model.parameters())\n\n# print(f'The model has {count_parameters(model):,} trainable parameters')","54e13d3e":"def train(model, iterator, optimizer, criterion, device):\n    \n    epoch_loss = 0\n    model.train()\n    bar = tqdm(iterator) if Progress_Bar else iterator\n    \n    for (x, y) in bar:\n        \n        x = x.to(device, dtype=torch.float)\n        y = y.to(device, dtype=torch.long)\n        optimizer.zero_grad()\n        y_pred = model(x)\n        loss = criterion(y_pred, y)\n        loss.backward()\n        optimizer.step()\n        loss_np = loss.detach().cpu().numpy()\n        epoch_loss += loss_np\n        if Progress_Bar:\n            bar.set_description('Training loss: %.5f' % (loss_np))\n        \n    return epoch_loss\/len(iterator)\n\ndef evaluate(model, iterator, criterion, device):\n    \n    epoch_loss = 0\n    preds = []\n    preds = np.array(preds)\n    targets = []\n    targets = np.array(targets)\n    model.eval()\n    bar = tqdm(iterator) if Progress_Bar else iterator\n    \n    with torch.no_grad():\n        \n        for (x, y) in bar:\n        \n            x = x.to(device, dtype=torch.float)\n            y = y.to(device, dtype=torch.long)\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            loss_np = loss.detach().cpu().numpy()\n            epoch_loss += loss_np\n            preds = np.append(preds, np.argmax(y_pred.detach().cpu().numpy(), axis = 1))\n            targets = np.append(targets, y.detach().cpu().numpy())\n#             preds = preds.reshape(-1)\n#             targets = targets.reshape(-1)\n            \n            if Progress_Bar:\n                bar.set_description('Validation loss: %.5f' % (loss_np))\n            \n    \n            \n    return epoch_loss\/len(iterator), metrics.cohen_kappa_score(targets, preds, weights='quadratic')","581961c6":"def fit_model(model, model_name, train_iterator, valid_iterator, optimizer, loss_criterion, device, epochs):\n    \"\"\" Fits a dataset to model\"\"\"\n    best_valid_loss = float('inf')\n    \n    train_losses = []\n    valid_losses = []\n    valid_metric_scores = []\n    \n    for epoch in range(epochs):\n    \n        start_time = time.time()\n    \n        train_loss = train(model, train_iterator, optimizer, loss_criterion, device)\n        valid_loss, valid_metric_score = evaluate(model, valid_iterator, loss_criterion, device)\n        \n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        valid_metric_scores.append(valid_metric_score)\n\n        if valid_loss < best_valid_loss:\n            best_valid_loss = valid_loss\n            torch.save(model.state_dict(), f'{model_name}.pt')\n    \n        end_time = time.time()\n\n        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n        print(f'Train Loss: {train_loss:.3f}')\n        print(f'Val. Loss: {valid_loss:.3f} |  Val. Metric Score: {valid_metric_score:.3f}')\n        \n    return train_losses, valid_losses, valid_metric_scores\n        \n#     return pd.DataFrame({f'{model_name}_Training_Loss':train_losses, \n#                         f'{model_name}_Training_Acc':train_accs, \n#                         f'{model_name}_Validation_Loss':valid_losses, \n#                         f'{model_name}_Validation_Acc':valid_accs})","94f49892":"tr_loss=[]\nval_loss=[]\nval_metric=[]\n\nfor fold in range(1):\n    print(f\"Fitting on Fold {fold+1}\")\n    #Make Train and Valid DataFrame from fold\n    train_df_fold = train_df[train_df['fold'] != fold]\n    valid_df_fold = train_df[train_df['fold'] == fold]\n    \n    #Build and load Dataset\n    train_data = Build_Dataset(train_df_fold, resize=(256, 256), mode='train', augmentations=train_transforms)\n    valid_data = Build_Dataset(valid_df_fold, resize=(256, 256), mode='train', augmentations=test_transforms)\n    train_iterator = DataLoader(train_data, shuffle=True, batch_size=16, num_workers=4)\n    valid_iterator = DataLoader(valid_data, batch_size=16, num_workers=4)\n    \n    #Initialize model, loss and optimizer\n    model = enetv2('efficientnet-b4', out_dim=6).to(device)\n    loss_criterion = nn.CrossEntropyLoss().to(device)\n    opt1=optim.Adam(model.parameters(), lr=0.01, betas=(0.9,0.999))\n    \n    temp_tr_loss, temp_val_loss, temp_val_metric = fit_model(model, 'efficientnet-b4', train_iterator, valid_iterator, opt1, loss_criterion, device, epochs=3)\n    \n    tr_loss+=temp_tr_loss\n    val_loss+=temp_val_loss\n    val_metric+=temp_val_metric\n    \n","568a3016":"opt2 = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\ntemp_tr_loss, temp_val_loss, temp_val_metric = fit_model(model, 'efficientnet-b4', train_iterator, valid_iterator, opt2, loss_criterion, device, epochs=4)\n\ntr_loss+=temp_tr_loss\nval_loss+=temp_val_loss\nval_metric+=temp_val_metric","3f39b6f3":"opt3 = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\ntemp_tr_loss, temp_val_loss, temp_val_metric = fit_model(model, 'efficientnet-b4', train_iterator, valid_iterator, opt3, loss_criterion, device, epochs=3)\n\ntr_loss+=temp_tr_loss\nval_loss+=temp_val_loss\nval_metric+=temp_val_metric","4beb7e62":"opt4 = optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.99))\ntemp_tr_loss, temp_val_loss, temp_val_metric = fit_model(model, 'efficientnet-b4', train_iterator, valid_iterator, opt4, loss_criterion, device, epochs=4)\n\ntr_loss+=temp_tr_loss\nval_loss+=temp_val_loss\nval_metric+=temp_val_metric","728932a9":"len(tr_loss)","aec35794":"plt.rcParams.update({'font.size':18})\nsns.set_style('darkgrid')\nplt.rcParams.update({'font.family':'Humor-Sans'})\n\nfig,ax = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\nax[0].plot(tr_loss)\nax[0].set_title('Training and Validation Loss')\nax[0].plot(val_loss)\nax[0].set_ylim((1,2))\nax[0].set_xlabel('Epoch')\n\nax[1].plot(val_metric)\nax[1].set_title('Val Cohen Score')\nax[1].set_xlabel('Epoch')\n\n\nax[0].legend();\nax[1].legend();","40508e1d":"def get_predictions(model, iterator, device):\n    \n    preds = []\n    model.eval()\n    bar = tqdm(iterator) if Progress_Bar else iterator\n    \n    with torch.no_grad():\n        \n        for (x, y) in bar:\n        \n            x = x.to(device, dtype=torch.float)\n            y = y.to(device, dtype=torch.long)\n            y_pred = model(x)\n            preds.append(np.argmax(y_pred.detach().cpu().numpy(), axis = 1))\n            \n    preds = np.array(preds)\n    preds = preds.reshape(-1)\n            \n    return preds","49ff40d3":"test_df = pd.read_csv(data_dir+'test.csv')\nsample = pd.read_csv('..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv')\ntest_df.drop(columns=['data_provider'], inplace=True)\ntest_img_dir = '..\/input\/prostate-cancer-grade-assessment\/test_images'\n    \n# #Build and load Test Data\n# test_data = Build_Dataset(test_df, resize=(256, 256), mode='test', augmentations=test_transforms)\n# test_iterator = DataLoader(test_data, batch_size=2, num_workers=4)\n    \n# #Get predictions\n# y_pred = get_predictions(model, test_iterator, device)\n    \n# #Submit Predictions\n# test_df['isup_grade'] = y_pred\n# test_df.to_csv('submission.csv', index=False)","89c2791d":"def submit(sample):\n    if os.path.exists('..\/input\/prostate-cancer-grade-assessment\/test_images'):\n        test_data = Build_Dataset(test_df, resize=(256, 256), mode='test', augmentations=test_transforms)\n        test_iterator = DataLoader(test_data, batch_size=2, num_workers=4)\n        preds = get_predictions(model, test_iterator, device)\n        sample['isup_grade'] = preds\n    return sample","5008c902":"submission = submit(sample)\nsubmission['isup_grade'] = submission['isup_grade'].astype(int)\nsubmission.head()","be59863b":"submission.to_csv('submission.csv', index=False)","23e208e3":"# Defining Training Loop","0f3d4064":"# Create Folds","abbd49ae":"# Making submission to leaderboard","dc955356":"# Building Model","5ce1d7bb":"# Fixing Config","2bf538a3":"# Training with 5-Fold CV","29acd3ea":"The Kernel uses the EfficientNet B4 to get a LB 0.6. The model is trained with three stages of decremented learning rate.\nI'm yet to add CV Folds and this Kernel runs for only one fold. \nTo add in the Future - \n1. 4-Fold CV\n2. N_tiles\n3. Try Cyclic learning rates\n\nHope this helps the viewer. It is not supposed to be score grabber but a simple Pytorch Implementation for beginners.\nPlease Upvote if you like it.","756a18a1":"# **Plotting the Losses and the Metric**","a4944814":"# Plotting some Images","10a73120":"# Building Dataset","b676fb26":"# Loading the Important Libraries","0296f3bd":"# Processing The Images","813d3e4c":"# Defining Training and Validation epochs"}}