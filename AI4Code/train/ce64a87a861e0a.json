{"cell_type":{"55473809":"code","c435e736":"code","ac74c0ba":"code","222a3550":"code","94807dfa":"code","d83c223d":"code","78e5e740":"code","05fcfd78":"code","1180851a":"code","593aced7":"code","f2098bf2":"code","54bf4d5e":"code","b3f6879e":"code","ade0810e":"code","974b8834":"code","21cf7ad4":"markdown","497bd919":"markdown","f6d34364":"markdown","8c6ac6b2":"markdown","17250973":"markdown","cf0dc1c0":"markdown","d9d0d79f":"markdown","2d0b5e9d":"markdown","8bba44b5":"markdown","f98a5726":"markdown","121210d2":"markdown","b09c71af":"markdown","b08ab596":"markdown","1308adcd":"markdown","d676a506":"markdown"},"source":{"55473809":"%%capture\n!pip install bertopic","c435e736":"from plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True) ","ac74c0ba":"import json\n\n# https:\/\/arxiv.org\/help\/api\/user-manual\ncategory_map = {'astro-ph': 'Astrophysics',\n'astro-ph.CO': 'Cosmology and Nongalactic Astrophysics',\n'astro-ph.EP': 'Earth and Planetary Astrophysics',\n'astro-ph.GA': 'Astrophysics of Galaxies',\n'astro-ph.HE': 'High Energy Astrophysical Phenomena',\n'astro-ph.IM': 'Instrumentation and Methods for Astrophysics',\n'astro-ph.SR': 'Solar and Stellar Astrophysics',\n'cond-mat.dis-nn': 'Disordered Systems and Neural Networks',\n'cond-mat.mes-hall': 'Mesoscale and Nanoscale Physics',\n'cond-mat.mtrl-sci': 'Materials Science',\n'cond-mat.other': 'Other Condensed Matter',\n'cond-mat.quant-gas': 'Quantum Gases',\n'cond-mat.soft': 'Soft Condensed Matter',\n'cond-mat.stat-mech': 'Statistical Mechanics',\n'cond-mat.str-el': 'Strongly Correlated Electrons',\n'cond-mat.supr-con': 'Superconductivity',\n'cs.AI': 'Artificial Intelligence',\n'cs.AR': 'Hardware Architecture',\n'cs.CC': 'Computational Complexity',\n'cs.CE': 'Computational Engineering, Finance, and Science',\n'cs.CG': 'Computational Geometry',\n'cs.CL': 'Computation and Language',\n'cs.CR': 'Cryptography and Security',\n'cs.CV': 'Computer Vision and Pattern Recognition',\n'cs.CY': 'Computers and Society',\n'cs.DB': 'Databases',\n'cs.DC': 'Distributed, Parallel, and Cluster Computing',\n'cs.DL': 'Digital Libraries',\n'cs.DM': 'Discrete Mathematics',\n'cs.DS': 'Data Structures and Algorithms',\n'cs.ET': 'Emerging Technologies',\n'cs.FL': 'Formal Languages and Automata Theory',\n'cs.GL': 'General Literature',\n'cs.GR': 'Graphics',\n'cs.GT': 'Computer Science and Game Theory',\n'cs.HC': 'Human-Computer Interaction',\n'cs.IR': 'Information Retrieval',\n'cs.IT': 'Information Theory',\n'cs.LG': 'Machine Learning',\n'cs.LO': 'Logic in Computer Science',\n'cs.MA': 'Multiagent Systems',\n'cs.MM': 'Multimedia',\n'cs.MS': 'Mathematical Software',\n'cs.NA': 'Numerical Analysis',\n'cs.NE': 'Neural and Evolutionary Computing',\n'cs.NI': 'Networking and Internet Architecture',\n'cs.OH': 'Other Computer Science',\n'cs.OS': 'Operating Systems',\n'cs.PF': 'Performance',\n'cs.PL': 'Programming Languages',\n'cs.RO': 'Robotics',\n'cs.SC': 'Symbolic Computation',\n'cs.SD': 'Sound',\n'cs.SE': 'Software Engineering',\n'cs.SI': 'Social and Information Networks',\n'cs.SY': 'Systems and Control',\n'econ.EM': 'Econometrics',\n'eess.AS': 'Audio and Speech Processing',\n'eess.IV': 'Image and Video Processing',\n'eess.SP': 'Signal Processing',\n'gr-qc': 'General Relativity and Quantum Cosmology',\n'hep-ex': 'High Energy Physics - Experiment',\n'hep-lat': 'High Energy Physics - Lattice',\n'hep-ph': 'High Energy Physics - Phenomenology',\n'hep-th': 'High Energy Physics - Theory',\n'math.AC': 'Commutative Algebra',\n'math.AG': 'Algebraic Geometry',\n'math.AP': 'Analysis of PDEs',\n'math.AT': 'Algebraic Topology',\n'math.CA': 'Classical Analysis and ODEs',\n'math.CO': 'Combinatorics',\n'math.CT': 'Category Theory',\n'math.CV': 'Complex Variables',\n'math.DG': 'Differential Geometry',\n'math.DS': 'Dynamical Systems',\n'math.FA': 'Functional Analysis',\n'math.GM': 'General Mathematics',\n'math.GN': 'General Topology',\n'math.GR': 'Group Theory',\n'math.GT': 'Geometric Topology',\n'math.HO': 'History and Overview',\n'math.IT': 'Information Theory',\n'math.KT': 'K-Theory and Homology',\n'math.LO': 'Logic',\n'math.MG': 'Metric Geometry',\n'math.MP': 'Mathematical Physics',\n'math.NA': 'Numerical Analysis',\n'math.NT': 'Number Theory',\n'math.OA': 'Operator Algebras',\n'math.OC': 'Optimization and Control',\n'math.PR': 'Probability',\n'math.QA': 'Quantum Algebra',\n'math.RA': 'Rings and Algebras',\n'math.RT': 'Representation Theory',\n'math.SG': 'Symplectic Geometry',\n'math.SP': 'Spectral Theory',\n'math.ST': 'Statistics Theory',\n'math-ph': 'Mathematical Physics',\n'nlin.AO': 'Adaptation and Self-Organizing Systems',\n'nlin.CD': 'Chaotic Dynamics',\n'nlin.CG': 'Cellular Automata and Lattice Gases',\n'nlin.PS': 'Pattern Formation and Solitons',\n'nlin.SI': 'Exactly Solvable and Integrable Systems',\n'nucl-ex': 'Nuclear Experiment',\n'nucl-th': 'Nuclear Theory',\n'physics.acc-ph': 'Accelerator Physics',\n'physics.ao-ph': 'Atmospheric and Oceanic Physics',\n'physics.app-ph': 'Applied Physics',\n'physics.atm-clus': 'Atomic and Molecular Clusters',\n'physics.atom-ph': 'Atomic Physics',\n'physics.bio-ph': 'Biological Physics',\n'physics.chem-ph': 'Chemical Physics',\n'physics.class-ph': 'Classical Physics',\n'physics.comp-ph': 'Computational Physics',\n'physics.data-an': 'Data Analysis, Statistics and Probability',\n'physics.ed-ph': 'Physics Education',\n'physics.flu-dyn': 'Fluid Dynamics',\n'physics.gen-ph': 'General Physics',\n'physics.geo-ph': 'Geophysics',\n'physics.hist-ph': 'History and Philosophy of Physics',\n'physics.ins-det': 'Instrumentation and Detectors',\n'physics.med-ph': 'Medical Physics',\n'physics.optics': 'Optics',\n'physics.plasm-ph': 'Plasma Physics',\n'physics.pop-ph': 'Popular Physics',\n'physics.soc-ph': 'Physics and Society',\n'physics.space-ph': 'Space Physics',\n'q-bio.BM': 'Biomolecules',\n'q-bio.CB': 'Cell Behavior',\n'q-bio.GN': 'Genomics',\n'q-bio.MN': 'Molecular Networks',\n'q-bio.NC': 'Neurons and Cognition',\n'q-bio.OT': 'Other Quantitative Biology',\n'q-bio.PE': 'Populations and Evolution',\n'q-bio.QM': 'Quantitative Methods',\n'q-bio.SC': 'Subcellular Processes',\n'q-bio.TO': 'Tissues and Organs',\n'q-fin.CP': 'Computational Finance',\n'q-fin.EC': 'Economics',\n'q-fin.GN': 'General Finance',\n'q-fin.MF': 'Mathematical Finance',\n'q-fin.PM': 'Portfolio Management',\n'q-fin.PR': 'Pricing of Securities',\n'q-fin.RM': 'Risk Management',\n'q-fin.ST': 'Statistical Finance',\n'q-fin.TR': 'Trading and Market Microstructure',\n'quant-ph': 'Quantum Physics',\n'stat.AP': 'Applications',\n'stat.CO': 'Computation',\n'stat.ME': 'Methodology',\n'stat.ML': 'Machine Learning',\n'stat.OT': 'Other Statistics',\n'stat.TH': 'Statistics Theory'}\n\ndata_file = '..\/input\/arxiv\/arxiv-metadata-oai-snapshot.json'\n\ndef get_metadata():\n    with open(data_file, 'r') as f:\n        for line in f:\n            yield line\n            \ntitles = []\nabstracts = []\nyears = []\ncategories = []\nmetadata = get_metadata()\nfor paper in metadata:\n    paper_dict = json.loads(paper)\n    ref = paper_dict.get('journal-ref')\n    try:\n        year = int(ref[-4:]) \n        if 2000 < year <= 2021:\n            categories.append(category_map[paper_dict.get('categories').split(\" \")[0]])\n            years.append(year)\n            titles.append(paper_dict.get('title'))\n            abstracts.append(paper_dict.get('abstract'))\n    except:\n        pass \n\nlen(titles), len(abstracts), len(years), len(categories)","222a3550":"from bertopic import BERTopic\n\ntopic_model = BERTopic(verbose=True, embedding_model=\"paraphrase-MiniLM-L12-v2\", min_topic_size=50)\ntopics, _ = topic_model.fit_transform(abstracts); len(topic_model.get_topic_info())","94807dfa":"topic_model.get_topic_info().head(10)","d83c223d":"topic_model.visualize_barchart(top_n_topics=9, height=700)","78e5e740":"topic_model.visualize_term_rank()","05fcfd78":"topic_model.visualize_term_rank(log_scale=True)","1180851a":"topic_model.visualize_topics(top_n_topics=50)","593aced7":"topic_model.visualize_hierarchy(top_n_topics=50, width=800)","f2098bf2":"topic_model.visualize_heatmap(n_clusters=20, top_n_topics=100)","54bf4d5e":"topics_over_time = topic_model.topics_over_time(abstracts, topics, years)","b3f6879e":"topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20, width=900, height=500)","ade0810e":"topics_per_class = topic_model.topics_per_class(abstracts, topics, classes=categories)","974b8834":"topic_model.visualize_topics_per_class(topics_per_class, top_n_topics=10, width=900)","21cf7ad4":"## Install BERTopic\nWe start by installing BERTopic from PyPi:","497bd919":"**NOTE**: After installing BERTopic, make sure to restart the notebook to re-import the correct versions of packages that were previously imported. ","f6d34364":"The distance between topics show, to a certain extend, the similarities between topics. However, to better visualize and understand the similarity between topics, we can use two plots to gives us further insight into that. Namely, visualizing the possible topic hierarchy and its similarity matrix:","8c6ac6b2":"## Topic Relationships\nHaving extracted the topics and their representations it might be helpful to check out the uniqueness of each topic. Some topics might be quite similar and could be merged or are simply interesting to research further. \n\nTo do this, we start off by mapping our topics to a 2D representation by reducing the topic vectors with UMAP:","17250973":"## Prepare Data\nWe start by extracting all abstracts between 2000 and 2021, their titles and the years in which they were published.","cf0dc1c0":"## Topics over Time\nAlthough extracting the topics and their representation is interesting, we are missing some dimensional information. For example, some topics might not be relevant anymore or some are gaining traction over the last years. That can be vital information when making decisions. \n\nHere, we will model the topics over the years. For each topic and timestep, we calculate the c-TF-IDF representation. This will result in a specific topic representation at each timestep without the need to create clusters from embeddings as they were already created. However, topics can be regarded as evolutionary entities that evolve and change over time. This means that a topic representation at timestep *t* should be related to its representation at timesetps *t-1* and *t+1*. To model this evolutionary trend, we average its c-TF-IDF representation with that of the c-TF-IDF representation at timestep *t-1*. This is done for each topic representation allowing for the representations to evolve over time.","d9d0d79f":"The blocky structure in the heatmap shows that there are some clusters of topics to be found that are somewhat similar to each other. Zooming into these topics helps us understand why they are similar. If you hover over the topics, you can see the topic ID and representation. ","2d0b5e9d":"Using the elbow method, it seems that 3 words per topic are sufficient in representing the topic well. Any words that we add after that have seemingly little effect. \n\n**NOTE**: All visualizations are created with Plotly and are as such interactive!","8bba44b5":"## Train Topic Model\nNext, we train our BERTopic model using just a few changes to the default parameters. \n\nStarting off is the embedding model. The string `\"paraphrase-MiniLM-L6-v2\"` references the embedding model that can be found [here](https:\/\/www.sbert.net\/docs\/pretrained_models.html#sentence-embedding-models) and is a great sentence-transformer model that balances performance with speed. \n\nNext, we make sure that the minimum topic size of our topics is 50. We do this to limit the number of topics that could be generated. For example, if the minimum were to be 10 then much more topics could be generated that are most likely to be of little interest. Since we want large topics, we set it to 50. ","f98a5726":"From a glance, the most frequent topics seem to have coherent and clear topic representations. Interpretation of these clusters is much easier if you are familiar with the content of the documents. For example, to me, Topic 6 seems to be clearly about anything Data Science and AI.\n\nFor each topic, we have generated 10 words that best represent that topic. However, are 10 words sufficient? Can we already have a good topic representation with 1 word? \n\nTo understand the amount of words needed to have a sufficient topic representation, we can show the decline of term score when adding terms. The idea here is that each term that is added has a lower term score than the previous since the first is the best term for the topic. Eventually, we reach the point of diminishing returns, which is very similar to the elbow-method used in k-NN. Below, you can see the decline in term score when adding terms per topic:","121210d2":"## Topics per Class\nLastly, let's focus on the given categories for each paper. Can we find out which topics are frequently found in certain categories? Typically, topic modeling tends to find more topics than the categories that were previously defined. This helps us find and understand certain subcategories that might exist in the data. ","b09c71af":"# Topic Modeling arXiv Abstracts\n\n<a href=\"https:\/\/github.com\/MaartenGr\/BERTopic\"><img src=\"https:\/\/raw.githubusercontent.com\/MaartenGr\/BERTopic\/master\/images\/logo.png\" width=\"20%\" height=\"20%\" align=\"right\" \/><\/a>\n\nIn this notebook, we will go through applying advanced topic modeling techniques with [BERTopic](https:\/\/github.com\/MaartenGr\/BERTopic). Topic modeling is a technique that allows users to generate insights into large amount of textual data without the need to read them individually. \n\nHowever, more than just looking at the generated topics, we want to understand topic relations, how they evolved over time, and how we can improve topic representations. The true strength of topic modeling is looking beyond merely generating topics and using them to truly understand the relationships and patterns in the data. \n\nThe great thing about using these Arxiv abstracts is that the text is typically well-structured and nicely written. For BERT-based embedding models this allows the document representations to be a bit more accurate than what we would normally see. ","b08ab596":"From the visualization above, we can see some interesting patterns appearing. Namely, around 2012 a lot of topics seem to become less and less frequent with several topics taking over. For example, topics 2 and 3 seem to be popular until 2012 after which its popularity decreased significantly. ","1308adcd":"## Topic Representation\n\nWe can see that roughly 200 topics were generated from our topics. Next, let's see what the major topics are:\n\n","d676a506":"**NOTE**: BERTopic is stochastic since it uses UMAP as one of its dependencies so the results may differ between runs. "}}