{"cell_type":{"5a91145c":"code","c19bea0d":"code","ad669f05":"code","72835d9f":"code","db34a9cf":"code","26fbb754":"code","47041670":"code","91b2aae5":"code","fb76f6d1":"code","01eb6cf6":"code","1c652d8d":"code","f70080ea":"markdown","8b667539":"markdown","20eddb1b":"markdown","7ac98ae8":"markdown","5c0db6ee":"markdown","6e87f9a9":"markdown","a8f6c332":"markdown","1fc5351e":"markdown","ea201d09":"markdown","3c1bb63f":"markdown","694816bd":"markdown","28c9a524":"markdown","80e120be":"markdown","169b6fa3":"markdown"},"source":{"5a91145c":"import pandas as pd\nimport numpy as np\n\n# m\u00e9trica y datasets\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\n# modelos\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# feature engineering\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.preprocessing import StandardScaler\n\n# visualizaci\u00f3n\nfrom seaborn import heatmap\n\nimport os\nprint(os.listdir(\"..\/input\"))","c19bea0d":"data = pd.concat([\n       pd.read_csv(\"..\/input\/banco-galicia-dataton-2019\/pageviews\/pageviews.csv\", parse_dates=[\"FEC_EVENT\"]),\n       pd.read_csv(\"..\/input\/banco-galicia-dataton-2019\/pageviews_complemento\/pageviews_complemento.csv\", parse_dates=[\"FEC_EVENT\"])\n])\n\n# Test\nX_test = []\nfor c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n    print(\"haciendo\", c)\n    temp = pd.crosstab(data.USER_ID, data[c])\n    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n    X_test.append(temp.apply(lambda x: x \/ x.sum(), axis=1))\nX_test = pd.concat(X_test, axis=1)\n\n# Train\ndata = data[data.FEC_EVENT.dt.month < 10]\nX_train = []\nfor c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n    print(\"haciendo\", c)\n    temp = pd.crosstab(data.USER_ID, data[c])\n    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n    X_train.append(temp.apply(lambda x: x \/ x.sum(), axis=1))\nX_train = pd.concat(X_train, axis=1)\n\nfeatures = list(set(X_train.columns).intersection(set(X_test.columns)))\nX_train = X_train[features]\nX_test = X_test[features]\n\ny_prev = pd.read_csv(\"..\/input\/banco-galicia-dataton-2019\/conversiones\/conversiones.csv\")\ny_train = pd.Series(0, index=X_train.index)\nidx = set(y_prev[y_prev.mes >= 10].USER_ID.unique()).intersection(\n        set(X_train.index))\ny_train.loc[list(idx)] = 1","ad669f05":"def model_auc_score(model, X_t, y_t, X_v, y_v):\n    model.fit(X_t, y_t)\n    y_pred_t = model.predict_proba(X_t)[:,1]\n    y_pred_v = model.predict_proba(X_v)[:,1]\n    auc_t = roc_auc_score(y_t, y_pred_t)\n    auc_v = roc_auc_score(y_v, y_pred_v)\n    return auc_t, auc_v\n\ndef report_model(label, auc_t, auc_v):\n    print('------- ' + label + '  --------')\n    print('Training auc:   ' + str(auc_t))\n    print('Validation auc: ' + str(auc_v))\n    \ndef normalize(x_train, x_test):\n    scaler = StandardScaler()\n    x_train = scaler.fit_transform(x_train)\n    x_test = scaler.transform(x_test)\n    return x_train, x_test","72835d9f":"SEED = 18 # mi n\u00famero de la suerte :)\nx_train = X_train.values\ny_tr = y_train.values\n\n# dividiendo el dataset\nX_t, X_v, y_t, y_v = train_test_split(x_train, y_tr, test_size=0.20, random_state=SEED)\n# normalizando\nX_t, X_v = normalize(X_t, X_v)\n\n# logistic regression\nlr = LogisticRegression(random_state=SEED)\nauc_t, auc_v = model_auc_score(lr, X_t, y_t, X_v, y_v)\nreport_model('Logistic Regression', auc_t, auc_v)\n\n\n# xgb\nxgb = XGBClassifier(random_state=SEED, booster='gbtree')\nauc_t, auc_v = model_auc_score(xgb, X_t, y_t, X_v, y_v)\nreport_model('XGB', auc_t, auc_v)","db34a9cf":"features = X_train.columns\nf_scores = f_classif(X_train, y_train)[0] # el [1] son los p-values.\n\ndf_fscores = pd.DataFrame({'features':features,'score':f_scores})\ndf_fscores = df_fscores.sort_values('score', ascending = False)\ndf_fscores.head(10)","26fbb754":"# eliminando las features que no son relevantes\nLIM_IRR = 10 # ajustable\ndf_fscores = df_fscores[df_fscores['score'] > LIM_IRR]\nX_sel = X_train[df_fscores['features']]\nX_sel.shape","47041670":"xcorr = X_sel.corr().abs()\nheatmap(xcorr)","91b2aae5":"# seleccionando las features redundantes\nLIM_COR = 0.9 # ajustable\nxcorr = xcorr[xcorr > LIM_COR].fillna(0)\nindex = []\ncolumn = []\nfor idx in list(xcorr.index):\n    for col in list(xcorr.columns):\n        # la matriz es diagonal\n        if idx == col:\n            break\n        if (xcorr.loc[idx,col] != 0):\n            index = index + [idx]\n            column = column + [col]\ndf_fcorr = pd.DataFrame({'index':index, 'col':column})\ndf_fcorr.head(10)","fb76f6d1":"# dropeamos las features correlacionadas que estan menos correlacionadas con el target\nfor idx in df_fcorr.index:\n    f_idx = df_fcorr.loc[idx,'index']\n    f_col = df_fcorr.loc[idx,'col']\n    score_idx = df_fscores.loc[df_fscores['features'] == f_idx, 'score'].ravel()\n    score_col = df_fscores.loc[df_fscores['features'] == f_col, 'score'].ravel()\n    if score_idx > score_col:\n        df_fcorr.loc[idx, 'drop'] = f_col\n    else:\n        df_fcorr.loc[idx, 'drop'] = f_idx \ndrop_features = list(df_fcorr['drop'].unique())\n\nX_sel.drop(columns=drop_features, inplace=True)\nX_sel.shape","01eb6cf6":"x_sel = X_sel.values\nX_t, X_v, y_t, y_v = train_test_split(x_sel, y_tr, test_size=0.20, random_state=SEED)\nX_t, X_v = normalize(X_t, X_v)","1c652d8d":"lr = LogisticRegression(random_state=SEED)\n[auc_t, auc_v] = model_auc_score(lr, X_t, y_t, X_v, y_v)\nreport_model('Logistic Regression', auc_t, auc_v)\n\nxgb = XGBClassifier(random_state=SEED)\n[auc_t, auc_v] = model_auc_score(xgb, X_t, y_t, X_v, y_v)\nreport_model('XGB', auc_t, auc_v)","f70080ea":"Veamos cu\u00e1les son esas features que est\u00e1n m\u00e1s correlacionadas con el target?\n* **PAGE_110: \/PRESTAMOS\/SOLICITAR**\n* **PAGE_109: \/PRESTAMOS\/SOLICITAR-SELECCIONAR-SUBTIPO-PRESTAMO-PER**\n* **PAGE_41 : \/PRESTAMOS\/INICIO**\n* **PAGE_108: \/PRESTAMOS\/SOLICITAR-SELECCIONAR-TIPO-PRESTAMO**\n* **PAGE_345: \/PRESTAMOS\/SOLICITAR-EXITO**\n* **PAGE_285: \/PRESTAMOS\/SOLICITAR-SELECCIONAR-DESTINO**\n* **PAGE_287: \/PRESTAMOS\/SOLICITAR-PRECONFIRMACION**\n* **PAGE_1259: \/PRESTAMOS\/SOLICITAR_SELECCIONAR_SUBTIPO_PRESTAMO_PER**\n* **CONTENT_CATEGORY_16: NO CATEGORY ASSIGNED > HB : PP** \n\nInteresante! La mayor\u00eda de las features con mayor correlaci\u00f3n son urls con el prefijo: **\/PRESTAMOS\/**. Seguramente habr\u00e1 **colinearidad** entre ellas, ya que es muy probable que para llegar a una el usuario tenga que haber pasado por la otra antes. En particular, la **PAGE_110** es la misma que la **PAGE_1259**, la diferencia est\u00e1 en los separadores... puede ser interesante tomar la suma de las visitas a esas dos y expresarla como una... animate :)","8b667539":"De la gr\u00e1fica vemos que hay alta correlaci\u00f3n entre algunas features (zonas blancas), lo que significa que hay muchas features **redundantes** que brindan la misma informaci\u00f3n. Entonces, c\u00f3mo las eliminamos? Se pueden probar varias estrategias, como agruparlas, en este kernel eliminaremos aquellas features redundantes y con menor relevancia, o sea con menor correlaci\u00f3n con el target.","20eddb1b":"### Correlaci\u00f3n con el target ANOVA f-test","7ac98ae8":"# Selecci\u00f3n de features\n\nEl prop\u00f3sito de este notebook es indagar en el proceso de **selecci\u00f3n de features** y sus efectos en **modelos lineales** y en **modelos basados en \u00e1rboles de decisi\u00f3n**. A diferencia de los modelos basados en \u00e1rboles de decisi\u00f3n, el desempe\u00f1o de los modelos lineales se ve significativamente afectado por la presencia de features redundantes (**multicolinearidad**). Por este motivo, existen numerosos procedimientos para la identificaci\u00f3n y eliminaci\u00f3n de estas features. \n\nEn particular, el m\u00e9todo empleado para la selecci\u00f3n es simple y artesanal pero muy ilustrativo, con el objetivo de tener el m\u00e1ximo control del proceso de selecci\u00f3n y, a la vez, familiarizarnos con el dominio muestral, lo que nos facilitar\u00e1 el proceso de creaci\u00f3n de features.  ","5c0db6ee":"## Conclusiones\n\nCon este proceso simple de selecci\u00f3n de features, logramos reducir la dimensionalidad del dataset a la vez que mejoramos dr\u00e1sticamente el desempe\u00f1o de Logistic Regression. Por otro lado, aunque el desempe\u00f1o de XGB no mejor\u00f3 significativamente, ahora se pueden tunear sus par\u00e1metros de forma r\u00e1pida y efectiva.\n\n* El desempe\u00f1o de **Logistic Regression** mejor\u00f3 significativamente (0.66 -> 0.82).\n* El desempe\u00f1o de **XGB** tambi\u00e9n mejor\u00f3 pero en menor medida (0.85 -> 0.86), esto se debe a que al ser un modelo basado en \u00e1rboles de decisi\u00f3n la multicolinearidad no lo afectaba.\n\n## Pr\u00f3ximos Pasos\n\n* Tratar el **skewness** de las features para Logistic Regression. \n* A\u00f1adir **regularizaci\u00f3n** al Logistic Regression.\n* Tunear los **hyperpar\u00e1metros** de ambos modelos.\n* **Crear features** con la informaci\u00f3n del dominio ganada.\n* Hacer **stack ensemble** con estos y otros modelos.","6e87f9a9":"## Creaci\u00f3n de datasets \n\nLos datasets ser\u00e1n creados de la misma forma que en el notebook del benchmark","a8f6c332":"## Definici\u00f3n de funciones \u00fatiles","1fc5351e":"## Evaluando de nuevo los modelos","ea201d09":"## Selecci\u00f3n de Features","3c1bb63f":"Los resultados hablan por si solos!\n* **XGB** tuvo buen score de validaci\u00f3n (compar\u00e1ndolo con el public leaderboard, pod\u00e9s probarlo ;) ) \n* **Logistic Regression** tuvo p\u00e9simo score de validaci\u00f3n y muy bueno de training, lo cu\u00e1l es un claro signo de **overfitting**\n\nPara mitigar este efecto hay varias estrategias: agregar **regularizaci\u00f3n** (C), tunear los **hyperpar\u00e1metros** del modelo o **eliminar features** redundantes y\/o irrelevantes. En este kernel se explora el efecto de esta \u00faltima a trav\u00e9s de un m\u00e9todo artesanal y simple. ","694816bd":"## Evaluaci\u00f3n sin selecci\u00f3n de features\n\nEn esta etapa inicial evaluaremos los modelos directamente sobre el dataset, la \u00fanica operaci\u00f3n que realizaremos es la de **estandarizaci\u00f3n**.\n* Modelo lineal: **LogisitcRegression**\n* Modelo basado en \u00e1rboles de decisi\u00f3n: **XGBClassifier(booster = 'gbtree')**\n\n*Hay que poner especial cuidado al hacer la estandarizaci\u00f3n, ya que tiene que ajustar sus par\u00e1metros con el training (**fit_transform**) y luego transformar (**transform**) el test. Por lo que hay que dividir nuestro dataset antes.*","28c9a524":"Bien, nuestro objetivo es eliminar aquellas features que sean **irrelevantes** y\/o **redundantes**. Una feature es irrelevante cuando est\u00e1 pobremente correlacionada (asociada, para features categ\u00f3ricas) con el **target**. Por otro lado, una feature es redundante cuando su informaci\u00f3n es expresada, parcial o completamente, por otra(s) feature(s) lo que se traduce en una alta **correlaci\u00f3n** entre ellas.","80e120be":"Ahora, c\u00f3mo medimos la correlaci\u00f3n entre una variable **num\u00e9rica** (nuestras features) y una variable **categ\u00f3rica** (el target)? \n\nEn este notebook, usaremos el test estad\u00edsitco-f para an\u00e1lisis de varianza **ANOVA**. Este test, b\u00e1sicamente, asigna un score a la variaci\u00f3n entre las medias obtenidas al agrupar los valores num\u00e9ricos en las distintas categor\u00edas de la variable categ\u00f3rica. A mayor score mayor **\"correlaci\u00f3n\"** entre la feature num\u00e9rica y la categ\u00f3rica.","169b6fa3":"### Correlaci\u00f3n lineal entre features (Multicolinearidad)"}}