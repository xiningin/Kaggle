{"cell_type":{"66314d01":"code","ed10a5d9":"code","b4bcb63a":"code","83cd1647":"code","1b94ef82":"code","055ed80c":"code","c88e32c6":"code","6ca61730":"code","60df87d2":"code","68d03588":"code","2e0650aa":"code","f85bdf26":"code","e2d23bbe":"code","61443a24":"code","72b4befb":"code","679ade5f":"code","09aa4548":"code","276bd09c":"code","627cd3c9":"code","7a6c6e0a":"code","8a9a1d54":"code","b9edce30":"code","0f04fdaa":"code","17b3b289":"code","cf913e47":"code","7590a1a8":"markdown","d8c7fb38":"markdown","a7dce798":"markdown","c5db3a76":"markdown","750d5641":"markdown","727f17c8":"markdown","2d536ee9":"markdown","d12bda2f":"markdown","34455cbb":"markdown","813c6565":"markdown","09e629db":"markdown","b9b3bcf5":"markdown","343f192e":"markdown","1a75ac76":"markdown"},"source":{"66314d01":"import pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\nimport numpy as np\nimport pandas as pd\nimport gc\nimport random\nrandom.seed(2018)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ed10a5d9":"X_test = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_inicial_test\/ib_base_inicial_test.csv\", parse_dates=[\"codmes\"])\ncampanias = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_campanias\/ib_base_campanias.csv\", parse_dates=[\"codmes\"])\ndigital = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_digital\/ib_base_digital.csv\", parse_dates=[\"codday\"])\nrcc = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_rcc\/ib_base_rcc.csv\", parse_dates=[\"codmes\"])\nreniec = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_reniec\/ib_base_reniec.csv\")\nsunat = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_sunat\/ib_base_sunat.csv\")\nvehicular = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_vehicular\/ib_base_vehicular.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_inicial_train\/ib_base_inicial_train.csv\" , parse_dates=[\"codmes\"])\n","b4bcb63a":"#Chequeo la forma de los dataset complementarios y hago un peque\u00f1o apunte para saber en que consiste cada variable.\n#Sentirse libre de mirar uno por uno con df.head()\nprint('Forma del csv campanias', campanias.shape)\nprint('Forma del csv digital', digital.shape)\nprint('Forma del csv rcc', rcc.shape)\nprint('Forma del csv reniec', reniec.shape)\nprint('Forma del csv sunat', sunat.shape)\nprint('Forma del csv vehicular', vehicular.shape)","83cd1647":"rcc.producto.value_counts()     ","1b94ef82":"# Chequeo nulos en rcc\ntotal = rcc.isnull().sum().sort_values(ascending = False)\npercent = (rcc.isnull().sum()\/rcc.isnull().count()*100).sort_values(ascending = False)\nmissing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_application_train_data.head(6)","055ed80c":"train.shape, X_test.shape","c88e32c6":"list(train.columns.values)","6ca61730":"train.head()","60df87d2":"X_test.head()","68d03588":"# Chequeo nulos\ntotal = train.isnull().sum().sort_values(ascending = False)\npercent = (train.isnull().sum()\/train.isnull().count()*100).sort_values(ascending = False)\nmissing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_application_train_data.head(20)","2e0650aa":"# Chequeo nulos\ntotal = X_test.isnull().sum().sort_values(ascending = False)\npercent = (X_test.isnull().sum()\/X_test.isnull().count()*100).sort_values(ascending = False)\nmissing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_application_train_data.head(20)","f85bdf26":"# Chequeo nulos en campa\u00f1as\ntotal = campanias.isnull().sum().sort_values(ascending = False)\npercent = (campanias.isnull().sum()\/campanias.isnull().count()*100).sort_values(ascending = False)\nmissing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_application_train_data.head(20)","e2d23bbe":"# Chequeo nulos en digital\ntotal = digital.isnull().sum().sort_values(ascending = False)\npercent = (digital.isnull().sum()\/digital.isnull().count()*100).sort_values(ascending = False)\nmissing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_application_train_data.head(6)","61443a24":"# Chequeo nulos en reniec\ntotal = reniec.isnull().sum().sort_values(ascending = False)\npercent = (reniec.isnull().sum()\/reniec.isnull().count()*100).sort_values(ascending = False)\nmissing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_application_train_data.head(3)","72b4befb":"# Chequeo nulos en sunat\ntotal = sunat.isnull().sum().sort_values(ascending = False)\npercent = (sunat.isnull().sum()\/sunat.isnull().count()*100).sort_values(ascending = False)\nmissing_application_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_application_train_data.head(6)","679ade5f":"#paso a formato fecha la columna codmes\ntrain['codmes'] =  pd.to_datetime(train['codmes'], format='%Y%m')","09aa4548":"#saco el dia que esta por defecto en el 1ero de cada mes\ntrain['codmes'] = pd.to_datetime(train['codmes'] ).dt.to_period('M')","276bd09c":"train.head()","627cd3c9":"sns.countplot(train['codtarget'], palette='Set3')","7a6c6e0a":"print(\"Existen\", round(100*train[\"codtarget\"].value_counts()[1]\/train.shape[0],2), \"% de registros del target buscado\")","8a9a1d54":"train.codmes.value_counts()","b9edce30":"X_test['codmes'] =  pd.to_datetime(X_test['codmes'], format='%Y%m')\nX_test['codmes'] = pd.to_datetime(X_test['codmes']).dt.to_period('M')\nX_test.codmes.value_counts()","0f04fdaa":"campanias['codmes'] =  pd.to_datetime(campanias['codmes'], format='%Y%m')\ncampanias['codmes'] = pd.to_datetime(campanias['codmes']).dt.to_period('M')\ncampanias.codmes.value_counts()","17b3b289":"digital['codday'] =  pd.to_datetime(digital['codday'], format='%Y%m%d')\ndigital['codday'] = pd.to_datetime(digital['codday']).dt.to_period('M')\ndigital.codday.value_counts()","cf913e47":"rcc['codmes'] =  pd.to_datetime(rcc['codmes'], format='%Y%m')\nrcc['codmes']= pd.to_datetime(rcc['codmes']).dt.to_period('M')\nrcc.codmes.value_counts()","7590a1a8":"1. Un acercamiento es entrenar con cada mes por separado, con modelos distintos y testear en el mes+3, quedandonos con aquellos clientes que fueran elegidos por varios modelos\n2. otro experimento puede ser entrenar con todo el dataset y solo testear siempre con el mes 07. \n\n> Vale la pena entender el concepto de Target =1 c\u00f3mo margen. Una posibilidad es quedarnos en el set de entrenamiento solo con la columna target=1, por otro lado, podr\u00edamos experimentar si los clientes que tienen mayor margen (3er cuartil?) son siempre elegidos en testing\n","d8c7fb38":"<h1><center><font size=\"6\">Aproximacion a la data de Interbank<\/font><\/center><\/h1>\n\nPor Federico Moreno\n\nMi objetivo es compartir una primer mirada a la data de la competencia. Tratando de entender que tipo de variables componen a cada fuente de datos c\u00f3mo tambi\u00e9n la forma. En mi humilde opini\u00f3n, generar miles de gr\u00e1ficos y test estad\u00edsticos no tiene mucho sentido si no entendemos conceptualmente la naturaleza del problema que estamos abordando. Esta es la primera vez que comparto un notebook en una competencia. Mi objetivo es crear comunidad y compartir ideas. Sepanse libres de escribirme y comentarme los errores para mejorar. \n\nMuchas gracias","a7dce798":"# El set de entreamineto se compone solo de cuatro meses","c5db3a76":"### Data\n* **campanias.csv** 4.890.317 registros, 4 columas, cod, mes, id_persona, producto, canal asignado\n* **digital.csv** 1.41728, id, y 32 variables respecto a la navegaci\u00f3n web\n* **reniec.csv** 256.351 registros, id y 6 variables \"Sociologicas\" \n* **sunat.csv** 196336 y 3columnas, id_persona, tipo de trabajo y antiguedad laboral (\u00bfSe puede pasar la antiguedad a fecha relativa de cada registro mensual? \u00bfTiene alg\u00fan sentido?)\n* **vehicular.csv** 76954 registros y 4 variables, id_persona, marca + 2 variables de vehiculos","750d5641":"### Productos\n\n**rcc.csv**    \nContiene 11.705.553 registros  y 7 columnas, mes,id,banco,producto, clasificacion, mto saldo y rango de mora. Asumo que es un historial crediticio. el mtsaldo es importante en relaci\u00f3n al ingreso y deber\u00edamos encodear los productos. Veo que hay Prestamos personales, comerciales, hipotecarios, Tarjetas y tmb otros conceptos como lesings","727f17c8":"El Objetivo de este Notebook era entender en que consist\u00eda el dataset. Los pasos a seguir ser\u00e1 crear nuevas variables unificando las fuentes externas al dataset train para ir probando distintos experimentos. Queda pendiente establecer en el train una funci\u00f3n de Ganancia que pueda resumirse de la siguiente manera: \n\n**Ganancia = Target1 X Margencliente - Target0 X Costocliente**\n\nPara esto podemos sumar la cantidad de margen positivo y contar la cantidad de clientes, ah\u00ed tendriamos target1 = cantidad de clientes 1 y margen 1= a la suma de ese margen, analogo para costo. Dejando as\u00ed c\u00f3mo incognita a la cantidad de clientes que nuestro algoritmo clasificara correctamente como positivo y negativo.\n\nLa funci\u00f3n a maximizar ser\u00e1 entonces la funci\u00f3n de ganancias. Recordemos que frente a una funcion de ganancia, mayor area bajo la curva roc no determina mayor ganancia.","2d536ee9":"Train tiene 212mil prospectos y 7 columnas, Test tiene 178mil y 6 columnas. Me imagino que train tiene el target y test no","d12bda2f":"### Trato de entender la variable target para poner foco en las conversiones.","34455cbb":"No hay nulos en test, ni en train.","813c6565":"### Train y Test","09e629db":"Recordemos que los arboles son robustos al ruido y a outliers, mi enfoque es aplicar xgboost o ligthgbm que estan basados en los arboles. Por otro lado los nulos podr\u00e1n ser contados y agregados como nueva variables.","b9b3bcf5":"### Analisis del campo de fecha en las distintas fuentes de dato","343f192e":"**Pasamos todas las columnas de tiempo a formato fecha vemos que RCC, digital y campa\u00f1as tiene m\u00e1s fechas que nuestro set de entrenamiento. Para realizar Ingenieria de variables ser\u00e1 clave ver la tendencia (regresion, Max, Min) de variables historicas y luego crear variables segun mes presente**","1a75ac76":"**Reniec (variales sociologicas), Sunat (tipo de empleo) y Vehicular (auto), son variables de categor\u00eda que no dependen de un mes. Habr\u00e1 que pensar c\u00f3mo sumarlas al analisis como categoria de los clientes.**"}}