{"cell_type":{"aa4f7631":"code","e24c0e3a":"code","0fae2945":"code","c8e7796e":"code","1968f100":"code","d3e0cf0e":"code","f3eaca62":"code","668431a1":"code","875a9fb0":"code","9ad3efc4":"code","b07877c7":"code","57d7cb89":"code","f173e8b8":"code","1f515ce9":"code","a92bd537":"code","915b0d8f":"code","051f9dc9":"code","b528542c":"code","3952d37a":"code","04b6ea14":"code","be32ec8d":"code","0a1c4d54":"code","4a8bd684":"code","314d98e3":"code","38ce841c":"code","f9a0bd4d":"code","fa8afa59":"code","c2b63f9b":"code","2e6a333a":"code","b0e567df":"code","0a0817c5":"code","22f7987b":"code","c496555f":"code","b9d63b42":"code","755d0e31":"code","3f8c645a":"code","30273fd0":"code","8b61f8f2":"code","729f007a":"code","f9acfb86":"markdown","f0372552":"markdown","54058f8d":"markdown","aad0c999":"markdown","d65afcc9":"markdown","61723754":"markdown","9757dd9b":"markdown","cfa0b972":"markdown","2531b4e0":"markdown","f4135157":"markdown"},"source":{"aa4f7631":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e24c0e3a":"import plotly.express as px","0fae2945":"pd.set_option(\"max.columns\", 1000)\ndata = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\")\n","c8e7796e":"data.head()","1968f100":"import re\nnumber_pattern = \"\\d+_\"\ndata = data.drop(data.index[0], axis = 0)\ndef clean_df(df):\n    for col in df.columns:\n        if \"_Part_\" in col:\n            try:\n                # Check for the unique value of this.\n                col_number = re.findall(number_pattern, col)[0].replace(\"_\", \"\")                \n                unique_colval = df[col].dropna().unique()                \n                col_value = unique_colval[0]                \n                real_col_name = \"Q\" + str(col_number) + \"_\" + str(col_value)                \n                df[col] = df[col].notna()    \n                df.rename(columns = {col:real_col_name}, inplace = True)\n            except:\n                print(\"couldn't rename\", col)            \n        else:\n            pass    \n    return df\n\ndef clean_colnames(df):\n    df.columns = map(str.lower, df.columns)\n    df.columns = df.columns.str.replace(' ', '_')\n    df.columns = df.columns.str.replace('(', '')\n    df.columns = df.columns.str.replace(')', '_')\n    df.columns = df.columns.str.replace('+', 'plus')\n    df.columns = df.columns.str.replace('\/', 'or')\n    df.columns = df.columns.str.replace('.', '_')\n    df.columns = df.columns.str.replace('__', '_')\n    df.columns = df.columns.str.replace('___', '_')    \n    return df\n\n\ndef fix_others(df):    \n    for col in df.columns:\n        if \"other\" in col:\n            try:\n                df[col] = df[col].notna()\n            except:\n                print(\"did not convert\")\n    return(df)\n\ndf = clean_df(data)\ndf = clean_colnames(df)\ndf = fix_others(df)","d3e0cf0e":"# few modifications\ndf = df.replace('United Kingdom of Great Britain and Northern Ireland','United Kingdom')\ndf = df.replace('Some college\/university study without earning a bachelor\u2019s degree','without bachelors')","f3eaca62":"age_group = df.groupby(['q1'])['q1'].count().reset_index(name = 'counts')\nage_group = age_group.rename(columns = {'q1':'age_group'})\nfig = px.bar(age_group, x='age_group', y='counts', color='age_group',\n             title='Age Groups Distribution', height=550, width = 800)\nfig.show()","668431a1":"time = df.groupby(\"time_from_start_to_finish_seconds_\")['time_from_start_to_finish_seconds_'].count().reset_index(name = 'counts')\ntime = time.sort_values(by = 'counts', ascending = False)\nfig = px.line(time, x=\"counts\", y=\"time_from_start_to_finish_seconds_\", title='Time taken to fill')\nfig.show()","875a9fb0":"gender = df.groupby(['q2'])['q2'].count().reset_index(name = 'counts')\ngender = gender.rename(columns = {'q2':'gender'})\nfig = px.bar(gender, x='gender', y='counts', color='gender',\n             title='Gender Distribution', height=550, width = 900)\nfig.show()","9ad3efc4":"country = df.groupby(['q3'])['q3'].count().reset_index(name = 'counts')\ncountry = country.rename(columns = {'q3':'country'})\ntop_10 = country.nlargest(10, 'counts')\nfig = px.bar(top_10, x='country', y='counts', color='country',\n             title='Top 10 Countries', height=550, width = 900)\nfig.show()","b07877c7":"lest_10 = country.nsmallest(10, 'counts')\nfig = px.bar(lest_10, x='country', y='counts', color='country',\n             title='Least 10 Countries', height=550)\nfig.show()","57d7cb89":"qual = df.groupby(['q4'])['q4'].count().reset_index(name = 'counts')\nqual = qual.rename(columns = {'q4':'qualfication'})\nfig = px.bar(qual, x='qualfication', y='counts', color='qualfication',\n             title='Qualification distribution', height=550, width = 900)\nfig.show()","f173e8b8":"job = df.groupby(['q5'])['q5'].count().reset_index(name = 'counts')\njob = job.rename(columns = {'q5':'job'})\nfig = px.bar(job, x='job', y='counts', color='job',\n             title='Job level distribution', height=550, width = 900)\nfig.show()","1f515ce9":"code_yrs = df.groupby(['q6'])['q6'].count().reset_index(name = 'counts')\ncode_yrs = code_yrs.rename(columns = {'q6':'code_yrs'})\nfig = px.bar(code_yrs, x='code_yrs', y='counts', color='code_yrs',\n             title='Years of coding experience distribution', height=550, width = 900)\nfig.show()","a92bd537":"prg_python = df.groupby(['q7_python'])['q7_python'].count().reset_index(name = 'counts')\nprg_python = prg_python.rename(columns = {'q7_python':'prg_python'})\nfig = px.pie(prg_python, values='counts', names='prg_python', title='prg_python distribution', height=550, width = 900)\nfig.show()","915b0d8f":"prg_R = df.groupby(['q7_r'])['q7_r'].count().reset_index(name = 'counts')\nprg_R = prg_R.rename(columns = {'q7_r':'prg_R'})\nfig = px.pie(prg_R, values='counts', names='prg_R', title='prg_R distribution', height=550, width = 900)\nfig.show()","051f9dc9":"prg_sql = df.groupby(['q7_sql'])['q7_sql'].count().reset_index(name = 'counts')\nprg_sql = prg_sql.rename(columns = {'q7_sql':'prg_sql'})\nfig = px.pie(prg_sql, values='counts', names='prg_sql', title='prg_sql distribution', height=550, width = 900)\nfig.show()","b528542c":"langu = df.groupby(['q8'])['q8'].count().reset_index(name = 'counts')\nlangu = langu.rename(columns = {'q8':'languages'})\nfig = px.bar(langu, x='languages', y='counts', color='languages',\n             title='Programming languages distribution', height=550, width = 900)\nfig.show()","3952d37a":"plat = df.groupby(['q11'])['q11'].count().reset_index(name = 'counts')\nplat = plat.rename(columns = {'q11':'platform'})\nplat = plat.replace('A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)','Cloud computing platform')\nplat = plat.replace('A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)','Deep learning workstation')\nfig = px.bar(plat, x='platform', y='counts', color='platform',\n             title='Platform distribution', height=550, width = 900)\nfig.show()","04b6ea14":"prg_sql = df.groupby(['q12_gpus'])['q12_gpus'].count().reset_index(name = 'counts')\nprg_sql = prg_sql.rename(columns = {'q12_gpus':'GPU'})\nfig = px.pie(prg_sql, values='counts', names='GPU', title='GPU distribution', height=550, width = 900)\nfig.show()","be32ec8d":"prg_sql = df.groupby(['q12_tpus'])['q12_tpus'].count().reset_index(name = 'counts')\nprg_sql = prg_sql.rename(columns = {'q12_tpus':'TPU'})\nfig = px.pie(prg_sql, values='counts', names='TPU', title='TPU distribution', height=550, width = 900)\nfig.show()","0a1c4d54":"matplotlib = df.groupby(['q14_matplotlib_'])['q14_matplotlib_'].count().reset_index(name = 'counts')\nmatplotlib = matplotlib.rename(columns = {'q14_matplotlib_':'matplotlib'})\nfig = px.pie(matplotlib, values='counts', names='matplotlib', title='matplotlib distribution', height=550, width = 900)\nfig.show()","4a8bd684":"seaborn = df.groupby(['q14_seaborn_'])['q14_seaborn_'].count().reset_index(name = 'counts')\nseaborn = seaborn.rename(columns = {'q14_seaborn_':'seaborn'})\nfig = px.pie(seaborn, values='counts', names='seaborn', title='seaborn distribution', height=550, width = 900)\nfig.show()","314d98e3":"plotly = df.groupby(['q14_plotly_or_plotly_express_'])['q14_plotly_or_plotly_express_'].count().reset_index(name = 'counts')\nplotly = plotly.rename(columns = {'q14_plotly_or_plotly_express_':'plotly'})\nfig = px.pie(plotly, values='counts', names='plotly', title='plotly distribution', height=550, width = 900)\nfig.show()","38ce841c":"ml = df.groupby(['q15'])['q15'].count().reset_index(name = 'counts')\nml = ml.rename(columns = {'q15':'ml'})\nml = ml.sort_values(by = 'counts', ascending = False)\nfig = px.bar(ml, x='ml', y='counts', color='ml',\n             title='ML algorithm usage distribution', height=550, width = 900)\nfig.show()","f9a0bd4d":"sklearn = df.groupby(['q16__scikit-learn_'])['q16__scikit-learn_'].count().reset_index(name = 'counts')\nsklearn = sklearn.rename(columns = {'q16__scikit-learn_':'Scikit-Learn'})\nfig = px.pie(sklearn, values='counts', names='Scikit-Learn', title='Scikit-Learn distribution', height=550, width = 900)\nfig.show()","fa8afa59":"tensorflow = df.groupby(['q16__tensorflow_'])['q16__tensorflow_'].count().reset_index(name = 'counts')\ntensorflow = tensorflow.rename(columns = {'q16__tensorflow_':'tensorflow'})\nfig = px.pie(tensorflow, values='counts', names='tensorflow', title='Tensorflow distribution', height=550, width = 900)\nfig.show()","c2b63f9b":"keras = df.groupby(['q16_keras_'])['q16_keras_'].count().reset_index(name = 'counts')\nkeras = keras.rename(columns = {'q16_keras_':'keras'})\nfig = px.pie(keras, values='counts', names='keras', title='Keras distribution', height=550, width = 900)\nfig.show()","2e6a333a":"\nlin = df.groupby(['q17_linear_or_logistic_regression'])['q17_linear_or_logistic_regression'].count().reset_index(name = 'counts')\nlin = lin.rename(columns = {'q17_linear_or_logistic_regression':'lin-log'})\nfig = px.pie(lin, values='counts', names='lin-log', title='Linear-Logistic distribution', height=550, width = 900)\nfig.show()","b0e567df":"trees = df.groupby(['q17_decision_trees_or_random_forests'])['q17_decision_trees_or_random_forests'].count().reset_index(name = 'counts')\ntrees = trees.rename(columns = {'q17_decision_trees_or_random_forests':'trees'})\nfig = px.pie(trees, values='counts', names='trees', title='Tree Ensembles distribution', height=550, width = 900)\nfig.show()","0a0817c5":"gbm = df.groupby(['q17_gradient_boosting_machines_xgboost,_lightgbm,_etc_'])['q17_gradient_boosting_machines_xgboost,_lightgbm,_etc_'].count().reset_index(name = 'counts')\ngbm = gbm.rename(columns = {'q17_gradient_boosting_machines_xgboost,_lightgbm,_etc_':'gbm'})\nfig = px.pie(gbm, values='counts', names='gbm', title='Boosting distribution', height=550, width = 900)\nfig.show()","22f7987b":"plat = df.groupby(['q20'])['q20'].count().reset_index(name = 'counts')\nplat = plat.rename(columns = {'q20':'emp'})\nfig = px.bar(plat, x='emp', y='counts', color='emp',\n             title='Employees distribution', height=550, width = 900)\nfig.show()","c496555f":"exp","b9d63b42":"exp = df.groupby(['q21'])['q21'].count().reset_index(name = 'counts')\nexp = exp.rename(columns = {'q21':'emp'})\nfig = px.pie(exp, values='counts', names='emp', title='Experience distribution', height=550, width = 900)\nfig.show()","755d0e31":"exp = df.groupby(['q22'])['q22'].count().reset_index(name = 'counts')\nexp = exp.rename(columns = {'q22':'emp'})\nfig = px.pie(exp, values='counts', names='emp', title='Experience distribution', height=550, width = 900)\nfig.show()","3f8c645a":"db = df.groupby(['q30'])['q30'].count().reset_index(name = 'counts')\ndb = db.rename(columns = {'q30':'db'})\nfig = px.pie(db, values='counts', names='db', title='DataBase distribution', height=550, width = 900)\nfig.show()","30273fd0":"db = df.groupby(['q32'])['q32'].count().reset_index(name = 'counts')\ndb = db.rename(columns = {'q32':'viz'})\nfig = px.pie(db, values='counts', names='viz', title='Visualization distribution', height=550, width = 900)\nfig.show()","8b61f8f2":"\nCoursera = df.groupby(['q37_coursera'])['q37_coursera'].count().reset_index(name = 'counts')\nCoursera = Coursera.rename(columns = {'q37_coursera':'Coursera'})\nfig = px.pie(Coursera, values='counts', names='Coursera', title='Coursera distribution', height=550, width = 900)\nfig.show()","729f007a":"df.head()","f9acfb86":"## Data Cleaning Module\n\nThe column names of this table is too ambiguous. So we cannot use it directly to do analysis.\n\nSo I have used this notebook to get the column names cleaned\n\nThanks to https:\/\/www.kaggle.com\/tpmeli\/kaggle-questionere-csv-cleaning","f0372552":"Compared to TPU, GPU is used by much more Kagglers","54058f8d":"This is showing Machine learning is an evolving field. higher number of people just started to learn.","aad0c999":"Woooow!!!!!.. India(my country) is on **TOP**\n\nIs this reflect the population :P","d65afcc9":"compared to R and Python, SQL is used much by data scientists","61723754":"Most of the Regression problems either linear or classification problems solved by Linear and Logistic Regression algorithms.\n\nEnsembled trees and more boosting and Neural networks are in progress to reach more.","9757dd9b":"hoooh hoo..... At least all the men in Kaggle are doing some great work.","cfa0b972":"Scikit-Learn is Machine Learning Algorithm and Tensorflow and Keras are Deep Learning Algorithms. Machine learning is spread much more than Deep Learning. \n\none more intrepretation: We have more problem to solve with Scikit learn or ML. we are still finding for problems to utilize Tensorflow, Keras or DL","2531b4e0":"Based on the above three pie plots, Matplotlib is still king the Python visualizations.","f4135157":"## Libraries"}}