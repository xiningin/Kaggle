{"cell_type":{"99c9f94b":"code","3fa31bf6":"code","0c7e01f4":"code","1b733268":"code","727561a3":"code","497f4e08":"code","892f94ac":"code","1a06b1ab":"code","f6487b8f":"code","b0b5f176":"code","a7ca6127":"code","9ab53ce5":"code","cb4dbf68":"code","d00ce78b":"code","0f95549a":"code","844702c7":"code","6a805d1c":"code","200f5846":"code","5f788cba":"code","f44f00ed":"code","0e823f51":"code","7ed7c5e0":"code","9214132c":"code","c1764375":"markdown","fa7b46df":"markdown","f8036f23":"markdown","d86b3006":"markdown","9066a535":"markdown"},"source":{"99c9f94b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fa31bf6":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom nltk import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import plot_confusion_matrix\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport regex as re\nfrom sklearn.svm import SVC\nfrom wordcloud import WordCloud, ImageColorGenerator","0c7e01f4":"# Read data\n\n# Read csv\n# Use cp1252 as the dataset is not suitable to be read with utf8 encoding\ntrain = pd.read_csv(\"..\/input\/email-classification-nlp\/SMS_train.csv\", encoding='cp1252')\ntest = pd.read_csv(\"..\/input\/email-classification-nlp\/SMS_test.csv\",encoding='cp1252')\n\ntrain.head()","1b733268":"train.info()","727561a3":"def tokenize(x):\n    tokenizer = RegexpTokenizer(r'\\w+')\n    return tokenizer.tokenize(x)\n                                \ndef stemmer(x):\n    stemmer = PorterStemmer()\n    return ' '.join([stemmer.stem(word) for word in x])\n \ndef lemmatize(x):\n    lemmatizer = WordNetLemmatizer()\n    return ' '.join([lemmatizer.lemmatize(word) for word in x])\n\nstop_words = stopwords.words('english')\n\n#  Preprocess train dataset\n# remove special characters from text column\ntrain.Message_body = train.Message_body.str.replace('[#,@,&]', '')\n# Remove digits\ntrain.Message_body = train.Message_body.str.replace(' \\d+ ','')\n#Remove www\ntrain.Message_body = train.Message_body.str.replace('w{3}','')\n# remove urls\ntrain.Message_body = train.Message_body.str.replace(\"http\\S+\", \"\")\n# remove multiple spaces with single space\ntrain.Message_body = train.Message_body.str.replace('\\s+', ' ')\n#remove all single characters\ntrain.Message_body = train.Message_body.str.replace(r'\\s+[a-zA-Z]\\s+', '')\ntrain['tokens'] = train['Message_body'].map(tokenize)\ntrain['lemma'] = train['tokens'].map(lemmatize)\ntrain['stems'] = train['tokens'].map(stemmer)\n\n#  Preprocess test dataset\n# remove special characters from text column\ntest.Message_body = test.Message_body.str.replace('[#,@,&]', '')\n#Remove digits\ntest.Message_body = test.Message_body.str.replace(' \\d+ ','')\n#Remove www\ntest.Message_body = test.Message_body.str.replace('w{3}','')\n# remove urls\ntest.Message_body = test.Message_body.str.replace(\"http\\S+\", \"\")\n# remove multiple spaces with single space\ntest.Message_body = test.Message_body.str.replace('\\s+', ' ')\n#remove all single characters\ntest.Message_body = test.Message_body.str.replace(r'\\s+[a-zA-Z]\\s+', '')\ntest['tokens'] = test['Message_body'].map(tokenize)\ntest['lemma'] = test['tokens'].map(lemmatize)\ntest['stems'] = test['tokens'].map(stemmer)","497f4e08":"train","892f94ac":"# WordCloud for spam marked emails in train set\n\n# Get a string of e-mails\nmessage_body_spam = \",\".join(spam_mail.lower() for spam_mail in train.Message_body[train.Label == 'Spam'])\n\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_font_size=50, \n                      max_words=70, \n                      stopwords=stop_words,\n                      scale=5,\n                      background_color=\"white\").generate(message_body_spam)\n\n# Display the generated image:\nplt.figure(figsize=(10,7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Most repeated words in spam mails',fontsize=15)\nplt.show()","1a06b1ab":"# WordCloud for Non-spam marked emails in train set\n\n# Get a string of e-mails\nmessage_body_spam = \",\".join(spam_mail.lower() for spam_mail in train.Message_body[train.Label == 'Non-Spam'])\n\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_font_size=50, \n                      max_words=70, \n                      stopwords=stop_words,\n                      scale=5,\n                      background_color=\"white\").generate(message_body_spam)\n\n# Display the generated image:\nplt.figure(figsize=(10,7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Most repeated words in not spam mails',fontsize=15)\nplt.show()","f6487b8f":"data_labels = train['Label']\ndata_tweets = train['lemma']\n\ntrain_X, test_X, train_y, test_y = train_test_split(data_tweets, \n                                                    data_labels, \n                                                    test_size=0.25, \n                                                    random_state = 42)\n\nval_y = test['Label']\nval_X = test['lemma']","b0b5f176":"pipe_mnnb = Pipeline(steps = [('tf', TfidfVectorizer()), ('mnnb', MultinomialNB())])\n\n# Create Parameter Grid\npgrid_mnnb = {\n 'tf__max_features' : [1000, 2000, 3000],\n 'tf__stop_words' : ['english', None],\n 'tf__ngram_range' : [(1,1),(1,2)],\n 'tf__use_idf' : [True, False],\n 'mnnb__alpha' : [0.1, 0.5, 1]\n}\n\n# Apply GridSearch to Pipeline to find the best parameters\ngs_mnnb = GridSearchCV(pipe_mnnb, pgrid_mnnb, cv=5, n_jobs=-1, verbose=2)\n\n# Fit the model\ngs_mnnb.fit(train_X, train_y)","a7ca6127":"# Check the best parameters for our model\ngs_mnnb.best_params_","9ab53ce5":"print('Score of train set', gs_mnnb.score(train_X, train_y))\nprint('Score of test set',gs_mnnb.score(test_X, test_y))","cb4dbf68":"## Naive Bayes Predictions on val set and confusion matrix\npreds_mnnb = gs_mnnb.predict(val_X)\ntest['preds'] = preds_mnnb\n\n# Generate confusion matrix\nmatrix_nb = plot_confusion_matrix(gs_mnnb, test_X, test_y,\n                                 cmap=plt.cm.Blues,\n                                 normalize='true')\n\nplt.title('Confusion matrix for NB classifier')\nplt.show(matrix_nb)\nplt.show()","d00ce78b":"pipe_lgrg = Pipeline(steps = [('tf', TfidfVectorizer()), ('lgrg', LogisticRegression())])\n\n# Create Parameter Grid\npgrid_lgrg = {\n 'tf__max_features' : [1000, 2000, 3000],\n 'tf__ngram_range' : [(1,1),(1,2)],\n 'tf__use_idf' : [True, False],\n 'lgrg__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n 'lgrg__class_weight' : ['balanced', None],\n 'lgrg__C' : [1.0, 0.9]\n}\n\n# Apply GridSearch to Pipeline to find the best parameters\ngs_lgrg = GridSearchCV(pipe_lgrg, pgrid_lgrg, cv=5, n_jobs=-1, verbose=2)\n\n# Fit the model\ngs_lgrg.fit(train_X, train_y)","0f95549a":"gs_lgrg.best_params_","844702c7":"print('Score of train set', gs_lgrg.score(train_X, train_y))\nprint('Score of test set',gs_lgrg.score(test_X, test_y))","6a805d1c":"## LR Predictions on val set and confusion matrix\npreds_lgrg = gs_lgrg.predict(val_X)\ntest['preds'] = preds_lgrg\n\n#conf_lgrg = confusion_matrix(val_y, preds_lgrg)\n#conf_lgrg\n\n# Generate confusion matrix\nmatrix_lr = plot_confusion_matrix(gs_lgrg, test_X, test_y,\n                                 cmap=plt.cm.Blues,\n                                 normalize='true')\n\nplt.title('Confusion matrix for LR classifier')\nplt.show(matrix_lr)\nplt.show()","200f5846":"pipe_svc = Pipeline(steps = [('tf', TfidfVectorizer()), ('svc', SVC())])\n\n# Create Parameter Grid\npgrid_svc = {\n 'tf__max_features' : [1000, 2000, 3000],\n 'tf__ngram_range' : [(1,1),(1,2)],\n 'tf__use_idf' : [True, False],\n 'svc__kernel' : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n 'svc__decision_function_shape' : ['ovo', 'ovr'],\n 'svc__C' : [1.0, 0.9, 0.8, 0.7]\n}\n\n# Apply GridSearch to Pipeline to find the best parameters\ngs_svc = GridSearchCV(pipe_svc, pgrid_svc, cv=5, n_jobs=-1, verbose=2)\n\n# Fit the model\ngs_svc.fit(train_X, train_y)","5f788cba":"gs_svc.best_params_","f44f00ed":"print('Score of train set', gs_svc.score(train_X, train_y))\nprint('Score of test set',gs_svc.score(test_X, test_y))","0e823f51":"## LR Predictions on val set and confusion matrix\npreds_svc = gs_svc.predict(val_X)\ntest['preds'] = preds_svc\n\n# Generate confusion matrix\nmatrix_svc = plot_confusion_matrix(gs_svc, test_X, test_y,\n                                 cmap=plt.cm.Blues,\n                                 normalize='true')\n\nplt.title('Confusion matrix for SVC classifier')\nplt.show(matrix_svc)\nplt.show()","7ed7c5e0":"# List with our trained models\nmodels = []\n\nmodels.append(gs_mnnb)\nmodels.append(gs_lgrg)\nmodels.append(gs_svc)\n\n# Build a list of (score, model) tuples\nscores = [(model.score(test_X, test_y), model) for model in models]\n\n# sort it on score\nscores = sorted(scores, key=lambda x: x[0], reverse=True)\n\nprint('Results for the three models: ')\nfor item in scores:\n    print('The model {} has reached {} accuracy on test set'.format(item[1].estimator[1], round(item[0], 2)))\n","9214132c":"# get the model with the best score, which is the\n# the second element of the first item\nbest_model = scores[0][1]\nprint(best_model)","c1764375":"# Choose the best model based on score","fa7b46df":"# Logistic Regression","f8036f23":"# Naive Bayes Pipeline","d86b3006":"# Data preprocessing","9066a535":"# SVC"}}