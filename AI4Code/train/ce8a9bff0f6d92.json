{"cell_type":{"72902770":"code","3514c508":"code","9f7d8b16":"code","5ad2fb1f":"code","1d18ad69":"code","53127369":"code","8b7b371d":"code","ba2b21c0":"code","6254579e":"code","ee5fb053":"code","23c84054":"code","e66156e5":"code","38316127":"code","8bc425ee":"code","add02d02":"code","7eea4049":"code","ecc5d065":"code","931230c9":"code","2f4f98a3":"code","5f90dd6a":"code","c32df692":"code","8954ee7f":"code","86b2752b":"code","6811ba94":"code","709e5570":"code","527be371":"code","4c82a23f":"code","9350745b":"code","a0492299":"code","29952457":"code","e09349b8":"code","cc369fb8":"code","87d74046":"markdown","85359717":"markdown"},"source":{"72902770":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","3514c508":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\n","9f7d8b16":"train_df.shape","5ad2fb1f":"train_df.info()","1d18ad69":"train_df.target.value_counts()\/train_df.target.value_counts().sum()","53127369":"train_df['Number_of_words'] = train_df.question_text.apply(lambda x: len(str(x).split()))","8b7b371d":"train_df['Char_count'] = train_df['question_text'].str.len()","ba2b21c0":"train_df.head()","6254579e":"def avg_word(sentence):\n    words = sentence.split()\n    return (sum(len(word) for word in words)\/len(words))\n","ee5fb053":" train_df['avg_word'] = train_df['question_text'].apply(lambda x:avg_word(x))","23c84054":"from nltk.corpus import stopwords\nstop = stopwords.words('english')","e66156e5":" train_df['stopwords'] = train_df['question_text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n","38316127":"train_df.head()","8bc425ee":"train_df['question_text'] = train_df['question_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ntest_df['question_text'] = test_df['question_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))","add02d02":" train_df.head()","7eea4049":"train_df['question_text'] = train_df['question_text'].str.replace('[^\\w\\s]','')\ntest_df['question_text'] = test_df['question_text'].str.replace('[^\\w\\s]','')","ecc5d065":"train_df['question_text'] = train_df['question_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\ntest_df['question_text'] = test_df['question_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n\ntrain_df.head()","931230c9":"freq_train = pd.Series(' '.join(train_df['question_text']).split()).value_counts()[:30]\ntrain_df['question_text'] = train_df['question_text'].apply(lambda x: ' '.join([i for i in x.split() if i not in freq_train]))\nfreq_train = pd.Series(' '.join(train_df['question_text']).split()).value_counts()[-30:]\ntrain_df['question_text'] = train_df['question_text'].apply(lambda x: ' '.join([i for i in x.split() if i not in freq_train]))\nfreq_test = pd.Series(' '.join(test_df['question_text']).split()).value_counts()[:30]\ntest_df['question_text'] = test_df['question_text'].apply(lambda x: ' '.join([i for i in x.split() if i not in freq_test]))\nfreq_test = pd.Series(' '.join(test_df['question_text']).split()).value_counts()[-30:]\ntest_df['question_text'] = test_df['question_text'].apply(lambda x: ' '.join([i for i in x.split() if i not in freq_test]))\n","2f4f98a3":"train_df['Number_of_words'] = train_df.question_text.apply(lambda x: len(str(x).split()))\ntrain_df['Char_count'] = train_df.question_text.str.len()\ntest_df['Number_of_words'] = test_df.question_text.apply(lambda x: len(str(x).split()))\ntest_df['Char_count'] = test_df.question_text.str.len()\ntrain_df.drop(['avg_word','stopwords'],axis=1,inplace=True)\ntrain_df[train_df['target']==1].head(20)","5f90dd6a":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.model_selection import train_test_split    ","c32df692":"y = train_df['target']\nX = train_df['question_text']\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1,test_size=0.3)","8954ee7f":"train_df['question_text'].apply(lambda x: len(x.split(' '))).sum()\ntest_df['question_text'].apply(lambda x: len(x.split(' '))).sum()\n","86b2752b":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n\nnb = Pipeline([('vect', CountVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', MultinomialNB()),\n              ])\nnb.fit(X_train, y_train)\nfrom sklearn.metrics import classification_report,accuracy_score\ny_pred = nb.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","6811ba94":"from sklearn.linear_model import SGDClassifier\n\nsgd = Pipeline([('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n               ])\nsgd.fit(X_train, y_train)\ny_pred = sgd.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","709e5570":"from sklearn.linear_model import LogisticRegression\n\nlogreg = Pipeline([('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', LogisticRegression(C=1e3)),\n               ])\nlogreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","527be371":"# from tqdm import tqdm\n# tqdm.pandas(desc=\"progress-bar\")\n# from gensim.models import Doc2Vec\n# from sklearn import utils\n# import gensim\n# from gensim.models.doc2vec import TaggedDocument\n# import re\n\n# def label_sentences(corpus, label_type):\n#     \"\"\"\n#     Gensim's Doc2Vec implementation requires each document\/paragraph to have a label associated with it.\n#     We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n#     a dummy index of the post.\n#     \"\"\"\n#     labeled = []\n#     for i, v in enumerate(corpus):\n#         label = label_type + '_' + str(i)\n#         labeled.append(TaggedDocument(v.split(), [label]))\n#     return labeled\n# X_train, X_test, y_train, y_test = train_test_split(train_df['question_text'], train_df['target'], random_state=0, test_size=0.3)\n# X_train = label_sentences(X_train, 'Train')\n# X_test = label_sentences(X_test, 'Test')\n# all_data = X_train + X_test","4c82a23f":"# model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n# model_dbow.build_vocab([x for x in tqdm(all_data)])\n\n# for epoch in range(30):\n#     model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n#     model_dbow.alpha -= 0.002\n#     model_dbow.min_alpha = model_dbow.alpha","9350745b":"# import  numpy as np\n# def get_vectors(model, corpus_size, vectors_size, vectors_type):\n#     \"\"\"\n#     Get vectors from trained doc2vec model\n#     :param doc2vec_model: Trained Doc2Vec model\n#     :param corpus_size: Size of the data\n#     :param vectors_size: Size of the embedding vectors\n#     :param vectors_type: Training or Testing vectors\n#     :return: list of vectors\n#     \"\"\"\n#     vectors = np.zeros((corpus_size, vectors_size))\n#     for i in range(0, corpus_size):\n#         prefix = vectors_type + '_' + str(i)\n#         vectors[i] = model.docvecs[prefix]\n#     return vectors\n    \n# train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n# test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')","a0492299":"# logreg = LogisticRegression(n_jobs=1, C=1e5)\n# logreg.fit(train_vectors_dbow, y_train)\n# logreg = logreg.fit(train_vectors_dbow, y_train)\n# y_pred = logreg.predict(test_vectors_dbow)\n","29952457":"# print('accuracy %s' % accuracy_score(y_pred, y_test))\n# print(classification_report(y_test, y_pred))\n","e09349b8":"y_pred1 = logreg.predict(test_df['question_text'])\ny_pred1.shape","cc369fb8":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['prediction']=y_pred1\nsub.to_csv('submission.csv',index=False)","87d74046":"**Linear SVM**","85359717":"<b> Basic Preprocessing <\/b>"}}