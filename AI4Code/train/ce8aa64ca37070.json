{"cell_type":{"7a52cfdc":"code","7804406a":"code","aa7fbd51":"code","f6c290af":"code","5fe46f8e":"code","97c854a2":"code","a166ece1":"code","f26f8e40":"code","3c17b9c8":"code","a5212b1f":"code","ee52cd92":"code","06d68660":"code","b1bdcd9f":"code","6692716f":"code","5bac7915":"code","50d49dd7":"code","99582083":"code","f1d8b82e":"code","393c89b0":"code","95c72536":"code","b6aee69d":"markdown","cdd229ec":"markdown","039bd6cb":"markdown","f7daecdd":"markdown"},"source":{"7a52cfdc":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split","7804406a":"df = pd.read_excel('..\/input\/mod-data\/dataset.xlsx', sheet_name='All')\ndf.head()","aa7fbd51":"df.groupby(\"SARS-Cov-2 exam result\").count()","f6c290af":"df['SARS-Cov-2 exam result'].value_counts().plot(kind='pie', autopct='%.2f%%')","5fe46f8e":"# Will delete columns including object(text) value\ndf.dtypes","97c854a2":"#Define the 'Y' array including target labels : positive = 1 , negative = 0\n\nY = df['SARS-Cov-2 exam result']\nY = np.array([1 if status==\"positive\" else 0 for status in Y])\n","a166ece1":"#  One-hot encoding :  *specific columns* \n#  *specific columns*\n#      = columns that consist of text values (such as 'detected', 'not detected')\n#      = columns that indicate the disease-infection except COVID-19\n# detected = [1,0,0], not_detected = [0,0,1], missing value = [0,1,0]\n\n\nA = df['Respiratory Syncytial Virus']\nA = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in A])\n\n\nB = df['Influenza A']\nB = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in B])\n\nC = df['Influenza B']\nC = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in C])\n\nD = df['CoronavirusNL63']\nD = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in D])\n\n\nE = df['Rhinovirus\/Enterovirus']\nE = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in E])\n\nF = df['Coronavirus HKU1']\nF = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in F])\n\n\nG = df['Parainfluenza 3']\nG = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in G])\n\n\nH = df['Adenovirus']\nH = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in H])\n\n\nI = df['Parainfluenza 4']\nI = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in I])\n\n\nJ = df['Coronavirus229E']\nJ = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in J])\n\n\nK = df['CoronavirusOC43']\nK = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in K])\n\n\nL = df['Inf A H1N1 2009']\nL = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in L])\n\n\nM = df['Metapneumovirus'] \nM = np.array([(1,0,0) if status==\"detected\" else (0,0,1) if status == \"not_detected\" else (0,1,0) for status in M])\n\n\nN = df['Influenza B, rapid test']\nN = np.array([(1,0,0) if status==\"positive\" else (0,0,1) if status == \"negative\" else (0,1,0) for status in N])\n\nO = df['Influenza A, rapid test']\nO = np.array([(1,0,0) if status==\"positive\" else (0,0,1) if status == \"negative\" else (0,1,0) for status in O])\n\n\nP = df['Strepto A']\nP = np.array([(1,0,0) if status==\"positive\" else (0,0,1) if status == \"negative\" else (0,1,0) for status in P])\n\n","f26f8e40":"# One-hot encoding causes feature-increase (curse of dimensionality)\n\nA = np.reshape(A, (1065,3))\nB = np.reshape(B, (1065,3))\nC = np.reshape(C, (1065,3))\nD = np.reshape(D, (1065,3))\nE = np.reshape(E, (1065,3))\nF = np.reshape(F, (1065,3))\nG = np.reshape(G, (1065,3))\nH = np.reshape(H, (1065,3))\nI = np.reshape(I, (1065,3))\nJ = np.reshape(J, (1065,3))\nK = np.reshape(K, (1065,3))\nL = np.reshape(L, (1065,3))\nM = np.reshape(M, (1065,3))\nN = np.reshape(N, (1065,3))\nO = np.reshape(O, (1065,3))\nP = np.reshape(P, (1065,3))\n\n\n# this numerated dataset will be combined with the training dataset (dataframe excluding object columns)\n\na = np.concatenate((A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P), axis = 1)\nprint(a.shape)\nprint(a)\n","3c17b9c8":"# Remove useless column\n# Remove Y dataset (target label\/ target variable)\n\ndf = df.drop(columns=['Patient ID'])\ndf = df.drop(columns=['SARS-Cov-2 exam result'])","a5212b1f":"# Remove the columns & rows lack of enough data value\n\ndf = df.dropna(axis=1, how='all')   #Delete coloum when all of values are null\ndf = df.dropna(axis=0, how='all')   #Delete row when all of values are null\ndf = df.dropna(thresh=2)            #Maintain iff the row has at least 2 non-null value\n\n\n# The number of features decreased (110  --> 104)\ndf.head()","ee52cd92":"# Remove the columes including 'object' (text values such as detected, not detected)\n# will combine the 'df' with One-hot encoded dataset: the entire dataset consists of numeric data \n\ndf = df.select_dtypes(exclude=['object'])\nprint(df.shape)\ndf.dtypes\n","06d68660":"# Replace the missing values with mean value (=0)\n\nX = df\nX = np.nan_to_num(X.to_numpy())\n\n#X = df.to_numpy()\nprint(X.shape)\n\nX = np.reshape(X, (1065,69))\n\nprint(X)\n","b1bdcd9f":"# Combine the one-hot encoded 'a' array with 'X' array \n\nX = np.concatenate((a, X), axis=1)\nprint(X.shape)\nX.dtype","6692716f":"X\nX.shape","5bac7915":"#Split the dataframe into Training data and Test data \n#6:4 ratio results in the optimal performance \n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=45)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(X_train)\n","50d49dd7":"# Reshape the patient data into rows\nprint(X_train.shape)\nX_train = np.reshape(X_train, (X_train.shape[0], -1))\nprint(X_train.shape)\nX_test = np.reshape(X_test, (X_test.shape[0], -1))\nprint(X_train.shape, X_test.shape)\n\nprint(X_train)","99582083":"# Split training data into 3 groups of data \n# Each group of data has to be the validation dataset in order to ingnore outliers (for optimal k value)\n\nnum_folds = 3\nk_choices = [1, 2, 3, 4, 5, 6,  7, 8,  9, 10, 11, 15, 19, 20, 30, 40,  50, 75, 100]\n\nX_train_folds = []\ny_train_folds = []\n\nX_train_folds = np.array_split(X_train, num_folds)\ny_train_folds = np.array_split(y_train, num_folds)\n\nk_to_accuracies = {}\n\nfor k in k_choices:\n    k_to_accuracies[k] = []\n    for i in range(num_folds): #split training data into 3 groups of data \n        # prepare training data for the current fold\n        X_train_fold = np.concatenate([ fold for j, fold in enumerate(X_train_folds) if i != j ]) #merge except X_train_folds[i]\n                                                                                                    #426 x 117\n        y_train_fold = np.concatenate([ fold for j, fold in enumerate(y_train_folds) if i != j ])\n\n        \n        J = X_train_folds[i] #0th fold, 1st fold, 2nd fold\n        num_X_train_folds = J.shape[0]              #validation\/ test (213)\n        num_X_train_fold = X_train_fold.shape[0]    #train            (426)\n       \n\n        # #i'th fold become the validation set\/ calculate the distance values\/ dists = 213 x 426\n        dists = np.reshape(np.sum(X_train_folds[i]**2, axis=1), [num_X_train_folds,1]) + np.sum(X_train_fold**2, axis=1) \\\n            - 2 * np.matmul(X_train_folds[i], X_train_fold.T)\n        dists = np.sqrt(dists)\n\n        \n            \n        #num_val = dists.shape[0]  #213\n        #y_pred = np.zeros(num_val) #213row coloum vector 0,1,0,1,..\n        \n       # U = y_train_fold    #validation_X dataset (213x117)\n       \n        num_val = dists.shape[0]\n        y_pred = []\n        y_pred = np.zeros(num_val)\n        U = y_train_fold          #426\n        for c in range(num_val): #213 \n        \n            \n            closest_y = []\n            closest_y = U[np.argsort(dists[c])][0:k] #returns indices of Y label mapped with the shortest distance value \n\n            \n            y_pred[c] = np.bincount(closest_y).argmax() #what is the most drawn Y label value?\n       \n        \n          \n        num_correct = np.sum(y_pred  == y_train_folds[i]) \n        accuracy = float(num_correct) \/ num_val\n          \n        k_to_accuracies[k].append(accuracy)\n\n                   \n# Print out the computed accuracies\nfor k in sorted(k_to_accuracies):\n    for accuracy in k_to_accuracies[k]:\n\n        print('k = %d, accuracy = %f' % (k, accuracy))              ","f1d8b82e":"q = [0.755869,0.723005,0.774648]\ni = [0.680751,0.652582, 0.661972]\nw = [0.638498,0.615023,0.605634]\nz = [0.619718,0.600939,0.610329]\nr = [0.638498, 0.615023,0.624413]\nt = [0.704225,0.690141,0.657277]\nx = [0.690141,0.643192,0.629108]\ns = [0.56338, 0.549296,0.516432]\n\nq = np.average(q)\ni = np.average(i)\nw = np.average(w)\nz = np.average(z)\nr = np.average(r)\nt = np.average(t)\nx = np.average(x)\ns = np.average(s)\n\n  #print('k = %d, accuracy = %f' % (k, accuracy))\n\nprint(q)\nprint('k = 2', 'accuracy = %f' %(q))\nprint('k = 3', 'accuracy = %f' %(i))\nprint('k = 5', 'accuracy = %f' %(w))\nprint('k = 7', 'accuracy = %f' %(z))\nprint('k = 15', 'accuracy = %f' %(r))\nprint('k = 30', 'accuracy = %f' %(t))\nprint('k = 50', 'accuracy = %f' %(x))\nprint('k = 100', 'accuracy = %f' %(s))\n","393c89b0":"# plot the raw observations\nfor k in k_choices:\n    accuracies = k_to_accuracies[k]\n    plt.scatter([k] * len(accuracies), accuracies)\n\n# plot the trend line with error bars that correspond to standard deviation\naccuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\naccuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\nplt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\nplt.title('Cross-validation on k')\nplt.xlabel('k')\nplt.ylabel('Cross-validation accuracy')\nplt.show()","95c72536":"best_k = k_choices[accuracies_mean.argmax()]\nprint(best_k)\n\n\nnum_X_test = X_test.shape[0]    \nnum_X_train = X_train.shape[0]              \n\n        #i'th fold become the validation set\/ calculate the distance values\ndists = np.reshape(np.sum(X_test**2, axis=1), [num_X_test,1]) + np.sum(X_train**2, axis=1) \\\n            - 2 * np.matmul(X_test, X_train.T)\ndists = np.sqrt(dists)\n\n        \n            \nnum_test = dists.shape[0]\ny_pred = []\ny_pred = np.zeros(num_test)\nU = y_train\nfor c in range(num_test):\n    closest_y = []\n    closest_y = U[np.argsort(dists[c])][0:best_k] \n\n            \n    y_pred[c] = np.bincount(closest_y).argmax()\n    \n       \n       \n  \n          \nnum_correct = np.sum(y_pred  == y_test) \naccuracy = float(num_correct) \/ num_test\n          \nk_to_accuracies[k].append(accuracy)\n\n\nprint('Got %d \/ %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n","b6aee69d":"# Test ","cdd229ec":"# 3-Fold Cross Validation & KNN Algorithm\n","039bd6cb":"# Defining\/Exploring Dataframe","f7daecdd":"# Pre-Processing"}}