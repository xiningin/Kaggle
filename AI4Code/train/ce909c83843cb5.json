{"cell_type":{"acbf11a6":"code","1d030304":"code","8f99fc70":"code","9c238355":"code","53222ce8":"code","47a2464c":"code","28a8b7b5":"code","87d67013":"code","cf227e87":"code","12cb9854":"code","b5897d96":"code","181f1a59":"code","45734b9a":"code","39558ef8":"code","50d983d0":"code","387ae8bf":"code","1a9d7780":"code","46b82056":"code","68f5e181":"code","aee5efa1":"code","e81989f1":"code","db474a90":"code","9d804ace":"code","b02f7fe9":"code","b6db3950":"code","5bedfa00":"code","18758725":"code","e9e3b929":"code","b31b5e54":"code","762197e9":"code","39ccd8f2":"code","e8355c88":"code","e5d83d37":"markdown","f0b29fd9":"markdown","3d2ca7bd":"markdown","e70b4756":"markdown","1447351e":"markdown","227ecf8c":"markdown","5c26b215":"markdown","d2a63f3e":"markdown","57c5e6c5":"markdown","2b5b6c9c":"markdown","68203a6a":"markdown","1da14690":"markdown","932696c4":"markdown","5fefee67":"markdown"},"source":{"acbf11a6":"import re\nimport os\nfrom random import shuffle\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nimport tempfile\nimport matplotlib.pyplot as plt\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","1d030304":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [299, 299]\nIMAGE_RESIZE = [299, 299]\n\nBRIGHTNESS_MAX_DELTA = 0.125\nSATURATION_LOWER = 0.5\nSATURATION_UPPER = 1.5\nHUE_MAX_DELTA = 0.2\nCONTRAST_LOWER = 0.5\nCONTRAST_UPPER = 1.5","8f99fc70":"TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/tf-records\/train\/train*.tfrecord')\nVALID_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/tf-records\/val\/validation*.tfrecord')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/tf-records\/test\/*.tfrecord')\nprint('Train TFRecord Files:', len(TRAINING_FILENAMES))\nprint('Validation TFRecord Files:', len(VALID_FILENAMES))\nprint('Test TFRecord Files:', len(TEST_FILENAMES))","9c238355":"def rescale_min_1_to_1(image):\n    \"\"\"Rescale image to [-1, 1]\n\n    Args:\n        image: Image tensor.\n    \n    Returns:\n        Scaled image.\n    \"\"\"\n    # Image must be casted to float32 first.\n    image = tf.cast(image, tf.float32)\n    # Rescale image from [0, 255] to [0, 2].\n    image = tf.multiply(image, 1. \/ 127.5)\n    # Rescale to [-1, 1].\n    return tf.subtract(image, 1.0)\n\n\ndef rescale_0_to_1(image):\n    \"\"\"Rescale image to [0, 1].\n\n    Args:\n        image: Image tensor.\n    \n    Returns:\n        A scaled image.\n    \"\"\"\n    return tf.image.convert_image_dtype(image, tf.float32)","53222ce8":"def decode_image(image, normalization_fn):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = normalization_fn(image)\n    #image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image","47a2464c":"def read_tfrecord(example, labeled):\n    tfrecord_format = {\"image\/encoded\": tf.io.FixedLenFeature((), tf.string),\n                \"image\/format\": tf.io.FixedLenFeature((), tf.string),\n                \"image\/class\/label\": tf.io.FixedLenFeature((), tf.int64),\n                \"image\/height\": tf.io.FixedLenFeature((), tf.int64),\n                \"image\/width\": tf.io.FixedLenFeature((), tf.int64)\n                      }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image\/encoded'], rescale_min_1_to_1)\n    label = tf.cast(\n                tf.reshape(example[\"image\/class\/label\"], [-1]),\n                tf.float32)\n    return image, label","28a8b7b5":"def load_dataset(filenames, labeled=True, ordered=False):\n    # returns a dataset of (image, label) pairs\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n    return dataset","87d67013":"def augmentation_pipeline(image, label, augmentation=True):\n    \n    image = tf.image.resize(image, IMAGE_RESIZE)\n    \n    # Apply data augmentations randomly.\n    augmentations = [\n        {'fn': tf.image.random_flip_left_right},\n        {'fn': tf.image.random_brightness,\n         'args': [BRIGHTNESS_MAX_DELTA]},\n        {'fn': tf.image.random_saturation,\n         'args': [SATURATION_LOWER, SATURATION_UPPER]},\n        {'fn': tf.image.random_hue,\n        'args': [HUE_MAX_DELTA]},\n        {'fn': tf.image.random_contrast,\n        'args': [CONTRAST_LOWER, CONTRAST_UPPER]}\n    ]\n\n    shuffle(augmentations)\n\n    if augmentation:\n        for aug in augmentations:\n            if 'args' in aug:\n                image = aug['fn'](image, *aug['args'])\n            else:\n                image = aug['fn'](image)\n\n    return image, label","cf227e87":"def get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(augmentation_pipeline, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","12cb9854":"def get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.repeat()\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","b5897d96":"def get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","181f1a59":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","45734b9a":"NUM_TRAINING_IMAGES = 34528 #count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = 8658 #count_data_items(VALID_FILENAMES)\nNUM_TEST_IMAGES = 8986 #count_data_items(TEST_FILENAMES)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\nprint(\n    'Dataset: {} training images, {} validation images, {} unlabeled test images'.format(\n        NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES\n    )\n)","39558ef8":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)","50d983d0":"train_dataset = get_training_dataset()\nvalid_dataset = get_validation_dataset()","387ae8bf":"image_batch, label_batch = next(iter(train_dataset))","1a9d7780":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(20,20))\n    for n in range(25):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"Retinopathy\")\n        else:\n            plt.title(\"Healthy\")\n        plt.axis(\"off\")","46b82056":"show_batch(image_batch.numpy(), label_batch.numpy())","68f5e181":"def make_model(output_bias = None, metrics = None):    \n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n        \n    base_model = tf.keras.applications.Xception(input_shape=(*IMAGE_RESIZE, 3),\n                                                include_top=False,\n                                                weights='imagenet')\n    \n    base_model.trainable = False\n    \n    # Freeze the feature extractor\n    for layer in base_model.layers:\n        layer.trainable=False\n    \n    model = tf.keras.Sequential([\n        base_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(2048, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(1, activation='sigmoid',\n                              bias_initializer=output_bias)\n    ])\n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=metrics)\n    \n    return model","aee5efa1":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES \/\/ BATCH_SIZE","e81989f1":"BATCH_SIZE","db474a90":"STEPS_PER_EPOCH","9d804ace":"malignant = 10238\nbenign = 32948\ntotal_img = malignant+benign\n\ninitial_bias = np.log([malignant\/benign])\ninitial_bias","b02f7fe9":"weight_for_0 = (1 \/ benign)*(total_img)\/2.0 \nweight_for_1 = (1 \/ malignant)*(total_img)\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","b6db3950":"with strategy.scope():\n    model = make_model(output_bias = initial_bias, metrics=tf.keras.metrics.AUC(name='auc'))","5bedfa00":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"dr_model_2.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=100,\n                                                     verbose=1, \n                                                     restore_best_weights=True)","18758725":"history = model.fit(\n    train_dataset, \n    epochs=20,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    validation_steps=VALID_STEPS,\n    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n    class_weight=class_weight\n)","e9e3b929":"import matplotlib.pyplot as plt\nauc = history.history['auc']\nval_auc = history.history['val_auc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(auc))\n\nplt.plot(epochs, auc, 'r', label='Training AUC')\nplt.plot(epochs, val_auc, 'b', label='Validation AUC')\nplt.title('Training and validation AUC')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","b31b5e54":"with strategy.scope():\n    \n    for layer in model.layers:\n        layer.trainable = True\n    \n    model.compile(\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-6,\n                                       decay=4e-5),\n              metrics=['accuracy', tf.keras.metrics.AUC()]\n             )","762197e9":"# Serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"dr_model_2.json\", \"w\") as json_file:\n    json_file.write(model_json)","39ccd8f2":"history = model.fit(\n    train_dataset, \n    epochs=250,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    validation_steps=VALID_STEPS,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n    class_weight=class_weight\n)","e8355c88":"import matplotlib.pyplot as plt\nauc = history.history['auc']\nval_auc = history.history['val_auc']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, auc, 'r', label='Training AUC')\nplt.plot(epochs, val_auc, 'b', label='Validation AUC')\nplt.title('Training and validation AUC')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","e5d83d37":"## 2.2 Data augmentation","f0b29fd9":" ### Unfreeze the extractor layers","3d2ca7bd":"# 3. Building our model","e70b4756":"### 3.4.2 Set class weights\n\nSince there are not enough malignant images, we want these malignant images to have more weight in our model. By increasing the weight of these malignant images, the model will pay more attention to them, and this will help balance out the difference in quantity.","1447351e":"We can use callbacks to stop training when there are no improvements in our validation set predictions, and this stops overfitting. Additionally, we can save the best weights for our model so that it doesn't have to be retrained. At the end of the training process, the model will restore the weights of its best iteration.","227ecf8c":"## 2.3 Define loading methods","5c26b215":"## 3.4 Correcting for data inbalance","d2a63f3e":"## 3.2 Explore our data\n\n","57c5e6c5":"## 3.3 Build our base model\n\nTransfer learning is a great way to reap the benefits of a well-trained model without having the train the model ourselves. ","2b5b6c9c":"## 2.1 Decoding the data","68203a6a":"## 3.5 Deciding our evaluation metrics\n","1da14690":"# 2. Load the data","932696c4":"## 3.1 Define the learning rate\n\nThe following function allows for the model to change the learning rate as it runs each epoch. Having a learning rate that is too high will prevent our model from converging. However, having a learning rate that is too small will cause our model to run for far too long. With this function, the model will know how to change its learning rate after each epoch and update the learning rate itself to allow for increased efficiency while still allowing the model to converge.","5fefee67":"### 3.4.1 Set initial bias\n\nWe want to set the correct initial bias for our model so that it will not waste time figuring out that there are not many malignant images in our dataset. We want our output layer to reflect the inbalance that we have in our data."}}