{"cell_type":{"acba5b04":"code","1dea7dfb":"code","07a0f38c":"code","2eabc8a0":"code","0eb008fc":"code","c8426e3a":"code","bb6a9523":"code","d4960a3b":"code","e77daf51":"code","fe06c318":"code","f9401a39":"code","a6412161":"code","d083176f":"code","592a928e":"code","54321e1b":"code","e8230056":"code","ebdb7bda":"code","8cc13cda":"code","a50051e8":"code","5ab96f53":"code","8e98312f":"code","3e291d3e":"code","6cdf1d40":"code","367b131f":"code","61a6a70f":"code","2bc24e2b":"code","980eaf1b":"code","fe7bfb78":"code","e3a0ee73":"code","bda353df":"code","5bf6673e":"code","32d71e0a":"code","13b99f2a":"code","fd57d4e0":"code","6299c74e":"code","fecb77c7":"code","c2d26112":"code","5ed7e1fb":"code","998e7620":"code","d4d051e3":"code","7f3553c4":"code","98122c39":"code","bfca4be8":"code","134a3f07":"code","dbd01205":"code","a6483533":"code","b80c22b9":"code","884222cb":"code","eca4fc3a":"code","c9a221b9":"code","6955e092":"markdown","905baeea":"markdown","7fbf7c13":"markdown","4da53933":"markdown","d605da20":"markdown","63dd138d":"markdown","b27ed088":"markdown","3088676c":"markdown","ee6f73ad":"markdown","cd7b6d06":"markdown"},"source":{"acba5b04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1dea7dfb":"import pandas as pd\nimport numpy as np","07a0f38c":"df1 = pd.read_csv('..\/input\/movie-review-sentiment-analysis-kernels-only\/sampleSubmission.csv', sep=\",\")\ndf2 = pd.read_csv('..\/input\/movie-review-sentiment-analysis-kernels-only\/train.tsv', sep=\"\\t\")\ndf3 = pd.read_csv('..\/input\/movie-review-sentiment-analysis-kernels-only\/test.tsv', sep=\"\\t\")\n","2eabc8a0":"df1.head(5)","0eb008fc":"df2.head(5)","c8426e3a":"df3.head(5)","bb6a9523":"df2.info()","d4960a3b":"df3.info()","e77daf51":"df2['Sentiment'].value_counts()","fe06c318":"df2[df2['Sentiment']==1]['Phrase'].head(3)","f9401a39":"df2.loc[df2.SentenceId ==2]","a6412161":"#regular expression \nimport re \n\n#regular expression for the removal of name tags and the emoticons from tweets.\ndef process(Phrase):\n    return \" \".join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \",Phrase.lower()).split())","d083176f":"#Applying the Process function to the given Train Data\ndf2['Newphrase']= df2['Phrase'].apply(process)","592a928e":"import matplotlib.pyplot as plt\nimport seaborn as sns","54321e1b":"z = df2['Sentiment']\nplt.hist(z, bins=5,color='Red')\nplt.ylabel('count')\nplt.xlabel('rating')\nplt.show()","e8230056":"df2.head(5)","ebdb7bda":"#df2.drop('Phrase',inplace=True,axis=1)","8cc13cda":"#df2.drop('PhraseId', inplace=True,axis=1)","a50051e8":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier","5ab96f53":"df2.info()","8e98312f":"count_vect = CountVectorizer(stop_words='english',ngram_range=(1,3),analyzer='word')\ntransformer = TfidfTransformer(norm='l2',sublinear_tf=True)","3e291d3e":"#splitting the data into random train and test subsets\nx_train, x_test, y_train, y_test = train_test_split(df2[\"Newphrase\"],df2[\"Sentiment\"],\n                                                    test_size = 0.2, random_state = 20)\n\nx_train_counts = count_vect.fit_transform(x_train)\nx_train_tfidf = transformer.fit_transform(x_train_counts)\nx_test_counts = count_vect.transform(x_test)\nx_test_tfidf = transformer.transform(x_test_counts)","6cdf1d40":"print(x_train_counts.shape)\nprint(x_train_tfidf.shape)\nprint(x_test_counts.shape)\nprint(x_test_tfidf.shape)","367b131f":"from sklearn.linear_model import SGDClassifier\n\nmodel = SGDClassifier(loss=\"modified_huber\", penalty=\"l1\")\nmodel.fit(x_train_tfidf,y_train)\npredictions = model.predict(x_test_tfidf)","61a6a70f":"from sklearn.metrics import precision_score,recall_score,f1_score, accuracy_score, confusion_matrix","2bc24e2b":"accuracy_score(y_test,predictions)","980eaf1b":"f1_score(y_test,predictions, average ='micro')","fe7bfb78":"recall_score(y_test,predictions, average = 'micro')","e3a0ee73":"precision_score(y_test,predictions,average = 'micro')","bda353df":"#different classification modesls being used\nfrom sklearn.svm import LinearSVC\n\nmodel_svc = LinearSVC(C=2.0,max_iter=500,tol=0.0001,loss ='hinge')\nmodel_svc.fit(x_train_counts,y_train)","5bf6673e":"predict_svc = model_svc.predict(x_test_counts)","32d71e0a":"f1_score(y_test,predict_svc, average = 'micro')","13b99f2a":"recall_score(y_test,predict_svc, average = 'micro')","fd57d4e0":"accuracy_score(y_test,predict_svc)","6299c74e":"#optimizing parameters\nfrom sklearn.model_selection import GridSearchCV\n\n\nparams = {\"tfidf__ngram_range\": [(1, 2), (1,3), (1,4)],\n          \"svc__C\": [.01, .1, 1, 10, 100]}\n\nclf = Pipeline([(\"tfidf\", TfidfVectorizer(sublinear_tf=True)),\n                (\"svc\", LinearSVC(loss='hinge'))])\n\ngs = GridSearchCV(clf, params, verbose=4, n_jobs=-1)\ngs.fit(x_train,y_train)\nprint(\"Best Estimator = \", gs.best_estimator_)\nprint(\"Best Score = \",gs.best_score_)","fecb77c7":"predicted = gs.predict(x_test)","c2d26112":"predicted","5ed7e1fb":"f1_score(y_test,predicted, average = 'micro')","998e7620":"recall_score(y_test,predicted, average = 'micro')","d4d051e3":"precision_score(y_test,predicted, average = 'micro')","7f3553c4":"accuracy_score(y_test,predicted)","98122c39":"df3['Newphrase']= df3['Phrase'].apply(process)","bfca4be8":"#df3.drop('Phrase',inplace=True,axis=1)","134a3f07":"#df3.drop('PhraseId', inplace=True,axis=1)","dbd01205":"df3.head(5)","a6483533":"predicted = gs.predict(df3['Newphrase'])","b80c22b9":"final_predict = pd.DataFrame(predicted,columns=['Sentiment'])\nresult = pd.DataFrame(df3['PhraseId'])\nresult = pd.concat([result,final_predict],axis=1)\nresult.to_csv('Submission.csv',index=False)","884222cb":"predicted","eca4fc3a":"result","c9a221b9":"result['Sentiment'].value_counts()","6955e092":"# 06 Tune the model","905baeea":"# 03 Analyze The data","7fbf7c13":"# 1st model","4da53933":"# 2nd model","d605da20":"Problem statement link :https:\/\/www.kaggle.com\/c\/movie-review-sentiment-analysis-kernels-only\/overview","63dd138d":"# 05 Model Selection","b27ed088":"# 04 Feature Enginnering","3088676c":"# 02 Obtain the data","ee6f73ad":"# 01 Frame the Problem","cd7b6d06":"# 07 Predict on new cases"}}