{"cell_type":{"68a84666":"code","304905e4":"code","e000aa02":"code","d72bc9ff":"code","52eeeedf":"code","9ddce2a1":"code","c91632b5":"code","459857b4":"code","b720cdde":"code","5d362fef":"code","b6ac9474":"code","84caae18":"code","17a23f02":"code","1beebeca":"code","16de348e":"code","1f647c49":"code","27493cdb":"code","7954d74a":"code","044fcb12":"code","6ae6ea42":"code","8b9a6c6e":"code","58fd2133":"code","e862310c":"code","f6e02aa0":"code","f2836a67":"code","95af535a":"code","30f4e2fc":"code","1f0feb6e":"code","6a020052":"code","cbb8d0c5":"code","30aece28":"code","d83d0708":"code","5e1865b7":"code","ce338d3e":"code","4542921b":"code","3c10cc29":"code","ee86938e":"code","ed907483":"code","a4f9db25":"code","6e044597":"code","21b88f08":"code","25db581c":"code","112e575c":"code","cbcc2852":"code","f3240761":"code","e466f826":"code","a5bda935":"code","e59de69b":"code","c45051c3":"code","0941e217":"code","e8539bb4":"code","8519130e":"code","0c656b5f":"code","f4cb1c8d":"code","fad35b16":"code","53f8f82b":"code","8011de36":"code","3c6a2791":"code","43014844":"code","bcca72b6":"code","bdcf196d":"code","a7e74f45":"code","b6c33906":"code","4a75e3c6":"code","b5806702":"code","7ce0e76b":"code","97977855":"code","eabf9686":"code","bf5c17ab":"code","7527843e":"code","fc0b55bc":"code","6b6d4e63":"code","a2e27487":"code","f201795a":"code","144dffe0":"code","216d5ae7":"code","842c3685":"code","2f3e0dc6":"code","a9a020cc":"code","ff83a49c":"code","cb551c45":"code","0804bef2":"code","cfde970c":"code","f7a24a8f":"code","0ec074bf":"code","bf13bb32":"code","1c19cd87":"code","6875d39d":"code","df7008bf":"code","00ceeb94":"code","221064a8":"code","6fc31e75":"code","2b6c7168":"code","14f6425a":"code","e428f950":"code","09445a11":"code","6b976e96":"code","0eb955a5":"code","5d126f97":"code","2048d944":"code","ac2eab60":"code","56cf1bbe":"code","a3de782e":"code","16450ca1":"code","e92d36e1":"code","d065a21b":"code","204879ba":"code","7a32ebd0":"code","dbd27c00":"markdown","90495510":"markdown","dc0889ed":"markdown","bed71d5e":"markdown","eb21f3c7":"markdown","3dd1e211":"markdown","3258bfe6":"markdown","f7bcfec6":"markdown","ed0a4982":"markdown","ddc9e6ee":"markdown","33c83fb9":"markdown","0d293bb0":"markdown","f8255f46":"markdown","16ae2476":"markdown","4c282d44":"markdown","94478b56":"markdown","5bef6710":"markdown","9202b762":"markdown","28bfc7a0":"markdown","1d0631af":"markdown","d5ab4173":"markdown","7d7340f3":"markdown","1c459534":"markdown","4b4417a2":"markdown","10af3a63":"markdown","a8a0a796":"markdown","b8e7db09":"markdown","e4aeb4d2":"markdown","2c206ae1":"markdown","0ae9a4f0":"markdown","8e08292b":"markdown","adc34941":"markdown","18f7f469":"markdown","c119fa15":"markdown","7420c79e":"markdown","bbf1836c":"markdown","d7d3a075":"markdown","3e7fedf6":"markdown","23c0d376":"markdown","aa02f0c0":"markdown","06c1fee1":"markdown","46bcfd81":"markdown","d476cf7c":"markdown","a744511f":"markdown","f446db16":"markdown","e46eaff5":"markdown","5f0f12a8":"markdown","2bf09170":"markdown","e0aeac82":"markdown","a79a5523":"markdown","72de58d5":"markdown","60d50119":"markdown","bd2015bb":"markdown","ba63fdcb":"markdown","3474d748":"markdown","bd4ce7b8":"markdown","8a055930":"markdown","214e644e":"markdown","633d1e8d":"markdown","3430f911":"markdown","18f66339":"markdown","dfa1fe5e":"markdown","8cc088dd":"markdown","6ab16bf5":"markdown","22389086":"markdown","8a97c7b2":"markdown","5a6b37b8":"markdown","d2552943":"markdown","b40d10a3":"markdown","71148bab":"markdown","5e1c70bf":"markdown","120617dd":"markdown","22a10d5b":"markdown","57774e54":"markdown","d5469cb0":"markdown","a9d548a6":"markdown","cc507e73":"markdown","f46c3710":"markdown","ae5fd5f3":"markdown","415e6043":"markdown","4963ec89":"markdown","f1784168":"markdown"},"source":{"68a84666":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","304905e4":"import numpy as np \nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nimport matplotlib.gridspec as gridspec\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nimport statsmodels.api as sm\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\n\nfrom keras.layers import Flatten \n","e000aa02":"data = pd.read_csv('..\/input\/countries-of-the-world\/countries of the world.csv')","d72bc9ff":"data.head(5)","52eeeedf":"data.info()","9ddce2a1":"data.columns = ([\"country\",\"region\",\"population\",\"area\",\"density\",\"coastline_area_ratio\",\"net_migration\",\"infant_mortality\",\"gdp_per_capita\",\n                  \"literacy\",\"phones\",\"arable\",\"crops\",\"other\",\"climate\",\"birthrate\",\"deathrate\",\"agriculture\",\"industry\",\n                  \"service\"])","c91632b5":"data.country = data.country.astype('category')\n\ndata.region = data.region.astype('category')\n\ndata.density = data.density.astype(str)\ndata.density = data.density.str.replace(\",\",\".\").astype(float)\n\ndata.coastline_area_ratio = data.coastline_area_ratio.astype(str)\ndata.coastline_area_ratio = data.coastline_area_ratio.str.replace(\",\",\".\").astype(float)\n\ndata.net_migration = data.net_migration.astype(str)\ndata.net_migration = data.net_migration.str.replace(\",\",\".\").astype(float)\n\ndata.infant_mortality = data.infant_mortality.astype(str)\ndata.infant_mortality = data.infant_mortality.str.replace(\",\",\".\").astype(float)\n\ndata.literacy = data.literacy.astype(str)\ndata.literacy = data.literacy.str.replace(\",\",\".\").astype(float)\n\ndata.phones = data.phones.astype(str)\ndata.phones = data.phones.str.replace(\",\",\".\").astype(float)\n\ndata.arable = data.arable.astype(str)\ndata.arable = data.arable.str.replace(\",\",\".\").astype(float)\n\ndata.crops = data.crops.astype(str)\ndata.crops = data.crops.str.replace(\",\",\".\").astype(float)\n\ndata.other = data.other.astype(str)\ndata.other = data.other.str.replace(\",\",\".\").astype(float)\n\ndata.climate = data.climate.astype(str)\ndata.climate = data.climate.str.replace(\",\",\".\").astype(float)\n\ndata.birthrate = data.birthrate.astype(str)\ndata.birthrate = data.birthrate.str.replace(\",\",\".\").astype(float)\n\ndata.deathrate = data.deathrate.astype(str)\ndata.deathrate = data.deathrate.str.replace(\",\",\".\").astype(float)\n\ndata.agriculture = data.agriculture.astype(str)\ndata.agriculture = data.agriculture.str.replace(\",\",\".\").astype(float)\n\ndata.industry = data.industry.astype(str)\ndata.industry = data.industry.str.replace(\",\",\".\").astype(float)\n\ndata.service = data.service.astype(str)\ndata.service = data.service.str.replace(\",\",\".\").astype(float)","459857b4":"data.info()","b720cdde":"data.shape","5d362fef":"data.head(5)","b6ac9474":"fig = plt.figure(figsize=(16,30))\nfeatures= [\"population\",\"area\", \"density\", \"coastline_area_ratio\",\"net_migration\",\"infant_mortality\", \"literacy\", \"phones\", \"arable\",\"crops\",\"other\",\"climate\",\"birthrate\",\"deathrate\",\"agriculture\",\"industry\",\"service\"]\n\nfor i in range(len(features)):\n    fig.add_subplot(9, 5, i+1)\n    sns.boxplot(y=data[features[i]])\nplt.tight_layout()\nplt.show()","84caae18":"fig = plt.figure(figsize=(16,30))\nfeatures= [\"population\",\"area\", \"density\", \"coastline_area_ratio\",\"net_migration\",\"infant_mortality\", \"literacy\", \"phones\", \"arable\",\"crops\",\"other\",\"climate\",\"birthrate\",\"deathrate\",\"agriculture\",\"industry\",\"service\"]\n\nfor i in range(len(features)):\n    fig.add_subplot(9, 5, i+1)\n    sns.distplot(data[features[i]])\nplt.tight_layout()\nplt.show()","17a23f02":"# boxplot for distribution analysis of region (categorical data) with GDP per Capita\n\nsns.boxplot(y=data['gdp_per_capita'],x= data['region'])\nplt.tight_layout()\nplt.xticks(rotation=90)\nplt.show()","1beebeca":"fig = plt.figure(constrained_layout=True, figsize=(16,6))\ngrid = gridspec.GridSpec(ncols=3, nrows=1, figure=fig)\nax1 = fig.add_subplot(grid[0, :2])\nax1.set_title('Histogram')\nsns.distplot(data.loc[:,'gdp_per_capita'], norm_hist=True, ax = ax1)\nax3 = fig.add_subplot(grid[:, 2])\nax3.set_title('Box Plot')\nsns.boxplot(data.loc[:,'gdp_per_capita'], orient='v', ax = ax3)\nplt.show()","16de348e":"#skewness and kurtosis\nprint(\"Skewness: %f\" % data['gdp_per_capita'].skew())\nprint(\"Kurtosis: %f\" % data['gdp_per_capita'].kurt())","1f647c49":"#missing data\ntotal = data.isnull().sum().sort_values(ascending=False)\npercent = ((data.isnull().sum()\/data.isnull().count()).sort_values(ascending=False))*100\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","27493cdb":"f, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=percent.index, y=percent)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)","7954d74a":"sns.heatmap(data.isnull()).set(title = 'Missing Data', xlabel = 'Columns', ylabel = 'Data Points')","044fcb12":"data.head(20)","6ae6ea42":"print(data.isnull().sum())","8b9a6c6e":"data['gdp_per_capita'].isnull()","58fd2133":"data['country'].iloc[223]","e862310c":"data[data['literacy'].isnull()].index.tolist()","f6e02aa0":"print(data['country'].iloc[66])\nprint(data['region'].iloc[66])","f2836a67":"data[data['phones'].isnull()].index.tolist()","95af535a":"print(data['country'].iloc[52])\nprint(data['region'].iloc[52])","30f4e2fc":"data['climate']","1f0feb6e":"data['agriculture']","6a020052":"data[data['agriculture'].isnull()].index.tolist()","cbb8d0c5":"print(data.iloc[3])\nprint(data.iloc[4])\nprint(data.iloc[78])\nprint(data.iloc[80])\nprint(data.iloc[83])\nprint(data.iloc[134])\nprint(data.iloc[140])\nprint(data.iloc[144])\nprint(data.iloc[153])\nprint(data.iloc[171])\nprint(data.iloc[174])\nprint(data.iloc[177])\nprint(data.iloc[208])\nprint(data.iloc[221])\nprint(data.iloc[223])","30aece28":"data[data['industry'].isnull()].index.tolist()","d83d0708":"print(data.iloc[138])","5e1865b7":"data['net_migration'].fillna(0, inplace=True)\ndata['infant_mortality'].fillna(0, inplace=True)\ndata['gdp_per_capita'].fillna(2500, inplace=True)\ndata['literacy'].fillna(data.groupby('region')['literacy'].transform('median'), inplace= True)\ndata['phones'].fillna(data.groupby('region')['phones'].transform('median'), inplace= True)\ndata['arable'].fillna(0, inplace=True)\ndata['crops'].fillna(0, inplace=True)\ndata['other'].fillna(0, inplace=True)\ndata['climate'].fillna(0, inplace=True)\ndata['birthrate'].fillna(data.groupby('region')['birthrate'].transform('mean'), inplace= True)\ndata['deathrate'].fillna(data.groupby('region')['deathrate'].transform('median'), inplace= True)","ce338d3e":"# For monaco, i will set the value for industry and service to be 0.05 and 0.78 respectively \ndata['industry'][138] = 0.05\ndata['service'][138] = 0.78\nprint(data['industry'][138])\nprint(data['service'][138])\n\n","4542921b":"# For western sahara, i will set the value for agriculture and industry to be 0.35 and 0.25 respectively.\ndata['industry'][223] = 0.25\ndata['agriculture'][223] = 0.35\nprint(data['industry'][223])\nprint(data['agriculture'][223])","3c10cc29":"data['agriculture'].fillna(0.15, inplace=True)\ndata['service'].fillna(0.8, inplace=True)\ndata['industry'].fillna(0.05, inplace= True)","ee86938e":"print(data.isnull().sum())","ed907483":"fig, ax = plt.subplots(figsize=(16,16)) \nsns.heatmap(data.corr(), annot=True, ax=ax).set(\n    title = 'Feature Correlation', xlabel = 'Columns', ylabel = 'Columns')\nplt.show()\n","a4f9db25":"fig = plt.figure(figsize=(12, 4))\ndata.groupby('region')['gdp_per_capita'].mean().sort_values().plot(kind='bar')\nplt.title('Regional Average GDP per Capita')\nplt.xlabel(\"Region\")\nplt.ylabel('Average GDP per Capita')\nplt.show()","6e044597":"sns.boxplot(x=\"region\",y=\"gdp_per_capita\",data=data,width=0.7,palette=\"Set3\",fliersize=5)\nplt.xticks(rotation=90)\nplt.title(\"Regional Average GDP per Capita\")","21b88f08":"fig = plt.figure(figsize=(12, 12))\nsns.jointplot(data= data, x= 'literacy', y= 'gdp_per_capita', kind= 'scatter')\nplt.title('GDP Analysis: GDP per capita vs Literacy')\nplt.show()","25db581c":"fig = plt.figure(figsize=(12, 12))\nsns.jointplot(data= data, x= 'phones', y= 'gdp_per_capita', kind= 'scatter')\nplt.title('GDP Analysis: GDP per capita vs Literacy')\nplt.show()","112e575c":"fig = plt.figure(figsize=(12, 12))\nsns.jointplot(data= data, x= 'phones', y= 'gdp_per_capita', kind= 'hex')\nplt.title('GDP Analysis: GDP per capita vs Literacy')\nplt.show()","cbcc2852":"fig = plt.figure(figsize=(12, 12))\nsns.jointplot(data= data, x= 'infant_mortality', y= 'gdp_per_capita', kind= 'scatter')\nplt.title('GDP Analysis: GDP per capita vs infant_mortality ')\nplt.show()","f3240761":"fig = plt.figure(figsize=(12, 12))\nsns.jointplot(data= data, x= 'birthrate', y= 'infant_mortality', kind= 'scatter')\nplt.title('GDP Analysis: birthrate vs infant_mortality')\nplt.show()","e466f826":"gdp=data.sort_values([\"gdp_per_capita\"],ascending=False)\n\n# prepare data frame\ndf = gdp.iloc[:100,:]\n\n# Creating trace1\ntrace1 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.birthrate,\n                    mode = \"lines\",\n                    name = \"Birthrate\",\n                    marker = dict(color = 'rgba(235,66,30, 0.8)'),\n                    text= df.country)\n# Creating trace2\ntrace2 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.deathrate,\n                    mode = \"lines+markers\",\n                    name = \"Deathrate\",\n                    marker = dict(color = 'rgba(10,10,180, 0.8)'),\n                    text= df.country)\nz = [trace1, trace2]\nlayout = dict(title = 'Birthrate and Deathrate of World Countries (Top 100)',\n              xaxis= dict(title= 'GDP',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = z, layout = layout)\niplot(fig)","a5bda935":"gdp=data.sort_values([\"gdp_per_capita\"],ascending=False)","e59de69b":"# prepare data frame\ndf = gdp.iloc[127:227,:]\n\n# Creating trace1\ntrace1 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.birthrate,\n                    mode = \"lines\",\n                    name = \"Birthrate\",\n                    marker = dict(color = 'rgba(235,66,30, 0.8)'),\n                    text= df.country)\n# Creating trace2\ntrace2 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.deathrate,\n                    mode = \"lines+markers\",\n                    name = \"Deathrate\",\n                    marker = dict(color = 'rgba(10,10,180, 0.8)'),\n                    text= df.country)\nz = [trace1, trace2]\nlayout = dict(title = 'Birthrate and Deathrate Percentage of World Countries (Last 100)',\n              xaxis= dict(title= 'GDP',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = z, layout = layout)\niplot(fig)","c45051c3":"# prepare data frame\ndf = gdp.iloc[:100,:]\n\n# Creating trace1\ntrace1 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.agriculture,\n                    mode = \"lines+markers\",\n                    name = \"AGRICULTURE\",\n                    marker = dict(color = 'rgba(235,66,30, 0.8)'),\n                    text= df.country)\n# Creating trace2\ntrace2 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.industry,\n                    mode = \"lines+markers\",\n                    name = \"INDUSTRY\",\n                    marker = dict(color = 'rgba(10,10,180, 0.8)'),\n                    text= df.country)\n# Creating trace3\ntrace3 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.service,\n                    mode = \"lines+markers\",\n                    name = \"SERVICE\",\n                    marker = dict(color = 'rgba(10,250,60, 0.8)'),\n                    text= df.country)\n\n\nz = [trace1, trace2,trace3]\nlayout = dict(title = 'Service , Industry and Agriculture Percentage of World Countries (TOP 100)',\n              xaxis= dict(title= 'GDP',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = z, layout = layout)\niplot(fig)","0941e217":"# prepare data frame\ndf = gdp.iloc[127:227,:]\n\n# Creating trace1\ntrace1 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.agriculture,\n                    mode = \"lines+markers\",\n                    name = \"AGRICULTURE\",\n                    marker = dict(color = 'rgba(235,66,30, 0.8)'),\n                    text= df.country)\n# Creating trace2\ntrace2 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.industry,\n                    mode = \"lines+markers\",\n                    name = \"INDUSTRY\",\n                    marker = dict(color = 'rgba(10,10,180, 0.8)'),\n                    text= df.country)\n# Creating trace3\ntrace3 = go.Scatter(\n                    x = df.gdp_per_capita,\n                    y = df.service,\n                    mode = \"lines+markers\",\n                    name = \"SERVICE\",\n                    marker = dict(color = 'rgba(10,250,60, 0.8)'),\n                    text= df.country)\n\n\nz = [trace1, trace2,trace3]\nlayout = dict(title = 'Service , Industry and Agriculture Percentage of World Countries (LAST 100)',\n              xaxis= dict(title= 'GDP',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = z, layout = layout)\niplot(fig)","e8539bb4":"lit = data.sort_values(\"literacy\",ascending=False).head(7)","8519130e":"trace1 = go.Bar(\n                x = lit.country,\n                y = lit.agriculture,\n                name = \"agriculture\",\n                marker = dict(color = 'rgba(255, 20, 20, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = lit.gdp_per_capita)\ntrace2 = go.Bar(\n                x = lit.country,\n                y = lit.service,\n                name = \"service\",\n                marker = dict(color = 'rgba(20, 20, 128, 0.5)',\n                              line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = lit.gdp_per_capita)\nz = [trace1, trace2]\nlayout = go.Layout(barmode = \"group\")\nfig = go.Figure(data = z, layout = layout)\niplot(fig)","0c656b5f":"x = lit.country\n\ntrace1 = {\n  'x': x,\n  'y': lit.industry,\n  'name': 'industry',\n  'type': 'bar'\n};\ntrace2 = {\n  'x': x,\n  'y': lit.service,\n  'name': 'service',\n  'type': 'bar'\n};\nz = [trace1, trace2];\nlayout = {\n  'xaxis': {'title': 'Top 7 country'},\n  'barmode': 'relative',\n  'title': 'industry and service percentage of top 7 country (literacy)'\n};\nfig = go.Figure(data = z, layout = layout)\niplot(fig)","f4cb1c8d":"#Population per country\nz = dict(type='choropleth',\n            locations = data.country,\n            locationmode = 'country names', z = data.population,\n            text = data.country, colorbar = {'title':'Population'},\n            colorscale = 'Blackbody', reversescale = True)\n\nlayout = dict(title='Population per country',\ngeo = dict(showframe=False,projection={'type':'natural earth'}))\nchoromap = go.Figure(data = [z],layout = layout)\niplot(choromap,validate=False)","fad35b16":"#Infant motality per country\nz = dict(type='choropleth',\n        locations = data.country,\n        locationmode = 'country names', z = data.infant_mortality,\n        text = data.country, colorbar = {'title':'Infant Mortality'},\n        colorscale = 'YlOrRd', reversescale = True)\nlayout = dict(title='Infant Mortality per Country',\ngeo = dict(showframe=False,projection={'type':'natural earth'}))\nchoromap = go.Figure(data = [z],layout = layout)\niplot(choromap,validate=False)","53f8f82b":"data.head(5)","8011de36":"#Population per country\nz = dict(type='choropleth',\nlocations = data.country,\nlocationmode = 'country names', z = data.gdp_per_capita,\ntext = data.country, colorbar = {'title':'GDP per Capita'},\ncolorscale = 'Hot', reversescale = True)\nlayout = dict(title='GDP per Capita of World Countries',\ngeo = dict(showframe=False,projection={'type':'natural earth'}))\nchoromap = go.Figure(data = [z],layout = layout)\niplot(choromap,validate=False)","3c6a2791":"fig = plt.figure(figsize=(18, 24))\nplt.title('Regional Analysis')\nax1 = fig.add_subplot(4, 1, 1)\nax2 = fig.add_subplot(4, 1, 2)\nax3 = fig.add_subplot(4, 1, 3)\nax4 = fig.add_subplot(4, 1, 4)\nsns.countplot(data= data, y= 'region', ax= ax1)\nsns.barplot(data= data, y= 'region', x= 'gdp_per_capita', ax= ax2, ci= None)\nsns.barplot(data= data, y= 'region', x= 'net_migration', ax= ax3, ci= None)\nsns.barplot(data= data, y= 'region', x= 'population', ax= ax4, ci= None)\nplt.show()","43014844":"data_final = pd.concat([data,pd.get_dummies(data['region'], prefix='region')], axis=1)\n#dropping the redundant region column\ndata_final.drop(['region'],axis=1,inplace=True)\nprint(data_final.info())","bcca72b6":"data_final.head(10)","bdcf196d":"y = data_final['gdp_per_capita']\nX = data_final.drop(['gdp_per_capita','country'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","a7e74f45":"#StandardScaler will transform data such that its distribution will have a mean value 0 and standard deviation of 1.\nsc_X = StandardScaler()\n\nX2_train = sc_X.fit_transform(X_train)\nX2_test = sc_X.fit_transform(X_test)\ny2_train = y_train\ny2_test = y_test","b6c33906":"data_final[data_final.columns[1:]].corr()['gdp_per_capita'][:]","4a75e3c6":"y3 = y\nX3 = data_final.drop(['gdp_per_capita','country','population', 'area', 'coastline_area_ratio', 'arable',\n                      'crops', 'other', 'climate', 'deathrate', 'industry'], axis=1)\n\nX3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=101)","b5806702":"sc_X4 = StandardScaler()\n\nX4_train = sc_X4.fit_transform(X3_train)\nX4_test = sc_X4.fit_transform(X3_test)\ny4_train = y3_train\ny4_test = y3_test","7ce0e76b":"lm1 = LinearRegression()\nlm1.fit(X_train,y_train)\n\nlm2 = LinearRegression()\nlm2.fit(X2_train,y2_train)\n\nlm3 = LinearRegression()\nlm3.fit(X3_train,y3_train)\n\nlm4 = LinearRegression()\nlm4.fit(X4_train,y4_train)","97977855":"lm1_pred = lm1.predict(X_test)\nlm2_pred = lm2.predict(X2_test)\nlm3_pred = lm3.predict(X3_test)\nlm4_pred = lm4.predict(X4_test)","eabf9686":"print('Linear Regression Performance:')\n\nprint('\\nall features, No scaling:')\nprint('MAE:', mean_absolute_error(y_test, lm1_pred))\nprint('RMSE:', np.sqrt(mean_squared_error(y_test, lm1_pred)))\nprint('R2_Score: ', r2_score(y_test, lm1_pred))\n\nprint('\\nall features, with scaling:')\nprint('MAE:', mean_absolute_error(y2_test, lm2_pred))\nprint('RMSE:', np.sqrt(mean_squared_error(y2_test, lm2_pred)))\nprint('R2_Score: ', r2_score(y2_test, lm2_pred))\n\nprint('\\nselected features, No scaling:')\nprint('MAE:', mean_absolute_error(y3_test, lm3_pred))\nprint('RMSE:', np.sqrt(mean_squared_error(y3_test, lm3_pred)))\nprint('R2_Score: ', r2_score(y3_test, lm3_pred))\n\nprint('\\nselected features, with scaling:')\nprint('MAE:', mean_absolute_error(y4_test, lm4_pred))\nprint('RMSE:', np.sqrt(mean_squared_error(y4_test, lm4_pred)))\nprint('R2_Score: ', r2_score(y4_test, lm4_pred))\n","bf5c17ab":"fig = plt.figure(figsize=(12, 6))\nplt.scatter(y4_test,lm4_pred,color='coral', linewidths=2, edgecolors='k')\nplt.xlabel('True GDP per Capita') \nplt.ylabel('Predicted GDP per Capita') \nplt.title('Linear Regression Prediction Performance (features selected and scaled)') \nplt.grid()\nplt.show()","7527843e":"model = sm.OLS(y4_train, X4_train).fit()\nprint_model = model.summary()\nprint(print_model)\n\n","fc0b55bc":"print(X3.columns[1])","6b6d4e63":"#what the coefficient values refers to\ni=1\nfor col in X3.columns: \n    print(\"x\"+str(i)+\":\"+str(col))\n    i=i+1","a2e27487":"print(lm4.coef_)\nfrom matplotlib import pyplot\n\nimportance = lm4.coef_\n# summarize feature importance\n# for i,v in enumerate(importance):\n#     print(\"Feature:\" + str(X3.columns[i]) + \", Score: %.5f\" % (i,v))\n# plot feature importance\npyplot.bar([x for x in range(len(importance))], importance)\npyplot.show()","f201795a":"features = {'Feature': ['density', 'net_migration','infant_mortality','literacy','phones', 'birthrate', 'agriculture','service','region_ASIA (EX. NEAR EAST)','region_BALTICS', 'region_C.W. OF IND. STATES', 'region_EASTERN EUROPE', 'region_LATIN AMER. & CARIB', 'region_NEAR EAST', 'region_NORTHERN AFRICA', 'region_NORTHERN AMERICA', 'region_OCEANIA', 'region_SUB-SAHARAN AFRICA', 'region_WESTERN EUROPE'],\n        'Coefficient': [-593.27081629, 1789.42167595, -309.12088609, 256.01950704, 5313.19849616, -1318.85076516, -1655.24940852, -706.2682728, -25.78832369, -262.58839876, -957.2313499, -789.87119263, -819.42112542, -230.40994515, -297.50983884, 467.15853813, 132.13764433, 241.54449668, 2086.82900519]}\n\ndf_features = pd.DataFrame(features, columns = ['Feature', 'Coefficient'])\nprint (df)\n\ndf_sorted_desc= df_features.sort_values('Coefficient',ascending=False)\nplt.figure(figsize=(10,6))\n# bar plot with matplotlib\nplt.bar('Feature', 'Coefficient',data=df_sorted_desc)\nplt.xticks(rotation=90)\nplt.xlabel(\"Feature\", size=15)\nplt.ylabel(\"Feature Coefficient\", size=15)\nplt.title(\"Coefficient of features (X4)\", size=18)","144dffe0":"df_features['AbsCoefficient']=\"\"\ndf_features['AbsCoefficient'] = df_features['Coefficient'].abs()\n\ndf_abs_desc= df_features.sort_values('AbsCoefficient',ascending=False)\nplt.figure(figsize=(10,6))\n# bar plot with matplotlib\nplt.bar('Feature', 'AbsCoefficient',data=df_abs_desc)\nplt.xticks(rotation=90)\nplt.xlabel(\"Feature\", size=15)\nplt.ylabel(\"Feature importance\", size=15)\nplt.title(\"Feature importance (X4)\", size=18)","216d5ae7":"print(\"Ridge Regression performance\")\nrr = Ridge(alpha=0.01)\nrr.fit(X4_train,y4_train) \npred_test_ridge= rr.predict(X4_test)\n\nprint('MAE:', mean_absolute_error(y4_test,pred_test_ridge))\nprint('RMSE:', np.sqrt(mean_squared_error(y4_test,pred_test_ridge)))\nprint('R2_Score: ', r2_score(y4_test,pred_test_ridge))","842c3685":"print(\"Lasso Regression performance\")\nmodel_lasso = Lasso(alpha=0.01,tol=0.01)\nmodel_lasso.fit(X4_train,y4_train) \npred_test_lasso= model_lasso.predict(X4_test)\nprint('MAE:', mean_absolute_error(y4_test,pred_test_lasso))\nprint('RMSE:', np.sqrt(mean_squared_error(y4_test,pred_test_lasso)))\nprint('R2_Score: ', r2_score(y4_test,pred_test_lasso))","2f3e0dc6":"svm1 = SVR(kernel='rbf')\nsvm1.fit(X_train,y_train)\n\nsvm2 = SVR(kernel='rbf')\nsvm2.fit(X2_train,y2_train)\n\nsvm3 = SVR(kernel='rbf')\nsvm3.fit(X3_train,y3_train)\n\nsvm4 = SVR(kernel='rbf')\nsvm4.fit(X4_train,y4_train)","a9a020cc":"svm1_pred = svm1.predict(X_test)\nsvm2_pred = svm2.predict(X2_test)\nsvm3_pred = svm3.predict(X3_test)\nsvm4_pred = svm4.predict(X4_test)","ff83a49c":"print('SVM Performance:')\n\nprint('\\nall features, No scaling:')\nprint('MAE:', metrics.mean_absolute_error(y_test, svm1_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, svm1_pred)))\nprint('R2_Score: ', metrics.r2_score(y_test, svm1_pred))\n\nprint('\\nall features, with scaling:')\nprint('MAE:', metrics.mean_absolute_error(y2_test, svm2_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y2_test, svm2_pred)))\nprint('R2_Score: ', metrics.r2_score(y2_test, svm2_pred))\n\nprint('\\nselected features, No scaling:')\nprint('MAE:', metrics.mean_absolute_error(y3_test, svm3_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y3_test, svm3_pred)))\nprint('R2_Score: ', metrics.r2_score(y3_test, svm3_pred))\n\nprint('\\nselected features, with scaling:')\nprint('MAE:', metrics.mean_absolute_error(y4_test, svm4_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y4_test, svm4_pred)))\nprint('R2_Score: ', metrics.r2_score(y4_test, svm4_pred))\n\nfig = plt.figure(figsize=(12, 6))\nplt.scatter(y3_test,svm3_pred,color='coral', linewidths=2, edgecolors='k')\nplt.xlabel('True GDP per Capita') \nplt.ylabel('Predictions') \nplt.title('Unoptimized SVM prediction Performance (with feature selection, and scaling)') \nplt.grid()\nplt.show()","cb551c45":"param_grid = {'C': [1, 10, 100], 'gamma': [0.01,0.001,0.0001], 'kernel': ['rbf']} \ngrid = GridSearchCV(SVR(),param_grid,refit=True,verbose=3)","0804bef2":"grid.fit(X4_train,y4_train)","cfde970c":"grid.best_params_","f7a24a8f":"grid.best_estimator_","0ec074bf":"grid_predictions = grid.predict(X4_test)","bf13bb32":"print(\"Optimized SVM Performance:\")\nprint('MAE:', metrics.mean_absolute_error(y4_test, grid_predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y4_test, grid_predictions)))\nprint('R2_Score: ', metrics.r2_score(y4_test, grid_predictions))\n\nfig = plt.figure(figsize=(12, 6))\nplt.scatter(y4_test,grid_predictions,color='coral', linewidths=2, edgecolors='k')\nplt.xlabel('True GDP per Capita') \nplt.ylabel('Predictions') \nplt.title('Optimized SVM prediction Performance (with feature selection, and scaling)') \nplt.grid()\nplt.show()","1c19cd87":"rf1 = RandomForestRegressor(random_state=101, n_estimators=200)\nrf3 = RandomForestRegressor(random_state=101, n_estimators=200)\n\nrf1.fit(X_train, y_train)\nrf3.fit(X3_train, y3_train)\nrf1_pred = rf1.predict(X_test)\nrf3_pred = rf3.predict(X3_test)","6875d39d":"print('Random Forest Performance:')\n\nprint('\\nall features, No scaling:')\nprint('MAE:', metrics.mean_absolute_error(y_test, rf1_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rf1_pred)))\nprint('R2_Score: ', metrics.r2_score(y_test, rf1_pred))\n\nprint('\\nselected features, No scaling:')\nprint('MAE:', metrics.mean_absolute_error(y3_test, rf3_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y3_test, rf3_pred)))\nprint('R2_Score: ', metrics.r2_score(y3_test, rf3_pred))\n\nfig = plt.figure(figsize=(12, 6))\nplt.scatter(y_test,rf1_pred,color='coral', linewidths=2, edgecolors='k')\nplt.xlabel('True GDP per Capita') \nplt.ylabel('Predictions') \nplt.title('Random Forest prediction Performance (No feature selection)') \nplt.grid()\nplt.show()","df7008bf":"rf_param_grid = {'max_features': ['sqrt', 'auto'],\n              'min_samples_leaf': [1, 3, 5],\n           # 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n                 'min_samples_split': [2, 5, 10],\n              'n_estimators': [100,500,1000],\n             'bootstrap': [False, True]}","00ceeb94":"rf_grid = GridSearchCV(estimator= RandomForestRegressor(), param_grid = rf_param_grid,  n_jobs=-1, verbose=0)","221064a8":"rf_grid.fit(X_train,y_train)","6fc31e75":"rf_grid.best_params_","2b6c7168":"rf_grid.best_estimator_","14f6425a":"rf_grid_predictions = rf_grid.predict(X_test)","e428f950":"print('Random Forest with optimization performance')\n\nprint('MAE:', metrics.mean_absolute_error(y_test, rf_grid_predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rf_grid_predictions)))\nprint('R2_Score: ', metrics.r2_score(y_test, rf_grid_predictions))\nfig = plt.figure(figsize=(12, 6))\nplt.scatter(y_test,rf_grid_predictions,color='coral', linewidths=2, edgecolors='k')\nplt.xlabel('True GDP per Capita') \nplt.ylabel('Predictions') \nplt.title('Optimized Random Forest prediction Performance (No feature selection)') \nplt.grid()\nplt.show()","09445a11":"gbm1 = GradientBoostingRegressor(learning_rate=0.1, n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_depth=3,\n                                 subsample=1.0, max_features= None, random_state=101)\ngbm3 = GradientBoostingRegressor(learning_rate=0.1, n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_depth=3,\n                                 subsample=1.0, max_features= None, random_state=101)\n\ngbm1.fit(X_train, y_train)\ngbm3.fit(X3_train, y3_train)\n\ngbm1_pred = gbm1.predict(X_test)\ngbm3_pred = gbm3.predict(X3_test)","6b976e96":"print('Gradient Boosting Performance:')\n\nprint('\\nall features, No scaling:')\nprint('MAE:', metrics.mean_absolute_error(y_test, gbm1_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, gbm1_pred)))\nprint('R2_Score: ', metrics.r2_score(y_test, gbm1_pred))\n\nprint('\\nselected features, No scaling:')\nprint('MAE:', metrics.mean_absolute_error(y3_test, gbm3_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y3_test, gbm3_pred)))\nprint('R2_Score: ', metrics.r2_score(y3_test, gbm3_pred))\n\nfig = plt.figure(figsize=(12, 6))\nplt.scatter(y_test,gbm1_pred,color='coral', linewidths=2, edgecolors='k')\nplt.xlabel('True GDP per Capita') \nplt.ylabel('Predictions') \nplt.title('Gradiant Boosting prediction Performance (No feature selection)') \nplt.grid()\nplt.show()","0eb955a5":"gbm_param_grid = {'learning_rate':[1,0.1, 0.01, 0.001], \n           'n_estimators':[100, 500, 1000],\n          'max_depth':[3, 5, 8],\n          'subsample':[0.7, 1], \n          'min_samples_leaf':[1, 20],\n          'min_samples_split':[10, 20],\n          'max_features':[4, 7]}\n\ngbm_tuning = GridSearchCV(estimator =GradientBoostingRegressor(random_state=101),\n                          param_grid = gbm_param_grid,\n                          n_jobs=-1,\n                          cv=5)\n\ngbm_tuning.fit(X_train,y_train)\nprint(gbm_tuning.best_params_)","5d126f97":"gbm_grid_predictions = gbm_tuning.predict(X_test)","2048d944":"print(\"Gradient Boosting with optimization performance\")\n\nprint('MAE:', metrics.mean_absolute_error(y_test, gbm_grid_predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, gbm_grid_predictions)))\nprint('R2_Score: ', metrics.r2_score(y_test, gbm_grid_predictions))\nfig = plt.figure(figsize=(12, 6))\nplt.scatter(y_test,gbm_grid_predictions,color='coral', linewidths=2, edgecolors='k')\nplt.xlabel('True GDP per Capita') \nplt.ylabel('Predictions') \nplt.title('Optimized Gradient Boosting prediction Performance') \nplt.grid()\nplt.show()","ac2eab60":"data = {'Linear Regression (all features, No scaling)':[330027.15, 1568861.27, -29787.03],\n        'Linear Regression (all features, with scaling)':[568426.40, 1281949.16, -19888.06],\n        'Linear Regression (selected features, No scaling)':[2948.38, 4109.82, 0.80],\n        'Linear Regression (selected features, with scaling)':[2854.65, 3760.87, 0.83],\n        'Ridge Regression':[2854.61, 3760.74, 0.83],\n       'Lasso Regression':[2852.57, 3784.96, 0.83],\n       'SVM Regression (all features, No scaling)':[7049.98, 9811.74, -0.17],\n       'SVM Regression (all features, with scaling)':[7042.73, 9800.41, -0.16],\n       'SVM Regression (selected features, No scaling)':[7047.71, 9807.98, -0.16],\n       'SVM Regression (selected features, with scaling)':[7040.05, 9794.57, -0.16],\n       'Optimized SVM':[6386.99, 9131.48, -0.0091],\n       'Random Forest (all features, No scaling)':[2127.80, 3065.70, 0.89],\n       'Random Forest (selected features, No scaling)':[2462.71, 3630.00,  0.84],\n       'Optimized Random Forest':[2329.73, 3180.77,  0.88],\n       'Gradiant Boosting (all features, No scaling)':[2093.38, 3124.43,   0.88],\n       'Gradiant Boosting (selected features, No scaling)':[2355.61, 3609.05,  0.84],\n       'Optimized Gradiant Boosting':[2334.88, 3391.41,  0.86]}\n\ndf = pd.DataFrame(data)\n\ndf.index = ['MAE', 'RMSE', 'R2_Score'] \n\nprint(df)","56cf1bbe":"df_MAE = df.sort_values(by =['MAE'], axis=1,ascending=False)\n\nprint(df_MAE)","a3de782e":"df_RMSE = df.sort_values(by =['RMSE'], axis=1,ascending=False)\n\nprint(df_RMSE)","16450ca1":"df_R2_Score = df.sort_values(by =['R2_Score'], axis=1)\n\nprint(df_R2_Score)","e92d36e1":"best_model = {\n        'Linear Regression':[2854.65, 3760.87, 0.83],\n        'Ridge Regression':[2854.61, 3760.74, 0.83],\n       'Lasso Regression':[2852.57, 3784.96, 0.83],\n       'Optimized SVM':[6386.99, 9131.48, -0.0091],\n       'Random Forest':[2127.80, 3065.70, 0.89],\n       'Gradiant Boosting':[2093.38, 3124.43,   0.88]}\n\ndf_best_model = pd.DataFrame(best_model)\n\ndf_best_model.index = ['MAE', 'RMSE', 'R2_Score'] \n\nprint(df_best_model)","d065a21b":"ax = df_best_model.iloc[0].plot.bar(rot=90)","204879ba":"ax = df_best_model.iloc[1].plot.bar(rot=90)","7a32ebd0":"ax = df_best_model.iloc[2].plot.bar(rot=90)","dbd27c00":"cool way to show joinplot too with kind = 'hex'. From the hex plot, it is very easy to see the concentrations at particular points of the graph.","90495510":"# Exploratory analysis","dc0889ed":"Observations:\n\nAs predicted, there is a downward trend where when GDP decreases, both Birthrate and death rate decreases. This trend is present in both the top 100 countries and the last 100 countries. However, there are anomalies such as Lesotho in the last 100 graph and Oman in the top 100 graph.","bed71d5e":"Showing number of null values as a percentage. From the data, we can see that 14 out of 20 columns have null values. The column with the largest null value is climate, with a null percentage of 9.69. However, the null percentage is still quite small (<10%).","eb21f3c7":"##### Analysis of missing data of gdp per capita column\nFinding out which country has a null value for gdp per capita. It turns out that its western sahara.","3dd1e211":"#### **Data Split 1: all of our final dataset, no scaling**","3258bfe6":"Observations:\n\nAs expected, western europe and northern america are the regions that have the highest GDP per capita and on the other hand, sub-saharan africa is the region that has the lowest GDP per capita. The average GDP per capita of western europe is slightly higher than northern america.","f7bcfec6":"Observations:\n\nAs expected, the top 100 countries have a very high service percentage (averaged at around 70%) and a very low agriculture percentage (averaged at around 3%) whereas the bottom 100 countries have a lower service percentage, in relation with the top 100 countries (averaged at around 43%) and a higher agriculture percentage (averaged at around 22%). However, it is interesting to note that service has the highest weightage amongst the 3 sectors in most of the last 100 countries and not agriculture.","ed0a4982":"## Model building\n\n### Linear Regression (Linear Model without Regularization)\n\nThis will be our baseline model.From our EDA, we can see that most features do not have a linear relationship with our labels (gdp_per_capita), yet we will try linear regression, and use the result as a reference (other methods should have better results).","ddc9e6ee":"Observations:\n\nThe optimization of Random Forest actually resulted in a fall in accuracy. ","33c83fb9":"checking to see that there are no null values","0d293bb0":"#### **Target variable analysis for linear regression analysis**","f8255f46":"#### Boxplot for distribution analysis of numerical features","16ae2476":"#### birthrate VS infant_mortality ","4c282d44":"I will be using the Countries of the World dataset from kaggle (link:https:\/\/www.kaggle.com\/fernandol\/countries-of-the-world)\n\nThe goal of this kaggle project is to understand the dataset, get some insights about it and finally train a model to predict GDP ($ per capita).","94478b56":"checking the new column names and data types","5bef6710":"Faroe Islands is located in western europe","9202b762":"There are 227 countries in this dataset.","28bfc7a0":"Observations: \n\nGradiant Boosting (all features, No scaling) performed the best for MAE while Random Forest (all features, No scaling) performed the best for RSME and R2_Score.\n\n**MAE vs RSME **\n\nCompared to MAE, RMSE does not treat each error the same. It gives more importance to the biggest errors. That means that one big error is enough to get a very bad RMSE.\n\nFor example:\nThe only difference is the forecast on the latest demand observation (period 12): forecast #1 undershot it by 7 units and forecast #2 by only 6 units.\n![0_Azpbrfj-oMhcITi-.jpeg](attachment:0_Azpbrfj-oMhcITi-.jpeg)\n\nIf we look at the KPI of these two forecasts, this is what we obtain:\n![0_qnnXGgsP3HMJwxlu.jpeg](attachment:0_qnnXGgsP3HMJwxlu.jpeg)\n\nWhat is interesting here is that by just changing the error of this last period by a single unit, we decrease the total RMSE by 6.9% (2.86 to 2.66) but MAE is only reduced by 3.6% (2.33 to 2.25), so the impact on MAE is nearly twice as low. Clearly RMSE puts much more importance on the biggest errors whereas MAE gives the same importance to each error.\n\nOverall, MAE provides protection against outliers whereas RMSE provides the assurance to get an unbiased forecast.","1d0631af":"To visualise rows (227 countries) in data that have missing data ","d5ab4173":"Observations:\n\nRandom forest performed better than linear regression. Random forest using all features performed significantly better than using selected features.","7d7340f3":"#### Sorting the different model's accuracy using MAE, RSME and R2_Score respectively. The least accurate model based on the particular accuracy indicator will be displayed first.","1c459534":"#### **Let's look at percentage of agriculture , industry and service of top 100 and last 100 countries interactively**","4b4417a2":"#### Analysis of missing data of climate column","10af3a63":"changing object type to float \/ category types","a8a0a796":"Observations:\n\nFrom the bar graph, it is derived that the importance of phones is almost 3 times more important than the next most important feature which is region_WESTERN EUROPE. The least important feature in X4 is region_ASIA (EX NEAR EAST) which makes sense due to the huge variation in GDP per Capita in the region. For example,Cambodia(1900), China(5000), Singapore(23700) and Japan(28200) are located all in the region with very huge varying levels of income. Therefore it is can be understandable that region_ASIA (EX. NEAR EAST) plays a small importance in determining GDP per Capita\/ unable to predict GDP per Capita. It would be good to use these observations into narrowing the features that will be use to determine GDP per Capita.","b8e7db09":"We will be trying out 4 different ways in which the data is split.","e4aeb4d2":"### Inputting missing data\nConclusion:\n\nHow I am going to handle the missing data:\n\nReplacing null value with mean vs median (if not already replaced by 0):\n\nObservations from box plot plotted earlier:\n\n* no outliers: birthrate, service\n* afew outliers(<5 outliers): phones, other, climate\n* significant number of outliers(>10 outliers, >= 5outliers): density, literacy, arable, agriculture, industry\n* alot of outliers(>=10 outliers): population, area, coastline_area_ratio, net_migration, crops, deathrate\n\nFor features that do not have any outliers, i will replace it with mean whereas I will replace the rest with median.\n\n1. Net Migration: there are 3 null values. I will replace the null values with 0.\n2. infant_mortality: there are 3 null values. I will replace the null values with 0.\n3. gdp_per_capita: there is 1 null value. The country with a null value for gdp per capita is western sahara. Using google search, the gdp per capita is $2500. I will replace the null value with 2500.\n4. literacy: there are 18 null values. I will replace the null values with the **median** literacy value of the country's region. \n5. phones: there are 4 null values. I will replace the null values with the **median** number of phones of the country's region.\n6. arable: there are 2 null values. I will replace the null values with 0.\n7. crops: there are 2 null values. I will replace the null values with 0.\n8. other: there are 2 null values. I will replace the null values with 0.\n9. climate: there are 22 null values. I will replace the null values with 0, where 0 represents that climate is unknown (is null).\n10. birthrate: there are 3 null values. I will replace the null values with the **mean** birthrate of the country's region.\n11. deathrate: there are 4 null values. I will replace the null values with the **median** deathrate of the country's region.\n12. agriculture, industry,service : Agriculture and service have 15 null values while industry has 16 null values. All belong to very small island nations. After inspection for similar nations, we found that those kind of nations usually have economies that rely heavily on services, with some agricultural and industrial activities. So we will replace the missing values with the following: agricultue = 0.15, industry = 0.05. service = 0.8. \n\n**Exception for western sahara where service already has a value of 0.4 and Monaco where agriculture already has a value of 0.17. For monaco, i will set the value for industry and service to be 0.05 and 0.78 respectively. For western sahara, i will set the value for agriculture and industry to be 0.35 and 0.25 respectively.","2c206ae1":"### Random Forest\n\n\nLet's first try random forest with our data splits (with and without feature selection). Scaling is not going to be tested for Random Forest, since it should not affect this algorithm's performance. Later we will try to improve its performance.","0ae9a4f0":"Observations:\n\nFrom the boxplots, it is derived that the median average GDP per capita is sligher hgiher for northern america than western europe. However, the interquartitle range and the range is alot larger for northern america than western europe. This may explained by the generous welfare system for countries in the european union which is funded through high tax rates on the rich.","8e08292b":"#### GDP per capita VS infant_mortality ","adc34941":"Observations:\n\nFeature scaling, and feature selection, made almost no difference in the prediction performance of the SVM algorithm.\nThe results of SVM is worse than that of Linear Regression, so we will try to improve SVM's performance by optimizing its parameters using grid search.","18f7f469":"MAE accuracy score (Taking into account that the gdp_per_capita values in the dataset ranges from 500 to 55100 USD.)","c119fa15":"#### **Data Split 4: feature selected dataset, with scaling**","7420c79e":"### GDP analysis","bbf1836c":"removing brackets and stuff in brackets of column names and also rephrasing to have shorter column names ","d7d3a075":"## Data cleaning","3e7fedf6":"#### Analysis of missing data of agriculture column","23c0d376":"Observations:\n\nSVM has improved a little with grid search, but it still performs below linear regression.","aa02f0c0":"#### **Let's look at industry and service features of top 7 countries (literacy)**","06c1fee1":"Observations:\n\nRidge Regression did slightly better than Lasso Regression. Both regressions did slightly better than normal linear regression.","46bcfd81":"#### **Data Split 3: feature selected dataset, no scaling**\n\nWe will select only a portion of our features, the ones with coreelation score larger than -\/+ 0.3 with gdp_per_capita.","d476cf7c":"#### Analysis of missing data of industry column","a744511f":"#### **Data Split 2: all of our final dataset, with scaling**","f446db16":"### Gradient Boosting optimization\n\nWe will use grid search in order to obtain good parameters for our GBM regressor. Of course our optimization here will be limited due to time and computing power constraints. The parameters we will optimiz are:\n* n-estimators: 100, 500, 1000\n* learning_rate: 0.001, 0.01, 0.1, 1\n* max_depth: 3, 5, 8\n* subsample = The fraction of observations to be selected for each tree. Selection is done by random sampling: 0.7, 1 (Values lower than 1 generally lead to a reduction of variance and an increase in bias)\n* min_samples_leaf: 1, 20\n* min_samples_split: 0.5-1% of our data --> we have 227 datapoints --> 10 -20\n* max_features: 4, 7 (sqrt of number of features is a good guess)\n\nThe parameters are self explanatory and some have already been discussed previously in the parameters for random forest. ","e46eaff5":"Observations:\n\n* no outliers: birthrate, service\n* afew outliers(<5 outliers): phones, other, climate\n* significant number of outliers(>10 outliers, >= 5outliers): density, literacy, arable, agriculture, industry\n* alot of outliers(>=10 outliers): population, area, coastline_area_ratio, net_migration, crops, deathrate","5f0f12a8":"Observations:\n\nstrong correaltion (>0.7)\n* there is a strong positive correlation between gdp per capita and phones (0.83)\n* there is a strong positive correlation between infant mortality and birthrate (0.84)\n* there is a strong nagative correaltion between literacy and birthrate (-0.78)\n* there is a strong negative correlation between literacy and infant motality (-0.75)\n* there is a strong negative correaltion between birthrate and phones (-0.72)\n* there is a strong negative correaltion between other and arable (-0.73)","2bf09170":"### Optimizing SVM","e0aeac82":"RSME accuracy score ((Taking into account that the gdp_per_capita values in the dataset ranges from 500 to 55100 USD.)","a79a5523":"Observation:\n\nFrom the joinplot graph, it is clear that the higher the literacy rate, the higher likelihood that the gdp per capita is higher. But it is also good to note that there are many countries with a high literacy rate but has a low gdp per capita, but there is no country that has a low literacy rate but have a high gdp per capita.","72de58d5":"Observations:\n\nGradient Boosting has a high accuracy even without optimization. Similar to Random Forest Gradient Boosting with all features has a higher accuracy compared to using selected features. The accuracy of Gradient Boosting is very close to that of Random Forest.","60d50119":"## Dataset Information","bd2015bb":"### SVM","ba63fdcb":"### Regional analysis","3474d748":"\nOptimization\n\nRefer to \n\nhttps:\/\/towardsdatascience.com\/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n\nuseful tutorial on parameters to use to optimise random forest\n\nWe will use grid search in order to obtain good parameters for our RF regressor. Of course our optimization here will be limited due to time and computing power constraints. The parameters we will optimize are:\n\n* max_features = max number of features considered for splitting a node : ['sqrt', 'auto'],\n* min_samples_leaf = min number of data points allowed in a leaf node : [1, 3, 5]\n* max_depth = max number of levels in each decision tree (left it out because it takes too long to run)\n* min_samples_split = min number of data points placed in a node before the node is split : [2, 5, 10]\n* n-estimators = number of trees in the foreset : [100,500,1000]\n* bootstrap = method for sampling data points (with or without replacement) : [False, True]","bd4ce7b8":"#### Histogram for distribution analysis of numerical features","8a055930":"As predicted, y4 which uses both feature selection and scaling has the highest R^2 score. We will set R^2 score = 0.83 as the benchmark that will be compared when building other models.\n\nSince y4 has the highest R2 score, we will plot its predicted against its actual values. ","214e644e":"### Distribution of dataset","633d1e8d":"#### Analysis of missing data of phone column","3430f911":"## Data Preconditioning\n\nIn this section we will make our data ready for model training. This will include:\n1. Transform 'region' column into numerical values.\n2. Split data set into training and testing parts (80\/20), while dropping the countries column (string, and not going to be used to train the models), and separating gdp_per_capita column, where it will be used as labels.\n3. We will try different splits of our dataset (with\/without feature selection, with\/without feature scaling.","18f66339":"Similar to random forest, gradient boosting also performed worse with optimization (R2_Score: 0.861) as compared to no optimization (R2_Score: 0.882). This is probably also due to the small dataset that we have (227 countries). The accuracy will probably be higher if there is a larger dataset to train on.","dfa1fe5e":"Observations:\n\nThe graph is pretty decent as there is some sort of linearity with the points that are plotted. However, it is clear that this can be improved.\n","8cc088dd":"### Conclusion:\n\nIn this project, we used countries_of_the_world dataset to predict GDP per Capita. We used 6 different learning regressors (Linear Regression, L1 and L2 regularization, SVM, Random Forest, and Gradiant Boosting) were tested.\n\nDepending on the accuracy indicator, Random Forest and Gradient Boosting performed the best while SVM acheived the worst performance of the 4.\n\nThe best prediction performance was acheived using \n\n1) Random Forest regressor, using all features in the dataset, and resulted in the following metrics:\n\n* Mean Absolute Error (MAE): 2127.80\n* Root mean squared error (RMSE): 3065.70\n* R-squared Score (R2_Score): 0.89\n\n2) Gradient Boosting regressor, using all features in the dataset,\n\n* Mean Absolute Error (MAE): 2093.38\n* Root mean squared error (RMSE): 3124.44\n* R-squared Score (R2_Score): 0.88\n\nTaking into account that the gdp_per_capita values in the dataset ranges from 500 to 55100 USD.","6ab16bf5":"#### Boxplot for distribution analysis of region (categorical data) with GDP per Capita","22389086":"#### **Let's look at the birthrate and deathrate of top 100 countries and last 100 countries interactively.**","8a97c7b2":"## Feature Engineering\n### Handling missing data","5a6b37b8":"### Region transform","d2552943":"### Gradient Boosting","b40d10a3":"### Correlation heatmap","71148bab":"Details of the dataset:\n\n* Country\n* Region\n* Population\n* Area\n* Pop. Density (per sq. mi.)\n* Coastline (coast\/area ratio)\n\n* Net migration\n* Infant mortality (per 1000 births)\t\n* GDP ($ per capita)\t\n* Literacy (%)\t\n* Phones (per 1000)\t\n* Arable (%)\t\n* Crops (%)\t\n* Other (%)\t\n* Climate\t\n* Birthrate\t\n* Deathrate\t\n* Agriculture\t\n* Industry\t\n* Service\n","5e1c70bf":"#### **Let's look at agriculture and service features of top 7 countries (literacy)**","120617dd":"### Using Statsmodel to interpretate feature importance\nrefer to: [https:\/\/datatofish.com\/statsmodels-linear-regression\/](http:\/\/) \n\nIt is a very useful tutorial to learn about the usage of statemodel in linear regression.","22a10d5b":"Observations:\n* Sub-Saharian Africa and Latin America regions have the most countries within them, with 52 and 45 respectively.\n* Western Europe and North America have the highest GDP per capita, while Sub-Saharian Africa has the lowest GDP per capita.\n* Western Europe, Near east, Asia and  are the main regions where migrants from other regions go.\n* Asia has the largest population, Oceania has the smallest.","57774e54":"I will first look at the dataset again to gain a brief understanding of the common values in the dataset.","d5469cb0":"#### GDP per capita VS phones\n\nSince GDP per capita and phones have a strong positive correlation as shown in the correlation heatmap, I want to see the relationship when plotted on a joinplot.","a9d548a6":"#### GDP per capita VS Literacy","cc507e73":"### Missing data","f46c3710":"Observations:\n* Our target variable, GDP per Capita is not normally distributed.\n* Our target variable is right-skewed.\n* There are 2 outliers in the variable\n\nTherefore, normalisation will be applied.","ae5fd5f3":"R2_score","415e6043":"### Regression \n\nRidge Regression:\n* Performs L2 regularization, i.e. adds penalty equivalent to square of the magnitude of coefficients\n* Minimization objective = LS Obj + \u03b1 * (sum of square of coefficients)\n\nLasso Regression:\n* Performs L1 regularization, i.e. adds penalty equivalent to absolute value of the magnitude of coefficients\n* Minimization objective = LS Obj + \u03b1 * (sum of absolute value of coefficients)\n\n3 main ways of regression:\n* Ridge Regression, which penalizes sum of squared coefficients (L2 penalty).\n* Lasso Regression, which penalizes the sum of absolute values of the coefficients (L1 penalty).\n* Elastic Net, a convex combination of Ridge and Lasso.","4963ec89":"Observations:\n\nAdjusted. R-squared reflects the fit of the model. R-squared values range from 0 to 1, where a higher value generally indicates a better fit, assuming certain conditions are met. The linear regression model has an Adjusted. R-squared of 0.354 which is not good.","f1784168":"#### Analysis of missing data of literacy column"}}