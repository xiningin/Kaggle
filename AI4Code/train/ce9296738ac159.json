{"cell_type":{"a3a433b6":"code","79069e2f":"code","555eb4d4":"code","a4581415":"code","ccbedc3e":"code","b36d4b71":"code","3902a20a":"code","2a8b4e81":"code","b1744791":"code","32af5872":"code","f7b44ffa":"code","2cb18943":"code","d742ac41":"code","b49f803b":"code","827c5a6e":"code","bf885a2a":"code","5f38b927":"code","ea8088a5":"code","fbb50d0b":"code","577d4670":"code","0bdcce30":"code","5d0021af":"code","9c125876":"code","00e5b748":"code","a4814bc1":"code","4b919507":"code","c56ebdb5":"code","3f6c99f1":"code","bc45cd0e":"code","aa34e8a7":"markdown","02f51c58":"markdown","9ee2de85":"markdown","a2a34ea9":"markdown","b70c6953":"markdown","1af4ad60":"markdown","5e3b3b46":"markdown","74388eff":"markdown","251300cc":"markdown","95aefd49":"markdown","95c7ea2b":"markdown","ea513fa6":"markdown","1bf1e4d0":"markdown"},"source":{"a3a433b6":"# Importing essential libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\nimport plotly.graph_objects as go\n# Importing libraries for performing Natural Language Processing on 'Restaurant_Reviews.tsv' dataset\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer \n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings \nwarnings.filterwarnings('ignore')","79069e2f":"# Loading the dataset\ndf = pd.read_csv('..\/input\/reviews\/Restaurant_Reviews.tsv', delimiter='\\t', quoting=3)","555eb4d4":"# Lets check the first five rows of data\ndf.head()","a4581415":"# Shape\ndf.shape","ccbedc3e":"df['Liked'].value_counts()","b36d4b71":"Labels = pd.DataFrame(df['Liked'].value_counts()).reset_index()\nLabels.columns = ['Liked','Count']\nLabels['Liked'] = Labels['Liked'].map({0: 'Negative',1: 'Positive'})\n\nfig = px.pie(Labels, values = 'Count', names = 'Liked', title='Percentage of reviews', hole=.4, color = 'Liked',\n             width=800, height=400)\nfig.show()","3902a20a":"positive_reviews = df[df[\"Liked\"] == 1]","2a8b4e81":"plt.subplots(figsize=(16,13))\nwordcloud = WordCloud(\n                          background_color='black',max_words = 10000,\n                          width=1500, stopwords=STOPWORDS,\n                          height=1080\n                         ).generate(\" \".join(positive_reviews.Review))\nplt.title(\"Positive Reviews\", fontsize=20)\nplt.imshow(wordcloud.recolor( colormap= 'viridis'))\nplt.axis('off')\nplt.show()","b1744791":"negative_reviews = df[df[\"Liked\"] == 0]","32af5872":"plt.subplots(figsize=(16,13))\nwordcloud = WordCloud(\n                          background_color='black',max_words = 10000,\n                          width=1500, stopwords=STOPWORDS,\n                          height=1080\n                         ).generate(\" \".join(negative_reviews.Review))\nplt.title(\"Negative Reviews\", fontsize=20)\nplt.imshow(wordcloud.recolor( colormap= 'viridis'))\nplt.axis('off')\nplt.show()","f7b44ffa":"# Here we get the length of each review\ndf['Length']= df['Review'].apply(len) \ndf.head()","2cb18943":"# Cleaning the reviews\ncorpus = []\nfor i in range(0,len(df)):\n    \n\n    # Cleaning special character from the reviews\n    review = re.sub(pattern='[^a-zA-Z]',repl=' ', string=df['Review'][i])\n\n    # Converting the entire review into lower case\n    review = review.lower()\n\n    # Tokenizing the review by words\n    review_words = review.split()\n\n    # Removing the stop words\n    review_words = [word for word in review_words if not word in set(stopwords.words('english'))]\n\n    # Stemming the words\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review_words]\n\n    # Joining the stemmed words\n    review = ' '.join(review)\n\n    # Creating a corpus\n    corpus.append(review)","d742ac41":"# lets check the corpus\ncorpus[0:5]","b49f803b":"# Creating the Bag of Words model\ncv = CountVectorizer(max_features=1500)\nX = cv.fit_transform(corpus).toarray()\ny = df.loc[:, 'Liked'].values","827c5a6e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)","bf885a2a":"# Model building function\ndef Model(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    return model,accuracy","5f38b927":"result = pd.DataFrame(columns = [\"Model\", \"Accuracy\"])\n\nmodels = [DecisionTreeClassifier(), LogisticRegression(), RandomForestClassifier(n_estimators=1000),\n                      KNeighborsClassifier(n_neighbors = 7, metric = \"minkowski\", p = 2),\n                      SVC(kernel = 'rbf'), GaussianNB(), XGBClassifier(n_estimators=300, learning_rate=0.01)]\n\nfor model in models:\n    clf, accuracy = Model(model)\n    result = result.append({\"Model\": model, \"Accuracy\": accuracy}, ignore_index=True)\n\nresult","ea8088a5":"# Fitting svm to the Training set\nclassifier = SVC(kernel = 'rbf')\nclassifier.fit(X_train, y_train)","fbb50d0b":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)","577d4670":"# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm,annot=True)\nplt.show()","0bdcce30":"# Create a dictionary called param_grid and fill out some parameters for kernels, C and gamma\nparam_grid = {'C': [0.1,1, 10, 100], \n              'gamma': [1,0.1,0.01,0.001],\n              'kernel': ['rbf', 'poly', 'sigmoid']}\n\n# Create a GridSearchCV object and fit it to the training data\ngrid = GridSearchCV(SVC(),param_grid,refit=True)\ngrid.fit(X_train,y_train)","5d0021af":"# Find the optimal parameters\nprint(grid.best_estimator_)","9c125876":"# Find the best score\nprint(grid.best_score_)","00e5b748":"pred = grid.predict(X_test)\n# Making the Confusion Matrix\ncm1 = confusion_matrix(y_test, pred)\nsns.heatmap(cm1,annot=True)\nplt.show()","a4814bc1":"# Helper Function for prediction\ndef predict_sentiment(sample_review):\n    sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ', string = sample_review)\n    sample_review = sample_review.lower()\n    sample_review_words = sample_review.split()\n    sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]\n    ps = PorterStemmer()\n    final_review = [ps.stem(word) for word in sample_review_words]\n    final_review = ' '.join(final_review)\n\n    temp = cv.transform([final_review]).toarray()\n    return grid.predict(temp)","4b919507":"# Predicting values\nsample_review = 'The food is really good here.'\n\nif predict_sentiment(sample_review):\n    print('This is a POSITIVE review.')\nelse:\n    print('This is a NEGATIVE review!')","c56ebdb5":"# Predicting values\nsample_review = 'Food was pretty bad and the service was very slow.'\n\nif predict_sentiment(sample_review):\n    print('This is a POSITIVE review.')\nelse:\n    print('This is a NEGATIVE review!')","3f6c99f1":"# Predicting values\nsample_review = 'The food was absolutely wonderful, from preparation to presentation, very pleasing.'\n\nif predict_sentiment(sample_review):\n    print('This is a POSITIVE review.')\nelse:\n    print('This is a NEGATIVE review!')","bc45cd0e":"# Predicting values\nsample_review = 'The food was disastrous.'\n\nif predict_sentiment(sample_review):\n    print('This is a POSITIVE review.')\nelse:\n    print('This is a NEGATIVE review!')","aa34e8a7":"### **EDA**","02f51c58":"**Logistic Regression and SVM performed better here.**","9ee2de85":"#### Let's see the most used words in positive reviews!","a2a34ea9":"### **Importing Required Libraries**","b70c6953":"### Tuning the hyper-parameters of SVM","1af4ad60":"### **Prediction**","5e3b3b46":"### **Model Building**","74388eff":"#### Now Let's see the most used words in negative reviews!","251300cc":"**Train-Test Split**","95aefd49":"### **Data Preprocessing**","95c7ea2b":"### **Loading the Dataset**","ea513fa6":"**data is equally distributed between liked and disliked**","1bf1e4d0":"### **Bag of Words**"}}