{"cell_type":{"ffa2944c":"code","5bc72ec2":"code","f706d702":"code","c6e8f987":"code","55e5a641":"code","8d423bf8":"code","e12eb976":"code","4944c9c0":"code","b8fc1578":"code","62aac971":"code","cb2f7e66":"code","0ae64d85":"code","6fef7e43":"code","16a48da0":"code","48e1461b":"code","b37ed844":"code","af5f0ca0":"code","fc4b4479":"code","96550c37":"code","bb11d87c":"code","35f56afb":"code","c906839d":"code","ef484824":"code","a4875f18":"code","85a52356":"code","fb768283":"code","42cc2a98":"markdown","ad266a0d":"markdown","18f63150":"markdown","4c0c2a9d":"markdown","55aebea5":"markdown","b3e5d84e":"markdown","666e432b":"markdown","157dbb43":"markdown","bf61d073":"markdown","a9785f22":"markdown","7df69f24":"markdown","015f2dd3":"markdown","ba2397e4":"markdown","639f2fd4":"markdown","aa20a5b9":"markdown","bd0d06b7":"markdown","901d0274":"markdown","7c18d46d":"markdown","9a9adf3b":"markdown","9fe3ab69":"markdown","11d9c58f":"markdown","2ff62148":"markdown","66a35900":"markdown","c3717826":"markdown","4c7c82ad":"markdown","316b4867":"markdown","2cd2f053":"markdown"},"source":{"ffa2944c":"import numpy as np \nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport tensorflow as tf","5bc72ec2":"dataframe = pd.read_csv('\/kaggle\/input\/iba-ml1-final-project\/train.csv')\ndataframe.drop([\"Id\"], axis = 1, inplace = True)\ndataframe","f706d702":"#dataframe_extra = pd.read_csv('\/kaggle\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')\n#dataframe_extra.drop(['Unnamed: 0', 'Clothing ID'], axis = 1, inplace = True)\n#dataframe_extra = dataframe_extra.rename(columns={'Title': 'Review_Title',\n#                                                  'Review Text': 'Review',\n#                                                  'Recommended IND':'Recommended',\n#                                                  'Positive Feedback Count':'Pos_Feedback_Cnt',\n#                                                  'Division Name':'Division',\n#                                                  'Department Name':'Department',\n#                                                  'Class Name':'Product_Category'})\n#dataframe = dataframe.append(dataframe_extra).reset_index().drop(\"index\",axis=1)","c6e8f987":"one_hot_Rating = pd.get_dummies(dataframe.Rating,prefix=\"Rating\")\ndataframe = dataframe.drop('Rating',axis = 1)\ndataframe = dataframe.join(one_hot_Rating)\ndataframe","55e5a641":"dataframe.drop(dataframe[dataframe.Review_Title.isnull() & dataframe.Review.isnull()].index, inplace = True)\ndataframe = dataframe.reset_index().drop('index',axis =1)\ndataframe","8d423bf8":"from nltk.corpus import wordnet\n\ndef get_pos(word):\n    tag = nltk.pos_tag([word])[0][1][0]\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n    element = tag_dict.get(tag)\n    if(element == \"J\" or element==\"N\" or element==\"V\" or element==\"R\"):\n        return element\n    return 'n' #it is just like for not getting the error, we pass 'n' if the pos tag couldn't found or is not in the dictionary.","e12eb976":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\n\ndataframe['Review_Title'] = dataframe['Review_Title'].fillna('None')\ndataframe['Review'] = dataframe['Review'].fillna('None')\npd.set_option('mode.chained_assignment', None)\ndataframe.Review = dataframe.Review.str.lower()\ndataframe.Review_Title = dataframe.Review_Title.str.lower()\nfor i in range(0,len(dataframe)):\n    review = re.sub('[^a-zA-z]', ' ', dataframe['Review'][i])\n    review = review.split()\n    wl = WordNetLemmatizer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')    \n    review = [wl.lemmatize(word, pos = get_pos(word)) for word in review if word not in set(all_stopwords)]\n    review = ' '.join(review)\n    dataframe['Review'][i] = review\n    \n    review_title = re.sub('[^a-zA-z]', ' ', dataframe['Review_Title'][i])\n    review_title = review_title.split()\n    review_title = [wl.lemmatize(word, pos = get_pos(word)) for word in review_title if word not in set(all_stopwords)]\n    review_title = ' '.join(review_title)\n    dataframe['Review_Title'][i] = review_title","4944c9c0":"dataframe[['Review_Title','Review']]","b8fc1578":"from sklearn.model_selection import train_test_split\nX_dataframe = dataframe.iloc[:,:-6]\ny_dataframe = dataframe.iloc[:,-6:]\n\nX_train, X_test, y_train, y_test = train_test_split(X_dataframe,y_dataframe, stratify = y_dataframe.Recommended)","62aac971":"X_train_review_title_input = X_train[['Review_Title']]\nX_train_review_input = X_train[['Review']]\nX_train_other_input = X_train[['Age','Pos_Feedback_Cnt','Division','Department','Product_Category']]\n\nX_test_review_title_input = X_test[['Review_Title']]\nX_test_review_input = X_test[['Review']]\nX_test_other_input = X_test[['Age','Pos_Feedback_Cnt','Division','Department','Product_Category']]\n\ny_train_rating_output = y_train[['Rating_1','Rating_2','Rating_3','Rating_4','Rating_5']]\ny_train_recommended_output = y_train[['Recommended']]\n\n\ny_test_rating_output = y_test[['Rating_1','Rating_2','Rating_3','Rating_4','Rating_5']]\ny_test_recommended_output = y_test[['Recommended']]","cb2f7e66":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.compose import ColumnTransformer\n\n\nprep_other_pipe = Pipeline(steps=[\n    ('preprocessing',ColumnTransformer(transformers=[\n        ('numeric', Pipeline(steps=[\n           ('impute', SimpleImputer(strategy='mean')),\n            ('scaler', RobustScaler())\n        ]), ['Age']),\n        ('categorical', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='most_frequent')),\n            ('one_hot_encoding', OneHotEncoder(handle_unknown = 'ignore', sparse = False))\n        ]), ['Pos_Feedback_Cnt','Division','Department','Product_Category'])\n    ]))\n])\nX_train_other_input = prep_other_pipe.fit_transform(X_train_other_input)\nX_test_other_input = prep_other_pipe.transform(X_test_other_input)","0ae64d85":"X_train_other_input","6fef7e43":"Vocab_Size_Review_Title = 5000\nencoder_RTitle = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=Vocab_Size_Review_Title)\nencoder_RTitle.adapt(np.array(X_train_review_title_input))\n#encoder_RTitle.get_vocabulary()","16a48da0":"Vocab_Size_Review = 10000\nencoder_Review = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=Vocab_Size_Review)\nencoder_Review.adapt(np.array(X_train_review_input))\n#encoder_Review.get_vocabulary()","48e1461b":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ninput_review_title = keras.Input(shape=(None,), name=\"review_title\")\ninput_review = keras.Input(shape=(None,), name=\"review\")\ninput_other_columns = keras.Input(shape=(X_train_other_input.shape[1],), name=\"other_columns\")\n\nembedding_review_title = layers.Embedding(len(encoder_RTitle.get_vocabulary()),500)(input_review_title)\nembedding_review = layers.Embedding(len(encoder_Review.get_vocabulary()),500)(input_review)\n\nlstm_review_title = layers.LSTM(16,name = 'lstm_review_title')(embedding_review_title)\nlstm_review = layers.LSTM(32,name = 'lstm_review')(embedding_review)\ndense_other_columns = layers.Dense(2, name='dense_other_columns')(input_other_columns)\n\nconcat_layer = layers.concatenate([lstm_review_title,lstm_review,dense_other_columns])\n\nrating_pred = layers.Dense(5,activation ='softmax',name=\"rating\")(concat_layer)\nrecommended_pred = layers.Dense(1,activation ='sigmoid',name=\"recommended\")(concat_layer)\n\nmodel = keras.Model(\n    inputs=[input_review_title, input_review,input_other_columns],\n    outputs=[rating_pred, recommended_pred],\n)","b37ed844":"keras.utils.plot_model(model,show_shapes=True)","af5f0ca0":"model.compile(optimizer='adam', loss = {\"rating\": \"categorical_crossentropy\",\n                                        \"recommended\": \"binary_crossentropy\"},\n                                metrics={'rating': 'accuracy', \n                                         'recommended': 'accuracy'})","fc4b4479":"callback_loss = tf.keras.callbacks.EarlyStopping(monitor='loss',patience = 5)\ncallback_accuracy = tf.keras.callbacks.EarlyStopping(monitor='val_rating_accuracy', patience = 3)\nhistory = model.fit({\"review_title\": encoder_RTitle(X_train_review_title_input),\n                     \"review\": encoder_Review(X_train_review_input),\n                     \"other_columns\": X_train_other_input}, \n                    {\"rating\": y_train_rating_output,\n                     \"recommended\":y_train_recommended_output}, \n                    epochs=30,batch_size=128, verbose=0, \n                    validation_data = ({\"review_title\": encoder_RTitle(X_test_review_title_input),\n                                        \"review\": encoder_Review(X_test_review_input),\n                                        \"other_columns\": X_test_other_input},\n                                         {\"rating\": y_test_rating_output,\n                                           \"recommended\":y_test_recommended_output}),\n                   callbacks=[callback_loss, callback_accuracy])","96550c37":"import matplotlib.pyplot as plt\nprint(history.history.keys())\n\nfig, axs = plt.subplots(2, 2, figsize = (20,10))\naxs[0, 0].plot(history.history['rating_loss'])\naxs[0, 0].set_title('rating_loss')\naxs[0, 1].plot(history.history['recommended_loss'], 'tab:orange')\naxs[0, 1].set_title('recommended_loss]')\naxs[1, 0].plot(history.history['val_rating_loss'], 'tab:green')\naxs[1, 0].set_title('val_rating_loss')\naxs[1, 1].plot(history.history['val_recommended_loss'], 'tab:red')\naxs[1, 1].set_title('val_recommended_loss')","bb11d87c":"test_dataframe = pd.read_csv('\/kaggle\/input\/iba-ml1-final-project\/test.csv')\ntest_dataframe_Id = test_dataframe[\"Id\"]\ntest_dataframe.drop([\"Id\"], axis = 1, inplace = True)\ntest_dataframe","35f56afb":"test_dataframe['Review_Title'] = test_dataframe['Review_Title'].fillna('None')\ntest_dataframe['Review'] = test_dataframe['Review'].fillna('None')\n#Now\ntest_dataframe.Review = test_dataframe.Review.str.lower()\ntest_dataframe.Review_Title = test_dataframe.Review_Title.str.lower()\nfor i in range(0,len(test_dataframe)):\n    review = re.sub('[^a-zA-z]', ' ', test_dataframe['Review'][i])\n    review = review.split()\n    wl = WordNetLemmatizer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')    \n    review = [wl.lemmatize(word, pos = get_pos(word)) for word in review if word not in set(all_stopwords)]\n    review = ' '.join(review)\n    test_dataframe['Review'][i] = review\n    \n    review_title = re.sub('[^a-zA-z]', ' ', test_dataframe['Review_Title'][i])\n    review_title = review_title.split()\n    review_title = [wl.lemmatize(word, pos = get_pos(word)) for word in review_title if word not in set(all_stopwords)]\n    review_title = ' '.join(review_title)\n    test_dataframe['Review_Title'][i] = review_title","c906839d":"test_df_review_title_input = test_dataframe[['Review_Title']]\ntest_df_review_input = test_dataframe[['Review']]\ntest_df_other_input = test_dataframe[['Age','Pos_Feedback_Cnt','Division','Department','Product_Category']]","ef484824":"test_df_other_input = prep_other_pipe.transform(test_df_other_input)","a4875f18":"test_pred = model.predict({\"review_title\": encoder_RTitle(test_df_review_title_input),\n                           \"review\": encoder_Review(test_df_review_input),\n                           \"other_columns\": test_df_other_input})","85a52356":"rating_answer = np.argmax(np.array(test_pred[0]),axis=1)+1\nrecom_answer = (test_pred[1] > 0.5).astype(int).flatten()","fb768283":"df_answer = pd.DataFrame({\"Id\":test_dataframe_Id,\n                          \"Rating\":rating_answer,\n                          \"Recommended\": recom_answer})\ndf_answer","42cc2a98":"Here we just read our dataframe and delete the first column which is useless in training phase","ad266a0d":"# Model","18f63150":"We will use adam optimizer, and as a loss functions we will use categorical_crossentropy for rating and binary_crossentropy for recommended. And as a metric we will use accuracy score for both of them","4c0c2a9d":"Let's put them to the pandas dataframe with proper columns","55aebea5":"Here we write our new function which just converts the pos_tag which nltk found for the word to wordnet pos_tag. We will need it for lemmatization.","b3e5d84e":"## Applying to the test set","666e432b":"# Interpretation","157dbb43":"When training the model you can see that the overfitting happening easily, it is because we have little data for the NLP task, and we know that one of the best ways of dealing against overfitting is adding the new data to our dataframe. That is why I have added new data, basically united two dataframe (our competition data, and another data which available in Kaggle). After training the model with this united dataframe, the model gives very very good results.","bf61d073":"Let's split our data to train test split","a9785f22":"Now let's predict our model","7df69f24":"Seperate columns for input","015f2dd3":"Now let's create our model. As I said, we will use function api for it.","ba2397e4":"Applying the same NLP techniques","639f2fd4":"Basically in this cell we read that dataframe, change appropriate columns and append it to our main dataframe.However due to new requirement,  this cell was commented, and it will not used in model fitting","aa20a5b9":"In these following 5 columns, we will do the same EDA processes for our test set","bd0d06b7":"# EDA","901d0274":"Here we just one hot encode the Rating target value with using get_dummies method in pandas.","7c18d46d":"Now let's do some preprocessing steps for the other columns train input. For it, we will create a pipeline and do some appropriate steps (scaling, imputing) for numerical and categorical columns.","9a9adf3b":"Let's find and drop the records which do not have both Review and Review title, because if both of them are null at the same time, there is no way that we can know what is our target values","9fe3ab69":"Transform them (imputing, scaling) with using the same object of main dataframe","11d9c58f":"Let's visualize our model","2ff62148":"Now let's Vectorize our Review and Review_Title columns. I will use 500  Vocabulary size for Review Title and 10000 Vocabulary size for Review","66a35900":"We will have two callback, one for loss and other for validation rating accuracy with patience 3. And for fitting the mmodel we will have 25 epoch with batch size 32","c3717826":"In this cell, First we filling missin values with None, and then we apply the classical NLP techniques to the Review and Review_Title columns. First we make all of them lower string, later we remove the stop words, and then lemmatize the review or review_title.","4c7c82ad":"Importing main libraries","316b4867":"Change the probabilities to appropriate numbers.","2cd2f053":"We will use functional API for that problem, that is why we wil have 3 different input, and two output. For inputs one for the Review_Title, another for Review, and the last one for other columns. And for outputs one for Recommended and the other for Review"}}