{"cell_type":{"020e2ee8":"code","e7a9501c":"code","b70f3e29":"code","56867852":"code","3ed29646":"code","98968b5a":"code","2c876b4b":"code","fa8e9dd2":"code","98739f57":"code","d265ab74":"code","709b6873":"code","ca966d51":"code","f8425109":"code","0ae3595e":"code","4511fe48":"code","57f95df4":"code","268642c1":"code","d754c28f":"code","bdf96ed1":"code","9f5d5a83":"markdown","c205f656":"markdown","71c29e4a":"markdown","7b933896":"markdown","426f0ff6":"markdown","5d1994fc":"markdown","6e1703ec":"markdown","639dade3":"markdown","b70d9f15":"markdown","ed155c39":"markdown","d4a10265":"markdown","21d854e3":"markdown","6f8f486a":"markdown","3e104fa8":"markdown","288b168a":"markdown","3da89b67":"markdown"},"source":{"020e2ee8":"os.listdir('..\/input\/resnet50')","e7a9501c":"import os\nimport pandas as pd\nimport numpy as np\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img\nimport datetime\nimport sys\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten,Dropout,MaxPool2D\nfrom keras.applications import ResNet50\nfrom keras import optimizers\nimport math","b70f3e29":"base_model = ResNet50(weights='..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                      include_top=False, input_shape=(224, 224, 3))\nmodel=Sequential()\nmodel.add(base_model)\n# Freeze the layers except the last 4 layers\nmodel.add(Dropout(0.40))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation='softmax'))\n\n","56867852":"model.summary()","3ed29646":"df=pd.read_csv('..\/input\/mnist1000-with-one-image-folder\/HAM10000_metadata.csv')\ndf['file_name']=df['image_id']+'.jpg'\ndf=df[['file_name','dx','lesion_id']]\ndf.head()\n","98968b5a":"from sklearn.model_selection import train_test_split\nlabel_dataframe=df.pop('dx').to_frame()\nX_train, X_test, y_train, y_test = train_test_split(df, label_dataframe, test_size=0.2, random_state=42)\nX_train,X_val,y_train,y_val=train_test_split(X_train, y_train, test_size=0.25, random_state=42)\nprint(X_val.shape)\nprint(X_train.shape)\nprint(X_test.shape)\n","2c876b4b":"train=pd.concat([X_train,y_train],axis=1)\ntrain.head()\nval=pd.concat([X_val,y_val],axis=1)\nval.head()\ntest=pd.concat([X_test,y_test],axis=1)\ntest.head()\n","fa8e9dd2":"from sklearn import preprocessing\nvle = preprocessing.LabelEncoder()\nvle.fit(val['dx'])\nlabel=vle.transform(val['dx']) \nprint(list(vle.classes_))\nval['label']=label\nprint(train.head())\nle_name_mapping = dict(zip(vle.classes_, vle.transform(vle.classes_)))\nprint(le_name_mapping)","98739f57":"trle = preprocessing.LabelEncoder()\ntrle.fit(train['dx'])\nlabel=trle.transform(train['dx']) \nprint(list(trle.classes_))\ntrain['label']=label\nprint(train.head())\nle_name_mapping = dict(zip(trle.classes_, trle.transform(trle.classes_)))\nprint(le_name_mapping)\n","d265ab74":"le = preprocessing.LabelEncoder()\nle.fit(test['dx'])\nlabel=le.transform(test['dx']) \nprint(list(le.classes_))\ntest['label']=label\nprint(test.head())\nle_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_name_mapping)","709b6873":"train_generator = ImageDataGenerator(\nrescale = 1.\/255,\nfeaturewise_center=False,  # set input mean to 0 over the dataset\nsamplewise_center=False,  # set each sample mean to 0\nfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\nsamplewise_std_normalization=False,  # divide each input by its std\nzca_whitening=False,  # apply ZCA whitening\nrotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\nzoom_range = 0.1, # Randomly zoom image \nwidth_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\nheight_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\nhorizontal_flip=False,  # randomly flip images\nvertical_flip=False)  # randomly flip images)\n\ntrain_data= train_generator.flow_from_dataframe(\ndataframe=train,\nx_col=\"file_name\",\ny_col=\"dx\",\nbatch_size=64,\nseed=311,\ndirectory=\"..\/input\/mnist1000-with-one-image-folder\/ham1000_images\/HAM1000_images\",\nshuffle=True,\nclass_mode=\"categorical\",\ntarget_size=(224,224))","ca966d51":"test_generator=ImageDataGenerator(\nrescale = 1.\/255)\ntest_data= test_generator.flow_from_dataframe(\ndataframe=test,\nx_col=\"file_name\",\ny_col=\"dx\",\nseed=45,\ndirectory=\"..\/input\/mnist1000-with-one-image-folder\/ham1000_images\/HAM1000_images\",\nshuffle=False,\nbatch_size=1,\nclass_mode=None,\ntarget_size=(224,224))\nval_data=test_generator.flow_from_dataframe(\ndataframe=val,\ndirectory=\"..\/input\/mnist1000-with-one-image-folder\/ham1000_images\/HAM1000_images\",\nx_col=\"file_name\",\ny_col=\"dx\",\nbatch_size=64,\nseed=45,\nshuffle=False,\nclass_mode=\"categorical\",\ntarget_size=(224,224))","f8425109":"from sklearn.utils import class_weight\nclass_weight = np.round(class_weight.compute_class_weight('balanced',np.unique(y_train),y_train['dx']))\nprint(class_weight)\nprint(train_data.class_indices)\nprint(val_data.class_indices)\nprint(train['dx'].value_counts())","0ae3595e":"from keras.metrics import top_k_categorical_accuracy\n\nfrom keras.callbacks import ReduceLROnPlateau\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                    patience=3, \n                                    verbose=1, \n                                    factor=0.5, \n                                    min_lr=0.00001)\n\nmodel.compile(optimizer=optimizers.adam(lr=0.0001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\nhistory=model.fit_generator(generator=train_data,\n                    steps_per_epoch=train_data.samples\/\/train_data.batch_size,\n                            validation_data=val_data,\n                            verbose=1,\n                            validation_steps=val_data.samples\/\/val_data.batch_size,\n                    epochs=35,class_weight=class_weight,callbacks=[learning_rate_reduction])","4511fe48":"val_data.reset()\npredictions = model.predict_generator(val_data, steps=val_data.samples\/val_data.batch_size,verbose=1)","57f95df4":"y_pred= np.argmax(predictions, axis=1)\nprint(y_pred)\nground_truth=val_data.classes","268642c1":"from sklearn.metrics import classification_report\nprint('Classification Report')\ntarget_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv','vasc']\nprint(classification_report(val_data.classes, y_pred, target_names=target_names))","d754c28f":"test_data.reset()\npredictions = model.predict_generator(test_data, steps=test_data.samples\/test_data.batch_size,verbose=1)\ny_pred= np.argmax(predictions, axis=1)\n","bdf96ed1":"print(y_pred)\nground_truth=test['label']\nfrom sklearn.metrics import classification_report\nprint('Classification Report')\ntarget_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv','vasc']\nprint(classification_report(ground_truth, y_pred, target_names=target_names))","9f5d5a83":"# 1 Constructing a model**","c205f656":"## Introduction","71c29e4a":"Here we construct a model based on pretrained Resnet50 model. In  order to prevent overfitting we had 2 Dropout layers. \n\nSince we have 7 class, we use a Dense of 7 neurons","7b933896":"In this notebook, I aim to use the HAM10000 Dataset to classify 7 types of skin diseases.\n\nThe accuracy reached 84-85% quite more than several previous work","426f0ff6":"# 5 Evaluation and testing on test set","5d1994fc":"# 4. Evaluation and testing on validation set","6e1703ec":"Reading filenames of images and their label","639dade3":"# 2: Constructing Data Flow","b70d9f15":"Data Augmentation and prepare the flow of data","ed155c39":"HAM10000 dataset consists of 10015 dermatoscopic images which can serve as a training set for academic machine learning purposes. \n\nCases include a representative collection of all important diagnostic categories in the realm of pigmented lesions: \n\nActinic keratoses  \n\nBowen's disease (akiec), \n\nbasal cell carcinoma (bcc), \n\nbenign keratosis-like lesions (solar lentigines \/ seborrheic keratoses and lichen-planus like keratoses, bkl),\n\ndermatofibroma (df),\n\nmelanoma (mel), \n\nmelanocytic nevi (nv) and \n\nvascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n\n**Original Data Source\n**\n\nhttps:\/\/dataverse.harvard.edu\/dataset.xhtml?persistentId=doi:10.7910\/DVN\/DBW86T Tschandl, P., Rosendahl, C. & Kittler, H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci. Data 5, 180161 (2018). doi: 10.1038\/sdata.2018.161","d4a10265":"Next, we split the data into training, validation and test set with stratitied methods","21d854e3":"Adding classweights","6f8f486a":"Automatically reducing the LR after 3 \"patient epochs\", then run","3e104fa8":"# 3.Combine and run","288b168a":"Convert string labels to int labels","3da89b67":"Concat labels with filenames"}}