{"cell_type":{"45399b2b":"code","54186cdf":"code","40cd693b":"code","d6438f68":"code","39e7f77a":"code","d295e71a":"code","0da61411":"code","29fd53a6":"code","d1401d21":"code","5e260e1d":"code","f56d8a9e":"code","449242c2":"code","b7c5d758":"code","bf6503d7":"code","09da7f9e":"code","d11edda8":"code","1278fa8a":"code","7251d263":"code","481f39a1":"code","6a199878":"code","9427d2ba":"code","f2ec814b":"code","7db4452b":"code","3cc05c4f":"code","41269e02":"code","bd7ee079":"code","6f1bb0ca":"code","98c5c636":"code","ed27307c":"code","80a55186":"code","a91dbcee":"code","520ea4ee":"code","ac640e3a":"code","c67ad054":"code","480b80cb":"code","7c79cce7":"code","5d2a6c91":"markdown","797df49a":"markdown"},"source":{"45399b2b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","54186cdf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\nfrom sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n\nfrom scipy.optimize import minimize\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\n\nfrom tqdm import tqdm_notebook\n\nfrom itertools import product\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","40cd693b":"import pandas as pd\nstock_prices_sample = pd.read_csv(\"..\/input\/stock_prices_sample.csv\")","d6438f68":"import pandas as pd\nstock_prices_sample = pd.read_csv(\"..\/input\/stock_prices_sample.csv\")\nstock_prices_samples = \"..\/input\/stock_prices_sample.csv\"","39e7f77a":"def mean_absolute_percentage_error(y_true, y_pred):\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","d295e71a":"data = stock_prices_sample","0da61411":"data.head()","29fd53a6":"data.info()","d1401d21":"data = data[data.TICKER != 'GEF']","5e260e1d":"data = pd.read_csv(stock_prices_samples,index_col=['DATE'], parse_dates=['DATE'])\ndata.head(10)","f56d8a9e":"data.shape","449242c2":"data = data[data.TICKER != 'GEF']\ndata = data[data.TYPE != 'Intraday']","b7c5d758":"data.head()","bf6503d7":"drop_cols = ['SPLIT_RATIO', 'EX_DIVIDEND', 'ADJ_FACTOR', 'ADJ_VOLUME', 'ADJ_CLOSE', 'ADJ_LOW', 'ADJ_HIGH', 'ADJ_OPEN', 'VOLUME', 'FREQUENCY', 'TYPE', 'FIGI']","09da7f9e":"len(drop_cols)","d11edda8":"data.columns","1278fa8a":"drop_cols","7251d263":"data.drop(drop_cols, axis=1, inplace=True)","481f39a1":"data.head()","6a199878":"data.CLOSE.head()","9427d2ba":"\nplt.figure(figsize=(17, 8))\nplt.plot(data.CLOSE)\nplt.title('Closing price of New Germany Fund Inc (GF)')\nplt.ylabel('Closing price ($)')\nplt.xlabel('Trading day')\nplt.grid(False)\nplt.show()","f2ec814b":"def plot_moving_average(series, window, plot_intervals=False, scale=1.96):\n    \n\n    rolling_mean = series.rolling(window=window).mean()\n    \n    #print(rolling_mean)\n    plt.figure(figsize=(17,8))\n    plt.title('Moving average\\n window size = {}'.format(window))\n    plt.plot(rolling_mean,'r', label='Rolling mean trend')\n    \n    \n    #Plot confidence intervals for smoothed values\n    if plot_intervals:\n        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n        deviation = np.std(series[window:] - rolling_mean[window:])\n        lower_bound = rolling_mean - (mae + scale * deviation)\n        upper_bound = rolling_mean + (mae + scale * deviation)\n        plt.plot(upper_bound, 'r--', label='Upper bound \/ Lower bound')\n        plt.plot(lower_bound, 'r--')\n            \n    plt.plot(series[window:], label='Actual values')\n    plt.legend(loc='best')\n    plt.grid(True)","7db4452b":"#Smooth by the previous 5 days (by week)\nplot_moving_average(data.CLOSE, 5)","3cc05c4f":"#Smooth by the previous 30 days (by month) WIndow size 30\nplot_moving_average(data.CLOSE, 30)","41269e02":"plot_moving_average(data.CLOSE, 90)","bd7ee079":"plot_moving_average(data.CLOSE, 90, plot_intervals=True)","6f1bb0ca":"def exponential_smoothing(series, alpha):\n\n    result = [series[0]] # first value is same as series\n    for n in range(1, len(series)):\n        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n    return result","98c5c636":"\ndef plot_exponential_smoothing(series, alphas):\n \n    plt.figure(figsize=(17, 8))\n    for alpha in alphas:\n        plt.plot(exponential_smoothing(series, alpha), label=\"Alpha {}\".format(alpha))\n    plt.plot(series.values, \"c\", label = \"Actual\")\n    plt.legend(loc=\"best\")\n    plt.axis('tight')\n    plt.title(\"Exponential Smoothing\")\n    plt.grid(True);","ed27307c":"\nplot_exponential_smoothing(data.CLOSE, [0.05, 0.3])","80a55186":"def double_exponential_smoothing(series, alpha, beta):\n\n    result = [series[0]]\n    for n in range(1, len(series)+1):\n        if n == 1:\n            level, trend = series[0], series[1] - series[0]\n        if n >= len(series): # forecasting\n            value = result[-1]\n        else:\n            value = series[n]\n        last_level, level = level, alpha * value + (1 - alpha) * (level + trend)\n        trend = beta * (level - last_level) + (1 - beta) * trend\n        result.append(level + trend)\n    return result\n\ndef plot_double_exponential_smoothing(series, alphas, betas):\n     \n    plt.figure(figsize=(17, 8))\n    for alpha in alphas:\n        for beta in betas:\n            plt.plot(double_exponential_smoothing(series, alpha, beta), label=\"Alpha {}, beta {}\".format(alpha, beta))\n    plt.plot(series.values, label = \"Actual\")\n    plt.legend(loc=\"best\")\n    plt.axis('tight')\n    plt.title(\"Double Exponential Smoothing\")\n    plt.grid(True)\n    \nplot_double_exponential_smoothing(data.CLOSE, alphas=[0.9, 0.02], betas=[0.9, 0.02])","a91dbcee":"def tsplot(y, lags=None, figsize=(12, 7), syle='bmh'):\n    \n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n        \n    with plt.style.context(style='bmh'):\n        fig = plt.figure(figsize=figsize)\n        layout = (2,2)\n        ts_ax = plt.subplot2grid(layout, (0,0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1,0))\n        pacf_ax = plt.subplot2grid(layout, (1,1))\n        \n        y.plot(ax=ts_ax)\n        p_value = sm.tsa.stattools.adfuller(y)[1]\n        ts_ax.set_title('Time Series Analysis Plots\\n Dickey-Fuller: p={0:.5f}'.format(p_value))\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n        plt.tight_layout()\n        \ntsplot(data.CLOSE, lags=30)\n\n# Take the first difference to remove to make the process stationary\ndata_diff = data.CLOSE - data.CLOSE.shift(1)\n\ntsplot(data_diff[1:], lags=30)","520ea4ee":"#Set initial values and some bounds\nps = range(0, 5)\nd = 1\nqs = range(0, 5)\nPs = range(0, 5)\nD = 1\nQs = range(0, 5)\ns = 5\n\n#Create a list with all possible combinations of parameters\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)","ac640e3a":"'''\n\n\ndef optimize_SARIMA(parameters_list, d, D, s):\n    \"\"\"\n        Return dataframe with parameters and corresponding AIC\n        \n        parameters_list - list with (p, q, P, Q) tuples\n        d - integration order\n        D - seasonal integration order\n        s - length of season\n    \"\"\"\n    \n    results = []\n    best_aic = float('inf')\n    \n    for param in tqdm_notebook(parameters_list):\n        try: model = sm.tsa.statespace.SARIMAX(data.CLOSE, order=(param[0], d, param[1]),\n                                               seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)\n        except:\n            continue\n            \n        aic = model.aic\n        \n        #Save best model, AIC and parameters\n        if aic < best_aic:\n            best_model = model\n            best_aic = aic\n            best_param = param\n        results.append([param, model.aic])\n        \n    result_table = pd.DataFrame(results)\n    result_table.columns = ['parameters', 'aic']\n    #Sort in ascending order, lower AIC is better\n    result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)\n    \n    return result_table\n\nresult_table = optimize_SARIMA(parameters_list, d, D, s)\n\n\n\n'''\n","c67ad054":"'''def plot_SARIMA(series, model, n_steps):\n    \"\"\"\n        Plot model vs predicted values\n        \n        series - dataset with time series\n        model - fitted SARIMA model\n        n_steps - number of steps to predict in the future\n    \"\"\"\n    \n    data = series.copy().rename(columns = {'CLOSE': 'actual'})\n    data['arima_model'] = model.fittedvalues\n    #Make a shift on s+d steps, because these values were unobserved by the model due to the differentiating\n    data['arima_model'][:s+d] = np.NaN\n    \n    #Forecast on n_steps forward\n    forecast = model.predict(start=data.shape[0], end=data.shape[0] + n_steps)\n    forecast = data.arima_model.append(forecast)\n    #Calculate error\n    error = mean_absolute_percentage_error(data['actual'][s+d:], data['arima_model'][s+d:])\n    \n    plt.figure(figsize=(17, 8))\n    plt.title('Mean Absolute Percentage Error: {0:.2f}%'.format(error))\n    plt.plot(forecast, color='r', label='model')\n    plt.axvspan(data.index[-1], forecast.index[-1],alpha=0.5, color='lightgrey')\n    plt.plot(data, label='actual')\n    plt.legend()\n    plt.grid(True);\n    \n# plot_SARIMA(data, best_model, 5)\nprint(best_model.predict(start=data.CLOSE.shape[0], end=data.CLOSE.shape[0] + 5))\nprint(mean_absolute_percentage_error(data.CLOSE[s+d:], best_model.fittedvalues[s+d:]))\n\n'''","480b80cb":"comparison = pd.DataFrame({'actual': [18.93, 19.23, 19.08, 19.17, 19.11, 19.12],\n                          'predicted': [18.96, 18.97, 18.96, 18.92, 18.94, 18.92]}, \n                          index = pd.date_range(start='2018-06-05', periods=6,))","7c79cce7":"plt.figure(figsize=(17, 8))\nplt.plot(comparison.actual)\nplt.plot(comparison.predicted)\nplt.title('Predicted closing price of New Germany Fund Inc (GF)')\nplt.ylabel('Closing price ($)')\nplt.xlabel('Trading day')\nplt.legend(loc='best')\nplt.grid(False)\nplt.show()","5d2a6c91":"I have completed this project with help of one article...\n\nTo impliment this project I have good knowledge and experience from below concepts...\n# stationary, seasonality,autocorrelated \nThere are many ways to model a time series in order to make predictions.\n\n1. # moving average\n1. # exponential smoothing\n1. # SARIMA\n\nI am worked this project on Single CPU so when I try to excute the SARIMA model ran into time complexity issues from myend... I used GPU from Kernal even though some issues.\nSo I kept those codes of line in Comments.\n\n","797df49a":"\n# stationary, seasonality,autocorrelated \n\n\n1. # Moving average\n1. # Exponential smoothing**\n1. # SARIMA\n\nI am worked this project on Single CPU so when I try to excute the SARIMA model ran into time complexity issues from myend... I used GPU from Kernal even though some issues.\nSo I kept those codes of line in Comments.*\n\n"}}