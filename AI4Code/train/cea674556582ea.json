{"cell_type":{"7835cecd":"code","8bfe7e38":"code","0e893bcc":"code","9f12ce77":"code","2dd400ae":"code","7f60df6f":"code","933f5bd6":"code","1c543337":"code","d1730a5e":"code","14940a34":"code","7312a469":"code","208e5d32":"code","4a6b3951":"code","44cc2665":"code","b5fab231":"code","fb9d104f":"code","bbfe8d9a":"code","faf7526a":"code","04ff13c9":"code","ce82587a":"code","efcf2ae5":"code","707ca77e":"code","6cb64237":"code","02a85eac":"code","b016bcf2":"code","1d039e15":"code","19dcb613":"code","db58f681":"code","1d5fd7dc":"code","7452f99b":"code","346f15db":"code","394b579b":"code","ecf937c7":"code","ebb2e887":"code","07745005":"code","13c4a91d":"code","584d2983":"code","30acf3c0":"code","ca5d1f2e":"code","be2e970d":"code","af4cc186":"code","aaf77e04":"code","2f45e156":"code","5371e861":"code","d5f53792":"markdown","57bd10e5":"markdown","f7101014":"markdown","840357f3":"markdown","1a046ae7":"markdown","1a3a42c3":"markdown","596dd7bf":"markdown","091b9785":"markdown","0aabe590":"markdown","b5ca9780":"markdown","b85cfa9e":"markdown","3b8562fa":"markdown","a8a6cfe5":"markdown","905c9788":"markdown"},"source":{"7835cecd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8bfe7e38":"df = pd.read_excel('\/kaggle\/input\/2020-kaggle-ml\/Cost of life.xlsx')\ndf.head()","0e893bcc":"#Code by Siti K https:\/\/www.kaggle.com\/khotijahs1\/2020-indonesia-university-rank\/comments\n\n#The (20) least expensive countries  by Rank\ntop_country = df.sort_values(by='Rank', ascending=False)[:20]\nfigure = plt.figure(figsize=(10,6))\nsns.barplot(y=top_country.Country, x=top_country.Rank)\nplt.xticks(rotation=45)\nplt.xlabel('Rank')\nplt.ylabel('Country')\nplt.title('20 Least Expensive Countries by Rank')\nplt.show()","9f12ce77":"#Code by Siti K https:\/\/www.kaggle.com\/khotijahs1\/2020-indonesia-university-rank\/comments\n\n# The most expensive Countries by Rank\ntop_country = df.sort_values(by='Rank', ascending=True)[:20]\nfigure = plt.figure(figsize=(10,6))\nsns.barplot(y=top_country.Country, x=top_country.Rank)\nplt.xticks(rotation=45)\nplt.xlabel('Rank')\nplt.ylabel('Country')\nplt.title('The most expensive Countries by Rank')\nplt.show()","2dd400ae":"#Code by Gabriel Preda https:\/\/www.kaggle.com\/gpreda\/explore-the-rainforest-soundscape\ndef plot_feature_distribution(df, feature, feature2, title, kde_mode=False, hist_mode=True):\n    f, ax = plt.subplots(1,1, figsize=(12,6))\n    for item in list(df[feature2].unique()):\n        d_df = df.loc[df[feature2]==item]\n        try:\n            sns.distplot(df[feature], kde=kde_mode, hist=hist_mode, label=item)\n        except:\n            pass\n    plt.legend(labels=list(df[feature2].unique()), bbox_to_anchor=(1, 1), loc='upper right', ncol=2)\n    plt.title(title)\n    plt.show()","7f60df6f":"plot_feature_distribution(df, 'Cost of Living Index','Rank', \"Cost of Living Index Rank\")","933f5bd6":"#Code by Puru Behl https:\/\/www.kaggle.com\/accountstatus\/mt-cars-data-analysis\n\nsns.distplot(df['Cost of Living Index'])\nplt.axvline(df['Cost of Living Index'].values.mean(), color='red', linestyle='dashed', linewidth=1)\nplt.title('Cost of Living Distribution')","1c543337":"#Code by Firat Gonen https:\/\/www.kaggle.com\/frtgnn\/elo-eda-lgbm\/notebook \n\nplt.figure(figsize=(10, 6))\nplt.title('Cost of Living Index')\nsns.despine()\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n\nsns.distplot(df['Cost of Living Index'], hist=True, rug=False,norm_hist=True)","d1730a5e":"from sklearn.preprocessing import LabelEncoder\n\n#fill in mean for floats\nfor c in df.columns:\n    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n        df[c].fillna(df[c].mean())\n\n#fill in -999 for categoricals\ndf = df.fillna(-999)\n# Label Encoding\nfor f in df.columns:\n    if df[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[f].values))\n        df[f] = lbl.transform(list(df[f].values))\n        \nprint('Labelling done.')","14940a34":"df = pd.get_dummies(df)","7312a469":"X = df[['Cost of Living Index', 'Country','Rent Index', 'Cost of Living Plus Rent Index', 'Groceries Index', 'Restaurant Price Index', 'Local Purchasing Power Index']]\ny = df['Rank']","208e5d32":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","4a6b3951":"from sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\n\ndef cross_val(model):\n    pred = cross_val_score(model, X, y, cv=10)\n    return pred.mean()\n\ndef print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)\n    \ndef evaluate(true, predicted):\n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    return mae, mse, rmse, r2_square","44cc2665":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('std_scalar', StandardScaler())\n])\n\nX_train = pipeline.fit_transform(X_train)\nX_test = pipeline.transform(X_test)","b5fab231":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train,y_train)","fb9d104f":"# print the intercept\nprint(lin_reg.intercept_)","bbfe8d9a":"coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\ncoeff_df","faf7526a":"pred = lin_reg.predict(X_test)","04ff13c9":"plt.scatter(y_test, pred)","ce82587a":"sns.distplot((y_test - pred), bins=50);","efcf2ae5":"test_pred = lin_reg.predict(X_test)\ntrain_pred = lin_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","707ca77e":"results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df","6cb64237":"from sklearn.linear_model import RANSACRegressor\n\nmodel = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","02a85eac":"results_df_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","b016bcf2":"from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","1d039e15":"results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","19dcb613":"from sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=0.1, \n              precompute=True, \n#               warm_start=True, \n              positive=True, \n              selection='random',\n              random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","db58f681":"results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","1d5fd7dc":"from sklearn.linear_model import ElasticNet\n\nmodel = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","7452f99b":"results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","346f15db":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_reg = PolynomialFeatures(degree=2)\n\nX_train_2_d = poly_reg.fit_transform(X_train)\nX_test_2_d = poly_reg.transform(X_test)\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train_2_d,y_train)\n\ntest_pred = lin_reg.predict(X_test_2_d)\ntrain_pred = lin_reg.predict(X_train_2_d)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","394b579b":"results_df_2 = pd.DataFrame(data=[[\"Polynomail Regression\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","ecf937c7":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\nsgd_reg.fit(X_train, y_train)\n\ntest_pred = sgd_reg.predict(X_test)\ntrain_pred = sgd_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","ebb2e887":"results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","07745005":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Activation, Dropout\n\nfrom tensorflow.keras.optimizers import Adam\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nmodel = Sequential()\n\nmodel.add(Dense(X_train.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(128, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer=Adam(0.00001), loss='mse')\n\nr = model.fit(X_train, y_train,\n              validation_data=(X_test,y_test),\n              batch_size=1,\n              epochs=100)","13c4a91d":"plt.figure(figsize=(10, 6))\n\nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()","584d2983":"test_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","30acf3c0":"results_df_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","ca5d1f2e":"from sklearn.ensemble import RandomForestRegressor\n\nrf_reg = RandomForestRegressor(n_estimators=1000)\nrf_reg.fit(X_train, y_train)\n\ntest_pred = rf_reg.predict(X_test)\ntrain_pred = rf_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","be2e970d":"results_df_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","af4cc186":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\nsvm_reg.fit(X_train, y_train)\n\ntest_pred = svm_reg.predict(X_test)\ntrain_pred = svm_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","aaf77e04":"results_df_2 = pd.DataFrame(data=[[\"SVM Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","2f45e156":"results_df.set_index('Model', inplace=True)\nresults_df['R2 Square'].plot(kind='barh', figsize=(12, 8))","5371e861":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#f54242','#42a7f5','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke was Here.' )","d5f53792":"#Ridge Regression","57bd10e5":"#Random Forest Regressor","f7101014":"#Codes by Fares Sayah https:\/\/www.kaggle.com\/faressayah\/linear-regression-house-price-prediction","840357f3":"#Linear Regression","1a046ae7":"#Models Comparison","1a3a42c3":"#Support Vector Machine","596dd7bf":"#Stochastic Gradient Descent","091b9785":"#Elastic Net","0aabe590":"#Robust Regression","b5ca9780":"#LASSO Regression","b85cfa9e":"![](https:\/\/static.guim.co.uk\/sys-images\/Guardian\/Pix\/maps_and_graphs\/2010\/6\/29\/1277832881229\/Cities-compared-graphic-002.jpg)theguardian.com","3b8562fa":"#Artificial Neural Network","a8a6cfe5":"According to the latest Cost of Living Survey from Mercer. Tokyo is in second position, with Ndjamena in Chad in third place. Moscow is in fourth position followed by Geneva in fifth while Karachi is ranked as the world's least expensive city. The survey found that Luanda is three times as costly as Karachi.\n\nFrom the survey, London (rank 17) is the UK's most expensive city, followed by Aberdeen (149), Glasgow (155), and Birmingham (158). Belfast (182) is ranked as the UK's least expensive city.\nThe survey covers 214 cities across five continents and measures the comparative cost of over 200 items in each location, including housing, transport, food, clothing, household goods and entertainment. New York is used as the base city for the index and all cities are compared against New York. The cost of housing \u2013 often the biggest expense for expats - plays an important part in determining where cities are ranked.\nhttps:\/\/www.theguardian.com\/news\/datablog\/2010\/jun\/30\/city-costs-living","905c9788":"#Polynomial Regression"}}