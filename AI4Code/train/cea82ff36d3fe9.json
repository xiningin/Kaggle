{"cell_type":{"1348e866":"code","3ab8f3e5":"code","5c16e442":"code","5e9a2ae8":"code","5d750e83":"code","809865f9":"code","30623c26":"code","6338883b":"code","ab9aa875":"code","b8677eb7":"code","1f9d3208":"code","f9e1fca6":"code","190ebd86":"code","a9df6eb4":"code","7cb50b4c":"code","0fcbb6b6":"code","9fe40bb4":"code","5eb860a5":"code","ee8b63d3":"code","a19aa7b9":"code","488df501":"code","c0fac77d":"code","66d62d06":"code","6e56ed2a":"code","0fdefb95":"code","03ab9841":"code","08d797c5":"code","b78cff6b":"code","55c0bb8a":"code","a90346e8":"code","45fdff54":"code","f94c6df8":"code","8df40862":"code","94774ac5":"code","c43595b0":"code","8053593e":"code","2e05cb4b":"code","03e7c809":"code","6e8e7eea":"code","6ad35f65":"code","4d452ccc":"code","24118658":"code","8b92082c":"code","37f277b3":"code","5d7c131f":"code","d83e4a1b":"code","baef274b":"code","ac7af7e0":"code","7842f3c2":"code","4e64ca63":"code","07ea5f32":"code","4d95ec64":"code","948d952f":"code","fdfa2e58":"code","26de4385":"code","426da4e0":"markdown","863baf99":"markdown","274a833e":"markdown","dffee30b":"markdown","8ad0576f":"markdown","1de5cbf1":"markdown","83d399d7":"markdown","2fbe6cf6":"markdown","ef5df845":"markdown","b4c45c28":"markdown","8498fbd4":"markdown","000d6945":"markdown","0d04705e":"markdown","44ff8f6b":"markdown","49b62376":"markdown","81e9f64f":"markdown","d65d03f2":"markdown","5808f209":"markdown","38f47e21":"markdown","42bb0ba2":"markdown","cd3db7fc":"markdown","197b9e94":"markdown","1cb8627e":"markdown","9280f4f7":"markdown"},"source":{"1348e866":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sympy import binomial\nfrom scipy.stats import binom, beta, norm\n#from scipy.stats import stats\nimport scipy.integrate as integrate\nimport matplotlib.pyplot as plt\nimport random\n\nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = 20, 15\n#plt.rcParams['figure.titlesize'] = 100","3ab8f3e5":"b = beta(2,3)\n\nx = np.linspace(0, 1, 1000)\nplt.plot(x, b.pdf(x), label='PDF')\nplt.plot(x, b.cdf(x), label='CDF')\nplt.axhline(.025)\nplt.axhline(1-.025)\nplt.axvline(b.ppf(.025))\nplt.axvline(b.ppf(1-.025))\nplt.xlabel('Conversion rate')\nplt.ylabel('Density (CDF : Probability)')\nplt.legend()\n\nprint(f'The 95 percent confidence interval (i.e., a 95 percent chance that our true conversion rate is \\\nsomewhere in that range) is marked to make it easier to see. At this point our data tells us that the \\\ntrue conversion rate could be anything between {b.ppf(.025)} and {b.ppf(1-.025)}.This is a reflection of how little \\\ninformation we\u2019ve actually acquired so far. Given that we\u2019ve had two conversions, we know the true \\\nrate can\u2019t be 0, and since we\u2019ve had three non-conversions, we also know it can\u2019t be 1. Almost \\\neverything else is fair game.\\n')","5c16e442":"b1, b2, b3 = beta(1,41), beta(2,80), beta(5,200)\n\nx = np.linspace(0, .15, 1000)\nplt.plot(x, b1.pdf(x), label='beta(1,41)')\nplt.plot(x, b2.pdf(x), label='beta(2,80)')\nplt.plot(x, b3.pdf(x), label='beta(5,200)')\nplt.legend()","5e9a2ae8":"print(f' Probabilities given by different distribution for p = 1\/42 are {b1.cdf(1\/42.),b2.cdf(1\/42.),b3.cdf(1\/42.)}')","5d750e83":"b1, b2 = beta(5,200), beta(5+86,200+214)\nx = np.linspace(0, .35, 1000)\nplt.plot(x, b1.pdf(x), label='No Prior')\nplt.plot(x, b2.pdf(x), label='With Prior')\nplt.legend()","809865f9":"b1, b2 = beta(2,8), beta(200,800)\nx = np.linspace(0, 1, 1000)\nplt.plot(x, b1.pdf(x), label=f'beta(2,8)')\nplt.plot(x, b2.pdf(x), label=f'beta(200,800)')\nplt.plot(x, b1.cdf(x), label=f'CDF beta(2,8)')\nplt.plot(x, b2.cdf(x), label=f'CDF beta(200,800)')\nplt.legend()","30623c26":"# confidence intervals that quantitatively model any expert's beliefs. We calculate 95 CI\nconf_int1 = (b1.ppf(.025), b1.ppf(1-.025))\nconf_int2 = (b2.ppf(.025), b2.ppf(1-.025))\nprint(conf_int1, conf_int2)","6338883b":"x=np.linspace(0,1,1000)\nfor i in range(10):\n    b = beta(i+1, i+1)\n    plt.plot(x, b.pdf(x), label=f'Beta{i+1,i+1}')\n    \n    plt.legend()","ab9aa875":"x=np.linspace(0,.001,1000)\nplt.plot(x, beta(1,11000).pdf(x))","b8677eb7":"'''Suppose you\u2019re playing air hockey with some friends and flip a coin\nto see who starts with the puck. After playing 12 times, you realize that\nthe friend who brings the coin almost always seems to go first: 9 out of\n12 times. Some of your other friends start to get suspicious. Define prior\nprobability distributions for the following beliefs:\n\u2022 One person who weakly believes that the friend is cheating and\nthe true rate of coming up heads is closer to 70 percent. (Denoted by b1)\n\u2022 One person who very strongly trusts that the coin is fair and pro-\nvided a 50 percent chance of coming up heads. (Denoted by b2)\n\u2022 One person who strongly believes the coin is biased to come up\nheads 70 percent of the time. (Denoted by b3)'''\n\nb1, b2, b3, b = beta(7,3), beta(1000,1000), beta(70,30), beta(9,3)\n\nx=np.linspace(0,1,1000)\nplt.plot(x, b1.pdf(x), label='Weakly 70% biased')\nplt.plot(x, b2.pdf(x), label='Fair coin')\nplt.plot(x, b3.pdf(x), label='Strongly 70% biased')\nplt.plot(x, b.pdf(x), label='Data given')\nplt.legend()","1f9d3208":"'''To test the coin, you flip it 20 more times and get 9 heads and 11 tails.\nUsing the priors you calculated in the previous question, what are the\nupdated posterior beliefs in the true rate of flipping a heads in terms of\nthe 95 percent confidence interval?'''\n\n'''Now we have an updated data set with a total of 32 observations,\nwhich includes 18 heads and 14 tails.'''\nb4 = beta(7+18, 3+14)\n\nplt.plot(x, b1.pdf(x), label='Weakly 70% biased')\nplt.plot(x, b2.pdf(x), label='Fair coin')\nplt.plot(x, b3.pdf(x), label='Strongly 70% biased')\nplt.plot(x, b4.pdf(x), label='Updated belief with Weakly 70% biased')\nplt.plot(x, b.pdf(x), label='Data given')\nplt.legend()","f9e1fca6":"l = [b1, b2, b3, b4, b]\nname = ['beta(7,3)', 'beta(1000,1000)', 'beta(70,30)', 'beta(7+18, 3+14)','beta(9,3)']\nfor b, name in zip(l, name):\n    print(f'\\nConfidence interval for {name} is :\\n')\n    print(f'{b.ppf(.025), b.ppf(1-.025)}')","190ebd86":"'''SETTING UP A BAYESIAN A\/B TEST\nKeeping with our email example from the previous chapter, imagine we want to see whether\nadding an image helps or hurts the conversion rate for our blog. Previously, the weekly email has\nincluded some image. For our test we\u2019re going to send one variant with images like usual, and\nanother without images. The test is called an A\/B test because we are comparing variant A (with\nimage) and variant B (without) to determine which one performs better.\nLet\u2019s assume at this point we have 600 blog subscribers. Because we want to exploit the knowledge\ngained during this experiment, we\u2019re only going to be running our test on 300 of them; that way, we\ncan send the remaining 300 subscribers what we believe to be the most effective variant of the\nemail.\nThe 300 people we\u2019re going to test will be split up into two groups, A and B. Group A will receive\nthe usual email with a big picture at the top, and group B will receive an email with no picture. The\nhope is that a simpler email will feel less \u201cspammy\u201d and encourage users to click through to the\ncontent. Finding Our Prior Probability\nNext, we need to figure out what prior probability we\u2019re going to use. We\u2019ve run an email campaign\nevery week, so from that data we have a reasonable expectation that the probability of clicking the\nlink to the blog on any given email should be around 30 percent. To make things simple, we\u2019ll use\nthe same prior for both variants. We\u2019ll also choose a pretty weak version of our prior distribution,\nmeaning that it considers a wider range of conversion rates to be probable. We\u2019re using a weak\nprior because we don\u2019t really know how well we expect B to do, and this is a new email campaign,\nso other factors could cause a better or worse conversion. We\u2019ll settle on Beta(3,7) for our prior\nprobability distribution. This distribution allows us to represent a beta distribution where 0.3 is the\nmean, but a wide range of possible alternative rates are considered. We can see this distribution below,'''\n\nb = beta(3,7)\n\nplt.plot(x, b.pdf(x))\nplt.xlabel('Conv Rate')\nplt.ylabel('Density')\nplt.title('Weak prior belief in conversion rate beta(3,7)')","a9df6eb4":"'''All we need now is our likelihood, which means we need to collect data.\nCollecting Data\nWe send out our emails and get the results'''\n\nprint('Table : Email  Click-through Rates\\n\\n\\\n\\t \\tClicked \\tNot clicked \\tObserved conversion rate \\n\\\nVariant A \\t36 \\t\\t114 \\t\\t0.24 \\n\\\nVariant B \\t50 \\t\\t100 \\t\\t0.33')","7cb50b4c":"b, b1, b2 = beta(3,7), beta(36+3,114+7), beta(50+3,100+7)\n\nplt.plot(x, b.pdf(x), label='Weak belief')\nplt.plot(x, b1.pdf(x), label='Variant A')\nplt.plot(x, b2.pdf(x), label='Variant B')\nplt.axvline(39\/160.)\nplt.axvline(53\/160.)\nplt.xlabel('Conv Rate')\nplt.ylabel('Density')\nplt.legend()\nplt.title('Parameter estimation Variants A and B')","0fcbb6b6":"n_sample = 100_000\nasample = beta.rvs(36+3,114+7, size=n_sample)\nbsample = beta.rvs(50+3,100+7, size=n_sample)\n\nplt.hist(asample)","9fe40bb4":"plt.hist(bsample)","5eb860a5":"sum(bsample > asample)\/n_sample","ee8b63d3":"np.mean(asample), 39\/160.,np.mean(bsample), 53\/160.","a19aa7b9":"ratios = bsample\/asample\n\nplt.hist(ratios, bins=20)","488df501":"def ecdf(data):\n    x = np.sort(data)\n    n = len(data)\n    y = np.arange(1, n+1) \/ n\n    return x, y\n\nx, y = ecdf(ratios)\nplt.plot(x,y)   ","c0fac77d":"'''Suppose a director of marketing with many years of experience tells you he believes\nvery strongly that the variant without images (B) won\u2019t perform any differently than the\noriginal variant. How could you account for this in our model? Implement this change and\nsee how your final conclusions change as well.'''\n\na_prior, b_prior = 300, 700\n\nA = beta.rvs(36 + a_prior, 114 + b_prior, size=n_sample)\nB = beta.rvs(50 + a_prior, 100 + b_prior, size=n_sample)\n\nsum(B > A) \/ n_sample","66d62d06":"'''The lead designer sees your results and insists that there\u2019s no way that\nvariant B should perform better with no images. She feels that you should\nassume the conversion rate for variant B is closer to 20 percent than\n30 percent. Implement a solution for this and again review the results of\nour analysis.'''\n\na_prior_a = 30\na_prior_b = 70\n\nb_prior_a = 20\nb_prior_b = 80\n\nA = beta.rvs(36 + a_prior_a, 114 + a_prior_b, size=n_sample)\nB = beta.rvs(50 + b_prior_a, 100 + b_prior_b, size=n_sample)\n\nsum(B > A) \/ n_sample","6e56ed2a":"'''Assume that being 95 percent certain means that you\u2019re more or less\n\u201cconvinced\u201d of a hypothesis. Also assume that there\u2019s no longer any limit\nto the number of emails you can send in your test. If the true conversion\nfor A is 0.25 and for B is 0.3, explore how many samples it would take to\nconvince the director of marketing that B was in fact superior. Explore\nthe same for the lead designer.'''\n\n# Thanks to https:\/\/github.com\/Montanaz0r\/Bayesian-Statistics-The-Fun-Way\/blob\/master\/Bayesian%20Statistics%20The%20Fun%20Way%20-%20Python%20Solutions%20%23%20CHAPTER%2015.ipynb for the code\n\na_true_rate = 0.25\nb_true_rate = 0.3\n\nprior_a = 300\nprior_b = 700\n\np_b_sup = 0\nn_samples = 0\nn_trials = 100000\n\ndef b_superior(B, A, n_trials):\n    return sum(B > A)\/n_trials\n\n\ndef draw_results(n_samples, rate):\n    results = []\n    for i in range(int(n_samples\/2)):\n        draw = random.random()\n        results.append(draw)\n    results = np.array(results)\n    a = sum(results <= rate)\n    b = sum(results > rate)\n    return a, b\n\nwhile p_b_sup < 0.95:\n    n_samples += 100\n    a_samples_a, a_samples_b = draw_results(n_samples, a_true_rate)\n    b_samples_a, b_samples_b = draw_results(n_samples, b_true_rate)\n    a_samples = beta.rvs(a_samples_a + prior_a, a_samples_b + prior_b, size=n_trials)\n    b_samples = beta.rvs(b_samples_a + prior_a, b_samples_b + prior_b, size=n_trials)\n    p_b_sup = b_superior(b_samples, a_samples, n_trials)\n    print(n_samples, p_b_sup)","0fdefb95":"'''Testing for a Loaded Die\nWe can use the Bayes factor and posterior odds as a form of hypothesis testing in which each test is\na competition between two ideas. Suppose your friend has a bag with three six-sided dice in it, and\none die is weighted so that it lands on 6 half the time(H1). The other two are traditional dice whose\nprobability of rolling a 6 is \u2159 (H2). Your friend pulls out a die and rolls 10 times, with the following\nresults:'''\n\ndata = [6, 1, 3, 6, 4, 5, 6, 1, 2, 6]\n\nprior1 = 1\/3\nprior2 = 2\/3\n\nlike1 = (1\/2)**4 * (1\/2)**6\nlike2 = (1\/6)**4 * (5\/6)**6\n\nwithout_prior = like1\/like2\nodds1 = prior1\/prior2\n\nwith_prior = without_prior * odds1\n\nprint(f'This means that H1 , the belief that the die is loaded, explains the data we observed almost four \\\ntimes better than H2. TO be exact {without_prior} better. Because H 1 is only half as likely as H 2 , H 1 is actually only about \\\ntwice as strong (To be exact {with_prior} strong) of an explanation as H 2.')","03ab9841":"'''Returning to the dice problem, assume that your friend made a mistake and suddenly\nrealized that there were, in fact, two loaded dice and only one fair die. How does this change\nthe prior, and therefore the posterior odds, for our problem? Are you more willing to believe\nthat the die being rolled is the loaded die?'''\ndata = [6, 1, 3, 6, 4, 5, 6, 1, 2, 6]\n\nprior1 = 2\/3\nprior2 = 1\/3\n\nlike1 = (1\/2)**4 * (1\/2)**6\nlike2 = (1\/6)**4 * (5\/6)**6\n\nwithout_prior = like1\/like2\nodds1 = prior1\/prior2\n\nwith_prior = without_prior * odds1\n\nprint(f'This means that H1, the belief that the die is loaded, explains the data we observed almost four \\\ntimes better than H2. TO be exact {without_prior} better. Because H 1 is twice as likely as H 2 , H 1 is actually about \\\n7 times as strong (To be exact {with_prior} strong) of an explanation as H 2.')","08d797c5":"'''Returning to the rare diseases example, suppose you go to the doctor, and after\nhaving your ears cleaned you notice that your symptoms persist. Even worse, you have a\nnew symptom: vertigo. The doctor proposes another possible explanation, labyrinthitis,\nwhich is a viral infection of the inner ear in which 98 percent of cases involve vertigo.\nHowever, hearing loss and tinnitus are less common in this disease; hearing loss occurs only\n30 percent of the time, and tinnitus occurs only 28 percent of the time. Vertigo is also a\npossible symptom of vestibular schwannoma, but occurs in only 49 percent of cases. In the\ngeneral population, 35 people per million contract labyrinthitis annually. What is the\nposterior odds when you compare the hypothesis that you have labyrinthitis against the\nhypothesis that you have vestibular schwannoma?'''\n\n'''We\u2019ll mix things up a bit and make H 1 \u201chas labryinthitis\u201d and H 2\n\u201chas vestibular schwannoma,\u201d since we already saw how unlikely vestibu-\nlar schwannoma is. We need to recalculate every piece of our posterior\nodds because we\u2019re looking at a new piece of data, \u201chas vertigo,\u201d and an\nentirely new hypothesis as well.\nLet\u2019s start with the Bayes factor. For H 1 we have:'''\n\nlike1 = .98 * .3 * .28\nlike2 = .63 * .55 * .49\n\n# bayes factor\nbf = like1\/like2\n\n'''This means that given the Bayes factor alone, vestibular schwan-\nnoma is a roughly two times better explanation than labyrinthitis. Now\nwe have to look at the odds ratio:'''\nprior1, prior2 = 35\/10**6, 11\/10**6\n\nprior_odds = prior1\/prior2\n\n'''Labyrinthitis is much less common than impacted earwax, and only\nabout three times more common than vestibular schwannoma. When\nwe put posterior odds together, we can see:'''\n\nposterior_odds = prior_odds * bf\n\nprint(f'The end result is that labyrinthititis is only a slightly better (about {posterior_odds} better) \\\nexplanation than vestibular schwannoma.')\n\n","b78cff6b":"'''Every time you and your friend get together to watch movies, you flip a coin to\ndetermine who gets to choose the movie. Your friend always picks heads, and every Friday\nfor 10 weeks, the coin lands on heads. You develop a hypothesis that the coin has two heads\nsides, rather than both a heads side and a tails side. Set up a Bayes factor for the hypothesis\nthat the coin is a trick coin over the hypothesis that the coin is fair. What does this ratio\nalone suggest about whether or not your friend is cheating you?'''\n\n'''Let\u2019s say H 1 is the hypothesis that the coin is in fact a trick coin, and\nH 2 is the hypothesis that it is fair. If the coin is indeed a trick coin, the\nprobability of getting 10 heads in a row is 1, so we know that:'''\n\nlike1 = 1\nlike2 = .5**10\n\n# bayes factor\nbf = like1\/like2\n\nprint(f'This means that, given the Bayes factor alone, it is {bf} times more \\\nlikely that the coin is a trick coin.')","55c0bb8a":"'''Now imagine three cases: that your friend is a bit of a prankster, that\nyour friend is honest most of the time but can occasionally be sneaky, and\nthat your friend is very trustworthy. In each case, estimate some prior\nodds ratios for your hypothesis and compute the posterior odds.'''\n\n'''This is a bit subjective, but let\u2019s make some estimates. We need to\ncome up with three different prior odds ratios. For each case we just\nmultiply the prior odds by the Bayes factor from the previous question\nto get our posterior.\nBeing a prankster means your friend is more likely than not to\ntrick you, so we\u2019ll set O(H 1 ) = 10.'''\n\nprior1 = 10\n\nprint(f'Then our posterior odds becomes {bf*prior1}')\n\n'''If your friend is mostly honest but can be sneaky, you wouldn\u2019t be\nthat surprised if he was tricking you, but don\u2019t expect it, so we\u2019ll make\nthe prior odds O(H 1 ) = 1\/4'''\n\nprior1 = 1\/4\n\nprint(f'Then our posterior odds becomes {bf*prior1}')\n\n'''If you really trust your friend, you might want to put the prior\nodds very low for cheating. Prior odds here might be O(H 1 ) = 1\/10,000,\nwhich gives you a posterior odds of roughly 1\/10, meaning you still\nthink it\u2019s 10 times more likely that the coin is fair than that your friend\nis cheating.'''\n\nprior1 = 1\/10**4\n\nprint(f'Then our posterior odds becomes {bf*prior1}')\n","a90346e8":"prior_odds = 1\/10000\n\nfor i in range(20):\n    bf = 1\/(.5 ** i)\n    if bf * prior_odds >= 1.5:\n        print(f'{i} tosses make sure that friend is tricking me, as posterior odds becomes {bf * prior_odds}')  \n        break","45fdff54":"'''Another friend of yours also hangs out with this same friend and,\nafter only four weeks of the coin landing on heads, feels certain you\u2019re\nboth being cheated. This confidence implies a posterior odds of about\n100. What value would you assign to this other friend\u2019s prior belief that\nthe first friend is a cheater?'''\n\npost_odd = 100\nlike1 = 1\nlike2 = .5 ** 4\nbf = like1\/like2\n\nprior_odds = post_odd \/ bf\n\nprint(f'Other friend\u2019s prior belief that the first friend is a cheater is {prior_odds}')","f94c6df8":"# h1 : Psychic h2: natural\nprior1 = 9\/10\nprior2 = 1\/6\n\n'''The first hypothesis, H 1 , represents your belief that the die is fair, and that your friend is not\npsychic. If the die is fair, there is a 1 in 6 chance of guessing the result correctly. The second\nhypothesis, H 2 , represents your friend\u2019s belief that they can, in fact, predict the outcome of a die roll 90 percent of the time and is therefore given a 9\/10 ratio. Next we need some data to start testing\ntheir claim. Your friend rolls the die 10 times and correctly guesses the outcome of the roll 9 times.\n\nComparing Likelihoods:\n\nAs we often have in previous chapters, we\u2019ll start by looking at the Bayes factor, assuming for now\nthat the prior odds for each hypothesis are equal. We\u2019ll formulate our likelihood ratio as: so that our results will tell us how many times better (or worse) your friend\u2019s claim of being\npsychic explains the data than your hypothesis does. For this example, we\u2019ll use the variable BFfor\n\u201cBayes factor\u201d in our equations for brevity. Here is our result, taking into account the fact that your\nfriend correctly predicted 9 out of 10 rolls:'''\nlk1, lk2 = (prior1)**9 * (1-prior1), (prior2)**9 * (1-prior2)\n\nbf = lk1 \/lk2\n\nprint(f'Our likelihood ratio shows that the friend-being-psychic hypothesis explains the data {bf} \\\ntimes better than the hypothesis that your friend is just lucky. This is a bit concerning. According to \\\nthe Bayes factor chart we saw in earlier chapters, this means we should be nearly certain that H 2 is \\\ntrue and your friend is psychic. Unless you\u2019re already a deep believer in the possibility of psychic \\\npowers, something seems very wrong here.')","8df40862":"'''Incorporating Prior Odds\nIn most cases in this book where the likelihood alone gives us strange results, we can solve the\nproblem by including our prior probabilities. Clearly, we don\u2019t believe in our friend\u2019s hypothesis\nnearly as strongly as we believe in our own, so it makes sense to create a strong prior odds in favor\nof our hypothesis. We can start by simply setting our odds ratio high enough that it cancels out the\nextreme result of the Bayes factor, and see if this fixes our problem:'''\n\nprior_odds = 1\/bf\n\n'''Now, when we work out our full posterior odds, we find that we are, once again, unconvinced that\nyour friend is psychic:'''\n\npost_odd = prior_odds * bf\n\nprint(f'Now post odd is : {post_odd}')","94774ac5":"'''For now, it looks like prior odds have once again saved us from a problem that occurred when we\nlooked only at the Bayes factor.\nBut suppose your friend rolls the die five more times and successfully predicts all five outcomes.\nNow we have a new set of data, D 15 , which represents 15 rolls of a die, 14 of which your friend\nguessed accurately. Now when we calculate our posterior odds, we see that even our extreme prior\nis of little help:'''","c43595b0":"lk1, lk2 = (prior1)**14 * (1-prior1), (prior2)**14 * (1-prior2)\n\nbf = lk1 \/lk2\n\npost_odds = prior_odds * bf \n\nprint(f'Using our existing prior, with just five more rolls of the die, we have posterior odds of {post_odds} \\\nwhich means we\u2019re back to being nearly certain that your friend is truly psychic!')","8053593e":"prior_odds = 1\/1000\n\nlike1, like2 = (prior1)**9 * (1-prior1), (prior1)**9 * (1-prior1)\n\npost_odds = prior_odds * like1\/like2\n\nprint(f'According to this calculation, our posterior odds are the same as our prior odds, O(H 2 )\u2032. This \\\nhappens because our two likelihoods are the same. In other words, P(D 15 | H 2 ) = P(D 15 | H 3 ). For both \\\nhypotheses, the likelihood of your friend correctly guessing the outcome of the die roll is exactly the \\\nsame for the loaded die because the probability each assigns to success is the same. This means that \\\nour Bayes factor will always be 1.')","2e05cb4b":"like1 = (prior1)**9 * (1-prior1)\nbf1 = like1\/1\n\n'''Because you refuse to believe anything other than that your friend is cheating, the probability of\nwhat you observe is, and will always be, 1. Even though the data is exactly as we would expect in\nthe case of your friend being psychic, we find our beliefs explain the data 26 times as well. Your\nfriend, deeply determined to change your stubborn mind, persists and rolls 100 times, getting 90\nguesses right and 10 wrong. Our Bayes factor shows something very strange that happens:'''\n\nlike1 = (prior1)**90 * (1-prior1)**10\nbf2 = like1\/1\n\nprint(f'Bayes factor gets to {bf2} from {bf1}, that is {bf2\/bf1} times decay. So if one is stubborn about the belief, the \\\narguement (that is \\\nmore date will worsen your position. So next time do not argue to prove your point in case the other one is stubborn \\\nabout the his belief.)')","03e7c809":"'''When two hypotheses explain the data equally well, one way to change\nour minds is to see if we can attack the prior probability. What are some\nfactors that might increase your prior belief in your friend\u2019s psychic\npowers?'''\n\nprint('Answer: Well, answer could be different for different people. Idea is to check psychic power. SO may be \\\n      I would ask if he can make predictions about some weird stuff. Say some arbitrary person like tea or not.')","6e8e7eea":"'''An experiment claims that when people hear the word Florida, they think of the\nelderly and this has an impact on their walking speed. To test this, we have two groups of 15\nstudents walk across a room; one group hears the word Florida and one does not.\nAssume H 1 = the groups don\u2019t move at different speeds, and H 2 = the Florida group is slower\nbecause of hearing the word Florida. Also assume:\n\nThe experiment shows that H 2 has a Bayes factor of 19. Suppose someone is unconvinced by\nthis experiment because H 2 had a lower prior odds. What prior odds would explain someone\nbeing unconvinced and what would the BF need to be to bring the posterior odds to 50 for\nthis unconvinced person?\nNow suppose the prior odds do not change the skeptic\u2019s mind. Think of an alternate H 3 that\nexplains the observation that the Florida group is slower. Remember if H 2 and H 3 both\nexplain the data equally well, only prior odds in favor of H 3 would lead someone to claim H 3 is\ntrue over H 2 , so we need to rethink the experiment so that these odds are decreased. Come\nup with an experiment that could change the prior odds in H 3 over H 2 .'''\n\n\n'''This question comes from an actual paper, \u201cAutomaticity of Social\nBehavior.\u201d 1 If the experiment seems questionable, you\u2019re not alone.\n\nIf you were unconvinced, we\u2019ll say that means prior odds must be\nabout 1\/19 to negate the results. In order to have a posterior odds of\n50, you would need: bf = 19*50 = 950.\n\nIt is entirely possible that the second group was on average slower. With\nonly 15 participants, it\u2019s not hard to imagine that the group hearing the\nword Florida just happened to include a higher number of shorter peo-\nple who might walk a short distance in a longer time. To be convinced\nI would need to, at minimum, see this experiment reproduced many\ntimes with many different groups of people to ensure that it wasn\u2019t just\nchance that led the group hearing the word Florida to be slower.\n'''","6ad35f65":"prior1 = 1\/2\nprior2 = 1\/20\n\nlike1, like2 = prior1**24 * (1-prior1)**76, prior2**24 * (1-prior2)**76\n\nbf = like1\/like2\n\nprint(f'Our Bayes factor tells us that H 1 , the attendant\u2019s hypothesis, explains the data {bf} times as well \\\nas H 2 , which means that the attendant\u2019s hypothesis (that the probability of getting a prize when \\\npicking up a duck is 0.5) is the more likely one.')","4d452ccc":"print(f'This should immediately seem strange. Clearly, the probability of getting only 24 prizes out of a \\\ntotal of 100 ducks seems really unlikely if the true probability of a prize is 0.5. In fact, the prob of this is \\\n{binom.pmf(24, 100, .5)}')","24118658":"'''As you can see, the probability of getting 24 or fewer prizes if the true probability of a prize is 0.5 is\nextremely low; expanding it out to the full decimal values, we get a probability of\n0.00000009050013! Something is definitely up with H 1 . Even though we don\u2019t believe the\nattendant\u2019s hypothesis, it still explains the data much better than the customer\u2019s.\nSo what\u2019s missing? In the past, we\u2019ve often found that the prior probability usually matters a lot\nwhen the Bayes factor alone doesn\u2019t give us an answer that makes sense. But as we saw in Chapter\n18, there are cases in which the prior isn\u2019t the root cause of our problem. In this case, using the\nfollowing equation seems reasonable, since we don\u2019t have a strong opinion either way: p(h2\/h1) =1.\n\nBut maybe the problem here is that you have a preexisting mistrust in carnival games. Because the\nresult of the Bayes factor favors the attendant\u2019s hypothesis so strongly, we\u2019d need our prior odds to\nbe at least 653 to get a posterior odds that favors the customer\u2019s hypothesis: p(h2\/h1) = 653\n\nThat\u2019s a really deep distrust of the fairness of the game! There must be some problem here other\nthan the prior.'''\n\n'''One obvious problem is that, while it seems intuitively clear that the attendant is wrong in his\nhypothesis, the customer\u2019s alternative hypothesis is just too extreme to be right, either, so we have\ntwo wrong hypotheses. What if the customer thought the probability of winning was 0.2, rather\nthan 0.05? We\u2019ll call this hypothesis H 3 . Testing H 3 against the attendant\u2019s hypothesis radically\nchanges the results of our likelihood ratio:'''\n\nlike3 = .2**24 * .8**76\n\nbf = like3\/like1\n\nprint(f'Here we see that H 3 explains the data wildly better than H 1 . With a Bayes factor of {bf}, we can  \\\nbe certain that H 1 is far from the best hypothesis for explaining the data we\u2019ve observed, \\\nbecause H 3 blows it out of the water. The trouble we had in our first hypothesis test was that the \\\ncustomer\u2019s belief was a far worse description of the event than the attendant\u2019s belief. As we can see,\\\nthough, that doesn\u2019t mean the attendant was right. When we came up with an alternative \\\nhypothesis, we saw that it was a much better guess than either the attendant\u2019s or the customer\u2019s. \\\nOf course, we haven\u2019t really solved our problem. What if there\u2019s an even better hypothesis out \\\nthere?')","8b92082c":"hypothesis = np.arange(0,1,.01)[1:]\n\ndef bayes_factor(bottom):\n    fctors = []\n    for i in hypothesis:\n        like1, like2 = bottom**24 * (1-bottom)**76, i**24 * (1-i)**76\n        bf = like2\/like1\n        fctors.append(bf)\n    return fctors\n        \nbfs = bayes_factor(.5)\nplt.plot(hypothesis, bfs)\n\nprint(f'Max of Bayes factors is {np.max(bfs)} for a hypothesis {hypothesis[np.argmax(bfs)]}. The binomial distribution gives the \\\nprobability of this hypothesis to be {binom.pmf(24,100,.24)}.\\n')","37f277b3":"priors = np.where((hypothesis <= .3) & (hypothesis >= .2), .001, 1)\nplt.plot(hypothesis, priors)","5d7c131f":"posterior = bfs*priors\nplt.plot(hypothesis, posterior)","d83e4a1b":"prob_posterior = posterior\/sum(posterior)\nplt.plot(hypothesis, prob_posterior)","baef274b":"print(f'As we can see, the probability that the prize rate is lower than the attendant\u2019s hypothesis is nearly \\\n{sum(prob_posterior[prob_posterior < .5])}. That is, we can be almost certain that the attendant is overstating the true prize rate.')","ac7af7e0":"print(f'We can also calculate the expectation of our distribution and use this result as our estimate for the \\\ntrue probability. Recall that the expectation is just the sum of the estimates weighted by their value: \\\n{sum(prob_posterior * hypothesis)}')","7842f3c2":"print(f'Of course, we can see our distribution is a bit atypical, with a big gap in the middle, so we might \\\nwant to simply choose the most likely estimate, which is : {hypothesis[np.argmax(prob_posterior)]}')","4e64ca63":"b = beta(24, 76)\nx = np.linspace(0,1, 1000)\nplt.plot(hypothesis, b.pdf(hypothesis)\/sum(b.pdf(hypothesis)), label='Normalized Beta(24,76)')\nplt.plot(hypothesis, bfs\/sum(bfs), label='Normalized BFS')\nplt.axvline(.24)\nplt.legend()","07ea5f32":"b = beta(24+1, 76+1)\nx = np.linspace(0,1, 1000)\nplt.plot(hypothesis, b.pdf(hypothesis)\/sum(b.pdf(hypothesis)), label='Normalized Beta(24+1,76+1)')\nplt.plot(hypothesis, bfs\/sum(bfs), label='Normalized BFS')\nplt.axvline(.24)\nplt.legend()","4d95ec64":"'''Our Bayes factor assumed that we were looking at H 1 : P(prize) = 0.5. This allowed us\nto derive a version of the beta distribution with an alpha of 1 and a beta of 1. Would it matter\nif we chose a different probability for H 1 ? Assume H 1 : P(prize) = 0.24, then see if the resulting\ndistribution, once normalized to sum to 1, is any different than the original hypothesis.'''\nbfs1 = bayes_factor(.24)\n\nplt.plot(hypothesis, bfs\/sum(bfs), label='P(prize) = 0.5')\nplt.scatter(hypothesis, bfs1\/sum(bfs1), label='P(prize) = 0.24')\nplt.legend()","948d952f":"plt.plot(hypothesis, bfs, label='P(prize) = 0.5')\nplt.axvline(.24)","fdfa2e58":"\nplt.plot(hypothesis, bfs1, label='P(prize) = 0.24')\nplt.axvline(.24)","26de4385":"'''Write a prior for the distribution in which each hypothesis is 1.05\ntimes more likely than the previous hypothesis (assume our dx remains\nthe same).'''\npriors = np.array([1.05**i for i in range(len(hypothesis))])\n\nposterior = bfs * priors\nprob_posterior = posterior\/sum(posterior)\nplt.plot(hypothesis, prob_posterior)\nplt.scatter(hypothesis, bfs\/sum(bfs))","426da4e0":"From this, if you absolutely had to draw a conclusion about whether the die was loaded or not, your\nbest bet would be to say that it is indeed loaded. However, a posterior odds of less than 2 is not\nparticularly strong evidence in favor of H 1 . If you really wanted to know whether or not the die was\nloaded, you would need to roll it a few more times until the evidence in favor of one hypothesis or\nthe other was great enough for you to make a stronger decision.\nNow let\u2019s look at a second example of using the Bayes factor to determine the strength of our\nbeliefs.","863baf99":"Following code is credited to,\nhttps:\/\/github.com\/Montanaz0r\/Bayesian-Statistics-The-Fun-Way\/blob\/master\/Bayesian%20Statistics%20The%20Fun%20Way%20-%20Python%20Solutions%20%23%20CHAPTER%2015.ipynb","274a833e":"# IS THE CARNIVAL GAME REALLY FAIR?\nSuppose you\u2019re at a carnival. While walking through the games, you notice someone arguing with a\ncarnival attendant near a pool of little plastic ducks. Curious, you get closer and hear the player\nyelling, \u201cThis game is rigged! You said there was a 1 in 2 chance of getting a prize and I\u2019ve picked up\n20 ducks and only received one prize! It looks to me like the chance of getting a prize is only 1 in\n20!\u201d","dffee30b":"We can treat each of these variants as a separate parameter we\u2019re trying to estimate. In order to\narrive at a posterior distribution for each, we need to combine both their likelihood distribution\nand prior distribution. We\u2019ve already decided that the prior for these distributions should be\nBeta(3,7), representing a relatively weak belief in what possible values we expect the conversion\nrate to be, given no additional information. We say this is a weak belief because we don\u2019t believe\nvery strongly in a particular range of values, and consider all possible rates with a reasonably high\nprobability. For the likelihood of each, we\u2019ll again use the beta distribution, making \u03b1 the number of\ntimes the link was clicked through and \u03b2 the number of times it was not.\nRecall that:\n\nBeta(\u03b1 posterior , \u03b2 posterior ) = Beta(\u03b1 prior + \u03b1 likelihood , \u03b2 prior + \u03b2 likelihood )\n\nVariant A will be represented by Beta(36+3,114+7) and variant B by Beta(50+3,100+7). Figure 15-\n2 shows the estimates for each parameter side by side.","8ad0576f":"This is a continuation of the notebook, https:\/\/www.kaggle.com\/bhavinmoriya\/bayesian-statistics-the-fun-way-by-will-kurt\n\n# Imports","1de5cbf1":"As we can see, we get a very strange distribution of possible beliefs. We have reasonable confidence\nin the values between 0.15 and 0.2 and between 0.3 and 0.35, but find the range between 0.2 and 0.3 to be extremely unlikely. But this distribution is an honest representation of the strength of\nbelief in each hypothesis, given what we\u2019ve learned about the duck game manufacturing process.\nWhile this visualization is helpful, we really want to be able to treat this data like a true probability\ndistribution. That way, we can ask questions about how much we believe in ranges of possible\nhypotheses and calculate the expectation of our distribution to get a single estimate for what we\nbelieve the hypothesis to be.","83d399d7":"# Considering Alternative Hypotheses\nThe issue here is that we don\u2019t want to believe your friend is psychic. If you found yourself in this\nsituation in real life, it\u2019s likely you would quickly come to some alternative conclusion. You might\ncome to believe that your friend is using a loaded die that rolls a certain value about 90 percent of\nthe time, for example. This represents a third hypothesis. Our Bayes factor is looking at only two\npossible hypotheses: H 1 , the hypothesis that the die is fair, and H 2 , the hypothesis that your friend is\npsychic.\nOur Bayes factor so far tells us that it\u2019s far more likely that our friend is psychic than that they are\nguessing the rolls of a fair die correctly. When we think of the conclusion in those terms, it makes\nmore sense: with these results, it\u2019s extremely unlikely that the die is fair. We don\u2019t feel comfortable\naccepting the H 2 alternative, because our own beliefs about the world don\u2019t support the idea\nthat H 2 is a realistic explanation.\nIt\u2019s important to understand that a hypothesis test compares only two explanations for an event,\nbut very often there are countless possible explanations. If the winning hypothesis doesn\u2019t convince\nyou, you could always consider a third one.\nLet\u2019s look at what happens when we compare H 2 , our winning hypothesis, with a new\nhypothesis, H 3 : that the die is rigged so it has a certain outcome 90 percent of the time.\nWe\u2019ll start with a new prior odds about H 2 , which we\u2019ll call O(H 2 )\u2032 (the tick mark is a common\nnotation in mathematics meaning \u201clike but not the same as\u201d). This will represent the odds of H 2 \/H 3 .\nFor now, we\u2019ll just say that we believe it\u2019s 1,000 times more likely that your friend is using a loaded\ndie than that your friend is really psychic (though our real prior might be much more extreme).\nThat means the prior odds of your friend being psychic is 1\/1,000. If we reexamine our new\nposterior odds, we get the following interesting result:","2fbe6cf6":"Now we\u2019ve used the Bayes factor to come up with a range of probabilistic estimates for the true\npossible rate of winning a prize in the duck game. This means that we\u2019ve used the Bayes factor as a\nform of parameter estimation!","ef5df845":"Now we can see that the two distributions are perfectly aligned. Chapter 5 mentioned that the beta\ndistribution was difficult to derive from our basic rules of probability. However, by using the Bayes\nfactor, we\u2019ve been able to empirically re-create a modified version of it that assumes a prior of\nBeta(1,1). And we did it without any fancy mathematics!","b4c45c28":"# A PSYCHIC FRIEND ROLLING DICE\nSuppose your friend tells you they can predict the outcome of a six-sided die roll with 90 percent\naccuracy because they are psychic. You find this claim difficult to believe, so you set up a hypothesis\ntest using the Bayes factor. As in the Mystic Seer example, you have two hypotheses you want to\ncompare:","8498fbd4":"# ARGUING WITH RELATIVES AND CONSPIRACY THEORISTS\nAnyone who has argued with relatives over a holiday dinner about politics, climate change, or their\nfavorite movies has experienced firsthand a situation in which they are comparing two hypotheses\nthat both explain the data equally well (to the person arguing), and only the prior remains. How can\nwe change someone else\u2019s (or our own) beliefs even when more data doesn\u2019t change anything?\nWe\u2019ve already seen that if you compare the belief that your friend has a loaded die and the belief\nthat they are psychic, more data will do nothing to change your beliefs about your friend\u2019s claim.\nThis is because both your hypothesis and your friend\u2019s hypothesis explain the data equally well. In\norder for your friend to convince you that they are psychic, they have to alter your prior beliefs. For\nexample, since you\u2019re suspicious that the die might be loaded, your friend could then offer to let you\nchoose the die they roll. If you bought a new die and gave it to your friend, and they continued to\naccurately predict their rolls, you might start to be convinced. This same logic holds anytime you\nrun into a problem where two hypotheses equally explain the data. In these cases, you must then\nsee if there\u2019s anything you can change in your prior.\nSuppose after you purchase the new die for your friend and they continue to succeed, you still don\u2019t\nbelieve them; you now claim that they must have a secret way of rolling. In response, your friend\nlets you roll the die for them, and they continue to successfully predict the rolls\u2014yet you still don\u2019t\nbelieve them. In this scenario, something else is happening beyond just a hidden hypothesis. You\nnow have an H 4 \u2014that your friend is completely cheating\u2014and you won\u2019t change your mind. This\nmeans that for any D n , P(D n | H 4 ) = 1. Clearly we\u2019re out of Bayesian territory since you\u2019ve essentially\nconceded that you won\u2019t change your mind, but let\u2019s see what happens mathematically if your\nfriend persists in trying to convince you.\nLet\u2019s look at how these two explanations, H 2 and H 4 , compete using our data D 10 with 9 correct\npredictions and 1 missed prediction. The Bayes factor for this is:","000d6945":"Except for the scale of the y-axis, the plot looks nearly identical to the original plot of our likelihood\nratios! In fact, if we do a few simple tricks, we can get these two plots to line up perfectly. If we scale\nour beta distribution by the size of our dx and normalize our bfs , we can see that these two\ndistributions get quite close as above.\n\nThere seems to be only a slight difference now. We can fix it by using the weakest prior that\nindicates that getting a prize and not getting a prize are equally likely\u2014that is, by adding 1 to both\nthe alpha and beta parameters, as shown below,","0d04705e":"Here we see the only difference is the y-axis. Choosing a weaker or\nstronger hypothesis changes only the scale of the distribution, not the\nshape of it. If we normalize and plot these two together, we see they are\nidentical","44ff8f6b":"These results correspond quite well to our everyday intuition; after all, prior odds aside, each\nhypothesis explains the data we\u2019ve seen equally well. That means that if, before considering the\ndata, we believe one explanation is far more likely than the other, then no amount of new evidence\nwill change our minds. So we no longer have a problem with the data we observed; we\u2019ve simply\nfound a better explanation for it.\nIn this scenario, no amount of data will change our mind about believing H 3 over H 2 because both\nexplain what we\u2019ve observed equally well, and we already think that H 3 is a far more likely\nexplanation than H 2 . What\u2019s interesting here is that we can find ourselves in this situation even if\nour prior beliefs are entirely irrational. Maybe you\u2019re a strong believer in psychic phenomena and\nthink that your friend is the most honest person on earth. In this case, you might make the prior\nodds O(H 2 )\u2032 = 1,000. If you believed this, no amount of data could convince you that your friend is\nusing a loaded die.\nIn cases like this, it\u2019s important to realize that if you want to solve a problem, you need to be willing\nto change your prior beliefs. If you\u2019re unwilling to let go of unjustifiable prior beliefs, then, at the\nvery least, you must acknowledge that you\u2019re no longer reasoning in a Bayesian\u2014or logical\u2014way\nat all. We all hold irrational beliefs, and that\u2019s perfectly okay, so long as we don\u2019t attempt to use\nBayesian reasoning to justify them.","49b62376":"# PREDICTING EMAIL CONVERSION RATES\nTo understand how the beta distribution changes as we gain information, let\u2019s look at another\nconversion rate. In this example, we\u2019ll try to figure out the rate at which your subscribers click a\ngiven link once they\u2019ve opened an email from you. Most companies that provide email list\nmanagement services tell you, in real time, how many people have opened an email and clicked the\nlink.\n\nOur data so far tells us that of the first five people that open an email, two of them click the\nlink. We have a beta distribution for this data.","81e9f64f":"As you see more data reduces the confidence interval.","d65d03f2":"What we see here is that in 96 percent of the 100,000 trials, variant B was superior. We can imagine\nthis as looking at 100,000 possible worlds. Based on the distribution of possible conversion rates\nfor each variant, in 96 percent of the worlds variant B was the better of the two. This result shows\nthat, even with a relatively small number of observed samples, we have a pretty strong belief that B\nis the better variant. If you\u2019ve ever done t-tests in classical statistics, this is roughly equivalent\u2014if\nwe used a Beta(1,1) prior\u2014to getting a p-value of 0.04 from a single-tailed t-test (often considered\n\u201cstatistically significant\u201d). However, the beauty of our approach is that we were able to build this\ntest from scratch using just our knowledge of probability and a straightforward simulation.","5808f209":"# IS THERE A FAIR PRIOR TO USE WHEN WE KNOW NOTHING?\nThere are certain schools of statistics that teach that you should always add 1 to both \u03b1 and \u03b2 when\nestimating parameters with no other prior. This corresponds to using a very weak prior that holds\nthat each outcome is equally likely: Beta(1,1). The argument is that this is the \u201cfairest\u201d (i.e.,\nweakest) prior we can come up with in the absence of information. The technical term for a fair\nprior is a noninformative prior.","38f47e21":"As you can see, the lower the combined \u03b1 + \u03b2, the wider our distribution. The problem now is that\neven the most liberal option we have, Beta(1,41), seems a little too pessimistic, as it puts a lot of our\nprobability density in very low values. We\u2019ll stick with this distribution nonetheless, since it is\nbased on the 2.4 percent conversion rate in the data from the email provider, and is the weakest of\nour priors. Being a \u201cweak\u201d prior means it will be more easily overridden by actual data as we collect\nmore of it. A stronger prior, like Beta(5,200), would take more evidence to change (we\u2019ll see how\nthis happens next). Deciding whether or not to use a strong prior is a judgment call based on how\nwell you expect the prior data to describe what you\u2019re currently doing. As we\u2019ll see, even a weak\nprior can help keep our estimates more realistic when we\u2019re working with small amounts of data.","42bb0ba2":"In most of our previous problems, we\u2019ve corrected nonintuitive posterior results by adding a sane\nprior. We\u2019ve added a pretty extreme prior against your friend being psychic, but our posterior odds\nare still strongly in favor of the hypothesis that they\u2019re psychic.\nThis is a major problem, because Bayesian reasoning should align with our everyday sense of logic.\nClearly, 15 rolls of a die with 14 successful guesses is highly unusual, but it\u2019s unlikely to convince\nmany people that the guesser truly possesses psychic powers! However, if we can\u2019t explain what\u2019s\ngoing on here with our hypothesis test, it means that we really can\u2019t rely on our test to solve our\neveryday statistical problems.","cd3db7fc":"So, as you can see, the weak prior provides the widest range of possibility, the very strong fair prior remains quite certain that the coin is\nfair, and the strong 70 percent prior still leans toward a higher range of\npossible values for the true rate of the coin.","197b9e94":"So, the next time you argue with a relative over politics or conspiracy theories, you should ask\nthem: \u201cWhat evidence would change your mind?\u201d If they have no answer to this, you\u2019re better off\nnot trying to defend your views with more evidence, as it will only increase your relative\u2019s certainty\nin their belief.","1cb8627e":"# FROM PARAMETER ESTIMATION TO HYPOTHESIS TESTING: BUILDING A BAYESIAN A\/B TEST\n\nHere, we\u2019re going to build our first hypothesis test, an A\/B test. Companies often use A\/B\ntests to try out product web pages, emails, and other marketing materials to determine which will\nwork best for customers. In this chapter, we\u2019ll test our belief that removing an image from an email\nwill increase the click-through rate against the belief that removing it will hurt the click-through\nrate.\nSince we already know how to estimate a single unknown parameter, all we need to do for our test\nis estimate both parameters\u2014that is, the conversion rates of each email. Then we\u2019ll use R to run a\nMonte Carlo simulation and determine which hypothesis is likely to perform better\u2014in other\nwords, which variant, A or B, is superior. A\/B tests can be performed using classical statistical\ntechniques such as t-tests, but building our test the Bayesian way will help us understand each part\nof it intuitively and give us more useful results as well.","9280f4f7":"# FROM THE BAYES FACTOR TO PARAMETER ESTIMATION\nLet\u2019s take a moment to look at our likelihood ratios alone again. When we weren\u2019t using a prior\nprobability for any of the hypotheses, you might have felt that we already had a perfectly good\napproach to solving this problem without needing the Bayes factor. We observed 24 ducks with\nprizes and 76 ducks without prizes. Couldn\u2019t we just use our good old beta distribution to solve this\nproblem?"}}