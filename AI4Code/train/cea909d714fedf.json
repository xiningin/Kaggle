{"cell_type":{"359f41c2":"code","94d36dd4":"code","fd0063dc":"code","4464208a":"code","38c82635":"code","4e7f8da0":"code","273e309e":"markdown","0d6ad143":"markdown","a270d843":"markdown","ece26d61":"markdown","335cdc92":"markdown"},"source":{"359f41c2":"import numpy as np\nimport pandas as pd\nimport datetime\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Lambda, LeakyReLU\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler","94d36dd4":"train = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/train.csv\")\nDig = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/Dig-MNIST.csv\")\ntrain_data = train.append(Dig)\ny_train = np.array(train_data[\"label\"])\ny_train = to_categorical(y_train)\nx_train = train_data.drop(\"label\",axis=1).values\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_train.shape, y_train.shape","fd0063dc":"X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.10, random_state=0) \n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,  #0~1\u5185\u306b\n                                   rotation_range = 10,  #\u56de\u8ee2\u7bc4\u56f2\n                                   width_shift_range = 0.25,  #\u6c34\u5e73\u30b7\u30d5\u30c8\n                                   height_shift_range = 0.25,  #\u5782\u76f4\u30b7\u30d5\u30c8\n                                   shear_range = 0.1,  #\u53cd\u6642\u8a08\u56de\u308a\u306e\u30b7\u30a2\u30fc\u89d2\u5ea6\n                                   zoom_range = 0.25,  #\u30e9\u30f3\u30c0\u30e0\u306b\u30ba\u30fc\u30e0\u3059\u308b\u7bc4\u56f2\n                                   horizontal_flip = False)  #\u6c34\u5e73\u65b9\u5411\u306b\u5165\u529b\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u53cd\u8ee2\n\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255) ","4464208a":"model = Sequential()\nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64,  (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"))\n          \nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n          \nmodel.add(Conv2D(128, (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128,  (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"))       \n          \nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))  \n          \nmodel.add(Conv2D(256, (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\n          \nmodel.add(Conv2D(128, (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\n          \nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n          \nmodel.add(Flatten())        \nmodel.add(Dense(256,activation='relu',name='dense1'))\nmodel.add(LeakyReLU(alpha=0.1))          \nmodel.add(BatchNormalization())\nmodel.add(Dense(10,activation='softmax'))","38c82635":"\"\"\"initial_learningrate=1e-3\n\ndef lr_decay(epoch):\n    if epoch < 5:\n        return initial_learningrate\n    else:\n        return initial_learningrate * 0.99 ** epoch\"\"\"\n\ninitial_learningrate=2e-3\n\ndef lr_decay(epoch):\n    return initial_learningrate * 0.99 ** epoch\n    \nmodel.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=initial_learningrate), metrics=[\"acc\"])\nmodel.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=2048),\n                    steps_per_epoch=300,\n                    epochs=10,\n                    callbacks=[LearningRateScheduler(lr_decay,verbose=1)],\n                    validation_data=valid_datagen.flow(X_valid,Y_valid),\n                    validation_steps=50,  \n                    verbose=1)","4e7f8da0":"\nX_test = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/test.csv\")\nX_test = X_test.drop(\"id\", axis=1).values\nsubmission = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv\")\n\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\nX_test = X_test.astype(np.float32)\/ 255\n\n\npredictions = model.predict_classes(X_test)\n\n\nsubmissions=pd.DataFrame({\"id\": submission[\"id\"], \"label\": predictions})\nsubmissions.to_csv(\"sUbmission.csv\", index=False)\n\nprint(\"FINISH\")","273e309e":"5, Create Submisson","0d6ad143":"3, Model","a270d843":"1, Train Data \n\ntrain.csv + Dig_MNIST.csv","ece26d61":"4, Model Run","335cdc92":"2, Preprocessing Image"}}