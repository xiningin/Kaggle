{"cell_type":{"1eed91f9":"code","5a8f8855":"code","7ee5f95c":"code","f5511dfb":"code","23016633":"code","1b503ca3":"code","4921c9e2":"code","9326bbd8":"code","e883e591":"code","f2c168e2":"code","ab6bc411":"code","285d60a6":"code","a508fc02":"code","3ae5bfe7":"code","5c022d05":"code","3c9d7c98":"code","81187fa3":"code","792130ab":"code","655118f7":"code","4321eeb9":"code","56785335":"code","266e1975":"code","cdd1a63d":"code","96f97f3b":"code","817fbd3b":"code","539115ba":"code","f8ad2cb0":"code","f1deb8b4":"code","0e13c7b2":"code","46c0ee10":"code","1eeaa934":"code","3cec2b39":"code","99200186":"code","77953c4a":"code","b9585c7e":"code","8ffde781":"code","66a9610c":"code","9f62f316":"code","47fca8e9":"code","83de4ebb":"code","18774ca7":"code","3a51b5b7":"code","c4df716a":"code","d08d6fc4":"code","8fe199c1":"code","290f1388":"code","c3722ec7":"code","e4eb9972":"code","824d6bb9":"code","ab334ab9":"code","d4993281":"code","a77920e3":"markdown","7ab41a93":"markdown","236b1202":"markdown","6f614a32":"markdown","7c92a6da":"markdown","7e2f89e8":"markdown","55999bcd":"markdown","3407e28c":"markdown","b412b6bc":"markdown","39513841":"markdown","8e219b68":"markdown","026f962c":"markdown","6f2dc397":"markdown","d763f6e6":"markdown","ebee0ea3":"markdown","f2102c88":"markdown","275e3601":"markdown","597b70f4":"markdown","a2edd8e1":"markdown","eb8f5d61":"markdown","7158f7ce":"markdown"},"source":{"1eed91f9":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nimport gc\n\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/shopee-code-league-20\/_DA_Marketing_Analytics'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom time import time, strftime, gmtime\n\nstart = time()\nprint(start)\n\nimport datetime\nprint(str(datetime.datetime.now()))","5a8f8855":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","7ee5f95c":"train = pd.read_csv('\/kaggle\/input\/shopee-code-league-20\/_DA_Marketing_Analytics\/train.csv')\nprint(train.shape)\ntrain","f5511dfb":"test = pd.read_csv('\/kaggle\/input\/shopee-code-league-20\/_DA_Marketing_Analytics\/test.csv')\nprint(test.shape)\ntest","23016633":"users = pd.read_csv('\/kaggle\/input\/shopee-code-league-20\/_DA_Marketing_Analytics\/users.csv')\nprint(users.shape)\nusers","1b503ca3":"train['grass_date'] = pd.to_datetime(train['grass_date']).dt.date\ntest['grass_date'] = pd.to_datetime(test['grass_date']).dt.date","4921c9e2":"train.describe().T","9326bbd8":"train.dtypes","e883e591":"users.describe().T","f2c168e2":"users.dtypes","ab6bc411":"plt.figure(figsize = (10, 10))\nsns.countplot(train['open_flag'])","285d60a6":"neg = train['open_flag'].value_counts().values[0]\npos = train['open_flag'].value_counts().values[1]\ntrain['open_flag'].value_counts(normalize = True), pos, neg","a508fc02":"plt.figure(figsize = (10, 10))\nsns.distplot(users['age'])","3ae5bfe7":"plt.figure(figsize = (10, 10))\nsns.boxplot(users['age'])","5c022d05":"lbls, freqs = np.unique(train['country_code'].values, return_counts = True)\n#print(list(zip(lbls, freqs)))\n\nplt.figure(figsize = (10, 10))\nplt.title('Train - Country Code')\nplt.pie(freqs, labels = lbls, autopct = '%1.1f%%', shadow = False, startangle = 90)\nplt.show()","3c9d7c98":"lbls, freqs = np.unique(test['country_code'].values, return_counts = True)\n#print(list(zip(lbls, freqs)))\n\nplt.figure(figsize = (10, 10))\nplt.title('Test - Country Code')\nplt.pie(freqs, labels = lbls, autopct = '%1.1f%%', shadow = False, startangle = 90)\nplt.show()","81187fa3":"plt.figure(figsize = (10, 10))\ntrain['grass_date'].hist()","792130ab":"print('***Checking Null values..***')\nfor col in train.columns:\n    #print('****' * 10, col, '****' * 10)\n    print('Train - ', col, ' : ', train[col].isnull().all())\nprint()\nfor col in test.columns:\n    #print('****' * 10, col, '****' * 10)\n    print('Test - ', col, ' : ', test[col].isnull().all())","655118f7":"for col in train.columns:\n    print('Train - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())\nprint()    \nfor col in test.columns:\n    print('Test - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())","4321eeb9":"#Another way to find the row index where the str appears\n#train[~train.applymap(lambda x: isinstance(x, (int, float)))]","56785335":"train['last_open_day'] = train['last_open_day'].replace('Never open', 0)\ntrain['last_login_day'] = train['last_login_day'].replace('Never login', 0)\ntrain['last_checkout_day'] = train['last_checkout_day'].replace('Never checkout', 0)\n\ntest['last_open_day'] = test['last_open_day'].replace('Never open', 0)\ntest['last_login_day'] = test['last_login_day'].replace('Never login', 0)\ntest['last_checkout_day'] = test['last_checkout_day'].replace('Never checkout', 0)","266e1975":"for col in ['last_open_day', 'last_login_day', 'last_checkout_day']:\n    print('Train - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())\nprint()    \nfor col in ['last_open_day', 'last_login_day', 'last_checkout_day']:\n    print('Test - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())","cdd1a63d":"for col in users.columns:\n    print('Users - ', col, ' : ', users[col].isnull().all())","96f97f3b":"for col in users.columns:\n    print(users[col].value_counts(dropna = False))","817fbd3b":"users['attr_1'].fillna(2.0, inplace = True)\nusers['attr_2'].fillna(users['attr_2'].value_counts().index[0], inplace = True)\nusers['attr_3'].fillna(users['attr_3'].value_counts().index[0], inplace = True)\nusers['domain'].fillna(users['domain'].value_counts().index[0], inplace = True)","539115ba":"median = round(users['age'].median())\nstd = users['age'].std()\noutliers = (users['age'] - median).abs() > std\nusers['age'][outliers] = np.nan\nusers['age'].fillna(median, inplace = True)","f8ad2cb0":"for col in users.columns:\n    print(users[col].value_counts(dropna = False))","f1deb8b4":"print(train.shape, test.shape)\ntrain = pd.merge(train, users, on = 'user_id')\ntest = pd.merge(test, users, on = 'user_id')\nprint(train.shape, test.shape)\ndisplay(train.head(), test.head())","0e13c7b2":"train['year'] = pd.to_datetime(train['grass_date']).dt.year\ntrain['month'] = pd.to_datetime(train['grass_date']).dt.month\ntrain['day'] = pd.to_datetime(train['grass_date']).dt.day\n\ntest['year'] = pd.to_datetime(test['grass_date']).dt.year\ntest['month'] = pd.to_datetime(test['grass_date']).dt.month\ntest['day'] = pd.to_datetime(test['grass_date']).dt.day\n\ndel train['grass_date'], test['grass_date'], train['user_id'], test['user_id'], train['row_id'], test['row_id']\ngc.collect()","46c0ee10":"target = train['open_flag'].copy()\ndel train['open_flag']\ngc.collect()","1eeaa934":"for col in train.columns:\n    if train[col].dtype == 'object' and col != 'domain':\n        train[col] = train[col].astype(np.int32)","3cec2b39":"for col in test.columns:\n    if test[col].dtype == 'object' and col != 'domain':\n        test[col] = test[col].astype(np.int32)","99200186":"train.dtypes","77953c4a":"cat_features = ['country_code', 'domain', 'year', 'month', 'day', 'attr_1', 'attr_2', 'attr_3']\nnum_features = [col for col in train.columns if col not in cat_features]\nprint(cat_features, num_features)","b9585c7e":"lbl = LabelEncoder()\nfor feature in cat_features:\n    lbl.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n    train[feature] = lbl.transform(list(train[feature].astype(str).values))\n    test[feature] = lbl.transform(list(test[feature].astype(str).values))","8ffde781":"%%time\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","66a9610c":"Xtrain, Xvalid, ytrain, yvalid = train_test_split(train, target, test_size = 0.2, random_state = 42)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","9f62f316":"import lightgbm as lgbm","47fca8e9":"pos_neg = np.sqrt(neg \/ pos)\npos_neg","83de4ebb":"params = {'num_leaves': 120,\n          'min_child_weight': 0.001,\n          'min_child_samples': 20,\n          'feature_fraction': 0.379,\n          'bagging_fraction': 0.8,\n          'min_data_in_leaf': 50,\n          'objective': 'binary',\n          'max_depth': 10,\n          'learning_rate': 0.002,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": {'auc'},\n          \"verbosity\": -1,\n          'reg_alpha': 0.389,\n          'reg_lambda': 0.648,\n          'scale_pos_weight': pos_neg,\n          'random_state': 47,\n         }","18774ca7":"def lgb_mcc_score(y_pred, data):\n    y_true = data.get_label()\n    y_pred = np.round(y_pred)\n    return 'mcc', matthews_corrcoef(y_true, y_pred), True\n\ndef lgb_mcc(preds, train_data):\n    THRESHOLD = 0.5\n    labels = train_data.get_label()\n    return 'mcc', matthews_corrcoef(labels, preds >= THRESHOLD)","3a51b5b7":"ltrain = lgbm.Dataset(Xtrain, label = ytrain, categorical_feature = cat_features)\nlvalid = lgbm.Dataset(Xvalid, label = yvalid, categorical_feature = cat_features)\n\nevals_result = {}\n\nclf = lgbm.train(params, ltrain, 12000, valid_sets = [ltrain, lvalid], \n                 feval = lgb_mcc_score, evals_result = evals_result,\n                 verbose_eval = 200, early_stopping_rounds = 1000)","c4df716a":"lgbm.plot_metric(evals_result, metric = 'mcc')","d08d6fc4":"feature_imp = pd.DataFrame(sorted(zip(clf.feature_importance(), train.columns)), columns = ['Value','Features'])\n\nplt.figure(figsize = (20, 10))\nsns.barplot(x = \"Value\", y = \"Features\", data = feature_imp.sort_values(by = \"Value\", ascending = False))\nplt.title('LightGBM Features)')\nplt.tight_layout()\nplt.show()\n#plt.savefig('lgbm_importances-01.png')","8fe199c1":"predictions = clf.predict(test, verbose = 1)","290f1388":"predictions[:10]","c3722ec7":"sample_sub = pd.read_csv('\/kaggle\/input\/shopee-code-league-20\/_DA_Marketing_Analytics\/sample_submission_0_1.csv')\nsample_sub","e4eb9972":"sample_sub['open_flag'] = np.where(predictions > 0.5, 1, 0)\nsample_sub.to_csv('.\/sample_sub_ShopeeEmail.csv', index = False)\nsample_sub","824d6bb9":"sample_sub['open_flag'].value_counts(normalize = True)","ab334ab9":"plt.figure(figsize = (10, 10))\nsns.countplot(sample_sub['open_flag'])","d4993281":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","a77920e3":"- Model run with only 'auc' as metric\n\nFrom the above feature importance chart we can see users' features attr_1 and attr_2 doesn't contribute much to the model, we can try removing them and rerun the model to see if any perf improvement.\n\n- Model with MCC metric looks more realistic with *subject_line* as major factor for opening the email which is true in most cases. We will rerun the model with *user_id* and *row_id* removed","7ab41a93":"__Country Code plot__","236b1202":"- So the 3 columns - last_open_day, last_login_day, last_checkout_day has str value in it. \n- Use Pandas.replace to change it to 0","6f614a32":"__Encoding Categorical features__","7c92a6da":"__Merge users data with train and test__","7e2f89e8":"Need to take care of the outliers in age","55999bcd":"- The dataset is clearly imbalanced, should take necessary measures to account for it.","3407e28c":"__User age Boxplot__","b412b6bc":"__Task Metric__\n\nMatthews Correlation Coefficient (MCC)\n\n- sklearn.metrics.matthews_corrcoef(y_true, y_pred, *, sample_weight=None)","39513841":"__Checking to confirm__","8e219b68":"100 - 0.881083\n200 - 0.8804\n120 - 0.881131","026f962c":"__Target Count__","6f2dc397":"- There are too many NaNs in 'attr_1'. One option is we can remove the column entirely and the other option is make the NaN values as another value like '2', so that the 'attr_1' has 3 values 0, 1, 2\n\n- 'attr_2' has very few NaNs comparitively, we can assume it to be 1 or do same as above\n\n- The NaNs in 'age' column can be imputed with mean age. Also, the there are some outlier values that needs to be taken care off - make them as NaNs and impute. \n\n- For 'attr_3' impute with most frequent value\n\n- Same for domain - most frequent value","d763f6e6":"__Change dtype to int, float or bool for Lgbm__","ebee0ea3":"Check for null values in columns","f2102c88":"__Shopee Email Campaign Analysis__\n\nThe aim of this project is to build a model that can predict whether a user opens the emails sent by Shopee. Predict 'open_flag' feature","275e3601":"__Baseline LGBM Model__","597b70f4":"- Use pd.to_numeric to convert the 'object' columns to numeric.\n- Also check all the columns for any str value","a2edd8e1":"__User age distribution__","eb8f5d61":"__Checking Users data__","7158f7ce":"__Train_Test Split__"}}