{"cell_type":{"3ad6c7c3":"code","d7f7323d":"code","60c47d61":"code","c281ea72":"code","dbb785f3":"code","a296799d":"code","ba54d89a":"code","446dae4c":"code","f5319bfd":"code","0dfbb6d0":"code","0a43fe6e":"code","26917cbf":"code","9062b2cf":"code","c7879026":"code","d314404e":"code","c11c13f6":"code","e4672a4b":"code","e56a73a2":"code","d7c02652":"code","c4859162":"code","8d536422":"code","32019908":"code","dd90c108":"markdown","244c3951":"markdown","dca373ec":"markdown","ff3edb52":"markdown","f8f19094":"markdown","fb2f175c":"markdown","7e709a34":"markdown","8f7f8a74":"markdown"},"source":{"3ad6c7c3":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport random\nfrom IPython.display import Image\nfrom PIL import Image as Image2, ImageEnhance","d7f7323d":"PATH = \"\/kaggle\/input\/applications-of-deep-learning-wustl-fall-2020\/final-kaggle-data\/\"\nPATH_TRAIN = os.path.join(PATH, \"train.csv\")\nPATH_TEST = os.path.join(PATH, \"test.csv\")\ndf_train = pd.read_csv(PATH_TRAIN)\ndf_test = pd.read_csv(PATH_TEST)\ndf_train = df_train[df_train.id != 1300]\ndf=pd.DataFrame()\ndf[\"id\"]=df_test[\"id\"].append(df_train[\"id\"])\ndf['filename'] = df[\"id\"].astype(str)+\".png\"","60c47d61":"df = df[:3]  # use smaller datasets first, in case of Kaggle webpage collasping","c281ea72":"def compute(img, min_percentile, max_percentile):\n    max_percentile_pixel = np.percentile(img, max_percentile)\n    min_percentile_pixel = np.percentile(img, min_percentile)\n\n    return max_percentile_pixel, min_percentile_pixel\n\ndef get_lightness(src):\n    hsv_image = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n    lightness = hsv_image[:,:,2].mean()\n    \n    return  lightness\n\ndef aug(src):\n    if get_lightness(src)>180:\n        print(\"The lightness of image is sufficient, no enhancement is made\")\n    max_percentile_pixel, min_percentile_pixel = compute(src, 1, 90)\n    \n    src[src>=max_percentile_pixel] = max_percentile_pixel\n    src[src<=min_percentile_pixel] = min_percentile_pixel\n\n    out = np.zeros(src.shape, src.dtype)\n    cv2.normalize(src, out, 255*0.1,255*0.9,cv2.NORM_MINMAX)\n\n    return out","dbb785f3":"# %matplotlib inline\n# from IPython.display import Image\n# PATH_image = os.path.join(PATH, '4.png')\n# Image(PATH_image)","a296799d":"for img_filename in df['filename']:\n    print(img_filename)\n    PATH_image = os.path.join(PATH, img_filename)\n    img = cv2.imread(PATH_image)\n    img_brighter=aug(img)\n    cv2.imwrite(img_filename,img_brighter)\nprint(\"Finish Enhancement\")","ba54d89a":"# Image(\".\/4.png\")","446dae4c":"# Image(\".\/10.png\")","f5319bfd":"from zipfile import ZipFile\nimport os\n\nzipObj = ZipFile('processed.zip', 'w')\n\nfor filename in os.listdir(\"\/kaggle\/working\"):\n    if filename.endswith(\".png\"):\n        zipObj.write(filename)\nzipObj.close()","0dfbb6d0":"os.chdir(r'\/kaggle\/working')\nfrom IPython.display import FileLink\nFileLink(r'processed.zip')","0a43fe6e":"PATH = \"\/kaggle\/input\/lighter-img\/\"","26917cbf":"#df = df[:20000]","9062b2cf":"# for img_filename in df['filename']:\n#     print(img_filename)\n#     PATH_image = os.path.join(PATH, img_filename)\n#     img = cv2.imread(PATH_image)\n#     kernel = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])\n#     sharpened = cv2.filter2D(img, -1, kernel)\n#     a = Image2.fromarray(sharpened)\n#     a.save(f'\/kaggle\/working\/{img_filename}')\n# print(\"Finished Sharpening\")\n","c7879026":"# Image(\"4.png\")","d314404e":"# %matplotlib inline\n# from IPython.display import Image\n# Image('\/kaggle\/working\/'+img_filename)","c11c13f6":"os.chdir(r'\/Kaggle\/input\/lighter-img\/')","e4672a4b":"os.chdir(r'\/kaggle\/working\/')\n\ndef unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=15.0, threshold=32):\n    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n    sharpened = float(amount + 1) * image - float(amount) * blurred\n    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n    sharpened = sharpened.round().astype(np.uint8)\n    if threshold > 0:\n        low_contrast_mask = np.absolute(image - blurred) < threshold\n        np.copyto(sharpened, image, where=low_contrast_mask)\n    return sharpened\n\n\nfor img_filename in df['filename']:\n    print(img_filename)\n    PATH_image = os.path.join(PATH, img_filename)\n    img = cv2.imread(PATH_image)\n    sharpened_image = unsharp_mask(img)\n    a = Image2.fromarray(sharpened_image)\n    a.save(f'\/kaggle\/working\/{img_filename}')\nprint(\"Finished Sharpening\")","e56a73a2":"# %matplotlib inline\n# from IPython.display import Image\n# Image('\/kaggle\/working\/'+'10.png')","d7c02652":"os.chdir(r'\/kaggle\/working\/')\n\nfrom zipfile import ZipFile\nimport os\n\nzipObj = ZipFile('processed.zip', 'w')\n\nfor filename in os.listdir(\"\/kaggle\/working\/\"):\n    print(filename)\n    if filename.endswith(\".png\"):\n        zipObj.write(filename)\nzipObj.close()","c4859162":"# os.chdir(r'\/kaggle\/working\/')\nfrom IPython.display import FileLink\nFileLink(r'processed.zip')","8d536422":"# cropping\n\n# os.mkdir('\/kaggle\/working\/crop\/')\n# for img_filename in df['filename']:\n#     PATH_image = os.path.join(PATH, img_filename)\n#     img = cv2.imread(PATH_image)\n#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#     gradX = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n#     gradY = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=-1)\n#     gradient = cv2.subtract(gradX, gradY)\n#     gradient = cv2.convertScaleAbs(gradient)\n#     blurred = cv2.blur(gradient, (9, 9))\n#     ret, thresh = cv2.threshold(blurred, np.mean(img), 255, cv2.THRESH_BINARY)\n#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n#     closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n#     closed = cv2.erode(closed, None, iterations=4)\n#     closed = cv2.dilate(closed, None, iterations=4)\n#     contours,hierarchy=cv2.findContours(closed,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n#     if len(contours)>0:\n#         cnt=sorted(contours,key=cv2.contourArea,reverse=True)[0]\n#         x,y,w,h=cv2.boundingRect(cnt)\n#         img=cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n#         crop = img[y:y+h, x:x+w]\n#         a = Image2.fromarray(crop)\n#         a.save(f'\/kaggle\/working\/crop\/{img_filename}')\n#     else:\n#         a = Image2.fromarray(img)\n#         a.save(f'\/kaggle\/working\/crop\/{img_filename}')\n        \n# Image(\".\/crop\/4.png\")","32019908":"# Image(\".\/crop\/4.png\")","dd90c108":"## Second method to sharpen the images.","244c3951":"## First method to sharpen the images, but this does not perform well, nor is this customizable.","dca373ec":"Did not use cropping eventually because it did not do well.","ff3edb52":"# Lightening","f8f19094":"The lighter PNG data was downloaded and re-uploaded to Kaggle.","fb2f175c":"# Sharpening","7e709a34":"Because Kaggle webpage will break when I click the output folder after the above steps, I have to produce a link for the compression file.","8f7f8a74":"# Cropping"}}