{"cell_type":{"424b6b49":"code","3d3c7738":"code","bc8235bc":"code","639053cc":"code","97749e64":"code","715f642a":"code","ff480407":"code","a86649ac":"code","ad179b48":"code","2d4c1eb9":"code","4e146cd7":"code","ce308868":"code","cb0fb223":"code","9822d0eb":"code","e8e2d87c":"code","c72841ca":"code","a39bb53a":"markdown","cc7d966e":"markdown","987b6f3b":"markdown","e23def31":"markdown","3460c5fd":"markdown","e0fd7533":"markdown","0fa30042":"markdown"},"source":{"424b6b49":"from os import path\nimport torch\nimport torch, torchvision\nimport seaborn as sns\nfrom torch.autograd import Variable\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom torchvision import  transforms\nimport numpy as np\nfrom torch import nn,optim","3d3c7738":"train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsubmission=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","bc8235bc":"#checking for null value\nprint('Null in train_data {}'.format(train.isna().any().sum()))\nprint('Null in test_data {}'.format(test.isna().any().sum()))","639053cc":"train.head(2)","97749e64":"#Looking for first number\nplt.imshow(train.loc[0,train.columns!='label'].values.reshape(28,28)) #for image\nplt.title(train.loc[0,train.columns=='label'].values[0])              #For target\nplt.show()","715f642a":"train['label'].value_counts()   #unique labels and there count","ff480407":"sns.countplot(x='label',data=train) #count of target","a86649ac":"class DigitDataset(Dataset):\n    def __init__(self,df,trans):\n        self.df=df\n        self.transform=trans\n        self.fnames = self.df.index.tolist()\n    def __getitem__(self,idx):\n        df=self.df\n        img=df.loc[idx,df.columns!='label'].values.astype('float32')\/255\n        target=train.loc[idx,train.columns=='label'].values[0]\n        img=img.reshape(28,28)\n        img=self.transform(img)\n        target=torch.tensor(target).type(torch.LongTensor)\n       # print(target.dtype)\n        return img,target\n    def __len__(self):\n        return len(self.fnames)\ndata_tranf=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])","ad179b48":"data=DigitDataset(train,data_tranf)\ndata_loader=DataLoader(data,batch_size=10,shuffle=False)","2d4c1eb9":"#lets see our Dataloader is working or not\nimg,target=data.__getitem__(0)\nimg.shape,target.shape","4e146cd7":"class CnnNetwork(nn.Module):\n    def __init__(self):\n        super(CnnNetwork,self).__init__()\n        self.conv1=nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n        self.conv2=nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n        self.fc1=nn.Linear(in_features=12*20*20,out_features=120)\n        self.fc2=nn.Linear(in_features=120,out_features=60)\n        self.out=nn.Linear(in_features=60,out_features=10)\n        self.relu=nn.ReLU()\n    def forward(self,x):\n        n=x.size(0)\n        x=self.relu(self.conv1(x))\n        x=self.relu(self.conv2(x))\n        x=x.view(n,-1)\n        x=self.fc1(x)\n        x=self.fc2(x)\n        x=self.out(x)\n        return x","ce308868":"model = CnnNetwork()\ncec_loss = nn.CrossEntropyLoss()\nparams = model.parameters()\noptimizer = optim.Adam(params=params,lr=0.001)","cb0fb223":"n_epochs=20\nn_iterations=2\n\n# vis=Visdom()\n# vis_window=vis.line(np.array([0]),np.array([0]))\n\nfor e in range(n_epochs):\n    for i,(images,labels) in enumerate(data_loader):\n        images = Variable(images)\n        labels = Variable(labels)\n        output = model(images)\n        \n        model.zero_grad()\n        loss = cec_loss(output,labels)\n #       print(loss)\n        loss.backward()\n        \n        optimizer.step()\n        \n        n_iterations+=1\n    print('Epoch: {} - Loss: {:.6f}'.format(e + 1, loss.item()))","9822d0eb":"test_d=DigitDataset(test,data_tranf)\ntest_loader=DataLoader(test_d,batch_size=test.shape[0],shuffle=False)\nfor i,(test_img,lab) in enumerate(test_loader):\n    print(i)\n    break\n","e8e2d87c":"output=model(test_img)\npredicted = torch.max(output,1)[1]\nsubmission['Label']=predicted","c72841ca":"submission.to_csv('submission1.csv',index=False)","a39bb53a":"# Training","cc7d966e":"This kernal is for the pople who wants to understand about Dataloader how we create them and how can we design architecture from scratch.\nBasically this is for Beginner.\n\n*   Steps:\n*      1.Work on Data \n        (Load Data,\n        Data filter,\n        Data visualisation)\n*      2.Data Loader \n*      3.Network Architecture\n*      4.Training\n*      5.Testing","987b6f3b":"### you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - Thankyou ","e23def31":"# Data Loader\n* This is a generalised method of calling image and it's target, will work for every type of dataset with little manupulation.","3460c5fd":"# Testing","e0fd7533":"# EDA","0fa30042":"# Network"}}