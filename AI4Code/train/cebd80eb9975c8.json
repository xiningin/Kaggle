{"cell_type":{"65e48948":"code","1f15682c":"code","284c7ce9":"code","fb16b0a7":"code","171101a8":"code","33d9f4e3":"code","0fd5f519":"code","4da1c7a8":"code","08114c34":"code","9aec5ffc":"code","2dfe3adc":"code","55140f79":"code","e520f3e6":"code","d46cfb3f":"code","e2b7908a":"code","d1552774":"markdown","f21d148d":"markdown","88e9b2c7":"markdown"},"source":{"65e48948":"import numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nplt.style.use(\"ggplot\")\nimport seaborn as sns\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score, RandomizedSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","1f15682c":"train = pd.read_csv(\"..\/input\/train.csv\")\nn_train = len(train) \nX_train = train.drop(['PassengerId', 'Survived'], axis=1)\ny_train = train.Survived\n\ntest = pd.read_csv(\"..\/input\/test.csv\")\nX_test = test.drop('PassengerId', axis=1)\n\nX_full = pd.concat([X_train, X_test], ignore_index=True)","284c7ce9":"# train.head()\n\n# sns.countplot(x='Sex', hue='Survived', data=train)\n# plt.gca().set_title('hh')\n# plt.show()\n\n# sns.countplot(x='Pclass', hue='Survived', data=train)\n\n# train.groupby(['Pclass', 'Sex'])['Survived'].mean()\n# # train.groupby(['Pclass', 'Sex'])['Survived'].mean().plot.bar()\n\n# sns.catplot(x='Pclass', y='Survived', hue='Sex', data=train)\n\n# sns.violinplot(x='Pclass', y='Age', hue='Survived', data=train, split=True)\n\n# train.head()","fb16b0a7":"na_info_train = train.isnull().sum()\nna_info_test = test.isnull().sum()\n\nna_info = pd.concat([na_info_train, na_info_test], axis=1)\nna_info.columns = ['train', 'test']\n\nna_info['total'] = na_info.train + na_info.test\nna_info['total_pct'] = na_info.total \/ (len(train) + len(test))\nna_info['dtype'] = train.dtypes[na_info.index]\n\nna_info.sort_values(['total', 'test', 'train'], ascending=False, inplace=True)\nna_info = na_info[na_info.total > 0]\n\nna_info","171101a8":"class AwesomeImputer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.fill_with_None = [\"Cabin\", \"Embarked\"]\n        self.fill_with_mean = [\"Age\"]\n        \n    def fit(self, X, y=None):\n        self.imp_mean = SimpleImputer(strategy=\"mean\")\n        self.imp_mean.fit(X[self.fill_with_mean])\n        return self\n    \n    def transform(self, X):\n        X[self.fill_with_None] = X[self.fill_with_None].fillna(\"None\")\n        X[self.fill_with_mean] = self.imp_mean.transform(X[self.fill_with_mean])\n        X[\"Fare\"] = X.groupby(\"Pclass\")[\"Fare\"].transform(lambda series: series.fillna(series.mean()))\n        assert(X.isnull().sum().sum() == 0)\n        return X","33d9f4e3":"class Dummies(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        self._X = pd.get_dummies(X).head(1)\n        return self\n\n    def transform(self, X):\n        X = pd.get_dummies(X)\n        _, X = self._X.align(X, axis=1, join='left', fill_value=0)\n        return X","0fd5f519":"class AwesomeScaler(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.scaler = RobustScaler()\n    \n    def fit(self, X, y=None):\n        self.scaler.fit(X)\n        return self\n    \n    def transform(self, X):\n        # Apply scaler while preserving pd.DataFrame format. Otherwise it casts X to np.ndarray\n        X[X.columns] = self.scaler.transform(X)\n        return X","4da1c7a8":"preprosessing = [\n    AwesomeImputer(),\n    Dummies(),\n    AwesomeScaler(),\n]\npipe_prep = make_pipeline(*preprosessing)","08114c34":"X_full_prep = pipe_prep.fit_transform(X_full)\nX_train_prep = X_full_prep[:n_train]\nX_test_prep = X_full_prep[n_train:]","9aec5ffc":"from scipy.stats import randint, uniform, expon\n\ndef random_search(model, param_dist, X, y, n_iter=10):\n    assert(len(param_dist) <= 6)\n    rand_search = RandomizedSearchCV(model, param_dist, scoring=\"accuracy\", cv=5, n_iter=n_iter, verbose=1)\n    rand_search.fit(X, y)\n    print(rand_search.best_score_, rand_search.best_params_)\n    f, axes = plt.subplots(len(param_dist)\/\/2 + 1, 2)\n    for idx, param in enumerate(param_dist):\n        ax = axes.flatten()[idx]\n        sns.scatterplot(rand_search.cv_results_['param_{}'.format(param)], \\\n                        rand_search.cv_results_['mean_test_score'], ax=ax)\n        ax.set_xlabel(param)\n        ax.set_ylabel('accuracy')\n\nclass ExpoUni(object):\n    def __init__(self, loc, end):\n        self.loc = loc\n        self.scale = end - loc\n        self.uni = uniform(self.loc, self.scale)\n        \n    def rvs(self, size=None, random_state=None):\n        uniform_samples = self.uni.rvs(size=size, random_state=random_state)\n        return np.power(10, uniform_samples)","2dfe3adc":"# random_search(SVC(gamma=0.03), {'C': uniform(loc=10, scale=50)}, X=X_train_prep, y=y_train, n_iter=20)","55140f79":"# random_search(SVC(C=10), {'gamma': uniform(loc=0.02, scale=0.06)}, X=X_train_prep, y=y_train)","e520f3e6":"model_subm = SVC(C=20, gamma=0.02)","d46cfb3f":"# cross_val_score(model_subm, X=X_train_prep, y=y_train, scoring='accuracy', verbose=1)","e2b7908a":"model_subm.fit(X=X_train_prep, y=y_train)\ny_pred = model_subm.predict(X_test_prep)\nresult = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_pred})\nresult.to_csv(\"submission.csv\", index=False)","d1552774":"## EDA","f21d148d":"Have a look at missing values:","88e9b2c7":"## Feature transformations"}}