{"cell_type":{"e9468c63":"code","11e3e800":"code","4ff8fd30":"code","8ab78ecf":"code","355adf54":"code","5588eb19":"code","ca073301":"code","5c101c62":"code","d1c36643":"code","4c9ffa30":"code","01d33598":"code","eb342e70":"code","c05c598b":"code","43da237d":"code","4175512e":"code","ac93876b":"code","d45310f4":"code","94c283c8":"code","a44e13c6":"code","102f3094":"code","ce213d50":"code","5dca9dca":"code","f4bb64aa":"code","924ae4df":"code","08be49f0":"code","8d8d5f1f":"code","9d45b49c":"code","c3eb6c06":"code","f6dcf955":"code","48695dbc":"code","0d71c908":"code","2bb42cc0":"code","4875e052":"code","994d775d":"code","52308826":"code","8e623403":"code","0be618e2":"markdown","08c58155":"markdown","8ad0af5f":"markdown","ea9ca7aa":"markdown","ad39bd0f":"markdown","4c6663ee":"markdown","7b918872":"markdown","40379936":"markdown","0980f882":"markdown","c40ea36a":"markdown","109687dc":"markdown","4af4d7cf":"markdown","e341aec4":"markdown","333c6273":"markdown","91999d8b":"markdown","8fe0c867":"markdown","c09d05c6":"markdown","077f2710":"markdown","1ee774ff":"markdown","ba093fed":"markdown","9b85fd0b":"markdown","588e6902":"markdown","86d1c13e":"markdown","7cd3de21":"markdown","4ec5451f":"markdown","eff98c5b":"markdown","844e5a6a":"markdown","6927953a":"markdown","6b0cae1a":"markdown","e070adcb":"markdown","ba176df0":"markdown","0f432010":"markdown"},"source":{"e9468c63":"\nimport numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.metrics import accuracy_score\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC, LinearSVC\n%matplotlib inline ","11e3e800":"titanic_train = pd.read_csv(\"..\/input\/train.csv\")\ntitanic_test = pd.read_csv(\"..\/input\/test.csv\")","4ff8fd30":"titanic_train.head()","8ab78ecf":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=titanic_train)\nsns.factorplot('Sex','Survived', data=titanic_train,size=4,aspect=3)","355adf54":"titanic_train[['Sex','Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","5588eb19":"sns.countplot(x='Survived',hue='Pclass',data=titanic_train)\nsns.factorplot('Pclass','Survived', data=titanic_train,size=4,aspect=3)","ca073301":"titanic_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","5c101c62":"sns.countplot(x='Survived',hue='Embarked',data=titanic_train)\nsns.factorplot('Embarked','Survived', data=titanic_train,size=4,aspect=3)","d1c36643":"titanic_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","4c9ffa30":"sns.heatmap(titanic_train.isnull(),yticklabels= False,cbar= False,cmap='viridis')","01d33598":"sns.heatmap(titanic_test.isnull(),yticklabels= False,cbar= False,cmap='viridis')","eb342e70":"#For tarining data \n(float ( sum(pd.isnull(titanic_train['Cabin'])) ) \/ (sum(pd.isnull(titanic_train['Cabin'])) + sum(pd.notnull(titanic_train['Cabin']))))\n","c05c598b":"#For test data\n(float ( sum(pd.isnull(titanic_test['Cabin'])) ) \/ (sum(pd.isnull(titanic_test['Cabin'])) + sum(pd.notnull(titanic_test['Cabin']))))","43da237d":"#drop values from both \n\ntitanic_train = titanic_train.drop(['Cabin','Ticket'],axis=1)\n\ntitanic_test = titanic_test.drop(['Cabin','Ticket'],axis=1)","4175512e":"sns.heatmap(titanic_train.isnull(),yticklabels= False,cbar= False,cmap='viridis')","ac93876b":"sns.heatmap(titanic_test.isnull(),yticklabels= False,cbar= False,cmap='viridis')","d45310f4":" def impute_age(col):\n    age=col[0]\n    pclass=col[1]\n    \n    if pd.isnull(age):\n        \n        if pclass == 1:\n            return  titanic_train[titanic_train[\"Pclass\"]==1].mean()[\"Age\"]\n        elif pclass == 2:\n            return  titanic_train[titanic_train[\"Pclass\"]==2].mean()[\"Age\"]\n        else:\n            return  titanic_train[titanic_train[\"Pclass\"]==3].mean()[\"Age\"]\n        \n    else:\n        return age\n        ","94c283c8":"titanic_train['Age']= titanic_train[['Age','Pclass']].apply(impute_age,axis=1)\ntitanic_test['Age']= titanic_test[['Age','Pclass']].apply(impute_age,axis=1)","a44e13c6":"titanic_train.dropna(inplace=True)","102f3094":"sns.heatmap(titanic_train.isnull(),yticklabels= False,cbar= False,cmap='viridis')","ce213d50":"sns.heatmap(titanic_test.isnull(),yticklabels= False,cbar= False,cmap='viridis')","5dca9dca":"titanic_full = [titanic_train,titanic_test]\nfor dataset in titanic_full:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","f4bb64aa":"titanic_full = [titanic_train,titanic_test]\nfor dataset in titanic_full:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)","924ae4df":"titanic_train.drop(['Name'],axis=1,inplace=True)\ntitanic_test.drop(['Name'],axis=1,inplace=True)\n\n","08be49f0":"titanic_full = [titanic_train,titanic_test]\nfor dataset in titanic_full:    \n    dataset.loc[ dataset['Age'] <= 5, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 5) & (dataset['Age'] <= 11), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 35), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 35) & (dataset['Age'] <= 64), 'Age'] = 5\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 6\n    dataset['Age'] = dataset['Age'].astype(int)\n","8d8d5f1f":"titanic_train.describe()","9d45b49c":"titanic_full = [titanic_train,titanic_test]\nfor dataset in titanic_full:\n    dataset.loc[ pd.isnull(dataset['Fare']), 'Fare'] = 0\n    dataset.loc[ dataset['Fare'] <= 7.89, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.89) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)","c3eb6c06":"titanic_train.head()","f6dcf955":"X_train = titanic_train.drop([\"Survived\" ,\"PassengerId\"], axis=1)\nY_train = titanic_train[\"Survived\"]\nX_test  = titanic_test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","48695dbc":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","0d71c908":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","2bb42cc0":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","4875e052":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","994d775d":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","52308826":"gbk = GradientBoostingClassifier()\ngbk.fit(X_train, Y_train)\ny_pred = gbk.predict(X_test)\nacc_gbk = round(gbk.score(X_train, Y_train) * 100, 2)\nacc_gbk","8e623403":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)\n","0be618e2":"So your chances of survival rate  is high with higher Passenger class \n\nnext up is where passenger  boraded , as mention C = Cherbourg, Q = Queenstown, S = Southampton , let's check ","08c58155":"My First Attempt in Data science  and Machine learning. I will be working on the Titanic data and with help of data visualization I will be updating the dataset with all logic and coments , Please feel free to comment and upvote if you find useful \n\n**Content **\n1.  Import  neccessary libarary\n2. Data Analysis & Visualization \n3. Data cleaning \n4. Value Imputation\n5. Run differen model with cleaned data \n6. Submission\n\n\n** Import  neccessary libarary**","8ad0af5f":"Next up Age as its a continuos value need to convert to category like  below (age group can be adjusted , based on inetrnet information :) )\n* Baby: 0  \n* Child : 1 \n* Teenager: 2\n* Student: 3\n* Young Adult: 4\n* Adult: 5\n* Senior: 6","ea9ca7aa":"Display data for visual analysis ","ad39bd0f":"**KNN**","4c6663ee":"** Data Analysis**\n\nCheck for Correlation between Gender and survival ","7b918872":"Now we know that there is one null value in fare we can  choose to impute or drop the value ","40379936":"**Gaussian Naive Bayes**","0980f882":"**Run differen model with cleaned data **\n\n\nLets prepare training & test data","c40ea36a":"**Gradient Boosting Classifier**","109687dc":"Now Age column has null value lets impute values with below logic, we are looking at  Passenger class  to calculate the mean  and impute the value","4af4d7cf":"Next is Gender column ","e341aec4":"Now lets check the null value  for training & test data","333c6273":"**Sources**\n\nhttps:\/\/www.kaggle.com\/nadintamer\/titanic-survival-predictions-beginner\n\nhttps:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n\nAll feedback is welcome ","91999d8b":"As confirmed from second graph female had more survival rate , now lets see Passaenger Class to survival rate ","8fe0c867":"As  cabin has 78% values missing make sense for dropping , ticket number can also be dropped as we have class information in another column.","c09d05c6":"By looking at first graph it looks like  male survived more than females , but second graph talks of % of male & female survived and looks \nlike female had more probability to be survive , let see the percentage ","077f2710":"Also we can drop the Name column  ","1ee774ff":"Based on the graph we can say higher your Passenger class the more your survival rate , lets check the percentage value for each class ","ba093fed":"**Logistic Regression**","9b85fd0b":"**Random Forest**","588e6902":"Final Check before we built our Machine Learning Models ","86d1c13e":"**Submission**\n\nBased on the score I have selected Random forest for submission ","7cd3de21":"Read files for training  &  test data ","4ec5451f":"Looks like we have no null value in training data , we will be  imputing  value for fare in test data  when we are creating category for Fare column\n** Value Imputation**\n\nNow next to other column conversion to  number , first Embarked ","eff98c5b":"Now lets create category for Fare  , lets analyz  data ","844e5a6a":"As we can see  we can create three category from it ","6927953a":"**Data Cleaning **\n\nFirst step is to check null values in data set  both training & test \n","6b0cae1a":"Looks like Age and Cabin has null value with one fare value missing.\n\nBefore we do something about lets check percentage of value missing for cabin and decide if we can drop the  column ","e070adcb":"Let  calculate the percentage value ","ba176df0":"**Decision Tree**","0f432010":"Looks like Age and Cabin has null value , lets check test data"}}