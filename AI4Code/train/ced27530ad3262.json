{"cell_type":{"a231a540":"code","32dcaca0":"code","bfbe28f0":"code","a6af841e":"code","6313e627":"code","df5379e2":"code","6ee60dfe":"code","9c28ce34":"code","c314ad69":"code","f271ba1e":"code","8b5d60f8":"code","c0ca365d":"code","fbc6339a":"code","7cf1568f":"code","d0ea359b":"code","97316194":"code","f2b426ba":"code","b2c298f9":"code","b8c6becb":"code","d43b949a":"code","997d1629":"code","dface08e":"markdown","d9bd76de":"markdown","95d43eac":"markdown","9d54c5a2":"markdown","b9a73550":"markdown","0a020e68":"markdown","9a6949d9":"markdown","49fd6608":"markdown","8a6922cc":"markdown","439af3c2":"markdown","1a23c549":"markdown","5342d619":"markdown","26536222":"markdown","a400f110":"markdown"},"source":{"a231a540":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","32dcaca0":"customers_df = pd.read_csv('..\/input\/customers-seg\/Mall_Customers.csv')","bfbe28f0":"customers_df.head()","a6af841e":"customers_df.describe()","6313e627":"plt.figure(figsize=(8,5))\nsns.countplot(x='Gender',data=customers_df)\nplt.show()","df5379e2":"plt.figure(figsize=(8,5))\ncustomers_df.Gender.value_counts().plot.pie( autopct='%.2f%%')\nplt.show()","6ee60dfe":"customers_df.Age.describe()","9c28ce34":"plt.figure(figsize=(8,5))\ncustomers_df.Age.plot.hist(bins=15,alpha=.8)\nplt.show()","c314ad69":"sns.boxplot(x='Age',data=customers_df)","f271ba1e":"customers_df['Annual Income (k$)'].describe()","8b5d60f8":"plt.figure(figsize=(8,5))\ncustomers_df['Annual Income (k$)'].plot.hist(bins=14,color=\"#660033\")\nplt.show()","c0ca365d":"plt.figure(figsize=(8,5))\nsns.kdeplot(customers_df['Annual Income (k$)'], color=\"blue\", shade=True)\nplt.show()","fbc6339a":"customers_df['Spending Score (1-100)'].describe()","7cf1568f":"customers_df['Spending Score (1-100)'].plot.box()\nplt.show()","d0ea359b":"sns.distplot(customers_df['Spending Score (1-100)'])\nplt.show()","97316194":"customers_df['Gender'] = customers_df.Gender.map({'Male':1,'Female':0})","f2b426ba":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm\n\nl=[]\nX = customers_df.iloc[:,1:]\nfor n_clusters in range(2,11):\n    fig, ax1 = plt.subplots(1, 1)\n    fig.set_size_inches(15, 7)\n\n\n    ax1.set_xlim([-.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n    l.append(silhouette_avg)\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) \/ n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    \n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on Customers data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n    ","b2c298f9":"clusters = list(range(2,11))\nplt.plot(clusters,l,'-bo')\naxes = plt.axes()\naxes.set_xlabel(\"Number of clusters k\")\naxes.set_ylabel(\"Average silhouette Width\")\nplt.show()","b8c6becb":"from sklearn.decomposition import PCA\nreduced = PCA(n_components=2).fit_transform(X)\n\nkmeans = KMeans(init='k-means++', n_clusters=6, random_state=10)\nkmeans.fit(reduced)\n\n","d43b949a":"pca_df = pd.DataFrame(reduced,columns=['Component1','Component2'])\npca_df['Segment'] = kmeans.labels_\npca_df.head(10)","997d1629":"plt.figure(figsize=(12,7))\nsns.scatterplot(x='Component1',y='Component2',data=pca_df,hue='Segment',palette='bright')\nplt.title('K-means clustering on the customers segmentation dataset (PCA-reduced data)\\n'\n          'Centroids are marked with white cross')\nplt.legend()\nplt.show()\n","dface08e":"#### **1. Exploratory data analysis**","d9bd76de":"\\- The minimum spending score is 1 while the maximum is 99 and the average is 50.20. From the distribution plot, we can conclude that class of customers having a spending score between 40 and 50 have the highest frequency among all classes.\n\n#### **2. K-means clustering**\nAfter exploring each feature of our dataset, now it's time to segment the customers based on their features. In order to do that, we will use k-means clustering. This algorithm starts by selecting k objects from dataset randomly that will serve as the initial centers for our clusters  known as centroids. Then at each step, the algorithm seek to minimize the intra distance which is the distance between individuals within each cluste and maximize the inter-distance which is the distance between clusters.\n\n* **Determining Optimal number of Clusters:**\n\nWhile working with clusters, we need to specify the number of clusters to use. Thus we need to find the optimal number of clusters, to do that we will use the Silhouette method.\n * **Average Silhouette Method:**\n\n With the help of the average silhouette method, we can measure the quality of our clustering operation. With this, we can determine how well within the cluster is the data object. If we obtain a high average silhouette width, it means that we have good clustering. The average silhouette method calculates the mean of silhouette observations for different k values. With the optimal number of k clusters, one can maximize the average silhouette over significant values for k clusters.\n \n","95d43eac":"#### **3. Visualizing the Clustering Results using the PCA with 2 components:**\n","9d54c5a2":"Let's begin by importing the necessary packages and loading our data.","b9a73550":"#### **Customer Segmentation Project**\nCustomer Segmentation is one the most important applications of unsupervised learning. With the help of clustering techniques, **B2C** (Business to customers) companies can identify the several segments of customers that share a similarity in different ways that are relevant to marketing such as gender, age, interests, and miscellaneous spending habits.This will allow them to target the potential user base. \n\n\\- In this Data Science Project, we will perform one of the most essential applications of machine learning \u2013 Customer Segmentation. In this project, we will implement customer segmentation in python. Whenever you need to find your best customer, customer segmentation is the ideal methodology.\n","0a020e68":"\\- From the above graph, we conclude that the percentage of female is 56%, whereas the percentage of male in our customer dataset is 44%.\n\n* **Age :**\n\n\\- Next, we analyse the age feature, it's a continuous variable, thus we will plot a histogram to view the distribution of customer ages. We will first proceed by taking summary of the this variable.","9a6949d9":"We will start our customer segmentation project by exploring the data. Our data consists of one .csv file containing the following features that describe each customer:\n* CustomerIDs. \n* Age.\n* Gender.\n*Annual Income.\n*Spending Score.","49fd6608":"<a href=\"https:\/\/colab.research.google.com\/github\/walidba\/DS-Portfolio\/blob\/master\/Customers_Segmentation\/Customer_Segmentation.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","8a6922cc":"\\- We will display the first five rows of our dataset using the head() function and use the describe() function to output a statistical summary of it","439af3c2":"\\- As we can see from the figure above, the optimal number of clusters k for our customers segmentation task is 6 with an average silhouette width of 0.45.","1a23c549":"\\- We need to dig down more to get better insights from the data. In order to do that we will next perform a univariate analysis on each feature of the dataset.\n* **Gender :**\n\n\\- In this, we will create a barplot and a piechart to show the gender distribution across our customers dataset.","5342d619":"From the above graphs, we can obviously conclude that most of the customers have an age between 30 and 35, also the minimum age of customers is 18, whereas the maximum age is 70.\n\n* **Annual Income**\n\nNow we will explore the annual income feature using a histogram and a density plots to get insights from this feature.\n","26536222":"  \\- **Cluster 0 and 5** \u2013 The two cluster consists of  customers with medium PCA2 and a high PCA1.\n\n  \\- **Cluster 1** \u2013 This cluster represents customers having a high PCA2 and a low PCA1.\n\n  \\- **Cluster 2** - This cluster consists of customers with medium PCA1 and medium PCA2 score.\n\n  \\- **Cluster 3** \u2013 This comprises of customers with a high PCA2 and a medium annual spend of income.\n\n  \\- **Cluster 4** \u2013 In this cluster, there are customers with a medium PCA1 and a low PCA2 score.\n\n  \n\n\n\n\n\n\n\n\n\\- With the help of clustering, we can understand the variables much better, prompting us to take careful decisions. With the identification of customers, companies can release products and services that target customers based on several parameters like income, age, spending patterns, etc. Furthermore, more complex patterns like product reviews are taken into consideration for better segmentation.","a400f110":"\\- From the above graphs, we can obviously see that the minimum annual income of the customers is 15 while the maximum income is 137. People earning an average income of 70 have the highest frequency count in our histogram distribution. The average income of all the customers is 60.56. In the Kernel Density Plot that we displayed above, we observe that the annual income has a normal distribution.\n\n* **Spending Score :**\n\nIn the same way, we will analyse the spending score feature."}}