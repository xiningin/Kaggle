{"cell_type":{"de1de27e":"code","b6239166":"code","444d6e5a":"code","5d1f4caa":"code","79575b87":"code","afc98ddc":"code","8c22fbde":"code","76378424":"code","af30e36d":"code","8115d49e":"code","23c55f77":"code","860d9140":"markdown"},"source":{"de1de27e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b6239166":"import operator, math, random, time\nimport numpy as np\nfrom deap import algorithms, base, creator, tools, gp\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nimport multiprocessing","444d6e5a":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv(\"..\/input\/test.csv\")","5d1f4caa":"y_train = train_df['target'].values\n# GP will be executed using 100 features.\nX_train = train_df.drop(['target', 'ID_code'],axis = 1).iloc[:,100:].values\nX_test = test_df.drop(['ID_code'],axis = 1).iloc[:,100:].values","79575b87":"# create 1 feature\nmax_features = 103\n# maximum number of iteration: iteration will be terminated if maximum number of features reaches 'max_features'.\nmax_iterations = 100\n# number of generation\nnum_generations = 3","afc98ddc":"n_features = X_train.shape[1]\nclf = GaussianNB()\n# initial AUC score \nprev_auc = np.mean(cross_val_score(clf, X_train, y_train, scoring=\"roc_auc\", cv=5, n_jobs=-1))\nprint('initial AUC: ', prev_auc)","8c22fbde":"def protectedDiv(left, right):\n    eps = 1.0e-7\n    tmp = np.zeros(len(left))\n    tmp[np.abs(right) >= eps] = left[np.abs(right) >= eps] \/ right[np.abs(right) >= eps]\n    tmp[np.abs(right) < eps] = 1.0\n    return tmp\n\n# set random seed\nrandom.seed(123)\n\n# define tree structure that maximize fitness\ncreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\ncreator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n\n\n# main\n# 5-fold CV scores(AUC) will be stored in 'results' array.\n# functional definitions of generated features will be stored in 'exprs' array.\nresults = []\nexprs = []\nfor i in range(max_iterations):\n    # define mathematical operators that are available in the tree structure.\n    pset = gp.PrimitiveSet(\"MAIN\", n_features)\n    pset.addPrimitive(operator.add, 2)\n    pset.addPrimitive(operator.sub, 2)\n    pset.addPrimitive(operator.mul, 2)\n    pset.addPrimitive(protectedDiv, 2)\n    pset.addPrimitive(operator.neg, 1)\n    pset.addPrimitive(np.cos, 1)\n    pset.addPrimitive(np.sin, 1)\n    pset.addPrimitive(np.tan, 1)\n\n    # set default value of the function\n    toolbox = base.Toolbox()\n    toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n    toolbox.register(\"compile\", gp.compile, pset=pset)\n\n    # set objective function\n    # define function that evaluate 5-fold CV score\n    def eval_genfeat(individual):\n        func = toolbox.compile(expr=individual)\n        features_train = [X_train[:,i] for i in range(n_features)]\n        new_feat_train = func(*features_train)\n        X_train_tmp = np.c_[X_train, new_feat_train]\n        return np.mean(cross_val_score(clf, X_train_tmp, y_train, scoring=\"roc_auc\", cv=5)),\n\n    # define evaluation, selection, intersection and mutation\n    toolbox.register(\"evaluate\", eval_genfeat)\n    toolbox.register(\"select\", tools.selTournament, tournsize=10)\n    toolbox.register(\"mate\", gp.cxOnePoint)\n    toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=3)\n    toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n\n    # define restriction for intersection and mutation.\n    toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=5))\n    toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=5)) \n\n    # execute main process as multiprocess\n    pool = multiprocessing.Pool()\n    toolbox.register(\"map\", pool.map)\n    # set population\n    pop = toolbox.population(n=100)\n    # create instance that store best solution for each loop\n    hof = tools.HallOfFame(1)\n\n    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n    stats_size = tools.Statistics(len)\n    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n    mstats.register(\"avg\", np.mean)\n    mstats.register(\"std\", np.std)\n    mstats.register(\"min\", np.min)\n    mstats.register(\"max\", np.max)\n\n    # execution\n    start_time = time.time()\n    pop, log = algorithms.eaSimple(pop, toolbox, 0.5, 0.1, num_generations, stats=mstats, halloffame=hof, verbose=True)\n    end_time = time.time()\n\n    # store best score and solution\n    best_expr = hof[0]\n    best_auc = mstats.compile(pop)[\"fitness\"][\"max\"]\n\n    # add new feature to the training data if that feature contributed to break the current best score.\n    if prev_auc < best_auc:\n        # add new feature to the training data\n        func = toolbox.compile(expr=best_expr)\n        features_train = [X_train[:,i] for i in range(n_features)]\n        features_test = [X_test[:,i] for i in range(n_features)]\n        new_feat_train = func(*features_train)\n        X_train = np.c_[X_train, new_feat_train]\n        new_feat_test = func(*features_test)\n        X_test = np.c_[X_test, new_feat_test]\n        \n        # replace the best score\n        prev_auc = best_auc\n        n_features += 1\n        \n        # store functional definition of newly created feature.\n        exprs.append(best_expr)\n\n        # terminate the loop if the number of the features reaches 'max_features'\n        if n_features >= max_features:\n            break","76378424":"print('AUC after GP: ', best_auc)","af30e36d":"new_feat_train = X_train[:,100:]\nnew_feat_test = X_test[:,100:]","8115d49e":"import pickle \nwith open(\".\/exprs_100_200.pkl\", \"wb\") as f:\n    pickle.dump(exprs, f)","23c55f77":"# save newly created features\nwith open(\".\/new_feat_train.pkl\", \"wb\") as f:\n    pickle.dump(new_feat_train, f)\nwith open(\".\/new_feat_test.pkl\", \"wb\") as f:\n    pickle.dump(new_feat_test, f)","860d9140":"The following example shows how to execute genetic programming feature engineering using deap.  \n  For faster exection, Gaussian Naive Bayes is used for this example."}}