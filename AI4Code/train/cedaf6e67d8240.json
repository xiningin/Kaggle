{"cell_type":{"835245fd":"code","41157dbb":"code","5d3382e3":"code","9cdb0c75":"code","59f546ad":"code","3b491806":"code","60ef77eb":"code","d8632d6b":"code","c4396656":"code","74e22e13":"code","de7215d3":"code","24d72d99":"code","03c734c4":"code","ac8aefd5":"code","853d5a0b":"code","ab734ae7":"code","e1e5ac6d":"code","4e6692df":"code","50325c70":"code","69bb3812":"code","8a7a2c6b":"code","5858801f":"code","1e3d571f":"code","b90a280c":"markdown","78513695":"markdown","e8db853d":"markdown","e7f12d17":"markdown","d7427f69":"markdown","2e604474":"markdown","d24bca50":"markdown","7e48fadb":"markdown","0e3e072c":"markdown","28930d3b":"markdown","46babc9c":"markdown","74bb5ea1":"markdown","7d6601db":"markdown","4496beae":"markdown","1a7dc548":"markdown","2c75c3e5":"markdown"},"source":{"835245fd":"image_directory = \"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\"\ntrain_csv_dir = \"\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv\"","41157dbb":"import pandas as pd\n\ntrain_csv = pd.read_csv(train_csv_dir,dtype=str)","5d3382e3":"def balanced_train_test_split(df, label_col, samples, split=0.25):\n    dfs_train = []\n    dfs_test = []\n\n    no_of_classes = len(set(df[label_col].tolist()))\n    for class_id in range(0, no_of_classes):\n        class_df = df[(df[label_col]==str(class_id))].head(n=samples)\n        class_df_train = class_df.sample(frac=1-split)\n        class_df_test = class_df.drop(class_df_train.index)\n        dfs_train.append(class_df_train)\n        dfs_test.append(class_df_test)\n    \n    \n    dfs_train = pd.concat(dfs_train).sample(frac=1)\n    dfs_test = pd.concat(dfs_test).sample(frac=1)\n    \n    return dfs_train, dfs_test","9cdb0c75":"train, test = balanced_train_test_split(train_csv, \"label\", samples = 500, split=0.2)\ntrain_examples = train.count()[0]\ntest_examples = test.count()[0]\n\nprint(\"Total training examples: \", train_examples)\nprint(\"Total testing examples: \", test_examples)","59f546ad":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size=(256,256)\nimage_shape=(256,256,3)\nbatch_size=16\n\nkwargs = {\n    \"directory\":image_directory, \"x_col\":'image_id', \"y_col\":'label',\n    \"target_size\":image_size, \"color_mode\":'rgb', \"classes\":None,\n    \"class_mode\":'categorical', \"batch_size\":batch_size, \"shuffle\":True, \n}\n\ngenerator = ImageDataGenerator()\n\ntrain_generator = generator.flow_from_dataframe(train, **kwargs)\ntest_generator = generator.flow_from_dataframe(test, **kwargs)","3b491806":"from tensorflow.keras.layers import Dropout,Flatten,Dense,BatchNormalization,Activation\nimport tensorflow as tf\n\nmodelsettings = {\n    \"include_top\":False, \"weights\":'imagenet', \"input_shape\":image_shape\n}\n\noptimize_adam =  tf.keras.optimizers.Adam(learning_rate=0.001)\nloss_func = \"categorical_crossentropy\"\nacc_mat = \"categorical_accuracy\"\n\nfit_settings={\n    \"x\":train_generator, \"steps_per_epoch\":train_examples\/\/batch_size,\n    \"validation_data\":test_generator, \"validation_steps\":test_examples\/\/batch_size, \n    \"epochs\":20, \"verbose\":1,\"shuffle\":True\n}\n\ndef create_model(model):\n    model = tf.keras.Sequential([\n            model,\n            Flatten(),\n            Dense(256),\n            BatchNormalization(),\n            Activation(\"relu\"),\n            Dropout(0.5),\n            Dense(32),\n            BatchNormalization(),\n            Activation(\"relu\"),\n            Dense(5, activation=\"softmax\"),\n        ])\n    return model","60ef77eb":"from tensorflow.keras.applications import DenseNet169\n\nDenseNet = create_model(DenseNet169(**modelsettings))\n\nDenseNet.summary()","d8632d6b":"DenseNet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\ndensenet_history = DenseNet.fit(**fit_settings)","c4396656":"from tensorflow.keras.applications import InceptionV3\n\nInception = create_model(InceptionV3(**modelsettings))\n\nInception.summary()","74e22e13":"Inception.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\ninception_history = Inception.fit(**fit_settings)","de7215d3":"from tensorflow.keras.applications import MobileNetV2\n\nmobilenet = create_model(MobileNetV2(**modelsettings))\n\nmobilenet.summary()","24d72d99":"mobilenet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nmobilenet_history = mobilenet.fit(**fit_settings)","03c734c4":"from tensorflow.keras.applications import NASNetMobile\n\nnasnet = create_model(NASNetMobile(input_shape=(256,256,3), include_top=False, weights=None))\n\nnasnet.summary()","ac8aefd5":"nasnet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nnasnet_history = nasnet.fit(**fit_settings)","853d5a0b":"from tensorflow.keras.applications import ResNet101V2\n\nresnet = create_model(ResNet101V2(**modelsettings))\n\nresnet.summary()","ab734ae7":"resnet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nresnet_history = resnet.fit(**fit_settings)","e1e5ac6d":"from tensorflow.keras.applications import VGG19\n\nvgg = create_model(VGG19(**modelsettings))\n\nvgg.summary()","4e6692df":"vgg.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nvgg_history = vgg.fit(**fit_settings)","50325c70":"from tensorflow.keras.applications import Xception\n\nxception = create_model(Xception(**modelsettings))\n\nxception.summary()","69bb3812":"xception.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nxception_history = xception.fit(**fit_settings)","8a7a2c6b":"from tensorflow.keras.applications import EfficientNetB4\n\nEfficientNet = create_model(EfficientNetB4(**modelsettings))\n\nEfficientNet.summary()","5858801f":"EfficientNet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nefficientnet_history = EfficientNet.fit(**fit_settings)","1e3d571f":"import matplotlib.pyplot as plt\n\ndef plot_loss(ax, history,title):\n    ax.plot(history.history[\"loss\"], label = \"loss\")\n    ax.plot(history.history[\"val_loss\"], label=\"val_loss\")\n    ax.set(xlabel=\"epochs\", ylabel=\"loss\")\n    ax.set_title(title)\n    ax.legend()\n    \ndef plot_metrics(ax, history,title, metrics):\n    ax.plot(history.history[metrics], label=metrics)\n    ax.plot(history.history[\"val_\"+metrics], label=\"val_\"+metrics)\n    ax.set(xlabel=\"epochs\", ylabel=title)\n    ax.set_title(title)\n    ax.legend()\n    \n    \nfig, axes = plt.subplots(8, 2, figsize=(18,40))\nplt.subplots_adjust(hspace=0.5)\n\n# model 1 - DenseNet169\nplot_loss(axes[0,0], densenet_history, \"DenseNet169 loss\")\nplot_metrics(axes[0,1], densenet_history, \"DenseNet169 accuracy\", \"categorical_accuracy\")\n\n# model 2 - inceptionv3\nplot_loss(axes[1,0], inception_history, \"InceptionV3 loss\")\nplot_metrics(axes[1,1], inception_history, \"InceptionV3 accuracy\", \"categorical_accuracy\")\n\n# model 3 - mobilenet\nplot_loss(axes[2,0], mobilenet_history, \"MobileNetV2 loss\")\nplot_metrics(axes[2,1], mobilenet_history, \"MobileNetV2 accuracy\", \"categorical_accuracy\")\n\n# model 4 - NASnetlarge\nplot_loss(axes[3,0], nasnet_history, \"NASNetLarge loss\")\nplot_metrics(axes[3,1], nasnet_history, \"NASNetLarge accuracy\", \"categorical_accuracy\")\n\n# model 5 - ResNet101\nplot_loss(axes[4,0], resnet_history, \"ResNet101V2 loss\")\nplot_metrics(axes[4,1], resnet_history, \"ResNet101V2 accuracy\", \"categorical_accuracy\")\n\n# model 6 - VGG19\nplot_loss(axes[5,0], vgg_history, \"VGG19 loss\")\nplot_metrics(axes[5,1], vgg_history, \"VGG19 accuracy\", \"categorical_accuracy\")\n\n# model 7 - Xception\nplot_loss(axes[6,0], xception_history, \"Xception loss\")\nplot_metrics(axes[6,1], xception_history, \"Xception accuracy\", \"categorical_accuracy\")\n\n# model 8 - EfficientNet\nplot_loss(axes[7,0], efficientnet_history, \"EfficientNetB4 loss\")\nplot_metrics(axes[7,1], efficientnet_history, \"EfficientNetB4 accuracy\", \"categorical_accuracy\")\n\nfig.savefig(\"Comparingmodels.png\", dpi=300)","b90a280c":"# Create seventh model - xception\nin the next cell xception will be trained for 20 epochs as per settings above","78513695":"# Create eighth model - EfficientNet\nin the next cell efficientnet will be trained for 20 epochs as per settings above","e8db853d":"# Create sixth model - VGG19\nin the next cell vgg will be trained for 20 epochs as per settings above","e7f12d17":"Following cell define setting to use for all the models and a function to attach final dense layers to make predictions. I will train each model for 30 epochs with learning rate of 0.001","d7427f69":"Following cell loads the train.csv","2e604474":"Let's set our directories here","d24bca50":"# Create first model - DenseNet169\nin the next cell densenet will be trained for 20 epochs as per settings above","7e48fadb":"# Comparing peformance of TF pretrained model\n\nIn this notebook, I am going to train a sample of provided data on every pretrained model provided by tensorflow. following models will be compared\n* DenseNet169\n* InceptionV3\n* MobileNetV2\n* NASNetLarge\n* ResNet101\n* VGG19\n* Xception\n* EfficientNetB4\n\nThis notebook generate a image of plots of loss and accuracy for every model you can download that from output tab\n\nThis is not a programming tutorial notebook. Main foucs is on comparing different architectures","0e3e072c":"Following cell makes generator to load images in batches. I am using batch of 16 for each  model and target image size will be 256x256","28930d3b":"# Create third model - MobileNetV2\nin the next cell mobilenet will be trained for 20 epochs as per settings above","46babc9c":"# Create Fifth model - ResNet101V2\nin the next cell resnet will be trained for 20 epochs as per settings above","74bb5ea1":"1. A useful function which splits data into train, test ensuring each set get equal not of examples for a class. In short it splits data eqaually.\n2. Secondly, it take a sample from whole data. where parameter samples refer to no of total examples to consider for each class which then later get split into train and test","7d6601db":"* to save time I will load only 500 examples of each class and use them to train all the networks","4496beae":"# Create second model - InceptionV3\nin the next cell inception will be trained for 20 epochs as per settings above","1a7dc548":"# Plot the results ","2c75c3e5":"# Create fourth model - NASNetMobile\nin the next cell nasnet will be trained for 20 epochs as per settings above"}}