{"cell_type":{"dd51a94b":"code","429fc044":"code","78255540":"code","998707e2":"code","52866828":"code","a12681fa":"code","2a3f3ef0":"code","b7dc030a":"code","e033270d":"code","4687ad3e":"code","0355ae47":"code","88e7714b":"code","a56d4cc6":"code","ca144576":"code","a46fc3d0":"code","9c846c2e":"code","e32fd79a":"code","b8ce3c50":"code","a5b12d5e":"code","8b4eaec8":"code","3e869488":"code","b1019db3":"code","cb6c5a0b":"code","5399345b":"code","4c172304":"code","dc039314":"markdown","e55911d7":"markdown","f25e3396":"markdown","82b8a111":"markdown","e7afa634":"markdown","cedc4370":"markdown","3db6f59a":"markdown","0de7e8f4":"markdown","d35a81b3":"markdown","19ce5852":"markdown","da770d75":"markdown","3b216e80":"markdown","456114d6":"markdown","a3c2d4f1":"markdown"},"source":{"dd51a94b":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb","429fc044":"# Loading the data\ntrain = pd.read_csv('..\/input\/train.csv', parse_dates=['date'])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['date'])\nsample_sub = pd.read_csv('..\/input\/sample_submission.csv')\nprint('Train shape:{}, Test shape:{}'.format(train.shape, test.shape))\ntrain.head()","78255540":"# Concatenating train & test\ntrain['train_or_test'] = 'train'\ntest['train_or_test'] = 'test'\ndf = pd.concat([train,test], sort=False)\nprint('Combined df shape:{}'.format(df.shape))\ndel train, test\ngc.collect()","998707e2":"# Extracting date features\ndf['dayofmonth'] = df.date.dt.day\ndf['dayofyear'] = df.date.dt.dayofyear\ndf['dayofweek'] = df.date.dt.dayofweek\ndf['month'] = df.date.dt.month\ndf['year'] = df.date.dt.year\ndf['weekofyear'] = df.date.dt.weekofyear\ndf['is_month_start'] = (df.date.dt.is_month_start).astype(int)\ndf['is_month_end'] = (df.date.dt.is_month_end).astype(int)\ndf.head()","52866828":"# Sorting the dataframe by store then item then date\n#df.sort_values(by=['store','item','month','dayofweek'], axis=0, inplace=True)\ndf.sort_values(by=['store','item','date'], axis=0, inplace=True)","a12681fa":"def create_sales_agg_monthwise_features(df, gpby_cols, target_col, agg_funcs):\n    '''\n    Creates various sales agg features with given agg functions  \n    '''\n    gpby = df.groupby(gpby_cols)\n    newdf = df[gpby_cols].drop_duplicates().reset_index(drop=True)\n    for agg_name, agg_func in agg_funcs.items():\n        aggdf = gpby[target_col].agg(agg_func).reset_index()\n        aggdf.rename(columns={target_col:target_col+'_'+agg_name}, inplace=True)\n        newdf = newdf.merge(aggdf, on=gpby_cols, how='left')\n    return newdf","2a3f3ef0":"# Creating sales lag features\ndef create_sales_lag_feats(df, gpby_cols, target_col, lags):\n    gpby = df.groupby(gpby_cols)\n    for i in lags:\n        df['_'.join([target_col, 'lag', str(i)])] = \\\n                gpby[target_col].shift(i).values + np.random.normal(scale=1.6, size=(len(df),))\n    return df\n\n# Creating sales rolling mean features\ndef create_sales_rmean_feats(df, gpby_cols, target_col, windows, min_periods=2, \n                             shift=1, win_type=None):\n    gpby = df.groupby(gpby_cols)\n    for w in windows:\n        df['_'.join([target_col, 'rmean', str(w)])] = \\\n            gpby[target_col].shift(shift).rolling(window=w, \n                                                  min_periods=min_periods,\n                                                  win_type=win_type).mean().values +\\\n            np.random.normal(scale=1.6, size=(len(df),))\n    return df\n\n# Creating sales rolling median features\ndef create_sales_rmed_feats(df, gpby_cols, target_col, windows, min_periods=2, \n                            shift=1, win_type=None):\n    gpby = df.groupby(gpby_cols)\n    for w in windows:\n        df['_'.join([target_col, 'rmed', str(w)])] = \\\n            gpby[target_col].shift(shift).rolling(window=w, \n                                                  min_periods=min_periods,\n                                                  win_type=win_type).median().values +\\\n            np.random.normal(scale=1.6, size=(len(df),))\n    return df\n\n# Creating sales exponentially weighted mean features\ndef create_sales_ewm_feats(df, gpby_cols, target_col, alpha=[0.9], shift=[1]):\n    gpby = df.groupby(gpby_cols)\n    for a in alpha:\n        for s in shift:\n            df['_'.join([target_col, 'lag', str(s), 'ewm', str(a)])] = \\\n                gpby[target_col].shift(s).ewm(alpha=a).mean().values\n    return df","b7dc030a":"def one_hot_encoder(df, ohe_cols=['store','item','dayofmonth','dayofweek','month','weekofyear']):\n    '''\n    One-Hot Encoder function\n    '''\n    print('Creating OHE features..\\nOld df shape:{}'.format(df.shape))\n    df = pd.get_dummies(df, columns=ohe_cols)\n    print('New df shape:{}'.format(df.shape))\n    return df","e033270d":"# Converting sales to log(1+sales)\ndf['sales'] = np.log1p(df.sales.values)\ndf.sample(2)","4687ad3e":"# For validation \n# We can choose last 3 months of training period(Oct, Nov, Dec 2017) as our validation set to gauge the performance of the model.\n# OR to keep months also identical to test set we can choose period (Jan, Feb, Mar 2017) as the validation set.\n# Here we will go with the latter choice.\nmasked_series = (df.year==2017) & (df.month.isin([1,2,3]))\nmasked_series2 = (df.year==2017) & (~(df.month.isin([1,2,3])))\ndf.loc[(masked_series), 'train_or_test'] = 'val'\ndf.loc[(masked_series2), 'train_or_test'] = 'no_train'\nprint('Train shape: {}'.format(df.loc[df.train_or_test=='train',:].shape))\nprint('Validation shape: {}'.format(df.loc[df.train_or_test=='val',:].shape))\nprint('No train shape: {}'.format(df.loc[df.train_or_test=='no_train',:].shape))\nprint('Test shape: {}'.format(df.loc[df.train_or_test=='test',:].shape))","0355ae47":"# Converting sales of validation period to nan so as to resemble test period\ntrain = df.loc[df.train_or_test.isin(['train','val']), :]\nY_val = train.loc[train.train_or_test=='val', 'sales'].values.reshape((-1))\nY_train = train.loc[train.train_or_test=='train', 'sales'].values.reshape((-1))\ntrain.loc[train.train_or_test=='val', 'sales'] = np.nan\n\n# # Creating sales lag, rolling mean, rolling median, ohe features of the above train set\ntrain = create_sales_lag_feats(train, gpby_cols=['store','item'], target_col='sales', \n                               lags=[91,98,105,112,119,126,182,364,546,728])\n\ntrain = create_sales_rmean_feats(train, gpby_cols=['store','item'], \n                                 target_col='sales', windows=[364,546], \n                                 min_periods=10, win_type='triang') #98,119,91,182,\n\n# # train = create_sales_rmed_feats(train, gpby_cols=['store','item'], \n# #                                 target_col='sales', windows=[364,546], \n# #                                 min_periods=10, win_type=None) #98,119,91,182,\n\ntrain = create_sales_ewm_feats(train, gpby_cols=['store','item'], \n                               target_col='sales', \n                               alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n                               shift=[91,98,105,112,119,126,182,364,546,728])\n\n# # Creating sales monthwise aggregated values\n# agg_df = create_sales_agg_monthwise_features(df.loc[df.train_or_test=='train', :], \n#                                              gpby_cols=['store','item','month'], \n#                                              target_col='sales', \n#                                              agg_funcs={'mean':np.mean, \n#                                              'median':np.median, 'max':np.max, \n#                                              'min':np.min, 'std':np.std})\n\n# # Joining agg_df with train\n# train = train.merge(agg_df, on=['store','item','month'], how='left')\n\n# One-Hot Encoding \ntrain = one_hot_encoder(train, ohe_cols=['store','item','dayofweek','month']) \n#,'dayofmonth','weekofyear'\n\n# Final train and val datasets\nval = train.loc[train.train_or_test=='val', :]\ntrain = train.loc[train.train_or_test=='train', :]\nprint('Train shape:{}, Val shape:{}'.format(train.shape, val.shape))","88e7714b":"avoid_cols = ['date', 'sales', 'train_or_test', 'id', 'year']\ncols = [col for col in train.columns if col not in avoid_cols]\nprint('No of training features: {} \\nAnd they are:{}'.format(len(cols), cols))","a56d4cc6":"def smape(preds, target):\n    '''\n    Function to calculate SMAPE\n    '''\n    n = len(preds)\n    masked_arr = ~((preds==0)&(target==0))\n    preds, target = preds[masked_arr], target[masked_arr]\n    num = np.abs(preds-target)\n    denom = np.abs(preds)+np.abs(target)\n    smape_val = (200*np.sum(num\/denom))\/n\n    return smape_val\n\ndef lgbm_smape(preds, train_data):\n    '''\n    Custom Evaluation Function for LGBM\n    '''\n    labels = train_data.get_label()\n    smape_val = smape(np.expm1(preds), np.expm1(labels))\n    return 'SMAPE', smape_val, False","ca144576":"# LightGBM parameters\nlgb_params = {'task':'train', 'boosting_type':'gbdt', 'objective':'regression', \n              'metric': {'mae'}, 'num_leaves': 10, 'learning_rate': 0.02, \n              'feature_fraction': 0.8, 'max_depth': 5, 'verbose': 0, \n              'num_boost_round':15000, 'early_stopping_rounds':200, 'nthread':-1}","a46fc3d0":"# Creating lgbtrain & lgbval\nlgbtrain = lgb.Dataset(data=train.loc[:,cols].values, label=Y_train, \n                       feature_name=cols)\nlgbval = lgb.Dataset(data=val.loc[:,cols].values, label=Y_val, \n                     reference=lgbtrain, feature_name=cols)","9c846c2e":"def lgb_validation(params, lgbtrain, lgbval, X_val, Y_val, verbose_eval):\n    t0 = time.time()\n    evals_result = {}\n    model = lgb.train(params, lgbtrain, num_boost_round=params['num_boost_round'], \n                      valid_sets=[lgbtrain, lgbval], feval=lgbm_smape, \n                      early_stopping_rounds=params['early_stopping_rounds'], \n                      evals_result=evals_result, verbose_eval=verbose_eval)\n    print(model.best_iteration)\n    print('Total time taken to build the model: ', (time.time()-t0)\/60, 'minutes!!')\n    pred_Y_val = model.predict(X_val, num_iteration=model.best_iteration)\n    pred_Y_val = np.expm1(pred_Y_val)\n    Y_val = np.expm1(Y_val)\n    val_df = pd.DataFrame(columns=['true_Y_val','pred_Y_val'])\n    val_df['pred_Y_val'] = pred_Y_val\n    val_df['true_Y_val'] = Y_val\n    print(val_df.shape)\n    print(val_df.sample(5))\n    print('SMAPE for validation data is:{}'.format(smape(pred_Y_val, Y_val)))\n    return model, val_df","e32fd79a":"# Training lightgbm model and validating\nmodel, val_df = lgb_validation(lgb_params, lgbtrain, lgbval, val.loc[:,cols].values, \n                               Y_val, verbose_eval=500)","b8ce3c50":"# Let's see top 25 features as identified by the lightgbm model.\nprint(\"Features importance...\")\ngain = model.feature_importance('gain')\nfeat_imp = pd.DataFrame({'feature':model.feature_name(), \n                         'split':model.feature_importance('split'), \n                         'gain':100 * gain \/ gain.sum()}).sort_values('gain', ascending=False)\nprint('Top 25 features:\\n', feat_imp.head(25))","a5b12d5e":"# Creating sales lag, rolling mean, rolling median, ohe features of the above train set\ndf_whole = create_sales_lag_feats(df, gpby_cols=['store','item'], target_col='sales', \n                                  lags=[91,98,105,112,119,126,182,364,546,728])\ndf_whole = create_sales_rmean_feats(df_whole, gpby_cols=['store','item'], \n                                    target_col='sales', windows=[364,546], \n                                    min_periods=10, win_type='triang')\n# df = create_sales_rmed_feats(df, gpby_cols=['store','item'], target_col='sales', \n#                              windows=[364,546], min_periods=2) #98,119,\ndf_whole = create_sales_ewm_feats(df_whole, gpby_cols=['store','item'], target_col='sales', \n                                  alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n                                  shift=[91,98,105,112,119,126,182,364,546,728])\n\n# # Creating sales monthwise aggregated values\n# agg_df = create_sales_agg_monthwise_features(df.loc[~(df.train_or_test=='test'), :], \n#                                              gpby_cols=['store','item','month'], \n#                                              target_col='sales', \n#                                              agg_funcs={'mean':np.mean, \n#                                              'median':np.median, 'max':np.max, \n#                                              'min':np.min, 'std':np.std})\n\n# # Joining agg_df with df\n# df = df.merge(agg_df, on=['store','item','month'], how='left')\n\n# One-Hot Encoding\ndf_whole = one_hot_encoder(df_whole, ohe_cols=['store','item','dayofweek','month']) \n#'dayofmonth',,'weekofyear'\n\n# Final train and test datasets\ntest = df_whole.loc[df_whole.train_or_test=='test', :]\ntrain = df_whole.loc[~(df_whole.train_or_test=='test'), :]\nprint('Train shape:{}, Test shape:{}'.format(train.shape, test.shape))","8b4eaec8":"# LightGBM dataset\nlgbtrain_all = lgb.Dataset(data=train.loc[:,cols].values, \n                           label=train.loc[:,'sales'].values.reshape((-1,)), \n                           feature_name=cols)","3e869488":"def lgb_train(params, lgbtrain_all, X_test, num_round):\n    t0 = time.time()\n    model = lgb.train(params, lgbtrain_all, num_boost_round=num_round, feval=lgbm_smape)\n    test_preds = model.predict(X_test, num_iteration=num_round)\n    print('Total time taken in model training: ', (time.time()-t0)\/60, 'minutes!')\n    return model, test_preds","b1019db3":"# Training lgb model on whole data(train+val)\nlgb_model, test_preds = lgb_train(lgb_params, lgbtrain_all, test.loc[:,cols].values, model.best_iteration)\nprint('test_preds shape:{}'.format(test_preds.shape))","cb6c5a0b":"# Create submission\nsub = test.loc[:,['id','sales']]\nsub['sales'] = np.expm1(test_preds)\nsub['id'] = sub.id.astype(int)\nsub.to_csv('submission.csv', index=False)\nsub.head()","5399345b":"df.head(2)","4c172304":"df.date.min(), df.date.max()","dc039314":"## Feature Engineering","e55911d7":"## Time-based Validation set","f25e3396":"## WaveNet Model ","82b8a111":"## Loading data","e7afa634":"### Training features","cedc4370":"## Model Validation","3db6f59a":"### Monthwise aggregated sales values","0de7e8f4":"## LightGBM Model","d35a81b3":"### Log Sales ","19ce5852":"## Final Model","da770d75":"### Features constructed from previous sales values","3b216e80":"### Date Features","456114d6":"### OHE of categorical features","a3c2d4f1":"## Submission"}}