{"cell_type":{"7f47f182":"code","5284010d":"code","baf15cfc":"code","3242a469":"code","9c396d57":"code","63bb950e":"code","208c1bd5":"code","c90ba220":"code","97427568":"code","f500dee8":"code","75d57c16":"code","5945670f":"markdown","925b2db1":"markdown","2fa4e9a1":"markdown","e67c7e3c":"markdown","ade2fa68":"markdown","bc6b59ae":"markdown","dce5fdec":"markdown","01cdabe9":"markdown","8e2d56fa":"markdown","be5f610f":"markdown","add69511":"markdown","490a3942":"markdown","759e6a18":"markdown","90124156":"markdown","d7848010":"markdown","b68faf44":"markdown","319e38bb":"markdown","c1834306":"markdown","e87ca527":"markdown","5fbf7830":"markdown","7f73b0d1":"markdown"},"source":{"7f47f182":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5284010d":"import matplotlib.pyplot as plt \nfrom sklearn.preprocessing import LabelEncoder \nplt.style.use(style='seaborn')","baf15cfc":"df = pd.read_csv(\"..\/input\/paysim1\/PS_20174392719_1491204439457_log.csv\",encoding=\"ISO-8859-1\",error_bad_lines=False)\ndf.head(2)","3242a469":"len(df)","9c396d57":"df.type.value_counts()","63bb950e":"df.amount.value_counts()","208c1bd5":"x = df['type'].value_counts().index\ny = df['type'].value_counts().values\n\nf = plt.figure(1,figsize=(16,6))\nax1 = f.add_subplot(1,2,1)\nax1.title.set_text('Type')\n_ =ax1.bar(x,y)\n\nz = df['amount'].value_counts().index\n\nax2 = f.add_subplot(1,2,2)\nax2.title.set_text('Amount')\n_ =ax2.boxplot(z)\n","c90ba220":"from sklearn.ensemble import IsolationForest \n\ncontamination = 0.01 \n\ndata = df.copy()","97427568":"for col in data.columns:\n    if data[col].dtype == \"object\":\n        le = LabelEncoder()\n        data[col].fillna(\"None\",inplace=True)\n        le.fit(list(data[col].astype(str).values))\n        data[col] = le.transform(list(data[col].astype(str).values))\n    else:\n        data[col].fillna(-999, inplace=True)\n\ndata.head(2)","f500dee8":"%%time \nmodel = IsolationForest(contamination=contamination,n_estimators=1000)\nmodel.fit(data)","75d57c16":"df[\"iforest\"] = pd.Series(model.predict(data))\ndf[\"iforest\"] = df[\"iforest\"].map({1:0,-1:1})\nprint(df[\"iforest\"].value_counts())","5945670f":"Amount is a continous numerical feature.","925b2db1":"# 4.Conclusion\n\nWe have done an anomaly detection using Isolation forest algorithm.\n\nWe had specified a contamination value of 1%. Our algorithm has classified 63627 values as anomalies from a dataset of 6298993  values.\n\nWe can use Isolation forest to do anomaly detection and fraud detection.","2fa4e9a1":"Type is a categorical value and it has five labels in it.","e67c7e3c":"# 3.Isolation Forest \n\nIt is one of the most efficient algorithm for outlier detection especially in case of high dimensionality data.The model builds a Random forest in which each decision tree grows randomly.At each node it picks a feature randomly and then a random threshold value (between min and max) to split the dataset into two.As the dataset gets gradually chopped into pieces each observation gets isolated from the others.Anomalies are different from other dataset so they get separated in less steps of the decision tree.So Isolation forest classifies such data as Anomaly.","ade2fa68":"We are doing label encoding to convert the caegorical values into numerical.Then we are filling the nulls with the String None for every other type of missing values we care filling with a random number -999.","bc6b59ae":"### Length of Dataset","dce5fdec":"Here we have considered 1% contimination.This we can specify based on our domain knowledge.","01cdabe9":"So the plots make it very clear that type is a categorical value and Amount is a continous numerical value.","8e2d56fa":"### Importing Python Modules","be5f610f":"### Ploting Type and Amount ","add69511":"### Predicting the Outliers","490a3942":"### Fitting the Model","759e6a18":"# 1.Data Import and Preprocessing ","90124156":"### Value Counts Type ","d7848010":"### Recently I published a self help book titled Inspiration: Thoughts on Spirituality, Technology, Wealth, Leadership and Motivation. The preview of the book can be read from the Amazon link https:\/\/lnkd.in\/gj7bMQA\n\n### To can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","b68faf44":"In this note we will see how to do anomaly detection using Isolation Forest.The concept is Anomalies will be detected with minimal split in case of decision trees.So the data separated with minimum split can be classified as anamoly.This notebook will have following sections \n\n1.Data import and Preprocessing \n\n2.Data Visualization \n\n3.Isolation Forest \n\n4.Conclusion ","319e38bb":"### Label Encoding","c1834306":"Isolation forest considers 1 as normal data and -1 as the anomaly data.But for our convinence we can us 1 as normal and 0 as anamoly.We have used the map funcation to do this.","e87ca527":"# 2.Data Visualization ","5fbf7830":"### Importing Dataset","7f73b0d1":"### Value counts Amount"}}