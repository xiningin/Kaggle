{"cell_type":{"9435d55c":"code","923cfd79":"code","ddee135a":"code","c342c80e":"code","75f01a7b":"code","600bd8c4":"code","2cfe0400":"code","33013e0c":"code","f6a578ad":"code","a7567e25":"code","d2a56663":"code","95a24afc":"code","74bd4d49":"markdown","77821b9f":"markdown","d5e13bbe":"markdown","ee4a7099":"markdown","359ec037":"markdown","0961fde9":"markdown","a0963a62":"markdown","59c40de8":"markdown","1f17869a":"markdown","ed86c1a6":"markdown","41c4930c":"markdown","5ab3ea5c":"markdown","a513ed43":"markdown","d0067844":"markdown"},"source":{"9435d55c":"import os\nfrom shutil import copyfile\nos.makedirs('images\/NORMAL', exist_ok=True)\nos.makedirs('images\/PNEUMONIA', exist_ok=True)\n\nbase_path = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray'\n\nfor path in ['\/train', '\/test', '\/val']:\n    for dirname, _, filenames in os.walk(base_path + path):\n        for i, file in enumerate(filenames):\n            img_class = dirname.split('\/')[6]\n            copyfile(os.path.join(dirname, file), 'images\/' + img_class + '\/' + file)","923cfd79":"for dirname, _, filenames in os.walk('images'):\n    if(len(dirname.split(\"\/\")) > 1):\n        print(dirname + \" has \" + str(len(filenames)) + \" files\")","ddee135a":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom shutil import rmtree\n\n#rmtree('train') # Remove existing, if re-run\n#rmtree('test') # Remove existing, if re-run\n\nos.makedirs('train\/NORMAL', exist_ok=True)\nos.makedirs('train\/PNEUMONIA', exist_ok=True)\nos.makedirs('test\/NORMAL', exist_ok=True)\nos.makedirs('test\/PNEUMONIA', exist_ok=True)\n\n# Split NORMAL\ntrain, test = train_test_split(os.listdir('images\/NORMAL'), \n                               test_size=0.2, \n                               random_state=42)\nfor img in train:\n    copyfile(os.path.join('images\/NORMAL\/', img), \n             os.path.join('train\/NORMAL\/', img))\nfor img in test:\n    copyfile(os.path.join('images\/NORMAL\/', img), \n             os.path.join('test\/NORMAL\/', img))\n\n# Split PNEUMONIA\ntrain, test = train_test_split(os.listdir('images\/PNEUMONIA'), \n                               test_size=0.2, \n                               random_state=42)\nfor img in train:\n    copyfile(os.path.join('images\/PNEUMONIA\/', img), \n             os.path.join('train\/PNEUMONIA\/', img))\nfor img in test:\n    copyfile(os.path.join('images\/PNEUMONIA\/', img), \n             os.path.join('test\/PNEUMONIA\/', img))","c342c80e":"from matplotlib import pyplot as plt\nfrom matplotlib import image as mpimg\n\nfor dirname, _, filenames in os.walk('train'):\n    for i, file in enumerate(filenames):\n        if(i > 1):\n            break\n        plt.imshow(mpimg.imread(os.path.join(dirname, file)), cmap='gray')\n        plt.title(dirname.split('\/')[1])\n        plt.show()","75f01a7b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nSIZE = 128\nBATCH = 64\n\n# image augmentations\nimage_gen = ImageDataGenerator(rescale=1.\/255,\n                                rotation_range=5,\n                                width_shift_range=0.1,\n                                height_shift_range=0.1,\n                                validation_split=0.2)\n\n# flow_from_directory generators\ntrain_generator = image_gen\\\n    .flow_from_directory('train',\n                        target_size=(SIZE, SIZE),\n                        class_mode=\"binary\",\n                        batch_size=BATCH,\n                        subset='training')\n\nvalidation_generator = image_gen\\\n    .flow_from_directory('train',\n                        target_size=(SIZE, SIZE),\n                        class_mode=\"binary\",\n                        batch_size=BATCH,\n                        subset='validation')","600bd8c4":"!pip install efficientnet","2cfe0400":"import efficientnet.keras as efn\nfrom tensorflow.keras.callbacks import Callback\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.metrics import Recall, Precision\n\n# Callbacks\n## Keep the best model\nmc = ModelCheckpoint('model.hdf5', \n                     save_best_only=True, \n                     verbose=0, \n                     monitor='val_loss', \n                     mode='min')\n\n## Reduce learning rate if it gets stuck in a plateau\nrlr = ReduceLROnPlateau(monitor='val_loss', \n                        factor=0.3, \n                        patience=3, \n                        min_lr=0.000001, \n                        verbose=1)\n\n# Model\n## Define the base model with EfficientNet weights\nmodel = efn.EfficientNetB4(weights = 'imagenet', \n                           include_top = False, \n                           input_shape = (SIZE, SIZE, 3))\n\n## Output layer\nx = model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dense(32, activation=\"relu\")(x)\npredictions = Dense(1, activation=\"sigmoid\")(x)\n\n## Compile and run\nmodel = Model(inputs=model.input, outputs=predictions)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy', \n              metrics=['accuracy', Recall(), Precision()])\n\nmodel_history = model.fit(train_generator,\n                            validation_data=validation_generator,\n                            steps_per_epoch=train_generator.n\/BATCH,\n                            validation_steps=validation_generator.n\/BATCH,\n                            epochs=15,\n                            verbose=1,\n                            callbacks=[mc, rlr])","33013e0c":"# Load the best model\nmodel.load_weights(\"model.hdf5\")","f6a578ad":"# Plot training and validation accuracy by epoch\nacc = model_history.history['accuracy']\nval_acc = model_history.history['val_accuracy']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()","a7567e25":"test_datagen = ImageDataGenerator(rescale=1.\/255,\n                                    rotation_range=5,\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=\"test\",\n    target_size=(SIZE, SIZE),\n    class_mode=\"binary\",\n    shuffle=False,\n    batch_size=BATCH\n)\n\npreds = model.predict_generator(generator=test_generator) # get proba predictions\nlabels = 1*(preds > 0.5) # convert proba to classes","d2a56663":"from sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nCM = confusion_matrix(test_generator.classes, labels)\nfig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\nplt.show()","95a24afc":"from sklearn.metrics import classification_report\nprint(classification_report(test_generator.classes, labels))","74bd4d49":"## Confusion matrix","77821b9f":"We'll start by addressing two major issues with the dataset. \n\nI discovered these issues after exploring the data and after my first attempt at validating a trained model:\n\n1. The original validation set was way too small (only 8 items in each class). This is insufficient, so we need to create our own train-validation split.\n2. The test set appears to be incorrectly labeled. After my first attempt at training a model I was able to achieve ~99% accuracy on both the training and validation sets, but only ~87% accuracy on the test set. After reading through some of the comments on Kaggle, it seems others have come to a similar conclusion: Some of the test set data is not correctly labeled (e.g., [see here](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\/discussion\/56672)). To address this, we'll create our own train-test split as well.\n\nThe first thing I'll do is remove the existing train\/validation\/test labels by combining the images into directories for each class, and then I'll do my own train\/test split. Later, I'll use a parameter in the `flow_from_directory` function to split the training set into training and validation sets for model training.","d5e13bbe":"# Addressing some issues with the original dataset","ee4a7099":"# Model evaluation","359ec037":"Let's look at some of the images, so we know what we're dealing with.","0961fde9":"Let's check how many images are in each class, now that we've combined them. \n\nIt appears we have imbalanced data -- i.e., a disproportionate number of items belong to the `PNEUMONIA` class. When it comes time to evaluate the model it will be important to look at more than just accuracy.","a0963a62":"To the eye of a layman like myself, it's hard to tell what distinguishes the classes. Maybe the chest area of the pneumonia images are \"cloudier\"?","59c40de8":"## Classification report","1f17869a":"Now we'll evaluate the model using the test set.","ed86c1a6":"# Model","41c4930c":"Next, let's split the new image set into training and test sets.","5ab3ea5c":"We'll train a model using EfficientNet as a base.\n\nWhen setting up the `flow_from_directory` we'll define a `validation_split`.\n\nWe'll also add precision and recall to the model metrics.","a513ed43":"In this notebook, I use [EfficientNet](https:\/\/github.com\/qubvel\/efficientnet) in keras to identify pneumonia from chest x-ray images.\n\n[EfficientNet](https:\/\/github.com\/qubvel\/efficientnet) is a CNN derived from ImageNet with similar accuracy but \"an order of magnitude fewer parameters and FLOPS\". In other words, it's a really efficient drop-in replacement for ImageNet. :)\n\nHere I show that, with few modifications to the EfficientNet base, I am able to achieve 98% accuracy, 98% precision, and 98% recall.","d0067844":"## Training performance"}}