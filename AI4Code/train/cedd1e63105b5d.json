{"cell_type":{"74eed9ba":"code","eece2ae8":"code","5aee39d5":"code","f1f87acb":"code","3036798d":"code","f1729f7a":"code","0344d61d":"code","b73176e8":"code","7ac8cc02":"code","2dda58c4":"code","6cc6adde":"code","91ebc592":"code","774192f4":"code","174eff0d":"markdown","1759ee0c":"markdown","5cdc3a41":"markdown"},"source":{"74eed9ba":"# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n# ATTENTION: Please use the provided epoch values when training.\n\n# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n# This will require you doing a lot of data preprocessing because\n# the dataset isn't split into training and validation for you\n# This code block has all the required inputs\nimport os\nimport zipfile\nimport random\nimport tensorflow as tf\nimport shutil\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nfrom os import getcwd\nimport numpy as np","eece2ae8":"path_cats_and_dogs = '..\/input\/dogs-vs-cats\/train'\nshutil.rmtree('\/input')\n\nlocal_zip = path_cats_and_dogs\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('\/input')\nzip_ref.close()\n","5aee39d5":"print(len(os.listdir('\/tmp\/PetImages\/Cat\/')))\nprint(len(os.listdir('\/tmp\/PetImages\/Dog\/')))\n\n# Expected Output:\n# 1500\n# 1500","f1f87acb":"# Use os.mkdir to create your directories\n# You will need a directory for cats-v-dogs, and subdirectories for training\n# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\ntry:\n    #YOUR CODE GOES HERE\n    os.makedirs(\"\/tmp\/cats-v-dogs\/training\/cats\/\")\n    os.makedirs(\"\/tmp\/cats-v-dogs\/training\/dogs\/\")\n    os.makedirs(\"\/tmp\/cats-v-dogs\/testing\/cats\/\")\n    os.makedirs(\"\/tmp\/cats-v-dogs\/testing\/dogs\/\")\n    \nexcept OSError:\n    pass","3036798d":"# Write a python function called split_data which takes\n# a SOURCE directory containing the files\n# a TRAINING directory that a portion of the files will be copied to\n# a TESTING directory that a portion of the files will be copie to\n# a SPLIT SIZE to determine the portion\n# The files should also be randomized, so that the training set is a random\n# X% of the files, and the test set is the remaining files\n# SO, for example, if SOURCE is PetImages\/Cat, and SPLIT SIZE is .9\n# Then 90% of the images in PetImages\/Cat will be copied to the TRAINING dir\n# and 10% of the images will be copied to the TESTING dir\n# Also -- All images should be checked, and if they have a zero file length,\n# they will not be copied over\n#\n# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n# os.path.getsize(PATH) gives you the size of the file\n# copyfile(source, destination) copies a file from source to destination\n# random.sample(list, len(list)) shuffles a list\ndef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n    All_data=os.listdir(SOURCE)\n    for i in range(len(All_data)):\n        if len(All_data[i]) == 0:\n            All_data.remove(All_data(i))\n    Train_size = int(len(All_data)*SPLIT_SIZE)\n    Test_size = int(len(All_data)*(1-SPLIT_SIZE))\n    \n    Training_data = All_data[0:Train_size]\n    Test_data = All_data[Train_size:Train_size+Test_size+1]\n    \n    for i in Training_data:\n        shutil.move(SOURCE + '\/'+i, TRAINING +'\/'+i)\n    for i in Test_data:\n        shutil.move(SOURCE + '\/'+i, TESTING +'\/'+i)\n\nCAT_SOURCE_DIR = \"\/tmp\/PetImages\/Cat\/\"\nTRAINING_CATS_DIR = \"\/tmp\/cats-v-dogs\/training\/cats\/\"\nTESTING_CATS_DIR = \"\/tmp\/cats-v-dogs\/testing\/cats\/\"\nDOG_SOURCE_DIR = \"\/tmp\/PetImages\/Dog\/\"\nTRAINING_DOGS_DIR = \"\/tmp\/cats-v-dogs\/training\/dogs\/\"\nTESTING_DOGS_DIR = \"\/tmp\/cats-v-dogs\/testing\/dogs\/\"\n\nsplit_size = .9\nsplit_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\nsplit_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)","f1729f7a":"print(len(os.listdir('\/tmp\/cats-v-dogs\/training\/cats\/')))\nprint(len(os.listdir('\/tmp\/cats-v-dogs\/training\/dogs\/')))\nprint(len(os.listdir('\/tmp\/cats-v-dogs\/testing\/cats\/')))\nprint(len(os.listdir('\/tmp\/cats-v-dogs\/testing\/dogs\/')))\n\n# Expected output:\n# 1350\n# 1350\n# 150\n# 150","0344d61d":"# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n# USE AT LEAST 3 CONVOLUTION LAYERS\nmodel = tf.keras.models.Sequential([\n# YOUR CODE HERE\n    tf.keras.layers.Conv2D(16,(3,3),input_shape = (150,150,3),activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation = 'relu'),\n    tf.keras.layers.Dense(1,activation = 'sigmoid' )\n])\n\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])","b73176e8":"TRAINING_DIR = '\/tmp\/cats-v-dogs\/training\/'\ntrain_datagen = ImageDataGenerator(rescale= 1\/255.0)\n\n# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n# TRAIN GENERATOR.\ntrain_generator = train_datagen.flow_from_directory(\n                                                   TRAINING_DIR ,\n                                                batch_size = 10,\n                                                class_mode = 'binary',\n                                                target_size = (150,150)\n)\n\nVALIDATION_DIR = '\/tmp\/cats-v-dogs\/testing\/'\nvalidation_datagen = ImageDataGenerator(rescale= 1.0\/255)\n\n# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \n# VALIDATION GENERATOR.\nvalidation_generator = validation_datagen.flow_from_directory(\n                                                VALIDATION_DIR ,\n                                                batch_size = 10,\n                                                class_mode = 'binary',\n                                                target_size = (150,150)\n)\n\n\n\n# Expected Output:\n# Found 2700 images belonging to 2 classes.\n# Found 300 images belonging to 2 classes.","7ac8cc02":"history = model.fit_generator(train_generator,\n                              epochs=2,\n                              verbose=1,\n                              validation_data=validation_generator)\n","2dda58c4":"# PLOT LOSS AND ACCURACY\n%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')\n\n# Desired output. Charts with training and validation metrics. No crash :)","6cc6adde":"# Now click the 'Submit Assignment' button above.","91ebc592":"%%javascript\n<!-- Save the notebook -->\nIPython.notebook.save_checkpoint();","774192f4":"%%javascript\nIPython.notebook.session.delete();\nwindow.onbeforeunload = null\nsetTimeout(function() { window.close(); }, 1000);","174eff0d":"# NOTE:\n\nIn the cell below you **MUST** use a batch size of 10 (`batch_size=10`) for the `train_generator` and the `validation_generator`. Using a batch size greater than 10 will exceed memory limits on the Coursera platform.","1759ee0c":"# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. ","5cdc3a41":"# Submission Instructions"}}