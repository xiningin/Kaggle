{"cell_type":{"b22c75f7":"code","0ece29d6":"code","c879e9a4":"code","aafdd8be":"code","dd647dce":"code","9ed6d9f6":"code","dce6efdc":"code","fdf5cb71":"code","b54f4966":"code","dcf5d508":"code","c9e91416":"code","c266919e":"code","ed4e6ba6":"code","1ca36671":"code","690ae070":"code","81addd2a":"markdown","346c4067":"markdown","c98e1cb3":"markdown","3e1ff5fe":"markdown","1c50a0f1":"markdown","964715b7":"markdown","d88413f6":"markdown","678af69b":"markdown","8a7bb624":"markdown","33212733":"markdown","ed4063a2":"markdown","1e2c1c8c":"markdown","617f3641":"markdown"},"source":{"b22c75f7":"get_ipython().run_line_magic('matplotlib', 'inline') \nimport joblib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing,feature_selection\n\nimport scipy.stats as ss\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0ece29d6":"cd {dirname}","c879e9a4":"def setup_seed(seed):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)","aafdd8be":"@np.vectorize\ndef is_bool(x):\n    return x in [True,False]\n'''Load data'''\ndf_train=pd.read_csv(\"train.csv\")\ndf_test=pd.read_csv(\"test.csv\")\ndf_train['terrainType']=df_train['terrainType'].astype(\"str\")\ndf_test['terrainType']=df_test['terrainType'].astype(\"str\")\ndf_mix=df_test.merge(df_train,how=\"outer\")\ndf_tmp=df_mix.iloc[:2].drop(columns=[\"class\",'id'])\n'''Categorize features by dtype'''\nall_cols=df_tmp.columns.values\nnum_cols=np.array([col for col in df_tmp[all_cols]._get_numeric_data().columns.values if col!=\"terrainType\"])\ntmp_cols=np.setdiff1d(all_cols,num_cols)\ncat_cols=tmp_cols[np.logical_or(~is_bool(df_tmp[tmp_cols].values[0]),~is_bool(df_tmp[tmp_cols].values[1]))]\nbinary_cols=np.setdiff1d(tmp_cols,cat_cols)\ncooc_cols=np.array([cont for cont in binary_cols if \"cooc\" in cont ])\nbinary_cols=np.setdiff1d(binary_cols,cooc_cols)","dd647dce":"df_train[\"class\"].value_counts()","9ed6d9f6":"df_mix[cat_cols].sample(3)","dce6efdc":"display(df_mix.weather.value_counts())\ndisplay(df_mix.weatherIcon.value_counts())","fdf5cb71":"plt.figure(figsize=[25,10])\nfor ii,cat in enumerate(cat_cols):\n    plt.subplot(3,2,ii+1)\n    plt.bar(df_train[cat].value_counts().index,df_train[cat].value_counts())\n    plt.xticks(rotation='45')","b54f4966":"plt.figure(figsize=[25,10])\nfor ii,cat in enumerate(cat_cols):\n    plt.subplot(3,2,ii+1)\n    contingency_table=pd.crosstab(df_train[cat],df_train[\"class\"])\n    sns.heatmap(contingency_table)","dcf5d508":"def cramers_v(x, y):\n    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n    uses correction from Bergsma and Wicher,\n    Journal of the Korean Statistical Society 42 (2013): 323-328\n    \"\"\"\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))\ncramers_v_corr=pd.DataFrame()\ntmp=[]\nfor cat in cat_cols:\n    tmp.append(cramers_v(df_train[cat],df_train[\"class\"]))\ncramers_v_corr[\"class\"]=cat_cols\ncramers_v_corr[\"cramers_v\"]=tmp\ncramers_v_corr.sort_values(\"cramers_v\").iloc[::-1]","c9e91416":"v_corr_matrix=pd.DataFrame()\n\nfor cat_i in cat_cols:\n    for cat_j in cat_cols:\n        v_corr_matrix.loc[cat_i,cat_j]=cramers_v(df_train[cat_i],df_train[cat_j])","c266919e":"sns.heatmap(v_corr_matrix,annot=True)","ed4e6ba6":"plt.figure(figsize=(20,3))\nsns.heatmap(pd.crosstab(df_train.continent,df_train.city))\nplt.xticks(rotation='45')\nplt.plot()\nplt.figure(figsize=(20,3))\nsns.heatmap(pd.crosstab(df_train.weather,df_train.weatherIcon))\nplt.xticks(rotation='45')\nplt.plot()","1ca36671":"## For firsttimers\nenc =preprocessing.OneHotEncoder()\nenc.fit(df_mix[cat_cols].values)\n# joblib.dump(enc,\"cat_enc.joblib\")\n\n## For secondtimers\n# enc=joblib.load(\"cat_enc.joblib\")","690ae070":"x_cat_train=enc.transform(df_train[cat_cols].values).toarray()","81addd2a":"Importances based on Cramers-V statistic:\n\n**city>terrainType>continent>weather>weatherIcon>appearedTimeOfDay**","346c4067":"There are some high correlation pairs: \n* (city,continent)\n* (weather,weatherIcon)","c98e1cb3":"**Maybe we can dump the \"continence\" tags for that we have \"city\" tags which is inclusive**","3e1ff5fe":"# Encoding Categorical features","1c50a0f1":"**Cramers-V statistic**: quantize correlation between two categorical features","964715b7":"All the categorical features may affect class probability ","d88413f6":"# Handeling Categorical featrues","678af69b":"## Distribution of Categorical features","8a7bb624":"**Contingency table**: see what the distribution of \"calss\" may be under certain feature values","33212733":"**not totally the same**","ed4063a2":"## Categorical features discriptions\n* appearedTimeOfDay: ordinal (or not), ok to be categorical\n* city: categorical\n* continent: categorical\n* terrainType: categorical\n* weather: categorical\n* weatherIcon: duplicated with weather?","1e2c1c8c":"The features are all imbalance in the data. Balancing should be taken before training.","617f3641":"## Categorical features' relation to result"}}