{"cell_type":{"56d135f3":"code","e2648b9d":"code","1b8e75f5":"code","5d54d40b":"code","9632d4dd":"code","d831ee2f":"code","ecd25bc0":"code","32614c33":"code","8dffcca0":"code","199220d1":"code","e78299ec":"code","d06b8055":"code","c22501ac":"code","762112cb":"code","fe17c0ed":"code","c877c294":"code","683ec7a2":"code","4f6416a8":"code","0d25bde4":"code","81ff95d7":"code","892aba32":"code","ec2fefa6":"code","b9631900":"code","7df37021":"code","9ef65553":"code","f5fbedbc":"code","821dd6d9":"code","0997fe92":"code","9ba6effd":"code","8ad055cf":"code","a9d4b715":"markdown","d5d81800":"markdown","93e683c4":"markdown","2b137cac":"markdown","f8cd4425":"markdown","965df675":"markdown","f68775cb":"markdown","3ef0a07c":"markdown","8efe7e02":"markdown","5e9a61f4":"markdown","f7befb23":"markdown","c3fb5fe3":"markdown","82ce5f21":"markdown","4c411188":"markdown","9ab4db90":"markdown","b8f092c0":"markdown","6928b1a5":"markdown","41f19cf8":"markdown","c204ba83":"markdown","fcbe90ae":"markdown","18d5aaaf":"markdown","d9458f85":"markdown","29282244":"markdown","9a3f5952":"markdown","a914689f":"markdown","8d4e07e8":"markdown","ef783e9a":"markdown","0738dc1a":"markdown","d761949f":"markdown","b800016e":"markdown","cecadfcd":"markdown"},"source":{"56d135f3":"import random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e2648b9d":"df = pd.read_csv(\"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\", header=None, skiprows=2)","1b8e75f5":"columns = [\"duration\", \"age\", \"gender\", \"country\", \"education\", \"role\", \"years_exp\", \"lan_python\", \"lan_r\", \"lan_sql\",\n           \"lan_c\", \"lan_c++\", \"lan_java\", \"lan_javascript\", \"lan_julia\", \"lan_swift\", \"lan_bash\",\n           \"lan_matlab\", \"lan_none\", \"lan_other\",\n           \"recommend\", \"ide_jupyter\", \"ide_rstudio\", \"ide_visual_studio\", \"ide_vs_code\", \"ide_pycharm\",\n           \"ide_spyder\", \"ide_notepad++\", \"ide_sublime_text\", \"ide_vim_emacs\", \"ide_matlab\",\n           \"ide_jupyter_notebook\", \"ide_none\", \"ide_other\", \"hosted_kaggle\", \"hosted_colab\", \"hosted_azure\",\n           \"hosted_paperspace_gradient\", \"hosted_binder_jupyterhub\", \"hosted_code_ocean\", \"hosted_ibm_watson\",\n           \"hosted_amazon_sage_maker\", \"hosted_amazon_emr\", \"hosted_google_notebooks\", \"hosted_google_datalab\",\n           \"hosted_databricks\", \"hosted_zepl\", \"hosted_deepnote\", \"hosted_observable\", \"hosted_none\",\n           \"hosted_other\", \"platform\", \"hardware_nvidia\", \"hardware_google_tpu\", \"hardware_aws_trainium\",\n           \"hardware_aws_inferentia\", \"hardware_none\", \"hardware_other\", \"tpu\", \"visual_matplotlib\",\n           \"visual_seaborn\", \"visual_plotly\", \"visual_ggplot\", \"visual_shiny\", \"visual_visual_d3_js\",\n           \"visual_altair\", \"visual_bokeh\", \"visual_geopoltlib\", \"visual_leaflet_folium\", \"visual_none\",\n           \"visual_other\", \"years_ml\", \"ml_scikit\", \"ml_tensor_flow\", \"ml_keras\", \"ml_pytorch\", \"ml_fast_ai\",\n           \"ml_mxnet\", \"ml_xgboost\", \"ml_light_gbm\", \"ml_cat_boost\", \"ml_prophet\", \"ml_h2o_3\", \"ml_caret\",\n           \"ml_tidy_models\", \"ml_jax\", \"ml_pytorch_lightning\", \"ml_hugging_face\", \"ml_none\", \"ml_other\",\n           \"algorithm_linear_logistic\", \"algorithm_tree_forest\", \"algorithm_gradient_boosting_machines\",\n           \"algorithm_bayesian\", \"algorithm_evolutionary\", \"algorithm_dense_neural\",\n           \"algorithm_convolution_neural\", \"algorithm_generative_adversarial\",\n           \"algorithm_recurrent_neural\", \"algorithm_transformer_networks\", \"algorithm_none\", \"algorithm_other\",\n           \"vision_general_purpose\", \"vision_image_segmentation\", \"vision_object_detection\",\n           \"vision_image_classification\", \"vision_generative_networks\", \"vision_none\", \"vision_other\",\n           \"nlp_word_embeddings\", \"nlp_encoder_decoder\", \"nlp_contextualized_embeddings\", \"nlp_transformer_language\",\n           \"nlp_none\", \"nlp_other\", \"industry\", \"company_size\", \"data_science_individuals\", \"employer_use_ml\",\n           \"role_analyze_understand\", \"role_build_run_infrastructure\", \"role_build_prototypes\", \"role_build_run_ml\",\n           \"role_improve_ml\", \"role_research_ml\", \"role_none\", \"role_other\", \"compensation\", \"spent_five_years\",\n           \"cloud_platforms_aws\", \"cloud_platforms_azure\", \"cloud_platforms_google\", \"cloud_platforms_ibm\",\n           \"cloud_platforms_oracle\", \"cloud_platforms_sap\", \"cloud_platforms_sales_force\", \"cloud_platforms_vmware\",\n           \"cloud_platforms_alibaba\", \"cloud_platforms_tencent\", \"cloud_platforms_none\", \"cloud_platforms_other\",\n           \"best_developer_experience\", \"cloud_products_amazon_ec2\", \"cloud_products_microsoft_vm\",\n           \"cloud_products_google_compute_engine\", \"cloud_products_none\", \"cloud_products_other\",\n           \"data_storage_azure_data_lake\", \"data_storage_azure_disk_storage\", \"data_storage_amazon_s3\",\n           \"data_storage_amazon_elastic_file_system\", \"data_storage_google_cloud_storage\",\n           \"data_storage_google_cloud_filestore\", \"data_storage_none\", \"data_storage_other\",\n           \"ml_products_amazon_sagemaker\", \"ml_products_azure_machine_learning_studio\",\n           \"ml_products_google_cloud_vertex\", \"ml_products_data_robot\", \"ml_products_data_bricks\",\n           \"ml_products_dataiku\", \"ml_products_alteryx\", \"ml_products_rapidminer\", \"ml_products_none\",\n           \"ml_products_other\", \"big_data_mysql\", \"big_data_postgresql\", \"big_data_sqlite\",\n           \"big_data_oracle\", \"big_data_mongodb\", \"big_data_snowflake\", \"big_data_ibm_db2\",\n           \"big_data_microsoft_sql\", \"big_data_microsoft_azure_sql\", \"big_data_microsoft_azure_cosmos\",\n           \"big_data_amazon_redshift\", \"big_data_amazon_aurora\", \"big_data_amazon_rds\",\n           \"big_data_amazon_dynamo_db\", \"big_data_google_bigquery\", \"big_data_google_sql\",\n           \"big_data_google_firestone\", \"big_data_google_bigtable\", \"big_data_google_spanner\",\n           \"big_data_none\", \"big_data_other\", \"big_data_most_often\", \"business_intelligence_amazon_quicksight\",\n           \"business_intelligence_microsoft_powerbi\", \"business_intelligence_google_data_studio\",\n           \"business_intelligence_looker\", \"business_intelligence_tableau\", \"business_intelligence_salesforce\",\n           \"business_intelligence_tableau_crm\", \"business_intelligence_qlik\", \"business_intelligence_domo\",\n           \"business_intelligence_tibco_spotfire\", \"business_intelligence_alteryx\", \"business_intelligence_sisense\",\n           \"business_intelligence_sap\", \"business_intelligence_microsoft_azure_synapse\",\n           \"business_intelligence_thoughtsplot\", \"business_intelligence_none\", \"business_intelligence_other\",\n           \"business_intelligence_most_often\", \"automl_automated_data_augmentation\",\n           \"automl_automated_feature_engineering\", \"automl_automated_model_selection\",\n           \"automl_model_architecture_searches\", \"automl_hyperparemeter_tuning\", \"automl_automation_full_ml_pipeline\",\n           \"automl_automl_none\", \"automl_other\", \"automl_tools_google_cloud_automl\",\n           \"automl_tools_h2o_driverless\", \"automl_tools_databricks\", \"automl_tools_datarobot\",\n           \"automl_tools_amazon_sagemaker_autopliot\", \"automl_tools_azure_automated_ml\", \"automl_tools_none\",\n           \"automl_tools_other\", \"ml_experiments_neptune\", \"ml_experiments_weights_and_biases\",\n           \"ml_experiments_comet\", \"ml_experiments_sacred_and_omniboard\", \"ml_experiments_tensorboard\",\n           \"ml_experiments_guild\", \"ml_experiments_polyaxon\", \"ml_experiments_clearml\",\n           \"ml_experiments_domino_model_monitor\", \"ml_experiments_mlflow\", \"ml_experiments_none\",\n           \"ml_experiments_other\", \"share_deploy_plotly\", \"share_deploy_streamlit\", \"share_deploy_nbviewer\",\n           \"share_deploy_github\", \"share_deploy_personal_blog\", \"share_deploy_kaggle\", \"share_deploy_colab\",\n           \"share_deploy_shiny\", \"share_deploy_do not_share\", \"share_deploy_other\", \"courses_coursera\",\n           \"courses_edx\", \"courses_kaggle_learning_courses\", \"courses_datacamp\", \"courses_fast\",\n           \"courses_udacity\", \"courses_udemy\", \"courses_linkedin_learning\",\n           \"courses_cloud_certification_programs\", \"courses_university\", \"courses_none\", \"courses_other\",\n           \"primary_tool_to_analyze\", \"media_twitter\", \"media_newsletters\", \"media_reddit\", \"media_kaggle\",\n           \"media_course_forums\", \"media_youtube\", \"media_podcasts\", \"media_blogs\", \"media_journal_publications\",\n           \"media_slack_communities\", \"media_none\", \"media_other\", \"cloud_platform_learn_aws\",\n           \"cloud_platform_learn_microsoft_azure\", \"cloud_platform_learn_google_cloud\",\"cloud_platform_learn_ibm\",\n           \"cloud_platform_learn_oracle\", \"cloud_platform_learn_sap\", \"cloud_platform_learn_vmware\",\n           \"cloud_platform_learn_salesforce\", \"cloud_platform_learn_alibaba\", \"cloud_platform_learn_tencent\",\n           \"cloud_platform_learn_none\", \"cloud_platform_learn_other\",\n           \"cloud_products_learn_amazon_ec2\", \"cloud_products_learn_microsoft_azure_vm\",\n           \"cloud_products_learn_google_cloud_compute_engine\", \"cloud_products_learn_none\",\n           \"cloud_products_learn_other\", \"data_storage_learn_microsoft_azure_data_lake\",\n           \"data_storage_learn_microsoft_azure_disk\", \"data_storage_learn_amazon_s3\",\n           \"data_storage_learn_amazon_elastic_file_system\", \"data_storage_learn_google_cloud_storage\",\n           \"data_storage_learn_google_cloud_filestore\", \"data_storage_learn_none\", \"data_storage_learn_other\",\n           \"ml_products_learn_amazon_sagemaker\", \"ml_products_learn_azure_ml_studio\",\n           \"ml_products_learn_google_cloud_vertex\", \"ml_products_learn_datarobots\", \"ml_products_learn_databricks\",\n           \"ml_products_learn_dataiku\", \"ml_products_learn_alteryx\", \"ml_products_learn_rapidminer\",\n           \"ml_products_learn_none\", \"ml_products_learn_other\", \"big_data_learn_mysql\", \"big_data_learn_postgresql\",\n           \"big_data_learn_sqlite\", \"big_data_learn_oracle\", \"big_data_learn_mongobd\", \"big_data_learn_snowflake\",\n           \"big_data_learn_ibm_db2\", \"big_data_learn_microsoft_sql\", \"big_data_learn_microsoft_azure_sql\",\n           \"big_data_learn_microsoft_azure_cosmos\", \"big_data_learn_amazon_redshift\",\n           \"big_data_learn_amazon_aurora\", \"big_data_learn_amazon_rds\", \"big_data_learn_amazon_dynamodb\",\n           \"big_data_learn_google_bigquery\", \"big_data_learn_google_sql\", \"big_data_learn_google_firestore\",\n           \"big_data_learn_google_bigtable\", \"big_data_learn_google_spanner\", \"big_data_learn_none\",\n           \"big_data_learn_other\", \"business_intelligence_learn_amazon_quicksight\",\n           \"business_intelligence_learn_microsoft_powerbi\", \"business_intelligence_learn_google_data_studio\",\n           \"business_intelligence_learn_looker\", \"business_intelligence_learn_tableau\",\n           \"business_intelligence_learn_salesforce\", \"business_intelligence_learn_einstein_analytics\",\n           \"business_intelligence_learn_qlik\", \"business_intelligence_learn_domo\",\n           \"business_intelligence_learn_tibco_spotfire\", \"business_intelligence_learn_alteryx\",\n           \"business_intelligence_learn_sisense\", \"business_intelligence_learn_sap\",\n           \"business_intelligence_learn_microsoft_azure_synapse\", \"business_intelligence_learn_thoughtsplot\",\n           \"business_intelligence_learn_none\", \"business_intelligence_learn_other\",\n           \"auto_ml_learn_automated_data_augmentation\", \"auto_ml_learn_automated_feature_engineering\",\n           \"auto_ml_learn_automated_model_selection\", \"auto_ml_learn_automated_model_architecture\",\n           \"auto_ml_learn_automated_hyperparameter_tuning\", \"auto_ml_learn_automation_full_pipelines\",\n           \"auto_ml_learn_none\", \"auto_ml_learn_other\", \"auto_ml_tool_learn_google_cloud\",\n           \"auto_ml_tool_learn_h2o_driverless\", \"auto_ml_tool_learn_databricks\", \"auto_ml_tool_learn_datarobot\",\n           \"auto_ml_tool_learn_amazon_sagemaker\", \"auto_ml_tool_learn_azure_automated_ml\",\n           \"auto_ml_tool_learn_none\", \"auto_ml_tool_learn_other\", \"ml_experiments_learn_neptune\",\n           \"ml_experiments_learn_weights_and_biases\", \"ml_experiments_learn_comet\",\n           \"ml_experiments_learn_sacred_and_omniboard\", \"ml_experiments_learn_tensorboard\",\n           \"ml_experiments_learn_guild\", \"ml_experiments_learn_polyaxon\", \"ml_experiments_learn_trains\",\n           \"ml_experiments_learn_domino_model_monitor\", \"ml_experiments_learn_mlflow\",\n           \"ml_experiments_learn_none\", \"ml_experiments_learn_other\"\n           ]\ndf.columns = columns","5d54d40b":"# create an id for each row\nid = range(len(df))\ndf[\"id\"] = id","9632d4dd":"df[\"years_exp\"].value_counts()\ndf[\"years_exp\"] = df[\"years_exp\"].astype(\"category\")\ndf[\"years_exp\"].cat.reorder_categories([\"I have never written code\", \"< 1 years\", \"1-3 years\", \"3-5 years\",\n                                        \"5-10 years\", \"10-20 years\", \"20+ years\"], inplace=True)\ndf[\"compensation\"].value_counts()\ndf[\"compensation\"] = df[\"compensation\"].astype(\"category\")\ndf[\"compensation\"].cat.reorder_categories([\"$0-999\", \"1,000-1,999\", \"2,000-2,999\", \"3,000-3,999\", \"4,000-4,999\",\n                                           \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \"15,000-19,999\",\n                                           \"20,000-24,999\", \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\",\n                                           \"50,000-59,999\", \"60,000-69,999\", \"70,000-79,999\", \"80,000-89,999\",\n                                           \"90,000-99,999\", \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\",\n                                           \"200,000-249,999\", \"250,000-299,999\", \"300,000-499,999\",\n                                           \"$500,000-999,999\", \">$1,000,000\"], inplace=True)\ndf[\"age\"].value_counts()\ndf[\"age\"] = df[\"age\"].astype(\"category\")\ndf[\"age\"].cat.reorder_categories([\"18-21\", \"22-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\",\n                                  \"55-59\", \"60-69\", \"70+\"], inplace=True)","d831ee2f":"df[\"age\"].value_counts().plot(kind=\"bar\")","ecd25bc0":"languages = [\"lan_python\", \"lan_r\", \"lan_sql\",\n           \"lan_c\", \"lan_c++\", \"lan_java\", \"lan_javascript\", \"lan_julia\", \"lan_swift\", \"lan_bash\",\n           \"lan_matlab\", \"lan_none\", \"lan_other\"]","32614c33":"languages_df = df[languages]","8dffcca0":"# remove the \"lan_\" in the names\nlanguages_new = [x[4:] for x in languages]\nlanguages_df.columns = languages_new","199220d1":"languages_df.head()","e78299ec":"languages_df= languages_df.applymap(lambda x: False if x is np.nan else True)\nlanguages_df.head()","d06b8055":"languages_df[\"age\"] = df[\"age\"]","c22501ac":"languages_count_df = languages_df.groupby(\"age\").sum()\nlanguages_count_df.plot(kind=\"bar\", stacked=\"True\")","762112cb":"languages_count_df[\"total\"] = languages_count_df.sum(axis=1)\nfor column in languages_count_df.columns:\n    languages_count_df[column] = languages_count_df[column] \/ languages_count_df[\"total\"] * 100\nlanguages_count_df.drop(\"total\", axis=1, inplace=True)\nlanguages_count_df.plot(kind=\"bar\", stacked=True, rot=0, cmap=\"tab20b\")\nax = plt.subplot(111)\nbox = ax.get_position()\nax.set_position([box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9])\n# Put a legend below current axis\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n          fancybox=True, shadow=True, ncol=8)","fe17c0ed":"# create a new recommendations data frame to look at recommendations for each individual\nrecommendations_df = languages_df.copy()\n# remove the age column\nrecommendations_df.drop(\"age\", axis=1, inplace=True)\n# add the recommend column from the original df\nrecommendations_df[\"recommend\"] = df[\"recommend\"]\n# we now have the languages used by each individual and the recommendation of each individual\n# add id so that we can convert wide to long\nrecommendations_df[\"id\"] = df[\"id\"]\n# now make data frame long so that we have a single column for the languages used\nrecommendations_df = pd.melt(recommendations_df, id_vars=[\"id\", \"recommend\"], var_name=\"languages\", value_name=\"used\").sort_values(\"id\")\n# keep only the languages that are used\nrecommendations_df = recommendations_df[recommendations_df[\"used\"] == True]\n# now get the count of each group\nrecommendations_df_count = recommendations_df.groupby([\"languages\", \"recommend\"]).size().reset_index(name=\"count\")\n# now pivot the table to wid eformat again so that we have a matrix where the columns are the languages recommended\n# and the rows are the languages used\nrecommendations_df_count = recommendations_df_count.pivot_table(index=\"languages\", columns=\"recommend\", values=\"count\")\nrecommendations_df_count.head()\n# we can now produce a heatmap\nsns.heatmap(recommendations_df_count, cmap='RdYlGn_r')","c877c294":"sns.heatmap(recommendations_df_count.loc[:, recommendations_df_count.columns != \"Python\"], cmap='RdYlGn_r')","683ec7a2":"countries = np.unique(df[\"country\"])\nlen(countries)","4f6416a8":"countries_random = random.sample(list(countries), 10)\ncountry_recommendation_df = df[[\"country\", \"recommend\"]]\ncountry_recommendation_df = country_recommendation_df[country_recommendation_df[\"country\"].isin(countries_random)]\ncountry_recommendation_count_df = country_recommendation_df.groupby([\"country\", \"recommend\"]).size().reset_index(name=\"count\")\ncountry_recommendation_count_df = country_recommendation_count_df.pivot_table(index=\"country\", columns=\"recommend\", values=\"count\")\n# replace missing values by zero\ncountry_recommendation_count_df = country_recommendation_count_df.replace(np.nan, 0)\ncountry_recommendation_count_df.plot(kind=\"bar\", stacked=True, cmap=\"tab20b\")\n# Put a legend below current axis\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))","0d25bde4":"salary_df = languages_df.copy()\nsalary_df.drop(\"age\", axis=1, inplace=True)\nsalary_df[[\"id\", \"compensation\"]] = df[[\"id\", \"compensation\"]]\nsalary_df = pd.melt(salary_df, id_vars=[\"id\", \"compensation\"], var_name=\"languages\", value_name=\"used\").sort_values(\"id\")\nsalary_df","81ff95d7":"salary_df = salary_df[salary_df[\"used\"] == True]\nsalary_df.drop(\"used\", axis=1, inplace=True)","892aba32":"salary_df = salary_df[~salary_df[\"languages\"].isin([\"none\", \"other\"])]","ec2fefa6":"salary_count_df = salary_df.groupby([\"languages\", \"compensation\"]).size().reset_index(name=\"count\").sort_values([\"languages\", \"compensation\"])\nsalary_count_df","b9631900":"salary_count_df = salary_count_df.pivot_table(index=\"languages\", columns=\"compensation\", values=\"count\").replace(np.nan, 0)\nsalary_count_df","7df37021":"salary_count_df[\"total\"] = salary_count_df.sum(axis=1)\nfor column in salary_count_df.columns:\n    salary_count_df[column] = salary_count_df[column] \/ salary_count_df[\"total\"] * 100\nsalary_count_df.drop(\"total\", axis=1, inplace=True)\nsns.heatmap(salary_count_df, cmap=\"YlGnBu\")","9ef65553":"experience_df = df[[\"id\", \"compensation\", \"years_exp\"]]\nexperience_counts_df = experience_df.groupby([\"compensation\", \"years_exp\"]).size().reset_index(name=\"count\")\nexperience_counts_df = experience_counts_df.pivot_table(index=\"compensation\", columns=\"years_exp\", values=\"count\")\nexperience_counts_df[\"total\"] = experience_counts_df.sum(axis=1)\nfor column in experience_counts_df.columns:\n    experience_counts_df[column] = experience_counts_df[column] \/ experience_counts_df[\"total\"] * 100\nexperience_counts_df.drop(\"total\", axis=1, inplace=True)\nexperience_counts_df.plot(kind=\"bar\", stacked=True)\nax = plt.subplot(111)\nbox = ax.get_position()\nax.set_position([box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9])\n# Put a legend below current axis\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))","f5fbedbc":"more_languages_df = languages_df.copy()\nmore_languages_df.drop(\"age\", axis=1, inplace=True)\nmore_languages_df[\"total_lan\"] = more_languages_df.sum(axis=1)\nmore_languages_df[\"compensation\"] = df[\"compensation\"]\nmore_languages_mean_df = more_languages_df[[\"total_lan\", \"compensation\"]].groupby(\"compensation\").mean().reset_index()\nmore_languages_mean_df.plot(x=\"compensation\", y=\"total_lan\", marker='o', rot=90)","821dd6d9":"more_languages2_df = languages_df.copy()\nmore_languages2_df.drop(\"age\", axis=1, inplace=True)\nmore_languages2_df[\"total_lan\"] = more_languages2_df.sum(axis=1)\nmore_languages2_df[\"years_exp\"] = df[\"years_exp\"]\nmore_languages2_mean_df = more_languages2_df[[\"total_lan\", \"years_exp\"]].groupby(\"years_exp\").mean().reset_index()\nmore_languages2_mean_df = more_languages2_mean_df[more_languages2_mean_df[\"years_exp\"] != \"I have never written code\"]\nmore_languages2_mean_df.plot(x=\"years_exp\", y=\"total_lan\", marker='o', rot=45)","0997fe92":"industry_df = df[[\"industry\", \"compensation\"]]\nindustry_count_df = industry_df.groupby([\"industry\", \"compensation\"]).size().reset_index(name=\"count\")\nindustry_count_df = industry_count_df.pivot_table(index=\"industry\", columns=\"compensation\", values=\"count\")\nindustry_count_df[\"total\"] = industry_count_df.sum(axis=1)\nfor column in industry_count_df.columns:\n    industry_count_df[column] = industry_count_df[column] \/ industry_count_df[\"total\"] * 100\nindustry_count_df.drop(\"total\", axis=1, inplace=True)\nsns.heatmap(industry_count_df, cmap=\"YlGnBu\")","9ba6effd":"courses = [\"courses_coursera\",\n           \"courses_edx\", \"courses_kaggle_learning_courses\", \"courses_datacamp\", \"courses_fast\",\n           \"courses_udacity\", \"courses_udemy\", \"courses_linkedin_learning\",\n           \"courses_cloud_certification_programs\", \"courses_university\", \"courses_none\", \"courses_other\"]\ncourses_df = df[courses]\ncourses_new = [x[8:] for x in courses]\ncourses_df.columns = courses_new\ncourses_df[\"id\"] = df[\"id\"]\ncourses_df = courses_df.applymap(lambda x: False if x is np.nan else True)\ncourses_df = pd.melt(courses_df, id_vars=[\"id\"], var_name=\"courses\", value_name=\"used\").sort_values(\"id\")\ncourses_df = courses_df[courses_df[\"used\"] == True]\ncourses_count_df = courses_df.groupby(\"courses\").size().reset_index(name=\"count\").sort_values(\"count\")\ncourses_count_df.plot(x = \"courses\", kind=\"barh\")","8ad055cf":"ide = [\"ide_jupyter\", \"ide_rstudio\", \"ide_visual_studio\", \"ide_vs_code\", \"ide_pycharm\",\n           \"ide_spyder\", \"ide_notepad++\", \"ide_sublime_text\", \"ide_vim_emacs\", \"ide_matlab\",\n           \"ide_jupyter_notebook\", \"ide_none\", \"ide_other\"]\nide_df = df[ide]\nide_new = [x[4:] for x in ide]\nide_df.columns = ide_new\nide_df = ide_df.applymap(lambda x: False if x is np.nan else True)\nexperience_df.drop(\"compensation\", axis=1, inplace=True)\nide_df = ide_df.join(experience_df)\nide_df = pd.melt(ide_df, id_vars=[\"id\", \"years_exp\"], var_name=\"courses\", value_name=\"used\").sort_values(\"id\")\nide_df = ide_df[ide_df[\"used\"] == True]\nide_df.drop(\"used\", axis=1, inplace=True)\nide_df.drop(\"id\", axis=1, inplace=True)\nide_count_df = ide_df.groupby([\"years_exp\", \"courses\"]).size().reset_index(name=\"count\")\nide_count_df = ide_count_df.pivot_table(index=\"years_exp\", columns=\"courses\", values=\"count\")\nide_count_df = ide_count_df.reset_index()\nide_count_df = ide_count_df[ide_count_df[\"years_exp\"] != \"I have never written code\"]\nide_count_df.set_index(\"years_exp\", inplace=True)\nide_count_df[\"total\"] = ide_count_df.sum(axis=1)\nfor column in ide_count_df.columns:\n    ide_count_df[column] = ide_count_df[column] \/ ide_count_df[\"total\"] * 100\nide_count_df.drop(\"total\", axis=1, inplace=True)\nide_count_df.plot(kind=\"bar\", stacked=True, cmap=\"tab20b\")\nax = plt.subplot(111)\nbox = ax.get_position()\nax.set_position([box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9])\n# Put a legend below current axis\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))","a9d4b715":"Yes. More languages are used as an indivdual gains more and more experience. Therefore, beginners can focus on a small number of languages now but expect to add more languages to their tool belt as they gain in experience.\n\n## Should I target a certain industry?\n\nWhat about targeting a certain industry in order to earn more? Does pay depend on industry?","d5d81800":"Next we read in the data:","93e683c4":"It does seem that those who earn the highest tend to use more than one language. Therefore, learning more than one language seems like a good idea. Perhaps learning more languages comes with experience, just like a higher salary?","2b137cac":"We notice that if a respondent states the he\/she uses a certain language, the name of the language is entered. Otherwise, the cell is a null. Let us convert this to a more readable true and false:","f8cd4425":"Some variables in the data set are cateorical in nature with a specific order existing, such as age and experience. In order to preserve the proper order, we set these columns as category types and then re-order the different levels:","965df675":"We only retain the rows with a true value in used since we are not interested in the language that the respondent does not use since it does not affect his salary:","f68775cb":"Let us now look at some of the rows:","3ef0a07c":"A first natural question to ask is whether most of the dat ascientists included in the srvey were young or old. What is the age distribution?","8efe7e02":"The plot clearly shows that python is the most used in all age groups. Due to the fact that there is a lot of variation in the number of individuals in each age group, comparing the sge groups is not easy. To be able to compare, we need to produce percentages. These percentages will help us know what percent of individuals in each age group use a specific language. To do this, we need to create a stacked plot after we have calculated the percentages:","5e9a61f4":"This makes more sense. Let us include the age column in order to see whether individuals from different age groups favor different languages:","f7befb23":"We now pivot the table in order to end up with one column for each level of compensation:","c3fb5fe3":"Next I give the columns meaningful names:","82ce5f21":"There are 66 countries, which is a lot. Let us randomly pick ten countries from the list:","4c411188":"The cell values represent the percent of individuals in each industry who earn a certain amount. We again see that most respondents are on the lower scale of pay. However, this does not mean that the plot is not without use. We see for example that most individuals in education are far less than individuals in other industries. Only a very small minority earn salaries in even the middle scales. The military industry seems to offer the highest salaries. Insurance also does not look bad. Non-profit organizations offer terrible salaries apparantly.\n\n## Should I take online courses?\n\nSo far, the advice offered to new dat ascientists is that python is the most popular, but it does not gurantee more money. In addition, focus on one, or a small number of languages, but expect to learn more languages along the way. Finally, stay away from education and non-profit organizations if salary is a priority for you.\n\nIn addition to knowing what programming language to start with, individuals might want to know where to start in terms of learnimg. Should they take specific courses? Let us look at whether the respondents indicated a preference for certain sources of courses:","9ab4db90":"In order to be able to compare the different langauges better, it would be better to produce a stacked bar chart that contains the percentages. This way we can ask \"what percentage of users who use Python are paid in a certain salary bracket:","b8f092c0":"We see that there isnt much variation based on experience. The most popular choices for all levels of experience seem to be jupyter notebook and vs_code. \n\n# Conclusion\n\nThe purpose of this analysis was to provide some insights that might be useful for individuals interested in a career in data science. Personally, knowing these results would have helped me when I first started.","6928b1a5":"We now create a new data frame that consists of these columns:","41f19cf8":"The rows represent the languages used by users while the columns represent the languages recommended. We note that the vast majority recommend python, no matter what languages they actually use actually, the presence of Python is making it difficult to make sense of the other information. Let us remove the Python recommendation:","c204ba83":"# Introduction\n\nMy interest in this data sets stems from the fact that when I was still a beginner to dat analysis I was confused as to where to start. Therefore, I have decided to look into some of the responses provided in this survey in order to extract some answers that might be useful for individuals who are new to the field. \n\nFirst we set up the environment:","fcbe90ae":"We see that users of python, R, and SQL recommend that users learn r and sql to a large extent. Once again, a beginner would do well to learn python.\n\nResults so far indicate that Python is by far the most popular no matter what the age group. It is also by far recommended the most by all users of programming languages. Let us see if this is country specific:","18d5aaaf":"We see the same patter in all countries.\n\n# Does python mean more money?\n\nThe advice so far is to learn python. Does this mean more money? To answer this question, we compare the salaries of indviduals while taking into account the languages that they use. Once again, we need to include all the columns that ask about the individual programing languages, in addition to the responses regarding compensation:","d9458f85":"Coursera seems to be a very popular place to go, followed by Kaggle. \n\n## Which IDE should I use?\n\nThe final question is to know whether a certain IDE is preferable for beginners. To answer this question, we need to produce a graph that includes information about both the experience of the individual and his\/her preferred IDE:","29282244":"This i sbetter. The figure clearly shows that python is the dominant language in all age groups, followed by SQL. Therefore, it seems that learning python is a good idea.\n\n## Do the respondents recommend Python?\n\nThe above analysis revealed that python is used the most. However, do the respondents actually recommend it the most? To answer this question, we can conduct a similar analysis, but instead of comparing the languages used with the age group, we can compare the languages used with the one that the respondent actually recommend:","9a3f5952":"Let us also remove the responses \"none\" and \"other\" for the questions about the programming languages used:","a914689f":"We can now calculate the size of each group, i.e. how many people know how to use a certain program language and are paid are a certain amount:","8d4e07e8":"Note that the column names all start with \"lan_\". Let us remove this part of the column names to make the output more readable:","ef783e9a":"We are now in a position to compare the use of different languages in each age group. Since the use of a language is indicated by true or false, we can simply add the responses in each age group to see the total number of individuals who use each language:","0738dc1a":"The figure is very clear. We note that the percentage of highly experienced individuals increases as we move from low salaries (left) to higher salaries (right). The opposite is seen for individuals with little experience. Therefore, although python is the most popular, experience is mostly responsible for salary, and not the proramming language.\n\n## Should I learn more than one language?\n\nLearning a specific language does not gurantee a higher salary. What about learning more than one? Do individuals who use more languages get paid more than individuals who use a smaller number of languages?","d761949f":"We had previously noted that the respondents are on the young side and that this might mean that the respondents do not have much experience. As we see, the highest ercentages are for the lowest compensation range. Nonetheless, we see no reason to beleive that python users are better paid than users of other programming languages. In fact, bash, swift, and julia users seem to be paid more.\n\nPerhaps differences in compensation ranges are better explained by differences in experience, and not by what programming language you use. To test this, a similar analysis is conducted, but instead of proramming language, experience is included:","b800016e":"Now I set an id to uniquely identify each record. This will be useful later when pivoting tables:","cecadfcd":"We see that the majority are on the younger side. This is not ideal because if the majority are young, then we would expect that the majority also have less experience, so the sample included in this survey migt not be representative of the population.\n\n## What programming language should I learn?\n\nThe first question that any aspiring dat ascientist might ask is what programming language should I start with? Let us look at the language cited as the most used by the respondents. Note that there are different questions for different languages. For example, one question asks if the respondent uses pythin. Another asks if the respondent uses R. This means that we need to consider all the columns that target this question. The following are the names of these columns:"}}