{"cell_type":{"d6ec54cc":"code","ad62f5e8":"code","3b567468":"code","13feeb76":"code","a4b45988":"code","a8cba17c":"code","84309b0a":"code","a86588e6":"code","33b1160c":"code","a3cf4d82":"code","faf1ca40":"code","fe2d6cfa":"code","e708b215":"code","43736b73":"code","6c21ee63":"code","4643f995":"code","84c8fdd8":"code","5402e459":"code","91d5751a":"code","4b6d55bc":"code","c8798e3d":"code","1b12f548":"code","18668167":"code","360f3595":"code","8b749c9f":"code","0d6b92b2":"code","e5b6659d":"code","32273993":"code","3a8c1818":"code","ec9f61a9":"code","9d4edfa4":"code","3d0b377d":"code","8b9a4f8a":"code","8413bade":"code","1b693201":"code","809c3a9a":"code","c49c5015":"code","d5fdf947":"code","5fd564f2":"code","8a182997":"code","f979e911":"code","d15115e3":"code","d5ca81b9":"markdown","e4ef158b":"markdown","5f6aa374":"markdown","18d4fba7":"markdown","68fbe74b":"markdown","5342fc80":"markdown","b1947499":"markdown","7e132f51":"markdown","1a17d9c2":"markdown","daf622a3":"markdown","6e62ab7a":"markdown","33c835ec":"markdown","e3cb6068":"markdown","5341372b":"markdown","661d0720":"markdown","2cf7ce21":"markdown","0f60b82e":"markdown","93d3c675":"markdown","fdb809f3":"markdown","a11cf949":"markdown","55ba3e4c":"markdown","016a163f":"markdown","f0ca8681":"markdown","dd85c718":"markdown","d201853d":"markdown","5744d7c3":"markdown","5cbb69f4":"markdown","58803f02":"markdown","4dcd12eb":"markdown","4bf8c1c6":"markdown","9ad5b30d":"markdown"},"source":{"d6ec54cc":"import numpy as np\nimport pandas as pd \nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nprint(os.listdir(\"..\/input\/dogs-vs-cats\"))\n","ad62f5e8":"import os, shutil, zipfile\nfolders = ['train', 'test1']\ncategories = []\nfor fn in folders:\n    with zipfile.ZipFile('..\/input\/dogs-vs-cats\/' + fn + \".zip\", \"r\") as z:\n        z.extractall(\".\")","3b567468":"FAST_RUN = False\nIMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3","13feeb76":"filenames = os.listdir(\"train\")\nprint(filenames)\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","a4b45988":"df.head()","a8cba17c":"df.tail()","84309b0a":"df['category'].value_counts().plot.bar()","a86588e6":"print(filenames)","33b1160c":"\nsample = random.choice(filenames)\nimage = load_img(\"train\/\"+sample)\nplt.imshow(image)","a3cf4d82":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","faf1ca40":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau","fe2d6cfa":"earlystop = EarlyStopping(patience=10)","e708b215":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","43736b73":"callbacks = [earlystop, learning_rate_reduction]","6c21ee63":"df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) ","4643f995":"train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","84c8fdd8":"train_df['category'].value_counts().plot.bar()","5402e459":"validate_df['category'].value_counts().plot.bar()","91d5751a":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=15","4b6d55bc":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"train\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","c8798e3d":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"train\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","1b12f548":"example_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"train\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","18668167":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","360f3595":"epochs=3 if FAST_RUN else 6\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","8b749c9f":"model.save_weights(\"model.h5\")","0d6b92b2":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","e5b6659d":"test_filenames = os.listdir(\"test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","32273993":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"test1\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","3a8c1818":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","ec9f61a9":"test_df['category'] = np.argmax(predict, axis=-1)","9d4edfa4":"label_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['category'] = test_df['category'].replace(label_map)","3d0b377d":"test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })","8b9a4f8a":"test_df['category'].value_counts().plot.bar()","8413bade":"sample_test = test_df.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"test1\/\"+filename, target_size=IMAGE_SIZE)\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()","1b693201":"#Confusion Matrix and Classification Report\nfrom sklearn.metrics import classification_report,confusion_matrix\nY_pred = model.predict_generator(predict)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(testdata.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['Cats', 'Dogs']\nprint(classification_report(testdata.classes, y_pred,target_names=target_names))","809c3a9a":"import keras\nimport matplotlib.pyplot as plt\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.utils import to_categorical","c49c5015":"from keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\ntrdata = ImageDataGenerator()\ntraindata = trdata.flow_from_directory(directory=\"..\/input\/cat-and-dog\/training_set\/training_set\",target_size=(227,227))\ntsdata = ImageDataGenerator()\ntestdata = tsdata.flow_from_directory(directory=\"..\/input\/cat-and-dog\/test_set\/test_set\", target_size=(227,227))","d5fdf947":"model = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding=\"valid\", activation = \"relu\"))\n\n# Max Pooling\nmodel.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"valid\"))\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding=\"same\", activation = \"relu\"))\n\n# Max Pooling\nmodel.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"valid\"))\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation = \"relu\"))\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation = \"relu\"))\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation = \"relu\"))\n\n# Max Pooling\nmodel.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"valid\"))\n\n# Passing it to a Fully Connected layer\nmodel.add(Flatten())\n# 1st Fully Connected Layer\nmodel.add(Dense(units = 9216, activation = \"relu\"))\n\n# 2nd Fully Connected Layer\nmodel.add(Dense(units = 4096, activation = \"relu\"))\n\n# 3rd Fully Connected Layer\nmodel.add(Dense(4096, activation = \"relu\"))\n\n# Output Layer\nmodel.add(Dense(2, activation = \"softmax\")) #As we have two classes","5fd564f2":"from keras.optimizers import Adam\nopt = Adam(lr=0.001)\nmodel.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","8a182997":"from keras.callbacks import ModelCheckpoint, EarlyStopping\ncheckpoint = ModelCheckpoint(\"alexnet_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\nhist = model.fit_generator(steps_per_epoch=10,generator=traindata, validation_data= testdata, validation_steps=6,epochs=6,callbacks=[checkpoint,early])","f979e911":"from keras.preprocessing import image\nimg = image.load_img(\"..\/input\/testcatdog\/test\/test\/dog.4001.jpg\",target_size=(227,227))\nimg = np.asarray(img)\nplt.imshow(img)\nimg = np.expand_dims(img, axis=0)\nfrom keras.models import load_model\nsaved_model = load_model(\"alexnet_1.h5\")\noutput = saved_model.predict(img)\nif output[0][0] > output[0][1]:\n    print(\"cat\")\nelse:\n    print('dog')","d15115e3":"#Confusion Matrix and Classification Report\nfrom sklearn.metrics import classification_report,confusion_matrix\nY_pred = model.predict_generator(output)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(testdata.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['Cats', 'Dogs']\nprint(classification_report(testdata.classes, y_pred,target_names=target_names))","d5ca81b9":"# See sample image","e4ef158b":"From our prepare data part. We map data with `{1: 'dog', 0: 'cat'}`. Now we will map the result back to dog is 1 and cat is 0","5f6aa374":"# Prepare Testing Data","18d4fba7":"**Early Stop**\n\nTo prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased","68fbe74b":"**AlexNet Architecture**","5342fc80":"**Deep Neural Network**","b1947499":"Seem to be nice ","7e132f51":"From our data we have 12000 cats and 12000 dogs","1a17d9c2":"# Build Model\n\n<img src=\"https:\/\/i.imgur.com\/ebkMGGu.jpg\" width=\"100%\"\/>","daf622a3":"### See predicted result with images","6e62ab7a":"# Define Constants","33c835ec":"Name: **Abdul Manan**\nRoll No: **191648**\nAssignment: **Deep Learning**","e3cb6068":"* **Input Layer**: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\n* **Conv Layer**: This layer will extract features from image.\n* **Pooling Layer**: This layerreduce the spatial volume of input image after convolution.\n* **Fully Connected Layer**: It connect the network from a layer to another layer\n* **Output Layer**: It is the predicted values layer. ","5341372b":"# Callbacks","661d0720":"For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max","2cf7ce21":"# Save Model","0f60b82e":"# Prepare data","93d3c675":"### Validation Generator","fdb809f3":"# Predict","a11cf949":"# Virtualize Training","55ba3e4c":"Because we will use image genaretor `with class_mode=\"categorical\"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding which is good for our classification. \n\nSo we will convert 1 to dog and 0 to cat","016a163f":"# Import Library","f0ca8681":"# Fit Model","dd85c718":"# See how our generator work","d201853d":"We will convert the predict category back into our generator classes by using `train_generator.class_indices`. It is the classes that image generator map while converting data into computer vision","5744d7c3":"# Prepare Traning Data","5cbb69f4":"### Virtaulize Result","58803f02":"# Create Testing Generator","4dcd12eb":"### See Total In count","4bf8c1c6":"# Traning Generator","9ad5b30d":"**Learning Rate Reduction**\n\nWe will reduce the learning rate when then accuracy not increase for 2 steps"}}