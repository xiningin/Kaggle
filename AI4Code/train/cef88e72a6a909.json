{"cell_type":{"dcff5563":"code","b5acc035":"code","664d3e87":"code","e8020141":"code","a88be2c7":"code","95b0b3f6":"code","818cbf5d":"code","235b66c8":"code","b5c17dc4":"code","c6477656":"code","f8b2485b":"code","177934b0":"code","28c041e2":"code","c9356eed":"code","758d6475":"code","4899bec3":"code","662dacb3":"code","5ce700ce":"code","c97181ef":"code","72f5aa47":"code","dfcfc688":"code","42531e52":"markdown","4272f4c4":"markdown","3a057de0":"markdown","b6a7676e":"markdown","e9c8550f":"markdown","b5d92f45":"markdown","42e818a8":"markdown","ff9762c2":"markdown","ebef1656":"markdown","afe797a2":"markdown"},"source":{"dcff5563":"!pip install efficientnet_pytorch","b5acc035":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torchvision import models\nfrom pathlib import Path\nPath.ls = lambda x: list(x.iterdir())\n\nimport cv2 \nimport pydicom\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom torchvision import transforms\n\nfrom torch import nn\nfrom efficientnet_pytorch import EfficientNet\nfrom efficientnet_pytorch.utils import MemoryEfficientSwish\n\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau","664d3e87":"class Config:\n    def __init__(self):\n        self.FOLDS = 2\n        self.EPOCHS = 1\n        self.DEVICE = 'cuda'\n        self.TRAIN_BS = 64\n        self.VALID_BS = 128\n        self.model_type = 'b3'\n        self.loss_fn = nn.L1Loss()\n        \nconfig = Config()","e8020141":"path = Path('\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/')\npath.ls()","a88be2c7":"train_df = pd.read_csv(path\/'train.csv')\ntrain_df.head()","95b0b3f6":"train_df = train_df.drop(np.nonzero(np.array(train_df['Patient'] == 'ID00011637202177653955184',dtype=float))[0], axis=0).reset_index(drop=True)\ntrain_df = train_df.drop(np.nonzero(np.array(train_df['Patient'] == 'ID00052637202186188008618',dtype=float))[0], axis=0).reset_index(drop=True)","818cbf5d":"def get_tab(df):\n    vector = [(df['Weeks'].values[0] - 30 )\/30]\n    \n    if df.Sex.values[0] == 'Male':\n        vector.append(0)\n    else: \n        vector.append(1)\n    \n    if df['SmokingStatus'].values[0] == 'Never smoked':\n        vector.extend([0,0])\n    elif df['SmokingStatus'].values[0] == 'Currently smokes':\n        vector.extend([0,1])\n    elif df['SmokingStatus'].values[0] == 'Ex-smoker':\n        vector.extend([1,0])\n    else :\n        vector.extend([1,1])\n    return np.array(vector)\n ","235b66c8":"TAB = {}\nTARGET = {}\nPerson = []\n\nfor i, p in enumerate(train_df.Patient.unique()):\n    sub = train_df.loc[train_df.Patient == p]\n    fvc = sub.FVC.values\n    weeks = sub.Weeks.values\n    c = np.vstack([weeks, np.ones(len(weeks))]).T\n    a, b = np.linalg.lstsq(c, fvc)[0]\n    \n    TARGET[p] = a\n    TAB[p] = get_tab(sub)\n    Person.append(p)\n\nPerson = np.array(Person)","b5c17dc4":"def get_img(path):\n    d = pydicom.dcmread(path)\n    return cv2.resize((d.pixel_array - d.RescaleIntercept) \/ (d.RescaleSlope * 1000), (512,512))","c6477656":"class Dataset:\n    def __init__(self, path, df, tabular, targets, folder = 'train'):\n        self.df = df\n        self.tabular = tabular\n        self.targets = targets\n        self.folder = folder\n        self.path = path\n        self.transform = transforms.Compose([\n            transforms.ToTensor()\n        ])\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        row = self.df.loc[idx,:]\n        pid = row['Patient']\n        # Path to record\n        record = self.path\/self.folder\/pid\n        # select image id\n        try: \n            \n            img_id =  np.random.choice(len(record.ls()))\n            \n            img = get_img(record.ls()[img_id])\n            img = self.transform(img)\n            tab = torch.from_numpy(self.tabular[pid]).float()\n            target = torch.tensor(self.targets[pid])\n            \n            return (img,tab), target\n        except Exception as e:\n            print(e)\n            print(pid, img_id)","f8b2485b":"def collate_fn(b):\n    xs, ys = zip(*b)\n    imgs, tabs = zip(*xs)\n    return (torch.stack(imgs).float(),torch.stack(tabs).float()),torch.stack(ys).float()","177934b0":"class Model(nn.Module):\n    def __init__(self,eff_name='b0'):\n        super().__init__()\n        self.input = nn.Conv2d(1,3,kernel_size=3,padding=1,stride=2)\n        self.bn = nn.BatchNorm2d(3)\n        self.model = EfficientNet.from_pretrained(f'efficientnet-{eff_name}')\n        self.model._fc = nn.Linear(1536, 500, bias=True)\n        self.meta = nn.Sequential(nn.Linear(4, 500),\n                                  nn.BatchNorm1d(500),\n                                  nn.ReLU(),\n                                  nn.Dropout(p=0.2),\n                                  nn.Linear(500,250),\n                                  nn.BatchNorm1d(250),\n                                  nn.ReLU(),\n                                  nn.Dropout(p=0.2))\n        self.output = nn.Linear(500+250, 1)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x,tab):\n        x = self.relu(self.bn(self.input(x)))\n        x = self.model(x)\n        tab = self.meta(tab)\n        x = torch.cat([x, tab],dim=1)\n        return self.output(x)","28c041e2":"from sklearn.model_selection import KFold\n\ndef get_split_idxs(n_folds=5):\n    kv = KFold(n_splits=n_folds)\n    splits = []\n    for i,(train_idx, valid_idx) in enumerate(kv.split(Person)):\n        splits.append((train_idx, valid_idx))\n        \n    return splits","c9356eed":"splits = get_split_idxs(n_folds=config.FOLDS)","758d6475":"def train_loop(model, dl, opt, sched, device, loss_fn):\n    model.train()\n    for X,y in dl:\n        imgs = X[0].to(device)\n        tabs = X[1].to(device)\n        y = y.to(device)\n        outputs = model(imgs, tabs)\n        loss = loss_fn(outputs.squeeze(), y)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        if sched is not None:\n            sched.step()\n            \n\ndef eval_loop(model, dl, device, loss_fn):\n    model.eval()\n    final_outputs = []\n    final_loss = []\n    with torch.no_grad():\n        for X,y in dl:\n            imgs = X[0].to(device)\n            tabs = X[1].to(device)\n            y=y.to(device)\n\n            outputs = model(imgs, tabs)\n            loss = loss_fn(outputs.squeeze(), y)\n\n            final_outputs.extend(outputs.detach().cpu().numpy().tolist())\n            final_loss.append(loss.detach().cpu().numpy())\n        \n    return final_outputs, final_loss","4899bec3":"from functools import partial\n\ndef apply_mod(m,f):\n    f(m)\n    for l in m.children(): apply_mod(l,f)\n\ndef set_grad(m,b):\n    if isinstance(m, (nn.Linear, nn.BatchNorm2d)): return \n    if hasattr(m, 'weight'):\n        for p in m.parameters(): p.requires_grad_(b)\n\n","662dacb3":"models = {}\nfor i in range(config.FOLDS):\n    models[i] = Model(config.model_type)","5ce700ce":"for k,v in models.items():\n    apply_mod(v.model, partial(set_grad, b=False))","c97181ef":"history = []","72f5aa47":"for i, (train_idx, valid_idx) in enumerate(splits):\n    print(f\"===================Fold : {i} ================\")\n\n    train = train_df.loc[train_df['Patient'].isin(Person[train_idx])].reset_index(drop=True)\n    valid = train_df.loc[train_df['Patient'].isin(Person[valid_idx])].reset_index(drop=True)\n\n\n    train_ds = Dataset(path, train, TAB, TARGET)\n    train_dl = torch.utils.data.DataLoader(\n        dataset=train_ds,\n        batch_size=config.TRAIN_BS,\n        shuffle=True,\n        collate_fn=collate_fn        \n    )\n\n    valid_ds = Dataset(path, valid, TAB, TARGET)\n    valid_dl = torch.utils.data.DataLoader(\n        dataset=valid_ds,\n        batch_size=config.VALID_BS,\n        shuffle=False,\n        collate_fn=collate_fn\n    )\n\n    model = models[i]\n    model.to(config.DEVICE)\n    lr=1e-3\n    momentum = 0.9\n    \n    num_steps = len(train_dl)\n    optimizer = Adam(model.parameters(), lr=lr,weight_decay=0.1)\n    scheduler = OneCycleLR(optimizer, \n                           max_lr=lr,\n                           epochs=config.EPOCHS,\n                           steps_per_epoch=num_steps\n                           )\n    sched = ReduceLROnPlateau(optimizer,\n                              verbose=True,\n                              factor=0.1)\n    losses = []\n    for epoch in range(config.EPOCHS):\n        print(f\"=================EPOCHS {epoch+1}================\")\n        train_loop(model, train_dl, optimizer, scheduler, config.DEVICE,config.loss_fn)\n        metrics = eval_loop(model, valid_dl,config.DEVICE,config.loss_fn)\n        total_loss = np.array(metrics[1]).mean()\n        losses.append(total_loss)\n        print(\"Loss ::\\t\", total_loss)\n        sched.step(total_loss)\n        \n    model.to('cpu')\n    history.append(losses)\n    \n    \n        ","dfcfc688":"for k, m in models.items():\n    torch.save(m.state_dict(), f'fold_{k}.pth')","42531e52":"# Dataset","4272f4c4":"I learnt how to use efficientnet from here : https:\/\/www.kaggle.com\/nroman\/melanoma-pytorch-starter-efficientnet","3a057de0":"# Model","b6a7676e":"These IDS raise gdcm import error. Couldn't figure it out yet. So decided to skip them for now.","e9c8550f":"# Collate function","b5d92f45":"A lot of code in this kernel is directly inspired and taken from https:\/\/www.kaggle.com\/khoongweihao\/k-fold-tf-efficientnet-models-training\/notebook . It would have been so easy to get this up and running. The attributed kernel is implemented in TensorFlow. I have implemented it in pytorch.","42e818a8":"This is something I learnt from fast.ai. Check out this notebook if interested: https:\/\/github.com\/fastai\/course-v3\/blob\/master\/nbs\/dl2\/11a_transfer_learning.ipynb","ff9762c2":"# Generating the splits","ebef1656":"# Configurations","afe797a2":"# Preprocessing the meta features"}}