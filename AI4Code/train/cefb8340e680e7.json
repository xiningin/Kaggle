{"cell_type":{"402e4df8":"code","b4c1229b":"code","59768e81":"code","d63eafb9":"code","81ee365d":"code","d9b189a3":"code","59bb2b44":"code","8076cfff":"code","9ec22dd1":"code","b5b6b9f0":"code","b4c8d5da":"code","1c8450b1":"code","88025065":"code","f54499a0":"code","7e4f1521":"code","3089cae9":"code","f64da676":"code","4b6c744a":"code","a1ab2ba2":"code","02701dc8":"code","52f16f9f":"code","3c784e78":"code","a4405555":"code","11088679":"code","a66b16f2":"code","9d308b9e":"code","9cf45e1a":"code","15ec8e25":"code","e95281bf":"code","1493ccf3":"markdown","c28bfe49":"markdown","24f5ef09":"markdown","8b739d4b":"markdown","41396d3d":"markdown","7d225e0a":"markdown","69740472":"markdown","10fac7b3":"markdown","e28e63b6":"markdown","1ff406e5":"markdown"},"source":{"402e4df8":"pip install sparkmagic","b4c1229b":"pip install pyspark","59768e81":"# libraries\nimport warnings\n# import findspark\nimport pandas as pd\nimport seaborn as sns\nfrom pyspark.ml.classification import GBTClassifier, LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, StandardScaler\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import Bucketizer\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.2f' % x)","d63eafb9":"spark = SparkSession.builder.master(\"local[*]\").getOrCreate()","81ee365d":"spark_df = spark.read.csv('..\/input\/churn-dataset', inferSchema=True, header=True)\nspark_df.show(10)","d9b189a3":"print(\"Shape: \", (spark_df.count(), len(spark_df.columns)))","59bb2b44":"spark_df.printSchema() #types of Variables","8076cfff":"spark_df.show(5)","9ec22dd1":"spark_df.describe().show() #summary statistics","b5b6b9f0":"spark_df.describe([\"age\", \"exited\"]).show() #summary statistics for specific variables","b4c8d5da":"spark_df.groupby(\"exited\").count().show() #class statistics of categorical variables","1c8450b1":"spark_df.select(\"exited\").distinct().show() #unique classes","88025065":"spark_df.groupby(\"exited\").count().show() #groupby transactions","f54499a0":"spark_df.groupby(\"exited\").agg({\"tenure\": \"mean\"}).show() #time spent","7e4f1521":"#Selection and summary statistics of all numeric variables\nnum_cols = [col[0] for col in spark_df.dtypes if col[1] != 'string']\nspark_df.select(num_cols).describe().show() ","3089cae9":"#Selection and summary of all categorical variables\ncat_cols = [col[0] for col in spark_df.dtypes if col[1] == 'string']\nspark_df.select(cat_cols).describe().show() ","f64da676":"# mean of numerical variables relative to the target variable\nfor col in [col.lower() for col in num_cols]:\n    spark_df.groupby(\"exited\").agg({col: \"mean\"}).show()","4b6c744a":"#Missing Values\nfrom pyspark.sql.functions import when, count, col\nspark_df.select([count(when(col(c).isNull(), c)).alias(c) for c in spark_df.columns]).toPandas().T","a1ab2ba2":"spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])\nspark_df.show(5)","02701dc8":"# Feature Interaction\nspark_df = spark_df.drop('rownumber', \"customerid\", \"surname\")\nspark_df = spark_df.withColumn('creditscore_salary', spark_df.creditscore \/ spark_df.estimatedsalary)\nspark_df = spark_df.withColumn('creditscore_tenure', spark_df.creditscore * spark_df.tenure)\nspark_df = spark_df.withColumn('balance_salary', spark_df.balance \/ spark_df.estimatedsalary)\nspark_df.show(5)","52f16f9f":"#Bucketization \/ Bining \/ Num to Cat\nspark_df.select('age').describe().toPandas().transpose()\nspark_df.select(\"age\").summary(\"count\", \"min\", \"25%\", \"50%\",\"75%\", \"max\").show()\nbucketizer = Bucketizer(splits=[0, 35, 55, 75, 95], inputCol=\"age\", outputCol=\"age_cat\")\nspark_df = bucketizer.setHandleInvalid(\"keep\").transform(spark_df)\nspark_df = spark_df.withColumn('age_cat', spark_df.age_cat + 1)","3c784e78":"#converting float values to integer\nspark_df = spark_df.withColumn(\"age_cat\", spark_df[\"age_cat\"].cast(\"integer\"))","a4405555":"#Label Encoding\n#indexer = StringIndexer(inputCol=\"segment\", outputCol=\"segment_label\")\n#indexer.fit(spark_df).transform(spark_df).show(5)\n#temp_sdf = indexer.fit(spark_df).transform(spark_df)\n#spark_df = temp_sdf.withColumn(\"segment_label\", temp_sdf[\"segment_label\"].cast(\"integer\"))\n#spark_df = spark_df.drop('segment')","11088679":"indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_label\")\nindexer.fit(spark_df).transform(spark_df).show(5)\ntemp_sdf = indexer.fit(spark_df).transform(spark_df)\nspark_df = temp_sdf.withColumn(\"gender_label\", temp_sdf[\"gender_label\"].cast(\"integer\"))\nspark_df = spark_df.drop('gender')","a66b16f2":"spark_df.show(5)","9d308b9e":"indexer = StringIndexer(inputCol=\"geography\", outputCol=\"geography_label\")\nindexer.fit(spark_df).transform(spark_df).show(5)\ntemp_sdf = indexer.fit(spark_df).transform(spark_df)\nspark_df = temp_sdf.withColumn(\"geography_label\", temp_sdf[\"geography_label\"].cast(\"integer\"))\nspark_df = spark_df.drop('geography')","9cf45e1a":"#One Hot Encoding\nencoder = OneHotEncoder(inputCols=[\"age_cat\", \"geography_label\"], outputCols=[\"age_cat_ohe\", \"geography_label_ohe\"])\nspark_df = encoder.fit(spark_df).transform(spark_df)","15ec8e25":"#Defining Target\nstringIndexer = StringIndexer(inputCol='exited', outputCol='label')\n\ntemp_sdf = stringIndexer.fit(spark_df).transform(spark_df)\ntemp_sdf.show()","e95281bf":"spark_df = temp_sdf.withColumn(\"label\", temp_sdf[\"label\"].cast(\"integer\"))\nspark_df.show(5)","1493ccf3":"<h1><center><span style=\"font-family:Georgia;color:#E8DCCC;font-weight:bold;background:#97A37B\"> \ud83e\udea2Creating A Spark Session","c28bfe49":"![churn-nedir_3.jpeg](attachment:cdd75f64-f9a1-4e28-bfc2-01ddda1b2fcd.jpeg)","24f5ef09":"<h1><center><span style=\"font-family:Georgia;color:#E8DCCC;font-weight:bold;background:#97A37B\"> \ud83d\udcdaImporting Libraries","8b739d4b":"# Intro\n\nAs we know, it is much more expensive to sign in a new client than keeping an existing one.\n\nIt is advantageous for banks to know what leads a client towards the decision to leave the company.\n\nChurn prevention allows companies to develop loyalty programs and retention campaigns to keep as many customers as possible.\n\n\n**Surname**: corresponds to the record (row) number and has no effect on the output.\n\n**CreditScore**: contains random values and has no effect on customer leaving the bank.\n\n**Geography**: a customer\u2019s location can affect their decision to leave the bank.\n\n**Gender**: it\u2019s interesting to explore whether gender plays a role in a customer leaving the bank.\n\n**Age**: this is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n\n**Tenure**: refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n\n**NumOfProducts**: refers to the number of products that a customer has purchased through the bank.\n\n**HasCrCard**: denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n\n**IsActiveMember**: active customers are less likely to leave the bank.\n\n**EstimatedSalary**: as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n\n**Exited**: (Dependent Variable): whether or not the customer left the bank.\n\n**Balance**: also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.","41396d3d":"<div style=\"display:fill;\n            border-radius: false;\n            border-style: solid;\n            border-color:#000000;\n            border-style: false;\n            border-width: 2px;\n            color:#CF673A;\n            font-size:15px;\n            font-family: Georgia;\n            background-color:#E8DCCC;\n            text-align:center;\n            letter-spacing:0.1px;\n            padding: 0.1em;\">\n\n**<h2>\u2661 Thank you for taking the time \u2661**","7d225e0a":"<h1><center><span style=\"font-family:Georgia;color:#E8DCCC;font-weight:bold;background:#97A37B\"> \u270d\ud83c\udffcData Preprocessing & Feature Engineering\n","69740472":"#  References","10fac7b3":"<h1><center><span style=\"font-family:Georgia;color:#E8DCCC;font-weight:bold;background:#97A37B\"> \ud83d\udcdaInstallation Required for Spark","e28e63b6":"<h1><center><span style=\"font-family:Georgia;color:#E8DCCC;font-weight:bold;background:#97A37B\"> \ud83d\udd0dExploratory Data Analysis","1ff406e5":"* https:\/\/github.com\/mvahit\n\n* https:\/\/www.kaggle.com\/kemalgunay\/pyspark-ml-churn-analysis"}}