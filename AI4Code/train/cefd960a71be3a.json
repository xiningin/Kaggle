{"cell_type":{"2963477a":"code","ff1db4d3":"code","f8b6fd68":"code","410300a9":"code","27a7a8f4":"code","0b5ff975":"code","d197bba7":"code","3806e390":"code","dfc8e559":"code","25850f6f":"code","956c45eb":"code","8af84510":"code","fd9c03df":"code","412facb6":"code","70a6be4e":"code","3a1a5123":"code","a594d1ae":"code","43b9ff1a":"code","ad23ea7f":"code","18bab699":"code","47f5e868":"markdown","686bf524":"markdown","2530cd97":"markdown","7363310c":"markdown","63a77190":"markdown","70b7ca07":"markdown"},"source":{"2963477a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff1db4d3":"import pandas as pd\nimport numpy as np\nimport nltk\nimport re\nfrom nltk.corpus import stopwords","f8b6fd68":"dataset_fake = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/Fake.csv\")\ndataset_fake[\"label\"]=1\ndataset_true = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/True.csv\")\ndataset_true[\"label\"]=0","410300a9":"dataset_fake.head(3)","27a7a8f4":"dataset_true.head(3)","0b5ff975":"dataset = pd.concat((dataset_fake,dataset_true), axis=0)\ndataset = dataset.sample(frac=1).reset_index(drop=True)","d197bba7":"dataset.head()","3806e390":"X = dataset.title\ny = dataset.label","dfc8e559":"X.head()","25850f6f":"y.head()","956c45eb":"from nltk.stem.porter import PorterStemmer\nps = PorterStemmer()","8af84510":"corpus = []\nfor i in range(len(X)):\n    news = re.sub( \"[^a-zA-Z]\",\" \",X[i])\n    news = news.lower()\n    news = news.split()\n    sub_corpus = [ps.stem(word) for word in news if not word in stopwords.words(\"english\")]\n    sub_corpus = \" \".join(sub_corpus)\n    corpus.append(sub_corpus)\ncorpus[:5]","fd9c03df":"from tensorflow.keras.preprocessing.text import one_hot\ninput_len = 1000\noh = [one_hot(word, input_len) for word in corpus]\noh[:5]","412facb6":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nohp = pad_sequences(oh, padding = \"post\")\nsent_len = len(ohp[0])\nohp[:5]","70a6be4e":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.models import Sequential","3a1a5123":"output_len = 50\nmodel = Sequential()\nmodel.add(Embedding(input_len, output_len, input_length=sent_len))\n# model.add(Dropout(0.3))\n# model.add(flatten()) Not required in Deep learning\nmodel.add(LSTM(100))\n# model.add(Dropout(0.3))\nmodel.add(Dense(1, activation=\"sigmoid\"))\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nprint(model.summary())","a594d1ae":"X_final = np.array(ohp)\ny_final = np.array(y)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size =0.2, random_state=20)","43b9ff1a":"model.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=10, batch_size=64)\ny_pred = model.predict_classes(X_test)","ad23ea7f":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred)","18bab699":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","47f5e868":"# Importing Data","686bf524":"# Model Creation","2530cd97":"# Training Model","7363310c":"# Importing Libraries","63a77190":"# Data Preprosessing","70b7ca07":"# Model Accuracy"}}