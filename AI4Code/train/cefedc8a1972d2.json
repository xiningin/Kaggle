{"cell_type":{"13cad767":"code","a5aeb3dc":"code","4444b751":"code","258d3cfd":"code","7fd3993e":"code","dce1a9d4":"code","f978f680":"code","69cbf5b5":"code","6b730b62":"code","39cdcef0":"code","46d71ddc":"code","3ffd81da":"code","41dac463":"code","0afdc2d7":"code","d14ea39b":"code","7ffa2280":"code","327d7514":"code","02c5fccd":"code","d1521987":"code","40098727":"code","3b6f9469":"code","73ce3896":"code","8cbd6fc1":"code","0b9e0420":"code","c2e9c96c":"code","5376d8e0":"code","d409003f":"code","06970a85":"code","3266ab2e":"code","a59845bb":"code","937f0171":"code","45960cfa":"code","45bf5178":"code","9a86b325":"code","01adb30a":"code","6d3123c2":"code","c53f9fbe":"code","f8ba423c":"code","a8c10279":"code","1dfdec8a":"code","b29a03a5":"code","88361b24":"code","c1e53779":"code","4941b7aa":"code","a6dce2d6":"code","11db1737":"markdown","3270a6bd":"markdown","9321f223":"markdown","740e512e":"markdown","496867da":"markdown","e647bdaa":"markdown","8a822489":"markdown","f041e29a":"markdown","9bbee307":"markdown","11d59f63":"markdown","43c40c79":"markdown","d8a62dda":"markdown","392adf76":"markdown","93afad8b":"markdown","a8c59703":"markdown","b9bea491":"markdown","a03b6d6a":"markdown","1609d5db":"markdown","61941359":"markdown","ae11172a":"markdown","ee3e46a8":"markdown","ddda17b2":"markdown","295f1689":"markdown","e0f2da5d":"markdown","1ba6da03":"markdown","43fd21a9":"markdown","560ff06c":"markdown","36a32c3c":"markdown","fb26bb00":"markdown","d39f9223":"markdown","ffdb925a":"markdown","06ac2762":"markdown","9b422be2":"markdown","0043fec8":"markdown","1be4287b":"markdown","95da780f":"markdown","0a759e9a":"markdown","99395d90":"markdown","3ab0614d":"markdown","74b05afb":"markdown","c7cc76be":"markdown","9e1497bf":"markdown","5a7f69c1":"markdown","27d54f5c":"markdown","742b79e2":"markdown"},"source":{"13cad767":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a5aeb3dc":"train = pd.read_csv('\/kaggle\/input\/heartbeat\/mitbih_train.csv',header=None)\ntest = pd.read_csv('\/kaggle\/input\/heartbeat\/mitbih_test.csv',header=None)","4444b751":"print(train.shape)\nprint(test.shape)","258d3cfd":"#plot first for training heartbeats. Each heartbeat is 188 long.\nimport matplotlib.pyplot as plt\n\nplt.subplot(2,2,1)\nplt.plot(train.iloc[0,:186])\n\nplt.subplot(2,2,2)\nplt.plot(train.iloc[1,:186])\n\nplt.subplot(2,2,3)\nplt.plot(train.iloc[2,:186])\n\nplt.subplot(2,2,4)\nplt.plot(train.iloc[3,:186])\n\nprint(train[187][0], train[187][1], train[187][2], train[187][3])","7fd3993e":"print(train[187].value_counts())","dce1a9d4":"f, axs = plt.subplots(5,1,figsize=(5,10))\n\nplt.subplot(5,1,1)\nplt.ylabel(\"Normal\")\nplt.ylim(0,1)\nplt.plot(train.loc[train[187] == 0.0].loc[0])\n\nplt.subplot(5,1,2)\nplt.ylabel(\"Supraventricular Premature\")\nplt.ylim(0,1)\nplt.plot(train.loc[train[187] == 1.0].loc[72471])\n\nplt.subplot(5,1,3)\nplt.ylabel(\"Premature VC\")\nplt.ylim(0,1)\nplt.plot(train.loc[train[187] == 2.0].loc[74694])\n\nplt.subplot(5,1,4)\nplt.ylabel(\"Fusion\")\nplt.ylim(0,1)\nplt.plot(train.loc[train[187] == 3.0].loc[80482])\n\nplt.subplot(5,1,5)\nplt.ylabel(\"Unclassifiable Beat\")\nplt.ylim(0,1)\nplt.plot(train.loc[train[187] == 4.0].loc[81123])","f978f680":"train_target = train[187]\nlabel= 187\n\ndf = train.groupby(label, group_keys=False)\ntrain = pd.DataFrame(df.apply(lambda x: x.sample(df.size().min()))).reset_index(drop=True)","69cbf5b5":"print(train[187].value_counts())","6b730b62":"train_target = train[187]\ntrain_target = train_target.values.reshape(3205,1)\n#one hot encode train_target\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import preprocessing\n# TODO: create a OneHotEncoder object, and fit it to all of X\n\n# 1. INSTANTIATE\nenc = preprocessing.OneHotEncoder()\n\n# 2. FIT\nenc.fit(train_target)\n\n# 3. Transform\nonehotlabels = enc.transform(train_target).toarray()\nonehotlabels.shape\n\ntarget = onehotlabels","39cdcef0":"print(target[0])","46d71ddc":"from sklearn.model_selection import train_test_split\n\nX = train\nX = X.drop(axis=1,columns=187)\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(X,target, test_size = 0.25, random_state = 36)","3ffd81da":"X_train = np.asarray(X_train)\nX_valid = np.asarray(X_valid)\nY_train = np.asarray(Y_train)\nY_valid = np.asarray(Y_valid)\n\n#X_train.reshape((1, 2403, 187))\nX_train = np.expand_dims(X_train, axis=2)\nX_valid = np.expand_dims(X_valid, axis=2)\nprint(X_train.shape)\nprint(Y_train.shape)","41dac463":"#1. Function to plot model's validation loss and validation accuracy\ndef plot_model_history(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()","0afdc2d7":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Flatten, Activation\n\nmodel = Sequential()\n#hidden layers is Ni + No * (2\/3) -> 187 + 5 *(2\/3) = 128\nmodel.add(LSTM(128, input_shape=(187, 1), dropout=0.2, recurrent_dropout=0.2,return_sequences=True))\nmodel.add(Flatten())\nmodel.add(Dense(5, activation='softmax')) #output of 5 potential encodings\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nepochs = 15\nbatch_size = 1\n\nhistory = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)","d14ea39b":"Y_pred = model.predict(X_valid)\n\n#Converting predictions to label\npred = list()\nfor i in range(len(Y_pred)):\n    pred.append(np.argmax(Y_pred[i]))\n#Converting one hot encoded test label to label\ntest = list()\nfor i in range(len(Y_valid)):\n    test.append(np.argmax(Y_valid[i]))","7ffa2280":"from sklearn.metrics import accuracy_score\na = accuracy_score(pred,test)\nprint('Accuracy is:', a*100)","327d7514":"import random\n\nrand_ind = random.randint(0,802)\nprint(rand_ind)\nplt.plot(X_valid[rand_ind,:,:])\n\nclass_dict = {0: \"normal\", 1: \"Supraventricular Premature Beat\", 2: \"Premature ventricular contraction\", 3:\"Fusion of ventricular and normal beat\", 4:\"Unclassifiable beat\"}\n\nprint(\"Predicted class: \", class_dict[pred[rand_ind]])\nprint(\"Actual class: \", class_dict[test[rand_ind]])","02c5fccd":"# Math\nimport math\nimport numpy as np\n\n# Tools\ndef tabulate(x, y, f):\n    \"\"\"Return a table of f(x, y). Useful for the Gram-like operations.\"\"\"\n    return np.vectorize(f)(*np.meshgrid(x, y, sparse=True))\n\ndef cos_sum(a, b):\n    \"\"\"To work with tabulate.\"\"\"\n    return(math.cos(a+b))\n\ndef sin_diff(a, b):\n    \"\"\"To work with tabulate.\"\"\"\n    return(math.sin(a-b))\n\ndef create_time_serie(size, time):\n    \"\"\"Generate a time serie of length size and dynamic with respect to time.\"\"\"\n    # Generating time-series\n    support = np.arange(0, size)\n    serie = np.cos(support + float(time))\n    return(t, serie)","d1521987":"# Math\nimport math\nimport numpy as np\n\nclass GASF:\n\n    def __init__(self):\n        pass\n    def transform(self, serie):\n        \"\"\"Compute the Gramian Angular Field of an image\"\"\"\n        # Min-Max scaling\n        min_ = np.amin(serie)\n        max_ = np.amax(serie)\n        scaled_serie = (2*serie - max_ - min_)\/(max_ - min_)\n\n        # Floating point inaccuracy!\n        scaled_serie = np.where(scaled_serie >= 1., 1., scaled_serie)\n        scaled_serie = np.where(scaled_serie <= -1., -1., scaled_serie)\n\n        # Polar encoding\n        phi = np.arccos(scaled_serie)\n        # Note! The computation of r is not necessary\n        r = np.linspace(0, 1, len(scaled_serie))\n\n        # GAF Computation (every term of the matrix)\n        gaf = tabulate(phi, phi, cos_sum)\n\n        return(gaf, phi, r, scaled_serie)\n    \nclass GADF:\n\n    def __init__(self):\n        pass\n    def transform(self, serie):\n        \"\"\"Compute the Gramian Angular Field of an image\"\"\"\n        # Min-Max scaling\n        min_ = np.amin(serie)\n        max_ = np.amax(serie)\n        scaled_serie = (2*serie - max_ - min_)\/(max_ - min_)\n\n        # Floating point inaccuracy!\n        scaled_serie = np.where(scaled_serie >= 1., 1., scaled_serie)\n        scaled_serie = np.where(scaled_serie <= -1., -1., scaled_serie)\n\n        # Polar encoding\n        phi = np.arccos(scaled_serie)\n        # Note! The computation of r is not necessary\n        r = np.linspace(0, 1, len(scaled_serie))\n\n        # GAF Computation (every term of the matrix)\n        gaf = tabulate(phi, phi, sin_diff)\n\n        return(gaf, phi, r, scaled_serie)","40098727":"gasf = GASF()\ngadf = GADF()","3b6f9469":"x_train2 = X_train.reshape(2403,187)\nx_valid2 = X_valid.reshape(802,187)","73ce3896":"x_train_gasf_images = np.zeros((2403,187,187))\ncounter = 0\nfor i in x_train2:\n    img = gasf.transform(i)\n    x_train_gasf_images[counter] = img[0]\n    counter = counter + 1","8cbd6fc1":"x_train_gadf_images = np.zeros((2403,187,187))\ncounter = 0\nfor i in x_train2:\n    img = gadf.transform(i)\n    x_train_gadf_images[counter] = img[0]\n    counter = counter + 1","0b9e0420":"x_valid_gasf_images = np.zeros((802,187,187))\ncounter2 = 0\nfor i in x_valid2:\n    img = gasf.transform(i)\n    x_valid_gasf_images[counter2] = img[0]\n    counter2 = counter2 + 1\n","c2e9c96c":"x_valid_gadf_images = np.zeros((802,187,187))\ncounter2 = 0\nfor i in x_valid2:\n    img = gadf.transform(i)\n    x_valid_gadf_images[counter2] = img[0]\n    counter2 = counter2 + 1","5376d8e0":"print(x_train_gasf_images.shape)\nprint(x_valid_gasf_images.shape)\nprint(x_train_gadf_images.shape)\nprint(x_valid_gadf_images.shape)","d409003f":"!pip install git+https:\/\/github.com\/johannfaouzi\/pyts.git","06970a85":"import matplotlib.pyplot as plt\nfrom pyts.image import MarkovTransitionField\nfrom pyts.datasets import load_gunpoint","3266ab2e":"print(np.transpose(x_train2[0].reshape(-1,1)).shape)\nprint(X_train[0,:,:].shape)","a59845bb":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nmtf = MarkovTransitionField(image_size=187)\nx_train_mtf_images = np.zeros((2403,187,187))\ncounter = 0\nfor i in x_train2:\n    img = mtf.fit_transform(np.transpose(i.reshape(-1,1)))\n    x_train_mtf_images[counter] = img[0]\n    counter = counter + 1","937f0171":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nmtf = MarkovTransitionField(image_size=187)\nx_valid_mtf_images = np.zeros((802,187,187))\ncounter = 0\nfor i in x_valid2:\n    img = mtf.fit_transform(np.transpose(i.reshape(-1,1)))\n    x_valid_mtf_images[counter] = img[0]\n    counter = counter + 1","45960cfa":"print(Y_train[512])\nprint(Y_train[67])\nprint(Y_train[55])\nprint(Y_train[9])\nprint(Y_train[77])","45bf5178":"f, axs = plt.subplots(5,4,figsize=(10,10))\n\n\nplt.subplot(5,4,1)\nplt.ylabel(\"Normal\")\nplt.plot(X_train[512])\nplt.subplot(5,4,2)\nplt.imshow(x_train_gasf_images[512])\nplt.subplot(5,4,3)\nplt.imshow(x_train_gadf_images[512])\nplt.subplot(5,4,4)\nplt.imshow(x_train_mtf_images[512])\n\nplt.subplot(5,4,5)\nplt.ylabel(\"Supraventricular Premature\")\nplt.plot(X_train[67])\nplt.subplot(5,4,6)\nplt.imshow(x_train_gasf_images[67])\nplt.subplot(5,4,7)\nplt.imshow(x_train_gadf_images[67])\nplt.subplot(5,4,8)\nplt.imshow(x_train_mtf_images[67])\n\nplt.subplot(5,4,9)\nplt.ylabel(\"Premature VC\")\nplt.plot(X_train[55])\nplt.subplot(5,4,10)\nplt.imshow(x_train_gasf_images[55])\nplt.subplot(5,4,11)\nplt.imshow(x_train_gadf_images[55])\nplt.subplot(5,4,12)\nplt.imshow(x_train_mtf_images[55])\n\nplt.subplot(5,4,13)\nplt.ylabel(\"Fusion\")\nplt.plot(X_train[9])\nplt.subplot(5,4,14)\nplt.imshow(x_train_gasf_images[9])\nplt.subplot(5,4,15)\nplt.imshow(x_train_gadf_images[9])\nplt.subplot(5,4,16)\nplt.imshow(x_train_mtf_images[9])\n\nplt.subplot(5,4,17)\nplt.xlabel(\"Timeseries\")\nplt.ylabel(\"Unclassifiable Beat\")\nplt.plot(X_train[77])\nplt.subplot(5,4,18)\nplt.xlabel(\"GASF\")\nplt.imshow(x_train_gasf_images[77])\nplt.subplot(5,4,19)\nplt.xlabel(\"GADF\")\nplt.imshow(x_train_gadf_images[77])\nplt.subplot(5,4,20)\nplt.xlabel(\"MTF\")\nplt.imshow(x_train_mtf_images[77])\n\n","9a86b325":"x_train_new = np.concatenate((np.expand_dims(x_train_gasf_images, axis=3),np.expand_dims(x_train_gadf_images, axis=3), np.expand_dims(x_train_mtf_images, axis=3)), axis=3)","01adb30a":"print(x_train_gasf_images.shape)\nprint(x_train_gadf_images.shape)\nprint(x_train_mtf_images.shape)\nprint(x_train_new.shape)","6d3123c2":"x_valid_new = np.concatenate((np.expand_dims(x_valid_gasf_images, axis=3),np.expand_dims(x_valid_gadf_images, axis=3), np.expand_dims(x_valid_mtf_images, axis=3)), axis=3)","c53f9fbe":"print(x_valid_gasf_images.shape)\nprint(x_valid_gadf_images.shape)\nprint(x_valid_mtf_images.shape)\nprint(x_valid_new.shape)","f8ba423c":"from keras.applications.resnet50 import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense","a8c10279":"from keras.layers import *\nfrom keras.models import Sequential\nfrom keras.applications.resnet50 import ResNet50\n\nCLASS_COUNT = 5\n\nbase_model = ResNet50(\n    weights='imagenet',\n    include_top=False, \n    input_shape=(187, 187, 3), \n    pooling='avg',\n)\nbase_model.trainable = False\n\nmodel = Sequential([\n  base_model,\n  Dense(CLASS_COUNT, activation='softmax'),\n])\n\n#compile model using accuracy to measure model performance\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","1dfdec8a":"print(\"training\")\nprint(x_train_new.shape)\nprint(Y_train.shape)\nprint(\"validation\")\nprint(x_valid_new.shape)\nprint(Y_valid.shape)","b29a03a5":"#train the model\nhistory = model.fit(x_train_new, Y_train, validation_data=(x_valid_new, Y_valid), epochs=10)","88361b24":"plot_model_history(history)","c1e53779":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPool2D\n#create model\nmodel = Sequential()\n#add model layers\nmodel.add(Conv2D(64, kernel_size=3, activation='softmax', input_shape=(187,187,3)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(32, kernel_size=3, activation='softmax'))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPool2D(pool_size = (2, 2)))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(5, activation='softmax'))\n\n#compile model using accuracy to measure model performance\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","4941b7aa":"#train the model\nhistory = model.fit(x_train_new, Y_train, validation_data=(x_valid_new, Y_valid), epochs=15)","a6dce2d6":"plot_model_history(history)","11db1737":"*This notebook is meant to be an initial exporation of time series classification for me. As this is one of my first notebooks and the subject matter is new to me, any feedback would be much appreciated!*","3270a6bd":"Again, while there are distinct differences between the hearbeats, there are definetely similarities between some of the classes that could result in misclassification.","9321f223":"*Transfer learning via RESNET50 was attempted but massively overfit on the validation set. A simple convolutionual NN from Keras seemed to perform better on validation data than the RESNET. Potential future routes of exploration to improve validation accuracy could be [Convolutional LSTM networks](https:\/\/papers.nips.cc\/paper\/5955-convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting.pdf) (combining RNN and CNN properties), Using Tiled CNNs as in the [original image encoding paper](https:\/\/aaai.org\/ocs\/index.php\/WS\/AAAIW15\/paper\/viewFile\/10179\/10251), or exploring state of the art TSC networks such as [InceptionTime](https:\/\/arxiv.org\/pdf\/1909.04939v2.pdf), a TSC equivalent of AlexNet. *","740e512e":"https:\/\/arxiv.org\/pdf\/1506.00327.pdf considers a GASF- GADF- MTF compound image (1 for each channel like RGB), then we can feed the 3 channel compound into a CNN","496867da":"From: \n1. [Wang and Oates et al. 2015] Zhiguang Wang and Tim Oates. **Imaging Time-Series to Improve Classification and Imputation.** In In Proceedings of the 24th International Conference on Artificial Intelligence (IJCAI'15), AAAI Press 3939-3945. https:\/\/arxiv.org\/pdf\/1506.00327.pdf \n2. **\"Encoding Time Series as Images for Visual Inspection and Classification Using Tiled Convolutional Neural Networks.\" **\nWang, Zhiguang, and Tim Oates. \nIn Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence. 2015.\n\n\n\nBecause many advances in deep learning have been made in the context of image classification, if we can somehow encode our timeseries data as an image, we could use convolutional neural networks and potentially increas classification accuracy. \n\nWe use Gramian Angular Summation Fields (GASF), Gramian Angular Difference Fields (GADF) and Markov Transition Fields (MTF) to encode the time series as images. \n\nWhile the paper feeds these into Tiled Convolutional Neural Nets ![image.png](attachment:image.png) (https:\/\/cs.stanford.edu\/~quocle\/TCNNweb\/nips_tcnn_poster.ppt), I opt to use simple CNNs here and save Tiled CNNs for future work.","e647bdaa":"Now our classes change from \"0\", \"1\", etc. to a vector of 0s and 1s shown below.","8a822489":"* 0: Normal beat\n* 1: Supraventricular premature beat\n* 2: Premature ventricular contraction\n* 3: Fusion of ventricular and normal beat\n* 4: Unclassifiable beat","f041e29a":"Implementation from: https:\/\/github.com\/devitrylouis\/imaging_time_series","9bbee307":"Convert training and validation timeseries data into GASF\/GADF encodings","11d59f63":"> Note that at each pixel, Gij denotes the superstition\/difference of the directions at ti and tj , Mij is the transition probability from the quantile at ti\nto the quantile at tj .\nGAF encodes static information while MTF depicts information about dynamics. From this point of view, we consider\nthem as three \u201corthogonal\u201d channels, like different colors in\nthe RGB image space. Thus, we can combine GAFs and MTF\nimages of the same size (i.e. SGAF s = SMT F ) to construct a\ntriple-channel image (GASF-GADF-MTF). It combines both\nthe static and dynamic statistics embedded in the raw time\nseries, and we posit that it will be able to enhance classification performance","43c40c79":"## What is an LSTM?\n\nRecurrent Neural networks contain nodes of the network that feed back to themselves. This can essentially ellicit a representation of \"memory\" in the network that makes them extremely useful for sequence data such as natural language processessing, timeseries data and genomic data.\n\nRecurrent Neural networks can be vulnerable to the vanishing gradient problem and not be able to use context from further in the past (or something it had encountered at the very beginning of a document, for example). LSTMs are a type of Recurrent neural network that get around the vanishing gradient problem by using an additive function within its \"memory unit\". \n<img src=\"https:\/\/colah.github.io\/images\/post-covers\/lstm.png\" width=\"400\"\/>\n\n(you can read more about them here: https:\/\/towardsdatascience.com\/understanding-lstm-and-its-quick-implementation-in-keras-for-sentiment-analysis-af410fd85b47)","d8a62dda":"To train my neural network I want to split up my training data into a training set and validation set. Training data will be fed to our model so that it can learn how to classify the arrythmias, while validation data will be used to test the accuracy of the classifier. I will also test against test data separately.\n\nI also want to separate the ground truth labels from the training data at this point.\n1. remove ground truth labels from training df\n2. train\/test split","392adf76":"This seems to vastly overfit on the training set...","93afad8b":"Number of Hidden layers heuristic from: https:\/\/ai.stackexchange.com\/questions\/3156\/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm\nI played around with this and got similar results from 100 - 128 units.","a8c59703":"[A great article I found explaining gramian angular fields](https:\/\/medium.com\/analytics-vidhya\/encoding-time-series-as-images-b043becbdbf3)\n\nI will attempt to explain the encoding in my own words, however many of my supporting images are from the link above.\n\nJust like we can encode complex numbers in a polar coordinate domain using magnitude and angle to represent real and imaginary pars of the number, we use a polar representation to encode our time series. \nWe can express the magnitude *r* and angle *phi* as shown below:\n<img src=\"https:\/\/miro.medium.com\/max\/370\/1*_E5pxbxn6BlXBxcQZB7NSw.png\" width=\"100\"\/>\nwhere the magnitude of the polar domain corresponds to the timesteps of the timeseries and the angle of the polar domain corresponds nonlinearly to the magnitude of the timeseries. [2]\n\n<img src=\"https:\/\/miro.medium.com\/max\/633\/1*5Q2XaC-BqDimZ-2TKz9mbg.png\" width=\"400\"\/>\nWe can then utilize the angular component of the polar coordinate system to learn about the temporal correlation between different time intervals. This is called the Gram matrix and can be displayed as an 2D image.  \n\nBasically the diagonal of the matrix can be considered the time, with top left being the start of the timeseries and bottom right being the end. **This can essentially be considered a temporal correlation matrix of the timeseries.** ","b9bea491":"*Utility function for tracking model loss and accuracy per epoch*","a03b6d6a":"## Exploratory data analysis","1609d5db":"We remake the plots of different class heartbeats earlier in the notebook as a plot of different encoded images. ","61941359":"First we try a transfer learning approach using RESNET50. Transfer learning allows us to utilize state of the art networks that have been trained and tuned on large amounts of data for long periods of time. RESNET50 is a convolutional neural network that has been used to classify images in the IMAGENET competetion. We import RESNET50 architecture from Keras library without the final output layer and add a custom Dense output layer to represent our 5 arrythmia classes.","ae11172a":"Here we graph the first four training heartbeats to get a sense of how the timeseries data looks. We see that the hearbeats are all 187 units longs, and each of the beats plotted are normal hearbeats. This tells us that amplitude and location of the QRS spike, as well as P and T wave patterns can vary between samples.\n\nStandard Heartbeat image for reference:\n![image.png](attachment:image.png)","ee3e46a8":"The third type of encoding, Markov Transition Fields bin the possible values the timeseries can take on as states in a Markov Chain, then use the timeseries data to construct a Markov Transition Matrix (probability of transitioning between states- or for our case probability that time series moves to different bins of magnitude). This is transformed into a Markov Transition Field by spreading out matrix values and considering the temporal positions of the bins. \n\n![image.png](attachment:image.png)\nhttps:\/\/arxiv.org\/pdf\/1610.07273.pdf\n\nSo basically the MTF image can be considered dynamic information about the timeseries, and what amplitudes the waveform is at a given temporal location.","ddda17b2":"So now each entry of our training and validation sets are 187x187 2D images instead of 1D 187 length timeseries.","295f1689":"Interpolation is already taken care of for this data set... let's downsample target data for multiclassification.\n> Remark: All the samples are cropped, downsampled and padded with zeroes if necessary to the fixed dimension of 188. \n","e0f2da5d":"# Naive LSTM setup","1ba6da03":"### Define our LSTM network via Keras package","43fd21a9":"### Gramian Angular Summation\/Difference Fields\n\n","560ff06c":"# Final Thoughts","36a32c3c":"Now there is an equal number of each class in our training set.","fb26bb00":"Since we will be using neural networks for our classification model, our output classes need to be turned into a numerical representation. We use one hot encoding (from sklearn package) to do this.","d39f9223":"Now we have successfully converted our testing and validation time series data into encoded images. Let's try transfer learning with a powerful CNN to see if we can better predict heartbeat classification","ffdb925a":"(I just hardcoded indeces that had examples of each class) Sorry!","06ac2762":"We try a simple CNN now...","9b422be2":"There are way more normal beats than any other class of arrythmia, so we will downsample (make class distrubtion even) shortly.","0043fec8":"# Transfer learning from RESNET50","1be4287b":"The training and testing accuracy ends up similar to the naive LSTM network. Perhaps hyperparameter optimization of the neural network is needed to increase accuracy.","95da780f":"Let's look at the distribution of classes in the training set:","0a759e9a":"GADF is used in [1] as an additional encoding of the timeseries. This is essentially the same GAF encoding explained above, except using a sin difference in the Gram matrix instead of a cos summation. This essentially creates an inverse mapping of the GASF encoding. \n\n![image.png](attachment:image.png) (from [1])","99395d90":"**Todo: Hyperparameter optimization? (activation function, architecture) Data Augmentation? Maybe try above with non-downsampled data (at least 10x training data points) **","3ab0614d":"### One hot encoding for categorical target","74b05afb":"So we have 2,403 training heartbeats and 802 validation heartbeats for a 75:25 train-test split. Let's move on to building our classifier.","c7cc76be":"To concretely show how our network classifies a heartbeat, we take a randomly generated index of the validation set and print out both the predicted and ground truth class. (This may or may not match since our accuracy is somewhat low)","9e1497bf":"Visualization of the 5 different Arrythmia Class Types","5a7f69c1":"# Time Series Classification (TSC) exploration with LSTM and Convolutional Neural Networks","27d54f5c":"# Image Encoding - a computer vision approach ","742b79e2":"So the training and testing data are timeseries of 187 timepoints, with the 188th as the ground truth class of heartbeat"}}