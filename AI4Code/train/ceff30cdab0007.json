{"cell_type":{"92d4f641":"code","7d87e003":"code","52c26e24":"code","3d593c27":"code","287a9914":"code","08cfb54b":"code","d03c922b":"code","41d3f90d":"code","fe7e0a47":"code","e1fe61aa":"code","ceb76d7d":"code","3d8650cc":"code","7ea04b7c":"code","8ead5c81":"code","c85f33e2":"code","4a6d57fe":"markdown","d6623a37":"markdown","e81734d5":"markdown","47f3d817":"markdown","a7694e1d":"markdown","c860b6b8":"markdown","b133cc6e":"markdown","42249504":"markdown","e7afc4be":"markdown","c9e2424a":"markdown","26981989":"markdown","d7453f3e":"markdown","eaf8a128":"markdown","ce38adeb":"markdown","31a3c424":"markdown"},"source":{"92d4f641":"print(\"Packages and Load Data..\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n%matplotlib inline\n\nfrom sklearn import preprocessing\n\ntrain = pd.read_csv(\"..\/input\/train.csv\", index_col = \"Id\")\ntraindex = train.index\ntest_df = pd.read_csv(\"..\/input\/test.csv\", index_col = \"Id\")\n\ntest_df[\"Target\"] = np.nan\ntrain[\"Target\"] = train[\"Target\"].map({1: \"Extreme Poverty\",\n                                       2: \"Moderate Poverty\",\n                                       3: \"Vulnerable Households\",\n                                       4: \"Non-Vulnerable Households\"})\nprint(\"Percent Class Distribution:\")\nprint(train[\"Target\"].value_counts(normalize=True)*100)\n\ndf = pd.concat([train,test_df],axis=0)\n\n# Label Encode\nlbl = preprocessing.LabelEncoder()\nprint([x for x in train.loc[:,train.dtypes == \"object\"].columns if x not in \"Target\"])\nfor col in [x for x in train.loc[:,train.dtypes == \"object\"].columns if x not in \"Target\"]:\n    df[col] = lbl.fit_transform(df[col].astype(str))\ntrain = df.loc[train.index,:]\ntest_df = df.loc[test_df.index,:]\n\ndf = pd.concat([train,test_df],axis=0)","7d87e003":"# Seperating Variables by Number of Unique Values\ntarget_var = \"Target\"\ndf_nnunique = df.nunique().reset_index().rename(columns = {\"index\": \"cols\",0:\"unique_num\"})\nbinary = list(df_nnunique.loc[df_nnunique.unique_num <= 2, \"cols\"]) + [\"Target\"]\ncontinuous = list(df_nnunique.loc[df_nnunique.unique_num > 10, \"cols\"]) + [\"Target\"]\nfew_categories = list(df_nnunique.loc[(df_nnunique.unique_num >= 3)\n                                      & (df_nnunique.unique_num <= 10) , \"cols\"])\n\nprint(\"Number of Binary Variables: \", len(binary)-1)\nprint(\"Number of Continous Variables: \", len(continuous)-1)\nprint(\"Number of Non-Binary, Categorical Variables: \", len(few_categories))","52c26e24":"# Melt\nmelt_df = pd.melt(df.loc[traindex,continuous], id_vars=\"Target\")\ngrid = sns.FacetGrid(melt_df,col=\"variable\", hue=target_var, col_wrap=3,\n                     size=4.0, aspect=1.3, sharex=False, sharey=False)\ngrid.map(sns.kdeplot, \"value\")\ngrid.set_titles(size=25)\ngrid.add_legend();\nplt.show()","3d593c27":"def rank_correlations(df, figsize=(12,20), n_charts = 18, polyorder = 2, asc = False):\n    # Rank Correlations\n    continuous_rankedcorr = (df\n                             .corr()\n                             .unstack()\n                             .sort_values(ascending=asc)\n                             .drop_duplicates().reset_index())\n    continuous_rankedcorr.columns = [\"f1\",\"f2\",\"Absoluate Correlation Coefficient\"]   \n\n    # Plot Top Correlations\n    top_corr = [(x,y) for x,y in list(continuous_rankedcorr.iloc[:, 0:2].values) if x != y]\n    f, axes = plt.subplots(int(n_charts\/3),3, figsize=figsize, sharex=False, sharey=False)\n    row = 0\n    col = 0\n    for (x,y) in top_corr[:n_charts]:\n        if col == 3:\n            col = 0\n            row += 1\n        g = sns.regplot(x=x, y=y, data=df, order=polyorder, ax = axes[row,col])\n        axes[row,col].set_title('Correlation for\\n{} and {}'.format(x, y))\n        col += 1\n    plt.tight_layout(pad=0)\n    plt.show()\nprint(\"rank_correlations Plot Function Ready..\")","287a9914":"rank_correlations(df = df.loc[traindex,continuous])","08cfb54b":"rank_correlations(df = df.loc[traindex,continuous], asc=True, polyorder = 2)","d03c922b":"# Melt\nmelt_df = pd.melt(df.loc[traindex,few_categories], id_vars=\"Target\")\nmelt_df = (melt_df.groupby(['Target', \"variable\"])['value']\n                     .value_counts(normalize=True)\n                     .rename('percentage')\n                     .mul(100)\n                     .reset_index())\nmelt_df.value = melt_df.value.astype(int)\n\n# Factor Plot\ngrid = sns.factorplot(x=\"value\", y=\"percentage\", hue= \"Target\", kind=\"bar\",\n                col=\"variable\", data=melt_df, col_wrap=2 , size=4.0, aspect=1.3,\n                sharex=False, sharey=False)\ngrid.set_titles(size=20)\n#grid.add_legend();\nplt.show()","41d3f90d":"rank_correlations(df = df.loc[traindex,few_categories], asc=False, polyorder = 1, figsize=(10,5), n_charts = 6)","fe7e0a47":"rank_correlations(df = df.loc[traindex,few_categories], asc=True, polyorder = 1, figsize=(10,5), n_charts = 6)","e1fe61aa":"# Melt\nmelt_df = pd.melt(df.loc[traindex,binary], id_vars=\"Target\")\nmelt_df = (melt_df.groupby(['Target', \"variable\"])['value']\n                     .value_counts(normalize=True)\n                     .rename('percentage')\n                     .mul(100)\n                     .reset_index())\nmelt_df.value = melt_df.value.astype(int)\n\n# Factor Plot\ngrid = sns.factorplot(x=\"value\", y=\"percentage\", hue= \"Target\", kind=\"bar\",\n                col=\"variable\", data=melt_df, col_wrap=4 , size=4.0, aspect=1.3,\n                sharex=False, sharey=False)\ngrid.set_titles(size=20)\ngrid.add_legend();\nplt.show()","ceb76d7d":"cm = sns.light_palette(\"purple\", as_cmap=True)\nbinary_means = pd.pivot_table(pd.melt(df.loc[traindex,binary], id_vars=target_var), values=\"value\",\n               index=\"variable\",columns=[\"Target\"],\n               aggfunc = np.mean)\nbinary_means = binary_means[[\"Extreme Poverty\", \"Moderate Poverty\", \"Vulnerable Households\", \"Non-Vulnerable Households\"]]\nbinary_means.style.background_gradient(cmap = cm)","3d8650cc":"# Melt\nmelt_df = pd.melt(df.loc[traindex,binary], id_vars=target_var)\nbinary_data = pd.pivot_table(melt_df, values=\"value\", index=\"variable\",columns=[\"Target\"], aggfunc = np.sum)\nbinary_data = binary_data[[\"Extreme Poverty\", \"Moderate Poverty\", \"Vulnerable Households\", \"Non-Vulnerable Households\"]]\n\nf, ax = plt.subplots(figsize=[10,10])\nsns.heatmap(binary_data, annot=False, fmt=\".2f\",cbar_kws={'label': 'Occurence'},cmap=\"YlGnBu\",ax=ax)\nax.set_title(\"Binary Variable Positive Occurence Count by Poverty Level\")\nplt.show()","7ea04b7c":"def binary_heatmap_rank_correlations(df, figsize=(12,20), n_charts = 18, asc = False):\n    # Rank Correlations\n    continuous_rankedcorr = (df\n                             .corr()\n                             .unstack()\n                             .sort_values(ascending=asc)\n                             .drop_duplicates().reset_index())\n    continuous_rankedcorr.columns = [\"f1\",\"f2\",\"Absoluate Correlation Coefficient\"]   \n\n    # Plot Top Correlations\n    top_corr = [(x,y) for x,y in list(continuous_rankedcorr.iloc[:, 0:2].values) if x != y]\n    f, axes = plt.subplots(int(n_charts\/3),3, figsize=figsize, sharex=False, sharey=False)\n    row = 0\n    col = 0\n    for (x,y) in top_corr[:n_charts]:\n        if col == 3:\n            col = 0\n            row += 1\n        axes[row,col] = sns.heatmap(pd.crosstab(df[x], df[y]),\n                    annot=False, fmt=\".2f\",cbar_kws={'label': 'Count'},cmap=\"plasma\",ax=axes[row,col])\n        axes[row,col].set_title('Binary Overlap Count for\\n{} and {}'.format(x, y))\n        col += 1\n    plt.tight_layout(pad=0)\n    plt.show()\nprint(\"binary_heatmap_rank_correlations Plot Function Ready..\")","8ead5c81":"binary_heatmap_rank_correlations(df.loc[traindex,binary], figsize=(12,6), n_charts = 6, asc = False)","c85f33e2":"binary_heatmap_rank_correlations(df.loc[traindex,binary], figsize=(12,6), n_charts = 6, asc = True)","4a6d57fe":"## **Continuous Variables** <br>","d6623a37":"**Top Negative Correlations:** <br>","e81734d5":"**Positive Correlations:**","47f3d817":"## **Investigate Top Correlations:** <br>","a7694e1d":"**Correlations:** <Br>","c860b6b8":"**Negative Correlations:** <br>","b133cc6e":"**Top Positive Correlations:** <br>","42249504":"## **Binary Variables:** <br>","e7afc4be":"## Costa Rican Poverty - Distributions and Correlations\n_By Nick Brooks, July 2018_\n\nSince most of the feature's true identities are concealed, this notebook focuses on automating the visualization of the distributions and top correlations of around 140 features.","c9e2424a":"**Top Positive Correlations:** <Br>","26981989":"**Binary Average by Poverty Level:** <br>\nThis plot enables us to glance at how the binary values interact over the poverty levels. A value of .9 means that the feature is 90% positive for a certain poverty level. <br>\nThis technique is good because it normalizes for the unequal class occurences.","d7453f3e":"**Top Negative Correlations:**","eaf8a128":"Thanks for reading, I am open to suggestions and improvements.","ce38adeb":"This plot is along the same lines as the last one, but it is not normalized for unequal class occurence.","31a3c424":"## Categorical Features\n\n**Features with 3 to 10 categories:**"}}