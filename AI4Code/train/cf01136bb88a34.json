{"cell_type":{"b970289e":"code","056309de":"code","c718ed9b":"code","e53fa40f":"code","acdd59f7":"code","9b14caea":"code","143eb16e":"code","8eaab46a":"code","dbc6a667":"code","bf1e5563":"code","7f34113f":"code","c75462be":"code","3a465492":"code","ea45a05d":"code","530f0a66":"code","4fc45617":"code","e6b7fd94":"code","a5a797ee":"code","0f7fbc4b":"code","69d77852":"code","4b15c186":"code","9e6c7dce":"code","bd9a4b86":"code","87949acb":"code","caba4e9e":"code","3f663bae":"code","993f2db0":"code","d5b45ed8":"code","12e3f193":"code","2d233f02":"code","bfec8457":"markdown"},"source":{"b970289e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","056309de":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","c718ed9b":"df = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","e53fa40f":"df.head()","acdd59f7":"df.shape","9b14caea":"sns.pairplot(data = df)","143eb16e":"sns.countplot(df['output'])","8eaab46a":"df.isnull().sum()","dbc6a667":"fig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(df.corr(),cmap='Blues',annot=True, linewidths=.5, ax=ax)","bf1e5563":"sns.countplot(x='output',data=df, hue='sex')","7f34113f":"def graph(col, col2, df):\n    plt.figure()\n    sns.countplot(x=col2, data=df, hue=col)","c75462be":"cols = df.columns\nfor col in cols:\n    graph(col,df['output'],df)","3a465492":"sns.boxplot(x='output', y='age', data=df)","ea45a05d":"import plotly.express as px\nax=px.pie(df, names= \"output\" ,template= \"plotly_dark\",title=\"Output\",hole=0.8)\nax.show()","530f0a66":"def printing(col, col2, df):\n    plt.figure()\n    sns.boxplot(x=col2, y=col, data=df)","4fc45617":"for col in cols:\n    printing(col,df['output'],df)","e6b7fd94":"x = df.drop(['output'], axis=1)\ny = df['output']","a5a797ee":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)","0f7fbc4b":"x_train","69d77852":"x_test","4b15c186":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit_transform(x_train)\nsc.transform(x_test)","9e6c7dce":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state = 10)\nclf.fit(x_train,y_train)","bd9a4b86":"y_pred = clf.predict(x_test)","87949acb":"from sklearn.metrics import accuracy_score\naccuracy_score(y_pred,y_test)","caba4e9e":"from sklearn.svm import SVC\ncl = SVC(kernel='rbf')\ncl.fit(x_train,y_train)","3f663bae":"y_pred2 = cl.predict(x_test)","993f2db0":"accuracy_score(y_pred2,y_test)","d5b45ed8":"from sklearn.ensemble import RandomForestClassifier\ncl2 = RandomForestClassifier(n_estimators=300,criterion=\"gini\",random_state=5,max_depth=100)\ncl2.fit(x_train,y_train)","12e3f193":"y_pred3 = cl2.predict(x_test)","2d233f02":"accuracy_score(y_pred3,y_test)","bfec8457":" **So we got the best accuracy of 0.8524590163934426 with Logistic Regression**  "}}