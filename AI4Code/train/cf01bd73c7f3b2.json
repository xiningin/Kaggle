{"cell_type":{"57ef7d7b":"code","c9b7331a":"code","0ff36c3c":"code","f92ccbab":"code","03c890b5":"code","e6efbbb9":"code","23786eb0":"code","5ca701b3":"code","0d53074d":"code","17fabc8e":"code","6761098a":"code","4eca03e7":"markdown","5f16afac":"markdown","23ce089b":"markdown","eab0549d":"markdown","fce1123b":"markdown","51aca241":"markdown","fc5d5c6d":"markdown"},"source":{"57ef7d7b":"import os\nimport gc\nimport random\nimport sys\nimport time\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport skimage.io\nimport cv2\nimport PIL\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip, Resize, \\\nRandomRotate90, OneOf, RandomContrast, RandomGamma, RandomBrightness, ShiftScaleRotate\nimport torch\nfrom skimage.transform import AffineTransform, warp\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.utils.data.dataloader import DataLoader\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score, confusion_matrix, accuracy_score\nimport seaborn as sn\nfrom functools import partial\n\n# Install pre-trained models\nsys.path.insert(0, '..\/input\/pytorch-pretrained-models\/semi-supervised-ImageNet1K-models-master\/semi-supervised-ImageNet1K-models-master\/')\nfrom hubconf import *\n\n#Define paths\nBASE_PATH = '\/kaggle\/input'\nTRAIN_IMG_DIR = f'{BASE_PATH}\/panda-128x128x20\/kaggle\/train_images\/'\ntrain = pd.read_csv(f'{BASE_PATH}\/prostate-cancer-grade-assessment\/train.csv').set_index('image_id')\n\n# Global variables\nMODEL_NAME = 'resnext50_32x4d_ssl' \n\nLOSS = 'CE' ","c9b7331a":"class CFG:\n    debug=False\n    lr=1e-3\n    batch_size=16\n    epochs=5\n    onecyclepolicy=False\n    seed=35\n    target_col='isup_grade'\n    n_fold=4\n    \nclass CFG_MODEL:\n    n_out = 6 # number of classes\n    lstm_layer = 2 # number of LSTM layers\n    lstm_hidden_sz = 512 # Number of features in hidden state","0ff36c3c":"files = sorted(set([p[:32] for p in os.listdir(TRAIN_IMG_DIR)]))\ntrain = train.loc[files]\ntrain = train.reset_index()","f92ccbab":"def seed_everything(seed=99):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.enabled = True\n    \n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n    \ndef init_logger(log_file='train.log'):\n    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n    \n    log_format = '%(asctime)s %(levelname)s %(message)s'\n    \n    stream_handler = StreamHandler()\n    stream_handler.setLevel(DEBUG)\n    stream_handler.setFormatter(Formatter(log_format))\n    \n    file_handler = FileHandler(log_file)\n    file_handler.setFormatter(Formatter(log_format))\n    \n    logger = getLogger('PANDA')\n    logger.setLevel(DEBUG)\n    logger.addHandler(stream_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n\nLOG_FILE = 'train.log'\nLOGGER = init_logger(LOG_FILE)","03c890b5":"class PandaDatasetInt:\n    def __init__(self, df, N, sz, transform=None):\n        self.image_ids=df.image_id.values\n        self.isup_grade = df.isup_grade.values\n        self.data_provider = df.data_provider.values\n        self.transform=transform\n        self.df=df\n        self.tile_sz = sz\n        self.tile_nb = N\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, index):\n        fn_base = f'{TRAIN_IMG_DIR}{self.image_ids[index]}'\n        img = PIL.Image.open(f\"{fn_base}.png\").convert('RGB')\n        img = np.array(img)\n        img = img.reshape(img.shape[0] \/\/ self.tile_sz, self.tile_sz, img.shape[1] \/\/ self.tile_sz, self.tile_sz, 3)\n        img = img.transpose(0, 2, 1, 3, 4).reshape(-1, self.tile_sz, self.tile_sz, 3)  # Nxszxszx3\n        img = img.astype(np.single)\n        \n        if self.transform:\n            for i in range(self.tile_nb):\n                aug = self.transform(image=img[i])\n                img[i] = aug['image'].permute(1,2,0)\n                \n        label = self.isup_grade[index]\n        provider = self.data_provider[index]\n        return  torch.tensor(img.transpose(0, 3, 1, 2)), torch.tensor(label), provider","e6efbbb9":"# Display batch\ntfm = Compose([\n        ToTensorV2(),\n    ])\n\n\ndataset = PandaDatasetInt(train, N=20, sz=128, transform=tfm)\nloader = DataLoader(dataset, batch_size=CFG.batch_size, shuffle=False)\n\nimages, label, provider = next(iter(loader))\nfor i in range(8):\n    grid = torchvision.utils.make_grid(images[i].int(), nrow=20)\n    plt.figure(figsize=(30,30))\n    plt.imshow(grid.permute(1,2,0))\n    plt.title(f'isup grade = {label[i].item()} | provider : {provider[i]}')","23786eb0":"def _resnext(block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n\n    return model\n\nclass Model(nn.Module):\n    def __init__(self, n = 6, bs = 16, nb_layer = 1, hidden = 512, device = 'cuda'):\n        super().__init__()\n        self.out_dim = n\n        self.hidden_sz = hidden\n        self.layer_dim = nb_layer\n        self.device = device\n        \n        # ResNext\n        m = _resnext(Bottleneck, [3, 4, 6, 3], False, progress=False, groups=32, width_per_group=4)\n        m.load_state_dict(torch.load('..\/input\/pytorch-pretrained-models\/semi_supervised_resnext50_32x4-ddb3e555.pth'))\n        self.backbone = nn.Sequential(*list(m.children())[:-1])\n        nc = list(m.children())[-1].in_features  # 2048\n        \n        # LSTM\n        self.lstm = nn.LSTM(nc, self.hidden_sz, self.layer_dim, dropout=0.5, batch_first=True, bidirectional=False)\n        \n        # FC              \n        self.fc = nn.Linear(self.hidden_sz, self.out_dim)\n\n    def forward(self, x):\n        # CNN\n        n = x.shape[1]\n        x = x.view(-1, x.shape[2], x.shape[3], x.shape[4]) # => x: bs*N x 3 x 128 x 128\n        x = self.backbone(x) # => x: bs*N x C x 1 x 1\n        x = x.view(-1, n, x.shape[1], x.shape[2], x.shape[3]) # => x: bs x N x C x 1 x 1\n        x = x.view(x.shape[0], x.shape[1], -1) # => x: bs x N x C\n        # Shuffle the tile features\n        row_idxs = list(range(x.shape[1]))\n        random.shuffle(row_idxs)\n        x = x[:, torch.tensor(row_idxs)]\n        \n        # LSTM\n        # Set initial hidden states\n        h0 = torch.zeros(self.layer_dim, x.shape[0], self.hidden_sz).to(self.device)\n        c0 = torch.zeros(self.layer_dim, x.shape[0], self.hidden_sz).to(self.device)\n        out,  h  = self.lstm(x, (h0, c0)) # => x: bs x hidden\n        \n        # FC\n        x = self.fc(out[:, -1, :]) # => x: bs x 6\n        return x","5ca701b3":"if CFG.debug:\n    folds = train.sample(n=50, random_state=CFG.seed).reset_index(drop=True).copy()\nelse:\n    folds = train.copy()\n\ntrain_labels = folds[CFG.target_col].values\nkf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n    folds.loc[val_index, 'fold'] = int(fold)\nfolds['fold'] = folds['fold'].astype(int)\nfolds.to_csv('folds.csv', index=None)\nfolds.head()","0d53074d":"def freeze(m):\n    for p in m.parameters():\n        p.requires_grad = False\n\ndef unfreeze(m):\n    for p in m.parameters():\n        p.requires_grad = True","17fabc8e":"def train_fn(fold):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"### fold: {fold} ###\")\n    \n    lossTrain = []\n    stepTrain = []\n    lossVal = []\n    stepVal = []\n    \n    step = 0\n        \n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n    \n    transformTrain = Compose([\n        OneOf([RandomBrightness(limit=0.15), RandomContrast(limit=0.3), RandomGamma()], p=0.25),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=0.3),\n        Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n        ),\n        ToTensorV2(),\n    ])\n\n    transformValid = Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n                        \n    train_dataset = PandaDatasetInt(folds.loc[trn_idx].reset_index(drop=True), N=20, sz=128, transform=transformTrain)\n    valid_dataset = PandaDatasetInt(folds.loc[val_idx].reset_index(drop=True), N=20, sz=128, transform=transformValid)\n    \n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, num_workers=4)\n    \n    model = Model(n=CFG_MODEL.n_out, bs=CFG.batch_size, nb_layer=CFG_MODEL.lstm_layer, hidden=CFG_MODEL.lstm_hidden_sz, device=device)\n    model.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n    if CFG.onecyclepolicy == True:\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG.lr, div_factor=100, pct_start=0.0, steps_per_epoch=len(train_loader), epochs=CFG.epochs)\n    else:\n        scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n    \n    if LOSS == 'CE':\n        criterion = nn.CrossEntropyLoss()\n    elif LOSS == 'LabelSmoothingCE':\n        criterion = label_smoothing_criterion()\n        \n    best_score = -100\n    best_loss = np.inf\n    \n    # Train only the RNN and the FC\n    freeze(model.backbone)\n    \n    for epoch in range(CFG.epochs):\n        start_time = time.time()\n        \n        # Unfreeze backbone\n        #if epoch == 5:\n        #    unfreeze(model.backbone)\n            \n        # --------- Training loop ----------\n        model.train()\n        avg_loss = 0.\n\n        optimizer.zero_grad()\n        tk0 = tqdm(enumerate(train_loader), total=len(train_loader))\n\n        for i, (images, labels, _) in tk0:\n\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lossTrain.append(loss.item())\n            stepTrain.append(step)\n            \n            if CFG.onecyclepolicy == True:\n                scheduler.step()\n\n            avg_loss += loss.item() \/ len(train_loader)\n            step += 1\n            \n        # ---------- Validation loop --------\n        model.eval()\n        avg_val_loss = 0.\n        preds = []\n        valid_labels = []\n        tk1 = tqdm(enumerate(valid_loader), total=len(valid_loader))\n\n        for i, (images, labels, _) in tk1:\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            with torch.no_grad():\n                y_preds = model(images)\n            \n            preds.append(y_preds.to('cpu').numpy().argmax(1))\n            valid_labels.append(labels.to('cpu').numpy())\n\n            loss = criterion(y_preds, labels)\n            avg_val_loss += loss.item() \/ len(valid_loader)\n            \n        lossVal.append(avg_val_loss)\n        stepVal.append(step)\n            \n        if CFG.onecyclepolicy == False:\n            scheduler.step(avg_val_loss)\n            \n        preds = np.concatenate(preds)\n        valid_labels = np.concatenate(valid_labels)\n        \n        LOGGER.debug(f'Counter preds: {Counter(preds)}')\n        score = cohen_kappa_score(valid_labels, preds, weights='quadratic')\n        \n        if epoch == (CFG.epochs - 1):\n            print(confusion_matrix(valid_labels, preds))\n\n        elapsed = time.time() - start_time\n        \n        LOGGER.debug(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.debug(f'  Epoch {epoch+1} - QWK: {score}')\n        \n        if score>best_score:\n            best_score = score\n            LOGGER.debug(f'  Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save(model.state_dict(), f'fold{fold}_se_resnext50.pth')\n            \n    # Plot losses \n    plt.figure(figsize=(26,6))\n    plt.subplot(1, 2, 1)\n    plt.plot(stepTrain, lossTrain, label=\"training loss\")\n    plt.plot(stepVal, lossVal, label = \"validation loss\")\n    plt.title('Loss')\n    plt.xlabel('step')\n    plt.legend(loc='center left')\n    plt.tight_layout()\n    plt.show()","6761098a":"train_fn(0)","4eca03e7":"# Libraries","5f16afac":"# Config","23ce089b":"# Define model","eab0549d":"# Utils","fce1123b":"# **Introduction**\n\nIt's been some weeks that the competition has started. The tiling method proposed by iafoss seems giving pretty good results on public LB. \nMajority of kernels use this method to fine-tune a CNN (resnet and its variants are often used) and predict isup grade with classification or regression.\n\nIn this kernel I've tackled a different way of classifying biopsy tissues.\nIndeed CNNs assume that inputs are independant of each other while RNNs assume that there is an interaction between the input sequences. The CNN could be used to extract tile features and the RNN could consider them as a sequence. The aim would be to extract the long-term dependencies of the features sequence to improve the classification accuracy. \n\n![image.png](attachment:image.png)\n\n1. This is a starter kernel. Unfortunately I don't have my own hardware so I cannot do all the tests that I want because of GPU quota. I hope this kernel will provide ideas for further improvements !\n2. I've \"frozen\" the backbone but one could train some epochs with that configuration and pursue training with the entire model \n3. One could also train the LSTM in pararell of the CNN and fuse features from both models, use some kind of attention layer to keep relevant features and perform classication.\n\n\nI've used a similar training framework that https:\/\/www.kaggle.com\/yasufuminakama\/panda-se-resnext50-classification-baseline + iafoss tiling method https:\/\/www.kaggle.com\/iafoss\/panda-concat-tile-pooling-starter-0-79-lb ","51aca241":"# Visualize","fc5d5c6d":"# Dataset"}}