{"cell_type":{"b527d810":"code","ce26a5e2":"code","a7ef8b44":"code","34ee5ca8":"code","4d47df19":"code","f6ae1fa4":"code","e8402dac":"code","4ed3db45":"code","6f216973":"code","2301650d":"code","e1df898f":"code","a8e034d1":"code","d908e2b5":"code","dcd17ebf":"code","f6112a4f":"code","7469d0b6":"code","3e9db709":"code","c1b5c40c":"code","b91b078d":"code","bdc80832":"code","2d87d143":"code","a8af2d47":"code","0f71c9cf":"code","eff1e125":"code","9d2ace2a":"code","0c7981f4":"code","383d80f9":"code","b5c70d6c":"code","922ab502":"code","8e32dc36":"markdown","6e60a4a8":"markdown","7adb3cb5":"markdown","9e3db95d":"markdown","f92cc512":"markdown","0b761106":"markdown","20b9142d":"markdown","9db319cb":"markdown","057d5f9a":"markdown","8098aa0e":"markdown","352c6a92":"markdown","d48b5e31":"markdown","d54c7012":"markdown","02957182":"markdown","b4dcb42f":"markdown","bb545ae4":"markdown","803984c9":"markdown","c163a763":"markdown","114f640b":"markdown","7be7443e":"markdown","e3c1d8ba":"markdown","91606336":"markdown","c3b7b4b4":"markdown","306174c3":"markdown","02a2625e":"markdown","7c43a7d0":"markdown","3b781f4f":"markdown","1d0c0bdc":"markdown","9eb121f0":"markdown","5b246a5a":"markdown","c93c5682":"markdown","aafc42a7":"markdown","be8b99e9":"markdown","6bbb4725":"markdown","e98a3c49":"markdown","a9b5707e":"markdown","4ddc600a":"markdown"},"source":{"b527d810":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce26a5e2":"# **2 - The DATA SET**","a7ef8b44":"!pip install sweetviz\n\n\n# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport sweetviz\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","34ee5ca8":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","4d47df19":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","f6ae1fa4":"train.info()","e8402dac":"# variable analysis with sweetviz\nmy_report = sweetviz.compare([train, \"Train\"], [test, \"Test\"], \"Survived\")\n","4ed3db45":"my_report.show_html(\"Report.html\") # Not providing a filename will default to SWEETVIZ_REPORT.html","6f216973":"# checking missing values\nlist1 = []\nfor i in train.columns:\n    null = sum(pd.isnull(train[i]))\n    null1 = i + ' - ' + str(null)\n    list1.append(null1)\nlist1","2301650d":"# treating empty values\nfor i in train.columns:\n    clas = train[i].dtypes\n    if clas == 'object':\n        train[i].fillna(train[i].mode()[0], inplace=True)\n    else:\n        train[i].fillna(train[i].mean(), inplace=True)\n","e1df898f":"# checking missing values\nlist1 = []\nfor i in train.columns:\n    null = sum(pd.isnull(train[i]))\n    null1 = i + ' - ' + str(null)\n    list1.append(null1)\nlist1","a8e034d1":"# eliminating features unwanted\ntrain_drop = train.drop(columns=['Name', 'Fare', 'Ticket', 'Cabin', 'Survived'])\n","d908e2b5":"train_drop.columns","dcd17ebf":"# treating categorical data - encoding\ncat_features = ['Survived', 'Pclass', 'Sex', 'Embarked']\ncat_features_minussurvived = ['Pclass', 'Sex', 'Embarked']\ntrain_proc = pd.get_dummies(train_drop, columns=cat_features_minussurvived, dummy_na=True)","f6112a4f":"train_proc.columns","7469d0b6":"train_proc.head()","3e9db709":"# applying same transformation at test\n\nfor i in test.columns:\n    clas = test[i].dtypes\n    if clas == 'object':\n        test[i].fillna(test[i].mode()[0], inplace=True)\n    else:\n        test[i].fillna(test[i].mean(), inplace=True)\n\ntest = test.drop(columns=['Name', 'Fare', 'Ticket', 'Cabin'])","c1b5c40c":"list2 = []\nfor i in test.columns:\n    null = sum(pd.isnull(test[i]))\n    null1 = i + ' - ' + str(null)\n    list2.append(null1)\nlist2","b91b078d":"test_proc = pd.get_dummies(test, columns=cat_features_minussurvived, dummy_na=True)","bdc80832":"test_proc.columns","2d87d143":"train_proc.shape","a8af2d47":"test_proc.shape","0f71c9cf":"train.head()","eff1e125":"# separating train and test\nX_train = train_proc\ny_train = train['Survived']\nX_test = test_proc","9d2ace2a":"# instance StandardScaler, fit and transform\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n","0c7981f4":"'''\n#Logistic Regression Model\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n'''","383d80f9":"#XGBClassifier\nfrom xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)","b5c70d6c":"# accuracy score\nclassifier.score(X_train, y_train)\nclassifier = round(classifier.score(X_train, y_train) * 100, 2)\nclassifier\n","922ab502":"xgb_submission = {'PassengerId': test_proc['PassengerId'], 'Survived': y_pred}\nsubmission_xgb = pd.DataFrame(xgb_submission)\nsubmission_xgb.to_csv('xgb_submission.csv', index=False)","8e32dc36":"![07%20-%20association.png](attachment:07%20-%20association.png)","6e60a4a8":"![06%20-%20fare.png](attachment:06%20-%20fare.png)","7adb3cb5":"![03-%20age.png](attachment:03-%20age.png)","9e3db95d":"# Defining variable types","f92cc512":"**5) Pclass**","0b761106":"Defining types of variables:\n* qualitative\n    * ordinal: Pclass\n    * nominal: Name, Survived, Sex, Embarked\n* quantitative\n    * continuous: PassengerId, Age, Fare\n    * discrete: SibSp, Parch    \n* mixed: \n    * Ticket    ","20b9142d":"* There are 20% of missing data in both train and test dataset\n* survivability greater at child (younger than 10 years)","9db319cb":"5) SibSp and Parch","057d5f9a":"![02%20-%20sex.png](attachment:02%20-%20sex.png)","8098aa0e":"![04%20-sibsp.png](attachment:04%20-sibsp.png)![05%20-%20parch.png](attachment:05%20-%20parch.png)","352c6a92":"**3) Sex**","d48b5e31":"* In SibSp, 1 or 2 have better chance of survival. Having some family member help survive, but not a big family.\n* In Parch, from one to three have better chance of survival. The same argument is valid here. ","d54c7012":"# Analysis with Sweetviz","02957182":"* There is no duplicate rows in any datasets\n","b4dcb42f":"# Defining missing data\n\nAge and Cabin have fewer entries:\n    total: 891\n    Age: 714\n    Cabin: 204","bb545ae4":"![01%20-%20train%20test.png](attachment:01%20-%20train%20test.png)","803984c9":"* 1st class survived more than 2nd and 3rd class\n* 2nd class survived more than 3rd class","c163a763":"**7) Associations**","114f640b":"**2) How many survived ?**","7be7443e":"The sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: **\u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc)**.","e3c1d8ba":"* Only 38% of train dataset survived.","91606336":"* sex and fare have high positive correlation with survival\n* fare and pclass have high positive correlation between them. only use one of them: pclass","c3b7b4b4":"# **1 - The Challenge**","306174c3":"**6) Fare**","02a2625e":"**Data Dictionary**\n\nVariable    Definition\t                         Key\n\nsurvival\tSurvival\t                         0 = No, 1 = Yes\npclass\t    Ticket class\t                     1 = 1st, 2 = 2nd, 3 = 3rd\nsex\t        Sex\t\nAge\t        Age in years\t\nsibsp\t    # of siblings \/ spouses aboard the Titanic\t\nparch\t    # of parents \/ children aboard the Titanic\t\nticket\t    Ticket number\t\nfare\t    Passenger fare\t\ncabin\t    Cabin number\t\nembarked\tPort of Embarkation\t                 C = Cherbourg, Q = Queenstown, S = Southampton\n\nVariable Notes\n\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","7c43a7d0":"# 4- Model, predict, solve","3b781f4f":"# 3 - EDA (Exploratory Data Analysis)","1d0c0bdc":"![08%20-%20survived.png](attachment:08%20-%20survived.png)","9eb121f0":"test_cvs contains 418 entries and will be used to test our ML model. We'll predict with our ML model what will happen with these 418 people. Will they survive?","5b246a5a":"**4) Age**","c93c5682":"We have 2 files: train_csv and test_csv.\n\ntrains_csv contains 891 entries and will be used to train our ML model. \nThe following characteristics are at this subset:","aafc42a7":"* the higher the fare higher is the chance to survive.","be8b99e9":"* Female survived more - 74% of survivors were female","6bbb4725":"![9-%20pclass.png](attachment:9-%20pclass.png)","e98a3c49":"# Importing libraries","a9b5707e":"# Loading and train dataset","4ddc600a":"**1) Comparing Train vs Test datasets**"}}