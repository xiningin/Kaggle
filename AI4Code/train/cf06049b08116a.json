{"cell_type":{"3d5bf056":"code","15476d46":"code","e753b3c9":"code","ec372945":"code","ce387523":"code","e3e188b7":"code","97ea0216":"code","8dd45489":"code","9b4866b5":"code","956a23a1":"code","2ef94596":"code","ebe6bf9b":"code","b7cde76e":"code","cb11f61b":"code","2b8e8eca":"code","983d415a":"markdown","ecee6743":"markdown","fb6f51a1":"markdown"},"source":{"3d5bf056":"import os\nimport zipfile\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.optimizers import Adam\nfrom keras.applications import MobileNet\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","15476d46":"plt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\npd.set_option('display.max_columns', 99)","e753b3c9":"img_width, img_height = 128, 128","ec372945":"# <SPECIFY YOUR PATH HERE>\npath = \"..\/input\/kaggledays-china\/\"\nos.listdir(path) # you should have test and train data here\n\n# This initial size of the pictures - change it, if you're going to crop them manually\n\n\n# Specify here where your data are located - I use combined, 3-channel data\n\ntrain_data_dir = path + 'train3c\/train3c' # train data - it should have directories for each class inside\ntest_data_dir = path + 'test3c'  # test data - you have to keep 2-level directory structure here\n\nnb_train_samples = 5024\nnb_validation_samples = 1257\nepochs = 60\nbatch_size = 512\nnb_test_samples = len(pd.read_csv(path + 'test.csv'))","ce387523":"if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)\n\n# I use sklearn's implementation of ROC AUC, out of convenience\ndef auroc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)","e3e188b7":"train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n#     shear_range=0.2,\n    zoom_range=[0.8,1.0],\n    brightness_range=[0.8,1.0],\n    rotation_range=90,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.15\n)\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    seed = 42,\n    subset='training'\n)\nvalid_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    seed = 42,\n    subset='validation'\n)\nX, y = next(train_generator)","97ea0216":"# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    zoom_range=[0.8,1.0],\n    brightness_range=[0.8,1.0],\n    rotation_range=90,\n    horizontal_flip=True,\n    vertical_flip=True\n)\n\n# avoid shuffling her - it'll make hard keeping your predictions and labels together\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode=None,\n    seed = 42,\n    shuffle = False\n)","8dd45489":"X, y = next(train_generator)\nX.shape, y.shape\nstars = X[y == 1]\nnonstars = X[y == 0]\nstars.shape, nonstars.shape","9b4866b5":"k = 5\nfig, axs = plt.subplots(nrows=k, ncols=k, sharex=True, sharey=True)\nfor i in  range(k * k):\n    axs[i \/\/k, i % k].imshow(stars[i])\nplt.tight_layout()\nplt.suptitle('Stars')\nplt.show();","956a23a1":"k = 5\nfig, axs = plt.subplots(nrows=k, ncols=k, sharex=True, sharey=True)\nfor i in  range(k * k):\n    axs[i \/\/k, i % k].imshow(nonstars[i])\nplt.tight_layout()\nplt.suptitle('Non Stars')\nplt.show();","2ef94596":"def get_model():\n    K.clear_session()\n    base_model = MobileNet(weights='imagenet', input_shape=(128, 128, 3),\n                  include_top=False, pooling='avg')\n    x = base_model.output\n    y_pred = Dense(1, activation='sigmoid')(x)\n    return Model(inputs=base_model.input, outputs=y_pred)\n\nmodel = get_model()\nprint(len(model.layers))\noptimizer = Adam(lr=0.0003)\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=[auroc])\nmodel.summary()","ebe6bf9b":"hists = []\nhist = model.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples \/\/ batch_size,\n    validation_data=valid_generator,\n    epochs=epochs,\n)\nhists.append(hist)","b7cde76e":"hist_df = pd.concat([pd.DataFrame(hist.history) for hist in hists], sort=True)\nhist_df.index = np.arange(1, len(hist_df)+1)\nfig, ax = plt.subplots(figsize=(16, 10))\nax.plot(hist_df.val_auroc, lw=5, label='Validation Accuracy')\nax.plot(hist_df.auroc, lw=5, label='Training Accuracy')\nax.set_ylabel('AUC')\nax.set_xlabel('Epoch')\nax.grid()\nplt.legend(loc=0)\nfig.savefig('hist.png', dpi=300)\nplt.show();","cb11f61b":"pred = np.zeros(nb_test_samples)\nn_tta = 30\nfor _ in range(n_tta):\n    p = model.predict_generator(test_generator, verbose=1) \n    pred += np.array([x[0] for x in p]) \/ n_tta\npred[:10] # check if format is correct\n\n\nlabels = (test_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\n# Save the data to required sumbission format\n\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"id\":[x.split(\"\/\")[2].split(\".\")[0] for x in filenames],\n                      \"is_star\":pred})\nresults.to_csv(\"results.csv\", index=False)","2b8e8eca":"results.head()","983d415a":"# Stars","ecee6743":"# NonStars","fb6f51a1":"# MobileNet with keras."}}