{"cell_type":{"97d93f0f":"code","35603ae1":"code","a9b53f09":"code","ccb12508":"code","7f89289e":"code","a8d5a88d":"code","bd5fc50c":"code","a7e8026f":"code","8d351702":"code","0a69a2c6":"code","2a33597f":"code","ad53d5f1":"code","0b5600ab":"code","544d4d65":"code","56038288":"markdown","1135378f":"markdown","287ded70":"markdown","9c066711":"markdown"},"source":{"97d93f0f":"!wget -nc https:\/\/open.kattis.com\/problems\/mnist2class\/file\/statement\/attachments\/mnist2_train.txt\n!wget -nc https:\/\/open.kattis.com\/problems\/mnist10class\/file\/statement\/attachments\/mnist10_train.txt","35603ae1":"import pickle\nimport numpy as np\nimport pandas as pd\n\nfrom time import time\nfrom itertools import product\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nBATCH_SIZE = 2048\nNUM_CLASSES = 2","a9b53f09":"def load_data(num_classes):\n    df = pd.read_csv('mnist%d_train.txt' % num_classes, sep=' ', header=None)\n    features, labels = df.iloc[:, :-1].values, df.iloc[:, -1:].values\n    \n    return train_test_split(features, labels, test_size=0.2, random_state=0)\n\nX_train, X_test, y_train, y_test = load_data(NUM_CLASSES)","ccb12508":"class BinaryNN:\n    '''\n    Class for Binary Neural Network\n\n    Arguments\n    ---------\n    - num_classes: int, default 2\n\n    - input_shape: int, default None\n        must be specified if init_weights is not Numpy array\n\n    - nodes_per_class: int, default 15\n        the number of hidden nodes used for each class\n\n    - init_weights: None, or Numpy array\n        if Numpy array, should be in shape of (nodes_per_class * num_classes, input_shape)\n    '''\n\n    def __init__(self, num_classes=2, input_shape=None, nodes_per_class=15, init_weights=None):\n        self.num_classes = num_classes\n\n        if isinstance(init_weights, np.ndarray):\n            assert(init_weights.ndim == 2)\n            self.weights = init_weights\n            self.hidden_nodes, self.input_shape = self.weights.shape\n            \n            assert(self.hidden_nodes % num_classes == 0)\n            self.nodes_per_class = self.hidden_nodes \/\/ num_classes\n        else:\n            assert(input_shape != None)\n            self.input_shape = input_shape\n            self.nodes_per_class = nodes_per_class\n            self.hidden_nodes = nodes_per_class * num_classes\n            self.weights = np.ones((self.hidden_nodes, self.input_shape), dtype=np.int64)\n\n    def predict(self, X, batch_size=64):\n        '''\n        Arguments\n        ---------\n        - X: Numpy array\n            Should be in shape of (num_samples, input_shape)\n\n        - batch_size: int, default 128\n            The number of samples used for each batch of computation to predict\n        \n        Returns\n        -------\n        - result: Numpy array\n            prediction result in shape of (num_samples, 1)\n\n        '''\n        result = []\n        \n        for i in range(0, len(X), batch_size):\n            x = X[i:i+batch_size]     # shape [batch_size, input_shape]\n            x = x.dot(self.weights.T)   # shape [batch_size, hidden_nodes]\n\n            class_sum = []\n            for j in range(0, self.hidden_nodes, self.nodes_per_class):\n                sum_class = x[:, j:j+self.nodes_per_class]\n                sum_class = sum_class.sum(axis=1)\n                class_sum.append(sum_class)\n\n            class_sum = np.vstack(class_sum).T\n            class_sum = class_sum.argmax(axis=1)\n            result.append(class_sum)\n\n        result = np.hstack(result).reshape(-1, 1)\n        return result","7f89289e":"def fitness_train(chromosome):\n    bnn = BinaryNN(num_classes=NUM_CLASSES, init_weights=chromosome.values)\n    y_pred = bnn.predict(X_train, batch_size=BATCH_SIZE)\n    return accuracy_score(y_train, y_pred)\n\ndef fitness_eval(chromosome):\n    bnn = BinaryNN(num_classes=NUM_CLASSES, init_weights=chromosome.values)\n    y_pred = bnn.predict(X_test, batch_size=BATCH_SIZE)\n    return accuracy_score(y_test, y_pred)\n\nclass Chromosome:\n    '''\n    Abstract base class for chromosome object for genetic algorithm\n    '''\n    def crossover(self):\n        pass\n    \n    def mutate(self):\n        pass\n\nclass BinaryMatrixChromosome(Chromosome):\n    '''\n    Class for binary matrix as chromosomes.\n    \n    Arguments\n    ---------\n    - n_rows, n_cols: int\n        Number of rows and columns used for the matrix\n    \n    - random_state: None or int, default None\n        random seed\n    '''\n    def __init__(self, n_rows, n_cols,\n                 random_state=None):\n        super().__init__()\n        self.n_rows = n_rows\n        self.n_cols = n_cols\n        self.random_state = random_state\n\n        np.random.seed(self.random_state)\n        self.values = np.random.randint(0, 2, size=(n_rows, n_cols))\n        self.values = 2 * self.values - 1","a8d5a88d":"class Initializer:\n    '''\n    Abstract base class for population initializer.\n    '''\n    def __call__(self):\n        pass\n    \nclass BinaryMatrixInitializer:\n    '''\n    Class for binary matrix initializer.\n    \n    Arguments\n    ---------\n    - n_rows, n_cols: int\n        Number of rows and columns used for the matrix\n    \n    - random_state: None or int, default None\n        random seed\n    '''\n    \n    def __init__(self, n_rows, n_cols, random_state=None):\n        self.n_rows = n_rows\n        self.n_cols = n_cols\n        self.random_state = random_state\n        np.random.seed(self.random_state)\n        \n    def __call__(self, n_init=100):\n        if self.random_state == None:\n            population = [\n                BinaryMatrixChromosome(\n                    n_rows=self.n_rows,\n                    n_cols=self.n_cols,\n                    random_state=random_state\n                ) for _ in range(n_init)\n            ]\n        else:\n            random_states = np.arange(n_init)\n            np.random.shuffle(random_states)\n            population = [\n                BinaryMatrixChromosome(\n                    n_rows=self.n_rows,\n                    n_cols=self.n_cols,\n                    random_state=random_state\n                ) for random_state in random_states\n            ]\n            \n        return population","bd5fc50c":"class MutationMethod:\n    '''\n    Abstract base class for mutation method.\n    '''\n    def __call__(self):\n        pass\n\nclass BinaryMatrixBitFlip(MutationMethod):\n    '''\n    Class for bit-flip mutation method in binary matrix chromosome.\n    \n    Arguments\n    ---------\n    \n    - negative: int, either 0 or -1\n        negative value\n    '''\n    def __init__(self, negative=-1, random_state=None):\n        super().__init__()\n        \n        assert(negative in [0, -1])\n        if negative == 0:\n            self.flip = self.flip0\n        else:\n            self.flip = self.flip1\n            \n        self.random_state = random_state\n        np.random.seed(self.random_state)\n    \n    def flip0(self, x):\n        return 1 - x\n    \n    def flip1(self, x):\n        return x * -1\n    \n    def __call__(self, chromosome):\n        i = np.random.randint(chromosome.n_rows)\n        j = np.random.randint(chromosome.n_cols)\n        \n        x = chromosome.values[i, j]\n        x = self.flip(x)\n        chromosome.values[i, j] = x\n        \n        return chromosome","a7e8026f":"class CrossoverMethod:\n    '''\n    Abstract base class for crossover method.\n    '''\n    def __call__(self):\n        pass\n    \nclass BinaryMatrixKPoints(CrossoverMethod):\n    '''\n    Class for k points crossover method in binary matrix chromosome.\n    \n    Arguments\n    ---------\n    \n    - k: int\n        number of cut points\n    '''\n    def __init__(self, k=2, random_state=None):\n        self.k = k\n        self.random_state = random_state\n        \n        np.random.seed(self.random_state)\n        \n    def __call__(self, chr1, chr2):\n        assert(chr1.values.shape == chr2.values.shape)\n        v1 = chr1.values.ravel()\n        v2 = chr2.values.ravel()\n        n = len(v1)\n        \n        index = np.random.choice(np.arange(1, n), size=self.k, replace=False)\n        index.sort()\n        index = [0] + index.tolist() + [n]\n\n        for i in range(len(index) - 1):\n            t = v1[index[i]:index[i + 1]]\n            if i % 2 == 0:\n                continue\n            v1[index[i]:index[i + 1]] = v2[index[i]:index[i + 1]]\n            v2[index[i]:index[i + 1]] = t\n        \n        n_rows, n_cols = chr1.n_rows, chr2.n_cols\n        v1 = v1.reshape(n_rows, n_cols)\n        v2 = v2.reshape(n_rows, n_cols)\n        \n        offspring1 = BinaryMatrixChromosome(n_rows, n_cols, random_state=chr1.random_state)\n        offspring2 = BinaryMatrixChromosome(n_rows, n_cols, random_state=chr2.random_state)\n        offspring1.values = v1\n        offspring2.values = v2\n        \n        return (offspring1, offspring2)","8d351702":"class SelectionMethod:\n    def __call__(self):\n        pass\n    \nclass RouletteWheelSelection(SelectionMethod):\n    def __call__(self, model):\n        model.compute_fitness()\n        index = list(zip(*model.fitness))[0]\n        fitness = list(zip(*model.fitness))[1]\n        probability = np.array(fitness) \/ sum(fitness)\n        size = (int(model.pc * model.population_size) \/\/ 2) * 2\n        \n        parent_list = np.random.choice(index, size=(size,), replace=False, p=probability)\n        parent_list = np.array(parent_list).reshape(-1, 2)\n        return parent_list","0a69a2c6":"def load_model(filename):\n    with open(filename, 'rb') as file:\n        return pickle.load(file)\n\nclass GAModel:\n    '''\n    Abstract base class for GA model.\n    '''\n    def mutation(self):\n        pass\n\n    def crossover(self):\n        pass\n\n    def selection(self):\n        pass\n\n    def run(self):\n        pass\n    \n    def save(self, filename):\n        with open(filename, 'wb') as file:\n            pickle.dump(self, file)\n\nclass BaseModel(GAModel):\n    '''\n    Class for Base GA model\n\n    Arguments\n    ---------\n\n    - population_size: int, default 100\n        The maximum number of chromosome in the mating pool.\n\n    - pm: float in range [0., 1.), default 0.1\n        Mutation probability\n\n    - pc: float in range [0., 1.), default 0.8\n        Crossover probability\n\n    - initializer: Initializer instance\n        Population initializer method\n\n    - selection_method: SelectionMethod instance\n        Selection method\n        \n    - crossover_method: CrossoverMethod instance\n        Crossover method\n        \n    - mutation_method: MutationMethod instance\n        Mutation method\n\n    - random_state: None, or int\n        Random seed\n\n    - fitness_train\/eval: callable\n        Fitness function with parameter of chromosome. Should be better if greater.\n\n    Another arguments:\n        - n_rows, n_cols: int\n            the number of rows and columns for each chromosome matrix.\n    '''\n    def __init__(self, population_size=100, pm=0.1, pc=0.8,\n                 initializer=None,\n                 selection_method=None,\n                 crossover_method=None,\n                 mutation_method=None,\n                 fitness_train=None,\n                 fitness_eval=None, \n                 random_state=None,\n                 **kwargs):\n        \n        super().__init__(**kwargs)\n        \n        self.population_size = population_size\n        self.pm = pm\n        self.pc = pc\n        self.initializer = initializer\n        self.selection_method = selection_method\n        self.crossover_method = crossover_method\n        self.mutation_method = mutation_method\n        self.fitness_train = fitness_train\n        self.fitness_eval = fitness_eval\n        self.random_state = random_state\n        \n        np.random.seed(random_state)\n        self.population = self.initializer(self.population_size)\n\n    def compute_fitness(self):\n        self.fitness = []\n        for i, chromosome in enumerate(self.population):\n            fitness_value = self.fitness_train(chromosome)\n            self.fitness.append((i, fitness_value))\n            \n        self.fitness = sorted(self.fitness, key=lambda x: x[1], reverse=True)\n        self.best_index, self.best_fitness_train = self.fitness[0]\n        \n        if self.fitness_eval:\n            self.best_fitness_eval = self.fitness_eval(self.population[self.best_index])\n            \n    def selection(self):\n        '''\n        Method to perform selection for each chromosome.\n        '''\n        parent_list = self.selection_method(self)\n        return parent_list\n        \n    def crossover(self, parent_list):\n        '''\n        Method to perform crossover.\n        '''\n        for i, j in parent_list:\n            offspring1, offspring2 = self.crossover_method(\n                self.population[i], self.population[j]\n            )\n            self.population[i] = offspring1\n            self.population[j] = offspring2\n\n    def mutation(self):\n        '''\n        Method to perform mutation for each chromosome.\n        '''\n        size = int(self.pm * self.population_size)\n        index = np.random.choice(np.arange(self.population_size),\n                                 size=(size,), replace=False)\n        \n        for i in index:\n            self.population[i] = self.mutation_method(self.population[i])\n        \n    def run(self, num_iter=10, verbose=2, start=0, callbacks=None):\n        '''\n        Main method to perform genetic algorithm.\n\n        Arguments\n        ---------\n\n        - num_iter: int, default 10\n            Number of iterations.\n\n        - verbose: boolean, default True\n            Verbosity. Print report for each iteration if set True.\n            \n        Returns\n        -------\n        \n        - history: dict\n            Dictionary of best fitness value for each iteration.\n        '''\n        start_run = time()\n        \n        np.random.seed(self.random_state)\n        self.history = {\n            'generation': [],\n            'best_fitness': []\n        }\n        if self.fitness_eval:\n            self.history['best_fitness_eval'] = []\n\n        for i in range(start, start + num_iter):\n            start = time()\n            self.compute_fitness()\n            parent_list = self.selection()\n            self.crossover(parent_list)\n            self.mutation()\n            \n            self.compute_fitness()\n            self.history['generation'].append(i + 1)\n            self.history['best_fitness'].append(self.best_fitness_train)\n            \n            logs = {\n                'generation': i + 1,\n                'best_fitness': self.best_fitness_train\n            }\n            \n            if self.fitness_eval:\n                self.history['best_fitness_eval'].append(self.best_fitness_eval)\n                logs.update({\n                    'best_fitness_eval': self.best_fitness_eval\n                })\n            \n            if callbacks != None:\n                for callback in callbacks:\n                    callback.on_iter_end(self, logs)\n            \n            finish = time()\n            if verbose >= 2:\n                report = '[G %d]\\t%.2fs\\t' % (i + 1, finish-start)\n                report += 'Best fitness: %.4f' % self.best_fitness_train\n\n                if self.fitness_eval:\n                    report += '\\tBest fitness eval: %.4f' % self.best_fitness_eval\n\n                print(report)\n                \n        finish_run = time()\n        total_time = finish_run - start_run\n        if verbose >= 1:\n            report = 'Done searching in %.2fs (average %.2fs)' % (\n                total_time, \n                total_time \/ num_iter\n            )\n            print(report)\n            \n        return self.history","2a33597f":"class Callback:\n    pass\n\nclass Checkpointer(Callback):\n    def __init__(self, filename, monitor='best_fitness_eval', verbose=True):\n        self.filename = filename\n        self.monitor = monitor\n        self.verbose = verbose\n        self.best = -float('inf')\n        \n    def on_iter_end(self, model, logs):\n        cur_fitness = logs.get(self.monitor)\n        \n        if cur_fitness > self.best:\n            gen = logs.get('generation')\n            \n            if self.verbose:\n                report = f'\\nNew {self.monitor} found (model saved to {self.filename})\\n'\n                report += f'Generation {gen:03}, scored {cur_fitness:.4f} (from {self.best:.4f})\\n'\n                print(report)\n            \n            self.best = cur_fitness\n            model.save(self.filename)","ad53d5f1":"def create_submission(weights, filename):\n    with open(filename, 'w') as file:\n        file.write('weights = ')\n        file.write(str(weights.tolist()))\n        file.write('\\n\\n')\n        file.write('for weight in weights:')\n        file.write('\\n')\n        file.write(\"  print(' '.join(map(str, weight)))\")\n\ndef main():\n    n_rows = NUM_CLASSES * 15\n    n_cols = 51\n    random_state = 42\n    \n    initializer = BinaryMatrixInitializer(n_rows, n_cols, random_state=random_state)\n    selection_method = RouletteWheelSelection()\n    crossover_method = BinaryMatrixKPoints(k=2, random_state=random_state)\n    mutation_method = BinaryMatrixBitFlip(random_state=random_state)\n\n    model = BaseModel(\n        population_size=500,\n        pm=0.1,\n        pc=0.9,\n        initializer=initializer,\n        selection_method=selection_method,\n        crossover_method=crossover_method,\n        mutation_method=mutation_method,\n        fitness_train=fitness_train,\n        fitness_eval=fitness_eval,\n        random_state=random_state\n    )\n\n    ckpt = Checkpointer('model.pkl', monitor='best_fitness')\n    history = model.run(num_iter=500, verbose=1,\n                        callbacks=[ckpt])\n    \n    best_weights = model.population[model.best_index].values\n    filename = 'submission%dclass.py' % NUM_CLASSES\n    create_submission(best_weights, filename)\n    \n    return model\n\nmodel = main()","0b5600ab":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nplt.figure(figsize=(10, 5))\ngeneration = model.history['generation']\nplt.plot(generation, model.history['best_fitness'], label='train')\nplt.plot(generation, model.history['best_fitness_eval'], label='eval')\nplt.xticks(generation)\nplt.xlabel('generation')\nplt.ylabel('best fitness value')\nplt.legend()\nplt.show()","544d4d65":"!cat submission2class.py","56038288":"# Binary Neural Network","1135378f":"# Genetic Algorithm Modules","287ded70":"# Main Program","9c066711":"# MNIST Genetic Algorithm\n\nThis notebook is used to solve MNIST classification problem using Binary Neural Network. This problem was presented in International Collegiate Programming Contest (ICPC) World Final 2019 as a challenge problem.\n\nSubmission can be done in https:\/\/open.kattis.com\/problems\/mnist2class and https:\/\/open.kattis.com\/problems\/mnist10class depending on how many classes of digits we want to classify. This notebook outputs a submission file that could be submitted to the link above.\n\nThis notebook could be enhanced more by making this paralellized, since the main genetic algorithm used here mostly stand on traditional for loops."}}