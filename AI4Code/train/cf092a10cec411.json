{"cell_type":{"e93539ab":"code","1aa0d150":"code","04de6c85":"code","7ccb2c89":"code","4c8e69c4":"code","1783cb9b":"code","02faee5b":"code","1c1c28a1":"code","c3aacaf0":"code","307f9232":"code","30e263dc":"code","796ed851":"code","578bc75d":"code","aced6d18":"code","32f85233":"code","fe24353b":"code","e743d8bc":"code","5d5e6641":"code","ad476c94":"code","b32c5c68":"code","47c11822":"code","56b3000d":"code","55e31c9c":"code","a880b8cb":"code","54e6dd38":"code","302ab33f":"code","69fbe3ef":"code","cfa99113":"code","05c7af72":"code","ff992df3":"code","b419ab3f":"code","96973863":"code","3e213043":"code","570dd5d1":"code","0c4915f4":"code","bc211eba":"code","6cca2b37":"code","48d6511a":"code","6ec47bee":"code","03840218":"code","59b40338":"code","453f7dc5":"code","94479e27":"code","9f87d8c3":"code","ac076cc5":"code","880cacb9":"code","b11822d9":"code","78a96193":"code","0949de5d":"code","d176861a":"code","9613418a":"markdown","4efdd586":"markdown","9d1d91ca":"markdown","69692b14":"markdown","91497753":"markdown","b8111283":"markdown","f38f0c86":"markdown","73c8c34c":"markdown","95231369":"markdown","35b867f0":"markdown","c1192771":"markdown"},"source":{"e93539ab":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1aa0d150":"data_train = pd.read_csv(\"..\/input\/train.csv\")\ndata_test = pd.read_csv(\"..\/input\/test.csv\")","04de6c85":"data_train.info()","7ccb2c89":"data_train.describe()","4c8e69c4":"plt.scatter(data_train.GrLivArea, data_train.SalePrice)\nplt.show()","1783cb9b":"data_train = data_train.drop(data_train[(data_train[\"GrLivArea\"] > 4000) & (data_train[\"SalePrice\"]<300000)].index)\nplt.scatter(data_train.GrLivArea, data_train.SalePrice)\nplt.show()","02faee5b":"sns.scatterplot(\"LotArea\", \"SalePrice\", data=data_train)\nplt.show()","1c1c28a1":"data_train = data_train.drop(data_train[(data_train[\"LotArea\"] > 100000) & (data_train[\"SalePrice\"]<400000)].index)\nplt.scatter(data_train.GrLivArea, data_train.SalePrice)\nplt.show()","c3aacaf0":"ntrain = data_train.shape[0]\nntest = data_test.shape[0]\ntrain_label = data_train[\"SalePrice\"]\ndata_train = data_train.drop([\"SalePrice\"], axis=1)\nall_data = pd.concat((data_train, data_test)).reset_index(drop=True)","307f9232":"total = all_data.isnull().sum().sort_values(ascending=False)\npercent = (all_data.isnull().sum()\/all_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(35)","30e263dc":"for col in (\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\"):\n    all_data[\"has_\" + col] = all_data[col].apply(lambda x: 0 if pd.isnull(x) else 1)\n    all_data[col] =  all_data[col].fillna(\"None\")","796ed851":"all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.mean()))","578bc75d":"all_data[\"has_garage\"] = all_data[\"GarageCond\"].apply(lambda x: 0 if pd.isnull(x) else 1)\nfor col in (\"GarageType\", \"GarageFinish\", \"GarageQual\",\"GarageCond\"):\n    all_data[col] = all_data[col].fillna('None')\nfor col in (\"GarageYrBlt\", \"GarageCars\",\"GarageArea\"):\n    all_data[col] = all_data[col].fillna(0)","aced6d18":"for col in (\"BsmtCond\", \"BsmtExposure\", \"BsmtQual\", \"BsmtFinType2\", \"BsmtFinType1\"):\n    all_data[col] = all_data[col].fillna('None')\nfor col in (\"BsmtHalfBath\", \"BsmtFullBath\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"BsmtFinSF1\",\"TotalBsmtSF\"):\n    all_data[col] = all_data[col].fillna(0)","32f85233":"all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)","fe24353b":"for col in (\"MSZoning\",\"Functional\", \"Electrical\",\"KitchenQual\", \"Exterior1st\",\"Exterior2nd\",\"SaleType\"):\n    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])","e743d8bc":"all_data.Utilities.value_counts()","5d5e6641":"all_data = all_data.drop([\"Utilities\"], axis=1)","ad476c94":"all_data[\"Age_of_house\"] = all_data.YrSold - all_data.YearBuilt ","b32c5c68":"all_data.columns[all_data.dtypes == \"object\"]","47c11822":"from sklearn.preprocessing import LabelEncoder\nfor col in all_data.columns[all_data.dtypes == \"object\"]:\n    all_data[col] = all_data[col].factorize()[0]\nall_data = all_data.drop([\"Id\"], axis=1)","56b3000d":"data_train = all_data.iloc[:ntrain]\ndata_test = all_data.iloc[ntrain:]","55e31c9c":"from sklearn.model_selection import train_test_split\ntrain_x, val_x, train_y, val_y = train_test_split(data_train, train_label, test_size=0.3, random_state=42)","a880b8cb":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\ndef model_tuning(n_jobs=4,colsample_bylevel = 1, colsample_bytree=1, gamma=0.0, \n                         learning_rate=0.1, max_depth= 3, min_child_weight=1, n_estimators=300, reg_alpha=0, reg_lambda=1,subsample=1):\n    model = XGBRegressor(n_jobs=n_jobs, objective='reg:linear', seed=42,silent=True,colsample_bylevel = colsample_bylevel, colsample_bytree=colsample_bytree,\n                         gamma=gamma,learning_rate=learning_rate, max_depth= max_depth,\n                         min_child_weight=min_child_weight, n_estimators=n_estimators, reg_alpha=reg_alpha, reg_lambda=reg_lambda,subsample=subsample)\n    model_cv = cross_val_score(model, train_x, train_y, cv=5, scoring=\"neg_mean_squared_log_error\")\n    return np.sqrt(-1*model_cv.mean())","54e6dd38":"accuracies = []\nparams = np.arange(1,8)\nfor i in params:\n    accuracies.append(model_tuning(max_depth=i)) #0.2, 0.3 is looks like good\nplt.plot(params,accuracies)\nplt.show()","302ab33f":"accuracies = []\nparams = np.arange(1,11)\/10\nfor i in params:\n    accuracies.append(model_tuning(max_depth=3, subsample=i))\nplt.plot(params,accuracies)\nplt.show()","69fbe3ef":"accuracies = []\nparams = np.arange(1,11)\/10\nfor i in params:\n    accuracies.append(model_tuning(max_depth=3, subsample=0.8, colsample_bytree=i))\nplt.plot(params,accuracies)\nplt.show()","cfa99113":"accuracies = []\nparams = np.arange(1,11)\/10\nfor i in params:\n    accuracies.append(model_tuning(max_depth=3, subsample=0.8, colsample_bytree=0.2, colsample_bylevel=i))\nplt.plot(params,accuracies)\nplt.show()","05c7af72":"accuracies = []\nparams = np.arange(650,1000,200)\nfor i in params:\n    accuracies.append(model_tuning(max_depth=3, subsample=0.8, colsample_bytree=0.2, colsample_bylevel=1.0, n_estimators=i))\nplt.plot(params,accuracies)\nplt.show()","ff992df3":"accuracies = []\nparams = [0.01, 0.03, 0.05, 0.07, 0.1]\nfor i in params:\n    accuracies.append(model_tuning(max_depth=3, subsample=0.8, colsample_bytree=0.2, colsample_bylevel=1.0, n_estimators=650,learning_rate=i))\nplt.plot(params,accuracies)\nplt.show()","b419ab3f":"model = XGBRegressor(max_depth=3, subsample=0.8, colsample_bytree=0.2, colsample_bylevel=1.0, n_jobs=4, n_estimators=600, learning_rate=0.03, seed=42)\nmodel.fit(train_x, train_y)","96973863":"from sklearn.metrics import mean_squared_log_error\nprint(\"val acc\", np.sqrt(mean_squared_log_error(model.predict(val_x), val_y)))\nprint(\"train acc\", np.sqrt(mean_squared_log_error(model.predict(train_x), train_y)))","3e213043":"def model_tuner(max_depth=4, subsample=0.68, \n                colsample_bytree=0.2, colsample_bylevel=1.0,\n                n_estimators=600, learning_rate=0.03,\n                min_child_weight=4.5, reg_lambda=5.9):\n    \n    model = XGBRegressor(max_depth=max_depth, subsample=subsample, \n                         colsample_bytree=colsample_bytree, colsample_bylevel=colsample_bylevel,\n                         n_jobs=4, n_estimators=n_estimators, learning_rate=learning_rate, seed=42,\n                         min_child_weight=min_child_weight, reg_lambda=reg_lambda)\n    model.fit(train_x, train_y)\n    train_accuracy = np.sqrt(mean_squared_log_error(model.predict(train_x), train_y))\n    test_accuracy = np.sqrt(mean_squared_log_error(model.predict(val_x), val_y))\n    return train_accuracy, test_accuracy","570dd5d1":"# train_accuracies = []\n# test_accuracies = []\n# params = np.arange(15,75)\/10\n# for i in params:\n#     train_acc, test_acc = model_tuner(min_child_weight=i)\n#     train_accuracies.append(train_acc)\n#     test_accuracies.append(test_acc)\n# sns.lineplot(params,train_accuracies,color=\"r\" )\n# sns.lineplot(params,test_accuracies,color=\"b\" )\n# plt.show()","0c4915f4":"# df = pd.DataFrame({\"param\": params, \"test_acc\":test_accuracies, \"train_acc\":train_accuracies})\n# df.sort_values(by=\"test_acc\").head(10)","bc211eba":"# train_accuracies = []\n# test_accuracies = []\n# params = np.arange(1,100)\/10\n# for i in params:\n#     train_acc, test_acc = model_tuner(reg_lambda=i)\n#     train_accuracies.append(train_acc)\n#     test_accuracies.append(test_acc)\n# sns.lineplot(params,train_accuracies,color=\"r\" )\n# sns.lineplot(params,test_accuracies,color=\"b\" )\n# plt.show()","6cca2b37":"# df = pd.DataFrame({\"param\": params, \"test_acc\":test_accuracies, \"train_acc\":train_accuracies})\n# df.sort_values(by=\"test_acc\").head(10)","48d6511a":"# train_accuracies = []\n# test_accuracies = []\n# params = np.arange(1,15)\n# for i in params:\n#     train_acc, test_acc = model_tuner(max_depth=i)\n#     train_accuracies.append(train_acc)\n#     test_accuracies.append(test_acc)\n# sns.lineplot(params,train_accuracies,color=\"r\" )\n# sns.lineplot(params,test_accuracies,color=\"b\" )\n# plt.show()","6ec47bee":"# df = pd.DataFrame({\"param\": params, \"test_acc\":test_accuracies, \"train_acc\":train_accuracies})\n# df.sort_values(by=\"test_acc\").head(10)","03840218":"# train_accuracies = []\n# test_accuracies = []\n# params = np.arange(1,100)\/100\n# for i in params:\n#     train_acc, test_acc = model_tuner(subsample=i)\n#     train_accuracies.append(train_acc)\n#     test_accuracies.append(test_acc)\n# sns.lineplot(params,train_accuracies,color=\"r\" )\n# sns.lineplot(params,test_accuracies,color=\"b\" )\n# plt.show()","59b40338":"# df = pd.DataFrame({\"param\": params, \"test_acc\":test_accuracies, \"train_acc\":train_accuracies})\n# df.sort_values(by=\"test_acc\").head(10)","453f7dc5":"# train_accuracies = []\n# test_accuracies = []\n# params = np.arange(1,100)\/100\n# for i in params:\n#     train_acc, test_acc = model_tuner(colsample_bytree=i)\n#     train_accuracies.append(train_acc)\n#     test_accuracies.append(test_acc)\n# sns.lineplot(params,train_accuracies,color=\"r\" )\n# sns.lineplot(params,test_accuracies,color=\"b\" )\n# plt.show()","94479e27":"# df = pd.DataFrame({\"param\": params, \"test_acc\":test_accuracies, \"train_acc\":train_accuracies})\n# df.sort_values(by=\"test_acc\").head(10)","9f87d8c3":"# train_accuracies = []\n# test_accuracies = []\n# params = np.arange(1,101)\/100\n# for i in params:\n#     train_acc, test_acc = model_tuner(colsample_bylevel=i)\n#     train_accuracies.append(train_acc)\n#     test_accuracies.append(test_acc)\n# sns.lineplot(params,train_accuracies,color=\"r\" )\n# sns.lineplot(params,test_accuracies,color=\"b\" )\n# plt.show()","ac076cc5":"# df = pd.DataFrame({\"param\": params, \"test_acc\":test_accuracies, \"train_acc\":train_accuracies})\n# df.sort_values(by=\"test_acc\").head(10)","880cacb9":"model = XGBRegressor(max_depth=4, subsample=0.68, colsample_bytree=0.2,\n                     colsample_bylevel=1.0, n_estimators=5000, \n                     learning_rate=0.01, min_child_weight=4.5, \n                     reg_lambda=5.9, n_jobs=4, seed=42)\nhistory = model.fit(train_x, train_y,\n             eval_set=[(val_x, val_y)], verbose=False)","b11822d9":"plt.plot(np.arange(1000,5000),history.evals_result_[\"validation_0\"][\"rmse\"][1000:])\nplt.show()","78a96193":"model = XGBRegressor(max_depth=4, subsample=0.68, colsample_bytree=0.2,\n                     colsample_bylevel=1.0, n_estimators=3000, \n                     learning_rate=0.01, min_child_weight=4.5, \n                     reg_lambda=5.9, n_jobs=4, seed=42)\naccuracy = cross_val_score(model, data_train, train_label, cv=5, scoring=\"neg_mean_squared_log_error\")\nprint(\"Accuracy\", np.sqrt(-accuracy.mean()))","0949de5d":"model.fit(data_train, train_label)","d176861a":"y_pred = model.predict(data_test)\nsubmission = pd.read_csv(\"..\/input\/sample_submission.csv\")\nsubmission[\"SalePrice\"] = y_pred\nsubmission.to_csv('submission.csv', index=False)","9613418a":"# 1. Data preparation\n[https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard](http:\/\/https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard)\n## 1.1 Load data","4efdd586":"This is very interesting because there is huge LotArea with low prices, personaly if i want to buy a house I'd stay away from those kind a things. They looks too suspicius to me.","9d1d91ca":"## 2.2. Parameter tuning","69692b14":"## 1.3 \u0130mpute null and missing values","91497753":"## 1.5 Split training and valdiation set","b8111283":"## 1.4 Label Encoding","f38f0c86":"* **1. Data preparation**\n    * 1.1 Load data\n    * 1.2 Outliers\n    * 1.3 \u0130mpute null and missing values\n    * 1.4 Label Encoding\n    * 1.5 Split training and valdiation set\n* **2. XGBoost**\n    * 2.1 Define the model\n    * 2.2 Parameter Tuning\n* **3. Prediction and submition**","73c8c34c":"## 1.2 Outliers","95231369":"# 2. XGBoost\n## 2.1 Define model","35b867f0":"it's look like overfitting here so i will try lambda, alpha and min child weight values","c1192771":"# 3. Prediction and submition"}}