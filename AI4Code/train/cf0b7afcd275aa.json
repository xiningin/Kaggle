{"cell_type":{"54dedc8f":"code","c10801d7":"code","df97fd2a":"code","cfe56949":"code","26037f26":"code","845ba093":"code","5962e900":"code","d5cdb387":"code","266eb8f9":"code","a487a760":"code","75e4295c":"code","8a7af46a":"code","e836b643":"code","a2a1c6c5":"markdown","3e8fa15c":"markdown","9936cd86":"markdown","83e6e1d9":"markdown","4ea9d557":"markdown","72fb1f90":"markdown","6f870ea1":"markdown","fb73c854":"markdown","2bb8b209":"markdown","9c6e6a45":"markdown"},"source":{"54dedc8f":"import os\nimport platform\n\nprint(f\"Python version: {platform.python_version()}\")\nassert platform.python_version_tuple() >= (\"3\", \"6\")\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np","c10801d7":"# Setup plots\n%matplotlib inline\nplt.rcParams['figure.figsize'] = 10, 8\n%config InlineBackend.figure_format = 'retina'","df97fd2a":"import torch\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(\"GPU found :)\" if torch.cuda.is_available() else \"No GPU :(\")\n\nimport torchvision\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","cfe56949":"# Hyper-parameters\nbatch_size = 100\n\n# values proposed by the paper\nlearning_rate = 2e-4\nbeta1 = 0.5\nlatent_size = 100\nimage_size = 64\nhidden_size = 64\nchannels = 3","26037f26":"sample_dir = \"samples\"\n\n# Create a directory if not exists\nif not os.path.exists(sample_dir):\n    os.makedirs(sample_dir)\n\n# Image processing\ntransform = transforms.Compose(\n    [\n        transforms.Resize(image_size),\n        transforms.CenterCrop(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=0.5, std=0.5),  # only one channel\n    ]\n)\n\n# roadsign dataset\n# is channels first\nds = torchvision.datasets.ImageFolder(\n    root=\"..\/input\/traffic-sign-cropped\/crop_dataset\/crop_dataset\", transform=transform\n)","845ba093":"dataloader = torch.utils.data.DataLoader(ds, batch_size=batch_size,shuffle=True, num_workers=2, drop_last=True)\n# first is a batch of size 100, iterating dataloader is made batch per batch\nfirst = next(iter(dataloader))","5962e900":"# display some data\n# of course, as it comes from centered\/reduced values, hard to see through the images\n# numpy conversion is not the best\nplt.figure(figsize=(16,16))\nplt.title(\"Input images\")\nfor i in range(25):\n    ax = plt.subplot(5,5, i+1)\n    plt.imshow(np.transpose(first[0][i], (1,2,0)))\n    plt.axis(\"off\")\nplt.show()","d5cdb387":"# Generator\n# input size is latent_size, output size is hidden size\n# we follow the values as provided in page 4 of the original paper\nG = nn.Sequential(\n        # kernel of size 4, stride 1, padding 0\n        # 512 * 4 * 4\n        nn.ConvTranspose2d(latent_size, hidden_size * 8, 4, 1, 0, bias=False),\n        nn.BatchNorm2d(hidden_size * 8),\n        nn.ReLU(True),\n        # 256 * 8 * 8\n        nn.ConvTranspose2d(hidden_size * 8, hidden_size * 4, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(hidden_size * 4),\n        nn.ReLU(True),\n        # 128 * 16 * 16\n        nn.ConvTranspose2d(hidden_size * 4, hidden_size * 2, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(hidden_size * 2),\n        nn.ReLU(True),\n        # 64 * 32 * 32\n        nn.ConvTranspose2d(hidden_size * 2, hidden_size, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(hidden_size),\n        nn.ReLU(True),\n        # 3 * 64 * 64\n        nn.ConvTranspose2d(hidden_size, channels, 4, 2, 1, bias=False),\n        nn.Tanh()\n        )\n\n# Discriminator\n# input is 3 x 64 x 64   \nD = nn.Sequential(\n    # 64 * 32 * 32\n    nn.Conv2d(channels, hidden_size, 4, 2, 1, bias=False),\n    nn.LeakyReLU(0.2, inplace=True),\n    # 128 * 16 * 16\n    nn.Conv2d(hidden_size, hidden_size * 2, 4, 2, 1, bias=False),    \n    nn.BatchNorm2d(hidden_size * 2),\n    nn.LeakyReLU(0.2, inplace=True),\n    # 256 * 8 * 8\n    nn.Conv2d(hidden_size * 2, hidden_size * 4, 4, 2, 1, bias=False),\n    nn.BatchNorm2d(hidden_size * 4),\n    nn.LeakyReLU(0.2, inplace=True),\n    # 512 * 4 * 4\n    nn.Conv2d(hidden_size * 4, hidden_size * 8, 3, 2, 1, bias=False),\n    nn.BatchNorm2d(hidden_size * 8),\n    nn.LeakyReLU(0.2, inplace=True),\n    # 1\n    nn.Conv2d(hidden_size * 8, 1, 4, 2, 0, bias=False),\n    nn.Sigmoid()\n)\n\n# Device setting\nG = G.to(device)\nD = D.to(device)","266eb8f9":"# Binary cross entropy loss and optimizer\ncriterion = nn.BCELoss()\n# YOUR CODE HERE\nd_optimizer = Adam(D.parameters(), lr=learning_rate, betas=(beta1, 0.999))\ng_optimizer = Adam(G.parameters(), lr=learning_rate, betas=(beta1, 0.999))","a487a760":"def denorm(x):\n    \"\"\"Denormalize an image tensor\"\"\"\n    out = (x + 1) \/ 2\n    return out.clamp(0, 1)\n\n\ndef reset_grad():\n    \"\"\"Reset gradients for both optimizers\"\"\"\n    d_optimizer.zero_grad()\n    g_optimizer.zero_grad()","75e4295c":"num_epochs = 101 # Increase for a better output quality\nstep_count = len(dataloader)\n\nevaluated_images = torch.randn(batch_size, latent_size, 1, 1, device=device)\n\n# Start training\nfor epoch in range(num_epochs):\n    for i, images in enumerate(dataloader, 0):\n        images = images[0].to(device)\n\n        # Create the labels which are later used as input for the BCE loss\n        real_labels = torch.ones(batch_size).to(device)\n        fake_labels = torch.zeros(batch_size).to(device)\n\n        # ================================================================== #\n        #                      Train the discriminator                       #\n        # ================================================================== #\n        # zero grad called in order to avoid explosing or vanishing gradients\n        D.zero_grad()\n        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n        # Second term of the loss is always zero since y == real_labels == 1\n        real_outputs = D(images).view(-1)\n        d_loss_real = criterion(real_outputs, real_labels)\n        d_loss_real.backward()\n        real_score = real_outputs\n\n        # Compute BCELoss using fake images\n        # First term of the loss is always zero since y == fake_labels == 0\n        z = torch.randn(batch_size, latent_size, 1, 1).to(device)\n        fake_images = G(z)\n        # detach so that no gradient is computed\n        fake_outputs = D(fake_images.detach()).view(-1)\n        d_loss_fake = criterion(fake_outputs, fake_labels)\n        fake_score = fake_outputs\n\n        # Backprop and optimize\n        d_loss_fake.backward()\n        d_loss = d_loss_real + d_loss_fake\n        d_optimizer.step()\n\n        # ================================================================== #\n        #                        Train the generator                         #\n        # ================================================================== #\n        # zero grad called in order to avoid explosing or vanishing gradients\n        G.zero_grad()\n        # Compute loss with fake images\n        z = torch.randn(batch_size, latent_size, 1, 1).to(device)\n        fake_images = G(z)\n        outputs = D(fake_images).view(-1)\n\n        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n        # For the reason, see the last paragraph of section 3. https:\/\/arxiv.org\/pdf\/1406.2661.pdf\n        g_loss = criterion(outputs, real_labels)\n\n        # Backprop and optimize\n        g_loss.backward()\n        g_optimizer.step()\n\n        if (i + 1) % 200 == 0:\n            print(\n                f\"Epoch [{epoch + 1}\/{num_epochs}]\"\n                f\", Step [{i + 1}\/{step_count}]\"\n                f\", d_loss: {d_loss.item():.4f}\"\n                f\", g_loss: {g_loss.item():.4f}\"\n                f\", D(x): {real_score.mean().item():.2f}\"\n                f\", D(G(z)): {fake_score.mean().item():.2f}\"\n            )\n\n    # Save real images\n    if (epoch + 1) == 1:\n        #images = images.reshape(images.size(0), 1, 28, 28)\n        save_image(denorm(images), os.path.join(sample_dir, \"real_images.png\"))\n\n    # Save sampled images\n    if (epoch + 1) % 10 == 0:\n        #fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n        save_image(\n            denorm(fake_images),\n            os.path.join(sample_dir, f\"fake_images-{epoch + 1}.png\"),\n        )","8a7af46a":"def plot_image(image):\n    # Convert PyTorch tensor to NumPy\n    img_tensor = image.cpu().numpy() if torch.cuda.is_available() else image.numpy()\n    plt.imshow(img_tensor.squeeze(), cmap=\"binary\")\n    plt.axis(\"off\")\n\ndef show_images(images, n_images=batch_size):\n    fig = plt.figure(figsize=(6, 10))\n    for image_index in range(n_images):\n        plt.subplot(13, 8, 1 + image_index)\n        plot_image(images[image_index])","e836b643":"#Random images\nz = torch.randn(batch_size, latent_size, 1, 1, device=device)\nfake_images = denorm(G(z))\n\nfig = plt.figure(figsize=(10, 10))\nwith torch.no_grad():\n    for i in range(batch_size):\n        plt.subplot(10, 10, i+1)\n        img = fake_images[i]\n        img_tensor = img.cpu().numpy() if torch.cuda.is_available() else img.numpy()\n        img_tensor = img_tensor.transpose(1, 2, 0)\n        plt.imshow(img_tensor.squeeze())\n        plt.axis(\"off\")\n","a2a1c6c5":"## Model training\n\n### Question\n\nComplete the following training loop to:\n\n- compute fake images and output during discriminator training; \n- implement gradient descent.","3e8fa15c":"### Question\n\nUse the trained generator to create fake images from Gaussian noise.","9936cd86":"## Model definition\n\n### Question\n\nComplete the following code to create a GAN:\n\n- generator must be a dense network with two hidden layers using ReLU as activation functions, and an output layer using tanh;\n- discriminator must be a dense network with two hidden layers using leaky ReLU (with $\\alpha=0.2$) as activation functions, and an output layer using sigmoid.","83e6e1d9":"## Data loading","4ea9d557":"## Environment setup","72fb1f90":"# Generate handwritten digits with a GAN (PyTorch)\n\nThe goal here is to train a GAN to generate roadsigns.\n## Author: MARGUERITTE Ga\u00ebtan.","6f870ea1":"## Generate digits","fb73c854":"This solution is generated using a basis given by Baptiste PESQUET, as a material used for a course provided at ENSEIRB-MATMECA engineering school.\n\nHyperparameters, generator and discriminant models were chosen using the following paper: UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS\nhttps:\/\/arxiv.org\/pdf\/1511.06434.pdf\n\nKaggle dataset that has been used in order to test the model is publicly available here: https:\/\/www.kaggle.com\/shanmukh05\/traffic-sign-cropped","2bb8b209":"### Question\n\nCreate batch data loader `data_loader` for training dataset.","9c6e6a45":"## Loss, optimizer and utilities\n\n### Question\n\nDefine optimizers `d_optimizer` and `g_optimizer`, both using Adam with  a learning rate of 0.0002."}}