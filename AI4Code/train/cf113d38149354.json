{"cell_type":{"d78d11c7":"code","8b5fecbb":"code","f1491253":"code","7e6fee17":"code","5d7a3326":"code","b9751e63":"code","d0f5d5a8":"code","d6cf075b":"code","53d1b423":"code","d210f9e8":"code","898ead14":"code","70c57653":"code","b021e826":"code","e1ffbfc4":"code","177e2b58":"code","96f49f7d":"code","4381fc40":"code","f062d3b7":"code","2d3a33ac":"code","15310abb":"code","8bc68af2":"code","856cad0f":"code","191873b0":"code","846b2f82":"code","93668614":"code","67244546":"code","1ffe501f":"code","511ff4cf":"code","2ac5c8c9":"code","7d044a22":"code","2bd0f259":"code","da205d38":"code","2ee52dd2":"code","0662daff":"code","cc12c6fb":"code","eb33bd1a":"code","5c5955ed":"code","6ff62eee":"code","1fe08c70":"code","55f9377a":"code","cfa70853":"code","cec13850":"code","8172b03e":"code","3d3da4e6":"code","32b15967":"code","f4788d3a":"code","ef7e2d25":"code","893cdeca":"code","46435174":"code","eeaf45b7":"markdown","231d878c":"markdown","0fe45415":"markdown","0c1c257e":"markdown","8396dd33":"markdown","c96a2f4f":"markdown","96dcdadf":"markdown"},"source":{"d78d11c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8b5fecbb":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nsns.set_style(\"whitegrid\")","f1491253":"data = pd.read_json(\"..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\ndata.shape","7e6fee17":"data = data.drop([\"article_link\"], axis=1)\ndata.head()","5d7a3326":"data.isnull().sum()","b9751e63":"sns.countplot(data[\"is_sarcastic\"])","d0f5d5a8":"import nltk, re, string\nfrom nltk import pos_tag\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\nfrom wordcloud import WordCloud, STOPWORDS","d6cf075b":"def text_cleaning(data):\n    data = data.apply(lambda x: x.strip().lower())\n    data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n    \n    data = data.apply(lambda x : word_tokenize(x))\n    data = data.apply(lambda x: [word for word in x if word not in stop_words])\n    \n    \n    lemmatizer = WordNetLemmatizer()\n    data = data.apply(lambda x: [lemmatizer.lemmatize(word, pos ='v') for word in x])\n\n    return data","53d1b423":"data[\"headline\"] = text_cleaning(data[\"headline\"])\ndata = data[data[\"headline\"].apply(lambda x: len(x)>0)]","d210f9e8":"wordcloud = WordCloud(stopwords=STOPWORDS,\n                      max_words=2000\n                         ).generate(\" \".join(list(map(lambda x: \" \".join(x), data[data.is_sarcastic==1][\"headline\"]))))\n\nplt.figure(figsize=(12,12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","898ead14":"wordcloud = WordCloud(stopwords=STOPWORDS,\n                      max_words=2000\n                         ).generate(\" \".join(list(map(lambda x: \" \".join(x), data[data.is_sarcastic==0][\"headline\"]))))\n\nplt.figure(figsize=(12,12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","70c57653":"data[\"words\"] = data[\"headline\"].apply(lambda x: len(x))\ndata[\"characters\"] = data[\"headline\"].apply(lambda x: len(\"\".join(x)))","b021e826":"plt.figure(figsize=(15,8))\n\nplt.subplot(1,2,1)\nplt.xlim(0, 20)\nsns.distplot(data[data.is_sarcastic==1][\"words\"], kde=False)\nplt.title(\"Words distribution in Sarcastic headlines\")\nplt.grid(False)\n\nplt.subplot(1,2,2)\nplt.xlim(0, 15)\nsns.distplot(data[data.is_sarcastic==0][\"words\"], kde=False)\nplt.title(\"Words distribution in Non Sarcastic headlines\")\n\nplt.grid(False)\nplt.show()","e1ffbfc4":"plt.figure(figsize=(15,8))\n\nplt.subplot(1,2,1)\nplt.xlim(0, 100)\nsns.distplot(data[data.is_sarcastic==1][\"characters\"], kde=False)\nplt.title(\"Character distribution in Sarcastic headlines\")\nplt.grid(False)\n\nplt.subplot(1,2,2)\nplt.xlim(0, 100)\nsns.distplot(data[data.is_sarcastic==0][\"characters\"], kde=False)\nplt.title(\"Character distribution in Non Sarcastic headlines\")\n\nplt.grid(False)\nplt.show()","177e2b58":"vectorizer = TfidfVectorizer()\nvector = vectorizer.fit_transform(list(map(lambda x: \" \".join(x), data[\"headline\"])))\nvector = vector.todense()\nprint(vector.shape)","96f49f7d":"xtrain, xtest, ytrain, ytest = train_test_split(vector, data[\"is_sarcastic\"], train_size=0.75)","4381fc40":"xtrain.shape, xtest.shape","f062d3b7":"model = LinearSVC(loss=\"hinge\",fit_intercept=False, max_iter=1500)\nmodel = model.fit(xtrain, ytrain) \npredictions = model.predict(xtest)\n\nsvc_train_acc = accuracy_score(ytrain, model.predict(xtrain))\nsvc_test_acc = accuracy_score(ytest, predictions)\nsvc_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {} \\n b) Test : {}\".format(svc_train_acc, svc_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", svc_f1_score)\n\nconfusion_matrix(ytest, predictions)","2d3a33ac":"model_lr = LogisticRegression(penalty='l2')\nmodel_lr = model_lr.fit(xtrain, ytrain) \npredictions = model_lr.predict(xtest)\n\nlr_train_acc = accuracy_score(ytrain, model_lr.predict(xtrain))\nlr_test_acc = accuracy_score(ytest, predictions)\nlr_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {} \\n b) Test : {} \".format(lr_train_acc, lr_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", lr_f1_score)\n\nconfusion_matrix(ytest, predictions)","15310abb":"from sklearn.ensemble import RandomForestClassifier\n\nmodel_rf = RandomForestClassifier(n_estimators = 200)\nmodel_rf = model_rf.fit(xtrain, ytrain) \npredictions = model_rf.predict(xtest)\n\nrf_train_acc = accuracy_score(ytrain, model_rf.predict(xtrain))\nrf_test_acc = accuracy_score(ytest, predictions)\nrf_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {} \\n b) Test : {}\".format(rf_train_acc, rf_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", rf_f1_score)\n\nconfusion_matrix(ytest, predictions)","8bc68af2":"tree = DecisionTreeClassifier(random_state = 11, max_features = \"auto\", class_weight = \"balanced\",max_depth = None)\n\nmodel_ada = AdaBoostClassifier(base_estimator=tree)\nmodel_ada = model_ada.fit(xtrain, ytrain)\npredictions = model_ada.predict(xtest)\n\nada_train_acc = accuracy_score(ytrain, model_ada.predict(xtrain))\nada_test_acc = accuracy_score(ytest, predictions)\nada_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {}\\n b) Test : {}\".format(ada_train_acc, ada_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \",  ada_f1_score)\n\nconfusion_matrix(ytest, predictions)","856cad0f":"model = ExtraTreesClassifier(bootstrap=False, criterion='gini', max_depth= None, \n                             max_features= 3, min_samples_leaf= 1, min_samples_split= 10, \n                             n_estimators= 300)\nmodel.fit(xtrain, ytrain)\npredictions = model.predict(xtest)\n\netc_train_acc = accuracy_score(ytrain, model.predict(xtrain))\netc_test_acc = accuracy_score(ytest, predictions)\netc_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {}\\n b) Test : {}\".format(etc_train_acc, etc_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", etc_f1_score)\n\nconfusion_matrix(ytest, predictions)","191873b0":"xtrain = np.array(xtrain)\nxtest = np.array(xtest)","846b2f82":"xtrain = xtrain.reshape(xtrain.shape[0], xtrain.shape[1],-1)\nxtest = xtest.reshape(xtest.shape[0], xtest.shape[1],-1)","93668614":"import tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(xtrain[0].shape)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\nhistory = model.fit(xtrain, ytrain, epochs=1)","67244546":"train_acc = []\ntest_acc = []\nf1 = []\n\nfor i in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n    print(\"For i =\",i)\n    predictions = model.predict(xtest)\n    predictions = [1 if j>i else 0 for j in predictions]\n    train_predict = model.predict(xtrain)\n    train_predict = [1 if j>i else 0 for j in train_predict]\n    rnn_train_acc = accuracy_score(ytrain, train_predict)\n    rnn_test_acc = accuracy_score(ytest, predictions)\n    rnn_f1_score = f1_score(predictions, ytest)\n    train_acc.append(rnn_train_acc)\n    test_acc.append(rnn_test_acc)\n    f1.append(rnn_f1_score)\n    print(\"Accuracy score: \\n a) Train : {}\\n b) Test : {}\".format(rnn_train_acc, rnn_test_acc))\n    print(\"Precision score: \", precision_score(ytest, predictions))\n    print(\"Recall score: \", recall_score(ytest, predictions))\n    print(\"F1 score : \", rnn_f1_score)\n\n    confusion_matrix(ytest, predictions)","1ffe501f":"temp = np.argmax(rnn_f1_score)\nrnn_train_acc = train_acc[temp]\nrnn_test_acc =  test_acc[temp]\nrnn_f1_score =  f1[temp]","511ff4cf":"models = [('Linear SVC', svc_test_acc, svc_test_acc, svc_f1_score),\n          ('Logistic Regression', lr_train_acc, lr_test_acc, lr_f1_score),\n          ('Random Forest', rf_train_acc, rf_test_acc, rf_f1_score),\n          ('Ada boost', ada_train_acc, ada_test_acc, ada_f1_score),\n          ('Extra tree', etc_train_acc, etc_test_acc, etc_f1_score),\n          ('RNN', rnn_train_acc, rnn_test_acc, rnn_f1_score)\n         ]\n         \npredict = pd.DataFrame(data = models, columns=['Model', 'Train accuracy', 'Test accuracy', 'F1 score'])","2ac5c8c9":"predict","7d044a22":"f, axe = plt.subplots(1,1, figsize=(12,6))\n\npredict.sort_values(by=['F1 score'], ascending=False, inplace=True)\n\nsns.barplot(x='F1 score', y='Model', data = predict, ax = axe, palette='inferno')\naxe.set_xlabel('F1 score', size=16)\naxe.set_ylabel('Model')\naxe.set_xlim(0,1.0)\naxe.set_xticks(np.arange(0, 1.1, 0.1))\nplt.show()","2bd0f259":"import time, itertools\nfrom gensim.models import Word2Vec","da205d38":"w2v_model = Word2Vec(window=2,\n                     min_count=0,\n                     size=500,\n                     sample=6e-5, \n                     alpha=0.03, \n                     min_alpha=0.0007, \n                     negative=20)","2ee52dd2":"t = time.time()\n\nw2v_model.build_vocab(list(data[\"headline\"]), progress_per=10000)\n\nprint('Time to build vocab: {} mins'.format(round((time.time() - t) \/ 60, 2)))","0662daff":"t = time.time()\n\nw2v_model.train(list(data[\"headline\"]), total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n\nprint('Time to train the model: {} mins'.format(round((time.time() - t) \/ 60, 2)))","cc12c6fb":"w2v_model.init_sims(replace=True)","eb33bd1a":"data_vector = []\nfor i in range(len(data)):\n     data_vector.append(np.mean(w2v_model[data[\"headline\"].iloc[i]], axis=0))","5c5955ed":"xtrain, xtest, ytrain, ytest = train_test_split(np.array(data_vector), data[\"is_sarcastic\"], train_size = 0.75)","6ff62eee":"model = LinearSVC(loss=\"hinge\",fit_intercept=False, max_iter=1500)\nmodel = model.fit(xtrain, ytrain) \npredictions = model.predict(xtest)\n\nsvc_train_acc = accuracy_score(ytrain, model.predict(xtrain))\nsvc_test_acc = accuracy_score(ytest, predictions)\nsvc_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {} \\n b) Test : {}\".format(svc_train_acc, svc_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", svc_f1_score)\n\nconfusion_matrix(ytest, predictions)","1fe08c70":"model_lr = LogisticRegression(penalty='l2')\nmodel_lr = model_lr.fit(xtrain, ytrain) \npredictions = model_lr.predict(xtest)\n\nlr_train_acc = accuracy_score(ytrain, model_lr.predict(xtrain))\nlr_test_acc = accuracy_score(ytest, predictions)\nlr_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {} \\n b) Test : {} \".format(lr_train_acc, lr_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", lr_f1_score)\n\nconfusion_matrix(ytest, predictions)","55f9377a":"from sklearn.ensemble import RandomForestClassifier\n\nmodel_rf = RandomForestClassifier(n_estimators = 200)\nmodel_rf = model_rf.fit(xtrain, ytrain) \npredictions = model_rf.predict(xtest)\n\nrf_train_acc = accuracy_score(ytrain, model_rf.predict(xtrain))\nrf_test_acc = accuracy_score(ytest, predictions)\nrf_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {} \\n b) Test : {}\".format(rf_train_acc, rf_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", rf_f1_score)\n\nconfusion_matrix(ytest, predictions)","cfa70853":"tree = DecisionTreeClassifier(random_state = 11, max_features = \"auto\", class_weight = \"balanced\",max_depth = None)\n\nmodel_ada = AdaBoostClassifier(base_estimator=tree)\nmodel_ada = model_ada.fit(xtrain, ytrain)\npredictions = model_ada.predict(xtest)\n\nada_train_acc = accuracy_score(ytrain, model_ada.predict(xtrain))\nada_test_acc = accuracy_score(ytest, predictions)\nada_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {}\\n b) Test : {}\".format(ada_train_acc, ada_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \",  ada_f1_score)\n\nconfusion_matrix(ytest, predictions)","cec13850":"model = ExtraTreesClassifier(bootstrap=False, criterion='gini', max_depth= None, \n                             max_features= 3, min_samples_leaf= 1, min_samples_split= 10, \n                             n_estimators= 300)\nmodel.fit(xtrain, ytrain)\npredictions = model.predict(xtest)\n\netc_train_acc = accuracy_score(ytrain, model.predict(xtrain))\netc_test_acc = accuracy_score(ytest, predictions)\netc_f1_score = f1_score(predictions, ytest)\nprint(\"Accuracy score: \\n a) Train : {}\\n b) Test : {}\".format(etc_train_acc, etc_test_acc))\nprint(\"Precision score: \", precision_score(ytest, predictions))\nprint(\"Recall score: \", recall_score(ytest, predictions))\nprint(\"F1 score : \", etc_f1_score)\n\nconfusion_matrix(ytest, predictions)","8172b03e":"xtrain = xtrain.reshape(xtrain.shape[0], xtrain.shape[1]\n               ,-1)\nxtest = xtest.reshape(xtest.shape[0], xtest.shape[1]\n               ,-1)","3d3da4e6":"import tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(xtrain[0].shape)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, \"sigmoid\")\n])\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\nhistory = model.fit(xtrain, ytrain, epochs=50)","32b15967":"train_acc = []\ntest_acc = []\nf1 = []\n\nfor i in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n    print(\"For i =\",i)\n    predictions = model.predict(xtest)\n    predictions = [1 if j>i else 0 for j in predictions]\n    train_predict = model.predict(xtrain)\n    train_predict = [1 if j>i else 0 for j in train_predict]\n    rnn_train_acc = accuracy_score(ytrain, train_predict)\n    rnn_test_acc = accuracy_score(ytest, predictions)\n    rnn_f1_score = f1_score(predictions, ytest)\n    train_acc.append(rnn_train_acc)\n    test_acc.append(rnn_test_acc)\n    f1.append(rnn_f1_score)\n    print(\"Accuracy score: \\n a) Train : {}\\n b) Test : {}\".format(rnn_train_acc, rnn_test_acc))\n    print(\"Precision score: \", precision_score(ytest, predictions))\n    print(\"Recall score: \", recall_score(ytest, predictions))\n    print(\"F1 score : \", rnn_f1_score)\n\n    confusion_matrix(ytest, predictions)","f4788d3a":"temp = np.argmax(rnn_f1_score)\nrnn_train_acc = train_acc[temp]\nrnn_test_acc =  test_acc[temp]\nrnn_f1_score =  f1[temp]","ef7e2d25":"models = [('Linear SVC', svc_test_acc, svc_test_acc, svc_f1_score),\n          ('Logistic Regression', lr_train_acc, lr_test_acc, lr_f1_score),\n          ('Random Forest', rf_train_acc, rf_test_acc, rf_f1_score),\n          ('Ada boost', ada_train_acc, ada_test_acc, ada_f1_score),\n          ('Extra tree', etc_train_acc, etc_test_acc, etc_f1_score),\n          ('RNN', rnn_train_acc, rnn_test_acc, rnn_f1_score)\n         ]\n         \npredict = pd.DataFrame(data = models, columns=['Model', 'Train accuracy', 'Test accuracy', 'F1 score'])","893cdeca":"predict","46435174":"f, axe = plt.subplots(1,1, figsize=(12,6))\n\npredict.sort_values(by=['F1 score'], ascending=False, inplace=True)\n\nsns.barplot(x='F1 score', y='Model', data = predict, ax = axe, palette='inferno')\naxe.set_xlabel('F1 score', size=16)\naxe.set_ylabel('Model')\naxe.set_xlim(0,1.0)\naxe.set_xticks(np.arange(0, 1.1, 0.1))\nplt.show()","eeaf45b7":"# TF -IDF","231d878c":"# Text analysis","0fe45415":"Wordcloud of Sacrastic headlines","0c1c257e":"Checking for the null values.","8396dd33":"# Word2Vec","c96a2f4f":"Wordcloud of Non sarcastic headlines","96dcdadf":"Text analysis of Sarcastic headlines "}}