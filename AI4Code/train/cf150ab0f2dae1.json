{"cell_type":{"a949455d":"code","790dcb16":"code","045cb483":"code","de1a68f0":"code","74638c5e":"code","49be7b39":"code","44f043ee":"code","6498a773":"code","7f78206c":"code","6a71de56":"code","5e4fd38b":"code","9680005e":"code","99a57d21":"code","abf41187":"code","0d5123d8":"code","3e283b29":"code","d767380d":"code","6e48022a":"code","7f8e212b":"code","24d9d7c0":"code","e6617a7c":"code","258123b1":"code","8a9d35d8":"markdown","ec636db4":"markdown","b40cf6a3":"markdown","48fd9b0a":"markdown"},"source":{"a949455d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","790dcb16":"df = pd.read_csv('..\/input\/frenchfakenewsdetector\/datafake_train.csv',delimiter=';', encoding='utf-8')\ndf.head()","045cb483":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision\nimport matplotlib.pyplot as plt\nimport re\nimport os\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","de1a68f0":"#data.dropna(inplace=True)  There is NO missing values\nchange_labels = lambda x: 1 if x==0 else 0\ndf['fake'] = df['fake'].apply(change_labels)","74638c5e":"remove_non_alphabets =lambda x: re.sub(r'[^a-zA-Z]',' ',x)","49be7b39":"tokenize = lambda x: word_tokenize(x)","44f043ee":"ps = PorterStemmer()\nstem = lambda w: [ ps.stem(x) for x in w ]","6498a773":"lemmatizer = WordNetLemmatizer()\nleammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]","7f78206c":"print('Processing : [=', end='')\ndf['post'] = df['post'].apply(remove_non_alphabets)\nprint('=', end='')\ndf['post'] = df['post'].apply(tokenize) # [ word_tokenize(row) for row in data['MESSAGE']]\nprint('=', end='')\ndf['post'] = df['post'].apply(stem)\nprint('=', end='')\ndf['post'] = df['post'].apply(leammtizer)\nprint('=', end='')\ndf['post'] = df['post'].apply(lambda x: ' '.join(x))\nprint('] : Completed', end='')\ndf.head()","6a71de56":"#Copied by my French StopWords W2V Notebook https:\/\/www.kaggle.com\/mpwolke\/french-stopwords-w2v\n\nstop_words =['d', 'comme', 'sois', 'la', 'sommes', 'eu', 'eus', 'auront', 'eux', 'que', 'de', 'si', 'des', 'le', 'qui', 'en', 'pas']","5e4fd38b":"max_words = 10000\ncv = CountVectorizer(max_features=max_words, stop_words= stop_words)\nsparse_matrix = cv.fit_transform(df['post']).toarray()","9680005e":"sparse_matrix.shape","99a57d21":"x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(df['fake']))","abf41187":"class LogisticRegression(nn.Module):\n    def __init__(self):\n        super(LogisticRegression, self).__init__()\n        self.linear1 = nn.Linear(10000, 100)\n        self.linear2 = nn.Linear(100, 10)\n        self.linear3 = nn.Linear(10, 2)\n        \n    def forward(self, x):\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x","0d5123d8":"model = LogisticRegression()","3e283b29":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)","d767380d":"x_train = Variable(torch.from_numpy(x_train)).float()\ny_train = Variable(torch.from_numpy(y_train)).long()","6e48022a":"epochs = 20\nmodel.train()\nloss_values = []\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    y_pred = model(x_train)\n    loss = criterion(y_pred, y_train)\n    loss_values.append(loss.item())\n    pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n    acc = pred * 100.0 \/ len(x_train)\n    print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n    loss.backward()\n    optimizer.step()","7f8e212b":"plt.plot(loss_values)\nplt.title('Loss Value vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Loss'])\nplt.show()","24d9d7c0":"x_test = Variable(torch.from_numpy(x_test)).float()\ny_test = Variable(torch.from_numpy(y_test)).long()","e6617a7c":"model.eval()\nwith torch.no_grad():\n    y_pred = model(x_test)\n    loss = criterion(y_pred, y_test)\n    pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n    print (\"Accuracy : {}%\".format(100*pred\/len(x_test)))","258123b1":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thanks to Shivam Mehta, all code by Shivam.')","8a9d35d8":"#All script by Shivam Mehta https:\/\/www.kaggle.com\/shivammehta007\/spam-not-spam-classifier-with-pytorch\n\nExcept french `stop_words`.","ec636db4":"#Preprocess text data\n\nRemove non words, lower it, then Tokenize, Lemmatize and Vectorize and Remove Stopwords from the data.","b40cf6a3":"![](https:\/\/www.lyceeshanghai.com\/wp-content\/uploads\/2020\/09\/Exposition-histoire-des-fausses-nouvelles.png)lyceeshanghai.com","48fd9b0a":"#https:\/\/www.kaggle.com\/shivammehta007\/spam-not-spam-classifier-with-pytorch"}}