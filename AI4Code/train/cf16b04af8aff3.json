{"cell_type":{"85636030":"code","f328944f":"code","b1968079":"code","4206b174":"code","eea52acd":"code","0e215c31":"code","22a91da5":"code","a5c91161":"code","8043cc5d":"code","06ccdbf5":"code","fd76c75a":"code","ff1436cd":"code","0bf4af08":"code","0e51cfb1":"code","70e355e1":"code","89b4a5a7":"code","28e09421":"code","673a5ba8":"code","132d1738":"code","47cbf254":"code","566f33de":"code","64e3c863":"code","acfa65e2":"code","5ba73aaa":"code","4178c5fe":"code","3a11ca31":"code","04d195f8":"code","e037782a":"code","7d912538":"code","b1107b74":"code","a1e67b18":"code","633ed56c":"code","99347dde":"code","db243283":"code","eef5645a":"code","49f8fd40":"code","4acb17e2":"code","2e519caa":"code","221c862f":"code","87cbe33f":"code","606d4ebb":"code","43445744":"code","942289c7":"code","f7589134":"code","48e52eb8":"code","f9f66996":"code","d069d0f9":"code","6d403ebf":"code","dce8ff77":"code","e099df71":"code","d707875a":"code","5d3659b2":"code","0faf33e0":"code","ec6f37c8":"code","58c5f31a":"code","30eb557e":"code","8a0b86bf":"code","a2c51c51":"code","9e048f71":"code","242148af":"code","27679ead":"code","e303e07e":"code","6d0302e9":"code","2ef58280":"code","a3e910e1":"code","125e3594":"code","8de8a491":"code","d20dcf2f":"code","a65e0a1d":"code","29b5d1b9":"code","9decd7a9":"code","1fb6253d":"code","51b01e5b":"code","6a20c810":"code","b8c89b32":"code","70e58246":"code","21819fb1":"code","54f9632d":"code","42d85cee":"code","5b90964f":"code","2858ca6d":"code","ee6d1f97":"code","20190b9c":"code","09fcf417":"code","ddae8bcd":"code","8c133a26":"markdown","f4dc4a72":"markdown","b3eada3d":"markdown","fb01f07c":"markdown","701be117":"markdown","e4578fca":"markdown","315e4c3f":"markdown","b4c06fd6":"markdown","9b99667c":"markdown","0f654f2a":"markdown","1171ced5":"markdown","e23969cc":"markdown","764858d4":"markdown","3773de31":"markdown","856a9a66":"markdown","72ca2f74":"markdown","87eba482":"markdown","fe44c812":"markdown","cfba42ce":"markdown","6714a376":"markdown","96e1141c":"markdown","0fa00238":"markdown","32f3ae8e":"markdown","f9123f5c":"markdown","c801b304":"markdown","e8ca5ba7":"markdown","db0143e7":"markdown","bfcd98b6":"markdown","160f9d41":"markdown","ff6aaa81":"markdown"},"source":{"85636030":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","f328944f":"import os\nimport os.path\nfrom pathlib import Path\nimport glob","b1968079":"from PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","4206b174":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers","eea52acd":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve","0e215c31":"from keras.optimizers import RMSprop,Adam,Optimizer,Optimizer","22a91da5":"from tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K","a5c91161":"from warnings import filterwarnings\n\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","8043cc5d":"Train_Data_Path = Path(\"..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TRAIN\")","06ccdbf5":"Test_Data_Path = Path(\"..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST\")","fd76c75a":"Validation_Data_Path = Path(\"..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST_SIMPLE\")","ff1436cd":"Train_JPG_Path = list(Train_Data_Path.glob(r\"**\/*.jpeg\"))","0bf4af08":"Test_JPG_Path = list(Test_Data_Path.glob(r\"**\/*.jpeg\"))","0e51cfb1":"Validation_JPG_Path = list(Validation_Data_Path.glob(r\"**\/*.jpeg\"))","70e355e1":"Train_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Train_JPG_Path))","89b4a5a7":"print(\"EOSINOPHIL: \", Train_JPG_Labels.count(\"EOSINOPHIL\"))\nprint(\"LYMPHOCYTE: \", Train_JPG_Labels.count(\"LYMPHOCYTE\"))\nprint(\"MONOCYTE: \", Train_JPG_Labels.count(\"MONOCYTE\"))\nprint(\"NEUTROPHIL: \", Train_JPG_Labels.count(\"NEUTROPHIL\"))","28e09421":"Test_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Test_JPG_Path))","673a5ba8":"print(\"EOSINOPHIL: \", Test_JPG_Labels.count(\"EOSINOPHIL\"))\nprint(\"LYMPHOCYTE: \", Test_JPG_Labels.count(\"LYMPHOCYTE\"))\nprint(\"MONOCYTE: \", Test_JPG_Labels.count(\"MONOCYTE\"))\nprint(\"NEUTROPHIL: \", Test_JPG_Labels.count(\"NEUTROPHIL\"))","132d1738":"Validation_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Validation_JPG_Path))","47cbf254":"print(\"EOSINOPHIL: \", Validation_JPG_Labels.count(\"EOSINOPHIL\"))\nprint(\"LYMPHOCYTE: \", Validation_JPG_Labels.count(\"LYMPHOCYTE\"))\nprint(\"MONOCYTE: \", Validation_JPG_Labels.count(\"MONOCYTE\"))\nprint(\"NEUTROPHIL: \", Validation_JPG_Labels.count(\"NEUTROPHIL\"))","566f33de":"Train_JPG_Path_Series = pd.Series(Train_JPG_Path,name=\"JPG\").astype(str)","64e3c863":"Train_JPG_Labels_Series = pd.Series(Train_JPG_Labels,name=\"CATEGORY\")","acfa65e2":"Test_JPG_Path_Series = pd.Series(Test_JPG_Path,name=\"JPG\").astype(str)","5ba73aaa":"Test_JPG_Labels_Series = pd.Series(Test_JPG_Labels,name=\"CATEGORY\")","4178c5fe":"Validation_JPG_Path_Series = pd.Series(Validation_JPG_Path,name=\"JPG\").astype(str)","3a11ca31":"Validation_JPG_Labels_Series = pd.Series(Validation_JPG_Labels,name=\"CATEGORY\")","04d195f8":"Main_Train_Data = pd.concat([Train_JPG_Path_Series,Train_JPG_Labels_Series],axis=1)","e037782a":"print(Main_Train_Data.head(-1))","7d912538":"Main_Test_Data = pd.concat([Test_JPG_Path_Series,Test_JPG_Labels_Series],axis=1)","b1107b74":"print(Main_Test_Data.head(-1))","a1e67b18":"Main_Validation_Data = pd.concat([Validation_JPG_Path_Series,Validation_JPG_Labels_Series],axis=1)","633ed56c":"print(Main_Validation_Data.head(-1))","99347dde":"Main_Train_Data = Main_Train_Data.sample(frac=1).reset_index(drop=True)","db243283":"print(Main_Train_Data.head(-1))","eef5645a":"print(Main_Train_Data[\"JPG\"][1])\nprint(Main_Train_Data[\"CATEGORY\"][1])\nprint(Main_Train_Data[\"JPG\"][1398])\nprint(Main_Train_Data[\"CATEGORY\"][1398])\nprint(Main_Train_Data[\"JPG\"][355])\nprint(Main_Train_Data[\"CATEGORY\"][355])\nprint(Main_Train_Data[\"JPG\"][710])\nprint(Main_Train_Data[\"CATEGORY\"][710])","49f8fd40":"Main_Test_Data = Main_Test_Data.sample(frac=1).reset_index(drop=True)","4acb17e2":"print(Main_Test_Data.head(-1))","2e519caa":"print(Main_Test_Data[\"JPG\"][1])\nprint(Main_Test_Data[\"CATEGORY\"][1])\nprint(Main_Test_Data[\"JPG\"][1398])\nprint(Main_Test_Data[\"CATEGORY\"][1398])\nprint(Main_Test_Data[\"JPG\"][355])\nprint(Main_Test_Data[\"CATEGORY\"][355])\nprint(Main_Test_Data[\"JPG\"][710])\nprint(Main_Test_Data[\"CATEGORY\"][710])","221c862f":"Main_Validation_Data = Main_Validation_Data.sample(frac=1).reset_index(drop=True)","87cbe33f":"print(Main_Validation_Data.head(-1))","606d4ebb":"print(Main_Validation_Data[\"JPG\"][1])\nprint(Main_Validation_Data[\"CATEGORY\"][1])\nprint(Main_Validation_Data[\"JPG\"][52])\nprint(Main_Validation_Data[\"CATEGORY\"][52])\nprint(Main_Validation_Data[\"JPG\"][11])\nprint(Main_Validation_Data[\"CATEGORY\"][11])\nprint(Main_Validation_Data[\"JPG\"][25])\nprint(Main_Validation_Data[\"CATEGORY\"][25])","43445744":"plt.style.use('dark_background')","942289c7":"sns.countplot(Main_Train_Data[\"CATEGORY\"])\nplt.show()","f7589134":"sns.countplot(Main_Test_Data[\"CATEGORY\"])\nplt.show()","48e52eb8":"sns.countplot(Main_Validation_Data[\"CATEGORY\"])\nplt.show()","f9f66996":"Main_Train_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","d069d0f9":"Main_Test_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","6d403ebf":"Main_Validation_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","dce8ff77":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Train_Data[\"JPG\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Train_Data[\"CATEGORY\"][0])","e099df71":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Test_Data[\"JPG\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Test_Data[\"CATEGORY\"][0])","d707875a":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Validation_Data[\"JPG\"][52])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Validation_Data[\"CATEGORY\"][52])","5d3659b2":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Train_Data[\"JPG\"][i]))\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","0faf33e0":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Test_Data[\"JPG\"][i]))\n    ax.set_title(Main_Test_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","ec6f37c8":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Validation_Data[\"JPG\"][i]))\n    ax.set_title(Main_Validation_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","58c5f31a":"Train_Generator = ImageDataGenerator(rescale=1.\/255,\n                                    zoom_range=0.3,\n                                    shear_range=0.3,\n                                    rotation_range=40,\n                                    horizontal_flip=True,\n                                    fill_mode=\"nearest\")","30eb557e":"Test_Validation_Generator = ImageDataGenerator(rescale=1.\/255,validation_split=0.5)","8a0b86bf":"exp_IMG = Main_Train_Data[\"JPG\"][22]\nLoad_IMG = image.load_img(exp_IMG,target_size=(220,220))\nArray_IMG = image.img_to_array(Load_IMG)\nArray_IMG = Array_IMG.reshape((1,) + Array_IMG.shape)","a2c51c51":"i = 0\nfor batch in Train_Generator.flow(Array_IMG,batch_size=1):\n    plt.figure(i)\n    IMG = plt.imshow(image.img_to_array(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\nplt.show()","9e048f71":"Train_IMG_Set = Train_Generator.flow_from_dataframe(dataframe=Main_Train_Data,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   color_mode=\"rgb\",\n                                                   class_mode=\"categorical\",\n                                                   subset=\"training\",\n                                                   seed=42,\n                                                   batch_size=32,\n                                                   target_size=(220,220))","242148af":"Test_IMG_Set = Test_Validation_Generator.flow_from_dataframe(dataframe=Main_Test_Data,\n                                                            x_col=\"JPG\",\n                                                            y_col=\"CATEGORY\",\n                                                            color_mode=\"rgb\",\n                                                            class_mode=\"categorical\",\n                                                            seed=42,\n                                                            batch_size=32,\n                                                            target_size=(220,220))","27679ead":"Validation_IMG_Set = Test_Validation_Generator.flow_from_dataframe(dataframe=Main_Validation_Data,\n                                                                  x_col=\"JPG\",\n                                                                  y_col=\"CATEGORY\",\n                                                                  color_mode=\"rgb\",\n                                                                  class_mode=\"categorical\",\n                                                                  seed=42,\n                                                                  batch_Size=32,\n                                                                  target_size=(220,200),\n                                                                  subset=\"validation\")","e303e07e":"for data_batch,label_batch in Train_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","6d0302e9":"for data_batch,label_batch in Validation_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","2ef58280":"for data_batch,label_batch in Test_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","a3e910e1":"print(\"TRAIN: \")\nprint(Train_IMG_Set.class_indices)\nprint(Train_IMG_Set.classes[0:5])\nprint(Train_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_IMG_Set.class_indices)\nprint(Validation_IMG_Set.classes[0:5])\nprint(Validation_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")\nprint(Test_IMG_Set.class_indices)\nprint(Test_IMG_Set.classes[0:5])\nprint(Test_IMG_Set.image_shape)","125e3594":"Model = Sequential()\n\nModel.add(SeparableConv2D(32,3,\n                          activation=\"relu\",\n                 input_shape=(220,220,3)))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2)))\n\n#\nModel.add(SeparableConv2D(64,3,\n                 activation=\"relu\"))\nModel.add(SeparableConv2D(128,(3,3),\n                 activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(MaxPooling2D((2)))\n\n#\nModel.add(SeparableConv2D(64,3,\n                 activation=\"relu\"))\nModel.add(SeparableConv2D(128,3,\n                 activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(GlobalAveragePooling2D())\n\n#\nModel.add(Flatten())\nModel.add(Dense(256,\n                activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(4,\n                activation=\"softmax\"))","8de8a491":"Call_Back = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=5,mode=\"max\")","d20dcf2f":"Model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","a65e0a1d":"CNN_Model = Model.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                            callbacks=Call_Back,\n                      epochs=50)","29b5d1b9":"Model_Results = Model.evaluate(Test_IMG_Set)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","9decd7a9":"print(Model.summary())","1fb6253d":"plt.plot(CNN_Model.history[\"accuracy\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","51b01e5b":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","6a20c810":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"accuracy\"])\nplt.ylabel(\"LOSS - ACCURACY\")\nplt.legend()\nplt.show()","b8c89b32":"plt.plot(CNN_Model.history[\"val_loss\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"VAL LOSS - VAL ACCURACY\")\nplt.legend()\nplt.show()","70e58246":"Dict_Summary = pd.DataFrame(CNN_Model.history)\nDict_Summary.plot()","21819fb1":"Any_IMG = Main_Train_Data[\"JPG\"][6]\nIMG = image.load_img(Any_IMG,target_size=(220,220))\nArray_IMG = image.img_to_array(IMG)\nArray_IMG = np.expand_dims(Array_IMG,axis=0)\nArray_IMG \/= 255\n\nplt.imshow(Array_IMG[0])\nplt.title(\"ANY TARGET IMAGE\")\nplt.show()","54f9632d":"layer_out = [layer.output for layer in Model.layers[:8]]\nactivation_model = models.Model(inputs=Model.input,outputs=layer_out)\nactivations = activation_model.predict(Array_IMG)\n\nfirst_layer_act = activations[0]\nprint(first_layer_act.shape)","42d85cee":"plt.matshow(first_layer_act[0,:,:,4],cmap=\"viridis\")","5b90964f":"plt.matshow(first_layer_act[0,:,:,7],cmap=\"viridis\")","2858ca6d":"plt.matshow(first_layer_act[0,:,:,15],cmap=\"viridis\")","ee6d1f97":"plt.matshow(first_layer_act[0,:10,:10,7],cmap=\"viridis\")","20190b9c":"Prediction = Model.predict(Test_IMG_Set)\nPrediction = Prediction.argmax(axis=-1)","09fcf417":"print(Prediction)","ddae8bcd":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Test_Data[\"JPG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{Prediction[i]}\")\nplt.tight_layout()\nplt.show()","8c133a26":"#### JPG PATH","f4dc4a72":"# TRANSFORMATION TO DATAFRAME STRUCTURE","b3eada3d":"#### TEST","fb01f07c":"#### SCALER & TRANSFORMATION","701be117":"#### IMG SET CHECKING","e4578fca":"# LEARNING IN EACH LAYER","315e4c3f":"#### IGNORING WARNINGS","b4c06fd6":"# PATH & LABELS","9b99667c":"#### GENERAL","0f654f2a":"#### MODEL LAYERS","1171ced5":"#### Context\n* The diagnosis of blood-based diseases often involves identifying and characterizing patient blood samples. Automated methods to detect and classify blood cell subtypes have important medical applications.\n\n#### Content\n* This dataset contains 12,500 augmented images of blood cells (JPEG) with accompanying cell type labels (CSV). There are approximately 3,000 images for each of 4 different cell types grouped into 4 different folders (according to cell type). The cell types are Eosinophil, Lymphocyte, Monocyte, and Neutrophil. This dataset is accompanied by an additional dataset containing the original 410 images (pre-augmentation) as well as two additional subtype labels (WBC vs WBC) and also bounding boxes for each cell in each of these 410 images (JPEG + XML metadata). More specifically, the folder 'dataset-master' contains 410 images of blood cells with subtype labels and bounding boxes (JPEG + XML), while the folder 'dataset2-master' contains 2,500 augmented images as well as 4 additional subtype labels (JPEG + CSV). There are approximately 3,000 augmented images for each class of the 4 classes as compared to 88, 33, 21, and 207 images of each in folder 'dataset-master'.","e23969cc":"# VISUALIZATION","764858d4":"# PREDICTION","3773de31":"# TRANSFORMATION TO SERIES STRUCTURE","856a9a66":"#### IMAGE GENERATOR","72ca2f74":"#### How Generator Applied Image Look Like","87eba482":"#### VALIDATION","fe44c812":"# CNN STRUCTURE WITH SeparableConv2D","cfba42ce":"# HISTORY","6714a376":"#### IMAGE PROCESS","96e1141c":"#### JPG LABELS","0fa00238":"#### OPTIMIZER","32f3ae8e":"# PACKAGES AND LIBRARIES","f9123f5c":"#### ACCURACY CONTROL","c801b304":"# DETERMINATION TRAIN AND TEST DATA","e8ca5ba7":"#### TRAIN","db0143e7":"#### APPLYING GENERATOR AND TRANSFORMATION TO TENSOR","bfcd98b6":"#### PATH PROCESS","160f9d41":"* 'EOSINOPHIL': 0\n* 'LYMPHOCYTE': 1\n* 'MONOCYTE': 2\n* 'NEUTROPHIL': 3","ff6aaa81":"# SHUFFLING"}}