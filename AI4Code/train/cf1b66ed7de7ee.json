{"cell_type":{"50874c4c":"code","1677e678":"code","ceb2de8f":"code","96116e91":"code","eff2f9cb":"code","97708560":"code","cba99dfa":"code","59f43996":"code","f7a9bd64":"code","0fc7b9b1":"code","a8de6491":"code","e0b9e0de":"code","8a34051a":"code","f3d72e88":"code","1fc57193":"code","39586c13":"code","5c74650f":"code","f63e3b59":"code","d067b297":"code","6159d0dd":"code","4e3007da":"code","f34cbac1":"code","dae49719":"code","00e2fb8e":"markdown","0c76f051":"markdown","0f3c9bc6":"markdown","a9f029bb":"markdown"},"source":{"50874c4c":"from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom PIL import Image","1677e678":"train_path = \"..\/input\/fruits\/fruits-360\/Training\/\"\ntest_path = \"..\/input\/fruits\/fruits-360\/Test\/\"","ceb2de8f":"numberOfClasses = len(glob(train_path+\"\/*\"))","96116e91":"from keras.applications.vgg16 import VGG16\n# vgg16_weights = '..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n\nvgg = VGG16()","eff2f9cb":"vgg.summary()","97708560":"vgg_layer_list = vgg.layers\nvgg_layer_list","cba99dfa":"# Removing the last layer\nmodel = Sequential()\nfor i in range(len(vgg_layer_list)-1):\n    model.add(vgg_layer_list[i])","59f43996":"model.summary()","f7a9bd64":"for layers in model.layers:\n    layers.trainable= False\n    \nmodel.add(Dense(numberOfClasses, activation='softmax'))","0fc7b9b1":"model.summary()","a8de6491":"model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])","e0b9e0de":"# train & test\ntrain_data = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224))\ntest_data = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224))","8a34051a":"batch_size = 32","f3d72e88":"hist = model.fit(train_data, \n                 steps_per_epoch=1600\/\/batch_size, \n                 epochs=25, \n                 validation_data=test_data, \n                 validation_steps=800\/\/batch_size)","1fc57193":"model.save_weights(\"model.h5\")","39586c13":"# save history\nimport json, codecs\nwith open(\"graph.json\",\"w\") as f:\n    json.dump(hist.history,f)","5c74650f":"# load history\nwith codecs.open(\"graph.json\", encoding=\"utf-8\") as f:\n    n = json.loads(f.read())","f63e3b59":"# evaluation\nplt.plot(n['loss'], label=\"training_loss\")\nplt.plot(n['val_loss'], label=\"validation_loss\")\nplt.legend()\nplt.show()","d067b297":"plt.plot(n['accuracy'], label=\"training_accuracy\")\nplt.plot(n['val_accuracy'], label=\"validation_accuracy\")\nplt.legend()\nplt.show()","6159d0dd":"from keras.applications.vgg19 import VGG19\nvgg = VGG19()","4e3007da":"vgg.summary()","f34cbac1":"vgg_layer_list = vgg.layers\n\n# Removing the last layer\nmodel = Sequential()\nfor i in range(len(vgg_layer_list)-1):\n    model.add(vgg_layer_list[i])\n\n    \nfor layers in model.layers:\n    layers.trainable= False\n    \nmodel.add(Dense(numberOfClasses, activation='softmax'))\n\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n\n\n# train & test\ntrain_data = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224))\ntest_data = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224))\n\n\nbatch_size = 32\n\nhist = model.fit(train_data, \n                 steps_per_epoch=1600\/\/batch_size, \n                 epochs=25, \n                 validation_data=test_data, \n                 validation_steps=800\/\/batch_size)","dae49719":"# cifar10 dataset and different vgg19 method\nfrom keras.datasets import cifar10\nimport numpy as np\nimport cv2\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nnumber_of_class = 10\ninput_shape = x_train.shape[1:]\n\ny_train = to_categorical(y_train, number_of_class)\ny_test = to_categorical(y_test, number_of_class)\n\n# increase dimension\ndef resize_img(img):\n    numberOfImage = img.shape[0]\n    new_array = np.zeros((numberOfImage,48,48,3))\n    for i in range(numberOfImage):\n        new_array[i] = cv2.resize(img[i,:,:,:],(48,48))\n    return new_array\n\nx_train = resize_img(x_train)\nx_test = resize_img(x_test)\n\nvgg = VGG19(include_top=False, weights='imagenet', input_shape=(48,48,3))\n\nvgg_layer_list = vgg.layers\n\nmodel = Sequential()\nfor i in range(len(vgg_layer_list)-1):\n    model.add(vgg_layer_list[i])\n    \nfor layers in model.layers:\n    layers.trainable= False\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Dense(number_of_class, activation='softmax'))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n\n# train & test\ntrain_data = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224))\ntest_data = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224))\n\n\nhist = model.fit(x_train, y_train, validation_split=0.2, epochs=25, batch_size=1000)","00e2fb8e":"# Transfer Learning\n\n![](https:\/\/miro.medium.com\/max\/3200\/0*azmg0auRA-orU2GB)\n\nDue to the training of some models, the complexity of the model or the size of the data set, it is almost impossible to perform on standard computer processors. That's why graphic processing units are needed. As a result of trainings that last for days or weeks, these trained models can be used in various ways to solve different problems. This is exactly what is called \"Transfer Learning\". For example; This process is advantageous when the data set you use is not large enough. If there is a model trained with a data set consisting of 15 million different images, such as ImageNet, even if your data set has very few images, much more successful results are obtained because the learning process takes place. So how many different ways can transfer learning be done?\n\n- By freezing the whole model (trainable parameter = 0, freeze = 1) by setting the softmax output according to the number of classes of your own problem,\n- Designing by keeping several layers of the model fixed and keeping the last layers different,\n- The entire network can be used for training in your own dataset (learnable parameter = 1, freeze = 0)\n\nTransfer learning provides faster solutions to many problems in artificial intelligence studies. Because an open source system is available and supported. The originals of the works on GitHub can be examined and used for pre-training or transfer learning in your own problems. The critical point here is to learn the applications (framework) designed for deep learning and to understand the configurations.","0c76f051":"# VGG19","0f3c9bc6":"# Practice\n## VGG16","a9f029bb":"## VGG16 & VGG19\n![](https:\/\/miro.medium.com\/max\/1658\/1*4F-9zrU07yhwj6gChX_q-Q.png)\nIt is a simple network model and the most important difference from the previous models is the use of convolutional additions with 2 or 3. It is converted into an attribute vector with 7x7x512 = 4096 neurons in the full link (FC) layer. Softmax performance of 1000 classes is calculated at the output of two FC layers. Approximately 138 million parameters are calculated. As in other models, the height and width dimensions of the matrices from the entrance to the exit decrease while the depth value (number of channels) increases.\n![](https:\/\/miro.medium.com\/max\/576\/0*jVx0rKGL9_u-xPaD.png)\nFilters with different weights are calculated at each convolution layer output of the model, and as the number of layers increases, the attributes formed in the filters symbolize the 'depths' of the image.\n![](https:\/\/miro.medium.com\/max\/603\/0*Nf7zOyC2OaNFhKIf.png)"}}