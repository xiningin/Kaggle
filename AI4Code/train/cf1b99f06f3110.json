{"cell_type":{"181a4acc":"code","16ec93d2":"code","2b8f0f8b":"code","452ee100":"code","fd9abd6b":"code","e1299b81":"code","f0425449":"code","ac8ddb49":"code","7b930c23":"code","a5f62bf2":"code","e737f4a7":"code","c5bfaba3":"code","c3459ba2":"code","a1ab24d0":"code","64acbbcf":"code","587b5302":"code","134dd096":"code","a469e090":"code","44514ff7":"code","48ff5f4f":"code","27a6bae5":"code","c05ca90f":"code","0663f30a":"code","48c69c30":"code","ab5959fb":"code","0c6762aa":"code","2dc436a9":"code","4ce16286":"markdown","10071a64":"markdown","e421c5f8":"markdown","be0b777e":"markdown","5956ac04":"markdown","79a65861":"markdown","3df9b7fe":"markdown","49e64675":"markdown","65c0a727":"markdown","d273ebd7":"markdown","6c716ba1":"markdown","38759951":"markdown","f02333c7":"markdown","0daf028e":"markdown"},"source":{"181a4acc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","16ec93d2":"heart_d=pd.read_csv(\"..\/input\/heart.csv\")\nheart_d.head()","2b8f0f8b":"heart_d.describe()","452ee100":"heart_d.info()","fd9abd6b":"heart_d.isnull()","e1299b81":"import seaborn as sns\ng=sns.pairplot(heart_d)","f0425449":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.subplots(figsize=(10,8))\nsns.heatmap(heart_d.corr(),annot=True,linewidths=0.8,cmap='coolwarm')","ac8ddb49":"plt.scatter(heart_d['chol'],heart_d['thalach'])","7b930c23":"sns.jointplot(x='chol',y='thalach',data=heart_d,kind='kde',color=\"g\")","a5f62bf2":"ax=plt.subplots(figsize=(10,8))\nsns.boxplot(data=heart_d['trestbps'])","e737f4a7":"sns.barplot(heart_d['target'],heart_d['trestbps'])","c5bfaba3":"plt.subplots(figsize=(10,8))\nsns.boxplot(data=heart_d['chol'])","c3459ba2":"sns.barplot(heart_d['target'],heart_d['chol'])","a1ab24d0":"sns.boxplot(data=heart_d['oldpeak'])","64acbbcf":"sns.barplot(heart_d['target'],heart_d['oldpeak'])","587b5302":"from sklearn.model_selection import train_test_split\nX=heart_d.drop(\"target\",axis=1)\nY=heart_d[\"target\"]\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20,random_state=42)\n","134dd096":"from sklearn.metrics import accuracy_score","a469e090":"from sklearn import svm\nsv=svm.SVC(kernel='linear')\nsv.fit(X_train,Y_train)\npred_sv=sv.predict(X_test)\n","44514ff7":"pred_sv.shape","48ff5f4f":"score_svm=accuracy_score(pred_sv,Y_test)\nprint(\"The accuracy achieved using svm is\"+\" \"+str((score_svm)*100))","27a6bae5":"from sklearn.linear_model import LogisticRegression\nlg=LogisticRegression()\nlg.fit(X_train,Y_train)\npred_lg=lg.predict(X_test)","c05ca90f":"score_lgr=accuracy_score(pred_lg,Y_test)\nprint(\"The accuracy achieved using Logistic regression\"+\" \"+str((score_lgr)*100))\n","0663f30a":"from keras.models import Sequential\nfrom keras.layers import Dense\nmodel=Sequential()\nmodel.add(Dense(11,input_dim=13,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","48c69c30":"model.fit(X_train,Y_train,epochs=250)","ab5959fb":"pred_nn=model.predict(X_test)","0c6762aa":"round_nn=[round(x[0]) for x in pred_nn]\nscore_nn=accuracy_score(round_nn,Y_test)*100\nprint(\"The accuracy score of the neural network is\"+\" \"+str(score_nn))\n","2dc436a9":"score=[score_svm*100,score_lgr*100,score_nn]\nalgorithms=[\"Support Vector Machine\",\"Logistic Regression\", \"Neural Network\"]\nsns.barplot(algorithms,score)","4ce16286":"Now, we go for plotting a heatmap that plots the correlation between each one of the features with another feature.","10071a64":"**Logistic Regression**","e421c5f8":"From the above operations on the dataset we can conclude that all the values are numerical and does not have any missing value.\nLuckily there is no missing value!!","be0b777e":"Now, we come to the point where we divide the dataset between training and test set.\nAs, this is a high quality dataset we do not need to divide it into a validation set.","5956ac04":"   The next piece of code imports the dataset in csv format.And, it converts the dataset into a panda dataframe.","79a65861":"After this if we use shape function to the train and test sets we will see the number of samples taken into them.","3df9b7fe":"Now, we will start visualizing each feature one after one. Also, known as univariate visualization. Along, with this we will also plot each of the feature to study the characteristics of the data.","49e64675":"FIrst, we plot each one of the features with respect to another. This gives us an empirical idea about the relation between each other. We plot this using **pairplot** function in **seaborn** library.","65c0a727":"**Data Visualization**\nThis is the most important part of data preprocessing. It give us an idea how the features of the data ar related  to each other.\nThere are many powerful plotting libraries provided by python. Some of the important plotting libraries are matplotlib, seaborn, etc.\n","d273ebd7":"**Neural Network**","6c716ba1":"So we can see that all the algorithms gives the same accuracy as the data is of very high quality.","38759951":"**Support Vector Machine**","f02333c7":"Now, comes the model fitting task here we import models from the sklearn library and also use the keras library to build a neural network.\nAlso, we will check the accuracy of the model along with each of the application. ","0daf028e":"Now, we will plot scatter plot between two features, one after another two relate between them. We will use functions from both libraries matplotlib and seaborn."}}