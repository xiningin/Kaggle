{"cell_type":{"8e654698":"code","dd93cbbf":"code","be54b90e":"code","dc9d65bf":"code","45e8538f":"code","765bdc9f":"code","40492165":"code","d00a36bd":"code","569fb863":"code","af8547fc":"code","9257d870":"code","7864ddd9":"code","46ddff9f":"code","759c8a19":"code","ef610960":"code","32810bb0":"code","f8c8e83c":"code","565df31d":"code","9329e696":"code","a98da442":"code","7555a9eb":"code","f622e960":"code","36834897":"code","ba9516dc":"code","9d325bd3":"code","e25eb372":"code","ce7c71c8":"code","d72e7466":"code","489f6cfa":"code","931c590c":"markdown","674efce8":"markdown","706e7d75":"markdown","83c57dc3":"markdown"},"source":{"8e654698":"DEBUG = False","dd93cbbf":"import os,random,copy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom tqdm import tqdm_notebook as tqdm\nimport time\nimport pickle\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 200)\n%matplotlib inline\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","be54b90e":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","dc9d65bf":"train = pd.read_csv(\"..\/input\/ai-medical-contest-2020\/train.csv\")\nall_train_len = len(train)\ntest = pd.read_csv(\"..\/input\/ai-medical-contest-2020\/test.csv\")\nsub = pd.read_csv(\"..\/input\/ai-medical-contest-2020\/sample_submission.csv\")\n\nif DEBUG:\n    train = train[:1000]\n    test = test[:1000]\n    sub = sub[:1000]","45e8538f":"# \u65e5\u6642\u3092\u8868\u3059\u5217\u3092string\u578b\u304b\u3089datetime\u578b\u306b\u5909\u63db\nformat='%Y-%m-%d' # \u4e8c\u6b21\u5730\u8868\u793a\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8, \u4f8b) 2020-09-26\ncols_time = ['entry_date', 'date_symptoms']\nfor col in cols_time:\n    train[col] = pd.to_datetime(train[col],format=format)\n    test[col] = pd.to_datetime(test[col],format=format)","765bdc9f":"def onehot_encoding(train: pd.DataFrame, test: pd.DataFrame, encode_cols):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    for f in encode_cols:\n        try:\n            if f in not_nan_cols:\n                dummies = pd.get_dummies(train[f], dummy_na=False, dtype=np.uint8, prefix='OH_'+f)\n            else:\n                dummies = pd.get_dummies(train[f], dummy_na=True, dtype=np.uint8, prefix='OH_'+f)\n        except:\n            print(\"exception :\",f)\n        train = pd.concat([train,dummies], axis=1)\n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    return train, test","40492165":"def standardization(train: pd.DataFrame, test: pd.DataFrame, encode_cols):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    for f in encode_cols:\n        try:\n            \n            train[f].fillna(train[f].mean(),inplace=True) #\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3082\u5e73\u5747\u5024\u306b\u542b\u3081\u3061\u3083\u3046\u306e\u306f\u8b70\u8ad6\u306e\u4f59\u5730\u304c\u3042\u308b\n            \n        except:\n            print(\"exception :\",f)\n    lbl = preprocessing.StandardScaler()\n    train[encode_cols] = lbl.fit_transform(train[encode_cols])\n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    return train, test","d00a36bd":"#minmax\u306e\u65b9\u304c\u3044\u3044\u304b\u3082\uff1f\ndef date_transform(train: pd.DataFrame, test: pd.DataFrame, encode_cols):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    for f in encode_cols:\n        try:\n            train[f] = train[f].apply(lambda x: x.dayofyear).astype(np.uint16)\n            train[f].fillna(-1,inplace=True)\n        except:\n            print(\"exception :\",f)\n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    return train, test","569fb863":"#https:\/\/www.kaggle.com\/osciiart\/ai-medical-contest-2020-baseline\ndef osciiart_transform(train: pd.DataFrame, test: pd.DataFrame, encode_cols=None):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    \n    ######################################################################\n    #\u65e2\u306b\u5909\u5f62\u3057\u3066\u3042\u308b\u72b6\u614b\u3067\u518d\u73fe\u3092\u884c\u3046\u305f\u3081\u3001\u4e0a\u8a18Notebook\u3068\u540c\u3058\u5024\u306b\u306f\u306a\u3089\u306a\u3044\u3053\u3068\u306b\u6ce8\u610f#\n    ######################################################################\n    #\"age_x_entry_date\",\u5e74\u9f62\u3068\u5165\u9662\u65e5\u3092\u4e57\u7b97\n    age = train['age'].values\n    age = (age - age.mean()) \/ age.std() # \u5e74\u9f62\u3092\u6b63\u898f\u5316\n    entry_date = train['entry_date'].values\n    entry_date = (entry_date - entry_date.mean()) \/ entry_date.std() # \u5e74\u9f62\u3092\u6b63\u898f\u5316\n    train['age_x_entry_date'] = age * entry_date # \u5e74\u9f62\u3068\u5165\u9662\u65e5\u3092\u4e57\u7b97. 2\u3064\u306e\u5909\u6570\u306e\u76f8\u4e92\u4f5c\u7528\u3092\u8868\u73fe\u3067\u304d\u308b\n    \n    #\"mean_of_icu_of_each_entry_date\",\u5165\u9662\u65e5\u3054\u3068\u306eICU\u5165\u5ba4\u7387\n    col_groupby = 'entry_date' # \u30b0\u30eb\u30fc\u30d7\u5206\u3051\u306b\u7528\u3044\u308b\u5217\u540d\n    col_aggregate = 'icu' # \u7d71\u8a08\u91cf\u3092\u5f97\u308b\u7279\u5fb4\u91cf\n    df_tmp = copy.deepcopy(train[[col_groupby,col_aggregate]])\n    df_tmp[col_aggregate] = train[col_aggregate]==\"Yes\" # ICU\u306b\u5165\u3063\u305f\u304b\u3069\u3046\u304b\n    method = 'mean' # \u7d71\u8a08\u91cf\u306e\u7a2e\u985e\n    df_agg = df_tmp.groupby(col_groupby)[col_aggregate].agg(method).reset_index() # \u96c6\u7d04\u7279\u5fb4\u91cf\u3092\u5f97\u308b\n    col_new = 'mean_of_icu_of_each_entry_date' # \u7279\u5fb4\u91cf\u540d. \u5165\u9662\u65e5\u3054\u3068\u306eICU\u5165\u5ba4\u7387\n    df_agg.columns = [col_groupby, col_new]\n    df_tmp = pd.merge(df_tmp, df_agg, on=col_groupby, how='left')\n    train[col_new] = df_tmp[col_new]\n    \n    \n    #\"entry_-_symptom_date\",\u767a\u75c7\u304b\u3089\u5165\u9662\u307e\u3067\u306e\u65e5\u6570\n    train['entry_-_symptom_date'] = train['entry_date'] - train['date_symptoms'] # \u767a\u75c7\u304b\u3089\u5165\u9662\u307e\u3067\u306e\u65e5\u6570\n    \n    #\"entry_date_count\",\u5165\u9662\u65e5\u306b\u304a\u3051\u308b\u3001\u305d\u306e\u65e5\u306e\u5165\u9662\u60a3\u8005\u6570\n    res = copy.deepcopy(train[[\"patient_id\",\"entry_date\"]])\n    res2 = train.groupby('entry_date')[\"patient_id\"].agg(len).reset_index() # \u96c6\u7d04\u7279\u5fb4\u91cf\u3092\u5f97\u308b\n    res2.columns = ['entry_date','entry_date_count']\n    res = pd.merge(res,res2, on='entry_date', how='left').drop('entry_date', axis=1)\n    train['entry_date_count'] = res['entry_date_count']\n    ###\n    \n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    return train, test","af8547fc":"def only_fill_na(train: pd.DataFrame, test: pd.DataFrame, encode_cols):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    for f in encode_cols:\n        try:\n            train[f].fillna(-1,inplace=True)\n        except:\n            print(\"exception :\",f)\n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    return train, test","9257d870":"train_cols = [\n    \"place_patient_live2\", #477\u60a3\u8005\u306e\u4f4f\u6240(\u8a73\u7d30)\n    \"age\", #\u5e74\u9f62\n    \"place_hospital\", #33\u75c5\u9662\u306e\u6240\u5728\n    \"place_patient_birth\", #33\u60a3\u8005\u306e\u51fa\u8eab\u5730\n    \"type_hospital\", #14\u60a3\u8005\u304c\u6cbb\u7642\u3092\u53d7\u3051\u305f\u65bd\u8a2d\n    \"contact_other_covid\", #2\u4ed6\u306eCOVID\u60a3\u8005\u3068\u63a5\u89e6\u6b74\u304c\u3042\u308b\u304b\n    \"test_result\", #3 PF,result awaitedPRC\u691c\u67fb\u7d50\u679c\n    \"pneumonia\", #2 nan not in train\u80ba\u708e\n    \"place_patient_live\", #33\n    \"age_x_entry_date\", #\u5143\u30c7\u30fc\u30bf\u306b\u306a\u3044\u3002\u5e74\u9f62\u3068\u5165\u9662\u65e5\u3092\u4e57\u7b97\n    \"mean_of_icu_of_each_entry_date\", #\u5143\u30c7\u30fc\u30bf\u306b\u306a\u3044\u3002\u5165\u9662\u65e5\u3054\u3068\u306eICU\u5165\u5ba4\u7387\n    \"place_patient_live\", #33\u60a3\u8005\u306e\u4f4f\u6240(\u5927\u5225)\n    \"date_symptoms\", #\u767a\u75c7\u65e5\n    \"entry_date\", #\u5165\u9662\u65e5 (\u53d7\u8a3a\u65e5)\n    \"intubed\", #\u633f\u7ba1\n    \"patient_type\", #\u5165\u9662or\u5916\u6765\n    \"entry_-_symptom_date\", #\u5143\u30c7\u30fc\u30bf\u306b\u306a\u3044\u3002\u767a\u75c7\u304b\u3089\u5165\u9662\u307e\u3067\u306e\u65e5\u6570\n    \"entry_date_count\", #\u5143\u30c7\u30fc\u30bf\u306b\u306a\u3044\u3002\u5165\u9662\u65e5\u306b\u304a\u3051\u308b\u3001\u305d\u306e\u65e5\u306e\u5165\u9662\u60a3\u8005\u6570\n    \"chronic_renal_failure\", #\u6162\u6027\u814e\u4e0d\u5168\u306e\u6709\u7121\n    \"diabetes\", #\u7cd6\u5c3f\u75c5\u306e\u6709\u7121\n    \"icu\", #ICU\u3067\u6cbb\u7642\u3092\u53d7\u3051\u305f\u304b\n    \"obesity\", #\u80a5\u6e80\n    \"immunosuppression\", #\u514d\u75ab\u6291\u5236\n    \"sex\", #\u6027\u5225\n    \"other_disease\", #\u305d\u306e\u4ed6\u306e\u75be\u60a3\n    \"pregnancy\", #\u598a\u5a20\n    \"hypertension\", #\u9ad8\u8840\u5727\n    \"cardiovascular\", #\u5fc3\u8840\u7ba1\u75be\u60a3\n    \"asthma\", #\u305c\u3093\u305d\u304f\n    \"tobacco\", #\u55ab\u7159\n    \"copd\", #COPD\n\n\n]\n\nstandard_cols = [\n    \"age\",\n    \"entry_-_symptom_date\",\n    \"entry_date_count\",\n    \"date_symptoms\",\n    \"entry_date\",\n\n\n]\n\nonehot_cols = [\n    #\"place_patient_live2\",\n    \"place_hospital\", \n    \"place_patient_birth\", \n    \"type_hospital\", \n    \"contact_other_covid\", \n    \"test_result\", \n    \"pneumonia\", \n    \"place_patient_live\",\n    \"intubed\", \n    \"patient_type\", \n    \"chronic_renal_failure\", \n    \"diabetes\",\n    \"icu\",\n    \"obesity\",\n    \"immunosuppression\",\n    \"sex\",\n    \"other_disease\",\n    \"pregnancy\",\n    \"hypertension\",\n    \"cardiovascular\",\n    \"asthma\",\n    \"tobacco\",\n    \"copd\",\n\n]\n\n#onehot\u3067nan\u304c\u542b\u307e\u308c\u306a\u3044\u3082\u306e\nnot_nan_cols = (\n    \"place_hospital\",\n    \"type_hospital\",\n    \"test_result\",\n    \"place_patient_live\",\n    \"patient_type\",\n    \"sex\",\n)\n\n\ndate_cols = [\n    \"date_symptoms\",\n    \"entry_date\",\n\n]","7864ddd9":"train, test = onehot_encoding(train, test, onehot_cols)\ntrain, test = date_transform(train, test, date_cols)\ntrain, test = osciiart_transform(train, test)\ntrain, test = standardization(train, test, standard_cols)","46ddff9f":"#if \"place_patient_live2\" is te.\ntrain,test = only_fill_na(train, test,[\"place_patient_live2\"])","759c8a19":"categorical_features_OH = [] #onehotencoding\u3055\u308c\u305f\u30d0\u30a4\u30ca\u30ea\u5024\u306e\u5217\nfor i in onehot_cols:\n    for j in train[i].unique():\n        categorical_features_OH.append(\"OH_\"+i+\"_\"+str(j))","ef610960":"numerical_features = [\n    \"age\",\n    \"entry_-_symptom_date\",\n    \"entry_date_count\",\n    \"date_symptoms\",\n    \"entry_date\",\n]","32810bb0":"class CFG:\n    model_name = \"medcon2020_tachyon_baseline\"\n    Progress_Bar = False\n    max_grad_norm=1000\n    gradient_accumulation_steps=1\n    hidden_size=512\n    dropout=0.5\n    init_lr=1e-2\n    weight_decay=1e-6\n    batch_size=128\n    n_epochs=5 if DEBUG else 10\n    n_fold = 4\n    num_workers = 2\n    num_features=numerical_features\n    cat_features=categorical_features_OH\n    target_cols= \"died\"\n    model_save_path = False","f8c8e83c":"skf = StratifiedKFold(CFG.n_fold, shuffle=True, random_state=0)\ntrain['fold'] = -1\nfor i, (train_idx, valid_idx) in enumerate(skf.split(train, train[CFG.target_cols])):\n    train.loc[valid_idx, 'fold'] = i","565df31d":"class Medcon2020Dataset(Dataset):\n    def __init__(self, df, num_features = CFG.num_features, cat_features = CFG.cat_features, train=True,target_cols = CFG.target_cols):\n        if train:\n            self.cont_values = df[num_features].values\n            self.cate_values = df[cat_features].values\n            self.labels = df[target_cols].values\n        else:\n            self.cont_values = df[num_features].values\n            self.cate_values = df[cat_features].values\n        self.train = train\n        \n    def __getitem__(self, idx):\n        \n        if self.train:\n            cont_x = torch.FloatTensor(self.cont_values[idx])\n            cate_x = torch.FloatTensor(self.cate_values[idx])\n            #cate_x = torch.LongTensor(self.cate_values[idx])\n            y = torch.from_numpy(np.array(self.labels[idx]))\n            return cont_x, cate_x, y\n        else:\n            cont_x = torch.FloatTensor(self.cont_values[idx])\n            cate_x = torch.FloatTensor(self.cate_values[idx])\n            #cate_x = torch.LongTensor(self.cate_values[idx])\n            return cont_x, cate_x\n    \n    def __len__(self):\n        return len(self.cont_values)","9329e696":"class TabularNN(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.mlp = nn.Sequential(\n                          nn.Linear(len(cfg.num_features)+len(cfg.cat_features)+1, cfg.hidden_size),\n                          nn.BatchNorm1d(cfg.hidden_size),\n                          nn.Dropout(cfg.dropout),\n                          nn.PReLU(),\n                          nn.Linear(cfg.hidden_size, cfg.hidden_size),\n                          nn.BatchNorm1d(cfg.hidden_size),\n                          nn.Dropout(cfg.dropout),\n                          nn.PReLU(),\n                          nn.Linear(cfg.hidden_size,1),\n                          )\n\n    def forward(self, cont_x, cate_x):\n        # no use of cate_x yet\n        x = torch.cat((cont_x, cate_x), dim=1)\n        x = self.mlp(x)\n        return x","a98da442":"def training(model, iterator, optimizer, criterion, device):\n    \n    epoch_loss = 0\n    model.train()\n    bar = tqdm(iterator) if CFG.Progress_Bar else iterator\n    \n    for (cont_x,cate_x,y) in bar:\n        optimizer.zero_grad()\n        cont_x,cate_x,y = cont_x.to(device),cate_x.to(device),y.to(device)\n        y_pred = model(cont_x,cate_x)\n        loss = criterion(y_pred, y.unsqueeze(1))\n        loss.backward()\n        optimizer.step()\n        loss_np = loss.detach().cpu().numpy()\n        epoch_loss += loss_np\n        \n        if CFG.Progress_Bar:\n            bar.set_description('Training loss: %.5f' % (loss_np))\n        \n    return epoch_loss\/len(iterator)\n\ndef evaluate(model, iterator, criterion, device):\n    \n    epoch_loss = 0\n    preds = []\n    preds = np.array(preds)\n    targets = []\n    targets = np.array(targets)\n    model.eval()\n    bar = tqdm(iterator) if CFG.Progress_Bar else iterator\n    \n    with torch.no_grad():\n        \n        for (cont_x,cate_x,y) in bar:\n            cont_x,cate_x,y = cont_x.to(device),cate_x.to(device),y.to(device)\n            y_pred = model(cont_x,cate_x)\n            loss = criterion(y_pred, y.unsqueeze(1))\n            loss_np = loss.detach().cpu().numpy()\n            epoch_loss += loss_np\n            y_pred = torch.sigmoid(y_pred)\n            preds = np.append(preds, y_pred.detach().cpu().numpy())\n            targets = np.append(targets, y.detach().cpu().numpy())\n            \n            if CFG.Progress_Bar:\n                bar.set_description('Validation loss: %.5f' % (loss_np))\n                \n    val_acc = accuracy_score(targets, np.round(preds))\n    try:\n       val_roc = roc_auc_score(targets, preds)\n    except ValueError:\n       val_roc = -1\n    \n    return epoch_loss\/len(iterator),val_acc,val_roc","7555a9eb":"def fit_model(model, model_name, train_iterator, valid_iterator, optimizer, loss_criterion, device, epochs):\n    \"\"\" Fits a dataset to model\"\"\"\n    best_valid_loss = float('inf')\n    \n    train_losses = []\n    valid_losses = []\n    valid_roc_scores = []\n    \n    for epoch in range(epochs):\n        scheduler.step(epoch)\n    \n        train_loss = training(model, train_iterator, optimizer, loss_criterion, device)\n        valid_loss,valid_acc_score, valid_roc_score= evaluate(model, valid_iterator, loss_criterion, device)\n        \n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        valid_roc_scores.append(valid_roc_score)\n\n        if valid_loss <= best_valid_loss:\n            best_valid_loss = valid_loss\n            if CFG.model_save_path:\n                torch.save(model.state_dict(), os.path.join(model_save_path,f'{model_name}.pt'))\n            else:\n                torch.save(model.state_dict(), f'{model_name}_best.pt')\n            best_model = copy.deepcopy(model)\n        \n        #scheduler\u306e\u51e6\u7406 cosineannealing\u306f\u5225\n        #if scheduler != None:\n        #    scheduler.step(valid_loss)\n        \n        print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.4f} | Val. Loss: {valid_loss:.4f} ')\n        print(f'Val. ACC Score: {valid_acc_score:.3f} | Val. Metric Score: {valid_roc_score:.4f}')\n        #print(f'Val. Loss: {valid_loss:.3f} | Val. ACC Score: {valid_acc_score:.3f} | Val. Metric Score: {valid_roc_score:.4f}')\n        #print(f'lr:{optimizer.param_groups[0][\"lr\"]:.7f}')\n        if CFG.model_save_path:\n                torch.save(model.state_dict(), os.path.join(model_save_path,f'{model_name}_final.pt'))\n        else:\n            torch.save(model.state_dict(), f'{model_name}_final.pt')\n    \n    return train_losses, valid_losses, valid_roc_scores,best_model","f622e960":"tr_loss=[]\nval_loss=[]\nval_roc=[]\nmodels = []\nbest_models = []\nfor fold in range(1 if DEBUG else CFG.n_fold): #n_fold\n    print(f\"Fitting on Fold {fold+1}\")\n    #Make Train and Valid DataFrame from fold\n    train_fold = train[train['fold'] != fold].reset_index(drop=True)\n    valid_fold = train[train['fold'] == fold].reset_index(drop=True)\n    \n    #target encoding\n    target_E_cols = [\"place_patient_live2\"]\n    for col in target_E_cols:\n        train_fold[col + \"_te\"] = -1\n        valid_fold[col + \"_te\"] = -1\n        data_tmp = pd.DataFrame({col:train_fold[col],\"target\":train_fold[CFG.target_cols]})\n        target_mean = data_tmp.groupby(col)[\"target\"].mean() #\u5e73\u5747\u5024\u306e\u7b97\u51fa\n        valid_fold.loc[:,col + \"_te\"] = valid_fold[col].map(target_mean) #\u8a55\u4fa1\u7528\u2192train\u306e\u5e73\u5747\u3067\u683c\u7d0d\n        \n        #\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u5909\u63db\u5f8c\u306e\u5024\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\u3092\u6e96\u5099\n        tmp = np.repeat(np.nan,train_fold.shape[0]) #\u4ed6fold\u306b\u51fa\u3066\u3053\u306a\u3044\u5024\u304c\u3042\u308b\u3068nan\u306e\u307e\u307e\u306b\u306a\u308b\u306e\u3067\u30c7\u30d5\u30a9\u30670\u3092\u5165\u308c\u3068\u304f\u3057\u304b\u306a\u3044\u3002\n        \n        #target encoding\u306b\u304a\u3044\u3066\u3001\u81ea\u5206\u306e\u5024\u3092\u53c2\u7167\u3057\u3066\u306f\u3044\u3051\u306a\u3044\u306e\u3067\u3001\u66f4\u306bfold\u306b\u5206\u3051\u308b\n        kf_encoding = KFold(n_splits=4,shuffle=False)\n        for idx_1,idx_2 in kf_encoding.split(train_fold):\n            target_mean = data_tmp.iloc[idx_1].groupby(col)[\"target\"].mean()\n            tmp[idx_2] = train_fold[col].iloc[idx_2].map(target_mean)\n        \n        train_fold.loc[:,col + \"_te\"] = tmp \n    train_fold[\"place_patient_live2_te\"].fillna(0.,inplace=True) #\u4ed6fold\u306b\u51fa\u3066\u3053\u306a\u3044\u5024\u304c\u3042\u308b\u3068nan\u306e\u307e\u307e\u306b\u306a\u308b\u306e\u3067\u30c7\u30d5\u30a9\u30670\u3092\u5165\u308c\u3068\u304f\u3057\u304b\u306a\u3044\u3002\n    valid_fold[\"place_patient_live2_te\"].fillna(0.,inplace=True)\n    #Build and load Dataset\n    train_data = Medcon2020Dataset(train_fold,num_features = CFG.num_features + [\"place_patient_live2_te\"], cat_features = CFG.cat_features)\n    valid_data = Medcon2020Dataset(valid_fold,num_features = CFG.num_features + [\"place_patient_live2_te\"], cat_features = CFG.cat_features)\n    \n    train_iterator = DataLoader(train_data, shuffle=True, batch_size=CFG.batch_size, num_workers=CFG.num_workers)\n    valid_iterator = DataLoader(valid_data, shuffle=False, batch_size=CFG.batch_size, num_workers=CFG.num_workers)\n    \n    #Initialize model, loss and optimizer\n    model = TabularNN(CFG).to(device)\n    loss_criterion = nn.BCEWithLogitsLoss()\n    opt=optim.Adam(model.parameters(), lr=CFG.init_lr, betas=(0.9,0.999))\n    scheduler = CosineAnnealingLR(opt, CFG.n_epochs)\n    \n    name = CFG.model_name + \"_f\" + str(fold)\n    \n    temp_tr_loss, temp_val_loss,temp_val_roc,best_model = fit_model(model, name, train_iterator, valid_iterator, opt, loss_criterion, device, epochs=CFG.n_epochs)\n    \n    tr_loss.append(temp_tr_loss)\n    val_loss.append(temp_val_loss)\n    val_roc.append(temp_val_roc)\n    models.append(model)\n    best_models.append(best_model)","36834897":"for i in range(len(tr_loss)):\n    fig,ax = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\n    ax[0].plot(tr_loss[i])\n    ax[0].set_title('Training and Validation Loss')\n    ax[0].plot(val_loss[i])\n    ax[0].set_xlabel('Epoch')\n\n    ax[1].plot(val_roc[i])\n    ax[1].set_title('Val ROC Score')\n    ax[1].set_xlabel('Epoch')\n\n\n    ax[0].legend();\n    ax[1].legend();","ba9516dc":"#if target E\nfor col in target_E_cols:\n    test[col + \"_te\"] = -1\n    data_tmp = pd.DataFrame({col:train[col],\"target\":train[CFG.target_cols]})\n    target_mean = data_tmp.groupby(col)[\"target\"].mean() #\u5e73\u5747\u5024\u306e\u7b97\u51fa\n    test.loc[:,col + \"_te\"] = test[col].map(target_mean) #\u8a55\u4fa1\u7528\u2192train\u306e\u5e73\u5747\u3067\u683c\u7d0d\ntest[\"place_patient_live2_te\"].fillna(0.,inplace=True)","9d325bd3":"test_dataset = Medcon2020Dataset(test,num_features = CFG.num_features + [\"place_patient_live2_te\"], cat_features = CFG.cat_features,train=False)","e25eb372":"def get_predictions(model, iterator, device):\n    \n    preds = np.array([0.]*len(test))\n    model.eval()\n    bar = tqdm(iterator) if CFG.Progress_Bar else iterator\n    \n    with torch.no_grad():\n        res = np.array([])\n        for (cont_x,cate_x) in bar:\n            cont_x,cate_x = cont_x.to(device),cate_x.to(device)\n            y_pred = model(cont_x,cate_x)\n            y_pred = torch.sigmoid(y_pred)\n            res = np.append(res, y_pred.detach().cpu().numpy())\n\n        preds += res\n    return preds","ce7c71c8":"prediction = np.array([0.]*len(test))\nfor i in range(len(models)):\n    test_iterator = DataLoader(dataset=test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n    preds = get_predictions(models[i], test_iterator, device)\n    prediction += preds\nprediction \/= len(models)","d72e7466":"sub[CFG.target_cols] = prediction\nsub.to_csv('submission_final.csv', index=False)\nsub.head()","489f6cfa":"prediction = np.array([0.]*len(test))\nfor i in range(len(best_models)):\n    test_iterator = DataLoader(dataset=test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n    preds = get_predictions(best_models[i], test_iterator, device)\n    prediction += preds\nprediction \/= len(best_models)\nsub[CFG.target_cols] = prediction\nsub.to_csv('submission_best.csv', index=False)\nsub.head()","931c590c":"# train columns","674efce8":"# baseline  \nname : medcon2020_tachyon_baseline  \nabout : simple NN baseline  \nmodel : Liner Model  \nbatch : 128  \nepoch : 10  \ncriterion : BCEWithLogitsLoss  \noptimizer : Adam  \ninit_lr : 1e-2  \nscheduler: CosineAnnealingLR  \ndata : look train_cols  \npreprocess : OnehotEncoding,Standardization,Target Encoding  \ntrain_test_split : StratifiedKFold, k=4  ","706e7d75":"# Encoding Func  ","83c57dc3":"# Data Loading"}}