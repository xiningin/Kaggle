{"cell_type":{"4ee64591":"code","70a982c7":"code","3bf18434":"code","db681edf":"code","5f77381c":"code","fb8857a7":"code","4db6f25c":"code","0b671940":"code","0146c956":"code","68307c58":"code","8d697068":"code","a8ccf535":"code","117d7db2":"code","a761cb42":"code","0d9c7ecc":"code","8bb492c4":"code","92260640":"code","43559bb5":"code","da10fbcf":"code","3c6cc8e1":"code","35a66d3b":"code","9ead6528":"code","3aa74e5f":"code","9f94bc42":"code","fcf975ac":"code","23e84cd3":"code","79880492":"code","24410f0e":"code","34d84233":"code","56d27c27":"code","8a808a5f":"code","98c11250":"code","01096491":"code","9ccc9fdd":"code","de90c8aa":"code","07f6da67":"code","eee701d6":"code","9a4b0c23":"code","ef3e144b":"code","3c30d290":"code","1c974647":"code","9bbc34e3":"code","a7b3be85":"code","81de5de3":"code","0d7dec4b":"code","64502c60":"code","35951600":"code","4b9ddc88":"code","5b9fbd3f":"code","bdc6866d":"code","d25475a7":"markdown","5cde5168":"markdown","692b4b83":"markdown","13aa1bcb":"markdown","da75c50b":"markdown","b81b35e3":"markdown","e0d524aa":"markdown","5b7ce0dd":"markdown","37296eb4":"markdown","9adb75b5":"markdown","b94c732e":"markdown","8ed5e95f":"markdown","491394e6":"markdown","15a133f3":"markdown","430d2705":"markdown","71dea26b":"markdown"},"source":{"4ee64591":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","70a982c7":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings  \nwarnings.filterwarnings('ignore')","3bf18434":"#Reading the data\nUSAhousing = pd.read_csv('\/kaggle\/input\/usa-housing\/USA_Housing.csv')\nUSAhousing.head()","db681edf":"USAhousing.describe()","5f77381c":"USAhousing.info()","fb8857a7":"USAhousing.columns","4db6f25c":"X=USAhousing[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n       'Avg. Area Number of Bedrooms', 'Area Population']]\ny=USAhousing[['Price']]","0b671940":"sns.distplot(y)","0146c956":"sns.pairplot(USAhousing)","68307c58":"sns.heatmap(USAhousing.corr(),annot=True)","8d697068":"sns.boxplot(USAhousing['Price'])","a8ccf535":"from sklearn.model_selection import train_test_split \nimport statsmodels.api as sm \nfrom sklearn.linear_model import LinearRegression \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor \nfrom sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score \nfrom sklearn.model_selection import cross_val_score\nimport random","117d7db2":"def cross_val(model):\n    pred = cross_val_score(model, X, y, cv=10)\n    return pred.mean()\n\ndef print_evaluate(true, predicted):  \n    mae = mean_absolute_error(true, predicted)\n    mse = mean_squared_error(true, predicted)\n    rmse = np.sqrt(mean_squared_error(true, predicted))\n    r2_square = r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)\n    print('__________________________________')\n    \ndef evaluate(true, predicted):\n    mae = mean_absolute_error(true, predicted)\n    mse = mean_squared_error(true, predicted)\n    rmse = np.sqrt(mean_squared_error(true, predicted))\n    r2_square = r2_score(true, predicted)\n    return mae, mse, rmse, r2_square\ndef VIF(X):\n    vif=pd.DataFrame()\n    vif[\"Features\"]=X.columns\n    vif[\"VIF\"]=[variance_inflation_factor(X.values,i) for i in range(X.shape[1])]\n    vif[\"VIF\"]= round(vif[\"VIF\"], 2)\n    vif=vif.sort_values(by=\"VIF\",ascending=False)\n    print(vif)","a761cb42":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","0d9c7ecc":"from sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\n\nX_train1 = sc.fit_transform(X_train)\nX_test1  = sc.transform(X_test)\n\nX_train=pd.DataFrame(X_train1,columns=X_train.columns,index=X_train.index)\nX_test=pd.DataFrame(X_test1,columns=X_test.columns,index=X_test.index)","8bb492c4":"random.seed(0)\n\nX_train1=sm.add_constant(X_train)\n\nmodel1=sm.OLS(y_train,X_train1).fit()\n\nprint(model1.summary())","92260640":"VIF(X_train1)","43559bb5":"X_train2=X_train1.drop('Avg. Area Number of Bedrooms',axis=1)\n\nX_train2=sm.add_constant(X_train2)\n\nmodel2=sm.OLS(y_train,X_train2).fit()\n\nprint(model2.summary())","da10fbcf":"VIF(X_train2)","3c6cc8e1":"X_test1=X_test.drop('Avg. Area Number of Bedrooms',axis=1)\nX_test1=sm.add_constant(X_test1)\npred=model2.predict(X_test1)","35a66d3b":"print_evaluate(y_test,pred)","9ead6528":"plt.scatter(y_test,pred)","3aa74e5f":"sns.distplot((y_test['Price']-pred),bins=40)","9f94bc42":"X_train=X_train.drop('Avg. Area Number of Bedrooms',axis=1)\nX_test=X_test.drop('Avg. Area Number of Bedrooms',axis=1)","fcf975ac":"print(X_train.columns,X_test.columns)","23e84cd3":"lr=LinearRegression()\n\nlr.fit(X_train,y_train)","79880492":"test_pred = lr.predict(X_test)\ntrain_pred = lr.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","24410f0e":"results = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults","34d84233":"from sklearn.linear_model import RANSACRegressor\n\nmodel = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","56d27c27":"results_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults = results.append(results_2, ignore_index=True)\nresults","8a808a5f":"from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","98c11250":"results_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults = results.append(results_2, ignore_index=True)\nresults","01096491":"from sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=0.1, \n              precompute=True, \n#               warm_start=True, \n              positive=True, \n              selection='random',\n              random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","9ccc9fdd":"results_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults = results.append(results_2, ignore_index=True)\nresults","de90c8aa":"from sklearn.linear_model import ElasticNet\n\nmodel = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","07f6da67":"results_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults = results.append(results_2, ignore_index=True)\nresults","eee701d6":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_reg = PolynomialFeatures(degree=2)\n\nX_train_2_d = poly_reg.fit_transform(X_train)\nX_test_2_d = poly_reg.transform(X_test)\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train_2_d,y_train)\n\ntest_pred = lin_reg.predict(X_test_2_d)\ntrain_pred = lin_reg.predict(X_train_2_d)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","9a4b0c23":"results_2 = pd.DataFrame(data=[[\"Polynomail Regression\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults = results.append(results_2, ignore_index=True)\nresults","ef3e144b":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\nsgd_reg.fit(X_train, y_train)\n\ntest_pred = sgd_reg.predict(X_test)\ntrain_pred = sgd_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","3c30d290":"results_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults = results.append(results_2, ignore_index=True)\nresults","1c974647":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nmodel = Sequential()\n\nmodel.add(Dense(X_train.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer=Adam(0.00001), loss='mse')\n\nr = model.fit(X_train, y_train,\n              validation_data=(X_test,y_test),\n              batch_size=1,\n              epochs=100)","9bbc34e3":"plt.figure(figsize=(10, 6))\n\nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()","a7b3be85":"test_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","81de5de3":"results_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults = results.append(results_2, ignore_index=True)\nresults","0d7dec4b":"from sklearn.ensemble import RandomForestRegressor\n\nrf_reg = RandomForestRegressor(n_estimators=1000)\nrf_reg.fit(X_train, y_train)\n\ntest_pred = rf_reg.predict(X_test)\ntrain_pred = rf_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","64502c60":"results_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults = results.append(results_2, ignore_index=True)\nresults","35951600":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\nsvm_reg.fit(X_train, y_train)\n\ntest_pred = svm_reg.predict(X_test)\ntrain_pred = svm_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","4b9ddc88":"results_2 = pd.DataFrame(data=[[\"SVM Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults = results.append(results_2, ignore_index=True)\nresults","5b9fbd3f":"results.set_index('Model', inplace=True)\nresults['R2 Square'].plot(kind='barh', figsize=(12, 8))","bdc6866d":"results","d25475a7":"> P value of  'Avg. Area Number of Bedrooms' is above the threshold, drop it","5cde5168":"> Considering the threshold of p value as 0.05 and VIF of 5","692b4b83":"# **Support Vector Machine**","13aa1bcb":"# **Robust Regression** (Random Sample Consensus - RANSAC)","da75c50b":"> Apply Standard Scaler for better regression results","b81b35e3":"# **Stochastic Gradient Descent**","e0d524aa":"# **Artificial Neural Network**","5b7ce0dd":"# **Comparison of models**","37296eb4":"> No null values are present","9adb75b5":"# **Lasso Regression**","b94c732e":"* High p-value High VIF : Drop the variable \n* High p-value Low VIF : Drop the variable with high p-value \ufb01rst \n* Low p-value Low VIF : accept the variable\n","8ed5e95f":"# **Ridge Regression**","491394e6":"# **Random Forest Regressor**","15a133f3":"# **Polynomial Regression**","430d2705":"# **ElasticNet**","71dea26b":"# **Linear Regression**"}}