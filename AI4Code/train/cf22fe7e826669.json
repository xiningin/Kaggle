{"cell_type":{"b85addb0":"code","540e7593":"code","06743199":"code","55d9bc11":"code","793d5e26":"code","47744045":"code","6af21e14":"code","0104c9bd":"code","996d7afd":"code","0b36dfb7":"code","86cde185":"code","39048fe9":"markdown","4589e949":"markdown","0162fd2f":"markdown","38b70866":"markdown","f3bb7332":"markdown"},"source":{"b85addb0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","540e7593":"import sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn.feature_extraction.text import TfidfVectorizer","06743199":"Data_bobot = [\n    'Darussalam Gontor University Has an Informatics Engineering Study Program',\n    'Informatics Engineering Students Must Have a Laptop or Computer',\n    'Laptop or computer is a requirement to attend lectures'\n]","55d9bc11":"vectorizer = CountVectorizer()\nvectorized_x = vectorizer.fit_transform(Data_bobot).todense()\nvectorized_x","793d5e26":"vectorizer.get_feature_names()","47744045":"data = pd.DataFrame(vectorized_x,\n                   index = [f'Teks-{i+1}' for i in range(len(Data_bobot))],\n                   columns = vectorizer.get_feature_names())\n\ndata","6af21e14":"for i in range(len(vectorized_x)):\n    for j in range(i,len(vectorized_x)):\n        if i == j:\n            continue\n            jarak = euclidean_distances(vectorized_x[i],vectorized_x[j])\n            print(f'Jarak Teks {i+1} dan {j+1} : {jarak}')","0104c9bd":"vectorizer = TfidfVectorizer(stop_words='english')\nresponse = vectorizer.fit_transform(Data_bobot)\nprint(response)","996d7afd":"vectorizer.get_feature_names()","0b36dfb7":"response.todense()","86cde185":"Data = pd.DataFrame(response.todense().T,\n                   index = vectorizer.get_feature_names(),\n                   columns = [f'Teks{i+1}' for i in range(len(Data_bobot))])\n\nData","39048fe9":"# Model Bag Of Words (BOW)","4589e949":"# Term Frequency - Invers Document Frequency (Tf-Idf)","0162fd2f":"# SEKIAN","38b70866":"> Dataset yang digunakan :","f3bb7332":"> Library Yang Digunakan"}}