{"cell_type":{"c2db6a87":"code","1afb3b42":"code","251da542":"code","545502db":"code","31a0ee46":"code","94a4fcbd":"code","d87608c7":"code","05e905ba":"code","b1ee4c74":"code","d7484aa3":"code","5fd11316":"code","84b78559":"code","b4553e9e":"code","1aa131e3":"code","25ae1236":"code","28a009e5":"code","52441897":"code","f8dcc258":"code","364af9d3":"code","6b94d06f":"code","e66639da":"code","6f39de16":"code","5e6048e5":"code","8b430217":"code","33f31eb3":"code","63dd15d0":"code","bb523335":"code","1a45247b":"code","5eed72b8":"code","464ea181":"markdown"},"source":{"c2db6a87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1afb3b42":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","251da542":"#read the dataset\ndf = pd.read_csv(\"..\/input\/classified-data\/Classified Data\", index_col=0)","545502db":"df.head()","31a0ee46":"df.shape","94a4fcbd":"df.info()","d87608c7":"df.describe()","05e905ba":"from sklearn.preprocessing import StandardScaler","b1ee4c74":"scaler = StandardScaler()","d7484aa3":"scaler.fit(df.drop('TARGET CLASS', axis=1))","5fd11316":"scaled_features = scaler.transform(df.drop('TARGET CLASS', axis=1))","84b78559":"df_transform = pd.DataFrame(scaled_features, columns=df.columns[:-1])","b4553e9e":"df_transform.head()","1aa131e3":"#pair plot\n\nsns.pairplot(df, hue='TARGET CLASS')","25ae1236":"#data splitting","28a009e5":"from sklearn.model_selection import train_test_split","52441897":"X_train, X_test, y_train, y_test = train_test_split(scaled_features, df['TARGET CLASS'], test_size=0.25)","f8dcc258":"#Using KNN","364af9d3":"from sklearn.neighbors import KNeighborsClassifier","6b94d06f":"knn = KNeighborsClassifier(n_neighbors=1)","e66639da":"knn.fit(X_train, y_train)","6f39de16":"pred = knn.predict(X_test)","5e6048e5":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_val_score","8b430217":"print(confusion_matrix(y_test, pred))","33f31eb3":"print(classification_report(y_test, pred))","63dd15d0":"accuracy_rate = []\nfor i in range(1,25):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    score = cross_val_score(knn, df_transform, df['TARGET CLASS'], cv=10)\n    accuracy_rate.append(score.mean())","bb523335":"error_rate = []\nfor i in range(1,25):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    score = cross_val_score(knn, df_transform, df['TARGET CLASS'], cv=10)\n    error_rate.append(1-score.mean())","1a45247b":"error_rate = []\nfor i in range(1,25):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","5eed72b8":"plt.figure(figsize=(10,6))\nplt.plot(range(1,25), accuracy_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","464ea181":"**choosing a best k-values**"}}