{"cell_type":{"c3885ac1":"code","a5b852b4":"code","0d054a10":"code","5625f197":"code","83aadf51":"code","6a26d220":"code","3232d5a6":"code","313ed528":"code","6a26f9c0":"code","446d035e":"code","fee3d706":"code","6859846d":"code","9df7d599":"code","720542bc":"code","6c413a6e":"code","d3b57e1e":"code","fb2e611b":"code","06488352":"code","a5f7cf45":"code","aea7c329":"code","908e4180":"code","bfb1752a":"code","84e21867":"code","b06909cb":"code","7c8d69d4":"code","785da806":"code","09fe1940":"code","1c80399b":"code","5874ea47":"code","b46acf0b":"code","b875360f":"code","5f812380":"code","0fa86165":"code","01dc1893":"code","79b3762c":"code","c5cdd903":"code","8ba8c81d":"code","d4ad6c94":"code","b243c146":"code","99172718":"code","be3e6ed3":"code","3ad3171f":"code","c371ebbf":"code","10c54b94":"code","701c93e9":"markdown","3afea0ad":"markdown","fd9afac9":"markdown","f5881038":"markdown","43591eaf":"markdown","051637a3":"markdown","da61a8cc":"markdown","78a5e011":"markdown","f1fe3447":"markdown","aa588fe3":"markdown","050841e6":"markdown","238a4f49":"markdown","01947e5b":"markdown","f619f8e0":"markdown","f82f482b":"markdown","192b9a10":"markdown","4170e863":"markdown","98a38507":"markdown","3fdde5bf":"markdown","d5c39055":"markdown","1c35257b":"markdown","bbb0dd79":"markdown","febc9684":"markdown","75f7d99b":"markdown","8bc20330":"markdown","b2c38a3b":"markdown","a61ea2d3":"markdown","d6094e77":"markdown","be22dc13":"markdown","90dabdd0":"markdown","c3f0ca40":"markdown","4f45f736":"markdown","effbb4af":"markdown","12b8a892":"markdown","8487efac":"markdown","85f5f1cb":"markdown","0ff1447a":"markdown","ee5d3239":"markdown","47006e36":"markdown","889f5288":"markdown","45990df9":"markdown","f557fb48":"markdown","6fae9ab9":"markdown","8e34725f":"markdown","698c64ea":"markdown","110cf8a4":"markdown","5b5bbfb3":"markdown","6a8d6b2d":"markdown","61ae501e":"markdown","474e999e":"markdown","7a22a668":"markdown","fd5dc4be":"markdown","6ddc7927":"markdown","e39b0285":"markdown"},"source":{"c3885ac1":"import os\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n        \n# Reading in the csv for the given sets.\ntrain_set = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/train.csv\")\neval_set = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/eval.csv\")","a5b852b4":"# Looking at a few observations of the train set.\ntrain_set","0d054a10":"print(train_set.dtypes)","5625f197":"# Looking at a few observations of the eval set.\neval_set","83aadf51":"print(eval_set.dtypes)","6a26d220":"# Viewing some common metrics for each of the features of the train set.\ntrain_set.describe()","3232d5a6":"# Viewing some common metrics for each of the features of the eval set.\neval_set.describe()","313ed528":"# A simple print statement that lists the columns in the train set.\nprint(train_set.columns)","6a26f9c0":"# Creating a plot that shows the ESRB Rating of Games and the counts for each.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating')\nplt.title('How All Games Were Rated')\nplt.show()","446d035e":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Blood'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='blood', palette='PuOr_r')\nplt.title('Games That Do\/Don\\'t Have Blood And Their Rating')\nplt.show()","fee3d706":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Blood And Gore'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='blood_and_gore', palette='PuOr_r')\nplt.title('Games That Do\/Don\\'t Have Blood\/Gore And Their Rating')\nplt.show()","6859846d":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Profanity'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='language', palette='GnBu')\nplt.title('Games That Do\/Don\\'t Have Profanity And Their Rating')\nplt.show()","9df7d599":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Strong Sexual Content'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='strong_sexual_content', palette='PiYG')\nplt.title('Games That Do\/Don\\'t Have Strong Sexual Content And Their Rating')\nplt.show()","720542bc":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Use of Drugs and Alcohol'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='use_of_drugs_and_alcohol', palette='Paired')\nplt.title('Games That Do\/Don\\'t Use Drugs&Alcohol And Their Rating')\nplt.show()","6c413a6e":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Intense Violence'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='violence', palette='RdPu')\nplt.title('Games That Do\/Don\\'t Have Violence And Their Rating')\nplt.show()","d3b57e1e":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Intense Violence'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='intense_violence', palette='PRGn_r')\nplt.title('Games That Do\/Don\\'t Have Intense Violence And Their Rating')\nplt.show()","fb2e611b":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Simulated Gambling'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='simulated_gambling', palette='BrBG')\nplt.title('Games That Do\/Don\\'t Have Simulated Gambling And Their Rating')\nplt.show()","06488352":"# Creating a plot that shows the ESRB Rating of Games and their value for 'Console'.\nsns.set()\nsns.countplot(data=train_set, x='esrb_rating', hue='console', palette='gist_rainbow_r')\nplt.legend(labels=['PS4', 'PS4 & Xbox One'])\nplt.title('The Available Platform Of Games And Their Rating')\nplt.show()","a5f7cf45":"# Seeing exactly how much missing data we're dealing\n# with in the train set.\nprint(train_set.shape)\nprint(train_set.isnull().sum())","aea7c329":"# Excluding the columns that are not categorical, as they will most definitely have more unique values, but we are not concerned with them.\ntrain_features = train_set.drop(['id', 'title', 'esrb_rating'], axis=1)\nprint('Unique values in all categorical columns.')\nfor col in train_features :\n    print(train_set[col].unique(), col)","908e4180":"train_set_mod = train_set.drop(['id', 'title', 'console'], axis=1)\neval_set_mod = eval_set.drop(['id', 'console'], axis=1)","bfb1752a":"# Helper libaries\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# The four models I will train\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","84e21867":"# Prepare data to feed into models.\nX = train_set_mod.drop('esrb_rating', axis=1)\ny = train_set_mod['esrb_rating']\nZ = eval_set_mod","b06909cb":"# Train Test Split to split the data we feed into the model, while keeping some to test after.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, stratify=y)","7c8d69d4":"# Making the models we will pass into our Grid Search.\nlr = LogisticRegression()\nsvm = SVC()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\nknn = KNeighborsClassifier()","785da806":"lr_params = {'penalty':['l2', 'l1'], 'solver':['liblinear', 'saga']}\nsvm_params = {'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\ndt_params = {'criterion':['gini', 'entropy'], 'splitter':['best', 'random'], 'max_depth':range(5, 30, 5)}\nrf_params = {'criterion':['gini', 'entropy'], 'max_depth':range(10,50,10), 'min_samples_leaf':range(5,20,5), 'n_estimators':range(100,1000,300)}\nknn_params = {'weights':['uniform', 'distance'], 'algorithm':['ball_tree', 'kd_tree'], 'leaf_size':range(10, 20, 5), 'p':[1, 2], 'n_neighbors':range(5,20,5)}\n\n# Storing the parameters into a list which will be iterated through in a for loop for Grid Search below.\nmodel_params = [lr_params, svm_params, dt_params, rf_params, knn_params]","09fe1940":"lr_gs = GridSearchCV(estimator=lr, param_grid=lr_params, scoring='accuracy', cv=4, n_jobs=-1, refit=True).fit(X_train, y_train)","1c80399b":"svm_gs = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=4, n_jobs=-1, refit=True).fit(X_train, y_train)","5874ea47":"dt_gs = GridSearchCV(estimator=dt, param_grid=dt_params, scoring='accuracy', cv=4, n_jobs=-1, refit=True).fit(X_train, y_train)","b46acf0b":"rf_gs = GridSearchCV(estimator=rf, param_grid=rf_params, scoring='accuracy', cv=4, n_jobs=-1, refit=True).fit(X_train, y_train)","b875360f":"knn_gs = GridSearchCV(estimator=knn, param_grid=knn_params, scoring='accuracy', cv=4, n_jobs=-1, refit=True).fit(X_train, y_train)","5f812380":"lr_scores = cross_val_score(lr_gs.best_estimator_, X, y, scoring='accuracy', cv=50)\nsvm_scores = cross_val_score(svm_gs.best_estimator_, X, y, scoring='accuracy', cv=50)\ndt_scores = cross_val_score(dt_gs.best_estimator_, X, y, scoring='accuracy', cv=50)\nrf_scores = cross_val_score(rf_gs.best_estimator_, X, y, scoring='accuracy', cv=50)\nknn_scores = cross_val_score(knn_gs.best_estimator_, X, y, scoring='accuracy',cv=50)\n\nlr_scores = pd.DataFrame(lr_scores)\nsvm_scores = pd.DataFrame(svm_scores)\ndt_scores = pd.DataFrame(dt_scores)\nrf_scores = pd.DataFrame(rf_scores)\nknn_scores = pd.DataFrame(knn_scores)","0fa86165":"sns.set()\nplt.hist(lr_scores)\nplt.title('Logistic Regression Accuracy Scores')\nplt.show()","01dc1893":"lr_scores.describe()","79b3762c":"sns.set()\nplt.hist(svm_scores)\nplt.title('SVM Accuracy Scores')\nplt.show()","c5cdd903":"svm_scores.describe()","8ba8c81d":"sns.set()\nplt.hist(dt_scores)\nplt.title('Decision Tree Accuracy Scores')\nplt.show()","d4ad6c94":"dt_scores.describe()","b243c146":"sns.set()\nplt.hist(rf_scores)\nplt.title('Random Forest Accuracy Scores')\nplt.show()","99172718":"rf_scores.describe()","be3e6ed3":"sns.set()\nplt.hist(knn_scores)\nplt.title('K-Nearest Neighbors Accuracy Scores')\nplt.show()","3ad3171f":"knn_scores.describe()","c371ebbf":"chosen_model = lr_gs.best_estimator_","10c54b94":"best_pred = chosen_model.predict(Z)\noutput = pd.DataFrame({'id': eval_set['id'], 'esrb_rating': best_pred})\nprint(output.to_string())\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","701c93e9":"Placing my train set (without target) into X, and placing target values into y. Placing my eval set into Z.\n\nI do this just to keep it consistent with how I learned in the datacamps.","3afea0ad":"-----\n# **Evaluating The Models**","fd9afac9":"***[2 point] You must build and train a Logistic Regression model on the training data and evaluate its performance on a set of validation data***","f5881038":"----","43591eaf":"No mismatch of datatypes for the eval set, which probably means we will not have to do too many transformations later.","051637a3":"Verifying another intuitive thought: Profanity! We know that profanity is generally something we do not want children hearing when playing games, and so it would follow that games on the lower side ('E', 'ET') would not have profanity in them.\n\nWait a second, there's a few observations in 'ET' that have profanity! That probably is not a mistake; 'ET' really is meant for ages 10 and up, and while I personally wouldn't want a child of mine hearing curse words at 10, I guess this rating system allows it. Most likely the 'profanity' in the 'ET' rated games are mild if anything (or you would hope).\n\nWe can safely say that games rated 'E' will have no profanity, and we would hope to observe the same thing in our predictions we make off the model we build.","da61a8cc":"As we suspected, only in games rated 'T' or higher do we begin to see observations that contain blood and gore. This dataset looks pretty reliable!","78a5e011":"# Selecting The Model\n\n***[2 points] You must select the best model that you have generated and use that model to predict the target vector for the test data.***\n\nI am opting for Logistic Regression over the other models. My reasoning behind this being the best choice is that, when you look at the distributions, the shape is the closest looking to normal as you can get. Even in repeated instances of me running my notebook, the Logistic Regression model looked the most consistent. While it does not have the best accuracy when compared to models like SVM, DT, and KNN (which could be because the other models may be overfitting), I think the Logistic Regression model is a happy medium that will work.\n","f1fe3447":"We will now do some minor data transformation.\n\nThe only real transformation that needs to be done is dropping the unnecessary columns such as the 'id', 'title', and 'console' columns. Simply put, the 'id' and 'title' columns are only used in the data to separate one observation from the other. As for dropping 'console', it feels like a feature that would not be a useful factor to make note about. The plot for that column showed a similar idea.\n\n***[2 point] You must describe any data transformations or feature engineering that are required and provide an explanation as to \"why\" each is being done.***","aa588fe3":"Gambling is something that you would not want children to fall into the habit of doing. Thankfully, the game ratings have (sort of) reflected this. I'm of the opinion that gambling is something that teens shouldn't even be exposed to, but it looks like there are some instances of simulated gambling in 'T' rated games.\n\n**Nevertheless, we have some features that may be useful in predicting what a game is rated. We could continue and investigate more individual features and how the games were rated, but for the most part the plots we've created indicate that the dataset is not too faulty and knows the way to rate games based on the characteristics of each game.**","050841e6":"----","238a4f49":"The first thing to do when cleaning the data is to see if there are any missing values.\n\n***[2 point] You must check for missing values within the training data and, if required, describe and implement an approach to handle those missing values.***","01947e5b":"Now that we have optimal parameters for our models thanks to grid search, we can now perform several fits of the data with the models and visualize the distribution of accuracy scores.","f619f8e0":"So as someone who has a general idea of some of the characteristics going into game ratings, I wanted to check if the dataset was consistent with my thoughts, that is, that games containing any blood would not be rated any lower than 'T'.\n\nAs we can see from the plot, notice how there are no observations in 'E' or 'ET' that have blood (otherwise there would be an orange bar for those ratings). It makes sense: being that 'E' and 'ET' games are meant for the young audience, these games would not want to include any sort of bloody imagery.\n\nI see there's a similarly described feature called 'blood_and_gore'; One would assume the trend just noted would follow here. Let's take a look.","f82f482b":"As we can see from the output of the print statement, the categorical features all obey the structure of being represented by either a 0 or 1.\n\nI believe there are no real outliers with the data provided to us in the dataset. All observations fall within the acceptable values for each column, and the plots done above also do not show any outstanding outliers.\n\nThat being said, it is good we checked for outliers as they could end up biasing our model if we tried building a model with them included.","192b9a10":"***[2 point] You must build and train a Random Forest model on the training data and evaluate its performance on a set of validation data***","4170e863":"-------------\n# **Building The Models (and some imports)**","98a38507":"***[2 point] You must build and train a K Nearest Neighbors model on the training data and evaluate its performance on a set of validation data***","3fdde5bf":"Now that we can see all the columns, it looks like all are represented in int64, aside from the 'title' and 'esrb_rating' columns, which make sense.","d5c39055":"-----","1c35257b":"# Feature Engineering\/Data Transformations","bbb0dd79":"--------","febc9684":"In order to do Grid Search, I need to instantiate the models we are making.","75f7d99b":"-----------\n# Cleaning The Data","8bc20330":"As with the train set's describe() output, the eval set looks to have the same idea in terms of features (categorical so 0\/1 range). \n\nWhile the tables are nice to view the actual numbers, I will now be producing some graphs of the data so we can visually represent the data.","b2c38a3b":"# Evaluating KNN Model\n\nThe KNN Model looks to not really have a normal distribution, being that there are some dips between certain accuracy scores (like between 0.75 and 0.85 and 0.85 and 0.90), but the mean accuracy score looks to be just as high as the others (matching SVM and DT). The minimum score is the highest out of the all the models we've looked at. The higher accuracy could also be an indicator that the model may overfit the training set.\n\nDue to the gaps in the distribution, which could just be one-off instances or unlucky, I probably will not opt for this model.","a61ea2d3":"I started by looking at both the train_set and eval_set's head() methods to quickly see if I can begin to understand the data we're working with.","d6094e77":"# Evaluating Logistic Regression\n\nLooking at the accuracy scores for Logistic Regression model, we have a pretty nice distribution for the most part, with the average score being around 0.82. 80% accuracy is good to see, and The minimum score observed by this model is a 0.69, which is not too bad! I would consider this model a pretty decent predictor.\n\nLet's look at the other models first before we make a final decision!","be22dc13":"# Evaluating Random Forest Model\n\nThe Random Forest Model is quite intriguing. There seems to be two 'peaks' in the graph, which is not really a tendency you see in a normal distribution. The average accuracy score closely matches the Logistic Regression Model. Another thing to note is that the minimum for this distribution is the lowest out of the bunch, likewise the max being the lowest as well. The higher accuracy could also be an indicator that the model may overfit the training set.\n\nI would probably not opt for this one just as it seems either the model may be biased or not reliable.","90dabdd0":"***[2 point] You must build and train a Decision Tree model on the training data and evaluate its performance on a set of validation data***","c3f0ca40":"# Checking for Missing Data","4f45f736":"I find this plot to be very intriguing. I would have thought that the use of drugs and alcohol in a game would almost certainly restrict its rating to 'M'. However, not only does it look like that is not the case, but the most games with use of drugs and alcohol are in the 'T' category. Even worse, there is a few games in 'E' that indicate the use of drugs and alcohol! \n\nI am disheartened slightly. I know the amount of observances where drugs & alcohol is low to begin with, but come on. Legally speaking, it is illegal to possess drugs below the age of 18. For that reason, I would hope the content in games for that audience would not feature the idea at all.","effbb4af":"What a nice sight to see! None of the data seems to be missing any values, and so we have no need to drop\/impute rows with missing data.\n\nI will now check for outliers by looking at the unique values for each categorical feature in the train set. We should expect to only see two values to represent the columns: 0 or 1.\n\n***[2 point] You must check for outliers within the training data and, if required, describe and implement an approach to handle those outliers.***","12b8a892":"-----","8487efac":"This is somewhat relieving. As the graph depicts, we do not see any observations rated 'E' or 'ET' that include violence. \n\nWell, since the 'violence' category and 'intense violence' categories are representing similar ideas, we would expect their plots to be similar.\n\nLet's investigate this.","85f5f1cb":"First I wanted to get an idea of how many observations for each rating we had in the train set. \n\nLooks like the 'T' rated games are the most abundant of them all, but we have a similar number of observations for the 'E' , 'ET', and 'M' rated games. The abundance of 'T' observations may give the model some bias towards rating games that, but I will likely try building a model off all the data first, then shift if needed.","0ff1447a":"I am glad to see here that strong sexual content is restricted to 'M' or 'Mature' rated games.\n\nWe are beginning to see some strong indicators of games and how they'd be rated. We know now that if a game has strong sexual content, it will always be rated 'M', going off the dataset.","ee5d3239":"From the looks of it, we have plenty of categorical columns to describe some characteristics of each game in the train set.","47006e36":"***[2 point] You must build and train an Support Vector Machine on the training data and evaluate its performance on a set of validation data***","889f5288":"-----------------------\n# **Conducting Exploratory Data Analysis**","45990df9":"The metrics are a good sight to see! Being that all the features in the set are categorical, it makes sense the min and max do not surpass 0 or 1, respectively. ","f557fb48":"Now this is a surprise. Indeed, games in 'T' and 'M' rating have observations that include violence in the game, but why is there some observations in 'ET' that have INTENSE violence?\n\nThe provided descriptions for each column have this to save for 'Intense Violence': *Graphic and realistic-looking depictions of physical conflict. May involve extreme and\/or realistic blood, gore, weapons, and depictions of human injury and death.*\n\nSince 'ET' is rated for children 10 and up, this would mean some children would be seeing this in their games they play. That is not okay!\n\nWhat's worse, is that there were no games in 'ET' that had violence at all, but with INTENSE violence they allow it? Could be unreliability we might have to address when we clean the data.","6fae9ab9":"# **Generating Submission**","8e34725f":"Making the param grids for each of the models, for which we will feed one into a respective Grid Search of that model.","698c64ea":"# Evaluating SVM Model\n\nLooking at the graph shows a not as clean distribution (there's a slight gap between 0.70 and the rest of the scores). On the other hand, the average accuracy for the SVM model is a 0.86, which is slightly higher than the Logistic Regression Model. The higher accuracy could also be an indicator that the model may overfit the training set.\n\nMinimum score is around the same. I am slightly perplexed about the gap, unsure what could cause such a thing. \n\nI was also kind of not thoroughly testing on my hyperparameters, but I would say if I could tune this model a bit, I would see a better distribution.","110cf8a4":"# Evaluating Decision Tree Model\n\nThe Decision Tree Model certainly has the most rectangular sjape out of the ones so far, but again looks to follow an almost normal distribution. Average accuracy is higher than the Logistic Regression but just barely loses to the SVM model. For the third time now, the minimum score is around the same as the others. The higher accuracy could also be an indicator that the model may overfit the training set.\n\nOnce again, we have a pretty decent model we could use, but let's continue.","5b5bbfb3":"Aside from that, I posit that there are no other columns that needed to be dropped and\/or created.\n\nNow that we've restricted our dataset to only the useful measures, we will build our models.","6a8d6b2d":"# **Loading The Data (and some imports)**\nTo begin my work, I import a few packages to aid me with overall code, which will allow me to conduct some EDA shortly :)\n\n***[2 point] You must load the data from the provided CSV files.***","61ae501e":"Likewise, the eval set also houses plenty columns, all of which seem to be categorical. \n\nSo from the looks of it, we're provided two sets of games with their respective categorical features. Furthermore, after some inspection in Excel of the sets, I was able to confirm that every column (aside from the Name, ID, and ESRB Rating which is the target). As such, it seems our job will be predicting the ESRB rating of the games in the eval set using the features we're provided.\n\nLet's have a look at some measures for each of the features we're working with.","474e999e":"------------","7a22a668":"Using cross val score to generate distribution plots for each of the models.","fd5dc4be":"Here are all the columns provided to us in the train set. Let's look at a few observation features of games and see how they were rated.","6ddc7927":"This last plot for EDA I wanted to bring attention to is a look at all consoles' platforms and how they were rated.\n\nNow, don't be alarmed. There's nothing really to gather from this plot. We see each rating has observations of both types. No real trends like we saw in the other plots, and that's because the type of console the game is on generally does not indicate how the game would be rated.\n\nI just wanted to plot it to be sure that console did not effect the rating of the games. I will likely be dropping this column when I clean the data.\n\nNow that we've looked at some plots of the data, I feel that I have a general idea of how the model might want to predict given some features.\n","e39b0285":"# Checking for Outliers"}}