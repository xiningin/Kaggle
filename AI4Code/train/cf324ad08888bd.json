{"cell_type":{"d50309ee":"code","fbbed185":"code","efead4e5":"code","6776fa80":"code","612814f6":"code","62034ffc":"code","0e374f40":"code","621fbb83":"code","4f0bb666":"code","fcd0553e":"code","4a5b9d30":"code","e0d3f2eb":"markdown","9766a431":"markdown","5fb5aa85":"markdown","4c03c467":"markdown","4df6439c":"markdown","0a63fe87":"markdown","a3391916":"markdown","10149151":"markdown","f42c256e":"markdown","69076f2e":"markdown","32026276":"markdown"},"source":{"d50309ee":"import math\nimport pickle\nimport statistics\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as tt\nimport imgaug\n\nfrom collections import defaultdict\nfrom typing import Type, List, Union\n\nfrom imgaug import augmenters as iaa\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm.notebook import tqdm, trange\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler, OneCycleLR\nfrom torch.utils.data import DataLoader, Dataset\n\nimport cifar100_resnets as models","fbbed185":"class CIFAR100(Dataset):\n    \n    def __init__(self, dataset_path: Path, image_transforms: tt.Compose, image_augmentations: Union[None, Type[iaa.Augmenter]] = None):\n        super().__init__()\n        data = pickle.load(dataset_path.open(\"rb\"), encoding=\"bytes\")\n        self.images = data[b\"data\"]\n        self.labels = data[b\"fine_labels\"]\n        \n        self.image_transforms = image_transforms\n        self.image_augmentations = image_augmentations\n        \n        assert len(self.images) == len(self.labels), \"Number of images and labels is not equal!\"\n        \n    def __len__(self) -> int:\n        return len(self.images)\n    \n    def __getitem__(self, index: int) -> tuple:\n        image = self.images[index]\n        label = self.labels[index]\n        \n        image = np.reshape(image, (3, 32, 32))\n        image = np.transpose(image, (1, 2, 0))\n        \n        if self.image_augmentations is not None:\n            image = self.image_augmentations.augment_image(image)\n        image = self.image_transforms(Image.fromarray(image))\n        return image, label\n    \n\nimage_transformations = tt.Compose([\n    tt.ToTensor(),\n    tt.Normalize(\n        mean=(0.5074, 0.4867, 0.4411),\n        std=(0.2011, 0.1987, 0.2025)\n    )\n])\n\ntrain_augmentations = iaa.Sequential([\n    iaa.Fliplr(0.5),\n    iaa.CropAndPad(px=(-4, 4), pad_mode=\"reflect\")\n])\n\n\nclass CIFAR100Net(nn.Module):\n    \n    def __init__(self, model_type: str = \"resnet18\", temperature: int = 1):\n        super().__init__()\n        model_class = getattr(models, model_type)\n        self.feature_extractor = model_class(num_classes=100)\n        self.temperature = temperature\n        \n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        activations = self.feature_extractor(images)\n        return activations \/ self.temperature\n\n    \ndef accuracy(predictions: torch.Tensor, labels: torch.Tensor, reduce_mean: bool = True) -> torch.Tensor:\n    predicted_classes = torch.argmax(F.softmax(predictions, dim=1), dim=1)\n    correct_predictions = torch.sum(predicted_classes == labels)\n    if reduce_mean:\n        return correct_predictions \/ len(labels)\n    return correct_predictions\n\n\ndef test_model(network: Type[nn.Module], data_loader: DataLoader) -> float:\n    num_correct_predictions = 0\n    device = get_device()\n    \n    for images, labels in data_loader:\n        images = to_device(images, device)\n        labels = to_device(labels, device)\n        predictions = network(images)\n        num_correct_predictions += float(accuracy(predictions, labels, reduce_mean=False).item())\n        \n    return num_correct_predictions \/ len(data_loader.dataset)\n\n\ndef get_device() -> torch.device:\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    return torch.device(\"cpu\")\n\n\ndef to_device(data: torch.Tensor, device: torch.device) -> torch.Tensor:\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device)\n\n\ndef plot_metrics(metrics: dict):\n    # we prepare the plotting by creating a set of axes for plotting, we want to put each metric in its own plot in a separate row\n    # furthermore, all plots should share the same x-axis values\n    fig, axes = plt.subplots(math.ceil(len(metrics) \/ 2), 2, sharex=True, figsize=(20, 20))\n\n    # we want to have a set of distinct colors for each logged metric\n    colors = iter(plt.cm.rainbow(np.linspace(0, 1, len(metrics))))\n    \n    # create the actual plot\n    for (metric_name, metric_values), axis in zip(metrics.items(), axes.flatten()):\n        iterations = []\n        values = []\n        for logged_value in metric_values:\n            iterations.append(logged_value[\"iteration\"])\n            values.append(logged_value[\"value\"])\n        axis.plot(iterations, values, label=metric_name, color=next(colors))\n        axis.legend()\n    plt.show()\n\n\nBATCH_SIZE = 128\ntrain_dataset = CIFAR100(Path(\"\/kaggle\/input\/cifar100\/train\"), image_transformations, train_augmentations)\ntrain_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\ntest_dataset = CIFAR100(Path(\"\/kaggle\/input\/cifar100\/test\"), image_transformations)\ntest_data_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)","efead4e5":"# TODO:\n# define `teacher_model` as a ResNet with 56 layers based on CIFAR100Net\n# define `student_model` as a ResNet with 20 layers based on CIFAR100Net\n# TASK START - Start coding here:\nraise NotImplementedError()\n# TASK END","6776fa80":"# TODO: initialize the correct loss functions\n# 1. teacher_loss_function should contain a PyTorch function for the Cross Entropy loss\n# 2. a) student_loss_function should contain a PyTorch implementation of the Kullback-Leibler divergence loss\n#    b) make sure, the mean of the student loss is calculated over the batch dimension only - not over all dimensions\n#    c) check out the documentation of the Kullback-Leibler divergence loss particularly about\n#       whether the inputs expect probabilities or log-probabilities\n# TASK START - Start coding here:\nraise NotImplementedError()\n# TASK END","612814f6":"def train_for_one_iteration(networks: List[Type[nn.Module]], batch: tuple, optimizers: List[Type[Optimizer]]) -> dict:\n    images, labels = batch\n    teacher_network, student_network = networks\n\n    # TODO: do the forward pass and loss calculation for the *teacher* network:\n    # 1. pass the images through the `teacher_network`, store the result (the predictions) in `teacher_predictions`\n    # 2. calculate the `teacher_loss` with the `teacher_loss_function` based on the `teacher_predictions` and the labels\n    # TASK START - Start coding here:\n    raise NotImplementedError()\n    # TASK END\n\n    # TODO: do the forward pass and loss calculation for the *student* network:\n    # 1. pass the images through the `student_network`, store the result (the predictions) in `student_predictions`\n    # 2. calculate the cross entropy loss `student_ce_loss` with the `teacher_loss_function` based on the `student_predictions` and the labels\n    # 3. calculate the knowledge distillaion loss `student_kd_loss` based on:\n    #    1) the softmax of our `student_predictions` calculated on the label axis (dim 1)\n    #    2) the softmax of our `teacher_predictions` calculated on the label axis (dim 1)\n    #    HINT: check whether you need to include the regular or the logarithmic softmax for each one (refer to the documentation of the loss function)\n    # 4. disable gradient calculation of the teacher in the previous step:\n    #    add `.detach()` to `teacher_predictions`, which forwards the outputs but disables backpropagation\n    # 5. add up both losses (`student_ce_loss` and `student_kd_loss`) as the `student_loss`\n    # TASK START - Start coding here:\n    raise NotImplementedError()\n    # TASK END\n\n    # calculate the accuracy of both predictions\n    teacher_accuracy = accuracy(teacher_predictions, labels)\n    student_accuracy = accuracy(student_predictions, labels)\n    \n    # Here come the real weight adjustments, first zero gradients, then calculate derivatives, followed by the actual update of the optimizer\n    for loss, optimizer in zip([teacher_loss, student_loss], optimizers):\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    return {\n        \"teacher_loss\": float(teacher_loss.item()),\n        \"teacher_train_acc\": float(teacher_accuracy.item()),\n        \"student_loss\": float(student_loss.item()),\n        \"student_train_acc\": float(student_accuracy.item()),\n    }","62034ffc":"def train(train_data: DataLoader, test_data: DataLoader, networks: List[Type[nn.Module]], optimizers: List[Type[Optimizer]], \\\n          lr_schedulers: List[Type[_LRScheduler]], num_epochs: int, update_lr_scheduler_each_iteration: bool = True) -> dict:\n    device = get_device()\n    # we save all metrics that we want to plot later on\n    metrics = defaultdict(list)\n    \n    for epoch in trange(num_epochs, desc=\"Epoch: \"):\n        losses = defaultdict(list)\n        \n        with tqdm(total=len(train_data), desc=\"Iteration: \") as progress_bar:\n            for iteration, batch in enumerate(train_data):\n                current_iteration = epoch * len(train_data) + iteration\n                \n                batch = to_device(batch, device)\n                calculated_losses = train_for_one_iteration(networks, batch, optimizers)\n                \n                for loss_name, loss_value in calculated_losses.items():\n                    losses[loss_name].append(loss_value)\n                    metrics[loss_name].append({\"iteration\": current_iteration, \"value\": loss_value})\n                # postfix_data is used to display current metrics in the progress bar\n                postfix_data = {name: f\"{value:.2f}\" for name, value in calculated_losses.items()}\n                \n                current_learning_rate = lr_schedulers[0].get_last_lr()[0]\n                postfix_data[\"lr\"] = f\"{current_learning_rate:.6f}\"\n                metrics[\"lr\"].append({\"iteration\": current_iteration, \"value\": current_learning_rate})\n                \n                progress_bar.set_postfix(postfix_data)\n                progress_bar.update()\n                \n                if update_lr_scheduler_each_iteration:\n                    for scheduler in lr_schedulers:\n                        scheduler.step()\n\n            progress_bar.set_description_str(\"Testing: \")\n            accuracies = {}\n            for metric_name,network in zip([\"teacher_acc\", \"student_acc\"], networks):\n                accuracy = test_model(network, test_data)\n                accuracies[f\"{metric_name}\"] = f\"{accuracy:.2f}\"\n                metrics[metric_name].append({\"iteration\": (epoch + 1) * len(train_data), \"value\": accuracy})\n\n            progress_bar.set_description_str(f\"Epoch: {epoch}\")\n            postfix_data = {name: f\"{statistics.mean(loss):.2f}\" for name, loss in losses.items()}\n            postfix_data.update()\n            postfix_data.update(accuracies)\n            progress_bar.set_postfix(postfix_data)\n            progress_bar.update()\n            \n            if not update_lr_scheduler_each_iteration:\n                    for scheduler in lr_schedulers:\n                        scheduler.step()\n    \n    return metrics","0e374f40":"learning_rate = 0.01\nnum_epochs = 50\n\nteacher_model = teacher_model.to(get_device())\nstudent_model = student_model.to(get_device())\n\nteacher_optimizer = torch.optim.Adam(teacher_model.parameters(), lr=learning_rate)\nstudent_optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n\nnum_iterations = num_epochs * (len(train_dataset) \/ BATCH_SIZE)\nteacher_scheduler = OneCycleLR(teacher_optimizer, learning_rate, epochs=num_epochs, steps_per_epoch=len(train_data_loader))\nstudent_scheduler = OneCycleLR(student_optimizer, learning_rate, epochs=num_epochs, steps_per_epoch=len(train_data_loader))\n\n# we are done with all setup and can start the training\nlogged_metrics = train(\n    train_data_loader,\n    test_data_loader,\n    [teacher_model, student_model],\n    [teacher_optimizer, student_optimizer],\n    [teacher_scheduler, student_scheduler],\n    num_epochs\n)","621fbb83":"plot_metrics(logged_metrics)","4f0bb666":"# try to import the library we need for calculating the number of operations\n# (if we can not import it, we need to install it)\ntry:\n    import torchinfo\nexcept ImportError:\n    !pip install torchinfo\n    import torchinfo\n# if you get the warning \"Failed to establish a new connection\", go to the side bar on the right, then \"Settings\" and switch on \"Internet\"","fcd0553e":"from torchinfo import summary\n\nbatch_size = 1\nprint(summary(teacher_model, input_size=(batch_size, 3, 32, 32)))","4a5b9d30":"print(summary(student_model, input_size=(batch_size, 3, 32, 32)))","e0d3f2eb":"Building the networks was simple.\nNow, we need to adapt the training loop from last week.\n\n# Task 2: Adapt our Training Code\n\nYou can reuse most parts of the training loop but we have to make the following changes:\n\n1. Since we are now handling two networks at the same time, we have to adopt our code to use two networks and also two optimizers (they should be given as parameters to the `train` function).\n1. We have to adapt our `train_for_one_iteration` function. Here, we need to forward the batch through both networks, then we calculate the losses:\n  1. the loss for the teacher network using the hard labels\n  1. the loss for the student network using the soft labels (the kullback leibler divergence or cross entropy of the softmax outputs of both networks) + the hard labels ([HINT](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.Tensor.detach.html): make sure to disallow the flow of gradients to the teacher network when using the softmax outputs of the teacher network)\n1. following the loss calculations, we need to run the backward passes for both networks and run the weight updates using the optimizers\n1. we can then return the losses of both networks\n\n## Task 2a: Initialize the Loss Functions\n\nFirst we should initialize our two loss functions:","9766a431":"## Plotting of Progress\n\nAs in the last exercise, we can now plot the train progress using the `plot_metrics` function:","5fb5aa85":"## Task 2b: Adapt the Training Logic\n\nThen we can adapt our training logic for a single batch:","4c03c467":"In the following cell, we added the code for data loading:","4df6439c":"# Knowledge Distillation\n\nIn knowledge distillation, our aim is to distill the knowledge of a large model into a smaller model.\nWe can do this in two ways:\n1. Train the large and the small model at the same time. Here, we train the large model only on the hard labels provided by the dataset. We train the small model using the soft labels provided by the large model.\n1. Train the large model first, then train the small models based on the outputs of the large model.\n\nWe will try to train both models at the same time.\nHowever, we highly encourage you to also try the other way, where we first train a larger model and then a smaller model!\n\nTo run the training, we need to perform the following steps:\n1. build two networks (a large and a smaller one)\n1. adapt the training code from last week to use two networks and also perform the correct loss calculations\n\n# Task 1: Building the Networks\n\nWe will start with the creation of the networks, which should be fairly simple.\nHave a look at the `CIFAR100Net` class above and figure out how you can use that class to build a `resnet56` and a `resnet20` model.\nNote that the variable `models` was imported in our first code cell, from the included [utility scripts](https:\/\/www.kaggle.com\/bartzi\/cifar100-resnets).\nWe will use the `resnet56` model as the teacher model and the `resnet20` model as the student.","0a63fe87":"# Performing Knowledge Distillation on CIFAR-100 using PyTorch\n\nThis is the third practical exercise of our course [Applied Edge AI](https:\/\/learn.ki-campus.org\/courses\/edgeai-hpi2022).\nIn the last exercise, we trained a neural network for image classification on CIFAR-100 using PyTorch.\nIn this exercise, we want to use the network we trained in the last exercise and distill the knowledge of that network into a smaller network.\n\nSimilarly to the previous exercise, we provide you with a notebook with missing code sections.\nIn the graded quiz at the end of the week, we might ask some questions that deal with this exercise, so make sure to do the exercise (and have your output handy) **before** taking the quiz!\n\n# Reusing Code\n\nIn the last exercise, we wrote quite some code that can be reused here.\nWe already added all of this code in the following cells.\nThere is nothing you need to do, since you already wrote such code in the last exercise.\n\nWe start with the imports:","a3391916":"## What Now?\n\nSimilar to the last week, you should keep in mind what you just did in this exercise, as we will ask about the implementation in the graded test.\nSince there was not too much coding required so far, we hope you are wondering, what else there is to do?\nSo we have prepared some suggestions:\n\nYou could also test different training optimizations and try to get the best performance out of your student model.\nIf you already developed a few improvements in the last week, you should try to use it in this week as well.\nAs you may have noticed we already include the learning rate scheduler [OneCycleLR](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.optim.lr_scheduler.OneCycleLR.html) in this week's code.\nMaybe you can try to find another scheduling that performs better or integrate improvements from the previous week?\n\nAnother interesting experiment might be to compare the performance of the model trained this week (with Knowledge Distillation) and the model from last week.\nTo do this, go back to the previous exercise and compare the accuracies.\nYou can also adapt the code above and train the student model completely independent of the teacher model.\nTo do so, you should first train the teacher individually, and then use it to train the student network.\n\nNow you can compare the accuracy to the ResNet-56 and the ResNet-20 that was achieved with simultaneous training.\nWhich models are performing better and why?\n\nAnother interesting question is, how much computation (during inference) you can save when you are using the ResNet-20 with distilled knowledge.\nTo see this, we can calculate the number of operations of each network using the [torchinfo](https:\/\/github.com\/TylerYep\/torchinfo) package and the following code:","10149151":"## Teacher Model Summary\n\nAfter installing torchinfo, we can now print the summary of our teacher model:","f42c256e":"We have already adapted the final `train` function for training both the student and the teacher:","69076f2e":"## Student Model Summary\n\nAnd compare that to our student model (which should be much smaller):","32026276":"Now, we just need to perform the last setup steps and then start the training. \\O\/\n\nBefore starting the training below, you should enable the GPU acclerator in the sidebar on the right (you can open the sidebar by clicking on the |< Symbol in the top right, then select *Settings*, *Accelerator*, *GPU*).\n\nIf you have not done so at the beginning of working on this exercise (which is fine), this means the other cells need to be run again.\nTo do so, you can select *Run All* in the top toolbar.\nThe notebook should run most of the previous cells very quickly until the training below is executed."}}