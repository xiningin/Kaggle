{"cell_type":{"8ae34a44":"code","eb1e6270":"code","5b322a8a":"code","f78370e7":"code","3eaf8cb6":"code","2a1d7b33":"code","9564207d":"code","fcf1d6c8":"code","f5cdb5d0":"code","6cb75946":"code","8209dfd5":"code","e9e0aa9b":"code","3bad75c0":"code","6f4a0a0e":"code","5a568478":"code","534854f7":"code","57f1647e":"code","febd29ff":"code","00918fc9":"code","459e6a4e":"code","bdf18702":"code","1cbd8104":"code","f9eb2494":"code","75efee65":"code","63b08c2f":"markdown","c6271047":"markdown","ab552e60":"markdown"},"source":{"8ae34a44":"import numpy as np # linear algebra\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport shutil","eb1e6270":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\nsample = pd.read_csv('..\/input\/shopee-product-matching\/sample_submission.csv')","5b322a8a":"import os\nimport json\nimport math\nfrom tqdm import tqdm \n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom keras import layers, optimizers\nfrom keras.applications import MobileNetV2\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Model\n\nimport keras.backend as K\nfrom keras.models import Sequential\nimport cv2\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.applications import imagenet_utils\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nimport numpy as np\nfrom IPython.display import Image\nfrom keras.optimizers import Adam","f78370e7":"generator = ImageDataGenerator(\n    rescale = 1.\/255,\n    validation_split=0.2,\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=True,  # randomly flip images\n    preprocessing_function=tf.keras.applications.resnet.preprocess_input\n    )\ntestgenerator = ImageDataGenerator(rescale = 1.\/255)\ntarget_size = [224, 224]\nbatch_size = 32\ntrain_dir='..\/input\/test1\/kaggle\/working\/class\/'\ntrain_gen = generator.flow_from_directory(train_dir,\n target_size = target_size,\n batch_size = batch_size,\n shuffle=True,\n class_mode = 'categorical',                                        \n subset='training')\n\nval_gen = generator.flow_from_directory(train_dir,\n target_size = target_size,\n batch_size = batch_size,\n shuffle=True,\n class_mode = 'categorical',                                        \n subset='validation')","3eaf8cb6":"# base_model=MobileNet(weights='imagenet',include_top=False,input_shape=(224,224,3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n\n# x=base_model.output\n# x=GlobalAveragePooling2D()(x)\n# x=Dense(224,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n# x=Dense(224,activation='relu')(x) #dense layer 2\n# x=Dense(128,activation='relu')(x) #dense layer 3\n# preds=Dense(11014,activation='softmax')(x) #final layer with softmax activation\n\n# model=Model(inputs=base_model.input,outputs=preds)","2a1d7b33":"# model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['AUC'])","9564207d":"def load_image(img_path, show=False):\n\n    img = image.load_img(img_path, target_size=(224, 224))\n    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n    img_tensor \/= 255.                                      # imshow expects values in the range [0, 1]\n\n\n    return img_tensor\n\n    \nimg_path = '..\/input\/shopee-product-matching\/test_images'\n\n#tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\nposting_id=test['posting_id'].tolist()\n# print(sample_sub)\n\nlabels = (train_gen.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npreds=[]\n\nmodel=tf.keras.models.load_model('..\/input\/model-10e\/my_test1_model.h5')\nfor test_image in test['image']:\n        #predicted_class_indices=[]\n        testimg=load_image(os.path.join(img_path,test_image))\n        preds.append(model.predict(testimg))\nlabel_group=[]        \nfor pred in preds:\n    predicted_class_indices=np.argmax(pred,axis=1)\n    predictions = [labels[k] for k in predicted_class_indices]    \n    label_group.append(predictions)    \nprint(label_group)\n\nsample_sub = pd.DataFrame(posting_id, columns=['posting_id'])\nsample_sub = pd.concat([sample_sub, pd.DataFrame(label_group,columns=['label_group'])],axis=1)\n\n \n\n        \n# sample_sub['matches']=sample_sub.label_group.map(tmp)\nsample_sub.head()","fcf1d6c8":"train.head()","f5cdb5d0":"t=load_image('..\/input\/shopee-product-matching\/train_images\/0000a68812bc7e98c42888dfb1c07da0.jpg')\nx=model.predict(t)","6cb75946":"tp=np.argmax(x,axis=1)\npredict = [labels[k] for k in tp]  ","8209dfd5":"predict","e9e0aa9b":"sample_sub['label_group']=pd.DataFrame(sample_sub['label_group'],dtype=np.int)","3bad75c0":"tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\nsample_sub['matches']=sample_sub.label_group.map(tmp)\n\nsample_sub.head()","6f4a0a0e":"tmp2 = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['pred_phash']=test.image_phash.map(tmp2)\ntest","5a568478":"submission=sample_sub.drop(['label_group'], axis=1)\nsubmission","534854f7":"for i in range(len(submission['matches'])):\n    submission['matches'][i]=submission['matches'][i].tolist()","57f1647e":"submission['matches']","febd29ff":"for i in range(len(submission['posting_id'])):\n    submission['matches'][i].append(test['posting_id'][i])","00918fc9":"def clean(x):\n    return \" \".join(x)\nsubmission['matches']=submission.matches.map(clean)\nsubmission","459e6a4e":"type(sample['matches'])","bdf18702":"sample.info()","1cbd8104":"submission.info()","f9eb2494":"type(submission['matches'])","75efee65":"submission.to_csv('submission.csv', index=False)","63b08c2f":"**TFIDF***","c6271047":"**imagephash**","ab552e60":"**CNN***"}}