{"cell_type":{"612f05d1":"code","20f436ab":"code","bbf7917c":"code","46313cd2":"code","70a61bd3":"code","79699bc7":"code","c76bd209":"code","4e40e6b2":"code","0c5cc88e":"code","2262420a":"code","3e44e1ef":"code","5914bda9":"code","4da99039":"code","06593b45":"markdown","d4aad880":"markdown","00ecc60b":"markdown","fd7713d3":"markdown","0920b706":"markdown","b8c668bd":"markdown","be8a0b53":"markdown","3636a081":"markdown","9dd146a9":"markdown","493503a1":"markdown","fc260ced":"markdown","aecebe71":"markdown","d124cee8":"markdown","15ff773c":"markdown","ab94ef86":"markdown","e72a869e":"markdown","1b44b48b":"markdown","09200876":"markdown","9a9fd6a6":"markdown","74952029":"markdown","b684c567":"markdown","5db4a78e":"markdown","363d0bc8":"markdown"},"source":{"612f05d1":"%%HTML\n<style type=\"text\/css\">\ndiv.h1 { background-color:#b300b3;\n        color: white; padding: 8px; padding-right: 300px;font-size: 35px; max-width: 1500px; margin: auto; margin-top: 50px; }\ndiv.h2 {background-color:#b300b3;\n        color: white; padding: 8px; padding-right: 300px; font-size: 25px; max-width: 1500px; margin: auto; margin-top: 50px; }\ndiv.h3 { color:#b300b3;\n        font-size: 16px; margin-top: 20px; margin-bottom:4px; }\nhr {display: block; color: gray; height: 1px; border: 0; border-top: 1px solid; }\nhr.light {display: block; color: lightgray; height: 1px; border: 0; border-top: 1px solid; }\n<\/style>","20f436ab":"import numpy as np\nimport pandas as pd\n\nfrom scipy.stats import boxcox_normmax\nfrom scipy.special import boxcox1p\nfrom sklearn.linear_model import LinearRegression","bbf7917c":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","46313cd2":"# Read the data\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","70a61bd3":"y = train.SalePrice.reset_index(drop=True)\nfeatures = train\nend_features = ['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath','TotRmsAbvGrd','MSSubClass','MSZoning']\nfeatures = features[end_features]\nfeatures['MSSubClass'] = features['MSSubClass'].apply(str)\nfeatures['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\nobjects = [col for col in features.columns if features[col].dtype == \"object\"]\nfeatures.update(features[objects].fillna('None'))\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = [col for col in features.columns if features[col].dtype in numeric_dtypes]\nfeatures.update(features[numerics].fillna(0))\n\nfor i in numerics:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))\nX = pd.get_dummies(features).reset_index(drop=True)\n#----------------- The model\nreg = LinearRegression().fit(X, y)\ny_pred = reg.predict(X)","79699bc7":"reg = LinearRegression().fit(X, y)\ny_pred = reg.predict(X)","c76bd209":"def MAE(predict,target):\n    return (abs(predict-target)).mean()\n\nfrom sklearn.metrics import mean_absolute_error\nprint ('MAE: ' + str(mean_absolute_error(y,y_pred)) )","4e40e6b2":"from sklearn.metrics import mean_squared_error\nprint ('MSE: ' + str(mean_squared_error(y,y_pred)) )","0c5cc88e":"def rmsle(predict, target):\n    return np.sqrt(((predict - target) ** 2).mean())\nprint ('RMSE: ' + str(rmsle(y_pred,y)) )","2262420a":"def MAPE(predict,target):\n    return ( abs((target - predict) \/ target).mean()) * 100\nprint ('MAPE: ' + str(MAPE(y_pred,y)) )","3e44e1ef":"def R2(predict, target):\n    return 1 - (MAE(predict,target) \/ MAE(target.mean(),target))\ndef R_SQR(predict, target):\n    r2 = R2(predict,target)\n    return np.sqrt(r2)\nprint ('R2         : ' + str(R2(y_pred,y)) )\nprint ('R          : ' + str(R_SQR(y_pred,y)) )","5914bda9":"def R2_ADJ(predict, target, k):\n    r2 = R2(predict,target)\n    n = len(target)\n    return (1 -  ( (1-r2) *  ( (n-1) \/ (n-(k+1)) ) ) )\n\nk= len(features.columns)\nprint ('R2 adjusted: ' + str(R2_ADJ(y_pred,y,k)) )","4da99039":"def rss_score(y, y_pred):\n    return np.sum((y - y_pred)**2)\nrss = rss_score(y, y_pred) \nprint ('Residual Sum of Squares (RSS): ' + str( rss ) )","06593b45":"# <div class=\"h3\">R\u00b2 and R-Squared: Coefficient of determination<\/div>\n\n<a id=\"m5\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)\n\n","d4aad880":"The residual sum of squares is the top term in the  R2  metric (albeit adjusted by 1 to account for degrees of freedom). It takes the distance between observed and predicted values (the residuals), squares them, and sums them all together. Ordinary least squares regression is designed to minimize exactly this value.\n\nRSS=\u22110n\u22121(yi\u2212y^i)2\n \nRSS is not very interpretable on its own, because it is the sum of many (potentially very large) residuals. For this reason it is rarely used as a metric, but because it is so important to regression, it's often included in statistical fit assays.","00ecc60b":"![](https:\/\/miro.medium.com\/max\/1063\/0*N8USfmlDmXq7YuNy.png)\n> Measure of prediction accuracy of a forecasting method in statistics, for example in trend estimation, also used as a loss function for regression problems in machine learning. It usually expresses accuracy as a percentage.","fd7713d3":"# <div class=\"h3\">Adjusted R\u00b2<\/div>\n<a id=\"m5\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)","0920b706":"Read the data","b8c668bd":"![](https:\/\/miro.medium.com\/max\/1189\/0*sA9a9MlNiZ1dI7so.jpg)\n\n> MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It\u2019s the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.","be8a0b53":"# <div class=\"h3\">RMSE: Root mean square error<\/div>\n<a id=\"m3\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)","3636a081":"# <div class=\"h3\">MAE: Mean absolute error<\/div>\n<a id=\"m1\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)","9dd146a9":"# <div class=\"h3\">MSE: Mean squared error<\/div>\n<a id=\"m2\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)","493503a1":"![](https:\/\/miro.medium.com\/max\/955\/0*1jxDmwoJF8R4tOVq.png)\nsource: http:\/\/www.haghish.com\/statistics\/stata-blog\/stata-programming\/adjusted_R_squared.php\n\n> A model performing equal to baseline would give R-Squared as 0. Better the model, higher the r2 value. The best model with all correct predictions would give R-Squared as 1. However, on adding new features to the model, the R-Squared value either increases or remains the same. R-Squared does not penalize for adding features that add no value to the model. So an improved version over the R-Squared is the adjusted R-Squared.\n","fc260ced":"# <div class=\"h1\">Regression metrics summary <\/div>\n<a id=\"M\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)\n\n![](https:\/\/miro.medium.com\/max\/1308\/1*lke9jk2uY-ppHO0h0xytQw.png)","aecebe71":"![](https:\/\/miro.medium.com\/max\/888\/0*-lBX506Imc6Hjqpu)\n\n> R\u00b2 and R-Squared help us to know how good our regression model as compared to a very simple model that just predicts the mean value of target from the train set as predictions.\n","d124cee8":"[Back to Table of Contents](#top)\n\n<a class=\"anchor\" id=\"theend\"><\/a>\n# Final","15ff773c":"Refer: \n- [Metrics and Python](https:\/\/towardsdatascience.com\/metrics-and-python-850b60710e0c)\n- [Understanding Regression Error Metrics](https:\/\/www.dataquest.io\/blog\/understanding-regression-error-metrics\/)\n- [The Absolute Best Way to Measure Forecast Accuracy](https:\/\/www.axsiumgroup.com\/the-absolute-best-way-to-measure-forecast-accuracy-2\/)\n","ab94ef86":"[Crisl\u00e2nio Mac\u00eado](https:\/\/medium.com\/sapere-aude-tech) -  March, 13th, 2020\n\n<div class=\"h1\">Understanding Regression Error Metrics in Python\ud83d\udc0d<\/div>\n\n- [**Github**](https:\/\/github.com\/crislanio)\n- [**Linkedin**](https:\/\/www.linkedin.com\/in\/crislanio\/)\n- [**Medium**](https:\/\/medium.com\/sapere-aude-tech)\n- [**Quora**](https:\/\/www.quora.com\/profile\/Crislanio)\n- [**Hackerrank**](https:\/\/www.hackerrank.com\/crislanio_ufc?hr_r=1)\n- [**Blog**](https:\/\/medium.com\/@crislanio.ufc)\n- [**Personal Page**](https:\/\/crislanio.wordpress.com\/about)\n- [**Twitter**](https:\/\/twitter.com\/crs_macedo)\n","e72a869e":"\n![](https:\/\/miro.medium.com\/max\/650\/0*at-j68ROeSmiruDE.png)\nsource: https:\/\/www.includehelp.com\/ml-ai\/root-mean-square%20error-rmse.aspx\n> RMSE is a quadratic scoring rule that also measures the average magnitude of the error. It\u2019s the square root of the average of squared differences between prediction and actual observation.","1b44b48b":"# <div class=\"h3\">MAPE: Mean absolute percentage error<\/div>\n<a id=\"m4\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)","09200876":"The model","9a9fd6a6":"<a class=\"anchor\" id=\"top\"><\/a>\n<a id='dsf4'><\/a>\n# <div class=\"h2\">  Table of contents<\/div>\n1. [Imports](#IMPORT)\n2. [Regression metrics summary ](#M)\n   -  <a href='#m1'>MAE<\/a>\n   -  <a href='#m2'>MSE<\/a>\n   -  <a href='#m3'>RMSE<\/a>\n   -  <a href='#m4'>MAPE<\/a>\n   -  <a href='#m5'>RMLSE<\/a>\n   -  <a href='#m6'>R-Square<\/a>   \n   -  <a href='#m6'>Ajusted R-Square<\/a>\n   -  <a href='#m7'>Residual Sum of Squares (RSS)<\/a>\n   \n  <hr>","74952029":"# <div class=\"h1\">Imports <\/div>\n<a id=\"IMPORT\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)\n\nWe are using a stack: ``numpy``, ``pandas``, ``sklearn``, ``matplotlib``.","b684c567":"Style of the data","5db4a78e":"![](https:\/\/miro.medium.com\/max\/978\/0*7RxO773DPeY8IYeD.png)\nsource: https:\/\/www.geeksforgeeks.org\/ml-mathematical-explanation-of-rmse-and-r-squared-error\/\n\n> MSE is a risk function, corresponding to the expected value of the squared error loss. The fact that MSE is almost always strictly positive (and not zero) is because of randomness or because the estimator does not account for information that could produce a more accurate estimate. The MSE is a measure of the quality of an estimator \u2014 it is always non-negative, and values closer to zero are better","363d0bc8":"# <div class=\"h3\">Residual Sum of Squares (RSS)<\/div>\n<a id=\"m6\"><\/a>\n[Back to Table of Contents](#top)\n\n[The End](#theend)"}}