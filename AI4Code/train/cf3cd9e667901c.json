{"cell_type":{"780544cf":"code","c3097543":"code","2eb51534":"code","9161c7bb":"code","8e09d7d2":"code","ed2927e2":"code","44ac99fe":"code","c4b9c6ed":"code","712e2974":"code","b3d96425":"code","eac0f37f":"code","026eb69b":"code","fa080c73":"code","6aaf589f":"code","0458d0ea":"code","f7a5520c":"code","ba567711":"code","19afe573":"code","d6be241b":"markdown","75297b7c":"markdown","26018da7":"markdown","17c44c56":"markdown","4190012f":"markdown","9f50b382":"markdown","603a33ab":"markdown","1cf0eb41":"markdown","2111c830":"markdown","b346fd42":"markdown","e172a0a1":"markdown","0ec0ed5e":"markdown"},"source":{"780544cf":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import utils as np_utils\nfrom tensorflow.keras.layers import Input, InputLayer, Conv2D, MaxPool2D, GlobalAveragePooling2D, BatchNormalization, Activation, ReLU, Flatten, Dense, Add, Dropout\nfrom tensorflow.keras.optimizers import  Adam, SGD\nfrom tensorflow.keras.activations import swish\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n","c3097543":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","2eb51534":"from PIL import Image\nimport matplotlib.pyplot as plt\nim = np.array(Image.open('..\/input\/plant-seedlings-classification\/train\/Maize\/006196e1c.png'))\n\nplt.imshow(im)","9161c7bb":"#\u690d\u7269\u540d\u306elist\u3092\u4f5c\u6210\nspecies_list = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\",\n                \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\",\n                \"Sugar beet\"]","8e09d7d2":"import glob\n\nfile_num = []\n#\u5404\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u753b\u50cf\u679a\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3057\u3066list\u306b\u3059\u308b\nfor i in range(12) :\n    imfile = glob.glob('..\/input\/plant-seedlings-classification\/train\/'+species_list[i]+'\/*.png')\n    file_num += [len(imfile)]\n\nfile_num","ed2927e2":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize = (8,5))\nax = fig.add_subplot(111)\nax.bar(species_list,file_num)\nplt.xticks(rotation = 90)\nplt.show()","44ac99fe":"train_generator = ImageDataGenerator(\n    #\u30e9\u30f3\u30c0\u30e0\u306b\u56de\u8ee2\u3055\u305b\u308b\u7bc4\u56f2\n    rotation_range = 80,\n    #\u30e9\u30f3\u30c0\u30e0\u306b\u30ba\u30fc\u30e0\u3059\u308b\u7bc4\u56f2\n    zoom_range = 0.2,\n    #\u30e9\u30f3\u30c0\u30e0\u306b\u6c34\u5e73\u30fb\u925b\u76f4\u65b9\u5411\u306b\u30b7\u30d5\u30c8\u3055\u305b\u308b\u7bc4\u56f2\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    #\u53cd\u6642\u8a08\u5468\u308a\u306e\u30b7\u30a2\u30fc\u5f37\u5ea6\n    shear_range = 0.2,\n    #\u6c34\u5e73\u30fb\u925b\u76f4\u65b9\u5411\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u53cd\u8ee2\u3055\u305b\u308b\n    vertical_flip = True,\n    horizontal_flip = True,\n)\ntrain_generator = train_generator.flow_from_directory(\n        directory = '\/kaggle\/input\/plant-seedlings-classification\/train',\n        target_size = (299, 299),\n        batch_size = 32,\n        color_mode = 'rgb',\n        #One-hot\u30d9\u30af\u30c8\u30eb\u3067\u30e9\u30d9\u30eb\u3092\u8868\u73fe\u3059\u308b\n        class_mode = \"categorical\",\n        subset ='training'\n)","c4b9c6ed":"test_generator = ImageDataGenerator()\ntest_generator = test_generator.flow_from_directory(\n        directory='\/kaggle\/input\/plant-seedlings-classification\/',\n        classes=['test'],\n        target_size=(299, 299),\n        batch_size=1,\n        color_mode='rgb',\n        shuffle=False,\n        class_mode=\"categorical\"\n)","712e2974":"plt.figure(figsize=(32,32))\nfor i in range(6):\n    batches = next(train_generator)\n    # \u753b\u50cf\u3068\u3057\u3066\u8868\u793a\u3059\u308b\u305f\u3081\u30013\u6b21\u5143\u30c7\u30fc\u30bf\u306b\u3057\u3001float \u304b\u3089 uint8(0-255) \u306b\u30ad\u30e3\u30b9\u30c8\u3059\u308b\u3002\n    gen_img = batches[0][i].astype(np.uint8)\n    #gen_img = batches[0][i]\n    #gen_img = array_to_img(gen_img,scale=True)\n    plt.subplot(2, 3, i + 1)\n    plt.imshow(gen_img)","b3d96425":"img = train_generator[0][0][1].astype(np.uint8)\n#img = array_to_img(img,scale=True)\nplt.imshow(img)","eac0f37f":"input_shape = (299,299,3)","026eb69b":"def ResBlock(x, kernel_size, filter_num) :\n    shortcut = x\n    \n    for l in range(2) :\n        x = Conv2D(filter_num, kernel_size, padding='same')(x)\n        x = BatchNormalization()(x)\n        \n        if l == 1 :\n            # shortcut\u3068Conv\u5c64\u901a\u904e\u5f8c\u3067\u30c1\u30e3\u30cd\u30eb\u6570\u304c\u9055\u3046\u3053\u3068\u304c\u3042\u308b\u306e\u30671x1conv\u3067\u305d\u308d\u3048\u308b\n            if K.int_shape(x) != K.int_shape(shortcut) :\n                shortcut = Conv2D(filter_num, (1,1), padding='same')(shortcut)\n            \n            x = Add()([x, shortcut])\n        x = Activation('swish')(x)\n    \n    return x","fa080c73":"block = 5\nfilter = 64\ninput = Input(shape=input_shape)\nx = Conv2D(filter,(3,3), strides=2, padding='same')(input)\nx = BatchNormalization()(x)\nx = Activation('swish')(x)\n\nfor f in range(block) :\n        \n    for s in range(3) :\n        x = ResBlock(x, (3,3), filter)\n\n    filter = filter * 2\n    if f < block - 1 :\n        #x = MaxPool2D(pool_size=(2, 2))(x)\n        x = Conv2D(filter, (1,1), strides = 2)\n\n#x = Dropout(0.2)(x)\nx = GlobalAveragePooling2D()(x)\nx = Flatten()(x)\n#x = Dense(256)(x)\n#x = ReLU()(x)\noutput = Dense(12, activation='softmax')(x)\n\nmodel = Model(inputs=input, outputs=output)\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])","6aaf589f":"model.summary()","0458d0ea":"epochs = 30\nbatch_size = 32\nhistory = model.fit(train_generator, batch_size=batch_size, epochs=epochs, verbose=1)","f7a5520c":"train_generator.class_indices","ba567711":"#\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u3092\u78ba\u8a8d\npredict = model_conv.predict(test_generator, steps=test_generator.samples)\npredict[0]","19afe573":"predict = model_conv.predict(test_generator, steps=test_generator.samples)\n\nclass_list = []\n\nfor i in range(0, predict.shape[0]):\n  #\u6700\u3082\u78ba\u7387\u304c\u9ad8\u3044\u3068\u4e88\u6e2c\u3055\u308c\u305f\u690d\u7269\u3092class_list\u306b\u8ffd\u52a0\u3059\u308b\n  y_class = predict[i, :].argmax(axis=-1)\n  class_list += [species_list[y_class]]\n\nsubmission = pd.DataFrame()\nsubmission['file'] = test_generator.filenames\nsubmission['file'] = submission['file'].str.replace(r'test\/', '')\nsubmission['species'] = class_list\n\nsubmission.to_csv('submission.csv', index=False)\n\nprint('Submission file generated. All done.')","d6be241b":"## keras\u306eImageDataGenerator\u3092\u7528\u3044\u3066\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7406\u3092\u884c\u3046","75297b7c":"InceptionResNetV2\u3092\u4f7f\u7528\u3059\u308b\uff0e","26018da7":"\u68d2\u30b0\u30e9\u30d5\u5316","17c44c56":"## \u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210","4190012f":"## \u7a2e\u985e\u3054\u3068\u306etrain\u753b\u50cf\u679a\u6570\u3092\u78ba\u8a8d\u3059\u308b\uff0e","9f50b382":"train\u753b\u50cf\u306e\u4e00\u3064\u3092\u8868\u793a\u3057\u3066\u307f\u308b","603a33ab":"## \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2","1cf0eb41":"## NN\u306e\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9","2111c830":"## train\u753b\u50cf\u3092\u78ba\u8a8d\u3059\u308b","b346fd42":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u306f12\u6b21\u5143\u306e\u30d9\u30af\u30c8\u30eb\u3067\u3042\u308b\uff0e\u307e\u305f\uff0c\u51fa\u529b\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570\u306bsoftmax\u95a2\u6570\u304c\u7528\u3044\u3089\u308c\u3066\u3044\u308b\u305f\u3081\uff0c\u51fa\u529b\u5024\u306e\u7bc4\u56f2\u306f0.0-1.0\u3067\u3042\u308a12\u500b\u306e\u51fa\u529b\u3092\u8db3\u3059\u30681\u306b\u306a\u308b\u3088\u3046\u306b\u5909\u63db\u3055\u308c\u3066\u3044\u308b\uff0e\n\u3064\u307e\u308a\uff0c\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u306f12\u500b\u306e\u690d\u7269\u306e\u3069\u308c\u306b\u5206\u985e\u3055\u308c\u308b\u304b\u306e\u78ba\u7387\u5206\u5e03\u3068\u306a\u3063\u3066\u3044\u308b\uff0e\n","e172a0a1":"train\u753b\u50cf\u306b\u5bfe\u3057\u3066\u4ee5\u4e0b\u306e\u8a2d\u5b9a\u3067DataAugmentation(\u30c7\u30fc\u30bf\u306e\u6c34\u5897\u3057)\u3092\u884c\u3046\uff0e","0ec0ed5e":"\u524d\u51e6\u7406\u5f8c\u306e\u5b66\u7fd2\u7528\u753b\u50cf\u3092\u78ba\u8a8d"}}