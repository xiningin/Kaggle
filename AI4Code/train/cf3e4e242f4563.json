{"cell_type":{"877a581f":"code","5fd5f018":"code","7a3238ea":"code","209d9bbe":"code","20b316b4":"code","af03320b":"code","15b44684":"code","d0ca7a19":"code","d4c76f88":"code","0336a5ce":"code","6f013ddd":"code","32b4cf14":"code","aec2b05f":"code","6de1f5e1":"code","815f622e":"code","270ea5c0":"code","662a806b":"code","dd459d8b":"code","abfcb848":"code","361ad336":"code","0cb293cc":"code","c0d0226b":"code","908adad6":"code","d4048b48":"code","c9919f92":"code","ad8db429":"code","01e6ea4f":"code","502be5d7":"code","5b3f0187":"code","d613895e":"code","ddaa6ef9":"code","256655e9":"code","5941b5f7":"code","8ff6f446":"code","231476ba":"code","d0ba9320":"code","56b396af":"code","43f1528b":"code","2e51efdb":"code","e4939b8b":"code","e622163d":"code","d93979f7":"code","e828ee82":"code","f9c177a9":"code","41b879d9":"code","6bdb2efe":"code","9dc2fa76":"code","f2583897":"code","7f45e8c3":"code","3c4d1748":"code","9588a3b6":"code","5742fe7a":"code","7bb0956d":"code","868f18bf":"code","7d960bc3":"code","f3eacf92":"code","6484831f":"code","ee93c751":"code","ab169e14":"code","65effb7a":"code","94c9654c":"code","2ec8eb66":"code","28e6303f":"code","2cee6a13":"code","ce3b9764":"code","3585b0fe":"code","7b98390c":"code","2ffc6210":"code","10b2ddee":"code","c363e445":"code","a8763ee9":"code","86b28cde":"code","e535a04a":"code","b1540f27":"code","b0897af1":"code","0e70867b":"code","f373f615":"markdown","d0fa6cda":"markdown","1566b9aa":"markdown","fe2555c2":"markdown","def40820":"markdown","20ba937f":"markdown","8f2a9b53":"markdown","cc0615a5":"markdown","802b4a1d":"markdown","3e4c9c3e":"markdown","ad9757e3":"markdown","9404ded5":"markdown","c5bf9faf":"markdown","1e159ffe":"markdown","4da80339":"markdown","a6a2374c":"markdown","62d5d63f":"markdown","a679b661":"markdown","583f76ae":"markdown","251fe367":"markdown","891a491b":"markdown","7e2624d8":"markdown","19f3c740":"markdown","8bdbd1ac":"markdown","f97ab5a8":"markdown","7287caa7":"markdown","e7873912":"markdown","4ba14582":"markdown","c72dcdac":"markdown","6d932cea":"markdown","e7f13b1b":"markdown","1b13c89b":"markdown"},"source":{"877a581f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5fd5f018":"# Importing Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model, metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split,GridSearchCV,KFold,cross_val_score\nimport os\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","7a3238ea":"# reading the train dataset\nhp = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nhp.head()","209d9bbe":"# reading the test dataset\nhp_test = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nhp_test.head()","20b316b4":"# summary of the train dataset: 1460 rows, 81 columns, has null values\nprint(hp.info())","af03320b":"# Summary of test dataset\nprint(hp_test.info())","15b44684":"# Checking for null values in train set\nhp.isnull().sum().sort_values(ascending=False).head(20)","d0ca7a19":"# Checking for null values in test set\nhp_test.isnull().sum().sort_values(ascending=False).head(40)","d4c76f88":"# columns with attributes like Pool, Fence etc. marked as NaN indicate the absence of these features.\nattributes_with_na = ['PoolQC','MiscFeature','Alley','Fence','FireplaceQu',\n               'GarageQual','GarageCond','GarageFinish','GarageType',\n               'BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2','MasVnrType']","0336a5ce":"# replace 'NaN' with 'None' in these columns\nfor col in attributes_with_na:\n    hp[col].fillna('None',inplace=True)\n    hp_test[col].fillna('None',inplace=True)","6f013ddd":"# Checking for null values in train set\nhp.isnull().sum().sort_values(ascending=False)","32b4cf14":"# Checking for null values in test set\nhp_test.isnull().sum().sort_values(ascending=False).head(20)","aec2b05f":"# Imputing missing values in 'Lot Frontage' by median\nhp['LotFrontage'].fillna(hp['LotFrontage'].median(),inplace=True)\nhp_test['LotFrontage'].fillna(hp_test['LotFrontage'].median(),inplace=True)","6de1f5e1":"# Imputing missing values in 'MasVnrType' by None\nhp_test['MasVnrType'].fillna('None',inplace=True) ","815f622e":"# Imputing missing values in 'MasVnrArea' by 0 as None in 'MasVnrType' implies no masonry\nhp['MasVnrArea'].fillna(0,inplace=True)\nhp_test['MasVnrArea'].fillna(0,inplace=True)","270ea5c0":"# Imputing missing values by Median in continuous variable and by Mode in categorical variable\n\nhp_test['GarageCars'].fillna(hp_test['GarageCars'].median(),inplace=True)\nhp_test['GarageArea'].fillna(hp_test['GarageArea'].median(),inplace=True)\nhp_test['KitchenQual'].fillna('TA',inplace=True)\nhp_test['Exterior1st'].fillna('VinylSd',inplace=True)\nhp_test['SaleType'].fillna('WD',inplace=True)\nhp_test['TotalBsmtSF'].fillna(hp_test['TotalBsmtSF'].median(),inplace=True)\nhp_test['BsmtUnfSF'].fillna(hp_test['BsmtUnfSF'].median(),inplace=True)\nhp_test['BsmtFinSF1'].fillna(hp_test['BsmtFinSF1'].median(),inplace=True)\nhp_test['BsmtFinSF2'].fillna(hp_test['BsmtFinSF2'].median(),inplace=True)\nhp_test['Exterior2nd'].fillna('VinylSd',inplace=True)\nhp_test['BsmtFullBath'].fillna(hp_test['BsmtFullBath'].median(),inplace=True)\nhp_test['BsmtHalfBath'].fillna(hp_test['BsmtHalfBath'].median(),inplace=True)\nhp_test['Functional'].fillna('Typ',inplace=True)\nhp_test['Utilities'].fillna('AllPub',inplace=True)\nhp_test['MSZoning'].fillna('RL',inplace=True)\n\nhp['Electrical'].fillna('SBrkr',inplace=True)","662a806b":"# Checking for null values in train set\nhp.isnull().sum().sort_values(ascending=False)","dd459d8b":"# Checking for null values in test set\nhp_test.isnull().sum().sort_values(ascending=False).head(20)","abfcb848":"hp.head()","361ad336":"# Dropping Id column\nhp.drop('Id', 1, inplace = True)\nhp_test_new = hp_test.drop('Id', 1)","0cb293cc":"# Function to check skewness in categorical columns\ndef chk_skewness(col):\n    print(col)\n    print(hp[col].value_counts(dropna=False,normalize=True))\n    print('')","c0d0226b":"# Creating a list of all categorical variables\ncat_var = [key for key in dict(hp.dtypes)\n             if dict(hp.dtypes)[key] in ['object'] ] # Categorical Varible\ncat_var","908adad6":"for col in cat_var:\n    chk_skewness(col)","d4048b48":"# dropping columns with more than 90% skewness\ncat_col_with_skewness = ['MiscFeature','PoolQC','PavedDrive','GarageCond','Functional','Electrical','CentralAir','Heating','RoofMatl','Condition2','LandSlope','Utilities','Alley','Street']\nhp.drop(cat_col_with_skewness,axis=1,inplace=True)\nhp_test_new.drop(cat_col_with_skewness,axis=1,inplace=True)","c9919f92":"hp.MSZoning.value_counts(normalize=True).plot.barh()","ad8db429":"hp.LotShape.value_counts(normalize=True).plot.barh()","01e6ea4f":"hp.LotConfig.value_counts(normalize=True).plot.barh()","502be5d7":"hp.Neighborhood.value_counts(normalize=True).plot.barh()","5b3f0187":"hp.BldgType.value_counts(normalize=True).plot.barh()","d613895e":"hp.HouseStyle.value_counts(normalize=True).plot.barh()","ddaa6ef9":"hp.OverallQual.value_counts(normalize=True).plot.barh()","256655e9":"hp.OverallCond.value_counts(normalize=True).plot.barh()","5941b5f7":"hp.Foundation.value_counts(normalize=True).plot.barh()","8ff6f446":"hp.SaleType.value_counts(normalize=True).plot.barh()","231476ba":"hp.SaleCondition.value_counts(normalize=True).plot.barh()","d0ba9320":"plt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.scatter(hp.LotArea,hp.SalePrice)\nplt.subplot(2,3,2)\nplt.scatter(hp.TotalBsmtSF,hp.SalePrice)\nplt.subplot(2,3,3)\nplt.scatter(hp['1stFlrSF'],hp.SalePrice)\nplt.subplot(2,3,4)\nplt.scatter(hp['GarageArea'],hp.SalePrice)\nplt.subplot(2,3,5)\nplt.scatter(hp['GrLivArea'],hp.SalePrice)\nplt.subplot(2,3,6)\nplt.scatter(hp['WoodDeckSF'],hp.SalePrice)","56b396af":"# Correlation Heat Map\ncorr_matrix = hp.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corr_matrix, vmax=0.9, square=True)","43f1528b":"import datetime\nnow = datetime.datetime.now()","2e51efdb":"#Imputing missing values in GarageYrBlt with current year so that age will be 0\nhp['GarageYrBlt'].fillna(str(now.year),inplace=True)\nhp_test_new['GarageYrBlt'].fillna(str(now.year),inplace=True)","e4939b8b":"# Changing datatype of GarageYrBlt\nhp['GarageYrBlt']=hp['GarageYrBlt'].astype(int)\nhp_test_new['GarageYrBlt']=hp_test_new['GarageYrBlt'].astype(int)\n#Changing datatype of MoSold\nhp['MoSold']=hp['MoSold'].astype('object')\nhp_test_new['MoSold']=hp_test_new['MoSold'].astype('object')","e622163d":"#Converting Year variables to Age\nhp['HouseAge'] = int(now.year) - hp['YearBuilt']\nhp['HouseRemodelAge'] = int(now.year) - hp['YearRemodAdd']\nhp['GarageAge'] = int(now.year) - hp['GarageYrBlt']\nhp['SoldAge'] = int(now.year) - hp['YrSold']\n\nhp_test_new['HouseAge'] = int(now.year) - hp_test_new['YearBuilt']\nhp_test_new['HouseRemodelAge'] = int(now.year) - hp_test_new['YearRemodAdd']\nhp_test_new['GarageAge'] = int(now.year) - hp_test_new['GarageYrBlt']\nhp_test_new['SoldAge'] = int(now.year) - hp_test_new['YrSold']","d93979f7":"# Dropping original Year Variables\nhp = hp.drop(['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold'],axis=1)\nhp_test_new = hp_test_new.drop(['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold'],axis=1)","e828ee82":"# Creating a list of all numerical columns\nnum_cols=hp.select_dtypes(include=['float64', 'int64','int32']).columns\nnum_cols_test=hp_test_new.select_dtypes(include=['float64', 'int64','int32']).columns\nnum_cols","f9c177a9":"# Combining train and test set for Encoding and Scaling the variables\nhp_comb = pd.concat([hp,hp_test_new])\nhp_comb.info()","41b879d9":"# Checking for null values in test set\nhp_comb.isnull().sum().sort_values(ascending=False)","6bdb2efe":"hp_comb[['ExterQual','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n            'HeatingQC','KitchenQual','GarageFinish','GarageQual','FireplaceQu','Fence',\n             'ExterCond','LotShape']].head()","9dc2fa76":"hp_comb['ExterQual'] = hp_comb.ExterQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhp_comb['BsmtQual'] = hp_comb.BsmtQual.map({'NA':0,'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhp_comb['BsmtCond'] = hp_comb.BsmtCond.map({'NA':0,'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhp_comb['BsmtExposure'] = hp_comb.BsmtExposure.map({'NA':0,'None':0,'No':1,'Mn':2,'Av':3,'Gd':4})\nhp_comb['BsmtFinType1'] = hp_comb.BsmtFinType1.map({'NA':0,'None':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\nhp_comb['BsmtFinType2'] = hp_comb.BsmtFinType2.map({'NA':0,'None':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\nhp_comb['HeatingQC'] = hp_comb.HeatingQC.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhp_comb['KitchenQual'] = hp_comb.KitchenQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhp_comb['GarageFinish'] = hp_comb.GarageFinish.map({'NA':0,'None':0,'Unf':1,'RFn':2,'Fin':3})\nhp_comb['GarageQual'] = hp_comb.GarageQual.map({'NA':0,'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhp_comb['FireplaceQu'] = hp_comb.FireplaceQu.map({'NA':0,'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhp_comb['Fence'] = hp_comb.Fence.map({'None':0,'MnWw':1,'GdWo':2,'MnPrv':3,'GdPrv':4})\nhp_comb['ExterCond'] = hp_comb.ExterCond.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhp_comb['LotShape'] = hp_comb.LotShape.map({'IR1':0,'IR2':1,'IR3':2,'Reg':3})","f2583897":"dummy_col = pd.get_dummies(hp_comb[['MSZoning','LandContour','LotConfig','Neighborhood','Condition1','BldgType',\n             'HouseStyle','RoofStyle','Exterior1st','Exterior2nd','MasVnrType','Foundation',\n             'GarageType','MoSold','SaleType','SaleCondition']],\n                           drop_first=True)\nprint(dummy_col.shape)\n\nhp_comb = pd.concat([hp_comb,dummy_col],axis=1)\n\nhp_comb = hp_comb.drop(['MSZoning','LandContour','LotConfig','Neighborhood','Condition1','BldgType',\n             'HouseStyle','RoofStyle','Exterior1st','Exterior2nd','MasVnrType','Foundation',\n             'GarageType','MoSold','SaleType','SaleCondition'],axis=1)","7f45e8c3":"hp_comb.head()","3c4d1748":"sns.distplot(hp_comb['SalePrice']).set_title(\"Distribution of SalePrice\")","9588a3b6":"hp_comb[\"SalePrice\"] = np.log1p(hp_comb[\"SalePrice\"])","5742fe7a":"sns.distplot(hp_comb['SalePrice']).set_title(\"Distribution of SalePrice\")","7bb0956d":"df_train = hp_comb[0:1460]\ndf_train.info()","868f18bf":"df_test = hp_comb[1460:]\ndf_test.info()","7d960bc3":"df_test.drop(['SalePrice'],axis=1,inplace=True)\ndf_test.head()","f3eacf92":"# Splitting the data into train and test\nfrom sklearn.model_selection import train_test_split\n\nhp_train, hp_test = train_test_split(df_train, train_size=0.8, test_size=0.2, random_state=42)","6484831f":"#scaling numeric columns\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler1 = StandardScaler()\nhp_train[num_cols_test] = scaler1.fit_transform(hp_train[num_cols_test])\nhp_test[num_cols_test] = scaler1.transform(hp_test[num_cols_test])\ndf_test[num_cols_test] = scaler1.transform(df_test[num_cols_test])","ee93c751":"hp_train.head()","ab169e14":"y_train = hp_train.pop('SalePrice')\nX_train = hp_train\n\n\ny_test = hp_test.pop('SalePrice')\nX_test = hp_test","65effb7a":"lm  = LinearRegression()\nlm.fit(X_train,y_train)\nrfe = RFE(lm,50)\nrfe.fit(X_train,y_train)\n\nrfe_scores = pd.DataFrame(list(zip(X_train.columns,rfe.support_,rfe.ranking_)))\nrfe_scores.columns = ['Column_Names','Status','Rank']\n\nrfe_sel_columns = list(rfe_scores[rfe_scores.Status==True].Column_Names)\n\nX_train1 = X_train[rfe_sel_columns]\nX_test1 = X_test[rfe_sel_columns]","94c9654c":"# Using GridSearchCV to find optimal value of alpha\nfolds = KFold(n_splits=10,shuffle=True,random_state=42)\n\nhyper_param = {'alpha':[0.00001,0.0001,0.001, 0.01, 0.1,1.0, 5.0]}\n\nmodel = Lasso()\n\nmodel_cv = GridSearchCV(estimator = model,\n                        param_grid=hyper_param,\n                        scoring='neg_mean_squared_error',\n                        cv=folds,\n                        verbose=1,\n                        return_train_score=True\n                       )\n\nmodel_cv.fit(X_train1,y_train)","2ec8eb66":"cv_result_l = pd.DataFrame(model_cv.cv_results_)\ncv_result_l['param_alpha'] = cv_result_l['param_alpha'].astype('float32')\ncv_result_l.head()","28e6303f":"plt.figure(figsize=(16,8))\nplt.plot(cv_result_l['param_alpha'],cv_result_l['mean_train_score'])\nplt.plot(cv_result_l['param_alpha'],cv_result_l['mean_test_score'])\nplt.xscale('log')\nplt.ylabel('MSE Score')\nplt.xlabel('Alpha')\nplt.legend(['train','test'])\nplt.show()","2cee6a13":"# Checking the best parameter(Alpha value)\nmodel_cv.best_params_","ce3b9764":"lasso = Lasso(alpha=0.0001)\nlasso.fit(X_train1,y_train)\n\ny_train_pred = lasso.predict(X_train1)\ny_test_pred = lasso.predict(X_test1)\n\nprint('Train Set MSE : ',np.sqrt(mean_squared_error(y_true=y_train,y_pred=y_train_pred)))\nprint('Test Set MSE : ',np.sqrt(mean_squared_error(y_true=y_test,y_pred=y_test_pred)))\n\nprint('Train Set R2 Score : ',r2_score(y_true=y_train,y_pred=y_train_pred))\nprint('Test Set R2 Score : ',r2_score(y_true=y_test,y_pred=y_test_pred))","3585b0fe":"df_test1 = df_test[rfe_sel_columns]\ntest_pred = lasso.predict(df_test1)\ntest_pred","7b98390c":"import xgboost\nfrom xgboost import plot_importance","2ffc6210":"#for tuning parameters\n#parameters_for_testing = {\n#    'colsample_bytree':[0.3,0.4,0.5,0.6],\n#    'gamma':[0,0.03,0.05],\n#    'min_child_weight':[1,1.3,1.5,1.6,1.8],\n#    'learning_rate':[0.001,0.007,0.01,0.02],\n#    'max_depth':[3,4,5],\n#    'n_estimators':[10000],\n#    'reg_alpha':[0.6,0.7,0.75,0.8],\n#    'reg_lambda':[1e-2, 0.45,0.55,0.6],\n#    'subsample':[0.4,0.5,0.6,0.7]\n#}\n\n\n#xgb_model = xgboost.XGBRegressor(tree_method='gpu_exact',random_state=42)\n#gsearch1 = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=-1,iid=False, verbose=10,scoring='neg_mean_squared_error')\n#gsearch1.fit(X_train,y_train)\n#print (gsearch1.grid_scores_)\n#print('best params')\n#print (gsearch1.best_params_)\n#print('best score')\n#print (gsearch1.best_score_)","10b2ddee":"xgb_model = xgboost.XGBRegressor(colsample_bytree=0.4,\n                 gamma=0,                 \n                 learning_rate=0.01,\n                 max_depth=4,\n                 min_child_weight=1.5,\n                 n_estimators=10000,                                                                    \n                 reg_alpha=0.7,\n                 reg_lambda=0.55,\n                 subsample=0.5,\n                 seed=42)\nxgb_model.fit(X_train,y_train)","c363e445":"y_train_pred = xgb_model.predict(X_train)\ny_test_pred = xgb_model.predict(X_test)\n\nprint('Train Set MSE : ',np.sqrt(mean_squared_error(y_true=y_train,y_pred=y_train_pred)))\nprint('Test Set MSE : ',np.sqrt(mean_squared_error(y_true=y_test,y_pred=y_test_pred)))\n\nprint('Train Set R2 Score : ',r2_score(y_true=y_train,y_pred=y_train_pred))\nprint('Test Set R2 Score : ',r2_score(y_true=y_test,y_pred=y_test_pred))","a8763ee9":"df_train[num_cols_test] = scaler1.fit_transform(df_train[num_cols_test])\nfinal_train = df_train\nfinal_train.head()","86b28cde":"f_y_train =final_train.pop('SalePrice')\nf_x_train = final_train","e535a04a":"xgb_model.fit(f_x_train,f_y_train)\ntest_pred = xgb_model.predict(df_test)\ntest_pred","b1540f27":"# Converting test_pred to a dataframe which is an array\ntest_pred_1 = pd.DataFrame(test_pred)\n# Renaming the column \ntest_pred_1= test_pred_1.rename(columns={ 0 : 'SalePrice'})\ntest_pred_1.head()","b0897af1":"test_pred_1[\"SalePrice\"] = np.expm1(test_pred_1[\"SalePrice\"])\ntest_pred_1.head()","0e70867b":"#test_pred_1.to_csv('Submission5.csv')\nfilename = 'final_submission1.csv'\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\npd.DataFrame({'Id': test.Id, 'SalePrice': test_pred_1.SalePrice}).to_csv(filename, index=False)","f373f615":"## Selecting XGBoost as the final model","d0fa6cda":"### North Ames area has highest number of houses","1566b9aa":"### Most of the houses belong to Inside Lot configuration","fe2555c2":"# Feature Engineering","def40820":"### More than 60% of houses have Regular shape","20ba937f":"## Creating Test-Train Split","8f2a9b53":"## Creating Dummy Variables","cc0615a5":"# EDA","802b4a1d":"## Plotting Scatter plot for some continuos variables w.r.t Target Variable","3e4c9c3e":"### The plot is right skewed and is not completely normal distribution. Hence Target variable needs to be transformed","ad9757e3":"# 1. Lasso","9404ded5":"### Most of the houses have Brick&Tile or Cinder Block foundation","c5bf9faf":"# Missing Value Treatment","1e159ffe":"# Plotting Distribution of Target Variable","4da80339":"### Using RFE to reduce the number of variables","a6a2374c":"### Now all missing values are treated in the dataset except GarageYrBlt which will be treated later","62d5d63f":"# Model Building","a679b661":"### Majority of houses have single family detached type of building","583f76ae":"## Building final model with optimal alpha","251fe367":"### From above two plots we see that most of the houses have average rating in overall condtion and quality","891a491b":"### For most of the houses sale type was Warranty Deed - Conventional","7e2624d8":"### Splitting Train and Test Set","19f3c740":"### Around 50% of houses are one storied","8bdbd1ac":"## Encoding Ordinal Variables","f97ab5a8":"### Univariate Analysis of some categorical variables","7287caa7":"# 2. XGBoost","e7873912":"### From above heatmap we can see that features like OverallQual, GrLivArea, GarageArea, GarageCars,TotalBsmtSF and 1stFlrSF are correlated to Target Variable","4ba14582":"### Most of the houses were sold in Normal sale","c72dcdac":"### Algorithms Used - Lasso Regression and XGBoost","6d932cea":"## Test Score - 0.12280\n## Top 15%","e7f13b1b":"### Now after the transformation the distribution becomes close to Normal","1b13c89b":"### We can see that most of the properties(around 80%) belong to Residential Low Density Zoning"}}