{"cell_type":{"5afb26e5":"code","f9bf1597":"code","b2705f99":"code","ee59d5ab":"code","15fe5622":"code","b0e11a48":"code","d7da7fc9":"code","ee6d242b":"code","27cc9b53":"code","cae075f0":"code","a34e200f":"code","a871b242":"code","726dd408":"code","cc3765e6":"code","4152e328":"code","a21da7fe":"code","23645cd1":"code","7f5beb19":"code","fd5789eb":"code","bf9b9e26":"code","c62a73dd":"code","57bf5ed4":"code","c0910531":"code","0231a73c":"code","f42e067e":"code","1aba71ca":"code","f2441ac7":"code","f8bef492":"code","6b6ce96c":"code","1acebe49":"code","09c3072e":"code","fce71c4c":"code","1bb1799f":"code","8f8cd0ef":"code","1e503f72":"code","068ce31a":"code","0f02ee60":"code","0d3d719b":"code","779a6e81":"markdown","66081c45":"markdown","dbb35fa2":"markdown","5d1389e8":"markdown","152c2e72":"markdown","03d52127":"markdown","b75f6704":"markdown","8b63fcd4":"markdown","985554a8":"markdown","875a782f":"markdown","43091e58":"markdown","a3f4ec16":"markdown","b00dda6c":"markdown","37f37de1":"markdown","b4ab786c":"markdown","628af51a":"markdown","2fbb7feb":"markdown","a49d9640":"markdown","b2896909":"markdown","3d91660d":"markdown","dccdcbc7":"markdown","9ba2fd62":"markdown","d82c830a":"markdown","73abf26a":"markdown","9b8022ed":"markdown","1706989a":"markdown","fe545c01":"markdown","41b05842":"markdown","eea96b7b":"markdown","e3c58b39":"markdown","748692f2":"markdown","a15de8eb":"markdown","262708ca":"markdown","57e3c827":"markdown","54944a35":"markdown","fd1aa8e2":"markdown","884b2740":"markdown","7df4d51a":"markdown","56ff022c":"markdown","c432ed7f":"markdown","1c07fb54":"markdown","f1a22499":"markdown","11687857":"markdown","17abdcda":"markdown"},"source":{"5afb26e5":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom lightgbm import LGBMRegressor","f9bf1597":"df = pd.read_csv(\"..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\")","b2705f99":"df.head()","ee59d5ab":"df.shape","15fe5622":"df.info()","b0e11a48":"df.describe().T","d7da7fc9":"df.isna().sum()","ee6d242b":"df.duplicated().sum()","27cc9b53":"df.drop(\"Serial No.\", axis=1, inplace=True)","cae075f0":"df.rename(columns={\"LOR \": \"LOR\", \"Chance of Admit \": \"Chance of Admit\"}, inplace=True)","a34e200f":"sns.set_theme()\n\nsns.pairplot(df)","a871b242":"for col in df.columns:\n    plt.figure(figsize=(10,8))\n    sns.distplot(df[col])\n    plt.title(f\"{col}\", size=15)\n    plt.show()","726dd408":"sns.set(style=\"whitegrid\")\n\nnum_cols = df.drop([\"University Rating\", \"Research\", \"Chance of Admit\"], axis=1).columns\ncat_cols = df[[\"University Rating\", \"Research\"]].columns\n\nfor col in num_cols:\n    plt.figure(figsize=(10,8))\n    sns.jointplot(x=df[col], y=df[\"Chance of Admit\"], kind=\"kde\", cmap=\"Blues\", fill=True)\n    plt.show()\n\nfor col in cat_cols:\n    plt.figure(figsize=(10,8))\n    sns.barplot(x=df[col], y=df[\"Chance of Admit\"])\n    plt.show()","cc3765e6":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(), annot=True, cmap=\"Blues\")\nplt.title(\"Correlations Between Features\", size=16)\nplt.show()","4152e328":"X = df.drop(\"Chance of Admit\", axis=1)\ny = df[\"Chance of Admit\"]","a21da7fe":"scaler = StandardScaler()\nX[num_cols] = scaler.fit_transform(X[num_cols])","23645cd1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","7f5beb19":"def evaluate(y_test, predictions):\n    mae = mean_absolute_error(y_test, predictions)\n    mse = mean_squared_error(y_test, predictions)\n    r2 = r2_score(y_test, predictions)\n    return mae, mse, r2\n\ndef rmse_cv(model):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5)).mean()\n    return rmse","fd5789eb":"models = pd.DataFrame(columns=[\"Model\", \"MAE\", \"MSE\", \"R2 Score\", \"RMSE (Cross-Validated)\"])","bf9b9e26":"lin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\npredictions = lin_reg.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(lin_reg)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"LinearRegression\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","c62a73dd":"lasso = Lasso(random_state=42)\nlasso.fit(X_train, y_train)\npredictions = lasso.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(lasso)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"Lasso\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","57bf5ed4":"ridge = Ridge(random_state=42)\nridge.fit(X_train, y_train)\npredictions = ridge.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(ridge)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"Ridge\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","c0910531":"elastic_net = ElasticNet(random_state=42)\nelastic_net.fit(X_train, y_train)\npredictions = elastic_net.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(elastic_net)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"ElasticNet\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","0231a73c":"poly_reg = PolynomialFeatures(degree=2)\nX_train_2d = poly_reg.fit_transform(X_train)\nX_test_2d = poly_reg.transform(X_test)\n\npoly_reg = LinearRegression()\npoly_reg.fit(X_train_2d, y_train)\npredictions = poly_reg.predict(X_test_2d)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(poly_reg)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"PolynomialRegression(degree=2)\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","f42e067e":"lgbm = LGBMRegressor(random_state=42)\nlgbm.fit(X_train, y_train)\npredictions = lgbm.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(lgbm)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"LGBMRegressor\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","1aba71ca":"models.sort_values(by=\"RMSE (Cross-Validated)\")","f2441ac7":"plt.figure(figsize=(12,8))\nsns.barplot(x=models[\"Model\"], y=models[\"RMSE (Cross-Validated)\"])\nplt.title(\"Models' Cross Validated RMSE Scores\", size=15)\nplt.xticks(rotation=30)\nplt.show()","f8bef492":"tuned_models = pd.DataFrame(columns=[\"Model\", \"MAE\", \"MSE\", \"R2 Score\", \"RMSE (Cross-Validated)\"])","6b6ce96c":"param_grid_lasso = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10],\n                    \"random_state\": [42]}\n\ngrid_lasso = GridSearchCV(Lasso(), param_grid_lasso, scoring=\"neg_root_mean_squared_error\", cv=5, verbose=0, n_jobs=-1)\n\ngrid_lasso.fit(X_train, y_train)","1acebe49":"lasso_params = grid_lasso.best_params_\n\nlasso = Lasso(**lasso_params)\nlasso.fit(X_train, y_train)\npredictions = lasso.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(lasso)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"Lasso\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","09c3072e":"param_grid_ridge = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10],\n                    \"random_state\": [42]}\n\ngrid_ridge = GridSearchCV(Ridge(), param_grid_ridge, scoring=\"neg_root_mean_squared_error\", cv=5, verbose=0, n_jobs=-1)\n\ngrid_ridge.fit(X_train, y_train)","fce71c4c":"ridge_params = grid_ridge.best_params_\n\nridge = Ridge(**ridge_params)\nridge.fit(X_train, y_train)\npredictions = ridge.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(ridge)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"Ridge\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","1bb1799f":"param_grid_elasticnet = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10],\n                         \"l1_ratio\": np.arange(0, 1, 0.05), \n                         \"random_state\": [42]}\n\ngrid_elasticnet = GridSearchCV(ElasticNet(), param_grid_elasticnet, scoring=\"neg_root_mean_squared_error\", cv=5, verbose=0, n_jobs=-1)\n\ngrid_elasticnet.fit(X_train, y_train)","8f8cd0ef":"elasticnet_params = grid_elasticnet.best_params_\n\nelastic_net = ElasticNet(**elasticnet_params)\nelastic_net.fit(X_train, y_train)\npredictions = elastic_net.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(elastic_net)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"ElasticNet\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","1e503f72":"param_grid_lgbm = {\"num_leaves\": [2, 3, 5, 7],\n                   \"learning_rate\": [0.01, 0.05],\n                   \"n_estimators\": [200, 500, 1000, 5000],\n                   \"max_bin\": [100, 150, 200],\n                   \"random_state\": [42]}\n\ngrid_lgbm = GridSearchCV(LGBMRegressor(), param_grid_lgbm, scoring=\"neg_root_mean_squared_error\", cv=5, verbose=0, n_jobs=-1)\n\ngrid_lgbm.fit(X_train, y_train)","068ce31a":"lgbm_params = grid_lgbm.best_params_\n\nlgbm = LGBMRegressor(**lgbm_params)\nlgbm.fit(X_train, y_train)\npredictions = lgbm.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(lgbm)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"R2 Score:\", r2)\nprint(\"RMSE (Cross-Validated)\", rmse)\n\nnew_row = {\"Model\": \"LGBMRegressor\", \"MAE\": mae, \"MSE\": mse, \"R2 Score\": r2, \"RMSE (Cross-Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","0f02ee60":"tuned_models.sort_values(by=\"RMSE (Cross-Validated)\")","0d3d719b":"plt.figure(figsize=(12,8))\nsns.barplot(x=tuned_models[\"Model\"], y=tuned_models[\"RMSE (Cross-Validated)\"])\nplt.title(\"Models' Cross Validated RMSE Scores After Hyperparameter Tuning\", size=15)\nplt.xticks(rotation=30)\nplt.show()","779a6e81":"# X, y Split","66081c45":"# Data Visualization","dbb35fa2":"<h3>Tuning the LightGBM Regressor<\/h3>","5d1389e8":"<center><img width=\"250px\" src=\"https:\/\/www.thoughtco.com\/thmb\/gItmqGd5HlnhyPIiLm1YHXOlTnw=\/330x242\/filters:fill(auto,1)\/zscore-56a8fa785f9b58b7d0f6e87b.GIF\"><\/center>","152c2e72":"***Renaming columns (removing whitespace around \"LOR\" and \"Chance of Admit\" columns)***","03d52127":"***Visualizing the linear correlations between variables using Heatmap visualization. The measure used for finding the linear correlation between each variable is Pearson Correlation Coefficient.***","b75f6704":"# Exploratory Data Analysis","8b63fcd4":"***Taking a look at the first 5 rows of the dataset.***","985554a8":"<h3>Tuning the Elastic Net<\/h3>","875a782f":"***Learning the dtypes of columns' and how many non-null values there are in those columns.***","43091e58":"***Standardizing the numerical columns in X dataset. StandardScaler() adjusts the mean of the features as 0 and standard deviation of features as 1. Formula that StandardScaler() uses is as follows:***","a3f4ec16":"<h3>Since the Lasso model is yielding relatively less RMSE score after Hyperparameter Tuning, the winner in this comparison is Lasso (L1 Regularization).<\/h3>","b00dda6c":"# Machine Learning Models","37f37de1":"# <center>Graduate Admission Chance Prediction \ud83c\udf93<\/center>","b4ab786c":"# Checking for Missing Values and Duplicates","628af51a":"<h3>LightGBM Regressor<\/h3>","2fbb7feb":"# Model Comparison","a49d9640":"# Hyperparameter Tuning","b2896909":"<h3>Elastic Net<\/h3>","3d91660d":"# Data Standardization","dccdcbc7":"<h3>Lasso (L1 Regularization)<\/h3>","9ba2fd62":"***Visualizing the Correlation between the numerical variables using pairplot visualization.***","d82c830a":"***Dropping redundant columns***","73abf26a":"# Importing the Essential Libraries, Metrics, Tools and Models","9b8022ed":"<center><img width=\"800px\" src=\"https:\/\/images.unsplash.com\/photo-1607013407627-6ee814329547?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=664&q=80\"><\/center>","1706989a":"***Splitting the data into Train and Test chunks for better evaluation.***","fe545c01":"<h3>Ridge (L2 Regularization)<\/h3>","41b05842":"***Defining several evaluation functions for convenience.***","eea96b7b":"***There is no missing value and duplicate, data seems clean so far.***","e3c58b39":"# Loading the Data","748692f2":"# Conclusion","a15de8eb":"<h3>Tuning the Lasso<\/h3>","262708ca":"***Getting the statistical summary of dataset.***","57e3c827":"# About the Dataset","54944a35":"<h2>Distribution of Each Variable<\/h2>","fd1aa8e2":"* **GRE Scores** ( out of 340 ) - *Input Variable*\n* **TOEFL Scores** ( out of 120 ) - *Input Variable*\n* **University Rating** ( out of 5 ) - *Input Variable*\n* **Statement of Purpose Strength** ( out of 5 ) - *Input Variable*\n* **Letter of Recommendation Strength** ( out of 5 ) - *Input Variable*\n* **Undergraduate GPA** ( out of 10 ) - *Input Variable*\n* **Research Experience** ( either 0 or 1 ) - *Input Variable*\n* **Chance of Admit** ( ranging from 0 to 1 ) - *Output Variable*","884b2740":"<h3>Linear Regression<\/h3>","7df4d51a":"***Checking the shape\u2014i.e. size\u2014of the data.***","56ff022c":"# Train-Test Split","c432ed7f":"<h2>Relationship Between Each Variable and Target Variable (Chance of Admit)<\/h2>","1c07fb54":"<h3>Polynomial Regression (degree=2)<\/h3>","f1a22499":"<h1 style=\"font-family: Times New Roman;\">Thank you so much for reading notebook. Preparing notebooks are taking a great deal of time. If you liked it, please do not forget to give upvote. Peace Out \u270c\ufe0f ...<\/h1>","11687857":"<h2>Putting the Data into More Proper Form<\/h2>","17abdcda":"<h3>Tuning the Ridge<\/h3>"}}