{"cell_type":{"a39f32d4":"code","44baa585":"code","eeac8d1e":"code","1bda4c03":"code","8fe7568c":"code","7ce27a29":"code","5ff4d870":"code","926ad550":"code","3a5007c7":"code","970efdbb":"code","1adfbf25":"code","743bcb2f":"code","a988be06":"code","01b7c0d6":"code","b869afbc":"code","39d39c6b":"code","ce5a1008":"code","b27c4dd8":"code","f12b63fd":"code","04cba800":"code","616af7f0":"code","0a90b840":"code","4c0c272a":"code","0307e887":"code","e259ab1e":"code","923d744d":"code","7f987f79":"code","0d3f8f85":"code","2b9c5c04":"code","e69e8b2f":"code","228e3ab8":"code","63e66d4d":"code","d7bf6788":"code","2bae37c1":"code","ea1281d1":"code","e227abcb":"code","792ba975":"code","c345374a":"code","642bb72d":"code","b2b78d63":"code","7986b0ff":"code","fed7d6a5":"code","8d37ff6e":"code","08cb65e7":"code","389ec115":"code","d234266a":"code","649b4926":"code","c8f6cff0":"code","d836cdbf":"code","f57d778f":"code","118be360":"code","8d7168d1":"code","e51c189d":"code","984c1a8c":"code","4640cfcc":"code","435f81b7":"code","556a9e3b":"markdown","5a542e1a":"markdown","9d901d83":"markdown","4561d9af":"markdown","ee8dba44":"markdown","64be9ed4":"markdown","d910026a":"markdown","65d2be0d":"markdown","25ffdf6b":"markdown","f4bf29c9":"markdown","4c903434":"markdown","9786351d":"markdown","e06c3e87":"markdown","49d49c9b":"markdown","61103cbb":"markdown","bbecc433":"markdown","4df7fd40":"markdown","8838300c":"markdown","938a51d2":"markdown","288435ab":"markdown","0c886b58":"markdown","af145051":"markdown","e7aacd3d":"markdown","e0d740d9":"markdown","38655260":"markdown","8424042d":"markdown","7637b48f":"markdown","355f0139":"markdown","2f2ac3b9":"markdown","e5f5e429":"markdown","7b5fab78":"markdown","3bbec846":"markdown","aae54c20":"markdown","468a2494":"markdown","bbf67694":"markdown","e9b5371a":"markdown","cf7fde36":"markdown","1b4ca5a0":"markdown","169e195e":"markdown","f8d0948e":"markdown","bc821356":"markdown","afaa1bf3":"markdown","7ee43682":"markdown","7bea3917":"markdown","d3c923ef":"markdown","8523ca4d":"markdown","cdd558fc":"markdown","5fa28a59":"markdown","6f7e4b2f":"markdown","e4f9aad6":"markdown"},"source":{"a39f32d4":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set()\npd.set_option('display.expand_frame_repr', False)","44baa585":"# loading the datasets\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","eeac8d1e":"train.head()","1bda4c03":"train.head()","8fe7568c":"train.info()","7ce27a29":"train.isnull().sum().sort_values(ascending=False)","5ff4d870":"def bar_chart(feature):\n    survived = train[train['Survived'] == 1][feature].value_counts()\n    dead = train[train['Survived'] == 0][feature].value_counts()\n    df = pd.DataFrame([survived, dead])\n    df.index = ['Survived', 'Dead']\n    df.plot(kind='bar', stacked=True, figsize=(10, 5))","926ad550":"# Pclass\nbar_chart('Pclass')","3a5007c7":"fig, ax = plt.subplots(nrows= 2, ncols=2, figsize=(16, 10))\n\nplots = []\nplots.append(train.groupby('Survived')['Survived'].count().plot(kind='bar', ax=ax[0][0], title='Total Survied\/Dead', color=['r', 'g']))\nplots.append(train.groupby('Sex')['Sex'].count().plot(kind='bar', ax=ax[0][1], title='Total Male\/Female'))\nplots.append(train.loc[train['Survived'] == 1].groupby('Sex')['Sex'].count().plot(kind='bar', ax=ax[1][0], title='Male\/Female Survived'))\nplots.append(train.loc[train['Survived'] == 0].groupby('Sex')['Sex'].count().plot(kind='bar', ax=ax[1][1], title='Male\/Female Died'))\n\n\nfor plot in plots:\n    total = 0\n\n    for index, i in enumerate(plot.patches):\n        total += i.get_height()\n        \n    plot.text(0, 10, \"Total Passengers: \" + str(total), bbox=dict(color='white'))\n    \n    for index, i in enumerate(plot.patches):\n        perc = str(round(i.get_height()\/total * 100, 2)) + '%'\n        plot.annotate(perc, xy=(0, 0.5), xytext=(index, i.get_height()))","970efdbb":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=5, margin_titles=True)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()), xlabel='Age (years)', \n          title='Kernel Density Estimation (Age and Survival Rate)', ylabel='Density')\nfacet.add_legend()\n\nplt.xticks(range(0, int(train['Age'].max()), 5))\nplt.show()","1adfbf25":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=5, margin_titles=True)\nfacet.map(sns.kdeplot, 'Fare', shade=True)\nfacet.set(xlim=(0, train['Fare'].max()), xlabel='Fare (pounds)', \n          title='Kernel Density Estimation (Fare and Survival Rate)', ylabel='Density')\nfacet.add_legend()","743bcb2f":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Fare', shade=True)\nfacet.set(xlim=(0, 100))\nfacet.add_legend()\n\nplt.xticks(range(0, 100, 10))\nplt.show()","a988be06":"# SibSp\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=5)\nfacet.map(sns.kdeplot,'SibSp',shade= True)\nfacet.set(xlim=(0, train['SibSp'].max()))\nfacet.add_legend()","01b7c0d6":"# Parch\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=5)\nfacet.map(sns.kdeplot,'Parch',shade= True, bw=1.5)\nfacet.set(xlim=(0, train['Parch'].max()))\nfacet.add_legend()","b869afbc":"fig, ax = plt.subplots(nrows= 2, ncols=2, figsize=(20, 12))\nplots = []\n\nPclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\n\ntrain.groupby('Embarked')['Embarked'].count().plot(kind='bar', ax=ax[0][0], title='Total Embarked')\ntrain.loc[train['Survived'] == 0].groupby('Embarked')['Embarked'].count().plot(kind='bar', ax=ax[0][1], title='Total Embarked | Died')\ntrain.loc[train['Survived'] == 1].groupby('Embarked')['Embarked'].count().plot(kind='bar', ax=ax[1][0], title='Total Embarked | Survived')\ndf.plot(kind='bar',stacked=True, ax=ax[1][1], title='Embarked\/Pclass Relation')\n","39d39c6b":"name = train.groupby('Name')['Name'].count().sort_values(ascending=False)\ncabin = train.groupby('Cabin')['Cabin'].count().sort_values(ascending=False)\nticket = train.groupby('Ticket')['Ticket'].count().sort_values(ascending=False)\n\nprint('--Name has {} unique values'.format(len(name)))\nprint('--Ticket has {} unique values'.format(len(ticket)))\nprint('--Cabin has total of {} values out of which {} are unique'.format(891-687, len(cabin)))","ce5a1008":"c = train[~train['Cabin'].isnull()]['Survived'].value_counts()\ncn = train[train['Cabin'].isnull()]['Survived'].value_counts()\n\ntotal_died = len(train.loc[train['Survived'] == 0])\n\ndf = pd.DataFrame([c, cn])\ndf.index = ['With Cabin', 'Missing Cabin']\ndf.columns = ['Dead', 'Survived']\n\nprint('With Cabin % on death rate: {}%'.format(round(df.iloc[0, 0]\/total_died * 100, 2)))\nprint('Missing Cabin % on death rate: {}%'.format(round(df.iloc[1, 0]\/total_died * 100, 2)))\n\ndf.plot(kind='bar', stacked=True, figsize=(10, 5))","b27c4dd8":"train_test_data = [train, test]\ntrain.head()","f12b63fd":"for dataset in train_test_data:\n    \n    dataset.loc[ dataset['Age'] <= 3, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 3) & (dataset['Age'] <= 10), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 10) & (dataset['Age'] <= 17), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 17) & (dataset['Age'] <= 30), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 30) & (dataset['Age'] <= 45), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 45) & (dataset['Age'] <= 52), 'Age'] = 5\n    dataset.loc[ dataset['Age'] > 52, 'Age'] = 6","04cba800":"for dataset in train_test_data:\n    \n    dataset.loc[ dataset['Fare'] <= 7, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7) & (dataset['Fare'] <= 20), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 20) & (dataset['Fare'] <= 27), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] > 27) & (dataset['Fare'] <= 40), 'Fare'] = 3\n    dataset.loc[(dataset['Fare'] > 40) & (dataset['Fare'] <= 50), 'Fare'] = 4\n    dataset.loc[(dataset['Fare'] > 50) & (dataset['Fare'] <= 65), 'Fare'] = 5\n    dataset.loc[(dataset['Fare'] > 65) & (dataset['Fare'] <= 80), 'Fare'] = 6\n    dataset.loc[(dataset['Fare'] > 80) & (dataset['Fare'] <= 110), 'Fare'] = 7\n    dataset.loc[ dataset['Fare'] > 110, 'Fare'] = 7","616af7f0":"train.head()","0a90b840":"train[\"Family\"] = train[\"SibSp\"] + train[\"Parch\"]\ntest[\"Family\"] = test[\"SibSp\"] + test[\"Parch\"]","4c0c272a":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=5)\nfacet.map(sns.kdeplot,'Family',shade= True)\nfacet.set(xlim=(0, train['Family'].max()))\nfacet.add_legend()\nplt.xticks(range(0, train['Family'].max(), 1))\nplt.show()","0307e887":"for dataset in train_test_data:\n    dataset.loc[ dataset['Family'] == 0, 'Family'] = 0\n    dataset.loc[ dataset['Family'] == 1, 'Family'] = 1\n    dataset.loc[(dataset['Family'] > 1) & (dataset['Family'] <= 3), 'Family'] = 2\n    dataset.loc[(dataset['Family'] > 3) & (dataset['Family'] <= 6), 'Family'] = 3\n    dataset.loc[ dataset['Family'] > 6, 'Family'] = 4","e259ab1e":"train['Alone'] = 1\ntrain.loc[train['Family'] > 0, 'Alone'] = 0\n\ntest['Alone'] = 1\ntest.loc[train['Family'] > 0, 'Alone'] = 0","923d744d":"for dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","7f987f79":"train['Title'].value_counts()","0d3f8f85":"bar_chart('Title')","2b9c5c04":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2,\n                 \"Master\": 3, \"Dr\": 4, \"Rev\": 4, \"Col\": 4, \"Major\": 4, \"Mlle\": 4,\"Countess\": 4,\n                 \"Ms\": 4, \"Lady\": 4, \"Jonkheer\": 4, \"Don\": 4, \"Dona\" : 4, \"Mme\": 4,\"Capt\": 4,\"Sir\": 4}\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","e69e8b2f":"facet = sns.FacetGrid(train, hue=\"Title\",aspect=5)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()","228e3ab8":"train['Age'].fillna(train.groupby('Title')['Age'].transform('median'), inplace=True)\ntest['Age'].fillna(test.groupby('Title')['Age'].transform('median'), inplace=True)\n\ntrain['Age'] = train['Age'].astype(int)\ntest['Age'] = test['Age'].astype(int)","63e66d4d":"# filling missing values for Embarked based on the most frequent value from our EDA\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","d7bf6788":"train.groupby('Pclass')['Fare'].median().sort_values(ascending=False)","2bae37c1":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n\ntrain['Fare'] = train['Fare'].astype(int)\ntest['Fare'] = test['Fare'].astype(int)","ea1281d1":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]\n\ntrain['Cabin'].value_counts()","e227abcb":"df = round((train.groupby('Cabin')['Survived'].sum() \/ len(train.loc[(train['Survived'] == 1) & (~train['Cabin'].isnull())])) * 100, 2)\ndf.sort_values(ascending=False)","792ba975":"bar_chart('Cabin')","c345374a":"P1 = train[train['Pclass'] == 1]['Cabin'].value_counts()\nP2 = train[train['Pclass'] == 2]['Cabin'].value_counts()\nP3 = train[train['Pclass'] == 3]['Cabin'].value_counts()\n\ndf = pd.DataFrame([P1, P2, P3])\ndf.index = ['Pclass 1', 'Pclass 2', 'Pclass 3']\ndf.plot(kind='bar', stacked=True, figsize=(10, 5))","642bb72d":"ES = train[train['Embarked'] == 'S']['Cabin'].value_counts()\nEC = train[train['Embarked'] == 'C']['Cabin'].value_counts()\nEQ = train[train['Embarked'] == 'Q']['Cabin'].value_counts()\n\ndf = pd.DataFrame([ES, EC, EQ])\ndf.index = ['S', 'C', 'Q']\ndf.plot(kind='bar', stacked=True, figsize=(10, 5))","b2b78d63":"facet = sns.FacetGrid(train, hue=\"Cabin\",aspect=5)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()","7986b0ff":"cabin_mapping = {\"A\": 5, \"B\":2, \"C\": 1, \"D\": 3, \"E\": 4, \"F\": 5, \"G\": 5, \"T\": 5}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)\n    \ntrain.head()","fed7d6a5":"sex_params = {'male': 0, 'female': 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_params)","8d37ff6e":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","08cb65e7":"# features_drop = ['Name', 'Ticket']\nfeatures_drop = ['Name', 'Ticket']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)\n\n","389ec115":"train.head()","d234266a":"test.head()","649b4926":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nsurvived = train['Survived']\ncabin_train = train.loc[~train['Cabin'].isna(), train.columns].drop('Survived', axis=1)\ncabin_null_train = train.loc[train['Cabin'].isna(), train.columns].drop(['Cabin', 'Survived'], axis=1)\n\npassengerId = test['PassengerId']\ncabin_test = test.loc[~test['Cabin'].isna(), test.columns].drop('PassengerId', axis=1)\ncabin_null_test = test.loc[test['Cabin'].isna(), test.columns].drop(['Cabin', 'PassengerId'], axis=1)\n\nX = pd.concat([cabin_train, cabin_test], axis=0)\n\ny = X['Cabin']\nX.drop(['Cabin'], axis=1, inplace=True)\n\n# Random Forest Classifier\nrfc = RandomForestClassifier(n_estimators=500,max_depth=16)\npredicted_values = rfc.fit(X, y).predict(X)\n\nf1 = round(f1_score(y, predicted_values, average='micro'), 2)\naccuracy = round(accuracy_score(y, predicted_values), 2)\nprecision = round(precision_score(y, predicted_values, average='micro'), 2)\nrecall = round(recall_score(y, predicted_values, average='micro'), 2)\nprint(\"Accuracy: {} | Precision: {} | Recall: {} | F1: {} \".format(accuracy, precision, recall, f1))\n\npreds = rfc.predict(cabin_null_train)\ncabin_null_train['Cabin'] = preds\ntrain = pd.concat([cabin_train, cabin_null_train], axis=0)\ntrain = pd.concat([survived, train], axis=1).reset_index(drop=True)\ntrain.head()","c8f6cff0":"# prepare Test Data\npreds = rfc.predict(cabin_null_test)\ncabin_null_test['Cabin'] = preds\ntest = pd.concat([cabin_test, cabin_null_test], axis=0)\ntest = pd.concat([passengerId, test], axis=1).reset_index(drop=True)\ntest.head()","d836cdbf":"# from sklearn.feature_selection import chi2, SelectKBest\n# from sklearn.preprocessing import MinMaxScaler\n# import numpy as np\n\n# X = train.drop('Survived', axis=1)\n# y = train['Survived']\n# x_cols = X.columns\n\n# _scaler = MinMaxScaler()\n# X = _scaler.fit_transform(X)\n\n\n# _selector_kbest = SelectKBest(chi2, k='all')\n# selected_features_kbest = []\n\n# _selector_kbest.fit(X, y)\n# selected_features_kbest.append(list(_selector_kbest.scores_))\n\n# selected_features_kbest = np.mean(selected_features_kbest, axis=0)\n# thresh = np.quantile(selected_features_kbest, 0.25)\n# selected_features_kbest = [x_cols[i] for i, score in enumerate(selected_features_kbest) if score > thresh]\n\n# print('Total Features Selected: {}\/{}'.format(len(selected_features_kbest), len(x_cols)))\n# print(selected_features_kbest)","f57d778f":"# sur = train['Survived']\n# pas = test['PassengerId']\n\n# train = train.loc[:, selected_features_kbest]\n# train['Survived'] = sur\n\n# test = test.loc[:, selected_features_kbest]\n# test['PassengerId'] = pas","118be360":"train.head()","8d7168d1":"test.head()","e51c189d":"# def onehotencode(df):\n#     pclass = pd.get_dummies(df['Pclass'], prefix='Pclass')\n#     cabin = pd.get_dummies(df['Cabin'], prefix='Cabin')\n#     title = pd.get_dummies(df['Title'], prefix='Title')\n#     embarked = pd.get_dummies(df['Embarked'], prefix='Embarked')\n    \n#     df2 = pd.concat([pclass, cabin, title, embarked], axis=1)\n#     return df2\n\n# train_encodings = onehotencode(train)\n# test_encodings = onehotencode(test)\n\n# train = pd.concat([train, train_encodings], axis=1)\n# test = pd.concat([test, test_encodings], axis=1)\n\n# features_drop = ['Pclass', 'Cabin', 'Title', 'Embarked']\n# train.drop(features_drop, axis=1, inplace=True)\n# test.drop(features_drop, axis=1, inplace=True)","984c1a8c":"train.head()","4640cfcc":"test.head()","435f81b7":"train.to_csv('.\/train_cleaned.csv', index=False)\ntest.to_csv('.\/test_cleaned.csv', index=False)","556a9e3b":"## Exploring Name, Ticket and Cabin","5a542e1a":"### Alone","9d901d83":"# Chi-squared based Features Selection ","4561d9af":"## Observations\n1. Every Passenger has a unique name which do not contribute to the survival rate. But later, we will do some feature engineering to make it useful.\n2. Similarly, there are very less tickets which are shared and most of them are unique.\n3. This is the same for the Cabin, since it has 70% missing values, we can eliminate it.","ee8dba44":"# Loading the Data","64be9ed4":"## Observations\n1. We can see that Embarked feature has almost the same numbers in first three plots. It means that Embarked doesn't contribute much towards the survival rate, whether it's C, Q or S, they all have the same impact.\n2. In the last plot, we can see that passengers from all three Pclasses has almost the same distribution of Port of Embarkation.\n3. We can either eliminate this feature or we can leave it as it as. \n4. There are two missing values for Embarked feature, we can fill them with the most frequent (S)","d910026a":"### Embarked\nFilling missing Embarked Value (only 2)","65d2be0d":"Let's Convert the Family into three categories based on the above plot e.g. alone, couple, small, medium and large","25ffdf6b":"# Feature Engineering","f4bf29c9":"### Focusing on the Fare from 0 to 100","4c903434":"### Let's find the impact of cabin missing and non-missing values on the Survival Rate","9786351d":"## Cabin\nAlthough from our previous observations, almost all known Cabin values are unique but further analysis shows that Cabins have few categories calssified into unique numbers. The category of Cabin can be identified from the first letter. Let's explore that !!!","e06c3e87":"### Cheking Cabin relation with Pclass","49d49c9b":"### Observations\nHere, we can see that the most of the known Cabins belongs to Pclass 1. Further, Cabin A, B, C, D and E holds alomst all of the space. We can fill missing Cabin vaues based on Pclass. Let's move further.","61103cbb":"## Fare","bbecc433":"# Titanic: Machine Learning from Disaster","4df7fd40":"## Mapping string vaues to Numerical","8838300c":"## Observations\n1. We have 687\/891 values missing for Cabin. Hence, it can be dropped of the dataset\n2. We have 177\/891 values missing for Age. We need to fill them with appropriate values\n3. Age and Fare has numeric float values\n4. All other are numeric categorical, nominal or arbitrary. We will see them later","938a51d2":"Ooh ! we have found something very interesting ... passenger who's Cabin is knows have survived liek 87% while the Cabin for almost all passengers who died is unknown. That means, if the Cabin is not known, there are higher chances that the passenger is dead.","288435ab":"### Now let's change the Cabin into numeric\n\nWe will fill Cabin values based on Machine Learning Model prediction in the later sections","0c886b58":"## Introducing New Features","af145051":"## Droping Unnecessary Features\n\nWe will drop Name, Ticket, SibSp and Parch from both of the dataset. We will only remove PassengerId from the train dataset because we'll need it in test dataset for submission.","e7aacd3d":"Let's check the contribution of Cabins on the Survival Rate in Percentage","e0d740d9":"## Relation of Embarkation Port with Pclass and its impact on the Survival Rate","38655260":"### Embarked Mapping","8424042d":"## Coverting Continuous Values into Categorical\n\nLet's first convert the continuous data for Age and Fare into categorical based on our observations. Categorical data is easy for a machine learning to understand and interpret. We will do this for both, train and test data.","7637b48f":"## Filling Missing Values\nWe have missing values for Age, Fare, Cabin and Embarked from our analysis. We will fill the missing values for Age based on the Title of a passenger we extracted before by taking the median value of all ages which lie in that Title category. ","355f0139":"### Sex","2f2ac3b9":"### Observations\n1. Passengers ranging from 0 to 17 have high changes to survive\n2. Passengers ranging from 17 to 32 have very low chances to survive","e5f5e429":"### Sex","7b5fab78":"### Fare\nFilling Missing values for Fare but let's first find the relation of fare with Pclass. We observe than Pclass 1 has fare category 5 which is between 45 and 60 Pounds. Pclass 1 has the highest fare as compared to Pclass 2 and 3. Hence, we'll fill the missing values based on Pclass.","3bbec846":"# Filling Cabin Values with Model Predictions","aae54c20":"All Values have been filled now. Let's move further towards SibSp and Parch","468a2494":"## Let's now check the impact of features on the survival rate","bbf67694":"## Let's check the dataset info and missing values","e9b5371a":"## Observations\n1. We can change Age and Fare into categorical data based on their distribution","cf7fde36":"### Age","1b4ca5a0":"1. Passenger in Pclass 1 has survived more than other Pclasses\n2. Passenger in Pclass 3 has died more than other Pclasses\n3. Passenger in Pclass 3 have greater number than other Pclasses\n4. Passenger in Pclass 2 are almost equal in both, survived and died","169e195e":"# One Hot Encoding\nAlthough, we now have a very clean datasets and ready to feed into a machine learning model but there's still some points we should take care of. In our dataset, we have sucessfully converted all features into categorical order but some of them have ranks e.g. Fare equals 1 is less than Fare equals 2. Similarly for Age and Family, we have some realtions between the numbers.\n\nOn the other hand, features like Pclass, Title, Embarked and Cabin do not have relation between their values. They just indicates the type of the feature, not ranks. It's possible that our machine learning model misunderstand those ranked values with unranked ones. Hence we need to apply One Hot Encoding to unranked featuers.\n\n<img src='.\/onehotencode.png'>","f8d0948e":"Now let's change these into titles into more generic form. We will make 5 categories of them and we'll convert them into numeric values.","bc821356":"RMS Titanic was a British passenger liner operated by the White Star Line that sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, after striking an iceberg during her maiden voyage from Southampton to New York City. Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, making the sinking one of modern history's deadliest peacetime commercial marine disasters. RMS Titanic was the largest ship afloat at the time she entered service and was the second of three Olympic-class ocean liners operated by the White Star Line. She was built by the Harland and Wolff shipyard in Belfast. Thomas Andrews, chief naval architect of the shipyard at the time, died in the disaster.(Source: Wikipedia)\n\n<img src=\"https:\/\/camo.githubusercontent.com\/e15a5414be97decd975cfed68e0c0f79e768f7e7\/68747470733a2f2f737461746963312e73717561726573706163652e636f6d2f7374617469632f3530303634353366653462303965663232353262613036382f742f3530393062323439653462303437626135346466643235382f313335313636303131333137352f544974616e69632d537572766976616c2d496e666f677261706869632e6a70673f666f726d61743d3135303077\">","afaa1bf3":"## SibSp and Parch","7ee43682":"## Columns Description\n1. Survivded: This is our target variable. We have to find whether a person has survived or not (0: dead, 1: survived)\n2. PassengerId: Arbitrary ID which doesn't contribute in survival rate\n3. Pclass: Class for a passenger in the ship e.g. business classs, economy class\n4. Name: Full names of passengers\n5. Sex: Sex of passengers (male, female)\n6. Age: Age of passengers given in years\n7. SibSp: Number of siblings\/Spouse aboard for a passenger\n8. Parch: Number of parents\/children aboard for a passenger\n9. Ticket: Ticket number\n10. Fare: Fare for the trip\n11. Cabin: Cabin number inside Pclass\n12. Embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","7bea3917":"### Pclass","d3c923ef":"# Exploratory Data Analysis (EDA)","8523ca4d":"### Observations\n1. We can see that both columns has almost the same impact on the survival rate. People with SibSp\/Parch number zero (alone) have greater number and have higher chances to die.\n2. Passengers who are not alone have higher chances to survive.\n3. As these columns has similar impact, we can merge them together into one feature. We will do that later in Feature Engineering Section","cdd558fc":"# Saving Cleaned Datasets\n\nOur data now is ready to feed into a machine learning model for training and testing.","5fa28a59":"### Age","6f7e4b2f":"### Family Size\nFrom EDA, we analysed that SibSp and Parch has almost the same impact on the survival rate. Hence, we need to merge these two features into one named Family","e4f9aad6":"### Title\nWe can extract the titles like Mr. Mrs. Dr. etc. from the names to make this feature useful. Let's explore if the titles contribute in predicting survival rate"}}