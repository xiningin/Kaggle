{"cell_type":{"74b7e568":"code","824751cf":"code","6d74b367":"code","3faa30ba":"code","4b72e918":"code","d470deab":"code","ada2a483":"code","9b29cb6d":"code","c8b03522":"code","b311e619":"code","a2924648":"code","4efdf68e":"code","5107325e":"code","c8cbfc78":"code","34236a3b":"code","fed948c1":"code","88dbf4e9":"code","8163f667":"code","209fef9b":"code","de02c7f1":"code","25d7f5da":"code","3b1d7f79":"code","4037d9f4":"code","28d4f123":"code","293cb8a7":"code","64a716e1":"code","e57c1de3":"code","990de1a3":"code","a7c4ad34":"code","0ba62f78":"code","c41d9d47":"code","ccf55f49":"code","179a7f6f":"code","3d2e4fd4":"code","45d55838":"code","47fe8a44":"code","cafff940":"code","22530e12":"code","6e9793f1":"code","a9adb042":"code","bf52a9fc":"code","eabd91ff":"code","b88ab47c":"code","13f56c9d":"code","ef6cf032":"code","84f3cfe1":"code","d640b99f":"code","0190352c":"code","cd5cd733":"markdown","7fd1d557":"markdown","a9dd7296":"markdown","9f612a9a":"markdown","7df7811b":"markdown","9efc0a23":"markdown","357ca9a4":"markdown","13716da9":"markdown","318eb78a":"markdown","ceaeee7c":"markdown","0c1f4745":"markdown","ad39dc2e":"markdown","e96e2678":"markdown","cebe3b53":"markdown","ef6fa37c":"markdown","d74a59d3":"markdown","4e7e9a95":"markdown","db785210":"markdown","21d6985e":"markdown","b8bbc514":"markdown","256baf48":"markdown","c0aca11c":"markdown","429647f4":"markdown","58c101ab":"markdown","387cd7bf":"markdown","067a0b79":"markdown","63b3a4a5":"markdown","47003659":"markdown","e3377d91":"markdown","dfebe1b1":"markdown","044a0a84":"markdown","d7ead301":"markdown","a3c1190c":"markdown","261c792d":"markdown","24205e54":"markdown","19fdfd9c":"markdown","fd39d280":"markdown","073aec25":"markdown","5bbf217a":"markdown"},"source":{"74b7e568":"# load the libraries\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","824751cf":"# read data\nrawdf = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv\")","6d74b367":"#see the head of data\nrawdf.head()","3faa30ba":"# get the data types of all features\nrawdf.dtypes","4b72e918":"#get integer data types\nrawdf.dtypes[rawdf.dtypes==\"int64\"]","d470deab":"# Driving_License, Previously_Insured,Response is a categorical varriable so we convert it into category\nrawdf[\"Driving_License\"] = rawdf[\"Driving_License\"].astype(\"category\") \nrawdf[\"Previously_Insured\"] = rawdf[\"Previously_Insured\"].astype(\"category\") \nrawdf[\"Driving_License\"] = rawdf[\"Driving_License\"].astype(\"category\") \nrawdf[\"Response\"] = rawdf[\"Response\"].astype(\"category\")","ada2a483":"# get float data types \nrawdf.dtypes[rawdf.dtypes == \"float64\"]","9b29cb6d":"#Region code , Policy Sales Channel are categorical varriables\nrawdf[\"Region_Code\"] = rawdf[\"Region_Code\"].astype(\"category\")\nrawdf[\"Policy_Sales_Channel\"] = rawdf[\"Policy_Sales_Channel\"].astype(\"category\")","c8b03522":"#vehicle age and vehicle damage is object varriable\nrawdf.dtypes[rawdf.dtypes==\"object\"]","b311e619":"# gender, vehicle age , vehicle damage are categorical varriables\nrawdf[\"Gender\"] = rawdf[\"Gender\"].astype(\"category\")\nrawdf[\"Vehicle_Age\"] = rawdf[\"Vehicle_Age\"].astype(\"category\")\nrawdf[\"Vehicle_Damage\"] = rawdf[\"Vehicle_Damage\"].astype(\"category\")","a2924648":"rawdf.dtypes","4efdf68e":"# describe of all numeric values\nrawdf.describe()","5107325e":"rawdf[\"Vehicle_Damage\"].describe()","c8cbfc78":"def UVA_numeric(data, var_group):\n  ''' \n  Univariate_Analysis_numeric\n  takes a group of variables (INTEGER and FLOAT) and plot\/print all the descriptives and properties along with KDE.\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot\/print it\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,3), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    mini = data[i].min()\n    maxi = data[i].max()\n    ran = data[i].max()-data[i].min()\n    mean = data[i].mean()\n    median = data[i].median()\n    st_dev = data[i].std()\n    skew = data[i].skew()\n    kurt = data[i].kurtosis()\n\n    # calculating points of standard deviation\n    points = mean-st_dev, mean+st_dev\n\n    #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.kdeplot(data[i], shade=True)\n    sns.lineplot(points, [0,0], color = 'black', label = \"std_dev\")\n    sns.scatterplot([mini,maxi], [0,0], color = 'orange', label = \"min\/max\")\n    sns.scatterplot([mean], [0], color = 'red', label = \"mean\")\n    sns.scatterplot([median], [0], color = 'blue', label = \"median\")\n    plt.xlabel('{}'.format(i), fontsize = 20)\n    plt.ylabel('density')\n    plt.title('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n                                                                                                   round(kurt,2),\n                                                                                                   round(skew,2),\n                                                                                                   (round(mini,2),round(maxi,2),round(ran,2)),\n                                                                                                   round(mean,2),\n                                                                                                   round(median,2)))","34236a3b":"# get numeric varriables\nrawdf.select_dtypes(include=['int64','float64','Int64']).dtypes","fed948c1":"#Segregating varriables into groups\ncustomer_details = [\"Age\",\"Vintage\"]","88dbf4e9":"UVA_numeric(rawdf,customer_details)","8163f667":"UVA_numeric(rawdf,[\"Annual_Premium\"])","209fef9b":"def UVA_category(data, var_group):\n\n  '''\n  Univariate_Analysis_categorical\n  takes a group of variables (category) and plot\/print all the value_counts and barplot.\n  '''\n  # setting figure_size\n  size = len(var_group)\n  plt.figure(figsize = (7*size,5), dpi = 100)\n\n  # for every variable\n  for j,i in enumerate(var_group):\n    n_uni = data[i].nunique()\n    if n_uni > 20:\n        norm_count1 = data[i].value_counts(normalize = True)\n        norm_count = norm_count1.sort_values().tail(20) \n    else:\n        norm_count = data[i].value_counts(normalize = True)\n    \n\n  #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.barplot(norm_count, norm_count.index , order = norm_count.index)\n    plt.xlabel('fraction\/percent', fontsize = 20)\n    plt.ylabel('{}'.format(i), fontsize = 20)\n    plt.title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,norm_count))","de02c7f1":"rawdf.select_dtypes(include=[\"category\"]).dtypes","25d7f5da":"# top 53 region code are taken\nUVA_category(rawdf,[\"Gender\",\"Driving_License\",\"Region_Code\"])","3b1d7f79":"UVA_category(rawdf,[\"Vehicle_Age\",\"Vehicle_Damage\"])","4037d9f4":"UVA_category(rawdf,[\"Policy_Sales_Channel\",\"Previously_Insured\"])","28d4f123":"UVA_category(rawdf,[\"Response\"])","293cb8a7":"rawdf.isnull().sum()","64a716e1":"# custom function for easy outlier analysis\n\ndef UVA_outlier(data, var_group, include_outlier = True):\n  '''\n  Univariate_Analysis_outlier:\n  takes a group of variables (INTEGER and FLOAT) and plot\/print boplot and descriptives\\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot\/print it \\n\\n\n\n  data : dataframe from which to plot from\\n\n  var_group : {list} type Group of Continuous variables\\n\n  include_outlier : {bool} whether to include outliers or not, default = True\\n\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,4), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    quant25 = data[i].quantile(0.25)\n    quant75 = data[i].quantile(0.75)\n    IQR = quant75 - quant25\n    med = data[i].median()\n    whis_low = med-(1.5*IQR)\n    whis_high = med+(1.5*IQR)\n\n    # Calculating Number of Outliers\n    outlier_high = len(data[i][data[i]>whis_high])\n    outlier_low = len(data[i][data[i]<whis_low])\n\n    if include_outlier == True:\n      print(include_outlier)\n      #Plotting the variable with every information\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('With Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low\/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))\n      \n    else:\n      # replacing outliers with max\/min whisker\n      data2 = data[var_group][:]\n      data2[i][data2[i]>whis_high] = whis_high+1\n      data2[i][data2[i]<whis_low] = whis_low-1\n      \n      # plotting without outliers\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data2[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low\/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))","e57c1de3":"UVA_outlier(rawdf,[\"Annual_Premium\",\"Age\",\"Vintage\"] )","990de1a3":"numerical_data = rawdf.select_dtypes(include=[\"int64\",\"Int64\",\"float64\"])\nnumerical_data.corr()","a7c4ad34":"# plotting heatmap usill all methods for all transaction variables\nplt.figure(figsize=(36,6), dpi=140)\nfor j,i in enumerate(['pearson']):\n  plt.subplot(1,3,j+1)\n  correlation = numerical_data.dropna().corr(method=i)\n  sns.heatmap(correlation, linewidth = 2)\n  plt.title(i, fontsize=18)","0ba62f78":"# scatter plot for all numerical varriables\nplt.figure(dpi=140)\nsns.pairplot(numerical_data)","c41d9d47":"def TwoSampZ(X1, X2, sigma1, sigma2, N1, N2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sampled Z-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import norm\n  ovr_sigma = sqrt(sigma1**2\/N1 + sigma2**2\/N2)\n  z = (X1 - X2)\/ovr_sigma\n  pval = 2*(1 - norm.cdf(abs(z)))\n  return pval","ccf55f49":"def TwoSampT(X1, X2, sd1, sd2, n1, n2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sample T-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import t as t_dist\n  ovr_sd = sqrt(sd1**2\/n1 + sd2**2\/n2)\n  t = (X1 - X2)\/ovr_sd\n  df = n1+n2-2\n  pval = 2*(1 - t_dist.cdf(abs(t),df))\n  return pval","179a7f6f":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'not {}'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')\n  ","3d2e4fd4":"Bivariate_cont_cat(rawdf, 'Vintage', 'Response', 1)","45d55838":"Bivariate_cont_cat(rawdf, 'Age', 'Response', 1)","47fe8a44":"Bivariate_cont_cat(rawdf, 'Annual_Premium', 'Response', 1)","cafff940":"def BVA_categorical_plot(data, tar, cat):\n  '''\n  take data and two categorical variables,\n  calculates the chi2 significance between the two variables \n  and prints the result with countplot & CrossTab\n  '''\n  #isolating the variables\n  data = data[[cat,tar]][:]\n\n  #forming a crosstab\n  table = pd.crosstab(data[tar],data[cat],)\n  f_obs = np.array([table.iloc[0][:].values,\n                    table.iloc[1][:].values])\n\n  #performing chi2 test\n  from scipy.stats import chi2_contingency\n  chi, p, dof, expected = chi2_contingency(f_obs)\n  \n  #checking whether results are significant\n  if p<0.05:\n    sig = True\n  else:\n    sig = False\n\n  #plotting grouped plot\n  sns.countplot(x=cat, hue=tar, data=data)\n  plt.title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n\n  #plotting percent stacked bar plot\n#   sns.catplot(ax, kind='stacked')\n  ax1 = data.groupby(cat)[tar].value_counts(normalize=True).unstack()\n  ax1.plot(kind='bar', stacked='True',title=str(ax1))\n  int_level = data[cat].value_counts()","22530e12":"BVA_categorical_plot(rawdf, \"Response\",\"Driving_License\")","6e9793f1":"BVA_categorical_plot(rawdf, \"Response\",\"Previously_Insured\")","a9adb042":"BVA_categorical_plot(rawdf, \"Response\",\"Vehicle_Damage\")","bf52a9fc":"BVA_categorical_plot(rawdf, \"Response\",\"Vehicle_Age\")","eabd91ff":"BVA_categorical_plot(rawdf, \"Response\",\"Gender\")","b88ab47c":"# Sales Channel wise Total Customers Count\npsc_total = rawdf.groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False)\npsc_total","13f56c9d":"# filter interested customers count \nFormattedData = rawdf[rawdf[\"Response\"]==1].groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False) \n\nFormattedData[\"total_count\"] = psc_total[\"count\"]\nFormattedData[\"success_rate\"] = (FormattedData[\"count\"]\/FormattedData[\"total_count\"])*100 \nFormattedData[FormattedData[\"total_count\"]>500].sort_values(\"success_rate\",ascending=False).head(50)","ef6cf032":"# Sales Channel wise Total Customers Count\npsc_total = rawdf.groupby(\"Region_Code\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False)\npsc_total.head(50)","84f3cfe1":"# filter interested customers count \nFormattedData = rawdf[rawdf[\"Response\"]==1].groupby(\"Region_Code\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False) \n\nFormattedData[\"total_count\"] = psc_total[\"count\"]\nFormattedData[\"success_rate\"] = (FormattedData[\"count\"]\/FormattedData[\"total_count\"])*100 \nFormattedData[FormattedData[\"total_count\"]>500].sort_values(\"success_rate\",ascending=False).head(51)","d640b99f":"FormattedData[FormattedData[\"total_count\"]>10000].sort_values(\"success_rate\",ascending=False)","0190352c":"# average success rate is less\nFormattedData[\"success_rate\"].mean()","cd5cd733":"#### summary\n* Most of the customers Age between 20 to 30 and 40 to 50 some peak there.\n* vintage is normaly distributed. Average vintage value is 150\n* Annual Premium is Highly skewed and also more kurtosis value so it has a extreme outliers ","7fd1d557":"### Inference\n* significant differnece is there.But 99%(univariate analysis) customers has a license, In that only 1 % customers are interested others are not interested  ","a9dd7296":"## Bivariate Analysis(categorical categorical)","9f612a9a":"### Are **vintage customers** interested in insurance?","7df7811b":"## Bivariate Analysis: Continuous-Categorical variables","9efc0a23":"### summary\n* In univarite Analysis, Already we have seen Policy sales channel 152 has a more entry","357ca9a4":"### Are customers with **low annual premium**,   **Interested** in insurance ?","13716da9":"# Univariate Analysis","318eb78a":"# Bivariate Analysis","ceaeee7c":"### Inference\n* Annual premium mean for interested customer is 30419\n* Annual premium mean for not interested customer is 31604\n* Annual Premium makes impact on customer interest\n","0c1f4745":"### Bivariate Analysis(Region_code vs Response)","ad39dc2e":"### Are aged customers interested in insurance?","e96e2678":"### summary\n\n* Features dont have a strong correlation\n\n","cebe3b53":"* Male customers has more interest in insurance. ","ef6fa37c":"### Integer Data type","d74a59d3":"### summary\n*  High total customers and succes rate plac is 28\n*  low success rate and high customers count, places(50,15,30,8,9) \n* Region code affects the customer interest but average success rate of all region is less.","4e7e9a95":"#### summary\n* Most of the customers not interested in insurance\n* 99% customers are licensed  and 87% customers are not interested in insurance. so hyposthesis \" **licensed customer** **interested** in insurance\" is false   \n* Imbalanced target Varriable ","db785210":"# Exploratory  Data Analysis","21d6985e":"### summary\n* No significant difference in vintage customers . so reject this hypothesis \n* both interested and no interested customers mean vintage is approxiamately same. no significant difference is there.so vintage has no impact on customer interest\n* No outliers ","b8bbc514":"# Univariate - Missing Values and Outlier Analysis","256baf48":"### summary\n* 95% Vechicle's age \"within 2 years\"\n* Vehicle Damage is equally splitted","c0aca11c":"### Univariate Analysis Integer","429647f4":"### summary\n* Annual premium has a extreme outlier","58c101ab":"### summary\n* policy sales channel 155 has high success rate(32%) when compared to other channels.\n* policy sales channel 26 has a more intersted customers. but success rate is 19%\n","387cd7bf":" ### Inference\n * Interested Customers age between 35 to 52.\n * Uninterested Customers age between 25 to 48.\n * p-value of z and t tests  is 0 , so significant difference there. It indicates age makes a impact on customer interest\n \n ","067a0b79":"### summary\n* Male customers higher than Female\n* 99 % customers has a License\n* Region Code 28 has a high number of customers\n* Region Code 8, 46, 41 has a second high number of customers","63b3a4a5":"This is My first EDA Notebook , So give a comment if i have done any mistakes in this EDA. \nI have tried EDA for following Analytics Vidya Problem \nhttps:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-cross-sell-prediction\/#ProblemStatement\n\nYour client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.","47003659":"### Inference\n* Vehicle damaged customers has a interest in insurance ","e3377d91":"### ScatterPlot","dfebe1b1":"## *Hypothesis*\n* Are customers with **low annual premium**,   **Interested** in insurance ?  \n* Are **vintage customers** intersted in insurance?\n* Are **Licensed customers** **interested** in insurance\n* Are customers **interested** in insurance  **when vehicle has a damage**\n* Are Customers **interested** in insurance when **vehicle age <1 year(new bike)**\n* Are **previously insured** customers, **not interested** in insurance\n","044a0a84":"### Float data type","d7ead301":"### Inference\n* Overall vehicle Age 1-2 year category , interested customer's count is high.but\n* In >2 year Age category, Interested customers percentage is high when compared to other category   ","a3c1190c":"# Varriable Identification and TypeCasting","261c792d":"### Object data type","24205e54":"### summary\n* Most used ploicy sales channel code(152,26,124,160,156,122,157,154)\n* Previously Insured people was less","19fdfd9c":"### Bivariate Analysis - Policy_Sales_Channel vs Response","fd39d280":"### Are licensed customer has a more interest?","073aec25":"### Inference\n* Previously Insured customers not interested in insurance","5bbf217a":"### Univariate Analysis - Category"}}