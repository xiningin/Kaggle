{"cell_type":{"de6893d9":"code","e4fabae4":"code","236b6c93":"code","d2f9adac":"code","1ec402a2":"code","803a8b47":"code","afa56565":"code","e550c6e6":"code","f9d45ef6":"code","f3463068":"code","c40a8f95":"code","d5c811fc":"code","41673d36":"code","441f508c":"code","6685e727":"code","f59dbccd":"code","f24ff697":"code","16ea2a43":"code","e643bf65":"code","a4fa188f":"code","cf5fb767":"code","58dfbcd9":"code","a94420d2":"code","3a4f93ad":"code","5a9770c1":"code","a2cd2594":"code","d902df59":"code","cd79a109":"code","4ea8d78c":"markdown","c277dbdd":"markdown","85c652ad":"markdown","6859a46e":"markdown","f87b1dbf":"markdown","a8a94826":"markdown","9bc5dfc1":"markdown","f73aa3ea":"markdown","535dde43":"markdown","0ad4d877":"markdown","d218c9c3":"markdown","b85bc0c8":"markdown","c00fc499":"markdown","22dd5fa2":"markdown","79cf8fd2":"markdown","ed0d0996":"markdown","8d0aa2be":"markdown","aa3fcb23":"markdown","638718d4":"markdown","b4315e34":"markdown","cbda545a":"markdown","ef9b7be1":"markdown","fff58733":"markdown","46217431":"markdown","fef33920":"markdown","79b04908":"markdown","11850211":"markdown","0b71565d":"markdown"},"source":{"de6893d9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler , LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import mode\n\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.utils import to_categorical\n\nfrom matplotlib import ticker\nimport time\nimport warnings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')","e4fabae4":"train = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv\")\n\n\ntrain.drop([\"Id\"] , axis = 1 , inplace = True)\ntest.drop([\"Id\"] , axis = 1 , inplace = True)\nTARGET = 'Cover_Type'\nFEATURES = [col for col in train.columns if col not in ['id', TARGET]]\nRANDOM_STATE = 10","236b6c93":"print(f'Number of rows in train data: {train.shape[0]}')\nprint(f'Number of columns in train data: {train.shape[1]}') \nprint(f'No of missing values in train data: {sum(train.isna().sum())}')\n\ntrain_misscnt = train.isnull().sum(axis = 1).value_counts()\ntrain_misscnt","d2f9adac":"print(f'Number of rows in test data: {test.shape[0]}')\nprint(f'Number of columns in test data: {test.shape[1]}')\nprint(f'No of missing values in test data: {sum(test.isna().sum())}')\n\ntest_misscnt = train.isnull().sum(axis = 1).value_counts()\ntest_misscnt","1ec402a2":"submission.head()","803a8b47":"# https:\/\/www.kaggle.com\/odins0n\/tps-dec-eda-modeling\nTrain_Describe = train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='Accent')\\\n                     .bar(subset=[\"max\"], color='#DD462B')\\\n                     .bar(subset=[\"mean\",], color='#2BAADD')\nTrain_Describe","afa56565":"#https:\/\/www.kaggle.com\/andrej0marinchenko\/tps12-21-data-visualization\nfrom tqdm import tqdm  # progressbar decorator for iterators\ncols=train.columns.tolist()\nfig, ax = plt.subplots(5,2,figsize=(16,25))\nfor i in tqdm(range(10)):\n    if i<11:\n        r=i\/\/2\n        c=i%2\n        sns.histplot(train[train.Cover_Type==1][cols[i]], label=cols[i]+' Cover_Type=1', ax=ax[r,c], color='#73c6b6',bins=20)\n        sns.histplot(train[train.Cover_Type==2][cols[i]], label=cols[i]+' Cover_Type=2', ax=ax[r,c], color='#FF5733',bins=20)\n        sns.histplot(train[train.Cover_Type==3][cols[i]], label=cols[i]+' Cover_Type=3', ax=ax[r,c], color='#DAF7A6',bins=20)\n        sns.histplot(train[train.Cover_Type==4][cols[i]], label=cols[i]+' Cover_Type=4', ax=ax[r,c], color='#FFC300',bins=20)\n        sns.histplot(train[train.Cover_Type==5][cols[i]], label=cols[i]+' Cover_Type=5', ax=ax[r,c], color='#C70039',bins=20)\n        sns.histplot(train[train.Cover_Type==6][cols[i]], label=cols[i]+' Cover_Type=6', ax=ax[r,c], color='#900C3F',bins=20)\n        sns.histplot(train[train.Cover_Type==7][cols[i]], label=cols[i]+' Cover_Type=7', ax=ax[r,c], color='#17202A',bins=20)\n        ax[r,c].legend()\n        ax[r,c].grid()\n    else:\n        r=i\/\/2\n        c=i%2\n        ax[r,c].axis(\"off\")\n\nplt.show()\n\n# cols=train.columns.tolist()\n# fig, ax = plt.subplots(28,2,figsize=(16,80))\n# for i in tqdm(range(55)):\n#     if i<55:\n#         r=i\/\/2\n#         c=i%2\n#         sns.histplot(train[train.Cover_Type==1][cols[i]], label=cols[i]+' Cover_Type=1', ax=ax[r,c], color='#73c6b6',bins=20)\n#         sns.histplot(train[train.Cover_Type==2][cols[i]], label=cols[i]+' Cover_Type=2', ax=ax[r,c], color='#FF5733',bins=20)\n#         sns.histplot(train[train.Cover_Type==3][cols[i]], label=cols[i]+' Cover_Type=3', ax=ax[r,c], color='#DAF7A6',bins=20)\n#         sns.histplot(train[train.Cover_Type==4][cols[i]], label=cols[i]+' Cover_Type=4', ax=ax[r,c], color='#FFC300',bins=20)\n#         sns.histplot(train[train.Cover_Type==5][cols[i]], label=cols[i]+' Cover_Type=5', ax=ax[r,c], color='#C70039',bins=20)\n#         sns.histplot(train[train.Cover_Type==6][cols[i]], label=cols[i]+' Cover_Type=6', ax=ax[r,c], color='#900C3F',bins=20)\n#         sns.histplot(train[train.Cover_Type==7][cols[i]], label=cols[i]+' Cover_Type=7', ax=ax[r,c], color='#17202A',bins=20)\n#         ax[r,c].legend()\n#         ax[r,c].grid()\n#     else:\n#         r=i\/\/2\n#         c=i%2\n#         ax[r,c].axis(\"off\")\n\n# plt.show()\n","e550c6e6":"df = pd.concat([train[FEATURES], test[FEATURES]], axis=0)\n\ncat_features = [col for col in FEATURES if df[col].nunique() < 25]\n# 25\ubbf8\ub9cc\uc740 category\ud615\uc73c\ub85c \ubcf4\uaca0\ub2e4. \ncont_features = [col for col in FEATURES if df[col].nunique() >= 25]\n\ndel df\nprint(f'Total number of features: {len(FEATURES)}')\nprint(f'Number of categorical features: {len(cat_features)}')\nprint(f'Number of continuos features: {len(cont_features)}')\n\nplt.pie([len(cat_features), len(cont_features)], \n        labels=['Categorical', 'Continuos'],\n        colors=['#E74C3C', '#16A085'],\n        textprops={'fontsize': 13},\n        autopct='%1.1f%%')\nplt.show()","f9d45ef6":"# categorical \nncols = 5\nnrows = int(len(cont_features) \/ ncols + (len(FEATURES) % ncols > 0))-1\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 8), facecolor='#EAEAF2')\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = cont_features[r*ncols+c]\n        sns.kdeplot(x=train[col], ax=axes[r, c], color='#E74C3C', label='Train data') # sns \uc758 histogram \uac19\uc740 \uc2dc\uac01\ud654\n        sns.kdeplot(x=test[col], ax=axes[r, c], color='#16A085', label='Test data')\n        axes[r, c].set_ylabel('')\n        axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n        axes[r, c].tick_params(labelsize=5, width=0.5)\n        axes[r, c].xaxis.offsetText.set_fontsize(4)\n        axes[r, c].yaxis.offsetText.set_fontsize(4)\n\nplt.legend()        \nplt.show()","f3463068":"# Non-categorical \nif len(cat_features) == 0 :\n    print(\"No Categorical features\")\nelse:\n    ncols = 5\n    nrows = int(len(cat_features) \/ ncols + (len(FEATURES) % ncols > 0)) \n\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 45), facecolor='#EAEAF2')\n\n    for r in range(nrows):\n        for c in range(ncols):\n            if r*ncols+c >= len(cat_features):\n                break\n            col = cat_features[r*ncols+c]\n            sns.countplot(x=train[col], ax=axes[r, c], color='#E74C3C', label='Train data')\n            sns.countplot(x=test[col], ax=axes[r, c], color='#16A085', label='Test data')\n            axes[r, c].set_ylabel('')\n            axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n            axes[r, c].tick_params(labelsize=5, width=0.5)\n            axes[r, c].xaxis.offsetText.set_fontsize(4)\n            axes[r, c].yaxis.offsetText.set_fontsize(4)\n    plt.legend()\n    plt.show()","c40a8f95":"target_df = pd.DataFrame(train[TARGET].value_counts()).reset_index()\ntarget_df.columns = [TARGET, 'count']\nfig = px.bar(data_frame =target_df, \n             x = 'Cover_Type',\n             y = 'count' , \n             color = \"count\",\n             color_continuous_scale=\"balance\") \nfig.show()\ntarget_df.sort_values(by =TARGET , ignore_index = True)","d5c811fc":"train.loc[train['Cover_Type'] == 5]","41673d36":"train = train.drop(index = int(np.where(train[\"Cover_Type\"] == 5 )[0]))\ntrain = train.drop(labels = [\"Soil_Type7\" ,\"Soil_Type8\", \"Soil_Type15\"] ,axis = 1)\nFEATURES.remove('Soil_Type7')\nFEATURES.remove('Soil_Type8')\nFEATURES.remove('Soil_Type15')","441f508c":"train.corr(method = \"pearson\").style.background_gradient(cmap='YlOrRd')","6685e727":"# \ud655\uc778\ntarget_df = pd.DataFrame(train[TARGET].value_counts()).reset_index()\ntarget_df.columns = [TARGET, 'count']\ntarget_df.sort_values(by =TARGET , ignore_index = True)","f59dbccd":"train[\"mean\"] = train[FEATURES].mean(axis=1)\ntrain[\"std\"] = train[FEATURES].std(axis=1)\ntrain[\"min\"] = train[FEATURES].min(axis=1)\ntrain[\"max\"] = train[FEATURES].max(axis=1)\n\ntest[\"mean\"] = test[FEATURES].mean(axis=1)\ntest[\"std\"] = test[FEATURES].std(axis=1)\ntest[\"min\"] = test[FEATURES].min(axis=1)\ntest[\"max\"] = test[FEATURES].max(axis=1)\n\nFEATURES.extend(['mean', 'std', 'min', 'max'])","f24ff697":"scaler = StandardScaler()\nfor col in FEATURES:\n    train[col] = scaler.fit_transform(train[col].to_numpy().reshape(-1,1))\n    test[col] = scaler.transform(test[col].to_numpy().reshape(-1,1))\n    \nX = train[FEATURES].to_numpy().astype(np.float32)\ny = train[TARGET].to_numpy().astype(np.float32)\nX_test = test[FEATURES].to_numpy().astype(np.float32)\n\ndel train, test","16ea2a43":"lgb_params = {\n    'objective' : 'multiclass',\n    'metric' : 'multi_logloss',\n    'device' : 'gpu',\n}\n\n\nlgb_predictions = []\nlgb_scores = []\n\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X = X, y = y)):\n\n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    x_train = X[train_idx, :]\n    x_valid = X[valid_idx, :]\n    y_train = y[train_idx]\n    y_valid = y[valid_idx]\n    \n    model = LGBMClassifier(**lgb_params)\n    model.fit(x_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(x_valid, y_valid)],\n          verbose=0)\n    \n    preds_valid = model.predict(x_valid)\n    acc = accuracy_score(y_valid,  preds_valid)\n    lgb_scores.append(acc)\n    run_time = time.time() - start_time\n    print(f\"Fold={fold+1}, acc: {acc:.8f}, Run Time: {run_time:.2f}\")\n    test_preds = model.predict(X_test)\n    lgb_predictions.append(test_preds)\n    \nprint(\"Mean Accuracy :\", np.mean(lgb_scores))","e643bf65":"# \uc131\ub2a5 \ud3c9\uac00 \ubaa8\ub450 \uad6c\ud558\uae30 (priecision, recall\/sensitiveity\/RPR, specificity, FPR)\n\nprint(classification_report(y_valid,  preds_valid))","a4fa188f":"catb_params = {\n    \"objective\": \"MultiClass\",\n    \"task_type\": \"GPU\",\n}\n\ncatb_predictions = []\ncatb_scores = []\n\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X = X, y = y)):\n\n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    x_train = X[train_idx, :]\n    x_valid = X[valid_idx, :]\n    y_train = y[train_idx]\n    y_valid = y[valid_idx]\n    \n    model = CatBoostClassifier(**catb_params)\n    model.fit(x_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(x_valid, y_valid)],\n          verbose=0)\n    \n    preds_valid = model.predict(x_valid)\n    acc = accuracy_score(y_valid,  preds_valid)\n    catb_scores.append(acc)\n    run_time = time.time() - start_time\n    print(f\"Fold={fold+1}, acc: {acc:.8f}, Run Time: {run_time:.2f}\")\n    test_preds = model.predict(X_test)\n    catb_predictions.append(test_preds)\n    \nprint(\"Mean Accuracy:\", np.mean(catb_scores))","cf5fb767":"#\uc131\ub2a5 \ud3c9\uac00 \ubaa8\ub450 \uad6c\ud558\uae30 (priecision, recall\/sensitiveity\/RPR, specificity, FPR)\nprint(classification_report(y_valid,  preds_valid))","58dfbcd9":"xgb_params = {\n    'objective': 'multi:softmax',\n    'eval_metric': 'mlogloss',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    }\n\nxgb_predictions = []\nxgb_scores = []\n\nxgb_predictions = []\nxgb_scores = []\n\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X = X, y = y)):\n\n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    x_train = X[train_idx, :]\n    x_valid = X[valid_idx, :]\n    y_train = y[train_idx]\n    y_valid = y[valid_idx]\n    \n    model = XGBClassifier(**xgb_params)\n    model.fit(x_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(x_valid, y_valid)],\n          verbose=0)\n    preds_valid = model.predict(x_valid)\n    acc = accuracy_score(y_valid,  preds_valid)\n    xgb_scores.append(acc)\n    run_time = time.time() - start_time\n    print(f\"Fold={fold+1}, acc: {acc:.8f}, Run Time: {run_time:.2f}\")\n    test_preds = model.predict(X_test)\n    xgb_predictions.append(test_preds)\n    \nprint(\"Mean Accuracy:\", np.mean(xgb_scores))","a94420d2":"print(classification_report(y_valid,  preds_valid))","3a4f93ad":"LEARNING_RATE = 0.0001\nBATCH_SIZE = 2048\nEPOCHS = 100\nVALIDATION_RATIO = 0.05\n\nLE = LabelEncoder()\ny = to_categorical(LE.fit_transform(y))\nX_train , X_valid ,y_train ,y_valid  = train_test_split(X,y , test_size = VALIDATION_RATIO , random_state=RANDOM_STATE)\n\n\ndef load_model(): \n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(2048, activation = 'swish', input_shape = [X.shape[1]]),\n        tf.keras.layers.Dense(1024, activation ='swish'),\n        tf.keras.layers.Dense(512, activation ='swish'),\n        tf.keras.layers.Dense(6, activation='softmax'),\n    ])\n    model.compile(\n        optimizer= tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE),\n        loss='categorical_crossentropy',\n        metrics=['acc'],\n    )\n    return model\n    \n    \nearly_stopping = callbacks.EarlyStopping(\n        patience=10,\n        min_delta=0,\n        monitor='val_loss',\n        restore_best_weights=True,\n        verbose=0,\n        mode='min', \n        baseline=None,\n    )\nplateau = callbacks.ReduceLROnPlateau(\n            monitor='val_loss', \n            factor=0.2, \n            patience=4, \n            verbose=0,\n            mode='min')\n\nnn_model = load_model()\nhistory = nn_model.fit(  X_train , y_train,\n                validation_data = (X_valid , y_valid),\n                batch_size = BATCH_SIZE, \n                epochs = EPOCHS,\n                callbacks = [early_stopping , plateau],\n              )\nnn_preds = nn_model.predict(X_test , batch_size=BATCH_SIZE)","5a9770c1":"lgb_submission = submission.copy()\nlgb_submission['Cover_Type'] = np.squeeze(mode(np.column_stack(lgb_predictions),axis = 1)[0]).astype('int')\nlgb_submission.to_csv(\"lgb-subs.csv\",index=None)\nlgb_submission.head()","a2cd2594":"catb_submission = submission.copy()\ncatb_submission['Cover_Type'] = np.squeeze(mode(np.column_stack(catb_predictions),axis = 1)[0]).astype('int')\ncatb_submission.to_csv(\"submission.csv\",index=None)\ncatb_submission.head()","d902df59":"xgb_submission = submission.copy()\nxgb_submission['Cover_Type'] = np.squeeze(mode(np.column_stack(xgb_predictions),axis = 1)[0]).astype('int')\nxgb_submission.to_csv(\"xgb-subs.csv\",index=None)\nxgb_submission.head()","cd79a109":"nn_submission = submission.copy()\nnn_submission[\"Cover_Type\"] = LE.inverse_transform(np.argmax((nn_preds), axis=1)).astype(int)\nnn_submission.to_csv(\"nn-sub.csv\" , index= False)\nnn_submission.head()","4ea8d78c":"##  TPS submission file ","c277dbdd":"### Feature Distribution of Continous Features","85c652ad":"## EDA","6859a46e":"## XGBoost Classifier","f87b1dbf":"#### Test data  \ud655\uc778 ","a8a94826":"### Modeling","9bc5dfc1":"#### Target Distribution","f73aa3ea":"### LGBM Classifier","535dde43":"-  train, test data\uc5d0\ub294 \uacb0\uce21\uce58\uac00 \uc5c6\ub2e4. \n    ","0ad4d877":"## Import Library","d218c9c3":"### Removing Unwanted Rows and columns","b85bc0c8":"### Neural Network","c00fc499":"- soil_type15, 7 \uc740  data\uac00 \uc5c6\ub2e4. \n- mean \uac12\uc774 0.001 \uc774\ud558\uc778 soil_type data \ub294 \ubc84\ub9ac\ub294 \uac83\uc774 \ub0ab\uc9c0 \uc54a\uc744\uae4c ? \n    - type 3, 6, 7, 8, 15, 25\n    - type 3 \uc740 4\uc640 \ube44\uc2b7\ud55c\uc9c0 \ud655\uc778 \ud6c4 \ud569\uce58\uae30 (\ud639\uc740 Drop)\n    - type 6 \uc740 5\uac00 vent family : \ud569\uce58\uae30\n    - type 8 drop\n    - type 25 Leighcan family \ub85c \ud569\uce58\uae30 \n- \uba3c\uc800 \uadf8\ub0e5 \ud588\uc744\ub54c, EDA \ud6c4 score \ud655\uc778 \ud6c4 \uc9c4\ud589 \n","22dd5fa2":"- wild area 4 : 0.250644\n- Evaluation : -0.395961\n\n","79cf8fd2":"- ACCURACY : \uc774\uc9c4 \ubd84\ub958 \uacb0\uacfc \ud45c (Binary confusion Matrix) \uc5d0 \ub530\ub77c \n    + (True Positive + True Negative) \/ Total","ed0d0996":"- Elevation (\uace0\ub3c4) \uc758 \uacbd\uc6b0 Train data\uac00 test data\ubcf4\ub2e4 \ub192\uc740 \ud3b8\uc778 \uc9c0\uc5ed\uc774 \uc788\uc9c0\ub9cc, \ubd84\ud3ec\ub294 \ube44\uc2b7\ud558\ub2e4. \n- Horizontal_Distance_To_fire_point\uc758 \uacbd\uc6b0 ","8d0aa2be":"### Catboost Classifier Submission","aa3fcb23":"### Feature Engineering","638718d4":"### Data Load","b4315e34":"### XGBoost Classifier Submission","cbda545a":"### Neural Network Submission","ef9b7be1":" - test data\uc5d0\ub294 \uc5c6\uace0, Train data\uc5d0\ub9cc \uc788\ub294 type 5 (Aspen)\n     + Wilderness_Area3 : Comanche Peak Wilderness Area\n     + soil_type 4 : Ratake family - Rock outcrop complex, rubbly.","fff58733":"##  Submission\n\n### LGBM Classifier Submission","46217431":"#### submission data  \ud655\uc778 ","fef33920":"- categorical \ud56d\ubaa9\uc774 \ub9ce\uc740 \uac83\uc744 \ubcfc \uc218 \uc788\ub2e4. (44, 10 \/ea)","79b04908":"#### Train data \ud655\uc778 ","11850211":" ### Continuos and Categorical Data Distribution","0b71565d":"### Catboost Classifier"}}