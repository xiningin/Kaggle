{"cell_type":{"2061be02":"code","a9ada664":"code","5e33491d":"code","126abc25":"code","08733b1b":"code","54a96bea":"code","8b8727a9":"code","401ffeae":"code","0ab510a3":"code","90f12095":"code","147d5ee8":"code","ee92987b":"code","0e87bcdd":"code","00541160":"code","6463e67d":"code","05966783":"code","fc2ab8a1":"code","577957cc":"code","a8f6f9cd":"code","f3fbc1eb":"markdown","a9ad0cd1":"markdown","feac5127":"markdown","3ea1ab52":"markdown","3a99bd34":"markdown","9827ac8d":"markdown","c195824d":"markdown","c5939090":"markdown","bc5352dd":"markdown","c0471f6c":"markdown","7a4f2a94":"markdown","f1d740ec":"markdown","792fd83d":"markdown","a9695b4f":"markdown","ef318ebc":"markdown","214b60ea":"markdown","8228e5c4":"markdown","0cbbe422":"markdown","49d751e1":"markdown","e5d4878d":"markdown","f7369829":"markdown","da70b2c7":"markdown","38299d0d":"markdown","06a3ef3c":"markdown","67521066":"markdown","4ee4268a":"markdown","145f7f81":"markdown","70a7a16b":"markdown"},"source":{"2061be02":"import numpy as np # linear algebra\nimport pandas as pd\nimport os\n\npd.options.mode.chained_assignment = None\n\n# Loading in all the raw datasets we will use here\npass_plays = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/plays.csv\")\npass_plays = pass_plays[pass_plays['playType'] == \"play_type_pass\"]\nplayers = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/players.csv\")\nall_plays = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/plays.csv\")\n\n\n\n# Setting global parameters to make the plots look nicer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as mpl\nmpl.rcParams[\"axes.spines.right\"] = False\nmpl.rcParams[\"axes.spines.top\"] = False\nmpl.rcParams['axes.linewidth'] = 2\nmpl.rcParams['ytick.labelsize'] = 12\nmpl.rcParams['xtick.labelsize'] = 12\nmpl.rcParams['axes.titlesize'] = 12\nmpl.rcParams['axes.labelsize'] = 12\n","a9ada664":"\n# This code loops through all the data to collect all the macro-level data about a given play. (down, time of play, duration, etc.)\ndf_list = []\n\nfor i in range(1, 18):\n    week_str = \"..\/input\/nfl-big-data-bowl-2021\/week\" + str(i) + \".csv\"\n    week = pd.read_csv(week_str)\n\n    # Only care about the football, at the snap and when the pass arrives. This gives us the intended pass distance.\n    football = week[(week['event'].isin(['ball_snap', 'pass_arrived'])) & (week['displayName'] == 'Football')]\n    distances = football.groupby(['gameId', 'playId'])['x'].diff()\n    football['distance'] = np.abs(distances)\n    football = football.dropna(subset = ['distance'])\n    # Take just the relevant columns\n    df_list.append(football[['gameId', 'playId', 'distance']])\n\n\npass_distances = pd.concat(df_list)\npass_plays = pass_plays.merge(pass_distances, on = ['gameId', 'playId'])","5e33491d":"## Plot for Down analysis\n\n\n\n\ndifferent_downs = [np.array(pass_plays[pass_plays['down'] == i]['distance']) for i in range(1, 5)]\n# Take middle 95 percent (robust to outliers)\ndifferent_downs = [x[ x > np.percentile(x, 2.5)] for x in different_downs]\ndifferent_downs = [np.log(x + 0.01) for x in different_downs]\n\n\nparts = plt.violinplot(different_downs, showmeans=False, showmedians=False,\n        showextrema=False)\nplt.xticks([1, 2, 3, 4])\nplt.title(\"Relative pass length on different downs\", fontweight = \"bold\")\nplt.xlabel(\"Down Number\")\nplt.ylabel(\"Length of Pass (log scale)\")\ncolors = [\"#2b8cbe\", \"#43a2ca\", \"#a8ddb5\", \"#e0f3db\"]\nfor i in range(len(parts['bodies'])):\n    pc = parts['bodies'][i]\n    pc.set_facecolor(colors[i])\n    pc.set_edgecolor('black')\n    pc.set_linewidths(1.5)\n    pc.set_alpha(1)\nplt.show()\n","126abc25":"different_downs = [np.array(pass_plays[pass_plays['yardsToGo'] == i]['distance']) for i in range(1, 20)]\n# Take middle 95 percent (robust to outliers)\ndifferent_downs = [x[ x > np.percentile(x, 2.5)] for x in different_downs]\ndifferent_downs = [x[ x < np.percentile(x, 97.5)] for x in different_downs]\ndifferent_downs = [np.log(x + 0.01) for x in different_downs]\nplt.figure(figsize=(11,3))\nplt.xlabel(\"Yards left to go\")\nplt.ylabel(\"Length of Pass (log scale)\")\nplt.violinplot(different_downs)\nplt.title(\"Relative pass length in different \\\"yard-to-go\\\" scenarios\", fontweight = \"bold\")\nplt.show()","08733b1b":"pass_plays['time_elapsed'] = time_elapsed(pass_plays['quarter'], pass_plays['gameClock'])\npass_plays = pass_plays[pass_plays['time_elapsed'] < 3600]\n# Over time data is excluded due to lack of data points\npass_plays['time_binned'] = np.floor(pass_plays['time_elapsed'] \/ 60)\ntemp = pass_plays.groupby(['time_binned']).mean()\nplt.figure(figsize=(11,3))\nplt.plot(temp.index.values, temp['distance'], 'o-')\nplt.xlabel(\"Minutes elapsed in game (regular time only)\")\nplt.ylabel(\"Average Pass length (yards)\")\nplt.title(\"Average pass length in games\", fontweight = \"bold\")\nplt.show()\n\n","54a96bea":"# Where are defenders lining up?\n\ndeltax = []\ndeltay = []\npass_result = []\n\nfor n in range(1, 18):\n    print(n)\n    df = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/week\" + str(n) + \".csv\")\n    unique_plays = df.drop_duplicates(['playId', 'gameId'])\n\n    plays = np.unique(df['playId'])\n\n    for i in range(len(unique_plays)):\n\n        PLAY_NUMBER = unique_plays.iloc[i, :]['playId']\n        game_id = unique_plays.iloc[i, :]['gameId']\n        result = get_details(PLAY_NUMBER, game_id)\n\n        play = df[df['playId'] == PLAY_NUMBER]\n        play = play[play['gameId'] == game_id]\n        play['nflId'] = play['nflId'].replace(np.nan, 0)\n\n        # Get the vectors of each of the defenders lining up\n        ## Code for finding the starting distance for each receiver\n\n        if len(find_all_receivers(play)) == 0:\n            # means there is no passing this play\n            continue\n\n        try:\n            pairings = find_closest_defender(play, \"all\")\n        except (IndexError, ValueError):\n            continue\n\n        if result == 'I':\n            pass_result.append('I')\n        elif result == 'C':\n            pass_result.append('C')\n        else:\n            pass_result.append('O')\n\n        # Finding the frame \n        frame = list(play[play['event'] == 'ball_snap']['frameId'])[0]\n\n        for i in range(len(pairings)):\n            try:\n                rec = pairings.iloc[i, :]['receiver']\n                dfndr = pairings.iloc[i, :]['closest_def']\n                temp = play[(play['nflId'] == dfndr) & (play['frameId'] == frame)]\n                x_def, y_def = float(pd.to_numeric(temp['x'])) , float(pd.to_numeric(temp['y']))\n\n                temp = play[(play['nflId'] == rec) & (play['frameId'] == frame)]\n                x_rec, y_rec = float(pd.to_numeric(temp['x'])) , float(pd.to_numeric(temp['y']))\n\n                dire = play.iloc[0, :]['playDirection']\n                x = x_def - x_rec\n                y = y_def - y_rec\n                if dire == \"left\":\n                    deltax.append(-1 * x)\n                    deltay.append(-1 * y)\n                else:\n                    deltax.append(x)\n                    deltay.append(y)\n            except TypeError:\n                pass","8b8727a9":"from scipy.ndimage.filters import gaussian_filter\nimport matplotlib.pyplot as plt\n\nheatmap, xedges, yedges = np.histogram2d(deltax, deltay, bins=40, density = True, range = [[0, 10], [-4, 4]])\nheatmap = gaussian_filter(heatmap, sigma=0.01)\nextent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n\nplt.figure(figsize=(9,6))\nplt.clf()\nplt.imshow(heatmap.T, extent=extent, origin='lower', cmap = \"PiYG\")\ncb = plt.colorbar()\ncb.set_label('density')\nplt.title(\"heatmap of positioning of defender\", fontweight = \"bold\")\nplt.xlabel(\"Yards off line of scrimmage (x-axis direction)\")\nplt.show()","401ffeae":"## Compare incomplete and complete passes\n\n# same runner code, one per play.\ndef exploration():\n    deltax = []\n    deltay = []\n    pass_result = []\n    all_plays = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/plays.csv\")\n\n    for n in range(1, 18):\n        print(n)\n        df = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/week\" + str(n) + \".csv\")\n        unique_plays = df.drop_duplicates(['playId', 'gameId'])\n\n        plays = np.unique(df['playId'])\n\n        for i in range(len(unique_plays)):\n\n            PLAY_NUMBER = unique_plays.iloc[i, :]['playId']\n            game_id = unique_plays.iloc[i, :]['gameId']\n            result = get_details(PLAY_NUMBER, game_id)\n\n            play = df[df['playId'] == PLAY_NUMBER]\n            play = play[play['gameId'] == game_id]\n            play['nflId'] = play['nflId'].replace(np.nan, 0)\n\n            # Get the vectors of each of the defenders lining up\n            ## Code for finding the starting distance for each receiver\n\n            if len(find_all_receivers(play)) == 0:\n                # means there is no passing this play\n                continue\n\n            try:\n                pairings = find_closest_defender(play, \"all\")\n            except (IndexError, ValueError):\n                continue\n\n            \n\n            # Finding the frame \n            frame = list(play[play['event'] == 'ball_snap']['frameId'])[0]\n\n            receiver = ball_thrown_to(play)\n            pairings = pairings[pairings['receiver'] == receiver]\n            for i in range(len(pairings)):\n                try:\n                    rec = pairings.iloc[i, :]['receiver']\n                    dfndr = pairings.iloc[i, :]['closest_def']\n                    temp = play[(play['nflId'] == dfndr) & (play['frameId'] == frame)]\n                    x_def, y_def = float(pd.to_numeric(temp['x'])) , float(pd.to_numeric(temp['y']))\n\n                    temp = play[(play['nflId'] == rec) & (play['frameId'] == frame)]\n                    x_rec, y_rec = float(pd.to_numeric(temp['x'])) , float(pd.to_numeric(temp['y']))\n\n                    dire = play.iloc[0, :]['playDirection']\n                    x = x_def - x_rec\n                    y = y_def - y_rec\n                    if dire == \"left\":\n                        deltax.append(-1 * x)\n                        deltay.append(-1 * y)\n                    else:\n                        deltax.append(x)\n                        deltay.append(y)\n                        \n                    if result == 'I':\n                        pass_result.append('I')\n                    elif result == 'C':\n                        pass_result.append('C')\n                    else:\n                        pass_result.append('O')\n                except TypeError:\n                    pass\n    return pd.DataFrame({'x': deltax, 'y': deltay, 'result': pass_result})\n\npasses_df = exploration()","0ab510a3":"from scipy.stats.kde import gaussian_kde\nfrom numpy import linspace\n\ncomplete_x = passes_df[passes_df['result'] == \"C\"]['x']\nincomplete_x = passes_df[passes_df['result'] == \"I\"]['x']\n\nplt.figure(figsize = (12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(complete_x, density = True, color = 'green', bins = 45, alpha = 0.2, range = (0, 20))\nplt.hist(incomplete_x, density = True, color = 'red', bins = 45, alpha = 0.2, range = (0, 20))\nkde = gaussian_kde( complete_x )\n# these are the values over wich your kernel will be evaluated\ndist_space = linspace( min(complete_x), max(complete_x), 300 )\n# plot the results\n\nplt.xlim((0, 20))\nplt.plot( dist_space, kde(dist_space), color = 'green', ls = '--', label = 'complete passes')\nkde = gaussian_kde( incomplete_x )\n# these are the values over wich your kernel will be evaluated\ndist_space = linspace( min(incomplete_x), max(incomplete_x), 300 )\n\n\nplt.plot( dist_space, kde(dist_space), color = 'red', ls = '--', label = 'incomplete passes')\nplt.legend(loc='upper right')\nplt.ylabel(\"density\")\nplt.xlabel(\"Yards from line of scrimmage along x-axis\")\nplt.title(\"X-axis positioning of defensive back\", fontweight = \"bold\")\nplt.xticks(2 * np.arange(1, 10))\n\n\nplt.subplot(1, 2, 2)\ncomplete_x = passes_df[passes_df['result'] == \"C\"]['y']\nincomplete_x = passes_df[passes_df['result'] == \"I\"]['y']\nplt.hist(complete_x, density = True, color = 'green', bins = 35, alpha = 0.2, range = (-7, 7))\nplt.hist(incomplete_x, density = True, color = 'red', bins = 35, alpha = 0.2, range = (-7, 7))\nkde = gaussian_kde( complete_x )\n# these are the values over wich your kernel will be evaluated\ndist_space = linspace( min(complete_x), max(complete_x), 300 )\n# plot the results\nplt.xlim((-7, 7))\nplt.plot( dist_space, kde(dist_space), color = 'green', ls = '--', label = 'complete passes')\nkde = gaussian_kde( incomplete_x )\n# these are the values over wich your kernel will be evaluated\ndist_space = linspace( min(incomplete_x), max(incomplete_x), 150 )\nplt.plot( dist_space, kde(dist_space), color = 'red', ls = '--', label = 'incomplete passes')\nplt.legend(loc='upper right')\nplt.ylabel(\"density\")\nplt.xlabel(\"Yards from receiver along y-axis\")\nplt.title(\"Y-axis positioning of defensive back\", fontweight = \"bold\")\nplt.tight_layout()\nplt.show()","90f12095":"## 1 - D histogram of the yards off line of scrimmage\nfrom scipy.stats.kde import gaussian_kde\nfrom numpy import linspace\nplt.figure(figsize=(9, 5))\nplt.hist(deltax, density = True, bins = 30, alpha = 0.2, range = (0, 20))\nkde = gaussian_kde( deltax )\n# these are the values over wich your kernel will be evaluated\ndist_space = linspace( min(deltax), max(deltax), 300 )\n# plot the results\nplt.plot( dist_space, kde(dist_space) )\nplt.xlim((0, 20))\nplt.xticks(2 * np.arange(1, 10))\nplt.axvline(x = 4, color = 'red', ls = '--', linewidth = 3)\nplt.axvline(x = 8, color = 'red', ls = '--', linewidth = 3)\nplt.title(\"Distribution of defender starting positions, and identification of coverage types\", fontweight = \"bold\")\nplt.xlabel(\"Starting position from line of scrimmage\")\nplt.ylabel(\"density\")\nplt.show()","147d5ee8":"data = {\n    \"avg_separation\": [],\n    \"avg_separation_air\": [],\n    \"down\": [],\n    \"ori_difference\": [],\n    \"rec\": [],\n    \"rec_name\": [],\n    \"rec_position\": [],\n    \"rec_weight\": [],\n    \"rec_height\": [],\n    \"rec_avg_ori\": [],\n    \"rec_avg_speed\": [],\n    \"rec_max_speed\": [],\n    \"rec_distance_ran\": [],\n    \"def\": [],\n    \"def_name\": [],\n    \"def_weight\": [],\n    \"def_height\": [],\n    \"def_position\": [],\n    \"def_avg_ori\": [],\n    \"def_avg_speed\": [],\n    \"def_max_speed\": [],\n    \"def_distance_ran\": [],\n    \"distance_to_go\": [],\n    \"total_time\": [],\n    \"route\": [],\n    \"def_starting_dist\": [],\n    \"sep_decreasing\": [],\n    \"game_id\": [],\n    \"play_id\": [],\n    \"is_completion\": []\n}\n\nfor i in range(1, 18):\n    print (i)\n    week_str = \"..\/input\/nfl-big-data-bowl-2021\/week\" + str(i) + \".csv\"\n    df = pd.read_csv(week_str)\n\n    unique_plays = df.drop_duplicates(['playId', 'gameId'])\n    plays = np.unique(df['playId'])\n    \n    for i in range(len(unique_plays)):\n        PLAY_NUMBER = unique_plays.iloc[i, :]['playId']\n        game_id = unique_plays.iloc[i, :]['gameId']\n        result = get_details(PLAY_NUMBER, game_id)\n        \n        play = df[df['playId'] == PLAY_NUMBER]\n        play = play[play['gameId'] == game_id]\n        play['nflId'] = play['nflId'].replace(np.nan, 0)\n        \n        try:\n            total_time = time_to_num(play[play['event'] == 'pass_arrived']['time'].iloc[0])\\\n                            - time_to_num(play[play['event'] == 'ball_snap']['time'].iloc[0])\n        except:\n            continue\n        \n        try:\n            receiver = ball_thrown_to(play)\n            if np.isnan(receiver):\n                continue\n            defenders = find_closest_defender_details(play, receiver, 'in_air', 'snap_reached')\n        except (IndexError, ValueError, TypeError):\n            continue\n        \n        for i in range(len(defenders)):\n            # get average separation\n            data['avg_separation'].append(defenders['avg_distance'].iloc[i])\n            data['avg_separation_air'].append(defenders['avg_distance_air'].iloc[i])\n            \n            data['sep_decreasing'].append(defenders['sep_decreasing'].iloc[i])\n            data['game_id'].append(game_id)\n            data['play_id'].append(PLAY_NUMBER)\n            \n            # get direction of play (plays going left will be flipped)\n            dire = play.iloc[0, :]['playDirection']\n            \n            # get orientation and difference between orientation\n            rec_ori = defenders['rec_ori'].iloc[i]\n            def_ori = defenders['def_ori'].iloc[i]\n            \n            if dire == \"left\":\n                rec_ori = 360 - rec_ori\n                def_ori = 360 - def_ori\n            \n            data['rec_avg_ori'].append(rec_ori)\n            data['def_avg_ori'].append(rec_ori)\n            data['ori_difference'].append(angle_diff(def_ori, rec_ori))\n            \n            data['rec_avg_speed'].append(defenders['rec_speed'].iloc[i])\n            data['rec_max_speed'].append(defenders['rec_max_speed'].iloc[i])\n            data['rec_distance_ran'].append(defenders['rec_dist'].iloc[i])\n            \n            data['def_avg_speed'].append(defenders['def_speed'].iloc[i])\n            data['def_max_speed'].append(defenders['def_max_speed'].iloc[i])\n            data['def_distance_ran'].append(defenders['def_dist'].iloc[i])\n            data['route'].append(defenders['route'].iloc[i])\n            data['def_starting_dist'].append(defenders['def_starting_dist'].iloc[i])\n            \n            # get information about receiver and defender\n            rec_id = defenders['receiver'].iloc[i]\n            receiver = players[players['nflId'] == rec_id].iloc[0]\n            def_id = defenders['closest_def'].iloc[i]\n            closest_def = players[players['nflId'] == def_id].iloc[0]\n            \n            data['def'].append(def_id)\n            data['def_name'].append(closest_def['displayName'])\n            data['def_position'].append(closest_def['position'])\n            data['def_weight'].append(closest_def['weight'])\n            data['def_height'].append(height_to_num(closest_def['height']))\n            \n            data['rec'].append(rec_id)\n            data['rec_name'].append(receiver['displayName'])\n            data['rec_position'].append(receiver['position'])\n            data['rec_weight'].append(receiver['weight'])\n            data['rec_height'].append(height_to_num(receiver['height']))\n            \n            data[\"is_completion\"].append(1 if result == 'C' else 0)\n            data[\"down\"].append(all_plays[(all_plays['playId'] == PLAY_NUMBER) & \\\n                                          (all_plays['gameId'] == game_id)]['down'].iloc[0])\n            data[\"distance_to_go\"].append(all_plays[(all_plays['playId'] == PLAY_NUMBER) & \\\n                                          (all_plays['gameId'] == game_id)]['yardsToGo'].iloc[0])\n            data[\"total_time\"].append(total_time)\n\nall_defenders = pd.DataFrame(data)\n\nall_defenders.head()","ee92987b":"name_sep = {}\ndf = all_defenders\nfor i in range(len(df)):\n  # name -> list([sum_separation, count])\n  if df.iloc[i]['def_name'] in name_sep:\n    name_sep[df.iloc[i]['def_name']] = [name_sep[df.iloc[i]['def_name']][0] + df.iloc[i]['avg_separation'], name_sep[df.iloc[i]['def_name']][1]+1]\n  else:\n    name_sep[df.iloc[i]['def_name']] = [df.iloc[i]['avg_separation_air'], 1]\nname_sep = {k: [v[0]\/v[1] if v[1] > 20 else 20] for k, v in name_sep.items()}\nname_sep = {k: v for k, v in sorted(name_sep.items(), key=lambda item: item[1])}\nsorted_df = pd.DataFrame.from_dict(name_sep).transpose()\nsorted_df.columns = ['avg_separation_air']\nsorted_df.head(10)","0e87bcdd":"import warnings\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\n\ndef encode_df_col (df, col):\n    le = LabelEncoder()\n    le.fit (df[col].unique())\n    df[col] = df[col].apply(lambda x : le.transform([x])[0])\n    \ndef clean(df):\n    return df.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n\ndesired_cols = ['avg_separation', 'avg_separation_air', 'down', 'ori_difference', 'rec_position', 'rec_weight', 'rec_height', 'rec_avg_ori',\n       'rec_avg_speed', 'rec_max_speed', 'rec_distance_ran', 'def_weight', 'def_height', 'def_position', 'def_avg_ori',\n       'def_avg_speed', 'def_max_speed', 'def_distance_ran', 'distance_to_go',\n       'total_time', 'def_starting_dist', 'sep_decreasing', 'is_completion']\n\npress = all_defenders[all_defenders['def_starting_dist'] < 4][desired_cols]\nnormal = all_defenders[(all_defenders['def_starting_dist'] >= 4) & (all_defenders['def_starting_dist'] < 8)][desired_cols]\nsoft = all_defenders[all_defenders['def_starting_dist'] >= 8][desired_cols]\nsoft = clean(soft)\nfor df in [press, normal, soft]:\n    encode_df_col(df, 'rec_position')\n    encode_df_col(df, 'def_position')\n    \nx_press = press.drop(press.columns[[len(desired_cols)-1]], axis=1)\ny_press = press.drop(press.columns[np.arange(len(desired_cols)-1)], axis=1)\n\nscaler_press = StandardScaler()\n\nx_press = scaler_press.fit_transform(x_press)\n\nx_normal = normal.drop(normal.columns[[len(desired_cols)-1]], axis=1)\ny_normal = normal.drop(normal.columns[np.arange(len(desired_cols)-1)], axis=1)\n\nscaler_normal = StandardScaler()\nx_normal = scaler_normal.fit_transform(x_normal)\n\nx_soft = soft.drop(soft.columns[[len(desired_cols)-1]], axis=1)\ny_soft = soft.drop(soft.columns[np.arange(len(desired_cols)-1)], axis=1)\n\nscaler_soft = StandardScaler()\nx_soft = scaler_soft.fit_transform(x_soft)\n\nX_train_press, X_test_press, y_train_press, y_test_press = train_test_split(x_press, y_press, test_size=0.2, random_state=42)\nX_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(x_normal, y_normal, test_size=0.2, random_state=42)\nX_train_soft, X_test_soft, y_train_soft, y_test_soft = train_test_split(x_soft, y_soft, test_size=0.2, random_state=42)\n\nprint (\"Press coverage: \")\nclf_press = LogisticRegression(class_weight={ 0:1.5, 1:1 })\nclf_press.fit(X_train_press, y_train_press)\npred_press = clf_press.predict(X_test_press)\nprint(\"Accuracy: \" + \"{perc:.2f}%\".format(perc=100 * accuracy_score(y_test_press, pred_press)))\nprint (\"% completions predicted: \" + \"{perc:.2f}%\".format(perc=100 * np.count_nonzero(pred_press) \/ len(pred_press)))\n\nprint (\"\")\n\nprint (\"Normal coverage: \")\nclf_normal = LogisticRegression(class_weight={ 0:2.6, 1:1 })\nclf_normal.fit(X_train_normal, y_train_normal)\npred_normal = clf_normal.predict(X_test_normal)\nprint(\"Accuracy: \" + \"{perc:.2f}%\".format(perc=100 * accuracy_score(y_test_normal, pred_normal)))\nprint (\"% completions predicted: \" + \"{perc:.2f}%\".format(perc=100 * np.count_nonzero(pred_normal) \/ len(pred_normal)))\n\nprint (\"\")\n\nprint (\"Soft coverage: \")\nclf_soft = LogisticRegression(class_weight={ 0:2.2, 1:1 })\nclf_soft.fit(X_train_soft, y_train_soft)\npred_soft = clf_soft.predict(X_test_soft)\nprint(\"Accuracy: \" + \"{perc:.2f}%\".format(perc=100 * accuracy_score(y_test_soft, pred_soft)))\nprint (\"% completions predicted: \" + \"{perc:.2f}%\".format(perc=100 * np.count_nonzero(pred_soft) \/ len(pred_soft)))","00541160":"f, ax = plt.subplots(1,1,figsize=(12,5))\nw = 0.2\n\nax.bar(x=np.arange(len(desired_cols)-1)-w, height=clf_soft.coef_[0], width=w, alpha=0.5, color='blue', align='center')\nax.bar(x=np.arange(len(desired_cols)-1), height=clf_normal.coef_[0], width=w, alpha=0.5, color='orange', align='center')\nax.bar(x=np.arange(len(desired_cols)-1)+w, height=clf_press.coef_[0], width=w, alpha=0.5, color='green', align='center')\nax.xaxis_date()\nax.autoscale(tight=True)\n\nplt.xticks(np.arange(len(desired_cols)-1), desired_cols[:-1], alpha=0.3, rotation=90)\n\ncolors = {'soft':'blue', 'normal':'orange', 'press':'green'}         \nlabels = list(colors.keys())\nhandles = [plt.Rectangle((0,0),1,1, color=colors[label], alpha=0.5) for label in labels]\nplt.legend(handles, labels)\nplt.title (\"Logistic Regression Weights Comparison\")\nplt.axhline(0, color = 'black', lw = 1, alpha = 0.5)\nplt.show()","6463e67d":"clf_soft_abs = np.abs(clf_soft.coef_[0])\nclf_normal_abs = np.abs(clf_normal.coef_[0])\nclf_press_abs = np.abs(clf_press.coef_[0])\n\nbiggest_soft = []\nbiggest_normal = []\nbiggest_press = []\nfor i in range(len(clf_soft.coef_[0])):\n    biggest_soft.append([clf_soft_abs[i], i])\n    biggest_normal.append([clf_normal_abs[i], i])\n    biggest_press.append([clf_press_abs[i], i])\n    \nbiggest_soft.sort()\nbiggest_normal.sort()\nbiggest_press.sort()\n\ntop_n = 7\n\nweight_rank = [[] for i in range(4)]\nweight_rank[0] = [i+1 for i in range(top_n)]\n\nfor i in range (top_n):\n    weight_rank[1].append(desired_cols[biggest_soft[-1-i][1]] + \" (\" + \\\n           (\"+\" if clf_soft.coef_[0][biggest_soft[-1-i][1]] > 0 else \"-\") + \")\")\n\nfor i in range (top_n):\n    weight_rank[2].append (desired_cols[biggest_normal[-1-i][1]] + \" (\" + \\\n           (\"+\" if clf_normal.coef_[0][biggest_normal[-1-i][1]] > 0 else \"-\") + \")\")\n\nfor i in range (top_n):\n    weight_rank[3].append (desired_cols[biggest_press[-1-i][1]] + \" (\" + \\\n           (\"+\" if clf_press.coef_[0][biggest_press[-1-i][1]] > 0 else \"-\") + \")\")\n\nprint (\"rank | soft | normal | press\")\nprint (\"--- | --- | --- | ---\")\nprint (\"\\n\".join([\"|\".join(x) for x in np.transpose(weight_rank)]))","05966783":"pred_soft = clf_soft.predict_proba(X_test_soft)[:,1]\n\nworst = np.argpartition(pred_soft, 10)[3]\n\nprint (\"Low catch probability (soft coverage): {prob:.2f}%\".format(prob=pred_soft[worst] * 100))\n\nworst_play = list(zip(desired_cols, list(scaler_soft.inverse_transform(X_test_soft[worst]))))\n_, worst_separation = worst_play[0]\nplay_id = 840\ngame_id = 2018100709\n\nprint (list(all_plays[(all_plays['playId'] == play_id) & (all_plays['gameId'] == game_id)]['playDescription'])[0])\n\nall_defenders[all_defenders['avg_separation'] == worst_separation]","fc2ab8a1":"pred_normal = clf_normal.predict_proba(X_test_normal)[:,1]\n\nworst = np.argpartition(pred_normal, 10)[6]\n\nprint (\"Low catch probability (normal coverage): {prob:.2f}%\".format(prob=pred_normal[worst] * 100))\n\nworst_play = list(zip(desired_cols, list(scaler_normal.inverse_transform(X_test_normal[worst]))))\n_, worst_separation = worst_play[0]\nplay_id = 2098\ngame_id = 2018121603\n\nprint (list(all_plays[(all_plays['playId'] == play_id) & (all_plays['gameId'] == game_id)]['playDescription'])[0])\n\nall_defenders[all_defenders['avg_separation'] == worst_separation]","577957cc":"pred_press = clf_press.predict_proba(X_test_press)[:,1]\n\nworst = np.argpartition(pred_press, 10)[6]\n\nprint (\"Low catch probability (press coverage): {prob:.2f}%\".format(prob=pred_press[worst] * 100))\n\nworst_play = list(zip(desired_cols, list(scaler_press.inverse_transform(X_test_press[worst]))))\n_, worst_separation = worst_play[0]\nplay_id = 3613\ngame_id = 2018091610\n\nprint (list(all_plays[(all_plays['playId'] == play_id) & (all_plays['gameId'] == game_id)]['playDescription'])[0])\n\nall_defenders[all_defenders['avg_separation'] == worst_separation]","a8f6f9cd":"def angle_diff (ang1, ang2):\n    \"\"\"Given two angles from 0 to 360, find the difference between the angles, ranging from -180 to 180\"\"\"\n    diff = ang1 - ang2\n    if diff < -180:\n        diff += 360\n    elif diff > 180:\n        diff -= 360\n    return diff\n\ndef ball_thrown_to(play):\n    \"\"\"Given a play, figure out to whom the ball is thrown to, by checking the closest receiver to \n    the football at the 'pass_arrived' frame, which exists for every throw.\"\"\"\n    \n    \n    pass_arrived = play[play['event'] == 'pass_arrived']\n    football = pass_arrived[pass_arrived['displayName'] == \"Football\"]\n    \n    receivers = find_all_receivers(play)\n    closest_receiver = np.float(\"NaN\")\n    mindist = 100\n    for rec in receivers:\n        dist = distance(pass_arrived, rec, 0) \n        if dist < mindist:\n            mindist = dist\n            closest_receiver = rec\n    return closest_receiver \n\ndef distance(play, id1, id2):\n    \"\"\"For a given play, given the id's of two players, calculate the average distance per frame\n    b\/w them through the entire play. Helper function\"\"\"\n     \n    p1 = play[play['nflId'] == id1]\n    p2 = play[play['nflId'] == id2]\n     \n    x1 = np.array(p1['x'])\n    x2 = np.array(p2['x'])\n    y1 = np.array(p1['y'])\n    y2 = np.array(p2['y'])\n    dist = np.sum(((x1 - x2) **2 + (y1 - y2) ** 2) ** 0.5)\n    # Return value should be float in yards\n    if len(p1) == 0:\n        return float('inf')\n    return dist\/len(p1)\n\ndef dist_decreasing(play, id1, id2):\n    \"\"\"For a given play, given the id's of two players, calculate the proportion of frames\n    where the distance between them decreases\"\"\"\n     \n    p1 = play[play['nflId'] == id1]\n    p2 = play[play['nflId'] == id2]\n     \n    x1 = np.array(p1['x'])\n    x2 = np.array(p2['x'])\n    y1 = np.array(p1['y'])\n    y2 = np.array(p2['y'])\n    dist = ((x1 - x2) **2 + (y1 - y2) ** 2) ** 0.5\n    change = dist[1:] - dist[:-1]\n    \n    if len (p1) <= 1:\n        return 0\n    \n    proportion = np.count_nonzero(change < 0) \/ len (change)\n    \n    # Return value should be float in yards\n    return proportion\n\n\ndef find_all_receivers(play):\n    \"\"\"Takes in a DF of a certain play, and returns the nfl IDs of all offensive receivers.\"\"\"\n    temp = play.dropna(subset = ['route'])\n    return np.unique(temp['nflId'])\n\ndef find_closest_defender(play, interval):\n    \"\"\"Given list of IDs for offensive receivers, find their closest defender across an interval.\n    Returns a DF with the schema: (receiver, closest_def, average distance).\n    params: \n    play - tracking DF for a certain play, from weekN.csv dataset\n    interval - pre_throw, in_air, after, all \n    \"\"\"\n    receivers = find_all_receivers(play)\n    closest_defenders = []\n    dst = []\n\n    if len(receivers) == 0:\n        raise IndexError(\"No receivers here\")\n\n    recs = play[play['nflId'].isin(receivers)]\n    side = np.unique(recs['team'])\n    assert len(side) == 1\n\n    if side[0] == \"home\":\n        facing = \"away\"\n    elif side[0] == \"away\":\n        facing = \"home\"\n    else:\n        raise ValueError(\"Bad side given.\")\n\n    opponents = play[play['team'] == facing]\n    # unique list of opponents\n    opponents = np.unique(opponents['nflId'])\n\n    ## Setting Frames and subsetting based on intervals\n    snap_frame = play[play['event'] == 'ball_snap']['frameId'].iloc[0]\n    throw_frame = play[play['event'] == 'pass_forward']['frameId'].iloc[0]\n    end_signals = ['pass_arrived', 'pass_outcome_caught',\n       'pass_outcome_incomplete', 'pass_outcome_interception',\n       'pass_outcome_touchdown']\n    reached_frame = play[play['event'].isin(end_signals)]['frameId'].iloc[0]\n\n\n    num_frames = np.max(play['frameId'])\n    # If specified all or nothing\n    num_index = np.arange(snap_frame, num_frames)\n    if interval == \"pre_throw\":\n        num_index = np.arange(snap_frame, throw_frame)\n    elif interval == \"in_air\":\n        num_index = np.arange(throw_frame, reached_frame)\n    elif interval == \"after\":\n        num_index = np.arange(reached_frame, num_frames)\n\n\n    # Subset play DF to contain desired frames\n    positions = play[play['frameId'].isin(num_index)]\n\n    # Begin distance calculations\n\n    for rec in receivers:\n    # Store per-frame distances in hashmap\n        distances = {}\n        for opp in opponents:\n            dist = distance(positions, rec, opp)\n            distances[opp] = dist\n\n        closest = min(distances, key = distances.get)\n        closest_defenders.append(closest)\n        dst.append(distances[closest])\n\n    return pd.DataFrame({'receiver': receivers, 'closest_def': closest_defenders, 'avg_distance': dst})\n\ndef find_closest_defender_details(play, receiver, rec_interval, calc_interval):\n  \"\"\"Given list of IDs for offensive receivers, find their closest defender across an interval\n  (one for finding clsoest defender, next for the calculations).\n  Returns a DF with the schema: (receiver, closest_def, average distance).\n  params: \n  play - tracking DF for a certain play, from weekN.csv dataset\n  interval - pre_throw, in_air, after, all \n  \"\"\"\n  receivers = [receiver]\n  \n  closest_defenders = []\n  dst = []\n  rec_ori = []\n  def_ori = []\n  def_speed = []\n  rec_speed = []\n  rec_max_speed = []\n  def_max_speed = []\n  def_dist = []\n  rec_dist = []\n  route = []\n  def_starting_dist = []\n  avg_distance_air = []\n  sep_decreasing = []\n\n  if len(receivers) == 0:\n    raise IndexError(\"No receivers here\")\n\n  recs = play[play['nflId'].isin(receivers)]\n  side = np.unique(recs['team'])\n  assert len(side) == 1\n\n  if side[0] == \"home\":\n      facing = \"away\"\n  elif side[0] == \"away\":\n      facing = \"home\"\n  else:\n      raise ValueError(\"Bad side given.\")\n      \n  opponents = play[play['team'] == facing]\n  # unique list of opponents\n  opponents = np.unique(opponents['nflId'])\n\n  ## Setting Frames and subsetting based on intervals\n  snap_frame = play[play['event'] == 'ball_snap']['frameId'].iloc[0]\n  throw_frame = play[play['event'] == 'pass_forward']['frameId'].iloc[0]\n  end_signals = ['pass_arrived', 'pass_outcome_caught',\n       'pass_outcome_incomplete', 'pass_outcome_interception',\n       'pass_outcome_touchdown']\n  reached_frame = play[play['event'].isin(end_signals)]['frameId'].iloc[0]\n\n  num_frames = np.max(play['frameId'])\n  # If specified all or nothing\n  rec_num_index = np.arange(snap_frame, num_frames)\n  if rec_interval == \"pre_throw\":\n    rec_num_index = np.arange(snap_frame, throw_frame)\n  elif rec_interval == \"in_air\":\n    rec_num_index = np.arange(throw_frame, reached_frame)\n  elif rec_interval == \"after\":\n    rec_num_index = np.arange(reached_frame, num_frames)\n  elif rec_interval == \"snap_reached\":\n    rec_num_index = np.arange(snap_frame, reached_frame)\n    \n  # If specified all or nothing\n  num_index = np.arange(snap_frame, num_frames)\n  if calc_interval == \"pre_throw\":\n    num_index = np.arange(snap_frame, throw_frame)\n  elif calc_interval == \"in_air\":\n    num_index = np.arange(throw_frame, reached_frame)\n  elif calc_interval == \"after\":\n    num_index = np.arange(reached_frame, num_frames)\n  elif calc_interval == \"snap_reached\":\n    num_index = np.arange(snap_frame, reached_frame)\n\n  # Subset play DF to contain desired frames\n  positions_rec = play[play['frameId'].isin(rec_num_index)]\n  positions = play[play['frameId'].isin(num_index)]\n\n  # Begin distance calculations\n\n  for rec in receivers:\n    # Store per-frame distances in hashmap\n    distances = {}\n    distances_full = {}\n    for opp in opponents:\n      dist = distance(positions_rec, rec, opp)\n      distances[opp] = dist\n    \n    closest = min(distances, key = distances.get)\n    closest_defenders.append(closest)\n    dst.append(distance(positions, rec, closest))\n    avg_distance_air.append(distance(positions_rec, rec, closest))\n    \n    sep_decreasing.append(dist_decreasing(positions, rec, closest))\n    \n    ori, avg_speed, max_speed, dist = play_details(positions, rec)\n    rec_ori.append(ori)\n    rec_speed.append(avg_speed)\n    rec_max_speed.append (max_speed)\n    rec_dist.append(dist)\n    \n    ori, avg_speed, max_speed, dist = play_details(positions, closest)\n    def_ori.append(ori)\n    def_speed.append(avg_speed)\n    def_max_speed.append (max_speed)\n    def_dist.append(dist)\n    \n    # get most common route (only make it nan if that's the only route)\n    route_frames = positions[positions['nflId'] == rec].dropna(subset=['route'])\n    rt = np.nan\n    if len(route_frames) > 0:\n        rt = route_frames['route'].value_counts().idxmax()\n    route.append(rt)\n    \n    defender = play[(play['event'] == 'ball_snap') & (play['nflId'] == closest)]\n    receiver = play[(play['event'] == 'ball_snap') & (play['nflId'] == rec)]\n    \n    def_starting_dist.append (np.abs(float(pd.to_numeric(defender['x'])) - float(pd.to_numeric(receiver['x']))))\n\n  return pd.DataFrame({'receiver': receivers, 'closest_def': closest_defenders, 'avg_distance': dst, \\\n                       'rec_ori': rec_ori, 'def_ori': def_ori, 'rec_speed': rec_speed, 'def_speed': def_speed, \\\n                       'rec_max_speed': rec_max_speed, 'def_max_speed': def_max_speed, 'rec_dist': rec_dist, 'def_dist': def_dist, \\\n                       'route': route, 'def_starting_dist': def_starting_dist, 'avg_distance_air': avg_distance_air, \\\n                       'sep_decreasing': sep_decreasing})\n\ndef get_details(playId, gameId):\n    \"\"\"Given a gameId, and a play ID (this uniquely defines a play), we extract a few important statistics.\n    Namely, we have the following returns:\n    is_completed: whether pass play is completed\n    yardage: number of yards gained\n    yardline: starting yardline\n    \"\"\"\n    temp = all_plays[(all_plays['playId'] == playId) & (all_plays['gameId'] == gameId)]\n    assert len(temp) == 1\n    complete = list(temp['passResult'])[0]\n    ## TODO: Add other fields as needed\n    return complete\n\ndef get_ball_details (gameId, playId, df):\n    \"\"\"\n    Given a DataFrame with frame-details of plays, and game ID and play ID\n    return the average speed of the ball and the average direction its heading\n    \"\"\"\n    \n    # speed is just an average\n    speed = df[(df['playId'] == playId) & (df['gameId'] == gameId) & (df['displayName'] == 'Football')]['s'].agg(np.mean)\n    \n    # direction is arctan from pass thrown to pass caught\n    temp = df[(df['playId'] == playId) & (df['gameId'] == gameId) & (df['displayName'] == 'Football') & (df['event'] == 'pass_forward')]\n\n    assert len(temp) == 1\n    start_x, start_y = float(pd.to_numeric(temp['x'])) , float(pd.to_numeric(temp['y']))\n    \n    temp = df[(df['playId'] == playId) & (df['gameId'] == gameId) & (df['displayName'] == 'Football') \\\n              & (df['event'] == 'pass_arrived')]\n    assert len(temp) == 1\n    end_x, end_y = float(pd.to_numeric(temp['x'])) , float(pd.to_numeric(temp['y']))\n    \n    dist = np.sqrt((end_x - start_x)**2 + (end_y - start_y)**2)\n    \n    dir = np.arccos (y \/ dist) * 180 \/ np.pi # range from 0 to 180 deg\n    if end_x < start_x:\n        dir = 360 - dir # corrects if angle is actually between 180 and 360 deg\n    \n    return (\n        speed,\n        dir,\n        distance_thrown\n    )\n\n\ndef height_to_num (str_height):\n    \"\"\"convert height from string format of 6-1 or 73 to integer\"\"\"\n    if \"-\" not in str_height:\n        return int (str_height)\n    else:\n        return int(str_height[0:str_height.index(\"-\")]) * 12 + int(str_height[str_height.index(\"-\")+1:])\n\ndef play_details(play, id1):\n    \"\"\"For a given play, given the id of a player, calculate the average orientation through\n    entire play, average speed, max speed, and distance ran. Helper function\"\"\"\n     \n    p1 = play[play['nflId'] == id1]\n     \n    ori = np.array(p1['o'])\n    speed = np.array(p1['s'])\n    dist = np.array(p1['dis'])\n    \n    if len (p1) == 0:\n        return 0\n    \n    return (np.mean(ori), np.mean(speed), np.amax(speed), np.sum(dist))\n\ndef time_to_num (str_time):\n    \"\"\"convert time of day to number\"\"\"\n    time = str_time[str_time.index(\"T\") + 1:-1].split(\":\")\n    hour, minute, sec = int(time[0]), int(time[1]), float(time[2])\n    return hour * 60 * 60 + minute * 60 + sec\n\ndef time_elapsed(quarter, gameclock):\n    \"\"\"Computes minutes elapsed given quarter and gameclock. Up to 75 minutes including overtime.\"\"\"\n    def compute_elapsed(string):\n        if string != string:\n            return 0\n        m, s, _ = string.split(':')\n        elapsed = 15 * 60 - 60 * int(m) - int(s)\n        return elapsed\n    gameclock = gameclock.apply(compute_elapsed)\n    t = 15 * 60 * (quarter - 1) + gameclock\n    # Overtime is now only 10 minutes long\n    t[t > 3600] -= 300\n    return t\n\n    \n","f3fbc1eb":"### Top Weights for probability models of each coverage type\nrank | soft | normal | press\n--- | --- | --- | ---\n1|avg_separation_air (+)|avg_separation_air (+)|avg_separation_air (+)\n2|def_distance_ran (-)|total_time (-)|def_avg_speed (-)\n3|rec_distance_ran (+)|def_max_speed (+)|def_max_speed (+)\n4|rec_avg_speed (-)|avg_separation (-)|def_distance_ran (+)\n5|avg_separation (-)|def_avg_speed (-)|total_time (-)\n6|def_max_speed (+)|rec_position (+)|rec_avg_speed (-)\n7|def_avg_speed (+)|def_weight (+)|sep_decreasing (-)","a9ad0cd1":"Our exploratory analysis was able to rule out the possibility of any obvious outliers or latent variables to the question posed, and we were able to further generate motivation to study the distance a defensive back lines up from the line of scrimmage as a fruitful route for analysis. ","feac5127":"### Exploration of Defender Starting Position","3ea1ab52":"We will now look into specific defender positioning along these two axes in a bit more detail. In particular, we want an precursory view of what types of positioning, along both the x-axis and the y-axis, are associated with a pass being complete\/incomplete. To directly compare such cases, it is not practical to use a heatmap as above, we will instead compare the positioning of the two axes individually, operating under the hypothesis that vertical positioning (y-axis) might not be so meaningful:\n","3a99bd34":"From these weights, we can see that the most important factor in all levels of coverage is average separation when the ball is in the air. This serves as a bit of a sanity check, as it is clear that a wide open receiver (high separation) is more likely to be a completion than a closely covered receiver. The other weights provide a bit more nuance in the analysis of defenses. \n\nWe will get the top 7 most significant variables (by the top 7 weights in terms of magnitude). These are each labeled with whether they contribute to a completion (+) or incompletion (-).","9827ac8d":"### Successful press coverage\n\nExploring the one of the lowest catch probabilities predicted by the press coverage model, we see an 20% catch probability for another deep ball thrown on a post route. The key variables that contributed to this low catch probability are: \n\n1. Fairly low separation in the air (given the speeds, this is significant)\n2. Extremely high average defender speed (only slightly lower than receiver metric)\n3. The maximum defender speed was not vastly different than the average speed, meaning that the defender maintained the high speed and was not beaten on something like a double move. \n\nThe defender's speed was what made the model predict low catch probability even though the defender had to run a large distance.\n\n#### Conclusions\nPress coverage is successful when the defender is fast and can respond quickly to the situation. In this play, the defender is able to change direction extremely quickly, which is significant because he starts very close to his receiver and cannot afford to get beat.","c195824d":"### Sensitivity Analysis \n\nA logistic regression is extremely interpretable. Roughly, the weights determine if a greater value contributes to a greater output probability or a smaller output probability. In this model, the inputs were normalized (to have a standard deviation of 1 and a mean of 0). The result of this is that the weights can be compared such that a greater weight means a greater impact of the variable on the model (interpreted as a more important variable when analyzing defenses). This is a critical insight of this analysis.","c5939090":"The insights that these weights give us is the importance of various factors in how defenders cover. \n\n1. The biggest factor is the average separation when the ball is thrown. More separation means a completion is more likely.\n\n2. In normal coverage, most of the weights are less significant than average separation. However, the defender's max speed has a positive weight while the defender's average speed has a negative weight. This suggests that a defender will be unsuccessful (high catch probability for the receiver) if they are more changes in speed \/ direction, situations which cause the defender to slow down. This suggests that a hitch route will be successful against normal coverage.\n\n3. The defender's distance ran varies greatly in the three cases. In soft coverage, the weight is large and negative. In normal coverage, the weight is near 0. In press coverage, the weight is large and positive. This is indicative of that in soft coverage, defender running far means they have time to recover the separation the receiver starts with. In press coverage, the defender running far means the receiver has time to create separation. \n\n4. The distance the defender and receiver ran are both important for soft coverage (the distance the receiver ran is only weighted heavily in soft coverage). A receiver needs to run further than the defender (and in the process creating separation) for an overall net zero contribution from these inputs. This also suggests that a defender does not need to move as far to be successful in soft coverage. \n\n5. The longer a play goes, the less likely it is to be a completion (may be indicative of a quarterback scrambling). Time of play has more of an effect on press coverage, which is tied to closer (likely man) coverages where if receivers aren't open after a few seconds then the quarterback may simply throw the ball away or be sacked.","bc5352dd":"Now, we look more closely into what type of defenders' positions occur throughout the past plays, and what type of defensive positions can help force an incomplete pass. We show here a heatmap of a defensive back's starting position for all passing plays in the data. For each play, we identified to whom the ball was thrown, and identify whether this pass was complete or incomplete. Then, for this specific receiver and his corresponding defensive back, we explore further their tracking data. Detailed implementation in the code. ","c0471f6c":"In the left figure above, we conclude that positioning along the x-axis has a clear effect on whether or not a pass will fall complete or incomplete. However, in the right figure, where we look at positioning along the y-axis, there is no difference at all in the means of distributions of complete and incomplete passes. Even though there is a slightly different variance between the two, the fact that they have zero mean and Gaussian shape suggests that any differences can be confidently attributed to noise.\n\nThus we focus our attention solely towards positioning on the x-axis (left figure). Fortunately, we have a good way of describing this type of positioning in the context of a real football game. These distances fall into one of three categories (press, medium, soft coverages). Additionally, the figure above suggests that defensive backs who start closer to the receiver in a typical play may do better in preventing a completed pass, but this is only an associative effect. The causality and certainty of such a claim will be explored in great depth throughout the rest of this analysis. \n\nWe also wish, here, to be concrete about what we would consider to be a \"press\", \"normal\", or \"soft\" coverage. To do this, we simply plot the distribution of all the positions of defensive backs in the data. It appears that there are three clear \"peaks\" in the data, which matches up with the understood idea of the three types of coverage. To preserve this natural clustering, we draw the following partitions in the data that distinguish coverage as being press, medium, or soft.\n\nWe include a table along with the figure below, which explicitly outlines our conditions for the different types of coverage.","7a4f2a94":"With this data, we then create three separate logistic regressions on these inputs to predict the probability of a catch. These models separate the press, normal, and soft cases of defending classified by defenders being less than 4, between 4 and 8, and more than 8 yards away from the receiver at snap (these groups were created by looking at the distribution of thed data earlier). Non-numerical inputs (categories) are also encoded. \n\nThese models were designed to aim for around the real percent of completions so we are sure that the uneven amount of completions and incompletions is not creating a model biased towards completions (remembering that a model that predicts completions only would have a high accuracy but not be very insightful). \n\nWe chose to use a logistic regression model to predict the probability of a catch for a variety of reasons. We chose this model since it is very efficient to train and makes no assumptions about class distribution in the feature space. This is beneficial since we trained the model on a high volume of data. Additionally, many of the feature weights were different for each of the covereages, so we didn't want any assumptions to be made. Another benefit of this model was that it easily provides us with a measure of how important a feature is as well as the direction of association. This was really important to us as our main goal with this project was to identify the most important features for completion prediction. This model is also less inclined to over-fitting. ","f1d740ec":"## Conclusions\n\nIn this report, we motivate and perform an analysis on the starting defender's position during a pass play. We begin by showing why this is an important problem to study and how the problem is significantly nuanced. We heuristically define three types of coverage which depends on this metric: press, normal, and soft. Then, we demonstrate that a high amount of the variance regarding whether a pass is completed can be explained by the feature set we propose. Using sensitivity analysis, we build logistic models for each of the play types and study which features increase and decrease in importance in each model. Using a cross-validated logistic model, we then are able to show what types of plays might be successful for each type of pass, which allows to make suggestions based on what attributes of a certain type of coverage are important.\n\nImportantly, we find what makes a certain type of coverage (especially press v.s. soft) successful **depends on different criteria** (listed above), which teams should look into depending on the defensive coverage scheme they wish to use. Further research could be done with regards to formalizing these criteria to do some form of probabilistic analysis how they empirically affect the catch probability.","792fd83d":"### Three types of defensive back coverage\n| Coverage Type      | Yard Range |\n| :----------------: | :-----------------:|\n| Press      | 0-4        |\n| Normal   | 4-8         |\n| Soft        | 8+          |\n","a9695b4f":"## Comparison of Defensive Back Positioning Schemes","ef318ebc":"We are interested in exploring the role of defender starting position in a given pass play. To begin with, we perform some basic analyses on passing plays to see if there are any anomalies in the data. If not, we can confidently continue with our specific analysis on defender starting position without worrying about outliers or underlying trends.","214b60ea":"## Appendix\nThis contains the function files for all the codes used in this report","8228e5c4":"First, since the choice of defender position depends on what type of play the defending team might suspect (long pass v.s. short pass), we first see if there are specific relationships that affect the types of pass plays that are chosen by the offense, which might confound with the our analysis of how a defensive team responds. ","0cbbe422":"# Defensive Back Starting Positions Reveal Key Predictors of Pass Completion Probabilities\n\nAgnim Agarwal <sup>1<\/sup>, Brandon Guo <sup>1<\/sup>, Neha Dalia <sup>1<\/sup>, Pranav Patil <sup>1<\/sup>\n\n<sup>1<\/sup> Caltech, Pasadena, CA","49d751e1":"## Introduction","e5d4878d":"### Successful soft coverage\n\nExploring the one of the lowest catch probabilities predicted by the soft coverage model, we see an 12% catch probability for a RB running a flat route. The key variables that contributed to this low catch probability are:\n\n1. Extremely low separation in the air\n2. High average separation (represents a successful soft coverage, maintaining a cushion of space until the ball is thrown so as not to get beat). \n3. The defender's average speed was lower than the receiver's average speed, although the max speeds were similar, signifying that the defender made up ground only when the RB entered the appropriate zone. The orientation also allows us to understand that this was likely a zone coverage. \n\n#### Conclusions\nFor soft coverage, a defensive back should not commit to a receiver too early, but need the speed to catch up if the receiver chooses to accelerate. ","f7369829":"From the figures above, we can see that there are no obvious underlying factors from the ones we studied above, like the time of the pass or the down of the pass, that make a very quantifiable impact on what type of passes teams tend to select. Therefore, from a defensive standpoint, these metrics do not give very significant information, and therefore these measures should not play too significant of a role in a defensive strategy. \n\nFor example, defenses should not necessarily assume a quarterback will select a long pass as the game elapses or when the offense has many yards to go. Sometimes a short pass can yield a large yardage gain, especially if the defense expects a very long pass. ","da70b2c7":"### Analysis of Special Cases\n\nHere we study, for each type of coverage, one particular play which has a very low catch probability. This obviously indicates a successful defensive effort. We look at the attributes of this play to draw some general conclusions of such plays predicted by the model.","38299d0d":"Based on the heatmap, we can see that the heatmap is roughly symmetrical across the x-axis (y = 0), which suggests that the fruit of the analysis might lie along different values of x (distance from line of scrimmage). We also notice that there is very little variation along the y-axis i.e. defenders typically line up directly with their receiver. This is what inspired us to approach the problem in terms of this distance along the x-axis, since different starting positions along the x-axis are established ideas in defensive strategy i.e. press coverage. ","06a3ef3c":"### Successful normal coverage\n\nExploring the one of the lowest catch probabilities predicted by the normal coverage model, we see an 11.28% catch probability for a deep ball thrown on a go route. The key variables that contributed to this low catch probability are: \n\n1. Low separation in the air\n2. High total time until the ball reached the target (lots of time for receiver to make up yardage)\n3. High average defender speed relative to receiver average speed. \n\n#### Conclusions\nIn order to be successful at normal coverage, a defender needs to keep track of the receiver extremely tightly. This type of coverage may favor a receiver with high speed and one who is heavier\/taller. The defender should also have a high average speed, but not necessarily a high top speed, which means it is less likely that they are caught in their tracks, but rather consistently following their receiver. ","67521066":"The NFL Big Data Bowl challenges the data science community to explore insights for defending the pass play. Here, we explore the importance of a defensive back's position relative to his receiver at the beginning of each play, offering some relevant, actionable insights to NFL organizations.\n\nWe chose this topic of research primarily because it is particularly actionable. There exists a wealth of research on the relevance of statistics during a play to the plays outcome or possible strategies. However, many of these plays rely on information of a play that is not known *a priori*, such as the routes of the receivers. Thus it remains a challenge to implement these research ideas in practice, especially since one defensive strategy against certain types of pass play may be completely undermined by a different one.\n\nWe have not seen much work done on exploring how defenders line up at the beginning of the play, but we believe that insights on this matter can be directly implemented during the games *without loss of generality*, which makes it of particular value to organizations.\n\nThus the goal of our work is to determine the most influential factors in different coverage types (position of the defensive back). Knowing this information would allow defensive coaches to determine the most favorable coverage matchups in a certain situation, for any type of defensive position they take. \n\nWe subset this notebook submission into a few main sections for clarity and organization. At each technical step of our work, we offer analysis and interpretation of key figures\/results, building to a few key conclusions and recommendations proposed at the end of the notebook. Source code is typically hidden, but can be expanded for detailed viewing.\n\n\nMany of the intermediate analyses depend on somewhat long scripts, so we have implemented them as external functions to make the code in the body of the report more readable and concise. All the functions not explicitly implemented in the body will be included in the Appendix, sorted by alphabetical order by function name. ","4ee4268a":"For each play in the season, we collected data about the receiver targeted and the closest defender as the ball was in the air, tracking various features:\n\n* avg. separation (from snap to throw)\n* avg. separation (when ball is in the air)\n* avg. difference in orientation between receiver and defender\n* down and distance\n* receiver position, height, weight\n* receiver avg. orientation\n* receiver avg. speed\n* receiver max speed\n* receiver total distance ran\n* defender position, height, weight\n* defender avg. orientation\n* defender avg. speed\n* defender max speed\n* defender total distance ran\n* time elapsed from snap to throw\n* defender starting distance away from the receiver\n* proportion of frames where separation is decreasing\n* if the play resulted in a completion\n\nOrientation was adjusted based on the direction of the play.\nFor a quick test, we rank the receivers by the lowest average separation when the ball is thrown (minimum 20 targets)","145f7f81":"## Background\n\n\nAnalyzing pass defenders is a difficult task. Looking at their overall metrics is a good start. Breaking down their play by coverage type and alignment is even better, as man vs zone schemes and slot vs wide alignment are all fundamentally different. Going a step further, however, previous studies ([FiveThirtyEight](https:\/\/fivethirtyeight.com\/features\/our-new-metric-shows-how-good-nfl-receivers-are-at-creating-separation\/), [FiveThirtyEight](https:\/\/fivethirtyeight.com\/features\/what-the-nfls-new-pass-defense-metric-can-and-cant-tell-us\/)) have found it helpful to break down their play by Press Type. This allows us to separate off coverage from tight bump-and-run coverage, which again are fundamentally different techniques and situations.\u00a0\n\nWhile evaluating a defender's press coverage ability could take hours of film study and can be subjective at times, tracking data can provide the same insight during just the first seconds of the play ([MaddenGuides](https:\/\/www.maddenguides.com\/press-normal-and-soft-coverage\/)) Shown below, the cornerback successfully limits the receiver using this technique to slow down the timing of the receiver running the route. \n\n![](https:\/\/images.actionnetwork.com\/blog\/2018\/11\/brad.gif)\n\nThis form of coverage is largely dependent on the distance between the defender and the receiver for the duration of the play. As such, we are motivated to further pursue this separation distance in the broader context of quantifying pass defender performance. As we see in our exploratory data analysis, this separation can be made in both the *x* and *y* axes, defined as shown below (from the competition page).\n\n![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F3258%2F820e86013d48faacf33b7a32a15e814c%2FIncreasing%20Dir%20and%20O.png?generation=1572285857588233&alt=media)\n\nWe will refer to the *x* and *y* axes in this way throughout the report.\n","70a7a16b":"## Exporatory Data Analysis (EDA)\n\nWe begin by exploring the given data regarding pass distances to see if there are any surface-level underlying features driving pass distance, which would in turn influence pass coverage."}}