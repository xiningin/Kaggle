{"cell_type":{"9ce2aab4":"code","95eee078":"code","0425f225":"code","543afdab":"code","3c920601":"code","671bab5b":"code","4766458f":"code","8660bfbe":"code","d0532555":"code","3cc90591":"code","b204a7fb":"code","eb6407c5":"code","a5baeb58":"code","2faceeed":"code","271a09e4":"code","9eb3cc1b":"code","00bbf19e":"code","8b1c8aba":"code","94afeccc":"code","3ef39852":"code","ac4912c8":"code","47e52a8e":"code","703035a9":"code","aa5fb7a5":"code","0680c057":"code","53b8cc24":"code","ddf49682":"code","8918329b":"code","17b31216":"markdown","51c1a082":"markdown","8d98ce50":"markdown","52d62770":"markdown","b08b4592":"markdown","3f18c949":"markdown","6519ddfc":"markdown","73b835f1":"markdown","bb96b4ea":"markdown","c5669866":"markdown","cb7a921d":"markdown","54152b7d":"markdown","56a46e50":"markdown","3897866f":"markdown","a3d5a755":"markdown","c0eb7684":"markdown","3b2963cd":"markdown","c0eb0269":"markdown","29443038":"markdown","00072194":"markdown","4bf94311":"markdown","31208986":"markdown","5fa26765":"markdown","a2d94ec4":"markdown"},"source":{"9ce2aab4":"#hide_input\n%load_ext autoreload\n%autoreload 2","95eee078":"!pip install TinyDB","0425f225":"#hide\n#carregando as depend\u00eancias\nimport pandas as pd\nimport altair as alt\nfrom tinydb import TinyDB, Query\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom IPython.display import display\nimport json\nalt.data_transformers.disable_max_rows()","543afdab":"#hide\n#setup inicial de algmas configura\u00e7\u00f5es \ndefault_color_1 = '#323443'\ndefault_color_2 = '#E7997A'","3c920601":"metadados_ficha_catalografica_path = \"..\/input\/lexml-brasil-acervo\/metadados_ficha_catalografica\/metadados_ficha_catalografica.json\"","671bab5b":"with open(metadados_ficha_catalografica_path, 'r') as f:\n    metadados_ficha_catalografica = json.load(f)","4766458f":"with open(\".\/metadados_ficha_catalografica.json\", 'w') as f:\n    json.dump(metadados_ficha_catalografica, f)","8660bfbe":"db = TinyDB(\".\/metadados_ficha_catalografica.json\") ","d0532555":"#persiste todos os registros do banco num objeto\ntotal_normativos = db.all()","3cc90591":"#collapse\ndef alter_cols(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"faz um tratamento nas colunas dataPublished e legislationType\"\"\"\n    normas = df.copy()\n    df['datePublished'] = pd.to_datetime(df['datePublished'])\n    df['legislationType'] = df['legislationType'].apply(lambda x : x.split(\"\/\")[-1] if x else np.nan)\n    return df\n\ndef load_into_dataframe(records: list) -> pd.DataFrame:\n    \"\"\"carrega os dados em um dataframe\"\"\"\n    # https:\/\/stackoverflow.com\/questions\/5352546\/extract-subset-of-key-value-pairs-from-python-dictionary-object\/5352658\n    content = [{k: data.get(k, None) for k in ('legislationIdentifier', 'legislationType', 'description',  'keywords',  'datePublished')} for data in records]\n    df = pd.DataFrame(content)\n    df = alter_cols(df)\n    return df","b204a7fb":"df = load_into_dataframe(total_normativos)","eb6407c5":"#hide\ndf = df.assign(year=df.datePublished.dt.year)\ndf = df.drop(df[df['legislationType'].isnull()].index)\ndf.loc[df['legislationType'] == 'Decreto_legislativo', 'legislationType'] = 'Decreto Legislativo'\ndf.loc[df['legislationType'] == 'Ordinary_law', 'legislationType'] = 'Lei Ordin\u00e1ria'\ndf.loc[df['legislationType'] == 'Constitution', 'legislationType'] = 'Constitui\u00e7\u00e3o'\ndf.loc[df['legislationType'] == 'Medida_provis%C3%B3ria', 'legislationType'] = 'Medida Provis\u00f3ria'\ndf.loc[df['legislationType'] == 'Lei_complementar', 'legislationType'] = 'Lei Complementar'\ndf.loc[df['legislationType'] == 'Lei_delegada', 'legislationType'] = 'Lei Delegada'\ndf.loc[df['legislationType'] == 'Constitutional_amendment', 'legislationType'] = 'Emenda Constitucional'","a5baeb58":"df.head(2)","2faceeed":"count_normas_by_year = df.groupby(['legislationType', 'year'])['legislationIdentifier']\\\n    .count()\\\n    .reset_index()\\\n    .rename(columns={'legislationIdentifier' : 'quantitativo'})","271a09e4":"#hide_input\nalt.Chart(count_normas_by_year).mark_area(opacity=0.35).encode(\n    alt.X(\"year:O\"),\n    alt.Y(\"quantitativo:Q\", stack=None),\n    alt.Color('legislationType:N', legend=alt.Legend(title=\"Tipo do Normativo\"), scale=alt.Scale(scheme='dark2')),\n    tooltip=['legislationType', 'quantitativo']\n).interactive()","9eb3cc1b":"df.loc[0, 'keywords']","00bbf19e":"tags = df.explode('keywords').copy()","8b1c8aba":"tags.head(2)","94afeccc":"#collapse\ndef plot_topN_tags(data: pd.DataFrame, field: str, N: int) -> None:\n    \"\"\"Plota um gr\u00e1fico de barras horizontais com as Top N tags mais frequentes\"\"\"\n    _ = pd.DataFrame(data)[field].value_counts()[:N]\\\n        .reset_index()\\\n        .rename(columns={'index' : 'keywords', 'keywords' : 'quantitativo'})\n    chart = alt.Chart(_)\\\n        .mark_bar()\\\n        .encode(\n            alt.X('quantitativo'),\n            alt.Y(\"keywords\", sort='-x'),\n            tooltip='quantitativo'\n        )\\\n        .properties(height=700)\\\n        .configure_mark(color=default_color_2)    \n    display(chart)","3ef39852":"plot_topN_tags(tags, 'keywords', 25)","ac4912c8":"#collapse\nnum_tags = tags['keywords'].nunique()","47e52a8e":"#collapse\ncount_clf_tags = pd.DataFrame(tags.groupby('keywords')['legislationIdentifier']\\\n                              .count()\\\n                              .sort_values(ascending=False)\\\n                              .copy())\\\n                              .rename(columns={'legislationIdentifier' : 'quantitativo'})\ncount_clf_tags = count_clf_tags.assign(\n    cumulative_sum=count_clf_tags.quantitativo.cumsum())\ncount_clf_tags = count_clf_tags.assign(\n    cumulative_perc= 100*count_clf_tags.cumulative_sum\/count_clf_tags.quantitativo.sum(),\n    rank=range(1, count_clf_tags.shape[0]+1)\n)\ncount_clf_tags['rank'] = count_clf_tags['rank'].astype('category')\ncount_clf_tags.reset_index(inplace=True)","703035a9":"count_clf_tags.head(25)","aa5fb7a5":"#collapse\ncount_select = count_clf_tags[count_clf_tags['cumulative_perc'] <= 95].copy()","0680c057":"#collapse\nchart_all_rank = alt.Chart(count_select).mark_area(\n    interpolate='step-after',\n    line=True\n).encode(\n    alt.X('rank:O', axis=alt.Axis(values=[50, 500, 1000, 2000, 3000])),\n    alt.Y('quantitativo:Q'),\n    color=alt.value(default_color_1),\n).properties(\n    width=400,\n    height=300,\n    title='Distribui\u00e7\u00e3o da frequ\u00eancia de ocorr\u00eancia das tags'\n).interactive()\n\nchart_top100_rank = alt.Chart(count_select[:100]).mark_area(\n    interpolate='step-after',\n    line=True\n).encode(\n    alt.X('rank:O', axis=alt.Axis(values=[10, 20, 30, 50, 75, 100])),\n    alt.Y('quantitativo:Q'),\n    tooltip='keywords',\n    color=alt.value(default_color_2)\n).properties(\n    width=400,\n    height=300,\n    title='Distribui\u00e7\u00e3o da frequ\u00eancia de ocorr\u00eancia das TOP 100 tags'\n).interactive()\nalt.vconcat(chart_all_rank, chart_top100_rank)\n#chart_all_rank | chart_top100_rank","53b8cc24":"#collapse\ntop50p_tags = count_clf_tags[count_clf_tags['cumulative_perc'] <= 50.00]\\\n    ['keywords'].values\\\n    .tolist() #lista das tags amostradas\n#faz um recorte nos dados que contenham as tags selecionadas\nsampling_tags = tags[tags['keywords'].isin(top50p_tags)].copy() \n#numero de tags selecionadas\nnum_tags_sampled = sampling_tags['keywords'].nunique()\n#quantitativo de normas que ser\u00e3o exclu\u00eddas da POC\nnum_diff_normas = (tags['legislationIdentifier'].nunique()-sampling_tags['legislationIdentifier'].nunique()) \n#percentual de normas que ser\u00e3o exclu\u00eddas da POC\npercent_diff_normas = num_diff_normas\/tags['legislationIdentifier'].nunique()*100 ","ddf49682":"#collapse\ndef most_common_tags_frequency(s: pd.Series) -> pd.DataFrame:\n    #faz uma contagem da ocorr\u00eancia dos quantitativos de tags por normativos\n    contador_tags = Counter()\n    for _ in s:\n        contador_tags[_] += 1\n    #cria um dataframe para armazenar as informa\u00e7\u00f5es estruturadas acima\n    plot_count = []\n    for _ in contador_tags.most_common(20): #TOP 20 ocorr\u00eancias mais frequentes\n        plot_count.append([_[0], _[1]])\n    quantidade_tags_mais_frequentes = pd.DataFrame(plot_count, columns=['n\u00b0 de tags por norma', 'n\u00b0 de ocorr\u00eancias'])\n    quantidade_tags_mais_frequentes['n\u00b0 de tags por norma'] = quantidade_tags_mais_frequentes['n\u00b0 de tags por norma'].astype('category')\n    return quantidade_tags_mais_frequentes\n\n#analise para o conjunto original (populacao)\n#identifica o n\u00famero de tags por norma\ncount_len_pop = df.loc[df['legislationIdentifier']\\\n                   .isin(sampling_tags['legislationIdentifier']\\\n                   .unique()), 'keywords'].apply(lambda x : len(x))\nquantidade_tags_mais_frequentes_populacao = most_common_tags_frequency(count_len_pop)\n\n#analise para o conjunto amostral\ncount_len_sampling = sampling_tags.groupby('legislationIdentifier')['keywords'].count()\nquantidade_tags_mais_frequentes_sample = most_common_tags_frequency(count_len_sampling)\n\n#graficos\n#hide\ntop20_pop_chart = alt.Chart(quantidade_tags_mais_frequentes_populacao, title='TOP 20 quantidades de tags por norma na popula\u00e7\u00e3o.')\\\n        .mark_bar(color=default_color_2)\\\n        .encode(\n            alt.X('n\u00b0 de ocorr\u00eancias'),\n            alt.Y(\"n\u00b0 de tags por norma\", sort='-x')\n        )\n#hide_input\ntop20_sample_chart = alt.Chart(quantidade_tags_mais_frequentes_sample, title=\"TOP 20 quantidades de tags por norma na amostragem.\")\\\n        .mark_bar(color=default_color_1)\\\n        .encode(\n            alt.X('n\u00b0 de ocorr\u00eancias'),\n            alt.Y(\"n\u00b0 de tags por norma\", sort='-x'))\nmedian_num_tags_norma_original = np.median(count_len_pop)\nmedian_num_tags_norma_sample = np.median(count_len_sampling)","8918329b":"#hide_input\ntop20_pop_chart | top20_sample_chart","17b31216":"![count_tags_95p](https:\/\/raw.githubusercontent.com\/netoferraz\/o-eu-analitico\/master\/_notebooks\/img\/eda-gov-data-product\/count_tag_95p.png)","51c1a082":"### Esse \u00e9 um notebook originalmente postado no blog <a href='https:\/\/netoferraz.github.io\/o-eu-analitico\/machine%20learning\/dados%20abertos\/data%20product\/2020\/07\/12\/gov-data-product.html' target='_blank' style='color: #f97b6f;'>o eu anal\u00edtico.<\/a>","8d98ce50":"A tabela abaixo apresenta que as 25 `tags` mais frequentes s\u00e3o respons\u00e1veis por aproximadamente **40%** de todas as ocorr\u00eancias de anota\u00e7\u00e3o em nosso _dataset_. Assim, temos um ind\u00edcio consider\u00e1vel sobre uma poss\u00edvel distribui\u00e7\u00e3o de cauda longa para essa `feature`.","52d62770":"Portanto, conclu\u00edmos que **33%** da popula\u00e7\u00e3o de `tags` do _dataset_ s\u00e3o respons\u00e1veis por **95%** de todas as anota\u00e7\u00f5es realizadas. Por fim, podemos plotar a distribui\u00e7\u00e3o de frequ\u00eancia da ocorr\u00eancia dessa _feature_ e claramente confirma o ind\u00edcio que trata-se de uma feature com distribui\u00e7\u00e3o assim\u00e9trica e com cauda longa.","b08b4592":"Dessa forma, podemos avaliar quantas tags representam **95%** das ocorr\u00eancias de anota\u00e7\u00e3o.","3f18c949":"Com a estrutura dos dados adequada a nossa an\u00e1lise, determinaremos as `tags` mais frequentes em nosso _dataset_.","6519ddfc":"![normas excluidas](https:\/\/raw.githubusercontent.com\/netoferraz\/o-eu-analitico\/master\/_notebooks\/img\/eda-gov-data-product\/normas_excluidas.png)","73b835f1":"Pudemos avaliar que as **TOP 25** `tags` variam em ocorr\u00eancias desde 16k como o caso de `MUNICIPIO` at\u00e9 algo pr\u00f3ximo a 2.7k para `CRIA\u00c7\u00c3O`. Al\u00e9m disso, precisamos avaliar quantas `tags` distintas existem em nosso `dataset`.","bb96b4ea":"Podemos inspecionar os dois primeiros registros dos nossos dados.","c5669866":"No \u00faltimo [post](https:\/\/netoferraz.github.io\/o-eu-analitico\/dados%20abertos\/governo\/crawler\/2020\/07\/07\/metadados-normativos-federais.html) coletamos um _dataset_ com o objetivo de criar um _data product_ a partir do treinamento de um modelo de classifica\u00e7\u00e3o multi-label, treinando-o sobre as ementas de normativos federais.","cb7a921d":"Assim, definimos um recorte **inicial** para podermos iniciar o treinamento do nosso modelo de classifica\u00e7\u00e3o multi-label para a nossa POC, todavia, o treinamento ficar\u00e1 para o pr\u00f3ximo post. Espero que tenham gostado de conhecer essa base, tanto quanto eu \ud83d\udc68, at\u00e9 a pr\u00f3xima!","54152b7d":"Como primeiro passo do nosso processo de constru\u00e7\u00e3o de um produto derivado de aprendizado de m\u00e1quina, precisamos iniciar com um processo de an\u00e1lise explorat\u00f3ria dos dados (AED). Portanto, vamos carregar os dados em uma inst\u00e2ncia do `TinyDB`, em seguida vamos selecionar as features do nosso interesse e carreg\u00e1-las em um dataframe.","56a46e50":"O campo `legislationType` nos informa o tipo de normativos existente na base de dados, abaixo apresentamos uma visualiza\u00e7\u00e3o onde podemos identificar os tipos e os respectivos quantitativos.","3897866f":"![median count tags](https:\/\/raw.githubusercontent.com\/netoferraz\/o-eu-analitico\/master\/_notebooks\/img\/eda-gov-data-product\/median_count_tags.png)","a3d5a755":"![count_tags](https:\/\/raw.githubusercontent.com\/netoferraz\/o-eu-analitico\/master\/_notebooks\/img\/eda-gov-data-product\/count_tag.png)","c0eb7684":"Constatada o elevado n\u00famero de `tags` distintas utilizadas em nosso _dataset_, \u00e9 necess\u00e1rio explorar a distribui\u00e7\u00e3o do percentual acumulado das suas respectivas frequ\u00eancias. Essa vis\u00e3o poder\u00e1 nos auxiliar se, eventualmente, estamos lidando com uma distribui\u00e7\u00e3o de cauda longa, isto \u00e9, um n\u00famero grande de `tags` que foram utilizadas apenas algumas vezes ao longo do processo de anota\u00e7\u00e3o da base de dados.","3b2963cd":"Nessa POC decidimos restringir o treinamento inicial a um subset das `tags` mais representativas e como temos uma distribui\u00e7\u00e3o de cauda longa \u00e9 razo\u00e1vel que tenhamos muitos registros de `tags` pouco frequentes pulverizadas em v\u00e1rias classifica\u00e7\u00f5es. Mas ao reduzir o escopo de `tags` em nossa amostragem espera-se uma redu\u00e7\u00e3o no quantitativo de anota\u00e7\u00f5es por norma, e de fato isso aconteceu j\u00e1 que pudemos constatar uma redu\u00e7\u00e3o da mediana das frequ\u00eancias das quantidades de `tags` por normativo reduziu de **10** para **5**.","c0eb0269":"Abaixo, podemos ver que um comparativo entre o conjunto de dados originais e da amostragem que realizamos. Para o primeiro, a maior frequ\u00eancia de ocorr\u00eancia \u00e9 uma norma ter 10 registros de `tags` anotadas. A quantidade elevada de anota\u00e7\u00f5es por normativo \u00e9 algo que ao meu ver confirma o potencial de uso de classifica\u00e7\u00e3o autom\u00e1tica por aprendizado de m\u00e1quina de modo a garantir uma maior homegeniedade e acur\u00e1cia no processo de classifica\u00e7\u00e3o.","29443038":"Al\u00e9m disso, podemos inspecionar o campo _keywords_ que cont\u00e9m m\u00faltiplas `tags` associadas a mesma norma, como apresentado abaixo:","00072194":"Nesse momento precisamos alterar a estrutura do `DataFrame` para que possamos ter o nosso `modelo de dados` com uma granularidade de um registro de `keyword`  por linha da tabela.","4bf94311":"Esse \u00e9 o segundo post de uma s\u00e9rie de como construir um produto *data-driven* de ponta a ponta, caso voc\u00ea ainda n\u00e3o tenha acompanhado os demais, abaixo segue uma s\u00edntese com os respectivos links \ud83d\ude00.\n 1. Em [metadados de normas jur\u00eddicas federais](https:\/\/netoferraz.github.io\/o-eu-analitico\/dados%20abertos\/governo\/crawler\/2020\/07\/07\/metadados-normativos-federais.html) coletamos dados do sistema LexML.","31208986":"Quando apresentamos o nosso problema de aprendizado de m\u00e1quina falamos que tratava-se de um tarefa de classifica\u00e7\u00e3o _multi-label_, portanto, sabendo que cada norma pode receber simultaneamente mais de uma tag, uma pergunta relevante \u00e9: **quantas tags por normativos costumam ser atribu\u00eddas a cada norma?**","5fa26765":"# \"um produto orientado a dados governamentais: parte 1\"\n> \"constru\u00e7\u00e3o de um produto data driven\"","a2d94ec4":"Para nossa prova de conceito iremos restringir, inicialmente, as `tags` que representam **50%** das ocorr\u00eancias. Essa decis\u00e3o restringe o quantitativo a **47** `tags`, mas pela representatividade destas um percentual muito pequeno de normas ser\u00e3o exclu\u00eddas da nossa amostragem."}}