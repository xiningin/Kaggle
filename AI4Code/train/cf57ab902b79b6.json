{"cell_type":{"56f3ab64":"code","3865d76e":"code","38a04395":"code","b45e920a":"code","2e1b25bd":"code","ba5e77cb":"code","acd14b27":"code","811f7f2f":"code","f34123e1":"code","cb56daf0":"code","9ec77e1c":"code","2e9a423a":"code","ad73b568":"code","23b3f073":"code","50083b07":"code","003addd1":"code","2ed4a527":"code","d8f0f153":"code","6d17656b":"code","f99d38e0":"markdown","870da40b":"markdown","1f0e8ca0":"markdown","d7a4cc80":"markdown","235c227d":"markdown","fbd6b678":"markdown","608f5cad":"markdown","b16883df":"markdown","6214cd62":"markdown"},"source":{"56f3ab64":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, MinMaxScaler, OrdinalEncoder\nfrom sklearn.model_selection import StratifiedKFold","3865d76e":"# read data \ntrain = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ntest  = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv\")","38a04395":"print(train.info(),test.info())","b45e920a":"#split numerical and categorical feature\nnum_feature = [\"Age\",\"Vintage\",\"Annual_Premium\"]\ncat_feature = [\"Gender\",\"Driving_License\",\"Region_Code\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\",\"Policy_Sales_Channel\"]\n\n# convert into integer\ntrain[\"Policy_Sales_Channel\"] = train[\"Policy_Sales_Channel\"].astype(\"int\")\ntrain[\"Region_Code\"] = train[\"Region_Code\"].astype(\"int\")","2e1b25bd":"psc_tot = train[\"Policy_Sales_Channel\"].value_counts()\ntrain[\"psc_count\"] = train[\"Policy_Sales_Channel\"].map(psc_tot)\npsc_scount = train[train[\"Response\"]==1].groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\ntrain[\"psc_scount\"] = train[\"Policy_Sales_Channel\"].map(psc_scount)\ntrain[\"psc_success_rate\"] = (train[\"psc_scount\"]\/train[\"psc_count\"])*100\ntrain[\"psc_success_rate\"].fillna(0,inplace=True)\nreg_tot = train[\"Region_Code\"].value_counts()\ntrain[\"reg_count\"] = train[\"Region_Code\"].map(reg_tot)\npsc_scount = train[train[\"Response\"]==1].groupby(\"Region_Code\")[\"Response\"].count()\ntrain[\"reg_scount\"] = train[\"Region_Code\"].map(psc_scount)\ntrain[\"reg_success_rate\"] = (train[\"reg_scount\"]\/train[\"reg_count\"])*100\n","ba5e77cb":"#Binning the Age \ntrain[\"Age_Cat\"]= pd.cut(train[\"Age\"],bins=[10,20,30,40,50,60,70,80,90,100],labels=[1,2,3,4,5,6,7,8,9])","acd14b27":"# encode the categorical varriable (encoding policy sales channel and Region Code makes high cardinality so i avoid encoding for this fields )\nohe = OneHotEncoder(sparse=False)        \ntransformed_train_data = ohe.fit_transform(train[[\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"]])\n\n# # the above transformed_data is an array so convert it to dataframe\nencoded_train_data = pd.DataFrame(transformed_train_data, index=train.index)        \nencoded_train_data.columns = ohe.get_feature_names([\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"])\ntrain_data = pd.concat([train, encoded_train_data], axis=1)","811f7f2f":"sc =  StandardScaler()\nvintage_scaled_array = sc.fit_transform(train_data[[\"Vintage\",\"Region_Code\",\"Policy_Sales_Channel\",\"psc_success_rate\",\"reg_success_rate\"]])\n\nminmaxsc = MinMaxScaler()\nannual_premium_scaled_array = minmaxsc.fit_transform(train_data[[\"Annual_Premium\"]])\n\ntrain_data[[\"Vintage\",\"Region_Code\",\"Policy_Sales_Channel\",\"psc_success_rate\",\"reg_success_rate\"]] = vintage_scaled_array\ntrain_data[\"Sc_Annual_Premium\"] = annual_premium_scaled_array","f34123e1":"train_data.head()","cb56daf0":"train_data.columns","9ec77e1c":"trainX = train_data.drop([\"id\",\"Age\",\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"psc_count\",\"psc_scount\",\"reg_count\",\"reg_scount\",\"Vintage\",\"Annual_Premium\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\",\"Response\"], axis=1)\ntrainY = train_data[\"Response\"]","2e9a423a":"trainX.head()","ad73b568":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nlogreg = LogisticRegression(random_state=0,max_iter=1000)\nmodels = {\n    \"Logistic Regression\":logreg,\n}\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nfor model_name,model in models.items():\n    scores = []\n    train_scores = []\n    for train_indx,val_indx in skf.split(X=trainX,y=trainY):\n        #get train and test data     \n        X_train,X_val = trainX.loc[train_indx],trainX.loc[val_indx]\n        Y_train,Y_val = trainY[train_indx],trainY[val_indx]\n        model.fit(X_train,Y_train)\n        #make a prediction\n        Y_predict = model.predict_proba(X_val)\n\n        accuracy = roc_auc_score(Y_val,Y_predict[:,1])\n        Ytrain_predict = model.predict_proba(X_train)\n        train_accuracy = roc_auc_score(Y_train,Ytrain_predict[:,1])        \n        print(\"train\",train_accuracy)\n        print(\"test\",accuracy)\n        scores.append(accuracy)\n        train_scores.append(train_accuracy)\n    print(\"Mean Accurracy of test {0} is {1}\".format(model_name,np.mean(scores)))\n    print(\"Mean Accurracy of train {0} is {1}\".format(model_name,np.mean(train_scores)))","23b3f073":"train","50083b07":"oe = OrdinalEncoder()\ntrain[[\"Gender\",\"Vehicle_Damage\",\"Vehicle_Age\",\"Age_Cat\"]] = oe.fit_transform(train[[\"Gender\",\"Vehicle_Damage\",\"Vehicle_Age\",\"Age_Cat\"]])","003addd1":"train","2ed4a527":"trainX = train.drop([\"id\",\"Age\",\"Vintage\",\"psc_count\",\"psc_scount\",\"reg_count\",\"reg_scount\",\"Response\"], axis=1)\ntrainY = train[\"Response\"]","d8f0f153":"trainX.dtypes","6d17656b":"from sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nrf = RandomForestClassifier(n_estimators=7,max_depth=10)\nmodels = {\n    \"rf\":rf,\n}\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nfor model_name,model in models.items():\n    scores = []\n    train_scores = []\n    for train_indx,val_indx in skf.split(X=trainX,y=trainY):\n        #get train and test data     \n        X_train,X_val = trainX.loc[train_indx],trainX.loc[val_indx]\n        Y_train,Y_val = trainY[train_indx],trainY[val_indx]\n        model.fit(X_train,Y_train)\n        #make a prediction\n        Y_predict = model.predict_proba(X_val)\n\n        accuracy = roc_auc_score(Y_val,Y_predict[:,1])\n        Ytrain_predict = model.predict_proba(X_train)\n        train_accuracy = roc_auc_score(Y_train,Ytrain_predict[:,1])        \n        print(\"train\",train_accuracy)\n        print(\"test\",accuracy)\n        scores.append(accuracy)\n        train_scores.append(train_accuracy)\n    print(\"Mean Accurracy of test {0} is {1}\".format(model_name,np.mean(scores)))\n    print(\"Mean Accurracy of train {0} is {1}\".format(model_name,np.mean(train_scores)))","f99d38e0":"# Scaling","870da40b":"# Random Forest Classifier","1f0e8ca0":"# Logistic Regression","d7a4cc80":"## Modelling\nHere target(Response) is a imbalanced data, So i have used stratified cross validation method\n","235c227d":"# Feature Engineering","fbd6b678":"# Binning","608f5cad":"# Encoding(Ordinal Encoder)","b16883df":"# Encoding","6214cd62":"# EDA\nI have done EDA and Baseline Model[ here](https:\/\/www.kaggle.com\/arunkumar13111\/vehicle-insurance-prediction-auc-84). In this notebook, i will  explore following classification algoithms for understanding.\n1. Logistic Regression\n2. RandomForest"}}