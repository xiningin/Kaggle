{"cell_type":{"a66d6a52":"code","1ceafd91":"code","7b8721d1":"code","d1d1eee0":"code","b73cffc9":"code","c7c71eea":"code","7a71e19a":"code","17db9540":"code","5e62952f":"code","afca1692":"code","2a8aec52":"code","490c51c3":"code","e3b597f5":"code","4093a90b":"code","2df0d9f5":"code","1224e0fb":"code","1855104e":"code","41a720a5":"markdown","89c5d2fd":"markdown","5fd9e7c3":"markdown","d30b4614":"markdown","ca55bc57":"markdown","6194f64f":"markdown","ca825263":"markdown","955916fb":"markdown"},"source":{"a66d6a52":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1ceafd91":"#importing libraries\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nimport matplotlib.pyplot as plt\n%matplotlib inline","7b8721d1":"#importing dataset\ndf = pd.read_csv(\"\/kaggle\/input\/spam-classification-for-basic-nlp\/Spam Email raw text for NLP.csv\")\ndf.head(10)","d1d1eee0":"#shape of dataset\ndf.shape","b73cffc9":"#checking for null values\ndf.isna().sum()","c7c71eea":"#info of data\ndf.info()","7a71e19a":"df.CATEGORY.unique()","17db9540":"sns.countplot(df[\"CATEGORY\"])","5e62952f":"df[\"CATEGORY\"].value_counts()","afca1692":"def standardize_text(df, content_field):\n    df[content_field] = df[content_field].str.replace(r\"http\\S+\", \"\")\n    df[content_field] = df[content_field].str.replace(r\"http\", \"\")\n    df[content_field] = df[content_field].str.replace(r\"@\\S+\", \"\")\n    df[content_field] = df[content_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n    df[content_field] = df[content_field].str.replace(r\"@\", \"at\")\n    df[content_field] = df[content_field].str.lower()\n    return df","2a8aec52":"standardize_text(df,\"MESSAGE\")","490c51c3":"import re\nimport nltk\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer","e3b597f5":"lemmatizer = WordNetLemmatizer()\ncorpus = []\n\nfor i in range(0, len(df)):\n    message = re.sub('[^a-zA-Z]', ' ', df['MESSAGE'][i])\n    message = message.split()\n    message =[word for word in message if not word in set(stopwords.words('english'))]\n    message = [lemmatizer.lemmatize(word) for word in message]\n    message = ' '.join(message)\n    corpus.append(message)","4093a90b":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(ngram_range=(1, 3))\nX = tfidf.fit_transform(corpus)\ny = df[\"CATEGORY\"]","2df0d9f5":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","1224e0fb":"# build the lightgbm model\nimport lightgbm as lgb\nclassifier = lgb.LGBMClassifier()\nclassifier.fit(X_train, y_train)","1855104e":"y_pred = classifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nacc = accuracy_score(y_pred, y_test)\nreport = classification_report(y_test, y_pred)\nprint(report)\ncm = confusion_matrix(y_pred, y_test)\nsns.heatmap(cm, annot=True)\nprint(\"Accuracy of LightGBM Model:\", acc*100,\"%\")","41a720a5":"## Applying tfidf","89c5d2fd":"Author: Purvit Vashishtha","5fd9e7c3":"Dependent variable(CATEGORY) is already encoded, so no need to apply encoding.","d30b4614":"# Spam Classification NLP- LightGBM Model","ca55bc57":"Please UPVOTE this notebook if you find it insightful!\n\nThanks in advance.","6194f64f":"# Cleaning Text","ca825263":"# Training LightGBM Classifier","955916fb":"## Accuracy and Confusion Matrix of Model"}}