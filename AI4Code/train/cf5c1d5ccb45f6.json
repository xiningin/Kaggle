{"cell_type":{"140bfa11":"code","26eb1d4e":"code","8a604cdf":"code","0bcb520d":"code","de62ef1d":"code","73e01c78":"code","82a3a0bc":"code","58f39216":"code","bda649ce":"code","0ef8bf17":"code","be810abe":"code","950528bf":"code","bfaaea90":"code","21c1acd7":"code","ee3af148":"code","10e54818":"code","da6ddc48":"code","5e021a8c":"code","6c24bdc5":"code","524e76a8":"code","c0c6cdeb":"code","d4909267":"code","b8793050":"code","1ee4c642":"code","226992d1":"code","1b364a3a":"code","c61c0796":"code","961e9baf":"code","190ded13":"code","11300585":"code","4da2c681":"code","79e5cf7d":"code","5923d655":"code","af05b86f":"code","42a63482":"code","82c8c5ba":"code","e2c996a0":"code","a9467554":"code","b52c83de":"code","e4e66b20":"code","c79a1398":"code","6adbd812":"code","40b4550f":"code","2099c875":"code","c8abab67":"code","5fc07a88":"code","dddc2479":"code","5cd5f1bb":"code","3c3e2fb6":"code","2e2ca871":"code","cdd3e977":"code","e6442981":"code","e16f77a9":"code","6f2df52b":"code","8323735f":"code","c078052a":"code","2de85f0d":"code","91702032":"code","c6f4aceb":"markdown","e7102c78":"markdown","17c3d69d":"markdown","3f2f2a5d":"markdown","b6c7d700":"markdown","c1590c98":"markdown","1a584b16":"markdown","a2f1d92a":"markdown","5a9c780e":"markdown","b046e22d":"markdown","6503883d":"markdown","31e37292":"markdown","b15b8f21":"markdown","644a60fc":"markdown","ed11eeed":"markdown","95797dbb":"markdown","4f7ed5e6":"markdown"},"source":{"140bfa11":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport os\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n","26eb1d4e":"# reading the dataset\ncars = pd.read_csv(r'\/kaggle\/input\/car-price\/CarPrice_Assignment.csv')\n","8a604cdf":"# summary of the dataset: 205 rows, 26 columns, no null values\nprint(cars.info())","0bcb520d":"# head\ncars.head()","de62ef1d":"# symboling: -2 (least risky) to +3 most risky\n# Most cars are 0,1,2\ncars['symboling'].astype('category').value_counts()\n\n","73e01c78":"# aspiration: An (internal combustion) engine property showing \n# whether the oxygen intake is through standard (atmospheric pressure)\n# or through turbocharging (pressurised oxygen intake)\n\ncars['aspiration'].astype('category').value_counts()","82a3a0bc":"# drivewheel: frontwheel, rarewheel or four-wheel drive \ncars['drivewheel'].astype('category').value_counts()","58f39216":"# wheelbase: distance between centre of front and rarewheels\nplt.figure(figsize=(20,5))\nsns.distplot(cars['wheelbase'])\nplt.show()","bda649ce":"# curbweight: weight of car without occupants or baggage\nplt.figure(figsize=(20,5))\nsns.distplot(cars['curbweight'])\nplt.show()","0ef8bf17":"# stroke: volume of the engine (the distance traveled by the piston in each cycle)\nplt.figure(figsize=(20,5))\nsns.distplot(cars['stroke'])\nplt.show()","be810abe":"# compression ration: ratio of volume of compression chamber at largest capacity to least capacity\nplt.figure(figsize=(20,5))\nsns.distplot(cars['compressionratio'])\nplt.show()","950528bf":"# target variable: price of car\nplt.figure(figsize=(20,5))\nsns.distplot(cars['price'])\nplt.show()","bfaaea90":"# all numeric (float and int) variables in the dataset\ncars_numeric = cars.select_dtypes(include=['float', 'int'])\ncars_numeric.head()","21c1acd7":"# dropping symboling and car_ID \ncars_numeric = cars_numeric.drop(['symboling','car_ID'], axis=1)\ncars_numeric.head()","ee3af148":"# paiwise scatter plot\nsns.pairplot(cars_numeric)\nplt.show()","10e54818":"# correlation matrix\ncor = cars_numeric.corr()\ncor","da6ddc48":"# plotting correlations on a heatmap\n\n# figure size\nplt.figure(figsize=(16,8))\n\n# heatmap\nsns.heatmap(cor, cmap=\"rainbow\", annot=True)\nplt.show()\n","5e021a8c":"# variable formats\ncars.info()","6c24bdc5":"# converting symboling to categorical\ncars['symboling'] = cars['symboling'].astype('object')\ncars.info()","524e76a8":"# CarName: first few entries\ncars['CarName'][:30]","c0c6cdeb":"# Extracting carname\n\n#str.split() by space\ncarnames = cars['CarName'].apply(lambda x: x.split(\" \")[0])\ncarnames[:30]","d4909267":"import re\n\n# regex: any alphanumeric sequence before a space, may contain a hyphen\np = re.compile(r'\\w+-?\\w+')\ncarnames = cars['CarName'].apply(lambda x: re.findall(p, x)[0])\nprint(carnames)","b8793050":"# New column car_company\ncars['car_company'] = cars['CarName'].apply(lambda x: re.findall(p, x)[0])","1ee4c642":"# look at all values \ncars['car_company'].astype('category').value_counts()","226992d1":"# replacing misspelled car_company names\n\n# volkswagen\ncars.loc[(cars['car_company'] == \"vw\") | \n         (cars['car_company'] == \"vokswagen\")\n         , 'car_company'] = 'volkswagen'\n\n# porsche\ncars.loc[cars['car_company'] == \"porcshce\", 'car_company'] = 'porsche'\n\n# toyota\ncars.loc[cars['car_company'] == \"toyouta\", 'car_company'] = 'toyota'\n\n# nissan\ncars.loc[cars['car_company'] == \"Nissan\", 'car_company'] = 'nissan'\n\n# mazda\ncars.loc[cars['car_company'] == \"maxda\", 'car_company'] = 'mazda'","1b364a3a":"cars['car_company'].astype('category').value_counts()","c61c0796":"# drop carname variable\ncars = cars.drop('CarName', axis=1)","961e9baf":"cars.info()","190ded13":"# outliers\ncars.describe()","11300585":"cars.info()","4da2c681":"# split into X and y\nX = cars.loc[:, ['symboling', 'fueltype', 'aspiration', 'doornumber',\n       'carbody', 'drivewheel', 'enginelocation', 'wheelbase', 'carlength',\n       'carwidth', 'carheight', 'curbweight', 'enginetype', 'cylindernumber',\n       'enginesize', 'fuelsystem', 'boreratio', 'stroke', 'compressionratio',\n       'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n       'car_company']]\n\ny = cars['price']\n","79e5cf7d":"# creating dummy variables for categorical variables\n\n# subset all categorical variables\ncars_categorical = X.select_dtypes(include=['object'])\ncars_categorical.head()\n","5923d655":"# convert into dummies\ncars_dummies = pd.get_dummies(cars_categorical, drop_first=True)\ncars_dummies.head()","af05b86f":"# drop categorical variables \nX = X.drop(list(cars_categorical.columns), axis=1)","42a63482":"# concat dummy variables with X\nX = pd.concat([X, cars_dummies], axis=1)","82c8c5ba":"# split into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    train_size=0.7,\n                                                    test_size = 0.3, random_state=100)","e2c996a0":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']]=scaler.fit_transform(X_train[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']])\nX_train.head()","a9467554":"X_test[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']]=scaler.transform(X_test[['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight',\n       'enginesize', 'boreratio', 'stroke', 'compressionratio', 'horsepower',\n       'peakrpm', 'citympg', 'highwaympg']])\nX_test.head()","b52c83de":"lasso = Lasso()\nparams = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\nfolds = 5\n# cross validation\nmodel_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train, y_train) ","e4e66b20":"cv_results = pd.DataFrame(model_cv.cv_results_)\n\ncv_results.head()","c79a1398":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.figure(figsize=(20,10))\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.grid()\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","6adbd812":"alpha =100\n\nlasso = Lasso(alpha=alpha)\n        \nlasso.fit(X_train, y_train) \nlasso.coef_","40b4550f":"imp_lasso = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Coefficient\": lasso.coef_})\nimp_lasso.sort_values(by=\"Coefficient\", ascending=False)","2099c875":"imp_lasso =imp_lasso[imp_lasso['Coefficient'] !=0]\nimp_lasso.sort_values(by=\"Coefficient\", ascending=False)","c8abab67":"y_pred = lasso.predict(X_test)\n","5fc07a88":"fig = plt.figure(figsize=(20,10))\nplt.scatter(y_test, y_pred, alpha=.5)\nfig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16) \nplt.show()","dddc2479":"df= pd.DataFrame({'Actual':y_test,'Predictions':y_pred})\ndf['Predictions']= round(df['Predictions'],2)\ndf.head()","5cd5f1bb":"from sklearn import metrics ","3c3e2fb6":"metrics.explained_variance_score(y_test,y_pred)","2e2ca871":"metrics.mean_absolute_error(y_test,y_pred)","cdd3e977":"metrics.max_error(y_test,y_pred)","e6442981":"metrics.mean_squared_error(y_test,y_pred)","e16f77a9":"metrics.mean_squared_log_error(y_test,y_pred)","6f2df52b":"metrics.median_absolute_error(y_test,y_pred)","8323735f":"metrics.r2_score(y_test,y_pred)","c078052a":"metrics.mean_poisson_deviance(y_test,y_pred)","2de85f0d":"metrics.mean_gamma_deviance(y_test,y_pred)","91702032":"metrics.mean_tweedie_deviance(y_test,y_pred)","c6f4aceb":"Notice that **some car-company names are misspelled** - vw and vokswagen should be volkswagen, porcshce should be porsche, toyouta should be toyota, Nissan should be nissan, maxda should be mazda etc.\n\nThis is a data quality issue, let's solve it.","e7102c78":"## Lasso Regression","17c3d69d":"## Model Building and Evaluation","3f2f2a5d":"Let's create a new column to store the company name and check whether it looks okay.","b6c7d700":"Let's now make a pairwise scatter plot and observe linear relationships.","c1590c98":"The heatmap shows some useful insights:\n\nCorrelation of price with independent variables:\n- Price is highly (positively) correlated with wheelbase, carlength, carwidth, curbweight, enginesize, horsepower (notice how all of these variables represent the size\/weight\/engine power of the car)\n\n- Price is negatively correlated to ```citympg``` and ```highwaympg``` (-0.70 approximately). This suggest that cars having high mileage may fall in the 'economy' cars category, and are priced lower (think Maruti Alto\/Swift type of cars, which are designed to be affordable by the middle class, who value mileage more than horsepower\/size of car etc.)\n\nCorrelation among independent variables:\n- Many independent variables are highly correlated (look at the top-left part of matrix): wheelbase, carlength, curbweight, enginesize etc. are all measures of 'size\/weight', and are positively correlated \n\n\nThus, while building the model, we'll have to pay attention to multicollinearity (especially linear models, such as linear and logistic regression, suffer more from multicollinearity).","1a584b16":"Notice that the carname is what occurs before a space, e.g. alfa-romero, audi, chevrolet, dodge, bmx etc.\n\nThus, we need to simply extract the string before a space. There are multiple ways to do that.\n\n\n","a2f1d92a":"## Data Cleaning\n\nLet's now conduct some data cleaning steps. \n\nWe've seen that there are no missing values in the dataset. We've also seen that variables are in the correct format, except ```symboling```, which should rather be a categorical variable (so that dummy variable are created for the categories).\n\nNote that it *can* be used in the model as a numeric variable also. \n\n","5a9c780e":"Here, although the variable ```symboling``` is numeric (int), we'd rather treat it as categorical since it has only 6 discrete values. Also, we do not want 'car_ID'.","b046e22d":"## Data Preparation \n\n\n#### Data Preparation\n\nLet's now prepare the data and build the model.","6503883d":"## Car Price Prediction \n\nThe solution is divided into the following sections: \n- Data understanding and exploration\n- Data cleaning\n- Data preparation\n- Model building and evaluation\n","31e37292":"Netx, we need to extract the company name from the column ```CarName```. ","b15b8f21":"#### Understanding the Data Dictionary\n\nThe data dictionary contains the meaning of various attributes; some non-obvious ones are:","644a60fc":"#### Data Exploration\n\nTo perform linear regression, the (numeric) target variable should be linearly related to *at least one another numeric variable*. Let's see whether that's true in this case.\n\n\nWe'll first subset the list of all (independent) numeric variables, and then make a **pairwise plot**.","ed11eeed":"### Data Understanding and Exploration\n\nLet's first have a look at the dataset and understand the size, attribute names etc.","95797dbb":"The ```car_company``` variable looks okay now. Let's now drop the car name variable.","4f7ed5e6":"This is quite hard to read, and we can rather plot correlations between variables. Also, a heatmap is pretty useful to visualise multiple correlations in one plot."}}