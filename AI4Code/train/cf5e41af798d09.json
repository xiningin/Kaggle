{"cell_type":{"204dc98a":"code","05893914":"code","704fd094":"code","2a948152":"code","562ae5ef":"code","48fe7acc":"code","7c7a8f5c":"code","b4152ec6":"code","5487bcf9":"code","bcf41f67":"code","102215b2":"code","96eee11a":"code","89952807":"code","bc4d9a9a":"code","fcfff552":"code","9cb8d4ba":"code","a597186b":"code","ff6364d7":"code","3bcd13e4":"code","5dfea6f2":"code","3d50928e":"code","0799f82f":"code","05851677":"code","d19b892d":"code","b2906d9a":"code","6f0086a9":"code","9c6eedff":"code","0253d197":"code","a4ee56e7":"code","4a51f646":"code","db1dccf4":"code","1dc20b8a":"code","d3cab8c9":"code","d8e84acc":"code","a2a6604b":"code","bbaa88e7":"code","698ec938":"code","d44cadff":"code","da94ff82":"code","0fbdfef4":"code","8300cf15":"code","9472335c":"code","cb31b546":"code","1c3d239f":"code","2e098107":"code","432b7792":"code","3a933ee5":"code","f32b3a5d":"code","d3fe5cc2":"code","7272985f":"code","b4343a77":"code","0d61ff6a":"code","d1ef76d9":"code","84d1cea0":"code","d1533d5c":"code","5259b057":"code","825ba088":"code","02b5140e":"code","6cf1c6f6":"code","add8b3e5":"code","7d6978cd":"code","376eee55":"code","e32edc8c":"code","84b2aa55":"code","fff6f47a":"markdown","7044e472":"markdown","286c47ff":"markdown","f5740967":"markdown","90d91ed5":"markdown","a0a9d9cb":"markdown","7758a6c7":"markdown","29442f17":"markdown","d6ecb1bd":"markdown","76b4217f":"markdown","aeca8414":"markdown","29ec29b6":"markdown","e0ed05e1":"markdown","051399c7":"markdown","00894eb2":"markdown","0cca3a4a":"markdown","775f2957":"markdown","316d0ce3":"markdown","1ad3770f":"markdown","df46570c":"markdown","736d36bc":"markdown"},"source":{"204dc98a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","05893914":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [train_data, test_data]","704fd094":"train_data.info()","2a948152":"train_data.head(10)","562ae5ef":"test_data.head(10)","48fe7acc":"print(train_data.shape)\nprint(test_data.shape)","7c7a8f5c":"train_data.describe()","b4152ec6":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women survivors:\", rate_women)","5487bcf9":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men survivors:\", rate_men)","bcf41f67":"train_data.isnull().sum()","102215b2":"for dataset in combine:\n    dataset.drop(['Cabin','Ticket'],axis = 1,inplace = True)\n    print(dataset.shape)","96eee11a":"for dataset in combine:\n    dataset['Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_data['Title'], train_data['Sex'])","89952807":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')","bc4d9a9a":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_data.head()","fcfff552":"train_data.drop(['Name','PassengerId'],axis = 1,inplace = True)\ntest_data.drop(['Name'],axis = 1,inplace = True)\ncombine = [train_data, test_data]\nprint(train_data.shape)\nprint(test_data.shape)","9cb8d4ba":"sns.countplot(x=\"Survived\",data=train_data)","a597186b":"sns.countplot(x=\"Survived\", hue = 'Pclass',data=train_data)","ff6364d7":"sns.countplot(x=\"Survived\", hue = 'Sex',data=train_data)","3bcd13e4":"sns.countplot(x=\"Survived\", hue = 'SibSp',data=train_data)","5dfea6f2":"sns.countplot(x=\"Survived\", hue = 'Parch',data=train_data)","3d50928e":"sns.violinplot(x=\"Survived\", y=\"Age\", data = train_data, size = 9)","0799f82f":"sns.countplot(x=\"Survived\",hue = \"Embarked\",data=train_data)","05851677":"#filling missing values for 'Embarked' with most frequent one\nfreq_port = train_data.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","d19b892d":"for dataset in combine:\n    mean = train_data[\"Age\"].mean()\n    std = test_data[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = train_data[\"Age\"].astype(int)","b2906d9a":"train_data.isnull().sum()","6f0086a9":"test_data.isnull().sum()","9c6eedff":"# Filling the one missing value from Fare in test_data\ntest_data['Fare'].fillna(test_data['Fare'].dropna().median(), inplace=True)\ntest_data.isnull().sum()","0253d197":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)","a4ee56e7":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","4a51f646":"train_data.head()","db1dccf4":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","1dc20b8a":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1","d3cab8c9":"train_data.head()","d8e84acc":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 36), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 50), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 50) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\ntrain_data.head()","a2a6604b":"train_data['FareBand'] = pd.qcut(train_data['Fare'], 4)\ntest_data['FareBand'] = pd.qcut(test_data['Fare'], 4)\ntrain_data[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\ntest_data.head()","bbaa88e7":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_data = train_data.drop(['FareBand'], axis=1)\ntest_data = test_data.drop(['FareBand'], axis=1)\ncombine = [train_data, test_data]","698ec938":"train_data.head()","d44cadff":"test_data.head()","da94ff82":"X_train = train_data.drop(['Survived'], axis = 1).values\nY_train = train_data['Survived'].values\nX_test  = test_data.drop(\"PassengerId\", axis=1).copy()","0fbdfef4":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)","8300cf15":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X_train,Y_train,test_size=0.2)","9472335c":"from sklearn.linear_model import LogisticRegression\nlr_clf = LogisticRegression()\nlr_clf.fit(x_train, y_train)","cb31b546":"pred_train = lr_clf.predict(x_train)\npred_test = lr_clf.predict(x_test)","1c3d239f":"from sklearn.metrics import accuracy_score\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","2e098107":"from sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier(n_jobs= -1, n_estimators = 100, warm_start= True, max_depth= 5, min_samples_leaf= 2, max_features = 'sqrt',verbose = 0)\nrf_clf.fit(x_train, y_train)","432b7792":"pred_train = rf_clf.predict(x_train)\npred_test = rf_clf.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","3a933ee5":"from sklearn.ensemble import AdaBoostClassifier\nadb_clf = AdaBoostClassifier(n_estimators = 100, learning_rate = 0.5)\nadb_clf.fit(x_train, y_train)","f32b3a5d":"pred_train = adb_clf.predict(x_train)\npred_test = adb_clf.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","d3fe5cc2":"from sklearn.ensemble import GradientBoostingClassifier\ngdb_clf = GradientBoostingClassifier(n_estimators = 100, max_depth = 3, min_samples_leaf = 2, verbose = 0)\ngdb_clf.fit(x_train, y_train)","7272985f":"pred_train = gdb_clf.predict(x_train)\npred_test = gdb_clf.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","b4343a77":"from sklearn.ensemble import ExtraTreesClassifier\net_clf = ExtraTreesClassifier(n_jobs = -1, n_estimators = 100, max_depth = 5, min_samples_leaf = 2, verbose = 0)\net_clf.fit(x_train,y_train)","0d61ff6a":"pred_train = et_clf.predict(x_train)\npred_test = et_clf.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","d1ef76d9":"from sklearn.svm import SVC\nsvc_clf = SVC(kernel = 'linear', C = 0.025)\nsvc_clf.fit(x_train,y_train)","84d1cea0":"pred_train = svc_clf.predict(x_train)\npred_test = svc_clf.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","d1533d5c":"from xgboost import XGBClassifier\nxgb_clf = XGBClassifier(n_estimators= 50, max_depth= 5, min_samples_leaf= 2)\nxgb_clf.fit(x_train, y_train)","5259b057":"pred_train = xgb_clf.predict(x_train)\npred_test = xgb_clf.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","825ba088":"import lightgbm as lgb\nlgb_clf = lgb.LGBMClassifier(n_estimators=100)\nlgb_clf.fit(x_train,y_train)","02b5140e":"pred_train = lgb_clf.predict(x_train)\npred_test = lgb_clf.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","6cf1c6f6":"from sklearn.ensemble import VotingClassifier\nvt_classifier = VotingClassifier(estimators = [('lr', lr_clf),\n                                               ('rf',rf_clf),\n                                               ('adb',adb_clf),\n                                               ('gdb',gdb_clf),\n                                               ('etc',et_clf),\n                                               ('svc',svc_clf),\n                                               ('xgb',xgb_clf),\n                                               ('lgbm',lgb_clf),], voting = 'hard')","add8b3e5":"vt_classifier.fit(x_train,y_train)","7d6978cd":"pred_train = vt_classifier.predict(x_train)\npred_test = vt_classifier.predict(x_test)\ntrain_accuracy = accuracy_score(y_train,pred_train)\ntest_accuracy = accuracy_score(y_test,pred_test)\nprint(\"Training Accuracy: \", train_accuracy)\nprint(\"Testing Accuracy: \", test_accuracy)","376eee55":"final_pred = vt_classifier.predict(X_train)\ntrain_accuracy = accuracy_score(final_pred,Y_train)\nprint(\"Training Accuracy: \", train_accuracy)","e32edc8c":"X_test = X_test.values\nfinal_pred = final_model.predict(X_test)","84b2aa55":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = final_pred\nsubmission.to_csv('titanic_submission3.csv', index=False)","fff6f47a":"# Creating new features FamilySize and IsAlone from Parch ana SibSp","7044e472":"## XGBoost Classifier","286c47ff":"## Logistic Regression","f5740967":"# Replacing Titles with common ones or Rare and coverting them to ordinal values","90d91ed5":"## Gradient Boosting Classifier","a0a9d9cb":"# Handling categorical variables","7758a6c7":"# Creating bands for age and Fare","29442f17":"# Dropping Name Column as we have extracted the Titles","d6ecb1bd":"# Checking Missing Values","76b4217f":"# Importing and Studying Data","aeca8414":"## Extra Trees Classifier","29ec29b6":"# Visualization and Analysis","e0ed05e1":"## Support Vector Classifier","051399c7":"# Final Model (Ensembling Stacking all the models)","00894eb2":"# Dropping Cabin(too many missing values) and Ticket(no contribution to survival)","0cca3a4a":"## LightGBM Classifier","775f2957":"## Random Forest Classifier","316d0ce3":"## Ada Boost Classifier","1ad3770f":"# Creating The Models and Checking individual performances","df46570c":"# Handling missing values for Age and Embarked","736d36bc":"# Creating a new feature 'Title' by extracting title from names"}}