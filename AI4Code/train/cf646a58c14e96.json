{"cell_type":{"d5c5b297":"code","8c822763":"code","43b3296f":"code","76b913df":"code","9b99f11a":"code","d42df10d":"code","66c619fe":"code","acf7d38a":"code","02307ab4":"code","e9cfd673":"code","179aaa8a":"code","29f555b8":"code","69ca3761":"code","f92e2d38":"code","4d81f52d":"code","e8e6ebf1":"code","f58bb953":"code","9f21c2a3":"markdown","9cbcc457":"markdown","274d7b4c":"markdown","da73fc0c":"markdown","633169d1":"markdown","49e2a2cc":"markdown","c0e96e89":"markdown","7b39b59c":"markdown","2885d497":"markdown","b3d3853d":"markdown","ef227bf8":"markdown","3661f806":"markdown","ee5fc545":"markdown","7adcb5bd":"markdown","e62adb56":"markdown","53670de2":"markdown","8d87dfe9":"markdown","2c80350c":"markdown","96f1c36f":"markdown","07d5d407":"markdown","c54ca4e6":"markdown","ebf3b5bf":"markdown"},"source":{"d5c5b297":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\n\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n\n\nimport tensorflow as tf\n\nimport cv2\nimport os\nimport pandas as pd\nimport numpy as np","8c822763":"labels = ['vehicles', 'non-vehicles']\nimg_size = 64\ndef get_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","43b3296f":"#Now we can easily fetch our train and validation data.\ndata = get_data('\/kaggle\/input\/vehicle-detection-image-set\/data')\n","76b913df":"df=pd.DataFrame(data,columns=['image','label'])\n","9b99f11a":"df['image'][1].shape","d42df10d":"X_train, X_test, y_train, y_test = train_test_split(df['image'], df['label'], test_size=0.2, random_state=1)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)","66c619fe":"print ('train_df length: ', len(X_train), '  test_df length: ', len(X_test), '  valid_df length: ', len(X_val))","acf7d38a":"l = []\nfor i in data:\n    if(i[1] == 0):\n        l.append(\"non-vehicles\")\n    else:\n        l.append(\"vehicles\")\nsns.set_style('darkgrid')\nsns.countplot(l)","02307ab4":"plt.figure(figsize = (5,5))\nplt.imshow(data[1][0])\nplt.title(labels[data[0][1]])","e9cfd673":"plt.figure(figsize = (5,5))\nplt.imshow(data[-1][0])\nprint(data[-1][0].shape)\nplt.title(labels[data[-1][1]])","179aaa8a":"def change_image_dimension(data):\n    data=np.reshape(data.to_list(),(len(data),img_size,img_size,3))\n    return data","29f555b8":"X_train=change_image_dimension(X_train)\nX_val=change_image_dimension(X_val)\nX_test=change_image_dimension(X_test)\nX_train=X_train\/255.0\nX_val=X_val\/255.0\nX_test=X_test\/255.0\nX_label=np.array(y_train,dtype=int)\nval_label=np.array(y_val,dtype=int)\ny_test=np.array(y_test,dtype=int)","69ca3761":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","f92e2d38":"model = Sequential()\nmodel.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(64,64,3)))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dense(2, activation=\"sigmoid\"))\n\nmodel.summary()","4d81f52d":"opt = Adam(lr=0.0001)\nmodel.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])","e8e6ebf1":"history = model.fit(X_train,X_label,epochs = 5 ,batch_size=10, validation_data = (X_val, val_label))","f58bb953":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(5)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","9f21c2a3":"Now, let\u2019s train our model for 50 epochs since our learning rate is very small.","9cbcc457":"Let\u2019s define a simple CNN model with 3 Convolutional layers followed by max-pooling layers. A dropout layer is added after the 3rd maxpool operation to avoid overfitting.","274d7b4c":"# Step 6:- Evaluating the result","da73fc0c":"# Step 1:- Import the required libraries ","633169d1":"Let\u2019s compile the model now using Adam as our optimizer and SparseCategoricalCrossentropy as the loss function. We are using a lower learning rate of 0.000001 for a smoother curve.","49e2a2cc":"# Step 3:- Visualize the data ","c0e96e89":"\nHere we will be making use of the Keras library for creating our model and training it. We also use Matplotlib and Seaborn for visualizing our dataset to gain a better understanding of the images we are going to be handling. Another important library to handle image data is Opencv.\n","7b39b59c":"**Let\u2019s Build our Image Classification Model!**","2885d497":"#  Understanding the Problem Statement","b3d3853d":"Next, let\u2019s define the path to our data. We define a function called get_data() that makes it easier for us to create our train and validation dataset. We define the two labels \u2018vehicles\u2019 and \u2018non-vehicles\u2019 that we will use. We use the Opencv imread function to read the images in the RGB format and resize the images to our desired width and height in this case both being 64.","ef227bf8":"Data augmentation on the train data:-","3661f806":"#  spliting of data","ee5fc545":"**Table of Contents**\n\n1. Image classification\n2. Understanding the problem statement\n3. Lets Build our Image Classification Model\n       1. Data Preprocessing\n       2. Data Augmentation\n       3. Model definition and training\n       4.Evaluating Results","7adcb5bd":"**Step 4:- Data Preprocessing and Data Augmentation** \n\nNext, we perform some Data Preprocessing and Data Augmentation before we can proceed with building the model.","e62adb56":"# Step 5:- Define the Model ","53670de2":"#  What is image classification","8d87dfe9":"# Step 2:- Loading the data","2c80350c":"Vehicle classification has crop up as an important field of study due of its importance in variety of applications like surveillance, security framework, traffic congestion prevention and accidents avoidance.\n\nOur Objective is to recognize if a vehicle in an image or not using Vehicle Detection Image Set which contains 17k images of dimension (64x64x3). separeted in two folders named: Non-Vehicles and Vehicles.","96f1c36f":"Let us also visualize a random image from the vehicles and non-vehicles classes","07d5d407":"\n\nAs a human, I can (usually) identify what it depicts with ease. Otherwise,the machine does not find this task *Image classification* quite easy as Human, then, is a challenge for machines. Which is where deep learning comes in.\n\nImage Classification is the task of assigning an input image, one label from a fixed set of categories. This is one of the core problems in Computer Vision.\n","c54ca4e6":"**Changing Dimension Of Data**","ebf3b5bf":"Let\u2019s visualize our data to explore the data that we are working in, for example, plot the number of images in both the classes in order to know how balance our data is, using seaborn library."}}