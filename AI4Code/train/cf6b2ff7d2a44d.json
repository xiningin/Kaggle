{"cell_type":{"91a21d60":"code","ad980b1a":"code","31119732":"code","785dfd9d":"code","d656caeb":"code","1bb397e4":"code","642433b6":"code","7ef6a80e":"code","a0addca9":"code","fb2bdc2d":"code","0608f12e":"code","8d05fd2e":"code","2cf6f7db":"code","f351d4c5":"code","39121649":"code","6d66dedb":"code","49dbe218":"code","1f7ffdf6":"code","9b89ca1b":"code","4dfab001":"code","61e9f83b":"code","815b304c":"code","657d118b":"code","ca11942f":"code","f1105758":"code","ee7f0b55":"code","8f2c03a2":"code","718812f2":"code","7171863e":"code","1bea205b":"code","344c92e0":"code","b74917a4":"code","4129512a":"code","6c975693":"code","2b68b607":"code","ab774ad2":"markdown","7207eb47":"markdown"},"source":{"91a21d60":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\n\nfrom torchvision import datasets, transforms, models \nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid","ad980b1a":"data_dir = '..\/input\/music-instrument-images-dataset\/music_instruments_images'","31119732":"labels=pd.read_csv('..\/input\/music-instrument-images-dataset\/music_data_img.csv')\nlabels","785dfd9d":"Name = labels['Instrument_Type'].unique().tolist()\nprint(Name)\nprint(len(Name))","d656caeb":"N=list(range(len(Name)))    \nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) ","1bb397e4":"labels['label']=labels['Instrument_Type'].map(normal_mapping)","642433b6":"files = labels['Image_File'].unique().tolist()\nprint(files[0:10])\nprint(len(files))","7ef6a80e":"dataset=[]\nfor i in tqdm(range(len(labels))):\n    labeli=labels.loc[i,'label']\n    filei=labels.loc[i,'Image_File']\n    path=os.path.join(data_dir,filei)\n    img1=cv2.imread(path)\n    img2=cv2.resize(img1,dsize=(100,100),interpolation=cv2.INTER_CUBIC)\n    img3=img2.astype(np.float32)\n    image=torch.from_numpy(img3)\n    dataset+=[[image,labeli]]","a0addca9":"dataset[100]","fb2bdc2d":"# view one image shape of the dataset.\nimg, label = dataset[100]\nprint(img.shape)\nprint(label)","0608f12e":"def show_image(img,label):\n    plt.imshow(img.numpy().astype(int))","8d05fd2e":"show_image(*dataset[20])","2cf6f7db":"torch.manual_seed(20)\nval_size = len(dataset)\/\/10\ntest_size = len(dataset)\/\/5\ntrain_size = len(dataset) - val_size - test_size","f351d4c5":"train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\nlen(train_ds), len(val_ds), len(test_ds)   ","39121649":"batch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size, num_workers=4, pin_memory=True)","6d66dedb":"m=len(dataset)\nM=list(range(m))\nrandom.seed(2021)\nrandom.shuffle(M)","49dbe218":"fig, axs = plt.subplots(3,3,figsize=(12,12))\nfor i in range(9):\n    r=i\/\/3\n    c=i%3\n    img1,label=dataset[M[i]]\n    ax=axs[r][c].axis(\"off\")\n    ax=axs[r][c].set_title(reverse_mapping[label])\n    ax=axs[r][c].imshow(img1.numpy().astype(int))\nplt.show()","1f7ffdf6":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","9b89ca1b":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","4dfab001":"torch.cuda.is_available()","61e9f83b":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","815b304c":"device = get_default_device()\ndevice","657d118b":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","ca11942f":"input_size = 3*100*100\noutput_size = len(Name)","f1105758":"class Model(ImageClassificationBase):\n    def __init__(self, input_size, output_size):\n        super().__init__()\n        # hidden layer\n        self.in_layer = nn.Linear(input_size, 8384)\n        self.hidden1 = nn.Linear(8384, 4192)\n        self.hidden2 = nn.Linear(4192, 2096)\n        self.hidden3 = nn.Linear(2096, 1048)\n        self.out_layer = nn.Linear(1048, output_size)\n        \n    def forward(self, xb):\n        # Flatten images into vectors\n        out = xb.view(xb.size(0), -1)\n        out = self.in_layer(out)\n        out = self.hidden1(F.relu(out))\n        out = self.hidden2(F.relu(out))\n        out = self.hidden3(F.relu(out))\n        out = self.out_layer(F.relu(out))\n        return out","ee7f0b55":"model = to_device(Model(input_size, output_size), device)","8f2c03a2":"model","718812f2":"history = [evaluate(model, val_loader)]\nhistory","7171863e":"history += fit(8, 0.01, model, train_loader, val_loader)","1bea205b":"history += fit(8, 0.001, model, train_loader, val_loader)","344c92e0":"history += fit(4, 0.0001, model, train_loader, val_loader)","b74917a4":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.show()\n    \n    \ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n    plt.show()","4129512a":"plot_accuracies(history)","6c975693":"plot_losses(history)","2b68b607":"evaluate(model, test_loader)","ab774ad2":"# Music Instrument Images Classify Torch Linear","7207eb47":"# Linear Model"}}