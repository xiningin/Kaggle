{"cell_type":{"4189e1f7":"code","a5328ca8":"code","ba6a6971":"code","219a2762":"code","777bcff9":"code","3dd10b33":"code","63b8fc4a":"code","56dc1ef4":"code","7c2aa7d3":"code","05c3336a":"code","226876f8":"code","a304d7ac":"code","52d5b603":"code","0988369d":"code","1d78fe66":"code","b9fa8b98":"code","76ca3659":"code","ec47a3fa":"code","5109f1d4":"code","561dd4f8":"code","39426052":"markdown","4052a36c":"markdown","ee9029ae":"markdown","b26e8e09":"markdown","d752efa0":"markdown","f3543a22":"markdown","af729726":"markdown","524650d5":"markdown","68784cd0":"markdown","900fe754":"markdown","4f3dae2e":"markdown","0119d8b4":"markdown","5b33b2d4":"markdown","927d9b33":"markdown","acb376d4":"markdown","6c8c929d":"markdown"},"source":{"4189e1f7":"# The following instruction is used to install a given library\n#!pip install library_name\n# (e.g below)\n!pip install tweepy # to install the tweepy library","a5328ca8":"# Useful Modules\n\nimport tweepy as tw # used to extract data from twitter\nimport pandas as pd # used to create a pandas dataframe\nimport json # used to load the json files","ba6a6971":"\"\"\"\nThis function loads the credentials in a secured maner from a json file given in parameter\n\"\"\"\ndef load_credentials(path_to_file):\n    \"\"\"\n    @param: \n        path_to_file: the path to the JSON file containing the credentials\n        \n    @return: \n        credentials: a dictionary containing the credential details\n    \"\"\"\n\n    with open(path_to_file) as json_file:\n        credentials = json.load(json_file)\n    return credentials","219a2762":"\"\"\"\nThis function is used to get the twitter API instance\n\"\"\"\ndef get_API(credentials):\n    \"\"\"\n    @params: \n        credentials: the dictionary containing the credentional details\n        \n    @return:\n        a twitter API instance\n    \"\"\"\n    auth = tw.OAuthHandler(credentials['consumer_key'], credentials['consumer_secret'])\n    auth.set_access_token(credentials['access_token'], credentials['access_token_secret'])\n    \n    return tw.API(auth, wait_on_rate_limit=True)","777bcff9":"credentials = load_credentials('..\/input\/twitter-credentials\/credentials.json')\napi = get_API(credentials)","3dd10b33":"\"\"\"\nThis function is used to extract tweets \n\"\"\"\ndef search_tweets(search_word, date_since, limit=20):\n    \"\"\"\n    @params:\n        search_word: the topic we want to search about (e.g. covid19)\n        data_since: the date from when we want the information related to \"search_word\"\n        limit: used to restrict the number of tweets to be returned. If not specified, it will retrive all the Tweets\n    @return:\n        tweets_cursor: a cursor used to paginate through the large retrieved data\n    \"\"\"\n    tweets_cursor = tw.Cursor(api.search,\n              q=search_words,\n              lang=\"en\",\n              since=date_since).items(limit)\n    \n    return tweets_cursor","63b8fc4a":"# Define the search term and the date_since date as variables\nsearch_words = \"#covid19\"\ndate_since = \"2020-10-01\" # October 1st","56dc1ef4":"# the cursor will contain the most 20 (because the default value is set to 20) recent tweets about covid19.\ncovid_cursor = search_tweets(search_words, date_since)","7c2aa7d3":"covid_cursor","05c3336a":"i=0\nfor tweet in covid_cursor:\n    i=i+1\n    print(f\"Tweet N\u00b0 {i}: {tweet.text}\\n\")","226876f8":"\"\"\"\nFunction creating pandas dataframe from Cursor\n\"\"\"\ndef create_df_from_cursor(tweet_cursor):\n    \"\"\"\n    @params:\n        tweet_cursor: the twitter cursor\n       \n    @return:\n       tweets_df: a pandas dataframe format of the tweets\n    \"\"\"\n    all_tweets = []\n    \n    for tweet in tweet_cursor:\n        parsed_tweet = {}\n        parsed_tweet['date'] = tweet.created_at\n        parsed_tweet['author'] = tweet.user.name\n        parsed_tweet['twitter_name'] = tweet.user.screen_name\n        parsed_tweet['text'] = tweet.text\n        parsed_tweet['number_of_likes'] = tweet.favorite_count\n        parsed_tweet['number_of_retweets'] = tweet.retweet_count\n        \n        all_tweets.append(parsed_tweet)\n    \n    tweets_df = pd.DataFrame(all_tweets)\n    \n    # Remove duplicates\n    tweets_df = tweets_df.drop_duplicates( \"text\" , keep='first')\n    \n    return tweets_df ","a304d7ac":"covid_cursor = search_tweets(search_words, date_since) # I didn't specify the limit because it will be taking the default value","52d5b603":"df = create_df_from_cursor(covid_cursor)","0988369d":"df.head()","1d78fe66":"df.shape","b9fa8b98":"covid_cursor = search_tweets(search_words, date_since, limit=100)\ndf2 = create_df_from_cursor(covid_cursor)","76ca3659":"df2.shape","ec47a3fa":"df2.to_csv('twitter_data.csv', index=False)","5109f1d4":"# Load the same file\ndf2 = pd.read_csv('\/kaggle\/working\/twitter_data.csv')","561dd4f8":"df2.shape","39426052":"### 0. Useful libraries for the notebook","4052a36c":"**But wait... Where are the tweets?**   \nAs I mentioned above, our *search_tweets* functions returns a Cursor object. To be able to get the data, we need to paginate through it, and that's what is done with the following instruction where we will be showing only the \"texts\" of the tweets. ","ee9029ae":"### 2. Get twitter API instance","b26e8e09":"**What is a cursor?**:   \nCursor() returns an object that you can iterate or loop over to access the data collected. Each item in the iterator has various attributes that you can access to get information about each tweet including:\n\n- the text of the tweet  \n- the person who posted the tweet  \n- the date the tweet was posted   \n- and more.   \n\nLets say we want tweets containing the term #covid19 since October 1st.","d752efa0":"Let say that I want to get the last 100 tweets. To do so, I only need to specify the value of *limit*, which will otherwise remain 20 if not changed","f3543a22":"#### Note:   \nWe see 82 instead of 100, because we decided to remove the duplicates from the dataframe. Those duplicated can come from the retweets of official tweets.   ","af729726":"### Final Step - Putting All Together\n","524650d5":"### 1. Load credentials for authentification on Twitter Client   \nTo access the Twitter API, you will need your Twitter developer credentials. I made a video how to get your own API (link: https:\/\/www.youtube.com\/watch?v=PqqXjwoDQiY).\nTo make sure nobody else access those credentials but me, I created a json file containing all the information. So the following function is used to load them.","68784cd0":"# Get Tweets related to a specific Topic on Twitter   \nSometimes we want to perform some experiments, but do not always have an existing dataset related to that specific experiments. Based on that, it might be important to know how to get data on your own to be able to continue the experiments you want to conduct.","900fe754":"### 3. Search for Tweets   \nAt this stage, I already have the API, so I can start searching for tweets related to a topic, a given date (date_since) and the number of tweets we want to retrieve","4f3dae2e":"![](http:\/\/)","0119d8b4":"**Ready to create an instance**:  \nWith the previous two functions I can finally create an API instance","5b33b2d4":"This notebook covers in four simple steps how to get tweets related to a specific topic (e.g. Covid19, US Election, etc.). The four steps are:  \n\n1. *Load credentials for authentification on Twitter Client*\n2. *Get twitter API instance*\n3. *Search for Tweets*\n4. *Create pandas dataframe on the tweets you retrieved* \n5. Save the final result as pandas dataframe","927d9b33":"### 4. Create pandas dataframe on the tweets you retrieved  ","acb376d4":"### 5. Save the final result as a pandas dataframe  \nThe file will be located under ***\/kaggle\/working*** directory","6c8c929d":"#### Did you like it? \nJust give it an upvote :)     \nI will happy to answer your questions in the comment section"}}