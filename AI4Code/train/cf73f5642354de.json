{"cell_type":{"8aacd40f":"code","c5e55123":"code","c2907194":"code","d875ea4c":"code","0779419f":"code","0ad11355":"code","8ed8efc0":"code","0fea6f4d":"code","fd9242c3":"code","2916866a":"code","e69e42da":"code","f09414f8":"code","508f8f97":"code","2c559735":"code","09035195":"code","51a3738d":"code","d947a12d":"code","8bc4f657":"code","ce852072":"code","e67cd6eb":"code","95c00318":"code","7e018f9e":"code","5b5636c2":"markdown","86a34c98":"markdown","78912074":"markdown","5357f935":"markdown","8fcdad19":"markdown","a4e567ae":"markdown","0e1b046e":"markdown","3453787f":"markdown","988744d1":"markdown","9d9453f3":"markdown","bd40dd97":"markdown","23cb4dd9":"markdown","4c7b87aa":"markdown","8a72ead4":"markdown"},"source":{"8aacd40f":"import numpy as np \nimport pandas as pd\n\nimport os\nimport glob\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.impute import SimpleImputer\nfrom datetime import datetime","c5e55123":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2907194":"products = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\ndistricts =pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")","d875ea4c":"path = \"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\"\nfiles = glob.glob(path + \"\/*.csv\")\nlist_of_df = [pd.read_csv(file).assign(district_id=os.path.basename(file).strip(\".csv\")) for file in files] ","0779419f":"engagement = pd.concat(list_of_df, ignore_index= True)","0ad11355":"districts = districts[districts.state.notna()].reset_index(drop = False)\n\n# Impute the missing values\ndistricts_imputed = districts.copy()\n#setting strategy to 'mean' to impute by the mean\nmean_imputer = SimpleImputer(strategy='most_frequent')# strategy can also be mean or median \ndistricts_imputed.iloc[:,:] = mean_imputer.fit_transform(districts_imputed)\ndistricts_imputed.isna().sum()\n","8ed8efc0":"districts_imputed = districts_imputed[districts_imputed['county_connections_ratio']=='[0.18, 1[']","0fea6f4d":"# convert datetime type, district_id to int64 (same as districts)\n\nengagement['time'] = pd.to_datetime(engagement['time'])\nengagement['district_id']= engagement['district_id'].astype(str).astype(int)\n\n# Impute the missing values\nengagement_imputed = engagement.copy()\nengagement_imputed['time']= engagement_imputed['time'].apply(lambda x: x.toordinal()) # convert datetime to ordinal to apply Imputer\n#setting strategy to 'mean' to impute by the mean\nmean_imputer_eng = SimpleImputer(strategy='most_frequent')# strategy can also be mean or median \nengagement_imputed.iloc[:,:]= mean_imputer_eng.fit_transform(engagement_imputed)\nengagement_imputed.isna().sum()","fd9242c3":"#convert back to datetime type.\nengagement_imputed['time'] = engagement_imputed['time'].astype(int) # convert to int to apply fromordinal()\nengagement_imputed['time']= engagement_imputed['time'].apply(lambda x: datetime.fromordinal(x))","2916866a":"#Remove punctuations\npd.options.mode.chained_assignment = None\nfor i in [' ', '.']:\n    for k in range(len(products)):\n        if pd.isna(products['Provider\/Company Name'][k]) == False:\n            products['Provider\/Company Name'][k] = products['Provider\/Company Name'][k].strip(i)\n\n#split the sub categories\nproducts['funct_main'] = products['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts['funct_sub'] = products['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts['funct_sub'] = products['funct_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproducts.drop(\"Primary Essential Function\", axis=1, inplace=True)","e69e42da":"districts_by_state = districts_imputed['state'].value_counts().to_frame().reset_index()\ndistricts_by_state.columns = ['state','count_districts']\n#using built-in United States Choropleth Map\nus_state = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\ndistricts_by_state['state_abbrev'] = districts_by_state['state'].replace(us_state) #https:\/\/stackoverflow.com\/questions\/40075106\/replace-values-in-pandas-series-with-dictionary\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of School Districts per State\",\n    geo_scope='usa',\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations=districts_by_state.state_abbrev,\n        zmax=1,\n        z = districts_by_state.count_districts,\n        locationmode = 'USA-states',\n        marker_line_color='white',\n        geo='geo',\n        colorscale = 'BuPu', \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()\n\nplt.figure(figsize = (15, 8))\nsns.set_style(\"white\")\na = sns.barplot(data = districts['state'].value_counts().reset_index(), x = 'state', y = 'index', palette='rocket')\nplt.xticks([])\nplt.yticks(fontname = 'arial', fontsize = 14, color = '#283655')\nplt.ylabel('')\nplt.xlabel('')\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n    \nfor p in a.patches:\n    width = p.get_width()\n    plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}',\n             ha = 'center', va = 'center', fontname = 'arial', fontsize = 15, color = '#283655')\n\nplt.show()","f09414f8":"fig = px.pie(districts_imputed['locale'].value_counts().reset_index().rename(columns = {'locale': 'count'}), values = 'count', names = 'index', width = 650, height = 650)\n\nfig.update_traces(textposition = 'inside', \n                  textinfo = 'percent + label', \n                  hole = 0.7, \n                  marker = dict(colors = ['#90afc5','#336b87','#2a3132','#763626'], line = dict(color = 'white', width = 2)))\n\nfig.update_layout(annotations = [dict(text = ' The count of districts <br>in each type <br>of areas', \n                                      x = 0.5, y = 0.5, font_size = 20, showarrow = False, \n                                      font_family = 'arial',\n                                      font_color = '#283655')],\n                  showlegend = False)\n                  \nfig.show()","508f8f97":"#replace intervals the the means\nfor i in ['pct_black\/hispanic', 'pct_free\/reduced']:\n    districts_imputed[i] = districts_imputed[i].apply(lambda x: float(x.split(',')[0][1:]) + 0.1)\n\ndistricts_imputed['pp_total_raw'] = districts_imputed['pp_total_raw'].apply(lambda x: int(x.split(',')[0][1:]) + 1000)\n\ndistricts_imputed.drop('county_connections_ratio', axis = 1, inplace = True)\n\ndistricts_imputed.head(5)","2c559735":"dist_area_group = districts_imputed.groupby('locale').agg({'pct_black\/hispanic': 'mean', 'pct_free\/reduced': 'mean', 'pp_total_raw': 'mean'}).reset_index()\n\ncolors = ['#90afc5', '#336b87', '#763626']\n\nfig = plt.figure(figsize = (12,10))\nfor i in range(len(dist_area_group.columns.tolist()[1:])):\n    plt.subplot(2, 2, i+1)\n    sns.set_style(\"white\")\n    plt.title(dist_area_group.columns.tolist()[1:][i], size = 16, fontname = 'arial', y = 1.09, color = colors[i])\n    plt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\n    a = sns.barplot(data = dist_area_group, x = 'locale', y = dist_area_group.columns.tolist()[1:][i], color = colors[i])\n    plt.ylabel('')\n    plt.xlabel('')\n    plt.xticks(fontname = 'arial', size = 12)\n    plt.yticks([])\n    \n    for j in ['right', 'top', 'left']:\n        a.spines[j].set_visible(False)\n    for j in ['bottom']:\n        a.spines[j].set_linewidth(1.4)\n      \n    if i < 2:\n        for p in a.patches:\n            height = p.get_height()\n            a.annotate(f'{int(height*100)} %', (p.get_x() + p.get_width() \/ 2, p.get_height()-0.03), \n                   ha = 'center', va = 'center', \n                   size = 12,\n                   xytext = (0, 5), \n                   textcoords = 'offset points',\n                   color = 'white',\n                   fontname = 'arial')\n    else:\n        for p in a.patches:\n            height = p.get_height()\n            a.annotate(f'{int(height)} $', (p.get_x() + p.get_width() \/ 2, p.get_height()-1000), \n                   ha = 'center', va = 'center', \n                   size = 12,\n                   xytext = (0, 5), \n                   textcoords = 'offset points',\n                   color = 'white',\n                   fontname = 'arial')\n            \nplt.figtext(0.07, 1.05, 'Characteristics of school districts by locale', fontsize = 20, fontname = 'arial', color = '#283655')\nfig.tight_layout(pad = 3)\n\nplt.show()","09035195":"plt.figure(figsize = (15, 8))\nplt.title('TOP-15 of learning providers\/companies')\na = sns.barplot(data = products['Provider\/Company Name'].value_counts().reset_index().head(15), x = 'Provider\/Company Name', y = 'index', palette='rocket')\nplt.xticks([])\nplt.yticks(fontname = 'arial', fontsize = 12, color = '#283655')\nplt.ylabel('')\nplt.xlabel('')\n\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n    \nfor p in a.patches:\n    width = p.get_width()\n    plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}',\n             ha = 'center', va = 'center', fontname = 'arial', fontsize = 15, color = '#283655')\nplt.show()","51a3738d":"fig = px.pie(products['Sector(s)'].value_counts().reset_index().rename(columns = {'Sector(s)': 'count'}).head(15), values = 'count', names = 'index', width = 650, height = 650)\n\nfig.update_traces(textposition = 'inside', \n                  textinfo = 'percent + label', \n                  hole = 0.7,marker = dict(colors = ['#336b87','#2a3132','#763626']))\n\nfig.update_layout(annotations = [dict(text = 'Sector of education <br>where the product is used', \n                                      x = 0.5, y = 0.5, font_size = 20, showarrow = False, \n                                      font_family = 'arial',\n                                      font_color = '#283655')],\n                  showlegend = False)\n                  \nfig.show()","d947a12d":"fig, ax = plt.subplots(1, 2, figsize=(16,4))\nsns.countplot(data=products, x='funct_main', palette ='rocket', ax=ax[0])\nax[0].set_title('Main Categories in Primary Functions')\n\nsns.countplot(data=products[products['funct_main'] == 'LC'], x='funct_sub', palette ='rocket', ax=ax[1])\nax[1].set_title('Sub-Categories in Primary Function LC')\nax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=90)\nplt.show()","8bc4f657":"engagement_imputed['weekday'] = engagement_imputed['time'].dt.dayofweek\nengagement_only_weekday = engagement_imputed[engagement_imputed.weekday < 5]","ce852072":"#get all products of \" Virtual Classroom\" category\nvrclass_lp_id = products[products.funct_sub == 'Virtual Classroom']['LP ID'].unique()\nvrclass_lp_id\n\n#function to annotate the interval of x-axis. Refer https:\/\/stackoverflow.com\/questions\/38677467\/how-to-annotate-a-range-of-the-x-axis-in-matplotlib\ndef annotation_line( ax, xmin, xmax, y, text, ytext=150, linecolor='black', linewidth=1, fontsize=12 ):\n\n    ax.annotate('', xy=(xmin, y), xytext=(xmax, y), xycoords='data', textcoords='data',\n            arrowprops={'arrowstyle': '|-|', 'color':linecolor, 'linewidth':linewidth})\n    ax.annotate('', xy=(xmin, y), xytext=(xmax, y), xycoords='data', textcoords='data',\n            arrowprops={'arrowstyle': '<->', 'color':linecolor, 'linewidth':linewidth})\n\n    xcenter = xmin + (xmax-xmin)\/2\n    if ytext==0:\n        ytext = y + ( ax.get_ylim()[1] - ax.get_ylim()[0] ) \/ 20\n    ax.annotate( text, xy=(xcenter,ytext), ha='center', va='center', fontsize=fontsize)\n    ","e67cd6eb":"# pct_access by products\nf, ax = plt.subplots(nrows=1, ncols=1, figsize=(24, 6))\nfor i in vrclass_lp_id:\n  temp = engagement_only_weekday[engagement_only_weekday.lp_id==i].groupby('time').pct_access.mean().to_frame().reset_index(drop = False)\n  sns.lineplot(data=temp, x = temp.time, y= temp.pct_access, label = products[products['LP ID']==i]['Product Name'].values[0], palette='rocket')\nax.annotate('WHO declared the pandemic',\n            xy =( np.datetime64('2020-03-11'), 0),\n            xycoords='data',\n            xytext=(0, 150),\n            size = 13,\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle='->', color='black'),\n            ha='center',\n            va='center')\n\nannotation_line( ax=ax, text='Summer break', xmin=np.datetime64('2020-06-25'), xmax=np.datetime64('2020-08-10'),\n                    y=3, ytext=5, linewidth=2, linecolor='black', fontsize=14 )\n\nax.set_title('Percentage students have at least one page-load event on a given day with the Virtual Class products')\nplt.legend()\nplt.show()","95c00318":"f, ax = plt.subplots(nrows=1, ncols=1, figsize=(24, 6))\nfor i in vrclass_lp_id:\n  temp = engagement_only_weekday[engagement_only_weekday.lp_id==i].groupby('time').engagement_index.mean().to_frame().reset_index(drop = False)\n  sns.lineplot(data=temp, x = temp.time, y= temp.engagement_index, label = products[products['LP ID']==i]['Product Name'].values[0], palette='rocket')\nax.annotate('WHO declared the pandemic',\n            xy =( np.datetime64('2020-03-11'), 0),\n            xycoords='data',\n            xytext=(0, 150),\n            size = 13,\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle='->', color='black'),\n            ha='center',\n            va='center')\n\nannotation_line( ax=ax, text='Summer break', xmin=np.datetime64('2020-06-25'), xmax=np.datetime64('2020-08-10'),\n                    y=1000, ytext=1500, linewidth=2, linecolor='black', fontsize=14 )\n\nax.set_title('Total page-load events per 1000 students on a given day with the Virtual Class products')\nplt.legend()\nplt.show()","7e018f9e":"products['lp_id'] =products['LP ID'].copy()\nfig, ax = plt.subplots(3,3, figsize = (18, 8))\nsub = products[products.funct_main == 'LC'].funct_sub.unique()\ni = 0\nj = 0\nfor k in sub:\n  lp_ids = products[products.funct_sub == k]['LP ID'].unique()\n  temp = engagement_only_weekday[engagement_only_weekday['lp_id'].isin(lp_ids)]\n  temp = temp.groupby('lp_id').pct_access.mean().sort_values(ascending = False).to_frame().reset_index(drop = False)\n  temp = temp.merge(products[['lp_id', 'Product Name']], on='lp_id').head()\n  sns.barplot(data = temp, x='pct_access', y='Product Name', palette='rocket', ax=ax[i,j])\n  ax[i, j].set_title(f'Top 5 in \\n{k}', fontsize=12)\n  ax[i, j].set_xlim([0, 20])\n  j = j + 1\n  if j == 3:\n    i = i + 1\n    j = 0\nfig.delaxes(ax[2, 1])\nfig.delaxes(ax[2, 2])\nplt.tight_layout()\nplt.show()","5b5636c2":"# Data Cleaning and Preprocessing","86a34c98":"# Exploratory Data Analysis","78912074":"**1. District**","5357f935":"With the plot above, we can notice that:\n\n* Zoom and Meet are the two most prevalent software for online classes.\n* Homeschooling starts at the beginning after WHO declared the pandemic.\n* Summer break is during July and August, thus there are almost no activities.\n* The noticeable increase in use of Zoom and Meet products after summer break due to the new wave of pandemic.\n* There are a few drop points throughout the year. These might be the national holidays.\n* During the winter term, it was just 15 % of students in the districts have at least one page-load event of Zoom or Meet. It means not all students had to attend classes virtually. They could have been able to have classes on campus. Compare to [State-by-State Map of Where School Buildings Are Opened or Close](http\/\/https:\/\/www.edweek.org\/leadership\/map-where-are-schools-closed\/2020\/07), it seems to hold true because a lot of schools * offered in-person lectures.","8fcdad19":"**3. Engagment of students**","a4e567ae":"As observed, pct_access Zoom and Meet seem to have roughly similiar values but Meet has more than 4 times the value of Zoom for engagement_index in the last quarter of 2020. It means If we have 1000 page-load events per 1000 students for Zoom on a given day that means that one student uses Zoom once a day. In contrast, Meet is used 4 or 5 times daily on average per student.","0e1b046e":"\nAs you can see in above plot, the available data does not cover all the states in the U.S. (19\/50). The states with the most available school districts are UT (29) and CT (26) while there are also states with only one school district (FL, TN, NY, AZ) ( Github does not support interactive plot so i have to supply a picture)","3453787f":"* Deal with missing values\n* Convert data type \n* Remove punctuations\n* Split the sub-categories","988744d1":"**2. Product**","9d9453f3":"As we notice that:\n\n* the largest count of students identified as Black or Hispanic are in cities.\n* 50% of the students in cities and towns are eligible for free or reduced-price lunch.\n* The highest total expenses per student is in rural area.","bd40dd97":"Firstly, I remove weekends because there are no classes on weekends. It avoids the disturbing visuals.","23cb4dd9":"From a glimpse, we can see the county_connections_ration has 3 values: NaN, [0.18, 1] and [1, 2]. However, [1,2] is only for one data point, so it is not valuable. Thus, we take only [0.18, 1]","4c7b87aa":"Looking at the count plot, we can see more than 50% school districts located in suburb.\n\n\nSince values of pct_black\/hispanic and pct_free\/reduced, pp_total_raw are presented as intervals, so we have to replace them by mean of those intervals. As mentioned above, the county_connections_ratio is the same for every data point, so we drop this column","8a72ead4":"Anatomize the most common category: LC = Learning & Curriculum, we see 5 sub-categories and top 5 most accessed products of each. We notice that most of products are on average by less than 5% students on daily basis except Google Docs, Youtube, Canvas. It's hard to say exactly about the trend of using Youtube because it serves for both studying and entertaining. In contrast, Google Docs and Canvas make a lot of sense, since these are to use for education. The average pct_access of Career Planning and Job Search is very low, it might be due to the fact that it is only relevant to the senior students."}}