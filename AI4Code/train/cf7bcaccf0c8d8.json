{"cell_type":{"ec35647f":"code","f4969b7c":"code","02d1a38a":"code","db54ffd7":"code","b18a36b1":"code","811b1dfb":"code","b54c1ac8":"code","d9a16e66":"code","ae404a9f":"code","751321a3":"code","e263ca2a":"code","ffc35629":"code","76a8845f":"code","51b97d5b":"code","968b060f":"code","1802ac7a":"code","a56ad453":"code","4a037571":"code","e8de7291":"code","4ad05cdc":"code","dfc7c74f":"code","1d9d97ef":"code","e63a59b9":"code","71472717":"markdown","aea27a32":"markdown"},"source":{"ec35647f":"!pip install scikit-learn-intelex --progress-bar off >> \/tmp\/pip_sklearnex.log\n\nfrom sklearnex import patch_sklearn\npatch_sklearn()","f4969b7c":"import pandas as pd","02d1a38a":"train_X = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest_X = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')","db54ffd7":"# train_X.head()\nprint(set(train_X['target']))","b18a36b1":"test_X.head()","811b1dfb":"print(train_X.shape,test_X.shape)","b54c1ac8":"target = train_X['target']\ntrain_X.drop(['target'],axis='columns',inplace=True)\ntrain_X.drop(['id'],axis='columns',inplace=True)","d9a16e66":"test_id = test_X['id']\ntest_X.drop(['id'],axis='columns',inplace=True)","ae404a9f":"print(train_X.shape,test_X.shape,target.shape)","751321a3":"# check for NAN\ntrain_X.isnull().sum()","e263ca2a":"# check for total sum == 0\ntrain_X.sum() == 0","ffc35629":"from sklearn.model_selection import train_test_split\n\nx_train,y_train,x_test,y_test = train_test_split(train_X,target,test_size=0.5,random_state=42)","76a8845f":"print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)","51b97d5b":"%%time\nfrom sklearn import svm\n\nsvm_clf = svm.SVC(kernel='rbf',C=1,gamma=1.0,probability=True).fit(x_train,x_test)","968b060f":"y_pred = svm_clf.predict(y_train)","1802ac7a":"from sklearn import metrics\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","a56ad453":"final = pd.DataFrame(svm_clf.predict_proba(test_X),columns=svm_clf.classes_)","4a037571":"print(final.shape)","e8de7291":"# x=10\n\n# for i in final:\n#     if x == 0:\n#         break\n#     print(i)\n#     x-=1","4ad05cdc":"final.head()","dfc7c74f":"final.insert(0, 'id', test_id)","1d9d97ef":"final.head()","e63a59b9":"final.to_csv('submission.csv', index=0)","71472717":"# Installing scikit-learn-intelex\n\nPackage also avaialble in conda  - please refer to details https:\/\/github.com\/intel\/scikit-learn-intelex","aea27a32":"# \ud83d\ude80 Optimizing Kaggle kernels using Intel(R) Extension for Scikit-learn - 80x speedup\n\nFor classical machine learning algorithms, we often use the most popular Python library, scikit-learn. We use it to fit models and search for optimal parameters, but\u202fscikit-learn\u202fsometimes works for hours, if not days. Speeding up this process is something anyone who uses scikit-learn would be interested in.\n\nI want to show you how to get results faster without changing the code. To do this, we will use another Python library,\u202f[scikit-learn-intelex](https:\/\/github.com\/intel\/scikit-learn-intelex). It accelerates scikit-learn and does not require you changing the code written for scikit-learn.\n\nWhile SVM is pretty slow in stock scikit-learn, with Intel Extension it can be now used for regular iterative work\n\nThis kernel is based on [SVM_Tabular Playground Series - May 2021](https:\/\/www.kaggle.com\/ahsu00\/svm-tabular-playground-series-may-2021)\n\nAs result, kernel execution time was reduced by **80 times ** - from 17505.4 seconds to 217.8 seconds"}}