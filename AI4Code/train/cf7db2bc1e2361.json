{"cell_type":{"26096e54":"code","9f0f24bc":"code","4b9206c5":"code","25f1b636":"code","b2a54ec5":"code","55c4cbbe":"code","7b1c0f56":"code","41b8e785":"code","e81f64ee":"code","90bafdf2":"code","28844e70":"code","0623ab93":"code","bd7eb9ee":"code","b53008d1":"code","cb0bc25e":"code","22fa6993":"code","2077a247":"code","b6ba7a1a":"code","58b7f6fb":"code","43b9f7c7":"code","53c6be9d":"code","a311c1a1":"code","919fa4ae":"code","f97ef829":"code","1d15cf48":"code","5b569073":"code","a986e2a0":"code","5c31295b":"code","3d89b25f":"code","6decaecc":"code","634f0aad":"code","d7ac67bc":"code","23361dfc":"code","5b13fa89":"code","e040d0d8":"markdown","ab891840":"markdown","4f915e5f":"markdown","588027c1":"markdown","d0f63b82":"markdown","0c151abb":"markdown","c51d4f64":"markdown","27f8ea07":"markdown","6626ed3c":"markdown","86c30128":"markdown","55eb7f0d":"markdown","5a104501":"markdown","fed75737":"markdown","59465db5":"markdown"},"source":{"26096e54":"import pandas as pd\nimport numpy as np\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9f0f24bc":"df=pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","4b9206c5":"df","25f1b636":"df.shape","b2a54ec5":"df.isnull().sum()","55c4cbbe":"df['sentiment'].value_counts()","7b1c0f56":"##New column for length of review\ndf['length']=df['review'].str.len()","41b8e785":"#Displaying maximum col width\npd.set_option('display.max_colwidth', None)","e81f64ee":"df.head()","90bafdf2":"#Removing html tags\ndef removehtml(text):\n    soup=BeautifulSoup(text)\n    return soup.get_text()\n\ndf['review']=df['review'].apply(removehtml)","28844e70":"#Converting into lower case\ndf['review']=df['review'].str.lower()","0623ab93":"#Replacing everthing except alpabets and numbers with space\ndf['review']=df['review'].str.replace(r'[^a-zA-Z0-9]',' ')","bd7eb9ee":"from nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nsw=set(stopwords.words('english'))\nsnow=SnowballStemmer('english')","b53008d1":"#Removing stop words and performimg stemming\ndef stemming(text):\n    text=' '.join([snow.stem(word) for word in text.split() if word not in sw])\n    return text\n\ndf['review']=df['review'].apply(stemming)","cb0bc25e":"df.head()","22fa6993":"#Label coding 0 and 1\ndf['sentiment'].replace({'negative':0,'positive':1},inplace=True)","2077a247":"df.head()","b6ba7a1a":"#New column (clean length) after removal of punctuations and stopwords\ndf['clean_length']=df['review'].str.len()","58b7f6fb":"#Message distribution before cleaning\nf,ax=plt.subplots(1,2,figsize=(15,8))\n\nsns.distplot(df[df['sentiment']==1]['length'],bins=20,ax=ax[0],label='Positive review distribution',color='r')\n\nax[0].set_xlabel('Positive review length')\nax[0].legend()\n\nsns.distplot(df[df['sentiment']==0]['length'],bins=20,ax=ax[1],label='Negative review distribution',color='b')\n\nax[1].set_xlabel('Negative review length')\nax[1].legend()\n\nplt.show()","43b9f7c7":"#Message distribution before cleaning\nf,ax=plt.subplots(1,2,figsize=(15,8))\n\nsns.distplot(df[df['sentiment']==1]['clean_length'],bins=20,ax=ax[0],label='Positive review distribution',color='r')\n\nax[0].set_xlabel('Positive review length')\nax[0].legend()\n\nsns.distplot(df[df['sentiment']==0]['clean_length'],bins=20,ax=ax[1],label='Negative review distribution',color='b')\n\nax[1].set_xlabel('Negative review length')\nax[1].legend()\n\nplt.show()","53c6be9d":"from wordcloud import WordCloud","a311c1a1":"#Getting sense of loud words in positive sentiments\npositive=df['review'][df['sentiment']==1]\nspamcloud=WordCloud(width=1200,height=800,background_color='white',max_words=25).generate(' '.join(positive))\n\nplt.figure(figsize=(12,8),facecolor='r')\nplt.imshow(spamcloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","919fa4ae":"#Getting sense of loud words in negative sentiments\nnegative=df['review'][df['sentiment']==0]\nspamcloud=WordCloud(width=1200,height=800,background_color='white',max_words=25).generate(' '.join(negative))\n\nplt.figure(figsize=(12,8),facecolor='r')\nplt.imshow(spamcloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","f97ef829":"from sklearn.feature_extraction.text import TfidfVectorizer","1d15cf48":"review=df['review']\ntfidf=TfidfVectorizer(ngram_range=(1,3))\nreview=tfidf.fit_transform(review)","5b569073":"sentiment=df['sentiment']","a986e2a0":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","5c31295b":"xtrain,xtest,ytrain,ytest=train_test_split(review,sentiment,test_size=0.3,random_state=7)","3d89b25f":"model=RandomForestClassifier()\nmodel.fit(xtrain,ytrain)","6decaecc":"p=model.predict(xtest)","634f0aad":"print('Accuracy score', accuracy_score(p,ytest))\nprint('-----------------------------------------')\nprint('Confusion Matrix')\nprint(confusion_matrix(p,ytest))\nprint('-----------------------------------------')\nprint('Classification Report')\nprint(classification_report(p,ytest))","d7ac67bc":"model=XGBClassifier(verbosity=0)\nmodel.fit(xtrain,ytrain)","23361dfc":"p=model.predict(xtest)","5b13fa89":"print('Accuracy score', accuracy_score(p,ytest))\nprint('-----------------------------------------')\nprint('Confusion Matrix')\nprint(confusion_matrix(p,ytest))\nprint('-----------------------------------------')\nprint('Classification Report')\nprint(classification_report(p,ytest))","e040d0d8":"# Conclusion","ab891840":"Dataset is balanced. There are 25000 reviews for each negative and posiive sentiments.","4f915e5f":"### XGBoost","588027c1":"##### Today we will preprocess this dataset using regular explressions, beautiful soup, visualize the dataset using matplotlib, seaborn and wordcloud then vectorize it using Tfidf Vectorizer and perform sentiment classification using ensemble methods","d0f63b82":"### Random Forest","0c151abb":"# Introduction","c51d4f64":"There are no null values","27f8ea07":"Negative reviews have word like see, plot etc.","6626ed3c":"Dataframe have 50000 rows and 2 columns","86c30128":"# **Please Upvote if you like my work. Thank You and God Bless You!!!****","55eb7f0d":"##### IMDB dataset having 50K movie reviews for natural language processing or Text analytics.This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms.For more dataset information, please go through the following link,\nhttp:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/","5a104501":"![](https:\/\/i.ytimg.com\/vi\/38RemgSBG0w\/maxresdefault.jpg)","fed75737":"Xgboost Seems to be slightly better than random Forest. We could have also used TextBlob to correct spellings from text only if we had more powerful machine. ","59465db5":"Positive reviews have words like well, life, love, play etc"}}