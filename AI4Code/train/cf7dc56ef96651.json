{"cell_type":{"8b574bfd":"code","bddfa676":"code","d493dd0c":"code","48a7acee":"code","a73d02ea":"code","6fd7755d":"code","13549e26":"code","cdbdc67d":"code","9ec0a512":"code","459ecbe9":"code","4fdf6367":"code","98eb98c6":"markdown","cea3f30a":"markdown","0c6623e3":"markdown","d0adf49a":"markdown","23e100ee":"markdown","1878d2ec":"markdown","98050b83":"markdown","df3ed71d":"markdown","b1e42e6c":"markdown"},"source":{"8b574bfd":"import pandas as pd\nimport numpy as np\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, InputLayer, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import StratifiedKFold","bddfa676":"def showLossHistory(history):\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(loss) + 1)\n    plt.figure(figsize=(20,10))\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    \ndef showAccuracysHistory(history):\n    plt.clf()\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    epochs = range(1, len(accuracy) + 1)\n    plt.figure(figsize=(20,10))\n    plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n    plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()","d493dd0c":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest= pd.read_csv('..\/input\/titanic\/test.csv')","48a7acee":"#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)\n\n# 4.qcut \ntrain[\"Fare_qcut\"] = pd.qcut(train[\"Fare\"],10,labels=np.arange(10, 0, -1))\ntest[\"Fare_qcut\"] = pd.qcut(test[\"Fare\"],10,labels=np.arange(10, 0, -1))","a73d02ea":"train[\"Fare_qcut\"]","6fd7755d":"y = train['Survived']\nX = train.drop('Survived', axis=1)\nX_test = test\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)","13549e26":"MONITOR_OBJECT = 'val_loss'\nMODE = \"min\"\nES_PATIENCE = 400\nES_MIN_DELTA = 0\nES_VERBOSE = 0\nRR_PATIENCE = 100\nRR_FACTOR = 0.2\n\nEPOCHS = 1000\nBATCH_SIZE = 128\n\n# early stopping\nearly_stopping = EarlyStopping(\n    monitor=MONITOR_OBJECT, \n    min_delta=ES_MIN_DELTA, \n    patience=ES_PATIENCE, \n    verbose=ES_VERBOSE,\n    mode=MODE, \n    baseline=None, \n    restore_best_weights=True\n)\n\n#Learning Rate tuning\nreduce_lr = ReduceLROnPlateau(\n    monitor=MONITOR_OBJECT, \n    factor=RR_FACTOR,\n    patience=RR_PATIENCE,\n    mode=MODE\n)\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape)))\nmodel.add(layers.Dropout(0.01))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.01))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dropout(0.01))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dropout(0.01))\nmodel.add(layers.Dense(8, activation='relu'))\nmodel.add(layers.Dropout(0.01))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, \n                    y_train,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    validation_data=(X_val, y_val),\n                    callbacks=[\n                    early_stopping,\n                    reduce_lr\n                ])","cdbdc67d":"showLossHistory(history)","9ec0a512":"showAccuracysHistory(history)","459ecbe9":"y_test = (model.predict(X_test) > 0.5).astype(int)\ny_test[:10]","4fdf6367":"sub = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsub.Survived = y_test\nsub.to_csv('submission.csv', index=False)","98eb98c6":"# 6.submit","cea3f30a":"# 2.preprocess","0c6623e3":"# 4.build","d0adf49a":"# 0.1.import ","23e100ee":"# 5.predict","1878d2ec":"# 1.load","98050b83":"# 0.2.commons","df3ed71d":"# 3.split","b1e42e6c":"# evaluate"}}