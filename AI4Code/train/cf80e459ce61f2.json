{"cell_type":{"7cdde089":"code","346b5a0d":"code","a323f5e0":"code","e822d2dc":"code","43f34936":"code","b2f35039":"code","9121c70c":"code","eada7c81":"code","ec38b657":"code","63f42349":"code","aba3d84d":"code","593f9f9c":"code","219e53cb":"code","c9a975e3":"code","f955c5d3":"code","55e41d2f":"code","19e66332":"code","1811872b":"code","515c5dea":"code","23e86158":"code","1373a863":"code","07a4cd17":"markdown","8488eef7":"markdown","5c280abd":"markdown","c8f8e1fe":"markdown","d5100d4a":"markdown","b432ed82":"markdown","52c01d4e":"markdown","21e13b0a":"markdown","8fa2cae0":"markdown"},"source":{"7cdde089":"# import library\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport numpy as np","346b5a0d":"# check out the version of tensorflow\n\ntf.__version__","a323f5e0":"# make images have same dimensions\nimage_size = (150,150)\nbatch_size = 64\n\n# training dataset - 80%\ntrain_ds = keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/intel-image-classification\/seg_train\/seg_train\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=42,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n\n# validition dataset - 20%\nval_ds = keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/intel-image-classification\/seg_train\/seg_train\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=42,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n\n# test dataset\ntest_ds = keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/intel-image-classification\/seg_test\/seg_test\",\n    seed=42,\n    image_size=image_size,\n    batch_size=batch_size,\n)","e822d2dc":"# Get the list of class names\n# The encoded number is the index of the class_names list\nclass_name = train_ds.class_names\n\nfig,ax = plt.subplots(5,5,figsize=(10,10))\nax = ax.flat\n\n# Get the first batch of dataset, it has batch_size(64) images and corresponding labels\n# Let's show the first 25 images\nfor images,labels in train_ds.take(1):\n    for i in range(25):\n        ax[i].imshow(images[i].numpy().astype('uint8'))\n        ax[i].set_xticks([])\n        ax[i].set_yticks([])\n        ax[i].set_xlabel(class_name[labels[i]])\nplt.show()","43f34936":"data_augmentation = keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip('horizontal'),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n    layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2)\n],name=\"data_augmentation\")","b2f35039":"for image, _ in train_ds.take(1):\n  plt.figure(figsize=(10, 10))\n  first_image = image[0]\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] \/ 255)\n    plt.axis('off')","9121c70c":"# Get Xception and freeze all layers of Xception\nbase_model = keras.applications.Xception(include_top=False,input_shape=image_size+(3,))\nbase_model.trainable = False\n\ninputs = layers.Input(shape=(150,150,3))\nx = data_augmentation(inputs)\nx = layers.experimental.preprocessing.Rescaling(1.\/255)(x)  # normalized\nx = base_model(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.3)(x)\noutputs = layers.Dense(6)(x)\n\nmodel = keras.Model(inputs, outputs)\n\n\n# Compile the model before training it. Since there are two classes, \n# use a categorical cross-entropy loss with `from_logits=True` since the model provides a linear output.\nbase_learning_rate = 0.0001\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=base_learning_rate),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","eada7c81":"# View the network structure and parameters\nmodel.summary()","ec38b657":"# Test the data before training to see the accuracy\nmodel.evaluate(test_ds)\n\n# The accuracy is a little low, it doesn't matter, let's train the output layer","63f42349":"# Using EarlyStopping, when the val_accuracy has not improved after 10 epochs, stop training.\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                        mode='max',restore_best_weights=True,patience=10)\n\nhistory = model.fit(train_ds,\n                    epochs=50,\n                    validation_data=val_ds,\n                    callbacks=[early_stopping])","aba3d84d":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","593f9f9c":"# Now let's test it again\nmodel.evaluate(test_ds)\n\n# It's good now. But we can make it better.","219e53cb":"print(\"Number of Xception layers:\", len(base_model.layers))","c9a975e3":"# Un-freeze the top layers of the model\n\nbase_model.trainable = True\n\nfor layer in base_model.layers[:80]:\n  layer.trainable =  False\n\n# Using lower learning rate\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=base_learning_rate\/10),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","f955c5d3":"# View the network structure and parameters again\n# The trainable parameters change\nmodel.summary()","55e41d2f":"# Started to fine tune\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                        mode='max',restore_best_weights=True,patience=10)\n\nhistory = model.fit(train_ds,\n                    epochs=50,\n                    validation_data=val_ds,\n                    callbacks=[early_stopping])","19e66332":"# Let's test it\nmodel.evaluate(test_ds)\n\n# Now,it's good,we try to unfreeze all layers to make accuracy better, but that maybe worse.","1811872b":"# unfreeze the whole model\n\nfor layer in base_model.layers[:80]:\n  layer.trainable =  True\n\n# Using lower learning rate\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=base_learning_rate\/50),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","515c5dea":"# View the network structure and parameters. Trainable parameters are already numerous\nmodel.summary()","23e86158":"# Started to fine tune again\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                        mode='max',restore_best_weights=True,patience=10)\nhistory = model.fit(train_ds,\n                    epochs=50,\n                    validation_data=val_ds,\n                    callbacks=[early_stopping])","1373a863":"# test it\nmodel.evaluate(test_ds)\n\n# It has some improvement","07a4cd17":"* Let's take a look at the learning curves of the training and validation accuracy\/loss","8488eef7":"## Fine tuning\n* As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly.","5c280abd":"* Use data augmentation  \n For better results, add an image enhancement layer after the input layer.","c8f8e1fe":"* We used Xception pre-trained on ImageNet for transfer learning, but there were 1000 output categories in ImageNet, so we need to remove the Xception top-level output layer and add a Dense layer of 6 units as output.  \n* So far we haven't normalized the image, don't worry, just add a `Rescaling` layer.\n* It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. ","d5100d4a":"## Load data from directory\n* Use `tf.keras` to load images more easily. Divide the seg_train into two parts by 8:2,  80% as training dataset and 20% as validition dataset. Finally, load the test images. When loading training dataset and validation dataset, you need to specify a seed of random numbers or `shuffle=False` to prevent data duplication. Why specify a seed of 42,  you might ask 'Deep Thought'.  \n* This dataset has different image sizes,but we need the same dimensions. We just need to specify `image_size` to do that. Isn't that easy?","b432ed82":"* Let's repeatedly apply these layers to the same image and see the result.","52c01d4e":"## Create model\n","21e13b0a":"* It's usually not a good idea to un-freeze the entire model, but let's give it a try","8fa2cae0":"* Now that the images are loaded, let's show a few of them"}}