{"cell_type":{"6449a5a4":"code","648b8970":"code","b56b57fe":"code","973bec13":"code","7c76f6f3":"code","67ce2460":"code","1d182157":"code","26aa05c9":"code","13fec420":"code","96382865":"code","75a3c70d":"code","3731a81f":"code","d4897b81":"code","4fab9891":"code","f836e622":"code","c7536bfe":"code","03a3c221":"code","ba627890":"markdown","d1b72235":"markdown","b87508fe":"markdown","caaed8ab":"markdown","da8da0da":"markdown","0b4ab8db":"markdown","55da75ae":"markdown","414e8ead":"markdown","120e6037":"markdown","88c809cf":"markdown","60e1f18a":"markdown"},"source":{"6449a5a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","648b8970":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\nnum_classes = 10\n","b56b57fe":"train_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv',sep=',')\ntest_df= pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv', sep = ',')\nprint(\"Train size:{}\\nTest size:{}\".format(train_df.shape, test_df.shape))","973bec13":"train_df.head()","7c76f6f3":"train_data = np.array(train_df, dtype = 'float32')\ntest_data = np.array(test_df, dtype='float32')\n","67ce2460":"x_train = train_data[:,1:]\/255\n\ny_train = train_data[:,0]\n\nx_test= test_data[:,1:]\/255\n\ny_test=test_data[:,0]","1d182157":"x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 12345)","26aa05c9":"image = x_train[22,:].reshape((28,28))\nplt.imshow(image)\nplt.show()\n","13fec420":"image_rows = 28\n\nimage_cols = 28\n\nbatch_size = 512\n\nimage_shape = (image_rows,image_cols,1) # Defined the shape of the image as 3d with rows and columns and 1 for the 3d visualisation","96382865":"x_train = x_train.reshape(x_train.shape[0],*image_shape)\nx_test = x_test.reshape(x_test.shape[0],*image_shape)\nx_validate = x_validate.reshape(x_validate.shape[0],*image_shape)","75a3c70d":"cnn_model = Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Dropout(0.5),\n    Flatten(), # flatten out the layers\n    Dense(32,activation='relu'),\n    Dense(10,activation = 'softmax')\n    \n])","3731a81f":"cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])","d4897b81":"history = cnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=17,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","4fab9891":"score = cnn_model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(score[1]))","f836e622":"plt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Complexity Graph:  Training vs. Validation Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\n\nplt.figure(2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\nplt.show()","c7536bfe":"\npredicted_classes = cnn_model.predict_classes(x_test)\n\n#get the indices to be plotted\n\ny_true = test_df.iloc[:, 0]\n\ncorrect = np.nonzero(predicted_classes==y_true)[0]\n\nincorrect = np.nonzero(predicted_classes!=y_true)[0]\n\nfrom sklearn.metrics import classification_report\n\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\n\nprint(classification_report(y_true, predicted_classes, target_names=target_names))","03a3c221":"classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nnum_rows = 5\nnum_cols = 10\nsample_size = num_rows * num_cols\nindices = np.arange(sample_size)\nx_pred = x_test[indices,:,:]\npredictions = cnn_model.predict(x_pred)\nx_pred = np.squeeze(x_test[indices,:,:])\ny_pred = np.argmax(predictions,axis=1)\n\nnum_images = num_rows*num_cols\nplt.figure(figsize=(num_cols*2, num_rows*2))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.6)\nfor i in range(num_images):\n  plt.subplot(num_rows, num_cols, i+1)\n  plt.imshow(x_pred[i])\n  plt.title(classes[y_pred[i]])\n  # plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  # plot_value_array(i, predictions, test_labels)\nplt.show()","ba627890":"Create the Convolutional Neural Networks (CNN)\n#### Define the model\n\n#### Compile the model\n\n#### Fit the model\n\nFirst of all let us define the shape of the image before we define the model","d1b72235":"Now it is observed that the first column is the label data and because it has 10 classes so it is going to have from 0 to 9.The remaining columns are the actual pixel data.Here as you can see there are about 784 columns that contain pixel data. Here each row is a different image representation in the form pixel data.\n\nNow let us split the train data into x and y arrays where x represents the image data and y represents the labels.\n\nTo do that we need to convert the dataframes into numpy arrays of float32 type which is the acceptable form for tensorflow and keras.","b87508fe":"# Here is a subset of correctly predicted classes","caaed8ab":"# classification_report","da8da0da":"compile model","0b4ab8db":"Let us explore the train and test data","55da75ae":"Create dataframes for train and test datasets","414e8ead":"# Results\nLet's plot training and validation accuracy as well as loss.\n\n","120e6037":"Each training and test example is assigned to one of the following labels:\n\n0 T-shirt\/top\n1 Trouser\n2 Pullover\n3 Dress\n4 Coat\n5 Sandal\n6 Shirt\n7 Sneaker\n8 Bag\n9 Ankle boot\nTL;DR\nEach row is a separate image\nColumn 1 is the class label.\nRemaining columns are pixel numbers (784 total).\nEach value is the darkness of the pixel (1 to 255)\nAcknowledgements\nOriginal dataset was downloaded from https:\/\/github.com\/zalandoresearch\/fashion-mnist\n\nDataset was converted to CSV with this script: https:\/\/pjreddie.com\/projects\/mnist-in-csv\/************","88c809cf":"># define model","60e1f18a":"# labels"}}