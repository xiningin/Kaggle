{"cell_type":{"5cc46f6d":"code","3be21f8e":"code","e85245a2":"code","c10c4c92":"code","fdd807f1":"code","0e496976":"code","42288bd5":"code","5bcc2d79":"code","9a59061d":"code","b5750a28":"code","947944f8":"code","764120ec":"code","7eb02348":"code","d2c3e884":"code","b7044895":"code","1daabf68":"code","e5937627":"code","2169ec86":"code","53a42012":"code","adf93d45":"code","e549f755":"code","f4bbeb87":"code","3f80c637":"code","fda082b8":"code","9f269c4f":"code","4756a103":"code","d29d51e7":"code","ef6bc995":"code","44b31857":"code","db799351":"code","e54c77d6":"code","a75aabca":"code","ff4cd08f":"code","ce02c000":"code","fbb8bbe0":"code","909fdfac":"code","7f274387":"code","2f542eec":"code","8bb6db4a":"code","fe540c1a":"code","238b0546":"code","3995a04a":"code","75d6e7ce":"code","9e3087a3":"code","f3d80adc":"code","e7d82bb3":"code","6c8c8229":"code","821f9b29":"code","e329b022":"code","c40c08f7":"code","6a789dfd":"markdown","1e6ab588":"markdown","e5a86bcc":"markdown","98fc63ae":"markdown","230c8cdc":"markdown","f2db0633":"markdown","8f80a4cd":"markdown","5808526e":"markdown","2ead485f":"markdown","107a8617":"markdown","2ed55075":"markdown","f526bc4e":"markdown","0844eab4":"markdown","0551646d":"markdown","413b7c37":"markdown","e55004d3":"markdown","1827c92c":"markdown","091d7791":"markdown","cc2b3306":"markdown","60cd1ee9":"markdown","4910ef2b":"markdown","92f02879":"markdown","a7154772":"markdown","8f44a0d1":"markdown","cacd0417":"markdown","6f394b7e":"markdown","ae2ee7e4":"markdown","876a0652":"markdown","bc21fa54":"markdown","61799a92":"markdown","0bb6367a":"markdown","b5707e92":"markdown","de80fe61":"markdown","aa21b1dd":"markdown","c3577897":"markdown","666dd017":"markdown","65572e3c":"markdown","dbfba147":"markdown","54a01125":"markdown","13cf4e0e":"markdown","b2a68ea1":"markdown","8b9da51c":"markdown","ddecdad3":"markdown","a7fce82e":"markdown","d8d36494":"markdown"},"source":{"5cc46f6d":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\n# for visualization\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# import holoviews as hv\n\n# Testing\nimport scipy\nimport scipy.stats as st\n\n# Modeling\nimport xgboost\nfrom xgboost import XGBClassifier\n\nimport sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n\nfrom sklearn import model_selection\n# Splitting Dataset\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\n# Scoring\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score\nfrom sklearn.model_selection import KFold\n\n# Class Imbalance\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n# from imblearn import over_sampling\n\n%matplotlib inline","3be21f8e":"print('Numpy Version : ' + np.__version__)\nprint('Pandas Version : ' + pd.__version__)\nprint('Matplotlib Version : ' + matplotlib.__version__)\nprint('Seaborn Version : ' + sns.__version__)\nprint('Scipy Version : ' + scipy.__version__)\nprint('Sklearn Version : ' + sklearn.__version__)\nprint('XGBoost Version : ' + xgboost.__version__)","e85245a2":"train = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntrain.head()","c10c4c92":"train[['id','Region_Code']].groupby('Region_Code', as_index=False).count().sort_values('id', ascending=False).head(10).Region_Code.to_list()","fdd807f1":"train[train.Region_Code.isin(train[['id','Region_Code']].groupby('Region_Code', as_index=False).count().sort_values('id').head(10).Region_Code.to_list())]","0e496976":"# test = pd.read_csv(groupbyive\/test.csv')\n# test.head()","42288bd5":"train.shape","5bcc2d79":"train.info()","9a59061d":"train.describe()","b5750a28":"numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndisplay(train.select_dtypes(include=numerics).columns)\nprint(train.select_dtypes(include=numerics).shape)\ndata_num = train.select_dtypes(include=numerics)","947944f8":"#Invalid Value\ndisplay(train.select_dtypes(include=['object']).columns)\nprint(train.select_dtypes(include=object).shape)\ndata_cat = train.select_dtypes(include=['object'])","764120ec":"train[['id', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured',\n       'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response']].describe()","7eb02348":"train['Gender'].value_counts()","d2c3e884":"train['Vehicle_Age'].value_counts()","b7044895":"train['Vehicle_Damage'].value_counts()","1daabf68":"train[['Gender', 'Vehicle_Age', 'Vehicle_Damage']].describe()","e5937627":"trainGroup = train.loc[:, train.columns.intersection(['id', 'Response'])]\ntrainGroup['Age-Group'] = train['Age'].apply(lambda x : '> 50' if x > 50 else ('36 - 50' if (x > 35) and (x < 51) else '20-35'))\ntrainGroup['Vintage-Group'] = train['Vintage'].apply(lambda x : '0-100' if x < 100 else ('100 - 200' if (x > 100) and (x < 200) else '200 - 300'))\ntrainGroup['Annual_Premium-Group'] = train['Annual_Premium'].apply(lambda x : '> 450K' if x > 450000 else ('150K - 450K' if (x > 150000) and (x < 450001) else '0 - 150K'))\n\ntrainGroup","2169ec86":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\n\n# Count Length Data Vehicle Damage\ndv_len = len(train['Driving_License'])\n\ng = sns.countplot(train['Driving_License'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Driving_License'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Driving License',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\n\nplt.savefig('.\/driving-license.jpg')\nplt.show();","53a42012":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\npi_len = len(train['Previously_Insured'])\n\ng = sns.countplot(train['Previously_Insured'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Previously_Insured'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Previously Insured',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\nplt.savefig('.\/previously-insured.jpg')\nplt.show();","adf93d45":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\nag_len = len(trainGroup['Age-Group'])\n\ng = sns.countplot(trainGroup['Age-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nh = sns.countplot(trainGroup['Age-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nax[1].legend(loc=\"upper left\", title=\"Response\",)\n\n    \nk = sns.distplot(train['Age'], ax=ax[2])\nl = sns.boxplot(train['Age'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Age',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/age.jpg')\nplt.show();","e549f755":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\nvg_len = len(trainGroup['Vintage-Group'])\n\ng = sns.countplot(trainGroup['Vintage-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(trainGroup['Vintage-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \ng = sns.distplot(train['Vintage'], ax=ax[2])\ng = sns.boxplot(train['Vintage'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Vintage',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\t\nfig.tight_layout()\n\nplt.savefig('.\/vintage.jpg')\nplt.show();","f4bbeb87":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\napg_len = len(trainGroup['Annual_Premium-Group'])\n\ng = sns.countplot(trainGroup['Annual_Premium-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(trainGroup['Annual_Premium-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \ng = sns.distplot(train['Annual_Premium'], ax=ax[2])\ng = sns.boxplot(train['Annual_Premium'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Annual Premium',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\t\nfig.tight_layout()\n\nplt.savefig('.\/annual-premium.jpg')\nplt.show();","3f80c637":"fig,ax = plt.subplots(2,figsize=(26,15),\n                     sharey=True)\n\ndata_region_code = train[train.Region_Code.isin(train[['id','Region_Code']].groupby('Region_Code', as_index=False).count().sort_values('id', ascending=False).head(10).Region_Code.to_list())]\n\ng = sns.countplot(data_region_code['Region_Code'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\nax[0].set_title('Distribution Region Code',fontsize=24,color='dodgerblue',fontweight='bold')\n\nh = sns.countplot(data_region_code['Region_Code'],hue= data_region_code['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\nax[1].set_title('Response to Region Code',fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout();","fda082b8":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\ng_len = len(train['Gender'])\n\ng = sns.countplot(train['Gender'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Gender'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nplt.suptitle('Response to Gender',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/gender.jpg')\nplt.show();","9f269c4f":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\nva_len = len(train['Vehicle_Age'])\n\ng = sns.countplot(train['Vehicle_Age'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Vehicle_Age'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\n\nplt.suptitle('Response to Vehicle Age',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/vehicle-age.jpg')\nplt.show();","4756a103":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\n# Count Length Data Vehicle Damage\nvd_len = len(train['Vehicle_Damage'])\n\ng = sns.countplot(train['Vehicle_Damage'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\n\n\nh = sns.countplot(train['Vehicle_Damage'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Vehicle Damage',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\nplt.savefig('.\/vehicle-damage.jpg')\nplt.show();","d29d51e7":"corr_= train.corr().round(3)\nmask = np.zeros_like(corr_)\n    \nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(21, 10))\n    ax = sns.heatmap(corr_, annot=True, cmap = \"BuPu\")\n\nplt.tight_layout;\n# plt.savefig('fig\/matrix correlation.png');","ef6bc995":"# Finding Missing Value\ndata_missing_value = train.isnull().sum().reset_index()\ndata_missing_value.columns = ['feature','missing_value']\ndata_missing_value = data_missing_value[data_missing_value['missing_value'] > 0]\n\ndata_missing_value","44b31857":"train.duplicated().sum()","db799351":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nss = StandardScaler()\n\nss_list = [\n    'Annual_Premium',\n    'Vintage',\n]\n\nfor x in ss_list :\n    train[[x]] = ss.fit_transform(train[[x]])","e54c77d6":"gd = {'Male' : 0, 'Female' : 1}\npi = {0 : 'No', 1 : 'Yes'}\ntrain['Gender'] = train['Gender'].map(gd)\ntrain['Previously_Insured'] = train['Previously_Insured'].map(pi)\ntrain","a75aabca":"# sns.boxplot(np.log(train['Annual_Premium']), orient='v')\n# train['Annual_Premium'].describe()","ff4cd08f":"train_dummies = pd.get_dummies(train[[\n    'Vehicle_Damage',\n    'Previously_Insured',    \n    'Vehicle_Age'\n]])\n# , drop_first=True\ntrain_d = pd.concat([train, train_dummies], axis=1)\ntrain_d.head()","ce02c000":"train_d=train_d.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\n\ntrain_d['Vehicle_Age_lt_1_Year']=train_d['Vehicle_Age_lt_1_Year'].astype('int')\ntrain_d['Vehicle_Age_gt_2_Years']=train_d['Vehicle_Age_gt_2_Years'].astype('int')\ntrain_d['Vehicle_Damage_Yes']=train_d['Vehicle_Damage_Yes'].astype('int')","fbb8bbe0":"train_d = train_d.drop([\n    'id', \n    'Vehicle_Age',\n    'Vehicle_Damage',\n    'Previously_Insured',\n    \n    'Vehicle_Damage_No',    \n    'Vehicle_Age_1-2 Year'\n    \n], axis=1)\ntrain_d.head()","909fdfac":"train_pp = train_d\n\ny = train_pp['Response'].values\nX = train_pp.drop(labels = ['Response'], axis = 1)\nprint(\"Shape of X is {} and that of y is {}\".format(X.shape, y.shape))\n\n# Splitting the dataset \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n\nprint('Shape of training set ', X_train.shape)\nprint('Shape of test set ', X_test.shape)","7f274387":"classifications = [\n    LogisticRegression(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\n]\n\nresult_model = pd.DataFrame(columns = ['Method', 'roc_auc_score'])\nresult_model","2f542eec":"for model in classifications:\n    model.fit(X_train, y_train)\n    y_score = model.predict_proba(X_test)[:,1]\n    \n    method = str(type(model)).split('.')[-1][:-2]\n    \n    #roc_auc_score\n    roc_auc_score_ = roc_auc_score(y_test, y_score)\n    roc_auc_score_ = roc_auc_score_.item()\n    \n    result_model = result_model.append({\n        'Method': method,\n        'roc_auc_score': roc_auc_score_,\n    },ignore_index=True)\n    \nresult_model","8bb6db4a":"rf = XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\nrf.fit(X_train, y_train)\n\nkfold = model_selection.KFold(n_splits=10, random_state=41)\n\n# Get score:\nresults_k = model_selection.cross_val_score(rf, X, y, cv=kfold, scoring='roc_auc')\nresults_k","fe540c1a":"from sklearn.model_selection import StratifiedKFold\n\nroc_auc_list = []\nroc_auc_holdout = []\nroc_auc_train = []\nfolds = []\nmodel = XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\nkfold = KFold(n_splits=10, random_state=41)\nfor i, (train_index, test_index) in enumerate(kfold.split(X_train)):\n    X1_train, X1_valid = X.iloc[train_index], X.iloc[test_index]\n    y1_train, y1_valid = y[train_index], y[test_index]\n    model.fit(X1_train, y1_train)\n    train_pred = model.predict_proba(X1_train)[:,1] # 70%\n    #Measure of the fit of your model.\n    pred = model.predict_proba(X1_valid)[:,1] # 10%\n    # DATA WHICH MODEL HAS NOT SEEN\n    pred_holdout = model.predict_proba(X_test)[:,1] # 20%\n    \n    print('Prediction length on validation set, XGBoost Classifier, fold ', i, ': ', len(pred))\n\n    folds.append(i)\n    roc_auc_list.append(roc_auc_score(y1_valid, pred))\n    roc_auc_holdout.append(roc_auc_score(y_test, pred_holdout))\n    roc_auc_train.append(roc_auc_score(y1_train, train_pred))","238b0546":"roc_auc_train # train","3995a04a":"roc_auc_holdout # test","75d6e7ce":"roc_auc_list # val","9e3087a3":"# import matplotlib as mpl\n# matplotlib.rcParams.update(mpl.rcParamsDefault)","f3d80adc":"rg = np.arange(0.840,0.900,0.005)\n\ntrain_mean = np.mean(roc_auc_train)\ntest_mean = np.mean(roc_auc_holdout)\nval_mean = np.mean(roc_auc_list)\n\ntrain_std = np.std(roc_auc_train)\ntest_std = np.std(roc_auc_holdout)\nval_std = np.std(roc_auc_list)\n\nplt.style.use('tableau-colorblind10')\n\nfig, ax = plt.subplots(figsize=(20,10))\nax.plot(roc_auc_train, label='Train', marker='o', linestyle='-.')\nax.plot(roc_auc_holdout, label='Test', marker='o', linestyle=':')\nax.plot(roc_auc_list, label='Val', marker='o', linestyle='--')\n\ntext_m = '''\n    * Train Mean : ''' + str(format(train_mean, '.5f')) + '''\n    * Test Mean : ''' + str(format(test_mean, '.5f')) + ''' \n    * Val Mean : ''' + str(format(val_mean, '.5f')) + '''     \n'''\n\nax.text(6,0.841,text_m,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n\n\ntext_s = '''\n    * Train Standard Deviation : ''' + str(format(train_std, '.5f')) + '''\n    * Test Standard Deviation : ''' + str(format(test_std, '.5f')) + ''' \n    * Val Standard Deviation : ''' + str(format(val_std, '.5f')) + '''     \n'''\n\nax.text(0.5,0.841,text_s,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n\n\nax.set_xlabel('No of variable at each split', fontsize=18, labelpad=20)\nax.set_ylabel('ROC_AUC Score', fontsize=18, labelpad=10)\n\nax.set_title('XGBoost - Train, Test, Val Error', pad=20, fontsize=30)\n\nax.legend()\nax.set_yticks(rg)\n\nsns.despine()\n\nplt.savefig('.\/xgb-ttv.jpg')\n\nplt.tight_layout()\n\nplt.show();","e7d82bb3":"#\nclf = XGBClassifier()\nclf.fit(X_train, y_train)\n\n#\nclf.feature_importances_\n\n#\nfeature_importances = pd.DataFrame(clf.feature_importances_,\n                                   index = X.columns,\n                                   columns=['importance']).sort_values('importance', ascending=False)\nfeature_importances\n\nfig, ax = plt.subplots(1,1, figsize=(10,15))\nsns.barplot(x='importance', y='index', color='#800000',data=feature_importances.reset_index());\n\nplt.title('Feature Importance', fontsize=30, pad=20)\n\n\nplt.savefig('.\/feature-importance.jpg')\nplt.tight_layout()\nplt.show();","6c8c8229":"# from sklearn.model_selection import XGBClassifier\n\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'max_depth': [10,15],\n#     'max_features': [2, 3],\n#     'min_samples_leaf': [3, 4, 5],\n#     'min_samples_split': [3,4,5],\n#     'n_estimators': [100, 200, 300]\n# }\n# # Create a based model\n# rf = RandomForestClassifier()\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1, verbose = 2)\n\n# # Fit the grid search to the data\n# grid_search.fit(X_train,y_train)","821f9b29":"# grid_search.best_estimator_","e329b022":"# rff = RandomForestClassifier(max_depth=10, max_features=2, min_samples_leaf=5,\n#                        min_samples_split=3)\n# rff.fit(X_train, y_train)\n# y_pred = rff.predict_proba(X_test)\n\n# print('Random Forest Classifier ', roc_auc_score_)","c40c08f7":"# result_model","6a789dfd":"#### 4.3.2.3. Visualize Vehicle Damage","1e6ab588":"#### 4.3.1.2. Visualize Previously Insured","e5a86bcc":"#### 4.3.1.6. Visualize Region Code","98fc63ae":"## 3.2. Numerical Data","230c8cdc":"## 3.1. General Information","f2db0633":"## 6.3. Cross Validation","8f80a4cd":"Target Output : Feature <strong>RESPONSE<\/strong>","5808526e":"# 7. Feature Importance","2ead485f":"# 1. Data Description","107a8617":"### 5.1.2. Duplicate Value","2ed55075":"### 5.1.5. One Hot Encoding","f526bc4e":"## 5.2. Splitting Values","0844eab4":"### 5.1.4. Reformat Label","0551646d":"### 5.1.6. Rename and Casting Feature","413b7c37":"## 4.4. Multivariate Analysis","e55004d3":"## 4.3. Univariate Analysis","1827c92c":"#### 4.3.1.5. Visualize Annual Premium","091d7791":"# 8. Tuning Hyperparameter (One Time Running)","cc2b3306":"## 5.1. Feature Engineering","60cd1ee9":"# 5. Pre-Processing","4910ef2b":"#### 4.3.1.4. Visualize Vintage","92f02879":"## 6.2. Modeling Process","a7154772":"## 6.4. Train, Test, Val Score","8f44a0d1":"#### 4.3.2.1. Visualize Gender","cacd0417":"## 4.2. Grouping Feature","6f394b7e":"#### 4.3.2.2. Visualize Vehicle Age","ae2ee7e4":"# #Reference Link\n* https:\/\/www.kaggle.com\/yashvi\/vehicle-insurance-eda-and-boosting-models\n* https:\/\/www.kaggle.com\/roshankumarg\/rank-10-solution-cross-sell-prediction-hackathon\n* https:\/\/www.kaggle.com\/isaienkov\/insurance-prediction-eda-and-modeling-acc-88\n* https:\/\/towardsdatascience.com\/boost-your-models-performance-with-these-fantastic-libraries-8dc10579b7ff\n* https:\/\/stats.stackexchange.com\/questions\/421582\/how-to-identify-a-case-of-overfitting-using-stratified-k-fold-cross-validation\n* https:\/\/towardsdatascience.com\/how-to-train-test-split-kfold-vs-stratifiedkfold-281767b93869\n* https:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/getting-started-with-feature-engineering\/\n* https:\/\/www.analyticsvidhya.com\/blog\/2016\/03\/complete-guide-parameter-tuning-xgboost-with-codes-python\/\n* https:\/\/wizardforcel.gitbooks.io\/tensorflow-examples-aymericdamien\/content\/","876a0652":"# 2. Data Collection","bc21fa54":"# 6. Modeling","61799a92":"#### 4.3.1.1. Visualize Driving License","0bb6367a":"### 4.1.1. Numerical Data","b5707e92":"## 4.1. Statistika Deskriptif","de80fe61":"#### 4.3.1.3. Visualize Age","aa21b1dd":"### 4.3.1. Numerical Data","c3577897":"## 3.3. Non-Numerical data","666dd017":"# 4. Exploratory Data Analyst","65572e3c":"### 5.1.1. Missing Value","dbfba147":"## 6.1. Define Model","54a01125":"![image.png](attachment:image.png)","13cf4e0e":"### 4.1.2. Non-Numerical Data","b2a68ea1":"## 6.5. Visualize Train, Test, Val Score","8b9da51c":"### 5.1.3. Scaling Use StandarScaler","ddecdad3":"# 3. Data Understanding","a7fce82e":"### 4.3.2. Non-Numerical Data","d8d36494":"### 5.1.7. Drop Feature"}}