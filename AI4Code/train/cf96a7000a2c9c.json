{"cell_type":{"38b1551e":"code","b984d186":"code","a6fa6ba1":"code","6414d316":"code","6e0a07ae":"code","ed7fb0aa":"code","a0c8fc60":"code","549ec0d1":"code","e4baf0f0":"code","02459c7f":"code","6811c202":"code","0fa3a758":"markdown"},"source":{"38b1551e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, auc\nfrom IPython.display import display\nimport gc\n\nimport tensorflow as tf\n\nimport keras\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, Input, LSTM, Bidirectional, BatchNormalization, Flatten\nfrom keras.layers import Dropout, Activation, GlobalMaxPool1D\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Model\nfrom keras import initializers, regularizers\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\nimport keras.backend as K\n\nimport random\nseed = 42\nrandom.seed(42)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom time import time, strftime, gmtime\nstart = time()","b984d186":"train = pd.read_json('..\/input\/train.json')\nprint(train.shape)\ndisplay(train.head())","a6fa6ba1":"test = pd.read_json('..\/input\/test.json')\nprint(test.shape)\ndisplay(test.head())","6414d316":"#target = to_categorical(train['is_turkey'].values)\ntarget = np.asarray(train['is_turkey'].values)\nprint(target.shape)\n\nmaxlen = 10\n\ntrain_pad = pad_sequences(train['audio_embedding'].tolist(), maxlen = 10)\ntest_pad = pad_sequences(test['audio_embedding'].tolist(), maxlen = 10)\n\nXtrain, Xvalid, ytrain, yvalid = train_test_split(train_pad, target, \n                                                  test_size = 0.2)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","6e0a07ae":"def as_keras_metric(method):\n    import functools\n    \n    @functools.wraps(method)\n    def wrapper(self, args, **kwargs):\n        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n        value, update_op = method(self, args, **kwargs)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([update_op]):\n            value = tf.identity(value)\n        return value\n    return wrapper\nauc_roc = as_keras_metric(tf.metrics.auc)","ed7fb0aa":"# https:\/\/www.kaggle.com\/suicaokhoailang\/lstm-attention-baseline-0-652-lb\n\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.layers import concatenate, Reshape, Flatten, Concatenate\n\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a \/= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","a0c8fc60":"inputs = Input(shape = (10, 128 ))\nx = BatchNormalization()(inputs)\n#x = Bidirectional(LSTM(128, activation = 'relu', return_sequences = True, \n #                      dropout = 0.4, recurrent_dropout = 0.4))(x)\nx = Bidirectional(LSTM(64, activation = 'relu', return_sequences = True, \n                       dropout = 0.4, recurrent_dropout = 0.4))(x)\nx = Attention(10)(x)\nx = Dense(32, activation = \"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation = \"sigmoid\")(x)\nmodel = Model(inputs = inputs, outputs = x)\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy', auc_roc])\n\nprint(model.summary())","549ec0d1":"hist = model.fit(Xtrain, ytrain, batch_size = 128, epochs = 20, \n          validation_data = (Xvalid, yvalid), \n          verbose = 2\n         )","e4baf0f0":"vpred = model.predict(Xvalid, verbose = 1)","02459c7f":"#Predict test set\n\ntpred = model.predict(test_pad, batch_size = 256, verbose = 1)\nsubmission = pd.DataFrame({'vid_id':test['vid_id'],'is_turkey':[x[0] for x in tpred]})\nprint(submission.shape)\ndisplay(submission.head())\nsubmission.to_csv('.\/submission.csv', index = False)","6811c202":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","0fa3a758":"__Building Bi-LSTM Model__"}}