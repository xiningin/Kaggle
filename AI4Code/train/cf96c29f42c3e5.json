{"cell_type":{"86476605":"code","dd96ce17":"code","4cfeb11a":"code","9e579b9a":"code","6b75eaa1":"code","b259cb14":"code","717b5bb4":"code","68ff60b1":"code","9090651f":"code","1026e2ab":"code","f2edbb85":"code","60f0c9ad":"code","7140e388":"code","46a7e2a5":"code","28da771a":"code","174614f5":"code","2ba260b4":"code","e1be9ef6":"code","6dc8b9fe":"code","a8ac4de2":"code","1bae2fd4":"code","b1776a18":"code","5b9f3ba4":"code","daeae337":"code","6647fd4f":"code","2c80c70d":"code","67394960":"code","1d16920b":"code","86410b36":"code","8d05be28":"code","eef7e767":"code","a837acc0":"markdown","08a21ec9":"markdown","d9cfca3b":"markdown"},"source":{"86476605":"import itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import patches\nfrom numpy import interp\nimport pandas as pd\nfrom pandas import read_csv, get_dummies, concat\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix, auc, roc_curve, recall_score, precision_score, accuracy_score, classification_report\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nrandom_state = np.random.RandomState(2021)","dd96ce17":"\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    \"\"\"\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2\n\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > (cm.max() - ((cm.max() - cm.min()) \/ 2)) else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","4cfeb11a":"clothes = read_csv(\"..\/input\/clothes\/clothes_new.csv\", header=0)\nx = clothes.drop(\"DEFAULT\", axis=1).copy()\ny = clothes[\"DEFAULT\"].copy()","9e579b9a":"features = []\nfor feature in x.columns:\n    features.append(feature)\n    \n\nscaler = StandardScaler()\nx[features] = scaler.fit_transform(x[features])","6b75eaa1":"x.head()","b259cb14":"param_grid = [\n    {\n        \"kernel\": [\"linear\"],\n        \"C\": [0.01, 0.1, 1, 10, 100]\n    },\n    {\n        \"kernel\": [\"poly\"],\n        \"C\": [0.01, 0.1, 1, 10, 100],\n        \"degree\": [1, 2, 3, 4],\n        \"gamma\": [\"auto\"],\n    },\n    {\n        \"kernel\": [\"rbf\"], \n        \"C\": [0.01, 0.1, 1, 10, 100], \n        \"gamma\": [\"auto\"]\n    },\n    {\n        \"kernel\": [\"sigmoid\"], \n        \"C\": [0.01, 0.1, 1, 10, 100]},\n]\nSVC = svm.SVC()\nfor SW in param_grid:\n\n    optimal_params = GridSearchCV(SVC, param_grid=SW, cv=10, scoring=\"accuracy\")\n\n    optimal_params.fit(x, y)\n    # print(DataFrame(optimal_params.cv_results_))\n    ss = concat(\n        [\n            pd.DataFrame(optimal_params.cv_results_[\"params\"]),\n            pd.DataFrame(\n                optimal_params.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]\n            ),\n            pd.DataFrame(optimal_params.cv_results_[\"rank_test_score\"], columns=[\"rank\"]),\n        ],\n        axis=1,\n    )\n    ss = ss.sort_values(by=\"Accuracy\", ascending=False)\n    print(ss)","717b5bb4":"clf_rbf = svm.SVC(kernel=\"rbf\", gamma=\"auto\", C=1)\nclf_poly = svm.SVC(kernel=\"poly\", degree=1, C=10, gamma=\"auto\")\nclf_linear = svm.SVC(kernel=\"linear\", C=1)\nclf_sigmoid = svm.SVC(kernel=\"sigmoid\", C=0.1)\nscores_rbf = cross_val_score(clf_rbf, x, y, cv=5)\nscores_poly = cross_val_score(clf_poly, x, y, cv=5)\nscores_linear = cross_val_score(clf_linear, x, y, cv=5)\nscores_sigmoid = cross_val_score(clf_sigmoid, x, y, cv=5)\n\nprint(\n    \"%0.2f accuracy linear with a standard deviation of %0.2f\"\n    % (scores_linear.mean(), scores_linear.std())\n)\nprint(\n    \"%0.2f accuracy poly with a standard deviation of %0.2f\"\n    % (scores_poly.mean(), scores_poly.std())\n)\nprint(\n    \"%0.2f accuracy rbf with a standard deviation of %0.2f\"\n    % (scores_rbf.mean(), scores_rbf.std())\n)\nprint(\n    \"%0.2f accuracy sigmoid with a standard deviation of %0.2f\"\n    % (scores_sigmoid.mean(), scores_sigmoid.std())\n)\n","68ff60b1":"clf = svm.SVC(kernel=\"linear\", C=0.1, random_state=random_state)\ncv = StratifiedKFold(n_splits=5, shuffle=True)\n\ncm_list = []\ntprs, fprs, tprs_pure = [[], [], []], [[], [], []], [[], [], []]\naucs = [[], [], []]\nmean_tpr_list, mean_auc_list= [], []\nmean_fpr = np.linspace(0, 1, 100)\nrecall, precision, accuracy = [],[],[]\ng = 1\n\nfor train_index, test_index in cv.split(x, y):\n    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    clf.fit(X_train, y_train)\n    pred_y1 = clf.predict(X_test)\n    cm_list.append(confusion_matrix(y_test, pred_y1))\n    pred_y = clf.decision_function(X_test)\n    y_test_dummies = get_dummies(y_test, drop_first=False).values\n\n    recall.append(recall_score(y_test, pred_y1, average='micro'))\n    accuracy.append(accuracy_score(y_test, pred_y1))\n    precision.append(precision_score(y_test, pred_y1, average='micro'))\n    target_names = ['class 0', 'class 1', 'class 2']\n    print('fold: '+str(g))\n    g+=1\n    print(classification_report(y_test, pred_y1, target_names=target_names))\n    \n    for i in range(3):\n        fpr, tpr, t = roc_curve(y_test_dummies[:, i], pred_y[:, i])\n        fprs[i].append(fpr)\n        tprs_pure[i].append(tpr)\n        tprs[i].append(interp(mean_fpr, fpr, tpr))\n        roc_auc = auc(fpr, tpr)\n        aucs[i].append(roc_auc)","9090651f":"\nfor i in range(3):\n    fig1 = plt.figure(figsize=[12, 12])\n    ax1 = fig1.add_subplot(111, aspect='equal')\n    ax1.add_patch(\n        patches.Arrow(0.45, 0.5, -0.25, 0.25, width=0.3, color='green', alpha=0.5)\n    )\n    ax1.add_patch(\n        patches.Arrow(0.5, 0.45, 0.25, -0.25, width=0.3, color='red', alpha=0.5)\n    )\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black')\n    for inx in range(5):\n        plt.plot(fprs[i][inx], tprs_pure[i][inx], lw=2, alpha=0.3,\n                 label='ROC fold %d (AUC = %0.2f)' % (inx+1, aucs[i][inx]))\n    mean_tpr = np.mean(tprs[i], axis=0)\n    mean_tpr[-1] = 1.0\n    mean_tpr_list.append(mean_tpr)\n    mean_auc = auc(mean_fpr, mean_tpr)\n    mean_auc_list.append(mean_auc)\n    std_auc = np.std(aucs[i])\n    plt.plot(mean_fpr, mean_tpr, color='b',\n             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n             lw=2, alpha=.8)\n\n    std_tpr = np.std(tprs[i], axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                     label=r'$\\pm$ 1 std. dev.')\n\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC for size '+'\\''+str('M' if i == 0 else 'L' if i == 1 else 'S')+'\\'')\n    plt.legend(loc=\"lower right\")\n    plt.text(0.32, 0.7, 'More accurate area', fontsize=12)\n    plt.text(0.63, 0.4, 'Less accurate area', fontsize=12)\n    plt.show()","1026e2ab":"fig1 = plt.figure(figsize=[12, 12])\nax1 = fig1.add_subplot(111, aspect='equal')\nax1.add_patch(\n    patches.Arrow(0.45, 0.5, -0.25, 0.25, width=0.3, color='green', alpha=0.5)\n)\nax1.add_patch(\n    patches.Arrow(0.5, 0.45, 0.25, -0.25, width=0.3, color='red', alpha=0.5)\n)\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black')\n\nfor inx in range(3):\n    plt.plot(mean_fpr, mean_tpr_list[inx], lw=2, alpha=0.3,\n             label='ROC class %d (AUC = %0.2f)' % (inx, mean_auc_list[inx]))\nmean_tpr = np.mean(mean_tpr_list, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(mean_auc_list)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(mean_tpr_list, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.text(0.32, 0.7, 'More accurate area', fontsize=12)\nplt.text(0.63, 0.4, 'Less accurate area', fontsize=12)\nplt.show()","f2edbb85":"cm = np.array([sum(i) \/ len(cm_list) for i in zip(*cm_list)])\n\nplot_confusion_matrix(cm=np.array(cm),\n                      normalize=False,\n                      target_names=['M', 'L', 'S'],\n                      title=\"Confusion Matrix\")\nplt.show()","60f0c9ad":"\ntitle = \"Learning Curves (SVM)\"\nfig2 = plt.figure()\nax1 = fig2.add_subplot(111)\nax1.grid()\nax1.set_title(title)\n\nax1.set_xlabel(\"Training examples\")\nax1.set_ylabel(\"Score\")\n\ntrain_sizes, train_scores, test_scores, fit_times, _ = learning_curve(clf, x, y, cv=cv, n_jobs=1,\n                                                                      return_times=True)\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nfit_times_mean = np.mean(fit_times, axis=1)\nfit_times_std = np.std(fit_times, axis=1)\n\n# Plot learning curve\n\nax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha=0.1,\n                 color=\"r\")\nax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.1,\n                 color=\"g\")\nax1.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n         label=\"Training score\")\nax1.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n         label=\"Cross-validation score\")\nax1.legend(loc=\"best\")\nplt.show()","7140e388":"print('recall')\nprint(np.mean(recall))\nprint('precision')\nprint(np.mean(precision))\nprint('accuracy')\nprint(np.mean(accuracy))","46a7e2a5":"heart = read_csv(\"..\/input\/heart-attack\/new_heart1.csv\", header=0)\nheart.drop(heart.columns[0], axis=1, inplace=True)\nheart.head()\n","28da771a":"x = heart.drop([\"DEFAULT\"], axis=1).copy()\n\ny = heart[\"DEFAULT\"].copy()\nx = get_dummies(x, columns=[\"cp\", \"thal\", \"ca\", \"slope\", \"restecg\"])","174614f5":"x.head()","2ba260b4":"y.head()","e1be9ef6":"features = []\nfor feature in x.columns:\n    features.append(feature)\n    \n\nscaler = StandardScaler()\nx[features] = scaler.fit_transform(x[features])","6dc8b9fe":"param_grid = [\n    {\"kernel\": [\"linear\"], \"C\": [0.01, 0.1, 1, 10, 100]},\n    {\n        \"kernel\": [\"poly\"],\n        \"C\": [0.01, 0.1, 1, 10, 100],\n        \"degree\": [1, 2, 3, 4],\n        \"gamma\": [\"auto\"],\n    },\n    {\"kernel\": [\"rbf\"], \"C\": [0.01, 0.1, 1, 10, 100], \"gamma\": [\"auto\"]},\n    {\"kernel\": [\"sigmoid\"], \"C\": [0.01, 0.1, 1, 10, 100]},\n]\nSVC = svm.SVC()\nfor SW in param_grid:\n\n    optimal_params = GridSearchCV(SVC, param_grid=SW, cv=10, scoring=\"accuracy\")\n\n    optimal_params.fit(x, y)\n    # print(DataFrame(optimal_params.cv_results_))\n    ss = concat(\n        [\n            pd.DataFrame(optimal_params.cv_results_[\"params\"]),\n            pd.DataFrame(\n                optimal_params.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]\n            ),\n            pd.DataFrame(optimal_params.cv_results_[\"rank_test_score\"], columns=[\"rank\"]),\n        ],\n        axis=1,\n    )\n    ss = ss.sort_values(by=\"Accuracy\", ascending=False)\n    print(ss)","a8ac4de2":"\nclf_rbf = svm.SVC(kernel=\"rbf\", gamma=\"auto\", C=1)\nclf_poly = svm.SVC(kernel=\"poly\", degree=1, C=0.1, gamma=\"auto\")\nclf_linear = svm.SVC(kernel=\"linear\", C=1)\nclf_sigmoid = svm.SVC(kernel=\"sigmoid\", C=1)\nscores_rbf = cross_val_score(clf_rbf, x, y, cv=5)\nscores_poly = cross_val_score(clf_poly, x, y, cv=5)\nscores_linear = cross_val_score(clf_linear, x, y, cv=5)\nscores_sigmoid = cross_val_score(clf_sigmoid, x, y, cv=5)\n\nprint(\n    \"%0.2f accuracy linear with a standard deviation of %0.2f\"\n    % (scores_linear.mean(), scores_linear.std())\n)\nprint(\n    \"%0.2f accuracy poly with a standard deviation of %0.2f\"\n    % (scores_poly.mean(), scores_poly.std())\n)\nprint(\n    \"%0.2f accuracy rbf with a standard deviation of %0.2f\"\n    % (scores_rbf.mean(), scores_rbf.std())\n)\nprint(\n    \"%0.2f accuracy sigmoid with a standard deviation of %0.2f\"\n    % (scores_sigmoid.mean(), scores_sigmoid.std())\n)\n","1bae2fd4":"clf = svm.SVC(kernel=\"linear\", C=0.1, random_state=random_state, probability=True)\ncv = StratifiedKFold(n_splits=5, shuffle=False)\nfig1 = plt.figure(figsize=[12, 12])\nax1 = fig1.add_subplot(111, aspect='equal')\nax1.add_patch(\n    patches.Arrow(0.45, 0.5, -0.25, 0.25, width=0.3, color='green', alpha=0.5)\n)\nax1.add_patch(\n    patches.Arrow(0.5, 0.45, 0.25, -0.25, width=0.3, color='red', alpha=0.5)\n)\ncm_list = []\ntprs, fprs = [], []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nrecall, precision, accuracy, spec = [], [], [], []\ni = 1\nfor train_index, test_index in cv.split(x, y):\n    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    clf.fit(X_train, y_train)\n    pred_y1 = clf.predict(X_test)\n    target_names = ['class 0', 'class 1']\n    print('fold: '+str(i))\n    print(classification_report(y_test, pred_y1, target_names=target_names))\n    cm_list.append(confusion_matrix(y_test, clf.predict(X_test)))\n    recall.append(recall_score(y_test, pred_y1))\n    accuracy.append(accuracy_score(y_test, pred_y1))\n    precision.append(precision_score(y_test, pred_y1))\n    spec.append(cm_list[i - 1][0][0] \/ (cm_list[i - 1][0][0] + cm_list[i - 1][0][1]))\n    fpr, tpr, t = roc_curve(y_test, clf.decision_function(X_test))\n    fprs.append(fpr)\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n    i = i + 1\ncm = np.array([sum(i) \/ len(cm_list) for i in zip(*cm_list)])\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black')\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC \\\"heart \\\"')\nplt.legend(loc=\"lower right\")\nplt.text(0.32, 0.7, 'More accurate area', fontsize=12)\nplt.text(0.63, 0.4, 'Less accurate area', fontsize=12)\nplt.show()","b1776a18":"plot_confusion_matrix(cm=np.array(cm),\n                      normalize=False,\n                      target_names=['no risk', 'risk'],\n                      title=\"Confusion Matrix\")\n\nplt.show()","5b9f3ba4":"\ntitle = \"Learning Curves (SVM)\"\nfig2 = plt.figure()\nax1 = fig2.add_subplot(111)\nax1.grid()\nax1.set_title(title)\n\nax1.set_xlabel(\"Training examples\")\nax1.set_ylabel(\"Score\")\n\ntrain_sizes, train_scores, test_scores, fit_times, _ = learning_curve(clf, x, y, cv=cv, n_jobs=1,\n                                                                      return_times=True)\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nfit_times_mean = np.mean(fit_times, axis=1)\nfit_times_std = np.std(fit_times, axis=1)\n\n# Plot learning curve\n\nax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha=0.1,\n                 color=\"r\")\nax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.1,\n                 color=\"g\")\nax1.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n         label=\"Training score\")\nax1.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n         label=\"Cross-validation score\")\nax1.legend(loc=\"best\")\nplt.show()","daeae337":"print('recall')\nprint(np.mean(recall))\nprint('precision')\nprint(np.mean(precision))\nprint('accuracy')\nprint(np.mean(accuracy))\nprint('specyficzno\u015b\u0107')\nprint(np.mean(spec))\n","6647fd4f":"starbucks = read_csv(\"..\/input\/starbucks\/starbucks_good.csv\", header=0)\nstarbucks.rename({\"loyal\": \"DEFAULT\"}, axis=\"columns\", inplace=True)","2c80c70d":"x = starbucks.drop([\"DEFAULT\"], axis=1).copy()\ny = starbucks[\"DEFAULT\"].copy()\nx = get_dummies(x, columns=[\"status\", \"age\"])","67394960":"param_grid = [\n    {\"kernel\": [\"linear\"], \"C\": [0.01, 0.1, 1, 10, 100]},\n    {\n        \"kernel\": [\"poly\"],\n        \"C\": [0.01, 0.1, 1, 10, 100],\n        \"degree\": [1, 2, 3, 4],\n        \"gamma\": [\"auto\"],\n    },\n    {\"kernel\": [\"rbf\"], \"C\": [0.01, 0.1, 1, 10, 100], \"gamma\": [\"auto\"]},\n    {\"kernel\": [\"sigmoid\"], \"C\": [0.01, 0.1, 1, 10, 100]},\n]\nSVC = svm.SVC()\nfor SW in param_grid:\n\n    optimal_params = GridSearchCV(SVC, param_grid=SW, cv=10, scoring=\"accuracy\")\n\n    optimal_params.fit(x, y)\n    # print(DataFrame(optimal_params.cv_results_))\n    ss = concat(\n        [\n            pd.DataFrame(optimal_params.cv_results_[\"params\"]),\n            pd.DataFrame(\n                optimal_params.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]\n            ),\n            pd.DataFrame(optimal_params.cv_results_[\"rank_test_score\"], columns=[\"rank\"]),\n        ],\n        axis=1,\n    )\n    ss = ss.sort_values(by=\"Accuracy\", ascending=False)\n    print(ss)","1d16920b":"\nclf_rbf = svm.SVC(kernel=\"rbf\", gamma=\"auto\", C=0.1)\nclf_poly = svm.SVC(kernel=\"poly\", degree=1, C=0.01, gamma=\"auto\")\nclf_linear = svm.SVC()\nclf_sigmoid = svm.SVC(kernel=\"sigmoid\", C=0.01)\nscores_rbf = cross_val_score(clf_rbf, x, y, cv=5)\nscores_poly = cross_val_score(clf_poly, x, y, cv=5)\nscores_linear = cross_val_score(clf_linear, x, y, cv=5)\nscores_sigmoid = cross_val_score(clf_sigmoid, x, y, cv=5)\nprint(\n    \"%0.2f accuracy linear with a standard deviation of %0.2f\"\n    % (scores_linear.mean(), scores_linear.std())\n)\nprint(\n    \"%0.2f accuracy poly with a standard deviation of %0.2f\"\n    % (scores_poly.mean(), scores_poly.std())\n)\nprint(\n    \"%0.2f accuracy rbf with a standard deviation of %0.2f\"\n    % (scores_rbf.mean(), scores_rbf.std())\n)\nprint(\n    \"%0.2f accuracy sigmoid with a standard deviation of %0.2f\"\n    % (scores_sigmoid.mean(), scores_sigmoid.std())\n)","86410b36":"\nclf = svm.SVC(kernel=\"linear\", C=1, random_state=random_state, probability=True)\ncv = StratifiedKFold(n_splits=5, shuffle=True)\nfig1 = plt.figure(figsize=[12, 12])\nax1 = fig1.add_subplot(111, aspect='equal')\nax1.add_patch(\n    patches.Arrow(0.45, 0.5, -0.25, 0.25, width=0.3, color='green', alpha=0.5)\n)\nax1.add_patch(\n    patches.Arrow(0.5, 0.45, 0.25, -0.25, width=0.3, color='red', alpha=0.5)\n)\ncm_list = []\ntprs, fprs = [], []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nrecall, precision, accuracy, spec = [], [], [], []\ni = 1\n\nfor train_index, test_index in cv.split(x, y):\n    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    clf.fit(X_train, y_train)\n    pred_y1 = clf.predict(X_test)\n    target_names = ['class 0', 'class 1']\n    print('fold: '+str(i))\n    print(classification_report(y_test, pred_y1, target_names=target_names))\n    cm_list.append(confusion_matrix(y_test, clf.predict(X_test)))\n    recall.append(recall_score(y_test, pred_y1))\n    accuracy.append(accuracy_score(y_test, pred_y1))\n    precision.append(precision_score(y_test, pred_y1))\n    spec.append(cm_list[i - 1][0][0] \/ (cm_list[i - 1][0][0] + cm_list[i - 1][0][1]))\n    fpr, tpr, t = roc_curve(y_test, clf.decision_function(X_test))\n    fprs.append(fpr)\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n    i = i + 1\ncm = np.array([sum(i) \/ len(cm_list) for i in zip(*cm_list)])\n\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black')\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC \\\"Starbucks\\\"')\nplt.legend(loc=\"lower right\")\nplt.text(0.32, 0.7, 'More accurate area', fontsize=12)\nplt.text(0.63, 0.4, 'Less accurate area', fontsize=12)\nplt.show()\nplot_confusion_matrix(cm=np.array(cm),\n                      normalize=False,\n                      target_names=['false', 'true'],\n                      title=\"Confusion Matrix\")\n\nplt.show()","8d05be28":"\ntitle = \"Learning Curves (SVM)\"\nfig2 = plt.figure()\nax1 = fig2.add_subplot(111)\nax1.grid()\nax1.set_title(title)\n\nax1.set_xlabel(\"Training examples\")\nax1.set_ylabel(\"Score\")\n\ntrain_sizes, train_scores, test_scores, fit_times, _ = learning_curve(clf, x, y, cv=cv, n_jobs=1,\n                                                                      return_times=True)\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nfit_times_mean = np.mean(fit_times, axis=1)\nfit_times_std = np.std(fit_times, axis=1)\n\n# Plot learning curve\n\nax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha=0.1,\n                 color=\"r\")\nax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.1,\n                 color=\"g\")\nax1.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n         label=\"Training score\")\nax1.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n         label=\"Cross-validation score\")\nax1.legend(loc=\"best\")\nplt.show()","eef7e767":"print('recall')\nprint(np.mean(recall))\nprint('precision')\nprint(np.mean(precision))\nprint('accuracy')\nprint(np.mean(accuracy))\nprint('specyficzno\u015b\u0107')\nprint(np.mean(spec))","a837acc0":"# **Heart attack**","08a21ec9":"# **Starbucks loyal**","d9cfca3b":"Data = {'M': 0,\n        'L': 1,\n        'S': 2}"}}