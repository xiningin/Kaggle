{"cell_type":{"c340a92b":"code","c164e04c":"code","f2c2e226":"code","80adce42":"code","bd4ced58":"code","1186dc7d":"code","e02c7212":"code","cdd75fc4":"code","629bcd1a":"code","ddbe029f":"code","282a91c5":"code","a2862270":"code","6ef4dede":"code","1787e068":"code","c4ba1c86":"code","18eafc6c":"code","2824e05f":"code","2e204372":"code","3cebbd9f":"code","932f26ba":"code","87d16656":"code","f0a4df9b":"code","318203f0":"code","71e357fe":"code","3701882c":"code","e5483a57":"code","2bfb9989":"code","ae601277":"code","c544b286":"code","b0315173":"code","ea6181d2":"code","13466de6":"code","b86881b7":"code","a4a6f783":"code","ec7d5f30":"code","30bc6f91":"code","22e85aab":"code","be9be2f8":"code","d6ae4547":"markdown","ab2a1e7b":"markdown","90d6488e":"markdown","cb3a690c":"markdown","20dd9995":"markdown","677d18cf":"markdown","ccf7d7c5":"markdown","baf8ae51":"markdown","f06380cd":"markdown","83baed54":"markdown","15effe61":"markdown","7e26aaec":"markdown","8b6e1ddf":"markdown","b9cbf9cb":"markdown","7b00ae1c":"markdown","ee4dfdb2":"markdown"},"source":{"c340a92b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c164e04c":"df = pd.read_csv('\/kaggle\/input\/ramen-ratings\/ramen-ratings.csv')\ndf.head()","f2c2e226":"df = df.drop(columns=['Top Ten'])","80adce42":"df.isnull().sum()","bd4ced58":"df = df.dropna()","1186dc7d":"df.isnull().sum()","e02c7212":"df.describe(include='all')","cdd75fc4":"x = df.drop(columns=['Style'])\nx","629bcd1a":"y = df['Style']\ny","ddbe029f":"import matplotlib.pyplot as plt\n# create figure and axis\nfig, ax = plt.subplots()\n# plot histogram\nax.hist(df['Style'])\n# set title and labels\nax.set_title('Style of Presenting')\nax.set_xlabel('Types')\nax.set_ylabel('Frequency')","282a91c5":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder()  \nx= x.apply(label_encoder.fit_transform)\nx","a2862270":"import seaborn as sns\nsns.distplot(x['Stars']);","6ef4dede":"y= label_encoder.fit_transform(y)\ny","1787e068":"import seaborn as sns\nsns.jointplot(x=x['Brand'], y=x['Stars'], kind=\"kde\")","c4ba1c86":"features=['Style', 'Country'] # Subplot for count plot\nfig=plt.subplots(figsize=(25,20))\nfor i, j in enumerate(features):\n    plt.subplot(4, 2, i+1)\n    plt.subplots_adjust(hspace = 1.0)\n    sns.countplot(x=j,data = df)\n    plt.xticks(rotation=90)\n    plt.title(\"Ramen\")\n    \nplt.show()","18eafc6c":"import seaborn as sns\nsns.kdeplot(data=x['Brand'], shade=True)\nsns.kdeplot(data=x['Country'], shade=True)\nsns.kdeplot(data=x['Stars'], shade=True)","2824e05f":"plt.figure(figsize=(12,6))\nsns.boxplot(x=\"Country\", y=\"Brand\", data=x)","2e204372":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","3cebbd9f":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)","932f26ba":"# data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n\n# fit scaler on training data\nnorm = MinMaxScaler().fit(x_train)\n\n# transform training data\nX_train_norm = norm.transform(x_train)\n\n\n# transform testing dataabs\nX_test_norm = norm.transform(x_test)","87d16656":"# fit scaler on training data\nnorm = MinMaxScaler().fit(x_train)\n\n# transform training data\nX_train_norm = norm.transform(x_train)\nprint(\"Scaled Train Data: \\n\\n\")\nprint(X_train_norm)","f0a4df9b":"# transform testing dataabs\nX_test_norm = norm.transform(x_test)\nprint(\"\\n\\nScaled Test Data: \\n\\n\")\nprint(X_test_norm)","318203f0":"from sklearn.ensemble import RandomForestClassifier\n# random forest model creation\nrfc = RandomForestClassifier()\nrfc.fit(X_train_norm,y_train)","71e357fe":"# predictions\nrfc_predict = rfc.predict(X_test_norm)\n\nprint(\"Accuracy:\",accuracy_score(y_test, rfc_predict))","3701882c":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4, n_init = 10, random_state=251)\nkmeans.fit(x)","e5483a57":"centroids = kmeans.cluster_centers_\ncentroid_df = pd.DataFrame(centroids, columns = list(x) )\ncentroid_df = pd.DataFrame(centroids, columns = list(x) )\ndf_labels = pd.DataFrame(kmeans.labels_ , columns = list(['labels']))","2bfb9989":"snail_df_labeled = x.join(df_labels)\ndf_analysis = (snail_df_labeled.groupby(['labels'] , axis=0)).head(4177) \ndf_analysis.head()","ae601277":"df_analysis.isnull().sum()","c544b286":"df_analysis = df_analysis.dropna()\ndf_analysis.isnull().sum()","b0315173":"from sklearn.model_selection import train_test_split  \nX= df_analysis.drop('labels',axis =1)\ny= df_analysis['labels']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)","ea6181d2":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train,y_train)","13466de6":"# predict Model\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\naccuracy_score(y_test,y_pred)","b86881b7":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'gini',random_state = 0)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))","a4a6f783":"from sklearn.ensemble import RandomForestClassifier\nrclf = RandomForestClassifier(n_estimators= 100)\nrclf.fit(X_train,y_train)\ny_pred = rclf.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))","ec7d5f30":"from sklearn.neighbors import KNeighborsClassifier \nclassifier = KNeighborsClassifier(n_neighbors= 5)\nclassifier.fit(X_train,y_train)","30bc6f91":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_true=y_test,y_pred=y_pred)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,y_pred))","22e85aab":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(X_train,y_train)\npredicted = model.predict(X_test)\nprint('Predicted Value',predicted)","be9be2f8":"cm = confusion_matrix(y_true=y_test,y_pred=predicted)\nprint('Confusion Matrix \\n',cm)\nprint(accuracy_score(y_test,predicted))","d6ae4547":"# Bar Plot","ab2a1e7b":"Dropping of 'Top Ten' column due to null values present.","90d6488e":"# Box Plot","cb3a690c":"# Naive Bayes Classifier","20dd9995":"# Random Forest Classifier","677d18cf":"Creating a new column as labels to increase the accuracy.","ccf7d7c5":"# Decision Tree Classifier","baf8ae51":"# Joint Plot","f06380cd":"In Style column, there are 2 null values present , we need to remove it.","83baed54":"# KNeighborsClassifier","15effe61":"# Count Plot","7e26aaec":"Label encoding for to change string to numeric type","8b6e1ddf":"# Logistic Regression","b9cbf9cb":"Now no 'NAN'(null) values is present.","7b00ae1c":"# **Random Forest Classifier**","ee4dfdb2":"Doing normalisation to improve accuracy quite a little bit."}}