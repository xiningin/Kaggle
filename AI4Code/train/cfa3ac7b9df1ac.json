{"cell_type":{"7a72b08b":"code","2c989027":"code","e6f26fb0":"code","0432c211":"code","c217a575":"code","51c7e91a":"code","4ff85f1b":"code","4b42439e":"code","3e34b37c":"code","475478e2":"code","50c05eb2":"code","81b9d378":"code","a3de0422":"code","30fd8e41":"code","d7a67656":"code","6ef81df5":"code","c9a0fe6b":"code","5287b4e2":"code","f8ff9f32":"code","77a12ccd":"code","ec2a43d7":"code","4e7ecdf6":"code","aa04934b":"code","7249e71c":"code","eb80ad94":"code","35f7ca45":"code","64f5cea0":"code","49406977":"code","999be95d":"code","3ce15674":"code","80ca7983":"code","78f7746a":"markdown","a8c195c2":"markdown","838c69dc":"markdown","b91b7009":"markdown","9098697e":"markdown","e3ca1f95":"markdown","71cbbb36":"markdown","944defb2":"markdown","d1a01586":"markdown","2d964adf":"markdown","bfef1869":"markdown"},"source":{"7a72b08b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2c989027":"!pip install tensorflow_decision_forests","e6f26fb0":"!pip install wurlitzer","0432c211":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport math\nimport tensorflow_decision_forests as tfdf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\n\ntry:\n    from wurlitzer import sys_pipes\nexcept:\n    from colabtools.googlelog import CaptureLog as sys_pipes","c217a575":"tf.random.set_seed(22)","51c7e91a":"import keras\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression","4ff85f1b":"train= pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv', sep=',', index_col='id')\ntrain.head()","4b42439e":"test= pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv', sep=',', index_col='id')\ntest.head()","3e34b37c":"#Create Train df and target df\ntarget=train['target']\ntrain = train.drop(columns='target')","475478e2":"#Adding 2 very simply feautres\ntrain['tot_mean'] = train.mean(axis=1)\ntest['tot_mean'] = test.mean(axis=1)\n\ntrain['tot_std'] = train.std(axis=1)\ntest['tot_std'] = test.std(axis=1)","50c05eb2":"rs = MinMaxScaler()\ntrain = pd.DataFrame(rs.fit_transform(train), index=train.index, columns=train.columns)\ntest = pd.DataFrame(rs.transform(test), index=test.index, columns=test.columns)","81b9d378":"X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=42, stratify=target)","a3de0422":"train_ds=tf.data.Dataset.from_tensor_slices((X_train,y_train))","30fd8e41":"val_ds = tf.data.Dataset.from_tensor_slices((X_val,y_val))","d7a67656":"test_ds = tf.data.Dataset.from_tensor_slices((test))","6ef81df5":"train_ds=train_ds.batch(128)\nval_ds=val_ds.batch(128)\ntest_ds=test_ds.batch(128)","c9a0fe6b":"#callbaks\nreduce_lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0)\nearly = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","5287b4e2":"input_1 = tf.keras.Input(shape=(102,))\n\ny = tf.keras.layers.Dense(300, activation=tf.nn.elu, kernel_initializer='he_normal')(input_1)\nyn = tf.keras.layers.BatchNormalization()(y)\nyd = tf.keras.layers.Dropout(0.2)(yn)\n\ny0 = tf.keras.layers.Dense(150, activation=tf.nn.elu, kernel_initializer='he_normal')(yd)\ny0n = tf.keras.layers.BatchNormalization()(y0) \ny0d = tf.keras.layers.Dropout(0.2)(y0n)\n\n\ny1 = tf.keras.layers.Dense(150, activation=tf.nn.elu, kernel_initializer='he_normal')(y0d)\ny1n = tf.keras.layers.BatchNormalization()(y1)\ny1d = tf.keras.layers.Dropout(0.1)(y1n)\n\ny2 = tf.keras.layers.Dense(93, activation=tf.nn.elu, kernel_initializer='he_normal')(y1d)\ny2n = tf.keras.layers.BatchNormalization()(y2)\ny2d = tf.keras.layers.Dropout(0.1)(y2n)\n\nlast_layer = tf.keras.layers.Dense(93, activation=tf.nn.elu, kernel_initializer='he_normal', name=\"last\")(y2d)\n\nclassification_output = tf.keras.layers.Dense(1, activation='sigmoid')(y2d)\n\nnn_model = tf.keras.models.Model(input_1, classification_output)","f8ff9f32":"nn_model.compile(\n  optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.9, epsilon=1e-07),\n  loss=tf.keras.losses.BinaryCrossentropy(),\n  metrics=[tf.keras.metrics.AUC()])","77a12ccd":"tf.keras.utils.plot_model(\n    nn_model,\n    to_file=\"model1.png\",\n    show_shapes=True,\n    show_dtype=True,\n    show_layer_names=True)","ec2a43d7":"nn_model.fit(x=train_ds, validation_data=val_ds, epochs=50, callbacks=[reduce_lr, early])\nnn_model.summary()","4e7ecdf6":"# Creating the GB model\nnn_without_head = tf.keras.models.Model(inputs=nn_model.inputs, outputs=last_layer)\ndf_and_nn_model = tfdf.keras.GradientBoostedTreesModel(preprocessing=nn_without_head,hyperparameter_template='benchmark_rank1')","aa04934b":"ds_train=tf.data.Dataset.from_tensor_slices((train,target))\nds_train=ds_train.batch(128)","7249e71c":"df_and_nn_model.compile(metrics=[tf.keras.metrics.AUC()])\nwith sys_pipes():\n    df_and_nn_model.fit(x=ds_train)","eb80ad94":"logs = df_and_nn_model.make_inspector().training_logs()\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Accuracy (out-of-bag)\")\n\nplt.subplot(1, 2, 2)\nplt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Logloss (out-of-bag)\")\n\nplt.show()","35f7ca45":"p = df_and_nn_model.predict(ds_train)\np2 = df_and_nn_model.predict(test_ds)\nparameters = {'C':[0.0001,0.0002,0.0003, 0.0004,0.0005,0.0006,0.0007,0.001, 0.005, 0.01, 0.1, 1, 10]}\nlr = LogisticRegression()\nclf = GridSearchCV(lr, param_grid=parameters, cv=10, scoring='roc_auc')","64f5cea0":"clf.fit(p,target)","49406977":"p3=clf.best_estimator_.predict_proba(p2)","999be95d":"sub= pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv', sep=',', index_col='id')\nsub.head()","3ce15674":"sub['target'] = p3[:,1]\nsub.head()","80ca7983":"sub = sub.reset_index()\nsub.to_csv('submission.csv',index=False)","78f7746a":"Application of the TF-DF tutorial available at:\nhttps:\/\/www.tensorflow.org\/decision_forests\/tutorials\/intermediate_colab\n\nit's highly recommended to set iper-parameters, try other models GB, apply cv folds..","a8c195c2":"the example shows that it's possible training the model in two steps:\n1) Normalization > NN > Classification\n\n2) Replace the last layer of the NN (before classification output) with a TF-DF tree model (RF, GB..)","838c69dc":"## The Model","b91b7009":"# continue.....","9098697e":"## NN Model","e3ca1f95":"# Gradient Boosting","71cbbb36":"#### Source","944defb2":"### Import Data","d1a01586":"### Calibration using Ligistic Regression Model","2d964adf":"### Scaling Data\/Split Train df\/Convert train\/test into tensorflow dataset","bfef1869":"# Submission"}}