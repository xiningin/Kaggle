{"cell_type":{"9dba1f56":"code","186fad96":"code","dbb8e84c":"code","fd449fd4":"code","999a084d":"code","fb501945":"code","a8e2fbee":"code","86f604a1":"code","1646591a":"code","afca160c":"code","4e8d2cb5":"markdown","e6691dbb":"markdown","cd129a82":"markdown","b3c8ac39":"markdown","d5bbfdfb":"markdown","8d0c62cb":"markdown","9474e3d5":"markdown","eaa67cd9":"markdown","e30a6fc3":"markdown"},"source":{"9dba1f56":"!pip install git+https:\/\/github.com\/keras-team\/keras-tuner.git -q","186fad96":"import pandas as pd\n\ndef load_train(path):\n    data = pd.read_csv(path)\n    y = data[\"label\"]\n    x = data.drop(labels=[\"label\"], axis=1).values.reshape(-1, 28, 28, 1)\n    return x, y\n\ndef load_test(path):\n    data = pd.read_csv(path)\n    x = data.values.reshape(-1, 28, 28, 1)\n    return x\n\nx_train, y_train = load_train(\"..\/input\/digit-recognizer\/train.csv\")\nx_test = load_test(\"..\/input\/digit-recognizer\/test.csv\")","dbb8e84c":"x_train.shape","fd449fd4":"x_test.shape","999a084d":"y_train.shape","fb501945":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef augment_images(x, hp):\n    use_rotation = hp.Boolean('use_rotation')\n    if use_rotation:\n        x = layers.experimental.preprocessing.RandomRotation(\n            hp.Float('rotation_factor', min_value=0.05, max_value=0.2)\n        )(x)\n    use_zoom = hp.Boolean('use_zoom')\n    if use_zoom:\n        x = layers.experimental.preprocessing.RandomZoom(\n            hp.Float('use_zoom', min_value=0.05, max_value=0.2)\n        )(x)\n    return x\n\ndef make_model(hp):\n    inputs = keras.Input(shape=(28, 28, 1))\n    x = layers.experimental.preprocessing.Rescaling(1. \/ 255)(inputs)\n    x = layers.experimental.preprocessing.Resizing(64, 64)(x)\n    x = augment_images(x, hp)\n    \n    num_block = hp.Int('num_block', min_value=2, max_value=5, step=1)\n    num_filters = hp.Int('num_filters', min_value=32, max_value=128, step=32)\n    for i in range(num_block):\n        x = layers.Conv2D(\n            num_filters,\n            kernel_size=3,\n            activation='relu',\n            padding='same'\n        )(x)\n        x = layers.Conv2D(\n            num_filters,\n            kernel_size=3,\n            activation='relu',\n            padding='same'\n        )(x)\n        x = layers.MaxPooling2D(2)(x)\n    \n    reduction_type = hp.Choice('reduction_type', ['flatten', 'avg'])\n    if reduction_type == 'flatten':\n        x = layers.Flatten()(x)\n    else:\n        x = layers.GlobalAveragePooling2D()(x)\n\n    x = layers.Dense(\n        units=hp.Int('num_dense_units', min_value=32, max_value=512, step=32),\n        activation='relu'\n    )(x)\n    x = layers.Dropout(\n        hp.Float('dense_dropout', min_value=0., max_value=0.7)\n    )(x)\n    outputs = layers.Dense(10)(x)\n    model = keras.Model(inputs, outputs)\n    \n    learning_rate = hp.Float('learning_rate', min_value=3e-4, max_value=3e-3)\n    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  optimizer=optimizer,\n                  metrics=[keras.metrics.SparseCategoricalAccuracy(name='acc')])\n    model.summary()\n    return model","a8e2fbee":"import kerastuner as kt\n\ntuner = kt.tuners.RandomSearch(\n    make_model,\n    objective='val_acc',\n    max_trials=100,\n    overwrite=True)\n\ncallbacks=[keras.callbacks.EarlyStopping(monitor='val_acc', mode='max', patience=3, baseline=0.9)]\ntuner.search(x_train, y_train, validation_split=0.2, callbacks=callbacks, verbose=1, epochs=100)","86f604a1":"best_hp = tuner.get_best_hyperparameters()[0]\nmodel = make_model(best_hp)\nhistory = model.fit(x_train, y_train, validation_split=0.2, epochs=50)","1646591a":"val_acc_per_epoch = history.history['val_acc']\nbest_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\nmodel = make_model(best_hp)\nmodel.fit(x_train, y_train, epochs=best_epoch)","afca160c":"import numpy as np\n\npredictions = model.predict(x_test)\nsubmission = pd.DataFrame({\"ImageId\": list(range(1, len(predictions) + 1)),\n                           \"Label\": np.argmax(predictions, axis=-1)})\nsubmission.to_csv(\"submission.csv\", index=False)","4e8d2cb5":"## Run hyperparameter search\n\nNow, we launch the search. For simplicity, we'll use `RandomSearch`. We'll limit the search to 100 different model configurations.\n\nNote that we configure the calls to `model.fit()` to use the `EarlyStopping` callbacks.\nIndeed, we train for 100 epochs, but the model is likely to start overfitting much earlier than that --\nin general, always use a large number of epochs + the `EarlyStopping` callback.\n\nOur search is guided by validation accuracy, which is computed on a fixed 20% hold-out set of the training data.","e6691dbb":"## Make a submission","cd129a82":"## Find the best epoch value\n\nNow, we can retrieve the best hyperparameters, use them to build the best model,\nand train the model for 50 epochs to find at which epoch training should stop.","b3c8ac39":"This is a full-run version of Francois Cholet's kernel. It also corrects the error of loading the train set as the test set, and produces the correct output file.","d5bbfdfb":"# Keras + KerasTuner best practices\n\nThis notebook presents how to use KerasTuner to find a high-performing model in just a few lines of code.\n\nFirst, let's start by installing the latest Kerastuner version:","8d0c62cb":"## Train the production model\n\nFinally, we can train the best model configuration from scratch for the optimal number of epochs.\n\nThis time, we train on the entirety of the training data -- no validation split. Our model parameters are already validated.","9474e3d5":"## Define a tunable model\n\nWe define a function `def make_model(hp):` which builds a compiled Keras model,\nparameterized by hyperparameters obtained from the `hp` argument.\n\nOur model includes a stage that does random image data augmentation, via the `augment_images`\nfunction. Our image augmentation is itself tunable: we'll find the best augmentation\nconfiguration during the hyperparameter search.","eaa67cd9":"## Load the data\n\nWe use Pandas to load the data into NumPy arrays.\n\nOur inputs are uint8 arrays of shape `(num_samples, 28, 28, 1)` and our targets are integer arrays of shape `(num_samples,)`.","e30a6fc3":"On the free Kaggle GPU, trying out 100 models takes 4 hours.\nAt the end of the search, our best validation accuracy is 99.33%."}}