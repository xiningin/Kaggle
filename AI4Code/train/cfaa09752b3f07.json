{"cell_type":{"9f10c2d9":"code","bdd910c4":"code","6fe48ed3":"code","b599a878":"code","0d367918":"code","d4175046":"code","e9245514":"code","077b8169":"code","4c7bd69a":"code","63efe595":"code","52d9e114":"code","f278ba04":"code","566c9cda":"code","33aa5d88":"code","1cf33365":"code","7e80281b":"code","90e8a06f":"code","4db65c43":"code","646ccb20":"code","06545f54":"code","c41712c8":"code","58a59420":"markdown"},"source":{"9f10c2d9":"# pip install --upgrade transformers","bdd910c4":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport copy\nimport tensorflow.keras.layers as L\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import regularizers\n\nfrom sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold, StratifiedKFold\nfrom transformers import BertTokenizer, TFBertModel, BertConfig, BertModel, TFDistilBertModel, DistilBertConfig\n","6fe48ed3":"def seed_everything(seed = 34):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()","b599a878":"train = pd.read_json('..\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest = pd.read_json('..\/input\/stanford-covid-vaccine\/test.json', lines=True)\nsub = pd.read_csv('..\/input\/stanford-covid-vaccine\/sample_submission.csv')\n\n#target columns\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","0d367918":"def MCRMSE(y_true, y_pred):\n    columnwise_mse = tf.reduce_mean(tf.square(y_true-y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=1)","d4175046":"AUTO = tf.data.experimental.AUTOTUNE\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","e9245514":"config = DistilBertConfig() ","077b8169":"config","4c7bd69a":"config.vocab_size = 10\nconfig.dim = 128\nconfig.hidden_dim = 128\nconfig.max_position_embeddings = 128\nconfig.n_layers = 2\nconfig.n_heads = 128\n# config.sinusoidal_pos_embds = True\n","63efe595":"def build_model(transformer, seq_len=107, pred_len=68, dropout=0.5, embed_dim=100, hidden_dim=128):\n    ids = L.Input(shape=(seq_len,3),  dtype=tf.int32, name=\"input_word_ids\")\n    flat = L.Flatten()(ids)\n    sequence_output = transformer(flat)[0]\n    truncated = sequence_output[:,:pred_len, :]\n    \n    out = L.Dense(5, activation='linear')(truncated)\n    model = tf.keras.Model(inputs=ids, outputs=out)\n\n    model.compile(tf.keras.optimizers.Adam(), loss=MCRMSE)\n    \n    return model","52d9e114":"with strategy.scope():\n    transformer_layer = (\n        TFDistilBertModel(config=config)\n    )\n    model = build_model(transformer_layer)\nmodel.summary()","f278ba04":"tokentoint = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [tokentoint[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\npreprocess_inputs(train).shape","566c9cda":"train_inputs = preprocess_inputs(train[train['signal_to_noise'] >= 1])\ntrain_labels = np.array(train[train['signal_to_noise'] >= 1][target_cols].values.tolist()).transpose(0, 2, 1)","33aa5d88":"print(train_inputs.shape)\nprint(train_labels.shape)","1cf33365":"public_df = test[test['seq_length']==107].copy()\nprivate_df = test[test['seq_length']==130].copy()\n\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)","7e80281b":"#basic training configuration\nFOLDS = 5\nEPOCHS = 100\nREPEATS = 1\nBATCH_SIZE = 64\nVERBOSE = 2\nSEED = 34","90e8a06f":"# pip install livelossplot","4db65c43":"from sklearn.model_selection import KFold\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau()\n","646ccb20":"bert_histories = []\nbert_private_preds = np.zeros((private_df.shape[0], 130, 5))\nbert_public_preds = np.zeros((public_df.shape[0], 107, 5))\n\nkf = KFold(n_splits=FOLDS,shuffle=True,random_state=42)\n\n\nwith strategy.scope():\n   \n    \n    for fold, (train_index, val_index) in enumerate(kf.split(train_inputs, train_labels)):\n        print(f\"FOLD {fold}\")\n        \n        model = build_model(transformer_layer)\n        \n        history = model.fit(\n            train_inputs[train_index,:,:], train_labels[train_index,:,:], \n            batch_size=BATCH_SIZE,\n            epochs=EPOCHS,\n            validation_split=0.1,\n                callbacks=[\n                            lr_callback,\n                            tf.keras.callbacks.ModelCheckpoint('model'+str(fold)+'.h5',save_weights_only=True,save_best_only=True)\n                            ])\n\n        model_short = build_model(transformer_layer,seq_len=107, pred_len=107)\n        model_long = build_model(transformer_layer,seq_len=130, pred_len=130)\n\n        model_short.load_weights('model'+str(fold)+'.h5')\n        model_long.load_weights('model'+str(fold)+'.h5')\n        \n        bert_histories.append(history)\n\n        bert_public_pred = model_short.predict(public_inputs) \/ FOLDS\n\n        bert_private_pred = model_long.predict(private_inputs) \/ FOLDS\n\n        bert_public_preds += bert_public_pred\n        bert_private_preds += bert_private_pred\n        \n","06545f54":"preds_bert = []\n\nfor df, preds in [(public_df, bert_public_preds), (private_df, bert_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_bert.append(single_df)\n\npreds_bert_df = pd.concat(preds_bert)\npreds_bert_df.head()","c41712c8":"submission = sub[['id_seqpos']].merge(preds_bert_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","58a59420":"![](https:\/\/camo.githubusercontent.com\/c1c57556008de61f649ae26939be7236e5a02d85\/68747470733a2f2f68756767696e67666163652e636f2f66726f6e742f7468756d626e61696c732f64697374696c626172745f6c617267652e706e67)\n\n\n\nreference : [https:\/\/www.kaggle.com\/eladwar\/openvaccine-bert-model](https:\/\/www.kaggle.com\/eladwar\/openvaccine-bert-model)"}}