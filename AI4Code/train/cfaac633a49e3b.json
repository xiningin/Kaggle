{"cell_type":{"184f65b4":"code","fc87df51":"code","866c1d5d":"code","363481c6":"code","b2bb9f3e":"code","2e846f0d":"code","7e12e6b9":"code","a3adb86b":"code","d7ab0b84":"code","0b589d09":"code","cb280cfa":"code","aed98e65":"code","7f492a43":"code","4a52c47f":"code","bf4b868a":"code","a79b8b21":"code","07186633":"code","9b32d8a0":"code","5333732e":"code","a42f4fcc":"code","3e8b4f45":"code","85606561":"code","920c7a8e":"code","11af4ff2":"code","5c7b3e65":"code","3ebe5f0d":"code","ffc986cc":"code","71ce0fe0":"code","cc80bada":"code","5e3bd066":"code","0055ffd5":"code","177d6da9":"code","8571f5d2":"code","fed0f7c6":"code","7a383198":"code","a2408fee":"code","94afec39":"code","ccccb474":"code","1f872a1e":"code","9e0afa8e":"code","42f4b987":"code","880bd4f3":"code","30b9a37d":"code","335b12d1":"code","c8b01414":"code","5994e0fa":"code","72ff55c8":"code","b3cec179":"code","85864dfd":"code","ddf9cebc":"code","338603dd":"code","d9f4f359":"code","feadcac3":"code","5844abf2":"code","d2c6bb8d":"markdown","873fee14":"markdown","6de21045":"markdown","3a1a427f":"markdown","8a6b1a12":"markdown","0b065ee8":"markdown","02fd175c":"markdown","62876671":"markdown","10d7baef":"markdown","9ee92070":"markdown","a658bfd5":"markdown","253635cc":"markdown","55e58ddf":"markdown","df55d813":"markdown","26ae642c":"markdown","1ce24e86":"markdown","e188c024":"markdown","7626b217":"markdown","5c3b5978":"markdown","500d55e6":"markdown","f33fa489":"markdown","d9b51aa5":"markdown","96b3fd67":"markdown","d22733e8":"markdown","7a8393af":"markdown","1218b842":"markdown","e850fb18":"markdown","76a258a8":"markdown","09be6f44":"markdown","91be711b":"markdown"},"source":{"184f65b4":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fc87df51":"df = pd.read_csv('\/kaggle\/input\/loan-application-data\/df1_loan.csv')\n\nprint(df.shape)\ndf.head()","866c1d5d":"df.drop(['Unnamed: 0', 'Loan_ID'], axis = 1, inplace = True)","363481c6":"df.describe()","b2bb9f3e":"target = 'Loan_Status'","2e846f0d":"df.groupby(target)['LoanAmount'].count().plot.bar()\nplt.ylabel('count')\nplt.show()","7e12e6b9":"print('Y: {}%'.format(df[target].value_counts()[0] \/ len(df)))\nprint('N: {}%'.format(df[target].value_counts()[1] \/ len(df)))","a3adb86b":"df.isnull().sum()","d7ab0b84":"nan_features = [feature for feature in df.columns if df[feature].isnull().sum() > 0]\n\nfor feature in nan_features:\n    print('{}: {}% values missing'.format(feature, (df[feature].isnull().sum() \/ len(df)) * 100))","0b589d09":"for feature in nan_features:\n    data = df.copy()\n    \n    data[feature] = np.where(data[feature].isnull(), 1, 0)\n    data[target] = np.where(data[target] == 'Y', 1, 0)\n    data.groupby(feature)[target].mean().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel(target)\n    plt.show()","cb280cfa":"nan_numeric = []\nnan_categoric = []\n\nfor feature in nan_features:\n    if df[feature].dtype != 'O':\n        nan_numeric.append(feature)\n    else:\n        nan_categoric.append(feature)\n        \nprint('Numeric missing:', nan_numeric)\nprint('Categorical missing:', nan_categoric)","aed98e65":"data = df.copy()","7f492a43":"for feature in nan_categoric:\n    data[feature] = np.where(data[feature].isnull(), data[feature].mode(), data[feature])\n    \nfor feature in nan_numeric:\n    data[feature] = np.where(data[feature].isnull(), int(data[feature].median()), data[feature])","4a52c47f":"data[target] = np.where(data[target] == 'Y', 1, 0)","bf4b868a":"data['Total_Income'] = data['ApplicantIncome'] + data['CoapplicantIncome']","a79b8b21":"num_features = [feature for feature in data.columns if data[feature].dtype != 'O' and feature != target]\n\ndata[num_features].head()","07186633":"dis_features = [feature for feature in num_features if len(data[feature].unique()) < 20]\n\ndis_features","9b32d8a0":"for feature in dis_features:\n    data.groupby(feature)[target].count().plot.bar()\n    \n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","5333732e":"for feature in dis_features:\n    data.groupby(feature)[target].mean().plot.bar()\n    \n    plt.xlabel(feature)\n    plt.ylabel(target)\n    plt.show()","a42f4fcc":"con_features = [feature for feature in num_features if feature not in dis_features]\n\ncon_features","3e8b4f45":"for feature in con_features:\n    data.boxplot(column = feature)\n    \n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","85606561":"for feature in con_features:\n    data[feature].hist(bins = 25)\n    \n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","920c7a8e":"for feature in con_features:\n   \n    extreme = data[feature].median() + 3 * data[feature].std()\n    print(feature)\n    print('Values to be replaced: {}%'.format((len(data.loc[data[feature] > extreme]) \/ len(data)) * 100))","11af4ff2":"for feature in con_features:\n    \n    extreme = data[feature].median() + 3 * data[feature].std()\n    data[feature] = np.where(data[feature] > extreme, extreme, data[feature])\n    \n    data[feature] = data[feature] ** 0.5\n    \n    data[feature].hist(bins = 25)\n    \n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","5c7b3e65":"cat_features = [feature for feature in data.columns if feature not in num_features and feature != target]\n\ndata[cat_features].head()","3ebe5f0d":"for feature in cat_features:\n    print('{}: {} categories'.format(feature, len(data[feature].unique())))","ffc986cc":"for feature in cat_features:\n    data.groupby(feature)[target].mean().plot.bar()\n    \n    plt.xlabel(feature)\n    plt.ylabel(target)\n    plt.show()","71ce0fe0":"df = pd.read_csv('\/kaggle\/input\/loan-application-data\/df1_loan.csv')\n\nprint(df.shape)\ndf.head()","cc80bada":"df.drop(['Unnamed: 0', 'Loan_ID'], axis = 1 , inplace = True)","5e3bd066":"df[target] = np.where(df[target] == 'Y', 1, 0)","0055ffd5":"for feature in nan_categoric:\n    df[feature] = np.where(df[feature].isnull(), df[feature].mode(), df[feature])\n    \nfor feature in nan_numeric:\n    df[feature] = np.where(df[feature].isnull(), int(df[feature].median()), df[feature])","177d6da9":"df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']","8571f5d2":"for feature in con_features:\n    \n    extreme = df[feature].median() + 3 * df[feature].std()\n    df[feature] = np.where(df[feature] > extreme, extreme, df[feature])\n    \n    df[feature] = df[feature] ** 0.5","fed0f7c6":"dummy_df = pd.get_dummies(df, drop_first = True)\ndummy_df.head()","7a383198":"X = dummy_df.drop('Loan_Status', axis = 1)\ny = dummy_df['Loan_Status']","a2408fee":"cor = X[num_features].corr()\n\nsns.heatmap(cor, annot = True, cmap = plt.cm.CMRmap_r)\nplt.show()","94afec39":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","ccccb474":"scaler = MinMaxScaler()\n\nscaler.fit(X_train)\n\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","1f872a1e":"model = LogisticRegression()\n\nmodel.fit(X_train_scaled, y_train)","9e0afa8e":"y_pred_lr = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred_lr))\nprint(classification_report(y_test, y_pred_lr, digits = 4))","42f4b987":"model = LogisticRegression()\n\nscores = cross_val_score(model, X_train_scaled, y_train, cv = 10)\nprint(np.mean(scores))","880bd4f3":"scores = []\n\nfor i in range(5, 12):\n    model = KNeighborsClassifier(n_neighbors = i)\n    model.fit(X_train_scaled, y_train)\n    scores.append(model.score(X_test_scaled, y_test))\n\nplt.plot(np.arange(5, 12), scores)\nplt.xlabel('No of Neighbors')\nplt.ylabel('Score')\nplt.show()\n\nbest_neighbors = np.arange(5, 12)[scores.index(max(scores))]\nprint('Best score = {}\\n Neighbors = {}'.format(max(scores), best_neighbors))","30b9a37d":"model = KNeighborsClassifier(n_neighbors = best_neighbors)\nmodel.fit(X_train_scaled, y_train)\n\ny_pred_knn = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred_knn))\nprint(classification_report(y_test, y_pred_knn, digits = 4))","335b12d1":"model = KNeighborsClassifier(n_neighbors = best_neighbors)\n\nscores = cross_val_score(model, X_train_scaled, y_train, cv = 10)\nprint(np.mean(scores))","c8b01414":"model = SVC()\n\nmodel.fit(X_train_scaled, y_train)","5994e0fa":"y_pred_svc = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred_svc))\nprint(classification_report(y_test, y_pred_svc, digits = 4))","72ff55c8":"model = SVC()\n\nscores = cross_val_score(model, X_train_scaled, y_train, cv = 10)\nprint(np.mean(scores))","b3cec179":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","85864dfd":"model = RandomForestClassifier()\n\nmodel.fit(X_train, y_train)","ddf9cebc":"y_pred_rf = model.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf, digits = 4))","338603dd":"model = RandomForestClassifier()\n\nscores = cross_val_score(model, X_train, y_train, cv = 10)\nprint(np.mean(scores))","d9f4f359":"model = XGBClassifier(use_label_encoder = False)\n\nmodel.fit(X_train, y_train)","feadcac3":"y_pred_xgb = model.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred_xgb))\nprint(classification_report(y_test, y_pred_xgb, digits = 4))","5844abf2":"model = XGBClassifier(use_label_encoder = False)\n\nscores = cross_val_score(model, X_train, y_train, cv = 10)\nprint(np.mean(scores))","d2c6bb8d":"# EDA","873fee14":"## Dropping unwanted columns","6de21045":"## Dealing with outliers and transformation","3a1a427f":"## Target Variable transformation","8a6b1a12":"### Continuous Features","0b065ee8":"## XGBoost","02fd175c":"# Feature Engineering","62876671":"No significant relationship can be observed between target variable and missing values. The number of missing values is not very large to impact the analysis significantly","10d7baef":"## Logistic Regression","9ee92070":"### Discrete Variables","a658bfd5":"No significant relationship can be determined","253635cc":"## Numeric Features","55e58ddf":"## Scaling","df55d813":"### vs Target variable","26ae642c":"## Missing values","1ce24e86":"#### Observation\nCredit History highly affects the target variable","e188c024":"## Random Forest","7626b217":"## SVM","5c3b5978":"## Target Variable","500d55e6":"#### Distribution","f33fa489":"#### vs Target Variable","d9b51aa5":"## Categorical Features","96b3fd67":"# Models","d22733e8":"## Correlation","7a8393af":"#### Outliers and Transformation","1218b842":"## KNN","e850fb18":"#### Distribution","76a258a8":"## Dealing with missing values","09be6f44":"# Feature Selection","91be711b":"No significant correlation present"}}