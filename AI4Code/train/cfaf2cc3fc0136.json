{"cell_type":{"03efc7aa":"code","623171c1":"code","9d177f25":"code","6a355dc3":"code","cfa35166":"code","6dd38e40":"code","f408d6ed":"code","a0a4c7ef":"code","4d670b60":"code","2c269b82":"code","ad6a7372":"code","1e2e9760":"code","7eb8408d":"code","b984fc7f":"code","d9c7df5e":"code","724b92c5":"code","4773f079":"code","fe56a22f":"code","d62f29e4":"code","cc4fff1e":"code","4ef9b8f5":"code","0cfec198":"code","9b35f6f9":"code","a9647041":"code","5658cf96":"code","888ba3f0":"code","22ef5618":"code","2b1c5104":"code","591e0deb":"code","553bd813":"code","4d70d4fd":"code","4eed5cac":"code","db4ea936":"code","36fb5d9d":"code","4aa4b891":"code","6420a411":"code","f6b8a3f5":"code","4a4d17e0":"code","d1f626a2":"code","16fe30cb":"code","0203faac":"code","0b22c3cb":"markdown"},"source":{"03efc7aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\".\"))\n\n# Any results you write to the current directory are saved as output.","623171c1":"from matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","9d177f25":"df_store = pd.read_csv('..\/input\/store.csv')\ndf = pd.read_csv('..\/input\/train.csv', low_memory=False)\n\ndf = df.merge(df_store, on='Store')","6a355dc3":"df_test = pd.read_csv('..\/input\/test.csv', low_memory=False)\ndf_test.head()","cfa35166":"df.head(5)","6dd38e40":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Month'] = df.Date.apply(lambda dt: dt.month)\ndf['Year'] = df.Date.apply(lambda dt: dt.year)\ndf['WeekOfYear'] = df.Date.apply(lambda dt: dt.weekofyear)\ndf['Day'] = df.Date.apply(lambda dt: dt.day)\n\ndf['isMonthEnd'] = df.Date.apply(lambda dt: dt.is_month_end)\ndf['isMonthStart'] = df.Date.apply(lambda dt: dt.is_month_start)\ndf['isQuarterEnd'] = df.Date.apply(lambda dt: dt.is_quarter_end )\ndf['isQuarterStart'] = df.Date.apply(lambda dt: dt.is_quarter_start)\ndf['isYearEnd'] = df.Date.apply(lambda dt: dt.is_year_end)\ndf['isYearStart'] = df.Date.apply(lambda dt: dt.is_year_start)","f408d6ed":"features = []\nfor feat in df.columns.drop('Sales'):\n    if df[feat].dtype == np.float64 or df[feat].dtype == np.int64:\n        features.append(feat)","a0a4c7ef":"fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 20));\ndf_sample = df.sample(frac=0.05)\n\nfor idx, feature in enumerate(features):\n    df_sample.plot(feature, \"Sales\", subplots=True, kind=\"scatter\", ax=axes[idx \/\/ 4, idx % 4]);","4d670b60":"import gc \n\ndel df_sample\ngc.collect()","2c269b82":"# \u0441\u0438\u043b\u044c\u043d\u043e \u0432\u044b\u0440\u0430\u0436\u0435\u043d\u043d\u0430\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f \u043c\u0435\u0436\u0434\u0443 Customers \u0438 Sales (\u0430 \u0442\u0430\u043a \u0436\u0435 Open\/Promo). \u041d\u043e \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043f\u043e\u043a\u0443\u043f\u0430\u0442\u0435\u043b\u0435\u0439 - \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u0430\u044f \u0437\u0430\u0434\u0430\u0447\u0430\n# Promo2 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043d\u0435 \u0441\u0442\u043e\u043b\u044c \u0445\u043e\u0440\u043e\u0448\u0430 \u0432 \u0446\u0435\u043b\u043e\u043c\n\ndf[df.columns.drop('Sales')].corrwith(df.Sales)","ad6a7372":"# \u0422\u0438\u043f \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u0430 \"b\" \u043f\u043e\u0447\u0442\u0438 \u0432 \u0434\u0432\u0430 \u0440\u0430\u0437\u0430 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u0442 \u043f\u0440\u043e\u0434\u0430\u0436\u0438 \n\ndf.groupby('StoreType')['Sales'].mean()","1e2e9760":"sns.distplot(df.Sales[df.Sales > 0])","7eb8408d":"df.info()","b984fc7f":"# \u043d\u0435\u0442 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f Promo2, \u0435\u0441\u043b\u0438 \u043d\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0434\u043b\u044f ~SinceWeek \u0438\u043b\u0438 ~SinceYear\ndf[(pd.isnull(df.Promo2SinceWeek) | pd.isnull(df.Promo2SinceYear)) & df.Promo2 != 0]","d9c7df5e":"df['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\ndf['CompetitionOpenSinceYear'].fillna(0, inplace=True)","724b92c5":"df['Promo2SinceWeek'].fillna(0, inplace=True)\ndf['Promo2SinceYear'].fillna(0, inplace=True)","4773f079":"df['CompetitionDistance'].fillna(df['CompetitionDistance'].median(), inplace=True)\ndf['CompetitionDistance'] = np.log(df.CompetitionDistance) + 1","fe56a22f":"df.sample(frac=.001).plot('CompetitionDistance', \"Sales\", subplots=True, kind=\"scatter\")","d62f29e4":"# \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043b\u0438\u0448\u044c \u043e\u0434\u0438\u043d \u043c\u0430\u0433\u0430\u0437\u0438\u043d \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0442\u043e\u0432 \u043f\u043e\u0431\u043b\u0438\u0437\u043e\u0441\u0442\u0438, \u0442\u0430\u043a \u0447\u0442\u043e \u043d\u0435\u0442 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u0438 \u0432\u0432\u0435\u0441\u0442\u0438 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u043e\u0440 \u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435 \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0442\u043e\u0432\ndf.groupby('Store')['CompetitionDistance'].unique().apply(lambda l: 1 if len(l) > 1 else 0).sum()","cc4fff1e":"# \u0431\u043e\u043b\u044c\u0448\u0438\u043d\u0441\u0442\u0432\u043e \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u043e\u0432 \u0437\u0430\u043a\u0440\u044b\u0442\u043e \u043f\u043e \u043f\u0440\u0430\u0437\u0434\u043d\u0438\u043a\u0430\u043c, \u0434\u0430 \u0438 \u0432\u0435\u0441\u043e\u043c\u043e\u0439 \u0440\u0430\u0437\u043d\u0438\u0446\u044b \u043c\u0435\u0436\u0434\u0443 \u043d\u0438\u043c\u0438 \u0432 \u043f\u0440\u043e\u0434\u0430\u0436\u0430\u0445 \u043d\u0435 \u043e\u043a\u0430\u0437\u0430\u043b\u043e\u0441\u044c\ndf['StateHoliday'] = df['StateHoliday'].replace(0, '0')\ndf['Holiday'] = df.StateHoliday.apply(lambda x: 0 if x == '0' else 1)\n\ndf.drop('StateHoliday', axis=1, inplace=True)","4ef9b8f5":"df = df.sort_values(by='Date')\ndf.drop('Date', axis=1, inplace=True)","0cfec198":"df = df[(df['Open'] != 0) & (df['Sales'] != 0)]\ndf.drop('Open', axis=1, inplace=True)","9b35f6f9":"# \u043c\u043e\u0436\u043d\u043e \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043a\u0430\u043a \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u0443\u044e \u0444\u0438\u0447\u0443 \n\ndf.PromoInterval.value_counts()","a9647041":"df['isMonthEnd'] = df['isMonthEnd'].astype(int)\ndf['isMonthStart'] = df['isMonthStart'].astype(int)\ndf['isQuarterEnd'] = df['isQuarterEnd'].astype(int)\ndf['isQuarterStart'] = df['isQuarterStart'].astype(int)\ndf['isYearEnd'] = df['isYearEnd'].astype(int)\ndf['isYearStart'] = df['isYearStart'].astype(int)","5658cf96":"# competition open time (in months)\ndf['CompetitionOpen'] = 12 * (df.Year - df.CompetitionOpenSinceYear) + \\\n        (df.Month - df.CompetitionOpenSinceMonth)\n    \n# Promo open time\ndf['PromoOpen'] = 12 * (df.Year - df.Promo2SinceYear) + \\\n        (df.WeekOfYear - df.Promo2SinceWeek) \/ 4.0\n\ndf = pd.get_dummies(df, columns=['DayOfWeek', 'StoreType', 'Assortment','PromoInterval'], dummy_na=True)","888ba3f0":"from sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import r2_score, make_scorer\n\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1.\/(y[ind]**2)\n    return w\n\n\ndef rmspe(yhat, y):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\n\n\ndef rmspe_xg(yhat, y):\n    # y = y.values\n    y = y.get_label()\n    y = np.exp(y) - 1\n    yhat = np.exp(yhat) - 1\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n    return \"rmspe\", rmspe","22ef5618":"# from sklearn.ensemble import RandomForestRegressor\n\n# rfr = RandomForestRegressor(n_estimators=300, criterion='mae', max_depth=12, n_jobs=-1, verbose=True)\n# rfr.fit(X_train.values, np.log(y_train.values) + 1)\n\n# y_hat = rfr.predict(X_test.values)\n# y_hat = np.exp(y_hat) - 1\n\n# print(f'MAE: {mae(y_test, y_hat)}')\n# print(f'RMSPE: {rmspe(y_hat, y_test)}')","2b1c5104":"import xgboost as xgb\nfrom hyperopt import hp\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\ndef train(index, train, hp_selection=False):\n    train_store = train[index]\n    X = train_store[train_store.columns.drop(['Sales', 'Store', 'Customers'])]\n    y = train_store['Sales']\n\n    train_size = int(X.shape[0]*.99)\n    print(f'Regressor for {index} store\\nTraining on {X.shape[0]} samples')\n    X_train, y_train = X.iloc[:train_size], y.iloc[:train_size]\n    X_test, y_test = X.iloc[train_size:], y.iloc[train_size:]\n\n    xtrain = xgb.DMatrix(X_train, np.log(y_train.values) + 1)\n    xtest = xgb.DMatrix(X_test, np.log(y_test.values) + 1)\n    \n    if hp_selection:\n        def score(params):\n            num_round = 200\n            model = xgb.train(params, xtrain, num_round, feval=rmspe_xg)\n            predictions = model.predict(xtest)\n            score = rmspe(y=y_test, yhat=predictions)\n            return {'loss': score, 'status': STATUS_OK}\n\n        def optimize(trials):\n            space = {\n                     'n_estimators' : hp.quniform('n_estimators', 1, 1000, 1),\n                     'eta' : hp.quniform('eta', 0.2, 0.825, 0.025),\n                     'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n                     'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n                     'subsample' : hp.quniform('subsample', 0.7, 1, 0.05),\n                     'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n                     'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n                     'eval_metric': 'rmse',\n                     'objective': 'reg:linear',\n                     'nthread': 4,\n                     'silent' : 1\n                     }\n\n            best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n            return best\n        \n        trials = Trials()\n        best_opts = optimize(trials)\n        best_opts['silent'] = 1\n    else:\n        best_opts = {'colsample_bytree': 0.7, \n                  'eta': 0.625, \n                  'gamma': 0.8, \n                  'max_depth': 6,\n                  'eval_metric': 'rmse',\n                  'min_child_weight': 6.0, \n                  'n_estimators': 8.0,  # 585\n                  'silent': 1,\n                  'nthread': 4,\n                  'subsample': 0.95}\n        \n    watchlist = [(xtrain, 'train'), (xtest, 'eval')]\n    num_round = 10000\n    regressor = xgb.train(best_opts, xtrain, num_round, watchlist, feval=rmspe_xg,\n                          verbose_eval=10, early_stopping_rounds=50)\n    print(\"Validating\")\n    train_probs = regressor.predict(xtest)\n    indices = train_probs < 0\n    train_probs[indices] = 0\n    error = rmspe(np.exp(train_probs) - 1, y_test.values)\n    print('error', error)\n    regressor = xgb.train(best_opts, xtest, 10, feval=rmspe_xg, xgb_model=regressor)\n    return regressor","591e0deb":"# params = {'colsample_bytree': 0.7000000000000001, \n#           'eta': 0.625, \n#           'gamma': 0.8, \n#           'max_depth': 6,\n#           'eval_metric': 'rmse',\n#           'min_child_weight': 6.0, \n#           'n_estimators': 8.0,  # 585\n#           'silent': 1,\n#           'subsample': 0.9500000000000001}\n\n\n# watchlist = [(xtrain, 'train'), (xtest, 'eval')]\n# num_round = 10000\n# xgb_regressor = xgb.train(params, xtrain, num_round, watchlist, feval=rmspe_xg,\n#                           verbose_eval=10, early_stopping_rounds=50)","553bd813":"# fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 20));\n# xgb.plot_importance(xgb_regressor, axes)","4d70d4fd":"# print(\"Validating\")\n# train_probs = xgb_regressor.predict(xtest)\n# indices = train_probs < 0\n# train_probs[indices] = 0\n# error = rmspe(np.exp(train_probs) - 1, y_test.values)\n# print('error', error)\n\n# xgb_regressor = xgb.train(params, xtest, 1000, feval=rmspe_xg, xgb_model=xgb_regressor)","4eed5cac":"df_test = pd.read_csv('..\/input\/test.csv', low_memory=False)\nclosed_store_ids = df_test[\"Id\"][df_test[\"Open\"] == 0].values\n\ndf_test = df_test.merge(df_store, on='Store')\ndf_test['Date'] = pd.to_datetime(df_test['Date'])\ndf_test['Month'] = df_test.Date.apply(lambda dt: dt.month)\ndf_test['Year'] = df_test.Date.apply(lambda dt: dt.year)\ndf_test['WeekOfYear'] = df_test.Date.apply(lambda dt: dt.weekofyear)\ndf_test['Day'] = df_test.Date.apply(lambda dt: dt.day)\n\ndf_test['isMonthEnd'] = df_test.Date.apply(lambda dt: dt.is_month_end).astype(int)\ndf_test['isMonthStart'] = df_test.Date.apply(lambda dt: dt.is_month_start).astype(int)\ndf_test['isQuarterEnd'] = df_test.Date.apply(lambda dt: dt.is_quarter_end ).astype(int)\ndf_test['isQuarterStart'] = df_test.Date.apply(lambda dt: dt.is_quarter_start).astype(int)\ndf_test['isYearEnd'] = df_test.Date.apply(lambda dt: dt.is_year_end).astype(int)\ndf_test['isYearStart'] = df_test.Date.apply(lambda dt: dt.is_year_start).astype(int)\n\ndf_test['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\ndf_test['CompetitionOpenSinceYear'].fillna(0, inplace=True)\n\ndf_test['Promo2SinceWeek'].fillna(0, inplace=True)\ndf_test['Promo2SinceYear'].fillna(0, inplace=True)\n\ndf_test['CompetitionDistance'].fillna(df_test['CompetitionDistance'].median(), inplace=True)\n\ndf_test['StateHoliday'] = df_test['StateHoliday'].replace(0, '0')\ndf_test['Holiday'] = df_test.StateHoliday.apply(lambda x: 0 if x == '0' else 1)\n\ndf_test.drop('StateHoliday', axis=1, inplace=True)\ndf_test.drop('Date', axis=1, inplace=True)\n\n# competition open time (in months)\ndf_test['CompetitionOpen'] = 12 * (df_test.Year - df_test.CompetitionOpenSinceYear) + \\\n        (df_test.Month - df_test.CompetitionOpenSinceMonth)\n    \n# Promo open time\ndf_test['PromoOpen'] = 12 * (df_test.Year - df_test.Promo2SinceYear) + \\\n        (df_test.WeekOfYear - df_test.Promo2SinceWeek) \/ 4.0\n\ndf_test.drop(['Open'], axis=1, inplace=True)\n\ndf_test = pd.get_dummies(df_test, columns=['DayOfWeek', 'StoreType', 'Assortment','PromoInterval'], dummy_na=True)\n","db4ea936":"store_grouped = dict(list(df.groupby('Store')))\ntest_grouped = dict(list(df_test.groupby('Store')))","36fb5d9d":"submission = pd.Series(np.zeros(df_test.Id.shape))\nsubmission.index += 1\n\nfor store in test_grouped:\n    test = test_grouped[store].copy()\n    ids = test['Id']\n    dpred = xgb.DMatrix(test[test.columns.drop(['Id', 'Store'])]) \n    regressor = train(store, store_grouped)\n    preds = regressor.predict(dpred)\n    preds[preds < 0] = 0\n    preds = np.exp(preds) - 1\n    submission[ids] = preds\n\nsubmission[closed_store_ids] = 0","4aa4b891":"submission.head()","6420a411":"df_submission = pd.DataFrame()\ndf_submission['Id'] = submission.index\ndf_submission['Sales'] = submission.values","f6b8a3f5":"df_submission","4a4d17e0":"df_submission.to_csv('submission.csv', index=False)","d1f626a2":"# def score(params):\n#     print(\"Training with params : \")\n#     print(params)\n#     num_round = int(params['n_estimators'])\n#     model = xgb.train(params, xtrain, num_round, feval=rmspe_xg)\n#     predictions = model.predict(xtest)\n#     score = rmspe(y=y_test, yhat=predictions)\n#     br = '-'*124\n#     print(f'{br}\\n\\tScore of RMSPE: {score}\\n{br}')\n#     return {'loss': score, 'status': STATUS_OK}\n\n# def optimize(trials):\n#     space = {\n#              'n_estimators' : hp.quniform('n_estimators', 1, 1000, 1),\n#              'eta' : hp.quniform('eta', 0.3, 0.825, 0.025),\n#              'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n#              'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n#              'subsample' : hp.quniform('subsample', 0.7, 1, 0.05),\n#              'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n#              'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n#              'eval_metric': 'rmse',\n#              'objective': 'reg:linear',\n#              'nthread': 4,\n#              'silent' : 1\n#              }\n\n#     best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n\n#     print(best)\n#     return best\n\n    \n# trials = Trials()\n# best_opts = optimize(trials)\n","16fe30cb":"# print(best_opts)","0203faac":"# def score(params):\n#     print(\"Training with params : \")\n#     print(params)\n#     num_round = 25  # int(params['n_estimators'])\n#     # del params['n_estimators']\n#     dtrain = xgb.DMatrix(X_train, label=y_train)\n#     dvalid = xgb.DMatrix(X_test, label=y_test)\n#     model = xgb.train(params, dtrain, num_round)\n#     predictions = model.predict(dvalid)\n#     score = mae(y_test, predictions)\n#     br = '-'*130\n#     print(f'{br}\\n\\tScore of MAE: {score}\\n{br}')\n#     return {'loss': score, 'status': STATUS_OK}\n\n# def optimize(trials):\n#     space = {\n#              'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n#              'eta' : hp.quniform('eta', 0.4, 0.825, 0.025),\n#              'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n#              'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n#              'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n#              'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n#              'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n#              'eval_metric': 'mae',\n#              'objective': 'reg:linear',\n#              'nthread': 4,\n#              'silent' : 1\n#              }\n\n#     best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=50)\n\n#     print(best)\n    \n# trials = Trials()\n# optimize(trials)","0b22c3cb":"Best params:\n{'colsample_bytree': 0.7000000000000001, 'eta': 0.625, 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 585.0, 'subsample': 0.9500000000000001}\n---"}}