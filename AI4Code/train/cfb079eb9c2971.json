{"cell_type":{"2acf1395":"code","dc0a6060":"code","d8371e1d":"code","10ee623a":"code","39f09d2b":"code","9152c5a5":"code","919ea6ff":"code","e78baa21":"code","af38b932":"code","4585cf78":"code","019df1bb":"code","3a7e3e48":"code","2fb925dd":"code","b3bca8f3":"code","e1bb49f8":"code","96f4a625":"code","e96fea46":"code","4126b162":"code","b0585368":"code","5feda0f3":"code","1a1b879b":"code","fd3759ec":"code","c6fbd9ee":"code","e5a81048":"code","3c7ff98c":"code","a5ac1f32":"code","83714a28":"code","5ac987e7":"code","8d4f1509":"code","9bf3b41a":"code","717dbb48":"code","16423991":"code","3ad54e99":"code","5e3de2c7":"code","9033614e":"code","6fee2e9f":"code","feb34db2":"code","a465fbf2":"code","79feb889":"code","a36435da":"code","5e2cf412":"code","eb55d5a4":"code","eb775708":"code","ae207566":"code","90b619d7":"code","6cb443ad":"code","9f248160":"code","5246fdda":"code","110d8184":"markdown","b3439bf3":"markdown","fcb7582f":"markdown","0f503c17":"markdown","d30db530":"markdown","9397ac3d":"markdown","a9f6236f":"markdown","d8d486b3":"markdown","0dbf89ba":"markdown","d44c6d90":"markdown","a8433c6f":"markdown","286c7a1e":"markdown","e45808bc":"markdown","7a42d2e7":"markdown","fb1c2ba3":"markdown","2af6ac5b":"markdown"},"source":{"2acf1395":"import pandas as pd\nimport numpy as np\nimport re","dc0a6060":"train_df = pd.read_csv(\"..\/input\/train.csv\")\nX_train = train_df[\"question_text\"].fillna(\"dieter\").values\ntest_df = pd.read_csv(\"..\/input\/test.csv\")\nX_test = test_df[\"question_text\"].fillna(\"dieter\").values\ny = train_df[\"target\"]\n\ntext = train_df['question_text']\n\nfor row in text[:10]:\n    print(row)","d8371e1d":"def removeNumbers(text):\n    \"\"\" Removes integers \"\"\"\n    text = ''.join([i for i in text if not i.isdigit()])         \n    return text\n\ntext_removeNumbers = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removeNumbers['TextBefore'] = text.copy()\n","10ee623a":"for index, row in text_removeNumbers.iterrows():\n    row['TextAfter'] = removeNumbers(row['TextBefore'])","39f09d2b":"text_removeNumbers['Changed'] = np.where(text_removeNumbers['TextBefore']==text_removeNumbers['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removeNumbers[text_removeNumbers['Changed']=='yes']), len(text_removeNumbers), 100*len(text_removeNumbers[text_removeNumbers['Changed']=='yes'])\/len(text_removeNumbers)))","9152c5a5":"for index, row in text_removeNumbers[text_removeNumbers['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","919ea6ff":"def replaceMultiExclamationMark(text):\n    \"\"\" Replaces repetitions of exlamation marks \"\"\"\n    text = re.sub(r\"(\\!)\\1+\", ' multiExclamation ', text)\n    return text\n\ndef replaceMultiQuestionMark(text):\n    \"\"\" Replaces repetitions of question marks \"\"\"\n    text = re.sub(r\"(\\?)\\1+\", ' multiQuestion ', text)\n    return text\n\ndef replaceMultiStopMark(text):\n    \"\"\" Replaces repetitions of stop marks \"\"\"\n    text = re.sub(r\"(\\.)\\1+\", ' multiStop ', text)\n    return text\n\ntext_replaceRepOfPunct = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_replaceRepOfPunct['TextBefore'] = text.copy()","e78baa21":"for index, row in text_replaceRepOfPunct.iterrows():\n    row['TextAfter'] = replaceMultiExclamationMark(row['TextBefore'])\n    row['TextAfter'] = replaceMultiQuestionMark(row['TextBefore'])\n    row['TextAfter'] = replaceMultiStopMark(row['TextBefore'])","af38b932":"text_replaceRepOfPunct['Changed'] = np.where(text_replaceRepOfPunct['TextBefore']==text_replaceRepOfPunct['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_replaceRepOfPunct[text_replaceRepOfPunct['Changed']=='yes']), len(text_replaceRepOfPunct), 100*len(text_replaceRepOfPunct[text_replaceRepOfPunct['Changed']=='yes'])\/len(text_replaceRepOfPunct)))","4585cf78":"for index, row in text_replaceRepOfPunct[text_replaceRepOfPunct['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","019df1bb":"import string\ntranslator = str.maketrans('', '', string.punctuation)\ntext_removePunctuation = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removePunctuation['TextBefore'] = text.copy()","3a7e3e48":"for index, row in text_removePunctuation.iterrows():\n    row['TextAfter'] = row['TextBefore'].translate(translator) ","2fb925dd":"text_removePunctuation['Changed'] = np.where(text_removePunctuation['TextBefore']==text_removePunctuation['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removePunctuation[text_removePunctuation['Changed']=='yes']), len(text_removePunctuation), 100*len(text_removePunctuation[text_removePunctuation['Changed']=='yes'])\/len(text_removePunctuation)))","b3bca8f3":"for index, row in text_removePunctuation[text_removePunctuation['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","e1bb49f8":"for index, row in text_removePunctuation[text_removePunctuation['Changed']=='no'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","96f4a625":"contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not') ]\ndef replaceContraction(text):\n    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n    for (pattern, repl) in patterns:\n        (text, count) = re.subn(pattern, repl, text)\n    return text\n\ntext_replaceContractions = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_replaceContractions['TextBefore'] = text.copy()","e96fea46":"for index, row in text_replaceContractions.iterrows():\n    row['TextAfter'] = replaceContraction(row['TextBefore'])","4126b162":"text_replaceContractions['Changed'] = np.where(text_replaceContractions['TextBefore']==text_replaceContractions['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_replaceContractions[text_replaceContractions['Changed']=='yes']), len(text_replaceContractions), 100*len(text_replaceContractions[text_replaceContractions['Changed']=='yes'])\/len(text_replaceContractions)))","b0585368":"for index, row in text_replaceContractions[text_replaceContractions['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","5feda0f3":"text_lowercase = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_lowercase['TextBefore'] = text.copy()","1a1b879b":"for index, row in text_lowercase.iterrows():\n    row['TextAfter'] = row['TextBefore'].lower()","fd3759ec":"text_lowercase['Changed'] = np.where(text_lowercase['TextBefore']==text_lowercase['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_lowercase[text_lowercase['Changed']=='yes']), len(text_lowercase), 100*len(text_lowercase[text_lowercase['Changed']=='yes'])\/len(text_lowercase)))","c6fbd9ee":"for index, row in text_lowercase[text_lowercase['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","e5a81048":"for index, row in text_lowercase[text_lowercase['Changed']=='no'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","3c7ff98c":"import nltk\nfrom nltk.corpus import wordnet\n\ndef replace(word, pos=None):\n    \"\"\" Creates a set of all antonyms for the word and if there is only one antonym, it returns it \"\"\"\n    antonyms = set()\n    for syn in wordnet.synsets(word, pos=pos):\n        for lemma in syn.lemmas():\n            for antonym in lemma.antonyms():\n                antonyms.add(antonym.name())\n    if len(antonyms) == 1:\n        return antonyms.pop()\n    else:\n        return None\n\ndef replaceNegations(text):\n    \"\"\" Finds \"not\" and antonym for the next word and if found, replaces not and the next word with the antonym \"\"\"\n    i, l = 0, len(text)\n    words = []\n    while i < l:\n        word = text[i]\n        if word == 'not' and i+1 < l:\n            ant = replace(text[i+1])\n            if ant:\n                words.append(ant)\n                i += 2\n                continue\n        words.append(word)\n        i += 1\n    return words\n\ndef tokenize1(text):\n    tokens = nltk.word_tokenize(text)\n    tokens = replaceNegations(tokens)\n    text = \" \".join(tokens)\n    return text\n\ntext_replaceNegations = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_replaceNegations['TextBefore'] = text.copy()","a5ac1f32":"for index, row in text_replaceNegations.iterrows():\n    row['TextAfter'] = tokenize1(row['TextBefore'])","83714a28":"text_replaceNegations['Changed'] = np.where(text_replaceNegations['TextBefore'].str.replace(\" \",\"\")==text_replaceNegations['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_replaceNegations[text_replaceNegations['Changed']=='yes']), len(text_replaceNegations), 100*len(text_replaceNegations[text_replaceNegations['Changed']=='yes'])\/len(text_replaceNegations)))","5ac987e7":"for index, row in text_replaceNegations[text_replaceNegations['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","8d4f1509":"def addCapTag(word):\n    \"\"\" Finds a word with at least 3 characters capitalized and adds the tag ALL_CAPS_ \"\"\"\n    if(len(re.findall(\"[A-Z]{3,}\", word))):\n        word = word.replace('\\\\', '' )\n        transformed = re.sub(\"[A-Z]{3,}\", \"ALL_CAPS_\"+word, word)\n        return transformed\n    else:\n        return word\n\ndef tokenize2(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(addCapTag(w))\n    text = \" \".join(finalTokens)\n    return text\n\ntext_handleCapWords = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_handleCapWords['TextBefore'] = text.copy()","9bf3b41a":"for index, row in text_handleCapWords.iterrows():\n    row['TextAfter'] = tokenize2(row['TextBefore'])","717dbb48":"text_handleCapWords['Changed'] = np.where(text_handleCapWords['TextBefore'].str.replace(\" \",\"\")==text_handleCapWords['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_handleCapWords[text_handleCapWords['Changed']=='yes']), len(text_handleCapWords), 100*len(text_handleCapWords[text_handleCapWords['Changed']=='yes'])\/len(text_handleCapWords)))","16423991":"for index, row in text_handleCapWords[text_handleCapWords['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","3ad54e99":"from nltk.corpus import stopwords\nstoplist = stopwords.words('english')\n\ndef tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        if (w not in stoplist):\n            finalTokens.append(w)\n    text = \" \".join(finalTokens)\n    return text\n\ntext_removeStopwords = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removeStopwords['TextBefore'] = text.copy()","5e3de2c7":"for index, row in text_removeStopwords.iterrows():\n    row['TextAfter'] = tokenize(row['TextBefore'])","9033614e":"text_removeStopwords['Changed'] = np.where(text_removeStopwords['TextBefore'].str.replace(\" \",\"\")==text_removeStopwords['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removeStopwords[text_removeStopwords['Changed']=='yes']), len(text_removeStopwords), 100*len(text_removeStopwords[text_removeStopwords['Changed']=='yes'])\/len(text_removeStopwords)))","6fee2e9f":"for index, row in text_removeStopwords[text_removeStopwords['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","feb34db2":"def replaceElongated(word):\n    \"\"\" Replaces an elongated word with its basic form, unless the word exists in the lexicon \"\"\"\n\n    repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n    repl = r'\\1\\2\\3'\n    if wordnet.synsets(word):\n        return word\n    repl_word = repeat_regexp.sub(repl, word)\n    if repl_word != word:      \n        return replaceElongated(repl_word)\n    else:       \n        return repl_word\n    \ndef tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(replaceElongated(w))\n    text = \" \".join(finalTokens)\n    return text\n\ntext_removeElWords = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removeElWords['TextBefore'] = text.copy()","a465fbf2":"for index, row in text_removeElWords.iterrows():\n    row['TextAfter'] = tokenize(row['TextBefore'])","79feb889":"text_removeElWords['Changed'] = np.where(text_removeElWords['TextBefore'].str.replace(\" \",\"\")==text_removeElWords['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removeElWords[text_removeElWords['Changed']=='yes']), len(text_removeElWords), 100*len(text_removeElWords[text_removeElWords['Changed']=='yes'])\/len(text_removeElWords)))","a36435da":"for index, row in text_removeElWords[text_removeElWords['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","5e2cf412":"from nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer() #set stemmer\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer() # set lemmatizer\n\ndef tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(stemmer.stem(w)) # change this to lemmatizer.lemmatize(w) for Lemmatizing\n    text = \" \".join(finalTokens)\n    return text\n\ntext_stemming = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_stemming['TextBefore'] = text.copy()","eb55d5a4":"for index, row in text_stemming.iterrows():\n    row['TextAfter'] = tokenize(row['TextBefore'])","eb775708":"text_stemming['Changed'] = np.where(text_stemming['TextBefore'].str.replace(\" \",\"\")==text_stemming['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_stemming[text_stemming['Changed']=='yes']), len(text_stemming), 100*len(text_stemming[text_stemming['Changed']=='yes'])\/len(text_stemming)))","ae207566":"for index, row in text_stemming[text_stemming['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","90b619d7":"def tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        if (w not in stoplist):\n            w = addCapTag(w) # Handle Capitalized Words\n            w = w.lower() # Lowercase\n            w = replaceElongated(w) # Replace Elongated Words\n            w = stemmer.stem(w) # Stemming\n            finalTokens.append(w)\n    text = \" \".join(finalTokens)\n    return text\n\ntext_combos = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_combos['TextBefore'] = text.copy()","6cb443ad":"for index, row in text_combos.iterrows():\n    row['TextAfter'] = replaceContraction(row['TextBefore']) # Replace Contractions\n    row['TextAfter'] = removeNumbers(row['TextAfter']) # Remove Integers\n    row['TextAfter'] = replaceMultiExclamationMark(row['TextAfter']) # Replace Multi Exclamation Marks\n    row['TextAfter'] = replaceMultiQuestionMark(row['TextAfter']) # Replace Multi Question Marks\n    row['TextAfter'] = replaceMultiStopMark(row['TextAfter']) # Repalce Multi Stop Marks\n    row['TextAfter'] = row['TextAfter'].translate(translator) # Remove Punctuation\n    row['TextAfter'] = tokenize(row['TextAfter'])","9f248160":"text_combos['Changed'] = np.where(text_combos['TextBefore'].str.replace(\" \",\"\")==text_combos['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_combos[text_combos['Changed']=='yes']), len(text_combos), 100*len(text_combos[text_combos['Changed']=='yes'])\/len(text_combos)))","5246fdda":"for index, row in text_combos[text_combos['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","110d8184":"## 5. Lowercase\n**Example:** What do you know about Bram Fischer and the Rivonia Trial? -> what do you know about bram fischer and the rivonia trial?","b3439bf3":"Hmm, i expected everything to change, because they are question with \"?\". Let's see the ones that didn't change.","fcb7582f":"## 6. Replace Negations with Antonyms\n**Example:** Why are humans not able to be evolved developing resistance against diseases? -> Why are humans unable to be evolved developing resistance against diseases ?","0f503c17":"Some question are written only in lowercase. This happens when they start with a number.","d30db530":"## 10. Stemming\/Lemmatizing\n**Example:** How do modern military submarines reduce noise to achieve stealth? -> how do modern militari submarin reduc nois to achiev stealth ?","9397ac3d":"## 2. Replace Repetitions of Punctuation\nThis technique:\n - replaces repetitions of exlamation marks with the tag \"multiExclamation\"\n - replaces repetitions of question marks with the tag \"multiQuestion\"\n - replaces repetitions of stop marks with the tag \"multiStop\"\n \n **Example:** How do I overcome the fear of facing an interview? It's killing me inside..what should I do? -> How do I overcome the fear of facing an interview? It's killing me inside multiStop what should I do?","a9f6236f":"## 4. Replace Contractions\nThis techniques replaces contractions to their equivalents.\n\n**Example:** What's the scariest thing that ever happened to anyone? -> What is the scariest thing that ever happened to anyone?","d8d486b3":"## 3. Remove Punctuation\n**Example:** Why haven't two democracies never ever went for a full fledged war? What stops them? -> Why havent two democracies never ever went for a full fledged war What stops them","0dbf89ba":"## 1. Remove Numbers\n**Example:** Which is best powerbank for iPhone 7 in India? -> Which is best powerbank for iPhone  in India?","d44c6d90":"## Load Dataset and print some questions","a8433c6f":"# Text Pre-processing Techniques\nThese techniques may or may not be useful for this competition. Given the fact that is a text competition, i thought that it would be a good oportunity to present them. \n\nI have used them before in two papers. [A Comparison of Pre-processing Techniques for Twitter Sentiment Analysis](https:\/\/link.springer.com\/chapter\/10.1007\/978-3-319-67008-9_31) and [A comparative evaluation of pre-processing techniques and their interactions for twitter sentiment analysis](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0957417418303683). \n\nThe full code is on this [Github repository](https:\/\/github.com\/Deffro\/text-preprocessing-techniques) with some extra techniques.","286c7a1e":"## 7. Handle Capitalized Words\n**Example:** Which is better to use, Avro or ORC? -> Which is better to use , Avro or ALL_CAPS_ORC ?","e45808bc":"## Combos\nOf course we can use more than one technique at the same time. The order is essential here.\n\n**Example:** What are the recommended 2D game engines for a beginning Python programmer? -> what recommend d game engin begin python programm","7a42d2e7":"Thank you for reaching this point! Hope you enjoyed it! Your upvote will be much appreciated!","fb1c2ba3":"## 8. Remove Stopwords\n**Example:** How I know whether a girl had done sex before sex with me? -> How I know whether girl done sex sex ?","2af6ac5b":"## 9. Replace Elongated Words\nThis technique replaces an elongated word with its basic form, unless the word exists in the lexicon.\n\n**Example:** Game of Thrones, what does Arya find out about Littlefinger? -> Game of Thrones , what does Arya find out about Litlefinger ?"}}