{"cell_type":{"265804a9":"code","0984b771":"code","88817d42":"code","0a906dc3":"code","326323e7":"code","0e78a45d":"code","a30b4c84":"code","8c1a79bc":"code","5a2b6067":"code","1e4116af":"code","4426ef76":"code","c2dbf225":"code","2e9373b6":"code","be95c6b5":"code","13c0246d":"code","73155498":"code","e0731883":"code","33627246":"code","6cdf7f86":"code","01edd064":"code","141c8218":"code","14fcc3e6":"code","3f5e0d65":"code","c5b4e85b":"code","e33ca1bc":"code","f6b5ed7a":"code","6e874809":"code","a56ba528":"code","24b02040":"code","3e7c42d4":"code","27aca2c4":"code","af3301cf":"markdown","ef04e829":"markdown","f80b83f6":"markdown","612582cd":"markdown"},"source":{"265804a9":"import tensorflow as tf\nimport numpy as np\nimport glob\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","0984b771":"train_img_gen = ImageDataGenerator(rescale=1\/255., validation_split=0.2)\ntest_img_gen = ImageDataGenerator(rescale=1\/255.)","88817d42":"# 80% of the Training data used for Training and 20% used for Validation\ntrain_data = train_img_gen.flow_from_directory(directory='..\/input\/intel-image-classification\/seg_train\/seg_train', target_size=(150, 150), batch_size=128, class_mode='binary', shuffle=True, subset='training')","0a906dc3":"valid_data = train_img_gen.flow_from_directory(directory='..\/input\/intel-image-classification\/seg_train\/seg_train', target_size=(150, 150), batch_size=128, class_mode='binary', shuffle=True, subset='validation')","326323e7":"test_data = test_img_gen.flow_from_directory(directory='..\/input\/intel-image-classification\/seg_test\/seg_test', target_size=(150, 150), batch_size=1, class_mode='binary', shuffle=False)","0e78a45d":"class_labels = train_data.class_indices\nclass_labels","a30b4c84":"base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(150, 150, 3))","8c1a79bc":"base_model.trainable=False","5a2b6067":"out_incep = base_model.output","1e4116af":"gavpooling = tf.keras.layers.GlobalAveragePooling2D()(out_incep)","4426ef76":"d1 = tf.keras.layers.Dense(units = 64, activation = 'relu')(gavpooling)","c2dbf225":"output = tf.keras.layers.Dense(units = 6, activation = 'softmax')(d1)","2e9373b6":"model = tf.keras.models.Model(base_model.input, output)","be95c6b5":"model.summary()","13c0246d":"model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), \n              loss=tf.keras.losses.sparse_categorical_crossentropy,\n              metrics=tf.keras.metrics.sparse_categorical_accuracy)","73155498":"train_data.reset()\nhistory = model.fit(x=train_data, epochs=5, validation_data=valid_data)","e0731883":"# Training Loss and Validation Loss versus Epochs plot. At 5 epochs validation loss almost reaches plateau\/flattens.\nplt.plot([1,2,3,4,5], history.history['loss'], 'bo--', label='Train Loss')\nplt.plot([1,2,3,4,5], history.history['val_loss'], 'ro--', label='Val Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","33627246":"# Training Accuracy and Validation Accuracy versus Epochs plot. At 5 epochs validation accuracy almost reaches plateau\/flattens.\nplt.plot([1,2,3,4,5], history.history['sparse_categorical_accuracy'], 'bo--', label='Train Accuracy')\nplt.plot([1,2,3,4,5], history.history['val_sparse_categorical_accuracy'], 'ro--', label='Val Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","6cdf7f86":"# Accuracy aghieved on the Test Data is better than the Validation and it is very close to the Training accuracy\ntest_data.reset()\neval_loss, eval_metrics = model.evaluate(test_data)","01edd064":"# Printing the Classification Report on Test Data\ntest_data.reset()\npreds = model.predict(test_data)\ntest_preds = np.argmax(preds, axis=1)\nprint(classification_report(test_data.classes, test_preds, target_names=test_data.class_indices.keys()))","141c8218":"# Printing the Confusion Matrix on Test Data\ncm = confusion_matrix(test_data.classes, test_preds)\nsn.heatmap(cm, annot=True, cmap='Blues', xticklabels=test_data.class_indices.keys(), yticklabels=test_data.class_indices.keys())\nplt.show()","14fcc3e6":"# # Based on above results on Test Data it is evident that the model has most of the errors in the \n# Between 'Buildings' and 'Streets'\n# Between 'Glacier' and 'Mountain'\n# Between 'Glacier' and 'Sea'","3f5e0d65":"# Dict to capture the labels and their text names\nlabels_dict = {0: 'buildings',\n 1: 'forest',\n 2: 'glacier',\n 3: 'mountain',\n 4: 'sea',\n 5: 'street'}","c5b4e85b":"# To investigate the mismatched classes in more detail, we will open the images which got incorrect predictions\n# function takes input the names of actual class and predicted class\ndef show_missclassified (actual_classname, predicted_classname, test_inputdata, test_predictions):\n\n    count = 0\n    filepaths = []\n\n    for i in range(test_inputdata.classes.shape[0]):\n        if labels_dict.get(test_inputdata.classes[i]) == actual_classname and labels_dict.get(test_predictions[i]) == predicted_classname:\n            count +=1\n            filepaths.append(test_inputdata.filepaths[i])\n\n    \n    test_images = []\n    for p in filepaths:\n        img = load_img(path=p, grayscale=False, target_size=(150, 150))\n        img = img_to_array(img, data_format='channels_last')\n        img = img \/ 255.\n        test_images.append(img)\n    test_images = np.array(test_images)\n\n    print('Actual Class: {0},  Predicted Class: {1}'.format(actual_classname, predicted_classname))\n    print('Number of missclassified images: {}'.format(count))\n    \n    if count > 0:\n        ncols = 7 if count > 7 else count\n        nrows = int(count\/ncols)+1\n        fig, ax = plt.subplots(nrows=nrows,ncols=ncols, figsize=(15,15))\n\n\n        img_count = 0\n        for i in range(nrows):\n            for j in range(ncols):\n                if img_count < count:\n                    ax[i,j].imshow(test_images[img_count], cmap=plt.cm.binary)\n                    ax[i,j].set_title('pred = '+predicted_classname)\n                    ax[i,j].axis('off')\n                    img_count +=1\n        plt.show()\n    return","e33ca1bc":"# To see the images with Actual Class Label: street,  Predicted Class Label: buildings\nshow_missclassified('street', 'buildings', test_data, test_preds)","f6b5ed7a":"# To see the another example of images with Actual Class Label: glacier,  Predicted Class Label: mountain\nshow_missclassified('glacier', 'mountain', test_data, test_preds)","6e874809":"# Loading the prediction folder images\npred_img_paths = glob.glob(pathname='..\/input\/intel-image-classification\/seg_pred\/seg_pred'+'\/*.jpg')\npred_images = []\nfor p in pred_img_paths:\n    img = load_img(path=p, grayscale=False, target_size=(150, 150))\n    img = img_to_array(img, data_format='channels_last')\n    img = img \/ 255.\n    pred_images.append(img)\npred_images = np.array(pred_images)","a56ba528":"# Loaded input shape\npred_images.shape","24b02040":"# Capture the file names of the images in the Pred folder\npred_file_names = [tf.strings.split(i, sep='\/')[-1].numpy() for i in pred_img_paths]","3e7c42d4":"# Predict the classes for the input images\npred_results = model.predict(pred_images, batch_size=1)","27aca2c4":"# Plot sample results from the predictions.  Format = Predicted Class Name (File Name)\nnrows = 7\nncols = 10\nfig, ax = plt.subplots(nrows=nrows,ncols=ncols, figsize=(30,20))\n\nimg_start = 6000\nimg_count = 0\nfor i in range(nrows):\n    for j in range(ncols):\n        ax[i,j].imshow(pred_images[img_start + img_count], cmap=plt.cm.binary)\n        ax[i,j].axis('off')\n        ax[i,j].set_title(labels_dict.get(np.argmax(pred_results[img_start + img_count]))+' ('+str(pred_file_names[img_start + img_count])+')')\n        img_count +=1\nplt.show()","af3301cf":"# As evident from the misclassified images, many of them do contain Mountains in the images. Possibly causing the model to predict them as class = 'mountain'.","ef04e829":"# Inference on Pred folder images (which are un-labelled)","f80b83f6":"# As evident from the misclassified images,  they do contain Buildings in the images. Possibly causing the model to predict them as class = 'buildings'.","612582cd":"# Transfer Learning from InceptionV3"}}