{"cell_type":{"9f77d1f1":"code","405b8b57":"code","4027c593":"code","325b3f91":"code","cd455974":"code","1d4720a8":"code","0389b050":"code","2c8d8889":"code","2bb2b545":"code","0ed5ec82":"code","cfae857a":"code","546173ed":"code","715617e7":"code","a5e3580e":"code","4cd9e52e":"code","628cb589":"code","d878d636":"code","663e018d":"code","ff1c26b8":"code","76fb3891":"code","963594b9":"code","ba3a8bb2":"code","ab7842ac":"code","6c3913bd":"code","503c0a30":"code","43308bb3":"code","0a1fea83":"code","acc6224e":"markdown","92223f34":"markdown","a48f877c":"markdown","386bee0d":"markdown","a06c3185":"markdown","5c195d88":"markdown","7c4669b5":"markdown","c94cb433":"markdown","df86d2ed":"markdown","155f82a7":"markdown"},"source":{"9f77d1f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","405b8b57":"import plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly\nplotly.offline.init_notebook_mode() # For not show up chart error\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n%matplotlib inline\n\nfrom tqdm import tqdm\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","4027c593":"pd.set_option('mode.chained_assignment', None)\ntest = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/train.csv\")\ntrain['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])","325b3f91":"# Fix error in train data\n\ntrain[['ConfirmedCases', 'Fatalities']] = train.groupby(['Country_Region', 'Province_State'])[['ConfirmedCases', 'Fatalities']].transform('cummax') \n","cd455974":"from sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\nfeature_day = [1,2,5,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n    #for country in ['Japan']:\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n            df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n            df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n            X_train = CreateInput(df_train)\n            y_train_confirmed = df_train['ConfirmedCases'].ravel()\n            y_train_fatalities = df_train['Fatalities'].ravel()\n            X_pred = CreateInput(df_test)\n\n            # Define feature to use by X_pred\n            feature_use = X_pred.columns[0]\n            for i in range(X_pred.shape[1] - 1,0,-1):\n                if (X_pred.iloc[0,i] > 0):\n                    feature_use = X_pred.columns[i]\n                    break\n            idx = X_train[X_train[feature_use] == 0].shape[0]          \n            adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n            adjusted_y_train_confirmed = y_train_confirmed[idx:]\n            adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n              \n            adjusted_X_pred = X_pred[feature_use].values.reshape(-1, 1)\n\n            model = make_pipeline(PolynomialFeatures(2), BayesianRidge())\n            model.fit(adjusted_X_train,adjusted_y_train_confirmed)                \n            y_hat_confirmed = model.predict(adjusted_X_pred)\n\n            model.fit(adjusted_X_train,adjusted_y_train_fatalities)                \n            y_hat_fatalities = model.predict(adjusted_X_pred)\n\n            pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n            pred_data['ConfirmedCases_hat'] = y_hat_confirmed\n            pred_data['Fatalities_hat'] = y_hat_fatalities\n            pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\n    \ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\n\ndf_val_1 = df_val.copy()","1d4720a8":"RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)","0389b050":"RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)","2c8d8889":"val_score = []\nfor country in df_val['Country_Region'].unique():\n    df_val_country = df_val[(df_val['Country_Region'] == country) & (df_val['Fatalities'].isnull() == False)]\n    val_score.append([country, RMSLE(df_val_country['ConfirmedCases'].values,df_val_country['ConfirmedCases_hat'].values),RMSLE(df_val_country['Fatalities'].values,df_val_country['Fatalities_hat'].values)])\n    \ndf_val_score = pd.DataFrame(val_score) \ndf_val_score.columns = ['Country','ConfirmedCases_Scored','Fatalities_Scored']\ndf_val_score.sort_values('ConfirmedCases_Scored', ascending = False)","2bb2b545":"country = \"Vietnam\"\ndf_val = df_val_1\ndf_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()","0ed5ec82":"country = \"Vietnam\"\ndf_val = df_val_1\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\ndf_train = train[(train['Country_Region'].isin(df_country['Country_Region'].unique())) & (train['ConfirmedCases'] > 0)].groupby(['Date']).sum().reset_index()\n\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Forecast Total Cases of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_train['Date'], y=df_train['ConfirmedCases'], mode='lines', name=\"Actual train\", showlegend=True)\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual test\", showlegend=True)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Forecast Total Fatalities of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_train['Date'], y=df_train['Fatalities'], mode='lines', name=\"Actual train\", showlegend=True)\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual test\", showlegend=True)\n\nfig.show()","cfae857a":"df_total = df_val.groupby(['Date']).sum().reset_index()\ndf_train = train[(train['Country_Region'].isin(df_val['Country_Region'].unique())) & (train['ConfirmedCases'] > 0)].groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World Forecast')\nfig.add_scatter(x=df_train['Date'], y=df_train['ConfirmedCases'], mode='lines', name=\"Actual train\", showlegend=True)\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual test\", showlegend=True)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World Forecast')\nfig.add_scatter(x=df_train['Date'], y=df_train['Fatalities'], mode='lines', name=\"Actual train\", showlegend=True)\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual test\", showlegend=True)\nfig.show()","546173ed":"df_now = train.groupby(['Date','Country_Region']).sum().sort_values(['Country_Region','Date']).reset_index()\ndf_now['New Cases'] = df_now['ConfirmedCases'].diff()\ndf_now['New Fatalities'] = df_now['Fatalities'].diff()\ndf_now = df_now.groupby('Country_Region').apply(lambda group: group.iloc[-1:]).reset_index(drop = True)\n\nfig = go.Figure()\nfor country in df_now.sort_values('ConfirmedCases', ascending=False).head(5)['Country_Region'].values:\n    df_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\n    idx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\n    fig.add_trace(go.Scatter(x=df_country['Date'][0:idx],y= df_country['ConfirmedCases'][0:idx], name = country))\n    fig.add_trace(go.Scatter(x=df_country['Date'],y= df_country['ConfirmedCases_hat'], name = country + ' forecast'))\nfig.update_layout(title_text='Top 5 ConfirmedCases forecast')\nfig.show()\n\nfig = go.Figure()\nfor country in df_now.sort_values('Fatalities', ascending=False).head(5)['Country_Region'].values:\n    df_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\n    idx = df_country[((df_country['Fatalities'].isnull() == False) & (df_country['Fatalities'] > 0))].shape[0]\n    fig.add_trace(go.Scatter(x=df_country['Date'][0:idx],y= df_country['Fatalities'][0:idx], name = country))\n    fig.add_trace(go.Scatter(x=df_country['Date'],y= df_country['Fatalities_hat'], name = country + ' forecast'))\nfig.update_layout(title_text='Top 5 Fatalities forecast')\nfig.show()","715617e7":"df_now = df_now.sort_values('ConfirmedCases', ascending = False)\nfig = make_subplots(rows = 2, cols = 2)\nfig.add_bar(x=df_now['Country_Region'].head(10), y = df_now['ConfirmedCases'].head(10), row=1, col=1, name = 'Total cases')\ndf_now = df_now.sort_values('Fatalities', ascending=False)\nfig.add_bar(x=df_now['Country_Region'].head(10), y = df_now['Fatalities'].head(10), row=1, col=2, name = 'Total Fatalities')\n\n\ndf_now = df_now.sort_values('New Cases', ascending=False)\nfig.add_bar(x=df_now['Country_Region'].head(10), y = df_now['New Cases'].head(10), row=2, col=1, name = 'New Cases')\ndf_now = df_now.sort_values('New Fatalities', ascending=False)\nfig.add_bar(x=df_now['Country_Region'].head(10), y = df_now['New Fatalities'].head(10), row=2, col=2, name = 'New Fatalities')\n\nfig.update_layout({'title_text':'Top 10 Country','legend_orientation':'h','legend_y':1.1,'legend_yanchor':'auto'})","a5e3580e":"def update(frame):    \n    fdata = df_country[df_country['Date'] <= frame].groupby('Country_Region').apply(lambda group: group.iloc[-1:])\n    fdata = fdata.sort_values(by = 'ConfirmedCases', ascending = False).head(20)\n    fdata = fdata.sort_values(by = 'ConfirmedCases', ascending = True)\n    xdata = fdata['Country_Region']\n    ydata = fdata['ConfirmedCases']\n    ax.clear()\n    time_unit_displayed = 'Top confirmed case forecast - ' + frame.strftime(\"%Y-%m-%d\")\n    ax.text(0, 1.06, 'History and forecast animation: from ' + frDate.strftime(\"%Y-%m-%d\") + \" to \" + toDate.strftime(\"%Y-%m-%d\"), transform = ax.transAxes, color = '#666666',\n            size = 12, ha = 'left', va = 'center', weight = 'bold')    \n    ax.text(0, 1.02, time_unit_displayed, transform = ax.transAxes, color = '#666666',\n            size = 10, ha = 'left', va = 'center', weight = 'bold')\n    #colors = list(map(lambda x:mapcolor(x),fdata['Change']))\n    colors = plt.get_cmap('PuRd')(np.linspace(0.15, 0.85, fdata.shape[0]))\n    ax.barh(xdata, ydata, color = colors, tick_label = fdata['Country_Region'])\n    num_of_elements = len(xdata)\n    dx = float(fdata['ConfirmedCases'].max()) \/ 200\n    for i, (name, value, change) in enumerate(zip(fdata['Country_Region'],fdata['ConfirmedCases'],fdata['Fatalities'])):\n        #ax.text(amount + dx, i, \" ({:.2f}%)\".format(change), size = 8, ha = 'left', va = 'center', color = '#666666')\n        ax.text(value, i, name, size=8, weight=600, ha='left', va='bottom', color = '#666666')\n        ax.text(value, i-.25, f'{value:,.0f}',  size=8, ha='left',  va='center', color = '#666666')\n    \ndf_country = train.groupby(['Date','Country_Region']).sum().reset_index()\ndf_future = df_val_1[df_val_1['ConfirmedCases'].isnull() == True].groupby(['Date','Country_Region']).sum()\ndf_future = df_future.reset_index()[['Date','Country_Region','ConfirmedCases_hat','Fatalities_hat']]\ndf_future.columns = ['Date','Country_Region','ConfirmedCases','Fatalities']\n\ndf_country = pd.concat([df_country,df_future], ignore_index=True, sort=True)\n\nfig, ax = plt.subplots(figsize=(15, 8))\nfrDate =  df_country['Date'].min()\ntoDate =  df_country['Date'].max()\nanimator = animation.FuncAnimation(fig, update, frames=pd.date_range(frDate, toDate).tolist(), interval=500)\nHTML(animator.to_jshtml())","4cd9e52e":"animator.save('confirm_animation.gif', writer='imagemagick', fps=2)\nfrom IPython.display import Image, display\ndisplay(Image(url='confirm_animation.gif'))","628cb589":"import warnings\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nfeature_day = [1,2,5,20,50,100,200,500,1000]\n\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n    #for country in ['Vietnam']:\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\")\n                df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n                df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                X_train = CreateInput(df_train)\n                y_train_confirmed = df_train['ConfirmedCases'].ravel()\n                y_train_fatalities = df_train['Fatalities'].ravel()\n                X_pred = CreateInput(df_test)\n\n                # Define feature to use by X_pred\n                feature_use = X_pred.columns[0]\n                for i in range(X_pred.shape[1] - 1,0,-1):\n                    if (X_pred.iloc[0,i] > 0):\n                        feature_use = X_pred.columns[i]\n                        break\n                idx = X_train[X_train[feature_use] == 0].shape[0]   \n\n                adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n                adjusted_y_train_confirmed = y_train_confirmed[idx:]\n                adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n\n                pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n                min_test_date = pred_data['Date'].min()\n                #The number of day forcast\n                #pred_data[pred_data['Date'] > max_train_date].shape[0]\n                #model = SimpleExpSmoothing(adjusted_y_train_confirmed).fit()\n                #model = Holt(adjusted_y_train_confirmed).fit()\n                #model = Holt(adjusted_y_train_confirmed, exponential=True).fit()\n                #model = Holt(adjusted_y_train_confirmed, exponential=True, damped=True).fit()\n\n                model = ExponentialSmoothing(adjusted_y_train_confirmed, trend = 'additive').fit()\n                y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n                y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n\n                #model = Holt(adjusted_y_train_fatalities).fit()\n\n                model = ExponentialSmoothing(adjusted_y_train_fatalities, trend = 'additive').fit()\n                y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n                y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n\n\n                pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n                pred_data['Fatalities_hat'] = y_hat_fatalities\n                pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_2 = df_val.copy()","d878d636":"country = \"Vietnam\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","663e018d":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","ff1c26b8":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima_model import ARIMA\n\nfeature_day = [1,2,5,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n    #for country in ['Vietnam']:\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\")\n                df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n                df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                X_train = CreateInput(df_train)\n                y_train_confirmed = df_train['ConfirmedCases'].ravel()\n                y_train_fatalities = df_train['Fatalities'].ravel()\n                X_pred = CreateInput(df_test)\n\n                feature_use = X_pred.columns[0]\n                for i in range(X_pred.shape[1] - 1,0,-1):\n                    if (X_pred.iloc[0,i] > 0):\n                        feature_use = X_pred.columns[i]\n                        break\n                idx = X_train[X_train[feature_use] == 0].shape[0] \n\n                adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n                adjusted_y_train_confirmed = y_train_confirmed[idx:]\n                adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n                idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n                adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n\n                pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n                min_test_date = pred_data['Date'].min()\n                model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0), \n                                #seasonal_order=(1,1,0,12),\n                                measurement_error=True).fit(disp=False)\n                y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n                y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n                model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0), \n                                #seasonal_order=(1,1,0,12),\n                                measurement_error=True).fit(disp=False)\n                y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n                y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n                pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n                pred_data['Fatalities_hat'] = y_hat_fatalities\n                pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_3 = df_val.copy()","76fb3891":"country = \"Vietnam\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","963594b9":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","ba3a8bb2":"[df_val_1.shape,df_val_2.shape,df_val_3.shape]","ab7842ac":"method_list = ['Poly Bayesian Ridge','Exponential Smoothing','SARIMA']\nmethod_val = [df_val_1,df_val_2,df_val_3]\nfor i in range(0,3):\n    df_val = method_val[i]\n    method_score = [method_list[i]] + [RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)] + [RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)]\n    print (method_score)","6c3913bd":"df_val = df_val_3\ndf_val['ConfirmedCases_hat'] = (df_val_1['ConfirmedCases_hat'] + df_val_2['ConfirmedCases_hat'] + df_val_3['ConfirmedCases_hat'])\/3\ndf_val['Fatalities_hat'] = (df_val_1['Fatalities_hat'] + df_val_2['Fatalities_hat'] + df_val_3['Fatalities_hat'])\/3\nsubmission = df_val[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission = submission.round({'ConfirmedCases': 0, 'Fatalities': 0})\nsubmission.to_csv('submission.csv', index=False)\nsubmission","503c0a30":"import requests\nfrom bs4 import BeautifulSoup\n\nreq = requests.get('https:\/\/www.worldometers.info\/coronavirus\/')\nsoup = BeautifulSoup(req.text, \"lxml\")\n\ndf_country = soup.find('div',attrs={\"id\" : \"nav-tabContent\"}).find('table',attrs={\"id\" : \"main_table_countries_today\"}).find_all('tr')\narrCountry = []\nfor i in range(1,len(df_country)-1):\n    tmp = df_country[i].find_all('td')\n    if (tmp[0].string.find('<a') == -1):\n        country = [tmp[0].string]\n    else:\n        country = [tmp[0].a.string] # Country\n    for j in range(1,7):\n        if (str(tmp[j].string) == 'None' or str(tmp[j].string) == ' '):\n            country = country + [0]\n        else:\n            country = country + [float(tmp[j].string.replace(',','').replace('+',''))]\n    arrCountry.append(country)\ndf_worldinfor = pd.DataFrame(arrCountry)\ndf_worldinfor.columns = ['Country','Total Cases','Cases','Total Deaths','Deaths','Total Recovers','Active Case']\nfor i in range(0,len(df_worldinfor)):\n    df_worldinfor['Country'].iloc[i] = df_worldinfor['Country'].iloc[i].strip()","43308bb3":"fig = px.bar(df_worldinfor.sort_values('Total Cases', ascending=False)[:10][::-1], \n             x='Total Cases', y='Country',\n             title='Total Cases Worldwide', text='Total Cases', orientation='h')\nfig.show()\n\nfig = px.bar(df_worldinfor.sort_values('Cases', ascending=False)[:10][::-1], \n             x='Cases', y='Country',\n             title='New Cases Worldwide', text='Cases', orientation='h')\nfig.show()\n\nfig = px.bar(df_worldinfor.sort_values('Active Case', ascending=False)[:10][::-1], \n             x='Active Case', y='Country',\n             title='Active Cases Worldwide', text='Active Case', orientation='h')\nfig.show()","0a1fea83":"df_worldinfor[df_worldinfor['Country'] == 'Vietnam']","acc6224e":"## Holt and ExponentialSmoothing","92223f34":"## History and forecast animation for top 20 country","a48f877c":"# Alternative version","386bee0d":"## Submission","a06c3185":"## Visualization","5c195d88":"## Prepare","7c4669b5":"## SARIMA","c94cb433":"## Evaluation","df86d2ed":"# Worldmeter Infor update\nBecause data update one time per day. I update lastest information from worldometers for reference only","155f82a7":"## Forecast with BayesianRidge"}}