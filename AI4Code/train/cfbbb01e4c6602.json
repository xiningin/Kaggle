{"cell_type":{"bbf5888a":"code","ee5554ec":"code","c35f214d":"code","7095d28e":"code","2e52c05b":"code","5c0c7daf":"code","572cfe67":"code","548a4ab4":"code","294425a1":"code","52beed57":"code","c22e5aeb":"code","bacb729a":"code","b47af61b":"code","3f11b96f":"code","93ae3de5":"code","d7657713":"code","af8f20cf":"code","cfc07fa2":"code","c601a940":"code","5e67f9fa":"code","1cc9944e":"code","7225dd4e":"code","884f0a0d":"code","7527495f":"code","c7fc8654":"code","a822d9d3":"code","33ce29b4":"code","dd157075":"code","2b64062d":"code","ad7e6be3":"code","6e079400":"code","86644c16":"code","2871f838":"code","4135e901":"code","14d14786":"code","e1700498":"code","9c2a863f":"code","308e3b22":"code","4231fd8c":"code","d7c0e3a4":"code","11fa4061":"code","0b5f96a7":"code","55131d27":"code","20e8b3a8":"code","de94577b":"code","9fc1d802":"code","131114fb":"code","a84e74a9":"code","19509eb0":"code","cccf2f6e":"code","46356ecf":"code","53c53109":"code","4836cce5":"code","fe06e335":"code","db87ed7f":"code","1572026e":"code","016e49a6":"code","c9093d07":"code","2be2e635":"code","5b8956db":"code","c3a8472b":"code","f5a45d0c":"code","2719c320":"code","cfb9d5a8":"code","9d877d64":"code","c870811d":"markdown","1852ad66":"markdown","190a6ff5":"markdown","66019a1d":"markdown"},"source":{"bbf5888a":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport ast\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee5554ec":"df_train = pd.read_csv('..\/input\/amexpert-2021-challenge\/train_go05W65.csv',\n                       converters={'Product_Holding_B1':ast.literal_eval, 'Product_Holding_B2':ast.literal_eval})","c35f214d":"df_train.head()","7095d28e":"df_test = pd.read_csv('..\/input\/amexpert-2021-challenge\/test_VkM91FT.csv',\n                       converters={'Product_Holding_B1':ast.literal_eval})","2e52c05b":"df_test.head()","5c0c7daf":"df_train['is_train']=1\ndf_test['is_train'] = 0","572cfe67":"df = pd.concat([df_train, df_test])","548a4ab4":"df.head()","294425a1":"df.info()","52beed57":"df.describe()","c22e5aeb":"def get_unique_values_from_list_col(df, col):\n    local_df=df[col]\n    products = []\n    for item in local_df:\n        unique_cols = np.unique(item)\n        for col in unique_cols:\n            if col not in products:\n                products.append(col)\n    return products","bacb729a":"def apply_transformation(row, col, prod_list, prefix):\n    if row['is_train']==0 and prefix=='B2_':\n        return row\n    \n    for item in prod_list:\n        if item in row[col]:\n            row[prefix+item] = 1\n    return row","b47af61b":"prod_list = get_unique_values_from_list_col(df, 'Product_Holding_B1')\nb1_prod_list = ['B1_'+item for item in prod_list]\nfor item in b1_prod_list:\n    df[item]= 0\n    \ndf = df.apply(apply_transformation, col='Product_Holding_B1',prod_list=prod_list, prefix='B1_',axis=1)","3f11b96f":"prod_list_b2 = get_unique_values_from_list_col(df, 'Product_Holding_B2')\nprod_list_b2 = [item for item in prod_list_b2 if str(item)!='nan']\nb2_prod_list = ['B2_'+item for item in prod_list_b2 ]\n \nfor item in b2_prod_list:\n    df[item]= 0","93ae3de5":"df.columns","d7657713":"df = df.apply(apply_transformation, col='Product_Holding_B2',prod_list=prod_list_b2, prefix='B2_', axis=1)","af8f20cf":"df.head()","cfc07fa2":"df['current_holdings'] = df['Product_Holding_B1'].apply(lambda x: len(x))","c601a940":"df = df.drop(columns = ['Product_Holding_B1','Product_Holding_B2'])","5e67f9fa":"df[df['is_train'] == 1].to_csv('.\/train_data.csv', index=False)\ndf[df['is_train'] == 0].to_csv('.\/test_data.csv', index=False)","1cc9944e":"df.describe(())","7225dd4e":"import xgboost as xgb\nimport pandas as pd","884f0a0d":"df_train = pd.read_csv('.\/train_data.csv')\ndf_test = pd.read_csv('.\/test_data.csv')","7527495f":"cat_cols = ['Gender', 'Is_Active', 'City_Category','Customer_Category']\ncols_to_drop = ['Customer_ID','is_train']","c7fc8654":"B1_cols = [col for col in list(df_train.columns) if col.startswith('B1')]","a822d9d3":"B2_cols = [col for col in list(df_train.columns) if col.startswith('B2')]","33ce29b4":"cat_cols = B1_cols + cat_cols\ntarget_cols = B2_cols","dd157075":"df_train = df_train.drop(columns = cols_to_drop)","2b64062d":"df_train.head()","ad7e6be3":"df_test = df_test.drop(columns = cols_to_drop)","6e079400":"df_test.head()","86644c16":"from sklearn.model_selection import train_test_split","2871f838":"X_train = df_train.drop(columns = target_cols)\ny_train = df_train[target_cols]","4135e901":"for cols in y_train.columns:\n    print(cols)\n    print(y_train[cols].unique())","14d14786":"#train_one_fold_y\nX_train['Gender'] = X_train['Gender'].astype('category')\nX_train['City_Category'] = X_train['City_Category'].astype('category')\nX_train['Customer_Category'] = X_train['Customer_Category'].astype('category')\ncat_cols2 = ['Gender','City_Category','Customer_Category']\nX_train[cat_cols2] = X_train[cat_cols2].apply(lambda x: x.cat.codes)","e1700498":"X_train.head()","9c2a863f":"from sklearn.multioutput import MultiOutputClassifier\nimport catboost\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport lightgbm as lgb\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom xgboost.sklearn import XGBClassifier\n#from sklearn import cross_validation, metrics\n#from sklearn.grid_search import GridSearchCV\n#classifier = MultiOutputClassifier(catboost.CatBoostClassifier(verbose=0)) #Rank -> 3\n#classifier = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=3))  #Rank -> 4\nclassifier = MultiOutputClassifier(xgb.XGBClassifier(learning_rate =0.01, #0.1->0.01\n        n_estimators=2000, #1000->10000\n        max_depth=5,\n        min_child_weight=1,\n        gamma=0,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        nthread=4,\n        #num_boost_round = 999,\n       eval_metric = 'mae',\n        #objective= 'multi:softprob',                                           \n        scale_pos_weight=1,\n        seed=42)) #Rank -> 1\n#classifier = MultiOutputClassifier(MLPClassifier(random_state=42, max_iter=500)) #Rank -> 2\n#classifier = MultiOutputClassifier(lgb.LGBMClassifier()) \n#classifier = MultiOutputClassifier(QuadraticDiscriminantAnalysis())\nclassifier = MultiOutputClassifier(xgb.XGBClassifier())","308e3b22":"#train_one_fold_x.columns\n#from fast_ml.model_development import train_valid_test_split\n\n#train_one_fold_x, valid_one_fold_x , train_one_fold_y, valid_one_fold_y = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n                                                                                           #stratify=y_train)\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.20, shuffle=False)","4231fd8c":"#cat_cols","d7c0e3a4":"#X_train.head()","11fa4061":"#y_train.head()","0b5f96a7":"#X_train[cat_cols].apply(lambda x: x.astype('category'))","55131d27":"#X_train.info()","20e8b3a8":"#X_train[cat_cols] = X_train[cat_cols].apply(lambda x: x.cat.codes)","de94577b":"#X_train.head()","9fc1d802":"#X_train.to_csv('.\/check_train_data.csv',index=False)","131114fb":"X_train.head()","a84e74a9":"#check = classifier.fit(X_train, y_train, cat_features=[0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27])\nclassifier.fit(X_train2, y_train2)#,eval_set=[(X_test2, y_test2)])","19509eb0":"#valid_one_fold_x['Gender'] = valid_one_fold_x['Gender'].astype('category')\n#valid_one_fold_x['City_Category'] = valid_one_fold_x['City_Category'].astype('category')\n#valid_one_fold_x['Customer_Category'] = valid_one_fold_x['Customer_Category'].astype('category')\n\n#valid_one_fold_x[cat_cols2] = valid_one_fold_x[cat_cols2].apply(lambda x: x.cat.codes)","cccf2f6e":"#print(classifier.score(valid_one_fold_x, valid_one_fold_y))\n#print(classifier.score(X_test2,y_test2))","46356ecf":"df_test['Gender'] = df_test['Gender'].astype('category')\ndf_test['City_Category'] = df_test['City_Category'].astype('category')\ndf_test['Customer_Category'] = df_test['Customer_Category'].astype('category')\n\ndf_test[cat_cols2] = df_test[cat_cols2].apply(lambda x: x.cat.codes)","53c53109":"df_test.head()","4836cce5":"X_test = df_test.drop(columns = target_cols)","fe06e335":"X_test.head()","db87ed7f":"preds = classifier.predict_proba(X_test)\n#preds = cart6.predict_proba(df_test)","1572026e":"preds_cal = []\nfor item in preds:\n    preds_cal.append( [local_item[1] for local_item in item] )","016e49a6":"df_catboost = pd.DataFrame(np.array(preds_cal).T, columns=B2_cols)","c9093d07":"df_catboost.to_csv('.\/catboost_preds.csv', index=False)","2be2e635":"df = pd.read_csv('..\/input\/amexpert-2021-challenge\/test_VkM91FT.csv')","5b8956db":"df_cat = pd.read_csv('.\/catboost_preds.csv')","c3a8472b":"df = pd.concat([df, df_cat], axis=1)","f5a45d0c":"total_cols = [col for col in df.columns if col.startswith('B2_')]","2719c320":"def get_labels(row):\n    labels = []\n    max_val = -1\n    max_label = ''\n    label_dict = {}\n    for col in total_cols:\n        if row[col] > max_val:\n            max_val = row[col]\n            max_label = col.split('_')[-1] \n\n        if row[col] > 0.5:\n            labels.append(col.split('_')[-1])\n            label_dict[col.split('_')[-1]] = row[col]\n    \n    if len(labels) == 0:\n        labels.append(max_label)\n        \n    if len(labels) > 3:\n        sorted_dict = dict(sorted(label_dict.items(), key=lambda item: item[1], reverse=True))\n        print(sorted_dict)\n        labels = []\n        labels.extend(list(sorted_dict.keys())[0:3])\n        \n    return str(labels)","cfb9d5a8":"df['Product_Holding_B2'] = df.apply( get_labels, axis=1 )","9d877d64":"df[['Customer_ID', 'Product_Holding_B2']].to_csv('.\/submission_catboost.csv', index=False)","c870811d":"from sklearn.datasets import make_regression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import VotingRegressor\n# define dataset\n#X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n# define the base models\nmodels = list()\nmodels.append(('cart1', MultiOutputClassifier(DecisionTreeClassifier(max_depth=1))))\nmodels.append(('cart2', MultiOutputClassifier(DecisionTreeClassifier(max_depth=2))))\nmodels.append(('cart3', MultiOutputClassifier(DecisionTreeClassifier(max_depth=3))))\nmodels.append(('cart4', MultiOutputClassifier(DecisionTreeClassifier(max_depth=4))))\nmodels.append(('cart5', MultiOutputClassifier(DecisionTreeClassifier(max_depth=5))))\nmodels.append(('cart6', MultiOutputClassifier(DecisionTreeClassifier(max_depth=6))))\n#models.append(('cart6', MultiOutputClassifier(catboost.CatBoostClassifier(verbose=0))))\n# define the voting ensemble\n#ensemble = VotingClassifier(estimators=models)\n# fit the model on all available data\ncart6 = MultiOutputClassifier(DecisionTreeClassifier(max_depth=6))\ncart6.fit(X_train, y_train)\n# make a prediction for one example\n#data = [[0.59332206,-0.56637507,1.34808718,-0.57054047,-0.72480487,1.05648449,0.77744852,0.07361796,0.88398267,2.02843157,1.01902732,0.11227799,0.94218853,0.26741783,0.91458143,-0.72759572,1.08842814,-0.61450942,-0.69387293,1.69169009]]\n\n#print('Predicted Value: %.3f' % (yhat))","1852ad66":"from numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom matplotlib import pyplot\n\n \n# get a voting ensemble of models\ndef get_voting():\n    # define the base models\n    models = list()\n    models.append(('cart1', MultiOutputClassifier(DecisionTreeClassifier(max_depth=1))))\n    models.append(('cart2', MultiOutputClassifier(DecisionTreeClassifier(max_depth=2))))\n    models.append(('cart3', MultiOutputClassifier(DecisionTreeClassifier(max_depth=3))))\n    models.append(('cart4', MultiOutputClassifier(DecisionTreeClassifier(max_depth=4))))\n    models.append(('cart5', MultiOutputClassifier(DecisionTreeClassifier(max_depth=5))))\n    models.append(('cart6', MultiOutputClassifier(DecisionTreeClassifier(max_depth=6))))\n    # define the voting ensemble\n    ensemble = VotingClassifier(estimators=models)\n    return ensemble\n \n# get a list of models to evaluate\ndef get_models():\n    models = dict()\n    models['cart1'] = MultiOutputClassifier(DecisionTreeClassifier(max_depth=1))\n    models['cart2'] = MultiOutputClassifier(DecisionTreeClassifier(max_depth=2))\n    models['cart3'] = MultiOutputClassifier(DecisionTreeClassifier(max_depth=3))\n    models['cart4'] = MultiOutputClassifier(DecisionTreeClassifier(max_depth=4))\n    models['cart5'] = MultiOutputClassifier(DecisionTreeClassifier(max_depth=5))\n    models['cart6'] = MultiOutputClassifier(DecisionTreeClassifier(max_depth=6))\n    models['voting'] = get_voting()\n    return models\n \n# evaluate a give model using cross-validation\ndef evaluate_model(model, X, y):\n    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n                             #error_score='raise')\n    return scores\n \n# define dataset\n#X, y = get_dataset()\n# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model, X_train, y_train)\n    results.append(scores)\n    names.append(name)\n    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n# plot model performance for comparison\npyplot.boxplot(results, labels=names, showmeans=True)\npyplot.show()","190a6ff5":"cv_results = xgb.cv(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    seed=42,\n    nfold=5,\n    metrics={'mae'},\n    early_stopping_rounds=10\n)","66019a1d":"## All credit of this notebook goes to @harveenchadha for sharing his code in github repository"}}