{"cell_type":{"719090c0":"code","6694fd18":"code","72531785":"code","3fcd697f":"code","c00fda63":"code","744b4eb5":"code","c65184f5":"code","54f63120":"markdown","34a33a2a":"markdown","d87645c9":"markdown","48ebee30":"markdown","931f4f40":"markdown","b0011b0a":"markdown","e9229e1d":"markdown"},"source":{"719090c0":"import random\nimport itertools\nimport copy\nimport json\n\nimport numpy\nimport pylab\nimport torch\n\nfrom torchvision import transforms","6694fd18":"class StimuliDataset(torch.utils.data.Dataset):\n    \"\"\"\n    A synthetic dataset with generated trajectories of different sized squares where\n    the final generated videos could be labelled in a few simple trajectory categories\n    like \"middle-sized square moving to the right\", \"small square moving upwards\", etc.\n\n    The trajectories remain straight lines and the squares move along them linearly.\n\n    For convenience we first create movies with double width and height\n    and at the end we select a window.\n\n    Original source: \"Next-frame prediction with Conv-LSTM\" by Keras authors.\n    \"\"\"\n    def __init__(self, frames=15, width=40, height=40, channels=1,\n                 squares_min=1, squares_max=1, size_min=1, size_max=2,\n                 subsample=1.0, filename=\"\", add_noise=False, transform=None):\n        super(StimuliDataset, self).__init__()\n\n        self.frames = frames\n        self.width = width\n        self.height = height\n        self.channels = channels\n\n        self.square_number_range = (squares_min, squares_max+1)\n        self.square_size_range = (size_min, size_max+1)\n\n        x_range = int(self.width \/ 4), int(self.width * 3 \/ 4)\n        y_range = int(self.height \/ 4), int(self.height * 3 \/ 4)\n\n        if filename == \"\":\n            square_states = []\n            for s in range(*self.square_size_range):\n                for dx in (-1, 0, 1):\n                    for dy in (-1, 0, 1):\n                        for x0 in range(*x_range):\n                            for y0 in range(*y_range):\n                                square_states.append((s, dx, dy, x0, y0))\n\n            self._idefs = []\n            for squares in range(*self.square_number_range):\n                self._idefs += [i for i in itertools.product(square_states, repeat=squares)]\n\n            if subsample < 1.0:\n                sample_count = int(subsample * len(self._idefs))\n                self._idefs = random.sample(self._idefs, sample_count)\n        else:\n            self.load_from_file(filename)\n\n        self.add_noise = add_noise\n        self.transform = transform\n\n    def __len__(self):\n        return len(self._idefs)\n\n    def __getitem__(self, i):\n        row, col = 2 * self.height, 2 * self.width\n        x_range = int(self.width \/ 2), int(self.width + self.width \/ 2)\n        y_range = int(self.height \/ 2), int(self.height + self.height \/ 2)\n        frames = numpy.zeros((self.frames, row, col, self.channels), dtype=numpy.float)\n\n        # Generate the frames of moving squares\n        label = 0\n        for j in range(len(self._idefs[i])):\n            s, dx, dy, x0, y0 = self._idefs[i][j]\n            # Calculate the label from the number of squares, square sizes, and directions\n            label += (self.classes_per_square ** j) * (dx + 1 + 3 * (dy + 1) + 9 * (s - self.square_size_range[0]))\n\n            for t in range(self.frames):\n                xt = x_range[0] + x0 + dx * t\n                yt = y_range[0] + y0 + dy * t\n                frames[t, max(yt - s, 0): max(yt + s, 0), max(xt - s, 0): max(xt + s, 0), :] += 1\n\n                # Improve robustness by adding noise\n                if self.add_noise:\n                    if numpy.random.randint(0, 2):\n                        # Generate random sign (-1, 0, +1) for the perturbation\n                        noise_f = (-1)**numpy.random.randint(0, 2)\n                        frames[t, max(yt - s - 1, 0): max(yt + s + 1, 0), max(xt - s - 1, 0): max(xt + s + 1, 0), 0] += noise_f * 0.1\n\n        # Cut to the final movie window\n        frames = frames[::, y_range[0]:y_range[1], x_range[0]:x_range[1], ::]\n        frames[frames >= 1] = 1\n\n        frames = torch.Tensor(frames)\n        if self.transform:\n            frames = self.transform(frames)\n\n        return frames, label\n\n    def __sub__(self, dataset):\n        diff = copy.copy(self)\n        diff._idefs = list(set(self._idefs) - set(dataset._idefs))\n        return diff\n\n    @property\n    def classes_per_square(self):\n        \"\"\"Calculate the number of available classes per square.\"\"\"\n        return 3 * 3 * (self.square_size_range[1] - self.square_size_range[0])\n\n    @property\n    def classes(self):\n        \"\"\"Calculate the number of available classes in total.\"\"\"\n        return self.classes_per_square ** (self.square_number_range[1] - self.square_number_range[0])\n\n    def load_from_file(self, filename):\n        \"\"\"\n        Load the dataset from a file.\n\n        :param str filename: file name to load from\n        \"\"\"\n        with open(filename, \"r\") as f:\n            self._idefs = json.load(f)\n        # resture notion of tuples to be able to set-subtract\n        for i in range(len(self._idefs)):\n            self._idefs[i] = tuple(tuple(self._idefs[i][j]) for j in range(len(self._idefs[i])))\n\n        width, height = max([i[0][3] for i in self._idefs]) + 1, max([i[0][4] for i in self._idefs]) + 1\n        assert self.width == int(numpy.ceil(width + width \/ 3))\n        assert self.height == int(numpy.ceil(height + height \/ 3))\n\n        squares_min, squares_max = len(min(self._idefs, key=lambda x: len(x))), len(max(self._idefs, key=lambda x: len(x)))\n        size_min, size_max = min([i[0] for i in self._idefs])[0], max([i[0] for i in self._idefs])[0]\n        self.square_number_range = (squares_min, squares_max+1)\n        self.square_size_range = (size_min, size_max+1)\n\n    def save_to_file(self, filename):\n        \"\"\"\n        Save the dataset to a file.\n\n        :param str filename: file name to load from\n        \"\"\"\n        with open(filename, \"w\") as f:\n            json.dump(self._idefs, f)\n\n    def summary(self, train=False):\n        \"\"\"\n        Print a summary of the loaded dataset.\n\n        :param bool train: whether the dataset is a train set or test set\n        \"\"\"\n        print()\n        print(f\"Total number of {'train' if train else 'test'} samples: {len(self)}\")\n        print(f\"Total number of classes: {self.classes}\")\n        print(f\"Video shape (frames, width, height, channels): {self.frames}x{self.width}x{self.height}x{self.channels}\")\n        print(f\"Number of squares: from {self.square_number_range[0]} to {self.square_number_range[1]-1}\")\n        print(f\"Size of squares: from {self.square_size_range[0]} to {self.square_size_range[1]-1}\")\n        print()","72531785":"batch_size, test_percentage = 10, 0.3\nframes, width, height, channels = 5, 40, 30, 1\nsquares_min, squares_max = 1, 1\nsize_min, size_max = 1, 2","3fcd697f":"tfs = transforms.Compose([\n        # provide three identical channels for grayscale RGB\n        transforms.Lambda(lambda x: torch.cat((x, x, x), -1)),\n        # reshape into (T, C, H, W) for easier convolutions\n        transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n])","c00fda63":"train_dataset = StimuliDataset(frames, width, height, channels,\n                               filename=\"\/kaggle\/input\/cognitive-stimuli\/stimuli_train324.json\",\n                               transform=tfs)\ntest_dataset = StimuliDataset(frames, width, height, channels,\n                              filename=\"\/kaggle\/input\/cognitive-stimuli\/stimuli_test324.json\",\n                              transform=tfs)\n\ntrain_dataset.summary(train=True)\ntest_dataset.summary(train=False)","744b4eb5":"%matplotlib inline\n    \ndef visualize(batch, train=False):\n    \"\"\"\n    Dump sample clip frames into image files.\n\n    :param batch: visualized dataset loader\n    :type batch: :py:class:`torch.Tensor`\n    :param bool train: whether the batch is from a train set or test set\n    \"\"\"\n    train_prefix = \"Train\" if train else \"Test\"\n    x, y = batch\n    for n in range(x.shape[0]):\n        for t in range(x.shape[1]):\n            fig = pylab.figure(figsize=(5, 5))\n\n            pylab.title(f'{train_prefix} trajectory {y[n]} for batch {n+1} at time {t+1}', fontsize=10)\n            pylab.imshow(x[n, t, 0, ::, ::], cmap='gray', vmin=0, vmax=1)\n            pylab.show()\n\n            pylab.close(fig)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nfor batch in train_loader:\n    visualize(batch, train=True)\n    break\nfor batch in test_loader:\n    visualize(batch)\n    break","c65184f5":"total_dataset = StimuliDataset(frames, width, height, channels,\n                               squares_min, squares_max, size_min, size_max)\ntest_dataset = StimuliDataset(frames, width, height, channels,\n                              squares_min, squares_max, size_min, size_max,\n                              test_percentage)\n\ntrain_dataset = total_dataset - test_dataset\nassert train_dataset.classes == test_dataset.classes\n\ntrain_dataset.save_to_file(\"stimuli_train.json\")\ntest_dataset.save_to_file(\"stimuli_test.json\")","54f63120":"Let's look at the first training (random) and testing (fixed) batch and visualize some of the moving bright regions.","34a33a2a":"Load the train and test datasets and summarize them.","d87645c9":"We start with the imports of the packages we will need, among which are some default python packages as well as `numpy`, `pylab`, and `torch`. We keep the imports minimal and without renames.","48ebee30":"Optionally, we could completely regenerate the dataset and store it to a file with a unique train-test split.","931f4f40":"Now let us define the stimuli dataset which could both generate a new dataset given a combination of constructor parameters or it could be loaded from a JSON file. There is a lot to unwrap in this class but here we will only use it to initialize from data already stored in a file.","b0011b0a":"Let's inititialize all variables determining the final dataset, the variable names speak for themselves.","e9229e1d":"Define any preprocessing, required for the dataset in order to be used for model training."}}