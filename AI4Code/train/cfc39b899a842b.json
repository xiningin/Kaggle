{"cell_type":{"40d55218":"code","d7bc65f5":"code","8241a8c0":"code","8f77c293":"code","f32b9f43":"code","2d12bcb1":"code","aaf44db4":"code","30d5075e":"code","7c988b72":"code","eab5bcb9":"code","34292cfb":"code","2c48e38a":"code","bb753197":"code","427745c8":"code","42a7367d":"code","bf0e7157":"code","03e1794b":"code","10496d7a":"code","4a6a7dd6":"code","3bd341a8":"code","783272bf":"code","fd654585":"code","764f788d":"code","8f05185f":"code","6f529745":"code","a3ecb063":"code","9c3f307b":"code","c1bff93e":"code","15888002":"code","7b5d1613":"code","0f0910ea":"code","7fdf88de":"code","f1b714a6":"code","234bc3a8":"code","fcdf617b":"code","f043a7ca":"code","cce720ae":"code","b0da5625":"code","fd068a02":"code","5986008b":"code","0e14e0b8":"code","ec8d7b5f":"code","190565c1":"code","b9aae5ca":"code","d652d21d":"code","959cd78a":"code","0f5b9075":"code","f7a00618":"code","b5fd4223":"code","5bc80fa2":"code","290de28c":"code","1bba9b38":"markdown","d3790dbf":"markdown","bbcd9f0b":"markdown","d392fc67":"markdown","cc483804":"markdown","1c1c1aec":"markdown","e6d9179c":"markdown","c5a53407":"markdown","9e1dab2e":"markdown","7ec905e4":"markdown","9e860100":"markdown","d18fe03f":"markdown","c8171867":"markdown","a9f83690":"markdown","9ae3cdcd":"markdown","6fe02ed4":"markdown","865983b2":"markdown","b952e6dd":"markdown","70467b32":"markdown","b25b88e6":"markdown","f0c6039a":"markdown","4b60ce91":"markdown","f0f0530a":"markdown","cf6f5ae7":"markdown","5092e4a5":"markdown","69f331b3":"markdown","71c34915":"markdown","ae50dd56":"markdown","5ee26503":"markdown","8ca6a201":"markdown","dcd2970a":"markdown","70419f84":"markdown"},"source":{"40d55218":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7bc65f5":"h = pd.read_csv(\"..\/input\/big-mart-sale-forecast\/train.csv\")","8241a8c0":"h.shape","8f77c293":"h.head()","f32b9f43":"h.dtypes","2d12bcb1":"h[\"Item_Fat_Content\"].value_counts()","aaf44db4":"h[\"Item_Fat_Content\"] = h[\"Item_Fat_Content\"].str.replace(\"LF\", \"Low Fat\")\nh[\"Item_Fat_Content\"] = h[\"Item_Fat_Content\"].str.replace(\"low fat\", \"Low Fat\")\nh[\"Item_Fat_Content\"] = h[\"Item_Fat_Content\"].str.replace(\"reg\", \"Regular\")","30d5075e":"h[\"Item_Fat_Content\"].value_counts()","7c988b72":"sns.countplot('Item_Fat_Content', data=h, palette='deep')\n\nplt.show()","eab5bcb9":"h[\"Item_Type\"].value_counts()","34292cfb":"g = sns.factorplot(\"Item_Type\", data=h, aspect=1.5, kind=\"count\", color=\"r\")\ng.set_xticklabels(rotation=90)","2c48e38a":"len(h[\"Outlet_Identifier\"].unique())","bb753197":"h[\"Outlet_Size\"].value_counts()","427745c8":"sns.countplot('Outlet_Size', data=h, palette='rocket')\n\nplt.show()","42a7367d":"h[\"Outlet_Location_Type\"].value_counts()","bf0e7157":"sns.countplot('Outlet_Location_Type', data=h, palette='Set3')\n\nplt.show()","03e1794b":"numbers = list(h.select_dtypes(['float64', 'int64']).keys())\nnumbers.remove('Outlet_Establishment_Year')","10496d7a":"h[numbers].hist(figsize=(20,10), color='green', edgecolor='white')\n\nplt.show()\n\ndisplay(h[numbers].describe())","4a6a7dd6":"sns.boxplot(x=h[\"Item_Weight\"])","3bd341a8":"sns.boxplot(x=h[\"Item_Visibility\"])","783272bf":"sns.boxplot(x=h[\"Item_MRP\"])","fd654585":"h[\"Outlet_Size\"].value_counts()","764f788d":"h[\"Outlet_Size\"] = h[\"Outlet_Size\"].replace(\"Medium\", 2)\nh[\"Outlet_Size\"] = h[\"Outlet_Size\"].replace(\"Small\", 1)\nh[\"Outlet_Size\"] = h[\"Outlet_Size\"].replace(\"High\", 3)","8f05185f":"h[\"Outlet_Size\"].value_counts()","6f529745":"h[\"Outlet_Location_Type\"].value_counts()","a3ecb063":"h[\"Outlet_Location_Type\"] = h[\"Outlet_Location_Type\"].replace(\"Tier 1\", 1)\nh[\"Outlet_Location_Type\"] = h[\"Outlet_Location_Type\"].replace(\"Tier 2\", 2)\nh[\"Outlet_Location_Type\"] = h[\"Outlet_Location_Type\"].replace(\"Tier 3\", 3)","9c3f307b":"h.head()","c1bff93e":"h[\"Item_Fat_Content\"].value_counts()","15888002":"h[\"Item_Fat_Content\"] = h[\"Item_Fat_Content\"].replace(\"Low Fat\", 1)\nh[\"Item_Fat_Content\"] = h[\"Item_Fat_Content\"].replace(\"Regular\", 2)","7b5d1613":"h.head()","0f0910ea":"h[\"Item_Type\"].value_counts()","7fdf88de":"h = pd.concat([h, pd.get_dummies(h.Item_Type, prefix = 'Item_Type') ] , axis = 1)\nh.head()","f1b714a6":"h = h.drop(['Item_Type'], axis=1)\n","234bc3a8":"h.head()","fcdf617b":"h = pd.concat( [h, pd.get_dummies(h.Outlet_Type, prefix = 'Outlet_Type') ] , axis = 1)\nh.head()","f043a7ca":"h = h.drop(['Outlet_Type'], axis=1)","cce720ae":"h.head()","b0da5625":"h = h.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1)","fd068a02":"h.head()","5986008b":"h.isnull().sum()","0e14e0b8":"#u = h[[\"Item_Weight\", \"Item_Visibility\", \"Item_MRP\", \"Outlet_Establishment_Year\", \"Item_Outlet_Sales\"]]\n#df.drop(['B', 'C'], axis=1)\n\n\n\nimputer = KNNImputer(n_neighbors=5)\nprint(imputer.fit_transform(h))\nDF = pd.DataFrame(imputer.fit_transform(h), columns = h.columns) # We assing the new dataset with no missing values in DF\n#h[\"Item_Weight\"] = u[\"Item_Weight\"]","ec8d7b5f":"DF.isnull().sum()","190565c1":"target_col = \"Item_Outlet_Sales\"\nX = DF.loc[:, DF.columns != target_col]\ny = DF.loc[:, target_col]","b9aae5ca":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","d652d21d":"\nout_list = []\nfor column in X_train.columns:\n    corr_tuple = pearsonr(X_train[column], y_train)\n    out_list.append([column, corr_tuple[0], corr_tuple[1]])\ncorr_df = pd.DataFrame(out_list, columns=[\"Features\", \"Correlation\", \"P-Value\"])\ncorr_df.sort_values(by=['P-Value'], inplace=True)\ncorr_df.head()","959cd78a":"X_train = X_train[[\"Item_MRP\", \"Outlet_Type_Grocery Store\", \"Outlet_Type_Supermarket Type3\", \"Item_Visibility\", \"Outlet_Type_Supermarket Type1\"]]\nX_train.head()","0f5b9075":"X_test = X_test[[\"Item_MRP\", \"Outlet_Type_Grocery Store\", \"Outlet_Type_Supermarket Type3\", \"Item_Visibility\", \"Outlet_Type_Supermarket Type1\"]]\nX_test.head()","f7a00618":"\nregressor = LinearRegression()  \nregressor.fit(X_train, y_train)\n#To retrieve the intercept:\nprint(regressor.intercept_)\n\n#For retrieving the slope:\nprint(regressor.coef_)","b5fd4223":"y_pred = regressor.predict(X_test)","5bc80fa2":"coeffecients = pd.DataFrame(regressor.coef_,X_test.columns)\ncoeffecients.columns = ['Coeffecient']\ncoeffecients","290de28c":"from sklearn import metric\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","1bba9b38":"Above are the features that are the most important for our dataset. Now we only keep theses predictor variables to train and test the model. ","d3790dbf":"From the above we concur that the least number of stores are in tier 1 regions, after that the least number of stores are in tier 2 region. Most of the stores are in tier 3 region. ","bbcd9f0b":"We split the datset into X and y. X consists of the predictor variables and y is the value we are trying to predict. In the below code, we are trying to split the values for the purpose of training and evaluating the model. ","d392fc67":"We observe that there Low Fat value is common for most items. ","cc483804":"Let us find out the numerical proportion of the categorical types in Outlet locations.","1c1c1aec":"We observe that 'Fruits and Vegetables' and 'Snack Foods' are the most commonly occuring item types. 'Seafood' and 'Breakfast' are the least commonly ocuring item types. ","e6d9179c":"We observe that the lightest item is 4.55 and the heaviest item is 21.35. While the middle 50% of the items are from 8.77 to 16.85. The median weight of an item is 12.60.  ","c5a53407":"We observe that this variable too can be considered an ordinal variable. ","9e1dab2e":"Having applied one hot encoding to the item type variable. We drop the column. ","7ec905e4":"We observe that this variable is a categorical variable with many values. So we perform one hot encoding. ","9e860100":"It's evident from the countplot above that small and medium are sizes of most of the outlets. A minority of the outlets are high sized. ","d18fe03f":"Now we load the csv file. ","c8171867":"We observe there are no missing values in the new dataset. ","a9f83690":"We finally look at the missing values.","9ae3cdcd":"Above is the intercept and the co-efficient of the different predictor variables. ","6fe02ed4":"Now we drop the Item Identifier and Outlet Identifier variables as they are of no use to use in any sense. They are constructs that won't help us in prediction. ","865983b2":"Let's inspect how many rows and columns the dataset has. ","b952e6dd":"Above is the plot of *Item_Visibility*. It displays the % of total display area of all products in a store allocated to the particular product. While the least visible products have no visibility at all and the most visible products is 0.33. The middle 50% of the products are between 0.03 and 0.09. The median visibility of an item is 0.05. Most products don't have much visibility. ","70467b32":"We observe that our attempt has been successful. ","b25b88e6":"Above are the co-efficients of the different predictor variables in a tabular format. \n\nFrom the above table we can conclude that when the MRP of an item is increased by 1 unit then the sales of that product in a particular store increases by 15.67 units provided all other variables are kept constant. Also, if the product is in the outlet type of a grocery store then it's sales goes down by -1644.72 provided all other variables are kept constant. However, if the oulet type is supermarket type 3 then the sales of a particular product goes up by 1681.63 provided all other variables are kept constant. If the outlet type is supermarket type 1 then the sales a particular product goes up by 310.79 provided all the other variables are kept constant. If the item visibility is improved by one unit then the sales of a particular product in a store goes down by -340.03 provided all other variables remain constant. ","f0c6039a":"We observe that two variables *Item_Weight* and *Outlet_Size* have missing values. We use K-nearest neighbours algorithm to cluster datapoints and impute missing values. ","4b60ce91":"We observe that the outlet size is an ordinal variable. We replace Small with 1, Medium with 2 and High with 3. ","f0f0530a":"Let's examine the data types of variables in the dataset. ","cf6f5ae7":"Let's find out the number of outlet's that are involved in this dataset. ","5092e4a5":"We observe that outlet location type too is an ordinal variable. So we replace Tier 1, Tier 2 and Tier 3 with 1, 2 and 3 respectively. ","69f331b3":"We observe that the LF and low fat refer to Low Fat while Regular and reg both refer to the same fat content. So we fix this. ","71c34915":"From the above we observe that the RMSE of the prediction conducted by the model is 1137.11.  ","ae50dd56":"Now we apply one hot encoding to the outlet type variable. ","5ee26503":"Now we inspect the first few entries of the dataset. ","8ca6a201":"Above is the boxlot of *Item_MRP*. MRP stands for maximum retail price of a item. Cheapest item is worth 31.29 and the most expensive item is worth 266.89. The median worth of an item is 143.01 and the middle 50% of the items are worth 93.84 to 185.65. ","dcd2970a":"Our dataset has a lot of features(columns). We would like to narrow down the number of features so as to make our findings more intuitive and easily understandable. ","70419f84":"We find out the numerical distribution of the size of the outlets."}}