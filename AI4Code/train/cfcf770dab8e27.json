{"cell_type":{"2358ea9f":"code","8cf2603d":"code","6b59c19e":"code","777e7b6f":"code","66d97a51":"code","e328c269":"code","0a867f42":"code","b5b7c546":"code","817ecf2c":"code","e2da98e7":"code","7a65778d":"code","fe0d60cd":"code","f92d942a":"code","f7193fb4":"code","3e638599":"code","5ded238f":"code","27855769":"code","f5c963fd":"code","d556b2b3":"markdown","e0fbffcd":"markdown","16d68c4f":"markdown","b2f00d6e":"markdown","8d69b59b":"markdown","aa1c1e4d":"markdown","031610d6":"markdown","a25d3793":"markdown","77c74fdf":"markdown","2a7e0039":"markdown","fba3c8d5":"markdown","48e9a157":"markdown","5048d121":"markdown","5cfa9436":"markdown"},"source":{"2358ea9f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport librosa\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport IPython.display as ipd\n\n# Any results you write to the current directory are saved as output.","8cf2603d":"meta = pd.read_csv(\"..\/input\/train_curated.csv\",sep=\",\")\nmeta.head()","6b59c19e":"meta.shape","777e7b6f":"meta.labels.value_counts()","66d97a51":"labels = meta.labels.str.split(\",\",expand=True)\nlabels.head()","e328c269":"labels_onehot = pd.get_dummies(labels.loc[:,0])","0a867f42":"labels_onehot.shape","b5b7c546":"for i in range(1, labels.shape[1]):\n    for lab in labels.loc[:,i].unique():\n        if lab is not None:\n            if not lab in list(labels_onehot):\n                print(lab)\n                labels_onehot[lab] = 0\n            labels_onehot.loc[labels.loc[:,i]==lab,lab] = 1","817ecf2c":"labels_onehot[[\"Strum\",\"Water_tap_and_faucet\"]].sum(axis=0)","e2da98e7":"labels_onehot.sum(axis=0)","7a65778d":"plt.figure(figsize=(15,15))\nplt.matshow(labels_onehot.corr(),fignum=1)\nplt.xticks(range(len(labels_onehot.columns)), labels_onehot.columns, rotation='vertical');\nplt.yticks(range(len(labels_onehot.columns)), labels_onehot.columns);\nplt.show()","fe0d60cd":"meta.loc[labels_onehot.Electric_guitar == 1,\"fname\"].head()","f92d942a":"ipd.Audio(wavfile.read(\"..\/input\/train_curated\/03730245.wav\")[1], rate=44100)","f7193fb4":"sampling, audio = wavfile.read(\"..\/input\/train_curated\/03730245.wav\")","3e638599":"plt.figure(figsize = (20,5))\nplt.plot(audio)\nplt.annotate(\"Attack\",(2500,8000),(0,25000), arrowprops = {\"arrowstyle\":\"->\"})\nplt.annotate(\"Beginning of note\",(20000,-20000),(30000,-25000), arrowprops = {\"arrowstyle\":\"->\"})\nplt.annotate(\"Muting\",(90000,-5000),(90000,-25000), arrowprops = {\"arrowstyle\":\"->\"})\n","5ded238f":"y, sr = librosa.load(\"..\/input\/train_curated\/03730245.wav\")\nmel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\nmel_spec.shape","27855769":"# since specshow does not seem to work from librosa library, just copying it from : https:\/\/github.com\/librosa\/librosa\/blob\/master\/librosa\/display.py\nfrom matplotlib.cm import get_cmap\nfrom matplotlib.axes import Axes\nfrom matplotlib.ticker import Formatter, ScalarFormatter\nfrom matplotlib.ticker import LogLocator, FixedLocator, MaxNLocator\nfrom matplotlib.ticker import SymmetricalLogLocator\n\ndef specshow(data, x_coords=None, y_coords=None,\n             x_axis=None, y_axis=None,\n             sr=22050, hop_length=512,\n             fmin=None, fmax=None,\n             bins_per_octave=12,\n             ax=None,\n            **kwargs):\n    if np.issubdtype(data.dtype, np.complexfloating):\n        warnings.warn('Trying to display complex-valued input. '\n                      'Showing magnitude instead.')\n        data = np.abs(data)\n    kwargs.setdefault('cmap', cmap(data))\n    kwargs.setdefault('rasterized', True)\n    kwargs.setdefault('edgecolors', 'None')\n    kwargs.setdefault('shading', 'flat')\n    all_params = dict(kwargs=kwargs,\n                      sr=sr,\n                      fmin=fmin,\n                      fmax=fmax,\n                      bins_per_octave=bins_per_octave,\n                      hop_length=hop_length)\n    # Get the x and y coordinates\n    y_coords = __mesh_coords(y_axis, y_coords, data.shape[0], **all_params)\n    x_coords = __mesh_coords(x_axis, x_coords, data.shape[1], **all_params)\n    axes = __check_axes(ax)\n    out = axes.pcolormesh(x_coords, y_coords, data, **kwargs)\n    __set_current_image(ax, out)\n    axes.set_xlim(x_coords.min(), x_coords.max())\n    axes.set_ylim(y_coords.min(), y_coords.max())\n    # Set up axis scaling\n    __scale_axes(axes, x_axis, 'x')\n    __scale_axes(axes, y_axis, 'y')\n    # Construct tickers and locators\n    __decorate_axis(axes.xaxis, x_axis)\n    __decorate_axis(axes.yaxis, y_axis)\n    return axes\n\ndef __set_current_image(ax, img):\n    plt.sci(img)\n\n    \ndef __mesh_coords(ax_type, coords, n, **kwargs):\n    if coords is not None:\n        if len(coords) < n:\n            raise ParameterError('Coordinate shape mismatch: '\n                                 '{}<{}'.format(len(coords), n))\n        return coords\n\n    coord_map = {\n                 'mel': __coord_mel_hz,\n                 None: __coord_n}\n\n    if ax_type not in coord_map:\n        raise ParameterError('Unknown axis type: {}'.format(ax_type))\n    return coord_map[ax_type](n, **kwargs)\n\n\ndef __check_axes(axes):\n    '''Check if \"axes\" is an instance of an axis object. If not, use `gca`.'''\n    if axes is None:\n        import matplotlib.pyplot as plt\n        axes = plt.gca()\n    elif not isinstance(axes, Axes):\n        raise ValueError(\"`axes` must be an instance of matplotlib.axes.Axes. \"\n                         \"Found type(axes)={}\".format(type(axes)))\n    return axes\n\n\ndef __scale_axes(axes, ax_type, which):\n    '''Set the axis scaling'''\n\n    kwargs = dict()\n    if which == 'x':\n        thresh = 'linthreshx'\n        base = 'basex'\n        scale = 'linscalex'\n        scaler = axes.set_xscale\n        limit = axes.set_xlim\n    else:\n        thresh = 'linthreshy'\n        base = 'basey'\n        scale = 'linscaley'\n        scaler = axes.set_yscale\n        limit = axes.set_ylim\n\n    # Map ticker scales\n    if ax_type == 'mel':\n        mode = 'symlog'\n        kwargs[thresh] = 1000.0\n        kwargs[base] = 2\n\n    elif ax_type == 'log':\n        mode = 'symlog'\n        kwargs[base] = 2\n        kwargs[thresh] = core.note_to_hz('C2')\n        kwargs[scale] = 0.5\n\n    elif ax_type in ['cqt', 'cqt_hz', 'cqt_note']:\n        mode = 'log'\n        kwargs[base] = 2\n\n    elif ax_type == 'tempo':\n        mode = 'log'\n        kwargs[base] = 2\n        limit(16, 480)\n    else:\n        return\n\n    scaler(mode, **kwargs)\n\n\ndef __decorate_axis(axis, ax_type):\n    '''Configure axis tickers, locators, and labels'''\n\n    if ax_type == 'tonnetz':\n        axis.set_major_formatter(TonnetzFormatter())\n        axis.set_major_locator(FixedLocator(0.5 + np.arange(6)))\n        axis.set_label_text('Tonnetz')\n\n    elif ax_type == 'chroma':\n        axis.set_major_formatter(ChromaFormatter())\n        axis.set_major_locator(FixedLocator(0.5 +\n                                            np.add.outer(12 * np.arange(10),\n                                                         [0, 2, 4, 5, 7, 9, 11]).ravel()))\n        axis.set_label_text('Pitch class')\n\n    elif ax_type == 'tempo':\n        axis.set_major_formatter(ScalarFormatter())\n        axis.set_major_locator(LogLocator(base=2.0))\n        axis.set_label_text('BPM')\n\n    elif ax_type == 'time':\n        axis.set_major_formatter(TimeFormatter(unit=None, lag=False))\n        axis.set_major_locator(MaxNLocator(prune=None,\n                                           steps=[1, 1.5, 5, 6, 10]))\n        axis.set_label_text('Time')\n\n    elif ax_type == 's':\n        axis.set_major_formatter(TimeFormatter(unit='s', lag=False))\n        axis.set_major_locator(MaxNLocator(prune=None,\n                                           steps=[1, 1.5, 5, 6, 10]))\n        axis.set_label_text('Time (s)')\n\n    elif ax_type == 'ms':\n        axis.set_major_formatter(TimeFormatter(unit='ms', lag=False))\n        axis.set_major_locator(MaxNLocator(prune=None,\n                                           steps=[1, 1.5, 5, 6, 10]))\n        axis.set_label_text('Time (ms)')\n\n    elif ax_type == 'lag':\n        axis.set_major_formatter(TimeFormatter(unit=None, lag=True))\n        axis.set_major_locator(MaxNLocator(prune=None,\n                                           steps=[1, 1.5, 5, 6, 10]))\n        axis.set_label_text('Lag')\n\n    elif ax_type == 'lag_s':\n        axis.set_major_formatter(TimeFormatter(unit='s', lag=True))\n        axis.set_major_locator(MaxNLocator(prune=None,\n                                           steps=[1, 1.5, 5, 6, 10]))\n        axis.set_label_text('Lag (s)')\n\n    elif ax_type == 'lag_ms':\n        axis.set_major_formatter(TimeFormatter(unit='ms', lag=True))\n        axis.set_major_locator(MaxNLocator(prune=None,\n                                           steps=[1, 1.5, 5, 6, 10]))\n        axis.set_label_text('Lag (ms)')\n\n    elif ax_type == 'cqt_note':\n        axis.set_major_formatter(NoteFormatter())\n        axis.set_major_locator(LogLocator(base=2.0))\n        axis.set_minor_formatter(NoteFormatter(major=False))\n        axis.set_minor_locator(LogLocator(base=2.0,\n                                          subs=2.0**(np.arange(1, 12)\/12.0)))\n        axis.set_label_text('Note')\n\n    elif ax_type in ['cqt_hz']:\n        axis.set_major_formatter(LogHzFormatter())\n        axis.set_major_locator(LogLocator(base=2.0))\n        axis.set_minor_formatter(LogHzFormatter(major=False))\n        axis.set_minor_locator(LogLocator(base=2.0,\n                                          subs=2.0**(np.arange(1, 12)\/12.0)))\n        axis.set_label_text('Hz')\n\n    elif ax_type in ['mel', 'log']:\n        axis.set_major_formatter(ScalarFormatter())\n        axis.set_major_locator(SymmetricalLogLocator(axis.get_transform()))\n        axis.set_label_text('Hz')\n\n    elif ax_type in ['linear', 'hz']:\n        axis.set_major_formatter(ScalarFormatter())\n        axis.set_label_text('Hz')\n\n    elif ax_type in ['frames']:\n        axis.set_label_text('Frames')\n\n    elif ax_type in ['off', 'none', None]:\n        axis.set_label_text('')\n        axis.set_ticks([])\n\n\ndef __coord_fft_hz(n, sr=22050, **_kwargs):\n    n_fft = 2 * (n - 1)\n    # The following code centers the FFT bins at their frequencies\n    # and clips to the non-negative frequency range [0, nyquist]\n    basis = core.fft_frequencies(sr=sr, n_fft=n_fft)\n    fmax = basis[-1]\n    basis -= 0.5 * (basis[1] - basis[0])\n    basis = np.append(np.maximum(0, basis), [fmax])\n    return basis\n\n\ndef __coord_mel_hz(n, fmin=0, fmax=11025.0, **_kwargs):\n    '''Get the frequencies for Mel bins'''\n\n    if fmin is None:\n        fmin = 0\n    if fmax is None:\n        fmax = 11025.0\n    basis = librosa.mel_frequencies(n, fmin=fmin, fmax=fmax)\n    basis[1:] -= 0.5 * np.diff(basis)\n    basis = np.append(np.maximum(0, basis), [fmax])\n    return basis\n\ndef cmap(data, robust=True, cmap_seq='magma', cmap_bool='gray_r', cmap_div='coolwarm'):\n    data = np.atleast_1d(data)\n\n    if data.dtype == 'bool':\n        return get_cmap(cmap_bool)\n\n    data = data[np.isfinite(data)]\n\n    if robust:\n        min_p, max_p = 2, 98\n    else:\n        min_p, max_p = 0, 100\n\n    max_val = np.percentile(data, max_p)\n    min_val = np.percentile(data, min_p)\n\n    if min_val >= 0 or max_val <= 0:\n        return get_cmap(cmap_seq)\n\n    return get_cmap(cmap_div)\n\ndef __coord_n(n, **_kwargs):\n    '''Get bare positions'''\n    return np.arange(n+1)","f5c963fd":"\nD = librosa.amplitude_to_db(mel_spec, ref=np.max)\nplt.figure(figsize=(10,10))\nspecshow(D, x_coords=None, y_coords=None,\n             x_axis=None, y_axis=\"mel\",\n             sr=sr, hop_length=512,\n             fmin=None, fmax=None,\n             bins_per_octave=12,\n             ax=None\n            )","d556b2b3":"So each of them appear 75 times, but they always appear with at least one other label. Given the first letter, we can assume that the labels are sorted by alphabetical order when there are multiple labels in a sample.","e0fbffcd":"Two labels had never been seen before: *Strum* & *Water_tap_and_faucet*. How often do they appear?","16d68c4f":"At most 5 different labels can appear in a single audio file. Let's do one-hot encoding of each sample:","b2f00d6e":"Each sound seems to be almost evenly distributed with ~ 70 samples of each label (with many having exactly 75 samples)\nWhat are the co-labels?","8d69b59b":"Since this is music, let's listen to it!","aa1c1e4d":"# Summary\n\nHere are the two things I wanted to share:\n1. [Labels](#labels) : What are the labels in this competitions and how they are related to one another\n2. [Music](#music) : How musical scales work and an example of analysis on sample from electric guitare","031610d6":"Multiclasses are not random, only a little number of classes co-occur like crows cheering and applauding or strum and acoustic guitar. This makes sense as you would not expect a computer keyboard sound in the middle of a car race!","a25d3793":"Since this is pretty messy (oscillations cannot be observed easily on this plot), let's swith to a spectrogram representation.","77c74fdf":"# Music\n\nI've been passionate about music, so here is a basic knowledge of how musical scales work nowadays (it changed during time, and it differs between cultures, but it does not matter for this competition).\n\nThe reference key is A (La in french) and has a frequency of 440 Hz. If you want to obtain the same note at a higher pitch (called an octave or scale), you double the frequency. If you want to have a lower pitch you divide the frequency by 2.\n\n## Why is that important?\nExcept for the dial tone (the one you heard when you picked up phones when I was young), no musical instrument is giving you a perfect 440Hz. However, what you get is a combination of this note and its harmonics (octaves). So a musical instrument should have a very clear pattern of doubled frequency.\n\n## How do we go from one note to another?\nThere isn't only a single note in a scale, and once again, the patterns for going between a note and the next one is very codified.\nOnce you have your scale, you divide it in **12 semitones**. As you're good with maths, you'll notice that 12 does not perfectly divide 440Hz, and this is where the magic of music lies: hiding this dissonance somewhere (and this is why scales have changed over time).\n\nLet's see if we can observe these patterns in the data\n\nHere are some curated *Electric_guitar* filenames:","2a7e0039":"We can see the harmonicity here: the base note has highest amplitude, then all harmonics have decreasing amplitudes. \nAlso the attack and muting add noise, as it requires a lot of sinusoidal signals to go from 0 to periodic (and reverse), this is due to the fourier transformation.\n\nFeel free to suggest improvements to this kernel, and if you're interested in musical scales construction I suggest you have a look at this video (which is much more complete than this kernel):\nhttps:\/\/www.youtube.com\/watch?v=cTYvCpLRwao (audio is in french, but there are some english subtitles).","fba3c8d5":"78 categories are available in just the first column (not sure if the order labels appear has any kind of importance).\nNext we:\n- create a column if a label has never been seen before\n- set to 1 the samples where the label is found ","48e9a157":"# Labels\nFirst import and have a look at labels","5048d121":"Some samples can have multiples classes (for example *tap* that goes with *bass_drum*), let's create a dataframe can be easily used for training and for data exploration of the different classes.","5cfa9436":"This is a single note played at quite low resolution (whether because the instruments are bad or the recording microphones or compression...)\n\nWhat does it look like?"}}