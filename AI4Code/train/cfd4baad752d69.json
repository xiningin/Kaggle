{"cell_type":{"c37e6d6e":"code","9770418a":"code","dcaf3f04":"code","6e0a288a":"code","1a16e51a":"code","aafecf42":"code","bc82cad3":"code","44a1b338":"code","79d749de":"code","90f869cd":"code","1999899c":"code","0114eb8b":"code","63e15f81":"code","16356b6b":"code","d57ba8b6":"code","ec209e69":"code","888f7b54":"code","70bab237":"code","b83c0b65":"code","de44b499":"code","c2645e36":"code","976070c5":"code","c98c488c":"code","3ce5e0fb":"code","5814fbe7":"code","deecbfe3":"code","9def9251":"code","feb8afcf":"code","27d774ea":"code","3434c5ed":"code","a11beb69":"code","812f64bc":"code","1d669116":"code","17793f14":"code","27317a9f":"code","cf4823fd":"code","a3f4eaf1":"code","15baa4f5":"code","a1165115":"code","753bc0c6":"code","54a04ebf":"code","55ecfb7f":"code","000c461c":"code","09ad1b7f":"code","790bdbf2":"code","44ed6ea0":"code","8e5acb0e":"code","00f53e24":"code","a987d53f":"code","adc35c02":"code","3b2cba2a":"code","36976fab":"code","a70eb013":"code","af969e32":"code","6b3d1024":"code","84237abf":"code","96960ff6":"code","f43d0d6b":"code","403f648c":"code","15ed602b":"code","69e6dd82":"code","b6d9a084":"code","21a246a0":"code","5fc2f690":"code","a9e7d5ac":"code","3a4a109f":"code","0b2a5a8f":"code","958b4a3b":"code","9605938d":"code","b5a9ae14":"code","938c105f":"code","ca692c33":"code","e06397f9":"code","2143f4d9":"code","c797c8e5":"code","75ef8a34":"code","0b13fe31":"code","1c5b3b1f":"code","9f738499":"code","b15f9174":"code","6e5fc62a":"code","daf3da27":"code","8b273f8c":"code","84e406cb":"code","bd407a43":"code","e206506b":"code","4d9147e0":"code","93512eee":"code","4a7aa2af":"code","2d6c51f1":"code","41312ccb":"code","ffbfcec1":"code","3db3c5ad":"code","335d1e96":"code","5818984a":"code","203f2b49":"code","10daa06c":"code","74ef1a8a":"code","633e964c":"code","19cf114d":"code","80ea17c9":"code","d3b227f2":"code","e5cbd133":"code","f40b8150":"code","e12a2c8f":"code","3cadc4aa":"code","cbe3fca8":"code","439164d5":"code","56dc1c18":"code","474f303c":"code","05565ece":"code","15a52525":"code","2c3e8512":"code","8c1a72cc":"code","bbf75f5b":"code","1310bc84":"code","cad46958":"code","4e2133e2":"code","77ac19dc":"code","f8cb5373":"code","93694d8e":"code","10d6758d":"code","0fd99ec5":"code","a1dfb888":"code","2945ff59":"code","f38aa203":"code","4c7b0d6f":"code","9143853e":"code","a4acd716":"code","587a191c":"code","8a9b18ee":"code","df83cba5":"code","2b0c2766":"code","cf7133bc":"code","da796150":"code","ea4ad71e":"code","7d2c4ada":"code","5e002118":"code","a9a59fd7":"code","7d070c0a":"code","95bd860f":"code","906aa30b":"code","c548a3d3":"code","79d1ead3":"code","f14488ee":"code","f7905336":"code","285f2f66":"markdown","70ffe60c":"markdown","7c33c9d1":"markdown","f0d75020":"markdown","ade73c27":"markdown","bc9c0433":"markdown","11edb85d":"markdown","5602878d":"markdown","9fed2803":"markdown","17b69e50":"markdown","98ac0621":"markdown","f86f160d":"markdown","28e03ec8":"markdown","4fccf3e2":"markdown","3fd2f562":"markdown","1ba8bd77":"markdown","94eb63b5":"markdown","76965699":"markdown","c03d034e":"markdown"},"source":{"c37e6d6e":"! pip install -q kaggle","9770418a":"! mkdir ~\/.kaggle","dcaf3f04":"! cp kaggle.json ~\/.kaggle\/","6e0a288a":"! chmod 600 ~\/.kaggle\/kaggle.json","1a16e51a":"! kaggle datasets list","aafecf42":"! kaggle datasets download -d mlg-ulb\/creditcardfraud","bc82cad3":"! unzip \/content\/creditcardfraud.zip","44a1b338":"from google.colab import files","79d749de":"files.upload()","90f869cd":"! unzip \/content\/creditcardfraud.zip","1999899c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0114eb8b":"df = pd.read_csv(\"\/content\/creditcard.csv\")","63e15f81":"df.head()","16356b6b":"df.describe()","d57ba8b6":"df.isnull().sum()","ec209e69":"count_values = df['Class'].value_counts()\nprint(count_values[0], count_values[1])","888f7b54":"from sklearn.preprocessing import RobustScaler\n\ntransformer = RobustScaler()\ndf['scaled_amount'] = transformer.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = transformer.fit_transform(df['Time'].values.reshape(-1,1))\n\ndf.drop(['Time','Amount'], axis=1, inplace=True)","70bab237":"df.head()","b83c0b65":"x = df.drop(labels = ['Class'], axis = 1)\ny = df['Class']","de44b499":"x.head()","c2645e36":"y.head()","976070c5":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42, stratify = y)","c98c488c":"print(X_train.shape, X_test.shape , y_train.shape , y_test.shape)","3ce5e0fb":"from sklearn.linear_model import LogisticRegression\n\nmodel1 = LogisticRegression(random_state=0).fit(X_train, y_train)\ny1 = model1.predict(X_test)","5814fbe7":"print(y1.sum())","deecbfe3":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y1)","9def9251":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model1, X_test, y_test)  \nplt.show()  ","feb8afcf":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y1, target_names=['Fraud','Non-Fraud']))","27d774ea":"print(y11)","3434c5ed":"# Area Under Curve of Precision Recall\ny11 = model1.predict_proba(X_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision1, recall1, thresholds1 = precision_recall_curve(y_test, y11[:, 1])\nauc_precision_recall = auc(recall1, precision1)\n\nprint(auc_precision_recall)","a11beb69":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\ny_score = model1.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\ndisp = plot_precision_recall_curve(model1, X_test, y_test)\ndisp.ax_.set_title('Logistic  Regression Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","812f64bc":"! pip install scikit-plot","1d669116":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y11)\n\nplt.show()","17793f14":"skplt.metrics.plot_lift_curve(y_test, y11)\nplt.show()","27317a9f":"from sklearn.linear_model import LogisticRegressionCV\nmodel1_1 = LogisticRegressionCV(cv=5, random_state=0).fit(X_train, y_train)\n\ny1_1 = model1_1.predict(X_test)","cf4823fd":"print(y1_1.sum())","a3f4eaf1":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y1_1)","15baa4f5":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model1_1, X_test, y_test)  \nplt.show()  ","a1165115":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y1_1, target_names=['Fraud','Non-Fraud']))","753bc0c6":"# Area Under Curve of Precision Recall\ny1_11 = model1_1.predict_proba(X_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision1_1, recall1_1, thresholds1_1 = precision_recall_curve(y_test, y1_11[:, 1])\nauc_precision_recall = auc(recall1_1, precision1_1)\n\nprint(auc_precision_recall)","54a04ebf":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\ny_score = model1_1.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\ndisp = plot_precision_recall_curve(model1_1, X_test, y_test)\ndisp.ax_.set_title('Logistic  Regression CV Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","55ecfb7f":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y1_11)\n\nplt.show()","000c461c":"skplt.metrics.plot_lift_curve(y_test, y1_11)\nplt.show()","09ad1b7f":"from sklearn.ensemble import RandomForestClassifier\n\nmodel2 = RandomForestClassifier(n_estimators=310, random_state=0).fit(X_train, y_train)\ny2 = model2.predict(X_test)","790bdbf2":"print(y2.sum())","44ed6ea0":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y2)","8e5acb0e":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model2, X_test, y_test)  \nplt.show()  ","00f53e24":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y2, target_names=['Fraud','Non-Fraud']))","a987d53f":"# Area Under Curve of Precision Recall\ny22 = model2.predict_proba(X_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision2, recall2, thresholds2 = precision_recall_curve(y_test, y22[:, 1])\nauc_precision_recall = auc(recall2, precision2)\n\nprint(auc_precision_recall)","adc35c02":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\n#y_score1 = model2.decision_function(X_test)\naverage_precision = 0.88 #average_precision_score(y_test, y_score1)\n\ndisp = plot_precision_recall_curve(model2, X_test, y_test)\ndisp.ax_.set_title('Random Forest Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","3b2cba2a":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y22)\n\nplt.show()","36976fab":"skplt.metrics.plot_lift_curve(y_test, y22)\nplt.show()","a70eb013":"from sklearn.ensemble import GradientBoostingClassifier\n\nmodel3 = GradientBoostingClassifier(n_estimators=961, learning_rate=1.0, max_depth=31, random_state=0).fit(X_train, y_train)\ny3 = model3.predict(X_test)","af969e32":"print(y3.sum())","6b3d1024":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y3)","84237abf":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model3, X_test, y_test)  \nplt.show()  ","96960ff6":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y3, target_names=['Fraud','Non-Fraud']))","f43d0d6b":"# Area Under Curve of Precision Recall\ny33 = model3.predict_proba(X_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision3, recall3, thresholds3 = precision_recall_curve(y_test, y33[:, 1])\nauc_precision_recall = auc(recall3, precision3)\n\nprint(auc_precision_recall)","403f648c":"print(y33[0])","15ed602b":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\ny_score2 = model3.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score2)\n\ndisp = plot_precision_recall_curve(model3, X_test, y_test)\ndisp.ax_.set_title('Gradient Boosting Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","69e6dd82":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y33)\n\nplt.show()","b6d9a084":"skplt.metrics.plot_lift_curve(y_test, y33)\nplt.show()","21a246a0":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import linear_model\n\nlasso_params = {'alpha':[0.02, 0.024, 0.025, 0.026, 0.03]}\nmodel4 = GridSearchCV(linear_model.Lasso(), param_grid=lasso_params).fit(X_train, y_train)\n","5fc2f690":"y4 = model4.predict(X_test)","a9e7d5ac":"for i in y4:\n  print(i)\n","3a4a109f":"print(len(y4))","0b2a5a8f":"print(y4.sum())","958b4a3b":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y4)","9605938d":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model4, X_test, y_test)  \nplt.show()  ","b5a9ae14":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y4, target_names=['Fraud','Non-Fraud']))","938c105f":"# Area Under Curve of Precision Recall\ny44 = model4.predict_proba(X_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision4, recall4, thresholds4 = precision_recall_curve(y_test, y44[:, 1])\nauc_precision_recall = auc(recall4, precision4)\n\nprint(auc_precision_recall)","ca692c33":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\ny_score = model4.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\ndisp = plot_precision_recall_curve(model4, X_test, y_test)\ndisp.ax_.set_title('Logistic  Regression Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","e06397f9":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y44)\n\nplt.show()","2143f4d9":"skplt.metrics.plot_lift_curve(y_test, y44)\nplt.show()","c797c8e5":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import linear_model\n\nridge_params = {'alpha':[200, 230, 250, 265, 270, 275, 290, 300, 500]}\nmodel5 = GridSearchCV(linear_model.RidgeClassifier(), param_grid=ridge_params).fit(X_train, y_train)\n","75ef8a34":"y5 = model5.predict(X_test)","0b13fe31":"print(y5.sum())","1c5b3b1f":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y5)","9f738499":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model5, X_test, y_test)  \nplt.show()  ","b15f9174":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y5, target_names=['Fraud','Non-Fraud']))","6e5fc62a":"# Area Under Curve of Precision Recall\ny55 = model5.predict_proba(X_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision5, recall5, thresholds5 = precision_recall_curve(y_test, y55[:, 1])\nauc_precision_recall = auc(recall5, precision5)\n\nprint(auc_precision_recall)","daf3da27":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\ny_score = model5.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\ndisp = plot_precision_recall_curve(model5, X_test, y_test)\ndisp.ax_.set_title('Ridge Classifier Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","8b273f8c":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y55)\n\nplt.show()","84e406cb":"skplt.metrics.plot_lift_curve(y_test, y55)\nplt.show()","bd407a43":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify = y_train)","e206506b":"import keras\nfrom tensorflow.keras import models\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import regularizers\nfrom keras.utils import np_utils\nfrom keras.models import load_model","4d9147e0":"input = Input(shape=(30,))\nx = Dense(64, activation='relu')(input)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(128, activation='relu')(x)\noutput = Dense(1, activation='sigmoid')(x)\n\nmodel6 = models.Model(inputs=input, outputs=output, name=\"model6\")\nmodel6.summary()","93512eee":"import tensorflow as tf\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n\n#optimizer = tf.keras.optimizers.Adamax(lr=0.01)\noptimizer=tf.keras.optimizers.Adam(learning_rate = 0.001)\n\n\nmodel6.compile(loss='binary_crossentropy',\n              optimizer = optimizer,\n              metrics=['accuracy'])\n\nearlystopper = EarlyStopping(patience=8, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=3, min_lr=1e-7, verbose=1)","4a7aa2af":"history = model6.fit(x = X_train, y = y_train,\n                    validation_data = (X_val, y_val),\n                    batch_size = 128,\n                    epochs = 50,\n                    shuffle = True,\n                    callbacks=[reduce_lr])","2d6c51f1":"import matplotlib.pyplot as plt\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1,51)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss for Adam')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","41312ccb":"import matplotlib.pyplot as plt\nacc_train = history.history['accuracy']\nacc_val = history.history['val_accuracy']\nepochs = range(1,51)\nplt.plot(epochs, acc_train, 'r', label='Training accuracy')\nplt.plot(epochs, acc_val, 'g', label='validation accuracy')\nplt.title('Training and Validation Accuracy for Adam')\nplt.xlabel('Accuracy')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","ffbfcec1":"model6.save('\/content\/model.h5')","3db3c5ad":"from keras.models import load_model\ntest_model = load_model('model6ann.h5')","335d1e96":"y6 = test_model.predict(X_test)","5818984a":"print(y6.sum())","203f2b49":"for i in range(len(y6)):\n  if y6[i][0]>0.5:\n    y6[i][0] = 1\n  else:\n    y6[i][0] = 0","10daa06c":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y6)\nprint(cm)","74ef1a8a":"# from sklearn.metrics import plot_confusion_matrix\n# class newmodel(MLPClassifier):\n#     def __init__(self, model6):\n#         self.model6 = model6\n#     def predict(self, X_test):\n#         y_test = self.model6.predict(X_test)\n#         for i in range(len(y_test)):\n#           if y_test[i][0]>0.5:\n#             y_test[i][0] = 1\n#           else:\n#             y_test[i][0] = 0\n#         return y_test\n\n# model = newmodel(model6)\n# plot_confusion_matrix(model, X_test, y_test) \n\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nlabels = [\"Non-Fraud\", \"Fraud\"]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","633e964c":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y6, target_names=['Fraud','Non-Fraud']))","19cf114d":"print(y66.shape)","80ea17c9":"# Area Under Curve of Precision Recall\ny66 = test_model.predict(X_test)\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision6, recall6, thresholds6 = precision_recall_curve(y_test, y66)\nauc_precision_recall = auc(recall6, precision6)\n\nprint(auc_precision_recall)","d3b227f2":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\ny_score = test_model.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\ndisp = plot_precision_recall_curve(test_model, X_test, y_test)\ndisp.ax_.set_title('Logistic  Regression Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","e5cbd133":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y66)\n\nplt.show()","f40b8150":"skplt.metrics.plot_lift_curve(y_test, y66)\nplt.show()","e12a2c8f":"X_train = X_train.values.reshape(-1, 1, 30)\nX_test  = X_test.values.reshape(-1, 1, 30)\nX_val = X_val.values.reshape(-1, 1, 30)\ny_train = y_train.values.reshape(-1, 1, 1)\ny_test = y_test.values.reshape(-1, 1, 1)\ny_val = y_val.values.reshape(-1, 1, 1)","3cadc4aa":"import keras\nfrom tensorflow.keras import models\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import regularizers\nfrom keras.utils import np_utils\nfrom keras.models import load_model","cbe3fca8":"input = Input(shape=(1,30))\nx = LSTM(30, dropout=0.25)(input)\nx = Dense(128, activation='relu')(x)\noutput = Dense(1, activation='sigmoid')(x)\n\nmodel7 = models.Model(inputs=input, outputs=output, name=\"model7\")\nmodel7.summary()","439164d5":"from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\nimport tensorflow as tf\n\n#optimizer = tf.keras.optimizers.Adamax(lr=0.01)\noptimizer=tf.keras.optimizers.Adam(learning_rate = 0.001)\n\n\nmodel7.compile(loss='binary_crossentropy',\n              optimizer = optimizer,\n              metrics=['accuracy'])\n\nearlystopper = EarlyStopping(patience=8, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=3, min_lr=1e-7, verbose=1)","56dc1c18":"history = model7.fit(x = X_train, y = y_train,\n                    validation_data = (X_val, y_val),\n                    batch_size = 128,\n                    epochs = 50,\n                    shuffle = True,\n                    callbacks=[reduce_lr])","474f303c":"import matplotlib.pyplot as plt\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1,51)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss for Adam')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","05565ece":"import matplotlib.pyplot as plt\nacc_train = history.history['accuracy']\nacc_val = history.history['val_accuracy']\nepochs = range(1,51)\nplt.plot(epochs, acc_train, 'r', label='Training accuracy')\nplt.plot(epochs, acc_val, 'g', label='validation accuracy')\nplt.title('Training and Validation Accuracy for Adam')\nplt.xlabel('Accuracy')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","15a52525":"model7.save('\/content\/model.h5')","2c3e8512":"from keras.models import load_model\ntest_model = load_model('model.h5')","8c1a72cc":"y7 = test_model.predict(X_test)","bbf75f5b":"print(y7.sum())","1310bc84":"for i in range(len(y7)):\n  if y7[i][0]>0.5:\n    y7[i][0] = int(1)\n  else:\n    y7[i][0] = int(0)","cad46958":"print(y7)","4e2133e2":"y_test = y_test.reshape(-1,1)\nprint(y_test)","77ac19dc":"from sklearn.metrics import confusion_matrix\n\ncm1 = confusion_matrix(y_test, y7)\nprint(cm1)","f8cb5373":"from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nlabels = [\"Non-Fraud\", \"Fraud\"]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm1, display_labels=labels)\n\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","93694d8e":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y7, target_names=['Fraud','Non-Fraud']))","10d6758d":"# Area Under Curve of Precision Recall\ny77 = test_model.predict(X_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision7, recall7, thresholds7 = precision_recall_curve(y_test, y77)\nauc_precision_recall = auc(recall7, precision7)\n\nprint(auc_precision_recall)","0fd99ec5":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\ny_score = test_model.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\ndisp = plot_precision_recall_curve(test_model, X_test, y_test)\ndisp.ax_.set_title('Logistic  Regression Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","a1dfb888":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y77)\n\nplt.show()","2945ff59":"skplt.metrics.plot_lift_curve(y_test, y77)\nplt.show()","f38aa203":"from sklearn.linear_model import Lasso\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nnames = df.drop('Class', axis=1).columns\nprint(names)","4c7b0d6f":"smodel = Lasso(alpha=0.9)\nlasso_coef = smodel.fit(X_train, y_train).coef_\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(names,lasso_coef)\nplt.show()","9143853e":"for i in lasso_coef:\n  print(i)","a4acd716":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier","587a191c":"sel = SelectFromModel(RandomForestClassifier(n_estimators = 310))\nsel.fit(X_train, y_train)","8a9b18ee":"sel.get_support()","df83cba5":"selected_feat= X_train.columns[(sel.get_support())]\nlen(selected_feat)","2b0c2766":"print(selected_feat)","cf7133bc":"X_important_train = sel.transform(X_train)\nX_important_test = sel.transform(X_test)","da796150":"Sel_important = RandomForestClassifier(n_estimators=310, random_state=0, n_jobs=-1)\nSel_important.fit(X_important_train, y_train)","ea4ad71e":"y_pred = Sel_important.predict(X_important_test)","7d2c4ada":"print(y_pred.sum())","5e002118":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y_pred)","a9a59fd7":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(Sel_important, X_important_test, y_test)  \nplt.show()  ","7d070c0a":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred, target_names=['Fraud','Non-Fraud']))","95bd860f":"# Area Under Curve of Precision Recall\ny_pred1 = Sel_important.predict_proba(X_important_test)\n\nfrom sklearn.metrics import precision_recall_curve , auc\n\nprecision1, recall1, thresholds1 = precision_recall_curve(y_test, y_pred1[:, 1])\nauc_precision_recall = auc(recall1, precision1)\n\nprint(auc_precision_recall)","906aa30b":"print(y_pred1)","c548a3d3":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score\n#y_score = Sel_important.decision_function(X_important_test)\naverage_precision = 0.84 #average_precision_score(y_test, y_score)\n\ndisp = plot_precision_recall_curve(Sel_important, X_important_test, y_test)\ndisp.ax_.set_title('Random Forest after feature selection Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))","79d1ead3":"! pip install scikit-plot","f14488ee":"import matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_cumulative_gain(y_test, y_pred1)\n\nplt.show()","f7905336":"skplt.metrics.plot_lift_curve(y_test, y_pred1)\nplt.show()","285f2f66":"###Setting up Kaggle","70ffe60c":"###Peeping Data","7c33c9d1":"###Ridge classifier","f0d75020":"###XGBoost Classifier","ade73c27":"Results after feature selection.","bc9c0433":"Tranforming the dataset","11edb85d":"###Logistic Regression","5602878d":"###LogisticRegressionCV","9fed2803":"###Upload file","17b69e50":"Making stratified validation set","98ac0621":"Random forest based feature selection","f86f160d":"###Feature selection","28e03ec8":"###Random Forest","4fccf3e2":"###ANN","3fd2f562":"###Preparing data","1ba8bd77":"Lasso feature selection","94eb63b5":"###Lasso classifier","76965699":"###LSTM","c03d034e":"Model"}}