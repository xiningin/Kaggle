{"cell_type":{"a9b0b2b7":"code","95485966":"code","5d8953ed":"code","a69c54e2":"code","db862dd6":"code","9126408b":"code","051490b4":"code","10fae0bb":"code","2c6bbcfc":"code","4eb74aa5":"code","94e2c19f":"code","a0fe7f58":"code","445c6c6f":"code","f940db89":"code","bd96e3d7":"code","d66d45a7":"code","65adc3a1":"code","89548376":"code","84a6c936":"code","aa6b9fa7":"code","4580fdfe":"code","bfa2d066":"code","448adac5":"code","581e44d3":"code","ecf91ae0":"code","023b3457":"code","cc666665":"code","a7b8ceba":"code","7791390c":"markdown","be8984e4":"markdown","41b9757c":"markdown","489621e8":"markdown","bae9581e":"markdown","4bf92f3e":"markdown","3fee5f5f":"markdown","3904508e":"markdown","f0b085fb":"markdown","5294ac33":"markdown","2d131a65":"markdown","1bbb8abe":"markdown","76aaf632":"markdown","3c67fb96":"markdown","948e78b9":"markdown","9eeb2b5a":"markdown"},"source":{"a9b0b2b7":"import pandas as pd \nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","95485966":"X_train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ny_train=X_train.label\nX_train=X_train.drop(['label'],axis=1)\nX_test=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\n\nm_x_train=X_train.shape[0]\nm_x_test=X_test.shape[0]","5d8953ed":"X_train=np.reshape(np.array(X_train),newshape=(m_x_train,28,28,1))\n\nX_test=np.reshape(np.array(X_test),newshape=(m_x_test,28,28,1))\n\n\nX_train.shape,X_test.shape","a69c54e2":"plt.imshow(X_train[0,...])","db862dd6":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy,MeanSquaredError,MeanAbsoluteError","9126408b":"class Conv(layers.Layer):\n    def __init__(self,kernel_size=3,strides=2,padding='same',filters=8,alpha=0.2,t=False):\n        super().__init__()\n        \n        if t:\n            self.conv=layers.Conv2DTranspose(kernel_size=kernel_size,\n                               strides=strides,\n                               padding=padding,\n                               filters=filters,\n                               activation=None)\n        else:\n            self.conv=layers.Conv2D(kernel_size=kernel_size,\n                               strides=strides,\n                               padding=padding,\n                               filters=filters,\n                               activation=None)\n        self.bn=layers.BatchNormalization(axis=-1)\n        self.lr=layers.LeakyReLU(alpha=alpha)\n        \n    def call(self,x,training=False):\n        x=self.conv(x)\n        x=self.bn(x,training=training)\n        x=self.lr(x)\n        return x","051490b4":"class Encoder(tf.keras.Model):\n    def __init__(self,n_layers=4,e_dim=10,i_dim=32,\n                 kernel_size=3,strides=2,padding='same',filters=8,alpha=0.2):\n        super().__init__()\n        self.encoder=tf.keras.Sequential([Conv(kernel_size=3,\n                                               strides=2,padding='same',\n                                               filters=8*(2**(i if i!=n_layers-1 else i-1)),\n                                               alpha=0.2)\n                                         for i in range(n_layers)])\n        \n        self.explicit=layers.Conv2D(kernel_size=3,strides=2,padding='same',\n                                    filters=e_dim,activation=None)\n        \n        self.implicit=layers.Conv2D(kernel_size=3,strides=2,padding='same',\n                                    filters=i_dim,activation='sigmoid',\n                                    kernel_initializer=tf.keras.initializers.RandomNormal(),\n                                    bias_initializer=tf.keras.initializers.Constant(-5.))\n        \n    def call(self,x,training=False):\n        x=self.encoder(x,training=training)\n        ex=self.explicit(x)\n        im=self.implicit(x)\n        \n        return tf.squeeze(ex),tf.squeeze(im)\n","10fae0bb":"#test\n\n'''\ne=Encoder()\nx=tf.random.normal((5,32,32,1))\nex,im=e(x)\n\nex.shape,im.shape\n'''","2c6bbcfc":"class Decoder(tf.keras.Model):\n    def __init__(self,n_layers=4,n_channels=1,kernel_size=3,strides=2,padding='same',filters=8,alpha=0.2):\n        super().__init__()\n        self.init=Conv(kernel_size=3,strides=2,\n                       padding='same',filters=8*(2**(n_layers-2)),alpha=0.2,t=True)\n        \n        self.decoder=tf.keras.Sequential([Conv(kernel_size=3,\n                                               strides=2,padding='same',\n                                               filters=8*(2**(n_layers-i-1)),\n                                               alpha=0.2,\n                                               t=True)\n                                         for i in range(1,n_layers)])\n        \n        self.out=layers.Conv2DTranspose(kernel_size=3,strides=2,padding='same',\n                                        filters=n_channels,activation='sigmoid') #image 0~1\n        \n        \n    def call(self,ex,im,training=False):\n        m=ex.shape[0]\n        x=tf.concat([ex,im],axis=-1) #1x(edim+idim)\n        x=tf.reshape(x,(m,1,1,-1)) #1x1xc\n        x=self.init(x,training=training)\n        x=self.decoder(x,training=training)\n        x=self.out(x)\n        return x","4eb74aa5":"'''\nd=Decoder()\n\nd(ex,im).shape\n\n'''","94e2c19f":"batch_size=128\n\nclass_num=np.unique(y_train).shape[0]\n\nlr=1e-4\n\nepochs=100\n\ntest_sampling=2","a0fe7f58":"ds_train=tf.data.Dataset.from_tensor_slices((X_train,y_train))\n\nds_test=tf.data.Dataset.from_tensor_slices(X_test)\n\n#pass 32x32\n#img 0~1\naug=tf.keras.Sequential([layers.Resizing(32,32),\n                         layers.Rescaling(scale=1.\/255)])\n\n\nds_train=ds_train.map(lambda x,y : (aug(x),y))\nds_test=ds_test.map(lambda x: aug(x))\n\nds_train=ds_train.batch(batch_size, drop_remainder=False)\n\nds_test=ds_test.batch(1, drop_remainder=False)","445c6c6f":"loss_class=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nloss_recon=MeanSquaredError() #L2\n\nloss_recon_img=MeanAbsoluteError()\n\nopt=Adam(learning_rate=lr)","f940db89":"@tf.function\ndef flow(x,y,E,D):\n    m=x.shape[0]\n    y_random=tf.experimental.numpy.random.randint(class_num,size=m)\n    \n    y_ohe=tf.one_hot(y,depth=class_num) #(m,10)\n    y_random_ohe=tf.one_hot(y_random,depth=class_num) #(m,10)\n    \n    \n    \n    with tf.GradientTape() as tape:\n        ex,im=E(x,training=True)\n        \n        \n        #given label\n        x_l=D(y_ohe,im,training=True)\n        ex_l,im_l=E(x_l,training=True)\n        \n        #random label\n        x_r=D(y_random_ohe,im,training=True)\n        ex_r,im_r=E(x_r,training=True)\n        \n        \n        #classification loss\n        lc=loss_class(y,ex) #given classification\n        le=loss_class(y_random,ex_r) #random classification\n        \n        #reconstruction loss\n        lr=loss_recon_img(x,x_l) #img reconstruction\n        li=loss_recon(im_l,im_r) #latent code reconstruction\n        \n        loss=lc+le+lr+li\n        \n    grad=tape.gradient(loss,E.trainable_weights+D.trainable_weights)\n    opt.apply_gradients(zip(grad,E.trainable_weights+D.trainable_weights))\n    return lc,le,lr,li","bd96e3d7":"def sampling(x,E,D):\n    y_test=tf.eye(class_num) #test each classes , identity matrix=one hot label\n    \n    fig,ax=plt.subplots(ncols=class_num+1)\n    \n    mse_=[]\n    ssim_=[]\n    ex,im=E(x,training=False)\n    \n    ax[0].imshow(x[0,...].numpy()*255.)\n    plt.gray()\n    ax[0].set_title('original')\n    \n    im=tf.expand_dims(im,axis=0)\n    for i,y in enumerate(y_test):\n        y=tf.expand_dims(y,axis=0)\n        x_r=D(y,im,training=False)\n        \n        mse=loss_recon(x*255,x_r*255).numpy()\n        ssim=tf.image.ssim(x,x_r,max_val=1.).numpy()[0]\n        \n        mse_.append(mse)\n        ssim_.append(ssim)\n        \n        ax[i+1].imshow(x_r[0,...].numpy()*255.)\n        plt.gray()\n        ax[i+1].set_title(i)\n    plt.show()\n        \n    print(f'mean mse:{np.mean(mse_)} mean ssim : {np.mean(ssim_)}')","d66d45a7":"from tqdm import tqdm","65adc3a1":"def train():\n    \n    E=Encoder()\n    D=Decoder()\n    \n    ckpt = tf.train.Checkpoint(E=E,D=D,opt=opt)\n    ckpt_manager = tf.train.CheckpointManager(ckpt,'.\/ckpt', max_to_keep=1)\n    if ckpt_manager.latest_checkpoint :\n        ckpt.restore(ckpt_manager.latest_checkpoint)\n        print('---ckpt restored----')\n    print('start training')\n    for epoch in range(epochs):\n        \n        loop=tqdm(ds_train,leave=True)\n        for x,y in loop:\n            lc,le,lr,li=flow(x,y,E,D)\n            loop.set_postfix(loss=f'epoch:{epoch}, given class loss : {lc}  random class loss : {le}  img reconstruction loss:{lr} latent reconstruction loss:{li}')\n        \n        if epoch%5==0:\n            print('start sampling')\n            for x_test in ds_test.take(test_sampling):\n                sampling(x_test,E,D)\n            ckpt_manager.save()\n    return E,D","89548376":"E,D=train()","84a6c936":"for x in ds_test.take(50):\n    sampling(x,E,D)","aa6b9fa7":"from sklearn.manifold import TSNE\nfrom sklearn.utils import shuffle","4580fdfe":"sample_size=1000 #since time complexity of tsne is large, s\n\nX,y=X_train[:sample_size],y_train[:sample_size]\n                                  \nX=X.astype('float32')\n\nX=tf.image.resize(X,(32,32))\/255.\n\nX.shape,y.shape","bfa2d066":"temp=X\n\n#last layer of encoder\nfor l in E.encoder.layers:\n    temp=l(temp,training=False)\nlast_output=temp.numpy().reshape(sample_size,-1) #(2,2,32)-->(128)\n\n\n#first layer of decoder\nex,im=E(X,training=False)\nI=tf.eye(class_num)\nfirst_output=[]\nfirst_output_label=[]\nfor idx,i in enumerate(I):\n    first_output_label.append(tf.repeat(idx,sample_size,axis=0).numpy()) #add label\n    i=tf.expand_dims(i,axis=0) #(1,10)\n    i=tf.repeat(i,sample_size,axis=0)\n    temp=tf.concat([i,im],axis=-1) #\n    temp=tf.reshape(temp,(temp.shape[0],1,1,-1))\n    temp=D.init(temp,training=False)\n    first_output.append(temp.numpy())\n    \n    \nfirst_output=np.array(first_output).reshape(class_num,sample_size,-1)\nfirst_output_label=np.array(first_output_label)","448adac5":"last_output.shape,y.shape,first_output.shape,first_output_label.shape","581e44d3":"tsne=TSNE(random_state=0)\n\ncomponent=tsne.fit_transform(last_output)\n\ncomponent.shape","ecf91ae0":"color_map={i:c for i,c in enumerate(['b','g','r','c','m','y','k','w','deeppink','gold'])}\n\nplt.scatter(component[:,0],component[:,1],c=list(map(lambda x:color_map[x],y)),edgecolor='black',marker='s')\nplt.title('Last layer output of encoder')\nplt.legend()\nplt.show()","023b3457":"fo=first_output.reshape(class_num*sample_size,-1)\nfol=first_output_label.reshape(class_num*sample_size,-1)\n\n\n\nfo,fol=shuffle(fo,fol)\n\nfo,fol=fo[:sample_size],fol[:sample_size]\n\nfo.shape,fol.shape","cc666665":"component=tsne.fit_transform(fo)\n\ncomponent.shape","a7b8ceba":"color_map={i:c for i,c in enumerate(['b','g','r','c','m','y','k','w','deeppink','gold'])}\n\nplt.scatter(component[:,0],component[:,1],c=list(map(lambda x:color_map[x],fol[:,0])),edgecolor='black',marker='s')\nplt.title('First layer output of decoder')\nplt.legend()\nplt.show()","7791390c":"* Block","be8984e4":"* Encoder","41b9757c":"### Distribution ","489621e8":"* Maybe add GAN machinism can improve stability ,  but the result looks really good","bae9581e":"* Encoder last layer output\n\n   * we can see that since using explicit code for classification , the backprop algorithm update weight based on this signal ,  so the distribution is very seperable","4bf92f3e":"* Show Result","3fee5f5f":"* Dataset","3904508e":"* Hope\n\n * MSE is not close to the origin\n \n * SSIM is not close to the origin","f0b085fb":"* Training","5294ac33":"## Modeling","2d131a65":"* Decoder first layer output\n\n   * The distribution is based on the input explicit code  , and more seperable than the above distribution","1bbb8abe":"![image.png](attachment:69e2b840-af59-4a6f-9753-8c8bb5b1928e.png)","76aaf632":"Design:\n\n*  Conditional Autoencoder \n  \n*  Implicit : Encoding an img into a latent code which each of its dimension controls attributes of decoded img\n  \n*  Explicit The label is not only for classification but also embedding information into latent space \n  \n  \n* To simplified , the label tells the latent code which to change \n\n* Example : the img is 0 and be encoded to a vector , the label 0 to 9 can change the result of the decoded img which showing 0~9 based on the input label ","3c67fb96":"* Explore distribution \n\n   * Output of last layer of the encoder\n      * check distribution before adding label information\n   * Output of first layer of the decder(input different label)\n      * Check distribution after adding label information ","948e78b9":"* Decoder","9eeb2b5a":"![image.png](attachment:51d5325d-a212-4a31-a86d-84f7d690f542.png)"}}