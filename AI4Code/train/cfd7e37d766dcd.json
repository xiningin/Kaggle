{"cell_type":{"f0946f98":"code","ae1cdffa":"code","357c80a9":"code","160615bd":"code","e21c6c99":"code","d54289f0":"code","06078d6f":"code","b77b42fb":"code","4acf01e0":"code","83c64244":"code","1e2a536a":"code","15b9862e":"code","f75cfe67":"code","a6c27884":"code","2f633af2":"code","09f9fe9b":"code","9dab976e":"code","e496ac6a":"code","9e43d283":"code","a37f42b9":"code","77968e18":"code","d40faa60":"code","ee88b6fa":"code","89311030":"code","2162ef38":"code","406324ea":"code","3d361f88":"code","68f9d651":"code","b1d91815":"code","0bc74799":"code","d696b313":"code","1910d19b":"code","071296f0":"code","da95dcc7":"code","96231829":"code","f1514d8f":"code","c461d036":"code","1fc542c9":"code","d216abc6":"code","4c9d0c62":"code","0abed02e":"code","7211bb02":"code","b41b4be7":"code","f092aeab":"code","d08d23a9":"code","88bdc3f2":"code","53e7a7b3":"code","0dab42e9":"code","67856a2a":"code","859a5905":"code","2a555a99":"code","13f59a06":"code","fe44dce3":"code","4ac68d45":"code","d0ad75ae":"code","7483f638":"code","b58aa710":"code","2be73a9f":"code","be1505d8":"code","eec40dbe":"code","4e10a6c1":"code","0fac86a5":"markdown"},"source":{"f0946f98":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae1cdffa":"train = pd.read_csv('\/kaggle\/input\/av-recommendation-systems\/train_mddNHeX\/train.csv')\nchallenge = pd.read_csv('\/kaggle\/input\/av-recommendation-systems\/train_mddNHeX\/challenge_data.csv')\ntest = pd.read_csv('\/kaggle\/input\/av-recommendation-systems\/test_HLxMpl7\/test.csv')\nprint(train.shape, test.shape, challenge.shape)","357c80a9":"challenge.head()","160615bd":"for col in challenge.columns:\n    print(f'{col}: {challenge[col].nunique()}')","e21c6c99":"test.head(20)","d54289f0":"print(f'The number of unique users in train set is: {train.user_id.nunique()}')\nprint(f'The number of unique challenges in train set is: {train.challenge.nunique()}')\n\nprint(f'The number of unique users in test set is: {test.user_id.nunique()}')\nprint(f'The number of unique challenges in test set is: {test.challenge.nunique()}')","06078d6f":"print(len(np.intersect1d(train.challenge, test.challenge)))\nprint(len(np.intersect1d(train.user_id, test.user_id)))","b77b42fb":"def apk(actual, predicted, k):\n    \"\"\"\n    Computes the average precision at k.\n    This function computes the average prescision at k between two lists of\n    items.\n    Parameters\n    ----------\n    actual : list\n             A list of elements that are to be predicted (order doesn't matter)\n    predicted : list\n                A list of predicted elements (order does matter)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The average precision at k over the input lists\n    \"\"\"\n    \n    actual = list(actual)\n    predicted = list(predicted)\n    \n    if len(predicted)>k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i,p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits \/ (i+1.0)\n            \n    if not actual:\n        return 0.0\n\n    return score \/ min(len(actual), k)\n\ndef mapk(actual, predicted, k):\n    \"\"\"\n    Computes the mean average precision at k.\n    This function computes the mean average prescision at k between two lists\n    of lists of items.\n    Parameters\n    ----------\n    actual : list\n             A list of lists of elements that are to be predicted \n             (order doesn't matter in the lists)\n    predicted : list\n                A list of lists of predicted elements\n                (order matters in the lists)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The mean average precision at k over the input lists\n    \"\"\"\n    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])","4acf01e0":"col = challenge.columns\ncol = ['challenge' if x =='challenge_ID' else x for x in col]\nchallenge.columns = col","83c64244":"train_ch = pd.merge(train, challenge, on = 'challenge', how = 'left')\ntest_ch = pd.merge(test, challenge, on = 'challenge', how = 'left')","1e2a536a":"train_ch.head(26)","15b9862e":"print(train_ch.shape, test_ch.shape)","f75cfe67":"submit = pd.read_csv('\/kaggle\/input\/av-recommendation-systems\/sample_submission_J0OjXLi_DDt3uQN.csv')\nsubmit.head()","a6c27884":"users = train.user_id\nval_user = list(users.sample(15000, random_state = 0))","2f633af2":"!pip install turicreate\nimport turicreate as tc","09f9fe9b":"train_sf = tc.SFrame.read_csv('\/kaggle\/input\/av-recommendation-systems\/train_mddNHeX\/train.csv')\ntest_sf = tc.SFrame.read_csv('\/kaggle\/input\/av-recommendation-systems\/test_HLxMpl7\/test.csv')\ntrain_sf = train_sf.append(test_sf)\n#training_data, validation_data = tc.recommender.util.random_split_by_user(train_sf, 'user_id', 'challenge')","9dab976e":"train_sf = train_sf.sort('user_id')\ntrain_sf['rating'] = 10.0\ntraining_data = train_sf[train_sf['challenge_sequence'] < 11]\nvalidation_data = train_sf[train_sf['challenge_sequence'] >= 11]","e496ac6a":"challenge_sf = tc.SFrame.read_csv('\/kaggle\/input\/av-recommendation-systems\/train_mddNHeX\/challenge_data.csv')\nchallenge_sf = challenge_sf.rename({'challenge_ID': 'challenge'})\nchallenge_sf['category_id']= challenge_sf['category_id'].fillna(0).astype(str)\nchallenge_sf['programming_language']= challenge_sf['programming_language'].astype(str)\nmean = np.mean(challenge['total_submissions'])\nchallenge_sf['total_submissions']= challenge_sf['total_submissions'].fillna(mean)","9e43d283":"#tc.config.set_num_gpus(0)\n#del model\nmodel = tc.recommender.ranking_factorization_recommender.create(training_data, 'user_id', 'challenge'\n                                                                , ranking_regularization = 0.09\n                                                                , max_iterations = 400\n                                                                , num_factors = 222\n                                                                #, regularization= 1e-4\n                                                                , target = 'challenge_sequence'\n                                                                #, item_data = challenge_sf#[['challenge', 'total_submissions']]\n                                                                , num_sampled_negative_examples = 7\n                                                                ,verbose = True\n                                                               )","a37f42b9":"validation_data.head()","77968e18":"users = validation_data['user_id'].unique()\nrecommend = model.recommend(users= users, k=3)\n#recommend2 = model2.recommend(users= users, k=3)","d40faa60":"recommend = recommend.sort(['user_id', 'rank'])\n#recommend2 = recommend2.sort(['user_id', 'rank'])","ee88b6fa":"validation_data = validation_data.sort(['user_id', 'challenge_sequence'])","89311030":"recommend_df = pd.DataFrame(recommend)\n#recommend2_df = pd.DataFrame(recommend2)\n\npredicted = recommend_df.groupby('user_id').agg(lambda x : ','.join(list(x))).reset_index().reindex(columns=recommend_df.columns)\n#predicted2 = recommend2_df.groupby('user_id').agg(lambda x : ','.join(list(x))).reset_index().reindex(columns=recommend2_df.columns)\n\nactual_df = pd.DataFrame(validation_data)\nactual = actual_df.groupby('user_id').agg(lambda x : ','.join(list(x))).reset_index().reindex(columns=actual_df.columns)","2162ef38":"actual.head()","406324ea":"actual_list = []\nfor x in actual.challenge:\n    actual_list.append([y for y in x.split(',')])\nactual_list[:5]","3d361f88":"#predicted2.head()","68f9d651":"pred_list = []\nfor x in predicted.challenge:\n    pred_list.append([y for y in x.split(',')])\npred_list[:5]","b1d91815":"#pred2_list = []\n#for x in predicted2.challenge:\n#    pred2_list.append([y for y in x.split(',')])\n#pred2_list[:5]","0bc74799":"[print(a,p) for a,p in zip(actual_list[-5:], pred_list[-5:])]","d696b313":"#[print(a,p) for a,p in zip(actual_list[-5:], pred2_list[-5:])]","1910d19b":"print(mapk(actual_list, pred_list, 3))","071296f0":"#print(mapk(actual_list, pred2_list, 3))","da95dcc7":"recommend.head()","96231829":"recommend2.head()","f1514d8f":"training_data[training_data['user_id'] == 113838]","c461d036":"users = test_sf['user_id'].unique()\nusers = np.sort(users)","1fc542c9":"users","d216abc6":"pred_rec = model.recommend(users= users, k=3)\nsubmit = pd.read_csv('\/kaggle\/input\/av-recommendation-systems\/sample_submission_J0OjXLi_DDt3uQN.csv')","4c9d0c62":"#pred_rec2 = model2.recommend(users= users, k=3)","0abed02e":"#pred_rec2.tail()","7211bb02":"submit['challenge'] = pred_rec['challenge']\nsubmit.to_csv('turi_tuned_1977.csv', index= False)","b41b4be7":"submit['challenge'] = pred_rec2['challenge']\nsubmit.to_csv('turi_model2.csv', index= False)","f092aeab":"submit.head(10)","d08d23a9":"challenge = pd.read_csv('\/kaggle\/input\/av-recommendation-systems\/train_mddNHeX\/challenge_data.csv')\nchallenge.head()","88bdc3f2":"challenge.challenge_series_ID = challenge.challenge_series_ID.fillna('None')\nchallenge.challenge_series_ID = challenge.challenge_series_ID.astype('str')\n\nchallenge.category_id = challenge.category_id.fillna('None')\nchallenge.category_id = challenge.category_id.astype('str')","53e7a7b3":"from sklearn.preprocessing import LabelEncoder\nle_series = LabelEncoder()\nchallenge.challenge_series_ID = le_series.fit_transform(challenge.challenge_series_ID)\n\nle_cat = LabelEncoder()\nchallenge.category_id = le_cat.fit_transform(challenge.category_id)","0dab42e9":"challenge = pd.get_dummies(challenge, columns = ['author_gender'], drop_first = True)","67856a2a":"challenge.head()","859a5905":"ch = challenge[['programming_language', 'challenge_series_ID', 'total_submissions', 'category_id', 'author_gender_M']]\nch.total_submissions = ch.total_submissions.fillna(np.mean(ch.total_submissions))","2a555a99":"ch.isnull().sum()","13f59a06":"from sklearn.metrics import pairwise\nmatrix = pairwise.cosine_similarity(ch, ch)","fe44dce3":"sim_df = pd.DataFrame(matrix, columns = challenge.challenge_ID)\nsim_df.index = challenge.challenge_ID","4ac68d45":"sim_df.head()","d0ad75ae":"#sim_df = pd.merge(sim_df, challenge, on = 'challenge_ID')\n#sim_df['publish_date'] = (sim_df['publish_date']).astype('str')","7483f638":"#date = sim_df[sim_df['challenge_ID'] == 'CI23714'].publish_date\nsim_df.nlargest(13, 'CI24915')['CI24915']","b58aa710":"train.head(13)","2be73a9f":"challenge = pd.read_csv('\/kaggle\/input\/av-recommendation-systems\/train_mddNHeX\/challenge_data.csv')\nchallenge.head()\ncol = ['programming_language', 'total_submissions', 'author_gender']\nch = challenge[col]\nch = pd.get_dummies(ch, columns = [ 'programming_language', 'author_gender'], drop_first = False)\nch.total_submissions = ch.total_submissions.fillna(np.mean(ch.total_submissions))\nprint(ch.shape)\nmatrix = pairwise.cosine_similarity(ch, ch)\nsim2_df = pd.DataFrame(matrix, columns = challenge.challenge_ID)\nsim2_df.index = challenge.challenge_ID","be1505d8":"sim2_df.head()","eec40dbe":"sim2_df.nlargest(500, 'CI24915')['CI24915']","4e10a6c1":"train.head(13)","0fac86a5":"model2 = tc.recommender.factorization_recommender.create(training_data, 'user_id', 'challenge'\n                                                                #, ranking_regularization = 0.15\n                                                                , max_iterations = 20\n                                                                , num_factors = 150\n                                                                , regularization= 1e-1\n                                                                , target = 'challenge_sequence'\n                                                                #, item_data = challenge_sf#[['challenge', 'total_submissions']]\n                                                                #, num_sampled_negative_examples = 65\n                                                                , sgd_step_size = 0.005\n                                                                , verbose= True\n                                                               )"}}