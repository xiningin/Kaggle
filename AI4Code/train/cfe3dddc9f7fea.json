{"cell_type":{"1526d9f5":"code","560abfb6":"code","316f8e4f":"code","79d02a2b":"code","e41bf2d5":"code","5942acbb":"code","41c03a7e":"code","9fdb4e35":"code","479c7227":"code","a4568464":"code","821c63a9":"code","befe9e97":"code","1ae7ceda":"code","5bd3bbd1":"code","0b2a50dc":"code","59612483":"code","1a17f894":"markdown","7c4bc37b":"markdown","b2529585":"markdown","00242c32":"markdown","3a966b0e":"markdown","f3360261":"markdown","d7539bdf":"markdown","1f73d378":"markdown","ee077f7d":"markdown","edb94bd6":"markdown","d32a508e":"markdown","b3cd328b":"markdown","f4a57cc6":"markdown"},"source":{"1526d9f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","560abfb6":"import json\nimport os\nimport glob\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\n\nimport re\nimport string\n\nfrom wordcloud import WordCloud, STOPWORDS","316f8e4f":"train_0 = pd.read_json('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train\/f8b03c87-9d1a-4f20-b76b-cb6c69d447b2.json')\ntrain_csv = pd.read_csv('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv')","79d02a2b":"train_csv","e41bf2d5":"train_csv.pub_title[0]","5942acbb":"print(f'There are {len(train_csv.Id.unique())} different articles and {len(train_csv.cleaned_label.unique())} different datasets.')","41c03a7e":"sns.countplot(x=train_csv.Id.value_counts())","9fdb4e35":"fig = plt.figure(figsize=(13, 6))\nfig.suptitle('Distribution of articles and datasets', fontsize=20)\n\nax0 = plt.subplot2grid((1, 2), (0, 0))\nax1 = plt.subplot2grid((1, 2), (0, 1))\n\nax0.hist(train_csv.Id.value_counts())\nax0.set_xlabel(\"# of linked datasets by article\")\nax0.set_ylabel(\"# of articles\")\n\nax1.hist(train_csv.cleaned_label.value_counts())\nax1.set_xlabel(\"# of occurences of datasets in articles\")\nax1.set_ylabel(\"# of datasets\")\nplt.show()","479c7227":"sns.kdeplot(x=train_csv.Id.value_counts())","a4568464":"sns.kdeplot(x=train_csv.cleaned_label.value_counts())","821c63a9":"article0 = pd.read_json('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train\/d0fa7568-7d8e-4db9-870f-f9c6f668c17b.json')","befe9e97":"article0","1ae7ceda":"article0.text[0]","5bd3bbd1":"for sentence in article0.section_title:\n    print(''.join(sentence))","0b2a50dc":"train_csv = pd.read_csv('..\/input\/coleridgeinitiative-show-us-the-data\/train.csv')","59612483":"stopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(background_color='white',\n                      stopwords=stopwords,\n                      max_words=100,\n                      max_font_size=30,\n                      scale=3,\n                      random_state=1)\n   \ncloud = wordcloud.generate(str(train_csv['dataset_title'].unique()))\n\nfig = plt.figure(figsize=(15, 15))\nplt.axis('off')\nplt.imshow(cloud)\nplt.show()","1a17f894":"Here for instance, the article title \"The Impact of Dual Enrollment on College Degree Attainment: Do Low-SES Students Benefit?\" uses data from the National Education Longitudinal Study. Remember that we must predict the dataset(s) used for all articles or publication names. There can obviously be several datasets attached to one article.","7c4bc37b":"# How many different publications are there in the training set? And how many datasets are referenced?","b2529585":"# Let's plot the distribution of publications and datasets","00242c32":"The goal is to predict whether scientific articles mention datasets. The submission must include the id of the article and a string justifying the prediction (cleaned using the ``clean_text()`` function provided). Our model must predict this string.","3a966b0e":"The distribution of linked datasets by articles is much less smoother than that of articles by datasets. **Why?** It looks like a Laplace distibution. **Could I test it?**","f3360261":"Let's look at the paragraph titles.","d7539bdf":"# What exactly is our training data?","1f73d378":"## What form do the articles have?","ee077f7d":"# Dataset representation","edb94bd6":"So our first article has 18 titles. The left column contains the title of the paragraph and the right column contains the text.","d32a508e":"This script allows to check the number of files in the train directory. Taking out the train.csv file we have one \nmore article than our code above found within the train.csv file.\\\n``cd ..\/..\/kaggle\/input\ncd .\/coleridgeinitiative-show-us-the-data\/train\nls -f . | wc -l``\\\nThe answer should be 14318.","b3cd328b":"``train.csv`` is a file linking the publication and datasets referenced. We find the publication texts in the individual .json files. As for the test data, we have 4 articles to parse and link to datasets. From what I understand now, we have to find strings within the articles' text that we find are likely to be references to datasets. ","f4a57cc6":"# What exactly is the objective of this competition?"}}