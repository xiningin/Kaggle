{"cell_type":{"4089bf3c":"code","010284ab":"code","d6a0cb02":"code","405961e9":"code","984ca13f":"code","ca878f46":"code","c65b6fa8":"code","b9567848":"code","6c76655e":"code","4d25c3f1":"code","e3b63541":"code","70ed9346":"code","58826701":"code","8027015e":"code","62344d65":"code","71654ccd":"code","a0308cb8":"code","6b7d9341":"code","ce8a52cf":"code","f15a552a":"code","758d3bb8":"code","2343b02e":"code","7e0e106e":"code","dea2721f":"code","3a3c9067":"code","b0e636bf":"code","262344e1":"code","091fedb0":"code","2b613769":"code","c771d724":"code","f8f68fef":"code","c0824bbb":"code","61b9e2cf":"code","710cc5da":"code","cef5eb21":"code","46dbb212":"code","0f50afad":"code","7562d918":"code","ccb33d96":"code","05c0bc48":"code","780edb34":"code","758f35cd":"code","3645f813":"code","0287806c":"code","da518b8d":"code","fd5b027b":"code","84eca212":"code","87d7df51":"code","c3d98b37":"code","b3a4b8df":"code","21b288b2":"markdown","a42adf8c":"markdown","b5fa9876":"markdown","87a8ee30":"markdown","cc19a3ef":"markdown","6244587e":"markdown","52312a2c":"markdown","a9c941d9":"markdown","3822ee89":"markdown","296a5a87":"markdown","73940a08":"markdown","894cf6d5":"markdown"},"source":{"4089bf3c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","010284ab":"df = pd.read_csv(\"\/kaggle\/input\/water-potability\/water_potability.csv\")","d6a0cb02":"df.head()","405961e9":"df.shape","984ca13f":"df.describe","ca878f46":"missing_values=pd.DataFrame(df.isna().sum().sort_values(ascending=False),columns=['Column'])\nmissing_values['Percentage']=(missing_values['Column']\/3276)*100","c65b6fa8":"missing_values.head()","b9567848":"df['Sulfate']=df['Sulfate'].fillna((df['Sulfate'].mean()))\ndf['ph']=df['ph'].fillna((df['ph'].mean()))\ndf['Trihalomethanes']=df['Trihalomethanes'].fillna((df['Trihalomethanes'].mean()))","6c76655e":"df.isna().sum()","4d25c3f1":"df.head()","e3b63541":"def water_hardness(x):\n    if 0<=x<17.1:\n        return 'Soft'\n    elif 17.1<=x<60:\n        return 'Slightly Hard'\n    elif 60<=x<120:\n        return 'Moderately Hard'\n    elif 120<=x<180:\n        return 'Hard'\n    else:\n        return 'Very Hard'\n    ","70ed9346":"df['Water_Hardness']=df['Hardness'].apply(water_hardness)","58826701":"df.head()","8027015e":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.model_selection import cross_val_score , cross_val_predict\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import plot_roc_curve,roc_auc_score,roc_curve\nimport datetime\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n","62344d65":"plt.figure(figsize=(10,10))\nsns.countplot(x='Potability',data=df)\nplt.show()","71654ccd":"\nsns.displot(data=df, x=\"Hardness\", hue=\"Potability\", col=\"Water_Hardness\", palette = \"twilight\",kind=\"kde\", col_wrap=1,aspect=2,rug=True)","a0308cb8":"feature_cols=['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity',\n       'Organic_carbon', 'Trihalomethanes', 'Turbidity',]","6b7d9341":"plt.figure(figsize=(5,10))\npx.histogram(x=df['ph'],color=df['Potability'])\n","ce8a52cf":"plt.figure(figsize=(5,10))\npx.histogram(x=df['Solids'],color=df['Potability'])","f15a552a":"plt.figure(figsize=(5,10))\npx.histogram(x=df['Chloramines'],color=df['Potability'])","758d3bb8":"plt.figure(figsize=(5,10))\npx.histogram(x=df['Hardness'],color=df['Potability'])","2343b02e":" for c in feature_cols:\n        plt.figure(figsize=(10,10))\n        sns.distplot(df.loc[df['Potability']==1][c],kde_kws={'label':'Potability 1'},color='green')\n        sns.distplot(df.loc[df['Potability']==0][c],kde_kws={'label':'Potability 0'},color='red')\n        plt.title(f'{c} Density Plot')\n        plt.legend(labels=['Drinkable','Not Drinkable'])","7e0e106e":"pd.plotting.scatter_matrix(df, figsize=(20, 20));","dea2721f":"plt.figure(figsize=(9,9))\n\ncorrMatrix=df.corr()\nsns.heatmap(corrMatrix,annot=True)\nplt.show()","3a3c9067":"df.head()","b0e636bf":"sns.jointplot(data=df, x=\"ph\", y=\"Hardness\",cmap =\"twilight\",height=7)","262344e1":"for col in feature_cols:\n    plt.figure(figsize=(8,5))\n    sns.set_style(\"whitegrid\")\n    sns.boxplot(x=df[f'{col}'],linewidth=2.5)","091fedb0":"for col in feature_cols:\n    plt.figure(figsize=(8,5))\n    sns.set_style(\"whitegrid\")\n    sns.violinplot(x=df[f'{col}'],linewidth=2.5)","2b613769":"df=pd.get_dummies(data=df,columns=['Water_Hardness'])","c771d724":"df.head()","f8f68fef":"X=df.drop('Potability',axis=1)\ny=df['Potability']","c0824bbb":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=45)","61b9e2cf":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","710cc5da":"logisticRegr = LogisticRegression()\nlogisticRegr.fit(X_train, y_train)\nlog_accuracy=accuracy_score(y_test,logisticRegr.predict(X_test))\nprint(f'The accuracy for logisitic regression is {log_accuracy*100}%')","cef5eb21":"r_fpr,r_tpr,_=roc_curve(y_test,logisticRegr.predict(X_test))\nr_auc=roc_auc_score(y_test,logisticRegr.predict(X_test))\nplt.plot(r_fpr,r_tpr,label='Logistic Regression (area={:.3f})'.format(r_auc))\nplt.title('Logistic Regression')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","46dbb212":"decision_tree=DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nlog_accuracy_decision_tree=accuracy_score(y_test,decision_tree.predict(X_test))\nprint(f'The accuracy score for decision tree is {log_accuracy_decision_tree*100}%')","0f50afad":"r_fpr,r_tpr,_=roc_curve(y_test,decision_tree.predict(X_test))\nr_auc=roc_auc_score(y_test,decision_tree.predict(X_test))\nplt.plot(r_fpr,r_tpr,label='Decision Tree Classifier (area={:.3f})'.format(r_auc))\nplt.title('Decision Tree Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","7562d918":"clf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\nlog_accuracy_rfc=accuracy_score(y_test,clf.predict(X_test))\n\nprint(f'The accuracy score for decision tree is {log_accuracy_rfc*100}%')","ccb33d96":"r_fpr,r_tpr,_=roc_curve(y_test,clf.predict(X_test))\nr_auc=roc_auc_score(y_test,clf.predict(X_test))\nplt.plot(r_fpr,r_tpr,label='Random Forest Classifier (area={:.3f})'.format(r_auc))\nplt.title('Random Forest Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","05c0bc48":"clf_GB = GaussianNB()\nclf_GB.fit(X_train,y_train)\nlog_accuracy_GNB=accuracy_score(y_test,clf_GB.predict(X_test))\nprint(f'The accuracy score for decision tree is {log_accuracy_GNB*100}%')","780edb34":"r_fpr,r_tpr,_=roc_curve(y_test,clf_GB.predict(X_test))\nr_auc=roc_auc_score(y_test,clf_GB.predict(X_test))\nplt.plot(r_fpr,r_tpr,label='Random Forest Classifier (area={:.3f})'.format(r_auc))\nplt.title('Gaussian NB')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","758f35cd":"clf_bagging_classifier=BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=450).fit(X_train,y_train)\nclf_bagging_classifier.fit(X_train,y_train)\nlog_accuracy_bagging_classifier=accuracy_score(y_test,clf_bagging_classifier.predict(X_test))\nprint(f'The accuracy score for Bagging classifier is {log_accuracy_bagging_classifier*100}%')","3645f813":"r_fpr,r_tpr,_=roc_curve(y_test,clf_bagging_classifier.predict(X_test))\nr_auc=roc_auc_score(y_test,clf_bagging_classifier.predict(X_test))\nplt.plot(r_fpr,r_tpr,label=' Bagging Classifier (area={:.3f})'.format(r_auc))\nplt.title('Bagging Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","0287806c":"clf_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\nclf_GBC.fit(X_train,y_train)\nlog_accuracy_GBC=accuracy_score(y_test,clf_GBC.predict(X_test))\nprint(f'The accuracy score for Bagging classifier is {log_accuracy_GBC*100}%')","da518b8d":"r_fpr,r_tpr,_=roc_curve(y_test,clf_GBC.predict(X_test))\nr_auc=roc_auc_score(y_test,clf_GBC.predict(X_test))\nplt.plot(r_fpr,r_tpr,label=' Gradient Boosting (area={:.3f})'.format(r_auc))\nplt.title('Gradient Boosting Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","fd5b027b":"xgb_model =XGBClassifier(random_state=2, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=50)\n\nxgb_model.fit(X_train, y_train)\nlog_accuracy_xgb=accuracy_score(y_test,xgb_model.predict(X_test))\nprint(f'The accuracy score for Bagging classifier is {log_accuracy_xgb*100}%')","84eca212":"models=pd.DataFrame({'Model':['LogisticRegression','DecisionTreeClassifier','RandomForestClassifier','GaussianNB','BaggingClassifier','GradientBoostingClassifier','XGBClassifier'],\n                     'Score':[log_accuracy,log_accuracy_decision_tree,log_accuracy_rfc,log_accuracy_GNB,log_accuracy_bagging_classifier,log_accuracy_GBC,log_accuracy_xgb]\n                    })","87d7df51":"models['Score']=models['Score']*100","c3d98b37":"models","b3a4b8df":"fig=plt.figure(figsize=(10,10))\nsns.barplot(x=models.Model,y=models.Score)\nplt.xticks(rotation=90)\nfig.show()","21b288b2":"# Density plots for the features and how they relate to the Potability","a42adf8c":"# Trying out different models","b5fa9876":"# Correlation Matrix","87a8ee30":"# Box Plots to visualize outliers","cc19a3ef":"# Analyzing Missing Values in the data set","6244587e":"# Adding descriptions for the Water Hardness","52312a2c":"# Creating Histograms to Analyze different features and their Outcome ","a9c941d9":"# Converting categorical variables to dummy variables for the model","3822ee89":"# Graphical view of how different models performed","296a5a87":"# Density Plots for Water Hardness","73940a08":"# Looking into the Data Frame","894cf6d5":"# Replacing missing values with the Mean"}}