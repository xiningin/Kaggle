{"cell_type":{"9d716986":"code","21c07168":"code","304a35b4":"code","1e4e34a3":"code","81068335":"code","8915f316":"code","913384ed":"code","b0da4dbb":"code","ac455c05":"code","899185f9":"code","23390a20":"code","704e15a8":"code","6bb8708d":"code","49c87468":"markdown","d0f18055":"markdown","57cae886":"markdown","5bcc9b38":"markdown","e27d5d85":"markdown","59107a41":"markdown"},"source":{"9d716986":"import numpy as np \nimport pandas as pd\nfrom collections import defaultdict\nfrom gensim.models import Word2Vec","21c07168":"pd.options.display.max_colwidth = 150","304a35b4":"df_jobs = pd.read_csv('\/kaggle\/input\/datathon-guess-the-last-one\/data_job_details.csv', index_col=0)\ndf_cvs = pd.read_csv('\/kaggle\/input\/datathon-guess-the-last-one\/data_cv_details.csv', index_col=0)\ndf_logs = pd.read_csv('\/kaggle\/input\/datathon-guess-the-last-one\/data_aday_log.csv', index_col=0)\ndf_preds = pd.read_csv('\/kaggle\/input\/datathon-guess-the-last-one\/son2_basvurular_test.csv')","1e4e34a3":"df_preds = df_preds.drop_duplicates('jobseekerId')","81068335":"sessions = []\n\nfor jobseeker in df_logs.groupby('jobseekerId'):\n    sessions.append([str(item) for item in jobseeker[1].jobId.values])\n    \nprint(f\"Total # of Sessions: {len(sessions)}\")","8915f316":"word_freq = defaultdict(int)\nfor sess in sessions:\n    for i in sess:\n        word_freq[i] += 1\n\nprint(f\"Total Unique jobIds: {len(word_freq)}\")","913384ed":"len_sessions = [len(x) for x in sessions]\nprint(f\"Sessions length:\\nMean: {np.mean(len_sessions):.2f},\\tMax: {np.max(len_sessions)},\\tMin: {np.min(len_sessions)}\\n\")\n\ntop10_jobIds = sorted(word_freq, key=word_freq.get, reverse=True)[:10]\nprint(f\"Top 10 Popular Job IDs: {top10_jobIds}\")","b0da4dbb":"### * Verbosity of gensim is controlled by logging modul, but Kaggle notebooks won't print logging.\n###   so if you want to see the progress you should run this locally or on google colab.\nimport logging  # Setting up the loggings to monitor gensim\nlogging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)","ac455c05":"import multiprocessing\ncores = multiprocessing.cpu_count() \nprint(f\"# of CPU cores: {cores}\")","899185f9":"w2v_model = Word2Vec(min_count=1, vector_size=100, sg=1, workers=cores-1)\nw2v_model.build_vocab(sessions, progress_per=10000)","23390a20":"w2v_model.train(sessions, total_examples=w2v_model.corpus_count, epochs=10, report_delay=1)","704e15a8":"job_col_headers = ['jobId', 'jobPosition', 'jobCity', 'minExperience', 'maxExperience']\n\ndef get_recommandations(job_seeker):\n    \"\"\"\n        Using this function we find top 10 jobIds which are most similar to job_seeker's past jobIds.\n        \n    \"\"\"\n    \n    ######################\n    print(\"User CV:\")\n    display(df_cvs[df_cvs.jobseekerId == job_seeker])\n    \n    ######################\n    past_jobids = df_logs.loc[df_logs.jobseekerId == job_seeker, 'jobId'].values\n    past_jobs = df_jobs.loc[df_jobs.jobId.isin(past_jobids), job_col_headers]\n    idx_temp = past_jobs.jobId.apply(lambda x: np.where(past_jobids == x)[0][0]).values\n    past_jobs.index = idx_temp\n    past_jobs = past_jobs.sort_index()\n    past_jobs['applicationDate'] = df_logs.loc[df_logs.jobseekerId == job_seeker, 'applicationDate'].values\n    past_jobids_idx = past_jobs.index\n    \n    print(f\"User already applied to {past_jobs.shape[0]} jobs \")\n    print(\"Recent 5 Jobs User Applied:\")\n    display(past_jobs.tail(5))\n    \n    ######################\n    recoms = w2v_model.wv.most_similar(positive=[str(x) for x in past_jobids if str(x) in w2v_model.wv])\n    df_recomm = pd.DataFrame(recoms, columns=['jobId', 'similarity'])\n    df_recomm.jobId = df_recomm.jobId.astype(np.int64)\n    df_jobs_user = df_jobs.loc[df_jobs.jobId.isin(df_recomm.jobId.values), job_col_headers].copy()\n    idx_temp = df_jobs_user.jobId.apply(lambda x: np.where(df_recomm.jobId.values == x)[0][0]).values\n    df_jobs_user.index = idx_temp\n    df_jobs_user = df_jobs_user.sort_index()\n    df_jobs_user['similarity'] = df_recomm.similarity.values\n    \n    print(\"Suggested jobs for user\")\n    print(df_jobs_user.shape)\n    display(df_jobs_user)","6bb8708d":"jobseeker_id = np.random.choice(df_logs.jobseekerId.values)\nget_recommandations(jobseeker_id)","49c87468":"## Dataset\nFirst we need to create a corpus to train our Prod2Vec model. \n\nlist of `jobId's` user already applied are going to make our sessions\/sentences.  ","d0f18055":"# Predicting Next Jobs","57cae886":"Now lets pick a random jobseeker_id from logs dataframe and recommend some jobs.","5bcc9b38":"# Intro\n\nIn this notebook I'm trying to demonestrate how we can achieve good results in the contest.\n\nThe method I'm going to use is called 'Prod2Vec', you can read more in [the original paper](https:\/\/arxiv.org\/pdf\/1606.07154.pdf).","e27d5d85":"# Jobs 2 Vectors\n\nNow we train our model to vectorize each JobId","59107a41":"# Data"}}