{"cell_type":{"ed5a6c40":"code","1a8c7d6a":"code","44b012eb":"code","fcac403f":"code","c2e76990":"code","2278083f":"code","8b2dd3f0":"code","1bddaec1":"code","1c23eeeb":"code","4eb755ac":"code","b1a5755a":"code","902df8cf":"code","ea4a45d8":"code","5df2632d":"code","da2b996a":"code","8ceca3fd":"code","f613b160":"code","5524311e":"code","1e7bd923":"code","f0b4f014":"code","13585500":"code","cd84d05e":"code","625393e5":"code","90433d93":"code","73176da8":"code","aa105012":"code","062ca008":"code","548fed7c":"code","0e694ca9":"code","41edf9aa":"markdown","0c989048":"markdown","59579d08":"markdown","8c9d9167":"markdown","27e4a07b":"markdown","840ab865":"markdown","1f546d1c":"markdown","eb3dcf02":"markdown","eaa0ca24":"markdown","873d6992":"markdown","7c51d7cd":"markdown","f3dc5e0a":"markdown","1589bfc9":"markdown","83934e5c":"markdown","65b06fab":"markdown","006d8024":"markdown","afb4c98d":"markdown"},"source":{"ed5a6c40":"# need TA-lib for technical analysis\n!pip install talib-binary\n\nimport numpy as np \nimport pandas as pd \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1a8c7d6a":"data_path = \"\/kaggle\/input\/minutebased-crypto-data-2020\/link-usd-2020.csv\"\ndf = pd.read_csv(data_path, parse_dates=True, index_col='time')\ndf.head()","44b012eb":"df.resample('min').mean().head()  #not done in place, just for demonstration","fcac403f":"# get info, length, date range, etc.. from data\ndf.info()","c2e76990":"#let's keep a copy of the raw data before resampling\ndf_raw = df.copy()\n\nresample_logic = {'low': 'min',\n                  'high': 'max',\n                  'open': 'first',\n                  'close': 'last',\n                  'volume': 'sum'}\n\nresampling_rate = '2H'\ndf = df.resample(resampling_rate).apply(resample_logic)\ndf.head()","2278083f":"df.isnull().sum()","8b2dd3f0":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ninit_notebook_mode(connected=True)\ncf.go_offline()","1bddaec1":"df['2020-10-01':].iplot(kind='candle')","1c23eeeb":"from statsmodels.tsa.seasonal import seasonal_decompose\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12, 8\n\nresult = seasonal_decompose(df['close'], model='mul')\nresult.plot(); ","4eb755ac":"# let's check the ADFuller test\nfrom statsmodels.tsa.stattools import adfuller\nadf = adfuller(df['close'])\nprint(f\"Dickey\u2013Fuller test p-value: {adf[1]}\")","b1a5755a":"df['percent_change'] = df['close'].pct_change() * 100\ndf['percent_change'].fillna(0, inplace=True)\n# for movement direction we use 1 for up and 0 for down\ndf['move'] = df['percent_change'].apply(lambda x: 0 if x <= 0 else 1)\ndf.head()","902df8cf":"df['percent_change'].iplot()\nadf2 = adfuller(df['percent_change'])\nprint(f\"Dickey\u2013Fuller test p-value on 'percent_change': {adf2[1]}\")","ea4a45d8":"#let's check again if there is more sense in the seasonality\npct_result = seasonal_decompose(df['percent_change'], model='add')  # model='mul' also works\npct_result.plot();","5df2632d":"#checking if the data is well balanced (as many ups and downs)\ndf['move'].value_counts()","da2b996a":"import talib as ta\n# exponential moving average\ndf['EMA10'] = ta.EMA(df.close, 10)\ndf['EMA50'] = ta.EMA(df.close, 50)\n# relative strength indicator (tells if an asset is overbought or oversold)\ndf['RSI28'] = ta.RSI(df.close, 28)\n# bollinger bands (lower and upper bands 2 standard deviation off the current price, based off a set rolling window)\n_, _, df['BBANDS_LOW'] = ta.BBANDS(df.close)  # use default parameters for Bollinger Bands","8ceca3fd":"df.tail()","f613b160":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12,12))\nsns.heatmap(df.corr(), annot=True)","5524311e":"# loading the other data\ncoins = ('btc', 'eth', 'xrp')\nfor coin in coins:\n    data_path = f\"\/kaggle\/input\/minutebased-crypto-data-2020\/{coin}-usd-2020.csv\"\n    dfc = pd.read_csv(data_path, parse_dates=True, index_col='time')\n    # resample like previous data\n    dfc = dfc.resample(resampling_rate).apply(resample_logic)\n    # rename volume and close to include the ticker so we can still know which close\/volume is which:\n    dfc.rename(columns={\"close\": f\"{coin}_close\", \"volume\": f\"{coin}_volume\"}, inplace=True)\n    # only keep close price and volume\n    dfc = dfc[[f\"{coin}_close\", f\"{coin}_volume\"]]  # ignore the other columns besides price and volume\n\n    df = df.join(dfc)","1e7bd923":"df.head()","f0b4f014":"# checking if there are any NaN values past the 50 first rows (which are expected to be NaN for EMA50)\ndf.iloc[49:].isnull().sum()","13585500":"# let's drop the rows containing NaN values\ndf.dropna(axis=0, inplace=True)\n# check if everything is ok\ndf.isnull().sum().sum()","cd84d05e":"# dropping unecessary data\ndf.drop(['low', 'high', 'open'], axis=1, inplace=True)","625393e5":"from sklearn.preprocessing import MinMaxScaler\n\ntest_len = 200\ntrain_len = len(df) - test_len\n\n# extract variables X and target labels y\nX = df\ny = df['move']\n\n# train\/test split the data\nX_train = X.iloc[:train_len]\nX_test = X.iloc[train_len:]\ny_train = y.iloc[:train_len]\ny_test = y.iloc[train_len:]\n\n# scale the data\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nscaled_X_train = scaler.transform(X_train)\nscaled_X_test = scaler.transform(X_test)","90433d93":"from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\nlength = 7*12   # 12 times 2 hours = 1 day, times 7 = 1 week\ngenerator = TimeseriesGenerator(scaled_X_train, y_train.values, length=length, batch_size=1)\nval_generator = TimeseriesGenerator(scaled_X_test, y_test.values, length=length, batch_size=1)","73176da8":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping","aa105012":"# define model\nmodel = Sequential()\nmodel.add(LSTM(32, input_shape=(length, scaled_X_train.shape[1]), activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(LSTM(16, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","062ca008":"model.summary()","548fed7c":"early_stop = EarlyStopping(monitor='val_loss',patience=2)\n# fit model\nmodel.fit(generator,\n          epochs=20,\n          validation_data=val_generator,\n          batch_size=64,\n          callbacks=[early_stop])","0e694ca9":"# Score model\nscore = model.evaluate(val_generator, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","41edf9aa":"Let's also explore the seasonal decomposition of the TimeSeries","0c989048":"The RSI seems like an interesting indicator to work with!","59579d08":"The seasonal_decompose is picking up a seasonal component, but there is strickly no reason for it and the period picked up does not make any sense. I would understand if we would start to see a weak weekly seasonal component because of correlation to the stock market.","8c9d9167":"Already we can see that there is some missing data (2020-01-01 00:01:00), which occurs when the exchange is down or if there were no transaction during that time. I am planning to resample hourly later on so I won't do anything about this for now. If you wanted to fix that right away, just resample the dataframe with the same frequency to create these missing lines, but then you would have to take care of the NaNs","27e4a07b":"# Load other cryptocurrency data","840ab865":"# Results","1f546d1c":"To resample the dataframe we need to create a custom function to handle how to deal with the different columns. The resampling is also made super simple because we are working with DateTimeIndex.","eb3dcf02":"The data is not stationnary. Not surprising considering the regular price increase over the year.\n\nNow let's create some new columns in the dataframe, in particular a percent change and movement direction, which we are going to try to predict later on when we set up a forecast model.","eaa0ca24":"Let's derive a few more columns with the technical analysis library (talib) to use to train our model on.","873d6992":"I like to use plotly to see this kind of financial data since one can hover over the data, zoom in and out, etc.. additionally I use cufflinks to use plotly directly off pandas dataframes. The idea is to call iplot() off the dataframe, and you get a beautiful responsive plotly plot.","7c51d7cd":"# Loading the LINK-USD data + EDA","f3dc5e0a":"# Setting up the forecasting model","1589bfc9":"We are not getting any NaN values meaning that there were not more than 2 hours consecutive missing data in our original dataframe. That's good","83934e5c":"Hey everyone,\n\nI have been interested in Chainlink for a while and wanted to set up a code to forecast its price evolution based on its past price as well as the past price of other important cryptocurrencies.\n\nMy current results for forecasting the next price movement (up or down) are really aweful and I hope I can get some inputs to improve the data fed to the model or the RNN model itself.","65b06fab":"The accuracy is really bad, in fact not better than by guessing at random. So I haven't analysed the results more. \n\nI would really appreciate any help in preparing the data or building the RNN to improve these results! Thanks","006d8024":"To make a forecast from TimeSeries data, it's useful to feed chronological sequences of data to predict a given label rather than just the last data available. I create sequences with the TimeseriesGenerator from tensorflow, which makes a sequence of length l from data t-l -> t and attaches the label to predict at t+1 (if batch_size=1), and then recursively through the whole data set.","afb4c98d":"Cryptocurrency prices are quite correlated, the question is which one is driving the market most. Let's use the price of some of the major currencies to train the model on as well, since an abrupt price change in BTC or ETH may be driving the price of LINK?"}}