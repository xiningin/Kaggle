{"cell_type":{"0340a8db":"code","64f9b649":"code","60a6437d":"code","b3368c36":"code","4057d8c1":"code","a89f1f1d":"code","6f433e77":"code","cae1382c":"code","b6323f47":"code","649124af":"code","066637d0":"code","0467c577":"code","10a8821d":"code","4a405f69":"code","e47e978e":"code","f52f5d71":"code","5f975705":"code","41c89bd9":"code","39af2b29":"code","44f958ed":"code","9e8a8ce4":"code","04cfb505":"code","a906d638":"code","4e672150":"code","3a79c363":"code","e07c9873":"code","6fd41e78":"code","e5ed333a":"code","b30d1db6":"code","e2411caf":"code","1ffd27b3":"code","2e46d5a4":"code","4b76827e":"code","709a0195":"code","a4756b4e":"code","454a0970":"code","8822ea29":"code","0e655ea6":"code","2e4621fa":"code","3266a20f":"code","349ba479":"code","bdf4180f":"code","17e19e0f":"code","fc117850":"code","bdd5dc1c":"code","7af10349":"code","1bf5dbbb":"code","bca178bc":"code","475bb836":"code","386b455c":"code","85f06111":"code","a6469049":"code","d89a1fba":"code","f6f92833":"code","d8c787ca":"code","6f24e236":"code","55ca0f79":"code","4c2ec6e2":"code","433a9ee4":"code","4fd63328":"code","06cf301d":"code","9f23130f":"code","5a306335":"code","ddc2f38e":"code","9c509a3e":"code","87255be5":"code","d052bc65":"code","0e6e5bb2":"code","e9902b86":"code","039eb9fa":"code","2e05f43f":"code","d22a3787":"code","a2d401f5":"code","aa53170b":"code","18649263":"code","99f16c73":"code","693b432d":"code","b2b4bffe":"code","6932ee35":"code","e40a6083":"code","c7aa892a":"code","13c030f6":"code","b281cc1b":"code","afa80c19":"code","83e14ed4":"code","c6b09bbd":"code","e13e7b02":"code","a2b8c13a":"markdown","bca9ecde":"markdown","0d0f205c":"markdown","22c3644a":"markdown","bf5dc77f":"markdown","1c4eee23":"markdown","ee8b98f4":"markdown","17786cc1":"markdown","760f3bd0":"markdown","0259ee71":"markdown","84c5d94e":"markdown","12cff83e":"markdown","2cb60edb":"markdown","0b163bd9":"markdown","26b812d2":"markdown","365fab7b":"markdown","199e2cda":"markdown","f263235d":"markdown","3fd32d59":"markdown","3f88cd3a":"markdown","66e3e3ee":"markdown","5a5798d3":"markdown","675a70be":"markdown","0045e40e":"markdown","76907b55":"markdown","1e2e3423":"markdown","bdfeabd9":"markdown","dde56efb":"markdown","3fb9bbdf":"markdown","de7990d9":"markdown","5e8dd725":"markdown","3853a15e":"markdown","2f4566e5":"markdown","4ce31d05":"markdown","58f9ada7":"markdown","01c06608":"markdown","97d033e4":"markdown","99833f74":"markdown","b386adcc":"markdown","0ed678d5":"markdown","d835a643":"markdown","09ae8c3c":"markdown","af72cd80":"markdown","128bc6c7":"markdown","f555655b":"markdown","6081ea69":"markdown","12d8de67":"markdown","0326d450":"markdown","b21c67ad":"markdown","a6fd3092":"markdown","c5abb335":"markdown","8cc9ea7e":"markdown","8ef7bbaf":"markdown","eabdd9f2":"markdown","eed63b5c":"markdown","bee7b4c8":"markdown","1c639ea5":"markdown","7d220576":"markdown","930eb888":"markdown","c94ad110":"markdown","79b4f016":"markdown","8bee3e35":"markdown","2a2c1dc7":"markdown","e40d1884":"markdown","743ba694":"markdown","1da6bf0c":"markdown","820eafcd":"markdown","6d8d1d71":"markdown","79f09dee":"markdown","ec91f324":"markdown","8699e506":"markdown","af0631b2":"markdown","1ad72f70":"markdown","0fbcc083":"markdown","21c1e708":"markdown","a74ec4a4":"markdown","3433ac10":"markdown","7e5b6157":"markdown","2857072f":"markdown","daec1790":"markdown","4ff22052":"markdown","bda4269e":"markdown","0357c78d":"markdown","90c14a47":"markdown","2b2af745":"markdown","dc0a02e1":"markdown","695fe841":"markdown","87b6903c":"markdown","4e71e16f":"markdown","e84fd4d9":"markdown","d5d06a62":"markdown","c6bf2eb7":"markdown","2284e81c":"markdown","b2c25af1":"markdown","07383369":"markdown","9bd28fe6":"markdown","4324a5a4":"markdown","d521c386":"markdown","86e4bd39":"markdown","72987fb1":"markdown","2c7ccd17":"markdown","05c389eb":"markdown","c49641b6":"markdown","e9c8087f":"markdown","23333418":"markdown","323ce194":"markdown","13c3f135":"markdown","84143d99":"markdown","1878f7ca":"markdown"},"source":{"0340a8db":"%matplotlib inline","64f9b649":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import make_scorer, f1_score, accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nfrom sklearn.cluster import KMeans","60a6437d":"pip install scikit-plot","b3368c36":"import scikitplot as skplt","4057d8c1":"obesity_data = pd.read_csv(\"..\/input\/obesity-levels\/ObesityDataSet_raw_and_data_sinthetic.csv\")","a89f1f1d":"obesity_data.head()","6f433e77":"obesity_data.shape","cae1382c":"obesity_data.info()","b6323f47":"def count_values(dataset, cat_variable, order = None):\n    \"\"\"\n    Function: Counts values in each category and displays them on a plot.\n    \n    Parameters: Dataset, category feature, and order of appearance (order is optional).\n    \"\"\"\n    ax = sns.countplot(x = cat_variable, data = dataset, palette = \"Blues_r\", order = order)\n    for p in ax.patches:\n        ax.annotate(f\"\\n{p.get_height()}\", (p.get_x()+0.2, p.get_height()), \n                    ha = \"center\", va = \"top\", color = \"white\", size = 10)\n    \n    plt.title(f\"Number of items in each {cat_variable} category\")\n    plt.show()","649124af":"count_values(obesity_data, \"Gender\")","066637d0":"def plot_distribution(dataset, feature):\n    \"\"\"\n    Function: Computes and displays distribution of features with continuous values; plots their mean and median.\n    \n    Parameters: Dataset and feature with continuous values.\n    \"\"\"\n    plt.hist(dataset[feature], bins = \"fd\")\n    \n    plt.axvline(dataset[feature].mean(), color = \"red\", label = \"mean\")\n    plt.axvline(dataset[feature].median(), color = \"orange\", label = \"median\")\n    \n    plt.xlabel(f\"{feature}\")\n    plt.ylabel(\"Count\")\n    plt.legend()\n    plt.title(f\"Distribution of values in {feature}\")\n    plt.show()","0467c577":"obesity_data[\"Age\"].describe()","10a8821d":"obesity_data[\"Age\"].median()","4a405f69":"plot_distribution(obesity_data, \"Age\")","e47e978e":"plot_distribution(obesity_data, \"Height\")","f52f5d71":"plot_distribution(obesity_data, \"Weight\")","5f975705":"plt.scatter(obesity_data[\"Height\"], obesity_data[\"Weight\"], alpha = 0.5)\nm, b = np.polyfit(obesity_data[\"Height\"], obesity_data[\"Weight\"], 1)\nplt.plot(obesity_data[\"Height\"], m * obesity_data[\"Height\"] + b, color = \"red\")\n\nplt.xlabel(\"Height [m]\")\nplt.ylabel(\"Weight [kg]\")\nplt.title(\"Correlation between 'Height' and 'Weight'\")\nplt.show()","41c89bd9":"count_values(obesity_data, \"family_history_with_overweight\")","39af2b29":"count_values(obesity_data, \"FAVC\")","44f958ed":"plot_distribution(obesity_data, \"FCVC\")","9e8a8ce4":"plot_distribution(obesity_data, \"NCP\")","04cfb505":"count_values(obesity_data, \"CAEC\", [\"no\", \"Sometimes\", \"Frequently\", \"Always\"])","a906d638":"count_values(obesity_data, \"SMOKE\")","4e672150":"plot_distribution(obesity_data, \"CH2O\")","3a79c363":"count_values(obesity_data, \"SCC\")","e07c9873":"plot_distribution(obesity_data, \"FAF\")","6fd41e78":"plot_distribution(obesity_data, \"TUE\")","e5ed333a":"count_values(obesity_data, \"CALC\")","b30d1db6":"plt.figure(figsize = (7, 4))\ncount_values(obesity_data, \"MTRANS\")","e2411caf":"plt.figure(figsize = (12, 5))\ncount_values(obesity_data, \"NObeyesdad\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]) ","1ffd27b3":"def cross_plot(dataset, lead_category, sup_category, order = None):\n    \"\"\"\n    Function: Plots interaction between two categorical variables.\n    \n    Parameters: Dataset, lead category, suplemental category, and order of appearance (order is optional).\n    \"\"\"\n    \n    sns.countplot(x = lead_category, hue = sup_category, data = dataset, order = order, palette = \"Blues_r\")\n    \n    plt.show()","2e46d5a4":"plt.figure(figsize = (13, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"Gender\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"])","4b76827e":"plt.figure(figsize = (13, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"family_history_with_overweight\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"])","709a0195":"plt.figure(figsize = (13, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"FAVC\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]) ","a4756b4e":"plt.figure(figsize = (18, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"CAEC\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]) ","454a0970":"plt.figure(figsize = (13, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"SMOKE\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]) ","8822ea29":"plt.figure(figsize = (13, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"SCC\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]) ","0e655ea6":"plt.figure(figsize = (18, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"CALC\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]) ","2e4621fa":"plt.figure(figsize = (18, 5))\ncross_plot(obesity_data, \"NObeyesdad\", \"MTRANS\", [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]) ","3266a20f":"obesity_data.describe().T","349ba479":"obesity_numeric = obesity_data[[\"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\"]]","bdf4180f":"fig, axs = plt.subplots(ncols = 4, nrows = 2, figsize = (20, 8))\n# fig.delaxes(axs[1][3])\nidx = 0\naxs = axs.flatten()\nfor k, v in obesity_numeric.items():\n    sns.boxplot(y = k, data = obesity_numeric, ax = axs[idx])\n    idx += 1\nplt.tight_layout(pad = 0.4, w_pad = 0.5, h_pad = 5.0)","17e19e0f":"plt.figure(figsize = (12, 10))\nsns.heatmap(obesity_data.corr(),\n           annot = True,\n           cmap = \"Blues_r\",\n           linewidths = 2, \n           linecolor = \"white\")\nplt.title(\"Correlation matrix of obesity data\")\nplt.show()","fc117850":"obesity_dummies = pd.get_dummies(obesity_data[[\"Gender\", \"family_history_with_overweight\", \"FAVC\", \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"]])","bdd5dc1c":"obesity_lab = obesity_data[[\"NObeyesdad\"]]","7af10349":"obesity_concatenated = pd.concat([obesity_numeric, obesity_dummies, obesity_lab], axis = 1)","1bf5dbbb":"obesity_concatenated.head()","bca178bc":"obesity_label = obesity_concatenated[\"NObeyesdad\"]\nobesity_features = obesity_concatenated.drop(\"NObeyesdad\", axis = 1)","475bb836":"obesity_label","386b455c":"obesity_features.info()","85f06111":"obesity_features = obesity_features.astype(\"float\")","a6469049":"obesity_features.dtypes","d89a1fba":"obesity_features_scaled = MinMaxScaler().fit_transform(obesity_features)","f6f92833":"obesity_features_scaled.min(axis = 1), obesity_features_scaled.max(axis = 1)","d8c787ca":"encoder = LabelEncoder()","6f24e236":"encoder.fit(obesity_label)","55ca0f79":"list(encoder.classes_)","4c2ec6e2":"obesity_labels_encoded = encoder.transform(obesity_label)","433a9ee4":"obesity_labels_encoded","4fd63328":"obesity_features_tr, obesity_features_ts, obesity_labels_tr, obesity_labels_ts = train_test_split(\n                obesity_features, obesity_labels_encoded, \n                test_size = 0.2, stratify = obesity_labels_encoded,\n                random_state = 42) # shuffle=True","06cf301d":"obesity_features_tr.shape, obesity_labels_tr.shape, obesity_features_ts.shape, obesity_labels_ts.shape","9f23130f":"Counter(obesity_labels_tr)","5a306335":"Counter(obesity_labels_ts)","ddc2f38e":"f1 = make_scorer(f1_score, average = \"weighted\")","9c509a3e":"params = {\n    \"max_depth\": [5, 7, 9, 11, 13, 15]\n}","87255be5":"grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid = params, cv = 5, scoring = f1)","d052bc65":"grid_search.fit(obesity_features_tr, obesity_labels_tr)","0e6e5bb2":"grid_search.cv_results_","e9902b86":"grid_search.best_params_","039eb9fa":"model_tree = DecisionTreeClassifier(max_depth = 13, random_state = 42)","2e05f43f":"def train_predict_score(estimator, train_features, train_labels, test_features, test_labels):\n    \"\"\"\n    Function: Trains model, predict classes and computes accuracy and f1 score.\n    \n    Parameters: estimator, X_train, y_train, X_test, y_test.\n    \"\"\"\n    estimator.fit(train_features, train_labels)\n    \n    print(f\"Accuracy on Train data: {accuracy_score(train_labels, estimator.predict(train_features))}\")\n    print(f\"F1 score on Train data: {f1_score(train_labels, estimator.predict(train_features), average = 'weighted')}\")\n    print(f\"Accuracy on Test data: {accuracy_score(test_labels, estimator.predict(test_features))}\")\n    print(f\"F1 on Test data: {f1_score(test_labels, estimator.predict(test_features), average = 'weighted')}\")","d22a3787":"train_predict_score(model_tree, obesity_features_tr, obesity_labels_tr, obesity_features_ts, obesity_labels_ts)","a2d401f5":"plt.figure(figsize = (22, 6))\nplot_tree(model_tree, max_depth = 2)\nplt.show()","aa53170b":"print(classification_report(obesity_labels_ts, model_tree.predict(obesity_features_ts)))","18649263":"model_tree.classes_","99f16c73":"list(encoder.classes_)","693b432d":"plt.figure(figsize = (8, 6))\nsns.heatmap(confusion_matrix(obesity_labels_ts, model_tree.predict(obesity_features_ts)),\n           annot = True,\n           fmt = \".0f\",\n           cmap = \"Blues_r\",\n           linewidths = 2, \n           linecolor = \"white\",\n           xticklabels = model_tree.classes_,\n           yticklabels = model_tree.classes_)\nplt.show()","b2b4bffe":"obesity_score_probability = model_tree.predict_proba(obesity_features_ts)","6932ee35":"obesity_score_probability","e40a6083":"roc_auc_score(obesity_labels_ts, obesity_score_probability, multi_class = \"ovr\")","c7aa892a":"skplt.metrics.plot_roc(obesity_labels_ts, obesity_score_probability)\nplt.show()","13c030f6":"kmeans = KMeans(n_clusters = 7, init = \"k-means++\")","b281cc1b":"model_tree.feature_importances_","afa80c19":"def plot_clusters(dataset, feature_one, feature_two, labels, title = None):\n    \"\"\"\n    Function: Computes and displays clusters.\n    \n    Parameters: dataset, 2 features, cluster indicator.\n    \"\"\"\n    sns.scatterplot(data = dataset, x = feature_one, y = feature_two, hue = labels, palette = \"Blues_r\")\n    if title is not None:\n        plt.title(title)\n    plt.show()","83e14ed4":"plot_clusters(obesity_features_ts, \"Height\", \"Weight\", obesity_labels_ts, \"Clusters in Test data\")","c6b09bbd":"predicted_labels = kmeans.fit_predict(obesity_features_ts)","e13e7b02":"plot_clusters(obesity_features_ts, \"Height\", \"Weight\", predicted_labels, \"Predicted clusters\")","a2b8c13a":"##### Overweight and means of transport","bca9ecde":"#### Consumption of high caloric food","0d0f205c":"# Exploring and modelling Obesity Dataset","22c3644a":"## I. Load data","bf5dc77f":"#### Age","1c4eee23":"Drinking water habits should have been categorised in three groups: \"Less than a litter\", \"Between 1 and 2 L\", and \"More than 2 L\". Instead, the answeres are entered as continuous values. Their distribution (not very informative, too) is shown below.","ee8b98f4":"`confusion_matrix` shows *actual* vs *predicted* labels. Rows represent actual classes, while columns represent predicted classes. For example, 47 samples were properly classified in the 0-th class but 7 were wrongly placed in 1-st class. Only one sample of class 4 was misclassified as a sample of class 3.","17786cc1":"#### Food between meals","760f3bd0":"### III.3 Convert Numerical Values","0259ee71":"People, according to their `Body mass index (BMI)`, are categorised as:\n\n* Underweight if BMI < 18.5\n* Normal if BMI 18.5 - 24.9 \n* Overweight if BMI 25.0 - 29.9\n* Obesity I if BMI 30.0 - 34.9\n* Obesity II if BMI 35.0 to 39.9\n* Obesity III if BMI > 40\n\nNumber of people per category is displayed below (note: categories are ordered logically).\n\nThe plot shows the dataset is balanced; only \"Obese Type I\" class slightly outnumber the other categories.","84c5d94e":"## III. Data pre-processing\n### III.1. Encoding Features","12cff83e":"The best model is a tree with 13 nodes (questions). Therefore, this value is set as a hyper-parameter. ","2cb60edb":"#### Transportation","0b163bd9":"The youngest person in the dataset is 14 years old, and the oldest one - 61 years of age. Values in this column are not normally distributed; the historgram is positively skewed with mean (24.31) and median (22.78) closer to the lower bound.","26b812d2":"Obesity is determined by computing the `Body mass index`. It is a function of person's height and weight. The exact formula is $Body mass index = \\frac{Weight}{Height * Height}$. Thus, height is an important element for determining obesity. \n\nDistribution of height values is plotted below. Most people are 1.60 m - 1.85 m tall. Both mean and median values are around 1.70. Still, height values do not seem to be normally distributed.","365fab7b":"#### Normal, Overweight or Obese?","199e2cda":"The code line below confirms the features hold only \"float64\" numbers now.","f263235d":"### III.4 Scale Features","3fd32d59":"Weight of those who \"frequently\" or \"always\" get food between meals does not seem to be abnormal. Only people having snaks from time to time go into \"Overweight\" or \"Obesity\" categories.","3f88cd3a":"## References:\n\n[1] Palechor, F. M., & de la Hoz Manotas, A. (2019). Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico. Data in Brief, 104344.","66e3e3ee":"#### Weight","5a5798d3":"It is interesting to see how Overweight\/Obesity interact with different categorical variables. The function below computes and plots this interaction.","675a70be":"### III.5 Encode Labels","0045e40e":"As mentioned earlier, part of the data were collected thought an online survey. Respondents had several options to answer each question. Features hold information gathered for each particular question and the corresponding possible answers. These are described and explored below.\n\nCounting and visualizing categorical variables is wrapped in a function for avoiding repeated operations. The first plot shows the number of men and women in the dataset.","76907b55":"Respondents were asked to share their physical activity. They had to choose 1 out of 4 optional answers: \"I do not have\", \"1 or 2 days\", \"2 or 4 days\", and \"4 or 5 days\". Values in \"FAF\" column are continuous instead of categorical ones. These are plotted below but their distribution (as well as mean and median) are hard for interpretation.","1e2e3423":"It seems obesity runs in the family. All those categorised as overweight or obese had family members suffering from weight problems.","bdfeabd9":"## V. Clustering ","dde56efb":"It would be interesting to see if there is any relationship between \"Height\" and \"Weight\" since both metrics are used to compute `Body mass index`. Furthermore, these are the most important features (see Chapter V) for predicting if a person suffers from overweight\/obesity.\n\nThe code line below plots each person's weight and height. The red line shows that there is a positive correlation between them, which means an increase in one variable leads to an increase in the other. In other words, taller people are more likely to weight more.","3fb9bbdf":"Both \"accuracy\" and \"f1 score\" on the training data are 100% but on the testing one is 91%-92%. The latter suggests the model is overfitting. Its performance could be improved either with regularization (e.g., shallower tree, setting minimum samples per leaf), or with feature selection (e.g., removing non-important columns), or with increasing the number of samples in both sets. Neither of these techniques is explored further since \"accuracy\" and \"f1 score\" over 90% is not so disappointing.","de7990d9":"#### Height","5e8dd725":"For clarity, `fit`, `predict`, and `score` are placed in a function, which facilitates model training, evaluation and selection. In this particular case it will only print Decision Tree's preformance in terms of its \"accuracy\" and \"f1 score\" on both sets. ","3853a15e":"Categorical variables are one-hot encoded with `get_dummies()`. Labels (i.e., the column holding information if a person is overweight\/obese or not) are stored in separate variable; it will be used later.","2f4566e5":"##### Overweight and alcohol","4ce31d05":"\"FCVC\" column denotes if people consume vegetables. Possible answers were \"Never\", \"Sometimes\", and \"Always\". It is not clear why values are numeric and not categorical (discrete) ones. It could be assumed that \"3\" means \"Always\", \"2\" - \"Sometimes\", and \"1\" - \"Never\", but it is not clear what the values inbetween mean.","58f9ada7":"Both normal weight and overweight\/obese people consume high calories food. Perhaps food quantity makes the difference and affects body fats.","01c06608":"A brief check shows that some columns hold \"float64\" numbers, and another - \"uint8\" values. Machine Learning algorithms work best with floating point numbers. For this reason, all values are converted into floats.","97d033e4":"## Conclusion","99833f74":"##### Overweight and family history","b386adcc":"### III.2 Separate Features and Labels","0ed678d5":"All three sets - numeric features, one-hot encoded ones, and labels are concatenated in a new DataFrame. It has 32 columns now. Its head rows are displayed below. ","d835a643":"`Counter` tells how many examples are placed in each class. The outputs below show that there are sufficient number of samples both in training and testing set. ","09ae8c3c":"A person's height and weight are the most important factors determining his\/her obesity status. Other factors might also play a role, e.g., eating habits and physical activity. Dataset features could be used both for classification and clustering tasks but it should be borne in mind that most samples are synthetically generated, i.e., they do not reflect the real world. Thus, robust conclusions require much more data representative for larger groups.","af72cd80":"A brief check confirms the dataset has 2111 rows and 17 columns.","128bc6c7":"There might exist a weak link between alcohol and obesity. The data suggest that people who \"sometimes\" drink alcohol could face weight propblems.","f555655b":"ROC Curves are ploted below. They climb up and to the left, which indicates a good model performance. As found earlier, the model best predicts class 4 (light green line), class 6 (red line) and class 0 (black line). AUCs for all classes are displayed on the legend.","6081ea69":"Classes on both plots differ since the clustering algorithm does not know how to order them (i.e., which predicted values correspond to class 0, which - to class 1, etc.). Nonetheless, KMeans managed to group \"Height\" and \"Weight\" points in 7 categories which very much overlap the testing labels.","12d8de67":"Most respondents do not smoke.","0326d450":"Aggregated AUC score for all classes (computed as \"One vs Rest\") is around 95%. This is not so bad performance.","b21c67ad":"An experiment was made to use dataset's features clustering. Forming separate clusters would indicate that values for the given features are specific for particular overweight\/obesity type. The task is performed with \"KMeans\" - the simplest clustering algorithm. Instantiating requires setting the number of clusters to form, as well as the number of centroids to generate. Number of clusters is known: 7, for each weight type. \"K-means++\" is the chosen method for initialization - it selects initial cluster centers in a smart way to speed up convergence.","a6fd3092":"#### Imports","c5abb335":"##### Confusion Matrix","8cc9ea7e":"There are almost an equal number of females and males in the dataset. Data is available for slightly more men than women but this does not make it imbalanced.","8ef7bbaf":"Most people (around 3\/4) rely on public transportation. Much fewer respondents use their cars. The remainder either commute or use a bike or motorbike.","eabdd9f2":"##### ROC Score and Curve","eed63b5c":"##### Classification Report","bee7b4c8":"### II. 2. Explore Statistics","1c639ea5":"The output below shows that there are not missing values in the DataFrame; half of the features hold numeric (float64) values, and the other half - categorical ones. All are further explored in this Chapter. In general, the dataset is tidy, hence data cleaning was not neccessary.","7d220576":"The first modelling task is to classify data into obesity categories. \"Accuracy\" is a good performance metric but \"f1 score\" (geometric mean of \"precision\" and \"recall\") is a more appropriate one. To use it for grid search and cross validation, it is instantiated as a variable. \n\nIt could be assumed that many classifiers would return good scores. `DecisionTreeClassifier()` is chosen for its simplicity and interpretability. It has several hyper-parameters, which could be tuned but only tree's depth was used.\n\n`RandomSearchCV()` checks which combination returns best results. The grid space is limited between 5 and 15 tree nodes (questions). These are stored in a dictionary, which is passed to for searching. Models are trained and cross-validated on 5 folds.","930eb888":"Survey respondents had to say if they eat high caloric food frequenty. There were only two possible answers: \"yes\" or \"no\". Most of them (ca. 88%) admitted they consume high caloric food.","c94ad110":"#### Smoke","79b4f016":"##### Overweight and smoking","8bee3e35":"(Linear) correlation between numeric features is weak or nonexistent. Thus, all features remain in the table.","2a2c1dc7":"Cross-validation shows that almost all combinations reach \"f1 score\" close to or above 90%. ","e40d1884":"Most people drink alcohol \"sometimes\", but almost a third claim they do not consume any alcoholic beverages.","743ba694":"People had to say if and how offen they eat between meals. They could answer eigher \"No\" (if they do not get bites between regular time for eating), or \"Sometimes\", \"Frequently\", or \"Always\". The data suggests that most people \"sometimes\" get small snacks between meals.","1da6bf0c":"It seems smoking is not a predictor or does not affect body weight. There is a tiny number of smokers who could be both normal and overweight.","820eafcd":"Features and their projection should be visualized to show how clustering works. However, displaying more than 3 dimensions on a 2D surface is impossible. For this reason, only the most important features (i.e., those holding the most valuable information) are shown. `DecisionTreeClassifier()` found that the second (\"Height\") and the third (\"Weight\") columns are the most important ones. They bear 21.9% and 47.85%, respectively, of the information in the data. The output below also shows that values in some columns were not beneficial for revealing their relationship with obesity and could have been removed.","6d8d1d71":"It seems people do not worry about the calories they get daily. On the other hand, they might not have been aware of the nutritional value and ingredients of each food if these were not listed on the packing.","79f09dee":"## II. Exploratory Data Analysis","ec91f324":"### II. 1. Explore Features","8699e506":"Features and labels are separated and stored in different variables.","af0631b2":"### IV. 1 Build Model","1ad72f70":"##### Overweight and monitoring calories","0fbcc083":"#### Drink water","21c1e708":"Similarly, repondents had to point the number of main meals they have daily: \"Between 1 and 2\",  \"Three\", and \"More than three\". Instead of categorical, this feature also holds numerical values. Mean and median are not informative here either.","a74ec4a4":"#### Gender","3433ac10":"`classification_report` is a `scikit learn` function which shows classification success (metrics) for each class. For example, most of the samples in \"Obesity_Type_III\" (class 4) were properly classified. The model reached 100% \"precision\" and 99% \"f1 score\". On the other hand, features indicating \"Normal_Weight\" (class 1) were wrongly interpreted and got around 80% on \"precision\" and \"f1 score\". ","7e5b6157":"The boxplots below show quartiles and outliers. Distributions in the last 5 columns are not taken into account. \n\nThe first boxplot suggests that there are outliers in the \"Age\" column. However, 40, 50 or 60 years of age are normal values (they are not extreme or errors) and for this reason these are not removed. \"Height\" does not seem to have outliers, and \"Weight\" has only a couple ones. These are not treated either.","2857072f":"People who tend to monitor their calories intake are less likely to get excess weight.","daec1790":"Transportation seems does not (significantly) affect a person's weight. Both slim, normal and overweight people use public transport; all groups rely on cars as well.","4ff22052":"The dataset is split into training and testing sets. A validation set was not withheld since the dataset is small and sufficient number of samples should be kept for training. Cross validation during Grid Search addresses this drawback. \n\nSplitting function (`train_test_split`) shuffles the data and reserves 20% for testing. Datasets' shape after splitting is checked below.","bda4269e":"Five-number statistics does not reveal much information about features with numeric values. Data in most columns (except age, height and weight) are not interpretable. Nonetheless, these are displayed below.","0357c78d":"#### Monitor intake of calories ","90c14a47":"#### Does overweight run in the family? ","2b2af745":"This Notebook explores the *Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico*[1] published on the University of California Irvine Machine Learning Repository ([link to the dataset](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition+)). \"ScienceDirect\" provides free access to the corresponding [paper](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S2352340919306985?via%3Dihub).\n\nThe dataset has 2111 records and 17 features. The records are labeled with the class variable \"NObesity\" (Obesity Level) that allows classification in 7 groups: \"Insufficient Weight\", \"Normal Weight\", \"Overweight Level I\", \"Overweight Level II\", \"Obesity Type I\", \"Obesity Type II\" and \"Obesity Type III\". The dataset authors note that 23% of the records were collected directly from users through a web platform, and the remaining 77% were generated synthetically with Weka tool and SMOTE filter.\n\nEating habits, physical activity, and genes are factors which affect person's obesity predisposition. The task here is to explore the dataset, and to find a decent model that would be capable to tell if someone is overweight or obese, or his or her body fits into the normal (health) range. On the other hand, an attempt was made to cluster the data based on all features (predictors). Both - classification and clustering - tasks are described after data exploration.","dc0a02e1":"The original data are provided in a `csv` file. It is loaded and stored in `obesity_data`. The first five rows are displayed below.","695fe841":"### III.6 Train - Test split","87b6903c":"People were asked if family members suffered from overweight. Most of them replied affirmative.","4e71e16f":"The first sample has the highest probability of being 0-th class, the second - 1-st class, and so forth.","e84fd4d9":"Similarly, people were asked to state how much time they spend on using technological devices such as cell phone, videogames, television, computer, etc. They could say \"0-2 hours\", \"3-5 hours\", and \"More than 5 hours\". Responses are stored as continuous values. Their distribution, which could not be interepreted, is shown below.","d5d06a62":"Values in all features should be in the same range. Otherwise, the algorithm might misinterpret and assign them wrong coefficients (weights). Obesity features are scaled with `MinMaxScaler()` which makes all values between 0 and 1. The second row confirms the scaling was successful.","c6bf2eb7":"#### Drink alcohol","2284e81c":"#### Physical INactivity","b2c25af1":"## IV. Train model to classify data into obesity categories","07383369":"Women are more likely to have \"Insufficient weight\" than men. On the other hand, there are more obese men than women, save in the last, extreme obesity category.","9bd28fe6":"##### Overweight and high calories food","4324a5a4":"Another popular classification metric is the ROC curve (Receiver Operating Characteristic curve). It is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate. Area Under the Curve (AUC) represents the probability that a random positive example is positioned to the right of a random negative example. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.\n\nAUC and ROC curve require computing probability prediction scores. These show the probability a certain sample belongs to a particular class.","d521c386":"##### Overweight and food between meals","86e4bd39":"#### Meals per day","72987fb1":"Clusters (formed by \"Height\" and \"Weight\" features) in the testing data according to their real labels are plotted below. ","2c7ccd17":"Decision trees are easier to interpret. If plotted (see below), they show how decisions were taken (i.e., how classification happened). Each node \"asks\" a question; if the response is \"True\", the information is transmitted to the child node on the left; if it is \"False\", information goes to the child on the right. This process continues either until no more questions could be asked, or until reaching \"max_depth\" limit. Only the first 2 nodes are displayed below.","05c389eb":"Most Machine Learning classification algorithms expect labels with numeric values (and not strings). For this reason, obesity class is encoded with `LabelEncoder()`. The latter replaces each class with an integer. \n\nFirst, the encoder is instantiated. Then, it \"overviews\" the data. `transform()` encodes the classes and assigns them the respective number.","c49641b6":"`KMeans` computes the distances between each point (described by feature values) and assigns it to a cluster. Thus, clustering could be considered an unsupervised learning classification tool (algorithm). However, its performance could not assessed since there are not evaluation metrics for unsuprevised training. ","e9c8087f":"### IV. 2. Train and Evaluate Model","23333418":"##### Overweight and Gender","323ce194":"#### Physical activity","13c3f135":"Computing and visualizing distribution of continuous values is wrapped in a function, too. It displays not only data distribution but also its mean and median.","84143d99":"#### Consumption of vegetables","1878f7ca":"Weight does not offer interesting observations. Distribution is more or less bi-modal; the mean and the median are shifted to the left because of the larger number of people weighting 80 kg. "}}