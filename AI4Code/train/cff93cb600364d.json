{"cell_type":{"ca7d7483":"code","fbb825d9":"code","1df5d996":"code","09f5d293":"code","f8d56efb":"code","adde08c8":"code","f9e8f3b0":"code","fc1e82aa":"code","0d15eff6":"code","8ec48ce0":"code","ee8ce52d":"code","4d582f2e":"code","2c3a57f5":"code","06d73ca8":"code","4408d61e":"code","1d6da4fa":"code","a36cfdcf":"code","52c610dc":"code","8696c24c":"code","e8277f97":"code","7e4c0dc1":"code","57c6266d":"code","95c270f0":"code","bb0d1126":"code","f5e94cfb":"code","9178fa24":"code","ac05eef6":"code","d0637589":"code","c9934a80":"code","1eb96e22":"code","354c0a7d":"code","3e27c236":"markdown","dd2fd539":"markdown","bd649da0":"markdown","944bd2d0":"markdown","463cfaab":"markdown","d7bc4a31":"markdown","62f8e0e6":"markdown","795eb41a":"markdown","63e9953b":"markdown","7f4bc46b":"markdown","4390c804":"markdown","1ae7b5c9":"markdown","8e5036ba":"markdown","6a09abe2":"markdown"},"source":{"ca7d7483":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom jcopml.plot import plot_correlation_matrix, plot_missing_value\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fbb825d9":"df = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\", index_col=\"Id\")\ndf.head()","1df5d996":"df.shape","09f5d293":"plot_missing_value(df, return_df=True).sort_values(\"missing_value\", ascending=False).head(20)","f8d56efb":"df.drop(columns=[\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"LotFrontage\"], inplace=True)\ndf.shape","adde08c8":"df['SalePrice'].isna().sum()","f9e8f3b0":"print(df[\"SalePrice\"].describe())\nplt.figure(figsize=(8, 4))\nax = sns.distplot(df[\"SalePrice\"], bins=200)","fc1e82aa":"filt = df[\"SalePrice\"] < 400000\ndf = df.loc[filt]\ndf.shape","0d15eff6":"# New Histogram\nprint(df[\"SalePrice\"].describe())\nplt.figure(figsize=(8, 4))\nax = sns.distplot(df[\"SalePrice\"], bins=200)","8ec48ce0":"plot_correlation_matrix(df, \"SalePrice\")","ee8ce52d":"correlation = df.corr()\nn = 9\ncols = correlation.nlargest(n, 'SalePrice')['SalePrice'].index\ndf_cor = np.corrcoef(df[cols].values.T)\n\nplt.figure(figsize=(8, 5))\nax = sns.heatmap(df_cor, cbar=True, annot=True, fmt='.1f', yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","4d582f2e":"df_new = df[[\"YearBuilt\", \"OverallQual\", \"GrLivArea\", \"GarageCars\", \"GarageArea\", \"TotalBsmtSF\", \"1stFlrSF\", \"FullBath\", \"SalePrice\"]]","2c3a57f5":"df_new.head(3)","06d73ca8":"sns.pairplot(df_new)","4408d61e":"f, axes = plt.subplots(4, 2, figsize=(15, 15), sharex=False)\nax = sns.scatterplot(x=\"YearBuilt\", y=\"SalePrice\", data=df_new, hue=\"OverallQual\", ax = axes[0, 0])\nax = sns.scatterplot(x=\"GrLivArea\", y=\"SalePrice\", data=df_new, hue=\"OverallQual\", ax = axes[0, 1])\nax = sns.scatterplot(x=\"GarageArea\", y=\"SalePrice\", data=df_new, hue=\"OverallQual\", ax = axes[1, 0])\nax = sns.scatterplot(x=\"TotalBsmtSF\", y=\"SalePrice\", data=df_new, hue=\"OverallQual\", ax = axes[1, 1])\nax = sns.scatterplot(x=\"1stFlrSF\", y=\"SalePrice\", data=df_new, hue=\"OverallQual\", ax = axes[2, 0])\nax = sns.boxplot(x=\"FullBath\", y=\"SalePrice\", data=df_new, ax=axes[2, 1])\nax = sns.boxplot(x=\"GarageCars\", y=\"SalePrice\", data=df_new, ax=axes[3, 0])\nax = sns.boxplot(x=\"OverallQual\", y=\"SalePrice\", data=df_new, ax=axes[3, 1])","1d6da4fa":"f, axes = plt.subplots(4, 2, figsize=(15, 15), sharex=False)\nax = sns.distplot(df[\"YearBuilt\"], bins=100, ax = axes[0, 0], color='r')\nax = sns.distplot(df[\"OverallQual\"], bins=10, ax = axes[0, 1], color='g')\nax = sns.distplot(df[\"GrLivArea\"], bins=100, ax = axes[1, 0], color='b')\nax = sns.distplot(df[\"GarageCars\"], bins=5, ax = axes[1, 1])\nax = sns.distplot(df[\"GarageArea\"], bins=100, ax = axes[2, 0])\nax = sns.distplot(df[\"TotalBsmtSF\"], bins=100, ax = axes[2, 1], color='r')\nax = sns.distplot(df[\"1stFlrSF\"], bins=100, ax = axes[3, 0], color='g')\nax = sns.distplot(df[\"FullBath\"], bins=10, ax = axes[3, 1], color='b')","a36cfdcf":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom jcopml.pipeline import num_pipe, cat_pipe\nfrom jcopml.utils import save_model, load_model\nfrom jcopml.plot import plot_missing_value\nfrom jcopml.feature_importance import mean_score_decrease, mean_loss_decrease","52c610dc":"# Separate the features and target columns\nX = df_new.drop(columns=[\"SalePrice\"])\ny = df_new[\"SalePrice\"]\n\n# Create data train and data test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","8696c24c":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","e8277f97":"preprocessor = ColumnTransformer([\n    ('numeric', num_pipe(poly=2), X_train.columns)\n])\n\npipeline = Pipeline([\n    ('prep', preprocessor),\n    ('algo', RandomForestRegressor(n_jobs=-1, random_state=42))\n])\n\nparameter_tune = {\n    'prep__numeric__poly__degree': [2, 3, 4],\n    'prep__numeric__poly__interaction_only': [False, True],\n    'algo__n_estimators': [220, 240],\n    'algo__max_depth': [20, 50, 80],\n    'algo__max_features': [0.5, 0.6, 0.8],\n    'algo__min_samples_leaf': [1, 2, 3]\n}\n\nmodel_rf = RandomizedSearchCV(pipeline, parameter_tune, cv=3, n_iter=100,n_jobs=-1, verbose=1)\nmodel_rf.fit(X_train, y_train)\n\nprint(model_rf.best_params_)\nprint(model_rf.score(X_train, y_train), model_rf.best_score_, model_rf.score(X_test, y_test))","7e4c0dc1":"preprocessor = ColumnTransformer([\n    ('numeric', num_pipe(poly=2), X_train.columns)\n])\n\npipeline = Pipeline([\n    ('prep', preprocessor),\n    ('algo', RandomForestRegressor(n_jobs=-1, random_state=42))\n])\n\nparameter_tune = {\n    'prep__numeric__poly__degree': [3],\n    'prep__numeric__poly__interaction_only': [False, True],\n    'algo__n_estimators': [260, 280],\n    'algo__max_depth': [80, 100],\n    'algo__max_features': [0.6, 0.8],\n    'algo__min_samples_leaf': [2]\n}\n\nmodel_rf = GridSearchCV(pipeline, parameter_tune, cv=3, n_jobs=-1, verbose=1)\nmodel_rf.fit(X_train, y_train)\n\nprint(model_rf.best_params_)\nprint(model_rf.score(X_train, y_train), model_rf.best_score_, model_rf.score(X_test, y_test))","57c6266d":"df_imp = mean_score_decrease(X_train, y_train, model_rf, plot=True, topk=10)","95c270f0":"from jcopml.plot import plot_actual_vs_prediction, plot_residual","bb0d1126":"plot_actual_vs_prediction(X_train, y_train, X_test, y_test, model_rf)","f5e94cfb":"plot_residual(X_train, y_train, X_test, y_test, model_rf)","9178fa24":"from xgboost import XGBRegressor","ac05eef6":"preprocessor = ColumnTransformer([\n    ('numeric', num_pipe(poly=2), X_train.columns)\n])\n\npipeline = Pipeline([\n    ('prep', preprocessor),\n    ('algo', XGBRegressor(n_jobs=-1, random_state=42))\n])\n\nparameter_tune = {\n    'algo__max_depth': [100],\n    'algo__colsample_bytree': [0.8],\n    'algo__n_estimators': [220],\n    'algo__subsample': [0.8],\n    'algo__gamma': [1, 5, 10],\n    'algo__learning_rate': [0.01, 0.1, 1],\n    'algo__reg_alpha': [0.01, 0.1],\n    'algo__reg_lambda': [0.01, 0.1, 10] \n}\n\nmodel_rf = GridSearchCV(pipeline, parameter_tune, cv=3, n_jobs=-1, verbose=1)\nmodel_rf.fit(X_train, y_train)\n\nprint(model_rf.best_params_)\nprint(model_rf.score(X_train, y_train), model_rf.best_score_, model_rf.score(X_test, y_test))","d0637589":"preprocessor = ColumnTransformer([\n    ('numeric', num_pipe(poly=2), X_train.columns)\n])\n\npipeline = Pipeline([\n    ('prep', preprocessor),\n    ('algo', XGBRegressor(n_jobs=-1, random_state=42))\n])\n\nparameter_tune = {\n    'prep__numeric__poly__degree': [3],\n    'prep__numeric__poly__interaction_only': [True, False],\n    'algo__max_depth': [100],\n    'algo__colsample_bytree': [0.8],\n    'algo__n_estimators': [220],\n    'algo__subsample': [0.8],\n    'algo__gamma': [1, 2],\n    'algo__learning_rate': [0.2],\n    'algo__reg_alpha': [10],\n    'algo__reg_lambda': [35] \n}\n\nmodel_xgb = GridSearchCV(pipeline, parameter_tune, cv=3, n_jobs=-1, verbose=1)\nmodel_xgb.fit(X_train, y_train)\n\nprint(model_xgb.best_params_)\nprint(model_xgb.score(X_train, y_train), model_xgb.best_score_, model_xgb.score(X_test, y_test))","c9934a80":"df_imp = mean_score_decrease(X_train, y_train, model_xgb, plot=True, topk=10)","1eb96e22":"plot_actual_vs_prediction(X_train, y_train, X_test, y_test, model_xgb)","354c0a7d":"plot_residual(X_train, y_train, X_test, y_test, model_rf)","3e27c236":"### Let's see the target value -  SalePrice","dd2fd539":"### Pair Plot","bd649da0":"# Modeling - Random Forest","944bd2d0":"# Random Forest Model Evaluation","463cfaab":"### PLot Correlation Matrix","d7bc4a31":"# Simple EDA\n### Check Missing Value","62f8e0e6":"### SalePrice Histogram","795eb41a":"# Import Datasets","63e9953b":"### Delete some columns which have missing value","7f4bc46b":"### Numeric Columns","4390c804":"# XgBoost Model Evaluation","1ae7b5c9":"# Modeling - XgBoost","8e5036ba":"Improving","6a09abe2":"# Datasets Splitting"}}