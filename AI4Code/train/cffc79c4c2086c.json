{"cell_type":{"4b709ac5":"code","79e5aca2":"code","9f61d05f":"code","a0ceedb9":"code","d5144906":"code","80a7d13d":"code","9d739a1c":"code","960c6a30":"code","b14ef605":"code","12a4d5c6":"code","8d122060":"code","d874cd28":"code","b3c25436":"code","cb76b77a":"code","d140ae30":"code","d16d8f4c":"code","ab87f222":"code","0b9ce2bc":"code","b5d278aa":"code","0b6be7c1":"code","d4464d53":"code","b038fdb4":"markdown","93424681":"markdown","eb53e8ec":"markdown","e5118ddc":"markdown","fd3178e2":"markdown","d6ed1aeb":"markdown","23c028b8":"markdown","98706508":"markdown","24404b39":"markdown","7ffe246e":"markdown","ee194cb2":"markdown","66293031":"markdown","a650ef26":"markdown","53318105":"markdown","25cd86ea":"markdown","37f3b08a":"markdown","85bdea98":"markdown","7f523c40":"markdown","35bb00cf":"markdown","ee02b895":"markdown","1f3d7af3":"markdown","85a2bc46":"markdown","be67b28c":"markdown","b632f25d":"markdown","815c27b9":"markdown","27989d43":"markdown"},"source":{"4b709ac5":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","79e5aca2":"df_train = pd.read_csv('..\/input\/30-days-of-ml\/train.csv', index_col='id')\ndf_test = pd.read_csv('..\/input\/30-days-of-ml\/test.csv', index_col='id')\ndf_submission = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv', index_col='id')","9f61d05f":"print(\"Train Data Size: \",df_train.shape)\nprint(\"=\" * 30)\nprint(\"Test Data Size: \",df_test.shape)","a0ceedb9":"plt.style.use('seaborn')\nplt.figure(figsize=(14,8))\nax = sns.histplot(x='target', data=df_train,bins=90,\n                   color=\"#801e8f\",\n                   edgecolor=\"white\")\nax.set_title(\"Histogram of Target Feature\", fontsize=18)\n\nplt.show()","d5144906":"df_train.dtypes.value_counts()","80a7d13d":"df_train.iloc[:5,:]","9d739a1c":"msno.matrix(df_train,figsize=(15,6),color=(0.3, 0.0, 0.4),fontsize=8)\nplt.show()","960c6a30":"\ndef change_width(ax, new_value,recenter=False) :\n    for patch in ax.patches :\n        current_width = patch.get_width()\n        diff = current_width - new_value\n        patch.set_width(new_value)\n        if recenter==True:  \n            patch.set_x(patch.get_x() + diff * .5)","b14ef605":"# list of continuous feature\nfeatures = [*df_train.columns[:9]]\n# we will look into the features distribution now, to get insight into the data\ni = 1\nplt.figure()\nfig, ax = plt.subplots(3, 3,figsize=(14, 24))\nfig.suptitle('Count plot for Categorical Features', fontsize=18, y=0.9)\nfor feature in features:\n    plt.subplot(3, 3,i)\n    ax1 = sns.countplot(df_train[feature],color=\"#08ccc5\", label='train')\n    change_width(ax1, 0.35)\n    ax2 = sns.countplot(df_test[feature],color=\"#780770\", label='test')\n    change_width(ax2, 0.35)\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\n\nplt.show()","12a4d5c6":"# list of continuous feature\nfeatures = [*df_train.columns[10:-1]]\n# we will look into the features distribution now, to get insight into the data\ni = 1\nplt.figure()\nfig, ax = plt.subplots(5, 3,figsize=(14, 24))\nfig.suptitle('Distrbution plot for Numerical Features', fontsize=18, y=0.9)\nfor feature in features:\n    plt.subplot(5, 3,i)\n    sns.distplot(df_train[feature],color=\"blue\", kde=True,bins=100, label='train')\n    sns.distplot(df_test[feature],color=\"green\", kde=True,bins=100, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\n    \nplt.subplot(5, 3,i)\n_ = sns.distplot(df_train['target'],color=\"blue\", kde=True,bins=100, label='train')\nplt.legend()\nplt.show()","8d122060":"# list of continuous feature\ncolumns = [*df_train.columns[10:]]\n# calculate correlation matrix.\ncorrMatt = df_train[columns].corr()\nmask = np.array(corrMatt)\nmask[np.tril_indices_from(mask)] = False\nfig,ax= plt.subplots()\nfig.set_size_inches(14,14)\ng = sns.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True, )\ng.set_title(\"Correlation between Numerical Features with Target\", fontsize=16, y=1.05)\nplt.show()","d874cd28":"\nfor col in df_train.columns[:10]:\n    df_train[col] = df_train[col].astype('category')\n    df_test[col] = df_test[col].astype('category')\ndf_train.dtypes.value_counts()","b3c25436":"for col in df_train.columns[:10]:\n    col_name = []\n    for i in df_train[col].unique():\n        col_name.append(col+\"_\"+i)\n        \n    df_train[col].replace(df_train[col].unique(), col_name, inplace=True)\n    df_test[col].replace(df_test[col].unique(), col_name, inplace=True)\n    \n    train_dummies_col = pd.get_dummies(df_train[col], drop_first=True)\n    test_dummies_col = pd.get_dummies(df_test[col], drop_first=True)\n    \n    df_train = pd.concat([df_train, train_dummies_col],axis=1)\n    df_test = pd.concat([df_test, test_dummies_col],axis=1)\n    \n    df_train.drop(col, axis=1, inplace=True)\n    df_test.drop(col, axis=1, inplace=True)","cb76b77a":"df_train.columns","d140ae30":"pd.DataFrame(df_train[df_train.columns[:15]].corr()['target'].sort_values(ascending=False))","d16d8f4c":"columns = df_train.columns.tolist()\ncolumns.append(columns.pop(14))\ndf_train = df_train[columns]","ab87f222":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(df_train.drop('target', axis=1),df_train.target,\n                                                  test_size=0.2, random_state=42)\nX_test = df_test","0b9ce2bc":"from sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nparams = {'n_estimators': 10000,\n          'learning_rate': 0.35,\n          'subsample': 0.926,\n          'colsample_bytree': 0.84,\n          'max_depth': 2,\n          'booster': 'gbtree', \n          'reg_lambda': 35.1,\n          'reg_alpha': 34.9,\n          'random_state': 42,\n          'n_jobs': 4}\nmodel = XGBRegressor(**params)\n# These three parameters will stop training before a model starts overfitting  \nmodel.fit(X_train, y_train,verbose=False,\n              eval_set=[(X_train, y_train), (X_val, y_val)],eval_metric=\"rmse\",early_stopping_rounds=100)\n\nprint(\"Train Loss = \",np.sqrt(mean_squared_error(y_train, model.predict(X_train))))\nprint(\"Validation Loss = \",np.sqrt(mean_squared_error(y_val, model.predict(X_val))))","b5d278aa":"model.score(X_train, y_train)","0b6be7c1":"df_submission.target = model.predict(X_test)","d4464d53":"df_submission.to_csv('submission.csv')","b038fdb4":"# Data Summary","93424681":"**Read Datasets**","eb53e8ec":"- *There is no Missing values on data*","e5118ddc":"- **Count Plot for Categorical Features**","fd3178e2":"**Import Necessary Librariess**","d6ed1aeb":"# Visualization","23c028b8":"- **Display Sample of Train Data**","98706508":"- **Save Prediction**","24404b39":"# Modeling","7ffe246e":"- **Get Dummies for Category Features**","ee194cb2":"- **Correlation**","66293031":"- **Train Model**","a650ef26":"### Thanks For Read My NoteBook :)","53318105":"- **Model Score**","25cd86ea":"- **Plot Histogram Of Target**","37f3b08a":"- **Split Train Data**","85bdea98":"![](https:\/\/github.com\/MhmdSyd\/needed_image\/blob\/main\/30_Days_ML.png?raw=true)","7f523c40":"# Missing Value Analysis","35bb00cf":"## 30 Day Challenge \ud83c\udfc3\ud83c\udffb\u200d\u2642\ufe0f | EDA and Model Building \ud83d\udd25","ee02b895":"- **Prediction**","1f3d7af3":"# Feature Engineering","85a2bc46":"**The notebook is structured in the following way:**\n\n> Data Summary.\n\n> Missing Value Analysis.\n\n> Visualization.\n\n> Feature Engineering.\n\n> Modeling.\n","be67b28c":"- **DistPlot for Numerical Features**","b632f25d":"- **Feature Data Type**","815c27b9":"- **Convert Object Feature to Category**","27989d43":"- **Size of the dataset.**"}}