{"cell_type":{"58a7491b":"code","5fc85a61":"code","bd982227":"code","ce8c7058":"code","8c4411d4":"code","ed2a35e7":"code","1c97cd1a":"code","7990e0a1":"code","48d82ad6":"code","489b539b":"code","c980e02e":"code","ed025ff4":"code","9efb2684":"code","a0f12599":"code","78ec625d":"code","d2f6473a":"code","dbaac468":"code","9779b800":"code","1b060207":"code","0b9a2148":"code","edff6304":"code","6c3e6b68":"code","786da2ec":"code","4af89ed5":"code","00dd8340":"code","5afb54db":"code","c906a53b":"code","f0751406":"code","888bb265":"code","ca0c3fa8":"code","1e22ee4d":"code","00597df1":"code","61977803":"code","8c98edbb":"code","e04884c7":"code","78babfbe":"markdown","80dd9e31":"markdown","d7cf0db1":"markdown","5f5976b0":"markdown","33574aa6":"markdown","b86ad693":"markdown","1cf20e05":"markdown","abc233ea":"markdown","ab845414":"markdown","15b64e63":"markdown","138efa50":"markdown","20edd75a":"markdown","dadc5dfb":"markdown","e4a48b2a":"markdown","0fa40a81":"markdown","bd78b83b":"markdown","01118564":"markdown","85054348":"markdown","0717aecd":"markdown","9f82f4af":"markdown","7528a5e5":"markdown","bf17beb0":"markdown","114f8839":"markdown","a6bf8b34":"markdown"},"source":{"58a7491b":"!pip install -q vaderSentiment\n# !pip install -q wordcloud\n# !pip install -U numpy==1.18.5\n","5fc85a61":"# Load packages\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nfrom wordcloud import WordCloud,STOPWORDS\n\nfrom lightgbm import LGBMRegressor,LGBMClassifier\nfrom sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error,f1_score,accuracy_score,confusion_matrix\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE\nfrom imblearn.under_sampling import NearMiss\n\n\nplt.rc('figure',figsize=(8,7.5))\n\nnp.random.seed(2021)\n\n","bd982227":"# Load data from the csv file\ndf = pd.read_csv('..\/input\/internet-articles-data-with-users-engagement\/articles_data.csv', index_col=0)\nprint(f\"Number of rows\/records: {df.shape[0]}\")\nprint(f\"Number of columns\/variables: {df.shape[1]}\")\ndf.head()","ce8c7058":"NA = pd.DataFrame(data=[df.isna().sum().tolist(), [\"{:.2f}\".format(i)+'%' \\\n            for i in (df.isna().sum()\/df.shape[0]*100).tolist()]], \n            columns=df.columns, index=['NA Count', 'NA Percent']).T.\\\n            sort_values(by='NA Count',ascending =False)\nNA.style.background_gradient(cmap=\"summer\", subset=['NA Count'])","8c4411d4":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\nsource_name = df[\"source_name\"].dropna().value_counts()[:10]\nauthor = df[\"author\"].dropna().value_counts()[:10]\n\nyticklabels = ['TAP',\n               'Reuters Editorial',\n               'CBS NEWS',\n               'BBC FB',\n               'AL Jazeera',\n               'The Irish Times',\n               'BBC News',\n               'CBS\/AP',\n               'DAN Cancian', \n               'AP']\nsns.barplot(x=source_name,y=source_name.index,palette='summer',ax=ax1)\nsns.barplot(x=author,y=author.index,palette='summer',ax=ax2 )\nsns.despine(bottom=True,left=True)\nax1.set(title='Top 10 Source')\nax2.set(title='Top 10 Author')\nax2.set_yticklabels(yticklabels) ;","ed2a35e7":"fig, ax  = plt.subplots(figsize=(16, 8))\nfig.suptitle('Top Article', size = 20, color = \"black\")\nexplode = ( 0.05, 0.3)\nlabels = [\"Not Top\",\"Top\"]\nsizes = df[\"top_article\"].dropna().value_counts()\nax.pie(sizes, \n       explode=explode, \n       colors=sns.color_palette(\"Set2\"),\n       startangle=60,\n       labels=labels,\n       autopct='%1.0f%%',\n       pctdistance=0.9)\nax.add_artist(plt.Circle((0,0),0.4,fc='white'))\nplt.show()","1c97cd1a":"eng = ['engagement_reaction_count',\n       'engagement_comment_count',\n       'engagement_share_count',\n       'engagement_comment_plugin_count'] \nax = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df[eng]),palette='summer')\nplt.xticks(rotation=45)\nax.set_yscale('Symlog')\nplt.show()","7990e0a1":"pd.DataFrame(df[\"engagement_comment_plugin_count\"].\\\n             value_counts().\\\n             reset_index().\\\n             rename(columns = {'index':'engagement_comment_plugin',\n                               'engagement_comment_plugin_count':'Counts'})).\\\n            astype(int).\\\n            style.background_gradient(cmap=\"summer\", subset=['Counts'])","48d82ad6":"df.published_at = pd.to_datetime(df.published_at)\n\ndf['Day_Of_Week'] = df.published_at.apply(lambda x: x.dayofweek)\ndf['Month'] = df.published_at.apply(lambda x: x.month)\ndf['Year'] = df.published_at.apply(lambda x: x.year)","489b539b":"df['title'][0:5]","c980e02e":"def clean_title(x:str):    \n    # lowering the text\n    x=x.lower() \n \n    #removing square brackets\n    x = re.sub('\\[.*?\\]', '', x)\n    x = re.sub('<.*?>+', '', x) \n\n    #removing hyperlink\n    x = re.sub('https?:\/\/\\S+|www\\.\\S+', '', x) \n\n    #removing puncuation\n    x = re.sub('[%s]' % re.escape(string.punctuation), '', x) \n    x = re.sub('\\n', '', x) \n\n    #remove words containing numbers\n    x = re.sub('\\w*\\d\\w*', '', x) \n    return x","ed025ff4":"df['clean_title'] = df['title'].astype(str).apply(clean_title) \ndf['clean_title'][0:5]","9efb2684":"\nanalyzer = SentimentIntensityAnalyzer()\ndef compound_score(txt):\n    return analyzer.polarity_scores(txt)[\"compound\"]\n\n## Sentiments\ndef sentiment(score):\n    emotion = \"\"\n    if score >= 0.5:\n        emotion = \"Positive\"\n    elif score <= -0.5:\n        emotion = \"Negative\"\n    else:\n        emotion = \"Neutral\"\n    return emotion","a0f12599":"\npolarity_scores = df[\"clean_title\"].astype(\"str\").apply(compound_score)\ndf[\"Sentiment_Score\"] = polarity_scores\n\n## Applying Sentiment\ndf[\"Sentiment\"] = df[\"Sentiment_Score\"].apply(sentiment)","78ec625d":"df.head()","d2f6473a":"sns.countplot(data=df,x=\"Sentiment\",palette=\"summer\");","dbaac468":"np.array(list(STOPWORDS))[0:5]","9779b800":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[14, 14], facecolor = None)\n\n\nwc = WordCloud(width = 800, height = 800,background_color=\"white\",min_font_size = 10,\\\n    repeat=True,stopwords = STOPWORDS)\nwc.generate(\"\".join(df['title'].astype(str)))\nax1.axis(\"off\")\nax1.imshow(wc, interpolation=\"bilinear\")\nax1.set_title('Common Words Used in Title',fontsize=16);\n\n\nwc2 = WordCloud(width = 800, height = 800,background_color=\"white\",min_font_size = 10,\\\n    repeat=True,stopwords = STOPWORDS)\nwc2.generate(\"\".join(df['description'].astype(str)))\nax2.axis(\"off\")\nax2.imshow(wc2, interpolation=\"bilinear\")\nax2.set_title('Common Words Used in description',fontsize=16);","1b060207":"fig, ax1 = plt.subplots( figsize=[15, 8], facecolor = None)\n\nb_date_mean = df.copy()\nb_date_mean.published_at = pd.to_datetime(b_date_mean.published_at).dt.normalize()\nb_date_mean = b_date_mean.groupby(by='published_at').mean().reset_index()\n\nax1 = sns.lineplot(\n    data=b_date_mean, x=\"published_at\", y=\"engagement_reaction_count\",label = 'reaction'\n)\n\nax1 = sns.lineplot(\n    data=b_date_mean, x=\"published_at\", y=\"engagement_comment_count\",label = 'comment'\n)\n\nax1 = sns.lineplot(\n    data=b_date_mean, x=\"published_at\", y=\"engagement_share_count\", label = 'share'\n)","0b9a2148":"df['published_at'].min(), df['published_at'].max()","edff6304":"dataplot = sns.heatmap(df.drop(columns = ['Year','engagement_comment_plugin_count']).corr(),\n                       cmap=\"YlGnBu\", annot=True)\n  \n# displaying heatmap\nplt.show()","6c3e6b68":"df.dropna(inplace=True)\n\ncount_vectorizer = CountVectorizer()\n\ntfidf_vec = TfidfVectorizer(ngram_range=(1,2),\n                            dtype=np.float32, \n                            sublinear_tf=True, \n                            use_idf=True, \n                            smooth_idf=True)\ntrain_tfidf = tfidf_vec.fit_transform(df['clean_title'])\n\n","786da2ec":"list_labels = df.dropna()[\"top_article\"]\nOS = SMOTE()\nNM= NearMiss(version=2)\nX,Y = OS.fit_resample(train_tfidf,list_labels)","4af89ed5":"X_train, X_test, y_train, y_test = train_test_split(X, Y,\n                                                    test_size=0.1,\n                                                    stratify = Y ,\n                                                    random_state=40)\n\nmodeltop = LGBMClassifier(verbose=-1,\n                          learning_rate=0.5,\n                          max_depth=20,\n                          num_leaves=50, \n                          n_estimators=120,\n                          max_bin=2000,)\n\nscores = cross_val_score(\n                 modeltop, X_train, y_train, cv=5, scoring='f1_macro')\n\nprint(\"Cross Validation F1 Scores : \",scores)","00dd8340":"modeltop.fit(X_train,y_train)\n\npredtop = modeltop.predict(X_test)\nprint(\"f1 score : \",round(f1_score(predtop,y_test),2))\nprint(\"accuracy score : \",round(accuracy_score(predtop,y_test),2))","5afb54db":"\nplt.figure(figsize = (10,10))\ncm = confusion_matrix(y_test,predtop)\nsns.heatmap(cm,cmap= \"Blues\",\n            linecolor = 'black' ,\n            linewidth = 1 ,\n            annot = True,\n            fmt='' ,\n            xticklabels = ['Covid_Negative','Covid_Positive'] ,\n            yticklabels = ['Covid_Negative','Covid_Positive'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\");","c906a53b":"df['Popularity_Score'] = np.log((df['engagement_reaction_count'] + \\\n                         df['engagement_comment_count']+\\\n                         df['engagement_share_count']+\\\n                         df['engagement_comment_plugin_count']+1))","f0751406":"sns.kdeplot(df['Popularity_Score']);","888bb265":"list_labels = df.dropna()[\"Popularity_Score\"]+0.001\n\nX_train, X_test, y_train, y_test = train_test_split(train_tfidf,\n                                                    list_labels,\n                                                    test_size=0.2,\n                                                    random_state=40)\n\nmodel1 = LGBMRegressor(verbose=-1,\n                       learning_rate=0.01,\n                       max_depth=20,\n                       num_leaves=50,\n                       n_estimators=150)\n\nscores = cross_val_score(\n                 model1, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n\nprint(\"Cross Validation RMSE Scores : \",-scores)\n","ca0c3fa8":"model1.fit(X_train,y_train)\n\npred1 = model1.predict(X_test)\nprint(\"RMSE : \",round(np.sqrt(mean_squared_error(pred1,y_test)),2))","1e22ee4d":"def title_score(title):\n    text = tfidf_vec.transform([title])\n    top_cat = modeltop.predict(text)\n    pop = model1.predict(text)\n    print(\"Top Article :\" , top_cat[0].astype(bool))\n    print(\"Popularity Score:\" , round(pop[0],2))\n    return top_cat,pop\n    ","00597df1":"df[df['top_article']==1]['title'].values[5]","61977803":"title_score(\"Manchin decides against running for West Virginia governor, will stay in Senate\");","8c98edbb":"title_score(\"Here Are the States With the Lowest COVID-19 Vaccination Rates\");","e04884c7":"title_score(\"New Orleans without power as Ida delivers 'catastrophic' damage\");","78babfbe":"## Applying Compund score","80dd9e31":"## Context\n![image](https:\/\/deepnote.com\/publish\/6da86419-8c62-4e7d-95b4-de4973e49e4c\/0e7b8483-f37c-4012-9024-95b56105b789\/file?path=1.jpeg)\nThis dataset (source) consists of data about news articles collected from Sept. 3, 2019 until Oct. 4, 2019. Afterwards, it is enriched by Facebook engagement data, such as number of shares, comments and reactions.\n\n- Sourceid column value indicates publisher unique identifier usually presented as lowercase sourcename with spaces replaced with underscore symbol.\n- Source_name column value indicates publisher name.\n- Author column value indicates article author. Some publishers do not share information about authors of their news, in this case usually source_name replaces that information.\n- Title column value indicates headline of an article.\n- Description column value indicates short article description usually visible in popups or recommendation boxes on the publisher's website. This field is shortened to a few sentences content column.\n- Url column value indicates URL (Uniform Resource Locator) for article located on the publisher website.\n- Urltoimage column value indicates a URL to the main image associated with the article.\n- Published_at column value indicates the exact date and time of publishing the article. Date and time are presented in UTC (+000) time format.\n- Content column value indicates the unformatted content of the article. This field is truncated to 260 characters.\n- Top_article column value indicates article listed as a top article on publisher website. This field can have only two values, 1 when the article is contained in the popular\/top articles group and 0 otherwise.","d7cf0db1":"## Time Series ","5f5976b0":"## Creating sentimental polarity ","33574aa6":"# Exploring Data","b86ad693":"## Missing Values","1cf20e05":"## Training Model","abc233ea":"## confusion matrix","ab845414":"# Title Score","15b64e63":"## Engagement Boxplots","138efa50":"## Vectorizer","20edd75a":"# Testing Function","dadc5dfb":"## Top Article","e4a48b2a":"## Loading Data","0fa40a81":"## Clean Text","bd78b83b":"## Clean title","01118564":"## Top Ten Author and Source\u00a0Name","85054348":"## Popularity_Score","0717aecd":"![cover](https:\/\/images.unsplash.com\/photo-1584714268709-c3dd9c92b378?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=799&q=80)\n\n# Internet News and Consumer Engagement\n\nIn this project, we will be using Internet News and Consumer Engagement dataset from Kaggle to predict top article and popularity score. We will be exploring our data to discover patterns, such as correlation, distribution, mean, and time series analysis. We will use both text regression and text classification models to predict engagement score and top article based on the title.\nText classification is common among the application that we use on daily basis. For example, email providers use text classification to filter out spam emails from your inbox. The other most common use of text classification is in customer care where they use sentimental analysis to differentiate bad reviews from good reviews ADDI AI 2050. We are going to train our model on titles so that it can predict where the article is top or not. Text Regression is similar where we take text vectorized data and predict popularity score which is a decimal value.","9f82f4af":"# Conclusion\nWe had fun exploring the data and playing around with different machine learning techniques and models. In short, we have explored our data and presented unique information that can help the News agency create better content that gets high traction from the consumers. We have developed machine learning models that will help writers and bloggers to write better titles. We have also discovered that high popularity doesn't mean that it's going to be a top article.\n\nFor future work, I would like to explore multiple clusters within the data and create a model using images of the article to predict popularity scores. I have experimented with deep learning text generation models but due to memory constraints, I was limited to simple tabular models.","7528a5e5":"## Heatmap","bf17beb0":"## Word Cloud","114f8839":"## Comment Plugin","a6bf8b34":"## Validation"}}