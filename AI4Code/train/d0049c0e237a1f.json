{"cell_type":{"06f58df6":"code","32877a5d":"code","96c71db4":"code","2b411a79":"code","c463a4e1":"code","a09db176":"code","cef7e148":"code","95858f90":"code","269307d6":"code","3bbc93eb":"markdown","cfd02cb8":"markdown","083c3b1c":"markdown","5c38dcb5":"markdown"},"source":{"06f58df6":"import torch\nimport torchvision.datasets  as dsets\nimport torch.utils.data\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.utils as vutils\nfrom torchvision.datasets import ImageFolder\n\nimport tqdm\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom PIL import Image","32877a5d":"batch_size = 32\nimage_size = 56\ntorch.cuda.set_device(\"cuda:0\")","96c71db4":"class ColorizationDataset(Dataset):\n    def __init__(self, transform_x, transform_y):\n        self.transform_x = transform_x\n        self.transform_y = transform_y\n\n    def __len__(self) -> int:\n        return 21511\n\n    def __getitem__(self, idx: int):\n        with Image.open(f'\/kaggle\/input\/anime-faces\/data\/data\/{str(idx+1)}.png') as image:\n            img = image.copy()\n        Y = self.transform_y(img)\n        X = self.transform_x(Y)\n        return X, Y","2b411a79":"transform_all = transforms.Compose([\n    transforms.RandomResizedCrop(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\ndef to_grayscale(x):\n    return (x[0] * 0.299 + x[1] * 0.587 + x[2] * 0.114).view(1, image_size, image_size)\n\ndset = ColorizationDataset(to_grayscale, transform_all)\n# cut the size of dataset\ndataset, _ = torch.utils.data.random_split(dset, [int(len(dset)\/3.3), len(dset)-int(len(dset)\/3.3)])\ndel _\ndataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True, shuffle=True)","c463a4e1":"real_batch = next(iter(dataloader))\nplt.figure(figsize=(8, 8))\nplt.axis(\"off\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0][:32], padding=2, normalize=True).cpu(),(1,2,0)))","a09db176":"class Colorizer(nn.Module):\n    def __init__(self):\n        super(Colorizer, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, 3, 2, 1)\n        self.conv2 = nn.Conv2d(16, 64, 3, 2, 1)\n        self.conv3 = nn.Conv2d(64, 256, 3, 2, 1)\n        self.conv4 = nn.Conv2d(256, 256, 3, 1, 2, dilation=2)\n        self.conv5 = nn.Conv2d(256, 256, 3, 1, 2, dilation=2)\n        self.conv6 = nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n        self.conv7 = nn.ConvTranspose2d(128, 64, 3, 2, 1, 1)\n        self.conv8 = nn.ConvTranspose2d(64, 3, 3, 2, 1, 1)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(256)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.bn5 = nn.BatchNorm2d(256)\n        self.bn6 = nn.BatchNorm2d(128)\n        self.bn7 = nn.BatchNorm2d(64)\n        self.leakyrelu = nn.LeakyReLU(0.2)\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        y = self.bn1(self.leakyrelu(self.conv1(x)))\n        y = self.bn2(self.leakyrelu(self.conv2(y)))\n        y = self.bn3(self.leakyrelu(self.conv3(y)))\n        y = self.bn4(self.leakyrelu(self.conv4(y)))\n        y = self.bn5(self.leakyrelu(self.conv5(y)))\n        y = self.bn6(self.leakyrelu(self.conv6(y)))\n        y = self.bn7(self.leakyrelu(self.conv7(y)))\n        y = self.tanh(self.conv8(y))\n        return y","cef7e148":"num_epochs = 4\nlr = 1e-3\n\nmodel = Colorizer()\nif os.path.isfile(\"\/kaggle\/input\/anime-face-colorization\/colorizer.pth\"):\n    model.load_state_dict(torch.load(\"\/kaggle\/input\/anime-face-colorization\/colorizer.pth\"))\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.L1Loss()","95858f90":"history = []\nfor epoch in range(num_epochs):\n    for x, y in tqdm(dataloader):\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, y)\n        history.append(loss)\n        loss.backward()\n        optimizer.step()\n    torch.save(model.state_dict(), \"colorizer.pth\")","269307d6":"def to_numpy_image(img):\n    return img.detach().cpu().view(3, image_size, image_size).transpose(0, 1).transpose(1, 2).numpy()\n\nfor t in range(3):\n    img_gray, img_true = dataset[t]\n    img_pred = model(img_gray.view(1, 1, image_size, image_size))\n    img_pred = to_numpy_image(img_pred)\n    plt.figure(figsize=(10,10))\n    \n    plt.subplot(141)\n    plt.axis('off')\n    plt.set_cmap('Greys')\n    plt.imshow(1-img_gray.reshape((image_size, image_size)))\n\n    plt.subplot(142)\n    plt.axis('off')\n    plt.imshow(img_pred.reshape((image_size, image_size, 3)))\n\n    plt.subplot(143)\n    plt.axis('off')\n    plt.imshow(to_numpy_image(img_true))\n    \n    plt.show()","3bbc93eb":"### network","cfd02cb8":"### imports","083c3b1c":"### visualization","5c38dcb5":"### dataset"}}