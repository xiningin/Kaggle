{"cell_type":{"3da5613d":"code","d4ef7440":"code","35fb4125":"code","93c0719c":"code","4c83fa7e":"code","5a10b3b5":"code","ef5788b3":"code","85978b63":"code","14b583a8":"code","5fbbb9ad":"code","d10198d0":"code","de39ab21":"code","fa7db80c":"code","59b793de":"code","c281069f":"code","20f09f58":"code","7fce92c2":"code","cf66c3cb":"code","c1b5a9f2":"code","c701eb3c":"code","54c7388a":"code","fdb271bb":"code","691e4247":"code","2deea508":"code","db85a56d":"code","040b9c63":"code","860c895c":"code","d9561b47":"code","554f184d":"code","11cde972":"code","15e3fbaa":"code","960b17a3":"code","e0337223":"code","440b1d3a":"code","cfebb1fe":"code","b4f60fb1":"code","3b28ff24":"code","01d88901":"code","bca4ba00":"code","c8211965":"markdown","338d9071":"markdown","7193509a":"markdown","dc1055b9":"markdown","3a646916":"markdown","898b7ba5":"markdown","daf4327a":"markdown","4411d52f":"markdown","cf66ecc6":"markdown","da77d23a":"markdown"},"source":{"3da5613d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4ef7440":"# !pip install --quiet torch\n# !pip install --quiet timm","35fb4125":"# Set GPU Device.\nfrom fastai.vision.all import *\ntorch.cuda.set_device(0)\ntorch.cuda.get_device_name()","93c0719c":"from fastcore.xtras import Path\n\nfrom fastai.callback.hook import summary\nfrom fastai.callback.progress import ProgressCallback\nfrom fastai.callback.schedule import lr_find, fit_one_cycle\n\nfrom fastai.data.block import DataBlock, CategoryBlock\nfrom fastai.data.core import Datasets\nfrom fastai.data.external import untar_data, URLs\nfrom fastai.data.transforms import get_image_files, Normalize, RandomSplitter, GrandparentSplitter, RegexLabeller, ToTensor, IntToFloatTensor, Categorize, parent_label\n\nfrom fastai.learner import Learner\nfrom fastai.losses import LabelSmoothingCrossEntropy\nfrom fastai.metrics import error_rate, accuracy\n\nfrom fastai.vision.augment import aug_transforms, RandomResizedCrop, Resize, FlipItem\nfrom fastai.vision.core import PILImage, imagenet_stats\nfrom fastai.vision.data import ImageBlock\nfrom fastai.vision.learner import cnn_learner, create_head, create_body, num_features_model, default_split, has_pool_type, apply_init, _update_first_layer\n\nimport torch\nfrom torch import nn","4c83fa7e":"# List of available EffNet Architectures.\n# import timm\n# from pprint import pprint\n# model_names = timm.list_models('*efficientne*t*')\n# pprint(model_names)","5a10b3b5":"train = pd.read_csv(\"..\/input\/satriadata\/data_process\/dataset\/train.csv\")\ntrain.head()","ef5788b3":"files = [] # Nama file.\njk = [] # Jenis kelamin.\nusia = [] # Usia.\n\n# Satu subfile ada 3 image.\nfor index, row in train.iterrows():\n    files.append(str(row[\"nomor\"]) + \"_1.jpg\") # Image 1.\n    jk.append(row[\"jenis kelamin\"])\n    usia.append(row[\"usia\"])\n    files.append(str(row[\"nomor\"]) + \"_2.jpg\") # Image 2.\n    jk.append(row[\"jenis kelamin\"])\n    usia.append(row[\"usia\"])\n    files.append(str(row[\"nomor\"]) + \"_3.jpg\") # Image 3.\n    jk.append(row[\"jenis kelamin\"])\n    usia.append(row[\"usia\"])\n    \n\ndf = pd.DataFrame({\n    \"name\": files,\n    \"label\": jk,\n})\ndf2 = pd.DataFrame({\n    \"name\": files,\n    \"label\": usia,\n})","85978b63":"df.head()","14b583a8":"nomor_lk = list(x[:-4] for x in df[df['label'] == 1]['name'])\nnomor_pr = list(x[:-4] for x in df[df['label'] == 0]['name'])","5fbbb9ad":"nomor_pr[:5]","d10198d0":"nomor_lk[:5]","de39ab21":"path = \"..\/input\/satriadata\/train_processed\"\nfilenames = get_image_files(path)\npat = r'\/([^\/]+)_\\d+.*'","fa7db80c":"def label_func(string):\n    stringed = str(string)\n    \n    x = 1\n    y = 0\n    \n    while True:\n        if stringed[-x] != \"\/\":\n            x += 1\n            y += 1\n        else:\n            break\n            \n    output = stringed[-y:][:-4]\n    \n    if output in nomor_pr:\n        return 0\n    else:\n        return 1","59b793de":"item = [\n    ToTensor(), \n    Resize(500, ResizeMethod.Squish)\n]\n\nbatch = [\n    IntToFloatTensor(),\n    Normalize.from_stats(*imagenet_stats)\n]","c281069f":"# image_jk = DataBlock(blocks=(ImageBlock, CategoryBlock),\n                    # get_items=get_image_files,\n                    # splitter=RandomSplitter(valid_pct=0.2, seed=42),\n                    # get_y=label_func,\n                    # item_tfms=item,\n                    # batch_tfms=batch)","20f09f58":"dfjk = ImageDataLoaders.from_df(df,\n                                \"..\/input\/satriadata\/\",\n                                folder='train_processed',\n                                valid_pct=0.2,\n                                item_tfms=item,\n                                batch_tfms=batch,\n                                bs=16, \n                                val_bs=8,\n)","7fce92c2":"dfjk.train.show_batch(max_n=10, nrows=2)","cf66c3cb":"dfjk.valid.show_batch(max_n=10, nrows=2)","c1b5a9f2":"print(\"Label: \" + str(dfjk.vocab))\nprint(\"Train size: \" + str(len(dfjk.train_ds)))\nprint(\"Valid size: \" + str(len(dfjk.valid_ds)))","c701eb3c":"!pip install --quiet efficientnet_pytorch\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_name('efficientnet-b3', num_classes=2)","54c7388a":"# def create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n    # \"Creates a body from any model in the `timm` library.\"\n    # model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n    # _update_first_layer(model, n_in, pretrained)\n    # if cut is None:\n        # ll = list(enumerate(model.children()))\n        # cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    # if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n    # elif callable(cut): return cut(model)\n    # else: raise NamedError(\"cut must be either integer or function\")","fdb271bb":"# body = create_timm_body('efficientnet_b4', pretrained=False)\n# num_feat = num_features_model(nn.Sequential(*body.children()))\n# head = create_head(num_feat, dfjk.c)\n# model = nn.Sequential(body, head)\n# apply_init(model[1], nn.init.kaiming_normal_)","691e4247":"learn = Learner(dfjk, model,\n                opt_func=Adam, \n                metrics=[accuracy, F1Score()], \n                loss_func=LabelSmoothingCrossEntropy())","2deea508":"learn.model_dir = '\/kaggle\/working\/models'","db85a56d":"# learn = Learner(dfjk, model, opt_func=Adam, loss_func=LabelSmoothingCrossEntropy(), \n                # splitter=default_split, metrics=[accuracy, F1Score()])","040b9c63":"# learn.unfreeze()\n# lr = learn.lr_find()","860c895c":"mixup = MixUp(1.)","d9561b47":"learn.fit_one_cycle(100, 3e-3,\n                    cbs=[SaveModelCallback(every_epoch=False, \n                                           with_opt=True,\n                                           fname='best_effnet_model_base', \n                                           monitor='f1_score'),\n                        mixup])","554f184d":"conf_mat = ClassificationInterpretation.from_learner(learn)\nconf_mat.plot_confusion_matrix()","11cde972":"conf_mat.plot_top_losses(9, nrows=3)","15e3fbaa":"learn.save('final_model')","960b17a3":"# Re-train with Mixed Dataset\nlearn.load('\/kaggle\/input\/retrain\/re\/final')","e0337223":"test = pd.read_csv('..\/input\/satriadata\/data_process\/dataset\/test_manual.csv')\ntest.head()","440b1d3a":"dirname = '..\/input\/satriadata\/test_processed'","cfebb1fe":"x = 0\nfor file in list(test['id']):\n    print(dirname + '\/' + file + '.jpg')\n    x += 1\n    if x == 5:\n        break","b4f60fb1":"prediction = []\nfor file in list(test['id']):\n    pred = learn.predict(dirname + '\/' + file + '.jpg')[0]\n    prediction.append(pred)","3b28ff24":"test['label'] = test['label'].astype(str)\ntest['pred'] = prediction\ntest.head()","01d88901":"from sklearn.metrics import classification_report\nprint(classification_report(test['label'], test['pred'], target_names=[\"Perempuan\", \"Laki\"]))","bca4ba00":"test.to_csv('submission.csv')","c8211965":"# Prediction","338d9071":"## Labelling Function","7193509a":"# Depedencies","dc1055b9":"## Data Block","3a646916":"## Load 1st Training Model","898b7ba5":"## Prediction Pipeline","daf4327a":"## Libraries","4411d52f":"# Input Data","cf66ecc6":"## Dataset","da77d23a":"# Model"}}