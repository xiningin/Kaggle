{"cell_type":{"2f74248e":"code","204a9c07":"code","7d5e0ef0":"code","b31233aa":"code","2e12846d":"code","43515198":"code","472ef461":"code","3fe4df3b":"code","5fe45c4d":"code","a1da76b5":"code","38b36121":"code","4e623e12":"code","5b9e7ae7":"markdown","72434fbf":"markdown","548d146f":"markdown","11edc335":"markdown","e4956948":"markdown","c444df02":"markdown","6e6d25df":"markdown","8781fd51":"markdown","58a66d54":"markdown","591ef20b":"markdown","5770299c":"markdown","876bed74":"markdown"},"source":{"2f74248e":"import os\nimport gc\nimport glob\nimport time\nimport random\nimport pandas as pd\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 100)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import RobustScaler\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay","204a9c07":"# For debug\nclass Config:\n    def __init__(self):\n        self.config = 0\n        self.debug_size = 754\n        self.data_dir = '..\/input\/ventilator-pressure-prediction\/'\n        self.post_processing = {\n                                'max_pressure': 64.82099173863948,\n                                'min_pressure': -1.8957442945646408,\n                                'diff_pressure': 0.07030215,\n                                }\n        \nconfig = Config()","7d5e0ef0":"# Dtype Changed for low size data\ndtypes = {'id': 'int32',\n          'breath_id': 'int32',\n          'R' : 'int8',\n          'C' : 'int8',\n          'time_step': 'float64',\n          'u_in': 'float64',\n          'u_out': 'int8',\n          'pressure': 'float64'}\n\n# Read train CSV data\ndef read_train():\n    train = pd.read_csv(config.data_dir + 'train.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_train = random.sample(set(train['breath_id'].unique()), config.config_size)\n        train_tmp = pd.DataFrame()\n        for i in lst_train:\n            train_tmp = pd.concat([train_tmp, train[train['breath_id'] == i]], axis=0)\n        train = train_tmp\n    train = train.astype(dtypes)\n    return train\n\n# Read test CSV data\ndef read_test():\n    test = pd.read_csv(config.data_dir + 'test.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_test = random.sample(set(test['breath_id'].unique()), config.config_size)\n        test_tmp = pd.DataFrame()\n        for i in lst_test:\n            test_tmp = pd.concat([test_tmp, test[test['breath_id'] == i]], axis=0)\n        test = test_tmp\n    test = test.astype(dtypes)\n    return test  \n\ntrain = read_train()   \ntrain.head(2)","b31233aa":"## Describe in exclude id columns\ntrain[train.columns[1:]].describe(include='all').round(3)","2e12846d":"if config.config:\n    fig, ax = plt.subplots(1, 3, figsize=(30, 6))\n    sns.set(font_scale=1.2)\n    for i, num in enumerate(random.sample(lst_train, 3)):\n        df = train[train['breath_id']==num]\n        ax2 = ax[i].twinx()\n\n        sns.lineplot(data=df, x='time_step', y='pressure', label='pressure', ax=ax[i])\n        sns.lineplot(data=df, x='time_step', y='u_in', label='u_in', ax=ax[i])\n        sns.lineplot(data=df, x='time_step', y='u_out', label='u_out', ax=ax2, color='r')\n\n        ax[i].set(xlabel='Timestep', ylabel='pressure, u_in', title=f'breath_id: {num}', xlim=(-0.2, 3.2), ylim=(-5, 105))\n        ax[i].legend(loc=(0.75, 0.7))\n        ax2.legend(loc=(0.75, 0.6))\n    plt.show()","43515198":"def log_exp_return(series):\n    return np.exp(np.log1p(series).diff(1).fillna(0))\n\ndef preprocessing(df):\n    # time diff\n    df['time_diff'] = df['time_step'].groupby(df['breath_id']).diff(1).fillna(0)\n    \n    # basic parameter\n    df['u_in_ratio'] = df['u_in'].groupby(df['breath_id']).apply(log_exp_return)\n    df['area_unit'] = df['u_in'] * df['time_diff']  \n    df['area_ratio'] = df['area_unit'].groupby(df['breath_id']).apply(log_exp_return) \n\n    # Create Time Windows\n    def create_time_window(df, time_min, time_max, diff_time):\n        feature_dict = {\n                        'u_in': [np.std], \n                        'area_unit': [np.std], \n                        'u_in_ratio': [np.prod, np.std],\n                        'area_ratio': [np.prod, np.std]\n                        }\n        for time_stamp in np.arange(time_min, time_max, diff_time):\n            df_tmp = df[['time_step'] + list(feature_dict.keys())][(df['time_step'] >= time_stamp - diff_time) & (df['time_step'] < time_stamp)] \\\n                        .groupby(df['breath_id']).agg(feature_dict)\n            df_tmp.columns = ['_'.join(col) for col in df_tmp.columns]\n            df = pd.merge(df, df_tmp.add_suffix(f'_{time_stamp}_term').reset_index(), on='breath_id', how='left')\n            del df_tmp\n            gc.collect()\n            time.sleep(1)\n\n        return df\n    \n    df = create_time_window(df, 0.1, 0.6, 0.1)\n\n    for i in np.arange(1, 5, 1):\n        df[f'u_in_lag_fwrd{i}'] = df['u_in'].groupby(df['breath_id']).shift(i).fillna(0)\n        df[f'u_in_lag_back{i}'] = df['u_in'].groupby(df['breath_id']).shift(int(-i)).fillna(0)       \n        df[f'area_lag_fwrd{i}'] = df['time_diff'] * df[f'u_in_lag_fwrd{i}']\n        df[f'area_lag_back{i}'] = df['time_diff'] * df[f'u_in_lag_back{i}']\n\n    # u_in parameter\n    df['last_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('last')\n    df['first_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('first')\n    df['u_in_cumsum'] = df['u_in'].groupby(df['breath_id']).cumsum()  \n    \n    # u_in area\n    df['last_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('last')\n    df['first_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('first')\n    df['area_cumsum'] = df['area_unit'].groupby(df['breath_id']).cumsum()    \n        \n    df = df.fillna(0)\n    \n    # u_out parameter\n    df['u_out'] = df['u_out'].astype('str')\n\n    # R, C parameter\n    df['R'] = df['R'].astype('str')\n    df['C'] = df['C'].astype('str')\n    df = pd.get_dummies(df, drop_first=True)\n    \n    return df\n\n\ntarget = train[\"pressure\"].values\ntrain = train.drop([\"id\", \"pressure\"], axis=1)\ntrain = preprocessing(train)\ntrain = train.drop(['breath_id'], axis=1)\nfeature_column = train.columns.values\ntime.sleep(1)","472ef461":"rs = RobustScaler()\ntrain = rs.fit_transform(train)\nprint(f'train shape: {train.shape}')","3fe4df3b":"# Reshape (BreathID, Time_step)\ntarget = target.reshape(-1, 80)\n\n# Reshape (BreathID, Time_step, feature)\ntrain = train.reshape(-1, 80, train.shape[-1])\nprint(train.shape)","5fe45c4d":"class Keras:\n    def __init__(self):\n        self.models = []\n        self.results = []\n        self.timeout = 28800\n        self.batch_size = 512\n        self.n_splits = 3\n        self.epoch = 200\n        self.es = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"min\", restore_best_weights=True)\n        self.lr = ReduceLROnPlateau(monitor=\"val_loss\", patience=2, verbose=0, factor=0.5, min_lr=1e-8)  \n        self.kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=2021)\n        \n    def create_model(self, n_layer, activation, mid_units, dropout_rate, train):\n        inputs = keras.layers.Input(shape=train.shape[-2:])\n        x = keras.layers.Bidirectional(keras.layers.LSTM(int(mid_units), return_sequences=True))(inputs)\n        for i in range(0, n_layer):\n            x = keras.layers.Bidirectional(keras.layers.LSTM(int(mid_units \/ (2**(i+1))), return_sequences=True))(x)\n#         x = keras.layers.Dropout(dropout_rate)(x)\n        x = keras.layers.Dense(int(mid_units \/ (2**(i+2))), activation=activation)(x)\n        output = keras.layers.Dense(1)(x)\n        model = keras.models.Model(inputs, output) \n        return model\n            \n    def keras_trial(self, params, train, target):        \n        for fold, (trn_idx, val_idx) in enumerate(self.kf.split(train, target)):\n            print(f'Fold {fold+1} started at {time.ctime()}')\n            model = self.create_model(params[\"n_layer\"], \n                                      params[\"activation\"],                                      \n                                      params[\"mid_units\"], \n                                      params[\"dropout_rate\"],\n                                      train)\n            model.compile(optimizer=params[\"optimizer\"], loss=\"mae\")\n            result = model.fit(x=train[trn_idx], \n                               y=target[trn_idx], \n                               batch_size=self.batch_size, \n                               epochs=self.epoch, \n                               verbose=1, \n                               callbacks=[self.lr, self.es], \n                               validation_data=(train[val_idx], target[val_idx])\n                              )\n            \n            self.results.append(result)\n            self.models.append(model)        \n            \n            del result, model\n            gc.collect()\n            time.sleep(1)   ","a1da76b5":"keras_inst = Keras()\nparams = {'n_layer': 3, 'mid_units': 64, 'dropout_rate': 0.01, 'activation': 'softplus', 'optimizer': 'adam'}\nkeras_inst.keras_trial(params, train, target)\ndel train, target\ngc.collect()","38b36121":"fig, ax = plt.subplots(1, keras_inst.n_splits, figsize=(30, 10))\nfor i in range(keras_inst.n_splits):\n    ax2 = ax[i].twinx()\n    ax[i].plot(range(1, len(keras_inst.results[i].history['loss'])+1), np.log(keras_inst.results[i].history['loss']), label=\"train\")\n    ax[i].plot(range(1, len(keras_inst.results[i].history['val_loss'])+1), np.log(keras_inst.results[i].history['val_loss']), label=\"valid\")\n    ax2.plot(range(1, len(keras_inst.results[i].history['lr'])+1), [x * 1000 for x in keras_inst.results[i].history['lr']], label=\"lr\", color=\"r\", ls=\"--\")\n    ax[i].set(xlabel='Epochs', ylabel='Loss')\n    ax2.set(ylabel=\"lr [x1000]\")\n    ax[i].legend()\nplt.tight_layout()\nplt.show()","4e623e12":"# Test does not have \"pressure\" column\ndtypes.pop('pressure')\n\ntest = read_test()\ntest = preprocessing(test)\ntest = test.drop([\"id\", 'breath_id'], axis=1)\ntest = rs.transform(test)\ntest = test.reshape(-1, 80, test.shape[-1])\ntest_shape = test.shape\nprint(test.shape)\n\ntest_preds = []\nfor model in keras_inst.models:\n    test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n\ndel test\ngc.collect()\n\nsubmission = pd.read_csv(config.data_dir + \"sample_submission.csv\")[:test_shape[0] * test_shape[1]]\nsubmission[\"pressure\"] = sum(test_preds) \/ keras_inst.n_splits\nsubmission[\"pressure\"] = np.round((submission[\"pressure\"] - config.post_processing[\"min_pressure\"]) \/ config.post_processing[\"diff_pressure\"]) * config.post_processing[\"diff_pressure\"] + config.post_processing[\"min_pressure\"]\nsubmission[\"pressure\"] = np.clip(submission[\"pressure\"], config.post_processing[\"min_pressure\"], config.post_processing[\"max_pressure\"])\nsubmission.to_csv('submission_keras.csv', index=False)\nprint(submission.tail(2))","5b9e7ae7":"## 2. Keras\n### 2-1. Reshape Data\n- Data Reshape for Keras","72434fbf":"### 2-4. Loss & learning ratio","548d146f":"### 2-3. Keras Trial","11edc335":"### 1-4. Preprocessing","e4956948":"### 1-5. RobustScaler","c444df02":"### 1-3. Time series data(pressure\/ u_in \/ u_out)\n- from [https:\/\/www.kaggle.com\/kaitohonda\/beginner-lgbm](https:\/\/www.kaggle.com\/kaitohonda\/beginner-lgbm)","6e6d25df":"## 0. Introduction\n- Updated 10\/13\/21\n- This code is a baseline with Keras LSTM method.\n- Fisaish to submit\n\n### 0-1. Libarary","8781fd51":"### 2-2. Keras Class","58a66d54":"### 0-2. Debug","591ef20b":"## 1 EDA & Preprocessing\n### 1-1. Train & Test data","5770299c":"### 1-2. Exploratory Data Analysis\n### Feature\n- id - globally-unique time step identifier across an entire file\n- breath_id - globally-unique time step for breaths\n- R - lung attribute indicating how restricted the airway is (in cmH2O\/L\/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n- C - lung attribute indicating how compliant the lung is (in mL\/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloon\u2019s latex, with higher C having thinner latex and easier to blow.\n- time_step - the actual time stamp.\n- u_in - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n- u_out - the control input for the exploratory solenoid valve. Either 0 or 1.\n- pressure - the airway pressure measured in the respiratory circuit, measured in cmH2O.","876bed74":"## 3. Submission"}}