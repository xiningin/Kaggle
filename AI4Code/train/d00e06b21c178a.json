{"cell_type":{"b3174c5c":"code","77b38a25":"code","dc926768":"code","c3de7121":"code","d200a808":"code","d810579d":"code","c644278a":"code","438be29b":"code","4096a5d8":"code","1cba3d36":"code","4926c8e4":"code","3925f5ca":"code","4f325cdc":"code","a48525f6":"code","f75541f9":"code","4516e802":"code","a8b0554d":"code","3da12e6f":"code","2b958300":"code","37d9251d":"code","b614e28f":"code","3f86c62c":"code","be20c802":"code","314f9ead":"code","4146d352":"code","cd9ca7fe":"markdown","222cf55d":"markdown","583651c3":"markdown","935f865d":"markdown"},"source":{"b3174c5c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport torch \nfrom PIL import Image \nimport cv2\nimport albumentations as A\nfrom matplotlib import patches, pyplot as plt \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77b38a25":"DATA_DIR = \"..\/input\/nfl-impact-detection\/\"\nim_path = \"..\/input\/nfl-impact-detection\/images\/\"","dc926768":"train_label = pd.read_csv(\"..\/input\/nfl-impact-detection\/train_labels.csv\")\nimage_label = pd.read_csv(DATA_DIR+\"image_labels.csv\")\ntrain_player_tracking = pd.read_csv(DATA_DIR+\"train_player_tracking.csv\")","c3de7121":"train_label.head(2)","d200a808":"image_label.head(2)\nlen(image_label[\"image\"].unique())","d810579d":"train_player_tracking.head(2)","c644278a":"len(image_label[\"label\"].unique())","438be29b":"len(train_label[\"label\"].unique())","4096a5d8":"\ndef draw_bb(ax, img, im_df):\n    \n    img_data= im_df[im_df[\"image\"]==img]\n    #print(img_data.shape)\n    for i in range(img_data.shape[0]):\n        data = img_data.iloc[i]\n        bb = patches.Rectangle(\n            (data[\"left\"], \n            data[\"top\"]),\n            data[\"width\"], \n            data[\"height\"],\n            linewidth =2, \n            edgecolor = \"red\"\n        )\n        ax.add_patch(bb)\n            \n    return \n    \ndef plot_img_with_bb():  \n    \n   \n    #image_label = pd.read_csv(DATA_DIR+\"image_labels.csv\")\n    img_list = os.listdir(im_path)\n    \n    fig, ax = plt.subplots(3,3, figsize=(16,14))\n    for i in range(3):\n        for j in range (3):\n            \n            #plt.subplot(3,3,i+1)\n            rand_idx = np.random.randint(len(img_list))\n            img =Image.open(im_path+img_list[rand_idx])\n            #print(img)\n            ax[i][j].imshow(img)\n            \n            draw_bb(ax[i][j], img_list[rand_idx], image_label)\n\n            ax[i][j].set_xticklabels([])\n            ax[i][j].set_yticklabels([])\n        fig.show()\n    fig.subplots_adjust(wspace=0, hspace=0)\n","1cba3d36":"#img_list = image_label[\"image\"].unique()\nplot_img_with_bb()","4926c8e4":"\nclass NFLDataset(object):\n    def __init__(self, df, image_dir):\n    \n        self.image_ids = df['image'].unique()\n        self.df = df\n        self.image_dir = image_dir\n        #self.transforms = transforms\n        self.labels_dict = {\n            'Helmet':1, \n            'Helmet-Blurred':2, \n            'Helmet-Difficult':3, \n            'Helmet-Sideline':4,\n            'Helmet-Partial':5\n        }\n\n    def __getitem__(self, idx:int):\n        # load images ad masks\n        image_id = self.image_ids[idx]\n        image = np.array(Image.open(f'{self.image_dir}\/{image_id}'))\/225.0\n        image = np.moveaxis(image, 2, 0)\n        records = self.df[self.df[\"image\"]==self.image_ids[idx]]\n        boxes = []\n        labels = []\n        for i in range(records.shape[0]):\n            img_data = records.iloc[i]\n            x_min = img_data.left\n            x_max = img_data.left + img_data.width\n            y_min = img_data.top\n            y_max = img_data.top + img_data.height\n            boxes.append([x_min, y_min, x_max, y_max])\n            label = self.labels_dict[img_data.label]\n            labels.append(label)\n\n        # convert everything into a torch.Tensor\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        # there are 5 classes \n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        image  = torch.as_tensor(image , dtype = torch.float32)\n        image_id = torch.tensor([idx])\n        \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        \n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        \n        '''if self.transforms:\n            sample = {\n                'image': image,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n'''\n        return image, target, image_id\n\n    def __len__(self):\n        return self.image_ids.shape[0]","3925f5ca":"#albumentation \ndef get_train_transform():\n    return A.Compose([\n        A.Flip(0.5),\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\ndef get_valid_transform():\n    return A.Compose([\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n","4f325cdc":"import torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\n# load a model pre-trained pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\n# replace the classifier with a new one, that has\n# num_classes which is user-defined\nnum_classes = 6  \n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","a48525f6":"#plt.imshow(Image.open(os.path.join(im_path, image_label[\"image\"][0])).convert(\"RGB\"))\n","f75541f9":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\n\ntrain_dataset = NFLDataset(image_label, im_path)\nvalid_dataset = NFLDataset(image_label, im_path)\n# split the dataset in train and test set\n#indices = torch.randperm(len(dataset)).tolist()\nindices = torch.randperm(len(train_dataset)).tolist()\ntrain_cnt = int(0.9*len(indices))\n\ntrain_dataset = torch.utils.data.Subset(train_dataset,indices[:train_cnt])\nvalid_dataset = torch.utils.data.Subset(valid_dataset,indices[train_cnt:])\n\n\n\ntrain_data_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader =  torch.utils.data.DataLoader(\n    valid_dataset,\n    batch_size=8,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n","4516e802":"#print(len(indices), len(train_dataset), len(valid_dataset))","a8b0554d":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","3da12e6f":"images, targets, image_ids = next(iter(train_data_loader))\nimages = list(image.to(device) for image in images)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]","2b958300":"boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\nsample = images[0].permute(1,2,0).cpu().numpy()","37d9251d":"fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","b614e28f":"model.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\nlr_scheduler = None\n\nnum_epochs = 2\n","3f86c62c":"\n#torch.cuda.empty_cache()\nloss = []\niterations = []\nfor epoch in range(num_epochs):\n    \n\n    for i, batch in enumerate(train_data_loader):\n        if torch.cuda.is_available():\n            images, targets, image_ids = batch\n            images = list(image.to(device) for image in images)\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n            model.train()\n            loss_dict = model(images, targets)\n\n            losses = sum(loss for loss in loss_dict.values())\n            loss_value = losses.item()\n\n            optimizer.zero_grad()\n            losses.backward()\n            optimizer.step()\n            \n            if i % 1000 == 0:\n                print(f\"Iteration #{i} loss: {loss_value}\")\n            \n            loss.append(loss_value)\n            iterations.append(i)\n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n        \n    plt.plot(iterations, loss)\n    plt.show()\n","be20c802":"torch.save(model.state_dict(), \"frcnnresnet50.pth\")","314f9ead":"images, targets, image_ids = next(iter(valid_data_loader))\nimages = list(img.to(device) for img in images)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]\nboxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\nsample = images[0].permute(1,2,0).cpu().numpy()\nmodel.eval()\ncpu_device = torch.device(\"cpu\")\n\noutputs = model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n","4146d352":"fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","cd9ca7fe":"# **Let's Look at our Data**","222cf55d":"# Define and Train Model","583651c3":"**Test**","935f865d":"# Model Faster RCNN "}}