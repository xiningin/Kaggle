{"cell_type":{"0120c160":"code","acf350cc":"code","0123e875":"code","77dc5953":"code","97ea3e60":"code","f43e3339":"code","2b265b18":"code","1edd40fc":"code","8ddcc0e0":"code","0bff4134":"code","239ae813":"code","e7102b07":"code","0ebb3379":"code","a4900cab":"code","0c352651":"code","0d2507b9":"code","56f68017":"code","1c2e064d":"code","03959219":"code","c217b178":"code","a8ed0b61":"code","5d5f4da7":"code","eef35553":"code","e75e762f":"code","ada5ee68":"code","533d8200":"code","c7cdc39a":"code","0d0fe5ff":"code","ecfa188f":"code","839b0c73":"code","fe443b9b":"code","a631861d":"code","49f15c84":"code","95061367":"markdown","9e1e5755":"markdown","579a8e5c":"markdown","b1c8fbcd":"markdown","0339b26d":"markdown","5b43b76b":"markdown","f76064c3":"markdown","9defd21c":"markdown","ddf05eb9":"markdown","20410d7f":"markdown","453bd1cc":"markdown","a763435f":"markdown","a27658fb":"markdown","1e1df938":"markdown","7d3b1d64":"markdown","a6c3c427":"markdown","5ad2e367":"markdown","88851f3b":"markdown","0276fa02":"markdown","a271949d":"markdown","a2512eb1":"markdown","cb76b337":"markdown","707b1efa":"markdown","58b9a7b5":"markdown","097c0ca7":"markdown","e0b940ca":"markdown","aaef1b00":"markdown","d1b37dfe":"markdown","034401d7":"markdown","357e8f8c":"markdown","af36d75a":"markdown","37022b13":"markdown","e14187c9":"markdown","810c0f4c":"markdown","d5706f58":"markdown"},"source":{"0120c160":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport scipy.stats as stats","acf350cc":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom scipy.spatial.distance import pdist, squareform\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics","0123e875":"import warnings #para que no molesten los warnings\nwarnings.filterwarnings('ignore')","77dc5953":"def MDS(D):                                                                                       \n    # Number of points                                                                        \n    n = len(D)\n    # Centering matrix                                                                        \n    H = np.eye(n) - np.ones((n, n))\/n\n    # YY^T                                                                                    \n    B = -H.dot(D**2).dot(H)\/2\n    # Diagonalize                                                                             \n    evals, evecs = np.linalg.eigh(B)\n    # Sort by eigenvalue in descending order                                                  \n    idx   = np.argsort(evals)[::-1]\n    evals = evals[idx]\n    evecs = evecs[:,idx]\n    # Compute the coordinates using positive-eigenvalued components only                      \n    w, = np.where(evals > 0)\n    L  = np.diag(np.sqrt(evals[w]))\n    V  = evecs[:,w]\n    Y  = V.dot(L)\n \n    return Y, evals","97ea3e60":"df = pd.read_csv ('..\/input\/water-potability\/water_potability.csv')\ndf","f43e3339":"df.isnull().sum()","2b265b18":"df[df['Sulfate'].isnull()]\ndf[df['ph'].isnull()]\ndf[df['Trihalomethanes'].isnull()]","1edd40fc":"df['ph']=df['ph'].fillna(df.groupby(['Potability'])['ph'].transform('mean'))\ndf['Sulfate']=df['Sulfate'].fillna(df.groupby(['Potability'])['Sulfate'].transform('mean'))\ndf['Trihalomethanes']=df['Trihalomethanes'].fillna(df.groupby(['Potability'])['Trihalomethanes'].transform('mean'))","8ddcc0e0":"df.isna().sum()","0bff4134":"x = df.drop(\"Potability\", axis=1)\ny = df.Potability\nx_train , x_test , y_train , y_test = train_test_split(x , y, test_size=0.25, random_state=42)","239ae813":"sns.countplot(x=\"Potability\",data=df, palette={0:'red', 1:'green'})\nplt.xlabel('Agua Potable:         1 (verde) -> Si,       0 (rojo) -> No')\nplt.ylabel('Cantidad de agua')\nporc = (len(df[df.Potability==1]) \/ len(df.Potability)) * 100\nprint('The percentage of waters that are potable is: {:.2f}%'.format(porc))","e7102b07":"df[df['Potability']==1].describe().T.style.background_gradient(subset=['mean','std','50%','count'])","0ebb3379":"df[df['Potability']==0].describe().T.style.background_gradient(subset=['mean','std','50%','count'])","a4900cab":"x.describe()","0c352651":"clasification = RandomForestClassifier()\nclasification.fit(x,y)\n\nvariables = x.columns\nimportance = pd.DataFrame()\n\nimportance['Features'] = variables\nimportance['Importance'] = clasification.feature_importances_\nimportance = importance.sort_values(by=['Importance'],ascending=True)\n\nlabels = importance['Features']\nvalues = importance['Importance']\n\nplt.figure(figsize=(10,10))\nplt.pie(values, labels=labels)\nplt.show()","0d2507b9":"fig = plt.figure(figsize = (10,10))\nvar = df.drop(\"Potability\", axis=1)\nax = fig.gca()\nvar.hist(ax=ax)\nplt.show();","56f68017":"pipelines = []\npipelines.append(('Scaled_logistic', Pipeline([('scaler', StandardScaler()),('linear', LogisticRegression())])))\npipelines.append(('Logistic', Pipeline([('linear', LogisticRegression())])))\npipelines.append(('Arbre', Pipeline([('arbre', RandomForestClassifier())])))\npipelines.append(('K-NN', Pipeline([('K-NN', KNeighborsClassifier())])))\n\nfor nombre, modelo in pipelines:\n    a= cross_val_score(modelo, x_train, y_train, cv = 5, scoring = 'accuracy').mean()*100\n    print(\"%s: %f \" % (nombre, a))","1c2e064d":"def fill_missing(df):\n    for column in df.columns:\n        if df[column].isna().sum():\n            df[column].fillna(df[column].median() , inplace=True)\n    return df","03959219":"x_train_filled = fill_missing(x_train)\nfor column in x_train_filled.columns:\n    # convert the training set to all integers\n    x_train_filled[column] = x_train_filled[column].astype(int)","c217b178":"modelo_SVC_Linear = LinearSVC()\nmodelo_SVC_Poly = LinearSVC()\nmodelo_SVC_RBF = LinearSVC()\nmodelo_LR = LogisticRegression()\nmodelo_RF = RandomForestClassifier()\nmodelo_KN = KNeighborsClassifier()","a8ed0b61":"pipelines = []\nresultados_mean = [] \nresultados = []\nnombres= []\n\n#pipelines.append(('SVC_Linear', Pipeline([('linear', SVC(kernel = 'linear', C = 1))])))\npipelines.append(('SVC Poly', Pipeline([('poly', SVC(kernel = 'poly', C = 2, degree = 2))])))\npipelines.append(('SVCRBF', Pipeline([('rbf', SVC(kernel = 'rbf', C = 1, gamma = 0.4))])))\npipelines.append(('Logistic', Pipeline([('linear', LogisticRegression())])))\npipelines.append(('Arbre', Pipeline([('arbre', RandomForestClassifier())])))\npipelines.append(('KNN', Pipeline([('K-NN', KNeighborsClassifier())])))\n\nfor nombre, modelo in pipelines:\n    a = cross_val_score(modelo, x_train, y_train, cv = 5, scoring = 'accuracy').mean()*100\n    b = cross_val_score(modelo, x_train, y_train, cv = 5, scoring = 'accuracy')*100\n    \n    resultados_mean.append(a)\n    resultados.append(b)\n    nombres.append(nombre)\n    \n    print(\"%s: %f \" % (nombre, a))\nprint('Array of results printed: \\n' + str(resultados))","5d5f4da7":"fig, ax = plt.subplots(1, 1, figsize = (25,10)) \nax.set_title('Algorithm comparison')\nprint(resultados)\nax.boxplot(resultados)\nax.set_xticklabels(nombres)\nax.set_ylim(58,77.5)\nplt.show()","eef35553":"sig , ax = plt.subplots(figsize = (10,8))\nscore_data = {\"SVCPoly\" : resultados_mean[0], \"SVCRBF\" : resultados_mean[1], \"LogisticRegression\" : resultados_mean[2], \"Arbre\" : resultados_mean[3], \"KNeighborsClassifier\" : resultados_mean[4]}\nax.set(ylabel = \"Score on test data\", title = \"Comparison of the classification models scores on training\", ylim = (0,110))\nax.bar(score_data.keys() , score_data.values())\n","e75e762f":"df.corr().abs()['Potability'].sort_values(ascending = True)","ada5ee68":"correlation_matrix = df.corr().round(3)\n\nfig, ax = plt.subplots(figsize = (10,10))\nsns.heatmap(data = correlation_matrix, annot = True, ax = ax, cmap = 'RdPu')","533d8200":"Features =['ph','Hardness','Solids','Sulfate','Turbidity','Trihalomethanes']\nx_aux=df[Features]","c7cdc39a":"correlation_matrix =df.drop('Potability',axis=1).corr().round(3)\nfig, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(data=correlation_matrix, ax=ax, annot = True, cmap='YlGnBu')","0d0fe5ff":"x_test_filled = fill_missing(x_test)\nfor column in x_test_filled.columns:\n    x_test_filled[column] = x_test_filled[column].astype(int)","ecfa188f":"dissimilarities = squareform(pdist(df.to_numpy(), 'cityblock')) # Manhattan\ncoords, eigenvals = MDS(dissimilarities)\n\ncolors={0:'blue', 1:'red'}\n\nplt.scatter(x = coords[:, 0], y = coords[:, 1], c = df['Potability'].apply(lambda x: colors[x]) , alpha=0.7)\nplt.xlabel(\"First dimension\")\nplt.ylabel(\"Second dimension\")\nplt.axis('equal')\nplt.title('Dos dimensiones MDS')\nprint('rojos: No Potable, azules: Potable')","839b0c73":"scaler = StandardScaler()\nx_scaler = scaler.fit_transform(x)\nscaler.fit(x)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","fe443b9b":"plt.figure(1, figsize = (5, 5))\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprojected = pca.fit_transform(x_scaler);","a631861d":"fig, ax = plt.subplots(1,2,figsize=(10,5))\n\nax[0].scatter(projected[:,0],projected[:,1], marker='x', alpha=0.4, c=df['Turbidity'], cmap = 'RdPu')\nax[1].scatter(projected[:,0],projected[:,1], marker='x', alpha=0.4, c=df['Trihalomethanes'])\n\nax[0].set_xlabel('PC1') , ax[0].set_ylabel('PC2')\nax[1].set_xlabel('PC1') , ax[1].set_ylabel('PC2')\n\nax[0].axis('equal'), ax[1].axis('equal')\n\nax[0].set_title('PCA in function of the Turbidity in the water'), ax[1].set_title('PCA in function of the Trihalomethanes in the water')","49f15c84":"modelo = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 3)\nmodelo.fit(x_train, y_train)\nprint(metrics.accuracy_score(y_train, modelo.predict(x_train)) * 100)\nprint(metrics.accuracy_score(y_test, modelo.predict(x_test)) * 100)\n\nfig, ax = plt.subplots(1, 1, figsize = (15, 15))\n#x_aux = pd.DataFrame(x)\ntree.plot_tree(modelo, impurity = True, class_names = str(y),feature_names = x.columns); \n","95061367":"Organic carbon -&gt; Quantintity of organic carbon per ppm. ","9e1e5755":"ph -&gt; Ph value of the water.","579a8e5c":"Chloramines -&gt; Chloramine quantities per ppm. ","b1c8fbcd":"### No more null values remain.","0339b26d":"### We create an auxiliary dataset X with only the features that have a >15% correlation with the target","5b43b76b":"All features have a very similar distribution of their values. In addition, they all show a very gaussian form so there is no need to normalize any feature.","f76064c3":"# Part 0: Preprocessing","9defd21c":"This dataset gives us information about potability for different waters with respect to their conductivity, PH, etc. With this information we expect to extract conclusions about which components have a bigger impact on the potability of water.","ddf05eb9":"Conductivity -&gt;Electrical conductivity in \u03bcS\/cm. ","20410d7f":"### We replace them with the mean","453bd1cc":"### There are null values, let's check which:","a763435f":"Trihalomethanes -&gt; Quantity of trihalomethanes in \u03bcg\/L. ","a27658fb":"In the pie chart we can see how the importance of each component is very similar to that of the others. It is obvious how pH and Sulfate, above all, have a very prominent importance compared to the rest, but among the rest of the components the importance of each of them is very similar to that of the others. That is why we have decided that there is no variable worth eliminating, since if we eliminate, for example, Turbidity there is no reason not to eliminate Conductivity or Solids as well since it is obvious that all of them have a very similar importance .","1e1df938":"Data preprocessing is complete","7d3b1d64":"##    We analyze separately those waters that are potable and those that aren't","a6c3c427":"# Part 1: Data visualtization","5ad2e367":"# End of correlation","88851f3b":"#                                                          THE END :D","0276fa02":"Potability -&gt; Indicates if water is or isn't suitable for human consumption","a271949d":"### We check for null values","a2512eb1":"Hardness -&gt; capacity of water to precipitate soap in mg \/ l. ","cb76b337":"## Dimensionality reduction","707b1efa":"# We predict water potability with a 74.11% success!","58b9a7b5":"## Representation of the random forest classifier","097c0ca7":"###                                                                                  Histograms","e0b940ca":"Solids -&gt; Total dissolved solids per ppm.","aaef1b00":"Sulfate -&gt; Dissolved sulfates per ppm. ","d1b37dfe":"###                                                                       Lets find out which are the most important variables","034401d7":"### Meaning of the variables:","357e8f8c":"Turbidity -&gt; Light emission measurement of water in NTU (Nephelometric Turbidity Units). ","af36d75a":"# Part 2: Models","37022b13":"We can see how the RandomForest model is the one that gives us the highest accuracy compared to the others, so we will use this model as the final model for this project.","e14187c9":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https:\/\/deepnote.com?utm_source=created-in-deepnote-cell&projectId=4a6c4b65-4e9c-4671-99fe-0a1467985330' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image\/svg+xml;base64,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' > <\/img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote<\/span><\/a>","810c0f4c":"###                                      We aggregate a function to fill any missing values","d5706f58":"# Correlation"}}