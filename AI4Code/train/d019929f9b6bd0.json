{"cell_type":{"665009ee":"code","39fb46a2":"code","528876b2":"code","710f5d42":"code","a97c962f":"code","4615f7f1":"code","0f970b96":"code","242ac774":"code","b7018e5a":"code","9fce988a":"code","d597808c":"code","7bb001ee":"markdown","de4a64c3":"markdown","df462bde":"markdown","383efd67":"markdown","8e6e45a6":"markdown","188d4358":"markdown"},"source":{"665009ee":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport torch","39fb46a2":"def matmul(a,b):\n    arow, acol = a.shape\n    brow, bcol = b.shape\n    c = torch.zeros(arow, bcol) # creating the output array\n    for i in range(arow):\n            #print(i)\n            for j in range(acol):\n                    for k in range(bcol):\n                        c[i,k] = a[i,j] * b[j,k]\n    return(c)","528876b2":"x = torch.randn(2,1)\ny = torch.randn(1,2)","710f5d42":"z = matmul(x,y)","a97c962f":"print(z)","4615f7f1":"def matmul(a,b):\n    arow, acol = a.shape\n    brow, bcol = b.shape\n    c = torch.zeros(arow, bcol) # creating the output array\n    for i in range(arow):\n            #print(i)\n            for j in range(acol):\n                for k in range(bcol):\n                    c[i,k] = (a[i,:] * b[:,k]).sum()\n    return(c)","0f970b96":"z = matmul(x,y)\nprint(z)\n# The output should confirm to earlier one.","242ac774":"def matmul(a,b):\n    arow, acol = a.shape\n    brow, bcol = b.shape\n    c = torch.zeros(arow, bcol) # creating the output array\n    for i in range(arow):\n        c[i,:] = (a[i,None] * b).sum(dim = 0)\n    return(c)","b7018e5a":"print(matmul(x,y))","9fce988a":"def matmul(a,b): return torch.einsum('ik,kj->ij', a, b)","d597808c":"matmul(x,y)","7bb001ee":"That's it for now. Thanks for reading and please do send your feedback through the comments section.\n\nNote: This Kernel is produced by following Jeremy Howard's FastAI course. You can check this out at fast.ai\n","de4a64c3":"MATMUL - following is implemented using purely python.","df462bde":"So, we are down from three loops to one loop using row\/column operations in one go instead element wise and using boradcasting. This is using Einstein Summation or **EinSum**. Two same letters on different inputs means it does a dot product for us. ","383efd67":"Above can be made faster by getting rid of the third loop. In general, we should try to avoid loops wherever possible. Code above is the version 2 of matmul where we do entire row\/column operation once.","8e6e45a6":"# Matrix Multiplication \nis a basic building block which is used almost all the time while doing deep learning. Here we will implement a basic version of this.","188d4358":"We will now use broadcasting which is even faster. Here we are taking one more loop off with help of boradcasting."}}