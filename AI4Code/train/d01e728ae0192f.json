{"cell_type":{"ef91543d":"code","66986d42":"code","9ac1192d":"code","6da1326a":"code","fe51f5b5":"code","145f83c6":"code","c7566619":"code","108151dc":"code","9a61b5f1":"code","d86d165a":"code","263c36c9":"code","84afec73":"code","97619a40":"code","b641cbc5":"code","e6357045":"code","20972a30":"code","0077a575":"code","37c55a26":"code","0a6b0d45":"code","131645be":"code","68f677f2":"code","c262b584":"code","b9e8d2b8":"code","73b7e900":"code","2c6d2236":"code","18075f62":"code","6054d2ca":"code","064753af":"code","1987c60d":"code","c1195e81":"code","dbd2e773":"code","80ceb735":"code","9cbcd75d":"code","1698dc27":"code","228667fe":"code","09abd845":"code","6b571531":"code","a564e74c":"code","9b8c12a4":"code","191c6f9e":"code","5aad64a2":"code","fe4c80f8":"code","2eb0d72f":"code","f5f7f80c":"code","cc55b62a":"code","7816e8b6":"code","0b6310cc":"code","73be3c66":"code","e3473e8a":"code","f2de687c":"code","e2515054":"code","f290e4ac":"code","8e6c2946":"code","2f58fe63":"code","d1bc3171":"code","fcfa77bf":"code","98ff669c":"code","59af24bd":"markdown","3e169f52":"markdown","d584770c":"markdown","cc317d5b":"markdown","65c44243":"markdown","30e32094":"markdown","ff0fac1c":"markdown","9b3e3ea2":"markdown","cc933513":"markdown","fff720b4":"markdown","83910183":"markdown","84071af3":"markdown","70dffa25":"markdown","8129ca5d":"markdown","d0dd9914":"markdown","4e0edf0e":"markdown","801c7fc4":"markdown"},"source":{"ef91543d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","66986d42":"train_df = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv\")","9ac1192d":"train_df.head()","6da1326a":"india = train_df[train_df[\"Country_Region\"]==\"India\"]","fe51f5b5":"india.head()","145f83c6":"india.tail()","c7566619":"plt.figure(figsize=(10,6))\nplt.plot(india[\"ConfirmedCases\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Confirmed Cases\")","108151dc":"plt.figure(figsize=(10,6))\nplt.plot(india[\"Fatalities\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Fatalities\")","9a61b5f1":"china_states = train_df[train_df[\"Country_Region\"]==\"China\"][\"Province_State\"].unique()","d86d165a":"train_df[\"Province_State\"].unique()","263c36c9":"def province(state,country):\n    if state == \"nan\":\n        return country\n    return state","84afec73":"train_df = train_df.fillna(\"nan\")","97619a40":"train_df[\"Province_State\"] = train_df.apply(lambda x: province(x[\"Province_State\"],x[\"Country_Region\"]),axis=1)","b641cbc5":"train_df","e6357045":"china_states","20972a30":"italy = train_df[train_df[\"Country_Region\"]==\"Italy\"]","0077a575":"plt.figure(figsize=(10,6))\nplt.plot(italy[\"ConfirmedCases\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Confirmed Cases\")","37c55a26":"plt.figure(figsize=(10,6))\nplt.plot(italy[\"Fatalities\"])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Fatalities Cases\")","0a6b0d45":"from datetime import datetime","131645be":"train_df.info()","68f677f2":"train_df[\"Date\"] = pd.to_datetime(train_df[\"Date\"])","c262b584":"train_df[\"month\"] = train_df[\"Date\"].dt.month","b9e8d2b8":"train_df.head()","73b7e900":"train_df['day'] = train_df['Date'].dt.day","2c6d2236":"train_df.tail()","18075f62":"train_df.drop('Date',axis=1,inplace=True)","6054d2ca":"train_df.head()","064753af":"from sklearn import preprocessing","1987c60d":"def labelencoder(data):\n    le = preprocessing.LabelEncoder()\n    new_data = le.fit_transform(data)\n    return new_data","c1195e81":"train_df[\"Country_Region\"] = labelencoder(train_df[\"Country_Region\"].values)\ntrain_df[\"Province_State\"] = labelencoder(train_df[\"Province_State\"].values)","dbd2e773":"train_df.head()","80ceb735":"test_df = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv\")","9cbcd75d":"test_df[\"Date\"] = pd.to_datetime(test_df[\"Date\"])","1698dc27":"test_df['day'] = test_df['Date'].dt.day","228667fe":"test_df[\"month\"] = test_df[\"Date\"].dt.month","09abd845":"test_df.drop('Date',axis=1,inplace=True)\ntest_df.head()","6b571531":"test_df.fillna(\"nan\",inplace=True)\ntest_df[\"Province_State\"] = test_df.apply(lambda x: province(x[\"Province_State\"],x[\"Country_Region\"]),axis=1)","a564e74c":"test_df.head()","9b8c12a4":"test_df[\"Country_Region\"] = labelencoder(test_df[\"Country_Region\"].values)\ntest_df[\"Province_State\"] = labelencoder(test_df[\"Province_State\"].values)","191c6f9e":"test_df.head()","5aad64a2":"countries = train_df[\"Country_Region\"].unique()","fe4c80f8":"from sklearn.preprocessing import PolynomialFeatures\n#from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler","2eb0d72f":"poly_reg_cc = PolynomialFeatures(degree = 4)\npoly_reg_ft = PolynomialFeatures(degree = 4)\n\nreg_cc = LinearRegression()\nreg_ft = LinearRegression()\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfor country in countries:\n    states = train_df[train_df[\"Country_Region\"]==country][\"Province_State\"].unique()\n    for state in states:\n        train_df_filt = train_df[(train_df[\"Country_Region\"]==country)&(train_df[\"Province_State\"]==state)]\n        y_train_cc = train_df_filt[\"ConfirmedCases\"].values\n        y_train_ft = train_df_filt[\"Fatalities\"].values\n        \n        \n        X_train = train_df_filt[[\"month\",\"day\"]]\n    \n        \n        test_df_filt = test_df[(test_df[\"Country_Region\"]==country)&(test_df[\"Province_State\"]==state)]\n        X_test = test_df_filt.drop('ForecastId',axis=1)\n        X_test = X_test[[\"month\",\"day\"]]\n        test_Id = test_df_filt[\"ForecastId\"].values\n        \n        scaler = MinMaxScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n        \n        \n        scaler_cc = MinMaxScaler()\n        scaler_ft = MinMaxScaler()\n        \n        y_train_cc=y_train_cc.reshape(-1,1)\n        y_train_ft=y_train_ft.reshape(-1,1)\n        \n        y_train_cc=scaler_cc.fit_transform(y_train_cc)\n        y_train_ft=scaler_ft.fit_transform(y_train_ft)\n        \n        y_train_cc = y_train_cc.flatten()\n        y_train_ft = y_train_ft.flatten()\n        \n        X_train_poly = poly_reg_cc.fit_transform(X_train)\n        reg_cc.fit(X_train_poly,y_train_cc)\n        X_test_poly = poly_reg_cc.fit_transform(X_test)\n        test_cc = reg_cc.predict(X_test_poly)\n        \n        test_cc = test_cc.reshape(-1,1)\n        test_cc = scaler_cc.inverse_transform(test_cc)\n        test_cc = test_cc.flatten()\n        \n        X_train_poly = poly_reg_ft.fit_transform(X_train)\n        reg_ft.fit(X_train_poly,y_train_ft)\n        X_test_poly = poly_reg_ft.fit_transform(X_test)\n        test_ft = reg_ft.predict(X_test_poly)\n        \n        test_ft = test_ft.reshape(-1,1)\n        \n        test_ft = scaler_ft.inverse_transform(test_ft)\n        test_ft = test_ft.flatten()\n        \n        df = pd.DataFrame({'ForecastId': test_Id, 'ConfirmedCases': test_cc, 'Fatalities': test_ft})\n        \n        df_out = pd.concat([df_out, df], axis=0)","f5f7f80c":"df_out[:20]","cc55b62a":"df_out.head()","7816e8b6":"df_out[\"Fatalities\"] = df_out[\"Fatalities\"].apply(int)\ndf_out[\"ConfirmedCases\"] = df_out[\"ConfirmedCases\"].apply(int)\ndf_out[:10]","0b6310cc":"df_out[\"ForecastId\"] = df_out[\"ForecastId\"].astype('int32')\ndf_out[\"Fatalities\"] = df_out[\"Fatalities\"].astype('int32')\ndf_out[\"ConfirmedCases\"] = df_out[\"ConfirmedCases\"].astype('int32')\ndf_out.info()\ndf_out.to_csv(\"submission.csv\",index=False)\nsub = pd.read_csv(\"submission.csv\")\nsub[:20]","73be3c66":"train = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv\")\n\ntrain[\"Province_State\"] = train[\"Province_State\"].fillna('')\ntest[\"Province_State\"] = test[\"Province_State\"].fillna('')\n\ntrain[\"Month\"], train[\"Day\"] = 0, 0\nfor i in range(len(train)):\n    train[\"Month\"][i] = (train[\"Date\"][i]).split(\"-\")[1]\n    train[\"Day\"][i] = (train[\"Date\"][i]).split(\"-\")[2]\n    \ntest[\"Month\"], test[\"Day\"] = 0, 0\nfor i in range(len(test)):\n    test[\"Month\"][i] = (test[\"Date\"][i]).split(\"-\")[1]\n    test[\"Day\"][i] = (test[\"Date\"][i]).split(\"-\")[2]","e3473e8a":"for i in range(len(train)):\n    if train[\"Province_State\"][i] != '':\n        train[\"Country_Region\"][i] = str(train[\"Province_State\"][i]) + \" (\" + str(train[\"Country_Region\"][i]) + \")\"\n       \nfor i in range(len(test)):\n    if test[\"Province_State\"][i] != '':\n        test[\"Country_Region\"][i] = str(test[\"Province_State\"][i]) + \" (\" + str(test[\"Country_Region\"][i]) + \")\"\n        \ntrain.drop(columns = \"Province_State\", inplace=True)\ntest.drop(columns = \"Province_State\", inplace=True)\n\ntrain.rename(columns = {\"Country_Region\" : \"Country\/State\"}, inplace=True)\ntest.rename(columns = {\"Country_Region\" : \"Country\/State\"}, inplace=True)\n","f2de687c":"train.tail()","e2515054":"i = 0\nfor value in train[\"Country\/State\"].unique():\n    if i < len(train):\n        j = 1\n        while(train[\"Country\/State\"][i] == value):\n            train[\"Day\"][i] = j\n            j += 1; i += 1\n            if i == len(train):\n                break\n\ni = 0\nfor value in test[\"Country\/State\"].unique():\n    if i < len(test):\n        j = 72\n        while(test[\"Country\/State\"][i] == value):\n            test[\"Day\"][i] = j\n            j += 1; i += 1\n            if i == len(test):\n                break","f290e4ac":"train = train.drop(columns = [\"Date\"])\ntest = test.drop(columns = [\"Date\"])","8e6c2946":"countries = train[\"Country\/State\"].unique()","2f58fe63":"from sklearn.preprocessing import PolynomialFeatures\npoly_reg_cc = PolynomialFeatures(degree = 4)\npoly_reg_ft = PolynomialFeatures(degree = 4)\n\nfrom sklearn.linear_model import LinearRegression\nreg_cc = LinearRegression()\nreg_ft = LinearRegression()\n\nfrom sklearn.preprocessing import StandardScaler\n\nsub = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\nfor value in countries:\n    train_temp = train.loc[train[\"Country\/State\"] == value]\n    test_temp = test.loc[test[\"Country\/State\"] == value]\n    train_temp_cc = train_temp[\"ConfirmedCases\"].loc[train[\"Country\/State\"] == value].to_frame()\n    train_temp_ft = train_temp[\"Fatalities\"].loc[train[\"Country\/State\"] == value].to_frame()\n    \n    train_temp_X = train_temp.iloc[:, 4:6]\n    test_temp_X = test_temp.iloc[:, 2:4]\n    sc1 = StandardScaler()\n    train_temp_X = sc1.fit_transform(train_temp_X)\n    test_temp_X = sc1.transform(test_temp_X)\n    \n    sc_cc = StandardScaler()\n    sc_ft = StandardScaler()\n    train_temp_cc = sc_cc.fit_transform(train_temp_cc)\n    train_temp_ft = sc_ft.fit_transform(train_temp_ft)\n    \n    X_poly = poly_reg_cc.fit_transform(train_temp_X)\n    reg_cc.fit(X_poly, train_temp_cc)\n    test_cc = sc_cc.inverse_transform(reg_cc.predict(poly_reg_cc.fit_transform(test_temp_X)))\n    \n    X_poly = poly_reg_ft.fit_transform(train_temp_X)\n    reg_ft.fit(X_poly, train_temp_ft)\n    test_ft = sc_ft.inverse_transform(reg_ft.predict(poly_reg_ft.fit_transform(test_temp_X)))\n    \n    a = int(train[\"Day\"].loc[train[\"Country\/State\"] == \"India\"].max())\n    b = int(a - test_temp[\"Day\"].min())\n    \n    test_cc[0:b+1] = sc_cc.inverse_transform(train_temp_cc)[(a-b-1):(a)]\n    test_ft[0:b+1] = sc_ft.inverse_transform(train_temp_ft)[(a-b-1):(a)]\n    \n    test_cc = test_cc.flatten()\n    test_ft = test_ft.flatten()\n    sub_temp = pd.DataFrame({'ForecastId': test_temp[\"ForecastId\"].loc[test[\"Country\/State\"] == value],\n                             'ConfirmedCases': test_cc, 'Fatalities': test_ft})\n    sub = pd.concat([sub, sub_temp], axis = 0)","d1bc3171":"sub[\"ForecastId\"] = sub[\"ForecastId\"].astype('int32')","fcfa77bf":"sub[:20]","98ff669c":"sub.to_csv(\"submission.csv\", index = False)","59af24bd":"# **One Thing I have noticed that the curve of a countries confirmed cases and fatalities looks pretty same And it make sense if you think, if the confirmed cases fluctuates deaths would also increase or decrease. **","3e169f52":"**Converting the date column to datetime datatype so that we can extract day and month from it**","d584770c":"# Here I did all the steps for the test data as I did with train.","cc317d5b":"**It started slow but as you can see it has started to increase rapidly and its not a good sign.**","65c44243":"# This is my first kernel explanation, I am not that good at explaining but the code is pretty clear in it self. I hope you are safe and fit.\n# Please upvote if you think it helped\n","30e32094":"# I thought of using the country and state column as a variable but the results were not good so I excluded them. So labelencoder is not required and but I kept it.(you can remove this as this will not effect the result).","ff0fac1c":"**Again you see both the plot looks the same.**","9b3e3ea2":"**I was checking how many states\/province are there in china**","cc933513":"# This is the important part.\n\n# Using a linear regressor wont work well as you can see the curve is not really linear.\n# Using just Linear regression will just coincide with some of the data.\n# Here is a link to a good post about it https:\/\/towardsdatascience.com\/machine-learning-polynomial-regression-with-python-5328e4e8a386)","fff720b4":"**Both the plot looks pretty same. For a minute I thought that I have done some mistake but not. **","83910183":"**No need fot the date column now, so dropping it**","84071af3":"**Extracting the day of the month**","70dffa25":"**Lets extract data about India out and plot it.**","8129ca5d":"**Italy is struggling right now so i thought to so see whats going on.**","d0dd9914":"**I filled all the nan value with a string nan this string could be anything.**","4e0edf0e":"**As there are many countries for which the province\/state column is nan so i thought to put the country name if it is nan.**","801c7fc4":"**The condition has not improved a lot its still increasing and thats not good.**"}}