{"cell_type":{"142b1972":"code","35858c5d":"code","c64ebc02":"code","43ac1a65":"code","04252776":"code","39289a12":"code","b55c3207":"code","38db564a":"code","9c09faf1":"code","6e95a5f7":"markdown","8cef8d40":"markdown","cda4a6ed":"markdown","e63d4d7e":"markdown","290eafff":"markdown","7c265c89":"markdown","63caf557":"markdown","4af71e1d":"markdown"},"source":{"142b1972":"import numpy as np\nimport pandas as pd\nimport os, json, gc, re, random\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)","35858c5d":"%%time\n\n!pip uninstall -q torch -y\n!pip install -q torch==1.6.0+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n!pip install -q -U tokenizers==0.7.0 > \/dev\/null\n!pip install -q -U transformers==3.0.2 > \/dev\/null\n!pip install -q -U simpletransformers==0.46.0 > \/dev\/null","c64ebc02":"import torch, transformers, tokenizers\ntorch.__version__, transformers.__version__, tokenizers.__version__","43ac1a65":"movies_df = pd.read_csv(\"..\/input\/wikipedia-movie-plots\/wiki_movie_plots_deduped.csv\")\nmovies_df.head()","04252776":"movies_df = movies_df[(movies_df[\"Origin\/Ethnicity\"]==\"American\") | (movies_df[\"Origin\/Ethnicity\"]==\"British\")]\nmovies_df = movies_df[[\"Plot\", \"Title\"]]\nmovies_df.columns = ['input_text', 'target_text']\nmovies_df","39289a12":"%%time\n\nfrom simpletransformers.seq2seq import Seq2SeqModel\n\neval_df = movies_df.sample(frac=0.1, random_state=42)\ntrain_df = movies_df.drop(eval_df.index)\n\nmodel_args = {\n    \"reprocess_input_data\": True,\n    \"overwrite_output_dir\": True,\n    \"save_model_every_epoch\": False,\n    \"save_eval_checkpoints\": False,\n    \"max_seq_length\": 512,\n    \"train_batch_size\": 8,\n    \"num_train_epochs\": 2,\n}\n\n# Create a Bart-base model\nmodel = Seq2SeqModel(encoder_decoder_type=\"bart\",\n                    encoder_decoder_name=\"facebook\/bart-base\",\n                    args=model_args)","b55c3207":"train_df","38db564a":"%%time\n\n# Train the model\nmodel.train_model(train_df)\n\n# Evaluate the model\nresult = model.eval_model(eval_df)\nprint(result)","9c09faf1":"test_df = eval_df.sample(n=200)\n\nfor idx, row in test_df.iterrows():\n\n    plot = row['input_text']\n    true_title = row['target_text']\n\n    # Predict with trained BART model\n    predicted_title = model.predict([plot])[0]\n\n    print(f'True Title: {true_title}\\n')\n    print(f'Predicted Title: {predicted_title}\\n')\n    print(f'Plot: {plot}\\n\\n\\n')","6e95a5f7":"## Introduction\n\n#### In this notebook, we use [BART](https:\/\/arxiv.org\/abs\/1910.13461) Transformer model to perform title generation from plot. BART is a sequence-to-sequence model where both the input and targets are text sequences. BART is commonly used for text summarization. In our case, we would want to summarize movie titles from plots.","8cef8d40":"### Prediction \ud83d\udd2e","cda4a6ed":"### Read CSV Data \ud83d\udcdd","e63d4d7e":"### Model Training & Evaluation \ud83d\ude9e","290eafff":"### Data Pre-processing \u2699\ufe0f","7c265c89":"### Libraries \ud83d\udcda\u2b07","63caf557":"### If you found this kernel helpful, please upvote it \ud83d\ude9e","4af71e1d":"<h1><center>Movie Title Prediction from Plot<\/center><\/h1>\n\n<img src=\"https:\/\/www.caleidoscope.in\/wp-content\/uploads\/2011\/12\/Wikipedia-logo-1024x576.jpg\" width=\"600\" height=\"600\" \/>"}}