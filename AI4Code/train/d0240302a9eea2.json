{"cell_type":{"afcc83db":"code","7cf5ed1e":"code","55f1df7a":"code","66621847":"code","2af11364":"code","1d1d8c5a":"code","35f69f27":"code","20c1e3f8":"code","72250e65":"code","dae16c56":"code","eb60d209":"code","ddc82ee1":"code","7f879f0d":"code","6535a715":"code","550bd04a":"code","33da8beb":"code","3e91d50e":"code","4cc6e646":"code","aef04850":"markdown","f1e74eb0":"markdown","90504bc0":"markdown","9b537441":"markdown","4b8e1628":"markdown","4edf7c44":"markdown","78e57e31":"markdown","57398367":"markdown","04f69abd":"markdown","b8d92465":"markdown","e4a79c80":"markdown","8f619f5b":"markdown","10d1c3c4":"markdown","298e475a":"markdown","e5a93bff":"markdown","003428d6":"markdown","f513672f":"markdown","1e37ab71":"markdown","274892fc":"markdown","be473dab":"markdown","14e43db9":"markdown","5d0811f3":"markdown"},"source":{"afcc83db":"! conda install -y gdown ##","7cf5ed1e":"# %cd \/opt\/conda\/bin\/\n# !python3.7 -m pip install --upgrade pip","55f1df7a":"# !pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n# !pip install numpy==1.17\n# !pip install PyYAML==5.3.1\n# !pip install git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI\n#We'll also install [Apex by NVIDIA]\n# !git clone https:\/\/github.com\/NVIDIA\/apex && cd apex && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" . --user && cd .. && rm -rf apex","66621847":"from pathlib import Path\nfrom tqdm import tqdm\nimport numpy as np\nimport json\nimport urllib\nimport PIL.Image as Image\nimport cv2\nimport torch\nimport torchvision\nfrom IPython.display import display\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nrcParams['figure.figsize'] = 16, 10\n\nnp.random.seed(42)","2af11364":"%cd \/kaggle\/working\/\nimport os\noutput=\"source\"\nif not os.path.exists(output):\n    os.makedirs(output)\n    \n%cd \/kaggle\/working\/source    \n\n# start download dataset \n!gdown --id 1CSmV4VtjGpq6e2CBueeEypx9XVuQDQaG\n!tar -zxf dataset_21_6147.tar.gz\n!rm -rf dataset_21_6147.tar.gz\n\n\n# download yolov5 \n!gdown --id 1-3jQu-rjBL-Act00RHQJR8a3L06vkS1E\n!tar -zxf yolov5.tar.gz\n!rm -rf yolov5.tar.gz","1d1d8c5a":"# %cd \/kaggle\/working\/\n# # download pre-trained \n# !gdown --id 11YkPRYum6afXTlLPYneYxwS07Lufytfa\n# %mv last.pt \/kaggle\/working\/source\/yolov5\/weights\/","35f69f27":"%cp -arvf \/kaggle\/input\/last-pre-trained-model-yolov5-epoch162\/last_yolov5x_21_1820.pt \/kaggle\/working\/source\/yolov5\/weights\/best_yolov5x_21_1820.pt","20c1e3f8":"\n# import os\n# output=\"\/kaggle\/working\/yolo\"\n# if not os.path.exists(output):\n#     os.makedirs(output)\n    \n# %cd \/kaggle\/working\/yolo\n\n# import os\n# output=\"dataset_21_2825_2\"\n# if not os.path.exists(output):\n#     os.makedirs(output)\n    \n# %cd  dataset_21_2825_2\n\n\n# !curl -L \"https:\/\/app.roboflow.ai\/ds\/QKJSwZ1IzA?key=gQ0GD10nQO\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n\n\n# #add folder test to valid because we will not needed\n\n# %cd \/kaggle\/working\/yolo\/dataset_21_2825_2\n# %cp -arvn test\/images\/* valid\/images \n# %cp -arvn test\/labels\/* valid\/labels\n# !rm -rf test\n\n# %cd \/kaggle\/working\/yolo\/dataset_21_2825_2\n# %mv train\/images train\/train\n# %mv train\/labels  valid\/train\n\n# %mv valid\/images  train\/val\n# %mv  valid\/labels valid\/val\n\n# %mv train images\n# %mv valid labels\n\n\n# #Check number of each class\n\n# import csv\n# import os\n# import copy\n\n# def convert_list_to_string(org_list, seperator=' '):\n#        # Convert list to string, by joining all item in list with given separator.\n#        # Returns the concatenated string \n#     return seperator.join(org_list)\n\n# def checkClasses(input_dir,input_folder,output_folder):\n#     output=os.path.join(input_dir,output_folder)\n#     names=['fusible5','fusible10mini','fusible15Medium','fusible15mini','fusible20','fusible20Medium','fusible20mini','fusible30Double','fusible30Medium','fusible40','fusible40Medium','fusible50','fusible60','fusible70','fusible80','Metale80A','relai','relaiGreen','relaiYellow','symbole','vide']\n#     if not os.path.exists(output):\n#         os.makedirs(output)\n#     print(\"\\n\"+input_folder+\"\\n\")\n#     cpt=0\n#     output_file=os.path.join(input_dir,output_folder)\n#     N=len(os.listdir(os.path.join(input_dir,input_folder)))\n#     for fileName in os.listdir(os.path.join(input_dir,input_folder)):\n#       # Delete this file \".ipynb_checkpoints\" and this is \".ipynb_checkpoints.txt\" if they found\n#       if fileName!=\".ipynb_checkpoints\" and fileName != \".ipynb_checkpoints.txt\":\n        \n#         input_file=os.path.join(input_dir,input_folder,fileName)\n#         output_file=os.path.join(input_dir,output_folder,fileName)\n#         # Using readlines() \n#         file1 = open(input_file, 'r') \n#         file2 = open(output_file, 'w') \n#         Lines = file1.readlines() \n#         className=fileName.split(\"_jpg.\")[0]\n#         numOfClass=names.index(className)\n#         cpt+=1\n#         # Strips the newline character \n#         for line in Lines: \n          \n#           # Replace the target string\n#           column=line.split(\" \")\n#           column[0]=str(numOfClass)\n#           line = convert_list_to_string(column)\n#           file2.write(line)\n#         file2.close()\n#         file1.close()\n#         print(\"\\rpercent {:.2f}%\".format(100*cpt\/N), end='')\n\n\n\n# input_dir= \"\/kaggle\/working\/yolo\/dataset_21_2825_2\/labels\"\n# input_folder=\"train\"\n# output_folder=\"train1\"\n# checkClasses(input_dir,input_folder,output_folder)\n# input_folder=\"val\"\n# output_folder=\"val1\"\n# checkClasses(input_dir,input_folder,output_folder)\n\n\n# print(\"\\n******\\n\")\n# %cd \/kaggle\/working\/yolo\/dataset_21_2825_2\/labels\n# !rm -rf  train val\n\n# !mv train1 train\n# !mv val1 val\n","72250e65":"%cd \/kaggle\/working\/source\/yolov5\n!python train.py  --batch 4 --epochs 180 \\\n  --data ..\/data\/data_21_6147.yaml  \\\n  --name yolov5x_21_1820  --img 1024 --cfg  ..\/models\/yolov5x.yaml --weights .\/weights\/best_yolov5x_21_1820.pt \\\n  # --adam #--cache --weights .\/weights\/last.pt --epochs 1820 --cache-images","dae16c56":"#the last model checkpoint \n#%cp -arvn \/kaggle\/working\/source\/yolov5\/weights\/last.pt \/kaggle\/working\/\n#the best model checkpoint\n#%cp -arv \/kaggle\/working\/source\/yolov5\/weights\/best_yolov5x_21_6147.pt \/kaggle\/working\/","eb60d209":"%cd \/kaggle\/working\/source\/yolov5\n# Look at training curves in tensorboard:\n%load_ext tensorboard\n%tensorboard --logdir=runs","ddc82ee1":"%cd \/kaggle\/working\/source\/yolov5\n!ls -l .\/weights\/","7f879f0d":"from utils.utils import plot_results\n\nplot_results();","6535a715":"# Run YOLOv5s on COCO test-dev2017 with argument --task test\n%cd \/kaggle\/working\/source\/yolov5\n\n# Run YOLOv5s on COCO test-dev2017 with argument --task test\n!python test.py --weights .\/weights\/best_yolov5x_21_1820.pt  --data ..\/data\/data_21_6147.yaml --task val","550bd04a":"#%cd \/kaggle\/working\/source\/yolov5\n#!find ..\/dataset_21_2825\/images\/val\/ -maxdepth 1 -type f | head -3  | xargs cp -t \".\/inference\/images\/\"","33da8beb":"%cd \/kaggle\/working\/source\/yolov5\nimport os,cv2\nimport matplotlib.pyplot as plt\ninput_dir=\"\/kaggle\/working\/source\/yolov5\/inference\/output\"\n\n#--conf 0.015\n!python detect.py --weights .\/weights\/best_yolov5x_21_1820.pt --conf 0.015 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\"--conf 0.015\")\n  plt.show()  \n\n#--conf 0.01\n!python detect.py --weights .\/weights\/best_yolov5x_21_1820.pt --conf 0.01 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\"--conf 0.01\")\n  plt.show()  \n\n\n#--conf 0.01\n!python detect.py --weights .\/weights\/best_yolov5x_21_1820.pt --conf 0.0099 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\"--conf 0.0099\")\n  plt.show()  \n\n\n#--conf --conf 0.0018\n!python detect.py --weights .\/weights\/best_yolov5x_21_1820.pt --conf 0.0018 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\"--conf 0.0018\")\n  plt.show()  \n\n\n\n#--conf 0.01\n!python detect.py --weights .\/weights\/best_yolov5x_21_1820.pt --conf 0.001 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\" --conf 0.001 \")\n  plt.show()  \n\n\n#--conf 0.0005\n!python detect.py --weights .\/weights\/best_yolov5x_21_1820.pt --conf 0.0005 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\" --conf 0.001 \")\n  plt.show()  ","3e91d50e":"%cp -arvf \/kaggle\/input\/last-pre-trained-yolov5-epoch20\/last_yolov5x_21_1820.pt \/kaggle\/working\/source\/yolov5\/weights\/best_model.pt","4cc6e646":"%cd \/kaggle\/working\/source\/yolov5\nimport os,cv2\nimport matplotlib.pyplot as plt\ninput_dir=\"\/kaggle\/working\/source\/yolov5\/inference\/output\"\n\n#--conf 0.05\n!python detect.py --weights .\/weights\/best_model.pt --conf 0.012 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\" --conf 0.012 \")\n  plt.show()  \n\n\n#--conf 0.01\n!python detect.py --weights .\/weights\/best_model.pt --conf 0.01 --source inference\/images\/  --img 1024 # --view-img\n\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\"--conf 0.01\")\n  plt.show()  ","aef04850":"Looks like the mean average precision (mAP) is getting better throughout the training. The model might benefit from more training, but it is good enough.","f1e74eb0":"**make a copy of our model for the last model checkpoint  and the best model checkpoint**","90504bc0":"# **Test**","9b537441":"We'll use the `detect.py` script to run our model on the images. Here are the parameters we're using:\n\n- weights weights\/best_yolov5x.pt - checkpoint of the model\n- img 1024 - resize the images to 1024x1024 px\n- conf 0.4 - take into account predictions with confidence of 0.4 or higher\n- source .\/inference\/images\/ - path to the images","4b8e1628":"# **Trianing**","4edf7c44":"We need two configuration files. One for the dataset and one for the model we're going to use. Let's download them:","78e57e31":"# Object Detection on a Custom Dataset using YOLO v5\n\n> TL;DR Learn how to build a custom dataset for YOLO v5 (darknet compatible) and use it to fine-tune a large object detection model. The model will be ready for real-time object detection on mobile devices.\n\nIn this tutorial, you'll learn how to fine-tune a pre-trained YOLO v5 model for detecting and classifying clothing items from images.\n\n- [Read the tutorial](https:\/\/www.curiousily.com\/posts\/object-detection-on-custom-dataset-with-yolo-v5-using-pytorch-and-python\/)\n- [Run the notebook in your browser (Google Colab)](https:\/\/colab.research.google.com\/drive\/1e4zvS6LyhOAayEDh3bz8MXFTJcVFSvZX?usp=sharing)\n- [Read the `Getting Things Done with Pytorch` book](https:\/\/github.com\/curiousily\/Getting-Things-Done-with-Pytorch)\n\nHere's what we'll go over:\n\n- Install required libraries\n- Build a custom dataset in YOLO\/darknet format\n- Learn about YOLO model family history\n- Fine-tune the largest YOLO v5 model\n- Evaluate the model\n- Look at some predictions\n\nHow good our final model is going to be?\n\n","57398367":"# **Prerequisites**\nLet's start by installing some required libraries by the YOLOv5 project:","04f69abd":"# **use the last model of previous output**","b8d92465":"**take look to folder weight**","e4a79c80":"## **Making predictions**\n\nLet's pick 50 images from the validation set and move them to `inference\/images` to see how our model does on those:","8f619f5b":"## References\n\n- [Clothing Item Detection for E-Commerce dataset](https:\/\/www.kaggle.com\/dataturks\/clothing-item-detection-for-ecommerce)\n- [YOLOv5 GitHub](https:\/\/github.com\/ultralytics\/yolov5)\n- [YOLOv5 Train on Custom Data](https:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data)\n- [NVIDIA Apex on GitHub](https:\/\/github.com\/NVIDIA\/apex)\n- [YOLOv4: Optimal Speed and Accuracy of Object Detection](https:\/\/arxiv.org\/pdf\/2004.10934.pdf)","10d1c3c4":"1. 1. # **The file data_21_6147.yaml**\n\nthe containt file is:\n\n\n> train: ..\/dataset_21_6147\/images\/train\/\n> val: ..\/dataset_21_6147\/images\/val\/\n> \n> nc: 21\n> names: ['fusible5','fusible10mini','fusible15Medium','fusible15mini','fusible20','fusible20Medium','fusible20mini','fusible30Double','fusible30Medium','fusible40','fusible40Medium','fusible50','fusible60','fusible70','fusible80','Metale80A','relai','relaiGreen','relaiYellow','symbole','vide']\n\n\n## nc: is number of classes\n## names: containe all name of classes\n\n\n","298e475a":"# **download yolov5 with dataset**\n* The dataset contains 6147 samples of images and bounding box. containing 21 classes ","e5a93bff":"upgrade pip","003428d6":"## Summary\n\nYou now know how to create a custom dataset and fine-tune one of the YOLO v5 models on your own. Nice!\n\n- [Read the tutorial](https:\/\/www.curiousily.com\/posts\/object-detection-on-custom-dataset-with-yolo-v5-using-pytorch-and-python\/)\n- [Run the notebook in your browser (Google Colab)](https:\/\/colab.research.google.com\/drive\/1e4zvS6LyhOAayEDh3bz8MXFTJcVFSvZX?usp=sharing)\n- [Read the `Getting Things Done with Pytorch` book](https:\/\/github.com\/curiousily\/Getting-Things-Done-with-Pytorch)\n\nHere's what you've learned:\n\n- Install required libraries\n- Build a custom dataset in YOLO\/darknet format\n- Learn about YOLO model family history\n- Fine-tune the largest YOLO v5 model\n- Evaluate the model\n- Look at some predictions\n\nHow well does your model do on your dataset? Let me know in the comments below.\n\nIn the next part, you'll learn how to deploy your model a mobile device.","f513672f":"Let's import all required libraries:","1e37ab71":"# **If you want to import another Dataset from roboflow**","274892fc":"# **use the best model with --conf 0.01 and just epoch=20**","be473dab":"# **Evaluation**\n\nThe project includes a great utility function `plot_results()` that allows you to evaluate your model performance on the last training run:","14e43db9":"The training took around 1.5 h or more on Tesla P100. The best model checkpoint is saved to `weights\/best_yolov5x_clothing.pt`.","5d0811f3":"### **Install gdown**"}}