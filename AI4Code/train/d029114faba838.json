{"cell_type":{"c8424069":"code","55578bb5":"code","e5b8ac89":"code","cadaea29":"code","4fed1cd5":"code","c209cc91":"code","058c85f3":"code","d8c55c8e":"code","1608a5ad":"code","a6cb3764":"code","cf933dfb":"code","84e336e0":"code","09b3a84d":"code","190f7996":"code","24d87a18":"code","dbad403c":"code","2266a442":"code","9c743495":"code","84d332c1":"code","b57cdcf6":"code","c5618b40":"code","b70ad1a5":"code","de6a8b18":"code","a4e1a5ed":"code","67708df4":"code","095c3f45":"code","56923a8c":"code","27f342e3":"code","f397db14":"code","fbd067c1":"code","8080dabf":"code","c96a75cb":"code","5492c388":"code","500f0595":"code","78857c73":"code","539ea9f0":"code","d941e644":"code","0c8d59e0":"code","46a01534":"code","2e88ad62":"code","86cd92fe":"code","1e1c878f":"code","ab42670e":"code","89d8b504":"code","64087431":"code","10f8b7a9":"code","4b8b152c":"code","3a2d5387":"code","fd2f7fe7":"code","0c89ccf4":"code","a0a1983c":"code","a8a5e906":"code","f3e48f09":"code","16eb70d8":"code","a89dd140":"code","c7b1aea3":"code","15efdeb7":"code","67b23ffb":"code","fe20a906":"code","0080f09c":"code","990d48e0":"code","00314331":"code","2a1bb3c7":"code","7f373cec":"code","82255d31":"code","9262fd04":"code","3e4f429e":"code","a3540b04":"code","8efad39a":"code","dc112c09":"code","28da6ae5":"code","7a5a96a1":"code","a33afb20":"code","c126e51c":"code","49ccf3e1":"code","c6c1814e":"code","15e47ab2":"code","61cedcf8":"code","5fe9d5c7":"code","ad1e9314":"code","659676ba":"code","f3bfffd7":"code","cfab0fd2":"code","16c14036":"code","eec46e21":"code","33dea2d1":"code","cfddab2e":"code","47f773bb":"code","4ad2003f":"code","a794d368":"code","1ba7ac41":"code","f60f10b9":"code","8901287e":"code","5c1fe286":"markdown","5392f313":"markdown","83635480":"markdown","3554fbad":"markdown"},"source":{"c8424069":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom warnings import filterwarnings as filt\n\nfilt('ignore')\nplt.rcParams['figure.figsize'] = (12,6)\nplt.style.use('Solarize_Light2')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","55578bb5":"base_dir = '\/kaggle\/input\/predict-the-genetic-disorders-datasetof-genomes\/'\ntraindf = pd.read_csv(f'{base_dir}train_genetic_disorders.csv')\ntestdf = pd.read_csv(f'{base_dir}test_genetic_disorders.csv')\ntraindf.head()","e5b8ac89":"traindf.shape, testdf.shape","cadaea29":"traindf.info()","4fed1cd5":"traindf.select_dtypes(exclude = 'object').describe()","c209cc91":"traindf.select_dtypes(include = 'object').describe()","058c85f3":"traindf = traindf.dropna(subset= ['Genetic Disorder', 'Disorder Subclass'])\ntarget1 = traindf['Genetic Disorder']\ntarget2 = traindf['Disorder Subclass']\nprint(f\"target 1 ==> {target1.unique()}\")\nprint()\nprint(f\"target 2 ==> {target2.unique()}\")","d8c55c8e":"trainIdx, testIdx = traindf.index, testdf.index\ndf = pd.concat([traindf.drop(['Genetic Disorder', 'Disorder Subclass'], axis = 1), testdf])\ndf = df.drop(['Patient Id'], axis = 1)\ndf.head()","1608a5ad":"def null(df):\n    null_feats = pd.DataFrame(df.isnull().sum(), index = df.columns, columns = ['nans']).sort_values('nans', ascending = False)\n    null_feats['nans %'] = df.isnull().sum() \/ df.shape[0]\n    null_feats['data_type'] = [df[c].dtypes.name for c in null_feats.index]\n    return null_feats[null_feats.nans > 0]\n\nnull(df)","a6cb3764":"df.select_dtypes(include = 'object').columns","cf933dfb":"df[null(df).index].head()","84e336e0":"feats_to_drop = [c for c in null(df).index if 'name' in c.lower()] + ['Place of birth', 'Location of Institute']\nfeats_to_drop","09b3a84d":"df = df.drop(feats_to_drop, axis = 1)","190f7996":"nan = null(df)\nnum_null = nan[nan.data_type != 'object']\nobj_null = nan[nan.data_type == 'onject']\ndf[num_null.index].head()","24d87a18":"tests = ['Test 1','Test 2','Test 3','Test 4','Test 5']\nfor col in tests:\n    print()\n    print(col.center(60,'='))\n    print(df[col].unique())\n    ","dbad403c":"df[tests][df['Test 1'] == -99].head()","2266a442":"# lets just fill the tests Na values with -99\ndf[tests] = df[tests].fillna(0.0)","9c743495":"from scipy.stats import skew, norm \n\nax = sns.distplot(df['Patient Age'], color = 'red')\nax = sns.distplot(df['Blood cell count (mcL)'], color = 'blue')\nax = sns.distplot(df['White Blood cell count (thousand per microliter)'], color = 'black')\nplt.legend(['Patient age','blood cell count','white blood cell count'])","84d332c1":"sns.scatterplot(data = df, x = 'White Blood cell count (thousand per microliter)',y ='Blood cell count (mcL)')","b57cdcf6":"sns.scatterplot(data = df, x = 'Patient Age',y ='Blood cell count (mcL)')","c5618b40":"sns.scatterplot(data = df, y = 'White Blood cell count (thousand per microliter)',x ='Patient Age')","b70ad1a5":"df['White Blood cell count (thousand per microliter)'][df['White Blood cell count (thousand per microliter)'] == 0].unique()","de6a8b18":"df['White Blood cell count (thousand per microliter)'] = df['White Blood cell count (thousand per microliter)'].fillna(df['White Blood cell count (thousand per microliter)'].mean())\ndf['Patient Age'] = df['Patient Age'].fillna(np.floor(df['Patient Age'].mean()))\ndf['Blood cell count (mcL)'] = df['Blood cell count (mcL)'].fillna(df['Blood cell count (mcL)'].mean())","a4e1a5ed":"sns.scatterplot(data = df, y = \"Mother's age\", x = \"Father's age\")","67708df4":"sns.distplot(df[\"Mother's age\"], fit = norm)","095c3f45":"sns.distplot(df[\"Father's age\"], fit = norm)","56923a8c":"parent_age = [\"Mother's age\", \"Father's age\"]\ndf[parent_age] = df[parent_age].fillna(np.floor(df[parent_age].mean()))","27f342e3":"np.floor(df[parent_age].mean())","f397db14":"sns.distplot(df['No. of previous abortion'])","fbd067c1":"df['No. of previous abortion'].unique()","8080dabf":"df[df['No. of previous abortion'] == -99.0]","c96a75cb":"sns.scatterplot(data = df, y = \"Mother's age\", x = 'No. of previous abortion')","5492c388":"plt.xticks(rotation = 90)\nsns.countplot(df[\"Father's age\"][df[\"Mother's age\"] == 18])\nplt.title(\"Father's age for 18 year old mother\");","500f0595":"import plotly.express as px\n\n# px.scatter_3d(data_frame = df,x = \"Father's age\", y = \"Mother's age\", z = 'No. of previous abortion')","78857c73":"df['No. of previous abortion'] = df['No. of previous abortion'].fillna(np.floor(df['No. of previous abortion'].mean()))","539ea9f0":"nans = null(df)\nobj_null = nans[nans.data_type == 'object']\nobj_null","d941e644":"simps = [f'Symptom {i}' for i in range(1,6)]\ndf[simps].head()","0c8d59e0":"df[simps] = df[simps].fillna(0.0)","46a01534":"df[null(df).index].head()","2e88ad62":"def plot(df, rc, kind = 'dist'):\n    fig, ax = plt.subplots(rc[0], rc[1], figsize = (13, 8))\n    fig.tight_layout()\n    cols = df.columns\n    ind = 0\n    for r in range(rc[0]):\n        for c in range(rc[1]):\n            if ind >= len(cols): break\n            x = df[cols[ind]]\n            if kind == 'dist':\n                sns.distplot(x, ax = ax[r,c])\n            elif kind == 'bar':\n                sns.countplot(x, ax = ax[r,c])\n            ind += 1","86cd92fe":"plot(df[null(df).index[:10]], [2,5], 'bar')","1e1c878f":"# since there are lot of parental consent we'll just assume that tests conducted due to parents consent , there's no way a kid will check up on his own\n\ndf = df.drop(['Parental consent'], axis = 1)","ab42670e":"null(df)","89d8b504":"for i in null(df).index:\n    print(i.center(60,'='))\n    print(df[i].unique())\n    print()","64087431":"nos = [c for c in null(df).index if 'No' in df[c].unique()]\nplot(df[nos], [4,3], 'bar')","10f8b7a9":"df[nos] = df[nos].fillna('No')","4b8b152c":"plot(df[null(df).index], [2,4], 'bar')","3a2d5387":"for i in null(df).index:\n    df[i] = df[i].fillna(df[i].mode()[0])","fd2f7fe7":"null(df)","0c89ccf4":"df.head()","a0a1983c":"categorical_feats = [c for c in df.columns if df[c].dtypes == 'object']\nnumerical_feats = [c for c in df.columns if df[c].dtypes != 'object']\nnum99 = [c for c in numerical_feats if -99.0 in df[c].unique()]\nobj99 = [c for c in categorical_feats if \"-99\" in df[c].unique()]","a8a5e906":"df[num99].head()","f3e48f09":"df[['Test 1','Test 2','Test 3','Test 4','Test 5','No. of previous abortion']] = df[['Test 1','Test 2','Test 3','Test 4','Test 5','No. of previous abortion']].replace({-99.0 : 0})\ndf['White Blood cell count (thousand per microliter)'] = df['White Blood cell count (thousand per microliter)'].replace({-99.0 : df['White Blood cell count (thousand per microliter)'].median()})","16eb70d8":"[c for c in numerical_feats if -99.0 in df[c].unique()]","a89dd140":"df[obj99].head()","c7b1aea3":"plot(df[obj99], [3,5], 'bar')","15efdeb7":"# Normal (30-60)\n# Respiratory Rate (breaths\/min)\tHeart Rate (rates\/min\tFollow-up\tGender\n\ndf[['Respiratory Rate (breaths\/min)','Heart Rate (rates\/min','Follow-up','Gender']]","67b23ffb":"for feat in ['Respiratory Rate (breaths\/min)','Heart Rate (rates\/min','Follow-up','Gender']:\n    df[feat] = df[feat].replace({'-99' : df[feat].mode()[0]})\n    \ndf['Respiratory Rate (breaths\/min)'] = df['Respiratory Rate (breaths\/min)'].replace({'Normal (30-60)' : 'Normal'})","fe20a906":"df['Birth asphyxia'] = df['Birth asphyxia'].replace({\n    'No record': 'Not available', \n    '-99' : 'Not available'})","0080f09c":"appli = [c for c in obj99[5:] if 'Not applicable' in df[c].unique()]\ndf[appli] = df[appli].replace({\n    '-99' : 'Not applicable',\n    'None' : 'No',\n    '-' : 'No'\n})\nfor i in appli:\n    print(df[i].unique())","990d48e0":"obj99 = [c for c in categorical_feats if '-99' in df[c].unique()]\nfor obj in obj99:\n    print(f\"{obj} ===> {df[obj].unique()}\")","00314331":"df[obj99[:-2]] = df[obj99[:-2]].replace({'-99' : 'No'})\nfor obj in obj99[-2:]:\n    df[obj] = df[obj].replace({'-99': df[obj].mode()[0]})","2a1bb3c7":"print([c for c in categorical_feats if '-99' in df[c].unique()])\nprint([c for c in numerical_feats if -99.0 in df[c].unique()])","7f373cec":"df.head()","82255d31":"categorical_feats = df.select_dtypes(include = 'object').columns","9262fd04":"for s in simps: \n    df[s] = pd.to_numeric(df[s])\n    \ncategorical_feats = df.select_dtypes(include = 'object').columns","3e4f429e":"df[categorical_feats].head()","a3540b04":"from sklearn.preprocessing import OrdinalEncoder as oe, LabelEncoder as le","8efad39a":"encoder = oe()\ndf[categorical_feats] = encoder.fit_transform(df[categorical_feats])\ndf[categorical_feats].head()","dc112c09":"x = df.reset_index(drop = True).iloc[: traindf.shape[0]]\ntest_x = df.reset_index(drop = True).iloc[traindf.shape[0] :]\ntarget_encoder = le()\ny_train = pd.DataFrame(target_encoder.fit_transform(target2), columns = [target2.name])\nx.shape, traindf.shape, test_x.shape, testdf.shape","28da6ae5":"x.head()","7a5a96a1":"test_x.head()","a33afb20":"fig, ax = plt.subplots(1,2)\nfig.tight_layout()\n# ax[0].xticks(rotation = 90)\nax[0].set_xticklabels(rotation = 90, labels = target2.unique())\nsns.countplot(target2.sort_values(ascending = True), ax = ax[0])\nsns.countplot(y_train[target2.name], ax = ax[1])","c126e51c":"from sklearn.ensemble import RandomForestClassifier as rfc\nfrom sklearn.svm import SVC\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom pdpbox import pdp\nimport shap\nfrom sklearn.feature_selection import mutual_info_classif\n\ndef permImp(val_x, val_y):\n    model = rfc(n_estimators=100).fit(val_x, val_y)\n    perm = PermutationImportance(model).fit(val_x, val_y)\n    return eli5.show_weights(perm, feature_names = val_x.columns.tolist())\n\ndef interact(cols, val_x, val_y):\n    model = rfc(n_estimators=100).fit(val_x, val_y)\n    pdp_dist = pdp.pdp_interact(model, dataset = val_x, model_features = val_x.columns, features = cols)\n    return pdp.pdp_interact_plot(pdp_dist, feature_names=cols)\n\ndef isolate(col, val_x, val_y):\n    model = rfc(n_estimators=100).fit(val_x, val_y)\n    pdp_dist = pdp.pdp_isolate(model, dataset = val_x, model_features = val_x.columns, feature = col)\n    return pdp.pdp_plot(pdp_dist, feature_name=col)\n\ndef forceplot(train_x, train_y, val_x):\n    model = rfc(n_estimators=100).fit(val_x, val_y)\n#     model = SVC().fit(val_x, val_y)\n    feats = val_x.sample(n = 1)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(feats)\n    return shap.force_plot(explainer.expected_value[1],shap_values[1], feature_names = feats.columns, features = feats)\n\ndef train_val(x, y, test_size = 0.2):\n    idx = x.sample(frac = test_size).index\n    train_x, val_x = x.drop(idx), x.iloc[idx]\n    train_y, val_y = y.drop(idx), y.iloc[idx]\n    return train_x, val_x, train_y, val_y\n\ndef plot_mi(score):\n    score = score.sort_values('mi_score', ascending = True)\n    plt.barh(score.index, score.mi_score)\n    return \n\ndef mi_score(x, y):\n    score = pd.DataFrame(mutual_info_classif(x, y, discrete_features=False), index = x.columns, columns = ['mi_score'])\n    plot_mi(score)\n    return score.sort_values('mi_score', ascending = False)","49ccf3e1":"train_x, val_x, train_y, val_y = train_val(x, y_train)\ntrain_x.shape, val_x.shape, train_y.shape, val_y.shape","c6c1814e":"sns.heatmap(train_x.corr(), cmap = 'icefire')","15e47ab2":"permImp(val_x, val_y)","61cedcf8":"mscore = mi_score(val_x, val_y)","5fe9d5c7":"isolate('Symptom 5', val_x, val_y);","ad1e9314":"shap.initjs()\nforceplot(train_x, train_y, val_x)","659676ba":"from sklearn.naive_bayes import GaussianNB as gnb\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nfrom xgboost import XGBRFClassifier as xgb \n\nfrom sklearn.model_selection import cross_val_score as cvs, GridSearchCV as gscv, StratifiedKFold as skf\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.preprocessing import StandardScaler as ss, RobustScaler as rs, MinMaxScaler as mms \n\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import skew, norm","f3bfffd7":"def best_model(train_x, train_y):\n    models = [SVC(), rfc(), knn(), gnb(), xgb()]\n    names = ['svm','random forest clf', 'knn', 'naive bayes', 'xgboost']\n    scores = []\n    for model in models:\n        cv = skf(n_splits = 5, shuffle = True, random_state = 1)\n        score = cvs(model, train_x, train_y, cv = cv, verbose = 1)\n        scores.append(score)\n    return pd.DataFrame(score, index = names, columns = ['accuracy']).sort_values('accuracy', ascending = False)\n\ndef gcv(train_x, train_y, model, params):\n    cv = skf(n_splits = 5, shuffle = True, random_state = 1)\n    clf = gscv(model, param_grid= params, verbose = 2, return_train_score=True, n_jobs = -1)\n    clf.fit(train_x, train_y)\n    results = pd.DataFrame(clf.cv_results_)\n    results = results[['mean_test_score','mean_train_score','params']]\n    return clf.best_estimator_, clf.best_params_, results\n\ndef get_score(yt, pred):\n    print(classification_report(yt, pred))","cfab0fd2":"# best_model(train_x, train_y)","16c14036":"train_x = train_x.drop(tests, axis = 1)\nval_x = val_x.drop(tests, axis = 1)\n# clf, best_params, results = gcv(ss().fit_transform(train_x), train_y, SVC(), {\n#     'C' : [1,10,40,50],\n#     'kernel' : ['rbf','poly','sigmoid'],\n#     'decision_function_shape' : ['ovo','ovr']\n# })\n# results.head()","eec46e21":"clf = xgb(max_depth = 15, learning_rate = 1.5, reg_lambda = 2, reg_alpha = 0.5, decision_function_shape = 'ovo')\nclf.fit(train_x, train_y)\npred = clf.predict(val_x)\nsns.heatmap(confusion_matrix(val_y, pred), fmt = '.1f', annot = True)\nget_score(val_y, pred)","33dea2d1":"clf.score(train_x, train_y), clf.score(val_x, val_y)","cfddab2e":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression as lrr","47f773bb":"n = int(np.sqrt(train_x.shape[0]))\nn += 1 if n % 2 == 0 else 0  \nn","4ad2003f":"\nestimators = [\n    ('svm' , SVC(C = 10)), \n    ('rfc' , rfc(n_estimators=100)), \n    ('knn' , knn(n_neighbors=n)), \n    ('gnb' , gnb()), \n    ('xgb' , xgb(n_estimators = 100))\n    ]\n\nclfs = StackingClassifier(estimators=estimators, final_estimator=lrr(solver='liblinear'), verbose= 1, n_jobs = -1 )\nclfs.fit(train_x, train_y)\npred = clfs.predict(val_x)\nclfs.score(train_x, train_y), clfs.score(val_x, val_y)","a794d368":"sns.heatmap(confusion_matrix(val_y, pred), fmt = '.1f', annot = True)\nget_score(val_y, pred)","1ba7ac41":"testing = val_x.sample(n = 1)\ntesting ","f60f10b9":"# val_y, \nval_y.loc[testing.index,], target_encoder.inverse_transform(val_y.loc[testing.index])[0]","8901287e":"clf.predict(testing)[0], clfs.predict(testing)[0]","5c1fe286":"### Handling null values","5392f313":"* hmm looks like there are lot of outliers for the white blood cells \n* A negative result means no white blood cells (leukocytes) were found in the sample. If you or your child's results were negative, the symptoms are probably not caused by an infection.","83635480":"### Data cleaning ","3554fbad":"wait what ?? just at the age of 18 there were 4 previos abortion ? 0.0"}}