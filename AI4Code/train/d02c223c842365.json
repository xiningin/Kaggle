{"cell_type":{"30e1cddd":"code","2ea9b45a":"code","661d5c05":"code","7fee49cb":"code","2784331e":"code","b45355e5":"code","9f89599a":"code","f13506a6":"code","6cd64f47":"code","48c99aff":"code","2c4fb577":"code","82ee9641":"code","c1e799fe":"code","7a9f4e55":"code","a58e8eb2":"code","4e86ed15":"code","df8dfc99":"code","b633557e":"code","5fc19e1d":"code","ecbe7524":"code","415e9ca5":"code","1b9093b0":"code","4741d3d4":"code","8cb850be":"code","2e501ac2":"code","47e2262b":"code","6800afff":"code","4c555cf5":"code","8a9703d6":"code","9833f1bb":"code","0708b1f5":"code","2e32da5b":"code","4e58933a":"code","92a69f9a":"markdown","43d857dc":"markdown","95b92525":"markdown","cf25d317":"markdown","9a0e2f38":"markdown","997a488e":"markdown","41ea4132":"markdown","0d959fb0":"markdown","2cab30a7":"markdown"},"source":{"30e1cddd":"!pip install ktrain # for BERT model","2ea9b45a":"import pandas as pd\nimport numpy as np\nimport spacy\nimport ktrain\nimport re\nimport string\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport unicodedata\nfrom wordcloud import WordCloud\nfrom textblob import TextBlob","661d5c05":"from spacy.lang.en.stop_words import STOP_WORDS as stopwords","7fee49cb":"train_df=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntrain_df.sample(5)","2784331e":"test_df=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\ntest_df.sample(5)","b45355e5":"g=sns.countplot(x='target',data=train_df)","9f89599a":"train_df.head(2)","f13506a6":"train_df['text'] = train_df['text'].apply(lambda x: str(x).lower())\ntest_df['text'] = test_df['text'].apply(lambda x: str(x).lower())\ntrain_df.head(2)","6cd64f47":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how does\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\" u \": \" you \",\n\" ur \": \" your \",\n\" n \": \" and \",\n\"won't\": \"would not\",\n'dis': 'this',\n'bak': 'back',\n'brng': 'bring'}","48c99aff":"def cont_to_exp(x):\n    if type(x) is str:\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key, value)\n        return x\n    else:\n        return x","2c4fb577":"train_df['text'] = train_df['text'].apply(lambda x: cont_to_exp(x))\ntest_df['text'] = test_df['text'].apply(lambda x: cont_to_exp(x))","82ee9641":"def wordcount(x):\n    length = len(str(x).split())\n    return length","c1e799fe":"def charcount(x):\n    s = x.split()\n    x = ''.join(s)\n    return len(x)\n\ndef hashtag_count(x):\n    l = len([t for t in x.split() if t.startswith('#')])\n    return l\n\ndef mentions_count(x):\n    l = len([t for t in x.split() if t.startswith('@')])\n    return l","7a9f4e55":"train_df['char_count'] = train_df['text'].apply(lambda x: charcount(x))\ntrain_df['word_count'] = train_df['text'].apply(lambda x: wordcount(x))\ntrain_df['hashtag_count'] = train_df['text'].apply(lambda x: hashtag_count(x))\ntrain_df['mention_count'] = train_df['text'].apply(lambda x: mentions_count(x))\ntrain_df.head(2)","a58e8eb2":"plt.figure(figsize=(20,4))\nplt.subplot(1,3,1)\nsns.barplot(y='char_count',x='target',data=train_df)\nplt.subplot(1,3,2)\nsns.barplot(y='word_count',x='target',data=train_df)\nplt.subplot(1,3,3)\ng=sns.barplot(y='hashtag_count',x='target',data=train_df)","4e86ed15":"test_df['char_count'] = test_df['text'].apply(lambda x: charcount(x))\ntest_df['word_count'] = test_df['text'].apply(lambda x: wordcount(x))\ntest_df['hashtag_count'] = test_df['text'].apply(lambda x: hashtag_count(x))\ntest_df['mention_count'] = test_df['text'].apply(lambda x: mentions_count(x))\ntest_df.head(2)","df8dfc99":"def remove_emails(x):\n     return re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", x)\n\n\ndef remove_urls(x):\n    return re.sub(r'(http|https|ftp|ssh):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?', '' , x)\n\ndef remove_rt(x):\n    return re.sub(r'\\brt\\b', '', x).strip()\n\ndef remove_special_chars(x):\n    x = re.sub(r'[^\\w ]+', \"\", x)\n    x = ' '.join(x.split())\n    return x\n\n\ndef remove_accented_chars(x):\n    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return x\n\ndef remove_stopwords(x):\n    return ' '.join([t for t in x.split() if t not in stopwords])\t\n\n","b633557e":"train_df['text'] = train_df['text'].apply(lambda x: remove_emails(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_urls(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_rt(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_special_chars(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_accented_chars(x))\ntrain_df['text'] = train_df['text'].apply(lambda x: remove_stopwords(x))","5fc19e1d":"test_df['text'] = test_df['text'].apply(lambda x: remove_emails(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_urls(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_rt(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_special_chars(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_accented_chars(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_stopwords(x))","ecbe7524":"text = ' '.join(train_df[train_df.target==1]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.title('Disaster tweets')\nplt.show()","415e9ca5":"text = ' '.join(train_df[train_df.target==0]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.title('Not Disaster tweets')\nplt.axis('off')\nplt.show()","1b9093b0":"def get_value_counts(df, col):\n    text = ' '.join(df[col])\n    text = text.split()\n    freq = pd.Series(text).value_counts()\n    return freq\n\ndef remove_common_words(x, freq, n=20):\n    fn = freq[:n]\n    x = ' '.join([t for t in x.split() if t not in fn])\n    return x","4741d3d4":"freq=get_value_counts(train_df,'text')","8cb850be":"train_df['text'] = train_df['text'].apply(lambda x: remove_common_words(x,freq,100))","2e501ac2":"text = ' '.join(train_df[train_df.target==1]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.title('Disaster tweets')\nplt.show()","47e2262b":"text = ' '.join(train_df[train_df.target==0]['text'])\nword_cloud = WordCloud(max_font_size=100).generate(text)\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.title('Not Disaster tweets')\nplt.show()","6800afff":"from ktrain import text","4c555cf5":"(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df=train_df, text_column='text', label_columns='target', maxlen=50, preprocess_mode='bert')","8a9703d6":"model = text.text_classifier(name='bert', train_data=(X_train, y_train), preproc=preproc)","9833f1bb":"learner = ktrain.get_learner(model=model, train_data=(X_train, y_train), val_data=(X_test, y_test), batch_size=32)\nlearner.fit_onecycle(lr = 2e-4, epochs=3)","0708b1f5":"predictor = ktrain.get_predictor(learner.model, preproc)","2e32da5b":"classes=predictor.get_classes()","4e58933a":"output = pd.DataFrame(columns=['id','target'])\nfor index, row in test_df.iterrows(): \n    y_pred,p= predictor.predict(row['text'],return_proba=True)\n    pred=classes.index(y_pred)\n    output1 = pd.DataFrame({'id': row['id'], 'target': pred},index=[0])\n    output=output.append(output1)\n    \noutput = output.astype({'target': 'int32'})\noutput.to_csv('submission_bert.csv', index=False)","92a69f9a":"> Convert to lowercase","43d857dc":"> Remove hashtags, mentions and emails","95b92525":"> Wordcloud Visualization ","cf25d317":"> Count number of words, characters, hashtags, mentions and emails","9a0e2f38":"# BERT","997a488e":"> Expansion ","41ea4132":"> After removing frequent words","0d959fb0":"> Contraction to Extraction","2cab30a7":"> Import Libraries"}}