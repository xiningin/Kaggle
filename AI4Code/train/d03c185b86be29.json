{"cell_type":{"161ecc0a":"code","01d9af9f":"code","de69c205":"code","f29f1535":"code","35f5bd60":"code","8398c8d7":"code","e14d0a57":"code","27445772":"code","901614e4":"code","86b64cbe":"code","ab65d8f6":"code","17a3ab01":"code","d0ddd7ab":"code","63c6dc0f":"code","99a7bd90":"code","ef1412e6":"code","624b544c":"code","654de881":"code","f17dcf47":"code","d8687153":"code","7dc6d565":"code","3ef54e10":"code","7583e700":"code","96277974":"code","3adad63b":"code","718c3d47":"markdown","e0926822":"markdown","2a3b87cb":"markdown","f0114272":"markdown","12931131":"markdown","dbcdf6e6":"markdown","c435a2dd":"markdown","aae70208":"markdown","6eb2c2a7":"markdown"},"source":{"161ecc0a":"!nvidia-smi","01d9af9f":"try:\n    import resnest\nexcept ModuleNotFoundError:\n    !pip install -q \"..\/input\/resnest50-fast-package\/resnest-0.0.6b20200701\/resnest\"","de69c205":"import numpy as np\nimport librosa as lb\nimport soundfile as sf\nimport pandas as pd\nimport cv2\nfrom pathlib import Path\nimport re\n\nimport torch\nfrom torch import nn\nfrom  torch.utils.data import Dataset, DataLoader\n\nfrom tqdm.notebook import tqdm\n\nimport time\nfrom resnest.torch import resnest50","f29f1535":"NUM_CLASSES = 397\nSR = 32_000\nDURATION = 5\nTHRESH = 0.1\n\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"DEVICE:\", DEVICE)\n\nTEST_AUDIO_ROOT = Path(\"..\/input\/birdclef-2021\/test_soundscapes\")\nSAMPLE_SUB_PATH = \"..\/input\/birdclef-2021\/sample_submission.csv\"\nTARGET_PATH = None\n    \nif not len(list(TEST_AUDIO_ROOT.glob(\"*.ogg\"))):\n    TEST_AUDIO_ROOT = Path(\"..\/input\/birdclef-2021\/train_soundscapes\")\n    SAMPLE_SUB_PATH = None\n    # SAMPLE_SUB_PATH = \"..\/input\/birdclef-2021\/sample_submission.csv\"\n    TARGET_PATH = Path(\"..\/input\/birdclef-2021\/train_soundscape_labels.csv\")","35f5bd60":"class MelSpecComputer:\n    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax\n        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr\/\/10)\n        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr\/\/(10*4))\n        self.kwargs = kwargs\n\n    def __call__(self, y):\n        melspec = lb.feature.melspectrogram(\n            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n        )\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec","8398c8d7":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) \/ (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) \/ (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\ndef crop_or_pad(y, length):\n    if len(y) < length:\n        y = np.concatenate([y, length - np.zeros(len(y))])\n    elif len(y) > length:\n        y = y[:length]\n    return y","e14d0a57":"class BirdCLEFDataset(Dataset):\n    def __init__(self, data, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n        \n        self.data = data\n        \n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr\/\/2\n\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        \n        self.res_type = res_type\n        self.resample = resample\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin,\n                                                 fmax=self.fmax)\n    def __len__(self):\n        return len(self.data)\n    \n    @staticmethod\n    def normalize(image):\n        image = image.astype(\"float32\", copy=False) \/ 255.0\n        image = np.stack([image, image, image])\n        return image\n    \n    def audio_to_image(self, audio):\n        melspec = self.mel_spec_computer(audio)\n        \n        image = mono_to_color(melspec)\n        image = self.normalize(image)\n        return image\n\n    def read_file(self, filepath):\n        audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n\n        if self.resample and orig_sr != self.sr:\n            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n          \n        audios = []\n        for i in range(self.audio_length, len(audio) + self.step, self.step):\n            start = max(0, i - self.audio_length)\n            end = start + self.audio_length\n            audios.append(audio[start:end])\n            \n        if len(audios[-1]) < self.audio_length:\n            audios = audios[:-1]\n            \n        images = [self.audio_to_image(audio) for audio in audios]\n        images = np.stack(images)\n        \n        return images\n    \n        \n    def __getitem__(self, idx):\n        return self.read_file(self.data.loc[idx, \"filepath\"])","27445772":"data = pd.DataFrame(\n     [(path.stem, *path.stem.split(\"_\"), path) for path in Path(TEST_AUDIO_ROOT).glob(\"*.ogg\")],\n    columns = [\"filename\", \"id\", \"site\", \"date\", \"filepath\"]\n)\nprint(data.shape)\ndata.head()","901614e4":"df_train = pd.read_csv(\"..\/input\/birdclef-2021\/train_metadata.csv\")\n\nLABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df_train[\"primary_label\"].unique()))}\nINV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}","86b64cbe":"test_data = BirdCLEFDataset(data=data)\nprint(len(test_data))\n\nprint(test_data[0].shape)","ab65d8f6":"import sys \nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master') \nimport timm \nimport torch\nimport torch.nn as nn\n\nclass densenet(nn.Module):\n    def __init__(self, n_class=397, model_name='densenet121', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained,num_classes=0)\n        self.dropout = torch.nn.Dropout(p=0.2)\n        self.classifier = nn.Linear(1024, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        \n        return x\n\nclass nfnet(nn.Module):\n    def __init__(self, n_class=397, model_name='eca_nfnet_l0', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained,num_classes=0)\n        self.dropout = torch.nn.Dropout(p=0.4)\n        self.classifier = nn.Linear(2304, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        \n        return x","17a3ab01":"def load_densenet(checkpoint_path, num_classes=NUM_CLASSES):\n    net = densenet(pretrained=False)\n    dummy_device = torch.device(\"cpu\")\n    d = torch.load(checkpoint_path, map_location=dummy_device)\n#     for key in list(d.keys()):\n#         d[key.replace(\"model.\", \"\")] = d.pop(key)\n    net.load_state_dict(d)\n    net = net.to(DEVICE)\n    net = net.eval()\n    return net\n\ndef load_resnest50dnet(checkpoint_path, num_classes=NUM_CLASSES):\n    net = timm.create_model('resnest50d',pretrained=False)\n    net.fc = nn.Linear(net.fc.in_features, num_classes)\n    dummy_device = torch.device(\"cpu\")\n    d = torch.load(checkpoint_path, map_location=dummy_device)\n    for key in list(d.keys()):\n        d[key.replace(\"model.\", \"\")] = d.pop(key)\n    net.load_state_dict(d)\n    net = net.to(DEVICE)\n    net = net.eval()\n    return net\n\ndef load_resnestnet(checkpoint_path, num_classes=NUM_CLASSES):\n    net = resnest50(pretrained=False)\n    net.fc = nn.Linear(net.fc.in_features, num_classes)\n    dummy_device = torch.device(\"cpu\")\n    d = torch.load(checkpoint_path, map_location=dummy_device)\n    for key in list(d.keys()):\n        d[key.replace(\"model.\", \"\")] = d.pop(key)\n    net.load_state_dict(d)\n    net = net.to(DEVICE)\n    net = net.eval()\n    return net\n\ndef load_nfnet(checkpoint_path, num_classes=NUM_CLASSES):\n    net = nfnet(pretrained=False)\n    dummy_device = torch.device(\"cpu\")\n    d = torch.load(checkpoint_path, map_location=dummy_device)\n#     for key in list(d.keys()):\n#         d[key.replace(\"model.\", \"\")] = d.pop(key)\n    net.load_state_dict(d)\n    net = net.to(DEVICE)\n    net = net.eval()\n    return net\n","d0ddd7ab":"\ncheckpoint_paths = [\n    Path(\"..\/input\/kkiller-birdclef-models-public\/birdclef_resnest50_fold0_epoch_10_f1_val_06471_20210417161101.pth\"),\n]\n\n\nnets = [\n    load_resnestnet(checkpoint_paths[0]),\n    \n]","63c6dc0f":"@torch.no_grad()\ndef get_thresh_preds(out, thresh=None):\n    thresh = thresh or THRESH\n    o = (-out).argsort(1)\n    npreds = (out > thresh).sum(1)\n    preds = []\n    for oo, npred in zip(o, npreds):\n        preds.append(oo[:npred].cpu().numpy().tolist())\n    return preds","99a7bd90":"def get_bird_names(preds):\n    bird_names = []\n    for pred in preds:\n        if not pred:\n            bird_names.append(\"nocall\")\n        else:\n            bird_names.append(\" \".join([INV_LABEL_IDS[bird_id] for bird_id in pred]))\n    return bird_names","ef1412e6":"def predict(nets, test_data, names=True):\n    preds = []\n    with torch.no_grad():\n        for idx in  tqdm(list(range(len(test_data)))):\n            xb = torch.from_numpy(test_data[idx]).to(DEVICE)\n            pred = 0.\n            for net in nets:\n                o = net(xb)\n                o = torch.sigmoid(o)\n\n                pred += o\n\n            pred \/= len(nets)\n            \n            if names:\n                pred = get_bird_names(get_thresh_preds(pred))\n\n            preds.append(pred)\n    return preds","624b544c":"pred_probas = predict(nets, test_data, names=False)\nprint(len(pred_probas))","654de881":"preds = [get_bird_names(get_thresh_preds(pred, thresh=THRESH)) for pred in pred_probas]\n#preds[:2]","f17dcf47":"def preds_as_df(data, preds):\n    sub = {\n        \"row_id\": [],\n        \"birds\": [],\n    }\n    \n    for row, pred in zip(data.itertuples(False), preds):\n        row_id = [f\"{row.id}_{row.site}_{5*i}\" for i in range(1, len(pred)+1)]\n        sub[\"birds\"] += pred\n        sub[\"row_id\"] += row_id\n        \n    sub = pd.DataFrame(sub)\n    \n    if SAMPLE_SUB_PATH:\n        sample_sub = pd.read_csv(SAMPLE_SUB_PATH, usecols=[\"row_id\"])\n        sub = sample_sub.merge(sub, on=\"row_id\", how=\"left\")\n        sub[\"birds\"] = sub[\"birds\"].fillna(\"nocall\")\n    return sub","d8687153":"#print(data)\n#print(preds)\nsub = preds_as_df(data, preds)\nprint(sub.shape)\n#sub","7dc6d565":"sub.to_csv(\"submission.csv\", index=False)","3ef54e10":"def get_metrics(s_true, s_pred):\n    s_true = set(s_true.split())\n    s_pred = set(s_pred.split())\n    n, n_true, n_pred = len(s_true.intersection(s_pred)), len(s_true), len(s_pred)\n    \n    prec = n\/n_pred\n    rec = n\/n_true\n    f1 = 2*prec*rec\/(prec + rec) if prec + rec else 0\n    \n    return {\"f1\": f1, \"prec\": prec, \"rec\": rec, \"n_true\": n_true, \"n_pred\": n_pred, \"n\": n}","7583e700":"if TARGET_PATH:\n    sub_target = pd.read_csv(TARGET_PATH)\n    #print(sub_target)\n    #print(sub)\n    sub_target = sub_target.merge(sub, how=\"left\", on=\"row_id\")\n    #print(sub_target)\n    \n    #print(sub_target[\"birds_x\"].notnull().sum(), sub_target[\"birds_x\"].notnull().sum())\n    assert sub_target[\"birds_x\"].notnull().all()\n    assert sub_target[\"birds_y\"].notnull().all()\n    \n    df_metrics = pd.DataFrame([get_metrics(s_true, s_pred) for s_true, s_pred in zip(sub_target.birds_x, sub_target.birds_y)])\n    \n    print(df_metrics.mean())","96277974":"sub_target[sub_target.birds_y != \"nocall\"]","3adad63b":"sub_target[sub_target.birds_x != \"nocall\"]","718c3d47":"# Notes","e0926822":"# Data","2a3b87cb":"* The inference is based on these [resnest50 weights](https:\/\/www.kaggle.com\/kneroma\/kkiller-birdclef-models-public). Please, don't forget upvoting the dataset to make it more visible for others\n* The inference pipeline is optimized as much as I can in order to reduce execution time","f0114272":"**If the only thing you wan't to change is `hyperparams`, please consider commenting instead of spamming with stupid forks !**","12931131":"# Configs","dbcdf6e6":"# Small validation","c435a2dd":"In this kenel, I'm going to use a classical **ResneSt50** for bird identification.","aae70208":"<h2><font color=\"blue\">If you find this work useful, please don't forget upvoting :)<\/font><\/h2>","6eb2c2a7":"# Inference"}}