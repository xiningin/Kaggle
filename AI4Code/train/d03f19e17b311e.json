{"cell_type":{"5ad3371c":"code","86c5ccbc":"code","bdffa991":"code","265a043c":"code","1894273a":"code","0e555896":"code","bac1153d":"code","3cee80f2":"code","b6e8e307":"code","e93f94c7":"code","dd7e61e5":"code","b598202c":"code","d88780e1":"code","c181d3c7":"code","ce7b9d42":"code","bb3d377a":"code","2b90dc0c":"code","d881ef53":"code","6cab97b7":"code","18029c95":"code","96343821":"code","1bab909e":"code","7cd65668":"code","bcfb6acc":"code","3e986a2c":"code","52e58a68":"markdown","fbf8ea8f":"markdown","9505781d":"markdown","56099ddc":"markdown","824cf5a1":"markdown","9d929f98":"markdown","acf2727b":"markdown","2f9e257e":"markdown","9f9a6d62":"markdown","80c32179":"markdown","7a423850":"markdown","4d847317":"markdown","8232dd0a":"markdown","5774005b":"markdown","9b072eb9":"markdown","515db3eb":"markdown","86ac715c":"markdown","a45f5b43":"markdown","e59f3db8":"markdown","35e6f8fb":"markdown","fede7214":"markdown","a241b491":"markdown","db54d4b2":"markdown","13c82834":"markdown","75710df9":"markdown","6cb089cb":"markdown","a2bd5fc4":"markdown","af787694":"markdown","e9c28a7d":"markdown"},"source":{"5ad3371c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86c5ccbc":"import string \nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom  nltk.stem import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nfrom textblob import TextBlob\n%matplotlib inline","bdffa991":"data=pd.read_csv(\"\/kaggle\/input\/all-trumps-twitter-insults-20152021\/trump_insult_tweets_2014_to_2021.csv\")","265a043c":"data.head()","1894273a":"data.isnull().sum()","0e555896":"data.info()","bac1153d":"data.shape","3cee80f2":"data['target'].value_counts()","b6e8e307":"fig,ax1=plt.subplots(figsize=(8,8))\ng=sns.barplot(x=data['target'].value_counts()[:10],y=data['target'].value_counts()[:10].index)\ng.set_ylabel('Tweet Targets')\ng.set_xlabel('Number of Tweets')\ng.set_title('Most Targetted areas')","e93f94c7":"year=[]\nfor x in data['date']:\n    a=x.split('-')\n    year.append(a[0])\ndata['year']=year\nfig, axs = plt.subplots(7,1, figsize=(18, 30), facecolor='w', edgecolor='k')\nfig.subplots_adjust(hspace = .5, wspace=.001)\naxs = axs.ravel()\nfor i in range(0,7):\n    x=data[data['year']==str(2015+i)]['target'].value_counts()[:10]\n    y=data[data['year']==str(2015+i)]['target'].value_counts()[:10].index\n    axs[i].bar(y,x)\n    axs[i].set_xlabel('Tweet Targets')\n    axs[i].set_ylabel('Number of Tweets')\n    axs[i].set_title(f'Most Tweets in year {2015+i}')\nplt.tight_layout()","dd7e61e5":"fig,ax1=plt.subplots(figsize=(8,8))\ndata['insult']=data['insult'].str.lower()\ng=sns.barplot(x=data['insult'].value_counts()[:10],y=data['insult'].value_counts()[:10].index)\ng.set_ylabel('Tweet Insults')\ng.set_xlabel('Number of Tweets')\ng.set_title('Most Insults done')","b598202c":"fig, axs = plt.subplots(7,1, figsize=(18, 30), facecolor='w', edgecolor='k')\nfig.subplots_adjust(hspace = .5, wspace=.001)\naxs = axs.ravel()\nfor i in range(0,7):\n    x=data[data['year']==str(2015+i)]['insult'].value_counts()[:10]\n    y=data[data['year']==str(2015+i)]['insult'].value_counts()[:10].index\n    axs[i].bar(y,x)\n    axs[i].set_xlabel('Tweet Insults')\n    axs[i].set_ylabel('Number of Tweets')\n    plt.xticks(rotation=90)\n    axs[i].set_title(f'Most Insults in year {2015+i}')\nplt.tight_layout()","d88780e1":"most_targetted=data['target'].value_counts()[:5].index\nfig, axs = plt.subplots(5,1, figsize=(18, 30), facecolor='w', edgecolor='k')\nfig.subplots_adjust(hspace = .5, wspace=.001)\naxs = axs.ravel()\nfor i in range(0,5):\n    x=data[data['target']==most_targetted[i]]['insult'].value_counts()[:10]\n    y=data[data['target']==most_targetted[i]]['insult'].value_counts()[:10].index\n    axs[i].bar(y,x)\n    axs[i].set_xlabel(f'Insults of {most_targetted[i]}')\n    axs[i].set_ylabel('Number of Tweets')\n    axs[i].set_title(f'Most Insults done of {most_targetted[i]}')\nplt.tight_layout()","c181d3c7":"stop_words = stopwords.words(\"english\")\nstemmer = SnowballStemmer(\"english\")\n\ndef preprocess(text, stem=False):\n    text = str(text).lower().strip()\n    tokens = []\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return \" \".join(tokens)\ndata['tweet']=data['tweet'].apply(lambda x:preprocess(x))","ce7b9d42":"def get_tweet_bigram(corpus,n):\n    vec=CountVectorizer(ngram_range=(2,2))\n    bow=vec.fit_transform(corpus)\n    sum_word=bow.sum(axis=0)\n    word_freq=[(x,sum_word[0,i]) for x,i in vec.vocabulary_.items()]\n    word_freq=sorted(word_freq,key=lambda x:x[1],reverse=True)\n    return word_freq[:n]","bb3d377a":"plt.figure(figsize=(10,5))\ntop_tweet_bigram=get_tweet_bigram(data['tweet'],10)\nx,y=map(list,zip(*top_tweet_bigram))\nsns.barplot(y,x)","2b90dc0c":"def remove_links(corpus):\n    pattern=re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return pattern.sub(r'',corpus)\ndata['tweet']=data['tweet'].apply(lambda x:remove_links(x))","d881ef53":"def remove_html(corpus):\n    pattern=re.compile(r'<.*?>')\n    return pattern.sub(r'',corpus)\ndata['tweet']=data['tweet'].apply(lambda x:remove_html(x))","6cab97b7":"def remove_emoji(string):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', string)\ndata['tweet']=data['tweet'].apply(lambda x:remove_emoji(x))","18029c95":"def remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)\ndata['tweet']=data['tweet'].apply(lambda x:remove_punct(x))","96343821":"plt.figure(figsize=(10,5))\ntop_tweet_bigram=get_tweet_bigram(data['tweet'],10)\nx,y=map(list,zip(*top_tweet_bigram))\nsns.barplot(y,x)","1bab909e":"def getPolarity(text):\n   return TextBlob(text).sentiment.polarity\ndata['polarity']=data['tweet'].apply(lambda x: getPolarity(x))","7cd65668":"def getAnalysis(score):\n if score < 0:\n  return 'Negative'\n elif score == 0:\n  return 'Neutral'\n else:\n  return 'Positive'\ndata['Analysis'] = data['polarity'].apply(getAnalysis)\n","bcfb6acc":"plt.subplots(figsize=(8,8))\nplt.pie(x=data['Analysis'].value_counts(),labels=data['Analysis'].value_counts().index,autopct='%1.1f%%',\n        shadow=True, startangle=180)","3e986a2c":"plt.subplots(figsize=(5,5))\ng=sns.barplot(x=data['Analysis'].value_counts(),y=data['Analysis'].value_counts().index)\ng.set_ylabel('Sentiments')\ng.set_xlabel('Number of Tweets')\ng.set_title('Sentiment Analysis - Number of Tweets')","52e58a68":"![image.png](attachment:image.png)","fbf8ea8f":"**Before doing the sentiment analysis we have to remove the stop words that have been used in the tweets**","9505781d":"# Most Insults done of Targets","56099ddc":"**Pie chart for the polarity of the data**","824cf5a1":"# Number of tweets for Insults","9d929f98":"**Removing the links**","acf2727b":"**Lets see the most common bigrams**","2f9e257e":"# Objective\n1. Exploratory Data Analysis\n2. Tweets Sentiment Analysis","9f9a6d62":"# Thanks from me and Donald Trump...!!","80c32179":"**Lets create bigrams for the corpus**","7a423850":"![image.png](attachment:image.png)","4d847317":"**Lets check the polarity of the data**","8232dd0a":"# Please Upvote this kernel and if you find it helpful please keep it in your Favourite Section.","5774005b":"**Finally the barplot for this polarity**","9b072eb9":"**Removing any emoji**","515db3eb":"# Most Insults done","86ac715c":"**Removing HTML tags(if any)**","a45f5b43":"# Most Targetted Areas","e59f3db8":"*As we can see there are a lot of links that has been used in the tweets so first we'll remove those*","35e6f8fb":"# Please upvote the notebook","fede7214":"*As you can see the links have been removed from the data*","a241b491":"# Exploratory Data Analysis","db54d4b2":"**Lets check the bigrams again after cleaning the data**","13c82834":"# Importing data","75710df9":"**Removing punctuations**","6cb089cb":"Donald Trump, Ex American President, has always been in the news due to his controversials tweets. Lets do some analysis of his tweets in last few years","a2bd5fc4":"# Importing Libraries","af787694":"# Year-wise Insults","e9c28a7d":"# Sentiment Analysis"}}