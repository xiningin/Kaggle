{"cell_type":{"f53f14be":"code","8fd35ab6":"code","b765c75b":"code","657362ef":"code","fedc2857":"code","a5a362a2":"code","1cf37e42":"code","87765797":"code","abf7f618":"code","2a7ba276":"code","457b287b":"code","803c4f77":"code","32e3fcde":"code","05a3d42a":"code","85ab71db":"code","79c9fa3f":"code","381600d4":"code","76926204":"code","86de5848":"code","4dfa1e4d":"code","a155f566":"code","263cb917":"code","cdfc1d8f":"code","100458c6":"code","77d4825a":"code","646da81a":"code","d770cb98":"code","f1f6e2cd":"code","81454b00":"code","7d11855f":"code","977b9b9a":"code","f67ab689":"code","43a3458d":"code","2303ad48":"code","df3bcb02":"code","57ef2704":"code","01524421":"code","870dcdea":"code","9e1361a1":"code","2b456eb3":"code","854a1c36":"code","9066e59c":"code","fdcac8bd":"code","8255723b":"code","18ca8eb1":"code","5e55ebce":"code","56f43325":"code","7afb5a8e":"code","2e1211ef":"code","0f628461":"code","164c52c3":"code","72e3b351":"code","6cbe0e4a":"code","efdd75a9":"markdown","22eb6066":"markdown","15f4d7dc":"markdown","84545e04":"markdown","1edcdbb0":"markdown","f28c6c44":"markdown","723ccfef":"markdown","769c7aeb":"markdown","992e289d":"markdown","afcf6bb6":"markdown","36b925e5":"markdown","5d9ce1d3":"markdown","608abaa0":"markdown","27a34969":"markdown","95eeaf33":"markdown","e846bf96":"markdown","b4df0f8b":"markdown","f7e55394":"markdown","f9f8d7ba":"markdown","691123e6":"markdown","e4c1ad30":"markdown","58bc6f94":"markdown","a8f3a865":"markdown","9d741974":"markdown","65c8d486":"markdown","0298d6ec":"markdown","d19c593a":"markdown"},"source":{"f53f14be":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import OrdinalEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling as pp\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport xgboost as xgb\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8fd35ab6":"def fills_good(data, main_column, function, group_columns):\n    \"\"\"Function for filling in missing values\n\n    To use the function, you must pass it\n    the following arguments:\n\n    data - an array of data in which you need to fill in the gaps;\n    main_column - the column in which the values are omitted;\n    function - the value of the function that will be used when\n    filling in empty values in quotes ('mean','median'...);\n    group_columns - columns for grouping data as an array [...]\n    filling in the gaps will be performed according to\n    grouped by the specified columns.\n    \"\"\"\n    \n    data[main_column] = data[main_column].fillna(data.groupby(group_columns)[main_column].transform(function))\n    \n    return data[main_column]","b765c75b":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_target = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","657362ef":"pp.ProfileReport(train_df)","fedc2857":"test_concat = pd.merge(test_df, test_target, on='PassengerId')","a5a362a2":"test_concat","1cf37e42":"main_df = pd.concat([train_df,test_concat], ignore_index= True,)","87765797":"main_df","abf7f618":"main_df = pd.get_dummies(main_df, columns=['Sex'],drop_first=True)\nmain_df = main_df.rename(columns={'Sex_male':'Sex'})","2a7ba276":"display(main_df.head())\nprint('-'*40)\n","457b287b":"main_df.info()\nprint('-'*40)\nmain_df.describe()\n","803c4f77":"sns.set(palette='BuGn_r')\nfig = plt.figure(figsize = (12,9))\nsns.histplot(main_df[\"Age\"], kde=True)\nplt.title('Hist of ages')\nplt.show()","32e3fcde":"sns.pairplot(main_df[['Age', 'Survived', 'Pclass', 'SibSp', 'Parch', 'Sex']],palette='CMRmap_r')\nplt.show()\n\n","05a3d42a":"main_df['Age'] = fills_good(main_df, 'Age', 'median', ['Pclass', 'SibSp', 'Parch', 'Embarked', 'Sex'])\nmain_df['Age'] = main_df['Age'].fillna(main_df['Age'].median())","85ab71db":"main_df.info()","79c9fa3f":"fig = plt.figure(figsize = (12,9))\nsns.histplot(main_df[\"Age\"], kde=True, palette='BuPu_r')\nplt.title('Age hist after filling')\nplt.show()","381600d4":"fig, ax = plt.subplots(figsize=(10,10))\ncolors = sns.color_palette(\"Accent\")\nax.pie(main_df[\"Embarked\"].value_counts(), labels=main_df[\"Embarked\"].value_counts().index, autopct='%.0f%%', colors = colors)\nax.set_title('Survery responses')\nplt.show()","76926204":"main_df['Embarked'] = main_df['Embarked'].fillna('S')\nmain_df['Fare'] = main_df['Fare'].fillna(main_df['Fare'].median())","86de5848":"main_df = main_df.drop(labels='Cabin', axis=1)","4dfa1e4d":"main_df.info()\nprint('-'*40)\ndisplay(main_df.describe())\nprint('-'*40)\ndisplay(main_df.describe(include=['O']))","a155f566":"main_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","263cb917":"main_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","cdfc1d8f":"main_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","100458c6":"main_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","77d4825a":"main_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","646da81a":"fig = sns.FacetGrid(main_df, \n                    col='Survived', \n                    height=5,\n                    palette='BuGn_r')\nfig.map(sns.histplot, 'Age',kde=True ,bins=20)\n","d770cb98":"grid = sns.FacetGrid(main_df, col='Survived', row='Sex',height=5)\ngrid.map(sns.histplot, 'Age', alpha=.5, bins=20, kde=True)\ngrid.add_legend()\n","f1f6e2cd":"grid = sns.FacetGrid(main_df, col='Survived', row='Pclass',height=5)\ngrid.map(sns.histplot, 'Age', alpha=.5, bins=20, kde=True)\ngrid.add_legend()","81454b00":"def survival_rate(feature):\n    rate = main_df[[feature, 'Survived']].groupby([feature], as_index=False).mean().sort_values(by=[feature], ascending=True)\n    sns.catplot(x=feature, y=\"Survived\", data=rate)\n\nfor feature in [\"Age\", \"Fare\", \"SibSp\", \"Parch\", \"Sex\", \"Embarked\", \"Pclass\"]:\n    survival_rate(feature)","7d11855f":"main_df","977b9b9a":"main_df = main_df.drop(['Name', 'Ticket'], axis=1)","f67ab689":"main_df","43a3458d":"main_df['Age_group'] = pd.cut(main_df['Age'], 5)\nmain_df[['Age_group', 'Survived']].groupby(['Age_group'], as_index=False).mean().sort_values(by='Age_group', ascending=True)","2303ad48":"main_df.loc[ main_df['Age'] <= 16, 'Age'] = 0\nmain_df.loc[(main_df['Age'] > 16) & (main_df['Age'] <= 32), 'Age'] = 1\nmain_df.loc[(main_df['Age'] > 32) & (main_df['Age'] <= 48), 'Age'] = 2\nmain_df.loc[(main_df['Age'] > 48) & (main_df['Age'] <= 64), 'Age'] = 3\nmain_df.loc[ main_df['Age'] > 64, 'Age'] = 4 \nmain_df.Age = main_df.Age.astype('int')\nmain_df = main_df.drop('Age_group', axis=1)\nmain_df.head()","df3bcb02":"main_df['Fare_group'] = pd.cut(main_df['Fare'], 5)\nmain_df[['Fare_group', 'Survived']].groupby(['Fare_group'], as_index=False).mean().sort_values(by='Fare_group', ascending=True)","57ef2704":"main_df.loc[ main_df['Fare'] <= 102, 'Fare'] = 0\nmain_df.loc[(main_df['Fare'] > 102) & (main_df['Fare'] <= 204), 'Fare'] = 1\nmain_df.loc[(main_df['Fare'] > 204) & (main_df['Fare'] <= 307), 'Fare'] = 2\nmain_df.loc[(main_df['Fare'] > 307) & (main_df['Fare'] <= 409), 'Fare'] = 3\nmain_df.loc[ main_df['Fare'] > 409, 'Fare'] = 4 \nmain_df.Age = main_df.Age.astype('int')\nmain_df = main_df.drop('Fare_group', axis=1)\nmain_df.head()","01524421":"main_df_ohe = pd.get_dummies(main_df, columns=['Pclass', 'SibSp','Fare', 'Age', 'Embarked'],drop_first=True)","870dcdea":"main_df_ohe","9e1361a1":"test_df_ohe = main_df_ohe[main_df_ohe['PassengerId'].isin(test_df.PassengerId)]\ntrain_df_ohe = main_df_ohe[main_df_ohe['PassengerId'].isin(train_df.PassengerId)]\n","2b456eb3":"train_target = train_df_ohe['Survived']\ntrain_df_ohe = train_df_ohe.drop(['Survived', 'PassengerId'], axis = 1)","854a1c36":"test_df_ohe = test_df_ohe.drop(['Survived', 'PassengerId'], axis = 1)","9066e59c":"display(train_target.shape) \nprint(\"-\"*40)\ndisplay(train_df_ohe.shape ) \nprint(\"-\"*40)\ndisplay(test_df_ohe.shape) ","fdcac8bd":"acc_models = pd.DataFrame()","8255723b":"test_target = test_target.drop('PassengerId',axis=1)","18ca8eb1":"model_LR = LogisticRegression()\nmodel_LR.fit(train_df_ohe, train_target)\npredict_LR = model_LR.predict(test_df_ohe)\nacc_LR = round(model_LR.score(train_df_ohe, train_target) * 100, 2)\nacc_LR_valid = round(model_LR.score(test_df_ohe, test_target) * 100, 2)\nacc_models.loc['LR', 'acc_score'] = acc_LR\nacc_models.loc['LR', 'target_score'] = round(model_LR.score(test_df_ohe, test_target) * 100, 2)\nx = np.arange(len(test_df_ohe))\nplt.figure(figsize=(16,10))\nplt.scatter(x, predict_LR, label = 'LogisticRegression', color = 'g')\nplt.title(f'Prediction for the training data by LogisticRegression model')\nplt.legend(loc='best')\nplt.grid(True)\n","5e55ebce":"acc_LR","56f43325":"model_gaussian = GaussianNB()\nmodel_gaussian.fit(train_df_ohe, train_target)\npredict_gaussian = model_gaussian.predict(test_df_ohe)\nacc_gaussian = round(model_gaussian.score(train_df_ohe, train_target) * 100, 2)\nacc_gaussian_valid = round(model_gaussian.score(test_df_ohe, test_target) * 100, 2)\nacc_models.loc['GaussianNB', 'acc_score'] = acc_gaussian\nacc_models.loc['GaussianNB', 'target_score'] = round(model_gaussian.score(test_df_ohe, test_target) * 100, 2)\nplt.figure(figsize=(16,10))\nplt.scatter(x, predict_gaussian, label = 'GaussianNB', color = 'g')\nplt.title(f'Prediction for the training data by GaussianNB model')\nplt.legend(loc='best')\nplt.grid(True)","7afb5a8e":"acc_gaussian","2e1211ef":"model_tree = DecisionTreeClassifier()\nmodel_tree.fit(train_df_ohe, train_target)\npredict_tree = model_tree.predict(test_df_ohe)\nacc_tree = round(model_tree.score(train_df_ohe, train_target) * 100, 2)\nacc_tree_valid = round(model_tree.score(test_df_ohe, test_target) * 100, 2)\nacc_models.loc['Tree', 'acc_score'] = acc_tree\nacc_models.loc['Tree', 'target_score'] = round(model_tree.score(test_df_ohe, test_target) * 100, 2)\nplt.figure(figsize=(16,10))\nplt.scatter(x, predict_tree, label = 'DecisionTreeClassifier', color = 'g')\nplt.title(f'Prediction for the training data by DecisionTreeClassifier model')\nplt.legend(loc='best')\nplt.grid(True)\n","0f628461":"print(f'DecisionTreeClassifier train score: {acc_tree} , valid score: {acc_tree_valid}')\nprint(f'Gaussian train score: {acc_gaussian} , valid score: {acc_gaussian_valid}')\nprint(f'LogisticRegression train score: {acc_LR} , valid score: {acc_LR_valid}')","164c52c3":"acc_models.sort_values(by='target_score', ascending=False)","72e3b351":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": predict_LR\n    })\nsubmission.reset_index()","6cbe0e4a":"submission.to_csv('submission.csv', index=False)","efdd75a9":"Interesting data can be obtained from visualizing the distribution of survivors based on the class of service.\n\nThe ratio of survivors to the dead in the first class is even more than 1, whereas in the third class most of the people did not survive the disaster. We see how the position in society and the well-being of passengers affected the survival rate in this disaster","22eb6066":"Delete the columns \"Name\", \"Ticket\"","15f4d7dc":"## Data import","84545e04":"We will delete the Cabin column, since there are a lot of missing values in it, which cannot be filled in","1edcdbb0":"Let's combine the data into one dataframe for analytical analysis","f28c6c44":"## Data preprocessing","723ccfef":"Age distributions based on survival in a disaster are similar, but there is one interesting point - there are noticeably more babies among the survivors than among the deceased","769c7aeb":"Missing values in columns:\n- Age\n- Fare\n- Cabin\n- Embarked\n","992e289d":"Discrete values will be evaluated using visual analysis","afcf6bb6":"There are about 3 times more women than men among the survivors, although there are 8 times more men than women among the deceased","36b925e5":"We will fill in the gaps in the values in accordance with the grouping by various parameters, consider the correspondence of various parameters to the age of passengers","5d9ce1d3":"## Local functions","608abaa0":"# EDA & Prediction for Titanic survive competition","27a34969":"In the Age column","95eeaf33":"Let's estimate the average survival rate depending on various parameters","e846bf96":"## Data analysis","b4df0f8b":"We will bring all the parameters to the same scale, divide the discrete variables into categories, then we will carry out the OHE procedure","f7e55394":"## Importing libraries","f9f8d7ba":"To fill in the gaps in \"Age\", we will use median values grouped by columns 'P class', 'Subsp', 'Perch'. The gaps that are not filled in according to three criteria will be grouped by the last two, then by the last one and the remaining ones by the total median value","691123e6":"## As a result, we got a score in the leaderboard = 0.77990, undoubtedly there is retraining in the models we have developed, you can fight with it, as well as select hyperparameters, but this is my first experience in competitions and I would like to move on","e4c1ad30":"Let's compare the accuracy of the models","58bc6f94":"Fill in the values in the \"Fare\" and \"Embarked\" columns with the median and most common values","a8f3a865":"Thanks for this beautiful notebook https:\/\/www.kaggle.com\/daniilseleznev\/titanic-survive-eda-prediction ;","9d741974":"## Preparing data for building models","65c8d486":"\n\n|Variable|Definition|Key|\n|--------|----------|---|\n|survival |\tSurvival |\t0 = No, 1 = Yes||\n|pclass \t|Ticket class \t|1 = 1st, 2 = 2nd, 3 = 3rd|\n|sex \t|Sex |\t|\n|Age |\tAge in years |\t|\n|sibsp \t|# of siblings \/ spouses aboard the Titanic |\t|\n|parch \t|# of parents \/ children aboard the Titanic |\t|\n|ticket \t|Ticket number| \t|\n|fare |\tPassenger fare |\t|\n|cabin| \tCabin number| \t|\n|embarked |\tPort of Embarkation| \tC = Cherbourg, Q = Queenstown, S = Southampton|\n","0298d6ec":"## Training and selection of models","d19c593a":"Preprocessing and data analysis will be carried out on a combined dataset to assess common patterns"}}