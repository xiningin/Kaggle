{"cell_type":{"b33c32c5":"code","42d02b23":"code","25dc88a7":"code","5b412268":"code","0c386b9f":"code","32d14f36":"code","7c0ae03d":"code","995d338f":"code","f192faa3":"code","dbc4771b":"code","c308c937":"code","1443a2b6":"code","4aa7f01f":"code","1cd2a67d":"code","80781712":"code","558f4777":"code","f6e28118":"code","1c848c64":"code","c99ca3d3":"code","fe2075ae":"code","5b72c9ca":"code","08dd7077":"code","216f9b4f":"code","082d924e":"code","68bed651":"code","9f2c34b0":"code","2974ec80":"code","69a780d5":"code","11ef072f":"code","25075c7c":"code","39abcc0b":"code","ea2641f0":"code","332ace99":"code","13230587":"markdown","f40c7a41":"markdown","f6c241c0":"markdown","fde3ed0e":"markdown","d2ddbe1d":"markdown","cf667342":"markdown","bc5bdc73":"markdown","9d61e079":"markdown"},"source":{"b33c32c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42d02b23":"import warnings\nwarnings.filterwarnings('ignore')","25dc88a7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\n\nfrom torchvision.utils import make_grid\nfrom torchvision import models as models \nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\n\n%matplotlib inline","5b412268":"data_dir = '..\/input\/flowers-recognition\/flowers\/'","0c386b9f":"transformer = torchvision.transforms.Compose(\n    [ # Applying Augmentation\n        torchvision.transforms.Resize((224, 224)),\n        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n        torchvision.transforms.RandomVerticalFlip(p=0.5),\n        torchvision.transforms.RandomRotation(40),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize(\n            mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]\n        ),\n    ]\n)\n\ndatabase = ImageFolder(data_dir, transform=transformer)","32d14f36":"database.classes","7c0ae03d":"# Flower Label\nflower_label = {\n    0: 'daisy',\n    1: 'dandelion',\n    2: 'rose',\n    3: 'sunflower',\n    4: 'tulip'\n}","995d338f":"# Show Single Picture and Batch Picture\ndef show_batch(dl, invert=True):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        \ndef show_sample(image, label, invert=True):\n    print('Label: ' + database.classes[label] + \"(\" + str(label) + \")\")\n    plt.imshow(image.permute(1, 2, 0))","f192faa3":"show_sample(*database[1])","dbc4771b":"validation_size = 500\ntraining_size = len(database) - validation_size","c308c937":"train_ds, val_ds_main = random_split(database, [training_size, validation_size])\nval_ds, test_ds = random_split(val_ds_main, [300, 200])\nlen(train_ds), len(val_ds)","1443a2b6":"## Choose the batch size, Put it in the DataLoader and show the batch\nbatch_size = 32\n\n\n# DataLoaders\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size)\ntest_dl = DataLoader(test_ds, batch_size)","4aa7f01f":"show_batch(train_dl, invert=True)","1cd2a67d":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\n\nclass ImageClassification(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","80781712":"# Flower Recognition Model\nclass FlowerModel(ImageClassification):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), \n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), \n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), \n\n            nn.Flatten(), \n            nn.Linear(256*28*28, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 5))\n        \n    def forward(self, xb):\n        return self.network(xb)","558f4777":"model = FlowerModel()\nmodel","f6e28118":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","1c848c64":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, optim=torch.optim.SGD):\n    history = []\n    optimizer = optim(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        # Validation Phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    \n    return history","c99ca3d3":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n    \ndevice = get_default_device()\ndevice","fe2075ae":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\n\nto_device(model, device)","5b72c9ca":"model = to_device(FlowerModel(), device)","08dd7077":"evaluate(model, val_dl)","216f9b4f":"epochs = 10\noptim = torch.optim.Adam\nlr = 0.001","082d924e":"%%time\ntry1 = fit(epochs, lr, model, train_dl, val_dl, optim)","68bed651":"def plot_accuracies(try1):\n    accuracies = [x['val_acc'] for x in try1]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy v\/s No. of Epochs')","9f2c34b0":"plot_accuracies(try1)","2974ec80":"def plot_losses(try1):\n    train_losses = [x.get('train_loss') for x in try1]\n    val_losses = [x['val_loss'] for x in try1]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","69a780d5":"plot_losses(try1)","11ef072f":"test_dl = DeviceDataLoader(test_dl, device)\nevaluate(model, test_dl)","25075c7c":"def predict_image(img, model):\n    xb = img.unsqueeze(0)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return flower_label[preds[0].item()]","39abcc0b":"img, label = test_ds[1]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', database.classes[label], ', Predicted:', predict_image(img, FlowerModel()))","ea2641f0":"img, label = test_ds[5]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', database.classes[label], ', Predicted:', predict_image(img, FlowerModel()))","332ace99":"torch.save(model.state_dict(), 'PyTorchFlowerClassificationCNN.pth')","13230587":"## Training and Validation Datasets","f40c7a41":"## Save Model","f6c241c0":"## Data Augmentation and Normalization","fde3ed0e":"## Flower Classification using CNN","d2ddbe1d":"## Get GPU as Default Device","cf667342":"## Split Train Data with Validation Data","bc5bdc73":"## Plot Results","9d61e079":"## Predict Image"}}