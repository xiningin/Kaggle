{"cell_type":{"347823d5":"code","27dc6319":"code","71047cfa":"code","a31a0371":"code","bbbb8d7e":"code","489483ed":"code","24a705f5":"code","34c3e319":"code","51b72ae3":"code","cafa48e5":"code","3122a260":"code","363850b0":"code","da2fe971":"code","c0506c9e":"code","34f0dc59":"code","26e5bb3b":"code","b10394df":"code","e35b06e9":"code","e5a50280":"code","bad6f718":"code","a179ec4e":"markdown","de40a942":"markdown","9bd6c3eb":"markdown","a0fb9d52":"markdown","d42ff714":"markdown","e7c37968":"markdown","829216ac":"markdown","264bfd69":"markdown","46001a15":"markdown","7e2e72ea":"markdown","f697ac6b":"markdown","c47525ff":"markdown","72beceb5":"markdown","456bf7cd":"markdown","a157f57b":"markdown","9b636537":"markdown","52d7b8f8":"markdown","9004076b":"markdown"},"source":{"347823d5":"import pandas as pd\nfrom PIL import Image, ImageDraw\nfrom pathlib import Path\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm","27dc6319":"def get_frame_from_video(frame, video):\n    frame = frame - 1\n    !ffmpeg \\\n        -hide_banner \\\n        -loglevel fatal \\\n        -nostats \\\n        -i $video -vf \"select=eq(n\\,$frame)\" -vframes 1 frame.png\n    img = Image.open('frame.png')\n    os.remove('frame.png')\n    return img","71047cfa":"video = '..\/input\/nfl-health-and-safety-helmet-assignment\/train\/57583_000082_Endzone.mp4'\nframe = 1\nimg = get_frame_from_video(frame, video)\nimg","a31a0371":"bboxes_df = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_baseline_helmets.csv')\nvideo_frame = Path(video).stem + '_' + str(frame)\ndf = bboxes_df[bboxes_df['video_frame'] == video_frame].copy()\nxc = (df['left'] + df['width']\/2).astype(int).values\nyc = (df['top'] + df['height']\/2).astype(int).values\nxc, yc","bbbb8d7e":"def annotate_frame(img, xc, yc, r, col = (57, 255, 20)):\n    draw = ImageDraw.Draw(img)\n    for x, y in zip(xc, yc):\n#         draw.point((x, y), fill=col)\n        draw.ellipse((x-r, y-r, x+r, y+r), fill=col, outline = 'black')\n    return img","489483ed":"annotate_frame(img, xc, yc, 5)","24a705f5":"# code from: https:\/\/www.kaggle.com\/robikscube\/nfl-helmet-assignment-getting-started-guide\ndef add_track_features(tracks, fps=59.94, snap_frame=10):\n    \"\"\"\n    Add column features helpful for syncing with video data.\n    \"\"\"\n    tracks = tracks.copy()\n    tracks[\"game_play\"] = (\n        tracks[\"gameKey\"].astype(\"str\")\n        + \"_\"\n        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n    )\n    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n    snap_dict = (\n        tracks.query('event == \"ball_snap\"')\n        .groupby(\"game_play\")[\"time\"]\n        .first()\n        .to_dict()\n    )\n    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n        \"timedelta64[ms]\"\n    ) \/ 1_000\n    # Estimated video frame\n    tracks[\"est_frame\"] = (\n        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n    )\n    return tracks\n\ndef add_video_features(videos):\n    videos['game_play'] = videos['video_frame'].apply(lambda x: '_'.join(x.split('_')[:2]))\n    videos['camera'] = videos['video_frame'].apply(lambda x: x.split('_')[2])\n    videos['frame'] = videos['video_frame'].apply(lambda x: x.split('_')[-1])\n    videos['xc'] = (videos['left'] + videos['width']\/2).astype(int).values\n    videos['yc'] = (videos['top'] + videos['height']\/2).astype(int).values\n    return videos","34c3e319":"def annotate_field(xc, yc, player, r = 10, width = 3, col = [(27, 3, 163), (255, 7, 58)], crop = None, box = True):\n    field = Image.open('..\/input\/nflhelmet-helper-dataset\/field.png')\n    w, h = field.size\n    zero = (68,68)\n    fs = (2424,1100)\n    draw = ImageDraw.Draw(field)\n    xc, yc = xc*fs[0]\/120 + zero[0], (1 - yc\/53.3)*fs[1] + zero[1]\n    for x, y, p in zip(xc, yc, player):\n        c = col[0] if p[0] == 'H' else col[1]\n        draw.ellipse((x-r, y-r, x+r, y+r), fill=c, width=width, outline = 'black')\n    if isinstance(crop, float):\n        if box:\n            cp = [xc.min() - crop*w, yc.min() - crop*h, xc.max() + crop*w, yc.max() + crop*h]\n        else:\n            cp = [xc.min() - crop*w, 0, xc.max() + crop*2*w, h]\n        field = field.crop(cp)\n        \n    return field","51b72ae3":"tracking_df = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_player_tracking.csv')\ntracking_df = add_track_features(tracking_df)\nx, y, player = tracking_df.query(f\"game_play == '57583_000082' and est_frame == 10\")[['x', 'y', 'player']].values.transpose()\nannotate_field(x, y, player, r = 20)","cafa48e5":"class show_play_with_tracking():\n    \n    def __init__(self, video_df = None, track_df = None):\n        if video_df is None:\n            video_df = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_baseline_helmets.csv')\n            self.video_df = add_video_features(video_df)\n        if track_df is None:\n            tracking_df = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_player_tracking.csv')\n            tracking_df = add_track_features(tracking_df)\n            self.tracking_df = tracking_df.query(\"est_frame > 0\")\n       \n    def __call__(self, game_play, frame, img_size = 800, video_folder = '..\/input\/nfl-health-and-safety-helmet-assignment\/train\/'):\n        \n        camera = 'Sideline'\n        frame_side = get_frame_from_video(frame, video_folder + game_play + '_' + camera + '.mp4')\n        df = self.video_df.query(f\"game_play == '{game_play}' and frame == '{frame}' and camera == '{camera}'\")\n        frame_side = annotate_frame(frame_side, df.xc, df.yc, 10)\n\n        camera = 'Endzone'\n        frame_end = get_frame_from_video(frame, video_folder + game_play + '_' + camera + '.mp4')\n        df = self.video_df.query(f\"game_play == '{game_play}' and frame == '{frame}' and camera == '{camera}'\")\n        frame_end = annotate_frame(frame_end, df.xc, df.yc, 10)\n\n        frames = self.tracking_df['est_frame'].values\n        if frame not in frames:\n            index = np.absolute(frames-frame).argmin()\n            frame = frames[index]\n        df = self.tracking_df.query(f\"game_play == '{game_play}' and est_frame == {frame}\")\n        field = annotate_field(df.x, df.y, df.player, 10, crop = 0.01)\n\n        wf, hf = field.size\n        wc, hc = frame_side.size\n        field = field.resize((int(wf*2*hc\/hf), 2*hc))\n        wf, hf = field.size\n\n        img = Image.new('RGB', (wf+wc+20, 2*hc+20))\n        img.paste(im=field, box=(5, 10))\n        img.paste(im=frame_side, box=(wf+15, 5))\n        img.paste(im=frame_end, box=(wf+15, hc+15))\n        img.thumbnail((img_size,img_size))\n        return img","3122a260":"spwt = show_play_with_tracking()","363850b0":"spwt('57682_002630', 1)","da2fe971":"all_plays = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/train_baseline_helmets.csv')['video_frame'].\\\n                apply(lambda x: '_'.join(x.split('_')[:2])).unique()\nlen(all_plays)","c0506c9e":"imgs = []\nfor play in tqdm(all_plays):\n    imgs.append(spwt(play, 1, 400)) # gameplay, frame, img_size\nimgs = [imgs[0:20], imgs[20:40], imgs[40:60]]","34f0dc59":"W, H = 400, 250\nimg = Image.new('RGB', (W*3, H*20), (255, 255, 255))\nfor x in range(3):\n    for y in range(20):\n        img.paste(im=imgs[x][y], box=(W*x, H*y))\nimg","26e5bb3b":"spwt('57682_002630', 300)","b10394df":"spwt('57682_002630', 200)","e35b06e9":"# Camera is on the TOP and LEFT in relation to the tracking data\nspwt(all_plays[30], 1)","e5a50280":"# Camera is on the BOTTOM and LEFT in relation to the tracking data\nspwt(all_plays[1], 1)","bad6f718":"# Camera is on the BOTTOM and RIGHT in relation to the tracking data\nspwt(all_plays[2], 1)","a179ec4e":"# Visualizing the tracking data\n\nIt would be helpful to have visualize the tracking data as well, so here a code that can plot dots on a nice 2d drawing of the football field","de40a942":"### Lesson 2\n\nCamera placemente is not consistent. Some gameplays, have the camera on the home endzone some on the visitor endzone","9bd6c3eb":"# Combining all together (tracking + camera)\n\nFor this, I decided to use a class that initializes by creating the expanded dataframes.","a0fb9d52":"Now, we can annotate the image passing the helmet centers and the radius of the circle. Originaly I only used a point, but the size of the pixel is too small to see.","d42ff714":"## Keypoint overlaying\n\nTo annotate the image with the key-point information, we first need to calculate the x-y coordinate of the helmet's center.\nFor now, I will use the baseline bounding boxes.","e7c37968":"And here is an example for the gameplay `57682_002630` at frame 1:","829216ac":"## Extracting a frame from a video\n\nThis function uses ffmeg to exctract a single frame from a video. It saves on the working dir, loads it as a PIL image object and then deletes the image from disk","264bfd69":"With this function we could easily do that for all 60 videos!","46001a15":"The function inputs `x`, `y` coordinates as well as the tag of each player (to extract H or V for coloring). Here is an example:","7e2e72ea":"# Helmet Keypoint annotation tool\n\nSimple and lightweight tool to extract a frame from a video file and annotate the helmet center coordinates.\nThis notebook is part of a more comprehensive processing pipeline that is still being developed. I will be updating this notebook quite often.\n\nIf you find this helpful, consider upvoting it! Thanks =)","f697ac6b":"## A few learned lessons","c47525ff":"The only way you could predict the red dot in the Endzone is by having temporal coherence. If you rewind this 100 frames you can see him.","72beceb5":"### Lesson 1 \n\nIf you are planing to use tracking data mapping. You can't have perfect score just by predicting each frame independently. On this example, we can't see the red guy in the endzone on either cameras.","456bf7cd":"Initializing the class with the default dataframes (`train_baseline_helmets.csv` and `train_player_tracking.csv`)","a157f57b":"## Importing the dependencies","9b636537":"Grab a coffee coz this will take a while \u2615","52d7b8f8":"Here, an example","9004076b":"# That is it for now! more coming soon! =)"}}