{"cell_type":{"eecd6c66":"code","3d75606e":"code","f3d5e8cc":"code","9444d49f":"code","6c927e0a":"code","1c42347e":"code","bd68467b":"code","fcd595ad":"code","6f691b6a":"code","9114ecf9":"code","5a6fadaa":"code","0e97d86b":"code","f1c987b1":"code","d03ee21e":"code","bd2f2c96":"code","80637f53":"code","a4e61c72":"code","8358576f":"code","40a53901":"code","8e41cdbb":"code","9f27d42b":"code","98ad6894":"code","70aa6e03":"code","c9445aed":"code","7f4f6953":"code","afcdebc9":"code","d1c7e3f1":"code","a93eca0a":"code","a3b5bbc6":"markdown","a1fa2f47":"markdown","07f3cccc":"markdown","d1493e0f":"markdown","f5cd9524":"markdown","11660c65":"markdown","0f643e15":"markdown","e71b57c7":"markdown","97bf8307":"markdown","792a0c86":"markdown","4f7b1644":"markdown","7b6103fd":"markdown","91a5fdd5":"markdown","34784d7a":"markdown","b24f63b9":"markdown","9514bc4e":"markdown","dd7e2422":"markdown","857cfbf2":"markdown","cd5a31a6":"markdown","e219a2a6":"markdown","34146249":"markdown","15f696f3":"markdown","1cea2011":"markdown","7abc5416":"markdown","bdcc2eed":"markdown","0ba4030b":"markdown","51a9c995":"markdown","2cf38d9d":"markdown","7fb763a7":"markdown"},"source":{"eecd6c66":"# Packages for data analysis\nimport pandas as pd\nimport numpy as np\nfrom itertools import combinations\n\n# Packages for visualisation \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_theme(style=\"darkgrid\")\n\n# Packages for machine learning\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\n\n# Others\nimport warnings\nwarnings.filterwarnings(\"ignore\")","3d75606e":"rain = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv', parse_dates=['Date'])\nrain.head()","f3d5e8cc":"rain.info()","9444d49f":"# Extract numerical features\nnum_cols=rain.select_dtypes(include=np.number).columns.tolist()\nprint('There are', len(num_cols), 'numerical features, including:')\nprint(num_cols, \"\\n\")\n\n# Extract categorical features\ncat_cols=rain.select_dtypes(object).columns.tolist()\nprint('There are', len(cat_cols), 'categorical features, including:')\nprint(cat_cols)","6c927e0a":"# Checking data completeness\nmissing = pd.DataFrame(rain.isnull().sum(), columns=['No. of missing values'])\nmissing['% missing_values'] = (missing\/len(rain)).round(2)*100\nmissing","1c42347e":"# Where are missing values located in the dataset (white color indicates missing values)\nplt.figure(figsize=(10,5))\nsns.heatmap(rain.isnull(), cbar = False, cmap=\"gray\")","bd68467b":"# Drop features that have a significant proportion of missing values\nrain.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1, inplace=True)\n\n# Remove rows where target variables are missing\nrain.dropna(how='all', subset=['RainTomorrow'], inplace=True) # Remove rows where target varible is missing","fcd595ad":"print('There are', len(cat_cols), 'categorical features, including:', \"\\n\", cat_cols, '\\n')\n# Extract details on categorical features\nfor i in cat_cols:\n    unique_no = rain[i].nunique()\n    unique_name = rain[i].unique().tolist()\n    print(i, 'has', unique_no, 'unique variables, including:')\n    print(unique_name, \"\\n\")","6f691b6a":"# Summary of categorical data\nncols=3\nnrows= int(np.floor(len(cat_cols)\/ncols) + np.ceil(len(cat_cols)%ncols\/ncols))\nfig, axs = plt.subplots(nrows, ncols, figsize=(ncols*6, nrows*3))           \n                                                \nfor row in range(nrows):\n    for column in range(ncols):\n        try:\n            feature = cat_cols[row*ncols+column]\n            sns.countplot(y=feature, data=rain, ax=axs[row, column], color='#99befd')\n        except:\n            pass\nplt.tight_layout(pad=0.5)","9114ecf9":"rain.describe()","5a6fadaa":"# Plots on numerical features to check data quality and data distribution\n\nnum_cols=rain.select_dtypes(include=['int64','float64']).columns.tolist() # a revised list of numerical features  \n\nfor i in num_cols:\n   \n    fig, axs = plt.subplots(1,2,figsize=(15, 3))\n\n    sns.histplot(rain[i],bins=20, kde=True,ax=axs[0]);\n    sns.boxplot(rain[i], ax = axs[1], color='#99befd', fliersize=1);\n    \n    axs[0].axvline(rain[i].median(), color='r', linewidth=2, linestyle='--', label='Mean')\n    axs[0].legend()","0e97d86b":"fig, ax = plt.subplots(figsize=(12,8))\nmask = np.triu(np.ones_like(rain.corr(), dtype=np.bool))\nsns.heatmap(rain.corr(), annot=True, cmap=\"Blues\", mask=mask, linewidth=0.5)","f1c987b1":"cols_to_drop = ['Rainfall', 'Temp9am', 'Temp3pm', 'Pressure9am']\nrain.drop(cols_to_drop, axis=1, inplace=True)","d03ee21e":"fig, axs = plt.subplots(ncols=2, figsize=(10,4))\nrain['RainTomorrow'].value_counts().plot(kind='bar', ax=axs[0])\nrain['RainTomorrow'].value_counts().plot.pie(autopct='%1.1f%%', startangle = 90, ax=axs[1])","bd2f2c96":"#rain_by_location =rain.groupby('Location')['RainTomorrow'].count()\/rain['Location'].count()\nrain_by_location = pd.crosstab(index=rain['Location'], columns=rain['RainTomorrow'], values=rain['RainTomorrow'], aggfunc='count', margins=True)\nrain_by_location['% Yes'] = (rain_by_location['Yes']\/rain_by_location['All']).round(3)*100\n# rain_by_location.sort_values(by='% Yes', ascending=False)\nf, ax = plt.subplots(figsize=(15,10))\nrain_by_location['% Yes'].sort_values().plot(kind='barh', alpha=0.5)\nax.set_xlabel ('% raining days')\n\n# Label values \ny = rain_by_location['% Yes'].sort_values().values\nfor h, v in enumerate(y):\n    ax.text(v+0.5 , h-0.5 , round(float(v),1), color='blue')","80637f53":"fig, ax = plt.subplots()\nsns.scatterplot(x='MinTemp', y='MaxTemp', data=rain, hue='RainTomorrow', alpha=0.5, style='RainTomorrow')\nx = y = plt.xlim()\nplt.plot(x, y, linestyle='--', color='g', lw=2, scalex=False, scaley=False)\nplt.annotate('MaxTemp=MinTemp', xy=(30,30), xytext=(30,28), color='g')","a4e61c72":"# Adding a new feature 'TempDiff'\nrain['TempDiff'] = rain['MaxTemp'] - rain['MinTemp']\n\n# TempDiff distribution\nsns.histplot(x='TempDiff', data=rain, bins=20, alpha=0.5, label='All RainTomorrow data')\nrain[rain['RainTomorrow']=='Yes']['TempDiff'].plot.hist(bins=20, color='red', alpha=0.3, label='RainTomorrow = Yes')\nplt.legend()","8358576f":"# Draw scatter charts with different wind speed data\nwind_speed = ['WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm']\nwind_speed_combination = [i for i in combinations(wind_speed,2)]\nfig, axs = plt.subplots(1,3,figsize=(15, 4))\nfor i, ws in enumerate(wind_speed_combination):\n    sns.scatterplot(x=ws[0], y=ws[1], data=rain, hue='RainTomorrow', ax=axs[i], alpha=0.5)","40a53901":"# Relationship between humidity\/pressure and RainTomorrow\nfig, axs = plt.subplots(1,2,figsize=(15, 4))\nsns.scatterplot(x='Humidity9am', y='Humidity3pm', data=rain, hue='RainTomorrow', alpha=0.5, ax=axs[0])\nsns.scatterplot(x='Humidity9am', y='Pressure3pm', data=rain, hue='RainTomorrow', alpha=0.5, ax=axs[1])","8e41cdbb":"both_rain = rain.loc[(rain['RainToday']=='Yes') & (rain['RainTomorrow']=='Yes')]\nboth_not_rain =  rain.loc[(rain['RainToday']=='No') & (rain['RainTomorrow']=='No')]\ntoday_rain_tmr_not_rain = rain.loc[(rain['RainToday']=='Yes') & (rain['RainTomorrow']=='No')]\ntoday_not_rain_tmr_rain = rain.loc[(rain['RainToday']=='No') & (rain['RainTomorrow']=='Yes')]\nrain_tmr = rain.loc[rain['RainTomorrow']=='Yes']\n\nprint('both_days_rain:', both_rain['Date'].count())\nprint('both_days_not_rain:',  both_not_rain['Date'].count())\nprint('today_rain_tmr_not_rain:', today_rain_tmr_not_rain ['Date'].count())\nprint('today_not_rain_tmr_rain:', today_not_rain_tmr_rain ['Date'].count())\nprint('rain_tmr:', rain_tmr['Date'].count())","9f27d42b":"# Extract `Year` and 'Month' information from Date\nrain['Year'] = pd.DatetimeIndex(rain['Date']).year\nrain['Month'] = pd.DatetimeIndex(rain['Date']).month\n\nrain_month = pd.crosstab(index=rain['Month'], columns=rain['RainTomorrow'], margins=True)\nrain_month['%Yes'] = (rain_month['Yes'] \/ rain_month['All']).round(3)*100 \nrain_month.iloc[:-1,-1].plot(style='.-')\nplt.xlabel('Month')\nplt.ylabel('% Raining days')","98ad6894":"# Lists for Categorized and Numerical features\ncat_cols=rain.select_dtypes(object).columns.tolist()\nnum_cols=rain.select_dtypes(include=np.number).columns.tolist()","70aa6e03":"# Convert categorized values to numerical values\nle = LabelEncoder()\nrain[cat_cols] = rain[cat_cols].astype('str').apply(le.fit_transform)","c9445aed":"# Impute missing values for categorical features\nmode_values=rain[cat_cols].mode()\nrain[cat_cols] = rain[cat_cols].fillna(value=mode_values)\n\n# Impute missing values for numerical features\nmedian_values = rain[num_cols].median()\nrain[num_cols] = rain[num_cols].fillna(value=median_values)","7f4f6953":"# Check if there is any missing values\nrain.isnull().sum()","afcdebc9":"cols_to_keep =['Location', 'WindGustDir', 'WindGustSpeed', 'Humidity9am', 'Pressure3pm', 'RainToday','TempDiff', 'Month']\ntarget_col = ['RainTomorrow']","d1c7e3f1":"X = rain[cols_to_keep]\ny = rain[target_col]\n\n# Split train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)","a93eca0a":"# Select Classifiers and inistaniate models\n\n\nclfs = [  \n            ('RF', RandomForestClassifier()),\n            ('KNN', KNeighborsClassifier()),\n            ('GNB', GaussianNB())\n            ]  \n       \nresults = []\n\nfor name, clf in  clfs:\n\n    # Fitting models\n    clf.fit(X_train, y_train)  \n    # Predict target value     \n    y_pred = clf.predict(X_test)      \n    \n    # Calculate the accuracy of the model\n    score = clf.score(X_test, y_test).round(3)*100 \n    \n    # Calculate the precision score of the model\n    precision = precision_score(y_test, y_pred).round(3)*100\n    \n    # Calculate the recall score of the model\n    recall = recall_score(y_test, y_pred).round(3)*100\n    \n    # Calculate the F1 score of the model\n    f1 = f1_score(y_test, y_pred).round(3)*100\n    \n    # Calculaate the ROC_AUC score\n    try:\n        y_pred_prob = clf.predict_proba(X_test) [:,1]\n    except:\n        roc = 'N.A'        \n    else: \n        roc = roc_auc_score(y_test, y_pred_prob).round(3)*100 \n    results.append([name, score, precision, recall, f1, roc])\n    \nresults = pd.DataFrame(results, columns=['Model', 'Accuracy','Precision', 'Recall', 'F1', 'ROC_AUC'])\nresults.sort_values(by='Accuracy', ascending = False)","a3b5bbc6":"##### Comment\n- `MaxTemp` and `MinTemp` do not seem to directly impact the chance of raining tomorrow\n- However, when we draw a MaxTemp = MinTemp line, it seems that most of the 'Yes' result is falling close to this line \n- This implies that there is a higher chance to rain tomorrow if there is little variation between the max and min temperature\n- We will verify this by adding a new feature `TempDiff` to the dataset (`TempDiff` = `MaxTemp` - `MinTemp`)","a1fa2f47":"### What else?","07f3cccc":"#### Comment\n- It can be easily seen from the chart that when tempeature different is less than 5C, there is a higher chance of raining tomorrow. ","d1493e0f":"##### Comment\n- `WindGustSpeed` seems to be a more important factor than `WindSpeed9am` and `WindSpeed3pm`\n- There is a higher chance of raining tomorrow when `WindGustSpeed`is higher than 75","f5cd9524":"##### Comment\n- `Evaporation`, `Sunshine`, `Cloud9am`, `Cloud3pm` contain a lot of missing values (i.e 40-50% of the cell is empty) throughout the dataset.\n- Therefore we will drop `Evaporation`, `Sunshine`, `Cloud9am`, `Cloud3pm` from the dataset\n- The target variable `RainTomorrow` has two missing data, we will drop these two rows from the dataset\n- For other features, there is a small number of data missing, we will handle these missing values with an appropriate method later in the study","11660c65":"##### Comment\n- The data set has 23 columns, including 22 features and 1 target variable\n- The data contains both numerical and categorical features","0f643e15":"## Importing data","e71b57c7":"# Exploratory Data Analysis (EDA)\n### Target variable: `RainTomorrow`","97bf8307":"## Modelling","792a0c86":"#### A quick glance at `Numerical Features`","4f7b1644":"### Conclusion from EDA\nTo sum up, there is a higher chance of raining tomorrow when:\n- Little variation of temperature throughout the day\n- Humidity is high\n- Pressure is low\n- WindGustSpeed is high\n- Raining today\n- June, July and August","7b6103fd":"##### Comment\n- There are 16 numerical features, including:\n    - ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm'] \n\n- There are 6 categorical features, including:\n    - ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']","91a5fdd5":"##### Comment\n- The mean values for different features range from 10+ to 1000+, as these features are not in a similar scale, we may need to adjust features sizes later in the study\n- The `Rainfall` data seems to have a huge distortion, we will drop this feature for our analysis","34784d7a":"# Machine Learning\n## Data preprocessing\nWe need to:\n- Impute missing values \n    - For categorical values, I will replace missing values with the most frequent value of that feature column\n    - For numerical values, I will replace missing values with median values\n- Convert categorical values to numerical values\n    - I will use LabelEncoder to transform the data\n- Adjust features sizes\n    - I will use StandardScaler to transform numerical features","b24f63b9":"##### Comment\n- The target variable `RainTomorrow` returns two values, 'Yes' and 'No'\n- 78% of result is 'Yes' and 22% is 'No'\n- This is an example of imbalanced classification, as we have uneven distribution of classes in the training dataset. We will address this problem in the Machine Learning section","9514bc4e":"### Whether `MinTemp` and `MaxTemp` impact `RainTomorrow`?","dd7e2422":"##### Comment\n- Higher chance of raining tomorrow with higher humidity and lower pressure","857cfbf2":"### How about wind speed and direction? \n- There are 3 different numerical features (`WindGustSpeed`,`WindSpeed9am` and `WindSpeed3pm`) that are associated with wind speed.   \n- There are 3 categorized features (`WindGustDir`,`WindDir9am` and `WindDir3pm`) that are associated with wind direction.   \n- Can we draw any conclusion from these values?","cd5a31a6":"# Data Preparation\n## Loading libraries","e219a2a6":"### Data summary\n#### A quick glance at `Categorical Features`","34146249":"##### Comment\n- Portland, Walpole, Cairns are the top3 locations in terms of number of raining days\n- Woomera, Uluru, AliceSprings are the bottom 3 of the list, with less than 10% of raining days","15f696f3":"### Data quality","1cea2011":"##### Comment\n- There are 6 categorical features, with 2 to 49 unique names in each features. \n- We will need to convert these categorized values to numerical values later in the study","7abc5416":"### `Location`: Which city has the most raining days?","bdcc2eed":"## Data inspection\n\n### Data types","0ba4030b":"##### Comment\n- Several features have very strong correlation\n    - `MinTemp` ~ `Temp9am` (corr = 90%)\n    - `MaxTemp` ~ `Temp3pm` (corr = 98%)\n    - `Temp9am` ~ `Temp3pm` (corr = 86%)\n    - `Pressure3pm` ~ `Pressure9am` (corr = 96%)\n- We will drop:  `Temp9am `, `Temp3pm`, `Pressure9am`","51a9c995":"## Feature selection\nIn EDA section, we have studied the relationship between different features. We will drop features that do not impact the outcome and we will also add features that are relevent to the analysis\n- Features to use:\n    - `Location`, `WindGustDir`, `WindGustSpeed`, `Humidity9am`, `Pressure3pm`, `RainToday`,`TempDiff`, `Month`","2cf38d9d":"##### Comment\n- Higher chance of raining between June and August","7fb763a7":"##### Comment\n- There are 31877 'Yes' values within RainTomorrow, and 14597 values of both days rain (~46% of total Yes RainTomorrow)\n- This means that if today rains, there is a high chance that tomorrow will rain "}}