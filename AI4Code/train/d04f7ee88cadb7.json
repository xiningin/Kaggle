{"cell_type":{"d9f0c06f":"code","03f2df36":"code","4e562adc":"code","a41d01ba":"code","43c53544":"code","e4312af5":"code","0343dcdb":"code","49784c62":"code","a867dc3f":"code","fc1bc901":"code","bce3f9f1":"code","c342b73d":"code","4b9b6061":"code","7d489ec7":"code","036cfed7":"code","0bccb5ca":"code","dd0468c7":"code","b5c6f11e":"code","e0d1c045":"code","7ddb2d00":"code","6b222bf4":"code","bdee7b72":"code","9a12699f":"code","cb1dd161":"code","58895314":"code","27fa4461":"code","42824709":"code","485902d8":"code","1ca83443":"code","8e2852e8":"code","fb4de58d":"code","f83891f6":"code","2eda815f":"code","9bc98fa4":"code","37047d36":"code","1bb70a43":"code","1a609648":"code","87da292f":"code","d78851d8":"code","30b45d65":"code","9fd79f65":"code","0f38a527":"code","3fd74771":"code","1455c260":"code","c81ad8a9":"code","02142bc7":"code","5dab635d":"code","4584f7dc":"code","a507947f":"markdown","b6208181":"markdown","3d53fb18":"markdown","9aca407c":"markdown","2394529a":"markdown","3f5b4426":"markdown","bb0974d3":"markdown","40b94372":"markdown","5b7a081b":"markdown","9036fc0b":"markdown","570cfc6a":"markdown","dc812734":"markdown","a4e9c102":"markdown","6856822b":"markdown","e5733974":"markdown","c8bc50dd":"markdown","94c6bb86":"markdown","5f0eb879":"markdown","50a441cf":"markdown","c019e79b":"markdown","dbebc4dc":"markdown","86294c4a":"markdown","091cb07a":"markdown","4c62ee11":"markdown","30437979":"markdown","8cb54b5f":"markdown","4ea59750":"markdown","9724061a":"markdown","0a077f70":"markdown","25c53aad":"markdown","fa0ef007":"markdown","c2253843":"markdown","c449650c":"markdown","05f893f7":"markdown","a5901639":"markdown","1b4a5897":"markdown","b342ed58":"markdown","92b50279":"markdown","451e6b31":"markdown","a741db4a":"markdown","4c4a71ec":"markdown","cfe8f688":"markdown"},"source":{"d9f0c06f":"pip install pyecharts","03f2df36":"import pandas as pd\nimport numpy as np\n\nfrom pyecharts import options as opts\nfrom pyecharts.charts import Pie,Grid,Bar,Map,Sankey\nfrom pyecharts.commons.utils import JsCode\nfrom pyecharts.globals import ThemeType\nfrom collections import defaultdict\n\nfrom pyecharts.globals import CurrentConfig, NotebookType\nCurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_NOTEBOOK\npd.options.mode.chained_assignment = None","4e562adc":"df=pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\nprint(df.shape)\ndf.head()","a41d01ba":"df=df.iloc[1:,:]\ndf.head()","43c53544":"def single_pie(q,title):\n    cols=[x for x in df.columns if x.startswith('%s_'%q) or x==q]\n    choice={col:[i for i in set(df[col].dropna())][0] for col in cols}\n    if len(cols)==1:\n        df_draw=df[q].value_counts()\n    else:\n        idx=[]\n        df_draw=[]\n        for col in cols:\n            tmp=df[col].value_counts()\n            if len(tmp)==0:\n                df_draw.append(0)\n            else:\n                df_draw.append(tmp.iloc[0])\n            idx.append(choice[col])\n        df_draw=pd.Series(df_draw,index=idx).sort_values(ascending=False)\n\n    pie=(\n        Pie(init_opts=opts.InitOpts(width=\"1200px\", height=\"800px\"))\n        .add(\n            series_name=\"count\/ratio\",\n            radius=[\"40%\", \"55%\"],\n            data_pair=[list(z) for z in zip(df_draw.index,df_draw.iloc[:])],\n            rosetype=\"radius\",\n            label_opts=opts.LabelOpts(\n                position=\"outside\",\n                formatter=\"{a|{a}}{abg|}\\n{hr|}\\n {b|{b}: }{c}  {per|{d}%}  \",\n                background_color=\"#eee\",\n                border_color=\"#aaa\",\n                border_width=1,\n                border_radius=4,\n                rich={\n                    \"a\": {\"color\": \"#999\", \"lineHeight\": 22, \"align\": \"center\"},\n                    \"abg\": {\n                        \"backgroundColor\": \"#e3e3e3\",\n                        \"width\": \"100%\",\n                        \"align\": \"right\",\n                        \"height\": 22,\n                        \"borderRadius\": [4, 4, 0, 0],\n                    },\n                    \"hr\": {\n                        \"borderColor\": \"#aaa\",\n                        \"width\": \"100%\",\n                        \"borderWidth\": 0.5,\n                        \"height\": 0,\n                    },\n                    \"b\": {\"fontSize\": 16, \"lineHeight\": 33},\n                    \"per\": {\n                        \"color\": \"#eee\",\n                        \"backgroundColor\": \"#334455\",\n                        \"padding\": [2, 4],\n                        \"borderRadius\": 2,\n                    },\n                },\n            ),\n        )\n        .set_global_opts(legend_opts=opts.LegendOpts(pos_left=\"right\", orient=\"vertical\",type_='scroll'),title_opts=opts.TitleOpts(title=title))\n        .set_series_opts(\n            tooltip_opts=opts.TooltipOpts(\n                trigger=\"item\", formatter=\"{a} <br\/>{b}: {c} ({d}%)\"\n            )\n        )\n    )\n    return pie\n    \n\npie=single_pie('Q1','Age')\npie.render_notebook()","e4312af5":"def nested_pie(inner_feature,outer_feature):\n    df_new=df.groupby([inner_feature])[outer_feature].apply(lambda x:x.value_counts()).unstack()\n    df_new['total']=df_new.sum(axis=1)\n\n    inner_x_data=list(df_new.index)\n    inner_y_data=df_new['total']\n    inner_data_pair = [list(z) for z in zip(inner_x_data, inner_y_data)]\n\n    df_new=df_new.drop('total',axis=1)\n    outer_x_data=list(df_new.columns)*len(df_new.index)\n    data_tmp=np.array(df_new).flatten()\n    data_tmp[np.isnan(data_tmp)]=0.\n    outer_y_data=data_tmp.tolist()\n    outer_data_pair = [list(z) for z in zip(outer_x_data, outer_y_data)]\n\n    pie=(\n        Pie(init_opts=opts.InitOpts(width=\"1600px\", height=\"1000px\"))\n        .add(\n            series_name=\"count\/ratio\",\n            data_pair=inner_data_pair,\n            radius=[0, \"30%\"],\n            label_opts=opts.LabelOpts(position=\"inner\"),\n        )\n        .add(\n            series_name=\"count\/ratio\",\n            radius=[\"40%\", \"55%\"],\n            data_pair=outer_data_pair,\n            label_opts=opts.LabelOpts(\n                position=\"outside\",\n                formatter=\"{a|{a}}{abg|}\\n{hr|}\\n {b|{b}: }{c}  {per|{d}%}  \",\n                background_color=\"#eee\",\n                border_color=\"#aaa\",\n                border_width=1,\n                border_radius=4,\n                rich={\n                    \"a\": {\"color\": \"#999\", \"lineHeight\": 22, \"align\": \"center\"},\n                    \"abg\": {\n                        \"backgroundColor\": \"#e3e3e3\",\n                        \"width\": \"100%\",\n                        \"align\": \"right\",\n                        \"height\": 22,\n                        \"borderRadius\": [4, 4, 0, 0],\n                    },\n                    \"hr\": {\n                        \"borderColor\": \"#aaa\",\n                        \"width\": \"100%\",\n                        \"borderWidth\": 0.5,\n                        \"height\": 0,\n                    },\n                    \"b\": {\"fontSize\": 16, \"lineHeight\": 33},\n                    \"per\": {\n                        \"color\": \"#eee\",\n                        \"backgroundColor\": \"#334455\",\n                        \"padding\": [2, 4],\n                        \"borderRadius\": 2,\n                    },\n                },\n            ),\n        )\n        .set_global_opts(legend_opts=opts.LegendOpts(pos_left=\"left\", orient=\"vertical\"))\n        .set_series_opts(\n            tooltip_opts=opts.TooltipOpts(\n                trigger=\"item\", formatter=\"{a} <br\/>{b}: {c} ({d}%)\"\n            )\n        )\n    )\n    return pie","0343dcdb":"pie=nested_pie('Q2','Q1')\npie.render_notebook()","49784c62":"def draw_country():\n    df_new=df['Q3'].value_counts().sort_values(ascending=False)\n    countries=pd.Series(df_new.index)\n    countries=countries.replace('United States of America','United States')\n    \n    map = (\n        Map()\n        .add(\"Number of interviewee\", [list(z) for z in zip(countries, df_new.iloc[:])], \"world\")\n        .set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n        .set_global_opts(\n            title_opts=opts.TitleOpts(title=\"Interviewee over the World\"),\n            visualmap_opts=opts.VisualMapOpts(max_=2000),\n        )\n    )\n    return map","a867dc3f":"pie=single_pie('Q3','Country')\npie.render_notebook()","fc1bc901":"map=draw_country()\nmap.render_notebook()","bce3f9f1":"def get_SankeyData(questions):\n    cols_all=[]\n    multi_choice=[]\n    for q in questions:\n        col_tmp=[x for x in df.columns if x.startswith('%s_'%q) or x==q]\n        if len(col_tmp)>1:\n            multi_choice.extend(col_tmp)\n        cols_all.extend(col_tmp)\n    df_new=df[cols_all]\n    cols=list(df_new.columns)\n\n    replace_choices=['NoAnwser','None','Other']\n    nodes=[]\n    name_set=set()\n    surfix=defaultdict(int)\n    for i in range(len(cols)):\n        values=df_new[cols[i]].unique()\n        for value in values:\n            if not pd.isnull(value):\n                if value in name_set:\n                    nodes.append({'name':'%s_%d'%(value,surfix[value])})\n                    df_new[cols[i]]=df_new[cols[i]].replace(value,'%s_%d'%(value,surfix[value]))\n                    surfix[value]+=1\n                else:\n                    nodes.append({'name':value})\n                    name_set.add(value)\n\n    df_new['count']=1\n    new_cols=['source','target','value']\n    groups=[]\n    for i in range(1,len(cols)):\n        if cols[i-1] not in multi_choice:\n            pre_choice=cols[i-1]\n        if cols[i] not in multi_choice:\n            j=i-1\n            if cols[j] in multi_choice:\n                while j>=0 and cols[j] in multi_choice:\n                    df_tmp=df_new.groupby([cols[j],cols[i]])['count'].sum().reset_index()\n                    df_tmp.columns=new_cols\n                    groups.append(df_tmp)\n                    j-=1\n            else:\n                df_tmp=df_new.groupby([cols[j],cols[i]])['count'].sum().reset_index()\n                df_tmp.columns=new_cols\n                groups.append(df_tmp)\n        else:\t\n            df_tmp=df_new.groupby([pre_choice,cols[i]])['count'].sum().reset_index()\n            df_tmp.columns=new_cols\n            groups.append(df_tmp)\n        df_tmp.columns=new_cols\n        groups.append(df_tmp)\n    df_concat=pd.concat(groups)\n\n    links=[]\n    for item in df_concat.values:\n        links.append({k:v for k,v in zip(new_cols,item) if not(pd.isnull(item[0]) or pd.isnull(item[1]))})\n    return nodes,links\n\ndef draw_Sankey(cols,title=''):\n    nodes,links=get_SankeyData(cols)\n    sankey=(\n        Sankey(init_opts=opts.InitOpts(width=\"1200px\", height=\"800px\"))\n        .add('',\n            nodes,\n            links,\n            linestyle_opt=opts.LineStyleOpts(opacity=0.3,curve=0.5,color='source'),\n            label_opts=opts.LabelOpts(position='right'),\n            #node_gap=30\n        )\n        .set_global_opts(title_opts=opts.TitleOpts(title=title))\n    )\n    return sankey","c342b73d":"pie=single_pie('Q5','Identity')\npie.render_notebook()","4b9b6061":"q=['Q4','Q5','Q6']\ns=draw_Sankey(q)\ns.render_notebook()","7d489ec7":"def draw_groupby(by,feature):\n    cols=[x for x in df.columns if x.startswith('%s_'%feature) or x==feature]\n    choice={col:[i for i in set(df[col].dropna())][0] for col in cols}\n\n    if len(cols)>1:\n        df_group=list(df.groupby(by))\n        n_group=len(df_group)\n        idx=[df_group[i][0] for i in range(n_group)]\n        dic_all=defaultdict(list)\n        for i in range(n_group):\n            df_tmp=df_group[i][1]\n            for col in cols:\n                tmp=df_tmp[col].value_counts()\n                if len(tmp)==0:\n                    dic_all[choice[col]].append(0)\n                else:\n                    dic_all[tmp.index[0]].append(tmp.iloc[0])\n        df_new=pd.DataFrame(dic_all,index=idx)\n    else:\n        df_new=df.groupby(by)[cols[0]].apply(lambda x:x.value_counts().sort_values(ascending=False)).unstack()\n\n    df_new['total']=df_new.sum(axis=1)\n    df_new=df_new.sort_values(by=['total'],ascending=True)\n    #print(df_new)\n\n    df_ratio=df_new.apply(lambda x:x\/x['total'],axis=1)\n\n    cols=df_new.columns[:-1]\n    rows=df_new.index\n\n    draw_lists=[]\n    for col in cols:\n        percents=df_new[col]\/df_new['total']\n        tmp=[{'value':v,'percent':p} for v,p in zip(df_new[col],percents)]\n        #print(tmp)\n        draw_lists.append(tmp)\n\n    bar1=(\n        Bar()\n        .add_xaxis(list(rows))\n        .add_yaxis(\"\",list(df_new['total']),category_gap=\"50%\")\n        .set_series_opts(\n            label_opts=opts.LabelOpts(\n            position=\"right\",\n            # formatter=JsCode(\n            #     \"function(x){return Number(x.data* 100).toFixed() + '%';}\"\n            # ),\n        )\n    )\n        .reversal_axis()\n    )\n\n    bar2=Bar().add_xaxis(list(rows))\n    for col in cols:\n        bar2.add_yaxis(col,[x*100 for x in df_ratio[col]],stack='stack1',category_gap=\"50%\")\n    bar2.set_series_opts(\n        label_opts=opts.LabelOpts(\n            position=\"bottom\",\n            formatter=JsCode(\n                \"function(x){return Number(x.data).toFixed() + '%';}\"\n            ),\n        )\n    )\n    bar2.set_global_opts(\n        xaxis_opts=opts.AxisOpts(\n            type_=\"value\",\n            min_=0,\n            max_=100,\n            axistick_opts=opts.AxisTickOpts(is_show=True),\n            splitline_opts=opts.SplitLineOpts(is_show=True),\n        ),\n    )\n    bar2.reversal_axis()\n\n    grid = (\n        Grid(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\"))\n        .add(bar1, grid_opts=opts.GridOpts(pos_right=\"55%\"))\n        .add(bar2, grid_opts=opts.GridOpts(pos_left=\"55%\"))\n    )\n    return grid","036cfed7":"g=draw_groupby('Q8','Q7')\ng.render_notebook()","0bccb5ca":"p=single_pie('Q9','IDE')\np.render_notebook()","dd0468c7":"g=draw_groupby('Q5','Q10')\ng.render_notebook()","b5c6f11e":"q=['Q11','Q12','Q13']\ns=draw_Sankey(q)\ns.render_notebook()","e0d1c045":"g=draw_groupby('Q5','Q14')\ng.render_notebook()","7ddb2d00":"q=['Q15','Q5','Q16']\ns=draw_Sankey(q)\ns.render_notebook()","6b222bf4":"p=single_pie('Q17','Machine learning methods')\np.render_notebook()","bdee7b72":"q=['Q5','Q18']\ns=draw_Sankey(q)\ns.render_notebook()","9a12699f":"q=['Q5','Q19']\ns=draw_Sankey(q)\ns.render_notebook()","cb1dd161":"q=['Q20','Q21','Q22','Q23','Q26']\ns=draw_Sankey(q)\ns.render_notebook()","58895314":"p=single_pie('Q24','Important work')\np.render_notebook()","27fa4461":"g=draw_groupby('Q25','Q20')\ng.render_notebook()","42824709":"g=draw_groupby('Q5','Q27_A')\ng.render_notebook()","485902d8":"p=single_pie('Q28','Enjoyable cloud platforms ')\np.render_notebook()","1ca83443":"p=single_pie('Q27_B','Cloud platform want to learn')\np.render_notebook()","8e2852e8":"q=['Q5','Q29_A']\ns=draw_Sankey(q)\ns.render_notebook()","fb4de58d":"p=single_pie('Q29_B','Cloud computing products want to learn')\np.render_notebook()","f83891f6":"g=draw_groupby('Q20','Q30_A')\ng.render_notebook()","2eda815f":"g=draw_groupby('Q15','Q31_A')\ng.render_notebook()","9bc98fa4":"p=single_pie('Q31_B','Managerd machine learning products want to learn')\np.render_notebook()","37047d36":"g=draw_groupby('Q5','Q33')\ng.render_notebook()","1bb70a43":"p=single_pie('Q32_B','Big data products want to learn')\np.render_notebook()","1a609648":"g=draw_groupby('Q5','Q35')\ng.render_notebook()","87da292f":"p=single_pie('Q34_B','Business intelligence tools want to learn')\np.render_notebook()","d78851d8":"p=single_pie('Q36_A','Usage of AutoML tools')\np.render_notebook()","30b45d65":"p=single_pie('Q36_B','Auto machine learning tools want to learn')\np.render_notebook()","9fd79f65":"p=single_pie('Q37_A','Usage of AutoML tools on a regular basis')\np.render_notebook()","0f38a527":"p=single_pie('Q37_B','Auto machine learning products want to learn')\np.render_notebook()","3fd74771":"p=single_pie('Q38_A','Tools to help manage machine learning experiments')\np.render_notebook()","1455c260":"p=single_pie('Q38_B','Tools for managing ML experiments want to learn')\np.render_notebook()","c81ad8a9":"p=single_pie('Q39','Platform to share data analysis or machine learning applications')\np.render_notebook()","02142bc7":"p=single_pie('Q40','Data science courses platforms ')\np.render_notebook()","5dab635d":"g=draw_groupby('Q5','Q41')\ng.render_notebook()","4584f7dc":"p=single_pie('Q42','Favorite media sources')\np.render_notebook()","a507947f":"**Many respondents share their data analysis or ML apllications on Github, Kaggle, colab, bolg, etc.**","b6208181":"**More than half of the interviewees are 18-29 years old.**","3d53fb18":"**About a 1\/4 of respondents use Jupyter Notebook as their IDE, followed by VSCode and PyCharm.**","9aca407c":"**Many people also do not use AutoML tools on a regular basis, while some may use Google Cloud AutoML, Azure Automated Machine Learning, Amazon Safemaker Auropilot, etc, they also attract many respondents to learn.**","2394529a":"# **About machine learning methods**","3f5b4426":"# **About media**","bb0974d3":"**Popular CV tools and NLP methods are also frequently used by people with different identities.**","40b94372":"# **About personal information**","5b7a081b":"**Fewer people use business intelligence tools, Microsoft Power BI and Tableau are most popular, many interviewees also want to be more familiar with them.**","9036fc0b":"**The results are saved as csv file, the rows are answers from a interviewee and columns are different questions, some of which are single choice questions and the other are multiple choice questions.**","570cfc6a":"**Many people do not use managed machine learning products, and people with more machine learning expericence may use more. Amazon SageMaker, Azure Machine Learning Stuidio, Google Cloud Vertex AI and Databricks are more popular, they also attract many people to learn.**","dc812734":"**For big data products, people with different identities may have different tendency. For example, statistician may use MySQL more and Database Engineer may use Microsoft SQL Server more. MySQL becomes products that most people want to learn with no doubt, and MongoDB is the second popular although it may not be used as much as other products such as Microsoft SQL Server.**","a4e9c102":"**Data scientist is also the main force of cloud computing products, including  Amazon Elastic Compute Cloud, Google Cloud Compute Engine and Microsoft Azure Virtual Machines. Many respondents also want to learn these 3 products.**","6856822b":"**For notebook, Kaggle Notebooks and Colab Notebooks are mostly used, while there are about 1\/5 of respondents do not use notebooks.**","e5733974":"**The left bar chart shows the programming language recommended by respondents, most of them surggest to learn python first. The left bar chart shows the languages respondents used, it's interesting to see python is most frequently used by people recommending different languages, while the second frequently used language is what they recommended. Obviously, python, R, SQL are most popular.**","c8bc50dd":"**Most interviewees are men, accounting for about 80%, while women accout for about 20%. Among male respondents, the most frequent age group is 25-29, while it is 18-21 for female respondents.**","94c6bb86":"**Most respondents use a laptop or PC\/desktop as their computing platform, and many of them do not use GPUs or TPUs. There are also many people who use NVIDIA GPUs or Google Cloud TPUs, many people alse have experience of using TPUs.**","5f0eb879":"**For cloud computing platforms, data scientists use them more often, and Amazon Web Services, Google Cloud Platform and Microsoft Azure are the most popular platforms, they are also platforms most people want to learn. Also, there are many people think all the platforms have similarly enjoyable expericence.**","50a441cf":"**Most interviewees come from India, accounting for more than 25%, followed by more than 2600 respondents from the United States.**","c019e79b":"# **About industry and company**","dbebc4dc":"**Industries of Computers\/Technology use data storage products more, among which Amazon Simple Storage Service and Google Cloud Storage are more popular.**","86294c4a":"**More than half of the interviewees have a Master's degree or Bachelor's degree, which are mainly contributed by students and data scientists. Doctoral degree is mainly contributed by research scientist. Comparing to other interviewees, most students may have less programming experience (<3 years). Data scientists contribute most to respondents with 5-10 years coding experience, while software engineers contriute most to these with more than 20 years coding experience.**","091cb07a":"**Most respodnets use machine learning method for 1-3 years, students and data scientists are likely to frameworks of Sklearn, Tensorflow, Keras, PyTorch and Xgboost, while other people may use diversified machine learning frameworks.**","4c62ee11":"# **About data and ML products**","30437979":"# **Introduction**\n**The 2021 Kaggle DS & ML Survey received 25,973 usable responses from participants in 171 different countries and territories, and the survey covers topics including programming tools, machine learning usage, cloud platform, big data products and so on. Based on the results, We can have a general understanding of the current data science and machine learning environment.**","8cb54b5f":"**For most interviewees are sutdents, the yearly compensation is concentrated on 0-999. People who works on Computer\/Technology accout most in different compensation ranges, and contributes more in higher compensation ranges.**","4ea59750":"**First, install the visulization package \"pyecharts\", then load necessary packages**","9724061a":"**For tools to analyze data, Business Analyst, Project Manager and Product Manager may use basic statistical software more, while Data Scientist, Research Scientist and ML Engineer may use local development environments more.**","0a077f70":"**Current popular machine learning methods are all frequently used by interviewees, including LR, decision tree, random forests, GBM, CNN, DNN...**","25c53aad":"**More than 1\/4 of respondents are students, followed by data scientists and software engineer.**","fa0ef007":"**I just skip the first row which describes the detailed questions.**","c2253843":"**Most people do not use tools to help manage machine learning experiments, while some people may use Tensorboard, MLflow, etc. And many respondents may be not interesting in tools for ML experiment, indicating many people do not pay much attention to the learning process in deep learning. So it remains great potential for these tools.**","c449650c":"**For visulization libraries, most respondents use Matplotlib, Seaborn and Plotly, while statisticians may use ggplot more often.**","05f893f7":"**Most people learn data science courses on Coursera, Kaggle, Udemy, etc. People learn courses in university only accounts for less than 10%.**","a5901639":"**For media sources that report on data science topics, Kaggle become most popular, followed by YouTube, Blogs, Twitter, etc.**","1b4a5897":"**For most respondents, works related to data and meachine learning methods play important roles in the their daily works.**","b342ed58":"# Conclusion\n\n**From above results, we can conclude that:**\n* Most interviewees are 18-29 years old, the ratio of male to female is about 1:4, many respondents are from India and the United States, students contributes most to total respondents, most respondents have a high degree.\n* Python is the most popular programming language and Jupyter Notebook is the most frequently used notebook. There are many respondents who do not use GPU or TPU.\n* Popular methods and tools for visulization, machine learning , CV or NLP are widely used by Kagglers.\n* Respondents come from different industries, companies with more employes are likely to spend more on machine learning.\n* Many respondents are not familiar with cloud computing platforms or big data products, for many of them are students.\n* Auto machine learning methods and tools are not widely used currently among respondents\uff0cso the autoML tools still have great potential and prospects.\n\n**Thanks for your read, this is my first notebook on Kaggle, there may be many problems in it. Any comments and suggestions are welcome.**","92b50279":"# **About programming environments**","451e6b31":"# **About cloud platforms**","a741db4a":"**Repondents from industries of Computers\/Technology and Academics\/Education are more than other industries. Companies with more than 1000 employees are more likely to have more poeple responsible for data science, and they may have well established ML methods, they also pay more on machine learning or cloud computing services.**","4c4a71ec":"**More than half of the interviewees do not use auto machine learning tools, some people may use popular AutoML tools such as auto-sklearn, hyperopt, tpot, etc. But many people are interesting in various autoML tools and willing to learn them.**","cfe8f688":"# **About Auto Machine Learning**"}}