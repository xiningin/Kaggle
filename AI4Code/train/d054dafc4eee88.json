{"cell_type":{"a083c301":"code","fdded597":"code","783fc420":"code","c9ea1672":"code","138f077c":"code","4a92e0a4":"code","590b05e4":"code","f437114b":"code","cae106fe":"code","b3fe3b0b":"code","038cb2dc":"code","483a570a":"code","7a64f804":"code","a17ee16b":"code","d8b48d95":"code","cfc98030":"code","68b93053":"code","0bb8fa36":"code","75b36658":"code","ba5f2d76":"code","f6234248":"code","de9397b8":"code","43664783":"code","78b05971":"code","8d56c972":"code","1529c19a":"code","8bdff8e6":"code","6899be43":"code","20e9fc53":"code","32d6c57e":"code","0d97d9a8":"code","a484f186":"code","e13fc604":"code","6c10591a":"code","65393dee":"code","38d36a15":"code","58dc5293":"code","cd46bb52":"code","cac7dd21":"code","bbd14ad7":"code","2d964e38":"code","efd7c4c8":"code","68ffc8f0":"code","dabc0843":"code","48a15980":"code","9aced402":"code","0050e4ea":"code","9be00e16":"code","0ec3455d":"code","1592e52a":"code","ffc80964":"code","c2dbfff9":"code","b2104fed":"code","62084ee0":"code","0d9b5dfa":"code","e80c7c22":"code","627d219c":"code","6d24f740":"code","92ec01ef":"code","11dbd8b1":"code","aafc5053":"code","e915b9f3":"code","005ed6b2":"code","c709dfd0":"code","9832e061":"code","46f0ccb7":"code","6910b6f9":"code","02918525":"code","4b7bfed3":"code","f1116d5d":"code","7620e630":"code","a87dc236":"code","0d2e3063":"code","2d0ad5f9":"code","641d358b":"code","8d00a9b3":"code","1c02ae29":"code","f778e420":"code","a53a3eac":"code","a145219b":"code","a89dad9d":"code","3f2c538e":"markdown","d4d93a9d":"markdown","bebb61cf":"markdown","32feabe5":"markdown","8f873196":"markdown","775c7355":"markdown","087c8096":"markdown","3c093c34":"markdown","5387defd":"markdown","95394bdd":"markdown","f27ace64":"markdown","bdbf57db":"markdown","27c2a061":"markdown","d02c5b75":"markdown","73e6be2b":"markdown","388cb62a":"markdown","40c81666":"markdown","ad211c89":"markdown","c4f6fdcd":"markdown","abebda2d":"markdown","f11021da":"markdown","9bee5782":"markdown","0af2e690":"markdown","3aed0994":"markdown","448dbef6":"markdown","f76741a7":"markdown","f3172dc5":"markdown","4ced8d56":"markdown","c49d6a5a":"markdown","7a8ce06c":"markdown","acb2d5fd":"markdown","e6c8f709":"markdown","f27dee28":"markdown","594b1261":"markdown","5c2e8eee":"markdown","f5c0c590":"markdown","64016af9":"markdown","2da1f012":"markdown"},"source":{"a083c301":"pip install missingno","fdded597":"# Importing required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt # visualization\nimport seaborn as sns # visualization\nimport missingno as msno # visualization\nfrom collections import Counter\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","783fc420":"import os\nprint(os.listdir(\"..\/input\"))","c9ea1672":"# read data \ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\ntest = pd.read_csv(\"..\/input\/titanic\/train.csv\")","138f077c":"# contact the two datasets\ndataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","4a92e0a4":"# shap of the data set \ntrain.shape","590b05e4":"# To display the top 5 rows\ntrain.head()","f437114b":"train.info()","cae106fe":"# To get quick information of data set\ntrain.describe()","b3fe3b0b":"def find_missing_data(data):\n    Total = data.isnull().sum().sort_values(ascending = False)\n    Percentage = (data.isnull().sum()\/data.isnull().count()).sort_values(ascending = False)\n    return pd.concat([Total,Percentage] , axis=1 , keys = ['Total' , 'Percent'])","038cb2dc":"#Visualize missing data\nmsno.matrix(train)","483a570a":"# finding misssing data in train data\nfind_missing_data(train)","7a64f804":"# finding misssing data in test data\nfind_missing_data(test)","a17ee16b":"# look at numeric and categorical values separately \ndf_num = train[['Age','SibSp','Parch','Fare']]\ndf_cat = train[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","d8b48d95":"#distributions for all numeric variables \n# Using histogram\nfor i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","cfc98030":"# plotting Age to get a closer at the distribution\nplt.hist(train['Age'], bins = 10)","68b93053":"# Age for different passenger classes\nclassAge = train.filter(['Age','Pclass'], axis=1)","0bb8fa36":"classAge_1 = classAge['Pclass'].eq(1) +  classAge ['Age']\nclassAge_1\nplt.hist(classAge_1, bins = 10)","75b36658":"classAge_2 = classAge['Pclass'].eq(2) +  classAge ['Age']\nplt.hist(classAge_2, bins = 10)","ba5f2d76":"classAge_3 = classAge['Pclass'].eq(3) +  classAge ['Age']\nplt.hist(classAge_3, bins = 10)","f6234248":"# obivosly it is  right-skrewed distribution\n#for age and the median should a good choice for substitution.","de9397b8":"# Median for Age seperated by Pclass and sex:\ntrain.groupby(['Pclass','Sex'])['Age'].median()","43664783":"train.groupby(['Pclass','Sex'])['Age'].count()","78b05971":"# Replace the missing values with the medians of each group\ndataset['Age'] = dataset.groupby(['Pclass', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))","8d56c972":"dataset.isnull().sum()","1529c19a":"Sib_Sur = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train,\n                   kind=\"bar\", size = 6 , palette = \"Blues\")\n\nSib_Sur.despine(left=True)\nSib_Sur = Sib_Sur.set_ylabels(\"survival probability\")","8bdff8e6":"Sur_Par = sns.factorplot(x=\"Parch\",y=\"Survived\",data=train, \n                         kind=\"bar\", size = 6 , palette = \"GnBu_d\")\n\nSur_Par.despine(left=True)\nSur_Par = Sur_Par.set_ylabels(\"survival probability\")","6899be43":"# We have just one missing value\ndataset.loc[dataset['Fare'].isnull()]","20e9fc53":"# We will replace it with the median value\ndataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())","32d6c57e":"dataset.isnull().sum()","0d97d9a8":"dataset[\"Cabin\"].isnull().sum()","a484f186":"dataset[\"Cabin\"].unique()","e13fc604":"dataset[\"Cabin\"].count()","6c10591a":"# There are a lot of missing values but \n# we should use the cabin variable because\n# it can be an important predictor.","65393dee":"# Keep all first letters of cabin in new variable and replace \n# the null values with 'N' \ndataset['level'] = dataset['Cabin'].apply(lambda x: x[0] if pd.notnull(x) else 0)","38d36a15":"dataset[['level', 'Survived']].groupby('level')['Survived'].mean().plot(kind='bar',figsize=(15,7))\nplt.title('survival rates for different cabiens')","58dc5293":"pd.pivot_table(dataset,index='Survived',columns='level', values = 'Name', aggfunc='count')","cd46bb52":"dataset['level'] = dataset['level'].replace(['A', 'B', 'C'], 'ABC')\ndataset['level'] = dataset['level'].replace(['D', 'E'], 'DE')\ndataset['level'] = dataset['level'].replace(['F', 'G'], 'FG')\n\ndataset['level'].value_counts()","cac7dd21":"dataset['level'] = dataset['level'].replace('ABC', 1)\ndataset['level'] = dataset['level'].replace('DE', 2)\ndataset['level'] = dataset['level'].replace('FG', 3)\ndataset['level'] = dataset['level'].replace('T', 4)","bbd14ad7":"dataset.drop(labels = ['Cabin'], axis = 1, \n             inplace = True)","2d964e38":"dataset.loc[dataset[\"Embarked\"].isnull()]","efd7c4c8":"dataset.loc[dataset['Embarked'].isnull(), 'Embarked'] = 'S'","68ffc8f0":"dataset.isnull().sum()","dabc0843":"dataset[\"Embarked\"].unique()","48a15980":"# We are going to encode the Embarked data so the model can deal with it\ndataset[\"Embarked\"] = dataset[\"Embarked\"].replace('S', 1)\ndataset[\"Embarked\"] = dataset[\"Embarked\"].replace('C', 2)\ndataset[\"Embarked\"] = dataset[\"Embarked\"].replace('Q', 3)","9aced402":"# Explore data in sex feature\ndataset['Sex'].head()","0050e4ea":"dataset['Sex'].tail()","9be00e16":"# We need to encode this values to categorical values so the model can understand\n# male = 0, Female = 1\ndataset['sex'] = pd.get_dummies(dataset['Sex'], drop_first= True)\ndataset = pd.concat([dataset,dataset['sex']], axis=1)\n# We drop the sex feature \ndataset.drop(['Sex'] , axis = 1 , inplace = True)","0ec3455d":"#let's see how data looks like now\ndataset.head()","1592e52a":"dataset['Name'].head()","ffc80964":"# We are just interested in titles NOT all name\n# Get Title from name\ndataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\n\n# Add dataset_title to the main dataset \ndataset[\"Title\"] = pd.Series(dataset_title)","c2dbfff9":"# Now let's look at the new title column & count the number of each title\ndataset[\"Title\"].value_counts()","b2104fed":"dataset[['Title', 'Survived']].groupby('Title')['Survived'].mean().plot(kind='bar',figsize=(15,7))","62084ee0":"plt.figure(figsize=(20,6))\nsns.barplot(x=dataset['Title'], y = dataset['Age'])","0d9b5dfa":"dataset['Title'].nunique()","e80c7c22":"dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess',\n                                             'Capt', 'Col','Don', 'Dr', \n                                             'Major', 'Rev', 'Sir', 'Jonkheer',\n                                             'Dona'], 'Rare')\ndataset[\"Title\"]","627d219c":"# Again, 0 for male and 1 for female :)\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 ,\n                                         \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \n                                         \"Rare\":3})\ndataset[\"Title\"]","6d24f740":"dataset[\"Title\"] = dataset[\"Title\"].astype(int)\n\n# Drop Name variable\ndataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","92ec01ef":"sns.countplot(dataset[\"Title\"]).set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"]);","11dbd8b1":"# Let's see, based on title what's the survival probability\nsns.barplot(x='Title', y='Survived', data=dataset);","aafc5053":"dataset","e915b9f3":"dataset['Ticket_Frequency'] = dataset.groupby('Ticket')['Ticket'].transform('count')\ndataset['Ticket_Frequency']","005ed6b2":"dataset[['Ticket_Frequency', 'Survived']].groupby('Ticket_Frequency').mean()","c709dfd0":"dataset.drop(labels = [\"Ticket\"], axis = 1, inplace = True)","9832e061":"dataset","46f0ccb7":"# using countplot to estimate amount\nsns.countplot(data = train , x = 'Survived' , hue = 'Sex', palette = 'GnBu_d')","6910b6f9":"train[['Sex','Survived']].groupby('Sex').mean()","02918525":"pd.pivot_table(train, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])","4b7bfed3":"for i in df_cat.columns:\n    sns.barplot(df_cat[i].value_counts().index,df_cat[i].value_counts()).set_title(i)\n    plt.show()","f1116d5d":"# Pclass\nprint(pd.pivot_table(train, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))","7620e630":"# Sex\nprint(pd.pivot_table(train, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))","a87dc236":"# Embarked\nprint(pd.pivot_table(train, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))","0d2e3063":"# # Outlier detection \n# def detect_outliers(df,n,features):\n#     \"\"\"\n#     Takes a dataframe df of features and returns a list of the indices\n#     corresponding to the observations containing more than n outliers according\n#     to the Tukey method.\n#     \"\"\"\n#     outlier_indices = []\n    \n#     # iterate over features(columns)\n#     for col in features:\n        \n#         # 1st quartile (25%)\n#         Q1 = np.percentile(df[col], 25)\n        \n#         # 3rd quartile (75%)\n#         Q3 = np.percentile(df[col],75)\n        \n#         # Interquartile range (IQR)\n#         IQR = Q3 - Q1\n        \n#         # outlier step\n#         outlier_step = 1.5 * IQR\n        \n#         # Determine a list of indices of outliers for feature col\n#         outlier_list_col = df[(df[col] < Q1 - outlier_step) | \n#                               (df[col] > Q3 + outlier_step )].index\n#         # append the found outlier indices for col to the list of outlier indices \n#         outlier_indices.extend(outlier_list_col)\n   \n        \n#     # select observations containing more than 2 outliers\n#     outlier_indices = Counter(outlier_indices)  \n\n#     multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n#     return multiple_outliers   \n\n# # detect outliers from Age, SibSp , Parch and Fare\n# Outliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","2d0ad5f9":"# Show the outliers rows\n# train.loc[Outliers_to_drop]","641d358b":"# # Drop outliers\n# train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n# # after removing outlier, let's re-concat the data sets\n# dataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","8d00a9b3":"dataset","1c02ae29":"train = dataset[: len(train)]\ntest = dataset[len(train):]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace = True)","f778e420":"## Separate train features and label \nY_train = train[\"Survived\"].astype(int)\nX_train = train.drop(labels = [\"Survived\"],axis = 1)\n\n# Cross validate model with Kfold stratified cross val\nK_fold = StratifiedKFold(n_splits=10)","a53a3eac":"# Modeling step Test differents algorithms \nrandom_state = 2\n\nmodels = [] # append all models or predictive models \ncv_results = [] # cross validation result\ncv_means = [] # cross validation mean value\ncv_std = [] # cross validation standard deviation\n\nmodels.append(KNeighborsClassifier())\nmodels.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nmodels.append(DecisionTreeClassifier(random_state=random_state))\nmodels.append(RandomForestClassifier(random_state=random_state))\nmodels.append(ExtraTreesClassifier(random_state=random_state))\nmodels.append(SVC(random_state=random_state))\nmodels.append(GradientBoostingClassifier(random_state=random_state))\nmodels.append(LogisticRegression(random_state = random_state))\nmodels.append(LinearDiscriminantAnalysis())\nmodels.append(MLPClassifier(random_state=random_state))\n\n\nfor model in models :\n    cv_results.append(cross_val_score(model, X_train, Y_train, \n                                      scoring = \"accuracy\", cv = K_fold, n_jobs=4))\n\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_frame = pd.DataFrame(\n    {\n        \"CrossValMeans\":cv_means,\n        \"CrossValErrors\": cv_std,\n        \"Algorithms\":[\n                     \"KNeighboors\",\n                     \"AdaBoost\", \n                     \"DecisionTree\",   \n                     \"RandomForest\",\n                     \"ExtraTrees\",\n                     \"SVC\",\n                     \"GradientBoosting\",                      \n                     \"LogisticRegression\",\n                     \"LinearDiscriminantAnalysis\",\n                     \"MultipleLayerPerceptron\"]\n    })\n\ncv_plot = sns.barplot(\"CrossValMeans\",\"Algorithms\", data = cv_frame,\n                palette=\"husl\", orient = \"h\", **{'xerr':cv_std})\n\ncv_plot.set_xlabel(\"Mean Accuracy\")\ncv_plot = cv_plot.set_title(\"CV Scores\")","a145219b":"RFC_model = RandomForestClassifier(n_estimators=10)\nscores = cross_val_score(RFC_model, X_train, Y_train, cv=K_fold, \n                        n_jobs=4, scoring='accuracy')\n\nprint(scores)\nround(np.mean(scores)*100, 2)","a89dad9d":"Log_Model = LogisticRegression(C=1)\nscores = cross_val_score(Log_Model, X_train, Y_train, cv=K_fold, \n                        n_jobs=4, scoring='accuracy')\n\nprint(scores)\nround(np.mean(scores)*100, 2)","3f2c538e":"Small families have more chance to survive, more than single.","d4d93a9d":"We can see that women have more chance to survive","bebb61cf":"<h2>4. Data cleansing","32feabe5":"<h3> Comparing survival and each of these categorical variables","8f873196":"<h1> Categorical data","775c7355":"It seems that passengers having a lot of siblings\/spouses have less chance to survive.","087c8096":" It is obivious that the captin did not survive :( \n### let's Now see how old this people","3c093c34":"<h2>SibSP","5387defd":"<h3> Explore the age by Pclass","95394bdd":"# A Machine Learning from Disaster","f27ace64":"<h2> Ticket","bdbf57db":"<h3>3. Findig Missing data","27c2a061":"### There is 18 titles in the dataset and most of them are very uncommon so we like to group them in 4 categories.","d02c5b75":"<h1>Evaluation using Cross Validation\n    \n### A great alternative is to use Scikit-Learn's cross-validation feature. \n### The following performs K-fold cross validation; \n### it randomly splits the training set into 10 distinct subsets called folds, \n### then it trains and evaluates the Models 10 times, picking a different fold for evaluation every time and training on the other 9 folds.","73e6be2b":"<h3>1. Get Data Ready","388cb62a":"<h2>4.1. Age","40c81666":"<h2>4.2. Fare","ad211c89":"## Logistic Regression Classifier.","c4f6fdcd":"<h3>Dealing with outliers","abebda2d":"<h3>Let's look Survived and Parch features in details.","f11021da":"<h2>4.3. Cabin","9bee5782":"<h2> 5. Feature Analysis","0af2e690":"# Numerical and categorical data Analysis","3aed0994":"<h1>Numerical Analysis","448dbef6":"we will use Tukey method","f76741a7":"<h4>Let's look Survived and Parch features in details.","f3172dc5":"<h2> Name","4ced8d56":"<h2>Sex","c49d6a5a":"<h3> Now we have null values in (Fare, cabin, Embarked, Survived)","7a8ce06c":"We just have two null value\nwe can look up similiar cases,to replace the missing value.\nMiss Amelie: https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/amelia-icard.html\nMrs. George Nelson: https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html\n\nRegarding to the linked articles both embarked in Southhampton.","acb2d5fd":"# Predictive Modeling","e6c8f709":"## Random Forest Classifier Model","f27dee28":"<h3>2. Look Inside data set","594b1261":"<h3> Now we have null values in (Cabin, Embarked,Survived)","5c2e8eee":"### Like before we have to convert the tiltes to categorical data","f5c0c590":"<h2>5.4. Embarked","64016af9":"<h3>compare survival rate across Age, SibSp, Parch, and Fare","2da1f012":"<h4>Now, let's look Survived and SibSp features in details."}}