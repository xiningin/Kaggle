{"cell_type":{"8f41f9cf":"code","5a3cb45a":"code","f1f4d977":"code","1b342b43":"code","40fd2299":"code","2c36e4c1":"code","eba898d9":"code","5f6b5cd4":"code","5df61b02":"code","5c2e282a":"code","c9b554a9":"code","1aef44c5":"code","afcbb10a":"code","9184bedc":"code","40b6e628":"code","871619a8":"code","4356d2ec":"markdown","ee9ae0c3":"markdown","8abe81d7":"markdown","94bf5984":"markdown","29e51bbc":"markdown","f319901c":"markdown","738945a1":"markdown","b30101d0":"markdown","7bff1e34":"markdown","de6629b1":"markdown","99b50988":"markdown","b9a66e69":"markdown","d6c90c5c":"markdown"},"source":{"8f41f9cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5a3cb45a":"image1='\/kaggle\/input\/original-image\/image1.jpg'\nimage=cv2.imread(image1)\nplt.axis('off')\nplt.imshow(image)\nplt.title('Original image')\nplt.show()","f1f4d977":"img=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)","1b342b43":"plt.axis('off')\nplt.imshow(img)\nplt.title('Original Image')\nplt.show()","40fd2299":"img.shape","2c36e4c1":"vectorized = np.float32(img.reshape((-1,3)))\nvectorized.shape","eba898d9":"criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)","5f6b5cd4":"K = 3\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)","5df61b02":"center = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))","5c2e282a":"figure_size = 15\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(2,3,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,3,2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","c9b554a9":"K = 4\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))\nfigure_size = 15\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(2,3,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,3,2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","1aef44c5":"K = 5\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))\nfigure_size = 15\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(2,3,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,3,2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","afcbb10a":"K = 6\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))\nfigure_size = 15\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(2,3,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,3,2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","9184bedc":"K = 7\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))\nfigure_size = 15\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(2,3,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,3,2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","40b6e628":"K = 8\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))\nfigure_size = 15\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(2,3,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,3,2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","871619a8":"K = 9\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))\nfigure_size = 15\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(2,3,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,3,2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","4356d2ec":"result_image is the output result. Lets see how the image looks after k-means clustering","ee9ae0c3":"Reference: [Introduction to image segmentation](https:\/\/towardsdatascience.com\/introduction-to-image-segmentation-with-k-means-clustering-83fd0a9e2fc3)","8abe81d7":"### Importing necessary Libraries","94bf5984":"Yep, this is the original image!","29e51bbc":"Applying k-Means clustering on the image:","f319901c":"Lets try segmentations with different K values and compare them with the original image.","738945a1":"In this kernal, let us start with one of the clustering-based approaches in Image Segmentation which is K-Means clustering.","b30101d0":"# **Image segmentation using Kmeans**","7bff1e34":"Image Segmentation involves converting an image into a collection of regions of pixels that are represented by a mask or a labeled image. By dividing an image into segments, you can process only the important segments of the image instead of processing the entire image.\n\nA variety of other approaches to perform image segmentation have been developed over the years using domain-specific knowledge to effectively solve segmentation problems in specific application areas.","de6629b1":"So, we need to convert our image from RGB Colours Space to HSV to work ahead.","99b50988":"Now, convert the (958 , 958 , 3) image to (917764, 3) (m*n) which will not be a vector in the 3-D space of RGB. Also, converting it to float value.","b9a66e69":"Wait, this is not the original image? \ud83e\udd14**","d6c90c5c":"According to [wikipedia](http:\/\/en.wikipedia.org\/wiki\/HSL_and_HSV#Use_in_image_analysis) the R, G, and B components of an object\u2019s color in a digital image are all correlated with the amount of light hitting the object, and therefore with each other, image descriptions in terms of those components make object discrimination difficult. Descriptions in terms of hue\/lightness\/chroma or hue\/lightness\/saturation are often more relevant."}}