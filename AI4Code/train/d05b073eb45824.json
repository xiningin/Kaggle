{"cell_type":{"6eb382b8":"code","b8d0365d":"code","5aa48316":"code","379295b4":"code","e865fb91":"code","6b1e06cd":"code","2fd5317c":"code","f06c71d9":"code","322223e8":"code","6edeb585":"code","dd350d8e":"code","a512f95b":"code","db06a3a7":"code","19963299":"code","dea1aa6b":"code","3e88deab":"code","ff292718":"code","0d2df3d5":"code","1ca82439":"code","5868ab5b":"code","3e3e0973":"code","92ca42c2":"code","353804e3":"code","d92e9f08":"code","13a4fc14":"code","30421ab8":"code","a8601140":"code","f0e8cf3c":"code","c10e4b5c":"code","cc554838":"code","f830632f":"code","efbe64dc":"code","65825405":"code","23b20492":"code","a381098d":"code","fd314de7":"code","a034bb31":"code","4af3c041":"code","40336794":"code","6572c289":"code","5cba78b6":"code","554e07d1":"code","3a537a92":"code","504349c3":"code","be61a576":"code","04460720":"code","6664f3af":"code","4ca4125c":"code","0809e94f":"code","0d460fe3":"code","42fa8ac1":"code","34462e87":"code","b6e5a456":"code","314f5ed9":"code","c7383856":"code","bdb6ce52":"code","9c8f90f4":"code","bbb0e652":"code","951b470e":"code","bb985dca":"code","57112242":"code","de5a1d5f":"code","f4efa835":"code","888595b8":"code","a5f21cfb":"code","c3887bbf":"code","93bbc372":"code","60eedcce":"code","2a477cd7":"code","9acc1aa2":"code","b1339ea9":"code","9f18bfd5":"code","25f7852d":"code","1f62fd13":"code","1fdca597":"code","25612a07":"code","3db9bb19":"code","ae507c61":"code","d58e044a":"code","6ac16818":"code","7ba8ddf1":"code","3dfaa372":"code","daf46f9e":"code","e5e04834":"code","f7b648d0":"code","dd359075":"code","a68b08e6":"code","6e96ca60":"code","f1f395b8":"code","9fdf83fe":"code","67f53405":"code","ebb178bc":"code","260cc4a5":"code","e0efaec9":"code","384d2175":"code","4a6c978b":"code","6ae26710":"code","0f6e0c8d":"code","2c90ef71":"code","ea7bc5e3":"code","7d563d05":"code","1e25bfd5":"code","81a0421e":"code","32d66cb6":"code","3bc7c957":"code","384a4281":"code","e2414185":"code","a99e068f":"code","72b3667f":"code","9a21b25c":"code","a0f37211":"code","591330a6":"code","5a06b372":"code","0f4a9a23":"code","95f7a6d0":"code","c6a58643":"code","3c14854e":"code","b561d3e4":"code","78c76b50":"code","309c0e0a":"code","4c736e34":"code","c5c47298":"code","7057eeb9":"code","2a121dcf":"code","023af20f":"code","2eb7a9f5":"code","02e9f347":"code","133e45f3":"code","599140c1":"code","b4c716d3":"code","bf3d60d0":"code","a2cac920":"code","298146b0":"code","89848530":"code","938c713a":"code","94a5b7ad":"code","da5d5c31":"code","76640453":"code","bfa4dc70":"code","077c264a":"code","3d2f7359":"code","c2d32824":"code","be3082db":"code","541ab8a8":"code","5be0fcab":"code","9145d004":"code","14036d7b":"code","9d298761":"code","5672e8ba":"code","c540fb33":"code","52db9962":"code","8adbfdf4":"code","bd36df27":"code","8889ca04":"code","e47f9deb":"code","ca88170c":"code","46f2369a":"code","156be035":"code","29f49d62":"code","9620a87f":"code","bbd91d6f":"code","9d2c1bec":"code","638cdadd":"code","e4b18518":"code","bad7d14f":"code","07401844":"code","8fc572a0":"code","bbc914e7":"code","2d3d2671":"code","c5e9d649":"code","06e89466":"code","b37689fe":"code","9bf33ab2":"code","1639a8f9":"code","91e95ec2":"markdown","8965095c":"markdown","9817a914":"markdown","a2e13931":"markdown","c480e014":"markdown","45bec779":"markdown","4f8a9eae":"markdown","fc0b24d0":"markdown","a9899682":"markdown","b700a05b":"markdown","c4233c42":"markdown","c17a2833":"markdown","ffddce20":"markdown","86c1c6b4":"markdown","09a29b51":"markdown","19bd9819":"markdown","217925bc":"markdown","7eaf75bf":"markdown","617b14e6":"markdown","53f857c7":"markdown","3034b8e2":"markdown","5ca9cd78":"markdown","76fe73f6":"markdown","350b3273":"markdown","921def1b":"markdown","439c7f27":"markdown","6825add5":"markdown","83bbe056":"markdown","b4cff4b2":"markdown","873cdc82":"markdown","3e8efeae":"markdown","bfc2c597":"markdown","a2ca4b0b":"markdown","617bd573":"markdown","b38f2bd1":"markdown","66b54efa":"markdown","647fe88d":"markdown","9603cf93":"markdown","cd2011cd":"markdown","ef126330":"markdown","e0df3e40":"markdown","489f4d7d":"markdown","26ee4143":"markdown","ab13c4e0":"markdown","beeb97c4":"markdown","7bfa4062":"markdown","3d626514":"markdown","9686e3d1":"markdown","28ec5d49":"markdown","19a5720b":"markdown","38820983":"markdown","f1b42e05":"markdown","5dadb9ec":"markdown","331e53bb":"markdown","f4281ae2":"markdown","7aa905aa":"markdown","dfd5a9a5":"markdown","c2e326c0":"markdown","6fc24073":"markdown","2be61a81":"markdown","fcebf234":"markdown","51ffeb51":"markdown","4232cb04":"markdown","44e3e06a":"markdown","26e0794d":"markdown","70854045":"markdown","8211f2be":"markdown","df6e7992":"markdown","decf74cf":"markdown","f7eab572":"markdown","bea41375":"markdown","0cf230e0":"markdown","48734f5e":"markdown","e01c2ea1":"markdown","654e2883":"markdown","ead2ab54":"markdown","c0c157e8":"markdown","16851ae3":"markdown","cba424fa":"markdown","35891637":"markdown","288732f0":"markdown","c5863254":"markdown","19d3a29e":"markdown","c04c4e8f":"markdown","9f3c3cea":"markdown","9f2bddbe":"markdown","5c68018d":"markdown","eb58e648":"markdown","2b5ddb66":"markdown","c2c024b4":"markdown","ae68a744":"markdown","3435695c":"markdown","f43f1c60":"markdown","f9cb8de5":"markdown","1d4da2f1":"markdown","6b2febef":"markdown","13b25fc1":"markdown","c36b746c":"markdown","b4498ec8":"markdown","c7549379":"markdown","c4eee6ee":"markdown","11e0e0a5":"markdown","92d6b478":"markdown","c64d1259":"markdown","aa6d440d":"markdown","8be40ed8":"markdown","fc1db773":"markdown","a04ef2c1":"markdown","3a6aa112":"markdown","0bf454ea":"markdown","c5807ba6":"markdown","2e5044b8":"markdown","b091606e":"markdown","14c96d47":"markdown","9b4b3cd8":"markdown"},"source":{"6eb382b8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b8d0365d":"df = pd.read_csv('..\/input\/stack-overflow-developing-survey-2019\/survey_results_public.csv')\n\ndf.head()","5aa48316":"df.shape","379295b4":"df.info()","e865fb91":"schema_df = pd.read_csv('..\/input\/stack-overflow-developing-survey-2019\/survey_results_schema.csv',index_col = 'Column')\n\nschema_df","6b1e06cd":"pd.set_option('display.max_columns',85)","2fd5317c":"schema_df","f06c71d9":"df['Country']","322223e8":"df[['Country','Hobbyist']]","6edeb585":"df.columns","dd350d8e":"df.iloc[0] #First row is specified and we get all the data for the 1st row","a512f95b":"#Accessing multiple rows by passing row indexes as a list\ndf.iloc[[1,3]]","db06a3a7":"df.iloc[1,3]\n\n#Note here that df.iloc[[1,3]] != df.iloc[1,3] as 3 here means the column index and not row index","19963299":"df.iloc[2:4] #As iloc is exclusive of outer bound, only indexes 2 and 3 are returned in this case.\n\n","dea1aa6b":"df.iloc[0,3] #This returns the value present in 1st row and 4th column","3e88deab":"df.iloc[[0,1],[3,4]] #This returns the dataframe having 2 rows which are 0,1 rows of orginal and 2 columns which are 3 and 4","ff292718":"df.loc[0] #First row is specified and we get all the data for the 1st row","0d2df3d5":"#Accessing multiple rows by passing row indexes as a list\ndf.loc[[0,3]]\n","1ca82439":"df.loc[1,3]\n\n#This throws an error as loc doesnt accept column indexes","5868ab5b":"df.loc[2:4] #As loc is inclusive of outer bound unlike iloc, so indexes 2,3 and 4 are returned in this case","3e3e0973":"df.loc[0,'OpenSourcer'] #Returns the value of opensourcer in first row which is \"Never\".","92ca42c2":"df.loc[[0,1],['Country','Student']]\n\n#returns the values of country and student in 1st and 2nd rows","353804e3":"df.loc[0:2,'Country':'OrgSize']\n\n#returns the values of all columns from country to orgsize in 1st to 3rd rows","d92e9f08":"df['Hobbyist']","13a4fc14":"df['Hobbyist'].value_counts()","30421ab8":"df.set_index('Respondent')","a8601140":"df.head()","f0e8cf3c":"df.set_index('Respondent',inplace=True)","c10e4b5c":"df","cc554838":"df.reset_index(inplace=True)","f830632f":"df.head() #Now, we can see that the dataset is back to its original index","efbe64dc":"df.index #Here the index is in the range(0,88883)","65825405":"pd.read_csv('..\/input\/stack-overflow-developing-survey-2019\/survey_results_public.csv',index_col='Respondent')\n\n#Now, we can see that the 'Respondent' column is automatically chosen to be the index","23b20492":"schema_df.head() #Column is the index","a381098d":"schema_df.loc['Hobbyist'] #Finding the meaning of \"Hobbyist\" column by using loc","fd314de7":"schema_df.sort_index(inplace=True)","a034bb31":"schema_df.head()","4af3c041":"schema_df.sort_index(inplace=True,ascending=False) #To sort indescending order","40336794":"schema_df.head()","6572c289":"#Specifying the filter function. This returns a series of True and False based on the condition\nfilt = df['Country']=='United States'\n\nfilt","5cba78b6":"#Passing the filter function inside dataframe to obtain a filtered dataframe\n\ndf[filt].head()","554e07d1":"#Finally accessing the specific columns to get the desired output\n\ndf[filt][['Employment','MainBranch']].head()","3a537a92":"df.loc[filt,['Employment','MainBranch']].head()","504349c3":"#Finding the people who reside in United States and not a student. We use paranthesis to seperate multiple conditions.\n\nfilt = ((df['Country']=='United States') & (df['Student']=='No'))\nfilt","be61a576":"#Finding the employment status of these filtered people\n\ndf.loc[filt].head()","04460720":"#An example for Or\n#Finding the people who reside in United States and not a student. We use paranthesis to seperate multiple conditions.\n\nfilt = ((df['Country']=='United States') | (df['Student']=='No'))\ndf[filt].head()","6664f3af":"high_sal = df['ConvertedComp']>70000\ndf.loc[high_sal,['Country','LanguageWorkedWith','ConvertedComp']]","4ca4125c":"#We can usethe isin() operator to find the list of column values in column\n\ncountries = ['United States','India','United Kingdom','Canada','Germany']\nfilt = df['Country'].isin(countries)","0809e94f":"df.loc[filt,'Country']","0d460fe3":"df['LanguageWorkedWith'].head()","42fa8ac1":"filt = df['LanguageWorkedWith'].str.contains('Python', na=False)\ndf.loc[filt,'LanguageWorkedWith'].head()","34462e87":"#looking at all the columns\ndf.columns","b6e5a456":"#Let us take a small dataframe to do it quickly for this\n\npeople = {\n    \"first\": [\"Corey\", 'Jane', 'John'], \n    \"last\": [\"Schafer\", 'Doe', 'Doe'], \n    \"email\": [\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JohnDoe@email.com']\n}\n\ndfa = pd.DataFrame(people)\n\ndfa","314f5ed9":"#Passing the new names as a list to the default df.columns\n\ndfa.columns = ['FirstName','LastName','Email']\n","c7383856":"#We can see the new column names inside the dataframe\ndfa","bdb6ce52":"#We can change the case of all the column names by using df.columns\n\ndf.columns = [i.upper() for i in df.columns]\n\ndf.head()","9c8f90f4":"#We can change the case of all the column names by using df.columns\n\ndf.columns = [i.lower() for i in df.columns]\n\ndf.head()","bbb0e652":"#Let us rename the respondent and mainbranch to 'UniqueID' and 'Branch'\n\ndf.rename(columns = {'respondent':'UniqueID','mainbranch':'Branch'},inplace=True)\n","951b470e":"df.head()","bb985dca":"dfa","57112242":"#Grabbing the data at index location 2\ndfa.loc[2]","de5a1d5f":"#Changing last name to smith and email as well\ndfa.loc[2] = ['John','Smith','JohnSmith@gmail.com']\n\ndfa","f4efa835":"#Grabbing only specific values of specific columns\n\ndfa.loc[2,['LastName','Email']] = ['Doe','JohnDoe@email.com']\ndfa","888595b8":"#Changing only one value by using loc\ndfa.loc[2,'LastName'] = 'Smith'\n\ndfa","a5f21cfb":"#Changing lastname of John to Doe again\n\ndfa.at[2,'LastName'] = 'Doe'\n\ndfa","c3887bbf":"filt = (dfa['Email'] == 'JohnDoe@email.com')\ndfa[filt]['LastName']","93bbc372":"dfa[filt]['LastName'] = 'Smith'","60eedcce":"#We can see that the LastName isnt changed\ndfa","2a477cd7":"#Correcting that mistake\n\ndfa.loc[filt,'LastName'] = 'Smith'\ndfa","9acc1aa2":"#Let us now change all the emails to lowercase\n\ndfa['Email'] = dfa['Email'].str.lower()\n\ndfa","b1339ea9":"#We used the apply function to find length of email addresses of a series\n\ndfa['Email'].apply(len)","9f18bfd5":"def update(email):\n    return email.upper()\n","25f7852d":"#Applying this function to email column\n\ndfa['Email'] = dfa['Email'].apply(update)\n\ndfa","1f62fd13":"#Converting the emails back to lowercase by using \"lambda\" function\n\ndfa['Email'] = dfa['Email'].apply(lambda x: x.lower())\n\ndfa\n\n#We can either use lambda or a custom function based on ur comfort","1fdca597":"dfa.apply(len)","25612a07":"#This is the function thats happening\n\nlen(dfa['FirstName'])","3db9bb19":"#Lets find the minimum value of each column in this dataframe\ndfa.apply(pd.Series.min)","ae507c61":"#We can see that it runs the len function on each value of the dataframe and returns their length\n\ndfa.applymap(len)","d58e044a":"def func(s):\n    return s.lower()\ndfa = dfa.applymap(func)","6ac16818":"dfa","7ba8ddf1":"dfa['FirstName'].map({'corey':'Rahul','jane':'emma'})\n","3dfaa372":"#Here, we can see that the name john is retained as we wanted to be\n\ndfa['FirstName'].replace({'corey':'Rahul','jane':'emma'})\n","daf46f9e":"#Let us rename the \"ConvertedComp\" column to \"SalaryUSD\" and keep it permanent\ndf.rename(columns={'ConvertedComp': 'SalaryUSD'}, inplace=True)","e5e04834":"#We can see that the change is reflected into the original dataframe\n\ndf['SalaryUSD']","f7b648d0":"#Lets look at this column now. We can clearly see that the only values in this are Yes and No.\n\n\ndf['Hobbyist']","dd359075":"#So, lets change the values of Yes and No to True or False by using the map() function\n\ndf['Hobbyist'] = df['Hobbyist'].map({'Yes':'True','No':'False'})\ndf['Hobbyist']\n\n#We can see the changes clearly","a68b08e6":"dfa","6e96ca60":"#Creating a new column by using string addition\n\ndfa['FullName'] = dfa['FirstName']+' '+dfa['LastName']\ndfa","f1f395b8":"#Returns the required datframe. if we want changes to be reflected, we can use inplace=True\n\ndfa.drop(columns=['FirstName','LastName'])","9fdf83fe":"\ndfa.drop(columns=['FirstName','LastName'],inplace=True)\ndfa","67f53405":"#We have split the FullName column to get firstname and lastname as a list so we can use this to assign columns\n\ndfa['FullName'].str.split(' ',expand=True)\n\n#Here the expand=True, returns a dataframe resulting by the split","ebb178bc":"#Finishing up by assigning new columns to the created dataframe as above\n\ndfa[['FirstName','LastName']] = dfa['FullName'].str.split(' ',expand=True)\ndfa","260cc4a5":"#We have to make sure to pass in ignore_index=True as pandas can only append if the existing series has a name or if\n#ignore_index=True\n\ndfa.append({'FirstName':'Tony','LastName':'Anthwan','Email':'tn@email.com','FullName':'Tony Anthwan'},ignore_index=True)","e0efaec9":"people = {\n    \"FirstName\": [\"Tony\", 'Steve'], \n    \"LastName\": [\"Stark\", 'Rogers'], \n    \"Email\": [\"TonyStark0@gmail.com\", 'SteveRogers@email.com']\n}\ndfb = pd.DataFrame(people)\ndfb","384d2175":"#We can see that, wherever the values are missing, it adds Nan to them\n\ndfa.append(dfb,ignore_index=True)","4a6c978b":"dfa = dfa.append(dfb,ignore_index=True)","6ae26710":"dfa","0f6e0c8d":"#For dropping a single row, we dont need brackets\n\ndfa.drop(index=[4,3],inplace=True)\ndfa","2c90ef71":"#We can do this by using a filtering condition as usual\n\nfilt = (df['Country']=='United States')   #Returns a series of True or False\n\ndf[filt].index  #Returns all the indexes where people live in US\n\ndf.drop(df[filt].index)","ea7bc5e3":"dfa","7d563d05":"#We can use the sort_values method to sort the dataframe and we use 'by' to assertain which column to sort\n\ndfa.sort_values(by='FirstName')","1e25bfd5":"#Sorting in descending order\n\ndfa.sort_values(by='FirstName',ascending=False)","81a0421e":"dfa.sort_values(by=['LastName','FirstName'],ascending=[False,True])","32d66cb6":"dfa","3bc7c957":"#Notice the indexes\n\ndfa.sort_values(by=['LastName','FirstName'],ascending=[False,False])","384a4281":"#Restoring the usual way\n\ndfa.sort_index()","e2414185":"dfa['FirstName'].sort_values()","a99e068f":"df.head()","72b3667f":"df.sort_values(by='Country',inplace=True)\n\ndf[['Country','SalaryUSD']].head(50)\n\n#Working fine","9a21b25c":"#Now lets sort the salaries in descending order and countries in ascending order\n\ndf.sort_values(by=['Country','SalaryUSD'],ascending=[True,False],inplace=True)\n\ndf[['Country','SalaryUSD']].head(50)","a0f37211":"#We can use the nalargest() method to view the n largest items in a series. This works only on numeric data\n\ndf['SalaryUSD'].nlargest(10)","591330a6":"#We can use the same method to get the dataframe where the salaries are the largest\n\ndf.nlargest(10,'SalaryUSD')","5a06b372":"#Alternate method\ndf.loc[df['SalaryUSD'].nlargest(10).index]","0f4a9a23":"df.nsmallest(10,'SalaryUSD')","95f7a6d0":"df['SalaryUSD'].head(15)","c6a58643":"#Let us find the median of the salary. This ignores the nan values\n\ndf['SalaryUSD'].median()","3c14854e":"#Returns the median of all the numeric columns\n\ndf.median()","b561d3e4":"df.describe()","78c76b50":"#count :-  Number of non null rows\n\ndf['SalaryUSD'].count()","309c0e0a":"#The count() method is different from value_counts()\n\ndf['Hobbyist'].value_counts()","4c736e34":"#Returns all the unique values in the column\n\ndf['SocialMedia'].unique()","c5c47298":"#The social media column in df means this\n\nschema_df.loc['SocialMedia']","7057eeb9":"#Let us find the most popular social media site\n\ndf['SocialMedia'].value_counts()","2a121dcf":"#Returns the percentages instead of number\n\ndf['SocialMedia'].value_counts(normalize=True)","023af20f":"df['Country'].value_counts()","2eb7a9f5":"#Let us now know how to use groupby() function. The steps are Splitting, applying function, combining results\n\ncountry_group = df.groupby(['Country'])\n\n#This returns a groupby object","02e9f347":"country_group.get_group('India')","133e45f3":"filt = df['Country']=='India'\ndf.loc[filt].head()\n\n#But by using groupby we can lookup at any country","599140c1":"#Now, let us look at the most popular social media sites by country. For a single country, we can use filter as below\n\ndf.loc[filt]['SocialMedia'].value_counts()","b4c716d3":"country_group['SocialMedia'].value_counts().head(50)","bf3d60d0":"#We can look for India as below. Since the grouping is done on Country, we can use Country Name now\n\ncountry_group['SocialMedia'].value_counts().loc['India']","a2cac920":"country_group['SocialMedia'].value_counts(normalize=True).loc['India']","298146b0":"country_group['Hobbyist'].get_group('India').value_counts(normalize=True)","89848530":"#Finding the salary of developers based on their countries\n\ncountry_group['SalaryUSD'].median()","938c713a":"#Grabbing a specific country median salary\n\ncountry_group['SalaryUSD'].median().loc['India']","94a5b7ad":"#Returns the dataframe consisting of median and mean salaries based on countries\n\ncountry_group['SalaryUSD'].agg(['median','mean']).head(20)","da5d5c31":"#Grabbing a single country as below\n\ncountry_group['SalaryUSD'].agg(['median','mean']).loc['Canada']","76640453":"#How many people in each country know Python\n\ncountry_group['LanguageWorkedWith'].value_counts()","bfa4dc70":"#Using filtering to perform this operation for a single country India\n\ndf.loc[df['Country']=='India']['LanguageWorkedWith'].str.contains('Python').value_counts()\n\n#this returned a series containing true and false but all we need is the people where the Python is True for Boolean.","077c264a":"#We can see that it returns the correct value\n\ndf.loc[df['Country']=='India']['LanguageWorkedWith'].str.contains('Python').sum()","3d2f7359":"#Now let us see how we can do the same for all columns using groupby\n\ncountry_group['LanguageWorkedWith'].str.contains('Python')\n\n#This returns an error so we can use apply method to rectify this","c2d32824":"#We can use lambda function as shown below. Lambda function can be especially used in groupby functions.\n\ncountry_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)).head(10)","be3082db":"#Another way\n\ncoun_res = df['Country'].value_counts()\ncoun_res","541ab8a8":"pyth_coun = country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())\npyth_coun","5be0fcab":"#Using the concat() funciton to concatenate two series. Since we are concatenating by columns, we use axis=1\n\ndfx = pd.concat([coun_res,pyth_coun],axis=1,sort=False)\ndfx.head()","9145d004":"dfx.rename(columns={'Country':'TotalPeople','LanguageWorkedWith':'NoofPythonUsers'},inplace=True)\ndfx","14036d7b":"dfx['Percentage_Python_Users'] = dfx['NoofPythonUsers']\/dfx['TotalPeople']","9d298761":"\ndfx","5672e8ba":"dfx.sort_values(by='Precentage_Python_Users',ascending=False)","c540fb33":"dfx.loc['Japan']","52db9962":"people = {\n    'first': ['Corey', 'Jane', 'John', 'Chris', np.nan, None, 'NA'], \n    'last': ['Schafer', 'Doe', 'Doe', 'Schafer', np.nan, np.nan, 'Missing'], \n    'email': ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com', None, np.nan, 'Anonymous@email.com', 'NA'],\n    'age': ['33', '55', '63', '36', None, None, 'Missing']\n}\n\ndfa = pd.DataFrame(people)\n\ndfa","8adbfdf4":"dfa.dropna()\n\n#Drops rows where atleast one row has missing values","bd36df27":"dfa.dropna(how='all')\n\n#only drops rows when all values in row are nan","8889ca04":"dfa.dropna(axis='columns',how='all')","e47f9deb":"#Returns an empty dataframe as column 1 of row 4 has Nan value\n\ndfa.dropna(axis='columns',how='any')","ca88170c":"dfa.dropna(axis='index',how='any',subset=['email'])","46f2369a":"#Passing multiple columns. Only drop the entries where both lastname and email are Nan values.\n\ndfa.dropna(axis='index',how='all',subset=['last','email'])\n\n#For a row to be dropped, both lastname and email should be missing","156be035":"#We can replace by using the replace() function.\n\ndfa = pd.DataFrame(people)\n\ndfa.replace({'NA':np.nan,'Missing':np.nan},inplace=True)\n","29f49d62":"dfa","9620a87f":"dfa.dropna(axis='index',how='all',subset=['last','email'])","bbd91d6f":"#We can use the isna() function to see which values are nan values\n\ndfa.isna()","9d2c1bec":"#All the na values are filled with 'Missing'.\n\ndfa.fillna('Missing')\n\n#This is mostly used with numeric data to replace missing value with either mean or by 0","638cdadd":"#Let us now look at the datatypes of our sample dataframe\n\ndfa.dtypes","e4b18518":"type(np.nan)","bad7d14f":"#Converting to floats\n\ndfa['age'] = dfa['age'].astype(float)","07401844":"#Finding the mean\n\ndfa['age'].mean()","8fc572a0":"#Let us answer a question wherein we have to calculate the average years of experience of a developer in the dataset","bbc914e7":"#YearsCode refers to the years of experience of each coder\n\ndf['YearsCode'].head(10)","2d3d2671":"#This is an object datatype so we have to change it to float\n\ndf['YearsCode'].dtypes","c5e9d649":"df['YearsCode'] = df['YearsCode'].astype(float)","06e89466":"df['YearsCode'].unique()\n\n#We can see two different values \"Less than 1 year\" and \"More than 50 years\".","b37689fe":"df['YearsCode'].replace({'Less than 1 year':0,'More than 50 years':50},inplace=True)","9bf33ab2":"df['YearsCode'].unique()\n\n#now its sorted so lets typecast it to float and finally see the mean","1639a8f9":"df['YearsCode'] =df['YearsCode'].astype(float)\ndf['YearsCode'].mean()","91e95ec2":"Now, I made the index of the schema dataframe to be column as we can easily search the meaning of the column name just by using the loc function as shown below. Note that, we cannot use the iloc function anymore for this as index is not an integer","8965095c":"We can see that, when we used a single column, we can see that a Series is returned while when passing multiple columns, we can see that a DataFrame is returned","9817a914":"Let us now replace the Less than one year to 0 and more than 50 years to 50 and then find out the mean","a2e13931":"Now, let us look at how we can update values based on a function.\n\nFor example, we ar gonna create a function that changes the email address to uppercase in all entries.","c480e014":"Now, let us try to create a column which has the sum of both FirstName and LastName titled as FullName","45bec779":"Sometimes, the value of a certain column isn't necessarily a string or a value instead it can be a list of strings or values or dictionaries etc.\n\nIn these cases, we cannot directly use the isin() function or the == to filter them.String functions come in hand y in these cases.\n\nNow, let us look at the most commonly used the string method called str.contains().\n\nThis takes in the string as an input argument which it searches and also a default na value incase the column has any null values in it.\n\n\nNow,let us look at an example wherein we filter the people based on if they worked with Python language and seperate the ones.","4f8a9eae":"Now, let us look at how we can add a single row to a dataframe. \n\nWe can usually do this by using the .append() method and passing all the attributes as a dictionary.\n\nLet us look at an example below","fc0b24d0":"Now, let us do some advanced operations on changing the values in columns. There are 4 different methods in which we can change all the values of a certain column based on some conditions.\n\n1. apply()\n2. map()\n3. applymap()\n4. replace()\n\nLet us look at each of them in detail.","a9899682":"We can use the same steps for updating the values based on a complex function as well","b700a05b":"We can view the index of the dataframe by using the \"df.index\" attribute as shown below\n","c4233c42":"There are a couple of ways in which we can add rows to a dataframe.\n\n1. We might want to add a new row or multiple rows to the existing dataframe\n2. We might want to merge two dataframes into a single dataframe by appending its rows","c17a2833":"We can even use the not operator in a similar way","ffddce20":"What we did here is that we tried to sort the dataframe based on the lastname first in descending order and if there are duplicates, we then sorted the data based on first name next in ascending order.\n\nSince the last name is in descending order, we got Schafer first. But the last names of both Jane and John are Doe so we sorted them in ascending order based on their first names. So the order is Schafer, Jane(Comes before John), John","86c1c6b4":"# Cleaning Data - Casting Datatypes and Handling Missing Values","09a29b51":"We can use dropna() method.\n\nThis dropna() uses some default arguments such as axis and how. \"axis\" is set to \"index\" and how is set to \"any\" by default.\n\naxis:- when we set axis=\"index\", it drops the rows which has Nan values. If it is set to \"columns\", it drops columns with missing values\n\nhow:-  When the how is by default set to \"any\", it drops rows with any missing values. This can be changed to \"all\" which only drops the rows when all rows are missing","19bd9819":"Now, let us take an example of the Public dataset. We want to find out the 'Employment' and \"Main Branch\" of all the people who reside in the \"United States\".\n\nFirst let us do this by the normal method.\n\nThe normal method is to create a filter function for \"United States\" and pass this inside a DataFrame by using the syntax like:- df[filtercondition] and then accessing these two specific columns of the new dataframe by using the loc function. We wont be using the iloc function as it is difficult to count the column number of specific columns all the time","217925bc":"Let us first look at some basic aggregations and then move onto advanced stuff.\n\nAggregation can be said as combining multiple pieces of data into a single result. Mean, Median and Mode are some aggregations\n\nThis is the part where statistics come into picture","7eaf75bf":"Let us now look at the custom missing values and how to handle them","617b14e6":"Apply is used to call a function onto a value. This can be used for both Series and Dataframes. Let us look at how it works on a Series and Dataframe.","53f857c7":"This is inefficient as for more entries datasets, we can use loc to grab some specific values of the dataframes","3034b8e2":"Now, let us look at how we can access all the data present in a single row by using \"iloc\". By default, the parameter list of iloc is [rows,columns] so rows come first followed by columns.\n\nBut since in this case, we need everything from columns, we dont specify an index for the column.\n\nBelow is the example","5ca9cd78":"So, now we can see that the index is set as \"Respondent\" column in the dataframe as it is unique as well. But when we look at the dataframe in the above cell, we can see that these changes we made are not included in the original dataframe.\n\nFor the changes to be reflected in the dataframe, we need to pass in the parameter called \"inplace\" and set it to True\n\nSo, the updated syntax would be like:\n\ndf.set_index('colname',inplace=True)","76fe73f6":"In order to know the number of values in a column of the dataframe as above, like knowing the number of Yes and No, we can use the value_counts() function as shown below","350b3273":"Now, let us look at how we can access the data of multiple rows by using iloc.\n\nSo for accessing multiple rows, there are two ways in which we can do them.\n\n1. By specifying the indexes of the rows as a list\n2. By slicing the indexes just like we do in lists\n\n\n1. In the first method, we pass the indexes of the rows we want to access,as a list inside the iloc function. The syntax for this is df.iloc[[row1,row2,...,rown]]. \n\nWhile using only 2 columns, we have to be vary of specifying them as a list as df.iloc[[x,y]] is entierly different from df.iloc[x,y] as in second case, it returns a single value at xth row and yth column and not a dataframe of x and y rows as we need\n\n2. In the second method, we pass the indexes as a slicing operation between a range so the dataframe is returned for that particular range. Keep note that, the range in iloc is exclusive of outer bound which means, the values are returned one less than outer bound.\n\nNow, let us look at the examples","921def1b":"Sometimes, when we sort the data based on doing this, we might see that our dataframes indexes would be in a mix. \n\nIf we ever want to retain our old indexes after sorting, we can use the \"sort_index()\" function to do so. \n\nLet us see an example below","439c7f27":"We can do this by using the sum() function, which counts the number of Trues in this case which happen to be 1 and display the count of them","6825add5":"But we want to find out the popularity based on all countries so manually writing code as below is inefficient. This is where groupby helps","83bbe056":"We can even sort a single series of a dataframe and not to view the entire dataframe","b4cff4b2":"Here we used the shape attribute to return the total number of rows and columns of the dataset. And the info() function is a convenient method to see the jist of the entire dataset.\n\nIt shows the number of columns with their names and data types and number of entries in them. This is a way to confirm if we can have some null values in the Dataset.\n\nFor example, in this we can see that, while  the total entries are 88883, second column has 88331 entires which means it has null values","873cdc82":"We can even use the 'And' and 'Or' operators to filter various conditions based on our requirement.\n\nA key point to note is that, in Pandas we have to use the symbols & and | for 'And' and 'Or' operations.\n\nLet us look at an example","3e8efeae":"We might want to need something advanced for datasets where we should have the flexibility to drop nan values at particular columns or rows. We can also do this in Pandas\n\nFor example, we need to drop rows where only the email is missing.\n\nTo accomplish this, we need a subset argument. This subset will be the column name that we need to check for nan.\n\nNote: Pass the columns as a list in subset","bfc2c597":"Unlike the drop method which has a default \"inplace=True\" method, this append method doesn't have it so we have to manually assign it to the returned dataframe for the changes to reflect","a2ca4b0b":"\"iloc\" stands for \"Integer Location\" and this is used to identify or locate the values present in the Dataframe by using the integers as its indexes.\n\nThere are several ways of accessing the data by using iloc so let us list them.\n\n1. By specifying only the row\n2. By specifying multiple rows\n3. By specifying a row and a specific column\n4. By specifying single\/multiple row\/rows and single\/multiple column\/columns","617bd573":"Now, let us look at how we can handle missing values and clean up our dataset.\n\nAlmost every dataset that we recieve is bound to have missing values or data that needs to be cleaned before trying to make a model.\n\nThis is because of the fact that human fetched data is always prone to errors and miscalculations. We will need to sometimes typecast some data to other datatype and replace or drop missing values","b38f2bd1":"# Sorting Data","66b54efa":"Note:\n\n1. Dataframe is a 2 Dimensional Structure as it has rows and columns and it is a concatenation of multiple series.\n2. Series is a 1 Dimensional Structure and it is a lot similar to 1D arrays with more functionalities","647fe88d":"One way we can sort this data is by using the country name as a sorting column","9603cf93":"Finally, now let us look at how we can remove the rows in a dataframe.\n\nWe can remove the rows by using their index values by passing them inside the drop() function\n\nLet us consider the example below","cd2011cd":"# Getting Started with Data Analysis using Pandas","ef126330":"There is a lot of confusion regarding the usage of the functions \"iloc\" and \"loc\" so let's talk about this in a detailed manner by using lots of examples of iloc and loc\n\nFirst, let us proceed with iloc","e0df3e40":"Now, let us use this knowledge to work on our larger dataset which is the \"Public\" dataset we already have","489f4d7d":"Inorder to answer more specific questions like, what social media platforms are popular in different regions or what is the median salary based on country, we need to understand grouping.\n\nWe use groupby() function for this.\n\ngroupby() function is the operation which involves splitting the object, applying the function and combining the results as given in Pandas documentation\n\nSPLITTING--------->APPLYING FUNCTION----------->COMBINING RESULTS","26ee4143":"Let us now look at how we can sort the data in columns. We will look at how we can sort a single column, multiple columns and how we can find the minimum and maximum of them.\n\nFirst, we will try to use this on a smaller dataset which is dfa as usual and then we will try to use this on the Survey dataset","ab13c4e0":"Now, we can see that these changes are reflected in the dataframe as well.\n\n\nNow, sometimes we want to reset our index back to the default index and pandas has a method called \"reset_index\" which does that.\n\nThe syntax would be like: \ndf.reset_index(inplace=True)","beeb97c4":"The other way is to do by using the .loc function. Although this is similar to the previous method in steps, we can reduce the complexity of code vastly by using the .loc function.\n\nWe know that the .loc() takes two parameters as an input which are [rows,column names]. Now, we can obtain the needed data by passing the filtered condtion as rows and the required column names as a list of columns inside loc to get the final dataframe","7bfa4062":"Now, let us look at the way in which we can access the dataframe by specifying multiple rows and multiple columns. \n\nThe way is simple as all we need to do is to pass the multiple rows and columns as a list and pass them inside the iloc function.\n\nLet us look at the example below","3d626514":"Note that, while creating new column, we cannot use the dot operator for assignning values to a new column","9686e3d1":"Now, let us go back to our Survey dataset and use these operations on it to view the results","28ec5d49":"Sometimes, we need the function to be applied to each and every value in the dataframe and this is precisely when we use the applymap() function.\n\nApplymap() function only works on dataframes and not series and it applies a certain condition to all the values in a dataframe","19a5720b":"In oder to get a statistical overview of the data we have, we can use the .describe() method.\n\nThis returns all the important aggregates like Mean, Median and Mode of all the numeric columns we have in our dataset","38820983":"Sometimes while working with the numeric data, we would need to fill in the na value with something.\n\nFor example in a test, if a student is absent and gets the result as NA, we can fill them with zeros.\n\nWe use fillna() method for this","f1b42e05":"Now, let us see how we can access a specific element by using loc. The default syntax is df.loc[row,\"column name\"] so we use this to access one element.\n\nLet us look at an example below","5dadb9ec":"Since we grouped the dataframe by country, we can access by mentioning the country name of the group to yield results","331e53bb":"Let us first look at how we can handle the custom Nan values while reading the data by using the read_csv() function\n\nIf we know what custom NA values are occuring in the dataset, we can use the \"na_values\" attribute in the read_csv() function","f4281ae2":"# Updating Rows and Columns - Modifying Data Within DataFrames","7aa905aa":"This is similar to the filter function as shown below","dfd5a9a5":"## Casting Datatype","c2e326c0":"Here, we notice a problem that whatever values which we havent specified as a dictionary are replaced as nan values when map() is used.\n\nSo we only use map functions wherein the unique values in that column are minimum like Yes\/No or 0\/1 etc","6fc24073":"An important thing to note while using slicing is that we should not pass them inside a list while using the iloc or loc function. The syntax shoule be like\n\ndf.iloc[rowx:rowy,colx:coly]\n\ndf.loc[rowx:rowy,\"colnamex\":\"colnamey\"]","2be61a81":"Now that we have seen how to filter the rows based on some conditions, let us now look at how we can use these filtering conditions to update and modify various rows within the dataframes","fcebf234":"Mean can be a bad aggregate to use for numeric columns like Salary as the higher values of Salary sometimes tend to push the mean to extremes.\n\nThese values which are abnormally higher than rest of the values in that column are called Outliers. Mean is prone to outliers so it is accurate to use median in these cases","51ffeb51":"By using the read_csv() method, we read the dataset and viewed the top 5 entries by using head() function.\n\nThe data we will use in this notebook is called \"StackOverflow Annual Developer Survey\" data of 2019.\n\nIt contains two datasets namely \"Public\" and \"Schema\". The Public dataset is the survey data while the Schema dataset explains each column of the Public data and their meaning.","4232cb04":"Right now, this might not be an efficient method to constantly come back to this Dataframe to see the meaning of the columns in \"Public\" but as we move down further, we will discuss about various filtering and accessing methods which will make our job easier.\n\nFor example, the row named \"Country\" in the \"Schema\" dataframe asks a question stating \"In which country do you currently reside?\", while the rows in the \"Public\" dataframe contains a list of country names in which various people who were surveyed reside in.","44e3e06a":"This is a series which have multiple indexes. This returns a series of all the countries","26e0794d":"# End of the Tutorial","70854045":"So, we have to convert the age column to float and not integers.\n\nTo cast datatype, we use the astype() method","8211f2be":"Now, let us look at how we can update the values in our rows by using loc and iloc by using the sample dataframe dfa","df6e7992":"We can handle the missing data based on our dataset in many ways. One such way is to remove the missing data completely. Although this practise is not recommended in real world application usecases as missing data often has data in other sections as well","decf74cf":"If we know the index which we can use while reading the dataframe, we can use a special paramter called \"index_col\" inside the read_csv function to specify the index while reading the dataframe.\n\nThis saves us both the effort and minimises the code to randomly setup the index later.\n\nThe syntax is like:\npd.read_csv('filename.csv\",index_col='colname')","f7eab572":"By setting the maximum rows to be displayed as 85, we can clearly see all the rows of the \"Schema\" dataset now","bea41375":"# Indexes - How to Set, Reset, and Use Indexes","0cf230e0":"For setting a particular column as an index, all we need to do is to pass in the column name as the parameter inside the set_index() function as shown below","48734f5e":"This method isnt useful as this only works for the case in which we want to replace the names of all the columns and not just some columns","e01c2ea1":"Now, let us see how we can access a specific element by using iloc. The default syntax is df.iloc[row,column] so we use this to access one element.\n\nLet us look at an example below","654e2883":"Now, let us look at some filters by using some examples","ead2ab54":"This result might come to be unexpected as we expected the function to give out the length of each value but in this case, the len function is returning the number of entries in each column of this dataframe.\n\nSo, FirstName has 3 rows called Corey,John,Jane. Thats why it returned 3","c0c157e8":"For analysis, let us suppose that we wanted to see not only the median but also the mean salary for developers based on countries.\n\nTo use multiple aggregation methods like this, we can use the agg() method and pass in all the aggregations we can use.\n\nLet us look at this example now","16851ae3":"Let us note that, using the median of the entire Salary column might not be the best way to work with data as different countries have different economic conditions and the median salary can sometimes be a lot higher than the highest salary of a particular country.\n\nTo overcome this, we can find the median salary of the developers based on their country","cba424fa":"# Add\/Remove Rows and Columns From DataFrames","35891637":"Now, let us look at the way in which we can access the dataframe by specifying multiple rows and multiple columns. \n\nThe way is simple as all we need to do is to pass the multiple rows and column names as a list and pass them inside the loc function.\n\n\nLet us look at the example below","288732f0":"Now, let us see how we can remove columns in a dataframe.\n\nIn this example, since we already have full name, lets remove both first name and last name.\n\nWe can use the .drop() function to remove a single column or a list of columns easily.\n\nThe syntax is like :- df.drop(columns=['col1','col2'.....,'coln'])","c5863254":"Pandas has a specific function called 'at' which performs the same function as .loc as we used above. Let us look at an example\n","19d3a29e":"So, these are the ways in which we use both \"loc\" and \"iloc\" functions.\n\nloc function is also used in indexing but we will look at it in later part of this notebook","c04c4e8f":"First, lets talk about how to drop missing values. \n\nLet us do in the smaller dataset first and then carry it over to the Survey dataset","9f3c3cea":"The first method is to pass in all the new column names inside a list and assigning it to the df.columns to update it","9f2bddbe":"We can even use conditionals to drop the rows which we dont need.\n\nLet us now use the example of Survey dataframe to accomplish this.\n\nLet us try to remove all the people who live in the United States","5c68018d":"Index is the default and one of the most prominent column in any dataset. By default, most of the datasets have indexes have ranges from 0 to number of rows-1\n\nHowever, in Pandas, we have many options wherein we can set our own custom indexes, reset them if we dont want and also create new indexes if we wish for it.\n","eb58e648":"Filtering is one of the most essential operations which we perform on a dataset based on various conditions and to extract some insights. \n\nNow, let us look at some ways in which we perform filtering.\n\nWe can filter data by specifying a filter condition and then passing the condition inside a dataframe to obtain the filtered dataframe.\n\nFor doing this, we can either use .loc function or the normal calling function.","2b5ddb66":"One of the common mistakes which we can do is as follows. Let us look at an example below.\n\nHere, we tried accessing the last name of \"John\" by using a filter condition and then accessing the lastname of that dataframe.\n\nThen we tried to set that value to \"Smith\" which resulted in an error.\n\nThis is due to the fact that the dataframe we created is a subset and a temporary dataframe and can be tossed out anytime.\n\nSo, make sure to change the values only by using the .loc method","c2c024b4":"There are a couple of ways in which we can change the name of the columns which we will look over now.\n\n1. Manually assigning all the columns to a list of new column names\n2. Using the .rename() function","ae68a744":"Inorder to handle these kind of custom missing values, we can do it in 2 ways depending on how we obtain the data.\n\n1. We created the data from a dictionary of lists just like the people data we created\n2. We read the data from a csv file by using read_csv()","3435695c":"Now, let us see how the apply function works on a dataframe.\n\nWhen we run apply on an entire dataframe, it runs on each row and column of a dataframe.","f43f1c60":"Now let us take this knowledge to the Survey data and do some analysis","f9cb8de5":"# Filtering - Using Conditionals to Filter Rows and Columns","1d4da2f1":"This returns the number of times each unique value occured in that particular column of the dataframe","6b2febef":"Now. let us look at the map() function.\n\nmap() funcion only works on a series. This is mainly used to subsitute various values in a series inplace of already exisitng values.\n\nmap() takes in a dictionary of values as {exisiting value:new value} and replaces them at all occurances","13b25fc1":"Now, that we have succesfully seen the iloc function, let us talk about the loc function.\n\n\"loc\" stands for location and in this function, we can access certain elements or the dataframe by specifying the indexes of the row and the \"name\" of the column. \n\nIf we try to access the dataframe or a value by specifying the column index, it throws an error.\n\nThe methods are similar to the \"loc\" just like iloc but the slicing operation's range is inclusive in this case. This means that the upper bound is considered too for the \"loc\" operation.\n\nNow, let us look at the examples just like iloc","c36b746c":"When we have some Nan values in the column that we are working and if we want to change their datatype, we should use float as nan values are in floating datatype by default","b4498ec8":"Till now, we have seen how we can updat elements within our rows and columns of the dataframe. Now, let us look at how we can create or remove various rows and columns based on our need.\n\nFirst, let us look at how we can create a new column.","c7549379":"We can access a single column in the dataframe by specifying it within the paranthesis of the dataframe as shown above.\n\nFor multiple columns, we use a list of columns inside the paranthesis.","c4eee6ee":"The first step is to import all the necessary libraries by using their aliases so we can use them without a hassle.","11e0e0a5":"The age column here is an object and if we want to find out the mean of age, we need to cast it into an integer datatype.\n\n","92d6b478":"Whatif we wanted to update only the selected values and keep other values as it is?\n\nThis is when we use replace() function.\n\nreplace() function replaces only the specified values and leaves the others as it is","c64d1259":"So, to sum the apply() function,\n1. It applies the function to each value of the series.\n2. It applies the function to each row and column in the dataframe and not their values","aa6d440d":"Sometimes, we need to sort the dataframe based on multiple columns and understanding this might be a bit complicated.\n\nWe can sort the dataframe on multiple columns by passing the column names as a list to the by attribute as shown below.\n\nWe can also pass the \"ascending\" attributes as a list as we want","8be40ed8":"The second method to rename is by using the .rename() function. This function is widely used as this replaces the names of the specific columns with a new value.\n\nThe syntax is:- df.rename(columns = {col1name:newcol1name, col2name:newcol2name......},inplace=True)","fc1db773":"Now, let us look at how we can append rows of multiple dataframes to create a single dataframe.\n\nFor this,we are gonna create a new dataframe similar to the dfa one","a04ef2c1":"# iloc and loc ","3a6aa112":"Here, we loaded the \"Schema\" dataset which displays the meaning of all the columns. \n\nNotice that we cannot see all the rows in this dataset as Pandas minimises these for not taking up too much of screen space. \n\nBut in cases like these where its essential to see all the rows, we can use a method called set_option() as shown below","0bf454ea":"# Grouping and Aggregating - Analyzing and Exploring Your Data","c5807ba6":"Now that we have seen how we can add, remove and update columns, let us now look at how to perform these operations on rows of the dataframe","2e5044b8":"Creating a new column is easy in Pandas. For creating a new column, we just have to pass in the name of the column to the dataframe and assign a list of values that it can hold as elements in that column.\n\nLet us look at how we can do it on a smaller dataset dfa before moving on to the Survey dataset.","b091606e":"Although, we made the index to the column names, it looks good if they are to be arranged in an alphabetical order.\n\nWe can do this by using the \"sort_index\"() function as shown below","14c96d47":"Now, let us explore the most important part of the data analysis using Pandas which is \"Grouping and Aggregating the Data\"\n\nThese are the methods which are used to answer the questions like \"How many persons in United States use Python and what is their average salary?\" etc\n\nLet us dive into this now.","9b4b3cd8":"An unexpected result occured wherein some of the entries of this column are strings which cannot be converted to floats.\nSo now, let us look at all the unique values of this column"}}