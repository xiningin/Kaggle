{"cell_type":{"abb95f50":"code","631be68a":"code","9b84823e":"code","6be2e61f":"code","7ab84f6f":"code","2f20b5c9":"code","be0964dc":"code","d1af54a2":"code","a6d710dc":"code","decc9d51":"code","ad86f3f9":"code","c1af2241":"code","0610222e":"code","9efa821a":"code","43f18235":"code","a54e92ce":"code","560494da":"code","57a5e38d":"code","dcbcf71d":"code","6f4ab00c":"code","d0f074a5":"code","adc46551":"code","21a6ae90":"markdown","f988d1a8":"markdown","cbc48686":"markdown","d1edc5e6":"markdown","9c120d37":"markdown","00cfdd6c":"markdown","99481a23":"markdown","8ed58114":"markdown","dd21cc94":"markdown"},"source":{"abb95f50":"!git clone https:\/\/github.com\/rkuo2000\/yolov5\n%cd yolov5","631be68a":"!mkdir -p Dataset\/FaceMask\/Images\n!mkdir -p Dataset\/FaceMask\/Labels","9b84823e":"# copy image files\n!cp -rf \/kaggle\/input\/face-mask-detection\/images\/* Dataset\/FaceMask\/Images","6be2e61f":"!mkdir -p Dataset\/images Dataset\/labels","7ab84f6f":"import os\nimport numpy as np\nfrom pathlib import Path\nfrom xml.dom.minidom import parse\nfrom shutil import copyfile","2f20b5c9":"FILE_ROOT = \"\/kaggle\/input\/face-mask-detection\/\"\nIMAGE_PATH = FILE_ROOT + \"images\"  \nANNOTATIONS_PATH = FILE_ROOT + \"annotations\"\n\nDATA_ROOT = \"Dataset\/\"\nLABELS_ROOT = DATA_ROOT + \"FaceMask\/Labels\"\nIMAGES_ROOT = DATA_ROOT + \"FaceMask\/Images\"  \n\nDEST_IMAGES_PATH = \"images\"\nDEST_LABELS_PATH = \"labels\" ","be0964dc":"classes = ['with_mask', 'without_mask', 'mask_weared_incorrect']","d1af54a2":"def cord_converter(size, box):\n    \"\"\"\n    convert xml annotation to darknet format coordinates\n    :param size\uff1a [w,h]\n    :param box: anchor box coordinates [upper-left x,uppler-left y,lower-right x, lower-right y]\n    :return: converted [x,y,w,h]\n    \"\"\"\n    x1 = int(box[0])\n    y1 = int(box[1])\n    x2 = int(box[2])\n    y2 = int(box[3])\n\n    dw = np.float32(1. \/ int(size[0]))\n    dh = np.float32(1. \/ int(size[1]))\n\n    w = x2 - x1\n    h = y2 - y1\n    x = x1 + (w \/ 2)\n    y = y1 + (h \/ 2)\n\n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return [x, y, w, h]\n\ndef save_file(img_jpg_file_name, size, img_box):\n    save_file_name = LABELS_ROOT + '\/' + img_jpg_file_name + '.txt'\n    print(save_file_name)\n    file_path = open(save_file_name, \"a+\")\n    for box in img_box:\n\n        cls_num = classes.index(box[0])\n\n        new_box = cord_converter(size, box[1:])\n\n        file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n\n    file_path.flush()\n    file_path.close()\n    \ndef get_xml_data(file_path, img_xml_file):\n    img_path = file_path + '\/' + img_xml_file + '.xml'\n    print(img_path)\n\n    dom = parse(img_path)\n    root = dom.documentElement\n    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n    img_size = root.getElementsByTagName(\"size\")[0]\n    objects = root.getElementsByTagName(\"object\")\n    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n    # print(\"img_name:\", img_name)\n    # print(\"image_info:(w,h,c)\", img_w, img_h, img_c)\n    img_box = []\n    for box in objects:\n        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n        # print(\"box:(c,xmin,ymin,xmax,ymax)\", cls_name, x1, y1, x2, y2)\n        img_jpg_file_name = img_xml_file + '.jpg'\n        img_box.append([cls_name, x1, y1, x2, y2])\n    # print(img_box)\n\n    # test_dataset_box_feature(img_jpg_file_name, img_box)\n    save_file(img_xml_file, [img_w, img_h], img_box)","a6d710dc":"files = os.listdir(ANNOTATIONS_PATH)\nfor file in files:\n    print(\"file name: \", file)\n    file_xml = file.split(\".\")\n    get_xml_data(ANNOTATIONS_PATH, file_xml[0])","decc9d51":"from sklearn.model_selection import train_test_split\nimage_list = os.listdir('Dataset\/FaceMask\/Images')\ntrain_list, test_list = train_test_split(image_list, test_size=0.2, random_state=7)\nval_list, test_list = train_test_split(test_list, test_size=0.5, random_state=8)\n\nprint('total =',len(image_list))\nprint('train :',len(train_list))\nprint('val   :',len(val_list))\nprint('test  :',len(test_list))","ad86f3f9":"def copy_data(file_list, img_labels_root, imgs_source, type):\n\n    root_file = Path(DATA_ROOT + DEST_IMAGES_PATH + '\/' + type)\n    if not root_file.exists():\n        print(f\"Path {root_file} is not exit\")\n        os.makedirs(root_file)\n\n    root_file = Path(DATA_ROOT + DEST_LABELS_PATH + '\/' + type)\n    if not root_file.exists():\n        print(f\"Path {root_file} is not exit\")\n        os.makedirs(root_file)\n\n    for file in file_list:\n        img_name = file.replace('.png', '')\n        img_src_file = imgs_source + '\/' + img_name + '.png'\n        label_src_file = img_labels_root + '\/' + img_name + '.txt'\n\n        # print(img_sor_file)\n        # print(label_sor_file)\n        # im = Image.open(rf\"{img_sor_file}\")\n        # im.show()\n\n        # Copy image\n        DICT_DIR = DATA_ROOT + DEST_IMAGES_PATH + '\/' + type\n        img_dict_file = DICT_DIR + '\/' + img_name + '.png'\n\n        copyfile(img_src_file, img_dict_file)\n\n        # Copy label\n        DICT_DIR = DATA_ROOT + DEST_LABELS_PATH + '\/' + type\n        img_dict_file = DICT_DIR + '\/' + img_name + '.txt'\n        copyfile(label_src_file, img_dict_file)","c1af2241":"copy_data(train_list, LABELS_ROOT, IMAGES_ROOT, \"train\")\ncopy_data(val_list,   LABELS_ROOT, IMAGES_ROOT, \"val\")\ncopy_data(test_list,  LABELS_ROOT, IMAGES_ROOT, \"test\")","0610222e":"!echo \"train: Dataset\/images\/train\" > data\/facemask.yaml\n!echo \"val:   Dataset\/images\/val\" >> data\/facemask.yaml\n!echo \"nc : 3\" >> data\/facemask.yaml\n!echo \"names: ['With_Mask', 'Without_Mask', 'Incorrect_Mask']\" >> data\/facemask.yaml\n\n!cat data\/facemask.yaml","9efa821a":"!python train.py --img 320 --batch 16 --epochs 300 --data data\/facemask.yaml --cfg models\/yolov5s.yaml --weights yolov5s.pt","43f18235":"# save trained weights for detection\n!cp runs\/train\/exp\/weights\/best.pt weights","a54e92ce":"!python detect.py --source Dataset\/images\/test --img-size 320 --conf 0.4 --weights weights\/best.pt ","560494da":"# display detected images\nfrom IPython.display import Image","57a5e38d":"from glob import glob\nimport matplotlib.pyplot as plt\ntestfiles = glob('runs\/detect\/exp\/*')\n\nimg = plt.imread(testfiles[0]) \nplt.imshow(img)    \nplt.show","dcbcf71d":"!python detect.py --source \/kaggle\/input\/input-images\/facemask.jpg --img-size 320 --conf 0.4 --weights weights\/best.pt ","6f4ab00c":"Image('runs\/detect\/exp2\/facemask.jpg')","d0f074a5":"!python detect.py --source \/kaggle\/input\/input-images\/facemask1.jpg --img-size 320 --conf 0.4 --weights weights\/best.pt ","adc46551":"Image('runs\/detect\/exp3\/facemask1.jpg')","21a6ae90":"## Create Dataset","f988d1a8":"### convert annotations (from COCO .xml to YOLO format .txt)","cbc48686":"## split Images dataset","d1edc5e6":"## Dataset: [Face Mask Detection](https:\/\/www.kaggle.com\/andrewmvd\/face-mask-detection)","9c120d37":"## Train YOLOv5","00cfdd6c":"### detect facemask","99481a23":"## Test YOLOv5","8ed58114":"## Repro [YOLOv5](https:\/\/github.com\/ultralytics\/yolov5)","dd21cc94":"## Create data\/facemask.yaml"}}