{"cell_type":{"d173cae0":"code","e611ea94":"code","b965df44":"code","9c044a6c":"code","d3bad0bd":"code","3877bef4":"code","4fc72b64":"code","f5e3913b":"code","240967cd":"code","a414ed1b":"code","4ebc1b35":"code","b9eaf910":"code","cf7ae2e0":"code","2c07e9c8":"code","fdc9aa49":"code","de81858b":"code","dc50d0d0":"code","af2f84e0":"code","dac5c613":"code","66568b51":"code","07c1a5e2":"code","0ce557d1":"code","7672acee":"code","a9711eca":"code","943c031d":"code","b60e30a1":"code","f7d27009":"code","e8d53c3c":"code","50e9e361":"code","5f788352":"code","72fbc62e":"code","41afabd5":"code","d4207979":"code","bc3920f6":"code","125027e4":"code","5184b83b":"code","9f2066b6":"code","0ac55d52":"code","8eee9bde":"code","35f04f35":"code","6ffbfbef":"code","54e2e6ca":"code","bdbecbff":"markdown","c1194221":"markdown","909b3259":"markdown","c9b48345":"markdown","4f02d53c":"markdown"},"source":{"d173cae0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e611ea94":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","b965df44":"data_1 = pd.read_csv(r\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(r\"\/kaggle\/input\/titanic\/test.csv\")\nsample = pd.read_csv(r\"\/kaggle\/input\/titanic\/gender_submission.csv\")","9c044a6c":"data_train = data_1.copy()\ndata_test = test.copy()","d3bad0bd":"# data_train.hist()","3877bef4":"data_train.corr()","4fc72b64":"data_train['Sex'] = data_train['Sex'].map({'male' : 0, 'female' : 1})\ndata_test['Sex'] = data_test['Sex'].map({'male' : 0, 'female' : 1})","f5e3913b":"data_train","240967cd":"data_train['Embarked'].unique()","a414ed1b":"data_train.info()","4ebc1b35":"data_train.drop(columns = ['PassengerId', 'Ticket', 'Cabin', 'Name', 'SibSp'], axis = 1, inplace = True)\ndata_test.drop(columns = ['PassengerId', 'Ticket', 'Cabin', 'Name', 'SibSp'], axis = 1, inplace = True)","b9eaf910":"data_train","cf7ae2e0":"data_train['Embarked'] = data_train['Embarked'].map({'S' : 0, 'C' : 1, 'Q' : 2})\ndata_test['Embarked'] = data_test['Embarked'].map({'S' : 0.0, 'C' : 1.0, 'Q' : 2.0})","2c07e9c8":"data_train","fdc9aa49":"plt.figure(figsize = (10, 8))\nplt.hist(data_train['Survived'], alpha = 0.5, color = 'blue')\nplt.xlabel(\"Survived\", color = \"blue\")\nplt.ylabel(\"Occurrence\", color = \"blue\")\nplt.show()","de81858b":"plt.figure(figsize = (10, 8))\nplt.hist(data_train['Sex'], alpha = 0.8, color = 'brown')\nplt.xlabel(\"Sex\", color = \"brown\")\nplt.ylabel(\"Occurrence\", color = \"brown\")\nplt.show()","dc50d0d0":"plt.figure(figsize = (10, 8))\nplt.hist(data_train['Pclass'], alpha = 0.8, color = 'orange')\nplt.xlabel(\"Pclass\", color = \"blue\")\nplt.ylabel(\"Occurrence\", color = \"blue\")\nplt.show()","af2f84e0":"plt.figure(figsize = (10, 8))\nplt.hist(data_train['Age'], alpha = 0.5, color = 'black')\nplt.xlabel(\"Age\", color = \"black\")\nplt.ylabel(\"Occurrence\", color = \"black\")\nplt.show()","dac5c613":"plt.figure(figsize = (10, 8))\nplt.scatter(data_train['Fare'], data_train['Age'], alpha = 0.3, color = 'green')\nplt.xlabel(\"Fare\", color = \"green\")\nplt.ylabel(\"Age\", color = \"green\")\nplt.show()","66568b51":"data_train['Age'] = data_train['Age'].fillna(data_train['Age'].mean())\ndata_test['Age'] = data_test['Age'].fillna(data_train['Age'].mean())","07c1a5e2":"data_test['Fare'] = data_test['Fare'].fillna(data_train['Fare'].mean())","0ce557d1":"data_train['Age']","7672acee":"data_train.info()","a9711eca":"data_train = data_train.dropna()\n","943c031d":"data_test.info()","b60e30a1":"data_train.info()","f7d27009":"X = data_train.drop(columns = ['Survived'], axis = 1)\ny = data_train['Survived']","e8d53c3c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","50e9e361":"model1 = LogisticRegression(C = 1)","5f788352":"model2 = DecisionTreeClassifier()","72fbc62e":"model3 = RandomForestClassifier(n_estimators = 700)","41afabd5":"model1.fit(X_train, y_train)","d4207979":"model1.score(X_test, y_test)","bc3920f6":"model2.fit(X_train, y_train)","125027e4":"model2.score(X_test, y_test)","5184b83b":"model3.fit(X_train, y_train)","9f2066b6":"model3.score(X_test, y_test)","0ac55d52":"data_test","8eee9bde":"data_train","35f04f35":"prediction = model3.predict(data_test)","6ffbfbef":"prediction","54e2e6ca":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': prediction})\noutput.to_csv('my_submission.csv', index=False)","bdbecbff":"# **Welcome to Titanic!!!**","c1194221":"**And, the third Model is Random Forest.**","909b3259":"**Second Model is Dicision Tree Classifier**","c9b48345":"**So the first Model is Logistic Regression.**","4f02d53c":"# Let's take her to the sea, Mr. Murdoch\n## \"Machine Learning\""}}