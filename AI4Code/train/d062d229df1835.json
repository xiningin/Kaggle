{"cell_type":{"46231684":"code","53392b7b":"code","ded3a9a1":"code","9e02b4cc":"code","abf0ccfc":"code","ab80516f":"code","a2286614":"code","96131dd0":"code","2db899de":"code","27159791":"code","c9256aa3":"code","dc4ad283":"code","cb742cbf":"code","5d738c36":"code","9eae67cf":"code","7a6635c8":"code","f2915480":"code","65549238":"code","dc02830b":"code","b1a67f60":"code","22d02f3c":"code","98da7550":"code","f563d0a1":"code","480668dd":"code","7b2b5f4b":"code","464c735a":"code","f8048462":"code","01914593":"code","fd0568d5":"code","93f40198":"code","a006a0f9":"code","24eda017":"code","fe49c970":"code","c0c5480d":"code","c692f4bb":"code","e632629f":"code","83172bde":"code","6ae154b5":"code","22266d4f":"code","fa8e2797":"code","678ad582":"code","76ec53b9":"code","1f80b903":"code","b8c6f183":"code","52cd1dfe":"code","f7287252":"code","39677f2f":"code","d757d9ae":"code","a5506284":"code","876ca816":"code","5da2908e":"code","c167ab34":"code","31b4eece":"code","8151e776":"code","6a5af53f":"code","ca358fca":"code","81120556":"code","4e499693":"code","1f2b01e0":"code","140a398c":"code","04027296":"code","246a24a9":"code","c3dba700":"code","755e4b67":"code","025f8657":"markdown","6b3d5dd5":"markdown","0bca4b3d":"markdown","a44a8497":"markdown","73eec49e":"markdown","7da30fdb":"markdown","edd5a201":"markdown","8bff7f95":"markdown","45a03ac1":"markdown","c9c6d5ba":"markdown","38e6c801":"markdown","19ed3e49":"markdown","d274196e":"markdown","da678df1":"markdown","1e20ae45":"markdown","1e68e28a":"markdown","66de6ee7":"markdown","6b033d97":"markdown","152c6e60":"markdown","b2bd1160":"markdown","7acd4bbf":"markdown","943b150b":"markdown","79638676":"markdown","4dbe4b2c":"markdown","f21851ff":"markdown","97c0341d":"markdown","43a28419":"markdown"},"source":{"46231684":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53392b7b":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","ded3a9a1":"test_df.shape","9e02b4cc":"test_df.head()","abf0ccfc":"train_df.head()","ab80516f":"train_df.info()","a2286614":"train_df.columns","96131dd0":"train_df.describe()","2db899de":"train_df.info()","27159791":"def bar_plot(variable):\n    var = train_df[variable]\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize = (9,5))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","c9256aa3":"category_1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\",\"Parch\"]\nfor a in category_1:\n    bar_plot(a)","dc4ad283":"category_2 = [\"Cabin\",\"Name\",\"Ticket\"]\nfor a in category_2:\n    print(\"{} \\n\".format(train_df[a].value_counts()))","cb742cbf":"def plot_hist(variable):\n    plt.figure(figsize = (9,5))\n    plt.hist(train_df[variable],bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","5d738c36":"numeric_var = [\"Fare\",\"Age\",\"PassengerId\"]\nfor c in numeric_var:\n    plot_hist(c)","9eae67cf":"train_df[[\"Pclass\",\"Survived\"]]","7a6635c8":"#Pclass vs Survived\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Survived\",ascending = True)","f2915480":"# Sex vs Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","65549238":"# SibSp vs Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","dc02830b":"#Parch vs Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","b1a67f60":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for a in features:\n        #1st quartile\n        Q1 = np.percentile(df[a],25)\n        #3rd quartile\n        Q3 = np.percentile(df[a],75)\n        #IQR\n        IQR = Q3 - Q1\n        #outlier step\n        outlier_step = IQR * 1.5\n        #detect outlier and their indeces\n        outlier_list_col = df[(df[a] < Q1 - outlier_step) | (df[a] > Q3 + outlier_step)].index\n        #store indeces\n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    return multiple_outliers","22d02f3c":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","98da7550":"# drop outliers\ntrain_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","f563d0a1":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)","480668dd":"train_df.head()","7b2b5f4b":"train_df.isnull().any()","464c735a":"train_df.columns[train_df.isnull().any()]","f8048462":"train_df.isnull().sum()","01914593":"def missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns","fd0568d5":"missing_values_table(train_df)","93f40198":"train_df.drop(\"Cabin\", inplace=True, axis=1)\n\nremove_vars = [\"Ticket\"]\ntrain_df.drop(remove_vars, inplace=True, axis=1)\ntrain_df.head()\n\n\ntrain_df[\"Embarked\"].value_counts()\ntrain_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0],inplace=True)\ntrain_df['Age'] = train_df['Age'].fillna(train_df.groupby('Sex')['Age'].transform('median'))","a006a0f9":"train_df[\"Survived\"].fillna(train_df.groupby(\"Sex\")['Survived'].transform('median'),inplace=True)","24eda017":"missing_values_table(train_df)","fe49c970":"train_df.Fare.fillna(train_df.Fare.mean(),inplace=True)","c0c5480d":"list1 = [\"SibSp\",\"Parch\",\"Age\",\"Fare\",\"Survived\"]\nsns.heatmap(train_df[list1].corr(),annot = True, fmt = \".2f\")\nplt.show()","c692f4bb":"f = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind=\"bar\", size = 6)\nf.set_ylabels(\"Survived Probability\")\nplt.show()","e632629f":"f = sns.factorplot(x = \"Parch\", y = \"Survived\",kind = \"bar\",data = train_df,size = 6)\nf.set_ylabels(\"Survived Probability\")\nplt.show()","83172bde":"f = sns.factorplot(x = \"Pclass\",y = \"Survived\", data = train_df,kind = \"bar\", size = 6) \nf.set_ylabels(\"Survived Probability\")\nplt.show()","6ae154b5":"f = sns.FacetGrid(train_df,col = \"Survived\")\nf.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","22266d4f":"f = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 2)\nf.map(plt.hist, \"Age\", bins = 25)\nf.add_legend()\nplt.show()","fa8e2797":"f = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\nf.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\nf.add_legend()\nplt.show()","678ad582":"f = sns.FacetGrid(train_df, row=\"Embarked\",col=\"Survived\",size = 2.3)\nf.map(sns.barplot,\"Sex\",\"Fare\")\nf.add_legend()\nplt.show()","76ec53b9":"train_df[train_df[\"Age\"].isnull()]","1f80b903":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind=\"box\")\nplt.show()","b8c6f183":"sns.factorplot(x = \"Sex\", y = \"Age\", hue=\"Pclass\",data = train_df, kind=\"box\")\nplt.show()","52cd1dfe":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","f7287252":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Pclass\",\"Parch\"]].corr(),annot = True)\nplt.show()","39677f2f":"index_nanAge = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nanAge:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) & (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"]) & (train_df[\"Pclass\"] == train_df.iloc[i][\"Parch\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","d757d9ae":"train_df[\"NEW_TITLE\"] = train_df[\"Name\"].str.extract(\" ([A-Za-z]+)\\. \", expand=False)\ntrain_df[\"NEW_NAME_COUNT\"] = train_df[\"Name\"].str.len()\ntrain_df[\"NEW_NAME_WORD_COUNT\"] = train_df.Name.apply(lambda name: len(str(name).split(\" \")))\ntrain_df[\"NEW_FAMILY_SIZE\"] = train_df.SibSp + train_df.Parch + 1\ntrain_df[\"NEW_AGE_PCLASS\"] = train_df.Age * train_df.Pclass\n\ntrain_df.loc[((train_df['SibSp'] + train_df['Parch']) > 0), \"NEW_IS_ALONE\"] = \"NO\"\ntrain_df.loc[((train_df['SibSp'] + train_df['Parch']) == 0), \"NEW_IS_ALONE\"] = \"YES\"\n\ntrain_df.loc[(train_df[\"Age\"] < 15), \"NEW_AGE_CAT\"] = \"child\"\ntrain_df.loc[(train_df[\"Age\"] >= 15) & (train_df[\"Age\"] < 25), \"NEW_AGE_CAT\"] = \"young\"\ntrain_df.loc[(train_df[\"Age\"] >= 25) & (train_df[\"Age\"] < 35), \"NEW_AGE_CAT\"] = \"adult\"\ntrain_df.loc[(train_df[\"Age\"] >= 35) & (train_df[\"Age\"] < 50), \"NEW_AGE_CAT\"] = \"mature\"\ntrain_df.loc[(train_df[\"Age\"] >= 50), \"NEW_AGE_CAT\"] = \"senior\"\n\ntrain_df.loc[(train_df[\"Sex\"] == \"male\") & (train_df[\"Age\"] < 15), \"NEW_SEX_CAT\"] = \"childmale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"male\") & (train_df[\"Age\"] >= 15) & (train_df[\"Age\"] < 25), \"NEW_SEX_CAT\"] = \"youngmale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"male\") & (train_df[\"Age\"] >= 25) & (train_df[\"Age\"] < 35), \"NEW_SEX_CAT\"] = \"adultmale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"male\") & (train_df[\"Age\"] >= 35) & (train_df[\"Age\"] < 50), \"NEW_SEX_CAT\"] = \"maturemale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"male\") & (train_df[\"Age\"] >= 50), \"NEW_SEX_CAT\"] = \"seniormale\"\n\ntrain_df.loc[(train_df[\"Sex\"] == \"female\") & (train_df[\"Age\"] < 15), \"NEW_SEX_CAT\"] = \"childfemale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"female\") & (train_df[\"Age\"] >= 15) & (train_df[\"Age\"] < 25), \"NEW_SEX_CAT\"] = \"youngfemale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"female\") & (train_df[\"Age\"] >= 25) & (train_df[\"Age\"] < 35), \"NEW_SEX_CAT\"] = \"adultfemale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"female\") & (train_df[\"Age\"] >= 35) & (train_df[\"Age\"] < 50), \"NEW_SEX_CAT\"] = \"maturefemale\"\ntrain_df.loc[(train_df[\"Sex\"] == \"female\") & (train_df[\"Age\"] >= 50), \"NEW_SEX_CAT\"] = \"seniorfemale\"","a5506284":"def label_encoder(dataframe, binary_col):\n    labelencoder = preprocessing.LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe","876ca816":"from sklearn import preprocessing\n\ntrain_df.columns = [col.upper() for col in train_df.columns]\n\n\n########################################################\n# Label Encoding\n########################################################\n\ntrain_df.head()\ntrain_df.shape\n\nbinary_cols = [col for col in train_df.columns if len(train_df[col].unique()) == 2 and train_df[col].dtypes == 'O']\n\nfor col in binary_cols:\n   train_df = label_encoder(train_df, col)\n\ntrain_df.columns\n\n\n########################################################\n# One-Hot Encoding\n########################################################\n\nohe_cols = [col for col in train_df.columns if 10 >= len(train_df[col].unique()) > 2]\n\ntrain_df = one_hot_encoder(train_df, ohe_cols, True)\n\ntrain_df.head()","5da2908e":"train_df.drop(labels = [\"PASSENGERID\"],axis = 1,inplace = True)","c167ab34":"train_df.columns","31b4eece":"train_df.drop(['NEW_TITLE','NAME'], axis=1, inplace=True)","8151e776":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","6a5af53f":"train_df_len","ca358fca":"test = train_df[train_df_len:]\ntest.drop(labels = [\"SURVIVED\"], axis = 1 , inplace = True)","81120556":"test.head()","4e499693":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"SURVIVED\", axis = 1)\nY_train = train[\"SURVIVED\"]\nX_train, X_test, Y_train , Y_test = train_test_split(X_train,Y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"Y_train\",len(Y_train))\nprint(\"Y_test\",len(Y_test))\nprint(\"test\",len(test))","1f2b01e0":"log_reg = LogisticRegression()\nlog_reg.fit(X_train,Y_train)\nacc_log_train = round(log_reg.score(X_train,Y_train)*100,2)\nacc_log_test = round(log_reg.score(X_test,Y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","140a398c":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","04027296":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,Y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","246a24a9":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","c3dba700":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, Y_train)\nprint(accuracy_score(votingC.predict(X_test),Y_test))","755e4b67":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","025f8657":"<a id = \"31\"><\/a><br>\n## Simple Logistic Regression","6b3d5dd5":"<a id = \"21\"><\/a><br>\n# Feature Engineering","0bca4b3d":"<a id = \"15\"><\/a><br>\n## Pclass - Survived","a44a8497":"<a id = \"30\"><\/a><br>\n## Train - Test - Split","73eec49e":"<a id = \"29\"><\/a><br>\n# Modeling","7da30fdb":"<a id = \"20\"><\/a><br>\n## Fill Missing : Age Feature","edd5a201":"<a id = \"12\"><\/a><br>\n## Visualization\n## Correlation Between SibSp - Parch - Age - Fare - Survived","8bff7f95":"<a id=\"5\"><\/a><br>\n## Numerical Variable","45a03ac1":"<a id = \"32\"><\/a><br>\n# Hyperparameter Tuning - Grid Search - Cross Validation\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","c9c6d5ba":"<a id = \"1\"><\/a> <br>\n# Load and Check","38e6c801":"<a id = \"8\"><\/a><br>\n## Missing Value\n* Find Missing Value\n* Fill Missing Value","19ed3e49":"# Introduction\n\nLet me be my first race kernel.\n\n<font color = 'blue'>\nContent: \n\n1. [Load and Check Data](#1)\n1. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable](#4)\n        * [Numerical Variable](#5)\n1. [Basic Data Analysis](#6)\n1. [Outlier Detection](#7)\n1. [Missing Value](#8)\n1. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing: Age Feature](#20)\n1. [Feature Engineering](#21)\n1. [Modeling](#29)\n    * [Train - Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32) \n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)","d274196e":"<a id = \"16\"><\/a><br>\n## Age - Survived","da678df1":"<a id = \"28\"><\/a><br>\n## Drop Passenger ID and Cabin","1e20ae45":"<a id =\"4\"><\/a><br>\n## Categorical Variable","1e68e28a":"<a id = \"19\"><\/a><br>\n## Embarked - Sex - Fare - Survived","66de6ee7":"<a id = \"33\"><\/a><br>\n## Ensemble Modeling","6b033d97":"* float64(2): Fare-Age\n* int64(5): PassengerId,Survived,Pclass,SibSp,Parch\n* object(5): Name,Sex,Ticket,Cabin,Embarked","152c6e60":"<a id = \"6\"><\/a><br>\n# Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","b2bd1160":"<a id =\"3\"><\/a><br>\n# Univariate Variable Analysis\n\n* Categorical Variable: Survived,Sex,Pclass,Embarked,Name,Cabin,Ticket,SibSp,Parch\n* Numerical Variable: Fare,Age,PassengerId","7acd4bbf":"<a id = \"14\"><\/a><br>\n## Parch - Survived","943b150b":"<a id = \"7\"><\/a><br>\n## Outlier Detection","79638676":"<a id = \"18\"><\/a><br>\n## Embarked - Sex - Pclass - Survived","4dbe4b2c":"<a id = \"34\"><\/a><br>\n## Prediction and Submission","f21851ff":"<a id = \"13\"><\/a><br>\n## SibSp - Survived","97c0341d":"<a id = \"17\"><\/a><br>\n## Pclass - Survived - Age","43a28419":"<a id = \"2\"><\/a> <br>\n# Variable Description\n\n1. PassengerId: unique id number to each passenger\n2. Survived: passenger 1(survive) or 0(died)\n3. Pclass: passenger class\n4. Name: name\n5. Sex: gender of passengers\n6. Age: age of passengers\n7. SibSp: number of siblings\/spouses\n8. Parch: number of parents\/children\n9. Ticket: ticket number\n10. Fare: amount of money ticket\n11. Cabin: cabin category\n12. Embarked: port where passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton)"}}