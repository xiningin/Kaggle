{"cell_type":{"b0524766":"code","ccc63079":"code","2a668114":"code","9e2d95f1":"code","89fac49c":"code","435a1b58":"code","80adf9c3":"code","78cbb8bd":"markdown","0b103da8":"markdown","80f6556a":"markdown","a0d555b3":"markdown","83cac4af":"markdown"},"source":{"b0524766":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport gc\nimport pathlib\nfrom tqdm.auto import tqdm\nimport joblib\nimport pathlib\nimport json\nimport glob\nimport time\nimport datetime\nfrom scipy import stats\nfrom multiprocessing import Pool, cpu_count\n\n# models\nfrom sklearn import linear_model\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nfrom matplotlib_venn import venn2, venn3\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('seaborn-colorblind')\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ccc63079":"# train = pd.read_parquet('..\/input\/ubiquant-parquet\/train.parquet')\ntrain = pd.read_parquet('..\/input\/ubiquant-parquet\/train_low_mem.parquet')\n\nprint(train.shape)\ntrain.head()","2a668114":"ss = pd.read_csv('\/kaggle\/input\/ubiquant-market-prediction\/example_sample_submission.csv')\nprint(ss.shape)\nss.head()","9e2d95f1":"features = train.columns[train.columns.str.startswith('f_')].values.tolist()\nprint(len(features), features)","89fac49c":"# fit a linear model\nmodel = linear_model.Ridge()\nmodel.fit(train[features], train['target'])","435a1b58":"# coef\nfeature_importance = pd.DataFrame()\nfeature_importance['features'] = features\nfeature_importance['weight'] = model.coef_.ravel()\n\nfeature_importance.sort_values(by=['weight'], ascending=False).style.background_gradient(cmap='viridis')","80adf9c3":"%%time\nimport ubiquant\n\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:    \n    sample_prediction_df['target'] = model.predict(test_df[features])  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions","78cbb8bd":"# Libraries","0b103da8":"# Submission","80f6556a":"# Modeling","a0d555b3":"# Load data","83cac4af":"In my (limited) experience in the financial ML, it is better to start simple. \n\nAs this is my very first notebook in this competition, I decided to use a linear model as my baseline. By using a linear model, we can effectively see how each anonymized feature is associated with the target.\n\nI use the following parquet file to fit everything within this notebook.\n\n[\u23eb Fast Data Loading and Low Mem with Parquet Files](https:\/\/www.kaggle.com\/robikscube\/fast-data-loading-and-low-mem-with-parquet-files)\n\nSo let's get it started!"}}