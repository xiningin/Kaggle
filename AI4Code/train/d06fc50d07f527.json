{"cell_type":{"a9ed29dc":"code","71568271":"code","e98f320d":"code","7daf4339":"code","e968776d":"code","4b92916d":"code","8ee4e875":"code","f675c5c6":"code","0c897b1e":"code","a89843ed":"code","4c787e73":"code","876a77cb":"code","02f6ebc8":"code","13ae8fcd":"code","bcecd313":"code","fe836ea0":"code","46530906":"code","231a842b":"code","cbe26a06":"code","c7b1fff4":"code","f02a342e":"code","c4d3375c":"code","a467bed3":"code","f36b996c":"code","36799320":"code","2745ace3":"markdown","ff69cfe3":"markdown","5f1100d1":"markdown","c44831a6":"markdown","fe028d90":"markdown","beea1cd4":"markdown","40173a8b":"markdown","30578de6":"markdown","bf550389":"markdown","5560f40f":"markdown","95c3b03f":"markdown","abaca14e":"markdown"},"source":{"a9ed29dc":"import warnings\nwarnings.filterwarnings(\"ignore\") ","71568271":"!pip install onnxruntime > \/dev\/null","e98f320d":"import os\nimport numpy as np\nimport pandas as pd\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport onnxruntime\n\nfrom tqdm.notebook import tqdm\nfrom scipy.io import loadmat \nfrom matplotlib import pyplot as plt","7daf4339":"import torch\nprint(torch.__version__)","e968776d":"class Config:\n    OUTPUT_PATH = '.\/'\n    DATA_FILE = '..\/input\/mnist-original\/mnist-original.mat'\n    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n    OUTPUT_MODEL_FILE = os.path.join(OUTPUT_PATH, f'mnist_{DEVICE}.pth')\n    ONNX_FILE = f'mnist.onnx'\n    N_EPOCH = 20\n    N_CLASSES = 10\n    SEED = 42,\n    LEARNING_RATE = 0.01\n    BATCH_SIZE = 32","4b92916d":"print(f'Using {Config.DEVICE} device.')","8ee4e875":"def to_numpy(tensor):\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()","f675c5c6":"def read_mnist_data(data_file=Config.DATA_FILE):\n    \"\"\"\n    \"\"\"\n    mnist = loadmat(data_file)\n    data = mnist['data'].T\n    labels = mnist['label'][0].astype(np.float)\n    \n    return data, labels\n                    \nmnist, labels = read_mnist_data()","0c897b1e":"def plot_mnist(X, y, y_pred=None, nrows=2, ncols=5):\n    \"\"\"\n    \"\"\"\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 8))\n\n    ypred = y if y_pred is None else y_pred\n    for data, label, pred, ax in zip(X, y, ypred, axes.flatten()):\n        c = 'red' if label != pred else 'black'\n        title = f'{int(label)} (pred: {int(pred)})' if y_pred is not None else int(label)\n        \n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n        ax.set_title(title, fontsize=18, color=c)\n        \n        ax.imshow(\n            data.reshape((28, 28)), \n            cmap=plt.cm.gray_r, \n            interpolation='nearest'\n        )\n\n    plt.show()","a89843ed":"idx = np.random.random_integers(mnist.shape[0], size=10)\nplot_mnist(mnist[idx], labels[idx])    ","4c787e73":"from torch.utils.data import Dataset\n\nclass MNISTDataset(Dataset):\n    \"\"\"\n    \"\"\"\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        image = self.X[idx].reshape((28, 28))\n        label = self.y[idx]\n        \n        return image, label","876a77cb":"from sklearn.model_selection import train_test_split\n\n# spit data into train and validation data sets\nX_train, X_vaild, y_train, y_vaild = train_test_split(\n    mnist, \n    labels, \n    test_size=0.3, \n    random_state=42\n)\n\nprint(f'Train size: {X_train.shape[0]}')\nprint(f'Validation size: {X_vaild.shape[0]}')","02f6ebc8":"train_set = MNISTDataset(X_train, y_train)\nvalid_set = MNISTDataset(X_vaild, y_vaild)","13ae8fcd":"from torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\nvalid_loader = DataLoader(valid_set, batch_size=64, shuffle=True)","bcecd313":"class MNISTNetwork(nn.Module):\n    def __init__(self):\n        super(MNISTNetwork, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=0),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n                      \n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=800, out_features=1024, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=1024, out_features=512, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=512, out_features=10, bias=True),\n            nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        return self.classifier(x)\n","fe836ea0":"model = MNISTNetwork().to(Config.DEVICE)\nprint(model)","46530906":"# check CNN model\ndummy_input = torch.randn([Config.BATCH_SIZE, 1, 28, 28]).to(Config.DEVICE)\n\npred =  model(dummy_input.float())\npred.size()","231a842b":"def train_loop(dataloader, model, loss_fn, optimizer):\n    \"\"\"\n    \"\"\"\n    size = len(dataloader.dataset)\n    train_loss = 0\n    \n    model.train()\n    \n    progress =  tqdm(enumerate(dataloader), total=len(dataloader))\n    for batch, (X, y) in progress:\n        X = X.to(Config.DEVICE).unsqueeze(1)\n        y = y.to(Config.DEVICE)\n        \n        # Compute prediction and loss\n        pred = model(X.float())\n        loss = loss_fn(pred, y.long())\n    \n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += np.mean(loss.item())\n        \n    return train_loss \/ size","cbe26a06":"def validation_loop(dataloader, model, loss_fn):\n    \"\"\"\n    \"\"\"\n    size = len(dataloader.dataset)\n    \n    accuracy = 0\n    valid_loss = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        for X, y in dataloader:\n            X = X.float().to(Config.DEVICE).unsqueeze(1)\n            y = y.to(Config.DEVICE)\n\n            pred = model(X)\n\n            valid_loss += loss_fn(pred, y.long()).item()\n            accuracy += (pred.argmax(1) == y).type(torch.float).sum().item()\n            \n    valid_loss \/= size\n    accuracy \/= size\n\n    print(f\"Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\")\n    return valid_loss, accuracy\n","c7b1fff4":"%%time\n\ntrain_losses = []\ntest_losses = []\naccuracies = []\n\n# initialize the loss function\nloss_fn = nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = torch.optim.SGD(\n    model.parameters(),\n    lr=Config.LEARNING_RATE\n)\n\nfor t in range(Config.N_EPOCH):\n    print(f'Epoch {t+1}')\n    \n    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n    train_losses.append(train_loss)\n    \n    valid_loss, accuracy = validation_loop(valid_loader, model, loss_fn)\n    test_losses.append(valid_loss)\n    accuracies.append(accuracy)","f02a342e":"from matplotlib.ticker import MaxNLocator \n\ndef plot_result(valid_loader, test_losses, accuracies):\n    x = list(range(1, len(train_losses) + 1))\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 7))\n    \n    ax[0].plot(x, train_losses, label='Training loss', marker ='o')\n    ax[0].plot(x, test_losses, label='Validation loss', marker ='o')\n    ax[0].legend(frameon=False, fontsize=14)\n    \n    ax[0].get_xaxis().set_major_locator(MaxNLocator(integer=True))\n    ax[0].set_title('Loss vs. Number of Iterations', fontsize=18)\n    ax[0].set_xlabel('Epoch', fontsize=14) \n    ax[0].set_ylabel('Loss', fontsize=14)  \n    \n    ax[1].plot(x, accuracies, label='Accuracy', marker ='o')\n    ax[1].legend(frameon=False, fontsize=14)\n    \n    ax[1].get_xaxis().set_major_locator(MaxNLocator(integer=True))\n    ax[1].set_title('Accuracy vs Number of Iterations', fontsize=18)\n    ax[1].set_xlabel('Epoch', fontsize=14) \n    ax[1].set_ylabel('Accuracy', fontsize=14)          \n        \n    plt.show()\n\nplot_result(train_losses, test_losses, accuracies)    ","c4d3375c":"_, (X, y) = next(enumerate(valid_loader))\n\nX = X.unsqueeze(1)\nX = X.to(Config.DEVICE).float()\n\ny_pred = to_numpy(torch.argmax(model(X), dim=1))\ny_test = to_numpy(y)\n\nplot_mnist(to_numpy(X), y_test, y_pred)","a467bed3":"# export as ONNX\ndef export_model(model):\n    dummy_input = torch.randn([1, 1, 28, 28]).to(Config.DEVICE)\n    input_names = ['input']\n    output_names = ['output']\n\n    # variable batch_size \n    dynamic_axes= {'input':{ 0:'batch_size'}, 'output':{ }}\n\n    torch.onnx.export(\n        model,\n        dummy_input,\n        f=Config.ONNX_FILE,\n        input_names=input_names,\n        output_names=output_names,\n        dynamic_axes=dynamic_axes\n    )\n    \nexport_model(model)","f36b996c":"# save model as PyTorch\ndef save_model(model, save_path=Config.OUTPUT_MODEL_FILE):\n    torch.save(model.state_dict(), save_path)\n    \nsave_model(model)    ","36799320":"session = onnxruntime.InferenceSession(Config.ONNX_FILE)\n\n# compute ONNX Runtime output prediction\ninputs = { 'input': to_numpy(X.float()) }\noutputs = session.run(None, inputs)\n\ny = np.argmax(outputs[0], axis=1)\nplot_mnist(to_numpy(X), y)","2745ace3":"## Plot digits","ff69cfe3":"## Load MNIST data","5f1100d1":"# MNIST - PyTorch - ONNX\n\nThis is a beginner notebook for PyTorch. We create a CNN network for the MNIST dataset and then save it as an ONNX file. ","c44831a6":"## Dataset and Loader","fe028d90":"## Save model","beea1cd4":"## Make predictions","40173a8b":"## Visualize","30578de6":"## Configuration","bf550389":"## Define model","5560f40f":"## Import modules","95c3b03f":"## Training Loop","abaca14e":"## Reload model"}}