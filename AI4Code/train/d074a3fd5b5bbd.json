{"cell_type":{"c874c448":"code","45820e06":"code","ae77bfd3":"code","6c45323c":"code","373ce34e":"code","f6573a92":"code","d58e4245":"code","3d161a8a":"code","16b59b95":"code","ffe85869":"code","4f4bff54":"code","d61cdc32":"markdown","6120079a":"markdown","bec7acfa":"markdown","4af16707":"markdown","d321e048":"markdown","fcf5ad33":"markdown","0f73dda3":"markdown","1489afe0":"markdown","e17c28e7":"markdown","4ae8adc0":"markdown","80fdfd23":"markdown","dd6881ac":"markdown"},"source":{"c874c448":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","45820e06":"## importing the required library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n## keras modules\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras import optimizers\nfrom keras.layers import LeakyReLU","ae77bfd3":"##Loading data\ndf_train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","6c45323c":"## Label Distribution of the data\nlabels = df_train[\"label\"]\ndist = labels.value_counts()\nprint(dist)\nsns.barplot(dist.index,dist)","373ce34e":"### Converting the data to a numpy array\ntrain = np.array(df_train)\nY_train = train[:,0]\nX_train = train[:,1:]","f6573a92":"### Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=np.random.seed(1))","d58e4245":"model = Sequential()\nmodel.add(Dense(800, input_dim=784, activation=\"sigmoid\",kernel_initializer='random_normal'))\nmodel.add(Dense(600, activation=LeakyReLU(0.3)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(200, activation=LeakyReLU(0.3)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(100, activation=LeakyReLU(0.5)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(50, activation=LeakyReLU(0.5)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax'))","3d161a8a":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, Y_train, epochs=100, batch_size=512,validation_data=(X_val,Y_val))\n_, accuracy_train = model.evaluate(X_train, Y_train)\nprint('Accuracy_train: %.2f' % (accuracy_train*100))","16b59b95":"Y_pred = model.predict_classes(X_val)\ncm = confusion_matrix(Y_val, Y_pred)\nplt.figure(figsize = (10,7))\nsns.heatmap(cm, annot=True,fmt='g')\nplt.show()","ffe85869":"count = 0\nfor i in range(Y_pred.shape[0]):\n    if Y_pred[i] != Y_val[i] and count<10:\n        img = X_val[i].reshape(28,28)\n        plt.imshow(img)\n        plt.show()\n        print(\"Predited Value:\",Y_pred[i])\n        print(\"True Value:\",Y_val[i])\n        count = count + 1","4f4bff54":"test = np.array(df_test)\nY_pred = model.predict_classes(test)\nimageid = np.array([i for i in range(1,28001)])\nout = np.array((imageid,Y_pred))\nout_df = pd.DataFrame(out,index = [\"ImageId\",\"Label\"],dtype = \"int64\")\nout_df = out_df.T\nout_df\nexport_csv = out_df.to_csv(\"submission.csv\",header = True,index = False)","d61cdc32":"**Plotting the confusion Matrix**","6120079a":"The accuracy will increase if rerun the model fit again with more epochs as the training will proceed on top of pretrained model weights (transfer learning).","bec7acfa":"**Deploying the model**","4af16707":"**1. Importing Required Library**","d321e048":"**Designing The Model**","fcf5ad33":"The issue mostly is with 4 and 9 predictions","0f73dda3":"**Splitting the Data into Train and  Validation Sets.**","1489afe0":"* ** Thank You for viewing this, an upvote will help a lot**","e17c28e7":"**3. Data Visulatization**","4ae8adc0":"**2. Loading Data**","80fdfd23":"**The Cases where the model failed to correctly identify the correct value**","dd6881ac":"**Converting Data to numpy array**"}}