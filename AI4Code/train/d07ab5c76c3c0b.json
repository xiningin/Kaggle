{"cell_type":{"cf04997b":"code","29c6f5aa":"markdown"},"source":{"cf04997b":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n#foudn the minimum value of n_estimator \nn_estimator=126\n#load data\niowa_train_path='..\/input\/train.csv'\niowa_train_data=pd.read_csv(iowa_train_path)\niowa_test_path='..\/input\/test.csv'\niowa_test_data=pd.read_csv(iowa_test_path)\nx = iowa_train_data.drop(['SalePrice'], axis=1)\ny=iowa_train_data.SalePrice\n#now split the train and test set between the two \ntrain_x, test_x, train_y, test_y=train_test_split(x,y,train_size=0.99,test_size=0.01, random_state = 0)\n#use the one hot encoding for the training set \ntrain_low_cardinality_cols = [cname for cname in train_x.columns if \n                                train_x[cname].nunique() < 10 and\n                                train_x[cname].dtype == \"object\"]\ntrain_numeric_cols = [cname for cname in train_x.columns if \n                                train_x[cname].dtype in ['int64', 'float64']]\ntrain_total_cols=train_low_cardinality_cols+train_numeric_cols\nprint(len(train_total_cols))\ntrain_x_cardinal = train_x[train_total_cols]\ntest_x_cardinal = test_x[train_total_cols]\npred_test_x_cardinal=iowa_test_data[train_total_cols]\n#print(train_x_cardinal.shape)\n#print(test_x_cardinal.shape)\n#test set \ntrain_x_one_hot_encoded=pd.get_dummies(train_x_cardinal)\ntest_x_one_hot_encoded=pd.get_dummies(test_x_cardinal)\npred_test_x_one_hot_encoded=pd.get_dummies(pred_test_x_cardinal)\nprint(train_x_one_hot_encoded.shape)\nprint(test_x_one_hot_encoded.shape)\n#now aligning the two \ntrain_x_final, test_x_final = train_x_one_hot_encoded.align(test_x_one_hot_encoded,\n                                                                    join='left', \n                                                             axis=1)\nprint(train_x_final.shape)\nprint(test_x_final.shape)\n#trying to align teh predic_train \ntrain_x_final_copy=train_x_final.copy()\npred_train_x_final,pred_test_x_final=train_x_final_copy.align(pred_test_x_one_hot_encoded,join='left',axis=1)\nprint(train_x_final_copy.shape)\nprint(pred_test_x_one_hot_encoded.shape)\nprint(pred_train_x_final.shape)\nprint(pred_test_x_final.shape)\nfinal_test_set=pred_test_x_final\n#call the imputer on the train and test data \nfrom sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\n\nimputed_train_x_plus = train_x_final.copy()\nimputed_test_x_plus=test_x_final.copy()\nimputed_final_test_x_plus=final_test_set.copy()\ncols_with_missing = {col for col in train_x_final.columns \n                                 if train_x_final[col].isnull().any()}\nfor col in cols_with_missing:\n    imputed_train_x_plus[col + '_was_missing'] = imputed_train_x_plus[col].isnull()\n    imputed_test_x_plus[col + '_was_missing'] = imputed_test_x_plus[col].isnull()\n    imputed_final_test_x_plus[col + '_was_missing'] = imputed_final_test_x_plus[col].isnull()\nimputed_train_x_plus = my_imputer.fit_transform(imputed_train_x_plus)\nimputed_test_x_plus=my_imputer.transform(imputed_test_x_plus)\nimputed_final_test_x_plus=my_imputer.transform(imputed_final_test_x_plus)\n#print(imputed_train_x_plus.shape)\n#print(imputed_test_x_plus.shape)\n#print(train_y.shape)\n#print(test_y.shape)\n#obtained a numpy array of the test and train data \n#function for computing the mae for xgboost given a particular learning rate, number of iterations ,train and test dataset\n#importing the mean square scikit metric \nfrom xgboost import XGBRegressor\nmy_model = XGBRegressor(n_estimators=127, learning_rate=0.7,random_state=1)\nmy_model.fit(imputed_train_x_plus, train_y, early_stopping_rounds=5, \n             eval_set=[(imputed_test_x_plus, test_y)], verbose=False)\n\npred=my_model.predict(imputed_final_test_x_plus)\noutput = pd.DataFrame({'Id': iowa_test_data.Id,\n                       'SalePrice': pred})\noutput.to_csv('submission.csv', index=False)","29c6f5aa":"Hello All ,\nThis kernel is realted to the iowa dataset where we use cardinality to hot encode the string colums and use imputation to fit to the NAN values .Please have a look at the code below : \n\n**Your submission scored 17266.76666, which is an improvement of your previous score of 18282.02181. Great job!**\nWe hope to improve the model further as the course progresses :-).\n\n"}}