{"cell_type":{"3f244b7d":"code","ce2907e5":"code","7b157661":"code","2ef08003":"code","68e377c7":"code","ed636700":"code","5e67f8b5":"code","f94af3aa":"code","99b9f9cb":"code","13d74651":"code","0c394b71":"code","ed0b95fc":"code","25bbbac8":"code","26fbcc88":"code","dd098bfe":"code","9c986351":"code","49019597":"code","fb5e6981":"code","aa02d521":"code","7dff585d":"code","7d8dae73":"code","2c88e4c7":"code","6b095cdf":"code","2f2c33f6":"code","e7a9301c":"code","e78c19d7":"code","3e562cb1":"code","67c97ecf":"code","19e7e92a":"code","5aa3fbe5":"code","eac76aac":"code","27c8e384":"code","61c3a2d7":"code","d0fc4db4":"code","c071bdc8":"code","213fed42":"code","2e2f5e13":"code","38df6cd6":"code","f162a926":"code","47bd5ea1":"code","8de5c94f":"code","84040c5f":"markdown","88b0877a":"markdown","6dd5749c":"markdown","aeab6a1c":"markdown","c20b2a62":"markdown","2f785e0d":"markdown","8fae198b":"markdown","650f816a":"markdown","c877718b":"markdown","9a7bec64":"markdown","19075498":"markdown","7842542e":"markdown","391ab7b3":"markdown","7ce5e59c":"markdown","0731d6aa":"markdown","3b0bf85b":"markdown","19a9c703":"markdown","804eaaae":"markdown","abb0e915":"markdown","e34468b6":"markdown","d8e75361":"markdown","76d5c36c":"markdown","2196f0cd":"markdown","9c90056e":"markdown"},"source":{"3f244b7d":"! conda install -q -c conda-forge gdcm -y","ce2907e5":"from fastai.vision.all import *","7b157661":"datapath = Path(\"..\/input\/siim-covid19-detection\/\")\nimage_df = pd.read_csv(datapath\/'train_image_level.csv')\nstudy_df = pd.read_csv(datapath\/'train_study_level.csv')\nsample_sub_df = pd.read_csv(datapath\/'sample_submission.csv')","2ef08003":"image_df.shape, study_df.shape, sample_sub_df.shape","68e377c7":"image_df.head()","ed636700":"study_df.head()","5e67f8b5":"sample_sub_df.head()","f94af3aa":"assert len(sample_sub_df['id'].unique()) == sample_sub_df.shape[0]","99b9f9cb":"image_counts = Counter(image_df.groupby(\"StudyInstanceUID\")[\"id\"].apply(lambda o: len(list(o)))); print(image_counts)\nx,h=list(zip(*image_counts.items()))\nfig,ax=plt.subplots(1,1);ax.bar(x,h); ax.set_xticks(x);","13d74651":"assert (study_df.iloc[:,1:].sum(1)==1).all()","0c394b71":"pd.DataFrame(study_df.iloc[:,1:].value_counts(),columns=['count'])","ed0b95fc":"study_df['StudyInstanceUID'] = study_df['id'].apply(lambda o: o[:-6])\nmerged_df = image_df.merge(study_df.drop('id',1),how='left',on='StudyInstanceUID')\nmerged_df[\"num_images\"] = merged_df[\"StudyInstanceUID\"].map(merged_df.groupby('StudyInstanceUID').apply(lambda o: len(o)))\nmerged_df.head()","25bbbac8":"merged_df.sort_values(\"num_images\", ascending=False).head(10)","26fbcc88":"def proc_labels(labels):\n    if isinstance(labels,str):\n        res = []\n        for l in list(chunked(labels.split(), chunk_sz=6)):\n            class_label, conf, bb = l[0], eval(l[1]), array(l[2:],dtype=np.float)\n            res.append([class_label, conf, bb])\n        return res\n    else: return","dd098bfe":"merged_df.head(3)","9c986351":"bboxes = [eval(o) if isinstance(o,str) else o for o in merged_df['boxes'].values]; bboxes[:3]","49019597":"labels = merged_df['label'].apply(proc_labels).values; labels[:3]","fb5e6981":"array([bboxes[0][0]['x'], bboxes[0][0]['y'], bboxes[0][0]['x'] + bboxes[0][0]['width'], bboxes[0][0]['y'] + bboxes[0][0]['height']]), labels[0][0]","aa02d521":"class_label_pat = '[a-zA-Z]+'\ndef get_class_labels(s): return re.findall(class_label_pat,s)\nunique_class_labels = np.unique(np.concatenate(merged_df['label'].apply(get_class_labels)))","7dff585d":"unique_class_labels","7d8dae73":"assert (study_df.sum(1)==1).all()","2c88e4c7":"merged_df[merged_df['Negative for Pneumonia'] == 1]['label'].unique()","6b095cdf":"non_negative = merged_df[merged_df['Negative for Pneumonia'] == 0]\nposstudy2boxes = dict(non_negative.groupby(\"StudyInstanceUID\")['boxes'].apply(list))\n\nnonnegative_studies_without_bboxes = []\nfor k in posstudy2boxes:\n    v = posstudy2boxes[k]\n    if len(v) == 1:\n        if not isinstance(v[0],str): nonnegative_studies_without_bboxes.append(k)","2f2c33f6":"merged_df.query(f\"StudyInstanceUID == {nonnegative_studies_without_bboxes}\")","e7a9301c":"merged_df.query(f\"StudyInstanceUID == {nonnegative_studies_without_bboxes}\").iloc[:,-5:-1].value_counts()","e78c19d7":"study_df.query(\"id=='ff0879eb20ed_study'\")","3e562cb1":"merged_df.query(\"StudyInstanceUID == 'ff0879eb20ed'\")","67c97ecf":"import pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom PIL import ImageOps\nfrom matplotlib import patches","19e7e92a":"trainfiles = get_files(datapath\/\"train\", extensions=\".dcm\")\nimage_id2fname = {o.stem:o for o in trainfiles}\nassert len(image_id2fname) == len(image_df) # no overlapping image ids in different studies","5aa3fbe5":"next(iter(image_id2fname.items()))","eac76aac":"#from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\ndef read_xray(path, voi_lut = True, fix_monochrome = True, equalize=False):\n    dicom = pydicom.read_file(path)\n\n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n    # add equalization similar to MIMIC-CXR JPG\n    img = Image.fromarray(data, mode='L')\n    if equalize: img = ImageOps.equalize(img)\n    return img","27c8e384":"random_study_id = merged_df[merged_df['Negative for Pneumonia']==0].query(\"num_images == 1\")['StudyInstanceUID'].sample(1).values[0]\nrow = merged_df.query(f\"StudyInstanceUID == '{random_study_id}'\");row","61c3a2d7":"row_arr = array(row)[0]\nimage_id, bboxes, labels = row_arr[0][:-6], eval(row_arr[1]), proc_labels(row_arr[2])","d0fc4db4":"img     = read_xray(image_id2fname[image_id], voi_lut=False)\nimg_voi = read_xray(image_id2fname[image_id], voi_lut=True)\nimg_eq  = read_xray(image_id2fname[image_id], voi_lut=True, equalize=True)","c071bdc8":"fig,ax = plt.subplots(1,3,figsize=(20,7))\nax[0].imshow(img.to_thumb(360),cmap='gray');     ax[0].set_title(\"original\")\nax[1].imshow(img_voi.to_thumb(360),cmap='gray'); ax[1].set_title(\"voi lut\");\nax[2].imshow(img_eq.to_thumb(360),cmap='gray');  ax[2].set_title(\"hist eq\");","213fed42":"bboxes, labels","2e2f5e13":"fig,ax = plt.subplots(1,1,figsize=(10,10))\nax.imshow(img_eq,cmap='gray')\nfor bb in bboxes: \n    lx,ly,w,h, = bb['x'],bb['y'], bb['width'], bb['height']\n    ax.add_patch(patches.Rectangle((lx,ly), w, h, fill=False, edgecolor='red', lw=2))","38df6cd6":"random_study_id = merged_df[merged_df['Negative for Pneumonia']==0].query(\"num_images > 1\")['StudyInstanceUID'].sample(1).values[0]\nrows = merged_df.query(f\"StudyInstanceUID == '{random_study_id}'\");rows","f162a926":"fnames = [image_id2fname[o[:-6]] for o in rows['id'].values]\nimgs   = [read_xray(o,equalize=True) for o in fnames]\nbboxes = [eval(o) if isinstance(o,str) else o for o in rows['boxes'].values]\nlabels = list(proc_labels(o) for o in rows['label']) # xmin,ymin,xmax,ymax","47bd5ea1":"fnames,bboxes, labels","8de5c94f":"fig,axes = plt.subplots(1,len(imgs),figsize=((len(imgs))*7, 15))\naxes = axes.flatten()\nfor fn,im,bbs,ax in zip(fnames, imgs,bboxes,axes):\n    ax.imshow(im,cmap='gray')\n    ax.set_title(fn.name)\n    if isinstance(bbs,list):\n        for bb in bbs: \n            lx,ly,w,h, = bb['x'],bb['y'], bb['width'],bb['height']\n            ax.add_patch(patches.Rectangle((lx,ly), w, h, fill=False, edgecolor='red', lw=2))","84040c5f":"We can see that all bounding boxes are labeled as `opacity` in `label` if not `none`.","88b0877a":"**Study labels are mutually exclusive**\n\nEach study has exactly 1 label, e.g. `negative|typical|indeterminate|atypical` don't coexist","6dd5749c":"#### B. Study with multiple images and pneumonia","aeab6a1c":"We can see that `boxes` have x1,y1 (upper left coordinate) and width and height information. `labels` have `x1,y1,x2,y2` coordinate format which can be constructed from `x1,x2,x1+width,y1+height`. This means during submission we will use `x1,y1,x2,y2` format.","c20b2a62":"Let's see if `negative` classes have any bboxes, if not maybe that is what meant by no finding. \n\nAll negative studies indeeed have `none 1 0 0 1 1` as their labels. I am not a medical expert but I assume we can expect to see bbox annotations of an opacity which can be a negative case of pneumonia. \n\nAlthough, in training dataset we don't have any such cases. This is an important information for the formulation of the problem.\n\nIn this case are we going to submit a study with `Negative for Pneumonia == 1` as `none 1 0 0 1 1` or `negative 1 0 0 1 1`?","2f785e0d":"Note that for studies with more than 1 image, we need to predict the union, e.g. if there exists at least one positve bounding box prediction with either `typical|indeterminate|atypical` finding then submission can't be `negative` or `none`.","8fae198b":"Here, we access the `.pixel_array` the image from the dicom dataset, do min-max normalization, convert the image to unsigned integer and finally apply histogram equalization to enhance the contrast.","650f816a":"There are 82 non negative without any bounding box.","c877718b":"At image level data we only have `opacity` label if there is a bounding box annotation, which doesn't tell us much. For accessing labels we need to use the study level labels. ","9a7bec64":"### Let's Visualize","19075498":"We are expected to make prediction for each study for each finding if there is any:\n\nThere are 4 possible classes: \"negative\", \"typical\", \"indeterminate\", \"atypical\"\n\n- If there are no findings for a given study we will submit: `none 1 0 0 1 1` \n\n- If there are any findings for a given study we will submit `negative|typical|indeterminate|atypical <confidence> <x1,y1,x2,y2>`","7842542e":"Now that we know the format of the bboxes we can visualize few examples","391ab7b3":"We can see that study level predictions requires consideration of all images as expected","7ce5e59c":"### Understanding Submission","0731d6aa":"To summarize, we can cosntruct this problem as an object detection problem with class labels `typical|indeterminate|atypical` since we don't have any bounding box annotations for `negative` cases. Additionally we can also predict a `no object|no finding|negative` similar to DETR. This framing is only possible since we don't have negative bounding boxes, e.g. an opacity localization with label `negative`. In general, we can use any object detection framework and decide not to predict an object if confidence is very low based on a thresholding startegy, in that case we can output `none 1 0 0 1 1` or `negative 1 0 0 1 1`. More clarification is needed on this.\n\n\n![Screen Shot 2021-05-18 at 3.20.08 PM.png](attachment:fcb915fd-7894-48ff-92c0-6391dc7f7ba3.png)\n","3b0bf85b":"Let's merge study and image data","19a9c703":"Let's check if all non-negative e.g. `Negative for Pneumonia == 0` studies have a bounding box annotation.","804eaaae":"### A brief look at data","abb0e915":"**Number of images per study**\n\nMost studies only have 1 image","e34468b6":"For a given study, images without bounding box annotations look very similar to the image that is annotated. What does this tell us? Are they free of abnormality or they are just not annotated? Disclaimer: I am not a medical expert so I hope someone can explain further.","d8e75361":"Below we can see that each study has exactly 1 label so maybe there is no notion of `No Finding` similar to the other CXR (Chest X-Ray) datasets such as Chexpert.","76d5c36c":"### What are Boxes and Labels?\n\nWhat is in `label` that is not present in `boxes`, do we need `label` column at all?","2196f0cd":"**Distribution of classes in studies**\n\nWhat are the detailed descriptions of each label? What does it mean to be `typical`?","9c90056e":"#### A. Study with a single image and pneumonia"}}