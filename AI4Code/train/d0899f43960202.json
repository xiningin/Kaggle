{"cell_type":{"2d8123c3":"code","138c34cf":"code","1952dad4":"code","6a6cd4cf":"code","daf9ce75":"code","2a58218c":"code","2ddc0fb4":"code","909c40b4":"code","c25a462a":"code","73e086f1":"code","6c50756e":"code","826cb30c":"code","f4d09dc9":"code","e65a9318":"code","f7b614a2":"code","50748527":"code","bc383c26":"code","62aa9fd0":"code","ff6344dd":"code","ff6fa36f":"code","226b40a2":"code","a9715809":"code","9e688844":"code","acaa1902":"code","9aa7043e":"code","fb4ac8f6":"code","55b3bac8":"code","a35a0060":"code","085c343a":"code","5859931f":"code","d708f270":"code","28eabcc0":"code","8d87f34f":"code","106e605a":"markdown"},"source":{"2d8123c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","138c34cf":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import cross_val_score","1952dad4":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","6a6cd4cf":"train_data.head()","daf9ce75":"sns.heatmap(train_data.isnull(),cbar=False)\ntrain_data.info()","2a58218c":"train_data.groupby('Sex').Survived.mean()","2ddc0fb4":"train_data.groupby('Pclass').Survived.mean()","909c40b4":"train_data.groupby('Embarked').Survived.mean()","c25a462a":"train_data.groupby(['Pclass','Sex']).Survived.mean()","73e086f1":"train_data.groupby(['Embarked','Sex']).Survived.mean()","6c50756e":"train_data.groupby(['Embarked','Sex']).Survived.value_counts()","826cb30c":"train_data.groupby(['Pclass','Embarked']).Survived.mean()","f4d09dc9":"train_data['SibSp'].value_counts()","e65a9318":"train_data['Parch'].value_counts()","f7b614a2":"train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())","50748527":"train_data['Title'].value_counts()","bc383c26":"train_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntest_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntrain_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\ntest_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)","62aa9fd0":"train_data['Ticket']","ff6344dd":"train_data['Ticket_1'] = train_data.Ticket.apply(lambda x: x[:2])\ntest_data['Ticket_1'] = test_data.Ticket.apply(lambda x: x[:2])","ff6fa36f":"train_data['Ticket_2'] = train_data.Ticket.apply(lambda x: len(x))\ntest_data['Ticket_2'] = test_data.Ticket.apply(lambda x: len(x))","226b40a2":"train_data['Fare'].value_counts()","a9715809":"train_data[train_data['Fare']==0]['Fare'].value_counts()","9e688844":"train_data.loc[train_data['Fare'] == 0, 'Fare'] = np.NaN\ntest_data.loc[train_data['Fare'] == 0, 'Fare'] = np.NaN","acaa1902":"train_data.head()","9aa7043e":"train_data['Fam_size'] = train_data['SibSp'] + train_data['Parch'] +1\ntest_data['Fam_size'] = test_data['SibSp'] + test_data['Parch'] +1","fb4ac8f6":"train_data['Fam_size'].value_counts()","55b3bac8":"train_data['Fam_type'] = pd.cut(train_data.Fam_size, [0,1,4,7,10], labels=['Solo', 'Small', 'Big', 'Very big'])\ntest_data['Fam_type'] = pd.cut(test_data.Fam_size, [0,1,4,7,10], labels=['Solo', 'Small', 'Big', 'Very big'])","a35a0060":"train_data.head()","085c343a":"y = train_data['Survived']\nfeatures = ['Pclass', 'Fare', 'Title', 'Embarked', 'Fam_type', 'Ticket_1', 'Ticket_2']\nx=train_data[features]\nx.head()","5859931f":"numerical_cols = ['Fare']\ncategorical_cols = ['Pclass', 'Title', 'Embarked', 'Fam_type', 'Ticket_1', 'Ticket_2']\n\nnumerical_transformer = SimpleImputer(strategy='median')\ncategorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),('cat', categorical_transformer, categorical_cols)])\n\ntitanic_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', ExtraTreesClassifier(n_estimators = 10,max_depth = None,min_samples_split = 10, random_state = 0))])\ntitanic_pipeline.fit(x,y)\n","d708f270":"cross_val_score(titanic_pipeline, x, y, cv=10).mean()\n\n","28eabcc0":"x_test = test_data[features]\npredictions = titanic_pipeline.predict(x_test)\n\ntitanic_pipeline.score(x,y)","8d87f34f":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint('Your submission was successfully saved!')","106e605a":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}