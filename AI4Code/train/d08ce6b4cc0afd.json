{"cell_type":{"2e89207c":"code","05d5feb9":"code","6debb4db":"code","d95b3c91":"code","fdf006b2":"code","2b18ab5d":"code","5edc789a":"code","79dc03d1":"code","efa7e927":"code","59d390f6":"code","3fb71a59":"code","e7bab954":"code","1715db5a":"code","d58a8863":"code","cb7e1ea6":"code","8884bda2":"code","eed0072a":"code","61626966":"markdown","58655cf8":"markdown","e6d7450b":"markdown","eb15275f":"markdown"},"source":{"2e89207c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05d5feb9":"# Reading the Data\n\ndf = pd.read_csv('\/kaggle\/input\/spotify-dataset-19212020-160k-tracks\/data_o.csv')\ndf.sort_values(['popularity'], ascending = True)","6debb4db":"print('Info:', df.info())","d95b3c91":"df.describe().round(decimals=2)","fdf006b2":"df.columns","2b18ab5d":"plt.figure(figsize = (15,15)) #creating the 'canvas'\nsns.heatmap(df.corr(), annot=True)","5edc789a":"#Looking at the overall Data Distribution\ndf.hist(figsize = (20,20))\nplt.show()","79dc03d1":"columns = ['acousticness','danceability', 'duration_ms', 'energy', 'explicit',\n       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n       'popularity', 'speechiness', 'tempo', 'valence']\nfor col in columns:\n    y = df.groupby('year')[col].mean()\n    x = y.index\n    plt.figure(figsize=(16, 8))\n    sns.set_style(\"darkgrid\")\n    sns.lineplot(x, y, data=df)","efa7e927":"plt.figure(figsize=(16, 8))\nsns.set(style=\"whitegrid\")\nx = df.groupby(\"artists\")[\"popularity\"].mean().sort_values(ascending=False).head(20)\nax = sns.barplot(x.index, x)\nax.set_title('Top Artists with Popularity by Mean ')\nax.set_ylabel('Popularity')\nax.set_xlabel('Artists')\nplt.xticks(rotation = 90)","59d390f6":"plt.figure(figsize=(16, 8))\nsns.set(style=\"whitegrid\")\nx = df.groupby(\"artists\")[\"popularity\"].sum().sort_values(ascending=False).head(20)\nax = sns.barplot(x.index, x)\nax.set_title('Top Artists with Popularity by Sum')\nax.set_ylabel('Popularity')\nax.set_xlabel('Artists')\nplt.xticks(rotation = 90)","3fb71a59":"df.columns","e7bab954":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n#Creating Random Forest\ny = df['popularity']\nx = df[['valence', 'year', 'acousticness', 'danceability',\n       'duration_ms', 'energy', 'explicit', 'instrumentalness', 'key',\n       'liveness', 'loudness', 'mode',\n       'speechiness', 'tempo']]\n\ntrain_x, val_x, train_y, val_y = train_test_split(x,y, random_state=1)\n\npopularity_model = RandomForestRegressor(random_state=1)\npopularity_model.fit(train_x, train_y)\n\npopularity_prediction = popularity_model.predict(val_x)","1715db5a":"r2_score(val_y, popularity_prediction), mean_squared_error(val_y, popularity_prediction)**0.5","d58a8863":"from sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = popularity_model, X = train_x, y = train_y, cv = 5, n_jobs = -1)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","cb7e1ea6":"#test\nprint(popularity_model.predict(x.tail()))\nprint('==============================================')\nprint(df['popularity'].tail())","8884bda2":"df['popularity_prediction'] = popularity_model.predict(x)\ndf","eed0072a":"# Print feature importances\nfrom sklearn.inspection import permutation_importance\nprint(\"Feature Importances: \")\npimp = permutation_importance(popularity_model, val_x, val_y, random_state = 1)\n\nfor i in pimp.importances_mean.argsort()[-10:]:\n    print(x.columns[i], pimp.importances_mean[i])","61626966":"# Some Key Time-Series Trends\n* Acousticness and instrumentaliness decreases from time to time (lowest in 2020)\n* Danceability, Energy, Explicit, Loudness, and Tempo increases through time\n* Speechiness stays within 0.1 to 0.2 after 1960","58655cf8":"# Conclusion\n\n1. Predictive power of the RF model is about 80%\n2. Root mean squared error is about 9\n3. Year, loudness, instrumentalness, duration, and acousticness are five most important popularity predictors.","e6d7450b":"# Random Forest Simulation","eb15275f":"# Overview\n* First, I think I'm going to just visualize the data as this is more like a time-series data (from 1921 to 2020) with approximately 169k entries of songs.\n* Second, I will use simple Random Forest Regressor to predict popularity of a song based on the available characteristics"}}