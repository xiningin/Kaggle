{"cell_type":{"e37e6b45":"code","7269ab1b":"code","eb848018":"code","a1143cc3":"code","9b85c09e":"code","a584b9f3":"code","c3a507ea":"code","79dfc442":"code","211f97c8":"code","551a7c42":"code","1e87dc54":"code","272e1da4":"code","5c66c356":"code","3d9cc75a":"code","e6aae8d7":"code","762b564a":"code","5e05268e":"markdown","f9f478b8":"markdown","e84d735d":"markdown","ee3e11ce":"markdown","0db96f52":"markdown","96436d0a":"markdown","9a818ee0":"markdown","709e93a2":"markdown","5b1737ca":"markdown","5723e7cb":"markdown","9c131dd2":"markdown","b8693f86":"markdown","89c668d6":"markdown","ec480163":"markdown","ea121667":"markdown","5f9f7cf8":"markdown","b18459f8":"markdown","430658c2":"markdown","2c743049":"markdown","717dc9ff":"markdown","ef12ccd4":"markdown","157609c3":"markdown"},"source":{"e37e6b45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom PIL import Image , ImageDraw\nfrom sklearn.preprocessing import *\nimport time\nimport ast\nimport os\nimport tensorflow as tf\nfrom keras import models, layers\nfrom keras import Input\nfrom keras.models import Model, load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers, initializers, regularizers, metrics\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers import BatchNormalization, Conv2D, Activation , AveragePooling2D\nfrom keras.layers import Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\nfrom keras.models import Sequential\nfrom keras.metrics import top_k_categorical_accuracy\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tqdm import tqdm\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        fpath = os.path.join(dirname, filename)","7269ab1b":"print(dirname)\nprint(filenames[0])","eb848018":"df = pd.read_csv(dirname+'\/'+'bird.csv')\ndf['word'] = df['word'].replace(' ','_',regex = True)\nprint(type(df['recognized'][0]))\n\nidx= df.iloc[:5].index\nprint(df.loc[idx,'recognized'].values)\n\nfor i in range(len(df.loc[idx,'drawing'].values)) :\n    if df.loc[idx,'recognized'].values[i] == True :\n        print(i, end=' ')\n\nidx= df.iloc[:2000].index\nT_cnt = 0\nF_cnt = 0\nfor i in range(len(df.loc[idx,'drawing'].values)) :\n    if df.loc[idx,'recognized'].values[i] == True :\n        T_cnt += 1\n    else : F_cnt += 1\n\nprint('\\nTrue Count :',T_cnt)\nprint('False Count :',F_cnt)\ndf.head()","a1143cc3":"def check_draw(img_arr) :\n    k=3\n    for i in range(len(img_arr[k])):\n        img = plt.plot(img_arr[k][i][0],img_arr[k][i][1])\n        plt.scatter(img_arr[k][i][0],img_arr[k][i][1])\n    plt.xlim(0,256)\n    plt.ylim(0,256)\n    plt.gca().invert_yaxis()\n\nten_ids = df.iloc[:10].index\nimg_arr = [ast.literal_eval(lst) for lst in df.loc[ten_ids,'drawing'].values]  #ast.literal_eval is squence data made string to array\nprint(img_arr[3])\ncheck_draw(img_arr)","9b85c09e":"def make_img(img_arr) :\n    image = Image.new(\"P\", (256,256), color=255)\n    image_draw = ImageDraw.Draw(image)\n    for stroke in img_arr:\n        for i in range(len(stroke[0])-1):\n            image_draw.line([stroke[0][i], \n                             stroke[1][i],\n                             stroke[0][i+1], \n                             stroke[1][i+1]],\n                            fill=0, width=5)\n    return image\nimg = make_img(img_arr[3])\nimg = img.resize((64,64))\nplt.imshow(img)","a584b9f3":"bar = '\u25a1\u25a1\u25a1\u25a1\u25a1\u25a1\u25a1\u25a1\u25a1\u25a1'\nsw = 1\ndef percent_bar(array,count,st_time):   #\ud37c\uc13c\ud2b8\ub97c \ud45c\uc2dc\ud574\uc8fc\ub294 \ud568\uc218\n    global bar\n    global sw\n    length = len(array)\n    percent = (count\/length)*100\n    spend_time = time.time()-st_time\n    if count == 1 :\n        print('preprocessing...')\n    print('\\r'+bar+'%3s'%str(int(percent))+'% '+str(count)+'\/'+str(length),'%.2f'%(spend_time)+'sec',end='')\n    if sw == 1 :\n        if int(percent) % 10 == 0 :\n            bar = bar.replace('\u25a1','\u25a0',1)\n            sw = 0\n    elif sw == 0 :\n        if int(percent) % 10 != 0 :\n            sw = 1","c3a507ea":"def preprocessing(filenames) :\n    img_batch = 2000\n    X= []\n    Y= []\n    class_label = []\n    st_time = time.time()\n    class_num = 340\n    Y_num = 0\n    for fname in filenames[0:class_num] :\n        percent_bar(filenames[0:class_num],Y_num+1,st_time)\n        df = pd.read_csv(os.path.join(dirname,fname))\n        df['word'] = df['word'].replace(' ','_',regex = True)\n        class_label.append(df['word'][0])\n        keys = df.iloc[:img_batch].index\n        #print(len(keys))\n        \n        for i in range(len(df.loc[keys,'drawing'].values)) :\n            if df.loc[keys,'recognized'].values[i] == True :\n                drawing = ast.literal_eval(df.loc[keys,'drawing'].values[i])\n                img = make_img(drawing)\n                img = np.array(img.resize((64,64)))\n                img = img.reshape(64,64,1)\n                X.append(img)\n                Y.append(Y_num)\n        Y_num += 1\n        \n    tmpx = np.array(X)\n\n    Y = np.array([[i] for i in Y])\n    enc = OneHotEncoder(categories='auto')\n    enc.fit(Y)\n    tmpy = enc.transform(Y).toarray()\n    \n    del X\n    del Y     #RAM\uba54\ubaa8\ub9ac \uc808\uc57d\uc744 \uc704\ud574 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294 \ubcc0\uc218 \uc0ad\uc81c\n    \n    return tmpx , tmpy , class_label , class_num\n\ntmpx , tmpy , class_label , class_num = preprocessing(filenames)\nprint('\\n',tmpx.shape, tmpy.shape, '\\n5th class : ',class_label[0:5])\n#df.head()\n#print(drawing[0])\n#img = make_img(drawing[1])\n#plt.imshow(img)","79dfc442":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(tmpx,tmpy, test_size = 0.1,random_state = 0)\ndel tmpx\ndel tmpy     #RAM\uba54\ubaa8\ub9ac \uc808\uc57d\uc744 \uc704\ud574 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294 \ubcc0\uc218 \uc0ad\uc81c\n\nprint(X_train.shape,X_val.shape,Y_train.shape,Y_val.shape)","211f97c8":"#CNN\ninputs = (64,64,1)\nst_filter = 32\nfilter_size = (3,3) \nCNN = Sequential()\nCNN.add(layers.Conv2D(st_filter,filter_size, input_shape = inputs ,padding= 'same'))\nCNN.add(BatchNormalization())\nCNN.add(Activation('relu'))\nCNN.add(layers.MaxPooling2D((2,2),padding= 'same'))\nCNN.add(layers.Dropout(0.25))\nCNN.add(layers.Conv2D(st_filter*2,filter_size, input_shape = inputs,padding= 'same'))\nCNN.add(BatchNormalization())\nCNN.add(Activation('relu'))\nCNN.add(layers.AveragePooling2D((2,2),padding= 'same'))\nCNN.add(layers.Dropout(0.25))\nCNN.add(layers.Conv2D(st_filter*4,filter_size, input_shape = inputs,padding= 'same'))\nCNN.add(BatchNormalization())\nCNN.add(Activation('relu'))\nCNN.add(layers.AveragePooling2D((2,2),padding= 'same'))\nCNN.add(layers.Dropout(0.25))\nCNN.add(layers.Conv2D(st_filter*8,filter_size, input_shape = inputs,padding= 'same'))\nCNN.add(BatchNormalization())\nCNN.add(Activation('relu'))\nCNN.add(layers.AveragePooling2D((2,2),padding= 'same'))\nCNN.add(layers.Dropout(0.25))\nCNN.add(layers.Conv2D(st_filter*16,filter_size, input_shape = inputs,padding= 'same'))\nCNN.add(BatchNormalization())\nCNN.add(layers.AveragePooling2D((2,2),padding= 'same'))\nCNN.add(layers.Flatten())\nCNN.add(layers.Dense(2*2*512,activation = 'relu'))\nCNN.add(layers.Dropout(0.5))\nCNN.add(layers.Dense(class_num, activation = 'softmax'))\n\nCNN.summary()","551a7c42":"def top_3_accuracy(x,y): \n    t3 = top_k_categorical_accuracy(x,y, 3)\n    return t3\n\nlearning_rate = 0.0001\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n                                   verbose=1, mode='auto', min_delta=0.005, cooldown=5, min_lr=learning_rate)\nearlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=4) \ncallbacks = [reduceLROnPlat]\n\nCNN.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', top_3_accuracy])\n\nhistory = CNN.fit(x=X_train, y=Y_train,\n          batch_size = 128,\n          epochs = 100,\n          validation_data = (X_val, Y_val),\n          callbacks = callbacks,\n          verbose = 1)\n\n#drop out no -> 0.75 0.90","1e87dc54":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1,len(acc) + 1 )\n\nplt.plot(epochs, acc, 'bo' , label = 'Training Accuracy')\nplt.plot(epochs, val_acc, 'b' , label = 'Validation Accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo' , label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b' , label = 'Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","272e1da4":"def preprocessing_test(df) :\n    X= []\n    keys = df.iloc[:].index\n    for i in tqdm(range(len(df.loc[keys,'drawing'].values))) :\n        drawing = ast.literal_eval(df.loc[keys,'drawing'].values[i])\n        img = make_img(drawing)\n        img = np.array(img.resize((64,64)))\n        img = img.reshape(64,64,1)\n        X.append(img)\n    \n    tmpx = np.array(X)\n    return tmpx\n\ntest = pd.read_csv(os.path.join('\/kaggle\/input\/quickdraw-doodle-recognition', 'test_simplified.csv'))\nx_test = preprocessing_test(test)\nprint(test.shape, x_test.shape)\ntest.head()","5c66c356":"plt.imshow(x_test[0].reshape(64,64))","3d9cc75a":"imgs = x_test\npred = CNN.predict(imgs, verbose=1)\ntop_3 = np.argsort(-pred)[:, 0:3]\nprint(\"Finished !!\")\n\n#print(pred)\nprint(top_3)","e6aae8d7":"top_3_pred = ['%s %s %s' % (class_label[k[0]], class_label[k[1]], class_label[k[2]]) for k in top_3]\nprint(top_3_pred[0:5])","762b564a":"preds_df = pd.read_csv('\/kaggle\/input\/quickdraw-doodle-recognition\/sample_submission.csv', index_col=['key_id'])\npreds_df['word'] = top_3_pred\npreds_df.to_csv('subcnn_small.csv')\npreds_df.head()","5e05268e":"# \uc804\ucc98\ub9ac\uc2dc \ub370\uc774\ud130\uac00 \uc804\ucc98\ub9ac\ub418\ub294 \uacfc\uc815\uc744 \ud655\uc778\ud560 \ud37c\uc13c\ud2b8\ubc14","f9f478b8":"**ResNet50","e84d735d":"# vector\ub85c \ud45c\ud604\ub41c \ub370\uc774\ud130\ub97c \uc774\ubbf8\uc9c0\ub85c \ub9cc\ub4e4\uae30\uc704\ud574 \uc774\ubbf8\uc9c0\ub85c \uadf8\ub824\uc900\ub2e4","ee3e11ce":"# \uc81c\ucd9c","0db96f52":"1. \ubb38\uc81c \uc778\uc2dd\n\n\ubb38\uc81c\uc5d0 \uc81c\uc2dc\ub41c \uc124\uba85\uc744 \uc77d\uace0\ub09c \ud6c4 \uc190\uadf8\ub9bc\uc744 \ubd84\ub958 340\uac1c\uc758 \ud074\ub798\uc2a4\ub85c \ud6c8\ub828\uc2dc\ucf1c \uc918\uc57c\ud55c\ub2e4\ub294 \uac83\uc744 \uc54c\uc558\ub2e4.\n\ud3c9\uac00 \ub9e4\uae30\ub294 \ubc29\uc2dd\uc740 key_id\uce7c\ub7fc\uc758 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0 \ub300\ud574 word\uac12\uc911 acc\uac00 \ub192\uc740 3\uac1c\uc758 \ud074\ub798\uc2a4\ub97c \ub123\uc5b4 csv\ub85c \ub9cc\ub4e4\uc5b4\uc8fc\ub294 \uac83\uc774\uace0\nword\uc5d0 \ub4e4\uc5b4\uc788\ub294 \uacf5\ubc31\uc740 '_'\ub85c \uce58\ud658\ud558\uc5ec \uc81c\ucd9c\ud558\ub77c\uace0 \ub418\uc5b4\uc788\uc5c8\ub2e4.\n\ub370\uc774\ud130 \ud0ed\uc73c\ub85c \ub4e4\uc5b4\uac00 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc124\uba85\uc744 \uc77d\uc5c8\ub2e4.\nraw\ub370\uc774\ud130\uc640 simplified\ub370\uc774\ud130\uac00 \uc788\ub294\ub370 \ubaa8\ub450 \uc0ac\uc6a9\ud560\uc218 \uc788\ub2e4\uace0 \ud588\uc73c\ub098\nsimplified\ub370\uc774\ud130\uac00 \ub3d9\uc77c\uc548 \uc815\ubcf4\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc81c\uacf5\ud55c\ub2e4\uace0 \uc368\uc788\uc5b4\uc11c \uc0ac\uc6a9\ud558\uc600\ub2e4 (raw\ub3c4 \ud655\uc778\ud558\ub824 \ud588\uc73c\ub098 \uc548\ub4e4\uc5b4\uac00\uc84c\ub2e4.)\n\uadf8 \ud6c4 sample_submission\uc5d0\uc11c \uc81c\ucd9c \uc591\uc2dd\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc5c8\ub2e4.\n\n2. \ub370\uc774\ud130 \ud655\uc778\n\n\uadf8 \ud6c4\uc5d0 \uc81c\uacf5\ub41c \ub370\uc774\ud130 \ud655\uc778\uc744 \ud558\uc600\ub2e4.\ncsv\uc758 \uac2f\uc218 \uc989 \ud074\ub798\uc2a4\uc758 \uac2f\uc218\ub294 340\uac1c\uc600\uace0, \nbird.csv\ub97c \uc77d\uc5b4\uc640\uc11c \ud655\uc778\ud574\ubd24\ub354\ub2c8 countrycode,drawing,key_id,recognized,timestamp,word \uce7c\ub7fc\uc774 \uc788\uc5c8\ub2e4.\nbird.csv\uc758 \ub370\uc774\ud130\uc758 \uac2f\uc218\ub294 12\ub9cc\uac1c \uc815\ub3c4 \uc600\uace0, \ub204\ub77d\uac12\uc740 \uc5c6\uc5c8\ub2e4.\n\uadf8\ub9bc\uc5d0 \ub300\ud55c \uc774\uc0c1\uce58\ub370\uc774\ud130\ub294 recognized \uce7c\ub7fc \ubd80\ubd84\uc774 True\uc640 False\ub85c \ub098\ud0c0\ub0b4\uace0 \uc788\uc5c8\ub294\ub370 \nbird.csv\ub370\uc774\ud130 2000\uac1c\ub97c \uae30\uc900\uc73c\ub85c True\uac00 1659\uac1c False\uac00 341\uac1c \uc600\ub2e4.\n\ucc98\uc74c\uc5d0\ub294 test\uc5d0\ub3c4 False\ub370\uc774\ud130\uac00 \uc788\uc744\uac70\ub77c\uace0 \ud310\ub2e8\ud558\uc5ec \ub370\uc774\ud130 \uc804\uccb4\ub97c \uc0ac\uc6a9\ud558\uc600\ub2e4.\n\uadf8 \ud6c4 \ubb38\uc81c\uc5d0 \uc81c\uc2dc\ub41c word \uc5f4\uc758 \uacf5\ubc31\uc744 \ubaa8\ub450 '_'\ub85c replace \ud574\uc8fc\uc5c8\ub2e4.\n\n3. \uccab\ubc88\uc9f8 \ub09c\uad00\n\ndrawing\uc774 \uc774\ubbf8\uc9c0\ub97c \ub098\ud0c0\ub0b4\ub294 \uce7c\ub7fc\uc774\uc5c8\ub294\ub370 pandas\ub85c \uc77d\uc5c8\uae30 \ub54c\ubb38\uc5d0 \ubaa8\ub450 string\uc73c\ub85c \ubc18\ud658\ub418\uc5c8\ub2e4\n\uadf8\ub798\uc11c \uac80\uc0c9 \uacb0\uacfc np.matrix\ub97c \ud1b5\ud574 \ubcc0\ud658\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc54c\uc558\uace0 matrix\ub97c \uc0ac\uc6a9\ud558\uc5ec\n\ubcc0\ud658\ud574 \ubcf4\uc558\uc9c0\ub9cc \uac00\uc7a5\uc548\ucabd \ubc30\uc5f4\uc758 \uad6c\uc870\ub294 \uc720\uc9c0 \ub418\uc9c0 \uc54a\uc740\ucc44 \uac12\ub4e4\uc744 \uc804\ubd80 1\ucc28\uc6d0\uc73c\ub85c \ubc18\ud658\ud558\uc600\ub2e4.\n\ubb38\uc790\uc5f4\uc774\ub77c shape\ub3c4 1\ucc28\uc6d0\uc73c\ub85c \ub098\uc624\ub294 \ud0d3\uc5d0 \uace0\ubbfc\uc744 \ub9ce\uc774 \ud588\ub2e4.\n\uadf8 \ud6c4\uc5d0 ast.literal_eval\uc774\ub77c\ub294 \ud568\uc218\uac00 \uc2dc\ud000\uc2a4\ud615 \ub370\uc774\ud130\ub85c \ub9cc\ub4e4\uc5b4\uc9c4 \ubb38\uc790\uc5f4\uc744 \uc2dc\ud000\uc2a4 \ub370\uc774\ud130 \uadf8\ub300\ub85c\ubcc0\ud658\ud560\uc218\uc788\ub294\uac78 \uc54c\uc558\uace0\nast.literal_eval \ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \uc2dc\ud000\uc2a4\ud615 \ub370\uc774\ud130\ub85c \ubcc0\ud658\ud574 \uc8fc\uc5c8\ub2e4.\n\n4. \ub450\ubc88\uc9f8 \ub09c\uad00\n\n\ubc30\uc5f4\uc740 \ubcc0\ud658 \ud558\uc600\uc73c\ub098 \uc774\ubbf8\uc9c0\uac00 NxN\ud615\ud0dc\uc758 \ubc30\uc5f4\uc774 \uc544\ub2c8\uc5c8\ub2e4. \n\uaf64\ub098 \uc624\ub7ab\ub3d9\uc548 \uace0\ubbfc\ub05d\uc5d0 \ud648\ud398\uc774\uc9c0\uc758 \ubb38\uc81c\ub97c \ub2e4\uc2dc \uc778\uc2dd\ud558\uae30\ub85c \ud588\uace0 dataset\uc5d0 \ub300\ud55c \uae43\ud5c8\ube0c\ud398\uc774\uc9c0\uac00 \uc788\uc5c8\ub2e4.\n\uae43\ud5c8\ube0c \ud398\uc774\uc9c0\ub97c \ubcf4\uc544 x,y,t\ub85c \uc774\ub8e8\uc5b4\uc838\uc788\uace0 t\uc5d0\ub300\ud55c \uc815\ubcf4\ub97c \uc81c\uac70\ud574\uc11c \uc0ac\uc6a9\ud55c\ub2e4\uace0 \uc368\uc788\uc5c8\ub294\ub370\ncsv\ub85c \uc8fc\uc5b4\uc9c4 \ub300\ud68c \ub370\uc774\ud130\ub294 t\ub294 \uc774\ubbf8 \uc9c0\uc6cc\uc9c4 \ud615\ud0dc\uc600\ub2e4. bird[0]\uc744 \ubf51\uc544\uc11c 2\uac00\uc9c0\uc758 \ubc30\uc5f4\ub9cc \uc788\ub2e4\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc5c8\ub2e4.\n\uadf8 \ud6c4\uc5d0 plt.plot\uc744 \uc774\uc6a9\ud558\uc5ec xy\ubc30\uc5f4\uc744 \ub123\uc5b4 \ud655\uc778\ud574\ubcf4\ub2c8 \uadf8\ub9bc\uc758 \ud615\ud0dc\uac00 \uadf8\ub824\uc84c\ub2e4.\n\n5. \uc138\ubc88\uc9f8 \ub09c\uad00\n\n\uadf8\ub9bc\uc740 \uadf8\ub838\uc73c\ub098 \uc774\uac83\uc744 \uc774\ubbf8\uc9c0\ub85c \ub9cc\ub4e4\uc5b4\uc57c\ub9cc \ud6c8\ub828\ub370\uc774\ud130\uc5d0 \uc9d1\uc5b4\ub123\uc5b4 \ud6c8\ub828\uc744 \ud574\ubcfc \uc218 \uc788\uc5c8\ub294\ub370 \nplt\uc5d0\uc11c \uadf8\ub9b0\uadf8\ub9bc\uc744 \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\uae30\uc5d0\ub294 \uc0c9\uae54\ub3c4 \uc788\uace0 \uc815\ud655\ud55c \ud615\ud0dc\uac00 \uc544\ub2c8\uc5c8\ub2e4.\n\uadf8\ub798\uc11c pillow \ubaa8\ub4c8\uc744 \uc774\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\ub97c \uc9c1\uc811 \uadf8\ub824\ub123\uc5b4 \uc8fc\uc5c8\ub2e4.\n\uc774\ubbf8\uc9c0\ub97c \ud655\uc778\ud558\ub294 \uacfc\uc815\uc5d0\uc11c True data\uc640 False data\ub97c \ud655\uc778\ud574\ubcf4\uc558\ub294\ub370 \nFalse\ub370\uc774\ud130\ub294 \uadf8\ub9bc\uc774 \uc544\ub2cc\uac83\ub4e4\ub3c4 \uc788\uace0 (\uc608\ub97c\ub4e4\uba74 airplane \ub370\uc774\ud130\uc758 \uadf8\ub9bc\uc758 \ub300\ubd80\ubd84\uc774 AIRPLANE\uc774\ub77c\uace0 \uc601\uc5b4\ub85c \uc190\uae00\uc528\ub85c \uc801\uc5b4\ub17c \uadf8\ub9bc\ub4e4\uc774 \uc788\ub2e4.)\n\uc81c\ub300\ub85c \uadf8\ub824\uc9c0\uc9c0 \uc54a\uc558\uae30 \ub54c\ubb38\uc5d0 True data\ub9cc \uc0ac\uc6a9\ud558\uae30\ub85c \ud558\uc600\ub2e4.\n\n6. \ub124\ubc88\uc9f8 \ub09c\uad00\n\n\uc804\ucc98\ub9ac \uc54c\uace0\ub9ac\uc998\uc744 \ub05d\ub0b4\uace0 training data\ub97c \ub9cc\ub4dc\ub294\ub370 1\uac1c\uc758 \ud074\ub798\uc2a4 (1\uac1c\uc758 csv\ud30c\uc77c)\ub2f9 \uc57d 1\ubd8430\ucd08\uac00\ub7c9\uac78\ub838\ub2e4.\n\ub370\uc774\ud130\ub97c \ubaa8\ub450 \uc77d\uc5b4\uc624\uae30\uc5d0\ub294 \uc804\uccb4 \ub370\uc774\ud130\uc758 \uac2f\uc218\uac00 \uc57d 3000\ub9cc\uac1c \uc774\ubbc0\ub85c RAM \uba54\ubaa8\ub9ac\uc5d0 \uc62c\ub9b4\uc218\uac00 \uc5c6\uc5b4 \ubb3c\ub9ac\uc801 \ubb38\uc81c\uac00 \uc0dd\uae30\uace0 \n1\uac1c\uc758 \ud30c\uc77c(\ud074\ub798\uc2a4)\ub2f9 1\ubd8430\ucd08\uac00 \uac78\ub9ac\uae30 \ub54c\ubb38\uc5d0 340\uac1c\uc758 \ud074\ub798\uc2a4\ub97c \ubaa8\ub450 \uc77d\uae30\uc5d0\ub294 \uc2dc\uac04\uc801\uc73c\ub85c\ub3c4 \ubb38\uc81c\uac00 \uc788\uc5c8\ub2e4.\n\uc77c\ub2e8 \ud6c8\ub828\uc774 \ub418\uace0 accuracy\ud655\uc778\ud55c \ud6c4\uc5d0 \ub370\uc774\ud130\uc758 \uac2f\uc218\ub97c \uc815\ud574\ub294\uac8c \ub9de\ub2e4\uace0 \uc0dd\uac01\uc774 \ub4e4\uc5b4 \n\ud074\ub798\uc2a4\ub2f9 1000\uac1c\uc758 \ub370\uc774\ud130\ub85c \uba3c\uc800 \uc9c4\ud589\uc744 \ud558\uc600\ub2e4.\n\n7. \ub2e4\uc12f\ubc88\uc9f8 \ub09c\uad00\n\nCNN\ubaa8\ub378\uc744 \uc124\uacc4\ud558\uc5ec \ubc14\ub85c \uc9d1\uc5b4\ub123\uc5b4 \ubd24\uc73c\ub098 \uc804\uc5d0 \ubc30\uc6e0\ub358 1.9.0 \ubc84\uc804\uc774\ub77c \ubb38\ubc95\uc624\ub958\uac00 \ub0ac\ub2e4. \nkaggle kernel\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 tf\ubc84\uc804\uc740 2.0\uc784\uc744 \ud655\uc778\ud55c \ud6c4\uc5d0 tensorflow\uc640 keras\uc911 \uace0\ubbfc\ud558\ub2e4\uac00\n\uc544\uc9c1 \uc0ac\uc6a9\ud574\ubcf4\uc9c0 \uc54a\uc740 keras\ub97c \uacf5\ubd80\ud558\ub294 \ubaa9\uc801\uc5d0\uc11c keras\ucc45\uc744 \uad6c\uc785\ud558\uc5ec keras\ub85c \ubaa8\ub378\uc744 \uc124\uacc4\ud588\ub2e4.\n\n8. keras\uacf5\ubd80 \ud6c4\n\nCNN \ucd08\uae30\ubaa8\ub378\uc744 \uba3c\uc800 \uc124\uacc4\ud574\uc11c \ub123\uc5b4\ubcf4\uc558\ub2e4 \uadf8\ub7ec\ub098 Training data\uc758 loss\uac00 \uc804\ud600 \ub5a8\uc5b4 \uc9c0\uc9c0\uc54a\uc558\ub2e4.\nVGG16 \ubaa8\ub378 \ub610\ud55c \uc9c1\uc811 \uc124\uacc4\ud558\uc5ec \ub123\uc5b4 \ubcf4\uc558\ub294\ub370 CNN \uacfc \uac19\uc774 \uc5ed\uc2dc loss\uac00 \ub5a8\uc5b4\uc9c0\uc9c0 \uc54a\ub294 \ubb38\uc81c\uac00 \uc0dd\uacbc\ub2e4.\n\uadf8 \ud6c4 \ub370\uc774\ud130 \uc804\ucc98\ub9ac\uc758 \ubb38\uc81c\uc778\uc9c0 \ubaa8\ub378\uc758 \ubb38\uc81c\uc778\uc9c0 \ud655\uc778\ud558\uae30 \uc704\ud574 \n\uac80\uc99d\ub41c \ubaa8\ub378\uc778 ResNet\ubaa8\ub378\uc744 \ub123\uc5b4 \ubcf4\uc558\ub294\ub370 \uc791\ub3d9\uc774 \ub418\uae30 \uc2dc\uc791\ud588\ub2e4 \uadf8\ub7ec\ub098 22epoch\uae30\uc900\uc73c\ub85c \nacc\uac00 \ud6c8\ub828\ub370\uc774\ud130\ub294 \ud3c9\uade0 :0.7 \ucd5c\uace0 : 0.98 , \uac80\uc99d\ub370\uc774\ud130\ub294 \ud3c9\uade0 :0.5 \ucd5c\uace0 :0.83 \uc5d0\uc11c \uadf8\ucce4\ub2e4.\nepoch\uc744 \ub298\ub9ac\uae30\uc5d4 \ud6c8\ub828\uc2dc\uac04\uc774 \uc57d 5\uc2dc\uac04\uc815\ub3c4 \uac78\ub838\uae30 \ub54c\ubb38\uc5d0 \ud074\ub798\uc2a4\ub97c \uc904\uc5ec\uc11c \ubaa8\ub378\ubcc4\ub85c acc\ub97c \ud655\uc778\ud558\uba70 \uc9c4\ud589\uc744 \ud574\ubcf4\uae30\ub85c \ud558\uc600\ub2e4.\n\n9. \uc2e4\ud5d8 \uacfc\uc815\n\n3\ud074\ub798\uc2a4 CNN\uc740 loss\uac00 \ub5a8\uc5b4\uc9c0\uc9c0\uc54a\uc544 acc\ub3c4 \uc624\ub974\uc9c0 \uc54a\uc74c \n       VGG16 \ub3c4 CNN\uacfc \uac19\uc740 \uacb0\uacfc\n       ResNet\uc740 50 epoch\uacb0\uacfc val\ub370\uc774\ud130\ub97c 0.97\uae4c\uc9c0 \uad6c\ubd84\ud574 \ub0c8\ub2e4.\n\n50\ud074\ub798\uc2a4 CNN \uc704\uc640 \ube44\uc2b7\ud55c\uacb0\uacfc\n        VGG16 \uc5ed\uc2dc \ube44\uc2b7\ud55c\uacb0\uacfc\n        ResNet\uc740 \uc624\ub974\uae34 \ud558\uc9c0\ub9cc \uc77c\uc815\uad6c\uac04\uc5d0\uc11c val\ub370\uc774\ud130\uc14b\uc758 loss\uac00 \ub5a8\uc5b4\uc9c0\uc9c0 \uc54a\uace0 \uc624\ubc84\ud53c\ud305\uc774 \uc77c\uc5b4\ub0ac\ub2e4.\n\nrecognized \uac00True\uc778 \uac83\uc73c\ub85c \uc2e4\ud5d8\n\uc704\uc758 5\ubc88\uc5d0\uc11c \ub9d0\ud55c\uac83\uacfc \uac19\uc774 False\ub370\uc774\ud130\ub97c \uc81c\uc678\ud558\uace0 \ub2e4\uc2dc \ud6c8\ub828\uc744 \uc2dc\ucf1c \ubcf4\uc558\ub2e4.\n\n50\ud074\ub798\uc2a4 CNN\ub3c4 \uc791\ub3d9\ud558\uae30 \uc2dc\uc791\ud588\uace0 \ud3c9\uade0 acc\uac00 83 , top acc\uac00 95\uae4c\uc9c0 \uc904\uc5c8\ub2e4. \ud6c8\ub828\uc2dc\uac04\uc774 \ub9e4\uc6b0 \uc801\uc5c8\ub2e4.\n        VGG\ub294 \uc5ed\uc2dc \uc791\ub3d9\ud558\uc9c0 \uc54a\uc558\ub2e4.(\uc774\uc720\ub294 convolution\uc774 \uc5ec\ub7ec\ubc88 \uc313\uc5ec 5x5\ub098 7x7\ud544\ud130\ucc98\ub7fc \uc791\uc6a9\ud558\ub294\uac83 \ub54c\ubb38\uc73c\ub85c \uc0dd\uac01 \ud55c\ub2e4.)\n        ResNet\uc740 12epoch\ub54c \uae4c\uc9c0\ub294 loss\uac00 \ucda9\ubd84\ud788 \uac10\uc18c\ud558\uace0 \ud3c9\uade0 acc\uac00 87 , top3 acc\uac00 98 \uae4c\uc9c0 \ub098\uc654\ub2e4.\n\ud558\uc9c0\ub9cc \ubaa8\ub4e0 \ubaa8\ub378\ub4e4\uc774 \uc5d0\ud3ec\ud06c \ucd08\ubc18\uc5d0 \uc624\ubc84\ud53c\ud305\uc774 \ub418\uc5b4 val loss\uac00 \ubc1c\uc0b0\uc744 \ud558\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218\uac00 \uc788\uc5c8\ub2e4.\n\n\uba3c\uc800 \uc624\ubc84\ud53c\ud305\uc744 \ub9c9\uae30\uc704\ud574 CNN\ucd08\uae30\ubaa8\ub378\uc744 \ucee4\uc2a4\ud140\ud558\uc5ec \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4 \ubcf4\uace0\uc790 \ud558\uc600\ub2e4.\nbatch nomalization\ub178\ub4dc\ub97c \ub123\uc5b4 \uc8fc\uace0 \uc2e4\ud5d8\uc744 \ub2e4\uc2dc\ud588\ub2e4. \uadf8\ub7ec\ub098 \uc544\uc9c1\ub3c4 \uc624\ubc84\ud53c\ud305\uc73c\ub85c\nloss\uac00 \ubc1c\uc0b0\ud574\uc11c \ubc1c\uc0b0\ud558\uc9c0 \uc54a\uac8c \ud558\ub294\uac83\uc744 \ubaa9\ud45c\ub85c \ud588\ub2e4 dropout\uc744 \ucd94\uac00\ud574\uc11c \ub2e4\uc2dc \ud574\ubcf4\uc558\ub354\ub2c8 loss\ub294 \ubc1c\uc0b0\ud558\uc9c0 \uc54a\uc558\uc9c0\ub9cc\n\uc804\uccb4 acc\uac00 \ub192\uac8c \ub098\uc624\uc9c0 \uc54a\uc558\ub2e4. \uadf8\ub798\uc11c \ub370\uc774\ud130\uc758 \ud615\ud0dc\ub97c \ub2e4\uc2dc \ubcf4\uace0 \uc77c\uc815\ud55c\ud328\ud134\uc740 \uc788\uc9c0\ub9cc \uc720\uc77c\ubb34\uc774\ud55c \ud328\ud134\uc774\n\uc5c6\ub2e4\uace0 \uc0dd\uac01\ud558\uace0 averagepooling\uc744 \uc0ac\uc6a9\ud574\ubcf4\uc558\ub354\ub2c8 loss\uac00 \uc548\uc815\ub418\uace0 acc\uac00 \ud5a5\uc0c1 \ub418\uc5c8\ub2e4.\n\n\uadf8 \ud6c4 Accuracy\ub97c \ub192\uc774\uae30 \uc704\ud574 \uc804\ucc98\ub9ac\ub41c \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub97c \ubc14\uafd4\ubcf4\uae30\ub85c \ud558\uc600\ub2e4.\n\ucc98\uc74c \uadf8\ub838\ub358 \uadf8\ub9bc\uc740 \ubc30\uacbd\uc774 255 \uadf8\ub9bc\uc774 0 \uac12\uc744 \uac00\uc9c0\uace0 \uc788\uc5c8\uae30\uc5d0 \ubc30\uacbd\uc744 0\uc73c\ub85c \uadf8\ub9bc\uc744 1\ub85c \ubc14\uafd4\uc8fc\uc5b4\uc11c \ud655\uc778 \ud574\ubcf4\uc558\ub2e4.\n50\ud074\ub798\uc2a4 \ubc18\uc804 \uc774\ubbf8\uc9c0 CNN val loss 0.58 val \ud3c9\uade0 acc 87 \n                  CNN_average val_loss 0.5 \ud3c9\uade0 acc 0.88 \n                  ResNet val_loss 0.49 \ud3c9\uade0 acc 0.89\n\nResNet\uc740 \uc131\ub2a5\uc774 \uc81c\uc77c \uc88b\uac8c \ub098\uc654\uc9c0\ub9cc \uadf8\ub0e5 \uc9dc\uc5ec\uc9c4 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\ubcf4\ub2e4\ub294 \uc9c1\uc811 \uc124\uacc4\ud574\ubcf8 \ubaa8\ub378\ub85c \uc81c\ucd9c\ud558\uae30\ub85c \ub9c8\uc74c \uba39\uace0\n\uc124\uacc4\ud55c \ubaa8\ub378\ub85c 340\ud074\ub798\uc2a4\ub2f9 \ub370\uc774\ud130 2000\uac1c\uc529 \ud6c8\ub828\uc2dc\ucf1c \ubd84\ub958 \ud574\ubcf4\uae30\ub85c \ud558\uc600\ub2e4. \n\n340\ud074\ub798\uc2a4 average pooling\uc0ac\uc6a9 -> val acc 75 top3 acc 91\n         Max pooling\uc0ac\uc6a9 -> val acc 69 top3 acc 89\n\n\ucd5c\uc885\uc801\uc73c\ub85c average pooling\uc744 \uc0ac\uc6a9\ud55c \ubaa8\ub378\ub85c \uacb0\uc815\ud558\uc5ec \uc81c\ucd9c\ud558\uae30\ub85c \ud558\uc600\ub2e4.","96436d0a":"# \ubaa8\ub378\uc124\uacc4","9a818ee0":"# test\ub370\uc774\ud130 \uc804\ucc98\ub9ac","709e93a2":"# \uc9c4\ud589\uacfc\uc815\uacfc \uc0dd\uac01 \uc815\ub9ac","5b1737ca":"# pyplot\uc744 \uc774\uc6a9\ud558\uc5ec \uadf8\ub9bc \ud655\uc778","5723e7cb":"# \uc704 \ud568\uc218\ub4e4\uc744 \uc774\uc6a9\ud558\uc5ec \uc804\ucc98\ub9ac\ub97c \ud558\uc5ec Train\ub370\uc774\ud130\ub97c \ucd94\ucd9c","9c131dd2":"# \ud6c8\ub828\uc744\ud1b5\ud574 \uc815\ud655\ub3c4 \uac80\uc99d","b8693f86":"# \uadf8\ub798\ud504\ub97c \ud1b5\ud55c \uc131\ub2a5 \uac80\uc99d","89c668d6":"    #ResNet50\n    K = class_num\n\n    input_tensor = Input(shape=(64, 64, 1), dtype='float32', name='input')\n\n    def conv1_layer(x):    \n        x = ZeroPadding2D(padding=(3, 3))(x)\n        x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = ZeroPadding2D(padding=(1,1))(x)\n\n        return x   \n\n    def conv2_layer(x):         \n        x = MaxPooling2D((3, 3), 2)(x)     \n\n        shortcut = x\n\n        for i in range(3):\n            if (i == 0):\n                x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n                shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n                x = BatchNormalization()(x)\n                shortcut = BatchNormalization()(shortcut)\n\n                x = Add()([x, shortcut])\n                x = Activation('relu')(x)\n\n                shortcut = x\n\n            else:\n                x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)            \n\n                x = Add()([x, shortcut])   \n                x = Activation('relu')(x)  \n\n                shortcut = x        \n\n        return x\n\n    def conv3_layer(x):        \n        shortcut = x    \n\n        for i in range(4):     \n            if(i == 0):            \n                x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)        \n\n                x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)  \n\n                x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n                shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n                x = BatchNormalization()(x)\n                shortcut = BatchNormalization()(shortcut)            \n\n                x = Add()([x, shortcut])    \n                x = Activation('relu')(x)    \n\n                shortcut = x              \n\n            else:\n                x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)            \n\n                x = Add()([x, shortcut])     \n                x = Activation('relu')(x)\n\n                shortcut = x      \n\n        return x\n\n    def conv4_layer(x):\n        shortcut = x        \n\n        for i in range(6):     \n            if(i == 0):            \n                x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)        \n\n                x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)  \n\n                x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n                shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n                x = BatchNormalization()(x)\n                shortcut = BatchNormalization()(shortcut)\n\n                x = Add()([x, shortcut]) \n                x = Activation('relu')(x)\n\n                shortcut = x               \n\n            else:\n                x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)            \n\n                x = Add()([x, shortcut])    \n                x = Activation('relu')(x)\n\n                shortcut = x      \n\n        return x\n\n    def conv5_layer(x):\n        shortcut = x    \n\n        for i in range(3):     \n            if(i == 0):            \n                x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)        \n\n                x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)  \n\n                x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n                shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n                x = BatchNormalization()(x)\n                shortcut = BatchNormalization()(shortcut)            \n\n                x = Add()([x, shortcut])  \n                x = Activation('relu')(x)      \n\n                shortcut = x               \n\n            else:\n                x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n                x = BatchNormalization()(x)\n                x = Activation('relu')(x)\n\n                x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n                x = BatchNormalization()(x)           \n\n                x = Add()([x, shortcut]) \n                x = Activation('relu')(x)       \n\n                shortcut = x                  \n\n        return x\n\n    x = conv1_layer(input_tensor)\n    x = conv2_layer(x)\n    x = conv3_layer(x)\n    x = conv4_layer(x)\n    x = conv5_layer(x)\n    x = GlobalAveragePooling2D()(x)\n    output_tensor = Dense(K, activation='softmax')(x)\n\n    resnet50 = Model(input_tensor, output_tensor)\n    resnet50.summary()","ec480163":"**VGG16 \ubaa8\ub378","ea121667":"# top3 \uc608\uce21\uac12 \ud074\ub798\uc2a4\uc774\ub984\uc73c\ub85c \ubcc0\ud658","5f9f7cf8":"# \uc0ac\uc6a9\ud560 \ud328\ud0a4\uc9c0 \ubaa8\ub4c8 import","b18459f8":"# pandas\ub97c \uc774\uc6a9\ud558\uc5ec \ub370\uc774\ud130 \ud655\uc778","430658c2":"# test\ub370\uc774\ud130 \uc608\uce21","2c743049":"****VGG16****\n\n    inputs = (64,64,1)\n    st_filter = 32\n    filter_size = (3,3) \n\n    VGG16 = Sequential()\n    VGG16.add(layers.Conv2D(st_filter,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.MaxPooling2D((2,2),padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*2,filter_size, activation = 'relu', input_shape = inputs,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*2,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.MaxPooling2D((2,2),padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*4,filter_size, activation = 'relu', input_shape = inputs,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*4,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*4,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.MaxPooling2D((2,2),padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*8,filter_size, activation = 'relu', input_shape = inputs,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*8,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*8,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.MaxPooling2D((2,2),padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*16,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*16,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.Conv2D(st_filter*16,filter_size, activation = 'relu', input_shape = inputs ,padding= 'same'))\n    VGG16.add(layers.MaxPooling2D((2,2),padding= 'same'))\n    VGG16.add(layers.Flatten())\n    VGG16.add(layers.Dense(2*2*512,activation = 'relu'))\n    VGG16.add(layers.Dropout(0.5))\n    VGG16.add(layers.Dense(class_num, activation = 'softmax'))\n\n    VGG16.summary()","717dc9ff":"# \ud3f4\ub354\uc774\ub984\uacfc \ud30c\uc77c \uc774\ub984 \ud655\uc778","ef12ccd4":"**CNN \ubaa8\ub378","157609c3":"# \ubaa8\ub378\uc5d0\uc11c \ud655\uc778\ud560 train\uacfc test\ub97c \ub098\ub204\uc5b4\uc90c"}}