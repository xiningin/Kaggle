{"cell_type":{"f3eccb2c":"code","3960ae77":"code","a656cf8d":"code","b04018f0":"code","aa06fb34":"code","ac0c4334":"code","50a67a90":"code","6205a176":"code","0ebec72d":"code","6ce21ae0":"code","28efe557":"code","0d2d15f4":"code","84b9152b":"code","6de0a4b7":"code","a919e523":"code","181764f3":"code","9664b4b6":"code","fe3b8db0":"markdown","1aaeded6":"markdown","2a8f6f3d":"markdown","ab4fd488":"markdown"},"source":{"f3eccb2c":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3960ae77":"data_df = pd.read_csv('\/kaggle\/input\/techuklon-int20h\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/techuklon-int20h\/test.csv')\nsample_submition = pd.read_csv('\/kaggle\/input\/techuklon-int20h\/Samle_Submission.csv')","a656cf8d":"print('Unique drivers id', len(data_df.Id.unique()))","b04018f0":"percentage_of_ones = round(100*data_df[data_df['target'] == 1].shape[0]\/data_df.shape[0], 2)\nplt.title('target '+str(percentage_of_ones)+'% ones')\nplt.hist(data_df['target'].dropna().values.reshape(-1,1))\nplt.show()","aa06fb34":"# % of nan in data by column\n100*data_df.isna().sum()\/data_df.shape[0]","ac0c4334":"print(data_df[data_df.V1.isna()].target.unique())\ndata_df[data_df.V1.isna()].sample(10)","50a67a90":"for col in ['P12', 'P20', 'P24']:\n    plt.title(col)\n    plt.hist(data_df[col].dropna().values.reshape(-1,1))\n    plt.show()","6205a176":"# All features are positive\n\n(data_df.iloc[:,1:] < 0).sum().sum()","0ebec72d":"# As I planned use LGBM will fill all nan with -1\n\ndata_df = data_df.fillna(-1)\ntest_df = test_df.fillna(-1)\n","6ce21ae0":"from sklearn.model_selection import KFold\n\nN_FOLDS = 10\nkf = KFold(n_splits=N_FOLDS, random_state=42)\n\nunique_drivers_df = pd.DataFrame(data_df.Id.unique(), columns=['id'])\nunique_drivers_df['fold'] = -1\nfor fold, (train_index, test_index) in enumerate(kf.split(unique_drivers_df)):\n    unique_drivers_df['fold'].iloc[test_index] = fold\n    \ndata_df['fold'] = data_df['Id'].replace(unique_drivers_df.set_index('id').to_dict()['fold'])\ndata_df['fold'].plot()","28efe557":"#from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import auc, roc_auc_score\nimport lightgbm as lgb","0d2d15f4":"columns_for_model = data_df.drop(columns=['Id', 'target', 'fold']).columns\n\nparams = {\n        'objective': 'cross_entropy',\n        'metric': 'auc',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'feature_fraction': 0.9,\n        'bagging_fraction': 0.8,\n        'bagging_freq': 5,\n        'verbose': 0\n    }\n\nparam_stopping = {'early_stopping': 100,\n                    'num_boost_round':1000\n                       }\n\nmetrics = []\ncross_validation_list = []\nfor fold in range(N_FOLDS):\n    \n    train_df = data_df[data_df.fold != fold]\n    valid_df = data_df[data_df.fold == fold]\n\n    lgb_train_dataset = lgb.Dataset(train_df[columns_for_model], train_df.target)\n    lgb_valid_dataset = lgb.Dataset(valid_df[columns_for_model], valid_df.target, reference=lgb_train_dataset)\n\n\n    lgb_model = lgb.train(params,\n                    lgb_train_dataset,\n                    num_boost_round=param_stopping['num_boost_round'],\n                    valid_sets=lgb_valid_dataset,\n                    callbacks=[lgb.early_stopping(stopping_rounds=param_stopping['early_stopping'])])\n\n    valid_df['pred'] = lgb_model.predict(valid_df[columns_for_model])\n    fold_metrics = roc_auc_score(valid_df['target'].values, valid_df['pred'].values)\n    metrics.append(fold_metrics)\n    cross_validation_list.append(valid_df[['Id', 'Week', 'target', 'pred']])\n    print('fold',fold,'auc', fold_metrics)\n    \n    test_df['pred_'+str(fold)] = lgb_model.predict(test_df[columns_for_model])\n    \ncross_validation_df = pd.concat(cross_validation_list)","84b9152b":"xgb_cross_validation_groupby_df = cross_validation_df.groupby(['Id', 'target']).apply(lambda row: row.pred.mean()).reset_index().rename(columns={0:'mean_pred'})","6de0a4b7":"lgb_cross_validation_groupby_df = cross_validation_df.groupby(['Id', 'target']).apply(lambda row:\n                                      row.pred.mean()).reset_index().rename(columns={0:'mean_pred'})\nlgb_cross_validation_groupby_df","a919e523":"roc_auc_score(lgb_cross_validation_groupby_df.target, lgb_cross_validation_groupby_df.mean_pred)","181764f3":"sub_df = test_df[['Id']]\nsub_df['Predicted'] = test_df[[col for col in test_df if 'pred' in col]].mean(1)\nsub_df = sub_df.groupby(['Id']).apply(lambda row:\n                                      row.Predicted.mean()).reset_index().rename(columns={0:'Predicted'})\nsub_df","9664b4b6":"sub_df.to_csv('sub_df.csv', index=False)","fe3b8db0":"# Mean work better than median ","1aaeded6":"# CV\n\nWe need split drivers into folds using unique ID","2a8f6f3d":"# Columns with rating\n\nThis 3 columns have similar values as rating of users or drivers\n\nDidn't come up with anything :)","ab4fd488":"# V1 and V2 nan\nIf drivers have 99% (in one week P14 has value) of column -> they will leave\n\nThis is 12 driver in train and 3 in test\n\nIf put the chance for this value manually for this drivers\ndifference in scores will be 1e-16 :)\n"}}