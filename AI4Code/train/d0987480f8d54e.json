{"cell_type":{"a95c7433":"code","a57974c5":"code","33c1f58a":"code","282da0af":"code","46156e74":"code","13f980b8":"code","70942bd5":"code","76da906b":"code","da3ebe3a":"code","6eaef1eb":"code","4b2ef720":"code","76828453":"code","dd5210eb":"code","47a52690":"code","78d53732":"code","6897c27f":"code","5a624eee":"code","f798056a":"code","7ca13720":"code","b6925195":"code","015d528f":"code","d2923ca9":"code","666c00d1":"code","b546e686":"code","326edce5":"code","92449ee5":"code","ee135749":"code","92209a41":"code","03aa851b":"code","2c91100c":"code","00bcd926":"code","4927dcd4":"code","f479ffcc":"code","8cd3d2b6":"code","5a74f296":"code","43e44416":"code","4fe1c423":"code","4734429f":"code","d9806993":"markdown","ef5b18cb":"markdown","d58dbb85":"markdown","ba646c49":"markdown","a90024de":"markdown","3811e4d2":"markdown"},"source":{"a95c7433":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a57974c5":"data_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndata_train.head()","33c1f58a":"sns.heatmap(data_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","282da0af":"train_num = data_train[['Age','SibSp','Parch','Fare']]\ntrain_cat = data_train[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","46156e74":"for i in train_num.columns:\n    plt.hist(train_num[i])\n    plt.title(i)\n    plt.show()","13f980b8":"pd.pivot_table(data_train, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])","70942bd5":"for i in train_cat.columns:\n    sns.barplot(train_cat[i].value_counts().index,train_cat[i].value_counts()).set_title(i)\n    plt.show()","76da906b":"print(pd.pivot_table(data_train, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(data_train, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(data_train, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))","da3ebe3a":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=data_train,palette='winter')","6eaef1eb":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age","4b2ef720":"data_train['Age'] = data_train[['Age','Pclass']].apply(impute_age,axis=1)","76828453":"sns.heatmap(data_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","dd5210eb":"data_train.drop('Cabin',axis=1,inplace=True)","47a52690":"data_train.head()","78d53732":"data_train.dropna(inplace=True)","6897c27f":"data_train.shape","5a624eee":"Q1 = data_train.quantile(0.25)\nQ3 = data_train.quantile(0.75)\nIQR = Q3 - Q1\ndata_train = data_train[~((data_train < (Q1 - 1.5 * IQR)) |(data_train > (Q3 + 1.5 * IQR))).any(axis=1)]","f798056a":"data_train.shape","7ca13720":"data_train.isnull().any()","b6925195":"data_train.info()","015d528f":"sex = pd.get_dummies(data_train['Sex'])\nembark = pd.get_dummies(data_train['Embarked'])","d2923ca9":"embark","666c00d1":"sex","b546e686":"data_train","326edce5":"data_train.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)\ndata_train.head()","92449ee5":"data_train = pd.concat([data_train,sex,embark],axis=1)\ndata_train.head()","ee135749":"data_test.head()\n\ndata_test['Age'] = data_test[['Age','Pclass']].apply(impute_age,axis=1)\ndata_test.drop('Cabin',axis=1,inplace=True)\n\nsex2 = pd.get_dummies(data_test['Sex'])\nembark2 = pd.get_dummies(data_test['Embarked'])\n\ndata_test.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)\ndata_test.head()\ndata_test = pd.concat([data_test,sex2,embark2],axis=1)\ndata_test.head()\n\ndata_test.shape\n\ndata_test\n\ndata_test.isnull().any()\n\nsns.heatmap(data_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n\ndata_test[\"Fare\"] = data_test[\"Fare\"].fillna((data_test[\"Fare\"].median()))\n\n","92209a41":"from sklearn.model_selection import train_test_split","03aa851b":"X = data_train.drop(['Survived'],axis=1)\ny = data_train['Survived']\nX.head()\n","2c91100c":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(X)\nx_test=sc.fit_transform(data_test)","00bcd926":"import time\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\ndef model_result(model):\n    start = time.time()\n    model.fit(x_train,y)\n    mean_result = cross_val_score(model,x_train,y,cv=5,scoring='neg_mean_squared_error')\n    stop = time.time()\n    print(f\"Time spend : {round((stop-start),2)}s\")\n    return -1*mean_result.mean()","4927dcd4":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogmodel = LogisticRegression()\nlogmodel.fit(x_train,y)\npredictions = logmodel.predict(x_test)\nprint(\"Linear Regression :  {}\".format(np.sqrt(model_result(logmodel))))","f479ffcc":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y)\npredictions2 = dt.predict(x_test)\nprint(\"Linear Regression :  {}\".format(np.sqrt(model_result(dt))))","8cd3d2b6":"from sklearn.neighbors import KNeighborsClassifier\nkkn = KNeighborsClassifier(n_neighbors=19)\nkkn.fit(x_train,y)\npredictions3 = kkn.predict(x_test)\nprint(\"Linear Regression :  {}\".format(np.sqrt(model_result(kkn))))","5a74f296":"from sklearn.naive_bayes import GaussianNB\nnaive = GaussianNB()\nnaive.fit(x_train,y)\npredictions4 = naive.predict(x_test)\nprint(\"Linear Regression :  {}\".format(np.sqrt(model_result(naive))))","43e44416":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(x_train,y)\npredictions5=rf.predict(x_test)\nprint(\"Linear Regression :  {}\".format(np.sqrt(model_result(rf))))","4fe1c423":"from sklearn import svm\ncls=svm.SVC(kernel=\"linear\")\ncls.fit(x_train,y)\npredictions6=cls.predict(x_test)\nprint(\"Linear Regression :  {}\".format(np.sqrt(model_result(cls))))","4734429f":"output = pd.DataFrame({'PassengerId': data_test.PassengerId,\n                       'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\noutput.head()","d9806993":"## Training and Predicting","ef5b18cb":"___\n## Data Cleaning\n","d58dbb85":"___\n## Converting Categorical Features ","ba646c49":"___\n# Building our Logistic Regression Model","a90024de":"___\n# Exploratory Data Analysis\n\nLet's explore the dataset","3811e4d2":"# Titanic - Machine Learning from Disaster\n\nHello everyone!\n\nThis is my third notebook and my first on analyzing Titanic Dataset.\n\nI've taken some code from some sources, including Ken Jee's, he is a great youtuber,\nHere's a link to his notebook, enjoy!\nhttps:\/\/www.kaggle.com\/kenjee\/titanic-project-example"}}