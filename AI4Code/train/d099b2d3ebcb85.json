{"cell_type":{"5ed08920":"code","088b5155":"code","2470bea1":"code","6b5feb9d":"code","4d968f39":"code","709e76c4":"code","ed84a7ab":"code","09998a7f":"code","5a6cd4e0":"code","e98748b9":"code","740152d1":"code","278c4df9":"code","0d052ba0":"code","0271037d":"code","953db55c":"code","5d977b96":"code","1dee3696":"code","0da2337f":"code","2eb0f83d":"code","66d18f8f":"code","d21ad193":"code","c63e84ec":"code","20ff93db":"code","eabeba80":"code","5058d762":"code","4370de19":"code","3e41261d":"code","1cca0b60":"code","5068a0c4":"code","11c06dc5":"code","fa28c1e8":"code","69f892f4":"code","cc6314e6":"code","fb55388a":"code","f30c82ad":"code","f9950427":"code","9a066c95":"code","c8f270d6":"code","3eb2e6b0":"markdown","7b61c291":"markdown","d4a315a0":"markdown","eca3317e":"markdown","0edc1660":"markdown","08a55786":"markdown","ee992c04":"markdown","5aaed9fa":"markdown","cfafb5bd":"markdown","ceb19ba1":"markdown","44794e01":"markdown","6da2d8d5":"markdown"},"source":{"5ed08920":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\nfrom sklearn.svm import SVC","088b5155":"data=pd.read_csv(\"..\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv\")","2470bea1":"data.head(5)","6b5feb9d":"len(data)","4d968f39":"data.info()","709e76c4":"data.isnull().sum()","ed84a7ab":"data.describe(include='all')","09998a7f":"data.rename(columns={'default.payment.next.month':'def_pay'}, inplace=True)\ndata.rename(columns={'PAY_0':'PAY_1'}, inplace=True)","5a6cd4e0":"data.head()","e98748b9":"# Creating a new dataframe with categorical variables\nsubset = data[['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', \n               'PAY_5', 'PAY_6', 'def_pay']]\n\nf, axes = plt.subplots(3, 3, figsize=(20, 15), facecolor='white')\nf.suptitle('FREQUENCY OF CATEGORICAL VARIABLES (BY TARGET)')\nax1 = sns.countplot(x=\"SEX\", hue=\"def_pay\", data=subset, palette=\"Blues\", ax=axes[0,0])\nax2 = sns.countplot(x=\"EDUCATION\", hue=\"def_pay\", data=subset, palette=\"Blues\",ax=axes[0,1])\nax3 = sns.countplot(x=\"MARRIAGE\", hue=\"def_pay\", data=subset, palette=\"Blues\",ax=axes[0,2])\nax4 = sns.countplot(x=\"PAY_1\", hue=\"def_pay\", data=subset, palette=\"Blues\", ax=axes[1,0])\nax5 = sns.countplot(x=\"PAY_2\", hue=\"def_pay\", data=subset, palette=\"Blues\", ax=axes[1,1])\nax6 = sns.countplot(x=\"PAY_3\", hue=\"def_pay\", data=subset, palette=\"Blues\", ax=axes[1,2])\nax7 = sns.countplot(x=\"PAY_4\", hue=\"def_pay\", data=subset, palette=\"Blues\", ax=axes[2,0])\nax8 = sns.countplot(x=\"PAY_5\", hue=\"def_pay\", data=subset, palette=\"Blues\", ax=axes[2,1])\nax9 = sns.countplot(x=\"PAY_6\", hue=\"def_pay\", data=subset, palette=\"Blues\", ax=axes[2,2]);","740152d1":"#  looking at correlations matrix, defined via Pearson function  \ncorr = data.corr() # .corr is used to find corelation\nf,ax = plt.subplots(figsize=(8, 7))\nsns.heatmap(corr, cbar = True,  square = True, annot = False, fmt= '.1f', \n            xticklabels= True, yticklabels= True\n            ,cmap=\"coolwarm\", linewidths=.5, ax=ax)\nplt.title('CORRELATION MATRIX - HEATMAP', size=18);","278c4df9":"x=data.drop('def_pay',axis=1)\ny=data['def_pay']","0d052ba0":"x","0271037d":"y","953db55c":"from sklearn.model_selection import train_test_split","5d977b96":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=100)","1dee3696":"from sklearn.ensemble import RandomForestClassifier\nclassifier=RandomForestClassifier(n_estimators=25)\nclassifier.fit(x_train,y_train)","0da2337f":"r2=classifier.score(x_train,y_train)\nr2","2eb0f83d":"x.shape","66d18f8f":"n=84\np=2\nadj_r2=1-(1-r2)*(n-1)\/(n-p-1)\nadj_r2","d21ad193":"from sklearn.feature_selection import f_regression","c63e84ec":"f_regression(x,y)","20ff93db":"p_value=f_regression(x,y)[1]\np_value","eabeba80":"p_value.round(4)","5058d762":"predicition=classifier.predict((x_test))","4370de19":"from sklearn.metrics import confusion_matrix,accuracy_score","3e41261d":"confusion_matrix(y_test,predicition)","1cca0b60":"accuracy_score(y_test,predicition)","5068a0c4":"n_estimators=[20,65,100,150,200,250,350]\nmax_features=['auto','sqrt']\nmax_depth=[2,4]\nmin_samples_split=[2,5]\nmin_samples_leaf=[1,2]\nbootstrap=[True,False]\n    ","11c06dc5":"param_grid={'n_estimators':n_estimators,\n            'max_features':max_features,\n            'max_depth':max_depth,\n            'min_samples_split':min_samples_split,\n            'min_samples_leaf':min_samples_leaf,\n            'bootstrap':bootstrap\n           }\nprint(param_grid)","fa28c1e8":"rf_model=RandomForestClassifier()","69f892f4":"from sklearn.model_selection import GridSearchCV\ngrid=GridSearchCV(estimator=rf_model,param_grid=param_grid,cv=3,verbose=2,n_jobs=4)","cc6314e6":"result=grid.fit(x_train,y_train)","fb55388a":"grid.best_params_","f30c82ad":"print (f'train accuracy-:{grid.score(x_train,y_train):.3f}')\nprint (f'test accuracy-:{grid.score(x_test,y_test):.3f}')","f9950427":"from sklearn.svm import SVC\nmodel=SVC()","9a066c95":"model.fit(x_train,y_train)","c8f270d6":"print (f' train accuracy-:{model.score(x_train,y_train):.3f}')\nprint (f'test accuracy-:{model.score(x_test,y_test):.3f}')","3eb2e6b0":"# build RandomForest model","7b61c291":"credit card","d4a315a0":"lets check any null value present in dataset","eca3317e":"to find good parameter for model","0edc1660":"now check first 5 rows using head functon.\n\nas you see in data we have 25coloums.in data set ","08a55786":"here we check lenght of dataset","ee992c04":"after importing librarys we read data using panda dataframe.","5aaed9fa":"first we import library and data","cfafb5bd":"# Build SVM model","ceb19ba1":"as we can see that the accuracy of randomforest is higher then supervectormachine","44794e01":"there is no null values or missing values present in dataset","6da2d8d5":"# Hypyerparameter tuning using RandomsedSearchCV"}}