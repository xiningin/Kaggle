{"cell_type":{"b22487cd":"code","b0b6bee1":"code","38348b31":"code","6918d4e6":"code","99919577":"code","b301bad9":"code","22033252":"code","e026c1b1":"code","523e0398":"code","71342242":"markdown","1930a94b":"markdown","6476564c":"markdown","057fba3f":"markdown","f04c206f":"markdown","cf594227":"markdown","d35a7ec3":"markdown","a8b3e659":"markdown","eb031008":"markdown","038d0395":"markdown"},"source":{"b22487cd":"import numpy as np\nimport pandas as pd\n\nimport IPython\nimport tensorflow as tf\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","b0b6bee1":"base_path = '..\/input\/binance-top-cryptocurrencies\/'\ndf_xlm = pd.read_csv(base_path + 'XLM.csv')['open']\ndf_xlm = pd.DataFrame({'open' : df_xlm.values})\n\ntrain_df, test_df = train_test_split(df_xlm, test_size=0.3, random_state=42)\nval_df = pd.read_csv(base_path + 'ADA.csv')['open']\nval_df = pd.DataFrame({'open' : val_df.values})","38348b31":"class WindowGenerator():\n    def __init__(self, input_width, label_width, shift,\n               train_df=train_df, val_df=val_df, test_df=test_df,\n               label_columns=None):\n        \n        # Store the raw data.\n        self.train_df = train_df\n        self.val_df = val_df\n        self.test_df = test_df\n\n        # Work out the label column indices.\n        self.label_columns = label_columns\n        if label_columns is not None:\n            self.label_columns_indices = {name: i for i, name in\n                                        enumerate(label_columns)}\n        self.column_indices = {name: i for i, name in\n                               enumerate(train_df.columns)}\n\n        # Work out the window parameters.\n        self.input_width = input_width\n        self.label_width = label_width\n        self.shift = shift\n\n        self.total_window_size = input_width + shift\n\n        self.input_slice = slice(0, input_width)\n        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n        self.label_start = self.total_window_size - self.label_width\n        self.labels_slice = slice(self.label_start, None)\n        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n    def __repr__(self):\n        return '\\n'.join([\n            f'Total window size: {self.total_window_size}',\n            f'Input indices: {self.input_indices}',\n            f'Label indices: {self.label_indices}',\n            f'Label column name(s): {self.label_columns}'])","6918d4e6":"class WindowGenerator(WindowGenerator):\n    def __init__(self, input_width, label_width, shift,\n               label_columns=None):\n        super().__init__(input_width, label_width, shift,\n               label_columns=label_columns)\n\n    def make_dataset(self, data):\n        data = np.array(data, dtype=np.float32)\n        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n            data=data,\n            targets=None,\n            sequence_length=self.total_window_size,\n            sequence_stride=1,\n            shuffle=True,\n            batch_size=32,)\n\n        ds = ds.map(self.split_window)\n        return ds\n    \n    def split_window(self, features):\n        inputs = features[:, self.input_slice, :]\n        labels = features[:, self.labels_slice, :]\n        if self.label_columns is not None:\n            labels = tf.stack(\n                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n                axis=-1)\n\n        # Slicing doesn't preserve static shape information, so set the shapes\n        # manually. This way the `tf.data.Datasets` are easier to inspect.\n        inputs.set_shape([None, self.input_width, None])\n        labels.set_shape([None, self.label_width, None])\n        return inputs, labels\n\n    @property\n    def train(self):\n        return self.make_dataset(self.train_df)\n\n    @property\n    def val(self):\n        return self.make_dataset(self.val_df)\n\n    @property\n    def test(self):\n        return self.make_dataset(self.test_df)\n\n    @property\n    def example(self):\n        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n        result = getattr(self, '_example', None)\n        if result is None:\n            # No example batch was found, so get one from the `.train` dataset\n            result = next(iter(self.train))\n            # And cache it for next time\n            self._example = result\n        return result","99919577":"class WindowGenerator(WindowGenerator):\n    def __init__(self, input_width, label_width, shift,\n               label_columns=None):\n        super().__init__(input_width, label_width, shift,\n               label_columns=label_columns)\n        \n    def plot(self, model=None, plot_col='open', max_subplots=3):\n        inputs, labels = self.example\n        plt.figure(figsize=(12, 8))\n        plot_col_index = self.column_indices[plot_col]\n        max_n = min(max_subplots, len(inputs))\n        for n in range(max_n):\n            plt.subplot(max_n, 1, n+1)\n            plt.ylabel(f'{plot_col} [normed]')\n            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n                 label='Inputs', marker='.', zorder=-10)\n\n        if self.label_columns:\n            label_col_index = self.label_columns_indices.get(plot_col, None)\n        else:\n            label_col_index = plot_col_index\n\n        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n        \n        if model is not None:\n            predictions = model(inputs)\n            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                      marker='X', edgecolors='k', label='Predictions',\n                      c='#ff7f0e', s=64)\n\n        if n == 0:\n            plt.legend()\n\n        plt.xlabel('Time [h]')","b301bad9":"num_features = 1\nOUT_STEPS = 24\n\nmulti_window = WindowGenerator(input_width=24,\n                               label_width=OUT_STEPS,\n                               shift=OUT_STEPS)\n\nmulti_window.plot()\nmulti_window","22033252":"class FeedBack(tf.keras.Model):\n    def __init__(self, units, out_steps):\n        super().__init__()\n        self.out_steps = out_steps\n        self.units = units\n        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n        self.dense = tf.keras.layers.Dense(num_features)\n        \n    def warmup(self, inputs):\n        # inputs.shape => (batch, time, features)\n        # x.shape => (batch, lstm_units)\n        x, *state = self.lstm_rnn(inputs)\n\n        # predictions.shape => (batch, features)\n        prediction = self.dense(x)\n        return prediction, state\n    \n    def call(self, inputs, training=None):\n        # Use a TensorArray to capture dynamically unrolled outputs.\n        predictions = []\n        # Initialize the lstm state\n        prediction, state = self.warmup(inputs)\n\n        # Insert the first prediction\n        predictions.append(prediction)\n\n        # Run the rest of the prediction steps\n        for n in range(1, self.out_steps):\n            # Use the last prediction as input.\n            x = prediction\n            # Execute one lstm step.\n            x, state = self.lstm_cell(x, states=state,\n                                      training=training)\n            # Convert the lstm output to a prediction.\n            prediction = self.dense(x)\n            # Add the prediction to the output\n            predictions.append(prediction)\n\n        # predictions.shape => (time, batch, features)\n        predictions = tf.stack(predictions)\n        # predictions.shape => (batch, time, features)\n        predictions = tf.transpose(predictions, [1, 0, 2])\n        return predictions\n\nfeedback_model = FeedBack(units=32, out_steps=OUT_STEPS)\nprediction, state = feedback_model.warmup(multi_window.example[0])\nprint(prediction.shape)","e026c1b1":"MAX_EPOCHS = 20\n\ndef compile_and_fit(model, window, patience=2):\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n    model.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer=tf.optimizers.Adam(),\n                metrics=[tf.metrics.MeanAbsoluteError()])\n\n    history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n    return history","523e0398":"history = compile_and_fit(feedback_model, multi_window)\n\nIPython.display.clear_output()\n\neval_val = feedback_model.evaluate(multi_window.val)\neval_test = feedback_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(feedback_model)","71342242":"![multistep_autoregressive.png](attachment:3932783a-fa84-4a77-a5ce-70750f603a8c.png)","1930a94b":"<h1 id=\"dataset\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","6476564c":"<h1 id=\"reference\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Reference\n        <a class=\"anchor-link\" href=\"#reference\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","057fba3f":"<h1 id=\"train\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#train\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","f04c206f":"<h1 id=\"window\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Window Generator Plot\n        <a class=\"anchor-link\" href=\"#window\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","cf594227":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/1095652\/1842717\/81b3e916b94ca50abf884397c5641711\/dataset-cover.jpeg\" \/>\n<\/div>","d35a7ec3":"<h1 id=\"window\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Window Generator Datasets\n        <a class=\"anchor-link\" href=\"#window\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","a8b3e659":"Tensorflow [Time Series Tutorial](https:\/\/www.tensorflow.org\/tutorials\/structured_data\/time_series)","eb031008":"<h1 id=\"window\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Window Generator\n        <a class=\"anchor-link\" href=\"#window\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","038d0395":"<h1 id=\"autoregressive\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Autoregressive\n        <a class=\"anchor-link\" href=\"#autoregressive\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}