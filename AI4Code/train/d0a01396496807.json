{"cell_type":{"9c9d3249":"code","018d29c2":"code","055eb501":"code","d70cb9d9":"code","3d62d806":"code","cc9c5411":"code","ee25b4ba":"code","f8b53aab":"code","6832248b":"code","7a83688d":"code","520377b1":"code","bde97d2f":"code","31f7e67e":"code","b0c19555":"code","5a11fb4f":"code","4f923eb0":"code","42b85000":"code","c7621d00":"code","07a122c0":"code","5203014b":"code","eee1fe8e":"code","b88991a9":"code","83f35190":"code","4089f197":"code","b703ab8e":"code","f9fab833":"code","d4dd96eb":"code","b1d19503":"code","ede864f8":"code","a94c3f7a":"code","e0256230":"code","7be81c0f":"code","c0404415":"code","cf4233f2":"code","a33d2e82":"code","ee7e695b":"code","d6fe8f54":"code","00c324b7":"code","d3ed41c3":"code","4c04cd49":"code","e93299f6":"code","e3e5cec6":"code","33017c63":"markdown","c874efc0":"markdown","d563bdde":"markdown","5bffe0c6":"markdown","e6e2818d":"markdown","86b7de90":"markdown","ec20f013":"markdown","ca534154":"markdown","e4728c22":"markdown","16a07b11":"markdown","d9eb589f":"markdown","ac18a3b7":"markdown","f3b6a5d5":"markdown","65817321":"markdown","c63ff649":"markdown","d0da2959":"markdown","61958ebb":"markdown","4b3683f2":"markdown","eb02eb57":"markdown","48e447f9":"markdown","b78274d0":"markdown","09717c79":"markdown","a829a4fe":"markdown","2e41717d":"markdown","5fe61f97":"markdown","e3cee454":"markdown","fda8d6d4":"markdown","429be737":"markdown","6dda6d9c":"markdown","d0c68208":"markdown"},"source":{"9c9d3249":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline","018d29c2":"df = pd.read_csv('..\/input\/winequality-red.csv')","055eb501":"df.head()","d70cb9d9":"df.describe()","3d62d806":"correlations = df.corr()['quality'].drop('quality')\nprint(correlations)","cc9c5411":"_ = correlations.plot(kind='bar')","ee25b4ba":"import seaborn as sns\nsns.heatmap(df.corr())","f8b53aab":"train = df.sample(frac=0.8)\ntest_and_validation = df.loc[~df.index.isin(train.index)]\nvalidation = test_and_validation.sample(frac=0.5)\ntest = test_and_validation.loc[~test_and_validation.index.isin(validation.index)]\n\nprint(train.shape, validation.shape, test.shape)","6832248b":"def get_features(correlation_threshold):\n    abs_corrs = correlations.abs()\n    high_correlations = abs_corrs[abs_corrs > correlation_threshold].index.values.tolist()\n    return high_correlations","7a83688d":"def compare_predictions(predicted, test_df, target_col):\n    # Since we have to predict integer values, and the regressor will return float, let's round predicted dataframe\n    predicted = predicted.round(0)\n    check_df = pd.DataFrame(data=predicted, index=test_df.index, columns=[\"Predicted \"+target_col])\n    check_df = pd.concat([check_df, test_df[[target_col]]], axis=1)\n    check_df[\"Error, %\"] = np.abs(check_df[\"Predicted \"+target_col]*100\/check_df[target_col] - 100)\n    check_df['Error, val'] = check_df[\"Predicted \"+target_col] - check_df[target_col]\n    return (check_df.sort_index(), check_df[\"Error, %\"].mean())","520377b1":"def evaluate_predictions(model, train_df, test_df, features, target_col):\n    train_pred = model.predict(train_df[features])\n    train_rmse = mean_squared_error(train_pred, train_df[target_col]) ** 0.5\n\n    test_pred = model.predict(test_df[features])\n    test_rmse = mean_squared_error(test_pred, test_df[target_col]) ** 0.5\n\n    print(\"RMSEs:\")\n    print(train_rmse, test_rmse)\n    \n    return test_pred","bde97d2f":"def lr_model_evaluation(feature_correlation_threshold=0):\n    lr = LinearRegression()\n    features = get_features(feature_correlation_threshold)\n    lr.fit(train[features], train['quality'])\n    lr_validation_predictions = evaluate_predictions(lr, train, validation, features, 'quality')\n    check_df, avg_error = compare_predictions(lr_validation_predictions, validation, 'quality')\n    print(\"Average validation error:\", avg_error)\n    return check_df","31f7e67e":"check = lr_model_evaluation()","b0c19555":"thresholds = [x * 0.05 for x in range(1, 8)] #threshold will scale up to 0.4\n\nfor thr in thresholds:\n    print('For threshold =', thr)\n    _ = lr_model_evaluation(thr)\n    print()","5a11fb4f":"print(get_features(0.15))","4f923eb0":"def dtr_model_evaluation(feature_correlation_threshold=0, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0., max_leaf_nodes=None):\n    dtr = DecisionTreeRegressor(random_state=42, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_leaf_nodes=max_leaf_nodes)\n    features = get_features(feature_correlation_threshold)\n    dtr.fit(train[features], train['quality'])\n    dtr_validation_predictions = evaluate_predictions(dtr, train, validation, features, 'quality')\n    check_df, avg_error = compare_predictions(dtr_validation_predictions, validation, 'quality')\n    print(\"Average validation error:\", avg_error)\n    return check_df, avg_error","42b85000":"check, error = dtr_model_evaluation()","c7621d00":"thresholds = [0, 0.05, 0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4]\nmax_depth_list = [None, 3, 4, 5, 7, 10, 15, 20]\nmin_samples_split_list = [2, 3, 4, 5, 7, 10, 15, 20]\nmin_samples_leaf_list = [1, 2, 3, 5, 7, 10, 0.01, 0.03, 0.05, 0.07, 0.1]\nmin_weight_fraction_leaf_list = [0., 0.01, 0.02, 0.03, 0.05, 0.07, 0.1, 0.12, 0.15, 0.18, 0.2, 0.23, 0.25, 0.3]\nmax_leaf_nodes_list = [None, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n\nhyperparams = {\n    'threshold': thresholds,\n    'max_depth': max_depth_list,\n    'min_samples_split': min_samples_split_list,\n    'min_samples_leaf': min_samples_leaf_list,\n    'min_weight_fraction_leaf': min_weight_fraction_leaf_list,\n    'max_leaf_nodes': max_leaf_nodes_list\n}\n\nvalidation_results = []\nfor hp_name, hp_list in hyperparams.items():\n    errors = []\n    for hp_val in hp_list:\n        if hp_name == 'threshold':\n            _, error = dtr_model_evaluation(feature_correlation_threshold=hp_val)\n        elif hp_name == 'max_depth':\n            _, error = dtr_model_evaluation(max_depth=hp_val)\n        elif hp_name == 'min_samples_split':\n            _, error = dtr_model_evaluation(min_samples_split=hp_val)\n        elif hp_name == 'min_samples_leaf':\n            _, error = dtr_model_evaluation(min_samples_leaf=hp_val)\n        elif hp_name == 'min_weight_fraction_leaf':\n            _, error = dtr_model_evaluation(min_weight_fraction_leaf=hp_val)\n        elif hp_name == 'max_leaf_nodes':\n            _, error = dtr_model_evaluation(max_leaf_nodes=hp_val)\n            \n        errors.append(error)\n    validation_results.append((hp_name, errors))","07a122c0":"fig = plt.figure(figsize=(6, 18))\n\nfor i, result in enumerate(validation_results):\n    ax = fig.add_subplot(len(validation_results), 1, i+1)\n    hp_name = result[0]\n    hp_errors = result[1]\n    \n    ax.set_title(hp_name)\n    ax.plot(range(0, len(hp_errors)), hp_errors)\n    plt.sca(ax)\n    x_labels = hyperparams[hp_name]\n    plt.xticks(range(0, len(hp_errors)), x_labels)\n    \nfig.tight_layout()\nplt.show()","5203014b":"thresholds = [0.2]\nmax_depth_list = [5, 6]\nmin_samples_split_list = [3]\nmin_samples_leaf_list = [0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.085, 0.09, 0.095]\nmin_weight_fraction_leaf_list = [0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.085, 0.09, 0.095]\nmax_leaf_nodes_list = [None]\n\nresults = []\nfor max_depth in max_depth_list:\n    for min_samples_split in min_samples_split_list:\n        for min_samples_leaf in min_samples_leaf_list:\n            for min_weight_fraction_leaf in min_weight_fraction_leaf_list:\n                for max_leaf_nodes in max_leaf_nodes_list:\n                    for thr in thresholds: \n                        hyperparameters = {\n                            'max_depth': max_depth,\n                            'min_samples_split': min_samples_split,\n                            'min_samples_leaf': min_samples_leaf,\n                            'min_weight_fraction_leaf': min_weight_fraction_leaf,\n                            'max_leaf_nodes': max_leaf_nodes,\n                            'threshold': thr\n                        }\n\n                        check, error = dtr_model_evaluation(thr, max_depth=max_depth, min_samples_split=min_samples_split,\n                            min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n                            max_leaf_nodes=max_leaf_nodes)\n                        \n                        results.append((hyperparameters, error))","eee1fe8e":"min(results, key = lambda x: x[1])","b88991a9":"check, error = dtr_model_evaluation(0.2, max_depth=5, min_samples_split=3, min_samples_leaf=0.055, min_weight_fraction_leaf=0.07)\ncheck.head(10)","83f35190":"def rfr_model_evaluation(n_estimators=100):\n    rfr = RandomForestRegressor(random_state=42, n_estimators=n_estimators, max_depth=5, min_samples_split=3, min_samples_leaf=0.055, min_weight_fraction_leaf=0.07)\n    features = get_features(0.2)\n    rfr.fit(train[features], train['quality'])\n    rfr_validation_predictions = evaluate_predictions(rfr, train, validation, features, 'quality')\n    check_df, avg_error = compare_predictions(rfr_validation_predictions, validation, 'quality')\n    print(\"Average validation error:\", avg_error)\n    return check_df, avg_error","4089f197":"check, error = rfr_model_evaluation()","b703ab8e":"rfr = RandomForestRegressor(random_state=42, n_estimators=100)\nfeatures = get_features(0.2)\nrfr.fit(train[features], train['quality'])\nrfr_validation_predictions = evaluate_predictions(rfr, train, validation, features, 'quality')\ncheck_df, avg_error = compare_predictions(rfr_validation_predictions, validation, 'quality')\nprint(\"Average validation error:\", avg_error)","f9fab833":"def rfr_model_evaluation(feature_correlation_threshold=0, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0., max_leaf_nodes=None):\n    rfr = RandomForestRegressor(random_state=42, n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_leaf_nodes=max_leaf_nodes)\n    features = get_features(feature_correlation_threshold)\n    rfr.fit(train[features], train['quality'])\n    rfr_validation_predictions = evaluate_predictions(rfr, train, validation, features, 'quality')\n    check_df, avg_error = compare_predictions(rfr_validation_predictions, validation, 'quality')\n    print(\"Average validation error:\", avg_error)\n    return check_df, avg_error","d4dd96eb":"thresholds = [0, 0.05, 0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4]\nmax_depth_list = [None, 3, 4, 5, 7, 10, 15, 20, 25, 30, 35]\nmin_samples_split_list = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\nmin_samples_leaf_list = [1, 2, 3, 5, 7, 10, 0.01, 0.03, 0.05, 0.07, 0.1]\nmin_weight_fraction_leaf_list = [0., 0.01, 0.02, 0.03, 0.05, 0.07, 0.1, 0.12, 0.15, 0.18, 0.2, 0.23, 0.25, 0.3]\nmax_leaf_nodes_list = [None, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\nn_estimators = [10, 20, 40, 50, 75, 100, 125, 150, 175, 200, 225]\n\nhyperparams = {\n    'threshold': thresholds,\n    'max_depth': max_depth_list,\n    'min_samples_split': min_samples_split_list,\n    'min_samples_leaf': min_samples_leaf_list,\n    'min_weight_fraction_leaf': min_weight_fraction_leaf_list,\n    'max_leaf_nodes': max_leaf_nodes_list,\n    'n_estimators': n_estimators\n}\n\nvalidation_results = []\nfor hp_name, hp_list in hyperparams.items():\n    errors = []\n    for hp_val in hp_list:\n        if hp_name == 'threshold':\n            _, error = rfr_model_evaluation(feature_correlation_threshold=hp_val)\n        elif hp_name == 'max_depth':\n            _, error = rfr_model_evaluation(max_depth=hp_val)\n        elif hp_name == 'min_samples_split':\n            _, error = rfr_model_evaluation(min_samples_split=hp_val)\n        elif hp_name == 'min_samples_leaf':\n            _, error = rfr_model_evaluation(min_samples_leaf=hp_val)\n        elif hp_name == 'min_weight_fraction_leaf':\n            _, error = rfr_model_evaluation(min_weight_fraction_leaf=hp_val)\n        elif hp_name == 'max_leaf_nodes':\n            _, error = rfr_model_evaluation(max_leaf_nodes=hp_val)\n        elif hp_name == 'n_estimators':\n            _, error = rfr_model_evaluation(n_estimators=hp_val)\n            \n        errors.append(error)\n    validation_results.append((hp_name, errors))","b1d19503":"fig = plt.figure(figsize=(7, 21))\n\nfor i, result in enumerate(validation_results):\n    ax = fig.add_subplot(len(validation_results), 1, i+1)\n    hp_name = result[0]\n    hp_errors = result[1]\n    \n    ax.set_title(hp_name)\n    ax.plot(range(0, len(hp_errors)), hp_errors)\n    plt.sca(ax)\n    x_labels = hyperparams[hp_name]\n    plt.xticks(range(0, len(hp_errors)), x_labels)\n    \nfig.tight_layout()\nplt.show()","ede864f8":"thresholds = [0.05, 0.15]\nmax_depth_list = [16, 17, 18, 19, 20, 21, 22, 23, 24]\nmin_samples_split_list = [7]\nmin_samples_leaf_list = [1, 2]\nmin_weight_fraction_leaf_list = [0.0]\nmax_leaf_nodes_list = [None]\nn_estimators = [130, 140, 150, 160, 170]\n\nresults = []\nfor n_estimator in n_estimators:\n    for max_depth in max_depth_list:\n        for min_samples_split in min_samples_split_list:\n            for min_samples_leaf in min_samples_leaf_list:\n                for min_weight_fraction_leaf in min_weight_fraction_leaf_list:\n                    for max_leaf_nodes in max_leaf_nodes_list:\n                        for thr in thresholds:\n                            hyperparameters = {\n                                'max_depth': max_depth,\n                                'min_samples_split': min_samples_split,\n                                'min_samples_leaf': min_samples_leaf,\n                                'min_weight_fraction_leaf': min_weight_fraction_leaf,\n                                'max_leaf_nodes': max_leaf_nodes,\n                                'threshold': thr,\n                                'n_estimators': n_estimator\n                            }\n\n                            check, error = rfr_model_evaluation(thr, n_estimators=n_estimator, max_depth=max_depth, min_samples_split=min_samples_split,\n                                min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n                                max_leaf_nodes=max_leaf_nodes)\n\n                            results.append((hyperparameters, error))","a94c3f7a":"min(results, key = lambda x: x[1])","e0256230":"check, error = rfr_model_evaluation(0.05, n_estimators=130, max_depth=19, min_samples_split=7,\n                                min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n                                max_leaf_nodes=None)","7be81c0f":"check.head(10)","c0404415":"import xgboost as xgb","cf4233f2":"def xgbr_model_evaluation(feature_correlation_threshold=0, learning_rate=0.3, gamma=0, max_depth=3,\n        min_child_weight=1, max_delta_step=0, subsample=1., reg_lambda=1, reg_alpha=0, n_estimators=100):\n\n    xgbr = xgb.XGBRegressor(max_depth=max_depth, min_child_weight=min_child_weight, max_delta_step=max_delta_step,\n                           learning_rate=learning_rate, reg_lambda=reg_lambda, reg_alpha=reg_alpha, gamma=gamma,\n                           n_estimators=n_estimators, subsample=subsample)\n    features = get_features(feature_correlation_threshold)\n    xgbr.fit(train[features], train['quality'])\n    xgbr_validation_predictions = evaluate_predictions(xgbr, train, validation, features, 'quality')\n    check_df, avg_error = compare_predictions(xgbr_validation_predictions, validation, 'quality')\n    print(\"Average validation error:\", avg_error)\n    return check_df, avg_error","a33d2e82":"check_df, avg_error = xgbr_model_evaluation()","ee7e695b":"thresholds = [0, 0.05, 0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4]\nmax_depth_list = [3, 4, 5, 7, 10, 15, 20, 25, 30, 35]\nmax_delta_steps = [x for x in range(0,11)]\nmin_child_weights = [0, 1, 3, 10, 30, 100, 300, 1000, 3000]\nlearning_rates = [0.03, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.5, 0.7, 0.8, 0.85, 0.9, 0.95, 1]\ngammas = [0, 0.01, 0.03, 0.1, 0.3, 0.5, 1, 3, 10, 30]\nsubsamples = [1., 0.9, 0.8, 0.7, 0.6, 0.5, 0.6]\nreg_lambdas = [0.1, 0.3, 1, 1.3, 1.5, 2, 3, 3.5, 4, 4.5, 5, 5.5, 10]\nreg_alphas = [0.1, 0.3, 1, 1.3, 1.5, 1.75, 2, 2.25, 2.5, 3]\nn_estimators = [10, 20, 40, 50, 75, 100, 125, 150, 175, 200, 225]\n\nhyperparams = {\n    'threshold': thresholds,\n    'max_depth': max_depth_list,\n    'max_delta_step': max_delta_steps,\n    'min_child_weight': min_child_weights,\n    'learning_rate': learning_rates,\n    'gamma': gammas,\n    'subsample': subsamples,\n    'reg_lambda': reg_lambdas,\n    'reg_alpha': reg_alphas,\n    'n_estimators': n_estimators,\n}\n\nvalidation_results = []\nfor hp_name, hp_list in hyperparams.items():\n    errors = []\n    for hp_val in hp_list:\n        if hp_name == 'threshold':\n            _, error = xgbr_model_evaluation(feature_correlation_threshold=hp_val)\n        elif hp_name == 'max_depth':\n            _, error = xgbr_model_evaluation(max_depth=hp_val)\n        elif hp_name == 'max_delta_step':\n            _, error = xgbr_model_evaluation(max_delta_step=hp_val)\n        elif hp_name == 'min_child_weight':\n            _, error = xgbr_model_evaluation(min_child_weight=hp_val)\n        elif hp_name == 'learning_rate':\n            _, error = xgbr_model_evaluation(learning_rate=hp_val)\n        elif hp_name == 'gamma':\n            _, error = xgbr_model_evaluation(gamma=hp_val)\n        elif hp_name == 'subsample':\n            _, error = xgbr_model_evaluation(subsample=hp_val)\n        elif hp_name == 'reg_lambda':\n            _, error = xgbr_model_evaluation(reg_lambda=hp_val)\n        elif hp_name == 'reg_alpha':\n            _, error = xgbr_model_evaluation(reg_alpha=hp_val)\n        elif hp_name == 'n_estimators':\n            _, error = xgbr_model_evaluation(n_estimators=hp_val)\n            \n        errors.append(error)\n    validation_results.append((hp_name, errors))","d6fe8f54":"fig = plt.figure(figsize=(7, 30))\n\nfor i, result in enumerate(validation_results):\n    ax = fig.add_subplot(len(validation_results), 1, i+1)\n    hp_name = result[0]\n    hp_errors = result[1]\n    \n    ax.set_title(hp_name)\n    ax.plot(range(0, len(hp_errors)), hp_errors)\n    plt.sca(ax)\n    x_labels = hyperparams[hp_name]\n    plt.xticks(range(0, len(hp_errors)), x_labels)\n    \nfig.tight_layout()\nplt.show()","00c324b7":"check_df, avg_error = xgbr_model_evaluation(feature_correlation_threshold=0.1, max_depth=10,\n    min_child_weight=0, learning_rate=0.9, gamma=0.1, subsample=0.5, reg_lambda=5, reg_alpha=2, n_estimators=125)","d3ed41c3":"lr = LinearRegression()\nfeatures = get_features(0.15)\nlr.fit(train[features], train['quality'])\nlr_test_predictions = evaluate_predictions(lr, train, test, features, 'quality')\ncheck_df, avg_error = compare_predictions(lr_test_predictions, test, 'quality')\nprint(\"Average test error:\", avg_error)","4c04cd49":"dtr = DecisionTreeRegressor(random_state=42, max_depth=5, min_samples_split=3, min_samples_leaf=0.055, min_weight_fraction_leaf=0.07, max_leaf_nodes=None)\nfeatures = get_features(0.2)\ndtr.fit(train[features], train['quality'])\ndtr_test_predictions = evaluate_predictions(dtr, train, test, features, 'quality')\ncheck_df, avg_error = compare_predictions(dtr_test_predictions, test, 'quality')\nprint(\"Average test error:\", avg_error)","e93299f6":"rfr = RandomForestRegressor(random_state=42, n_estimators=130, max_depth=19, min_samples_split=7, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_leaf_nodes=None)\nfeatures = get_features(0.05)\nrfr.fit(train[features], train['quality'])\nrfr_test_predictions = evaluate_predictions(rfr, train, test, features, 'quality')\ncheck_df, avg_error = compare_predictions(rfr_test_predictions, test, 'quality')\nprint(\"Average validation error:\", avg_error)","e3e5cec6":"xgbr = xgb.XGBRegressor(max_depth=10, min_child_weight=0, learning_rate=0.9, reg_lambda=5, reg_alpha=2, gamma=0.1,\n                           n_estimators=125, subsample=0.5)\nfeatures = get_features(0.1)\nxgbr.fit(train[features], train['quality'])\nxgbr_test_predictions = evaluate_predictions(xgbr, train, test, features, 'quality')\ncheck_df, avg_error = compare_predictions(xgbr_test_predictions, test, 'quality')\nprint(\"Average test error:\", avg_error)","33017c63":"### Random forest","c874efc0":"Let's have a quick look on the whole correlation matrix to understand how different features correlate with each other.","d563bdde":"We got a significant improvement. Let's try to tune hyperparameters as we did it with a single decision tree.","5bffe0c6":"RMSEs for train and validation sets are quite close, it's unlikely there is a lot of overfitting.","e6e2818d":"### Gradient boosted tree","86b7de90":"Now, based on graphics above, it is easy to select best hyperparameters. For hyperparameters where it is still not crystally clear what is the best hyperparameter let's use several and search among them.","ec20f013":"# Initial data exploration","ca534154":"# Conclusion\nWe have found an approach that showed about 92.8% of accuracy (~7.2% of errors).\n\nThe model above could be improved in the following manner:\n\n* Quality of wine could be regarded as categorical data. In predictions we rounded the values, and that added additional error to that, about which model had no idea. \n\n* We could ran more precise search for best hyperparameters. Some hyperparameters tend to work better or worse in combination with others. We didn't test that possibility.","e4728c22":"Let's use random forest with newly found best hyperparameters for decision tree.","16a07b11":"The above method is computationally impractical. Better approach would to use default parameters and change only one at the time to understand how it affects the results, and only then, with narrowed lists of hyperparameters, try every plausible combination.","d9eb589f":"No categorical data, pure regression problem. Let's explore correlations.","ac18a3b7":"We have tuned 3 models against validation sets. Now it is time to assess models against data that they haven't seen at all before.","f3b6a5d5":"Let's try different feature selection thresholds in hopes for better results","65817321":"Average error dropped, but there is still room for improvements! As RMSEs suggest, an overfitting takes place. Let's start by trying different combinations for hyperparams of decision tree and then move on to random forests.","c63ff649":"Let's split data into train (80%), validation (10%) and test (10%) sets.","d0da2959":"thresholds = [x * 0.05 for x in range(1, 8)]\nmax_depth_list = [None, 3, 4, 5, 7, 10, 15, 20]\nmin_samples_split_list = [2, 3, 4, 5, 7, 10, 15, 20]\nmin_samples_leaf_list = [1, 2, 3, 5, 7, 10, 0.01, 0.03, 0.05, 0.07, 0.1]\nmin_weight_fraction_leaf_list = [0., 0.01, 0.02, 0.03, 0.05, 0.07]\nmax_leaf_nodes_list = [None, 5, 10, 15, 20, 25, 30]\n\nresults = []\nfor max_depth in max_depth_list:\n    for min_samples_split in min_samples_split_list:\n        for min_samples_leaf in min_samples_leaf_list:\n            for min_weight_fraction_leaf in min_weight_fraction_leaf_list:\n                for max_leaf_nodes in max_leaf_nodes_list:\n                    for thr in thresholds: \n                        hyperparameters = {\n                            'max_depth': max_depth,\n                            'min_samples_split': min_samples_split,\n                            'min_samples_leaf': min_samples_leaf,\n                            'min_weight_fraction_leaf': min_weight_fraction_leaf,\n                            'max_leaf_nodes': max_leaf_nodes,\n                            'threshold': thr\n                        }\n\n                        check, error = dtr_model_evaluation(thr, max_depth=max_depth, min_samples_split=min_samples_split,\n                            min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n                            max_leaf_nodes=max_leaf_nodes)\n                        \n                        results.append((hyperparameters, error))","61958ebb":"# Gradient boosted tree approach","4b3683f2":"As with decision tree, let's narrow down best hyperparameters with additional parameter search. We should expect that best results should have less than 5.5% of errors.","eb02eb57":"~8.2% errors with default parameters. Let's try to tune the model.","48e447f9":"### Random Forest approach","b78274d0":"### Linear regression","09717c79":"The best result so far was achieved with feature selection threshold of 0.15, but improvement was not too impressive.","a829a4fe":"So far the best result for validation set with Decision Tree Regressor is ~8% of errors, with the following hyperparameters (apart from default ones): Feature Selection Correlation Threshold = 0.2, max_depth=5, min_samples_split=3,         min_samples_leaf=0.055, min_weight_fraction_leaf=0.07","2e41717d":"### Decision tree","5fe61f97":"# Decision tree approach","e3cee454":"Random forest didn't showed any improvements in comparison with tuned decision tree. Perhaps using the same tuning for random forest as for decision tree is not as effective. Let's run random forest regressor with all default hyperparameters.","fda8d6d4":"The best results on validation set found with random forest regressor have ~5.13% of errors with the hyperparameters shown above.","429be737":"# Linear regression approach","6dda6d9c":"As suspected, acidity somewhat correlate with each other and pH.","d0c68208":"# Final check of best models against the TEST set."}}