{"cell_type":{"21e702b1":"code","25ac9d10":"code","f242cd60":"code","a2c000f1":"code","59945c2e":"code","4a052da4":"code","1d7e47fd":"code","20c9477d":"code","fce6e2b6":"code","ea262291":"code","0805359f":"code","6a8eb431":"code","789aaa00":"code","0a6642bb":"code","f2291ccd":"code","aa223ad6":"code","cc1996c6":"code","c614fd39":"code","bc720f15":"code","6e436da5":"code","9c8b163f":"code","a5a8c7e4":"code","9426ccaa":"code","a81f41d9":"code","a85739e1":"code","22be430e":"code","cf29ae07":"code","2d8dabd8":"code","b0bfe66f":"code","b2073a30":"code","e74fbcdd":"code","2f2e6914":"code","da695670":"code","5988b440":"code","c25dc91a":"code","22c3a89b":"code","96817943":"code","673c963d":"code","ceb8dd42":"code","cf08837d":"code","9505bb5b":"code","1d63e30e":"code","b2297e49":"code","b125a32c":"code","520d6ea7":"code","5c99cf02":"code","91b747da":"code","1c19124a":"code","a393cb8e":"markdown","48227097":"markdown","d4c47b13":"markdown","ce164087":"markdown","f35482b3":"markdown","ef3df839":"markdown","839a91fc":"markdown","ccc6fd6f":"markdown","d528907d":"markdown","b71f298a":"markdown","6c11d3d5":"markdown","708405ee":"markdown","d2a7a07f":"markdown","bb93b3f9":"markdown","535137c4":"markdown"},"source":{"21e702b1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport scipy as sp\nimport string\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\n\n","25ac9d10":"data=pd.read_csv(\"..\/input\/japanese-fakenews-dataset\")\n","f242cd60":"data","a2c000f1":"data.head()","59945c2e":"data.info()","4a052da4":"data.describe()","1d7e47fd":"data.value_counts","20c9477d":"data.dtypes","fce6e2b6":"data.shape","ea262291":"data.columns","0805359f":"data.isnull().sum()","6a8eb431":"data.isnull().any()","789aaa00":"###Drop Nan Values\ndata=data.dropna()\n","0a6642bb":"data.isnull().sum()","f2291ccd":"## Get the Independent Features\n\nX=data.drop('id',axis=1)\n","aa223ad6":"y=data['id']\n","cc1996c6":"y.value_counts()\n","c614fd39":"X.shape","bc720f15":"y.shape","6e436da5":"plt.style.use(\"default\")\nsns.barplot(x=\"id\", y=\"title\",data=data[180:190])\nplt.title(\"ID vs TITLE\",fontsize=15)\nplt.xlabel(\"ID\")\nplt.ylabel(\"TITLE\")\nplt.show()\n\n\n","9c8b163f":"data.columns","a5a8c7e4":"sns.set_palette(\"Paired\")\nsns.pairplot(data,hue='text',height=5,palette='colorblind')\nplt.show()\n","9426ccaa":"plt.figure(figsize=(14,10))\nsns.set_style(style='whitegrid')\nplt.subplot(2,3,1)\nsns.boxplot(x='id',data=data)\n\n","a81f41d9":"sns.pairplot(data=data)","a85739e1":"import tensorflow as tf\n","22be430e":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\n\n","cf29ae07":"### Vocabulary size\nvoc_size=5000\n","2d8dabd8":"messages=X.copy()\n","b0bfe66f":"messages.reset_index(inplace=True)\n\n","b2073a30":"import nltk\nimport re\nfrom nltk.corpus import stopwords","e74fbcdd":"nltk.download('stopwords')\n","2f2e6914":"### Dataset Preprocessing\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    print(i)\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\n","da695670":"corpus","5988b440":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr","c25dc91a":"sent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)\n","22c3a89b":"embedded_docs[0]\n","96817943":"## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='mae',optimizer='adam',metrics=['accuracy'])\n\n","673c963d":"model.summary()","ceb8dd42":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)\n","cf08837d":"X_final.shape,y_final.shape","9505bb5b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state=42)\n","1d63e30e":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=256)\n","b2297e49":"from tensorflow.keras.layers import Dropout\n## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='mae',optimizer='adam',metrics=['accuracy'])","b125a32c":"y_pred=model.predict(X_test)\n","520d6ea7":"y_pred","5c99cf02":"print((y_pred > 0.5))\n","91b747da":"from tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes = True)\n","1c19124a":"model.summary()","a393cb8e":"# FAKE NEWS CLASSIFIER ","48227097":"**Types of Optimizers:**\n\n**1) Gradient Descent (GD)**\n\n**2) Stochastic Gradient Descent**\n\n**3) Mini-Batch Gradient Descent**\n\n**4) Adagrad**\n\n**5) RMSProp**\n\n\n\n","d4c47b13":"***So now we can see all the null values have been dropped .***","ce164087":"**Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.**","f35482b3":"**Types of Activation Functions:**\n\n**1) Relu**\n\n**2) Sigmoid**\n\n**3) Threshold**\n\n**4) Hyperbolic Tangent**","ef3df839":"***So we have to drop the null values .***","839a91fc":"**Types of Loss Functions:**\n\n**1) Mean Squared Error**\n\n**2) Regression Loss Function**\n\n**3) Mean Absolute Error Loss**\n\n**4) Binary Classification Loss Function**\n\n**5) Binary Cross Entropy Loss**\n","ccc6fd6f":"**MODEL CREATION**","d528907d":"# **Checking Null Values**","b71f298a":"**NLTK**","6c11d3d5":"# **Exploratory Data Analysis**","708405ee":"**With Dense we can also use Dropout and Batch Normalization**","d2a7a07f":"# IMPORTING THE LIBRARIES","bb93b3f9":"# LOADING THE DATASET","535137c4":"**LSTM**"}}