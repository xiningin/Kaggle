{"cell_type":{"b99f12a6":"code","d7f4cd8d":"code","4bce69a4":"code","60296a99":"code","6ae986e8":"code","745e482c":"code","569b2a32":"code","48f35fe1":"code","7a371fa1":"code","2d689d9c":"code","010d70cd":"code","e1a60bc8":"code","319b6b42":"code","8a807d8d":"code","5a810b46":"code","d48e2511":"code","8d3c1d7c":"code","f546a476":"code","1834d7f7":"code","404d5bc4":"code","2b692ecf":"code","6b22a134":"code","bd63401e":"code","3a2944e0":"code","904acade":"code","096b651c":"code","201062cb":"code","b3a82b1c":"code","f46e6ddd":"code","4f2d37e2":"code","440e7e21":"code","d9e94756":"code","fb66fcd2":"code","15f93e99":"code","d93e9a2c":"code","7e34ebe3":"code","b2f3c2f4":"code","d218d603":"code","484e4281":"code","76c79566":"markdown","dee61529":"markdown","6c7a62dd":"markdown","c4a8e425":"markdown","8b9de7cc":"markdown","8f94c9e2":"markdown","46623b54":"markdown","9872a760":"markdown","a98f446a":"markdown","9a184ddb":"markdown","d2b79fd5":"markdown","21b5e70a":"markdown","57296754":"markdown","fea65f27":"markdown","298d0615":"markdown","368edff5":"markdown","93df6498":"markdown","f9d6619c":"markdown","3ce948ab":"markdown"},"source":{"b99f12a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d7f4cd8d":"import pandas as pd\nimport pandas_profiling \n\ntitanic_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","4bce69a4":"# import plotting libraries\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline \n\nimport seaborn as sns\nsns.set(style=\"white\", color_codes=True)\nsns.set(font_scale=1.5)\n\n# import libraries for model validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# import libraries for metrics and reporting\nfrom sklearn.metrics import confusion_matrix","60296a99":"\n df = titanic_df ","6ae986e8":"\ndf.shape","745e482c":"df.head()","569b2a32":"# see distinct values in the Survived column\ndf.Survived.value_counts()","48f35fe1":"# see distinct values in the Sex column\ndf.Sex.value_counts()","7a371fa1":"df.columns","2d689d9c":"#create the new dataframe abd assign the varibale to it\nX = pd.DataFrame()\nX['sex'] = df['Sex']\nX['age'] = df['Age']\nX['pclass'] = df['Pclass']\nX['sibsp'] = df['SibSp']\nX['parch'] = df['Parch']\nX['Embarked'] = df['Embarked']","010d70cd":"X.head()","e1a60bc8":"y = df['Survived']\ny[:5]","319b6b42":"df.isnull().sum()","8a807d8d":"X.hist('age')","5a810b46":"X['age'] = X['age'].fillna(X.age.median()) # because the hist is skewed\nprint (X.age.isnull().sum())","d48e2511":"print(X.Embarked.mode()[0])\nX['Embarked'] = X['Embarked'].fillna(X.Embarked.mode()[0])\nprint (X.Embarked.isnull().sum())","8d3c1d7c":"print (X.sex[:5])\nX['sex'] = pd.get_dummies(X.sex)['female']\nprint (X.sex[:5])","f546a476":"# see distinct values in the pclass column\nX.pclass.value_counts()","1834d7f7":"X1 = X.join(pd.get_dummies(df.Pclass))#, prefix='pclass'))\nX1[:5]","404d5bc4":"display (X[:5])\nX = X.join(pd.get_dummies(df.Pclass, prefix ='pclass'))\ndisplay (X[:5])","2b692ecf":"X = X.drop(['pclass_1', 'pclass'], axis=1)\ndisplay (X[:5])","6b22a134":"X = X.join(pd.get_dummies(df.Embarked, prefix ='Embarked'))\ndisplay (X[:5])","bd63401e":"X = X.drop(['Embarked_C', 'Embarked'], axis=1)\ndisplay (X[:5])","3a2944e0":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndisplay (X[:5])\nX.age = scaler.fit_transform(X[['age']])\ndisplay (X[:5])","904acade":"X.hist('age')","096b651c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)","201062cb":"print (X_train.shape)\nprint (X_test.shape)\nprint (y_train.shape)\nprint (y_test.shape)","b3a82b1c":"from sklearn.linear_model import LogisticRegression\n\n# fit the model to the training data\nmodel=LogisticRegression()\nmodel.fit(X_train,y_train)\n\nprint (model.intercept_)\nprint (model.coef_)\nprint (X_train.columns)","f46e6ddd":"# A female in Pclass_1 with Age 0.2 and Embarked_C\nlog_odds = 0.16895636 + 2.56939259*1 - 0.36361616*(0.2) - 0.26361411*0 - 0.07520945*0 - 0.57435637*0 - 1.84009514*0 - 0.1786976*0  - 0.5393869*0\nlog_odds","4f2d37e2":"import numpy as np\np = np.exp(log_odds)\/(1+np.exp(log_odds))\np","440e7e21":"# A male in Pclass_1 with Age 0.2 and Embarked_C\nlog_odds = 0.16895636 + 2.56939259*0 - 0.36361616*(0.2) - 0.26361411*0 - 0.07520945*0 - 0.57435637*0 - 1.84009514*0 - 0.1786976*0  - 0.5393869*0\n# log_odds\np = np.exp(log_odds)\/(1+np.exp(log_odds))\np","d9e94756":"display (X_test[:10])\nprint ()\ndisplay (model.predict_proba(X_test)[:10]) # prob\nprint ()\ndisplay (model.predict(X_test)[:10]) # classification","fb66fcd2":"# compute the accuracy of our predictions\nfrom sklearn.metrics import accuracy_score\nprint (\"Logistic testing accuracy is %2.2f\" % accuracy_score(y_test,model.predict(X_test)))","15f93e99":"print (\"Logistic training accuracy is %2.2f\" % accuracy_score(y_train,model.predict(X_train)))","d93e9a2c":"from sklearn.metrics import roc_auc_score\n# lets measure the logistic model AUC\nlogistic_roc_auc = roc_auc_score(y_test, model.predict(X_test)) \nlogistic_roc_auc","7e34ebe3":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])","b2f3c2f4":"model.predict_proba(X_test)[:,1][:5] # P(Y=1)","d218d603":"display (thresholds[:10])\ndisplay (fpr[:10])\ndisplay (tpr[:10])","484e4281":"# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, label = 'ROC curve (area = %0.2f)' % logistic_roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc =\"lower right\")\nplt.show()\nprint(\"Logistic AUC = %2.2f \" % logistic_roc_auc )","76c79566":"**Creating dummies for varibles Pclass**","dee61529":"Interpretation of Model Equation\nLog_odds (Survival)\nSex - +ve - prob of female survival is higher\nAge - -ve - lower the age survival is higher\nSibsp - -ve\nParch - -ve\nPclass_2 - -ve\nPclass_3 - -ve\nEmbarked_Q - -ve\nEmbarked_S - -ve","6c7a62dd":"**Encoding the categorical variables and Standardizing the Continuous Variables are Hygiene Steps**","c4a8e425":"**Standardizing Age variable**","8b9de7cc":"**ROC Curve**","8f94c9e2":"                                             **Sinking of Titanic**\nImage of Titanic\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nDo a complete analysis on what sorts of people were likely to survive.","46623b54":"**Prediction**","9872a760":"**Check Missing Values**","a98f446a":"**Creating dummies for varibles Embarked**","9a184ddb":"**Dropping These Variables**\n\nFare - Does the fare a person paid effect his survivability? Will be related to Pclass\nWhat about a person's name, ticket number, and passenger ID number? # Identity columns\n\n**Retaining These Variables**\n\nSurvived - This variable is obviously relevant.\nPclass - Does a passenger's class on the boat affect their survivability?\nSex - Could a passenger's gender impact their survival rate?\nAge - Does a person's age impact their survival rate?\nSibSp - Does the number of relatives on the boat (that are siblings or a spouse) affect a person survivability? Probably\nParch - Does the number of relatives on the boat (that are children or parents) affect a person survivability? Probably\nEmbarked - Does a person's point of embarkation matter?","d2b79fd5":"* There are only 891 rows in the titanic data frame. Cabin is almost all missing values, so we can drop that variable completely\n* Age seems like a relevant predictor for survival right? We'd want to keep the variables, but it has 177 missing values.","21b5e70a":"prob for a female in Pclass_1 with Age 0.2 and Embarked_C is 0.9349","57296754":"log_odds = 0.16895636 + 2.56939259*sex - 0.36361616*age - 0.26361411*sibsp - 0.07520945*parch - 0.57435637*pclass_2 - 1.84009514*pclass_3 - 0.1786976*Embarked_Q  - 0.5393869*Embarked_S","fea65f27":"**Model Building**","298d0615":"> **The overall Logistic AUC for this model is 0.79**","368edff5":"**Treating Missing Values in Embarked**","93df6498":"**Treating Missing Values in Age**","f9d6619c":"prob for a male in Pclass_1 with Age 0.2 and Embarked_C is 0.5240","3ce948ab":"**Sex column**"}}