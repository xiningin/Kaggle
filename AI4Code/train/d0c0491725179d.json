{"cell_type":{"4083538d":"code","e8c1503d":"code","cbc9ebe0":"code","2b61e203":"code","feabd2dc":"code","cf06a49a":"code","f2127db4":"code","7eebdf34":"code","a1ef20fe":"code","e0a51b14":"code","1b27917f":"code","cdeb3915":"code","42358270":"code","bb27037a":"code","28dfcfbd":"code","b7133225":"code","574e0ae2":"code","fed43a59":"code","e4d16622":"code","e1f10386":"code","02518efa":"code","d00f991b":"code","47a18c53":"code","dfc77466":"code","f40b8a03":"code","43bc135f":"code","0d1f1e51":"code","71c0e4b9":"code","9f86506e":"code","ffd9acc8":"code","4b484dcb":"code","1726cd93":"code","4e39aa6a":"code","7090f04b":"code","e5a8fae5":"code","9a5e737d":"code","6923849e":"code","b062e139":"code","a5e179b6":"code","a1db7064":"code","fb8e6c38":"code","ef3bd921":"code","3c7377a3":"code","6c716edb":"code","95980b2c":"code","4ac03941":"code","92e7d594":"code","4b3870ba":"code","2ee1c954":"code","e679209a":"code","db853ed0":"code","321766b2":"code","b1efbfca":"code","84aff9f5":"code","5fed11f5":"code","850c59ff":"code","fab40bc0":"code","3fec37c9":"code","c11fa964":"code","159aecb5":"code","9c8dde29":"code","56d1f406":"code","c0b67e60":"code","fead9ddd":"code","97eafdbe":"code","caac6d38":"code","0738e1ed":"code","39e12464":"code","b9f6678e":"code","6ea1cbf8":"code","73631b86":"code","5535e198":"code","ae9fd547":"code","4ec3b846":"code","bc3afb57":"code","c11927af":"code","9e1e2703":"code","38799a32":"code","f0458025":"code","55f20656":"code","a2e7d65c":"code","23311943":"code","dcd27853":"code","ea5d3857":"code","78588e19":"code","bc373726":"code","c1d97ed8":"code","04475b80":"code","dd9e1fca":"code","c161333a":"code","2022be55":"code","3f440f3f":"code","a2cbd940":"code","e3e1e944":"code","50067492":"code","88b8d91d":"code","43fbb391":"code","1786d806":"code","6ae1b450":"markdown","c32b108a":"markdown","3318caec":"markdown","b697ba9e":"markdown","86a646ab":"markdown","51a550dc":"markdown","04779398":"markdown","a90abc80":"markdown","d12f3a67":"markdown","531f2d33":"markdown","229ace04":"markdown","8a5761d0":"markdown","89ff6fd2":"markdown","b70d04e6":"markdown","4c66ffce":"markdown","d770ae60":"markdown","b3dc636b":"markdown","0043d18b":"markdown","368f0f3e":"markdown","709933e5":"markdown","e431839f":"markdown","cdbba7f4":"markdown","9494359c":"markdown","7f70a7fd":"markdown","9cd52abd":"markdown","329e4f26":"markdown","58ee664f":"markdown"},"source":{"4083538d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8c1503d":"sample=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ntrain= pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest= pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n","cbc9ebe0":"import matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor\nimport seaborn as sns\nfrom scipy.stats import norm, skew\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10,shuffle=True,random_state=True)\nfrom xgboost import XGBRegressor","2b61e203":"train.head()","feabd2dc":"\ntrain.shape","cf06a49a":"train.info()","f2127db4":"train['SalePrice'].describe()","7eebdf34":"# it looks like that this variable is skewed to right. plotting histogram of SalePrice to check it's skewness-\nsns.histplot(train['SalePrice'])","a1ef20fe":"#it's skewed. to correct it we take log of the variable.\ntrain_copy=train.copy()\ntrain_copy['SalePrice']= np.log(train_copy['SalePrice'])\nsns.distplot(train_copy['SalePrice'], fit=norm)","e0a51b14":"#It's looking normally distributed and not skewed. \n#Now, we will analyze correlation between independent variables\ncorre= train_copy.corr()\nf, ax = plt.subplots(figsize=(24,16))\nsns.heatmap(corre,vmax=0.9, square =True)","1b27917f":"# Now we will see correlation of all independent variables with the dependent variable SalePrice\ntrain_copy.corr().loc[:,'SalePrice'].abs().sort_values(ascending=False)","cdeb3915":"# we will see impact of all independent variables on the dependent varibale SalePrice\n# Now we will se boxplots of all thosevaiables which have correaltion of more than 0.4 with SalePrice\ndef box(a):\n    plt.figure(figsize=(16,4))\n    sns.boxplot(x=train_copy[a],y=train_copy['SalePrice'])\n    plt.title('Boxplot')\n    plt.show()\n\ncol= ['OverallQual','GrLivArea','GarageCars','GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt',\n'TotRmsAbvGrd', 'Fireplaces','MasVnrArea']\nfor i,j in enumerate(col):\n    box(col[i])","42358270":"train_copy2=train_copy.drop(['GarageCars', 'GarageYrBlt' ,'TotRmsAbvGrd'], axis=1, inplace=False)","bb27037a":"train_copy2.shape","28dfcfbd":"train_copy.describe()","b7133225":"missing= train_copy2.isnull().sum().sort_values(ascending=False)\nmissing.head(25)","574e0ae2":"SalePrice=train_copy2['SalePrice']\nId= test['Id']\nCombined= pd.concat([train_copy,test],axis=0,sort=False)\nCombined= Combined.drop(['SalePrice'],axis=1)","fed43a59":"Combined.shape","e4d16622":"# Dropping these 3 variables from whole the model as they were highly correlated and having no significant impact as such\nCombined=Combined.drop(['GarageCars', 'GarageYrBlt' ,'TotRmsAbvGrd'], axis=1)","e1f10386":"Combined.info()","02518efa":"missing2= Combined.isnull().sum().sort_values(ascending=False)\nmissing2.head(20)","d00f991b":"Combined=Combined.drop(['PoolQC' ,'MiscFeature' , 'Alley', 'Fence' ,'FireplaceQu'],axis=1)\n","47a18c53":"Combined.info()","dfc77466":"missing2=Combined.isnull().sum().sort_values(ascending=False)\nmissing2.head(30)","f40b8a03":"missing_data= pd.concat([missing2],axis=1,keys=['missing'])\nmissing_data.head(30)\n","43bc135f":"Combined.select_dtypes(include=['object']).columns","0d1f1e51":"def count(a):\n    plt.figure(figsize=(20,5))\n    sns.countplot(x=train_copy2[a])\n    plt.title('countplot')\n    plt.show()\n    \nfeatures=['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1', 'BsmtFinType2','MasVnrType'] \nfor i,j in enumerate(features):\n    count(features[i])\n    ","71c0e4b9":"pd.crosstab(train_copy2['BsmtFinType2'],columns='count',normalize= True)\n\n","9f86506e":"pd.crosstab(train_copy2['BsmtCond'],columns='count',normalize= True)\n","ffd9acc8":"pd.crosstab(train_copy2['GarageCond'],columns='count',normalize= True)\n","4b484dcb":"pd.crosstab(train_copy2['GarageQual'],columns='count',normalize= True)","1726cd93":"for i,j in enumerate(features):\n    box(features[i])","4e39aa6a":"Combined= Combined.drop(['BsmtFinType1','BsmtFinType2'],axis=1)\nCombined.info()","7090f04b":"Combined.isnull().sum()","e5a8fae5":"features_new= ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','BsmtQual', 'BsmtCond', 'BsmtExposure','MasVnrType']\nfor a in features_new:\n    Combined[a]= Combined[a].fillna(Combined[a].mode()[0])","9a5e737d":"Combined['LotFrontage'].describe()","6923849e":"Combined['MasVnrArea'].describe()","b062e139":"sns.boxplot(x=train_copy2['MasVnrArea'],y= train_copy2['SalePrice'])","a5e179b6":"Combined2= Combined.drop(['MasVnrArea'],axis=1)\n","a1db7064":"Combined2['LotFrontage']= Combined2['LotFrontage'].fillna(Combined2['LotFrontage'].mean())\nmissing3= Combined2.isnull().sum().sort_values(ascending=False)\nmissing3.head(30)","fb8e6c38":"Combined.select_dtypes(include=['object']).columns","ef3bd921":"features_2= ['MSZoning','Utilities','Functional','Exterior2nd','Exterior1st','SaleType','Electrical','KitchenQual']\nfor a in features_2:\n    Combined2[a]=Combined2[a].fillna(Combined2[a].mode()[0])\nCombined2.info()","3c7377a3":"no_skew = Combined2.dtypes[Combined2.dtypes != 'object'].index\nskewed = Combined2[no_skew].apply(lambda x: skew(x)).sort_values(ascending=False)\nhigh_skewed = skewed[abs(skewed) > 0.5]\nhigh_skewed","6c716edb":"for a in no_skew:\n    Combined2[a]=np.log1p(Combined2[a])","95980b2c":"# Now as TotalBsmtSF , 1stFlrSF and 2ndFlrSF are highly correlated so introducing a new variable with taking there average\nCombined2['AvgSF']=((Combined2['TotalBsmtSF']+Combined2['1stFlrSF']+Combined2['2ndFlrSF'])\/3)\nCombined2.info()","4ac03941":"Combined2.drop(['TotalBsmtSF','1stFlrSF','2ndFlrSF'],axis=1,inplace=True)\nCombined2.info()","92e7d594":"Combined2.select_dtypes(include=['object']).columns\n","4b3870ba":"features2=['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'Heating', 'HeatingQC',\n       'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'GarageType',\n       'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType',\n       'SaleCondition']\nfor i,j in enumerate(features2):\n    box(features2[i])","2ee1c954":"pd.crosstab(Combined2['Utilities'],columns='count',normalize=True)","e679209a":"Combined2.drop(['LotConfig','LandSlope','Utilities'],axis=1,inplace=True)\n","db853ed0":"Combined2.info()","321766b2":"Features_numeric=['AvgSF','GarageArea','BsmtHalfBath','BsmtFullBath','BsmtUnfSF','BsmtFinSF2','BsmtFinSF1']\nfor a in Features_numeric:\n    Combined2[a]=Combined2[a].fillna(Combined2[a].mean())\nCombined2.info()","b1efbfca":"##Changing categorical to numerical\nnew_data=pd.get_dummies(Combined2, drop_first=True)\nnew_data.head()","84aff9f5":"x_train= new_data[:len(SalePrice)]\nx_test= new_data[len(SalePrice):]","5fed11f5":"x_train.shape\n","850c59ff":"x_test.shape","fab40bc0":"x_train.tail()","3fec37c9":"x_test.head()","c11fa964":"x_train= x_train.drop(['Id'],axis=1)\nx_test= x_test.drop(['Id'],axis=1)","159aecb5":"y_train= SalePrice","9c8dde29":"train_x,test_x,train_y,test_y=train_test_split(x_train,y_train,test_size=0.25,random_state=12)\n","56d1f406":"dtr=  DecisionTreeRegressor()\n","c0b67e60":"dtr.fit(train_x,train_y)","fead9ddd":"prediction_dtr=dtr.predict(test_x)","97eafdbe":"dtr_mse= mean_squared_error(test_y,prediction_dtr)\ndtr_rmse=np.sqrt(dtr_mse)\nprint(dtr_rmse)","caac6d38":"r2_dtr_train=dtr.score(train_x,train_y)\nr2_dtr_test=dtr.score(test_x,test_y)\nprint(r2_dtr_train,r2_dtr_test)","0738e1ed":"Residuals=test_y-prediction_dtr\nsns.regplot(x=prediction_dtr,y=Residuals,scatter=True,fit_reg=True,data=new_data)","39e12464":"rfr=RandomForestRegressor()\n","b9f6678e":"rfr.fit(train_x,train_y)\n","6ea1cbf8":"prediction_rfr= rfr.predict(test_x)","73631b86":"mse_rfr=mean_squared_error(test_y,prediction_rfr)\nrmse_rfr=np.sqrt(mse_rfr)\n","5535e198":"print(rmse_rfr)","ae9fd547":"r2_rfr_train= rfr.score(train_x,train_y)\nr2_rfr_test=rfr.score(test_x,test_y)\nprint(r2_rfr_test,r2_rfr_train)","4ec3b846":"Residuals2=test_y-prediction_rfr\nsns.regplot(x=prediction_rfr,y=Residuals2,scatter=True,fit_reg=True,data=new_data)","bc3afb57":"xgb= XGBRegressor()\n\n","c11927af":"xgb.fit(train_x, train_y)\n","9e1e2703":"prediction_xgb=xgb.predict(test_x)","38799a32":"mse_xgb=mean_squared_error(test_y,prediction_xgb)\nrmse_xgb=np.sqrt(mse_xgb)\nprint(rmse_xgb)","f0458025":"r2_xgb_train= xgb.score(train_x,train_y)\nr2_xgb_test= xgb.score(test_x,test_y)\nprint(r2_xgb_train,' ',r2_xgb_test)","55f20656":"Residuals3=test_y-prediction_xgb\nsns.regplot(x=prediction_xgb,y=Residuals3,fit_reg=True,scatter=True,data=new_data)","a2e7d65c":"Linreg= LinearRegression()","23311943":"Linreg.fit(train_x,train_y)","dcd27853":"prediction_Linreg=Linreg.predict(test_x)","ea5d3857":"mse_Linreg=mean_squared_error(test_y,prediction_Linreg)\nrmse_Linreg=np.sqrt(mse_Linreg)\nprint(rmse_Linreg)","78588e19":"r2_Linreg_train= Linreg.score(train_x,train_y)\nr2_Linreg_test=Linreg.score(test_x,test_y)\nprint(r2_Linreg_train,r2_Linreg_test)","bc373726":"Residuals4=test_y-prediction_Linreg\nsns.regplot(x=prediction_Linreg,y=Residuals4,scatter=True,fit_reg=True,data=new_data)","c1d97ed8":"prediction_final=np.exp(Linreg.predict(x_test))\nprint(prediction_final)","04475b80":"from sklearn.preprocessing import MinMaxScaler\nscaler= MinMaxScaler(feature_range=(0,1))\n\nx_train_scaled= scaler.fit_transform(train_x)\nx_train2= pd.DataFrame(x_train_scaled)\n\nx_test_scaled= scaler.fit_transform(test_x)\nx_test2= pd.DataFrame(x_test_scaled)","dd9e1fca":"from sklearn import neighbors\nfrom math import sqrt","c161333a":"model22 = neighbors.KNeighborsRegressor(n_neighbors = 5)\nmodel22.fit(x_train2,y_train)\npred_1=model22.predict(x_test2)\npred_1.size","2022be55":"test_y.size\n","3f440f3f":"rmse_val=[]\nfor k in range(0,50):\n    k=k+1\n    model23 = neighbors.KNeighborsRegressor(n_neighbors = k)\n    model23.fit(x_train2,train_y)\n    pred_1=model23.predict(x_test2)\n    error=sqrt(mean_squared_error(test_y,pred_1))\n    rmse_val.append(error)","a2cbd940":"curve=pd.DataFrame(rmse_val)\ncurve.plot()","e3e1e944":"model25=neighbors.KNeighborsRegressor(n_neighbors=13)\nmodel25.fit(x_train,y_train)\nprediction_final_knn=np.exp(model25.predict(x_test))\nprint(prediction_final_knn)","50067492":"data_set= pd.DataFrame()\ndata_set['Id']= Id\ndata_set['SalePrice']=prediction_final_knn\ndata_set.to_csv('Price_projection_project_knn.csv',index=False)","88b8d91d":"data_set= pd.DataFrame()\ndata_set['Id']= Id\ndata_set['SalePrice']=prediction_final\ndata_set.to_csv('Price_projection_project1.csv',index=False)\n","43fbb391":"prediction_rfr_final= np.exp(rfr.predict(x_test))","1786d806":"data_set2= pd.DataFrame()\ndata_set2['Id']=Id\ndata_set2['SalePrice']=prediction_rfr_final\ndata_set2.to_csv('price_projection_project1_2.csv',index=False)","6ae1b450":"# 2. RandomForestRegressor","c32b108a":"# 4. LinearRegression","3318caec":"these first 5 columns have very high no of missing values so dropping all these columns will no affect my data interpretation.","b697ba9e":"Now, we are all up with data cleaning. Now we will apply regression Techniques to our model","86a646ab":"We will add the two data sets (train and test) in one so that it would be easy for us to manipulate the same operation in both the data sets at a time.","51a550dc":"As we had combined the test and train data with each other so now we will separate out both the data sets.","04779398":"Now Checking for the other data type columns which were having NaN values in their data","a90abc80":"# 3. XGBRegressor","d12f3a67":"Here, again TA dominates the whole variable.","531f2d33":"# 1. DecisionTreeRegressor","229ace04":"Linear regression algorithm has given best r2_score and least rmse value.","8a5761d0":"Here only one category dominates the whole variable.","89ff6fd2":"Now, we will correct our data for skewness.","b70d04e6":"as no categorical effect of LotConfig and LandSlope so we will drop these.","4c66ffce":"As it's highly skewed so we will drop this variable also","d770ae60":"MasVnrArea is very highly skewed. So we will drop this variable.","b3dc636b":"# Now Importing all the necessary libraries","0043d18b":"As BsmtFinType1 and BsmtFinType2 has approximately same median for all the categories they don't have much categorical effect on the saleprice. So we will drop out these variable.","368f0f3e":"So out of these columns which are having more than 20 NaN values only LotFrontage and MasVnrArea are float64 data types. rest of all are object datatypes. \nNow checking for these object data types variables for their importance on the SalePrice","709933e5":"Now as we have seen that these object type variables effect my SalePrice significantly so we will fill out these columns' NaN values by their mode value.","e431839f":"Now, we will fill out all NaN values with the mean values.","cdbba7f4":"2. **GrLiveArea and TotRmsAbvGrd are correlated with each other. so we will take only one of these variable in the model. Now we will check which variable has higher effect on SalePrice**","9494359c":"1. **GarageCars and GarageArea are highly correlated with each other\nGarageYrBlt and YrBlt are correlated with each other\nTotalBsmtSF and 1stFlrSF are correlated with each other**","7f70a7fd":"Again,here TA dominates the whole variable.","9cd52abd":"**By seeing Boxplots of all the variables we can drop GarageCars, GarageYrBlt and TotRmsAbvGrd from our data.**","329e4f26":"**Reading All the Data-Sets**","58ee664f":"**Creating test and train data randomly out of train data so that we can figure out which algorithm is having best goodness of fit and least rmse.**"}}