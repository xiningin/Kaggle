{"cell_type":{"0e4b2d9b":"code","d33c915b":"code","bf45a1bc":"code","57450a49":"code","1f551c2a":"code","28dd2ffd":"code","353fa601":"code","5597f6f0":"code","497114ee":"code","4a455e3d":"code","73f2297b":"code","e26fdf01":"code","8c27dde9":"code","a00c65d9":"code","71b71452":"code","446c4c87":"code","cb81f46e":"code","19ee5c58":"code","e7dc8153":"code","f1ec7c88":"code","bfe54098":"code","1f46e5b0":"code","3b997d8e":"code","19bcfd22":"code","dbf80361":"code","3771a0d0":"code","e2c93bb9":"code","8c927980":"code","a4e4311b":"code","396070cb":"code","6ccdb91c":"code","4775f4eb":"code","5700ccb7":"markdown","dd6e6441":"markdown","9567ea73":"markdown","b69daf72":"markdown","3c7bd703":"markdown","c01e7a9d":"markdown","5b1046f9":"markdown","7f007e75":"markdown","693c7fe1":"markdown","fe2baf04":"markdown","07f4ef4c":"markdown","6919a03d":"markdown"},"source":{"0e4b2d9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re #Regular Expression\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\npd.set_option('display.max_columns', None)  # to show all the column of the dataset\n","d33c915b":"#Read both datasets\ngooglestore = pd.read_csv(\"..\/input\/googleplaystore.csv\")\ngooglereviews = pd.read_csv(\"..\/input\/googleplaystore_user_reviews.csv\")","bf45a1bc":"#The row 10472 is problematic, it doesn't have the Category camp so everything is shifted to the left\ngooglestore.loc[[10472]]\n#Best choice for the row 10472 is the record removal\ngooglestore=googlestore.drop(10472)","57450a49":"googlestore.head()","1f551c2a":"googlereviews.head()","28dd2ffd":"googlestore.Size.unique()","353fa601":"size_to_num = re.compile('(?P<number>\\d+\\.{0,1}\\d*)(?P<prefix>\\w*)')\n#In this function we use lowercase k for kilo and uppercase M for Mega.\n#We Assume no file with any other unit otherwise the unit will be ignored.\ndef prefix_to_mult(unit):\n    if unit == 'M':\n        return 1000000\n    if unit == 'k':\n        return 1000\n    return 1\n\n#This function can understand the format of the data given to it using regex,\n#If the given data is not in the expected format it will return 'Not a Number'\n#For example 'Varies with device' is transformed in NaN\ndef ConvertSizeToByte(Size):\n    searched = size_to_num.search(Size)\n    if searched is None:\n        return np.nan\n    else:\n        prefix = searched.group('prefix')\n        mult = prefix_to_mult(prefix)\n        result = float(searched.group('number'))\n        return int(result*mult)\n    \n#Here We apply it\ngooglestore['SizeInBytes'] = googlestore['Size'].apply(ConvertSizeToByte)","5597f6f0":"googlestore.Installs.unique()","497114ee":"install_to_num = re.compile('(?P<number>[\\d,]+)') #the format is num,num,num,...,num\n\n#We find using regex the number in the format \ndef installToNumber(installs):\n    found = install_to_num.search(installs)\n    if(found):\n        replacedComma = found.group('number').replace(',','') #replace the commas with nothing\n        return int(replacedComma)\n    else:\n        return np.nan\n    \n#Here we apply it\ngooglestore['InstallNumber']=googlestore['Installs'].apply(installToNumber)","4a455e3d":"#We Transform \u201cVaries with device\u201d into a missing value so it's easier to manage\ngooglestore.replace('Varies with device', np.nan,inplace=True)\n#inplace is needed so the replace is executed on the dataframe itself","73f2297b":"print('There are {0} missing data values in Current Ver out of {1} more than 12%'\n      .format(googlestore[googlestore['Current Ver'].isnull()].shape[0], googlestore.shape[0]))","e26fdf01":"googlestore['Current Ver'].value_counts()","8c27dde9":"#It will search for any string with the format num.num.num...\n#It should end with a number, can also not have a dot for example \n#a new app can have version 1 and not necessarily 1.0\ncurrentVer = re.compile('(?P<ver>[\\d+\\.]*\\d)') \n\ndef convertCurrentVer(version):\n    #Since we checked that there are some NaN values we use an extra condition\n    if pd.isnull(version):\n        return np.nan\n    CurVer=currentVer.search(version)\n    if CurVer is not None:\n        return CurVer.group('ver')\n    else:\n        return np.nan\n    \n#Here we apply it\ngooglestore['CurrentVersion']=googlestore['Current Ver'].apply(convertCurrentVer)","a00c65d9":"googlestore['Android Ver'].value_counts()","71b71452":"print('There are {0} missing data values in Android Ver out of {1} more than 12%'\n      .format(googlestore[googlestore['Android Ver'].isnull()].shape[0], googlestore.shape[0]))","446c4c87":"MinVer_toNum=re.compile('^(?P<MinVer>\\d+\\.\\d+\\.{0,1}\\d*)')\nMaxVer_toNum=re.compile('(?P<MaxVer>\\d+\\.\\d+\\.{0,1}\\d*)$')\n\n#To be changed if new version is released, will be used instead of 'and up'\nmajor_Android_ver = 8.1\n\n#We Decide not to trow away the missing version since we would we throwing away more that 12% of the data!\ndef MinAndroidVersion_ToNum(version):\n    if pd.isnull(version):\n        return np.nan\n    MinVer=MinVer_toNum.search(version)\n    if MinVer is not None:\n        return MinVer.group('MinVer')\n    else:\n        return np.nan\n    \ndef MaxAndroidVersion_ToNum(version):\n    #Since there are some NaN values\n    if pd.isnull(version):\n        return np.nan\n    MaxVer=MaxVer_toNum.search(version)\n    if MaxVer is not None:\n        return MaxVer.group('MaxVer')\n    else:\n        return major_Android_ver\n    \n#Here we apply it\ngooglestore['Min_Android_Ver']=googlestore['Android Ver'].apply(MinAndroidVersion_ToNum)\ngooglestore['Max_Android_Ver']=googlestore['Android Ver'].apply(MaxAndroidVersion_ToNum)","cb81f46e":"googlestore.head()","19ee5c58":"print('Total Extra Apps: ',googlestore[googlestore.duplicated('App')].shape[0])","e7dc8153":"#Convert the review column to numeric\ngooglestore.Reviews = googlestore.Reviews.apply(pd.to_numeric)\n#Check it's type now\ngooglestore.Reviews.dtype","f1ec7c88":"#We sort according to Reviews decendingly, keeping only the first\n#This way we keep the most updated instance\ngooglestore=googlestore.sort_values(['App','Reviews'],ascending=False).drop_duplicates('App',keep='first')","bfe54098":"print('Remaining Extra Apps: ',googlestore[googlestore.duplicated('App')].shape[0])","1f46e5b0":"googlestore.groupby('Category').size()","3b997d8e":"googlestore.groupby('Category')['Rating'].mean()","19bcfd22":"genre = pd.DataFrame([genres.split(';') for genres in googlestore.Genres])\n\ngenre_series = pd.Series() #Empty Series\nApps2 = pd.Series() #Empty Series\n\nfor i in genre.columns:\n    #just for convenience it indicates the column number of the genre dataframe created before\n    genre_i = genre[i] \n    #We append in a single series all the columns of the dataframe genre\n    genre_series = genre_series.append(genre_i)\n    #We append as many times as genre also the application, we will need to later for the join table\n    Apps2 = Apps2.append(googlestore.App)\n#We drop the None values assuming all the apps to hava a genre and keep only the unique values\n#So no app can have a None Genre.\ngenre_unique = genre_series.dropna().unique()\n#We sort it because we want the column of the genre ordered so it's easier to find thema\ngenre_unique_sorted = np.sort(genre_unique)\n\nprint(genre_unique_sorted)","dbf80361":"false_vector = np.repeat([False],googlestore.shape[0])\nfor elem in genre_unique_sorted:\n    googlestore[elem]=false_vector\n\n#Checking dtype of one of the columns\ngooglestore[genre_unique_sorted[0]].dtype","3771a0d0":"#We zip the only two important attributes for the exercise\n\n#We use zip instead of iterating because pandas is slow when it comes \n#to iterate over the rows using a for cycle and the loc or iloc function\nfor i in zip(googlestore.index, googlestore.Genres):\n    genrePerApp=i[1].split(';')\n    for elem in genrePerApp:\n        googlestore.at[i[0],elem] = True #We assign True only where needed and leave the rest False\n        #googlestore.loc[i[0],elem] = True\n        \n#I changed from .loc to .at because it is faster than loc because\n#'loc' select multiple columns while 'at' only a single value at a time. ","e2c93bb9":"#Since we created the new columns for each genre, let's use them. \n#Could have also used a groupby on each column\naverage_rating_per_genre=pd.Series() #Empty series, we use series because later we need use idxmax() \nfor genere in genre_unique:\n    ratings=googlestore[googlestore[genere]==True]['Rating']\n    average_rating_per_genre[genere]=ratings.mean(skipna=True)\n    #The mean is by deafault with skipna=True, but we put it explicitly to show the need here.\n    \npd.DataFrame(average_rating_per_genre,columns=['average_rating'])","8c927980":"#The maximum is\nprint(\"'{}' is the genre with highest ratings with {} average rating\"\n            .format(average_rating_per_genre.idxmax(),\n            average_rating_per_genre[average_rating_per_genre.idxmax()]))","a4e4311b":"#First we need to convert from Price to numbers\nmoney_to_float = re.compile('\\D*(?P<amount>\\d+\\.{0,1}\\d*)')\n\ndef Convert(money):\n    found = money_to_float.search(money)\n    if found:\n        return float(found.group('amount'))\n    else:\n        return None\n\n\ngooglestore['PriceInNumber']=googlestore.Price.apply(Convert)\n#Or just strip('$') and convert to numeric, but regex makes the code cooler.\n\ngooglestore['approximate_income']=googlestore.InstallNumber * googlestore.PriceInNumber","396070cb":"googlestore[['App','Price','InstallNumber','PriceInNumber','approximate_income']][googlestore.Price!='0'].head()\n#Holy Moly Look at that app it's $399.99 and 10,000 people bought it!","6ccdb91c":"googlereviews.isna().any() ","4775f4eb":"minSentiment = pd.DataFrame(googlereviews.groupby('App')['Sentiment_Polarity'].min())\nmaxSentiment = pd.DataFrame(googlereviews.groupby('App')['Sentiment_Polarity'].max())\nMinMaxSentiment = minSentiment.merge(maxSentiment, on='App',suffixes=['_min','_max'])\n\n#### We show only the ones without NaN, because the only one useful\nMinMaxSentiment[MinMaxSentiment.notnull().any(axis=1)]","5700ccb7":"**Convert the app sizes and the number of installs to a number**","dd6e6441":"**Another way was using the ```pd.DataFrame.apply()``` on the dataframe with a the following function:**\n\n```python\ndef checkGenre(row,AppGenres):\n    AppGenres=AppGenres.split(';')\n    for genre in AppGenres:\n        row[genre]=True\n    return row\n\ngooglestore=googlestore.apply(lambda x: checkGenre(x,x['Genres']), axis = 1)\n```\n\nbut it was slower than the method above\n\n\n**In Association Analysis we have another function of pandas to trasform the table having as the colums the frequency of the objects appearing in a column, and with some option we can even have a boolean transformation. The function of pandas is get_dummies(...)**","9567ea73":"**For each genre, compute the average rating. What is the genre with highest average?**","b69daf72":"The following cell contains the major_Android_ver considered 8.1 as of today.\n\nWe define two function one to compute the maximum version and one the minimum version.","3c7bd703":"**Remove the duplicated Rows**","c01e7a9d":"**For each app, compute its minimum and maximum Sentiment_polarity**","5b1046f9":"**For each genre, create a new column of the original dataframe. The new columns must have boolean values (True if the app has a given genre)**","7f007e75":"**For each category, compute the number of apps and the average rating**","693c7fe1":"**Convert Current Ver and Android Ver into dotted number (e.g. 4.0.3 or 4.2)**","fe2baf04":"**For each app, compute the approximate income, obtain as a product of number of installs and price.**","07f4ef4c":"We create a new column for each element in genre_unique_sorted and assign it a vector of False of size the number of elements of the googlestore dataframe, and we will assign True later only where needed (only a few elements will have True value and all the rest will have False)","6919a03d":"Another way of doing this exercise without could have been to replace k with e+3 and M with e+6 and convert all of the data to a numeric type:\n```python\n    googlestore.Size = googlestore.Size.str.replace('k','e+3')\n    googlestore.Size = googlestore.Size.str.replace('M','e+6')\n    googlestore.Size = googlestore.Size.replace('Varies with device',np.nan) \n    #Can create problem in the conversion \n    googlestore.Size=pd.to_numeric(googlestore.Size)\n```\nIt is cleaner but I peferred using regex"}}