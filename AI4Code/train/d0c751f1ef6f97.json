{"cell_type":{"a26b8294":"code","c31c3112":"code","cf821e31":"code","4ea26dee":"code","5e183862":"code","efc5e517":"code","b70ea85c":"code","d2e5395f":"code","564255da":"code","69880444":"code","f3883050":"code","fdc38527":"code","ef6801d9":"code","a48bfe3a":"code","f5bfd6af":"code","1dabefaf":"code","12cf0069":"code","09aef1b2":"code","0dc672be":"code","ffcf8a59":"code","727c155e":"code","85237fd1":"code","fb9fd758":"code","0c60df0b":"code","eba6ac59":"code","cc36c4d4":"code","2a0b6238":"code","4f547e90":"markdown"},"source":{"a26b8294":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport string\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c31c3112":"df = pd.read_csv(\"..\/input\/warframe.csv\")\ndf.head()","cf821e31":"# Groups of playTime\n#playTime = [\"0-1\",\"1-10\",\"10-50\",\"50-100\",\"100-500\",\"500-1000\",\"1000-1500\",\"1500-2000\",\"2000-2500\",\"2500-3000\",\"3000+\"]\nplayTime = [\"0-1\",\"1-10\",\"10-50\",\"50-100\",\"100-500\",\"500-1000\",\"1000-3000\",\"3000+\"]\ndf['playTime'] = pd.cut(df['hours'],bins=[0,1,10,50,100,500,1000,3000,11000],labels=playTime)\ndf['playTime'] = df['playTime'].astype('str')","4ea26dee":"# Preprocessing\ndf_review = df[[\"date\", \"hours\", \"products\",\"text\", \"recommended\",\"playTime\"]].copy()\ndf_review[\"recommended\"] = df_review[\"recommended\"].astype(dtype=np.int64)\ndf_review[\"text\"] = df_review[\"text\"].astype(str)\ndf_review.head()","5e183862":"printable = set(string.printable)\nprintable.remove(\"'\")\nnumbers = []\nfor i in range(10):\n    numbers.append(str(i))\nfor number in numbers:\n    printable.remove(number)\n\ndef pre_process(text):\n    text = text.lower()\n    text = re.sub('&lt;\/?.*?&gt;',' &lt;&gt; ',text)\n    text=re.sub('(\\\\d|\\\\W)+',' ',text)\n    \n    return text\ndf_review['cleantext'] = df_review['text'].apply(lambda row: ''.join(filter(lambda x:x in printable,row)))\ndf_review['cleantext'] = df_review['cleantext'].apply(lambda x:pre_process(x))\ndf_review.head()","efc5e517":"from nltk.corpus import stopwords\nfrom sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n\nenglish_stop_words = ENGLISH_STOP_WORDS\ndef remove_stop_words(corpus):\n    removed_stop_words = []\n    for review in corpus:\n        removed_stop_words.append(\n            ' '.join([word for word in review.split() \n                      if word not in english_stop_words])\n        )\n    return removed_stop_words\n\ndf_review['cleantext'] = remove_stop_words(df_review['cleantext'])\ndf_review.head()","b70ea85c":"from nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\ndef get_stemmed_text(corpus):\n    stemmer = PorterStemmer()\n    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\ndef get_lemmatized_text(corpus):\n    lemmatizer = WordNetLemmatizer()\n    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n\ndf_review['stemmedtext'] = get_stemmed_text(df_review['cleantext'])\ndf_review['lemmatext'] = get_lemmatized_text(df_review['stemmedtext'])\ndf_review.head()","d2e5395f":"# tf-idf weighting\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ntfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\ntfidf_vectorizer.fit(df_review['lemmatext'])\nX = tfidf_vectorizer.transform(df_review['lemmatext'])\ny = df_review['recommended']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c)\n    lr.fit(X_train, y_train)\n    print('Accuracy for C=%s: %s' %(c, accuracy_score(y_test, lr.predict(X_test))))\n","564255da":"final_tfidf = LogisticRegression(C=1)\nfinal_tfidf.fit(X_train, y_train)\naccuracy_score(y_test, final_tfidf.predict(X_test))","69880444":"# Determine the output(Overall, Single-Word, Paired-Words)\ndef sum_ngram(ngram_dict):\n    positive = []\n    for best_positive in sorted(\n        ngram_dict.items(),\n        key=lambda x: x[1],\n        reverse=True)[:20]:\n        positive.append(best_positive)\n    positive = pd.DataFrame(positive)\n    positive.columns = [\"poswords\", \"pos_importance\"]\n    \n    negative = []\n    for best_negative in sorted(\n        ngram_dict.items(),\n        key=lambda x: x[1])[:20]:\n        negative.append(best_negative)\n    negative = pd.DataFrame(negative)\n    negative.columns = [\"negwords\", \"neg_importance\"]\n    total = positive.join(negative)\n    return total\n\n# tfidf Model\ndef tfidf_game_model(hrs, ngram):\n    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n    tfidf_vectorizer.fit(df_review.loc[df_review[\"playTime\"]==hrs]['lemmatext'])\n    X = tfidf_vectorizer.transform(df_review.loc[df_review[\"playTime\"]==hrs]['lemmatext'])\n    y = df_review.loc[df_review[\"playTime\"]==hrs]['recommended']\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)\n    \n    final_tfidf = LogisticRegression(C=1)\n    final_tfidf.fit(X_train, y_train)\n    \n    tfidf_feature_to_coef = {\n    word: coef for word, coef in zip(\n     tfidf_vectorizer.get_feature_names(), final_tfidf.coef_[0])\n}\n    single_tfidf_feature_to_coef={}\n    pair_tfidf_feature_to_coef={}\n    for key, val in tfidf_feature_to_coef.items():\n        if len(key.split()) == 1:\n            single_tfidf_feature_to_coef[key] = val\n        else:\n            pair_tfidf_feature_to_coef[key] = val\n            \n    # return Overall\/Single\/Paired Analysis        \n    if ngram == None:\n        return(sum_ngram(tfidf_feature_to_coef))\n    if ngram == 1:\n        return(sum_ngram(single_tfidf_feature_to_coef))\n    else:\n        return(sum_ngram(pair_tfidf_feature_to_coef))","f3883050":"df_review.head()","fdc38527":"tfidf_game_model(\"0-1\",ngram=1)","ef6801d9":"tfidf_game_model(\"0-1\",ngram=2)","a48bfe3a":"tfidf_game_model(\"1-10\",ngram=1)","f5bfd6af":"tfidf_game_model(\"1-10\",ngram=2)","1dabefaf":"tfidf_game_model(\"10-50\",ngram=1)","12cf0069":"tfidf_game_model(\"10-50\",ngram=2)","09aef1b2":"tfidf_game_model(\"50-100\",ngram=1)","0dc672be":"tfidf_game_model(\"50-100\",ngram=2)","ffcf8a59":"tfidf_game_model(\"100-500\",ngram=1)","727c155e":"tfidf_game_model(\"100-500\",ngram=2)","85237fd1":"tfidf_game_model(\"500-1000\",ngram=1)","fb9fd758":"tfidf_game_model(\"500-1000\",ngram=2)","0c60df0b":"tfidf_game_model(\"1000-3000\",ngram=1)","eba6ac59":"tfidf_game_model(\"1000-3000\",ngram=2)","cc36c4d4":"tfidf_game_model(\"3000+\",ngram=1)","2a0b6238":"tfidf_game_model(\"3000+\",ngram=2)","4f547e90":"# Preprocessing data"}}