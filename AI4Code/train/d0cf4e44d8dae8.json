{"cell_type":{"929d7e1e":"code","29c82c65":"code","7a180b1f":"code","4d739136":"code","1035ad9f":"code","e6433e8a":"code","66182291":"code","c904ced5":"code","393e5894":"code","50afe8bd":"code","6adc3e48":"code","63ad5b10":"code","f3073452":"code","83e7b64e":"code","6935e794":"code","fc04ce6a":"code","04880482":"code","6a8b7458":"code","803f9c9c":"code","6caf8fed":"code","5be443cd":"markdown","43e732ad":"markdown","e141a9d4":"markdown","56d7464a":"markdown","3c17e8e1":"markdown","71454af3":"markdown","c4f9ea78":"markdown","f843f5e8":"markdown","9db2b077":"markdown","15cdb8ce":"markdown","1309748d":"markdown","f0347c3e":"markdown","d1308d4d":"markdown","880571e7":"markdown","19a671d4":"markdown","383a3709":"markdown","0fa18cb7":"markdown","cb0619fc":"markdown","b104b71a":"markdown","b258a7a7":"markdown","c2f00282":"markdown","afc61db7":"markdown"},"source":{"929d7e1e":"# Get some packages\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow\nimport time\nimport random","29c82c65":"# Read CSV\ncsv = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","7a180b1f":"csv","4d739136":"# Separate into metrices\nX_train = csv.iloc[:, 1:].to_numpy()\nY_train = csv.iloc[:,0].to_numpy()","1035ad9f":"X_train.shape","e6433e8a":"Y_train.shape","66182291":"count_imgs = X_train.shape[0] # 42000","c904ced5":"X_train_imgs = np.zeros([42000, 1, 28, 28])\nfor i in range(count_imgs):\n    img = X_train[i,:].reshape([1,28,28])\/255. # reshape & normalize\n    X_train_imgs[i] = img","393e5894":"Y_train_oh = np.zeros([42000,10]) # 42000 rows * 10 columns(filled with 0.)\nfor i in range(count_imgs):\n    oh = np.zeros([10]) # array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n    oh[int(Y_train[i])] = 1. # one-hot encoded Y vector(1 row)\n    Y_train_oh[i] = oh # fill one-hot encoded Y vector to Y_trian_oh matrix","50afe8bd":"X_train_imgs[0].shape","6adc3e48":"np.squeeze(X_train_imgs[0]).shape","63ad5b10":"sample_img = np.squeeze(X_train_imgs[0]) # (1,28,28) --(squeeze)--> (28,28)\nimshow(sample_img)\nplt.show()\nprint('This is : {}'.format(Y_train[0]))","f3073452":"class _G(nn.Module):\n    def __init__(self, z_size, c_size):\n        super(_G, self).__init__()\n        \n        self.conv2dtranspose_z = nn.ConvTranspose2d(in_channels=z_size, out_channels=256, kernel_size=4, stride=1)\n        self.bn2d_z = nn.BatchNorm2d(256, momentum=0.9)\n        self.conv2dtranspose_c = nn.ConvTranspose2d(in_channels=c_size, out_channels=256, kernel_size=4, stride=1)\n        self.bn2d_c = nn.BatchNorm2d(256, momentum=0.9)\n        self.backbone = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(negative_slope=0.2),\n            nn.BatchNorm2d(256, momentum=0.9),\n            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(negative_slope=0.2),\n            nn.BatchNorm2d(128, momentum=0.9),\n            nn.ConvTranspose2d(in_channels=128, out_channels=1, kernel_size=2, stride=2, padding=2),\n            nn.Tanh()\n        )\n        \n    # weight_init\n    def weight_init(self, mean, std):\n        for m in self._modules:\n            normal_init(self._modules[m], mean, std)\n\n    def forward(self, z, c):\n        z = z.view(-1, 100, 1, 1)\n        z = self.conv2dtranspose_z(z)\n        z = self.bn2d_z(z)\n        z = F.leaky_relu(z)\n        \n        c = c.view(-1, 10, 1, 1)\n        c = self.conv2dtranspose_c(c)\n        c = self.bn2d_c(c)\n        c = F.leaky_relu(c)\n        \n        zc = torch.cat([z,c],dim=1)\n        output = self.backbone(zc)\n        return output\n    ","83e7b64e":"class _D(nn.Module):\n    def __init__(self, c_size):\n        super(_D, self).__init__()\n        \n        self.conv2d_x = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.conv2d_c = nn.Conv2d(in_channels=10, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.backbone = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(negative_slope=0.2),\n            nn.BatchNorm2d(256, momentum=0.9),\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1 ),\n            nn.LeakyReLU(negative_slope=0.2),\n            nn.BatchNorm2d(512, momentum=0.9),\n            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=3, stride=2),\n            nn.Sigmoid()\n        )\n        \n    # weight_init\n    def weight_init(self, mean, std):\n        for m in self._modules:\n            normal_init(self._modules[m], mean, std)\n            \n    def forward(self, x, c):\n        x = self.conv2d_x(x)\n        \n        c = c.view(-1, 10, 1, 1)\n        c = c.expand(-1, 10, 28, 28)\n        c = self.conv2d_c(c)\n        \n        xc = torch.cat([x,c], dim=1)\n        output = self.backbone(xc)\n        output = output.view(-1,1)\n        return output","6935e794":"G = _G(100, 10) # Noise vector will have size 100\n                # and wee will have a condition vector of 10(1 for each type of item)\nD = _D(10) # The Discriminator will also use the condition,\n           # So we say it has size 10\n\ndef normal_init(m, mean, std):\n    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n        m.weight.data.normal_(mean, std)\n        m.bias.data.zero_()\n\nG.weight_init(mean=0, std=0.2) # GAN works better with these wight initializations\nD.weight_init(mean=0, std=0.2)","fc04ce6a":"if torch.cuda.is_available():\n    print('Current device : GPU - cuda:{}'.format(torch.cuda.current_device()))\n    print('\\n-------------------------------')\n    print('G.cuda() :\\n')\n    print(G.cuda())\n    print('\\n-------------------------------')\n    print('D.cuda() :\\n')\n    print(D.cuda())\nelse:\n    print('Current device : CPU')","04880482":"# 1. Creating Loss Function\ncriterion = nn.BCELoss() # Binary Cross-Entropy Loss\n\n# 2. Creating Optimizers\noptim_G = optim.Adam(G.parameters(), lr=0.0002)\noptim_D = optim.Adam(D.parameters(), lr=0.0002)","6a8b7458":"def optimize_G(G, D, z, c, optimizer, criterion):\n    \n    \"\"\"\n    When we train the generator we want it to trick the discriminator. This means that we want the output of D to be close to 1,\n    meaning it thinks its real. Keep that in mind. When we train G, we make the fake labels equal 1 so the optimizer tried to\n    make the generator make an image that tricks D.\n    \"\"\"\n    \n    #Even though the images are fake, we want the discriminator to think they are real\n    trick_labels = Variable(torch.ones([z.shape[0],1])-torch.rand([z.shape[0],1])\/3).cuda()\n    #Zero gradient buffers\n    G.zero_grad()\n    #Generate Images\n    fake_x = G.forward(z, c)\n    D_preds = D(fake_x, c)\n    loss = criterion(D_preds, trick_labels)\n    loss.backward()\n    optimizer.step()\n    \n    return fake_x, loss","803f9c9c":"def optimize_D(net, fake_x, fake_c, real_x, real_c, optimizer, criterion):\n    # We cannot feed a numpy variable. We have to use a torch.autograd.Variable\n    fake_labels = Variable(torch.zeros([fake_x.shape[0],1]) + torch.rand([z.shape[0],1])\/3).cuda()\n    real_labels = Variable(torch.ones([real_x.shape[0],1]) - torch.rand([z.shape[0],1])\/3).cuda()\n    \n    # We need to empty the gradient buffers\n    net.zero_grad()\n    \n    # Let's get the discriminator predictions for the fake images\n    fake_preds = net.forward(fake_x.detach(), fake_c)\n    # Do the optimization\n    fake_loss = criterion(fake_preds, fake_labels)\n    # Let's get the discriminator predictions for the real images\n    real_preds = net.forward(real_x, real_c)\n    # Do the optimization\n    real_loss = criterion(real_preds, real_labels)\n    \n    loss = fake_loss + real_loss\n    loss.backward()\n    optimizer.step()\n    \n    return fake_loss + real_loss","6caf8fed":"D_history = []\nG_history = []\nEPOCHS = 3 # for test, just 3 epochs.\nBATCH_SIZE = 128\n\nfor epoch in range(EPOCHS):\n    train_loss = 0\n    speed = 0\n    for batch_number in range(int(Y_train.shape[0]\/BATCH_SIZE)):\n        G.train()\n        time_start = time.time()\n        real_x = Variable(torch.FloatTensor(X_train_imgs[batch_number*BATCH_SIZE:(1+batch_number)*BATCH_SIZE])).cuda()\n        real_x = (real_x - real_x.mean())\/real_x.std() # Standardization\n        real_c = Variable(torch.FloatTensor(Y_train_oh[batch_number*BATCH_SIZE:(1+batch_number)*BATCH_SIZE])).cuda()\n        \n        z = Variable(torch.FloatTensor(np.random.randn(BATCH_SIZE, 100))).cuda()\n        fake_x, loss = optimize_G(G,D,z,real_c,optim_G,criterion)\n        G_history.append(loss.data.cpu().numpy().item())\n        \n        loss = optimize_D(D,fake_x,real_c,real_x,real_c,optim_D,criterion)\n        D_history.append(loss.data.cpu().numpy().item())\n        \n        if batch_number % 25 == 0:\n            bigfig = []\n            for i in range(0,10):\n                z = np.random.randn(1,100)\n                z = torch.FloatTensor(z)\n                z = Variable(z).cuda()\n                G.eval()\n                fig = []\n                for i in range(0,10):\n                    c = np.zeros([1,10])\n                    c[0,i] = 1.\n                    c = torch.FloatTensor(c)\n                    c = Variable(c).cuda()\n                    gens = G.forward(z, c)\n                    gens = gens.data.cpu().numpy()\n                    gens = gens.reshape([28,28])\n                    fig.append(gens\/2+0.5)\n                fig = np.hstack(fig)\n                bigfig.append(fig)\n            bigfig = np.vstack(bigfig)\n            print (bigfig.shape)\n            imshow(bigfig)\n            plt.show()\n            \n            print('G loss : ', G_history[-1])\n            print('D loss : ', D_history[-1])\n            print('D loss variance : ', np.stack(D_history, axis=0).std())\n    print('Finished Epoch', epoch+1)","5be443cd":"### 2-d. Moving the networks to the GPU\n\nUnlike Keras, we have to move the network to the GPU manually. PyTorch doesn't do this automatically. This is because it allows you to construct a complex multithreaded data feeder. This gist is that PyTorch gives you a lot more flexibility than Keras. It is also nearly twice as fast and extremely memory efficient.","43e732ad":"### 1-d. Data Preprocessing - Y","e141a9d4":"> index\n```\nStep 1. Load Data\n     1-a. read csv\n     1-b. x & y split\n     1-c. data preprocessing - x\n     1-d. data preprocessing - y \n     1-e. show sample image\nStep 2. Modeling\n     2-a. generator network\n     2-b. discriminator network\n     3-c. instantiate the networks\n     3-d. moving the networks to the gpu\n     3-e. create the loss function and optimizers\n     3-f. creating network optimizing functions \nStep 3. Model Training\n```\n","56d7464a":"# Conditional GAN\n\nIn a CGAN, you can specify a condition that the generated image has to adhere to. If you were to do this with MNIST, you can choose which label you would like to use to generate an image. This is extremely powerful when you are trying to create images of a certain type. As long as you have labels, you can choose what type of image to create. For example, you could use the CelebA dataset which supplies a picture of a celebrity plus sum attributes which you could use as a set of conditions. Then you could say you want an image of a male actor with sunglasses, etc. We will make a simple CGAN for the MNIST:","3c17e8e1":"# Now let's create two functions for optimizing each network\n\nI'm going this to simplify the process. Let's start with the optimization function:","71454af3":"## Step 2. Modeling","c4f9ea78":"# Tricks on Training GANs\n\nGANs are notoriously hard to train. Since we are using 2 neural networks, we need to make sure they are balaced. That is ONE of the problems. Another is mode collapse, where the generator doesn't produce images with lots of variety. This can get problematic, so we try to employ some tricks to keep the GANs balanced:\n\n1. Sample from a normal distribution, not a uniform one\n2. Normalize images between -1 and 1, not 1 and 0\n3. Use `max log D` instead of `min(log 1 - D)` as a loss to train the Generator\n4. Construct whole mini-batches of real and generated images, not a mix\n5. Use LeakyReLU not ReLU\n6. Use ConvTranspose2D instead of Upsampling\n7. Use Label Smooting\n\nWe will also add a more complex set of variables that will be returned when training. Not only will we return the `G`and `D` loss, but also the `D`'s variance. We want the variance to stay low in the discriminator loss, so we will keep track of it.\n\n**Note**: We will be using a Deep Convolutional GAN for it's superior performance!\n![image](https:\/\/i2.wp.com\/kawahara.ca\/wp-content\/uploads\/unsupervised_representation_learning_with_DCGAN.png)","f843f5e8":"## Step 3. Model Training","9db2b077":"### 1-b. X & Y Split","15cdb8ce":"### 1-e. show sample image","1309748d":"### 1-a. read csv","f0347c3e":"> This kernel and all of idea in it are a copy of [Conditional_Generative_Adversarial_Network - by Arpan Dhatt](https:\/\/www.kaggle.com\/arpandhatt\/conditional-generative-adversarial-network).\nThank you.","d1308d4d":"# Basic Concept\n![image](https:\/\/i.pinimg.com\/736x\/05\/75\/ca\/0575cab5214b55e99a59f0b64c35e1c5--arches.jpg)\n\nAs you can see, it's very simple. When we generate an image, we input the noize `z` concatenated with the conditions `c`. When we use the discriminator, we concatenate the generated image withe the `c` we used to generate it. If we are showing a real example, we add the condition, `c` with it. \n\nWe are going to use PyTorch for this demo. This way, I can get into more detail than I could have using Keras. As always, let's download and view the data first:","880571e7":"# Now let's start the training\n\nLets lay out the plan to the code we will use for training:\n\n1. Sample `z` from a Gaussian Distribution\n2. Create a batch of condition `c`\n3. Optimize `G`\n4. Optimize `D`\n5. Repeat","19a671d4":"### 2-c. Instantiate the Networks","383a3709":"### 2-e. Creating the Loss Function and Optimizers","0fa18cb7":"### 1-c. Data Preprocessing - X","cb0619fc":"### 2-f. Creating Network Optimizing Functions - Network : G","b104b71a":"### 2-b. Disciminator Network","b258a7a7":"### 2-g. Creating Network Optimizing Functions - Network : D","c2f00282":"### 2-a. Generator Network","afc61db7":"## Step 1. Load Data"}}