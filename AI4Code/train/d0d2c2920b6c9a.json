{"cell_type":{"e65fc2d5":"code","61bd64ed":"code","b8720534":"code","aecd360e":"code","0e9d3b6a":"code","02612043":"code","e24b0155":"code","e61c3ad6":"code","c89c80c3":"code","aa63d943":"code","99130e29":"code","3ec6ce8d":"code","e7dad650":"code","ab7f03de":"code","a5840963":"code","493f751f":"markdown","1fc41bb5":"markdown","32b10f10":"markdown","47d80cc4":"markdown","7b030c82":"markdown"},"source":{"e65fc2d5":"corpus = ['king is a strong man', \n          'queen is a wise woman', \n          'boy is a young man',\n          'girl is a young woman',\n          'prince is a young king',\n          'princess is a young queen',\n          'man is strong', \n          'woman is pretty',\n          'prince is a boy will be king',\n          'princess is a girl will be queen']","61bd64ed":"def remove_stop_words(corpus):\n    stop_words = ['is', 'a', 'will', 'be']\n    results = []\n    for text in corpus:\n        tmp = text.split(' ')\n        for stop_word in stop_words:\n            if stop_word in tmp:\n                tmp.remove(stop_word)\n        results.append(' '.join(tmp))\n    \n    return results","b8720534":"corpus = remove_stop_words(corpus)\nprint(corpus)","aecd360e":"words = []\nfor text in corpus:\n    for word in text.split(' '):\n        words.append(word)\n\nwords = set(words)\nwords","0e9d3b6a":"word_to_id = {}\nfor i, word in enumerate(words):\n    word_to_id[word] = i\n\nsentences = []\nfor sentence in corpus:\n    sentences.append(sentence.split())\n\nwindow_size = 2\n\ndata = []\nfor sentence in sentences:\n    for idx, word in enumerate(sentence):\n        for neighbor in sentence[max(idx - window_size, 0) : min(idx + window_size, len(sentence))+1]:\n            if neighbor != word:\n                data.append([word, neighbor])        ","02612043":"print(data)","e24b0155":"word_to_id","e61c3ad6":"import pandas as pd\n# for text in corpus:\n#     print(text)\n\ndf = pd.DataFrame(data, columns = ['input', 'label'])\nprint(df)","c89c80c3":"df.shape","aa63d943":"word_to_id","99130e29":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nimport numpy as np\n\nONE_HOT_DIM = len(words)\n\ndef to_one_hot_encoding(data_point_index):\n    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n    one_hot_encoding[data_point_index] = 1\n    return one_hot_encoding\n\nX = []\nY = []\n\nfor x, y in zip(df['input'], df['label']):\n    X.append(to_one_hot_encoding(word_to_id[x]))\n    Y.append(to_one_hot_encoding(word_to_id[y]))    \n\nX_train = np.asarray(X)\nY_train = np.asarray(Y)\n\nx = tf.placeholder(tf.float32, shape = (None, ONE_HOT_DIM))\ny_label = tf.placeholder(tf.float32, shape = (None, ONE_HOT_DIM))\nEMBEDDING_DIM = 2\n\nw1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\nb1 = tf.Variable(tf.random_normal([1]))\nhidden_layer = tf.add(tf.matmul(x, w1), b1)\n\nw2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\nb2 = tf.Variable(tf.random_normal([1]))\nprediction = tf.nn.softmax(tf.add(tf.matmul(hidden_layer, w2), b2))\n\nloss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis = [1]))\n\ntrain_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)","3ec6ce8d":"sess = tf.Session()\ninit = tf.global_variables_initializer()\nsess.run(init)\n\niteration = 20000\nfor i in range(iteration):\n    sess.run(train_op, feed_dict = {x : X_train, y_label : Y_train})\n    if i % 3000 == 0:\n        print('iteration ' + str(i) + 'loss is : ', sess.run(loss, feed_dict = {x : X_train, y_label : Y_train}))","e7dad650":"vectors = sess.run(w1 + b1)\nprint(vectors)","ab7f03de":"w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\nw2v_df['word'] = list(words)\nw2v_df = w2v_df[['word', 'x1', 'x2']]\nw2v_df","a5840963":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots()\n\nfor word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n    ax.annotate(word, (x1, x2))\n\nPADDING = 1.0\n\nx_axis_min = np.amin(vectors, axis=0)[0] - PADDING\ny_axis_min = np.amin(vectors, axis=0)[1] - PADDING\nx_axis_max = np.amax(vectors, axis=0)[0] + PADDING\ny_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n\nplt.xlim(x_axis_min, x_axis_max)\nplt.ylim(y_axis_min, y_axis_max)\nplt.rcParams['figure.figsize'] = (10, 10)\n\nplt.show()","493f751f":"## Define Tensorflow Graph","1fc41bb5":"<h3>Data Generation<\/h3>\n- we will generate label for each word using skip gram","32b10f10":"**Remove Stop words**<p><\/p>\nIn order for efficiency of creating word vector, we will remove commonly used words","47d80cc4":"<h4>Today I'm studying about Word2Vce.<\/h4> <p><\/p>\n<h4>I'm using tensorflow as a simple example<\/h4>","7b030c82":"**First I'm setting some corpus to create word vectors**"}}