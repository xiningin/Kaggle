{"cell_type":{"f3543832":"code","6a236b05":"code","5bc4d6ea":"code","64ccdcd2":"code","ebeb2926":"code","fa882382":"code","d9e733fc":"code","b7669357":"code","c3d542e7":"code","51d3b929":"code","cdb9d736":"code","2d595bbc":"code","d8770bfa":"code","4d83b9c9":"code","794970d0":"code","c11117de":"code","9ba2c1c3":"code","904a218f":"code","cf72cb26":"code","1ba051cb":"code","044ad4d6":"code","94cf19d5":"code","86a2a810":"code","e4b2cc3c":"code","ef466d1e":"code","b63260eb":"code","458ca602":"code","4d716fde":"code","c13d42a6":"code","8c2afcdd":"code","c279004a":"code","547fe441":"code","30e3a9a6":"code","b78b2083":"code","8b12fac9":"code","68852255":"code","f11e0d73":"code","d609e514":"code","e647d3ab":"code","abce13b7":"code","6446010d":"code","652f7f35":"code","5d7460dc":"code","4a003d3a":"code","c6f3b365":"code","b93afe31":"code","48e89f91":"markdown","1294e7d6":"markdown","9543f9be":"markdown","f24c2bc3":"markdown","428f6f85":"markdown","a26ada7e":"markdown","62ff57f9":"markdown","037e4f3e":"markdown","15f7dd26":"markdown","453e78f5":"markdown","b503913f":"markdown","39d5daaf":"markdown","2f54095f":"markdown","2314d240":"markdown","75028538":"markdown","702596ab":"markdown","053aefb4":"markdown","977d3c96":"markdown"},"source":{"f3543832":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a236b05":"#import data\ndf_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\npd.set_option('display.max_columns', None)\ndf_train.head()","5bc4d6ea":"df_train.columns","64ccdcd2":"df_train.info()","ebeb2926":"unique_id = len(set(df_train['Id'])) #set buat ngecek unique value\ntotal = df_train.shape[0]\nprint(\"There's {} double id on the data\" .format(total-unique_id))","fa882382":"df_train['SalePrice'].describe()","d9e733fc":"numeric_features = df_train.dtypes[df_train.dtypes != \"object\"].index\nnumeric_features = numeric_features.drop(\"SalePrice\")\ncategorical_features = df_train.dtypes[df_train.dtypes == \"object\"].index","b7669357":"df_train.hist(figsize=(30,15))\nplt.show()","c3d542e7":"def regplot(x, y, **kwargs):\n    sns.regplot(x=x, y=y)\n    x=plt.xticks(rotation=90)\n\nf = pd.melt(df_train, id_vars=['SalePrice'], value_vars=numeric_features)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False, size=5)\ng = g.map(regplot, \"value\", \"SalePrice\")\nplt.show()","51d3b929":"def boxplot(x, y, **kwargs):\n    sns.boxplot(x=x, y=y)\n    x=plt.xticks(rotation=90)\n\nf = pd.melt(df_train, id_vars=['SalePrice'], value_vars=categorical_features)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False, size=5)\ng = g.map(boxplot, \"value\", \"SalePrice\")\nplt.show()","cdb9d736":"corr = df_train.corr()\nfig, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corr, vmax=.8, square=True);\nplt.show()","2d595bbc":"print(corr.iloc[-1].sort_values(ascending=False).drop(\"SalePrice\"))","d8770bfa":"df = pd.concat([df_train, df_test])\ndf.head()","4d83b9c9":"df.shape","794970d0":"df_na = pd.DataFrame()\ndf_na[\"Feature\"] = df.columns\nmissing = ((df.isnull().sum() \/ len(df)) * 100).values\ndf_na[\"Missing\"] = missing\ndf_na = df_na[df_na[\"Feature\"] != \"SalePrice\"]\ndf_na = df_na[df_na[\"Missing\"] != 0]\ndf_na=df_na.sort_values(by=\"Missing\", ascending=False)\nprint(df_na)","c11117de":"df['Alley'] = df['Alley'].fillna('None')\ndf['MasVnrType'] = df['MasVnrType'].fillna('None')\ndf['BsmtQual'] = df['BsmtQual'].fillna('None')\ndf['BsmtCond'] = df['BsmtCond'].fillna('None')\ndf['BsmtExposure'] = df['BsmtExposure'].fillna('None')\ndf['BsmtFinType1'] = df['BsmtFinType1'].fillna('None')\ndf['BsmtFinType2'] = df['BsmtFinType2'].fillna('None')\ndf['FireplaceQu'] = df['FireplaceQu'].fillna('None')\ndf['GarageType'] = df['GarageType'].fillna('None')\ndf['GarageFinish'] = df['GarageFinish'].fillna('None')\ndf['GarageQual'] = df['GarageQual'].fillna('None')\ndf['GarageCond'] = df['GarageCond'].fillna('None')\ndf['Fence'] = df['Fence'].fillna('None')\ndf['MiscFeature'] = df['MiscFeature'].fillna('None')\ndf['PoolQC'] = df['PoolQC'].fillna('None')","9ba2c1c3":"df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\ndf['BsmtFinSF1'] = df['BsmtFinSF1'].fillna(0)\ndf['BsmtFinSF2'] = df['BsmtFinSF2'].fillna(0)\ndf['BsmtUnfSF'] = df['BsmtUnfSF'].fillna(0)\ndf['TotalBsmtSF'] = df['TotalBsmtSF'].fillna(0)\ndf['BsmtFullBath'] = df['BsmtFullBath'].fillna(0)\ndf['BsmtHalfBath'] = df['BsmtHalfBath'].fillna(0)\ndf['GarageCars'] = df['GarageCars'].fillna(0)\ndf['GarageArea'] = df['GarageArea'].fillna(0)\ndf['GarageYrBlt'] = df['GarageYrBlt'].fillna(0)","904a218f":"df['MSZoning'] = df['MSZoning'].fillna('RL')\ndf[\"Exterior1st\"] = df[\"Exterior1st\"].fillna('VinylSd')\ndf[\"Exterior2nd\"] = df[\"Exterior2nd\"].fillna('VinylSd')\ndf['Electrical'] = df['Electrical'].fillna('SBrkr')\ndf['KitchenQual'] = df['KitchenQual'].fillna('TA')\ndf['Functional'] = df['Functional'].fillna('Typ')\ndf['SaleType'] = df['SaleType'].fillna('WD')\ndf['Utilities'] = df['Utilities'].fillna('AllPub')","cf72cb26":"df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))","1ba051cb":"df_na = pd.DataFrame()\ndf_na[\"Feature\"] = df.columns\nmissing = ((df.isnull().sum() \/ len(df)) * 100).values\ndf_na[\"Missing\"] = missing\ndf_na = df_na[df_na[\"Feature\"] != \"SalePrice\"]\ndf_na = df_na[df_na[\"Missing\"] != 0]\ndf_na=df_na.sort_values(by=\"Missing\", ascending=False)\nprint(df_na)","044ad4d6":"df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']","94cf19d5":"num_to_cat=[\"BedroomAbvGr\", \"BsmtFullBath\", \"BsmtHalfBath\", \"Fireplaces\", \"FullBath\",\n            \"GarageCars\", \"HalfBath\", \"KitchenAbvGr\", \"MoSold\", \"MSSubClass\", \"OverallCond\", \n            \"OverallQual\", \"TotRmsAbvGrd\", \"YrSold\"]\n\ndf[num_to_cat] = df[num_to_cat].apply(lambda x: x.astype(\"str\"))","86a2a810":"df[num_to_cat]","e4b2cc3c":"df = pd.get_dummies(df, drop_first=True)","ef466d1e":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0,1))\ndf_trans = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)","b63260eb":"df_trans.info()","458ca602":"train = df_trans.iloc[:df_train.shape[0]]\ntrain = train.drop('Id', axis = 1)\ntest = df_trans.iloc[df_train.shape[0]:].drop(\"SalePrice\", axis=1)\n\nprint('Size of Training Data: {}' .format(train.shape))\nprint('Size of Testing Data: {}' .format(test.shape))","4d716fde":"df_trans.head()","c13d42a6":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split","8c2afcdd":"# bagi x dan y\nX = train.drop('SalePrice', axis=1)\nY = train['SalePrice']\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=35)\n\nprint(\"number of training samples:\",x_train.shape)\nprint(\"number of test samples:\", x_test.shape)","c279004a":"from keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.losses import mean_squared_error\nfrom keras import backend\nfrom keras.callbacks import ModelCheckpoint\n \ndef rmse(y_true, y_pred):\n    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))","547fe441":"nn = Sequential()\nnn.add(Dense(128, input_shape = (x_train.shape[1], ), activation = 'relu'))\nnn.add(Dense(256, activation='relu'))\nnn.add(Dense(1, activation = 'sigmoid'))\nnn.summary()\nnn.compile(optimizer='sgd', loss='mse')","30e3a9a6":"J = nn.fit(x_train,y_train, epochs=200, batch_size=16, validation_split = 0.001, verbose=0)\nprint('MSE of the training data: {}' .format(J.history['loss'][-1]))","b78b2083":"plt.plot(J.history['loss'][10:])","8b12fac9":"yhat = nn.predict(x_test)\nyhat.shape","68852255":"ytest = np.array(y_test).reshape(-1,1)\nfrom sklearn.metrics import mean_squared_error\nprint('MSE of testing data: {}'.format(mean_squared_error(ytest, yhat, squared= True)))","f11e0d73":"# Function that creates our Keras model\ndef create_model(optimizer= 'adam' , activation= 'relu'):\n    model = Sequential()\n    model.add(Dense(128, input_shape=(336,), activation=activation))\n    model.add(Dense(256, activation=activation))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer=optimizer, loss='mse', metrics=[\"accuracy\"])\n    return model\n\n# Import sklearn wrapper from keras\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n# Create a model as a sklearn estimator\nmodel = KerasClassifier(build_fn=create_model, epochs=6, batch_size=16, verbose = 0)","d609e514":"from sklearn.model_selection import RandomizedSearchCV\n\n# Define a series of parameters\nparams = dict(optimizer=['sgd','adam'],batch_size=[16, 32], activation=['relu','tanh', 'sigmoid', 'softmax'])\n\n# Create a random search cv object and fit it to the data\nrandom_search = RandomizedSearchCV(model, param_distributions=params, cv=5)\nrandom_search_results = random_search.fit(x_train, y_train, verbose=0)","e647d3ab":"print(\"Best: {} using {}\".format(random_search_results.best_score_,random_search_results.best_params_))","abce13b7":"y_pred = nn.predict(test.drop('Id',axis =1))","6446010d":"s = np.where(train.columns == 'SalePrice')\ntest.insert(23,'SalePrice', y_pred )","652f7f35":"test.head()","5d7460dc":"result = pd.DataFrame(scaler.inverse_transform(test), columns = test.columns)","4a003d3a":"result['Id'] = round(result['Id'])\nresult['Id'] = result['Id'].astype(int)","c6f3b365":"res = result[['Id', 'SalePrice']]\nres.to_csv('result.csv', index=False)","b93afe31":"res","48e89f91":"# Exploratory Data Analysis","1294e7d6":"Some missing values indicate None for some features","9543f9be":"For the rest categorical missing value, I change it to its mode","f24c2bc3":"Transform the data with MinMaxScaler to faster the iteration","428f6f85":"## Correlation Matrix","a26ada7e":"## Reference\n[1] https:\/\/towardsdatascience.com\/deep-neural-networks-for-regression-problems-81321897ca33","62ff57f9":"# Data Preparation","037e4f3e":"# Save the Result","15f7dd26":"Since I transform the data with MinMaxScaler, so I have to transform it to the original values with inverse_transform","453e78f5":"here I tried to insert SalePrice column to test table","b503913f":"# Data Modeling","39d5daaf":"This is the result","2f54095f":"## Deal with Missing Value","2314d240":"## Numerical features & Categorical features\nIn this step, I identify which features is categorical and which one is numerical","75028538":"# House Price Prediction using Neural Networks\nThis is my first Kaggle Project but published later due to some improvement. In this project I am predicting house price using Neural Networks with 1 hidden layer consists 256 neurons.","702596ab":"get dummies for categorical features","053aefb4":"# Tuning Hyperparameter","977d3c96":"## Loading the data"}}