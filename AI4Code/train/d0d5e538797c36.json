{"cell_type":{"457a610a":"code","9af58e27":"code","5f015182":"code","918c3ae9":"code","5420ffb1":"code","e6a2d9b7":"code","c9966967":"code","7c8f9fe7":"code","8cc6deff":"code","6d4bb411":"code","75bbd5dc":"code","8507bf53":"code","4dad7b6e":"code","7d87322d":"code","e6b0ad24":"code","ceeb4228":"code","3d79d50c":"code","4c54c834":"code","c653558b":"code","a8343ae7":"code","3ff6cb09":"code","9addf56e":"code","9fce24cd":"code","0c59ff06":"code","bb2f6ee6":"code","6a65aaf4":"code","a939225e":"code","ee31e407":"code","739992d2":"code","7ad9ba4e":"code","d1b40bf0":"code","52698be1":"code","2f58e76d":"code","50a33e31":"code","0126f2f3":"code","f410b910":"code","1cac198c":"code","8c7bbe01":"code","e426b25f":"code","bee03975":"code","0c12b057":"code","b8b72121":"code","32ba218f":"code","26bcb20d":"code","f058ea4c":"code","88a77f06":"code","3f2af6e6":"code","a6030828":"code","97b6e897":"code","a0ec1483":"code","91d782e0":"code","d72b188b":"code","02e08974":"code","bf9c8f50":"code","f97697e9":"code","d86ea87d":"code","b7244665":"code","5229dcfc":"markdown","5d659282":"markdown","005688eb":"markdown","71d4e17a":"markdown","9ec61040":"markdown","347dabab":"markdown","cfe385c6":"markdown","03a83783":"markdown","1e1c0721":"markdown","edacdd5d":"markdown","043790b0":"markdown","b0d4d854":"markdown","89d86009":"markdown","052aa572":"markdown","b9699699":"markdown","9f857a13":"markdown","82a4aba0":"markdown","eb8934d8":"markdown","0a66ad78":"markdown","833523f3":"markdown","ac9ad0fd":"markdown","86024f9b":"markdown","7104773e":"markdown"},"source":{"457a610a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9af58e27":"import sys\nprint('python: {}'.format(sys.version))\n\nimport scipy\nprint('scipy: {}'.format(scipy.__version__))\n\nimport numpy\nprint('numpy: {}'.format(numpy.__version__))\n\nimport matplotlib\nprint('matplotlib: {}'.format(matplotlib.__version__))\n\nimport pandas\nprint('pandas: {}'.format(pandas.__version__))\n\n\nimport sklearn\nprint('sklearn: {}'.format(sklearn.__version__))","5f015182":"import pandas\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","918c3ae9":"url = \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/iris\/iris.data\"\nnames =['sepal-length','sepal-width','petal-length','petal-width','class']\ndataset = pandas.read_csv(url, names=names) ","5420ffb1":"dataset.shape","e6a2d9b7":"dataset.head","c9966967":"dataset.describe()","7c8f9fe7":"dataset.groupby('class').size()","8cc6deff":"dataset.plot(kind ='box', subplots = True, layout =(2,2) ,sharex=False, sharey = False)\nplt.show()","6d4bb411":"dataset.hist()\nplt.show()","75bbd5dc":"scatter_matrix(dataset)\nplt.show()","8507bf53":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (20.0,10.0)\n\n#reading data\ndata = pd.read_csv('\/kaggle\/input\/headbraincsv\/headbrain.csv')\nprint(data.shape)\ndata.head()","4dad7b6e":"#Collecting X and Y\nX = data['Head Size(cm^3)'] .values\nY = data['Brain Weight(grams)'] .values\n\n# Mean X and Y\nmean_x = np.mean(X)\nmean_y = np.mean(Y)\n\n# Total number of values\nn=len(X)\n\n#using the formula to calculate b1(m) and b0(c)  (y = mx + c)\nnumer = 0\ndenom = 0\nfor i in range(n):\n    numer += (X[i] - mean_x)*(Y[i] - mean_y)\n    denom += (X[i] - mean_x) ** 2\nb1 = numer \/ denom\nb0 = mean_y - (b1 * mean_x)\n\n#print coefficients\nprint(b1,b0)","7d87322d":"max_x = np.max(X) + 100\nmin_x = np.min(Y) + 100\n\n#Calculating lines values x and y\nx = np.linspace(min_x,max_x,1000)\ny = b0 + b1 * x\n\n#plotting Line\nplt.plot(x,y,color='#58b970', label='Regression Line')\n\n#Plotting Scatter Points\nplt.scatter(X,Y, c='#ef5423' , label = 'Scatter Plot' )\n\nplt.xlabel('Head Size cm^3')\nplt.ylabel('Brain Weight grams')\nplt.legend()\nplt.show()","e6b0ad24":"ss_t = 0\nss_r = 0\nfor i in range(n):\n    y_pred = b0 + b1 * X[i]\n    ss_t += (Y[i] - mean_y) ** 2\n    ss_r += (Y[i] - y_pred) ** 2\nr2 = 1 - (ss_r\/ss_t)    \nprint(r2)","ceeb4228":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n#cannot use rank 1 matrix in scikit learn\nX = X.reshape((n,1))\n\n#Creating model\nreg = LinearRegression()\n\n#Fitting training data\nreg = reg.fit(X,Y)\n\n#Y Prediction\nY_pred = reg.predict(X)\n\n#Calculating RMSE and R2 Score\nmse = mean_squared_error(Y,Y_pred) \nrmse = np.sqrt(mse)\nr2_score = reg.score(X,Y)\n\nprint(np.sqrt(mse))\nprint(r2_score)","3d79d50c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport math\n\ntitanic_data = pd.read_csv(\"\/kaggle\/input\/titanic123\/ChanDarren_RaiTaran_Lab2a.csv\")\ntitanic_data.head(10)","4c54c834":"print(\"No of passengers in Original data \" + str(len(titanic_data.index)))","c653558b":"sns.countplot(x=\"Survived\" , data=titanic_data)","a8343ae7":"sns.countplot(x=\"Survived\", hue=\"Sex\" , data =titanic_data)","3ff6cb09":"sns.countplot(x=\"Survived\", hue=\"Pclass\" , data =titanic_data)","9addf56e":"titanic_data[\"Age\"].plot.hist()","9fce24cd":"titanic_data[\"Fare\"].plot.hist(bins=20, figsize =(10,5))","0c59ff06":"titanic_data.info()","bb2f6ee6":"sns.countplot(x=\"SibSp\",data=titanic_data)","6a65aaf4":"titanic_data.isnull()","a939225e":"titanic_data.isnull().sum()","ee31e407":"sns.heatmap(titanic_data.isnull(), yticklabels=False, cmap =\"viridis\")","739992d2":"sns.boxplot(x=\"Pclass\" ,y=\"Age\" ,data=titanic_data)","7ad9ba4e":"titanic_data.drop(\"Cabin\",axis=1,inplace=True)\ntitanic_data.head()","d1b40bf0":"titanic_data.dropna(inplace=True)","52698be1":"sns.heatmap(titanic_data.isnull(), yticklabels=False ,cbar=False)","2f58e76d":"titanic_data.isnull().sum()","50a33e31":"titanic_data.head(2)","0126f2f3":"sex=pd.get_dummies(titanic_data[\"Sex\"])\nsex.head(5)","f410b910":"sex=pd.get_dummies(titanic_data[\"Sex\"], drop_first =True)\nsex.head(5)","1cac198c":"embark=pd.get_dummies(titanic_data[\"Embarked\"])\nembark.head(5)","8c7bbe01":"embark=pd.get_dummies(titanic_data[\"Embarked\"], drop_first =True)\nembark.head(5)","e426b25f":"Pcl = pd.get_dummies(titanic_data[\"Pclass\"])\nPcl.head(5)","bee03975":"Pcl = pd.get_dummies(titanic_data[\"Pclass\"], drop_first=True)\nPcl.head(5)","0c12b057":"titanic_data = pd.concat([titanic_data,sex,embark,Pcl],axis=1)\ntitanic_data.head(5)","b8b72121":"titanic_data.drop(['Sex','Embarked','PassengerId','Name','Ticket','Pclass'],axis=1 ,inplace=True)\ntitanic_data.head(5)","32ba218f":"X = titanic_data.drop(\"Survived\" ,axis=1)\ny = titanic_data[\"Survived\"]","26bcb20d":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y , test_size=0.3, random_state=1)","f058ea4c":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression(max_iter=400).fit(X_train,y_train)","88a77f06":"predictions= logmodel.predict(X_test)","3f2af6e6":"from sklearn.metrics import classification_report\nclassification_report(y_test,predictions)","a6030828":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,predictions)","97b6e897":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,predictions)","a0ec1483":"dataset=pd.read_csv(\"\/kaggle\/input\/suv-data\/suv_data.csv\")\ndataset.head(10)","91d782e0":"X = dataset.iloc[:,[2,3]].values\nY = dataset.iloc[:,4]","d72b188b":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.25, random_state=0)","02e08974":"from sklearn.preprocessing import StandardScaler","bf9c8f50":"sc=StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","f97697e9":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train,y_train)","d86ea87d":"y_pred=classifier.predict(X_test)","b7244665":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","5229dcfc":"# Version Check","5d659282":"# Importing All Necessary Packages","005688eb":"**Visualization**","71d4e17a":"**Linear relation between Head Size and Brain Weight**","9ec61040":"# Reading Data","347dabab":"# **SUV Data Analysis**\nA car company has released a new SUV in the market. Using the previous data about the sales of their SUV's, they want to predict the category of people who might be interested in buying this.\n\nQ. What factors made people more interested in buying SUV?","cfe385c6":"Explore titanic dataset and explore about the people, both those who survived and those who did not.\n\nQ. What factors made people more likely to survive the sinking of the Titanic?","03a83783":"Since one column is enough two know the info therefore we will drop the 1st column","1e1c0721":"Implement Logistic Regression\nSteps we will follow: \n1. Collecting Data \n2. Analyzing Data \n3. Data Wrangling \n4. Train and Test \n5. Accuracy Check","edacdd5d":"# Linear Regression","043790b0":"**Logistic Regression**","b0d4d854":"This notebook contains Linear Regression example, Logistic Regression example. Soon all other machine learning algorithms will be covered.  ","89d86009":"Since two column is enough two know the info therefore we will drop the 1st column","052aa572":"As we can see there are lot of string values. So this has to be converted into categorical variables in order to implement logistic regression.\nSo we will convert this to categorical variables into some dummy variables and this can done using pandas because logistic regression takes just two values","b9699699":"**5. Accuracy Check**\n\nCalculate accuracy to check how accurte our results are.","9f857a13":"**3. Data Wrangling**\n\nClean the data by removing the Nan values and unnecessary columns in the dataset","82a4aba0":"**How Good our Model is?**","eb8934d8":"# **Titanic Data Analysis**","0a66ad78":"**4.Train and Test**\n\nHere will spilt the data into train subset and subset and then we will build a model on the train data and then predict the output on our test data set","833523f3":"**2. Analyzing Data**\n\n\n\nCreating different plot to check reltionship between variables","ac9ad0fd":"**1. Collecting Data**","86024f9b":"**Building Machine Learning Model using Scikit Learn**","7104773e":"Now, We can also scale our input values for better performance and this can be done using standard scalar"}}