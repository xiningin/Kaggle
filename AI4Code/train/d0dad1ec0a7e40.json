{"cell_type":{"00977c95":"code","14edab4e":"code","22a0591a":"code","56b9f832":"code","2f5d49c6":"code","0dedcd3b":"code","3c25fbe0":"code","4e002ce9":"code","89690df9":"code","7333594d":"code","4fbc1fb0":"code","408094c4":"code","f4f2f1f2":"code","439e866d":"markdown","e86323c9":"markdown"},"source":{"00977c95":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport librosa as lr\nimport matplotlib.pyplot as plt\n\nfrom pandas.plotting import lag_plot\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom librosa.display import specshow\nfrom librosa.core import stft\nfrom pprint import pprint\nfrom datetime import timezone, datetime, timedelta\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error as MSE\n\n# Make sure stdout lists the .csv files.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","14edab4e":"covid = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/train.csv', index_col=0)\nsubmission = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/test.csv', index_col=0)","22a0591a":"foo = covid[covid['Group'] == 'By Week']\nprint(foo[['COVID-19 Deaths', 'Start Date', 'Age Group']].dropna().groupby(['Start Date', 'Age Group']).sum()\\\n      .groupby('Age Group').mean())\nprint(foo[['COVID-19 Deaths', 'Start Date', 'Race and Hispanic Origin Group']].dropna().groupby(['Start Date', 'Race and Hispanic Origin Group']).sum()\\\n      .groupby('Race and Hispanic Origin Group').mean())\nfoo[['COVID-19 Deaths', 'Start Date']].dropna().groupby('Start Date').sum().mean()","56b9f832":"def split_X_y(df):\n    \"\"\"\n    Seperate the y column from `df` and returns (X, y)\n    \"\"\"\n    if 'COVID-19 Deaths' in df.columns:\n        return df.drop('COVID-19 Deaths', axis=1), df[['COVID-19 Deaths']]\n    else:\n        return df, None","2f5d49c6":"class SimpleCleanerDontUseInPipeline:\n    '''\n    Clean up columns of X, y.\n    '''\n\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        pass\n    def transform(self, X, y=None):\n        \n        # Get X and y. Cleaning is the first step in the pipeline so copy everything.\n        X_new = X.copy()\n        X_new['COVID-19 Deaths'] = y['COVID-19 Deaths'].copy() if not(y is None) else X['Start Date'].copy()\n        \n        # Convert 'Start Date' to datetime.\n        X_new['Start Date'] = pd.to_datetime(X_new['Start Date'])\n        \n        # Keep only rows where 'Group' and 'HHS Region' are 'By Week' and 'United States'.\n        X_new = X_new[(X['Group'] == 'By Week') & (X['HHS Region'] == 'United States')]\n        \n        # Sort by 'Start Date'.\n        X_new.sort_values(by='Start Date', inplace=True)\n        \n        # Keep only these.\n        keep = [\n            'Age Group',\n            'Race and Hispanic Origin Group',\n            'Start Date',\n            'MMWR Week',\n            'COVID-19 Deaths',\n            'Total Deaths'\n        ]\n        X_new = X_new[keep]\n        \n        # Keep only rows where val of col 'Start Date' > March 2020.\n        X_new = X_new[X_new['Start Date'] > datetime(year=2020, month=3, day=1)]\n        \n        # Return the new X and y.\n        if y is None:\n            return X_new.drop('COVID-19 Deaths', axis=1)\n        else:\n            return X_new.drop('COVID-19 Deaths', axis=1), X_new[['COVID-19 Deaths']]\n    \n    def fit_transform(self, X, y=None):\n        self.fit(X, y)\n        return self.transform(X, y)\n\nclass SimpleImputerDontUseInPipeline:\n    '''\n    Impute COVID-19 deaths.\n    \n    The `submission` dataset (i.e., when `y` is None) must NOT have any missing values.\n    \n    Data MUST be already sorted by 'Start Date'.\n    '''\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        pass\n        \n    def transform(self, X, y=None):\n        if y is None:\n            return X\n        \n        ages = X['Age Group'].unique()\n        races = X['Race and Hispanic Origin Group'].unique()\n        \n        for age in ages:\n            for race in races:\n                mask = (X['Age Group'] == age) & (X['Race and Hispanic Origin Group'] == race)\n                y.loc[mask, ['COVID-19 Deaths']] = y.loc[mask, ['COVID-19 Deaths']].interpolate('linear')\n                X.loc[mask, ['Total Deaths']] = X.loc[mask, ['Total Deaths']].interpolate('linear')\n                \n        # Fill in those pesky front values.\n        #y['COVID-19 Deaths'].fillna(0, inplace=True)\n        \n        # Drop all NaN.\n        notna = (X.notna().all(axis=1) & y.notna().all(axis=1))\n        X = X[notna]\n        y = y[notna]\n        \n        return X, y\n    def fit_transform(self, X, y=None):\n        self.fit(X, y)\n        return self.transform(X, y)\n    \nclass SimpleEngineer:\n    def __init__(self):\n        self.wavelength = timedelta(days=36 * 7)\n        self.wavelengthOffset = timedelta(days=0)\n    def fit(self, X, y=None):\n        pass\n    def transform(self, X, y=None):\n        X = X.copy()        \n        \n        # These are to let linear models predict on cyclic data.\n        def weeksAfter(wavelength, scale=1.0):\n            def lambda_weeksAfter(endDate):\n                '''\n                Convert datetime `endDate` to a [0, scale] interval based\n                on its position in the `wavelength` time interval.\n                '''\n                daystamp = int(endDate.replace(tzinfo=timezone.utc).timestamp() \/\/ 3_600 \/\/ 24)\n                return scale * (daystamp % wavelength.days) \/ wavelength.days\n            return lambda_weeksAfter\n        X['Start Date_cos'] = np.cos(2*np.pi * X['Start Date'].apply(weeksAfter(self.wavelength + self.wavelengthOffset)))\n        X['Start Date_sin'] = np.sin(2*np.pi * X['Start Date'].apply(weeksAfter(self.wavelength + self.wavelengthOffset)))\n        \n\n        # Enumerate 'Start Date'.\n        startdate_replacements = {v:i for i, v in enumerate(X['Start Date'].unique())}\n        X['Start Date'].replace(startdate_replacements, inplace=True)\n\n        \n        X = pd.get_dummies(X)\n        \n        return X\n    def fit_transform(self, X, y=None):\n        self.fit(X, y)\n        return self.transform(X, y)\n    def set_params(self, **params):\n        if 'wavelengthOffset' in params:\n            self.wavelengthOffset = timedelta(days=7 * params['wavelengthOffset'])","0dedcd3b":"# The TL;DR is that it blocks a serial-kfold:\n#\n# Un-blocking:\n# [___]###------------\n# [______]###---------\n# [_________]###------\n# [____________]###---\n# [_______________]###\n#\n# Blocking:\n# [___]###------------\n# ---[___]###---------\n# ------[___]###------\n# ---------[___]###---\n# ------------[___]###\n# \nclass BlockingTimeSeriesSplit():\n    '''\n    `block_size` -- Should be a float in (0.0, 1.0) or should be None. If set to\n                    None then `block_size` is set to `1 \/ n_splits`.\n    '''\n    def __init__(self, n_splits, block_size=None):\n        self.n_splits = n_splits\n        self.block_size = block_size\n    \n    def get_n_splits(self, X, y, groups):\n        return self.n_splits\n    \n    def split(self, X, y=None, groups=None):\n        \n        if self.block_size is None:\n            self.block_size = 1 \/ self.n_splits\n        \n        X_length = len(X)\n        block_length = int(X_length * self.block_size)\n        increment_length = (X_length - block_length) \/\/ self.n_splits\n        \n        margin = 0\n        indices = np.arange(X_length)\n        for i in range(self.n_splits):\n            beg = i * increment_length\n            end = beg + block_length\n            mid = beg + int(0.8 * (end - beg))\n            yield indices[beg:mid], indices[mid+margin:end]","3c25fbe0":"def split_X_y(df):\n    \"\"\"\n    Seperate the y column from `df` and returns (X, y)\n    \"\"\"\n    if 'COVID-19 Deaths' in df.columns:\n        return df.drop('COVID-19 Deaths', axis=1), df[['COVID-19 Deaths']]\n    else:\n        return df, None","4e002ce9":"class AggregateModel:\n    def __init__(self):\n        pass\n    def search(self, X, y):\n        \n        self.models = {}\n        for race in X['Race and Hispanic Origin Group'].unique():\n            self.models[race] = {}\n            for age in X['Age Group'].unique():\n                print(f'Searching \"{race}\" and \"{age}\".')\n                mask = (X['Race and Hispanic Origin Group'] == race) & (X['Age Group'] == age)\n                \n                pipeline = Pipeline([\n                    ('engineer', SimpleEngineer()),\n                    ('scaler', StandardScaler()),\n                    ('pca', PCA()),\n                    ('elastic', ElasticNet()),\n                ])\n                \n                params = {\n                    'elastic__alpha': np.linspace(.5, 10.5, 50),\n                    'elastic__l1_ratio': [.7],\n                    'engineer__wavelengthOffset': [-2, -1, 0, 1, 2],\n                }\n                \n                search = RandomizedSearchCV(pipeline,\n                                            param_distributions=params,\n                                            cv=5,\n                                            scoring='neg_root_mean_squared_error',\n                                            random_state=42)\n                search.fit(X[mask], y[mask])\n                self.models[race][age] = search.best_estimator_\n                \n    def fit(self, X, y):\n        for race in X['Race and Hispanic Origin Group'].unique():\n            for age in X['Age Group'].unique():\n                mask = (X['Race and Hispanic Origin Group'] == race) & (X['Age Group'] == age)\n                self.models[race][age].fit(X[mask], y[mask])\n                \n    def predict(self, X):\n        result = pd.DataFrame(columns=['id', 'COVID-19 Deaths'])\n\n        for race in X['Race and Hispanic Origin Group'].unique():\n            for age in X['Age Group'].unique():\n                mask = (X['Race and Hispanic Origin Group'] == race) & (X['Age Group'] == age)\n\n                prediction = self.models[race][age].predict(X[mask])\n                prediction = pd.DataFrame({\n                    'id': X[mask].index,\n                    'COVID-19 Deaths': prediction.ravel(),\n                })\n\n                result = result.append(prediction)\n        result.loc[result['COVID-19 Deaths'] < 0, 'COVID-19 Deaths'] = 0\n        return result.sort_values('id')['COVID-19 Deaths'].values","89690df9":"X, y = split_X_y(covid.copy())\nX, y = SimpleCleanerDontUseInPipeline().fit_transform(X, y)\nX, y = SimpleImputerDontUseInPipeline().fit_transform(X, y)\n\nmodel = AggregateModel()\nmodel.search(X, y)\n\nbest = {\n    'aggregate': {\n        'name': 'aggregate',\n        'model': model,\n    }\n}\nbest","7333594d":"'''for _, b in best.items():\n    scores = []\n    folds = 30\n    size = len(X)\n    for i in range(folds):\n        X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                            train_size=.3,\n                                                            random_state=i)\n        b['model'].fit(X_train, y_train)\n        scores.append(MSE(y_test, b['model'].predict(X_test)) ** .5)\n    \n    sns.swarmplot(data=scores)\n    plt.show()\n    print('='*20, b['name'])\n    print(pd.DataFrame(scores).describe())'''","4fbc1fb0":"\ndef plotResult(df_X, df_y):\n    '''\n    Plot X['COVID-19 Deaths'] vs y.\n    '''\n    result = pd.DataFrame({'COVID-19 Deaths': df_y['COVID-19 Deaths'], 'Start Date': df_X['Start Date']})\n    result.set_index('Start Date', inplace=True)\n    plt.plot(result)\n    plt.show()\n\ndef concatPrediction(X, y, X_sub, y_sub):\n    '''\n    Concat the prediction at the end of the training set.\n    '''\n    original = pd.DataFrame({'COVID-19 Deaths': y['COVID-19 Deaths'], 'Start Date': X['Start Date']})\n    original.set_index('Start Date', inplace=True)\n\n    predicted = pd.DataFrame({'COVID-19 Deaths': y_sub['COVID-19 Deaths'], 'Start Date': X_sub['Start Date']})\n    predicted.set_index('Start Date', inplace=True)\n\n    return pd.concat([original, predicted])\n\nfig, ax = plt.subplots(len(best.items()), 2, figsize=(25, 6))\n\nfor i, bitems in enumerate(best.items()):\n    _, b = bitems\n    best_model = b['model']\n    best_model.fit(X, y)\n    X_sub, _ = split_X_y(submission.copy())\n    X_sub = SimpleCleanerDontUseInPipeline().fit_transform(X_sub)\n    X_sub = SimpleImputerDontUseInPipeline().fit_transform(X_sub)\n\n    # Make prediction.\n    predictions = best_model.predict(X_sub)\n    output = pd.DataFrame({\n        'id': X_sub.index,\n        'COVID-19 Deaths': predictions.ravel(),\n    })\n    output.set_index('id', inplace=True)\n\n    result = concatPrediction(X, y, X_sub, output)\n    ax[0].plot(result, marker='.', linestyle='', alpha=.3)\n    ax[0].set_title(b['name'])\n    ax[1].plot(result)\n    ax[1].set_title(b['name'])\nplt.show()\n","408094c4":"\nX_sub, _ = split_X_y(submission.copy())\nX_sub = SimpleCleanerDontUseInPipeline().fit_transform(X_sub)\nX_sub = SimpleImputerDontUseInPipeline().fit_transform(X_sub)\n\n# Select model.\nselection = 'aggregate'\nbest_model = best[selection]['model']\nbest_name = best[selection]['name']\nprint(f'Submitting using {best_name}.')\n\n# Make prediction.\npredictions = best_model.predict(X_sub)\noutput = pd.DataFrame({\n    'id': X_sub.index,\n    'COVID-19 Deaths': predictions.ravel(),\n})\noutput.set_index('id', inplace=True)\n\n# Save it.\noutput.reset_index(level='id', inplace=True)\noutput.to_csv('submission.csv', index=False)\noutput.sort_values('id')\n","f4f2f1f2":"submission.sort_index()","439e866d":"# Build Model","e86323c9":"# Imports + Load Data from CSV"}}