{"cell_type":{"9975e3f5":"code","04809636":"code","98135569":"code","785bce7b":"code","514ef1c5":"code","7b8358b2":"code","ef8cdd35":"code","8fc0796e":"code","8be7adda":"code","3dc47537":"code","cc6f86b5":"code","282a4d96":"code","4d6a1094":"code","3bdbd86d":"code","5e499626":"code","08b358af":"code","7b9694c0":"code","24b97387":"code","c465ac10":"code","e048318e":"code","6357c36f":"code","a0a263ef":"code","549c96c9":"code","2c2e67a4":"code","b74c1920":"code","21e2b246":"code","ae91d6fe":"code","f09056f0":"code","1876e03a":"code","6162df4f":"code","ff246a78":"code","6b34bc82":"code","1264841f":"code","97c4920e":"markdown","2affbe10":"markdown","622feeb0":"markdown","3551d5a3":"markdown","f9a6473d":"markdown","361fee8d":"markdown","0ba29bf8":"markdown","18d69fba":"markdown","eff7076d":"markdown","bda2ed7d":"markdown","1a51433e":"markdown"},"source":{"9975e3f5":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","04809636":"import numpy as np \nimport seaborn as sns \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","98135569":"\ntrain_data=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\n#This displays first 5 data from the training-dataset\ntrain_data.head()\n#observation: the dataset consists of categorical variable and a few numerical variables.","785bce7b":"train_data.tail()\n#displaying bottom 5 data from the training-dataset","514ef1c5":"#Finding dimensions\nprint(\"number of rows in traning set\",train_data.shape[0])\nprint(\"number of columns in training set\",train_data.shape[1])\nprint(\"number of rows in test set\",test_data.shape[0])\nprint(\"number of columns in test set\",test_data.shape[1])","7b8358b2":"train_data.isna().sum()\n#Here Age,Cabin and Embarked have missing values","ef8cdd35":"test_data.isna().sum()\n#here Age,Fare,Cabin have missing values","8fc0796e":"# Data preprocessing\nsns.heatmap(train_data.corr(),annot=True)\n#Age is correlated to PCLASS the most with correlation coff=-0.37.","8be7adda":"df=train_data.groupby('Pclass',as_index=False)['Age'].median()\ndf.head()","3dc47537":"#Replacing missing vales in training set\n#AGE\nfor i,row in train_data.iterrows():\n    if(np.isnan(train_data['Age'][i])==True):\n        if(train_data['Pclass'][i]==1):\n            train_data['Age'][i]=37.0\n        elif(train_data['Pclass'][i]==2):\n            train_data['Age'][i]=29.0\n        else:\n            train_data['Age'][i]=24.0\n#CABIN (It has maximum number of missing values and hence it will NOT be worth a feature to work on. Still we will replace\n#the missing values with its mode)\ntrain_data['Cabin']=train_data['Cabin'].fillna(train_data['Cabin'].mode()[0])\n#EMBARKED\n#For this we have two missing values each having equivalent Fare of $80 and same PClass,same ticketnumber this\n#means that they had to board from the same station.And on google search, I got to know that she boarded from SouthHampton.\n#This means that Both of them boarded from SouthHampton.\ntrain_data['Embarked']=train_data['Embarked'].fillna('S')","cc6f86b5":"train_data.info()\n#no missing values in training set","282a4d96":"df=test_data.groupby('Pclass',as_index=False)['Age'].median()\ndf.head()","4d6a1094":"#Replacing Missing Values in Test Set\n#AGE\nfor i,row in test_data.iterrows():\n    if(np.isnan(test_data['Age'][i])==True):\n        if(test_data['Pclass'][i]==1):\n            test_data['Age'][i]=42.0\n        elif(test_data['Pclass'][i]==2):\n            test_data['Age'][i]=26.0\n        else:\n            test_data['Age'][i]=24.0\n#CABIN\ntest_data['Cabin']=test_data['Cabin'].fillna(test_data['Cabin'].mode()[0])\n#FARE\n#We can see that Fare is most correlated to Pclass and hence it should be computed by median of fare grouped by pclass.\n#As the person belonged to class 3, we will take median of class 3.","3bdbd86d":"df=test_data.groupby('Pclass',as_index=False)['Fare'].median()\ndf.head()","5e499626":"test_data['Fare']=test_data['Fare'].fillna(7.89)\ntest_data.isna().sum()\n#NO MISSING VALUES","08b358af":"# DATA VISUALIZATION\nplt.figure(figsize=(12,5))\nplt.subplot(121)\ntrain_data['Survived'].value_counts().plot.pie(autopct='%0.2f%%',colors=['red','green'])\nplt.subplot(122)\nplt.title('Survival distribution')\ntrain_data.Survived.value_counts().plot(kind='bar',color=['red','green'])","7b9694c0":"sns.pairplot(train_data)","24b97387":"plt.figure(figsize=(12,5))\nplt.subplot(121)\ntrain_data['Sex'].value_counts().plot.pie(autopct='%0.2f%%',colors=['blue','pink'])\nplt.subplot(122)\nsns.countplot(x = 'Survived',data = train_data,hue = 'Sex',palette=['blue','pink'])\nplt.xlabel('Survived')\nplt.ylabel('Passenger Count')\nplt.title('Survival distribution based on Sex')\nplt.legend()","c465ac10":"plt.figure(figsize=(12,5))\nplt.subplot(121)\ntrain_data['Pclass'].value_counts().plot.pie(autopct='%0.2f%%',colors=['blue','orange','green'])\nplt.subplot(122)\nsns.countplot(x = 'Survived',data = train_data,hue = 'Pclass',palette=['orange','green','blue'])\nplt.xlabel('Survived')\nplt.ylabel('Passenger Count')\nplt.title('Survival distribution based on Socio economic class of Passenger')\nplt.legend()","e048318e":"plt.figure(figsize=(12,5))\nplt.subplot(121)\ntrain_data['Embarked'].value_counts().plot.pie(autopct='%0.2f%%',colors=['blue','orange','green'])\nplt.subplot(122)\nsns.countplot(x = 'Survived',data = train_data,hue = 'Embarked',palette=['blue','orange','green'])\nplt.xlabel('Survived')\nplt.ylabel('Passenger Count')\nplt.title('Survival distribution based on Embarkment of Passenger')\nplt.legend()","6357c36f":"plt.figure(figsize=(12,6))\nsns.countplot(x = 'SibSp',data = train_data,hue = 'Survived',palette=['red','green'])\nplt.xlabel('SibSp')\nplt.ylabel('Passenger Count')\nplt.title('Survival distribution based on Number of Sibling\/spouse with Passenger')\nplt.legend()\n\nplt.figure(figsize=(12,6))\nsns.countplot(x = 'Parch',data = train_data,hue = 'Survived',palette=['red','green'])\nplt.xlabel('Parent\/Children')\nplt.ylabel('Passenger Count')\nplt.title('Survival distribution based on Number of Parent\/Children with Passenger')\nplt.legend()","a0a263ef":"sns.countplot(x = 'Parch',data = train_data,hue = 'Survived',palette=['red','green'])\nplt.xlabel('Parent\/Children')\nplt.ylabel('Passenger Count')\nplt.title('Survival distribution based on Number of Parent\/Children with Passenger')\nplt.legend()","549c96c9":"plt.figure(figsize=(16,4))\nplt.title('Age vs survival')\nsns.distplot(train_data['Age'][train_data['Survived']==0],bins=20,kde=True,hist=False,kde_kws={\"color\": \"red\", \"label\": \"Not Survived\"})\nsns.distplot(train_data['Age'][train_data['Survived']==1],bins=20,kde=True,hist=False,kde_kws={\"color\": \"green\", \"label\": \"Survived\"})","2c2e67a4":"plt.figure(figsize=(16,4))\nplt.title('Fare vs survival')\nsns.distplot(train_data['Fare'][train_data['Survived']==0],bins=10,kde=True,hist=False,kde_kws={\"color\": \"red\", \"label\": \"Not Survived\"})\nsns.distplot(train_data['Fare'][train_data['Survived']==1],bins=10,kde=True,hist=False,kde_kws={\"color\": \"green\", \"label\": \"Survived\"})","b74c1920":"sns.scatterplot(data=train_data,x='Age',y='Survived',hue='Survived')","21e2b246":"traindata=train_data.drop(['Name','Ticket','Cabin','PassengerId','Fare','SibSp','Age'],axis=1)\ntestdata=test_data.drop(['Name','Ticket','Cabin','PassengerId','Fare','SibSp','Age'],axis=1)\ntraindata.head()","ae91d6fe":"X_train=traindata.iloc[:,1:]\ny_train=traindata.iloc[:,0]\nX_train=pd.get_dummies(X_train,['Sex','Embarked'])\nX_test=testdata.iloc[:,:]\nX_test=pd.get_dummies(X_test,['Sex','Embarked'])","f09056f0":"from sklearn.svm import SVC\nclassifier=SVC(kernel='rbf')\nclassifier.fit(X_train,y_train)","1876e03a":"y_train_predict=classifier.predict(X_train)\ny_test=classifier.predict(X_test)","6162df4f":"from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,classification_report\nprint('Accuracy for training set is: ',accuracy_score(y_train,y_train_predict))\nprint('AUC SCORE for training set: ',roc_auc_score(y_train,y_train_predict))\n","ff246a78":"cm=confusion_matrix(y_train,y_train_predict)\nsns.heatmap(cm,annot=True)","6b34bc82":"print(classification_report(y_train,y_train_predict))","1264841f":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_test})\noutput.to_csv('svc-titanic.csv', index=False)\n","97c4920e":"Please, upvote my work if it could help! Thank you!","2affbe10":"# Visualizng Dataset","622feeb0":"**We have got 81% accuracy using support vector classifier.**","3551d5a3":"**Approach**:\n\nIn this Project firstly, I will display some feature analysis then ill focus on feature engineering. Last part concerns modeling and predicting the survival on the Titanic using a voting procedure.\nIn the modeling,I've used support vector classifier.","f9a6473d":"# Importing Libraries","361fee8d":"# **Titanic Project**","0ba29bf8":"**Target**:\n\nTo predict what sorts of people were more likely to survive i.e \"Survived\" column  in the Dataset.","18d69fba":"# Modelling using Support Vector Classifier ","eff7076d":"**About Dataset:** \n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.","bda2ed7d":"# Getting dataset","1a51433e":"# **Exploratory Data Analysis**"}}