{"cell_type":{"97779abc":"code","21031c3b":"code","41fdcb6a":"code","24b3c976":"code","6fd1f8bf":"code","2736448e":"code","bbbc3879":"code","6a14950d":"code","983c608f":"code","827f3a40":"code","ed5201de":"code","bc027a2e":"code","fe328c61":"code","749e321f":"code","ffef91c7":"code","102abfa0":"code","24b2fed6":"code","5dc2afc8":"code","155487b3":"code","083648a2":"code","a8302fb3":"code","01de8d26":"code","d0589a4f":"code","d2d3fbf7":"code","f45c49cb":"code","8dfdfdaf":"code","38482c8b":"code","283090b7":"code","37a436ff":"code","bc3cd69c":"code","66b7e513":"code","c55384b5":"code","4e6be120":"code","591ef04e":"code","0bca7df7":"code","097de973":"code","8578b6e5":"code","d7e0a122":"code","2f6da718":"code","56a16cce":"code","c066293b":"code","5b41d67c":"code","9595533f":"code","4df0b4fe":"code","96e1ae30":"code","51e5a682":"code","4eea59e2":"code","ffa02464":"code","2966277d":"code","f60ae7b8":"code","d6ec91bb":"code","d041926b":"code","d11d7905":"code","8797ed24":"code","80cd7a26":"code","1e048f99":"code","391b655d":"code","73e21fd5":"code","d1b951d0":"code","6175e9e8":"code","cee76cf6":"code","ca8f66a3":"code","f0be0f54":"code","6b8d6d90":"code","cabcd5e5":"code","78786092":"code","1ba97cb6":"code","2061e1a2":"markdown","8210d658":"markdown","58738078":"markdown","730a36ea":"markdown","9015e347":"markdown","dd771474":"markdown","6ba7d428":"markdown","fa3ba5b3":"markdown","47b32905":"markdown","8bdbf14b":"markdown","fe5374b6":"markdown","41789b1c":"markdown","f2b0cff9":"markdown","1b1de9c7":"markdown","3c3b27ea":"markdown","613124b3":"markdown","ce4895f6":"markdown","fe33694a":"markdown","b42932b2":"markdown","529b807e":"markdown","2258d14f":"markdown","91b43b66":"markdown","1da4274e":"markdown","33468da7":"markdown","e25e6a5e":"markdown","5d2f9059":"markdown","d279c47c":"markdown","d22936b0":"markdown","66d4d482":"markdown","ae0c6891":"markdown","335caf95":"markdown","7b70caed":"markdown","b4e6b94c":"markdown","73c1b033":"markdown","d64d5085":"markdown","7be8dea4":"markdown","70b03243":"markdown"},"source":{"97779abc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\", color_codes=True)\nsns.set(font_scale=1)\nfrom scipy import stats\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","21031c3b":"import matplotlib.pyplot as plt\nimport seaborn as sns","41fdcb6a":"trainData = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntestData = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\nprint('trainData: ', trainData.shape)\nprint('testData: ', testData.shape)","24b3c976":"# pd.set_option('max_columns', 82)\ntrainData.head()","6fd1f8bf":"testData.head()","2736448e":"trainData.columns # to know the columns","bbbc3879":"#description\ndesc_file = open('..\/input\/house-prices-advanced-regression-techniques\/data_description.txt')\nprint(desc_file.read())","6a14950d":"trainData.describe()","983c608f":"sns.displot(trainData['SalePrice'])\nplt.show()","827f3a40":"trainData.dtypes.value_counts()","ed5201de":"corr= trainData.corr()[\"SalePrice\"]\ncorr[np.argsort(corr, axis=0)[::-1]]","bc027a2e":"plt.figure(figsize=(20,20))\ncorr = corr[1:-1]   #remove 1s SalePrice\ncorr.plot(kind='barh')\nplt.title('Correlation coeff wrt SalesPrice')\nplt.legend()","fe328c61":"high_Correlated_Var = ['SalePrice', 'OverallQual', 'GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath','TotRmsAbvGrd','YearBuilt','YearRemodAdd','GarageYrBlt','MasVnrArea','Fireplaces']\n\ncorrMatrix=trainData[high_Correlated_Var].corr()\n\nplt.figure(figsize=(15,15))\nsns.heatmap(corrMatrix, vmax=.8, linewidths=0.01,square=True, annot=True, cmap='viridis',linecolor='black')\nplt.title('Correlation between Features')\n","749e321f":"feature_var = 'OverallQual'\ntarget_var = 'SalePrice'\ntrainData[[feature_var, target_var]].groupby([feature_var], as_index = False).mean().sort_values(by=feature_var, ascending=False)","ffef91c7":"cols = ['SalePrice', 'OverallQual','GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt']\nsns.pairplot(trainData[cols],size=2.5)","102abfa0":"#box plot\nplt.figure(figsize=[10,5])\nsns.boxplot(x='OverallQual', y='SalePrice', data=trainData)","24b2fed6":"#histogram for skewness and kurtosis\nplt.figure(figsize=[20,5])\nsns.distplot(trainData['SalePrice'])\nplt.title('SalePrice Distribution')\nplt.xlabel('Sale Price')\nplt.ylabel('No. of Occurence')\n\nprint(\"Skewness: %f\" %trainData['SalePrice'].skew())\nprint(\"Kurtosis: %f\" %trainData['SalePrice'].kurt())","5dc2afc8":"#normal probability plot to know the how data is linearly distributed\nplt.figure(figsize=[10,8])\nstats.probplot(trainData['SalePrice'], plot = plt)","155487b3":"#plot the distribution of sale price\nplt.figure(figsize=[10,8])\nplt.scatter(trainData[\"SalePrice\"].values, range(trainData.shape[0]))\nplt.title(\"Distribution of SalePrice\")\nplt.xlabel(\"SalePrice\")\nplt.ylabel(\"No. of Occurence\")","083648a2":"upperlimit=np.percentile(trainData.SalePrice.values,99.5)\ntrainData['SalePrice'].loc[trainData['SalePrice']>upperlimit] = upperlimit","a8302fb3":"plt.figure(figsize=[10,8])\nplt.scatter(trainData[\"SalePrice\"].values, range(trainData.shape[0]))\nplt.title(\"Distribution of SalePrice\")\nplt.xlabel(\"SalePrice\")\nplt.ylabel(\"No. of Occurence\")","01de8d26":"trainData['SalePrice'] = np.log(trainData['SalePrice'])\n","d0589a4f":"#histogram for skewness and kurtosis\nplt.figure(figsize=[16,6])\nsns.distplot(trainData['SalePrice'])\nplt.title('SalePrice Distribution')\nplt.xlabel('Sale Price')\nplt.ylabel('No. of Occurence')\n\n#normal prob plot\nplt.figure(figsize=[16,6])\nstats.probplot(trainData['SalePrice'], plot = plt)\n\n\nprint(\"Skewness: %f\" %trainData['SalePrice'].skew())\nprint(\"Kurtosis: %f\" %trainData['SalePrice'].kurt())","d2d3fbf7":"sns.catplot(x='PoolArea', y='SalePrice', data=trainData, hue=\"PoolQC\", kind='bar')\nplt.title(\"Pool Area, PoolQuality & Sale Price\")\nplt.ylabel(\"SalePrice\")\nplt.xlabel(\"Pool Area(insqfeet)\")","f45c49cb":"sns.catplot(x=\"Fireplaces\", y=\"SalePrice\", data=trainData, hue=\"FireplaceQu\", kind='point')","8dfdfdaf":"plt.figure(figsize=[8,6])\nplt.scatter(x=trainData['GrLivArea'], y=trainData['SalePrice'])\nplt.xlabel('GrLivArea', fontsize=13)\nplt.ylabel('SalePrice', fontsize=13)","38482c8b":"# trainData.drop(trainData[(trainData['GrLivArea']>4000) & (trainData['SalePrice'] < 300000)].index)\n\ntrainData = trainData.drop(trainData[(trainData['GrLivArea']>4000) & (trainData['SalePrice'] <300000)].index)","283090b7":"plt.figure(figsize=[8,6])\nplt.scatter(x=trainData['GrLivArea'], y=trainData['SalePrice'])\nplt.xlabel('GrLivArea', fontsize=13)\nplt.ylabel('SalePrice', fontsize=13)","37a436ff":"ntrain = trainData.shape[0]\nntest = testData.shape[0]\ny_train = trainData.SalePrice.values\nall_data = pd.concat((trainData,testData)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\n\nall_data.shape","bc3cd69c":"#list variable with missing data\nnull_col = all_data.columns[all_data.isnull().any()]\ntotal_null_columns = all_data[null_col].isnull().sum()\npercent_null_col =(total_null_columns\/all_data[null_col].isnull().count())\nmissing_data = pd.concat([total_null_columns, percent_null_col], axis=1, keys=['Total', 'Percent']).sort_values(by=['Percent'], ascending=False)\nmissing_data.head()","66b7e513":"#lets plot it\nplt.figure(figsize=[20,4])\nplt.xticks(rotation='90', fontsize=10)\nsns.barplot(x=missing_data.index, y=missing_data.Percent, palette='Dark2')\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent msising data by features', fontsize=20)","c55384b5":"all_data['PoolQC'].unique()","4e6be120":"#replace null with None\nall_data['PoolQC'].fillna('None', inplace =True)","591ef04e":"all_data['MiscFeature'].fillna('None', inplace=True)\nall_data['Alley'].fillna('None', inplace=True)\nall_data['Fence'].fillna('None', inplace=True)\nall_data['FireplaceQu'].fillna('None', inplace=True)","0bca7df7":"#median plot\nplt.figure(figsize=[15,5])\nplt.xticks(rotation=90)\n\nsns.barplot(data=trainData, x = \"Neighborhood\", y='LotFrontage', estimator=np.median)\n","097de973":"#get unique values of the column data\nall_data['LotFrontage'].unique()","8578b6e5":"#replae null with median\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x:x.fillna(x.median()))","d7e0a122":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    print(all_data[col].unique())","2f6da718":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col].fillna('None', inplace=True)","56a16cce":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col].fillna('None', inplace=True)","c066293b":"for col in (\"GarageYrBlt\", \"GarageArea\", \"GarageCars\"):\n    print(all_data[col].unique())","5b41d67c":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col].fillna(0, inplace=True)","9595533f":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    print(all_data[col].unique())","4df0b4fe":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col].fillna('None', inplace=True)","96e1ae30":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF','BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col].fillna(0, inplace=True)","51e5a682":"all_data['MasVnrType'].fillna(\"None\", inplace=True)\nall_data['MasVnrArea'].fillna(0, inplace=True)","4eea59e2":"for col in ('MSZoning', 'Utilities','Functional', 'Exterior2nd','Exterior1st','KitchenQual','Electrical','SaleType'):\n    all_data[col].fillna(all_data[col].mode()[0], inplace=True)","ffa02464":"null_col = all_data.columns[all_data.isnull().any()]\nprint(null_col)","2966277d":"numeric_features = all_data.dtypes[all_data.dtypes != 'object'].index\nskewness = []\nfor col in numeric_features:\n    skewness.append((col, all_data[col].skew()))\n    \npd.DataFrame(skewness, columns=('Feature', 'Skewness')).sort_values(by='Skewness', ascending=False)\n","f60ae7b8":"#use log transformation to reduce skewness of positivley skewed features\nall_data.head()","d6ec91bb":"positively_skewed_features = all_data[numeric_features].columns[abs(all_data[numeric_features].skew()) > 1]\n# print (positively_skewed_features)\n\n# applying log transformation\nfor col in positively_skewed_features:\n    all_data[col] = np.log(np.ma.array(all_data[col], mask=(all_data[col]<=0))) ","d041926b":"all_data.head()","d11d7905":"all_data = pd.get_dummies(all_data)\nprint(all_data.shape)","8797ed24":"train = all_data[:ntrain]\ntest = all_data[ntrain:]\ntrain.head()","80cd7a26":"#import\nfrom sklearn.linear_model import ElasticNet, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","1e048f99":"x_train = train.drop(['Id'], axis=1)\nx_test = test.drop(['Id'], axis = 1)","391b655d":"model_lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005))\ncv_score = np.sqrt( -cross_val_score(model_lasso, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=5) )\nprint (cv_score)\nprint (\"SCORE (mean: %f , std: %f)\" % (np.mean(cv_score), np.std(cv_score)))","73e21fd5":"modelElastic_net = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005))\ncv_score = np.sqrt(-cross_val_score(modelElastic_net, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=5))\nprint(cv_score)\nprint (\"SCORE (mean: %f , std: %f)\" % (np.mean(cv_score), np.std(cv_score)))","d1b951d0":"modelKernel_ridge = KernelRidge(alpha=0.6)\ncv_score = np.sqrt(-cross_val_score(modelKernel_ridge, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=5))\nprint(cv_score)\nprint (\"SCORE (mean: %f , std: %f)\" % (np.mean(cv_score), np.std(cv_score)))","6175e9e8":"model_gboost = GradientBoostingRegressor(n_estimators= 3000, learning_rate=0.05,\n                                        max_depth=4, max_features='sqrt', \n                                        min_samples_leaf=15, min_samples_split=10,\n                                        loss='huber', random_state=5)\n\ncv_score = np.sqrt(-cross_val_score(model_gboost, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=5))\nprint(cv_score)\nprint (\"SCORE (mean: %f , std: %f)\" % (np.mean(cv_score), np.std(cv_score)))","cee76cf6":"model_xgboost = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=True, nthread = -1)\n\n# y_train is defined above where we combined train and test data to create all_data\n# np.sqrt() function is used to create square root of MSE returned by cross_val_score function\ncv_score = np.sqrt( -cross_val_score(model_xgboost, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=5) )\nprint (cv_score)\nprint (\"SCORE (mean: %f , std: %f)\" % (np.mean(cv_score), np.std(cv_score)))","ca8f66a3":"model_lgbm = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n\n# y_train is defined above where we combined train and test data to create all_data\n# np.sqrt() function is used to create square root of MSE returned by cross_val_score function\ncv_score = np.sqrt( -cross_val_score(model_lgbm, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=5) )\nprint (cv_score)\nprint (\"SCORE (mean: %f , std: %f)\" % (np.mean(cv_score), np.std(cv_score)))","f0be0f54":"model_lasso.fit(x_train, y_train)\nmodel_lgbm.fit(x_train, y_train)\nmodel_xgboost.fit(x_train, y_train)\nmodelElastic_net.fit(x_train, y_train)\nmodelKernel_ridge.fit(x_train, y_train)\nmodel_gboost.fit(x_train, y_train)","6b8d6d90":"dict_models = {'lasso':model_lasso, 'elastic_net':modelElastic_net, 'kernel_ridge':modelKernel_ridge, \n            'gboost':model_gboost, 'xgboost':model_xgboost, 'lgbm':model_lgbm}\n\nfor key, value in dict_models.items():\n    pred_train = value.predict(x_train)\n    rmse = np.sqrt(mean_squared_error(y_train, pred_train))\n    print (\"%s: %f\" % (key, rmse))","cabcd5e5":"prediction_lasso = np.expm1(model_lasso.predict(x_test))\nprediction_elastic_net = np.expm1(modelElastic_net.predict(x_test))\nprediction_kernel_ridge = np.expm1(modelKernel_ridge.predict(x_test))\nprediction_gboost = np.expm1(model_gboost.predict(x_test))\n\nprediction_xgboost = np.expm1(model_xgboost.predict(x_test))\nprediction_lgbm = np.expm1(model_lgbm.predict(x_test))","78786092":"prediction = (prediction_lasso + prediction_elastic_net)\/float(2)\nprint(prediction)","1ba97cb6":"submission = pd.DataFrame({\n    \"Id\": test[\"Id\"],\n    \"SalePrice\":prediction\n})\nsubmission.to_csv('submission.csv', index=False)","2061e1a2":"with this graph we can eaisly see the outliers between 4000 and 6000 GrLivArea\n\nLets remove them","8210d658":"#### 3. LotFrontage\n\n`Linear Feet of Street Connected to Property`\nThe missing value means property is not connnected with street. SO we **assume that the distance of street connected to current property will be same as that of the neighbor's property**.\nSo Fill the Missing Value by *Median*","58738078":"Data Distribution is closly following diagonals","730a36ea":"### Lasso Regression\nRobustScaler() method is added to pipeline to make it less sensisitive to outliers\n","9015e347":"## Creating Dummy Categorical Features","dd771474":"#### 1. PoolQC  --> replace Null with None","6ba7d428":"## Work on Missing Values","fa3ba5b3":"Now we have solved the problem of null Values\n\n# Reduce Skewness of Independent Variables\nIn this we will use **Log Transformation**\n\nFirstly check the skewness of numeric dependent variables:","47b32905":"### GrLivArea vs SalePrice","8bdbf14b":"## Modelling\nCreate different regresion model and evaluate with RMSE of prediction done by model.\n\nModels that will be tested\n* Lasso\n* ELastic Net\n* Kernel Ridge\n* Gradient Boost\n* XGBoost\n* LightGBM","fe5374b6":"## Submission","41789b1c":"## Heatmap of Correlation with  SalePrice","f2b0cff9":"Replace the NA of *MasVnrType* with **None** and NA of *MasVnrArea* with **0(zero)**","1b1de9c7":"# Get new Train and Test DataSet","3c3b27ea":"## Correlation Features with Target Variable\n\nA positive correlation is a relationship between two variables in which both variables move in the same direction. ... A negative correlation is a relationship between two variables in which an increase in one variable is associated with a decrease in the other.","613124b3":"## Replace Missing Data with values","ce4895f6":"#### BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath\nReplace missing values with 0(zero)\n","fe33694a":"\"SO SalePirce is `positively skeweed and highly kurtosis`\n\n- High kurtos data means it has some outliners. Its time to remove them","b42932b2":"## Log Transformation\nby this data distribution become more linear --> Log funciton squeezes the larger values and stretches the smaller values","529b807e":"### Gradient Boosting Reg","2258d14f":"#### 2. MiscFeature, Alley, Fence, FireplaceQu --> replace with None","91b43b66":"### GarageType, GarageFinish, GarageQual and GarageCond","1da4274e":"## Generate Prediction","33468da7":"### Generate Prediction on Trainig data","e25e6a5e":"#### GarageYrBlt, GarageArea and GarageCars\n\nThese are numeric variables --> replace null with 0(zero)","5d2f9059":"### Kernel Ridge REgression","d279c47c":"From above graph we can observe that some features are intercorrelated among themselves and this will cause **MultiCollinearity**\n\nWe need to reduce this collinearity by:\n1. removing the interrelated features\n2. creating a new feature by combining the interrealted features.","d22936b0":"### Generate Prediction on Test Data\nnp.expm1() ==> exp(x)-1","66d4d482":"## Dependent variable distribution analysis [SalesPrice]\n\n1. Skewness --> measure of Symmetry  (negative --> left tail longer | positive --> right tail longer\n2. Kurtosis --> measure of heavy tailed and light tailed data relative to normal distirbution","ae0c6891":"Analysis: GrLivArea and TotalBsmtSF are linearly related with PRice whereas YearBuilt and OverAllQual are positively related.\n\nConclusion: Draw OveralQual wrt SalePrice","335caf95":"### ElasticNet Regression","7b70caed":"Replace nominal features means those who has less than 5 missing values with the most common value","b4e6b94c":"# Analyzing Independent Variables Distribution\n\nLet's do Multivariate Analysis (involvles two or more variables at a time)","73c1b033":"### LightGBM(Light Gradient Boosting)","d64d5085":"### XGBOOST --> for decision tree","7be8dea4":"#### BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2","70b03243":"#### GarageYrBlt, GarageArea and GarageCars\n"}}