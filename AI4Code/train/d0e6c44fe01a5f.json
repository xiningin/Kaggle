{"cell_type":{"9f47f46d":"code","81945d99":"code","9f1915b7":"code","c95cbdb9":"code","d971a5f7":"code","d9fd039b":"code","0dd878d5":"code","59bd4b2b":"code","6251e6bb":"code","25cca57b":"code","fab68aa0":"code","f1c5e40a":"code","94e390cb":"code","4533a31b":"code","4e663805":"code","d4695cf3":"code","e776d35c":"code","7c7341ab":"code","ca444393":"code","af01293b":"code","e5b94312":"code","6541006a":"code","8cbfce3c":"code","30a5d80f":"code","55229d7e":"markdown","d6949177":"markdown","5be2262d":"markdown","8117664e":"markdown","352933bd":"markdown","6ed19bca":"markdown","1d72cfb4":"markdown","1aebb5a2":"markdown","f74c7d37":"markdown","64b88c11":"markdown","bc703c2e":"markdown","62e68002":"markdown","abcc43a2":"markdown","e1ccb883":"markdown","2cc538a3":"markdown","70f91d2d":"markdown","20bd82f3":"markdown","e1b204b3":"markdown","685784a6":"markdown","cc7c041a":"markdown","a904bcc7":"markdown","04f250ce":"markdown","283519d4":"markdown","2a866d7a":"markdown","6ceea4ea":"markdown","cae24cc8":"markdown"},"source":{"9f47f46d":"from IPython.display import Image\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport numpy as np\nfrom matplotlib import cm\nfrom sklearn.metrics import silhouette_samples\nimport pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.datasets import make_moons\nfrom sklearn.cluster import DBSCAN\n\nprint(\"Imports done\")","81945d99":"X, y = make_blobs(n_samples=150, \n                  n_features=2, \n                  centers=3, \n                  cluster_std=0.5, \n                  shuffle=True, \n                  random_state=0)","9f1915b7":"plt.scatter(X[:, 0], X[:, 1], \n            c='white', marker='o', edgecolor='black', s=50)\nplt.grid()\nplt.tight_layout()\nplt.show()\n# See saved image:\n# Image(filename='..\/input\/11_01.png', width=400)","c95cbdb9":"km = KMeans(n_clusters=3, \n            init='random', \n            n_init=10, \n            max_iter=300,\n            tol=1e-04,\n            random_state=0)\n\ny_km = km.fit_predict(X)","d971a5f7":"plt.scatter(X[y_km == 0, 0],\n            X[y_km == 0, 1],\n            s=50, c='lightgreen',\n            marker='s', edgecolor='black',\n            label='cluster 1')\nplt.scatter(X[y_km == 1, 0],\n            X[y_km == 1, 1],\n            s=50, c='orange',\n            marker='o', edgecolor='black',\n            label='cluster 2')\nplt.scatter(X[y_km == 2, 0],\n            X[y_km == 2, 1],\n            s=50, c='lightblue',\n            marker='v', edgecolor='black',\n            label='cluster 3')\nplt.scatter(km.cluster_centers_[:, 0],\n            km.cluster_centers_[:, 1],\n            s=250, marker='*',\n            c='red', edgecolor='black',\n            label='centroids')\nplt.legend(scatterpoints=1)\nplt.grid()\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_02.png', width=400)","d9fd039b":"print('Distortion: %.2f' % km.inertia_)","0dd878d5":"distortions = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters=i, \n                init='k-means++', \n                n_init=10, \n                max_iter=300, \n                random_state=0)\n    km.fit(X)\n    distortions.append(km.inertia_)\nplt.plot(range(1, 11), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_03.png', width=400)","59bd4b2b":"km = KMeans(n_clusters=3, \n            init='k-means++', \n            n_init=10, \n            max_iter=300,\n            tol=1e-04,\n            random_state=0)\ny_km = km.fit_predict(X)\n\ncluster_labels = np.unique(y_km)\nn_clusters = cluster_labels.shape[0]\nsilhouette_vals = silhouette_samples(X, y_km, metric='euclidean')\ny_ax_lower, y_ax_upper = 0, 0\nyticks = []\nfor i, c in enumerate(cluster_labels):\n    c_silhouette_vals = silhouette_vals[y_km == c]\n    c_silhouette_vals.sort()\n    y_ax_upper += len(c_silhouette_vals)\n    color = cm.jet(float(i) \/ n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n             edgecolor='none', color=color)\n\n    yticks.append((y_ax_lower + y_ax_upper) \/ 2.)\n    y_ax_lower += len(c_silhouette_vals)\n    \nsilhouette_avg = np.mean(silhouette_vals)\nplt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n\nplt.yticks(yticks, cluster_labels + 1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\n\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_04.png', width=400)","6251e6bb":"km = KMeans(n_clusters=2,\n            init='k-means++',\n            n_init=10,\n            max_iter=300,\n            tol=1e-04,\n            random_state=0)\ny_km = km.fit_predict(X)\n\nplt.scatter(X[y_km == 0, 0],\n            X[y_km == 0, 1],\n            s=50,\n            c='lightgreen',\n            edgecolor='black',\n            marker='s',\n            label='cluster 1')\nplt.scatter(X[y_km == 1, 0],\n            X[y_km == 1, 1],\n            s=50,\n            c='orange',\n            edgecolor='black',\n            marker='o',\n            label='cluster 2')\n\nplt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n            s=250, marker='*', c='red', label='centroids')\nplt.legend()\nplt.grid()\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_05.png', width=400)","25cca57b":"cluster_labels = np.unique(y_km)\nn_clusters = cluster_labels.shape[0]\nsilhouette_vals = silhouette_samples(X, y_km, metric='euclidean')\ny_ax_lower, y_ax_upper = 0, 0\nyticks = []\nfor i, c in enumerate(cluster_labels):\n    c_silhouette_vals = silhouette_vals[y_km == c]\n    c_silhouette_vals.sort()\n    y_ax_upper += len(c_silhouette_vals)\n    color = cm.jet(float(i) \/ n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n             edgecolor='none', color=color)\n\n    yticks.append((y_ax_lower + y_ax_upper) \/ 2.)\n    y_ax_lower += len(c_silhouette_vals)\n    \nsilhouette_avg = np.mean(silhouette_vals)\nplt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n\nplt.yticks(yticks, cluster_labels + 1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\n\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_06.png', width=400)","fab68aa0":"Image(filename='..\/input\/11_05.png', width=400)","f1c5e40a":"np.random.seed(123)\n\nvariables = ['X', 'Y', 'Z']\nlabels = ['ID_0', 'ID_1', 'ID_2', 'ID_3', 'ID_4']\n\nX = np.random.random_sample([5, 3])*10\ndf = pd.DataFrame(X, columns=variables, index=labels)\ndf","94e390cb":"row_dist = pd.DataFrame(squareform(pdist(df, metric='euclidean')),\n                        columns=labels,\n                        index=labels)\nrow_dist","4533a31b":"# 1. incorrect approach: Squareform distance matrix\n# Should give ClusterWarning\n\nrow_clusters = linkage(row_dist, method='complete', metric='euclidean')\npd.DataFrame(row_clusters,\n             columns=['row label 1', 'row label 2',\n                      'distance', 'no. of items in clust.'],\n             index=['cluster %d' % (i + 1)\n                    for i in range(row_clusters.shape[0])])","4e663805":"# 2. correct approach: Condensed distance matrix\n\nrow_clusters = linkage(pdist(df, metric='euclidean'), method='complete')\npd.DataFrame(row_clusters,\n             columns=['row label 1', 'row label 2',\n                      'distance', 'no. of items in clust.'],\n             index=['cluster %d' % (i + 1) \n                    for i in range(row_clusters.shape[0])])","d4695cf3":"# 3. correct approach: Input sample matrix\n\nrow_clusters = linkage(df.values, method='complete', metric='euclidean')\npd.DataFrame(row_clusters,\n             columns=['row label 1', 'row label 2',\n                      'distance', 'no. of items in clust.'],\n             index=['cluster %d' % (i + 1)\n                    for i in range(row_clusters.shape[0])])","e776d35c":"# make dendrogram black (part 1\/2)\n# from scipy.cluster.hierarchy import set_link_color_palette\n# set_link_color_palette(['black'])\n\nrow_dendr = dendrogram(row_clusters, \n                       labels=labels,\n                       # make dendrogram black (part 2\/2)\n                       # color_threshold=np.inf\n                       )\nplt.tight_layout()\nplt.ylabel('Euclidean distance')\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_11.png', width=400)","7c7341ab":"# plot row dendrogram\nfig = plt.figure(figsize=(8, 8), facecolor='white')\naxd = fig.add_axes([0.09, 0.1, 0.2, 0.6])\n\n# note: for matplotlib < v1.5.1, please use orientation='right'\nrow_dendr = dendrogram(row_clusters, orientation='left')\n\n# reorder data with respect to clustering\ndf_rowclust = df.iloc[row_dendr['leaves'][::-1]]\n\naxd.set_xticks([])\naxd.set_yticks([])\n\n# remove axes spines from dendrogram\nfor i in axd.spines.values():\n    i.set_visible(False)\n\n# plot heatmap\naxm = fig.add_axes([0.23, 0.1, 0.6, 0.6])  # x-pos, y-pos, width, height\ncax = axm.matshow(df_rowclust, interpolation='nearest', cmap='hot_r')\nfig.colorbar(cax)\naxm.set_xticklabels([''] + list(df_rowclust.columns))\naxm.set_yticklabels([''] + list(df_rowclust.index))\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_12.png', width=400)","ca444393":"ac = AgglomerativeClustering(n_clusters=3, \n                             affinity='euclidean', \n                             linkage='complete')\nlabels = ac.fit_predict(X)\nprint('Cluster labels: %s' % labels)","af01293b":"ac = AgglomerativeClustering(n_clusters=2, \n                             affinity='euclidean', \n                             linkage='complete')\nlabels = ac.fit_predict(X)\nprint('Cluster labels: %s' % labels)","e5b94312":"Image(filename='..\/input\/11_13.png', width=500) ","6541006a":"from sklearn.datasets import make_moons\n\nX, y = make_moons(n_samples=200, noise=0.05, random_state=0)\nplt.scatter(X[:, 0], X[:, 1])\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_14.png', width=500) ","8cbfce3c":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n\nkm = KMeans(n_clusters=2, random_state=0)\ny_km = km.fit_predict(X)\nax1.scatter(X[y_km == 0, 0], X[y_km == 0, 1],\n            edgecolor='black',\n            c='lightblue', marker='o', s=40, label='cluster 1')\nax1.scatter(X[y_km == 1, 0], X[y_km == 1, 1],\n            edgecolor='black',\n            c='red', marker='s', s=40, label='cluster 2')\nax1.set_title('K-means clustering')\n\nac = AgglomerativeClustering(n_clusters=2,\n                             affinity='euclidean',\n                             linkage='complete')\ny_ac = ac.fit_predict(X)\nax2.scatter(X[y_ac == 0, 0], X[y_ac == 0, 1], c='lightblue',\n            edgecolor='black',\n            marker='o', s=40, label='cluster 1')\nax2.scatter(X[y_ac == 1, 0], X[y_ac == 1, 1], c='red',\n            edgecolor='black',\n            marker='s', s=40, label='cluster 2')\nax2.set_title('Agglomerative clustering')\n\nplt.legend()\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_15.png', width=500) ","30a5d80f":"from sklearn.cluster import DBSCAN\n\ndb = DBSCAN(eps=0.2, min_samples=5, metric='euclidean')\ny_db = db.fit_predict(X)\nplt.scatter(X[y_db == 0, 0], X[y_db == 0, 1],\n            c='lightblue', marker='o', s=40,\n            edgecolor='black', \n            label='cluster 1')\nplt.scatter(X[y_db == 1, 0], X[y_db == 1, 1],\n            c='red', marker='s', s=40,\n            edgecolor='black', \n            label='cluster 2')\nplt.legend()\nplt.tight_layout()\n\nplt.show()\n\n# See saved image:\n# Image(filename='..\/input\/11_16.png', width=500) ","55229d7e":"## Using the elbow method to find the optimal number of clusters ","d6949177":"<br>\n<br>","5be2262d":"- [Grouping objects by similarity using k-means](#Grouping-objects-by-similarity-using-k-means)\n  - [K-means clustering using scikit-learn](#K-means-clustering-using-scikit-learn)\n  - [Using the elbow method to find the optimal number of clusters](#Using-the-elbow-method-to-find-the-optimal-number-of-clusters)\n  - [Quantifying the quality of clustering via silhouette plots](#Quantifying-the-quality-of-clustering-via-silhouette-plots)\n- [Organizing clusters as a hierarchical tree](#Organizing-clusters-as-a-hierarchical-tree)\n  - [Grouping clusters in bottom-up fashion](#Grouping-clusters-in-bottom-up-fashion)\n  - [Performing hierarchical clustering on a distance matrix](#Performing-hierarchical-clustering-on-a-distance-matrix)\n  - [Attaching dendrograms to a heat map](#Attaching-dendrograms-to-a-heat-map)\n  - [Applying agglomerative clustering via scikit-learn](#Applying-agglomerative-clustering-via-scikit-learn)\n- [Locating regions of high density via DBSCAN](#Locating-regions-of-high-density-via-DBSCAN)","8117664e":"# Python Machine Learning - Code Examples","352933bd":"We can either pass a condensed distance matrix (upper triangular) from the `pdist` function, or we can pass the \"original\" data array and define the `metric='euclidean'` argument in `linkage`. However, we should not pass the squareform distance matrix, which would yield different distance values although the overall clustering could be the same.","6ed19bca":"## Applying agglomerative clustering via scikit-learn","1d72cfb4":"## Grouping clusters in bottom-up fashion","1aebb5a2":"K-means and hierarchical clustering:","f74c7d37":"## Attaching dendrograms to a heat map","64b88c11":"*Python Machine Learning 2nd Edition* by [Sebastian Raschka](https:\/\/sebastianraschka.com), Packt Publishing Ltd. 2017\n\nCode Repository: https:\/\/github.com\/rasbt\/python-machine-learning-book-2nd-edition\n\nCode License: [MIT License](https:\/\/github.com\/rasbt\/python-machine-learning-book-2nd-edition\/blob\/master\/LICENSE.txt)","bc703c2e":"### Overview","62e68002":"## K-means clustering using scikit-learn","abcc43a2":"# Grouping objects by similarity using k-means","e1ccb883":"## Quantifying the quality of clustering  via silhouette plots","2cc538a3":"<br>","70f91d2d":"<br>","20bd82f3":"# Locating regions of high density via DBSCAN","e1b204b3":"<br>\n<br>","685784a6":"## Performing hierarchical clustering on a distance matrix","cc7c041a":"<br>","a904bcc7":"# Organizing clusters as a hierarchical tree","04f250ce":"Density-based clustering:","283519d4":"<br>\n<br>","2a866d7a":"# Chapter 11 - Working with Unlabeled Data \u2013 Clustering Analysis","6ceea4ea":"Comparison to \"bad\" clustering:","cae24cc8":"<br>"}}