{"cell_type":{"590dd102":"code","16c1e534":"code","75232266":"code","f780cafa":"code","04e8148a":"code","73b4d969":"code","35f464ec":"code","1c3429fa":"code","18741bce":"code","5e890bfb":"code","fa5171b2":"code","973e5ad8":"code","d890496b":"code","002c57c7":"code","0de97761":"code","1c974ff5":"code","f738254b":"code","3e26dee2":"code","f99add87":"markdown","ba6058fe":"markdown","d3613d62":"markdown","f9b3ff1b":"markdown","1e7a9e5f":"markdown","b7ee8daf":"markdown","e3c9c906":"markdown"},"source":{"590dd102":"import tarfile\nimport zipfile\nimport json\nimport os, shutil\nimport pandas as pd\nfrom tqdm import tqdm","16c1e534":"def preprocess(dataset, tier):\n    num_exs = 0 \n    examples = []\n\n    for articles_id in tqdm(range(len(dataset['data'])), desc=\"Preprocessing {}\".format(tier)):\n        article_paragraphs = dataset['data'][articles_id]['paragraphs']\n        for pid in range(len(article_paragraphs)):\n            context = article_paragraphs[pid]['context']\n            context = context.replace(\"''\", '\" ')\n            context = context.replace(\"``\", '\" ')\n            qas = article_paragraphs[pid]['qas'] \n            for qn in qas:\n                question = qn['question'] \n                ans_text = qn['answers'][0]['text']\n                ans_start_charloc = qn['answers'][0]['answer_start']\n                ans_end_charloc = ans_start_charloc + len(ans_text)\n                examples.append(\n                    {\n                        'context':context, \n                        'question':question, \n                        'answer_text':ans_text, \n                        'answer_start':ans_start_charloc, \n                    }\n                )\n\n                num_exs += 1\n    print(num_exs)    \n    return examples","75232266":"# !wget https:\/\/thunlp.s3-us-west-1.amazonaws.com\/data_XQA.tar.gz","f780cafa":"# xqa_file = r'\/kaggle\/working\/data_XQA.tar.gz'\n# with tarfile.open(xqa_file, \"r\") as tar_file:\n#     tar_file.extractall()","04e8148a":"# xqa_train_json_data = '\/kaggle\/working\/data\/ta\/dev_doc.json'\n# xqa_test_json_data = '\/kaggle\/working\/data\/ta\/test_doc.json'\n# xqa_train_txt_data = '\/kaggle\/working\/data\/ta\/dev.txt'\n# xqa_test_txt_data = '\/kaggle\/working\/data\/ta\/test.txt'\n\n# train_file_xqa = [json.loads(line) for line in open(xqa_train_json_data, 'r')]\n# test_file_xqa = [json.loads(line) for line in open(xqa_test_json_data, 'r')]","73b4d969":"# examples_train_xqa = preprocess(train_file_xqa, 'dev')\n# examples_test_xqa = preprocess(test_file_xqa, 'test')","35f464ec":"# examples_xqa = examples_train_xqa + examples_test_xqa\n# xqa = pd.DataFrame(examples_xqa)\n# xqa['language'] = 'tamil'","1c3429fa":"!wget https:\/\/dl.fbaipublicfiles.com\/MLQA\/MLQA_V1.zip","18741bce":"mlqa_file = r'\/kaggle\/working\/MLQA_V1.zip'\nwith zipfile.ZipFile(mlqa_file) as zip_ref:\n    zip_ref.extractall('\/kaggle\/working\/')","5e890bfb":"mlqa_train_data = '\/kaggle\/working\/MLQA_V1\/dev\/dev-context-hi-question-hi.json'\nmlqa_test_data = '\/kaggle\/working\/MLQA_V1\/test\/test-context-hi-question-hi.json'\n\nwith open(mlqa_train_data, 'r') as file_input:\n    train_file_mlqa = json.load(file_input)\n    \nwith open(mlqa_test_data, 'r') as file_input:\n    test_file_mlqa = json.load(file_input)","fa5171b2":"examples_train_mlqa = preprocess(train_file_mlqa, 'dev')\nexamples_test_mlqa = preprocess(test_file_mlqa, 'test')","973e5ad8":"examples_mlqa = examples_train_mlqa + examples_test_mlqa\nmlqa = pd.DataFrame(examples_mlqa)\nmlqa['language'] = 'hindi'","d890496b":"!git clone https:\/\/github.com\/deepmind\/xquad.git","002c57c7":"xquad_train_file = '\/kaggle\/working\/xquad\/xquad.hi.json'\n\nwith open(xquad_train_file, 'r') as file_input:\n    train_file = json.load(file_input)\n    \nexamples_train = preprocess(train_file, 'dev')\nxquad = pd.DataFrame(examples_train)\nxquad['language'] = 'hindi'","0de97761":"folder = '\/kaggle\/working\/'\nfor filename in os.listdir(folder):\n    file_path = os.path.join(folder, filename)\n    try:\n        if os.path.isfile(file_path) or os.path.islink(file_path):\n            os.unlink(file_path)\n        elif os.path.isdir(file_path):\n            shutil.rmtree(file_path)\n    except Exception as e:\n        print('Failed to delete %s. Reason: %s' % (file_path, e))","1c974ff5":"# xqa.to_csv('xqa_tamil.csv', index=False)\nmlqa.to_csv('mlqa_hindi.csv', index=False)\nxquad.to_csv('xquad_hindi.csv', index=False)","f738254b":"mlqa.head()","3e26dee2":"xquad.head()","f99add87":"## Remove Downloaded files","ba6058fe":"## Importing relevant Modules & Setting up pre-processor function","d3613d62":"## Create CSV formats for respective datasets","f9b3ff1b":"# chaii - Dataset Extension\nThis notebook is intended to help you download 3 datasets from their sources and utilize them to extend the relevant dataset for chaii competition. \nHowever, these 3 sources are only intended to extend the QA dataset for Hindi Language and are mentioned below:\n1. XQA <br>\nHomepage Link: https:\/\/github.com\/thunlp\/XQA <br>\nDownloading Link: https:\/\/thunlp.s3-us-west-1.amazonaws.com\/data_XQA.tar.gz <br>\n\n## XQA is still under process and will be updated once completed with a newer version of this notebook\n\n2. MLQA <br>\nHomepage Link: https:\/\/github.com\/facebookresearch\/MLQA <br>\nDownloading Link: https:\/\/dl.fbaipublicfiles.com\/MLQA\/MLQA_V1.zip <br>\n\n3. XQUAD: <br>\nHompage Link: https:\/\/github.com\/deepmind\/xquad <br>\nDownlaoding Link: https:\/\/github.com\/deepmind\/xquad.git <br>\n\nOnce these datasets are downloaded, we will try to preprocess these to utilize them for chaii pretraining part kernels.","1e7a9e5f":"## Downloading MLQA dataset and expanding its files","b7ee8daf":"## Downloading XQUAD dataset and expanding its files","e3c9c906":"## Downlaoding XQA dataset and expanding its files\nCommented for now, will be re-evaluated once the dataset understanding is completed"}}