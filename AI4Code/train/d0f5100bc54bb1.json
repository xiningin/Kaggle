{"cell_type":{"f7c72aaa":"code","e3380986":"code","995e48e7":"code","57cd2a04":"code","7a88daa4":"code","73d1126e":"code","ef53b8ec":"code","72d34c1d":"code","2615624e":"code","f6530ee3":"code","7d45cf64":"code","6a177ad6":"code","d4260388":"code","59e9b5b2":"code","a35d69dd":"code","ff37012f":"code","018b566e":"code","1116cc45":"code","561380d2":"code","8565604f":"code","0219eee3":"code","3fa7538d":"code","a7bae7c6":"code","fe34c357":"code","91bb42e7":"code","f802d891":"code","a69aa128":"code","5d9267fd":"code","22df5a21":"code","97ab9700":"code","4a668e92":"code","072c8a51":"code","646e6a15":"code","9ba6a7ad":"code","e4b29432":"code","bad42fa8":"code","ceff333a":"code","c20c800d":"code","5f9295d9":"code","bf76bff5":"code","b13cdf08":"code","cf904e2f":"code","076b5ef1":"code","a9e07446":"code","bf6d70a0":"code","e0ff83fc":"code","bc8febbc":"code","76f73984":"code","bb4c38ac":"code","0ad6f890":"code","db037e49":"code","cbfced9f":"code","a63d090a":"code","72807049":"code","bf84a6e8":"code","a97d4c1a":"code","fdf86213":"code","46423e64":"code","36eccfa9":"code","62952258":"code","5d4e9ff3":"code","50588d4f":"code","3ca94ea9":"code","9cf18d78":"code","74555b99":"code","b2df528c":"code","5018b9be":"code","6d3332cd":"markdown","914c3ff1":"markdown","d5305f27":"markdown","4db997c5":"markdown","fc32e34a":"markdown","e2847aae":"markdown","81ed5a5b":"markdown","46bbbd3d":"markdown","682283df":"markdown","f121d6aa":"markdown","8c83aad9":"markdown","b76337e7":"markdown","fbf500a7":"markdown","e285a445":"markdown","6c23379a":"markdown","8307432b":"markdown","d0d16021":"markdown","8a4c8823":"markdown","e0ea0329":"markdown","e210ce2a":"markdown","1fccbdfa":"markdown","62b41e6c":"markdown","4591d6be":"markdown","8bf0fda1":"markdown","1d32f8d1":"markdown","ff50471f":"markdown","476ff2a4":"markdown","ddd85a39":"markdown","7dfd4536":"markdown","9be983bf":"markdown","56c61aae":"markdown"},"source":{"f7c72aaa":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e3380986":"# import datasets\ndf_train = pd.read_csv(\"..\/input\/train.csv\") \ndf_test = pd.read_csv(\"..\/input\/test.csv\") \n\n# view first five lines of training data\ndf_train.head()","995e48e7":"df_test.head()","57cd2a04":"df_train.info()","7a88daa4":"df_train.describe()","73d1126e":"# plot of count(Survived)\nsns.countplot(x=\"Survived\", data=df_train)\nplt.show()","ef53b8ec":"no_survived = pd.Series([0] * df_test.shape[0])","72d34c1d":"out = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': no_survived})","2615624e":"out.to_csv('no_survival.csv', index=False)","f6530ee3":"# plot count of male and female on titanic\nsns.countplot(x=\"Sex\", data=df_train);","7d45cf64":"sns.countplot(x=\"Survived\", hue='Sex', data=df_train);","6a177ad6":"sns.catplot(x=\"Survived\", col=\"Sex\", kind=\"count\", data=df_train);","d4260388":"df_train.groupby(['Sex']).Survived.sum()","59e9b5b2":"df_train.groupby([\"Sex\"]).Survived.value_counts()","a35d69dd":"print(df_train[df_train[\"Sex\"]==\"female\"].Survived.sum() \/ df_train[df_train[\"Sex\"]==\"female\"].shape[0]) \n# print(df_train[df_train[\"Sex\"]==\"female\"].Survived.sum() \/ df_train[df_train[\"Sex\"]==\"female\"].count()) \nprint(df_train[df_train[\"Sex\"]==\"male\"].Survived.sum() \/ df_train[df_train[\"Sex\"]==\"male\"].shape[0]) ","ff37012f":"women_survived_series = pd.Series(list(map(int, df_test[\"Sex\"]==\"female\")))","018b566e":"out = pd.DataFrame({\"PassengerId\": df_test.PassengerId, \"Survived\": women_survived_series})\nout.to_csv('all_women_survived.csv', index=False)","1116cc45":"sns.catplot(x=\"Survived\", col=\"Pclass\", kind=\"count\", data=df_train);","561380d2":"sns.catplot(x=\"Survived\", col=\"Pclass\", kind=\"count\", hue=\"Sex\", data=df_train);","8565604f":"print(df_train.groupby(\"Pclass\").Survived.sum() \/ df_train.groupby(\"Pclass\").Survived.count())","0219eee3":"sns.catplot(x=\"Survived\", col=\"Embarked\", kind=\"count\", data=df_train);","3fa7538d":"#sns.catplot(x=\"Embarked\", col=\"Survived\", kind=\"count\", data=df_train);","a7bae7c6":"print(df_train.groupby(\"Embarked\").Survived.sum() \/ df_train.groupby(\"Embarked\").Survived.count())","fe34c357":"sns.catplot(x=\"Survived\", col=\"Embarked\", hue=\"Pclass\", kind=\"count\", data=df_train);","91bb42e7":"# df_train.groupby(\"Embarked\").Survived.sum()  # shows number of people survived from each embarked point\n# df_train.groupby(\"Embarked\").Survived.count() # shows number of poeple embarked form each port","f802d891":"plt.figure(figsize=(18, 8))\nsns.distplot(a=df_train.Fare, kde=False);","a69aa128":"# Use a pandas plotting method to plot the column 'Fare' for each value of 'Survived' on the same plot.\ndf_train.groupby('Survived').Fare.hist(alpha=0.5);","5d9267fd":"df_train_drop = df_train.Age.dropna()\nplt.figure(figsize=(18, 8))\nsns.distplot(a=df_train_drop, kde=False);","22df5a21":"sns.stripplot(x=\"Survived\", y=\"Fare\", data=df_train);","97ab9700":"sns.swarmplot(x=\"Survived\", y=\"Fare\", data=df_train);","4a668e92":"df_train.Fare.describe()","072c8a51":"# Use the DataFrame method .describe() to check out summary statistics of 'Fare' as a function of survival.\ndf_train.groupby('Survived').Fare.describe()","646e6a15":"sns.scatterplot(x=\"Age\", y=\"Fare\", hue=\"Survived\", data=df_train, alpha=0.5);","9ba6a7ad":"sns.pairplot(data=df_train, hue=\"Survived\");","e4b29432":"# Import modules\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# Figures inline and set visualization style\n%matplotlib inline\nsns.set()\n\n# Import data\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","bad42fa8":"# target variable\nsurvived_train = df_train.Survived\n# concatenate train and test set (to perform same data manipulation on both datasets)\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])","ceff333a":"data.info()","c20c800d":"data['Age'] = data.Age.fillna(data.Age.median())\ndata['Fare'] = data.Fare.fillna(data.Fare.median())\ndata.info()","5f9295d9":"data = pd.get_dummies(data, columns=[\"Sex\"], drop_first=True)\ndata.head()","bf76bff5":"data = data[[\"Pclass\", \"Age\", \"SibSp\", \"Fare\", \"Sex_male\"]]\ndata.head()","b13cdf08":"data_train = data.iloc[:891]\ndata_test = data.iloc[891:]","cf904e2f":"X = data_train.values\ntest = data_test.values\ny = survived_train.values","076b5ef1":"clf = tree.DecisionTreeClassifier(max_depth=3)\nclf.fit(X, y)","a9e07446":"Y_pred = clf.predict(test)\nout = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': Y_pred})","bf6d70a0":"out.to_csv('DecisionTree3.csv', index=False)","e0ff83fc":"# plt.figure(figsize=(10, 10))\n# tree.plot_tree(clf.fit(X, y));","bc8febbc":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42, stratify=y)","76f73984":"# Setup arrays to store train and test accuracies\ndep = np.arange(1, 9)\ntrain_accuracy = np.empty(len(dep))\ntest_accuracy = np.empty(len(dep))\n\n# Loop over different values of k\nfor i, k in enumerate(dep):\n    # Setup a k-NN Classifier with k neighbors: knn\n    clf = tree.DecisionTreeClassifier(max_depth=k)\n\n    # Fit the classifier to the training data\n    clf.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = clf.score(X_train, y_train)\n\n    #Compute accuracy on the testing set\n    test_accuracy[i] = clf.score(X_test, y_test)\n\n# Generate plot\nplt.title('clf: Varying depth of tree')\nplt.plot(dep, test_accuracy, label = 'Testing Accuracy')\nplt.plot(dep, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Depth of tree')\nplt.ylabel('Accuracy')\nplt.show()","bb4c38ac":"# Imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import GridSearchCV\n\n# Figures inline and set visualization style\n%matplotlib inline\nsns.set()\n\n# Import data\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\n\n# Store target variable of training data in a safe place\nsurvived_train = df_train.Survived\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\n\n# View head\ndata.head()","0ad6f890":"data.Name.head()","db037e49":"data.Name.tail()","cbfced9f":"data['Title'] = data.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\nsns.countplot(data.Title)\nplt.xticks(rotation=90);","a63d090a":"data['Title'] = data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\ndata['Title'] = data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr',\n                                            'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\nsns.countplot(x='Title', data=data);\nplt.xticks(rotation=90);","72807049":"data[data.Cabin.isnull()].Fare.hist()","bf84a6e8":"data['hasCabin'] = ~data.Cabin.isnull()\ndata.head()","a97d4c1a":"# drop columns ['PassengerId', 'Name', 'Ticket', 'Cabin']\ndata.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\ndata.head()","fdf86213":"data.info()","46423e64":"data['Age'] = data.Age.fillna(data.Age.median())\ndata['Fare'] = data.Fare.fillna(data.Fare.median())\ndata['Embarked'] = data.Embarked.fillna('S')    # as most of passsengers embarked from Southampton\ndata.info()","36eccfa9":"data['CatAge'] = pd.qcut(data.Age, q=4, labels=False)\ndata['CatFare'] = pd.qcut(data.Fare, q=4, labels=False)\ndata.info()","62952258":"# Now we can drop 'Age' and 'Fare' column\ndata.drop(['Age', 'Fare'], axis=1, inplace=True)\ndata.head()","5d4e9ff3":"data['FamSize'] = data.SibSp + data.Parch\ndata.head()","50588d4f":"# drop 'SibSp' and 'Parch'\ndata.drop(['SibSp', 'Parch'], axis=1, inplace=True)\ndata.head()","3ca94ea9":"data_dum = pd.get_dummies(data, drop_first=True)\ndata_dum.head()","9cf18d78":"data_train = data_dum[:891]\ndata_test = data_dum[891:]\n\nX = data_train.values\ny = survived_train.values\ntest = data_test.values","74555b99":"# setup the hyperparameter grid\ndep = np.arange(1, 9)\nparam_grid = {'max_depth': dep}\n\nclf = tree.DecisionTreeClassifier()\nclf_cv = GridSearchCV(clf, param_grid=param_grid, cv=5)\nclf_cv.fit(X, y)\n\nprint(\"Tuned Decision Tree Parameters: {}\".format(clf_cv.best_params_))\nprint(\"Best score is {}\".format(clf_cv.best_score_))","b2df528c":"y_pred = clf_cv.predict(test)","5018b9be":"out = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': y_pred})\nout.to_csv('feature_engg4.csv', index=False)","6d3332cd":"About 74% of women survived and only 19% men survived.\n\nLet's build a model that predicts all womens survived and no male survived.","914c3ff1":"# 1","d5305f27":"Accuracy: ","4db997c5":"We have 2 numerical columns with missing values, so perform imputation","fc32e34a":"Port of Embarkation\n- C = Cherbourg\n- Q = Queenstown\n- S = Southampton","e2847aae":"**How to approach a supervised learning problem:**\n\n1. Do some EDA.\n2. Build a baseline model.\n3. Do more EDA.\n4. Engineer features.\n5. Build a better model.","81ed5a5b":"Binning","46bbbd3d":"- SibSp: Number of siblings or spouse onboard\n- Parch: Number of parents or children onboard\n\nSo we can create a new feature 'Fam_Size' and drop these two colunns","682283df":"Now we need to convert non numerical columns to numerical columns.","f121d6aa":"- Three passengers with fare greater than 300 (`Fare=512.3292`), and all of them survived.\n- About 340 passengers paid less than 10\\$\n- Very few passengers with fare more than 50\\$","8c83aad9":"# 2","b76337e7":"Accuracy: 76.5%","fbf500a7":"- People with `Pclass=1` are more likely to survive i.e. rich people\n- Very very few females did not survive in `Pclass=1` and `Pclass=2` whereas about 50% female did not survive in `Pclass=3`\n","e285a445":"More than 500 people didn't survive.\n\nA few over 300 people survived.\n\nSo, we will predict that nobody survived as base model.","6c23379a":"# 3","8307432b":"- Those who survived and paid low fare were more likely to be children.","d0d16021":"There are more than 575 male and a little over 300 females, so let's check survival according to gender.","8a4c8823":"# 4","e0ea0329":"- About 63% people survived in `Pclass=1`\n- About 47% people survived in `Pclass=2`\n- About 24% people survived in `Pclass=2`","e210ce2a":"We can see out of 300 female passengers, more than 200 survived whereas out of 600 male passengers about 100 survived.\n\n**Take Away:** Women were more likely to survive than men.","1fccbdfa":"# 3","62b41e6c":"**EDA with numerical variables**","4591d6be":"We have missing values in columns `['Age', 'Fare', 'Embarked']`. Now we need to impute these missing values before we can proceed further","8bf0fda1":"Several NaN values in `Cabin`. This may suggest those people didn't have a Cabin because it is NaN for those who paid low fare as shown in plot above. \n\nSo we can create a new feature `hasCabin` showing whether they had cabin or not.","1d32f8d1":"- Most of the passengers are young","ff50471f":"Build model","476ff2a4":"- Those who embarked from `C` had greater chances of survival (55%). \n- Q (39%)\n- S (33%)","ddd85a39":"Accuracy: 76.5%\n\nAccuracy: 78% (2nd time due to random initialization)","7dfd4536":"- Those who paid more had more chances of survival.","9be983bf":"we can extract titles from Name column to create a new feature","56c61aae":"Accuracy: 62.7"}}