{"cell_type":{"a7b8f987":"code","6abe6125":"code","cd287896":"code","ff203aff":"code","73a296f5":"code","a32f5c23":"code","4ce458fb":"code","4a81fadb":"code","a722da62":"code","f6b9e25b":"code","3eec012a":"code","1658a165":"code","d9734132":"code","c1177f73":"code","55e33248":"markdown","82cf3a6f":"markdown","16873979":"markdown","78d70e79":"markdown","2ba1de4a":"markdown","b882dbf9":"markdown","e2d7d632":"markdown","99b36dac":"markdown","46f010f2":"markdown","fe901bba":"markdown","e9034ed5":"markdown"},"source":{"a7b8f987":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6abe6125":"import pandas as pd \n\ndf = pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv')\ndf.head()","cd287896":"df['dx'].unique()","ff203aff":"import matplotlib.pyplot as plt\n#exp = pd.Series.to_frame(df1.groupby('dx').sex.value_counts())\ndf['dx'].value_counts().plot.bar(rot=0)\nplt.title('Number of images for different dx type')\nplt.xlabel('dx')\nplt.ylabel('Counts')\nplt.grid(axis='y')","73a296f5":"from os.path import isfile\nfrom PIL import Image as pil_image\ndf['num_images'] = df.groupby('lesion_id')[\"image_id\"].transform(\"count\")\n\nclasses = df['dx'].unique()\nlabeldict = {}\nfor num, name in enumerate(classes):\n    labeldict[name] = num\ndf['dx_id'] = df['dx'].map(lambda x: labeldict[x])\n\n\ndef expand_path(p):\n    if isfile('..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_1\/' + p + '.jpg'): return '..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_1\/' + p + '.jpg'\n    if isfile('..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_2\/' + p + '.jpg'): return '..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_2\/' + p + '.jpg'\n    return p \ndf['image_path'] = df['image_id']\ndf['image_path'] = df['image_path'].apply(expand_path)\n\n\ndf['images'] = df['image_path'].map(lambda x: np.asarray(pil_image.open(x).resize((150,112))))\ndf.head()","a32f5c23":"import matplotlib.pyplot as plt\n        \ndef plot_images(imgs, labels, cols=4):\n    # Set figure to 13 inches x 8 inches\n    figure = plt.figure(figsize=(10, 7))\n\n    rows = len(imgs) \/\/ cols + 1\n\n    for i in range(len(imgs)):\n        img = plt.imread(expand_path(imgs[i]))\n        subplot = figure.add_subplot(rows, cols, i + 1)\n        subplot.axis('Off')\n        if labels:\n            subplot.set_title(labels[i], fontsize=16)\n        plt.imshow(img, cmap='gray')        \n\nimages = df[df['lesion_id'] == 'HAM_0003033'].image_id\n\nplot_images(list(images),list(images))","4ce458fb":"imgdict = {'akiec':list(df[df['dx']=='akiec']['image_id'])[0:24:6],'bcc':list(df[df['dx']=='bcc']['image_id'])[0:24:6],\\\n        'bkl':list(df[df['dx']=='bkl']['image_id'])[0:24:6],'df':list(df[df['dx']=='df']['image_id'])[0:24:6],\\\n        'mel':list(df[df['dx']=='mel']['image_id'])[0:24:6],'nv':list(df[df['dx']=='nv']['image_id'])[0:24:6],\\\n        'vasc':list(df[df['dx']=='vasc']['image_id'])[0:24:6]}\n#print(imgdict,'\\n',list(imgdict.values()),list(imgdict.keys()))\nfor i in np.arange(7):\n    cancertype = list(imgdict.keys())[i]\n    cancertypetolist = [cancertype,cancertype,cancertype,cancertype]\n    plot_images(list(imgdict.values())[i],cancertypetolist)\n","4a81fadb":"from sklearn.model_selection import train_test_split\n\ndf_single = df[df['num_images'] == 1]\ntrainset1, testset = train_test_split(df_single, test_size=0.2,random_state = 50)\ntrainset2, validationset = train_test_split(trainset1, test_size=0.2,random_state = 100)\ntrainset3 = df[df['num_images'] != 1]\nframes = [trainset2, trainset3]\ntrainset = pd.concat(frames)\n\ntrainimages = np.asarray(list(trainset['images']\/255))\ntestimages = np.asarray(list(testset['images']\/255))\nvalidationimages = np.asarray(list(validationset['images']\/255))\ntrainlabels = np.asarray(trainset['dx_id'])\ntestlabels = np.asarray(testset['dx_id'])\nvalidationlabels = np.asarray(validationset['dx_id'])\n","a722da62":"from keras.preprocessing.image import ImageDataGenerator\n\ntrainimages = trainimages.reshape(trainimages.shape[0], *(112, 150, 3))\n\ndata_gen = ImageDataGenerator(\n        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1)  # randomly shift images vertically\n#x = imageLoader(trainset,batch_size)\ndata_gen.fit(trainimages)","f6b9e25b":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\n\ninput_shape = (112, 150, 3)\nnum_labels = 7\n\n# trainmodel includs four convolutional layers and three fully connected layers\n\ntrainmodel = Sequential()\ntrainmodel.add(Conv2D(32, (3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n#trainmodel.add(BatchNormalization())\ntrainmodel.add(MaxPool2D(pool_size = (2, 2)))\ntrainmodel.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\ntrainmodel.add(MaxPool2D(pool_size = (2, 2)))\ntrainmodel.add(Dropout(0.25))\ntrainmodel.add(Conv2D(128, (3, 3), activation='relu',padding = 'Same'))\ntrainmodel.add(MaxPool2D(pool_size = (2, 2)))\ntrainmodel.add(Conv2D(256, (3, 3), activation='relu',padding = 'Same'))\ntrainmodel.add(MaxPool2D(pool_size=(2, 2)))\ntrainmodel.add(Dropout(0.5))\n\ntrainmodel.add(Flatten())\ntrainmodel.add(Dense(504, activation='relu'))\ntrainmodel.add(Dropout(0.5))\ntrainmodel.add(Dense(63, activation='relu'))\ntrainmodel.add(Dense(num_labels, activation='softmax'))\ntrainmodel.summary()","3eec012a":"from keras.optimizers import Adam\noptimizer = Adam(lr=0.001)\ntrainmodel.compile(optimizer = optimizer , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","1658a165":"# Fit the model\nimport keras\n\nclass CustomModelCheckPoint(keras.callbacks.Callback):\n    def __init__(self,**kargs):\n        super(CustomModelCheckPoint,self).__init__(**kargs)\n        self.epoch_accuracy = {} # loss at given epoch\n        self.epoch_loss = {} # accuracy at given epoch\n        def on_epoch_begin(self,epoch, logs={}):\n            # Things done on beginning of epoch. \n            return\n\n        def on_epoch_end(self, epoch, logs={}):\n            # things done on end of the epoch\n            self.epoch_accuracy[epoch] = logs.get(\"acc\")\n            self.epoch_loss[epoch] = logs.get(\"loss\")\n            self.model.save_weights(\"name-of-model-%d.h5\" %epoch)\n            \ncheckpoint = CustomModelCheckPoint()\n\nepochs = 30 \nbatch_size = 20\ntrainhistory = trainmodel.fit_generator(data_gen.flow(trainimages,trainlabels, batch_size=batch_size),\n                              epochs = epochs, validation_data = (validationimages,validationlabels),\n                              verbose = 1, steps_per_epoch=trainimages.shape[0] \/\/ batch_size,\n                                       callbacks=[checkpoint])","d9734132":"acc = trainhistory.history['acc']\nval_acc = trainhistory.history['val_acc']\nloss = trainhistory.history['loss']\nval_loss = trainhistory.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, '', label='Training loss')\nplt.plot(epochs, val_loss, '', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, '', label='Training accuracy')\nplt.plot(epochs, val_acc, '', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()","c1177f73":"test_loss, test_acc = trainmodel.evaluate(testimages, testlabels, verbose=1)\nprint(\"test_accuracy = %f  ;  test_loss = %f\" % (test_acc, test_loss))","55e33248":"select the testset and validationset from the lesion_id with only one corresponding image_id. It is reasonable to use such dataset in the test and validation step as these images have no similar sibling images","82cf3a6f":"# 4. Data augmentation","16873979":"# 1. Create several more columns for the dataframe 'df'","78d70e79":"# 6. Plot the accuracy and loss of both training and validation dataset","2ba1de4a":"### show images belonging to the same lesion_id","b882dbf9":"### Since there are not too many images belonging to each skin cancer type, it is better to augment data before training. Data augmentation includes rotation, zoom, shift in two directions","e2d7d632":"### show images belonging to the seven different types","99b36dac":"# 5. Build CNN model","46f010f2":"1. Create 'num_images' to record the number of images belonging to the same 'lesion_id'\n2. Create 'dx_id' convert the 'dx' to integer label\n3. Create 'image_path' to store the path to access the image\n4. Create 'images' to store the resized image as arrays","fe901bba":"# 2. show images","e9034ed5":"# 3. Split the dataframe and create train, test and validation images and labels"}}