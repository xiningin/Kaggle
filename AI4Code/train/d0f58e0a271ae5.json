{"cell_type":{"31dbbb30":"code","110cc828":"code","99bae369":"code","5cf88a1a":"code","35f19c3e":"code","a27340a9":"code","470acd04":"code","d9ea7c6f":"code","443cfef2":"code","49f6a64d":"code","42f1c13d":"code","0b81de6f":"markdown","65440c6f":"markdown","ee44d353":"markdown"},"source":{"31dbbb30":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport os\nimport sys\nimport skimage.io\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset","110cc828":"COMP_DIR = '..\/input\/prostate-cancer-grade-assessment'\ntrain_df = pd.read_csv(os.path.join(COMP_DIR, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(COMP_DIR, 'test.csv'))\nsub_df = pd.read_csv(os.path.join(COMP_DIR, 'sample_submission.csv'))","99bae369":"model_dir = '..\/input\/panda-public-models'\nimage_folder = os.path.join(COMP_DIR, 'test_images')\nis_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\n\nimage_folder = image_folder if is_test else os.path.join(COMP_DIR, 'train_images')\ndf = test_df if is_test else train_df.loc[:100]\n\nclass config:\n    SZ = 256\n    IMG_SIZE = 256\n    N = 36\n    BS = 8 # batch size\n    NUM_WORKERS = 4\n\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nprint(image_folder)","5cf88a1a":"def get_tiles(img, mode=0):\n    result = []\n    \n    h, w, c = img.shape\n    pad_h = (config.SZ - h % config.SZ) % config.SZ + ((config.SZ * mode) \/\/ 2)\n    pad_w = (config.SZ - w % config.SZ) % config.SZ + ((config.SZ * mode) \/\/ 2)\n\n    img2 = np.pad(img, [[pad_h \/\/ 2, pad_h - pad_h \/\/ 2], \n                        [pad_w \/\/ 2, pad_w - pad_w\/\/2], \n                        [0,0]], constant_values=255)\n    img3 = img2.reshape(\n        img2.shape[0] \/\/ config.SZ,\n        config.SZ,\n        img2.shape[1] \/\/ config.SZ,\n        config.SZ,\n        3\n    )\n    \n    img3 = img3.transpose(0, 2, 1, 3, 4).reshape(-1, config.SZ, config.SZ, 3) # (783, 256, 256, 3)\n\n    # all tile pixel < a piece of white\n    n_tiles_with_info = (img3.reshape(img3.shape[0], -1).sum(1) < config.SZ ** 2 * 3 * 255).sum() # number of having image\n    \n    # supplement\n    if len(img3) < config.N:\n        img3 = np.pad(img3, [ [0, config.N-len(img3)], [0,0],[0,0],[0,0]], constant_values=255)\n        \n    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:config.N]\n    img3 = img3[idxs]\n    for i in range(len(img3)):\n        result.append({'img':img3[i], 'idx':i})\n        \n    return result, n_tiles_with_info >= config.N","35f19c3e":"# sample img\npath = os.path.join(image_folder, train_df.loc[2, 'image_id'] + '.tiff')\nimg = skimage.io.MultiImage(path)[1]\nprint(img.shape)","a27340a9":"# test get_tiles\na, b = get_tiles(img, mode=0)\nprint(b)\nfig, ax = plt.subplots(6, 6, figsize=(10, 10))\nfor i in range(6):\n    for j in range(6):\n        ax[i, j].imshow(a[i*6+j]['img'])","470acd04":"def show_grid(path, level, SZ=256, N=36, mode=0, ):\n    \n    img = skimage.io.MultiImage(path)[level]\n    \n    h, w, c = img.shape\n    pad_h = (SZ - h % SZ) % SZ + ((SZ * mode) \/\/ 2)\n    pad_w = (SZ - w % SZ) % SZ + ((SZ * mode) \/\/ 2)\n\n    img2 = np.pad(img, [[pad_h \/\/ 2, pad_h - pad_h \/\/ 2], \n                        [pad_w \/\/ 2, pad_w - pad_w\/\/2], \n                        [0,0]], constant_values=255)\n    print(img2.shape)\n    nh, nw, _ = img2.shape\n    \n    # show padded result\n    # to know what mode means\n    fig, ax = plt.subplots(1, figsize=(40, 40))\n    ax.imshow(img2)\n    ax.set_yticks(np.arange(0, nh, SZ))\n    ax.set_xticks(np.arange(0, nw, SZ))\n    ax.grid(color='black', linestyle='-', linewidth=1)\n\n    # show which tiles are chosen\n    img3 = img2.reshape(\n        img2.shape[0] \/\/ SZ,\n        SZ,\n        img2.shape[1] \/\/ SZ,\n        SZ,\n        3\n    )\n    \n    new_row, new_col = img3.shape[0], img3.shape[2]\n    img3 = img3.transpose(0, 2, 1, 3, 4).reshape(-1, SZ, SZ, 3) # (783, 256, 256, 3)\n    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:N]\n    for idx in idxs:\n        x = (idx % new_col) * SZ\n        y = (idx \/\/ new_col) * SZ\n        rect = patches.Rectangle((x, y), SZ, SZ, linewidth=1, edgecolor='b', facecolor='b', alpha=0.1)\n        ax.add_patch(rect)\n\n    plt.show()","d9ea7c6f":"show_grid(path=os.path.join(image_folder, train_df.loc[2, 'image_id'] + '.tiff'), \n             level=1, \n             SZ=256, \n             N=36, \n             mode=0)","443cfef2":"show_grid(path=os.path.join(image_folder, train_df.loc[2, 'image_id'] + '.tiff'), \n             level=1, \n             SZ=256, \n             N=36, \n             mode=2)","49f6a64d":"show_grid(path=os.path.join(image_folder, train_df.loc[2, 'image_id'] + '.tiff'), \n             level=2, \n             SZ=128, \n             N=16, \n             mode=0)","42f1c13d":"show_grid(path=os.path.join(image_folder, train_df.loc[2, 'image_id'] + '.tiff'),\n             level=1, \n             SZ=64, \n             N=448, \n             mode=0)","0b81de6f":"# Show level1 256X256X36","65440c6f":"# Show Grid Result","ee44d353":"# Show level2 128X128X16"}}