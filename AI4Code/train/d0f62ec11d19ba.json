{"cell_type":{"ec582462":"code","85819a6c":"code","876dccbc":"code","cc8bc2d9":"code","37fe7e3d":"code","d4253cec":"code","746e2981":"code","1e879670":"code","896149de":"code","1aacb32f":"code","01d347fe":"code","813fe7cf":"code","7dd3623b":"code","32ccfffa":"code","c353185c":"code","d136d684":"code","1b51a53f":"code","d1fb358d":"code","eb69358f":"code","660b1dd0":"code","9add6500":"code","608a63d7":"code","540b5592":"code","a3c80c2e":"code","4f033e92":"code","b58cef34":"code","30853449":"code","e5f3e953":"code","17b91f30":"code","52e24d41":"code","10188893":"code","45dfc53e":"code","4fd2597e":"code","2605062f":"code","45a22989":"code","88d6a538":"code","f05d74c7":"code","38d8dd18":"code","91de277c":"code","01829a88":"code","66f3004e":"code","7e5a6325":"code","69d18c33":"code","f35c0ef5":"code","7a5d2f3e":"code","e73e40cd":"code","94ecbfde":"code","ded15224":"code","633158c1":"code","6ab463ac":"code","903e785f":"code","65f92519":"code","3b0c56b8":"code","73f90c98":"code","2e747960":"code","4d0ae308":"code","20880d2a":"code","1afd1e31":"code","4f4f83ec":"markdown","e41ab8d0":"markdown","4340337f":"markdown","d4337e85":"markdown","2b45defd":"markdown","48820202":"markdown","2bc039dc":"markdown","04479d55":"markdown"},"source":{"ec582462":"import numpy as np\nimport pandas as pd\nimport os\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nfrom scipy.interpolate import UnivariateSpline\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport collections\nfrom dataclasses import dataclass\nimport dataclasses","85819a6c":"@dataclass\nclass Config: \n    stage_2 = True # True for Stage 2 submission\n    debug = False # True for fast debug run\n\nconfig = Config()","876dccbc":"tourney_results = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MNCAATourneyDetailedResults.csv')\nseeds = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MNCAATourneySeeds.csv')\nregular_results = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MRegularSeasonDetailedResults.csv')\nkenpom = pd.read_csv('..\/input\/kenpom-2020\/Mkenpom2021.csv')","cc8bc2d9":"all(regular_results.columns == tourney_results.columns)","37fe7e3d":"regular_results.columns","d4253cec":"regular_results_swap = regular_results[[\n    'Season', 'DayNum', 'LTeamID', 'LScore', 'WTeamID', 'WScore', 'WLoc', 'NumOT', \n    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', \n    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]","746e2981":"regular_results_swap.head()","1e879670":"regular_results_swap.loc[regular_results['WLoc'] == 'H', 'WLoc'] = 'A'\nregular_results_swap.loc[regular_results['WLoc'] == 'A', 'WLoc'] = 'H'\nregular_results.columns.values[6] = 'location'\nregular_results_swap.columns.values[6] = 'location'","896149de":"regular_results.columns = [x.replace('W','T1_').replace('L','T2_') for x in list(regular_results.columns)]\nregular_results_swap.columns = [x.replace('L','T1_').replace('W','T2_') for x in list(regular_results.columns)]","1aacb32f":"regular_results.head()","01d347fe":"regular_data = pd.concat([regular_results, regular_results_swap]).sort_index().reset_index(drop = True)","813fe7cf":"regular_data.head(10)","7dd3623b":"tourney_results = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MNCAATourneyDetailedResults.csv')\nseeds = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MNCAATourneySeeds.csv')\nregular_results = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MRegularSeasonDetailedResults.csv')\n\ndef prepare_data(df):\n    dfswap = df[['Season', 'DayNum', 'LTeamID', 'LScore', 'WTeamID', 'WScore', 'WLoc', 'NumOT', \n    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', \n    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]\n\n    dfswap.loc[df['WLoc'] == 'H', 'WLoc'] = 'A'\n    dfswap.loc[df['WLoc'] == 'A', 'WLoc'] = 'H'\n    df.columns.values[6] = 'location'\n    dfswap.columns.values[6] = 'location'    \n      \n    df.columns = [x.replace('W','T1_').replace('L','T2_') for x in list(df.columns)]\n    dfswap.columns = [x.replace('L','T1_').replace('W','T2_') for x in list(dfswap.columns)]\n\n    output = pd.concat([df, dfswap]).reset_index(drop=True)\n    output.loc[output.location=='N','location'] = '0'\n    output.loc[output.location=='H','location'] = '1'\n    output.loc[output.location=='A','location'] = '-1'\n    output.location = output.location.astype(int)\n    \n    output['PointDiff'] = output['T1_Score'] - output['T2_Score']\n    \n    return output","32ccfffa":"regular_data = prepare_data(regular_results)\ntourney_data = prepare_data(tourney_results)","c353185c":"regular_data.shape","d136d684":"tourney_data.shape","1b51a53f":"tourney_data.columns","d1fb358d":"boxscore_cols = ['T1_Score', 'T2_Score', \n        'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_FTM', 'T1_FTA', 'T1_OR', 'T1_DR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_Blk', 'T1_PF', \n        'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_FTM', 'T2_FTA', 'T2_OR', 'T2_DR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk', 'T2_PF', \n        'PointDiff']\n\nboxscore_cols = [\n        'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_OR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_PF', \n        'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_OR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk',  \n        'PointDiff']\n\nfuncs = [np.mean]","eb69358f":"season_statistics = regular_data.groupby([\"Season\", 'T1_TeamID'])[boxscore_cols].agg(funcs)\nseason_statistics.head()","660b1dd0":"season_statistics = regular_data.groupby([\"Season\", 'T1_TeamID'])[boxscore_cols].agg(funcs).reset_index()\nseason_statistics.head()","9add6500":"season_statistics.columns = [''.join(col).strip() for col in season_statistics.columns.values]\nseason_statistics.head()","608a63d7":"season_statistics_T1 = season_statistics.copy()\nseason_statistics_T2 = season_statistics.copy()\n\nseason_statistics_T1.columns = [\"T1_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(season_statistics_T1.columns)]\nseason_statistics_T2.columns = [\"T2_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(season_statistics_T2.columns)]\nseason_statistics_T1.columns.values[0] = \"Season\"\nseason_statistics_T2.columns.values[0] = \"Season\"","540b5592":"season_statistics_T1.head()","a3c80c2e":"season_statistics_T2.head()","4f033e92":"tourney_data = tourney_data[['Season', 'DayNum', 'T1_TeamID', 'T1_Score', 'T2_TeamID' ,'T2_Score']]\ntourney_data.head()","b58cef34":"tourney_data = pd.merge(tourney_data, season_statistics_T1, on = ['Season', 'T1_TeamID'], how = 'left')\ntourney_data = pd.merge(tourney_data, season_statistics_T2, on = ['Season', 'T2_TeamID'], how = 'left')","30853449":"tourney_data.head()","e5f3e953":"last14days_stats_T1 = regular_data.loc[regular_data.DayNum>118].reset_index(drop=True)\nlast14days_stats_T1['win'] = np.where(last14days_stats_T1['PointDiff']>0,1,0)\nlast14days_stats_T1 = last14days_stats_T1.groupby(['Season','T1_TeamID'])['win'].mean().reset_index(name='T1_win_ratio_14d')\n\nlast14days_stats_T2 = regular_data.loc[regular_data.DayNum>118].reset_index(drop=True)\nlast14days_stats_T2['win'] = np.where(last14days_stats_T2['PointDiff']<0,1,0)\nlast14days_stats_T2 = last14days_stats_T2.groupby(['Season','T2_TeamID'])['win'].mean().reset_index(name='T2_win_ratio_14d')","17b91f30":"tourney_data = pd.merge(tourney_data, last14days_stats_T1, on = ['Season', 'T1_TeamID'], how = 'left')\ntourney_data = pd.merge(tourney_data, last14days_stats_T2, on = ['Season', 'T2_TeamID'], how = 'left')","52e24d41":"regular_season_effects = regular_data[['Season','T1_TeamID','T2_TeamID','PointDiff']].copy()\nregular_season_effects['T1_TeamID'] = regular_season_effects['T1_TeamID'].astype(str)\nregular_season_effects['T2_TeamID'] = regular_season_effects['T2_TeamID'].astype(str)\nregular_season_effects['win'] = np.where(regular_season_effects['PointDiff']>0,1,0)\nmarch_madness = pd.merge(seeds[['Season','TeamID']],seeds[['Season','TeamID']],on='Season')\nmarch_madness.columns = ['Season', 'T1_TeamID', 'T2_TeamID']\nmarch_madness.T1_TeamID = march_madness.T1_TeamID.astype(str)\nmarch_madness.T2_TeamID = march_madness.T2_TeamID.astype(str)\nregular_season_effects = pd.merge(regular_season_effects, march_madness, on = ['Season','T1_TeamID','T2_TeamID'])\nregular_season_effects.shape","10188893":"def team_quality(season):\n    formula = 'win~-1+T1_TeamID+T2_TeamID'\n    glm = sm.GLM.from_formula(formula=formula, \n                              data=regular_season_effects.loc[regular_season_effects.Season==season,:], \n                              family=sm.families.Binomial()).fit()\n    \n    quality = pd.DataFrame(glm.params).reset_index()\n    quality.columns = ['TeamID','quality']\n    quality['Season'] = season\n    quality['quality'] = np.exp(quality['quality'])\n    quality = quality.loc[quality.TeamID.str.contains('T1_')].reset_index(drop=True)\n    quality['TeamID'] = quality['TeamID'].apply(lambda x: x[10:14]).astype(int)\n    return quality","45dfc53e":"seeds.head()","4fd2597e":"seeds['seed'] = seeds['Seed'].apply(lambda x: int(x[1:3]))\nseeds.head()","2605062f":"seeds_T1 = seeds[['Season','TeamID','seed']].copy()\nseeds_T2 = seeds[['Season','TeamID','seed']].copy()\nseeds_T1.columns = ['Season','T1_TeamID','T1_seed']\nseeds_T2.columns = ['Season','T2_TeamID','T2_seed']","45a22989":"tourney_data = pd.merge(tourney_data, seeds_T1, on = ['Season', 'T1_TeamID'], how = 'left')\ntourney_data = pd.merge(tourney_data, seeds_T2, on = ['Season', 'T2_TeamID'], how = 'left')","88d6a538":"tourney_data[\"Seed_diff\"] = tourney_data[\"T1_seed\"] - tourney_data[\"T2_seed\"]","f05d74c7":"y = tourney_data['T1_Score'] - tourney_data['T2_Score']\ny.describe()","38d8dd18":"features = list(season_statistics_T1.columns[2:999]) + \\\n    list(season_statistics_T2.columns[2:999]) + \\\n    list(seeds_T1.columns[2:999]) + \\\n    list(seeds_T2.columns[2:999]) + \\\n    list(last14days_stats_T1.columns[2:999]) + \\\n    list(last14days_stats_T2.columns[2:999]) + \\\n    [\"Seed_diff\"]\n\nlen(features)","91de277c":"tourney_data","01829a88":"X = tourney_data[features].values\ndtrain = xgb.DMatrix(X, label = y)","66f3004e":"def cauchyobj(preds, dtrain):\n    labels = dtrain.get_label()\n    c = 5000 \n    x =  preds-labels    \n    grad = x \/ (x**2\/c**2+1)\n    hess = -c**2*(x**2-c**2)\/(x**2+c**2)**2\n    return grad, hess","7e5a6325":"param = {} \n#param['objective'] = 'reg:linear'\nparam['eval_metric'] =  'mae'\nparam['booster'] = 'gbtree'\nparam['eta'] = 0.02\nparam['subsample'] = 0.35\nparam['colsample_bytree'] = 0.7\nparam['num_parallel_tree'] = 10\nparam['min_child_weight'] = 40\nparam['gamma'] = 10\nparam['max_depth'] =  3\nparam['silent'] = 1\n\nprint(param)","69d18c33":"xgb_cv = []\nrepeat_cv = 20\nn_splits = 5\nif config.debug: \n    repeat_cv = 2\n    n_splits = 2\n\nfor i in range(repeat_cv): \n    print(f\"Fold repeater {i}\")\n    xgb_cv.append(\n        xgb.cv(\n          params = param,\n          dtrain = dtrain,\n          obj = cauchyobj,\n          num_boost_round = 3500,\n          folds = KFold(n_splits = n_splits, shuffle = True, random_state = i),\n          early_stopping_rounds = 25,\n          verbose_eval = 50\n        )\n    )","f35c0ef5":"iteration_counts = [np.argmin(x['test-mae-mean'].values) for x in xgb_cv]\nval_mae = [np.min(x['test-mae-mean'].values) for x in xgb_cv]\niteration_counts, val_mae","7a5d2f3e":"oof_preds = []\nfor i in range(repeat_cv):\n    print(f\"Fold repeater {i}\")\n    preds = y.copy()\n    kfold = KFold(n_splits = 5, shuffle = True, random_state = i)    \n    for train_index, val_index in kfold.split(X,y):\n        dtrain_i = xgb.DMatrix(X[train_index], label = y[train_index])\n        dval_i = xgb.DMatrix(X[val_index], label = y[val_index])  \n        model = xgb.train(\n              params = param,\n              dtrain = dtrain_i,\n              num_boost_round = iteration_counts[i],\n              verbose_eval = 50\n        )\n        preds[val_index] = model.predict(dval_i)\n    oof_preds.append(np.clip(preds,-30,30))","e73e40cd":"plot_df = pd.DataFrame({\"pred\":oof_preds[0], \"label\":np.where(y>0,1,0)})\nplot_df[\"pred_int\"] = plot_df[\"pred\"].astype(int)\nplot_df = plot_df.groupby('pred_int')['label'].mean().reset_index(name='average_win_pct')\n\nplt.figure()\nplt.plot(plot_df.pred_int,plot_df.average_win_pct)","94ecbfde":"spline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n        \n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    \n    print(f\"logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","ded15224":"plot_df = pd.DataFrame({\"pred\":oof_preds[0], \"label\":np.where(y>0,1,0), \"spline\":spline_model[0](oof_preds[0])})\nplot_df[\"pred_int\"] = (plot_df[\"pred\"]).astype(int)\nplot_df = plot_df.groupby('pred_int')['spline','label'].mean().reset_index()\n\nplt.figure()\nplt.plot(plot_df.pred_int,plot_df.spline)\nplt.plot(plot_df.pred_int,plot_df.label)","633158c1":"spline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    \n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","6ab463ac":"spline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n\n    \n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","903e785f":"spline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    \n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","65f92519":"val_cv = []\nspline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    val_cv.append(pd.DataFrame({\"y\":np.where(y>0,1,0), \"pred\":spline_fit, \"season\":tourney_data.Season}))\n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") \n    \nval_cv = pd.concat(val_cv)\nval_cv.groupby('season').apply(lambda x: log_loss(x.y, x.pred))","3b0c56b8":"if config.stage_2: \n    sub = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MSampleSubmissionStage2.csv')\n    sub[\"Season\"] = 2021\n    sub[\"T1_TeamID\"] = sub[\"ID\"].apply(lambda x: x[5:9]).astype(int)\n    sub[\"T2_TeamID\"] = sub[\"ID\"].apply(lambda x: x[10:14]).astype(int)\n    sub = pd.merge(sub, season_statistics_T1, on = ['Season', 'T1_TeamID'])\n    sub = pd.merge(sub, season_statistics_T2, on = ['Season', 'T2_TeamID'])\n#     sub = pd.merge(sub, glm_quality_T1, on = ['Season', 'T1_TeamID'])\n#     sub = pd.merge(sub, glm_quality_T2, on = ['Season', 'T2_TeamID'])\n    sub = pd.merge(sub, seeds_T1, on = ['Season', 'T1_TeamID'])\n    sub = pd.merge(sub, seeds_T2, on = ['Season', 'T2_TeamID'])\n    sub = pd.merge(sub, last14days_stats_T1, on = ['Season', 'T1_TeamID'])\n    sub = pd.merge(sub, last14days_stats_T2, on = ['Season', 'T2_TeamID'])\n    sub[\"Seed_diff\"] = sub[\"T1_seed\"] - sub[\"T2_seed\"]\n    Xsub = sub[features].values\n    dtest = xgb.DMatrix(Xsub)\n    sub_models = []\n    for i in range(repeat_cv):\n        print(f\"Fold repeater {i}\")\n        sub_models.append(\n            xgb.train(\n              params = param,\n              dtrain = dtrain,\n              num_boost_round = int(iteration_counts[i] * 1.05),\n              verbose_eval = 50\n            )\n        )\n    sub_preds = []\n    for i in range(repeat_cv):\n        sub_preds.append(\n            spline_model[i](np.clip(sub_models[i].predict(dtest),-30,30))\n        )\n\n    sub[\"Pred\"] = pd.DataFrame(sub_preds).mean(axis=0)\n    #sub[['ID','Pred']].to_csv(\"submission.csv\", index = None)","73f90c98":"def add_gameround(game_df):\n    rnds = pd.read_csv(DATAPATH+'MNCAATourneySeedRoundSlots.csv', sep=',')\n    rnds['ASeed'] = rnds['Seed'].apply(lambda x: int(x[1:3]))\n    rnds['DayNum'] = rnds['EarlyDayNum']\n    temp = rnds.copy()\n    temp['DayNum'] = temp['LateDayNum']\n    rnds = rnds[['ASeed','GameRound','DayNum']].append(temp[['ASeed','GameRound','DayNum']], ignore_index=True, sort=False)\n    rnds.drop_duplicates(inplace=True)\n    game_df = game_df.merge(rnds, on=['ASeed','DayNum'], how='left')\n    return game_df","2e747960":"rnds = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MNCAATourneySeedRoundSlots.csv', sep=',')\nrnds['ASeed'] = rnds['Seed'].apply(lambda x: int(x[1:3]))\nrnds['DayNum'] = rnds['EarlyDayNum']\ntemp = rnds.copy()\ntemp['DayNum'] = temp['LateDayNum']\nrnds = rnds[['ASeed','GameRound','DayNum']].append(temp[['ASeed','GameRound','DayNum']], ignore_index=True, sort=False)\nrnds.drop_duplicates(inplace=True)","4d0ae308":"sub.head()","20880d2a":"sub_final = sub[['ID','Pred']]\nsub_final.to_csv(\"submission.csv\", index = None)","1afd1e31":"sub\n","4f4f83ec":"# NCAAM Prediction\n---\nPrevious [notebook](https:\/\/www.kaggle.com\/readoc\/ncaam-prediction-v3).\n\nThe 2019 best solution was based on @raddar's solution\n\nChanges: \n1. Removed bad bets \n2. Tuned some hyperparameters\n3. Removed prediction clipping","e41ab8d0":"### Load the data","4340337f":"### Feature engineering","d4337e85":"### Model Building","2b45defd":"### Submission","48820202":"### Preparing the data","2bc039dc":"# If you fork, do leave an upvote!","04479d55":"You can also add Kenpom data, 538 ratings data and spread data in the features"}}