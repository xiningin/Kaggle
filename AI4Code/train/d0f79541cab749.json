{"cell_type":{"0c6fa9e6":"code","0ad2b0fc":"code","87a731c8":"code","cd202027":"code","6cf3eb42":"code","b248d795":"code","ef1e5d65":"code","5d079dec":"code","8c80ef75":"code","e6a65361":"code","7a030cf7":"code","95c9ba91":"code","be300bbf":"code","e81b7c9f":"markdown","cf09459f":"markdown","779e81ca":"markdown","11744536":"markdown","eb1dd408":"markdown","31dec945":"markdown"},"source":{"0c6fa9e6":"import os\nimport csv\nimport pandas as pd\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nDATA_DIR = '\/kaggle\/input\/movielens-100k-dataset\/ml-100k'\nOUTPUT_DIR = '.\/'\n\nclass Config:\n    device='cpu'\n    epochs=40\n    seed=17\n    train_bs=8\n    valid_bs=8\n    embedding_dim=20\n    lr=1e-2\n    num_workers=None       \n    verbose_step=100\n    \ndef torch_seed_everything(seed_value=777):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nconfig=Config()\ntorch_seed_everything(config.seed)","0ad2b0fc":"df = pd.read_csv(os.path.join(DATA_DIR, 'u.data'), sep='\\t', header=None)\ndf.columns = ['user_id', 'item_id', 'rating', 'timestamp']\n#df = df.sort_values('timestamp').reset_index(drop=True)\nn_user = df.user_id.nunique()\nn_item = df.item_id.nunique()\ndf","87a731c8":"print('user_num', n_user)\nprint('item_num', n_item)","cd202027":"train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['user_id'], random_state=config.seed)\nassert train_df.user_id.nunique() == valid_df.user_id.nunique()\nprint(train_df.shape, valid_df.shape)\n#print(valid_df.user_id.nunique())","6cf3eb42":"class MovieLensDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        user_id, item_id, rating, _ = self.df.iloc[idx]\n        # index starts with 0\n        sample = {\"user\": user_id - 1, \"item\": item_id - 1, \"rating\": rating}\n        return sample","b248d795":"class MatrixFactorizationPyTorch(nn.Module):\n    def __init__(self, n_user, n_item, k=20):\n        \"\"\"\n        n_user: user num\n        n_item: item num\n        k: embedding dim\n        \"\"\"\n        super().__init__()\n        self.user_factors = nn.Embedding(n_user, k, sparse=True)\n        self.item_factors = nn.Embedding(n_item, k, sparse=True)\n\n    def forward(self, user, item):\n        #print(user, item)\n        u_emb = self.user_factors(user)\n        i_emb = self.item_factors(item)\n        # print(u_emb.shape, i_emb.shape)\n        # print((u_emb * i_emb).shape)\n        # print((u_emb * i_emb).sum(axis=1).shape)\n        return (u_emb * i_emb).sum(axis=1)","ef1e5d65":"train_loader = DataLoader(MovieLensDataset(train_df), batch_size=2, shuffle=True,)\nnext(iter(train_loader))","5d079dec":"data = next(iter(train_loader))\nuser, item = data['user'], data['item']\nmodel = MatrixFactorizationPyTorch(n_user, n_item, k=config.embedding_dim)\nmodel(user, item)","8c80ef75":"def train_one_epoch(epoch, model, loss_fn, optimizer,\n                    train_loader, device, scheduler=None):\n    model.train()\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    data_cnt = 0\n    total_loss = 0.0\n\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u30b7\u30e3\u30c3\u30d5\u30eb\u3057\u3066\u30eb\u30fc\u30d7\n    for step, data in pbar:\n        user = data['user']\n        item = data['item']\n        rating = data['rating']\n        data_cnt += user.shape[0]\n\n        # \u52fe\u914d\u30ea\u30bb\u30c3\u30c8\n        optimizer.zero_grad()\n\n        #\u9806\u4f1d\u642c\u3001\u9006\u4f1d\u642c\n        outputs = model(user, item)\n        #print('outupts', outputs)\n        #print(rating)\n        loss = loss_fn(outputs,  rating.float())\n        #print('loss', loss)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        #print(total_loss)\n        if ((step + 1) % config.verbose_step == 0) or ((step + 1) == len(train_loader)):\n            description = f'train epoch {epoch} loss: {total_loss \/ data_cnt:.4f}'\n            pbar.set_description(description)\n\n    total_loss = total_loss \/ len(train_loader)\n    print('train loss = {:.4f}'.format(total_loss))\n\ndef valid_one_epoch(epoch, model, loss_fn, val_loader, device):\n\n    model.eval()\n    total_loss = 0.0\n    data_cnt = 0\n    #preds = []\n    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n\n    for step, data in pbar:\n        user = data['user']\n        item = data['item']\n        rating = data['rating']\n        data_cnt += user.shape[0]\n\n        outputs = model(user, item)\n        loss = loss_fn(outputs, rating)\n        total_loss += loss\n        \n        # preds.append(outputs.detach().cpu().numpy())\n\n        if ((step + 1) % config.verbose_step == 0) or ((step + 1) == len(val_loader)):\n            description = f'val epoch {epoch} loss: {total_loss \/ data_cnt:.4f}'\n            pbar.set_description(description)\n        \n\n    valid_loss = total_loss \/ len(val_loader)\n    print('val loss = {:.4f}'.format(valid_loss))\n    return valid_loss \n\ndef run_train(train_loader, valid_loader):\n    device = torch.device(config.device)\n    model = MatrixFactorizationPyTorch(n_user, n_item, k=config.embedding_dim)\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(model.parameters(), lr=config.lr)\n    best_loss=1e10\n    for epoch in range(config.epochs):\n        train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device)\n\n        with torch.no_grad():\n            val_loss = valid_one_epoch(epoch, model, loss_fn, valid_loader, device)\n        \n        if best_loss > val_loss:\n            best_loss = val_loss\n            best_rmse = torch.sqrt(best_loss)\n            best_epoch = epoch\n            # TODO: save model,  figure\n            best_path =  os.path.join(OUTPUT_DIR,f'best_model.bin')\n            torch.save({'model':model.state_dict(),},\n                           best_path)\n    print(f'----- result ------')\n    print(f'Best epoch: {epoch}')\n    print(f'Best loss: {best_loss}, RMSE: {best_rmse}')","e6a65361":"train_loader = DataLoader(MovieLensDataset(train_df), batch_size=config.train_bs, shuffle=True,)\nvalid_loader = DataLoader(MovieLensDataset(valid_df), batch_size=config.valid_bs, shuffle=False,)\nrun_train(train_loader, valid_loader)","7a030cf7":"m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\nitem_df = pd.read_csv(os.path.join(DATA_DIR, 'u.item'), sep='|', encoding=\"iso-8859-1\", usecols=range(5), names=m_cols)\nitem_df.head()","95c9ba91":"def load_model():\n    best_path = os.path.join(OUTPUT_DIR, 'best_model.bin')\n    model = MatrixFactorizationPyTorch(n_user, n_item, k=config.embedding_dim)\n    model.load_state_dict(torch.load(best_path)['model'])\n    return model\n\ndef predict_rating(rec_df):\n    model = load_model()\n    model.eval()\n    dataloader = DataLoader(MovieLensDataset(rec_df), batch_size=10, shuffle=False,)\n    pbar = tqdm(dataloader, total=len(dataloader))\n    preds = []\n    for data in pbar:\n        user_id = data['user']\n        item_id = data['item']\n        rating = data['rating']\n\n        preds += model(user_id, item_id)\n\n    return torch.stack(preds).detach().numpy()\n\ndef recommend_for_user(user_id, rating_df, item_df, top_n=10):\n    # Extract data that user have never seen.\n    rec_df = rating_df.query(\"user_id != @user_id\")\n    rec_df['user_id'] = user_id\n    rec_df = rec_df.drop_duplicates(subset=['user_id','item_id'])\n\n    # predict rating\n    rec_df['rating'] = predict_rating(rec_df)\n    \n    # clip rating\n    # I don't know if this is the right way...\n    rec_df = rec_df.query('0.5 <= rating <= 5.5 ')\n\n    # add title column \n    d = dict(zip(item_df.movie_id, item_df.title))\n    rec_df['title'] = rec_df['item_id'].map(d)\n    rec_df = rec_df.sort_values('rating', ascending=False)\n\n    # show recommended movies\n    print('-'*30 + 'recommendations' + '-'*30)\n    print(rec_df[['title','rating']].head(top_n))\n#     for i, row in rec_df.head(top_n).iterrows():\n#         title, rating = row['title'],row['rating']\n#         print(f'{i:}: title:{title}  score:{rating}')\n\n    # show movies which user have watched before\n    user_df = rating_df.query(\"user_id == @user_id\")\n    user_df['title'] = user_df['item_id'].map(d)\n    user_df = user_df.sort_values('rating', ascending=False)\n\n    print('-'*30 + 'watched_movies' + '-'*30)\n    print(user_df[['title','rating']].head(top_n))\n#     for i, row in user_df.head(top_n).iterrows():\n#         title, rating = row['title'], row['rating']\n#         print(f'{i}: title:{title}  score:{rating}')\n\n","be300bbf":"user_id = random.choice(df.user_id.values)\nprint(user_id)\nrecommend_for_user(user_id, df, item_df)","e81b7c9f":"# model","cf09459f":"# get recommendation","779e81ca":"# load data","11744536":"# split data","eb1dd408":"# train","31dec945":"# Dataset"}}