{"cell_type":{"4a04a665":"code","d5391270":"code","40dcac02":"code","ea49e84a":"code","286aa8a6":"code","ae016537":"code","42e38691":"code","6a92fb49":"code","5a56b603":"code","66d24ccc":"code","4fdcffc5":"code","ffc0a9a1":"code","5c975d96":"code","53ae00da":"code","ff4e49ed":"code","b610abf8":"code","ff281c5e":"code","ac6e9629":"code","a46373a7":"code","7605e731":"code","5622703f":"code","fed156f7":"code","b0b044d9":"code","ef16537f":"code","7b32850e":"code","74e3caa0":"code","03771410":"code","32dda1ba":"code","fe79f824":"code","e655db35":"code","4cd24afd":"code","c78dcfed":"code","312cdc48":"code","061f0033":"code","0ce95798":"code","19303b12":"code","e10c2eb7":"code","74c760c5":"code","2ca9a545":"code","0982447d":"markdown","5f6af155":"markdown","d39c83bd":"markdown","6639b39c":"markdown","e3ce441f":"markdown","8687c38f":"markdown","0eb5a380":"markdown","56abf936":"markdown","32ca7be0":"markdown","e3b45f81":"markdown","cab66714":"markdown","e65aa9ff":"markdown","044466a6":"markdown","d35f7945":"markdown"},"source":{"4a04a665":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","d5391270":"train = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")\nprint(\"--Done--\")","40dcac02":"print(f'Shape of Train Dataset: {train.shape}')\nprint(f'Shape of Test Dataset: {test.shape}')\nprint(f'Total null values in Train Dataset: {train.isna().sum().sum()}')\nprint(f'Total null values in Test Dataset: {test.isna().sum().sum()}')","ea49e84a":"train.describe().T.style.bar(subset='mean', color='limegreen').background_gradient(subset=['50%'], cmap='Greens')","286aa8a6":"def visualize(x, data, xname, yname, title, note, textx, texty, y=None, bar=False, tick_labels=True):\n    # Set the size of the figure in concern\n    fig, ax = plt.subplots(figsize=(20, 8), facecolor='#2b2b2b')\n    ax.set_facecolor('#2b2b2b') # Change the color of the background\n    if not bar:\n        ax = sns.histplot(data=data, x=x, y=y, kde=True, line_kws={'linewidth': 3}, color='mistyrose', alpha=0.5)\n        ax.lines[0].set_color('crimson') #change the line color of the kdeplot\n    else:\n        ax = sns.barplot(x=x, y=y, color='lightpink', alpha=0.5)\n\n    #Shows only the bottom and left axes\n    for i in ['bottom', 'left']:\n        ax.spines[i].set_color('skyblue')\n        ax.spines[i].set_linewidth(3) \n\n    # Hides the spines\n    for i in ['top', 'right']:\n        ax.spines[i].set_visible(False)\n        \n    # Changes the size and the color of x and y ticks\n    ax.tick_params(axis='x', colors='white', size=8)\n    ax.tick_params(axis='y', colors='white', size=8)\n\n    # Changes the size of x and y ticks\n    if not tick_labels:\n        ax.set_xticklabels(ax.get_xticks(), fontsize=14)\n        ax.set_yticklabels(ax.get_yticks(), fontsize=14)\n\n    # Changes the color and size of x and y labels\n    ax.set_xlabel(xname, fontsize=18, color='yellow')\n    ax.set_ylabel(yname, fontsize=20, color='yellow')\n\n    #Sets the title and the text to a particular x and y axis\n    ax.set_title(title, color='gold', fontsize=24)\n    annon = note\n    ax.text(x=textx, y=texty, s=annon, color='white', size=14)\n\n    plt.show()","ae016537":"visualize(x='song_duration_ms', data=train, xname='Song Duration(ms)', yname='Count', title='Distribution of Song Duration',\n          note='We can see that the distribution is a bit right skewed.\\nNot massively but this tells us that most of the songs \\nare around the 3 mintues mark.',\n          textx= 27*(10_000), texty=600)","42e38691":"visualize(x='acousticness', data=train, xname='Acousticness', yname='Count', title='Distribution of Acousticness',\n          note='We can see that the distribution is right skewed and majority of \\nthe values lie towards zero. This tells us that nearly \\nmore than 50% of our data have acousticness > 0.5',\n          textx=0.4, texty=2500)","6a92fb49":"visualize(x='danceability', data=train, xname='Danceability', yname='Count', title='Distribution of Danceability',\n          note='We can see that the distribution is left skewed and majority of \\nthe values lie towards 1. This gives us a basic idea \\nthat majority of the songs in our training dataset are groovy.',\n          textx=0.1, texty=1200)","5a56b603":"visualize(x='energy', data=train, xname='Energy', yname='Count', title='Distribution of Energy',\n          note='We can see that this distribution too is left skewed and majority of \\nthe values lie towards 1. Our training dataset has nearly no songs \\nthat would make you sulk, understandable as most of them are groovy, \\nthey have to have high energy too!',\n          textx=0.05, texty=1000)","66d24ccc":"visualize(x='instrumentalness', data=train, xname='Instrumentalness', yname='Count', title='Distribution of Instrumentalness',\n          note='Woaah! This is nasty. We have to fix this probably \\nwith a log transformation or a box-cox. It\\'s everything \\nwe don\\'t want our model to see! Extreme skewness.',\n          textx=0.4, texty=500)","4fdcffc5":"visualize(x='liveness', data=train, xname='Liveness', yname='Count', title='Distribution of Liveness',\n          note='We can see that the distribution is right skewed and majority of \\nthe values lie towards zero. Out training dataset doesn\\'t have many \\nlive performances, meaning most of them are studio recorded.',\n          textx=0.4, texty=500)","ffc0a9a1":"visualize(x='loudness', data=train, xname='Loudness', yname='Count', title='Distribution of Loudness',\n          note='We can see that the distribution is left skewed and majority of \\nthe values lie towards zero. Doing a little research it shows that dB \\ncan actually be negative as that just implies - \\n\\nThat the sound is few times softer than the threshold. \\nSince these are recorded using professional sound equipment, \\n0 dB usually refers to the loudest level before distortion begins.',\n          textx=-30, texty=500)","5c975d96":"visualize(x='liveness', data=train, xname='Liveness', yname='Count', title='Distribution of Liveness',\n          note='We can see that the distribution is right skewed and majority of \\nthe values lie towards zero. Out training dataset doesn\\'t have many \\nlive performances, meaning most of them are studio recorded.',\n          textx=0.4, texty=500)","53ae00da":"visualize(x='speechiness', data=train, xname='Speechiness', yname='Count', title='Distribution of Speechiness',\n          note='We can see that the distribution is right skewed and majority of \\nthe values lie towards zero making our dataset have barely any speechiness. \\nConsidering that our songs range around 3 minutes mark, this may be \\nco-related to the fact that there are less words and more music.',\n          textx=0.2, texty=1800)","ff4e49ed":"visualize(x='tempo', data=train, xname='Tempo', yname='Count', title='Distribution of Tempo',\n          note='Tempo distribution is skewed having two heads, however \\nthis tells us that most of our songs range around the moderate \\ntempo mark, neither too fast nor too slow. Keeping in mind, \\nthat we would need to transform this distirubution as well.',\n          textx=140, texty=800)","b610abf8":"visualize(x='audio_valence', data=train, xname='Valence', yname='Count', title='Distribution of Valence',\n          note='Higher valence means that the song is joyful \\nor cheerful and lower valence means sad or angry. \\nBased on the distribution we can see that majority of the \\nsong lies on the positive side of the scale which explains \\nthe groovyness however, it would still be interesting to dive \\nmore into the data on how they are related.',\n          textx=0, texty=1050)","ff281c5e":"key_g = train.key.value_counts()\nvisualize(x=key_g.index, y=key_g.values, data=train, xname='Key', yname='Count', title='Distribution of Key', bar=True,\n          note='In the below distribution we can see \\nthat there are integer as catergorical \\nvalues. The most used scales are \\nC, D, F\u266f - G\u266d, & A\u266f - B\u266d',\n          textx=2.5, texty=4000)","ac6e9629":"audio_g = train.audio_mode.value_counts()\nvisualize(x=audio_g.index, y = audio_g.values, data=train, xname='Audio Mode', yname='Count', title='Distribution of Audio Mode',\n          note='We can see that there are almost twice as many \\nsong in minor scale(0) than compared to major scale(1)',\n          textx=0.5, texty=20000, bar=True)","a46373a7":"time_g = train.time_signature.value_counts()\nvisualize(x=time_g.index, y = time_g.values, data=train, xname='Time_Signature', yname='Count', title='Distribution of Time Signature',\n          note='We can see that most of the songs \\nare a 3-rythm song and the next \\nare 4-rythm songs.',\n          textx=2.5, texty=20000, bar=True, tick_labels=True)","7605e731":"song_g = train.song_popularity.value_counts()\nvisualize(x=song_g.index, y = song_g.values, data=train, xname='Song Popularity', yname='Count', title='Distribution of Song Popularity',\n          note='We see that the data is imbalanced and would require \\nundersampling or oversampling to train our model well.',\n          textx=0.5, texty=20000, bar=True, tick_labels=True)","5622703f":"corr = train.corr()[:-1]\nfig, ax = plt.subplots(figsize=(20, 10), facecolor='#2b2b2b')\nax.set_facecolor('#2b2b2b')\nax.tick_params(axis='x', colors='white', size=8)\nax.tick_params(axis='y', colors='white', size=8)\nmap = np.triu(np.ones_like(corr))\nsns.heatmap(corr, cmap='crest', mask=map,annot=True,linecolor='#2b2b2b', linewidths=2, cbar=False)\n\nax.text(x=8, y=6, color='white', s=\"-Loudness and Energy are positively co-related. \\n\\n-Loudness and Acousticness are negatively co-related. \\n\\n-Energy and Acousticness are negatively co-related. \\n\\n-Valence and Danceability are positvely co-related to some extent. \\n\\n-Valence and Loudness are positvely co-related to some extent\")\nax.set_title('Lower-traingle Co-relation between the data', fontsize=18, color='gold')\nplt.show()","fed156f7":"fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9) = plt.subplots(nrows=9,figsize=(20, 60), facecolor='#2b2b2b')\nplt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.3,)\n\nax1 = sns.stripplot(data=train, x='key', y='danceability', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax1)\nax2 = sns.stripplot(data=train, x='key', y='energy', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax2)\nax3 = sns.stripplot(data=train, x='key', y='loudness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax3)\nax4 = sns.stripplot(data=train, x='key', y='speechiness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax4)\nax5 = sns.stripplot(data=train, x='key', y='audio_valence', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax5)\nax6 = sns.stripplot(data=train, x='key', y='liveness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax6)\nax7 = sns.stripplot(data=train, x='key', y='tempo', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax7)\nax8 = sns.stripplot(data=train, x='key', y='acousticness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax8)\nax9 = sns.stripplot(data=train, x='key', y='song_duration_ms', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax9)\n\nfor ele in [ax1, ax2, ax3, ax4, ax5,ax6, ax7, ax8, ax9]:\n    ele.set_facecolor('#2b2b2b')\n    ele.tick_params(axis='x', colors='white', size=8)\n    ele.tick_params(axis='y', colors='white', size=8)\n    for i in ['left', 'bottom']:\n        ele.spines[i].set_color('skyblue')\n        ele.spines[i].set_linewidth(3)\n    for i in ['right', 'top']:\n        ele.spines[i].set_visible(False)\n    ele.grid(alpha=0.2, ls='-.')\n    ele.set_xlabel('Key', fontsize=16, color='powderblue')\n\nax1.set_ylabel('Danceability', fontsize=16, color='powderblue')\nax2.set_ylabel('Energy', fontsize=16, color='powderblue')\nax3.set_ylabel('Loudness', fontsize=16, color='powderblue')\nax4.set_ylabel('Speechiness', fontsize=16, color='powderblue')\nax5.set_ylabel('Valence', fontsize=16, color='powderblue')\nax6.set_ylabel('Liveness', fontsize=16, color='powderblue')\nax7.set_ylabel('Tempo', fontsize=16, color='powderblue')\nax8.set_ylabel('Acousticness', fontsize=16, color='powderblue')\nax9.set_ylabel('Song Duration(ms)', fontsize=16, color='powderblue')\n\nax1.set_title('Relationship between Danceability and Key', size=18, color='gold')\nax2.set_title('Relationship between Energy and Key', size=18, color='gold')\nax3.set_title('Relationship between Loudness and Key', size=18, color='gold')\nax4.set_title('Relationship between Speechiness and Key', size=18, color='gold')\nax5.set_title('Relationship between Valence and Key', size=18, color='gold')\nax6.set_title('Relationship between Liveness and Key', size=18, color='gold')\nax7.set_title('Relationship between Tempo and Key', size=18, color='gold')\nax8.set_title('Relationship between Acousticness and Key', size=18, color='gold')\nax9.set_title('Relationship between Song Duration(ms) and Key', size=18, color='gold')\n\nplt.show()","b0b044d9":"fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9) = plt.subplots(nrows=9,figsize=(20, 60), facecolor='#2b2b2b')\nplt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.3,)\n\nax1 = sns.stripplot(data=train, x='time_signature', y='danceability', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax1)\nax2 = sns.stripplot(data=train, x='time_signature', y='energy', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax2)\nax3 = sns.stripplot(data=train, x='time_signature', y='loudness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax3)\nax4 = sns.stripplot(data=train, x='time_signature', y='speechiness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax4)\nax5 = sns.stripplot(data=train, x='time_signature', y='audio_valence', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax5)\nax6 = sns.stripplot(data=train, x='time_signature', y='liveness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax6)\nax7 = sns.stripplot(data=train, x='time_signature', y='tempo', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax7)\nax8 = sns.stripplot(data=train, x='time_signature', y='acousticness', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax8)\nax9 = sns.stripplot(data=train, x='time_signature', y='song_duration_ms', palette=['mediumvioletred', 'aliceblue'], hue='song_popularity', ax=ax9)\n\nfor ele in [ax1, ax2, ax3, ax4, ax5,ax6, ax7, ax8, ax9]:\n    ele.set_facecolor('#2b2b2b')\n    ele.tick_params(axis='x', colors='white', size=8)\n    ele.tick_params(axis='y', colors='white', size=8)\n    for i in ['left', 'bottom']:\n        ele.spines[i].set_color('skyblue')\n        ele.spines[i].set_linewidth(3)\n    for i in ['right', 'top']:\n        ele.spines[i].set_visible(False)\n    ele.grid(alpha=0.2, ls='-.')\n    ele.set_xlabel('Time Signature', fontsize=16, color='powderblue')\n\nax1.set_ylabel('Danceability', fontsize=16, color='powderblue')\nax2.set_ylabel('Energy', fontsize=16, color='powderblue')\nax3.set_ylabel('Loudness', fontsize=16, color='powderblue')\nax4.set_ylabel('Speechiness', fontsize=16, color='powderblue')\nax5.set_ylabel('Valence', fontsize=16, color='powderblue')\nax6.set_ylabel('Liveness', fontsize=16, color='powderblue')\nax7.set_ylabel('Tempo', fontsize=16, color='powderblue')\nax8.set_ylabel('Acousticness', fontsize=16, color='powderblue')\nax9.set_ylabel('Song Duration(ms)', fontsize=16, color='powderblue')\n\nax1.set_title('Relationship between Danceability and Time Signature', size=18, color='gold')\nax2.set_title('Relationship between Energy and Time Signature', size=18, color='gold')\nax3.set_title('Relationship between Loudness and Time Signature', size=18, color='gold')\nax4.set_title('Relationship between Speechiness and Time Signature', size=18, color='gold')\nax5.set_title('Relationship between Valence and Time Signature', size=18, color='gold')\nax6.set_title('Relationship between Liveness and Time Signature', size=18, color='gold')\nax7.set_title('Relationship between Tempo and Time Signature', size=18, color='gold')\nax8.set_title('Relationship between Acousticness and Time Signature', size=18, color='gold')\nax9.set_title('Relationship between Song Duration(ms) and Time Signature', size=18, color='gold')\n\nplt.show()","ef16537f":"cols = train.columns.tolist()\nmiss_dict = {i: round(train[i].isnull().mean()*100,2) for i in cols}","7b32850e":"missing = pd.DataFrame(miss_dict, index=['percent'])\nmissing = missing.T.reset_index()\nmissing = missing[missing['percent'] > 0]\nmissing.sort_values('percent', ascending=False, inplace=True)\n\n\nfig, ax = plt.subplots(figsize=(20, 5), facecolor='#2b2b2b')\nax = sns.barplot(data=missing, x='percent', y='index', palette='crest_r')\n\n\nfor ele in [ax]:\n    ele.set_facecolor('#2b2b2b')\n    ele.tick_params(axis='x', colors='white', size=8)\n    ele.tick_params(axis='y', colors='white', size=8)\n    for i in ['left', 'bottom']:\n        ele.spines[i].set_color('skyblue')\n        ele.spines[i].set_linewidth(3)\n    for i in ['right', 'top']:\n        ele.spines[i].set_visible(False)\n    ele.grid(alpha=0.2, ls='-.')\n    ele.set_xlabel('Percent', fontsize=16, color='powderblue')\n\nax.set_ylabel('Features', fontsize=16, color='powderblue')\nax.set_title('Percentange of missing values', size=18, color='gold')\n\nfor i, v in enumerate(missing.percent):\n    plt.text(v+0.05, i+.01, str(v) + '%', color = 'khaki', fontweight = 'bold')\n\nplt.show()","74e3caa0":"na_cols = ['song_duration_ms', 'liveness', 'key', 'danceability', 'acousticness', 'instrumentalness', 'energy', 'loudness']\n\ntrain['n_missing'] = train[na_cols].isna().sum(axis=1)\ntest['n_missing'] = test[na_cols].isna().sum(axis=1)","03771410":"missing_counts = train.n_missing.value_counts().sort_values(ascending=True)\n\nfig, ax = plt.subplots(figsize=(20, 5), facecolor='#2b2b2b')\nax = sns.barplot(data=missing_counts, y=missing_counts.index, x=missing_counts.values, palette='Greens', orient='h')\n\n\nfor ele in [ax]:\n    ele.set_facecolor('#2b2b2b')\n    ele.tick_params(axis='x', colors='white', size=8)\n    ele.tick_params(axis='y', colors='white', size=8)\n    for i in ['left', 'bottom']:\n        ele.spines[i].set_color('skyblue')\n        ele.spines[i].set_linewidth(0.1)\n    for i in ['right', 'top']:\n        ele.spines[i].set_visible(False)\n    ele.grid(alpha=0.2, ls='-.')\n    ele.set_xlabel('Percent', fontsize=16, color='powderblue')\n    \nax.set_xticklabels(ax.get_xticks(), fontsize=14)\nax.set_yticklabels(ax.get_yticks(), fontsize=14)\n\nax.set_ylabel('Count', fontsize=16, color='powderblue')\nax.set_title('Count of missing values per row', size=18, color='gold')\n\nfor i, v in enumerate(missing_counts.values):\n    plt.text(v+100, i+0.13, str(v), color = 'khaki', fontweight = 'bold')\n    \nplt.show()","32dda1ba":"#Imputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n#Metrics\nfrom sklearn.metrics import roc_auc_score\n\n#Undersampler\nfrom imblearn.under_sampling import RandomUnderSampler","fe79f824":"iterative_imp = IterativeImputer(max_iter=1000)\nimp_cols = [i for i in train.columns.to_list() if i not in ['n_missing', 'kfold', 'id']]\n\ntrain_imp = iterative_imp.fit_transform(train[imp_cols])\n\ndf_train = pd.DataFrame(train_imp, columns=imp_cols)","e655db35":"X = df_train.copy()\ny = X.pop('song_popularity')\n\nundersample = RandomUnderSampler(sampling_strategy=1)\nX_res, y_res= undersample.fit_resample(X, y)","4cd24afd":"y_res = y_res.reset_index()\ny_res.columns = ['id', 'song_popularity']\n\nnew_train = X_res.copy()\nnew_train = new_train.reset_index()\nnew_train = new_train.rename(columns = {'index':'id'})\n\nnew_train = new_train.merge(y_res, on='id', how='left')\nnew_train.head(2)","c78dcfed":"new_train.shape","312cdc48":"from sklearn.model_selection import StratifiedKFold","061f0033":"X = new_train.copy()\ny = X.pop('song_popularity')\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X, y)):\n    new_train.loc[valid_indicies, \"kfold\"] = fold\n    \n    \nnew_train.to_csv(\"SongP_5Fold.csv\", index=False)","0ce95798":"from sklearn.preprocessing import PowerTransformer\nfrom lightgbm import LGBMRegressor","19303b12":"df = pd.read_csv('.\/SongP_5Fold.csv')\ndf.head()","e10c2eb7":"imp_cols = [i for i in train.columns.to_list() if i not in ['song_popularity', 'n_missing', 'kfold', 'id']]\n\nfinal_test_preds = []\nscores = []\n\nfor fold in range(5):\n    xtrain = df[df['kfold'] != fold].reset_index(drop=True)\n    xvalid = df[df['kfold'] == fold].reset_index(drop=True)\n    xtest = test.copy()\n    \n    ytrain = xtrain.pop('song_popularity')\n    yvalid = xvalid.pop('song_popularity')\n    \n    xtrain = xtrain[imp_cols]\n    xvalid = xvalid[imp_cols]\n    \n    valid_id = xvalid.index.values.tolist()\n    \n    \n    iterative_imp = IterativeImputer(max_iter=1000)\n\n    train_imp = iterative_imp.fit_transform(xtrain[imp_cols])\n    valid_imp = iterative_imp.fit_transform(xvalid[imp_cols])\n    test_imp = iterative_imp.transform(xtest[imp_cols])\n\n    x_train = pd.DataFrame(train_imp, columns=imp_cols)\n    x_valid = pd.DataFrame(valid_imp, columns=imp_cols)\n    x_test = pd.DataFrame(test_imp, columns=imp_cols)\n    \n    \n    pt = PowerTransformer(method = 'yeo-johnson')\n    x_train[imp_cols] = pt.fit_transform(x_train[imp_cols])\n    x_valid[imp_cols] = pt.transform(x_valid[imp_cols])\n    x_test[imp_cols] = pt.transform(x_test[imp_cols])\n    \n    \n    lgb_params={\n                \"task\": \"train\",\n                \"boosting_type\": \"gbdt\",\n                \"objective\": \"binary\",\n                'subsample': 0.95312,\n                'learning_rate': 0.001635,\n                \"max_depth\": 3,\n                \"feature_fraction\": 0.2256038826485174,\n                \"bagging_fraction\": 0.7705303688019942,\n                \"min_child_samples\": 290,\n                \"reg_alpha\": 14.68267919457715,\n                \"reg_lambda\": 66.156,\n                \"max_bin\": 772,\n                \"min_data_per_group\": 177,\n                \"bagging_freq\": 1,\n                \"cat_smooth\": 96,\n                \"cat_l2\": 17,\n                \"verbosity\": -1,\n                'random_state':42,\n                'n_estimators':5000,\n                'colsample_bytree':0.1107,\n    }\n    \n    model = LGBMRegressor(**lgb_params, verbose=False)\n    model.fit(x_train, ytrain)\n    preds_valid = model.predict(x_valid)\n    \n    score = roc_auc_score(yvalid, preds_valid)\n    scores.append(score)\n    \n    preds_test = model.predict(x_test[imp_cols])\n    final_test_preds.append(preds_test)\n    \n    print(f\"fold: {fold},roc: {score}\")\n    ","74c760c5":"final_preds = np.mean(np.column_stack(final_test_preds), axis=1)\nsubmit = submission.copy()\nsubmit['song_popularity'] = final_preds\nsubmit","2ca9a545":"submit.to_csv('submit_undersample.csv', index=False)\nprint(\"--Done--\")","0982447d":"# Visualizing NaN values","5f6af155":"## Thank you for taking your time to read this. \n\n> Please upvote if you have liked it or you have learned something new. Any feedback is appreciated. \n\n**I look forward to keep improving this**","d39c83bd":"#### Adding a column `n_missing` that helps count the number of missing values in a single row of data","6639b39c":"# Importing libraries for Under Sampling","e3ce441f":"## Importing EDA libraries","8687c38f":"# Running cross-validation on the training set","0eb5a380":"Observations:\n- `Loudness` and `Energy` are positively co-related\n- `Loudness` and `Acousticness` are negatively co-related\n- `Energy` and `Acousticness` are negatively co-related\n- `Valence` and `Danceability` are positvely co-related to some extent\n- `Valence` and `Loudness` are positvely co-related to some extent\n","56abf936":"#### Using Random UnderSampler (suggestion to try and experiment others too)","32ca7be0":"# Introduction\n\n Before I begin a massive thanks to -\n1. [Martin](https:\/\/www.kaggle.com\/headsortails) for his *EDA notebook*. \n2. [Rob](https:\/\/www.kaggle.com\/robikscube) for his notebook on *How to work with NaN values*.\n3. [Abhishek](https:\/\/www.kaggle.com\/abhishek) for organizing the competion. \n\nAnd lastly, all of you participants who have unified to work and help grow the community, constantly finding solutions to improve the way we learn. \n\n**P.S : If this helped you in any way, I would appreciate an UPVOTE, feel free to leave any comments too. **","e3b45f81":"# In-Depth relation with Categorical features and Continuous Features","cab66714":"# Creating the model - Importing Libraries\n\n**Note:** The Hyperparameters are used from [this notebook by Yashwanth Gali](https:\/\/www.kaggle.com\/yaswanthgali\/model-blending). This is a Model Blending notebook take a look and you can experiment more on it.","e65aa9ff":"#### Imputing missing values before Undersampling","044466a6":"# Basic EDA\n\n> Defining a common function to plot all continious data","d35f7945":"# Co-relation Heatmap"}}