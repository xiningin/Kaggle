{"cell_type":{"97740bcf":"code","3ef808ab":"code","289c044b":"code","28fae5d4":"code","bd686b68":"code","dbbebb32":"code","f5d03cc9":"code","d25d02d5":"code","965446e2":"code","445ac028":"code","d369d88b":"code","3baa9022":"code","1d2776d3":"code","7eab6c1b":"code","737317a5":"code","b0c4dd70":"code","f0891669":"code","fbd4d88e":"code","c0e79f2d":"code","60ff84f9":"code","cd3bca94":"code","0448d71e":"code","7941c9c4":"code","41bd62f1":"markdown","39a38bbf":"markdown","4d823582":"markdown","095d640a":"markdown","63da07c5":"markdown","aa2d46f0":"markdown","1f2e41d2":"markdown","c8412c72":"markdown","49c99574":"markdown","877d2e61":"markdown"},"source":{"97740bcf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ef808ab":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nsns.set()","289c044b":"sns.__version__","28fae5d4":"import warnings\nwarnings.filterwarnings('ignore')","bd686b68":"columns = 'age,\\\nworkclass,\\\nfnlwgt,\\\neducation,\\\neducation-num,\\\nmarital-status,\\\noccupation,\\\nrelationship,\\\nrace,\\\nsex,\\\ncapital-gain,\\\ncapital-loss,\\\nhours-per-week,\\\nnative-country,\\\nsalary'","dbbebb32":"Train_set = pd.read_csv('\/kaggle\/input\/adult-dataset\/adult.data', header=None, names=columns.split(','))\nTest_set = pd.read_csv('\/kaggle\/input\/adult-dataset\/adult.test', header=None, skiprows=[0] , names=columns.split(','))\n\nTrain_set.head(3)","f5d03cc9":"Test_set.head(3)","d25d02d5":"print('Train_set shape =',Train_set.shape)\nprint('Test_set shape =',Test_set.shape)","965446e2":"for data in [Train_set, Test_set]:\n    for col in data.columns:\n        try:\n            data[col] = data[col].str.strip()\n        except:\n            continue\nTest_set['salary'] = Test_set['salary'].str[:-1]","445ac028":"below50K = sns.color_palette(\"Set2\")[0]\nabove50K = sns.color_palette(\"Set2\")[1]","d369d88b":"sns.countplot(data=Train_set, x='salary', palette={'<=50K':below50K, '>50K':above50K})\nplt.show()","3baa9022":"#sns.histplot(data=Train_set_balanced, x='age', hue='salary', kde=True, palette={'<=50K':below50K, '>50K':above50K})\nfig, ax = plt.subplots()\nax.hist(Train_set[Train_set['salary']=='<=50K']['age'],label='<=50K', alpha=0.4, color=below50K, density=True, bins=30)\nax.hist(Train_set[Train_set['salary']=='>50K']['age'],label='>50K',alpha=0.4, color=above50K, density=True, bins=30)\nTrain_set[Train_set['salary']=='<=50K']['age'].plot(kind='kde', ax=ax, color=below50K, label='')\nTrain_set[Train_set['salary']=='>50K']['age'].plot(kind='kde', ax=ax, color=above50K, label='')\nax.set_xlim(0,90)\nax.set_xlabel('Age')\nplt.legend()\nplt.show()","1d2776d3":"for col in Train_set.columns:\n    try:\n        Train_set[col] is str\n        print(Train_set[col].value_counts())\n    except:\n        continue","7eab6c1b":"Train_set.replace('?', np.nan, inplace=True)\nTest_set.replace('?', np.nan, inplace=True)","737317a5":"Train_set.isnull().sum()","b0c4dd70":"Test_set.isnull().sum()","f0891669":"Train_set_not_null = Train_set.dropna(axis=0)\nTest_set_not_null = Test_set.dropna(axis=0)\n\nprint('Train not null shape =', Train_set_not_null.shape)\nprint('Test not null shape =', Test_set_not_null.shape)","fbd4d88e":"'''\nage: continuous\nworkclass: OHE\nfnlwgt: continuous\neducation:  OHE\neducation-num: continuous.\nmarital-status: OHE\noccupation: OHE\nrace: OHE\nsex: OHE\ncapital-gain: continuous.\ncapital-loss: continuous.\nhours-per-week: continuous.\nnative-country: OHE\n'''\nfrom sklearn.preprocessing import OneHotEncoder , LabelEncoder , StandardScaler\nfrom sklearn.compose import make_column_transformer, ColumnTransformer\nfrom sklearn.pipeline import make_pipeline, Pipeline\n\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier \nfrom sklearn.metrics import confusion_matrix, classification_report","c0e79f2d":"X_train = Train_set_not_null.drop('salary', axis=1)\nY_train = Train_set_not_null.salary","60ff84f9":"X_test = Test_set_not_null.drop('salary', axis=1)\nY_test = Test_set_not_null.salary","cd3bca94":"# Use ColumnTransformer to One-Hot encode categorical columns and scale the continuous columns\nct = ColumnTransformer(\n    [(\"one hot encode\",OneHotEncoder(sparse=False),[1,3,5,6,7,8,9,13]),\n     (\"scale\", StandardScaler(), [0, 2,4,10,11,12])],\n    remainder='passthrough')\n\n# Also encode the target\nle = LabelEncoder()\nY_train = le.fit_transform(Y_train)\nY_test = le.transform(Y_test)","0448d71e":"estimators = [ ('logistic regression', LogisticRegression(max_iter=1000)), ('Decision tree',DecisionTreeClassifier()), \n              ('Random forest', RandomForestClassifier()), ('Gradient boosting',GradientBoostingClassifier())]\n\npipelines = dict()\nfor estimator in estimators:\n    pipe = Pipeline([('columns transform', ct),estimator])\n    pipe.fit(Train_set_not_null.drop('salary',axis=1), Y_train)\n    pipelines[estimator[0]]=pipe","7941c9c4":"for each in pipelines:\n    print('---------------------'+each+'---------------------')\n    y_pred = pipelines[each].predict(Test_set_not_null)\n    print(confusion_matrix(y_pred, Y_test))\n    print(classification_report(y_pred , Y_test))\n    print('\\n')","41bd62f1":"# Importing data","39a38bbf":"# Cleaning","4d823582":"# Building a couple models","095d640a":"### Peek the target, Oh it's highly imbalanced!","63da07c5":"There are only missing data in 'workclass', 'occupation', native-country' categorical columns.\n### Drop rows that contain missingdata","aa2d46f0":"# In this Notebook, \nI will try to build a couple of machine-learning model to predict whether income exceeds $50K\/yr based on census data. Also known as \"Census Income\" dataset extracted by Barry Becker from the 1994 Census database.\n\n#### Prediction task is to determine whether a person makes over 50K a year.","1f2e41d2":"### See if it has some missing value","c8412c72":"### It has some interesting relationship between age and salary","49c99574":"age: continuous <br>\nworkclass: OHE <br>\nfnlwgt: continuous <br>\neducation:  OHE <br>\neducation-num: continuous. <br>\nmarital-status: OHE <br>\noccupation: OHE <br>\nrelationship: OHE <br>\nrace: OHE <br>\nsex: OHE <br>\ncapital-gain: continuous. <br>\ncapital-loss: continuous. <br>\nhours-per-week: continuous. <br>\nnative-country: OHE <br>","877d2e61":"### Select the unique colors for our target"}}