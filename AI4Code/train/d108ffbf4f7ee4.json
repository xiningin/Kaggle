{"cell_type":{"cb32ea65":"code","4f50e2e6":"code","03be231d":"code","f482b4bb":"code","f207064d":"code","1b2ce00e":"code","b069ba54":"code","12484dd6":"code","d6653106":"code","6d48d18c":"code","7903d40e":"code","113e403c":"code","05dd184d":"code","432e2157":"code","37e825ef":"code","056f5100":"code","89e0aab5":"code","67ab49f7":"code","d1ecf5ce":"code","ff11f294":"code","cb4405c6":"code","372eddf1":"code","f527deac":"code","971caf23":"code","5724c1f9":"code","451aefb9":"code","261d020d":"markdown","5afdd1f4":"markdown","bfd919ba":"markdown","2c3ab950":"markdown","39d3fbba":"markdown","f569b35f":"markdown","375a33c4":"markdown","0800cf8c":"markdown","34ea661f":"markdown","903c21ca":"markdown","17a0e191":"markdown","637bb3b8":"markdown","7d4fcadd":"markdown","ac0adb03":"markdown","f3acc89a":"markdown"},"source":{"cb32ea65":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport keras\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","4f50e2e6":"!unzip -q '..\/input\/train.zip'\n!unzip -q '..\/input\/test1.zip'","03be231d":"filenames = os.listdir(\".\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\ndf.head()","f482b4bb":"df['category'].value_counts().plot.bar()","f207064d":"sample = random.choice(filenames)\nimage = load_img(\".\/train\/\"+sample)\nplt.imshow(image)","1b2ce00e":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.applications import VGG16\nfrom keras.models import Model\n\nimage_size = 224\ninput_shape = (image_size, image_size, 3)\n\nepochs = 5\nbatch_size = 16\n\npre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n    \nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\n\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n    \nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n    \n# Flatten the output layer to 1 dimension\nx = GlobalMaxPooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = Model(pre_trained_model.input, x)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","b069ba54":"train_df, validate_df = train_test_split(df, test_size=0.1)\ntrain_df = train_df.reset_index()\nvalidate_df = validate_df.reset_index()\n\n# validate_df = validate_df.sample(n=100).reset_index() # use for fast testing code purpose\n# train_df = train_df.sample(n=1800).reset_index() # use for fast testing code purpose\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]","12484dd6":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \".\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(image_size, image_size),\n    batch_size=batch_size\n)","d6653106":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \".\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(image_size, image_size),\n    batch_size=batch_size\n)","6d48d18c":"example_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \".\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary'\n)\nplt.figure(figsize=(12, 12))\nfor i in range(0, 9):\n    plt.subplot(3, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","7903d40e":"epochs=2","113e403c":"#os.makedirs(\"keras_saved_model\", exist_ok=True)\ncheckpoint_filepath = 'vgg16dogcat_ep1_model.h5'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=False, # else, error\n    monitor='val_loss',\n    save_best_only=True)\n\n# fine-tune the model\nhistory = model.fit_generator(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=[model_checkpoint_callback]\n)","05dd184d":"loss, accuracy = model.evaluate_generator(validation_generator, total_validate\/\/batch_size, workers=12)\nprint(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))","432e2157":"model.save(\"vgg16_epoch1_dogcat.h5\")","37e825ef":"def plot_model_history(model_history, acc='acc', val_acc='val_acc'):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    axs[0].plot(range(1,len(model_history.history[acc])+1),model_history.history[acc])\n    axs[0].plot(range(1,len(model_history.history[val_acc])+1),model_history.history[val_acc])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history[acc])+1),len(model_history.history[acc])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    \nplot_model_history(history)","056f5100":"Y_val = validate_df['category']\ny_pred =  model.predict_generator(validation_generator)","89e0aab5":"threshold = 0.5\ny_final = np.where(y_pred > threshold, 1,0)","67ab49f7":"y_final.size","d1ecf5ce":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n# Predict the values from the validation dataset\n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_val, y_final) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","ff11f294":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(Y_val, y_final, target_names=['0','1'])\n\nprint(report)","cb4405c6":"test_filenames = os.listdir(\".\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","372eddf1":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \".\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    batch_size=batch_size,\n    target_size=(image_size, image_size),\n    shuffle=False\n)","f527deac":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))\nthreshold = 0.5\ntest_df['category'] = np.where(predict > threshold, 1,0)","971caf23":"sample_test = test_df.sample(n=9).reset_index()\nsample_test.head()\nplt.figure(figsize=(12, 12))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\".\/test1\/\"+filename, target_size=(256, 256))\n    plt.subplot(3, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')')\nplt.tight_layout()\nplt.show()","5724c1f9":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission_13010030.csv', index=False)\n\nplt.figure(figsize=(10,5))\nsns.countplot(submission_df['label'])\nplt.title(\"(Test data)\")","451aefb9":"!rm -r '.\/train'\n!rm -r '.\/test1'","261d020d":"# Prepare Test and Train Data","5afdd1f4":"# Submission","bfd919ba":"# Prepare Traning Data","2c3ab950":"# Predict","39d3fbba":"# Create Testing Generator","f569b35f":"# Fit Model","375a33c4":"# See sample image","0800cf8c":"### See Total In count","34ea661f":"# Build Model","903c21ca":"# Traning Generator","17a0e191":"# See predicted result","637bb3b8":"# See sample generated images","7d4fcadd":"# Validation Generator","ac0adb03":"# Import Library","f3acc89a":"# Prepare Testing Data"}}