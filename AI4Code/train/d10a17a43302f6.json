{"cell_type":{"126e9360":"code","4f25a521":"code","3ff92aee":"code","bf8ef49f":"code","02e1cb18":"code","eb4422d7":"code","557752f1":"code","10f15ce5":"code","22182ad4":"code","7dd13897":"code","e8bb86a8":"code","c4c46de4":"code","bf4dea49":"code","07a272dd":"code","a58262ee":"code","c16d5f5e":"markdown","06891b63":"markdown","6e4d839c":"markdown","8f3168c4":"markdown","145157b3":"markdown","baab369b":"markdown","f4163ef6":"markdown","602e0759":"markdown","f867aeff":"markdown","49e0c54e":"markdown","f992ee7f":"markdown","ab346c37":"markdown","57229384":"markdown","a3448af9":"markdown","590a3d8d":"markdown","133478d9":"markdown"},"source":{"126e9360":"from __future__ import division\nimport numpy as np\nimport os\nimport glob\n\nfrom random import *\nfrom PIL import Image\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\nfrom keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD, Adam, RMSprop","4f25a521":"d = {}\nfrom subprocess import check_output\n# print(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n# forms = pd.read_csv('..\/input\/iam-handwriting-top50\/forms_for_parsing.txt', header=None)\n# print(forms.head)\nwith open('..\/input\/forms_for_parsing.txt') as f:\n    for line in f:\n        key = line.split(' ')[0]\n        writer = line.split(' ')[1]\n        d[key] = writer\nprint(len(d.keys()))","3ff92aee":"tmp = []\ntarget_list = []\n\npath_to_files = os.path.join('..\/input\/data_subset\/data_subset', '*')\nfor filename in sorted(glob.glob(path_to_files)):\n#     print(filename)\n    tmp.append(filename)\n    image_name = filename.split('\/')[-1]\n    file, ext = os.path.splitext(image_name)\n    parts = file.split('-')\n    form = parts[0] + '-' + parts[1]\n    for key in d:\n        if key == form:\n            target_list.append(str(d[form]))\n\nimg_files = np.asarray(tmp)\nimg_targets = np.asarray(target_list)\nprint(img_files.shape)\nprint(img_targets.shape)","bf8ef49f":"for filename in img_files[:3]:\n    img=mpimg.imread(filename)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img, cmap ='gray')","02e1cb18":"encoder = LabelEncoder()\nencoder.fit(img_targets)\nencoded_Y = encoder.transform(img_targets)\n\nprint(img_files[:5], img_targets[:5], encoded_Y[:5])","eb4422d7":"train_files, rem_files, train_targets, rem_targets = train_test_split(\n        img_files, encoded_Y, train_size=0.66, random_state=52, shuffle= True)\n\nvalidation_files, test_files, validation_targets, test_targets = train_test_split(\n        rem_files, rem_targets, train_size=0.5, random_state=22, shuffle=True)\n\nprint(train_files.shape, validation_files.shape, test_files.shape)\nprint(train_targets.shape, validation_targets.shape, test_targets.shape)","557752f1":"# Generator function for generating random crops from each sentence\n\n# # Now create generators for randomly cropping 113x113 patches from these images\n\nbatch_size = 16 #16\nnum_classes = 50\n\n# Start with train generator shared in the class and add image augmentations\ndef generate_data(samples, target_files,  batch_size=batch_size, factor = 0.1 ):\n    num_samples = len(samples)\n    from sklearn.utils import shuffle\n    while 1: # Loop forever so the generator never terminates\n        for offset in range(0, num_samples, batch_size):\n            batch_samples = samples[offset:offset+batch_size]\n            batch_targets = target_files[offset:offset+batch_size]\n\n            images = []\n            targets = []\n            for i in range(len(batch_samples)):\n                batch_sample = batch_samples[i]\n                batch_target = batch_targets[i]\n                im = Image.open(batch_sample)\n                cur_width = im.size[0]\n                cur_height = im.size[1]\n\n                # print(cur_width, cur_height)\n                height_fac = 113 \/ cur_height\n\n                new_width = int(cur_width * height_fac)\n                size = new_width, 113\n\n                imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n                now_width = imresize.size[0]\n                now_height = imresize.size[1]\n                # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n\n                avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n\n                # Pick random x%\n                pick_num = int(len(avail_x_points)*factor)\n\n                # Now pick\n                random_startx = sample(avail_x_points,  pick_num)\n\n                for start in random_startx:\n                    imcrop = imresize.crop((start, 0, start+113, 113))\n                    images.append(np.asarray(imcrop))\n                    targets.append(batch_target)\n\n            # trim image to only see section with road\n            X_train = np.array(images)\n            y_train = np.array(targets)\n\n            #reshape X_train for feeding in later\n            X_train = X_train.reshape(X_train.shape[0], 113, 113, 1)\n            #convert to float and normalize\n            X_train = X_train.astype('float32')\n            X_train \/= 255\n\n            #One hot encode y\n            y_train = to_categorical(y_train, num_classes)\n            yield shuffle(X_train, y_train)","10f15ce5":"train_generator = generate_data(train_files, train_targets, batch_size=batch_size, factor = 0.3)\nvalidation_generator = generate_data(validation_files, validation_targets, batch_size=batch_size, factor = 0.3)\ntest_generator = generate_data(test_files, test_targets, batch_size=batch_size, factor = 0.1)","22182ad4":"def resize_image(image):\n    import tensorflow as tf\n    return tf.image.resize_images(image,[56,56])\n\n# Function to resize image to 64x64\nrow, col, ch = 113, 113, 1\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), input_shape=(row, col, ch)))\n\n# Resise data within the neural network\nmodel.add(Lambda(resize_image))  #resize images to allow for easy computation\n\n# CNN model - Building the model suggested in paper\n\nmodel.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2,2), padding='same', name='conv1')) #96\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool1'))\n\nmodel.add(Convolution2D(filters= 64, kernel_size =(3,3), strides= (1,1), padding='same', name='conv2'))  #256\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool2'))\n\nmodel.add(Convolution2D(filters= 128, kernel_size =(3,3), strides= (1,1), padding='same', name='conv3'))  #256\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool3'))\n\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(512, name='dense1'))  #1024\n# model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, name='dense2'))  #1024\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes,name='output'))\nmodel.add(Activation('softmax'))  #softmax since output is within 50 classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n\n","7dd13897":"model.summary()","e8bb86a8":"nb_epoch = 1\n\nsamples_per_epoch = 3268\nnb_val_samples = 842\n\n# #save every model using Keras checkpoint\nfrom keras.callbacks import ModelCheckpoint\n#filepath=\"check-{epoch:02d}-{val_loss:.4f}.hdf5\"\nfilepath=\"low_loss.hdf5\"\ncheckpoint = ModelCheckpoint(filepath= filepath, verbose=1, save_best_only=False)\ncallbacks_list = [checkpoint]\n\n# #Model fit generator\nhistory_object = model.fit_generator(train_generator, steps_per_epoch = samples_per_epoch\/batch_size,\n                                      validation_data=validation_generator,\n                                      validation_steps=nb_val_samples, epochs=nb_epoch, verbose=1, callbacks=callbacks_list)","c4c46de4":"model.load_weights('low_loss.hdf5')\nscores = model.evaluate_generator(test_generator,842) \nprint(\"Accuracy = \", scores[1])","bf4dea49":"images = []\nfor filename in test_files[:50]:\n     im = Image.open(filename)\n     cur_width = im.size[0]\n     cur_height = im.size[1]\n\n     #print(cur_width, cur_height)\n     height_fac = 113 \/ cur_height\n\n     new_width = int(cur_width * height_fac)\n     size = new_width, 113\n\n     imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n     now_width = imresize.size[0]\n     now_height = imresize.size[1]\n     # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n\n     avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n\n     # Pick random x%\n     factor = 0.1\n     pick_num = int(len(avail_x_points)*factor)\n    \n     random_startx = sample(avail_x_points,  pick_num)\n\n     for start in random_startx:\n         imcrop = imresize.crop((start, 0, start+113, 113))\n         images.append(np.asarray(imcrop))\n        \n     X_test = np.array(images)\n    \n     X_test = X_test.reshape(X_test.shape[0], 113, 113, 1)\n     #convert to float and normalize\n     X_test = X_test.astype('float32')\n     X_test \/= 255\n     shuffle(X_test)\n\n     #print(X_test.shape)","07a272dd":"predictions = model.predict(X_test, verbose =1)\n\nprint(predictions.shape)\npredicted_writer = []\nfor pred in predictions:\n    predicted_writer.append(np.argmax(pred))\n    #print(len(predicted_writer))","a58262ee":"writer_number = 18\ntotal_images =10\ncounter = 0\nfor i in range(len(predicted_writer)\/\/10):\n     #if predicted_writer[i] == writer_number:\n     image = X_test[i].squeeze()\n     plt.figure(figsize=(2,2))\n     plt.imshow(image, cmap ='gray')","c16d5f5e":"Splitting of data into training and validation sets for cross validation with 4:1:1 ratio.","06891b63":"### Predictions","6e4d839c":"### Visualization of images\nLet's visualize the image data.","8f3168c4":"### Performance Metrics\n\nLet's now test our model for calculating accuracy.","145157b3":"A Keras Model is built. Summary of the model is printed below.","baab369b":"References\n\n1. http:\/\/u-pat.org\/ICDAR2017\/program_competitions.php\n1. https:\/\/towardsdatascience.com\/handwriting-recognition-using-tensorflow-and-keras-819b36148fe5\n1. https:\/\/github.com\/priya-dwivedi\/Deep-Learning\/blob\/master\/handwriting_recognition\/English_Writer_Identification.ipynb\n1. https:\/\/github.com\/TejasReddy9\/handwriting_cnn\/blob\/master\/neural_net_model.ipynb\n1. https:\/\/tejasreddy9.github.io\/handwriting_cnn\n1. https:\/\/www.kaggle.com\/tejasreddy\/iam-handwriting-top50\n1. http:\/\/www.fki.inf.unibe.ch\/databases\/iam-handwriting-database\n1. https:\/\/www.kaggle.com\/tejasreddy\/offline-handwriting-recognition-cnn","f4163ef6":"# Handwriting Recognition using CNN\n\n\n## Classification Model\n\nThis model is language independent as we dont consider the letters or words in particular, but patches of image size 113x113 are extracted and fit into the model for learning. \n\n## Results\n\n78% accuracy on test data.\n","602e0759":"### Imports\nImport these packages to the project.","f867aeff":"These are the forms in the dataset for quick access from manipulation of the file names on each column. Let's create a dictionary with form and writer mapping.","49e0c54e":"### Insights","f992ee7f":"All file-names list and target-writer names list are created.","ab346c37":"Load in test data.","57229384":"### Training the model\n\nLet's take 8 epochs. And the following specifications.","a3448af9":"For training and testing,  generator function is called with the intent of making train and test generator data.","590a3d8d":"### Input to the model\n\nAs said before, we take patches of data, each of size 113x133. A generator function is implemented for that purpose.","133478d9":"Good to observe that there are no categorical data. So, normalisation is done using label encoder."}}