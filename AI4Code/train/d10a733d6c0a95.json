{"cell_type":{"360b8ff4":"code","77918041":"code","48cb3954":"code","9303b1ba":"code","16d90047":"code","2c568de2":"code","39f3689f":"code","550e161a":"code","6414ba67":"code","b2912872":"code","adf2976d":"code","c9f3d52e":"code","bd82c4cc":"code","757dbc1d":"code","bc18c2ba":"code","3577f343":"code","d67090ef":"code","ad770005":"code","39313b80":"code","307f4426":"code","56d77e0b":"markdown"},"source":{"360b8ff4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","77918041":"import cv2\nfrom tqdm import tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","48cb3954":"from keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.utils import plot_model\nfrom keras.models import Sequential\nfrom keras.layers import MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers.merge import concatenate\nfrom keras.preprocessing.image import ImageDataGenerator","9303b1ba":"import gc","16d90047":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","2c568de2":"train.head()","39f3689f":"train['diagnosis'].hist()\ntrain['diagnosis'].value_counts()","550e161a":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n        img = cv2.resize(img,(28,28),interpolation=cv2.INTER_CUBIC)\n        \n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(train)","6414ba67":"images = []\npaths = train.id_code\nfor path in paths :\n    img = cv2.imread(f'..\/input\/train_images\/{path}.png')\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.resize(img,(112,112),interpolation=cv2.INTER_CUBIC).tolist()\n    images.append(img)","b2912872":"gc.collect()","adf2976d":"model = Sequential()\nmodel.add(ZeroPadding2D((1,1),input_shape=(112,112,1)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512,kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))","c9f3d52e":"images = np.array(images)","bd82c4cc":"images.shape","757dbc1d":"trainx, testx, trainy, testy = train_test_split(images,train.diagnosis,test_size=0.2)","bc18c2ba":"trainy= to_categorical(trainy)\ntesty = to_categorical(testy)","3577f343":"trainx= trainx.reshape(-1, 112, 112,1)\ntestx= testx.reshape(-1, 112, 112,1)","d67090ef":"del images\ngc.collect()","ad770005":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","39313b80":"model.fit(trainx, trainy,\n           epochs=10, batch_size=100, verbose=2)","307f4426":"model.evaluate(testx, testy,\n            batch_size=100)","56d77e0b":"**This kernel implements VGG on APTOS data **"}}