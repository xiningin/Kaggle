{"cell_type":{"7b90787c":"code","ef1ad126":"code","aa9f113b":"code","38a106f0":"code","e87a43b1":"code","2b4bec77":"code","fd75c649":"code","5a3c234d":"code","630af60f":"code","a4d00964":"code","b535b141":"code","3309314f":"code","86a22e8a":"code","59a9cd4f":"code","7bbd7f91":"code","4a86e4e1":"code","05e245e4":"code","b268ff8e":"code","6b36cea3":"code","9d4d762c":"code","f47727a6":"code","7868bcb2":"code","4c8779ab":"code","a77169c9":"code","470606ab":"code","1ce61327":"code","18c0c8b2":"code","01e0d89f":"code","8f10a203":"code","d43fb935":"code","69bd78e6":"code","2410ea19":"code","84872b31":"code","e169b296":"code","18c773d0":"code","dd1fc24b":"code","462f9a9f":"code","13833d04":"code","a10c8245":"code","d406eb28":"code","9d4f0462":"code","6f405dbc":"code","7904dd90":"markdown","a6312d4d":"markdown","7c55292f":"markdown","6a4b43c6":"markdown","432020b8":"markdown","5ae6bafd":"markdown","ea3a9d5b":"markdown","854f55d8":"markdown","ac1876e5":"markdown","3f7f4250":"markdown","8120c9d9":"markdown","df069823":"markdown","f561edcf":"markdown","5f699f24":"markdown","8516e215":"markdown","b5752df1":"markdown","167c3f81":"markdown","0d9388d2":"markdown","f0a113a5":"markdown","25312752":"markdown","3bdeaf3c":"markdown","59bde1d7":"markdown","d3dd6d1b":"markdown","34ec2958":"markdown","1aae4bb3":"markdown","619f082a":"markdown","57b790ba":"markdown","7cc78f2a":"markdown","512eed6f":"markdown","af2673c4":"markdown","38a91a08":"markdown"},"source":{"7b90787c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef1ad126":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\n\nfrom catboost import CatBoostRegressor\n\nfrom datetime import datetime\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","aa9f113b":"import warnings\nwarnings.filterwarnings('ignore')","38a106f0":"matplotlib.rcParams.update({'font.size': 14})","e87a43b1":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","2b4bec77":"TRAIN_DATASET_PATH = '\/kaggle\/input\/real-estate-price-prediction-moscow\/train.csv'\nTEST_DATASET_PATH = '\/kaggle\/input\/real-estate-price-prediction-moscow\/test.csv'","fd75c649":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntrain_df.tail()","5a3c234d":"test_df = pd.read_csv(TEST_DATASET_PATH)\ntest_df.tail()","630af60f":"train_df.dtypes","a4d00964":"num_feat = list(train_df.select_dtypes(exclude='object').columns)\nobj_feat = list(train_df.select_dtypes(include='object').columns)\ntrain_df['Id'] = train_df['Id'].astype(str)\ntarget = 'Price'\n\nnum_feat","b535b141":"print('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0440\u0435\u0439\u043d\u0435:', train_df.shape[0])\nprint('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0435\u0441\u0442\u0435:', test_df.shape[0])","3309314f":"train_df.shape[1] - 1 == test_df.shape[1]","86a22e8a":"submission_df = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/sample_submission.csv')","59a9cd4f":"plt.figure(figsize = (16, 8))\n\ntrain_df['Price'].hist(bins=30)\nplt.ylabel('Count')\nplt.xlabel('Price')\n\nplt.title('Target distribution')\nplt.show()","7bbd7f91":"train_df.describe()","4a86e4e1":"train_df.select_dtypes(include='object').columns.tolist()","05e245e4":"train_df['DistrictId'].value_counts()","b268ff8e":"train_df['Ecology_2'].value_counts()","6b36cea3":"train_df['Ecology_3'].value_counts()","9d4d762c":"train_df['Shops_2'].value_counts()","f47727a6":"train_df[list(train_df.select_dtypes(exclude='object').columns)].hist(\n    figsize=(16,16)\n)\nplt.show()","7868bcb2":"train_df.describe().T","4c8779ab":"train_df['Square'].sort_values().round(1)","a77169c9":"train_df['Rooms'].value_counts()","470606ab":"train_df['LifeSquare'].sort_values().round(1)","1ce61327":"train_df['LifeSquare_nan'] = train_df['LifeSquare'].isna() * 1\n\ncondition = (train_df['LifeSquare'].isna()) \\\n             & (~train_df['Square'].isna()) \\\n             & (~train_df['KitchenSquare'].isna())\n        \ntrain_df.loc[condition, 'LifeSquare'] = train_df.loc[condition, 'Square'] \\\n                                            - train_df.loc[condition, 'KitchenSquare'] - 3","18c0c8b2":"train_df['HouseFloor'].value_counts()","01e0d89f":"train_df['KitchenSquare'].value_counts()","8f10a203":"train_df.isna().sum()","d43fb935":"class Data:\n    \n    def __init__(self):\n        \"\"\"\u041a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u044b \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n        self.Square_min = 15\n        self.Square_max = 300\n        \n        self.LifeSquare_min = 10\n        self.LifeSquare_max = 280\n        \n        self.Rooms_min = 1\n        self.Rooms_max = 5\n        \n        self.HouseFloor_min = 1\n        self.HouseFloor_max = 50\n        \n        self.KitchenSquare_min = 3\n        self.KitchenSquare_max = 30\n        \n        self.current_year = datetime.now().year\n        \n        self.medians = None\n        self.DistrictId_value_counts = None\n        self.SquareMeterPrice_by_DistrictId = None\n        self.Healthcare_1_by_DistrictId = None\n        \n        \n    def fit(self, train_df):\n        \n        # \u043c\u0435\u0434\u0438\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\n        self.medians = train_df[['LifeSquare', 'HouseFloor']].median()\n        \n        # \u043f\u043e\u0434\u0441\u0447\u0435\u0442 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0445 \u0440\u0430\u0439\u043e\u043d\u043e\u0432\n        self.DistrictId_value_counts = dict(train_df['DistrictId'].value_counts())\n        \n        # \u043f\u043e\u0434\u0441\u0447\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0439 \u0446\u0435\u043d\u044b \u0437\u0430 \u043c2 \u043f\u043e \u0440\u0430\u0439\u043e\u043d\u0443\n        train_df_temp = train_df.loc[((train_df['Square'] > self.Square_min) & (train_df['Square'] < self.Square_max))]\n        train_df_temp[\"SquareMeterPrice\"] = train_df_temp[\"Price\"] \/ train_df_temp[\"Square\"]\n        self.SquareMeterPrice_by_DistrictId = train_df_temp.groupby('DistrictId', as_index=False)\\\n            .agg({'SquareMeterPrice': 'mean'})\\\n            .rename(columns={'SquareMeterPrice': 'AverageSquareMeterPrice'})\n        \n        # \u043f\u043e\u0434\u0441\u0447\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 Healthcare_1 \u043f\u043e \u0440\u0430\u0439\u043e\u043d\u0443\n        self.Healthcare_1_by_DistrictId = train_df.groupby('DistrictId', as_index=False)\\\n            .agg({'Healthcare_1': 'mean'})\\\n            .rename(columns={'Healthcare_1': 'AverageHealthcare_1'})\n        \n        del train_df_temp\n        \n    def transform(self, train_df):\n        \n        # \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432\n        train_df['HouseFloor'] = train_df['HouseFloor'].fillna(self.medians)\n        \n        # \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\n        \n        # \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n        train_df.loc[(train_df['Square'] > self.Square_max), 'Square'] = self.Square_max\n        train_df.loc[(train_df['Square'] < self.Square_min), 'Square'] = self.Square_min\n        \n        # \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n        train_df.loc[(train_df['LifeSquare'] < self.LifeSquare_min), 'LifeSquare'] = self.LifeSquare_min\n        train_df.loc[(train_df['LifeSquare'] > self.LifeSquare_max), 'LifeSquare'] = self.LifeSquare_max\n        \n        # \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0443\u0445\u043d\u0438\n        train_df.loc[(train_df['KitchenSquare'] < self.KitchenSquare_min), 'KitchenSquare'] = self.KitchenSquare_min\n        train_df.loc[(train_df['KitchenSquare'] > self.KitchenSquare_max), 'KitchenSquare'] = self.KitchenSquare_max\n        \n        # \u0433\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043e\u043c\u0430\n        train_df.loc[(train_df['HouseYear'] > self.current_year), 'HouseYear'] = self.current_year\n        \n        # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442\n        train_df.loc[(train_df['Rooms'] > self.Rooms_max), 'Rooms'] = self.Rooms_max\n        train_df.loc[(train_df['Rooms'] < self.Rooms_min), 'Rooms'] = self.Rooms_min\n        \n        # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439\n        train_df.loc[(train_df['HouseFloor'] < self.HouseFloor_min), 'HouseFloor'] = self.HouseFloor_min\n        train_df.loc[(train_df['HouseFloor'] > self.HouseFloor_max), 'HouseFloor'] = self.HouseFloor_max\n        \n        # \u0435\u0441\u043b\u0438 \u044d\u0442\u0430\u0436 \u0431\u043e\u043b\u044c\u0448\u0435 \u044d\u0442\u0430\u0436\u043d\u043e\u0441\u0442\u0438 \u0434\u043e\u043c\u0430, \u0442\u043e \u043f\u0440\u0438\u0441\u0432\u0430\u0438\u0432\u0430\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u044d\u0442\u0430\u0436 \u043e\u0442 self.HouseFloor_min \u0434\u043e \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u044d\u0442\u0430\u0436\u0430 \u0432 \u0434\u043e\u043c\u0435\n        floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\n        train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor'].apply(lambda x: self.HouseFloor_min if (self.HouseFloor_min == x) else np.random.randint(self.HouseFloor_min, x))\n        \n        # \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439\n        train_df = pd.concat([train_df, pd.get_dummies(train_df['Ecology_2'], prefix='Ecology_2', dtype='int8')], axis=1)\n        train_df = pd.concat([train_df, pd.get_dummies(train_df['Ecology_3'], prefix='Ecology_3', dtype='int8')], axis=1)\n        train_df = pd.concat([train_df, pd.get_dummies(train_df['Shops_2'], prefix='Shops_2', dtype='int8')], axis=1)\n        \n        return train_df\n    \n    def features(self, train_df):\n        \n        # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u043e\u0441\u0442\u0438 \u0440\u0430\u0439\u043e\u043d\u0430\n        train_df['DistrictId_counts'] = train_df['DistrictId'].map(self.DistrictId_value_counts)\n        train_df['DistrictId_counts'].fillna(train_df['DistrictId_counts'].median(), inplace=True)\n        \n        # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u0441\u0440\u0435\u0434\u043d\u0435\u0439 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 \u043c2 \u043f\u043e \u0440\u0430\u0439\u043e\u043d\u0443\n        train_df = train_df.merge(self.SquareMeterPrice_by_DistrictId, on=[\"DistrictId\"], how='left')\n        train_df['AverageSquareMeterPrice'].fillna(train_df['AverageSquareMeterPrice'].median(), inplace=True)\n        \n        # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f Healthcare_1 \u043f\u043e \u0440\u0430\u0439\u043e\u043d\u0443\n        train_df = train_df.merge(self.Healthcare_1_by_DistrictId, on=[\"DistrictId\"], how='left')\n        train_df['AverageHealthcare_1'].fillna(train_df['AverageHealthcare_1'].median(), inplace=True)\n        \n        return train_df","69bd78e6":"data_inst = Data()\n\n# \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\ndata_inst.fit(train_df)\ntrain_df = data_inst.transform(train_df)\ntrain_df = data_inst.features(train_df)\n\n# \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\ntest_df = data_inst.transform(test_df)\ntest_df = data_inst.features(test_df)","2410ea19":"train_df.columns.tolist()","84872b31":"feature_names = ['AverageSquareMeterPrice', 'DistrictId_counts', 'Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor',\n                    'HouseFloor', 'HouseYear', 'Helthcare_2', 'Ecology_1', 'Social_1', 'Social_2', 'Social_3',\n                    'Shops_1', 'Ecology_2_A', 'Ecology_2_B', 'Ecology_3_A', 'Ecology_3_B', 'Shops_2_A', 'Shops_2_B',\n                    'AverageHealthcare_1']\ntarget_name = 'Price'","e169b296":"train_df = train_df[feature_names + [target_name]]\ntest_df = test_df[feature_names + ['Id']]\nX = train_df[feature_names]\ny = train_df[target_name]","18c773d0":"final_model = CatBoostRegressor(\n    silent=True,\n    learning_rate=0.1,\n    iterations=1150,\n    eval_metric='R2',\n    depth=8\n)\n\nfinal_model.fit(X, y)\n\ncv_score = cross_val_score(\n    final_model,\n    X,\n    y,\n    scoring='r2',\n    cv=KFold(\n            n_splits=5,\n            shuffle=True,\n            random_state=42\n    )\n)","dd1fc24b":"print(f'R2: {round(cv_score.mean(), 3)}')","462f9a9f":"feature_importances = pd.DataFrame(\n    zip(X.columns, final_model.get_feature_importance()),\n    columns=['feature_name', 'importance']\n)\n\nfeature_importances.sort_values(by='importance', ascending=False, inplace=True)\nfeature_importances.head(20)","13833d04":"test_df.shape","a10c8245":"test_df","d406eb28":"submit = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/sample_submission.csv')\nsubmit.head()","9d4f0462":"preds_final = pd.DataFrame()\npreds_final['Id'] = test_df['Id'].copy()\n\ntest_df.set_index('Id', inplace=True)\ntest_df = test_df[feature_names]","6f405dbc":"cb_pred_final = final_model.predict(test_df)\n\nsubmission_df['Price'] = cb_pred_final\nsubmission_df.to_csv('cb_pred_final.csv', index=False, encoding='utf-8', sep=',')\n\nsubmission_df.head()","7904dd90":"#### \u0421\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u043a\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043f\u043e \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u0438","a6312d4d":"#### \u0412\u044b\u0431\u0440\u043e\u0441\u044b \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u044e\u0442\u0441\u044f \u0432: HouseYear, KitchenSquare.\n\n#### \u041f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0441 \u0430\u043d\u043e\u043c\u0430\u043b\u044c\u043d\u043e \u0432\u044b\u0441\u043e\u043a\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0443\u0436\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0438\u0442\u044c: HouseFloor, LifeSquare, Rooms, Square.","7c55292f":"\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430\n\n* Id - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b\n* DistrictId - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u0440\u0430\u0439\u043e\u043d\u0430\n* Rooms - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442\n* Square - \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* LifeSquare - \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* KitchenSquare - \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0443\u0445\u043d\u0438\n* Floor - \u044d\u0442\u0430\u0436\n* HouseFloor - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0434\u043e\u043c\u0435\n* HouseYear - \u0433\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043e\u043c\u0430\n* Ecology_1, Ecology_2, Ecology_3 - \u044d\u043a\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* Social_1, Social_2, Social_3 - \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* Healthcare_1, Helthcare_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043e\u0445\u0440\u0430\u043d\u043e\u0439 \u0437\u0434\u043e\u0440\u043e\u0432\u044c\u044f\n* Shops_1, Shops_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043d\u0430\u043b\u0438\u0447\u0438\u0435\u043c \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u043e\u0432, \u0442\u043e\u0440\u0433\u043e\u0432\u044b\u0445 \u0446\u0435\u043d\u0442\u0440\u043e\u0432\n* Price - \u0446\u0435\u043d\u0430 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b","6a4b43c6":"#### \u041e\u0442\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","432020b8":"### \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0430 \u043c\u0435\u0442\u0440\u0438\u043a","5ae6bafd":"#### \u0412 'LifeSquare' \u041f\u043e\u043c\u0438\u043c\u043e \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432 \u0435\u0441\u0442\u044c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438.","ea3a9d5b":"#### \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u0442\u0440\u043e\u043a \u0432 \u0442\u0435\u0441\u0442\u0435 \u0438 \u0442\u0440\u0435\u0439\u043d\u0435","854f55d8":"#### \u041f\u043e\u0438\u0441\u043a \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432","ac1876e5":"#### KitchenSquare","3f7f4250":"#### \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043a\u043b\u0430\u0441\u0441\u0430 Data","8120c9d9":"### \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0438 \u043a\u043b\u0430\u0441\u0441\u044b","df069823":"### \u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f","f561edcf":"#### \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435","5f699f24":"#### LifeSquare","8516e215":"### \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432","b5752df1":"#### HouseFloor","167c3f81":"### \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 CatBoostRegressor","0d9388d2":"### \u041f\u0440\u0435\u0434\u0443\u043f\u0440\u0435\u0436\u0434\u0435\u0438\u044f","f0a113a5":"### \u0421\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0439 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445","25312752":"### \u041f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0430\u043c \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438","3bdeaf3c":"#### Square","59bde1d7":"### \u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 train \u0438 test","d3dd6d1b":"#### \u041f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0442\u0438\u043f\u043e\u0432","34ec2958":"#### \u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","1aae4bb3":"#### \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043e\u0441\u0442\u0430\u0432\u0448\u0438\u0445\u0441\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432","619f082a":"#### \u0421\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445","57b790ba":"#### Rooms","7cc78f2a":"### \u041d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435","512eed6f":"### \u0423\u043d\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0448\u0440\u0438\u0444\u0442\u0430","af2673c4":"#### \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435.","38a91a08":"### \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445"}}