{"cell_type":{"179d3663":"code","e3109376":"code","07ba83a3":"code","17da5a53":"code","d2abea46":"code","8098e59e":"code","5a90cf29":"code","c9970eb1":"code","8d650d77":"code","c25a14bf":"code","69b29953":"code","4282cc19":"code","44ce3527":"code","8aa32d7b":"code","18f3942e":"code","8d36801d":"code","8c4cd496":"code","a8db100d":"code","e59c48a6":"code","a24061aa":"markdown","b435361a":"markdown","6eaa16ad":"markdown","5641196c":"markdown","628f0c3d":"markdown","6f10dab8":"markdown","54cf5bf1":"markdown","bb75f59f":"markdown","1adf71c1":"markdown","065b1f87":"markdown","3d0731b1":"markdown","cd23a691":"markdown"},"source":{"179d3663":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n","e3109376":"# Import training dataset \ntrain_df = pd.read_csv(\"\/kaggle\/input\/google-stock-prices-training-and-test-data\/Google_Stock_Price_Train.csv\")\n\ntrain_df","07ba83a3":"# Extract open column and conver to numpy array\n\ntrain = train_df.iloc[:, 1:2].values\nlen(train)","17da5a53":"scale = MinMaxScaler(feature_range=(0,1))\ntrain_scaled = scale.fit_transform(train)","d2abea46":"# 60 previous stock prices before the given day \nx_train = []\n# Stock price of next day\ny_train = []\n\nfor i in range(60,len(train_scaled)):\n    x_train.append(train_scaled[i-60:i, 0])\n    y_train.append(train_scaled[i,0])\n\nx_train, y_train = np.array(x_train), np.array(y_trian)","8098e59e":"# Data is 2D converting it to 3D tensor for the training\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))","5a90cf29":"model = Sequential()\n\n# Add LSTM layer\nmodel.add(LSTM(units = 50, return_sequences=True, input_shape = (x_train.shape[1], 1)))\n# Add Regularization \nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units = 50, return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units = 50, return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units = 50))\nmodel.add(Dropout(0.2))\n\n# Add output layer \nmodel.add(Dense(units = 1))","c9970eb1":"model.summary()","8d650d77":"# Compile the model \n\nmodel.compile(optimizer= 'adam',\n             loss='mean_squared_error')","c25a14bf":"# Train the model \nmodel.fit(x_train, y_train, epochs = 100, batch_size= 32)","69b29953":"test_df = pd.read_csv(\"\/kaggle\/input\/google-stock-prices-training-and-test-data\/Google_Stock_Price_Test.csv\")\ntest_df.head()","4282cc19":"stock_price = test_df.iloc[:, 1:2].values","44ce3527":"# Fetch 60 timesteps by combining train and test got prediction\ntotal_df = pd.concat((train_df['Open'], test_df['Open']), axis = 0)\ninputs = total_df[len(total_df) - len(test_df) -  60:].values\ninputs = inputs.reshape(-1, 1)\ninputs = scale.transform(inputs)","8aa32d7b":"# Reshape the dataset\n\nx_test = []\n\nfor i in range(60, len(inputs)):\n    x_test.append(inputs[i-60:i, 0])\n    \nx_test = np.array(x_test)\n\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))","18f3942e":"predicted_stock_price = model.predict(x_test)\npredicted_stock_price","8d36801d":"predicted_stock_price = scale.inverse_transform(predicted_stock_price)\npredicted_stock_price","8c4cd496":"plt.plot(stock_price, color = 'red', label = 'Real Google Stock price')\nplt.plot(predicted_stock_price, color = 'green', label = 'Predicted Google Stock price')\nplt.title(\"Google Stock Price Prediction\")\nplt.xlabel('Time')\nplt.ylabel('Stock price')\nplt.legend()\nplt.show()","a8db100d":"import math\nfrom sklearn.metrics import mean_squared_error\nrmse = math.sqrt(mean_squared_error(stock_price, predicted_stock_price))","e59c48a6":"print(f\"Mean square error : {rmse}\")","a24061aa":"# Step 2: Building Stacked LSTM\n\nAbout LSTM:\nhttps:\/\/web.stanford.edu\/class\/cs379c\/archive\/2018\/class_messages_listing\/content\/Artificial_Neural_Network_Technology_Tutorials\/OlahLSTM-NEURAL-NETWORK-TUTORIAL-15.pdf \n\nhttps:\/\/blog.mlreview.com\/understanding-lstm-and-its-diagrams-37e2f46f1714\n\nhttp:\/\/karpathy.github.io\/2015\/05\/21\/rnn-effectiveness\/\n\nhttps:\/\/arxiv.org\/pdf\/1503.04069.pdf\n\n","b435361a":"### Initializing the RNN - LSTM","6eaa16ad":"### Visualization","5641196c":"### Prepare test data","628f0c3d":"### Modify dataset to make prediction using 60 timesteps\n\n60 past time steps are used to make the prediction at every stage","6f10dab8":"# Part 3: Prediction","54cf5bf1":"# Step 1: Data Preprocessing","bb75f59f":"### Load in the data","1adf71c1":"### Reshaping the dataset","065b1f87":"### Evaluation","3d0731b1":"### Feature Scaling\n\nNormalization $x_{norm}$ =  $\\frac{x-min(x)}{max(x) - min(x)}$\n\nIt is recommended to use normalization when the output layer is a sigmoid function ","cd23a691":"### Predict stock for 2017"}}