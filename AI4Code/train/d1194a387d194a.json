{"cell_type":{"54654d0a":"code","297a8d4d":"code","482f6fc4":"code","5c4712b3":"code","ecd4e6b5":"code","0f3571dc":"code","0c553a1f":"code","0bcee310":"code","710994c6":"code","780b0700":"code","0cb243f8":"code","1d175e32":"code","a51fe96b":"code","6ed76d7a":"code","2a0d45cd":"code","060c974f":"code","7f8455ed":"code","a2a457b2":"code","827631ab":"code","89c2268b":"code","91b99478":"code","be213d8b":"code","e7a673ea":"code","7d345faa":"code","88899724":"code","ec9461f6":"code","7b34f23c":"code","36a2542d":"code","32e5624c":"code","66c58f82":"code","c539f450":"code","f13d98f0":"code","a9d2736a":"code","28171666":"markdown","27d33733":"markdown","86d8980c":"markdown"},"source":{"54654d0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","297a8d4d":"# loading dataset\ndf=pd.read_csv('..\/input\/diabetes\/diabetes.csv')","482f6fc4":"# getting top 3 rows\ndf.head(3)","5c4712b3":"# getting shape of data\ndf.shape","ecd4e6b5":"# printing 'number of null values' column wise\ndf.isnull().sum()","0f3571dc":"# getting statistical description\ndf.describe().T","0c553a1f":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n","0bcee310":"# getting information of data types\ndf.info()","710994c6":"# let's create a copy of the data, so that original data is not affected\ndiabetes_df=df.copy(deep=True)\n# when 'deep=True', any changes to new df does not affect the original dataframe, and vice-versa ","780b0700":"diabetes_df.columns","0cb243f8":"# replacing all zeros with np.NaN, in some columns\ndiabetes_df[['Glucose','BloodPressure','SkinThickness','BMI','Insulin']].replace(0,np.NaN)","1d175e32":"# again checking for null values\ndiabetes_df.isnull().sum()","a51fe96b":"# import seaborn library for data visualisation\nimport seaborn as sns","6ed76d7a":"sns.histplot(diabetes_df['BloodPressure'])","2a0d45cd":"p=diabetes_df.hist(figsize=(19,17))","060c974f":"# replacing all null values of Glucose Columns with its mean\ndiabetes_df['Glucose'].fillna(diabetes_df['Glucose'].mean(),inplace=True)","7f8455ed":"# likewise replacking null values of all other columns with their mean\ndiabetes_df['BloodPressure'].fillna(diabetes_df['BloodPressure'].mean(), inplace = True)\ndiabetes_df['SkinThickness'].fillna(diabetes_df['SkinThickness'].median(), inplace = True)\ndiabetes_df['Insulin'].fillna(diabetes_df['Insulin'].median(), inplace = True)\ndiabetes_df['BMI'].fillna(diabetes_df['BMI'].median(), inplace = True)","a2a457b2":"# plotting after removing NaN values\np=diabetes_df.hist(figsize=(17,15))","827631ab":"# getting number of different outcome\ndiabetes_df.Outcome.value_counts()","89c2268b":"sns.pairplot(diabetes_df,hue='Outcome')","91b99478":"# printing heatmap of correlation\n\nplt.figure(figsize=(12,10))\nplt.set_cmap('Greens')\nprint('Correlation between various Features')\nsns.heatmap(diabetes_df.corr(),annot=True)\nplt.show()","be213d8b":"# getting data type of each columns of the dataframe\ndiabetes_df.dtypes","e7a673ea":"# Extracting dependent and independent varirable for training\nX=diabetes_df.drop(['Outcome'],axis=1)\ny=diabetes_df.Outcome","7d345faa":"# Now before feeding our data to training algorithm we need to do some preprocessing\n# So, here we do Standard scaling first\n\nfrom sklearn.preprocessing import StandardScaler\nss=StandardScaler()","88899724":"# scaling input data using StandardScaler & then converting it into a dataframe\nX =  pd.DataFrame(ss.fit_transform(diabetes_df.drop([\"Outcome\"],axis = 1)),\n        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])","ec9461f6":"# prining top 5 rows of scaled input data\nX.head()","7b34f23c":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42,stratify=y)","36a2542d":"# importing KNeighborsClassifier for model training \nfrom sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()","32e5624c":"# fitting the model\nknn.fit(X,y)","66c58f82":"# getting model traning score\nknn.score(X_train,y_train)","c539f450":"# getting model test score\nknn.score(X_test,y_test)","f13d98f0":"# definind prediction vector\ny_pred=knn.predict(X_test)","a9d2736a":"# printing first 5 prediction, here 0 means person doesnt have diabetes and 1 means person has diabetes\ny_pred[0:5]","28171666":"**From above code, we have find that all columns are numerical in nature and there is no Null Value associate to any\ncolumn**","27d33733":"We have 2000 rows & 9 columns","86d8980c":"\n#### From above we can infer that\n##### 1.Pregnancy is more correlated to age\n##### 2.Glucose is more correlated to outcome\n##### 3.SkinThickNess is more correlated to Insulin\n##### 4.BMI is more correlated to SkinThickNess"}}