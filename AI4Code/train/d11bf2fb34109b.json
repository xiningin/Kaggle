{"cell_type":{"7f3c2c06":"code","df6e07f4":"code","91da83b9":"code","7bc5e156":"code","f7b20e70":"code","25dac513":"code","bbe46672":"code","7f6527f1":"code","728be16f":"code","612b7d85":"code","b6a39d14":"code","13c992d6":"code","cb7ddedb":"code","45275770":"markdown","b9693409":"markdown","18058aaf":"markdown","2f5386c1":"markdown","c12ef1ff":"markdown","6d3d3109":"markdown","7898b98c":"markdown","2068e305":"markdown","2618f7d3":"markdown","b62ff9fd":"markdown","bbf81cb2":"markdown","729cda4d":"markdown","1b4cb100":"markdown","5185015e":"markdown","d6fa16e7":"markdown","77984721":"markdown","df62a4c8":"markdown","12b66720":"markdown","c9cb5856":"markdown","f760c362":"markdown","7579902d":"markdown","96e0ed6b":"markdown"},"source":{"7f3c2c06":"## Importing support libraries\nimport numpy as np ## for numerical calculations of arrays\nimport pandas as pd ## for reading csv file and wroking with dataframe operations\nfrom PIL import Image ## for image processing and output\nimport cv2 ## for image processing\nfrom numpy import linalg as LA ## numpy's Linear Algebra library\nimport os ## for reading images from image folder\nimport math\nfrom scipy.spatial import distance ## for calculating distance between two entities\nimport requests ## to get the file from url\n\n## Get file from URL\nurl = 'https:\/\/fei.edu.br\/~cet\/originalimages_part1.zip'\nr = requests.get(url, allow_redirects=True)\n\nopen('originalimages_part1.zip', 'wb').write(r.content)","df6e07f4":"# unzipping the zip file\nimport zipfile\nwith zipfile.ZipFile(\".\/originalimages_part1.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\".\/originalimages_part1\")","91da83b9":"## BASE is the name of the base folder\nBASE = \".\/originalimages_part1\"\nimg = cv2.imread(BASE + '\/1-01.jpg', 0) # '0' for reading grayscale images\nIMG_SHAPE = img.shape\n\nfilepaths = [] # Contains the absolute paths of all the image files\nfor filename in os.listdir(BASE):\n\t\tfilepaths.append(BASE + '\/' + filename)\nfilepaths.sort()\n\n## Converting filepaths list to dataframe\ndf = pd.DataFrame({'filepaths':filepaths})\nprint(df)","7bc5e156":"total_images = 210\ntotal_classes = 15","f7b20e70":"face_vector = []\nfor i in range(total_images):\n    img = cv2.imread(filepaths[i])\n    face_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    face_image = face_image.reshape(face_image.shape[0] * face_image.shape[1],)\n    face_vector.append(face_image)\nface_vector = np.asarray(face_vector)\nface_vector = face_vector.transpose()\nprint(\"face_vector shape: \", face_vector.shape)","25dac513":"avg_face_vector = face_vector.mean(axis=1)\navg_face_vector = avg_face_vector.reshape(face_vector.shape[0], 1)\nresult = Image.fromarray(avg_face_vector.reshape(480, 640).astype('uint8'))\nst = \"avg_face_vector.jpg\"\nresult.save(st)\nresult.show()\nprint(\"avg_face_vector shape = \", avg_face_vector.shape)\n\nnormalized_face_vector = face_vector - avg_face_vector","bbe46672":"covariance_matrix = np.cov(np.transpose(normalized_face_vector))","7f6527f1":"eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\nprint(len(eigen_values))","728be16f":"k=20\nprint(eigen_vectors)\nx = eigen_vectors.copy()\nidx = np.argsort(eigen_values)\neigen_values.sort()\neigen_values = eigen_values[::-1]\nidx = idx[::-1]\nprint(idx)\nfor i in range(total_images):\n\teigen_vectors[i] = x[idx[i]]\n\nk_eigen_vectors = eigen_vectors[0:k, :]","612b7d85":"eigen_faces = k_eigen_vectors.dot(normalized_face_vector.T)\nprint(\"eigen_faces shape = \", eigen_faces.shape)\nfor i in range(k):\n\tresult = Image.fromarray(eigen_faces[i].reshape(480, 640).astype('uint8'))\n\tst = \"eigenface\" + str(i) + \".jpg\"\n\tresult.save(st)","b6a39d14":"weights = (normalized_face_vector.T).dot(eigen_faces.T)\nprint(\"weights shape: \", weights.shape)\nresult = Image.fromarray(weights.astype('uint8'))\nst = \"weights.jpg\"\nresult.save(st) ","13c992d6":"#train-test split\navg_class_vector = []\ntest = []\nk=0\nfor i in range(total_classes):\n\tavg_class_vector.append(np.average(face_vector.T[k:(k+9)], axis=0))\n\ttest.append(face_vector.T[(k+9):(k+14)])\n\tk = k + 14\navg_class_vector = np.array([im for im in avg_class_vector])\ntest = np.array([im for im in test])\nprint(\"avg_class_vector shape: \", avg_class_vector.shape)\nprint(\"test shape: \", test.shape)\n\n## train images normalization anf weight calculation\ntrain_normalized_face_vector = np.zeros(shape=(10, 480*640))\ntrain_weight = np.zeros(shape = (total_classes, 20))\nfor i in range(total_classes):\n\ttrain_weight[i] = (avg_class_vector[i]).dot(eigen_faces.T)\nprint(\"train_weight = \", train_weight.shape)","cb7ddedb":"#testing\ncountEud=0\ncountManh=0\ncountMinkow=0\nfor i in range(total_classes):\n\tfor j in range(5):\n\t\ttest_img = test[i][j]\n\t\ttest_weight = (test_img.T).dot(eigen_faces.T)\n\n\t\t#Euclidean Distance\n\t\tdist = 100000000000\n\t\tclasss = -1\n\t\tfor k in range(total_classes):\n\t\t\terrEud = distance.euclidean(test_weight.astype(\"float\"), train_weight[k].astype(\"float\"))\n\t\t\tif(errEud < dist):\n\t\t\t\tclasss = k\n\t\t\t\tdist = errEud\n\t\tprint(\"Test Image \", i, \"-\", j, \" belongs to Euclidean class:  \", classs)\n\t\tif classs == i:\n\t\t\tcountEud = countEud + 1\n\n\t\t#Manhattan Distance\n\t\tdist = 100000000000\n\t\tclasss = -1\n\t\tcount = 0\n\t\tfor k in range(total_classes):\n\t\t\terrManh = distance.cityblock(test_weight.astype(\"float\"), train_weight[k].astype(\"float\"))\n\t\t\tif(errManh < dist):\n\t\t\t\tclasss = k\n\t\t\t\tdist = errManh\n\t\tprint(\"Test Image \", i, \"-\", j, \" belongs to Manhattan class:  \", classs)\n\t\tif classs == i:\n\t\t\tcountManh = countManh + 1\n\n\t\t#Minkowski Distance\n\t\tdist = 10000000000\n\t\tclasss = -1\n\t\tcount = 0\n\t\tfor k in range(total_classes):\n\t\t\terrMinkow = distance.minkowski(test_weight.astype(\"float\"), train_weight[k].astype(\"float\"), 4)\n\t\t\terrMinkow = pow(errMinkow, (1\/float(4)))\n\t\t\tif(errMinkow < dist):\n\t\t\t\tclasss = k\n\t\t\t\tdist = errMinkow\n\t\tprint(\"Test Image \", i, \"-\", j, \" belongs to Minkowski class:  \", classs)\n\t\tif classs == i:\n\t\t\tcountMinkow = countMinkow + 1\n\t\tprint(\"\\n\")\n\naccEud = (float)(100 * countEud) \/ (total_classes * 5)\naccManh = (float)(100 * countManh) \/ (total_classes * 5)\naccMinkow = (float)(100 * countMinkow) \/ (total_classes * 5)\n\nprint(\"Euclidean Distance Accuracy = \", accEud, \"%\")\nprint(\"Manhattan Distance Accuracy = \", accManh, \"%\")\nprint(\"Minkowski Distance Accuracy = \", accMinkow, \"%\")","45275770":"![image.png](attachment:addd3129-382c-4540-a1d6-f8091b099b95.png)","b9693409":"## Tesing\n\nThe final step is to test our prediction.\n\nwe will calculate the distance (using each of the theree methods: Euclidian, Manhattan and MInkowski) between `test_normalized_image` and `train_normalized_image` **or** `test_weight` and `train_weight` per image. ","18058aaf":"## Training \n\nWe will first perfrom the **Train-Test split**. Here we have 14 images per class from where, 9 images will go fro training and 5 images will be saved for testing. Thus out of 210 images, we have 9 \\* 15 = **135** training images and 5 \\* 15 = **75** testing images.\n\nAfter spiliting, we can now normalize each train images and calculate the weight according to it.","2f5386c1":"Here, the PIL library is used to open the images and make conversion from array to image. The numpy library is used to perform numerical operations like average and sum. The use of os library function is to read the image files from its parent folder. ","c12ef1ff":"## Code:","6d3d3109":"#### Find Covariance Matrix\n\nNext step in PCA is to find the covariance matrix of the normalized face vector. \n\nCovariance matrix is the multiplication of the transpose of `normalized_face_vector` with itself.","7898b98c":"#### - Generating Eigen faces\n\nFrom calculated eigen vectors, we can now convert them into distint eigen faces. This eigen faces are further used for regeneration of any image by the projecting them into average image.","2068e305":"Source of dataset: https:\/\/fei.edu.br\/~cet\/facedatabase.html\n\nThe dataset contains 700 images of 50 person, each person class consist of 14 images in different face poses. The size of each image is 480 x 640 pixels. The code is been written in python language using sublime text editor and tested\/run through command prompt.\n\nThe sample image class that is used by the program is:\n![image.png](attachment:7f93468e-cfd7-41c6-8f78-0bf871ab9958.png)","2618f7d3":"## Distance Measures: \n### 1. Euclidean Distance: ![image.png](attachment:724a5f67-b324-4ade-a4e0-bf38fed56907.png)\n\n### 2. Manhattan Distance: ![image.png](attachment:07fc104f-4d42-4295-bc0e-56ca9ab1fbf7.png)\n\n### 3. Minkowski Distance: ![image.png](attachment:5689235c-3c95-4f6c-b47f-e433417f2e1f.png)","b62ff9fd":"#### Reading images and storing\n\nHere we will first read the image from folder to \"face_image\" array. This array is of shape (480, 640, 3) where 480 & 640 are the dimensions of the image and 3 is the values of RGB per cell of an image.\n\nSo, we will first convert the RGB images to GrayScale images.\n\n##### Next,\nFor using the images, we need to first convert the 2D array into 1D vector. So, we will reshape the images from **480 \\* 640** to **307200 \\* 1**. \n\nAnd finally, we will store them one after another into \"face_vector\".","bbf81cb2":"#### Clculating the average face and converting it to image form\n\nWe will take an avearge of all images and create one final image called `avg_face_vector`\n\nAfter getting the average face vector, we will normalize each image by subtracting the `avg_face_vector` from each of the `face_vector` image and sotre the result to `normalized_face_vector`. ","729cda4d":"#### Eigen faces generated:\n![image.png](attachment:f3c4fa84-0f24-4c94-9a1a-ff4ae95572ed.png)","1b4cb100":"#### Projected Weights of all images: \n![image.png](attachment:d385ba2d-6bf7-47ae-9e83-05f1ca96573e.png)","5185015e":"#### - Read files from \"original_images1\" named folder and save the file names to \"filepaths\" dataframe :","d6fa16e7":"#### Eigen values and vectors\n\nBy using the NumPy's linerl algebra function, we calculate the eigen values and eigen vectors of the Covariance matris as follows. ","77984721":"#### - We will use 15 distinct classes (persons) and 14 images oer person i.e. total 210 images","df62a4c8":"#### - Unzipping the zip file:","12b66720":"# Principal Component Analysis on Face Images","c9cb5856":"## Conclusion: \n\nIn this program we have used 15 classes and 14 images per class i.e. total 210 images. Here, 9 images per class are training images and 5 images per class are testing images. Top 20 eigen values are used to project images onto the vector space. So, we have total 135 train images and 75 test images. And our accuracy in distance measures are \n\n- **78.66%** in Euclidean distance, \n- **77.33%** in Manhattan distance and \n- **78.667%** in Minkowski Distance. ","f760c362":"### Feature Extraction\n\nPCA's main objective is to minimize the number of features used for the prediction in high dimensional data. (Dimension = Feature). As, we know, we cannot use all 210 features into prediction. Also, we have calculated eigen values. \n\nNow, eigen values shows the amount information it can provide if we use that specific feature into prediction. The higher the eigen_value, the higher the information amount. \n\nThat's why we will sort the eigen values into decreasing order. Then, we can decide how many number of feature we want to use. In the straight away implementation, we can provide any number for first few eigen values. \n\nIn our case, I am taking k = 20 i.e. first 20 eigen values as extracted features from 210. And now let's see how much our prediction becomes correct.","7579902d":"### Principle component analysis (PCA) Algorithm:\n1.\tset of m images\n2.\tdimensions: n*n\n3.\tconvert images into vector of size (n * n) => (n^2 * 1)\n4.\ttotal m vectors: \n    - x1 = [n^2 * 1]\n    - x2 = [n^2 * 1]\n    - .\n    - .\n    - xm = [n^2 * 1]\n5.\tcalculate the average of all the face vectors (xi) \n    - phi = 1 \/ m * (sum i to m -> xi)\n6.\tsubtract it from each vector:\n    - ai = xi - phi\n7.\tcombine all the face vectors (ai) into one matrix A\n    - A = [a1\ta2\ta3\t...\tam]\n    - sizeof(A) = [n^2 * m]\n8.\ttake transpose of A\n    - A_T = transpose(A)\n    - sizeof(A_T) = [m * n^2]\n9.\tcalculate cvariance :\n    - Cov = A_T * A\n    - sizeof(Cov) = [m * m]\n10.\tcalculate eigen values and eigen vector from below formula: \n    - i.\tCov * vi = lambdai * vi\t\t\t :(lambdai -> eigenvalue, \n    - ii.\tA_T * A * vi = lambdai * vi\t\t\t\tvi -> eigenvector)\n    - iii.\tsizeof(vi) = [m * 1]\n11.\tthere will be total 'm' eigenvalues and eigenvectors\n12.\tsort eigenvalues in descending order\n13.\tselect k eigenvalues starting from top (k < m)\n14.\tui = A * vi -------- sizeof(ui) = [n^2 * 1]\n15.\tform a projection matrix\n    - proj_mat = [u1\tu2\tu3\t...\tuk]_T\n    - sizeof(proj_mat) = [k * n^2]\n16.\tproject training mean subtracted images matrix onto projection matrix:\n    - sizeof(classave) = [n^2 * 1]\n    - fin = proj_mat * classave\n    - sizeof(fin) = [k * 1]\n17.\tnumber of 'fin' matrices = number of classes\n18.\tproject testing mean subtracted images matrix onto projection matrix:\n    - test = test_A * proj_mat\n19.\tcalculate the distances of test to all fin matrices\n20.\tgive the classvalues of least diatance to test image.\n","96e0ed6b":"Here, one thing to note that, the number of eigen values and eigen vectors are same as the number of distinct objects or variable or sample points. In our case, it is 210. "}}