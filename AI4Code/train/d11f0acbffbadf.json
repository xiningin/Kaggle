{"cell_type":{"2c27bbdb":"code","80fe9ab5":"code","a4bf631a":"code","ff1667f7":"code","6bb5f717":"code","5b51cce7":"code","5f3c1ed5":"code","a7b654b4":"code","8020ac07":"code","9e867c48":"code","4b3d2871":"code","1d8bad05":"code","6e1f1ae7":"code","876d5101":"code","c520a83a":"code","3876f5ef":"code","edd35a5c":"code","754d82b9":"markdown","7c4a09b8":"markdown"},"source":{"2c27bbdb":"import os\nfrom kaggle_datasets import KaggleDatasets\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# tensorflow stuff\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\n\n# visualization\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nAUTO = tf.data.experimental.AUTOTUNE","80fe9ab5":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    tpu_strategy = tf.distribute.TPUStrategy(tpu)\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\nexcept ValueError:\n    strategy = tf.distribute.MirroredStrategy()\n    \nprint(\"Number of accelerators: \", tpu_strategy.num_replicas_in_sync)","a4bf631a":"GCS_PATH = KaggleDatasets().get_gcs_path()\nGCS_PATH","ff1667f7":"!gsutil ls $GCS_PATH","6bb5f717":"# Main dir on GCS\nmain_dir = os.path.join(GCS_PATH, \"tfrecords-jpeg-224x224\/\")\n\n# creating paths dictionary\npaths = dict()\npaths['train'], paths['val'], paths['test'] = None, None, None\n\nfor k, v in paths.items():\n    paths[k] = tf.io.gfile.glob(main_dir + k + '\/*.tfrec')\n# paths","5b51cce7":"IMAGE_SHAPE = [224, 224, 3]\nBATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\nNUM_CLASSES = 104\nTRAIN_SIZE = 12753\nVALIDATION_SIZE = 16 * 232\nTRAIN_STEPS = TRAIN_SIZE \/\/ BATCH_SIZE\nVALIDATION_STEPS = VALIDATION_SIZE \/\/ BATCH_SIZE","5f3c1ed5":"def augment_image(image, label):\n    aug_image = tf.image.random_brightness(image, 0.6)\n    aug_image = tf.image.random_flip_left_right(aug_image)\n    aug_image = tf.image.random_flip_up_down(aug_image)\n    return aug_image, label\n\ndef load_training_data(apply_augmentation=True):\n    dataset = load_dataset(paths['train'], labeled=True)\n    if apply_augmentation:\n        dataset = dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\ndef load_validation_data():\n    dataset = load_dataset(paths['val'], labeled=True)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\ndef load_test_data():\n    dataset = load_dataset(paths['test'], labeled=False)\n    dataset = dataset.batch(BATCH_SIZE)\n    \n    return dataset\n\ndef parse_image(image_bytes):\n    image = tf.image.decode_jpeg(image_bytes, channels=3)\n    image = tf.reshape(image, IMAGE_SHAPE)\n    \n    return image\n\ndef load_dataset(paths, labeled):\n    # read from files\n    dataset = tf.data.TFRecordDataset(paths, num_parallel_reads=AUTO)\n    \n    dataset = dataset.with_options(ignore_order)\n    # map tfrecord to normal data\n    dataset = dataset.map(\n        parse_labeled_data if labeled else parse_unlabeled_data)\n    \n    return dataset\n\n    \ndef parse_labeled_data(example):\n    IMAGE_MESSAGE = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'class': tf.io.FixedLenFeature([], tf.int64),\n    }\n    image_data = tf.io.parse_single_example(example, IMAGE_MESSAGE) \n    image = parse_image(image_data['image'])\n    label = tf.cast(image_data['class'], tf.int32)\n    \n    return image, label\n\ndef parse_unlabeled_data(example):\n    IMAGE_MESSAGE = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'id': tf.io.FixedLenFeature([], tf.int64), \n    }\n    image_data = tf.io.parse_single_example(example, IMAGE_MESSAGE)\n    image_id = tf.cast(image_data['id'], tf.int32)\n    \n    return image, image_id\n    \n    ","a7b654b4":"# for (x,y) in load_training_data().take(1):\n#     plt.imshow(x[0])\n#     plt.imshow(tf.image.random_brightness(x[0], 0.6))\n#     break","8020ac07":"print(load_training_data())","9e867c48":"# data dump\nprint(\"Training data shapes:\")\nfor image, label in load_training_data().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy()[:15])","4b3d2871":"# labels, counts = np.unique(train_y, return_counts=True)\n# max_count = max(counts)\n# normalized_counts = counts \/ max_count\n# my_cmap = plt.get_cmap('viridis_r')\n# colors = my_cmap(normalized_counts)\n# fig, ax = plt.subplots(figsize=(20,30))\n# count_graph = ax.barh(labels, counts, color=colors)\n# ax.set_title('Class Count Histogram')\n# ax.set_yticks(labels);","1d8bad05":"\n# img = train_x[0]\n# plt.axis('off')\n# plt.imshow(img)\n# print(f'Label : {train_y[0]}')\n# print(f'Image shape : {img.shape}')","6e1f1ae7":"\nwith tpu_strategy.scope():\n    # defining the layers\n    dense = layers.Dense(NUM_CLASSES, activation='softmax', name='Last-Layer')\n    core = keras.applications.EfficientNetB6(weights='imagenet', include_top=False, pooling='avg')\n    preproc_img = layers.Lambda(lambda data: \n                                keras.applications.efficientnet.\n                                    preprocess_input(tf.cast(data, tf.float32)), input_shape=IMAGE_SHAPE)\n    # model process\n    i = layers.Input(shape=IMAGE_SHAPE)\n    x = preproc_img(i)\n    x = core(x)\n    x = dense(x)\n\n    # creating model\n    model = keras.Model(inputs=[i], outputs=[x])\n    \n    # create an optimizer\n    optimizer = keras.optimizers.Adam()\n    # create a loss function\n    loss_fn = keras.losses.SparseCategoricalCrossentropy()\n    # create metrics\n    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n\n    model.compile(\n        optimizer=optimizer,\n        loss =loss_fn,\n        metrics=metrics,\n        steps_per_execution=8\n        )\n\n\n","876d5101":"model.summary()","c520a83a":"history = model.fit(\n    load_training_data(),\n    validation_data=load_validation_data(),\n    epochs=30,\n    steps_per_epoch=TRAIN_STEPS,\n    validation_steps=VALIDATION_STEPS\n    )","3876f5ef":"plt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.legend(['train loss', 'val loss'], loc='upper right');","edd35a5c":"plt.plot(history.history[\"sparse_categorical_accuracy\"])\nplt.plot(history.history[\"val_sparse_categorical_accuracy\"])\nplt.legend(['train acc', 'val acc'], loc='upper left');","754d82b9":"# **Data Retrieval**","7c4a09b8":"# **Constants**"}}