{"cell_type":{"e36d17e6":"code","c82b65ee":"code","b1e9f4e3":"code","e99e1ce6":"code","fc90f9eb":"code","b8735f77":"code","6b361337":"code","c95b389d":"code","43f77172":"code","72c582e9":"code","d8c97e60":"code","c091a543":"code","d53e1e7e":"markdown","0f7b394c":"markdown","1ca95bf3":"markdown","c997763e":"markdown","6b2ca0d1":"markdown","5595ed24":"markdown","a4e53ada":"markdown","ba1a78ba":"markdown","16799fe1":"markdown","6ac73c44":"markdown"},"source":{"e36d17e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c82b65ee":"import h2o\nprint(h2o.__version__)\nfrom h2o.estimators.deeplearning import H2ODeepLearningEstimator\n\nh2o.init(max_mem_size='16G')","b1e9f4e3":"train = h2o.import_file(\"\/kaggle\/input\/Kannada-MNIST\/train.csv\")\ntest = h2o.import_file(\"\/kaggle\/input\/Kannada-MNIST\/test.csv\")\nsubmission = h2o.import_file(\"\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv\")","e99e1ce6":"train.head()","fc90f9eb":"x = train.columns[1:]\ny = 'label'\n","b8735f77":"\ntrain[y] = train[y].asfactor()","6b361337":"dl = H2ODeepLearningEstimator(input_dropout_ratio = 0.2, nfolds=3)\ndl.train(x=x, y=y, training_frame=train)","c95b389d":"dl.model_performance(xval=True)","43f77172":"preds = dl.predict(test)\npreds['p1'].as_data_frame().values.shape","72c582e9":"preds","d8c97e60":"sample_submission = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv')\nsample_submission.shape","c091a543":"sample_submission['label'] = preds['predict'].as_data_frame().values\nsample_submission.to_csv('H2O_DL.csv', index=False)\nsample_submission.head()","d53e1e7e":"## Encode the response column as categorical for **multinomial classification","0f7b394c":"## Extracting the Results","1ca95bf3":"## Upload the datasets to the the H2O cluster. \n\nThe data is imported into H2OFrames, which operate similarly in function to pandas DataFrames.  ","c997763e":" ## Specify the response and predictor columns","6b2ca0d1":"# Kannada MNIST with H2O DeepLearning\n\n![](https:\/\/miro.medium.com\/max\/1095\/1*s1tZoytg71DUnEKEYWtyNw.png)\n\n[H2O\u2019s](http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/welcome.html) is an open source, in-memory, distributed, fast, and scalable machine learning and predictive analytics platform that allows you to build machine learning models on big data and provides easy productionalization of those models in an enterprise environment.\n\nH2O's [Deep Learning](http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/deep-learning.html) is based on a multi-layer feedforward artificial neural network that is trained with stochastic gradient descent using back-propagation. The network can contain a large number of hidden layers consisting of neurons with tanh, rectifier, and maxout activation functions.\n\nAdvanced features such as adaptive learning rate, rate annealing, momentum training, dropout, L1 or L2 regularization, checkpointing, and grid search enable high predictive accuracy. Each compute node trains a copy of the global model parameters on its local data with multi-threading (asynchronously) and contributes periodically to the global model via model averaging across the network.\n","5595ed24":"## Train Deep Learning model \n\nHere nfolds = 3, which means it performs three folds cross validation. To disable cross-validation, use nfolds=0,\nwhich is the default value. More information about the parameters can be found in the [H2O Deep Learning booklet](http:\/\/h2o.ai\/resources\/).\n","a4e53ada":"## Sample Submissions","ba1a78ba":"## Acknowledgement\n\nArno Candel for his [kernel](https:\/\/www.kaggle.com\/arnocandel\/mnist-with-h2o-deeplearning) on MNIST with H2O DeepLearning","16799fe1":"## Starting H2O cluster and Importing the DeepLearning Estimator","6ac73c44":"## Predictions"}}