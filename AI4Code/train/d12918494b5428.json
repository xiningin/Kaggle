{"cell_type":{"234722f1":"code","b89819c6":"code","89197ad6":"code","eb79f7cc":"code","ada6c7d9":"code","73cdfa12":"code","15b684ca":"code","25545514":"code","e5d81c47":"code","5802cef5":"code","144013e7":"code","630f64c0":"code","0ed407b6":"code","c15d5e2c":"code","fcf27848":"code","c2baaab8":"code","528f6657":"code","a49eeb8d":"code","3cb013d2":"code","5ea660fe":"code","135850ab":"code","bdf8a058":"code","f878522c":"code","e379b102":"code","ddd71d17":"markdown","be656a02":"markdown","d81b9a26":"markdown"},"source":{"234722f1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nimport gc\nwarnings.filterwarnings('ignore')","b89819c6":"train_df = pd.read_csv('..\/input\/data-without-drift\/train_clean.csv')\ntest_df  = pd.read_csv('..\/input\/data-without-drift\/test_clean.csv')","89197ad6":"def apply_group():\n    for i in range(20):\n        train_df.loc[((train_df.time) > i * 50) & (train_df.time <= (i+1) * 50), 'batch'] = i + 1\n        test_df.loc[i*100_000:(i+1)*100_000, 'batch'] = i\n    \n    batch_group = [(1,0), (2,0), (3,1), (4,2), (5,4), (6,3), (7,1), (8,2), (9,3), (10,4),\n                   (11,4),(12,3),(13,2),(14,1),(15,3),(16,4),(17,2),(18,1),(19,0),(20,0)]\n    for batch_i, group_i in batch_group:\n        train_df.loc[train_df.batch == batch_i, 'group'] = group_i\n    \n    batch_group = [(1,0), (2,2), (3,3), (4,0), (5,1), (6,4), (7,3), (8,4), (9,0), (10,2),\n                         (21,0),(22,0),(23,0),(24,0),(25,0),(26,0),(27,0),(28,0),(29,0),(30,0),\n                         (31,2),(32,0),(33,4),(34,3),(35,4),(36,1),(37,0),(38,3),(39,2),(40,0)]\n    batch_group.extend([(i, 0) for i in range(11,21)])\n    for batch_i, group_i in batch_group:\n        test_df.loc[test_df.batch == batch_i, 'group'] = group_i","eb79f7cc":"apply_group()","ada6c7d9":"plt.figure(figsize=(20,5))\nfor _ in train_df.group.unique():\n    plt.plot(train_df[train_df.group == _].set_index('time').signal[::1000], '.')","73cdfa12":"plt.figure(figsize=(20,5))\nfor _ in train_df.group.unique():\n    plt.plot(test_df[test_df.group == _].set_index('time').signal[::200], '.')","15b684ca":"from sklearn.linear_model import LinearRegression, LogisticRegression","25545514":"diff = {}; alpha = {}; beta = {}\nfor _ in train_df.group.unique():\n    temp = train_df[train_df.group == _]\n    beta[_] = np.cov(temp.signal, temp.open_channels)[0,1] \/ np.var(temp.signal.astype(np.float64))\n    alpha[_] = np.mean(temp.open_channels) - (beta[_] * np.mean(temp.signal.astype(np.float64)))\n    diff[_] = temp.open_channels - (beta[_] * temp.signal + alpha[_])","e5d81c47":"alpha, beta","5802cef5":"def ls(group_i, start, stop):\n    train_df[train_df.group == group_i].sample(1000).plot.scatter(x='signal', y='open_channels', figsize=(18,6))\n    \n    ols = lambda x, i: beta[i] * x + alpha[i]\n    plt.plot(np.linspace(start, stop), np.linspace(ols(start, group_i), ols(stop, group_i)), label='ols')\n    \n    lr = LogisticRegression(multi_class='multinomial')\n    lr.fit(\n        train_df[train_df.group == group_i].signal.values.reshape(-1,1),\n        y=train_df[train_df.group == group_i].open_channels.values.reshape(-1,1)\n    )\n    plt.plot(np.linspace(start, stop), lr.predict(np.linspace(start, stop).reshape(-1,1)), label='multinomial')\n    \n    lr = LogisticRegression(multi_class='ovr')\n    lr.fit(\n        train_df[train_df.group == group_i].signal.values.reshape(-1,1),\n        y=train_df[train_df.group == group_i].open_channels.values.reshape(-1,1)\n    )\n    plt.plot(np.linspace(start, stop), lr.predict(np.linspace(start, stop).reshape(-1,1)), label='ovr')\n\n    plt.legend(loc='upper left', fontsize=10)\n    plt.show()","144013e7":"ls(0, -3.5, -1)","630f64c0":"ls(1, -4, -0.5)","0ed407b6":"ls(2, -4, 3)","c15d5e2c":"ls(3, -4, 4)","fcf27848":"ls(4, -4, 8)","c2baaab8":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=10, shuffle=True, random_state=8982)\n\nfrom sklearn import metrics","528f6657":"def ls_cv(model, cv, group_i, feature_cols):\n    \n    # Drop noise\n    if group_i == 2:\n        temp = train_df.drop(train_df.loc[3642932:3822753].index)[train_df.group == group_i]\n    else:\n        temp = train_df[train_df.group == group_i]\n    train_df_idx = temp.index\n        \n    # Define empty oof \/ Fill missing values with mean if present\n    oof = np.zeros(temp.shape[0])\n    temp = temp.fillna(temp.astype(np.float32).mean())\n    \n    # Cross-validate\n    models = []\n    for train_idx, valid_idx in cv.split(temp, temp.open_channels):\n        \n        if issubclass(model, LinearRegression):\n            lr = model()\n        elif issubclass(model, LogisticRegression):\n            lr = model(multi_class='multinomial')\n        \n        lr.fit(temp[feature_cols].iloc[train_idx].values,\n               temp.open_channels.iloc[train_idx].values.reshape(-1,1))\n        oof[valid_idx] = lr.predict(temp[feature_cols].iloc[valid_idx].values).flatten()\n        models.append(lr)\n    \n    # Predict OOF\n    try:\n        valid_f1 = metrics.f1_score(temp.open_channels, oof, average='macro')\n    except ValueError:\n        oof = np.round(np.clip(oof, 0, 10)).astype(np.int8)\n        valid_f1 = metrics.f1_score(temp.open_channels, oof, average='macro')\n    \n    print(f'valid_f1 of group {int(group_i)}: {valid_f1}')\n    \n    # Predict on test set\n    temp = test_df[test_df.group == group_i]\n    temp = temp.fillna(temp.astype(np.float64).mean())\n    test_df_idx = temp.index\n    \n    y_test = np.zeros(temp.shape[0])\n    for lr in models:\n        y_test += lr.predict(temp[feature_cols].values).flatten()\n    y_test \/= len(models)\n    \n    del temp, models\n    gc.collect()\n    \n    return y_test, oof, train_df_idx, test_df_idx","a49eeb8d":"score_linear = {}\nfor i in train_df.group.unique():\n    _ = ls_cv(LinearRegression, kf, i, ['signal'])\n    test_df.loc[_[3], 'linear'] = _[0]\n    train_df.loc[_[2], 'linear'] = _[1]","3cb013d2":"score_logistic = {}\nfor i in train_df.group.unique():\n    _ = ls_cv(LogisticRegression, kf, i, ['signal'])\n    test_df.loc[_[3], 'logistic'] = _[0]\n    train_df.loc[_[2], 'logistic'] = _[1]","5ea660fe":"def blend_thresholder(oofs, y_tests, col_1, col_2, blend_name):\n    \n    best = {i: 0 for i in range(5)}\n    threshold = {}\n    start = 0.0\n    end = 1.0\n    \n    def _print(improved: bool):\n        if improved:\n            if _ == end:\n                print('!')\n            else:\n                print('!', end='')\n        else:\n            if _ == end:\n                print('.')\n            else:\n                print('.', end='')\n    \n    for i in range(5):\n        print(f'[Thresholder] ({i})', end=' ')\n        \n        for _ in np.linspace(start, end, 50):\n            temp = _ * oofs[col_1] + (1 - _) * oofs[col_2]\n            mask = oofs.group == i\n            one = oofs.open_channels.drop(oofs.open_channels.loc[3642932:3822753].index)[mask]\n            two = temp.drop(oofs.loc[3642932:3822753].index)[mask]\n            score = metrics.f1_score(one,\n                                     np.round(np.clip(two, 0, 10)).astype(np.int8),\n                                     average='macro')\n            if score > best[i]:\n                _print(True)\n                best[i] = score\n                threshold[i] = _\n            else:\n                _print(False)\n                \n        oofs.loc[mask, blend_name] = threshold[i] * oofs[mask][col_1] + (1 - threshold[i]) * oofs[mask][col_2]\n        one = oofs.open_channels.drop(oofs.loc[3642932:3822753].index)[mask]\n        two = oofs[blend_name].drop(oofs.loc[3642932:3822753].index)[mask]\n        \n        temp = metrics.f1_score(one, np.round(np.clip(two, 0, 10)), average='macro')\n        assert best[i] == temp\n        \n        mask = oofs.group == i\n        temp = threshold[i] * y_tests[mask][col_1] + (1 - threshold[i]) * y_tests[mask][col_2]\n        y_tests.loc[mask, blend_name] = temp\n    \n    del one, two, temp; gc.collect()\n    print()\n    print('best_threshold -', threshold)\n    print('overall_score -', metrics.f1_score(oofs.open_channels.drop(train_df.loc[3642932:3822753].index),\n                                              np.round(np.clip(oofs[blend_name].drop(train_df.loc[3642932:3822753].index), 0, 10)), average='macro'))","135850ab":"blend_thresholder(train_df, test_df, 'linear', 'logistic', 'ls')","bdf8a058":"train_df.ls[::2000].plot(figsize=(20,5))","f878522c":"test_df.ls[::900].plot(figsize=(20,5))","e379b102":"sample_submission = pd.read_csv('..\/input\/liverpool-ion-switching\/sample_submission.csv', dtype={'time':str})\nsample_submission['open_channels'] = test_df.ls.astype(np.int8)\nsample_submission.to_csv('submission.csv', index=False)","ddd71d17":"# Fit Linear Models by Group (without CV) and Visualize","be656a02":"# CV","d81b9a26":"# Visualizing Group Assignments"}}