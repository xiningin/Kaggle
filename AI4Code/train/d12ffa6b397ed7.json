{"cell_type":{"332b5729":"code","0fdc65ae":"code","0292173d":"code","7e20cc12":"code","e6c412ed":"code","4dbd0293":"code","96c2cabe":"code","10711dd4":"code","4b159a5e":"code","12088aba":"code","0e4ca998":"code","b3ce24ba":"code","29959d6a":"code","6fe70942":"code","5bf8a1c1":"code","44f6ae5a":"code","ee75cfe1":"code","c1a459fd":"code","3b3d4367":"code","646925c6":"code","caec0036":"code","866c6591":"code","bfc86e2f":"code","b94cbfc9":"markdown"},"source":{"332b5729":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0fdc65ae":"!pip install baostock -i https:\/\/pypi.tuna.tsinghua.edu.cn\/simple\/ --trusted-host pypi.tuna.tsinghua.edu.cn","0292173d":"import baostock as bs\nimport pandas as pd\nimport os","7e20cc12":"def mkdir(directory):\n    if not os.path.exists(directory):\n        os.makedirs(directory)","e6c412ed":"class Downloader(object):\n    def __init__(self,\n                 output_dir,\n                 date_start='1990-01-01',\n                 date_end='2020-03-23'):\n        self._bs = bs\n        bs.login()\n        self.date_start = date_start\n        # self.date_end = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n        self.date_end = date_end\n        self.output_dir = output_dir\n#         self.fields = \"date,code,open,high,low,close,volume,amount,\" \\\n#                       \"adjustflag,turn,tradestatus,pctChg,peTTM,\" \\\n#                       \"pbMRQ,psTTM,pcfNcfTTM,isST\"\n        self.fields = \"open,high,low,close,pctChg,volume,amount\"\n\n    def exit(self):\n        bs.logout()\n\n    def run(self):\n        #\u62db\u5546\u94f6\u884c sh.600036\n        df_code = bs.query_history_k_data_plus(\"sh.600036\", self.fields,\n                                                   start_date=self.date_start,\n                                                   end_date=self.date_end,\n                                                   adjustflag=\"2\").get_data()\n        df_code.to_csv(f'{self.output_dir}\/sh.600036.csv', sep=',', index=False, header=False)\n        self.exit()","4dbd0293":"mkdir('\/kaggle\/working\/stockdata\/train')\ndownloader = Downloader('\/kaggle\/working\/stockdata\/train', date_start='2005-04-09', date_end='2021-09-14')\ndownloader.run()","96c2cabe":"mkdir('\/kaggle\/working\/stockdata\/test')\ndownloader = Downloader('\/kaggle\/working\/stockdata\/test', date_start='2020-09-14', date_end='2021-09-14')\ndownloader.run()","10711dd4":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfrom torch.utils.data import Dataset,DataLoader\nimport math\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt","4b159a5e":"SEQ_LEN=90\nLEARNING_RATE=0.00001\nBATCH_SIZE=4\nBATCH_SIZE_TEST=1","12088aba":"mean_list=[]\nstd_list=[]","0e4ca998":"class Stock_Data(Dataset):\n    def __init__(self,train=True,transform=None):        \n        if train==True:\n            train_path=\"\/kaggle\/working\/stockdata\/train\/sh.600036.csv\"\n            with open(train_path) as f:\n                self.data = np.loadtxt(f,delimiter = \",\")\n            for i in range(len(self.data[0])):\n                mean_list.append(np.mean(self.data[:,i]))\n                std_list.append(np.std(self.data[:,i]))\n                self.data[:,i]=(self.data[:,i]-np.mean(self.data[:,i]))\/(np.std(self.data[:,i])+1e-10)\n            print(self.data.shape[0]-SEQ_LEN)\n            self.value=torch.rand(self.data.shape[0]-SEQ_LEN,SEQ_LEN,self.data.shape[1])\n            self.label=torch.rand(self.data.shape[0]-SEQ_LEN,1)\n            for i in range(self.data.shape[0]-SEQ_LEN):                  \n                self.value[i,:,:]=torch.from_numpy(self.data[i:i+SEQ_LEN,:].reshape(SEQ_LEN,self.data.shape[1]))    \n                self.label[i,:]=self.data[i+SEQ_LEN,3]\n            self.data=self.value\n        else:\n            test_path=\"\/kaggle\/working\/stockdata\/test\/sh.600036.csv\"\n            with open(test_path) as f:\n                self.data = np.loadtxt(f,delimiter = \",\")\n            for i in range(len(self.data[0])):\n                self.data[:,i]=(self.data[:,i]-mean_list[i])\/(std_list[i]+1e-10)\n            print(self.data.shape[0]-SEQ_LEN)\n            self.value=torch.rand(self.data.shape[0]-SEQ_LEN,SEQ_LEN,self.data.shape[1])\n            self.label=torch.rand(self.data.shape[0]-SEQ_LEN,1)\n            for i in range(self.data.shape[0]-SEQ_LEN):                  \n                self.value[i,:,:]=torch.from_numpy(self.data[i:i+SEQ_LEN,:].reshape(SEQ_LEN,self.data.shape[1]))    \n                self.label[i,:]=self.data[i+SEQ_LEN,3]\n            self.data=self.value\n    def __getitem__(self,index):\n        return self.data[index],self.label[index]\n    def __len__(self):\n        return len(self.data[:,0])","b3ce24ba":"stock_train=Stock_Data(train=True)\nstock_test=Stock_Data(train=False)","29959d6a":"# ## Neural Network example\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n\n# class Net(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.conv1 = nn.Conv2d(3, 6, 5)\n#         self.pool = nn.MaxPool2d(2, 2)\n#         self.conv2 = nn.Conv2d(6, 16, 5)\n#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n#         self.fc2 = nn.Linear(120, 84)\n#         self.fc3 = nn.Linear(84, 10)\n\n#     def forward(self, x):\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.pool(F.relu(self.conv2(x)))\n#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n#         x = F.relu(self.fc1(x))\n#         x = F.relu(self.fc2(x))\n#         x = self.fc3(x)\n#         return x","6fe70942":"class LSTM(nn.Module):\n    def __init__(self,dimension):\n        super(LSTM,self).__init__()\n        self.lstm=nn.LSTM(input_size=dimension,hidden_size=256,num_layers=2,batch_first=True)\n        self.linear1=nn.Linear(in_features=256,out_features=16)\n        self.linear2=nn.Linear(16,1)\n    def forward(self,x):\n        out,_=self.lstm(x)\n        x=out[:,-1,:]        \n        #x=self.linear1(x)\n        x = F.relu(self.linear1(x))\n        x=self.linear2(x)\n        return x","5bf8a1c1":"model=LSTM(dimension=7)\nmodel=model.to(device)\ncriterion=nn.MSELoss()\noptimizer=optim.Adam(model.parameters(),lr=LEARNING_RATE)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                               step_size=10,\n                                               gamma=0.1)\n","44f6ae5a":"def train(epoch):    \n    model.train()\n    global loss_list\n    global iteration\n    dataloader=DataLoader(dataset=stock_train,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n    for i,(data,label) in enumerate(dataloader):\n        iteration=iteration+1\n        data,label = data.to(device),label.to(device)\n#         print(data)\n        optimizer.zero_grad()\n        output=model.forward(data)\n        loss=criterion(output,label)\n        loss.backward()        \n        optimizer.step()\n        if i%40==0:\n            loss_list.append(loss.item())\n            print(\"epoch=\",epoch,\"iteration=\",iteration,\"loss=\",loss.item())","ee75cfe1":"def test():\n    model.eval()\n    global accuracy_list\n    global predict_list\n    loss_list=[]\n    dataloader=DataLoader(dataset=stock_test,batch_size=BATCH_SIZE_TEST,shuffle=False,drop_last=True)\n    for i,(data,label) in enumerate(dataloader):\n        with torch.no_grad():            \n            data,label=data.to(device),label.to(device)\n            optimizer.zero_grad()\n            predict=model.forward(data)\n            predict_list.append(predict)\n            loss=criterion(predict,label)\n            loss_list.append(loss.item())\n#             accuracy_fn=nn.MSELoss()\n#             accuracy_fn=nn.L1Loss\n#             accuracy=accuracy_fn(predict, label)\n#             accuracy_list.append(accuracy.item())\n    print(\"test_data MSELoss=\",np.mean(loss_list))\n#     print(\"test_data (pred-real)\/real=\",np.mean(accuracy_list))\n#     print(\"test_data L1 loss=\",np.mean(accuracy_list))","c1a459fd":"mkdir('\/kaggle\/working\/output\/')","3b3d4367":"def loss_curve(loss_list):\n    x=np.linspace(1,len(loss_list),len(loss_list))\n    x=20*x\n    plt.plot(x,np.array(loss_list),label=\"train_loss\")\n    plt.ylabel(\"MSELoss\")\n    plt.xlabel(\"iteration\")\n    plt.savefig(\"\/kaggle\/working\/output\/train_loss.png\",dpi=3000)\n    plt.show()","646925c6":"def contrast_lines(predict_list):\n    real_list=[]\n    prediction_list=[]\n    dataloader=DataLoader(dataset=stock_test,batch_size=BATCH_SIZE_TEST,shuffle=False,drop_last=True)\n    for i,(data,label) in enumerate(dataloader):\n        for idx in range(BATCH_SIZE_TEST):\n            real_list.append(np.array(label[idx]*(std_list[3]+1e-10)+mean_list[3]))\n    for item in predict_list:\n        item=item.to(\"cpu\")\n        for idx in range(BATCH_SIZE_TEST):\n            prediction_list.append(np.array((item[idx]*std_list[3]+1e-10)+mean_list[3]))\n    x=np.linspace(1,len(real_list),len(real_list))\n    plt.plot(x,np.array(real_list),label=\"real\")\n    plt.plot(x,np.array(prediction_list),label=\"prediction\")\n    plt.legend()\n    plt.savefig(\"\/kaggle\/working\/output\/600036SH_Pre.png\",dpi=3000)\n    plt.show()","caec0036":"iteration=0\nloss_list=[]\n#\u5f00\u59cb\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\nfor epoch in range(30):\n    predict_list=[]\n    accuracy_list=[]\n    train(epoch)\n    lr_scheduler.step()\n    test()","866c6591":"#\u7ed8\u5236\u635f\u5931\u51fd\u6570\u4e0b\u964d\u66f2\u7ebf    \nloss_curve(loss_list)","bfc86e2f":"#\u7ed8\u5236\u6d4b\u8bd5\u96c6pred-real\u5bf9\u6bd4\u66f2\u7ebf\ncontrast_lines(predict_list)","b94cbfc9":"Refers:\n\nhttps:\/\/github.com\/wangshub\/RL-Stock\/blob\/master\/get_stock_data.py\n\nhttp:\/\/baostock.com\/baostock\/index.php\/Python_API%E6%96%87%E6%A1%A3#.E8.8E.B7.E5.8F.96.E5.8E.86.E5.8F.B2A.E8.82.A1K.E7.BA.BF.E6.95.B0.E6.8D.AE.EF.BC.9Aquery_history_k_data_plus.28.29\n\nhttps:\/\/github.com\/MiaoChenglin125\/stock_prediction-based-on-lstm-and-transformer\/blob\/main\/000001SZ_predict.ipynb"}}