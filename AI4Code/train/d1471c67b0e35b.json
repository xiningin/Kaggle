{"cell_type":{"ecf5a95e":"code","e68a37e8":"code","6bb315fa":"code","fe3a7bc2":"code","4e1f8225":"code","1dce937a":"code","2e7772d2":"code","003101c1":"code","7ead8d7f":"code","9895d86c":"code","d8b02fff":"markdown","15b17119":"markdown","a0e6af94":"markdown","57909eb1":"markdown","ff93cf99":"markdown","e74dfe9f":"markdown","3bbbfc71":"markdown","38e5947f":"markdown","04afdd11":"markdown","5b6d34c5":"markdown","eda917f0":"markdown"},"source":{"ecf5a95e":"! python ..\/input\/mlcomp\/mlcomp\/setup.py","e68a37e8":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport cv2\nimport albumentations as A\nfrom tqdm import tqdm_notebook\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.jit import load\n\nfrom mlcomp.contrib.transform.albumentations import ChannelTranspose\nfrom mlcomp.contrib.dataset.classify import ImageDataset\nfrom mlcomp.contrib.transform.rle import rle2mask, mask2rle\nfrom mlcomp.contrib.transform.tta import TtaWrap","6bb315fa":"unet = load('..\/input\/severstaleffnet\/traced_effnetb7_mixup_retrain.pth').cuda()\ncls = load('..\/input\/severstall-effnetb0-fimal-stage\/traced_model.pth').cuda()\ncls_alt = load('..\/input\/severstaleffnet\/traced_effnetb0_lovasz.pth').cuda()","fe3a7bc2":"def create_transforms(additional):\n    res = list(additional)\n    # add necessary transformations\n    res.extend([\n        A.Normalize(\n            mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n        ),\n        ChannelTranspose()\n    ])\n    res = A.Compose(res)\n    return res\n\nimg_folder = '\/kaggle\/input\/severstal-steel-defect-detection\/test_images'\nbatch_size = 1\nnum_workers = 0\n\n# Different transforms for TTA wrapper\ntransforms = [\n    [],\n    [A.HorizontalFlip(p=1)],\n    [A.VerticalFlip(p=1)],\n]\n\ntransforms = [create_transforms(t) for t in transforms]\ndatasets = [TtaWrap(ImageDataset(img_folder=img_folder, transforms=t), tfms=t) for t in transforms]\nloaders = [DataLoader(d, num_workers=num_workers, batch_size=batch_size, shuffle=False) for d in datasets]","4e1f8225":"class Classifier:\n    def __init__(self, model):\n        self.model = model\n    \n    def __call__(self, loaders_batch):\n        with torch.no_grad():\n            preds = []\n            image_file = []\n            for i, batch in enumerate(loaders_batch):\n                features = batch['features'].cuda()\n                pred_raw, _ = model(features)\n                p = torch.sigmoid(pred_raw)\n                image_file = batch['image_file']\n\n                # inverse operations for TTA\n                p = datasets[i].inverse(p)\n                preds.append(p)\n\n            # TTA mean\n            preds = torch.stack(preds)\n            preds = torch.mean(preds, dim=0)\n            preds = preds.detach().cpu().numpy()\n\n            # Batch post processing\n            p_img = []\n            for p, file in zip(preds, image_file):\n                file = os.path.basename(file)\n                # Image postprocessing\n                for i in range(4):\n                    p_channel = p[i]\n                    p_channel = (p_channel>thresholds[i]).astype(np.uint8)\n                    if p_channel.sum() < min_area[i]:\n                        p_channel = np.zeros(p_channel.shape, dtype=p_channel.dtype)\n                    p_img.append(p_channel)\n        return p_img\n\n\nclass Model:\n    def __init__(self, models):\n        self.models = models\n    \n    def __call__(self, x):\n        res = []\n        labels = []\n        x = x.cuda()\n        with torch.no_grad():\n            for m in self.models:\n                masks, label = m(x)\n                res.append(masks)\n                labels.append(label)\n        res = torch.stack(res)\n        labels = torch.stack(labels)\n        return torch.mean(res, dim=0), torch.mean(labels, dim=0)\n\nmodel = cls_alt\n# cls2 = Classifier(cls_alt)","1dce937a":"import numpy as np\nimport torch\nl = torch.tensor([1, 0])\nif np.count_nonzero(l):\n    print('yay')","2e7772d2":"thresholds = [0.6, 0.99, 0.6, 0.6] # [0.5, 0.5, 0.5, 0.5] | [0.55, 0.55, 0.55, 0.55] | [0.6, 0.99, 0.6, 0.6]\nmin_area = [600, 600, 1000, 2000] # instead of 900 -> 1000 in old version\n\nres = []\n# Iterate over all TTA loaders\ntotal = len(datasets[0])\/\/batch_size\nwith torch.no_grad():\n    for loaders_batch in tqdm_notebook(zip(*loaders), total=total):\n        preds = []\n        image_file = []\n        labels = []\n        for i, batch in enumerate(loaders_batch):\n            features = batch['features'].cuda()\n            output = model(features)\n            pred_raw, label = output\n            labels.append(label)\n            p = torch.sigmoid(pred_raw)\n            image_file = batch['image_file']\n\n            # inverse operations for TTA\n            p = datasets[i].inverse(p)\n            preds.append(p)\n    \n        # TTA mean\n        preds = torch.stack(preds)\n        preds = torch.mean(preds, dim=0)\n        preds = preds.detach().cpu().numpy()\n        labels = torch.stack(labels)\n        labels = torch.mean(labels, dim=0)\n        labels = labels.detach().cpu().numpy()  # has shape (1, 4)\n        labels = labels[0] \n    \n        # Batch post processing\n        for p, file in zip(preds, image_file):\n            file = os.path.basename(file)\n            # Image postprocessing\n            for i in range(4):\n                p_channel = np.zeros((256, 1600), dtype=np.uint8)\n                imageid_classid = file+'_'+str(i+1)\n                if labels[i] > 0:\n                    p_channel = p[i]\n                    p_channel = (p_channel>thresholds[i]).astype(np.uint8)\n                    if p_channel.sum() < min_area[i]:\n                        p_channel = np.zeros(p_channel.shape, dtype=p_channel.dtype)\n\n                res.append({\n                    'ImageId_ClassId': imageid_classid,\n                    'EncodedPixels': mask2rle(p_channel)\n                })\n        \ndf = pd.DataFrame(res)\ndf.to_csv('submission.csv', index=False)","003101c1":"df = pd.DataFrame(res)\ndf = df.fillna('')\ndf.to_csv('submission.csv', index=False)","7ead8d7f":"df['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\ndf['empty'] = df['EncodedPixels'].map(lambda x: not x)\ndf[df['empty'] == False]['Class'].value_counts()","9895d86c":"%matplotlib inline\n\ndf = pd.read_csv('submission.csv')[:40]\ndf['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\n\nfor row in df.itertuples():\n    img_path = os.path.join(img_folder, row.Image)\n    img = cv2.imread(img_path)\n    mask = rle2mask(row.EncodedPixels, (1600, 256)) \\\n        if isinstance(row.EncodedPixels, str) else np.zeros((256, 1600))\n    if mask.sum() == 0:\n        continue\n    \n    fig, axes = plt.subplots(1, 2, figsize=(20, 60))\n    axes[0].imshow(img\/255)\n    axes[1].imshow(mask*60)\n    axes[0].set_title(row.Image)\n    axes[1].set_title(row.Class)\n    plt.show()","d8b02fff":"### Create TTA transforms, datasets, loaders","15b17119":"As the competition does not allow commit with the kernel that uses internet connection, we use offline installation","a0e6af94":"### Import required libraries","57909eb1":"### Load models","ff93cf99":"### Loaders' mean aggregator","e74dfe9f":"### Visualization","3bbbfc71":"Save predictions","38e5947f":"### Models' mean aggregator","04afdd11":"### Install MLComp library(offline version):","5b6d34c5":"Catalyst allows to trace models. That is an extremely useful features in Pytorch since 1.0 version: \n\nhttps:\/\/pytorch.org\/docs\/stable\/jit.html\n\nNow we can load models without re-defining them","eda917f0":"Histogram of predictions"}}