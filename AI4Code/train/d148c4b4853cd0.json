{"cell_type":{"c980214e":"code","1e2386fb":"code","77a86d3a":"code","ecc727ef":"code","a5f28aaa":"code","b66b2093":"code","8823939d":"code","a7b5d2a3":"code","3d2968df":"code","e03cb4c4":"code","1c2b6641":"code","cdade454":"code","205114d3":"code","1193d4a1":"code","71e4df38":"code","9f7f89c0":"code","257fee2b":"code","5902677b":"code","0276a9db":"code","6b0505ef":"code","2e2d9964":"code","411ee468":"code","36dc0faf":"code","90ebb555":"code","e820491b":"code","178d9478":"code","0bbd741d":"code","bdc352c3":"markdown","82606d9e":"markdown","9b8ef731":"markdown","54e01ad1":"markdown","4def240f":"markdown","710a662b":"markdown","e071d366":"markdown","de83f0d4":"markdown","6760008a":"markdown","30a25169":"markdown","de87ad99":"markdown","d26c553b":"markdown"},"source":{"c980214e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1e2386fb":"data=pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndata.head()","77a86d3a":"%matplotlib inline\nimport seaborn as sns","ecc727ef":"x=data.iloc[:,0:13]\ny=data.iloc[:,13:]","a5f28aaa":"from sklearn.model_selection import cross_val_score\nfrom catboost import CatBoostClassifier\ncat=CatBoostClassifier(iterations=5)\ncross_val_score(cat,x,y,cv=3)","b66b2093":"cat=CatBoostClassifier(iterations=50)\ncross_val_score(cat,x,y,cv=3)","8823939d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","a7b5d2a3":"cat=CatBoostClassifier(iterations=150,learning_rate=1)\ncat.fit(X_train,y_train)","3d2968df":"ypred=cat.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","e03cb4c4":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=20)\ngb.fit(X_train,y_train)\nypred=gb.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","1c2b6641":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=10)\ngb.fit(X_train,y_train)\nypred=gb.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","cdade454":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(X_train,y_train)\nypred=rfc.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","205114d3":"from sklearn.decomposition import PCA\npca=PCA(n_components=3)\nx_pca=pca.fit_transform(x)","1193d4a1":"from sklearn.model_selection import train_test_split\nxp_train, xp_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.25, random_state=42)","71e4df38":"cat=CatBoostClassifier(iterations=150,learning_rate=1)\ncat.fit(xp_train,y_train)\nypred=cat.predict(xp_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","9f7f89c0":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=10)\ngb.fit(xp_train,y_train)\nypred=gb.predict(xp_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","257fee2b":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(xp_train,y_train)\nypred=rfc.predict(xp_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","5902677b":"from sklearn.decomposition import PCA\npca=PCA(n_components=10)\nx_pca=pca.fit_transform(x)","0276a9db":"from sklearn.model_selection import train_test_split\nxp_train, xp_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.25, random_state=42)\n","6b0505ef":"cat=CatBoostClassifier(iterations=150,learning_rate=1)\ncat.fit(xp_train,y_train)\nypred=cat.predict(xp_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","2e2d9964":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=10)\ngb.fit(xp_train,y_train)\nypred=gb.predict(xp_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","411ee468":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(xp_train,y_train)\nypred=rfc.predict(xp_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","36dc0faf":"import category_encoders as ce\ncount_encode=ce.CountEncoder(cols=[\"sex\",\"cp\",\"slope\",\"thal\"])\nx_count=count_encode.fit_transform(x)\n\nfrom sklearn.model_selection import train_test_split\nXco_train, Xco_test, y_train, y_test = train_test_split(x_count, y, test_size=0.25, random_state=42)","90ebb555":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(Xco_train,y_train)\nypred=rfc.predict(Xco_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","e820491b":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=10)\ngb.fit(Xco_train,y_train)\nypred=gb.predict(Xco_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","178d9478":"from sklearn.model_selection import cross_val_score\nfrom catboost import CatBoostClassifier\ncat=CatBoostClassifier(iterations=5)\ncross_val_score(cat,x_count,y,cv=3)","0bbd741d":"cat=CatBoostClassifier(verbose=0)\ncat.fit(Xco_train,y_train)\nypred=cat.predict(Xco_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))","bdc352c3":"## Less column can't work well with these algorithm. Especially gradient boosting algorithm. ","82606d9e":"### I don't know much about catboost but looks like it's work.","9b8ef731":"Catboost is crying. %64 accuracy is horrific.","54e01ad1":"## Conclusion\nBoosting Algorithm has potential but old school algorithm is also in race. ","4def240f":"## Count Encoders improve Categorical variable further with frequency and it's works :)","710a662b":"Same things as catboost.","e071d366":"## \u0130t's work better than Catboost.What our old friend random forest. ","de83f0d4":"With Count Encoder accuracy is greater than ever. ","6760008a":"Same","30a25169":"## Random forest is works better than XGBoost","de87ad99":"Better than 3 component pca but not best.","d26c553b":"## Catboost have promising results."}}