{"cell_type":{"a47c58bd":"code","585a9997":"code","cbc71d03":"code","a1e1588b":"code","1e196146":"code","a82e9df3":"code","41f43050":"code","867dfc27":"code","bc7ae616":"code","6ea27e7e":"code","d00416ea":"code","b4339769":"code","b12b7838":"code","7c493966":"code","fd8561e3":"code","b69191fa":"code","54cb1d8d":"code","adaad4b8":"code","47dded77":"code","a84d534c":"code","bd35c92a":"code","2a12c984":"code","dc6db1ed":"code","22f3da13":"code","f08eb82c":"code","6199f8b4":"code","e71f7afc":"code","42d6a2cd":"code","8685891c":"code","72a4ab09":"markdown","528efaad":"markdown","e5f62e64":"markdown","4093106e":"markdown","40e23895":"markdown","bdb3acbf":"markdown","cad2473f":"markdown","38c37f38":"markdown","f214faa2":"markdown","856569bf":"markdown","4260af6b":"markdown","f1ee2f9c":"markdown"},"source":{"a47c58bd":"#import libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)","585a9997":"train_df = pd.read_csv('..\/input\/titanicdataset-traincsv\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic-test-set\/test.csv')","cbc71d03":"corrmatrix = train_df.corr()\ncorrmatrix","a1e1588b":"train_df.drop(\"Name\", axis =1, inplace=True)\ntrain_df.drop(\"Cabin\", axis =1, inplace=True)\ntrain_df.drop(\"Fare\", axis =1, inplace=True)\ntrain_df.drop(\"PassengerId\", axis =1, inplace=True)\ntrain_df.drop(\"Ticket\", axis =1, inplace=True)\n\n\ntest_df.drop(\"Ticket\", axis =1, inplace=True)\ntest_df.drop(\"PassengerId\", axis =1, inplace=True)\ntest_df.drop(\"Name\", axis =1, inplace=True)\ntest_df.drop(\"Cabin\", axis =1, inplace=True)\ntest_df.drop(\"Fare\", axis =1, inplace=True)","1e196146":"train_df.head()","a82e9df3":"test_df.head()","41f43050":"source = train_df.drop('Survived', axis=1)\ntarget = train_df['Survived']\n\nsource.shape, target.shape","867dfc27":"source.head()","bc7ae616":"target.head()","6ea27e7e":"df_cat = source.drop(['Age', 'Parch', 'SibSp', 'Pclass'], axis =1)\n\ncat_attribs = list(df_cat)\ncat_attribs","d00416ea":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n\n\ncat_pipeline = Pipeline([\n    ('imputer_cat', SimpleImputer(strategy=\"most_frequent\")),\n    ('encoder', OneHotEncoder(handle_unknown='ignore')),\n])\n\nfull_pipeline = ColumnTransformer([\n    (\"cat\", cat_pipeline, cat_attribs),\n])\n\nsource_final = full_pipeline.fit_transform(source)\n","b4339769":"source_final.shape","b12b7838":"target1 = target.to_numpy()","7c493966":"target.shape","fd8561e3":"target = target1.reshape(1,-1)","b69191fa":"target = target.transpose()\ntarget.shape","54cb1d8d":"#test_final = full_pipeline.transform(test_df)","adaad4b8":"from sklearn.model_selection import train_test_split\nsource_train, source_test, target_train, target_test = train_test_split(source_final, target, test_size = 0.25, random_state=0)","47dded77":"target_test.shape","a84d534c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import accuracy_score","bd35c92a":"LR = LogisticRegression()","2a12c984":"LR.fit(source_train, target_train)","dc6db1ed":"LRpred = LR.predict(source_test)","22f3da13":"LR.score(source_test, LRpred)","f08eb82c":"LRpred","6199f8b4":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(target_test,LRpred)","e71f7afc":"accuracy_score(target_test,LRpred)","42d6a2cd":"from sklearn.metrics import recall_score\nrecall_score(target_test,LRpred, average=None)","8685891c":"from sklearn.metrics import precision_score\nprecision_score(target_test,LRpred, average=None","72a4ab09":"The confusion matrix tells us the true positives and true negatives that the model predicted.","528efaad":"Linear Models","e5f62e64":"Now lets create train test split as it will help when I calculate accuracy and other scores.","4093106e":"Import the train and test data sets into different dataframes.","40e23895":"Now I need to convert categorical attributes into numberical values, therefore I created a new dataframe where I only stored categorical attributes.","bdb3acbf":"Then I created a new pipeline where I was able to one hot encode the data and merge it back into the source_final dataframe.","cad2473f":"As you can see the model worked.","38c37f38":"Creating the source and target dataframes. I dropped the label for source as we are going to use to train the model.","f214faa2":"I applied logistic regression, but if you want you can also apply other algorithms.","856569bf":"I decided to drop the above columns from the datasets as they had no influence on the final prediction. For example, knowing the name, cabin number, fare, passengerID or ticket doesnot effect the prediction. I did decide to keep the passengerclass (pclass) column becuase it tells me which class the passenger belongs to. This is helpful because different classes are assigned different levels. For example, higher class passengers will have the upper deck where as lower class passengers will have the lower deck. So, in the advent of an accident, it is more likely that people in the lower class will be hurt first.","4260af6b":"As you can see, this model corrected classifed 115 True Positives and 59 True Negatives the rest were false predictions. Below you will find all the different accuracy scores, you can try to improve the score by trying different algorithms like XGboost, KNN and SVC, you can also apply crossvalidation to find the best hyperparameters.","f1ee2f9c":"First import the relevant libraries into Python."}}