{"cell_type":{"797fc4ee":"code","33a5b67e":"code","bcf2715a":"code","ad10e76a":"code","b6c6fefb":"code","6adc6ce2":"code","94bec7b2":"code","e5cc78ba":"code","79e4c844":"code","eacc7d22":"code","03f7197c":"code","1d2ecc5e":"code","1b758f5b":"code","6a9b91c0":"code","9d2e4205":"code","b62f13a5":"code","c0fc316b":"markdown","0f73b82b":"markdown","5744c48c":"markdown","5aeac34e":"markdown","ea13a713":"markdown","53dec133":"markdown","9aa625fc":"markdown","c8501c94":"markdown","ed584438":"markdown","add2365b":"markdown","7b8f4bf8":"markdown"},"source":{"797fc4ee":"!pip install matplotlib pandas\n!pip install --upgrade https:\/\/download.pytorch.org\/whl\/cu100\/torch-1.0.1.post2-cp37-cp37m-linux_x86_64.whl\n!pip install --upgrade torchvision","33a5b67e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n# Any results you write to the current directory are saved as output.\nimport torch\nfrom torch import nn\nfrom torch.nn.parameter import Parameter\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom matplotlib import pyplot as plt\nimport time\nfrom PIL import Image\n\nimport torchvision\nfrom torchvision import transforms\n\nif torch.cuda.is_available():\n    use_cuda=True\nelse:\n    use_cuda=False\n\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\nprint(device)","bcf2715a":"data_train = torchvision.datasets.FashionMNIST(\".\/\", train=True, transform=None, target_transform=None, download=True)\ndata_test = torchvision.datasets.FashionMNIST(\".\/\", train=False, transform=None, target_transform=None, download=True)","ad10e76a":"df_train = pd.DataFrame(np.hstack((data_train.train_labels.reshape(-1, 1), data_train.train_data.reshape(-1,28*28))))\ndf_test = pd.DataFrame(np.hstack((data_test.test_labels.reshape(-1, 1), data_test.test_data.reshape(-1,28*28))))\ndf_train.head()","b6c6fefb":"lbl_map = {\n    0 : \"T-shirt\/top\",\n    1 : \"Trouser\",\n    2 : \"Pullover\",\n    3 : \"Dress\",\n    4 : \"Coat\",\n    5 : \"Sandal\",\n    6 : \"Shirt\",\n    7 : \"Sneaker\",\n    8 : \"Bag\",\n    9 : \"Ankle boot\"\n}","6adc6ce2":"#plot.bar(figsize=(16,6), color=\"b\")\ncnt_df = df_train.iloc[:,0].value_counts()\ncnt_df.rename(lbl_map, axis='index').plot.bar(figsize=(16,6), color=\"b\")","94bec7b2":"def random_blackout(img, input_dim=(28, 28)):\n    min_side = np.min(input_dim)\n    high = np.round(min_side * .60)\n    low = np.round(min_side * .15)\n    # height, width\n    h, w = np.random.randint(high=high, low=low, size=(2))\n\n    # offsets top and left\n    ofs_t = np.random.randint(high=input_dim[0]-h, low=0, size=1)[0]\n    #ofs_t = 0\n    ofs_l = np.random.randint(high=input_dim[1]-w, low=0, size=1)[0]\n    #ofs_l = 0\n\n    mask = np.ones(input_dim)\n\n    mask[ofs_t:ofs_t+h,ofs_l:ofs_l+w] = 0\n\n    return img * mask\n\nclass BlackoutTransform():\n    def __init__(self):\n        \"\"\"\n        \"\"\"\n        \n    def __call__(self, img):\n        img_dim = img.shape\n        np_arr = img.view(28,28).numpy()\n        np_arr = random_blackout(np_arr, np_arr.shape)\n        return torch.FloatTensor(np_arr).view(img_dim)\n\nclass ReshapeTransform():\n    def __init__(self, new_size):\n        \"\"\"\n        :new_size: tuple\n        \"\"\"\n        self.new_size = new_size\n\n    def __call__(self, img):\n        \"\"\"Reshape an image\n        :img: ex 1x28x28\n        :returns: reshaped tensor\n        \"\"\"\n        return torch.reshape(img, self.new_size)\n    \n\nt = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n                        #transforms.RandomVerticalFlip(p=0.5),\n                        transforms.Pad((5,6)),\n                        transforms.RandomCrop(size=28, padding_mode=\"reflect\"),\n                        #transforms.RandomCrop(size=28),\n                        #transforms.RandomAffine([0,180], translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n                        # Resize random crop, then pad\n                        #transforms.RandomResizedCrop(28, scale=(1.1, 1.3), ratio=(1.1, 1.5), interpolation=2),\n                        transforms.ToTensor(),\n                        BlackoutTransform(),\n                        ReshapeTransform((1, 28, 28))\n])\n\nclass CustomTensorDataset(torch.utils.data.TensorDataset):\n    def __init__(self, *tensors, transforms=None):\n        self.transform = transforms\n        super().__init__(*tensors)\n    \n    def __getitem__(self, index):\n        img, target = self.tensors[0][index], self.tensors[1][index]\n        \n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(np.uint8(img.view(28,28).numpy()), mode='L')\n    \n        if self.transform is not None:\n            img = self.transform(img)\n                \n        return (img, target)","e5cc78ba":"def exclude_class(inputs, lbls, class_lbl):\n    indices = np.where(lbls != class_lbl)\n    inputs = np.take(inputs, indices[0], axis=0)\n    lbls = np.take(lbls, indices[0], axis=0)\n    return inputs, lbls\n","79e4c844":"# Train data\ntrain_X = df_train.iloc[:,1:]\ntrain_Y = df_train.iloc[:,:1]\n# Test data\ntest_X = df_test.iloc[:,1:]\ntest_Y = df_test.iloc[:,:1]\n\n#train_X, train_Y = exclude_class(train_X, train_Y, 2)\n#test_X, test_Y = exclude_class(test_X, test_Y, 2)\n\n# Normalize data to [0,1]\n#fmnist_train = torch.utils.data.TensorDataset(torch.FloatTensor(train_X.values\/255).view(-1,1,28,28), torch.LongTensor(train_Y.values).view(-1))\nfmnist_train = CustomTensorDataset(torch.FloatTensor(train_X.values), torch.LongTensor(train_Y.values).view(-1), transforms=t)\nfmnist_test = torch.utils.data.TensorDataset(torch.FloatTensor(test_X.values\/255).view(-1,1,28,28), torch.LongTensor(test_Y.values).view(-1))","eacc7d22":"def show_images(images):\n    n_images = len(images)\n    w, h = 10, 10\n    columns = 10\n    rows = n_images \/ columns\n    fig=plt.figure(figsize=(columns*2, rows*2))\n    for i in range(n_images):\n        img = images[i].reshape(28,28)\n        fig.add_subplot(rows, columns, i+1)\n        plt.imshow(img, cmap='gray')\n        plt.axis('off')\n    plt.show()\n\n\nexamples = []\n# Take 10 of each lbl class\nfor k in lbl_map.keys():\n    indices = np.where(train_Y == k)\n    images = np.take(train_X.values, indices[0][:10], axis=0)\n    examples = examples + [x for x in images]\n    \n#examples = [x for x in examples for y in examples[]]\n\nprint(lbl_map)\nshow_images(examples)\n\nprint(\"Preprocessed random 40:\")\nexamples = [fmnist_train[x][0] for x in range(40)]\nshow_images(examples)","03f7197c":"def conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"Creates a 3x3 convolution w. padding (1,1)\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, \n                     padding=1, bias=False)\n\nclass ResnetBlock(nn.Module):\n    expansion = 1\n    \n    def __init__(self, in_planes, out_planes, stride=1, downsample=None, dropout=0.18):\n        super(ResnetBlock, self).__init__()\n        # Conv layer 1\n        self.conv_1 = conv3x3(in_planes, out_planes, stride)\n        self.batch_norm_1 = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropout = dropout\n        if self.dropout:\n            self.dropout1 = nn.Dropout(p=dropout)\n        # Conv layer 2\n        self.conv_2 = conv3x3(out_planes, out_planes)\n        self.batch_norm_2 = nn.BatchNorm2d(out_planes)\n        self.downsample = downsample\n        self.stride = stride\n        \n    def forward(self, x):\n        residual = x\n        \n        out = self.conv_1(x)\n        # If no dropout then use batchnorm\n        if not self.dropout:\n            out = self.batch_norm_1(out)\n        out = self.relu(out)\n        \n        # Use dropout in between\n        if self.dropout:\n            out = self.dropout1(out)\n        \n        out = self.conv_2(out)\n        out = self.batch_norm_2(out)\n        \n        if self.downsample is not None:\n            residual = self.downsample(x)\n        \n        out += residual\n        out = self.relu(out)\n        return out\n    \nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=10, k=1):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        # Convert to 64 channels\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)  # out bx64x28x28\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # out bx64x14x14\n        self.layer1 = self._make_layer(block, 64*k, layers[0])  # out bx(64xk)x14x14\n        self.layer2 = self._make_layer(block, 128*k, layers[1], stride=2)  # out bx(128xk)x7x7\n        #self.layer3 = self._make_layer(block, 256*k, layers[2], stride=2)\n        #self.layer4 = self._make_layer(block, 512*k, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # out bx(128*k)x1x1\n        self.fc = nn.Linear(128*k * block.expansion, num_classes)  # out bx10\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                #nn.init.xavier_normal_(m.weight)\n                \n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        #x = self.layer3(x)\n        #x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n    \ndef init_weights(m):\n    if type(m) == nn.Linear:\n        nn.init.xavier_normal_(m.weight.data)\n","1d2ecc5e":"## Initialize model\nmodel = ResNet(ResnetBlock, [2,2,2,2], k=2)\n\n# Initialize linear layers\nmodel.apply(init_weights)\n\n# load pretrained state\nmodel.to(device)\nmodel.load_state_dict(torch.load(\"..\/input\/fashion-mnist-model\/test_acc-9560-epoch73.pth\"))\n\n# Loss fn\ncriterion = nn.CrossEntropyLoss()\n\n# optimizer and scheduler\noptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', min_lr=1e-4, patience=8, verbose=True)\n\n# only save model state if test acc is above \"best_test_acc\"\nbest_test_acc = 9560\n\n# Use dramatic increased LR every x'th epoch (0 = None)\nlr_inc_interval = 40\n\n# Batch size\nbatch_size = 256\n\ntrain_loader = torch.utils.data.DataLoader(dataset=fmnist_train,\n                                           batch_size=batch_size,\n                                           pin_memory=True if use_cuda else False,\n                                           shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=fmnist_test,\n                                          batch_size=batch_size,\n                                          pin_memory=True if use_cuda else False,\n                                          shuffle=False)\n\n# Cache train and testset size\ntrain_size = len(train_loader.dataset)\ntest_size = len(test_loader.dataset)","1b758f5b":"# Used 800 epochs in both training steps\nfor epoch in range(0):\n    # statistics\n    train_loss = 0\n    train_correct = 0\n    test_correct = 0\n    test_loss = 0\n    time_start = time.time()\n    # --\n\n    if lr_inc_interval and not epoch % lr_inc_interval and epoch is not 0:\n        print(\"Increasing LR -- Big Steps\")\n        tmp_param_groups = optimizer.param_groups\n        scheduler.num_bad_epochs -= 2\n        for g in optimizer.param_groups:\n            g['lr'] = 0.2\n    else:\n        tmp_param_groups = None\n\n    model.train()\n    for i, data in enumerate(train_loader):\n        # inputs\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the gradient\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n\n        optimizer.step()\n\n        # stats\n        train_loss += loss\n        train_correct += outputs.argmax(-1).eq(labels).sum()\n\n    # Release unesecary memory\n    if use_cuda:\n        torch.cuda.empty_cache()\n        \n    # Sometimes take a huge step\n    if tmp_param_groups:\n        optimizer.param_groups = tmp_param_groups\n\n    model.eval()\n    with torch.no_grad():\n        for i, data in enumerate(test_loader):\n            # inputs\n            inputs, labels = data[0].to(device), data[1].to(device)\n            outputs = model(inputs)\n\n            # test loss\n            test_loss += criterion(outputs, labels)\n\n            # accuracy\n            test_correct += outputs.argmax(-1).eq(labels).sum()\n            \n\n    test_loss = test_loss\/test_size\n    scheduler.step(test_loss)\n    \n    if test_correct > best_test_acc and test_correct > 9480:\n        best_test_acc = test_correct\n        print(\"Saving model\")\n        torch.save(model.state_dict(), 'test_acc-{}-epoch{}.pth'.format(test_correct, epoch))\n    \n    print(\"#{} {:.2f} seconds, \\n  train: {}, {}\/{}, test: {}, {}\/{}\".format(\n        epoch+1, time.time() - time_start,\n        train_loss\/train_size,\n        train_correct, train_size,\n        test_loss,\n        test_correct, test_size))","6a9b91c0":"total_wrong_labels = torch.LongTensor().cuda()\nmodel.eval()\nwith torch.no_grad():\n    for i, data in enumerate(test_loader):\n        # inputs\n        inputs, labels = data[0].to(device), data[1].to(device)\n        outputs = model(inputs)\n\n        # correct\n        test_correct = outputs.argmax(-1).eq(labels)\n        wrong_labels = labels[test_correct == 0]\n        total_wrong_labels = torch.cat((total_wrong_labels, wrong_labels))","9d2e4205":"t_np = total_wrong_labels.cpu().numpy()","b62f13a5":"lbl_counts = np.unique(t_np, return_counts=True)\n\nlbls, counts = lbl_counts\nfor idx, lbl in enumerate(lbls):\n    try:\n        print(\"{}: {}\".format(lbl_map[lbl], counts[idx]))\n    except:\n        print(\"{} is excluded.\".format(lbl_map[lbl]))\n        \ndf_wrong = pd.DataFrame(counts).rename(lbl_map, axis='index')\nax = df_wrong.plot.bar(figsize=(16,6), color=\"b\", title=\"Model Wrong Classifications\", fontsize=16, rot=0)\n\nprint(\"Total wrong classifications: {}\/{}\".format(counts.sum(), len(fmnist_test)))","c0fc316b":"__Yeah, I know the data is already here with the Kaggle kernel, but I had to run the notebook locally as well__","0f73b82b":"## Simple model evaluation","5744c48c":"Above function where used to exclude some classes from tesand training set to experiment\n\nBelow the training and test datasets are wrapped in Pytorch datasets for using their data loaders in training.","5aeac34e":"## Wrap up\nThe Model has some problems seperating T-shirt\/top, Pullover and Shirts apart - that's also tricky for the human eye, so all in all I am happy with the performance\n","ea13a713":"## Data preprocessing pipeline\n- Random horizontal flips\n- Padding left\/right 5px, top\/bottom 6px\n- Random cropping to 28x28 px\n- Random square blackout region in img with hight, width being between: 28 x 0.15 <--> 28 x 0.60","53dec133":"First column = lbl, and rest = image\n\nAbove is the distrubution of classes in the training set:","9aa625fc":"### The training part\n","c8501c94":"#### Ensure the right versions of pytorch + torchvision are installed","ed584438":"### Inspecting data manually\nPlots 10 images of each class without preprocessing\n\n.. and then 40 preprocessed images to verify the preprocessing pipeline","add2365b":"## Network Inspired by WRN and Deep ResNet\n__Papers used:__ \n- Wide Residual Networks: https:\/\/arxiv.org\/pdf\/1605.07146.pdf \n- Deep Residual Learning for Image Recognition: https:\/\/arxiv.org\/pdf\/1512.03385.pdf\n\nWhile reading the Deep Learning Book (by Ian Goodfellow and Yoshua Bengio and Aaron Courville), I am trying the various concepts off on smaller datasets to sharpen my DL skills.\n\nIn this network I wanted to use CNN (chapter 9) on a dataset, which where a bit more challenging than the simple MNIST, I used when playing with plain Deep NN's.\n\nI managed to get to an accuracy of __95.60%__ on the test set.\n\nI started by reading the papers I mentioned above and used the _resnet18_ from pytorch as a starting point, then I ended up with following architecture:\n\n    input bx1x28x28\n    -> Conv (out: bx64x28x28)\n    -> maxpool (out: bx64x14x14)\n    -> resnet block (out: bx128x14x14)\n    -> resnet block (out: bx256x7x7)\n    -> avgpool(1,1) (out: bx256x1x1)\n    -> linear(256, 10) (out: bx10)\n    \n    Using Dropout 0.18 in the resnet blocks instead of Batch norm\n    \n    Also I introduced setting the LR to 0.2 (Big Steps) every x'th epoch in order to escape out of local minimas. It turned out to improve my test acc. by almost 1%\n    \nTraining using SGD with: <br>\n__Weight decay :__ 0.0001<br>\n__Momentum fixed     :__ 0.9:<br>\n\nTraining where done in 2 parts: \n- First without the LR (Big steps) and saving the best state\n- Loading best state and using \"Big steps\" to acheive __95.60%__ acc. on test set.","7b8f4bf8":"#### The Actual Model and helper functions\/classes to create resnet blocks"}}