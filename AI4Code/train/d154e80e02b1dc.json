{"cell_type":{"4b80eeea":"code","8fbaae9b":"code","e955735d":"code","f874e48f":"code","b4608418":"code","e01ee455":"code","747d961c":"code","024665e8":"code","0a51bb1e":"code","c809c324":"code","59f76e53":"code","a5ca83de":"code","e1af90d7":"code","822d953a":"code","474ed5b0":"code","6388fcbe":"code","1412e57e":"code","b9a6b41e":"code","3b121c69":"code","8eef8f25":"code","0defbc0d":"code","32370f3d":"code","bad29633":"code","2dd2762b":"code","107b172a":"code","a8e4be13":"code","90200af5":"code","fd26fcbe":"code","b41b4d06":"code","b03a0704":"code","f8a20bec":"code","c9c4445d":"code","9d41b7f0":"code","0195a66f":"code","7da0fa59":"code","211dfa85":"code","af156d8a":"code","474d256d":"code","716a7d70":"code","23cc3d13":"markdown","a8bb9d24":"markdown","b4f150f9":"markdown","aef5f280":"markdown","aaf2cfc9":"markdown","309c98d2":"markdown","71187690":"markdown","6ee4a8d7":"markdown","18d7faeb":"markdown","810778f5":"markdown","6b6529a2":"markdown","b04928fd":"markdown","cc44f80b":"markdown","b9cb1d18":"markdown"},"source":{"4b80eeea":"from fastai.conv_learner import *\nfrom fastai.dataset import *\n\nfrom pathlib import Path\nimport json\ntorch.cuda.set_device(0)\nfrom pathlib import Path\ntorch.cuda.set_device(0)","8fbaae9b":"ls \/kaggle\/input\/","e955735d":"MASKS = 'train.csv'\nSUB = 'sample_submission.csv'\nTRAIN = Path('train\/')\nTEST = Path('test\/')\nPATH = Path('\/kaggle\/input\/human-protein-atlas-image-classification\/')\nTMP = Path('\/kaggle\/working\/tmp\/')\nMODEL = Path('\/kaggle\/working\/model\/')\nPRETRAINED = '\/kaggle\/input\/4-channel-darknet-sz-256\/model\/256'\nseg = pd.read_csv(PATH\/MASKS).set_index('Id')\nsample_sub = pd.read_csv(PATH\/SUB).set_index('Id')\n\nsample= len(seg)\nseg.head()","f874e48f":"train_names_png = [TRAIN\/f for f in os.listdir(PATH\/TRAIN)]\ntrain_names = list(seg.index.values)\ntrain_names_sample = list(seg.index.values)[0:sample]\ntest_names_png = [TEST\/f for f in os.listdir(PATH\/TEST)]\ntest_names = list(sample_sub.index.values)\ntest_names_sample = list(sample_sub.index.values)[0:sample]\nlen(train_names_sample), len(test_names)","b4608418":"TMP.mkdir(exist_ok=True)\nMODEL.mkdir(exist_ok=True)","e01ee455":"def rgba_open(fname, path=PATH, sz=128):\n    '''open RGBA image from 4 different 1-channel files.\n    return: numpy array [4, sz, sz]'''\n    flags = cv2.IMREAD_GRAYSCALE\n    red = cv2.imread(str(path\/(fname+ '_red.png')), flags)\n    blue = cv2.imread(str(path\/(fname+ '_blue.png')), flags)\n    green = cv2.imread(str(path\/(fname+ '_green.png')), flags)\n    yellow = cv2.imread(str(path\/(fname+ '_yellow.png')),flags)\n    im = np.array([red, green, blue, yellow], dtype=np.float32)\n    if sz==512:\n        return im\/255\n    else:\n        rgba = cv2.resize(np.rollaxis(im, 0,3), (sz, sz), interpolation = cv2.INTER_CUBIC)\n        return np.rollaxis(rgba, 2,0)\/255\n","747d961c":"seg2 = seg.iloc[0:sample]\nval_idxs = get_cv_idxs(sample)","024665e8":"class CustomDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path, sz):\n        self.y=y\n        self.fnames = fnames\n        self.sz = sz\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n        \n    def get_x(self, i): \n        return rgba_open(self.fnames[i], self.path, self.sz)\n        \n    def get_y(self, i):\n        return self.y[i]\n    def get_sz(self): return self.sz\n    def get_c(self): return 28\n    @property\n    def is_multi(self):\n        return True","0a51bb1e":"indexes = seg2.Target.apply(str.split)\ny = np.zeros((sample, 28))\nfor i in range(sample):\n    y[i,np.array(indexes[i], dtype=int)]=1","c809c324":"len(train_names_sample),  y.shape, y.dtype","59f76e53":"((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(train_names_sample), y)","a5ca83de":"# tfms = tfms_from_model(resnet34, sz=sz, crop_type=CropType.NO, aug_tfms=[])\ndef get_data(sz=128, bs=32):\n    datasets = ImageData.get_ds(CustomDataset, (trn_x,trn_y), (val_x,val_y), sz=sz, tfms=(None,None), path=PATH\/TRAIN)\n    datasets[4] = CustomDataset(test_names, test_names, None, PATH\/TEST, sz)\n    return ImageData(PATH, datasets, bs=bs, num_workers=4, classes=28)","e1af90d7":"class ConvBN(nn.Module):\n    \"convolutional layer then batchnorm\"\n\n    def __init__(self, ch_in, ch_out, kernel_size = 3, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(ch_out, momentum=0.01)\n        self.relu = nn.LeakyReLU(0.1, inplace=True)\n\n    def forward(self, x): return self.relu(self.bn(self.conv(x)))","822d953a":"class DarknetBlock(nn.Module):\n    def __init__(self, ch_in):\n        super().__init__()\n        ch_hid = ch_in\/\/2\n        self.conv1 = ConvBN(ch_in, ch_hid, kernel_size=1, stride=1, padding=0)\n        self.conv2 = ConvBN(ch_hid, ch_in, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x): return self.conv2(self.conv1(x)) + x","474ed5b0":"class Darknet(nn.Module):\n    \"Replicates the darknet classifier from the YOLOv3 paper (table 1)\"\n\n    def make_group_layer(self, ch_in, num_blocks, stride=1):\n        layers = [ConvBN(ch_in,ch_in*2,stride=stride)]\n        for i in range(num_blocks): layers.append(DarknetBlock(ch_in*2))\n        return layers\n\n    def __init__(self, num_blocks, num_classes=1000, start_nf=32):\n        super().__init__()\n        nf = start_nf\n        layers = [ConvBN(4, nf, kernel_size=3, stride=1, padding=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=(1 if i==1 else 2))\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n#         layers += [nn.Sigmoid()]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)","6388fcbe":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        \n        return loss.sum(dim=1).mean()","1412e57e":"from sklearn.metrics import fbeta_score\nimport warnings\n\ndef f1_(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        return max([fbeta_score(targs, (preds>th), 1, average='samples')\n                    for th in np.arange(start,end,step)])","b9a6b41e":"m = Darknet([1, 2, 4, 4, 3], 28).cuda()","3b121c69":"m","8eef8f25":"md = get_data(512,8)","0defbc0d":"learn = Learner.from_model_data(m, md, tmp_name=TMP, models_name=MODEL)\nlearn.crit = FocalLoss()\nlearn.opt_fn = optim.Adam\nlearn.metrics = [f1_]","32370f3d":"learn.load(PRETRAINED)","bad29633":"lr = 1E-2","2dd2762b":"learn.fit(lr\/10,1,cycle_len=1,use_clr_beta=(10,10, 0.85, 0.9))","107b172a":"learn.save('512')","a8e4be13":"learn.load('512')","90200af5":"p_v, t_v = learn.predict_with_targs()","fd26fcbe":"def sigmoid(a):\n    return 1\/(1+np.exp(-a))","b41b4d06":"sp_v = sigmoid(p_v) #compute the sigmoid of the network output","b03a0704":"def f1_np(y_pred, y_true, threshold=0.5):\n    '''numpy f1 metric'''\n    y_pred = (y_pred>threshold).astype(int)\n    TP = (y_pred*y_true).sum(1)\n    prec = TP\/(y_pred.sum(1)+1e-7)\n    rec = TP\/(y_true.sum(1)+1e-7)\n    res = 2*prec*rec\/(prec+rec+1e-7)\n    return res.mean()\n\n\ndef f1_n(y_pred, y_true, thresh, n, default=0.5):\n    '''partial f1 function for index n'''\n    threshold = default * np.ones(y_pred.shape[1])\n    threshold[n]=thresh\n    return f1_np(y_pred, y_true, threshold)\n\ndef find_thresh(y_pred, y_true):\n    '''brute force thresh finder'''\n    ths = []\n    for i in range(y_pred.shape[1]):\n        aux = []\n        for th in np.linspace(0,1,100):\n            aux += [f1_n(y_pred, y_true, th, i)]\n        ths += [np.array(aux).argmax()\/100]\n    return np.array(ths)","f8a20bec":"ths = find_thresh(sp_v, t_v); ths","c9c4445d":"f1_np(sp_v, t_v, 0.5), f1_np(sp_v, t_v, ths)","9d41b7f0":"preds = learn.predict(is_test=True)","0195a66f":"preds = sigmoid(preds)\nthreshold = ths\nprint(preds.shape)\nclasses = np.array([str(n) for n in range(28)])\nres = np.array([\" \".join(classes[(np.where(pp>threshold))])for pp in preds])","7da0fa59":"filenames = np.array([os.path.basename(fn).split('.')[0] for fn in test_names])","211dfa85":"res.shape, filenames.shape","af156d8a":"frame = pd.DataFrame(np.array([filenames, res]).T, columns = ['Id','Predicted'])","474d256d":"frame.head()","716a7d70":"frame.to_csv('submission.csv', index=False)","23cc3d13":"Before optim: `f1 = 0.32`after `f1= 0.48`","a8bb9d24":"This kernel implements a Darknet model for the HUman Protein Atals comp.\nIt uses the 4 separated images as input, concatenating them in a 4 channel RGBY image. To do so, I modified the first convolution in the Darknet implementation from 3-->4 channels.\nThe model trained is a Darknet_small. Better results can be achieved with computing power and a deeper network (Darknet53 for instance, check yolo [website](https:\/\/pjreddie.com\/darknet\/yolo\/) )\n\nThis kernel uses the fastai library version 0.7 and one cycle training schedule.  No transforms are used.\n\nTo be able to train in the limited computing power of kallge, I trained a 128 model, then a 256 and finally this one, but only one epoch.","b4f150f9":"Train with one cycle policy","aef5f280":"Helper optimisation functions for F1 metric","aaf2cfc9":"loading 256 model","309c98d2":"## Predictions and submission file","71187690":"We first get predictions on the validation set with corresponding targets. We will use this to compute an \"optimised\" set of thresholds","6ee4a8d7":"One improvement could be to train in `Darknet([1, 2, 4, 8, 8, 4])` for instance.","18d7faeb":"A threshold optimisation can immrove this results a lot.","810778f5":"Compute `y` vector of targets.","6b6529a2":"This is to be able to use a smaller data sample to debug, sample=31072 is the full dataset. ","b04928fd":"sample : can be used to train in smaller dataset. For debug set sample to 3000 for instance.","cc44f80b":"# Fastai Darknet Model","b9cb1d18":"## Darknet Model definition"}}