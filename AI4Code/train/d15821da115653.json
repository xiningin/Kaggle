{"cell_type":{"95466aac":"code","b866b732":"code","534ca18f":"code","ec4213d6":"code","43078584":"code","4367dba2":"code","d7a9dcf4":"code","5dabf6dc":"code","ca07ddb8":"code","2686cf56":"code","678e7641":"code","6ca6dde5":"code","a20f6af1":"code","906ae4fe":"code","8791105d":"code","8b12bbf4":"code","8f3ca433":"code","ef452bc0":"code","a9bb5038":"code","0718ec4e":"code","56a82d07":"code","b24bdf23":"code","88285f81":"code","1d5366d9":"code","ff8b896a":"code","09f9b164":"code","34b506b1":"code","17ea8c27":"code","a109a947":"code","7fe373c3":"code","d5c4cb92":"markdown","baa55755":"markdown","c85368a3":"markdown","aa4a074c":"markdown","e4e569fe":"markdown","92b51335":"markdown"},"source":{"95466aac":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","b866b732":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","534ca18f":"train=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","ec4213d6":"test=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","43078584":"sample=pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","4367dba2":"train.head()","d7a9dcf4":"train.info()","5dabf6dc":"train.describe()","ca07ddb8":"train.shape","2686cf56":"BASE = \"\/kaggle\/input\/nlp-getting-started\/\"\ntrain = pd.read_csv(BASE + \"train.csv\")\ntest = pd.read_csv(BASE + \"test.csv\")\nsub = pd.read_csv(BASE + \"sample_submission.csv\")","678e7641":"tweets = train[['text', 'target']]\ntweets.head()","6ca6dde5":"tweets.target.value_counts()","a20f6af1":"tweets.shape","906ae4fe":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer","8791105d":"def remove_punctuation(text):\n    '''a function for removing punctuation'''\n    import string\n    # replacing the punctuations with no space, \n    # which in effect deletes the punctuation marks \n    translator = str.maketrans('', '', string.punctuation)\n    # return the text stripped of punctuation marks\n    return text.translate(translator)","8b12bbf4":"tweets['text'] = tweets['text'].apply(remove_punctuation)\ntweets.head(10)","8f3ca433":"# extracting the stopwords from nltk library\nsw = stopwords.words('english')\n# displaying the stopwords\nnp.array(sw);","ef452bc0":"def stopwords(text):\n    '''a function for removing the stopword'''\n    # removing the stop words and lowercasing the selected words\n    text = [word.lower() for word in text.split() if word.lower() not in sw]\n    # joining the list of words with space separator\n    return \" \".join(text)","a9bb5038":"tweets['text'] = tweets['text'].apply(stopwords)\ntweets.head(10)","0718ec4e":"# create an object of stemming function\nstemmer = SnowballStemmer(\"english\")\n\ndef stemming(text):    \n    '''a function which stems each word in the given text'''\n    text = [stemmer.stem(word) for word in text.split()]\n    return \" \".join(text)","56a82d07":"tweets['text'] = tweets['text'].apply(stemming)\ntweets.head(10)","b24bdf23":"vectorizer = CountVectorizer(analyzer='word', binary=True)\nvectorizer.fit(tweets['text'])","88285f81":"X = vectorizer.transform(tweets['text']).todense()\ny = tweets['target'].values\nX.shape, y.shape","1d5366d9":"from sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import f1_score","ff8b896a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)","09f9b164":"model = LogisticRegression()\nmodel.fit(X_train, y_train)","34b506b1":"y_pred = model.predict(X_test)\n\nf1score = f1_score(y_test, y_pred)\nprint(f\"Model Score: {f1score * 100} %\")","17ea8c27":"tweets_test = test['text']\ntest_X = vectorizer.transform(tweets_test).todense()\ntest_X.shape","a109a947":"lr_pred = model.predict(test_X)","7fe373c3":"sub['target'] = lr_pred\nsub.to_csv(\"submission.csv\", index=False)\nsub.head()","d5c4cb92":"# \u6a5f\u68b0\u5b66\u7fd2","baa55755":"# \u30b9\u30c6\u30e0\u30b7\u30b9\u30c6\u30e0","c85368a3":"# \u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u306e\u51e6\u7406","aa4a074c":"# \u30c6\u30ad\u30b9\u30c8\u30d7\u30ed\u30bb\u30b9","e4e569fe":"# \u30c7\u30fc\u30bf\u306e\u6e96\u5099","92b51335":"# \u30e2\u30c7\u30eb\u8a55\u4fa1"}}