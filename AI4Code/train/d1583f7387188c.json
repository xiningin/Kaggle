{"cell_type":{"340e7b72":"code","9f4a89dc":"code","915cb0b3":"code","d6386c8e":"code","7d9c8596":"code","c7ce40f7":"code","eb2e0bdd":"code","6c07fb43":"code","4ee11da2":"code","88b355d3":"code","533d06ad":"code","c16f9d48":"code","b591578a":"code","1bd26f70":"code","3f15bd2c":"code","1ac2715f":"code","22f9a358":"code","98a1a9f3":"code","48261c52":"code","6c8d3ca4":"code","144c5012":"code","bd4c469e":"code","e10c8c45":"code","d2eeedbc":"code","e8568d3b":"code","0d0c89cf":"code","ae602fd8":"code","040dc8ae":"code","7b936313":"code","38d7569e":"code","d3f8ee07":"code","6b9d11c3":"code","f13ebddf":"code","f77c089e":"code","d960c7de":"code","412d2400":"code","0ca0d448":"code","3cc1ba49":"code","1063461b":"code","11f484ab":"code","964b4bf8":"code","f781f1cc":"code","73524b47":"code","98256dad":"code","fc0a13d1":"code","bac6d4c5":"code","0197b990":"code","1cbc62bd":"code","0b98159e":"code","76f2c899":"code","0dce84f2":"markdown","e5dd3c12":"markdown","962da616":"markdown","5a5d0343":"markdown","206a5ea6":"markdown","eb6f672d":"markdown","74a8b5f0":"markdown","8f2029f8":"markdown","537c51b8":"markdown","1724bfad":"markdown","f3b73559":"markdown","5e1a8352":"markdown","3fcba835":"markdown"},"source":{"340e7b72":"# SEE WHAT'S UNDER THE HOOD HERE\n!cat \/etc\/os-release","9f4a89dc":"# WHERE ARE WE RIGHT NOW?\n!ls -l .","915cb0b3":"# BUT, WHERE, REALLY, ARE WE RIGHT NOW? (p.s. IT LOOKS LIKE WE'RE INSIDE \/kaggle\/working FOLDER, INSIDE AN ISOLATE DOCKER CONTAINER\/IMAGE)\n!echo \"ls -l \/kaggle\"\n!ls -l \/kaggle\n\n!echo \"\\nls -l \/kaggle\/working\"\n!ls -l \/kaggle\/working","d6386c8e":"# LOOK AT INPUT FOLDER, WE SHOULD SEE \"firefox-63.0.3\" FOLDER ALREADY THERE\n!ls -l \"..\/input\"","7d9c8596":"# WE WILL MAKE NEW SUBFOLDER IN WORKING FOLDER (WHICH ISN'T READ-ONLY)\n!mkdir \"..\/working\/firefox\"\n!ls -l \"..\/working\"","c7ce40f7":"# COPY OVER FIREFOX FOLDER INTO NEW SUBFOLDER JUST CREATED\n!cp -a \"..\/input\/firefox-63.0.3\/firefox\/.\" \"..\/working\/firefox\"\n!ls -l \"..\/working\/firefox\"","eb2e0bdd":"# ADD READ\/WRITE\/EXECUTE CAPABILITES\n!chmod -R 777 \"..\/working\/firefox\"\n!ls -l \"..\/working\/firefox\"","6c07fb43":"# INSTALL PYTHON MODULE FOR AUTOMATIC HANDLING OF DOWNLOADING AND INSTALLING THE GeckoDriver WEB DRIVER WE NEED\n!pip install webdriverdownloader","4ee11da2":"# INSTALL LATEST VERSION OF THE WEB DRIVER\nfrom webdriverdownloader import GeckoDriverDownloader\ngdd = GeckoDriverDownloader()\ngdd.download_and_install(\"v0.23.0\")","88b355d3":"# INSTALL SELENIUM MODULE FOR AUTOMATING THINGS\n!pip install selenium","533d06ad":"# LAUNCHING FIREFOX, EVEN INVISIBLY, HAS SOME DEPENDENCIES ON SOME SCREEN-BASED LIBARIES\n!apt-get install -y libgtk-3-0 libdbus-glib-1-2 xvfb","c16f9d48":"# SETUP A VIRTUAL \"SCREEN\" FOR FIREFOX TO USe\n!export DISPLAY=:99","b591578a":"# PYTHON MODULES TO USE\nfrom selenium import webdriver as selenium_webdriver\nfrom selenium.webdriver.firefox.options import Options as selenium_options\nfrom selenium.webdriver.common.desired_capabilities import DesiredCapabilities as selenium_DesiredCapabilities","1bd26f70":"!ps -A","3f15bd2c":"# FIRE UP A HEADLESS BROWSER SESSION WITH A \"SCREEN SIZE\" OF 1920x1080\n\nbrowser_options = selenium_options()\nbrowser_options.add_argument(\"--headless\")\nbrowser_options.add_argument(\"--window-size=1920,1080\")\n\ncapabilities_argument = selenium_DesiredCapabilities().FIREFOX\ncapabilities_argument[\"marionette\"] = True\n\nbrowser = selenium_webdriver.Firefox(\n    options=browser_options,\n    firefox_binary=\"..\/working\/firefox\/firefox\",\n    capabilities=capabilities_argument\n)","1ac2715f":"import time\nbrowser.set_window_size(800, 800)\nbrowser.get(\"https:\/\/www.youtube.com\/channel\/UC9Ije5dQVFx9uTGddG_U5XA\/videos\")\nprint(browser.current_url)\n\n\n\n\n\n","22f9a358":"browser.save_screenshot(\"screenshot.png\")\nfrom IPython.display import Image\nImage(\"screenshot.png\", width=800, height=800)\n","98a1a9f3":"#if stuck with the cookies policy popup \n#try:\n#    browser.find_element_by_xpath(\"\/\/*[contains(text(), 'I agree')]\").click()\n#except:\n#    print(\"failed\")\n#browser.switch_to.default_content()","48261c52":"# I found hights of this page manually.Need to check if the browser is at the bottom of the page each time.  \nbrowser.execute_script(\"window.scrollTo(0, 510000);\")\n\ntitles = browser.find_elements_by_xpath('\/\/a[@id=\"video-title\"]')\n\nbrowser.save_screenshot('a.png')\nImage(\"a.png\", width=800, height=500)","6c8d3ca4":"len(titles)","144c5012":"print(titles[0].get_attribute('aria-label'))","bd4c469e":"def get_datas(text):\n    list =text.split(' ')\n    title = list[0]\n    channel = list[2] \n    time = (' ').join(list[3:-2])\n    views = (' ').join(list[-2:])\n    \n    return {'title': title,'channel':channel,'time':time, 'views':views}","e10c8c45":"list = []\nfor i in range(len(titles)):\n    \n  dict = get_datas(titles[i].get_attribute('aria-label'))  \n  dict[\"url\"] = titles[i].get_attribute('href')\n  list.append(dict)","d2eeedbc":"list[0]","e8568d3b":"import pandas as pd\ndf = pd.DataFrame(list)\n","0d0c89cf":"df = df.reindex(['channel','title','views','time','url'],axis=1)","ae602fd8":"#data was collected 12\/15\/2021\ndf.head()","040dc8ae":"#df.to_csv('shogihourouki_data.csv')\n","7b936313":"browser.quit()\n!ps -A","38d7569e":"browser = selenium_webdriver.Firefox(\n    options=browser_options,\n    firefox_binary=\"..\/working\/firefox\/firefox\",\n    capabilities=capabilities_argument\n)","d3f8ee07":"#Get a video page \nbrowser.get(\"https:\/\/www.youtube.com\/watch?v=H5h0TW3preQ\")","6b9d11c3":"# Ensure what I have\nbrowser.save_screenshot('video.png')\nImage(\"video.png\", width=800, height=500)\n","f13ebddf":"#tags\ntags = browser.find_elements_by_xpath('\/\/a[@class = \"yt-simple-endpoint style-scope yt-formatted-string\"]')\nfor i in range(len(tags)-1):\n    if \"#\" in tags[i].text:\n        print(tags[i].text)","f77c089e":"#Youtube made dislike count private. \n\nlikes = browser.find_elements_by_xpath('\/\/yt-formatted-string[@class = \"style-scope ytd-toggle-button-renderer style-text\"]')\n#print(likes)\n\nlikes[0].get_attribute('aria-label').split(' ')[0]\n#for i in range(len(likes)):\n#print(likes[i].get_attribute('aria-label'))","d960c7de":"#date \n\ndate = browser.find_elements_by_xpath('\/\/yt-formatted-string[@class = \"style-scope ytd-video-primary-info-renderer\"]')\nfor i in range(len(date)):\n    print(date[i].text)","412d2400":"browser.quit()","0ca0d448":"def get_info(url):\n    \n    # open broswer and go to the target page\n    browser = selenium_webdriver.Firefox(\n    options=browser_options,\n    firefox_binary=\"..\/working\/firefox\/firefox\",\n    capabilities=capabilities_argument)\n    \n    browser.get(url)\n    \n    #Giving time to load a page\n    browser.implicitly_wait(3)\n    \n    #tags \n    tag_list =[]\n    tags = browser.find_elements_by_xpath('\/\/a[@class = \"yt-simple-endpoint style-scope yt-formatted-string\"]')\n    for i in range(len(tags)):\n        if \"#\" in tags[i].text:\n            tag_list.append(tags[i].text)\n                \n    #likes \n    likes = browser.find_element_by_xpath('\/\/yt-formatted-string[@class = \"style-scope ytd-toggle-button-renderer style-text\"]')\n    like= likes.get_attribute('aria-label').split(' ')[0]\n        \n    #date \n    dates = browser.find_elements_by_xpath('\/\/yt-formatted-string[@class = \"style-scope ytd-video-primary-info-renderer\"]')\n    date = dates[1].text\n    \n    browser.quit()\n    print({'tags':tag_list,'likes':like,'date':date})\n    return {'tags':tag_list,'likes':like,'date':date}\n\n    ","3cc1ba49":"get_info(\"https:\/\/www.youtube.com\/watch?v=yQyVSrEAOpc\")","1063461b":"#Get data from all the video on the channel\n\nnew_list = []\nfor i in df['url']:\n    new_list.append(get_info(i))","11f484ab":"df1 = pd.DataFrame(new_list)","964b4bf8":"df1.head(10)","f781f1cc":"dfs = pd.concat([df,df1],axis=1)","73524b47":"dfs = dfs.drop(columns='time')","98256dad":"dfs.columns","fc0a13d1":"dfs = dfs.reindex(['channel','title','views','likes','tags','date','url'],axis=1)","bac6d4c5":"int('1195')","0197b990":"#data cleaning\ndfs['views'] = [int(a.split(' ')[0].replace(',','')) for a in dfs['views']]","1cbc62bd":"dfs['likes'] = [int(a.split(' ')[0].replace(',','')) for a in dfs['likes']]","0b98159e":"dfs.head()","76f2c899":"dfs.to_csv('shogihourouki_data.csv')","0dce84f2":"## This notebook shows how to use headless Firefox browser + selenium library in Python to scrape data live in real-time from within a Kaggle notebook","e5dd3c12":"**Tips**\n\nYoutube channel video page is scrollerble. If the browser is at the top of page, you will get recent 20 titles only by find_elements_by_xpath. I tried to search a way to extract all the titles, but could not find the way on the internet. However, I figured it out on my own when I played it around. If your browser is  at the bottome of the page, you will get all the titles by the same method.    ","962da616":"# Shogi Hourouki as Example\n\nI used Professionl Shogi (Japanese chess) player youtube channel for this project. I hope some Shogi fans or players on Kaggle see this notebook. \n","5a5d0343":"### **Part 1: ** installing portable Firefox binary, geckodriver, and selenium library","206a5ea6":"1) Manually \"+Add data | Your Datasets | firefox-63.0.3.tar.bz2\"\n\nnote: referencing uploaded binary files as \"datasets\" automatically places them into \"..\/input\" folder\n\n2) Under Settings section, set Internet = \"Internet Conneted\"","eb6f672d":"# Part 2: Extract data from each video page. \n\nNext I will extract the data from each video page instead of channel video page.","74a8b5f0":"### **Pre-requisite steps:**\n\n1) First, manually download firefox for linux locally somewhere:\n\nhttp:\/\/ftp.mozilla.org\/pub\/firefox\/releases\/63.0.3\/linux-x86_64\/en-US\/firefox-63.0.3.tar.bz2\n\n2) then upload as new private \"dataset\" to kaggle account, making it selectable across kernels\n\n*note: when uploading, make sure to choose \"Keep tabular files in original format\" *","8f2029f8":"I was curious if I could make web scraping via a headless Firefox browser and selenium work in a Kaggle kernel. While this curiosity led to much frustration and hair tugging, I learned alot and am happy to report it works!","537c51b8":"# Background of this project\n\nI have been into a Kaggle community lately and thinking how to participate more. I was looking into more ways to contribute to the community, and I found a post [How to create your first dataset using web scraping: BeautifulSoup library](https:\/\/www.kaggle.com\/getting-started\/294380). It made me feel making my own dataset is another good way to improve my data analysis skills. \n\nI tried using Beautifil Soup first, and eventually I realized I could not collect much data from the complicating website such as Youtube with it. I used Selenium to do web scraping this time.\n","1724bfad":"****************************************\n# Set up environment to use Selenium on Kaggle Notebook.\n\n\nI forked  this notebook. [Kaggle web scraping via headless Firefox+selenium](https:\/\/www.kaggle.com\/dierickx3\/kaggle-web-scraping-via-headless-firefox-selenium) For some reason, I could not upload firefox file on my end. \n\n","f3b73559":"# Part 1: Get information from a Channel Page","5e1a8352":"# End of the Project\n\nThis is the product of this notebook: https:\/\/www.kaggle.com\/satoshiss\/shogi-channels-data.\nData was collected on 12\/16.\n\nIt was really fun to complete this project.I will try webscraping on the other website.\nHope you find something useful on this notebook.","3fcba835":"******************************************************************"}}