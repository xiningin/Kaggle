{"cell_type":{"c004cf93":"code","fec44f08":"code","364ea4f5":"code","f8b710d1":"code","efa269f8":"code","d414eee6":"code","89624612":"code","1b55b758":"code","c7a19071":"code","6a9c5da9":"code","9c21aa6e":"code","0b2d6290":"code","62c12d9a":"code","e8528ee9":"code","3213cccc":"markdown","2b87b4e1":"markdown","d6c91a4e":"markdown","67964972":"markdown","0b11711c":"markdown"},"source":{"c004cf93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fec44f08":"import pandas as pd\nimport os\n\n# Read the data\ntrain_data = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest_data = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\ntrain_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = train_data.SalePrice\nX = train_data.drop(['SalePrice'], axis=1)","364ea4f5":"X.head()","f8b710d1":"X.shape","efa269f8":"X.describe()","d414eee6":"# Get numeric columns\nnumerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n","89624612":"# Number of missing values in each numeric column of training data\nnumerical_cols_missing = (X[numerical_cols].isnull().sum())\nprint(numerical_cols_missing[numerical_cols_missing > 0])","1b55b758":"# Get all categorical columns\nobject_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n# Number of missing values in each numeric column of training data\nobject_cols_missing = (X[object_cols].isnull().sum())\nprint(object_cols_missing[object_cols_missing > 0])","c7a19071":"# Columns that will be droped from the dataset\ncols_to_drop = list(object_cols_missing[object_cols_missing > 1000].index)\n# Add columns with potential target leakage\ncols_to_drop += ['MoSold', 'YrSold', 'SaleType', 'SaleCondition']\nreduced_object_cols = list(set(object_cols)-set(cols_to_drop))\nreduced_numerical_cols = list(set(numerical_cols)-set(cols_to_drop))\ncols_to_drop","6a9c5da9":"# Columns that will be one-hot encoded\nlow_cardinality_cols = [cname for cname in reduced_object_cols if X[cname].nunique() < 10]\n\n# Columns that will be label encoded\nhigh_cardinality_cols = list(set(reduced_object_cols)-set(low_cardinality_cols))\n\nprint('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\nprint('\\nCategorical columns that will be droped from the dataset:', high_cardinality_cols)","9c21aa6e":"# Drop columns with high rate of missing values and potential target leakage\nreduced_X = X.drop(cols_to_drop + high_cardinality_cols, axis=1)\nreduced_X_test = test_data.drop(cols_to_drop + high_cardinality_cols, axis=1)","0b2d6290":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='mean')\n\n# Preprocessing for categorical data with low cardinality\nlow_cardinality_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer( transformers=[\n    ('num', numerical_transformer, reduced_numerical_cols),\n    ('lowcard', low_cardinality_transformer, low_cardinality_cols),\n])\n\n# Define model\nmodel = XGBRegressor(random_state=0,\n                         n_estimators=500,\n                         learning_rate=0.05,\n                         n_jobs=4)\n\n# Bundel preprocessing and modeling in a pipeline\nmy_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\nscores = -1* cross_val_score(my_pipeline, reduced_X, y,\n                                cv=5,\n                                scoring='neg_mean_absolute_error')\nprint(\"Average MAE score: \", scores.mean())","62c12d9a":"# Final training on all available data\nmy_pipeline.fit(reduced_X, y)","e8528ee9":"# Save test predictions to file\npreds_test = my_pipeline.predict(reduced_X_test)\noutput = pd.DataFrame({'Id': reduced_X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","3213cccc":"# Step 5: Submit your results\n\nOnce you have successfully completed Step 4, you're ready to submit your results to the leaderboard!  First, you'll need to join the competition if you haven't already.  So open a new window by clicking on [this link](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course).  Then click on the **Join Competition** button.\n\n![join competition image](https:\/\/i.imgur.com\/wLmFtH3.png)\n\nNext, follow the instructions below:\n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the blue **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!","2b87b4e1":"# Step 1: Load the data\n","d6c91a4e":"# Step 4: Final training","67964972":"# Step 2: Data Exploration","0b11711c":"# Step 3: Build a pipeline for preprocessing and modeling"}}