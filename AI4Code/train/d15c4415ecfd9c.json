{"cell_type":{"856f6582":"code","bdbd6f92":"code","51a90acf":"code","1d958780":"code","f61364e4":"code","4dadc763":"code","5f2ec58f":"code","338924fa":"code","9d58b1e5":"code","554bb118":"markdown","50b0a65f":"markdown","56868f4e":"markdown","d55883b3":"markdown","f8e1b8ec":"markdown","3a6e2ae0":"markdown","23082e27":"markdown"},"source":{"856f6582":"from tensorflow.python.client import device_lib\nimport tensorflow as tf\n\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\nprint(physical_devices)\n\n# Grow memory\ntf.config.experimental.set_memory_growth(physical_devices[0], True)","bdbd6f92":"import os\n\n# General path\npath = \"C:\\\\Users\\\\T-Gamer\\\\Desktop\\\\TCC\\\\resultados-mat\\\\\"\n\nfolders_path = []\n\nfor degree_level in range(1, 4):\n    degreePath = os.listdir(f\"{path}grau{degree_level}\")\n    folders_path.append(degreePath)\n    \n# list of classes\nclass_names=['grau1', 'grau2', 'grau3'] ","51a90acf":"import cv2\n\ndef change_brightness(img, value=30):\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    h, s, v = cv2.split(hsv)\n    v = cv2.add(v,value)\n    v[v > 255] = 255\n    v[v < 0] = 0\n    final_hsv = cv2.merge((h, s, v))\n    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n    return img","1d958780":"import pandas as pd\nimport numpy as np\n\nX = []\ny = []\n\n# Feature extraction\nfor classes_files, classe in zip (folders_path, range(10)):\n    for i in range(len(classes_files)):\n        name = str(path) + str(class_names[classe]) + str('\/') + str(classes_files[i]) \n        image = cv2.imread(name)\n        image = cv2.resize(image,(75,75))  # Change image height and width\n        imagem = change_brightness(image, value=50) # Change image brightness\n        img = np.asarray(imagem)\n        y.append(classe)      \n        X.append(img)\n\n# Saving the extracted features (deep) in a csv file\nnp.save('X', X)\n\n# Saving the classes in a csv file\ndf_class = pd.DataFrame(y)\ndf_class.to_csv('y.csv', header=False, index=False)","f61364e4":"# Scale pixels\ndef prep_pixels(train, test):\n    # Convert from integers to floats\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    # Normalize to range 0-1\n    train_norm = train_norm \/ 255.0\n    test_norm = test_norm \/ 255.0\n    # Return normalized images\n    return train_norm, test_norm","4dadc763":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# Load the images and the corresponding labels\ny = pd.read_csv('y.csv', header=None)\ny = y.to_numpy()\ny = np.ravel(y)\nprint(f\"y shape: {y.shape}\")\n\nX = np.load('X.npy')\nprint(f\"X shape: {X.shape}\")\n\n# Holdout -> Dividing the database into training (70%) and testing (30%), stratified\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.3, random_state=42, stratify=y)\n\n# Data normalization\ntrainX, testX = prep_pixels(X_train, X_test)\ntrainX = X_train \ntestX = X_test\n\n# Preparing the labels\ntrainY = to_categorical(y_train)\ntestY = to_categorical(y_test)","5f2ec58f":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet_v2 import ResNet152V2\nfrom tensorflow.keras.applications.resnet import ResNet50, ResNet101, ResNet152\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom tensorflow.keras.applications.densenet import DenseNet201, DenseNet169, DenseNet121\n\ninput_shape = (75, 75, 3)\n\nvgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=input_shape, classes=1000)\nincepctionv3_conv = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\nResNet152V2_conv = ResNet152V2(weights='imagenet', include_top=False, input_shape=input_shape)\nDenseNet201_conv = DenseNet201(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=input_shape, pooling=None, classes=1000)\nDenseNet169_conv = DenseNet169(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=input_shape, pooling=None, classes=1000)\nDenseNet121_conv = DenseNet121(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=input_shape, pooling=None, classes=1000)\nXception_conv = Xception(input_shape=input_shape, include_top=False, weights=\"imagenet\", input_tensor=None, pooling=None, classes=1000)\nResNet50_conv = ResNet50(input_shape=input_shape, include_top=False, weights=\"imagenet\", input_tensor=None, pooling=None, classes=1000)\nResNet101_conv = ResNet101(input_shape=input_shape, include_top=False, weights=\"imagenet\", input_tensor=None, pooling=None, classes=1000)\nResNet152_conv = ResNet152(input_shape=input_shape, include_top=False, weights=\"imagenet\", input_tensor=None, pooling=None, classes=1000)","338924fa":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.losses import categorical_crossentropy\n\ndef model(conv):\n    model = Sequential()\n    model.add(conv)\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(3, activation='softmax'))\n    \n    # Freeze the layers except the last 4 layers\n    for layer in model.layers[:-4]:\n        layer.trainable = False\n        \n    # Compile the model\n    model.compile(loss=categorical_crossentropy, optimizer=\"adam\", metrics=['accuracy'])\n    \n    # Create data generator\n    datagen = ImageDataGenerator(rotation_range=45, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n    \n    # Apply data generator\n    datagen.fit(trainX)\n    \n    # Prepare Iterator\n    it_train = datagen.flow(trainX, trainY, batch_size=150)\n    \n    # Fit model\n    history = model.fit(it_train, epochs=2, validation_data=(testX, testY), verbose=1)\n    \n    # Evaluate model\n    _, acc = model.evaluate(testX, testY, verbose=0)\n    print('Test Accuracy: > %.3f' % (acc * 100.0))\n    \n    predY = model.predict(testX)\n    predY_arg = np.argmax(predY, axis=1)\n    testY_arg = np.argmax(testY, axis=1)\n    \n    # Classification report\n    cr = classification_report(testY_arg, predY_arg, zero_division=0)\n    print(cr)\n    \n    # Confusion matrix \n    cm = confusion_matrix(testY_arg, predY_arg)\n    sns.heatmap(cm, annot = True)\n    \n    return model","9d58b1e5":"resNet152 = model(ResNet152_conv)","554bb118":"## Uploading images and classes","50b0a65f":"## Normalization, Fine Tunning and database separation","56868f4e":"## Upload the CNNS","d55883b3":"# TCC - Detecting Allergies Degrees","f8e1b8ec":"## Feature Extraction","3a6e2ae0":"## Handling the Model","23082e27":"## Check GPU Connection"}}