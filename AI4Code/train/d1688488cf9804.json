{"cell_type":{"ffa49254":"code","0e6e4f25":"code","a053a209":"code","c6d06eed":"code","e7defa96":"code","80f7ae75":"code","99c099e2":"code","2f52bc4c":"code","a5a6c117":"code","98a5c0a1":"code","324bd08f":"code","761f251d":"code","064ee5bb":"code","8181dabc":"code","4e92ad30":"code","627b39ab":"code","e7cef0db":"code","be8be985":"code","334c7859":"code","b0db6f36":"code","e47481e2":"code","41768d37":"code","c3612836":"code","f4464f0c":"code","d805f47f":"markdown"},"source":{"ffa49254":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport random\nimport matplotlib.pylab as plt\nimport keras.backend as K\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport keras\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.applications import VGG16\n%matplotlib inline","0e6e4f25":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","a053a209":"imagePatches = glob('..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/**\/*.png', recursive=True)\nfor filename in imagePatches[0:10]:\n    print(filename)","c6d06eed":"# Two arrays holding images by class type\n\nclass0 = [] # 0 = no cancer\nclass1 = [] # 1 = cancer\n\nfor filename in imagePatches:\n    if filename.endswith(\"class0.png\"):\n         class0.append(filename)\n    else:\n        class1.append(filename)","e7defa96":"len(class1)","80f7ae75":"sampled_class0 = random.sample(class0, 78786)\nsampled_class1 = random.sample(class1, 78786)\nlen(sampled_class0)","99c099e2":"from matplotlib.image import imread\nimport cv2\n\ndef get_image_arrays(data, label):\n    img_arrays = []\n    for i in data:\n      if i.endswith('.png'):\n        img = cv2.imread(i ,cv2.IMREAD_COLOR)\n        img_sized = cv2.resize(img, (50, 50), interpolation=cv2.INTER_LINEAR)\n        img_arrays.append([img_sized, label])\n    return img_arrays","2f52bc4c":"class0_array = get_image_arrays(sampled_class0, 0)\nclass1_array = get_image_arrays(sampled_class1, 1)","a5a6c117":"class0_array[1]","98a5c0a1":"combined_data = np.concatenate((class0_array, class1_array))\nrandom.seed(41)\nrandom.shuffle(combined_data)","324bd08f":"X = []\ny = []\n\nfor features,label in combined_data:\n    X.append(features)\n    y.append(label)","761f251d":"# print(X[11].reshape(-1, 50, 50, 3))\n# reshape X data\nX = np.array(X).reshape(-1, 50, 50, 3)","064ee5bb":"X.shape","8181dabc":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","4e92ad30":"#Transfer Learning\n\n\nbase_model = tf.keras.applications.InceptionV3(input_shape=(50,50,3),include_top=False,weights=\"imagenet\")","627b39ab":"# Freezing Layers\n\nfor layer in base_model.layers[:-5]:\n    layer.trainable=False","e7cef0db":"# Building Model\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='softmax'))","be8be985":"# Model Summary\n\nmodel.summary()","334c7859":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","b0db6f36":"def f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val","e47481e2":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        f1_score,\n]","41768d37":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 5,verbose = 1,factor = 0.75, min_lr = 1e-10)\n\nmcp = ModelCheckpoint('model.h5')\n\nes = EarlyStopping(verbose=1, patience=5)","c3612836":"model.compile(optimizer='Adam', loss='binary_crossentropy',metrics=METRICS)","f4464f0c":"y_train,validation_data=(X_test, y_test),verbose = 1,epochs = 5,callbacks=[lrd,mcp,es]","d805f47f":"test = cv2.imread('..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/13689\/1\/13689_idx5_x801_y1501_class1.png' ,cv2.IMREAD_COLOR)\ntest.shape"}}