{"cell_type":{"e385dc8a":"code","c986acb9":"code","f789a53f":"code","a3fd6de8":"code","a9dfb1b0":"code","e109eb46":"code","97d479bd":"code","b5cf3e56":"code","f721d18c":"code","903f2426":"code","023a843c":"code","cbc799f1":"code","23e65e22":"code","05fd1e9c":"code","8cf27b51":"code","3d648453":"code","1f57f869":"code","fe7671db":"code","7b67e4e4":"code","fe2155cf":"code","87e689fd":"code","b560719c":"code","a166cc7f":"code","c56f9a9a":"code","104e2ced":"code","46b31a9b":"code","af65d716":"code","5db6afdb":"code","0656d609":"code","97bdd329":"code","7af4f274":"code","acb835ed":"code","5400c763":"code","8fa394e2":"code","2a988da4":"code","90f5ade7":"code","9be57d05":"code","7fbc81f8":"code","80f88536":"code","8c9690ad":"code","4d10f18f":"code","fdbdffd8":"code","884389aa":"code","2c06473a":"code","59fdc6d6":"code","823143de":"code","8f16a4af":"code","04792f22":"code","de166ecc":"code","4305d16c":"code","a7c606a6":"code","81e13620":"code","01ee297b":"code","b046406f":"code","3e4c47e2":"code","45d40d25":"code","f5a69508":"code","71192ca8":"code","7578bae5":"code","438ae80d":"code","f88b5f94":"code","56ac212f":"code","23607ca3":"code","bd4a7202":"code","23052168":"code","a6d62264":"code","32978892":"code","84e39f2e":"code","8901f338":"code","188a5d43":"code","12bed7ed":"code","0d9e4445":"code","a9539f1b":"code","b93531bb":"code","d4df41af":"code","4332251f":"code","5e637187":"code","271878eb":"code","69592e5b":"code","63fc5382":"code","72f7b9b3":"code","becd2888":"code","527f8967":"code","f0a55a05":"code","f13aa141":"code","5aad1dba":"code","0f73e386":"code","5495bb76":"code","527f6a02":"code","d7f7f2ac":"code","92ca40a0":"code","d6875f3a":"code","546b341a":"markdown","553b7742":"markdown","48cc5e18":"markdown","c34abb0a":"markdown","4b27f697":"markdown","24660d6f":"markdown","1c1c554e":"markdown","c0d75b05":"markdown","1e3c19fc":"markdown","344780c9":"markdown","63509b6f":"markdown","cb5faca9":"markdown","c2da1dc2":"markdown","dd894533":"markdown","bf5a3a18":"markdown","35fadbad":"markdown","6c3b366d":"markdown","50da3977":"markdown","9c172145":"markdown","3b13a6e9":"markdown","0aa7c1b2":"markdown","fee3e60b":"markdown","6093fdcc":"markdown","accb92e4":"markdown"},"source":{"e385dc8a":"%%html\n<marquee style='width: 100%; color: red;'><H1>prostate-cancer-grade-assessment<\/H1><\/marquee>","c986acb9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport openslide\nimport os\nimport cv2\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation\nfrom keras.layers import GlobalMaxPooling2D,GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.callbacks.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import cohen_kappa_score\nimport tensorflow as tf\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.metrics import *\n\ntrain_df = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/train.csv\")\nimage_path = \"..\/input\/prostate-cancer-grade-assessment\/train_images\/\"\nPATH = \"..\/input\/prostate-cancer-grade-assessment\/\"\ntrain_df = pd.read_csv(os.path.join(PATH,'train.csv'))\ntest_df =  pd.read_csv(os.path.join(PATH,'test.csv'))\ntrain_img_path = '..\/input\/prostate-cancer-grade-assessment\/train_images'\ntrain_read_img= pd.read_csv(PATH+\"train.csv\")\nmasks = '..\/input\/prostate-cancer-grade-assessment\/train_label_masks'\nimages_train_list = os.listdir(os.path.join(PATH, 'train_images'))\nmasks_list = os.listdir(os.path.join(PATH, 'train_label_masks'))\nsns.set_style(\"darkgrid\")","f789a53f":"DEVICE = \"TPU\"","a3fd6de8":"if DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\nAUTO = tf.data.experimental.AUTOTUNE\n","a9dfb1b0":"print(train_df)","e109eb46":"print(test_df)","97d479bd":"train_df.head()","b5cf3e56":"test_df.head()","f721d18c":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"data_provider\", data=train_df)\nax1.set_title(\"distribution de data_provider  dans  training data\")\nsns.countplot(ax=ax2, x=\"data_provider\", data=test_df)\nax2.set_title(\"distribution de data_provider dans test data\")\nplt.show()","903f2426":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"isup_grade\", data=train_df)\nax1.set_title(\"ISUP Grade distribution dans  Data Provider\")\nsns.countplot(ax=ax2, x=\"gleason_score\", data=train_df)\nax2.set_title(\"Gleason_Score distribution dans  Data Provider\")\nplt.show()","023a843c":"from tqdm import tqdm\n\nimg_dim= []\n\nfor i,row in tqdm(train_df.iterrows()):\n    slide = openslide.OpenSlide(os.path.join(train_img_path, train_df.image_id.iloc[i]+'.tiff'))\n    img_dim.append(slide.dimensions)\n    slide.close()\n    \nwidth = [dimensions[0] for dimensions in img_dim] \nheight = [dimensions[1] for dimensions in img_dim] \n\ntrain_df['width'] = width\ntrain_df['height'] = height","cbc799f1":"fig = plt.figure(figsize=(20,5))\nax = sns.scatterplot(x='width', y='height', data=train_df, hue='data_provider', alpha=0.70)\nax.tick_params(labelsize=10)\n\nplt.title('Dimensions des images')\nplt.show()","23e65e22":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(20, 5)\n\nsns.stripplot(train_df['width'],train_df['data_provider'],ax=ax[0],jitter=True)\nsns.stripplot(train_df['height'],train_df['data_provider'],ax=ax[1],jitter=True)\n\nax[0].tick_params(labelsize=10)\nax[1].tick_params(labelsize=10)\nax[0].tick_params(labelrotation=90)\nax[1].tick_params(labelrotation=90)\nplt.show()","05fd1e9c":"data_file_masks = pd.Series(masks_list).to_frame()\ndata_file_masks.columns = ['mask_file_name']\ndata_file_masks.head()","8cf27b51":"data_file_masks['image_id'] =data_file_masks.mask_file_name.apply(lambda x: x.split('_')[0])\ndata_file_masks.head()","3d648453":"train_df = pd.merge(train_df, data_file_masks, on='image_id', how='outer')\ntrain_df.head()","1f57f869":"del data_file_masks\nprint(f\"Il y a {len(train_df[train_df.mask_file_name.isna()])} images sans masque.\")","fe7671db":"print(f\"Train data avant la r\u00e9duction: {len(train_df)}\")\ndf_train_reduction= train_df[~train_df.mask_file_name.isna()]\nprint(f\"Train data apr\u00e8s la r\u00e9duction: {len(df_train_reduction)}\")","7b67e4e4":"fig,ax=plt.subplots(1,2,figsize=(20,5))\ntrain_df['data_provider'].value_counts().plot.pie(autopct='%1.1f%%',ax=ax[0])\nax[0].set_ylabel('')\ndf_train_reduction['data_provider'].value_counts().plot.pie(autopct='%1.1f%%',ax=ax[1])\nax[1].set_ylabel('')\nplt.show()","fe2155cf":"\"\"\"\nimages_without_masks=train_df[train_df.mask_file_name.isna()]\nwithout_masks=images_without_masks.groupby('image_id').data_provider.unique().to_frame()\nwithout_masks.to_csv(\"new_test.csv\",index=False)\nwithout_masks\n\"\"\"","87e689fd":"df_train_reduction.groupby('isup_grade').gleason_score.unique().to_frame()","b560719c":"df_train_reduction[(df_train_reduction.isup_grade == 2) & (df_train_reduction.gleason_score == '4+3')].reset_index()","a166cc7f":"df_train_reduction.reset_index(inplace=True)\ndf_train_reduction = df_train_reduction[df_train_reduction.image_id !='b0a92a74cb53899311acc30b7405e101']","c56f9a9a":"df_train_reduction[(df_train_reduction.isup_grade == 2) & (df_train_reduction.gleason_score == '4+3')].reset_index()","104e2ced":"df_train_reduction.groupby('isup_grade').gleason_score.unique().to_frame()","46b31a9b":"temp = df_train_reduction.groupby('isup_grade').count()['image_id'].reset_index().sort_values(by='image_id',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","af65d716":"temp = df_train_reduction.groupby('gleason_score').count()['image_id'].reset_index().sort_values(by='image_id',ascending=False)\ntemp.style.background_gradient(cmap='Reds')","5db6afdb":"df_train_reduction[(df_train_reduction.isup_grade == 0) & (df_train_reduction.gleason_score =='negative')].reset_index()","0656d609":"sns.set_style(\"darkgrid\")\nfig= plt.subplots(figsize=(20,5))\nsns.countplot(x='gleason_score', hue=\"data_provider\", data=df_train_reduction)\nplt.show()","97bdd329":"df_train_reduction[\"gleason_score\"]= df_train_reduction[\"gleason_score\"].replace(\"negative\", \"0+0\")","7af4f274":"df_train_reduction.groupby('isup_grade').gleason_score.unique().to_frame()","acb835ed":"temp = df_train_reduction.groupby('gleason_score').count()['image_id'].reset_index().sort_values(by='image_id',ascending=False)\ntemp.style.background_gradient(cmap='Reds')","5400c763":"def show_images(df, read_region=(1780,1950)):\n    \n    data = df\n    f, ax = plt.subplots(3,3, figsize=(20,20))\n    for i,data_row in enumerate(data.iterrows()):\n        image = str(data_row[1][0])+'.tiff'\n        image_path = os.path.join(PATH,\"train_images\",image)\n        image = openslide.OpenSlide(image_path)\n        spacing = 1 \/ (float(image.properties['tiff.XResolution']) \/ 10000)\n        patch = image.read_region(read_region, 0, (256, 256))\n        ax[i\/\/3, i%3].imshow(patch) \n        image.close()       \n        ax[i\/\/3, i%3].axis('off')\n        ax[i\/\/3, i%3].set_title('ID: {}\\nSource: {} ISUP: {} Gleason: {}'.format(\n                data_row[1][0], data_row[1][1], data_row[1][2], data_row[1][3]))\n\n    plt.show()\n    \nimages = [\n    '07a7ef0ba3bb0d6564a73f4f3e1c2293',\n    '037504061b9fba71ef6e24c48c6df44d',\n    '035b1edd3d1aeeffc77ce5d248a01a53',\n    '059cbf902c5e42972587c8d17d49efed',\n    '06a0cbd8fd6320ef1aa6f19342af2e68',\n    '06eda4a6faca84e84a781fee2d5f47e1',\n    '0a4b7a7499ed55c71033cefb0765e93d',\n    '0838c82917cd9af681df249264d2769c',\n    '046b35ae95374bfb48cdca8d7c83233f'\n]\ndata_sample = train_df.loc[train_df.image_id.isin(images)]\nshow_images(data_sample)","8fa394e2":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"isup_grade\", data=df_train_reduction)\nax1.set_title(\"ISUP Grade Count by Data Provider\")\nsns.countplot(ax=ax2, x=\"gleason_score\", data=df_train_reduction)\nax2.set_title(\"Gleason_Score Count by Data Provider\")\nplt.show()","2a988da4":"def show_masks(slides): \n    f, ax = plt.subplots(5,3, figsize=(18,22))\n    for i, slide in enumerate(slides):\n        mask = openslide.OpenSlide(os.path.join(mask_dir, f'{slide}_mask.tiff'))\n        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n        cmap = matplotlib.colors.ListedColormap(['black', 'gray', 'green', 'yellow', 'orange', 'red'])\n        ax[i\/\/3, i%3].imshow(np.asarray(mask_data)[:,:,0], cmap=cmap, interpolation='nearest', vmin=0, vmax=5) \n        mask.close()       \n        ax[i\/\/3, i%3].axis('off')    \n        image_id = slide\n        data_provider = data_sample_mask.loc[slide, 'data_provider']\n        isup_grade = data_sample_mask.loc[slide, 'isup_grade']\n        gleason_score = data_sample_mask.loc[slide, 'gleason_score']\n        ax[i\/\/3, i%3].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score}\")\n        f.tight_layout()\n        \n    plt.show()","90f5ade7":"images_mask  = [\n    '07a7ef0ba3bb0d6564a73f4f3e1c2293',\n    '037504061b9fba71ef6e24c48c6df44d',\n    '035b1edd3d1aeeffc77ce5d248a01a53',\n    '059cbf902c5e42972587c8d17d49efed',\n    '06a0cbd8fd6320ef1aa6f19342af2e68',\n    '06eda4a6faca84e84a781fee2d5f47e1',\n    '0a4b7a7499ed55c71033cefb0765e93d',\n    '0838c82917cd9af681df249264d2769c',\n    '028098c36eb49a8c6aa6e76e365dd055',\n    '0280f8b612771801229e2dde52371141',\n    '028dc05d52d1dd336952a437f2852a0a',\n    '02a2dcd6ad8bc1d9ad7fdc04ffb6dff3',\n    '049031b0ea0dede1ca1e5ca470c1332d',\n    '05f4e9415af9fdabc19109c980daf5ad',\n    '07fd8d4f02f9b95d86da4bc89563e077'\n]\n\nmask_dir = os.path.join(PATH,\"train_label_masks\")\ndata_sample_mask = df_train_reduction.set_index('image_id')\nshow_masks(images_mask)","9be57d05":"def mask_img(image,max_size=(600,400)):\n    slide = openslide.OpenSlide(os.path.join(train_img_path, f'{image}.tiff'))\n    mask =  openslide.OpenSlide(os.path.join(mask_dir, f'{image}_mask.tiff'))\n    f,ax =  plt.subplots(1,2 ,figsize=(18,22))\n    spacing = 1 \/ (float(slide.properties['tiff.XResolution']) \/ 10000)\n    img = slide.get_thumbnail(size=(600,400)) \n    mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n    cmap = matplotlib.colors.ListedColormap(['black', 'gray', 'green', 'yellow', 'orange', 'red'])\n    \n    \n    ax[0].imshow(img)\n    ax[1].imshow(np.asarray(mask_data)[:,:,0], cmap=cmap, interpolation='nearest', vmin=0, vmax=5) \n    \n    image_id = image\n    data_provider = data_sample_mask.loc[image, 'data_provider']\n    isup_grade = data_sample_mask.loc[image, 'isup_grade']\n    gleason_score = data_sample_mask.loc[image, 'gleason_score']\n    ax[0].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score} IMAGE\")\n    ax[1].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score} IMAGE_MASK\")","7fbc81f8":"images1= [\n    '08ab45297bfe652cc0397f4b37719ba1',\n    '090a77c517a7a2caa23e443a77a78bc7',\n    '07fd8d4f02f9b95d86da4bc89563e077'\n]\n\nfor image in images1:\n    mask_img(image)","80f88536":"train_df=df_train_reduction\nAccuracies_list=[]\nlabels=[]\ndata=[]\ndata_dir='..\/input\/panda-resized-train-data-512x512\/train_images\/train_images\/'\nfor i in range(train_df.shape[0]):\n    data.append(data_dir + train_df['image_id'].iloc[i]+'.png')\n    labels.append(train_df['isup_grade'].iloc[i])\ndf=pd.DataFrame(data)\ndf.columns=['images']\ndf['isup_grade']=labels","8c9690ad":"df.head()","4d10f18f":"print(len(df))","fdbdffd8":"print(labels)","884389aa":"X_train, X_val, y_train, y_val = train_test_split(df['images'],df['isup_grade'], test_size=0.1, random_state=42)","2c06473a":"train=pd.DataFrame(X_train)\ntrain.columns=['images']\ntrain['isup_grade']=y_train\n\nvalidation=pd.DataFrame(X_val)\nvalidation.columns=['images']\nvalidation['isup_grade']=y_val\n\ntrain['isup_grade']=train['isup_grade'].astype(str)\nvalidation['isup_grade']=validation['isup_grade'].astype(str)","59fdc6d6":"print(\"train size \",len(train))\nprint(\"validation size \",len(validation))","823143de":"print(train)","8f16a4af":"print(validation)","04792f22":"sns.set(style=\"darkgrid\")\na = ['TRAIN DATA ','TEST DATA ']\nb = [len((train)),len((validation))]\nax = sns.barplot(x=a, y=b)","de166ecc":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"isup_grade\", data=train)\nax1.set_title(\"distribution de Grade ISUP dans le TRAIN DATA apr\u00e8s le divisiment\")\nsns.countplot(ax=ax2, x=\"isup_grade\", data=validation)\nax2.set_title(\"distribution de Grade ISUP dans le TEST DATA apr\u00e8s le divisiment\")\nplt.show()","4305d16c":"train_datagen = ImageDataGenerator(rescale=1.\/255,rotation_range=45,\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    zoom_range=[0.8, 1.2],        \n    horizontal_flip=True, vertical_flip = True,\n    brightness_range=[0.9, 1.1],\n    width_shift_range=1.0,\n    height_shift_range=1.0)\n\nval_datagen=train_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train,\n    x_col='images',\n    y_col='isup_grade',\n    target_size=(224, 224),\n    batch_size=32,\n    seed=2020,\n    shuffle = True,\n    class_mode='categorical')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    dataframe=validation,\n    x_col='images',\n    y_col='isup_grade',\n    target_size=(224, 224),\n    batch_size=32,\n    seed=2020,\n    class_mode='categorical')","a7c606a6":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'), \n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]","81e13620":"\"\"\"\n%load_ext tensorboard\nlogdir = \"logs\/scalars\/\"\n\"\"\"","01ee297b":"\"\"\"\nimport keras\ndef lr_schedule(epoch):\n  \n  learning_rate = 0.2\n  if epoch > 10:\n    learning_rate = 0.02\n  if epoch > 20:\n    learning_rate = 0.001\n  if epoch > 50:\n    learning_rate = 0.0005\n\n  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n  return learning_rate\n\n\nlr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n\"\"\"","b046406f":"\"\"\"\ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.5),\n             EarlyStopping(monitor='val_loss', patience=3),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n\"\"\"\n\n\n#earlyStopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n#mcp_save = ModelCheckpoint(filepath='best_model.h5', save_best_only=True, monitor='val_loss', mode='auto')\n#reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='auto')\n\n\nearlyStopping =tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\nmcp_save  = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5',save_best_only=True,monitor='val_loss', mode='auto')\n#reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.0001,epsilon=1e-4)\n\n\n\ndef lrfn(epoch):\n    LR_START          = 0.000005\n    LR_MAX            = 0.000020 * strategy.num_replicas_in_sync\n    LR_MIN            = 0.000001\n    LR_RAMPUP_EPOCHS = 5\n    LR_SUSTAIN_EPOCHS = 0\n    LR_EXP_DECAY = .8\n    \n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr","3e4c47e2":"lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","45d40d25":"def vgg16_model( num_classes=None):\n\n    model = VGG16(weights='..\/input\/keras-pretrained-models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(224, 224, 3))\n    x=Dropout(0.3)(model.output)\n    x=Flatten()(x)\n    x=Dense(32, activation = 'relu')(x)\n    x=Dropout(0.2)(x)\n    output=Dense(num_classes,activation='softmax')(x)\n    model=Model(model.input,output)\n    return model\nvgg16_conv=vgg16_model(6)","f5a69508":"vgg16_conv.summary()","71192ca8":"\"\"\"\ndef kappa_score(y_true, y_pred):\n    \n    y_true=tf.math.argmax(y_true)\n    y_pred=tf.math.argmax(y_pred)\n    return tf.compat.v1.py_func(cohen_kappa_score ,(y_true, y_pred),tf.double)\n\"\"\"","7578bae5":"#opt =SGD(lr= 0.0005, momentum=0.9,decay=1e-4)\nvgg16_conv.compile(optimizer='adam',\n    loss = 'binary_crossentropy',\n    metrics=['accuracy'])","438ae80d":"nb_epochs =10\nbatch_size=32\nnb_train_steps = train.shape[0]\/\/batch_size\nnb_val_steps=validation.shape[0]\/\/batch_size\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","f88b5f94":"\"\"\"\ndef data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.7, 1.3)\n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    image = tf.image.random_brightness(image, 0.1)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() \n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) =\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\"\"\"","56ac212f":"vgg16_history=vgg16_conv.fit_generator(train_generator,\n                                       steps_per_epoch=nb_train_steps,\n                                       epochs=nb_epochs,\n                                       validation_data=validation_generator,\n                                       validation_steps=nb_val_steps,\n                                       callbacks=[earlyStopping,mcp_save,lr_schedule])","23607ca3":"vgg16_conv.save('prostate_cancer_vgg16_model.h5')\nvgg16_weights =vgg16_conv.save_weights('vgg16_weights.h5')\nAccuracies_list.append(['vgg16', vgg16_history])","bd4a7202":"def show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(20,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('AUC')\n    ax[1].plot(history.epoch, history.history[\"auc\"], label=\"Train AUC\")\n    ax[1].plot(history.epoch, history.history[\"val_auc\"], label=\"Validation AUC\")\n    ax[2].set_title('Accuracy')\n    ax[2].plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\n    ax[2].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()","23052168":"show_history(vgg16_history)","a6d62264":"from keras.applications.resnet50 import ResNet50\ndef ResNet50_model(num_classes = None):\n    #model = ResNet50(weights='imagenet', include_top = False, input_shape = (224,224,3))\n    model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    #x=Dropout(0.2)(model.output)\n    #x = GlobalAveragePooling2D()(model.output)\n    x=Flatten()(model.output)\n    #x =Dropout(0.2)(x)\n    x =Dense(16, activation = 'relu')(x)\n    x =Dropout(0.2)(x)\n    output=Dense(num_classes,activation='softmax')(x)\n    model=Model(model.input,output)\n    return model\nResNet50_conv = ResNet50_model(6)","32978892":"ResNet50_conv.summary()","84e39f2e":"ResNet50_conv.compile(loss='binary_crossentropy',optimizer=opt,metrics=METRICS)","8901f338":"RN_50_history=ResNet50_conv.fit_generator(train_generator,\n                                          steps_per_epoch=nb_train_steps,\n                                          epochs=nb_epochs,\n                                          validation_data=validation_generator,\n                                          validation_steps=nb_val_steps,\n                                          callbacks=[earlyStopping, mcp_save,lr_schedule])","188a5d43":"ResNet50_conv.save('prostate_cancer_ResNet50_conv.h5')\nAccuracies_list.append(['ResNet50', RN_50_history])","12bed7ed":"def show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(20,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('AUC')\n    ax[1].plot(history.epoch, history.history[\"auc\"], label=\"Train AUC\")\n    ax[1].plot(history.epoch, history.history[\"val_auc\"], label=\"Validation AUC\")\n    ax[2].set_title('Accuracy')\n    ax[2].plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\n    ax[2].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()","0d9e4445":"show_history(RN_50_history)","a9539f1b":"from keras.applications.vgg19 import VGG19\ndef vgg19_model(num_classes = None):\n    model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    x=Dropout(0.3)(model.output)\n    x=Flatten()(x)\n    x =Dense(32, activation = 'relu')(x)\n    x =Dropout(0.2)(x)\n    output=Dense(num_classes,activation='softmax')(x)\n    model=Model(model.input,output)\n    return model\nvgg19_conv = vgg19_model(6)","b93531bb":"vgg19_conv.summary()","d4df41af":"vgg19_conv.compile(loss='binary_crossentropy',optimizer=opt,metrics=METRICS)","4332251f":"vgg19_history=vgg19_conv.fit_generator(train_generator,\n                                       steps_per_epoch=nb_train_steps,\n                                       epochs=nb_epochs,\n                                       validation_data=validation_generator,\n                                       validation_steps=nb_val_steps,\n                                       callbacks=[earlyStopping, mcp_save,lr_schedule])","5e637187":"vgg19_conv.save('prostate_cancer_vgg19_conv.h5')\nAccuracies_list.append(['vgg19', vgg19_history])","271878eb":"def show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(20,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('AUC')\n    ax[1].plot(history.epoch, history.history[\"auc\"], label=\"Train AUC\")\n    ax[1].plot(history.epoch, history.history[\"val_auc\"], label=\"Validation AUC\")\n    ax[2].set_title('Accuracy')\n    ax[2].plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\n    ax[2].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()","69592e5b":"show_history(vgg19_history)","63fc5382":"from keras.applications.inception_v3 import InceptionV3\ndef InceptionV3_model(num_classes = None):\n    InceptionV3_weights = '..\/input\/keras-pretrained-models\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    model = InceptionV3(weights= InceptionV3_weights, include_top=False, input_shape=(224, 224, 3))\n    x=Dropout(0.3)(model.output)\n    x=Flatten()(x)\n    x =Dense(32, activation = 'relu')(x)\n    x =Dropout(0.2)(x)\n    output=Dense(num_classes,activation='softmax')(x)\n    model=Model(model.input,output)\n    return model\nInceptionV3_conv = InceptionV3_model(6)","72f7b9b3":"InceptionV3_conv.summary()","becd2888":"InceptionV3_conv.compile(loss='binary_crossentropy',optimizer=opt,metrics=METRICS)","527f8967":"InceptionV3_history=InceptionV3_conv.fit_generator( train_generator,\n                                           steps_per_epoch=nb_train_steps,\n                                           epochs=nb_epochs,\n                                           validation_data=validation_generator,\n                                           validation_steps=nb_val_steps,\n                                           callbacks=[earlyStopping, mcp_save,lr_schedule])","f0a55a05":"InceptionV3_conv.save('prostate_cancer_vgg19_conv.h5')\nAccuracies_list.append(['InceptionV3',InceptionV3_history])","f13aa141":"def show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(20,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('AUC')\n    ax[1].plot(history.epoch, history.history[\"auc\"], label=\"Train AUC\")\n    ax[1].plot(history.epoch, history.history[\"val_auc\"], label=\"Validation AUC\")\n    ax[2].set_title('Accuracy')\n    ax[2].plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\n    ax[2].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()","5aad1dba":"show_history(InceptionV3_history)","0f73e386":"Accuracies_list = np.array(Accuracies_list)\nmodel_names = Accuracies_list[:, 0]\nhistories = Accuracies_list[:, 1]\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 20))\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('auc')[-1], histories)), ax=ax[0, 0], palette='Spectral')\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('val_auc')[-1], histories)), ax=ax[0, 1], palette='gist_yarg')\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('accuracy')[-1], histories)), ax=ax[1, 0], palette='rocket')\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('val_accuracy')[-1], histories)), ax=ax[1, 1], palette='ocean_r')\nax[0, 0].set_title('Model Training AUC scores')\nax[0, 1].set_title('Model Validation AUC scores')\nax[1, 0].set_title('Model Training Accuracies')\nax[1, 1].set_title('Model Validation Accuracies')\nfig.suptitle('Model Comparisions')\nplt.show()","5495bb76":"metric_dataframe = pd.DataFrame({\n    'Model Names': model_names,\n    'True Positives': list(map(lambda x: x.history.get('tp')[-1], histories)),\n    'False Positives': list(map(lambda x: x.history.get('fp')[-1], histories)),\n    'True Negatives': list(map(lambda x: x.history.get('tn')[-1], histories)),\n    'False Negatives': list(map(lambda x: x.history.get('fn')[-1], histories))\n})\nfig, ax = plt.subplots(2, 2, figsize=(20, 20))\nsns.barplot(x='Model Names', y='True Positives', data=metric_dataframe, ax=ax[0, 0], palette='BrBG')\nsns.barplot(x='Model Names', y='False Positives', data=metric_dataframe, ax=ax[0, 1], palette='icefire_r')\nsns.barplot(x='Model Names', y='True Negatives', data=metric_dataframe, ax=ax[1, 0], palette='PuBu_r')\nsns.barplot(x='Model Names', y='False Negatives', data=metric_dataframe, ax=ax[1, 1], palette='YlOrBr')\nax[0, 0].set_title('True Positives of Models')\nax[0, 1].set_title('False Positives of Models')\nax[1, 0].set_title('True Negatives of Models')\nax[1, 1].set_title('False Negatives of Models')\nfig.suptitle('Confusion Matrix comparision of Models', size=16)\nplt.show()","527f6a02":"vgg16_conv.load_weights(\"best_model.h5\")\n","d7f7f2ac":"import skimage.io\ndef predict_isup_grade(df, path):\n    \n    df[\"image_path\"] = [path+image_id+\".tiff\" for image_id in df[\"image_id\"]]\n    df[\"isup_grade\"] = 0\n    predictions = []\n    for idx, row in df.iterrows():\n        print(row.image_path)\n        img=skimage.io.imread(str(row.image_path))\n        img = cv2.resize(img, (224,224))\n        img = cv2.resize(img, (224,224))\n        img = img.astype(np.float32)\/255.\n        img=np.reshape(img,(1,224,224,3))\n        prediction=vgg16_conv.predict(img)\n        predictions.append(np.argmax(prediction))\n            \n    df[\"isup_grade\"] = predictions\n    df = df.drop('image_path', 1)\n    return df[[\"image_id\",\"isup_grade\"]]\n","92ca40a0":"training_df_val = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/train.csv\")[:20]\npredict_isup_grade(training_df_val, image_path)","d6875f3a":"\"\"\"\ntest_path = \"..\/input\/prostate-cancer-grade-assessment\/test_images\/\"\ntest_df = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/test.csv\")[:20]\npredict_isup_grade(test_df, test_path, passes=5)\npredict_isup_grade.head()\n\"\"\"","546b341a":"\npanda-resized-train-data-512x512 , code source : [Links](https:\/\/www.kaggle.com\/xhlulu\/panda-resize-and-save-train-data)","553b7742":"## Visualisation de donn\u00e9es","48cc5e18":"# Affichage de quelques masques pour loacaliser le cancer et comprendre chaque grade de la maladie","c34abb0a":"#### METRIC","4b27f697":"## prochain travail\n1. cr\u00e9er une nouvelle data-set a partir des images supprim\u00e9es pour le test apr\u00e8s ,car il y a juste le test.csv , les images pour le test n'existe pas\n1. essayer de nouvelle techniques ,il est possible que j'utilise pytorch","24660d6f":"* 1. ISUP grade = 0  Gleason score 0+0 or negative.\n* 1. ISUP grade = 1  Gleason score 3+3.\n* 1. ISUP grade = 2  Gleason score 3+4.\n* 1. ISUP grade = 3  Gleason score 4+3.\n* 1. ISUP grade = 4  Gleason score 4+4 (majority), 3+5 or 5+3.\n* 1. ISUP grade = 5  Gleason score 4+5 (majority), 5+4 or 5+5.","1c1c554e":"# Affichage de quelques images","c0d75b05":"### apr\u00e8s le divisiment de notre data set","1e3c19fc":"# 3.Pr\u00e9paration de la base de donn\u00e9es","344780c9":"<img src=\"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/PANDA\/Screen%20Shot%202020-04-08%20at%202.03.53%20PM.png\" height=\"100px\">","63509b6f":"# ISUP = 2 Gleason score = 4 + 3 \n** Il n'y a pas de ISUP = 2 , Gleason score = 4+3 dans le syst\u00e8me de notation Gleason + il n'y a qu'une seule image de ce type et elle semble \u00eatre une erreur, je vais donc la supprimer.**","cb5faca9":"# Sommaire\n1. Objectifs\n2. Comprendre la base de donn\u00e9es\n   * Comprendre la base de donn\u00e9es\n3. Pr\u00e9paration de la base de donn\u00e9es\n * Visualisation de donn\u00e9es\n * Fixer quelques probl\u00e8mes dans la base de donn\u00e9es\n    * Images sans masque\n    * ISUP = 2 Gleason score = 4 + 3 \n    * remplacer \"n\u00e9gatif\" par \"0+0\"\n    * Quelques probl\u00e8mes dans la base de donn\u00e9es","c2da1dc2":"# Images sans masque\nil y a des images sans masque dans la base de ddonn\u00e9es","dd894533":"inspir\u00e9 de : [Links](https:\/\/medium.com\/@kvnamipara\/a-better-visualisation-of-pie-charts-by-matplotlib-935b7667d77f)","bf5a3a18":"### diviser notre data set","35fadbad":"### data  augmentation","6c3b366d":"# 2.Comprendre la base de donn\u00e9es\n\n\ntrain.csv et test.csv:\n\n* image_id: Code d'identification de l'image.\n\n* data_provider: Le nom de l'institution qui a fourni les donn\u00e9es. L'Institut **Karolinska** et le Centre m\u00e9dical universitaire **Radboud** \n\n\n\n*   uniquement dans train.csv\n\n* isup_grade: La gravit\u00e9 du cancer sur une \u00e9chelle de 0 \u00e0 5.\n\n* gleason_score: Un syst\u00e8me alternatif d'\u00e9valuation de la gravit\u00e9 du cancer avec plus de niveaux que l'\u00e9chelle ISUP. \n\n* train_images:\n* 10616 images de type .tiff \n  * Karolinska=5455 images\n  * Radboud=5060 images\n* test_images:\n3 images de type .tiff\n\ntrain_label_masks: Segmentation masks showing which parts of the image led to the ISUP grade. Not all training images have label masks, and there may be false positives or false negatives in the label masks for a variety of reasons. These masks are provided to assist with the development of strategies for selecting the most useful subsamples of the images. The mask values depend on the data provider:","50da3977":"# 1. Objectifs\nD\u00e9tecter et classer la gravit\u00e9 du cancer de la prostate sur des images d'\u00e9chantillons de tissus prostatiques.\n\nEn pratique, les \u00e9chantillons de tissus sont examin\u00e9s et not\u00e9s par les pathologistes selon le syst\u00e8me de notation dit de Gleason, qui est ensuite converti en grade ISUP.","9c172145":"* le test data contient uniquement 3 images , donc  je vais cr\u00e9er un autre fichier new_test.csv  avec les 100 images que j'ai supprim\u00e9 (images sans masque)","3b13a6e9":"# Affichage de quelques images et leurs masques","0aa7c1b2":"*   nous pouvons voir que radboud n'a pas de valeurs \"0+0\" alors que karolinska n'a pas de valeurs \"negative\".\n*    conclusion : \"negative\" correspond \u00e0 la fa\u00e7on dont le radbound repr\u00e9sente \"0+0\" (c'est-\u00e0-dire l'absence de cancer) ; il serait donc plus logique de remplacer \"negative\" par \"0+0\".","fee3e60b":"lr= 0.0005, momentum=0.9,decay=1e-4 ,inspir\u00e9 de : [Links](https:\/\/machinelearningmastery.com\/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks\/)","6093fdcc":"## Fixer quelques probl\u00e8mes dans la base de donn\u00e9es","accb92e4":"# remplacer \"negative\" par \"0+0\""}}