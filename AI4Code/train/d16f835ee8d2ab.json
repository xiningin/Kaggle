{"cell_type":{"770be949":"code","af01cfd2":"code","eb0f2e94":"code","b10493c0":"code","c0abb1cf":"code","b903e4d5":"code","a2c27ce8":"code","7fa7aedc":"code","883fe349":"code","b8ea25bb":"code","2db069a1":"code","d641d302":"code","cded868e":"code","95f62091":"code","a73fe039":"code","f2d775fe":"code","0e6f38e5":"code","d0356d9c":"code","34b4dcdf":"code","173348c9":"code","e6ed7045":"code","3aa2354f":"code","eb3d9754":"code","c83f086f":"code","45fcad0c":"code","9c50453b":"markdown","f478136f":"markdown","54b367a0":"markdown","557feee0":"markdown","e9a11a5c":"markdown","acd9ecd7":"markdown","2436f1e6":"markdown","6ec9adf2":"markdown","5f1b7c63":"markdown","7a1a1443":"markdown","a39df4cd":"markdown","1b917123":"markdown","d6d99958":"markdown"},"source":{"770be949":"# import libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","af01cfd2":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","eb0f2e94":"# Load the data\ndata = pd.read_csv('..\/input\/chinese-mnist-digit-recognizer\/chineseMNIST.csv')","b10493c0":"#take a look at the data\ndata.head()","c0abb1cf":"#check the unique labels\ndata['label'].unique()","b903e4d5":"# replace the labels\ndata['label'].replace(100, 11, inplace=True)\ndata['label'].replace(1000, 12, inplace=True)\ndata['label'].replace(10000, 13, inplace=True)\ndata['label'].replace(100000000, 14, inplace=True)","a2c27ce8":"# check agin to be sure\ndata['label'].unique()","7fa7aedc":"# define X and Y\nX = data.drop(['label', 'character'], axis = 1)\nY = data['label']","883fe349":"# normalize the data (features)\nX = X \/ 255.0","b8ea25bb":"# convert data to np.array\nX = X.values","2db069a1":"# here we rashape the image into the following dimensions: height x width x channel\n# 64 pixels x 64 pixels x 1 pixel (for black and white)\n\nX = X.reshape(-1,64,64,1)","d641d302":"Y.unique()","cded868e":"# convert features to categorical (similar to one hot encoder)\nY = to_categorical(Y, num_classes = 15)","95f62091":"# check the shape of the data\nprint(X.shape, Y.shape)","a73fe039":"# split the data into train and test\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 42)\nX_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size = 0.5, random_state = 42)\n\nprint(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)","f2d775fe":"# define the model function\n\ndef create_model():\n    \n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', activation ='relu', input_shape = (64,64,1), name='conv_11'))\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', activation ='relu', name='conv_12'))\n    model.add(MaxPool2D(pool_size=(2,2), name='pool_1'))\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu', name='conv_21'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu', name='conv_22'))\n    model.add(MaxPool2D(pool_size=(2,2), name='pool_2'))\n    model.add(Dropout(0.4))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(256, activation = \"relu\"))\n    \n    model.add(Dropout(0.4))\n    \n    model.add(Dense(15, activation = \"softmax\"))\n    \n    return model","0e6f38e5":"# create the model\nmodel_CNN = create_model()\nprint(model_CNN.summary())","d0356d9c":"# use data augmentation to improve accuracy and prevent overfitting\naugs_gen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False, \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1, \n        horizontal_flip=False,  \n        vertical_flip=False) \n\ngenerator_train = augs_gen.flow(X_train, Y_train, batch_size=64)","34b4dcdf":"# define number of steps (length of train set divided by batch size)\nsteps = int(X_train.shape[0] \/ 64)","173348c9":"# optimize the model\noptimizer = RMSprop( learning_rate = 0.001, rho = 0.9, epsilon = 0.0000001, decay=0.0, centered=False)","e6ed7045":"# compile the model\nmodel_CNN.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])","3aa2354f":"#use callbacks\ncheckpoint = ModelCheckpoint(\"\", monitor='val_accuracy', verbose=1, save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=0.00005, verbose=1)\nearly_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=7, mode='auto', restore_best_weights=True)","eb3d9754":"# fit the model\nhistory = model_CNN.fit(generator_train, steps_per_epoch=steps, batch_size = 64, epochs = 50, validation_data = (X_val, Y_val), verbose = 1, callbacks = [checkpoint, reduce_lr, early_stop])","c83f086f":"# evaluate the model\n\n# predict on validation set\nY_pred_val = model_CNN.predict(X_val)\n\n# check the class predicted with the highest probability (most common)\nY_pred_mc_class = np.argmax(Y_pred_val, axis=1)\n\n# check the groudtruth most common class\nY_test_mc_class = np.argmax(Y_val, axis=1)\n\n# compare them\naccuracy_on_val = np.mean(Y_pred_mc_class == Y_test_mc_class)\n\n# print the accuracy\nprint(\"Validation accuracy (after the training): \", accuracy_on_val, \"\\n\")\n\n\n# plot the validation and training accuracy\nfig, axis = plt.subplots(1, 2, figsize=(16,6))\naxis[0].plot(history.history['val_accuracy'], label='val_acc')\naxis[0].set_title(\"Validation Accuracy\")\naxis[0].set_xlabel(\"Epochs\")\naxis[1].plot(history.history['accuracy'], label='acc')\naxis[1].set_title(\"Training Accuracy\")\naxis[1].set_xlabel(\"Epochs\")\nplt.show()\n\n\n# predict on test set\nY_pred_test = model_CNN.predict(X_test)\n\n# check the class predicted with the highest probability (most common)\nY_pred_mc_class = np.argmax(Y_pred_test, axis=1)\n\n# check the groudtruth most common class\nY_test_mc_class = np.argmax(Y_test, axis=1)\n\n# compare them\naccuracy_on_test = np.mean(Y_pred_mc_class == Y_test_mc_class)\n\n# print the accuracy\nprint(\"Test accuracy (prediction on test data): \", accuracy_on_test, \"\\n\")\n\n\n# plot the Confusion Matrix\nfig, ax = plt.subplots(figsize=(12, 12))\ncm = confusion_matrix(Y_test_mc_class,Y_pred_mc_class, normalize='true')\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14])\ndisp = disp.plot(ax=ax,cmap=plt.cm.Blues)\nax.set_title(\"Confusion Matrix\")\nplt.show()\n","45fcad0c":"# evaluate the model with Keras method\nmodel_CNN.evaluate(X_test, Y_test)","9c50453b":"**Data augmentation** \n\nOne way to avoid overfitting and improve the accuracy is to increase the variability of existing samples. Which is also helps to compensate lack of data.\n<br>Data augmentation generates data from existing samples by applying various transformations to the original dataset. This method aims to increase the number of unique input samples, which, in turn, will allow the model to show better accuracy on the validation dataset.","f478136f":"Our data is now stored as 1D np.array. The length of the array is 4096 (64 pixels x 64 pixels). To feed the data into the Keras model, we reshape it to 64 pixels x 64 pixels and add additional dimension for the number of channels (1 in case of greyscale).","54b367a0":"...and here we go!","557feee0":"Here I use Keras Sequential API with the following architecture:\n\n - Input<br>\n - Conv2D - > Conv2D - > MaxPool2D -> Dropout<br>\n - Conv2D - > Conv2D - > MaxPool2D -> Dropout<br>\n - Flatten<br>\n - Dense<br>\n - Dropout<br>\n - Output\n","e9a11a5c":"We did not make any significant transformations or conversions of the data. We rescale pixel values from the range (0, 255) to the range (0, 1) as it is the best format for neural network models. Through this transformation, we also reduce the effect of illumination's differences, which is not as relevant for our case but can generally be helpful when working with the photo. \n\nScaling data to the range (0, 1) is usually called **normalization** and, in our case, is achieved by dividing the value of each pixel by 255 (normalization coefficient 1\/255 = ~0.0039).","acd9ecd7":"## Load and prepare the data","2436f1e6":"We have 15 classes. We need to replace 100, 1000, 10000 and 100000000 with other class labels like 11, 12, 13 and 14. Otherewise we couldn't convert the class to categorical.","6ec9adf2":"Some comments to the layers.\n\n**Conv2D**  layers perform the process that is called convolution. The essence of convolution is to create another set of values, which is called a kernel or filter. In our case, this is a 3 x 3 matrix. Then we scan our image using this kernel. A convolution layer is applied to each section of the input image. In other words, here, the network learns the details of the image.\n\nWe can experiment with number of filters and their size.\n\n**MaxPool2D** layer is simply compressing (reducing the size of) the image. The result will be a smaller image compared to the original input image. At this layer, the network also learns the whole structure of the image.\n\n**Dropout** layer is used to avoid overfitting. \n\n**Flatten** layer converts the data into a 1D array. ","5f1b7c63":"## Introduction","7a1a1443":"In this notebook I use the Sequential Convolutional Neural Network for Chinese characters recognition. This task is similar to the famous  MNIST digits data set. The algorithm I use here is a fairly simple and versatile, in this version it can be used for different image recognition tasks. \n\nIf you have any ideas please share them in the comments. Feel free to use this code in your notebooks. You can try to use this code also for MNIST digits recognition as well as other image recognition cases.","a39df4cd":"For the optimizer I use RMSprop (root mean square propagation), one of the built-in optimizers based on the gradient descent algorithm. In the documentation we can find the formula by which the optimizer updates the model parameters.","1b917123":"## Model","d6d99958":"Callbacks are very convenient because we can be sure that the learning process will stop as soon as the chosen metrics stop improving. In this way, we can set a large number of epochs and do not worry that the metrics stopped improving."}}