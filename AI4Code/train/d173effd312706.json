{"cell_type":{"f3ba3302":"code","43089a42":"code","51348e05":"code","4dd0f49e":"code","46c282a0":"code","b0b13024":"code","b26b6416":"code","1edc2122":"code","a6481bb8":"code","6c3c4614":"code","0e78ffc8":"code","85d31f9c":"code","be62377b":"code","1576813a":"code","56d9c50b":"code","865f2a69":"code","ec3249ef":"code","d60b3acc":"code","75dc6809":"code","72960082":"code","b99d0381":"code","53b07c35":"code","a98332f7":"code","58f6c67b":"code","e7997808":"code","1362beac":"markdown","3d2bef3b":"markdown","539c3900":"markdown","dc0eccdf":"markdown","47e7f2b1":"markdown","e586edcf":"markdown","a83417dc":"markdown","ead0d23b":"markdown","52b76278":"markdown","b38db176":"markdown","fee71c0b":"markdown","005a3eec":"markdown"},"source":{"f3ba3302":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nimport re\nimport nltk\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Split\nfrom sklearn.model_selection import train_test_split\n\n# Score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, plot_confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# SMOTE\nfrom imblearn.over_sampling import SMOTE\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","43089a42":"df = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv',encoding=\"ISO-8859-1\")\nprint('Data is loaded!')","51348e05":"df.head()","4dd0f49e":"message = df['v2']\nlabel = df['v1']\n\ndf = pd.DataFrame({'text':message,'label':label})","46c282a0":"df.head()","b0b13024":"df","b26b6416":"df['label'].value_counts()","1edc2122":"sns.countplot(x='label',data=df)","a6481bb8":"plt.rcParams['figure.figsize'] = (8, 8)\nwordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 121).generate(str(df['text']))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Most Popular Words',fontsize = 15)\nplt.show()","6c3c4614":"corpus = []\nfor i in range(0, 5572):\n  text = re.sub('[^a-zA-Z]', ' ', df['text'][i])\n  text = text.lower()\n  text = text.split()\n  ps = PorterStemmer()\n  all_stopwords = stopwords.words('english')\n  all_stopwords.remove('not')\n  text = [ps.stem(word) for word in text if not word in set(all_stopwords)]\n  text = ' '.join(text)\n  corpus.append(text)","0e78ffc8":"print(corpus[:15])","85d31f9c":"label_encode = df.label.factorize()\ndf['label'] = label_encode[0]","be62377b":"cv = CountVectorizer()\nX = cv.fit_transform(corpus).toarray()\ny = df.iloc[:, -1].values","1576813a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","56d9c50b":"# Handle imbalance class using oversampling minority class with SMOTE method\nos = SMOTE(sampling_strategy='minority',random_state = 1,k_neighbors=5)\nX_train,y_train = os.fit_resample(X_train,y_train)","865f2a69":"# Build the model\nlength = X_train.shape[1]\n\nmodel = Sequential()\nmodel.add(Dense(100,input_shape=(length,) , activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam', \n                           metrics=['accuracy'])\nprint(model.summary())","ec3249ef":"earlystopping = callbacks.EarlyStopping(monitor='val_loss',\n                                        mode='min',\n                                        verbose=1,\n                                        patience=5)","d60b3acc":"history = model.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=200,batch_size=32,callbacks =[earlystopping])","75dc6809":"# summarize history for acc\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","72960082":"print('Max val_acc achieved: %.2f' %(max(history.history['val_accuracy'])*100), '%')\nprint('Max acc achieved: %.2f' %(max(history.history['accuracy'])*100), '%')","b99d0381":"print('Final val_acc achieved: %.2f' %(history.history['val_accuracy'][-1]*100), '%')\nprint('Final acc achieved: %.2f' %(history.history['accuracy'][-1]*100), '%')","53b07c35":"val_accuracy = np.mean(history.history['val_accuracy'])\nprint(\"\\n%s: %.2f%%\" % ('Mean of validation accuracy', val_accuracy*100))","a98332f7":"y_pred = model.predict(X_test)","58f6c67b":"y_pred = (y_pred > 0.5)","e7997808":"print(\"Accuracy Score:\", accuracy_score(y_test,y_pred)*100,\"%\")\n\nfig, ax = plt.subplots(1,figsize=(6,6))\nlabels=['No','Yes']\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap=\"Blues\", fmt='g', cbar=False,ax=ax)\nplt.suptitle('Confusion Matrix', fontsize=30)\nax.set_title('Accurcay Score')\nax.set_yticklabels(labels);\nax.set_xticklabels(labels);\nax.set_ylabel('Test',fontsize=20)\nax.set_xlabel('Predicted',fontsize=20)","1362beac":"<a id=\"eda\"><\/a>\n## 3. EDA","3d2bef3b":"### Load Dataset","539c3900":"<a id=\"data_preprocessing\"><\/a>\n## 4. Data Preprocessing","dc0eccdf":"<h1 style='color:white;background-color:black' > Table of Contents <\/h1>\n\n* [Introduction](#introduction)\n* [Data Acquisition](#data_acquisition)\n* [EDA](#eda)\n* [Data Preprocessing](#preprocessing)\n* [Building the Model](#model)\n* [Evaluation](#evaluation)","47e7f2b1":"<a id=\"data_acquisition\"><\/a>\n## 2. Data Acquisition","e586edcf":"<a id=\"introduction\"><\/a>\n## 1. Introduction","a83417dc":"<a id=\"evaluation\"><\/a>\n## 4. Evaluation","ead0d23b":"> <center><img src=\"https:\/\/www.rd.com\/wp-content\/uploads\/2020\/12\/spamtext-1024x683.gif\" width=\"1000px\"><\/center>","52b76278":"<div align='left'><font size=\"3\" color=\"#000000\"> The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.\n<\/font><\/div>\n\n* **Problem Statement:**\n<div align='left'><font size=\"3\" color=\"#000000\"> Can you use this dataset to build a prediction model that will accurately classify which texts are spam?\n<\/font><\/div>\n\n\n","b38db176":"<a id=\"model\"><\/a>\n## 3. Building the Model","fee71c0b":"# **SMS Spam Detection**","005a3eec":"### Import Libraries"}}