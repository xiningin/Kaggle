{"cell_type":{"ee820e31":"code","2581519c":"code","4fedc187":"code","b47410ba":"code","6ddb732d":"code","c9193391":"code","a4233bcd":"code","96f25ce7":"code","9e5f9214":"code","853afac2":"code","cbd6813a":"code","89b05ac0":"code","4e425e6b":"code","4ea0925c":"code","116fc41d":"code","19ac7ab8":"markdown","133c7c7e":"markdown","727084ea":"markdown"},"source":{"ee820e31":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport lightgbm as lgbm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport gc","2581519c":"def reduce_mem_usage(df):\n    for col in df.columns:\n        if df[col].dtype=='float64': df[col] = df[col].astype('float32')\n        if df[col].dtype=='int64': df[col] = df[col].astype('int32')\n    return df","4fedc187":"# import data\ntrain_transaction = reduce_mem_usage(pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID'))\ntrain_identity = reduce_mem_usage(pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv', index_col='TransactionID'))\n\n# merge\ntrain_df = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n\n# Prepare data\nX = train_df.drop(['TransactionDT','isFraud'],axis=1)\ny = train_df['isFraud']\n\nfor col in X.columns:\n    if X[col].dtype == 'object':\n        le = LabelEncoder()\n        X[col] = le.fit_transform(list(X[col].astype(str).values))","b47410ba":"\nlgbm_params = {'num_leaves':165,\n               'min_child_weight': 10,\n               'min_child_samples': 10,\n               'min_split_gain': 0,\n               'subsample': .632,\n               'subsample_freq':1,\n               'objective': 'binary',\n               'max_depth': -1,\n               'learning_rate': 0.1, \n               \"boosting_type\": \"rf\",\n               \"bagging_seed\": 11,\n               \"metric\": 'auc',\n               'random_state': 47,\n               'num_rounds': 400,\n               'reg_alpha':10 # Tweak Me\n              }","6ddb732d":"### train\/test\/split\ntrain_idx = int(len(X)*0.6)\nx_trn = X[:train_idx]\ny_trn = y[:train_idx]\n\n### hold out valid\nidx = int(0.8*len(X))\n\ny_ho = y[idx:]\nx_ho = X[idx:]","c9193391":"# CV\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS, shuffle=True, random_state=47)\n\ncolumns = x_trn.columns\nsplits = folds.split(x_trn, y_trn)\ny_preds = np.zeros(x_ho.shape[0])\n\nl1_feature_importances = pd.DataFrame()\nl1_feature_importances['feature'] = columns","a4233bcd":"for fold_n, (train_index, valid_index) in enumerate(splits):\n    X_train, X_valid = x_trn[columns].iloc[train_index], x_trn[columns].iloc[valid_index]\n    y_train, y_valid = y_trn.iloc[train_index], y_trn.iloc[valid_index]\n    \n    dtrain = lgbm.Dataset(X_train, label=y_train)\n    dvalid = lgbm.Dataset(x_ho, label=y_ho)\n\n    clf = lgbm.train(lgbm_params, dtrain, valid_sets = [dtrain, dvalid], \n                    verbose_eval=200)\n    \n    l1_feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n    \n    y_pred_valid = clf.predict(x_ho)\n\n    del X_train, X_valid, y_train, y_valid\n    gc.collect()\n    \ndel clf, x_trn, y_trn, x_ho, y_ho","96f25ce7":"l1_feature_importances['average'] = l1_feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(folds.n_splits)]].mean(axis=1)\nl1_feature_importances.to_csv('l1_feature_importances.csv')\n\nplt.figure(figsize=(16, 16))\nsns.barplot(data=l1_feature_importances.sort_values(by='average', ascending=False).head(30), x='average', y='feature');","9e5f9214":"print('L1 Zero Importance Features:')\nprint(l1_feature_importances[l1_feature_importances['average'] == 0]['feature'])","853afac2":"lgbm_params = {'num_leaves':165,\n               'min_child_weight': 10,\n               'min_child_samples': 10,\n               'min_split_gain': 0,\n               'subsample': .632,\n               'subsample_freq':1,\n               'objective': 'binary',\n               'max_depth': -1,\n               'learning_rate': 0.1, \n               \"boosting_type\": \"rf\",\n               \"bagging_seed\": 11,\n               \"metric\": 'auc',\n               'random_state': 47,\n               'num_rounds': 400,\n               'reg_lambda':5 # Tweak Me\n              }","cbd6813a":"### train\/test\/split\ntrain_idx = int(len(X)*0.6)\nx_trn = X[:train_idx]\ny_trn = y[:train_idx]\n\n### hold out valid\nidx = int(0.8*len(X))\n\ny_ho = y[idx:]\nx_ho = X[idx:]\n\n# CV\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS, shuffle=True, random_state=47)\n\ncolumns = x_trn.columns\nsplits = folds.split(x_trn, y_trn)\ny_preds = np.zeros(x_ho.shape[0])\n\nl2_feature_importances = pd.DataFrame()\nl2_feature_importances['feature'] = columns","89b05ac0":"for fold_n, (train_index, valid_index) in enumerate(splits):\n    X_train, X_valid = x_trn[columns].iloc[train_index], x_trn[columns].iloc[valid_index]\n    y_train, y_valid = y_trn.iloc[train_index], y_trn.iloc[valid_index]\n    \n    dtrain = lgbm.Dataset(X_train, label=y_train)\n    dvalid = lgbm.Dataset(x_ho, label=y_ho)\n\n    clf = lgbm.train(lgbm_params, dtrain, valid_sets = [dtrain, dvalid], \n                    verbose_eval=200)\n    \n    l2_feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n    \n    y_pred_valid = clf.predict(x_ho)\n\n    del X_train, X_valid, y_train, y_valid\n    gc.collect()\n    \ndel clf, x_trn, y_trn, x_ho, y_ho","4e425e6b":"l2_feature_importances['average'] = l2_feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(folds.n_splits)]].mean(axis=1)\nl2_feature_importances.to_csv('l2_feature_importances.csv')\n\nplt.figure(figsize=(16, 16))\nsns.barplot(data=l2_feature_importances.sort_values(by='average', ascending=False).head(30), x='average', y='feature');","4ea0925c":"print('L2 Zero Importance Features:')\nprint(l2_feature_importances[l2_feature_importances['average'] == 0]['feature'])","116fc41d":"### Reference\n# https:\/\/www.kaggle.com\/ogrellier\/lgbm-regularized-random-forest","19ac7ab8":"<h1 align=\"center\"> L2 Regularisation <\/h1> <br>","133c7c7e":"<h1 align=\"center\"> L1 Regularisation <\/h1> <br>","727084ea":"<h1 align=\"center\"> Feature Selection via Regularised Random Forest <\/h1> <br>\n\nThis notebook describe a way of feature selection using regularised trees. \n\n> The key idea is to penalize selecting a new feature by its information gain in the splitting process"}}