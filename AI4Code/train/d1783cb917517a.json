{"cell_type":{"26795e65":"code","ff57724a":"code","4e2b1832":"code","a51c2448":"code","81da2582":"code","6257891e":"code","436349c5":"code","185b49e6":"code","eef97ddf":"code","716d505b":"code","39265e53":"code","0418f6bb":"code","124ef51f":"code","1899156e":"code","43ed7e9f":"code","b9af824c":"code","d61aebea":"code","6d0b2f9d":"markdown","88fcf8c6":"markdown","7d60d141":"markdown","5fa68343":"markdown","29a4cca8":"markdown","5c685546":"markdown","7120057b":"markdown","17222486":"markdown","a6bddb3f":"markdown"},"source":{"26795e65":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff57724a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score,confusion_matrix,accuracy_score,precision_score,recall_score,plot_precision_recall_curve\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,GlobalMaxPooling2D,BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator,load_img\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.utils import to_categorical\n","4e2b1832":"#Load the Data\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nx_train = train.drop(labels=['label'],axis=1)\ny_train = train['label']","a51c2448":"#Count \ncount = y_train.value_counts()\nplt.figure(figsize=(8,6))\nsns.countplot(y_train)\nprint(count)","81da2582":"#Normalize\nx_train = x_train\/255.0\ntest = test\/255.0\n\n#Reshape\nx_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","6257891e":"#Images\nindex = np.random.randint(0,42000)\nimg = x_train[index][:,:,0]\nplt.imshow(img)\nplt.title(y_train[index])","436349c5":"#Split Data\nx_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=42)","185b49e6":"model = Sequential()\n\nmodel.add(Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(128,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(10,activation='softmax'))\n\nmodel.compile(RMSprop(lr=0.001,rho=0.9),loss='sparse_categorical_crossentropy',metrics=['acc'])\nmodel.summary()\n","eef97ddf":"train_datagen = ImageDataGenerator(rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=False,\n                                   fill_mode='nearest')\ntrain_datagen.fit(x_train)\ntrain_generator = train_datagen.flow(x_train,y_train,batch_size=128)\n","716d505b":"#Callbacks\nearlystop = EarlyStopping(monitor='val_loss',patience=2,verbose=1)\nlearning_reduce = ReduceLROnPlateau(patience=2,monitor=\"val_acc\",verbose=1,min_lr=0.00001,factor=0.5)\ncallbacks = [earlystop,learning_reduce]","39265e53":"history = model.fit_generator(train_generator,epochs=30,verbose=1,validation_data=(x_val,y_val),callbacks=callbacks)","0418f6bb":"#Visualize Training\ndef plot_graphs(history, string):\n    plt.figure(figsize=(8,8))\n    plt.plot(history.history[string])\n    plt.plot(history.history[\"val_\"+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string,\"val_\"+string])\n    plt.show()\nplot_graphs(history,'acc')\nplot_graphs(history,'loss')","124ef51f":"loss,accuracy = model.evaluate(x_val,y_val,verbose=1)\nprint(\"Validation Loss: \",loss)\nprint(\"Validation Accuracy: \",accuracy)","1899156e":"y_pred = model.predict(x_val)\ny_pred = np.argmax(y_pred,axis=1)\n\nconfusion = confusion_matrix(y_val, y_pred)\n\nplt.figure(figsize=(10,10))\nsns.heatmap(confusion, annot=True,cmap=\"Blues\",fmt='.1f')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","43ed7e9f":"recall = recall_score(y_val,y_pred,average='micro')\nprecision = precision_score(y_val,y_pred,average='micro')\nprint(\"Precision: \",precision)\nprint(\"Recall: \",recall)","b9af824c":"predict = model.predict(test)\npredict = np.argmax(predict,axis=1)","d61aebea":"result = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nresult['Label'] = predict\nresult.to_csv(\"submission.csv\",index=False)","6d0b2f9d":"# Callback","88fcf8c6":"# Classification Model","7d60d141":"# Training","5fa68343":"# Confusion Matrix","29a4cca8":"# Test Submission","5c685546":"# Data Preparation","7120057b":"# Image Generator","17222486":"# Importing Libraries","a6bddb3f":"# Evaluation"}}