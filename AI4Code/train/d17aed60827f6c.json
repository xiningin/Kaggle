{"cell_type":{"b9763397":"code","3edaf7ff":"code","e6752161":"code","8da30002":"code","7719e06c":"code","2ecc0258":"code","703676c2":"code","6e76a8bb":"code","01dccf57":"code","deaec40f":"code","8228e67b":"code","1e5da2ef":"code","6bef086a":"code","a71441f5":"code","ee0cb38f":"code","e6446b77":"code","787141b4":"code","478504c0":"code","59cab49b":"code","df99f570":"markdown","1751ca08":"markdown","9463a4a9":"markdown","f3ed57b7":"markdown","8b4ccaf5":"markdown","bdd461d8":"markdown","26e7ec5d":"markdown","565388c8":"markdown","79468538":"markdown","fb8a9d12":"markdown"},"source":{"b9763397":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom tensorflow.python.util import compat\nfrom tensorflow.core.protobuf import saved_model_pb2\nfrom google.protobuf import text_format\nimport pprint\nimport json\nimport os","3edaf7ff":"# needed to install object_detection library and enlarge labels\n! rm -rf .\/models && git clone https:\/\/github.com\/tensorflow\/models.git \\\n    && sed -i \"s#ImageFont.truetype('arial.ttf', 24)#ImageFont.truetype('arial.ttf', 50)#g\" .\/models\/research\/object_detection\/utils\/visualization_utils.py \\\n    && cp \/usr\/share\/fonts\/truetype\/dejavu\/DejaVuSans.ttf \/usr\/share\/fonts\/truetype\/dejavu\/arial.ttf","e6752161":"# install object_detection library\n! cd models\/research \\\n    && protoc object_detection\/protos\/*.proto --python_out=. \\\n    && cp object_detection\/packages\/tf2\/setup.py . && \\\n    python3 -m pip install --use-feature=2020-resolver .","8da30002":"from object_detection.utils import visualization_utils as vis_util\nfrom object_detection.utils import dataset_util, label_map_util\nfrom object_detection.protos import string_int_label_map_pb2","7719e06c":"# reconstruct frozen graph\ndef reconstruct(pb_path):\n    if not os.path.isfile(pb_path):\n        print(\"Error: %s not found\" % pb_path)\n\n    print(\"Reconstructing Tensorflow model\")\n    detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.compat.v1.GraphDef()\n        with tf.io.gfile.GFile(pb_path, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    print(\"Success!\")\n    return detection_graph","2ecc0258":"# visualize detection\ndef image2np(image):\n    (w, h) = image.size\n    return np.array(image.getdata()).reshape((h, w, 3)).astype(np.uint8)\n\ndef image2tensor(image):\n    npim = image2np(image)\n    return np.expand_dims(npim, axis=0)\n\n%matplotlib inline\ndef detect(detection_graph, test_image_path):\n    with detection_graph.as_default():\n        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.01)\n        with tf.compat.v1.Session(graph=detection_graph,config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)) as sess:\n            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n\n            image = Image.open(test_image_path)\n            (boxes, scores, classes, num) = sess.run(\n                [detection_boxes, detection_scores, detection_classes, num_detections],\n                feed_dict={image_tensor: image2tensor(image)}\n            )\n\n            npim = image2np(image)\n            vis_util.visualize_boxes_and_labels_on_image_array(\n                npim,\n                np.squeeze(boxes),\n                np.squeeze(classes).astype(np.int32),\n                np.squeeze(scores),\n                category_index,\n                use_normalized_coordinates=True,\n                line_thickness=15)\n            plt.figure(figsize=(12, 8))\n            plt.imshow(npim)\n            plt.show()","703676c2":"DATA_DIR = '\/kaggle\/input\/tacotrashdataset\/data'\nANNOTATIONS_FILE = os.path.join(DATA_DIR, 'annotations.json')\nNCLASSES = 60","6e76a8bb":"with open(ANNOTATIONS_FILE) as json_file:\n    data = json.load(json_file)\n    \ncategories = data['categories']","01dccf57":"print('Building label map from examples')\n\nlabelmap = string_int_label_map_pb2.StringIntLabelMap()\nfor idx,category in enumerate(categories):\n    item = labelmap.item.add()\n    # label map id 0 is reserved for the background label\n    item.id = int(category['id'])+1\n    item.name = category['name']\n\nwith open('.\/labelmap.pbtxt', 'w') as f:\n    f.write(text_format.MessageToString(labelmap))\n\nprint('Label map witten to labelmap.pbtxt')\n\nwith open('.\/labelmap.pbtxt') as f:\n    pprint.pprint(f.readlines())","deaec40f":"label_map = label_map_util.load_labelmap('labelmap.pbtxt')\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NCLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)","8228e67b":"detection_graph = reconstruct(\"..\/input\/trained-models-taco-trash-annotations-in-context\/ssd_mobilenet_v2_taco_2018_03_29.pb\")","1e5da2ef":"detect(detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_1\/000000.jpg')","6bef086a":"detect(detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_3\/IMG_4852.JPG')","a71441f5":"detect(detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_5\/000000.JPG')","ee0cb38f":"detect(detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_6\/000000.JPG')","e6446b77":"detect(detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_1\/000001.jpg')","787141b4":"detect(detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_1\/000003.jpg')","478504c0":"detect(detection_graph, '\/kaggle\/input\/tacotrashdataset\/data\/batch_1\/000010.jpg')","59cab49b":"! rm -rf .\/models","df99f570":"# Cleanup","1751ca08":"Now we are going to reconstruct the TensorFlow frozen graph (.pb).","9463a4a9":"We are going to use pretrained models in this notebook to show how you can do inference on them of unseen images. The pretrained models can be found here: https:\/\/www.kaggle.com\/bouweceunen\/trained-models-taco-trash-annotations-in-context","f3ed57b7":"# TACO (Garbage) Detection (SSD MobileNet v2) with TensorFlow","8b4ccaf5":"We can now test it on some test images.","bdd461d8":"First we need to create the label map.","26e7ec5d":"# Reconstruct Frozen Graph","565388c8":"TACO can be found here: http:\/\/tacodataset.org\/. \ud83c\udf2e is an open image dataset of waste in the wild. It contains photos of litter taken under diverse environments, from tropical beaches to London streets.","79468538":"# Validate Test Images","fb8a9d12":"# Create LabelMap"}}