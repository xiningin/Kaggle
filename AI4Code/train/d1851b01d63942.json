{"cell_type":{"e4e9fb3b":"code","ac519601":"code","938bd8ec":"code","be9b0172":"code","357c34e5":"code","c46dacf3":"code","f4ecd8ea":"code","80645a26":"code","b471dce9":"code","95e42c92":"code","21be3d68":"code","cca246c7":"code","9d2e6963":"code","10b20b78":"code","fb2c88cf":"code","af5d88dd":"code","0fa63a2f":"code","b1fbbcea":"code","45fc58ca":"code","84babe26":"code","a0b0bb7a":"code","065ada47":"code","75b1ab96":"code","95a08945":"code","dc43da2b":"code","5f947c38":"code","89cb5a65":"code","fa41d506":"code","42892b8e":"code","27f71bcb":"code","723eb7af":"code","f58fad89":"code","333f4548":"code","af6ab8b3":"code","d3f481de":"code","45873ce4":"code","02fe61b3":"code","6deb6b33":"code","c9ba9a4b":"code","0742bc98":"code","662fad1a":"code","53c64b8a":"code","a9bc83f6":"code","45b16383":"code","a1c9e702":"code","6af302f2":"code","bb0fdfaf":"code","9b8007f7":"code","4f9f5096":"code","cf4a9dd0":"code","fed6657c":"code","78771577":"code","36b01b0e":"code","407f9ad3":"code","2ee96b3f":"code","9e3b0be7":"markdown","57903dc3":"markdown","d16334ed":"markdown","4e5b584e":"markdown","ea98bdd4":"markdown","d49e2bd3":"markdown","03903d8f":"markdown","94e786fa":"markdown","ee898476":"markdown","5b83d83c":"markdown","1c3705c7":"markdown","32729334":"markdown","490d7113":"markdown","c9db15eb":"markdown","122da4a3":"markdown","28056590":"markdown","c7983755":"markdown","926e52d5":"markdown","bf85ad8c":"markdown","cdd44b80":"markdown","16f1111e":"markdown","d669cf58":"markdown","44dcd767":"markdown"},"source":{"e4e9fb3b":"import pandas as pd\nimport numpy as np\nimport io\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats","ac519601":"df_train = pd.read_csv(\"..\/input\/datawiz-2021-round-1\/train.csv\", index_col=\"Id\")\ndf_test = pd.read_csv(\"..\/input\/datawiz-2021-round-1\/test.csv\", index_col=\"Id\")","938bd8ec":"df_train.drop(\"Country\", axis=1, inplace=True)\ndf_test.drop(\"Country\", axis=1, inplace=True)","be9b0172":"pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\ndf_train.head()","357c34e5":"print(df_train.shape)\nprint(df_test.shape)","c46dacf3":"print(df_train.info())\nprint(\"\\n============================================\\n\")\nprint(df_test.info())","f4ecd8ea":"df_train.describe()","80645a26":"df_test.describe()","b471dce9":"numerical_lst = [i for i in df_train.columns if df_train[i].dtype == np.float64 or df_train[i].dtype == np.int64]\ncategorical_lst = [i for i in df_train.columns if df_train[i].dtype == \"object\"]","95e42c92":"discrete_lst = [i for i in numerical_lst if len(df_train[i].unique())<20]\nfor i in discrete_lst:\n    sns.countplot(x=i, data=df_train)\n    plt.show(np)\n    print(\"\\n\")","21be3d68":"left_skew_lst = []\nright_skew_lst = []\nfor i in numerical_lst:\n    if i not in discrete_lst:\n        sns.histplot(data=df_train, x=i, bins=50, kde=True)\n        plt.show()\n        num = df_train[i].skew()\n        if num > 1:\n            left_skew_lst.append(i)\n        if num<-1:\n            right_skew_lst.append(i)\n        print(num)\n        print(\"\\n\")","cca246c7":"for i in categorical_lst:\n    plt.figure(figsize=(10, 5))\n    sns.countplot(x=i, data=df_train)\n    plt.show()\n    print(\"\\n\")","9d2e6963":"plt.figure(figsize=(12, 12))\nsns.heatmap(df_train[numerical_lst].corr(), annot=True)","10b20b78":"for i in numerical_lst:\n    if i not in discrete_lst and i != \"Answer\":\n        a = df_train[df_train[\"Answer\"] == 0][i]\n        b = df_train[df_train[\"Answer\"] == 1][i]\n        print(f\"Ttest b\/w {i} and answer is: \", stats.ttest_ind(a, b, nan_policy=\"omit\"))","fb2c88cf":"sns.scatterplot(x=\"Loan\", y=\"Investment\", data=df_train, hue=\"Answer\")","af5d88dd":"sns.scatterplot(x=\"Loan\", y=\"Income\", data=df_train, hue=\"Answer\")","0fa63a2f":"sns.scatterplot(x=\"Income\", y=\"Investment\", data=df_train, hue=\"Answer\")","b1fbbcea":"sns.scatterplot(x=\"Income\", y=\"Working_Hours\", data=df_train, hue=\"Answer\")","45fc58ca":"func1 = lambda r: r\/r.sum()","84babe26":"for i in discrete_lst:\n    plt.figure(figsize=(5, 10))\n    stackCol = pd.crosstab(df_train[i], df_train[\"Answer\"])\n    print(f\"Chi Square test b\/w {i} and Answer is: \", stats.chi2_contingency(np.array(stackCol))[1])\n    stackCol = stackCol.apply(func1, axis=1)\n    stackCol.plot(kind='bar', stacked=True)\n    plt.show()","a0b0bb7a":"for i in categorical_lst:\n    plt.figure(figsize=(5, 10))\n    stackCol = pd.crosstab(df_train[i], df_train[\"Answer\"])\n    print(f\"Chi Square test b\/w {i} and Answer is: \", stats.chi2_contingency(np.array(stackCol))[1])\n    stackCol = stackCol.apply(func1, axis=1)\n    stackCol.plot(kind='bar', stacked=True)\n    plt.show()","065ada47":"drop_lst = [\"Housing\", \"Employer_Kind\", \"Yearly_Breaks\", \"Debt_Paid\"]","75b1ab96":"df_train1 = df_train.drop(drop_lst, axis=1).copy()\ndf_test1 = df_test.drop(drop_lst, axis=1).copy()","95a08945":"df_train1.columns","dc43da2b":"for i in numerical_lst:\n    if i not in discrete_lst and i not in drop_lst:\n        sns.boxplot(x=i, hue=\"Answer\", data=df_train1)\n        plt.show()","5f947c38":"range_lst = []\nfor i in numerical_lst:\n    if i not in discrete_lst and i not in drop_lst:\n        q25, q75 = df_train1[i].quantile(0.25), df_train1[i].quantile(0.75)\n        iqr = q75-q25\n        cut_off = iqr*1.5\n        lower, upper = q25-cut_off, q75+cut_off\n        range_lst.append((lower, upper))","89cb5a65":"df1 = df_train1[(df_train1[\"Age\"]>range_lst[0][0]) & (df_train1[\"Age\"]<range_lst[0][1])]","fa41d506":"df1 = df1[(df1[\"Working_Hours\"]>range_lst[1][0]) & (df1[\"Working_Hours\"]<range_lst[1][1])]","42892b8e":"df1 = df1[(df1[\"Income\"]>range_lst[5][0]) & (df1[\"Income\"]<range_lst[5][1])]","27f71bcb":"df_train2 = df1.copy()\ndel df1","723eb7af":"group_ans = df_train2.groupby(\"Answer\")","f58fad89":"group1 = group_ans.get_group(1)\ngroup0 = group_ans.get_group(0)\ndf_train2.loc[group1.index, \"Marital_Status\"] = group1[\"Marital_Status\"].fillna(\"Single\")\ndf_train2.loc[group0.index, \"Marital_Status\"] = group0[\"Marital_Status\"].fillna(\"Separated\")","333f4548":"group1 = df_test1[df_test1[\"Age\"]<35]\ngroup0 = df_test1[df_test1[\"Age\"]>=35]\ndf_test1.loc[group1.index, \"Marital_Status\"] = group1[\"Marital_Status\"].fillna(\"Separated\")\ndf_test1.loc[group0.index, \"Marital_Status\"] = group0[\"Marital_Status\"].fillna(\"Single\")","af6ab8b3":"df_test1.fillna(value=41, axis=1, inplace=True)","d3f481de":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nohe = OneHotEncoder(drop=\"first\").fit(df_train2[[\"Gender\", \"Marital_Status\"]])","45873ce4":"columns_lst = [\"Gender_M\", \"Marital_Status_DWC\", \"Marital_Status_Engaged\", \"Marital_Status_Married\",\n               \"Marital_Status_Separated\", \"Marital_Status_Single\"]\ndf_train2[columns_lst] = ohe.transform(df_train2[[\"Gender\", \"Marital_Status\"]]).toarray()\ndf_test1[columns_lst] = ohe.transform(df_test1[[\"Gender\", \"Marital_Status\"]]).toarray()","02fe61b3":"oe = OrdinalEncoder().fit(np.array(df_train2[\"Loan Status\"]).reshape((df_train2.shape[0], 1)))\noe.categories_","6deb6b33":"df_train2[\"Loan_Status_new\"] = oe.transform(np.array(df_train2[\"Loan Status\"]).reshape((df_train2.shape[0], 1)))\ndf_test1[\"Loan_Status_new\"] = oe.transform(np.array(df_test1[\"Loan Status\"]).reshape((df_test1.shape[0], 1)))","c9ba9a4b":"df_train2.drop([\"Gender\", \"Marital_Status\", \"Loan Status\"], axis=1, inplace=True)\ndf_test1.drop([\"Gender\", \"Marital_Status\", \"Loan Status\"], axis=1, inplace=True)","0742bc98":"plt.figure(figsize=(14, 14))\nsns.heatmap(df_train2.corr(), cmap=\"plasma\", annot=True)","662fad1a":"#Evaluation\ndef result(model, X, y_true):\n    pred = model.predict_proba(X)\n    print('ROC-AUC:', roc_auc_score(y_true, pred[:, 1]))\n    print(\"\\nClassification report\\n\")\n    pred = model.predict(X)\n    print(classification_report(y_true, pred))\n    print('\\nConfusion matrix:')\n    return confusion_matrix(y_true, pred)","53c64b8a":"from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, learning_curve\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE, RandomOverSampler\nfrom imblearn.under_sampling import NearMiss, TomekLinks\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.feature_selection import f_classif, chi2, SelectKBest, f_oneway\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom scipy.stats import chi2_contingency, ttest_ind\nimport pickle\nfrom lightgbm import LGBMClassifier as lgbm\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA","a9bc83f6":"ss_lst = [\"Age\", \"Working_Hours\", \"Investment\", \"Loan\", \"City\", \"Income\"]","45b16383":"ss = StandardScaler()\nss.fit(df_train2[ss_lst])","a1c9e702":"df_train3 = df_train2.copy()\ndf_test2 = df_test1.copy()","6af302f2":"df_train3[ss_lst] = ss.transform(df_train2[ss_lst])\ndf_test2[ss_lst] = ss.transform(df_test1[ss_lst])","bb0fdfaf":"X = df_train3.drop(\"Answer\", axis=1)\ny = df_train3[\"Answer\"]","9b8007f7":"X.shape","4f9f5096":"X_train, X_div, y_train, y_div = train_test_split(X, y, test_size=0.15, stratify=y)","cf4a9dd0":"model1 = CatBoostClassifier(iterations=800, learning_rate=0.01, max_depth=8, objective=\"Logloss\", silent=True, \n                            auto_class_weights=\"Balanced\")\nmodel1.fit(X_train, y_train)\nprint(result(model1, X_div, y_div))","fed6657c":"cross_val = RepeatedStratifiedKFold()\nscore = cross_validate(estimator=model1, X=X_train, y=y_train, scoring=\"roc_auc\", \n                       cv=cross_val, n_jobs=-1, return_estimator=True)\nscore","78771577":"model2 = score[\"estimator\"][np.argmax(score[\"test_score\"])]\nprint(result(model2, X_div, y_div))","36b01b0e":"pred = model1.predict_proba(df_test2)","407f9ad3":"df_send = pd.DataFrame({\"Id\":df_test1.index, \"Answer\":pred[:, 1]})\ndf_send.head()","2ee96b3f":"df_send.to_csv(\"predict5.csv\", index=False)","9e3b0be7":"<ul>\n    <li>More Education_duration more happy  <b>#LifeLongLearning<\/b><\/li>\n    <li>More No. of Siblings More Happy<\/li>\n    <li>Those who have 1 or 6 Dependent, they are more Happy<\/li>\n    <li>Yearly Breaks is not Important Feature<\/li>\n<\/ul>","57903dc3":"In training set ---> Housing, Working_Hours, Marital_Status, Employer_Kind <br>\nIn test set ---> Housing, Working_Hours, Marital_Status, Employer_Kind <br>\nColumns are null","d16334ed":"# Importing Data","4e5b584e":"## Removing Null Value","ea98bdd4":"# **EDA**","d49e2bd3":"### Categorical Feature","03903d8f":"# **Feature Transformation**","94e786fa":"## Modify Object Feature","ee898476":"Answer is imbalance","5b83d83c":"## Univariate Analysis","1c3705c7":"### Conti-Conti Feature","32729334":"<ul>\n    <li>Female are more happy than Male<\/li>\n    <li>Single Person are more happy<\/li>\n    <li>Those who have no loan or paid there loan are more happy<\/li>\n    <li>Housing and Employer_kind are not Important Features<\/li>\n<\/ul>","490d7113":"## Bivariate Analysis","c9db15eb":"## Preprocessing","122da4a3":"## Removing Outliers","28056590":"# **Model Building**","c7983755":"### Numerical Feature","926e52d5":"### Cat-Cat Feature","bf85ad8c":"### Conti-Cat Feature","cdd44b80":"Income and Debt_paid are not important feature","16f1111e":"Investment, loan, city, income are skewed data","d669cf58":"# **Imp Function**","44dcd767":"## ML Algo"}}