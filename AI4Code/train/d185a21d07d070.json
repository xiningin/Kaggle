{"cell_type":{"570f1b6b":"code","e611e396":"code","cac26d8c":"code","6fe16188":"code","d07a077f":"code","85c76fe3":"code","ae7aa1c2":"code","7a1f131e":"code","07d51374":"code","22112713":"code","632940cd":"code","b51bbc4a":"code","77f68ef2":"code","39077304":"markdown","01a6252f":"markdown","bc3a36d5":"markdown","79de9c36":"markdown","8f7443d6":"markdown","03b3e4a4":"markdown","ab594e50":"markdown","8081a4c6":"markdown","a7e77b15":"markdown","ff7250ef":"markdown"},"source":{"570f1b6b":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","e611e396":"from fastai.vision import *\nfrom fastai.vision.gan import *","cac26d8c":"path = Path('..\/input\/abstract-art-gallery\/Abstract_gallery')","6fe16188":"def get_data(bs, size):\n    return (GANItemList.from_folder(path, noise_sz=100)\n               .split_none()\n               .label_from_func(noop)\n               .transform(tfms=[[crop_pad(size=size, row_pct=(0,1), col_pct=(0,1))], []], size=size, tfm_y=True)\n               .databunch(bs=bs)\n               .normalize(stats = [torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5])], do_x=False, do_y=True))","d07a077f":"data = get_data(128, 64)","85c76fe3":"data.show_batch(rows=3)","ae7aa1c2":"generator = basic_generator(in_size=64, n_channels=3, n_extra_layers=1)\ncritic = basic_critic(in_size=64, n_channels=3, n_extra_layers=1)","7a1f131e":"# weight decay set to 0 since there's not really a concept of 'overfitting' here when the input is noise\nwd = 0.\n\nlearn = GANLearner.wgan(data, generator, critic, switch_eval=False,\n                        opt_func = partial(optim.Adam, betas = (0.,0.99)), wd=wd)","07d51374":"learn.model_dir = '\/kaggle\/working'","22112713":"learn.fit(40, 5e-3)","632940cd":"learn.gan_trainer.switch(gen_mode=True)\nlearn.show_results(ds_type=DatasetType.Train, rows=4, figsize=(32,32))","b51bbc4a":"learn.model_dir = '\/kaggle\/working'\nlearn.save('abstract-art-gallery-wgan')","77f68ef2":"# learn.export('\/kaggle\/working\/wgan')","39077304":"# Exploratory: GAN for generating abtract art images v0\n","01a6252f":"We then grab images in the folder with the data block API. The training set will consist of a noise vector of size 100 and images from the abstract-art-gallery directory will be used as validation. The latter will receive transformations like cropping and resizing.\n\nLet's see what we're working with:","bc3a36d5":"This ipy notebook uses the FastAI library (built on Pytorch) to generate abstract art images. It uses a Wasserstein-GAN (wgan in FastAI) where the generator takes in random noise as input and attempts to produce images like the ones from a Kaggle dataset compiled by user 'BryanB' \u2013 i.e. no image input required. \n\nHere are some examples...\n\n**Earlier Epochs of training**\n![Prediction Results](https:\/\/user-images.githubusercontent.com\/45775098\/89133842-573d1e80-d4d4-11ea-9a29-928c94f8cee4.png)\n\n**Later Epochs of training**\n![Prediction Results](https:\/\/user-images.githubusercontent.com\/45775098\/89133864-881d5380-d4d4-11ea-9d19-f3c6297037ff.png)\n","79de9c36":"Kaggle's input directory is read-only. Switching model directory to the `working` folder","8f7443d6":"Clearly, the model is overlaying some patterns on top of the input that is more or less similar across most predictions. It does vary some texture, seemingly in relation to the composition of the actual image. But overall, the choice of arranging the component colors into vertical panes heavily influenced the images that the generator was able to produce.\n\n**Potential future exercise: use a less constraining method of generating input images for the UNet to use (bilinear interpolation?).**","03b3e4a4":"## Abstract art gallery data","ab594e50":"Momentum should be set to 0 for GANLearners,as it would adversely affect training when we switch between Generator and Critic","8081a4c6":"Here, we'll use the [Wassertein GAN](https:\/\/arxiv.org\/pdf\/1701.07875.pdf). A generator and a critic are created and passed to `gan_learner`.","a7e77b15":"NOTE: [AvgFlatten function](https:\/\/github.com\/fastai\/fastai\/blob\/6f3fec2efaa22c67ad2aabba2ecd09814e448842\/fastai\/vision\/gan.py) in the in the critic can't be pickled ... try defining a custom critic instead?\n","ff7250ef":"## Initialize a generator and critic for the WGAN"}}