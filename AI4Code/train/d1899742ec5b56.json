{"cell_type":{"54e92ee8":"code","159d5e8b":"code","741744de":"code","90d8e107":"code","7e8438d4":"code","18990602":"code","73eeb2c4":"code","fa339fb7":"code","8e9b2e77":"code","b726e8dd":"code","6d735567":"code","081131dd":"code","7f3725af":"code","d870ee11":"code","0ed8e826":"code","bd9d5521":"code","7745d087":"code","5d0b2775":"code","111ab7b1":"code","5f4b9a49":"code","147f61f8":"markdown","a96efd2f":"markdown","bed6926b":"markdown","bcc23543":"markdown","b9d0d4c0":"markdown","bc60d668":"markdown","5249f000":"markdown","635f16bd":"markdown","4e758946":"markdown","f50bf374":"markdown","0c88875a":"markdown","b65a22a3":"markdown","0976a09e":"markdown","9359faaa":"markdown","3a83630b":"markdown","36a1baaa":"markdown","1e353f5a":"markdown"},"source":{"54e92ee8":"import pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report \nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.svm import SVC","159d5e8b":"# Read csv file into dataframe\ndf = pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\n\nY = df['DEATH_EVENT']\nX = df[['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']]\nX.head()","741744de":"import seaborn as sns\n\n# Heatmap to Invertigate Correlation in Data\nsns.set()\nfig, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(df.corr(), linewidths=.5, ax=ax, cmap='Blues')\nplt.show()","90d8e107":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, test_size=0.2, random_state=52)\n\nprint('Shape of X_train:', X_train.shape)\nprint('Shape of X_test:', X_test.shape)\nprint('Shape of Y_train:', Y_train.shape)\nprint('Shape of Y_test:', Y_test.shape)","7e8438d4":"# Changing the kernel function\n\nkernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]","18990602":"report_listt = []\n\ni = 1\nfor k in kernels:\n    print(\"Model\",i,\"with Kernel =\", k)\n    i = i + 1\n    model = SVC(kernel= k, C = .01)\n    model.fit(X_train, Y_train)\n\n    Y_predict = model.predict(X_test)\n    \n    report = classification_report(Y_test, Y_predict, output_dict=True)\n    report_listt.append(report)\n    \n    print(classification_report(Y_test, Y_predict))","73eeb2c4":"import matplotlib.pyplot as plt\n\ny_prec = []\ny_rec = []\n\nfor i in range(len(kernels)):\n    y_prec.append(report_listt[i]['macro avg']['precision'])\n    y_rec.append(report_listt[i]['macro avg']['recall'])\n    \nfor i in range(len(kernels)):\n    print(\"Kernel -\",kernels[i],\" :: Avg Accuracy -\", y_prec[i])\n    \n# creating the bar plot \nplt.plot(kernels, y_prec)\nplt.title(\"Kernales) vs Average Precision\")\nplt.xlabel(\"Kernels\")\nplt.ylabel(\"Average Precision\")\nplt.show()","fa339fb7":"# Change values of c to identify the best model.\n\nclistt = [10, 1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.01, 0.001]\n\nreport_listt = []\n\ni = 1\nfor c in clistt:\n    print(\"Model\",i,\"with C =\", c)\n    i = i + 1\n    model = SVC(kernel='linear', C = c)\n    model.fit(X_train, Y_train)\n\n    Y_predict = model.predict(X_test)\n    \n    report = classification_report(Y_test, Y_predict, output_dict=True)\n    report_listt.append(report)\n    \n    print(classification_report(Y_test, Y_predict))\n    ","8e9b2e77":"import matplotlib.pyplot as plt\n\ny_prec = []\n\nfor i in range(len(report_listt)):\n    y_prec.append(report_listt[i]['macro avg']['precision'])\n    \nfor i in range(len(clistt)):\n    print(\"C(Regularization parameter) -\",clistt[i],\" :: Avg Accuracy -\", y_prec[i])\n","b726e8dd":"# creating the line plot \nplt.plot(clistt, y_prec)\nplt.title(\"C(Regularization parameter) vs Average Precision\")\nplt.xlabel(\"C(Regularization parameter)\")\nplt.ylabel(\"Average Precision\")\nplt.show()","6d735567":"# Change values of gamma to identify the best model.\n\nglistt = [1, 0.1, 0.01, 0.001, 0.0001]\n\nreport_listt = []\n\ni = 1\nfor g in glistt:\n    print(\"Model\",i,\"with gamma =\", g)\n    i = i + 1\n    model = SVC(kernel='linear', gamma = g)\n    model.fit(X_train, Y_train)\n\n    Y_predict = model.predict(X_test)\n    \n    report = classification_report(Y_test, Y_predict, output_dict=True)\n    report_listt.append(report)\n    \n    print(classification_report(Y_test, Y_predict))","081131dd":"import matplotlib.pyplot as plt\n\ny_prec = []\n\nfor i in range(len(report_listt)):\n    y_prec.append(report_listt[i]['macro avg']['precision'])\n    \nfor i in range(len(glistt)):\n    print(\"Gamma (Kernel coefficient) -\",glistt[i],\" :: Avg Accuracy -\", y_prec[i])","7f3725af":"# creating the bar plot \nplt.plot(glistt, y_prec)\nplt.title(\"Gamma (Kernel coefficient) vs Average Precision.\")\nplt.xlabel(\"Gamma (Kernel coefficient)\")\nplt.ylabel(\"Average Precision\")\nplt.show()","d870ee11":"# Best model is for  C  =  0.01\n\nmodel = SVC(kernel='linear', C = .01)\nmodel.fit(X_train, Y_train)\n\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(4,4), \n                                title='Confusion Matrix: SVM',\n                                normalize=True,\n                                cmap='Blues')","0ed8e826":"print(classification_report(Y_test, Y_predict))","bd9d5521":"from sklearn.model_selection import GridSearchCV \n  \n# defining parameter range \nparam_grid = {'C': [0.1, 1, 10, 100, 1000],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['rbf']}  \n  \ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n  \n# fitting the model for grid search \ngrid.fit(X_train, Y_train)","7745d087":"# print best parameter after tuning \nprint(grid.best_params_) \n  \n# print how our model looks after hyper-parameter tuning \nprint(grid.best_estimator_)","5d0b2775":"model = SVC(kernel='linear', C = 1, gamma = 0.001)\nmodel.fit(X_train, Y_train)\n\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(6,6), \n                                    title='Confusion Matrix: SVM',\n                                    normalize=True,\n                                    cmap='Blues')\n\nplt.show()","111ab7b1":"report = classification_report(Y_test, Y_predict)\nprint(report)","5f4b9a49":"# Best model using Manual Apprach\n\nmodel = SVC(kernel='linear', C = .01, gamma = 0.2)\nmodel.fit(X_train, Y_train)\n\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(4,4), \n                                title='Confusion Matrix: SVM',\n                                normalize=True,\n                                cmap='Blues')\n\nprint(classification_report(Y_test, Y_predict))","147f61f8":"## Best SVM using Grid Search","a96efd2f":"## Hyperparameter Tuning of C (Regularization parameter)","bed6926b":"Applying Gridsearch to find the best Model.","bcc23543":"## Final Model Confusion matrix and Classification Report - Manual","b9d0d4c0":"## Confusion Matrix and Classification Report of current best Model","bc60d668":"All gamma values gives the same precision as per above live chart","5249f000":"## Plot - C(Regularization parameter) vs Average Precision.","635f16bd":"## Feature Selection","4e758946":"## Heart Faliure Prediction using SVM(Support Vector Machine)","f50bf374":"## Plot - Gamma (Kernel coefficient) vs Average Precision.","0c88875a":"## Try different kernel tuning mecahnisms","b65a22a3":"Athul Mathew Konoor - 20016  M-Tech AI and DS 19AI613 Machine Learning Lab Evaluation- Hyper Parameter Tuning.","0976a09e":"Approach (Manual):\n    1. Find suitable kernal.   Output = linear.\n    2. Find suitabel C(Regularization parameter).  Output = 0.01\n    3. Find suitable Gamma (Kernel coefficient).  Output = 0.2\n    4. Average Accuracy of best Model.    Output = 0.85\n  \nApproach (Automatic - Using GridSearch):\n    1. Find suitable kernal.   Output = rbf.\n    2. Find suitabel C(Regularization parameter).  Output = 1\n    3. Find suitable Gamma (Kernel coefficient).  Ouput = 0.001\n    4. Average Accuracy of best Model.    Output = 0.78","9359faaa":"## Conclusion","3a83630b":"## Hyperparameter Tuning of Gamma (Kernel coefficient)","36a1baaa":"Only Linear kernel provides good accuracy. We now have Regualarisation and Gamma parameter to tune.","1e353f5a":"## Apply Grid search feature in sklearn to find best hyperparamenters(C, gamma)."}}