{"cell_type":{"ff56425f":"code","9d98ba1f":"code","e9fa220b":"code","ebae06f4":"code","e1a0c540":"code","ed021c7c":"code","d54291fe":"code","53e3b8d5":"code","331f28b7":"code","4fa2e8ec":"code","419ef379":"code","30015cbd":"code","87b10b4e":"code","8d0e0f07":"code","ccadb389":"code","659a2c1f":"code","c3c739f0":"code","9d080515":"code","caac4d3a":"code","1ddaef03":"code","9b6ac5db":"code","e6521eaf":"code","345f0a48":"code","31859f77":"code","47158bd9":"code","649b41b1":"code","deda56a2":"code","458d9e47":"code","4d51341d":"code","054b54d7":"code","26f381e0":"markdown","bbaeeedc":"markdown","0182b270":"markdown","eab4500e":"markdown","233e09f3":"markdown","866cbeb5":"markdown","a4b2d70f":"markdown","cfbc3fe4":"markdown","90738a4d":"markdown","24e13189":"markdown","6ac61988":"markdown","3e6b81b4":"markdown","a1b5f2c8":"markdown","c6d877da":"markdown"},"source":{"ff56425f":"BASE_MODEL='DenseNet121' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\nDISEASE_TAGS='Pneumonia' # ['Pneumonia', 'Pneumonia,Infiltration', 'Atelectasis,Pneumonia,Infiltration']\nTEST_DISEASE_TAGS='Pneumonia'\nIMG_SIZE = (224, 224) # [(224, 224), (384, 384), (512, 512), (640, 640)]\nBATCH_SIZE = 24 # [1, 8, 16, 24]\nDENSE_COUNT = 128 # [32, 64, 128, 256]\nDROPOUT = 0.5 # [0, 0.25, 0.5]\nLEARN_RATE = 1e-4 # [1e-4, 1e-3, 4e-3]\nTRAIN_SAMPLES = 6000 # [2000, 4000, 6000]\nTEST_SAMPLES = 600\nUSE_ATTN = False # [True, False]","9d98ba1f":"%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom glob import glob \nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom skimage.util.montage import montage2d\nfrom skimage.io import imread\nfrom tqdm import tqdm\nbase_dir = os.path.join('..', 'input') # 'pulmonary-chest-xray-abnormalities'\nall_xray_df = pd.read_csv(os.path.join(base_dir, 'Data_Entry_2017.csv'))\nwith open(os.path.join(base_dir, 'test_list.txt'), 'r') as f:\n    validated_files = [x.strip() for x in f.readlines()]\nall_xray_df['validated'] = all_xray_df['Image Index'].isin(validated_files)\nall_xray_df.sample(5)","e9fa220b":"all_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input',  'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['Pneumonia-like'] = all_xray_df['Finding Labels'].map(lambda x: any([c_label.upper() in x.upper() \n                                                                                 for c_label in DISEASE_TAGS.split(',')]))\nall_xray_df['Patient Age'] = np.clip(all_xray_df['Patient Age'], 5, 100)\nall_xray_df.sample(3)","ebae06f4":"all_xray_df[['Patient Age', 'Patient Gender', 'Pneumonia-like']].hist(figsize = (10, 5))","e1a0c540":"positive_cases = np.sum(all_xray_df.query('not validated')['Pneumonia-like']==True)\/\/2\noversample_factor = 4 # maximum number of cases in negative group so it isn't super rare\nmore_balanced_df = all_xray_df.query('not validated').groupby(['Patient Gender', 'Pneumonia-like']).apply(lambda x: x.sample(min(oversample_factor*positive_cases, x.shape[0]), \n                                                                                   replace = False)\n                                                      ).reset_index(drop = True)\n\nprint(more_balanced_df['Pneumonia-like'].value_counts())\nmore_balanced_df[['Patient Age', 'Pneumonia-like']].hist(figsize = (10, 5))","ed021c7c":"from sklearn.model_selection import train_test_split\nraw_train_df, valid_df = train_test_split(more_balanced_df, \n                                   test_size = 0.30, \n                                   random_state = 2018,\n                                   stratify = more_balanced_df[['Pneumonia-like', 'Patient Gender']])\n\ntest_df = all_xray_df.query('validated').copy()\ntest_df['Pneumonia-like'] = test_df['Finding Labels'].map(lambda x: any([c_label.upper() in x.upper()\n                                                                         for c_label in TEST_DISEASE_TAGS.split(',')]))\n                                       \ntest_df = test_df.groupby('Pneumonia-like').apply(lambda x:\n                                                 x.sample(min(x.shape[0],\n                                                             1400))).reset_index(drop=True)                                                                                \nprint('train', raw_train_df.shape[0], 'validation', valid_df.shape[0], 'test', test_df.shape[0])\nprint('train', raw_train_df['Pneumonia-like'].value_counts())\nprint('test', test_df['Pneumonia-like'].value_counts())\nraw_train_df.sample(1)","d54291fe":"train_df = raw_train_df.groupby(['Pneumonia-like']).apply(lambda x: x.sample(TRAIN_SAMPLES\/\/2, replace = True)\n                                                      ).reset_index(drop = True)\nprint('New Data Size:', train_df.shape[0], 'Old Size:', raw_train_df.shape[0])\ntrain_df[['Pneumonia-like', 'Patient Age']].hist(figsize = (10, 5))","53e3b8d5":"from keras.preprocessing.image import ImageDataGenerator\nif BASE_MODEL=='VGG16':\n    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\nelif BASE_MODEL=='RESNET52':\n    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\nelif BASE_MODEL=='InceptionV3':\n    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\nelif BASE_MODEL=='Xception':\n    from keras.applications.xception import Xception as PTModel, preprocess_input\nelif BASE_MODEL=='DenseNet169': \n    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\nelif BASE_MODEL=='DenseNet121':\n    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\nelse:\n    raise ValueError('Unknown model: {}'.format(BASE_MODEL))\n    \ncore_idg = ImageDataGenerator(samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip=False, \n                              vertical_flip=False, \n                              height_shift_range=0.1, \n                              width_shift_range=0.1, \n                              rotation_range=3, \n                              shear_range=0.01,\n                              brightness_range = [0.9, 1.1],\n                              fill_mode='nearest',\n                              zoom_range=0.125,\n                             preprocessing_function=preprocess_input)","331f28b7":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","4fa2e8ec":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia-like', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = BATCH_SIZE)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia-like', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia-like', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = TEST_SAMPLES)) # one big batch\n# used a fixed dataset for final evaluation\nfinal_test_X, final_test_Y = next(flow_from_dataframe(core_idg, \n                               test_df, \n                             path_col = 'path',\n                            y_col = 'Pneumonia-like', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = TEST_SAMPLES)) # one big batch","419ef379":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('%s' % ('Pneumonia' if c_y>0.5 else 'Healthy'))\n    c_ax.axis('off')","30015cbd":"base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n                              include_top = False, weights = 'imagenet')\nbase_pretrained_model.trainable = False","87b10b4e":"from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\npt_features = Input(base_pretrained_model.get_output_shape_at(0)[1:], name = 'feature_input')\npt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\nfrom keras.layers import BatchNormalization\nbn_features = BatchNormalization()(pt_features)\n# here we do an attention mechanism to turn pixels in the GAP on an off\nattn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'elu')(bn_features)\nattn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\nattn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer) # smooth results\nattn_layer = Conv2D(1, \n                    kernel_size = (1,1), \n                    padding = 'valid', \n                    activation = 'sigmoid')(attn_layer)\n# fan it out to all of the channels\nup_c2_w = np.ones((1, 1, 1, pt_depth))\nup_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n               activation = 'linear', use_bias = False, weights = [up_c2_w])\nup_c2.trainable = False\nattn_layer = up_c2(attn_layer)\nif USE_ATTN:\n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]\/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\nelse:\n    gap = GlobalAveragePooling2D()(bn_features)\n\ngap_dr = Dropout(DROPOUT)(gap)\ndr_steps = Dropout(DROPOUT)(Dense(DENSE_COUNT, activation = 'elu')(gap_dr))\nout_layer = Dense(1, activation = 'sigmoid')(dr_steps)\n\nattn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\n\nattn_model.compile(optimizer = Adam(lr=LEARN_RATE), loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\n\nattn_model.summary()","8d0e0f07":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cardio_attn')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=10) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","ccadb389":"from keras.models import Sequential\nfrom keras.optimizers import Adam\ntb_model = Sequential(name = 'combined_model')\nbase_pretrained_model.trainable = False\ntb_model.add(base_pretrained_model)\ntb_model.add(attn_model)\ntb_model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\ntb_model.summary()","659a2c1f":"train_gen.batch_size = BATCH_SIZE\ntb_model.fit_generator(train_gen, \n                      validation_data = (test_X, test_Y), \n                      epochs = 30, \n                      callbacks = callbacks_list,\n                      workers = 3)","c3c739f0":"tb_model.load_weights(weight_path)","9d080515":"!rm -rf ~\/.keras # clean up the model \/ make space for other things","caac4d3a":"# get the attention layer since it is the only one with a single output dim\nfor attn_layer in attn_model.layers:\n    c_shape = attn_layer.get_output_shape_at(0)\n    if len(c_shape)==4:\n        if c_shape[-1]==1:\n            print(attn_layer)\n            break","1ddaef03":"import keras.backend as K\nif USE_ATTN:\n    rand_idx = np.random.choice(range(len(test_X)), size = 6)\n    attn_func = K.function(inputs = [attn_model.get_input_at(0), K.learning_phase()],\n               outputs = [attn_layer.get_output_at(0)]\n              )\n    fig, m_axs = plt.subplots(len(rand_idx), 2, figsize = (8, 4*len(rand_idx)))\n    [c_ax.axis('off') for c_ax in m_axs.flatten()]\n    for c_idx, (img_ax, attn_ax) in zip(rand_idx, m_axs):\n        cur_img = test_X[c_idx:(c_idx+1)]\n        cur_features = base_pretrained_model.predict(cur_img)\n        attn_img = attn_func([cur_features, 0])[0]\n        img_ax.imshow(cur_img[0,:,:,0], cmap = 'bone')\n        attn_ax.imshow(attn_img[0, :, :, 0], cmap = 'viridis', \n                       vmin = 0, vmax = 1, \n                       interpolation = 'lanczos')\n        real_label = test_Y[c_idx]\n        img_ax.set_title('Pneumonia\\nClass:%s' % (real_label))\n        pred_confidence = tb_model.predict(cur_img)[0]\n        attn_ax.set_title('Attention Map\\nPred:%2.1f%%' % (100*pred_confidence[0]))\n    fig.savefig('attention_map.png', dpi = 300)","9b6ac5db":"pred_Y = tb_model.predict(test_X, \n                          batch_size = BATCH_SIZE, \n                          verbose = True)","e6521eaf":"from sklearn.metrics import classification_report, confusion_matrix\nplt.matshow(confusion_matrix(test_Y, pred_Y>0.5))\nprint(classification_report(test_Y, pred_Y>0.5, target_names = ['Healthy', 'Cardiomegaly']))","345f0a48":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(test_Y, pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'VGG-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc_valid.pdf')","31859f77":"final_pred_Y = tb_model.predict(final_test_X, \n                                verbose = True, \n                                batch_size = BATCH_SIZE)","47158bd9":"plt.matshow(confusion_matrix(final_test_Y, final_pred_Y>0.5))\nprint(classification_report(final_test_Y, final_pred_Y>0.5, target_names = ['Healthy', 'Cardiomegaly']))","649b41b1":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(final_test_Y, final_pred_Y)\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'VGG-Model (AUC:%2.2f)' % roc_auc_score(test_Y, pred_Y))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nfig.savefig('roc_test.pdf')","deda56a2":"tb_model.save('full_pred_model.h5')","458d9e47":"train_results = tb_model.evaluate_generator(train_gen, steps=50)\nvalid_results = tb_model.evaluate(test_X, test_Y, \n                                  batch_size = BATCH_SIZE)\ntest_results = tb_model.evaluate(final_test_X, final_test_Y, \n                                 batch_size = BATCH_SIZE)","4d51341d":"out_res_df = pd.DataFrame([\n    dict(zip(tb_model.metrics_names, train_results), split='train'),\n    dict(zip(tb_model.metrics_names, valid_results), split='valid'),\n    dict(zip(tb_model.metrics_names, test_results), split='test'),\n])\nout_res_df.to_csv('results.csv', index = False)\nout_res_df","054b54d7":"if USE_ATTN:\n    img_in = Input(t_x.shape[1:])\n    feat_lay = base_pretrained_model(img_in)\n    just_attn = Model(inputs = attn_model.get_input_at(0), \n          outputs = [attn_layer.get_output_at(0)], name = 'pure_attention')\n    attn_img = just_attn(feat_lay)\n    pure_attn_model = Model(inputs = [img_in], outputs = [attn_img], name = 'just_attention_model')\n    pure_attn_model.save('pure_attn_model.h5')\n    pure_attn_model.summary()","26f381e0":"# Model Setup\nHere we setup the hyperparmeters for the model so we can re-run it with different settings. The comment afterwards should be a python parseable list of options to run for that value","bbaeeedc":"# Split Data into Training and Validation","0182b270":"# Show Attention\nDid our attention model learn anything useful?","eab4500e":"# Test Results\nThe results on the hold-out data which hasn't been touched yet","233e09f3":"# Attention Model\nThe basic idea is that a Global Average Pooling is too simplistic since some of the regions are more relevant than others. So we build an attention mechanism to turn pixels in the GAP on an off before the pooling and then rescale (Lambda layer) the results based on the number of pixels. The model could be seen as a sort of 'global weighted average' pooling. There is probably something published about it and it is very similar to the kind of attention models used in NLP.\nIt is largely based on the insight that the winning solution annotated and trained a UNET model to segmenting the hand and transforming it. This seems very tedious if we could just learn attention.","866cbeb5":"# Examine the distributions\nShow how the data is distributed and why we need to balance it","a4b2d70f":"# Export the Attention Model\nWe can run the attention model in addition to the classification to produce attention maps for the image. Here we just package the relevant inputs and outputs together","cfbc3fe4":"# Pretrained Features\nHere we generate the pretrained features for a large batch of images to accelerate the training process","90738a4d":"# Build the whole model\nWe build the whole model and fine-tune the results (much lower learning rate)","24e13189":"## Preprocessing\nOrganize the files by cases with and without pneumonia (or something like ","6ac61988":"## Export Results\nHere we export the results for model comparison if we do any hyperparameter tweaking","3e6b81b4":"# Overview\nThe notebook tries to classify pneumonia from chest x-rays. I picked this specific task because it is one that as a non-physician seemed tractable (does that patient have a big heart). It also seemed like a good test for attention mechanisms because while there might be indications of a big heart in your shoulder, probably almost all of the attention should be focused on the heart region. Any time the focus isn't there, we should be suspicious. \n\nThe model uses transfer learning by taking the first layers of a VGG16 model trained on ImageNet data (classifying color images of dogs, airplanes, cats, ...) and retrains it on grayscale images of chests. To make the model a bit smarter we add an attention mechanism (described in more detail below) to mask out the most useful values for the classification. This should help the model learn to avoid or be too distracted by shoulders, bones, lungs, and so forth. \n\nWe resample the data for training (unbalanced problems are harder to train) and for testing \/ validation (since pneumonia is rare enough that only having a few cases makes it difficult to know how well the detector is working. This, however, is not a good approximation of a real clinical environment where it remains a rare condition. The model is thus better suited for informative or additional information and not at all well suited for a screening-style use.","a1b5f2c8":"> # Evaluate the validation results\nHere we evaluate the results by loading the best version of the model and seeing how the predictions look on the results. We use the validation data which was not directly trained on but still *tainted* since it was used as a stopping criteria","c6d877da":"# Balance the distribution in the training set"}}