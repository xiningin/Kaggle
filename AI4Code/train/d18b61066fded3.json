{"cell_type":{"7ba557dd":"code","4344fc08":"code","905aa710":"code","50895547":"code","c149bf9c":"code","7c1aa059":"code","b88d2023":"code","84f76699":"code","327abc86":"code","d41d7fd6":"code","44e3868d":"code","d7d8a4f7":"code","cceb6430":"code","4d2f57b2":"code","a2abc431":"code","d9bef50c":"code","a6a37aaa":"code","c8592829":"code","19ae7265":"code","1a19657f":"code","ce633e16":"markdown","e79c502b":"markdown","d17a8166":"markdown","d2e8f1b4":"markdown","ea6c02f4":"markdown","b4fc4cfd":"markdown"},"source":{"7ba557dd":"# Imports\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom fastai.structured import *\nfrom fastai.column_data import *\nnp.set_printoptions(threshold=50, edgeitems=20)\nfrom IPython.display import HTML, display\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\nfrom sklearn.model_selection import StratifiedKFold","4344fc08":"# Load the csv\nPATH = '..\/input\/'\ntrain_df = pd.read_csv(PATH+'train.csv')\ntest_df = pd.read_csv(PATH+'test.csv')","905aa710":"test_df.shape","50895547":"# Classify our labels:\ncat_vars = ['hacdor',\n            'hacapo',\n            'v14a',\n            'refrig',\n            'v18q',\n            'paredblolad',\n            'paredzocalo',\n            'paredpreb',\n            'pareddes',\n            'paredmad',\n            'paredzinc',\n            'paredfibras',\n            'paredother',\n            'pisomoscer',\n            'pisocemento',\n            'pisoother',\n            'pisonatur',\n            'pisonotiene',\n            'pisomadera',\n            'techozinc',\n            'techoentrepiso',\n            'techocane',\n            'techootro',\n            'cielorazo',\n            'abastaguadentro',\n            'abastaguafuera',\n            'abastaguano',\n            'public',\n            'planpri',\n            'noelec',\n            'coopele',\n            'sanitario1',\n            'sanitario2',\n            'sanitario3',\n            'sanitario5',\n            'sanitario6',\n            'energcocinar1',\n            'energcocinar2',\n            'energcocinar3',\n            'energcocinar4',\n            'elimbasu1',\n            'elimbasu2',\n            'elimbasu3',\n            'elimbasu4',\n            'elimbasu5',\n            'elimbasu6',\n            'epared1',\n            'epared2',\n            'epared3',\n            'etecho1',\n            'etecho2',\n            'etecho3',\n            'eviv1',\n            'eviv2',\n            'eviv3',\n            'dis',\n            'estadocivil1',\n            'estadocivil2',\n            'estadocivil3',\n            'estadocivil4',\n            'estadocivil5',\n            'estadocivil6',\n            'estadocivil7',\n            'parentesco1',\n            'parentesco2',\n            'parentesco3',\n            'parentesco4',\n            'parentesco5',\n            'parentesco6',\n            'parentesco7',\n            'parentesco8',\n            'parentesco9',\n            'parentesco10',\n            'parentesco11',\n            'parentesco12',\n            'dependency',\n            'edjefe',\n            'edjefa',\n            'instlevel1',\n            'instlevel2',\n            'instlevel3',\n            'instlevel4',\n            'instlevel5',\n            'instlevel6',\n            'instlevel7',\n            'instlevel8',\n            'instlevel9',\n            'tipovivi1',\n            'tipovivi2',\n            'tipovivi3',\n            'tipovivi4',\n            'tipovivi5',\n            'computer',\n            'television',\n            'mobilephone',\n            'lugar1',\n            'lugar2',\n            'lugar3',\n            'lugar4',\n            'lugar5',\n            'lugar6',\n            'area1',\n            'area2']\n\ncontin_vars = ['v2a1',\n               'rooms',\n               'v18q1',\n               'r4h1',\n               'r4h2',\n               'r4h3',\n               'r4m1',\n               'r4m2',\n               'r4m3',\n               'r4t1',\n               'r4t2',\n               'r4t3',\n               'tamhog',\n               'escolari',\n               'rez_esc',\n               'hhsize',\n               'male',\n               'female',\n               'hogar_nin',\n               'hogar_adul',\n               'hogar_mayor',\n               'hogar_total',\n               'meaneduc',\n               'bedrooms',\n               'overcrowding',\n               'qmobilephone',\n               'age',\n               'SQBescolari',\n               'SQBage',\n               'SQBhogar_total',\n               'SQBedjefe',\n               'SQBhogar_nin',\n               'SQBovercrowding',\n               'SQBdependency',\n               'SQBmeaned',\n               'agesq']\n\nobjective= ['Target']\n\nids = ['Id']","c149bf9c":"# Apply categorical type:\nfor v in cat_vars: train_df[v] = train_df[v].astype('category').cat.as_ordered()\n\napply_cats(test_df, train_df)","7c1aa059":"# Contin_vars as floats:\nfor v in contin_vars:\n    train_df[v] = train_df[v].fillna(0).astype('float32')\n    test_df[v] = test_df[v].fillna(0).astype('float32')","b88d2023":"# Create new features per individuals:\n# Credits to this notebook in R for the features:\n# https:\/\/www.kaggle.com\/taindow\/predicting-poverty-levels-with-r\nfor dataframe in (train_df, test_df):\n    dataframe['Rent_per_individual'] = dataframe['v2a1']\/dataframe['r4t3']\n    dataframe['Rent_per_child'] = dataframe['v2a1']\/dataframe['r4t1']\n    dataframe['Rent_per_over_65'] = dataframe['v2a1']\/dataframe['r4t3']\n    dataframe['Rent_per_room'] = dataframe['v2a1']\/dataframe['rooms']\n    dataframe['Rent_per_bedrooms'] = dataframe['v2a1']\/dataframe['bedrooms']\n    dataframe['Proportion_under_12'] = dataframe['r4t1']\/dataframe['r4t3']\n    dataframe['Proportion_under_12_male'] = dataframe['r4h1']\/dataframe['r4t3']\n    dataframe['Proportion_under_12_female'] = dataframe['r4m1']\/dataframe['r4t3']\n    dataframe['Proportion_male'] = dataframe['r4h3']\/dataframe['r4t3']\n    dataframe['Proportion_female'] = dataframe['r4m3']\/dataframe['r4t3']\n    dataframe['Rooms_per_individual'] = dataframe['rooms']\/dataframe['r4t3']\n    dataframe['Rooms_per_child'] = dataframe['rooms']\/dataframe['r4t1']\n    dataframe['Tablets_per_individual'] = dataframe['v18q1']\/dataframe['r4t3']\n    dataframe['Tablets_per_child'] = dataframe['v18q1']\/dataframe['r4t1']\n    dataframe['Years_schooling_per_individual'] = dataframe['escolari']\/dataframe['r4t3']\n    dataframe['Years_schooling_per_adult'] = dataframe['escolari']\/(dataframe['r4t3']-dataframe['r4t1'])\n    dataframe['Years_schooling_per_child'] = dataframe['escolari']\/dataframe['r4t1']\n    dataframe['Proportion_under_19'] = dataframe['hogar_nin']\/dataframe['r4t3']\n    dataframe['Proportion_over_19'] = dataframe['hogar_adul']\/dataframe['r4t3']\n    dataframe['Proportion_under_65'] = (dataframe['hogar_total']-dataframe['hogar_mayor'])\/dataframe['r4t3']\n    dataframe['Proportion_over_65'] = dataframe['hogar_mayor']\/dataframe['r4t3']\n    dataframe['Bedrooms_per_individual'] = dataframe['bedrooms']\/dataframe['r4t3']\n    dataframe['Bedrooms_per_child'] = dataframe['bedrooms']\/dataframe['r4t1']\n    dataframe['Bedrooms_per_over_65'] = dataframe['bedrooms']\/dataframe['r4t3']\n    dataframe['Extreme_conditions_flag'] = (dataframe['abastaguano'] & dataframe['noelec'] & dataframe['sanitario1'] & dataframe['energcocinar1'])\n    dataframe['bedrooms_to_rooms'] = dataframe['bedrooms']\/dataframe['rooms']\n    dataframe['tamhog_to_rooms'] = dataframe['tamhog']\/dataframe['rooms']\n    dataframe['tamhog_to_bedrooms'] = dataframe['tamhog']\/dataframe['bedrooms']\n    dataframe['r4t3_to_tamhog'] = dataframe['r4t3']\/dataframe['tamhog']\n    dataframe['hhsize_to_rooms'] = dataframe['hhsize']\/dataframe['rooms']\n    dataframe['hhsize_to_bedrooms'] = dataframe['hhsize']\/dataframe['bedrooms']\n    dataframe['rent_to_hhsize'] = dataframe['v2a1']\/dataframe['hhsize']\n    dataframe['qmobilephone_to_r4t3'] = dataframe['qmobilephone']\/dataframe['r4t3']\n    dataframe['qmobilephone_to_v18q1'] = dataframe['qmobilephone']\/dataframe['v18q1']","84f76699":"# Features per Household on the training set:\ngroupper = train_df.groupby('idhogar')\ninteractions = (pd.DataFrame(dict(\n                head_partner_escolari=train_df.parentesco2.astype(int) * train_df.escolari.astype(int)))\n                .groupby(train_df.idhogar)\n                .max())\nmy_features = (groupper.mean()[['escolari', 'age', 'male', 'meaneduc', 'SQBdependency']]\n                .join(groupper.std()[['escolari', 'age']], \n                      rsuffix='_std')\n                .join(groupper[['escolari', 'age']].min(), rsuffix=\"_min\")\n                .join(groupper[['escolari', 'age']].max(), rsuffix=\"_max\")\n                .join(groupper[['dis']].sum())\n                .join(interactions)\n                .join(groupper[['computer', 'television', 'qmobilephone', 'v18q1']].mean().sum(axis=1).rename('technics')))\nmy_features.rename(columns={'escolari': 'escolari_mean', 'age': 'age_mean', 'male': 'male_mean', 'dis': 'dis_sum', \n                            'meaneduc': 'meaneduc_mean', 'SQBdependency': 'SQBdependency_mean'}, inplace=True)\ntrain_df = train_df.merge(my_features, how='left', left_on='idhogar', right_on='idhogar')","327abc86":"# Features per Household on the testing set:\ngroupper = test_df.groupby('idhogar')\ninteractions = (pd.DataFrame(dict(\n                head_partner_escolari=test_df.parentesco2.astype(int) * test_df.escolari.astype(int)))\n                .groupby(test_df.idhogar)\n                .max())\nmy_features = (groupper.mean()[['escolari', 'age', 'male', 'meaneduc', 'SQBdependency']]\n                .join(groupper.std()[['escolari', 'age']], \n                      rsuffix='_std')\n                .join(groupper[['escolari', 'age']].min(), rsuffix=\"_min\")\n                .join(groupper[['escolari', 'age']].max(), rsuffix=\"_max\")\n                .join(groupper[['dis']].sum())\n                .join(interactions)\n                .join(groupper[['computer', 'television', 'qmobilephone', 'v18q1']].mean().sum(axis=1).rename('technics')))\nmy_features.rename(columns={'escolari': 'escolari_mean', 'age': 'age_mean', 'male': 'male_mean', 'dis': 'dis_sum',\n                            'meaneduc': 'meaneduc_mean', 'SQBdependency': 'SQBdependency_mean'}, inplace=True)\ntest_df = test_df.merge(my_features, how='left', left_on='idhogar', right_on='idhogar')","d41d7fd6":"list(train_df)","44e3868d":"train_df.drop('idhogar', axis=1, inplace=True)\ntest_df.drop('idhogar', axis=1, inplace=True)","d7d8a4f7":"new_features = ['Rent_per_individual',\n                'Rent_per_child',\n                'Rent_per_over_65',\n                'Rent_per_room',\n                'Rent_per_bedrooms',\n                'Proportion_under_12',\n                'Proportion_under_12_male',\n                'Proportion_under_12_female',\n                'Proportion_male',\n                'Proportion_female',\n                'Rooms_per_individual',\n                'Rooms_per_child',\n                'Tablets_per_individual',\n                'Tablets_per_child',\n                'Years_schooling_per_individual',\n                'Years_schooling_per_adult',\n                'Years_schooling_per_child',\n                'Proportion_under_19',\n                'Proportion_over_19',\n                'Proportion_under_65',\n                'Proportion_over_65',\n                'Bedrooms_per_individual',\n                'Bedrooms_per_child',\n                'Bedrooms_per_over_65',\n                'Extreme_conditions_flag',\n                'bedrooms_to_rooms',\n                'tamhog_to_rooms',\n                'tamhog_to_bedrooms',\n                'r4t3_to_tamhog',\n                'hhsize_to_rooms',\n                'hhsize_to_bedrooms',\n                'rent_to_hhsize',\n                'qmobilephone_to_r4t3',\n                'qmobilephone_to_v18q1',\n                'escolari_mean',\n                'age_mean',\n                'male_mean',\n                'meaneduc_mean',\n                'SQBdependency_mean',\n                'escolari_std',\n                'age_std',\n                'escolari_min',\n                'age_min',\n                'escolari_max',\n                'age_max',\n                'dis_sum',\n                'head_partner_escolari',\n                'technics']\n# Treat the new features as contin_vars:\nfor v in new_features:\n    train_df[v] = train_df[v].replace([np.inf, -np.inf], np.nan).fillna(0).astype('float32')\n    test_df[v] = test_df[v].replace([np.inf, -np.inf], np.nan).fillna(0).astype('float32')","cceb6430":"# Process the training data using the awesome fastai function proc_df:\ntrain_df = train_df.set_index('Id')\ntrain_df = train_df[cat_vars+contin_vars+new_features+objective]\n\ndf, y, nas, mapper = proc_df(train_df, 'Target', do_scale=True)","4d2f57b2":"# Process the testing data using the awesome fastai function proc_df:\ntest_df = test_df.set_index('Id')\n\n# Just a dummy column so that the column exists.\ntest_df['Target'] = 0\ntest_df = test_df[cat_vars+contin_vars+new_features+['Target']]\n\ndf_test, _, nas, mapper = proc_df(test_df, 'Target', do_scale=True,\n                                  mapper=mapper, na_dict=nas)","a2abc431":"# Create a K-fold instance\nk = 5\nkf = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)","d9bef50c":"# Train\/validate on 5 different training\/validation sets thanks to K-folds and predict on the testing set:\npredicts = []\ntest_X = np.array(df_test)\nfor train_index, test_index in kf.split(df, y):\n    print(\"###\")\n    X_train, X_val = np.array(df)[train_index], np.array(df)[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n    \n    xgb_params = {\n        'learning_rate': 0.1,\n        'n_estimators': 1000,\n        'objective': 'multi:softmax',\n        'eval_metric': 'merror',\n        'silent': 1,\n        'num_class': 5,\n        'seed': 27}\n    \n    d_train = xgb.DMatrix(X_train, y_train)\n    d_valid = xgb.DMatrix(X_val, y_val)\n    d_test = xgb.DMatrix(test_X)\n    \n    model = xgb.train(xgb_params, d_train, num_boost_round = 10000, evals=[(d_valid, 'eval')], verbose_eval=100, \n                     early_stopping_rounds=50)\n                        \n    xgb_pred = model.predict(d_test)\n    predicts.append(list(xgb_pred))","a6a37aaa":"# Average the 5 predictions sets:\npreds=[]\nfor i in range(len(predicts[0])):\n    sum=0\n    for j in range(k):\n        sum+=predicts[j][i]\n    preds.append(sum \/ k)","c8592829":"# Create the results datframe:\ndf_test['Target'] = np.array(preds).astype(int)\nsub = df_test[['Target']].copy()","19ae7265":"sub.reset_index(inplace=True, drop=False)\nsub.head()","1a19657f":"sub.to_csv('sample_submission.csv', index=False)","ce633e16":"## XGBB model using K-folds and fastai.\n\nUse fastai to prepare the dataset and use XGB 5 K-Folds for the model.\n","e79c502b":"### 2. Modeling","d17a8166":"### 1. Data processing","d2e8f1b4":"predicts = []\ntest_X = df_test\nfor train_index, test_index in kf.split(df, y):\n    print(\"###\")\n    X_train, X_val = df.iloc[train_index], df.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n            early_stopping_rounds=10)\n    feat_imp = pd.DataFrame(list(zip(list(X_train),clf.feature_importances_)), columns=('Name', 'Importance'))\n    feat_imp.sort_values('Importance', inplace=True)\n    \n    \n    predicts.append(clf.predict(test_X))\nprint(feat_imp.tail(10))","ea6c02f4":"### 0. Data Cleaning \/ Feature engineering","b4fc4cfd":"clf = lgb.LGBMClassifier(class_weight='balanced', boosting_type='dart',\n                         drop_rate=0.9, min_data_in_leaf=100, \n                         max_bin=255,\n                         n_estimators=500,\n                         bagging_fraction=0.01,\n                         min_sum_hessian_in_leaf=1,\n                         importance_type='gains',\n                         learning_rate=0.1, \n                         max_depth=-1, \n                         num_leaves=31)"}}