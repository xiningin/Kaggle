{"cell_type":{"b78ac0b2":"code","6f225165":"code","4ceddf84":"code","7efb809d":"code","2a18ad72":"code","5ba68ce3":"code","7f4465d7":"code","2ac767f4":"code","6e488a78":"code","5ceaed0c":"code","3a83f625":"code","540aebd2":"code","eafa21fd":"code","8938ba80":"code","e24c44e5":"code","649bf4c2":"code","b33b0f11":"code","6d652405":"code","a7e9a70a":"code","60ee5a17":"code","64a98500":"markdown","b0499b1f":"markdown","76edaba4":"markdown","dc5b4beb":"markdown","72b0d004":"markdown"},"source":{"b78ac0b2":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6f225165":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data","4ceddf84":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data","7efb809d":"or_test_data = test_data","2a18ad72":"train_data.columns","5ba68ce3":"train_data.isnull().sum()","7f4465d7":"train_data = train_data.drop(['Name', 'Ticket', 'PassengerId', 'Fare'], axis=1)\ntest_data = test_data.drop(['Name', 'Ticket', 'PassengerId', 'Fare'], axis=1)","2ac767f4":"train_data['relatives'] = train_data['SibSp'] + train_data['Parch']\ntest_data['relatives'] = test_data['SibSp'] + test_data['Parch']\n\ntrain_data = train_data.drop(['SibSp', 'Parch'], axis=1)\ntest_data = test_data.drop(['SibSp', 'Parch'], axis=1)","6e488a78":"str_columns = ['Sex', 'Cabin', 'Embarked']\nnum_columns = ['Pclass', 'Age', 'relatives']","5ceaed0c":"#\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0441\u043e \u0441\u0442\u0440\u043e\u043a\u043e\u0432\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u0432 \u0446\u0435\u043b\u044b\u0435 \u0447\u0438\u0441\u043b\u0430\ndef convert_to_str(data):\n    for col in data.columns:\n        if (data[col].dtype == np.int64 or data[col].dtype == np.float64):\n            data[col] = data[col].fillna(data[col].mean())\n        else:\n            data[col] = data[col].fillna(method='ffill')\n    return data","3a83f625":"train_data = convert_to_str(train_data)\ntest_data = convert_to_str(test_data)","540aebd2":"train_data['type'] = 'train'\ntest_data['type'] = 'test'\n\n# \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0444\u0438\u043a\u0442\u0438\u0432\u043d\u043e\u0433\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430 SalePrice, \u0447\u0442\u043e\u0431\u044b \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0431\u044b\u043b\u043e \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u043c. \ntest_data['Survived'] = train_data['Survived'].iloc[:418]\n\ndata = train_data.append(test_data, ignore_index=True)","eafa21fd":"for col in str_columns:\n    one_hot = pd.get_dummies(data[col])\n\n    replace_cols = {}\n    for one_col in one_hot.columns:\n        replace_cols[one_col] = f\"{col}_{one_col}\"\n    one_hot = one_hot.rename(columns=replace_cols)\n\n    data = data.drop(col, axis = 1)\n    data = data.join(one_hot)","8938ba80":"train_data = data[data['type'] == 'train']\ntest_data = data[data['type'] == 'test']\n\ntrain_data = train_data.drop(['type'], axis=1)\ntest_data = test_data.drop(['type'], axis=1)\n\ntest_data = test_data.reset_index(drop=True)","e24c44e5":"scaler = MinMaxScaler()\nscaler.fit(train_data[num_columns])","649bf4c2":"train_data[num_columns] = scaler.transform(train_data[num_columns])\ntest_data[num_columns] = scaler.transform(test_data[num_columns])\ntest_data = test_data.drop(['Survived'], axis=1)\ntrain_labels = train_data['Survived']\ntrain_df = train_data.drop(['Survived'], axis=1)","b33b0f11":"model = RandomForestClassifier()\nmodel.fit(train_df, train_labels)","6d652405":"predictions = model.predict(test_data)\ntest_data['Survived'] = predictions","a7e9a70a":"results = pd.DataFrame()\nresults['PassengerId'] = or_test_data['PassengerId']\nresults['Survived'] = test_data['Survived']\nresults","60ee5a17":"results.to_csv('submissions.csv', index=False)","64a98500":"### **\u041c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435**","b0499b1f":"### **\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0444\u0440\u0435\u0439\u043c\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432**","76edaba4":"##### **\u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445**","dc5b4beb":"### **\u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0441\u043e \u0441\u0442\u0440\u043e\u043a\u043e\u0432\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u0432 \u0446\u0435\u043b\u044b\u0435 \u0447\u0438\u0441\u043b\u0430**","72b0d004":"##### **\u041c\u043e\u0434\u0435\u043b\u044c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438**"}}