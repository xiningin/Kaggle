{"cell_type":{"4e6f0156":"code","d87d5589":"code","0cc05c1f":"code","96179071":"code","872d8d1d":"code","adf5c486":"code","b99e29fb":"code","44c82155":"code","6222d4e5":"code","ed8d8d39":"code","a451c213":"markdown","84f5d1fc":"markdown","bac771c5":"markdown","1916d34e":"markdown","0625bb44":"markdown","dffde0e9":"markdown","0081fff7":"markdown"},"source":{"4e6f0156":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d87d5589":"# from transformers import pipeline\n\n# # Using default model and tokenizer for the task\n# pipeline(\"<task-name>\")\n\n# # Using a user-specified model\n# pipeline(\"<task-name>\", model=\"<model_name>\")\n\n# # Using custom model\/tokenizer as str\n# pipeline('<task-name>', model='<model name>', tokenizer='<tokenizer_name>')","0cc05c1f":"tasks = ['feature-extraction', 'sentiment-analysis', 'ner', 'question-answering', 'fill-mask', 'summarization', 'translation_en_to_fr', 'translation_en_to_de', 'translation_en_to_ro', 'text-generation']\nprint(tasks)","96179071":"import transformers\nfrom transformers import pipeline\n","872d8d1d":"nlp_sentence_classif = pipeline('sentiment-analysis')\nnlp_sentence_classif('Such a nice weather outside !')","adf5c486":"\n\nnlp_token_class = pipeline('ner',tokenizer=transformers.PreTrainedTokenizer('bert-based-uncased'))\nnlp_token_class('Hugging Face is a French company based in New-York.')\n\n","b99e29fb":"nlp_qa = pipeline('question-answering')\nnlp_qa(context='Hugging Face is a French company based in New-York.', question='Where is based Hugging Face ?')","44c82155":"nlp_fill = pipeline('fill-mask')\nnlp_fill('Hugging Face is a French company based in <mask>')","6222d4e5":"nlp_features = pipeline('feature-extraction')\noutput = nlp_features('Hugging Face is a French company based in Paris')\nnp.array(output).shape   # (Samples, Tokens, Vector Size)","ed8d8d39":"# use bart in pytorch\nsummarizer1 = pipeline(\"summarization\")\nsummarizer1(\"Sam Shleifer writes the best docstring examples in the whole world.\", min_length=5, max_length=20)\n\n# use t5 in tf\nsummarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\nsummarizer(\"Sam Shleifer writes the best docstring examples in the whole world.\", min_length=5, max_length=20)","a451c213":"\n# 4. Text Generation - Mask Filling\u00b6\n","84f5d1fc":"Pipeline from Transformers can able to solve different Task in NLP \nPipeline module accepts few things\n\n>Task -> # The task which you are going to solve\n\n>Model - > Which Model you are going to use for the task , like Bert,T5\n\n>Config - > Each and everymodel has it's own configuration files , if you                   specify any model in model instance dont forget to provide exact                 config or tokenizer path or instance\n\n>Tokenizer - > If you are going to use Bert you are going to select \n\n>BertTokenizer from transformer\nFramework -> Either \"pt\" or\"tf\"\n             pt -> Pytorch\n             tf -> Transformers","bac771c5":"# 6.Summarization","1916d34e":"\n# 3. Question Answering\u00b6\n","0625bb44":"# Sentence_Classification","dffde0e9":"# 5. Projection - Features Extraction\u00b6\n","0081fff7":"\n# 2. Token Classification - Named Entity Recognition\u00b6\n"}}