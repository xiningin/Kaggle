{"cell_type":{"d4fa3375":"code","3bad25a5":"code","0f8a582a":"code","55709afa":"code","481134e5":"code","449c7133":"code","a1e64fc7":"code","ddc84567":"code","822085eb":"code","5bdfac26":"code","c9581dd4":"code","4b1ba5a4":"code","6bf2844a":"code","16b3fa0c":"code","6de56abd":"code","8b5f26eb":"code","416977a4":"code","3942ed1a":"code","e2208f08":"code","b13a2d27":"code","43bee11e":"code","d9a1e0c9":"code","88898e5b":"markdown"},"source":{"d4fa3375":"import os\nimport sys\nsys.path = ['..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master',] + sys.path\nimport pandas as pd\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torchvision.models as models\nimport albumentations as A\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom sklearn.model_selection import KFold, StratifiedKFold\n!pip install -q timm\nimport timm","3bad25a5":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nseed = 42\nrandom_state = set_seed(seed)","0f8a582a":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","55709afa":"RTransform = A.Compose([\n    A.Resize(128, 768, cv2.INTER_NEAREST)\n])  ","481134e5":"\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets, isTrain=True): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.isTrain = isTrain\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item])\n        image1 = np.vstack(image).transpose((1, 0)).astype(np.float32)[:, :, np.newaxis]\n        targets = self.targets[item]\n        image1 = RTransform(image=image1)[\"image\"]\n        image1 = image1.transpose(2, 0, 1)\n                \n        return {\n            \"image1\": torch.tensor(image1, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }        ","449c7133":"df = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\nprint (df.shape)\ndf['img_path'] = df['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')","a1e64fc7":"df.head()","ddc84567":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        \n        \n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        \n        return x","822085eb":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","5bdfac26":"def train(data_loader, model, optimizer, device):\n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs1 = data[\"image1\"]\n        targets = data['targets']\n        \n        inputs1, targets_a, targets_b, lam = mixup_data(inputs1, targets.view(-1, 1), use_cuda=True)\n\n        inputs1 = inputs1.to(device, dtype=torch.float)\n        targets_a = targets_a.to(device, dtype=torch.float)\n        targets_b = targets_b.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs1)\n        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs1 = data[\"image1\"]\n            targets = data[\"targets\"]\n            \n            inputs1 = inputs1.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.long)\n            \n            output = model(inputs1)\n            output = torch.sigmoid(output)\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","c9581dd4":"paths = [\n 'efficientnet-b0-08094119.pth',\n 'efficientnet-b1-dbc7070a.pth',\n 'efficientnet-b2-27687264.pth',\n 'efficientnet-b3-c8376fa2.pth',\n 'efficientnet-b4-e116e8b3.pth',\n 'efficientnet-b5-586e6cc6.pth',\n 'efficientnet-b6-c76e70fd.pth',\n 'efficientnet-b7-dcc49843.pth',\n]\npretrained_model = {\n    'efficientnet-b0': '..\/input\/efficientnet-pytorch\/' + paths[0],\n    'efficientnet-b1': '..\/input\/efficientnet-pytorch\/' + paths[1],\n    'efficientnet-b2': '..\/input\/efficientnet-pytorch\/' + paths[2],\n    'efficientnet-b3': '..\/input\/efficientnet-pytorch\/' + paths[3],\n    'efficientnet-b4': '..\/input\/efficientnet-pytorch\/' + paths[4],\n    'efficientnet-b5': '..\/input\/efficientnet-pytorch\/' + paths[5],\n    'efficientnet-b6': '..\/input\/efficientnet-pytorch\/' + paths[6],\n    'efficientnet-b7': '..\/input\/efficientnet-pytorch\/' + paths[7],\n}\n","4b1ba5a4":"class MetricNet(nn.Module):\n\n    def __init__(self, backbone='efficientnet_b5', pretrained=True):\n        super(MetricNet, self).__init__()\n        self.backbone = timm.create_model(backbone, pretrained=pretrained, num_classes=1, in_chans = 1)\n        \n    def forward(self, x):\n        x = self.backbone(x)\n        return x","6bf2844a":"#timm.list_models()","16b3fa0c":"device = \"cuda\"\nbaseline_name = 'efficientnet-b0'\nmodel = enetv2(baseline_name, out_dim=1)\nmodel.to(device)\ncriterion = nn.BCEWithLogitsLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 7e-4)\nn_epochs = 25\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)","6de56abd":"#df = df.sample(n = 500).reset_index(drop=True)","8b5f26eb":"X = df.img_path.values\nY = df.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\n\nfor train_index, test_index in skf.split(X, Y):\n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n    break\n","416977a4":"epochs = 12\nBatch_Size = 16\n\ntrain_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets)\nvalid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets, isTrain=False)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n","3942ed1a":"for epoch in range(epochs):\n    \n    if epoch % 5 == 0 and epoch > 1:\n        torch.save(model.state_dict(),'aug_training_1_' + str(epoch) + '.pt')\n        \n    train(train_loader, model, optimizer, device=device)\n    predictions, valid_targets = evaluate(valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n    scheduler.step()\n    ","e2208f08":"torch.save(model.state_dict(),'fold1_training_1_25_ep.pt')","b13a2d27":"submission = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy')\n\ntest_dataset = ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=8)\ntest_predictions, test_targets = evaluate(test_loader, model, device=device)","43bee11e":"test_predictions = np.array(test_predictions)\nsubmission.target = test_predictions[:, 0]\nsubmission.drop(['img_path'], axis=1, inplace=True)","d9a1e0c9":"submission.to_csv('fold1_submission.csv', index=False)\nsubmission.head()","88898e5b":"# Training Pipeline :) "}}