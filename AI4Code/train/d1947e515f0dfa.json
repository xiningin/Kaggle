{"cell_type":{"77fec613":"code","14c0caa8":"code","1c177e09":"code","fe10ee7f":"code","5d29aa91":"code","08cb5ca9":"code","387aa00b":"code","dfc598ab":"code","05e6d706":"code","32eb0dee":"code","ae92a342":"code","d57ac407":"code","c3dd719e":"code","c8445006":"code","113bfd55":"code","5ee66ac6":"code","8129a107":"code","0a0d2f54":"code","7ac8ea6b":"code","31b1f35f":"code","4a990aea":"code","8cace337":"code","3a008031":"code","2a5dd740":"code","35a8498e":"code","cd268d65":"code","b327735e":"code","11c17853":"code","b38c7a85":"code","379002f8":"code","aa47eab1":"code","b5e1d92e":"code","f38eded8":"code","24b3a973":"code","4a13fd42":"code","72983092":"code","e5f4d56e":"code","92b2ab5f":"code","7a967e6b":"code","1a1924f6":"code","676ade6f":"code","637ae903":"code","ff25e551":"code","bc4ab6cb":"code","ab3a3b2a":"code","fe8d3fab":"code","5b6f3d4e":"code","0491148e":"code","6a8415bd":"code","a41bd856":"code","e95f3844":"code","41a5b2fb":"code","4a8acdd2":"code","0d992e4a":"code","149c2d48":"code","4ea08974":"code","5ab2e639":"code","8b33f0d5":"code","d20b1310":"code","26c522b1":"code","f420aa3c":"markdown","d76fafa2":"markdown","cccd9435":"markdown","70d3885f":"markdown","4553cfe6":"markdown","61d05e26":"markdown","3e320b2a":"markdown","1140d61c":"markdown","f923f07f":"markdown","967e8ac8":"markdown","3e46a4bd":"markdown","cca422d3":"markdown","08e693fc":"markdown","ecd1b149":"markdown","a14584d9":"markdown","7a31d2f0":"markdown","17fa57e5":"markdown","5f664ce7":"markdown","06a3bb51":"markdown","f88f54d4":"markdown","9f447804":"markdown"},"source":{"77fec613":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14c0caa8":"%ls \"..\/input\"","1c177e09":"import pandas as pd\n# Load product data\nproduct = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\",\n                      header=0,sep=\",\")","fe10ee7f":"# Assess data\nproduct.sample(n=5)","5d29aa91":"# Dataset size\nprint(\"Number of rows\",product.shape[0])\nprint(\"Number of columns\",product.shape[1])","08cb5ca9":"# Get info on features\nproduct.info()","387aa00b":"# Simplify the names of features\nproduct.rename(columns=({\"Product Name\":\"Product\",\n                         \"Provider\/Company Name\":\"Provider\",\"Sector(s)\":\"Sector\",\n                         \"Primary Essential Function\":\"Usage\"})\n               ,inplace=True)","dfc598ab":"# check new header\nproduct.head(2)","05e6d706":"# Identify missing values in products' dataframe\nnulls_ = product.isnull()\nN_nulls = nulls_.sum()\nN_nulls\n","32eb0dee":"# Assess rows with nulls\nproduct[product[\"Sector\"].isnull()]","ae92a342":"# We have been able to find these missing entries.\n\nfor i in [61,293,314,352,354,370]:\n    product.loc[i,\"Sector\"] = \"PreK-12\"\n\nproduct.loc[356,\"Sector\"] = \"PreK-12; Higher Ed\"\n\nproduct.loc[61,\"Usage\"] = \"LC - Study Tools\"\nproduct.loc[293,\"Usage\"] = \"CM - Classroom Engagement & Instruction - Communication & Messaging\"\nproduct.loc[314,\"Usage\"] = \"LC - Sites, Resources & Reference\"\nproduct.loc[352,\"Usage\"] = \"LC - Sites, Resources & Reference\"\nproduct.loc[354,\"Usage\"] = \"LC - Sites, Resources & Reference - Streaming Services\"\nproduct.loc[356,\"Usage\"] = \"LC - Online Course Providers & Technical Skills Development\"\nproduct.loc[370,\"Usage\"] = \"LC - Digital Learning Platforms\"\n","d57ac407":"# These entries will have to be dropped. Either the websites have been taken down or\n# or the classification was not possible\n\ndropList = list(product[product[\"Sector\"].isnull()].index)\ndropList","c3dd719e":"product.drop(dropList,axis=0,inplace=True)\nproduct.shape","c8445006":"# Focus only on students and learning\n# remove functions associated with school management, techer education etc\n\nirrelevant = [\"SDO - Data, Analytics & Reporting - Site Hosting & Data Warehousing\",\"CM - Teacher Resources - Professional Learning\",\n\"LC - Career Planning & Job Search\",\"CM - Teacher Resources - Professional Learning\",\n\"CM - Teacher Resources - Lesson Planning\",\n\"SDO - School Management Software - Mobile Device Management\",\n\"SDO - Large-Scale & Standardized Testing\",\n\"SDO - School Management Software - SSO\",\n\"CM - Teacher Resources - Grading & Attendance\",\n\"SDO - Environmental, Health & Safety (EHS) Compliance\",\n\"SDO - Admissions, Enrollment & Rostering\"]\nrelevant_prod = product[product.apply(lambda x:x[\"Usage\"] not in irrelevant,axis=1)] ","113bfd55":"relevant_prod.shape","5ee66ac6":"# Who are the main service providers?\n\ndf_provider = pd.DataFrame(relevant_prod[\"Provider\"].value_counts())\ntop10_providers = df_provider.head(10)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.barplot(data=top10_providers,x=top10_providers.index,y=\"Provider\")\nplt.xlabel(\"Providers\")\nplt.xticks(rotation=90)\nplt.title(\"TOP educational digital service providers\")","8129a107":"# Making a dataframe with only the top 10 providers\nmini_df = relevant_prod[relevant_prod.apply(lambda x:x[\"Provider\"] \n                                            in list(top10_providers.index),\n                                            axis=1)]","0a0d2f54":"from pandas.plotting import parallel_coordinates\nplt.figure(figsize=(10,20))\nparallel_coordinates(mini_df.iloc[:,3:6],\"Usage\",colormap=\"gist_rainbow\")\nplt.title(\"Classes for which resources were provided\")\nplt.show()","7ac8ea6b":"mini_df_service = pd.DataFrame(mini_df.groupby([\"Provider\",\"Usage\"])[\"Usage\"].count())","31b1f35f":"# Load engagement data and construct one dataframe df\nimport glob\n \npath = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/*.csv\"\n\ndf = pd.DataFrame(columns=[\"time\",\"lp_id\",\"pct_access\",\"engagement_index\"])\n\nfor file in glob.glob(path):\n    df = pd.concat([df,pd.read_csv(file,header=0,sep=\",\")],axis=0)","4a990aea":"df.shape","8cace337":"df.sample(n=20)","3a008031":"noMissing = df.isnull().sum()","2a5dd740":"noMissing","35a8498e":"list_nan = df[df['lp_id'].isnull()].index.to_list()\ndf.drop(index=list_nan,axis=0,inplace=True)","cd268d65":"df[\"lp_id\"] = df[\"lp_id\"].astype(int)\n","b327735e":"from datetime import datetime\n\ndf[\"time\"] = df[\"time\"].map(lambda x:datetime.strptime(x,'%Y-%m-%d'))\ndf[\"day\"] = df[\"time\"].map(lambda x:x.day)\ndf[\"month\"] = df[\"time\"].map(lambda x:x.month)\ndf[\"Year\"] = df[\"time\"].map(lambda x:x.year)\n","11c17853":"df.dtypes","b38c7a85":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfig,axes = plt.subplots(1,2,figsize=(12,10),sharey=True)\ntime_ = [\"month\",\"day\"]\nfor i in [0,1]:\n  sns.scatterplot(ax=axes[i],data=df,x=\"pct_access\",y=\"engagement_index\",hue=time_[i])","379002f8":"DF = product.copy()\ndf.rename(columns={\"lp_id\":\"LP ID\"},inplace=True)\ndf_joined = pd.merge(DF,df,on=[\"LP ID\"])","aa47eab1":"# Usage by Product\nval_count = pd.DataFrame(df_joined[\"Product\"].value_counts())\nval_count[\"Count\"] = val_count[\"Product\"]\nval_count.drop([\"Product\"],inplace=True,axis=1)\nval_count[\"%\"] = val_count[\"Count\"]\/val_count[\"Count\"].sum()*100\nval_count","b5e1d92e":"val_count_service = pd.DataFrame(df_joined[\"Usage\"].value_counts())\nval_count_service[\"Count\"] = val_count_service[\"Usage\"]\nval_count_service.drop([\"Usage\"],inplace=True,axis=1)\nval_count_service[\"%\"] = val_count_service[\"Count\"]\/val_count_service[\"Count\"].sum()*100","f38eded8":"plt.figure(figsize=(30,10))\ntop_50_service = val_count_service.head(50).copy()\nsns.barplot(data = top_50_service,x=top_50_service.index,y=\"%\")\nplt.xticks(rotation=90)","24b3a973":"grouped_tools = pd.DataFrame(df_joined.groupby([\"Product\"])[\"engagement_index\"].mean())","4a13fd42":"engagement_by_tool = grouped_tools[\"engagement_index\"].sort_values(ascending=False)\nengagement_by_tool_top_60 = pd.DataFrame(engagement_by_tool.head(20))","72983092":"plt.figure(figsize=(30,10))\nsns.barplot(data = engagement_by_tool_top_60,x=engagement_by_tool_top_60.index,y=\"engagement_index\")\nplt.xticks(rotation=90)","e5f4d56e":"grouped_function = pd.DataFrame(df_joined.groupby([\"Usage\"])[\"engagement_index\"].mean())\n","92b2ab5f":"engagement_by_function = grouped_function[\"engagement_index\"].sort_values(ascending=False)\nengagement_by_function_top_60 = pd.DataFrame(engagement_by_function.head(20))","7a967e6b":"plt.figure(figsize=(30,10))\nsns.barplot(data = engagement_by_function_top_60,x=engagement_by_function_top_60.index,y=\"engagement_index\")\nplt.xticks(rotation=90)","1a1924f6":"# Load data\ndistrict = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\",header=0,sep=\",\")\ndistrict ","676ade6f":"state_null_list = set(district[district[\"state\"].isnull()].index)\nlocale_null_list = set(district[district[\"locale\"].isnull()].index)","637ae903":"locale_null_list.difference(state_null_list)","ff25e551":"district.drop(state_null_list,axis=0,inplace=True)\ndistrict.isnull().sum()","bc4ab6cb":"#district[\"pct_black\/hispanic\"].value_counts()","ab3a3b2a":"district","fe8d3fab":"#district[district[\"pct_free\/reduced\"].isnull()]","5b6f3d4e":"#district[\"pct_free\/reduced\"].value_counts()","0491148e":"# Convert interval data into a sigle number using mean of boundary points\nimport numpy as np\n\ndef split_function(data):\n    data = data.replace(\"[\",\"\")\n    data = data.replace(\" \",\"\").split(\",\")\n    a = float(data[0])\n    b = float(data[1])\n    return (a+b)\/2\n\nfor features in [\"pct_black\/hispanic\",\"pct_free\/reduced\",\"county_connections_ratio\",\"pp_total_raw\"]:\n    district[features] = district[features].map(lambda x: split_function(x) if isinstance(x,str) else np.nan)","6a8415bd":"district.shape\ndistrict.isnull().sum()","a41bd856":"# Drop na\nreduced_dataset = district.dropna(axis=0)\nreduced_dataset.shape","e95f3844":"import statsmodels.api as sm\nX = reduced_dataset[\"pct_black\/hispanic\"]\nY = reduced_dataset[\"pct_free\/reduced\"]\nmodel = sm.OLS(Y,X)\nresults = model.fit()\nprint(\"R2: \", results.rsquared)\n","41a5b2fb":"ind = list(district[district[\"pct_free\/reduced\"].isnull()].index)\nfor i in ind:\n   x = district.loc[i,\"pct_black\/hispanic\"] \n   district.loc[i,\"pct_free\/reduced\"] = results.predict([x])[0]","4a8acdd2":"reduced_dataset","0d992e4a":"correl = reduced_dataset.corr()\nsns.heatmap(correl,annot=True)","149c2d48":"new_index = list(district[district[\"pp_total_raw\"].isnull()][\"locale\"].index)\nreduced_dataset = district.drop(new_index,axis=0)\n","4ea08974":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\nZ = np.array(reduced_dataset[\"pp_total_raw\"]).reshape(-1,1)\nsc = RobustScaler()\nreduced_dataset[\"pp_total_raw_trans\"] = sc.fit_transform(Z)\n\npca = PCA(svd_solver = \"full\")\nreduced_dataset.iloc[:,3:7].isnull().sum()\nreduced_dataset.drop([\"county_connections_ratio\"],axis=1,inplace=True)\nreduced_dataset","5ab2e639":"reduced_dataset.drop([\"pp_total_raw\"],axis=1,inplace=True)\nX_pca = pca.fit_transform(reduced_dataset.iloc[:,3:6])","8b33f0d5":"from sklearn.cluster import KMeans\nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom yellowbrick.cluster import SilhouetteVisualizer\n\n\ndef plot_silhouette_inertie(df, k_range):\n    from sklearn.cluster import KMeans\n    from sklearn import metrics\n    import matplotlib.pyplot as plt\n    \n    inertia = []\n    res = []\n    \n    for k in k_range:\n        model = KMeans(n_clusters=k, n_init=20).fit(df)\n        res.append(metrics.silhouette_score(df, model.labels_))\n        inertia.append(model.inertia_)\n\n    #plot clusters vs. silhouette score \n    plt.grid()\n    plt.plot(k_range, res)\n    plt.title(\"Silhouette\")\n    plt.xlabel(\"Number of clusters\")\n    plt.ylabel(\"Coefficient de silhouette\")\n    plt.tight_layout()\n    plt.show() \n    #plot clusters vs. Inertial score \n    plt.grid()\n    plt.plot(k_range, inertia)\n    plt.title(\"Inertia\")\n    plt.xlabel(\"Number of clusters\")\n    plt.ylabel(\"Coefficient of inertia\")\n    plt.tight_layout()\n    plt.show() \n    \n    \nfig, ax = plt.subplots(3, 2, figsize=(15,8))\nfor i in [2, 3, 4, 5, 6, 7]:\n    km = KMeans(n_clusters=i, n_init=10, max_iter=100, random_state=42)\n    q, mod = divmod(i, 2)\n\n    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n    visualizer.fit(X_pca)","d20b1310":"#librairies pour la CAH\nfrom matplotlib import pyplot as plt\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nreduced_dataset.index = reduced_dataset[\"pct_free\/reduced\"].map(lambda x:np.round(x,2))","26c522b1":"\n#g\u00e9n\u00e9rer la matrice des liens\ndf0 = reduced_dataset.copy()\ndf0.index = df0[\"locale\"]\nZ = linkage(X_pca,method='ward',metric='euclidean')\nfig,ax = plt.subplots(1,2,figsize=(30, 30))\n# Create dendograms\ndendrogram(Z,labels=reduced_dataset.index,orientation='left',color_threshold= 4,leaf_font_size=12,ax=ax[0])\ndendrogram(Z,labels=df0.index,orientation='right',color_threshold= 4,leaf_font_size=12,ax=ax[1])\nplt.title(\"Hierarchical clusters illustrating pct_free\/reduced by Sector type\")\nplt.show()\n","f420aa3c":"reduced_dataset","d76fafa2":"district.isnull().all(axis=0).sum()","cccd9435":"Services which were more used at PreK-12 : LC Digital Learning Platforms\nRousource sites, Games and Simulations followed far behind","70d3885f":"Here we identify the main digital educational resource providers","4553cfe6":"**The Learning management systems were found to be more engaging**","61d05e26":"plt.figure(figsize=(30,10))\ntop_50 = val_count.head(50).copy()\nsns.barplot(data = top_50,x=top_50.index,y=\"%\")\nplt.xticks(rotation=90)","3e320b2a":"**What were the most engaging products?**","1140d61c":"What are the primary functions of the services?","f923f07f":"In which sectors did the top10 providers supplied resources?","967e8ac8":"There is a strong linear correlation between pct_black\/hispanic and beneficiaries of the pct_free\/reduced incentive","3e46a4bd":"# Analysis of access to digital services","cca422d3":"There is a non-linear (almost quadratic) relationship between pct_access and engagement.\nThe engagement level increases with greater internet access. Towards the last 3 months of the year, a significant increase is also noted.","08e693fc":"![Who are the main providers?](http:\/\/)","ecd1b149":"# Conclusions\n1. Some major companies in the digital world have been very active providing educational services at school.\n2. Most of the resources were aimed at the PreK-12 learner groups\n3. Programs aimed at facilitating online access, is not evenly distributed.\n4. Most suburb groups benefit least from these programs\n","a14584d9":"Massive data set!!","7a31d2f0":"There is a non-linear (almost quadratic) relationship between pct_access and engagement.\nThe engagement increases with greater access, but also towards the last 3 months of the year.","17fa57e5":"We note that there are some characteristics which regroup different sectors. The grouping seem to happen by pct_free\/reduced feature, with a distinct cluster of suburbs receiving lower pct_free\/reduced, than most city and rural areas.  ","5f664ce7":"There are some clusters which are made. However, they do not seem to be well formed","06a3bb51":"**The most used software was not necessarily the most engaging**","f88f54d4":"We note that all missing values from Provider, Sector and Usage are in these 20 rows.\nGiven the small size of the dataset, we will avoid deleting them as far as possible.\nWe can find some of these missing values by visiting the websites and using classes\ndefined in Sector and Usage. This is the approach taken.","9f447804":"All providers supplied for PreK-12. We will run all analysis on these classes, because\nthis is the group which is of major interest when it comes to access to and use of technology"}}