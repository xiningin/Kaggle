{"cell_type":{"0d1a00c0":"code","53063bc4":"code","00496d26":"code","81758050":"code","c54aa0ee":"code","cf17391c":"code","ffc101ae":"code","82741664":"code","96dcffc4":"code","7a5f9631":"code","28c533bc":"code","4c0622c5":"code","637d40fa":"code","f2e7304f":"code","7b744a4e":"code","49f64aa1":"code","40af114c":"code","0679956a":"code","3fc08b3a":"code","71cd846b":"code","c90853b1":"code","2f9106bd":"markdown","38c31785":"markdown","5811d3af":"markdown","e91d47e9":"markdown","9f7de837":"markdown","591d2c55":"markdown","1a49b3d4":"markdown","99a2a98d":"markdown","b6dcde81":"markdown","529f416b":"markdown","e3ad428a":"markdown","f14c17f8":"markdown","1b287243":"markdown","593155eb":"markdown","31c028de":"markdown"},"source":{"0d1a00c0":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, roc_auc_score\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nsns.set_style(\"dark\")\nimport warnings\nwarnings.filterwarnings('ignore')","53063bc4":"#Import datset\ndata = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndata.head(10)","00496d26":"data.info()","81758050":"data.drop(['Unnamed: 32','id'], axis = 1 , inplace=True)","c54aa0ee":"data.describe()","cf17391c":"data.skew()","ffc101ae":"#Visualizing Multidimensional Relationships\nplt.style.use('fivethirtyeight')\nsns.set_style(\"white\")\nsns.pairplot(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]], hue = 'diagnosis' , size=3)","82741664":"#create the correlation matrix heat map\nplt.figure(figsize=(10,6))\nsns.heatmap(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]].corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);\nplt.suptitle('Correlation Matrix')","96dcffc4":"# Transform the 'yes' and 'no' values (target variable) to 1 and 0 respectively\ndata['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n\n#Scalling\nscaler =MinMaxScaler(feature_range=(0, 1))\nscaled_data =  pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n# Split the data to train and test sets\nX = scaled_data.loc[:, scaled_data.columns != 'diagnosis']\ny = scaled_data['diagnosis']","7a5f9631":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","28c533bc":"#Defining model evaluation function\ndef getModelEvaluationMetrics(classifier, model_name: str, x_test: pd.core.frame.DataFrame,\n                              y_test: pd.core.frame.DataFrame, y_predicted, plot_confusion_matrix=False,\n                              figsize=(10, 8)) -> np.ndarray:\n\n    conf_mat = confusion_matrix(y_true=y_test, y_pred=y_predicted)\n    print('Confusion matrix:\\n\\n {0}'.format(conf_mat))\n\n    if plot_confusion_matrix:\n        labels = ['M', 'B']\n        fig = plt.figure(figsize=figsize)\n        ax = fig.add_subplot(111)\n        cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n        fig.colorbar(cax)\n        ax.set_xticklabels([''] + labels)\n        ax.set_yticklabels([''] + labels)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('Predicted')\n        plt.ylabel('Expected')\n        plt.title(f'Confusion Matrix for {model_name}', fontweight='bold')\n        plt.show()\n\n    # Calculating the precision (tp\/tp+fp)\n    precision = str(np.round((conf_mat[1][1] \/ (conf_mat[1][1] +\n                              conf_mat[0][1])) * 100, 2))\n    print('The precision is: {0} %'.format(precision))\n\n    # Calculating the recall (tp\/tp+fn)\n    recall = str(np.round((conf_mat[1][1] \/ (conf_mat[1][1] +\n                           conf_mat[1][0])) * 100, 2))\n    print('The recall is: {0} %'.format(recall))\n\n    return conf_mat","4c0622c5":"#Defining function for performing a full ROC analysis\ndef createROCAnalysis(classifier, model_name: str, y_test: pd.core.series.Series, pred_probs: np.ndarray,\n                      plot_ROC_Curve=False, figsize=(10, 8)) -> int:\n   \n    if plot_ROC_Curve:\n        plt.figure(figsize=figsize)\n        plt.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier')\n        fp_rate, tp_rate, _ = roc_curve(y_test, pred_probs[:, 1])\n        plt.plot(fp_rate, tp_rate, marker='.', label=model_name)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve for {model_name}', fontweight='bold')\n        plt.grid(True, alpha=0.1, color='black')\n        plt.legend(loc='lower right')\n        plt.show()\n\n    # Calculate Area Under Curve (AUC) for the Receiver Operating\n    # Characteristics Curve (ROC)\n    auc_score = np.round(roc_auc_score(y_test, pred_probs[:, 1]), 4)\n    print(f'{model_name} - ROC AUC score: {auc_score}')\n\n    return auc_score","637d40fa":"# Instantiate the Random Forest model\n#Pre-tuned Hyperparameter of Random Forest Classifier on this dataset\n\nrf_class = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features=10, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=20, min_samples_split=20,\n            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","f2e7304f":"# Assign the above probabilities to the corresponding class ('no', 'yes')\nrf_class.fit(X_train, y_train)\nrf_y_pred = rf_class.predict(X_test)\n# Evaluate the model by using Recall\/Precission:\ngetModelEvaluationMetrics(classifier=rf_class, model_name='Random Forest',x_test=X_test, y_test=y_test,\n                              y_predicted=rf_y_pred, plot_confusion_matrix=True, figsize=(8,6))","7b744a4e":"# Evaluate the model by using ROC Curve:\nrf_pred_probs = rf_class.predict_proba(X_test)\ncreateROCAnalysis(classifier=rf_class, model_name='Random Forest', y_test=y_test, pred_probs=rf_pred_probs,\n                  plot_ROC_Curve=True, figsize=(8,6))","49f64aa1":"feature_importance = {}\nbest_estimator_fi = rf_class.feature_importances_\n\nfor feature, importance in zip(X_train.columns, best_estimator_fi):\n    feature_importance[feature] = importance\n\nimportances = pd.DataFrame.from_dict(feature_importance, orient='index').rename(columns={0: 'Gini Score'})\n\nimportances = importances.sort_values(by='Gini Score', ascending=False)","40af114c":"# Plot for feature importance\nplt.figure(figsize=(20, 8))\nplt.style.use('fivethirtyeight')\nsns.set_style(\"white\")\nsns.barplot(x=importances.index[0:10],\n            y=importances['Gini Score'].iloc[0:10], palette='muted')\nplt.title(f'Importance for the Top 10 Features (Gini criterion) ',\n          fontweight='bold')\nplt.grid(True, alpha=0.1, color='black')\nplt.show()","0679956a":"sc = StandardScaler()\nX_s = sc.fit_transform(X)\n\npca = PCA(n_components = 10)\nX_pca = pca.fit_transform(X_s)\n\nPCA_df = pd.DataFrame()\n\nPCA_df['PCA_1'] = X_pca[:,0]\nPCA_df['PCA_2'] = X_pca[:,1]\n\nplt.plot(PCA_df['PCA_1'][data.diagnosis == 1],PCA_df['PCA_2'][data.diagnosis == 1],'o', alpha = 0.7, color = 'r')\nplt.plot(PCA_df['PCA_1'][data.diagnosis == 0],PCA_df['PCA_2'][data.diagnosis == 0],'o', alpha = 0.7, color = 'b')\nplt.xlabel('PCA 1')\nplt.ylabel('PCA 2')\nplt.legend(['Malignant','Benign'])\nplt.show()","3fc08b3a":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\npca = PCA(n_components = 10)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","71cd846b":"# Assign the above probabilities to the corresponding class ('no', 'yes')\nrf_class.fit(X_train, y_train)\nrf_y_pred = rf_class.predict(X_test)\n# Evaluate the model by using Recall\/Precission:\ngetModelEvaluationMetrics(classifier=rf_class, model_name='Random Forest',x_test=X_test, y_test=y_test,\n                              y_predicted=rf_y_pred, plot_confusion_matrix=True, figsize=(8,6))","c90853b1":"# Evaluate the model by using ROC Curve:\nrf_pred_probs = rf_class.predict_proba(X_test)\ncreateROCAnalysis(classifier=rf_class, model_name='Random Forest', y_test=y_test, pred_probs=rf_pred_probs,\n                  plot_ROC_Curve=True, figsize=(8,6))","2f9106bd":"Let\u2019s evaluate the same algorithms with a standardized copy of the dataset. Here, I use sklearn to scale and transform the data such that each attribute has a mean value of zero and a standard deviation of one.","38c31785":"All features are complete, only 'Unnamed: 32' is completely null, probably an error in the dataset, let's drop the unnecessary data","5811d3af":"# Data Preprocessing","e91d47e9":"\n# Model Evaluation Metrics\n\nFor model evaluation and To perform a full ROC analysis let's define two functions","9f7de837":"Using PCA I used only 10 components (important) from the dataset, though it contains 30 components!\nHowever, with PCA+RF the model slightly outweigh in recall, precision and ROC AUC score than that of the previous model.\n\n*** Random Forest Model Prediction without PCA**\n1. The precision is: 95.24 %\n1. The recall is: 93.02 %\n1. ROC AUC score: 0.9954\n\n*** Random Forest Model Prediction with PCA**\n\n1. The precision is: 97.62 %\n1. The recall is: 95.35 %\n1. ROC AUC score: 0.9974","591d2c55":"**Dataset Description**\n\nThe Breast Cancer datasets is available UCI machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.\n\nThe first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnosis (M=malignant, B=benign), respectively. The columns 3-32 contain 30 real-value features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.\n\n* 1= Malignant (Cancerous) - Present (M)\n*  0= Benign (Not Cancerous) -Absent (B)","1a49b3d4":"# Breast Cancer Prediction","99a2a98d":"# Load libraries and read the data","b6dcde81":"\n\nTransform the 'M' and 'B' values (target variable) to 1 and 0 respectively. Following the encoding of the categorical features, we will continue with the normalization (scalling) of the numerical features. For this we will use the MinMax scalling method.","529f416b":"The skew result show a positive (right) or negative (left) skew. Values closer to zero show less skew. From the graphs, we can see that **radius_mean, perimeter_mean, area_mean, concavity_mean and concave_points_mean** are useful in predicting cancer type due to the distinct grouping between malignant and benign cancer types in these features. We can also see that area_worst and perimeter_worst are also quite useful.","e3ad428a":"# Feature decomposition using Principal Component Analysis( PCA)","f14c17f8":"# Conclution","1b287243":"# Exploratory Data Analysis (EDA)","593155eb":"The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.","31c028de":"***If you find this notebook useful, would like to hear from you about it. Any feedbacks or any future tips for support will be highly appreciated.***"}}