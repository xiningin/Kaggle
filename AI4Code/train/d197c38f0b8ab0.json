{"cell_type":{"32bc9381":"code","450cbb5c":"code","60d49a13":"code","76148271":"code","060734f6":"code","1868682b":"code","c1421784":"code","52e9ff5a":"code","3d282c68":"markdown","0008beed":"markdown"},"source":{"32bc9381":"%pylab inline\nimport os\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.io import wavfile\n\n\nos.listdir('..\/input\/darpa-timit-acousticphonetic-continuous-speech\/')","450cbb5c":"traindf = pd.read_csv('..\/input\/darpa-timit-acousticphonetic-continuous-speech\/train_data.csv')\ntestdf = pd.read_csv('..\/input\/darpa-timit-acousticphonetic-continuous-speech\/test_data.csv')\nbase_data_dir= '..\/input\/darpa-timit-acousticphonetic-continuous-speech\/data'\nsrc_audio_files = traindf[(traindf['is_audio']==True)&(traindf['is_converted_audio']==True)]\n","60d49a13":"sample_row = src_audio_files.sample().iloc[0]\nsample_file_name = sample_row['path_from_data_dir']\nbasename = sample_row['filename'][:sample_row['filename'].index('.')]\nprint(basename)","76148271":"sample_related_files = traindf[(traindf['filename'].str.contains(basename+'.').fillna(False))&\n                               (traindf['dialect_region']==sample_row['dialect_region'])&\n                               (traindf['speaker_id']==sample_row['speaker_id'])]\nprint(sample_related_files['filename'])\nsample_word_file_name = sample_related_files[sample_related_files['filename'].str.contains('.WRD')].iloc[0]\nsample_phon_file_name = sample_related_files[sample_related_files['filename'].str.contains('.PHN')].iloc[0]\nsample_word_df = pd.read_csv(os.path.join(base_data_dir,sample_word_file_name['path_from_data_dir']),sep=' ',header=None,names=['nsam_start','nsam_end','word']) \nsample_word_df[['nsam_start','nsam_end']]=sample_word_df[['nsam_start','nsam_end']].astype('i')\nsample_phon_df = pd.read_csv(os.path.join(base_data_dir,sample_phon_file_name['path_from_data_dir']),sep=' ',header=None,names=['nsam_start','nsam_end','phoneme']) \nsample_phon_df[['nsam_start','nsam_end']]=sample_phon_df[['nsam_start','nsam_end']].astype('i')","060734f6":"with open(os.path.join(base_data_dir,sample_phon_file_name['path_from_data_dir'])) as f:\n    print(f.readlines())","1868682b":"sample_related_files","c1421784":"traindf['is_phonetic_file'].value_counts()","52e9ff5a":"sr,ws = wavfile.read(os.path.join(base_data_dir,sample_file_name))\nw=ws\/max(ws)\nfig,ax=subplots(2,figsize=(18,8),sharex=True)\nax[0].plot(w)\nax[1].specgram(w,Fs=1,NFFT=2**8,cmap='gray')\nfor ir,row in sample_word_df.iterrows():\n    for axi in ax:\n        axi.axvline(row['nsam_start'],color='r',alpha=.5)\n    ax[0].annotate(row['word'],((row['nsam_start']+row['nsam_end'])\/2,.9),bbox=dict(boxstyle=\"round\", fc=\"0.9\"),ha='center')\nfor ir,row in sample_phon_df.iterrows():\n    for axi in ax:\n        axi.axvline(row['nsam_start'],color='g',alpha=.5,lw=1)\n    ax[1].annotate(row['phoneme'],((row['nsam_start']+row['nsam_end'])\/2,0.45),ha='center')\n","3d282c68":"## Get a sample","0008beed":"### Get the word and phoneme boundaries for this sample"}}