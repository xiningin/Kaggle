{"cell_type":{"3e10b550":"code","23c2735a":"code","1d3bec93":"code","9123d2fe":"code","0f70dc15":"code","18a3c490":"code","5263a215":"code","c18fa1a4":"code","2772c326":"code","0cb8e519":"code","6c248d4d":"markdown","d9d5a5cc":"markdown"},"source":{"3e10b550":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = 20, 15","23c2735a":"train, test = mnist.load_data()\nprint(f'Shape of Train and Test is {train[0].shape, test[0].shape}')\nprint(f'Train and Test labels are of shape{train[1].shape, test[1].shape}')","1d3bec93":"codings_size = 30\n\ngenerator = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n    keras.layers.Dense(150, activation=\"selu\"),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\ndiscriminator = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(150, activation=\"selu\"),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])\ngan = keras.models.Sequential([generator, discriminator])\n","9123d2fe":"gan = Sequential([generator, discriminator])\ngan.summary()","0f70dc15":"X_train = train[0] \/ 255.","18a3c490":"discriminator.compile(loss=\"binary_crossentropy\", optimizer='rmsprop')\ndiscriminator.trainable = False\ngan.compile(loss=\"binary_crossentropy\", optimizer='rmsprop')","5263a215":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(10)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","c18fa1a4":"def plot_multiple_images(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols, n_rows))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","2772c326":"def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n    generator, discriminator = gan.layers\n    for epoch in range(n_epochs):\n        print(\"Epoch {}\/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n        for X_batch in dataset:\n            # phase 1 - training the discriminator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            generated_images = generator(noise)\n            generated_images = tf.cast(generated_images, dtype='float64')\n            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(X_fake_and_real, y1)\n            # phase 2 - training the generator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            y2 = tf.constant([[1.]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, y2)\n        plot_multiple_images(generated_images, 8)                     # not shown\n        plt.show()   ","0cb8e519":"train_gan(gan, dataset, batch_size, codings_size)","6c248d4d":"Thanks to https:\/\/github.com\/ageron\/handson-ml2\/blob\/master\/17_autoencoders_and_gans.ipynb\nfor a great notebook.\n\n# Imports","d9d5a5cc":"# Process Data"}}