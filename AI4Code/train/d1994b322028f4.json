{"cell_type":{"776f440c":"code","5cf3da24":"code","c3e2b1d0":"code","b49b0187":"code","9586dd64":"code","ddd4a0e4":"code","fdf23c25":"code","7818bdd1":"code","a570ce34":"code","1a8a740b":"code","a256ead9":"code","0e274539":"code","d5d43fe1":"code","e800abfd":"markdown","fe004fa3":"markdown","c205818c":"markdown","fc136aef":"markdown","1cd882c1":"markdown"},"source":{"776f440c":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import cross_val_score\n\nimport optuna.integration.lightgbm as lgb\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\nfrom optuna.integration import LightGBMPruningCallback\n\nfrom tqdm import tqdm","5cf3da24":"train=pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest=pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')\nsub=pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')","c3e2b1d0":"X1 = train.drop(['target', 'id'], axis=1).copy()\nX2 = train.drop(['target', 'id'], axis=1).copy()\nX3 = train.drop(['target', 'id'], axis=1).copy()\nX4 = train.drop(['target', 'id'], axis=1).copy()\n\ny1 = np.where(train.target==\"Class_1\", 1, 0)\ny2 = np.where(train.target==\"Class_2\", 1, 0)\ny3 = np.where(train.target==\"Class_3\", 1, 0)\ny4 = np.where(train.target==\"Class_4\", 1, 0)\n\nX1_train, X1_val, y1_train, y1_val = train_test_split(X1, y1, test_size=0.10, random_state=42)\nX2_train, X2_val, y2_train, y2_val = train_test_split(X2, y2, test_size=0.10, random_state=42)\nX3_train, X3_val, y3_train, y3_val = train_test_split(X3, y3, test_size=0.10, random_state=42)\nX4_train, X4_val, y4_train, y4_val = train_test_split(X4, y4, test_size=0.10, random_state=42)","b49b0187":"params = {\n    \"objective\": \"binary\",\n    \"metric\": \"binary_logloss\",\n    \"verbosity\": -1,\n    \"boosting_type\": \"gbdt\",\n    'learning_rate': 0.02,\n    'random_state': 314\n    }","9586dd64":"booster1 = lgb.train(params, \n                     lgb.Dataset(X1_train, label=y1_train),\n                     valid_sets=lgb.Dataset(X1_val, label=y1_val),\n                     verbose_eval=0,\n                     early_stopping_rounds=70)","ddd4a0e4":"y1_pred = booster1.predict(test.drop('id', axis=1), num_iteration=booster1.best_iteration)","fdf23c25":"booster2 = lgb.train(params, \n                     lgb.Dataset(X2_train, label=y2_train),\n                     valid_sets=lgb.Dataset(X2_val, label=y2_val),\n                     verbose_eval=0,\n                     early_stopping_rounds=70)","7818bdd1":"y2_pred = booster2.predict(test.drop('id', axis=1), num_iteration=booster2.best_iteration)","a570ce34":"booster3 = lgb.train(params, \n                     lgb.Dataset(X3_train, label=y3_train),\n                     valid_sets=lgb.Dataset(X3_val, label=y3_val),\n                     verbose_eval=0,\n                     early_stopping_rounds=70)","1a8a740b":"y3_pred = booster3.predict(test.drop('id', axis=1), num_iteration=booster3.best_iteration)","a256ead9":"booster4 = lgb.train(params, \n                     lgb.Dataset(X4_train, label=y4_train),\n                     valid_sets=lgb.Dataset(X4_val, label=y4_val),\n                     verbose_eval=0,\n                     early_stopping_rounds=70)","0e274539":"y4_pred = booster4.predict(test.drop('id', axis=1), num_iteration=booster4.best_iteration)","d5d43fe1":"sub = pd.DataFrame({\n    'id': test.id,\n    'Class_1': y1_pred, \n    'Class_2': y2_pred,\n    'Class_3': y3_pred,\n    'Class_4': y4_pred\n})\n\nsub.to_csv('lgbm_tuner_one_x_rest.csv', index=False)","e800abfd":"# Load dependencies","fe004fa3":"# Models","c205818c":"# Prepare data to one vs rest","fc136aef":"# Submission","1cd882c1":"# Problem definition\n\nFrom description:\n\n\"The dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.\"\n\n\nSee notebooks using R:\n\n1. [Finding the best pre-processing configuration and predictive models based on the original data](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-r-eda-tidymodels-workflowsets\/)\n2. [Create DAE dataset and fit models in DAE data](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-r-dae-keras) \n4. [Stacking all](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-r-tidymodels-stacks\/)\n\nNotebooks using Python language:\n\n1. [LightGbm sequencial tuning with Optuna Step-wise by LightGBM Tuner](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-optuna-lightgbm-tuner)\n2. [LightGbm tuning with Optuna TPE (Tree-structured Parzen Estimator)](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-optuna-lightgbm-tpe\/)\n3. **LightGbm tuning one vs rest with Optuna Step-wise by LightGBM Tuner**\n4. [LightGbm tuning pseudo label with Optuna Tuner](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-lightgbm-pseudolabel\/)\n5. [Stacking All](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-stacking)\n\nAll notebooks will be public and suggestions and criticism are very welcome!\n\n\n<br>\n\n<p align=\"right\"><span style=\"color:firebrick\">Dont forget the upvote if you liked the notebook! <i class=\"fas fa-hand-peace\"><\/i><\/span> <\/p>"}}