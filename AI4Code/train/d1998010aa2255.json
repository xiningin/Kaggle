{"cell_type":{"eb3609bd":"code","4b21456e":"code","31456d7f":"code","1e616818":"code","3bc4eb38":"code","c74f8a14":"code","37dfcd26":"code","a780043c":"code","1272b8d0":"code","f5811b01":"code","c1660068":"markdown","a32b6397":"markdown","89fc79a5":"markdown","adc81eb3":"markdown","f16548e1":"markdown","66414ceb":"markdown","4edee73e":"markdown","fd70c90d":"markdown","b5d802cd":"markdown","eee0d023":"markdown","7350fe6e":"markdown"},"source":{"eb3609bd":"import sys, csv\nimport numpy as np\nimport keras\nimport matplotlib.pyplot as plt\nfrom keras import models\nfrom keras import layers\nfrom keras.utils.np_utils import to_categorical","4b21456e":"def smooth_curve(points, factor=0.9):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points","31456d7f":"Train_Data_List = []\nTrain_Target_List = []","1e616818":"with\topen('..\/input\/crime_by_district_rt.csv',\t'r')\tas\tf:\n    reader\t=\tcsv.DictReader(f,\tdelimiter=',')\n    for\trow\tin\treader:\n        Murder\t=\tfloat(row[\"Murder\"])\n        Assault_on_women    =   float(row[\"Assault on women\"])\n        Kidnapping_and_Abduction  =\tfloat(row[\"Kidnapping and Abduction\"])\n        Dacoity\t=\tfloat(row[\"Dacoity\"])\n        Robbery\t=\tfloat(row[\"Robbery\"])\n        Arson\t=\tfloat(row[\"Arson\"])\n        Hurt\t=\tfloat(row[\"Hurt\"])\n        POA\t    =\tfloat(row[\"Prevention of atrocities (POA) Act\"])\n        PCR\t    =\tfloat(row[\"Protection of Civil Rights (PCR) Act\"])\n        Other\t=\tfloat(row[\"Other Crimes Against SCs\"])\n        \n        Train_Data_List.append([Murder, Assault_on_women, Dacoity, Robbery, Arson, Hurt, POA, PCR, Other])\n        Train_Target_List.append(Kidnapping_and_Abduction)\n\nprint(\"=======================Training data=======================\")\nprint(Train_Data_List)\nprint(\"=======================Training Targets====================\")\nprint(Train_Target_List)","3bc4eb38":"train_data =  np.array(Train_Data_List)\ntrain_targets = np.array(Train_Target_List)\nprint(\"=======================Training data=======================\")\nprint(train_data)\nprint(train_data.shape)\nprint(\"=========================Test data=========================\")\nprint(train_targets)\nprint(train_targets.shape)","c74f8a14":"mean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data \/= std","37dfcd26":"def build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n    return model","a780043c":"k = 4\nnum_val_samples = len(train_data) \/\/ k\nnum_epochs = 200\nall_mae_histories = []\nfor i in range(k):\n    print('processing fold #', i)\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    \n    partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n    \n    model = build_model()\n    history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=100, verbose=0)\n    \n    mae_history = history.history['val_mean_absolute_error']\n    all_mae_histories.append(mae_history)","1272b8d0":"average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]","f5811b01":"smooth_mae_history = smooth_curve(average_mae_history[10:])\n    \nplt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()","c1660068":"# Regression Model for crimes by District\nThis regression model trains itself with crime data in the ***crimes_by_district_rt.csv*** data set\n","a32b6397":"Plot the validation scores using matplotlib","89fc79a5":"Train the model, validate the model using k-fold validation and save the validation logs at each fold","adc81eb3":"Take data from ***crimes_by_district_rt.csv*** and append the required data to the above two lists.\nIn this case the target column is chosen to be \"Kidnapping_and_Abduction\".Print the training data and training targets","f16548e1":"Create two lists to store the training data and the training targets.","66414ceb":"Calucate and store the mean MAE for each fold","4edee73e":"Normalize the training and test data","fd70c90d":"Deep learning regression model architecture as a function","b5d802cd":"Convert the Training data and targets into 2D Tensors and print the tensors and there shapes.","eee0d023":"A function that's used to smooth the resultant visualiztions","7350fe6e":"Using Keras with tensorflow backend, and other imports"}}