{"cell_type":{"85e61efe":"code","fe12bb37":"code","ee423dd4":"code","2c2f2ab1":"code","fab428c8":"code","4571e53c":"code","a2d6e6e5":"code","e62e2733":"code","3cc63ae7":"code","b673312d":"code","04ab2397":"markdown","98801477":"markdown","08bc8011":"markdown","5383a806":"markdown","ac1a9523":"markdown"},"source":{"85e61efe":"%matplotlib inline\nfrom keras.datasets import mnist # For Loading the MNIST data\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 9]\nfrom sklearn.preprocessing import RobustScaler\nfrom keras.models import Sequential # To build a sequential model\nfrom keras.layers import Dense, LSTM, CuDNNLSTM, Dropout, BatchNormalization # For the layers in the model\nfrom keras.callbacks import EarlyStopping, TensorBoard #\u00a0For our early stopping and tensorboard callbacks\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport time","fe12bb37":"# Get MNIST data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nclasses = np.unique(y_train)\nclasses_str = [str(x) for x in classes]\nnb_classes = len(classes)\n\n# Normalise our data\nx_train = x_train \/ 255\nx_test = x_test \/ 255\n\n# Sample the training data\n#x_train, x_del, y_train, y_del = train_test_split(x_train, y_train, test_size=0.95, random_state=42)","ee423dd4":"# Apply corrections (to test data only)\ncorrections = {}\n\nfor (index, new_value) in corrections.items():\n    y_test[index] = new_value","2c2f2ab1":"# Function to display a single digit\ndef plot_single(label, pixels):\n    plt.figure(figsize=(5,3))\n    plt.title('Label is {label}'.format(label=label))\n    plt.imshow(pixels, cmap='gray')\n    plt.show()\n    \ndef display_single(x, y, index):\n    plot_single(y[index], x[index])\n    \ndisplay_single(x_train, y_train, 7)","fab428c8":"x_train.shape[1:]","4571e53c":"es_callback = EarlyStopping(patience = 2)\n\ninput_shape = x_train.shape[1:]\n\nmodel = Sequential()\nmodel.add(CuDNNLSTM(128, input_shape=(input_shape), return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(CuDNNLSTM(128))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=Adam(lr=0.001, amsgrad=False),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=128, epochs=50, callbacks=[es_callback])","a2d6e6e5":"print(f\"Validation Accuracy: {history.history['val_acc'][-1]}\")\n\n# Validation Accuracy: 0.9835 (256 in first LSTM layer, 32 in Dense layer)\n# Validation Accuracy: 0.9865 (256 in first LSTM layer, 64 in Dense layer)\n# Validation Accuracy: 0.985 (256 in first LSTM layer, 256 in 2nd LSTM layer, 64 in Dense layer)\n# Validation Accuracy: 0.9869 (256 in first LSTM layer, Dropout of 2nd LSTM set to 0.1, 64 in Dense layer, Patience = 2)\n# Validation Accuracy: 0.9858 (as above but with BatchNorm after each layer)","e62e2733":"predictions = model.predict_classes(x_test)\n\nincorrect_indexes = np.where(predictions != y_test)[0]\nprint(f\"There are {len(incorrect_indexes)} incorrect guesses out of {len(y_test)} images\")","3cc63ae7":"# Function to display a single digit (with guess)\ndef plot_single(label, predicted, pixels, index):\n    plt.title(f\"Index: {index}\\nPredicted value: {predicted}\\nActual value: {label}\")\n    plt.imshow(pixels, cmap='gray')\n    plt.axis('off')\n    \ndef display_single_predicted(x, y, predictions, index):\n    plot_single(y[index], predictions[index], x[index], index)\n    \ngrid_size = 4\nincorrect_sample = np.random.choice(incorrect_indexes, grid_size**2, replace=False)\nfor i in range(1, grid_size**2 + 1):\n    plt.subplot(grid_size, grid_size, i)\n    display_single_predicted(x_test, y_test, predictions, incorrect_sample[i-1])\n    \nplt.tight_layout()\nplt.show()","b673312d":"# Compute confusion matrix\ncm = confusion_matrix(y_test, predictions)\n\n# Plot normalized confusion matrix\ncm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\ncm[cm < 0.001] = np.nan\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(10,10))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.RdYlGn)\n#plt.clim(0.0001, 1);\nplt.title('Confusion matrix')\nplt.colorbar()\ntick_marks = np.arange(nb_classes)\nplt.xticks(tick_marks, classes)\nplt.yticks(tick_marks, classes)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()\n\nprint(classification_report(y_test, predictions, target_names=classes_str))","04ab2397":"# Investigate confusion Matrix","98801477":"To do:\n* Batch normalisation?\n","08bc8011":"#\u00a0Look at incorrect guesses","5383a806":"# Establish LSTM model structure\nAdd early stopping\n","ac1a9523":"# Initialise notebook"}}