{"cell_type":{"8ad050ea":"code","a65376b4":"code","1e688021":"code","286a26be":"code","1d17c3ab":"code","58c4d127":"code","a95ea1d2":"code","8ecdabe4":"code","a9bd1de7":"code","28891e1a":"code","c37f9d4e":"code","a44c159b":"code","51f49d98":"code","6a09fb02":"code","9721faba":"code","6251ff71":"code","7d368723":"code","128ccedc":"code","122b8c38":"code","9c92edea":"code","210d506b":"code","efc47985":"code","eb9ff500":"markdown"},"source":{"8ad050ea":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport random\nimport itertools\n\n\nfrom shutil import copyfile, rmtree\nfrom pathlib import Path\n\n\nfrom glob import glob\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input\/facial-age\/face_age'):\n#     print (dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix\n","a65376b4":"\nINPUT_CLASSES_DIR = '\/kaggle\/input\/facial-age\/face_age\/'\n\nfolders = glob(INPUT_CLASSES_DIR + '*')\n\nages_dict = {}\n\nfor dirname in folders:\n    ages_dict[dirname.rsplit('\/')[-1]] = len(os.listdir(dirname))\n\nprint ('Possible ages:')\nages_dict = dict(sorted(ages_dict.items()))\ndel[ages_dict['face_age']]","1e688021":"plt.figure(figsize=(30, 10))\n\nplt.bar(list(ages_dict.keys()), ages_dict.values(), color='g')\n\nplt.show()\n","286a26be":"age_splits = [1,5,12,19,35,45,65,111]\n\nage_splits_ranges = [[str(x).rjust(3,\"0\") for x in list(range(age_splits[idx],age_splits[idx+1]))] for idx in range(len(age_splits)-1)]\n\n\nage_groups = {}\n\nfor age_range in age_splits_ranges:\n    total = 0\n    for age in age_range:\n        if age in ages_dict:\n            total += ages_dict[age]\n    age_groups[f'{age_range[0]}-{age_range[-1]}'] = total\n    \n#age_groups\nplt.figure(figsize=(30, 10))\n\nplt.bar(list(age_groups.keys()), age_groups.values(), color='g')\n\nplt.show()\n","1d17c3ab":"age_groups","58c4d127":"MIN_COUNT_IN_CLASS = min(age_groups.values())\nMIN_COUNT_IN_CLASS = 40\nTRAIN_SAMPLE_SIZE = int(MIN_COUNT_IN_CLASS * 0.85 )\nTEST_SAMPLE_SIZE = MIN_COUNT_IN_CLASS - TRAIN_SAMPLE_SIZE","a95ea1d2":"test_root = '.\/test'\ntrain_root = '.\/train'\n\nrmtree(train_root, ignore_errors=True)\nrmtree(test_root, ignore_errors=True)\n\nage_groupped_filenames_dict = {}\n\nfor age_range in age_splits_ranges:\n    Path(f\"{test_root}\/{age_range[0]}-{age_range[-1]}\").mkdir(parents=True, exist_ok=True)\n    Path(f\"{train_root}\/{age_range[0]}-{age_range[-1]}\").mkdir(parents=True, exist_ok=True)\n    age_groupped_filenames = []\n    for age in age_range:\n        full_dirname = INPUT_CLASSES_DIR + age\n        age_groupped_filenames.extend(glob(full_dirname + '\/*'))\n    age_groupped_filenames_dict[f'{age_range[0]}-{age_range[-1]}'] = age_groupped_filenames\n    \nfor age_range in age_groupped_filenames_dict:\n    age_sample = random.sample(age_groupped_filenames_dict[age_range], MIN_COUNT_IN_CLASS)\n    train_filenames = age_sample[:TRAIN_SAMPLE_SIZE]\n    for f in train_filenames:\n        copyfile(f, f\"{train_root}\/{age_range}\/{f.split('\/')[-1]}\")\n        \n    \n    test_filenames = age_sample[TRAIN_SAMPLE_SIZE:]\n    for f in test_filenames:\n        copyfile(f, f\"{test_root}\/{age_range}\/{f.split('\/')[-1]}\")","8ecdabe4":"# useful for getting number of files\ntrain_files = glob(train_root + '\/*\/*.png')\ntest_files = glob(test_root + '\/*\/*.png')\n","a9bd1de7":"print(len(train_files))\nprint(len(test_files))\n","28891e1a":"plt.imshow(image.load_img(np.random.choice(train_files)))","c37f9d4e":"plt.imshow(image.load_img(np.random.choice(test_files)))\n","a44c159b":"# re-size all the images to this\nIMAGE_SIZE = [100, 100]\n\n# training config:\nepochs = 20\nbatch_size = 128\n\n\n# resnet base\nres = ResNet50(\ninput_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in res.layers:\n  layer.trainable = False\n\n# our layers - you can add more if you want\nx = Flatten()(res.output)\n# x = Dense(1000, activation='relu')(x) # example\nprediction = Dense(len(folders), activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=res.input, outputs=prediction)\n# tell the model what cost and optimization method to use\nmodel.compile(\nloss='sparse_categorical_crossentropy',\noptimizer='adam',\nmetrics=['accuracy'])","51f49d98":"# create an instance of ImageDataGenerator\ntrain_gen = ImageDataGenerator(\n  rotation_range=20,\n  width_shift_range=0.1,\n  height_shift_range=0.1,\n  shear_range=0.1,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  vertical_flip=True,\n  preprocessing_function=preprocess_input\n)\n\nval_gen = ImageDataGenerator(\n  preprocessing_function=preprocess_input\n)","6a09fb02":"# get label mapping for confusion matrix plot\ntest_gen = val_gen.flow_from_directory(test_root, target_size=IMAGE_SIZE)\nprint(test_gen.class_indices)\nlabels = [None] * len(test_gen.class_indices)\nfor k, v in test_gen.class_indices.items():\n  labels[v] = k","9721faba":"# create generators\ntrain_generator = train_gen.flow_from_directory(\n  train_root,\n  target_size=IMAGE_SIZE,\n  shuffle=True,\n  batch_size=batch_size,\n  class_mode='sparse',\n)\nvalid_generator = val_gen.flow_from_directory(\n  test_root,\n  target_size=IMAGE_SIZE,\n  shuffle=False,\n  batch_size=batch_size,\n  class_mode='sparse',\n)","6251ff71":"# fit the model\nr = model.fit(\n  train_generator,\n  validation_data=valid_generator,\n  epochs=epochs,\n  steps_per_epoch=len(train_files) \/\/ batch_size,\n  validation_steps=len(test_files) \/\/ batch_size,\n)","7d368723":"cm = get_confusion_matrix(train_root, len(train_files))\nprint(cm)\nvalid_cm = get_confusion_matrix(test_root, len(test_files))\nprint(valid_cm)","128ccedc":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n      cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n      print(\"Normalized confusion matrix\")\n  else:\n      print('Confusion matrix, without normalization')\n\n  print(cm)\n\n  plt.figure(figsize=(30, 30))\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n\n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() \/ 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(j, i, format(cm[i, j], fmt),\n               horizontalalignment=\"center\",\n               color=\"white\" if cm[i, j] > thresh else \"black\")\n\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  plt.show()","122b8c38":"plot_confusion_matrix(cm, labels, title='Train confusion matrix')\n","9c92edea":"import requests, io, cv2\nimport numpy as np\nfrom PIL import Image\n","210d506b":"URL = 'https:\/\/media.istockphoto.com\/photos\/cheerful-senior-man-picture-id153011771?k=20&m=153011771&s=612x612&w=0&h=vBUDBf5sjvvgoWn-2aeZaHb6E5iDg-yVBLOa2PruOSk='\nresponse = requests.get(URL)\nbytes_im = io.BytesIO(response.content)\ncv_im = cv2.cvtColor(np.array(Image.open(bytes_im)), cv2.COLOR_RGB2BGR)\n\ninternal_image = cv2.resize(cv_im,IMAGE_SIZE)\ninternal_image = internal_image.reshape(1,IMAGE_SIZE[0], IMAGE_SIZE[1],3) \n\n\nplt.imshow(internal_image[0])","efc47985":"p = model.predict(internal_image)\n#p = np.argmax(p)\npred_list = {x : float(y) for x,y in zip(labels, p[0])}\npred_list = dict(sorted(pred_list.items(), reverse=True, key=lambda item: item[1]))\npred_list","eb9ff500":"# Imports"}}