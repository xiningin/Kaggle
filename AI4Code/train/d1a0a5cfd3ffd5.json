{"cell_type":{"c6003bfb":"code","7cd29cd1":"code","7f5de2af":"code","e8c6d9d8":"code","65817ace":"code","8dca77a2":"code","e39651cc":"code","225292ec":"code","a89d90de":"code","cf573377":"code","f1d112b8":"code","5ad3f71d":"code","4ffd08e7":"code","54cbbbe5":"code","99e53a14":"code","0eae0869":"code","51d414d1":"code","120b1360":"code","cba0e8f5":"code","df718f50":"code","650c526c":"code","eaeab304":"markdown","a1818b2d":"markdown","cc7c9375":"markdown","d85b5597":"markdown","05c7a952":"markdown","63a4765c":"markdown","163a1dcc":"markdown"},"source":{"c6003bfb":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier\nimport optuna\nfrom sklearn.experimental import enable_iterative_imputer  \nfrom sklearn.impute import IterativeImputer\nimport warnings\nwarnings.filterwarnings('ignore')","7cd29cd1":"df = pd.read_csv('..\/input\/kfolds-song-comp\/train_folds.csv')\ndf_test = pd.read_csv('..\/input\/song-popularity-prediction\/test.csv')\nsample_submission = pd.read_csv('..\/input\/song-popularity-prediction\/sample_submission.csv')","7f5de2af":"df.head()","e8c6d9d8":"df.shape","65817ace":"df.isnull().sum()","8dca77a2":"df_test.shape","e39651cc":"df_test.isnull().sum()","225292ec":"useless_features = ['id','song_popularity','kfold']\nuseful_features = [f for f in df.columns if f not in useless_features]\nobject_cols = ['key','audio_mode','time_signature']\nnon_numerical_cols = object_cols + useless_features\nnumerical_cols = [c for c in df.columns if c not in non_numerical_cols  ]","a89d90de":"it_imputer = IterativeImputer(max_iter=10)\ntrain_iterimp = it_imputer.fit_transform(df[useful_features])\ntest_iterimp = it_imputer.transform(df_test[useful_features])","cf573377":"train_iterimp = pd.DataFrame(train_iterimp, columns = useful_features)\ntest_iterimp = pd.DataFrame(test_iterimp, columns = useful_features)","f1d112b8":"df = df.drop(useful_features, axis = 1)\ndf = pd.concat([df,train_iterimp], axis = 1)\ndf_test = df_test.drop(useful_features, axis = 1)\ndf_test = pd.concat([df_test,test_iterimp], axis = 1)\n","5ad3f71d":"df['f1']          = df['acousticness'].apply(lambda x:1 if x > 0.5 else 0)\ndf['f2']           = df['danceability'].apply(lambda x:1 if x > 0.5 else 0)\ndf['f3']       = df['energy'].apply(lambda x:1 if x>0.5 else 0)\ndf['f4']    = df['instrumentalness'].apply(lambda x:1 if x>0.09 else 0)\ndf['f5']            = df['liveness'].apply(lambda x:1 if x>0.2 else 0)\ndf['f6']            = df['loudness'].apply(lambda x:1 if x > -13 else 0)\ndf['f7']          = df['speechiness'].apply(lambda x:1 if x>0.25 else 0)\ndf_test['f1']          = df['acousticness'].apply(lambda x:1 if x > 0.5 else 0)\ndf_test['f2']           = df['danceability'].apply(lambda x:1 if x > 0.5 else 0)\ndf_test['f3']       = df['energy'].apply(lambda x:1 if x>0.5 else 0)\ndf_test['f4']    = df['instrumentalness'].apply(lambda x:1 if x>0.09 else 0)\ndf_test['f5']            = df['liveness'].apply(lambda x:1 if x>0.2 else 0)\ndf_test['f6']            = df['loudness'].apply(lambda x:1 if x > -13 else 0)\ndf_test['f7']          = df['speechiness'].apply(lambda x:1 if x>0.25 else 0)","4ffd08e7":"poly = preprocessing.PolynomialFeatures(degree=3, interaction_only=True, include_bias=False)\ntrain_poly = poly.fit_transform(df[numerical_cols])\ntest_poly = poly.fit_transform(df_test[numerical_cols])\n\ndf_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\ndf_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n\ndf = pd.concat([df, df_poly], axis=1)\ndf_test = pd.concat([df_test, df_test_poly], axis=1)\n","54cbbbe5":"final_predictions = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain['song_popularity']\n    yvalid = xvalid['song_popularity']\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    xtest = xtest[useful_features]\n    \n    scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n     \n    # Hyperparameter tuning using Optuna\n    learning_rate = 0.02859668002863679\n    reg_lambda = 0.00012042589601632438\n    reg_alpha = 16.683659682374774\n    subsample = 0.4464941229852304\n    colsample_bytree =0.5235019404878758\n    max_depth = 4\n\n    \n    model = XGBClassifier(random_state=42,\n#         tree_method=\"gpu_hist\",\n#         gpu_id=1,\n#         predictor=\"gpu_predictor\",\n        n_estimators=7000,\n       learning_rate=learning_rate,\n         reg_lambda=reg_lambda,\n         reg_alpha=reg_alpha,\n         subsample=subsample,\n         colsample_bytree=colsample_bytree,\n         max_depth=max_depth)\n        \n    model.fit(xtrain, ytrain,early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000 )\n    preds_valid = model.predict_proba(xvalid)\n    test_preds = model.predict_proba(xtest)[:,1]\n    final_predictions.append(test_preds)\n    print(fold, roc_auc_score(yvalid, preds_valid[:,1]))","99e53a14":"# def run(trial):\n#     fold = 0\n   \n#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n#     reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n#     reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n#     subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n#     colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n#     max_depth = trial.suggest_int(\"max_depth\", 1, 7)\n    \n    \n#     xtrain =  df[df.kfold != fold].reset_index(drop=True)\n#     xvalid = df[df.kfold == fold].reset_index(drop=True)\n#     xtest = df_test.copy()\n\n#     ytrain = xtrain['song_popularity']\n#     yvalid = xvalid['song_popularity']\n\n#     xtrain = xtrain[useful_features]\n#     xvalid = xvalid[useful_features]\n#     xtest = xtest[useful_features]\n    \n#     scaler = preprocessing.StandardScaler()\n#     xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n#     xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n#     xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n\n\n#     model = XGBClassifier(random_state=42,\n#         tree_method=\"gpu_hist\",\n#         gpu_id=1,\n#         predictor=\"gpu_predictor\",\n#         n_estimators=7000,\n#         learning_rate=learning_rate,\n#         reg_lambda=reg_lambda,\n#         reg_alpha=reg_alpha,\n#         subsample=subsample,\n#         colsample_bytree=colsample_bytree,\n#         max_depth=max_depth)\n    \n#     model.fit(xtrain, ytrain,early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000 )\n#     preds_valid = model.predict_proba(xvalid)\n#     return roc_auc_score(yvalid, preds_valid[:,1])","0eae0869":"# study = optuna.create_study(direction=\"maximize\")\n# study.optimize(run, n_trials=100)","51d414d1":"# study.best_params","120b1360":"preds = np.mean(np.column_stack(final_predictions), axis=1)","cba0e8f5":"preds","df718f50":"sample_submission['song_popularity'] = preds\nsample_submission.to_csv(\"submission.csv\", index=False)","650c526c":"sample_submission","eaeab304":"# Hyperparameter Tuning using Optuna","a1818b2d":"# Polynomial Features","cc7c9375":"# Loading Dataset","d85b5597":"# Importing Libraries","05c7a952":"# Submission","63a4765c":"# Feature Engineering","163a1dcc":"# The Magic"}}