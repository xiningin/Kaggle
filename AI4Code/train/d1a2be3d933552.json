{"cell_type":{"bfc8cf9a":"code","031445f6":"code","40241104":"code","64c4902c":"code","a89745c9":"code","24ae9d93":"code","0e0e8cab":"code","91c2d830":"code","1d66ddeb":"markdown","4d46d71e":"markdown","9701fe71":"markdown","6fd7dcb0":"markdown","e24296d9":"markdown","ac91ac1b":"markdown","4c9b75c4":"markdown","85bcbd73":"markdown","0cdf1e0a":"markdown","04042399":"markdown","b1c0246f":"markdown","c2da7c15":"markdown","7aa2ccbb":"markdown"},"source":{"bfc8cf9a":"import numpy as np \nimport tensorflow as tf\nimport tensorflow_hub as hub # <--- To load our transfer learning model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","031445f6":"!pip install split-folders","40241104":"import splitfolders as sf\n\n# Split the data 80\/20 into training and validation sets. Save the split data in a folder called \"fish\".\nsf.ratio(\"..\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset\", ratio=(0.8, 0.2), output=\"fish\", seed=42)","64c4902c":"# First we create our data generators. We need separate objects for training and validation since we \n# want to apply augmentation to our training data but not our validation set.\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=180,\n    shear_range=0.3,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode=\"nearest\"\n)\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# We then grab our data from their respective folders.\ntrain_generator = train_datagen.flow_from_directory(\n    \"fish\/train\",\n    target_size=(300, 300),\n    class_mode=\"categorical\"\n)\nval_generator = val_datagen.flow_from_directory(\n    \"fish\/val\",\n    target_size=(300, 300),\n    class_mode=\"categorical\"\n)","a89745c9":"control_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(300, 300, 3)), \n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3)), \n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(256, activation=\"relu\"),\n    tf.keras.layers.Dense(9, activation=\"softmax\")\n])\ncontrol_model.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"acc\"]\n)\ncontrol_model.summary()","24ae9d93":"tl_model = tf.keras.Sequential([\n    hub.KerasLayer(\"https:\/\/tfhub.dev\/google\/imagenet\/inception_v3\/feature_vector\/5\",\n                   trainable=False),                 # Lock the layer from being updated during training  \n    tf.keras.layers.Dense(256, activation=\"relu\"),  # Same top layers as control\n    tf.keras.layers.Dense(9, activation='softmax') \n])\ntl_model.build([None, 300, 300, 3])\ntl_model.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"acc\"]\n)\ntl_model.summary()","0e0e8cab":"control_model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator\n)","91c2d830":"tl_model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator\n)","1d66ddeb":"Finally, we can train our two models and see how they stack up.","4d46d71e":"Next, we'll declare our transfer learning model. We use the ``hub.KerasLayer()`` method to download our pre-trained layer from its source. For the sake of simplicity, we'll lock this layer for now to prevent it from being updated during training. Later we will look at how to tweak the pre-trained layers.","9701fe71":"# Training the models","6fd7dcb0":"First we'll create our \"control\" model from scratch. We'll use a basic convolutional net with two convolutional layers each followed by a max pooling layer followed by a 10% dropout layer. We'll use the same set of dense layers as the top for each of our models.","e24296d9":"Even after the first epoch we see a validation accuracy three times that of our control model. After 10 epochs of training we have over 90% validation accuracy and almost no signs of overfitting.","ac91ac1b":"Here I will demonstrate how to use transfer learning in TensorFlow. For more info on transfer learning you can check out [this article](https:\/\/machinelearningmastery.com\/transfer-learning-for-deep-learning\/) for a decent intro. Basically, transfer learning is using another, pretrained model as a starting point for a new model. This can be advantageous in several ways, not the least of which being that you are spared the lion's share of training a robust model. Training a good image classification model can be particularly arduous making the transfer learning paradigm a must for any competent deep learning practitioner to have in their toolbelt. In TensorFlow, this is most easily done using TensorFlow Hub.","4c9b75c4":"To see how transfer learning models can drastically speed up your training process, we will build two convolutional networks to classify a set of images; one from scratch and the other using a slimmed-down version of the [Inception 3](https:\/\/tfhub.dev\/google\/imagenet\/inception_v3\/feature_vector\/5) image classification model used for extracting feature vectors as a base for our own image classifier. We'll train each model for 10 epochs and see which one produces better results. For our image data, we'll use [this](https:\/\/www.kaggle.com\/crowww\/a-large-scale-fish-dataset) dataset from Kaggle containing labelled images of fish. ","85bcbd73":"# Preprocessing the Data","0cdf1e0a":"# Creating the Models","04042399":"Now we've seen the remarkable results that can be gained by building off pf the sturdy platforms provided by the hard work of others. While it may feel a little like cheating, transfer learning is an invaluable tool that is not only extremely functional but also highly flexible. I like to think of them like suits off the rack. You can get a pretty good fit just by finding one in your size and you can always have it tailored to get an even better fit. Soon, I'll dive into how transfer learning models can be improved to get even better results. Stay tuned!","b1c0246f":"Before creating our models, we'll prepare our data. We first need to separate our data into training and validation sets. For this we can use the [split-folders](https:\/\/pypi.org\/project\/split-folders\/) library. We'll then use the [ImageDataGenerator](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator) class from the preprocessing package in Keras to load and apply transformations such as rescaling and augmentation to our images without altering them on-disk.","c2da7c15":"# Conclusion","7aa2ccbb":"After 10 training epochs we still see only very poor results with our homemade CNN. Our validation accuracy maxes out at about 30% around epoch 5 and backslides as the model appears to become more overfit. Obviously there is a lot more work to be done to make this model presentable. Next, let's see how our transfer learning model performs."}}