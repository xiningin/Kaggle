{"cell_type":{"af95b0b7":"code","c37c1946":"code","92ef2998":"code","0e6956ed":"code","a0e10333":"code","d904b494":"code","3e678ba8":"code","d2a91fa5":"code","e00365a9":"code","8949a0b5":"code","a15dcaf0":"code","79170d62":"code","71bb86f7":"code","1176d444":"code","eeadcb52":"code","3b1b414c":"code","a7512306":"code","3d27a343":"code","dd757bd2":"code","02816f34":"code","09ee6255":"code","36116705":"code","98fd469f":"code","6856325a":"code","139ade6f":"code","be185d77":"code","2e945a97":"markdown","c07318bb":"markdown","d46989e6":"markdown","b8b615ad":"markdown"},"source":{"af95b0b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c37c1946":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as plt\nimport tensorflow as tf\nimport nltk\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\nfrom sklearn.model_selection import train_test_split\nprint(tf.__version__)","92ef2998":"MIXED_PRECISION = True\nXLA_ACCELERATE  = False # Didn't work; Dunno Why!\n\nGPUS = tf.config.experimental.list_physical_devices('GPU')\nif GPUS:\n    try:\n        for GPU in GPUS:\n            tf.config.experimental.set_memory_growth(GPU, True)\n            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n            print(len(GPUS), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n    except RuntimeError as  RE:\n        print(RE)\n\nif MIXED_PRECISION:\n    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    tf.keras.mixed_precision.experimental.set_policy(policy)\n    print('Mixed precision enabled')\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')\n    \nstrategy = tf.distribute.get_strategy()\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}') \nprint(\"Tensorflow version \" + tf.__version__)","0e6956ed":"train= pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip')\ntest= pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')\ntest_labels= pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test_labels.csv.zip')\nsample_submission= pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/sample_submission.csv.zip')","a0e10333":"print(\"train datas\")\nprint(train.head())\n\n\nprint('----------------------------')\nprint(\"Test data\")\nprint(test.head())\n\n\nprint('----------------------------')\nprint('Test Labels')\nprint(test_labels.head())","d904b494":"train.info()","3e678ba8":"sample_submission.head()","d2a91fa5":"toxic_text= train.loc[train['toxic']==1]\ntoxic_text","e00365a9":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\ncomments = train['comment_text'].loc[train['toxic']].values\nwordcloud = WordCloud(\n    width = 640,\n    height = 640,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(comments))\nfig = plt.figure(\n    figsize = (12, 8),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","8949a0b5":"\ncomments = test['comment_text'].values\nwordcloud = WordCloud(\n    width = 640,\n    height = 640,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(comments))\nfig = plt.figure(\n    figsize = (12, 8),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","a15dcaf0":"values= train['comment_text'].values\n#sentences= nltk.tokenize.sent_tokenize(values)\nfor sentence in values:\n    sentences= nltk.tokenize.sent_tokenize(sentence)\n    for text in sentences:\n        print(text)\n","79170d62":"toxic_texts= train['comment_text'].loc[train['toxic']==1].values\nline=[]\nfor sentence in toxic_texts:\n    sentences= nltk.tokenize.sent_tokenize(sentence)\n    for text in sentences:\n        print(text)\n        line.append(text)\n","71bb86f7":"wordcloud = WordCloud(\n    width = 640,\n    height = 640,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(line))\nfig = plt.figure(\n    figsize = (12, 8),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","1176d444":"print(train.toxic.value_counts())\nsns.countplot(train.toxic)","eeadcb52":"print(test_labels.toxic.value_counts())\nsns.countplot(test_labels.toxic)","3b1b414c":"train_data=train[['comment_text','toxic' ]]","a7512306":"def get_ax(rows=1, cols=2, size=7):\n    \"\"\"Return a Matplotlib Axes array to be used in\n    all visualizations in the notebook. Provide a\n    central point to control graph sizes.\n    \n    Adjust the size attribute to control how big to render images\n    \"\"\"\n    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n    return fig, ax","3d27a343":"fig, ax = get_ax()\n\nsns.distplot(train_data[train_data['toxic']==0]['comment_text'].str.len(), axlabel=\"Non Toxic\", ax=ax[0])\nsns.distplot(train_data[train_data['toxic']==0]['comment_text'].str.split().str.len(), axlabel=\"Non Toxic\", ax=ax[1])\n\nfig.show()","dd757bd2":"fig, ax = get_ax()\n\nsns.distplot(train_data[train_data['toxic']==1]['comment_text'].str.len(), axlabel=\"Toxic\", ax=ax[0])\nsns.distplot(train_data[train_data['toxic']==1]['comment_text'].str.split().str.len(), axlabel=\"Toxic\", ax=ax[1])\n\nfig.show()","02816f34":"label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n# Assigned to count all clean comments\nvalue_counts_0 = []\n# Assigned to count all offensive comments\nvalue_counts_1 = []\n\nfor col in label_columns:\n  value_counts_0.append(train[col].value_counts()[0])\n  value_counts_1.append(train[col].value_counts()[1])\n\nprint(\"Number of clean comments:\",value_counts_0)\nprint(\"Number of offensive comments:\",value_counts_1)","09ee6255":"def plot_toxicity(labels,count,ylabel,xlabel,subtitle):\n    fig = plt.figure(figsize = (10, 5)) \n\n    # creating the bar plot \n    plt.bar(labels,count, color=['#422680','#341671','#280659','#660F56','#AE2D67','#F54952'],  width = 0.5) \n\n    plt.xlabel(xlabel,fontweight ='bold',fontname='Monsterrat') \n    plt.ylabel(ylabel,fontweight ='bold',fontname='Monsterrat') \n    plt.title(subtitle,fontweight ='bold',fontname='Comic Sans MS') \n\n    for x,y in zip(labels,count):\n\n        label = \"{:}\".format(y)\n\n        plt.annotate(label, # this is the text\n                     (x,y), # this is the point to label\n                     textcoords=\"offset points\", # how to position the text\n                     xytext=(0,3), # distance from text to points (x,y)\n                     ha='center') # horizontal alignment can be left, right or c\n    \n    plt.show() \n\nplot_toxicity(label_columns,value_counts_0,\"No. of occurences\",\"Type of toxicity\",\"Clean Comments\")\nplot_toxicity(label_columns,value_counts_1,\"No. of occurences\",\"Type of toxicity\",\"Toxicity Distribution\")","36116705":"offensive= train.iloc[:, 2:].sum()\nrow_sum= train.iloc[:, 2:].sum(axis=1)\n\ntrain['clean']= (row_sum ==0)\nprint('Total Comments:', len(train))\nprint('Total clean comments:', train['clean'].sum())\nprint('Offensive texts:', offensive.sum())","98fd469f":"clean_lines= train[train['clean']==True]\noffensive_lines= train[train['clean']==False]","6856325a":"def cal_len(data):\n    return len(data)\n\n#Create generic plotter with Seaborn\ndef plot_count(count_ones,count_zeros,title_1,title_2,subtitle):\n    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,10))\n    sns.distplot(count_zeros,ax=ax1,color='#422680')\n    ax1.set_title(title_1)\n    sns.distplot(count_ones,ax=ax2,color='#F54952')\n    ax2.set_title(title_2)\n    fig.suptitle(subtitle)\n    plt.show()    \n\n\ncount_clean_words=clean_lines['comment_text'].str.split().apply(lambda z:cal_len(z))\ncount_offensive_words=offensive_lines['comment_text'].str.split().apply(lambda z:cal_len(z))\nplot_count(count_clean_words,count_offensive_words,\"Clean Words\",\"Offensive words\",\"Comments Word Analysis\")","139ade6f":"import string\ncount_clean_punctuations=clean_lines['comment_text'].apply(lambda z: len([c for c in str(z) if c in string.punctuation]))\ncount_offensive_punctuations=offensive_lines['comment_text'].apply(lambda z:len([c for c in str(z) if c in string.punctuation]))\nplot_count(count_clean_punctuations,count_offensive_punctuations,\"Clean Comments Punctuations\",\"Offensive Comments Punctuations\",\"Comments Word Punctuation Analysis\")","be185d77":"y=train[['toxic', 'severe_toxic']].values\ntrain_sentence= train['comment_text']\ntest_sentence= test['comment_text']","2e945a97":"Took lot of help from https:\/\/www.kaggle.com\/sbongo\/for-beginners-tackling-toxic-using-keras and https:\/\/www.kaggle.com\/metrisrashmi\/toxic-comments-problem-novice-s-approach.\n***Please sure do comment. Any suggestion will be very handy.***","c07318bb":"## Lets See word Density","d46989e6":"# Import Necessary Libraries","b8b615ad":"## Lets see the WordCloud"}}