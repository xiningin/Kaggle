{"cell_type":{"48fefd1d":"code","7a5d850f":"code","706a88fb":"code","0e7c79d8":"code","9a412cc4":"code","0b9c15b3":"code","c8618e4a":"code","3eef9b2f":"code","c5194c5c":"code","6f29f450":"code","7299b0fc":"code","a06dc7f8":"code","56d17067":"code","bf58d37e":"code","e3641a3f":"code","a5f09868":"code","e564473d":"code","2fcde29b":"code","08446759":"code","8539d3ef":"code","376deb65":"code","ca3389be":"code","cb3856b0":"code","ef743253":"code","abe78bd1":"code","7e1015f4":"code","93b80812":"code","42dd0649":"code","3d5fc9b0":"code","9c8a0c29":"code","d68cf986":"code","c3da9b5c":"code","0fa5165a":"code","f7207954":"code","f8588d3e":"code","9ea4cf17":"code","6b8933d0":"code","1d5b8f59":"code","5d93ea30":"code","f6aecc8e":"code","5cc442d3":"code","6d38fd74":"code","9fd54b19":"code","bbb23703":"code","3ad4a9fb":"code","847e46cf":"code","58b5c2da":"code","0d0dabf7":"code","b4716a8b":"code","48fd13e5":"code","f79b6f03":"code","3e1965d4":"code","b719196e":"code","5c2abb78":"code","1c259d73":"code","9033e105":"code","32fd5c6a":"markdown","1fdcfa59":"markdown","f962eeba":"markdown","1625dfb5":"markdown","4020c6fb":"markdown","7ac5cdfc":"markdown","16239789":"markdown","b98472da":"markdown","3459da00":"markdown","8d4df3b3":"markdown","7b1a60dd":"markdown","a32e04f9":"markdown","03b3d604":"markdown","26487edb":"markdown","2a179f55":"markdown","69b25734":"markdown","6d4bac80":"markdown","4088d3fd":"markdown","a1349d4c":"markdown","e30b97c9":"markdown","7cb8b74d":"markdown","845eee18":"markdown","46123238":"markdown","db7d0d29":"markdown","f33c4fdd":"markdown","ac7fff5c":"markdown","7090d451":"markdown"},"source":{"48fefd1d":"#preparing kaggle for pyspark\n!pip install pyspark","7a5d850f":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n\n\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession, SQLContext\n\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import col\n\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\n\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import GBTClassifier\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nprint(\"Import completed\")","706a88fb":"spark = SparkSession.builder.master(\"local\").appName(\"soddisfazione-passeggeri\").getOrCreate()\nsc = spark.sparkContext\nsqlContext = SQLContext(spark.sparkContext)\n\nprint(spark, sc, sqlContext)","0e7c79d8":"airline_test_dataset = \"..\/input\/airline-passenger-satisfaction\/test.csv\"\nairline_train_dataset = \"..\/input\/airline-passenger-satisfaction\/train.csv\"\n\nprint(\"Datasets imported\")","9a412cc4":"original_test_df = spark.read.csv(path=airline_test_dataset, inferSchema =True, header=True).cache()\noriginal_train_df = spark.read.csv(path=airline_train_dataset, inferSchema =True, header=True).cache()\n\n#merge test and train dataframes\nfull_df = original_test_df.union(original_train_df) \n\n#show a summary of dataframe\nfull_df.summary().show()","0b9c15b3":"#Clean the dataframe from id e number _c0 features, which are useless.\nfull_df = full_df.drop(\"_c0\",\"id\") \n\nprint(\"Cleaned\")","c8618e4a":"#Counting null values in Arrival Delay in Minutes\nfull_df.filter(col(\"Arrival Delay in Minutes\").isNull()).count()","3eef9b2f":"#Fill missing arrival delay values with column mean\nfull_df = full_df.fillna({\"Arrival Delay in Minutes\":'15.1'})\n\nprint(\"Filled, now null values count is: \",full_df.filter(col(\"Arrival Delay in Minutes\").isNull()).count())","c5194c5c":"#Replace blank characters with underscore\nreplacements = {c:c.replace(' ','_') for c in full_df.columns if ' ' in c}\n\n#Replace satisfied with '1', neutral or dissatisfied with '0'\nfull_df = full_df.withColumn(\"satisfaction\", F.when(F.col(\"satisfaction\")==\"satisfied\", 1).otherwise(F.col(\"satisfaction\")))\nfull_df = full_df.withColumn(\"satisfaction\", F.when(F.col(\"satisfaction\")==\"neutral or dissatisfied\", 0).otherwise(F.col(\"satisfaction\")))\n\n#Cast String type of satisfaction column into Integer type\nfull_df = full_df.withColumn(\"satisfaction\",col(\"satisfaction\").cast(IntegerType()))\n\nprint(\"renamed\")\n\nfull_df.dtypes","6f29f450":"pandas_full_df = full_df.toPandas()\nplt.figure(figsize=(13,13))\nsns.heatmap(abs(pandas_full_df.corr()), cmap = 'Blues', annot=True, fmt=\".2f\")","7299b0fc":"fig = plt.figure(figsize = (10,7))\nplt.scatter(pandas_full_df['Departure Delay in Minutes'], pandas_full_df['Arrival Delay in Minutes'], alpha = 0.1)\n\nplt.xlabel(\"Departure Delay in Minutes\")\nplt.ylabel(\"Arrival Delay in Minutes\")","a06dc7f8":"#Drop Arrival delay in minutes, since it is highly correlated with other column\n\nfull_df = full_df.drop(\"Arrival Delay in Minutes\") \n\nprint(\"dropped Arrival Delay in Minutes\")","56d17067":"abs(pandas_full_df.corr()['satisfaction']).sort_values().drop('satisfaction').plot(kind='barh')","bf58d37e":"import plotly.express as px\nfig = px.sunburst(pandas_full_df, path=[\"satisfaction\",'Type of Travel','Class', 'Customer Type'],color_continuous_scale='RdBu')\nfig.show()","e3641a3f":"g= sns.FacetGrid(pandas_full_df,col=\"satisfaction\")\ng.map(sns.distplot,\"Age\",bins=25)\nplt.show()\n# 0=neutral or dissatisfied, 1=satisfied ","a5f09868":"#Missing categorical columns\npandas_full_df.hist(bins=50, figsize=(20,15))","e564473d":"g=sns.catplot(x=\"Customer Type\",y=\"satisfaction\",data=pandas_full_df,kind=\"bar\",height=6, palette=\"Blues\")\ng.set_ylabels(\"Satisfaction Probability\")\nplt.show()","2fcde29b":"g=sns.catplot(x=\"Class\",y=\"satisfaction\",data=pandas_full_df,kind=\"bar\",height=6, palette=\"Blues\")\ng.set_ylabels(\"Satisfation Probability\")\nplt.show()","08446759":"#Rename the satisfaction column as label for easier manipulation\nfull_df = full_df.withColumnRenamed(\"satisfaction\",\"label\")\n\n#Merge train and test dataframes into a single one for easier manipulation\ntrain_df, test_df = full_df.randomSplit([0.7, 0.3], seed=30)\n\nprint(f\"Train set length: {train_df.count()} entries\")\nprint(f\"Test set length: {test_df.count()} entries\")","8539d3ef":"#Select only categorical features excluding the label satisfaction\ncatCols = [x for (x, dataType) in full_df.dtypes if ((dataType ==\"string\") & (x !=\"label\"))]\nnumCols = [x for (x, dataType) in full_df.dtypes if ((dataType !=\"string\") & (x !=\"label\"))]\n\nprint(catCols)\nprint(numCols)","376deb65":"#recap of datatypes\ntrain_df.dtypes","ca3389be":"#from pyspark.ml.feature import (StringIndexer, OneHotEncoder)\n\nstring_indexer = [\n    StringIndexer(inputCol=x, outputCol=x + \"_StringIndexer\", handleInvalid=\"skip\")\n    for x in catCols\n]\nstring_indexer","cb3856b0":"one_hot_encoder = [\n    OneHotEncoder(\n        inputCols=[f\"{x}_StringIndexer\" for x in catCols],\n        outputCols=[f\"{x}_OneHotEncoder\" for x in catCols]\n    )\n]\n\none_hot_encoder","ef743253":"#from pyspark.ml.feature import VectorAssembler\n\nassemblerInput = [x for x in numCols]\nassemblerInput += [f\"{x}_OneHotEncoder\" for x in catCols]\n\nassemblerInput","abe78bd1":"vector_assembler = VectorAssembler(\n    inputCols = assemblerInput, outputCol=\"features\"\n)\n\nvector_assembler","7e1015f4":"#from pyspark.ml.classification import LogisticRegression\n\nlr = LogisticRegression()","93b80812":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , lr] #Must be inserted as list\n\nstages","42dd0649":"#from pyspark.ml import Pipeline\n\npipeline = Pipeline().setStages(stages)\nmodel_pp_lr = pipeline.fit(train_df)\npredictions_pp_lr = model_pp_lr.transform(test_df)\n\nprint(\"pipeline completed\")","3d5fc9b0":"predictions_pp_lr.select(\"features\", \"rawPrediction\", \"probability\", \"prediction\",\"label\").show()","9c8a0c29":"#show\npredictions_pp_lr.summary()","d68cf986":"#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nprint('PySpark Area Under ROC', evaluator.evaluate(predictions_pp_lr))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_lr, {evaluator.metricName: \"areaUnderPR\"})))","c3da9b5c":"model_pp_lr.stages[-1].summary.pr.show()","0fa5165a":"#from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nprint('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_lr))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_lr))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_lr))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_lr))","f7207954":"trainingSummary = model_pp_lr.stages[-1].summary\nroc = trainingSummary.roc.toPandas()\nplt.plot(roc['FPR'],roc['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\nprint('AreaUnderROC: ' + str(trainingSummary.areaUnderROC))","f8588d3e":"pr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.title('PR Curve')\nplt.show()","9ea4cf17":"rmse = evaluator.evaluate(predictions_pp_lr)\nprint(\"RMSE: %g\" % rmse)","6b8933d0":"#from pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(maxDepth = 3)\n","1d5b8f59":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , dt] \n\nstages","5d93ea30":"pipeline = Pipeline().setStages(stages)\nmodel_pp_dt = pipeline.fit(train_df)\npredictions_pp_dt = model_pp_dt.transform(test_df)\n\nprint(\"pipeline completed\")","f6aecc8e":"evaluator = BinaryClassificationEvaluator()\n\nprint(\"Area Under ROC: \" + str(evaluator.evaluate(predictions_pp_dt, {evaluator.metricName: \"areaUnderROC\"})))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_dt, {evaluator.metricName: \"areaUnderPR\"})))","5cc442d3":"print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_dt))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_dt))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_dt))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_dt))","6d38fd74":"rmse = evaluator.evaluate(predictions_pp_dt)\nprint(\"RMSE: %g\" % rmse)","9fd54b19":"#from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')","bbb23703":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , rf]\n\nstages","3ad4a9fb":"pipeline = Pipeline().setStages(stages)\nmodel_pp_rf = pipeline.fit(train_df)\npredictions_pp_rf = model_pp_rf.transform(test_df)\n\nprint(\"pipeline completed\")","847e46cf":"evaluator = BinaryClassificationEvaluator()\n\nprint(\"Area Under ROC: \" + str(evaluator.evaluate(predictions_pp_rf, {evaluator.metricName: \"areaUnderROC\"})))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_rf, {evaluator.metricName: \"areaUnderPR\"})))","58b5c2da":"print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_rf))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_rf))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_rf))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_rf))","0d0dabf7":"trainingSummary = model_pp_rf.stages[-1].summary\nroc = trainingSummary.roc.toPandas()\nplt.plot(roc['FPR'],roc['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n\nprint('AreaUnderROC: ' + str(trainingSummary.areaUnderROC))","b4716a8b":"pr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.title('PR Curve')\n\nplt.show()","48fd13e5":"rmse = evaluator.evaluate(predictions_pp_rf)\nprint(\"RMSE: %g\" % rmse)","f79b6f03":"#from pyspark.ml.classification import GBTClassifier\n\ngbt = GBTClassifier(maxIter=10)","3e1965d4":"stages = []\nstages += string_indexer\nstages += one_hot_encoder\nstages += [vector_assembler , gbt] \n\nstages","b719196e":"pipeline = Pipeline().setStages(stages)\nmodel_pp_gbt = pipeline.fit(train_df)\npredictions_pp_gbt = model_pp_gbt.transform(test_df)\n\nprint(\"pipeline completed\")","5c2abb78":"evaluator = BinaryClassificationEvaluator()\n\nprint(\"Area Under ROC: \" + str(evaluator.evaluate(predictions_pp_gbt, {evaluator.metricName: \"areaUnderROC\"})))\nprint(\"Area Under PR: \" + str(evaluator.evaluate(predictions_pp_gbt, {evaluator.metricName: \"areaUnderPR\"})))","1c259d73":"print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='label',metricName='accuracy').evaluate(predictions_pp_gbt))\nprint('Precision: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedPrecision').evaluate(predictions_pp_gbt))\nprint('Recall: ',MulticlassClassificationEvaluator(labelCol='label',metricName='weightedRecall').evaluate(predictions_pp_gbt))\nprint('f1: ',MulticlassClassificationEvaluator(labelCol='label',metricName='f1').evaluate(predictions_pp_gbt))","9033e105":"rmse = evaluator.evaluate(predictions_pp_gbt)\nprint(\"RMSE: %g\" % rmse)","32fd5c6a":"# Heatmap analysis ","1fdcfa59":"What influences satisfaction?","f962eeba":"Class & Satisfaction","1625dfb5":"Customer Type & Satisfaction","4020c6fb":"# Transform categorical variables\n\nLabel encoding assigns each unique value to a different integer.","7ac5cdfc":"# Merge test and train csv into a single dataframe","16239789":"# Data types manipulation","b98472da":"# Pipeline creation","3459da00":"# AUC","8d4df3b3":"# Data cleaning","7b1a60dd":"# \ud83c\udf84 Gradient-boosted tree classifier","a32e04f9":"Import onehot encoder and string indexer. OnehotEncoder is used because I don't want the model to see some sort of unrelated ordering.","03b3d604":"Arrival Delay in Minutes and Departure Delay in Minutes are highly correlated. One of them can be dropped","26487edb":"# IMPORTING DATASET","2a179f55":"> ","69b25734":"vector assembler to be used by the machine model. transform all the features in a single vector\n","6d4bac80":"# DATA Visualization","4088d3fd":"# create spark session","a1349d4c":"# TRAIN TEST SPLIT","e30b97c9":"# \ud83c\udf32\ud83c\udf34\ud83c\udf33 Random forest ","7cb8b74d":"# Logistic regression","845eee18":"# TREES \ud83c\udf33","46123238":"As shown in summary, all features have 129880 values, just **\"Arrival Delay in Minutes\"** has 129487. Its mean value is 15.09112883918849","db7d0d29":"# \ud83c\udf33 Decision tree classifier","f33c4fdd":"ROC evaluation with PySpark.","ac7fff5c":"# importing","7090d451":"Age & Satisfaction"}}