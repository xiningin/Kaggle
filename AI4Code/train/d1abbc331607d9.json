{"cell_type":{"5a4878a6":"code","8d931d34":"code","f9d28d4e":"code","3917179c":"code","91b3d9ce":"code","82305505":"code","227abc5b":"code","46b95d2a":"code","8c46d5f6":"code","0139d135":"code","7cfc4fef":"code","402d1b85":"code","b5d71719":"code","fd58072d":"code","4ca21fb9":"code","6cb430ab":"code","30ee121d":"code","769c2108":"code","67772d23":"markdown","238c1b92":"markdown"},"source":{"5a4878a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_rows',300)\npd.set_option('display.min_rows',1)\npd.set_option('display.max_columns',300)\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegressionCV, LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d931d34":"# load train and test data\ndf=pd.read_csv('..\/input\/titanic\/train.csv')\ndf.set_index('PassengerId', inplace=True)\ndf_test=pd.read_csv('..\/input\/titanic\/test.csv')\ndf.head()","f9d28d4e":"plt.rcParams['figure.figsize']=[10,7]\ndf.hist(bins=50)","3917179c":"# see which field, if any, contains missing values\ndf_test.isnull().any()","91b3d9ce":"# create features\nDF=pd.DataFrame(index=df.index)\nDF.loc[:, 'survived'] = df.Survived                                           \nDF.loc[:, 'class1']=(df.Pclass==1).astype(int) \nDF.loc[:, 'class2']=(df.Pclass==2).astype(int)\nDF.loc[:, 'class3']=(df.Pclass==3).astype(int)\nDF.loc[:, 'sex1'] = (df.Sex=='female').astype(int)\nDF.loc[:, 'sex1_single'] = df.Name.str.contains('Miss').astype(int)\nDF.loc[:, 'sex1_married'] = df.Name.str.contains('Mrs').astype(int)\nDF.loc[:, 'sex2'] = (df.Sex=='male').astype(int)\nDF.loc[:, 'class1sex1'] = ((df.Pclass==1) & (df.Sex=='female')).astype(int)\nDF.loc[:, 'class1sex2'] = ((df.Pclass==1) & (df.Sex=='male')).astype(int)\nDF.loc[:, 'class2sex1'] = ((df.Pclass==2) & (df.Sex=='female')).astype(int)\nDF.loc[:, 'class2sex2'] = ((df.Pclass==2) & (df.Sex=='male')).astype(int)\nDF.loc[:, 'class3sex1'] = ((df.Pclass==3) & (df.Sex=='female')).astype(int)\nDF.loc[:, 'class3sex2'] = ((df.Pclass==3) & (df.Sex=='male')).astype(int)\nDF.loc[:, 'is_master'] = df.Name.str.contains('Master').astype(int)\nDF.loc[:, 'sibSp'] = df.SibSp\nDF.loc[:, 'Parch'] = df.Parch\nDF.loc[:, 'fare'] = df.Fare\nDF.loc[:,'fare1']=np.tanh(DF.fare\/30)\nDF.loc[:, 'age'] = df.Age.fillna(0)\nDF.loc[:,'age1']=np.tanh(DF.age\/30)\nDF.loc[:, 'age_ischild'] = ((df.Age>0) & (df.Age<10)).astype(int)\nDF.loc[:, 'age_iselder'] = (df.Age>50).astype(int)\nDF.loc[:,'age_missing'] = df.Age.isnull().astype(int)\nDF.loc[:,'emb_C'] = (df.Embarked=='C').astype(int)\nDF.loc[:,'emb_Q'] = (df.Embarked=='Q').astype(int)\nDF.loc[:,'emb_S'] = (df.Embarked=='S').astype(int)\nDF.loc[:,'emb_missing'] = df.Embarked.isnull().astype(int)\nDF.loc[:, 'cabin_C'] = (df.Cabin.str[0]=='C').astype(int)\nDF.loc[:, 'cabin_E'] = (df.Cabin.str[0]=='E').astype(int)\nDF.loc[:, 'cabin_G'] = (df.Cabin.str[0]=='G').astype(int)\nDF.loc[:, 'cabin_D'] = (df.Cabin.str[0]=='D').astype(int)\nDF.loc[:, 'cabin_A'] = (df.Cabin.str[0]=='A').astype(int)\nDF.loc[:, 'cabin_B'] = (df.Cabin.str[0]=='B').astype(int)\nDF.loc[:, 'cabin_F'] = (df.Cabin.str[0]=='F').astype(int)\nDF.loc[:, 'cabin_T'] = (df.Cabin.str[0]=='T').astype(int)","82305505":"df[~df.Cabin.isnull()].Cabin.str[0].describe()\ndf[~df.Cabin.isnull()].Cabin.str[0].unique()","227abc5b":"# correlation matrix\ncorr=DF.corr()\ncorr.style.background_gradient(cmap='coolwarm')","46b95d2a":"# try a few transformations to make Fare look more normalized\ntest=pd.DataFrame()\ntest.loc[:,'fare']=df.Fare\ntest.loc[:,'fare1']=np.tanh(test.fare\/30)\ntest.loc[:,'fare2']=np.tanh(test.fare\/40)\ntest.loc[:,'fare3']=np.tanh(test.fare\/60)\ntest.hist(bins=50)","8c46d5f6":"# try a few transformations on Age\ntest=pd.DataFrame()\ntest.loc[:,'age']=df[df.Age>0].Age\ntest.loc[:,'age1']=np.tanh(test.age\/30)\ntest.loc[:,'age2']=np.tanh(test.age\/40)\ntest.hist(bins=50)","0139d135":"# fit logistic regression model via CV, compute in-sample prediction accuracy\nclf=LogisticRegressionCV(cv=5,random_state=0,max_iter=1000).fit(DF.iloc[:,1:], DF.iloc[:, 0])\nrs=pd.DataFrame(index=DF.index)\nrs.loc[:,'pred']=clf.predict(DF.iloc[:,1:])\nrs.loc[:,'y']=DF.survived\nprint('in-sample prediction rate via Logistic Regression CV: {:.2f}'.format((rs.pred==rs.y).astype(int).sum()\/rs.shape[0]))","7cfc4fef":"# found a nice tutorial on gridsearching hyperparameters at https:\/\/towardsdatascience.com\/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1800, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrf = RandomForestClassifier()\n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(DF.iloc[:,1:], DF.iloc[:, 0])","402d1b85":"rf_random.best_params_","b5d71719":"# Create the parameter grid based on the results of random search \nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [5, 10, 15],\n    'max_features': ['sqrt'],\n    'min_samples_leaf': [1],\n    'min_samples_split': [4, 5, 6],\n    'n_estimators': [1600,1800,2000]\n}\n# Create a based model\nrf = RandomForestClassifier()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)\ngrid_search.fit(DF.iloc[:,1:], DF.iloc[:, 0])","fd58072d":"rf_model = grid_search.best_estimator_\nrs=pd.DataFrame(index=DF.index)\nrs.loc[:,'pred']=rf_model.predict(DF.iloc[:,1:])\nrs.loc[:,'y']=DF.survived\nprint('in-sample prediction rate via Logistic Regression CV: {:.2f}'.format((rs.pred==rs.y).astype(int).sum()\/rs.shape[0]))","4ca21fb9":"df2=pd.DataFrame()\ndf2.loc[:, 'class1']=(df_test.Pclass==1).astype(int) \ndf2.loc[:, 'class2']=(df_test.Pclass==2).astype(int)\ndf2.loc[:, 'class3']=(df_test.Pclass==3).astype(int)\ndf2.loc[:, 'sex1'] = (df_test.Sex=='female').astype(int)\ndf2.loc[:, 'sex1_single'] = df_test.Name.str.contains('Miss').astype(int)\ndf2.loc[:, 'sex1_married'] = df_test.Name.str.contains('Mrs').astype(int)\ndf2.loc[:, 'sex2'] = (df_test.Sex=='male').astype(int)\ndf2.loc[:, 'class1sex1'] = ((df_test.Pclass==1) & (df_test.Sex=='female')).astype(int)\ndf2.loc[:, 'class1sex2'] = ((df_test.Pclass==1) & (df_test.Sex=='male')).astype(int)\ndf2.loc[:, 'class2sex1'] = ((df_test.Pclass==2) & (df_test.Sex=='female')).astype(int)\ndf2.loc[:, 'class2sex2'] = ((df_test.Pclass==2) & (df_test.Sex=='male')).astype(int)\ndf2.loc[:, 'class3sex1'] = ((df_test.Pclass==3) & (df_test.Sex=='female')).astype(int)\ndf2.loc[:, 'class3sex2'] = ((df_test.Pclass==3) & (df_test.Sex=='male')).astype(int)\ndf2.loc[:, 'is_master'] = df_test.Name.str.contains('Master').astype(int)\ndf2.loc[:, 'sibSp'] = df_test.SibSp\ndf2.loc[:, 'Parch'] = df_test.Parch\ndf2.loc[:, 'fare'] = df_test.Fare.fillna(0)\ndf2.loc[:,'fare1']=np.tanh(df2.fare\/30)\ndf2.loc[:, 'age'] = df_test.Age.fillna(0)\ndf2.loc[:,'age1']=np.tanh(df2.age\/30)\ndf2.loc[:, 'age_ischild'] = ((df_test.Age>0) & (df_test.Age<10)).astype(int)\ndf2.loc[:, 'age_iselder'] = (df_test.Age>50).astype(int)\ndf2.loc[:,'age_missing'] = df_test.Age.isnull().astype(int)\ndf2.loc[:,'emb_C'] = (df_test.Embarked=='C').astype(int)\ndf2.loc[:,'emb_Q'] = (df_test.Embarked=='Q').astype(int)\ndf2.loc[:,'emb_S'] = (df_test.Embarked=='S').astype(int)\ndf2.loc[:,'emb_missing'] = df_test.Embarked.isnull().astype(int)\ndf2.loc[:, 'cabin_C'] = (df_test.Cabin.str[0]=='C').astype(int)\ndf2.loc[:, 'cabin_E'] = (df_test.Cabin.str[0]=='E').astype(int)\ndf2.loc[:, 'cabin_G'] = (df_test.Cabin.str[0]=='G').astype(int)\ndf2.loc[:, 'cabin_D'] = (df_test.Cabin.str[0]=='D').astype(int)\ndf2.loc[:, 'cabin_A'] = (df_test.Cabin.str[0]=='A').astype(int)\ndf2.loc[:, 'cabin_B'] = (df_test.Cabin.str[0]=='B').astype(int)\ndf2.loc[:, 'cabin_F'] = (df_test.Cabin.str[0]=='F').astype(int)\ndf2.loc[:, 'cabin_T'] = (df_test.Cabin.str[0]=='T').astype(int)","6cb430ab":"predictions1 = clf.predict(df2)\npredictions2 = rf_model.predict(df2)","30ee121d":"output1 = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': predictions1})\noutput2 = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': predictions2})\noutput2.to_csv('submission2.csv', index=False)","769c2108":"output2.head()","67772d23":"## make predictions on test data for submission","238c1b92":"## Fit model: 1)LogisticRegression with CV 2)RandomForest with RandomSearchCV + GridSearchCV"}}