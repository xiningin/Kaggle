{"cell_type":{"b861d7f4":"code","1dd9ab77":"code","3f9f8a03":"code","927ea391":"code","158d3613":"code","60b6e0a2":"code","86e85bf4":"code","397670bb":"code","e8af2cfe":"code","06379a4e":"code","4f7c747a":"code","43fbd502":"code","aee22969":"code","881a5b8d":"code","c465ee9d":"code","74ea4c8a":"code","5f84ce63":"code","57ef4841":"code","9f2fb6c2":"code","fb583327":"code","637b58c8":"code","f5e253f1":"code","d371c931":"markdown","4887a76d":"markdown","68c700e0":"markdown","0f4d1f0b":"markdown","9b058229":"markdown","d2bfc0e7":"markdown","765a9a87":"markdown","8ca4c969":"markdown","d1a94afc":"markdown","c7b5d7a8":"markdown","d22c9ed8":"markdown","b0a2d863":"markdown","378f16fd":"markdown","0289c8fb":"markdown","2f7d4f95":"markdown","3a890090":"markdown","f2f28af8":"markdown","c3b2bc7d":"markdown","9307ae65":"markdown","c4ee4777":"markdown","da75f788":"markdown","040d2931":"markdown","7a418d8e":"markdown"},"source":{"b861d7f4":"#importing the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","1dd9ab77":"#reading the CSV file\n\nlocation = \"..\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv\"\ndata = pd.read_csv(location)\ndata","3f9f8a03":"#Checking whether the dataset have any NaN.\n\ndata.isnull().sum()","927ea391":"data.dtypes","158d3613":"from sklearn.impute import KNNImputer\n\ncol_names = data.columns\nfor feature in col_names:\n    data[feature+\" nan\"] = np.where(data[feature].isnull(),1,0)\n\nimputer = KNNImputer(n_neighbors=3)\ndf = imputer.fit_transform(data)\ndf = pd.DataFrame(df, columns=data.columns)\n\ndf","60b6e0a2":"#checking for NaN's \n\ndf.isnull().sum()","86e85bf4":"numeric_columns = df.select_dtypes(exclude=\"O\")\n\nfor feature in numeric_columns:\n    q1 = df[feature].quantile(0.05)\n    q3 = df[feature].quantile(0.95)\n    iqr = q3-q1\n    Lower_tail = q1 - 1.5 * iqr\n    Upper_tail = q3 + 1.5 * iqr\n    med = np.mean(df[feature])\n    for i in df[feature]:\n        if i > Upper_tail or i < Lower_tail:\n                df[feature] = df[feature].replace(i, med)","397670bb":"#Grouping education and cigsPerDay\n\ngraph_1 = df.groupby(\"education\", as_index=False).cigsPerDay.mean()","e8af2cfe":"\nplt.figure(figsize=(12,8))\nsns.regplot(x=graph_1[\"education\"], y=graph_1[\"cigsPerDay\"])\nplt.title(\"Graph showing cigsPerDay in every level of education.\")\nplt.xlabel(\"education\", size=20)\nplt.ylabel(\"cigsPerDay\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12)","06379a4e":"#Plotting a linegraph to check the relationship between age and cigsPerDay, totChol, glucose.\n\ngraph_3 = df.groupby(\"age\").cigsPerDay.mean()\ngraph_4 = df.groupby(\"age\").totChol.mean()\ngraph_5 = df.groupby(\"age\").glucose.mean()\n\nplt.figure(figsize=(12,8))\nsns.lineplot(data=graph_3, label=\"cigsPerDay\")\nsns.lineplot(data=graph_4, label=\"totChol\")\nsns.lineplot(data=graph_5, label=\"glucose\")\nplt.title(\"Graph showing totChol and cigsPerDay in every age group.\")\nplt.xlabel(\"age\", size=20)\nplt.ylabel(\"count\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12)","4f7c747a":"#checking for which gender has more risk of coronary heart disease CHD\n\ngraph_6 = df.groupby(\"male\", as_index=False).TenYearCHD.sum()","43fbd502":"#Ploting the above values\n\nplt.figure(figsize=(12,8))\nsns.barplot(x=graph_6[\"male\"], y=graph_6[\"TenYearCHD\"])\nplt.title(\"Graph showing which gender has more risk of coronary heart disease CHD\")\nplt.xlabel(\"0 is female and 1 is male\",size=20)\nplt.ylabel(\"total cases\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12)","aee22969":"#grouping the necessary features\n\ngraph_7 = df.groupby(\"age\",as_index=False).currentSmoker.sum()\n\nplt.figure(figsize=(12,8))\nsns.barplot(x=graph_7[\"age\"], y=graph_7[\"currentSmoker\"])\nplt.title(\"Graph showing which age group has more smokers.\")\nplt.xlabel(\"age\", size=20)\nplt.ylabel(\"currentSmokers\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12)","881a5b8d":"graph_8 = df.groupby(\"TenYearCHD\", as_index=False).cigsPerDay.mean()\n\nplt.figure(figsize=(12,8))\nsns.barplot(x=graph_8[\"TenYearCHD\"], y=graph_8[\"cigsPerDay\"])\nplt.title(\"Graph showing the relation between cigsPerDay and risk of coronary heart disease.\")\nplt.xlabel(\"Rick of CHD\", size=20)\nplt.ylabel(\"cigsPerDay\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12)","c465ee9d":"# Grouping up the data and ploting it\n\ngraph_9 = df.groupby(\"TenYearCHD\", as_index=False).sysBP.mean()\n\nplt.figure(figsize=(12,8))\nsns.barplot(x=graph_9[\"TenYearCHD\"], y=graph_9[\"sysBP\"])\nplt.title(\"Graph showing the relation between sysBP and risk of CHD\")\nplt.xlabel(\"Rick of CHD\", size=20)\nplt.ylabel(\"sysBP\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12)","74ea4c8a":"# Grouping up the data and ploting it\n\ngraph_9 = df.groupby(\"TenYearCHD\", as_index=False).diaBP.mean()\n\nplt.figure(figsize=(12,8))\nsns.barplot(x=graph_9[\"TenYearCHD\"], y=graph_9[\"diaBP\"])\nplt.title(\"Graph showing the relation between diaBP and risk of CHD\")\nplt.xlabel(\"Rick of CHD\", size=20)\nplt.ylabel(\"diaBP\", size=20)\nplt.xticks(size=12)\nplt.yticks(size=12)","5f84ce63":"from sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n# collecting the features in X\nX = df.drop(columns=[\"TenYearCHD\", \"TenYearCHD nan\"])\n\n# y is the target variable (risk of CHD)\ny = df[\"TenYearCHD\"]\n\ntrain_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.2)\n\nmodel1 = LogisticRegression()\nmodel2 = XGBClassifier()\nmodel3 = RandomForestClassifier()\n\nmodel1.fit(train_X, train_y)\nmodel2.fit(train_X, train_y)\nmodel3.fit(train_X, train_y)\n\nscore1 = model1.score(test_X, test_y)\nscore2 = model2.score(test_X, test_y)\nscore3 = model2.score(test_X, test_y)\n\nprint(\"accuracy of logistic regression is \", score1, \"accuracy of xgboost is \", score2, \"accuracy of random forest Clssifier is\", score3)","57ef4841":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(model1, random_state=1).fit(test_X, test_y)\neli5.show_weights(perm, feature_names = test_X.columns.tolist())","9f2fb6c2":"features = [\"sysBP\",\"age\",\"prevalentHyp\", \"diaBP\",\"cigsPerDay\"] \n\ndf = df[features]\n\nnew_train_x = df\nnew_train_y = y\n\nTrain_X, Test_X, Train_y, Test_y = train_test_split(new_train_x, new_train_y, test_size=0.2)","fb583327":"model = LogisticRegression()\n\nparams = {\n    \"max_iter\"          : [30,40,50,100,150,200,],\n    \"random_state\"      : [1,2,3,4,5,6],\n    \"n_jobs\"            : [1,2,3,4,5],\n    \"penalty\"           : [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n    \"intercept_scaling\" : [1,2,3,4,5],\n    \"solver\"            : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n    \"multi_class\"       : [\"auto\", \"ovr\", \"multinomial\"],\n    \"verbose\"           : [0,1,2,3,4,5]\n    }\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrandom_search = RandomizedSearchCV(model, param_distributions=params, n_iter=5, cv=5)\n\nrandom_search.fit(Train_X, Train_y)","637b58c8":"random_search.best_estimator_","f5e253f1":"model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=2, l1_ratio=None, max_iter=30,\n                   multi_class='ovr', n_jobs=4, penalty='none', random_state=3,\n                   solver='newton-cg', tol=0.0001, verbose=4, warm_start=False)\n\nmodel.fit(Train_X, Train_y)\n\nscore = model.score(Test_X, Test_y)\n\nprint(\"The accuracy of our model is \", score)","d371c931":"**Which age group has more smokers.**","4887a76d":"**Relationship between age and cigsPerDay, totChol, glucose.**","68c700e0":"The summary of this notebook:\n\n* Feature Engineering.\n\n* Relationship between education and cigsPerDay,\n\n* Relationship between age and cigsPerDay, totChol, glucose.\n\n* Which gender has more risk of coronary heart disease CHD.\n\n* Which age group has more smokers.\n\n* Relation between cigsPerDay and risk of coronary heart disease.\n\n* Relation between sysBP and risk of CHD.\n\n* Relation between diaBP and risk of CHD.\n\n* Modelling.","0f4d1f0b":"**Using KNNImputer to fill the null values.**","9b058229":"**We will go with Logistic regression since we are getting better accuracy.**","d2bfc0e7":"**Relation between sysBP and risk of CHD.**","765a9a87":"We see a minor relation between totChol and glucose.","8ca4c969":"# Modelling","d1a94afc":"There is no such linear relationship found.\nlevel 3 education shows the lowest mean.","c7b5d7a8":"Mid-age groups have more smokers","d22c9ed8":"**Relation between cigsPerDay and risk of coronary heart disease.**","b0a2d863":"**Which gender has more risk of coronary heart disease CHD**","378f16fd":"**Removing the outliers.**","0289c8fb":"High cigsPerDay comes with higher risk of CHD.","2f7d4f95":"**Relation between diaBP and risk of CHD**","3a890090":"According to this dataset, males have slighly higher risk of coronary heart disease CHD.","f2f28af8":"**Relationship between education and cigsPerDay**","c3b2bc7d":"Minor relation found between higher risk with higher sysBP  ","9307ae65":"These are the most related features.","c4ee4777":"# World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases.","da75f788":"# Feature Engineering","040d2931":"Minor relation found between higher risk with higher diaBP  ","7a418d8e":"Now our data is ready for further use: "}}