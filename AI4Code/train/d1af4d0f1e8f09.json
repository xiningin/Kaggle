{"cell_type":{"745f403d":"code","451bd327":"code","e1789097":"code","766e1e5d":"code","90a57679":"code","dd650c4d":"code","6823ca0b":"code","a732b4f9":"code","e354d0f1":"code","ad18061f":"code","ac853db4":"code","74f4e5fe":"code","10a4b7ce":"code","5b360360":"markdown","2097d4d1":"markdown","8f266449":"markdown","31d13679":"markdown","05157882":"markdown","7acb69f4":"markdown","bb122162":"markdown","32b7e4e6":"markdown","5f11d027":"markdown","7fb9499b":"markdown"},"source":{"745f403d":"import cv2\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nfrom keras.models import Sequential\nimport keras\nfrom keras.layers import Activation, Dropout, Flatten, Dense,Conv2D,Conv3D,MaxPooling2D,AveragePooling2D,BatchNormalization\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix,classification_report,roc_auc_score\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.image as mpimg\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/weights\/\"))\nIMAGE_SIZE = 32","451bd327":"train_dir = \"..\/input\/aerial-cactus-identification\/train\/train\/\"\ntest_dir = \"..\/input\/aerial-cactus-identification\/test\/test\/\"\ntrain_df = pd.read_csv('..\/input\/aerial-cactus-identification\/train.csv')\ntrain_df.head()","e1789097":"im = cv2.imread(\"..\/input\/aerial-cactus-identification\/train\/train\/01e30c0ba6e91343a12d2126fcafc0dd.jpg\")\nplt.imshow(im)","766e1e5d":"X_tr = []\nY_tr = []\nimges = train_df['id'].values\nfor img_id in tqdm_notebook(imges):\n    image = np.array(cv2.imread(train_dir + img_id))\n    X_tr.append(image)\n    Y_tr.append(train_df[train_df['id'] == img_id]['has_cactus'].values[0])  \n\n    X_tr.append(np.flip(image))\n    Y_tr.append(train_df[train_df['id'] == img_id]['has_cactus'].values[0])  \n\n    X_tr.append(np.flipud(image))\n    Y_tr.append(train_df[train_df['id'] == img_id]['has_cactus'].values[0])  \n\n    X_tr.append(np.fliplr(image))\n    Y_tr.append(train_df[train_df['id'] == img_id]['has_cactus'].values[0])  \n                \nX_tr = np.asarray(X_tr)\nX_tr = X_tr.astype('float32')\nX_tr \/= 255\nY_tr = np.asarray(Y_tr)\n\n\n","90a57679":"\nX_tr_2 = X_tr\nY_tr_2 = Y_tr\n","dd650c4d":"\nX_tr = X_tr_2\nY_tr = Y_tr_2\n","6823ca0b":"X_tr.shape,Y_tr.shape","a732b4f9":"test_image_names = []\nfor filename in os.listdir(test_dir):\n    test_image_names.append(filename)\ntest_image_names.sort()\nX_ts = []\n#imges = test_df['id'].values\nfor img_id in tqdm_notebook(test_image_names):\n    X_ts.append(cv2.imread(test_dir + img_id))    \nX_ts = np.asarray(X_ts)\nX_ts = X_ts.astype('float32')\nX_ts \/= 255","e354d0f1":"x_train,x_test,y_train,y_test = train_test_split(X_tr, Y_tr, test_size = 0.2 , stratify = Y_tr )","ad18061f":"\n\nbase=keras.applications.vgg16.VGG16(include_top=False, weights='..\/input\/weights\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',input_shape=(32,32,3))\n\n","ac853db4":"\n\nprint(\"Current train size:\",X_tr.shape)\nmodel = Sequential()\nmodel.add(base)\n\nmodel.add(Flatten())\nmodel.add(Dense(256, use_bias=True))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(16, activation='tanh'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\ncallback=[keras.callbacks.EarlyStopping(monitor='val_acc', patience=20, verbose=1, mode='auto', restore_best_weights=True),\n         keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='auto')]\nmodel.fit(X_tr,Y_tr,batch_size=64, epochs=80, verbose=1,   validation_split=0.1,callbacks=callback)\n","74f4e5fe":"\n\n\nclf=model\ny_pred_proba = clf.predict_proba(X_tr_2)\n\ny_pred = clf.predict_classes(X_tr_2)\nconf_mat = confusion_matrix(Y_tr_2, y_pred)\nfig, ax = plt.subplots(figsize=(10,10))\n\nsns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=['0','1'], yticklabels=['0','1'])\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()\n\nprint(classification_report(Y_tr_2, y_pred, target_names=['0','1']))\nprint(\"\\n\\n AUC: {:<0.4f}\".format(roc_auc_score(Y_tr_2,y_pred_proba)))\n\n","10a4b7ce":"\n\n\ntest_df = pd.read_csv('..\/input\/aerial-cactus-identification\/sample_submission.csv')\nX_test = []\nimges = test_df['id'].values\nfor img_id in tqdm_notebook(imges):\n    X_test.append(cv2.imread(test_dir + img_id))     \nX_test = np.asarray(X_test)\nX_test = X_test.astype('float32')\nX_test \/= 255\n\ny_test_pred  = model.predict_proba(X_test)\n\ntest_df['has_cactus'] = y_test_pred\ntest_df.to_csv('tf_learning_vgg16_aug2_80epoch.csv', index=False)","5b360360":"# Load weights of pretrained VGG16 model","2097d4d1":"# Results","8f266449":"## Read and convert horizontally an vertically augmented images to numpy array","31d13679":"# Submit","05157882":"## Check out an image sample","7acb69f4":"# Save an instance of initial images for future use","bb122162":"## Set Directories","32b7e4e6":"## Import Packages","5f11d027":"# Train","7fb9499b":"# Read test images"}}