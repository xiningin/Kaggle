{"cell_type":{"a37e70de":"code","f361693d":"code","874b4fb4":"code","ed1e80eb":"code","14e61598":"code","2e7e13a0":"code","d58e0434":"code","e0bcdf6d":"code","7227888c":"code","3c2b4526":"code","3e837c87":"code","48035a5b":"code","346400d9":"code","9562b0e0":"code","55d21217":"code","ea5b85c1":"code","282a00b2":"code","84f62279":"code","e2ee3e64":"code","ab56fe71":"code","27d2b321":"code","4ecdd9be":"code","ded4aa41":"code","6d7ab8ac":"code","4cbf04b5":"code","6c90ce03":"code","f2f6473e":"code","9270fc17":"markdown","c4dc0fa6":"markdown","20132862":"markdown","8d6a07fe":"markdown","48cf0fa6":"markdown","ef232180":"markdown","c60d593b":"markdown","4e86e947":"markdown","ae794de8":"markdown","eb891a19":"markdown","6a868eaf":"markdown","541d7579":"markdown","df5d5eab":"markdown","1d18387a":"markdown","50a52bb3":"markdown","1edf02fe":"markdown","43b75d1a":"markdown","6988e375":"markdown","221b08f5":"markdown","4d455821":"markdown","5abf7bff":"markdown","88b106f7":"markdown","c1799d14":"markdown","d1fa2d0b":"markdown","b93fd4b4":"markdown"},"source":{"a37e70de":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","f361693d":"dataset_train = pd.read_csv('..\/input\/google-stock-price\/dataset\/Google_Stock_Price_Train.csv')","874b4fb4":"dataset_train.head()","ed1e80eb":"dataset_train.info()","14e61598":"dataset_train.describe()","2e7e13a0":"training_set = dataset_train.iloc[:, 1:2].values","d58e0434":"training_set","e0bcdf6d":"training_set.shape","7227888c":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\ntraining_set_scaled = sc.fit_transform(training_set)","3c2b4526":"X_train = []\ny_train = []\nfor i in range(60, 1258):\n    X_train.append(training_set_scaled[i-60:i, 0])\n    y_train.append(training_set_scaled[i,0])\n    \n#converting lists into numpy array for further procedure\nX_train, y_train = np.array(X_train), np.array(y_train)","3e837c87":"X_train.shape","48035a5b":"y_train.shape","346400d9":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))","9562b0e0":"X_train.shape","55d21217":"from tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout","ea5b85c1":"regressor = Sequential()","282a00b2":"regressor.add(LSTM(units=60, return_sequences=True, input_shape=(X_train.shape[1], 1)))\nregressor.add(Dropout(0.1))","84f62279":"regressor.add(LSTM(units=60, return_sequences= True))\nregressor.add(Dropout(0.1))","e2ee3e64":"regressor.add(LSTM(units=60, return_sequences=True))\nregressor.add(Dropout(0.1))","ab56fe71":"regressor.add(LSTM(units=60))\nregressor.add(Dropout(0.1))","27d2b321":"regressor.add(Dense(1))","4ecdd9be":"opt = keras.optimizers.Adam(learning_rate=0.001)\nregressor.compile(optimizer=opt, loss='mean_squared_error')","ded4aa41":"regressor.fit(X_train, y_train, epochs=150, batch_size=32)","6d7ab8ac":"dataset_test = pd.read_csv('..\/input\/google-stock-price\/dataset\/Google_Stock_Price_Test.csv')\nreal_stock_price = dataset_test.iloc[:, 1:2].values","4cbf04b5":"dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\ninputs = dataset_total[len(dataset_total)-len(dataset_test)-60:].values\ninputs = inputs.reshape(-1,1)\ninputs = sc.transform(inputs)\n\nX_test = []\nfor i in range(60,80):\n    X_test.append(inputs[i-60:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)","6c90ce03":"predicted_stock_price","f2f6473e":"plt.plot(real_stock_price, color='red', label=\"Real Google Stock Price\")\nplt.plot(predicted_stock_price, color=\"blue\", label=\"Predicted Google Stock Price\")\nplt.title(\"Google Stock Price Prediction\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Google Stock Price\")\nplt.legend()","9270fc17":"## Visualizing the Result","c4dc0fa6":"## Importing the keras libraries and packages","20132862":"## Adding the output layer\n* units: 1 since we predict only one value","8d6a07fe":"## Importing the libararies","48cf0fa6":"* optimizer: **adam** is always a safe choice or you can use **RMSprop** which is also a good choice for RNN\n* loss: since we have a regression problem we gonna use **mean_squared_error**","ef232180":"#### Now we only select second column of the dataset_train which is **Open** and convert into numpy array using values method","c60d593b":"* units : number of neurons we choose 60\n* return_sequences: choose **True** because we are gonna add another lstm layer after this one\n* input_shape: it will take 2d array(timestemps and indicator(no of predictor) and the value would be **(X_train.shape[1], 1)**\n* Dropout Layer : we give it to 0.1 means 10%, that means drop the 10 percent(6 neurons) of neurons which are least involving.\n* **NOTE**: Dropout is used to Prevent **Overfitting**","4e86e947":"### Checking for Null values ","ae794de8":"### Adding the second LSTM layer and some Dropout regularisation\n* after first lstm layer we dont need to specify input_shape","eb891a19":"### Checking first 5 records of the training set","6a868eaf":"## Fitting the RNN to the Training set","541d7579":"# Part 3 - Making the predictions and visualising the results","df5d5eab":"### Adding the third LSTM layer and some Dropout regularisation\n","1d18387a":"### Adding the first LSTM layer and some Dropout regularisation","50a52bb3":"### Getting the real stock price of 2017 which we gonna predict","1edf02fe":"### Getting the predicted stock price of jan 2017\n### 3 Key Points\n1. we trained our model to be able to predict the stock price at time t+1 based on the 60 previous stock prices and therefore to predict each stock price of each financial day of January, 2017 we will need 60 previous stock prices of the 60 previous financial days, before the actual day.\n2. in order to get day of january,2017 the 60 previous stock prices of the 60 previous day, so we will need both the train set and test set because we will have some of the 60 days that will be from the testing set because they will be form november 2016 and we will also have some stock prices of the test set because some of them will come from january 2017, and therefore first thing we need to do now is now some concatenation of training set and test set to be able to get these 60 previous inputs for each day of january, 2017.\n3. we will have to concatenate both but we do not change the actual test values. so we have to concatenate orininal dataset.(we have to feed our model with scaling values but make prediction on actual values so we have to keep them)","43b75d1a":"# Part 2 - Building the RNN\n","6988e375":"## Feature Scaling\n*  there are mainly two ways to feature scaling\n   1. Standardisation  \n   2. Normalization \n* in our case we gonna use normalization and specifically minmax scaler and the idea behind that is since we gonna create RNN and in this network we use sigmoid activation function in output layer.so it's great to values lies between 0 to 1 and minmax scaler exactly doing same","221b08f5":"## Creating a data structure with 60 timesteps and 1 output\n* we'll take 60 to timestamps, first of for whats timestemp? since we gonna predict stock price(Open) so timestamp of 60 is saying that when you predict stock price at any given day at that time consider last 60 days to make prediction.\n* then we create 2 numpy array X_train and y_train where X_train is containing stock price with last 60 days stock price values and y_train containing single day stock price at given day.","4d455821":"## Importing the training set","5abf7bff":"## Initializing the RNN","88b106f7":"### Adding the fourth LSTM layer and some Dropout regularisation\n* we don't have to specify return_sequences in last lstm layer since it by default false.","c1799d14":"## Reshaping\n* we have to convert into standard format rnn format X_train into 3D tensor with shape(batch_size, timestemps, output_size)\n* let's see each perameters values for our model\n1. batch_size: No of Observation(X_train.shape[0] which is 1198)\n2. timestems: 60 as we initialized above(X_train.shape[1])\n3. input_dim: 1 since we gonna predict only one varibale google stock price","d1fa2d0b":"# Part 1 - Data Preprocessing","b93fd4b4":"## Compiling the RNN"}}