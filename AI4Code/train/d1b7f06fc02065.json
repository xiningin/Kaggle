{"cell_type":{"ecbfe998":"code","9770ac5e":"code","3027546b":"code","30d6d3e3":"code","ae422c3f":"code","071ece99":"code","91dab8fd":"code","ec020c0c":"code","ff6b4f20":"code","bcbbdc89":"code","4c06343f":"code","0d630764":"code","5fb95fde":"code","2fe49d27":"code","1b954731":"code","636c3b9f":"code","0bfed151":"code","22342291":"code","2dfd9975":"code","861a5af5":"code","beef7d89":"code","b8971152":"code","1122bbc4":"code","f279b1e8":"code","9f680375":"code","0b009cf3":"code","d1931e44":"code","a024c9b2":"markdown","7cc966b1":"markdown","9959dc6c":"markdown","844dcf8a":"markdown","06f1458c":"markdown","5a9f7ded":"markdown","74f38d93":"markdown","b59fb822":"markdown"},"source":{"ecbfe998":"import gc\nimport os\nimport random\n\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport itertools\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nfrom sklearn.cluster import KMeans\n\nsns.set(style='darkgrid')\nSEEDS = 19","9770ac5e":"def rmse(y_true, y_pred):\n    return (mean_squared_error(y_true, y_pred))** .5","3027546b":"# treemodel_wrapper\nclass TreeModel:\n    def __init__(self, model_type):\n        self.model_type = model_type\n        self.tr_data = None\n        self.vl_data = None\n        self.model = None\n    \n    def train(self, params, train_x, train_y, valid_x=None, valid_y=None, num_round=None, early_stopping=None, verbose=None):\n        if self.model_type == 'lgb':\n            self.tr_data = lgb.Dataset(train_x, label=train_y)\n            self.vl_data = lgb.Dataset(valid_x, label=valid_y)\n            self.model = lgb.train(params, self.tr_data, valid_sets=[self.tr_data, self.vl_data],\n                                   num_boost_round=num_round, early_stopping_rounds=early_stopping,verbose_eval=verbose)\n            \n        if self.model_type == 'rf_reg':\n            self.train_x = train_x\n            self.train_y = train_y\n            self.model = RandomForestRegressor(**params).fit(self.train_x, self.train_y)\n            \n        if self.model_type == 'xgb':\n            self.tr_data = xgb.DMatrix(train_x, train_y)\n            self.vl_data = xgb.DMatrix(valid_x, valid_y)\n            self.model = xgb.train(params, self.tr_data, num_boost_round=num_round,\n                                   evals=[(self.tr_data, 'train'), (self.vl_data, 'val')], \n                                   verbose_eval=verbose, early_stopping_rounds=early_stopping)\n            \n        if self.model_type == 'cat':\n            params['num_boost_round'] = num_round\n            self.cat_cols = list(train_x.select_dtypes(include='object').columns)\n            self.tr_data = Pool(train_x, train_y, cat_features=self.cat_cols)\n            self.vl_data = Pool(valid_x, valid_y, cat_features=self.cat_cols)\n            self.model = CatBoost(params).fit(self.tr_data, eval_set=self.vl_data,\n                                                early_stopping_rounds=early_stopping, verbose=verbose, use_best_model=True)\n            \n            return self.model\n            \n    \n    def predict(self,X):\n        if self.model_type == 'lgb':\n            return self.model.predict(X, num_iteration=self.model.best_iteration)\n        \n        if self.model_type == 'rf_reg':\n            return self.model.predict(X)\n        \n        if self.model_type == 'xgb':\n            X_DM = xgb.DMatrix(X)\n            return self.model.predict(X_DM)\n        \n        if self.model_type == 'cat':\n            X_pool = Pool(X, cat_features=self.cat_cols)\n            return self.model.predict(X_pool)\n    \n    @property\n    def feature_names_(self):\n        if self.model_type == 'lgb':\n            return self.model.feature_name()\n        \n        if self.model_type == 'rf_reg':\n            return self.train_x.columns\n        \n        if self.model_type == 'xgb':\n            return list(self.model.get_score(importance_type='gain').keys())\n        \n        if self.model_type == 'cat':\n            return self.model.feature_names_\n    \n    @property\n    def feature_importances_(self):\n        if self.model_type == 'lgb':\n            return self.model.feature_importance(importance_type='gain')\n        \n        if self.model_type == 'rf_reg':\n            return self.model.feature_importances_\n        \n        if self.model_type == 'xgb':\n            return list(self.model.get_score(importance_type='gain').values())\n        \n        if self.model_type == 'cat':\n            return self.model.feature_importances_","30d6d3e3":"train = pd.read_json('..\/input\/stanford-covid-vaccine\/train.json',lines=True)\ntest = pd.read_json('..\/input\/stanford-covid-vaccine\/test.json', lines=True)\nsubmission = pd.read_csv('\/kaggle\/input\/stanford-covid-vaccine\/sample_submission.csv')\ntrain.head()","ae422c3f":"# SN_filter == 1 split Extraction \ntrain2 = train[train.SN_filter < 1]\ntrain = train[train.SN_filter == 1]","071ece99":"train2.describe()","91dab8fd":"train.describe()","ec020c0c":"train_data = []\nfor mol_id in train['id'].unique():\n    sample_data = train.loc[train['id'] == mol_id]\n    sample_seq_length = sample_data.seq_length.values[0]\n    \n    for i in range(68):\n        sample_dict = {'id' : sample_data['id'].values[0],\n                       'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                       'sequence' : sample_data['sequence'].values[0][i],\n                       'structure' : sample_data['structure'].values[0][i],\n                       'predicted_loop_type' : sample_data['predicted_loop_type'].values[0][i],\n                       'reactivity' : sample_data['reactivity'].values[0][i],\n                       'reactivity_error' : sample_data['reactivity_error'].values[0][i],\n                       'deg_Mg_pH10' : sample_data['deg_Mg_pH10'].values[0][i],\n                       'deg_error_Mg_pH10' : sample_data['deg_error_Mg_pH10'].values[0][i],\n                       'deg_pH10' : sample_data['deg_pH10'].values[0][i],\n                       'deg_error_pH10' : sample_data['deg_error_pH10'].values[0][i],\n                       'deg_Mg_50C' : sample_data['deg_Mg_50C'].values[0][i],\n                       'deg_error_Mg_50C' : sample_data['deg_error_Mg_50C'].values[0][i],\n                       'deg_50C' : sample_data['deg_50C'].values[0][i],\n                       'deg_error_50C' : sample_data['deg_error_50C'].values[0][i]}\n        \n        \n        shifts = [1,2,3,4,5]\n        shift_cols = ['sequence', 'structure', 'predicted_loop_type']\n        for shift,col in itertools.product(shifts, shift_cols):\n            if i - shift >= 0:\n                sample_dict['b'+str(shift)+'_'+col] = sample_data[col].values[0][i-shift]\n            else:\n                sample_dict['b'+str(shift)+'_'+col] = -1\n            \n            if i + shift <= sample_seq_length - 1:\n                sample_dict['a'+str(shift)+'_'+col] = sample_data[col].values[0][i+shift]\n            else:\n                sample_dict['a'+str(shift)+'_'+col] = -1\n        \n        \n        train_data.append(sample_dict)\ntrain_data = pd.DataFrame(train_data)\ntrain_data.head()","ff6b4f20":"train_data.describe()","bcbbdc89":"#maximum error value\nmax_reactivity_error = train_data['reactivity_error'].max()\nmax_deg_error_Mg_pH10 = train_data['deg_error_Mg_pH10'].max()\nmax_deg_error_pH10 = train_data['deg_error_pH10'].max()\nmax_deg_error_Mg_50C = train_data['deg_error_Mg_50C'].max()\nmax_deg_error_50C = train_data['deg_error_50C'].max()","4c06343f":"train_data2 = []\nfor mol_id in train2['id'].unique():\n    sample_data = train2.loc[train2['id'] == mol_id]\n    sample_seq_length = sample_data.seq_length.values[0]\n    \n    for i in range(68):\n        sample_dict = {'id' : sample_data['id'].values[0],\n                       'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                       'sequence' : sample_data['sequence'].values[0][i],\n                       'structure' : sample_data['structure'].values[0][i],\n                       'predicted_loop_type' : sample_data['predicted_loop_type'].values[0][i],\n                       'reactivity' : sample_data['reactivity'].values[0][i],\n                       'reactivity_error' : sample_data['reactivity_error'].values[0][i],\n                       'deg_Mg_pH10' : sample_data['deg_Mg_pH10'].values[0][i],\n                       'deg_error_Mg_pH10' : sample_data['deg_error_Mg_pH10'].values[0][i],\n                       'deg_pH10' : sample_data['deg_pH10'].values[0][i],\n                       'deg_error_pH10' : sample_data['deg_error_pH10'].values[0][i],\n                       'deg_Mg_50C' : sample_data['deg_Mg_50C'].values[0][i],\n                       'deg_error_Mg_50C' : sample_data['deg_error_Mg_50C'].values[0][i],\n                       'deg_50C' : sample_data['deg_50C'].values[0][i],\n                       'deg_error_50C' : sample_data['deg_error_50C'].values[0][i]}\n        \n        \n        shifts = [1,2,3,4,5]\n        shift_cols = ['sequence', 'structure', 'predicted_loop_type']\n        for shift,col in itertools.product(shifts, shift_cols):\n            if i - shift >= 0:\n                sample_dict['b'+str(shift)+'_'+col] = sample_data[col].values[0][i-shift]\n            else:\n                sample_dict['b'+str(shift)+'_'+col] = -1\n            \n            if i + shift <= sample_seq_length - 1:\n                sample_dict['a'+str(shift)+'_'+col] = sample_data[col].values[0][i+shift]\n            else:\n                sample_dict['a'+str(shift)+'_'+col] = -1\n        \n        \n        train_data2.append(sample_dict)\ntrain_data2 = pd.DataFrame(train_data2)\ntrain_data2.head()","0d630764":"train_data2.describe()","5fb95fde":"train_data2 = train_data2.query('reactivity_error <= @max_reactivity_error')\ntrain_data2 = train_data2.query('deg_error_Mg_pH10 <= @max_deg_error_Mg_pH10')\ntrain_data2 = train_data2.query('deg_error_pH10 <= @max_deg_error_pH10')\ntrain_data2 = train_data2.query('deg_error_Mg_50C <= @max_deg_error_Mg_50C')\ntrain_data2 = train_data2.query('deg_error_50C <= @max_deg_error_50C')\ntrain_data2.describe()","2fe49d27":"#Combine to train_data.\ntrain_data = pd.concat([train_data, train_data2], axis=0)","1b954731":"train_data.describe()","636c3b9f":"test_data = []\nfor mol_id in test['id'].unique():\n    sample_data = test.loc[test['id'] == mol_id]\n    sample_seq_length = sample_data.seq_length.values[0]\n    for i in range(sample_seq_length):\n        sample_dict = {'id' : sample_data['id'].values[0],\n                       'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                       'sequence' : sample_data['sequence'].values[0][i],\n                       'structure' : sample_data['structure'].values[0][i],\n                       'predicted_loop_type' : sample_data['predicted_loop_type'].values[0][i]}\n        \n        shifts = [1,2,3,4,5]\n        shift_cols = ['sequence', 'structure', 'predicted_loop_type']\n        for shift,col in itertools.product(shifts, shift_cols):\n            if i - shift >= 0:\n                sample_dict['b'+str(shift)+'_'+col] = sample_data[col].values[0][i-shift]\n            else:\n                sample_dict['b'+str(shift)+'_'+col] = -1\n            \n            if i + shift <= sample_seq_length - 1:\n                sample_dict['a'+str(shift)+'_'+col] = sample_data[col].values[0][i+shift]\n            else:\n                sample_dict['a'+str(shift)+'_'+col] = -1\n        \n        test_data.append(sample_dict)\ntest_data = pd.DataFrame(test_data)\ntest_data.head()","0bfed151":"# label_encoding\nsequence_encmap = {'A': 0, 'G' : 1, 'C' : 2, 'U' : 3}\nstructure_encmap = {'.' : 0, '(' : 1, ')' : 2}\nlooptype_encmap = {'S':0, 'E':1, 'H':2, 'I':3, 'X':4, 'M':5, 'B':6}\n\nenc_targets = ['sequence', 'structure', 'predicted_loop_type']\nenc_maps = [sequence_encmap, structure_encmap, looptype_encmap]\n\nfor t,m in zip(enc_targets, enc_maps):\n    for c in [c for c in train_data.columns if t in c]:\n        train_data[c] = train_data[c].replace(m)\n        test_data[c] = test_data[c].replace(m)","22342291":"not_use_cols = ['id', 'id_seqpos']\nfeatures = [c for c in test_data.columns if c not in not_use_cols]\ntargets = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","2dfd9975":"FOLD_N = 5\ngkf = GroupKFold(n_splits=FOLD_N)","861a5af5":"params = {'objective': 'regression',\n          'boosting': 'gbdt',\n          'metric': 'rmse',\n          'learning_rate': 0.1,\n          'seed' : SEEDS}","beef7d89":"feature_importances = pd.DataFrame()\nresult = {}\noof_df = pd.DataFrame(train_data.id_seqpos)\n\nfor target in targets:\n    oof = pd.DataFrame()\n    preds = np.zeros(len(test_data))\n    scores = 0.0\n    \n    for n, (tr_idx, vl_idx) in enumerate(gkf.split(train_data[features], train_data['reactivity'], train_data['id'])):\n        tr_x, tr_y = train_data[features].iloc[tr_idx], train_data[target].iloc[tr_idx]\n        vl_x, vl_y = train_data[features].iloc[vl_idx], train_data[target].iloc[vl_idx]\n        vl_id = train_data['id_seqpos'].iloc[vl_idx]\n\n        model = TreeModel(model_type='lgb')\n        model.train(params, tr_x, tr_y, vl_x, vl_y,\n                    num_round=20000, early_stopping=100,verbose=1000)\n\n        fi_tmp = pd.DataFrame()\n        fi_tmp['feature'] = model.feature_names_\n        fi_tmp['importance'] = model.feature_importances_\n        fi_tmp['fold'] = n\n        fi_tmp['target'] = target\n        feature_importances = feature_importances.append(fi_tmp)\n\n        vl_pred = model.predict(vl_x)\n        score = rmse(vl_y, vl_pred)\n        scores += score \/ FOLD_N\n        print(f'score : {score}')\n\n        oof = oof.append(pd.DataFrame({'id_seqpos':vl_id, target:vl_pred}))\n\n        pred = model.predict(test_data[features])\n        preds += pred \/ FOLD_N\n    \n    oof_df = oof_df.merge(oof, on='id_seqpos', how='inner')\n    submission[target] = preds\n    \n    print(f'{target}_rmse : {scores}')\n    result[target] = scores","b8971152":"display(result)\ndisplay(f'total : {np.mean(list(result.values()))}')","1122bbc4":"# feature_importances\nfor target in targets:\n    tmp = feature_importances[feature_importances.target==target]\n    order = list(tmp.groupby('feature').mean().sort_values('importance', ascending=False).index)\n\n    plt.figure(figsize=(10, 5))\n    sns.barplot(x=\"importance\", y=\"feature\", data=tmp, order=order)\n    plt.title(target)\n    plt.tight_layout()","f279b1e8":"oof_df.head()","9f680375":"submission.head()","0b009cf3":"display(oof_df.shape)\ndisplay(submission.shape)","d1931e44":"oof_df.to_csv('oof_df.csv', index=False)\nsubmission.to_csv('submission.csv', index=False)","a024c9b2":"## Reference\nI referred to the notebook below. Thank you for sharing.  \n- https:\/\/www.kaggle.com\/t88take\/openvaccine-simple-lgb-baseline\n- https:\/\/www.kaggle.com\/mightyrains\/a-study-in-errors\n","7cc966b1":"Sorting by SN == 1 results in 66% of all data.","9959dc6c":"# train & predict","844dcf8a":"The error value is small due to SN_filter processing.","06f1458c":"# load data","5a9f7ded":"# preprocess","74f38d93":"Check Train_data2 (SN_filter <1) in the same way.\n","b59fb822":"Train_data2 has a very large error value. On the other hand, the error value of most data is small.  \nExclude large error values and extract data that may be useful for prediction."}}