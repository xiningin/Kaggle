{"cell_type":{"78feb740":"code","1b7ce627":"code","108af92e":"code","44f512dc":"code","4e4eae27":"code","83f678a0":"code","ea84a524":"code","b8f39860":"code","6eb317e3":"code","1f54a31b":"code","09927bab":"code","182728c2":"code","d37e8ce0":"code","5101b44e":"code","eaee29df":"code","ea67849c":"code","2b3431c0":"code","b30c7dc9":"code","a5e0ad15":"code","f3e0b3a9":"code","3b38fcff":"code","2215b3e9":"code","25f7d9dd":"code","ffa3d2bb":"code","15be6e11":"code","3303fdc2":"code","98b878d1":"code","69f425b9":"code","0d04dae4":"code","520d931e":"code","5998b148":"code","241f523f":"code","15d4db34":"markdown","73e3e420":"markdown","8911e1c4":"markdown","0d8df3a2":"markdown","2443cf7d":"markdown","f871080e":"markdown","d1660ffc":"markdown","aa0ca3d3":"markdown","3c799b37":"markdown","476e76d4":"markdown","f2377cf1":"markdown","bd6834bd":"markdown","466b6a75":"markdown","33083a1a":"markdown","3d2974dd":"markdown","b10f3232":"markdown","a0c960d6":"markdown","fa72d5d9":"markdown"},"source":{"78feb740":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n    \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b7ce627":"categories=['dandelion', 'daisy', 'sunflower', 'tulip', 'rose']","108af92e":"dire='\/kaggle\/input\/flowers-recognition\/flowers'","44f512dc":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfeatures=[]\nfor i in categories:\n    path=os.path.join(dire,i)\n    num_classes=categories.index(i)\n    for img in os.listdir(path):\n        if img.endswith('.jpg'):\n            \n            img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_COLOR)\n            img_array=cv2.resize(img_array,(150,150))\n            features.append([img_array,num_classes])","4e4eae27":"X=[]\ny=[]\nfor i,j in features:\n    X.append(i)\n    y.append(j)","83f678a0":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=np.random.randint(0,len(y))\n        ax[i,j].imshow(X[l])\n        ax[i,j].set_title('Flower: '+categories[y[l]])\nplt.axis('off')        \nplt.tight_layout()","ea84a524":"X=np.array(X).reshape(-1,150,150,3)\/255.0\n","b8f39860":"sns.set_style('whitegrid')\nplt.figure(figsize=(14,7))\nfig=sns.countplot(y)\nfig.set(xticks=range(len(categories)), xticklabels=[i for i in categories])\nplt.xlabel('FLOWER SPECIES')\nplt.show()\n","6eb317e3":"list_dandelion=len([i for i in y if i==0])\nlist_daisy=len([i for i in y if i==1])\nlist_sunflower=len([i for i in y if i==2])\nlist_tulip=len([ i for i in y if i==3])\nlist_rose=len([i for i in y if i==4])","1f54a31b":"list_species=[list_dandelion,list_daisy,list_sunflower,list_tulip,list_rose]\n","09927bab":"sns.set_style('whitegrid')\nplt.figure(figsize=(18,10))\nplt.pie(list_species,labels=categories,startangle=90,colors=['r','g','b','y','m'],autopct='%1.1f%%',explode = (0, 0.1, 0, 0,0),shadow=True)\nplt.legend()\nplt.show()","182728c2":"from tensorflow.keras.utils import to_categorical\ny=to_categorical(y)\n","d37e8ce0":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=12)","5101b44e":"from keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.utils import to_categorical\n\n# specifically for cnn\nfrom keras.layers import Dropout, Flatten,Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n \nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\n","eaee29df":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2, padding=\"same\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2, padding=\"same\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2, padding=\"same\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5, activation=\"softmax\"))\n","ea67849c":"epochs=50\n\nfrom keras.callbacks import ReduceLROnPlateau\nred_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)\n","2b3431c0":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","b30c7dc9":"model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","a5e0ad15":"model.summary()","f3e0b3a9":"History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=128),\n                              epochs = epochs, validation_data = (x_test,y_test),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ 128)\n# model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data = (x_test,y_test))","3b38fcff":"sns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()\n","2215b3e9":"sns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","25f7d9dd":"preds=model.predict(x_test)","ffa3d2bb":"predictions=np.argmax(preds,axis=1)","15be6e11":"correct_class=[]\nincorrect_class=[]\ni=0\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])==predictions[i]):\n        correct_class.append(i)\n    if(len(correct_class)==8):\n        break\n    \n","3303fdc2":"i=0\nfor i in range(len(y_test)):\n    \n    if (np.argmax(y_test[i])!=predictions[i]):\n        \n        incorrect_class.append(i)\n    if (len(incorrect_class)==8):\n        break\n        \n        ","98b878d1":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(x_test[correct_class[count]])\n        ax[i,j].set_title(\"Predicted Flower : \"+ categories[predictions[correct_class[count]]] +\"\\n\"+\"Actual Flower : \"+ categories[np.argmax(y_test[correct_class[count]])])\n        plt.tight_layout()\n        count+=1","69f425b9":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range(4):\n    for j in range(2):\n        ax[i,j].imshow(x_test[incorrect_class[count]])\n        ax[i,j].set_title(\"Predicted flower : \" + categories[predictions[incorrect_class[count]]] + \"\\n\"+\"Actual Flower : \" +categories[np.argmax(y_test[incorrect_class[count]])])\n        plt.tight_layout()\n        count+=1","0d04dae4":"import requests\nfrom PIL import Image\nfrom io import BytesIO\n\ndef process_image(url):\n    response=requests.get(url)\n    img=Image.open(BytesIO(response.content))\n    fix,ax=plt.subplots(1,3,figsize=(15,20))\n    ax[0].imshow(img)\n    ax[0].set_title('image')\n    \n    #grayscale and normalization\n    img=np.array(img)\n    img=cv2.cvtColor(img,cv2.IMREAD_COLOR)\n    print(img.shape)\n    img=img\/255.0\n    ax[1].imshow(img)\n    ax[1].set_title('color image')\n    \n    #resizing\n    img=cv2.resize(img,(150,150))\n    print(img.shape)\n    ax[2].imshow(img)\n    ax[2].set_title('predicted image')\n    plt.tight_layout()\n    img=np.expand_dims(img,axis=0)\n    #making it model ready\n    \n    print(img.shape)\n    return img\n\n\n    ","520d931e":"def predict(url):\n    img=process_image(url)\n    label=model.predict(img)\n    final_1=np.argmax(label,axis=1)[0]\n    plt.xlabel(categories[final_1])\n    return categories[final_1]","5998b148":"predict(\"https:\/\/media4.picsearch.com\/is?LwsQDsAhRnF2IV-PP61f1fCUcQWD2jYoz6X55V_6-dg&height=266\") ","241f523f":"predict(\"https:\/\/media5.picsearch.com\/is?8agnR1fAz2qzGkGmQsnFEb0nXkmuh-7hb-Il2rLLd7U&height=341\")","15d4db34":"# lets visualize our model functioning","73e3e420":"# Splitting the data","8911e1c4":"> # OneHotEncoding:To deal with categorical values we need to preprocess it using onehot ecnoding","0d8df3a2":"# initializing the working directory","2443cf7d":"# Model building","f871080e":"# Analysing the predicitons","d1660ffc":"# Experiment and Fun","aa0ca3d3":"# visualizations: lets have a look on our dataset","3c799b37":">Thats all kagglers.Please upvote my notebook if you found it informative and helpful.\n> If you want to give any suggestions  and queries regarding notebbok please feel free to mention it in comments","476e76d4":"> # Data Augmentation:It is the technique used to overome the problem of overfitting and make our model to generalize well on the unseen data.For more info [Click Here](https:\/\/towardsdatascience.com\/data-augmentation-for-deep-learning-4fe21d1a4eb9)","f2377cf1":"# Preprocessing: separating the features and lables form the data","bd6834bd":"# Reshaping and normalizing: the need of resizing the feature vetcor x is to meet the keras requirement and normalization is done to scale all the values in a similar range","466b6a75":"# Loading Data**: This is the first and most important step to begin with the process**","33083a1a":"> Well this is for experiment and have fun with the model you have built.You can load images from the internet and predict using the code written below","3d2974dd":"# Its time for prediction ","b10f3232":"#  lets see how our class lables are distributed","a0c960d6":"# the categories  of flowers we want to classify","fa72d5d9":"> The image we want to predict is also needed to be preprocessed according to the requirements of the model.You need to take care of resizing  like we did below to resize it in (150,150) dimensions"}}