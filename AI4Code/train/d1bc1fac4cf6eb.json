{"cell_type":{"3988c6e5":"code","94235614":"code","120bab82":"code","fad91312":"code","6dd490e0":"code","8799d2d7":"code","0befe2b9":"code","627b6436":"code","0724eaaf":"code","cff3f6ba":"code","b1799c00":"code","e7cf0147":"code","7c06efde":"code","b586e57b":"code","0fc4efb9":"code","514d5243":"code","6e42f876":"markdown","364ec4f3":"markdown"},"source":{"3988c6e5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","94235614":"path='\/kaggle\/input\/quora-insincere-questions-classification\/train.csv'\ntrain = pd.read_csv(path,nrows=1000)\ntrain.head()","120bab82":"#target=0 - can be asked in public forum\n#target=1 - insincere questions\n#qid is just ID - we can ignore","fad91312":"## converting every character to lower case\ndocs=train['question_text'].str.lower()\ndocs.sample(20)\n","6dd490e0":"##remove non-alphabets\ndocs= docs.str.replace('[^a-z ]','') # retaining alphabets, spaces and remove evrything else","8799d2d7":"## remove commonly used words\n\nimport nltk #natural language tool kit\nstopwords=nltk.corpus.stopwords.words('english')\nstemmer=nltk.stem.PorterStemmer()\ndef clean_sentance(doc):\n    words=doc.split(' ')\n    words_clean=[stemmer.stem(word) for word in words if word not in stopwords] #removing the common words\n# and stemming all the words\n    return ' '.join(words_clean) #because sklearn expects one string\n    \ndocs=docs.apply(clean_sentance)","0befe2b9":"#docs.apply(lambda v: v.split(' ')).head() - another way","627b6436":"#Example\n\n# stemmer=nltk.stem.PorterStemmer()\n# stemmer.stem('organization')","0724eaaf":"# Document term matrix- is also called as sparsity matrix because maximum will be 0 in the matrix","cff3f6ba":"#Term Frequency - Inverse Document Frequency (TF-IDF)","b1799c00":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\ndtm_vectorizer=CountVectorizer()\n\ntrain_x,validate_x,train_y,validate_y=train_test_split(docs,train['target'],test_size=0.2,random_state=1)\n\ndtm_vectorizer.fit(train_x) #it only identifies unique words - only fit\n\n#do not use fit and transform together\n\n#always first fit and then transform on training, testing etc\n#or the columns order will change in the test data\n\n\ndtm_train=dtm_vectorizer.transform(train_x) # we are tranforming here on train data\n#it will compress the matrix, ignore 0's and only give number - compressed output and will give it as input to model\ndtm_validate=dtm_vectorizer.transform(validate_x) # we are tranforming here on test data\n","e7cf0147":"dtm_train #2405 unique values in training matrix\n\n#800x2405 - total number of elements\n#out of whihc 4822 non 0 values we have\n# most of the are 0's. Hence, sparse metrix","7c06efde":"df_dtm_train=pd.DataFrame(dtm_train.toarray(),columns=dtm_vectorizer.get_feature_names(),index=train_x.index)\ndf_dtm_train","b586e57b":"df_dtm_train.sum().sort_values(ascending=False).head(20).plot.bar()","0fc4efb9":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB().fit(dtm_train,train_y)\ntrain_y_pred=model.predict(dtm_validate)\n\nfrom sklearn.metrics import accuracy_score,f1_score\nprint(accuracy_score(validate_y,train_y_pred))\nprint(f1_score(validate_y,train_y_pred))","514d5243":"from nltk.sentiment import SentimentIntensityAnalyzer\nsentiment_analyzer=SentimentIntensityAnalyzer()\nsentiment_analyzer.polarity_scores('i like india')","6e42f876":"# Text Mining","364ec4f3":"## Methods to convert text to numerical values\n- Document Term Matrix\/Term Document Metrix\n- Using word2vec\/Doc2vec\n\n## Text cleaning for classification\/regression\/clustering\n- Convert every character to lower case\n- Using regular expression retail only alphabets (sometimes numbers, symbols(#&@ etc))\n- Remove commonly used words\n- Identify root form of the word (stemming, lemmatization)"}}