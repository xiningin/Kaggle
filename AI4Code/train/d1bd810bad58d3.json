{"cell_type":{"328931fb":"code","ca587df6":"code","5889549d":"code","9b87b428":"code","bf42832d":"code","41a59f5f":"code","6d17defb":"code","72fed4b2":"code","8befb7b4":"code","666905a4":"code","cd58524a":"code","bb381291":"code","a1042b08":"code","f66911b0":"code","177dbe2d":"code","b84ac798":"code","5f542d7a":"code","a5c4b2f0":"code","ce501130":"code","e87ed408":"code","0bfae438":"code","3a5b5757":"code","ee16e719":"code","326ee575":"code","f4c03264":"code","8bf546cb":"code","42cadde2":"code","cc774217":"code","677fea42":"code","2296efe7":"code","b2299473":"code","12e50f12":"code","36ebeb33":"code","e4651d71":"code","9a6c5565":"code","aa026529":"code","d8f3336c":"code","717843dc":"code","616ce513":"code","3acc2791":"code","88742696":"code","f1c06a5e":"markdown","268a88e4":"markdown","a68b56f0":"markdown","00ba88cb":"markdown","f41eb91f":"markdown","1e67f218":"markdown","a6de69fc":"markdown","1ad6b285":"markdown","81274096":"markdown","c8d92268":"markdown","1bddf554":"markdown","3a992d9d":"markdown","27e3cbaa":"markdown","96cd46f6":"markdown","5758d5ff":"markdown","41831836":"markdown","4e24004d":"markdown","588eaad7":"markdown","3ecb8d48":"markdown","808ba53f":"markdown","fca7362a":"markdown"},"source":{"328931fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = 100\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ca587df6":"## Task 1: Reading and Inspection\n### Subtask 1.1: Import and read\n#Import and read the movie database. Store it in a variable called `movies`.\nmovies = pd.read_csv('\/kaggle\/input\/imdb-dataset19162016-python-for-data-science\/MovieAssignmentData.csv')","5889549d":"# Write your code for inspection here\nmovies.head() #Checking first 5 rows","9b87b428":"movies.count() # Checking the count of all the present cell values in each columns.","bf42832d":"movies.shape # Checking the shape of the dataset.\n# The data set has - 5043 Rows & 28 Columns","41a59f5f":"movies.info() #Checking information of the dataset\n#This provides us the sum of all the non-null values in each column and the datatype of the column.","6d17defb":"null_val = movies.isnull()\nnull_val\n# .isnull() returns boolean values , True if the cell is Null , False if the cell is Non-Null ","72fed4b2":"# Writing code for column-wise null count\nnull_sum_col = null_val.sum()\nnull_sum_col\n","8befb7b4":"# Writing code for column-wise null percentages \nnull_percentage = null_val.mean().round(4)*100\nnull_percentage","666905a4":"movies.columns\n#Dropping unnecessary columns","cd58524a":"# Writing code for dropping the columns. It is advised to keep inspecting the dataframe after each set of operations \nmovies.drop(['color', 'director_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes','actor_3_facebook_likes','actor_2_name',\n             'cast_total_facebook_likes','actor_3_name','duration','facenumber_in_poster','content_rating',\n             'country','movie_imdb_link','aspect_ratio','plot_keywords'], axis = 1 , inplace=True)","bb381291":"movies.columns","a1042b08":"dict(null_percentage)\n#Dictionary for all the columns with respective null percentage","f66911b0":"# Writing code for dropping the rows which have more than 5 null values\n# Drop column rows with null values\nexclude_columns = []\nfor col_name, percentage in dict(null_percentage).items():\n    if percentage> 5:\n        print (col_name)\n        exclude_columns.append(col_name)","177dbe2d":" movies.head()","b84ac798":"list1 = []\nfor c in exclude_columns:\n    if c in movies:\n        for i in range(len(movies[c])):\n            if np.isnan(movies[c][i]):\n                #print(i)\n                list1.append(i)\n                \nlist1 = set(list1)\nprint(list1)\nmovies.drop(list(list1), axis = 0, inplace=True)","5f542d7a":"movies.count()","a5c4b2f0":"movies.info()","ce501130":"#Code for dropping the rows here\nmovies.drop(movies[movies.isnull().sum(axis=1)>5].index,axis=0,inplace=True)\n\nprint(round(100*(1-movies.count()\/len(movies)),2))","e87ed408":"for i in range(len(movies.index)) :\n    print(\"Null in row \", i , \" : \" ,  movies.iloc[i].isnull().sum())","0bfae438":"# Code for filling the NaN values in the 'language' column here\nmovies[\"language\"].fillna(\"English\", inplace = True) \n  \nmovies\n\n","3a5b5757":"# Code for checking number of retained rows here\nretained_rows_percentage = (3891\/5043)*100\nretained_rows_percentage","ee16e719":"# Code for unit conversion here\nmovies['budget'] = movies['budget']\/1000000 \nmovies['gross'] = movies['gross']\/1000000\n","326ee575":"movies.head()","f4c03264":"# Code for creating the profit column here\nmovies['Profit'] = movies['gross'] - movies['budget']\nmovies.head()\n","8bf546cb":"# Code for sorting the dataframe here\nmovies.sort_values(\"Profit\", axis = 0, ascending = False, \n                 inplace = True) \nmovies.head()\n","42cadde2":"# Code for dropping duplicate values here\nmovies.drop_duplicates(subset=None, keep='first', inplace=True)\n\n\n","cc774217":"# Code for repeating subtask 2 here\n# top10 = movies.iloc[0:10]\ntop10 = movies.sort_values(by=['Profit'],ascending=False).head(10)\ntop10\n","677fea42":"# Code for extracting the top 250 movies as per the IMDb score here. Make sure that you store it in a new dataframe \n# and name that dataframe as 'IMDb_Top_250'\n\n\nIMDb_Top_250= movies.sort_values(by=['imdb_score'],ascending=False).head(250)\nIMDb_Top_250.loc[(IMDb_Top_250.num_voted_users>25000),:]\nIMDb_Top_250['Rank']=range(1,251)\nIMDb_Top_250","2296efe7":"# foreign_language = {}\n# for i in IMDb_Top_250['language']:\n#     if i not in foreign_language:\n#         foreign_language[i] = 1\n#     else:\n#         temp = foreign_language[i]\n#         foreign_language[i] = temp + 1\n# print(foreign_language)\n\nTop_Foreign_Lang_Film =IMDb_Top_250.loc[(IMDb_Top_250.language != 'English'),:]       # Code to extract top foreign language films from 'IMDb_Top_250' here\nTop_Foreign_Lang_Film ","b2299473":"Top_Foreign_Lang_Film = IMDb_Top_250.loc[IMDb_Top_250['language'] == 'Mandarin']['movie_title']\nTop_Foreign_Lang_Film","12e50f12":"# Code for extracting the top 10 directors here\ntop10director=movies.groupby('director_name')['imdb_score'].mean().sort_values(ascending=False).head(10)\ntop10director","36ebeb33":"# Code for extracting the first two genres of each movie here\nfirst=movies['genres'].apply(lambda x: pd.Series(x.split('|')))\nmovies['genre_1']=first[0]\nmovies['genre_2']=first[1]\nmovies.loc[pd.isnull(movies['genre_2']), ['genre_2']] = movies['genre_1']\nprint(movies.genre_1)\nprint(movies.genre_2)\n","e4651d71":"#Grouping by first 2 genres\nmovies_by_segment =movies.groupby(['genre_1','genre_2'])\nmovies_by_segment\n","9a6c5565":"PopGenre = movies_by_segment['gross'].mean().sort_values(ascending=False).head(5)\nPopGenre\n","aa026529":"# Code for creating three new dataframes here\n\nMeryl_Streep = movies.loc[(movies.actor_1_name=='Meryl Streep'),:].head(3891)\nMeryl_Streep","d8f3336c":"#Checking Leonardo DiCaprio's movies\nLeo_Caprio = movies.loc[(movies.actor_1_name=='Leonardo DiCaprio'),:].head(3891)\nLeo_Caprio","717843dc":"#Checking Brad_Pitt's movies\nBrad_Pitt = movies.loc[(movies.actor_1_name=='Brad Pitt'),:].head(3891)\nBrad_Pitt","616ce513":"# Code for combining the three dataframes here\nCombined_df = Meryl_Streep.append(Leo_Caprio).append(Brad_Pitt)\nCombined_df\n","3acc2791":"# Code for grouping the combined dataframe here\nactor_name=Combined_df.groupby('actor_1_name')\nactor_name","88742696":"# Code for finding the mean of critic reviews and audience reviews here\ncritic_reviews=actor_name['num_critic_for_reviews'].mean().sort_values(ascending=False).head(49)\nprint(critic_reviews)\naudience_reviews=actor_name['num_user_for_reviews'].mean().sort_values(ascending=False).head(49)\nprint(audience_reviews)\n","f1c06a5e":"- ### Subtask 3.5: Find the best directors\n\n    1. Group the dataframe using the `director_name` column.\n    2. Find out the top 10 directors for whom the mean of `imdb_score` is the highest and store them in a new dataframe `top10director`. ","268a88e4":"### Subtask 1.2: Inspect the dataframe\n##Inspect the dataframe's columns, shapes, variable types etc.","a68b56f0":"**Checkpoint 6:** `Leonardo` has aced both the lists!","00ba88cb":"movie(language)","f41eb91f":"-  ### Subtask 3.3: Drop duplicate values\n\nAfter you found out the top 10 profiting movies, you might have notice a duplicate value. So, it seems like the dataframe has duplicate values as well. Drop the duplicate values from the dataframe and repeat `Subtask 3.2`.","1e67f218":"-  ### Subtask 2.4: Drop unecessary rows\n\nSome of the rows might have greater than five NaN values. Such rows aren't of much use for the analysis and hence, should be removed.","a6de69fc":"-  ### Subtask 2.5: Fill NaN values\n\nYou might notice that the `language` column has some NaN values. Here, on inspection, you will see that it is safe to replace all the missing values with `'English'`.","1ad6b285":"-  ### Subtask 3.2: Find the movies with highest profit\n\n    1. Create a new column called `profit` which contains the difference of the two columns: `gross` and `budget`.\n    2. Sort the dataframe using the `profit` column as reference.\n    3. Extract the top ten profiting movies in descending order and store them in a new dataframe - `top10`","81274096":"## Task 3: Data Analysis\n\n-  ### Subtask 3.1: Change the unit of columns\n\nConvert the unit of the `budget` and `gross` columns from `$` to `million $`.","c8d92268":"## Task 2: Cleaning the Data\n\n-  ### Subtask 2.1: Inspecting Null values\n\nFinding out the number of Null values in all the columns and rows. Also, finding the percentage of Null values in each column. Round off the percentages upto two decimal places.","1bddf554":"-  ### Subtask 3.6: Find popular genres\n\nYou might have noticed the `genres` column in the dataframe with all the genres of the movies seperated by a pipe (`|`). Out of all the movie genres, the first two are most significant for any film.\n\n1. Extract the first two genres from the `genres` column and store them in two new columns: `genre_1` and `genre_2`. Some of the movies might have only one genre. In such cases, extract the single genre into both the columns, i.e. for such movies the `genre_2` will be the same as `genre_1`.\n2. Group the dataframe using `genre_1` as the primary column and `genre_2` as the secondary column.\n3. Find out the 5 most popular combo of genres by finding the mean of the gross values using the `gross` column and store them in a new dataframe named `PopGenre`.","3a992d9d":"**Checkpoint 5:** Well, as it turns out. `Family + Sci-Fi` is the most popular combo of genres out there!","27e3cbaa":"**Checkpoint 2:** You might spot two movies directed by `James Cameron` in the list.","96cd46f6":"**Checkpoint 4:** No surprises that `Damien Chazelle` (director of Whiplash and La La Land) is in this list.","5758d5ff":"**Checkpoint 3:** Can you spot `Veer-Zaara` in the dataframe?","41831836":"-  ### Subtask 3.4: Find IMDb Top 250\n\n    1. Create a new dataframe `IMDb_Top_250` and store the top 250 movies with the highest IMDb Rating (corresponding to the column: `imdb_score`). Also make sure that for all of these movies, the `num_voted_users` is greater than 25,000.\nAlso add a `Rank` column containing the values 1 to 250 indicating the ranks of the corresponding films.\n    2. Extract all the movies in the `IMDb_Top_250` dataframe which are not in the English language and store them in a new dataframe named `Top_Foreign_Lang_Film`.","4e24004d":"-  ### Subtask 2.2: Drop unecessary columns\n\nFor this assignment, you will mostly be analyzing the movies with respect to the ratings, gross collection, popularity of movies, etc. So many of the columns in this dataframe are not required. So it is advised to drop the following columns.\n-  color\n-  director_facebook_likes\n-  actor_1_facebook_likes\n-  actor_2_facebook_likes\n-  actor_3_facebook_likes\n-  actor_2_name\n-  cast_total_facebook_likes\n-  actor_3_name\n-  duration\n-  facenumber_in_poster\n-  content_rating\n-  country\n-  movie_imdb_link\n-  aspect_ratio\n-  plot_keywords","588eaad7":"**Checkpoint 1:** You might have noticed that we still have around `77%` of the rows!","3ecb8d48":"-  ### Subtask 2.3: Drop unecessary rows using columns with high Null percentages\n\nNow, on inspection you might notice that some columns have large percentage (greater than 5%) of Null values. Drop all the rows which have Null values for such columns.","808ba53f":"-  ### Subtask 2.6: Check the number of retained rows\n\nYou might notice that two of the columns viz. `num_critic_for_reviews` and `actor_1_name` have small percentages of NaN values left. You can let these columns as it is for now. Check the number and percentage of the rows retained after completing all the tasks above.","fca7362a":"-  ### Subtask 3.7: Find the critic-favorite and audience-favorite actors\n\n    1. Create three new dataframes namely, `Meryl_Streep`, `Leo_Caprio`, and `Brad_Pitt` which contain the movies in which the actors: 'Meryl Streep', 'Leonardo DiCaprio', and 'Brad Pitt' are the lead actors. Use only the `actor_1_name` column for extraction. Also, make sure that you use the names 'Meryl Streep', 'Leonardo DiCaprio', and 'Brad Pitt' for the said extraction.\n    2. Append the rows of all these dataframes and store them in a new dataframe named `Combined`.\n    3. Group the combined dataframe using the `actor_1_name` column.\n    4. Find the mean of the `num_critic_for_reviews` and `num_user_for_review` and identify the actors which have the highest mean."}}