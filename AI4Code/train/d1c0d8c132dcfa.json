{"cell_type":{"72102699":"code","086ad0c7":"code","1a68851e":"code","e1ee9a40":"code","743f5844":"code","8f0defe9":"code","ce72c2fb":"code","62e0d0d1":"code","e2aea7bb":"code","54607f99":"code","637c47d1":"code","06de7e3e":"code","6200e486":"code","ced0e7f6":"code","265e2e08":"code","e27130d3":"code","5ddaac1b":"code","ef89785e":"code","27687edd":"code","f45f5b5c":"code","39dcb3d0":"code","43d11cd5":"code","89fec6cd":"code","223e7639":"code","985a5a94":"code","c89cd20b":"code","39a2cc1a":"code","8eafd693":"markdown"},"source":{"72102699":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport glob\nimport shutil\nimport imageio\nfrom IPython import display\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport PIL\nfrom tensorflow.keras import layers\nimport time\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","086ad0c7":"import csv\nwith open('.\/training_labels.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"filename\", \"label\"])\n    a = glob.glob('..\/input\/xrayfortoothroot\/xrays database\/1 root\/*')\n    for i in range(len(a)):\n        writer.writerow([a[i],\"1Root\"])\n    \nwith open('.\/training_labels2.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"filename\", \"label\"])   \n    b = glob.glob('..\/input\/xrayfortoothroot\/xrays database\/2 or more roots\/*')\n    for i in range(len(b)):\n        writer.writerow([b[i],\"2Root\"])\n    ","1a68851e":"def make_generator_model():\n        model = tf.keras.Sequential()\n        model.add(layers.Dense(14*14*256, use_bias=False, input_shape=(100,)))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Reshape((14, 14, 256)))\n        assert model.output_shape == (None, 14, 14, 256) # Note: None is the batch size\n\n        model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n        assert model.output_shape == (None, 14, 14, 128)\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n        assert model.output_shape == (None, 28, 28, 64)\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n        \n        model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n        assert model.output_shape == (None, 56, 56, 32)\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n        \n        model.add(layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n        assert model.output_shape == (None, 112, 112, 16)\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n        assert model.output_shape == (None, 224, 224, 3)\n\n        return model","e1ee9a40":"def make_discriminator_model():\n        model = tf.keras.Sequential()\n        model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                         input_shape=[224, 224, 3]))\n        model.add(layers.LeakyReLU())\n        model.add(layers.Dropout(0.3))\n\n        model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n        model.add(layers.LeakyReLU())\n        model.add(layers.Dropout(0.3))\n\n        model.add(layers.Flatten())\n        model.add(layers.Dense(1))\n\n        return model","743f5844":"BATCH_SIZE = 25\nnoise_dim = 100\nEPOCHS = 1500\ngenerator = make_generator_model()\ndiscriminator = make_discriminator_model()\nnum_examples_to_generate = 16\nSEED = tf.random.normal([num_examples_to_generate, noise_dim])\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ncheckpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)\n","8f0defe9":"def discriminator_loss(real_output, fake_output):\n        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss\ndef generator_loss(fake_output):\n        return cross_entropy(tf.ones_like(fake_output), fake_output)","ce72c2fb":"!mkdir .\/1s\/\n!mkdir .\/2s\/\n!mkdir .\/demo\/","62e0d0d1":"def generate_and_evaluate_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('.\/demo\/image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","e2aea7bb":"def generate_and_save_images(model, test_input, folder, name):\n      # Notice `training` is set to False.\n      # This is so all layers run in inference mode (batchnorm).\n      predictions = model(test_input, training=False)\n     # fig = plt.figure(figsize=(4,4))\n      for i in range(predictions.shape[0]):\n#           plt.subplot(4, 4, i+1)\n          plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n          plt.axis('off')\n          plt.savefig(f'.\/{folder}\/{name}{i}.jpg')\n\n      \n      plt.show()","54607f99":"# create a line plot of loss for the gan and save to file\ndef plot_history(d_hist, g_hist):\n    # plot loss\n    plt.subplot(2, 1, 1)\n    plt.plot(d_hist, label='disc')\n    plt.plot(g_hist, label='gen')\n    plt.legend()\n    \n    # save plot to file\n    plt.savefig('results_baseline\/plot_line_plot_loss.png')\n    plt.close()","637c47d1":"@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n    \n      \n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    # record history\n#     for i in range(BATCH_SIZE):\n#         d_hist.append(disc_loss[i])\n#         g_hist.append(gen_loss[i])\n\ndef train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    # Produce images for the GIF as we go\n    #display.clear_output(wait=True)\n    if (epoch + 1) % 50 == 0:\n       generate_and_evaluate_images(generator,\n                             epoch + 1,\n                             SEED) \n    # Save the model every 15 epochs\n    if (epoch + 1) % 500 == 0:\n       checkpoint.save(file_prefix = checkpoint_prefix)\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n    \n#   plot_history(d_hist, g_hist)\n\n  # Generate after the final epoch\n  #display.clear_output(wait=True)\n#   generate_and_save_images(generator,\n#                            epochs,\n#                            seed)\n","06de7e3e":"def generateImage(classes):\n    \n    train_images = []\n    data = pd.read_csv(classes)\n    X = data[['filename']]\n    for i in range(X.shape[0]):\n        img = cv2.imread(X[\"filename\"][i], cv2.IMREAD_UNCHANGED)\n        img = cv2.resize(img, (224,224))\n        train_images.append(np.array(img))\n    #trains = np.concatenate([arr[np.newaxis] for arr in train_images])\n    trains = np.array(train_images)\n    #print(train_images[7].shape)\n    train_images = (trains - 127.5) \/ 127.5 # Normalize the images to [-1, 1]\n    tf.convert_to_tensor(train_images)\n    # Batch and shuffle the data\n    BUFFER_SIZE = X.shape[0]\n    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n    \n    train(train_dataset, EPOCHS)\n\n#     #restore the latest checkpoint\n#     checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n#     checkpoint.save(file_prefix = checkpoint_prefix)","6200e486":"generateImage('training_labels.csv')","ced0e7f6":"num_examples_to_generate = 200\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\nfolder = \"1s\"\nname = \"one\"\ngenerate_and_save_images(generator,seed,folder,name)","265e2e08":"generateImage('training_labels2.csv')","e27130d3":"num_examples_to_generate = 200\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\nfolder = \"2s\"\nname = \"two\"\ngenerate_and_save_images(generator,seed,folder, name)","5ddaac1b":"# Display a single image using the epoch number\ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n#display_image(3000)","ef89785e":"a = glob.glob('..\/input\/xrayfortoothroot\/xrays database\/1 root\/*')\nfor i in range(len(a)):\n    shutil.copy(a[i], '.\/1s\/') \n    \nb = glob.glob('..\/input\/xrayfortoothroot\/xrays database\/2 or more roots\/*')\nfor i in range(len(b)):\n    shutil.copy(b[i], '.\/2s\/')\n","27687edd":"with open('.\/train1_labels1.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"filename\", \"label\"])\n    a = glob.glob('.\/1s\/*')\n    for i in range(len(a)):\n        writer.writerow([a[i],\"1Root\"])\n    \n    b = glob.glob('.\/2s\/*')\n    for i in range(len(b)):\n        writer.writerow([b[i],\"2Root\"])","f45f5b5c":"a = glob.glob('.\/1s\/*')\nb=glob.glob('.\/2s\/*')\nprint(len(a)+len(b))","39dcb3d0":"#Using 5-fold cross validation \ntrain_data = pd.read_csv('train1_labels1.csv')\nY = train_data[['label']]\n\nkf = KFold(5, shuffle = True)","43d11cd5":"print(len(Y))","89fec6cd":"idg = ImageDataGenerator(preprocessing_function =tf.keras.applications.xception.preprocess_input,rescale= 1\/255,\n                         rotation_range=20,zoom_range=0.30,width_shift_range=0.2,height_shift_range=0.2,\n                                    featurewise_center=True,brightness_range=[.5,1.5],shear_range=0.15,\n                         horizontal_flip=True, vertical_flip = True)","223e7639":"def get_model_name(k):\n    return 'model_'+str(k)+'.h5'","985a5a94":"#TENSORBOARD_SETUP\n!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir .\/logs\/ --host 0.0.0.0 --port 6006 &\",\n                        \".\/ngrok http 6006 &\"\n                        ]]","c89cd20b":"#TENSORBOARD_SETUP\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","39a2cc1a":"VALIDATION_ACCURACY = []\nVALIDATION_LOSS = []\n!mkdir .\/saved_models\/\nsave_dir = '.\/saved_models\/'\nfold_var = 1\nn = len(a)+len(b)\nfor train_index, val_index in kf.split(np.zeros(n),Y):\n    training_data = train_data.iloc[train_index]\n    validation_data = train_data.iloc[val_index]\n\n    valid_data_generator  = idg.flow_from_dataframe(validation_data,\n                x_col = \"filename\", y_col = \"label\",\n                class_mode = \"categorical\", shuffle = True)\n    train_data_generator = idg.flow_from_dataframe(training_data,\n                   x_col = \"filename\", y_col = \"label\",\n                   class_mode = \"categorical\", shuffle = True)\n    \n    #print(\"kjdjfgghgdhgjhgfgjh>>>>>>>><MM<<<<<<<<<<<<<hhjghjghg\")\n\n    # CREATE NEW MODEL\n    new_input = tf.keras.Input(shape=(224, 224,3))\n    model = tf.keras.applications.Xception(weights='imagenet', include_top=False, \n                                        input_tensor=new_input, input_shape=(224, 224, 3),pooling ='avg')\n    #print(\"kjdjfgghgdhgjhgfgjh>>>>>>>><MM<<<<<<<<<<<<<hhjghjghg\")\n    for layer in model.layers:\n        layer.trainable = False\n    for layer in model.layers[90:137]:\n        if 'conv' in layer.name:\n            layer.trainable = True\n    flat1 = tf.keras.layers.Flatten()(model.layers[-1].output)\n    drop = tf.keras.layers.Dropout(.4)(flat1) # this is added later as model was overfitting the data\n    class1 = tf.keras.layers.Dense(256, activation='relu')(drop)\n    #class1 = tf.keras.layers.BatchNormalization()(flat1)\n    #class2 = tf.keras.layers.Dense(256, activation='relu')(class1)\n    drop1 = tf.keras.layers.Dropout(.2) (class1) \n    output = tf.keras.layers.Dense(2, activation='softmax')(drop1)\n    model = tf.keras.Model(inputs=model.inputs, outputs=output)\n    #print(\"kjdjfgghgdhgjhgfgjh>>>>>>>><MM<<<<<<<<<<<<<hhjghjghg\")\n    \n    # COMPILE NEW MODEL\n    opt = tf.keras.optimizers.Adam(lr=0.0001)\n    model.compile(loss='categorical_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy'])\n\n    # CREATE CALLBACKS\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n                monitor='val_accuracy', verbose=1, \n                save_best_only=True, mode='max')\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=.2, cooldown=2, patience=8, \n                      verbose=0, mode='auto',\n                      min_lr=0.0000001)\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n    log_dir = \"logs\/fit\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n    callbacks_list = [checkpoint, reduce_lr, early_stop, tensorboard_callback]\n    #print(\"kjdjfgghgdhgjhgfgjh>>>>>>>><MM<<<<<<<<<<<<<hhjghjghg\")\n    # FIT THE MODEL\n    history = model.fit(train_data_generator,epochs=40,\n    callbacks=callbacks_list,\n    validation_data=valid_data_generator)\n    #print(\"kjdjfgghgdhgjhgfgjh>>>>>>>><MM<<<<<<<<<<<<<hhjghjghg\")\n    # LOAD BEST MODEL to evaluate the performance of the model\n    model.load_weights(\".\/saved_models\/model_\"+str(fold_var)+\".h5\")\n    \n    results = model.evaluate(valid_data_generator)\n    results = dict(zip(model.metrics_names,results))\n\n    VALIDATION_ACCURACY.append(results['accuracy'])\n    VALIDATION_LOSS.append(results['loss'])\n\n    tf.keras.backend.clear_session()\n\n    fold_var += 1","8eafd693":"**Xray image Classification of 1 root and 2 root teeth. Dataset was very small (only 156 images), so Generative Adversarial Network was used to produce more synthetic images for better generalization of the result. Transfer learning, fine-tuning, k-fold learning and augmentation were used to get better performance and by a considerable hard-work, I managed to obtain an accuracy of 95% on the best model which was also consistent throughout the training showing better generalization.**"}}