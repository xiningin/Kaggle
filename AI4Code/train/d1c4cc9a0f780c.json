{"cell_type":{"447c6f71":"code","88c3c487":"code","65a33034":"code","c3b9b3a6":"code","602d9cc1":"code","25f6ec8c":"code","c5dc80b6":"code","9c2f26ad":"code","a1a733af":"code","5ae3ef6b":"code","e0f3bbef":"code","a407e818":"code","96538480":"markdown","77e6cbdf":"markdown","8286cc1c":"markdown","3143a175":"markdown"},"source":{"447c6f71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n!pip install fastai==0.7.0\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fastai.imports import *\nfrom fastai.structured import *\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\nfrom sklearn import metrics\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","88c3c487":"df_raw = pd.read_csv('..\/input\/train\/Train.csv', low_memory=False, parse_dates=[\"saledate\"])\ndf_test = pd.read_csv('..\/input\/Test.csv',low_memory=False, parse_dates=[\"saledate\"])\ndf_test.columns","65a33034":"#Converting saleprice to log since competition rules state using rmsle\ndf_raw.SalePrice = np.log(df_raw.SalePrice)","c3b9b3a6":"add_datepart(df_raw,'saledate')\nadd_datepart(df_test,'saledate')","602d9cc1":"train_cats(df_raw)\napply_cats(df_test,df_raw)","25f6ec8c":"X, y , nas = proc_df(df_raw, 'SalePrice') #training\nX_test, _, nas = proc_df(df_test, na_dict=nas)\nX, y , nas = proc_df(df_raw, 'SalePrice', na_dict=nas)","c5dc80b6":"def split_vals(a,n): return a[:n].copy(), a[n:].copy()","9c2f26ad":"n_valid = 12000 #kaggle's test set size\nn_trn = len(X) - n_valid\nraw_train, raw_valid = split_vals(df_raw, n_trn)\nX_train, X_valid = split_vals(X, n_trn)  #splitting the data except the prediction variable \ny_train, y_valid = split_vals(y, n_trn)   #splitting the prediction variable - saleprice ","a1a733af":"#Defining some functions for measuring performance \ndef rmse(x,y): return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","5ae3ef6b":"m = RandomForestRegressor(n_estimators=150, min_samples_leaf=3, max_features=0.7, n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","e0f3bbef":"prediction = m.predict(X_test)","a407e818":"submission = pd.DataFrame()\nsubmission['id_column']=df_test.SalesID\nsubmission['SalePrice']= prediction\nsubmission.to_csv('submission.csv',index=False)","96538480":"**Preprocessing Data**","77e6cbdf":"**Building model with training set**","8286cc1c":"**Dividing data into training and validation sets**","3143a175":"**Submission**"}}