{"cell_type":{"64bf9452":"code","d3dd828c":"code","a61500fc":"code","3f4ba29f":"code","94824305":"code","a1993784":"code","a5423198":"code","30210ee7":"code","43a07551":"code","be925ecb":"code","33f0c227":"code","17751dcf":"code","f368f593":"code","37e55766":"code","270cade5":"code","2e5d238a":"code","2c96361a":"code","d15c7a9c":"code","1c7f0d7b":"code","20f5dd3f":"markdown"},"source":{"64bf9452":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd","d3dd828c":"train=pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_train.csv')\ntest=pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_test.csv')","a61500fc":"train.head()","3f4ba29f":"train.info()","94824305":"test.info()","a1993784":"train.shape","a5423198":"test.shape","30210ee7":"labels = train['label'].values\nplt.figure(figsize = (14,8))\nsns.countplot(x =labels)","43a07551":"\nX_train = train.drop([\"label\"],axis=1)\nX_test = test.drop([\"label\"],axis=1)\nY_train = train['label']\nY_test = test['label']\ndel train['label']\ndel test['label']","be925ecb":"X_train = X_train\/255.0\nX_test = X_test\/255.0\nX_train.shape\nX_test.shape","33f0c227":"X_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nX_train.shape\nX_test.shape","17751dcf":"from sklearn.preprocessing import LabelBinarizer\nlabel_binrizer = LabelBinarizer()\nY_train = label_binrizer.fit_transform(Y_train)","f368f593":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","37e55766":"from sklearn.metrics import confusion_matrix\nimport itertools\nimport tensorflow as tf\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nmodel = tf.keras.models.Sequential([\n                        tf.keras.layers.Conv2D(64, (3, 3), activation='relu',padding = 'same', input_shape=(28, 28, 1)),\n                        tf.keras.layers.MaxPooling2D(2, 2),\n                        tf.keras.layers.Conv2D(128, (3, 3),padding = 'same', activation='relu'),\n                        tf.keras.layers.MaxPooling2D(2, 2),\n                        tf.keras.layers.Conv2D(512, (3, 3),padding = 'same', activation='relu'),\n                        tf.keras.layers.MaxPooling2D(2, 2),\n                        \n                        tf.keras.layers.Conv2D(512, (3, 3),padding = 'same', activation='relu'),\n                        tf.keras.layers.Flatten(),\n                        tf.keras.layers.Dense(512, activation='relu'),\n                        tf.keras.layers.Dense(24, activation='softmax')])\nmodel.summary()","270cade5":"#optimizer = Adam(lr=0.003, beta_1=0.9, beta_2=0.999)\n\nmodel.compile( optimizer='rmsprop' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","2e5d238a":"epochs = 50 \nbatch_size = 200\n","2c96361a":"#Data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False, \n        zca_whitening=False,\n        rotation_range=15, \n        zoom_range = 0.5,\n        width_shift_range=0.15,  \n        height_shift_range=0.15, \n        horizontal_flip=True,  \n        vertical_flip=False)  \n\ndatagen.fit(X_train)","d15c7a9c":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] \/\/ batch_size)","1c7f0d7b":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","20f5dd3f":"Author: Kazi Amit Hasan <br>\nDepartment of Computer Science & Engineering,<br>\nRajshahi University of Engineering & Technology (RUET)<br>\nWebsite: https:\/\/amithasanshuvo.github.io\/<br>\nLinkedin: https:\/\/www.linkedin.com\/in\/kazi-amit-hasan-514443140\/<br>\nEmail: kaziamithasan89@gmail.com\n\n**Please upvote if you like it**\n\n<hr>\nReferences:\n1. https:\/\/www.kaggle.com\/codeblogger\/convolutional-neural-network-cnn-tutorial\n2. https:\/\/www.kaggle.com\/rushikesh0203\/mnist-sign-language-recognition-cnn-99-94-accuracy"}}