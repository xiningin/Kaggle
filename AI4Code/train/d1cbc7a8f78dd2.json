{"cell_type":{"f913dccf":"code","425b0d0f":"code","1db3df42":"code","6a95afe5":"code","0408cc4b":"code","6229334a":"code","8cc2b484":"code","b78121c9":"code","f59db4c9":"code","0149158d":"code","be15e19d":"code","f784f7d6":"code","9850d98a":"code","df306370":"code","eafef66e":"code","32e2e1ac":"code","dfcc0a00":"markdown","af853ecd":"markdown","d6c2b223":"markdown"},"source":{"f913dccf":"import gc\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport time\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nwarnings.filterwarnings('ignore')\n\nPATH=\"..\/input\/\"\n\nN_SPLITS = 10\nSEED_SKF = 4221","425b0d0f":"def merge_train_test(df_train, df_test):\n    if \"target\" not in df_test.columns.values:\n        df_test[\"target\"] = -1\n    res = pd.concat([df_train, df_test])\n    res.reset_index(inplace=True, drop=True)\n    return res\n\ndef split_train_test(df):\n    df_train = df[df[\"target\"] >= 0]\n    df_test = df[df[\"target\"] <= -1]\n    df_train.reset_index(inplace=True, drop=True)\n    df_test.reset_index(inplace=True, drop=True)\n    assert list(df_train[\"ID_code\"].values) == [f\"train_{i}\" for i in range(200000)]\n    assert list(df_test[\"ID_code\"].values) == [f\"test_{i}\" for i in range(200000)]\n    return df_train, df_test","1db3df42":"%%time\ntrain_df = pd.read_csv(PATH+\"train.csv\")\ntest_df = pd.read_csv(PATH+\"test.csv\")","6a95afe5":"class CountEncoder:\n    def fit(self, series):\n        self.counts = series.groupby(series).count()\n    \n    def transform(self, series):\n        return series.map(self.counts).fillna(0).astype(np.int16)","0408cc4b":"# separate into real and fake\n\ndf_cnt = pd.DataFrame()\nfor v in range(200):\n    sr = test_df[f\"var_{v}\"]\n    enc = CountEncoder()\n    enc.fit(sr)\n    df_cnt[f\"cnt_{v}\"] = enc.transform(sr)\ntest_df[\"target\"] = -df_cnt.min(1)  # target==-1 -> real, target==-2 -> fake\ndel df_cnt","6229334a":"df_merged = merge_train_test(train_df, test_df)\ndf_merged.tail()","8cc2b484":"%%time\n\n# count encoding\n\ncount_enc = [None] * 200\ndf_real = df_merged[df_merged[\"target\"]!=-2]\nfor v in range(200):\n    enc = CountEncoder()\n    enc.fit(df_real[f\"var_{v}\"])\n    count_enc[v] = enc.transform(df_merged[f\"var_{v}\"])\n    \nfor v in range(200):\n    df_merged[f\"cnt_{v}\"] = count_enc[v]\n\ndel df_real","b78121c9":"train_df, test_df = split_train_test(df_merged)\ntarget = train_df['target']\ngc.collect()\nprint(train_df.shape)\ntest_df.head()","f59db4c9":"param = {\n    \"objective\": \"binary\", \n    \"boost\": \"gbdt\",\n    \"metric\": \"auc\",\n    \"boost_from_average\": False,\n    \"learning_rate\": 0.01,\n    \"num_leaves\": 5,\n    \"max_depth\": -1,\n    \"tree_learner\": \"serial\",\n    \"feature_fraction\": 1.0,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\": 0.4,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\": 10.0,\n    \"verbosity\": 1,\n    \"seed\": 44000,\n}","0149158d":"target = train_df['target']\ndf_merged_cut = [df_merged[[f\"var_{v}\", \n                            f\"cnt_{v}\", \n                           ]] for v in range(200)]\ngc.collect()","be15e19d":"%%time\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values, target.values)):\n    print(\"fold n\u00b0{}\".format(fold_))\n    df_meta = df_merged[[\"ID_code\", \"target\"]]\n    \n    trn_X, trn_y = train_df.iloc[trn_idx], target.iloc[trn_idx]\n    val_X, val_y = train_df.iloc[val_idx], target.iloc[val_idx]\n    for v in range(200):\n        print(f\"var {v}\")\n        features = [f\"var_{v}\", \n                    f\"cnt_{v}\", \n                   ]\n\n        trn_data = lgb.Dataset(trn_X[features], label=trn_y)\n        val_data = lgb.Dataset(val_X[features], label=val_y)\n\n        num_round = 1000000\n        clf = lgb.train(param, \n                        trn_data, \n                        num_round, \n                        valid_sets=[trn_data, val_data], \n                        verbose_eval=1000, \n                        early_stopping_rounds=100)\n        df_meta[f\"{v}_meta\"] = clf.predict(df_merged_cut[v], num_iteration=clf.best_iteration).astype(np.float32)\n\n    df_meta.to_pickle(f\"fold_{fold_}_meta.pickle\")","f784f7d6":"param = {\n    \"objective\": \"binary\", \n    \"boost\": \"gbdt\",\n    \"metric\": \"auc\",\n    \"boost_from_average\": \"false\",\n    \"learning_rate\": 0.01,\n    \"num_leaves\": 2,\n    \"max_depth\": -1,\n    \"tree_learner\": \"serial\",\n    \"feature_fraction\": 0.5,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\": 0.4,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\": 10.0,\n    \"verbosity\": 1,\n    \"seed\": 44000,\n}","9850d98a":"\n%%time\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values, target.values)):\n    print(\"fold n\u00b0{}\".format(fold_))\n    df_meta = pd.read_pickle(f\"fold_{fold_}_meta.pickle\")\n    train_df, test_df = split_train_test(df_meta)\n    features = [f\"{v}_meta\" for v in range(200)]\n    \n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 1000000\n    clf = lgb.train(param, \n                    trn_data, \n                    num_round, \n                    valid_sets=[trn_data, val_data], \n                    verbose_eval=1000, \n                    early_stopping_rounds=2000)\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) \/ N_SPLITS\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","df306370":"plt.figure(figsize=(10,80))\nsns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.sort_values(by=\"importance\",ascending=False))\nplt.title('Features importance (averaged\/folds)')\nplt.tight_layout()\nplt.savefig('FI.png')","eafef66e":"sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsub_df[\"target\"] = predictions\nsub_df.to_csv(\"submission.csv\", index=False)","32e2e1ac":"feature_importance_df.to_csv(\"feature_importance_df.csv\", index=False)","dfcc0a00":"# 1st step - make meta features","af853ecd":"2\/2: https:\/\/www.kaggle.com\/nagiss\/9-solution-nagiss-part-2-2-weightshareing-nn","d6c2b223":"# 2nd step - prediction"}}