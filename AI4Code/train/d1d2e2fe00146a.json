{"cell_type":{"d4166121":"code","f8db2fb7":"code","750be6db":"code","c54f3de2":"code","6090e410":"code","25015239":"code","9efa11ee":"code","6dc52326":"code","7f08fe6d":"code","61dee677":"code","87fad125":"code","90e94297":"code","53003c44":"code","23a2bf96":"code","1aac8e5b":"code","a8c440c0":"code","1196d945":"code","aec62e39":"code","43757bbb":"code","f06b3aa7":"code","6be7cda3":"code","29dfe13c":"code","eb1e325a":"code","9537569e":"code","3c61a493":"code","cdbf4597":"code","33659caa":"code","1b27c2ac":"code","36bb36c7":"code","d1120c5f":"code","42068697":"code","ac1005bb":"code","2f703834":"code","27684ffe":"code","9d7acfb0":"code","b852940c":"code","2f0f8e0b":"code","11a138a1":"code","3ec34aae":"code","11150785":"code","53fbd032":"code","f57b05d7":"code","7107acef":"code","b8d9191f":"code","c5214d71":"code","00149b6e":"code","236a710d":"code","cc5278f6":"code","3a97d17f":"code","5ca6c356":"markdown","9a10f9a1":"markdown","4a568e4a":"markdown","e7341957":"markdown","8bb76e95":"markdown","3ab4d77f":"markdown","f0ea93fb":"markdown","af9a204f":"markdown","8a101560":"markdown","e477b54e":"markdown","f57d46f0":"markdown","7dc972f2":"markdown","f4b11e9a":"markdown"},"source":{"d4166121":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n# Redes Neurais\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation, MaxPooling2D\n\n# from tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import *\n# Plot\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Avalia\u00e7\u00e3o\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.model_selection import train_test_split\nimport itertools","f8db2fb7":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","750be6db":"dir_base = '\/kaggle\/input\/faceexpressionsdataset\/'","c54f3de2":"df = pd.read_csv(dir_base + 'icml_face_data.csv')\ndf.columns = ['emotion', 'Usage', 'pixels']\nprint(f'Shape: {df.shape}')\ndf.head()","6090e410":"fig = plt.figure(1, (20, 20))\nemotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\nk = 0\nfor label in sorted(df['emotion'].unique()):\n    for j in range(1):\n        px = df[df['emotion']==label].pixels.iloc[k]\n        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n\n        k += 1\n        ax = plt.subplot(7, 7, k)\n        ax.imshow(px, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(emotions[label])\n        plt.tight_layout()","25015239":"treino = pd.read_csv(dir_base + 'train.csv')\nprint(f'Shape treino: {treino.shape}')\ntreino.head()","9efa11ee":"teste = pd.read_csv(dir_base + 'test.csv')\nprint(f'Shape teste: {teste.shape}')\nteste.head()","6dc52326":"teste_data = df[df['Usage']!='Training']\nteste_data.drop(columns='Usage', inplace=True)\nprint(f'Teste data com label - Shape:{teste.shape}')\nteste_data.head()","7f08fe6d":"def reshape_image(data, is_train):\n    image = np.zeros(shape=(len(data), 48, 48, 1))\n    if is_train:\n        target = np.array(list(map(int, data['emotion'])))\n\n    for i, row in enumerate(data.index):\n        img = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n        img = np.reshape(img, (48, 48))\n        image[i, :, :, 0] = img \/ 255\n        \n    if is_train:\n        return image, target\n    else:\n        return image\n    ","61dee677":"X_treino, y_treino = reshape_image(treino, True)\nX_teste_data, y_teste_data = reshape_image(teste_data, True)\nX_teste = reshape_image(teste, False)","87fad125":"X_treino[0]","90e94297":"# Vamos ajustar o formato da saida\nnum_classes = 7\n\ny_treino = keras.utils.to_categorical(y_treino, num_classes)\nprint(y_treino[0])","53003c44":"x_train, x_val, y_train, y_val = train_test_split(X_treino, y_treino, test_size = 0.1, random_state=5)\nprint('Qtde de treino: {}'.format(len(x_train)))\nprint('Qtde de valida\u00e7\u00e3o: {}'.format(len(x_val)))","23a2bf96":"model = Sequential()\n\n#1st conv\nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1))) #1is for grayscale\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n###\nmodel.add(Dense(64))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n###\n\n#2nd conv\nmodel.add(Conv2D(128, (5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n###\nmodel.add(Dense(128))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n###\n#3rd conv\nmodel.add(Conv2D(256, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n###\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n###\n#4th conv\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n###\nmodel.add(Dense(64))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n###\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n\n########\n# model.add(Conv2D(128, kernel_size=(3, 3),\n#                  activation='relu',\n#                  input_shape=(48,48,1)))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Conv2D(40, kernel_size=(3,3), activation='relu'))\n\n# model.add(Dense(50, activation='relu'))\n# model.add(Dropout(0.2))\n\n# model.add(Conv2D(50, kernel_size=(3,3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n\n# model.add(Conv2D(30, kernel_size=(3,3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n\n# model.add(Flatten())\n# model.add(Dense(15, activation='relu'))\n# model.add(Dropout(0.2))\n\n# model.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","1aac8e5b":"model.compile(loss='categorical_crossentropy',\n              optimizer=Adam(learning_rate=0.0003, amsgrad=True),\n              metrics=['accuracy'])","a8c440c0":"# Treina com os parte dos dados\nbatch_size = 32\nepochs = 100\n\n#Salvar o melhor modelo\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]\n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    callbacks = callbacks_list,\n                    verbose=1, # 1 para verbose\n                    validation_data=(x_val, y_val))","1196d945":"#Vamos ver como foi o treino?\n\nfig, ax = plt.subplots(1,2, figsize=(16,8))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","aec62e39":"from tensorflow.keras.models import load_model\n# Load the best saved model\nmodel = load_model('model.h5')","43757bbb":"# Testa\nscore = model.evaluate(x_val, y_val, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","f06b3aa7":"import itertools\n\n#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6be7cda3":"# Vendo alguns reports# Vendo alguns reports\n# Usando sklearn\nimport numpy as np\n\n# Classificando toda base de teste\n# y_pred = model.predict_classes(x_val)\ny_pred = np.argmax(model.predict(x_val), axis=-1)\n# voltando pro formato de classes\ny_test_c = np.argmax(y_val, axis=1)\ntarget_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\n#Confution Matrix\ncm = confusion_matrix(y_test_c, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n\nprint('Classification Report')\nprint(classification_report(y_test_c, y_pred, target_names=target_names))","29dfe13c":"# Faz classifica\u00e7\u00e3o para dataset de teste\n# y_pred = model.predict_classes(X_teste)\ny_pred = np.argmax(model.predict(x_val), axis=-1)\n\n# # Verficando algum exemplo\n# i = 0\n# plt.imshow(test.values[i].reshape(28,28), cmap=plt.cm.binary)\n# plt.show()\n# print('Previsto: {}'.format(y_pred[i]))\n\n# Botando no formato de sa\u00edda (competi\u00e7\u00e3o Kaggle)\nresults = pd.Series(y_pred,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,len(y_pred)+1),name = \"ImageId\"),results],axis = 1)\nprint(submission.head(10))\n#Salvando Arquivo\nsubmission.to_csv(\"face_expression_cnn_v1.csv\",index=False)","eb1e325a":"from tensorflow import keras\n#from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n#from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n#from tensorflow.python.keras.applications.efficientnet import EfficientNetB7,EfficientNetB0, preprocess_input\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as Imgen\nimport pandas as pd\nimport numpy as np \nimport seaborn as sns\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation, MaxPooling2D","9537569e":"dir_base = '\/kaggle\/input\/faceexpressionsdataset\/'","3c61a493":"df = pd.read_csv(dir_base + 'icml_face_data.csv')\ndf.columns = ['emotion', 'Usage', 'pixels']\nprint(f'Shape: {df.shape}')\ndf.head()","cdbf4597":"train_data = df[df[\"Usage\"]==\"Training\"]\nval_data = df[df[\"Usage\"]==\"PublicTest\"]\ntest_data = df[df[\"Usage\"]==\"PrivateTest\"]","33659caa":"nb_train_samples = len(train_data)\nprint(nb_train_samples)","1b27c2ac":"nb_val_samples = len(val_data)\nprint(nb_val_samples)","36bb36c7":"nb_test_samples = len(test_data)\nprint(nb_test_samples)","d1120c5f":"# to extract image data from pixel column\n\ndef toPixels(pixels):\n\n    arr = np.array(pixels.split(),\"float64\")\n    return arr\n\ndef reshapetoImage(data):\n\n    Images = np.reshape(data[\"pixels\"].to_list(),(data.shape[0],48,48))\n\n    return Images","42068697":"train_data[\"pixels\"] = train_data[\"pixels\"].apply(toPixels)\nval_data[\"pixels\"] = val_data[\"pixels\"].apply(toPixels)\ntest_data[\"pixels\"] = test_data[\"pixels\"].apply(toPixels)","ac1005bb":"# images and labels\n\ntrain_images = reshapetoImage(train_data)\nval_images = reshapetoImage(val_data)\ntest_images = reshapetoImage(test_data)\n\ntrain_labels = train_data[\"emotion\"]\nval_labels = val_data[\"emotion\"]\ntest_labels = test_data[\"emotion\"]","2f703834":"train_images.shape","27684ffe":"print(train_images.shape)  # (28709, 48, 48)\nrgb_batch_train = np.repeat(train_images[..., np.newaxis], 3, -1)\nprint(rgb_batch_train.shape)  # (28709, 48, 48, 3)\n\nprint(val_images.shape)  # (28709, 48, 48, 3)\nrgb_batch_val = np.repeat(val_images[..., np.newaxis], 3, -1)\nprint(rgb_batch_val.shape)  # (64, 224, 224, 3)\n\nprint(test_images.shape)  # ((28709, 48, 48)\nrgb_batch_test = np.repeat(test_images[..., np.newaxis], 3, -1)\nprint(rgb_batch_test.shape)  # (28709, 48, 48, 3)\n","9d7acfb0":"trainGen = Imgen(rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        preprocessing_function=preprocess_input,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest'\n                 )\nvalGen = Imgen(preprocessing_function=preprocess_input)\ntestGen = Imgen(preprocessing_function=preprocess_input)","b852940c":"trainds = trainGen.flow(rgb_batch_train,train_labels,\n                   batch_size = 32\n                   )\n\nvalds = valGen.flow(rgb_batch_val,val_labels,\n               batch_size = 32\n               )\n\ntestds = testGen.flow(rgb_batch_test,test_labels,\n                      batch_size=32,\n                      shuffle=False)","2f0f8e0b":"trainds","11a138a1":"im_shape = (48,48)\n\nseed = 10\n\nBATCH_SIZE = 32\n\nnum_classes = 7","3ec34aae":"#base_model = VGG16(include_top=False, input_shape=(48, 48, 3), weights='imagenet')\n\nbase_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(im_shape[0], im_shape[1], 3))\n\n\n#base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(im_shape[0], im_shape[1], 3))\n#Input size must be at least 75x75; got `input_shape=(48, 48, 3)\n\n#NASNetLarge\n#For loading imagenet weights, input_shape should be (331, 331, 3)","11150785":"x = base_model.output\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\npredictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freezing pretrained layers\nfor layer in base_model.layers:\n    layer.trainable=False\n    \nprint(model.summary())    \n    \n# Compile the model\nprint(\"Compiling the Model....\")\nmodel.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nprint(\"Model Compiled!\")","53fbd032":"# Saving the best model\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]","f57b05d7":"hist = model.fit(trainds, epochs=80, validation_data=valds,callbacks=callbacks_list,verbose = 1)","7107acef":"#Vamos ver como foi o treino?\n\nfig, ax = plt.subplots(1,2, figsize=(16,8))\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","b8d9191f":"from tensorflow.keras.models import load_model\n# Load the best saved model\nmodel = load_model('model.h5')","c5214d71":"# Teste\npred = model.predict(testds)","00149b6e":"pred = [np.argmax(i) for i in pred]","236a710d":"y_test = np.array(test_labels)","cc5278f6":"print(classification_report(y_test,pred))","3a97d17f":"target_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\ncm = confusion_matrix(y_test,pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n","5ca6c356":"# 3. Rede Convolucional - Arquitetura Cl\u00e1ssica (VGG16) + Transfer Learning\n","9a10f9a1":"# Exerc\u00edcio 02 - Redes Neurais convolucionais e Transfer Learninig","4a568e4a":"## 2.1 - Prepera\u00e7\u00e3o para treino","e7341957":"## 1.2 - Verificando o diret\u00f3rio de dados","8bb76e95":"## Separando uma parte para treino (90%) e outra para valida\u00e7\u00e3o (10%)","3ab4d77f":"## 1.5 - Visualiza\u00e7\u00e3o de Faces","f0ea93fb":"## Submiss\u00e3o Rede Convolucional","af9a204f":"## 1.6 - Instanciando data treino","8a101560":"## 1 - Rede Neural Convolucional","e477b54e":"## 2.2 - Plotando a Perda e a Acur\u00e1cia","f57d46f0":"## 1.4 - Instanciando o dataset ","7dc972f2":"## 1.1 - Carregando bibliotecas ","f4b11e9a":"## 1.3 - Diret\u00f3rio"}}