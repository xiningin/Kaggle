{"cell_type":{"c2ec6284":"code","a239200f":"code","ecd9f6c8":"code","11f0ef60":"code","d038dfa1":"code","0251dc53":"code","33b70bf8":"code","6ceebfa7":"code","c61e6ce1":"code","735e2df9":"code","20f6cb33":"code","ece045cb":"code","80e15f22":"code","30467e0a":"code","e423f700":"code","f9d2e017":"code","c4748809":"code","a11e7890":"code","d906eeed":"code","a8d7dcf1":"code","4f2478f9":"code","b3bcc8b9":"code","3c36f42c":"code","91bf003f":"code","a3c840a4":"code","f9f90849":"code","43af6e9c":"code","ed0b7093":"code","a1ef703c":"code","891f8e89":"code","4dec6615":"code","9df66803":"code","f5301d49":"code","894712e8":"code","07e4f3f1":"code","098a106d":"code","af46373a":"code","056a5132":"code","5eca4588":"code","da13bfd4":"code","65a66fd7":"code","c3bd3d4e":"code","56446549":"code","2387f61c":"markdown","3faad395":"markdown","b5ab4881":"markdown","1d057d54":"markdown","9c35901b":"markdown","06dcb6d5":"markdown","d362be97":"markdown","c8620a81":"markdown","79fca438":"markdown","3d575732":"markdown","f495018c":"markdown","e33c9a15":"markdown","0d8589a2":"markdown","54a7db03":"markdown","793ad871":"markdown","dbc589c5":"markdown","4858bd15":"markdown","70841635":"markdown","f1d23656":"markdown"},"source":{"c2ec6284":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a239200f":"# load basic library\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n","ecd9f6c8":"train = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')","11f0ef60":"train.head()","d038dfa1":"print(train.shape, test.shape)","0251dc53":"train.info(), test.info()","33b70bf8":"train.describe()","6ceebfa7":"# make a tempdate\n\ntrain['tempdate'] = train.datetime.apply(lambda x : x.split())\ntrain['tempdate'].head()","c61e6ce1":"# Use apply function\ntrain['year'] = train.tempdate.apply(lambda x : x[0].split('-')[0])\ntrain['month'] = train.tempdate.apply(lambda x : x[0].split('-')[1])\ntrain['day'] = train.tempdate.apply(lambda x : x[0].split('-')[2])\ntrain['hour'] = train.tempdate.apply(lambda x : x[1].split(':')[0])\n# check the year\ntrain['year']\n# transfer proper type\ntrain['year'] = pd.to_numeric(train['year'])\ntrain['month'] = pd.to_numeric(train['month'])\ntrain['day'] = pd.to_numeric(train['day'])\ntrain['hour'] = pd.to_numeric(train['hour'])","735e2df9":"# When we think about the bike sharing. Day is not a important factor, but weekday is import factor.(I think so..)\ntrain['weekday'] = train.tempdate.apply(lambda x : datetime.strptime(x[0],'%Y-%m-%d').weekday())\n# Checking is important for beginner(it's make me comportable)\ntrain['weekday']","20f6cb33":"# I don't need more tempdate. Drop in the castle!!!\ntrain = train.drop(['tempdate'],axis=1)","ece045cb":"figure = plt.figure(figsize = (10,10))\n\nax1 = plt.subplot(2,2,1)\nax1 = sns.barplot(x = 'season', y='count', data=train)\n\nax2 = plt.subplot(2,2,2)\nax2 = sns.barplot(x = 'holiday', y='count', data=train )\n\nax3 = plt.subplot(2,2,3)\nax3 = sns.barplot(x = 'workingday', y='count', data=train )\n\nax4 = plt.subplot(2,2,4)\nax4 = sns.barplot(x = 'weather', y='count', data=train )","80e15f22":"figure = plt.figure(figsize = (10,10))\n\nax1 = plt.subplot(2,2,1)\nax1 = sns.barplot(x = 'year', y='count', data=train)\n\nax2 = plt.subplot(2,2,2)\nax2 = sns.barplot(x = 'month', y='count', data=train )\n\nax3 = plt.subplot(2,2,3)\nax3 = sns.barplot(x = 'day', y='count', data=train )\n\nax4 = plt.subplot(2,2,4)\nax4 = sns.barplot(x = 'hour', y='count', data=train )","30467e0a":"# make function for change season\n\ndef seson_change(month):\n    if month in [12,1,2]:\n        return 4\n    elif month in [3,4,5]:\n        return 1\n    elif month in [6,7,8]:\n        return 2\n    elif month in [9,10,11]:\n        return 3\n\ntrain['season'] = train.month.apply(seson_change)","e423f700":"# One more visualization\nfigure = plt.figure(figsize = (10,10))\n\nax1 = plt.subplot(2,2,1)\nax1 = sns.barplot(x = 'season', y='count', data=train)\n\nax2 = plt.subplot(2,2,2)\nax2 = sns.barplot(x = 'holiday', y='count', data=train )\n\nax3 = plt.subplot(2,2,3)\nax3 = sns.barplot(x = 'workingday', y='count', data=train )\n\nax4 = plt.subplot(2,2,4)\nax4 = sns.barplot(x = 'weather', y='count', data=train )","f9d2e017":"figure = plt.figure(figsize = (10,10))\n\nax1 = plt.subplot(2,2,1)\nax1 = sns.distplot(train.temp)\n\nax2 = plt.subplot(2,2,2)\nax2 = sns.distplot(train.atemp)\n\nax3 = plt.subplot(2,2,3)\nax3 = sns.distplot(train.humidity)\n\nax4 = plt.subplot(2,2,4)\nax4 = sns.distplot(train.windspeed)","c4748809":"figure = plt.figure(figsize = (20,20))\n\nax = sns.heatmap(train.corr(), annot=True,vmin =0)","a11e7890":"sns.jointplot(x='temp', y='atemp', data=train)","d906eeed":"# Draw mix value graph\nfigure = plt.figure(figsize = (10,10))\nlist = ['season','holiday','weekday','weather']\ni=0\n\nfor j in list:\n    i = i+1\n    plt.subplot(2,2,i)\n    sns.pointplot(x='hour', y='count', hue=j,data=train)","a8d7dcf1":"fig = plt.figure(figsize=(10,10))\n\nax1 = plt.subplot(2,1,1)\nax1 = sns.pointplot(x='month',y='count', hue='weather',data= train)\n\nax2 = plt.subplot(2,1,2)\nax2 = sns.barplot(x='month',y='count',data=train, hue='weather')","4f2478f9":"# before preprocessing we need to load the first train data\n\ntrain = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')","b3bcc8b9":"# concentrate the train, test\nTotal = pd.concat([train,test],axis=0)\nTotal","3c36f42c":"# Do the same process, once more for preprocessing\n\nTotal['tempdate'] = Total.datetime.apply(lambda x : x.split())\n\nTotal['year'] = Total.tempdate.apply(lambda x : x[0].split('-')[0])\nTotal['month'] = Total.tempdate.apply(lambda x : x[0].split('-')[1])\nTotal['day'] = Total.tempdate.apply(lambda x : x[0].split('-')[2])\nTotal['hour'] = Total.tempdate.apply(lambda x : x[1].split(':')[0])\nTotal['weekday'] = Total.tempdate.apply(lambda x : datetime.strptime(x[0], \"%Y-%m-%d\").weekday())\n\nTotal['year'] = pd.to_numeric(Total.year)\nTotal['month'] = pd.to_numeric(Total.month)\nTotal['day'] = pd.to_numeric(Total.day)\nTotal['hour'] = pd.to_numeric(Total.hour)\n\nTotal = Total.drop('tempdate',axis=1)\n\nTotal['season'] = Total.month.apply(seson_change)","91bf003f":"# load forest\nfrom sklearn.ensemble import RandomForestRegressor","a3c840a4":"# See the wind\nsns.distplot(train['windspeed'])","f9f90849":"# first, seperate wind '0'&'1' value\nTotal_wind_speed0 = Total[Total['windspeed'] == 0]\nTotal_wind_speed1 = Total[Total['windspeed'] != 0]\n\n# When we make a wind in the forest, there are useless value in the train data\ntemp_drop_columns = ['windspeed','casual','registered','count','datetime','holiday','workingday']\n\n# Save after drop columns\nTotal_wind_speed0_df = Total_wind_speed0.drop(temp_drop_columns, axis = 1)\nTotal_wind_speed1_df = Total_wind_speed1.drop(temp_drop_columns, axis = 1)\n\n# Save the value for predict\nTotal_wind_speed1_df_speed = Total_wind_speed1['windspeed']","43af6e9c":"# simple train forest\n\nrf = RandomForestRegressor()\n\nrf.fit(Total_wind_speed1_df, Total_wind_speed1_df_speed)\n\n# make wind using forest\nTotal_wind_speed0_df_speed = rf.predict(Total_wind_speed0_df)\n\n# Save wind\nTotal_wind_speed0['windspeed'] = Total_wind_speed0_df_speed","ed0b7093":"# Remake the Total with wind\nTotal = pd.concat([Total_wind_speed0,Total_wind_speed1],axis=0)","a1ef703c":"# This columns have several values, but it's a category value. \n# I will divided several columns by using get dummies function\n\ncat_columns = [ 'season', 'weather','year', 'hour', 'weekday' ] \n\n# Of coures, there are several category value that not contain cat_columns, but don't worry. i will drop the columns\n\nfor i in cat_columns:\n    Total[i] = Total[i].astype('category')\n\n# get_dummies\nweather_df = pd.get_dummies(Total['weather'],prefix = 'w')\nseason_df = pd.get_dummies(Total['season'],prefix='s')\nyear_df = pd.get_dummies(Total['year'], prefix = 'y')\nhour_df = pd.get_dummies(Total['hour'], prefix = 'h')\nweekday_df = pd.get_dummies(Total['weekday'], prefix='we')","891f8e89":"# Sum dummies data\nTotal = pd.concat([Total,weather_df], axis=1)\nTotal = pd.concat([Total,season_df], axis=1)\nTotal = pd.concat([Total,year_df], axis=1)\nTotal = pd.concat([Total,hour_df], axis=1)\nTotal = pd.concat([Total,weekday_df], axis=1)\n\n# Data Checking is alway right \nTotal.head()","4dec6615":"Total.head()","9df66803":"# If you use log, '0' value tranfered infinity value(it make error)\n# So, log1p make log(data +1) it's avoid error\nTotal['atemp'] = np.log1p(Total['atemp'])\nTotal['humidity'] = np.log1p(Total['humidity'])\nTotal['windspeed'] = np.log1p(Total['windspeed'])\n\n\n#checking is alway right.\nTotal.head()","f5301d49":"# divide values(seperate by using 'count'values)\ntrain = Total[pd.notnull(Total['count'])]\ntest = Total[~pd.notnull(Total['count'])]\n\nprint(train.shape, test.shape)","894712e8":"drop_columns = ['casual', 'count','temp', 'datetime','registered','weather','season','year','month','day','hour','weekday']\n\n# But, before we drop, we have to save some value(datetime need for submission, count need for prediction)\n\ntest_datetime = test['datetime']\ny_label = train['count']\n\ntrain = train.drop(drop_columns,axis=1)\ntest = test.drop(drop_columns,axis=1)","07e4f3f1":"print(train.shape, test.shape)\nprint(y_label.shape)","098a106d":"# load library for predict\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import metrics","af46373a":"# save some model\nlr = LinearRegression()\nridge = Ridge()\nlasso = Lasso()","056a5132":"# make label value transfer logvlaue for predict\ny_label_log = np.log1p(y_label)\n\n# train model\nlr.fit(train,y_label_log)\nrf.fit(train,y_label_log)\nridge.fit(train,y_label_log)\nlasso.fit(train,y_label_log)\n","5eca4588":"# predict easy\nlr_preds = lr.predict(train)\nrf_preds = rf.predict(train)\nridge_preds = ridge.predict(train)\nlasso_preds = lasso.predict(train)","da13bfd4":"# we will use np.exp for transfer log value\n# and just use MAE because it's easy\nprint(\"lr MAE :{:.5f}\".format(metrics.mean_absolute_error(np.exp(y_label_log),np.exp(lr_preds))))\nprint(\"rf MAE :{:.5f}\".format(metrics.mean_absolute_error(np.exp(y_label_log),np.exp(rf_preds))))\nprint(\"ridge MAE :{:.5f}\".format(metrics.mean_absolute_error(np.exp(y_label_log),np.exp(ridge_preds))))\nprint(\"lasso MAE :{:.5f}\".format(metrics.mean_absolute_error(np.exp(y_label_log),np.exp(lasso_preds))))","65a66fd7":"# I just borrowed idea from EDA & Ensemble Model (Top 10 Percentile) kernel\nfrom sklearn.ensemble import GradientBoostingRegressor\n\ngb = GradientBoostingRegressor()\ngb_params={'max_depth':range(1,11,1),'n_estimators':[1,10,100]}\nacc_scorer = metrics.make_scorer(metrics.mean_absolute_error,greater_is_better=False)\ngrid_gb=GridSearchCV(gb,gb_params,scoring=acc_scorer,cv=5)","c3bd3d4e":"grid_gb.fit(train,y_label_log)\npreds = grid_gb.predict(train)\nprint(\"GB MAE :{:.5f}\".format(metrics.mean_absolute_error(np.exp(y_label_log),np.exp(preds))))","56446549":"predsTest = grid_gb.predict(test)\n\n# make dataFrame\nsubmission = pd.DataFrame({\n        \"datetime\": test_datetime,\n        \"count\": [max(0, x) for x in np.exp(predsTest)]\n    })\n\n# make file\nsubmission.to_csv('bike_and_idea_sharing_for_beginner.csv', index=False)\n","2387f61c":"# 4'th for beginner : Model make & predict\n\n* Use some regression model and predict submission value","3faad395":"## When we see the wind value, we find there are many '0' value\n## But you know, wind is important thing for rider. So we will make a wind in the forest","b5ab4881":"# The end. Happy kaggle~","1d057d54":"## Casual, registered value is not include the testset\n## I will remove this value(If it's useless, it's bound to be thrown away.)","9c35901b":"# Ensemble is better than 1 model","06dcb6d5":"# It's just first impression\n\n* we need to go deeper... How?\n* we have a visualization tool!  matplot and seaborn bring us to deeper understanding\n\n\n\n## But, I don't like the shape of datetime, so before we go, i like to transfer the shape of datetime columns\n## Let's divide the datetime in to year, month, day(weekday), hour","d362be97":"# OK, well done, just remain simple process ","c8620a81":"## and I think numeric value is too large. so i will make small","79fca438":"### Of course, atemp & temp have very strong correlation.(I think we don't need two value, atemp more proper to predict bike sharing)","3d575732":"## Wind story is done\n\n## Next story is about cat.(category value)","f495018c":"## Preprocessing It should proceed simultaneously.\n## So, before preprocessing data, we need to concat the train, test value.(Total)","e33c9a15":"# If it's useless, it's bound to be thrown away.\n# Drop the columns, Drop the beat","0d8589a2":"## hmm.... Season is right?\n## I want change the season, because January and February are not spring. It is winter.","54a7db03":"* rf model value is better than gb.. but when i submit two model predict data. GBR model has a more high score than rf model\n* I think MAE value is not proper in case. I need to use RMSE.\n* BUT, Anyway I will make submission file\n\n# Final step for beginner : Make submission file","793ad871":"# 2'nd Step for beginner : Visualization\n\n* It's a time that we use visualization tool\n* I think Seaborn is the beautiful tool, especially for beginner","dbc589c5":"# 1'st Step for beginner : First meeting with Data\n\n## Load everything you need , and let's see what a dataset look like.\n* I worked as a process engineer for a ten years, So I'm not familiar with computer science. That mean, I will use simple and easy code\n* 1'st I loaded a basic library and I will load csv file(train and test set)","4858bd15":"### It's a first meething\n* See head or tail.\n* See shape.\n* See info & describe","70841635":"# 3'th for beginner : Preprocessing\n\n* visulization is enough(Actually not enough)\n* It's a time we prepair data for a model","f1d23656":"* We see the all value.\n* Next step. we need to see the correlation(it's basic)"}}