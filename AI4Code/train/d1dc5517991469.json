{"cell_type":{"446652b4":"code","4caee75a":"code","2d8c6c0c":"code","42b469ed":"code","0b25fbfa":"code","5535dcde":"code","8d438208":"code","db12cf4c":"code","6d465130":"markdown"},"source":{"446652b4":"# Libraries \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport os\n","4caee75a":"# Reading the input images and putting them into a numpy array\ndata=[]\nlabels=[]\n\nheight = 30\nwidth = 30\nchannels = 3\nclasses = 43\nn_inputs = height * width*channels\n\nfor i in range(classes) :\n    path = \"..\/input\/train\/{0}\/\".format(i)\n    print(path)\n    Class=os.listdir(path)\n    for a in Class:\n        try:\n            image=cv2.imread(path+a)\n            image_from_array = Image.fromarray(image, 'RGB')\n            size_image = image_from_array.resize((height, width))\n            data.append(np.array(size_image))\n            labels.append(i)\n        except AttributeError:\n            print(\" \")\n            \nCells=np.array(data)\nlabels=np.array(labels)\n\n#Randomize the order of the input images\ns=np.arange(Cells.shape[0])\nnp.random.seed(43)\nnp.random.shuffle(s)\nCells=Cells[s]\nlabels=labels[s]","2d8c6c0c":"#Spliting the images into train and validation sets\n(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]\nX_train = X_train.astype('float32')\/255 \nX_val = X_val.astype('float32')\/255\n(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]\n\n#Using one hote encoding for the train and validation labels\nfrom keras.utils import to_categorical\ny_train = to_categorical(y_train, 43)\ny_val = to_categorical(y_val, 43)","42b469ed":"#Definition of the DNN model\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(43, activation='softmax'))\n\n#Compilation of the model\nmodel.compile(\n    loss='categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)","0b25fbfa":"#using ten epochs for the training and saving the accuracy for each epoch\nepochs = 10\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\nvalidation_data=(X_val, y_val))\n\n#Display of the accuracy and the loss values\nimport matplotlib.pyplot as plt\n\nplt.figure(0)\nplt.plot(history.history['acc'], label='training accuracy')\nplt.plot(history.history['val_acc'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","5535dcde":"#Predicting with the test data\ny_test=pd.read_csv(\"..\/input\/Test.csv\")\nlabels=y_test['Path'].as_matrix()\ny_test=y_test['ClassId'].values\n\ndata=[]\n\nfor f in labels:\n    image=cv2.imread('..\/input\/test\/'+f.replace('Test\/', ''))\n    image_from_array = Image.fromarray(image, 'RGB')\n    size_image = image_from_array.resize((height, width))\n    data.append(np.array(size_image))\n\nX_test=np.array(data)\nX_test = X_test.astype('float32')\/255 \npred = model.predict_classes(X_test)","8d438208":"#Accuracy with the test data\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, pred)","db12cf4c":"# Confussion matrix \nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=75) \n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n            plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\nclass_names = range(43)\ncm = confusion_matrix(pred,y_test)\n\nplt.figure(2)\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')","6d465130":"This is my first attempt on this database, some parts of the kernel is based on Linus W. kernel, mostly how to access de data. It implements a very easy DNN achieving 96% of accuracy in the test set.\nI hope that this can be helpful as a starting point for anyone in the future. I will try to improve it in future revisions."}}