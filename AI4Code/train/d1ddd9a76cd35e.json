{"cell_type":{"89a081c8":"code","4dd298f0":"code","6548ad6e":"code","9f52287c":"code","e76533a0":"code","fe9964a0":"code","f06f2099":"code","8ec52653":"code","8b189bcb":"code","770e15d1":"code","251872e3":"code","695d0b66":"code","0de41c92":"code","96b58525":"code","ec398aaa":"code","955f59b4":"code","7e1d01ea":"code","b72e49bc":"markdown","4b982ce5":"markdown","9bd000a0":"markdown","7bdd2171":"markdown","cd1cfc47":"markdown","e87f6ba0":"markdown","5558c227":"markdown","7c475e87":"markdown","f82cec9e":"markdown","5bef1af5":"markdown","14ed214f":"markdown","19865f32":"markdown"},"source":{"89a081c8":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten,BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n\nimport cv2","4dd298f0":"train_data = \"..\/input\/dog-breed-identification\/train\"\nlabel_csv = \"..\/input\/dog-breed-identification\/labels.csv\"","6548ad6e":"label_csv = pd.read_csv(\"..\/input\/dog-breed-identification\/labels.csv\")\nlabel_csv[\"path\"] = '..\/input\/dog-breed-identification\/train\/'+label_csv[\"id\"]+\".jpg\"","9f52287c":"label_csv.head()","e76533a0":"#Checking number of dog breeds\n\nlabel_csv[\"breed\"].nunique()","fe9964a0":"x = np.zeros((label_csv.shape[0], 128, 128, 3))\n\nfor i, index in tqdm(enumerate(label_csv[\"path\"])):\n#     image_path = os.path.join(data_dir+\"\/images\", all_keys[index])\n    image = tf.keras.preprocessing.image.load_img(index, target_size=(128,128))\n\n    arr = tf.keras.preprocessing.image.img_to_array(image)\n    arr = tf.keras.applications.mobilenet_v2.preprocess_input(arr)\n    arr = np.expand_dims(arr, axis=0)\n    x[i] = arr","f06f2099":"#Converting the breed column into categorical class\n\nlabel_csv.breed = pd.Categorical(pd.factorize(label_csv.breed)[0])\ny = to_categorical(label_csv[\"breed\"],num_classes=120)","8ec52653":"from pylab import rcParams\nrcParams['figure.figsize'] = 25, 5\n\nlabel_csv[\"breed\"].value_counts().plot.bar(color=[\"r\",\"orange\",\"y\",\"b\",\"green\",\"pink\"])\n\nplt.title(\"Total count of different dog breed\")\nplt.ylabel('Number')\nplt.xlabel('Class')\nplt.show()","8b189bcb":"plt.figure(figsize=(15,15))\n\nstart_index = 50\n\nfor i in range(16):\n    plt.subplot(4,4, i+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    image = label_csv[\"path\"][start_index+i]\n\n    plt.imshow(cv2.imread(image))\n    plt.tight_layout()\n\nplt.show()\n","770e15d1":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=2)\n# X_train, X_test=X_train\/255,X_test\/255","251872e3":"tf.keras.backend.clear_session()\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    mnet = MobileNetV2(include_top = False, pooling=\"max\", weights = \"imagenet\" ,input_shape=(128,128,3))\n    model = Sequential([mnet,\n                        BatchNormalization(),\n                        Dropout(0.6),\n                        Dense(120, activation=\"softmax\")])\n\n    model.layers[0].trainable = False\n\n    model.compile(loss=\"categorical_crossentropy\", metrics = \"accuracy\", optimizer=\"adam\")","695d0b66":"model.summary()","0de41c92":"#We will reduce the learning rate when then accuracy not increase for 2 steps\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy',factor=0.2,patience=2, min_lr=1e-7, verbose=1, mode=\"max\" )\n\n#To prevent over fitting we will stop the learning after 3 epochs and val_loss value not decreased\n\nstop = EarlyStopping(monitor='val_accuracy', patience=3, mode=\"max\" )","96b58525":"history = model.fit(X_train, y_train, epochs=20,callbacks=[stop,reduce_lr], batch_size=32, validation_data = (X_test, y_test))","ec398aaa":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 20, 1))\nax1.set_yticks(np.arange(0, 1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 20, 1))\nax1.set_yticks(np.arange(0, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","955f59b4":"#Creating an array of predicted test images\n\npredictions = model.predict(X_test)","7e1d01ea":"plt.figure(figsize=(15,15))\n\nstart_index = 50\n\nfor i in range(16):\n  plt.subplot(4,4, i+1)\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  preds = np.argmax(predictions[[start_index+i]])\n    \n  gt = np.argmax(y_test[start_index+i])\n\n  col = \"g\"\n  if preds != gt:\n    col =\"r\"\n\n  plt.xlabel('i={}, pred={}, gt={}'.format(start_index+i,preds,gt),color=col)\n  plt.imshow(X_test[start_index+i])\n  plt.tight_layout()\n\nplt.show()","b72e49bc":"## Import Library","4b982ce5":"## Preparing training data","9bd000a0":"## Splitting the data into Train and Test","7bdd2171":"## Predicting the test images","cd1cfc47":"This Kernel is for someone who wants to deep dive into Computer Vision. I have used MobileNet (transfer learning) model for classification of the images of different breeds of dog.\n\nIf you found this Kernel helpful please up vote it. If you have some feedback and question donot forget to comment below.\n\nHappy_Learning","e87f6ba0":"## Callbacks","5558c227":"## Building and compiling of the Model","7c475e87":"## Visualization of data","f82cec9e":"## Training the model","5bef1af5":"## Sample Image","14ed214f":"## Visulazing the training","19865f32":"## Visualising the predicted images"}}