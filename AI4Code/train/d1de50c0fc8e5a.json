{"cell_type":{"e7697319":"code","f9083cb0":"code","ac23546a":"code","096b7661":"code","e0c3fe14":"code","46ca630d":"code","c827b84a":"code","97793f09":"code","36f0dc16":"code","a58dfb47":"code","7f8a28b4":"code","4cb8118b":"code","cf8f4003":"code","2409cf67":"code","c7569bdc":"markdown","79d7070a":"markdown","0ee88cf2":"markdown","40e8c95a":"markdown","5fc42fca":"markdown","e8bf1de4":"markdown","ca5c8a18":"markdown","4c343d1d":"markdown"},"source":{"e7697319":"#Importing the necessary libraries and the required classes\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import plot_model\n\nBATCH_SIZE = 256","f9083cb0":"# we read the data from both the training and the test datasets\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","ac23546a":"print(\"train.csv shape : \" + str(train.shape))\nprint(\"test.csv  shape : \" + str(test.shape))","096b7661":"X = np.array(train.drop('label', axis=1))\nX = X.reshape(-1, 28, 28, 1)\nX = X\/255.0\n\nout = pd.get_dummies(train.label)\nY = np.array(out)\n\nprint(\"X Shape :\" + str(X.shape))\nprint(\"Y shape :\" + str(Y.shape))","e0c3fe14":"# Let's print some of the images randomly along with their label\n# You can run this cell multiple times to get different images at each execution\n\nfig,plot = plt.subplots(2, 5, figsize=(16,7))\n\nfor i in range(10):\n    z = np.random.randint(low=0, high=X.shape[0])\n    axes = plot[i\/\/5, i%5]\n    axes.axis(\"off\")\n    axes.imshow(X[z].reshape(28,28), cmap='gray')\n    axes.set_title(\"Label : \" + str(np.argmax(Y[z])))\n\nplt.show()","46ca630d":"# Here, we will be dividing the training data into training and validation data\n\ntrain_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.05, random_state=21)\nprint(\"Training data :\" + str(train_x.shape))\nprint(\"Validation data :\" + str(val_x.shape))\nprint(\"Training labels :\" + str(train_y.shape))\nprint(\"Validation labels :\" + str(val_y.shape))\n\nplt.figure(figsize=(16,5))\nplt.subplot(1,2,1)\nsns.countplot(np.argmax(train_y, axis=1))\nplt.title(\"Training Data\")\nplt.xlabel(\"Digit Label\")\nplt.ylabel(\"Count\")\nplt.subplot(1,2,2)\nsns.countplot(np.argmax(val_y,axis=1))\nplt.title(\"Validation Data\")\nplt.xlabel(\"Digit Label\")\nplt.ylabel(\"Count\")\nplt.show()","c827b84a":"generator = ImageDataGenerator(rotation_range=45, \n                               width_shift_range=0.2, \n                               height_shift_range=0.2,\n                               zoom_range=0.2, \n                               shear_range=0.2)\ntrain_values = generator.flow(train_x, train_y, batch_size=BATCH_SIZE)","97793f09":"model = Sequential([Conv2D(32, kernel_size=(5,5), padding='Same', activation=tf.nn.relu, input_shape=(28,28,1)),\n                    Conv2D(32, kernel_size=(5,5), padding='Same', activation=tf.nn.relu),\n                    MaxPooling2D(pool_size=(2,2)),\n                    Dropout(0.2),\n                    Conv2D(32, kernel_size=(3,3), padding='Same', activation=tf.nn.relu),\n                    Conv2D(32, kernel_size=(3,3), padding='Same', activation=tf.nn.relu),\n                    MaxPooling2D(pool_size=(2,2)),\n                    Dropout(0.2),\n                    BatchNormalization(),\n                    Flatten(),\n                    Dense(256, activation=tf.nn.relu),\n                    Dropout(0.2),\n                    Dense(128, activation=tf.nn.relu),\n                    Dropout(0.2),\n                    Dense(10, activation=tf.nn.softmax)])","36f0dc16":"# With the help of the summary() function, we can see the total structure of the model in a tabular format\nmodel.summary()","a58dfb47":"plot_model(model, show_shapes=True)","7f8a28b4":"model.compile(optimizer=tf.keras.optimizers.RMSprop(), \n              loss=tf.keras.losses.CategoricalCrossentropy(), \n              metrics=['accuracy'])\n\"\"\"\ncallback = EarlyStopping(monitor=\"val_accuracy\", mode=\"\", patience=15, verbose=1)\nhistory = model.fit(train_values, validation_data=(val_x, val_y), batch_size=BATCH_SIZE, \n                    epochs=200, verbose=1, callbacks = [callback])\n\"\"\"\n\nhistory = model.fit(train_values, validation_data=(val_x, val_y), batch_size=BATCH_SIZE, epochs=50, verbose=1)","4cb8118b":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs= range(len(acc))\n\nplt.figure(figsize=(16, 5))\nplt.subplot(121)\nplt.plot(epochs, acc, label='Train_acc')\nplt.plot(epochs, val_acc, label='Val_acc')\nplt.legend()\nplt.title('Accuracy')\n\nplt.subplot(122)\nplt.plot(epochs, loss, label='Train_loss')\nplt.plot(epochs, val_loss, label='Val_loss')\nplt.legend()\nplt.title('Loss')\nplt.show()","cf8f4003":"print(\"Model accuracy on training set = \", model.evaluate(train_values)[1]*100, \"%\")\nprint(\"Model accuracy on validation set = \", model.evaluate(val_x, val_y)[1]*100, \"%\")\n\nY_pred = model.predict(val_x)\nY_pred = np.argmax(Y_pred, axis=1)\nY_actual = np.argmax(val_y, axis=1)\n\nconf_mtx = confusion_matrix(Y_actual, Y_pred)\n\nplt.figure(figsize=(12,10))\nsns.heatmap(conf_mtx, annot=True, cmap=\"Reds\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","2409cf67":"test_values = np.array(test)\/255.0\ntest_values = test_values.reshape(-1, 28, 28, 1)\nprint(\"Test data shape : \" + str(test_values.shape))\npred = np.argmax(model.predict(test_values), axis=1)\n\nsub = pd.DataFrame({'ImageId': list(range(1, pred.shape[0]+1)), 'Label':pred})\nsub.to_csv(\".\/submission.csv\", index=False)","c7569bdc":"According to the above heatmap, some of the confusing identification tasks including distinguishing between 1 & 7 and 0 & 6 . This somewhat correlates to real life distinction issues between the aboves pair due to similar visuals.\n\nNow, after training the model and noting observations, let's proceed to predicting the test values and storing them as a csv file. Similar to the training data, I will convert the DataFrame, containing the test data, to a numpy array, reshape it to 28x28x1 and the apply <i>Regularization<\/i> by dividing each pixel value by 255.0<br>\nThen we will predict the label values using the model trained above and store them in a csv file.","79d7070a":"Now, I will print the trend of the loss and accuracy of the model after each epoch.","0ee88cf2":"# Digit Recognizer\n\n* This notebook uses the <a href=\"https:\/\/en.wikipedia.org\/wiki\/MNIST_database\">MNIST dataset<\/a>, which is one of the most basic datasets that one uses to get a familiarity with the computer vision application of Machine Learning. \n* Through this task, we will get a basic knowledge about Convulational Neural Networks along with Deep Neural Networks. \n* We also get the experience as to how can we generate more examples by tweaking the training dataset using operations like rotation, zooming in\/out, shear distortion, etc.\n\nI have tried to make this notebook as descriptive and informative as possible. I hope the viewers like it. Please do suggest any modifications or give constructive feedbacks so that I can improve.","40e8c95a":"The above DataFrames consist of the pixel values for each image and the each column of the DataFrame corresponds to each of the pixel values.\n\nNow, for input image data - \n* We will convert the data from a DataFrame to a `numpy` array to effectively store the image data.\n* We will reshape the same array to 28x28x1 as all images are 28x28 grey-scale images.\n* We will perform <i>Regularization<\/i> by dividing the pixel values by 255.0 so as to restrict them between 0 and 1.\n\nFor the labels - \n* We will implement <i>One-Hot Encoding<\/i> using the `get_dummies()` function under the `pandas` library.\n* Then we will convert the Dataframe to a `nunmpy` array.","5fc42fca":"<i>Image Data Augmentation<\/i> artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, zooming in\/out, etc.\nSo, we will use Image Data Augmentation which will make our model more robust towards the variation of the handwritten digits. For this, we will use the `ImageDataGenerator()` method under `keras` library.<br>\nNote:- Horizontal and Vertical flips will not be used here as some of the images (e.g. 2,5,7) lose their semantic information after flipping (as the digits no longer remain a digit or a 6 becomes a 9) <br><br>\nFor more information, you can click <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator\">here<\/a> or <a href=\"https:\/\/towardsdatascience.com\/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2\">here<\/a> to know more about this function and its parameterization \n","e8bf1de4":"Now comes the model construction.<br>\n* The first half will consist of Convolutional layers with Relu Activation\n* They will be accompanied by Maximum Polling and Dropout layers after each Convolution\n* Batch Normalisation will be performed after these layers\n* The intermediate output will be flatten to serve as an input to the following dense layers\n* The second half will comprise of 1 hidden dense layer with Relu Activation\n* Dropout layers will be played after the Dense layer\n* A final dense layer will be present to give the categorical output using the softmax activation","ca5c8a18":"After the model is created, the optimizers, the loss, and other metrics need to be selected before training the model.<br>\nI will be using the Adam Optimizer and calculating the Categorical Crossentropy to quantify the epoch-wise performace of the model. In addition to that, since the output here is categorical, I will be selecting the metric as \"accuracy\", which will return epoch-wise accuracy.<br><br>\nYou can also implement <i>Early Stopping<\/i> using the <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/EarlyStopping\">`EarlyStopping()`<\/a> function in the `keras` library.","4c343d1d":"Let's see how well out model performs on the training and the validation datasets. I will also build a <a href=\"https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix\">confusion matrix<\/a> and show a <a href=\"https:\/\/en.wikipedia.org\/wiki\/Heat_map#:~:text=A%20heat%20map%20(or%20heatmap,clustered%20or%20varies%20over%20space.\">heatmap<\/a> for better visualization."}}