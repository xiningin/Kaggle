{"cell_type":{"87e3ceb5":"code","e9ff7c54":"code","134aacbd":"code","cc14e6d8":"code","28e6752d":"code","92b51d7d":"code","4efa135c":"code","89fc0031":"code","d9dbc879":"code","180590d3":"code","9b224641":"code","605c9366":"code","5d765b60":"code","edf7d723":"code","d2142fec":"code","a8b5ddd0":"code","ca3fadd6":"code","14d15841":"code","725afa56":"code","7a8079c5":"markdown","4f6d8530":"markdown","2ae6affa":"markdown","20847359":"markdown","cb69c296":"markdown","12a0828d":"markdown","afb431d4":"markdown","0c1d9d21":"markdown","6cbac914":"markdown","77f03510":"markdown","22621db2":"markdown","b957f505":"markdown"},"source":{"87e3ceb5":"from pathlib import Path\n\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sklearn\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nfrom tqdm.notebook import tqdm\n\n!pip install mediapipe\nimport mediapipe as mp\nmp_hands = mp.solutions.hands","e9ff7c54":"data_root = Path('..\/input\/sign-language-digits-dataset\/Sign-Language-Digits-Datase\/')\ntrain_dir = data_root \/ 'train'\nvalidation_dir = data_root \/ 'valid'\n\nassert train_dir.exists()\nassert validation_dir.exists()","134aacbd":"def imread_rgb(x):\n    return cv2.imread(str(x))[..., ::-1].astype(np.uint8)\n    \nsample_file = list((train_dir.glob('*\/*')))[9]\nsample_img = imread_rgb(sample_file)\n\nfig, ax = plt.subplots(figsize=(12, 12))\nax.imshow(sample_img);\nax.set_yticks([])\nax.set_xticks([]);","cc14e6d8":"def load_landm(img):\n    with mp_hands.Hands(\n        static_image_mode=True,\n        max_num_hands=2,\n        min_detection_confidence=0.5) as hands:\n\n        results = hands.process(img)\n    return results\n\nsample_lm = load_landm(sample_img)\nsample_lm","28e6752d":"def visulize_lm(lm, img):\n    _img = img.copy()\n    \n    if load_landm(img).multi_hand_landmarks is None:\n        cv2.line(_img, [0, 0], [_img.shape[1], _img.shape[0]], color=(255, 0, 0))\n        cv2.line(_img, [_img.shape[1], 0], [0, _img.shape[0]], color=(255, 0, 0))\n        return _img\n\n    for l in load_landm(img).multi_hand_landmarks[0].landmark:\n        x = int(l.x*_img.shape[1])\n        y = int(l.y*_img.shape[0])\n        v = (l.z * 1500 * -1)\n        cv2.circle(_img, (x, y), 1, color=(v, 0, 255-v), thickness=-1)\n    \n    return _img\n\nimg_vis = visulize_lm(sample_lm, sample_img)\n\nfig, ax = plt.subplots(figsize=(12, 12))\nax.imshow(img_vis);\nax.set_yticks([])\nax.set_xticks([]);","92b51d7d":"def landmark_to_nparray(lm):\n    arr = np.empty(shape=[21, 3])\n    for i, l in enumerate(lm.multi_hand_landmarks[0].landmark):\n        arr[i, :] = [l.x, l.y, l.z]\n    return arr\n        \n\ndef build_datsframe(dir_path):\n#     df = pd.DataFrame()\n\n    files = list(dir_path.glob('*\/*'))\n    labels = list(map(lambda x: int(str(x.parent)[-1]), files))\n\n    files_list = []\n    lm_list = []\n    lbl_list = []\n    is_lm = []\n\n    for f, l in tqdm(zip(files, labels), total=len(files)):\n        img = imread_rgb(f)\n        lm = load_landm(img)\n        if lm.multi_hand_landmarks is None:\n            lm_list.append(None)\n            lbl_list.append(l)\n            files_list.append(files)\n            is_lm.append(False)\n            continue\n\n        lmarr = landmark_to_nparray(lm)\n        lm_list.append(lmarr)\n        lbl_list.append(l)\n        files_list.append(files)\n        is_lm.append(True)\n        \n    return pd.DataFrame({'file': files, 'label': labels, 'lm': lm_list})\n        \ntrain_df = build_datsframe(train_dir)\nvalid_df = build_datsframe(validation_dir)","4efa135c":"train_df.sample(5)","89fc0031":"train_file_count = train_df.groupby('label').count().file\ntrain_lm_count = train_df.groupby('label').count().lm\n\nvalid_file_count = valid_df.groupby('label').count().file\nvalid_lm_count = valid_df.groupby('label').count().lm\n\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(24, 4), ncols=2)\n\nsns.barplot(np.arange(10), train_file_count, label='Without landmark', color='tab:red', ax=ax[0])\nsns.barplot(np.arange(10), train_lm_count, label='With landmark', color='tab:green', ax=ax[0])\n\nsns.barplot(np.arange(10), valid_file_count, label='Without landmark', color='tab:red', ax=ax[1])\nsns.barplot(np.arange(10), valid_lm_count, label='With landmark', color='tab:green', ax=ax[1])\n\nfor i in range(2):\n    ax[i].set_ylabel('Count')\n    ax[i].set_ylabel('Class')\n    ax[i].legend()\n    \nax[0].set_title('Train set');\nax[1].set_title('Validation set');","d9dbc879":"train_df_with_lm = train_df[~pd.isnull(train_df.lm)]\n\nfig, ax = plt.subplots(ncols=5, nrows=2, figsize=[24, 8])\nax = ax.ravel()\n\nfor i, (idx, row) in enumerate(train_df_with_lm.sample(10).iterrows()):\n    img = imread_rgb(row.file)\n    vis = visulize_lm(row.lm, img)\n    \n    ax[i].imshow(vis)\n    ax[i].set_title(f'Label: {row.label}')\n    \nfig.suptitle('Samples with landmarks', fontsize=16);","180590d3":"train_df_without_lm = train_df[pd.isnull(train_df.lm)]\n\nfig, ax = plt.subplots(ncols=5, nrows=2, figsize=[24, 8])\nax = ax.ravel()\n\nfor i, (idx, row) in enumerate(train_df_without_lm.sample(10).iterrows()):\n    img = imread_rgb(row.file)\n    vis = visulize_lm(row.lm, img)\n    \n    ax[i].imshow(vis)\n    ax[i].set_title(f'Label: {row.label}')\n    \nfig.suptitle('Samples where skeleton was not detected', fontsize=16);","9b224641":"def load_x_y_from_df(df):\n    _df = df[~pd.isnull(df.lm)]\n    return np.stack([x for x in _df.lm]), _df.label\n#     return _df\n    \nx_train, y_train = load_x_y_from_df(train_df)\nx_valid, y_valid = load_x_y_from_df(valid_df)","605c9366":"def prepare_x(x):\n    num_samples, num_features, num_coordinates = x.shape\n    x_prepared = x.reshape((num_samples, num_features*num_coordinates))\n    return x_prepared\n\n\n# x_train_augmented = flip_x_coordinate(x_train)\n# x_train_augmented = prepare_x(x_train_augmented)\nx_train = prepare_x(x_train)\nx_valid = prepare_x(x_valid)\n\n# x_train = np.concatenate([x_train ,x_train_augmented], axis=0)\n# y_train = np.concatenate([y_train, y_train], axis=0)\nx_train.shape, y_train.shape, '\\n', x_valid.shape, y_valid.shape","5d765b60":"classifier = MLPClassifier(random_state=1, max_iter=500)\nclassifier.fit(x_train, y_train)","edf7d723":"pred_train = classifier.predict(x_train)\npred_valid = classifier.predict(x_valid)\nval_acc = accuracy_score(pred_valid, y_valid)\ntrain_acc = accuracy_score(pred_train, y_train)\n\ntrain_df_with_pred = train_df[~pd.isnull(train_df.lm)].copy()\ntrain_df_with_pred['pred'] = pred_train\n\nvalid_df_with_pred = valid_df[~pd.isnull(valid_df.lm)].copy()\nvalid_df_with_pred['pred'] = pred_valid\n\nprint(f'Train acc: {train_acc} \\t Valid acc: {val_acc}')","d2142fec":"fig, ax = plt.subplots(ncols=5, nrows=2, figsize=[24, 8])\nax = ax.ravel()\n\nfor i, (idx, row) in enumerate(valid_df_with_pred.sample(10).iterrows()):\n    img = imread_rgb(row.file)\n    vis = visulize_lm(row.lm, img)\n    \n    ax[i].imshow(vis)\n    ax[i].set_title(f'Gt: {row.label} Pred: {row.pred}')\n    \nfig.suptitle('Sample predictions', fontsize=16);","a8b5ddd0":"\nfig, ax = plt.subplots(ncols=2, nrows=1, figsize=[24, 8])\nax = ax.ravel()\n\nvalid_df_with_false_pred = valid_df_with_pred[valid_df_with_pred.label != valid_df_with_pred.pred]\nfor i, (idx, row) in enumerate(valid_df_with_false_pred.sample(2).iterrows()):\n    img = imread_rgb(row.file)\n    vis = visulize_lm(row.lm, img)\n    \n    ax[i].imshow(vis)\n    ax[i].set_title(f'Gt: {row.label} Pred: {row.pred}')\nfig.suptitle('Incorrect predictions', fontsize=16);","ca3fadd6":"conf_matr = confusion_matrix(pred_train, y_train)\ncm_display = ConfusionMatrixDisplay(conf_matr).plot()","14d15841":"conf_matr = confusion_matrix(pred_valid, y_valid)\ncm_display = ConfusionMatrixDisplay(conf_matr).plot()","725afa56":"import time\n\nts = []\nfor idx, row in tqdm(valid_df.iterrows(), total=len(valid_df)):\n    img = imread_rgb(row.file)\n\n    \n    t1 = time.time()\n    lm = load_landm(sample_img)\n    lmnp = landmark_to_nparray(lm)\n    x = prepare_x(np.expand_dims(lmnp, axis=0))\n    y = classifier.predict(x)\n    t2 = time.time()\n    \n    ts.append(t2-t1)\n    \nprint(f'Mean inference time: {np.mean(ts):0.4f}s (std: {np.std(ts)}:0.4f)')","7a8079c5":"# Visualize some landmarks","4f6d8530":"# Validation confusion matrix","2ae6affa":"# Calculate inference time","20847359":"# Find landmarks for each sample","cb69c296":"# Load image sample","12a0828d":"# Visualize random predictions from validation set","afb431d4":"# Only 2 validation samples failed. Visualize them","0c1d9d21":"# Train confusion matrix","6cbac914":"# Find and visualize landmark using mediapipe lib","77f03510":"# Train model using landmakrs","22621db2":"# Visualize sampels where mediapipe failed to load landmarks","b957f505":"# Check how many samples have been discarded"}}