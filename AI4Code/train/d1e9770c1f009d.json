{"cell_type":{"e3ba18f1":"code","e38c3898":"code","815fb88f":"code","8f417f89":"code","ed3d0911":"code","905688ec":"code","9a7de147":"code","c3e94f14":"code","fceab97e":"code","5849c203":"code","c38a2ca3":"code","2b1c5e5b":"code","9ae131b3":"code","99a882b8":"code","3e45a7e4":"code","6879e671":"code","12cb5f76":"code","3af0d555":"code","6c5eb105":"code","1af617a8":"code","fd81af68":"code","3a0a5b8a":"code","db924b68":"code","eadfd7bb":"code","5dd7a498":"code","4c3f7cac":"code","d851d6cf":"code","2a2c0244":"code","36f2ff48":"code","53e33d1e":"code","3e78e27c":"code","8f1141ed":"code","629f57e3":"code","926c713f":"code","ab4a1d6b":"code","6f5f9fcb":"code","e76ce66a":"code","32ba9aef":"code","5c717cbd":"code","db56b0fb":"code","5a7b451b":"code","e4dd1072":"code","2d28278c":"code","c10965fa":"code","7bc3de5f":"code","1db307ba":"code","6b38729f":"code","4d7d82bf":"code","fed49d40":"code","c19b5816":"code","86dba0e2":"code","8832210b":"code","15d0e3b5":"code","7046e89a":"code","ba08407b":"code","58fe5806":"code","c56a4ba5":"code","0cd67bf3":"code","09e7b67f":"code","601ef222":"code","1cd570bb":"code","7744a4e6":"code","4b82b0a6":"code","fef8c776":"code","c819cc69":"code","b2b9e052":"code","26073029":"code","8c3ae89c":"code","4532b0c3":"code","b1436a4f":"code","3d293a22":"code","e3b799fa":"code","afac3be1":"markdown","95fe2131":"markdown","677dee25":"markdown","4b4cf2a4":"markdown","d96de4e9":"markdown","1c7a5ac2":"markdown","bc5ee05e":"markdown","73b93ef9":"markdown","3532cd9e":"markdown","77c43673":"markdown","85dbd899":"markdown","2f800e4c":"markdown","28532ff7":"markdown","797f9342":"markdown","5365dd68":"markdown","8a7dc9fa":"markdown","523a6d25":"markdown","6959e7c1":"markdown","d7cdf235":"markdown","566a27cb":"markdown","9b2f695a":"markdown","b8f0a697":"markdown","d321aed9":"markdown","2099cb09":"markdown","639a5f13":"markdown","baf5eb9b":"markdown","07c012cd":"markdown","f4d84487":"markdown","bff2d2a8":"markdown","3e5f2b7e":"markdown","e2d6d2c2":"markdown","2bab23d1":"markdown","0a793333":"markdown","9d756d8a":"markdown","771f3f7e":"markdown","bd4a0f5f":"markdown","6d71507d":"markdown","192f4b8f":"markdown","0ddbd956":"markdown","b501057d":"markdown","cb85cb6e":"markdown","904b424b":"markdown","12949150":"markdown","cc77961e":"markdown","3bbd85b7":"markdown","e5d5429c":"markdown","44ff1d4c":"markdown","24ffa410":"markdown","cb8c29e8":"markdown","dbbdf79d":"markdown","a107b488":"markdown","e5751279":"markdown","020bb818":"markdown","a97b36bb":"markdown","39ab3d16":"markdown","b66c6c6b":"markdown"},"source":{"e3ba18f1":"import numpy as np\nimport pandas as pd\n!pip install openpyxl\nimport openpyxl\nfrom itertools import combinations\nfrom sklearn.feature_selection import RFECV\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom skopt import forest_minimize\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import KNeighborsClassifier\npd.set_option('display.max_columns', 500)","e38c3898":"df = pd.read_excel('\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')","815fb88f":"lab_feat = ['ALBUMIN',           \n 'BE_ARTERIAL',\n 'BE_VENOUS',\n 'BIC_ARTERIAL',\n 'BIC_VENOUS',\n 'BILLIRUBIN',\n 'BLAST',\n 'CALCIUM',\n 'CREATININ',\n 'FFA',\n 'GGT',\n 'GLUCOSE',\n 'HEMATOCRITE',\n 'HEMOGLOBIN',\n 'INR',\n 'LACTATE',\n 'LEUKOCYTES',\n 'LINFOCITOS',\n 'NEUTROPHILES',\n 'P02_ARTERIAL',\n 'P02_VENOUS',\n 'PC02_ARTERIAL',\n 'PC02_VENOUS',\n 'PCR',\n 'PH_ARTERIAL',\n 'PH_VENOUS',\n 'PLATELETS',\n 'POTASSIUM',\n 'SAT02_ARTERIAL',\n 'SAT02_VENOUS',\n 'SODIUM',\n 'TGO',\n 'TGP',\n 'TTPA',\n 'UREA',\n 'DIMER']","8f417f89":"monit_feat = [ 'BLOODPRESSURE_DIASTOLIC_MEAN',\n 'BLOODPRESSURE_SISTOLIC_MEAN',\n 'HEART_RATE_MEAN',\n 'RESPIRATORY_RATE_MEAN',\n 'TEMPERATURE_MEAN',\n 'OXYGEN_SATURATION_MEAN',\n 'BLOODPRESSURE_DIASTOLIC_MEDIAN',\n 'BLOODPRESSURE_SISTOLIC_MEDIAN',\n 'HEART_RATE_MEDIAN',\n 'RESPIRATORY_RATE_MEDIAN',\n 'TEMPERATURE_MEDIAN',\n 'OXYGEN_SATURATION_MEDIAN',\n 'BLOODPRESSURE_DIASTOLIC_MIN',\n 'BLOODPRESSURE_SISTOLIC_MIN',\n 'HEART_RATE_MIN',\n 'RESPIRATORY_RATE_MIN',\n 'TEMPERATURE_MIN',\n 'OXYGEN_SATURATION_MIN',\n 'BLOODPRESSURE_DIASTOLIC_MAX',\n 'BLOODPRESSURE_SISTOLIC_MAX',\n 'HEART_RATE_MAX',\n 'RESPIRATORY_RATE_MAX',\n 'TEMPERATURE_MAX',\n 'OXYGEN_SATURATION_MAX',\n 'BLOODPRESSURE_DIASTOLIC_DIFF',\n 'BLOODPRESSURE_SISTOLIC_DIFF',\n 'HEART_RATE_DIFF',\n 'RESPIRATORY_RATE_DIFF',\n 'TEMPERATURE_DIFF',\n 'OXYGEN_SATURATION_DIFF',\n 'BLOODPRESSURE_DIASTOLIC_DIFF_REL',\n 'BLOODPRESSURE_SISTOLIC_DIFF_REL',\n 'HEART_RATE_DIFF_REL',\n 'RESPIRATORY_RATE_DIFF_REL',\n 'TEMPERATURE_DIFF_REL',\n 'OXYGEN_SATURATION_DIFF_REL']","ed3d0911":"demo_feat = ['AGE_ABOVE65',\n 'AGE_PERCENTIL']","905688ec":"como_feat = ['DISEASE GROUPING 1',\n 'DISEASE GROUPING 2',\n 'DISEASE GROUPING 3',\n 'DISEASE GROUPING 4',\n 'DISEASE GROUPING 5',\n 'DISEASE GROUPING 6',\n 'HTN',\n 'IMMUNOCOMPROMISED',\n 'OTHER']","9a7de147":"y = ['ICU']","c3e94f14":"df.sample(15)","fceab97e":"# Para facilitar leitura vamos ordernar o dataframe de acordo com o identificador de cada paciente e a janela da visita desse paciente.\ndf.sort_values(['PATIENT_VISIT_IDENTIFIER','WINDOW'],inplace=True)\n\n#ajustar para que todas as colunas bin\u00e1rias sigam  o padr\u00e3o 0 ou 1.\nadapt_bool = df[df.columns[df.nunique() == 1]]\nadapt_bool = adapt_bool.fillna(0)\nadapt_bool = adapt_bool.abs()\ndf[df.columns[df.nunique() == 1]] = adapt_bool","5849c203":"df.head(10)","c38a2ca3":"df[df['PATIENT_VISIT_IDENTIFIER']==199]","2b1c5e5b":"# Existe um paciente com registros defeituosos. Dado que isso s\u00f3 ocorre com um dos pacientes, vamos eliminar ele do nosso dataset.\ndf.drop(df[df['PATIENT_VISIT_IDENTIFIER']==199].index,inplace=True)","9ae131b3":"class RepeatedSet:\n    def __init__(self,d,l):\n        self.d = d\n        self.l = l\n\ndef repeated_columns(dataframe):\n    \n    \"\"\"This function takes a DataFrame Object and return a dictionary with \n    all sets of columns that contains the same values. \n    \n    The keys of the dictionary are the names of the column used to compare values \"\"\"\n    \n    temp = dataframe.copy()\n    repeated_sets={}\n\n    for j in dataframe.columns:\n        if j in temp.columns:\n            repeats =[]\n            for i in dataframe.columns: \n                repeats.append(temp[j].equals(dataframe[i]))\n            if repeats.count(True) > 1:\n                repeated_sets[j] = dataframe.columns[repeats].to_list()[1:]\n            else:\n                pass\n            temp.drop(dataframe.columns[repeats].to_list(),axis = 1,inplace=True)\n        else:\n            pass\n    return RepeatedSet(repeated_sets,[item for sublist in repeated_sets.values() for item in sublist])","99a882b8":"#Drop redundant columns\nsets= repeated_columns(df)\ndf.drop(sets.l,axis=1,inplace=True)\n\n#Create map for redudant sets\ncolumn_maps = dict(zip(list(sets.d.keys())[2:],[item[:item.rindex('_')] for item in list(sets.d.keys())[2:]]))\ncolumn_maps['ALBUMIN_MEDIAN'] = 'ALBUMIN'\ncolumn_maps['ALBUMIN_DIFF'] = 'DIFF_SET'\n#Rename columns that represent the redudant sets\ndf.rename(columns=column_maps,inplace=True)","3e45a7e4":"df.drop('GENDER',axis=1,inplace=True)","6879e671":"df.head()","12cb5f76":"msno.matrix(df);","3af0d555":"df['MISSING DATA'] = df.isnull().sum(axis=1)","6c5eb105":"df.describe()","1af617a8":"aux = abs(df.groupby(\"PATIENT_VISIT_IDENTIFIER\")[\"ICU\"].sum()-5)\naux = aux.value_counts().reset_index()\naux.sort_values(by = \"index\", inplace = True)\n\naux_map = {0:\"0-2\", 1:\"2-4\", 2:\"4-6\", 3:\"6-12\", 4:\"Above-12\",5:\"Never\"}\n\naux['index'] = aux['index'].map(aux_map)\naux.rename(columns = {'index':'WINDOW'},inplace=True)\naux.set_index('WINDOW',inplace= True)\n\ntotal_icu = aux.ICU.sum()\ny = aux.ICU[0:5].cumsum()\/total_icu\n\ntot_icu_inpatients = aux.ICU[0:5].sum()\ny = aux.ICU[0:5].cumsum()\/total_icu\nplt.figure(figsize=(10,6))\nplt.plot(y, marker = \".\",)\nplt.title(\"Crescimento no percentual de interna\u00e7\u00f5es com o tempo de observa\u00e7\u00e3o.\")\nplt.xlabel('Tempo de observa\u00e7\u00e3o')\nplt.ylabel('Percentual de interna\u00e7\u00e3o');","fd81af68":"edites_list = []\nmax_patid = df['PATIENT_VISIT_IDENTIFIER'].max()\nfor i in range(int(max_patid)):\n  aux = df[df['PATIENT_VISIT_IDENTIFIER']==i]\n  if(len(aux)!=0):\n    aux.fillna(method = 'bfill', inplace=True)\n    aux = aux.iloc[[0]]\n    edites_list.append(aux)\n\n  \ngrouped_df = pd.concat(edites_list)\ngrouped_df.set_index('PATIENT_VISIT_IDENTIFIER',inplace=True)\n\ngrouped_df['ICU'] = df[['PATIENT_VISIT_IDENTIFIER','ICU']].groupby('PATIENT_VISIT_IDENTIFIER').max('ICU')['ICU']\n\ngrouped_df","3a0a5b8a":"ICU_Admitted = grouped_df[grouped_df['ICU']==1]\nages = sorted(grouped_df['AGE_PERCENTIL'].unique())\n\nx = [[],[]]\n\nfor i in ages:\n    x[0].append(grouped_df[grouped_df['AGE_PERCENTIL']==i].shape[0])\n    \nfor i in ages:\n    x[1].append(ICU_Admitted[ICU_Admitted['AGE_PERCENTIL']==i].shape[0])\n\nplt.figure(figsize=(17,6))\n    \na = []\nc=1\nfor i in x[0]:\n  a.extend([c*10]*i)\n  c+=1\nplt.hist(a, 20, label='Total')\nb = []\nc=1\nfor i in x[1]:\n  b.extend([c*10]*i)\n  c+=1\n\nplt.hist(b, 20, label='N\u00e3o Internados')\nplt.xticks([10,20,30,40,50,60,70,80,90,100],ages, rotation = 70)\nplt.legend()\nplt.ylabel('Ocorr\u00eancias')\nplt.title('Distribui\u00e7\u00e3o de idades entre internados e n\u00e3o internados')\nplt.show()\n","db924b68":"x = [[],[]]\n\nfor i in como_feat:\n    x[0].append(grouped_df[grouped_df[i]==1].shape[0])\n    \nfor i in como_feat:\n    x[1].append(ICU_Admitted[ICU_Admitted[i]==1].shape[0])\n    \nplt.figure(figsize=(17,6))\n\n\na = []\nc=1\nfor i in x[0]:\n  a.extend([c]*i)\n  c+=1\nplt.hist(a, 18, label='N\u00e3o Internados')\nb = []\nc=1\nfor i in x[1]:\n  b.extend([c]*i)\n  c+=1\nprint(x)\nplt.hist(b, 18, label='Internados')\nplt.xticks([1,2,3,4,5,6,7,8,9],como_feat, rotation = 70)\nplt.legend()\nplt.ylabel('Ococrr\u00eancias')\nplt.title('Distribui\u00e7\u00e3o de Comorbidades entre internados e n\u00e3o internados')\nplt.show()","eadfd7bb":"UTI_False = grouped_df[grouped_df['ICU']==0]\nUTI_True = grouped_df[grouped_df['ICU']==1]","5dd7a498":"monit_uti_false = np.array(UTI_False[lab_feat].mean(axis=0)) \nmonit_uti_true = np.array(UTI_True[lab_feat].mean(axis=0)) ","4c3f7cac":"monit_uti_false = np.array(UTI_False[monit_feat].mean(axis=0)) \nmonit_uti_true = np.array(UTI_True[monit_feat].mean(axis=0)) \n\nbarWidth = 0.25\nfig = plt.subplots(figsize =(21, 6)) \n\nbr1 = np.arange(len(monit_uti_true)) + (barWidth*0.5)\nbr2 = [x + barWidth for x in br1]  \n   \n# Make the plot \nplt.bar(br2, monit_uti_true,  width = barWidth, edgecolor ='w', label ='Internados') \nplt.bar(br1, monit_uti_false,  width = barWidth, edgecolor ='w', label ='N\u00e3o Internados') \n\n   \nplt.xlabel('M\u00e9tricas', fontweight ='bold') \nplt.ylabel('valores', fontweight ='bold') \nplt.xticks([r + barWidth for r in range(len(vital_ICU))],monit_feat, rotation = 90) \n\nplt.legend()\nplt.title(\"Compara\u00e7\u00e3o de monitoramentos entre pacientes internados e n\u00e3o internados\")\nplt.show()\n\n","d851d6cf":"lab_uti_false = np.array(UTI_False[lab_feat].mean(axis=0)) \nlab_uti_true = np.array(UTI_True[lab_feat].mean(axis=0)) \n\nbarWidth = 0.25\nfig = plt.subplots(figsize =(21, 6)) \n\nbr1 = np.arange(len(lab_uti_true)) + (barWidth*0.5)\nbr2 = [x + barWidth for x in br1]  \n   \n# Make the plot \nplt.bar(br2, lab_uti_true, color ='orange', width = barWidth, edgecolor ='w', label ='Internados') \nplt.bar(br1, lab_uti_false, color ='purple', width = barWidth, edgecolor ='w', label ='N\u00e3o Internados') \n\n   \nplt.xlabel('M\u00e9tricas', fontweight ='bold') \nplt.ylabel('valores', fontweight ='bold') \nplt.xticks([r + barWidth for r in range(len(vital_ICU))],lab_feat, rotation = 90) \n\nplt.legend()\nplt.title(\"Compara\u00e7\u00e3o de exames laboratoriais entre pacientes internados e n\u00e3o internados\")\nplt.show()\n\n","2a2c0244":"corr = grouped_df.corr()\ncorr.shape\nplt.subplots(figsize=(20,20))\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,square=True)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=90,\n    horizontalalignment='right');","36f2ff48":"df['MISSING DATA'].unique()","53e33d1e":"dict_miss = {}\nfor i in sorted(df['MISSING DATA'].unique()):\n    tempdf = df[(df['MISSING DATA']==i)]\n    \n    dict_miss[i] = tempdf.columns[tempdf.isnull().all()].to_list()\n    \ndict_miss","3e78e27c":"\ndict_miss_lab = {}\nfor i in sorted(df['MISSING DATA'].unique()):\n    tempdf = df[(df['MISSING DATA']==i)]\n    tempdf.drop(monit_feat,axis=1, inplace=True)\n    \n    dict_miss_lab[i] = tempdf.columns[tempdf.isnull().all()].to_list()\n    \nfor i in dict_miss_lab.keys():\n    print(set(dict_miss_lab[i]) == set([]) or set(dict_miss_lab[i]) == set(lab_feat))","8f1141ed":"df['missing_lab_exam'] = df[lab_feat].isnull().apply(lambda x: all(x), axis=1).astype(int)","629f57e3":"#Break monit_feature into smaller groups\nbloodpressure_monit = [idx for idx in monit_feat if idx.startswith('BLOODPRESSURE')]\nheart_monit = [idx for idx in monit_feat if idx.startswith('HEART')]\noxygen_monit = [idx for idx in monit_feat if idx.startswith('OXYGEN')]\nrespiratory_monit = [idx for idx in monit_feat if idx.startswith('RESPIRATORY')]\ntemperature_monit = [idx for idx in monit_feat if idx.startswith('TEMPERATURE')]\n\nmonit_list = [bloodpressure_monit,heart_monit,oxygen_monit,respiratory_monit,temperature_monit]","926c713f":"def check_monit(missing_list):\n    '''given a list of columns with all NaN rows, this function returns what was not being monitored\n    false = no monitoring\n    true = monitoring'''\n    \n    monit_list = [bloodpressure_monit,heart_monit,oxygen_monit,respiratory_monit,temperature_monit]\n    \n    \n    print('______group with {} missing values_______'.format(i))\n    if set(bloodpressure_monit).issubset(set(missing_list)) == True:\n        print('Bloodpressure is NOT being monitored')\n    if set(heart_monit).issubset(set(missing_list)) == True:\n        print('Heart Rate is NOT being monitored')\n    if set(oxygen_monit).issubset(set(missing_list)) == True:\n        print('Oxygen level is NOT being monitored')\n    if set(respiratory_monit).issubset(set(missing_list)) == True:\n        print('Respirartory Frequency is NOT being monitored')\n    if set(temperature_monit).issubset(set(missing_list)) == True:\n        print('Body Temperature is NOT being monitored')\n        \n        \nfor i in dict_miss.keys():\n    check_monit(dict_miss[i])","ab4a1d6b":"#Criando novas features para cada conjunto de indicadores\ndf['missing_bloodpresure_monit'] = df[bloodpressure_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_heart_monit'] = df[heart_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_oxygen_monit'] = df[oxygen_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_respiratory_monit'] = df[respiratory_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_temperature_monit'] = df[temperature_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)","6f5f9fcb":"#Conferindo se existe ocorrencias de NaN que n\u00e3o s\u00e3o explicadas pelos 6 conjuntos acima\n\n(df['MISSING DATA']\\\n- (len(lab_feat)* df['missing_lab_exam'])\\\n- (len(bloodpressure_monit)* df['missing_bloodpresure_monit'])\\\n- (len(heart_monit)* df['missing_heart_monit'])\\\n- (len(oxygen_monit)* df['missing_oxygen_monit'])\\\n- (len(respiratory_monit)* df['missing_respiratory_monit'])\\\n- (len(temperature_monit)* df['missing_temperature_monit'])).unique()","e76ce66a":"model_df = df.copy()","32ba9aef":"target_var =  model_df[['PATIENT_VISIT_IDENTIFIER','ICU']].groupby('PATIENT_VISIT_IDENTIFIER').sum('ICU')\n\ntarget_var['target']= target_var['ICU']>0.5\ntarget_var['target']= target_var['target'].astype('int')\ntarget_var.drop('ICU',axis=1,inplace=True)\n\ntarget_mapping = target_var['target'].to_dict()\nmodel_df['target'] = model_df['PATIENT_VISIT_IDENTIFIER'].map(target_mapping)\nmodel_df.reset_index(drop=True,inplace=True)","5c717cbd":"dummies =  pd.get_dummies(model_df['AGE_PERCENTIL'])\n\nmodel_df =pd.concat([model_df,dummies],axis=1)\nmodel_df.drop('AGE_PERCENTIL',axis=1,inplace=True)","db56b0fb":"model_df.drop(['PATIENT_VISIT_IDENTIFIER','MISSING DATA','WINDOW','ICU'],axis=1,inplace=True)","5a7b451b":"model_df = model_df.fillna(0)","e4dd1072":"y = model_df.pop('target')\nX = model_df","2d28278c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=11111993)","c10965fa":"def fast_model_training(hyperparam_dict,model):\n    rscv = RandomizedSearchCV(model, hyperparam_dict, random_state=11111993,n_iter=100)\n    search = rscv.fit(X_train, y_train)\n    return search.best_params_","7bc3de5f":"def teste_performance(y_test,y_pred):\n  vn, fp, fn, vp = confusion_matrix(y_test, y_pred).ravel()\n  acuracia=(vp+vn)\/(vp+fp+fn+vn)\n  especificidade = vn\/(vn+fp)\n  sensibilidade=vp\/(vp+fn)\n  print(\"Acur\u00e1cia:\",acuracia*100)\n  print(\"Sensibilidade:\",especificidade*100)\n  print(\"Especificidade:\",sensibilidade*100)\n  print(\"ROC_AUC:\",roc_auc_score(y_test, y_pred)*100)","1db307ba":"from sklearn.neighbors import KNeighborsClassifier\n\n\nknn = KNeighborsClassifier(n_jobs=-1)\n\nkkn_hyperparameters={\n    'weights':['uniform','distance'],\n    'n_neighbors':range(1,50),\n    'p':[1,2,3,4,5]\n    }\n\nbest_param = fast_model_training(kkn_hyperparameters,knn)\nbest_param","6b38729f":"knn = KNeighborsClassifier(**best_param, n_jobs=-1)\nknn.fit(X_train, y_train)\n\nprint(\"train shape: \" + str(X_train.shape))\nprint(\"score on test: \" + str(knn.score(X_test, y_test)))\nprint(\"score on train: \"+ str(knn.score(X_train, y_train)))","4d7d82bf":"teste_performance(y_test,knn.predict(X_test))","fed49d40":"from sklearn.svm import LinearSVC\n\nsvm=LinearSVC(dual=False)\n\nsvm_hyperparameters={\n    'penalty':['l1','l2'],\n    'loss':['hinge','squared_hinge'],\n    'C':[0,1,1,1.5,2,5],\n    'dual': [False]\n    }\n\nbest_param = fast_model_training(svm_hyperparameters,svm)\nprint(best_param)","c19b5816":"svm=LinearSVC(**best_param)\nsvm.fit(X_train, y_train)\nprint(\"train shape: \" + str(X_train.shape))\nprint(\"score on test: \" + str(svm.score(X_test, y_test)))\nprint(\"score on train: \"+ str(svm.score(X_train, y_train)))","86dba0e2":"teste_performance(y_test,svm.predict(X_test))","8832210b":"from sklearn.linear_model import LogisticRegression\n\nlr=LogisticRegression()\n\nlr_hyperparameters={\n    'penalty':['l1','l2'],\n    'class_weight':[None,'balanced'],\n    'C':[0,1,1,1.5,2,5],\n    'dual': [False],\n    'max_iter': [100,200,500,1000]\n    }\n\nbest_param = fast_model_training(lr_hyperparameters,lr)\nprint(best_param)","15d0e3b5":"lr = LogisticRegression(**best_param)\nlr.fit(X_train, y_train)\n\nprint(\"score on test: \" + str(lr.score(X_test, y_test)))\nprint(\"score on train: \"+ str(lr.score(X_train, y_train)))","7046e89a":"teste_performance(y_test,lr.predict(X_test))","ba08407b":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\n\n\nrf_hyperparameters={'bootstrap': [True, False],\n 'max_depth': [10, 30, 60, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [300]}\n\nbest_param = fast_model_training(rf_hyperparameters,rf)\nprint(best_param)","58fe5806":"rf = RandomForestClassifier(**best_param)\nrf.fit(X_train, y_train)\n\nprint(\"score on test: \" + str(rf.score(X_test, y_test)))\nprint(\"score on train: \"+ str(rf.score(X_train, y_train)))","c56a4ba5":"teste_performance(y_test,rf.predict(X_test))","0cd67bf3":"best_param_rf={'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}","09e7b67f":"rf = RandomForestClassifier(**best_param_rf)\nrf.fit(X_train, y_train)","601ef222":"params = {}\n\nclf = xgb.XGBClassifier(**params,verbosity=0)\n_ = clf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nteste_performance(y_test,y_pred)","1cd570bb":"# Vetores do hyperparametros que vamos testar\nfeaturespace = [(1e-3, 1e-1, 'log-uniform'), # learning rate\n          (100, 2000), # n_estimators\n          (1, 10), # max_depth \n          (1, 6.), # min_child_weight \n          (0, 0.5), # gamma \n          (0.5, 1.), # subsample \n          (0.5, 1.)] # colsample_bytree ","7744a4e6":"def tune_xgbc(params):\n# video tutorial: https:\/\/www.youtube.com\/watch?v=WhnkeasZNHI\n\n    print(params)\n    learning_rate = params[0] \n    n_estimators = params[1] \n    max_depth = params[2]\n    min_child_weight = params[3]\n    gamma = params[4]\n    subsample = params[5]\n    colsample_bytree = params[6]\n\n    clf = xgb.XGBClassifier(learning_rate = learning_rate, \n                            n_estimators = n_estimators, \n                            max_depth = max_depth, \n                            min_child_weight = min_child_weight, \n                            gamma = gamma, \n                            subsample = subsample, \n                            colsample_bytree = colsample_bytree)\n\n\n    #Valida\u00e7\u00e3o cruzada pra evitar Overfitting\n    auc = cross_val_score(clf, X_train, y_train, cv = 10, scoring = 'roc_auc')\n\n    print(auc.mean())\n    return -auc.mean()\n\n# Minizar erro utilizando arvores de decis\u00e3o e 25 itera\u00e7\u00f5es com otimiza\u00e7\u00e3o bayesiana.\nresult = forest_minimize(tune_xgbc, featurespace, random_state = 42, n_random_starts = 20, n_calls  = 25, verbose = 1)","4b82b0a6":"-result.fun","fef8c776":"param_call = ['learning_rate','n_estimators','max_depth','min_child_weight','gamma','subsample','colsample_bytree']\nparam_val = result.x\n\nparam = dict(zip(param_call, param_val))\n\nparam","c819cc69":"clf = xgb.XGBClassifier(**params,verbosity=0)\n#_ = clf.fit(X_train, y_train)\n\n\nrfecv = RFECV(estimator=clf, step=1, cv=5,\n              scoring='roc_auc')\nrfecv.fit(X_train, y_train)\n\n#Visualiza\u00e7\u00e3o da elimina\u00e7\u00e3o recursiva\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)","b2b9e052":"#Visualiza\u00e7\u00e3o da elimina\u00e7\u00e3o recursiva\n\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)","26073029":"#RFECV Feature List\n\nfeatures = [f for f in X.columns if f not in ['TARGET','SK_ID_CURR']]\n\nrfecv_features = list()\nindexes = np.where(rfecv.support_ == True)\nfor x in np.nditer(indexes):\n    rfecv_features.append(features[x])\nprint(rfecv_features)\n\nfeature_space = rfecv_features","8c3ae89c":"X_train = X_train[feature_space]\nX_test = X_test[feature_space]","4532b0c3":"kf = KFold(n_splits=5)\n\ntprs,fprs,aucs = [],[],[]\n\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    clf = xgb.XGBClassifier(**params)\n    _ = clf.fit(X_train, y_train)\n    y_pred = clf.predict_proba(X_test)[:,1]\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n    auc = metrics.auc(fpr, tpr)\n    tprs += [tpr]\n    fprs += [fpr]\n    aucs += [auc]","b1436a4f":"fig, (ax1) = plt.subplots(1,1,figsize=(10,6))\npal = sns.cubehelix_palette(8)\nsns.set_palette(pal)\n\nax1.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'grey')\n\nfor i in range(5):\n    ax1.plot(fprs[i], tprs[i],\n             label=r'Fold '+str(i+1)+' ROC (AUC = %0.4f)' % (aucs[i]),lw=2, alpha=1)\n\nax1.set_xlabel('\u00cdndice de Falsos Positivos')\nax1.set_ylabel('\u00cdndice de Verdadeiros Positivos')\nax1.set_title('M\u00e9dia da ROC')\nax1.legend(loc=\"lower right\")","3d293a22":"y_pred = clf.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\nauc = metrics.auc(fpr, tpr)\nprecision, recall, th = metrics.precision_recall_curve(y_test, y_pred)","e3b799fa":"fig, ax1 = plt.subplots(1, 1,figsize=(7,7))\n#ROC \nax1.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'grey')\n\nax1.plot(fpr, tpr, color='blue',\n         label=r'Fold 1 ROC (AUC = %0.4f)' % (auc),lw=2, alpha=1)\n\nax1.set_xlabel('\u00cdndice de Falsos Positivos')\nax1.set_ylabel('\u00cdndice de Verdadeiros Positivos')\nax1.set_title('M\u00e9dia da ROC')\nax1.legend(loc=\"lower right\")","afac3be1":"Acima vemos que a performance do nosso modelo aumentou consideravelmente em rela\u00e7\u00e3o ao modelo base!\n","95fe2131":"Al\u00e9m desses problemas, existem diversas colunas com valores repetidos. Vamos criar uma fun\u00e7\u00e3o para identificar conjuntos de colunas repetidas, ent\u00e3o vamos agregar cada conjunto de colunas repetidas em uma \u00fanica coluna e deletar as redund\u00e2ncias","677dee25":"## Matriz de Correla\u00e7\u00f5es\n\nAbaixo vamos construir uma matriz para identificar correla\u00e7\u00f5es entre todas as colunas da nossa base de dados. A tabela abaixo tem uma interpreta\u00e7\u00e3o simples: Dados muito claros tem uma alta correla\u00e7\u00e3o. Cores pr\u00f3ximas ao amarelo indicam correla\u00e7\u00f5es positivas e cores pr\u00f3ximas ao azul indicam correla\u00e7\u00f5es negativas.","4b4cf2a4":"### O modelo de random forest teve a melhor performance entre todos os modelos acima, ent\u00e3o vamos pegar ele para otimizar.","d96de4e9":"Vemos pouca correla\u00e7\u00e3o entre indicadores sanguineos e a admiss\u00e3o na UTI. N\u00e3o vale a pena isolar nenhum conjunto de indicadores em particular. essas leve varia\u00e7\u00f5es v\u00e3o ser bem capturadas por essas vari\u00e1veis no modelo","1c7a5ac2":"# KNN\n\n \u00e9 um classificador onde o aprendizado \u00e9 baseado \u201cno qu\u00e3o pr\u00f3ximo\u201d \u00e9 um dado (um vetor) do outro. Esse modelo \u00e9 baseado em dist\u00e2ncia e como todas nossas vari\u00e1veis est\u00e3o normalizadas, ele pode ser aplicado sem tratamento.","bc5ee05e":"<a id='part4'><\/a>\n\n# 4. Novas Vari\u00e1veis","73b93ef9":"<a id='part8'><\/a>\n# 8. Conclus\u00f5es\n\nConcluimos esse estudo com um modelo de AUC 0.8206. Acredito que esse AUC seja excepcional, especialmente considerando os nossos ajustes na vari\u00e1veis resposta e o tratamento que escolhemos para os dados faltantes, que n\u00e3o permitiu vazamento de informa\u00e7\u00f5es futuras ao longo do treinamento.","3532cd9e":"## 6.4 Modelo Final\n\nCom nossa vari\u00e1veis reposta escolhida, nossos modelo selecionado, nossos hyperparametros configurados e nossas variaveis explicativas filtradas, podemos finalmente treinar nosso modelo final e analisar sua performance usando valida\u00e7\u00e3o cruzada.","77c43673":"Podemos ver que uma pessoa de 60 anos ou mais de tem maior probabilidade de ser internada (pode-se estimar probabilidade visualmente, pela diferen\u00e7a das barras azuis e laranjas).\n\nEssa informa\u00e7\u00e3o \u00e9 condizente o que conhecendo do comportamento do virus e justifica mantermos a vari\u00e1vel `AGE_ABOVE65` no nosso modelo, para capturar o padr\u00e3o observado nesse gr\u00e1fico.","85dbd899":"Podemos ver um crescimento muito grande interna\u00e7\u00e3o nas primeiras 12 horas de observa\u00e7\u00e3o. Isso \u00e9 um dado not\u00e1vel, dado que sabemos que o tempo m\u00e9dio de um paciente de COVID na UTI \u00e9 muito maior que 12 horas.[o tempo m\u00e9dio de um paciente de COVID na UTI \u00e9 muito maior que 12 horas.](https:\/\/www.agenciabrasilia.df.gov.br\/2020\/12\/15\/reabilitacao-do-base-reduz-tempo-de-pacientes-de-coronavirus-na-uti\/). Por mais que isso pare\u00e7a \u00f3bvio, isso indica para a gente que n\u00e3o h\u00e1 ganhos relevantes em tentar otimizar um momento de diagnostico espec\u00edfico. Devemos simplesmente prever o quanto antes que a pessoa deve ir para a UTI.\n\nBaseado nisso, Vamos limitar nossa An\u00e1lise \u00e0 primeira observa\u00e7\u00e3o do paciente (`WINDOW == 0-2`), considerar se ela foi internada em algum momento (`ICU == 1` em qualquer observa\u00e7\u00e3o) e utilizar o premeiro exame dele para preencher os `NaN`. **Importante ressaltar que estamos usando esse tipo de tratamento na An\u00e1lise explorat\u00f3ria, n\u00e3o necessariamente na modelagem.**","2f800e4c":"Tamb\u00e9m \u00e9 vis\u00edvel a presen\u00e7a de `NaN` na base de dados, abaixo vamos visualizar quais das nossas colunas tem algum dado faltante, utilizando a matrix `missingno`.","28532ff7":"<a id='part1'><\/a>\n\n# 1. Importando os dados","797f9342":"Podemos ver que, entre mais de 700 observa\u00e7\u00f5es, existem apenas 13 valores poss\u00edvel de dados faltantes. Isso nos direciona para possiveis padr\u00f5es nos tipos de dados que n\u00e3o estamos vendo. Vamos tentar ver os tipos de dados que est\u00e3o faltando em cada um desses valores.","5365dd68":"<a id='part6'><\/a>\n\n# 6. Otimiza\u00e7\u00e3o\n\nEm particular vamos usar XGBoost, que \u00e9 uma implementa\u00e7\u00e3o de Gradient Boosted Decision Trees. Essa t\u00e9cnica tenta melhorar a performance de um conjunto de modelos (tal qual o Random Forest \u00e9 um conjunto de arvores de decis\u00e3o). Ela se baseia na intui\u00e7\u00e3o de que o o melhor modelo possivel, quando combinado com o modelo anterior, tem um erro m\u00e9dio menor.\n\nNosso processo de otimiza\u00e7\u00e3o vai seguir os seguintes passos:\n\n1. gerar um modelo base para compararmos as melhoras.\n2. Otimizar hyperparametros\n3. Reduzir a quantidade total de vari\u00e1veis.\n4. Treinar o Modelo Final","8a7dc9fa":"Podemos agrupar a maior parte dos dados em 4 categorias diferentes:\n\n1. Demogr\u00e1fico\n2. Comorbidades\n3. Monitoramento\n4. Laboratoriais\n\nTodos as m\u00e9tricas laboratoriais e de monitoramento receberam as seguintes caracteristicas\n\n- M\u00e9dia\n- Mediana\n- Min\n- Max\n\nAbaixo vamos agrupar esses diferentes grupos de dados em listas para facilitar an\u00e1lise futura de cada um desses elementos.","523a6d25":"# Random Forest\n\nA floresta Aleat\u00f3ria \u00e9 um modelo de emsemble de arvores de decis\u00e3o. Vamos modelar varias \u00e1rvores diferentes, com segmenta\u00e7\u00f5es diferentes do nosso conjunto de treino e classificar cada ponto do conjunto de teste baseado numa vota\u00e7\u00e3o entre essas \u00e1rvores.","6959e7c1":"Existem 0 ocorr\u00eancias de `NaN` n\u00e3o explicadas pelas nossas novas vari\u00e1veis.","d7cdf235":"Agora tamb\u00e9m vamos tirar da nossa base dados que n\u00e3o v\u00e3o ser relevante para nosso modelo.","566a27cb":"Para esssa an\u00e1lise, tamb\u00e9m estamos escolhendo n\u00e3o analisar genero do paciente. N\u00e3o \u00e9 um crit\u00e9rio que queremos que seja considerado na alo\u00e7\u00e3o na UTI.","9b2f695a":"## 6.1 Modelo Base\n\nNosso modelo base vai ser treinado com os parametros padr\u00f5es da API do XGBoost e ser\u00e1 nossa refer\u00eancia.","b8f0a697":"## Incidencia de cada intervalo de idade, separado entre internados e n\u00e3o internados.\n\nAbaixo queremos ver se existe alguma correla\u00e7\u00e3o entre certos intervalos de idade e a incid\u00eancias de interna\u00e7\u00f5es na UTI ou n\u00e3o.","d321aed9":"## Distribui\u00e7\u00e3o de Interna\u00e7\u00f5es por hor\u00e1rio de admiss\u00e3o.\n\nPodem ver o percentual de pacientes com `ICU = 1` em cada um dos intervalos de `WINDOW`.","2099cb09":"Por via das duvidas, vamos ver se ainda existe algum conjunto de dados faltantes que n\u00e3o \u00e9 explicado por nenhuma das 6 vari\u00e1veis que criamos.","639a5f13":"Antes de escolher um modelo para otimizar, vamos treinar rapidamente as principais op\u00e7\u00f5es de modelos usando um random search para afinar os hiperparametros. O modelo com melhor performance vai ser o que vamos investir mais energia em otimizar.","baf5eb9b":"Assim, conseguimos ver que, em todas as ocorrencias de `NaN` acontecem no conjunto inteiro de um dado monitoramento. Baseado nisso, podemos criar vari\u00e1veis para representar a aus\u00eancia de cada um desses 5 tipos de monitoramento.","07c012cd":"## Compara\u00e7\u00e3o de indicadores de monitoramento hospitalar entre pacientes internados e n\u00e3o internados\n\nVamos continuar comparando indicadores entre pacientes internados e n\u00e3o internados. Dessa vez vamos olhar para todos os indicadores relacionados a algum monitoramento hospitalar (`[monit_feat]`)","f4d84487":"<a id='part3'><\/a>\n\n# 3. An\u00e1lise Explorat\u00f3ria","bff2d2a8":"## Indicadores de Exames Laboratoriais\nOs exames laboratoriais ```lab_feat``` s\u00e3o obtidos atrav\u00e9s de um exame de sangue. O tempo entre a coleta do sangue e obten\u00e7\u00e3o dos resultados pode variar de acordo com din\u00e2micas internas do hospital e do laborat\u00f3rio. Observa\u00e7\u00f5es com ```NaN``` em todos os elemento de ```lab_feat``` representem a aus\u00eancia de resultados laboratoriais. Seja por atraso no laborat\u00f3rio ou por n\u00e3o solicita\u00e7\u00e3o desse exame. Baseado nisso, n\u00f3s vamos adicionar uma vari\u00e1vel representando se existem resutlados de exame laboratoriais naquela observa\u00e7\u00e3o ou n\u00e3o.\n\n\nAbaixo,para cada conjuto de pedidos com i dados faltantes, listamos as colunas que tem algum dado faltando. Depois testamos todos os conjuntos de pedidos para saber se eles tem zero exames laboratoriais faltando ou todos os exames laboratoriais faltando. Esse teste retorna FALSE caso existam ocorrencia de falta parciais de exame em algum grupo","3e5f2b7e":"Vamos tratar nossa tabela para conseguirmos treinar devidamente um modelo com ela!\n\nPrimeiramente, vamos criar vari\u00e1veis bin\u00e1rias baseadas no campo `AGE_PERCENTIL`","e2d6d2c2":"## Compara\u00e7\u00e3o de exames laboratorais entre pacientes internados e n\u00e3o internados\n\nAgora vamos ver como os exames laboratoriais descrevem ou n\u00e3o a decis\u00e3o de interna\u00e7\u00e3o na UTI. Para isso vamo fazer graficos de barra representando  o valor m\u00e9dio de um certo exame para o grupo internado e n\u00e3o internado","2bab23d1":"# Previs\u00e3o de Interna\u00e7\u00e3o na UTI para casos confirmados de COVID-19\n\nA pandemia do novo coronavirus sobrecarregou o sistema hospitalar global durante meses. Despreparados para a demanda longa e volumosa, solicita\u00e7\u00f5es por leitos nas Unidades de Tratamento Intensivo (UTI), equipamentos e profissionais ultrapassaram os recursos disponiveis para praticamente todos os hospitais do pa\u00eds. O primeiro caso de COVID-19 no Brasil foi identificado em 26 de Fevereiro de 2020 e desde ent\u00e3o, otimizar aloca\u00e7\u00e3o de recursos na UTI tem sido uma prioridade.\n\n## Objetivo\n\nSabemos que existe um espectro amplo de casos de COVID-19. Desde pacientes assintomaticos at\u00e9 pacientes necessitando respira\u00e7\u00e3o mec\u00e2nica. Nesse estudo, vamos tentar entender os principais indicadores que levam um paciente para UTI, assim como desenvolver um modelo que nos permita identificar se um paciente precisar\u00e1 ser direcionado para a UTI ou n\u00e3o, vai facilitar a previs\u00e3o de demanda de leitos de UTI. Importante enfatizar que esse \u00e9 um modelo focado em previs\u00e3o, n\u00e3o infer\u00eancia.\n\n## Indice\n\n1. [Importando os dados](#part1)\n2. [TRATANDO A BASE DE DADOS](#part2)\n3. [An\u00e1lise Explorat\u00f3ria](#part3)\n4. [Novas Vari\u00e1veis](#part4)\n5. [O Modelo](#part5)\n6. [Otimiza\u00e7\u00e3o](#part6)\n7. [Resultados do Modelo](#part7)\n8. [Conclus\u00f5es](#part8)\n\n## Resultados e Premissas do Modelo\n\n\n| M\u00e9trica | # |\n| --- | --- |\n| AUC | 82% |\n| Acur\u00e1cia | 72.9% |\n| Sensibildiade | 71.6% |\n| Especificidade | 74.5% |\n| # Vari\u00e1veis | 46 |\n\nAo longo desse caderno dois tratamentos foram realizados que diferem dos tratamentos mostrados durante o curso. Isso se refere ao **tratamento de NaN e o tratamento da Vari\u00e1vel Resposta**. Esses dois tratamentos podem afetar negativamente a performance do modelo mas acredito que deixam ele mais aplic\u00e1vel em produ\u00e7\u00e3o e portanto s\u00e3o positivos. Ao longo do estudo entraremos em mais detalhes, mas resumidamente\n\n1. A coluna ICU sem tratamento ser\u00e1 usada como Vari\u00e1vel Resposta porque ela n\u00e3o descreve quando alguem deve ser enviado para a UTI ou n\u00e3o. Ela descreve quando a admiss\u00e3o ocorreu. Um usu\u00e1rio desse modelo precisaria tomar a decis\u00e3o antes da Admiss\u00e3o e o tempo entre decis\u00e3o e admiss\u00e3o pode variar mais do que o valor m\u00e1ximo da vari\u00e1vel `WINDOW`.\n2. N\u00e3o tratamos os dados faltantes (`NaN`) com base em nenhum dado dispon\u00edvel. Nosso objetivo \u00e9 tomar a decis\u00e3o de interna\u00e7\u00e3o utilizando apenas UMA observa\u00e7\u00e3o. N\u00e3o podemos contar com o hospital tendo suposi\u00e7\u00f5es para valores em exames n\u00e3o realizados e tamb\u00e9m n\u00e3o podemos esperar que o usu\u00e1rio do nosso modelo insira informa\u00e7\u00f5es novas a cada duas horas. ","0a793333":"# Regress\u00e3o Logistica\n\nA Regress\u00e3o logistica \u00e9 um modelo de regress\u00e3o linear aplicado a uma fun\u00e7\u00e3o sigmoidal, permitindo assim que as probabilidades de cada ponto sejam distribuidas e as previs\u00f5es sejam separadas em um dado ponto de corte.","9d756d8a":"Agora que iteramos entre diversas combina\u00e7\u00f5es, podemos extrair a lista de valores que maximizaram o AUC_ROC nessas tentativas e resultaram num AUC de 0.83","771f3f7e":"<a id='RELU'><\/a>\n## 6.3 Remo\u00e7\u00e3o recursiva de vari\u00e1veis\n\nAgora que encontramos os valores dos nossos hyper parametros, podemos tentar retirar vari\u00e1veis que n\u00e3o contribuem para o nosso AUC. Vamos fazer isso utilizando valida\u00e7\u00e3o cruzada. N\u00f3s vamos iterar entre varias retiradas de var\u00e1veis e treinar nosso modelo novamente. Vamos repetir esse processo para todas as nossas vari\u00e1veis para identificarmos quais delas est\u00e3o de fato contribuindo para nossa previs\u00e3o.","bd4a0f5f":"\u00e9 bem f\u00e1cil identificar alguns conjuntos de correla\u00e7\u00f5es entre todos ods indicadores de monitoramento. esses pequenos padr\u00f5es que se foram no canto inferior direito represetam algumas m\u00e9tricas correlacionadas por sempre interdependentes. Essas s\u00e3o as vari\u00e1veis que descrevem informa\u00e7\u00f5es semelhantes e[ vamos explorar a remo\u00e7\u00e3o delas ap\u00f3s termos um modelo base treinado](#RELU)","6d71507d":"Esse paciente \u00e9 de uma crian\u00e7a, que n\u00e3o tem dados de comorbidade. Como \u00e9 o unico pedido com essa caracteristica, vamos desconsiderar ele da nossa an\u00e1lise.","192f4b8f":"<a id='part5'><\/a>\n\n# 5. O Modelo\n\nnos queremos desenvolver um modelo preditivo com classifica\u00e7\u00e3o bin\u00e1ria mapeada para as op\u00e7\u00f5es no conjunto `{Deve ser enviado para a UTI, N\u00e3o deve ser enviado para a UTI}`. A nossa id\u00e9ia que esse modelo seja utilizado para identificar, na triagem inicial, o destino mais adequado para aquele paciente.\n\nDado a quantidade limitada de leitos de UTI, falsos positivo representam um gasto desnecess\u00e1rio de recursos. Todavia, o risco de cont\u00e1gio associado a um falsos negativos podem gerar ainda mais infectados, promovendo um efeito em cadeia. Portanto, tentaremos minimizar as previs\u00f5es falsos, mas priorizaremos minimizar falsos negativos.","0ddbd956":"Observando o dicion\u00e1rio acima notamos alguns padr\u00f5es nos conjuntos de dados faltantes. Vamos analisar os mais proeminentes, que s\u00e3o os de exames laboratoriais e monitoramentos.","b501057d":"Acima, observamos que a maioria das comorbidades implica em uma maior chance de interna\u00e7\u00e3o. Todavia a sua incid\u00eancia \u00e9 relativamente baixa e todos os padr\u00f5es parecem j\u00e1 estar capturados em suas respectivas vari\u00e1veis. As comorbidades designadas como `OTHER`, n\u00e3o apresentam efeito relevante na decis\u00e3o de interna\u00e7\u00e3o ou n\u00e3o.","cb85cb6e":"Com isso observamos que `NaN` em vari\u00e1veis de exame laboratorial s\u00f3 existem em conjunto, indicamento a falta de resultados de exames laboratoriais durante o registro da observa\u00e7\u00e3o.\n\nBaseado nisso, podemos adicionar a vari\u00e1vel `missing_lab_exam`, que retorno `1` caso a pessoa n\u00e3o tenha resultados de exame de sangue durante a observa\u00e7\u00e3o.","904b424b":"## Missing Data\n\nDurante o tratamento n\u00f3s adicionamos uma contagem de dados faltantes na coluna `MISSING DATA`. Olhando para a distribui\u00e7\u00e3o de valores, podemos tentar ter um entendimento mais profundo do comportamento dessa vari\u00e1vel.","12949150":"## Escolhendo o algoritmo.\n\nExitem diversos algoritmos para escolhermos. Mas mantendo aten\u00e7\u00e3o na nossa base de dados e necessidades, podemos ter algumas premissas para embassar nossa escolha\n\n1. Queremos uma classifica\u00e7\u00e3o bin\u00e1ria.\n2. Temos uma vari\u00e1vel resposta bem balanceada\n3. Temos muitas vari\u00e1veis com valor zero\n4. nossas variaveis continuas est\u00e3o distribuidas entre 0 e -1\n\nAs principais op\u00e7\u00f5es que me vem a mente s\u00e3o KNN, SVM,Regress\u00e3o Logistica e Random Forest","cc77961e":"\n## Dados de Monitoramento\nO monitoramento de sinais vitais de um paciente \u00e9 feito utilizando cinco diferentes instrumentos:\n* Esfigmoman\u00f4metro \u00e9 utilizado para medir press\u00e3o sanguinea\n* Frequenc\u00edmetro \u00e9 utilizado para medir frequencia cardiaca\n* Ox\u00edmetro \u00e9 utilizado para medir n\u00edvel de oxygena\u00e7\u00e3o no sangue e a frequencia respirat\u00f3ria\n* Termometro \u00e9 utilizado para medir temperatura corporal\n\nEm qualquer dada observa\u00e7\u00e3o \u00e9 possivel um ou mais desses registros n\u00e3o tenham sido feitos, por falta ou falha de equipamento. Com base nisso vamos segmentar esses diferente tipos de monitoramento e testar cada um dos conjuntos de dados faltantes para ver qual dos monitoramentos estava faltando naquele conjunto de pacientes.","3bbd85b7":"Um paciente em particular chama aten\u00e7\u00e3o ao explorarmos a base. O paciente `199`.","e5d5429c":"Mesmo antes da otiza\u00e7\u00e3o, encontramos um ROC_AUC de 75, que \u00e9 um valor muito bom. Vamos tentar encontrar hyperparametros que melhorem essa performance","44ff1d4c":"Tamb\u00e9m observamos poucas correla\u00e7\u00f5es significativas nesse grupo. As divergencias mais notaveis est\u00e3o nos indices de satura\u00e7\u00e3o de oxigenio no sangue e taxa respirat\u00f3ria. Algo que est\u00e1 alinhado com nosso conhecimento pr\u00e9vio sobre o comportamento do Virus.","24ffa410":" Existe uma padr\u00e3o bem visivel em quais colunas tem mais ocorrencia de `NaN`. Vamos entrar mais afundo na escolha da forma de tratamento dos dados NaN adiante no nosso estudo. Nesse momento, nesse momento vamos criar uma coluna contando a quantidade de dados faltantes em cada linha.","cb8c29e8":"## 6.2 Otimizar Hiperparametros\n\nNos vamos otimizar nosso XGBoost utilizando otimiza\u00e7\u00f5es bayesianas em arvores decis\u00e3o contendo diversas combina\u00e7\u00f5es dos parametros abaixo.","dbbdf79d":"<a id='part7'><\/a>\n# 7. Avalia\u00e7\u00e3o do Modelo\n\nPara Avaliar nosso modelos vamos continuar usando a AUC_ROC. Foi a m\u00e9trica que nos focamos durante toda otimiza\u00e7\u00e3o. Al\u00e9m disso tamb\u00e9m vamos olhar a curva PR, que vai mostrar a rela\u00e7\u00e3o da nossa Precision e Recall em todos os possiveis cortes do nosso modelo.","a107b488":"<a id='part2'><\/a>\n\n# 2. TRATANDO A BASE DE DADOS\n\nAntes de come\u00e7armos uma explora\u00e7\u00e3o mais  detalhada, uma simples olhada nas amostras acima ja chamam nossa aten\u00e7\u00e3o para alguns problemas na tabela. Em particular a forma com que dados bin\u00e1rios s\u00e3o apresentados e a ordena\u00e7\u00e3o da planilha, para visualizarmos mais facilmente o progresso de pacientes","e5751279":"## Incidencia de cada comorbidade, separado entre internados e n\u00e3o internados.\n\nComo fizemos anteriormente, vamos tentar ver o se existe alguma correla\u00e7\u00e3o entre certos grupos de comorbidade e a quantidade de interna\u00e7\u00f5es na UTI.","020bb818":"Vemos acima que nosso AUC \u00e9 maximizado qunado utilizamos nossas 43 principais features. Assim podemos eliminar mais de metade das nossas colunas sem diminuir a capacidade de previs\u00e3o do nosso modelo. Abaixo extraimos a lista das 43 variaveis mais importantes.","a97b36bb":"### Nossa Vari\u00e1vel resposta\n\nNa nossa base de dados, a coluna ```ICU``` indica se aquela observa\u00e7\u00e3o foi feita na UTI (1) ou n\u00e3o (0). Entender a sutileza desse indicador \u00e9 extramente importante para nossos proximos passos. A coluna ```ICU``` n\u00e3o descreve quando houve solicita\u00e7\u00e3o de um leito de UTI. Al\u00e9m disso, sabemos que a transferencia de um paciente da emergencia\/triagem para um leito de UTI pode demorar significativamente.\n\n> **Esses dois fatores enfraquecem o v\u00ednculo das vari\u00e1veis ```WINDOW``` e ```ICU``` com a nossa vari\u00e1vel resposta**.\n\nN\u00e3o vai importar para gente quantas horas demorou para ele ser alocado na UTI. Nossa vari\u00e1vel resposta vai identificar se o paciente foi eventualmente para a UTI ou n\u00e3o.","39ab3d16":"# SVM\n\nSVM \u00e9 outro algoritmo de classifica\u00e7\u00e3o, que vai mapear nossas features em um hyperespa\u00e7o e depois tentar parti-lo em utilizando um \u00fanico hiperplano. Ele \u00e9 uma outra forma de calculo da fronteira bayesiana do KNN.","b66c6c6b":"## Como lidar com os dados faltantes\n\nExistem algumas op\u00e7\u00f5es de tratamento para dados com ```NaN```. Nesse estudo vamos usar ```NaN = 0```.\n\nTentar preencher esse valor vazio com m\u00e9dias ou valores obtidos em outras observa\u00e7\u00f5es simplesmente ignoraria o fato de que, em produ\u00e7\u00e3o, nosso algoritmo ter\u00e1 de lidar com a ausencia de certos valores, de acordo com a falta de certos tipos de monitoramento ou exames. Portanto, \u00e9 conceitualmente invi\u00e1vel utilizarmos dados futuros para realizar nossa previs\u00e3o, pois nossos usu\u00e1rios finais n\u00e3o ter\u00e3o acesso \u00e0 eles no dia-a-dia. \n\nTamb\u00e9m existe um problema gerado por utilizarmos ```NaN = 0```. O valor zero vai passar a descrever duas situa\u00e7\u00f5es diferentes. zero vai representar tanto a n\u00e3o mensura\u00e7\u00e3o, quanto a mensura\u00e7\u00e3o igual \u00e0 zero, que s\u00e1o conceitualmente diferentes. Acredito que isso n\u00e3o vai gerar problemas porque: \n* Mensura\u00e7\u00f5es iguais a zero s\u00e3o pouco representativas\n* A falta de mensura\u00e7\u00f5es tamb\u00e9m ser\u00e1 capturada nas vari\u00e1veis de monitoramentos e exame, que definimos na se\u00e7\u00e3o anterior."}}