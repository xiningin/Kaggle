{"cell_type":{"7af83ab4":"code","8db2b10d":"code","e6fd5808":"code","2b460eee":"code","fe8dc644":"code","3025a530":"code","1f4da4e7":"code","63247e2d":"code","3494dfc7":"code","f65f3403":"code","bd7a4700":"code","ec491969":"code","d8702fd2":"markdown"},"source":{"7af83ab4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8db2b10d":"data_time=pd.read_csv('..\/input\/2004-2019.tsv',sep='\\t')\ncols=list(data_time.columns)\nprint(data_time.shape)\nfor col in cols:\n    print(data_time[col].count())\n\n    ","e6fd5808":"for col in cols:\n    print(col)\nprint(data_time.head())","2b460eee":"!pip install googletrans","fe8dc644":"import googletrans\nfrom googletrans import Translator\ntranslator=Translator()","3025a530":"cols_en=[]\nfor col in cols:\n    translation=translator.translate(col)\n    text_col=translation.text\n    cols_en.append(text_col)\nprint(cols_en)    ","1f4da4e7":"data_time.columns=cols_en\ndata_time=data_time.drop('Unnamed: 0',axis=1)\nprint(data_time['INITIAL DATE'].unique().tolist())\nprint(data_time['DATA FINAL'].unique().tolist())\n","63247e2d":"print(data_time['UNIT OF MEASUREMENT'].unique().tolist())","3494dfc7":"regions=data_time['REGION'].unique().tolist()\nstates=data_time['STATE'].unique().tolist()\nprint(len(regions))\nprint(len(states))","f65f3403":"def columns_describer(column,data=data_time):\n    col_list=data[column].unique().tolist()\n    print('for column',column,'lengths of uniques are:',len(col_list))","bd7a4700":"for col in list(data_time.columns):\n    columns_describer(col)","ec491969":"cols=list(data_time.columns)\nplt.hist(data_time[cols[1]].tolist())","d8702fd2":"observe that each row is a data for 7 days. It starts from 2014,9th may to 2019, 23th june. So, the data is weekly summary for 5 years, 1 month."}}