{"cell_type":{"acf6d00f":"code","f96e804c":"code","998c986c":"code","1d21e328":"code","220e3bd6":"code","8ee37c75":"code","427dc67a":"code","03185d6c":"code","74f44fac":"code","3bfed3d8":"code","fcad663f":"code","8ae5ab2b":"code","062244b6":"code","781a471c":"code","f05a109a":"code","842eedd2":"code","46cd7fa9":"code","f15c0f5e":"code","027e686e":"code","a3ba7264":"code","962c6f20":"code","f22b3ebe":"code","8a7cd58f":"code","83ea5552":"code","f8b96bbd":"code","948241cf":"code","0a780e75":"code","2983e90d":"code","113d9bdf":"code","a5ee1ef9":"code","78eb022a":"code","7cdfae57":"code","b38777f0":"code","334eb0e3":"code","e1ac3df8":"code","89699d22":"code","e59c13aa":"code","24564456":"code","e6245ac1":"code","62a2575e":"code","50f18f45":"code","217827a3":"code","35bbc91e":"code","68bcf646":"code","a628ba73":"code","8ab13e06":"code","834beb6e":"code","22e2878b":"code","ac26c995":"code","4b43ef31":"code","90c18a9f":"code","cbeeac44":"code","3a4b8bdc":"code","6837b8d6":"code","ef086abe":"code","29f4e3e6":"code","f43d8b65":"code","ee1e0151":"code","4d35ba99":"code","4eab94f5":"code","eb7e6437":"code","c28257f5":"code","781f3a9c":"code","9cf22f03":"code","979f6456":"code","8bcc1c28":"code","0be9af43":"code","21ec6e3b":"code","4c5510d1":"code","7a789924":"code","3c8ceb98":"code","40967bf7":"code","6c0a46fe":"code","45534f3a":"code","c82bcefb":"code","8a52d1db":"code","4da4342e":"code","f6b1c01f":"code","13cbfdf0":"code","35042b72":"code","171cab30":"code","3cba1f62":"code","6067a5be":"code","7bcc6d7e":"code","7dc74642":"code","00adcc54":"code","64c12615":"code","2b39fe72":"code","da24be25":"code","28c166d3":"code","c28aa564":"code","718e92e0":"code","70b95a27":"code","14e430dc":"code","ac66e338":"code","fb068c91":"code","63e03eed":"code","b1a2fb7a":"code","8506eb1b":"code","255a6a37":"code","e462d9fb":"code","857e466e":"code","d1b8d653":"code","16df78ae":"code","b65e6275":"code","9d04cd47":"code","fcdfa7cf":"code","503346f7":"code","e24c9b47":"code","54a6cdae":"code","de17d4f7":"code","a8c5f555":"markdown","db814c86":"markdown","cdd2cfb1":"markdown","5bea2363":"markdown","e302f91a":"markdown","307f4bfc":"markdown","0279eedb":"markdown","3179df18":"markdown","222e6221":"markdown","57e9e206":"markdown","436e78fd":"markdown","0bfb2df4":"markdown","be985640":"markdown","0cad0d16":"markdown","b0483eb0":"markdown","63b50831":"markdown","f8353353":"markdown","5b7b4e3e":"markdown","75548ee0":"markdown","f8c90c1a":"markdown","9011fede":"markdown","5b42dcdb":"markdown","e4589f96":"markdown","d745d3ee":"markdown","25462cac":"markdown","148634c5":"markdown","2c2bda95":"markdown","da0155e8":"markdown","d7773453":"markdown","f36ef57b":"markdown","e3df0969":"markdown","6fa7116c":"markdown","d4934ef1":"markdown","4fe55a1f":"markdown","ca60b0b8":"markdown","210e87d2":"markdown","13c75b01":"markdown","569922bf":"markdown","b216d1e2":"markdown","d4bb54a1":"markdown","364beaaa":"markdown","339fc962":"markdown","3eeb084a":"markdown","5fe954c1":"markdown","c95f5a1f":"markdown","7163300c":"markdown","055ca788":"markdown","d1782b45":"markdown","c8f145a7":"markdown","ac30f74b":"markdown","4908c62c":"markdown","c302ca93":"markdown","32db9764":"markdown","4517b07f":"markdown","ffa6fe07":"markdown","0fcf859b":"markdown","679fefcc":"markdown","480fadef":"markdown","f8cb9edd":"markdown","92b0e5b4":"markdown","2ebc41b4":"markdown","15b4d8ad":"markdown","d70e3841":"markdown","f6278387":"markdown","055c2382":"markdown","633fd090":"markdown","a0ff270b":"markdown","138a5e11":"markdown","70e7a4a8":"markdown","e6d44184":"markdown","f86e0d16":"markdown","8c0da7bb":"markdown","d407a586":"markdown","3c38d230":"markdown","bb672b27":"markdown","87a07a6d":"markdown","2a1e2c64":"markdown","ff70e59f":"markdown","395b5479":"markdown","8096745f":"markdown","bcd93648":"markdown","80f32447":"markdown","13b811d6":"markdown","9b991af9":"markdown","95d1ad1f":"markdown","4e5b271d":"markdown","10e986fd":"markdown","b5d1de02":"markdown","f64d984d":"markdown","6f9080df":"markdown","807d4c05":"markdown","efcc9e08":"markdown","7a1e4718":"markdown","149932b2":"markdown","09dabccb":"markdown","d7c258ad":"markdown","a3fcc7b5":"markdown","49fb51ff":"markdown","3c0c57c5":"markdown","2a76f144":"markdown","607da2fc":"markdown","68744a97":"markdown","acec0666":"markdown","c1ec13ab":"markdown","e80e1c4d":"markdown","6bd955b5":"markdown","912b9d58":"markdown","1f16db0d":"markdown","1e7ae34f":"markdown","502870ca":"markdown","0d5e6419":"markdown","8fe8baba":"markdown","efaff6a7":"markdown"},"source":{"acf6d00f":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.impute import SimpleImputer\nfrom matplotlib import pyplot as mpl\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport numpy as np\n\n\n# Local application\nimport utilidades_practica_1_ordinaria as utils","f96e804c":"seed = 27912","998c986c":"filepath = \"..\/input\/breast-cancer-wisconsin-data\/data.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"\n\nwisconsin_data = utils.load_data(filepath, index, target)","1d21e328":"filepath = \"..\/input\/pima-indians-diabetes-database\/diabetes.csv\"\n\nindex = None\ntarget = \"Outcome\"\n\npima_data = utils.load_data(filepath, index, target)","220e3bd6":"wisconsin_data.sample(5, random_state=seed)","8ee37c75":"pima_data.sample(5, random_state=seed)","427dc67a":"(X_wisconsin, y_wisconsin) = utils.divide_dataset(wisconsin_data, target=\"diagnosis\")","03185d6c":"(X_pima, y_pima) = utils.divide_dataset(pima_data, target=\"Outcome\")","74f44fac":"X_wisconsin.sample(5, random_state=seed)","3bfed3d8":"X_pima.sample(5, random_state=seed)","fcad663f":"y_wisconsin.sample(5, random_state=seed)","8ae5ab2b":"y_pima.sample(5, random_state=seed)","062244b6":"train_size = 0.7\n\n(X_wisconsin_train, X_wisconsin_test, y_wisconsin_train, y_wisconsin_test) = train_test_split(X_wisconsin, y_wisconsin,\n                                                      stratify=y_wisconsin,\n                                                      random_state=seed,\n                                                      train_size=train_size)","781a471c":"train_size = 0.7\n\n(X_pima_train, X_pima_test, y_pima_train, y_pima_test) = train_test_split(X_pima, y_pima,\n                                                      stratify=y_pima,\n                                                      random_state=seed,\n                                                      train_size=train_size)","f05a109a":"X_pima_train.sample(5, random_state=seed)","842eedd2":"X_wisconsin_test.sample(5, random_state=seed)","46cd7fa9":"X_pima_train.sample(5, random_state=seed)","f15c0f5e":"X_pima_test.sample(5, random_state=seed)","027e686e":"y_wisconsin_train.sample(5, random_state=seed)","a3ba7264":"y_pima_train.sample(5, random_state=seed)","962c6f20":"y_wisconsin_test.sample(5, random_state=seed)","f22b3ebe":"y_pima_test.sample(5, random_state=seed)","8a7cd58f":"wisconsin_data_train = utils.join_dataset(X_wisconsin_train, y_wisconsin_train)","83ea5552":"pima_data_train = utils.join_dataset(X_pima_train, y_pima_train)","f8b96bbd":"wisconsin_data_test = utils.join_dataset(X_wisconsin_test, y_wisconsin_test)","948241cf":"pima_data_test = utils.join_dataset(X_pima_test, y_pima_test)","0a780e75":"wisconsin_data_train.sample(5, random_state=seed)","2983e90d":"pima_data_train.sample(5, random_state=seed)","113d9bdf":"wisconsin_data_test.sample(5, random_state=seed)","a5ee1ef9":"pima_data_test.sample(5, random_state=seed)","78eb022a":"wisconsin_data_train.shape","7cdfae57":"wisconsin_data_train.info(memory_usage=False)","b38777f0":"pima_data_train.shape","334eb0e3":"pima_data_train.info(memory_usage=False)","e1ac3df8":"y_wisconsin_train.cat.categories","89699d22":"y_pima_train.cat.categories","e59c13aa":"utils.plot_histogram(wisconsin_data_train)","24564456":"utils.plot_histogram(pima_data_train)","e6245ac1":"utils.plot_barplot(wisconsin_data_train)","62a2575e":"utils.plot_barplot(pima_data_train)","50f18f45":"utils.plot_pairplot(wisconsin_data_train, target=\"diagnosis\")","217827a3":"utils.plot_pairplot(pima_data_train, target=\"Outcome\")","35bbc91e":"corrM_wisconsin = wisconsin_data_train.corr()","68bcf646":"corrM_wisconsin","a628ba73":"f,ax = mpl.subplots(figsize=(31,31))\nsns.heatmap(corrM_wisconsin, annot=True, linewidths= .5, fmt=\".1f\", ax = ax)","8ab13e06":"corrM_pima = pima_data_train.corr()","834beb6e":"corrM_pima","22e2878b":"f,ax = mpl.subplots(figsize=(31,31))\nsns.heatmap(corrM_pima, annot=True, linewidths= .5, fmt=\".1f\", ax = ax)","ac26c995":"utils.missingdata(wisconsin_data_train)","4b43ef31":"utils.missingdata(pima_data_train)","90c18a9f":"print(\"Pregnances:\",(pima_data_train.Pregnancies == 0).sum())\nprint(\"DiabetesPedigreeFunction:\",(pima_data_train.DiabetesPedigreeFunction==0).sum())\nprint(\"Age:\",(pima_data_train.Age==0).sum())\n\nprint(\"Glucose:\",(pima_data_train.Glucose==0).sum())\nprint(\"BloodPressure:\",(pima_data_train.BloodPressure==0).sum())\nprint(\"SkinThickness:\",(pima_data_train.SkinThickness==0).sum())\nprint(\"Insulin:\",(pima_data_train.Insulin==0).sum())\nprint(\"BMI:\",(pima_data_train.BMI==0).sum())\n\n","cbeeac44":"pima_data_train = pima_data_train.replace({'Glucose': 0,'BloodPressure': 0,'SkinThickness': 0,'Insulin': 0,'BMI': 0},np.nan)\n\n","3a4b8bdc":"utils.missingdata(pima_data_train)","6837b8d6":"utils.plot_box_diagram(wisconsin_data_train)","ef086abe":"utils.plot_box_diagram(pima_data_train)","29f4e3e6":"del_columns_wisconsin = utils.QuitarColumnasTransformer(['perimeter_mean', 'area_mean', 'compactness_mean', 'concave points_mean','radius_se','texture_se',\n                                    'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n                                    'fractal_dimension_se', 'radius_worst', 'smoothness_worst', 'symmetry_worst', 'texture_worst', 'perimeter_worst', 'area_worst', \n                                    'compactness_worst', 'concavity_worst', 'concave points_worst', 'fractal_dimension_worst', 'Unnamed: 32'])\n\nnan_anomalos_wisconsin=utils.AnomalosANanTransformer({'radius_mean':[6.981,22.27], 'texture_mean':[10.38,29.97],'smoothness_mean':[0.06251, 0.1326],\n                                     'symmetry_mean':[0.1203, 0.2459], 'fractal_dimension_mean':[0.04996, 0.0795], 'concavity_mean':[0, 0.2871]})","f43d8b65":"del_columns_pima = utils.QuitarColumnasTransformer(['SkinThickness', 'Insulin'])\n\nnan_anomalos_pima=utils.AnomalosANanTransformer({'Glucose':[56,199], 'BloodPressure':[38,102], 'Pregnancies':[0,13],\n                                      'BMI':[18.2,50], 'DiabetesPedigreeFunction':[0.078,1.182], 'Age':[21,64], })","ee1e0151":"imp = SimpleImputer(missing_values=float('nan'), strategy='mean')","4d35ba99":"wisconsin_data_train_aux=wisconsin_data_train[['radius_mean','texture_mean','smoothness_mean','symmetry_mean','fractal_dimension_mean','concavity_mean','diagnosis']]","4eab94f5":"utils.plot_pairplot(wisconsin_data_train_aux, target=\"diagnosis\")","eb7e6437":"discretizer_wisconsin = KBinsDiscretizer(n_bins=5, strategy=\"uniform\")","c28257f5":"pima_data_train_aux=pima_data_train[['Pregnancies','Glucose','BloodPressure','BMI','DiabetesPedigreeFunction','Age','Outcome']]","781f3a9c":"utils.plot_pairplot(pima_data_train_aux, target=\"Outcome\")","9cf22f03":"discretizer_pima = KBinsDiscretizer(n_bins=5, strategy=\"uniform\")","979f6456":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","8bcc1c28":"tree_model_classifier = DecisionTreeClassifier(random_state=seed)","0be9af43":"wisconsin_zero_r_model = make_pipeline(del_columns_wisconsin, nan_anomalos_wisconsin, imp, zero_r_model)","21ec6e3b":"pima_zero_r_model = make_pipeline(del_columns_pima, nan_anomalos_pima, imp, zero_r_model)","4c5510d1":"wisconsin_tree_model = make_pipeline(del_columns_wisconsin, nan_anomalos_wisconsin, imp, tree_model_classifier)","7a789924":"pima_tree_model = make_pipeline(del_columns_pima, nan_anomalos_pima, imp, tree_model_classifier)","3c8ceb98":"wisconsin_discretize_tree_model = make_pipeline(del_columns_wisconsin, nan_anomalos_wisconsin, imp, discretizer_wisconsin, tree_model_classifier)","40967bf7":"pima_discretize_tree_model = make_pipeline(del_columns_pima, nan_anomalos_pima, imp, discretizer_pima, tree_model_classifier)","6c0a46fe":"utils.evaluate(wisconsin_zero_r_model,\n               X_wisconsin_train, X_wisconsin_test,\n               y_wisconsin_train, y_wisconsin_test,'M')","45534f3a":"utils.evaluate2(pima_zero_r_model,\n               X_pima_train, X_pima_test,\n               y_pima_train, y_pima_test)","c82bcefb":"utils.evaluate(wisconsin_tree_model,\n               X_wisconsin_train, X_wisconsin_test,\n               y_wisconsin_train, y_wisconsin_test,'M')","8a52d1db":"utils.evaluate2(pima_tree_model,\n               X_pima_train, X_pima_test,\n               y_pima_train, y_pima_test)","4da4342e":"utils.evaluate(wisconsin_discretize_tree_model,\n               X_wisconsin_train, X_wisconsin_test,\n               y_wisconsin_train, y_wisconsin_test,'M')","f6b1c01f":"utils.evaluate2(pima_discretize_tree_model,\n               X_pima_train, X_pima_test,\n               y_pima_train, y_pima_test)","13cbfdf0":"filepath = \"..\/input\/titanic\/train.csv\"\n\nindex = \"PassengerId\"\ntarget = \"Survived\"\n\ntitanic_data = utils.load_data(filepath, index, target)","35042b72":"titanic_data.sample(5)","171cab30":"titanic_data[\"Survived\"]=titanic_data[\"Survived\"].astype(\"category\")\ntitanic_data.info(memory_usage=False)","3cba1f62":"(X_titanic_data,y_titanic_data)=utils.divide_dataset(titanic_data,target=\"Survived\")","6067a5be":"X_titanic_data.sample(5,random_state=seed)","7bcc6d7e":"y_titanic_data.sample(5,random_state=seed)","7dc74642":"train_size = 0.7\n\n(X_titanic_data_train, X_titanic_data_test, y_titanic_data_train, y_titanic_data_test) = train_test_split(X_titanic_data, y_titanic_data,\n                                                      stratify=y_titanic_data,\n                                                      random_state=seed,\n                                                      train_size=train_size)","00adcc54":"X_titanic_data_train.sample(5,random_state=seed)","64c12615":"X_titanic_data_test.sample(5,random_state=seed)","2b39fe72":"y_titanic_data_train.sample(5,random_state=seed)","da24be25":"y_titanic_data_test.sample(5,random_state=seed)","28c166d3":"titanic_data_train=utils.join_dataset(X_titanic_data_train,y_titanic_data_train)","c28aa564":"titanic_data_train.sample(5,random_state=seed)","718e92e0":"titanic_data_test=utils.join_dataset(X_titanic_data_test,y_titanic_data_test)","70b95a27":"titanic_data_test.sample(5,random_state=seed)","14e430dc":"titanic_data_train.shape","ac66e338":"y_titanic_data_train.cat.categories","fb068c91":"utils.plot_histogram(titanic_data_train)","63e03eed":"utils.plot_barplot(titanic_data_train)","b1a2fb7a":"utils.missingdata(titanic_data_train)","8506eb1b":"copiaT=titanic_data_train.copy()\ncopiaT = copiaT.drop(['Name', 'Ticket', 'Cabin', 'Fare'], axis=1)\ncopiaT['Sex']=copiaT['Sex'].map({'male':1,'female':0})\ncopiaT['Embarked']=copiaT['Embarked'].map({'Q':1,'C':2,'S':3})","255a6a37":"utils.plot_pairplot(copiaT, target=\"Survived\")","e462d9fb":"corrMatrix = copiaT.corr()","857e466e":"corrMatrix","d1b8d653":"f,ax=mpl.subplots(figsize=(7,7))\nsns.heatmap(corrMatrix,annot=True,linewidths=.5,fmt=\".1f\",ax=ax)","16df78ae":"utils.plot_box_diagram(copiaT)","b65e6275":"del_columns = utils.QuitarColumnasTransformer(['Cabin', 'Name', 'Ticket', 'Fare'])\n\nstring_int1 = utils.StringAIntTransformer('Sex',['female','male'],[0,1])\nstring_int2 = utils.StringAIntTransformer('Embarked',['Q','C','S'],[1,2,3])\n\nnan_anomalos_titanic = utils.AnomalosANanTransformer({'Pclass':[1,3], 'Sex':[0,1], 'SibSp':[0, 8],\n                                         'Parch':[0, 6], 'Embarked':[1, 3] })\n\nimp = SimpleImputer(missing_values=float('nan'), strategy='most_frequent')\n\ndiscretizer_titanic = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")","9d04cd47":"titanic_zero_r_model = make_pipeline(del_columns,string_int1,string_int2,nan_anomalos_titanic, imp, zero_r_model)","fcdfa7cf":"titanic_tree_model = make_pipeline(del_columns,string_int1,string_int2,nan_anomalos_titanic, imp, tree_model_classifier)","503346f7":"titanic_tree_model_disc = make_pipeline(del_columns,string_int1,string_int2,nan_anomalos_titanic, imp, discretizer_titanic, tree_model_classifier)","e24c9b47":"utils.evaluate(titanic_zero_r_model,\n               X_titanic_data_train, X_titanic_data_test,\n               y_titanic_data_train, y_titanic_data_test)","54a6cdae":"utils.evaluate(titanic_tree_model,\n               X_titanic_data_train, X_titanic_data_test,\n               y_titanic_data_train, y_titanic_data_test)","de17d4f7":"utils.evaluate(titanic_tree_model_disc,\n               X_titanic_data_train, X_titanic_data_test,\n               y_titanic_data_train, y_titanic_data_test)","a8c5f555":"Seg\u00fan la funci\u00f3n info, tenemos 8 variables predictoras las cuales son num\u00e9ricas (float e int) y una variable clase (categorica).","db814c86":"### *Pipeline*","cdd2cfb1":"Es importante para el proceso diferenciar entre el conjunto de variables predictoras y las variables objetivo.","5bea2363":"Utilizaremos la funci\u00f3n train_test_split, a la que le indicaremos la proporci\u00f3n ya indicada. Adem\u00e1s, incluiremos la semilla y el conjunto de datos a utilizar para la estratificaci\u00f3n.","e302f91a":"Adem\u00e1s, vamos a dividir el conjunto X e Y a su vez en conjuntos de entrenamiento y test, utilizando la proporci\u00f3n de antes y estratificaci\u00f3n.","307f4bfc":"En el caso de wisconsin podemos ver que todas las variables carecen de valores nulos salvo por la variable unnamed 32, que solo tiene valores nulos.","0279eedb":"### Limpieza de datos","3179df18":"Ambas variables objetivo toman dos valores, pero la de pima se registra en unos y ceros, y la de wisconsin toma los valores \"B\" y \"M\".","222e6221":"Ahora que tenemos el conjunto entrenamiento de X e Y en una variable, vamos a volver a unirlos en otra variable para agilizar las operaciones y tener el conjunto completo de entrenamiento.","57e9e206":"Una vez hemos creado el modelo pasando el pipeline al conjunto de datos, vamos a estudiar los resultados de cada uno:","436e78fd":"A continuaci\u00f3n, utilizaremos un diagrama de caja para ver los intervalos est\u00e1ndar de las variables y definir los l\u00edmites por los que se define un valor an\u00f3malo.","0bfb2df4":"# 6. Evaluaci\u00f3n de modelos","be985640":"Y con el conjunto de datos discretizado:","0cad0d16":"Vamos a usar dos bases de datos en esta pr\u00e1ctica:","b0483eb0":"Y prueba:","63b50831":"Como nos indica la funci\u00f3n shape, tenemos un total de 623 pasajeros y 11 variables en el conjunto de entrenamiento.","f8353353":"Tras ver las variables m\u00e1s correlacionadas, vamos a mostrar ahora una gr\u00e1fica para cada conjunto de datos en las que se muestra si alguna de ellas tiene algun valor nulo.","5b7b4e3e":"Una es la base de datos Breast Cancer Wisconsin (Diagnostic) Data Set. La cual, mediante valores m\u00e9dicos relacionados, permite diagnosticar a un paciente con un cancer maligno o benigno. Las variables m\u00e9dicas que estudiaremos son:\n\n* `Area_mean`: Media del area\n* `Diagnosis`: El diagnostico final (M = maligno, B = benigno)\n* `Smoothness_mean`: Media de las variaciones locales en longitudes de radio\n* `Texture_mean`: Desviaci\u00f3n est\u00e1ndar de los valores de la escala de grises.\n* `Radius_mean`: Media de distancias desde el centro a puntos del perimetro \n* `Perimeter_mean`: Tama\u00f1a del centro del tumor.\n* `Concave_points_mean`: N\u00famero medio de porciones c\u00f3ncavas del contorno.\n* `Compactness_mean`: Media del perimetro^2 \/ area - 1.0\n* `Concavity_mean`: Media de la gravedad de las porciones c\u00f3ncavas del contorno.\n* `Symmetry_mean`: Media de las simetrias\n* `Fractal_Dimension_mean`: Media de \"coastline approximation\" - 1\n\nAsociada a cada variable, tenemos tambi\u00e9n tenemos su error est\u00e1ndar y su peor caso.\n\nA partir de estas variables, se guarda la conclusi\u00f3n en la variable objetivo \"Outcome\" bajo el valor de M o B. Si el resultado es M el tumor es maligno, si es B, benigno.","75548ee0":"En el caso de wisconsin, debemos indicar \"diagnosis\" como la variable objetivo y la variable \"id\", como \u00edndide.\nEn Pima, sin embargo, como no tenemos \u00edndice en la base de datos, indicamos el index como None y \"Outcome\" como variable objetivo.","f8c90c1a":"Antes de evaluar los modelos, vamos a crear los pipeline, que utilizaremos para aplicar los transformadores que hemos creado anteriormente al conjunto de datos.\nCrearemos los pipeline con la funci\u00f3n make_pipeline y le pasaremos como par\u00e1metros los transformadores y el estimador.","9011fede":"El primer algoritmo de clasificaci\u00f3n que vamos a aprender es el m\u00e1s sencillo de todos, el Zero-R.","5b42dcdb":"Podemos volver a utilizar la funci\u00f3n sample, para comprobar que la partici\u00f3n se ha hecho correctamente.","e4589f96":"Usando la funci\u00f3n categories podemos ver que valores pueden tomar este tipo de variables.","d745d3ee":"El proceso de discretizaci\u00f3n permite convertir variables num\u00e9ricas en categ\u00f3ricas. Esto facilita mucho el trabajo para los algoritmos de aprendizaje.\nNosotros crearemos un discretizador para cada conjunto de datos.","25462cac":"    Pclass: [1 - 3] -> como vimos anteriormente solo tenemos estas tres clases y no se ven valores anomalos.\n    Sex: [0 - 1] -> es una variable binaria donde solo se puede ser hombre (1) o mujer (0), no se encuentran valores anomalos.\n    Age: [20 - 39] -> vemos que hay algunos valores fuera de lo comun como recien nacidos con 0 a\u00f1os y personas ancianas con hasta 80 a\u00f1os, esto es menos comun pero no lo trataremos como valores anomalos.\n    SibSp: [0 -1] -> la mayoria de gente ha venido sin o con un nunico acompa\u00f1ante cercano (marido, mujer, hermano) aunque hay casos extra\u00f1os como el 3, 4, 5 y el 8.\n    Parch: [0-2] -> la mayoria de gene ha venido sola o con un hijo\/padre, hay pocos que han venido con dos, y podemos ver casos pocos comunes que han venido 3, 4, 5, o hasta 6 acompa\u00f1antes entre hijos y padres.\n    Fare: [7.92 - 30.6] -> respecto a las tarifas la mayoria tienen una qure ronda el precio de entre los 8 a los 3, aunque podemos encontrar muchos valores anomalos (puede ser resultado de que fueran los ultimos tickets o una posible reventa) que llegan hasta los 500.\n    Embarked: [1 - 3] -> unicamente hay tres posibilidades y no encontramos valores anomalos.","148634c5":"# 4. Preprocesamiento de datos","2c2bda95":"Ahora vamos convertir estos 0s en 'Nan' en las variables donde no tienen sentido estos 0s es decir en Glucose, BloodPressure, SkinThickness, Insulin y BMI.","da0155e8":"Una vez conocemos la base de datos, vamos a proceder a incluirla en la libreta utilizando su filepath. Indicaremos el \u00edndice del conjunto utilizando la variable PassengerId y la variable objetivo con Survived.","d7773453":"Tenemos 10 variables. Cinco de ellas son num\u00e9ricas, tanto enteros como float (Pclass, Age, Sibsip, Parch y Fare). Sin embargo, hay otras de tipo object que debemos modificar para poder utilizarlas correctamente (Name, Sex, Ticket, Cabin y Embarked).","f36ef57b":"# 7.Titanic","e3df0969":"Con Pima quitaremos 'SkinThickness' e 'Insulin' debido a la gran cantidad de valores 'Nan' o anteriormente 0s, tambien pudimos observar gracias al mapa de correlacion que Age y Pregnances tienen bastante correlacion entre ellas (0.6) pero no vemos necesario eliminar alguna de ellas.","6fa7116c":"Y continuamos con la variable clase:","d4934ef1":"Tal y como se puede observar, el conjunto de datos est\u00e1 formado por 537 casos y 9 variables (8 variables predictoras y 1 variable clase).\n\nPara conocer informacion sobre esta base de datos recurrimos al m\u00e9todo `info` de nuevo:","4fe55a1f":"Ahora vamos a volver a mostrar el conjunto de datos de Diabetes para ver los valores a Nan","ca60b0b8":"Se puede ver que la union de los conjuntos se han unido correctamente.","210e87d2":"Vamos a comprobar tambi\u00e9n la proporci\u00f3n de valores de la variable objetivo.","13c75b01":"Por \u00faltimo, finalizamos con la variable objetivo del conjunto de datos de entrenamiento:","569922bf":"Este paso del procedimiento es fundamental, pues es el que m\u00e1s va a influenciar nuestra eficacia en el proceso. Aqu\u00ed, modificaremos nuestro conjunto de datos para que se adapte a nuestras necesidades y ofrezca mejores resultados en el entrenamiento y el test.\nVamos a seguir los siguientes pasos:\n\n* Limpieza de datos: donde trataremos los valores perdidos, ruidosos...\n* Discretizaci\u00f3n: a trav\u00e9s de selecci\u00f3n de variables, de instancias...","b216d1e2":"# 2. Acceso y almacenamiento de datos","d4bb54a1":"El primer paso consiste en importar las librer\u00edas que nos ser\u00e1n \u00fatiles en los distintos apartados de la pr\u00e1ctica.","364beaaa":"Sin discretizador","339fc962":"Utilizaremos los siguientes transformadores para generar nuestro Pipeline:\n\n* del_columns: la utilizamos para borrar las variables que no aportan informaci\u00f3n o tienen muchos valores anomalos (cabin, name, ticket y fare).\n* Usamos cambiarStringAInt para convertir Sex y Embarked a un rango de n\u00fameros enteros que se corresponden con sus clases.\n* nan_anomalos_titanic sirve para definir un rango de valores para cada variable, evitando as\u00ed lo an\u00f3malos.\n* Imputador simple, que intercambia los valores nulos por los valores m\u00e1s utilizados ya que en algunos casos las  variables son categoricas y no se puede utilizar la media.\n* Discretizador de dos bins y estrategia uniforme.","3eeb084a":"# 1. Preliminares","5fe954c1":"Por \u00faltimo, como parte final de la entrega Extraordinaria, vamos a a\u00f1adir la base de datos Titanic y vamos a proceder a explorarla como las dos bases de datos anteriores. Este conjunto de datos tiene como idea ofrecer algunas caracter\u00edsticas de los pasajeros abordo del famoso transatl\u00e1ctico y, a partir de las mismas, debemos predecir si ese pasajero sobrevive o no a su hundimiento.\n\nLas variables que encontramos en este conjunto de datos son:\n\n* Survival: variable clase con valor 1 si sobrevive o 0 si no lo hace.\n* Pclass: clase del ticket. Puede ser 1, 2 o 3.\n* Sex: sexo del pasajero. \"Male\" o \"Female\".\n* Age: edad del pasajero en a\u00f1os.\n* Sibsip: n\u00famero de parejas y hermanos a bordo.\n* Parch: n\u00famero de padres e hijos a bordo.\n* Ticket: n\u00famero del ticket.\n* Fare: tarifa del pasajero.\n* Cabin: n\u00famero de cabina del pasajero.\n* Embarked: puerto de embarque. (C para Cherbourg, Q para Queenstown y S para Southampton).","c95f5a1f":"Con toda la informaci\u00f3n que hemos obtenido ( correlacion entre variables, variables ruidosas, valores anomalos) vamos a descartar las variables 'concavity', 'compactness' y 'concavity points', ya que son variables que tienen mucha correlaci\u00f3n con otras variables y adem\u00e1s tienen mucho ruido. Tambien vamos a eliminar perimeter y area por su gr\u00e1n parecido a radius (mucha correlacion). Adem\u00e1s, quitaremos las variables de tipo 'SE' y las de tipo 'WORST' ya que no se deben de usar para predecir.","7163300c":"Por \u00faltimo, vamos a evaluar el rendimiento de los modelos creados usando una matriz de confusi\u00f3n y la tasa de acierto asociada.","055ca788":"Antes de nada vamos a volver a generar unos diagramas de nube de puntos (pairplots) que nos ayudaran a generar nuestro discretizador facilitandonos la decision sobre la cantidad de conjuntos en los que dividir el rango de nuestras variables.","d1782b45":"###### Datos Mean:\n\n    Radius:[6.981 - 22.27] -> valores anomalos entre el 23.21 y el 28.11\n    Texture:[10.38 - 29.97] -> valores anomalos entre el 30.72 y el 39.28\n    Perimeter:[43.79 - 152.1] -> valores anomalos entre el 152.8 y el 188.5\n    Area:[143.5 - 1364] -> valores anomalos entre el 1384 y el 2501\n    Smoothness:[0.06251 - 0.1326] -> valores anomalos entre el 0.1371 y el 0.1634\n    Compactness:[0.01938 - 0.2293] -> valores anomalos entre el 0.2363 y el 0.3454\n    Concavity:[0 - 0.2871] -> valores anomalos entre el 0.3001 y el 0.4268\n    Concave_Points:[0 - 0.152] -> valores anomalos entre el 0.1595 y el 0.2012\n    Symmetry:[0.1203 - 0.2459] -> valores anomalos entre el 0.2495 y el 0.304, y el 0.106\n    Fractal_Dimension:[0.04996 - 0.0795] -> valores anomalos entre el 0.08046 y el 0.09744\n    \n###### Datos SE:\n\n    Radius:[0.1115 - 0.9317] -> valores anomalos entre el 0.9553 y el 2.873\n    Texture:[0.3981 - 2.342] -> valores anomalos entre el 2.426 y el 4.885\n    Perimeter:[0.7714 - 6.372] -> valores anomalos entre el 6.462 y el 21.98\n    Area:[7.228 - 90.47] -> valores anomalos entre el 93.91 y el 542.2\n    Smoothness:[0.001713 - 0.01215] -> valores anomalos entre el 0.01236 y el 0.03113\n    Compactness:[0.00252 - 0.06158] -> valores anomalos entre el 0.06213 y el 0.1354\n    Concavity:[0 - 0.08232] -> valores anomalos entre el 0.09263 y el 0.1535\n    Concave_Points:[0 - 0.02593] -> valores anomalos entre el 0.02598 y el 0.05279\n    Symmetry:[0.01013 - 0.03546] -> valores anomalos entre el 0.03756 y el 0.07895\n    Fractal_Dimension:[968.3\u00b5 - 0.007877] -> valores anomalos entre el 0.008015 y el 0.02984\n    \n###### Datos Worst:\n\n    Radius:[7.93 - 28.4] -> valores anomalos entre el 29.17 y el 36.04\n    Texture:[12.49 - 41.85] -> valores anomalos entre el 44.87 y el 47.16\n    Perimeter:[50.41 - 188.5] -> valores anomalos entre el 195 y el 251.2\n    Area:[185.2 - 2022] -> valores anomalos entre el 2053 y el 4254\n    Smoothness:[0.08125 - 0.1862] -> valores anomalos entre el 0.1873 y el 0.2226 y el 0.07117\n    Compactness:[0.02729 - 0.6247] -> valores anomalos entre el 0.659 y el 1.058\n    Concavity:[0 - 0.8216] -> valores anomalos entre el 0.8402 y el 1.252\n    Concave_Points:[0 - 0.291] -> sin valores anomalos\n    Symmetry:[0.1566 - 0.4228] -> valores anomalos entre el 0.4264 y el 0.6638\n    Fractal_Dimension:[0.05521 - 0.1224] -> valores anomalos entre el 0.1233 y el 0.2075\n    \n    \n    ","c8f145a7":"Usamos el comando sample para comprobar que se ha cargado adecuadamente.","ac30f74b":"Ahora, con el conjunto de entrenamiento completo, podemos estudiarlo a fondo antes de comenzar el preprocesamiento de datos.","4908c62c":"En el caso de wisconsin, el n\u00famero de variables es tan elevado que resulta imposible discernir ning\u00fan tipo de informaci\u00f3n \u00fatil de esta gr\u00e1fica, ya que todo resulta confuso.","c302ca93":"    Pregnances:[0 - 13] -> valores anomalos 14 y 17\n    Glucose:[56 - 199] -> valor anomalo 0\n    BloodPressure:[38 - 102] -> valores anomalos 0, y entre el 104 y el 122\n    SkinThickness:[1 - 63] -> valores anomalos 99 y el 0 o muy cercanos ya que es imposible que el grosor de la piel sea 0\n    Insulin:[14 - 342] -> valores anomalos entre el 318 , el 510 y el 0, los mayores podr\u00edan ser considerados ruido (543, 579, 600, 680, 846)\n    BMI:[18.2 - 50] -> valores anomalos 0, 52.3, 52.9, 53.2, 57.3, 59.4\n    DiabetesPedigreeFunction:[0.078 - 1.182] -> valores anomalos entre el 1.213 y el 2.42\n    Age:[21 - 64] -> valores anomalos entre el 65 y el 81","32db9764":" Segun \"info\", de las 32 variables, 31 son numericas (float) que coincide con las variables predictoras, y diagnosis, la variable clase (categorica). Y un dato que cabe destacar es que la variable Unnamed: 32 Es una variable despreciable ya que no tiene informacion y es todo Null.","4517b07f":"Los histogramas de algunas variables predictoras representan una distribuci\u00f3n normal (BMI, BloodPressure, Glucose, Skin Thickness), aunque presentan alg\u00fan dato ruidoso ya que son valores err\u00f3neos, por ejemplo:\n\n*     BMI, en 0.\n*     BloodPressure, en 0.\n*     Glucose, en 0.\n*     Skin Thickness, en 0, el valor en 95 lo tomaremos como anomalo.\n\nLos datos suelen estar entre los siguientes rangos:\n\n*     BMI se encuentra en el rango [17,69]\n*     BloodPressure se encuentra en el rango [20,124]\n*     Glucose se encuentra en el rango [55,200]\n*     Skin Thickness se encuentra en el rango [4,64]\n\nPor otro lado, las distribuciones de las variables Pregnancies, DiabetesPedigreeFunction son normales pero que tienden a la derecha.\n\n*     La distribuci\u00f3n de la variable Pregancies se encuentra en el rango [0,17].\n*     La distribuci\u00f3n de la variable DiabatesPedrigreeFunction se encuentra en el rango [0,2.5].\n*     La distribuci\u00f3n de la variable Age se encuentra en el rango [20,71], y encontramos un dato an\u00f3malo en el valor 80 porque se aleja de la distribuci\u00f3n de la variable.\n\nRespecto a la variable Insuline, podemos encontrar una distribucion normal que tiende a la derecha en el rango [20 - 700], podemos ver unos valores anomalos hasta el 800, los cuales los consideramos anomalos ya que estan muy alejados de la distribucion normal de la variable. Tambien podemos ver una gran cantidad de 0s los cuales los consideramos un valor ruidoso.","ffa6fe07":"De nuevo, vamos a utilizar la funci\u00f3n sample para comprobar que la separaci\u00f3n se ha realizado correctamente.","0fcf859b":"## Zero-R Model Pipelines","679fefcc":"### Algoritmo *CART* (*Classification and Regression Trees*): Inducci\u00f3n de \u00e1rboles de decisi\u00f3n","480fadef":"Lo que podemos apreciar en ambos casos es que el problema est\u00e1 desbalanceado, ya que no tenemos el mismo n\u00famero de casos para ambos valores. ","f8cb9edd":"El modelo con \u00e1rbol de decisi\u00f3n mejora notablemente los resultados ya que, utiliza un modelo m\u00e1s elaborado. Por ello, obtenemos hasta un 0.660 de recall en este caso, que aunque nu es un muy buen porcentaje tampoco es el peor.","92b0e5b4":"Vamos a estudiar las variables utilizando una gr\u00e1fica de barras que indique la distribuci\u00f3n de los valores de cada variable.","2ebc41b4":"A continuaci\u00f3n, incluimos las bases de datos, indicando en cada una cual es la variable objetivo.","15b4d8ad":"El discretizador de pima utiliza tambi\u00e9n la estrategia uniforme y define 5 conjuntos de la misma forma que anteriormente.","d70e3841":"Gracias a este diagrama obtenemos datos m\u00e1s precisos de nuestras variables y adem\u00e1s podemos observar los valores anomalos que toman nuestras variables.","f6278387":"El conjunto de datos est\u00e1 formado por 398 casos y 32 variables (31 variables predictoras y 1 variable clase).\n\nPodemos ver distinta informacion sobre nuestras bases de datos gracias al metodo `info` como el n\u00famero de entradas, el n\u00famero total de variables, la cantidad de `Non-Null` por variable o el tipo de cada una de estas:","055c2382":"Evidentemente, los resultados del Zero-R son nulos porque se trata de un algoritmo muy poco sofisticado que se limita a predecir siempre el valor m\u00e1s com\u00fan de la variable objetivo. Podemos observar que en el caso de Cancer con este algoritmo siempre predice como Benigno y esto no se puede tener en cuenta, de igual forma para diabetes ya que siempre predice que no hay diabetes (0).\n","633fd090":"El clasificador ZeroR predice simplemente la categor\u00eda mayoritaria. Aunque no hay poder de predictibilidad en ZeroR, es \u00fatil para determinar un desempe\u00f1o como un punto de referencia para otros m\u00e9todos de clasificaci\u00f3n.","a0ff270b":"Por \u00faltimo, antes de crear el pipeline, hemos utilizado un diagrama de cajas que nos muestra el rango de valores que suelen tener las variables num\u00e9ricas. Con esta informaci\u00f3n, podemos delimitar rangos de valores para las variables num\u00e9ricas, tanto las que son num\u00e9ricas inicialmente como las que eran categoricas las cuales hemos hecho numericas tambien para una mas facil representacion y tratamiento.","138a5e11":"Despu\u00e9s de crear los transformadores referentes a los datos anomalos y variables que no vamos a utilizar para nuestro pipeline, ahora creamos un imputador donde todos los valores nulos seran sustituidos por la media.","70e7a4a8":"# 3. An\u00e1lisis exploratorio de datos","e6d44184":"Despu\u00e9s de haber estudiado las variables, vamos a dividir el conjunto de datos en variables predictoras (X) y variable objetivo (y) para hacer m\u00e1s c\u00f3modas algunas operaciones.","f86e0d16":"A continuaci\u00f3n, es necesario dividir el conjunto de datos en dos. Por un lado, creamos un conjunto de entrenamiento y otro de prueba.\nEl primero lo utilizaremos para entrenar nuestro modelo y mejorar su rendimiento, y el segundo se dejar\u00e1 intacto para, cuando haya terminado el proceso de entrenamiento, utilizarlo para comprobar la eficacia del modelo.\nEn este caso, vamos a dividir los conjuntos siguiendo la proporci\u00f3n m\u00e1s t\u00edpica: un 70% para el de entrenamiento y un 30% para el de prueba.","8c0da7bb":"Utilizando un mapa de calor para ilustrar la matriz de correlaci\u00f3n, vemos que no hay ning\u00fan par de variables que tenga una correlaci\u00f3n alta o, ni siquiera, rese\u00f1able. De hecho, en algunos casos vemos una correlaci\u00f3n negativa, aunque nunca extrema.","d407a586":"Igual que hemos dicho antess gracias a este mapa de colores podemos ver mejor la correlacion que hay entre las variables de nuestra base de datos.","3c38d230":"Tambi\u00e9n es necesario, antes de comenzar a trabajar, definir una semilla que nos asegure que la distribuci\u00f3n aleatoria de los datos no var\u00ede de una ejecuci\u00f3n a otra.","bb672b27":"Como podemos ver, el problema est\u00e1 desbalanceado porque el n\u00famero de los que sobreviven y los que no no es similar.","87a07a6d":"Ahora vamos a crear los pipelines con los transformadores creados anteriormente.","2a1e2c64":"Podemos observar que Insulin tiene un 48.6% de valores Nulos (anteriormente 0s), este es un porcentaje muy alto por lo que deberiamos eliminar esta variable. SkinThickness igualmente tiene un 29.2% de valores nulos, no es tan alto como insulin pero tambien es un porcentaje considerable por lo que tambien desecharemos esta variable. Respeccto a BloodPressure, BMI y Glucose vemos que hay algunos casos pero que no llegan ni al 5% asi que no eliminaremos estas variables y estos casos seran tratados.","ff70e59f":"En el caso de Pima vamos a ver el mapa de correlacion representado con un mapa de calor, aunque al tener menos variables que Wisconsin este mapa de correlacion se puede llegar a entender, pero visualmente es m\u00e1s rapido de entender el mapa de calor.","395b5479":"Si nos fijamos en la gr\u00e1fica, podemos llegar a varias conclusiones:\n* En la gr\u00e1fica no aparecen todas las variables, solo las que tienen valores num\u00e9ricos.\n* La gran mayor\u00eda de las variables tienden a los extremos y ofrecen una distribuci\u00f3n desbalanceada a la izquierda.\n\nPor ello, resulta evidente que debemos procesar los datos para poder utilizarlos adecuadamente.\n\nRespecto a los datos mostrados en la grafica podemos observar:\n\n* Pclass la mayoria de gente son de tercera clase, de primera y de segunda hay mas o menos la misma cantidad de gente.\n* Age podemos observar que la mayoria de personas rondan entre los 20 y 30 a\u00f1os, y tiene una distribucion normal.\n* SibSp respecto a familiares vemos que la mayoria de personas han ido sin familiares del tipo hermanos, esposa o esposo, y tiene una distribucion normal que tiende a la derecha.\n* Parch en cuanto a padres o hijos tambien vemos que la mayoria de gentes ha ido sin padres o hijos, igual a SibSp tambien tiene una distribucion que tiende a la derecha.\n* Fare podemos  ver que la tarifa mayormente utilizada por la gente esta entre 5 y 14.9, podemos ver valores anomalos como el valor cercano a 500, aunque podria llegar a ser verdad, tambien tiene una distribucion normal que tiende a la derecha pero en este caso podemos encontrar algunos valores anomalos por la distancia a la distribucion normal, como los que van desde el 205 al 514.9.","8096745f":"# 5. Algoritmos de clasificaci\u00f3n","bcd93648":"Ahora vamos a ver la cantidad de ceros que tienen las variables de pima, y que no tendrian sentido estos resultados.\n\nGlucose, BloodPressure, SkinThickness, Insulin y BMI es imposible que tengan un valor 0 biologicamente y podria ser que los valores nulos han sido codificados como ceros en estos casos","80f32447":"Realizamos tambi\u00e9n una gr\u00e1fica por parejas en la que se nos muestra la relaci\u00f3n entre cada pareja de variables. Sin emabargo, resulta tan ca\u00f3tico al final, que es muy dif\u00edcil extraer ning\u00fan tipo de conclusi\u00f3n. Por ello, como en los conjuntos anteriores, vamos a utilizar una matriz de correlaci\u00f3n que nos muestre m\u00e1s claramente la relaci\u00f3n entre las variables.","13b811d6":"Repetimos el proceso para el conjunto Pima.","9b991af9":"Mostramos una gr\u00e1fica que nos indique el n\u00famero de valores nulos que tiene cada variable. Vemos claramente que cabin tiene una proporci\u00f3n enorme y age tiene una cantidad que no llega al 20%. Por tanto, deber\u00edamos eliminar cabin unicamente por la cantidad de valores nulos que tiene.","95d1ad1f":"Las variables predictoras de tipo mean y worst que presentan una distribuci\u00f3n normal:\n\n* radius_mean aunque es un poco asim\u00e9trica. No tiene ruido aunque tiene valores an\u00f3malos en 27 y 28.\n* texture_mean con un valor an\u00f3malo en 39.\n* perimeter_mean parece que sigue una distribuci\u00f3n normal aunque se encuentra algo asim\u00e9trica (aparentemente no tiene ning\u00fan valor an\u00f3malo).\n* smoothness_mean presenta un valor an\u00f3malo en 0.16.\n* symmetry_mean aparentemente no presenta ning\u00fan valor an\u00f3malo ni ruidoso.\n* fractal_dimension_mean presenta valores an\u00f3malos a partir de 0.09. No tiene valores ruidosos.\n* radius_worst con un valor an\u00f3malo en 36\n* texture_worst sin ning\u00fan valor an\u00f3malo ni ruidoso aparentemente.\n* perimeter_worst igual que perimeter_mean presenta una distribuci\u00f3n normal aunque se encuentra algo asim\u00e9trica. Tiene un valor an\u00f3malo en 250.\n* smoothness_worst tiene dos valores an\u00f3malos en 0.215 y 0.22.\n* symmetry_worst con bastantes valores an\u00f3malos a partir de 0.5.\n* fractal_dimension_worst con valores an\u00f3malos a partir de 0.14.\n\nA continuaci\u00f3n hablaremos sobre las variables que no representan distribuciones normales:\n\n* concave point_worst y concave point_mean: parecen una mixtura de distribuciones normales. Aparentemente no tienen valores an\u00f3malos ni ruidosos.\n* area_mean: es parecida a una distribuci\u00f3n normal pero no llega a serlo porque sus datos se encuentran balanceados hacia la izquierda. Tiene valores an\u00f3malos a partir de 2000.\n* area_worst: tiene una distribuci\u00f3n parecida a area_mean. Tiene un valor an\u00f3malo en 4200.\n* compactness_mean y compactness_worst: tambi\u00e9n tiene una distribuci\u00f3n balanceada hacia la izquierda. compactness_mean tiene valores an\u00f3malos a partir de 0.27 y compactness_worst a partir de 0.85.\n* concavity_mean y concavity_worst: tienen una distribuci\u00f3n como las anterior. concavity_mean tiene valores an\u00f3malos a partir de 0.4 y concavity_worst a partir de 1.\n\nEn las gr\u00e1ficas anteriores no se han encontrado valores ruidosos (no hab\u00eda valores que parecieran err\u00f3neos seg\u00fan el significado de la variable) por lo tanto, vamos a analizar las variables de tipo \"se\" (error estandar) para as\u00ed poder encontrar los valores ruidosos de las variables:\n\n* radius_se: hay nueve valores que se alejan de la distribuci\u00f3n de errores (a partir de 1.2). Estos valores los consideraremos como ruidosos.\n* texture_se: hay 14 valores ruidosos a partir de 2.5.\n* perimeter_se: tiene dos valores ruidosos a partir de 18.5.\n* area_se: tiene cuatro valores ruidosos a partir de 229.99.\n* smoothness_se: hay nueve valores ruidosos a partir de 0.015.\n* compactness_se: tiene 131 varios valores ruidosos a partir de 0.03\n* concavity_se : tiene 216 valores ruidosos a partir de 0.025.\n* concave points_se : tiene 105 valores ruidosos a partir de 0.015.\n* simmetry_se : tiene 19 valores ruidosos a partir de 0.036.\n* fractal_dimension_se : tiene 18 valores ruidosos a partir de 0.0085.\n\nPara analizar la cantidad de valores ruidosos y el umbral por el que consideramos que un valor es ruidoso hemos comparado gr\u00e1ficas de \"mean\" y \"se\" para ver los valores promedios. Por ejemplo como concavity tiene valores muy peque\u00f1os, el m\u00ednimo error estandar ya ocasiona que sea un valor ruidoso","4e5b271d":"En el caso de Pima resulta mucho m\u00e1s visible que en wisconsin, pero a\u00fan as\u00ed no somos capaces de tomar ninguna decisi\u00f3n sobre la base de datos partiendo de estas gr\u00e1ficas. \nPor tanto, hemos decidido utilizar otras funciones que describan mejor las variables para, despu\u00e9s de estudiarlas m\u00e1s profundamente, realizar una matriz de correlaci\u00f3n que nos muestre de forma sencilla cual es la relaci\u00f3n entre todas las variables.","10e986fd":"En el pairplot podemos ver que si dividimos los rangos en 5 hay partes donde encontraremos solo puntos azules en la izquierda y puntos rojos en la derecha de algunos diagramas.\nPor lo que decidimos que nuestro discretizador tendra 5 conjuntos.","b5d1de02":"La variable categorica podemos ver que toma valores enteros 1 y 0.","f64d984d":"En el caso de pima, no encontramos ninguna variable con valores nulos.","6f9080df":"El modelo de \u00e1rbol de decisi\u00f3n ofrece un rendimiento muy superior al Zero-R, ya que se trata de un algoritmo mucho m\u00e1s elaborado y utiliza de forma m\u00e1s eficiente los datos (con un 0,84 para wisconsin y un 0,59 para pima sin discretizadoy 0.75 en wisconsin y 0.56 en pima con el discretizado).Estos resultados no son los peores pero ni mucho menos los mejores dado que en ningun caso hemos llegado ni si quiera a una tasa de acierto del 90%, nosotros nos esperabamos que al utilizar el discretizado la tasa de acierto iba a mejorarpero al contrario esta empeoro en casi un 10% para cancer y en casi un 5% para diabetes.","807d4c05":"Sin embargo, en el modelo de \u00e1rbol de decisi\u00f3n discretizado no encontramos ninguna mejora, m\u00e1s que mejorar nos empeora los resultados, ya que obtenemos un 0.57. Seguramente esta influyendo el hecho de que los datos recibidos son bastante ca\u00f3ticos y no ofrecen muchas posibilidades a la hora de realizar una predicci\u00f3n.","efcc9e08":"Gracias a este mapa de calor, podemos ver de forma mucho m\u00e1s intuitiva cual es la correlaci\u00f3n entre las distintas variables. Nos interesa eliminar las que muestren una correlaci\u00f3n muy alta, ya que no aportan demasiada informaci\u00f3n y complican el proceso.\nPor ello, bas\u00e1ndonos en este mapa, podemos ver que hay algunas variables que tienen mucha correlaci\u00f3n y, por tanto, convendr\u00eda eliminar.","7a1e4718":"En esta primera pr\u00e1ctica, estudiaremos el proceso KDD siguiendo los pasos necesarios y comprendiendo tanto su utilidad como su correcta utilizaci\u00f3n. Los pasos que seguiremos son:\n* Carga de Datos\n* An\u00e1lisis Exploratorio\n* Preprocesamiento de datos\n* Validaci\u00f3n de los modelos\n\nAs\u00ed, cuando acabemos la pr\u00e1ctica, abremos utilizado dos bases de datos (Pima y Wisconsin), para comprender de forma m\u00e1s profunda el proceso de generaci\u00f3n, mejora y validaci\u00f3n de modelos.","149932b2":"### Discretizaci\u00f3n","09dabccb":"## Tree Model Pipelines","d7c258ad":"El n\u00famero de casos y variables (respectivamente) del conjunto de datos se puede obtener consultando el atributo `shape`:","a3fcc7b5":"## Pr\u00e1ctica 1: An\u00e1lisis exploratorio de datos, preprocesamiento y validaci\u00f3n de modelos de clasificaci\u00f3n\\*\n\n### Miner\u00eda de Datos: Curso acad\u00e9mico 2020-2021\n\n### Profesorado:\n\n* Juan Carlos Alfaro Jim\u00e9nez\n* Jos\u00e9 Antonio G\u00e1mez Mart\u00edn\n\n\\* Adaptado de las pr\u00e1cticas de Jacinto Arias Mart\u00ednez y Enrique Gonz\u00e1lez Rodrigo**\n\n### Alumnos:\n\n* Pablo Moreira Garcia\n* Ruben Martinez Sotoca","49fb51ff":"La otra base de datos que usaremos es la Pima Indians Database. Este conjunto de datos sirve para, partiendo de las variables que vemos a continuaci\u00f3n, predecir si una paciente sufre de diabetes o no.\n\n* `Glucose`: Concentraci\u00f3n de glucosa en plasma sangu\u00edneo de la paciente.\n* `Pregnancies`: N\u00famero de embarazos de la paciente.\n* `insulin`: Cantidad de insulina en sangre de la paciente (en mu Insulina\/ml).\n* `BloodPressure`: Presi\u00f3n diast\u00f3lica arterial de la paciente (en mm Hg).\n* `SkinThickness`: Grosor de la piel en el triceps de la paciente (en mm).\n* `DiabetesPedigreeFunction`: Funci\u00f3n del historial de diabetes en la familia del paciente.\n* `BMI`: \u00cdndice de Masa Corporal de la paciente (en kg\/m^2).\n* `Age`: Edad de la paciente.\n\nEstudiando las variables, se obtiene un diagn\u00f3stico que se almacena en `Outcome` con el valor 0 o 1. Si el valor es 1, la paciente tiene diabetes y si es 0, no tiene.","3c0c57c5":"### Algoritmo *Zero-R*","2a76f144":"Ahora que conocemos un poco m\u00e1s en detalle las caracter\u00edsticas de las variables, vamos a proceder a representarlas gr\u00e1ficamente. Debemos tener en cuenta los distintos tipos de gr\u00e1ficas para los distintos tipos de variables:\n* Los histogramas sirven para mostrar la distribuci\u00f3n de variables num\u00e9ricas.\n* Los gr\u00e1ficos de barras muestran la proporci\u00f3n en los valores de una variable categ\u00f3rica.","607da2fc":"Volvemos a unir las variables predictoras y las variables clase ya que lo necesitaremos para poder visualizar esta informacion con diferentes graficas a lo largo de la practica, lo hacemos ahora para no tener que ir uniendolas cada vez que nos haga falta y poder facilitar el analisis exploratorio de datos.","68744a97":"Volvemos a unir tambi\u00e9n los dos subconjuntos de test que hab\u00edamos separado para poder volver a trabajar con el conjunto completo.","acec0666":"Eliminamos Nombre, Ticket, Cabin y Fare porque son datos innecesarios para saber si sobrevivieron los pasajeros. y Por el numero de valores nulos que tiene Cabin.","c1ec13ab":"El modelo Zero-R obtiene resultados nulos, al igual que los dos realizados anteriormente con las otras bases de datos. Al igual que anteriormente explicado esto se bebe a que siempre elige la opcion mayoritaria aunque no sea la correcta.","e80e1c4d":"Con discretizador","6bd955b5":"Una vez tenemos los intervalos de valores para las variables, creamos transformadores para suavizar los valores anomalos:","912b9d58":"El algoritmo CART es el acr\u00f3nimo de Classification And Regression Trees. Con este algoritmo, se generan \u00e1rboles de decisi\u00f3n binarios, lo que quiere decir que cada nodo se divide en exactamente dos ramas.\n\nEste modelo admite variables de entrada y de salida nominales, ordinales y continuas, por lo que se pueden resolver tanto problemas de clasificaci\u00f3n como de regresi\u00f3n.","1f16db0d":"Una vez hemos introducido los datos, utilizando la funci\u00f3n sample (que muestra un conjunto aleatorio de filas), podemos comprobar que se han introducido correctamente.","1e7ae34f":"Podemos ver ahora el n\u00famero de variables que hay y su tipo.","502870ca":"En este paso nos vamos a centrar en las caracter\u00edsticas de cada conjunto de datos, estudiando sus variables, los valores que toman y las relaciones que se puedan apreciar de ellas. Para facilitar este estudio, vamos a recurrir a varias funciones gr\u00e1ficas que muestren la informaci\u00f3n de forma m\u00e1s visual.","0d5e6419":"Continuamos visualizando las variables categ\u00f3ricas del problema:","8fe8baba":"A continuaci\u00f3n, utilizando un pair_plot, podemos realizar una gr\u00e1fica por parejas en la que comparamos todas las variables por parejas:","efaff6a7":"### Visualizaci\u00f3n de las variables"}}