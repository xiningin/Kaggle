{"cell_type":{"3c0a6358":"code","9858c05a":"code","9bc620d2":"code","06b9a9d6":"code","7a94c072":"code","13f0bf2c":"code","766cf50c":"code","ee909a84":"code","74397e7a":"code","a0611655":"code","13dc5bbd":"code","aa5106be":"code","71d56066":"code","64ffb5b9":"code","aa7d40b2":"code","c539a09d":"code","11e1dcb1":"code","a09b3dcc":"code","baf97377":"code","d97b8dce":"code","e02fafbb":"code","54bf9fa8":"code","74fc2978":"code","14266819":"code","675b651d":"code","f6d9e0f4":"code","2f1138fa":"code","3dc55b89":"code","0139af4f":"code","0ba9fd9a":"code","ba506d8b":"code","6916a338":"code","87b517ed":"code","44ce8f76":"markdown","0482067b":"markdown","bdc9b25f":"markdown","bb966902":"markdown","97397939":"markdown","4a1c4367":"markdown","dde4ae17":"markdown","d7831eef":"markdown","2df20bbf":"markdown","3d75d43d":"markdown","9ddc211a":"markdown","1aebcff0":"markdown","c141085d":"markdown","e5252ab1":"markdown","fd211117":"markdown","a0c177d7":"markdown","a29d13da":"markdown","5a4ec194":"markdown","eec076ed":"markdown","3b803cae":"markdown","9fdb387d":"markdown","5d8a32a7":"markdown","a391dc22":"markdown","f0698817":"markdown","71eaa0f7":"markdown","58607354":"markdown","9bbd55fb":"markdown","401cd1e0":"markdown","fbcd8e2a":"markdown","3bcc817d":"markdown","dde07bd2":"markdown","36dfb50a":"markdown","8c4f2425":"markdown","f3314357":"markdown","befff65a":"markdown","47aa05d8":"markdown","08bb498f":"markdown","85482ad0":"markdown"},"source":{"3c0a6358":"#importing libraries \nimport os \nimport pandas as pd  \nimport numpy  as np\nimport matplotlib.pyplot as plt # ploting\nfrom collections import Counter\nimport math \n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"ticks\")\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.preprocessing import MinMaxScaler , StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(\"Packages Imported \")","9858c05a":"train_data = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsample     = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","9bc620d2":"#quick look at the train data\ntrain_data.head(5).style.set_properties(**{'background-color': 'white',\n                           'color': 'darkblue',\n                           'border-color': 'dark'})","06b9a9d6":"print(f'Number of rows: {train_data.shape[0]};  Number of columns: {train_data.shape[1]}; No of missing values: {sum(train_data.isna().sum())}')","7a94c072":"print(\"number of misssing values by feature\")\ntrain_data.isnull().sum().sort_values(ascending = False)","13f0bf2c":"print('Info about the train data: ')\nCounter(train_data.dtypes.values)\n","766cf50c":"train_data.describe().style.background_gradient(cmap='coolwarm')","ee909a84":"# variables variaition \ntrain_data.var()\n#Standard  deviation  \ntrain_data.std()","74397e7a":"# Correlationmatrix\ncorrMatrix =train_data.corr(method='pearson', min_periods=1)\ncorrMatrix","a0611655":"corr_targ = train_data.corrwith(train_data[\"claim\"])\ncorr_targ ","13dc5bbd":"print('percentage of claim values:')\npercent_value = pd.DataFrame(train_data['claim'].value_counts()\/len(train_data))\npercent_value.T","aa5106be":"# visualization \ncountplt, ax = plt.subplots(figsize = (8,5))\nax =sns.countplot(train_data['claim'],palette=\"husl\")","71d56066":"test_data.head(5).style.set_properties(**{'background-color': 'white',\n                           'color': 'darkblue',\n                           'border-color': 'dark'}) # head ","64ffb5b9":"print(f'Number of rows: {test_data.shape[0]};  Number of columns: {test_data.shape[1]}; No of missing values: {sum(test_data.isna().sum())}')","aa7d40b2":"print('Info about test data: ')\ntest_data.info()","c539a09d":"test_data.describe().style.background_gradient(cmap='YlOrRd')","11e1dcb1":"features = train_data.iloc[:,1:119] # loc features \ni = 1\nplt.figure()\nfig, ax = plt.subplots(9,6,figsize=(28, 28))\nfor feature in features:\n    plt.subplot(24, 5,i)\n    sns.distplot(train_data[feature],color=\"blue\", kde=True,bins=120, label='train')\n    sns.distplot(test_data[feature],color=\"orange\", kde=True,bins=120, label='test')\n    i += 1\nplt.show()","a09b3dcc":"# copy of datasets\nX_train_stand =  train_data.iloc[:,1:119]\nX_test_stand  = test_data.drop (['id'], axis=1)\nnum_cols = X_train_stand.columns\nfor i in num_cols:\n    scale = StandardScaler()\n    X_train_stand[i] = scale.fit_transform(X_train_stand[[i]])\n    X_test_stand[i] = scale.transform(X_test_stand[[i]])\n    \n# adding claim column back \nX_train_stand[\"claim\"] = train_data[\"claim\"]","baf97377":"imp=SimpleImputer(missing_values=np.NaN, strategy='mean')\ntrain_df=pd.DataFrame(imp.fit_transform(train_data))\ntest_df=pd.DataFrame(imp.fit_transform(test_data))\ntrain_df.columns=train_data.columns\ntrain_df.index=train_data.index\ntest_df.columns=test_data.columns\ntest_df.index=test_data.index\nprint(\"Missing values imputed by sklearn simpleimputer with MEAN strategy..\")","d97b8dce":"# train a basic RF classifier \nrf = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=42)\nrf.fit(train_df.drop(['id', 'claim'],axis=1), train_df.claim)\nprint(\"Training Done\" )","e02fafbb":"#this snapCode comes from this notbook (https:\/\/www.kaggle.com\/arthurtok\/interactive-porto-insights-a-plot-ly-tutorial)\nfeatures = train_df.drop(['id', 'claim'],axis=1).columns.values\ntrace = go.Scatter(\n    y = rf.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        color = rf.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Random Forest Feature Importance',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","54bf9fa8":"#install_packages \nimport h2o\nfrom h2o.automl import H2OAutoML \nh2o.init() # h2o initialization ","74fc2978":"##  just add a new feature consisting of number of nan values in each row.\n###check this discussion for more ( https:\/\/www.kaggle.com\/c\/tabular-playground-series-sep-2021\/discussion\/270206)\n#train_data[\"nan_count\"] = train_data.isnull().sum(axis=1)\n#test_data[\"nan_count\"]  = test_data.isnull().sum(axis=1)","14266819":"train= h2o.H2OFrame(train_data) # convert to h2o frame\ntest = h2o.H2OFrame(test_data) # convert to h2o frame ","675b651d":"x = train.columns \ny = \"claim\" # target \nx.remove(y) # # X_train \ntrain[y] = train[y].asfactor() #binary classification ","f6d9e0f4":"auto_ml = H2OAutoML( \n    nfolds=5, # use 5 folds \n    seed = 1222,\n    max_models = 10,\n    include_algos = [\"XGBoost\" ,\"StackedEnsemble\",\"GBM\"],\n    max_runtime_secs=3600*2,  #time in sec , if set to much high value may give high score around 0.80...\n    stopping_metric='AUC'\n    )\nauto_ml.train(x=x, y=y, training_frame=train)\n","2f1138fa":"# check leaderboard\nleader = auto_ml.leaderboard\nleader","3dc55b89":"model = h2o.get_model(leader[2,\"model_id\"]) # get gbm model \nmodel.varimp_plot()","0139af4f":"mc_plot = auto_ml.model_correlation_heatmap(train)","0ba9fd9a":"learning_curve_plot = model.learning_curve_plot()","ba506d8b":"preds = auto_ml.leader.predict(test)","6916a338":"## create submission\nsubmission = pd.DataFrame({\n    'id': test['id'].as_data_frame().id,\n    'claim': preds.as_data_frame().predict\n})\nsubmission.head()","87b517ed":"# save submission\nsubmission.to_csv('h2o_submission.csv', index=False)","44ce8f76":"**Correlation with  target** \n<p> let's check whar features are more correlated to target.","0482067b":"## About the data \nThe dataset  used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting whether a claim will be made on an insurance policy. Although the features are anonymized, they have properties relating to real-world features. the data contain three files :  \n* train.csv - the training data with the target claim column\n* test.csv - the test set; you will be predicting the claim for each row in this file\n* sample_submission.csv - a sample submission file in the correct format   ","bdc9b25f":"**Check leaderboard**","bb966902":"**Feature Importance**","97397939":"**Basic summary statistic for test data.**","4a1c4367":"### Data Standardization\nBesides tree-based models, Data scaling is well recommended specially when working with neural networks.","dde4ae17":"<div class=\"alert alert-success\">\n    <h1 align=\"center\">Overview<\/h1>\n<\/div>","d7831eef":"## Feature Selection\nIn order to conduct feature selction we are going to train a basic random forest classifier and the plot it's feature importance.","2df20bbf":"**Prepare data**","3d75d43d":"![Capture.JPG](attachment:5eaac67a-4366-4169-901b-92e00ed1ed0d.JPG)","9ddc211a":"**Correlation matrix**\n<p> let's check the features correlation matrix.\n","1aebcff0":"Almost equal counts but we kinda have more zeros than ones xD.","c141085d":"### Basic EDA to better know the data \nWe first take a look at our dataframes ( train and test ). after that we will make predictions for the test data.","e5252ab1":"**Model Correlation Heatmap**\n","fd211117":"<div class=\"alert alert-success\">\n  <h2><center>  I hope you find this useful , Thank you \ud83d\ude4f <\/h2><\/center>\n<\/div>\n","a0c177d7":"### Generate Prediction","a29d13da":"\n Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, Kaggle have launched many Playground competitions that are more approachable than Featured competition, and thus more beginner-friendly.\n    \n  For this competition, we will predict whether a customer made a claim upon an insurance policy. The ground truth claim is binary valued, but a prediction may be any number from 0.0 to 1.0, representing the probability of a claim.","5a4ec194":"**Features Variation**","eec076ed":"From here we can select some \"Golden features \" and start our training with those predictors.at the first look we can select up to 17 features as a start.","3b803cae":"The train dataset has 957919 of rows with 120 of columns and there are 1820782 missing values ( that's bad :\/). we can continue for now.","9fdb387d":"#### Feature Distribution ( train \/test data )","5d8a32a7":"**Install Packages**","a391dc22":"**Learning Curve Plot**","f0698817":"**Train AutoML**","71eaa0f7":"**Target Column**\n<p> The target [\"claim\"] for this competition which we are predicting is binary valued,.","58607354":"## AutoML and Submission \nWe are going to use athen autoMl library called  H2o Which is an automated machine learnin povided by H2o.ai .and you can check[ Documentation here](https:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/automl.html)","9bbd55fb":"**Basic summary statistic**\n","401cd1e0":"The test dataset has 493474 of rows with 119 of columns and there is 936218 missing values. we can continue for now. ","fbcd8e2a":"**Plotly Scatter Plot of feature importances**\n","3bcc817d":"**Quick look at the Test dataset**","dde07bd2":"# Load the data ","36dfb50a":"**Dealing with missing values** ","8c4f2425":"<center> <h1> Tabular Playground Series - Sep 2021 <center><h1> \n","f3314357":" ## Note: \n   <strong>This is just a starter where a lot of improvement can be made.You may look deeper into the data .for prediction you can always expriment with other techniques,models and frameworks...","befff65a":"**Quick look at the Train Data**","47aa05d8":"**Train a basic RF classifier**","08bb498f":"We can see that Train and test data are quite similar.","85482ad0":"![Capture.JPG](attachment:7c2cc9ea-22ee-4c82-9ee0-616220b46d46.JPG)"}}