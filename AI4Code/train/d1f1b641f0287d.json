{"cell_type":{"9d595078":"code","8d8fcf84":"code","883cea0d":"code","c3544202":"code","6636515f":"code","0de9278e":"code","3b9cdf62":"code","de9a962f":"code","148ebd63":"code","f01231cb":"code","4ed3493b":"code","d21bb7fa":"code","29344e72":"code","ba85e887":"code","89fa59a5":"code","f948942a":"code","f612404a":"markdown","e1f0aa1a":"markdown","028f5a55":"markdown","8a48e4c9":"markdown","85c3e331":"markdown","b05603ed":"markdown","2b3999e8":"markdown"},"source":{"9d595078":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8d8fcf84":"df = pd.read_csv('..\/input\/BreadBasket_DMS.csv')\ndf.head()","883cea0d":"df.info()","c3544202":"df['datetime'] = pd.to_datetime(df['Date']+' '+ df['Time'])\ndf['day_of_week'] = df['datetime'].dt.day_name()","6636515f":"total_items = df['Transaction'].count()\nunique_transactions = df['Transaction'].nunique()\n\nitems_per_transaction = total_items \/ unique_transactions\nprint(total_items, unique_transactions,items_per_transaction)","0de9278e":"new_df = pd.pivot_table(df, values='Transaction', columns='day_of_week', aggfunc=('count','nunique')).transpose().reset_index()\nnew_df = new_df.sort_values(by='count', ascending=False)","3b9cdf62":"total_items_by_weekday = df['day_of_week'].value_counts()\nprint(total_items_by_weekday.sort_values(ascending=False))","de9a962f":"unique_transactions_by_weekday = df.groupby('day_of_week')['Transaction'].nunique()\nprint(unique_transactions_by_weekday.sort_values(ascending=False))","148ebd63":"items_per_transaction_by_weekday = total_items_by_weekday \/ unique_transactions_by_weekday\nprint(items_per_transaction_by_weekday.sort_values(ascending=False))","f01231cb":"new_df.plot.bar('day_of_week')","4ed3493b":"df['Item'].value_counts().head(20)","d21bb7fa":"df['Item'].nunique()","29344e72":"list_of_items = df['Item'].unique().tolist()\nprint(list_of_items)","ba85e887":"df.set_index('datetime', inplace=True, drop=True)","89fa59a5":"df_ts = df.drop(['Date', 'Time', 'day_of_week', 'Item'], axis=1)\nweekly = df_ts.resample('W-MON').agg(['count', 'nunique'])\nweekly['Transaction'].plot(kind='line')","f948942a":"monthly = df_ts.resample('M').agg(['count', 'nunique'])\nmonthly['Transaction'].plot(kind='line')","f612404a":"**1. Load and examine data**","e1f0aa1a":"Broken down by day of the week we see that Saturday is our best day both for total items sold and transactions, but we're selling slightly more items per transaction on a Sunday.","028f5a55":"But what are our bestseller? Unsurprisingly, it's coffee and bread, followed by tea and cake! But our little bakery sells a lot of things - 95 different items, to be precise.","8a48e4c9":"**2. Data Exploration**\n\nOK, let's start having a closer look at the data! We've sold a total of 21,293 items in 9,531 transactions. That's 2.2 items per transaction.","85c3e331":"A quick look at the data table shows that the Item column has quite a few values listed as NONE - leaving this in for now as it still contributes to transactions under the assumption that it was an item of some kind.","b05603ed":"Creating a datetime column and a column to show the day of the week.","2b3999e8":"**3. Time series analysis**\n\nFinally, let's have a look at the bakery's transactions over time. It looks like the bakery had a really good launch week and then transactions trailed off, hitting a low beginning of January (maybe due to the bakery being close over the Christmas\/NY period?) and then business picked up again."}}