{"cell_type":{"f04bdc0c":"code","4baec249":"code","4c3d4bfb":"code","afb3c66c":"code","ff716fad":"code","a7219935":"code","6cb2a97a":"code","0c7b79f2":"code","97ea2c45":"code","4f0ad4b0":"code","d21716c1":"code","a32c1a22":"code","9541e470":"code","e0d1fd20":"code","7d8abef4":"code","fc82195c":"code","7a734828":"code","4e4dbd68":"code","f444d933":"code","0fb1c16b":"code","5a653c9b":"code","a712650f":"code","1f9284d0":"code","450b60d6":"code","4343b1ef":"code","dc4c268f":"code","7855310e":"code","022a1089":"code","70710413":"code","f0eee050":"code","86f5efac":"code","bf8d9d3d":"markdown","516ef6c4":"markdown","061601b1":"markdown","206c0287":"markdown","2a0cc74d":"markdown","fe62028f":"markdown","8a181fab":"markdown","e7a9fd6b":"markdown","58e10d31":"markdown","dc175612":"markdown","b5a6c65f":"markdown","6907c887":"markdown","0a4f8957":"markdown","56092481":"markdown","4cb06143":"markdown","2599b29b":"markdown","805ee3e1":"markdown","ab2b13ff":"markdown"},"source":{"f04bdc0c":"import torch\ncuda_version_major = int(torch.version.cuda.split('.')[0])\n\n!wget https:\/\/raw.githubusercontent.com\/airctic\/icevision\/master\/icevision_install.sh\n!bash icevision_install.sh cuda11\n!pip install torchtext==0.11.0 --upgrade\n\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(True)","4baec249":"import os\nimport shutil\n\nfrom kaggle_secrets import UserSecretsClient\nimport copy \nimport time\n\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\n\nimport numpy as np\nimport ast\n\nimport cv2\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport torch\nfrom icevision.all import *\n\nimport wandb\n\nfrom colorama import Fore, Back, Style\n\nfrom IPython.display import IFrame\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')","4c3d4bfb":"TRAIN_PATH = \"..\/input\/tensorflow-great-barrier-reef\/train_images\"\nHEIGHT, WIDTH = 720, 1280\nimage_size = 640","afb3c66c":"def get_files(path):\n    vid_ls = [os.path.join(path,f) for f in os.listdir(path)]\n    return sorted(vid_ls, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))","ff716fad":"vid_paths = [\n    f'{TRAIN_PATH}\/video_0',\n    f'{TRAIN_PATH}\/video_1',\n    f'{TRAIN_PATH}\/video_2',\n]\n\nfiles_ls = [get_files(vid_path) for vid_path in vid_paths]\nlen(files_ls)\n\ntrain_df = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/train.csv\")","a7219935":"train_df","6cb2a97a":"def get_oldpath(x):\n    return os.path.join(vid_paths[x.video_id], f'{str(x.video_frame)}.jpg')\n\ndef get_newpath(x):\n    filename = f\"{x.video_id}_{x.video_frame}.jpg\"\n    return os.path.join(\".\/dataset\", filename)\n\ndef get_filename(x):\n    return f\"{x.video_id}_{x.video_frame}.jpg\"","0c7b79f2":"# annotation \uc989 \ub808\uc774\ube14\uc774 \uc788\ub294 \uac83\ub4e4\ub9cc\uc73c\ub85c \ucd94\ub9b0\ub2e4 (\ud559\uc2b5\uc6a9 \uc774\ub2c8\uae4c)\ntrain_df = train_df[train_df.annotations != \"[]\"]\n\n# annotation \uc815\ubcf4\ub294 \ubb38\uc790\uc5f4\uc774\ub2e4 (\uc608\uc2dc.\"[{'x': 559, 'y': 213, 'width': 50, 'height': 32}]\")\n# \uc774\ub97c \ud30c\uc774\uc36c \uac1d\uccb4\ub85c \ubcc0\ud658\ud558\ub294 \ubc29\ubc95 \uc911 \ud558\ub098\ub85c ast.literal_eval \uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub2e4.\ntrain_df[\"annotations\"] = train_df[\"annotations\"].map(lambda x : ast.literal_eval(x))\n\n# DataFrame\uc758 apply \ub294 \ub808\ucf54\ub4dc\ubcc4\ub85c \uc9c0\uc815\ub41c \ud568\uc218\ub97c \uc801\uc6a9\ud55c \ub4a4, \uc804\uccb4\uac00 \uc801\uc6a9\ub41c \uc0c8\ub85c\uc6b4 DataFrame\uc744 \ubc18\ud658\ud55c\ub2e4.\n# filepath\ub294 \uc2e4\uc81c \ud30c\uc77c\uc774 \uc800\uc7a5\ub41c \uc704\uce58 (\uc6d0\ubcf8)\n# newpath\ub294 \uc6d0\ubcf8 \ud30c\uc77c\uc744 \ubcf5\uc0ac\ud574 \uc62e\uaca8\ub193\uc744 \uc704\uce58 (\ubcf5\uc0ac\ubcf8)\n# filename\uc740 \ub2e8\uc21c\ud788 \ud30c\uc77c\uc774\ub984\ntrain_df[\"filepath\"] = train_df.apply(lambda x : get_oldpath(x), axis=1)\ntrain_df[\"newpath\"] = train_df.apply(lambda x : get_newpath(x), axis=1)\ntrain_df[\"filename\"] = train_df.apply(lambda x : get_filename(x), axis=1)\n\nos.makedirs(\".\/dataset\",exist_ok=True)\n\nfor i in tqdm(range(len(train_df))):\n    src = train_df.iloc[i][\"filepath\"]\n    dst = train_df.iloc[i][\"newpath\"]\n    shutil.copy(src,dst)\n    \ntrain_df.head(2)","97ea2c45":"train_df.iloc[0:2].explode('annotations').apply(lambda x : x.annotations[\"x\"], axis=1)","4f0ad4b0":"df = train_df\n\n# DataFrame\uc758 explode \uba54\uc11c\ub4dc\ub294 \ub9ac\uc2a4\ud2b8\ub97c \ud480\uc5b4\ud5e4\uce5c\ub2e4\n# [{'x': 559, 'y': 213, 'width': 50, 'height': 32}] => {'x': 559, 'y': 213, 'width': 50, 'height': 32}\ndf = df.explode(\"annotations\")\n\n# \ubaa8\ub4e0 \uc774\ubbf8\uc9c0\uc758 \ud06c\uae30(\ub192\uc774 \ub108\ube44), \ub808\uc774\ube14\uc774 \ubaa8\ub450 \ub3d9\uc77c\ud558\ub2e4\n# \uc5d1\uc140\uc5d0\uc11c \ub4dc\ub798\uadf8\ub85c \uc8fc\ub8e8\ub8e9 \uac19\uc740 \uac1a\uc744 \ucc44\uc6cc\ub123\ub294\uac83 \uac19\uc740 \uc77c\ndf[\"width\"] = [WIDTH]*len(df)\ndf[\"height\"] = [HEIGHT]*len(df)\ndf[\"label\"] = [\"starfish\"]*len(df)\n\n# annotation\uc5d0 \ub2f4\uae34 x, y, width, height \ub300\uc2e0, \n# \uac1d\uccb4\ud0d0\uc9c0\uc5d0\uc11c \uc77c\ubc18\uc801\uc73c\ub85c \uc0ac\uc6a9\ub418\ub294 xmin, ymin, xmax, ymax \uc6a9\uc5b4\uc640 \uc54c\ub9de\uc740 \uac12\uc73c\ub85c \ub300\uccb4\ud55c\ub2e4\ndf[\"xmin\"] = df.apply(lambda x : x.annotations[\"x\"], axis=1)\ndf[\"ymin\"] = df.apply(lambda x : x.annotations[\"y\"], axis=1)\ndf[\"xmax\"] = df.apply(lambda x : x.annotations[\"x\"]+x.annotations[\"width\"], axis=1)\ndf[\"ymax\"] = df.apply(lambda x : x.annotations[\"y\"]+x.annotations[\"height\"], axis=1)\n\n# \ubc14\uc6b4\ub529\ubc15\uc2a4\uc758 \uc6b0\uce21 \ud558\ub2e8 \uc88c\ud45c\uac00 \n# \uc774\ubbf8\uc9c0\uc758 \uc6b0\uce21 \ud558\ub2e8 \ubaa8\uc11c\ub9ac\ub97c \ubc97\uc5b4\ub098\ub294 \uacbd\uc6b0\ndf.loc[df[\"xmax\"] > 1280, \"xmax\"] = 1280\ndf.loc[df[\"ymax\"] > 720, \"ymax\"] = 720\n\n# \uac1d\uccb4 \ud0d0\uc9c0\uc5d0 \ubd88\ud544\uc694\ud55c \uc5f4\uc740 \uc81c\uac70\ud55c\ub2e4\ndf = df.drop([\"video_id\",\"sequence\",\"video_frame\",\"sequence_frame\",\"image_id\",\"annotations\",\"filepath\",\"newpath\"], axis=1)\ndf = df.reset_index(drop=True)\ndf.head(3)","d21716c1":"# Check https:\/\/www.kaggle.com\/debarshichanda\/pytorch-w-b-pawpularity-training for more details\n\n# \uc774 \uc139\uc158\uc740 \ud559\uc2b5\uc6a9 \ub370\uc774\ud130\uc14b\uc744 W&B \ub300\uc2dc\ubcf4\ub4dc\uc5d0\uc11c \uc2dc\uac01\ud654\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc900\ub2e4.\n# \n# 1. W&B\uc758 API \ud0a4\ub97c \ubc1c\uae09 \ubc1b\ub294\ub2e4\n# 2. Add-ons => Secrets \uba54\ub274\ub97c \ud1b5\ud574, wandb_api \ub77c\ub294 \ud0a4\uc5d0 W&B API\uac12\uc744 \ud560\ub2f9\ud55c\ub2e4\n# 3. \uc544\ub798 \ucf54\ub4dc\ub97c \uc2e4\ud589\ud55c\ub2e4.\n\ntry:\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=api_key)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('''If you want to use your W&B account, Follow these steps :\n            -> go to Add-ons {Below name of notebook} -> Secrets -> Add a new Secret\n            -> Label = wandb_api\n            -> Value = W&B access token from https:\/\/wandb.ai\/authorize \n         ''')","a32c1a22":"WANDB_CONFIG = {\n   \"project_name\"    : \"Protect Great Barrier Reef\",\n   \"group_name\"      : \"IceVision Training\",\n   \"job_type_data\"   : \"Data Visualization\",\n   \"job_type_train\"  : \"Training\",\n   \"anonymity\"       : \"must\",\n   \"artifact\"        : \"training_data\"\n}\n\nrun = wandb.init(\n    project = WANDB_CONFIG[\"project_name\"],\n    group = WANDB_CONFIG[\"group_name\"],\n    job_type = WANDB_CONFIG[\"job_type_data\"],\n    anonymous= WANDB_CONFIG[\"anonymity\"]\n)","9541e470":"# \ub514\uc2a4\ud50c\ub808\uc774\ub420 \ud14c\uc774\ube14\uc758 \uc5f4\uc744 \uc815\uc758\ud55c\ub2e4\nwb_table = wandb.Table(columns = [\n    \"filename\", \"Image\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"\n])\n\n# \ud559\uc2b5\uc6a9 \ub370\uc774\ud130 \uc911 \ucc98\uc74c 100\uac1c\uc5d0 \ub300\ud574\uc11c tqdm \ud55c\ub2e4\nfor i in tqdm(range(len(df))[:100]):\n    row = df.loc[i]\n    impath = os.path.join(\".\/dataset\",row[\"filename\"])\n    im = PIL.Image.open(impath)\n    bbox = [{\n            \"position\": {\n                \"minX\": int(row['xmin']),\n                \"maxX\": int(row[\"xmax\"]),\n                \"minY\": int(row[\"ymin\"]),\n                \"maxY\": int(row[\"ymax\"])\n            },\n            \"class_id\": 1,\n            \"box_caption\": \"starfish\",\n            \"domain\": \"pixel\"\n        }]\n    \n    # \uc774\ubbf8\uc9c0\ub294 wandb.Image \uac1d\uccb4 \ud615\ud0dc\uac00 \ub418\uc5b4\uc57c\ud55c\ub2e4.\n    # \ubcf4\ub2e4\uc2dc\ud53c PIL\uc758 Image \ud615\uc2dd\uc744 \uadf8\ub300\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc73c\uba70,\n    # boxes \ubc0f classes \ub77c\ub294 \ucd94\uac00 \ud30c\ub77c\ubbf8\ud130\ub97c \uc124\uc815\ud558\uba74 \uc774\ubbf8\uc9c0\ub0b4 \uac1d\uccb4 \uc704\uce58 \ubc0f \ubc94\uc8fc\ub97c \uacb0\uc815\ud574 \ubcf4\uc5ec\uc904 \uc218 \uc788\ub2e4.\n    image = wandb.Image(im,\n                        boxes = {\n                            \"ground_truth\": {\n                                \"box_data\": bbox,\n                                \"class_labels\" : {1: 'starfish'}\n                            }\n                        },\n                        classes = [{\"id\": 0, \"name\": \"background\"}, {\"id\": 1, \"name\": \"starfish\"}]\n                    )\n    \n    # \uc785\ub825\ub41c \ub370\uc774\ud130\uac00 \uc900\ube44\ub418\uc5c8\uc73c\uba74,\n    # \ud14c\uc774\ube14\uc758 \ud589 \ub370\uc774\ud130\ub85c \ucd94\uac00\ud55c\ub2e4\n    wb_table.add_data(row['filename'],\n                      image,\n                      row[\"xmin\"],\n                      row[\"ymin\"],\n                      row[\"xmax\"],\n                      row[\"ymax\"]\n                     )\n    \nwandb.log({'Data Visualization': wb_table})\nrun.finish()","e0d1fd20":"# \uc9c1\uc811 W&B \ub300\uc2dc\ubcf4\ub4dc\uc5d0\uc11c \ud655\uc778\ud574\ub3c4 \ub418\uc9c0\ub9cc,\n# \uc544\ub798 \uba85\ub839\uc744 \uc218\ud589\ud558\uba74 IFrame\uc73c\ub85c W&B \ub300\uc2dc\ubcf4\ub4dc \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc8fc\ud53c\ud130 \ub178\ud2b8\ubd81\ub0b4 \ucd9c\ub825\ud55c\ub2e4\nframe = IFrame(run.url, width=1280, height=720)\nframe","7d8abef4":"train_report = ProfileReport(df,title=\"Metadata of Training images\")\ntrain_report.to_file(\".\/train_metadata.html\")\ntrain_report","fc82195c":"# \uac1d\uccb4 \ud0d0\uc9c0\ub97c \uc704\ud55c \ub808\ucf54\ub4dc\ub294 ObjectDetectionRecord \uac1d\uccb4\ub85c \ud45c\ud604\ub41c\ub2e4.\n# Parser.generate_template \uba54\uc11c\ub4dc\ub294 \ub808\ucf54\ub4dc \uac1d\uccb4\ub97c \ub9cc\ub4e4\uae30 \uc704\ud574 \ud544\uc694\ud55c \uae30\ubcf8 \ud15c\ud50c\ub9bf\uc744 \ucd9c\ub825\ud55c\ub2e4.\ntemplate_record = ObjectDetectionRecord()\nParser.generate_template(template_record)","7a734828":"\n# \ubcf4\ub2e4\uc2dc\ud53c \uc704\uc5d0 \ucd9c\ub825\ub41c MyParser \ud15c\ud50c\ub9bf\ucf54\ub4dc\ub97c \uadf8\ub300\ub85c \uac00\uc838\uc628 \ub2e4\uc74c, \uac01 \uba54\uc11c\ub4dc\ub97c \uad6c\ud604\ud558\uc600\ub2e4\nclass PGBRParser(Parser):\n    def __init__(self, template_record, data_dir, df):\n        super().__init__(template_record=template_record)\n\n        self.data_dir = data_dir\n        self.df = df\n        self.class_map = ClassMap(list(self.df['label'].unique()))\n\n    # \uac01 \ub370\uc774\ud130 \ub808\ucf54\ub4dc(\ud589)\uc744 \uc774\ud130\ub808\uc774\uc158\ud558\uace0, \n    # \uac01 \uc774\ud130\ub808\uc774\uc158 \ub9c8\ub2e4 \ubc18\ud658\ud560 \uac1d\uccb4\ub97c \uc815\uc758\ud55c\ub2e4\n    def __iter__(self) -> Any:\n        for o in self.df.itertuples():\n            yield o\n\n    def __len__(self) -> int:\n        return len(self.df)\n\n    # \uc720\ub2c8\ud06c ID \ud560\ub2f9\uc5d0 \uc0ac\uc6a9\ub420 \uc218 \uc788\ub294 \uc815\ubcf4\ub97c \ubc18\ud658\ud55c\ub2e4.\n    # \uc5ec\uae30\uc11c o\ub294 __iter__\uac00 \uc774\ud130\ub808\uc774\uc158\ub9c8\ub2e4 \ubc18\ud658\ud558\ub294 \uac1d\uccb4\ub97c \uc758\ubbf8\ud55c\ub2e4\n    def record_id(self, o) -> Hashable:\n        return o.filename\n\n    # \uc5ec\uae30\uc11c o\ub294 __iter__\uac00 \uc774\ud130\ub808\uc774\uc158\ub9c8\ub2e4 \ubc18\ud658\ud558\ub294 \uac1d\uccb4\ub97c \uc758\ubbf8\ud55c\ub2e4\n    #\n    # \ubcf4\ub2e4\uc2dc\ud53c is_new \ub77c\ub294 \uc778\uc790\uac00 \uc874\uc7ac\ud55c\ub2e4. \uc0ac\uc9c4 \ud55c \uc7a5\uc5d0 \uc5ec\ub7ec \ubb3c\uccb4\uac00 \uae30\ub85d\ub418\uc5b4 \uc788\uc744 \uc218 \uc788\ub2e4.\n    # DataFrame \ud589\uc744 \ud558\ub098\uc529 \ud0d0\uc0c9\ud558\ub2e4\uac00 \ub3d9\uc77c\ud55c \uc774\ubbf8\uc9c0 \uc774\ub984\uc744 \uac00\uc9c4 \ub808\ucf54\ub4dc(\ud589)\uc774 \ub610 \ub2e4\uc2dc \ubc1c\uacac\ub41c\ub2e4\uba74 \uc774\ub97c \uac19\uc740 \ub808\ucf54\ub4dc\ub85c \uac04\uc8fc\ud55c\ub2e4 (record_id\uc5d0\uc11c \uc218\ud589)\n    # \uadf8\ub9ac\uace0 record.detection.add_bboxes, record.detection.add_labels\uc5d0 \ucd94\uac00 bbox \ubc0f \ub808\uc774\ube14\uc744 \uae30\ub85d\ud574 \ub123\ub294\ub2e4.\n    # is_new\ub294 \uc9c0\uae08\uae4c\uc9c0 \ubcf8 \uc801 \uc5c6\ub294 record_id\uac00 \ubc1c\uacac\ub418\uc5c8\uc744 \ub54c\ub9cc \uc218\ud589\ud55c\ub2e4.\n    #\n    # \uc774 \ub0b4\uc6a9\uc73c\ub85c \ubbf8\ub8e8\uc5b4 \ubcf4\uba74, \ud559\uc2b5 \ub370\uc774\ud130\uc758 \uc785\ub825\uc778 \uc774\ubbf8\uc9c0\ub294 set_filepath\ub85c \uc9c0\uc815\ub41c\ub2e4 (\uc774\ubbf8\uc9c0 \uac1d\uccb4 \uc790\uccb4\uac00 \uc544\ub2c8\ub2e4)\n    def parse_fields(self, o, record, is_new):\n        if is_new:\n            record.set_filepath(os.path.join(self.data_dir,o.filename))\n            record.set_img_size(ImgSize(width=o.width, height=o.height))\n            record.detection.set_class_map(self.class_map)\n\n        record.detection.add_bboxes([BBox.from_xyxy(o.xmin, o.ymin, o.xmax, o.ymax)])\n        record.detection.add_labels([o.label])","4e4dbd68":"# \ub370\uc774\ud130\ud504\ub808\uc784\uc5d0\uc11c \ub370\uc774\ud130\ub97c \ud30c\uc2f1 (\ub808\uc774\ube14\uacfc BBOX)\ntemplate_record = ObjectDetectionRecord()\nparser = PGBRParser(template_record, \".\/dataset\", df)\n\ntrain_records, valid_records = parser.parse()\nprint(parser.class_map)\n# \uc5ec\uae30\uae4c\uc9c0\ud558\uba74 \ud30c\uc2f1\uc774 \uc644\ub8cc\ub41c\ub2e4.\n\ntrain_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\nvalid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])\n# \uc5ec\uae30\uae4c\uc9c0\ud558\uba74 \ud30c\uc2f1\ub41c \ub370\uc774\ud130 \uc801\uc6a9\ud560 \ubcc0\ud615\ub4e4\uc758 \uc815\uc758\uac00 \uc644\ub8cc\ub41c\ub2e4.\n\ntrain_ds = Dataset(train_records, train_tfms)\nvalid_ds = Dataset(valid_records, valid_tfms)\n# \uc5ec\uae30\uae4c\uc9c0 \ud558\uba74 \uc2e4\uc81c \ubaa8\ub378\uc5d0 \uc785\ub825\ub420 Dataset \uac1d\uccb4 \uc0dd\uc131\uc774 \uc644\ub8cc\ub41c\ub2e4.\n# \ubcf4\ub2e4\uc2dc\ud53c \uc77c\ubd80 \ub370\uc774\ud130 \uc99d\uac15\uae4c\uc9c0 \uc218\ud589\ub418\uc5c8\ub2e4. (presizing - https:\/\/notesbylex.com\/presizing.html)\n\nsamples = [train_ds[0] for _ in range(3)]\nshow_samples(samples, ncols=3)\n# \uc77c\ubd80 \ub370\uc774\ud130\ub97c \ucd9c\ub825\ud55c\ub2e4","f444d933":"# model_type\uc740 \uac1d\uccb4\ud0d0\uc9c0\uc6a9 \uc804\uccb4 \ubaa8\ub378 \uad6c\uc870\ub97c \uc120\ud0dd\ud55c\ub2e4\n# - https:\/\/velog.io\/@zeen263\/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-3-Detection-2.-VFNet-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0\nmodel_type = models.mmdet.vfnet\n\n# \ubaa8\ub378 \uad6c\uc870 \uc911 \ubc31\ubcf8\uc73c\ub85c \uc0ac\uc6a9\ud560 \ubaa8\ub378\uc744 \uc120\ud0dd\ud55c\ub2e4\nbackbone = model_type.backbones.resnet50_fpn_mstrain_2x(pretrained=True)\n\n# \uadf8\ub9ac\uace0 \uc774 \ub458\uc744 \uacb0\ud568\ud574 \uc804\uccb4 \ubaa8\ub378\uc758 \uc778\uc2a4\ud134\uc2a4\ub97c \uc0dd\uc131\ud55c\ub2e4\nmodel = model_type.model(backbone=backbone, num_classes=len(parser.class_map))\n\n# \ubaa8\ub378\uc5d0 \uc785\ub825\ub420 \ub370\uc774\ud130\ub97c \uc815\uc758\ud558\ub294 DataLoader \uac1d\uccb4\ub97c \uc0dd\uc131\ud55c\ub2e4\ntrain_dl = model_type.train_dl(train_ds, batch_size=16, num_workers=4, shuffle=True)\nvalid_dl = model_type.valid_dl(valid_ds, batch_size=16, num_workers=4, shuffle=False)","0fb1c16b":"# VFNet\uc774 \ud0c0\uac8c\ud305\ud55c \ub370\uc774\ud130\uc14b\uc740 COCO \uc774\ub2e4\nmetrics = [COCOMetric(metric_type=COCOMetricType.bbox)]","5a653c9b":"learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)","a712650f":"# learn.lr_find()","1f9284d0":"learn.fine_tune(30, 0.0003, freeze_epochs=5)","450b60d6":"torch.save(model.state_dict(), '.\/gbr_vfnet_resnet50_fpn_mstrain_2x_30epochs.pt')","4343b1ef":"!ls ..\/input\/gbr-vfnet-resnet50-fpn-mstrain-2x-30epochspt\/gbr_vfnet_resnet50_fpn_mstrain_2x_30epochs.pt","dc4c268f":"state_dict = torch.load('..\/input\/gbr-vfnet-resnet50-fpn-mstrain-2x-30epochspt\/gbr_vfnet_resnet50_fpn_mstrain_2x_30epochs.pt')","7855310e":"model_type = models.mmdet.vfnet\nbackbone = model_type.backbones.resnet50_fpn_mstrain_2x(pretrained=True)\nmodel = model_type.model(backbone=backbone, num_classes=len(parser.class_map))\n\ntrain_dl = model_type.train_dl(train_ds, batch_size=16, num_workers=4, shuffle=True)\nvalid_dl = model_type.valid_dl(valid_ds, batch_size=16, num_workers=4, shuffle=False)\n\nmodel.load_state_dict(state_dict)","022a1089":"learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)","70710413":"learn.fine_tune(1, 10e-5, freeze_epochs=0)","f0eee050":"infer_dl = model_type.infer_dl([valid_ds[0],valid_ds[4],valid_ds[7],valid_ds[9]], batch_size=4, shuffle=False)\npreds = model_type.predict_from_dl(model, infer_dl, keep_images=True)\nshow_preds(preds=preds)","86f5efac":"# shutil.make_archive('.\/checkpoints',\n#                     'zip',\n#                     '.\/',\n#                     'checkpoints')\n\n# shutil.rmtree(\".\/checkpoints\")\n# shutil.rmtree(\".\/dataset\")\n# shutil.rmtree(\".\/wandb\")","bf8d9d3d":"<div style = \"font-family : Lucida Sans Typewriter;background: rgb(224,224,224);border-radius: 25px;\">\n    <h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">IceVision<\/h2>\n    <center><img src = \"https:\/\/airctic.com\/0.11.0\/images\/icevision-logo-slogan.png\" width=200 height = 200><\/center>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    IceVision is the first agnostic computer vision framework to offer a curated collection with hundreds of high-quality pre-trained models from torchvision, MMLabs, and soon Pytorch Image Models. It orchestrates the end-to-end deep learning workflow allowing to train networks with easy-to-use robust high-performance libraries such as Pytorch-Lightning and Fastai<\/p> \n    IceVision Unique Features:\n    <ul>\n        <li>Data curation\/cleaning with auto-fix<\/li>\n        <li>Access to an exploratory data analysis dashboard<\/li>\n        <li>Pluggable transforms for better model generalization<\/li>\n        <li>Access to hundreds of neural net models<\/li>\n        <li>Acccss to multiple training loop libraries<\/li>\n        <li>Multi-task training to efficiently combine object detection, segmentation, and classification models<\/li>\n    <\/ul>\n    <a href = \"https:\/\/airctic.com\/0.11.0\/\">Go to offocial website for documentation<\/a>\n<\/div>","516ef6c4":"How to create custom Parser for IceVision [[LINK](https:\/\/airctic.com\/0.11.0\/custom_parser\/)]\n\n\ub370\uc774\ud130\uc14b\uc744 \ubaa8\ub378\uc758 \uc785\ub825\uc73c\ub85c \ub9cc\ub4e4\uae30\uc704\ud55c \ud074\ub798\uc2a4\ub97c \ub9cc\ub4e0\ub2e4. Pandas DataFrame\uc758 \ub0b4\uc6a9\uc744 \ud30c\uc2f1\ud574\uc57c \ud558\uae30 \ub54c\ubb38\uc5d0, Parser \ub77c\uace0 \ubd88\ub9ac\ub294 \uac1d\uccb4\ub97c \ud65c\uc6a9\ud558\uba70, \uac1d\uccb4 \ud0d0\uc9c0\uc5d0 \uc0ac\uc6a9\ub418\ub294 \uae30\ubcf8 \uac1d\uccb4\ub294 ObjectDetectionRecord \uc774\ub2e4.","061601b1":"<br>\n<h3 style = \"font-family: Consolas; text-align:center; color:#FF0000\">If you come this far, you could've got some insights from this notebook. An upvote would be very helpful :). Kindly comment if there are any doubts or mistakes<\/h3>\n\n<center><img src = \"https:\/\/img.shields.io\/badge\/Completed-The%20End-brightgreen\" width=300 height = 300><\/center>","206c0287":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \"> Data Preprocessing \u2692\ufe0f\ud83d\udd2c<\/h1>","2a0cc74d":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Data Loader<\/h2>","fe62028f":"<a href=\".\/checkpoints.zip\"> Download File <\/a>","8a181fab":"<center style = \"font-family: 'Lucida Console', 'Courier New', monospace;\">\n    <img src = \"https:\/\/blogger.googleusercontent.com\/img\/a\/AVvXsEj6-rQw5r22Bt47BUTtW5bn_dcWT7zMeADwtvsAHS3kBt6w8eWTmCM649ZcJcvosIMup6flKFIaI8p4M9ZzH1yXpEaMRjvwwfVZ_hMqgXCxtwNzEK25vTa-J2ly20by3M1zx7rTymo-tBI6Fq-mj1SJfCOXsOz0Ou1Esi4h2omvQSW98AjsONsVS-EA\" width=400 height = 200>\n    <h1 style = \"background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%);border-radius: 20px; font-size:30px\">Tensorflow - Help Protect the Great Barrier Reef \ud83c\udf1f\ud83d\udc20<\/h1>\n<\/center>\n\n<div style = \"background: rgb(224,224,224);border-radius: 42px;\">\n    <h1 style = \"font-family: Consolas; text-align:center; color:#FF69B4\">Introduction<\/h1>\n    <h2 style = \"font-family: Consolas; text-align:center\">Why this Competition \u2753<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    Australia's stunningly beautiful Great Barrier Reef is the world\u2019s largest coral reef and home to 1,500 species of fish, 400 species of corals, 130 species of sharks, rays, and a massive variety of other sea life.Unfortunately, the reef is under threat, in part because of the overpopulation of one particular starfish \u2013 the coral-eating crown-of-thorns starfish (or COTS for short).\n    <\/p>\n    <h2 style = \"font-family: Consolas; text-align:center\">Goal of Competition \ud83e\udd45<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    The goal of this competition is to accurately identify starfish in real-time by building an object detection model trained on underwater videos of coral reefs.\n    <\/p>\n<\/div>\n\n<div style = \"background: rgb(224,224,224);border-radius: 42px;\">\n    <h1 style = \"font-family: Consolas; text-align:center; color:#FF69B4\">Sponsors \ud83d\udcb0<\/h1>\n    <h2 style = \"font-family: Consolas; text-align:center\">TensorFlow<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    TensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks.\n    <\/p>\n    <h2 style = \"font-family: Consolas; text-align:center\">CSIRO<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    The Commonwealth Scientific and Industrial Research Organisation is an Australian Government agency responsible for scientific research. CSIRO works with leading organisations around the world.\n    <\/p>\n    <h2 style = \"font-family: Consolas; text-align:center\">GBRF<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    The Great Barrier Reef Foundation is an Australian non-profit organisation established in 1999 to help protect and preserve the Great Barrier Reef. \n    <\/p>\n<\/div>\n\n<h2 style = \"font-family: Consolas\">More Details<\/h2>\n<p style = \"font-family : Lucida Sans Typewriter\">Check <a href = \"https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/data\">competition page<\/a> for details<\/p>\n<h2 style = \"font-family : Comic Sans MS\">Let's dive in \u2b07\ufe0f<\/h2>\n\n<center><img src = \"https:\/\/img.shields.io\/badge\/Upvote-If%20you%20found%20this%20notebook%20useful-blue\" width=400 height = 400><\/center>","e7a9fd6b":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Initialize Constants \ud83d\udd30<\/h1>","58e10d31":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Data Visualization \ud83d\udcca\ud83d\udcb9<\/h1>","dc175612":"<div style = \"font-family : Lucida Sans Typewriter;background: rgb(224,224,224);border-radius: 25px;\">\n    <h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Pandas Profiling<\/h2>\n    <center><img src = \"https:\/\/pandas-profiling.github.io\/pandas-profiling\/docs\/assets\/logo_header.png\" width=200 height = 200><\/center>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    Pandas profiling is an open source Python module with which we can quickly do an exploratory data analysis with just a few lines of code. Besides, if this is not enough to convince us to use this tool, it also generates interactive reports in web format that can be presented to any person, even if they don\u2019t know programming.\n    <\/p>  \n    <a href = \"https:\/\/pandas-profiling.github.io\/pandas-profiling\/\">Go to offocial website for documentation<\/a>\n<\/div>","b5a6c65f":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Metrics<\/h2>","6907c887":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Data Parser<\/h2>","0a4f8957":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Import Libraries \ud83d\udcda<\/h1>","56092481":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Inference \ud83d\udd2e<\/h1>","4cb06143":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Modelling \ud83c\udfeb<\/h1>","2599b29b":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Training<\/h2>","805ee3e1":"<div style = \"font-family : Lucida Sans Typewriter;background: rgb(224,224,224);border-radius: 25px;\">\n    <h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Weights and Biases<\/h2>\n    <center><img src = \"https:\/\/i.imgur.com\/KISYcqD.png\" width=200 height = 200><\/center>\n    <a href = \"https:\/\/wandb.ai\/shanmukh\/Protect%20Great%20Barrier%20Reef\/runs\/2eywhb67\"; style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; text-align:center; font-size:25px\">Checkout Dashboard created for this notebook<\/a>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    Weights and Biases is a set of Machine Learning tools used for experiment tracking, dataset versioning, and collaborating on ML projects. Weights and Biases is useful in many applications such as\n    <\/p>  \n    <ul>\n          <li>Experiment Tracking<\/li>\n          <li>Hyperparameter Tuning<\/li>\n          <li>Data Visualization<\/li>\n          <li>Data and model Versioning<\/li>\n          <li>Collaborative Reports<\/li>\n    <\/ul>\n    <a href = \"https:\/\/wandb.ai\/site\">Go to offocial website for more tutorials and Documentation<\/a>\n<\/div>","ab2b13ff":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Install Libraries \u23ec<\/h1>"}}