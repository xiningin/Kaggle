{"cell_type":{"e5b8146e":"code","77d145c3":"code","b09c9e18":"code","b6ed814c":"markdown","e98a54ae":"markdown","da4e9e2b":"markdown"},"source":{"e5b8146e":"import pandas as pd, numpy as np\nimport random\nimport tensorflow_hub as hub\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\nfrom tqdm.contrib.concurrent import process_map\ntqdm.pandas()\n\nIS_TEST = False\nDIST_THRESHOLD = .75\nfl = '..\/input\/shopee-product-matching\/train.csv' if not IS_TEST else '..\/input\/shopee-product-matching\/test.csv'\ndata = pd.read_csv(fl)\ntot_rows = data.shape[0]\n\nsentence_embed = hub.load(\"..\/input\/use-v4\/use_v4\")\ntitle_embeddings = sentence_embed(data['title'].values.tolist()) #512-d\ntitle_embeddings = title_embeddings.numpy() \ntitle_embeddings = pd.DataFrame(title_embeddings)\ntitle_embeddings.columns = [f'title_emb_{i}' for i in range(512)]\ndata = pd.merge(data, title_embeddings, left_index=True, right_index=True)\n\nfeat_cols = [f'title_emb_{i}' for i in range(512)] \nall_vecs = data[feat_cols].values","77d145c3":"def generate_predictions(ix):\n    dists = np.linalg.norm(all_vecs-all_vecs[ix], axis=1)\n    indices = np.where(dists<=DIST_THRESHOLD)[0]\n    clusters = data.iloc[indices]['posting_id'].values.tolist()\n    return ' '.join(clusters)\n\ndef generate_ground_truths(ix):\n    lbl = data.iloc[ix]['label_group']\n    gt_indices = data[data['label_group']==lbl].index\n    gt_clusters = data.iloc[gt_indices]['posting_id'].values.tolist()\n    return ' '.join(gt_clusters)\n    \nif __name__ == '__main__':\n    data['matches'] = ''\n    data['matches'] = process_map(generate_predictions, list(range(all_vecs.shape[0])), max_workers=4, chunksize=1000)\n    if not IS_TEST:\n        data['gts'] = ''\n        data['gts'] = process_map(generate_ground_truths, list(range(all_vecs.shape[0])), max_workers=4, chunksize=1000)","b09c9e18":"if IS_TEST:\n    data[['posting_id', 'matches']].to_csv('submission.csv', index=False)\nelse:\n    data['gts'] = data['gts'].progress_apply(lambda x: x.split())\n    data['matches'] = data['matches'].progress_apply(lambda x: x.split())\n    tp = data.progress_apply(lambda row: len(set(row['gts']).intersection(row['matches'])), axis=1)\n    fp = data.progress_apply(lambda row: len(set(row['matches'])-set(row['gts'])), axis=1)\n    fn = data.progress_apply(lambda row: len(set(row['gts'])-set(row['matches'])), axis=1)\n    data['f1_score'] = tp\/(tp + (fp+fn)\/2)\n    print('Train mean F1: ', data['f1_score'].mean())\n    \n    stats = pd.DataFrame()\n    stats['tp'] = tp\n    stats['fp'] = fp\n    stats['fn'] = fn\n    print(stats.describe(percentiles=[(ix+1)*.05 for ix in range(19)]))    ","b6ed814c":"## Predictions using Sentence embeddings","e98a54ae":"## F1 Stats on training data","da4e9e2b":"This is a simple, unsupervised approach to clustering products in this competition. For each test record, [sentence embeddings](https:\/\/tfhub.dev\/google\/collections\/universal-sentence-encoder) are generated on `title`. Universal sentence encoders are case insensitive and are robust enough to accommodate small typos. Embeddings whose euclidean distance are within a certain threshold (usually less than 1.) are assumed to belong to the same cluster. Since euclidean distances are reflexive ($Cluster(A)=Cluster(A)$) and symmetric ($Cluster(A)=Cluster(B) \\iff Cluster(B)=Cluster(A)$), [all evaluation criteria](https:\/\/www.kaggle.com\/c\/shopee-product-matching\/overview\/evaluation) are met.\n\nNeedless to say, it makes more sense to combine the embeddings with features generated from images and perceptual hashes for a better feature set.\n\n**Few implementation notes:**\n* This notebook does not filter for the top 50 similar products alone. But that can be easily done by altering `generate_predictions`\n* I load the entire title set (including repetitions) in this notebook. Alternatively, title strings can either be batched and\/or repetitions can be ignored. \n* Submission takes approximately 1 hour.\n* Set `IS_TEST = True` during commit to submit. When `IS_TEST = False`, this notebook evaluates on training data instead. \n\n\n**NOTE:** This is my first public notebook and any feedback is most welcome. Thanks. "}}