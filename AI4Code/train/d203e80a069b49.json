{"cell_type":{"abdc10cd":"code","d9b95288":"code","4cca28b1":"code","38d6814e":"code","401e478c":"code","08fc3c9d":"code","9ab31823":"code","68f9c4ce":"code","50821d63":"code","f4e01103":"code","47e0f557":"code","e6d3ba60":"code","d1bbb4ca":"code","84088e3d":"code","6706d7cf":"code","e4e54969":"code","567b24a3":"code","00d1cfd3":"code","1cc19fcc":"code","e397f0ff":"code","03663568":"code","ce38a825":"code","28f10e24":"code","cddb9508":"code","bca25895":"code","cbef0059":"code","509ece11":"code","6e508fff":"code","4a464df7":"code","8b653895":"code","feac4484":"code","29bfc342":"code","db461b1c":"code","c60f7fcd":"code","7d00dbf0":"code","68e44a5b":"code","13ff6cba":"code","15a2803b":"code","1288896f":"code","637ec2f6":"code","53edff65":"code","520b19bd":"code","5d8bea5b":"code","5bdd5479":"code","b6e13072":"code","c1ae95d3":"code","e15f55fe":"code","72462d21":"code","921f8d62":"code","e8654ee4":"code","2cc4abe2":"code","e401a9ba":"code","fa879e4e":"code","2361d8db":"code","7ec1bd48":"code","2183d2a9":"markdown","de9f3320":"markdown","2556b2aa":"markdown"},"source":{"abdc10cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9b95288":"# Importing all the necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","4cca28b1":"# Reading and making a copy of the dataset\n\nmain_df = pd.read_csv(\"\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv\", sep=\"\\t\")\ndf = main_df.copy()\ndf.head()","38d6814e":"df.shape","401e478c":"df.info()","08fc3c9d":"# Finding the number of unique values present in each column\n\ndf.nunique()","9ab31823":"# Checking if any NaN is present in column or not\n\ndf.isna().any()","68f9c4ce":"# Checking for null value using heatmap\n\nsns.heatmap(df.isnull())","50821d63":"df=df.drop(columns=[\"Z_CostContact\", \"Z_Revenue\"],axis=1)\ndf.head()","f4e01103":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(), annot=True)\nplt.show()","47e0f557":"# Checking for correlation by unstacking data\n\ncorr = df.corr()\nc1 = corr.abs().unstack()\nc1.sort_values(ascending = False)[24:50:2]","e6d3ba60":"df['Income'] = df['Income'].fillna(df['Income'].mean())\ndf.isna().any() ","d1bbb4ca":"df.head()","84088e3d":"# Checking number of unique categories present in the \"Marital_Status\"\n\ndf['Marital_Status'].value_counts()  \n","6706d7cf":"df['Marital_Status'] = df['Marital_Status'].replace(['Married', 'Together'],'relationship')\ndf['Marital_Status'] = df['Marital_Status'].replace(['Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd'],'Single')","e4e54969":"# Count of different values present in Marital_Status\n\ndf['Marital_Status'].value_counts() ","567b24a3":"# Combining different dataframe into a single column to reduce the number of dimension\n\ndf['Kids'] = df['Kidhome'] + df['Teenhome']\ndf['Expenses'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']\ndf['TotalAcceptedCmp'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + df['AcceptedCmp4'] + df['AcceptedCmp5'] + df['Response']\ndf['NumTotalPurchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumDealsPurchases']","00d1cfd3":"# Deleting some column to reduce dimension and complexity of model\n\ncol_del = [\"AcceptedCmp1\" , \"AcceptedCmp2\", \"AcceptedCmp3\" , \"AcceptedCmp4\",\"AcceptedCmp5\", \"Response\",\"NumWebVisitsMonth\", \"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\",\"NumDealsPurchases\" , \"Kidhome\", \"Teenhome\",\"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\"]\ndf=df.drop(columns=col_del,axis=1)\ndf.head()","1cc19fcc":"# Adding a column \"Age\" in the dataframe\n\ndf['Age'] = 2015 - df[\"Year_Birth\"]","e397f0ff":"df['Education'].value_counts()","03663568":"# Changing category into UG and PG only\n\ndf['Education'] = df['Education'].replace(['PhD','2n Cycle','Graduation', 'Master'],'PG')  \ndf['Education'] = df['Education'].replace(['Basic'], 'UG')","ce38a825":"# Number of days a customer was engaged with company\n\n# Changing Dt_customer into timestamp format\ndf['Dt_Customer'] = pd.to_datetime(df.Dt_Customer)\ndf['first_day'] = '01-01-2015'\ndf['first_day'] = pd.to_datetime(df.first_day)\ndf['day_engaged'] = (df['first_day'] - df['Dt_Customer']).dt.days","28f10e24":"df.info()","cddb9508":"df=df.drop(columns=[\"ID\", \"Dt_Customer\", \"first_day\", \"Year_Birth\", \"Dt_Customer\", \"Recency\", \"Complain\"],axis=1)\ndf.shape","bca25895":"fig = px.bar(df, x='Marital_Status', y='Expenses', color=\"Education\")\nfig.show()","cbef0059":"fig = px.bar(df, x='Marital_Status', y='Expenses', color=\"Marital_Status\")\nfig.show()","509ece11":"fig = px.histogram (df, x = \"Expenses\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","6e508fff":"fig = px.histogram (df, x = \"Expenses\",  facet_row = \"Education\",  template = 'plotly_dark')\nfig.show ()","4a464df7":"fig = px.histogram (df, x = \"NumTotalPurchases\",  facet_row = \"Education\",  template = 'plotly_dark')\nfig.show ()","8b653895":"fig = px.histogram (df, x = \"Age\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","feac4484":"fig = px.histogram (df, x = \"Income\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","29bfc342":"fig =  px.pie (df, names = \"Marital_Status\", hole = 0.4, template = \"gridon\")\nfig.show ()","db461b1c":"fig =  px.pie (df, names = \"Education\", hole = 0.4, template = \"plotly_dark\")\nfig.show ()","c60f7fcd":"sns.barplot(x = df['Expenses'],y = df['Education']);\nplt.title('Total Expense based on the Education Level');","7d00dbf0":"sns.barplot(x = df['Income'],y = df['Education']);\nplt.title('Total Income based on the Education Level');","68e44a5b":"df.describe()","13ff6cba":"sns.heatmap(df.corr(), annot=True)","15a2803b":"cate = []\nfor i in df.columns:\n    if (df[i].dtypes == \"object\"):\n        cate.append(i)\n\nprint(cate)","1288896f":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","637ec2f6":"lbl_encode = LabelEncoder()\nfor i in cate:\n    df[i]=df[[i]].apply(lbl_encode.fit_transform)","53edff65":"df1 = df.copy()","520b19bd":"scaled_features = StandardScaler().fit_transform(df1.values)\nscaled_features_df = pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)","5d8bea5b":"scaled_features_df.head()","5bdd5479":"from sklearn.cluster import KMeans","b6e13072":"wcss=[]\nfor i in range (1,11):\n kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)\n kmeans.fit(scaled_features_df)\n wcss.append(kmeans.inertia_)\nplt.figure(figsize=(16,8))\nplt.plot(range(1,11),wcss, 'bx-')\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","c1ae95d3":"from sklearn.metrics import silhouette_score ","e15f55fe":"silhouette_scores = []\nfor i in range(2,10):\n    m1=KMeans(n_clusters=i, random_state=42)\n    c = m1.fit_predict(scaled_features_df)\n    silhouette_scores.append(silhouette_score(scaled_features_df, m1.fit_predict(scaled_features_df))) \nplt.bar(range(2,10), silhouette_scores) \nplt.xlabel('Number of clusters', fontsize = 20) \nplt.ylabel('S(i)', fontsize = 20) \nplt.show()","72462d21":"silhouette_scores","921f8d62":"# Getting the maximum value of silhouette score and adding 2 in index because index starts from 2.\n\nsc=max(silhouette_scores)\nnumber_of_clusters=silhouette_scores.index(sc)+2\nprint(\"Number of Cluster Required is : \", number_of_clusters)","e8654ee4":"# Training a predicting using K-Means Algorithm.\n\nkmeans=KMeans(n_clusters=number_of_clusters, random_state=42).fit(scaled_features_df)\npred=kmeans.predict(scaled_features_df)\n\n\n# Appending those cluster value into main dataframe (without standard-scalar)\n\ndf['cluster'] = pred + 1","2cc4abe2":"df.head()","e401a9ba":"scaled_features_df.head()","fa879e4e":"df['Education'].value_counts()","2361d8db":"pl = sns.countplot(x=df[\"cluster\"])\npl.set_title(\"Distribution Of The Clusters\")\nplt.show()","7ec1bd48":"# Clusters interpretation \nsns.set(rc={'axes.facecolor':'black', 'figure.facecolor':'black', 'axes.grid' : False, 'font.family': 'Ubuntu'})\n\nfor i in df:\n    diag = sns.FacetGrid(df, col = \"cluster\", hue = \"cluster\", palette = \"Set1\")\n    diag.map(plt.hist, i, bins=6, ec=\"k\") \n    diag.set_xticklabels(rotation=25, color = 'white')\n    diag.set_yticklabels(color = 'white')\n    diag.set_xlabels(size=16, color = 'white')\n    diag.set_titles(size=16, color = '#f01132', fontweight=\"bold\")\n    diag.fig.set_figheight(6)","2183d2a9":"## EDA","de9f3320":"## If You like then upvote\n# Thanks!","2556b2aa":"## Import The Modules"}}