{"cell_type":{"f437d372":"code","2eee9d8c":"code","385be994":"code","4244f95b":"code","0e3c236e":"code","5c06e99c":"code","a76515bf":"code","c74b7c42":"code","10b08df9":"code","585c4beb":"code","d62363f4":"code","e5554f5c":"code","4b61091d":"code","1b0ccb50":"code","24d99e40":"code","6f4ed3f5":"code","e8280abc":"code","cab3fe30":"code","f5da69aa":"code","05f0614f":"code","329f8642":"code","bfce06b4":"code","8c874f77":"code","8ca885a7":"code","7b3404c2":"code","c86b48d4":"code","28bca124":"code","ee6e86f1":"code","a5ce4394":"code","9ed017a0":"code","e69f28ef":"code","8cfa9c47":"code","611e52f1":"code","a6b4a7b2":"code","5bb76f03":"code","67226582":"code","5cb4ae2e":"code","85c02f92":"code","8bc5d143":"code","4de30ade":"code","51d46cec":"code","341a64dc":"code","20a3fb85":"code","75a8a0c2":"code","930deda4":"code","757dfb98":"code","a292f33e":"code","53d0164b":"code","345bf0a8":"code","ba82f313":"code","44b0d19d":"code","fdc8dc45":"markdown","ef83dabb":"markdown"},"source":{"f437d372":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2eee9d8c":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n#from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ntrainfile = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_train.csv\")\ntestfile = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_test.csv\")\ndatapath = Path(\"..\/input\/google-smartphone-decimeter-challenge\")\ntruths = (datapath\/'train').rglob('ground_truth.csv')\ncols1 = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg',\n       'lngDeg']\ntruthlist = []\nfor fpath in truths:\n    fcsv = pd.read_csv(fpath, usecols = cols1)\n    truthlist.append(fcsv)\n\ntruthdata = pd.concat(truthlist, ignore_index = True) # dump all truth files into a single file","385be994":"\ncols2 = ['collectionName','phoneName','millisSinceGpsEpoch','constellationType','svid','signalType','receivedSvTimeInGpsNanos','xSatPosM','ySatPosM','zSatPosM']\nlogs = (datapath\/'train').rglob('*derived.csv')\n\nlogslist = []\nfor fpath in logs:\n    logcsv = pd.read_csv(fpath, usecols = cols2)\n    logslist.append(logcsv)\n\nlogsdata = pd.concat(logslist, ignore_index = True) # dump all derived logs files into a single file\nlogsdata['constellationType'].value_counts()","4244f95b":"logsdata['svid'].value_counts().index[0]","0e3c236e":"logsdata_svtime = logsdata.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).receivedSvTimeInGpsNanos.apply(lambda x: np.min(x)).reset_index()\nlogsdata_xsat = logsdata.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).xSatPosM.apply(lambda x: np.average(x)).reset_index()\nlogsdata_ysat = logsdata.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).ySatPosM.apply(lambda x: np.average(x)).reset_index()\nlogsdata_zsat = logsdata.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).zSatPosM.apply(lambda x: np.average(x)).reset_index()\nlogsdata_svid = logsdata.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).svid.apply(lambda x: x.value_counts().index[0]).reset_index()\n#logsdata_constellation = logsdata.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).constellationType.apply(lambda x:x.value_counts().index[0]).reset_index()\nlogsdata_signaltype = logsdata.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).signalType.apply(lambda x: x.value_counts().index[0]).reset_index()\n\nlogsdata1 = logsdata_svtime.merge(logsdata_xsat, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata2 = logsdata1.merge(logsdata_ysat, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata3 = logsdata2.merge(logsdata_zsat, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata4 = logsdata3.merge(logsdata_svid, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\n#logsdata5 = logsdata4.merge(logsdata_constellation, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata_final = logsdata4.merge(logsdata_signaltype, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\n#logsdata_final['constellationType'] = logsdata_final.constellationType.apply(lambda x: \"one\" if x == 1 else(\"two\" if x == 2 else(\"three\" if x == 3 else(\"four\" if x == 4 else(\"five\" if x == 5 else(\"six\" if x == 6 else \"zero\"))))))                                                                                                 \nlogsdata_final.head()","5c06e99c":"print(len(logsdata_final))\nprint(len(trainfile))\ntraindata1 = trainfile.merge(truthdata, on = cols1[:3], suffixes=(\"_current\",\"_truth\")) # merge train file with observed data\ntraindata = pd.merge(traindata1, logsdata_final, how = 'left', on = ['collectionName','phoneName','millisSinceGpsEpoch'])\ntraindata.sort_values(by = ['phone','millisSinceGpsEpoch'])\n#traindata = trainfile.merge(truthdata, on = cols1[:3], suffixes=(\"_current\",\"_truth\")) # merge train file with observed data\n#traindata = traindata.merge(logsdata, on = cols1[:3]) # add columns from gnss logs to the traindata\ntraindata.head()\ntraindata = traindata.fillna(0)\ntraindata['latDeg_prev'] = traindata['latDeg_current'].shift(1).where(traindata['phone'].eq(traindata['phone'].shift(1)))\ntraindata['lngDeg_prev'] = traindata['lngDeg_current'].shift(1).where(traindata['phone'].eq(traindata['phone'].shift(1)))    \ntraindata['latDeg_next'] = traindata['latDeg_current'].shift(-1).where(traindata['phone'].eq(traindata['phone'].shift(-1)))\ntraindata['lngDeg_next'] = traindata['lngDeg_current'].shift(-1).where(traindata['phone'].eq(traindata['phone'].shift(-1)))\ntraindata['time_prev'] = traindata['millisSinceGpsEpoch'].shift(1).where(traindata['phone'].eq(traindata['phone'].shift(1)))\ntraindata['time_next'] = traindata['millisSinceGpsEpoch'].shift(-1).where(traindata['phone'].eq(traindata['phone'].shift(-1)))\n\n#traindata['svid'] = pd.Categorical(traindata.svid)\n#traindata['constellationType'] = pd.Categorical(traindata.constellationType) \nfor i in traindata.index:\n    if pd.isna(traindata['latDeg_prev'][i]):\n        traindata['latDeg_prev'][i] = traindata['latDeg_current'][i]\n        traindata['lngDeg_prev'][i] = traindata['lngDeg_current'][i]\n        traindata['time_prev'][i] = traindata['millisSinceGpsEpoch'][i]\n    if pd.isna(traindata['latDeg_next'][i]):\n        traindata['latDeg_next'][i] = traindata['latDeg_current'][i]\n        traindata['lngDeg_next'][i] = traindata['lngDeg_current'][i]\n        traindata['time_next'][i] = traindata['millisSinceGpsEpoch'][i]\n    \n    #if traindata['time_prev'][i] == traindata['millisSinceGpsEpoch'][i]:\n        #traindata['vel_lat'] = 0\n        #traindata['vel_lng'] = 0\n    #else:\n        #traindata['vel_lat'] = (traindata['latDeg_current'][i] - traindata['latDeg_prev'][i])\/(traindata['millisSinceGpsEpoch'][i] - traindata['time_prev'][i])\n        #traindata['vel_lng'] = (traindata['lngDeg_current'][i] - traindata['lngDeg_prev'][i])\/(traindata['millisSinceGpsEpoch'][i] - traindata['time_prev'][i])\n\ntraindata['time_since_last_read'] = traindata['millisSinceGpsEpoch'] - traindata['time_prev']\ntraindata['latd_prev_est'] = (traindata['latDeg_current'] - traindata['latDeg_prev'])*(10**6)\ntraindata['latd_next_est'] = (traindata['latDeg_next'] - traindata['latDeg_current'])*(10**6)\ntraindata['latd_prev_act'] = (traindata['latDeg_truth'] - traindata['latDeg_prev'])*(10**6)\ntraindata['lngd_prev_est'] = (traindata['lngDeg_current'] - traindata['lngDeg_prev'])*(10**6)\ntraindata['lngd_next_est'] = (traindata['lngDeg_next'] - traindata['lngDeg_current'])*(10**6)\ntraindata['lngd_prev_act'] = (traindata['lngDeg_truth'] - traindata['lngDeg_prev'])*(10**6)\nprint(len(traindata))\n#print(len(trainfile))\ntraindata.head(1)","a76515bf":"traindata['lat_d'] = traindata['latDeg_current'] - traindata['latDeg_truth']\ntraindata['lng_d'] = traindata['lngDeg_current'] - traindata['lngDeg_truth']","c74b7c42":"#traindata['time_since_last_read'].value_counts()\ncorr_df = pd.DataFrame(traindata.iloc[:, 3:].corr())# draw correlation between all columns from collection name, phone name, lat & lng Deg both estimated & observed\ncorr_df.to_csv('.\/corr_df.csv')\n#testfile.head()","10b08df9":"x_cols = ['heightAboveWgs84EllipsoidM','time_since_last_read','xSatPosM','ySatPosM','zSatPosM','receivedSvTimeInGpsNanos','latd_prev_est','latd_next_est','lngd_prev_est','lngd_next_est']\nxdata = traindata[x_cols] #creating the x variable df\nxdata.head() # dummies for the categorical variable\n#xdata_dummies = pd.get_dummies(xdata, prefix = \"dum_\")\n#xdata_dummies.columns","585c4beb":"ydata = traindata[['latd_prev_act','lngd_prev_act']]\nydata.head()","d62363f4":"from sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(xdata,ydata, test_size = 0.3, random_state = 162)\ncols = list(xtrain.columns)\n#latcols = [e for e in cols if e not in ('latd_prev_act','lngd_prev_act','millisSinceGpsEpoch')]\n#lngcols = [e for e in cols if e not in ('latd_prev_act','lngd_prev_act','millisSinceGpsEpoch')]\n#xtrain.head() -- x train & xtest is already transformed to have the right set of columns\nytrain_lat = ytrain[['latd_prev_act']]\nytest_lat = ytest[['latd_prev_act']]\nytrain_lng = ytrain[['lngd_prev_act']]\nytest_lng = ytest[['lngd_prev_act']]\nxtrain.head()","e5554f5c":"ytrain_lng.head() #check if datasets share the same indexes - for merging dataframes later","4b61091d":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV # library for random search hyper param tuning\nfrom sklearn import metrics #library for metrics to measure model performance\nparam_grid = {#'bootstrap': [True],  ##applicable only for random forests not gradient boosting \n              'max_depth': [10,15],\n              'n_estimators': [200,300]}   # create random grid\nrf = GradientBoostingRegressor()\n#rf_lat = RandomForestRegressor(bootstrap = True, n_estimators = 100, max_depth = 20, max_features = 'auto')\n#rf_lat.fit(xtrain_lat, ytrain_lat)\n#rf_lat.feature_importances_\nrf_grid_lat = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, verbose = 150)\nrf_grid_lat.fit(xtrain, ytrain_lat)\n#xtrain_lat_arr = xtrain_lat.to_numpy()\n#ytrain_lat_arr = ytrain_lat.to_numpy()\n#ytrain_lat_arr\n#rf_grid_lat = rf_grid.fit(xtrain_lat, ytrain_lat)\n#rf_grid_lat.cv_results_\nrf_grid_lat.best_params_ #throws the best model for latitude prediction","1b0ccb50":"rf_grid_lat.feature_importances_","24d99e40":"rf_grid_lat.cv_results_","6f4ed3f5":"from sklearn.ensemble import GradientBoostingRegressor\nrf = GradientBoostingRegressor()\nrf_lat = GradientBoostingRegressor(n_estimators = 200, max_depth = 10) # fitting with the best regressor & low variance\nrf_lat.fit(xtrain, ytrain_lat)\nypred_lat = rf_lat.predict(xtest)\nrf_lat.feature_importances_\n#score(xtrain_lat, ytrain_lat)","e8280abc":"xtrain.columns","cab3fe30":"from sklearn.model_selection import RandomizedSearchCV\nparam_grid = {#'bootstrap': [True],  ##applicable only for random forests not gradient boosting \n              'max_depth': [15,20,25,30,35,40],\n              'n_estimators': [300,400,500,600]} \nrf_grid_lng = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, cv = 5, n_iter = 8, verbose = 250)\nrf_grid_lng.fit(xtrain, ytrain_lng)\nrf_grid_lng.best_params_","f5da69aa":"rf_grid_lng.cv_results_","05f0614f":"rf_lng = GradientBoostingRegressor(n_estimators = 300, max_depth = 20)\nrf_lng.fit(xtrain_lng, ytrain_lng)\nypred_lng = rf_lng.predict(xtest_lng)","329f8642":"#code fore adding phone to the test data\nytest_lat = ytest[['latDeg_truth','lngDeg_truth']]\n#ytest_lat.head()\nytest_lat['millisSinceGpsEpoch'] = traindata['millisSinceGpsEpoch']\n#ytest_lat.head()\nytest_lat['phone'] = traindata['phone']\nytest_lat.head()","bfce06b4":"ytest_lat.reset_index(inplace = True)\nytest_lat = ytest_lat.drop(['index'], axis = 1)\n#ytest_lat.head()\n\nytest_lat['latDeg_pred'] = pd.Series(ypred_lat)\nytest_lat['lngDeg_pred'] = pd.Series(ypred_lng)\nytest_lat.head()","8c874f77":"ytest_lat['lngDeg_truth'][5]","8ca885a7":"#cacluating the havesine distance\nfrom math import radians, cos, sin, asin, sqrt\ndef haversine(df):\n    dist = []\n    for i in df.index:\n        lat1 = df['latDeg_truth'][i]\n        lng1 = df['lngDeg_truth'][i]\n        lat2 = df['latDeg_pred'][i]\n        lng2 = df['lngDeg_pred'][i]\n        # convert decimal degrees to radians \n        lat1,lng1,lat2,lng2 = map(radians, [lat1, lng1, lat2, lng2])\n\n        # haversine formula \n        dlon = lng2 - lng1 \n        dlat = lat2 - lat1 \n        a = sin(dlat\/2)**2 + cos(lat1) * cos(lat2) * sin(dlon\/2)**2\n        c = 2 * asin(sqrt(a)) \n        r = 6371000 # Radius of earth in kilometers. Use 3956 for miles\n        d = c * r\n        dist.append(d)\n    return dist","7b3404c2":"ytest_lat['dist'] = haversine(ytest_lat)\nytest_lat.head()","c86b48d4":"ytest_lat.head()","28bca124":"#xtest.head()\n#xdata.head()\n#final_df = pd.DataFrame()\nytest_pred_df = ytest_lat.groupby(['phone']).dist.apply(lambda x: np.percentile(x,50)).reset_index()\nytest_pred_df.head()\nlen(ytest_pred_df)\n\n#df.groupby(['group'])['price'].apply(lambda x: np.percentile(x,60))\n#ytest_lat.head()","ee6e86f1":"ytest_pred_df1 = ytest_lat.groupby(['phone']).dist.apply(lambda x: np.percentile(x,95)).reset_index()\nytest_pred_df1.head()","a5ce4394":"ytest_pred_df['dist_95'] = ytest_pred_df1['dist']\navg_dist = []\nfor i in ytest_pred_df.index:\n    a = (ytest_pred_df['dist'][i] + ytest_pred_df['dist_95'][i])\/2\n    avg_dist.append(a)\navg_dist\nytest_pred_df['avg_dist'] = avg_dist","9ed017a0":"#ytest_pred_df = ytest_pred_df.drop(['avg_dist'], axis = 1)\nytest_pred_df.head()","e69f28ef":"#final average\nk = 0\ns = 0\nfor i in ytest_pred_df.index:\n    k = k + 1\n    s = s + ytest_pred_df['avg_dist'][i]\n\nl = s\/k\nprint(\"overall average error across phones: %.5f\", {l})","8cfa9c47":"submission = pd.read_csv(\"..\/input\/google-smartphone-decimeter-challenge\/sample_submission.csv\")\nsubmission.head()","611e52f1":"cols2 = ['collectionName','phoneName','millisSinceGpsEpoch','constellationType','svid','signalType','receivedSvTimeInGpsNanos','xSatPosM','ySatPosM','zSatPosM']\nlogs = (datapath\/'test').rglob('*derived.csv')\n\nlogslist = []\nfor fpath in logs:\n    logcsv = pd.read_csv(fpath, usecols = cols2)\n    logslist.append(logcsv)\n\nlogsdata_test = pd.concat(logslist, ignore_index = True)","a6b4a7b2":"logsdata_svtime = logsdata_test.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).receivedSvTimeInGpsNanos.apply(lambda x: np.min(x)).reset_index()\nlogsdata_xsat = logsdata_test.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).xSatPosM.apply(lambda x: np.average(x)).reset_index()\nlogsdata_ysat = logsdata_test.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).ySatPosM.apply(lambda x: np.average(x)).reset_index()\nlogsdata_zsat = logsdata_test.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).zSatPosM.apply(lambda x: np.average(x)).reset_index()\nlogsdata_svid = logsdata_test.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).svid.apply(lambda x: x.value_counts().index[0]).reset_index()\n#logsdata_constellation = logsdata_test.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).constellationType.apply(lambda x:x.value_counts().index[0]).reset_index()\nlogsdata_signaltype = logsdata_test.groupby(['collectionName','phoneName','millisSinceGpsEpoch']).signalType.apply(lambda x: x.value_counts().index[0]).reset_index()\n\nlogsdata1 = logsdata_svtime.merge(logsdata_xsat, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata2 = logsdata1.merge(logsdata_ysat, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata3 = logsdata2.merge(logsdata_zsat, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata4 = logsdata3.merge(logsdata_svid, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\n#logsdata5 = logsdata4.merge(logsdata_constellation, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nlogsdata_test_final = logsdata4.merge(logsdata_signaltype, on = ['collectionName','phoneName','millisSinceGpsEpoch'])\n#logsdata_final['constellationType'] = logsdata_final.constellationType.apply(lambda x: \"one\" if x == 1 else(\"two\" if x == 2 else(\"three\" if x == 3 else(\"four\" if x == 4 else(\"five\" if x == 5 else(\"six\" if x == 6 else \"zero\"))))))                                                                                                 \nlogsdata_test_final.head()","5bb76f03":"len(xtrain_lat)","67226582":"#traindata = trainfile.merge(truthdata, on = cols1[:3], suffixes=(\"_current\",\"_truth\")) # merge train file with observed data\n#testdata = testfile.merge(logsdata_test_final, on = cols1[:3]) # add columns from gnss logs to the traindata\ntestdata = pd.DataFrame()\nprint(len(testfile))\nprint(len(logsdata_test_final))\ntestdata = pd.merge(testfile, logsdata_test_final, how = 'left', on = ['collectionName','phoneName','millisSinceGpsEpoch'])\nprint(len(testdata))\ntestdata.tail()","5cb4ae2e":"testdata['receivedSvTimeInGpsNanos'].value_counts()","85c02f92":"testdata = testdata.fillna(0)\ntestdata['svid'] = pd.Categorical(testdata.svid)\n#testdata['constellationType'] = pd.Categorical(testdata.constellationType) \ntestdata['signalType'] = pd.Categorical(testdata.signalType)\ntestdata.iloc[:, 3:].corr()","8bc5d143":"testdata.rename(columns = {'latDeg': 'latDeg_current', 'lngDeg': 'lngDeg_current'}, inplace = True)\ntestdata.sort_values(by = ['phone','millisSinceGpsEpoch'])\n#testdata = testdata.fillna(0)\ntestdata['latDeg_prev'] = testdata['latDeg_current'].shift(1).where(testdata['phone'].eq(testdata['phone'].shift(1)))\ntestdata['lngDeg_prev'] = testdata['lngDeg_current'].shift(1).where(testdata['phone'].eq(testdata['phone'].shift(1)))    \ntestdata['latDeg_next'] = testdata['latDeg_current'].shift(-1).where(testdata['phone'].eq(testdata['phone'].shift(-1)))\ntestdata['lngDeg_next'] = testdata['lngDeg_current'].shift(-1).where(testdata['phone'].eq(testdata['phone'].shift(-1)))\ntestdata['time_prev'] = testdata['millisSinceGpsEpoch'].shift(1).where(testdata['phone'].eq(testdata['phone'].shift(1)))\ntestdata['time_next'] = testdata['millisSinceGpsEpoch'].shift(-1).where(testdata['phone'].eq(testdata['phone'].shift(-1)))\n\nfor i in testdata.index:\n    if pd.isna(testdata['latDeg_prev'][i]):\n        testdata['latDeg_prev'][i] = testdata['latDeg_current'][i]\n        testdata['lngDeg_prev'][i] = testdata['lngDeg_current'][i]\n        testdata['time_prev'][i] = testdata['millisSinceGpsEpoch'][i]\n    if pd.isna(testdata['latDeg_next'][i]):\n        testdata['latDeg_next'][i] = testdata['latDeg_current'][i]\n        testdata['lngDeg_next'][i] = testdata['lngDeg_current'][i]\n        testdata['time_next'][i] = testdata['millisSinceGpsEpoch'][i]\n    \ntestdata['time_since_last_read'] = testdata['millisSinceGpsEpoch'] - testdata['time_prev']\nprint(len(testdata))\n#print(len(trainfile))\ntestdata.head()","4de30ade":"testdata['receivedSvTimeInGpsNanos'].value_counts()","51d46cec":"\n#x_cols = ['latDeg_current','lngDeg_current','heightAboveWgs84EllipsoidM','latDeg_prev', 'latDeg_next', 'lngDeg_prev', 'lngDeg_next','time_since_last_read','xSatPosM','ySatPosM','zSatPosM','receivedSvTimeInGpsNanos']\n#len(x_cols)\ntest_cols = [x for x in x_cols if x not in ('latDeg_truth','lngDeg_truth')]\nxdata_test = testdata[test_cols] #creating the x variable df\n#xdata_test.head() # dummies for the categorical variable\nxdata_test_dummies = pd.get_dummies(xdata_test, prefix = \"dum_\")\nxdata_test_dummies.columns","341a64dc":"xdata_test_dummies.head()\nxdata_test_dummies = xdata_test_dummies.fillna(0)","20a3fb85":"#arrange the columns correctly\ncol_list_train = [c for c in xtrain.columns]\nxdata_test_dummies1 = pd.DataFrame()\nfor c in xtrain.columns:\n    if c in xdata_test_dummies.columns:\n        xdata_test_dummies1[c] = xdata_test_dummies[c]\n    else:\n        xdata_test_dummies1[c] = 0\n\nxdata_test_dummies1.head()","75a8a0c2":"clen = len(xtrain.columns)\nxtraincols = [c for c in xtrain.columns]\nxtestcols = [c for c in xdata_test_dummies1.columns]\nfor i in range(clen):\n    if xtraincols[i] != xtestcols[i]:\n        print(xtestcols[i])\nif len(xtraincols) != len(xtestcols):\n    print(\"array len mismatch\")","930deda4":"xtrain_lat.columns","757dfb98":"xtest_lat.describe()","a292f33e":"cols = list(xdata_test_dummies1.columns)\nlatcols = [e for e in cols if e not in ('lngDeg_current','lngDeg_prev','lngDeg_next','latDeg_truth','lngDeg_truth')]\nlngcols = [e for e in cols if e not in ('latDeg_current','latDeg_prev','latDeg_next','latDeg_truth','lngDeg_truth')]\nxtest_lat = xdata_test_dummies[latcols]\nxtest_lng = xdata_test_dummies[lngcols]\nlat_pred = rf_lat.predict(xtest_lat)\nxdata_test['latDeg'] = pd.Series(lat_pred)\nlng_pred = rf_lng.predict(xtest_lng)\nxdata_test['lngDeg'] = pd.Series(lng_pred)\nxdata_test.head()","53d0164b":"xtest_lng.head()","345bf0a8":"#testdata.head()\n#testdata = testdata.rename({'latDeg': 'latDeg_current', 'lngDeg': 'lngDeg_current'}, axis=1)\n#testdata.head()\ntestdata['latDeg'] = xdata_test['latDeg']\ntestdata['lngDeg'] = xdata_test['lngDeg']\ncollist_sub = ['phone','millisSinceGpsEpoch','latDeg','lngDeg']\nsubdata = testdata[collist_sub]\nsubdata.head()","ba82f313":"subdata.to_csv('.\/submissions_v3.csv', index = False)","44b0d19d":"!kaggle competitions submit -c google-smartphone-decimeter-challenge -f 'submissions_v3.csv' -m \"Message\"","fdc8dc45":"Add the additional columns from derived csv files","ef83dabb":"Create the columns needed for making prediction"}}