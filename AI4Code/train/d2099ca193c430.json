{"cell_type":{"63802421":"code","e8a576fa":"code","5c1cb658":"code","a3bdf562":"code","4dd11fae":"code","073daaa1":"code","5f2f0c4e":"code","d5fe0dbb":"code","ebc165c1":"code","88a04219":"code","3780e47c":"code","73c65d94":"code","1bb49600":"code","7286fd37":"code","2b673f3a":"code","03c260ef":"code","9e2288c4":"markdown","fb6b921a":"markdown"},"source":{"63802421":"import torch\nimport torchvision.models as models\nimport torch.optim as optim\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, random_split\nimport numpy as np\nfrom os import path\nfrom matplotlib import pyplot as plt\nfrom PIL import Image","e8a576fa":"use_cuda = torch.cuda.is_available()","5c1cb658":"def init_data():\n    batch_size = 20\n    data_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n    dataset = datasets.ImageFolder('..\/input\/camerataken-images-of-printed-english-alphabet\/dataset', transform=data_transforms)\n\n    dataset_len = len(dataset)\n    train_len = int(0.6 * dataset_len)\n    valid_len = int(0.2 * dataset_len)\n    test_len = dataset_len - train_len - valid_len\n\n    train_data, valid_data, test_data = random_split(dataset, [train_len, valid_len, test_len])\n\n    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n    valid_loader = DataLoader(valid_data, batch_size=batch_size)\n    test_loader = DataLoader(test_data, batch_size=batch_size)\n\n    loaders = {'train': train_loader, 'valid': valid_loader, 'test': test_loader}\n    class_names = [item[0] for item in dataset.classes]\n    return loaders, class_names","a3bdf562":"def init_model():\n    model = models.wide_resnet50_2(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    n_inputs = model.fc.in_features\n    alphabet_length = 52\n    last_layer = torch.nn.Linear(n_inputs, alphabet_length)\n    model.fc = last_layer\n    model.fc.requires_grad = True\n    if use_cuda:\n        model = model.cuda()\n    return model","4dd11fae":"def train(n_epochs, loaders, model, use_cuda):\n    valid_loss_min = np.Inf\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.fc.parameters(), lr=0.005, momentum=0.9)\n\n    for epoch in range(1, n_epochs + 1):\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for batch_idx, (data, target) in enumerate(loaders['train']):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # update training loss\n            train_loss = train_loss + ((1 \/ (batch_idx + 1)) * (loss.data - train_loss))\n\n        ######################\n        # validate the model #\n        ######################\n        model.eval()\n        for batch_idx, (data, target) in enumerate(loaders['valid']):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # update average validation loss\n            valid_loss = valid_loss + ((1 \/ (batch_idx + 1)) * (loss.data - valid_loss))\n\n        # print training\/validation statistics\n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch,\n            train_loss,\n            valid_loss\n        ))\n\n        # save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n                valid_loss_min,\n                valid_loss))\n            torch.save(model.state_dict(), \"model.pt\")\n            valid_loss_min = valid_loss\n    # return trained model\n    return model","073daaa1":"def test(loaders, model, use_cuda):\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n    criterion = torch.nn.CrossEntropyLoss()\n    model.eval()\n    for batch_idx, (data, target) in enumerate(loaders['test']):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss\n        test_loss = test_loss + ((1 \/ (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n\n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d\/%2d)' % (\n        100. * correct \/ total, correct, total))","5f2f0c4e":"def load_trained_model(model):\n    if path.exists(\"model.pt\"):\n        model.load_state_dict(torch.load('model.pt'))\n        print(\"Model loaded successfully\")\n        return\n    print(\"Model needs to be trained first!\")\n    return","d5fe0dbb":"def predict(model, class_names, img):\n    model.eval()\n    pil_img = Image.fromarray(img.astype(float) * 255).convert('RGB')\n    pil_img = Image.open(img_path).convert('RGB')\n    pil_img.show()\n    img_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n    transformed_img = img_transforms(pil_img)\n    transformed_img = torch.unsqueeze(transformed_img, 0)\n    output = model(transformed_img)\n    _, prediction = torch.max(output, 1)\n    print(prediction)\n    return class_names[prediction.item()]","ebc165c1":"def imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))","88a04219":"loaders, class_names = init_data()","3780e47c":"dataiter = iter(loaders['train'])\nimages, indices = dataiter.next() # _ for no labels\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(20, 4))\nplot_size=20\nfor idx in np.arange(plot_size):\n    ax = fig.add_subplot(2, plot_size\/2, idx+1, xticks=[], yticks=[])\n    ax.set_title(class_names[indices[idx]], color=\"green\")\n    imshow(images[idx])","73c65d94":"model = init_model()","1bb49600":"model = train(5, loaders, model, use_cuda)","7286fd37":"load_trained_model(model)","2b673f3a":"test(loaders, model, use_cuda)","03c260ef":"dataiter = iter(loaders['test'])\nimages, indices = dataiter.next()\nmodel = model.cpu()\nmodel.eval()\noutput = model(images)\n_, preds = torch.max(output, 1)\n\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.set_title(\"{} ({})\".format(str(class_names[preds[idx].item()]), str(class_names[indices[idx].item()])),\n                 color=(\"green\" if preds[idx]==indices[idx] else \"red\"))\n    imshow(images[idx])","9e2288c4":"## Functions definitions:","fb6b921a":"# This kernel is used in the following application: [doclense](https:\/\/github.com\/naderabdalghani\/doclense-flask): A simple web app that utilizes image processing techniques to extract text from photos of computer-printed text into Microsoft Word .docx files"}}