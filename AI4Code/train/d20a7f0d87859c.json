{"cell_type":{"3a6ba0d9":"code","a8a6b4ba":"code","ff2f84ce":"code","ebc63650":"code","249d5319":"code","1340e531":"code","770de0fd":"code","e983ddb4":"code","e9447e08":"code","5f88b1e3":"code","5525e9ae":"code","590a4983":"code","6289a326":"code","1b7e9798":"code","88d24bdb":"markdown","eb5b612e":"markdown","a92388bd":"markdown","1be6fba9":"markdown","f0ea3a40":"markdown","93503e5e":"markdown","b4447bc2":"markdown","496623c8":"markdown","2e7a0247":"markdown","837851ee":"markdown","43d370a4":"markdown","8cbadb5b":"markdown","6c0a0f6a":"markdown"},"source":{"3a6ba0d9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a8a6b4ba":"data_dir = Path('..\/input\/tabular-playground-series-nov-2021')","ff2f84ce":"%time\ntrain_df = pd.read_csv(data_dir \/ \"train.csv\", \n#                        nrows=10000,\n                       index_col=0,\n                      )\ntest_df = pd.read_csv(data_dir \/ \"test.csv\",\n#                      nrows=1000,\n                     index_col=0,\n                     )\nsample_submission = pd.read_csv(data_dir \/ \"sample_submission.csv\")\n\nprint(f\"train data: Rows={train_df.shape[0]}, Columns={train_df.shape[1]}\")\nprint(f\"test data : Rows={test_df.shape[0]}, Columns={test_df.shape[1]}\")","ebc63650":"train_df.head()","249d5319":"train_df.isna().sum().sum()\n# train_df.info()","1340e531":"features = []\ncategorical_features = []\nnumerical_features = []\n\nfor feature in test_df.columns:\n    features.append(feature)\n    if test_df.dtypes[feature] == object or test_df.dtypes[feature] == 'int8':\n        categorical_features.append(feature)\n    else:\n        numerical_features.append(feature)\n\nplt.bar([1,2],[len(categorical_features),len(numerical_features)])\nplt.xticks([1,2],('Categorical','Numerical'))\nplt.show()\n\nprint(\"Categorical features:\", len(categorical_features))\nprint(\"Numerical features:\", len(numerical_features))","770de0fd":"train_df.describe().T.style.background_gradient(cmap='autumn').set_precision(4)","e983ddb4":"plt.figure(figsize=(12,8));\ntrain_df.hist(bins=12, alpha=0.5, figsize=(20,12));","e9447e08":"ax = sns.countplot(x=train_df['target'], data=train_df);\nax.set_title('Target Variable Distribution', fontsize=20, y=1.05);","5f88b1e3":"percent_ones = train_df.target.sum()\/train_df.target.count()\nprint(f\"Class: 0 = {1 - percent_ones:.4f} ; 1 = {percent_ones:.4f}\")","5525e9ae":"corr = train_df.corr()\ncorr","590a4983":"features = ['f0', 'f1', 'f2', 'f3', 'f4', 'target'] # , 'f1', 'f2'\n","6289a326":"corr = train_df[features].corr()\n","1b7e9798":"f,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(corr, annot = True, linewidths=1.5 , fmt = '.2f',ax=ax)\nplt.show()","88d24bdb":"<a id=\"missing-values\"><\/a>\n\n# **<span style=\"color:#006994;\">Missing Values<\/span>**\n\nThere are no missing values.","eb5b612e":"<a id=\"configuration\"><\/a>\n\n# **<span style=\"color:#006994;\">Configuration<\/span>**","a92388bd":"<a id=\"import-libraries\"><\/a>\n\n# **<span style=\"color:#006994;\">Import Libraries<\/span>**\n - [TOC](#toc)","1be6fba9":"<a id=\"correlation-of-features\"><\/a>\n\n# **<span style=\"color:#006994;\">Correlation of Features<\/span>**\n\n## TODO: Too many features...Fix?","f0ea3a40":"<a id=\"distributions-of-features\"><\/a>\n\n# **<span style=\"color:#006994;\">Distributions of Features<\/span>**","93503e5e":"<a id=\"load-data\"><\/a>\n\n# **<span style=\"color:#006994;\">Load Data<\/span>**","b4447bc2":"<a id=\"identify-feature-types\"><\/a>\n\n# **<span style=\"color:#006994;\">Identify Feature Types<\/span>**","496623c8":"<a id=\"distribution-of-target-variable\"><\/a>\n\n# **<span style=\"color:#006994;\">Distribution of Target Variable<\/span>**","2e7a0247":"<a id=\"toc\"><\/a>\n\n<h1 style='text-align: left;'>Table of Contents<\/h1>\n\n- [Import Libraries](#import-libraries)\n- [Configuration](#configuration)\n- [Load Data](#load-data)\n- [Missing Values](#missing-values)\n- [Identify Feature Types](#identify-feature-types)\n   - Categorical\n   - Continuous\n- [Summary Statistics](#summary-statistics)\n- [Distributions of Features](#distributions-of-features)\n   - Continuous Features\n      - Boxplots\n   - Frequency Distribution of Categorical Features\n- [Distribution of Target Variable](#distribution-of-target-variable)\n- Numerical Variables vs Target\n   - Calculate Target Ratio\n- Categorical Variables vs Target\n   - Boxplots\n- [Correlation of Features](#correlation-of-features)\n   - Correlation Chart\n   - 1 Row Table of Sorted Correlations vs Target\n   - Heatmap","837851ee":"<h1 style='text-align: center;color:#006994;'>TPS Nov 21 - EDA - FE - Playground<\/h1><br>\n\n\nMy playground to learn how to build a great EDA.  It's supposed to be a mess. Hopefully, after a few months, I will learn how to do it right.\n\nHere's what I've studied to create this notebook.\n\n# Sources\n\n- https:\/\/www.kaggle.com\/bentorchakarim\/linearity-is-the-king-eda-feature-selection\n- https:\/\/www.kaggle.com\/rigeltal\/tps-11-first-look-eda\n- https:\/\/www.kaggle.com\/mmellinger66\/titanic-eda01-biased-outliers\n- https:\/\/www.kaggle.com\/craigmthomas\/tps-oct-2021-eda\n- https:\/\/www.kaggle.com\/dailysergey\/petfinder-eda-w-b-visualization\n- https:\/\/www.kaggle.com\/prashant111\/extensive-analysis-eda-fe-modelling\n- https:\/\/www.kaggle.com\/usharengaraju\/eda-fe-tabnet-weights-and-biases","43d370a4":"## Calculate Target Ratio","8cbadb5b":"<a id=\"summary-statistics\"><\/a>\n\n# **<span style=\"color:#006994;\">Summary Statistics<\/span>**","6c0a0f6a":"# Problem Definition\n\n## Columns\n\n- f0-f99 - All continuous features\n- target - binary target\n\n## Evaluation Metric\n\nROC\n\n- "}}