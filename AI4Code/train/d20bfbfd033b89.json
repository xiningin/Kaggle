{"cell_type":{"013b0718":"code","f754ce40":"code","92684869":"code","347fb63d":"code","c031c34f":"code","f1ce67a2":"code","84e573a6":"code","4943ff1c":"code","172cedad":"code","c75d4e60":"code","db58220d":"code","378c81bd":"code","4f541b81":"code","496aae55":"code","4db74e62":"code","84871d64":"code","9fc94cdc":"code","88a3624b":"code","b91d660e":"code","91b45089":"code","90127746":"code","ef8194da":"code","94fbc69c":"code","e6c47ece":"code","3e73985d":"code","e5e9c43a":"code","daf33b6c":"code","1fcc167e":"code","f88447d5":"code","c2a2a478":"code","113fb056":"code","4edaf3ff":"code","93e3db94":"code","81f7a64b":"code","b349e3de":"code","e41fceb3":"code","d7132000":"code","7a359db2":"code","cb1b95e4":"code","d33d6b55":"code","665c759e":"code","541bd05d":"markdown","ece77a58":"markdown","481abc19":"markdown","43e56226":"markdown","31701742":"markdown","152389c8":"markdown","68fe01a5":"markdown","f01f8d58":"markdown","95a20f11":"markdown","909f5a42":"markdown","cbd8e179":"markdown","66fd1b41":"markdown","41cf4c38":"markdown"},"source":{"013b0718":"# Import all required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport keras as kr\nimport sklearn\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport itertools\nimport warnings\nwarnings.filterwarnings('ignore')","f754ce40":"data = pd.read_csv('..\/input\/El-Nino.csv', sep = '\\t')","92684869":"data.head()","347fb63d":"cols = ['Year','Janauary','February','March','April','May','June','July','August','September','October','November','December']","c031c34f":"data.columns = cols","f1ce67a2":"data.head(10)","84e573a6":"data.set_index('Year', inplace = True)\ndata.head()","4943ff1c":"data1 = data.transpose()\ndata1","172cedad":"dates = pd.date_range(start = '1950-01', freq = 'MS', periods = len(data1.columns)*12)\ndates","c75d4e60":"data_np = data1.transpose().as_matrix()\nshape = data_np.shape\ndata_np","db58220d":"data_np = data_np.reshape((shape[0] * shape[1], 1))\ndata_np.shape","378c81bd":"df = pd.DataFrame({'Mean' : data_np[:,0]})\ndf.set_index(dates, inplace = True)\ndf.head()","4f541b81":"plt.figure(figsize = (15,5))\nplt.plot(df.index, df['Mean'])\nplt.title('Yearly vs Monthly Mean')\nplt.xlabel('Year')\nplt.ylabel('Mean across Month')","496aae55":"dataset = df.values\ndataset.shape","4db74e62":"train = dataset[0:696,:]\ntest = dataset[696:,:]","84871d64":"print(\"Original data shape:\",dataset.shape)\nprint(\"Train shape:\",train.shape)\nprint(\"Test shape:\",test.shape)","9fc94cdc":"# Converting the data into MinMax Scaler because to avoid any outliers present in our dataset\nscaler = MinMaxScaler(feature_range = (0,1))\nscaled_data = scaler.fit_transform(dataset)\nscaled_data.shape","88a3624b":"x_train, y_train = [], []\nfor i in range(60,len(train)):\n    x_train.append(scaled_data[i-60:i,0])\n    y_train.append(scaled_data[i,0])\nx_train, y_train = np.array(x_train), np.array(y_train)","b91d660e":"#x_train shape\nx_train.shape","91b45089":"#y_train shape\ny_train.shape","90127746":"x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\nx_train.shape","ef8194da":" # Creating and fitting the model\nmodel = Sequential()\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1],1)))\nmodel.add(LSTM(units = 50))\nmodel.add(Dense(1))","94fbc69c":"model.compile(loss = 'mean_squared_error', optimizer = 'adam')\nmodel.fit(x_train, y_train, epochs=10, batch_size = 1, verbose = 2)","e6c47ece":"# Now Let's perform same operations that are done on train set\ninputs = df[len(df) - len(test) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs = scaler.transform(inputs)","3e73985d":"X_test = []\nfor i in range(60,inputs.shape[0]):\n    X_test.append(inputs[i-60:i,0])\nX_test = np.array(X_test)","e5e9c43a":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\nMean = model.predict(X_test)\nMean1 = scaler.inverse_transform(Mean)","daf33b6c":"# Check for the RMS error between test set and Mean1 predicted values\nrms=np.sqrt(np.mean(np.power((test-Mean1),2)))\nrms","1fcc167e":"#plotting the train, test and forecast data\ntrain = df[:696]\ntest = df[696:]\ntest['Predictions'] = Mean1\n\nplt.figure(figsize=(15,5))\nplt.plot(train['Mean'])\nplt.plot(test['Mean'], color = 'black')\nplt.plot(test['Predictions'], color = 'orange')\nplt.xlabel('Years')\nplt.ylabel('Mean')\nplt.title('Forecasting on Actual data')\n","f88447d5":"# Here we are taking steps as 2, means we have taken test size as 120 that is step=1.  \n#steps=2 means taking 120 test values and 120 future values i.e next 10 year values from test data\ntrainpred = model.predict(X_test,steps=2)","c2a2a478":"trainpred.shape","113fb056":"pred = scaler.inverse_transform(trainpred)","4edaf3ff":" # Total predicted values are 240, but now I'm printing only first 24 values\npred[0:24] ","93e3db94":"test.head()","81f7a64b":"# Now printing the test Accuracy\ntestScore = math.sqrt(mean_squared_error(test['Mean'], trainpred[:120,0]))*100\nprint('Accuracy Score: %.2f' % (testScore))","b349e3de":"# Now consider which year we want to predict the value\n# Here enter the year which should be greater than 2017 i.e above test set values\nstep_yr = 2017\nyr = int(input('Enter the Year to Predict:'))\nc = yr - step_yr\ne = c-1\nb = pred[120+(e*12) : 120+(e*12)+12].mean(axis=0)","e41fceb3":"print(b)\nif b >= 0.5 and b <= 0.9:\n    print(yr, 'is Weak El-Nino')\nelif b >= 1.0 and b <= 1.4:\n    print('It is Moderate El-Nino')\nelif b >= 1.5 and b <= 1.9:\n    print(yr, 'is Strong El-Nino')\nelif b >= 2:\n    print(yr, 'is Very Strong El-Nino')\nelif b <=-0.5 and b >= -0.9:\n    print(yr, 'is Weak La-Nina')\nelif b <= -1 and b >= -1.4:\n    print(yr, 'is Moderate La-Nina')\nelif b <= -1.5:\n    print(yr, 'is Strong La-Nina')\nelse:\n    print(yr, 'is a Moderate Year')","d7132000":"# Now plot the graph of future predicted values for that generate a date range series upto 2027\ndates1 = pd.date_range(start = '2008-01', freq = 'MS', end = '2027-12')\ndates1","7a359db2":"new_df = pd.DataFrame({'Predicted_values':pred[:,0]})\n","cb1b95e4":"new_df.set_index(dates1, inplace = True)","d33d6b55":"new_df.head()","665c759e":"# Now plot the graph to see how over train, test and future values are predicted\nplt.figure(figsize=(15,5))\nplt.plot(train['Mean'])\nplt.plot(test['Mean'], color = 'black')\nplt.plot(test['Predictions'], color = 'orange')\nplt.plot(new_df['Predicted_values'][120:], color = 'red')\nplt.xlabel('Years')\nplt.ylabel('Mean')\nplt.legend(loc = True)\nplt.title('Forecasting on Actual data')\n","541bd05d":"### As we know we use LSTM model to our data then we follow Imporvements over RNN principle\n* To see more inbrief Click [here](https:\/\/www.analyticsvidhya.com\/blog\/2017\/12\/fundamentals-of-deep-learning-introduction-to-lstm\/)","ece77a58":"### Do transpose to know, how many years are present","481abc19":"### Convert the data_np into dataframe\n* Here we are merging two series data i.e data_np and dates series into dataframe.\n* As this dataset belongs to timeseries concept, we apply dates series as index to our dataframe.","43e56226":"## Data Preprocessing\n### Replace all column names by overwritting on it","31701742":"## This project is mainly concerned about Weather Prediction of an year is El-Nina or La-Nina year using LSTM Model.\nTake aways from this project is\n* This project is helpful to build the skills in Data Analysis for new programmers.\n* Using Time Series for Weather Prediction.\n* Data Preprocessing.\n* Modelling LSTM.","152389c8":"### Generate the date_range series. It is because converting whole 12 attributes into single series of each month by considering length of data1.columns multiplied by 12.","68fe01a5":"### Now Let's plot how our data looks like","f01f8d58":"### Here we are splitting the data into train and test set","95a20f11":"### Inorder to check how these values are adjusted, you can check from [here](https:\/\/ggweather.com\/enso\/oni.htm)\n","909f5a42":"### Set Index as Year, it is because by seeing the data one can understand is the problem is related to Time Series Forecasting","cbd8e179":"### Convert the dataframe into matrix ","66fd1b41":"### LSTM Modelling","41cf4c38":"### Let's convert the matrix size of 68 x 12 into column vector "}}