{"cell_type":{"62fc4211":"code","d2a649f7":"code","26c1bd00":"code","efc234c5":"code","aa65c188":"code","e0e8480c":"code","4c41387c":"code","10be0b1f":"code","6040bf16":"code","e6470cd2":"code","7958e4c7":"code","1e87d1e4":"code","73932ce5":"code","4e81f705":"code","15e9a1d6":"code","53675fe2":"code","442f9c9c":"code","230a59ae":"code","e16a2ef7":"code","5dc919b9":"code","b15003fd":"code","fe686dc1":"code","ad9e7538":"code","522aec75":"code","44d02ead":"code","c526e732":"code","16227ef3":"code","fd7996bc":"code","0c647188":"code","d78da30a":"code","37bf16d4":"code","60b1c1f7":"markdown","b451d771":"markdown","167dc379":"markdown","32bd6847":"markdown","22786c7d":"markdown","3249ef89":"markdown","0a8ac56b":"markdown","c2c3911c":"markdown","2b4092e0":"markdown","4706eaea":"markdown","2fd0da5f":"markdown","f9f40236":"markdown","3f528cb4":"markdown","90f94dff":"markdown","ae38f65c":"markdown","b76842e5":"markdown","7ac764f1":"markdown","291cfb91":"markdown","f94179b4":"markdown","66dc0f85":"markdown","77528a86":"markdown","107e780b":"markdown","79463d13":"markdown"},"source":{"62fc4211":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2a649f7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom sklearn.metrics import mean_absolute_error as mae","26c1bd00":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","efc234c5":"def reduce_memory_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))    \n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","aa65c188":"data = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ndata = reduce_memory_usage(data)\ndata.head()","e0e8480c":"data.shape","4c41387c":"data.isnull().sum()","10be0b1f":"data.info()","6040bf16":"data.describe()","e6470cd2":"plt.figure(figsize=(8,6))\nsns.heatmap(data.corr(), cmap='cool')","7958e4c7":"cat_col = []\nnum_col = []\nfor i in data.columns:\n    if data[i].value_counts().count() > 10:\n        num_col.append(i)\n    else:\n        cat_col.append(i)\nprint(f'categorical columns: {cat_col}')\nprint(f'numerical columns: {num_col}')","1e87d1e4":"fig, ax = plt.subplots(1,3,figsize=(12,5))\nj=0\nfor i in cat_col:\n    sns.countplot(data[i], palette='cool', ax=ax[j])\n    j+=1\nfig.suptitle('Countplot of Categorical Data')","73932ce5":"num_col = num_col[2:]\nnum_col","4e81f705":"fig, ax = plt.subplots(1,3, figsize=(18,5))\nj=0\nfor i in num_col:\n    sns.histplot(data[i], ax=ax[j])\n    j+=1\nfig.suptitle('Histplot of Numerical Data')","15e9a1d6":"fig, ax = plt.subplots(1,3, figsize=(18,5))\nj=0\nfor i in num_col:\n    sns.boxplot(data[i], ax=ax[j], palette='cool')\n    j+=1\nfig.suptitle('Boxplot of Numerical Data')","53675fe2":"train = data.copy()","442f9c9c":"# fig, ax = plt.subplots(1,2, figsize=(12,5))\n# sns.distplot(train['pressure'], ax=ax[0])\n\n# train['pressure'] = np.where(train['pressure'] < 0, 0, train['pressure'])\n# train['pressure'] = np.sqrt(np.sqrt(train['pressure']))\n\n# sns.distplot(train['pressure'], ax=ax[1])","230a59ae":"def create_new_feat(df):\n    df[\"u_in_sum\"]         = df.groupby(\"breath_id\")[\"u_in\"].transform(\"sum\")\n    df[\"u_in_std\"]         = df.groupby(\"breath_id\")[\"u_in\"].transform(\"std\")\n    df[\"u_in_min\"]         = df.groupby(\"breath_id\")[\"u_in\"].transform(\"min\")\n    df[\"u_in_first\"]       = df.groupby(\"breath_id\")[\"u_in\"].transform(\"first\")\n    df[\"u_in_last\"]        = df.groupby(\"breath_id\")[\"u_in\"].transform(\"last\")\n    df[\"time_passed\"]      = df.groupby(\"breath_id\")[\"time_step\"].diff()\n    df['area']             = df['time_step'] * df['u_in']\n    df['area_2']           = df.groupby('breath_id')['area'].cumsum()\n    df['u_in_cumsum']      = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['u_in_lag1']        = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1']       = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1']   = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1']  = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2']        = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2']       = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2']   = df.groupby('breath_id')['u_in'].shift(-2) \n    df['u_out_lag_back2']  = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3']        = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3']       = df.groupby('breath_id')['u_out'].shift(3) \n    df['u_in_lag_back3']   = df.groupby('breath_id')['u_in'].shift(-3) \n    df['u_out_lag_back3']  = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4']        = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4']       = df.groupby('breath_id')['u_out'].shift(4) \n    df['u_in_lag_back4']   = df.groupby('breath_id')['u_in'].shift(-4) \n    df['u_out_lag_back4']  = df.groupby('breath_id')['u_out'].shift(-4) \n    \n    df = df.fillna(0)\n    \n    df['breath_id__u_in__diffmax']  = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    df['cross']                     = df['u_in']*df['u_out']\n    df['cross2']                    = df['time_step']*df['u_out']\n    df['R']                         = df['R'].astype(str)\n    df['C']                         = df['C'].astype(str)\n    df['R__C']                      = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n#     df['u_in_lag5']  = df.groupby('breath_id')['u_in'].shift(5)  #\n#     df['u_in_lag6']  = df.groupby('breath_id')['u_in'].shift(6)  #\n#     df['u_in_lag7']  = df.groupby('breath_id')['u_in'].shift(7)  #\n#     df['u_in_lag8']  = df.groupby('breath_id')['u_in'].shift(8)  #\n#     df['u_in_lag9']  = df.groupby('breath_id')['u_in'].shift(9)  #\n#     df['u_in_lag10'] = df.groupby('breath_id')['u_in'].shift(10) #\n#     df['u_in_lag11'] = df.groupby('breath_id')['u_in'].shift(11) #\n#     df['u_in_lag12'] = df.groupby('breath_id')['u_in'].shift(12) #\n#     df['u_in_lag13'] = df.groupby('breath_id')['u_in'].shift(13) #\n#     df['u_in_lag14'] = df.groupby('breath_id')['u_in'].shift(14) #\n#     df['u_in_lag15'] = df.groupby('breath_id')['u_in'].shift(15) #\n#     df['u_in_lag16'] = df.groupby('breath_id')['u_in'].shift(16) #\n#     df['u_in_lag17'] = df.groupby('breath_id')['u_in'].shift(17) #\n#     df['u_in_lag18'] = df.groupby('breath_id')['u_in'].shift(18) #\n#     df['u_in_lag19'] = df.groupby('breath_id')['u_in'].shift(19) #\n#     df['u_in_lag20'] = df.groupby('breath_id')['u_in'].shift(20) #\n    df['time_diff']  = (df['time_step']).groupby(df['breath_id']).diff(1)\n    df['time_diff2'] = (df['time_step']).groupby(df['breath_id']).diff(2)\n    df['time_diff3'] = (df['time_step']).groupby(df['breath_id']).diff(3)\n    df['time_diff4'] = (df['time_step']).groupby(df['breath_id']).diff(4)\n    df['time_diff5'] = (df['time_step']).groupby(df['breath_id']).diff(5)\n    df['time_diff6'] = (df['time_step']).groupby(df['breath_id']).diff(6)\n    df['time_diff7'] = (df['time_step']).groupby(df['breath_id']).diff(7)\n    df['time_diff8'] = (df['time_step']).groupby(df['breath_id']).diff(8)\n    df['u_in_diff1']                = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1']               = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2']                = df['u_in'] - df['u_in_lag2'] \n    df['u_out_diff2']               = df['u_out'] - df['u_out_lag2'] \n    df['u_in_diff3']                = df['u_in'] - df['u_in_lag3'] \n    df['u_out_diff3']               = df['u_out'] - df['u_out_lag3'] \n    df['u_in_diff4']                = df['u_in'] - df['u_in_lag4'] \n    df['u_out_diff4']               = df['u_out'] - df['u_out_lag4'] \n    return df","e16a2ef7":"train = create_new_feat(train)\ntrain = train.fillna(train.min())\ntrain.head()","5dc919b9":"train = reduce_memory_usage(train)","b15003fd":"test_data = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\ntest_data.head()","fe686dc1":"fig, ax = plt.subplots(1,2, figsize=(18,5))\nj=0\nfor i in num_col[:2]:\n    sns.histplot(test_data[i], ax=ax[j])\n    j+=1\nfig.suptitle('Histplot of Numerical Data')","ad9e7538":"test_data = create_new_feat(test_data)\ntest_data = test_data.fillna(test_data.min())\ntest_data.head()","522aec75":"test_data = reduce_memory_usage(test_data)","44d02ead":"from sklearn.preprocessing import RobustScaler\ntargets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest_data = test_data.drop(['id', 'breath_id'], axis=1)\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest_data = RS.transform(test_data)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest_data = test_data.reshape(-1, 80, train.shape[-1])","c526e732":"idx_len = round(0.90*len(train))\nX_train, X_valid = train[0:idx_len], train[idx_len:]\ny_train, y_valid = targets[0:idx_len], targets[idx_len:]","16227ef3":"EPOCH = 500\nBATCH_SIZE = 256\n\nlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\nes = EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1, mode=\"min\", restore_best_weights=True)\n\nwith strategy.scope():\n    model = keras.models.Sequential([\n    keras.layers.Input(shape=train.shape[-2:]),    \n    keras.layers.Bidirectional(keras.layers.LSTM(2048, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n   # keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n    keras.layers.Dense(64, activation='selu'),\n    keras.layers.Dense(1),\n    ])\n\nmodel.compile(optimizer=\"adam\", loss=\"mae\")\n\nhistory = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es])","fd7996bc":"plt.figure(figsize=(15,3))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.show()","0c647188":"pred = model.predict(test_data, batch_size=BATCH_SIZE)","d78da30a":"# sample = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\n# sample['id'] = test_data['id']\n# sample['pressure'] = pd.DataFrame({'pressure': pred[:]})\n# sample.head()","37bf16d4":"sample = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\nsample['pressure'] = pred.squeeze().reshape(-1, 1).squeeze()\n\nq1 = sample['pressure'].quantile(0.001)\nq2 = sample['pressure'].quantile(0.999)\nsample['pressure'] = sample['pressure'].apply(lambda x: x if x>q1 else x*0.77)\nsample['pressure'] = sample['pressure'].apply(lambda x: x if x<q2 else x*1.1)\nsample.to_csv('submission_LSTM.csv', index=False)","60b1c1f7":"## Splitting of categorical and numerical data.","b451d771":"> I can see a skewness in 'pressure', which is our target variable.\n\n> And, a great outliers in 'u_in' and 'pressure'.","167dc379":"> There is no null value","32bd6847":"## Creating New Features","22786c7d":"We can see a strong correaltion between :\n> 'pressure' and 'time_step'\n\n> 'pressure' and 'u_out'","3249ef89":"## Model","0a8ac56b":"![](https:\/\/raw.githubusercontent.com\/google\/deluca-lung\/main\/assets\/2020-10-02%20Ventilator%20diagram.svg)","c2c3911c":"> It is always good practice to work with copied dataset. \u2713\u2713","2b4092e0":"## TPU","4706eaea":"## Removing Skewness of target variable.\n#### Methods tried :-\n1. Log Transformation\n2. Log + 1 Transformation\n3. Square Root\n4. Double Square Root --> This works best.","2fd0da5f":"## Thank you!!!\n## Hope you enjoyed this notebook. \ud83d\ude0a","f9f40236":"## Outliers\n> Let us have a look at outliers now, by using boxplot.","3f528cb4":"#### Numerical Data","90f94dff":"#### Categorical Data","ae38f65c":"## Columns\n**id** - globally-unique time step identifier across an entire file\n\n**breath_id** - globally-unique time step for breaths\n\n**R** - lung attribute indicating how restricted the airway is (in cmH2O\/L\/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n\n**C** - lung attribute indicating how compliant the lung is (in mL\/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloon\u2019s latex, with higher C having thinner latex and easier to blow.\ntime_step - the actual time stamp.\n\n**u_in** - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n\n**u_out** - the control input for the exploratory solenoid valve. Either 0 or 1.\n\n**pressure** - the airway pressure measured in the respiratory circuit, measured in cmH2O.","b76842e5":"## Splitting of dependent and independent variable.","7ac764f1":"## Prediction","291cfb91":"Removing 'id' and 'breath_id' from numerical column list.","f94179b4":"![](https:\/\/bookdown.org\/ejvanholm\/Text-Quant\/images\/DataTypes.png)","66dc0f85":"## Working with Test Data","77528a86":"#### Creating New Features","107e780b":"## Custom Activation Function","79463d13":"### As previous versions failed because of my notebook tried to allocate more memory than is available.\n> This function helps in reducing memory usage by changing unnecessary data type.\n\n> You could learn more about it [here](https:\/\/www.kaggle.com\/questions-and-answers\/282144)"}}