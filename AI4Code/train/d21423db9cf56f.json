{"cell_type":{"28578736":"code","a2e5ba52":"code","019d9c07":"code","9d6cf8bd":"code","62ae43a8":"code","fc55d9b4":"code","6bcc9775":"code","8ead0178":"code","254039eb":"code","184ac61a":"code","f25bc8cf":"code","53bb1d2e":"code","efcb9a8f":"code","9c6153f2":"code","29fe076a":"code","f6360729":"code","1406ad0f":"code","9674c5bb":"code","9181b4e8":"code","b76e86ac":"code","8ebf4eb3":"code","8ca1aec8":"code","dd6bf4f6":"code","e9bf7d50":"code","358d1851":"code","73ffc290":"code","29c090c5":"code","16ddc97d":"code","37be4b79":"code","8fff080f":"code","1a7d1419":"code","575400b4":"code","95628914":"code","a9c4e253":"code","850d0f68":"code","d4e0c61a":"code","ddb3e94a":"code","3b3950c5":"code","9d857bd3":"code","3b50d0dc":"code","429b52d4":"code","9e2881ce":"code","c81ceca3":"code","aec842ca":"code","b5a6895a":"code","a13590a3":"code","99dc4fb0":"code","17459adf":"code","ac87b5ff":"code","b36b4322":"code","fca5dfb3":"code","1fbed672":"code","7dcf5086":"code","7432145b":"code","fbd023b2":"code","fa0db829":"code","6bbfb817":"code","178f7db4":"code","8aaa84fc":"code","8b17db81":"markdown","141ad3ba":"markdown","93b8a128":"markdown","1171a8ee":"markdown","d03b4c48":"markdown","ba20fb96":"markdown","04d8dc96":"markdown"},"source":{"28578736":"# import required packages\n\nimport pandas as pd \nimport numpy as np\nimport os, gc, time, warnings\n\nfrom scipy.misc import imread\nfrom scipy import sparse\nimport scipy.stats as ss\nfrom scipy.sparse import csr_matrix, hstack, vstack\n\nimport matplotlib.pyplot as plt, matplotlib.gridspec as gridspec \nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom PIL import Image\nimport matplotlib_venn as venn\nimport pydot, graphviz\nfrom IPython.display import Image\n\nimport string, re, nltk, collections\nfrom nltk.util import ngrams\nfrom nltk.corpus import stopwords\nimport spacy\nfrom nltk import pos_tag\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import TweetTokenizer   \n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_is_fitted\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.models import Model, Sequential\nfrom keras.utils import plot_model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization\nfrom keras.layers import GRU, LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import Callback","a2e5ba52":"# settings\n\nos.environ['OMP_NUM_THREADS'] = '4'\nstart_time = time.time()\ncolor = sns.color_palette()\nsns.set_style(\"dark\")\nwarnings.filterwarnings(\"ignore\")\n\neng_stopwords = set(stopwords.words(\"english\"))\nlem = WordNetLemmatizer()\nps = PorterStemmer()\ntokenizer = TweetTokenizer()\n\n%matplotlib inline","019d9c07":"# print the names of files available in the root directory\nprint(os.listdir('..\/input'))","9d6cf8bd":"# import the dataset\n\ntrain = pd.read_csv('..\/input\/nslkdd-dataset\/KDDTrain.csv')\ntest = pd.read_csv('..\/input\/nslkdd-dataset\/KDDTest.csv')","62ae43a8":"print(\"Training data information...\")\ntrain.info()","fc55d9b4":"train.head(10)","6bcc9775":"print('Test data information...')\ntest.info()","8ead0178":"# obtaining a new target variable for each attack class\n\nattack_classes = ['back', 'buffer_overflow', 'ftp_write', 'guess_passwd', 'imap', 'ipsweep', 'land', \n                  'loadmodule', 'multihop', 'neptune', 'nmap', 'normal', 'perl', 'phf', 'pod', 'portsweep',\n                  'rootkit', 'satan', 'smurf', 'teardrop', 'warezmaster']\n\ndos_classes = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop']\nprobe_classes = ['ipsweep', 'satan', 'nmap', 'portsweep']\nr2l_classes = ['ftp_write', 'guess_passwd', 'imap', 'phf', 'multihop', 'wazermaster']\nu2r_classes = ['buffer_overflow', 'loadmodule', 'rootkit', 'perl']\nnormal_classes = ['normal']\n\ntrain_label = pd.DataFrame()\ntest_label = pd.DataFrame()\n\nfor attack_type in attack_classes:\n    train_label[attack_type] = train['attack_class'].apply(lambda x : int(x == attack_type))\n    test_label[attack_type] = test['attack_class'].apply(lambda x : int(x == attack_type))    ","254039eb":"# extracting numerical labels from categorical data\n\nencoder = LabelEncoder()\n\ntrain['protocol_type_label'] = encoder.fit_transform(train['protocol_type'])\ntest['protocol_type_label'] = encoder.fit_transform(test['protocol_type'])\n\ntrain['service_label'] = encoder.fit_transform(train['service'])\ntest['service_label'] = encoder.fit_transform(test['service'])\n\ntrain['flag_label'] = encoder.fit_transform(train['flag'])\ntest['flag_label'] = encoder.fit_transform(test['flag'])","184ac61a":"# removing useless columns\n\ntrain.drop(['attack_class', 'num_learners'], axis = 1, inplace = True)\ntest.drop(['attack_class', 'num_learners'], axis = 1, inplace = True)","f25bc8cf":"print(\"Training data information...\")\ntrain.info()","53bb1d2e":"# creating dataframes for storing training data for stacked model\n\nstacked_train_df = {}\nstacked_test_df = {}\n\nfor attack_type in attack_classes:\n    stacked_train_df[attack_type] = pd.DataFrame()\n    stacked_test_df[attack_type] = pd.DataFrame()","efcb9a8f":"# preparing data for training on models\n\nx_train = train.copy(deep = True)\nx_train.drop(['protocol_type', 'service', 'flag'], axis = 1, inplace = True)\n\nx_test = test.copy(deep = True)\nx_test.drop(['protocol_type', 'service', 'flag'], axis = 1, inplace = True)","9c6153f2":"# logistic regression classifier\n\ndef getLRClf():\n    clf = LogisticRegression(C = 0.2, solver = 'liblinear')\n    return clf","29fe076a":"# training on logistic regression classifier\n\nlr_accuracy = []\nlr_precision = []\nlr_recall = []\nlr_tn = []\nlr_fp = []\nlr_fn = []\nlr_tp = []\nlr_dos_accuracy = []\nlr_probe_accuracy = []\nlr_r2l_accuracy = []\nlr_u2r_accuracy = []\nlr_normal_accuracy = []\n\nfor attack_type in attack_classes:\n    clf = getLRClf()\n    clf.fit(x_train, train_label[attack_type])\n    y_pred = clf.predict(x_test)\n    stacked_train_df[attack_type]['logistic_regression'] = clf.predict(x_train)\n    stacked_test_df[attack_type]['logistic_regression'] = y_pred\n    lr_accuracy += [accuracy_score(test_label[attack_type], y_pred)]\n    if attack_type in dos_classes:\n        lr_dos_accuracy += [lr_accuracy[-1]]\n    if attack_type in probe_classes:\n        lr_probe_accuracy += [lr_accuracy[-1]]\n    if attack_type in r2l_classes:\n        lr_r2l_accuracy += [lr_accuracy[-1]]\n    if attack_type in u2r_classes:\n        lr_u2r_accuracy += [lr_accuracy[-1]]\n    if attack_type in normal_classes:\n        lr_normal_accuracy += [lr_accuracy[-1]]\n    lr_precision += [precision_score(test_label[attack_type], y_pred)]\n    lr_recall += [recall_score(test_label[attack_type], y_pred)]\n    cm = confusion_matrix(test_label[attack_type], y_pred).ravel()\n    if len(cm) > 1:\n        lr_tn += [cm[0]]\n        lr_fp += [cm[1]]\n        lr_fn += [cm[2]]\n        lr_tp += [cm[3]]\n    else:\n        lr_tn += [0]\n        lr_fp += [0]\n        lr_fn += [0]\n        lr_tp += [0]\n    \nmean_lr_accuracy = np.mean(lr_accuracy)\nmean_lr_precision = np.mean(lr_precision)\nmean_lr_recall = np.mean(lr_recall)\n\nprint(\"Logistic Regression Classifier...\")\nprint(\"Mean Accuracy score : \" + str(mean_lr_accuracy))\nprint(\"Mean Precision score : \" + str(mean_lr_precision))\nprint(\"Mean Recall score : \" + str(mean_lr_recall))\nprint(\"Mean accuracy DOS attacks : \" + str(np.mean(lr_dos_accuracy)))\nprint(\"Mean accuracy Probe attacks : \" + str(np.mean(lr_probe_accuracy)))\nprint(\"Mean accuracy R2L attacks : \" + str(np.mean(lr_r2l_accuracy)))\nprint(\"Mean accuracy U2R attacks : \" + str(np.mean(lr_u2r_accuracy)))\nprint(\"Mean accuracy Normal class : \" + str(np.mean(lr_normal_accuracy)))","f6360729":"# graphical comparison\n\nn_groups = 4\nscores = [np.mean(lr_dos_accuracy), np.mean(lr_probe_accuracy), np.mean(lr_r2l_accuracy), np.mean(lr_u2r_accuracy)]\nscores = [item-0.90 for item in scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, scores, bar_width, alpha = opacity, align = 'center', label = 'Average Accuracy')\n\nrows = ['DoS', 'Probe', 'R2L', 'U2R']\n\nplt.xlabel('Attack Category')\nplt.ylabel('Average Accuracy Score')\nplt.title('Accuracy scores for different attack categories using LR Classifier')\nplt.xticks(index, rows)\nplt.yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10], [0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","1406ad0f":"# SGD classifier\n\ndef getSGDClf():\n    clf = SGDClassifier(max_iter = 1000, tol = 1e-3, learning_rate = 'optimal')\n    return clf","9674c5bb":"# training on SGD classifier\n\nsgd_accuracy = []\nsgd_precision = []\nsgd_recall = []\nsgd_tn = []\nsgd_fp = []\nsgd_fn = []\nsgd_tp = []\nsgd_dos_accuracy = []\nsgd_probe_accuracy = []\nsgd_r2l_accuracy = []\nsgd_u2r_accuracy = []\nsgd_normal_accuracy = []\n\nfor attack_type in attack_classes:\n    clf = getSGDClf()\n    clf.fit(x_train, train_label[attack_type])\n    y_pred = clf.predict(x_test)\n    stacked_train_df[attack_type]['sgd'] = clf.predict(x_train)\n    stacked_test_df[attack_type]['sgd'] = y_pred\n    sgd_accuracy += [accuracy_score(test_label[attack_type], y_pred)]\n    if attack_type in dos_classes:\n        sgd_dos_accuracy += [sgd_accuracy[-1]]\n    if attack_type in probe_classes:\n        sgd_probe_accuracy += [sgd_accuracy[-1]]\n    if attack_type in r2l_classes:\n        sgd_r2l_accuracy += [sgd_accuracy[-1]]\n    if attack_type in u2r_classes:\n        sgd_u2r_accuracy += [sgd_accuracy[-1]]\n    if attack_type in normal_classes:\n        sgd_normal_accuracy += [sgd_accuracy[-1]]\n    sgd_precision += [precision_score(test_label[attack_type], y_pred)]\n    sgd_recall += [recall_score(test_label[attack_type], y_pred)]\n    cm = confusion_matrix(test_label[attack_type], y_pred).ravel()\n    if len(cm) > 1:\n        sgd_tn += [cm[0]]\n        sgd_fp += [cm[1]]\n        sgd_fn += [cm[2]]\n        sgd_tp += [cm[3]]\n    else:\n        sgd_tn += [0]\n        sgd_fp += [0]\n        sgd_fn += [0]\n        sgd_tp += [0]\n    \nmean_sgd_accuracy = np.mean(sgd_accuracy)\nmean_sgd_precision = np.mean(sgd_precision)\nmean_sgd_recall = np.mean(sgd_recall)\n    \nprint(\"SGD Classifier...\")\nprint(\"Mean Accuracy score : \" + str(mean_sgd_accuracy))\nprint(\"Mean Precision score : \" + str(mean_sgd_precision))\nprint(\"Mean Recall score : \" + str(mean_sgd_recall))\nprint(\"Mean accuracy DOS attacks : \" + str(np.mean(sgd_dos_accuracy)))\nprint(\"Mean accuracy Probe attacks : \" + str(np.mean(sgd_probe_accuracy)))\nprint(\"Mean accuracy R2L attacks : \" + str(np.mean(sgd_r2l_accuracy)))\nprint(\"Mean accuracy U2R attacks : \" + str(np.mean(sgd_u2r_accuracy)))\nprint(\"Mean accuracy Normal class : \" + str(np.mean(sgd_normal_accuracy)))","9181b4e8":"# graphical comparison\n\nn_groups = 4\nscores = [np.mean(sgd_dos_accuracy), np.mean(sgd_probe_accuracy), np.mean(sgd_r2l_accuracy), np.mean(sgd_u2r_accuracy)]\nscores = [item-0.90 for item in scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, scores, bar_width, alpha = opacity, align = 'center', label = 'Average Accuracy')\n\nrows = ['DoS', 'Probe', 'R2L', 'U2R']\n\nplt.xlabel('Attack Category')\nplt.ylabel('Average Accuracy Score')\nplt.title('Accuracy scores for different attack categories using SGD Classifier')\nplt.xticks(index, rows)\nplt.yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10], [0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","b76e86ac":"# lgbm classifier\n\nimport lightgbm as lgb\n\ndef getlgbclf(d_train, valid_sets):\n    params = {'learning_rate': 0.2, 'application': 'binary', 'num_leaves': 31, 'verbosity': -1,\n          'bagging_fraction': 0.8, 'feature_fraction': 0.6, 'nthread': 4, 'lambda_l1': 1, 'lambda_l2': 1}\n    \n    clf = lgb.train(params, train_set = d_train, num_boost_round = 300, early_stopping_rounds = 100,\n                    valid_sets = valid_sets, verbose_eval = False)   \n    \n    return clf","8ebf4eb3":"# training on lgbm classifier\n\nlgb_accuracy = []\nlgb_precision = []\nlgb_recall = []\nlgb_tn = []\nlgb_fp = []\nlgb_fn = []\nlgb_tp = []\nlgb_dos_accuracy = []\nlgb_probe_accuracy = []\nlgb_r2l_accuracy = []\nlgb_u2r_accuracy = []\nlgb_normal_accuracy = []\n\nfor attack_type in attack_classes:\n    d_train = lgb.Dataset(x_train, label = train_label[attack_type])\n    d_test = lgb.Dataset(x_test, label = test_label[attack_type])\n    valid_sets = [d_train, d_test]\n    clf = getlgbclf(d_train, valid_sets)\n    y_pred = (clf.predict(x_test) >= 0.5).astype(int)\n    stacked_train_df[attack_type]['lgbm'] = (clf.predict(x_train) >= 0.5).astype(int)\n    stacked_test_df[attack_type]['lgbm'] = y_pred\n    lgb_accuracy += [accuracy_score(test_label[attack_type], y_pred)]\n    if attack_type in dos_classes:\n        lgb_dos_accuracy += [lgb_accuracy[-1]]\n    if attack_type in probe_classes:\n        lgb_probe_accuracy += [lgb_accuracy[-1]]\n    if attack_type in r2l_classes:\n        lgb_r2l_accuracy += [lgb_accuracy[-1]]\n    if attack_type in u2r_classes:\n        lgb_u2r_accuracy += [lgb_accuracy[-1]]\n    if attack_type in normal_classes:\n        lgb_normal_accuracy += [lgb_accuracy[-1]]\n    lgb_precision += [precision_score(test_label[attack_type], y_pred)]\n    lgb_recall += [recall_score(test_label[attack_type], y_pred)]\n    cm = confusion_matrix(test_label[attack_type], y_pred).ravel()\n    if len(cm) > 1:\n        lgb_tn += [cm[0]]\n        lgb_fp += [cm[1]]\n        lgb_fn += [cm[2]]\n        lgb_tp += [cm[3]]\n    else:\n        lgb_tn += [0]\n        lgb_fp += [0]\n        lgb_fn += [0]\n        lgb_tp += [0]\n    \nmean_lgb_accuracy = np.mean(lgb_accuracy)\nmean_lgb_precision = np.mean(lgb_precision)\nmean_lgb_recall = np.mean(lgb_recall)\n    \nprint(\"LGBM Classifier...\")\nprint(\"Mean Accuracy score : \" + str(mean_lgb_accuracy))\nprint(\"Mean Precision score : \" + str(mean_lgb_precision))\nprint(\"Mean Recall score : \" + str(mean_lgb_recall))\nprint(\"Mean accuracy DOS attacks : \" + str(np.mean(lgb_dos_accuracy)))\nprint(\"Mean accuracy Probe attacks : \" + str(np.mean(lgb_probe_accuracy)))\nprint(\"Mean accuracy R2L attacks : \" + str(np.mean(lgb_r2l_accuracy)))\nprint(\"Mean accuracy U2R attacks : \" + str(np.mean(lgb_u2r_accuracy)))\nprint(\"Mean accuracy Normal class : \" + str(np.mean(lgb_normal_accuracy)))","8ca1aec8":"# graphical comparison\n\nn_groups = 4\nscores = [np.mean(lgb_dos_accuracy), np.mean(lgb_probe_accuracy), np.mean(lgb_r2l_accuracy), np.mean(lgb_u2r_accuracy)]\nscores = [item-0.90 for item in scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, scores, bar_width, alpha = opacity, align = 'center', label = 'Average Accuracy')\n\nrows = ['DoS', 'Probe', 'R2L', 'U2R']\n\nplt.xlabel('Attack Category')\nplt.ylabel('Average Accuracy Score')\nplt.title('Accuracy scores for different attack categories using LGBM Classifier')\nplt.xticks(index, rows)\nplt.yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10], [0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","dd6bf4f6":"# XGBoost classifier\n\nimport xgboost as xgb\n\ndef getxgbclf(d_train, eval_list):\n    params = {'booster' : 'gbtree', 'nthread' : 4, 'eta' : 0.2, 'max_depth' : 6, 'min_child_weight' : 4,\n          'subsample' : 0.7, 'colsample_bytree' : 0.7, 'objective' : 'binary:logistic'}\n\n    clf = xgb.train(params, d_train, num_boost_round = 300, early_stopping_rounds = 100, \n                    evals = evallist, verbose_eval = False)\n    return clf","e9bf7d50":"# training on XGBoost classifier\n\nxgb_accuracy = []\nxgb_precision = []\nxgb_recall = []\nxgb_tn = []\nxgb_fp = []\nxgb_fn = []\nxgb_tp = []\nxgb_dos_accuracy = []\nxgb_probe_accuracy = []\nxgb_r2l_accuracy = []\nxgb_u2r_accuracy = []\nxgb_normal_accuracy = []\n\nfor attack_type in attack_classes:\n    d_train = xgb.DMatrix(x_train, label = train_label[attack_type])\n    d_test = xgb.DMatrix(x_test, label = test_label[attack_type])\n    evallist = [(d_train, 'train'), (d_test, 'valid')]\n    clf = getxgbclf(d_train, evallist)\n    y_pred = (clf.predict(d_test) >= 0.5).astype(int)\n    stacked_train_df[attack_type]['xgb'] = (clf.predict(d_train) >= 0.5).astype(int)\n    stacked_test_df[attack_type]['xgb'] = y_pred\n    xgb_accuracy += [accuracy_score(test_label[attack_type], y_pred)]\n    if attack_type in dos_classes:\n        xgb_dos_accuracy += [xgb_accuracy[-1]]\n    if attack_type in probe_classes:\n        xgb_probe_accuracy += [xgb_accuracy[-1]]\n    if attack_type in r2l_classes:\n        xgb_r2l_accuracy += [xgb_accuracy[-1]]\n    if attack_type in u2r_classes:\n        xgb_u2r_accuracy += [xgb_accuracy[-1]]\n    if attack_type in normal_classes:\n        xgb_normal_accuracy += [xgb_accuracy[-1]]\n    xgb_precision += [precision_score(test_label[attack_type], y_pred)]\n    xgb_recall += [recall_score(test_label[attack_type], y_pred)]\n    cm = confusion_matrix(test_label[attack_type], y_pred).ravel()\n    if len(cm) > 1:\n        xgb_tn += [cm[0]]\n        xgb_fp += [cm[1]]\n        xgb_fn += [cm[2]]\n        xgb_tp += [cm[3]]\n    else:\n        xgb_tn += [0]\n        xgb_fp += [0]\n        xgb_fn += [0]\n        xgb_tp += [0]\n    \nmean_xgb_accuracy = np.mean(xgb_accuracy)\nmean_xgb_precision = np.mean(xgb_precision)\nmean_xgb_recall = np.mean(xgb_recall)\n    \nprint(\"XGBoost Classifier...\")\nprint(\"Mean Accuracy score : \" + str(mean_xgb_accuracy))\nprint(\"Mean Precision score : \" + str(mean_xgb_precision))\nprint(\"Mean Recall score : \" + str(mean_xgb_recall))\nprint(\"Mean accuracy DOS attacks : \" + str(np.mean(xgb_dos_accuracy)))\nprint(\"Mean accuracy Probe attacks : \" + str(np.mean(xgb_probe_accuracy)))\nprint(\"Mean accuracy R2L attacks : \" + str(np.mean(xgb_r2l_accuracy)))\nprint(\"Mean accuracy U2R attacks : \" + str(np.mean(xgb_u2r_accuracy)))\nprint(\"Mean accuracy Normal class : \" + str(np.mean(xgb_normal_accuracy)))","358d1851":"# graphical comparison\n\nn_groups = 4\nscores = [np.mean(xgb_dos_accuracy), np.mean(xgb_probe_accuracy), np.mean(xgb_r2l_accuracy), np.mean(xgb_u2r_accuracy)]\nscores = [item-0.90 for item in scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, scores, bar_width, alpha = opacity, align = 'center', label = 'Average Accuracy')\n\nrows = ['DoS', 'Probe', 'R2L', 'U2R']\n\nplt.xlabel('Attack Category')\nplt.ylabel('Average Accuracy Score')\nplt.title('Accuracy scores for different attack categories using XGBoost Classifier')\nplt.xticks(index, rows)\nplt.yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10], [0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","73ffc290":"# Deep Neural Network classifier\n\ndef getdnnclf():\n    clf = Sequential()\n    clf.add(Dense(1024, input_dim = 41, activation = 'relu'))\n    clf.add(BatchNormalization())\n    clf.add(Dense(1024, activation = 'relu'))\n    clf.add(BatchNormalization())\n    clf.add(Dense(512, activation = 'relu'))\n    clf.add(Dense(64, activation = 'relu'))\n    clf.add(Dense(1, activation = 'sigmoid'))\n    clf.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return clf","29c090c5":"# training on DNN classifier\n\ndnn_accuracy = []\ndnn_precision = []\ndnn_recall = []\ndnn_tn = []\ndnn_fp = []\ndnn_fn = []\ndnn_tp = []\ndnn_dos_accuracy = []\ndnn_probe_accuracy = []\ndnn_r2l_accuracy = []\ndnn_u2r_accuracy = []\ndnn_normal_accuracy = []\n\nfor attack_type in attack_classes:\n    clf = getdnnclf()\n    clf.fit(x_train, train_label[attack_type], batch_size = 1024, epochs = 5, \n            validation_data = (x_test, test_label[attack_type]), verbose = 0)\n    y_pred = (clf.predict(x_test) >= 0.5).astype(int)\n    stacked_train_df[attack_type]['dnn'] = (clf.predict(x_train) >= 0.5).astype(int)\n    stacked_test_df[attack_type]['dnn'] = y_pred\n    dnn_accuracy += [accuracy_score(test_label[attack_type], y_pred)]\n    if attack_type in dos_classes:\n        dnn_dos_accuracy += [dnn_accuracy[-1]]\n    if attack_type in probe_classes:\n        dnn_probe_accuracy += [dnn_accuracy[-1]]\n    if attack_type in r2l_classes:\n        dnn_r2l_accuracy += [dnn_accuracy[-1]]\n    if attack_type in u2r_classes:\n        dnn_u2r_accuracy += [dnn_accuracy[-1]]\n    if attack_type in normal_classes:\n        dnn_normal_accuracy += [dnn_accuracy[-1]]\n    dnn_precision += [precision_score(test_label[attack_type], y_pred)]\n    dnn_recall += [recall_score(test_label[attack_type], y_pred)]\n    cm = confusion_matrix(test_label[attack_type], y_pred).ravel()\n    if len(cm) > 1:\n        dnn_tn += [cm[0]]\n        dnn_fp += [cm[1]]\n        dnn_fn += [cm[2]]\n        dnn_tp += [cm[3]]\n    else:\n        dnn_tn += [0]\n        dnn_fp += [0]\n        dnn_fn += [0]\n        dnn_tp += [0]\n    \nmean_dnn_accuracy = np.mean(dnn_accuracy)\nmean_dnn_precision = np.mean(dnn_precision)\nmean_dnn_recall = np.mean(dnn_recall)\n    \nprint(\"Deep Neural Network Classifier...\")\nprint(\"Mean Accuracy score : \" + str(mean_dnn_accuracy))\nprint(\"Mean Precision score : \" + str(mean_dnn_precision))\nprint(\"Mean Recall score : \" + str(mean_dnn_recall))\nprint(\"Mean accuracy DOS attacks : \" + str(np.mean(dnn_dos_accuracy)))\nprint(\"Mean accuracy Probe attacks : \" + str(np.mean(dnn_probe_accuracy)))\nprint(\"Mean accuracy R2L attacks : \" + str(np.mean(dnn_r2l_accuracy)))\nprint(\"Mean accuracy U2R attacks : \" + str(np.mean(dnn_u2r_accuracy)))\nprint(\"Mean accuracy Normal class : \" + str(np.mean(dnn_normal_accuracy)))","16ddc97d":"# graphical comparison\n\nn_groups = 4\nscores = [np.mean(dnn_dos_accuracy), np.mean(dnn_probe_accuracy), np.mean(dnn_r2l_accuracy), np.mean(dnn_u2r_accuracy)]\nscores = [item-0.90 for item in scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, scores, bar_width, alpha = opacity, align = 'center', label = 'Average Accuracy')\n\nrows = ['DoS', 'Probe', 'R2L', 'U2R']\n\nplt.xlabel('Attack Category')\nplt.ylabel('Average Accuracy Score')\nplt.title('Accuracy scores for different attack categories using DNN Classifier')\nplt.xticks(index, rows)\nplt.yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10], [0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","37be4b79":"# training on stacked classifier\n\nstacked_accuracy = []\nstacked_precision = []\nstacked_recall = []\nstacked_tn = []\nstacked_fp = []\nstacked_fn = []\nstacked_tp = []\nstacked_dos_accuracy = []\nstacked_probe_accuracy = []\nstacked_r2l_accuracy = []\nstacked_u2r_accuracy = []\nstacked_normal_accuracy = []\n\nfor attack_type in attack_classes:\n    clf = getLRClf()\n    clf.fit(stacked_train_df[attack_type], train_label[attack_type])\n    y_pred = clf.predict(stacked_test_df[attack_type])\n    stacked_accuracy += [accuracy_score(test_label[attack_type], y_pred)]\n    if attack_type in dos_classes:\n        stacked_dos_accuracy += [stacked_accuracy[-1]]\n    if attack_type in probe_classes:\n        stacked_probe_accuracy += [stacked_accuracy[-1]]\n    if attack_type in r2l_classes:\n        stacked_r2l_accuracy += [stacked_accuracy[-1]]\n    if attack_type in u2r_classes:\n        stacked_u2r_accuracy += [stacked_accuracy[-1]]\n    if attack_type in normal_classes:\n        stacked_normal_accuracy += [stacked_accuracy[-1]]\n    stacked_precision += [precision_score(test_label[attack_type], y_pred)]\n    stacked_recall += [recall_score(test_label[attack_type], y_pred)]\n    cm = confusion_matrix(test_label[attack_type], y_pred).ravel()\n    if len(cm) > 1:\n        stacked_tn += [cm[0]]\n        stacked_fp += [cm[1]]\n        stacked_fn += [cm[2]]\n        stacked_tp += [cm[3]]\n    else:\n        stacked_tn += [0]\n        stacked_fp += [0]\n        stacked_fn += [0]\n        stacked_tp += [0]\n    \nmean_stacked_accuracy = np.mean(stacked_accuracy)\nmean_stacked_precision = np.mean(stacked_precision)\nmean_stacked_recall = np.mean(stacked_recall)\n    \nprint(\"Stacked Model Classifier...\")\nprint(\"Mean Accuracy score : \" + str(mean_stacked_accuracy))\nprint(\"Mean Precision score : \" + str(mean_stacked_precision))\nprint(\"Mean Recall score : \" + str(mean_stacked_recall))\nprint(\"Mean accuracy DOS attacks : \" + str(np.mean(stacked_dos_accuracy)))\nprint(\"Mean accuracy Probe attacks : \" + str(np.mean(stacked_probe_accuracy)))\nprint(\"Mean accuracy R2L attacks : \" + str(np.mean(stacked_r2l_accuracy)))\nprint(\"Mean accuracy U2R attacks : \" + str(np.mean(stacked_u2r_accuracy)))\nprint(\"Mean accuracy Normal class : \" + str(np.mean(stacked_normal_accuracy)))","8fff080f":"# graphical comparison\n\nn_groups = 4\nscores = [np.mean(stacked_dos_accuracy), np.mean(stacked_probe_accuracy), np.mean(stacked_r2l_accuracy), np.mean(stacked_u2r_accuracy)]\nscores = [item-0.90 for item in scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, scores, bar_width, alpha = opacity, align = 'center', label = 'Average Accuracy')\n\nrows = ['DoS', 'Probe', 'R2L', 'U2R']\n\nplt.xlabel('Attack Category')\nplt.ylabel('Average Accuracy Score')\nplt.title('Accuracy scores for different attack categories using Stacked Model Classifier')\nplt.xticks(index, rows)\nplt.yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10], [0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","1a7d1419":"# models comparison\n\ncolumns = ['Average Accuracy Score', 'Average Precision Score', 'Average Recall Score']\nrows = ['Log Reg', 'SGD', 'LGBM', 'XGBoost', 'DNN', 'Stacked Model']\nlr_scores = [mean_lr_accuracy, mean_lr_precision, mean_lr_recall]\nsgd_scores = [mean_sgd_accuracy, mean_sgd_precision, mean_sgd_recall]\nlgb_scores = [mean_lgb_accuracy, mean_lgb_precision, mean_lgb_recall]\nxgb_scores = [mean_xgb_accuracy, mean_xgb_precision, mean_xgb_recall]\ndnn_scores = [mean_dnn_accuracy, mean_dnn_precision, mean_dnn_recall]\nstacked_scores = [mean_stacked_accuracy, mean_stacked_precision, mean_stacked_recall]\n\ntable = pd.DataFrame(data = [lr_scores, sgd_scores, lgb_scores, xgb_scores, dnn_scores, stacked_scores], columns = columns, index = rows)\nprint(table)","575400b4":"acc_df = pd.DataFrame()\n\nacc_df['attack_type'] = attack_classes\nacc_df['lr_accuracy_scores'] = lr_accuracy\n\nprint(acc_df)","95628914":"acc_df.drop(['lr_accuracy_scores'], axis = 1, inplace = True)\nacc_df['sgd_accuracy_scores'] = sgd_accuracy\n\nprint(acc_df)","a9c4e253":"acc_df.drop(['sgd_accuracy_scores'], axis = 1, inplace = True)\nacc_df['lgb_accuracy_scores'] = lgb_accuracy\n\nprint(acc_df)","850d0f68":"acc_df.drop(['lgb_accuracy_scores'], axis = 1, inplace = True)\nacc_df['xgb_accuracy_scores'] = xgb_accuracy\n\nprint(acc_df)","d4e0c61a":"acc_df.drop(['xgb_accuracy_scores'], axis = 1, inplace = True)\nacc_df['dnn_accuracy_scores'] = dnn_accuracy\n\nprint(acc_df)","ddb3e94a":"acc_df.drop(['dnn_accuracy_scores'], axis = 1, inplace = True)\nacc_df['stacked_accuracy_scores'] = stacked_accuracy\n\nprint(acc_df)","3b3950c5":"prec_df = pd.DataFrame()\n\nprec_df['attack_type'] = attack_classes\nprec_df['lr_precision_scores'] = lr_precision\n\nprint(prec_df)","9d857bd3":"prec_df.drop(['lr_precision_scores'], axis = 1, inplace = True)\nprec_df['sgd_precision_scores'] = sgd_precision\n\nprint(prec_df)","3b50d0dc":"prec_df.drop(['sgd_precision_scores'], axis = 1, inplace = True)\nprec_df['lgb_precision_scores'] = lgb_precision\n\nprint(prec_df)","429b52d4":"prec_df.drop(['lgb_precision_scores'], axis = 1, inplace = True)\nprec_df['xgb_precision_scores'] = xgb_precision\n\nprint(prec_df)","9e2881ce":"prec_df.drop(['xgb_precision_scores'], axis = 1, inplace = True)\nprec_df['dnn_precision_scores'] = dnn_precision\n\nprint(prec_df)","c81ceca3":"prec_df.drop(['dnn_precision_scores'], axis = 1, inplace = True)\nprec_df['stacked_precision_scores'] = stacked_precision\n\nprint(prec_df)","aec842ca":"rec_df = pd.DataFrame()\n\nrec_df['attack_type'] = attack_classes\nrec_df['lr_recall_scores'] = lr_recall\n\nprint(rec_df)","b5a6895a":"rec_df.drop(['lr_recall_scores'], axis = 1, inplace = True)\nrec_df['sgd_recall_scores'] = sgd_recall\n\nprint(rec_df)","a13590a3":"rec_df.drop(['sgd_recall_scores'], axis = 1, inplace = True)\nrec_df['lgb_recall_scores'] = lgb_recall\n\nprint(rec_df)","99dc4fb0":"rec_df.drop(['lgb_recall_scores'], axis = 1, inplace = True)\nrec_df['xgb_recall_scores'] = xgb_recall\n\nprint(rec_df)","17459adf":"rec_df.drop(['xgb_recall_scores'], axis = 1, inplace = True)\nrec_df['dnn_recall_scores'] = dnn_recall\n\nprint(rec_df)","ac87b5ff":"rec_df.drop(['dnn_recall_scores'], axis = 1, inplace = True)\nrec_df['stacked_recall_scores'] = stacked_recall\n\nprint(rec_df)","b36b4322":"cf_df = pd.DataFrame()\n\ncf_df['attack_type'] = attack_classes\ncf_df['lr_tn'] = lr_tn\ncf_df['lr_fp'] = lr_fp\ncf_df['lr_fn'] = lr_fn\ncf_df['lr_tp'] = lr_tp\n\nprint('Total samples : ' + str(x_train.shape[0]))\nprint(cf_df)","fca5dfb3":"cf_df.drop(['lr_tn', 'lr_fp', 'lr_fn', 'lr_tp'], axis = 1, inplace = True)\n\ncf_df['sgd_tn'] = sgd_tn\ncf_df['sgd_fp'] = sgd_fp\ncf_df['sgd_fn'] = sgd_fn\ncf_df['sgd_tp'] = sgd_tp\n\nprint('Total samples : ' + str(x_train.shape[0]))\nprint(cf_df)","1fbed672":"cf_df.drop(['sgd_tn', 'sgd_fp', 'sgd_fn', 'sgd_tp'], axis = 1, inplace = True)\n\ncf_df['lgb_tn'] = lgb_tn\ncf_df['lgb_fp'] = lgb_fp\ncf_df['lgb_fn'] = lgb_fn\ncf_df['lgb_tp'] = lgb_tp\n\nprint('Total samples : ' + str(x_train.shape[0]))\nprint(cf_df)","7dcf5086":"cf_df.drop(['lgb_tn', 'lgb_fp', 'lgb_fn', 'lgb_tp'], axis = 1, inplace = True)\n\ncf_df['xgb_tn'] = xgb_tn\ncf_df['xgb_fp'] = xgb_fp\ncf_df['xgb_fn'] = xgb_fn\ncf_df['xgb_tp'] = xgb_tp\n\nprint('Total samples : ' + str(x_train.shape[0]))\nprint(cf_df)","7432145b":"cf_df.drop(['xgb_tn', 'xgb_fp', 'xgb_fn', 'xgb_tp'], axis = 1, inplace = True)\n\ncf_df['dnn_tn'] = dnn_tn\ncf_df['dnn_fp'] = dnn_fp\ncf_df['dnn_fn'] = dnn_fn\ncf_df['dnn_tp'] = dnn_tp\n\nprint('Total samples : ' + str(x_train.shape[0]))\nprint(cf_df)","fbd023b2":"cf_df.drop(['dnn_tn', 'dnn_fp', 'dnn_fn', 'dnn_tp'], axis = 1, inplace = True)\n\ncf_df['stacked_tn'] = stacked_tn\ncf_df['stacked_fp'] = stacked_fp\ncf_df['stacked_fn'] = stacked_fn\ncf_df['stacked_tp'] = stacked_tp\n\nprint('Total samples : ' + str(x_train.shape[0]))\nprint(cf_df)","fa0db829":"acc_scores = [[mean_lr_accuracy], [mean_sgd_accuracy], [mean_lgb_accuracy], [mean_xgb_accuracy], \n          [mean_dnn_accuracy], [mean_stacked_accuracy]]\nprec_scores = [[mean_lr_precision], [mean_sgd_precision], [mean_lgb_precision], [mean_xgb_precision], \n          [mean_dnn_precision], [mean_stacked_precision]]\nrec_scores = [[mean_lr_recall], [mean_sgd_recall], [mean_lgb_recall], [mean_xgb_recall], \n          [mean_dnn_recall], [mean_stacked_recall]]","6bbfb817":"# graphical comparison\n\nn_groups = 6\nacc = [item[0]-0.80 for item in acc_scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, acc, bar_width, alpha = opacity, align = 'center', label = 'Average Accuracy')\n\nplt.xlabel('Model')\nplt.ylabel('Average Accuracy Score')\nplt.title('Graphical Comparison of Average Accuracy for all models')\nplt.xticks(index, rows)\nplt.yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12,\n           0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20], \n           [0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n            0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","178f7db4":"# graphical comparison\n\nn_groups = 6\nprec = [item[0] for item in prec_scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, prec, bar_width, alpha = opacity, align = 'center', label = 'Average Precision')\n\nplt.xlabel('Model')\nplt.ylabel('Average Precision Score')\nplt.title('Graphical Comparison of Average Precision for all models')\nplt.xticks(index, rows)\nplt.yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","8aaa84fc":"# graphical comparison\n\nn_groups = 6\nrec = [item[0] for item in rec_scores]\n\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.30\nopacity = 0.8\n \nrects = plt.bar(index, rec, bar_width, alpha = opacity, align = 'center', label = 'Average Recall')\n\nplt.xlabel('Model')\nplt.ylabel('Average Recall Score')\nplt.title('Graphical Comparison of Average Recall for all models')\nplt.xticks(index, rows)\nplt.yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\nplt.legend()\n\nfig = plt.tight_layout(rect = (0, 0, 1.4, 1.4))\nplt.show()","8b17db81":"<div><h3>Stacked Model<\/h3>\n    <p> Stacked Model contains all the models we have trained above as base learners. We will use a Logistic Regression classifier to combine the outputs of all the base learners to give a single output with greater accuracy.\n    <\/p>\n<\/div>","141ad3ba":"<div><h3>Gradient Boosting Decision Tree (GBDT) Ensemble Models<\/h3><\/div>","93b8a128":"<div>\n    <h2> Network Intrusion Detection using Linear Models, GBDT Ensembles and Deep Learning - A comparative study using state-of-the-art tools and libraries <\/h2>\n    <p> In this study, we use the <a href='https:\/\/www.unb.ca\/cic\/datasets\/nsl.html'>NSL KDD dataset<\/a> to predict the probability of occurence of 23 different classes of attacks on a network. Here, we use three different categories of models - Linear Models including Logistic Regression and Stochastic Gradient Descent (SGD) classifier; Gradient Boosting Decision Tree emsembles including LightGBM (LGBM) and XGBoost; and a Deep Neural Network (DNN) classifier. We also train a stacked model consisting of all these models as base learners. Finally, we compare the performances of all the models for Network Intrusion Detection using the NSL-KDD dataset and draw useful conclusions.<\/p>\n<\/div>","1171a8ee":"<div><h3>Deep Learning Model<\/h3><\/div>","d03b4c48":"<div><h3>Comparing Performances of all the models trained<\/h3><\/div>","ba20fb96":"<div>\n    <h3>Linear Models<\/h3>\n<\/div>","04d8dc96":"<div>\n    <h3> Feature Engineering <\/h3>\n    <p> We will extract useful features from the existing ones, and convert some features into formats suitable for training on different categories of models. <\/p>\n<\/div>"}}