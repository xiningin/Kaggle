{"cell_type":{"fdae526a":"code","4edafd80":"markdown"},"source":{"fdae526a":"import numpy as np\nimport pandas as pd \nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom xgboost import XGBRegressor\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nsample_sub_filepath = \"..\/input\/av-healthcare-analytics-ii\/healthcare\/sample_sub.csv\"\ntrain_data_dictionary_filepath = \"..\/input\/av-healthcare-analytics-ii\/healthcare\/train_data_dictionary.csv\"\ntrain_data_filepath = \"..\/input\/av-healthcare-analytics-ii\/healthcare\/train_data.csv\"\ntest_data_filepath = \"..\/input\/av-healthcare-analytics-ii\/healthcare\/test_data.csv\"\n\nsample_sub = pd.read_csv(sample_sub_filepath)\ntrain_data_dictionary = pd.read_csv(train_data_dictionary_filepath)\ntrain_data = pd.read_csv(train_data_filepath)\ntest_data = pd.read_csv(test_data_filepath)\n\n# Determine objective in training data\ntrain_y = train_data.Stay\n\n# Remove unnecessary columns in train & test\nfeatures = [\"Type of Admission\",\"Severity of Illness\",\"Age\"]\ntrain_X = train_data[features]\nval_X = test_data[features]\n\n# Label encoding (X)\n    # Get relevant columns\nlabel_encoder_features = [\"Severity of Illness\", \"Age\"]\n    # Make copy to preserve original data\nlabel_train_X = train_X.copy()\nlabel_val_X = val_X.copy()\nlabel_train_X = label_train_X[label_encoder_features]\nlabel_val_X = label_val_X[label_encoder_features]\n    # Label encode\nlabel_encoder=LabelEncoder()\nfor col in label_encoder_features:\n    label_train_X[col]=label_encoder.fit_transform(label_train_X[col])\n    label_val_X[col]=label_encoder.transform(label_val_X[col])\n\n# Label encoding (y)\nlabel_train_y = train_y.copy()\nlabel_train_y = label_encoder.fit_transform(label_train_y)\n\n# One hot encoding (X)\n    # Get relevant columns\none_hot_encoder_features = [\"Type of Admission\"]\n    # Make copy to preserve original data\none_hot_train_X = train_X.copy()\none_hot_val_X = val_X.copy()\none_hot_train_X = one_hot_train_X[one_hot_encoder_features]\none_hot_val_X = one_hot_val_X[one_hot_encoder_features]\n    # One hot encode \none_hot_encoder = OneHotEncoder(sparse=False)\none_hot_train_X = pd.DataFrame(one_hot_encoder.fit_transform(one_hot_train_X))\none_hot_val_X = pd.DataFrame(one_hot_encoder.transform(one_hot_val_X))\n    # Get back columns names \none_hot_train_X.columns = one_hot_encoder.get_feature_names(one_hot_encoder_features)\none_hot_val_X.columns = one_hot_encoder.get_feature_names(one_hot_encoder_features)\n\n# Concatenate label and one hot encoding\nconcat_train_X = pd.concat([label_train_X,one_hot_train_X],axis=1)\nconcat_val_X = pd.concat([label_val_X,one_hot_val_X],axis=1)\n\n# Make predictions using the XGB model\nXGB_model = XGBRegressor(n_estimators=500)\nXGB_model.fit(concat_train_X, label_train_y)\n\n# Undo label encoding for predictions\npredictions = XGB_model.predict(concat_val_X).round()\npredictions = list(label_encoder.inverse_transform(predictions.astype(int)))\npredictions = np.array(predictions)\n\n# Save predictions to file\noutput = pd.DataFrame( {\"case_id\" : test_data[\"case_id\"],\n                        \"Stay\": predictions})\noutput.to_csv('submission.csv', index=False)","4edafd80":"This is my first attempt\n\nThe next steps are to add pipelines, research more effective methods, and improve accuracy"}}