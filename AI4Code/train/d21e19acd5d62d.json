{"cell_type":{"a56b0e6e":"code","aaf761d8":"code","da72a55c":"code","120ea632":"code","70de5a6b":"code","a6e0634f":"code","27d522a9":"code","bdc8b991":"code","b3fa8b94":"code","6d5bbe87":"code","e02f4df5":"code","405f029c":"code","8a266e6d":"code","d7f1a370":"code","8959f0e0":"markdown","49560494":"markdown","0fb4a4f8":"markdown","349f58b6":"markdown","a7aa56fc":"markdown","eac19a33":"markdown","063e248d":"markdown","b59ee9d0":"markdown","856460a4":"markdown"},"source":{"a56b0e6e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aaf761d8":"from sklearn.datasets import make_moons,make_circles\nimport numpy as np\nfrom matplotlib import pyplot as plt","da72a55c":"p,q=make_moons(n_samples=200,noise=0.1)","120ea632":"plt.scatter(p[:,0],p[:,1],c=q,)\nplt.xlabel(\"P1\")\nplt.ylabel(\"P2\")\nplt.legend()\nplt.show()","70de5a6b":"from sklearn.cluster import KMeans","a6e0634f":"km=KMeans(n_clusters=2)","27d522a9":"km.fit(p)","bdc8b991":"centers=km.cluster_centers_\nlabel=km.labels_","b3fa8b94":"plt.scatter(p[:,0],p[:,1],c=label)\nplt.scatter(centers[:,0],centers[:,1],color=\"red\",marker=\"*\")\nplt.show()\n# as we can see its preety bad ","6d5bbe87":"from sklearn.cluster import DBSCAN","e02f4df5":"dbs=DBSCAN(eps=0.188,min_samples=2)","405f029c":"dbs.fit(p)","8a266e6d":"ypred=dbs.fit_predict(p)","d7f1a370":"plt.scatter(p[:,0],p[:,1],c=ypred)\nplt.show()","8959f0e0":"# using DBSCAN","49560494":"## Datasets on which K-Means Clustering fails!\n\n- k-mean clustering fails or give poor results when datasets are not linearly separable or have complex scatter plot arrangement\n- In this notebook we have seen an example on which the K-mean clustering fails \n- Alternative approach i.e, DBSCAN(DENSITY BASED SPATIAL CLUSTERING OF APPLICATION WITH NOISE)","0fb4a4f8":"# VISUALIZING THE DATASET","349f58b6":"## Importing required packages","a7aa56fc":"## As we can see this approach is giving better results because of the following reason\n- DBSCAN is based upon the idea, that a cluster is a high density area surrounded by low density region.\n- Stat exploring a small area , if density is good enough it's considerd as the part of the cluster\n- alse have criteria for thrashold distance for the point to being consider as the part of cluster\n","eac19a33":"# GENERATING DATASETS","063e248d":"### that's the point where DBSCAN comes into play","b59ee9d0":"## Upvote if you like this notebook and feel free to ask your doubts in commnet section.\n\n## Thank You :)","856460a4":"## visualisation of accuracy of K-mean"}}