{"cell_type":{"ab8a9bb1":"code","aac115d6":"code","58865c53":"code","7582e7e8":"code","148ef4dd":"code","8c42a7da":"code","06da0fd4":"code","65aa172a":"code","7318666c":"code","b150a672":"code","f8bafe45":"code","904b862a":"code","05df839b":"code","2147296e":"code","082565c4":"code","e1e43e1a":"markdown","7bed78f5":"markdown"},"source":{"ab8a9bb1":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras","aac115d6":"#importing dataset\nds = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/tsla.us.txt\")\nds.head()","58865c53":"ds.shape","7582e7e8":"#splitting dataset into test and train dataset\ntrain_ds, test_ds = ds[0:int(len(ds)*0.80)],ds[int(len(ds)*0.80):len(ds)]","148ef4dd":"#defining training set taking column 'open'\ntrain_set = train_ds.iloc[:,1:2].values\ntrain_set","8c42a7da":"plt.plot(train_set)","06da0fd4":"#applying feature scaling,Normalization is preferred in RNN\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0,1))\nscaled_train_set = sc.fit_transform(train_set)","65aa172a":"#creating a data structure with 60 timestamps and 1 output\nx_train = []\ny_train = []\n\n#values can be changed but i got best results with 60 timestamps\nfor i in range(60,len(train_set)):\n    x_train.append(scaled_train_set[i-60:i,0])\n    y_train.append(scaled_train_set[i,0])\n    \nx_train = np.array(x_train)\ny_train = np.array(y_train)","7318666c":"#reshaping x_train for inputting in RNN\n#here reshape(batch_size,timesteps,input_dim)\nx_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)","b150a672":"#building the RNN\nrnn = keras.models.Sequential()\n\n#adding first layer of LSTM\nrnn.add(keras.layers.LSTM(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\nrnn.add(keras.layers.Dropout(0.2))\n\n#adding second layer of LSTM\nrnn.add(keras.layers.LSTM(units = 50,return_sequences = True))\nrnn.add(keras.layers.Dropout(0.2))\n\n#adding third layer of LSTM\nrnn.add(keras.layers.LSTM(units = 50,return_sequences = True))\nrnn.add(keras.layers.Dropout(0.2))\n\n#adding fourth layer of LSTM\nrnn.add(keras.layers.LSTM(units = 50))\nrnn.add(keras.layers.Dropout(0.2))\n        \n#adding output layer of LSTM\nrnn.add(keras.layers.Dense(units = 1))\n\n#compiling the model\nrnn.compile(optimizer = 'adam', loss = 'mean_squared_error')\n        \n#training the model\nrnn.fit(x_train, y_train, epochs = 100, batch_size = 32)","f8bafe45":"#defining y_test(actual values)\ny_test = test_ds.iloc[:,1:2].values","904b862a":"#inputs contain 60 previous values of the first element of test_ds\n#bcause for prediction of first values of test_ds we need 60 prior values\nds_total = pd.concat((train_ds[\"Open\"], test_ds[\"Open\"]), axis = 0)\ninputs = ds_total[(len(ds_total) - len(test_ds) - 60):].values\ninputs = inputs.reshape(-1,1)\ninputs = sc.transform(inputs)","05df839b":"#creating a x_test \nx_test = []\n\nfor i in range(60,432):\n    x_test.append(inputs[i-60:i,0])\n    \nx_test = np.array(x_test)","2147296e":"#reshaping x_test for prediction\n#here reshape(batch_size,timesteps,input_dim)\nx_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\ny_pred = rnn.predict(x_test)\ny_pred = sc.inverse_transform(y_pred)","082565c4":"plt.plot(y_test, color = 'red', label = 'Real Stock Price')\nplt.plot(y_pred, color = 'blue', label = 'Predicted Stock Price')\nplt.title('Tesla Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Stock Price')\nplt.legend()\nplt.show()","e1e43e1a":"**PREDICTING STOCK PRICE OF TESLA(THAT IS UPWARD AND DOWNWARD TREND) WITH THE HELP OF STACKED LSTM(SINCE MULTIPLE LAYERS OF LSTM ARE USED).**\n\n**HERE FROM MANY DATESETS I HAVE USED DATASET FOR TESLA STOCKS**","7bed78f5":"**HERE 60 IS TAKEN BECAUSE IN ORDER FOR LSTM TO WORK WE REQUIRE SOME PRIOR KNOWLEDGE,** \n\n**HENCE FOR STOCK PRICE AT TIME (T)** \n* **WE REQUIRE KNOWLEDGE PREVIOUS 60 STOCKS** \n* **TO PREDICT THE STOCK AT TIME (T+1)**"}}