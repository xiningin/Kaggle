{"cell_type":{"dc597c95":"code","c4770fc3":"code","c425b62d":"code","4bce64e9":"code","a2927795":"code","87f82e3d":"code","dedb95da":"code","bae4ca5f":"code","8ebca1ec":"code","120f0216":"code","b72baf89":"code","dcb54430":"code","ce818a68":"code","00533777":"code","09c8996d":"code","96381256":"code","7b6c0da7":"code","edb2942c":"code","ad186706":"code","de687ff3":"code","4e63c276":"code","54c9f10e":"code","4ac118ba":"code","29a6b9a5":"code","0f389efb":"code","b4e365b8":"code","d3232028":"code","5950097d":"code","b29cbf4d":"code","70b92f64":"code","47c56b49":"code","19f24a97":"code","de3ad55e":"markdown","10a91bd7":"markdown","2eec9d2d":"markdown","0cd3a871":"markdown","bd2fb2de":"markdown","e5b39c3c":"markdown","7a42b4fc":"markdown","be733c64":"markdown","6e7ca6ac":"markdown","e06ee14e":"markdown","402b5f4a":"markdown","7361985b":"markdown","aa26dc09":"markdown","8cd57456":"markdown","5924376e":"markdown","1dc3ec64":"markdown","fecbae11":"markdown","283f7216":"markdown","081c324b":"markdown","9531de27":"markdown","7f6e6ed9":"markdown","c82c6bed":"markdown"},"source":{"dc597c95":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","c4770fc3":"train = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')","c425b62d":"print(\"train shape\", train.shape)\nprint(\"test shape\", test.shape)","4bce64e9":"print(\"train shape\", train.shape)\ntrain.describe().T","a2927795":"print('Data types of the columns \\n\\n', train.info())\nprint('\\n\\n\\n Total Null values\\n', train.isnull().sum())","87f82e3d":"print('Total Duplicate values\\n', train.duplicated().sum())","dedb95da":"# date time has to be change from object to a datetine format, this can be directly done also while importing the data\ntrain['date_time']=pd.to_datetime(train['date_time'])\ntrain.set_index('date_time', inplace = True)\n\n# dataset for univariate analysis\ntrain_u = train.copy()\ncols = ['deg_C', 'relative_humidity', 'absolute_humidity',\n       'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\ntrain_u.drop(cols, axis = 1, inplace = True)\n\n#renaming the columns\n# cm - carbon monoxide; ben = benzene; no = nitrogen oxides\ntrain_u.columns = [\"cm\", \"ben\", \"no\"]\n\ntrain_u.head()\n","bae4ca5f":"train_u.plot(\n    subplots = True, \n    layout = (3,1), \n    sharex = True, \n    figsize = (30,15) )","8ebca1ec":"# Separately performing each target variable.\n# Purpose of train_cm is to decide for the model parameters later\n\ntrain_cm = train_u.copy()\ntrain_cm.drop(columns = ['ben','no'], inplace = True)\ntrain_cm.tail()","120f0216":"train_cm.plot(figsize = (20,10))","b72baf89":"# Testing For Stationarity\nfrom statsmodels.tsa.stattools import adfuller\n\n\n#Ho: It is non stationary\n#H1: It is stationary\ndef adfuller_test(levels):\n    result=adfuller(levels)\n    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n    for value,label in zip(result,labels):\n        print(label+' : '+str(value) )\n    if result[1] <= 0.05:\n        print(\"\\n strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n    else:\n        print(\"\\n weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")","dcb54430":"adfuller_test(train_cm['cm'])","ce818a68":"from pandas.plotting import autocorrelation_plot\n\nplt.figure(figsize=(20,8))\nautocorrelation_plot(train_cm['cm']).set_xlim([0,100]) # setting the limit to a managable level\nplt.xticks(np.arange(0, 200, 12)) # changing the tick frequency for matplotlib\nplt.show()","00533777":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf","09c8996d":"# AR(p) or MA(q) based on the ACF and PACF graphs without accounting for the cyclic nature\n\nfig = plt.figure(figsize=(24,8))\nax1 = fig.add_subplot(211)\nfig = plot_acf(train_cm['cm'], lags = 60, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = plot_pacf(train_cm['cm'], lags=60, ax=ax2)","96381256":"train_cm['diff'] = train_cm['cm'] - train_cm['cm'].shift(24)\ntrain_cm['diff'].plot(figsize = (24,6))\n\n# post differencing \nfig = plt.figure(figsize=(24,10))\nax1 = fig.add_subplot(211)\nfig = plot_acf(train_cm['diff'].iloc[24:], lags = 200, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = plot_pacf(train_cm['diff'].iloc[24:],lags = 200, ax=ax2)","7b6c0da7":"# arima 111\nfrom statsmodels.tsa.arima_model import ARIMA\n\narima_model = ARIMA(train_cm['cm'],order=(1,1,1))\nmodel_fit = arima_model.fit()\ntrain_cm['forecast111'] = model_fit.predict(start=6000 , end=7110 )\ntrain_cm[['cm','forecast111']].plot(figsize=(20,10))","edb2942c":"# sarima 111\nimport statsmodels.api as sm\n\nsarima_model = sm.tsa.statespace.SARIMAX(train_cm['cm'],order=(1, 1, 1))\nmodel_fit = sarima_model.fit()\ntrain_cm['sforecast111'] = model_fit.predict(start=6000 , end=7110 )\ntrain_cm[['cm','sforecast111']].plot(figsize=(20,10))","ad186706":"# sarima 211\nimport statsmodels.api as sm\n\nsarima_model = sm.tsa.statespace.SARIMAX(train_cm['cm'],order=(2, 1, 1))\nmodel_fit = sarima_model.fit()\ntrain_cm['sforecast211'] = model_fit.predict(start=6000 , end=7110 )\ntrain_cm[['cm','sforecast211']].plot(figsize=(20,10))","de687ff3":"train_cm.columns","4e63c276":"model_111 = np.mean(np.abs(train_cm['forecast111'].iloc[6000:7111] - train_cm['cm'].iloc[6000:7111])\/np.abs(train_cm['cm'].iloc[6000:7111]))\n\nmodel_s111 = np.mean(np.abs(train_cm['sforecast111'].iloc[6000:7111] - train_cm['cm'].iloc[6000:7111])\/np.abs(train_cm['cm'].iloc[6000:7111]))\n\nmodel_s211 = np.mean(np.abs(train_cm['sforecast211'].iloc[6000:7111] - train_cm['cm'].iloc[6000:7111])\/np.abs(train_cm['cm'].iloc[6000:7111]))\n\nprint(' error - 111',model_111, '\\n error - s111', model_s111, '\\n error - s211', model_s211)","54c9f10e":"sub = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\n\n# dataset for univariate analysis\n\ncols = ['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']\nsub.drop(cols, axis = 1, inplace = True)\nsub","4ac118ba":"test = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')\n\n# dataset for univariate analysis\n\ncols = ['deg_C', 'relative_humidity', 'absolute_humidity',\n       'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\ntest.drop(cols, axis = 1, inplace = True)\ntest","29a6b9a5":"test","0f389efb":"# cm - sarima 111\nimport statsmodels.api as sm\n\nsarima_model = sm.tsa.statespace.SARIMAX(train_u['cm'],order=(1, 1, 1))\nmodel_fit = sarima_model.fit(full_output = True)\npre_cm = model_fit.predict(start = pd.to_datetime('2011-01-01 00:00:00'), \n                           end=pd.to_datetime('2011-04-04 14:00:00'), dynamic = False)","b4e365b8":"pre_cm","d3232028":"# ben - sarima 111\nimport statsmodels.api as sm\n\nsarima_model = sm.tsa.statespace.SARIMAX(train_u['ben'],order=(1, 1, 1))\nmodel_fit = sarima_model.fit()\npre_ben = model_fit.predict(start = pd.to_datetime('2011-01-01 00:00:00'), \n                           end=pd.to_datetime('2011-04-04 14:00:00'), dynamic = False)","5950097d":"pre_ben","b29cbf4d":"# no - sarima 111\nimport statsmodels.api as sm\n\nsarima_model = sm.tsa.statespace.SARIMAX(train_u['no'],order=(1, 1, 1))\nmodel_fit = sarima_model.fit()\npre_no = model_fit.predict(start = pd.to_datetime('2011-01-01 00:00:00'), \n                           end=pd.to_datetime('2011-04-04 14:00:00'), dynamic = False)","70b92f64":"pre_no","47c56b49":"final = pd.DataFrame({'cm':pre_cm, 'ben':pre_ben, 'no':pre_no}).reset_index()\nfinal.columns = ['date_time', 'target_carbon_monoxide','target_benzene', 'target_nitrogen_oxides']\nfinal","19f24a97":"final.to_csv(\"Submission.csv\", index = False)","de3ad55e":"### Time to predict ","10a91bd7":"### Accuracy test","2eec9d2d":"### Selecting the order","0cd3a871":"## Generic data analysis \nlike **Null-Value**; **Data Types**; **Duplicate Data**","bd2fb2de":"The data is repeating every 24 lags, thus a seasonal pattern observed that can be used in the model preparation later.\n* Next would be to get the ACF and PACF analysed for the TSA model","e5b39c3c":"* From the ACF plot, a seasonality\/cyclic nature of 24 is again observed\n* PACF = P = 1 or 2 for sure. \n* Need to removed the pattern by differencing with a 24 moving window format","7a42b4fc":"Steps in data analysis will follow these following steps\n\n* Check out categorical and numerical data\n* Check for duplicate data\n* Detect Null values \n* Explore the data with graphs and plots \n* Buiild model and predict\n\n\n\n\n\n","be733c64":"Least error is observed for seasonal arima with 111 model. \n* *There is still room for improvement if the exogenous variables are used in a multivarite Time series analysis*","6e7ca6ac":"The fact that forecast is bad proves the initial point of seasonality and the i need to try SARIMA model. \n* Note for this starting project i am just focusing on the traget variables, but in the subsequent notebook will try adding the exogenous variables","e06ee14e":"## Visualize the data\nSo we have hourly data from 10th march to 1st jan next year. \n* we can extract information or trend based on month, week, day, and hourly ","402b5f4a":"## Importing Libraries and **Data files**","7361985b":"For the sARIMA model, since there is seasonality observed\n* AR(p) = can be 1 or strecthed to 2, since post that the correlation values drops in the PACF plot\n* d = 1, since the differencing has been conducted once \n* MA(q) = is 1 since the inertia of that is carried forward to the rest of the values, and it is something that is validated by the ACF plot also.\n","aa26dc09":"### *Inference* 1: \n* No Null values\n* All except time are continuous variables of float type data\n* I will change the Date-Time from string to date format\n* Predcitions can be a forecast or forecasting methods like -\n * *Simple Univariate time series*\n * *Multivariate time series*\n * *Regression model, since the target is a continuous variable*","8cd57456":"Mean Absolute Percentage Error (MAPE) \nmape = np.mean(np.abs(forecast - actual)\/np.abs(actual))","5924376e":"## Loading and preparing the data","1dc3ec64":"## Building sARIMA ","fecbae11":"## Stationarity in the data","283f7216":"## AR \/ MA ? model parameters\n","081c324b":"sARIMA ***111, 211***; all gave promising result compared to arima\n* Combined error for the forecast \n* the best model will be applied on the test csv","9531de27":"# Data Analysis","7f6e6ed9":"# Time Analysis:  ","c82c6bed":"Plotting all the target together made me realise that the pollutants all share a same pattern. Toward the end the their respective values have increased, may be an over all increase in the trend. \n"}}