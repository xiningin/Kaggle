{"cell_type":{"5f7e9160":"code","3826d6d3":"code","4e7e9892":"code","c68a64e3":"code","daf995f7":"code","90f49862":"code","de55ca14":"code","a9b47539":"code","4a2b7896":"code","ba45d1e2":"code","915af87c":"code","716e3236":"code","44307efa":"code","3cedbcac":"code","9b4d349e":"code","b21822b9":"code","4b108b91":"markdown","d760e589":"markdown"},"source":{"5f7e9160":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dataset\n\n\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nimport matplotlib.pyplot as plt","3826d6d3":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(),\n    transforms.ToTensor()\n])","4e7e9892":"data = dataset.ImageFolder('..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets' , transform = transform)","c68a64e3":"datalen = len(data)\ndataidx = np.array(list(range(datalen)))\nnp.random.shuffle(dataidx)\n\nsplitfrac = 0.9\nsplit_idx = int(splitfrac * datalen)\ntrain_idxs = dataidx[:split_idx]\nvalid_idxs = dataidx[split_idx:]\n\ntestsplit = 0.1\ntestidxs = int(testsplit * len(train_idxs))\n\n\ntest_idxs = train_idxs[:testidxs]\ntrain_idxs = train_idxs[testidxs:]\n\nnp.random.shuffle(test_idxs)","daf995f7":"batch_size = 30","90f49862":"len(data) \/ batch_size","de55ca14":"train_samples = torch.utils.data.SubsetRandomSampler(train_idxs)\nvalid_samples = torch.utils.data.SubsetRandomSampler(valid_idxs)\ntest_samples  = torch.utils.data.SubsetRandomSampler(test_idxs)\ndataloader = DataLoader(data , batch_size = batch_size , sampler = train_samples)\nvalidloader = DataLoader(data , batch_size = batch_size ,sampler = valid_samples)\ntestloader  = DataLoader(data , batch_size = batch_size , sampler = test_samples)","a9b47539":"data.classes","4a2b7896":"images , labels = iter(dataloader).next()\nimages , labels = images.numpy() , labels.numpy()\n\nfig = plt.figure(figsize = (25,4))\n\nfor i in range(batch_size):\n    ax = fig.add_subplot(2 , batch_size\/2 , i+1 , xticks = [] , yticks = [])\n    ax.imshow(images[i].transpose(2,1,0).squeeze())\n    ax.set_title(data.classes[labels[i]])\n    \nplt.tight_layout()","ba45d1e2":"from torchvision import models\nmodel = models.vgg16(pretrained = True)\n\n\n# Parameters -> Do not perform gradient decent -> Freeze\n\nfor param in model.parameters():\n    param.no_grad_ = True\n\nmodel.classifier[6] = nn.Linear(4096 , 3)","915af87c":"model.cuda()","716e3236":"criterion = nn.CrossEntropyLoss().cuda()\noptimizer = optim.Adam(model.parameters() , lr = 1e-5)","44307efa":"%timeit\nn_epochs = 1\n\nfor e in range(n_epochs):\n    train_loss = 0.0\n    valid_loss = 0.0\n    min_valid_loss = np.inf\n    model.train()\n    for batch_idx , (data , target) in enumerate(dataloader):\n        data = data.cuda()\n        target = target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output , target)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n    model.eval()\n    for batch_idx , (data , target) in enumerate(validloader):\n        data = data.cuda()\n        target = target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output , target)\n        valid_loss += loss.item()\n            \n        \n    train_loss = train_loss \/ len(dataloader)\n    valid_loss = valid_loss \/ len(validloader)\n    print(\"Epoch : {} , Batch : {} , Loss : {}\".format(e+1 , batch_idx , train_loss)) \n    \n    if valid_loss < min_valid_loss:\n        print(\"Valid Loss decreased from {} ---> {}\".format(min_valid_loss , valid_loss))    \n        torch.save(model.state_dict() , \"model_lung_canc.pt\")\n        min_valid_loss = valid_loss","3cedbcac":"def test(loaders, model, criterion, use_cuda  = True):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    model.eval()\n    for batch_idx, (data, target) in enumerate(loaders):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 \/ (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d\/%2d)' % (\n        100. * correct \/ total, correct, total))","9b4d349e":"test(testloader, model, criterion, use_cuda  = True)","b21822b9":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n# get predictions\npreds = np.squeeze(model(images.cuda()).data.max(1, keepdim=True)[1].cpu().numpy())\nimages = images.cpu().numpy()\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(batch_size):\n    ax = fig.add_subplot(2, batch_size\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx].transpose(1,2,0)), cmap='gray')\n    ax.set_title(\"{} ({})\".format(data.classes[preds[idx]], data.classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))\nplt.tight_layout()","4b108b91":"**Importing the Required Libraries**","d760e589":" 224X224X3"}}