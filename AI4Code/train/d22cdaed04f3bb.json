{"cell_type":{"b8fe581f":"code","05a04980":"code","a741cd77":"code","35cac2f4":"code","c57b4ade":"code","bfe9be27":"code","2a85ce08":"code","2a02cd53":"code","a2b1cf19":"code","0aeb2fd5":"code","abf984ae":"code","bb28317f":"code","7e8755c3":"code","71040b54":"code","1f38ee3e":"code","bd5acc6e":"code","5ce18293":"code","62abac0b":"code","d8b31c6a":"code","1925307e":"code","a7bdb7a5":"code","ffbaf82e":"code","ba904487":"code","53db089a":"code","80f1d3b6":"code","620324a3":"code","af428a9c":"code","b1e2dd67":"code","77fe44cb":"code","33875504":"code","c09a959a":"code","cddda50b":"code","bae15b3b":"code","8c4deb9c":"code","9002fa15":"code","cfa96d13":"code","04ed6623":"code","88127497":"code","390ce22a":"code","0875d7c2":"code","f3263dda":"code","4b05086b":"code","b5f0af4d":"code","7b096661":"code","5c6ecebd":"code","d5e1bc46":"code","9895b476":"code","88dc6580":"markdown","344a85a7":"markdown","23161307":"markdown","978f181d":"markdown","9288946e":"markdown","f8dbe778":"markdown","e2eb7a4f":"markdown","db693394":"markdown","9d676c70":"markdown","85bc49af":"markdown","23922807":"markdown"},"source":{"b8fe581f":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import Model\nfrom keras import applications\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nimport random\nfrom shutil import copyfile\nimport os\nimport gc\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom keras import backend as K\n# Any results you write to the current directory are saved as output.","05a04980":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib import style\nimport seaborn as sns\nfrom keras.callbacks import ModelCheckpoint\n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)","a741cd77":"import os\nprint(os.listdir('..\/input\/flower_photos\/flower_photos'))","35cac2f4":"X=[]\ny=[]\nIMG_SIZE=150\nDAISY_DIR='..\/input\/flower_photos\/flower_photos\/daisy'\nSUNFLOWER_DIR='..\/input\/flower_photos\/flower_photos\/sunflowers'\nTULIP_DIR='..\/input\/flower_photos\/flower_photos\/tulips'\nDANDI_DIR='..\/input\/flower_photos\/flower_photos\/dandelion'\nROSE_DIR='..\/input\/flower_photos\/flower_photos\/roses'\n","c57b4ade":"def assigning_label(img,flower_type):\n    return flower_type","bfe9be27":"def make_train_data(flower_type,DIR):\n    for img in tqdm(os.listdir(DIR)):\n        label=assigning_label(img,flower_type)\n        path = os.path.join(DIR,img)\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        \n        X.append(np.array(img))\n        y.append(str(label))","2a85ce08":"#create training data\nmake_train_data('Daisy',DAISY_DIR)\nmake_train_data('Sunflowers',SUNFLOWER_DIR)\nmake_train_data('Tulips',TULIP_DIR)\nmake_train_data('dandelion',DANDI_DIR)\nmake_train_data('Roses',ROSE_DIR)\nprint(len(X))","2a02cd53":"import random as rn\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=rn.randint(0,len(y))\n        ax[i,j].imshow(X[l])\n        ax[i,j].set_title('Flower: '+y[l])\n        \nplt.tight_layout()","a2b1cf19":"from sklearn.preprocessing import LabelEncoder\n\nlabelEncoder=LabelEncoder()\ny=labelEncoder.fit_transform(y)\ny=to_categorical(y,5)\nX=np.array(X)\nX=X\/255","0aeb2fd5":"X.shape","abf984ae":"y.shape","bb28317f":"X_train_val,X_test,y_train_val,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\nX_train,X_val,y_train,y_val=train_test_split(X_train_val,y_train_val,test_size=0.10,random_state=42)","7e8755c3":"X_train.shape","71040b54":"y_train.shape","1f38ee3e":"# VGG16 pre-trained model without fully connected layers and with different input dimensions\nimage_w, image_h = 150,150\nmodel = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (image_w, image_h, 3))","bd5acc6e":"model.summary()","5ce18293":"for layer in model.layers:\n    layer.trainable = False\n    \nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","62abac0b":"def Revised_1_fn(learn_rate=0.01): \n    last = model.output\n    x = Flatten()(last)\n    x = Dense(256, activation='relu', name='new_fc1', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(5, activation='softmax')(x)\n\n    Revised_Model_1 = Model(model.input, preds)\n    Revised_Model_1.summary()\n    Revised_Model_1.compile(loss = \"categorical_crossentropy\", optimizer = 'Adam', metrics=[\"accuracy\"])\n    return Revised_Model_1","d8b31c6a":"for layer in model.layers[15:]:\n    layer.trainable = True\n     \nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","1925307e":"def Revised_2_fn(learn_rate=0.01):\n    last = model.output\n    x = Flatten()(last)\n    x = Dense(256, activation='relu', name='new_fc1', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(5, activation='softmax')(x)\n\n    Revised_Model_2 = Model(model.input, preds)\n    Revised_Model_2.summary()\n    Revised_Model_2.compile(loss = \"categorical_crossentropy\", optimizer = 'Adam', metrics=[\"accuracy\"])\n    return Revised_Model_2","a7bdb7a5":"for layer in model.layers:\n    layer.trainable = True\n     \nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","ffbaf82e":"def Revised_3_fn(learn_rate=0.01): \n    last = model.output\n    x = Flatten()(last)\n    x = Dense(256, activation='relu', name='new_fc1', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(5, activation='softmax')(x)\n\n    Revised_Model_3 = Model(model.input, preds)\n    Revised_Model_3.summary()\n    Revised_Model_3.compile(loss = \"categorical_crossentropy\", optimizer = 'Adam', metrics=[\"accuracy\"])\n    return Revised_Model_3","ba904487":"#using Grid Search and Early stopping\nes = EarlyStopping(monitor='val_acc', verbose=2, patience=25)\nmc = ModelCheckpoint('.\/best_model_1.h5', monitor='val_acc', verbose=2, save_best_only=True)\n\nHyp_Model_1 = KerasClassifier(build_fn=Revised_1_fn)\n#You need to pick the right hyper-parameters for your training (try with different ones)\n\nlearn_rate = [0.01]\nbatch_size = [32,75,100]\nepochs = [5]\n\nparam_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate = learn_rate)\nrandSearch_1 = GridSearchCV(estimator = Hyp_Model_1, param_grid=param_grid, cv=5)","53db089a":"new_grid_1 = randSearch_1.fit(X_train,y_train, validation_data = (X_val, y_val), verbose=2,callbacks=[es,mc])","80f1d3b6":"from keras.models import load_model\nfinal_model_1 = load_model('.\/best_model_1.h5')","620324a3":"# evaluate the model on validation set\nval_scores = []\nval_scores_1 = final_model_1.evaluate(X_val,y_val, verbose=0)\nprint(\"%s: %.2f%%\" % (final_model_1.metrics_names[1], val_scores_1[1]*100))\nval_scores.append(val_scores_1[1] * 100)","af428a9c":"# evaluate the model\nfinalscores = []\nfinal_scores_1 = final_model_1.evaluate(X_test,y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (final_model_1.metrics_names[1], final_scores_1[1]*100))\nfinalscores.append(final_scores_1[1] * 100)","b1e2dd67":"import gc\ngc.collect()","77fe44cb":"#using Grid Search and Early stopping\nes = EarlyStopping(monitor='val_acc', verbose=2, patience=5)\nmc = ModelCheckpoint('.\/best_model_2.h5', monitor='val_acc', verbose=2, save_best_only=True)\n\nHyp_Model_2 = KerasClassifier(build_fn=Revised_2_fn)\n#You need to pick the right hyper-parameters for your training (try with different ones)\n\nlearn_rate = [0.01]\nbatch_size = [32,75,100]\nepochs = [5]\n\nparam_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate = learn_rate)\nrandSearch_2 = GridSearchCV(estimator = Hyp_Model_2, param_grid=param_grid, cv=5)","33875504":"new_grid_2 = randSearch_2.fit(X_train,y_train,validation_data = (X_val, y_val), verbose=2,callbacks=[es,mc])","c09a959a":"from keras.models import load_model\nfinal_model_2 = load_model('.\/best_model_2.h5')","cddda50b":"val_scores_2 = final_model_2.evaluate(X_val,y_val, verbose=0)\nprint(\"%s: %.2f%%\" % (final_model_2.metrics_names[1], val_scores_2[1]*100))\nval_scores.append(val_scores_2[1] * 100)","bae15b3b":"# evaluate the model\nfinal_scores_2 = final_model_2.evaluate(X_test,y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (final_model_2.metrics_names[1], final_scores_2[1]*100))\nfinalscores.append(final_scores_2[1] * 100)","8c4deb9c":"import gc\ngc.collect()","9002fa15":"#using Grid Search and Early stopping\n\nes = EarlyStopping(monitor='val_acc', verbose=2, patience=5)\nmc = ModelCheckpoint('.\/best_model_3.h5', monitor='val_acc', verbose=2, save_best_only=True)\n\nHyp_Model_3 = KerasClassifier(build_fn=Revised_3_fn)\n#You need to pick the right hyper-parameters for your training (try with different ones)\n\nlearn_rate = [0.01]\nbatch_size = [32,75,100]\nepochs = [5]\n\nparam_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate = learn_rate)\nrandSearch_3 = GridSearchCV(estimator = Hyp_Model_3, param_grid=param_grid, cv=5)","cfa96d13":"new_grid_3 = randSearch_3.fit(X_train,y_train,validation_data = (X_val, y_val), verbose=2,callbacks=[es,mc])","04ed6623":"from keras.models import load_model\nfinal_model_3 = load_model('.\/best_model_3.h5')","88127497":"val_scores_3 = final_model_3.evaluate(X_val,y_val, verbose=0)\nprint(\"%s: %.2f%%\" % (final_model_3.metrics_names[1], val_scores_3[1]*100))\nval_scores.append(val_scores_3[1] * 100)","390ce22a":"# evaluate the model\nfinal_scores_3 = final_model_3.evaluate(X_test,y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (final_model_3.metrics_names[1], final_scores_3[1]*100))\nfinalscores.append(final_scores_3[1] * 100)","0875d7c2":"import gc\ngc.collect()","f3263dda":"val_scores","4b05086b":"finalscores","b5f0af4d":"plt.figure(figsize=(25, 5))\n\nplt.subplot(141)\ny_hits = val_scores\nx_hits = ['Val Score 1' ,'Val Score 2' ,'Val Score 3']\nplt.xticks(rotation = 'vertical')\nwidth = 1\/1.5\nplt.bar(x_hits, y_hits, width, color=['red', 'green', 'blue'])\nplt.xlabel('Training Set')\nplt.ylabel('Accuracy')\nplt.title('Bar Plot of Validation Score for all 3 Models')\n\nplt.subplot(142)\ny_hits = finalscores\nx_hits = ['Test Score 1','Test Score 2','Test Score 3']\nplt.xticks(rotation = 'vertical')\nwidth = 1\/1.5\nplt.bar(x_hits, y_hits, width, color=['red', 'green', 'blue'])\nplt.xlabel('Test Sets')\nplt.ylabel('Accuracy')\nplt.title('Bar Plot of Test Accuracy for all 3 Models')","7b096661":"pred=final_model_1.predict(X_test)\npred_digits=np.argmax(pred,axis=1)\nact_digits = np.argmax(y_test,axis=1)","5c6ecebd":"# now storing some properly as well as misclassified indexes'.\ni=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(y_test)):\n    if(act_digits[i]==pred_digits[i]):\n        prop_class.append(i)\n    if(len(prop_class)==8):\n        break\n\ni=0\nfor i in range(len(y_test)):\n    if(not act_digits[i]==pred_digits[i]):\n        mis_class.append(i)\n    if(len(mis_class)==8):\n        break","d5e1bc46":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ncount=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(X_test[prop_class[count]])\n        ax[i,j].set_title(\"Predicted Flower : \"+str(labelEncoder.inverse_transform([pred_digits[prop_class[count]]])) +\"\\n\"+\"Actual Flower : \"+str(labelEncoder.inverse_transform([act_digits[prop_class[count]]])))\n        plt.tight_layout()\n        count+=1","9895b476":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ncount=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(X_test[mis_class[count]])\n        ax[i,j].set_title(\"Predicted Flower : \"+str(labelEncoder.inverse_transform([pred_digits[mis_class[count]]])) +\"\\n\"+\"Actual Flower : \"+str(labelEncoder.inverse_transform([act_digits[mis_class[count]]])))\n        plt.tight_layout()\n        count+=1","88dc6580":"Classifying Flowers using Transfer Learning in Keras\n\n1- Download a small flower dataset (http:\/\/download.tensorflow.org\/example_images\/flower_photos.tgz). This dataset has 5 classes (Daisy, Dandelion, Rese, Sunflower, and Tulip). Images for each class are stored in its own folder.\n\n2- The images have different dimensions. Resize all of them to 150x150.\n\n3- Split images to 75-25% for training and test. Make sure you have the same distribution of flower types between train and test datasets. \n\n4- Use a VGG16 model (pre-trained on ImageNet)\n\n5- Remove the top layers (fully connected layers)\n\n6- Add your own fully connected layers (one with 256 nodes using \u2018relu\u2019 activation and output layer with 5 nodes and \u2018softmax\u2019 activation)\n\n7- First, freeze all layers of VGG16, train (fine-tune) and evaluate the model. You need to pick the right hyper-parameters for your training (try with different ones)\n\n8- Second, unfreeze the last block of VGG16 (block5), re-train and evaluate the model\n\n9- Unfreeze all the layers and try again. \n\n10- Compare the accuracy you got in both cases . Which one is better and why? ","344a85a7":"Train, Fine-Tune using Hyper parameters and evaluate the third model.","23161307":"Train, Fine-Tune using Hyper parameters and evaluate the first model.","978f181d":"Train, Fine-Tune using Hyper parameters and evaluate the second model.","9288946e":"Based on the graph above, The model with all trainable layers (model 1) is the Best model. \n\nNow we predict on Test Data using the best model and Classify the images correctly identified and incorrectly classified","f8dbe778":"CORRECTLY CLASSIFIED FLOWER IMAGES","e2eb7a4f":"MIS CLASSIFIED FLOWER IMAGES","db693394":"Model 2 -  Second, unfreeze the last block of VGG16 (block5)","9d676c70":"<b>Summary:<\/b>\n\nBased on the graph above, The model with all trainable layers (model 1) is the Best model in terms of accuracy.\n\nBy not updating the weights of most of the network we are only optimizing in a subset of the feature space. But the default VGG16 model had been trained on many Image datasets in the past and has been proven to deliver better results. But as soon as we unfreeze the layers, the model starts becoming trainable and because of back propogation enabled for a few layers in the model, it changes the weights for the 5th Block (Model 2), affecting its accuracy. The model 3, as a result becomes the worse model with all the layers been trainable. As more trainable layers use certain activation functions are added to neural networks, The gradients of the loss function approaches zero, making the network hard to train. Thus We may need a lot of data to train the 3rd model in order to achieve a better accuracy.","85bc49af":"Model 1 - VGG16  imorted with top layers cut off, all layers then are frozen and new fully connected layers are added.","23922807":"Model 3 : Unfreeze all the layers "}}