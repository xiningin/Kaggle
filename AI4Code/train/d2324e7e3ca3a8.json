{"cell_type":{"90b97c40":"code","9bc321aa":"code","14bcd69c":"code","482d7642":"code","ed449c3e":"code","cbd151f1":"code","6b2bd212":"code","95114d79":"code","bfd78a5e":"code","b32460c6":"markdown","64500243":"markdown","513d4e59":"markdown","a41ceea7":"markdown","3e755ad7":"markdown","86563ca7":"markdown","8ed13b26":"markdown"},"source":{"90b97c40":"import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport os","9bc321aa":"dataset = pd.read_csv('..\/input\/bbc-fulltext-and-category\/bbc-text.csv')\ndataset.head()","14bcd69c":"dataset.text[0] #The data was already prepared and stop words were removed :(","482d7642":"import re, string\nvectorizer = TfidfVectorizer(ngram_range=(1,2),\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1, stop_words='english')\nX = vectorizer.fit_transform(dataset.text)\nword_vects = X.toarray()\nword_vects.shape","ed449c3e":"import umap\n\nreducer = umap.UMAP(random_state=70,metric='cosine')\nembedding = reducer.fit_transform(word_vects)","cbd151f1":"import matplotlib.pyplot as plt\nplt.scatter(embedding[:,0], embedding[:,1])\nplt.title(\"UMAP dimentionality Reduction\")\nplt.show()","6b2bd212":"from sklearn.cluster import KMeans\n\nclustering = KMeans(n_clusters=6, init='k-means++').fit(embedding)\n\ndataset['cluster'] = clustering.labels_\ndataset['vectX'] = embedding[:,0]\ndataset['vectY'] = embedding[:,1]\ndataset.cluster.unique()\nplt.figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\nfor x in dataset.cluster.unique():\n    vctsX = dataset.loc[dataset.cluster == x].vectX\n    vctsY = dataset.loc[dataset.cluster == x].vectY\n    c = dataset.loc[dataset.cluster == x].cluster\n    plt.title(\"K-means Clustering\")\n    plt.scatter(vctsX, vctsY, c=np.random.rand(3,), label=x)\n    plt.legend(loc='upper left')","95114d79":"cluster2cat = {}\n\nfor x in dataset.cluster.unique():\n    cat = {}\n    ds = dataset.loc[dataset.cluster == x]\n    for y in ds.category.unique():\n        cat[y] = ds.loc[ds.category == y].count()['category']\n    print(x, 'Shows labeled data of:', cat)\n    i = 0\n    # Get the most frequent label\n    selected = list(cat.values()).index(max(cat.values()))\n    cluster2cat[x] = list(cat.keys())[selected]\nprint(\"Mapping is:\",cluster2cat)","bfd78a5e":"dataset['cluster_class'] = dataset['cluster'].map(cluster2cat)\nconfusion_matrix = pd.crosstab(dataset.category, dataset.cluster_class, rownames=['Actual'], colnames=['Predicted'])\naccuracy = confusion_matrix.values.diagonal().sum()\/(confusion_matrix.values.sum())\nprint(\"Accuracy: %.2f\"%(100*accuracy)+\"%\")\nconfusion_matrix.head(10)","b32460c6":"### Defined Clusters\nAs you can see we have well defined clusters when using UMAP (cosine metric)","64500243":"## Dimentionality Reduction and Clustering\nWe will use UMAP to reduce the dimentionality after that we will use K-Means to separate out the clusters.","513d4e59":"### Conclusion\nWe can see that it clusters quite well!! :D","a41ceea7":"## Results and Conclusion\nWe can compare the clustering with the labels.\nIn a real life scenario we might use human assistance to read some examples and label the clusters accordingly.","3e755ad7":"## Basics 3 - \"Unsupervised Beginner Mode\"\nWe want to group articles without using the given category.. we will use the category only to ensure that our model is coherent. ","86563ca7":"## Vectorize\nhere we build a Sparce Matrix of the vectors in the database ","8ed13b26":"### Let's give K-Means a go... "}}