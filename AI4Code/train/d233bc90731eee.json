{"cell_type":{"bfa7575f":"code","3ca908bc":"code","10e1afc4":"code","98cdc6f3":"code","5f52577c":"code","f484492d":"code","f1c6a339":"code","fd779299":"code","e2c5d66c":"code","0359c500":"code","2a2acbe9":"markdown","4c111af0":"markdown","fc88e3d1":"markdown","eea79be9":"markdown","ce385c5c":"markdown","1871a1c7":"markdown","8f29629f":"markdown","57e04837":"markdown"},"source":{"bfa7575f":"import tensorflow as tf\nimport os, sys\ntf.__version__","3ca908bc":"%%capture\n!pip install ..\/input\/tf-model-garden-official-models\/tf_models_official-2.3.0-py2.py3-none-any.whl --user\n!pip install pycocotools","10e1afc4":"!cp \/kaggle\/input\/tf-model-garden-official-models\/tf-models-official-2.3.0\/tf-models-official-2.3.0\/official\/vision\/detection\/main.py .","98cdc6f3":"%%writefile .\/config.yaml\narchitecture:\n  num_classes: 14\ntrain:\n  train_file_pattern: \n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?0-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?2-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?3-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?4-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?5-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?6-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?7-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?8-of-020.tfrecord\"\n  total_steps: 18000\n  batch_size: 12\n  input_sharding: true\n  iterations_per_loop: 1000\neval:\n  eval_file_pattern: \n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?1-of-020.tfrecord\"\n    - \"\/kaggle\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/VinBig-0?9-of-020.tfrecord\"\n  batch_size: 1\n  eval_samples: 879\n    \nretinanet_parser:\n  aug_rand_hflip: false\n  aug_scale_max: 1.0\n  aug_scale_min: 1.0","5f52577c":"%%capture cap\n!python main.py \\\n  --strategy_type=one_device \\\n  --num_gpus=1 \\\n  --model_dir=.\/model1 \\\n  --mode=train \\\n  --model=retinanet \\\n  --config_file=\".\/config.yaml\"","f484492d":"with open('.\/train.log', 'w') as f:\n    f.write(cap.stdout)","f1c6a339":"%%capture\n!pip install --user parse","fd779299":"from parse import *\nimport matplotlib.pyplot as plt\n%matplotlib inline","e2c5d66c":"with open('.\/train.log', 'r') as f:\n    data=f.read()\nloss=[]\nfor r in findall(\"\\'model_loss\\': {:f}\", data):\n    loss.append(r[0])\ncls=[] \nfor r in findall(\"\\'cls_loss\\': {:f}\", data): # class loss\n    cls.append(r[0])\nstep=[]\nfor r in findall(\"Train Step: {:d}\", data):\n    step.append(r[0])\nplt.figure(figsize=(16, 8))\nplt.plot(step,loss[0::2])\nplt.plot(step,cls[0::2])\nplt.legend(['model loss', 'class loss'])\nplt.xlabel('Global step')\nplt.title('Learning curves');","0359c500":"import json \n\nwith open('..\/input\/data-create-tfrecords-of-vinbigdata-chest-x-rays\/dparams.json') as json_file:\n     dparams = json.load(json_file)\ndparams","2a2acbe9":"![TF](https:\/\/www.gstatic.com\/devrel-devsite\/prod\/ve312520032ba2ac0c4d23f7b46fc670cbbe051886a2d1f04563a5e4768ad9787\/tensorflow\/images\/lockup.svg)","4c111af0":"# Install the TF Object Detection API\nImportant here that we install the same version of the API as the TensorFlow version.","fc88e3d1":"One important detail to be aware of is that the check-points created during training are about 260MByte each - and the maximum notebook diskspace use is 5GB. We could move the training from \/kaggle\/working to \/tmp which has more space. Or we can increase the interval between checkpoints by setting the \"iterations_per_loop\" to desired interval. The default setting is 100 (steps). We increase it to 1000 in the .yaml file above. ","eea79be9":"Next we copy the training script from the source code.","ce385c5c":"# Training\nRunning \"main.py\" below will perform training. The output is captured to file for parsing further down.","1871a1c7":"Check the learning curves (by parsing the log file).","8f29629f":"\"main.py\" will create the file \"params.yaml\" with the model configuration in the model directory we specify. We need to add the training and evaluation files (which were created in [this notebook](https:\/\/www.kaggle.com\/mistag\/data-create-tfrecords-of-vinbigdata-chest-x-rays)), and also override some of the default parameters. This is done by creating another .yaml file with our custom settings:","57e04837":"That's it! The trained model in the \"model1\" directory can now be used for predictions, but that must be done in a notebook without internet enabled for submission...  \nAlso remember to use the same preprocessing (CLAHE) on the test images as the [TFRecords creation notebook](https:\/\/www.kaggle.com\/mistag\/data-create-tfrecords-of-vinbigdata-chest-x-rays). The CLAHE parameters used can be found in a .json file:"}}