{"cell_type":{"a23cfcf4":"code","cce98dd9":"code","01c61cb5":"code","42ef70c1":"code","65608bca":"code","dfd868db":"code","955b3475":"code","ebccf7f2":"code","0d545711":"code","e986d17d":"code","0920f577":"code","4e35e434":"code","079fc32d":"code","4be70ac6":"markdown","161bd30b":"markdown","0f3d3610":"markdown","29779634":"markdown","80cf48e9":"markdown","539afd8e":"markdown","201580ed":"markdown","9cc5dba0":"markdown","7c2efc11":"markdown","bbceaba5":"markdown","9982f647":"markdown","4fb88d68":"markdown","9654b9d2":"markdown"},"source":{"a23cfcf4":"import os\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n#os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"10\"\n#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n\nfrom platform import python_version\nimport warnings\nimport time\nimport datetime as dt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport multiprocessing as mp\nimport shutil\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\n# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\n\nfrom PIL import Image\nimport xml.etree.ElementTree as ET\nimport psutil\nimport random\n\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy)\n\nprint(\"py\", python_version())\nprint(\"tf\", tf.__version__)\nprint(\"keras\", tf.keras.__version__)\nmem = psutil.virtual_memory()\nprint(\"mem\", mem.total\/1024\/1024)\ncpu = mp.cpu_count()\nprint(\"cpu\", cpu)\nprint('Compute dtype: %s' % policy.compute_dtype)\nprint('Variable dtype: %s' % policy.variable_dtype)\n\n%system nvidia-smi\n#%system rocm-smi","cce98dd9":"epochs = 100\nbatch_size = 100\ntestsplit = .2\ntargetx = 224\ntargety = 224\nlearning_rate = 0.0001\nclasses = 120\nseed = random.randint(1, 1000)\n\ndata_dir = \"\/kaggle\/input\/images\/Images\/\"\nannotations_dir = \"\/kaggle\/input\/annotations\/Annotation\/\"\ncropped_dir = \"\/kaggle\/working\/cropped\/\"","01c61cb5":"%system rm -rf $cropped_dir\n%system mkdir $cropped_dir\n\n#this function adapted from https:\/\/www.kaggle.com\/hengzheng\/dog-breeds-classifier\ndef save_cropped_img(path, annotation, newpath):\n    tree = ET.parse(annotation)\n    xmin = int(tree.getroot().findall('.\/\/xmin')[0].text)\n    xmax = int(tree.getroot().findall('.\/\/xmax')[0].text)\n    ymin = int(tree.getroot().findall('.\/\/ymin')[0].text)\n    ymax = int(tree.getroot().findall('.\/\/ymax')[0].text)\n    image = Image.open(path)\n    image = image.crop((xmin, ymin, xmax, ymax))\n    image = image.convert('RGB')\n    image.save(newpath)\n\ndef crop_images():\n    breeds = os.listdir(data_dir)\n    annotations = os.listdir(annotations_dir)\n\n    print('breeds: ', len(breeds), 'annotations: ', len(annotations))\n\n    total_images = 0\n\n    for breed in breeds:\n        dir_list = os.listdir(data_dir + breed)\n        annotations_dir_list = os.listdir(annotations_dir + breed)\n        img_list = [data_dir + breed + '\/' + i for i in dir_list]\n        os.makedirs(cropped_dir + breed)\n\n        for file in img_list:\n            annotation_path = annotations_dir + breed + '\/' + os.path.basename(file[:-4])\n            newpath = cropped_dir + breed + '\/' + os.path.basename(file)\n            save_cropped_img(file, annotation_path, newpath)\n            total_images += 1\n    \n    print(\"total images cropped\", total_images)\n\ncrop_images()","42ef70c1":"datagen = ImageDataGenerator(\n        shear_range=0.1,\n        zoom_range=0.1,\n        brightness_range=[0.9,1.1],\n        horizontal_flip=True,\n        validation_split=testsplit,\n        preprocessing_function=preprocess_input\n)\n\ntrain_generator = datagen.flow_from_directory(\n        cropped_dir,\n        target_size=(targetx, targety),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True,\n        seed=seed,\n        subset=\"training\"\n)\n\ntest_generator = datagen.flow_from_directory(\n        cropped_dir,\n        target_size=(targetx, targety),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False,\n        seed=seed,\n        subset=\"validation\"\n)","65608bca":"img = train_generator.filepaths[np.random.random_integers(low=0, high=train_generator.samples)]\nprint(img)\nimg = mpimg.imread(img)\nplt.imshow(img)","dfd868db":"checkpoint = ModelCheckpoint('dog_breed_classifier.h5',\n                             monitor='val_accuracy',\n                             save_best_only=True,\n                             verbose=1,\n                             mode='auto',\n                             save_weights_only=False,\n                             period=1)\n\n#https:\/\/github.com\/keras-team\/keras\/issues\/3358\ntensorboard = TensorBoard(log_dir=\".\/logs-\"+dt.datetime.now().strftime(\"%m%d%Y%H%M%S\"),\n                            histogram_freq=0,\n                            batch_size=batch_size,\n                            write_graph=False,\n                            update_freq='epoch')\n\ndef epoch_end(epoch, logs):\n    message = \"End of epoch \"+str(epoch)+\". Learning rate: \"+str(K.eval(model.optimizer.lr))\n    os.system('echo '+message)\n\ndef epoch_begin(epoch, logs):\n    print(\"Learning rate: \", K.eval(model.optimizer.lr))\n    \ndef train_begin(logs):\n    os.system(\"echo Beginning training\")\n\nearlystop = EarlyStopping(monitor='val_accuracy',\n                          min_delta=.0001,\n                          patience=20,\n                          verbose=1,\n                          mode='auto',\n                          baseline=None,\n                          restore_best_weights=True)\n\nreducelr = ReduceLROnPlateau(monitor='val_accuracy',\n                             factor=np.sqrt(.1),\n                             patience=5,\n                             verbose=1,\n                             mode='auto',\n                             min_delta=.0001,\n                             cooldown=0,\n                             min_lr=0.0000001)\n\nlambdacb = LambdaCallback(on_epoch_begin=epoch_begin,\n                          on_epoch_end=epoch_end,\n                          on_batch_begin=None,\n                          on_batch_end=None,\n                          on_train_begin=train_begin,\n                          on_train_end=None)","955b3475":"# base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))\nbase_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# x = Dropout(rate = .2)(x)\nx = BatchNormalization()(x)\nx = Dense(1280, activation='relu',  kernel_initializer=glorot_uniform(seed), bias_initializer='zeros')(x)\n# x = Dropout(rate = .2)(x)\nx = BatchNormalization()(x)\npredictions = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\noptimizer = Adam(lr=learning_rate)\n# optimizer = RMSprop(lr=learning_rate)\n\nloss = \"categorical_crossentropy\"\n# loss = \"kullback_leibler_divergence\"\n\nfor layer in model.layers:\n    layer.trainable = True\n# for layer in model.layers[-2:]:\n#     layer.trainable = True\n\nmodel.compile(optimizer=optimizer,\n              loss=loss,\n              metrics=[\"accuracy\"])\n\nmodel.summary()\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","ebccf7f2":"%%time\n\nparams = model.fit_generator(generator=train_generator, \n                                steps_per_epoch=len(train_generator), \n                                validation_data=test_generator, \n                                validation_steps=len(test_generator),\n                                epochs=epochs,\n                                callbacks=[reducelr, earlystop, lambdacb, tensorboard, checkpoint])","0d545711":"plt.subplot(1, 2, 1)\nplt.title('Training and test accuracy')\nplt.plot(params.epoch, params.history['accuracy'], label='Training accuracy')\nplt.plot(params.epoch, params.history['val_accuracy'], label='Test accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.title('Training and test loss')\nplt.plot(params.epoch, params.history['loss'], label='Training loss')\nplt.plot(params.epoch, params.history['val_loss'], label='Test loss')\nplt.legend()\n\nplt.show()","e986d17d":"# Randomly test an image from the test set\n# model.load_weights('dog_breed_classifier.h5')\n\nimageno=np.random.random_integers(low=0, high=test_generator.samples)\n\nname = test_generator.filepaths[imageno]\nprint(name)\nplt.imshow(mpimg.imread(name))\n\nimg = Image.open(test_generator.filepaths[imageno]).resize((targetx, targety))\nprobabilities = model.predict(preprocess_input(np.expand_dims(img, axis=0)))\nbreed_list = tuple(zip(test_generator.class_indices.values(), test_generator.class_indices.keys()))\n\nfor i in probabilities[0].argsort()[-5:][::-1]: \n    print(probabilities[0][i], \"  :  \" , breed_list[i])","0920f577":"test_generator.reset()\npredictions = model.predict_generator(test_generator, steps=len(test_generator))\ny = np.argmax(predictions, axis=1)\n\nprint('Classification Report')\ncr = classification_report(y_true=test_generator.classes, y_pred=y, target_names=test_generator.class_indices)\nprint(cr)","4e35e434":"print('Confusion Matrix')\ncm = confusion_matrix(test_generator.classes, y)\ndf = pd.DataFrame(cm, columns=test_generator.class_indices)\nplt.figure(figsize=(80,80))\nsn.heatmap(df, annot=True)","079fc32d":"shutil.rmtree(cropped_dir)","4be70ac6":"# Keras callbacks","161bd30b":"# Sample prediction","0f3d3610":"# Fit model","29779634":"# Changelog\n\n## V38 - Update to mixed precision float16 training, TF 2.4\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-efficientnets\n\n## V37 - Updates, switch to EfficientNets, TF 2.3\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-efficientnets?scriptVersionId=40698248\n\n## V36 - Updates, works with TF 2.0\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-mobilenet-v2?scriptVersionId=24113974\n\n## V32 - Updates, added Confusion Matrix\/Classification Report\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-mobilenet-v2?scriptVersionId=19440127\n\n## V24 - First working notebook\nhttps:\/\/www.kaggle.com\/devang\/transfer-learning-with-keras-and-mobilenet-v2?scriptVersionId=16125907\n","80cf48e9":"# Confusion matrix","539afd8e":"# Imports","201580ed":"# Keras image data readers","9cc5dba0":"# Variables","7c2efc11":"# Classification report","bbceaba5":"# Sample image","9982f647":"# Crop images using provided annotations","4fb88d68":"# Training and test loss\/accuracy graphs","9654b9d2":"# Define new top layers and compile model"}}