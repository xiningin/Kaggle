{"cell_type":{"4dac3243":"code","8b8dcd26":"code","9f8677b0":"code","55df431a":"code","80e32a26":"code","85a3fd49":"code","8c7afd62":"code","a17a5af1":"code","3371a459":"code","a05ea231":"code","d59a169e":"code","17deeb85":"code","eb113b83":"code","de3a7cbb":"code","1f41aa40":"code","3bfe2d69":"code","70e8bcba":"code","ef9d295b":"code","8afd0d8b":"markdown","692f22c4":"markdown","29a9fba7":"markdown","30a9fc51":"markdown","13c529e7":"markdown","1c14824e":"markdown","c0433479":"markdown","e252f434":"markdown","2275ca95":"markdown"},"source":{"4dac3243":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nfrom scipy.spatial import distance\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8b8dcd26":"#loading haarcascade_frontalface_default.xml\nface_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')","9f8677b0":"import matplotlib.pyplot as plt\n#trying it out on a sample image\nimg = cv2.imread('..\/input\/face-mask-detection\/images\/maksssksksss244.png')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4) #returns a list of (x,y,w,h) tuples\n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n\n#plotting\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,250,0),1)\nplt.figure(figsize=(12,12))\nplt.imshow(out_img)","55df431a":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras import Sequential\nfrom keras.layers import Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator","80e32a26":"#Load train and test set\ntrain_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\ntest_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\nval_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'","85a3fd49":"# Data augmentation\n\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\ntrain_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\nval_datagen = ImageDataGenerator(rescale=1.0\/255)\nval_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\ntest_datagen = ImageDataGenerator(rescale=1.0\/255)\ntest_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)","8c7afd62":"vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n\nfor layer in vgg19.layers:\n    layer.trainable = False\n    \nmodel = Sequential()\nmodel.add(vgg19)\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='sigmoid'))\nmodel.summary()","a17a5af1":"model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")","3371a459":"history = model.fit_generator(generator=train_generator,\n                              steps_per_epoch=len(train_generator)\/\/32,\n                              epochs=20,validation_data=val_generator,\n                              validation_steps=len(val_generator)\/\/32)","a05ea231":"model.evaluate_generator(test_generator)","d59a169e":"sample_mask_img = cv2.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithMask\/1565.png')\nsample_mask_img = cv2.resize(sample_mask_img,(128,128))\nplt.imshow(sample_mask_img)\nsample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\nsample_mask_img = sample_mask_img\/255.0","17deeb85":"model.predict(sample_mask_img)","eb113b83":"model.save('masknet.h5')","de3a7cbb":"mask_label = {\n    0:'MASK',\n    1:'NO MASK'\n             }\nrect_label = {\n    0:(0,250,0),\n    1:(250,0,0)\n             }","1f41aa40":"def show_results(p):\n    img = cv2.imread(p)\n    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n    faces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n\n    label = [0 for i in range(len(faces))]\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    counter_masks = {\n        'has_mask': 0,\n        'no_mask': 0\n    }\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])\/255.0\n\n        mask_result = model.predict(crop)\n        has_mask = mask_result.argmax()\n\n        if has_mask==0:\n            counter_masks['has_mask'] += 1\n        else:\n            counter_masks['no_mask'] += 1\n\n        cv2.putText(new_img,mask_label[has_mask],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,rect_label[has_mask],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),rect_label[has_mask],1)\n\n    plt.figure(figsize=(10,10))\n    annot1 = f\"People with MASKS: {counter_masks['has_mask']};\"\n    annot2 = f\"People with NO MASKS: {counter_masks['no_mask']}.\"\n    cv2.putText(new_img,text=annot1,org=(10, 10),fontFace=cv2.FONT_HERSHEY_TRIPLEX,fontScale=0.5,color=(255, 255, 255),thickness=1)\n    cv2.putText(new_img,text=annot2,org=(10, 30),fontFace=cv2.FONT_HERSHEY_TRIPLEX,fontScale=0.5,color=(255, 255, 255),thickness=1)\n    plt.imshow(new_img)","3bfe2d69":"import random\nimport glob","70e8bcba":"good_preds = [\n'..\/input\/face-mask-detection\/images\/maksssksksss37.png',\n'..\/input\/face-mask-detection\/images\/maksssksksss21.png',\n'..\/input\/face-mask-detection\/images\/maksssksksss537.png',\n'..\/input\/face-mask-detection\/images\/maksssksksss29.png',\n'..\/input\/face-mask-detection\/images\/maksssksksss581.png',\n'..\/input\/face-mask-detection\/images\/maksssksksss96.png']\n\nfor p in good_preds:\n    print(p)\n    show_results(p)","ef9d295b":"some_img = glob.glob(\"..\/input\/face-mask-detection\/images\/*.png\")\n\nfor p in random.choices(some_img, k=5):\n    print(p)\n    show_results(p)","8afd0d8b":"### Using haar cascade to detect faces\n\nObject Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. We'll be using a Haar Cascade Model trained to detect faces in order to obtain the bounding box coordinates of faces in an image.","692f22c4":"### Testing the model on the test data","29a9fba7":"We now take crops of the faces detected in the image and use the model trained in the above section to determine whether the individual faces have a mask or not.","30a9fc51":"### Building VGG19 transfer learning model.","13c529e7":"### Using VGG19 for mask detection\n","1c14824e":"#### Good prediction examples","c0433479":"The model is able to classify if the person is wearing a mask or not.","e252f434":"### Save the model.","2275ca95":"### Integrating with haar cascade"}}