{"cell_type":{"2e480dc4":"code","e59d053a":"code","3262a74c":"code","25feee06":"code","d26820d6":"code","9d9b94a8":"code","7f663e66":"code","7518c862":"code","d3a74a20":"code","76e90934":"code","7d543677":"code","b4e363b0":"code","fbbc7f79":"code","8f39fae4":"code","a02a0db6":"code","7c3678d8":"code","87c4ffde":"code","2a832a88":"code","f7e88a75":"code","410ff9c2":"code","313d384a":"code","3607b8c8":"code","a7581071":"code","73eb6e9c":"code","af6fc95c":"code","f6f394f4":"code","6b1efc51":"code","32504c1e":"code","039007d6":"code","ca84a809":"code","3c933ce8":"code","e1673962":"code","55489a19":"code","db95f9d7":"code","ed8a583e":"code","ef5c2564":"code","67e7ce99":"code","73818d5f":"code","3e727855":"code","bb82fa4f":"code","b8398390":"code","afca5f91":"code","2554e0cd":"code","3f25d26e":"code","cfb7521c":"code","bd0af86b":"code","b048ebde":"code","fdf004e9":"code","a967e8ef":"code","234f2125":"code","02266854":"code","cf55c90d":"markdown"},"source":{"2e480dc4":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.impute import SimpleImputer","e59d053a":"# reading the train.csv \ndata=pd.read_csv(\"..\/input\/train.csv\") \n#reading the test data\ntest=pd.read_csv(\"..\/input\/test.csv\")","3262a74c":"data.head()","25feee06":"data.shape","d26820d6":"data.describe()","9d9b94a8":"#checking NA's \ndata.isna().sum()","7f663e66":"# removing rows where fare_amount is 0 as those rows cannot help us to predict the target(fare_amount)\ndata=data.loc[data.fare_amount>0,]","7518c862":"data['passenger_count'].value_counts()","d3a74a20":"#removing rows where passenger_count is zero\ndata=data[data[\"passenger_count\"]>0]","76e90934":"#droping NA's from pickup_longitute,pickup_latitide,dropoff_latittue,dropff_longitute columns\ndata.dropna(subset = ['pickup_longitude', 'pickup_latitude', 'dropoff_latitude', 'dropoff_longitude'], inplace= True)","7d543677":"#converting pickup_datetime,dropoff_datetime into datetime\ndata[\"pickup_datetime\"]=pd.to_datetime(data[\"pickup_datetime\"])\ndata[\"dropoff_datetime\"]=pd.to_datetime(data[\"dropoff_datetime\"])\n\n#adding  new variables called \"duration\",'hour','day','month','year' \ndata['duration']=abs(data['pickup_datetime']-data['dropoff_datetime'])\/np.timedelta64(1,'m')\n\ndata['hour'] = data.pickup_datetime.dt.hour\ndata['day'] = data.pickup_datetime.dt.day\ndata['month'] = data.pickup_datetime.dt.month\ndata['year'] = data.pickup_datetime.dt.year","b4e363b0":"#creating a list of unwanted features\ncols_drop=['TID','pickup_datetime','dropoff_datetime','new_user','store_and_fwd_flag']","fbbc7f79":"#droping the unwanted features\ndata.drop(cols_drop,axis=1,inplace=True)","8f39fae4":"#addind a new feature called \"distance\",which is extracted from latitudes and langitudes.\ndef distance(s_lat, s_lng, e_lat, e_lng):\n    \n    # approximate radius of earth in km\n    R = 6373.0\n    \n    s_lat = s_lat*np.pi\/180.0                      \n    s_lng = np.deg2rad(s_lng)     \n    e_lat = np.deg2rad(e_lat)                       \n    e_lng = np.deg2rad(e_lng)  \n    \n    d = np.sin((e_lat - s_lat)\/2)**2 + np.cos(s_lat)*np.cos(e_lat) * np.sin((e_lng - s_lng)\/2)**2\n    \n    return 2 * R * np.arcsin(np.sqrt(d)) \n#adding distance column to the dataset \ndata['distance'] = distance(data.pickup_latitude,data.pickup_longitude,data.dropoff_latitude,data.dropoff_longitude)","a02a0db6":"corr=data.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr,annot=True,)","7c3678d8":"sns.distplot(data.loc[data.fare_amount<200,'fare_amount'])\nplt.xlabel(\"fare_amount\")\nplt.ylabel(\"Frequency\")\nplt.title(\"distribution of fare_amount\")","87c4ffde":"sns.distplot(data.loc[data.distance<200,'distance'])\nplt.title(\"distrtibution of distance travelled\")\nplt.ylabel(\"Frequency\")","2a832a88":"sns.boxplot(x='passenger_count',y='fare_amount',data=data)\nplt.ylim(0,40)\nplt.title('passenger count vs fare')","f7e88a75":"plt.scatter(x='distance',y='fare_amount',data=data)\nplt.ylim(0,70)\nplt.xlim(0,80)\nplt.xlabel('distance')\nplt.ylabel('fare amount')\nplt.title('distance vs fare amount')","410ff9c2":"plt.scatter(x='duration',y='fare_amount',data=data)\nplt.ylim(0,70)\nplt.xlim(0,200)\nplt.xlabel('duration in minutes')\nplt.ylabel('fare_amount')\nplt.title('duratoin vs fare amount')","313d384a":"sns.boxplot(x='passenger_count',y='distance',data=data)\nplt.ylim(0,10)\nplt.title('passenger count vs fare')","3607b8c8":"#splitting the data into train,validation\ny=data.fare_amount\nX=data\nX.drop('fare_amount',axis=1,inplace=True)","a7581071":"train_X,valid_X,train_y,valid_y=train_test_split(X,y,train_size=0.7,random_state=1)\nprint(train_X.shape)\nprint(valid_X.shape)\nprint(train_y.shape)\nprint(valid_y.shape)","73eb6e9c":"#creating lists fro categorical and numeric columns\ncat_cols = [\"vendor_id\",\"payment_type\"]\nnum_cols = train_X.columns.difference(cat_cols)\nnum_cols","af6fc95c":"#converting the datatypes \ntrain_X[cat_cols]=train_X[cat_cols].apply(lambda x:x.astype(\"category\"))\ntrain_X[num_cols]=train_X[num_cols].apply(lambda x:x.astype(\"float\"))\n\n","f6f394f4":"train_num_data = train_X.loc[:,num_cols]\ntrain_cat_data = train_X.loc[:,cat_cols]","6b1efc51":"# numeric cols imputation\nimp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp_num.fit(train_num_data)\ntrain_num_data = pd.DataFrame(imp_num.transform(train_num_data),columns=num_cols)\n\n# Categorical columns imputation\nimp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n\ntrain_cat_data = pd.DataFrame(imp_cat.fit_transform(train_cat_data),columns=cat_cols)","32504c1e":"#standardizing the train data\nstand=StandardScaler()\nstand.fit(train_num_data[train_num_data.columns])\ntrain_num_data[train_num_data.columns]=stand.transform(train_num_data[train_num_data.columns])","039007d6":"train_X=pd.concat([train_num_data,train_cat_data],axis=1)","ca84a809":"#creating dummies for categorical columns\ntrain_X=pd.get_dummies(train_X,columns=cat_cols)","3c933ce8":"train_X.head()","e1673962":"# preprocessing on validation set\nvalid_X[cat_cols]=valid_X[cat_cols].apply(lambda x:x.astype(\"category\"))\nvalid_X[num_cols]=valid_X[num_cols].apply(lambda x:x.astype(\"float\"))\nvalid_num_data = valid_X.loc[:,num_cols]\nvalid_cat_data = valid_X.loc[:,cat_cols]\n\n# numeric cols imputation\n\nvalid_num_data = pd.DataFrame(imp_num.transform(valid_num_data),columns=num_cols)\n\n# Categorical columns imputation\n\n\nvalid_cat_data = pd.DataFrame(imp_cat.transform(valid_cat_data),columns=cat_cols)","55489a19":"#standarding the valdiation data\nvalid_num_data[valid_num_data.columns]=stand.transform(valid_num_data[valid_num_data.columns])","db95f9d7":"valid_X=pd.concat([valid_num_data,valid_cat_data],axis=1)\n\nvalid_X=pd.get_dummies(valid_X,columns=cat_cols)","ed8a583e":"#preprocessing on test data\n#converting pickup_datetime,dropoff_datetime into datetime\ntest[\"pickup_datetime\"]=pd.to_datetime(test[\"pickup_datetime\"])\ntest[\"dropoff_datetime\"]=pd.to_datetime(test[\"dropoff_datetime\"])\n\n#adding a new variable called \"duration\" \ntest['duration']=abs(test['pickup_datetime']-test['dropoff_datetime'])\/np.timedelta64(1,'m')\n\ntest['hour'] = test.pickup_datetime.dt.hour\ntest['day'] = test.pickup_datetime.dt.day\ntest['month'] = test.pickup_datetime.dt.month\ntest['year'] = test.pickup_datetime.dt.year\n\n#droping unwanted columns\ncols_drop=['TID','pickup_datetime','dropoff_datetime','new_user','store_and_fwd_flag']\ntest.drop(cols_drop,axis=1,inplace=True)\n\ndef distance(s_lat, s_lng, e_lat, e_lng):\n    \n    # approximate radius of earth in km\n    R = 6373.0\n    \n    s_lat = s_lat*np.pi\/180.0                      \n    s_lng = np.deg2rad(s_lng)     \n    e_lat = np.deg2rad(e_lat)                       \n    e_lng = np.deg2rad(e_lng)  \n    \n    d = np.sin((e_lat - s_lat)\/2)**2 + np.cos(s_lat)*np.cos(e_lat) * np.sin((e_lng - s_lng)\/2)**2\n    \n    return 2 * R * np.arcsin(np.sqrt(d)) \ntest['distance'] = distance(test.pickup_latitude,test.pickup_longitude,test.dropoff_latitude,test.dropoff_longitude)","ef5c2564":"# preprocessing on test set\ntest[cat_cols]=test[cat_cols].apply(lambda x:x.astype(\"category\"))\ntest[num_cols]=test[num_cols].apply(lambda x:x.astype(\"float\"))","67e7ce99":"test_num_data=test.loc[:,num_cols]\ntest_cat_data=test.loc[:,cat_cols]\n# numeric cols imputation\n\ntest_num_data = pd.DataFrame(imp_num.transform(test_num_data),columns=num_cols)\n\n# Categorical columns imputation\n\n\ntest_cat_data = pd.DataFrame(imp_cat.transform(test_cat_data),columns=cat_cols)","73818d5f":"#standarding the test data\ntest_num_data[test_num_data.columns]=stand.transform(test_num_data[test_num_data.columns])","3e727855":"test=pd.concat([test_num_data,test_cat_data],axis=1)\n\ntest=pd.get_dummies(test,columns=cat_cols)","bb82fa4f":"# MODEL1 LINEAR REGRESSION\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nlir=LinearRegression()\nlir.fit(train_X,train_y)\n\ntrain_preds1=lir.predict(train_X)\nvalid_preds1=lir.predict(valid_X)","b8398390":"# MODEL1 PREDICTIONS\nprint(\"mean_absolute_error on train data:\",mean_absolute_error(train_y,train_preds1))\nprint(\"mean_absolute_error on validation data:\",mean_absolute_error(valid_y,valid_preds1))","afca5f91":"# MODEL2 DECISION TREE REGRESSOR \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\ndtc=DecisionTreeRegressor()\ndtc.fit(train_X,train_y)\n\ntrain_preds2=dtc.predict(train_X)\nvalid_preds2=dtc.predict(valid_X)\n\nprint(\"mean_absolute_error on train data:\",mean_absolute_error(train_y,train_preds2))\nprint(\"mean_absolute_error on validation data:\",mean_absolute_error(valid_y,valid_preds2))","2554e0cd":"# MODEL3 KNN REGRESSOR\nfrom sklearn.neighbors import KNeighborsRegressor\nknn=KNeighborsRegressor(n_neighbors=3,algorithm=\"brute\",weights=\"distance\")\nknn.fit(train_X,train_y)\n\ntrain_preds3=knn.predict(train_X)\nvalid_preds3=knn.predict(valid_X)\nprint(\"mean_absolute_error on train data:\",mean_absolute_error(train_y,train_preds3))\nprint(\"mean_absolute_error on validation data:\",mean_absolute_error(valid_y,valid_preds3))","3f25d26e":"# MODEL 4 XGBOOST\nfrom xgboost import XGBRegressor\nxgb = XGBRegressor()\nxgb.fit(train_X,train_y)\n\ntrain_pred4=xgb.predict(train_X)\nvalid_pred4=xgb.predict(valid_X)\n\nprint(\"mean_absolute_error on train data:\",mean_absolute_error(train_y,train_pred4))\nprint(\"mean_absolute_error on validation data:\",mean_absolute_error(valid_y,valid_pred4))","cfb7521c":"#hyperparameters tuning\nXgb=XGBRegressor()\nn_estimaters=[50,100,150,200]\nmax_depth=[2,3,5,7]\nlearnin_rate=[0.05,0.1,0.15,0.20]\nmin_child_wgt=[1,2,3,4]\n\n\n\nhyperparameter={\n    \"n_estimaters\":n_estimaters,\n    \"max_depth\":max_depth,\n    \"learnin_rate\":learnin_rate,\n    \"min_child_wgt\":min_child_wgt,\n\n}\n\nrandom_cv2=RandomizedSearchCV(estimator=Xgb,param_distributions=hyperparameter,cv=5,n_jobs=-1)","bd0af86b":"random_cv2.fit(train_X,train_y)","b048ebde":"random_cv2.best_estimator_","fdf004e9":"#XGBOOST WITH BEST ESTIMATER\nXgb2=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0,\n             importance_type='gain', learnin_rate=0.05, learning_rate=0.1,\n             max_delta_step=0, max_depth=7, min_child_weight=1, min_child_wgt=2,\n             missing=None, n_estimaters=50, n_estimators=100, n_jobs=1,\n             nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n             subsample=1, verbosity=1)\n\nXgb2.fit(train_X,train_y)\n\n\ntrain_pred6=Xgb2.predict(train_X)\nvalid_pred6=Xgb2.predict(valid_X)","a967e8ef":"print(\"mean_absolute_error on train data:\",mean_absolute_error(train_y,train_pred6))\nprint(\"mean_absolute_error on validation data:\",mean_absolute_error(valid_y,valid_pred6))","234f2125":"#prediction on test data with Xgboost best estimator\ntest_predictions=Xgb2.predict(test)\ntest_prediction=pd.DataFrame(test_predictions)","02266854":"test_prediction","cf55c90d":"**problem statement :**\n\nThe predicting of fare amount (inclusive of tolls) for a taxi ride, given the pickup and dropoff locations,the pickup date time and many other attributes given below.\n\n**Target :**\n\nfare_amount\n\n**description of variables**\n\nTID:-Unique ID\n\nVendor_ID:-Technology service vendor associated with cab company\n\nNew_User:-If a new user is taking the ride\n\ntoll_price:-toll tax amount\n\ntip_amount:-tip given to driver (if any)\n\ntax:-applicable tax\n\npickup_timestamp:-time at which the ride started\n\ndropoff_timestamp:-time at which ride ended\n\npassenger_count:-number of passenger during the ride\n\npickup_longitude:-pickup location longitude data\n\npickup_latitude:-pickup location latitude data\n\nrate_category:-category assigned to different rates at which a customer is charged\n\nstore_and_fwd:-if driver stored the data offline and later forwarded\n\ndropoff_longitude:-drop off longitude data\n\ndropoff_latitude:-drop off latitude data\n\npayment_type:-payment mode used by the customer (CRD = Credit Card, CSH - Cash, DIS - dispute, NOC - No Charge, UNK - Unknown)\n\nsurcharge:-surchage applicable on the trip\n\nfare_amount:-trip fare (to be predicted)"}}