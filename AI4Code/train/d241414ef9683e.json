{"cell_type":{"b16700bd":"code","8398f6e3":"code","a5ca5d0f":"code","2f1764ec":"code","e9f2da46":"code","e35bc717":"code","8ce480d6":"code","f5779366":"code","7f6d21ae":"code","1c7631a2":"code","0c0c2d73":"code","7ca48d64":"code","a045e6b2":"code","e782874e":"code","88978acf":"code","bdaab45c":"code","73edd604":"code","c18b344e":"code","6ccbf7a1":"code","3e11cc01":"code","b439a3b8":"code","8498ade5":"code","3fdad196":"code","ee8d0d3e":"code","7ea36144":"code","e4868b95":"code","8f1cadca":"code","3bc2e7bf":"markdown","373def86":"markdown","8e1e827d":"markdown","6f482cfc":"markdown","e4706b7b":"markdown","f73cb425":"markdown","5702be71":"markdown","d3e695ee":"markdown","727e86f0":"markdown","663f4604":"markdown","bd59736e":"markdown","d6447a36":"markdown","9a36ebae":"markdown","55d5a659":"markdown","25a6b63a":"markdown","1ed31529":"markdown","abb0fea0":"markdown","1a9b12ab":"markdown","c819cb71":"markdown","af7473b7":"markdown","b6d8baf2":"markdown","0927fbbe":"markdown","6e25375e":"markdown","d8781fd5":"markdown","8ceb1aed":"markdown","d36ace81":"markdown","67f02063":"markdown","f4d43145":"markdown","8f787082":"markdown"},"source":{"b16700bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8398f6e3":"import matplotlib.pyplot as plt","a5ca5d0f":"hotel= pd.read_csv(\"\/kaggle\/input\/hotel-reviews\/7282_1.csv\")\nhotel.head()","2f1764ec":"hotel = hotel.loc[hotel['categories']=='Hotels']\n# Drop rows with empty review rating\nhotel = hotel[hotel['reviews.rating'].notna()] ","e9f2da46":"#Review text related to the 0.0 score\nhotel.loc[hotel['reviews.rating']==0.0].iloc[0,14]","e35bc717":"#I get rid of the 0.0 score since the reviews in this scores are only promts to write reviews.\nhotel = hotel.loc[hotel['reviews.rating']!=0.0]\nhotel = hotel.reset_index(drop = True)\nhotel.sort_values(by = 'reviews.rating')","8ce480d6":"hotel_s = hotel[['name','reviews.rating','reviews.text']]\nhotel_s[\"reviews.text\"] = hotel_s[\"reviews.text\"].apply(str)\n#Review rating range from (1.0 - 10.0) \nhotel_s['reviews.rating'].unique()\n\n\n#Create the label\n#If a review rating is lower than 5, it is considered as a negative review; vice versa\nhotel_s['is_bad_review'] = hotel_s['reviews.rating'].apply(lambda x:1 if x<5 else 0)\nhotel_s","f5779366":"# return the wordnet object value corresponding to the POS tag\nfrom nltk.corpus import wordnet\n    \nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\n\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","7f6d21ae":"def clean_text(text):\n    # lower text\n    text = text.lower()\n    # tokenize text and remove puncutation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # remove stop words\n    stop = stopwords.words('english')\n    text = [x for x in text if x not in stop]\n    #remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    #pos tag text\n    pos_tags = pos_tag(text)\n    # lemmatize text\n    \n    # the 'post_tag'function will return turples with the first word t[0] is the orginal word, and the second t[1] is the speech tag\n    # for example, ('fly', 'NN')\n    \n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)\n\n# clean text data\n\nhotel_s[\"review_clean\"] = hotel_s[\"reviews.text\"].apply(lambda x: clean_text(x))\nhotel_s.dtypes\nhotel_s","1c7631a2":"# Add sediment analysis columns (neg,neu,pos,compond)\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n#something in the reviews.text \n\nsid = SentimentIntensityAnalyzer()\nhotel_s[\"sentiments\"] = hotel_s[\"review_clean\"].apply(lambda x: sid.polarity_scores(x))\n#It turns out the hotel_s[\"sentiments\"] values are dictionaries. Thus, I will need to transform it into 4 seperated column using pd.concat \n#(I have no idea how this function work)\nhotel_s = pd.concat([hotel_s.drop(['sentiments'], axis=1), hotel_s['sentiments'].apply(pd.Series)], axis=1)\n\nhotel_s","0c0c2d73":"# Number of words in a review\nhotel_s['num_words'] = hotel_s['reviews.text'].apply(lambda x: len(x.split()))\n\n# Number of characters in a review\nhotel_s['num_chars'] = hotel_s['reviews.text'].apply(lambda x: len(x))\n","7ca48d64":"#create doc2vec vector columns\n\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\n# I think the tag here is for the whole review sentence.\ndocuments =[TaggedDocument(doc,[i]) for i,doc in enumerate(hotel_s['reviews.text'].apply(lambda x: x.split()))]\n\n# train a Doc2Vec model with our text data\nmodel = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n\n# transform each document into a vector data\ndoc2vec_df = hotel_s[\"review_clean\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n#Rename doc2vec dataframe columns\ndoc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\nhotel_s = pd.concat([hotel_s, doc2vec_df], axis=1)\nhotel_s","a045e6b2":"# add tf-idfs columns\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Ignore terms that have a document frequency strictly lower than 10\ntfidf = TfidfVectorizer(min_df = 10)\n# Learn vocabulary and idf, return term-document matrix (What is this)\ntfidf_result = tfidf.fit_transform(hotel_s[\"review_clean\"]).toarray()\n# Named columns the names of the words\ntfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\ntfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\ntfidf_df.index = hotel_s.index\n# Merge the hotel_s dataframe and tfidf dataframe\nhotel_s = pd.concat([hotel_s, tfidf_df], axis=1)\nhotel_s","e782874e":"pd.options.display.max_colwidth = 9999\n\n# Compound score ranks from high-low, top 3 positive reviews\n\nhotel_s[['reviews.text','review_clean','compound','is_bad_review']].sort_values('compound',ascending = False).head(3)","88978acf":"# Compound score ranks from low-high, top 3 negative reviews\n\nhotel_s[['reviews.text','review_clean','compound','is_bad_review']].sort_values('compound',ascending = True).head(3)","bdaab45c":"#Set the stype\nplt.style.use('seaborn')","73edd604":"# Hotels with highest compound scores\n\npos_review = hotel_s[hotel_s['compound']>=0.05]\ntop_pos_com = pos_review[['name','compound']].groupby(['name']).mean().sort_values('compound',ascending = True).tail(10).reset_index() \n# top_pos_com\n\nplt.figure(figsize = (10,5))\nplt.barh(top_pos_com['name'],top_pos_com['compound'])\nplt.title('Top 10 Hotels with the Best Reviews',fontSize = 18)\nplt.ylabel('Hotel Name',fontSize = 14)\nplt.xlabel('Mean Compound Sentiment Score',fontSize = 14)\nplt.figure(figsize = (10,2))","c18b344e":"# Hotels with lowest compound scores\n\nneg_review = hotel_s[hotel_s['compound']<= -0.05]\ntop_neg_com = neg_review[['name','compound']].groupby(['name']).mean().sort_values('compound',ascending = False).tail(10).reset_index() \n\nplt.figure(figsize = (10,5))\nplt.barh(top_neg_com['name'],top_neg_com['compound'])\nplt.title('Top 10 Hotels with the Worst Reviews',fontSize = 18)\nplt.ylabel('Hotel Name',fontSize = 14)\nplt.xlabel('Mean Compound Sentiment Score(negative numbers)',fontSize = 14)\nplt.figure(figsize = (10,2))","6ccbf7a1":"from wordcloud import WordCloud\n\ndef show_wordCloud(text,title):\n    wordcloud = WordCloud(\n                    background_color ='white', \n                    max_words = 200,\n                    min_font_size = 10,\n                    min_word_length = 3).generate(str(text))\n\n    plt.figure(figsize = (10,10)) \n    plt.title(title,fontsize =30, pad = 30)\n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n\n    plt.show()\n\n\n# Wordcloud in positive reviews\n\nshow_wordCloud(pos_review['review_clean'],'WordCloud in Positive Reviews')","3e11cc01":"# Wordcloud in Negative reviews\n\nshow_wordCloud(neg_review['review_clean'],'WordCloud in Negative Reviews')","b439a3b8":"hotel_s[['compound']].hist(figsize = (10,8))\nplt.xlabel('Compound Sentimemt Score')\nplt.ylabel('Number of Reviews')\nplt.title(\"Reviews' Compound Sentiment Score Distribution\",fontsize =20)","8498ade5":"label = 'is_bad_review'\nignore_columns = [label,'name','reviews.rating','reviews.text','review_clean']\nfeatures = [c for c in hotel_s.columns if c not in ignore_columns]\n\n#Split the data into train and test\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n# 80% train and 20% test\nx_train, x_test, y_train, y_test = train_test_split(hotel_s[features], hotel_s[label], test_size = 0.20, random_state = 42) \n\n# Train model M1\nrf = RandomForestClassifier(n_estimators = 100, random_state = 42)\nrf.fit(x_train, y_train)\n","3fdad196":"feature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending = False)\nfeature_importances_df = feature_importances_df.head(100)\n\nimp_feature = [f for f in feature_importances_df['feature']]\n\nfeature_importances_df","ee8d0d3e":"label = 'is_bad_review'\n\n# Split train data and test data\n# 80% train and 20% test\nx2_train, x2_test, y2_train, y2_test = train_test_split(hotel_s[imp_feature], hotel_s[label], test_size = 0.20, random_state = 42) \n\n# Train model M2\nrf2 = RandomForestClassifier(n_estimators = 100, random_state = 42)\nrf2.fit(x2_train, y2_train)\n","7ea36144":"# Use the M1 to Predict x_test\ny_pred= rf.predict(x_test)\n\n#Import scikit-learn metrics module for accuracy calculation\n\nfrom sklearn import metrics\n\n# Model Accuracy, how often is the classifier correct?\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","e4868b95":"y2_pred= rf2.predict(x2_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y2_test, y2_pred))","8f1cadca":"from sklearn.metrics import roc_curve, auc, roc_auc_score\n\n# print(rf.predict_proba(x_test))\n\n# x[0] means the probability that the testing sample is not classified as the first class \n# x[1] means the probability that the testing sample is classified as the first class\n\ny_pred = [x[1] for x in rf.predict_proba(x_test)]\ny2_pred = [a[1] for a in rf2.predict_proba(x2_test)]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = 1)\nfpr2, tpr2, thresholds2 = roc_curve(y2_test, y2_pred, pos_label = 1)\n\n# print(thresholds)\n\nroc_auc = auc(fpr, tpr)\nroc_auc2 = auc(fpr2,tpr2)\n\nplt.figure(1, figsize = (15, 10))\nlw = 2\n\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve M1 (area = %0.2f)' % roc_auc) #0.2f means only print 2 digit of the float \nplt.plot(fpr2, tpr2, color='green',\n         lw=lw, label='ROC curve M2 (area = %0.2f)' % roc_auc2)\nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","3bc2e7bf":"After understanding which features are more important, I select the top 100 important features to feed into another model M2, and see if this move could increase the accuracy.","373def86":"Train model M2","8e1e827d":"## TF-IDF(Term Frequency - Inverse Document Frequency)\n\nAdd the TF-IDF(Term Frequency - Inverse Document Frequency) values. \n* TF computes the classic number of times the word appears in the text\n* IDF computes the relative importance of this word which depends on how many texts the word can be found","6f482cfc":"## Calculate Sentiment Scores\n\nIn this step I will add sentiment analysis features to the dataframe. I will use Vader, a part of the NLTK module to calculate sentiment scores for each review. Vader returns 4 values:\n\n* a neutrality score\n* a positivity score\n* a negativity score\n* an compound score that summarizes the previous scores\n<br>\n<br>\npositive sentiment(compound score >=0.05)\n<br>\nneutral sentiment(compound score<-0.05 and <0.05)\n<br>\nnegative sentiment(compound score <= -0.05)\n","e4706b7b":"## Number of Words and Characters\n\nAdd additional features to the dataframe:\n* number of characters in the review texts\n* number of words in the review texts\n","f73cb425":"The ROC curve matches the accuracy metric that that M1\u2019s performance is slightly better than M2. However, as I mentioned above,  this data contains about 65% of positive reviews. This may lead to a low false-positive rate, which jeopardizes the accuracy of the AUC result.","5702be71":"# Pre-process Data and Label Reviews","d3e695ee":"It turns out over 8000 out of 21328 reviews are considered 'extremely positive', and over 14000 out of 21328 (65%) reviews are 'positive'. The imbalanced distribution of the dataset might reduce its liability. Let's see how the model doing.","727e86f0":"## Receiver Operating Characteristic (ROC) Curve\n\nReceiver Operating Characteristic (ROC) metric is used to evaluate classifier output quality. Usually a larger area under the curve (AUC) means the classifier performs better.","663f4604":"# Sentiment Analysis Model Training and Evaluation","bd59736e":"## Compound Sentiment Score Distribution\n\nBefore start training the model, it is important to know if the reviews in the dataset is balance - that is, the distribution of the sentiment score. I guess that if the positive reviews are much more than negative reviews, it will affect the accuracy of the prediction.","d6447a36":"# Clean Review Data","9a36ebae":"# Reflection\n\nIt is quite a challenge to conduct sentiment analysis with raw data. The shortage of this dataset is threefold. First, it is a sample of a larger hotel review dataset. It is fragmented and the hotel list is incomplete. Second, the dataset is imbalanced, most of the reviews are positive. Third, some of the reviews are written in foreign languages. These issues impact on review cleaning. sentiment score calculation, data vectorization, which ultimately affect the liability of the model accuracy result.\n\nNonetheless, I appreciate this chance to familiarize myself with machine learning techniques and sentiment analysis. I am so glad that I\u2019ve learned a lot of new concepts such as Bag of Words and Text Vectorization, even though I believe I only touched the surface this time.\n\nAs I mentioned, I used a reference to guide me through this project. One thing I couldn\u2019t understand is why we need to include so many features to train a model. Isn\u2019t the sentiment score enough to determine whether the review \u201cis_bad_review\u201d or not? What\u2019s the purpose of adding the number of words, and TF-IDF (Term Frequency - Inverse Document Frequency) into consideration? Another question is how to use this model to predict a new dataset. The TF-IDF feature looks like a problem. If I want to use this model to predict another dataset,  how could I deal with the difference of the TF-IDF columns (since I think the TF-IDF are unique to each dataset). \n","55d5a659":"## Model Training using Random Forest Classifier\n\nTo train and optimize the sentiment model I will use following steps:\n* split the dataset into two parts: One to train the model; One to evaluate the model performance\n* Feed the first part of the dataset into Random forest (RF) classifier to train the model (M1)\n* Generate feature importance\n* Select critical features and then do the training again (M2)\n* Get the accuracy score of M1 and M2","25a6b63a":"# Feature Engineering","1ed31529":"* Positive Review: overall rating >= 5.0 \/ is_bad_review = 0\n* Negative Review: overall rating < 5.0 \/ is_bad_review = 1","abb0fea0":"# Conclusion\n\nTo sum up, Park Terrace Suites is the hotel that has the best reviews, while Hotel Eugene En Ville has the worst.  High-frequency words in positive reviews are friendly, staff, location, breakfast, water\uff0ccomfortable, etc. These words indicate that the good experience of hotel stays may be related to friendly staff, comfortable and clean rooms, delicious breakfast, water views, and\/or convenient locations. The word cloud failed to compute meaningful words in negative reviews due to the constrains of the dataset. In the end, I trained the model with 80% of the dataset and assess the model using the rest. The accuracy of the model is about 74.8% with 81% AUC (area under curve). (**(NOTE:THE ACCURACY SLIGHTLY CHANGES EVERYTIME)**\n","1a9b12ab":"# Evaluation\n\n## Model Accuracy\n\nThe accuracy of M1 is 75.0% and the accuracy of M2 is 74.4% **(NOTE:THE ACCURACY SLIGHTLY CHANGES EVERYTIME)**. Although decreasing features speeds up the training process, it lowers a littble bit of the accuracy. \n","c819cb71":"## Positive\/Negative Review Samples\n\nBefore conducting the analysis, I would like to get a sense of what kind of reviews are associated with high or low compound scores. The positive reviews look normal, and the \"is_bad_review\" labels correctly. However, the negative reviews are written in foreign languages, I assume this will affect the accuracy of the following analysis. This is a problem of working with raw data. ","af7473b7":"\nWordCloud in the negative reviews does NOT make much sense. I believe the reason is that part of the reviews are written in foreign languages. The frequent word \u2018wir\u2019 means \"we\" in German, which is supposed to be deleted during the stopword cleaning process. This reveals the limitation in both cleaning process and sentiment score computation - they might only apply to English reviews.\n","b6d8baf2":"Show feature importance","0927fbbe":"# Overview\n\nFor this project, I will conduct a sentiment analysis for a hotel review dataset sample from Datafiniti (https:\/\/www.kaggle.com\/datafiniti\/hotel-reviews). With this dataset I will do the following researches:\n* Explore which hotel has the highest frequency of positive\/negative reviews\n* Use the word crowd function to find out what kind of words appear in our positive\/negative reviews\n* Use 80% of dataset to train a classifier and use 20% to assess the classifier, and then visualize the evaluation\n\n# Method\n\nI will use supervised learning - classification to implement the analysis. The model I will use is Random Forest Classifier.\n\nLibraries:\n* NLTK: a python module for NLP analysis\n* Gensim: a topic-modelling and vector space modelling toolkit\n* Scikit-learn: machine learning library\n\n# Reference\n\nTo conduct the analysis, I will follow the example from Jonathan Oheix's Kaggle notebook: \n<br>\nSentiment analysis with hotel reviews (https:\/\/www.kaggle.com\/jonathanoheix\/sentiment-analysis-with-hotel-reviews )\n\n","6e25375e":"## Word Cloud in Positive\/Negative Reviews","d8781fd5":"## Vectorize Data\n\nI used Doc2Vec to Doc2vec from the Gensim module to generate vectors for sentence\/paragraphs\/documents, which vectorizes documents based on the estimated similarity of relations between words. Similar words will have similar representation vectors. \n\n<br>\n(I don't think I 100% understand these concepts)","8ceb1aed":"The main purpose of this step is to label the reviews as positive or negative. The column \"is_bad_review\" displays the result with 0(positive) and 1(negative). This is part of supervised learning and the labels could be considered as 'baselines'.\n\n* Positive Review: overall rating >= 5.0 \/ is_bad_review = 0\n* Negative Review: overall rating < 5.0 \/ is_bad_review = 1","d36ace81":"# Explore Data","67f02063":"\n## Hotels with the best\/worst reviews\n\n**Sentiment Metric**\n<br>\npositive sentiment(compound score >=0.05)\n<br>\nneutral sentiment(compound score<-0.05 and <0.05)\n<br>\nnegative sentiment(compound score <= -0.05)\n\nIn order to rank the hotels with the most postive\/negative reviews, I will do following steps:\n\n* get 2 new dataframes with all the postive\/negative reviews based on the Sentiment Metric\n* Group positive\/negative dataframes with hotel names, and get the mean value of the compound score\n* Sort values based on the mean compound score of each hotel and visualize ranking","f4d43145":"Texts are cleaned with these steps (I copy this from the tutorial):\n* lower the text\n* tokenize the text (split the text into words) and remove the punctuation\n* remove useless words that contain numbers\n* remove useless stop words like 'the', 'a' ,'this' etc.\n* Part-Of-Speech (POS) tagging: assign a tag to every word to define if it corresponds to a noun, a verb etc. using the WordNet lexical database\n* lemmatize the text: transform every word into their root form (e.g. rooms -> room, slept -> sleep)\n\nOne problem of the stopword cleaning is that it removes words like \"not\"\"won't\", which completely changes the meaning of the sentence. However, it looks like the NLTK - stopword module is popularly used in stopword cleaning. I am not sure whether it matters or not.","8f787082":"The wordcloud analysis indicates positive reviews possibly contain these terms: friendly,staff, location, breakfast, water\uff0ccomfortable, etc. Based on these words,  good experience of hotel stays may be related to friendly staff, comfortable and clean rooms, delicious breakfast, water views, and\/or convenient locations."}}