{"cell_type":{"803878bc":"code","8d87f99e":"code","ac0940c1":"code","cdf7536b":"code","d51434ee":"code","bf7bd974":"code","8bd9a0ac":"code","b4978a4f":"code","8f4cc416":"code","0e7a527c":"code","a8afe730":"code","c3dfa3d3":"code","8540dfc1":"code","076348c8":"code","8c6fba16":"code","55e53e81":"code","0164bff6":"code","fc6010e4":"code","a3afaeac":"code","91e02033":"code","7a77f5ef":"code","965432ea":"code","ebb7a7a0":"code","c184e7ae":"code","87fc46cd":"code","de5c5367":"code","bc434da7":"code","fcde2e7c":"code","24b61fe5":"code","35f41128":"code","99d87277":"code","011fed62":"code","7232b32a":"code","288ce45a":"code","3d9a371c":"code","e32d7f4e":"code","69d12a4b":"code","385f2be1":"code","b66f1213":"code","0a4bc17d":"code","0585c784":"code","64c43223":"code","c066207e":"code","d4b4704e":"code","17cff2bc":"code","1651932f":"code","94a5c7ed":"markdown","6278e014":"markdown","9080c46f":"markdown"},"source":{"803878bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g.L pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8d87f99e":"# importing libraries\n\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ac0940c1":"# Reading the data\n\n# Reading metadata\n# specify column dtypes to save memory (by default pandas reads some columns as floats)\ndtypes = {\n    \"site_id\": np.int8,\n    \"building_id\": np.int8,\n    \"primary_use\": np.object,\n    \"square_feet\": np.int8,\n    \"year_built\": np.float16,\n    \"floor_count\": np.float16,\n}\n\n# meta data information for metadata dataframe\nskiprows = None\nnrows = None\ncolumns = ['site_id', 'building_id', 'primary_use', 'square_feet', 'year_built', 'floor_count']\npath = \"\/kaggle\/input\/ashrae-energy-prediction\/building_metadata.csv\"\n\nmetadata_df = pd.read_csv(path, skiprows=skiprows, nrows=nrows, dtype=dtypes, usecols=columns)","cdf7536b":"# Reading training data\n\n# specify column dtypes to save memory (by default pandas reads some columns as floats)\ndtypes = {\n    \"building_id\": np.int8,\n    \"meter\": np.int8,\n    \"timestamp\": np.object,\n    \"meter_reading\": np.float16\n}\n\n# meta data information for metadata dataframe\nskiprows = None\nnrows = None\ncolumns = ['building_id', 'meter', 'timestamp', 'meter_reading']\npath = \"\/kaggle\/input\/ashrae-energy-prediction\/train.csv\"\n\n# using chunck size to avoid memory related issues\ntrain_df = pd.read_csv(path, skiprows=skiprows, nrows=nrows, dtype=dtypes, usecols=columns)","d51434ee":"# Reading testing data\n\n# specify column dtypes to save memory (by default pandas reads some columns as floats)\ndtypes = {\n    \"row_id\": np.int8,\n    \"building_id\": np.int8,\n    \"meter\": np.int8,\n    \"timestamp\": np.object\n}\n\n# meta data information for metadata dataframe\nskiprows = None\nnrows = None\ncolumns = ['row_id', 'building_id', 'meter', 'timestamp']\npath = \"\/kaggle\/input\/ashrae-energy-prediction\/test.csv\"\n\n# using chunck size to avoid memory related issues\ntest_df = pd.read_csv(path, skiprows=skiprows, nrows=nrows, dtype=dtypes, usecols=columns)","bf7bd974":"# Reading weather training data\n\n# specify column dtypes to save memory (by default pandas reads some columns as floats)\ndtypes = {\n    \"site_id\": np.int8,\n    \"timestamp\": np.object,\n    \"air_temperature\": np.float16,\n    \"cloud_coverage\": np.float16,\n    \"dew_temperature\": np.float16,\n    \"precip_depth_1_hr\": np.float16,\n    \"sea_level_pressure\": np.float16,\n    \"wind_direction\": np.float16,\n    \"wind_speed\": np.float16\n}\n\n# meta data information for metadata dataframe\nskiprows = None\nnrows = None\ncolumns = ['site_id', 'timestamp', 'air_temperature', 'cloud_coverage',\n       'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n       'wind_direction', 'wind_speed']\npath = \"\/kaggle\/input\/ashrae-energy-prediction\/weather_train.csv\"\n\nweather_train_df = pd.read_csv(path, skiprows=skiprows, nrows=nrows, dtype=dtypes, usecols=columns)","8bd9a0ac":"# Reading weather testing data\n\n# specify column dtypes to save memory (by default pandas reads some columns as floats)\ndtypes = {\n    \"site_id\": np.int8,\n    \"timestamp\": np.object,\n    \"air_temperature\": np.float16,\n    \"cloud_coverage\": np.float16,\n    \"dew_temperature\": np.float16,\n    \"precip_depth_1_hr\": np.float16,\n    \"sea_level_pressure\": np.float16,\n    \"wind_direction\": np.float16,\n    \"wind_speed\": np.float16\n}\n\n# meta data information for metadata dataframe\nskiprows = None\nnrows = None\ncolumns = ['site_id', 'timestamp', 'air_temperature', 'cloud_coverage',\n       'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n       'wind_direction', 'wind_speed']\npath = \"\/kaggle\/input\/ashrae-energy-prediction\/weather_test.csv\"\n\nweather_test_df = pd.read_csv(path, skiprows=skiprows, nrows=nrows, dtype=dtypes, usecols=columns)","b4978a4f":"# describing about the data\n\nmetadata_df.head()","8f4cc416":"metadata_df.describe()","0e7a527c":"metadata_df.info()","a8afe730":"weather_test_df.head()","c3dfa3d3":"weather_train_df.describe()","8540dfc1":"weather_train_df.info()","076348c8":"weather_test_df.head()","8c6fba16":"weather_test_df.describe()","55e53e81":"weather_test_df.info()","0164bff6":"train_df.head()","fc6010e4":"train_df.describe()","a3afaeac":"train_df.info()","91e02033":"test_df.head()","7a77f5ef":"test_df.describe()","965432ea":"test_df.info()","ebb7a7a0":"# checking the null values on metadata dataset\n\nmetadata_df.isnull().sum(axis=0)","c184e7ae":"weather_train_df.isnull().sum(axis=0)","87fc46cd":"weather_test_df.isnull().sum(axis=0)","de5c5367":"train_df.isnull().sum(axis=0)","bc434da7":"test_df.isnull().sum(axis=0)","fcde2e7c":"# percentage of missing values in weather training dataset\n\nround((weather_train_df.isnull().sum() * 100 \/ len(weather_train_df)), 2)","24b61fe5":"# percentage of missing values in weather testing dataset\n\nround((weather_test_df.isnull().sum() * 100 \/ len(weather_test_df)), 2)","35f41128":"# Finding no.f unique values in weather training dataset\n\nprint(\"Finding no.f unique values in weather training dataset: {}\".format(len(pd.unique(weather_train_df['site_id']))))","99d87277":"# Finding no.f unique values in weather testing dataset\n\nprint(\"Finding no.f unique values in weather testing dataset: {}\".format(len(pd.unique(weather_test_df['site_id']))))","011fed62":"# Finding no.f unique values in training dataset \n\nprint(\"Finding no.f unique values in training dataset: {}\".format(len(pd.unique(train_df[\"building_id\"]))))","7232b32a":"# Finding no.f unique values in testing dataset\n\nprint(\"Finding no.f unique values in testing dataset: {}\".format(len(pd.unique(test_df[\"building_id\"]))))","288ce45a":"# No.f records in weather training dataset\n\nprint(\"No.f records in weather training dataset: {}\".format(len(weather_train_df)))","3d9a371c":"# No.f records in weather testing dataset\n\nprint(\"No.f records in weather testing dataset: {}\".format(len(weather_test_df)))","e32d7f4e":"# No.f records in trainging dataset\n\nprint(\"No.f records in training dataset: {}\".format(len(train_df)))","69d12a4b":"# No.f records in testing dataset\n\nprint(\"No.f records in testing dataset: {}\".format(len(test_df)))","385f2be1":"weather_train_df['timestamp'] = pd.to_datetime(weather_train_df['timestamp'])","b66f1213":"weather_test_df['timestamp'] = pd.to_datetime(weather_test_df['timestamp'])","0a4bc17d":"weather_train_df.head()","0585c784":"weather_test_df.head()","64c43223":"train_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"])","c066207e":"test_df[\"timestamp\"] = pd.to_datetime(test_df[\"timestamp\"])","d4b4704e":"train_df.head()","17cff2bc":"test_df.head()","1651932f":"# removing unnecessary data\n\nimport gc\ngc.collect()","94a5c7ed":"#### Converting data types in the given dataset","6278e014":"#### Reading the data and performing some basic statistics on given data frame using the methods like pandas describe() and info().\n\n#### To avoid memory issues or reducing the memory we'll supress the datatypes into 32-bit or 16-bit.","9080c46f":"### Basic EDA \n#### Performing some basic EDA which includes techniques like cleaning, feature engineering, transforming and standardising the data.\n#### Performing univariate analysis and bivariate analysis."}}