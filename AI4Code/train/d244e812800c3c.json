{"cell_type":{"9f89d826":"code","d2858206":"code","6e8f82e7":"code","090d3b91":"code","ec6f453b":"code","c9ba3664":"code","7ca6ec6f":"code","e6534b61":"code","b56abcb2":"code","978d7916":"code","5fe1b13b":"code","24776d56":"code","9358cefa":"code","9933dcb2":"code","cfcc219f":"code","63ff733c":"code","0138090f":"code","cd039c30":"markdown","03d54760":"markdown","d47368ac":"markdown","092f7ea4":"markdown","ac698d96":"markdown","2c08c073":"markdown","79e9bc35":"markdown","e2bdd39f":"markdown","27b1de10":"markdown"},"source":{"9f89d826":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom jcopml.pipeline import num_pipe, cat_pipe\nfrom jcopml.utils import save_model, load_model\nfrom jcopml.plot import plot_missing_value\nfrom jcopml.feature_importance import mean_score_decrease\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2858206":"pd.options.display.max_columns = 100\ndf = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")\ndf.drop(columns=\"Unnamed: 32\", inplace=True)\ndf.head()","6e8f82e7":"plot_missing_value(df, return_df=True)","090d3b91":"df.shape","ec6f453b":"import matplotlib.pyplot as plt\nimport seaborn as sns","c9ba3664":"sns.countplot(x=df[\"diagnosis\"])","7ca6ec6f":"plt.figure(figsize=(20, 10))\nax = sns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.1f')","e6534b61":"df.describe()","b56abcb2":"X = df.drop(columns=[\"diagnosis\", \"id\"])\ny = df[\"diagnosis\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","978d7916":"from sklearn.decomposition import PCA","5fe1b13b":"pca = PCA().fit(X_train)\n\nplt.figure(figsize=(14,5))\nplt.plot(pca.explained_variance_ratio_.cumsum())\nplt.xlabel(\"n_components\")\nplt.ylabel(\"Comulative explained variance\")","24776d56":"from sklearn.svm import SVC\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom jcopml.tuning import random_search_params as rsp\nfrom jcopml.tuning.space import Integer, Real","9358cefa":"preprocessor = ColumnTransformer([\n    ('numeric', num_pipe(impute='median', poly=2), X_train.columns)\n])\n\npipeline = Pipeline([\n    ('prep', preprocessor),\n    ('pca', PCA(whiten=True)),\n    ('algo', SVC(max_iter=500))\n])","9933dcb2":"parameter = {\n    'prep__numeric__poly__degree': [2],\n    'pca__n_components' : [10],\n    'algo__gamma': Real(low=-3, high=3, prior='log-uniform'),\n    'algo__C': Real(low=-3, high=3, prior='log-uniform')\n}\n\n\nmodel = RandomizedSearchCV(pipeline, parameter, cv=3,  n_iter=100, n_jobs=-1, verbose=1, random_state=42)\nmodel.fit(X_train, y_train)\n\nprint(model.best_params_)\nprint(model.score(X_train, y_train), model.best_score_, model.score(X_test, y_test))\nprint(\"\\nTrain Akurasi:\", model.score(X_train, y_train))\nprint(\"Test Akurasi:\", model.score(X_test, y_test))","cfcc219f":"from jcopml.plot import plot_classification_report, plot_confusion_matrix, plot_roc_curve, plot_pr_curve","63ff733c":"plot_confusion_matrix(X_train, y_train, X_test, y_test, model)","0138090f":"plot_classification_report(X_train, y_train, X_test, y_test, model, report=True)","cd039c30":"## Check missing value","03d54760":"### Numerical Columns","d47368ac":"# Import Datasets","092f7ea4":"# Evaluation","ac698d96":"# PCA to reduce columns\n## Datasets Splitting","2c08c073":"We can reduce from 30 to 10 columns\n# Modelling with SVM Classifier","79e9bc35":"# Visualize the data","e2bdd39f":"### Correlation plot","27b1de10":"### Target Columns"}}