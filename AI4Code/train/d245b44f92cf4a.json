{"cell_type":{"666ed76f":"code","c1458d9a":"code","3eea77cd":"code","08b242ae":"code","8cf3084d":"code","30f656ee":"code","e07190a7":"code","c4ec1b28":"code","a874ff98":"code","96174c98":"code","7e7c7534":"code","df876a32":"code","5d60ac9e":"code","7772dbe9":"code","805d19bf":"code","65c3dbd2":"code","d5480405":"code","0f77a105":"code","ee32a3d2":"code","3014b141":"code","99eb19f4":"code","3b175250":"code","31b3c472":"code","7240db63":"code","277306e8":"code","11f087ba":"code","ac5da503":"code","c1012cee":"markdown","924ab1ac":"markdown","085927a6":"markdown","006ca109":"markdown","6b0a24a5":"markdown","c54460cf":"markdown","27c8c921":"markdown","78505681":"markdown"},"source":{"666ed76f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs # using these ^^ for demonstration of algorithm\n\nimport timeit\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c1458d9a":"links = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/links.csv\")","3eea77cd":"ratings = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/ratings.csv\")","08b242ae":"credits = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/credits.csv\")","8cf3084d":"metadata = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/movies_metadata.csv\")","30f656ee":"keywords = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/keywords.csv\")","e07190a7":"plt.figure(figsize=(12, 12))\n\nn_samples = 1500\nrandom_state = 170\nX, y = make_blobs(n_samples=n_samples, random_state=random_state)\n\n# Incorrect number of clusters\ny_pred = KMeans(n_clusters=2, random_state=random_state).fit_predict(X)\n\nplt.subplot(221)\nplt.scatter(X[:, 0], X[:, 1], c=y_pred)\nplt.title(\"Incorrect Number of Blobs\")\n\n# Anisotropicly distributed data\ntransformation = [[0.60834549, -0.63667341], [-0.40887718, 0.85253229]]\nX_aniso = np.dot(X, transformation)\ny_pred = KMeans(n_clusters=3, random_state=random_state).fit_predict(X_aniso)\n\nplt.subplot(222)\nplt.scatter(X_aniso[:, 0], X_aniso[:, 1], c=y_pred)\nplt.title(\"Anisotropicly Distributed Blobs\")\n\n# Different variance\nX_varied, y_varied = make_blobs(n_samples=n_samples,\n                                cluster_std=[1.0, 2.5, 0.5],\n                                random_state=random_state)\ny_pred = KMeans(n_clusters=3, random_state=random_state).fit_predict(X_varied)\n\nplt.subplot(223)\nplt.scatter(X_varied[:, 0], X_varied[:, 1], c=y_pred)\nplt.title(\"Unequal Variance\")\n\n# Unevenly sized blobs\nX_filtered = np.vstack((X[y == 0][:500], X[y == 1][:100], X[y == 2][:10]))\ny_pred = KMeans(n_clusters=3,\n                random_state=random_state).fit_predict(X_filtered)\n\nplt.subplot(224)\nplt.scatter(X_filtered[:, 0], X_filtered[:, 1], c=y_pred)\nplt.title(\"Unevenly Sized Blobs\")\n\nplt.show()","c4ec1b28":"print(metadata.axes)","a874ff98":"# get a list of columns\ncols = list(metadata)\n# move the column to head of list using index, pop and insert\ncols.insert(0, cols.pop(cols.index('budget')))\ncols.insert(0, cols.pop(cols.index('revenue')))\ncols.insert(0, cols.pop(cols.index('title'))) # see movie title in the front\nmetadata = metadata.loc[:, cols]","96174c98":"metadata.loc[:, 'budget'] = pd.to_numeric(metadata.loc[:, 'budget'], errors='coerce')\nmetadata.loc[:, 'budget'] = metadata.loc[:, 'budget'].replace(0, np.nan)\n\nmetadata.loc[:, 'revenue'] = metadata.loc[:, 'revenue'].replace(0, np.nan)","7e7c7534":"print(metadata.shape)\nmetadata = metadata.dropna(subset=['revenue', 'budget'])\nprint(metadata.shape)","df876a32":"metadata","5d60ac9e":"metadata.plot(x = 'revenue', y = 'budget', kind = 'scatter', title= 'Revenue and Budget')","7772dbe9":"rev = metadata['revenue'].to_numpy()\nbudget = metadata['budget'].to_numpy()","805d19bf":"rev = rev.flatten()\nbudget = budget.flatten()\nrevenue_budget = np.vstack((rev, budget)).T\nrevenue_budget.shape","65c3dbd2":"kmeans = KMeans(n_init=5, max_iter= 100).fit(revenue_budget)","d5480405":"kmeans.cluster_centers_","0f77a105":"kmeans.labels_","ee32a3d2":"plt.scatter(revenue_budget[:,0], revenue_budget[:,1], c=kmeans.labels_, cmap='rainbow')\nplt.xlabel(\"Revenue\")\nplt.ylabel(\"Budget\")\nplt.title(\"Clustering of Revenue and Budget for Movies\")\nfig1 = plt.figure()\nfig1.show()","3014b141":"revenue_col = metadata['revenue']\nprint(revenue_col.shape)\nbudget_col = metadata['budget']\nprint(budget_col.shape)\ntitle_col = metadata['title']\nprint(title_col.shape)","99eb19f4":"type(budget_col)","3b175250":"d = {'title': title_col,'revenue': revenue_col, 'budget': budget_col}\ndf = pd.DataFrame(data=d)\ndf = df.set_index('title') \n# normally indexes by a number, changing it to be title so that the title series can be used to access a row\nprint(df.head())","31b3c472":"import random\n# random.sample([1, 100, 99, 45, 66, 78, 34], 3) -> returns a list randomly chosen from the list","7240db63":"def makePoints(X, Y):\n    # corresponding x1 and y1 vals make one point\n    a = []\n    for x, y in np.nditer([X, Y]):\n        a.append(np.array([x,y]))\n    return a","277306e8":"class KMeans:\n\"\"\"\n    Members\n    -------\n    n_init: \n    *   Number of time the k-means algorithm will be run with different centroid seeds. \n    *   The final results will be the best output of n_init consecutive runs in terms of inertia.\n    \n    Methods\n    -------\n    \n\"\"\"\n    def __init__(self, kClusters = 8, maxIter = 300, nInit = 10):\n        \n        self.clusterLabels = None # ndarray of shape (n_samples,): array 1 - kClusters\n        self.centroidLocations = None #  ndarray of shape (n_clusters, n_features) \n        self.kClusters = kClusters\n        self.maxIter = maxIter\n        self.nInit = nInit\n        \n    # data: the dataset to operate on, \n    def computeKMeansCluster(self, data= None):\n        k = self.kClusters\n        labels = np.zeros(shape=data.shape[0]) \n        if (data):\n            centroidLocations = np.zeros(shape=data.shape)\n        # find min and max of set to find range of vals\n        minim = np.floor(data.min()).astype(int)\n        maxim = np.ceil(data.max()).astype(int)\n        # random init of k centroids from the domain and range of values\n        X = random.sample(range(minim['revenue'], maxim['revenue']), k)\n        Y = random.sample(range(minim['budget'], maxim['budget']), k)\n        # centroid assignment step\n        distance = []\n\n        for row in data.itertuples():\n            a = np.array([row[1], row[2]]) # revenue, budget\n            B = makePoints(X, Y)\n            for i in range(k):\n                distance.append(np.linalg.norm(a-B[i])) # euclidean distance -https:\/\/stackoverflow.com\/questions\/1401712\/how-can-the-euclidean-distance-be-calculated-with-numpy\n            # find smallest distance amongst clusters\n            minimum = min(distance)        \n            # assign each row to a label\n            \n\n            del distance[:]\n\n        return","11f087ba":"Kmeans(data=df)","ac5da503":"kevin = np.zeros(shape=df.shape)\ndf.shape[0]","c1012cee":"### Initial Findings\nInitial attempts to cluster give narrow vertical clusters that aren't exactly ideal.","924ab1ac":"# My implementation of K Means\n1. Random init of 'k' centroids\n2. **Centroid assignment step**\n    1. assign each data point to its nearest centroid\n    2. create new centroids by taking the mean value of all the samples assigned to each previous centroid\n        * note: the difference between old and new centroids are computed and the algorithm repeats until the difference falls beneath some threshold --> in other words the algo repeats until the **inertia** of the centroids is less than some standard\n","085927a6":"## KMeans on Movie Dataset\nUsing the scikit-learn library functions","006ca109":"*for later use*\n[how to use timeit](https:\/\/pythonhow.com\/measure-execution-time-python-code\/) (timing the efficiency of each algorithm)","6b0a24a5":"The budget feature has some unclean values that makes Pandas assign it as a generic object. We proceed to convert this into a numeric variable and replace all the non-numeric values with NaN.","c54460cf":"# Given example of k-means assumptions in practice\n> This example is meant to illustrate situations where k-means will produce unintuitive and possibly unexpected clusters. In the first three plots, the input data does not conform to some implicit assumption that k-means makes and undesirable clusters are produced as a result. In the last plot, k-means returns intuitive clusters despite unevenly sized blobs.","27c8c921":"## My implementation of KMeans\nWill iteratively develop until I get a result of similar or better quality than the scikit","78505681":"# KMeans Description (SciKit Library)\nThe k-means problem is solved using either Lloyd\u2019s or Elkan\u2019s algorithm.\n\nThe average complexity is given by O(k n T), were n is the number of samples and T is the number of iteration.\n\nThe worst case complexity is given by O(n^(k+2\/p)) with n = n_samples, p = n_features. (D. Arthur and S. Vassilvitskii, \u2018How slow is the k-means method?\u2019 SoCG2006)\n\nIn practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That\u2019s why it can be useful to restart it several times.\n\nIf the algorithm stops before fully converging (because of tol or max_iter), labels_ and cluster_centers_ will not be consistent, i.e. the cluster_centers_ will not be the means of the points in each cluster. Also, the estimator will reassign labels_ after the last iteration to make labels_ consistent with predict on the training set.\n\n[*kmeans documentation*](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.cluster.KMeans.html#examples-using-sklearn-cluster-kmeans)\n"}}