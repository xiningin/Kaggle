{"cell_type":{"88985b66":"code","7906d8d8":"code","fabefe71":"code","aefa5530":"code","eb430972":"code","49f8cbea":"code","91c13f4a":"code","be5a48bf":"code","7abd654f":"code","6c5057ae":"code","d1dca5c9":"code","73902121":"code","2bdd5d2b":"code","c35df520":"code","700f40c6":"code","a19bfa48":"code","a2e6a5e5":"code","97342a38":"markdown","29c8e920":"markdown","39ae5831":"markdown","f8c16de6":"markdown","41717521":"markdown","a2482d66":"markdown","17b855a2":"markdown"},"source":{"88985b66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7906d8d8":"train = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv\")\n","fabefe71":"train.head()","aefa5530":"train.isnull().sum()","eb430972":"train[\"Response\"].value_counts()","49f8cbea":"import seaborn as sns\n\nsns.countplot(train[\"Response\"])","91c13f4a":"one = train.loc[train[\"Response\"] == 1]\nzero = train.loc[train[\"Response\"] == 0]\n\nzero = zero.iloc[0:len(one), :]\n\ndata = pd.concat([one, zero], axis = 0)\n\nimport seaborn as sns\n\nsns.countplot(data[\"Response\"])","be5a48bf":"data.head()","7abd654f":"sns.scatterplot(x = \"Region_Code\", y = \"Annual_Premium\", hue = \"Response\", data = data)","6c5057ae":"sns.distplot(data[\"Age\"])","d1dca5c9":"sns.countplot(data[\"Gender\"])","73902121":"sns.distplot(data.Vintage)","2bdd5d2b":"df = data.copy()\n\ngender = pd.get_dummies(data[\"Gender\"])\nvehicle_age = pd.get_dummies(data[\"Vehicle_Age\"])\nvehicle_damage = pd.get_dummies(data[\"Vehicle_Damage\"])\ndriving_license = pd.get_dummies(data[\"Driving_License\"])\n\ndf = pd.concat([df, gender, vehicle_age, vehicle_damage, driving_license], axis = 1)\n\ndf = df.drop([\"Gender\", \"Vehicle_Age\", \"Vehicle_Damage\", \"Driving_License\"], axis = 1)\ndel df[\"id\"]\n\n\nx = df.iloc[:, 0:6]\nx2 = df.iloc[:, 7:]\nx = pd.concat([x, x2], axis = 1)\nx[\"a\"] = x[\"> 2 Years\"]\nx[\"b\"] = x[\"< 1 Year\"]\nx = x.drop([\"> 2 Years\", \"< 1 Year\"], axis = 1)\ny = df[\"Response\"]\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 34)\n\nx_train.head()","c35df520":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nxgb.fit(x_train, y_train)\nxgb_pred = xgb.predict(x_test)\n\nprint(accuracy_score(y_test, xgb_pred))\nprint(confusion_matrix(y_test, xgb_pred))","700f40c6":"from sklearn.metrics import roc_auc_score \npreds = xgb.predict_proba(x_train)\nclas = xgb.predict(x_train)\nscore = roc_auc_score(y_train, preds[:,1])\nprint(score)","a19bfa48":"from sklearn.metrics import precision_recall_curve, auc, roc_curve, recall_score\nimport matplotlib.pyplot as plt\n\ny_score = xgb.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\n\nprint ('Area under curve (AUC): ', auc(fpr,tpr))\n","a2e6a5e5":"print(\"Thanks! :)\")","97342a38":"The Response variable we want to predict seems to be not well distributed in data. Approximately 88% of the data is 0, so even if we say 0 to the sample without establishing any model, we find a high accuracy rate, but of course this would be a completely wrong choice. I will subtract 0 from the data to reduce the bias. Leaving equal numbers 0 and 1, I will proceed with my transactions.","29c8e920":"Thanks for your attention ! :)","39ae5831":"**EXAMINING VARIABLES**","f8c16de6":"**IMPORT**","41717521":"**MODEL**","a2482d66":"\nHello, in this worksheet I will try to predict whether customers will buy car insurance or not.\n\nYou can be evaluated by giving the work uptove.\n\nYour views are important to me.\n\nThanks :)","17b855a2":"**DATA PREPROCESSING**"}}