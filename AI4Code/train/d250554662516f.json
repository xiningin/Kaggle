{"cell_type":{"8aada500":"code","1e3c2ec3":"code","d37a8f25":"code","197e9d3b":"code","e2865813":"code","e763ffe8":"code","19609bf1":"code","b727b2ac":"code","b11ba92e":"code","15b9ac68":"code","e7dcca18":"code","baa485ea":"code","8b5ad90e":"markdown","89df766d":"markdown","b90a91b5":"markdown","dfca2ef0":"markdown","dc6900dc":"markdown"},"source":{"8aada500":"!pip install imageai","1e3c2ec3":"import numpy as np\nimport os\nimport shutil\nfrom pathlib import Path","d37a8f25":"root_annots_path = '..\/input\/chess-piece-dectection\/annotations\/'\nroot_images_path = '..\/input\/chess-piece-dectection\/images\/'\n\nannots_path = sorted([i for i in Path(root_annots_path).glob('*.xml')])\nimages_path = sorted([i for i in Path(root_images_path).glob('*.png')])\n\nn_imgs = len(images_path)\n\nclasses = np.array([\"black-king\", \"white-king\", \n                    \"black-pawn\", \"white-pawn\",\n                    \"white-knight\", \"black-knight\",\n                    \"black-bishop\", \"white-bishop\",\n                    \"white-rook\", \"black-rook\",\n                    \"black-queen\", \"white-queen\"])","197e9d3b":"with open(annots_path[5], 'r') as f:\n    print(f.read())","e2865813":"os.makedirs('imageai\/data\/train\/images', exist_ok=True)\nos.makedirs('imageai\/data\/train\/annotations', exist_ok=True)\n\nos.makedirs('imageai\/data\/validation\/images', exist_ok=True)\nos.makedirs('imageai\/data\/validation\/annotations', exist_ok=True)\n\nos.makedirs('imageai\/data\/test\/images', exist_ok=True)\nos.makedirs('imageai\/data\/test\/annotations', exist_ok=True)","e763ffe8":"n_imgs = 81\nn_split = n_imgs \/\/ 6\n\n\nfor i, (annot_path, img_path) in enumerate(zip(annots_path, images_path)):    \n    if i > n_imgs:\n        break\n    # train-val-test split\n    if i < n_split:\n        shutil.copy(img_path, 'imageai\/data\/test\/images\/' + img_path.parts[-1])\n        shutil.copy(annot_path, 'imageai\/data\/test\/annotations\/' + annot_path.parts[-1])\n    elif n_split <= i < n_split*2:\n        shutil.copy(img_path, 'imageai\/data\/validation\/images\/' + img_path.parts[-1])\n        shutil.copy(annot_path, 'imageai\/data\/validation\/annotations\/' + annot_path.parts[-1])\n    else:\n        shutil.copy(img_path, 'imageai\/data\/train\/images\/' + img_path.parts[-1])\n        shutil.copy(annot_path, 'imageai\/data\/train\/annotations\/' + annot_path.parts[-1])","19609bf1":"print(len(list(Path('imageai\/data\/train\/annotations\/').glob('*.xml'))))\nprint(len(list(Path('imageai\/data\/validation\/annotations\/').glob('*.xml'))))\nprint(len(list(Path('imageai\/data\/test\/annotations\/').glob('*.xml'))))","b727b2ac":"from imageai.Detection.Custom import DetectionModelTrainer\n\ntrainer = DetectionModelTrainer()\ntrainer.setModelTypeAsYOLOv3()\ntrainer.setDataDirectory(data_directory=\".\/imageai\/data\/\")\ntrainer.setTrainConfig(object_names_array=classes,\n                       batch_size=8,\n                       num_experiments=30,\n                       train_from_pretrained_model=\"..\/input\/gb-pretrainedyolov3h5\/pretrained-yolov3.h5\")\n#                        train_from_pretrained_model=\"imageai\/data\/models\/detection_model-ex-020--loss-0036.609.h5\")\n\ntrainer.trainModel()","b11ba92e":"model_path = sorted(list(Path('.\/imageai\/data\/models\/').iterdir()))[-1]\nmodel_path","15b9ac68":"from imageai.Detection.Custom import DetectionModelTrainer\n\ntrainer = DetectionModelTrainer()\ntrainer.setModelTypeAsYOLOv3()\ntrainer.setDataDirectory(data_directory=\".\/imageai\/data\/\")\nmetrics = trainer.evaluateModel(model_path=model_path,\n                                json_path=\"imageai\/data\/json\/detection_config.json\",\n                                iou_threshold=0.2,\n                                object_threshold=0.3,\n                                nms_threshold=0.5)","e7dcca18":"from imageai.Detection.Custom import CustomObjectDetection\n\ndetector = CustomObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(model_path)\ndetector.setJsonPath(\"imageai\/data\/json\/detection_config.json\")\ndetector.loadModel()\ndetections = detector.detectObjectsFromImage(minimum_percentage_probability=60,\n                                             input_image=\"imageai\/data\/test\/images\/chess16.png\",\n                                             output_image_path=\"detected.jpg\")\nfor detection in detections:\n    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])","baa485ea":"from PIL import Image\nImage.open('detected.jpg')","8b5ad90e":"## Data Preparation","89df766d":"## Training","b90a91b5":"https:\/\/www.kaggle.com\/brendan45774\/chess-piece-dectection","dfca2ef0":"## Testing\n\nhttps:\/\/github.com\/OlafenwaMoses\/ImageAI\/blob\/master\/imageai\/Detection\/Custom\/CUSTOMDETECTION.md\n","dc6900dc":"## Evaluating detection model\n"}}