{"cell_type":{"e76c7f49":"code","ed377a6d":"code","973ebd86":"code","ba7db024":"code","c00a9ce4":"code","e77f4ea0":"code","95e85d8f":"code","84314954":"code","61770163":"code","d3ba28b1":"code","f0f1bb4c":"code","224e004d":"code","3cfd9f68":"code","f27a4833":"code","3627a1cf":"code","31c020c8":"code","425899af":"code","876ef730":"code","461974cf":"markdown","eef54b34":"markdown","757c1b95":"markdown","08ede332":"markdown","36575009":"markdown","5bd2f504":"markdown"},"source":{"e76c7f49":"import json\nimport os\nimport shutil\nfrom tqdm import tqdm\n\ndef MakeFolders(path=None):\n    # Create folders\n    if os.path.exists(path):\n        shutil.rmtree(path)  # delete output folder\n    os.makedirs(path)  # make new output folder\n    return path\n\ndef CreateCategoryIDMap(categoriesData):\n    num = 0\n    category_id_map = {}\n    for category in categoriesData:\n        category_id_map[category['id']] = num\n        num+=1\n    return category_id_map\n\ndef ConvertBoundingBoxFromCOCOToYOLO(image_width, image_height, bounding_box):\n    dw = 1. \/ image_width\n    dh = 1. \/ image_height\n    x = bounding_box[0] + bounding_box[2] \/ 2.0\n    y = bounding_box[1] + bounding_box[3] \/ 2.0\n    w = bounding_box[2]\n    h = bounding_box[3]\n \n    # \u5f52\u4e00\u5316\n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return (x, y, w, h)\n\ndef ConvertCOCOToYOLOv5(json_dir='', fileName=''):\n    labels_path = MakeFolders(json_dir + 'labels\/')  # label directory\n    jsonsData = json.load(open(json_dir + fileName))\n    category_id_map = CreateCategoryIDMap(jsonsData['categories'])\n\n    # transfer the annotationtation, and generated a train dataframe file\n    f = open(json_dir+'train.csv','w')\n    f.write('id,file_name\\n')\n    for i in tqdm(range(len(jsonsData['images']))):\n        file_name = jsonsData['images'][i]['file_name']\n        image_width = jsonsData['images'][i]['width']\n        image_height = jsonsData['images'][i]['height']\n        image_id = jsonsData['images'][i]['id']\n        yolo_txt_name = file_name.split('.')[0] + '.txt' #remove .jpg\n        \n        f.write('{},{}\\n'.format(image_id, file_name))\n        yolo_txt_file = open(os.path.join(labels_path, yolo_txt_name), 'w')\n        \n        for annotation in jsonsData['annotations']:\n            if annotation['image_id'] == image_id:\n                yolo_bbox = ConvertBoundingBoxFromCOCOToYOLO(image_width, image_height, annotation['bbox']) # \"bbox\": [x,y,width,height]        \n                yolo_txt_file.write('{} {} {} {} {}\\n'.format(category_id_map[annotation['category_id']], yolo_bbox[0], yolo_bbox[1], yolo_bbox[2], yolo_bbox[3]))\n        yolo_txt_file.close()\n    f.close()\n    return category_id_map","ed377a6d":"from pandas.core.indexes import category\nfrom ConvertCOCOToYOLO import ConvertCOCOToYOLOv5\nimport pandas as pd\nimport os","973ebd86":"filePath = 'E:\\DeepLearning\\CowboyOutfitsDetection\\cowboyoutfits\\\\'\ntrainPath = filePath + 'train.json'\ntestPath = filePath + 'test.csv'\nvalidPath = filePath + 'valid.csv'\nimagesPath = filePath + 'images\\\\'","ba7db024":"categoryIDMap = ConvertCOCOToYOLOv5(filePath, 'train.json')","c00a9ce4":"trainList = pd.read_csv(filePath + 'train.csv')\nvalidList = pd.read_csv(filePath + 'valid.csv')\ntestList = pd.read_csv(filePath + 'test.csv')\n\n# \u6dfb\u52a0\u6570\u636e\u96c6\/\u9a8c\u8bc1\u96c6\u6807\u7b7e\ntrainList.loc[:, 'split'] = 'train'\nvalidList.loc[:, 'split'] = 'valid'\ntestList.loc[:, 'split'] = 'test'\ntrainAndValidData = pd.concat([trainList, validList, testList]).reset_index(drop=True)","e77f4ea0":"# make directory for traning section\nos.makedirs(filePath + 'images\/train', exist_ok=True)\nos.makedirs(filePath + 'images\/valid', exist_ok=True)\nos.makedirs(filePath + 'images\/test', exist_ok=True)\nos.makedirs(filePath +'labels\/train', exist_ok=True)\nos.makedirs(filePath +'labels\/valid', exist_ok=True)","95e85d8f":"# \u79fb\u52a8\u56fe\u50cf\/\u6807\u7b7e\u81f3\u5bf9\u5e94\u6587\u4ef6\u5939\nfrom tqdm import tqdm\nfrom shutil import copyfile\n\nmissList = []\nfor i in tqdm(range(len(trainAndValidData))):\n    row = trainAndValidData.loc[i]\n    name = row.file_name.split('.')[0]\n    if row.split == 'train':\n        copyfile(filePath + f'images\/{name}.jpg', filePath + f'images\/train\/{name}.jpg')\n        copyfile(filePath + f'labels\/{name}.txt', filePath + f'\/labels\/train\/{name}.txt')\n    elif row.split == 'valid':\n        try:\n            copyfile(filePath + f'labels\/{name}.txt', filePath + f'\/labels\/valid\/{name}.txt')\n        except:\n            name=name+'.jpg'\n            missList.append(name)\n            continue\n        copyfile(filePath + f'images\/{name}.jpg', filePath + f'images\/valid\/{name}.jpg')\n    elif row.split == 'test':\n        copyfile(filePath + f'images\/{name}.jpg', filePath + f'images\/test\/{name}.jpg')\nprint(len(missList))","84314954":"# train and val data as 1) directory: path\/images\/, 2) file: path\/images.txt, or 3) list: [path1\/images\/, path2\/images\/]\ntrain: E:\/DeepLearning\/CowboyOutfitsDetection\/cowboyoutfits\/images\/train\nval: E:\/DeepLearning\/CowboyOutfitsDetection\/cowboyoutfits\/images\/valid\n\n# number of classes\nnc: 5\n\n# class names\nnames: [\"belt\", \"sunglasses\", \"boot\", \"cowboy_hat\", \"jacket\"]","61770163":"@echo on\nset YOLO_PATH=D:\\Anaconda3\\Lib\\site-packages\\yolov5\nset DATA_YAML_PATH=E:\\DeepLearning\\CowboyOutfitsDetection\\cowboyoutfits\\yolov5-cowboy-outfit.yaml\nset NAME=RTX3070_local_first\nset NUM_EPOCHS=200\nset BATCH_SIZE=4\n\ncd \/d d:\ncd %YOLO_PATH%\npython train.py --data %DATA_YAML_PATH%  ^\n                        --cfg .\\models\\yolov5l.yaml ^\n                        --weights .\\weights\\yolov5l.pt ^\n                        --batch-size %BATCH_SIZE% ^\n                        --epochs %NUM_EPOCHS% ^\n                        --name %NAME%\npause","d3ba28b1":"\u7b2c\u4e00\u8f6e\u8bad\u7ec3\u5b8c\u6210\u540e\u63d0\u4ea4\uff0cmap\u5c31\u5df2\u7ecf\u8fbe\u523057.63\u4e86\u3002\u7b2c\u4e8c\u8f6e\u5728\u7b2c\u4e00\u8f6e\u7684\u9057\u4f20\u6743\u91cd\u4e0b\u7ee7\u7eed\u8bad\u7ec3\u4e86100\u8f6e\uff0c\u66f4\u6539\u4e86\u8d85\u53c2\u6570\u3002\u6ca1\u6709\u518d\u7528mosaic\u548cmixup\uff0coptimizer\u6362\u6210Adam","f0f1bb4c":"# Hyperparameters for COCO training from scratch\n# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n# See tutorials for hyperparameter evolution https:\/\/github.com\/ultralytics\/yolov5#tutorials\n\n\nlr0: 0.001  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.843  # SGD momentum\/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 0.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 5.0  # image rotation (+\/- deg)\ntranslate: 0.245  # image translation (+\/- fraction)\nscale: 0.898  # image scale (+\/- gain)\nshear: 0.602  # image shear (+\/- deg)\nperspective: 0.0  # image perspective (+\/- fraction), range 0-0.001\nflipud: 0.0  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 0.0  # image mosaic (probability)\nmixup: 0.0  # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)","224e004d":"@echo on\nset YOLO_PATH=D:\\Anaconda3\\Lib\\site-packages\\yolov5\nset DATA_YAML_PATH=E:\\DeepLearning\\CowboyOutfitsDetection\\cowboyoutfits\\yolov5-cowboy-outfit.yaml\nset NAME=RTX3070_local_second\nset NUM_EPOCHS=100\nset BATCH_SIZE=4\n\ncd \/d d:\ncd %YOLO_PATH%\npython train.py --data %DATA_YAML_PATH%  ^\n                        --cfg .\\models\\yolov5l.yaml ^\n                        --weights  .\\weights\\best-first.pt ^\n                        --batch-size %BATCH_SIZE% ^\n                        --epochs %NUM_EPOCHS% ^\n                        --adam\n                        --name %NAME%\npause","3cfd9f68":"\u7b2c\u4e8c\u8f6e\u63d0\u4ea4\u540emap\u5df2\u7ecf\u7a81\u783460\u4e86\uff0c\u63a5\u4e0b\u6765\u662f\u7b2c\u4e09\u8f6e\u3002\u53d6\u6d88\u4e86\u6240\u6709hsv\u548c\u5176\u4ed6\u7684\u56fe\u50cf\u589e\u5f3a\uff0c\u4f7f\u7528\u4e86focal loss\uff0c\u636e\u8bf4\u80fd\u63d0\u5347\u6559\u5c0f\u6837\u672c\u7684\u5b66\u4e60\u6548\u679c","f27a4833":"# Hyperparameters for COCO training from scratch\n# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n# See tutorials for hyperparameter evolution https:\/\/github.com\/ultralytics\/yolov5#tutorials\n\n\nlr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.843  # SGD momentum\/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 0.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 1.5  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.0  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.0  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.0  # image HSV-Value augmentation (fraction)\ndegrees: 0.0  # image rotation (+\/- deg)\ntranslate: 0.0  # image translation (+\/- fraction)\nscale: 0.0  # image scale (+\/- gain)\nshear: 0.0  # image shear (+\/- deg)\nperspective: 0.0  # image perspective (+\/- fraction), range 0-0.001\nflipud: 0.0  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 0.0  # image mosaic (probability)\nmixup: 0.0  # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)","3627a1cf":"@echo on\nset YOLO_PATH=D:\\Anaconda3\\Lib\\site-packages\\yolov5\nset DATA_YAML_PATH=E:\\DeepLearning\\CowboyOutfitsDetection\\cowboyoutfits\\yolov5-cowboy-outfit.yaml\nset NAME=RTX3070_local_third\nset NUM_EPOCHS=100\nset BATCH_SIZE=4\n\ncd \/d d:\ncd %YOLO_PATH%\npython train.py --data %DATA_YAML_PATH%  ^\n                        --cfg .\\models\\yolov5l.yaml ^\n                        --weights .\\weights\\best-60.pt ^\n                        --batch-size %BATCH_SIZE% ^\n                        --epochs %NUM_EPOCHS% ^\n                        --multi-scale ^\n                        --rect ^\n                        --name %NAME%\npause","31c020c8":"\u6700\u540e\u751f\u6210submission","425899af":" [code]","876ef730":"import os\nimport pandas as pd\nfrom tqdm import tqdm\nfrom PIL import Image\nimport zipfile\n\nfilePath = 'E:\/DeepLearning\/CowboyOutfitsDetection\/cowboyoutfits\/'\nexperimentName = 'RTX3070_local_third'\nvalidList = pd.read_csv(filePath + 'test.csv')\nvalidList.head()\ncate_id_map = {87: 0, 1034: 1, 131: 2, 318: 3, 588: 4}\nPRED_PATH = 'D:\/Anaconda3\/Lib\/site-packages\/yolov5\/runs\/detect\/' + experimentName +'\/labels'\nIMAGE_PATH = 'E:\/DeepLearning\/CowboyOutfitsDetection\/cowboyoutfits\/images'\n\n# list our prediction files path\nprediction_files = os.listdir(PRED_PATH)\nprint('Number of test images with detections: ', len(prediction_files))\n\n# convert yolo to coco annotation format\ndef yolo2cc_bbox(img_width, img_height, bbox):\n    x = (bbox[0] - bbox[2] * 0.5) * img_width\n    y = (bbox[1] - bbox[3] * 0.5) * img_height\n    w = bbox[2] * img_width\n    h = bbox[3] * img_height\n    return (x, y, w, h)\n\n# reverse the categories numer to the origin id\nre_cate_id_map = dict(zip(cate_id_map.values(), cate_id_map.keys()))\nprint(re_cate_id_map)\n\ndef make_submission(df, PRED_PATH, IMAGE_PATH):\n    output = []\n    for i in tqdm(range(len(df))):\n        row = df.loc[i]\n        image_id = row['id']\n        file_name = row['file_name'].split('.')[0]\n        if f'{file_name}.txt' in prediction_files:\n            img = Image.open(f'{IMAGE_PATH}\/{file_name}.jpg')\n            width, height = img.size\n            with open(f'{PRED_PATH}\/{file_name}.txt', 'r') as file:\n                for line in file:\n                    preds = line.strip('\\n').split(' ')\n                    preds = list(map(float, preds))  # conver string to float\n                    cc_bbox = yolo2cc_bbox(width, height, preds[1:-1])\n                    result = {\n                        'image_id': image_id,\n                        'category_id': re_cate_id_map[preds[0]],\n                        'bbox': cc_bbox,\n                        'score': preds[-1]\n                    }\n\n                    output.append(result)\n    return output\n\n\nsub_data = make_submission(validList, PRED_PATH, IMAGE_PATH)\n\nop_pd = pd.DataFrame(sub_data)\n\nos.makedirs(filePath + experimentName, exist_ok=True)\nop_pd.to_json(filePath + experimentName + '\/answer.json', orient='records')\nsubmissionZipFile = zipfile.ZipFile(filePath + experimentName +'\/sample_answer.zip', 'w')\nsubmissionZipFile.write(filePath + experimentName +'\/answer.json', 'answer.json')\nsubmissionZipFile.close()","461974cf":"\u521b\u5efaCowboyOutfitsDetection.py","eef54b34":"\u521b\u5efayolov5-cowboy-outfit.yaml","757c1b95":"\u8fd9\u91cc\u7684\u9a8c\u8bc1\u96c6\u662f\u6211\u81ea\u5df1\u624b\u52a8\u4ece999\u5f20\u56fe\u7247\u4e2d\uff0c\u5728[makesense](https:\/\/www.makesense.ai\/)\u4e0a\u6807\u6ce8\u4e86\u8fd1400\u5f20\u56fe\uff0c\u8fd9\u6837\u83b7\u5f97\u7684\u7ed3\u679c\u76f8\u5bf9\u66f4\u51c6\u786e","08ede332":"\u63a5\u4e0b\u6765\u662f\u7528yolov5\u8bad\u7ec3\uff0clarge\u7f51\u7edc\u662f\u5e73\u8861\u4e86\u6027\u80fd\u548c\u6548\u679c\u7684\u9009\u62e9\u3002\n\u7b2c\u4e00\u8f6e\u76f4\u63a5\u7528\u7684\u662f\u9ed8\u8ba4\u7684\u8d85\u53c2\u6570\uff0c\u8bad\u7ec3\u4e86200\u8f6e\uff0c\u4f46\u770b\u56fe50\u8f6e\u4e4b\u540e\u5c31\u6ca1\u5565\u533a\u522b\u4e86\u3002\n\u4e0b\u9762\u662f\u6211\u81ea\u5df1\u5199\u7684bat\u6587\u4ef6","36575009":"\u521b\u5efaConvertCOCOToYOLO.py\u6587\u4ef6\uff0c\u6a21\u5757\u5316","5bd2f504":"\u4eceConvertCOCOToYOLO.py\u6587\u4ef6\u52a0\u8f7d\u8fdb\u7684function"}}