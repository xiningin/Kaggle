{"cell_type":{"7970785f":"code","4a8d1c23":"code","9bc64dbe":"code","a0cf2c0c":"code","0b59bcb4":"code","8a214c3d":"code","47058832":"code","7aea01e7":"code","0f5daa0a":"code","d4266a8b":"code","0334c857":"code","3f077def":"code","b257cc1b":"code","f5bcd914":"code","de4cf405":"code","fe5863d7":"code","082e5f99":"code","b122bfac":"code","f453bb31":"code","01ac279e":"code","c8d466e3":"code","439574aa":"code","d69c4c84":"code","b940d30e":"code","16eec27f":"code","def18dcc":"code","7ff4f046":"code","a12726a6":"code","e3afd70f":"code","86b2798b":"code","a76c5996":"code","868304ee":"code","3eb42252":"code","2a6400c7":"code","6512bc47":"code","0bfc3eb7":"code","1e806bf1":"code","d1059aeb":"code","7f11cf71":"code","ec65377b":"code","74891a30":"code","fcff1385":"code","30128c47":"code","ecd8faef":"code","0809eabd":"code","7eb42d3b":"code","0d0bf7b0":"code","c9d1ccb1":"code","f7f8fa76":"code","f4f29b84":"code","b2c9da40":"code","09d813a5":"code","17508a2b":"code","ed0e527b":"code","4e4ea6ff":"code","0e913228":"code","12777c5e":"code","e1824fea":"code","7e19f74d":"code","8e0c7421":"code","4ced019c":"code","a8f64b2d":"code","646cd836":"code","46470652":"code","c6689d8f":"code","710ab88c":"code","19af93c1":"code","59c797c7":"code","f76ccece":"code","53ce325c":"code","47858425":"code","b19f7dd3":"code","4d7e24cf":"code","bbb6d411":"code","14151d13":"code","2e70f7f5":"code","ddd5076b":"code","1599af64":"code","5da6e7af":"code","ed8e4dca":"code","363941de":"code","80271c03":"code","111b105f":"code","8bffa0d3":"code","7d0ab6cd":"code","8bbd5cf2":"code","480cc333":"code","73157d2a":"code","3c1fdfcc":"code","79a5e3dc":"code","eaeb2901":"code","b9c8798e":"code","6e509520":"code","7a01bdd5":"code","24f0c2f3":"code","028f37dc":"code","8fe4357c":"code","681feb7a":"code","2c33818c":"code","b3a1cf0a":"code","f6fd80fd":"code","1f3ba17f":"code","03b9c923":"code","473603ac":"code","d7c364b4":"code","d9dbabf1":"code","a813c531":"code","8f07b2ea":"markdown","f8f9126b":"markdown","a9957ebe":"markdown"},"source":{"7970785f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a8d1c23":"customers = pd.read_csv('..\/input\/segmentation\/olist_customers_dataset.csv')\ngeolocation = pd.read_csv('..\/input\/segmentation\/olist_geolocation_dataset.csv')\norder_items = pd.read_csv('..\/input\/segmentation\/olist_order_items_dataset.csv')\norder_payments = pd.read_csv('..\/input\/segmentation\/olist_order_payments_dataset.csv')\norders = pd.read_csv('..\/input\/segmentation\/olist_orders_dataset.csv')\nproducts = pd.read_csv('..\/input\/segmentation\/olist_products_dataset.csv')\nsellers = pd.read_csv('..\/input\/segmentation\/olist_sellers_dataset.csv')\nproduct_category_name_translation = pd.read_csv('..\/input\/segmentation\/product_category_name_translation.csv')\nreviews_dataset = pd.read_csv('..\/input\/segmentation\/olist_order_reviews_dataset.csv')","9bc64dbe":"orders.head()","a0cf2c0c":"orders.sort_values(by='order_delivered_customer_date', ascending=False).tail(30)\norders.groupby('order_status').sum()","0b59bcb4":"orders.order_status.isin(['canceled','unavailable']).sum()\n#on peut supprimer ces lignes puisque pas de d'achat finalement non ?","8a214c3d":"orders.order_status.isin(['shipped','delivered']).sum()","47058832":"orders.shape","7aea01e7":"orders[orders.customer_id.duplicated()]\norders[orders.duplicated(['customer_id'])]","0f5daa0a":"customers[customers.customer_unique_id =='9a736b248f67d166d2fbb006bcb877c3'] ","d4266a8b":"customers[customers.customer_unique_id =='6fbc7cdadbb522125f4b27ae9dee4060'] ","0334c857":"customers[customers.customer_unique_id =='f9ae226291893fda10af7965268fb7f6'] ","3f077def":"d = dict(zip(customers.customer_id, customers.customer_unique_id))\nd","b257cc1b":"#df5.customer_unique_id.value_counts().to_dict()","f5bcd914":"orders.customer_id = orders.customer_id.map(d)","de4cf405":"orders.customer_id.value_counts()","fe5863d7":"orders[orders.customer_id =='8d50f5eadf50201ccdcedfb9e2ac8455' ]","082e5f99":"order_payments","b122bfac":"# joindre orders et order items\ndf1 = pd.merge(orders, order_items, on='order_id')\n# joindre df1 et customers (changed to unique_id)\ndf1 = df1.rename(columns={'customer_id':'customer_unique_id'})\n#customers.product_category_name = df5.product_category_name.map(category_dict)\n\ndf2 = pd.merge(df1, customers, on='customer_unique_id')","f453bb31":"df1.head()","01ac279e":"# joindre df2 et seller\ndf3 = pd.merge(df2, sellers, on='seller_id')","c8d466e3":"# joindre df3 et products\ndf4= pd.merge(df3, products, on='product_id')","439574aa":"df5 = pd.merge(df4,order_payments,on='order_id')","d69c4c84":"geolocation.head()","b940d30e":"customers.head()","16eec27f":"customers.isnull().sum()\ncustomers.shape","def18dcc":"customers.customer_state.value_counts()","7ff4f046":"customers.customer_state.value_counts()\n# \u00e7a compte 27 states","a12726a6":"# customers city counts more than 4000 cities\/\/\/ city and state can be replaced by zip code ","e3afd70f":"customers.customer_zip_code_prefix.value_counts()","86b2798b":"customers[customers.customer_zip_code_prefix == 22790]","a76c5996":"sellers.head()","868304ee":"sellers[sellers.seller_zip_code_prefix ==14940]","3eb42252":"sellers.seller_zip_code_prefix.value_counts()","2a6400c7":"order_items.head()","6512bc47":"order_items.shape","0bfc3eb7":"order_items.isnull().sum()","1e806bf1":"reviews_dataset.head()","d1059aeb":"products.head()","7f11cf71":"products.product_category_name.value_counts()","ec65377b":"df5.product_category_name.value_counts()","74891a30":"df5.product_category_name.isnull().sum()","fcff1385":"products.product_category_name.isnull().sum()","30128c47":"#df5.to_csv('df5.csv')","ecd8faef":"products.shape","0809eabd":"df5.shape","7eb42d3b":"product_category_name_translation.head()","0d0bf7b0":"#category_dict = pd.Series(product_category_name_translation.product_category_name.values,index=product_category_name_translation.product_category_name_english).to_dict()\ncategory_dict = pd.Series(product_category_name_translation.product_category_name_english.values,index=product_category_name_translation.product_category_name).to_dict()","c9d1ccb1":"category_dict","f7f8fa76":"df5.product_category_name = df5.product_category_name.map(category_dict)\n","f4f29b84":"product_categories_dict = {\n    'construction_tools_construction': 'construction',\n    'construction_tools_lights': 'construction',\n    'construction_tools_safety': 'construction',\n    'costruction_tools_garden': 'construction',\n    'costruction_tools_tools': 'construction',\n    'garden_tools': 'construction',\n    'home_construction': 'construction',\n\n    'fashio_female_clothing': 'fashion',\n    'fashion_bags_accessories': 'fashion',\n    'fashion_childrens_clothes': 'fashion',\n    'fashion_male_clothing': 'fashion',\n    'fashion_shoes': 'fashion',\n    'fashion_sport': 'fashion',\n    'fashion_underwear_beach': 'fashion',\n\n    'furniture_bedroom': 'furniture',\n    'furniture_decor': 'furniture',\n    'furniture_living_room': 'furniture',\n    'furniture_mattress_and_upholstery': 'furniture',\n    'bed_bath_table': 'furniture',\n    'kitchen_dining_laundry_garden_furniture': 'furniture',\n    'office_furniture': 'furniture',\n\n    'home_appliances': 'home',\n    'home_appliances_2': 'home',\n    'home_comfort_2': 'home',\n    'home_confort': 'home',\n    'air_conditioning': 'home',\n    'housewares': 'home',\n    'art': 'home',\n    'arts_and_craftmanship': 'home',\n    'flowers': 'home',\n    'cool_stuff': 'home',\n\n    'drinks': 'food_drink',\n    'food': 'food_drink',\n    'food_drink': 'food_drink',\n    'la_cuisine': 'food_drink',\n    'electronics': 'electronics',\n    'audio': 'electronics',\n    'tablets_printing_image': 'electronics',\n    'telephony': 'electronics',\n    'fixed_telephony': 'electronics',\n    'small_appliances': 'electronics',\n    'small_appliances_home_oven_and_coffee': 'electronics',\n    'computers_accessories': 'electronics',\n    'computers': 'electronics',\n'sports_leisure': 'sports_leisure',\n    'consoles_games': 'sports_leisure',\n    'musical_instruments': 'sports_leisure',\n    'toys': 'sports_leisure',\n    'cine_photo': 'sports_leisure',\n    'dvds_blu_ray': 'sports_leisure',\n    'cds_dvds_musicals': 'sports_leisure',\n    'music': 'sports_leisure',\n    'books_general_interest': 'sports_leisure',\n    'books_imported': 'sports_leisure',\n    'books_technical': 'sports_leisure',\n\n    'health_beauty': 'health_beauty',\n    'perfumery': 'health_beauty',\n    'diapers_and_hygiene': 'health_beauty',\n    'baby': 'health_beauty',\n\n    'christmas_supplies': 'supplies',\n    'stationery': 'supplies',\n    'party_supplies': 'supplies',\n    'auto': 'supplies',\n    'luggage_accessories': 'supplies',\n\n    'watches_gifts': 'gifts',\n\n    'agro_industry_and_commerce': 'misc',\n    'industry_commerce_and_business': 'misc',\n    'security_and_services': 'misc',\n    'signaling_and_security': 'misc',\n    'market_place': 'misc',\n    'pet_shop': 'misc',\n}","b2c9da40":"df5.product_category_name.value_counts()","09d813a5":"df5.product_category_name = df5.product_category_name.map(product_categories_dict)\n","17508a2b":"df5.product_category_name.value_counts()","ed0e527b":"df5[['order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','order_purchase_timestamp','shipping_limit_date']] =df5[['order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','order_purchase_timestamp','shipping_limit_date']].apply(pd.to_datetime)\n","4e4ea6ff":"df5.dtypes","0e913228":"cat = df5.select_dtypes(include='O').keys()\ndates = df5.select_dtypes(include='datetime64[ns]').keys()","12777c5e":"#df5.isnull().sum()","e1824fea":"df5.payment_type.value_counts()","7e19f74d":"df5.order_status.value_counts()","8e0c7421":"customers.customer_state.value_counts()\n#divisons les \u00e9tats du br\u00e9sil selon leurs localisation\n#r\u00e9gions 1-nord 2-nord est 3-centre-est 4-sud-est 5-sud\n# 1-AM,AC,TO,RO,PA,RR,\n# 2-PE,AL,BA,CE,MA,PB,PI,RN,SE,\n# 3-GO,DF,MT,MS\n# 4- SP,MG,ES,RJ,\n# 5- SC,PR,RS,\n\n\n\n\n","4ced019c":"states_dict=dict.fromkeys(['AM','AC','TO','RO','PA','RR'] ,'north')\nstates_dict.update(dict.fromkeys(['PE','AL','BA','CE','MA','PB','PI','RN','SE'], 'north east'))\nstates_dict.update(dict.fromkeys(['GO','DF','MT','MS'], 'center east'))\nstates_dict.update(dict.fromkeys(['SP','MG','ES','RJ'], 'south east'))\nstates_dict.update(dict.fromkeys(['SC','PR','RS'], 'south'))","a8f64b2d":"states_dict","646cd836":"df5.seller_state = df5.seller_state.map(states_dict)\ndf5.customer_state = df5.customer_state.map(states_dict)","46470652":"import pandas as pd\n\n# Multiple categorical columns\n\ndf5 = pd.get_dummies(df5, columns=['order_status','payment_type','product_category_name','customer_state','seller_state'])","c6689d8f":"df5","710ab88c":"df5.columns","19af93c1":"df5[df5.order_status_delivered == 1].order_delivered_customer_date","59c797c7":"cat.difference(['payment_type','order_status','product_category_name'])","f76ccece":"'''df = df5.drop(cat.difference(['payment_type','order_status','product_category_name']) ,axis =1)\ndf = df.drop(df[dates], axis =1)\n'''","53ce325c":"'''df = df.fillna(df.mean())'''","47858425":"'''df.shape'''","b19f7dd3":"orders.customer_id.isnull().sum()","4d7e24cf":"df5.order_delivered_customer_date.describe()","bbb6d411":"#reference date (ici derni\u00e8re livraison le 2018-10-17 prenons 2018-11-01 comme date d'aujourd'hui)","14151d13":"df6 = df5[df5.order_status_delivered == 1]","2e70f7f5":"df6['recency'] = df6.groupby('customer_unique_id')['order_delivered_customer_date'].transform('last')\n","ddd5076b":"orders[orders.order_id=='e481f51cbdc54678b7cc49136f2d6af7']","1599af64":"df6[df6.customer_unique_id == '7c396fd4830fd04220f754e42b4e5bff']","5da6e7af":"df6 = df6.drop(df6[df6.order_id.duplicated()== True].index)","ed8e4dca":"#v\u00e9rifions qu'on a des order_id unique on prend cet exemple \ndf6[df6.customer_unique_id == '7c396fd4830fd04220f754e42b4e5bff']","363941de":"df6['recency'].describe()","80271c03":"from datetime import datetime\n\nreference_date = datetime(2018,10,18,0,0,0,0)\n(reference_date -df6['recency']).dt.days\n","111b105f":"# Grouping by CustomerID\ndata_process = df6.groupby(['customer_unique_id']).agg({\n        'recency': lambda x: (reference_date -x).dt.days,\n        'order_id': 'count',\n        'price': 'sum'})\n#recency last order since x days","8bffa0d3":"data_process.recency =pd.to_numeric(data_process.recency, errors ='coerce').fillna(0).astype('int')\n","7d0ab6cd":"data_process.recency","8bbd5cf2":"data_process = data_process.rename(columns={'order_id':'total numbers of orders','price':'sum of expenses'})\ndata_process.sort_values(by='recency',ascending = True)","480cc333":"data_process.sort_values(by='total numbers of orders',ascending = False)","73157d2a":"data_process.sort_values(by='sum of expenses',ascending = False)","3c1fdfcc":"df6 = df6.drop(columns=['recency'],axis=1)","79a5e3dc":"#rfm_table = pd.merge(df6, data_process, on='customer_unique_id')\nrfm_table = data_process","eaeb2901":"rfm_table = rfm_table.rename(columns={'total numbers of orders':'Frequency','sum of expenses':'Monetary','recency':'Recency'})","b9c8798e":"import pandas as pd\nimport datetime as dt\nfrom datetime import datetime\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nimport squarify\nfrom sklearn.cluster import KMeans\n\nsse={}\ntx_recency = rfm_table[['Recency']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(tx_recency)\n    rfm_table[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_ \nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","6e509520":"import pandas as pd\nimport datetime as dt\nfrom datetime import datetime\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nimport squarify\nfrom sklearn.cluster import KMeans\n\nsse={}\ntx_recency = rfm_table[['Frequency']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(tx_recency)\n    rfm_table[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_ \nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","7a01bdd5":"import pandas as pd\nimport datetime as dt\nfrom datetime import datetime\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nimport squarify\nfrom sklearn.cluster import KMeans\n\nsse={}\ntx_recency = rfm_table[['Monetary']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(tx_recency)\n    rfm_table[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_ \nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","24f0c2f3":"# Plot RFM distributions\nplt.figure(figsize=(12,10))\n# Plot distribution of R\nplt.subplot(3, 1, 1); sns.distplot(rfm_table['Recency'])\n# Plot distribution of F\nplt.subplot(3, 1, 2); sns.distplot(rfm_table['Frequency'])\n# Plot distribution of M\nplt.subplot(3, 1, 3); sns.distplot(rfm_table['Monetary'])\n# Show the plot\nplt.show()","028f37dc":"#### Function for ordering clusters\ndef order_cluster(cluster_field_name, target_field_name, df, ascending):\n    new_cluster_field_name = 'new_'+cluster_field_name\n    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n    df_new = df_new.sort_values(by=target_field_name, ascending = ascending).reset_index(drop=True)\n    df_new['index']=df_new.index\n    df_final = pd.merge(df, df_new[[cluster_field_name, 'index']], on=cluster_field_name)\n    df_final = df_final.drop([cluster_field_name], axis=1)\n    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n    return df_final\n  \n#Recency Clusters\nkmeans = KMeans(n_clusters=2)\nkmeans.fit(rfm_table[['Recency']])\nrfm_table['RecencyCluster']=kmeans.predict(rfm_table[['Recency']])\nrfm_table = order_cluster('RecencyCluster','Recency', rfm_table, False)\n\n#Frequency Clusters\nkmeans = KMeans(n_clusters=2)\nkmeans.fit(rfm_table[['Frequency']])\nrfm_table['FrequencyCluster']=kmeans.predict(rfm_table[['Frequency']])\nrfm_table = order_cluster('FrequencyCluster','Frequency', rfm_table, True)\n\n#Monetary Clusters\nkmeans = KMeans(n_clusters=2)\nkmeans.fit(rfm_table[['Monetary']])\nrfm_table['MonetaryCluster']=kmeans.predict(rfm_table[['Monetary']])\nrfm_table = order_cluster('MonetaryCluster','Monetary', rfm_table, True)\n\n# Define a function to map the values \ndef set_value(row_number, assigned_value): \n    return assigned_value[row_number] \n  \n# Creating Recency Custer Tag Column\nc=rfm_table.groupby('RecencyCluster')['Recency'].agg(['min','max','mean']).reset_index()\nr1=str(c.iloc[0,1])+' to '+str(c.iloc[0,2]) \nr2='<='+str(c.iloc[1,2])\n# Create the dictionary \nR ={0 : r1, 1 : r2} \nrfm_table['RecencyClusterTag']=rfm_table['RecencyCluster'].apply(set_value, args =(R, )) \n\n# Creating Frequency Cluster Tag Column\na=rfm_table.groupby('FrequencyCluster')['Frequency'].agg(['min','max','mean']).reset_index()\nf2=str(a.iloc[0,1])+' to '+str(a.iloc[0,2]) \nf1='<='+str(a.iloc[1,2])\n# Create the dictionary \nF ={0 : f1, 1 : f2} \nrfm_table['FrequencyClusterTag']=rfm_table['FrequencyCluster'].apply(set_value, args =(F, )) \n\n# Creating Monetary Cluster Tag Column\nb=rfm_table.groupby('MonetaryCluster')['Monetary'].agg(['min','max','mean']).reset_index()\nm2=str(a.iloc[0,1])+' to '+str(a.iloc[0,2]) \nm1='<='+str(a.iloc[1,2])\n# Create the dictionary \nM ={0 : m1, 1 : m2} \nrfm_table['MonetaryClusterTag']=rfm_table['MonetaryCluster'].apply(set_value, args =(M, )) \n\nrfm_table[\"FrequencyClusterTag\"] = rfm_table[\"FrequencyClusterTag\"].astype(pd.api.types.CategoricalDtype(categories=[f1, f2]))\nrfm_table[\"MonetaryClusterTag\"] = rfm_table[\"MonetaryClusterTag\"].astype(pd.api.types.CategoricalDtype(categories=[m1, m2]))\nrfm_table[\"RecencyClusterTag\"] = rfm_table[\"RecencyClusterTag\"].astype(pd.api.types.CategoricalDtype(categories=[r1, r2]))\n","8fe4357c":"a","681feb7a":"rfm_table","2c33818c":"# Concat RFM quartile values to create RFM Segments\ndef join_rfm(x): return str(x['RecencyCluster']) + str(x['FrequencyCluster']) + str(x['MonetaryCluster'])\nrfm_table['RFM_Segment_Concat'] = rfm_table.apply(join_rfm, axis=1)\nrfm_table","b3a1cf0a":"# transformer les donn\u00e9es en array numpy only numeric data\n'''X = df.values'''","f6fd80fd":"'''from sklearn import preprocessing\n\nstd_scale = preprocessing.StandardScaler().fit(X)\nX_scaled = std_scale.transform(X)'''","1f3ba17f":"'''from sklearn import decomposition\n\npca = decomposition.PCA(n_components=4)\npca.fit(X_scaled)'''","03b9c923":"'''print(pca.explained_variance_ratio_)\nprint(pca.explained_variance_ratio_.sum())'''","473603ac":"'''from sklearn.preprocessing import StandardScaler # data normalization\nfrom sklearn.cluster import KMeans # K-means algorithm\nimport matplotlib.pyplot as plt # visualization\nimport seaborn as sns # visualization\nfrom termcolor import colored as cl # text customization\n\n\n\nplt.rcParams['figure.figsize'] = (20, 10)\nsns.set_style('whitegrid')'''","d7c364b4":"'''# DATA PROCESSING\n\nX = df.values\nX = np.nan_to_num(X)\n\nsc = StandardScaler()\n\ncluster_data = sc.fit_transform(X)\nprint(cl('Cluster data samples : ', attrs = ['bold']), cluster_data[:5])'''","d9dbabf1":"'''# MODELING\n\nclusters = 5\nmodel = KMeans(init = 'k-means++', \n               n_clusters = clusters, \n               n_init = 12)\nmodel.fit(X)\n\nlabels = model.labels_\nprint(cl(labels[:100], attrs = ['bold']))'''","a813c531":"'''df['cluster_num'] = labels\ndf.head()'''","8f07b2ea":"On choisit k =2","f8f9126b":"#best customers RFM score 111\nWho They Are: Highly engaged customers who have bought the most recent, the most often, and generated the most revenue.\n\nRFM Score: X1X\nWho They Are: Customers who buy the most often from your store.\n\nYour Highest Paying Customers\nRFM Score: XX1\nWho They Are: Customers who have generated the most revenue for your store.\n\nRFM Score: 00X\nWho They Are: Great past customers who haven't bought in a while.\n\nYour Newest Customers\nRFM Score: 10X\nWho They Are: First time buyers on your site.\n\nRFM Score: Remaining Scores\nWho They Are: Customer who have average metrics across each RFM scores.\n\n","a9957ebe":"#### df.groupby('cluster_num').mean()"}}