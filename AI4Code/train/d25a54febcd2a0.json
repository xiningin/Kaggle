{"cell_type":{"b03b024d":"code","ac7ee161":"code","b50322e1":"code","c2b694b9":"code","cfff3b35":"code","7163c7e8":"code","41a4a7ae":"code","ca91b740":"code","fffc2102":"code","ed92a1c1":"code","2669209e":"code","d6e0ccc4":"code","b7c8fc4e":"code","d0352dd5":"code","944ff01e":"code","266a9f7f":"code","5ecea23c":"code","4f9883b2":"code","e43804a7":"code","ef64fcb9":"code","beb17536":"code","78497d01":"code","a2eaabc1":"code","a07e4484":"code","565b5afb":"code","33baa20c":"code","3091f44e":"code","3ad91b48":"code","056811cc":"code","5475c465":"code","6c5dcf69":"code","4e823dd5":"code","8bbe34bf":"code","c9d39d35":"code","5b181675":"code","67b5c95b":"code","bdaa536c":"code","3792d925":"markdown","f8d04752":"markdown","98615d9f":"markdown","7d0774ce":"markdown","57c3b906":"markdown","d4d9eabc":"markdown","4e9ee453":"markdown","2c9c6cb6":"markdown","22f8c3c5":"markdown","f1488e23":"markdown","fad1e8be":"markdown","c2c5a997":"markdown","49f6a5d9":"markdown","3a95db90":"markdown","e493d2ad":"markdown","e4e31be5":"markdown","07a397c8":"markdown","d3505624":"markdown"},"source":{"b03b024d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ac7ee161":"df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id')\ndf","b50322e1":"df.columns\n","c2b694b9":"cols_with_missing = [[col,df[col].isna().sum()] for col in df.columns\n                     if df[col].isnull().any()]\ncols_with_missing","cfff3b35":"drop_col = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\nnew_df = df.drop(drop_col, axis=1)\nnew_df","7163c7e8":"imputed_col = ['LotFrontage','MasVnrArea','GarageYrBlt']\nimpu_df = df[imputed_col]\nimpu_df","41a4a7ae":"from sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\nimputed_df = pd.DataFrame(my_imputer.fit_transform(impu_df))\n# Imputation removed column names; put them back\nimputed_df.columns = impu_df.columns\nimputed_df\n","ca91b740":"new_df.update(imputed_df)\nnew_df[imputed_col].isnull().sum()","fffc2102":"# Get list of categorical variables\ns = (new_df.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)\n","ed92a1c1":"from sklearn.preprocessing import LabelEncoder\ncols = object_cols\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(new_df[c].values)) \n    new_df[c] = lbl.transform(list(new_df[c].values))","2669209e":"y = new_df['SalePrice']\nX = new_df.drop(columns=['SalePrice'])\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2)","d6e0ccc4":"df = new_df\ndf","b7c8fc4e":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\ntf.__version__","d0352dd5":"df_val = df.sample(frac=0.2, random_state=33)\ndf_val","944ff01e":"df_train = df.drop(df_val.index)\ndf_train","266a9f7f":"# A utility method to create a tf.data dataset from a Pandas Dataframe\ndef df_to_dataset(dataframe, target, shuffle=True, batch_size=10):\n  dataframe = dataframe.copy()\n  labels = dataframe.pop(target)\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","5ecea23c":"train_ds = df_to_dataset(dataframe=df_train, target='SalePrice')\nval_ds = df_to_dataset(dataframe=df_val, target='SalePrice')","4f9883b2":"for b in train_ds.take(1):\n    print(b)","e43804a7":"from tensorflow import feature_column\n\nfeature_columns = []\n# numeric cols\nfor col in df.columns:\n  if col == 'SalePrice':\n    continue\n  feature_columns.append(feature_column.numeric_column(col, dtype=tf.float16)) \nfeature_columns","ef64fcb9":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.DenseFeatures(feature_columns))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))","beb17536":"model.compile(optimizer='adam', loss='mae',metrics=['mae'])","78497d01":"model.evaluate(val_ds)","a2eaabc1":"model.fit(train_ds, epochs=400, validation_data=val_ds)","a07e4484":"model.summary()","565b5afb":"model.evaluate(val_ds)","33baa20c":"predictions = list (model.predict(val_ds))\npredictions","3091f44e":"df_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col='Id')\ndf_test","3ad91b48":"df_test = df_test.drop(drop_col, axis=1)\ndf_test","056811cc":"object_columns_test = df_test.select_dtypes(include='object')\nobject_columns_test","5475c465":"# Get list of categorical variables\ns1 = (df_test.dtypes == 'object')\nobject_columns_test = list(s1[s1].index)\n\nprint(\"Categorical variables:\")\nprint(object_columns_test)","6c5dcf69":"from sklearn.preprocessing import LabelEncoder\ncols = object_columns_test\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(df_test[c].values)) \n    df_test[c] = lbl.transform(list(df_test[c].values))\n","4e823dd5":"imputer = SimpleImputer(strategy='most_frequent')\ndf_test_final = pd.DataFrame(imputer.fit_transform(df_test))\ndf_test_final.columns = df_test.columns","8bbe34bf":"cols_with_missing = [col for col in df_test.columns if df_test_final[col].isnull().any()]\ncols_with_missing","c9d39d35":"input_dict = {name: tf.convert_to_tensor([value]) for name, value in df_test.loc[1461].items()}\ninput_dict","5b181675":"preds = []\nfor i, r in df_test_final.iterrows():\n    input_dict = {name: tf.convert_to_tensor([value]) for name, value in r.items()}\n    # print(model.predict(input_dict)[0][0])\n    preds.append(model.predict(input_dict)[0][0])","67b5c95b":"preds = pd.Series(preds)\npreds","bdaa536c":"# Save test predictions to file\noutput = pd.DataFrame({'Id': df_test.index,\n                       'SalePrice': preds})\noutput","3792d925":"1. Missing data (Drop)","f8d04752":"# Test Data","98615d9f":"# Train the model using fit fucntion\n","7d0774ce":"# Convert dataframe to tensor data","57c3b906":"# Compile model\n1. optimizer\n2. loss\n3. metircs","d4d9eabc":"# Import Keras\n","4e9ee453":"# Define model\n","2c9c6cb6":"# Read Data","22f8c3c5":"# Missing Values","f1488e23":"# Prepare X, y and Split data","fad1e8be":"# Prepare input layer","c2c5a997":"# Get predictions","49f6a5d9":"# Split data in to train and validation","3a95db90":"# Model summary","e493d2ad":"# Evaluate (after training)","e4e31be5":"# Evalute before training (evalute on random weights)\n","07a397c8":"2. Missing data (Imputation)","d3505624":"# Categorical Variables\nLabel Encoding"}}