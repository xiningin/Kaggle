{"cell_type":{"b9b49687":"code","82d1d4fd":"code","520668ab":"code","1baf2b41":"code","f1216aae":"code","a0c5f5e2":"code","3010551b":"code","d29156d1":"code","fc55f2a4":"code","edc42afb":"code","d08b40d0":"code","205efaca":"code","61b4ad59":"code","94bf938e":"code","98b38c00":"code","6ad7bdd5":"code","f6419a0c":"code","e735c605":"code","8ac7fcb7":"code","0993c727":"code","55a19fa3":"code","bb30f7fd":"code","0ea6a49a":"code","3f7f3849":"code","8a7d22a6":"code","ea58babe":"code","abd087c8":"code","a4580351":"markdown","45b0bfd2":"markdown","edaa819b":"markdown","cadbbf2b":"markdown","a4d9c574":"markdown","92d644ca":"markdown","5156fe38":"markdown","c38ff04d":"markdown","9047d778":"markdown","402236d8":"markdown"},"source":{"b9b49687":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","82d1d4fd":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\nfrom tensorflow.keras import Sequential","520668ab":"DATA_PATH = '\/kaggle\/input\/mobile-gallery-image-classification-data\/mobile_gallery_image_classification\/mobile_gallery_image_classification'","1baf2b41":"print(os.listdir(DATA_PATH))","f1216aae":"train_path = os.path.join(DATA_PATH, 'train')\ntest_path = os.path.join(DATA_PATH, 'test')\nprint(os.listdir(train_path))\nprint(os.listdir(test_path))","a0c5f5e2":"def view_random_image(target_dir, target_class):\n  # We will view image from here\n  target_folder = target_dir + target_class\n\n  # Get a random image path\n  random_image = random.sample(os.listdir(target_folder), 1)\n\n  # Read in the image and plot it using matplotlib\n  img = mpimg.imread(target_folder+'\/'+random_image[0])\n  plt.imshow(img)\n  plt.title(target_class)\n  plt.axis('off');\n  print(f\"Image shape {img.shape}\")\n\n  return img","3010551b":"target_dir = DATA_PATH+'\/train\/'\ntarget_dir","d29156d1":"img = view_random_image(target_dir=target_dir,\n                        target_class='Memes')","fc55f2a4":"class_names = sorted(os.listdir(os.path.join(DATA_PATH, 'train')))\nclass_names","edc42afb":"for i in class_names:\n  k = 1\n  plt.figure(figsize=(20,15))\n  plt.subplot(2,4,k)\n  rand_img = view_random_image(target_dir=target_dir,\n                        target_class=i)\n  k+=1","d08b40d0":"# Define training and test directory paths\ntrain_dir = DATA_PATH+'\/train\/'\ntest_dir = DATA_PATH+'\/test\/'\nprint(train_dir,\"\\n\", test_dir)","205efaca":"# Create augmented data generator instance\ntrain_datagen = ImageDataGenerator(rescale=1\/255.,\n                                   rotation_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   validation_split=0.3,\n                                   dtype='float32')\n\nval_datagen = ImageDataGenerator(rescale=1\/255.,\n                                 data_format='channels_last', \n                                 validation_split=0.3,\n                                 dtype='float32')","61b4ad59":"# Load data(data, label) from directory and turn them into batches\ntrain_data = train_datagen.flow_from_directory(train_dir,\n                                               target_size=(224,224),\n                                               batch_size=32,\n                                               class_mode='categorical',\n                                               subset=\"training\")\nval_data = val_datagen.flow_from_directory(train_dir,\n                                           target_size=(224,224),\n                                           batch_size=32,\n                                           class_mode='categorical',\n                                           subset=\"validation\")","94bf938e":"model = Sequential([\n  Conv2D(16, 3, padding='same', activation='relu', input_shape=(224,224,3)),\n  MaxPool2D(),\n  Conv2D(32, 3, padding='same', activation='relu'),\n  MaxPool2D(),\n  Conv2D(64, 3, padding='same', activation='relu'),\n  MaxPool2D(),\n  Flatten(),\n  Dense(128, activation='relu'),\n  Dense(6, activation='softmax')\n])\n\nmodel.compile(loss=\"categorical_crossentropy\",\n              optimizer=Adam(),\n              metrics=['accuracy'])","98b38c00":"model.summary()","6ad7bdd5":"history = model.fit(train_data,\n                    epochs=4,\n                    batch_size=32,\n                    steps_per_epoch=len(train_data),\n                    validation_data=val_data,\n                    validation_steps=len(val_data))","f6419a0c":"model.evaluate(val_data)","e735c605":"pd.DataFrame(history.history).plot()","8ac7fcb7":"print(class_names)","0993c727":"memes = mpimg.imread(test_dir+ \"house.jpg\")\n# View image\nplt.imshow(memes)\nplt.axis(False);","55a19fa3":"# Create a function to import an image and resize it to be able to be used with our model\ndef load_and_prep_image(filename, img_shape=224):\n  \"\"\"\n  Reads in an image from filename, turns it into a tensor and reshape into (224,224,3).\n  \"\"\"\n  img = tf.io.read_file(filename)\n  img = tf.image.decode_jpeg(img)\n  img = tf.image.resize(img,[img_shape, img_shape])\n  img = img\/255.\n  return img","bb30f7fd":"# Adjust function to work with multi-class\ndef pred_and_plot(model, filename, class_names):\n  \"\"\"\n  Imports an image located at filename, makes a prediction on it with\n  a trained model and plots the image with the predicted class as the title.\n  \"\"\"\n  # Import the target image and preprocess it\n  img = load_and_prep_image(filename)\n\n  # Make a prediction\n  pred = model.predict(tf.expand_dims(img, axis=0))\n\n  # Get the predicted class\n  if len(pred[0]) > 1: # check for multi-class\n    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n  else:\n    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n\n  # Plot the image and predicted class\n  plt.imshow(img)\n  plt.title(f\"Prediction: {pred_class}\")\n  plt.axis(False);","0ea6a49a":"file_name = test_dir + \"mahabodhi_tree.jpg\"\npred_and_plot(model, file_name, class_names)","3f7f3849":"for dirpath, dirnames, filenames in os.walk(test_dir):\n  test_data = filenames\ntest_data","8a7d22a6":"class_names","ea58babe":"test_classes = ['Memes', 'Memes', 'Cars', 'Memes', 'Selfies','Trees','Selfies']\nlen(test_classes), len(test_data)","abd087c8":"# Make preds on test data provided\nimport os\nimport random\n\n# test_dir = '\/content\/drive\/MyDrive\/Deep Learning\/data\/mobile_gallery_image_classification\/test\/'\nplt.figure(figsize=(25, 15))\nfor i in range(len(test_data)): \n  test_name = test_data[i]\n  filepath = test_dir + test_name\n\n  # Load the image and make predictions\n  img = load_and_prep_image(filepath) # don't scale images for EfficientNet predictions\n  pred_prob = model.predict(tf.expand_dims(img, axis=0)) # model accepts tensors of shape [None, 224, 224, 3]\n  pred_class = class_names[pred_prob.argmax()] # find the predicted class \n\n  # Plot the image(s)\n  plt.subplot(2, 4, i+1)\n  plt.imshow(img)\n  if test_classes[i] == pred_class:\n    title_color = \"g\"\n  else:\n     title_color = \"r\"\n  plt.title(f\"Actual: {test_classes[i]}, Pred: {pred_class}, prob: {pred_prob.max():.2f}\", c=title_color)\n  plt.axis(False);","a4580351":"# Basic model Buildinig a CNN Classifier","45b0bfd2":"## View random image from data","edaa819b":"## Fit and evaluate model","cadbbf2b":"# Prepare data for modeling","a4d9c574":"## Model Architecture","92d644ca":"# Import all relevant libraries","5156fe38":"## View random image from all classes","c38ff04d":"# Make prediction on image","9047d778":"# Overview\n- Get data from kaggle and explore\n- Prepare data for modeling\n- Basic model using CNN Classifier\n- Save, load and evaluate again\n- Run for some more epochs\n- Make final prediction","402236d8":"There is scope to improvement the model. But as a basic structure notebook I have just implemented how tensorflow works in multiclass image classification"}}