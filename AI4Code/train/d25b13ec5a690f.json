{"cell_type":{"cf4e0907":"code","2b471d10":"code","03fb719e":"code","7055d81e":"code","0a00fa46":"code","7c39a021":"code","b4b7f8d0":"code","093f01b9":"code","f8968b05":"code","9b1a015d":"code","c3bb941a":"code","64b6e61b":"markdown","8eb86633":"markdown","93f6a355":"markdown","6b0e3241":"markdown","7b003317":"markdown","a88c03a8":"markdown","1c18f6aa":"markdown","0a46fdbd":"markdown","99dd0358":"markdown"},"source":{"cf4e0907":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n!cp ..\/input\/sample_submission.csv  \/kaggle\/working\/sample_submission.csv\n# Any results you write to the current directory are saved as output.","2b471d10":"# Importing required libraries\nimport pandas as pd\nimport os\nimport numpy\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.set_style('whitegrid')\n\nfrom keras import models, layers\nfrom keras.utils.training_utils import multi_gpu_model","03fb719e":"# defining a function to create the LeNet5 network\ndef LeNet5(input_shape, activation='tanh'):\n    \n    \"\"\"\n    Build and return the LeNet5 CNN\n    with tanh activation in the Convolutional layers\n    and ReLu activation in the Dense layers\n    \"\"\"\n    \n    # taking the input and assigning it to X_input\n    X_input = layers.Input(shape=input_shape)\n    \n    # padding zeros to make the size of the \n    X = layers.ZeroPadding2D((2, 2))(X_input)\n    \n    # adding a Convolutional layer of 6 filters of size 5x5\n    X = layers.Conv2D(filters=6, kernel_size=(5, 5), activation=activation)(X)\n    \n    # adding an average pool layer of filter size 2x2 and stride size 2(helps in decreasing size of \"volume\" in case it is too big)\n    X = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n    \n    # adding another Convolutional layer with 16 filters of size 5x5\n    X = layers.Conv2D(filters=16, kernel_size=(5, 5), activation=activation)(X)\n    \n    # another average pool layer of filter size 2x2 and stride size 2\n    X = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n    \n    # flattening the \"volume\" to pass to the next Dense layer\n    X = layers.Flatten()(X)\n    \n    # a Dense layer that outputs a vector with 120 neurons and applies the relu activation\n    X = layers.Dense(120, activation='relu')(X)\n    \n    # a dense layer that outputs a vector with 84 neurons and applies the relu activation\n    X = layers.Dense(84, activation='relu')(X)\n    \n    # the final Dense layer with 10 neurons and applies the softmax activation which gives the probability of the current example belonging to each of the classes (10 in our case)\n    X = layers.Dense(10, activation='softmax')(X)\n    \n    # making a keras model object to return when the function is called\n    model = models.Model(inputs=X_input, outputs=X)\n    \n    # return the model\n    return model","7055d81e":"# reading the dataset train.csv\ntrain_df = pd.read_csv(\"..\/input\/train.csv\", header=0)\n\n# creating one hot encoded vectors for the label column to train the network\nlabels = pd.get_dummies(train_df['label']).values\n\n# assigning the pixel intensities to inputs\ninputs = train_df.iloc[:, 1:]\n\n# looping over all examples and reshaping them to 28x28 numpy arrays to feed into the network\ninputs_format = []\nfor _, row in inputs.iterrows():\n    inputs_format.append(row.values.reshape((28, 28, 1)).tolist())\n\ninputs_format = numpy.array(inputs_format)\nprint(inputs_format.shape)","0a00fa46":"counts = train_df.loc[:, ['label']].sort_values('label').label.value_counts().to_dict()\nordered_keys = [i for i in range(10)]\nordered_values = [counts[i] for i in range(10)]\nsns.barplot(x=ordered_keys, y=ordered_values)\n_ = plt.xticks(ordered_keys)\n_ = plt.xlabel('Class Label')\n_ = plt.ylabel('Number of examples')\n_ = plt.title('Number of examples in each class')","7c39a021":"# making the model\nlenet5 = LeNet5(inputs_format[0].shape) # inputs_format[0].shape is (28, 28, 1)\n\n# compiling the model with adam optimizer and categorical_crossentropy loss function along with the accuracy metric\nlenet5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# training the model with the processed data and splitting the dataset with 30% of the samples in the validation data set\nhistory = lenet5.fit(x=inputs_format, y=labels, validation_split=0.3, epochs=30)\n\n# saving the model in an h5 file\nlenet5.save('lenet5_mnist.h5')","b4b7f8d0":"fig, ax = plt.subplots(2, 3, figsize=(19.2, 9.6))\nfor ind in range(1, 7):\n    rand_ind = numpy.random.randint(0, 42000)\n    rand_img = inputs.iloc[rand_ind, :]\n    label = train_df['label'][rand_ind]\n    \n    pred_proba = lenet5.predict(numpy.array([rand_img.values.reshape((28, 28, 1)).tolist()]))\n    pred_label = numpy.argmax(pred_proba, axis=1)[0]\n    confidence = round(numpy.max(pred_proba, axis=1)[0] * 100, 2)\n    \n    plot_title = f\"\"\"Actual Label: {label}\n    Predicted Label: {pred_label}\n    Confidence: {confidence}%\"\"\"\n    \n    plt.subplot(2, 3, ind)\n    plt.imshow(rand_img.values.reshape(28, 28), cmap='gray')\n    plt.title(plot_title)\n\nplt.tight_layout()","093f01b9":"# importing the test data from test.csv\ntest_df = pd.read_csv(\"..\/input\/test.csv\", header=0)\n\n# looping over all examples and reshaping them to 28x28 numpy arrays to feed into the network\ntest_inputs_format = []\nfor _, row in test_df.iterrows():\n    test_inputs_format.append(row.values.reshape((28, 28, 1)).tolist())\n\ntest_inputs_format = numpy.array(test_inputs_format)\nprint(test_inputs_format.shape)","f8968b05":"pred_proba = lenet5.predict(test_inputs_format) # get the probabilities of the examples belonging to each class\npred_labels = numpy.argmax(pred_proba, axis=1) # get the actual class label(index of maximum probability)\n\n# create a pandas Series from pred_labels to feed into the sample_submissions.csv\npred_labels_series = pd.Series(pred_labels)\n\n# read the sample_submission.csv file\nsubmission_df = pd.read_csv(os.path.abspath(\"sample_submission.csv\"), header=0)\n\n# assigning the predicted labels to the Label column\nsubmission_df['Label'] = pred_labels_series\n\n# resetting the index of the csv file\nsubmission_df = submission_df.set_index(['ImageId'])\nprint(submission_df.head())\n# writing back the updated data frame\nsubmission_df.to_csv(os.path.abspath(\"sample_submission.csv\"))","9b1a015d":"fig, ax = plt.subplots(2, 3, figsize=(19.2, 9.6))\nfor ind in range(1, 7):\n    rand_ind = numpy.random.randint(0, 28000)\n    rand_img = test_df.iloc[rand_ind, :]\n    \n    pred_proba = lenet5.predict(numpy.array([rand_img.values.reshape((28, 28, 1)).tolist()]))\n    pred_label = numpy.argmax(pred_proba, axis=1)[0]\n    confidence = round(numpy.max(pred_proba, axis=1)[0] * 100, 2)\n    \n    plot_title = f\"\"\"Predicted Label: {pred_label}\n    Confidence: {confidence}%\"\"\"\n    \n    plt.subplot(2, 3, ind)\n    plt.imshow(rand_img.values.reshape(28, 28), cmap='gray')\n    plt.title(plot_title)\n\nplt.tight_layout()","c3bb941a":"# make a matplotlib figure and subplots\nfig, ax = plt.subplots(1, 2, figsize=(12.8, 4.8))\n\n# plot lineplots for train and validation accuracies\nsns.lineplot(x=range(len(history.history['acc'])), y=list(map(lambda x: x * 100, history.history['acc'])), ax=ax[0], label='Train')\nsns.lineplot(x=range(len(history.history['val_acc'])), y=list(map(lambda x: x * 100, history.history['val_acc'])), ax=ax[0], label='Validation')\n# setting other configurations for the plot\nax[0].set_title('Model Accuracies')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\nax[0].legend()\n\n# plot lineplots for train and avlidation losses\nsns.lineplot(x=range(len(history.history['loss'])), y=history.history['loss'], ax=ax[1], label='Train')\nsns.lineplot(x=range(len(history.history['val_loss'])), y=history.history['val_loss'], ax=ax[1], label='Validation')\n# setting other configurations for the plot\nax[1].set_title('Model Losses')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nax[1].legend()\n\n_ = plt.tight_layout()","64b6e61b":"## Reading the test data to predict the labels","8eb86633":"# The LeNet5 architecture implemented in Keras\n\n###### The LeNet5 model is a Convoutional Neural Network with 5 layers and works exceptionally well in recognizing handwritten digits.\n###### Below is the architecture of the LeNet5 neural network","93f6a355":"## Training the model and saving it","6b0e3241":"## Predicting the labels and writing them in the sample_submission file","7b003317":"## Reading the training data set","a88c03a8":"## Building and training the model with Keras","1c18f6aa":"![LeNet5](https:\/\/indoml.files.wordpress.com\/2018\/03\/lenet-52.png)","0a46fdbd":"## Plotting the trends in Accuracy and Loss","99dd0358":"## Visualizing distribution of number of examples in each class"}}