{"cell_type":{"960a6b02":"code","5a272426":"code","316f3160":"code","24d2db87":"code","8729b480":"code","043fddda":"code","77b97f87":"code","baae2b45":"code","43d2ed03":"code","cc17acf0":"code","a3998bd2":"code","8504ce79":"code","bdbe1fce":"code","d78ee187":"code","cfc658ef":"code","83988bfb":"code","57367708":"code","9cbdd2a4":"code","39bc89bf":"code","8812eeff":"code","1b5d5bfc":"code","34112562":"code","9dc31aa5":"code","6385474f":"code","343ea07e":"code","b48f0a36":"code","87e9f5d4":"code","317f7cff":"code","dfe704e3":"code","1d2ac7a9":"code","51e4ab34":"code","5e60e7a9":"code","f108cdff":"markdown","02302b8b":"markdown","551288a9":"markdown","b90fb7ea":"markdown","0f13ef67":"markdown","add3a554":"markdown","7c1804b8":"markdown"},"source":{"960a6b02":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","5a272426":"# IMPORTING DATA \ntrain=pd.read_csv('..\/input\/fashion-mnist_train.csv')\ntest=pd.read_csv('..\/input\/fashion-mnist_test.csv')","316f3160":"# For Plotting\nimport matplotlib.pyplot as plt","24d2db87":"train.shape , test.shape","8729b480":"train_label=train.iloc[:,0]\ndel train['label']","043fddda":"plt.imshow(train.values[250].reshape(28,28))\nprint('This is product number',train_label[250])","77b97f87":"plt.imshow(train.values[20].reshape(28,28))\nprint('This is product number',train_label[20])","baae2b45":"train_label=train_label.astype('category')","43d2ed03":"train_label=pd.get_dummies(train_label)\ntrain_label.head()","cc17acf0":"import tensorflow as tf","a3998bd2":"# Input \nx=tf.placeholder(tf.float32,name='x',shape=[None,784])\ny=tf.placeholder(tf.float32,name='y',shape=[None,10])\nkeep=tf.placeholder(tf.float32)","8504ce79":"def function(x,w_shape,b_shape):\n    w_init=tf.random_normal_initializer(stddev=0.2)\n    b_init=tf.constant_initializer(0.2)\n    w=tf.get_variable(name='w',shape=w_shape,initializer=w_init)\n    b=tf.get_variable(name='b',shape=b_shape,initializer=b_init)\n    return (tf.add(tf.matmul(x,w),b))","bdbe1fce":"x=tf.reshape(x,shape=[-1,28,28,1])","d78ee187":"def conv2d(x,weight_shape,bias_shape):\n    w_init=tf.truncated_normal_initializer(stddev=0.3)\n    b_init=tf.constant_initializer(0.1)\n    w=tf.get_variable(name='w',shape=weight_shape,initializer=w_init)\n    b=tf.get_variable(name='b',shape=bias_shape,initializer=b_init)\n    out=tf.nn.conv2d(x,w,strides=[1,1,1,1],padding='SAME')\n    return tf.add(out,b)","cfc658ef":"def max_pool(x,k=2):\n    return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')","83988bfb":"with tf.variable_scope('layer_1'):\n    hidden1=conv2d(x,[3,3,1,32],[32])\n    out1=max_pool(hidden1)\nwith tf.variable_scope('layer_2'):\n    hidden2=conv2d(out1,[3,3,32,64],[64])\n    out2=max_pool(hidden2)\nwith tf.variable_scope('layer_3'):\n    hidden3=conv2d(out2,[3,3,64,128],[128])\n    out3=max_pool(hidden3)\nwith tf.variable_scope('layer_4'):\n    new=tf.reshape(out3,shape=[-1,4*4*128])\n    out=function(new,[4*4*128,1024],[1024])\n    out2=tf.nn.dropout(out,keep)\nwith tf.variable_scope('layer_5'):\n    out1=function(out2,[1024,10],[10])","57367708":"#LOSS FUNCTION\ncross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=out1))","9cbdd2a4":"# Optimizer\nopti=tf.train.AdamOptimizer(learning_rate=0.001)\nstep=opti.minimize(cross_entropy)","39bc89bf":"# Accuracy checker\ncorrect=tf.equal(tf.argmax(out1,1),tf.argmax(y,1))\naccuracy=tf.reduce_mean(tf.cast(correct,tf.float32))","8812eeff":"# For mini batch\niteration=3000\nbatch_size=128","1b5d5bfc":"df=train.values","34112562":"df_label=train_label.values","9dc31aa5":"sess=tf.Session()\nvar_init=tf.initialize_all_variables()\nsess.run(var_init)","6385474f":"for i in range(iteration):\n    choice=np.random.choice(60000,size=batch_size)\n    df=df.reshape([-1,28,28,1])\n    sess.run(step,feed_dict={x:df[choice],y:df_label[choice],keep:0.4})\n    if i%200 == 0:\n        loss,accu =sess.run([cross_entropy,accuracy],feed_dict={x:df[choice],y:df_label[choice],keep:1})\n        print ('loss is',loss,'|   Accuracy is',accu)","343ea07e":"test_label=test.iloc[:,0]","b48f0a36":"del test['label']","87e9f5d4":"test=test.values","317f7cff":"test=test.reshape([-1,28,28,1])","dfe704e3":"test_label=test_label.astype('category')","1d2ac7a9":"test_label=pd.get_dummies(test_label)","51e4ab34":"test_label=test_label.values","5e60e7a9":"loss,accu=sess.run([cross_entropy,accuracy],feed_dict={x:test,y:test_label,keep:1})\nprint ('accuracy is',accu,'|   Loss is',loss)","f108cdff":"# CNN MODEL TO DETERMINE FASHION PRODUCTS","02302b8b":"## Let's See some of the Fashion items","551288a9":"## Test dataset","b90fb7ea":"## Seperating labels from train set","0f13ef67":"## Used 3 Convolution & pooling layer and finally used FC layer of 1024 neurons. \n### 1. Importing data \n### 2. Manipulation (shape,size) to feed to network\n### 3. Building Neural Network with convulotion layer and max pooling\n### 4. FC layer at last with Dropout to prevent from overfitting\n### 5. Accuracy checks ","add3a554":"## Building Network now","7c1804b8":"## Got accuracy of 88% on test dataset"}}