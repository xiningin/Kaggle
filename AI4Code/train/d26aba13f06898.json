{"cell_type":{"63f8890f":"code","a8d666ac":"code","13c48bf4":"code","30d72d02":"code","2dfb585b":"code","f761a4fb":"code","1ec1d5cd":"code","63aeeac9":"code","4654ddd1":"code","69687245":"code","fdf41205":"code","88ad35ef":"code","9d762ecf":"code","da295578":"code","d1747322":"code","3f253cd8":"code","c4d76c87":"code","a38b0d3d":"code","743b84bb":"code","5aabae66":"code","06cd9e16":"code","2cd91fe1":"code","9869e391":"code","98fc3a78":"code","d9599731":"code","48406356":"code","a7def108":"code","37faf98a":"code","99ca1fc8":"code","8558eb19":"code","a77292b3":"code","d017fa6d":"markdown","c2322d32":"markdown","c46afe78":"markdown","5a599318":"markdown","0f9b33d8":"markdown","96c545a8":"markdown","dde707fc":"markdown","bf2099ec":"markdown","59a6094f":"markdown","ba9e9631":"markdown","1e9ab595":"markdown","bd612a2a":"markdown","8b6537cf":"markdown","e3a00f80":"markdown","0306e93f":"markdown","274d6962":"markdown","896c8e1a":"markdown","f0f8ad20":"markdown","c45f83a5":"markdown","dbda2f1e":"markdown","1415046d":"markdown","54a1f0a6":"markdown","fb8c6c6c":"markdown","a53c8a8c":"markdown","e1965dad":"markdown","5c42d0f0":"markdown"},"source":{"63f8890f":"## Loading Libraries\n\nimport numpy as np\nimport pandas as pd\nfrom math import sqrt\n\n## For visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# set theme\nsns.set_style('whitegrid')\nplt.rc('font', size=14)\nplt.style.use('tableau-colorblind10')","a8d666ac":"data = pd.read_csv('..\/input\/sales-forecasting\/train.csv')\ndata.head()","13c48bf4":"# summary statistics\ndata.describe()","30d72d02":"# shape\ndata.shape","2dfb585b":"# data types\ndata.dtypes","f761a4fb":"data.info()","1ec1d5cd":"# change datatype of Date columns.\ndata['order_date'] = pd.to_datetime(data['Order Date'], dayfirst=True)\ndata['ship_date'] = pd.to_datetime(data['Ship Date'], dayfirst=True)","63aeeac9":"# Create `Year-Month`, 'year' and 'month' columns.\ndata['YearMonth'] = data['order_date'].apply(lambda x: x.strftime(\"%Y-%m\"))\ndata['year'] = data['order_date'].dt.year\ndata['month'] = data['order_date'].dt.month_name()\n\n# Create a column for Number of Days require to ship the product.\ndata['shipInDays'] = (data['ship_date'] - data['order_date']).dt.days\n\n# Viewing first five rows of data.\ndata.head()","4654ddd1":"# Shipping Time observation accourding to ShipModes.\na = data.groupby(by = ['shipInDays', 'Ship Mode']).count()['Order ID']\n\n# plot\na.unstack().plot(kind='bar', figsize=(14, 8))\n\nplt.xlabel(\"Shipping Time(in Days)\")\nplt.ylabel(\"Counts\")\nplt.title(\"Shipping Time According To Ship Modes\")\n\nplt.show()","69687245":"# Let's consider standard shipping days is 4. if shipping time is greater than 4 days then consider it as delayed.\ndata['is_delayed'] = data.shipInDays > 4\n\n# Feature columns\nfeatures = ['Order ID','Customer ID', 'Product ID', 'order_date', 'ship_date', 'Product Name', 'Country', 'Region', 'State', 'City', \n            'Segment', 'Category', 'Sub-Category', 'Ship Mode', 'YearMonth', 'year', 'month', 'shipInDays', 'is_delayed', 'Sales']\n\ndf = data[features]\ndf.head()","fdf41205":"df['is_delayed'] = df.is_delayed.map({True:1, False:0})\ndf.head(2)","88ad35ef":"# create a column for days of week.\ndf['day_of_week'] = df.order_date.dt.weekday","9d762ecf":"# Check Missing data\ndf.isnull().sum()","da295578":"# check for duplicate rows.\nif df.duplicated().sum() > 0:\n    df = df.drop_duplicates()","d1747322":"# Let's examine Sales over time.\na = pd.DataFrame(df.groupby(by=['year']).sum())\n\nplt.figure(figsize=(14, 4))\nsns.pointplot(x=a.index, y='Sales', data=a)\n\nplt.xlabel('Year')\nplt.ylabel('Sales')\nplt.title(\"Total Sales per Year\")\n\nplt.show()","3f253cd8":"# Year-to-Year observation of TotalSales.\na = pd.DataFrame(df.groupby(by=['YearMonth']).sum())['Sales']\n\nplt.figure(figsize=(14, 7))\na.plot(kind='line')\n\nplt.xlabel('Year')\nplt.ylabel('Sales')\nplt.title(\"Total Sales Trend\")\n\nplt.xticks(rotation=90)\nplt.show()","c4d76c87":"# Monthly observation of Sales Pattern.\nmonthSales_data = df.groupby(by='month').sum()['Sales']\nmonthSales_data = monthSales_data.sort_values()\n\n# plot\nmonthSales_data.plot(kind='line', figsize=(14, 7), color=\"#261C2C\", marker='o', label='TotalSales')\nmonthSales_data.plot(kind='bar', figsize=(14, 7), color=\"#6E85B2\", label='TotalSales')\n\nplt.xlabel('Months')\nplt.ylabel(\"Sales\")\nplt.title(\"Monthly Observation of Total Sales.\")\n\nplt.legend()\nplt.show()","a38b0d3d":"# Monthly Year-to-Year observation of Sales Pattern.\nmonthSales_data = df.groupby(by=['year', 'month']).sum()\n\na = monthSales_data.reset_index()\na['month'] = a.month.apply(lambda x:x[:3])\nmonthSales_data = a.groupby(by=['year', 'month']).sum()['Sales']\n\n# plot\nfig, ax = plt.subplots(nrows=4, ncols=1, figsize=(14, 8))\n\nyrs = [2015, 2016, 2017, 2018]\nfor i in range(4):\n    yr = yrs[i]\n    a = monthSales_data.loc[yr]\n    ax[i] = sns.lineplot(x= a.index, y=a.values, data=a, ax=ax[i], label=yr, marker=\"o\", color=\"#3F007190\")\n    ax[i].set_ylabel('Sales')\n\nplt.show()","743b84bb":"# Sales trends over days.\nsns.catplot(data=df, x='day_of_week', y='Sales', kind='point', aspect=2)\n\nplt.title(\"Sales Trends Over Days\")\nplt.show()","5aabae66":"# Sales Distribution\nplt.figure(figsize=(14, 8))\nsns.distplot(data.Sales)\n\nplt.title('Sales Distribution Plot')\nplt.show()","06cd9e16":"bins = [0, 50, 100, 200, 500, 1000, 5000, 10000, 20000]\nlabels=['Sales50', 'Sales100', 'Sales200', 'Sales500', 'Sales1000', 'Sales5000', 'Sales10000', 'Sales20000']\na = pd.DataFrame(pd.cut(df['Sales'], bins=bins, labels=labels))\na['SalesCount'] = df['Order ID']\n\n# visualization\na.groupby('Sales').count().plot(kind='line', marker='o', figsize=(14, 8))\n\nplt.ylabel(\"Counts\")\nplt.title(\"Sales Count\")\n\nplt.legend()\nplt.show()","2cd91fe1":"# check for outliers in Sales.\nplt.figure(figsize=(14, 8))\nsns.boxplot(data=df, x='year', y='Sales', saturation=0.5)\nplt.show()","9869e391":"# prepare data\nsales_data = df[['order_date', 'Sales']]\nsales_data = sales_data.set_index('order_date')\n\n# calculating rolling statistics.\nroll_mean = sales_data.rolling(window=7).mean()\nroll_std = sales_data.rolling(window=7).std()\n\n# plotting rolling statistics with orignal data mean.\nplt.figure(figsize=(14, 7), dpi=100)\ndata_mean = plt.plot(sales_data.resample('W').mean(), label='Original', marker=\"o\", alpha=0.5)\nmean = plt.plot(roll_mean.resample('W').mean(), label=\"Rolling Mean\", marker=\".\")\nstd = plt.plot(roll_std.resample('W').std(), label=\"Rolling Standard\", alpha=0.5)\n\nplt.title(\"Rolling Mean Test\")\nplt.legend()\nplt.show()","98fc3a78":"from statsmodels.tsa.stattools import adfuller\n\nprint(\"Augmented Dickey-fuller test result: \")\nresult = adfuller(sales_data, autolag=\"AIC\")\n\nprint(\"ADF test statistic: \", result[0])\nprint(\"p-value:\", result[1])\n\nprint(\"Critical Values:\")\nfor key, val in result[4].items():\n    print(\"\\t%s : %f\" %(key, val))","d9599731":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = seasonal_decompose(df.Sales, model = 'multiplicative', freq=365)\n\nestimated_seasonal = decomposition.seasonal\nestimated_trend = decomposition.trend\nestimated_residuals = decomposition.resid\n\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(14, 10))\naxs[0].plot(estimated_trend, label='Trend')\naxs[0].set_title(\"Trend Plot\")\naxs[0].legend()\n\naxs[1].plot(estimated_seasonal, label='Seasonality', color='orange')\naxs[1].set_title(\"Seasonality Plot\")\naxs[1].legend()\n\nplt.show()","48406356":"import statsmodels.api as sm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsales = pd.DataFrame(df.groupby(by=['order_date']).sum()['Sales'])\n\n# Fitting ARIMA model\nmodel = sm.tsa.statespace.SARIMAX(sales,order=(1, 0, 0), seasonal_order=(1, 1, 1, 12))\nresult = model.fit()\nprint(\"SARIMAX Summary\")\nprint(result.summary().tables[1])","a7def108":"# Visualization of the performance of our model\nresult.plot_diagnostics(figsize=(14, 10))\nplt.show()","37faf98a":"sales['Forecast']= pd.DataFrame(result.predict(start='2018-01-01', end='2018-12-30', dynamic=False))\n\n# visualization for the same\nsales.plot(figsize=(14, 8))\nplt.show()","99ca1fc8":"actual = sales.loc['2018-01-01':'2018-12-30']['Sales']\npreds = sales.loc['2018-01-01':'2018-12-30']['Forecast']\nrmse_sarima = sqrt(mean_squared_error(preds, actual))\nprint(\"Root Mean Squared Error for SARIMAX:\", rmse_sarima)","8558eb19":"from xgboost import XGBRegressor\n\nxgb_sales = pd.DataFrame(df.groupby(by=['order_date']).sum())\n\nx = xgb_sales.drop('Sales', axis=1)\ny = xgb_sales['Sales']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.3, random_state=42)\n\nmodel = XGBRegressor(learning_rate=0.03, max_depth=1,)\nmodel.fit(x_train, y_train)\n\npreds = model.predict(x_test)\nrmse_xgb = sqrt(mean_squared_error(y_test, preds))\n\nprint(\"Root Mean Squared Error for XGBoost:\", rmse_xgb)","a77292b3":"result = pd.DataFrame([[rmse_sarima], [rmse_xgb]], columns=['RMSE'], index=['SARIMAX','XGBRegressor'])\nresult","d017fa6d":"## Line Plot","c2322d32":"To use the time series forecasting models, we need to ensure that the our data is **stationay**. The time series is stationay when data has constant mean, constant variance, and constant covariance with respect to time.\n\nThere are two ways to check Stationarity of Time Series.\n\n#### 1. Rolling Mean: \nA rolling analysis of a time series model is often used to assess the model\u2019s stability over time. The window is rolled (slid across the data) on a weekly basis, in which the average is taken on a weekly basis. Rolling Statistics is a visualization test, where we can **compare** the **original data with the rolled data and check if the data is stationary or not**.\n\n#### 2. Augmented Dickey-Fuller test: \nThe Dickey Fuller test is one of the most popular statistical tests. It can be used to determine the presence of unit root in the series, and hence help us to understand if the series is stationary or not. The **null hypothesis** of the **Augmented Dickey-Fuller** is that there is a **unit root(i.e data is non-stationary)**, with the **alternative** that **there is no unit root(i.e data is stationary)**. if the p-value is less than **critical value (i.e 0.05)** we reject the null hypothesis which means that data is **Stationary**.\n  ","c46afe78":"# Loading Libraries and Dataset","5a599318":"# Model Evaluation","0f9b33d8":"Distribution is **not Gaussian Distribution**. The shape has **long right tail**, which means that data is **Right Skewed**. The most of the sales values are less than 50.","96c545a8":"## Box and Whisker plots for Distribution.\nYearly observation of Distribution of Data. This will gives us an idea of spread of observation for each year.","dde707fc":"# Data Analysis","bf2099ec":"# Sales Forcasting Time Series Analysis","59a6094f":"The above line plot does **not show** any **trends** in data. So, There **no differencing is required**.","ba9e9631":"The plot shows that there is more than **4000** product with sales value **less than 50**.","1e9ab595":"# Building a Model\n\n## 1. AutoRegressive Integrated Moving Average (ARIMA) Model","bd612a2a":"The Root mean squared error of XGBRegressor model is less than SARIMAX. We can use XGBRegressor for forecasting Sales.","8b6537cf":"Above plot show that, The Mean and Standard deviation does not change over time much which means that the **Mean and Deviation is constant**. \n\nThe result output of **ADF (Augmented Dickey-Fuller) statistical test** has value **-98.33059943935697** which is **smaller than critical value at 1% of -3.431018**. This suggest that **we can reject the null hypothesis** with the significance level **less than 1%**.\nRejecting null hypothesis means that, The **time series is stationary** and **does not have time-dependent structure**.","e3a00f80":"We can see that, there is maximum sales on **Wednesday** and **Thursday**.","0306e93f":"There is increasing trends or growth in **Sales** over time. There may be **seasonality** to the sales for each year","274d6962":"We can see that,There is rise in months of **December**, **November**, and **September**. The **same pattern observed in each year**, however it appears at the different levels.","896c8e1a":"## Bar Plot","f0f8ad20":"# 1. Trends and Seasonality","c45f83a5":"From above bar plot, we can see that, overall growth in sales obseved in Months of **September**, **December**, **November**. Let's examine, if the same sales pattern observed in each year.","dbda2f1e":"# 2. Stationarity of Time Series","1415046d":"### 1. Rolling Mean","54a1f0a6":"## Density plots","fb8c6c6c":"We can see that there are **outliers** in Sales values for each year.","a53c8a8c":"We can see that Date columns is of **Object** types, Let's change it into **Date** datatype.","e1965dad":"## 2. XGBoost","5c42d0f0":"### 2. Augmented Dickey-Fuller test"}}