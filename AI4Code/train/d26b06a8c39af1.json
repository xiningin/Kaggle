{"cell_type":{"3fcd42a2":"code","b638e1b0":"code","dc556260":"code","f858ac71":"code","127dba7a":"code","05648fdd":"code","5702051f":"code","7f983e28":"code","5aa0342a":"code","536a54cf":"code","f8619a55":"code","84bdf4a7":"code","4bfaa947":"code","776d0bfe":"code","92f0f020":"code","90ffa1e7":"code","4c68e4ac":"code","c18fb497":"code","174231e1":"code","1b21f6f8":"code","65ea9c7b":"code","fb66878f":"code","a0ef626e":"code","28235572":"code","15637cde":"code","b8d8c49f":"code","7b07f00a":"code","607bebc1":"code","192e5ab8":"code","896726ec":"code","d110d3d4":"code","de9ebb4b":"code","4f552d46":"code","d2d83325":"code","94af434c":"code","a9c375ec":"code","30e95fd4":"code","d57f129c":"code","864ec802":"code","44ac2fc5":"code","7f040111":"code","735d6152":"code","1076890e":"code","07918333":"code","b946f4b1":"code","f0a98fa9":"code","7637ce2d":"code","470319ba":"code","3a810c1e":"code","e8008f14":"code","6999cff7":"code","231f9820":"code","cfa6ecb6":"code","d3ff3a99":"markdown","a3b734dc":"markdown","53f17588":"markdown","67089ddb":"markdown","af719112":"markdown","a1743ce9":"markdown","7c40564c":"markdown","4d9c3597":"markdown","31c485cc":"markdown","59285053":"markdown","9bf93592":"markdown","e39b988e":"markdown","02d20b1c":"markdown","ed541546":"markdown","dc91c42b":"markdown","56159f18":"markdown","908b7bba":"markdown","e369bb57":"markdown","f4856304":"markdown","56ca868e":"markdown","b1698b72":"markdown","e0785434":"markdown","9d10f202":"markdown","e358af7e":"markdown","164e751a":"markdown","5a4bbf60":"markdown","ccab8f39":"markdown","bb319976":"markdown","55181400":"markdown","19539801":"markdown","287e6b1e":"markdown","f961f1ad":"markdown","a94acddd":"markdown","b104df2d":"markdown"},"source":{"3fcd42a2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.utils import resample\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score, KFold, GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nplt.style.use('ggplot')\n# %notebook inline","b638e1b0":"# Function which read csv raw data into pandas dataframe.\ndef process_raw_data(row_data_dir=\"..\/input\/\", hf=False):\n    if hf:\n        hf_data = pd.read_csv(row_data_dir+\"HF.csv\", header=None).T\n        hf_ts = pd.read_csv(row_data_dir+\"TimeTicksHF.csv\", dtype='float64')\n        hf_ts['datetime'] = pd.to_datetime(hf_ts.iloc[:, 0], unit='s')\n        \n        # adding the timestamps to the data.\n        hf_data['datetime'] = hf_ts['datetime']\n        # drop nans values.\n        hf_data = hf_data.dropna()\n        # set datetime as index.\n        hf_data = hf_data.set_index('datetime')\n        # round datetime index to seconds.\n        hf_data.index = hf_data.index.floor('s')\n        # drop duplicated index.\n        hf_data = hf_data[~hf_data.index.duplicated(keep='first')]\n#         hf_data = hf_data.drop(columns = ['ts'])\n        \n\n    else:\n        lf1i_data = pd.read_csv(row_data_dir+\"LF1I.csv\", header=None )\n        lf1v_data = pd.read_csv(row_data_dir+\"LF1V.csv\", header=None)\n        lf2i_data = pd.read_csv(row_data_dir+\"LF2I.csv\", header=None)\n        lf2v_data = pd.read_csv(row_data_dir+\"LF2V.csv\", header=None)\n\n        lf1_ts = pd.read_csv(row_data_dir+\"TimeTicks1.csv\", dtype='float64')\n        lf1_ts['datetime'] = pd.to_datetime(lf1_ts.iloc[:, 0], unit='s')\n        lf2_ts = pd.read_csv(row_data_dir+\"TimeTicks2.csv\", dtype='float64')\n        lf2_ts['datetime'] = pd.to_datetime(lf2_ts.iloc[:, 0], unit='s')\n        \n\n        # list of dataframes.\n        data_lst = [lf1i_data, lf1v_data, lf2i_data, lf2v_data]\n        # converting from str to complex.\n        for data in data_lst:\n            for i in range(data.shape[1]):\n                data.iloc[:,i] = data.iloc[:,i].str.replace('i', 'j').apply(complex)\n\n                \n         # adding the timestamps to the data.\n        lf1i_data['datetime'] = lf1_ts['datetime']\n        lf1v_data['datetime'] = lf1_ts['datetime']\n        lf2i_data['datetime'] = lf2_ts['datetime']\n        lf2v_data['datetime'] = lf2_ts['datetime']\n        \n        # drop nans values.\n        lf1i_data = lf1i_data.dropna()\n        lf1v_data = lf1v_data.dropna() \n        lf2i_data = lf2i_data.dropna()\n        lf2v_data = lf2v_data.dropna()\n        \n        \n        # set datetime as index and round the index to seconds.\n        lf1i_data.index = lf1i_data.set_index('datetime').index.floor('s')\n        lf1v_data.index = lf1v_data.set_index('datetime').index.floor('s')\n        lf2i_data.index = lf2i_data.set_index('datetime').index.floor('s')\n        lf2v_data.index = lf2v_data.set_index('datetime').index.floor('s')     \n        \n        \n        # remove duplicated index.\n        lf1i_data = lf1i_data[~lf1i_data.index.duplicated(keep='first')]\n        lf1i_data.index = lf1i_data.set_index('datetime').index.floor('s')\n        \n        lf1v_data = lf1v_data[~lf1v_data.index.duplicated(keep='first')]\n        lf1v_data.index = lf1v_data.set_index('datetime').index.floor('s')\n        \n        lf2i_data.index = lf2i_data.set_index('datetime').index.floor('s')\n        lf2i_data = lf2i_data[~lf2i_data.index.duplicated(keep='first')]\n        \n        lf2v_data.index = lf2v_data.set_index('datetime').index.floor('s')\n        lf2v_data = lf2v_data[~lf2v_data.index.duplicated(keep='first')]\n    \n    ### tagging_data ###\n    tagging_data = pd.read_csv(row_data_dir+\"TaggingInfo.csv\", header=None, dtype={'1':str})\n\n    # convertion from unix to datetime.        \n    tagging_data['dt_on'] = pd.to_datetime(tagging_data.iloc[:,2], unit='s')\n    tagging_data['dt_off'] = pd.to_datetime(tagging_data.iloc[:,3], unit='s')\n    \n    if hf:\n        print('hf_data shape: {0}'.format(hf_data.shape))\n\n        return hf_data, tagging_data\n        \n    else:  \n        print('lf1i_data shape: {0}'.format(lf1i_data.shape))\n        print('lf1v_data shape: {0}'.format(lf1v_data.shape))\n        print('lf2i_data shape: {0}'.format(lf2i_data.shape))\n        print('lf2v_data shape: {0}'.format(lf2v_data.shape))\n        \n                \n        return lf1i_data, lf1v_data, lf2i_data, lf2v_data, tagging_data","dc556260":"def assign_labels(tagging_data, row):\n    for i in range(tagging_data.shape[0]):\n        if row['datetime'] in pd.Interval(tagging_data.iloc[i,-2], tagging_data.iloc[i ,-1], closed='both'):\n            return tagging_data.iloc[i, 1]\n    return 'None'","f858ac71":"def elec_features(lf1i_data, lf1v_data, lf2i_data, lf2v_data, idx):\n    # Compute net complex power \n    # S=Sum_over(In*Vn*cos(PHIn))=Sum(Vn*complex_conjugate(In))=P+jQ\n    l1_p = np.multiply(lf1v_data.iloc[:, :6], np.conj(lf1i_data.iloc[:, :6])).loc[idx]\n    l2_p = np.multiply(lf2v_data.iloc[:, :6], np.conj(lf2i_data.iloc[:, :6])).loc[idx]\n        \n    l1_complex_power = np.sum(l1_p, axis=1).loc[idx]\n    l2_complex_power = np.sum(l2_p, axis=1).loc[idx]\n    \n    # Real, Reactive, Apparent powers: P=Real(S), Q=Imag(S), S=Amplitude(S)=P^2+Q^2\n    # l1 - stands for phase 1 S - Vector Aparent Power\n    # Phase-1\n    l1_real = l1_complex_power.apply(np.real).loc[idx]\n    l1_imag = l1_complex_power.apply(np.imag).loc[idx]\n    l1_app  = l1_complex_power.apply(np.absolute).loc[idx]\n\n    # Real, Reactive, Apparent power currents\n    # l2 - stands for phase 2 S - Vector Aparent Power\n    # Phase-2\n    l2_real = l2_complex_power.apply(np.real).loc[idx]\n    l2_imag = l2_complex_power.apply(np.imag).loc[idx]\n    l2_app  = l2_complex_power.apply(np.absolute).loc[idx]\n    \n    # Compute Power Factor, we only consider the first 60Hz component\n    # PF=cosine(angle(S))\n    l1_pf = l1_p.iloc[:,0].apply(np.angle).apply(np.cos).loc[idx]\n    l2_pf = l2_p.iloc[:,0].apply(np.angle).apply(np.cos).loc[idx]\n    y = lf2i_data['label'].astype(str).loc[idx] \n    \n    \n    return l1_real, l1_imag, l1_app, l2_real, l2_imag, l2_app, l1_pf, l2_pf, y ","127dba7a":"def proper_index(tagging_data, hf_data, lf1i_data):\n    \n    print('orginal hf_data  shape: {}'.format(hf_data.shape))\n    print('orginal lf_data  shape: {}'.format(lf1i_data.shape))\n        \n    # slice idx to be in the range of first tagging device on datetime idx to last device off datetime idx.\n    idx = lf1i_data.loc[tagging_data.dt_on.iloc[0]:tagging_data.dt_off.iloc[-1],:].index\n    \n    print('idx len (first transformation): {}'.format(len(idx)))\n    \n    # idx which are common to hf_data and lf1_data\/lf2_data.\n    idx = hf_data.index.intersection(idx)\n    \n    print('idx shape (second transformation): {}'.format(len(idx)))\n    \n    return idx, hf_data.loc[idx]","05648fdd":"hf_data, tagging_data = process_raw_data(hf=True)\nhf_data.head()","5702051f":"lf1i_data, lf1v_data, lf2i_data, lf2v_data, tagging_data = process_raw_data() \nlf1i_data.head()","7f983e28":"lf1v_data.head()","5aa0342a":"lf2i_data.head()","536a54cf":"lf2v_data.head()","f8619a55":"tagging_data.head()","84bdf4a7":"tagging_data.shape","4bfaa947":"lf2i_data['label'] = lf2i_data.apply(lambda row: assign_labels(tagging_data, row), axis=1)","776d0bfe":"lf2i_data.shape","92f0f020":"lf1i_data.shape","90ffa1e7":"idx, hf_data = proper_index(tagging_data, hf_data, lf1i_data)","4c68e4ac":"l1_real, l1_imag, l1_app, l2_real, l2_imag, l2_app, l1_pf, l2_pf, y = elec_features(lf1i_data, lf1v_data, lf2i_data, lf2v_data, idx)","c18fb497":"y.shape","174231e1":"l1_real.shape","1b21f6f8":"lf2i_data.shape","65ea9c7b":"lf2i_data.label.unique()","fb66878f":"y.unique().tolist()","a0ef626e":"y.value_counts() ","28235572":"y.value_counts().plot(kind='bar')\nplt.show()","15637cde":"X = pd.concat([l1_real, l1_imag, l1_app, l1_pf, l2_real, l2_imag, l2_app, l2_pf, hf_data], axis=1).values","b8d8c49f":"X.shape","7b07f00a":"y.shape","607bebc1":"X_PCA = StandardScaler().fit_transform(X)\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(X_PCA)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])","192e5ab8":"pca.explained_variance_ratio_","896726ec":"y_PCA = y.reset_index(drop=True)\ny_PCA.head()","d110d3d4":"finalDf = pd.concat([principalDf, y_PCA ], axis = 1)","de9ebb4b":"finalDf.head()","4f552d46":"# %matplotlib notebook\n%matplotlib inline\nfig = plt.figure(figsize = (10,7))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = y.unique().tolist()\ntargets = list(filter(lambda x: x!= 'None', targets))\ncolors = ['r', 'g', 'b', 'y', 'm', 'k', 'w', 'c', 'darkred', 'lime', 'dodgerblue', 'magenta', 'yellow' ]\nfor target, color in zip(targets,colors):\n    indicesToKeep = finalDf['label'] == target\n    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n               , finalDf.loc[indicesToKeep, 'principal component 2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nplt.show()","d2d83325":"clf = KNeighborsClassifier() \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nkf = KFold(n_splits=5, shuffle=True, random_state=25)\nscores = cross_val_score(clf, X, y, cv=kf)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() ))","94af434c":"clf.fit(X_train, y_train)\nprint(classification_report(y,clf.predict(X)))","a9c375ec":"cm = pd.DataFrame(confusion_matrix(y, clf.predict(X)), index=clf.classes_, columns=clf.classes_)\ncm","30e95fd4":"plt.figure(figsize=(20,12))\nsns.heatmap(cm, annot=True)\nplt.show()","d57f129c":"clf = RidgeClassifier( )\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nkf = KFold(n_splits=5, shuffle=True, random_state=25)\nscores = cross_val_score(clf, X, y, cv=kf)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() ))","864ec802":"clf.fit(X_train, y_train)\nprint(classification_report(y,clf.predict(X)))","44ac2fc5":"cm = pd.DataFrame(confusion_matrix(y, clf.predict(X)), index=clf.classes_, columns=clf.classes_)\ncm","7f040111":"plt.figure(figsize=(20,12))\nsns.heatmap(cm, annot=True)\nplt.show()","735d6152":"clf = RandomForestClassifier(n_estimators=100, n_jobs=3, class_weight='balanced')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nkf = KFold(n_splits=5, shuffle=True, random_state=25)\nscores = cross_val_score(clf, X, y, cv=kf)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() ))","1076890e":"clf.fit(X_train, y_train)\nprint(classification_report(y,clf.predict(X)))","07918333":"cm = pd.DataFrame(confusion_matrix(y, clf.predict(X)), index=clf.classes_, columns=clf.classes_)\ncm","b946f4b1":"plt.figure(figsize=(20,12))\nsns.heatmap(cm, annot=True)\nplt.show()","f0a98fa9":"clf = LogisticRegression(solver='lbfgs', n_jobs=-1, multi_class = 'auto', class_weight='balanced')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nkf = KFold(n_splits=5, shuffle=True, random_state=25)\nscores = cross_val_score(clf, X, y, cv=kf)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() ))","7637ce2d":"clf.fit(X_train, y_train)\nprint(classification_report(y,clf.predict(X)))","470319ba":"cm = pd.DataFrame(confusion_matrix(y, clf.predict(X)), index=clf.classes_, columns=clf.classes_)\ncm","3a810c1e":"plt.figure(figsize=(20,12))\nsns.heatmap(cm, annot=True)\nplt.show()","e8008f14":"clf = DecisionTreeClassifier(class_weight='balanced')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nkf = KFold(n_splits=5, shuffle=True, random_state=25)\nscores = cross_val_score(clf, X, y, cv=kf)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() ))","6999cff7":"clf.fit(X_train, y_train)\nprint(classification_report(y,clf.predict(X)))","231f9820":"cm = pd.DataFrame(confusion_matrix(y, clf.predict(X)), index=clf.classes_, columns=clf.classes_)\ncm","cfa6ecb6":"plt.figure(figsize=(20,12))\nsns.heatmap(cm, annot=True)\nplt.show()","d3ff3a99":"# PCA - Data visualization","a3b734dc":"### Classification Report","53f17588":"# Classifaction models ","67089ddb":"* High accuracy classification report.\n* **Confusion matrix:** high accuracy, some confusion between None(none of the devices is on) and some devices.\n* Although imbalanced data - accuracy is high for unbalanced devices - small confusion between kitchen counter, Light and kitchen light with dimmer - this is resolved if train on variable percentage of dimmer lights,some confusion between stove and oven.\n* Heatmap plot based on the confusion matrix dataframe. ","af719112":"## Logistic Regression Classifier","a1743ce9":"# Random Forest Classifier","7c40564c":"### Classification Report","4d9c3597":"* PCA - Principal Component Analysis. Analysis through linear dimensionality reduction to two dimensions in order to enable a 2D plot.\n\n* principalDf is constructed dataframe of principal Components, two components as columns of data representing components 1,2.\n\n* pca.explained_variance_ratio_ is vector of percentile variance contained at each component.\n\n* finalDf is a dataframe with 2 principal components that are two linear combinations of the physically meaningful components with class identifier of electric component (stove, dishwasher...) such that the two primary components are the most significant information carriers of model.\n\n* plot a figure of the two components.\n\n* targets is target y vector unique identifiers turned into a list.\n\n* each target electric device class is scatter plotted with components 1,2 as coordinates.","31c485cc":"## Electrical features:","59285053":"using sklearn function - train_test_split(X, y, test_size=0.3) Split arrays or matrices into random train and test subsets. \n\ntest dataset size is 30% of X\n\nKFold is for cross-validation. split the X, y into n_splits=5 segments to avoid overfitting of training\nn segments constructing the test dataset are embedded separately into training dataset\nclf.fit fits with KNN clasifier the X_train vector to the y_train outcome","9bf93592":"### Confusion Matrix","e39b988e":"* **value_counts Return a Series containing counts of unique values - how many records of electric device of any class.**\n\n* **bar plot of instants count of every electric device within the target vector y.**\n","02d20b1c":"### Confusion Matrix","ed541546":"### Confusion matrix heatmap","dc91c42b":"# Functions:","56159f18":"### Confusion matrix heatmap","908b7bba":"## Phases data","e369bb57":"# Unbalanced data","f4856304":"* **X** - input array is contain electrical features and white noise data.\n* **y** - is target class: electric load - dishwasher, lamp, stove...","56ca868e":"### Confusion matrix heatmap","b1698b72":"### Classification Report","e0785434":"### Classification Report","9d10f202":"## White noise data","e358af7e":"### Confusion matrix heatmap","164e751a":"### Confusion Matrix","5a4bbf60":"# Ridge Classifier","ccab8f39":"### Confusion matrix heatmap","bb319976":"### Classification Report","55181400":"### Confusion Matrix","19539801":"# Decision Tree Classifier","287e6b1e":"* **I1_real:** is real component of current harmonic (I) of first phase (1) as recorded from one of the apartments it indicates active current component - the current invested at work: entire power is consumed at load - resistive component.\n\n\n* **I1_imag:** is imaginary component of current harmonic (I) of first phase (1) as recorded from one of the apartments it indicates reactive current component - the current invested at work: entire power is consumed at load- capacitive\/inductive component.\n\n\n* **I1_app:** is apparent power - it represents the entire power S^2=P^2+Q^2 where I1_app=SQRT(I1_real^2+I1_imag^2).\n\n\n* **I1_pf:** is power factor angle component - PF=P\/Q, PF=I1_real\/I1_imag.\n\n\n* **I2:** is same as I1 except for 2nd phase.\n\n\n* **hf_data:** spectrogram of high frequency noise captured in the home.\n\n\n* **y:** is target result indicating the device class: stove, dishwasher, lamp.","f961f1ad":"* Random Forest classifier with cross-validation.\n* Notice: using hyper parameter class_weight to deal with the unbalanced data. \n* Accuracy modification is small downwards by 0.1%.\n* Confusion non diagonal components rise a little bit.","a94acddd":"### Confusion Matrix","b104df2d":"# KNN Classifier"}}