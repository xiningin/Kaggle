{"cell_type":{"adda7b2a":"code","982fa4b7":"code","206e0d22":"code","09e64a90":"code","dc58a27a":"code","608e7400":"code","961aedbc":"code","a14e5a37":"code","8a8083b2":"code","e5730115":"code","39e12cc0":"code","1e925711":"code","6e74eca5":"code","088d2424":"code","b53a4f4a":"code","620dd3bd":"code","e20c60c0":"code","760c3bc4":"code","5b6135f3":"code","9325f9c9":"markdown"},"source":{"adda7b2a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nimport tensorflow as tf\nimport keras","982fa4b7":"print('tf version:',tf.__version__,'\\n' ,'keras version:',keras.__version__,'\\n' ,'numpy version:',np.__version__)","206e0d22":"# read the data file\nsolarpower = pd.read_csv(\"..\/input\/solarpanelspower\/PV_Elec_Gas3.csv\",header = None,skiprows=1 ,\n                    names = ['date','cum_power','Elec_kW', 'Gas_mxm'], sep=',',usecols = [0,1,2,3],\n                     parse_dates={'dt' : ['date']}, infer_datetime_format=True,index_col='dt')\nprint(solarpower.head(2))","09e64a90":"# make cum_power stationary\n\nsolarpower2 = solarpower.shift(periods=1, freq='D', axis=0)\nsolarpower['cum_power_shift'] = solarpower2.loc[:,'cum_power']\nsolarpower['day_power'] = solarpower['cum_power'].values - solarpower['cum_power_shift']\nsolarpower.iloc[0:1].day_power.value = 0.\nA = solarpower.dropna()\ndel A['cum_power'], A['cum_power_shift']\nsolarpower = A","dc58a27a":"X_train = solarpower[:'2018-10-28']\nX_valid = solarpower['2018-10-29':'2019-10-28'] # is 365 days\nX_train.shape, X_valid.shape","608e7400":"# we devide the series into multiple input and output patterns\n\ndef my_split_window(array, y_series, window_in, window_out):\n    '''\n    the Pandas dataframe is split into output sequences of length window_in and \n    output sequences of lenght window_out\n    returns arrays X, y\n    '''\n    X = []\n    y = []\n    n_steps = array.shape[0] - window_in + 1\n    #print('n_steps', n_steps)\n    for step in range(n_steps):\n        if (step + window_in + window_out -1) > (len(y_series)):\n            break\n        X_w = []\n        for i in range(window_in):\n            X_w.append(array[i+step])\n            y_w = []\n            for j in range(window_out):\n                n = i + j + step\n                y_w.append(y_series[n])\n        X_w = np.array(X_w)\n        X.append(X_w)\n        y_w = np.array(y_w)\n        y.append(y_w)   \n    X = np.array(X)\n    y = np.array(y)\n    return X, y","961aedbc":"# adding a feature with simple feature engineering\n\nX_train = X_train.copy()\nX_valid = X_valid.copy()\nX_train['Gas_plus_Elek'] = X_train.Gas_mxm + X_train.Elec_kW\nX_valid['Gas_plus_Elek'] = X_valid.Gas_mxm + X_valid.Elec_kW","a14e5a37":"# apply my_split_window on daily solar power with a window of 365 days (we do not make account for leap years)\n# the input series is the daily solar power\n\nwindow_in = 365\nwindow_out = 365\nfeatures = ['Elec_kW', 'Gas_mxm', 'Gas_plus_Elek']\ny_series = X_train.day_power.values\nX, y = my_split_window(np.array(X_train[features]) , y_series ,  window_in, window_out)\nprint('X.shape', X.shape, 'y.shape', y.shape)\n# print a sample\nfor i in range(2):\n    print(X[i][-2:], y[i][-2:])","8a8083b2":"print('X.shape', X.shape)","e5730115":"# vector output model:\n# model for univariate series input and prediction of  timestep vector\n# we have an input shape = (number of windows, window_in) \n#  and we have a window size of one year (365 days)\n# the output vector is of shape(number of window_out)\n\nn_features = 3\n# define model\n\ndef cnn_model(window_in, n_features, filters=10):\n    visible = tf.keras.layers.Input(shape=(window_in, n_features))\n    cnn = tf.keras.layers.Conv1D(filters=filters, kernel_size=2, activation='relu')(visible)\n    cnn = tf.keras.layers.MaxPool1D(pool_size=2)(cnn)\n    cnn = tf.keras.layers.BatchNormalization()(cnn)\n    cnn = tf.keras.layers.Dense(window_out, activation='relu')(cnn)\n    cnn = tf.keras.layers.Dropout(0.2)(cnn)\n    cnn = tf.keras.layers.Conv1D(filters=filters ,kernel_size=2, activation='relu')(cnn)\n    cnn = tf.keras.layers.MaxPool1D(pool_size=2)(cnn)\n    cnn = tf.keras.layers.Flatten()(cnn)\n    cnn = tf.keras.layers.BatchNormalization()(cnn)\n    cnn = tf.keras.layers.Dense(window_out, activation='relu')(cnn)\n    cnn = tf.keras.layers.Dropout(0.2)(cnn)\n    return visible, cnn\n\nvisible1, cnn1 = cnn_model(window_in, n_features, filters=1)\nvisible2, cnn2 = cnn_model(window_in, n_features, filters=2)\nvisible3, cnn3 = cnn_model(window_in, n_features, filters=3)\nvisible4, cnn4 = cnn_model(window_in, n_features, filters=4)\nvisible5, cnn5 = cnn_model(window_in, n_features, filters=5)\nvisible6, cnn6 = cnn_model(window_in, n_features, filters=6)\n\n\nmerge = tf.keras.layers.concatenate([cnn1, cnn2, cnn3, cnn4, cnn5, cnn6])\ndense = tf.keras.layers.Dense(window_out, activation='relu')(merge)\noutput = tf.keras.layers.Dense(window_out)(merge)\nmodel = tf.keras.Model(inputs=[visible1,visible2, visible3, visible4,visible5, visible6], outputs = output)\n\n# compile the model:\nmodel.compile(optimizer='adam', loss='mae')\n\n# fit model\nhistory = model.fit([X, X , X, X, X, X], y, epochs=10, verbose=1)\n\n# graph of the loss shows convergence\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title('loss')\nplt.xlabel('epochs')\nplt.show()","39e12cc0":"# predicting next year on X_train last year \n# the model expects an input of shape(1, window_in, n_features  )\nX_input = np.array(X_train[features][-365:].values)\nX_input = X_input.reshape(1, window_in, n_features)\n\ny_hat = model.predict([X_input, X_input, X_input, X_input, X_input, X_input], verbose=0)","1e925711":"# plot predicted an true values\nplt.plot(y_hat[0], label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","6e74eca5":"# print relevant scores\nfirst_r2_score = r2_score(y_true, y_hat[0]) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true, y_hat[0])\nprint('r2_score %.5f' % first_r2_score)\nprint('mae %.2f' % first_mae)","088d2424":"def cumulate(series, start=0):\n    '''\n    start is the starting cumulative power, the series is the daily solar power\n    a list with daily cumulative power is the result\n    '''\n    cum = [start]\n    for i in range(len(series)):\n        sum_plus = cum[i] + series[i]\n        cum.append(sum_plus)\n    return cum","b53a4f4a":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_hat[0])\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","620dd3bd":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)\/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))","e20c60c0":"# train more\n\n# fit model\nhistory = model.fit([X,X,X,X,X,X], y, epochs=10000, verbose=0)\n\n# graph of the loss shows convergence\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title('loss')\nplt.xlabel('epochs')\nplt.show()\n\n\n# predicting next year on X_train last year \n# the model expects an input of shape(1, window_in, n_features  )\nX_input = np.array(X_train[features][-365:].values)\nX_input = X_input.reshape(1, window_in, n_features)\n\ny_hat = model.predict([X_input, X_input, X_input, X_input, X_input, X_input], verbose=0)","760c3bc4":"# plot the prediction and validation\nplt.plot(y_hat[0], label='predicted_power')\n\ny_true = X_valid.day_power.values[-365:]\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()\n\nfirst_r2_score = r2_score(y_true, y_hat[0]) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true, y_hat[0])\nprint('r2_score %.5f' % first_r2_score)\nprint('mae %.2f' % first_mae)\n\ny_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_hat[0])\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","5b6135f3":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)\/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))","9325f9c9":"\nThis notbook uses :\ntf version: 2.0.0-beta1 ; keras version: 2.2.4 ; numpy version: 1.16.4 "}}