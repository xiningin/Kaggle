{"cell_type":{"81666f99":"code","eff9d309":"code","852b6aac":"code","6a5f73f6":"code","9374295b":"code","7b928c3e":"code","56876598":"code","ee3a7cd6":"code","9c2ccdd8":"code","a9924676":"code","60cadd68":"markdown","0c38a575":"markdown","be11f8b5":"markdown","57b0b850":"markdown"},"source":{"81666f99":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nimport skimage.io\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torchvision\nfrom torchvision import models, transforms\n\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nimport time\nimport copy\n\nfrom PIL import Image","eff9d309":"# Require compose objects\ndata_transforms = {\n    'train': transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n                                 transforms.RandomVerticalFlip(p=0.5),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                      std=[0.229, 0.224, 0.225])]),\n    'test': transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                     std=[0.229, 0.224, 0.225])])\n}\n\ndef get_transforms(*, data):\n    \n    assert data in ('train', 'valid')\n    \n    if data == 'train':\n        return Compose([\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    \n    elif data == 'valid':\n        return Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","852b6aac":"class TrainDataset(Dataset):\n    def __init__ (self, image_id, labels, transform=None):\n        self.image_id = image_id\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_id)\n    \n    def __getitem__(self, idx):\n#         Creating the image\n        name = self.image_id[idx]\n        file_names = [f\"..\/input\/panda-16x128x128-tiles-data\/train\/{name}_{i}.png\" for i in range(16)]\n        image_tiles = skimage.io.imread_collection(file_names, conserve_memory=True)\n        image_tiles = cv2.hconcat([cv2.vconcat([image_tiles[0], image_tiles[1], image_tiles[2], image_tiles[3]]),\n                                   cv2.vconcat([image_tiles[4], image_tiles[5], image_tiles[6], image_tiles[7]]),\n                                   cv2.vconcat([image_tiles[8], image_tiles[9], image_tiles[10], image_tiles[11]]),\n                                   cv2.vconcat([image_tiles[12], image_tiles[13], image_tiles[14], image_tiles[15]])])\n#         image_tiles = cv2.cvtColor(image_tiles, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image_tiles = Image.fromarray(image_tiles)\n            image_tiles = self.transform(image_tiles)\n#         Creating the label\n        label = self.labels[idx]\n        label = torch.tensor(label).float()\n#         Return image, and label\n        return image_tiles, label","6a5f73f6":"class TestDataset(Dataset):\n    def __init__ (self, image_id, dir_name=None, transform=None):\n        self.image_id = image_id\n        self.dir_name = dir_name\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_id)\n    \n    def __getitem__(self, idx):\n#         Creating the image\n        name = self.image_id[idx]\n        file_names = [f\"..\/panda-16x128x128-tiles-data\/train\/{name}_{i}.png\" for i in range(16)]\n        image_tiles = skimage.io.imread_collection(file_names, conserve_memory=True)\n        image_tiles = cv2.hconcat([cv2.vconcat([image_tiles[0], image_tiles[1], image_tiles[2], image_tiles[3]]),\n                                   cv2.vconcat([image_tiles[4], image_tiles[5], image_tiles[6], image_tiles[7]]),\n                                   cv2.vconcat([image_tiles[8], image_tiles[9], image_tiles[10], image_tiles[11]]),\n                                   cv2.vconcat([image_tiles[12], image_tiles[13], image_tiles[14], image_tiles[15]])])\n#         image_tiles = cv2.cvtColor(image_tiles, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image_tiles = Image.fromarray(image_tiles)\n            image_tiles = self.transform(image_tiles)\n#         Return image\n        return image_tiles ","9374295b":"def train_model(model, criterion, optimizer, scheduler, num_epochs=8, bs=5):\n#     Time tracking and saving model weights and accuracies\n    time_start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    train_dataset = TrainDataset(X_train, y_train, transform=data_transforms['train'])\n    test_dataset = TrainDataset(X_test, y_test, transform=data_transforms['test'])\n    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n    \n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}')\n        \n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train()\n                dataloader = train_loader\n            else:\n                model.eval()\n                dataloader = test_loader\n                \n            running_loss = 0.0\n            running_corrects = 0\n            \n            for inputs, labels in dataloader:\n                inputs = inputs.to(device)\n                labels = labels.to(device=device, dtype=torch.int64)\n                \n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):    \n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                \n                    if phase == 'train':\n                        loss.backward(retain_graph=False)\n                        optimizer.step()\n                        \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n#             if phase == 'train':\n#                 scheduler.step()\n                \n            if phase == 'train':\n                epoch_loss = running_loss \/ len(train_dataset)\n                epoch_acc = running_corrects.double() \/ len(train_dataset)\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            else:\n                epoch_loss = running_loss \/ len(test_dataset)\n                epoch_acc = running_corrects.double() \/ len(test_dataset)\n                scheduler.step(epoch_acc)\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n                \n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n        print(f\"Time: {(time.time()-time_start) \/\/ 60,} minutes and {(time.time()-time_start) % 60} seconds\")\n        print()\n    time_taken = time.time() - time_start\n    print(f'Training completed in {time_taken \/\/ 60,} minutes and {time_taken % 60} seconds')\n    print(f\"Best Val Accuracy: {best_acc}\")\n                \n    model.load_state_dict(best_model_wts)\n    return model ","7b928c3e":"class config:\n    debug=False\n    seed=101","56876598":"train = pd.read_csv(\"..\/input\/panda-train-csv-with-file-check\/train_with_file_check.csv\", index_col='Unnamed: 0')\nprint(train.shape)\ntrain = train.query(\"has_file == True\")\nprint(train.shape)\n\nif config.debug:\n    train = train.sample(150, random_state=config.seed, axis=0)\n    \nprint(train.shape)\n\nX = train['image_id']\ny = train['isup_grade']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=config.seed)\n# Reseting Index\nX_train.reset_index(drop=True, inplace=True)\nX_test.reset_index(drop=True, inplace=True)\ny_train.reset_index(drop=True, inplace=True)\ny_test.reset_index(drop=True, inplace=True)","ee3a7cd6":"# Device (sending our model, inputs, labels to either cuda or cpu)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Changing out_features\nmodel = torch.hub.load('facebookresearch\/semi-supervised-ImageNet1K-models', 'resnext50_32x4d_swsl')\n# model = models.resnet50(pretrained=True)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 6)\nmodel = model.to(device)\n\n# Other modules\n# optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\noptimizer_ft = optim.Adam(model.parameters(), lr=0.001)\nexp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.5, patience=3)\n\ncriterion = nn.CrossEntropyLoss()","9c2ccdd8":"# 10516, batch_size=16\ntrain_model(model, criterion, optimizer_ft, exp_lr_scheduler, \n           num_epochs=25,\n           bs=20)","a9924676":"# Saving Model\ntorch.save({\n    'epoch': 25,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer_ft.state_dict()\n}, \"..\/working\/resnext_50_sw_10500_6hours_Adam_Plateua.tar\")\n\ntorch.save(model, \"resnext_50_sw_10500_6hours_Adam_Plateua.pth\")","60cadd68":"## Definging Transforms","0c38a575":"## Dataset and Dataloaders","be11f8b5":"## Running Model","57b0b850":"## Model Training "}}