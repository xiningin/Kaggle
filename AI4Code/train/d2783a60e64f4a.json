{"cell_type":{"0e9d50a6":"code","f4aa4a9a":"code","df5873f2":"code","65cacf15":"code","3577be93":"code","f74663a2":"code","b447fb1d":"code","bbd59106":"code","d8e16c43":"code","2dddae8e":"markdown","f1de4056":"markdown","b335902a":"markdown","dbbe3ccf":"markdown","0c3ae50e":"markdown"},"source":{"0e9d50a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4aa4a9a":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import log_loss\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression","df5873f2":"train_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\ns_submission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')","65cacf15":"def average_log_loss(y_true, y_pred):\n    print(y_true.shape, y_pred.shape)\n    num_samples, num_outputs = y_true.shape\n    loss = 0.00\n    for i in range(num_outputs):\n        loss += log_loss(y_true[:, i], y_pred[:, i], labels=[0, 1])\n    loss \/= num_outputs\n    return loss","3577be93":"def preprocess(df):\n    df = df.drop(columns=['sig_id'])\n    df.cp_dose = df.cp_dose.map({'D1': -1, 'D2': 1})\n    df.cp_time = df.cp_time.map({24: -1, 48: 0, 72: 1})\n    df.cp_type = df.cp_type.map({'trt_cp': -1, 'ctl_vehicle': 1})\n    return df","f74663a2":"train_features = preprocess(train_features)\ntrain_targets_scored = train_targets_scored.drop(columns=['sig_id'])\ntest_features = preprocess(test_features)\n\ntargets_np = train_targets_scored.to_numpy()","b447fb1d":"g_cols = [col for col in train_features.columns if col.startswith('g-')]\nc_cols = [col for col in train_features.columns if col.startswith('c-')]\ncp_cols = [col for col in train_features.columns if col.startswith('cp_')]\n\ndef scaler_and_PCA(pca_num_components, train, test):\n    data = np.concatenate((train, test), axis=0)\n    n = train.shape[0]\n    \n    # variance threshold\n    selector = VarianceThreshold(threshold=0.8)\n    data = selector.fit_transform(data)\n    \n    # scale\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n\n    # PCA\n    pca = PCA(pca_num_components)\n    pca_data = pca.fit_transform(scaled_data)\n\n    train_trans = pca_data[:n, :]\n    test_trans = pca_data[n:, :]\n\n    return train_trans, test_trans\n\n\n# For columns \"g-\"\ntrain_X_g = train_features[g_cols].to_numpy()\ntest_X_g = test_features[g_cols].to_numpy()\ntrain_X_g, test_X_g = scaler_and_PCA(80, train_X_g, test_X_g)\n\n# For columns \"c-\"\ntrain_X_c = train_features[c_cols].to_numpy()\ntest_X_c = test_features[c_cols].to_numpy()\ntrain_X_c, test_X_c = scaler_and_PCA(20, train_X_c, test_X_c)\n\nfeatures_np = np.concatenate((train_features[cp_cols].to_numpy(), train_X_g, train_X_c), axis=1)\ntest_np = np.concatenate((test_features[cp_cols].to_numpy(), test_X_g, test_X_c), axis=1)\nprint('Shape after scaler and PCA', features_np.shape)","bbd59106":"best_model = None\nbest_loss = 999999999999999999\nkf = KFold(n_splits=5)\nj = 1\nfor train_indices, val_indices in kf.split(features_np):\n    X_train, Y_train = features_np[train_indices, :], targets_np[train_indices, :]\n    X_val, Y_val = features_np[val_indices, :], targets_np[val_indices, :]\n\n    all_categories = list(train_targets_scored.columns)\n    model_dict = {}\n    print('FIT')\n    for i in tqdm(range(206)):\n        if Y_train[:, i].max() == 0:\n            # use last model\n            model_dict[all_categories[i]] = logistic_model\n        else:\n            logistic_model = LogisticRegression(C=0.1, max_iter=1000, class_weight={0: 0.4, 1: 0.6})\n            logistic_model.fit(X_train, Y_train[:, i])\n            # saving model\n            model_dict[all_categories[i]] = logistic_model\n    print('PREDICT')\n    Y_pred = np.zeros(Y_val.shape)\n    i = 0\n    for category in tqdm(all_categories):\n        Y_pred[:, i] = np.copy(model_dict[category].predict_proba(X_val)[:, 1])\n        i += 1\n    print('VALIDATE')\n    cur_loss = average_log_loss(Y_val, Y_pred)\n    print('Log_loss', j, cur_loss)\n    if cur_loss < best_loss:\n        best_model = model_dict\n        best_loss = cur_loss\n    j += 1\n\nprint('Best loss is:', best_loss)","d8e16c43":"Y_res = s_submission.drop(columns=['sig_id']).to_numpy()\ni = 0\nall_categories = list(train_targets_scored.columns)\nprint('PREDICT RESULT')\nfor category in tqdm(all_categories):\n    Y_res[:, i] = np.copy(best_model[category].predict_proba(test_np)[:, 1])\n    i += 1\n# POSTPROCESS\nfor i in range(test_np.shape[0]):\n    if test_np[i][0] == 1:\n        Y_res[i, :] = np.zeros(Y_res.shape[1])\ns_res = pd.DataFrame(Y_res, columns=all_categories)\ns_res = pd.concat([s_submission['sig_id'], s_res], axis=1)\ns_res.to_csv('submission.csv', index=False)","2dddae8e":"Preprocessing","f1de4056":"Predict result","b335902a":"Cross Validation Logistic Regression","dbbe3ccf":"Log_loss metric","0c3ae50e":"Scaler and transform"}}