{"cell_type":{"dd2abb6f":"code","91430bef":"code","b89eef01":"code","74019993":"code","b3f32b36":"code","286dbc71":"code","538ce8c0":"code","160f0b90":"code","ca0e7e74":"code","3b8c6cbb":"code","1564b1ee":"code","9601ef70":"code","3e47b05f":"code","7f77ce01":"code","1374266c":"code","8dc29f3d":"code","43f2eab9":"code","03e4c3d1":"code","bd198a9f":"code","1a00f91d":"code","3683c629":"code","8c498246":"code","e8c7047e":"code","1e0a39d7":"code","16593838":"code","1a4ae86f":"code","858d9e3b":"code","82745fd0":"code","bbd17963":"code","7d7ee20c":"code","d402413f":"code","5d57eded":"code","d18400a2":"code","3a4ae928":"code","63a80dd5":"code","282669c1":"code","7dc133c6":"code","ba3a3c59":"code","08a60c9f":"code","27af7718":"code","1a32d7c2":"code","f5996137":"code","3732f3f1":"code","ff31ff63":"code","e2ac7c19":"code","b91073ce":"code","6e4fd7c6":"code","65f91fd9":"code","bb51d8d3":"code","49ea51eb":"code","ef451c33":"markdown","eb745773":"markdown","a4180006":"markdown","36ccf606":"markdown","d1a560f9":"markdown","f298cffd":"markdown","4e20d698":"markdown","19ba910a":"markdown","5231dc54":"markdown","bd8df52c":"markdown","08f0b809":"markdown","db974927":"markdown","9225272b":"markdown","e4d2eae1":"markdown","d79e12cf":"markdown","478bf9be":"markdown","6c466eee":"markdown","617fc709":"markdown","c7c65d06":"markdown","d878ff8a":"markdown","321857c3":"markdown","d009beaa":"markdown","9c53296c":"markdown","6e32612e":"markdown","993e4c1b":"markdown","f09bd1fc":"markdown","2e7e1585":"markdown","5bd99b44":"markdown","5e07f64a":"markdown","152587e4":"markdown","7eb40173":"markdown","ad5bb8b8":"markdown"},"source":{"dd2abb6f":"import numpy as np \nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer","91430bef":"# Dados de treino e de teste oferecidos na atividade.\n\ntrain = pd.read_csv('..\/input\/task-04\/training_data.csv')\ntest = pd.read_csv('..\/input\/task-04\/test_data_without_label.csv')","b89eef01":"train.sample(10)","74019993":"train.head()","b3f32b36":"train.shape","286dbc71":"train.info()","538ce8c0":"print(train.isnull().sum())","160f0b90":"# Fun\u00e7\u00e3o de pre-processamento dos dados de treino\ndef pre_clean_dataset(tratamento):\n    \n    # remo\u00e7\u00e3o de colunas\n    df_temp = tratamento.copy()\n    df_temp.drop(['num_atend'],axis=1,inplace=True)\n    df_temp.drop(['respiracao'],axis=1,inplace=True)\n\n    # aplica\u00e7\u00e3o de filtros\n    df_temp.loc[df_temp.temperatura>42,'temperatura']=np.nan\n    df_temp.loc[df_temp.temperatura<=32,'temperatura']=np.nan    \n    df_temp.loc[df_temp.pulso>200, 'pulso']=np.nan\n    df_temp.loc[df_temp.pulso<=20, 'pulso']=np.nan\n    df_temp.loc[df_temp.pa_min<=60,'pa_min']=np.nan\n    df_temp.loc[df_temp.pa_min>200,'pa_min']=np.nan\n    df_temp.loc[df_temp.pa_max<=60,'pa_max']=np.nan\n    df_temp.loc[df_temp.pa_max>200,'pa_max']=np.nan\n   \n    # Imputer por K-NN\n    imp_median = KNNImputer(missing_values=np.nan, weights = 'distance', n_neighbors = 3)\n    imp_median.fit(df_temp)\n    \n    # transforma\u00e7\u00e3o a partir do objeto KNNImputer\n    trat = imp_median.transform(df_temp)\n    \n    n_df = pd.DataFrame(trat)\n    \n    # devolu\u00e7\u00e3o das colunas de interesse ao dataframe\n    n_df.columns = ['id', 'temperatura', 'pulso', 'pa_min', 'pa_max', 'sepse']\n    \n    \n    return n_df","ca0e7e74":"trat = pre_clean_dataset(train)\nn_train = pd.DataFrame(trat)\nn_train.head(10)","3b8c6cbb":"n_train.sample(10)","1564b1ee":"n_train.shape","9601ef70":"n_train.info()","3e47b05f":"print(n_train.isnull().sum())","7f77ce01":"print(\"Temperatura \\nm\u00e1xima: \", n_train['temperatura'].max())\nprint(\"m\u00ednima: \", n_train['temperatura'].min())\nprint(\"\\n\\n\\nPulso \\nm\u00e1ximo: \", n_train['pulso'].max())\nprint(\"m\u00ednimo: \", n_train['pulso'].min())\nprint(\"\\n\\n\\nPress\u00e3o max \\nm\u00e1xima\", n_train['pa_max'].max())\nprint(\"m\u00ednima: \", n_train['pa_max'].min())\nprint(\"\\n\\n\\nPress\u00e3o min \\nm\u00e1xima\", n_train['pa_min'].max())\nprint(\"m\u00ednima: \", n_train['pa_min'].min())","1374266c":"# estilo de plot ggplot\nplt.style.use('ggplot')\n\nplt.figure(figsize=(10, 10))\nsns.catplot(data=n_train, x = 'sepse', kind = \"count\", palette = 'viridis').set_xticklabels(['0-NS', '1-S'], fontsize = 12)\nplt.xlabel('Diagn\u00f3stico', fontsize = 14)\nplt.ylabel('Ocorr\u00eancia', fontsize = 14)\nplt.title('Detec\u00e7\u00e3o de S\u00e9pse', fontsize = 16)\nplt.show()\nplt.show(True)","8dc29f3d":"plt.figure(figsize=(20, 8))\nsns.histplot(data=n_train, x = 'temperatura',hue = 'sepse', palette = 'magma')\nplt.title(\"Histograma para a temperatura dividindo-se por resultado de diagn\u00f3stico (frequ\u00eancias empilhadas)\")\nplt.show(True)","43f2eab9":"plt.figure(figsize=(15, 7))\nsns.histplot(data=n_train, x = 'pa_max',hue = 'sepse', multiple=\"stack\", palette = 'viridis')\nplt.title(\"Histograma para a press\u00e3o m\u00e1xima dividindo-se por resultado de diagn\u00f3stico (frequ\u00eancias empilhadas)\")\nplt.show(True)","03e4c3d1":"plt.figure(figsize=(15, 7))\nsns.histplot(data=n_train, x = 'pa_min',hue = 'sepse', multiple=\"stack\", palette = 'viridis')\nplt.title(\"Histograma para a press\u00e3o m\u00ednima dividindo-se por resultado de diagn\u00f3stico (frequ\u00eancias empilhadas)\")\nplt.show(True)","bd198a9f":"plt.figure(figsize=(15, 7))\nsns.histplot(data=n_train, x = 'pulso', hue = 'sepse', multiple=\"stack\", palette = 'viridis')\nplt.title(\"Histograma para o pulso dividindo-se por resultado de diagn\u00f3stico (frequ\u00eancias empilhadas)\")\nplt.show(True)","1a00f91d":"plt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train[n_train[\"sepse\"]==1], x =\"pulso\", y=\"temperatura\", palette = 'viridis')\nplt.title(\"Gr\u00e1fico de dispers\u00e3o temperatura X pulso para pacientes que apresentaram sepse\")\nplt.show(True)\nplt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train, x=\"pulso\", y=\"temperatura\", hue=\"sepse\", palette = 'viridis', size = 'sepse', sizes=(150, 40))\nplt.title(\"Gr\u00e1fico de dispers\u00e3o temperatura X pulso considerando-se o diagn\u00f3stico\")\nplt.show(True)","3683c629":"plt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train[n_train[\"sepse\"]==1],  x=\"pulso\", y=\"pa_max\", palette = 'viridis')\nplt.title(\"Gr\u00e1fico de dispers\u00e3o press\u00e3o m\u00e1xima X pulso para pacientes que apresentaram sepse\")\nplt.show(True)\nplt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train, x=\"pulso\", y=\"pa_max\", hue=\"sepse\", palette = 'viridis', size = 'sepse', sizes=(150, 40))\nplt.title(\"Gr\u00e1fico de dispers\u00e3o press\u00e3o m\u00e1xima X pulso considerando-se o diagn\u00f3stico\")\nplt.show(True)","8c498246":"plt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train[n_train[\"sepse\"]==1], x=\"pulso\", y=\"pa_min\", palette = 'viridis')\nplt.title(\"Gr\u00e1fico de dispers\u00e3o press\u00e3o m\u00ednima X pulso para pacientes que apresentaram sepse\")\nplt.show(True)\nplt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train, x=\"pulso\", y=\"pa_min\", hue=\"sepse\", palette = 'viridis', size = 'sepse', sizes=(150, 40))\nplt.title(\"Gr\u00e1fico de dispers\u00e3o press\u00e3o m\u00ednima X pulso considerando-se o diagn\u00f3stico\")\nplt.show(True)","e8c7047e":"plt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train[n_train[\"sepse\"]==1], x=\"pa_min\", y=\"pa_max\", palette = 'viridis')\nplt.title(\"Gr\u00e1fico de dispers\u00e3o press\u00e3o m\u00e1xima X press\u00e3o m\u00ednima para pacientes que apresentaram sepse\")\nplt.show(True)\nplt.figure(figsize=(15, 7))\nsns.scatterplot(data=n_train, x=\"pa_min\", y=\"pa_max\", hue=\"sepse\", palette = 'viridis', size = 'sepse', sizes=(150, 40))\nplt.title(\"Gr\u00e1fico de dispers\u00e3o press\u00e3o m\u00e1xima X press\u00e3o m\u00ednima considerando-se o diagn\u00f3stico\")\nplt.show(True)","1e0a39d7":"np.matrix(n_train.iloc[:,1:5])","16593838":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\n\nX = np.matrix(n_train.iloc[:,1:5])\npca.fit(X)\n\nprint(np.round(pca.explained_variance_ratio_,6))\n\nPCA1 = pca.transform(X)[:,0]\nPCA2 = pca.transform(X)[:,1]\nn_train[\"Component 1\"] = PCA1\nn_train[\"Component 2\"] = PCA2\n\nn_train.head()","1a4ae86f":"pca.components_","858d9e3b":"plt.figure(figsize=(20, 7))\nsns.scatterplot(data=n_train[n_train[\"sepse\"]==1], x=\"Component 1\", y=\"Component 2\", palette = 'viridis')\nplt.xlim([-75,130])\nplt.ylim([-70,100])\nplt.title(\"Comportamento das duas componentes principais mais importantes em pacientes com sepse\")\nplt.show(True)\n\nplt.figure(figsize=(20, 7))\nsns.scatterplot(data=n_train[n_train[\"sepse\"]==0], x=\"Component 1\", y=\"Component 2\", palette = 'viridis')\nplt.xlim([-75,130])\nplt.ylim([-70,100])\nplt.title(\"Comportamento das duas componentes principais mais importantes em pacientes com sepse\")\nplt.show(True)\n\nplt.figure(figsize=(20, 7))\nsns.scatterplot(data=n_train, x=\"Component 1\", y=\"Component 2\", hue=\"sepse\", palette = 'viridis', \n                size = 'sepse', sizes=(150, 40))\nplt.xlim([-75,130])\nplt.ylim([-70,100])\nplt.title(\"Comportamento das duas componentes principais mais importantes\")\nplt.show(True)","82745fd0":"# Dados de treino e de teste oferecidos na atividade.\n\ntrain = pd.read_csv('..\/input\/task-04\/training_data.csv')\ntest = pd.read_csv('..\/input\/task-04\/test_data_without_label.csv')","bbd17963":"n_train = pre_clean_dataset(train)","7d7ee20c":"n_train.head(10)","d402413f":"n_train.sample(10)","5d57eded":"from sklearn.model_selection import train_test_split\n\n#Selecionando as colunas\ny = n_train.loc[:,'sepse'].to_numpy()\n\n#Variaveis que vamos usar para 'X'\ncolunas = [coluna for coluna in n_train.columns if coluna not in ['id','sepse']]\nX = n_train[colunas].to_numpy()\n\n#Para calcularmos o score\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 0.8, random_state=2112)","d18400a2":"from imblearn.over_sampling import SMOTE\n\noversampling = SMOTE(random_state = 2112)\nX_train_over, y_train_over = oversampling.fit_resample(X_train, y_train.ravel())","3a4ae928":"plt.figure(figsize=(10, 10))\nsns.catplot(data=n_train, x = 'sepse', kind = \"count\", palette = 'viridis').set_xticklabels(['0-NS', '1-S'], fontsize = 12)\nplt.xlabel('Diagn\u00f3stico', fontsize = 14)\nplt.ylabel('Ocorr\u00eancia', fontsize = 14)\nplt.title('Detec\u00e7\u00e3o de S\u00e9pse', fontsize = 16)\nplt.show()\nplt.show(True)\n\n\nplt.figure(figsize=(10, 10))\nsns.catplot(data=pd.DataFrame(y_train_over), x=0, kind = \"count\", \n            palette = 'viridis').set_xticklabels(['0-NS', '1-S'], fontsize = 12)\nplt.xlabel('Diagn\u00f3stico', fontsize = 14)\nplt.ylabel('Ocorr\u00eancia', fontsize = 14)\nplt.title('Detec\u00e7\u00e3o de S\u00e9pse (Treino oversampling)', fontsize = 16)\nplt.show(True)","63a80dd5":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n\nrf_pipeline = Pipeline(steps = [('scale',StandardScaler()),('RF',RandomForestClassifier(random_state=2112))])\n#xgboost_pipeline = Pipeline(steps = [('XGB',XGBClassifier(random_state=7, eval_metric='mlogloss'))])","282669c1":"print('M\u00e9dia de f1:')\nprint('M\u00e9dia Random Forest:',cross_val_score(rf_pipeline,X_train_over,y_train_over,cv=10,scoring='f1').mean())\n#print('M\u00e9dia XGBoost:',cross_val_score(xgboost_pipeline,X_train_over,y_train_over,cv=10,scoring='f1').mean())","7dc133c6":"print('M\u00e9dia de acur\u00e1cia:')\nprint('M\u00e9dia Random Forest:',cross_val_score(rf_pipeline,X_train_over,y_train_over,cv=10,scoring='accuracy').mean())\n#print('M\u00e9dia XGBoost:',cross_val_score(xgboost_pipeline,X_train_over,y_train_over,cv=10,scoring='accuracy').mean())","ba3a3c59":"# Modelo final\nrfc = RandomForestClassifier()\nrfc.fit(X_train_over, y_train_over)\nrfc_pred = rfc.predict(X_test)","08a60c9f":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import balanced_accuracy_score\n\nprint('Accuracy Score: ',accuracy_score(y_test,rfc_pred))\nprint('F1 Score: ',f1_score(y_test,rfc_pred))\nprint('Balanced Accuracy Score: ',balanced_accuracy_score(y_test,rfc_pred))","27af7718":"def pre_clean_dataset_test(tratamento):\n    \n    df_temp = tratamento.copy()\n    df_temp.drop(['num_atend'],axis=1,inplace=True)\n    df_temp.drop(['respiracao'],axis=1,inplace=True)\n\n    df_temp.loc[df_temp.temperatura>42,'temperatura']=np.nan\n    df_temp.loc[df_temp.temperatura<=32,'temperatura']=np.nan    \n    df_temp.loc[df_temp.pulso>200, 'pulso']=np.nan\n    df_temp.loc[df_temp.pulso<=20, 'pulso']=np.nan\n    df_temp.loc[df_temp.pa_min<=60,'pa_min']=np.nan\n    df_temp.loc[df_temp.pa_min>200,'pa_min']=np.nan\n    df_temp.loc[df_temp.pa_max<=60,'pa_max']=np.nan\n    df_temp.loc[df_temp.pa_max>200,'pa_max']=np.nan\n   \n\n    imp_median = KNNImputer(missing_values=np.nan, weights = 'distance', n_neighbors = 3)\n    imp_median.fit(df_temp)\n    \n    trat = imp_median.transform(df_temp)\n    \n    n_df = pd.DataFrame(trat)\n    \n    n_df.columns = ['id', 'temperatura', 'pulso', 'pa_min', 'pa_max']\n    \n    \n    return n_df","1a32d7c2":"n_test = pre_clean_dataset_test(test)","f5996137":"n_test.head()","3732f3f1":"ids = n_test['id']","ff31ff63":"n_test.drop(['id'],axis=1,inplace=True)","e2ac7c19":"y_pred = rfc.predict(n_test)","b91073ce":"y_pred = [int(i) for i in y_pred]\n\npred = pd.DataFrame(data = ids)\npred['sepse'] = list(y_pred)","6e4fd7c6":"pred","65f91fd9":"pred['id']=pd.to_numeric(pred['id'], downcast='integer')\npred['sepse']=pd.to_numeric(pred['sepse'], downcast='integer')","bb51d8d3":"pred","49ea51eb":"pred.to_csv(\"respostaFINAL.csv\", index=False)","ef451c33":"A fun\u00e7\u00e3o abvaixo trata os dados de teste da mesma forma que antes, mas est\u00e1 alterada por n\u00e3o h\u00e1 a cooluna sepse agora.","eb745773":"Abaixo, importam-se algumas bibliotecas que ser\u00e3o utilizadas na an\u00e1lise dos dados. ","a4180006":"Pesos atribu\u00eddos aos features pela t\u00e9cnica PCA.","36ccf606":"# Detec\u00e7\u00e3o de sepse","d1a560f9":"Submiss\u00e3o:","f298cffd":"\u00c9 importante perceber que os dados s\u00e3o extremamente desbalanceados. Isso ser\u00e1 importante para a an\u00e1lise futura, j\u00e1 que utiliz\u00e1-los diretamente em modelos de aprendizado de m\u00e1quina pode causar em vi\u00e9ses no sentido de grande ocorr\u00eancia de falsos negativos, ou seja, os modelos podem acabar se ajustando de forma que n\u00e3o consigam prever se um paciente apresenta sepse ou n\u00e3o. Voltaremos nessa quest\u00e3o mais adiante.","4e20d698":"E seus primeiros valores.","19ba910a":"Performemos alguns cross validation:","5231dc54":"## An\u00e1lise explorat\u00f3ria","bd8df52c":"As vari\u00e1veis est\u00e3o correlacionadas pelo resultado da explica\u00e7\u00e3o da vari\u00e2ncia. Mas n\u00e3o o suficiente para justificar a retiradq de mais features nesse momento, considerando-se os resultados at\u00e9 ent\u00e3o. Por\u00e9m, \u00e9 interessante notar como a componente principal 2 \u00e9 influenciada pelo seu coeficiente positivo em rela\u00e7\u00e3o \u00e0 caracter\u00edstica \"pulso\", sendoq que ela parece ser mais discriminante na identifica\u00e7\u00e3o de pacientes com sepse. Para melhor en tender os conceitos por tr\u00e1s do mecanismo do PCA, recomendamos as aulas da professora Dra. Cibele Russo, do Instituto de Ci\u00eancias Matem\u00e1ticas e de Computa\u00e7\u00e3o, as quais oferecem uma excelente explica\u00e7\u00e3o sobre o assunto. As aulas podem ser verificadas no [canal](https:\/\/www.youtube.com\/channel\/UCDIZ-7AE6IFe70UskD0GtUA) da professora.","08f0b809":"Ap\u00f3s esta breve an\u00e1lise, \u00e9 percept\u00edvel que a vari\u00e1vel \"pulso\" parece ser um feature importante na detec\u00e7\u00e3o de sepse, j\u00e1 que pacientes diagnosticados positivamente com sepse parecem apresentar maiores valores para tal em geral. Tamb\u00e9m \u00e9 percept\u00edvel, corroborando com a an\u00e1lise feita pelos histogramas, que valores extremos para \"press\u00e3o m\u00ednima\", \"press\u00e3o m\u00e1xima\" e \"temperatura\", parecem estar associadas \u00e0 sepse, j\u00e1 que a propor\u00e7\u00e3o entre pacientes com sepse e sem sepse parece aumentar conforme essas caracter\u00edsticas se extremizam.\n\nFa\u00e7amos um breve PCA para verificar correla\u00e7\u00f5es.","db974927":"Para completar nossa an\u00e1lise, fa\u00e7amos alguns gr\u00e1ficos de dispers\u00e3o.","9225272b":"Agora, estudemos o o comportamento dos dados a partir de uma investiga\u00e7\u00e3o explorat\u00f3ria, utilizando de fun\u00e7\u00f5es da biblioteca [seaborn](https:\/\/seaborn.pydata.org\/).","e4d2eae1":"\u00c9 not\u00f3rio que n\u00e3o podemos simplesmente remover todas as observa\u00e7\u00f5es que apresentam dados faltantes, j\u00e1 que perder\u00edamos quase a totalidade dos dados dispon\u00edveis, impedindo a formula\u00e7\u00e3o de um classificador com performance significativa. Apenas nos dados referentes \u00e0 respira\u00e7\u00e3o, temos mais de 13000 dados faltantes, e a perda de informa\u00e7\u00e3o que possivelmente ser\u00eda ut\u00edl, ficaria inevit\u00e1vel se simplemente removessemos tais dados. Assim sendo, tratemos os dados com a inten\u00e7\u00e3o de perder o m\u00ednimo de observa\u00e7\u00f5es poss\u00edvel.","d79e12cf":"## Treino de modelo\n\n\nAgora, iremos treinar um modelo Random Forest, o qual mostrou-se mais adequado nos testes desenvolvidos com o tretamento que foi feito.","478bf9be":"Podemos estruturar os dados de interesse em estruturas de DataFrame do Pandas.","6c466eee":"Temos tamb\u00e9m uma boa acur\u00e1cia para o modelo, considerando-se a m\u00e9dia do cross validation.","617fc709":"Agora, o banco de dados n\u00e3o apresenta mais observa\u00e7\u00f5es com caracter\u00edsticas NaN e podemos prosseguir com a an\u00e1lise, as quais foram ubstitu\u00eddas por um m\u00e9todo conveniente. Perceba que a fun\u00e7\u00e3o aplica os filtros **antes** de aplicar o KNNImputer. Isso \u00e9 importante pelo fato de que os novos valores poderiam, de alguma forma, ser influenciado por valores extremos, os quais n\u00e3o correspondem ao mecanismo probabil\u00edstico que gerou os dados (no caso, o mecanismo probabil\u00edstico est\u00e1 relacionado com os sintomas e sua rela\u00e7\u00e3o com a sepse).","c7c65d06":"Tratamento nos dados.","d878ff8a":"O tratamento de outliers ser\u00e1 necess\u00e1rio e, para tal, iremos aplicar alguns filtros. Aqui fazemos a aplica\u00e7\u00e3o de [filtros](https:\/\/cmdlinetips.com\/2018\/02\/how-to-subset-pandas-dataframe-based-on-values-of-a-column\/) veross\u00edmeis \u00e0 realidade para o caso estudado. Assim sendo, consideramos os seguintes filtros como veross\u00edveis ao contexto real dos dados:\n\n* Temperatura: entre 32 e 42 graus Celsius;\n* Pulso: entre 20 e 200;\n* Press\u00e3o M\u00ednima: entre 60 e 200;\n* Press\u00e3o M\u00e1xima: entre 60 e 200;\n\nOs dados referentes \u00e0 respira\u00e7\u00e3o foram removidos devido ao fato de muitos serem faltantes e o processo que faremos a seguir poderia ocasionar em dados n\u00e3o coerentes para este feature, viesando a an\u00e1lise.","321857c3":"A raz\u00e3o $r$ parece se comportar de forma aprecida para todas as vari\u00e1veis de interesse, o que nos diz que valores para os sinais vitais de interesse que se afastem da m\u00e9dia, s\u00e3o indicadores de maior probabilidade de ocorr\u00eancia de sepse, o que \u00e9 esperado, considerando-se que se trata de uma doen\u00e7a e o corpo responder\u00e1 de forma extrema \u00e0 ela.","d009beaa":"Obtenhamos alguns outros histogramas para as vari\u00e1veis de interesse.","9c53296c":"Analisando-se o histograma, observemos a raz\u00e3o dada por:\n\n$$r = \\frac{Nsepse}{sepse}$$\n\nSendo $sepse$ a contagem de ocorr\u00eancias de paientes com sepse e $Nsepse$ a contagem de ocorr\u00eancias de paientes sem sepse no banco de dados.\n\n\u00c9 not\u00f3rio que tal raz\u00e3o aumenta quando a temperatura se encontra em valores mais extremos (valores distantes do normal corporal de 36 graus celsius). Assim sendo, parece que temperaturas extremas est\u00e3o relacionadas com a ocorr\u00eancia de sepse.","6e32612e":"Vejamos algumas amostars dos dados de interesse.","993e4c1b":"Pode-se notar que a medida F1 foi consideravelmente satisfat\u00f3ria, o que \u00e9 um bom in\u00b4dicio de que o balanceamento deu certo.","f09bd1fc":"<br>\n<br>\n\u00c9 tamb\u00e9m not\u00f3rio que o tratamento com filtros removeu os outliers. Assim sendo, n\u00e3o ser\u00e3o desenvolvidos mais tratamentos nesse sentido. e partiremos para uma an\u00e1lise explorat\u00f3ria mais detalhada.","2e7e1585":"A primeira componente principal explica 51% da variabilidade dos dados, enquanto a segunda explica 39%.","5bd99b44":"Com tal ideia, a fun\u00e7\u00e3o abaixo foi criada. Nela retiramos os features que n\u00e3o ser\u00e3o usados (respiracao, por motivos j\u00e1 explicados e num_atend pelo fato de em an\u00e1lises anteriores, termos concluido que n\u00e3o parece haver correla\u00e7\u00e3o forte entre o n\u00famero de atendimento e o diagn\u00f3stico de sepse). Depois, os filtros mencionados anteriormente s\u00e3o aplicados e em cada observa\u00e7\u00e3o, as colunas que n\u00e3o respeitam o intervalo dos filtros s\u00e3o substitu\u00eddos por np.nan (identificador de NaN do numpy). Por fim, utilizamos da fun\u00e7\u00e3o KNNImputer do m\u00f3dulo sklearn, com par\u00e2metros testados, para aplicar valores previstos por aprendizado por K-NN nos dados faltantes. A documenta\u00e7\u00e3o de tal fun\u00e7\u00e3o pode ser encontrada [aqui](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.impute.KNNImputer.html).","5e07f64a":"Aqui, iremos utilizar uma t\u00e9cnica de oversampling da biblioteca imblearn com a fun\u00e7\u00e3o SMOTE, assim podemos tratar o desbalanceamento comentado anteriormente.","152587e4":"Podemos ver que o banaceamento foi feito com sucesso.","7eb40173":"\u00c9 not\u00f3rio que o banco de dados possui diversas informa\u00e7\u00f5es faltantes. Colunas como as de \"press\u00e3o m\u00e1xima\" e \"m\u00ednima\" est\u00e3o presentes em apenas aproximadamente metade das observa\u00e7\u00f5es e a caracter\u00edstica \"respira\u00e7\u00e3o\" possui tantos dados faltantes que talvez sua reconctru\u00e7\u00e3o seja invi\u00e1vel. Assim sendo, ser\u00e1 performado um pr\u00e9-processamento dos dados para que possamos utilizar do m\u00e1ximo das observa\u00e7\u00f5es fornecidas poss\u00edvel.","ad5bb8b8":"## Pr\u00e9-processamento de dados"}}