{"cell_type":{"8fb29c6a":"code","a20b0c48":"code","9763f14e":"code","05575cba":"code","13132926":"code","9fac2868":"code","95059c2f":"code","7170e318":"code","f21f9905":"code","21fbc4f5":"code","aa4ffee2":"code","d838513e":"code","59d26c42":"code","726a77f3":"code","3a60420a":"code","71c38327":"code","44f87074":"code","111529fe":"code","0b280e82":"code","84126091":"code","f6b56d02":"code","51773055":"code","f0870531":"code","882d9c24":"code","2f0f68a4":"code","a1f97d41":"code","7570fdbf":"code","cc2d151e":"code","9f2535cd":"code","bf5e513f":"code","279a032f":"code","421b7b9b":"code","ab85623e":"markdown","5d87044c":"markdown","5f54efb8":"markdown","deee7689":"markdown","8dcd967d":"markdown","4e3c9995":"markdown","26c3d7fa":"markdown","6cb45cc1":"markdown","fdf44559":"markdown","edfe3c7a":"markdown","a7471cde":"markdown","fa0dbb78":"markdown","07c27af4":"markdown","49bbfa37":"markdown","212a0b57":"markdown"},"source":{"8fb29c6a":"import pandas as pd\nimport numpy as np","a20b0c48":"training = pd.read_csv(\"..\/input\/disease-prediction-using-machine-learning\/Training.csv\")\ntraining","9763f14e":"training.info()","05575cba":"training.drop('Unnamed: 133', axis=1, inplace=True)\ntraining.columns","13132926":"len(training['prognosis'].value_counts())","9fac2868":"training['prognosis'].value_counts()","95059c2f":"for column in training.columns[:-1]:\n    print(\"{} ({}) : {}\".format(column, len(training[column].unique()), training[column].unique()))","7170e318":"testing = pd.read_csv(\"..\/input\/disease-prediction-using-machine-learning\/Testing.csv\")\ntesting.head()","f21f9905":"testing.shape","21fbc4f5":"len(testing['prognosis'].unique())","aa4ffee2":"X_train = training.drop('prognosis', axis=1)\ny_train = training['prognosis']\ny_train = np.array(y_train).reshape(y_train.shape[0], 1)\n\nX_test = testing.drop('prognosis', axis=1)\ny_test = testing['prognosis']\ny_test = np.array(y_test).reshape(y_test.shape[0], 1)\n\nprint(\"X_train : {} \\ny_train : {} \\nX_test: {} \\ny_test : {}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))","d838513e":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report,accuracy_score","59d26c42":"tree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)\n\npred = tree.predict(X_test)\nacc = tree.score(X_test, y_test)\n\nprint(\"Acurray on test set: {:.2f}%\".format(acc*100))","726a77f3":"np.ravel(y_test[:10])","3a60420a":"np.ravel(pred[:10])","71c38327":"print(classification_report(y_test, pred))","44f87074":"fi = pd.DataFrame(tree.feature_importances_*100, X_train.columns, columns=['Importance'])\nfi.sort_values(by='Importance',ascending=False, inplace=True)\nfi","111529fe":"zeros = np.array(fi[fi['Importance'] == 0.000000].index)\nzeros","0b280e82":"zeros.shape","84126091":"print(\"Count of Features have 0% importance: {}\".format(len(zeros)))","f6b56d02":"training_new = training.drop(columns=zeros, axis=1)\ntraining_new.shape[1]","51773055":"testing_new = testing.drop(columns=zeros, axis=1)\ntesting_new.shape[1]","f0870531":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation","882d9c24":"X_train_new = training_new.drop('prognosis', axis=1)\ny_train_new = training['prognosis']\n\nX_test_new = testing_new.drop('prognosis', axis=1)\ny_test_new = testing['prognosis']","2f0f68a4":"print(\"X_train_new : {} \\ny_train_new : {} \\nX_test_new: {} \\ny_test_new : {}\".format(X_train_new.shape, y_train_new.shape, X_test_new.shape, y_test_new.shape))","a1f97d41":"y_train_enc = pd.get_dummies(y_train_new)\ny_test_enc = pd.get_dummies(y_test_new)\ny_train_enc.head(10)","7570fdbf":"model = Sequential()\nmodel.add(Dense(32, input_dim=X_train_new.shape[1]))\nmodel.add(Activation('relu'))\nmodel.add(Dense(16))\nmodel.add(Activation('relu'))\nmodel.add(Dense(y_train_enc.shape[1]))\nmodel.add(Activation('softmax'))\nmodel.summary()","cc2d151e":"model.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer='adam')","9f2535cd":"history = model.fit(X_train_new, y_train_enc, batch_size=120, epochs=30, validation_split=0.3)","bf5e513f":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use('fivethirtyeight')","279a032f":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\n\nax1.plot(history.history['accuracy'])\nax1.plot(history.history['val_accuracy'])\nax1.set_title('Accuracy')\nax1.set_ylabel('accuracy')\nax1.set_xlabel('epochs')\nplt.legend(['train', 'val'], loc='lower right')\n\nax2.plot(history.history['loss'])\nax2.plot(history.history['val_loss'])\nax2.set_title('Loss')\nax2.set_ylabel('loss')\nax2.set_xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')","421b7b9b":"score = model.evaluate(X_test_new, y_test_enc, steps=5, batch_size=1, verbose=1)\n\nprint('Loss: ', score[0])\nprint('Accuracy: ', score[1]*100)","ab85623e":"# Decision Tree","5d87044c":"# Visualization","5f54efb8":"# Loading Data","deee7689":"## Important Features","8dcd967d":"There are 41 different prognonsis which means our labels in data. To see what these are:","4e3c9995":"Comparision of predictions for first 10 test data:","26c3d7fa":"## Droping unnecessary column","6cb45cc1":"We had 133 columns and with deleting 69, new dataframe has to consist of 64 columns.","fdf44559":"I'm doing same for test set.","edfe3c7a":"### Counts of prognosis in data","a7471cde":"# Neural Network","fa0dbb78":"We have the same count of label samples for each prognosis. Now see unique features in other columns:","07c27af4":"I'm deleting these features having 0% importance for tree to decision and creating new dataframe. I will use new dataframe for a neural network.","49bbfa37":"# Train Test Split","212a0b57":"# New Dataframe"}}