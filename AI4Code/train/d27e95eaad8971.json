{"cell_type":{"70d1dbef":"code","cdff2bf9":"code","79871c9a":"code","19ed8788":"code","453b691a":"code","5b892a44":"markdown"},"source":{"70d1dbef":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport glob\nimport os","cdff2bf9":"feature_dir = \"..\/input\/indoor-wifi-features\/\"","79871c9a":"# the metric used in this competition\ndef comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat - x,2) + np.power(yhat-y,2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()\/xhat.shape[0]\n\n# get our train and test files\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nssubm = pd.read_csv('..\/input\/indoor-location-navigation\/sample_submission.csv', index_col=0)","19ed8788":"predictions = list()\n\nfor e, file in enumerate(train_files):\n    data = pd.read_csv(file, index_col=0)\n    test_data = pd.read_csv(test_files[e], index_col=0)\n\n    # simple grid search for tuning using path and groupkfold cv\n    #for i in [127]:\n    #    for n in [75]:\n    #        modely = lgb.LGBMRegressor(\n    #        n_estimators=n, num_leaves=i, n_jobs=1)\n    #        gkf = model_selection.GroupKFold()\n    #        scores = model_selection.cross_val_score(\n    #            modely, x_train, y_trainy, scoring='neg_mean_squared_error',\n    #            cv=gkf, groups=data.iloc[:,-1], n_jobs=5)\n    #        print(i, n, l, scores, scores.mean())\n    \n\n    x_train = data.iloc[:,:-3]\n    y_trainy = data.iloc[:,-2]\n    y_trainx = data.iloc[:,-3]\n    y_trainf = data.iloc[:,-1]\n\n    modely = lgb.LGBMRegressor(\n        n_estimators=125, num_leaves=90)\n    modely.fit(x_train, y_trainy)\n\n    modelx = lgb.LGBMRegressor(\n        n_estimators=125, num_leaves=90)\n    modelx.fit(x_train, y_trainx)\n\n    modelf = lgb.LGBMClassifier(\n        n_estimators=125, num_leaves=90)\n    modelf.fit(x_train, y_trainf)\n    \n    test_predsx = modelx.predict(test_data.iloc[:,:-1])\n    test_predsy = modely.predict(test_data.iloc[:,:-1])\n    test_predsf = modelf.predict(test_data.iloc[:,:-1])\n    \n    test_preds = pd.DataFrame(np.stack((test_predsf, test_predsx, test_predsy))).T\n    test_preds.columns = ssubm.columns\n    test_preds.index = test_data[\"site_path_timestamp\"]\n    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n    predictions.append(test_preds)","453b691a":"# generate prediction file \nall_preds = pd.concat(predictions)\nall_preds = all_preds.reindex(ssubm.index)\nall_preds.to_csv('submission.csv')","5b892a44":"### Simple benchmark using wifi features and lightgbm \n\nShows the use of wifi features I made to predict phone position. There is a lot of room for improvement, and for people interested in hyperparameter etc these features are an easy way to get started on this competition. Wifi features are available in [this dataset](https:\/\/www.kaggle.com\/ammarali32\/indoor-wifi-features). See this [forum post](https:\/\/www.kaggle.com\/c\/indoor-location-navigation\/discussion\/215445) for information on the approach. The code to generate the features is available in [this notebook](https:\/\/www.kaggle.com\/devinanzelmo\/wifi-features)\n\nThe Main Difference Between the datasets that mine includes the features using only wifi's that had 1000 or more bssid in the training dataset.\nIf you found it helpful upvote the original notebook."}}