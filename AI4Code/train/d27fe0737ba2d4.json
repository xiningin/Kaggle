{"cell_type":{"36f2822a":"code","102008e3":"code","84b394e4":"code","95b3a7c1":"code","e4a47859":"code","8a0dbca1":"code","cf6f3fc8":"code","366c14f4":"code","b39bc6d8":"code","a0804484":"code","e24f1638":"code","aeb3ad76":"code","fd5031d1":"code","51998696":"code","e460c2e7":"code","f3a18bf3":"code","2511fd5c":"code","d3cddbb7":"code","6657a04f":"code","96e070c1":"code","a68223a5":"code","6f9b55e4":"code","3820b0be":"code","7c953307":"code","57c0dc71":"markdown","d1d9794c":"markdown","6ec0166c":"markdown","b388c77c":"markdown","af11ed9d":"markdown","13e4b93f":"markdown","50c22e15":"markdown","bf44cf17":"markdown","ca54f755":"markdown","c85b5249":"markdown","26b46474":"markdown","c31288ed":"markdown","c006e86b":"markdown","464ab14e":"markdown","55a5d6c5":"markdown"},"source":{"36f2822a":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\nfrom scipy.stats import mode\n\nfrom time import sleep\n\nfrom tqdm import tqdm\n\nfrom collections import defaultdict \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nfrom torchvision import transforms\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import MultiplicativeLR\n\nimport warnings\nwarnings.filterwarnings('ignore')","102008e3":"GPU = True\ndevice = \"cuda\" if GPU and torch.cuda.is_available() else \"cpu\"\n\nprint(f'Using device {device}')","84b394e4":"df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\ndf.head()","95b3a7c1":"df['label'].value_counts()","e4a47859":"df_test.head()","8a0dbca1":"submission.head()","cf6f3fc8":"df.shape","366c14f4":"class CreateDataset(Dataset):\n    \n    def __init__(self, dataframe, transform, count_pixel=28 * 28):\n        \n        if dataframe.columns.shape[0] == count_pixel:\n            # test\n            self.features = dataframe.values.reshape((-1,28,28)).astype(np.uint8)\n            self.labels = None\n        else:\n            # train\n            self.features = dataframe.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)\n            self.labels = torch.from_numpy(dataframe['label'].values)\n        \n        self.transform = transform\n    \n    def __len__(self):\n        return self.features.shape[0]\n    \n    def __getitem__(self, index):\n            \n        if self.labels is not None:\n            return self.transform(self.features[index]), self.labels[index]\n        else:\n            return self.transform(self.features[index])","b39bc6d8":"# \u043d\u0435 \u0441\u043e\u0432\u0441\u0435\u043c \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\nmean, std = 0.5, 0.5\n\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ntransform2 = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(25),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ntransform3 = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 0.8)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ntransform4 = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomAffine(degrees=30, scale=(1.1, 1.1)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ntransform5 = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomAffine(degrees=30, translate=(0.1,0.1)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ntransform6 = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomAffine(degrees=10, shear=45),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])","a0804484":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3),\n            nn.BatchNorm2d(32),\n            # inplace=True -> \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u043f\u0430\u043c\u044f\u0442\u0438\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(32, 32, kernel_size=3),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(32, 32, kernel_size=5, stride=2, padding=14),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(2, 2),\n            nn.Dropout2d(0.25)\n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64, 64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=6),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.MaxPool2d(2, 2),\n            nn.Dropout2d(0.25)\n        )\n        \n        self.conv3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=4),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(0.25)\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(128 * 1 * 1, 10),\n#             \u0445\u0443\u0436\u0435????\n#             nn.Softmax(dim=1)\n        )\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        \n        x = x.view(-1, 128 * 1 * 1)\n        \n        x = self.fc(x)\n        \n        return x","e24f1638":"def create_dataloaders(random_state, test_size=0.15, batch_size=32):\n    # \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0430\u044f \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u0447\u0430\u0441\u0442\u0438\n    train_data, valid_data = train_test_split(df, test_size=test_size, stratify=df['label'], random_state=random_state)\n    \n    # \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u044b\n    train_dataset_0 = CreateDataset(dataframe=train_data, transform=transform)\n    train_dataset_1 = CreateDataset(dataframe=train_data, transform=transform2)\n    train_dataset_2 = CreateDataset(dataframe=train_data, transform=transform3)\n    train_dataset_3 = CreateDataset(dataframe=train_data, transform=transform4)\n    train_dataset_4 = CreateDataset(dataframe=train_data, transform=transform5)\n    train_dataset_5 = CreateDataset(dataframe=train_data, transform=transform6)\n    train_dataset = ConcatDataset([train_dataset_0, train_dataset_1, train_dataset_2, train_dataset_3, train_dataset_4, train_dataset_5])\n\n    valid_dataset = CreateDataset(dataframe=valid_data, transform=transform)\n    \n    # \u0437\u0430\u0433\u0440\u0443\u0437\u0447\u0438\u043a\u0438\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n\n    return train_loader, valid_loader, train_dataset.__len__(), valid_dataset.__len__()","aeb3ad76":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)\n\ndef other_metrics(y_true, y_pred):\n    accuracy = accuracy_score(y_true, y_pred)\n    roc_auc = multiclass_roc_auc_score(y_true, y_pred)\n    return np.array([accuracy, roc_auc])","fd5031d1":"def make_dirr(name):\n    try:\n        os.makedirs(name)\n    except FileExistsError:\n        pass","51998696":"def train_model(epochs, device, seed):\n    # 2 \u0437\u0430\u0433\u0440\u0443\u0437\u0447\u0438\u043a\u0430, \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n    train_loader, valid_loader, size_train, size_valid = create_dataloaders(random_state=seed)\n\n    # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0430\u0442\u0447\u0435\u0439\n    size_batch_train = train_loader.__len__()\n    size_batch_valid = valid_loader.__len__()\n    \n    # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f\n    checkpoint_dirr = f'.\/checkpoint{seed}\/'\n    make_dirr(checkpoint_dirr)\n    \n    # \u043c\u0435\u0442\u0440\u0438\u043a\u0438 (accuracy, roc_auc, loss)\n    metrics = defaultdict(list)\n    best_loss = np.inf\n    \n    # \u0434\u043b\u044f \u0440\u0430\u043d\u043d\u0435\u0439 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438\n    early_count = 0\n    early_stopping = 2\n    \n    # \u043c\u043e\u0434\u0435\u043b\u044c\n    net = Net().to(device)\n    \n    # \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u0439\n    criterion = nn.CrossEntropyLoss().to(device)\n    \n    # \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\n    optimizer = optim.Adam(net.parameters(), lr=0.003)\n    \n    # \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f learning rate\n    scheduler = MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.85)\n    \n    for epoch in range(epochs):\n        # \u0440\u0435\u0436\u0438\u043c train\n        net.train()\n\n        # \u043e\u0431\u043d\u0443\u043b\u0438\u0442\u044c \u043c\u0435\u0442\u0440\u0438\u043a\u0438\n        train_loss = 0\n        metric = 0\n\n        with tqdm(train_loader, unit=\"batch\") as tepoch:\n            tepoch.set_description(f\"Epoch {epoch}\")\n\n            # \u043f\u043e \u043a\u0430\u0436\u0434\u043e\u043c\u0443 \u0431\u0430\u0442\u0447\u0443\n            for i, batch in enumerate(tepoch):\n                # \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0438\u0437\u043e \u0438 \u043c\u0435\u0442\u043a\u0438 \u0438\u0437 \u0431\u0430\u0442\u0447\u0430\n                images, labels = batch\n\n                # \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u0434 \u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u043e\n                images = images.to(device)\n                labels = labels.to(device) \n\n                # \u0432 64 \u0431\u0438\u0442\u0430\n                labels = labels.long()\n                \n                # \u043e\u0431\u043d\u0443\u043b\u0438\u0442\u044c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u043f\u0435\u0440\u0435\u0434 \u043e\u0431\u0440\u0430\u0442\u043d\u044b\u043c \u0440\u0430\u0441\u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0435\u043d\u0438\u0435\u043c\n                optimizer.zero_grad()\n                \n                # \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u044b\n                preds = net(images)\n                pred = preds.argmax(dim=1)\n                \n                # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c\n                # https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.CrossEntropyLoss.html\n                loss = criterion(preds, labels)\n                \n                # \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442 \u043f\u043e\u0442\u0435\u0440\u044c\n                loss.backward()\n                \n                # \u043e\u0431\u043d\u043e\u0432\u0438\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n                optimizer.step()\n\n                # \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\n                train_loss += loss.item()\n                \n                # \u0434\u0440\u0443\u0433\u0438\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438\n                metric += other_metrics(labels.tolist(), pred.tolist())\n                accuracy, roc_auc = metric\n                \n                tepoch.set_postfix(loss=train_loss \/ (i + 1), accuracy=accuracy \/ (i + 1), roc_auc=roc_auc \/ (i + 1), lr=scheduler.get_lr()[0])\n            \n            metrics['loss'].append(train_loss \/ (i + 1))\n            metrics['accuracy'].append(accuracy \/ (i + 1))\n            metrics['roc_auc'].append(roc_auc \/ (i + 1))\n            metrics['lr'].append(scheduler.get_lr()[0])\n        \n        # \u0440\u0435\u0436\u0438\u043c eval\n        net.eval()\n        \n        sleep(0.1)\n\n        with torch.no_grad():\n            valid_loss = 0\n            metric = 0\n            \n            with tqdm(valid_loader, unit=\"batch\") as tepoch:\n                tepoch.set_description(f\"Epoch {epoch}\")\n\n                for i, valid_batch in enumerate(tepoch):\n                    valid_images, valid_labels = valid_batch\n                    valid_images = valid_images.to(device)\n                    valid_labels = valid_labels.to(device)\n                    valid_labels = valid_labels.long()\n\n                    valid_preds = net(valid_images)\n                    valid_pred = valid_preds.argmax(dim=1)\n\n                    loss_valid = criterion(valid_preds, valid_labels)\n\n                    valid_loss += loss_valid.item()\n\n                    metric += other_metrics(valid_labels.tolist(), valid_pred.tolist())\n                    accuracy, roc_auc = metric\n\n                    tepoch.set_postfix(loss=valid_loss \/ (i + 1), accuracy=accuracy \/ (i + 1), roc_auc=roc_auc \/ (i + 1))\n\n                metrics['val_loss'].append(valid_loss \/ (i + 1))\n                metrics['val_accuracy'].append(accuracy \/ (i + 1))\n                metrics['val_roc_auc'].append(roc_auc \/ (i + 1))\n\n        sleep(0.1)\n        \n        scheduler.step()\n        \n        if valid_loss < best_loss:\n            # \u043f\u0435\u0440\u0435\u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c\n            best_loss = valid_loss\n\n            # \u0437\u0430\u043d\u0443\u043b\u0438\u0442\u044c \u0441\u0447\u0451\u0442\u0447\u0438\u043a\n            early_count = 0\n\n            # \u0437\u0430\u043f\u0438\u0441\u0430\u0442\u044c \n            torch.save(net.state_dict(), f'{checkpoint_dirr}epoch:{epoch}.pt')\n        else:\n            early_count += 1\n\n            if early_count >= early_stopping:\n                print(f\"Loss did not improve over {early_stopping} epochs => early stopping\")\n                break\n                \n    return net, metrics, checkpoint_dirr","e460c2e7":"count_models = 7\nmax_epochs = 12\n\nlist_models = []\nlist_metrics = []\nlist_dirr = []\n\nfor seed in range(count_models):\n    print(f'Train \u2116{seed + 1} CNN')\n    model_network, dict_metric, dirr_save = train_model(max_epochs, device, seed)\n    list_models.append(model_network)\n    list_metrics.append(dict_metric)    \n    list_dirr.append(dirr_save)","f3a18bf3":"def graph_plot(history, typ=False):\n    if typ:\n        for i in history.keys():\n            print(f'{i} = [{min(history[i])}; {max(history[i])}]\\n')\n    \n    epoch = len(history['loss'])\n    # \u043d\u0430 \u043a\u0430\u0436\u0434\u0443\u044e: (train, val) + lr\n    size = len(history.keys()) \/\/ 2 + 1\n\n    ncols = 4\n    nrows = int(np.ceil(size \/ ncols))\n\n    \n    fig = plt.figure(figsize=(27, 4))\n    i = 1\n    for k in list(history.keys()):\n        if 'val' not in k:\n            fig.add_subplot(nrows, ncols, i)\n            plt.plot(history[k], marker='o', markersize=5)\n            if k != 'lr':\n                plt.plot(history['val_' + k], marker='o', markersize=5)\n            plt.title(k, fontsize=10)\n\n            plt.ylabel(k)\n            plt.xlabel('epoch')\n            plt.grid()\n\n            plt.yticks(fontsize=10, rotation=30)\n            plt.xticks(fontsize=10, rotation=30)\n            plt.legend(['train', 'valid'], loc='upper left', fontsize=10, title_fontsize=15)\n            i += 1\n#         plt.show()","2511fd5c":"for metric in list_metrics:\n    graph_plot(metric)","d3cddbb7":"for ind, dirr in enumerate(list_dirr):\n    num = np.argmax(-np.array(list_metrics[ind]['val_loss']))\n    print(f'Model \u2116{ind + 1} - Best epoch: {num + 1}')","6657a04f":"for ind, dirr in enumerate(list_dirr):\n    \n    model = list_models[ind].to(device)\n    num = np.argmax(-np.array(list_metrics[ind]['val_loss']))\n    \n    model.load_state_dict(torch.load(f\"{dirr}{[name for name in sorted(os.listdir(dirr)) if str(np.argmax(-np.array(list_metrics[ind]['val_loss']))) in name][0]}\"))\n    model.eval()","96e070c1":"test_dataset = CreateDataset(dataframe=df_test, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","a68223a5":"def get_predict(models, data, method_voting='soft', count_classes=10):\n    if method_voting == 'soft':\n        for_test = np.zeros((data.shape[0], count_classes))\n        \n        for i in range(len(models)):\n            for_test += models[i](data).cpu().detach().numpy()\n\n        return np.argmax(for_test, axis=1)\n        \n    elif method_voting == 'hard':\n        for_test = np.zeros((data.shape[0], len(models)))\n\n        for i in range(len(models)):\n            temp = models[i](data)\n            for_test[:, i] += temp.argmax(dim=1).cpu().detach().numpy()\n        \n        return np.int32(mode(for_test, axis=1)[0].T.flatten())","6f9b55e4":"predict = []\npredict2 = []\n\nfor test_batch in test_loader:\n    data = test_batch\n    data = data.to(device)\n    \n    pred = get_predict(models=list_models, data=data)\n    pred2 = get_predict(models=list_models, data=data, method_voting='hard')\n\n    predict += pred.tolist()\n    predict2 += pred2.tolist()","3820b0be":"submission2 = submission.copy()\nsubmission['Label'] = predict\nsubmission2['Label'] = predict2\n\nsubmission.set_index('ImageId', inplace=True)\nsubmission.to_csv('submittion.csv')\n\nsubmission2.set_index('ImageId', inplace=True)\nsubmission2.to_csv('submittion2.csv')","7c953307":"comparison = submission.join(submission2, lsuffix='_1', rsuffix='_2')\ncomparison.loc[~(comparison['Label_1'] == comparison['Label_2']), ]","57c0dc71":"## \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 CNN","d1d9794c":"## Dataset Class","6ec0166c":"## \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0410\u043d\u0441\u0430\u043c\u0431\u043b\u044f CNN","b388c77c":"## \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043c\u0435\u0442\u0440\u0438\u043a","af11ed9d":"## GPU","13e4b93f":"## \u0411\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438","50c22e15":"## Net class","bf44cf17":"## Augmentation","ca54f755":"## \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043b\u0443\u0447\u0448\u0438\u0445 \u0432\u0435\u0440\u0441\u0438\u0439 \u043c\u043e\u0434\u0435\u043b\u0435\u0439","c85b5249":"## Metrics","26b46474":"C\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438","c31288ed":"## Transforms","c006e86b":"## DataFrames","464ab14e":"## \u041f\u0440\u043e\u0433\u043d\u043e\u0437 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 (Soft + Hard Voting)","55a5d6c5":"## \u0420\u0430\u0437\u043d\u0438\u0446\u0430 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u043e\u0432"}}