{"cell_type":{"9e35500c":"code","81163005":"code","720cda9e":"code","00805e77":"code","541a2e6c":"code","c0b43b85":"code","93279a44":"code","40ad07fe":"code","844dde17":"code","4380ffbd":"code","17e7f9d1":"code","ff7c49fc":"code","484a6b65":"code","ddc2a65a":"code","079f155d":"code","f5f42084":"code","c1271212":"code","55e8dae4":"code","6ade7287":"code","cb4d67c2":"code","dc2223a9":"code","6c75a19b":"code","b7dbd830":"code","43573dd7":"code","e39c0a1f":"code","32873c97":"code","fcc0cf6e":"code","79fbd6ef":"code","67c8ec24":"code","e91da9a2":"code","2381c4ce":"code","a7f54c1e":"code","da6b82a4":"code","2e4f7818":"code","4f333eb2":"code","d96d7378":"code","349aac5f":"code","3efb6397":"markdown","8b8d6325":"markdown","5d145ce7":"markdown","a0dc9839":"markdown","2efeb35d":"markdown","3db1b82c":"markdown","dd28a354":"markdown","2841c57f":"markdown","612dbd0d":"markdown","c0caec74":"markdown","c6792946":"markdown","45777959":"markdown","f4f621d1":"markdown"},"source":{"9e35500c":"import numpy as np \nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport missingno as msno\n%matplotlib inline\npd.set_option('display.max_rows',200)\npd.set_option('display.max_columns',100)\nimport pickle\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error,make_scorer\nfrom sklearn.model_selection import KFold,RandomizedSearchCV\nimport statsmodels.formula.api as smf\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax","81163005":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nprint(train.shape)\nprint(test.shape)","720cda9e":"train.info()","00805e77":"# Combining dataset\ntrain_y = train['SalePrice']\ndata = pd.concat((train,test),sort= False).reset_index(drop=True)\ndata.drop(['SalePrice','Id'],axis=1,inplace=True)\ndata.rename(columns={'1stFlrSF':'FirstFlrSF','2ndFlrSF':'SecondFlrSF','3SsnPorch':'ThreeSsnPorch'}, inplace=True)\ndata.shape","541a2e6c":"data.head()","c0b43b85":"train_y.describe()","93279a44":"#Distribution plot\nsns.distplot(train_y);\n#skewness and Kurtosis\nprint('Skewness: %f' % train_y.skew())\nprint('Kurtosis: %f' % train_y.kurt())","40ad07fe":"# using numpy function log fucntion\ntrain_y = np.log(train_y + 1)\nsns.distplot(train_y);\nprint(\"Skewness: %f\" % train_y.skew())\nprint(\"Kurtosis: %f\" % train_y.kurt())","844dde17":"# correlation matrix\nplt.subplots(figsize=(10,8))\nsns.heatmap(train.corr());","4380ffbd":"#Saleplice corr matrix\nk = 10# no. of variables for heatmap\ncols = train.corr().nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale = 1)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)","17e7f9d1":"# Top\nnum = train.corr()['SalePrice'].sort_values(ascending = False).head(10).to_frame()\ncm = sns.light_palette('grey', as_cmap = True)\ns = num.style.background_gradient(cmap = cm)\ns","ff7c49fc":"# Compute the correlation matrix \ncorr_all = train.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr_all, dtype = np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize = (11, 9))\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr_all, mask = mask,\n            square = True, linewidths = .5, ax = ax, cmap = \"BuPu\")      \nplt.show()","484a6b65":"#scatter plot\nsns.set()\nsns.pairplot(train[cols],size = 2.5);","ddc2a65a":"# missing values?\nsns.set(style = \"ticks\")\n\nmsno.matrix(data)\nmsno.heatmap(data, cmap = 'binary')","079f155d":"missing_data = pd.DataFrame(data.isnull().sum()).reset_index()\nmissing_data.columns = ['ColumnName','MissingCount']\n\nmissing_data['PercentMissing'] = round(missing_data['MissingCount']\/data.shape[0],3)*100\nmissing_data =missing_data.sort_values(by = 'MissingCount',ascending = False).reset_index(drop = True)\nmissing_data.head(35)","f5f42084":"data.drop(['PoolQC','MiscFeature','Alley'],axis=1,inplace=True)\nffill= list(missing_data.ColumnName[18:34])\ndata[ffill] = data[ffill].fillna(method = 'ffill')\nmissing_data.ColumnName[3:18]","c1271212":"col_for_zero = ['Fence','FireplaceQu','GarageFinish','GarageQual','GarageCond','GarageType','BsmtExposure','BsmtCond','BsmtQual','BsmtFinType2','BsmtFinType1','MasVnrType']\ndata[col_for_zero] = data[col_for_zero].fillna('None')\ndata['LotFrontage'] = data['LotFrontage'].fillna(data['LotFrontage'].dropna().mean())\ndata['GarageYrBlt'] = data['GarageYrBlt'].fillna(data['GarageYrBlt'].dropna().median())\ndata['MasVnrArea'] = data['MasVnrArea'].fillna(data['MasVnrArea'].dropna().median())","55e8dae4":"data['YrBltAndRemod']=data['YearBuilt']+data['YearRemodAdd']\ndata['TotalSF']=data['TotalBsmtSF'] + data['FirstFlrSF'] + data['SecondFlrSF']\ndata['Total_sqr_footage'] = (data['BsmtFinSF1'] + data['BsmtFinSF2'] +data['FirstFlrSF'] + data['SecondFlrSF'])\ndata['Total_Bathrooms'] = (data['FullBath'] + (0.5 * data['HalfBath']) +data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath']))\ndata['Total_porch_sf'] = (data['OpenPorchSF'] + data['ThreeSsnPorch'] + data['EnclosedPorch'] + data['ScreenPorch'] + data['WoodDeckSF'])\ndata['hasfence'] = data['Fence'].apply(lambda x: 0 if x == 0 else 1).astype(str)\ndata['hasmasvnr'] = data['MasVnrArea'].apply(lambda x: 0 if x == 0 else 1).astype(str)\ndata['haspool'] = data['PoolArea'].apply(lambda x: 1 if x > 0 else 0).astype(str)\ndata['has2ndfloor'] = data['SecondFlrSF'].apply(lambda x: 1 if x > 0 else 0).astype(str)\ndata['hasgarage'] = data['GarageArea'].apply(lambda x: 1 if x > 0 else 0).astype(str)\ndata['hasbsmt'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0).astype(str)\ndata['hasfireplace'] = data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0).astype(str)\ndata['MSSubClass'] = data['MSSubClass'].astype(str)\ndata['YrSold'] = data['YrSold'].astype(str)\ndata['MoSold'] = data['MoSold'].astype(str)","6ade7287":"num_var=[key for key in dict(data.dtypes) if dict(data.dtypes)[key] in ['float64', 'int64', 'float32', 'int32']]\ncat_var=[key for key in dict(data.dtypes) if dict(data.dtypes)[key] in ['object']]\nprint(len(num_var))\nprint(len(cat_var))\nnum_data = data[num_var]\ncat_data = data[cat_var]","cb4d67c2":"#skew X variables\nskew_data = num_data.apply(lambda x: x.skew()).sort_values(ascending=False)\n\n\nhigh_skew = skew_data[skew_data > 0.5]\nskew_index = high_skew.index\n\nfor i in skew_index:\n    data[i] = boxcox1p(data[i], boxcox_normmax(data[i] + 1))","dc2223a9":"def outlier_capping(x):\n    x = x.clip_upper(x.quantile(0.99))\n    x = x.clip_lower(x.quantile(0.01))\n    return x\nnum_data.drop('PoolArea',axis=1,inplace=True)\nnum_data = num_data.apply(outlier_capping)\nnum_data['PoolArea'] = data.PoolArea","6c75a19b":"def create_dummies(df,colname):\n    col_dummies = pd.get_dummies(df[colname],prefix =colname)\n    col_dummies.drop(col_dummies.columns[0],axis=1,inplace=True)\n    df = pd.concat([df,col_dummies],axis=1)\n    df.drop(colname,axis=1,inplace=True)\n    return df\n#for c_feature in categorical_features\nfor c_feature in cat_data.columns:\n    cat_data[c_feature] = cat_data[c_feature].astype('category')\n    cat_data = create_dummies(cat_data , c_feature )\nprint(cat_data.shape)\nprint(num_data.shape)","b7dbd830":"final_data = pd.concat([cat_data,num_data,train_y],axis=1)\nprint(final_data.shape)","43573dd7":"final_data.columns= [var.strip().replace('.', '_') for var in final_data.columns]\nfinal_data.columns= [var.strip().replace('&', '_') for var in final_data.columns]\nfinal_data.columns= [var.strip().replace(' ', '_') for var in final_data.columns]","e39c0a1f":"overfit = []\nfor i in final_data.columns:\n    counts = final_data[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros \/ len(final_data) * 100 > 99.94:\n        overfit.append(i)\n\noverfit\nfinal_data.drop(overfit,axis=1,inplace=True)","32873c97":"#splitting the data set into two sets\nfinal_train = final_data.loc[final_data.SalePrice.isnull()==0]\nfinal_test = final_data.loc[final_data.SalePrice.isnull()==1]\nfinal_train = final_train.drop('SalePrice',axis=1)\nfinal_test = final_test.drop('SalePrice',axis=1)\nprint(final_train.shape)\nprint(final_test.shape)","fcc0cf6e":"X = final_train\ny = train_y\nprint(X.shape)\nprint(y.shape)\ntest_X = final_test\nprint(test_X.shape)","79fbd6ef":"kfolds =  KFold(n_splits = 10,shuffle = True,random_state = 21)\ndef rmse(y,y_pred):\n    return np.sqrt(mean_squared_error(y,y_pred))\n\ndef cv_rmse(model,X=X):\n    rmse = np.sqrt(-cross_val_score(model,X,y,scoring='neg_mean_squared_error',cv = kfolds))\n    return rmse","67c8ec24":"alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5,15.6,15.7,15.8,15.9,16]\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,0.0009,0.0010,0.0011,0.0012,0.0013,0.0014,0.0015]\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,0.0009,0.0010,0.0011,0.0012,0.0013,0.0014,0.0015]\ne_l1ratio = [0.05, 0.15,0.2, 0.25,0.3, 0.35,0.4, 0.45,0.5, 0.55,0.6, 0.65,0.7, 0.75,0.8, 0.85, 0.9, 0.95, 0.99, 1]","e91da9a2":"# ridge = make_pipeline(RobustScaler(),RidgeCV(alphas = alphas_alt,cv = kfolds))\n# lasso = make_pipeline(RobustScaler(),LassoCV(max_iter = 1e7,alphas = alphas2,random_state = 42,cv = kfolds))\n# elasticnet = make_pipeline(RobustScaler(),ElasticNetCV(max_iter = 1e7,alphas = e_alphas,cv = kfolds,l1_ratio =e_l1ratio))\n# svr = make_pipeline(RobustScaler(),SVR(C= 20,epsilon = 0.008 , gamma = 0.0003))\n# gbr = GradientBoostingRegressor(n_estimators=3000,learning_rate= 0.05,max_depth=4,max_features='sqrt',min_samples_leaf = 15,min_samples_split = 10,loss = 'huber',random_state =21)\n# lightgbm = LGBMRegressor(objective = 'regression',num_leaves = 4,learning_rate = 0.01,n_estimators=5000,max_bin = 200,bagging_fraction = 0.75,bagging_freq = 5,bagging_seed=7,feature_fraction=0.2,feature_fraction_seed = 7,verbose=-1)\n# xgboost = XGBRegressor(learning_rate=0.01,n_estimators=3460,max_depth=3,min_child_weight=0,gamma = 0,subsample=0.7,colsample_bytree=0.7,objective='reg:linear',nthread=-1,scale_pos_weight=1,seed=27,reg_alpha = 0.00006)\n# stack_gen = StackingCVRegressor(regressors=(ridge,lasso,elasticnet,gbr,xgboost,lightgbm,svr),meta_regressor=xgboost,use_features_in_secondary=True)","2381c4ce":"# score = cv_rmse(ridge)\n# print('Ridge: {:.4f} ({:.4f})\\n'.format(score.mean(),score.std()))\n# score = cv_rmse(lasso)\n# print('Lasso: {:.4f} ({:.4f})\\n'.format(score.mean(),score.std()))\n# score = cv_rmse(elasticnet)\n# print('Elasticnet: {:.4f} ({:.4f})\\n'.format(score.mean(),score.std()))\n# score = cv_rmse(svr)\n# print('SVR: {:.4f} ({:.4f})\\n'.format(score.mean(),score.std()))\n# score = cv_rmse(gbr)\n# print('GBRegressor: {:.4f} ({:.4f})\\n'.format(score.mean(),score.std()))\n# score = cv_rmse(lightgbm)\n# print('LightGBM: {:.4f} ({:.4f})\\n'.format(score.mean(),score.std()))\n# score = cv_rmse(xgboost)\n# print('XGBoost: {:.4f} ({:.4f})\\n'.format(score.mean(),score.std()))","a7f54c1e":"# print('Start Fit')\n\n# print('stack_gen')\n# stack_gen_model = stack_gen.fit(np.array(X),np.array(y))\n# print('Ridge')\n# ridge_model_full_data = ridge.fit(X,y)\n# print('Lasso')\n# lasso_model_full_data = lasso.fit(X,y)\n# print('Elasticnet')\n# elastic_model_full_data = elasticnet.fit(X,y)\n# print('SVR')\n# svr_model_full_data = svr.fit(X,y)\n# print('GradientBoosting')\n# gbr_model_full_data = gbr.fit(X,y)\n# print('LightGBM')\n# lightgbm_model_full_data = lightgbm.fit(X,y)\n# print('XGBoost')\n# xgboost_model_full_data = xgboost.fit(X,y)","da6b82a4":"# #Blending models\n# def blend_models_predict(X):\n#     return ((0.0175 * elastic_model_full_data.predict(X)) + \\\n#             (0.0175 * lasso_model_full_data.predict(X)) + \\\n#             (0.0075 * ridge_model_full_data.predict(X)) + \\\n#             (0.0075 * svr_model_full_data.predict(X)) + \\\n#             (0.2 * gbr_model_full_data.predict(X)) + \\\n#             (0.2 * xgboost_model_full_data.predict(X)) + \\\n#             (0.2 * lightgbm_model_full_data.predict(X)) + \\\n#             (0.35 * stack_gen_model.predict(np.array(X))))","2e4f7818":"# print('RMSE score on train data: ')    \n# print(rmse(y,blend_models_predict(X)))","4f333eb2":"# print('Predict submission')\nsubmission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\n# submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(test_X)))\nsubmission = pd.read_csv('..\/input\/topsubmissions\/submission.csv')","d96d7378":"# print('Blend with my Top Kernels submissions\\n')\n# sub_1 = pd.read_csv('..\/input\/topsubmissions\/submission1.csv')\n# sub_2 = pd.read_csv('..\/input\/topsubmissions\/submission2.csv')\n\n# submission.iloc[:,1] = np.floor((0.5 * np.floor(np.expm1(blend_models_predict(test_X)))) + \n                                \n#                                 (0.5 * sub_2.iloc[:,1]))\n\n","349aac5f":"submission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","3efb6397":"Plotting Missing values dataset","8b8d6325":"### Importing Packages","5d145ce7":"### Features Generation","a0dc9839":"###  OutLier Treatement","2efeb35d":"### Reading Data","3db1b82c":"### applying Log transformation on SalePrice","dd28a354":"> rmse score on train data 0.052","2841c57f":"# Data Cleaning","612dbd0d":"### Converting Categorical Features into Numeric Features","c0caec74":"### Distribution of SalePrice","c6792946":"### Data left to be filled\n\n- Fence         Zero\n- FireplaceQu   zero\n- LotFrontage   mean\/median\n- GarageYrBlt   median or most frequent 1980\n- GarageFinish  zero\n- GarageQual    zero\n- GarageCond    zero\n- GarageType    zero\n- BsmtExposur   zero\n- BsmtCond      zero\n- BsmtQual      zero\n- BsmtFinType2  zero\n- BsmtFinType1  zero\n- MasVnrType    zero\n- MasVnrArea    mean\/median","45777959":"### Splitting numeric and categorical features","f4f621d1":"### Dealing with data to be filled with zero\n"}}