{"cell_type":{"442e02ca":"code","1c70d52a":"code","5c47984c":"code","6c22e17d":"code","472b035e":"code","982d506b":"code","7b7c313d":"code","a7fbb903":"code","b9599028":"code","9e4688e4":"code","490a7816":"code","8f9768c1":"code","501fb21a":"code","30977f67":"code","9e3170ad":"code","9ed4ceed":"markdown"},"source":{"442e02ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#from sklearn.metrics import cross_validation \n#from sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn. ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1c70d52a":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', header=0)\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', header=0)\ndf.info()\ndf_test.info()","5c47984c":"cols = ['Name', 'SibSp', 'Parch', 'Ticket', 'Cabin']\ndf=df.drop(cols, axis=1)\ndf_test = df_test.drop(cols,axis=1)\ndf.info()\ndf_test.info()","6c22e17d":"df['Age'] = df['Age'].interpolate()\ndf.info()\ndf_test['Age'] = df_test['Age'].interpolate()\ndf_test['Fare'] = df_test['Age'].interpolate()\ndf_test.info()","472b035e":"dummies=[]\ncols=['Pclass', 'Sex', 'Embarked']\n\nfor col in cols:\n    dummies.append(pd.get_dummies(df[col]))\n\ntitanic_dummies = pd.concat(dummies, axis=1)\ndf = pd.concat((df,titanic_dummies), axis=1)\ndf.info()\n\ndummies_test=[]\nfor col in cols:\n    dummies_test.append(pd.get_dummies(df_test[col]))\n\ntitanic_dummies_test = pd.concat(dummies_test, axis=1)\ndf_test = pd.concat((df_test,titanic_dummies_test), axis=1)\ndf_test.info()","982d506b":"df = df.drop(['Sex', 'Embarked', 'Pclass'], axis=1)\ndf_test = df_test.drop(['Sex', 'Embarked', 'Pclass'], axis=1)\ndf.info()\ndf_test.info()","7b7c313d":"X = df.values\ny = df['Survived'].values\nprint(X.shape)\nprint(y.shape)\nX = np.delete(X, [1], axis=1)\nprint(\"After deleting array shape =\",X.shape)\n\nX_final = df_test.values\nprint(X_final.shape)\n# no survived column in test.csv","a7fbb903":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\ndtc = tree.DecisionTreeClassifier(max_depth=5)\ndtc.fit(X_train,y_train)\ndtc.score(X_test,y_test)\n# public score of 0.72248","b9599028":"lr = LogisticRegression()\nlr.fit(X_train,y_train)\nlr.score(X_test, y_test)\n# public score of 0.75598","9e4688e4":"rfc = RandomForestClassifier(n_estimators=100)\nrfc.fit (X_train, y_train)\nrfc.score (X_test, y_test)\n#public score of 0.74162","490a7816":"gbc = GradientBoostingClassifier(n_estimators=50)\ngbc.fit (X_train, y_train)\ngbc.score (X_test, y_test)\n#public score of 0.7272","8f9768c1":"#Bagging\n\nbg = BaggingClassifier(DecisionTreeClassifier(), max_samples= 0.5, max_features = 1.0, n_estimators = 20)\nbg.fit(X_train,y_train)\nbg.score(X_test, y_test)\n\n# public score of 0.70813","501fb21a":"#Boosting - Ada Boost\n\nadb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 5, learning_rate = 1)\nadb.fit(X_train,y_train)\nadb.score(X_test, y_test)\n# public score of 0.65550","30977f67":"# Voting Classifier - Multiple Model Ensemble \nsvm = SVC(kernel = 'poly', degree = 2 )\nevc = VotingClassifier( estimators= [('lr',lr),('dtc',dtc),('svm',svm)], voting = 'hard')\nevc.fit(X_train,y_train)\nevc.score(X_test, y_test)\n# public score of 0.76076","9e3170ad":"y_results = dtc.predict(X_final)\nsubmission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": y_results\n    })\nsubmission.to_csv('my_titanic_submission.csv', index=False)","9ed4ceed":"**Submission**"}}