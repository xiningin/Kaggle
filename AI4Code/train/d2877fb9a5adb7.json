{"cell_type":{"14b85968":"code","252abc38":"code","bcab7dac":"code","e34761e1":"code","dcf3861b":"code","a4dcae38":"code","9befd1f0":"code","cedb466b":"code","f07d77bc":"code","5b6b9505":"code","865b4f24":"code","1f5bf40d":"code","ec0be525":"code","cd20563b":"code","22feae04":"markdown","49c0d8dc":"markdown","65245e63":"markdown","b0ebc130":"markdown","66c2fdd9":"markdown","e67b9e5f":"markdown","75e4715d":"markdown","66f3d484":"markdown"},"source":{"14b85968":"import random \nimport shutil\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras import metrics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\n\nfrom keras import Sequential\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n\n\nSEED=1\nos.listdir()","252abc38":"#Checking length of each class type type\n\nos.chdir('..\/input\/plantdisease\/plantvillage\/PlantVillage\/')\nprint(len(os.listdir('Pepper__bell___Bacterial_spot')))\nprint(len(os.listdir('Pepper__bell___healthy')))\nprint(len(os.listdir('Potato___Early_blight')))\nprint(len(os.listdir('Potato___Late_blight')))\nprint(len(os.listdir('Potato___healthy')))\nprint(len(os.listdir('Tomato_Bacterial_spot')))\nprint(len(os.listdir('Tomato_Early_blight')))\nprint(len(os.listdir('Tomato_Late_blight')))\nprint(len(os.listdir('Tomato_Leaf_Mold')))\nprint(len(os.listdir('Tomato_Septoria_leaf_spot')))\nprint(len(os.listdir('Tomato_Spider_mites_Two_spotted_spider_mite')))\nprint(len(os.listdir('Tomato__Target_Spot')))\nprint(len(os.listdir('Tomato__Tomato_YellowLeaf__Curl_Virus')))\nprint(len(os.listdir('Tomato__Tomato_mosaic_virus')))\nprint(len(os.listdir('Tomato_healthy')))","bcab7dac":"#Copying the dataset which is read-only\n\nos.system('scp -r \/kaggle\/input\/plantdisease\/plantvillage\/PlantVillage \/kaggle\/input\/')","e34761e1":"#Just checking the files in the library\n!ls -lrt","dcf3861b":"base_dir='\/kaggle\/input\/PlantVillage\/'\n\n#Creating training and validation directory \nos.chdir(base_dir)\n\nos.mkdir('dataset')\nos.mkdir('training')\nos.mkdir('validation')\n\nos.chdir('dataset')\n\nos.chdir(base_dir)\nos.listdir()\nos.chdir('dataset')\nos.system('scp -r ..\/Tom* ..\/Pepper* ..\/Potato* .')","a4dcae38":"#Creating subdirectories in each of the two folders viz training and validation\nclasses = os.listdir()\nfor i in classes:\n    tr_dir = os.path.join('\/kaggle\/input\/PlantVillage\/training',i)\n    val_dir = os.path.join('\/kaggle\/input\/PlantVillage\/validation',i)\n    \n    os.mkdir(tr_dir)\n    os.mkdir(val_dir)\n    \n    \n# Checking\n\nprint(os.listdir('\/kaggle\/input\/PlantVillage\/training'))\n\nprint(os.listdir('\/kaggle\/input\/PlantVillage\/validation'))\n","9befd1f0":"print(classes)\n\nprint(os.getcwd())\n\nfor item in classes:\n    n_val = round(len(os.listdir(item))*.2)\n    n_train = round(len(os.listdir(item))*.8)\n    fnames = os.listdir(item)\n    \n    assert(n_val+n_train == len(fnames))\n    \n    random.seed(SEED+5)\n    random.shuffle(fnames)\n    val_fnames = fnames[0:n_val]\n    tr_fnames = fnames[n_val:len(fnames)]\n    \n    assert(len(val_fnames)+len(tr_fnames)==len(fnames))\n    \n    for i in val_fnames:\n        src ='\/kaggle\/input\/PlantVillage\/dataset\/{}\/{}'.format(item,i)\n        dest = '\/kaggle\/input\/PlantVillage\/validation\/{}\/'.format(item)\n        shutil.copy(src,dest)\n        \n    for j in tr_fnames:\n        src ='\/kaggle\/input\/PlantVillage\/dataset\/{}\/{}'.format(item,j)\n        dest = '\/kaggle\/input\/PlantVillage\/training\/{}\/'.format(item)\n        shutil.copy(src,dest)      ","cedb466b":"for i in classes:\n    path=os.path.join('\/kaggle\/input\/PlantVillage\/training\/',i)\n    print('Training samples in {} is {}'.format(i,len(os.listdir(path))))\n    \n    path=os.path.join('\/kaggle\/input\/PlantVillage\/validation\/',i)\n    print('Validation samples in {} is {}\\n'.format(i,len(os.listdir(path))))\n    \n##Removing class files from the base directory\nos.system('rm -r \/kaggle\/input\/PlantVillage\/Tom* \/kaggle\/input\/PlantVillage\/Pepper* \/kaggle\/input\/PlantVillage\/Potato* .')","f07d77bc":"validation_dir = '\/kaggle\/input\/PlantVillage\/validation\/'\ntraining_dir = '\/kaggle\/input\/PlantVillage\/training\/'","5b6b9505":"#Simple Deep Learning Architecture\n\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_categorical_loss')>0.97):\n            print(\"\\nReached 97% validation accuracy so cancelling training!\")\n            self.model.stop_training = True\n\n\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    tf.keras.layers.Dropout(0.3),\n    \n    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    \n    tf.keras.layers.Conv2D(256, (2,2), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    tf.keras.layers.Dropout(0.3),\n    \n    tf.keras.layers.Conv2D(512, (2,2), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(axis=-1),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(15, activation='softmax')\n])\n\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=1e-3,decay=1e-4\/500),\n              metrics=['categorical_accuracy'])#,top_3_categ_acc,top_5_categ_acc])\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=90,\n      width_shift_range=0.5,\n      height_shift_range=0.5,\n      shear_range=0.4,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      #vertical_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Flow training images in batches of 100 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        training_dir,  # This is the source directory for training images\n        target_size=(256, 256),  # All images will be resized to 256x256\n        batch_size=32,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(256, 256),\n        batch_size=32,\n        class_mode='categorical')\n\n\nmodel_path = '\/kaggle\/working\/bst_mdl_plant_disease.hdf5'\n\ncallbacks = myCallback()\nearlyStopping = EarlyStopping(monitor='val_categorical_accuracy', patience=10, verbose=0, mode='max', restore_best_weights=True)\nmodelcp_save = ModelCheckpoint(model_path, save_best_only=True, monitor='val_categorical_accuracy', mode='max')\nreduce_lr_loss_on_plateau = ReduceLROnPlateau(monitor='val_categorical_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')\n\ncallback_lists = [earlyStopping, modelcp_save, reduce_lr_loss_on_plateau ]\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=500,  # 16511 images = batch_size * steps\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=128,  # 4127 images = batch_size * steps\n      verbose=1,\n      callbacks = callback_lists\n      )","865b4f24":"import matplotlib.pyplot as plt\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\nplt.savefig('\/kaggle\/working\/Acc_plot.png',dpi=200)\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n\nplt.savefig('\/kaggle\/working\/Loss_plot.png',dpi=200)\n\n\nacc_l= pd.DataFrame(acc)\nval_acc_l=pd.DataFrame(val_acc)\n\nloss_df = pd.DataFrame(loss)\nval_loss_df = pd.DataFrame(val_loss)\n\nacc_l.to_csv('\/kaggle\/working\/accuracy.csv')\nval_acc_l.to_csv('\/kaggle\/working\/val_acc.csv')\n\nloss_df.to_csv('\/kaggle\/working\/loss.csv')\nval_loss_df.to_csv('\/kaggle\/working\/val_loss.csv')\n","1f5bf40d":"'''from tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\nfrom tensorflow.keras import applications\n\n\n# Downloading the pretrained model\n\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n\n#Initialising the model with inbuilt InceptionV3\npre_trained_model = InceptionV3(input_shape = (256, 256, 3), \n                                weights='imagenet',\n                                include_top = False, \n                                )\n\n\n#Setting the layers as not trainable, as we want it to use the pretrained weights during epochs\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \n\npre_trained_model.summary()\n\n#Pointing towards a stage in the model (refer Summary), we are telling that last_layer will be the 'mixed6' layer, similarly we assign the last output which need not be trained\nlast_layer = pre_trained_model.get_layer('mixed6') #Tried mixed7\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output'''","ec0be525":"'''## Adding our paramaters to the model\n\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_acc')>0.97):\n            print(\"\\nReached 97% validation accuracy so cancelling training!\")\n            self.model.stop_training = True\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nfrom tensorflow.keras.optimizers import Adam\n# Flatten the output layer to 1 dimension\n\nx = layers.GlobalAveragePooling2D()(last_output)\n\nx = layers.Dropout(0.5)(x) \n\nx = layers.Conv2D(256,(3,3),activation='relu')(x)\nx = layers.layers.BatchNormalization(axis=-1)(x)\nx = layers.MaxPooling2D(2, 2)(x)\n\n\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Conv2D(128,(3,3),activation='relu')(x)\nx = layers.layers.BatchNormalization(axis=-1)(x)\nx = layers.MaxPooling2D(2, 2)(x)\n\n\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Conv2D(64,(3,3),activation='relu')(x)\nx = layers.layers.BatchNormalization(axis=-1)(x)\nx = layers.MaxPooling2D(2, 2)(x)\n\nx = layers.Flatten()(x)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.3\nx = layers.Dense(1024, activation='relu')(x)\n\nx = layers.Dense(512, activation='relu')(x)\n\nx = layers.Dropout(0.5)(x)                  \n# Add a final softmax layer for classification into 15 categories\nx = layers.Dense(15, activation='softmax')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\ndef top_3_categ_acc(y_pred,y_true):\n    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n\ndef top_5_categ_acc(y_pred,y_true):\n    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=1e-4),\n              metrics=['acc'])#,top_3_categ_acc,top_5_categ_acc])\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=70,\n      width_shift_range=0.5,\n      height_shift_range=0.5,\n      shear_range=0.4,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      #vertical_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Flow training images in batches of 100 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        training_dir,  # This is the source directory for training images\n        target_size=(256, 256),  # All images will be resized to 256x256\n        batch_size=64,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(256, 256),\n        batch_size=64,\n        class_mode='categorical')\n\ncallbacks = myCallback()\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=258,  # 16512 images = batch_size * steps\n      epochs=50,\n      validation_data=validation_generator,\n      validation_steps=64,  # 4126 images = batch_size * steps\n      verbose=1,\n      callbacks = [callbacks])'''","cd20563b":"'''\nimport matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n\nacc_l= pd.DataFrame(acc)\nval_acc_l=pd.DataFrame(val_acc)\n\nacc_l.to_csv('accuracy.csv')\nval_acc_l.to_csv('val_acc.csv')\n\n\nmodel.save('DeepLearn.h5')\nmodel.save_weights('DeepLearn_Weights.h5')\n'''","22feae04":"# Making directories from the dataset so that ImageGenerator can be used\n\nWe have to split the sub-directories into validation and training set, so creating ","49c0d8dc":"Since I will be using ImageGenerator, a class wise folder generation will be needed. So I have used os library as well as shell scripting has been used to split samples into validation and training set in 20-80 split ratio. \n\nThe dataset had 15 subfolders each containing leaf images corresponding to the labels given by their folder name.","65245e63":"# Splitting Data into Training and Validation Set in 80-20 ratio\n\nSplitting the data into 80-20 ratio across each of folders (Validation and Training)\n\n**We need to make sure that the division of the data, while being random, should be stratified across classes. Which means we need to make sure that the division is uniform across classes as well, the loop below makes sure that the division is stratified and random(within the folders)**","b0ebc130":"Counting number of samples across each class","66c2fdd9":"Since the dataset which has been imported is read-only, we need to make a copy in our \/kaggle\/input\/ directory","e67b9e5f":"# Architecture\n\nUsing Keras Library to build our architecture\n\n\nThe model has been updated over each commit.\n\nv9\nFilter size has been changed from 3x3 to 2x2.\n\nv10\nChanged filter size to 3x3 on top layers, whereas 2x2 on lower layers to learn smaller abstractions.\n\nv11\nChanged n_epochs to 100. Increased learning rate to 1e-3\n\nNB: **The model has used 3 callbacks**\n\n* EarlyStopping\n* Decrease Learning Rate if the learning hits a plateau\n* \n\n","75e4715d":"In this kernel, I will be dealing with Plant Disease Dataset. The dataset has been taken from SP Mohanty's repository. The data set has ~20000 images belonging to 15 classes from 3 crops. ","66f3d484":"[](http:\/\/)* * Using Inception Net to achieve better accuracy"}}