{"cell_type":{"948a5636":"code","f9293880":"code","0de686da":"code","7f99b112":"code","5c61ebb3":"code","5bb8cfc1":"code","2172a4ab":"code","5a111c11":"code","44e31a00":"code","767bdb81":"code","f476ab64":"code","f745571c":"code","de7724a9":"code","6e8ec450":"code","e1297750":"code","fd8ee475":"code","039d72b2":"code","6510f252":"code","27c4139b":"code","a97da8b3":"code","9d013878":"code","844d5ba8":"code","2b277603":"code","7784a0f2":"code","1ccdd83b":"code","6fed900f":"code","6f588e62":"code","42c79a29":"code","efdf2f4d":"code","075ff0ce":"code","25c39b94":"markdown","84f9421f":"markdown","de430ced":"markdown","187bb067":"markdown","ee9d103e":"markdown","a625c248":"markdown","b748659a":"markdown","ce19a884":"markdown","239cc50b":"markdown","9eda6bee":"markdown","94a0786f":"markdown","eeb3e5d0":"markdown","cd181534":"markdown","2357b662":"markdown","543f880e":"markdown","a4f9f7de":"markdown","80851554":"markdown","47dc9413":"markdown","463f41c1":"markdown","2934ef6e":"markdown","27288ca8":"markdown","ac75def7":"markdown","663db46c":"markdown","2295d2a1":"markdown","8321622a":"markdown","12327595":"markdown","069a5dde":"markdown"},"source":{"948a5636":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.utils import plot_model\nfrom IPython.display import Image\nfrom keras.utils.np_utils import to_categorical","f9293880":"df1 = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf2 = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","0de686da":"df1.head()","7f99b112":"Y_train = df1[\"label\"]\nX_train = df1.drop(labels = [\"label\"],axis = 1).values ","5c61ebb3":"fig = plt.figure(figsize=(20,20))\nfor i in range(6):\n    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n    ax.imshow(X_train[i].reshape(28,28), cmap='gray')\n    ax.set_title(str(Y_train[i]))","5bb8cfc1":"def visualize_input(img, ax):\n    ax.imshow(img, cmap='gray')\n    width, height = img.shape\n    thresh = img.max()\/2.5\n    for x in range(width):\n        for y in range(height):\n            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n                        horizontalalignment='center',\n                        verticalalignment='center',\n                        color='white' if img[x][y]<thresh else 'black')\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nvisualize_input(X_train[9].reshape(28,28), ax)","2172a4ab":"g = sns.countplot(Y_train)","5a111c11":"X_train = X_train\/255.0\nX_test = df2\/255.0","44e31a00":"X_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)","767bdb81":"Y_train = to_categorical(Y_train, num_classes = 10)","f476ab64":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=7)","f745571c":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","de7724a9":"plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\nImage(\"model.png\")","6e8ec450":"epochs = 30\nbatch_size = 64","e1297750":"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","fd8ee475":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","039d72b2":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","6510f252":"image_gen=ImageDataGenerator(rotation_range=10,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=False,vertical_flip=False,fill_mode='nearest')","27c4139b":"train_image_gen=image_gen.fit(X_train)","a97da8b3":"model.fit_generator(image_gen.flow(X_train, Y_train, batch_size=batch_size), epochs=epochs, validation_data = (X_val, Y_val), callbacks = [learning_rate_reduction])","9d013878":"metrics=pd.DataFrame(model.history.history)\nmetrics","844d5ba8":"metrics[['loss' , 'val_loss']].plot()\nplt.show()","2b277603":"metrics[['accuracy' , 'val_accuracy']].plot()\nplt.show()","7784a0f2":"np.random.seed(16)\nrandom_selection=np.random.randint(0,4201,size=1)\nrandom_sample=X_val[random_selection]\nprint('Prediction:')\nprint(model.predict_classes(random_sample.reshape(1,28,28,1))[0])\nplt.imshow(random_sample.reshape(28,28),cmap='binary')\nplt.show","1ccdd83b":"np.random.seed(9)\nrandom_selection=np.random.randint(0,4201,size=1)\nrandom_sample=X_val[random_selection]\nprint('Prediction:')\nprint(model.predict_classes(random_sample.reshape(1,28,28,1))[0])\nplt.imshow(random_sample.reshape(28,28),cmap='binary')\nplt.show","6fed900f":"np.random.seed(27)\nrandom_selection=np.random.randint(0,4201,size=1)\nrandom_sample=X_val[random_selection]\nprint('Prediction:')\nprint(model.predict_classes(random_sample.reshape(1,28,28,1))[0])\nplt.imshow(random_sample.reshape(28,28),cmap='binary')\nplt.show","6f588e62":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\nY_pred = model.predict(X_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","42c79a29":"results = model.predict(X_test)","efdf2f4d":"results = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","075ff0ce":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","25c39b94":"<a id='13'><\/a>\n## Callback Technique\nYou define and use a callback when you want to automate some tasks after every training\/epoch that help you have controls over the training process. This includes stopping training when you reach a certain accuracy\/loss score, saving your model as a checkpoint after each successful epoch, adjusting the learning rates over time, and more.\nHere I am using ReduceLRonPlateau technique which reduces learning rate when a metric has stopped improving.","84f9421f":"<a id='6'><\/a>\n### Plotting first six training images","de430ced":"<a id='9'><\/a>\n## Encoding the Label column\nLabels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors using the to_categorical function from the keras.<br> (eg:- 5 -> [0,0,0,0,0,1,0,0,0,0]).","187bb067":"### Let us see how many each digits are present","ee9d103e":"If you are a beginner to Deep Learning or if you are confused to which framework to choose refer my this notebook and it will definately help you:-\n<div class=\"row\" align=\"center\">\n    <div class = \"card\">\n      <div class = \"card-body\" style = \"width: 20rem; \">\n        <h5 class = \"card-title\" style = \"font-size: 1.2em;\"align=\"center\">Choosing a correct Deep Learning Framework<\/h5>\n          <img src=\"https:\/\/deepsense.ai\/wp-content\/uploads\/2019\/02\/Keras-or-PyTorch.png\" class = \"card_img-top\" style = \"padding: 2% 0;width:19rem;height:10rem;\"  alt=\"...\">\n        <p class=\"card-text\" style = \"font-size: 1.0em;text-align: center \"><b>Keras VS PyTorch: A perfect guide<\/b><\/p>\n        <a href = \"https:\/\/www.kaggle.com\/utcarshagrawal\/keras-vs-pytorch-a-perfect-guide\" class = \"btn btn-info btn-lg active\"  role = \"button\" style = \"color: white; margin: 0 15% 0 25%\" data-toggle = \"popover\" title = \"Click\">Click here<\/a>\n      <\/div>\n    <\/div>\n  <\/div>","a625c248":"<a id='4'><\/a>\n# **CNN Model**","b748659a":"<a id='11'><\/a>\n#### Now we come to the most important part of our notebook.\n\nFirstly, we will define our model to be a Sequential model.\nThen we add our first layer i.e. a convolutional(Conv2D) layer. So what does a convolutional layer perform?\n- Takes an input volume \n- Applies a filter at every position of the input\n- Outputs another volume (usually of different size)\n\n## **Like this:-** \n\n![Convolution_schematic.gif](attachment:Convolution_schematic.gif)\n<caption><center> <u> <font color='purple'>Convolution operation<br> with a filter of 3x3 and a stride of 1 (stride = amount you move the window each time you slide)<\/font><\/u> <\/center><\/caption>\n\n<br>In a computer vision application like this competition, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias.\n\nNext we add a BatchNormalization layer. Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n<br>  \nThen again we add a convolutional layer and a batch normalization layer. After that we add a pooling layer. Here we are adding a MaxPool2D layer.The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input.\n<br>(Max-pooling layer: slides an (f,f) window over the input and stores the max value of the window in the output.)\n![max_pool1.png](attachment:max_pool1.png)\n<br> Then, we add a Dropout Layer. A Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.<br>\n\nWe repeat the whole process one more time. Then we add a Flatten layer. A flatten layer collapses the spatial dimensions of the input into the channel dimension.\n<br>    \nLastly, just add two dense layers followed by a batch normalization layer and one dropout layer. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.","ce19a884":"<a id='16'><\/a>\n## Evaluating our model","239cc50b":"<a id='7'><\/a>\n## Normalization\nTo represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\n\nOne common preprocessing step in machine learning is to normalize our dataset, meaning divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).","9eda6bee":"### Let us visualize how are images stored in matrix form","94a0786f":"<a id='10'><\/a>\nLet's split our data into training and validation set and we are going to use the train_test_split function of sklearn library for this step.","eeb3e5d0":"# **Table of Contents**\n<ul style=\"list-style-type: square;\">\n    <li><a href='#1'>Importing Libraries<\/a><\/li>\n    <li><a href='#2'>Reading the data<\/a><\/li>\n    <li><a href='#3'>Data Preparation<\/a><\/li>\n    <ul>\n        <li><a href='#6'>Visualization<\/a><\/li>\n        <li><a href='#7'>Normalization<\/a><\/li>\n        <li><a href='#8'>Reshaping<\/a><\/li>\n        <li><a href='#9'>Encoding<\/a><\/li>\n        <li><a href='#10'>Splitting the data<\/a><\/li>\n    <\/ul>\n    <li><a href='#4'>CNN Model<\/a><\/li>\n    <ul>\n        <li><a href='#11'>Explanation of layers<\/a><\/li>\n        <li><a href='#12'>Optimizer<\/a><\/li>\n        <li><a href='#13'>Callback Technique<\/a><\/li>\n        <li><a href='#14'>Data Augmentation<\/a><\/li>\n        <li><a href='#15'>Training our model<\/a><\/li>\n        <li><a href='#16'>Evaluating our model<\/a><\/li>\n    <\/ul>\n    <li><a href='#5'>Submission<\/a><\/li>\n<\/ul>","cd181534":"<a id='8'><\/a>\n## Reshaping our data","2357b662":"<a id='15'><\/a>\n### So we have completed all the pre processes. Now its time to train our model.","543f880e":"<a id='3'><\/a>\n# **Data Preparation**","a4f9f7de":"<a id='0'><\/a>\n<font size=\"+2\" color=\"blue\"><b>My other kernels<\/b><\/font><br>\n<div class=\"row\">\n    <div class=\"col-sm-4\">\n    <div class = \"card\">\n      <div class = \"card-body\" style = \"width: 20rem; \">\n        <h5 class = \"card-title\" style = \"font-size: 1.2em;\"align=\"center\">Natural Language Processing<\/h5>\n          <img src=\"https:\/\/media-exp1.licdn.com\/dms\/image\/C561BAQGEbzpXZ34-gQ\/company-background_10000\/0?e=2159024400&v=beta&t=o3vOn3Ye-qpqlDH64A1of1_aRAQ8TunahPQ4ZWuISRI\" class = \"card_img-top\" style = \"padding: 2% 0;width:20rem;height:12rem;\"  alt=\"...\">\n        <p class=\"card-text\" style = \"font-size: 1.0em;text-align: center \"><b>NLP model: The easiest way !<\/b><\/p>\n        <a href = \"https:\/\/www.kaggle.com\/utcarshagrawal\/nlp-model-the-easiest-way\" class = \"btn btn-info btn-lg active\"  role = \"button\" style = \"color: white; margin: 0 15% 0 25%\" data-toggle = \"popover\" title = \"Click\">Click here<\/a>\n      <\/div>\n    <\/div>\n  <\/div>\n    <div class=\"col-sm-4\">\n      <div class=\"card\">\n        <div class=\"card-body\" style=\"width: 20rem;\">\n          <h5 class = \"card-title\"  style = \"font-size: 1.2em; \" align=\"center\" > Tutorial on Spark ML <\/h5>\n            <img src = \"https:\/\/miro.medium.com\/max\/650\/1*mzhf9OccFn7DeVHI9dPiLQ.jpeg\" class = \"card_img-top\" style = \" padding: 2% 0;width:20rem;height:12rem;\"  alt=\"...\">\n          <p class=\"card-text\" style = \"font-size: 1.0em;text-align: center \"><b>Titanic:Spark ML Magic + EDA & Feature Engineering<\/b><\/p>\n          <a href = \"https:\/\/www.kaggle.com\/utcarshagrawal\/titanic-spark-ml-magic-eda-feature-engineering\" class = \"btn btn-info btn-lg active\"  role = \"button\" style = \"color: white; margin: 0 15% 0 25%\" data-toggle = \"popover\" title = \"Click\">Click here<\/a>\n        <\/div>\n      <\/div>    \n    <\/div>\n      <div class=\"col-sm-4\">\n        <div class=\"card\">\n          <div class=\"card-body\" style=\"width: 20rem;\">\n            <h5 class = \"card-title\"  style = \"font-size: 1.2em; \" align=\"center\" > More on Spark ML <\/h5>\n              <img src = \"https:\/\/cdn.hswstatic.com\/gif\/water-life-crop.jpg\" class = \"card_img-top\" style = \" padding: 2% 0;width:20rem;height:12rem;border-radius:20%\"  alt=\"...\">\n            <p class=\"card-text\" style = \"font-size: 1.0em;text-align: center \"><b>Water Quality Prediction using Spark ML<\/b><\/p>\n            <a href = \"https:\/\/www.kaggle.com\/utcarshagrawal\/water-quality-prediction-using-sparkml\/notebook\" class = \"btn btn-info btn-lg active\"  role = \"button\" style = \"color: white; margin: 0 15% 0 25%\" data-toggle = \"popover\" title = \"Click\">Click here<\/a>\n          <\/div>\n        <\/div>    \n      <\/div>\n    <\/div>    \n    ","80851554":"Let us see the summary of our model. Here we are going to plot the model summary using plot_model.","47dc9413":"<a id='12'><\/a>\n## Define the optimizer\nOptimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses. Optimization algorithms or strategies are responsible for reducing the losses and to provide the most accurate results possible.\n![](https:\/\/cs231n.github.io\/assets\/nn3\/opt1.gif)\nWe have many options for optimizers and I tried many options and RMSprop gave me the best result.\n<br>\n\nThen we will compile our model with RMSprop optimizer and categorical_crossentropy as loss function.","463f41c1":"### So this is it. I hope I have tried to explain each and every thing. But if you still have any doubt\n![1_yIPIuNIn6ar7MvQnNqlWlQ.jpeg](attachment:1_yIPIuNIn6ar7MvQnNqlWlQ.jpeg)\n### Just comment below I will definitely try to solve your problem.\n<b>Also, if you want to know about Spark ML and some of its different techniques or about NLP you can refer my other kernels :-<\/b> [My other kernels](#0) \n\n<h3><font color = \"red\">Thanks a lot for having a look at this notebook. I would like to get an appreciation from you with an upvote. Please upvote if you liked the kernel.<\/font><\/h3>","2934ef6e":"### Let's see some of our predictions","27288ca8":"<a id = '1'><\/a>\n# **Importing Libraries**","ac75def7":"<a id='2'><\/a>\n# **Reading the data**","663db46c":"## What is CNN?\nConvolutional Neural Network(CNN) are powerful image processing, artificial intelligence (AI) that use deep learning to perform both generative and descriptive tasks, often using machine vison that includes image and video recognition, along with recommender systems and natural language processing (NLP). A CNN uses a system much like a multilayer perceptron that has been designed for reduced processing requirements. The layers of a CNN consist of an input layer, an output layer and a hidden layer that includes multiple convolutional layers, pooling layers, fully connected layers and normalization layers. The removal of limitations and increase in efficiency for image processing results in a system that is far more effective, simpler to trains limited for image processing and natural language processing.","2295d2a1":"<a id='5'><\/a>\n# Submission","8321622a":"<a id='14'><\/a>\n## Data Augmentation\nThe performance of deep learning neural networks often improves with the amount of data available.\nMany people have downloaded mnist data to increase the model. But a more appropriate way to increase the data is to apply data augmentation technique.\n\nData augmentation is a technique to artificially create new training data from existing training data. This is done by applying domain-specific techniques to examples from the training data that create new and different training examples.\n\nImage data augmentation is perhaps the most well-known type of data augmentation and involves creating transformed versions of images in the training dataset that belong to the same class as the original image.\n\nTransforms include a range of operations from the field of image manipulation, such as shifts, flips, zooms, and much more.\n\nI am applying data augmentation technique by using ImageDataGenerator function from keras and what I have done is:-\n\n* Randomly rotate some training images by 10 degrees\n* Randomly zoom by 10% \n* Randomly shear by 10%\n* Randomly shift images horizontally by 10% of the width\n* Randomly shift images vertically by 10% of the height ","12327595":"## Confusion Matrix","069a5dde":"# **Introduction**\nIn this kernel I will go through detailed explanation of CNN Model. This notebook will work as a perfect tutorial for beginers who are working first time with the CNN. I will start with preparing the data so that we can use it for our model. Then coming to the model part, I will explain each layer of the model so that you know the insights of what each layer is actually doing. Then we will talk about optimizers, callback techniques and data augmentation technique in detail. Finally we will evalaute our model and check how our model is working.<br>\nThis notebook will give you 0.9956 score. Play with some hyperparamters and you might get a better score. I will also update this notebook if I get a better score.\n\n<h2><font color = \"red\">Please do an upvote if you find the kernel useful.<\/font><\/h2>"}}