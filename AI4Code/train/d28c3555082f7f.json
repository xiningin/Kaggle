{"cell_type":{"6d43716d":"code","756ce4d7":"code","c4684435":"code","adf33d17":"code","fbfa2306":"code","c4ae0cdf":"code","25fb2e78":"code","fbe1da8e":"code","88c8b8cd":"code","bfff0eb6":"code","27c2fbff":"code","c79ddacc":"code","44076018":"code","aedb4679":"markdown","3c642868":"markdown","cb1b3b7a":"markdown","0f1b354b":"markdown","f9001d1d":"markdown","faf2b126":"markdown","b7a8d849":"markdown","bcad6a43":"markdown","8162d4fd":"markdown","8177ed9e":"markdown","15e92826":"markdown","548d08bd":"markdown","4f822b53":"markdown","2d2ed0d0":"markdown"},"source":{"6d43716d":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https:\/\/pypi.org\/simple\/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'","756ce4d7":"debug = False","c4684435":"import numpy as np\n\nfrom kaggle_environments import evaluate, make, utils\n# Since utils.get_last_callable moved to agent.get_last_callable\n# See https:\/\/github.com\/Kaggle\/kaggle-environments\/blob\/e4a5651a3a0775b823fc27fe2c24b55cbd340420\/kaggle_environments\/agent.py#L37\nfrom kaggle_environments import agent as kaggle_env_agent","adf33d17":"env = make(\"connectx\", debug=True)\nenv.render()","fbfa2306":"# This agent one-step lookahead chooses a non-empty column\n# kaggle.com\/alexisbcook\/one-step-lookahead\ndef my_agent(observation, configuration, N_STEPS=3, cutoff_time=None, cutoff_time_offset=0.6, debug=True):\n    '''\n    '''\n    import numpy as np\n    import random\n    import time\n    \n    # Parameters for keeping track of time while searching deeply\n    START_TIME = time.time()\n    \n    # Use the configurations action timeout as basis the cutoff time\n    if cutoff_time is None:\n        cutoff_time = (configuration.get('actTimeout',cutoff_time) - cutoff_time_offset)\n        \n    if debug:\n        print(f'###### Turn {observation.board.count(1):02} ######') \n        # Just to check for debugging (first 2 turns)\n        if observation.board.count(1) <= 1:\n            print(f'\"configuration\":{configuration}')   \n        print('Cutoff Time:',cutoff_time)\n        print(f'Using {N_STEPS} step lookahead')\n\n    # Helper function for score_move: gets board at next step if agent drops piece in selected column\n    def drop_piece(grid, col, mark, config):\n        next_grid = grid.copy()\n        for row in range(config.rows-1, -1, -1):\n            if next_grid[row][col] == 0:\n                break\n        next_grid[row][col] = mark\n        return next_grid\n\n    # Helper function for get_heuristic: checks if window satisfies heuristic conditions\n    def check_window(window, num_discs, piece, config):\n        return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n\n    # Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n    def count_windows(grid, num_discs, piece, config):\n        num_windows = 0\n        # horizontal\n        for row in range(config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[row, col:col+config.inarow])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # vertical\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns):\n                window = list(grid[row:row+config.inarow, col])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # positive diagonal\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # negative diagonal\n        for row in range(config.inarow-1, config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        return num_windows\n\n    # Helper function for score_move: gets board at next step if agent drops piece in selected column\n    def drop_piece(grid, col, mark, config):\n        next_grid = grid.copy()\n        for row in range(config.rows-1, -1, -1):\n            if next_grid[row][col] == 0:\n                break\n        next_grid[row][col] = mark\n        return next_grid\n\n    # Helper function for minimax: calculates value of heuristic for grid\n    def get_heuristic(grid, mark, config):\n        num_twos = count_windows(grid, 2, mark, config)\n        num_threes = count_windows(grid, 3, mark, config)\n        num_fours = count_windows(grid, 4, mark, config)\n        num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n        num_fours_opp = count_windows(grid, 4, mark%2+1, config)\n        # Only consider fours & threes\n        score = 1e6*num_fours + 1e0*num_threes - 1e2*num_threes_opp - 1e4*num_fours_opp \n        return score\n\n    # Uses minimax to calculate value of dropping piece in selected column\n    def score_move(grid, col, mark, config, nsteps, time_to_search_col=None):\n        next_grid = drop_piece(grid, col, mark, config)\n        # Note the time we should stop searching\n        if time_to_search_col is None:\n            time_to_search_col = (cutoff_time\/config.columns)\n        stop_search_time = time.time() + time_to_search_col\n        # If time is getting close, stop everything!\n        if (time.time() - START_TIME ) >= stop_search_time:\n            print('timeout!!')\n            score = get_heuristic(grid, mark, config)\n        else:\n            minimax_out = minimax(next_grid, nsteps-1, False, mark, config, stop_search_time)\n            score = minimax_out\n        if debug:\n            summary_stats = {\n                'column': col,\n                'score': score,\n                'nsteps_to_take': nsteps,\n                'time_to_search_col': time_to_search_col,\n                'time_elapsed':time.time() - START_TIME\n            }\n            print(f'\"summary_stats\":{summary_stats}')\n        return score\n\n    # Helper function for minimax: checks if agent or opponent has four in a row in the window\n    def is_terminal_window(window, config):\n        return window.count(1) == config.inarow or window.count(2) == config.inarow\n\n    # Helper function for minimax: checks if game has ended\n    def is_terminal_node(grid, config):\n        # Check for draw \n        if list(grid[0, :]).count(0) == 0:\n            return True\n        # Check for win: horizontal, vertical, or diagonal\n        # horizontal \n        for row in range(config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[row, col:col+config.inarow])\n                if is_terminal_window(window, config):\n                    return True\n        # vertical\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns):\n                window = list(grid[row:row+config.inarow, col])\n                if is_terminal_window(window, config):\n                    return True\n        # positive diagonal\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n                if is_terminal_window(window, config):\n                    return True\n        # negative diagonal\n        for row in range(config.inarow-1, config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n                if is_terminal_window(window, config):\n                    return True\n        return False\n\n    # Minimax implementation\n    def minimax(node, depth, maximizingPlayer, mark, config, timeout_elapsed):\n        is_terminal = is_terminal_node(node, config)\n        valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n        # Could help being biased looking at the left-side of the board\n        random.shuffle(valid_moves)\n        # Check if we've reached the cutoff time\n        elapsed_time = time.time() - START_TIME\n        if (elapsed_time >= timeout_elapsed):\n            # If time runs out, just look for the current heuristic at this depth\n            return get_heuristic(node, mark, config)\n        elif depth == 0 or is_terminal:\n            return get_heuristic(node, mark, config)\n        if maximizingPlayer:\n            value = -np.Inf\n            for col in valid_moves:\n                child = drop_piece(node, col, mark, config)\n                # Get the deepest it went\n                minimax_out = minimax(child, depth-1, False, mark, config, timeout_elapsed)\n                value = max(value, minimax_out)\n        else:\n            value = np.Inf\n            for col in valid_moves:\n                child = drop_piece(node, col, mark%2+1, config)\n                minimax_out = minimax(child, depth-1, True, mark, config, timeout_elapsed)\n                value = min(value, minimax_out)\n        return value\n\n    # Get list of valid moves\n    valid_moves = [c for c in range(configuration.columns) if observation.board[c] == 0]\n    # Could help being biased looking at the left-side of the board\n    random.shuffle(valid_moves)\n    # Allow a given amount of time to search\n    time_to_search = (cutoff_time\/len(valid_moves))\n    # Convert the board to a 2D grid\n    grid = np.asarray(observation.board).reshape(configuration.rows, configuration.columns)\n    # Use the heuristic to assign a score to each possible board in the next step\n    scores = dict(zip(valid_moves, [score_move(grid, col, observation.mark, configuration, N_STEPS, time_to_search) for col in valid_moves]))\n    # Get a list of columns (moves) that maximize the heuristic\n    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n    # Select at random from the maximizing columns    \n    chosen_col = random.choice(max_cols)\n    \n    # Try to pick the middle column if it is maximal choice\n    mid_col = configuration.columns \/\/ 2\n    if mid_col in max_cols:\n        chosen_col = mid_col\n    \n    if debug:\n        print(f'Total time: {time.time()- START_TIME}')\n    \n    return chosen_col","c4ae0cdf":"env.reset()\n# Play against \"negamax\" agent until my agent loses\ntest_agent = debug # Set to True to test \ndebug_agent = lambda x,y: my_agent(x,y, debug=True)\nwhile test_agent:\n    env.reset()\n    env.run([debug_agent, 'negamax'])\n    # Don't count ties as losses\n    if len(env.steps) == 43:\n        print('tie')\n    elif len(env.steps) % 2 == 1:\n        print('lost')\n        break\n    else:\n        print('won')\n    print('=======')\nenv.render(mode=\"ipython\", width=500, height=450)","25fb2e78":"# Play as first position against random agent.\ntrainer = env.train([None, \"negamax\"])\n\nobservation = trainer.reset()\n\nwhile debug and not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","fbe1da8e":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) \/ float(len(rewards))\n\n# Run multiple episodes to estimate its performance.\nif debug:\n    print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\n    print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))","88c8b8cd":"# \"None\" represents which agent you'll manually play as (first or second player).\nenv.play([None, my_agent], width=500, height=450)","bfff0eb6":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)","27c2fbff":"submission_file = 'submission.py'\nwrite_agent_to_file(my_agent, submission_file)","c79ddacc":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\nsubmission = utils.read_file(\"\/kaggle\/working\/submission.py\")\nagent = kaggle_env_agent.get_last_callable(submission)\nsys.stdout = out","44076018":"env = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","aedb4679":"# Debug\/Train your Agent","3c642868":"We're using a few modifications from the [minimax algorith](https:\/\/en.wikipedia.org\/wiki\/Minimax):\n\n- Search only doing up to **3-step lookahead**\n- Split the time limit for each (valid) column to search\n- If scores are equal with the middle column, **choose the middle column**","cb1b3b7a":"# Submit to Competition\n\n1. Save this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https:\/\/kaggle.com\/c\/connectx\/submissions) to view your score and episodes being played.","0f1b354b":"# Write Submission File\n\n","f9001d1d":"# Validate Submission\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely.","faf2b126":"# Play your Agent\nClick on any column to place a checker there (\"manually select action\").","b7a8d849":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n","bcad6a43":"# Install kaggle-environments","8162d4fd":"# Create ConnectX Environment","8177ed9e":"# Motivation","15e92826":"## About this algorithm","548d08bd":"Although more advanced algorithms to search for different policies, this notebook (and it's versions) attempts to show how a relatively simple search with some modification can do a decent job in this problem.","4f822b53":"# Evaluate your Agent","2d2ed0d0":"# Test your Agent"}}