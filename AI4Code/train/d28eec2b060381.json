{"cell_type":{"b811037b":"code","b41e6d9b":"code","3c401b60":"code","14372026":"code","2b78817b":"code","3cd7a231":"code","f995115b":"code","3f9aae1c":"code","4c5bf7c9":"code","66fdc9d5":"code","b17e0578":"code","25d33fdd":"code","dfc0d100":"code","c9c9877e":"code","fe4c3d1f":"code","ed0694f1":"code","89d4122f":"code","d5a4bac7":"code","063b8744":"code","b3a2868a":"code","7227cec1":"code","184d9763":"code","5503fcce":"code","47f9df84":"code","9aa06449":"code","fa5d25b1":"code","0bb6f8c9":"code","6b65d29a":"code","1979eba3":"code","03687f09":"code","019e0db0":"code","b412beff":"code","4fee8f6e":"code","b29d498e":"code","5fb6f39f":"code","db8c6e1c":"code","45cb9da6":"code","6ae8dbbd":"code","bb11e852":"code","6c199932":"code","bde63f0d":"code","58a0b4cb":"code","5264dff4":"code","d4c2cbe4":"code","7e89f240":"code","947c445a":"code","af5a1a24":"code","900a1c9c":"code","158fa467":"code","a846f6f1":"code","cc5312fe":"code","5d582d1e":"code","78b1fc95":"code","75d5a21f":"code","c459ea7e":"code","ad31a3ad":"markdown","a912c017":"markdown","1a011ef6":"markdown","6a707cbc":"markdown","2e6f3347":"markdown","53cfab5d":"markdown","c15cbb15":"markdown","e618aca3":"markdown","3b5a5a18":"markdown","588eac90":"markdown","7463ffc5":"markdown","e9d9afb3":"markdown","df36a506":"markdown","619ba86a":"markdown","e2e45cfd":"markdown","70d19be4":"markdown","10b03c95":"markdown","d31ac926":"markdown","d75c35ba":"markdown","d3008191":"markdown","ad9fd641":"markdown","acad1d95":"markdown","676dc4f2":"markdown","06bdabe5":"markdown","17ace6c7":"markdown","3d540a1c":"markdown","ed8f006b":"markdown","a1de2b5e":"markdown","8bf86aa0":"markdown","55b9604e":"markdown","e375698c":"markdown","1ade646d":"markdown","997bcbf5":"markdown","e048f358":"markdown","723d1b8c":"markdown","f0ca40ad":"markdown"},"source":{"b811037b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom pandas.plotting import scatter_matrix\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport os","b41e6d9b":"train_data = pd.read_csv(\"..\/input\/emotions-dataset-for-nlp\/train.txt\", sep=';',names=['text','emotion'])\ntest_data = pd.read_csv(\"..\/input\/emotions-dataset-for-nlp\/test.txt\", sep=';',names=['text','emotion'])\nvalidation_data = pd.read_csv(\"..\/input\/emotions-dataset-for-nlp\/val.txt\", sep=';',names=['text','emotion'])","3c401b60":"train_data.info()","14372026":"train_data.describe()","2b78817b":"list(train_data.emotion.unique())","3cd7a231":"train_data.head(10)","f995115b":"joy_text = train_data[train_data[\"emotion\"] == 'joy'][\"text\"].values\nfor i in range(0,5):\n    print(joy_text[i], \"\\n\")","3f9aae1c":"sadness_text = train_data[train_data[\"emotion\"] == 'sadness'][\"text\"].values\nfor i in range(0,5):\n    print(sadness_text[i], \"\\n\")","4c5bf7c9":"anger_text = train_data[train_data[\"emotion\"] == 'anger'][\"text\"].values\nfor i in range(0,5):\n    print(anger_text[i], \"\\n\")","66fdc9d5":"from wordcloud import WordCloud\nfrom nltk.corpus import stopwords\n# nltk.download('stopwords')\nstop_words = set(stopwords.words('english'))","b17e0578":"def get_wordcloud(text):\n    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stopwords.words('english')).generate(str(text))\n    \n    return wordcloud;","25d33fdd":"emotions = train_data[\"emotion\"].unique()\n\nfigure, axes = plt.subplots(ncols=2, nrows=3,figsize=(30,25))\nplt.axis('off')\n\n# for each emotion\nfor emotion, ax in zip(emotions, axes.flat):\n    wordcloud = get_wordcloud(train_data[train_data[\"emotion\"]==emotion]['text'])\n    ax.imshow(wordcloud)\n    ax.title.set_text(emotion)\n    ax.title.set_size(50)\n    \n    ax.axis('off')\n    \nplt.subplots_adjust(wspace=0.15, hspace=0.05)","dfc0d100":"train_data['emotion'].value_counts().plot(kind='barh')","c9c9877e":"train_data['emotion'].value_counts().plot(kind='pie')","fe4c3d1f":"# From https:\/\/towardsdatascience.com\/detecting-bad-customer-reviews-with-nlp-d8b36134dc7e\n\n# return the wordnet object value corresponding to the POS tag\nfrom nltk.corpus import wordnet\n\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n    \nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\n\ndef clean_text(text):\n    # lower text\n    text = text.lower()\n    # tokenize text and remove puncutation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # remove stop words\n    stop = stopwords.words('english')\n    text = [x for x in text if x not in stop]\n    # remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    # pos tag text\n    pos_tags = pos_tag(text)\n    # lemmatize text\n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)","ed0694f1":"# Train data\ntrain_data[\"text\"] = train_data[\"text\"].apply(lambda x: clean_text(x))\n\n# Test data\ntest_data[\"text\"] = test_data[\"text\"].apply(lambda x: clean_text(x))\n\n# ---\n# Let's take a look at the result\ntrain_data.head()","89d4122f":"# Train data\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nsid = SentimentIntensityAnalyzer()\ntrain_data[\"sentiments\"] = train_data[\"text\"].apply(lambda x: sid.polarity_scores(x))\ntrain_data = pd.concat([train_data.drop(['sentiments'], axis=1), train_data['sentiments'].apply(pd.Series)], axis=1)\n\ntrain_data.head()\n\n# Test data\nsid = SentimentIntensityAnalyzer()\ntest_data[\"sentiments\"] = test_data[\"text\"].apply(lambda x: sid.polarity_scores(x))\ntest_data = pd.concat([test_data.drop(['sentiments'], axis=1), test_data['sentiments'].apply(pd.Series)], axis=1)\n\n# test_data.head()","d5a4bac7":"test_data.shape","063b8744":"test_data.shape","b3a2868a":"train_data.head()","7227cec1":"from sklearn.metrics import make_scorer\nfrom sklearn.metrics import fbeta_score\nimport spacy\nfrom sklearn import preprocessing\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nimport pickle\n\n","184d9763":"# Create encoder based on train data\nlabelEncoder = preprocessing.LabelEncoder()\nlabelEncoder.fit(train_data.emotion)\n\n# Train data\ntrain_data.emotion = labelEncoder.transform(train_data.emotion)\n \n       \n# Validation data\n# validation_data.emotion = labelEncoder.transform(validation_data.emotion)\n\n# Test data\ntest_data.emotion = labelEncoder.transform(test_data.emotion)","5503fcce":"targets = labelEncoder.inverse_transform([0,1,2,3,4,5])\n","47f9df84":"targets","9aa06449":"list(train_data.emotion.unique())","fa5d25b1":"test_data.shape","0bb6f8c9":"train_data.head()","6b65d29a":"# Load the large model to get the vectors\nnlp = spacy.load('en_core_web_lg')","1979eba3":"def vectorize(dataset):\n    \"\"\"\n    Get vectors for data in parameter\n    =================================\n    \n    Parameters:\n        data:\n            Dataset\n    \"\"\"\n    with nlp.disable_pipes():\n        vectors = np.array([nlp(data.text).vector for index, data in dataset.iterrows()])\n        return vectors","03687f09":"# create doc2vec vector columns\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\n# Train data\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_data[\"text\"].apply(lambda x: x.split(\" \")))]\nmodel = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n\n# transform each document into a vector data\ndoc2vec_df = train_data[\"text\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\ndoc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\ntrain_data = pd.concat([train_data, doc2vec_df], axis=1)\n\ntrain_data.head()\n\n# Test data\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(test_data[\"text\"].apply(lambda x: x.split(\" \")))]\nmodel = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n\ndoc2vec_df = test_data[\"text\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\ndoc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\ntest_data = pd.concat([test_data, doc2vec_df], axis=1)","019e0db0":"# Train data\ntext_column_data = train_data.drop(train_data.columns.difference(['text']), 1, inplace=False)\ntrain_data_text_vectors = vectorize(text_column_data) \n\n# Test data\ntext_column_data = test_data.drop(test_data.columns.difference(['text']), 1, inplace=False)\ntest_data_text_vectors = vectorize(text_column_data)","b412beff":"text_column_data.head()","4fee8f6e":"test_data.shape","b29d498e":"test_data_text_vectors.shape","5fb6f39f":"train_data_text_vectors.shape","db8c6e1c":"type(train_data_text_vectors)","45cb9da6":"train_data.head()","6ae8dbbd":"# Training set\nX_train = pd.concat([pd.DataFrame(train_data_text_vectors), train_data.drop([\"emotion\", \"text\"], axis=1)], axis=1)\ny_train = train_data.emotion\n\nprint(\"X_train shape \", X_train.shape)\nprint(\"y_train shape \", y_train.shape)\n\n# Test set\nX_test = pd.concat([pd.DataFrame(test_data_text_vectors), test_data.drop([\"emotion\", \"text\"], axis=1)], axis=1)\ny_test = test_data.emotion\n","bb11e852":"X_test.shape","6c199932":"X_test.head()","bde63f0d":"X_train.head()","58a0b4cb":"def checkPerformances(classifier, best_clf):\n    \"\"\"\n    Check model performance with unoptimized \n    and optimized same model for comparison\n    =======================================\n    \n    Parameters:\n        classifier:\n            Basic unoptimized classifier model\n        best_clf:\n            Optimized classifier model\n    \"\"\"\n    # Make predictions using the unoptimized and optimized and model\n    predictions = (classifier.fit(X_train, y_train)).predict(X_test)\n    best_predictions = best_clf.predict(X_test)\n\n\n    # Report the before-and-afterscores\n    print(\"Unoptimized model\\n------\")\n    print(classifier)\n    print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n    print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5, average=\"micro\")))\n    print(\"\\nOptimized Model\\n------\")\n    print(best_clf)\n    print(\"\\nFinal accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n    print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5,  average=\"micro\")))","5264dff4":"scorer = make_scorer(fbeta_score, beta=0.5, average=\"micro\")\n\n# sklearn.metrics.accuracy_score","d4c2cbe4":"import os.path\nfrom os import path","7e89f240":"best_LR_clf_filepath = \"\/kaggle\/input\/modelsaves\/best_LR_clf_v2.pkl\"\n\nLR_clf = LogisticRegression(random_state = 0)\nif not path.exists(best_LR_clf_filepath):\n    print(\"Performing GridSearch for LR\")\n    LR_parameters = {\n        'penalty': ['l1', 'l2'],\n        'C': np.logspace(0, 4, 10)\n        }\n\n    # Run the grid search\n    grid_obj = GridSearchCV(LR_clf, LR_parameters, scoring=scorer)\n    grid_obj = grid_obj.fit(X_train, y_train)\n\n    # Set the regressor to the best combination of parameters\n    best_LR_clf = grid_obj.best_estimator_\n\n    best_LR_clf\n\n    # save the model\n    pickle.dump(best_LR_clf, open(\"\/kaggle\/working\/best_LR_clf_v2.pkl\", 'wb'))\nelse:\n    print(\"Best LR file loading\")\n    best_LR_clf = pickle.load(open(best_LR_clf_filepath, 'rb'))\n    \n# check performances\ncheckPerformances(LR_clf, best_LR_clf)","947c445a":"best_SVM_clf_filepath = \"\/kaggle\/input\/modelsaves\/best_SVM_clf_v2.pkl\"\nSVM_clf = SVC()\nif not path.exists(best_SVM_clf_filepath):\n    print(\"Performing GridSearch for SVM\")\n    SVM_parameters = {\n        'kernel': ['linear', 'poly', 'rbf'],\n        'degree': [1, 2, 3, 4],\n        'shrinking' : [True, False]\n        }\n\n    # Run the grid search\n    grid_obj = GridSearchCV(SVM_clf, SVM_parameters, scoring='accuracy')\n    grid_obj = grid_obj.fit(X_train, y_train)\n\n    # Set the regressor to the best combination of parameters\n    best_SVM_clf = grid_obj.best_estimator_\n    \n    # save the model\n    pickle.dump(best_SVM_clf, open(\"\/kaggle\/working\/best_SVM_clf_v2.pkl\", 'wb'))\nelse:\n    print(\"Best SVM file loading\")\n    best_SVM_clf = pickle.load(open(best_SVM_clf_filepath, 'rb'))\n    \n# check performances\ncheckPerformances(SVM_clf, best_SVM_clf)","af5a1a24":"best_DT_clf_filepath = \"\/kaggle\/input\/modelsaves\/best_DT_clf_v2.pkl\"\n\nDT_clf = DecisionTreeClassifier()\n\nif not path.exists(best_DT_clf_filepath):\n    print(\"Performing GridSearch for DT\")\n    DT_parameters = {\n        'criterion': ['gini', 'entropy'],\n        'min_samples_leaf': [1, 2, 3, 4]\n        }\n\n    # Run the grid search\n    grid_obj = GridSearchCV(DT_clf, DT_parameters, scoring=scorer)\n    grid_obj = grid_obj.fit(X_train, y_train)\n\n    # Set the regressor to the best combination of parameters\n    best_DT_clf = grid_obj.best_estimator_\n    \n    # save the model\n    pickle.dump(best_DT_clf, open(\"\/kaggle\/working\/best_DT_clf_v2.pkl\", 'wb'))\nelse:\n    print(\"Best DT file loading\")\n    best_DT_clf = pickle.load(open(best_DT_clf_filepath, 'rb'))\n    \ncheckPerformances(DT_clf, best_DT_clf)","900a1c9c":"# from sklearn.ensemble import RandomForestClassifier\n# RF_clf = RandomForestClassifier(max_depth=None, random_state=None)\n\n# best_RF_clf_filepath = \"\/kaggle\/working\/best_RF_clf.pkl\"\n\n# if not path.exists(best_RF_clf_filepath):\n#     parameters = {'n_estimators': [10, 20, 30, 100], 'max_features':[3,4,5, None], 'max_depth': [5,6,7, None], 'criterion': ['gini', 'entropy']}\n#     grid_obj = GridSearchCV(RF_clf, parameters, scoring=scorer)\n#     grid_fit = grid_obj.fit(X_train, y_train)\n\n#     # Get the estimator\n#     best_RF_clf = grid_fit.best_estimator_\n    \n    \n#     # save the model\n#     pickle.dump(best_RF_clf, open(best_RF_clf_filepath, 'wb'))\n# else:\n#     print(\"Best RF file loading\")\n#     best_RF_clf = pickle.load(open(best_RF_clf_filepath, 'rb'))\n    \n# checkPerformances(classifier=RF_clf, best_clf=best_RF_clf)","158fa467":"NB_clf = GaussianNB()\nNB_clf.fit(X_train, y_train)\npredictions = (NB_clf.fit(X_train, y_train)).predict(X_test)\n\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5, average=\"micro\")))","a846f6f1":"from sklearn import model_selection\n# 10-fold cross validation\n# Test options and evaluation metric\nseed = 7\n# Using metric accuracy to measure performance\nscoring = 'accuracy' ","cc5312fe":"# Spot Check Algorithms\nmodels = []\nmodels.append(('LR', best_LR_clf))\nmodels.append(('DT', best_DT_clf))\nmodels.append(('NB', NB_clf))\nmodels.append(('SVM', best_SVM_clf))\n\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n\tresults.append(cv_results)\n\tnames.append(name)\n\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n\tprint(msg)","5d582d1e":"fig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","78b1fc95":"from sklearn.metrics import confusion_matrix","75d5a21f":"# from https:\/\/stackoverflow.com\/questions\/39033880\/plot-confusion-matrix-sklearn-with-multiple-labels\n\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","c459ea7e":"y_pred = (best_SVM_clf.fit(X_train, y_train)).predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\ntargets = labelEncoder.inverse_transform([0,1,2,3,4,5])\n\nplot_confusion_matrix(cm, target_names=targets, title=\"Confusion Matrix for SVM\")","ad31a3ad":"We will display a confusion matrix for the best model (SVM)","a912c017":"It's all about \"feeling\"...","1a011ef6":"## Diving into the (training) data","6a707cbc":"What does the vocabulary used look like?","2e6f3347":"![minimalism-4846000_1920.jpg](attachment:minimalism-4846000_1920.jpg)\n\n*Photo by <a href=\"https:\/\/pixabay.com\/fr\/users\/alexas_fotos-686414\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4846000\">\ud83c\udf84Merry Christmas \ud83c\udf84<\/a> on <a href=\"https:\/\/pixabay.com\/fr\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4846000\">Pixabay<\/a>*","53cfab5d":"Vectors for each dataset (without the target feature)","c15cbb15":"### Some \"joy\" text:","e618aca3":"## Word cloud","3b5a5a18":"## Logistic Regression","588eac90":"### And some \"anger\" text","7463ffc5":"> Tell me something, i'll tell you your mood\n\n*Unknown, 2021*","e9d9afb3":"## SVM","df36a506":"At least there is a lot of \"joy\" in this dataset... ","619ba86a":"Without grid search","e2e45cfd":"### Some \"sadness\" text:","70d19be4":"There is no NULL data in the dataset.  \nThere are 6 different emotions (characteristic to be predicted) in the dataset :","10b03c95":"# Training models","d31ac926":"## Cleaning texts","d75c35ba":"# K-fold cross validation","d3008191":"We have two columns: the text and the associated emotion.","ad9fd641":"Let's take a look at the result","acad1d95":"## Encode target feature","676dc4f2":"Just to see the results of these operations.","06bdabe5":"We keep the result of the two vectorizations to train the models.","17ace6c7":"### Clean texts","3d540a1c":"## Splitting datasets","ed8f006b":"## Confusion Matrix","a1de2b5e":"## Decision tree","8bf86aa0":"# Models comparison","55b9604e":"# Data visualization","e375698c":"# Tell me your mood","1ade646d":"# Data Handling","997bcbf5":"One can be worried to see that the word \"horrible\" still appears a lot in the text that is supposed to be related to \"joy\".We'll see what the results looks like. ","e048f358":"## Naive Bayes","723d1b8c":"EDIT: ***[Take a look at the medium article I wrote in addition to this notebook.](https:\/\/kindji.medium.com\/tell-me-your-mood-nlp-classification-5fd11958c7e0)***","f0ca40ad":" ## Vectorizing Language"}}