{"cell_type":{"b39bf6c4":"code","46bf0545":"code","5b27829f":"code","517d3a99":"code","aa8863c5":"code","32452a17":"code","8293d189":"code","cc126c3b":"code","07aa4d8d":"code","f2f340de":"code","ddba38c8":"code","cf31413a":"code","c53ef336":"code","64a61fd4":"code","60e15b54":"code","c9450f7a":"code","461645f8":"code","2251fc27":"code","93db8423":"code","4663facc":"markdown","38f2c8e3":"markdown","7f34ad45":"markdown","5a41eed9":"markdown","98863482":"markdown","f13348de":"markdown","ef971a8d":"markdown","47badfbd":"markdown","2d2ac5e0":"markdown","61d59c49":"markdown","370e28ea":"markdown","46423c62":"markdown","e6db4445":"markdown","31ffba4c":"markdown","0a2123fa":"markdown","377f8acc":"markdown","723f236d":"markdown","322f7c70":"markdown","0341f576":"markdown","9481c89d":"markdown","d10fc83a":"markdown","6476d679":"markdown","9948ddb9":"markdown","aa702d73":"markdown","178b25a5":"markdown","a281a86c":"markdown","a671890b":"markdown","b61d7538":"markdown","d23d003a":"markdown"},"source":{"b39bf6c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","46bf0545":"import datetime as dt\nimport warnings\nimport matplotlib.pyplot as plt\nimport datetime as dt \nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings('ignore', 'statsmodels.tsa.ar_model.AR', FutureWarning)\nwarnings.warn('ignore')\n\nfrom matplotlib.dates import DateFormatter\nfrom datetime import timedelta, date\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.arima_model import ARIMA\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom numpy import log\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.metrics import mean_squared_error\n","5b27829f":"train_set = pd.read_csv(r\"..\/input\/covid19-global-forecasting-week-3\/train.csv\", parse_dates=['Date'])\nprint(train_set.head())\nprint(train_set.describe())","517d3a99":"#split column Date into day | month | Year\ntrain_set['Day'] = pd.to_datetime(train_set[\"Date\"]).dt.day\ntrain_set['Month'] = pd.to_datetime(train_set[\"Date\"]).dt.month\ntrain_set['Year'] = pd.to_datetime(train_set[\"Date\"]).dt.year\n\nprint(train_set.head())","aa8863c5":"#preprocess \ntrain_set.isna().sum()","32452a17":"#countries with  Province State\ncountries_with_Province_State = train_set[train_set['Province_State'].isna()==False]['Country_Region'].unique()\nprint(countries_with_Province_State)","8293d189":"#create df only with Greece \ngreece= train_set[train_set.Country_Region  == 'Greece'  ]\n#drop feature 'province_state' because of Nan values\ngreece.drop(['Province_State'],axis=1,inplace=True) \nprint(greece)","cc126c3b":"#specify the form of the dates\ndate_form= DateFormatter(\"%m-%d\")\n\n\nfig, ax1 = plt.subplots(1,2,figsize=(18,5)) \n#some explanaition here : ax1[0] and ax1[1] stands for plot 0 & 1 respectively  \nax1[1].plot(greece[\"Date\"],greece[\"Fatalities\"]  , color='r')\nax1[1].xaxis.set_major_formatter(date_form)\nax1[1].set_xlim([ greece[\"Date\"].min(), greece[\"Date\"].max()+timedelta(days=5) ])\nax1[1].set_xlabel('Date',size=12)\nax1[1].set_ylabel('Fatalities',size=12)\nax1[1].set_title('Fatalities in Greece during the \\n period: {}  to {} '.format(greece[\"Date\"].min() , greece[\"Date\"].max() ) , size=15)\n\nax1[0].plot(greece[\"Date\"],greece[\"ConfirmedCases\"] )\nax1[0].xaxis.set_major_formatter(date_form)\nax1[0].set_xlim([ greece[\"Date\"].min(), greece[\"Date\"].max()+timedelta(days=5) ])\nax1[0].set_xlabel('Date' , size=13 )\nax1[0].set_ylabel('ConfirmedCases',size=12)\nax1[0].set_title('ConfirmedCases in Greece during the \\n period: {}  to {}'.format(greece[\"Date\"].min(),greece[\"Date\"].max()), size=15)\n","07aa4d8d":"# Comparison with other countries \n# Italy population 60480000  \n# Turkey population 80810000\n# Greece population 10740000\n# Albania population 2863000\n\n\nGreece_population =10740000\nTurkey_population =80810000\nItaly_population = 60480000 \nAlbania_population= 2863000\n\ntotal_greece_confirmed = train_set[(train_set['Country_Region']=='Greece' )& (train_set['ConfirmedCases']!=0)]\ntotal_italy_confirmed = train_set[(train_set['Country_Region']=='Italy' )& (train_set['ConfirmedCases']!=0)]\ntotal_turkey_confirmed = train_set[(train_set['Country_Region']=='Turkey' )& (train_set['ConfirmedCases']!=0)]\ntotal_albania_confirmed = train_set[(train_set['Country_Region']=='Albania' )& (train_set['ConfirmedCases']!=0)]\n\n\ntotal_greece_confirmed['pop_freq'] = total_greece_confirmed.ConfirmedCases\/ Greece_population  * 100\ntotal_italy_confirmed['pop_freq'] = total_italy_confirmed.ConfirmedCases\/ Italy_population  * 100\ntotal_turkey_confirmed['pop_freq'] = total_turkey_confirmed.ConfirmedCases\/ Turkey_population  * 100\ntotal_albania_confirmed['pop_freq'] = total_albania_confirmed.ConfirmedCases\/ Albania_population  * 100\n","f2f340de":"#plot the cases for each country and remark the first cases\nplt.figure(figsize=(15,8))\nplt.plot(total_greece_confirmed['Date'] ,total_greece_confirmed['pop_freq'] , 'b') \nplt.axvline(total_greece_confirmed['Date'].values[0] , 0 , linestyle='--',color='b')\n\nplt.plot(total_italy_confirmed['Date'] , total_italy_confirmed['pop_freq'] , 'y')\nplt.axvline(total_italy_confirmed['Date'].values[0] , 0 , linestyle='--',color='y')\n\nplt.plot(total_turkey_confirmed['Date'], total_turkey_confirmed['pop_freq'],'r')\nplt.axvline(total_turkey_confirmed['Date'].values[0] , 0 , linestyle='--',color='r')\n\nplt.plot(total_albania_confirmed[\"Date\"], total_albania_confirmed[\"pop_freq\"], 'orange')\nplt.axvline(total_albania_confirmed['Date'].values[0] , 0 , linestyle='--', color='orange')\nplt.legend(('Greece cases' , 'Greece first case' , 'Italy cases', 'Italy first case'  ,'Turkey cases' , 'Turkey first case', 'Albania case' , 'Albania first case ') ,fontsize=12)\nplt.xlabel('Date' , size= 14)\nplt.ylabel('% of Population' , size=14)\nplt.title('Infection of the virus from first confirmed case', size=18)\n# plt.plot()\nplt.show()\n","ddba38c8":"#create a new column for case fatality rate\n\ntotal_greece_confirmed['CFR'] = total_greece_confirmed['Fatalities']\/ total_greece_confirmed['ConfirmedCases']\ntotal_greece_confirmed['CFR'].replace([np.inf, -np.inf], 0, inplace=True)\n#Lets check mortality \nfig,ax = plt.subplots(  1 ,2 ,figsize=(18,6))\nax[0].plot( total_greece_confirmed['Date'] , total_greece_confirmed['ConfirmedCases'] , 'b')\nax[0].plot(total_greece_confirmed['Date'] , total_greece_confirmed['Fatalities'] , color='red')\nax[0].legend(('Confirmed Cases', 'Deaths') , fontsize=8)\nax[0].set_xlabel('Date',size=13)\nax[0].set_ylabel('Population',size=13)\nax[0].set_title('Mortality in Greece',size=16)\n\nsize=[total_greece_confirmed['Fatalities'].max(), total_greece_confirmed['ConfirmedCases'].max()]\n#print(total_greece_confirmed['Fatalities'])\n#print(total_greece_confirmed['ConfirmedCases'])\ncolors = ['red', 'yellowgreen']\nexplode = (0.2, 0) \nax[1].pie(  size,   colors=colors,explode=explode , labels = ['Fatalities','ConfirmedCases'],autopct='%1.1f%%', shadow=True, startangle=140)\nax[1].set_title('Case fatality rate' ,size=16)\n\n\nplt.show()","cf31413a":"\n\ndata=total_greece_confirmed[['ConfirmedCases','Date']]\n \nmodel_arima = ARIMA(data['ConfirmedCases'] ,dates=data['Date'], order=(1, 2, 1))\nmodel_fit_arima = model_arima.fit()\nyhat_arima = model_fit_arima.predict(len(data), len(data)+7, typ='levels' )\n\n\nmodel = AR(data['ConfirmedCases'] , data['Date'])\nmodel_fit = model.fit()\nprint('Lag: %s'%model_fit.k_ar)\nyhat = model_fit.predict(len(data), len(data)+7)\n\nfrom  statsmodels.tsa.holtwinters import ExponentialSmoothing as Holt\nts = data.set_index('Date')\n#smoothing_level = The alpha value of the simple exponential smoothing\n#smoothing_slope =The beta value of the Holt\u2019s trend method\nfit1 = Holt(ts , trend='add').fit(smoothing_level=0.8, smoothing_slope=0.7, optimized=False) \nyhat_holt = fit1.forecast(7).rename(\"Holt's linear trend\")\n\n\n\nplt.figure(figsize=(10,8))\nplt.plot(data['Date'],data['ConfirmedCases'], color='blue')\nplt.plot(yhat, color='red')\nplt.plot(yhat_arima , color='green')\nplt.plot(yhat_holt , color='orange')\nplt.title(('Predictions of the ARIMA, AR and ExponentialSmoothing models'),size=16)\nplt.xlabel('Date',size=12)\nplt.ylabel('Confirmed Cases',size=12)\nplt.legend(('Real data','AR','ARIMA','ExponentialSmoothing' ),fontsize=12)\nplt.show()\n","c53ef336":"#Split data\n\n#print(total_greece_confirmed)\ndataset  = total_greece_confirmed[['Date','ConfirmedCases']]\n#set date as index\ndataset=dataset.set_index('Date')\nx_train = dataset[:'2020-04-01']\nx_test =dataset['2020-04-02':]\nprint(np.shape(x_train))\nprint(np.shape(x_test))\n#Seasonal decomposition using moving averages.\nimport statsmodels.api as sm\ndecomposition = sm.tsa.seasonal_decompose(dataset, model='additive')\nfig,ax = plt.subplots(  4 ,1 ,figsize=(17,8))\nax[0].grid(True)\nax[0].plot(decomposition.observed.values)\nax[0].set_ylabel('Observed',size=12)\nax[1].grid(True)\nax[1].plot(decomposition.trend.values)\nax[1].set_ylabel('Trend',size=12)\nax[2].grid(True)\nax[2].plot(decomposition.seasonal.values)\nax[2].set_ylabel('Seasonal',size=12)\nax[2].hlines(y=0 , xmin=0 , xmax=40, linestyles='--',color='grey')\nax[3].grid(True)\nax[3].plot(decomposition.resid.values)\nax[3].set_xlabel('Days',size=14)\nax[3].set_ylabel('Residuals',size=12)\nax[3].hlines(y=0 , xmin=0 , xmax=40, linestyles='--',color='grey')\nplt.subplots_adjust(hspace=0.5)\n\n\n","64a61fd4":"#Forecasting with Arima  model \n#If a time series, has seasonal patterns, then you need to add seasonal terms and it becomes SARIMA,\n#explore the p,q,d \n#term \u2018Auto Regressive\u2019 in ARIMA means it is a linear regression model that uses its own lags as predictors\n#Predicted Yt = Constant + Linear combination Lags of Y (upto p lags) + Linear Combination of Lagged forecast errors (upto q lags) \n\n#define the d (differencing  in ARIMA model )\nresult = adfuller(x_train.dropna())\n#print(result)\n#print(type(result))#tuple\n\nresult = pd.DataFrame(data=result)\n\n# Original Series\nfig, axes = plt.subplots(4, 2, sharex=True, figsize=(13,10))\n\naxes[0, 0].plot(x_train.values)\naxes[0, 0].set_title('Original Series')\nplot_acf(x_train.values, ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(x_train.diff().values)\naxes[1, 0].set_title('1st Order Differencing')\nplot_acf(x_train.diff().dropna().values, ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(x_train.diff().diff().values)\naxes[2, 0].set_title('2nd Order Differencing')\nplot_acf(x_train.diff().diff().dropna().values, ax=axes[2, 1])\n\n# 3nd Diferencing\naxes[3, 0].plot(x_train.diff().diff().diff().values)\naxes[3, 0].set_title('3nd Order Differencing',size=10)\nplot_acf(x_train.diff().diff().diff().dropna().values, ax=axes[3, 1])\nplt.subplots_adjust(hspace=0.5)\n\nplt.show()\n\n\n \n\n","60e15b54":"#find the AR term \n#plot Partial autocorrelation (autocorrelation between yt and yt\u2013h after removing any linear dependence on y1, y2, ..., yt\u2013h+1 )\n#plot parc with 1 differencing\nplt.rcParams[\"figure.figsize\"] = (12,6)\nplot_pacf(x_train.diff().dropna().values,use_vlines=True ,lags=20,zero=True)\nplt.title('Partial Autocorrelation',size=14)\nplt.xlabel('lags' , size=12)\nplt.ylabel('Correlation',size=12)\nplt.xticks(range(0,21))\nplt.show()\n\n","c9450f7a":"# select term for MA \n\narima_model = ARIMA(x_train, order=(3,2,1))\narima_model_fit = arima_model.fit(disp=0)\nprint(arima_model_fit.summary())","461645f8":"residuals = pd.DataFrame(arima_model_fit.resid)\nresiduals.plot(kind='kde')\nprint(residuals.describe())\nplt.title('Residuals density ')","2251fc27":"#make predictions \nhistory = [ x for x in x_train.values]\npredictions= list()\n\n\nfor t in range(0,len(x_test)):\n    arima_model = ARIMA(history, order=(3,2,1))\n    arima_model_fit = arima_model.fit(disp=0)\n    output = arima_model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = x_test.iloc[t]\n    history.append(obs)\n    print('predicted=%f, expected=%f' % (yhat, obs))\nerror = mean_squared_error(x_test, predictions)\nprint('Test MSE: %.3f' % error)\n\n\nplt.plot(x_test.values,color='b')\nplt.plot(predictions,color='red')\nplt.title('Predicted VS Real' ,size=12)\nplt.legend(('Real cases','Predicted cases'),fontsize=18)\nplt.xlabel('days',size=12)\nplt.ylabel('Comfired Cases',size=12)\nplt.show()","93db8423":"#kaggle evaluation metric\nfrom sklearn.metrics import mean_squared_log_error as rmsle\nprint('RMSLE : {}'.format(rmsle(x_test, predictions)))\n","4663facc":"# <div id=\"fit\">Model fitting and Evaluation<\/div> \n","38f2c8e3":"** The dataset has 13376 nan values in 'Province_State' feature. Below we see the countries where  'Province_State' isn't missing.**","7f34ad45":"<div id=\"#\">  <\/div>","5a41eed9":"# Covid Greece Visulizations + ARIMA forecast","98863482":"**Let's specify through Autocorrelation the term $d$ of the <font size=\"4\"> $order=(p,q,d)$ <\/font>","f13348de":"# <div id=\"AR\">AR, ARIMA and Holt-Winters\u2019 models <\/div> ","ef971a8d":"# <div id=\"countries\">Greece, Italy, Albania and Turkey <\/div> \n\n**We calculate the frequencies of the infected population for each country in order to make comparisons,**","47badfbd":"**Books :\n*** Hyndman, R.J., & Athanasopoulos, G. (2018) Forecasting: principles and practice, 2nd edition, OTexts: Melbourne, Australia.\n\n**Online sources** :\n* https:\/\/matplotlib.org\/index.html\n* https:\/\/www.statsmodels.org\/stable\/index.html\n* https:\/\/machinelearningmastery.com\/time-series-forecasting-methods-in-python-cheat-sheet\/\n\n","2d2ac5e0":"**Looking at the Autocorrelation plots for the 1st ,2nd and 3rd differencing lag. An autocorrelation plot is designed to show whether the elements of a time series are correlated. In the plot of 2nd and 3rd differencing the lags goes into far negative zone fairly quick, so we will set <font size=\"4\"> d=1<\/font> (even though the series is not perfectly stationary ).**","61d59c49":"![%CE%94%CE%91%CE%94.jpg](attachment:%CE%94%CE%91%CE%94.jpg)","370e28ea":"1. <a href=\"#import\">Imports<\/a>\n\n2. <a href=\"#eda\">Exploratory data analysis (EDA)<\/a>\n \n3. <a href=\"#greece\">Greece Cases<\/a>\n\n4. <a href=\"#countries\">Greece, Italy, Albania and Turkey<\/a>\n\n5. <a href=\"#CASES\">Cases Fatalities Rate<\/a>\n\n6. <a href=\"#AR\">AR, ARIMA and Holt-Winters\u2019 models<\/a>\n \n7. <a href=\"#ARIMA\">Define ARIMA terms<\/a>\n\n8. <a href=\"#fit\">Model fitting and Evaluation<\/a>\n\n9. <a href=\"#Referencees\">References<\/a>\n\n","46423c62":"# <div id=\"Referencees\">References<\/div> ","e6db4445":"**A zero-mean distribution of the residuals reflect a non biased model. In our case the -2.01 mean shows that indeed there is a bias on the prediction.**","31ffba4c":"**For the MA (q) term we look at the ACF plot. An MA term is technically, the error of the lagged forecast. Thas is, how many MA terms are required to remove any autocorrelation. So, in the autocorrelation plot of the differenced series we notice that the first 2 lags are above the significance line. As a result, we fix ** <font size=\"4\">  q as 2.<\/font>","0a2123fa":"# <div id=\"greece\">Greece Cases <\/div> \n","377f8acc":"**Next,we display a density plot of the residual error values, suggesting the errors are Gaussian, <font size=\"4\"> but may not be centered on zero.<\/font> **","723f236d":"*** These datasets constitute an opportunity to explore our understanding of  disease transmission, and the components that we can observe,understand and control to address the spread of disease and its social, economical impacts. <font size=\"3\">BUT # it goes without saying<\/font>, in real life diseases are affected by thousends of factors, and thats why the below machine learning techniques inevitably fall from the complexities in real desease transmition.  **\n* I hope this notebook will be a valuable and informative resource for everyone.","322f7c70":"**Below we use** :\n* autoregressive model $AR(p)$  \n* $ARIMA(p,q,d)$   and   \n* $Holt\u2019s$ $Exponential$ $Smoothing$ model\nSome statistics here :  \n 1.  In an autoregression model  $AR(p)$, we forecast the variable of interest using a linear combination of past values of the variable.Thus, an autoregressive model of order $p$ can be written as : \n<font size=\"4\">$$y_t= c + \u03c6_1* y_{t-1} + \u03c6_2 *y_{t-2}  + ... + \u03c6_p *y_{t-p}$$<\/font>\n\n 2. ARIMA models aim to describe the autocorrelations in the data. This acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are\n* $AR$: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n* $I$: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n* $MA$: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n \n* Each of the above components are explicitly specified in the model as a parameter.That is,  \n p : the # of lags, \n d : the # of  times that the raw observations are differenced (degree of differencing),\n q : the # of the moving average window (MA) \n\n3.   $Holt\u2019s$ $Exponential$ $Smoothing$ \nThe Holt-Winters seasonal method comprises the forecast equation and three smoothing equations \u2014 one for the level, one for the trend, and one for the seasonal component. This method takes the next time step as an exponentially weighted linear function of observations at prior time steps, taking trends and seasonality into account. This method is suitable for univariate time series with trend and\/or seasonal components.","0341f576":"# <div id=\"CASES\">Cases Fatalities Rate <\/div> \n\n**In order to calculate the case fatality rate **:   $Case Fatality Rate $= $Fatalities \\div (Confirmed Cases)$\n","9481c89d":"**Focusing on Greece,**","d10fc83a":"**We observe a trend-cyrcle in every 7 days and obviously a positive trend (so non-stationary series ).**\n* $Tip$ : Occasionally, the values of the time series in a **small** number of periods may be particularly unusual.","6476d679":"# <div id=\"ARIMA\">Define ARIMA terms<\/div> ","9948ddb9":"**Searching for NaNs values,**","aa702d73":" # <div id=\"eda\">Exploratory data analysis (EDA) <\/div> \n** A glimpse in the dataset,**","178b25a5":"** Spliting the date-time for further analyses, **","a281a86c":" # <div id=\"import\"> Imports <\/div>","a671890b":"**Next, for identifying the AR term we plot thr PACF plot.\nIn the partial autocorrelation plot above, we observe that lags 1 ,2 and 3 are quite significant since is well above the significance line. So we tentatively fix the $p$ as 3.**","b61d7538":"**We split the data in train set-> 36 days  | test set->5 days. (Greece set)**\n* In the **train set** we use decomposition methods for extracting useful components from the time series.\n\n","d23d003a":"**We create a dataframe with features **['ConfirmedCases', 'Date']** and we handle the data as TimeSeries. We visualize the fit of the three models in the data and their 7-days predictions. **"}}