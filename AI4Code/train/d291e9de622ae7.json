{"cell_type":{"814a8dc3":"code","b5aea72b":"code","16c692a1":"code","50dac044":"code","a01d8d77":"code","ec694d75":"code","df1476ff":"code","409244cd":"code","28c94f60":"code","3552f822":"code","565f5927":"code","690f6751":"code","a5c9b5fa":"code","68925cfe":"code","f28906de":"code","fb0a8f75":"code","5c400e96":"code","e87d6f48":"code","7c1f636e":"markdown","c3673e40":"markdown","f1ec031e":"markdown","fc6a72c8":"markdown","5d84d4a4":"markdown","3d1285ea":"markdown","cba349f5":"markdown","dfb33b04":"markdown","86b5b4d0":"markdown","f23986a0":"markdown","cab67d5c":"markdown","c52ed749":"markdown","f9c1ec36":"markdown","06020920":"markdown","e0e9a76b":"markdown","8575c6c5":"markdown"},"source":{"814a8dc3":"#Load data and starting packages\n\nimport numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b5aea72b":"train_all = pd.read_csv('train1.csv', index_col= 'Id')\ntest_all = pd.read_csv('test1.csv', index_col='Id')\n\ntarget = train_all['SalePrice']","16c692a1":"train_all.shape, test_all.shape","50dac044":"train_all.drop(['SalePrice'], axis=1, inplace=True)\ntrain_all.select_dtypes(exclude='number').nunique().sort_values(ascending=True)","a01d8d77":"train_all.select_dtypes(exclude='object').nunique().sort_values(ascending=True)","ec694d75":"for col in ('BsmtHalfBath', 'HalfBath', 'BsmtFullBath', 'Fireplaces','KitchenAbvGr','FullBath'):\n    train_all[col] = train_all[col].astype(str)\n    test_all[col] = test_all[col].astype(str)","df1476ff":"cat_cols = [col for col in train_all.columns if train_all[col].dtype == \"object\"]\nten_or_over = []\n\nfor col in cat_cols:\n    if train_all[col].nunique() > 10:\n        ten_or_over.append(col)\n        \n\nprint(ten_or_over)","409244cd":"def drop_columns(data, drop_list):\n    for col in drop_list:\n        data = data.drop([col], axis = 1)\n    return data\n\ntrain = drop_columns(train_all, ten_or_over)\ntest = drop_columns(test_all, ten_or_over)\n","28c94f60":"X_train, X_valid, y_train, y_valid = train_test_split(train, target, \n                                                                train_size=0.9, test_size=0.1, random_state=42)\n\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","3552f822":"X_train.info()","565f5927":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import Lasso\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor","690f6751":"#define numerical and categorical columns\nnumerical_cols = [col for col in X_train.columns if X_train[col].dtype == \"int64\" or X_train[col].dtype == \"float\"]\ncategorical_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n\n#define transform strategy\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n#categorical columns are encoded during this step\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])","a5c9b5fa":"preprocess = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\ndef process_and_fit(model, train, target):\n    pipeline = Pipeline(steps=[('preprocess', preprocess),\n                   ('scale', StandardScaler()),\n                   ('model', model)])\n    pipeline.fit(train, target)\n    return pipeline\n\ndef rmse(validation, target):\n    return np.sqrt(mean_squared_error(validation, target))","68925cfe":"randomForest = RandomForestRegressor(n_estimators=800, random_state=20)\n\ngradientBoost = GradientBoostingRegressor(n_estimators = 600, random_state=20)\n\ncatBoost = CatBoostRegressor(loss_function='RMSE', random_state=20, verbose=False)\n\nxgBoost = XGBRegressor(colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 7, alpha = 4, n_estimators = 200)\n\nlassoReg = Lasso(alpha=0.0005, normalize = True)\n\nlightGBM = LGBMRegressor(objective='regression')","f28906de":"#Random Forest\nrfPipeline = process_and_fit(randomForest, X_train, y_train)\nrfPred = rfPipeline.predict(X_valid)\n\n#GradientBoosting\ngbPipeline = process_and_fit(gradientBoost, X_train, y_train)\ngbPred = gbPipeline.predict(X_valid)\n\n#CatBoost\ncbPipeline = process_and_fit(catBoost, X_train, y_train)\ncbPred = cbPipeline.predict(X_valid)\n\n#XGB\nxgbPipeline = process_and_fit(xgBoost, X_train, y_train)\nxgbPred = xgbPipeline.predict(X_valid)\n\n#Lasso\nlassoPipeline = process_and_fit(lassoReg, X_train, y_train)\nlassoPred = lassoPipeline.predict(X_valid)\n\n#LightGBM\ngbmPipeline = process_and_fit(lightGBM, X_train, y_train)\ngbmPred = gbmPipeline.predict(X_valid)","fb0a8f75":"models = ['Random Forest', 'Gradient Boosting', 'Cat Boost', 'XGBoost', 'Lasso Regression', 'Light GBM']\nmodel_names = [rfPred, gbPred, cbPred, xgbPred, lassoPred, gbmPred]\n\navg_score = 0\nfor m in range(len(models)):\n    score = rmse(y_valid, model_names[m])\n    avg_score += score\n    print(models[m], \"score:\", rmse(y_valid, model_names[m]))\nprint(\"Average Score Across Models: \", avg_score\/6)","5c400e96":"preds_test1 = rfPipeline.predict(test)\npreds_test2 = gbPipeline.predict(test)\npreds_test3 = cbPipeline.predict(test)\npreds_test4 = xgbPipeline.predict(test)\npreds_test5 = lassoPipeline.predict(test)\npreds_test6 = gbmPipeline.predict(test)\npreds_test = (preds_test1+preds_test2+ preds_test3 + preds_test4 + preds_test5 + preds_test6)\/6","e87d6f48":"output = pd.DataFrame({'Id': test_all.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","7c1f636e":"Define preprocessing step to remove missing values\/encode categorical variables. Then combine this with scaling and modeling steps within the process_and_fit function using pipeline. \n\nRoot Mean Squared Error (rmse) is also defined to calculate error rates.","c3673e40":"Next, identify categorical variables with 10 or more categories.","f1ec031e":"Predict on test data:","fc6a72c8":"Fit the models to the pipeline-processed data and predict on the X_validation set. Lasso Regression may not converge, yet prediction results were not as successfull when it was removed. ","5d84d4a4":"Create csv submission file","3d1285ea":"Evaluate scores on validation data, and include an average RMSE across models. ","cba349f5":"Examine the data:","dfb33b04":"Split training data into a training and validation set","86b5b4d0":"Investigate the number of unique categories in each of the categorical and numeric predictors:","f23986a0":"There are a number of numeric columns that have less than 5 unique values, and are likely to have low variance when compared to other numeric predictors. These columns are recoded as categorical values. ","cab67d5c":"Read in training and set data and save the SalePrice as the training target","c52ed749":"Drop these columns from the data set to prevent data sparcity","f9c1ec36":"Processing steps: \n1. Deal with NA values by replacing them with 0 for numeric predictors, and replacing them with the most frequent category for non-numeric\n2. Standardize features by removing the mean and scaling to unit variance (Standard Scaler)\n3. Fit to the specified model","06020920":" Parameter tuning. RandomizedSearchCV was used to test and find somewhat optimal parameters (not included here for brevity), though many more tests could be conducted. Below final models are defined. ","e0e9a76b":"Quite a few columns with missing values. These will be imputed using the sklearn simple imputer. Load all necessary packages and continue processing. ","8575c6c5":"Examine the training set to identify predictors with missing values. "}}