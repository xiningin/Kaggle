{"cell_type":{"b0b9c06d":"code","890e23c0":"code","55bd3da0":"code","d7095111":"code","b82d5aaf":"code","4a855404":"code","1f48a4d8":"code","d29785c4":"code","24327c36":"code","76e3af6c":"code","c6899aa4":"code","916fba55":"code","d4402008":"code","9fadd888":"code","44c3fe4f":"code","e3b588a0":"code","4dd7e96d":"code","9c53c88d":"code","386e5274":"code","f53d6a76":"markdown","4ee79780":"markdown","875d853e":"markdown"},"source":{"b0b9c06d":"# checking whether we have loaded the datasets we need and their input names\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","890e23c0":"from keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D, MaxPool2D\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf\nimport os\n%matplotlib inline \n#sets the backend of matplotlib to the \"inline\" backend. With this backend, the output of plotting commands is displayed inline within frontends like in Jupyter notebook, directly below the code cell that produced it. ","55bd3da0":"data = \"..\/input\/covid-19-x-ray-10000-images\/dataset\"","d7095111":"os.listdir(data)\n\n#os.listdir: returns a list containing the names of the entries in the directory given by the path","b82d5aaf":"import glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\n# glob.glob: returns a possibly empty list of path names that match pathnamme, which must be a string containing \n# a pth specification. Pathname can be either absolute like \/usr\/src\/Python-1.5\/Makefile or relative like\n# ..\/..\/Tools\/*\/*.gif and can contain shell-style wildcards.","4a855404":"normal_images = [] # creating an empty list to be later employed\nfor img_path in glob.glob(data + '\/normal\/*'): # tells the function to add normal images within our dataset into our created normal lung CT list\n    normal_images.append(mpimg.imread(img_path)) # and additionally reads our image\n\n\nfig = plt.figure()\nfig.suptitle('normal lung')\nplt.imshow(normal_images[0], cmap = 'gray')\n\ncovid_images = []\nfor img_path in glob.glob(data + '\/covid\/*'):\n    covid_images.append(mpimg.imread(img_path))\n    \nfig = plt.figure()\nfig.suptitle('covid infected lung')\nplt.imshow(covid_images[0], cmap = 'gray')","1f48a4d8":"print(len(normal_images))\nprint(len(covid_images))","d29785c4":"IMG_W = 150\nIMG_H = 150\nCHANNELS = 3\n\nINPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\nNB_CLASSES = 2\nEPOCHS = 48\nBATCH_SIZE = 6","24327c36":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape = INPUT_SHAPE)) #initializing the weights, input and output\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250, (3, 3)))\nmodel.add(Activation(\"relu\"))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2, 2))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2, 2))\n\nmodel.add(Conv2D(256, (2, 2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2, 2))\n\nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","76e3af6c":"model.compile(loss = \"binary_crossentropy\",\n             optimizer = \"rmsprop\", \n             metrics = ['accuracy'])","c6899aa4":"model.summary()","916fba55":"train_datagen = ImageDataGenerator(rescale = 1.\/225,\n                                  shear_range = 0.2,\n                                  zoom_range = 0.2,\n                                  horizontal_flip = True,\n                                  validation_split = 0.3)\n\ntrain_generator = train_datagen.flow_from_directory(\n    data, \n    target_size = (IMG_H, IMG_W),\n    batch_size = BATCH_SIZE,\n    class_mode = \"binary\",\n    subset = \"training\")\n\n# .flow_from_directory: to read the images from a big numpy array and folders containing images.\n\nvalidation_generator = train_datagen.flow_from_directory(\n    data,\n    target_size = (IMG_H, IMG_W),\n    batch_size = BATCH_SIZE,\n    class_mode = \"binary\",\n    shuffle = False,\n    subset = \"validation\")\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ BATCH_SIZE,\n    validation_data = validation_generator,\n    validation_steps = validation_generator.samples \/\/ BATCH_SIZE,\n    epochs = EPOCHS)\n\n#.fit_generator: to perform data augmentation to avoid the overfitting of a model and also to increase the ability of our model to generalize.\n# additional_info: https:\/\/www.geeksforgeeks.org\/keras-fit-and-keras-fit_generator\/","d4402008":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"accuracy\")\nplt.xlabel(\"epoch\")\nplt.legend(['train', 'test'], loc = \"upper left\")\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend(['train', 'test'], loc = \"upper left\")\nplt.show()","9fadd888":"print(\"training_accuracy\", history.history['accuracy'][-1])\nprint(\"validation_accuracy\", history.history['val_accuracy'][-1])","44c3fe4f":"label = validation_generator.classes","e3b588a0":"pred = model.predict(validation_generator)\npredicted_class_indices = np.argmax(pred, axis = 1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k, v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint(labels)\nprint(predictions)","4dd7e96d":"from sklearn.metrics import confusion_matrix\n\ncf = confusion_matrix(predicted_class_indices, label)\ncf","9c53c88d":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames = ['Actual'], colnames = ['Predicted'], margins = True)","386e5274":"plt.matshow(cf)\nplt.title(\"Confusion Matrix Plot\")\nplt.colorbar()\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show();","f53d6a76":"The size of the data tells us that there are simply more covid-infected lung CTs than normal lungs","4ee79780":"Original source code: https:\/\/www.kaggle.com\/eswarchandt\/covid-19-detection-from-lung-x-rays\/","875d853e":"We can tell from the images that the size of covid infected lungs are immensely smaller."}}