{"cell_type":{"83e6cfb0":"code","af5d64bf":"code","32b0f6ea":"code","b3749bc2":"code","50cb2f5d":"code","07aa7c6f":"code","a10cc555":"code","4c8a4c32":"code","05aaa6ee":"code","41025d87":"code","8c2285d3":"code","7bf2609a":"code","9c765a17":"code","6a7e7261":"code","1b4cf870":"code","26ee97c9":"code","748576e2":"code","4d21deff":"code","b226b666":"code","6f2d0161":"markdown","e6235863":"markdown","37205cbd":"markdown","2b38d5a5":"markdown","407d889a":"markdown","226c6138":"markdown","c4139f46":"markdown","6fd32024":"markdown"},"source":{"83e6cfb0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af5d64bf":"#Importing Beginning Libraries \n\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport sklearn\n\n#These libraries help with dealing with image datasets\nimport matplotlib.pyplot as plt\nimport torch \nimport torchvision \nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils \nfrom torchvision import datasets, models, transforms\n","32b0f6ea":"#Viewing file paths in the directory\nprint(os.listdir('..\/input\/wikiart-gangogh-creating-art-gan'))","b3749bc2":"#Defining the sub-datasets I'll be working with\nbase_path = '..\/input\/wikiart-gangogh-creating-art-gan\/'\n\ngenres = ['abstract', 'landscape', 'portrait']\n\n\nabstract_path = os.path.join(base_path, 'abstract')\nlandscape_path  = os.path.join(base_path, 'landscape')\nportrait_path  = os.path.join(base_path, 'portrait')\n\nprint(abstract_path)","50cb2f5d":"import cv2\n\nabstract=[]\nfor file in os.walk(abstract_path):\n    image = cv2.imread(file)\n    abstract.append(image)\n    #print(os.path.join(dirname, filename))\n\nprint(abstract)","07aa7c6f":"#Placing images in list instead of a folder\n\nimport cv2\n\nabstract = []\nlandscape= []\nportrait = []\n\nfor img in abstract_path: \n    image = cv2.imread(img)\n    abstract.append(image)\n\nfor img in landscape_path: \n    image = cv2.imread(img)\n    landscape.append(image)\n\nfor img in portrait_path: \n    image = cv2.imread(img)\n    portrait.append(image)","a10cc555":"#transforming list into an array \n\nabstract= np.array(abstract)\nlandscape = np.array(landscape)\nportrait = np.array(portrait)\n\nprint(abstract)","4c8a4c32":"print(abstract.shape)\nprint(landscape.shape)\nprint(portrait.shape)","05aaa6ee":"\n#Splitting abstract, landscape and portrait dataset into train and test sets\n\nfrom sklearn.model_selection import train_test_split\n\n#abstract_train, abstract_test, landscape_train, landscape_test, portrait_train, portrait_test (abstract, landscape, portrait, test_size=0.40)\ntrain_abstract, test_abstract  = train_test_split (abstract,  test_size=0.40)\ntrain_portrait, test_portrait = train_test_split (portrait, test_size=0.40)\ntrain_landscape, test_landscape = train_test_split (landscape, test_size = 0.40)","41025d87":"#Importing necessary libraries \nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn import preprocessing\nimport numpy as np\n\nimport seaborn as sns\n%matplotlib inline\n","8c2285d3":"LogReg = LogisticRegression()\n\n\nscaler = preprocessing.StandardScaler()\ntrain_abstract = scaler.fit_transform(train_abstract)\ntest_abstract = scaler.transform(test_abstract)\n\nLogReg.fit(train_abstract,test_abstract)\n\n\npred=LogReg.predict(test_abstract)\n","7bf2609a":"print('Classes', LogReg.classes_)\nprint('Intercept',LogReg.intercept_)\nprint(\"Coefficients\", LogReg.coef_ )\n\n","9c765a17":"print(\"Accuracy\", LogReg.score(X_test, y_test))\nprint(classification_report(y_test, LogReg.predict(X_test)))","6a7e7261":"#Confusion Matrix\nconf_mat = confusion_matrix(y_test, y_pred)\nconf_mat","1b4cf870":"categories = [0,1] \nfig, ax = plt.subplots()\nplt.xticks([0,1], categories)\nplt.yticks([0,1], categories)\n# create heatmap\nsns.heatmap(pd.DataFrame(conf_mat), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","26ee97c9":"# Dummy classifier in SKlearn\nfrom sklearn.dummy import DummyClassifier\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")","748576e2":"#F1 Score\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))","4d21deff":"y_pred_proba = LogReg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n        lw=2, label='ROC curve (area = %0.2f)' % auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()\n","b226b666":"#importing necessary libraries\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error as MSE\n\n","6f2d0161":"# Pt. 5 Nueral Network (Pytorch)","e6235863":"# Pt.4 Nueral Network (Keras)","37205cbd":"# Conclusion","2b38d5a5":"# Pt. 1 Logistic Regression","407d889a":"# Introduction\n\nThe dataset I will be working with for my final project is the Wiki-Art: Visual Art Encyclopedia. This large data set consists of 14 folders art images separtes by genre, all as jpg files.\n\n\nMy overall goal for this project is to be able to classify artworks by genre. My focus will be to narrow in on the three largest genre folders that depcict images of *abstract artwork*, *landscape artwork* and *portraits*. \n\nI am focusing on these specific genres because they are distinct enough for the average person to distinguish between genres and they also have all have similar amounts of data (all around 15k files in each folder). I think this will make my models stronger because I will have a realtively even amount of training data for each category. \n","226c6138":"# Pt. 3 XGBoost ","c4139f46":"# Pt. 2 Decision Tree Classification","6fd32024":"# ****Kennedy Whitehead's 414 Final Project****"}}