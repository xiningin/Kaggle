{"cell_type":{"b9be7715":"code","0117359f":"code","84dd2fce":"code","c904d4fe":"code","f5157c9a":"code","24de0f54":"code","86ee9d19":"code","1e90a7a8":"code","6064c885":"markdown"},"source":{"b9be7715":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib import rcParams\nrcParams.update({'figure.autolayout': True})\n\nimport seaborn as sns\nfrom functools import reduce\nimport pylab\nimport scipy.stats as scp\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","0117359f":"#define function as data-cleaning)\ndef data_cleaning(df, col_list):\n    \"\"\"\n    Return a dataset with the col_list removed and without duplicates\n    \"\"\"\n    df2 = df.drop(col_list, axis=1)\n    df2.drop_duplicates(inplace=True)\n    return df2","84dd2fce":"#Importing the datasets\ndf_pop = pd.read_csv(\"..\/input\/population.csv\")\ndf_geo = pd.read_csv(\"..\/input\/name_geographic_information.csv\", na_values='-') \ndf_geo.rename(columns={'code_insee': 'CODGEO'}, inplace = True)\ndf_salary = pd.read_csv(\"..\/input\/net_salary_per_town_categories.csv\")\n#df_ind = pd.read_csv(\"..\/input\/base_etablissement_par_tranche_effectif.csv\")\n\n#Cleaning the data for easier merging. We don't need (for now) the different population category\ndf_pop = df_pop[df_pop[\"CODGEO\"].apply(lambda x: str(x).isdigit())]\ndf_pop[\"CODGEO\"] = df_pop[\"CODGEO\"].astype(int)\ndf_pop_red = df_pop.loc[:,[\"CODGEO\",'SEXE','NB']]\ndf_pop_grouped = df_pop_red.groupby([\"CODGEO\",'SEXE']).agg({'NB' : 'sum'})","c904d4fe":"#Main merge into the df dataset which will stay untouched.\n#It is the \"reference\" dataset with as few modification as possible\ndrop_salary = ['LIBGEO','SNHMC14','SNHMP14','SNHME14','SNHMO14','SNHM1814', 'SNHM2614', 'SNHM5014']\ndf_salary_red = data_cleaning(df_salary, drop_salary)\ndf_salary_red = df_salary_red[df_salary_red[\"CODGEO\"].apply(lambda x: str(x).isdigit())]\ndf_salary_red[\"CODGEO\"] = df_salary_red[\"CODGEO\"].astype(int)\ndf_salary_red.set_index('CODGEO', inplace=True, verify_integrity=True)\n\ndrop_geo = ['chef.lieu_r\u00e9gion','pr\u00e9fecture','\u00e9loignement','num\u00e9ro_circonscription','codes_postaux']\ndf_geo_red = data_cleaning(df_geo, drop_geo)\ndf_geo_red.drop([33873,36823], axis=0, inplace=True) #There are duplicates for Saint-Pierre-et-Miquelon and Lagu\u00e9pie\ndf_geo_red.set_index('CODGEO', inplace=True, verify_integrity=True)\n\ndf = df_salary_red.merge(df_geo_red, how=\"outer\", left_index=True, right_index=True)\ndf = df.merge(df_pop_grouped, how = \"outer\", left_index=True, right_index=True)","f5157c9a":"#Creation of df_main, which is df with human-readable labels.\n#Drop unnecessary columns\ndf_main = df.copy()\nprint(df_main.columns)\n\ndict_columns = {\n    'CODGEO': 'codgeo',\n    'code_r\u00e9gion':'region_code', \n    'nom_r\u00e9gion':'region_name',\n    'num\u00e9ro_d\u00e9partement':'department_code', \n    'nom_d\u00e9partement':'department_name', \n    'nom_commune':'commune_name',\n    'SNHM14' : 'mean_net_salary_hour',\n    'SNHMF14': 'mean_net_salary_hour_female', \n    'SNHMFC14':'mean_net_salary_hour_female_executive', \n    'SNHMFP14':'mean_net_salary_hour_female_middle_manager', \n    'SNHMFE14':'mean_net_salary_hour_female_employee', \n    'SNHMFO14':'mean_net_salary_hour_female_worker',\n    'SNHMH14' :'mean_net_salary_hour_male', \n    'SNHMHC14':'mean_net_salary_hour_male_executive', \n    'SNHMHP14':'mean_net_salary_hour_male_middle_manager', \n    'SNHMHE14':'mean_net_salary_hour_male_employee', \n    'SNHMHO14':'mean_net_salary_hour_male_worker', \n    'SNHMF1814':'mean_net_salary_hour_female_18_25',\n    'SNHMF2614':'mean_net_salary_hour_female_26_50', \n    'SNHMF5014':'mean_net_salary_hour_female_51',\n    'SNHMH1814':'mean_net_salary_hour_male_18_25',\n    'SNHMH2614':'mean_net_salary_hour_male_26_50',\n    'SNHMH5014':'mean_net_salary_hour_male_51'\n}\n\ndf_main.reset_index(level=1, inplace=True)\ndf_main.rename(columns = dict_columns, inplace = True)\ndf_main.dropna(inplace=True, subset=['mean_net_salary_hour'])\ndf_main['longitude'] = pd.to_numeric(df_main['longitude'].str.replace(',', '.'))\n#We print relevant information about the dataset\ndf_main.shape\ndf_main.info()\ndf_main.head(5)","24de0f54":"# Perform the necessary imports\nfrom scipy.cluster.hierarchy import linkage, dendrogram, fcluster\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# Prepare the data\nlist_departments = [\"department_name\", \"NB\",'mean_net_salary_hour_male', 'mean_net_salary_hour_male_executive', 'mean_net_salary_hour_male_middle_manager', 'mean_net_salary_hour_male_employee', 'mean_net_salary_hour_male_worker']\ndepartments = df_main[list_departments].groupby(\"department_name\").agg(\n    {'NB':'sum',\n     'mean_net_salary_hour_male':'mean',\n     'mean_net_salary_hour_male_executive':'mean',\n     'mean_net_salary_hour_male_middle_manager':'mean', \n     'mean_net_salary_hour_male_employee':'mean', \n     'mean_net_salary_hour_male_worker':'mean'\n    }).sort_values(\"NB\", ascending=True).reset_index()\ndepartments.rename(columns={'index': 'department_rank',}, inplace=True)\ndepartments_labels = departments[\"department_name\"].tolist()\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,18))\n\ndepartments_salary = departments.loc[:,['mean_net_salary_hour_male', 'mean_net_salary_hour_male_executive', 'mean_net_salary_hour_male_middle_manager', \n                                        'mean_net_salary_hour_male_employee', 'mean_net_salary_hour_male_worker']].values\n\n# Calculate the linkage: mergings\nmergings = linkage(departments_salary, method='ward')\n\n# Plot the dendrogram, using varieties as labels\ndend = dendrogram(mergings,\n        labels=departments_labels,\n        leaf_rotation=0,\n        leaf_font_size=10,\n        orientation = 'right',\n        color_threshold = 4,\n        ax = ax\n)\nax.set_title = \"Dendrogram of the French departments, groups by male salaries\"\nplt.show()","86ee9d19":"# Do the TSNE\ntsne = TSNE(learning_rate=150)\ndepartments_transformed = tsne.fit_transform(departments_salary)\n\nks = range(4, 20)\ninertias = []\n\nfor k in ks:\n    # Create a KMeans instance with k clusters: model\n    model = KMeans(n_clusters = k)\n    \n    # Fit model to samples\n    model.fit(departments_transformed)\n    \n    # Append the inertia to the list of inertias\n    inertias.append(model.inertia_)\n    \n# Plot ks vs inertias\nfig, ax = plt.subplots(nrows=1, ncols=1)\nax.plot(ks, inertias, '-o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.title('Inertia by number of clusters')\nplt.xticks(ks)\nax.add_patch(\n    patches.Rectangle(\n        (6.5, 40),   # (x,y)\n        7,          # width\n        110,          # height\n        facecolor='none',\n        edgecolor='r',\n        linewidth=1\n    )\n)\nplt.show()","1e90a7a8":"# Create a KMeans model with 10 clusters: model\nnclust = 10\nmodel = KMeans(n_clusters = nclust)\n\n# Fit model and obtain cluster labels and cmap them\nclasses = model.fit_predict(departments_transformed)\nnum_colors = nclust\ncm = pylab.get_cmap('tab20')\n\n# Create the visualization\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,8))\n\nfor i in np.unique(classes):\n    ix = np.where(classes == i)\n    ax = plt.scatter(departments_transformed[ix,0], departments_transformed[ix,1], \n                 c = cm(1*i\/num_colors), label = i)\n# Annotations\n    for label, x, y in zip(departments_labels, departments_transformed[:, 0], departments_transformed[:, 1]):\n        plt.annotate(\n            label,\n            xy=(x + x\/100, y + y\/100),\n            fontsize=10, \n            alpha=0.6)\n    plt.legend(loc = \"upper right\")\n\n    # Print the cluster\ndepartments['cluster'] = classes\nfor i in departments['cluster'].sort_values().unique():\n    print(\"-----#####-----\")\n    print(\"Cluster \" + str(i))\n    print(departments[departments[\"cluster\"] == i][\"department_name\"])","6064c885":"**Clustering the Departments**\n\nThis part is about getting some information about departments and salaries. In France like in many other countries, there is a clear difference between rural and urban areas: as metropolitan cities centralize more and more services, rural areas may be left on their own devices. We have no label that could tell us how departments are grouped salary-wise. That is why I am going to use unsupervised classification algorithms to handle it. I will first build another dataset which is basically our main dataset grouped by departments and keeping only the male salaries (global mean, executive mean etc.). Then, I will build a dendrogram about this data. The dendrogram will create clusters of data based on our features (the salaries) to minimize the variance of these clusters. In other words, it will keep alike data together and provide a great visualisation to better understand potential groups.\n\nThen, I will use a k-means algorithm to create clusters of departments. As we have more than 2 dimensions, I can' get the result on a scatterplot without either dropping some columns or reducing the dimensions. That is what I will do through a t-SNE algorithm.\n\nMoreover, I should get a good number of clusters to have relevant insight about the data. We will have a good idea of this number thanks to the dendrogram but I will nevertheless test different possible values."}}