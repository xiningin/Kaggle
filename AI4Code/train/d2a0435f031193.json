{"cell_type":{"8f86eebf":"code","c5cf03a3":"code","86ccc4e8":"code","7d3991be":"code","0370e55f":"code","6beffa72":"code","67329f16":"code","53b051b8":"code","32d52fc9":"code","21ad0c63":"code","34389cc7":"code","ceca5f6e":"code","32de3825":"code","073f0db8":"code","bbcb2f44":"code","87620f1a":"code","1b95b859":"code","6be22bac":"code","b485e629":"code","b10b0966":"code","549c08fc":"code","4bfc2cbe":"code","aaedb1a0":"code","b034f05d":"code","b0f43a20":"code","72af6899":"markdown","518c8e68":"markdown","02f5d166":"markdown","dfe1611f":"markdown","35411077":"markdown","eb410f70":"markdown","7be42b25":"markdown"},"source":{"8f86eebf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c5cf03a3":"#Importando pacotes\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom math import sqrt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom statistics import mode","86ccc4e8":"# Coletando dados\ntreino = pd.read_csv(\"..\/input\/kernel02\/dataset_treino.csv\")\nteste = pd.read_csv(\"..\/input\/kernel02\/dataset_teste.csv\")\nsubmission = pd.read_csv(\"..\/input\/kernel02\/sample_submission.csv\")\ntransacoeshist = pd.read_csv(\"..\/input\/kernel02\/transacoes_historicas.csv\")","7d3991be":"hist = transacoeshist.groupby([\"card_id\"])\nhist= hist[\"purchase_amount\"].size().reset_index()\nhist.columns = [\"card_id\", \"hist_transactions\"]\ntreino = pd.merge(treino,hist, on=\"card_id\", how=\"left\")\nteste = pd.merge(teste,hist, on=\"card_id\", how=\"left\")\n\nhist = transacoeshist.groupby([\"card_id\"])\nhist = hist[\"purchase_amount\"].agg(['sum','mean','max','min','std']).reset_index()\nhist.columns = ['card_id','sum_hist_tran','mean_hist_tran','max_hist_tran','min_hist_tran','std_hist_tran']\ntreino = pd.merge(treino,hist,on='card_id',how='left')\nteste = pd.merge(teste,hist,on='card_id',how='left')","0370e55f":"treino.head(2)","6beffa72":"teste.head(2)","67329f16":"#Substituindo valor nulo na coluna 'first_active_month' pela data mais frequente\nteste['first_active_month'].fillna(mode(treino['first_active_month']), inplace=True)","53b051b8":"#Representando numericamente valores da vari\u00e1vel \"first_active_month\"\ntreino['first_active_month']=pd.to_datetime(treino['first_active_month'])\nteste['first_active_month']=pd.to_datetime(teste['first_active_month'])\ntreino[\"ano\"] = treino[\"first_active_month\"].dt.year\nteste[\"ano\"] = teste[\"first_active_month\"].dt.year\ntreino[\"mes\"] = treino[\"first_active_month\"].dt.month\nteste[\"mes\"] = teste[\"first_active_month\"].dt.month","32d52fc9":"#One Hot Encoding\n\n#treino\ndumtreino_feature_1 = pd.get_dummies(treino['feature_1'],prefix = 'f1_')\ndumtreino_feature_2 = pd.get_dummies(treino['feature_2'],prefix = 'f2_')\ndumtreino_feature_3 = pd.get_dummies(treino['feature_3'],prefix = 'f3_')\n\n#teste\ndumteste_feature_1 = pd.get_dummies(teste['feature_1'], prefix = 'f1_')\ndumteste_feature_2 = pd.get_dummies(teste['feature_2'], prefix = 'f2_')\ndumteste_feature_3 = pd.get_dummies(teste['feature_3'], prefix = 'f3_')\n\n#concatenando dados\ntreino = pd.concat([treino, dumtreino_feature_1, dumtreino_feature_2, dumtreino_feature_3], axis = 1, sort = False)\nteste = pd.concat([teste, dumteste_feature_1, dumteste_feature_2, dumteste_feature_3], axis = 1, sort = False)","21ad0c63":"treino.head()","34389cc7":"teste.head()","ceca5f6e":"fig = plt.figure(figsize=(15,5))\nsns.distplot(treino['target'])","32de3825":"#Criando coluna que representa os outliers\ntreino['outlier'] = 0\ntreino.loc[treino['target'] < -30, 'outlier'] = 1\ntreino['outlier'].value_counts()","073f0db8":"treino.head()","bbcb2f44":"#Criando dataset com valores \"n\u00e3o-outliers\"\nintreino = treino[treino['outlier'] == 0]","87620f1a":"fig = plt.figure(figsize=(15,5))\nsns.distplot(intreino['target'])","1b95b859":"treino.columns","6be22bac":"#Cria\u00e7\u00e3o do modelo01 - Treinando modelo 01 com dados \"n\u00e3o outliers\"\n\n#Separando em componentes de input e output\narrayX = intreino[['hist_transactions', 'sum_hist_tran', 'mean_hist_tran',\n       'max_hist_tran', 'min_hist_tran', 'std_hist_tran', 'mes', 'ano', \n        'f1__1', 'f1__2', 'f1__3', 'f1__4', 'f1__5', 'f2__1', 'f2__2',\n       'f2__3', 'f3__0', 'f3__1']].values\n\narrayY = intreino[['target']].values\n\n#Divide os dados em treino e teste\nX_train, X_test, Y_train, Y_test = train_test_split(arrayX, arrayY, test_size = 0.33, random_state = 5)\n\n#Criando o modelo\nmodelo01 = LinearRegression()\n\n#Treinando o modelo\nmodelo01.fit(X_train, Y_train)\n\n#Fazendo previs\u00f5es\nY_pred = modelo01.predict(X_test)\n\n#Resultado\nrmse = sqrt(mean_squared_error(Y_test, Y_pred)) \nprint(\"RMSE:\", rmse)","b485e629":"#Previs\u00e3o nos dados de teste\n\narrayTeste = teste[['hist_transactions', 'sum_hist_tran', 'mean_hist_tran',\n       'max_hist_tran', 'min_hist_tran', 'std_hist_tran', 'mes', 'ano', \n        'f1__1', 'f1__2', 'f1__3', 'f1__4', 'f1__5', 'f2__1', 'f2__2',\n       'f2__3', 'f3__0', 'f3__1']].values\n\ny_pred = modelo01.predict(arrayTeste)\n\nsubmission['target'] = y_pred","b10b0966":"submission.head()","549c08fc":"#Cria\u00e7\u00e3o do modelo 02 - Regress\u00e3o log\u00edstica para tentar prever outliers nos dados de teste\n\n#Separando  em componentes de input e output\narrayX = treino[['hist_transactions', 'sum_hist_tran', 'mean_hist_tran',\n       'max_hist_tran', 'min_hist_tran', 'std_hist_tran', 'mes', 'ano', \n        'f1__1', 'f1__2', 'f1__3', 'f1__4', 'f1__5', 'f2__1', 'f2__2',\n       'f2__3', 'f3__0', 'f3__1']].values\n\narrayY = treino[['outlier']].values\n\n#Divide os dados em treino e teste\nX_train, X_test, Y_train, Y_test = train_test_split(arrayX, arrayY, test_size = 0.33, random_state = 5)\n\n#Definindo os valores para o n\u00famero de folds\nnum_folds = 10\nseed = 7\n\n#Separando os dados em folds\nkfold = KFold(num_folds, True, random_state = seed)\n\n#Criando o modelo\nmodelo02 = LogisticRegression()\n\n#Treinando o modelo com dados de treino\nmodelo02.fit(X_train, Y_train)\n\n#Cross Validation\nresultado = cross_val_score(modelo02, arrayX, arrayY, cv = kfold)\n\n#Print do resultado\nprint(\"Acur\u00e1cia: %.3f\" % (resultado.mean() * 100))","4bfc2cbe":"#Prevendo outliers nos dados de teste\narrayTeste = teste[['hist_transactions', 'sum_hist_tran', 'mean_hist_tran',\n       'max_hist_tran', 'min_hist_tran', 'std_hist_tran', 'mes', 'ano', \n        'f1__1', 'f1__2', 'f1__3', 'f1__4', 'f1__5', 'f2__1', 'f2__2',\n       'f2__3', 'f3__0', 'f3__1']].values\n\n#Previs\u00f5es\nout_prev = modelo02.predict(arrayTeste)\n\n#Gerando dataset com valores previstos e imprimindo resultado\nsubmission['outlier'] = out_prev\nsubmission.groupby('outlier').size()","aaedb1a0":"#Substituindo target dos valores outliers por (-33,21)\nsubmission.loc[submission['outlier'] == 1, 'target'] = -33,21","b034f05d":"submission.head()","b0f43a20":"del(submission['outlier'])\n\nsubmission.to_csv('submission.csv', header = True, index = False)","72af6899":"Como podemos ver, o modelo 02 apresentou uma boa acur\u00e1cia nos dados de treino, mas n\u00e3o foi capaz de prever outliers nos novos dados de teste. \n","518c8e68":"Iremos utilizar uma combina\u00e7\u00e3o de regress\u00e3o linear com regress\u00e3o log\u00edstica para tentar prever os outliers nos dados de teste, de acordo com a seguinte abordagem:\n\n1. Classificar outliers e \"n\u00e3o outliers\" na vari\u00e1vel target dos dados de treino \n\n\n2. Criar e treinar Modelo 01 com dados \"n\u00e3o outliers\"\n\n\n3. Utilizar Modelo 01 para prever target nos dados de teste\n\n\n4. Criar e treinar Modelo 02 com dados de treino classificados (Outlier = 1, n\u00e3o outlier = 0)\n\n\n5. Utilizar o Modelo 02 para tentar prever outliers nos dados de teste\n\n\n6. Concatenar resultados","02f5d166":"# Competi\u00e7\u00e3o DSA de Machine Learning\n### Competi\u00e7\u00e3o DSA de Machine Learning - Edi\u00e7\u00e3o Junho\/2019","dfe1611f":"Este Kernel foi criado como uma tentativa de abordarmos os outliers da vari\u00e1vel \"target\" dos dados de treino da competi\u00e7\u00e3o.\n\nO kernel principal com a an\u00e1lise explorat\u00f3ria pode ser visto [aqui](http:\/\/https:\/\/www.kaggle.com\/andrehofreire\/kernel01)","35411077":"### Conclus\u00e3o","eb410f70":"## Abordagem","7be42b25":"## Criando vari\u00e1veis"}}