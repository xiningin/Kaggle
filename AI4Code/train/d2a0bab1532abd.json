{"cell_type":{"8b711534":"code","11c86c05":"code","b32e9b89":"code","e7dde7dd":"code","a8df50ce":"code","3b678a48":"code","c863b31b":"code","716574de":"code","ed492e1b":"code","274270ce":"code","878706a0":"code","73dcf119":"code","76c1cfae":"code","cb2c1ac0":"code","72a65138":"code","779b04bc":"code","e8e48727":"code","c3a4e741":"code","9c416490":"code","73596a4f":"code","69cc751f":"code","db5c203e":"code","d7182a0f":"code","96b0d123":"code","f7467ce3":"code","2673b8a2":"code","d877b81f":"code","286a7b4f":"code","dc0411ae":"code","f4062d54":"code","9df4dc6c":"code","6e65ac99":"markdown","334be76c":"markdown","bed4df4c":"markdown","0706b4ac":"markdown","ba24f80b":"markdown","f35cd037":"markdown","5e653d0f":"markdown","0cc7c0b3":"markdown","1687568d":"markdown","6fa79604":"markdown","bb7ae8a1":"markdown","27e81d58":"markdown","79f7b4ef":"markdown","45b5a83f":"markdown","90b87800":"markdown"},"source":{"8b711534":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","11c86c05":"# Few necessary imports\nimport os\nimport subprocess\nimport matplotlib.pyplot as plt\nimport graphviz\nimport seaborn as sns","b32e9b89":"# Load data\ndata = pd.read_csv('..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\n# Don't need customerID to find out trends in the data\ndata = data.drop(columns=['customerID'])\n# Convert TotalCharges from string to numeric datatype and fill NaN values witht the median\ndata['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\ndata['TotalCharges'] = data['TotalCharges'].fillna(data['TotalCharges'].median())\n# Convert SeniorCitizen from integer to string\ndata['SeniorCitizen'] = data['SeniorCitizen'].apply(lambda x: 'Yes' if x==1 else 'No')\n\ncolumns = list(data.columns)\nnon_numeric_cols = list(set(columns) - set(['tenure', 'TotalCharges', 'MonthlyCharges']))\nnumeric_cols = ['tenure', 'TotalCharges', 'MonthlyCharges']","e7dde7dd":"for column in non_numeric_cols:\n    print('------------------------')\n    print(data[column].value_counts())  ","a8df50ce":"data[['tenure', 'TotalCharges', 'MonthlyCharges']].describe()","3b678a48":"# Remove Churn from feature columns since it is the target value\nnon_numeric_cols.remove('Churn')","c863b31b":"# Exploratory analysis on non-continuous features\nfor idx in range(0, len(non_numeric_cols), 2):\n    plt.subplots(figsize=(12,4))\n    plt.subplot(1, 2, 1)\n    ax = sns.countplot(x=non_numeric_cols[idx], data=data, alpha=0.6)\n    ax = sns.countplot(x=non_numeric_cols[idx], data=data[data['Churn'] == 'Yes'])\n    ax.set(ylabel='churned \/ total')\n    plt.subplot(1, 2, 2)\n    ax = sns.countplot(x=non_numeric_cols[idx+1], data=data, alpha=0.6)\n    ax = sns.countplot(x=non_numeric_cols[idx+1], data=data[data['Churn'] == 'Yes'])\n    ax.set(ylabel='churned \/ total')\n    plt.tight_layout()\n    plt.show()","716574de":"# Exploratory analysis on continuous features\nfor column in numeric_cols:\n    plt.subplots(figsize=(12,4))\n    plt.subplot(1, 2, 1)\n    sns.distplot(data[data['Churn'] == 'Yes'][column], label='Yes')\n    sns.distplot(data[data['Churn'] == 'No'][column], label='No')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    sns.boxplot(x=column, y='Churn', hue='Churn', data=data)\n    plt.tight_layout()\n    plt.show()","ed492e1b":"# Correlation matrix to find the dependencies amongst the continuous features\ncorrelation_matrix = data[numeric_cols].corr()\nsns.heatmap(correlation_matrix,\n            xticklabels=correlation_matrix.columns.values,\n            yticklabels=correlation_matrix.columns.values)","274270ce":"# Dropping TotalCharges column from dataframe\ndata = data.drop(columns=['TotalCharges'])\nnumeric_cols.remove('TotalCharges')\ncolumns = list(data.columns)","878706a0":"from sklearn import tree, svm\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectFromModel","73dcf119":"# List of columns containg boolean data\nbool_cols = ['Partner', 'Dependents', 'SeniorCitizen', 'PaperlessBilling', 'PhoneService']\n\n# Convert string data with two classes to boolean values\nfor column in bool_cols:\n    data[column] = data[column].apply(lambda x: 1 if x in 'Yes' else 0)\ndata['gender'] = data['gender'].apply(lambda x: 1 if x in 'Female' else 0)\n\n# Create dummy variables for features with more than two classes\nnon_numeric_data = pd.get_dummies(data[non_numeric_cols])\nnon_numeric_data.head()","76c1cfae":"# Standardization of continuous features\nnumeric_data = pd.DataFrame(scale(data[numeric_cols]), index=data.index, columns=numeric_cols)\nnumeric_data.head()","cb2c1ac0":"# Create the final feature dataframe to perform predictive analysis\nfeatures = pd.concat([numeric_data, non_numeric_data], axis=1)\nfeatures.head()","72a65138":"# Create target dataframe for predictive analysis\nlabels = data['Churn'].apply(lambda x: 1 if x in 'Yes' else 0)\nlabels.head()","779b04bc":"# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2)\nprint('X_train: ', X_train.shape)\nprint('y_train: ', y_train.shape)\nprint('X_val: ', X_val.shape)\nprint('y_val: ', y_val.shape)\n\nkfold = model_selection.KFold(n_splits=10, random_state=101)\nscoring = 'accuracy'","e8e48727":"models = {'decision_tree': tree.DecisionTreeClassifier(min_samples_split=20, max_depth=11),\n         'random_forest': RandomForestClassifier(criterion='entropy', random_state=101, n_estimators=200, max_depth=11),\n         'logistic_regression': LogisticRegressionCV(),\n         'svm_model': svm.SVC(kernel='linear', C=1),\n         'mlp': MLPClassifier(hidden_layer_sizes=(16, 16), max_iter=1000)\n        }\n\nfor key, model in models.items():\n    results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    print(\"10-fold cross-validation average accuracy for {}: %.3f\".format(key) % (results.mean()))","c3a4e741":"decision_tree = models['decision_tree'].fit(X_train, y_train)","9c416490":"y_pred = decision_tree.predict(X_val)\nacc = accuracy_score(y_val, y_pred)\nprint(\"Accuracy: {}\".format(acc))\nprint()\nprint(classification_report(y_val,y_pred))","73596a4f":"# Visualize the decision tree and save it as a png file\ndot_data = tree.export_graphviz(decision_tree, out_file=None, feature_names=features.columns,\n                         filled=True, rounded=True, special_characters=True)\n\ngraph = graphviz.Source(dot_data)\ngraph","69cc751f":"with open(\"decision_tree.dot\", 'w') as f:\n    dot_data = tree.export_graphviz(decision_tree, out_file=f, feature_names=features.columns,\n                         filled=True, rounded=True, special_characters=True)\ntry:\n    subprocess.check_call([\"dot\", \"-Tpng\", \"decision_tree.dot\", \"-o\", \"decision_tree.png\"])\n    subprocess.check_call([\"rm\", \"decision_tree.dot\"])\n    print(\"Graph successfully stored as decision_tree.png\")\nexcept:\n    exit(\"Could not run dot, ie graphviz, to produce visualization\")","db5c203e":"log_reg = models['logistic_regression'].fit(X_train, y_train)","d7182a0f":"y_pred = log_reg.predict(X_val)\nacc = accuracy_score(y_val, y_pred)\nprint(\"Accuracy: {}\".format(acc))\nprint()\nprint(classification_report(y_val,y_pred))","96b0d123":"mlp = models['mlp'].fit(X_train, y_train)","f7467ce3":"y_pred = mlp.predict(X_val)\nacc = accuracy_score(y_val, y_pred)\nprint(\"Accuracy: {}\".format(acc))\nprint()\nprint(classification_report(y_val,y_pred))","2673b8a2":"churn = log_reg.predict(X_val)\nchurn_rate = np.sum(churn)\/len(churn)\n\nprint(\"Current churn rate: {}%\".format(np.round(churn_rate*100,2)))","d877b81f":"# Returns the churn rate after removing specific features\n# The coefficient of that particular feature is made 0 so that it doesn't contribute to the predictions\ndef remove_features(feat_idx):\n    lr = LogisticRegressionCV()\n    lr.coef_ = np.copy(log_reg.coef_)\n    for idx in feat_idx:\n        lr.coef_[0, idx] = 0\n    lr.intercept_ = log_reg.intercept_\n    lr.classes_ = log_reg.classes_\n    churn = lr.predict(X_val)\n    churn_rate = np.sum(churn)\/len(churn)\n    return np.round(churn_rate*100,2)","286a7b4f":"feature_list = ['OnlineSecurity', 'MultipleLines', 'TechSupport', 'OnlineBackup', 'DeviceProtection']\nfeat_idx = []\n\nfor feat in feature_list:\n    idx = list(features.columns).index(feat+'_No')\n    feat_idx.append(idx)\n    print(\"Churn rate if all customers had {}: {}%\".format(feat, remove_features([idx])))\n\nprint(\"\\nChurn rate if all customers had all of the above facilities: {}%\".format(remove_features(feat_idx)))","dc0411ae":"idx = list(features.columns).index('PaymentMethod_Electronic check')\nprint(\"Churn rate if the company discontinues the electronic check payment method: {}%\".format(remove_features([idx])))","f4062d54":"idx = list(features.columns).index('InternetService_Fiber optic')\nprint(\"Churn rate if the company starts offering better fiber optic internet service: {}%\".format(remove_features([idx])))","9df4dc6c":"idx = list(features.columns).index('Contract_Month-to-month')\nprint(\"Churn rate if the company discontinues the month-to-month contract: {}%\".format(remove_features([idx])))","6e65ac99":"Though, this might not be the best way to make such inferences, but this method offers an approximate way to see how each feature affects the churn propensity. The churn rate went down from **21%** to **13%** if all of the above facilities were being taken up by all of the customers. This inference intutively seems to be correct since offering more and better services to customers should make them want to stay with the company for longer.","334be76c":"### Decision Tree\nEven though the decision tree model performed the worst in our cross-validation test, we could still draw several useful insights after visualizing the trained decision tree.","bed4df4c":"#### Conclusions drawn:\n- Tenure and Monthly Charges have a weak correlation\n- Total Charges is significantly dependent on both Tenure and Monthly Charges, which reinforces our decision to drop the TotalCharges as a feature","0706b4ac":"#### Conclusions drawn:\n- Customers who have not been with the company for long (0-20 months) tend to have a higher rate of leaving than customers who have been with the company for a long time\n- The median tenure for customers who have left in the last month is close to 10 while the median tenure for customers who have stayed is close to 40\n- Customers having higher monthly charges (>65) have a higher tendency to leave than customers having lower monthly charges\n- The median monthly charge of the customers who left in the last month is close to 80\n- Total Charges has a lot of outliers and is not very intutive, dropping this feature is probably the best option","ba24f80b":"## Exploratory Analysis","f35cd037":"### 10-fold Cross Validation","5e653d0f":"## Solutions\nWe will now try to find out how changing certain important features affects the churn propensity","0cc7c0b3":"#### Solutions:\n- There seems to be a problem with the tech services that the company offers to its customers. A huge proportion of the customers who don't have these services tend to leave the company. Services such as online security, tech support, online backup, and device protection, if made better, could lead to a higher customer retention rate.\n- Customers seem uncomfortable with the lectronic check payment method. The payment method should be looked into for problems or discontinued all together.\n- The fiber optic internet services being offered by the company seem to be having some problems. Customers who have opted for this service in the past have had higher rates of leaving the company. Improving the quality of the fibe optic service could definitely reduce the number of customers leaving the company.\n- The month-to-month contract seems to be the biggest reason why a lot of the customers leave the company. A reason for this could be that the month-to-month contract has an extremely high monthly charge when compared to the other contract offers. Reducing the monthly charge on the month-to-month contract is a sure shot way of increasing customer retention.","1687568d":"#### Conclusions drawn:\n- The Logistic Regression model outperforms the other models in the 10-fold cross validation tests\n- The SVM with linear SVC kernel comes close, but is heavier compared to the logistic regression model which makes it the worse option out of the two","6fa79604":"### Logistic Regression","bb7ae8a1":"## Desriptive Analysis","27e81d58":"In our exploratory analysis, we made the following discoveries:\n- Customers **without online security** have a significantly high churn rate\n- Customers who **don't have multiple lines** almost certainly have left in the last month\n- Customers without services like tech support, online backup, device protection have a high churn rate\n\nWhat happens if we assume that these services are offered to future customers?","79f7b4ef":"### Multi-Layered Perceptron","45b5a83f":"#### Conclusions Drawn:\n- Customers **without online security** have a significantly high churn rate\n- Customers who pay using **electronic check** have a significantly high churn rate\n- Customers having a **month-to-month contract** have a significantly higher rate of leaving\n- Customers who **don't have multiple lines** almost certainly have left in the last month\n- Customers having **fiber optic internet service** have higher churn rates\n- Customers without services like tech support, online backup, device protection have a high churn rate\n- Customers who have phone services tend to have higher churn rates\n- Number of customers who left in the last month is almost equal for males and females\n- Senior citizens tend to have higher churn rates\n- Customers who don't have dependents tend to leave more often tha the ones that do\n- Customers who don't have partners have a higher churn rate\n- Customers with and without StreamingTV facility have similar churn rates\n- Customers who have paperless billing have a higher rate of leaving","90b87800":"## Predictive Analysis"}}