{"cell_type":{"f55a115d":"code","95e74a4a":"code","603718bb":"code","96060bab":"code","9f0388b2":"code","0790599a":"code","91c35c0c":"code","be329067":"code","f7245c34":"code","96f01799":"code","8d072679":"code","2672d7da":"code","4c0adb25":"code","23372f98":"code","bd9d1492":"code","679a104a":"code","4d62c3a7":"code","cba598a1":"code","3cf65447":"code","f2af73bb":"code","3b8f9d90":"code","9dfffc2e":"code","57c62eb5":"code","dee9a88c":"code","ddfd4219":"code","e4bae490":"code","7461c03b":"code","fd94c339":"code","22b3581f":"code","631ac738":"code","e8d32d3f":"code","3976d5c0":"code","a9474412":"markdown","2a4e5c9e":"markdown","03795f5e":"markdown","aaeaa2fe":"markdown","723014b2":"markdown","93b406de":"markdown","b48ca218":"markdown","ad3be0fa":"markdown","6685ad62":"markdown","cfbf4ae0":"markdown","f053a50b":"markdown","efbf433a":"markdown","01306613":"markdown","5e122590":"markdown","b9862931":"markdown","bba69e9c":"markdown","a01f217f":"markdown","def28022":"markdown","4744ea67":"markdown","d7eb2961":"markdown","6ead3992":"markdown","545de077":"markdown","eb819ed0":"markdown","afeabec0":"markdown","e07b9464":"markdown","1681d4c1":"markdown","b311a14c":"markdown","436d932c":"markdown","ac266a33":"markdown","f25d803d":"markdown","d747a266":"markdown","fdc568c8":"markdown","f799d1a1":"markdown","66d97302":"markdown"},"source":{"f55a115d":"import numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn.preprocessing\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\nimport pandas as pd\nimport glob\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn_pandas import DataFrameMapper\nimport sklearn.preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor","95e74a4a":"csvfiles = []\nfor file in glob.glob(\"..\/input\/used-car-dataset-ford-and-mercedes\/*.csv\"):\n    csvfiles.append(file)","603718bb":"csvfiles","96060bab":"csvfiles.remove(\"..\/input\/used-car-dataset-ford-and-mercedes\/unclean focus.csv\")\ncsvfiles.remove(\"..\/input\/used-car-dataset-ford-and-mercedes\/unclean cclass.csv\")","9f0388b2":"pds = []\nfor i, file in enumerate(csvfiles):\n    pds.append(pd.read_csv(file))\n    name = file[44:-4]\n    pds[i][\"type\"] = name\n    print(i, \": \", len(pds[i].columns))","0790599a":"pds = [x for x in pds if not len(x.columns) != 10]","91c35c0c":"for element in pds:\n    print(len(element.columns))","be329067":"for element in pds:\n    print(element.columns)","f7245c34":"names = pds[0].columns.tolist()","96f01799":"for element in pds:\n    element.columns = names","8d072679":"the_data = pd.DataFrame()\nfor element in pds:\n    the_data = the_data.append(element, ignore_index=True)","2672d7da":"the_data.isnull().sum()","4c0adb25":"the_data.describe()","23372f98":"the_data[the_data[\"year\"] > 2020]","bd9d1492":"the_data = the_data[the_data[\"year\"] < 2020]","679a104a":"sns.displot(the_data[\"price\"])","4d62c3a7":"sns.displot(the_data[\"price\"], log_scale=True)","cba598a1":"the_data[\"type\"].value_counts().plot(kind=\"bar\")","3cf65447":"type_year_count = the_data[[\"year\", \"type\"]].groupby([\"type\", \"year\"]).size().reset_index(name=\"counts\")\n# pivot the table to wide format\ntype_year_count = type_year_count.pivot_table(index=\"type\", columns=\"year\", values=\"counts\")\n# replace nan values by 0\ntype_year_count = type_year_count.replace(np.nan, 0)\n# make column names a string instead of a number\ntype_year_count.columns = list(map(str, type_year_count.columns))\n# get the names of the columns\nyears = type_year_count.columns\n# convert the columns to int instead of float\ntype_year_count[years] = type_year_count[years].astype(int)\n# calculate percentages\ntype_year_count[\"total\"] = type_year_count.sum(axis=1)\nfor column in years:\n    type_year_count[column] = type_year_count[column]\/type_year_count[\"total\"]\n# drop the total column\ntype_year_count.drop(\"total\", 1, inplace=True)\n# now plot\ntype_year_count.plot(kind=\"bar\", stacked = True)\nplt.legend(ncol=5, loc = \"upper left\")","f2af73bb":"type_fuel_count = the_data[[\"fuelType\", \"type\"]].groupby([\"type\", \"fuelType\"]).size().reset_index(name=\"counts\")\n# pivot the table to wide format\ntype_fuel_count = type_fuel_count.pivot_table(index=\"type\", columns=\"fuelType\", values=\"counts\")\n# replace nan values by 0\ntype_fuel_count = type_fuel_count.replace(np.nan, 0)\n# get the names of the columns\nfuel = type_fuel_count.columns\ntype_fuel_count = type_fuel_count.astype(int)\n# calculate percentages\ntype_fuel_count[\"total\"] = type_fuel_count.sum(axis=1)\nfor column in fuel:\n    type_fuel_count[column] = type_fuel_count[column]\/type_fuel_count[\"total\"]\n# drop the total column\ntype_fuel_count.drop(\"total\", 1, inplace=True)\n# now plot\ntype_fuel_count.plot(kind=\"bar\", stacked = True)\nplt.legend(ncol=5, loc = \"upper left\")","3b8f9d90":"heat = the_data[[\"price\", \"type\", \"year\"]].groupby([\"type\", \"year\"]).mean()\n# now pivot the table to wide format\nheat = heat.pivot_table(index = \"type\", columns=\"year\", values=\"price\")\n# now plot\nsns.heatmap(heat.transpose(), cmap = sns.cm.rocket_r)","9dfffc2e":"sns.lmplot(x=\"mileage\", y=\"price\", hue=\"type\", scatter=False, lowess=True, ci=None, data=the_data)","57c62eb5":"the_data.corr().sort_values(\"price\").loc[:, \"price\"][the_data.corr()[\"price\"] != 1.0].plot(kind=\"bar\")\nplt.xticks(rotation=0)","dee9a88c":"the_data[the_data.select_dtypes([\"object\"]).columns] = the_data[the_data.select_dtypes([\"object\"]).columns].apply(lambda x: x.astype(\"category\"))","ddfd4219":"mapper = DataFrameMapper([\n    ([\"year\"], sklearn.preprocessing.StandardScaler()),\n    ([\"mileage\"], sklearn.preprocessing.StandardScaler()),\n    ([\"tax\"], sklearn.preprocessing.StandardScaler()),\n    ([\"mpg\"], sklearn.preprocessing.StandardScaler()),\n    ([\"engineSize\"], sklearn.preprocessing.StandardScaler()),\n    (\"type\", sklearn.preprocessing.LabelBinarizer()),\n    (\"fuelType\", sklearn.preprocessing.LabelBinarizer()),\n    (\"transmission\", sklearn.preprocessing.LabelBinarizer()),\n    (\"model\", sklearn.preprocessing.LabelBinarizer()),\n    (\"price\", None)\n], df_out=True)\nthe_data_transformed = mapper.fit_transform(the_data)","e4bae490":"the_data_transformed = pd.concat([the_data_transformed, the_data[\"type\"]], axis=1)","7461c03b":"split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=8)\nfor train_index, test_index in split.split(the_data_transformed, the_data_transformed[\"type\"]):\n    strat_train_set = the_data_transformed.iloc[train_index]\n    strat_test_set = the_data_transformed.iloc[test_index]","fd94c339":"x_train = strat_train_set.drop([\"price\", \"type\"], axis=1)\ny_train = strat_train_set[\"price\"]\nx_test = strat_test_set.drop([\"price\", \"type\"], axis=1)\ny_test = strat_test_set[\"price\"]","22b3581f":"lm = LinearRegression()\nlm.fit(x_train, y_train)\n# calculate predicted values for the test set\nyhat_lm = lm.predict(x_test)\n# get the RMSE\nnp.sqrt(mean_squared_error(y_test, yhat_lm))","631ac738":"tree_reg = DecisionTreeRegressor()\ntree_reg.fit(x_train, y_train)\nyhat_tree = tree_reg.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, yhat_tree))\ntree_reg.score(x_test, y_test)","e8d32d3f":"yhat_tree = pd.DataFrame(yhat_tree)\nyhat_tree.columns = [\"yhat_tree\"]\ncheck = pd.concat([x_test.reset_index().drop(\"index\", 1),\n                   strat_test_set[\"type\"].reset_index().drop(\"index\", 1),\n                   y_test.reset_index().drop(\"index\", 1),\n                   yhat_tree.reset_index().drop(\"index\", 1)], axis=1)","3976d5c0":"color = iter(cm.rainbow(np.linspace(0, 1, 9)))\nfig, ax = plt.subplots(3, 3)\nrow = 0\ncolumn = 0\nfor label, df in check[[\"yhat_tree\", \"price\", \"type\"]].groupby(\"type\"):\n    c = next(color)\n    ax[row, column].scatter(x=\"yhat_tree\", y=\"price\", data=df, alpha = 0.2, c=c)\n    ax[row, column].axline([0, 0], [1, 1], color=\"black\")\n    ax[row, column].tick_params(axis=\"both\", which=\"major\", labelsize=6)\n    ax[row, column].set_title(label)\n    if column == 2:\n        column = 0\n    elif column < 2:\n        column += 1\n    if column == 0:\n        row += 1","a9474412":"Summarise the data:","2a4e5c9e":"Now plot the predicted vs actual for each car type. The line represents x=x which is the ideal situation:","03795f5e":"Add again the categorical type column because it will be useful later and we need it for the stratified sampling since this column represents the groups:","aaeaa2fe":"We note that the RMSE is very high. Let us try another algorithm.\n\n### Decision tree","723014b2":"Let us now look at the frequency of the car types in the data set:","93b406de":"## Machine Learning\n\nFirst convert string to categories:","b48ca218":"Now create copies of train and test sets for x and y:","ad3be0fa":"## Visualise the data\n\nLook at the distribution of price:","6685ad62":"Let us now look at the percentage of each car in terms of year. This will help us understand whether the data set contains some car types that are newer than other car types. First we need to put the data in the appropriate shape. Count the number of cars for each type in each year:","cfbf4ae0":"We should remove this record:","f053a50b":"We now produce the same graph but for fuel type:","efbf433a":"Everything looks fine.","01306613":"We note that in one case the tax column is labelled differently. We need the same labels. Get the column names from first data frame:","5e122590":"### Linear regression","b9862931":"We note that the model does a good job of predicting the values.","bba69e9c":"Some files have the word \"unclean\" in the title. Let us remove these files:","a01f217f":"Now transform the variables in the train sets using a mapper. I transform before splitting in order to have same columns in train and test sets:","def28022":"We now read the data files","4744ea67":"Check for missing values:","d7eb2961":"Some files have 8 columns while most have 10. Remove the ones that dont have 10 columns:","6ead3992":"Now split the data set using stratified sampling using the variable type. We use this kind of sampling because we have data for different car types and we want the sets to be representative of the original data:","545de077":"We now look at differences in price when taking into account the car type and the year. First we need to get the data in the correct format. Calculate the average price for each type and year combination:","eb819ed0":"Now read  into a pandas array the files into pandas and print number of columns from each file also, create a new column with the name of the car:","afeabec0":"Let us look at the names of the files","e07b9464":"The plot shows that the most expensive cars are audi. bmw, and mercedes. However, we also see a significant drop in their prices as they get older. We do not see the same steep decrease in price for ford and hyundai.\n\nWe now look at the change in price as a function of mileage:","1681d4c1":"We see that the price is highly skewed. Produce the same but on a log scale:","b311a14c":"Now append the data frames into a single data frame:","436d932c":"Check the number of columns in each panda","ac266a33":"Let us look at the correlation between price and the other variables:","f25d803d":"The RMSE for the decision tree is much smaller. We therefore go with it. It also has a good R2 value on the test set.\n\nWe now create a single data frame that contains that test set, the predicted values, and the original values of the column \"type\":","d747a266":"First we import the necessary libraries","fdc568c8":"Now loop thrpugh the data frames setting the names to this variable:","f799d1a1":"It seems that the maximum year is 2060. This doesnt make sense.","66d97302":"Let us now look at the names of the columns:"}}