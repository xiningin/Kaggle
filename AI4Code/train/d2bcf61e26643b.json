{"cell_type":{"948bc161":"code","cc7ba112":"code","68569838":"code","7001ed88":"code","f440690b":"code","ed189218":"code","9d521f21":"code","e14f2a80":"code","2e1eb005":"code","704fd760":"code","82249a99":"code","fb054782":"code","c97495e7":"code","bedca4f1":"code","31afbbc7":"code","d97b323a":"code","7b191db7":"code","e32e7467":"code","81cc9c0c":"code","ee12151c":"code","a98763b8":"code","7b175b48":"code","24882cfc":"code","8e0a0a2e":"code","ca9799e5":"code","5e6297bd":"code","17e7f8f6":"code","025c6f4f":"code","246d4a7a":"code","75857d55":"code","434d4de8":"code","d4ca24e6":"code","e4de8019":"code","be9aaf7a":"code","85121aac":"code","430ff21f":"code","5174e74a":"code","c31f8c2d":"code","a1a79d6b":"code","61a9123d":"code","70c84371":"code","51088ddb":"code","6b87ab90":"code","7b0536f9":"markdown"},"source":{"948bc161":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport tensorflow as tf\nimport keras\nimport keras.layers as L\nimport math\nimport cv2\nfrom keras.utils import Sequence\nfrom keras.preprocessing import image\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split","cc7ba112":"#pip install imutils\n#from imutils import paths\n#image_paths = list(paths.list_images('..\/input\/landmark-recognition-2021\/train'))","68569838":"GLR_labels=pd.read_csv(\"..\/input\/landmark-recognition-2021\/train.csv\")\nGLR_labels.shape","7001ed88":"from sklearn import preprocessing\nle_id = preprocessing.LabelEncoder()\nGLR_labels[\"id_le\"]= le_id.fit_transform(GLR_labels[\"landmark_id\"])\nGLR_labels","f440690b":"image_paths=[]\npath=\"..\/input\/landmark-recognition-2021\/train\"\nfor number in range(len(GLR_labels[\"id\"])):\n    i=GLR_labels[\"id\"][number][0]\n    j=GLR_labels[\"id\"][number][1]\n    k=GLR_labels[\"id\"][number][2]\n    id=GLR_labels[\"id\"][number]\n\n    image_paths.append(path+\"\/\"+i+\"\/\"+j+\"\/\"+k+\"\/\"+id+\".jpg\")","ed189218":"image_paths[0:10]","9d521f21":"GLR_labels[\"Image_paths\"]=image_paths\nGLR_labels","e14f2a80":"#temp=GLR_labels[\"landmark_id\"].value_counts()\n#temp\n#temp1=temp[temp<50]\n#temp1\n#sum(temp1)\n#for i in range(len(temp1)):\n    #Image_dataset.drop(Image_dataset[Image_dataset['id_le'] == temp1.index[i]].index, inplace = True)\n","2e1eb005":"Image_dataset=GLR_labels\nImage_dataset","704fd760":"train_images = []\ntrain_labels = []\n#class_object = annotations['labels']\n\n# loop over the input images\nfor (i, image_path) in enumerate(image_paths):\n    #read image\n    image = cv2.imread(image_path)\n    #make images gray\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    #label image using the annotations\n    label = Image_dataset[\"id_le\"][i]\n    # resize image\n    image = cv2.resize(image, (64, 64))\n    # flatten the image\n    #pixels = image.flatten()\n    #Append flattened image to\n    train_images.append(image)\n    train_labels.append(label)\n    if i%100000==0:\n        print(i)\n    #print('Loaded...', '\\U0001F483', 'Image', str(i+1), 'is a', tmp_label)","82249a99":"GLR_labels.columns","fb054782":"image_name","c97495e7":"GLR_labels.index[GLR_labels['id'] == image_name].tolist()\n","bedca4f1":"GLR_labels.head(20)","31afbbc7":"GLR_labels['landmark_id'].max()","d97b323a":"GLR_submission = pd.read_csv('..\/input\/landmark-recognition-2021\/sample_submission.csv')","7b191db7":"GLR_submission.shape","e32e7467":"GLR_submission.head(100)","81cc9c0c":"GLR_submission.describe()","ee12151c":"counts = GLR_labels.landmark_id.value_counts()\ncounts\n#counts = counts[counts >=50].index #indexing only classes which have atleast 50 samples\n#counts[0:10]","a98763b8":"counts[138982]","7b175b48":"from tensorflow.keras.utils import to_categorical\n\nlabel_cat = to_categorical(GLR_labels[\"landmark_id\"])\n\n","24882cfc":"label_cat.shape","8e0a0a2e":"\n#GLR_labels = GLR_labels.loc[GLR_labels.landmark_id.isin(counts)]\n#num_classes = counts.shape[0]\nnum_classes = label_cat.shape[1]\n\nprint(num_classes)","ca9799e5":"GLR_labels.shape[0]","5e6297bd":"def id2path(idx,is_train=True):\n    path = '..\/input\/landmark-recognition-2021'\n    if is_train:\n        path += '\/train\/'+idx[0]+'\/'+idx[1]+'\/'+idx[2]+'\/'+idx+'.jpg'\n    else:\n        path += '\/test\/'+idx[0]+'\/'+idx[1]+'\/'+idx[2]+'\/'+idx+'.jpg'\n    return path\nGLR_labels['file_path'] = GLR_labels['id'].apply(id2path)\nGLR_submission['file_path'] = GLR_submission['id'].apply(id2path,False)","17e7f8f6":"def read_image(idx):\n    image = cv2.imread(idx)\n    image = image\/255.\n    image = cv2.resize(image,(256,256))\n    return image","025c6f4f":"def plot_images(landmark_id): #plot images by image_id\n    landmark = GLR_labels[GLR_labels['landmark_id']==landmark_id].head(25)\n    imgs = [read_image(x) for x in landmark['file_path']]\n    _, axs = plt.subplots(5,5, figsize=(12, 12))\n    axs = axs.flatten()\n    for i, (img, ax) in enumerate(zip(imgs, axs)):\n        ax.title.set_text(str(landmark['id'].iloc[i]))\n        ax.imshow(img)\n        ax.axis('off')\n    plt.show()","246d4a7a":"plot_images(138982)","75857d55":"class Dataset(Sequence):\n    def __init__(self,idx,y=None,batch_size=128,shuffle=True):\n        self.idx = idx\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        if y is not None:\n            self.is_train=True\n        else:\n            self.is_train=False\n        self.y = y\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n    def __getitem__(self,ids):\n        batch_ids = self.idx[ids * self.batch_size:(ids + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x = np.array([read_image(x) for x in batch_ids])\n        batch_X = np.stack(list_x)\n        if self.is_train:\n            return batch_X, batch_y\n        else:\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","434d4de8":"train_idx =  GLR_labels['file_path'].values\ny = GLR_labels['landmark_id'].values\ntest_idx = GLR_submission['file_path'].values","d4ca24e6":"test_idx","e4de8019":"x_train,x_valid,y_train,y_valid = train_test_split(train_idx,y,test_size=0.05,random_state=42)","be9aaf7a":"train_dataset = Dataset(x_train,y_train)\nvalid_dataset = Dataset(x_valid,y_valid)\ntest_dataset = Dataset(test_idx)","85121aac":"print(len(train_dataset))","430ff21f":"temp=train_dataset[1]","5174e74a":"train_dataset[0][0].shape","c31f8c2d":"train_dataset[0][1]","a1a79d6b":"from tensorflow.keras.applications import EfficientNetB1\nmodel = EfficientNetB1(weights='imagenet')\n","61a9123d":"!pip install -U efficientnet\n","70c84371":"import efficientnet.keras as efn\n","51088ddb":"model = tf.keras.Sequential(\n        [efn.EfficientNetB0(include_top=False,input_shape=(256,256,3),weights='imagenet'),\n        L.GlobalAveragePooling2D(),\n        L.Dense(128,activation='relu'),\n        L.Dense(64,activation='relu'),\n        L.Dense(num_classes, activation='sigmoid')])\nmodel.summary()\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n              loss=keras.losses.SparseCategoricalCrossentropy(), metrics=[keras.metrics.SparseCategoricalAccuracy()])","6b87ab90":"model.fit(train_dataset,epochs=1,validation_data=valid_dataset)","7b0536f9":"# Dataset for all the images "}}