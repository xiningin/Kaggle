{"cell_type":{"f60a605f":"code","bcc1d606":"code","bff32b8e":"code","5a738691":"code","054882d3":"code","97119625":"code","c4f89602":"code","33342613":"code","e1fef62b":"code","aa4ce04a":"code","2b836b33":"code","bb5ae4e5":"code","17e35ebb":"code","3f631a4a":"code","acc57cc7":"code","bf636b92":"code","999cf117":"code","921ea848":"code","4392993f":"code","6ae9bdb4":"code","32e4fb36":"code","b310ac50":"code","bf6d7d8d":"code","3acfdc11":"code","1d21bc14":"code","d15f1603":"code","b753b700":"code","5c928ca8":"code","ac779839":"code","7c2a242a":"code","df6fb444":"code","1a2c732b":"code","6deb5134":"code","cd7b44d6":"code","1a9638c8":"code","7705b5b1":"code","f5169436":"code","6a9e0772":"code","7ac7eb70":"code","29ca7116":"code","f11b8792":"code","6998925f":"code","c7a399a2":"code","00e8b508":"code","372c3511":"code","09f85455":"code","576de850":"code","658dd690":"code","a8b98c4e":"code","fa22c47d":"code","d853571c":"code","be5820e8":"code","111fafcc":"code","5e4857f7":"code","a48c6ee2":"code","cac8ddca":"code","cbe40542":"code","156b6b3d":"code","45bf7867":"code","45fd951a":"code","ebd71145":"code","188d15fa":"markdown","913b4654":"markdown","2e4ff47a":"markdown","1401481d":"markdown","f6495263":"markdown","605a8848":"markdown","1c4fc1d4":"markdown","9cd9e286":"markdown","2165d5ae":"markdown","0fd6df67":"markdown","557a4401":"markdown","3e3ecd0e":"markdown","ed320352":"markdown","18dc0770":"markdown","b8a2a169":"markdown","f1979c99":"markdown","d77677e3":"markdown","87059d11":"markdown","d6ff6cd2":"markdown","0c9a55fc":"markdown","34b883ca":"markdown","f795f47e":"markdown","56cfbfb8":"markdown","55f7076b":"markdown"},"source":{"f60a605f":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nimport statsmodels.api as sm\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bcc1d606":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\") #loading datas\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest_df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nprint(f\"train shape : {train.shape} , test shape : {test.shape} \")","bff32b8e":"train.head()","5a738691":"train.describe()","054882d3":"corr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nf, ax = plt.subplots(figsize=(15, 12))\n\ncmap = sns.diverging_palette(250, 15, s=190, l=40, center=\"dark\", as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","97119625":"f, ax = plt.subplots(figsize=(19, 9))\nsns.lineplot(\n    data=train,\n    x=\"Id\", y=\"SalePrice\",palette=\"flare\",color='orange')","c4f89602":"\nfig = plt.figure(figsize=(25,18))\n\ngs = fig.add_gridspec(3,3)\n\n# fill grid with subplots\nax00 = fig.add_subplot(gs[0,0])\nax01 = fig.add_subplot(gs[0,1])\nax02 = fig.add_subplot(gs[0, 2])\nax10 = fig.add_subplot(gs[1,0])\nax11 = fig.add_subplot(gs[1,1])\nax12 = fig.add_subplot(gs[1,2])\nax20 = fig.add_subplot(gs[2,0])\nax21 = fig.add_subplot(gs[2,1])\nax22 = fig.add_subplot(gs[2,2])\n\nax00.set_title('OverallQual', fontsize=20)\nax01.set_title('LotShape', fontsize=20)\nax02.set_title('OverallCond', fontsize=20)\nax10.set_title('HeatingQC', fontsize=20)\nax11.set_title('ExterQual', fontsize=20)\nax12.set_title('BsmtQual', fontsize=20)\nax20.set_title('BsmtFinType1', fontsize=20)\nax21.set_title('KitchenQual', fontsize=20)\nax22.set_title('FireplaceQu', fontsize=20)\n\nax00.tick_params(labelsize=12)\nax01.tick_params(labelsize=12)\nax02.tick_params(labelsize=12)\nax10.tick_params(labelsize=12)\nax11.tick_params(labelsize=12)\nax12.tick_params(labelsize=12)\nax20.tick_params(labelsize=12)\nax21.tick_params(labelsize=12)\nax22.tick_params(labelsize=12)\n\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax00, bins=50, hue=\"OverallQual\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax01, bins=50, hue=\"LotShape\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax02, bins=25, hue=\"OverallCond\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax10, bins=25, hue=\"HeatingQC\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax11, bins=25, hue=\"ExterQual\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax12, bins=25, hue=\"BsmtQual\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax20, bins=25, hue=\"BsmtFinType1\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax21, bins=25, hue=\"KitchenQual\", palette=\"Set3\", multiple=\"stack\")\nsns.histplot(data = train,x=\"SalePrice\", kde=False, ax =ax22, bins=25, hue=\"FireplaceQu\", palette=\"Set3\", multiple=\"stack\")\n\n# add headline\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Quality and condition features vs SalePrice', fontsize=\"28\");","33342613":"f, ax = plt.subplots(figsize=(25, 10))\nax.tick_params(labelsize=15)\nsns.scatterplot(data=train, x=\"SalePrice\", y=\"YearBuilt\", hue=\"MSSubClass\", sizes=(50, 500), size=\"TotalBsmtSF\", palette=\"Paired\")\nf.subplots_adjust(top=0.9)\nf.suptitle('SalePrice compared to YearBuilt, MSSubClass and TotalBsmtSF', fontsize=\"28\");\n","e1fef62b":"def get_cat_idx():\n    cat_column_index=[]\n    for i in range(len(train.columns)):\n        if(train.iloc[:,i].dtype==\"O\"):\n            cat_column_index.append(i)\n    return cat_column_index    \n\ndef get_num_idx():\n    num_column_index=[]\n    for i in range(len(train.columns)):\n        if(train.iloc[:,i].dtype!=\"O\"):\n            num_column_index.append(i)\n    return num_column_index \n\ntrain_cat_idx = get_cat_idx()  \ntrain_num_idx = get_num_idx()","aa4ce04a":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        Q1 = np.percentile(df[c],25)\n        Q3 = np.percentile(df[c],75)\n        IQR = Q3 - Q1\n        outlier_step = IQR * 1.5\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 10)\n    \n    return multiple_outliers","2b836b33":"col_num_name=[]\nfor i in train_num_idx:\n    colname = train.columns[i]\n    col_num_name.append(colname)\n\ncol_num_name.remove('Id')","bb5ae4e5":"train.loc[detect_outliers(train,col_num_name)]","17e35ebb":"print(f\"train shape : {train.shape} , test shape : {test.shape} \")\ntrain_len = len(train)\ntrain = pd.concat([train,test],axis = 0).reset_index(drop = True)\nprint(f\"concatenate shape : {train.shape}\")","3f631a4a":"def find_missing_value(data):\n    nulls = data.isnull().sum()\n\n    for index,item in nulls.items():\n        if item>0:\n            print(f\"Index : {index}, Value : {item}\")  ","acc57cc7":"find_missing_value(train)","bf636b92":"index_nan_GarageArea = list(train[\"GarageArea\"][train[\"GarageArea\"].isnull()].index)\nfor i in index_nan_GarageArea:\n    GarageArea_pred = train[\"GarageArea\"][((train[\"GarageCars\"] == 2))].median()\n    GarageArea_med = train[\"GarageArea\"].median()\n    if not np.isnan(GarageArea_pred):\n        train[\"GarageArea\"].iloc[i] = GarageArea_pred\n    else:\n        train[\"GarageArea\"].iloc[i] = GarageArea_med","999cf117":"index_nan_LotFrontage = list(train[\"LotFrontage\"][train[\"LotFrontage\"].isnull()].index)\nfor i in index_nan_LotFrontage:\n    LotFrontage_pred = train[\"LotFrontage\"][((train[\"MSZoning\"] == train.iloc[i][\"MSZoning\"]) &(train[\"Neighborhood\"] == train.iloc[i][\"Neighborhood\"]))].median()\n    LotFrontage_med = train[\"LotFrontage\"].median()\n    if not np.isnan(LotFrontage_pred):\n        train[\"LotFrontage\"].iloc[i] = LotFrontage_pred\n    else:\n        train[\"LotFrontage\"].iloc[i] = LotFrontage_med","921ea848":"index_nan_BsmtFinSF1 = list(train[\"BsmtFinSF1\"][train[\"BsmtFinSF1\"].isnull()].index)\nfor i in index_nan_BsmtFinSF1:\n    BsmtFinSF1_pred = train[\"BsmtFinSF1\"][((train[\"LotConfig\"] == train.iloc[i][\"LotConfig\"]) &(train[\"HouseStyle\"] == train.iloc[i][\"HouseStyle\"]))].median()\n    BsmtFinSF1_med = train[\"BsmtFinSF1\"].median()\n    if not np.isnan(BsmtFinSF1_pred):\n        train[\"BsmtFinSF1\"].iloc[i] = BsmtFinSF1_pred\n    else:\n        train[\"BsmtFinSF1\"].iloc[i] = BsmtFinSF1_med","4392993f":"index_nan_BsmtFinSF2 = list(train[\"BsmtFinSF2\"][train[\"BsmtFinSF2\"].isnull()].index)\nfor i in index_nan_BsmtFinSF2:\n    BsmtFinSF2_pred = train[\"BsmtFinSF2\"][((train[\"LotConfig\"] == train.iloc[i][\"LotConfig\"]) &(train[\"HouseStyle\"] == train.iloc[i][\"HouseStyle\"]))].median()\n    BsmtFinSF2_med = train[\"BsmtFinSF2\"].median()\n    if not np.isnan(BsmtFinSF2_pred):\n        train[\"BsmtFinSF2\"].iloc[i] = BsmtFinSF2_pred\n    else:\n        train[\"BsmtFinSF2\"].iloc[i] = BsmtFinSF2_med","6ae9bdb4":"index_nan_BsmtUnfSF = list(train[\"BsmtUnfSF\"][train[\"BsmtUnfSF\"].isnull()].index)\nfor i in index_nan_BsmtFinSF2:\n    BsmtUnfSF_pred = train[\"BsmtUnfSF\"][((train[\"LotConfig\"] == train.iloc[i][\"LotConfig\"]) &(train[\"HouseStyle\"] == train.iloc[i][\"HouseStyle\"]))].median()\n    BsmtUnfSF_med = train[\"BsmtUnfSF\"].median()\n    if not np.isnan(BsmtUnfSF_pred):\n        train[\"BsmtUnfSF\"].iloc[i] = BsmtUnfSF_pred\n    else:\n        train[\"BsmtUnfSF\"].iloc[i] = BsmtUnfSF_med","32e4fb36":"index_nan_TotalBsmtSF = list(train[\"TotalBsmtSF\"][train[\"TotalBsmtSF\"].isnull()].index)\nfor i in index_nan_TotalBsmtSF:\n    TotalBsmtSF_pred = train[\"TotalBsmtSF\"][((train[\"LotConfig\"] == train.iloc[i][\"LotConfig\"]) &(train[\"HouseStyle\"] == train.iloc[i][\"HouseStyle\"]))].median()\n    TotalBsmtSF_med = train[\"TotalBsmtSF\"].median()\n    if not np.isnan(TotalBsmtSF_pred):\n        train[\"TotalBsmtSF\"].iloc[i] = TotalBsmtSF_pred\n    else:\n        train[\"TotalBsmtSF\"].iloc[i] = TotalBsmtSF_med","b310ac50":"def fill_with_n(feature):\n    train[feature] = train[feature].fillna(\"N\")","bf6d7d8d":"n_list=[\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"BsmtFinType2\",\"Fence\",\"GarageQual\",\"GarageCond\",\"GarageType\",\"GarageYrBlt\",\"GarageFinish\"]","3acfdc11":"for f in n_list:\n    fill_with_n(f)","1d21bc14":"train[\"Electrical\"] = train[\"Electrical\"].fillna(\"FuseA\")\ntrain[\"Utilities\"] = train[\"Utilities\"].fillna(\"AllPub\")\ntrain[\"Exterior1st\"] = train[\"Exterior1st\"].fillna(\"VinylSd\")\ntrain[\"Exterior2nd\"] = train[\"Exterior2nd\"].fillna(\"VinylSd\")\ntrain[\"MSZoning\"] = train[\"MSZoning\"].fillna(\"RL\")\ntrain[\"SaleType\"] = train[\"SaleType\"].fillna(\"WD\")\ntrain[\"GarageCars\"] = train[\"GarageCars\"].fillna(2)\ntrain[\"KitchenQual\"] = train[\"KitchenQual\"].fillna(\"TA\")\ntrain[\"BsmtFullBath\"] = train[\"BsmtFullBath\"].fillna(0)\ntrain[\"BsmtHalfBath\"] = train[\"BsmtHalfBath\"].fillna(0)","d15f1603":"train = train.drop([\"MasVnrType\",\"Id\",\"MasVnrArea\",\"Alley\",\"FireplaceQu\",\"Street\",\"PoolQC\",\"MiscFeature\",\"Functional\",\"LandContour\",\"Utilities\",\"RoofMatl\",\"Heating\",\"GarageCond\"], axis=1)","b753b700":"find_missing_value(train)","5c928ca8":"ax = sns.countplot(x=\"ExterCond\", data=train,palette=\"dark:salmon_r\")","ac779839":"other_BsmtCond = list(train[(train[\"BsmtCond\"]!='TA')]['BsmtCond'].index) \nfor i in other_BsmtCond:\n    train[\"BsmtCond\"].iloc[i] = 'Other'","7c2a242a":"other_ExterCond = list(train[(train[\"ExterCond\"]!='TA')&(train[\"ExterCond\"]!='Gd')&(train[\"ExterCond\"]!='Fa')]['ExterCond'].index) \nfor i in other_ExterCond:\n    train[\"ExterCond\"].iloc[i] = 'Other'","df6fb444":"other_LandSlope = list(train[(train[\"LandSlope\"]!='Gtl')]['LandSlope'].index) \nfor i in other_LandSlope:\n    train[\"LandSlope\"].iloc[i] = 'Other'","1a2c732b":"other_BsmtFinType2 = list(train[(train[\"BsmtFinType2\"]!='Unf')]['BsmtFinType2'].index) \nfor i in other_BsmtFinType2:\n    train[\"BsmtFinType2\"].iloc[i] = 'Other'","6deb5134":"other_Electrical = list(train[(train[\"Electrical\"]!='SBrkr')]['Electrical'].index) \nfor i in other_Electrical:\n    train[\"Electrical\"].iloc[i] = 'Other'","cd7b44d6":"other_GarageQual = list(train[(train[\"GarageQual\"]!='TA')&(train[\"GarageQual\"]!='N')&(train[\"GarageQual\"]!='Fa')]['GarageQual'].index) \nfor i in other_GarageQual:\n    train[\"GarageQual\"].iloc[i] = 'Other'","1a9638c8":"other_SaleType = list(train[(train[\"SaleType\"]!='WD')&(train[\"SaleType\"]!='New')&(train[\"SaleType\"]!='COD')]['SaleType'].index) \nfor i in other_SaleType:\n    train[\"SaleType\"].iloc[i] = 'Other'","7705b5b1":"def find_pool(data):\n    data[[\"HavePool\"]] = 0\n    \n    pool_t = data[data[\"PoolArea\"]!=0].index\n    data[\"HavePool\"].iloc[pool_t] = 1\n    \n    data = data.drop([\"PoolArea\"], axis=1)\n        \n    return data\n\ntrain = find_pool(train)","f5169436":"def resto(data):\n\n    data[[\"Rest\"]]=data[\"YearRemodAdd\"]-data[\"YearBuilt\"]\n    data = data.drop([\"YearRemodAdd\"], axis=1)    \n    return data\n\ntrain = resto(train)","6a9e0772":"train.shape","7ac7eb70":"train_cat_idx = get_cat_idx() \ntrain_num_idx = get_num_idx()","29ca7116":"col_cat_name=[]\nfor i in train_cat_idx:\n    colname = train.columns[i]\n    col_cat_name.append(colname)","f11b8792":"for f in col_cat_name:\n    train = pd.get_dummies(train, columns= [f])","6998925f":"col_num_name=[]\nfor i in train_num_idx:\n    colname = train.columns[i]\n    col_num_name.append(colname)","c7a399a2":"train[\"MSSubClass\"] = train[\"MSSubClass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns= [\"MSSubClass\"])\n\ntrain[\"HavePool\"] = train[\"HavePool\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns= [\"HavePool\"])\n","00e8b508":"test = train[train_len:]\ntrain = train[:train_len]\n\ntest.drop(labels = [\"SalePrice\"],axis = 1, inplace = True)","372c3511":"print(f\"train shape : {train.shape} , test shape : {test.shape} \")","09f85455":"X_train = train.drop(labels = \"SalePrice\", axis = 1)\ny_train = train[\"SalePrice\"]","576de850":"def backward_elimination(data, target,significance_level = 0.05):\n    features = data.columns.tolist()\n    while(len(features)>0):\n        features_with_constant = sm.add_constant(data[features])\n        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n        max_p_value = p_values.max()\n        if(max_p_value >= significance_level):\n            excluded_feature = p_values.idxmax()\n            features.remove(excluded_feature)\n        else:\n            break \n    return features","658dd690":"feat=backward_elimination(X_train,y_train)","a8b98c4e":"X_train = X_train.loc[:,feat]\nX_test = test.loc[:,feat]","fa22c47d":"X_train = X_train.to_numpy()\nX_test = X_test.to_numpy()\ny_train = y_train.to_numpy()","d853571c":"print(f\"X_train shape : {X_train.shape} ,X_test shape : {X_test.shape} , y_train shape : {y_train.shape} \")","be5820e8":"model = sm.OLS(y_train,X_train).fit()\nmodel.summary()","111fafcc":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import linear_model\nfrom sklearn.model_selection import GridSearchCV\n","5e4857f7":"xgb_model = XGBRegressor(subsample=0.7, learning_rate=0.02, max_depth=3, random_state=np.random.randint(1000),n_estimators=500).fit(X_train, y_train)\nprint(\"Performance on train data:\", xgb_model.score(X_train, y_train))","a48c6ee2":"gb_model = GradientBoostingRegressor(subsample=0.7,learning_rate=0.017, max_depth=4 ,random_state=np.random.randint(1000),n_estimators=800).fit(X_train, y_train)\nprint(\"Performance on train data:\", gb_model.score(X_train, y_train))","cac8ddca":"clf = linear_model.Lasso(alpha=0.5).fit(X_train, y_train)\nprint(\"Performance on train data:\", clf.score(X_train, y_train))","cbe40542":"y_pred_xgb = xgb_model.predict(X_test)\ny_pred_gb = gb_model.predict(X_test)\ny_pred_clf = clf.predict(X_test)","156b6b3d":"submission_xgb = pd.DataFrame(columns=['Id', 'SalePrice'])\nsubmission_xgb['Id'] = test_df['Id']\nsubmission_xgb['SalePrice'] = y_pred_xgb\nsubmission_xgb.to_csv('submission_xgb.csv', index=False)","45bf7867":"submission_gb = pd.DataFrame(columns=['Id', 'SalePrice'])\nsubmission_gb['Id'] = test_df['Id']\nsubmission_gb['SalePrice'] = y_pred_gb\nsubmission_gb.to_csv('submission_gb.csv', index=False)","45fd951a":"model_dict = pd.DataFrame(columns=['model', 'acc'])\nmodel_dict['model'] = [\"xgb_model\",\"gb_model\",\"clf\"]\nmodel_dict['acc'] = [0.9539 , 0.9818 , 0.8918]","ebd71145":"fig = plt.figure(figsize=(10,7))\nax = sns.barplot(x=\"model\", y=\"acc\", data=model_dict, palette=\"Set3\")\nax.set(xlabel = 'Models', ylabel='Accuracy', title='MODELS VS ACCURACY')","188d15fa":"<a id=\"41\"> <\/a>\n## Changing The Distribution Of Categories","913b4654":"<a id=\"31\"> <\/a>\n## Find Outliers","2e4ff47a":"<br>\n<h1 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #C66363 ; color : #E8D6D8; text-align: center; border-radius: 100px 100px;\">CONTENT <\/h1>\n<br>\n<img style =\"margin-left: auto; margin-right: auto; margin-bottom: 20;\" src=\"https:\/\/bordoklavyeli.net\/wp-content\/uploads\/2019\/08\/stonks.jpg\" alt=\"\u0131nc\" class=\"center\" width=\"500\">\n<img style =\"margin-left: auto; margin-right: auto; margin-bottom: 20;\" src=\"https:\/\/www.tekyedi.com\/wp-content\/uploads\/2021\/05\/nostonks-1.jpg\" alt=\"dec\" class=\"center\" width=\"500\">\n\n\n* #### [Add Libaries](#1)\n* #### [Load and Examine Data](#2)\n    * ##### [Examine Data](#21)\n    * ##### [Visualize Data](#22)\n* #### [Preprocess Data](#3)\n    * ##### [Dropping Outliers](#31)\n    * ##### [Concatenating Train and Test Data](#32)\n    * ##### [Find And Drop High Missing Value Columns](#33)\n    * ##### [Fill Missing Values](#34)\n* #### [Feature Engineering](#4)\n    * ##### [Changing The Distribution Of Categories](#41)\n    * ##### [Make New Features](#42)\n    * ##### [Dummy Encoding](#43)\n* #### [Make Models](#5) \n    * ##### [Separating Test And Train Datas](#51)\n    * ##### [Backward Elimination](#52)\n    * ##### [Importing Models Libaries](#53)\n    * ##### [XGB Model](#54)\n    * ##### [GB Model](#55)\n    * ##### [CLF Model](#56)\n    * ##### [Make Prediction](#57)\n    * ##### [Submissons](#58)\n    * ##### [Visualize Predictions](#59)","1401481d":"<a id=\"57\"> <\/a>\n## Make Prediction","f6495263":"<a id=\"58\"> <\/a>\n## Submissions","605a8848":"<a id=\"42\"> <\/a>\n## Make New Features","1c4fc1d4":"<a id=\"5\"> <\/a>\n# Make Models","9cd9e286":"<a id=\"4\"> <\/a>\n# Feature Engineering","2165d5ae":"<a id=\"51\"> <\/a>\n## Separating Test And Train Datas","0fd6df67":"<a id=\"52\"> <\/a>\n## Backward Elemination","557a4401":"<a id=\"56\"> <\/a>\n## CLF Model ","3e3ecd0e":"<a id=\"3\"> <\/a>\n# Preprocess Data","ed320352":"<a id=\"22\"> <\/a>\n## Visualize Data","18dc0770":"<a id=\"2\"> <\/a>\n# Load and Examine Data","b8a2a169":"<a id=\"32\"> <\/a>\n## Concatenating Train and Test Data","f1979c99":"<a id=\"53\"> <\/a>\n## Importing Models Libaries","d77677e3":"<a id=\"1\"> <\/a>\n# Add Libaries","87059d11":"<a id=\"59\"> <\/a>\n## Visualize Predictions","d6ff6cd2":"<a id=\"34\"> <\/a>\n## Fill Missing Values","0c9a55fc":"<a id=\"54\"> <\/a>\n## XGB Model ","34b883ca":"<a id=\"43\"> <\/a>\n## Dummy Encoding","f795f47e":"<a id=\"33\"> <\/a>\n## Find And Drop High Missing Value Columns ","56cfbfb8":"<a id=\"21\"> <\/a>\n## Examine Data","55f7076b":"<a id=\"55\"> <\/a>\n## GB Model "}}