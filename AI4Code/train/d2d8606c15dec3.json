{"cell_type":{"6c752bec":"code","3ffeb8c5":"code","5c18c85e":"code","0e64eaae":"code","5bfc738a":"code","2a85439d":"code","af67ac78":"code","4414c45a":"code","5af96384":"code","ab9b75b6":"code","da74a128":"code","41215ad7":"code","57d4ab6b":"code","38fa9c3c":"code","7fb7f85e":"markdown","80b8b455":"markdown","123912f0":"markdown","a47f26e1":"markdown"},"source":{"6c752bec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom functools import reduce\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3ffeb8c5":"M1 = pd.read_csv('..\/input\/home123\/11111.csv')\nM2 = pd.read_csv('..\/input\/home123\/22222.csv')\nM3 = pd.read_csv('..\/input\/home123\/33333.csv')\nM4 = pd.read_csv('..\/input\/home123\/44444.csv')\nM5 = pd.read_csv('..\/input\/home123\/55555.csv')\nM6 = pd.read_csv('..\/input\/home123\/Think1.csv')\nM7 = pd.read_csv('..\/input\/home123\/new1submit8aug.csv')\nM8 = pd.read_csv('..\/input\/home123\/newthinking.csv')\nM9 = pd.read_csv('..\/input\/home123\/Think123.csv')","5c18c85e":"# Function for merging dataframes efficiently \ndef merge_dataframes(dfs, merge_keys):\n    dfs_merged = reduce(lambda left,right: pd.merge(left, right, on=merge_keys), dfs)\n    return dfs_merged","0e64eaae":"dfs = [M1,M2,M3,M4,M5,M6,M7,M8,M9]\nmerge_keys=['SK_ID_CURR']\ndf = merge_dataframes(dfs, merge_keys=merge_keys)","5bfc738a":"df.columns = ['SK_ID_CURR','T1','T2','T3','T4','T5','T6','T7','T8','T9']\ndf.head()","2a85439d":"pred_prob = 0.6 * df['T9'] + 0.4 * df['T6']\npred_prob.head()","af67ac78":"sub = pd.DataFrame()\nsub['SK_ID_CURR'] = df['SK_ID_CURR']\nsub['target']= pred_prob","4414c45a":"sub.to_csv('ldit.csv', index=False)","5af96384":"B_prob = 0.4 * df['T9'] + 0.15 * df['T4'] + 0.15 * df['T6'] + 0.15 *df['T1'] + 0.15*df['T5']","ab9b75b6":"B_prob.head()","da74a128":"SUB = pd.DataFrame()\nSUB['SK_ID_CURR'] = df['SK_ID_CURR']\nSUB['TARGET'] = B_prob\nSUB.to_csv('Blendss.csv', index=False)","41215ad7":"df_c = df.copy()\ndf_c = df.drop(['SK_ID_CURR'],axis=1)\nCorr_Mat = df_c.corr()\nprint(Corr_Mat) # Correlation matrix of five submission files\nsns.heatmap(Corr_Mat)","57d4ab6b":"corr_pred = 0.6 * df['T9'] + 0.2 * df['T8'] + 0.2 * df['T7']\ncorr_pred.head()","38fa9c3c":"SuB = pd.DataFrame()\nSuB['SK_ID_CURR'] = df['SK_ID_CURR']\nSuB['TARGET'] = corr_pred\nSuB.to_csv('corr_blend.csv', index=False)","7fb7f85e":"## Blending lowest correlated models","80b8b455":"## Diversified blend [0.803 LB]\n\n\n**The blending ingredients are taken from three different type of models.**","123912f0":"**This is my first try towards blending. Do upvote if you like it and also if you have any ideas do share in the comment section below.**\n\n**To be Continued**","a47f26e1":"## Blend with one rank weighted submission [0.8 LB]"}}