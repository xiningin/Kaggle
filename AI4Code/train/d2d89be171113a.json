{"cell_type":{"ec877371":"code","00a06b38":"code","da80cc6b":"code","17bc2401":"code","77af150c":"code","c777f3f4":"code","923334d3":"code","a2bbd714":"code","67f64445":"code","78f89ed4":"code","15905577":"code","baf0661c":"markdown","b099f091":"markdown","e20cad8e":"markdown","f3b1f7ac":"markdown","cd2b4df0":"markdown","9b71e614":"markdown"},"source":{"ec877371":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport glob\n%matplotlib inline","00a06b38":"print(\"TensorFlow Version: {}\".format(tf.__version__))","da80cc6b":"def generator(inputs_real, is_train=True, alpha=0.01, name=\"generator\"):\n    # 256*256*3\n    with tf.variable_scope(name, reuse=(not is_train)):\n        # 128*128*64\n        conv1 = tf.layers.conv2d(inputs_real, 64, (3,3), padding='same')\n        conv1 = tf.nn.relu(conv1)\n        conv1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n        # 64*64*128\n        conv2 = tf.layers.conv2d(conv1, 128, (3,3), padding='same')\n        conv2 = tf.layers.conv2d(conv1, 128, (3,3), padding='same')\n        conv2 = tf.nn.relu(conv2)\n        conv2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n        # 32*32*256\n        conv3 = tf.layers.conv2d(conv2, 256, (3,3), padding='same')\n        conv3 = tf.layers.conv2d(conv2, 256, (3,3), padding='same')\n        conv3 = tf.nn.relu(conv3)\n        conv3 = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n        # 16*16*512\n        conv4 = tf.layers.conv2d(conv3, 512, (3,3), padding='same')\n        conv4 = tf.layers.conv2d(conv3, 512, (3,3), padding='same')\n        conv4 = tf.nn.relu(conv4)\n        conv4 = tf.layers.max_pooling2d(conv4, (2,2), (2,2), padding='same')\n        # 8*8*512\n        conv5 = tf.layers.conv2d(conv4, 512, (3,3), padding='same')\n        conv5 = tf.layers.conv2d(conv4, 512, (3,3), padding='same')\n        conv5 = tf.nn.relu(conv5)\n        conv5 = tf.layers.max_pooling2d(conv5, (2,2), (2,2), padding='same')\n        # 4*4*512\n        conv6 = tf.layers.conv2d(conv5, 512, (3,3), padding='same')\n        conv6 = tf.layers.conv2d(conv5, 512, (3,3), padding='same')\n        conv6 = tf.nn.relu(conv6)\n        conv6 = tf.layers.max_pooling2d(conv6, (2,2), (2,2), padding='same')\n        # 2*2*512\n        conv7 = tf.layers.conv2d(conv6, 512, (3,3), padding='same')\n        conv7 = tf.layers.conv2d(conv6, 512, (3,3), padding='same')\n        conv7 = tf.nn.relu(conv7)\n        conv7 = tf.layers.max_pooling2d(conv7, (2,2), (2,2), padding='same')\n        # 1*1*512\n        conv8 = tf.layers.conv2d(conv7, 512, (3,3), padding='same')\n        conv8 = tf.nn.relu(conv8)\n        conv8 = tf.layers.max_pooling2d(conv8, (2,2), (2,2), padding='same')\n        \n        \n        # 2*2*512\n        conv9 = tf.layers.conv2d_transpose(conv8, 512, 3, strides=2, padding='same')\n        conv9 = tf.layers.batch_normalization(conv9, training=is_train)\n        conv9 = tf.nn.relu(conv9)\n        conv9 = tf.nn.dropout(conv9, keep_prob=0.5)\n        # 4*4*512\n        conv10 = tf.concat([conv9,conv7], 3)\n        conv10 = tf.layers.conv2d_transpose(conv10, 512, 3, strides=2, padding='same')\n        conv10 = tf.layers.batch_normalization(conv10, training=is_train)\n        conv10 = tf.nn.relu(conv10)\n        conv10 = tf.nn.dropout(conv10, keep_prob=0.5)\n        # 8*8*512\n        conv11 = tf.concat([conv10,conv6], 3)\n        conv11 = tf.layers.conv2d_transpose(conv11, 512, 3, strides=2, padding='same')\n        conv11 = tf.layers.batch_normalization(conv11, training=is_train)\n        conv11 = tf.nn.relu(conv11)\n        conv11 = tf.nn.dropout(conv11, keep_prob=0.5)\n        # 16*16*512\n        conv12 = tf.concat([conv11,conv5], 3)\n        conv12 = tf.layers.conv2d_transpose(conv12, 512, 3, strides=2, padding='same')\n        conv12 = tf.layers.batch_normalization(conv12, training=is_train)\n        conv12 = tf.nn.relu(conv12)\n        # 32*32*256\n        conv13 = tf.concat([conv12,conv4], 3)\n        conv13 = tf.layers.conv2d_transpose(conv13, 256, 3, strides=2, padding='same')\n        conv13 = tf.layers.batch_normalization(conv13, training=is_train)\n        conv13 = tf.nn.relu(conv13)\n        # 64*64*128\n        conv14 = tf.concat([conv13,conv3], 3)\n        conv14 = tf.layers.conv2d_transpose(conv14, 128, 3, strides=2, padding='same')\n        conv14 = tf.layers.batch_normalization(conv14, training=is_train)\n        conv14 = tf.nn.relu(conv14)\n        # 128*128*64\n        conv15 = tf.concat([conv14,conv2], 3)\n        conv15 = tf.layers.conv2d_transpose(conv15, 64, 3, strides=2, padding='same')\n        conv15 = tf.layers.batch_normalization(conv15, training=is_train)\n        conv15 = tf.nn.relu(conv15)\n        # 256*256*3\n        conv16 = tf.concat([conv15,conv1], 3)\n        conv16 = tf.layers.conv2d_transpose(conv16, 3, 3, strides=2, padding='same')\n#        conv16 = tf.layers.batch_normalization(conv16, training=is_train)\n    \n        # \u56fe\u7247\u5f52\u4e00\u5316\n        outputs = tf.nn.tanh(conv16)\n        \n        return outputs","17bc2401":"def discriminator(inputs_image, reuse=False, alpha=0.01, name=\"discriminator\"):\n    \n    with tf.variable_scope(name, reuse=reuse):\n        \n\n        layer1 = tf.layers.conv2d(inputs_image, 64, 3, strides=2, padding='same')\n        layer1 = tf.layers.batch_normalization(layer1, training=True)\n        layer1 = tf.maximum(alpha * layer1, layer1)\n        \n        layer2 = tf.layers.conv2d(layer1, 64, 3, strides=2, padding='same')\n        layer2 = tf.layers.conv2d(layer1, 64, 3, strides=2, padding='same')\n        layer2 = tf.layers.batch_normalization(layer2, training=True)\n        layer2 = tf.maximum(alpha * layer2, layer2)\n        \n        layer3 = tf.layers.conv2d(layer2, 128, 3, strides=2, padding='same')\n        layer3 = tf.layers.conv2d(layer2, 128, 3, strides=2, padding='same')\n        layer3 = tf.layers.batch_normalization(layer3, training=True)\n        layer3 = tf.maximum(alpha * layer3, layer3)\n        \n        layer4 = tf.layers.conv2d(layer3, 128, 3, strides=2, padding='same')\n        layer4 = tf.layers.conv2d(layer3, 128, 3, strides=2, padding='same')\n        layer4 = tf.layers.batch_normalization(layer4, training=True)\n        layer4 = tf.maximum(alpha * layer4, layer4)\n        \n        layer5 = tf.layers.conv2d(layer4, 256, 3, strides=2, padding='same')\n        layer5 = tf.layers.conv2d(layer4, 256, 3, strides=2, padding='same')\n        layer5 = tf.layers.batch_normalization(layer5, training=True)\n        layer5 = tf.maximum(alpha * layer5, layer5)\n        \n        layer6 = tf.layers.conv2d(layer5, 256, 3, strides=2, padding='same')\n        layer6 = tf.layers.conv2d(layer5, 256, 3, strides=2, padding='same')\n        layer6 = tf.layers.batch_normalization(layer6, training=True)\n        layer6 = tf.maximum(alpha * layer6, layer6)\n        \n        layer7 = tf.layers.conv2d(layer6, 512, 3, strides=2, padding='same')\n        layer7 = tf.layers.conv2d(layer6, 512, 3, strides=2, padding='same')\n        layer7 = tf.layers.batch_normalization(layer7, training=True)\n        layer7 = tf.maximum(alpha * layer7, layer7)\n        \n        flatten = tf.reshape(layer7, (-1, 2*2*512))\n        logits = tf.layers.dense(flatten, 1)\n        outputs = tf.sigmoid(logits)\n        \n        return  logits, outputs","77af150c":"def get_loss(inputs_images, inputs_cartoons, smooth=0.1):\n    \n    \n    fake_cartoons = generator(inputs_images, name=\"generatorI2C\")\n    fake_images_ = generator(fake_cartoons, name=\"generatorC2I\")\n    fake_images = generator(inputs_cartoons, False, name=\"generatorC2I\")\n    fake_cartoons_ = generator(fake_images, False, name=\"generatorI2C\")\n\n    discriminator_cartoon_fake, cartoon_fake_logits = discriminator(fake_cartoons, reuse=False, name=\"discriminator_cartoon\")\n    discriminator_image_fake, image_fake_logits = discriminator(fake_images, reuse=False, name=\"discriminator_image\")\n    \n    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=cartoon_fake_logits, \n                                                                    labels=tf.ones_like(discriminator_cartoon_fake)*(1-smooth))) \\\n            + tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=image_fake_logits,\n                                                                    labels=tf.ones_like(discriminator_image_fake)*(1-smooth))) \\\n            + tf.reduce_mean(tf.abs(inputs_images - fake_images_))\\\n            + tf.reduce_mean(tf.abs(inputs_cartoons - fake_cartoons_))\n            \n            \n    \n    discriminator_cartoon_real, cartoon_real_logits = discriminator(inputs_cartoons, reuse=True, name=\"discriminator_cartoon\")\n    discriminator_image_real, image_real_logits = discriminator(inputs_images, reuse=True, name=\"discriminator_image\")\n    \n    d_cartoon_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=cartoon_real_logits, \n                                                                                 labels=tf.ones_like(discriminator_cartoon_real)*(1-smooth)))\n    d_image_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=image_real_logits, \n                                                                                 labels=tf.ones_like(discriminator_image_real)*(1-smooth)))\n    d_cartoon_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=cartoon_fake_logits, \n                                                                                 labels=tf.zeros_like(discriminator_cartoon_fake)*(1-smooth)))\n    d_image_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=image_fake_logits, \n                                                                                 labels=tf.zeros_like(discriminator_image_fake)*(1-smooth)))\n    \n    d_loss = d_cartoon_real_loss + d_image_real_loss + d_cartoon_fake_loss + d_image_fake_loss\n\n    \n    return g_loss, d_loss","c777f3f4":"def get_optimizer(g_loss, d_loss, g_loss_tran, learning_rate=0.0001):\n    \n    train_vars = tf.trainable_variables()\n    \n    g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n    d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n    \n    \n    # Optimizer\n    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n        g_opt = tf.train.AdamOptimizer(learning_rate*5).minimize(g_loss, var_list=g_vars)\n        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n    \n    return g_opt, d_opt","923334d3":"def plot_images(samples):\n    samples = (samples + 1) \/ 2\n    fig, axes = plt.subplots(nrows=1, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n    for img, ax in zip(samples, axes):\n        ax.imshow(img)\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    fig.tight_layout(pad=0)","a2bbd714":"def show_generator_output(sess, samp_images):\n    samples = sess.run(generator(samp_images, False , name=\"generatorI2C\"))\n    samples = sess.run(tf.reshape(samples, [-1, 256, 256, 3]))\n    return samples\n","67f64445":"# \u5b9a\u4e49\u53c2\u6570\nbeta1 = 0.4\nlearning_rate = 0.0001","78f89ed4":"def train():\n    \n    # \u5b58\u50a8loss\n    losses = []\n    steps = 1000\n    \n    apple_list = glob.glob('..\/input\/white1118\/*.jpg')\n    orange_list = glob.glob('..\/input\/bb1110\/*.jpg')\n    image_que = tf.train.slice_input_producer([apple_list, orange_list], shuffle=True)\n    \n    image_ = tf.read_file(image_que[0])\n    image = tf.image.decode_jpeg(image_, channels=3)\n    image = tf.image.resize_image_with_crop_or_pad(image, 256, 256)\n    \n    \n    new_img = tf.image.convert_image_dtype(image, tf.float32)\n    new_img = new_img*2 -1\n    \n    cartoon_ = tf.read_file(image_que[1])\n    cartoon = tf.image.decode_jpeg(cartoon_, channels=3)\n    cartoon = tf.image.resize_image_with_crop_or_pad(cartoon, 256, 256)\n    \n    \n    new_cartoon = tf.image.convert_image_dtype(cartoon, tf.float32)\n    new_cartoon = new_cartoon*2 -1\n    \n    batch_size = 20\n    capacity = 3 + 2 * batch_size\n          \n    image_batch, cartoon_batch = tf.train.batch([new_img, new_cartoon], batch_size=batch_size, capacity=capacity)\n    \n    g_loss, d_loss = get_loss(image_batch, cartoon_batch)\n    g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, beta1, learning_rate)\n    \n    \n    saver = tf.train.Saver()\n#    model_file=tf.train.latest_checkpoint('..\/input\/cycel-apple-to-orange')\n    with tf.Session() as sess:\n#        saver.restore(sess, model_file)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        sess.run(tf.global_variables_initializer())\n        \n        \n        \n        \n        # \u8fed\u4ee3epoch\n        \n        for e in range(steps):\n                # run optimizer\n            _ = sess.run(d_train_opt)\n            _ = sess.run(g_train_opt)\n                \n            if e % 100 == 0:\n#                saver.save(sess,'.\/less96', global_step = e)\n                train_loss_d = d_loss.eval()\n                train_loss_g = g_loss.eval()\n                losses.append((train_loss_d, train_loss_g))\n                    # \u663e\u793a\u56fe\u7247\n                samples = show_generator_output(sess, image_batch)\n                plot_images(samples)\n                \n                print(\"Epoch {}\/{}....\".format(e+1, steps), \n                     \"Discriminator Loss: {:.4f}....\".format(train_loss_d),\n                     \"Generator Loss: {:.4f}....\". format(train_loss_g))\n        saver.save(sess,'.\/less96',global_step = steps)\n        coord.request_stop()\n        coord.join(threads)                 ","15905577":"with tf.Graph().as_default():\n    train()","baf0661c":"# Generator","b099f091":"## Train","e20cad8e":"## Discriminator","f3b1f7ac":"## \u8f85\u52a9\u51fd\u6570\uff0c\u7528\u6765\u5728\u8fed\u4ee3\u4e2d\u663e\u793a\u56fe\u7247","cd2b4df0":"## Optimizer","9b71e614":"## Loss"}}