{"cell_type":{"d95710a6":"code","ecfc3874":"code","a1d60486":"code","90b890ed":"code","4a56d415":"code","6633e90c":"markdown","71a3b036":"markdown","79734e4d":"markdown"},"source":{"d95710a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport keras\nfrom keras import layers\nfrom keras.preprocessing import image\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ecfc3874":"latent_dim = 32\nheight = 32\nwidth = 32\nchannels = 3\n\ngenerator_input = keras.Input(shape=(latent_dim,))\nx = layers.Dense(128 * 16 * 16)(generator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((16, 16, 128))(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\ngenerator = keras.models.Model(generator_input, x)\ngenerator.summary()","a1d60486":"discriminator_input = layers.Input(shape=(height, width, channels))\nx = layers.Conv2D(128, 3)(discriminator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.4)(x)\nx = layers.Dense(1, activation='sigmoid')(x)\ndiscriminator = keras.models.Model(discriminator_input, x)\ndiscriminator.summary()\ndiscriminator_optimizer = keras.optimizers.RMSprop(\n    lr=0.0008,\n    clipvalue=1.0,\n    decay=1e-8)\ndiscriminator.compile(optimizer=discriminator_optimizer,\n    loss='binary_crossentropy')","90b890ed":"discriminator.trainable = False\ngan_input = keras.Input(shape=(latent_dim,))\ngan_output = discriminator(generator(gan_input))\ngan = keras.models.Model(gan_input, gan_output)\ngan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')","4a56d415":"(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\nx_train = x_train[y_train.flatten() == 6]\nx_train = x_train.reshape(\n    (x_train.shape[0],) +\n    (height, width, channels)).astype('float32') \/ 255.\niterations = 10000\nbatch_size = 20\nsave_dir = '..\/working'\nstart = 0\nfor step in range(iterations):\n    random_latent_vectors = np.random.normal(size=(batch_size,\n    latent_dim))\n    generated_images = generator.predict(random_latent_vectors)\n    stop = start + batch_size\n    real_images = x_train[start: stop]\n    combined_images = np.concatenate([generated_images, real_images])\n    labels = np.concatenate([np.ones((batch_size, 1)),\n        np.zeros((batch_size, 1))])\n    labels += 0.05 * np.random.random(labels.shape)\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n    random_latent_vectors = np.random.normal(size=(batch_size,\n        latent_dim))\n    misleading_targets = np.zeros((batch_size, 1))\n    a_loss = gan.train_on_batch(random_latent_vectors,\n        misleading_targets)\n    start += batch_size\n    if start > len(x_train) - batch_size:\n        start = 0\n    if step % 100 == 0:\n        gan.save_weights('gan.h5')\n        print('discriminator loss:', d_loss)\n        print('adversarial loss:', a_loss)\n        img = image.array_to_img(generated_images[0] * 255., scale=False)\n        img.save(os.path.join(save_dir,\n            'generated_frog' + str(step) + '.png'))\n        img = image.array_to_img(real_images[0] * 255., scale=False)\n        img.save(os.path.join(save_dir,\n            'real_frog' + str(step) + '.png'))","6633e90c":"## GAN training","71a3b036":"## GAN discriminator","79734e4d":"## Adversarial network"}}