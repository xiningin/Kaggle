{"cell_type":{"fab263d2":"code","d681f8e5":"code","e3577075":"code","04e30d8d":"code","00c1fd6b":"code","c109ee24":"code","6f0f5f0c":"code","f58c1b58":"code","e0c58d0d":"code","b8d2e5e2":"code","ce488a87":"code","e8a1ee12":"code","0c5b3653":"code","9efedb3a":"code","8f5359d9":"code","82705dc9":"code","56940c66":"code","2d78dc02":"code","f797cf44":"markdown","e15f4eae":"markdown","f66212e0":"markdown","65995987":"markdown","1c5c2b3c":"markdown","3bfc25e5":"markdown","854a053a":"markdown","82e80bdc":"markdown","4265a571":"markdown"},"source":{"fab263d2":"# packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Time to say good-bye, chainer...\nimport chainer\nimport chainer.links as L\nimport chainer.functions as F","d681f8e5":"# get datas\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ntest_df = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')\ntrain_df = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')\nprint(test_df.shape)\nprint(train_df.shape)","e3577075":"# load dataframe to numpy\nX_train, Y_train, X_test, Y_test= [], [], [], []\nX_train = train_df.iloc[:,1:].values.reshape(-1,1,28,28)\nY_train = train_df.iloc[:,0].values\n\nprint(len(X_train))\nprint(len(Y_train))","04e30d8d":"# Transfer 32\nX_train = X_train.astype('float32')\nY_train = Y_train.astype('int32')","00c1fd6b":"# Dataset for Chainer\ndataset = chainer.datasets.TupleDataset(X_train, Y_train)\nlen(dataset)","c109ee24":"# 70% as training\nn_train = int(len(dataset) * 0.7)\ntrain, test = chainer.datasets.split_dataset_random(dataset, n_train, seed=1)\n\n# check raws\nlen(train)","6f0f5f0c":"# very simple CNN\nclass CNN(chainer.Chain):\n\n    def __init__(self, n_mid=100, n_out=10):\n        super().__init__()\n        with self.init_scope():\n            self.conv1 = L.Convolution2D(in_channels=1, out_channels=3, ksize=6, stride=1, pad=1)\n            self.conv2 = L.Convolution2D(in_channels=1, out_channels=3, ksize=3, stride=1, pad=1)\n            self.fc1 = L.Linear(None, n_mid)\n            self.fc2 = L.Linear(None, n_out)\n\n    def __call__(self, x):\n        h = F.relu(self.conv1(x))\n        h = F.max_pooling_2d(h, 3, 3)\n        h = F.relu(self.conv2(x))\n        h = F.max_pooling_2d(h, 3, 3)\n        h = self.fc1(h)\n        h = self.fc2(h)\n        return h","f58c1b58":"# define random seed\nimport random\ndef reset_seed(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    if chainer.cuda.available:\n        chainer.cuda.cupy.random.seed(seed)","e0c58d0d":"reset_seed(0)\nmodel = L.Classifier(CNN())\ngpu_id = -1\n# none gpu\n# when gpu use\n# gpu_id = 0\n# model.to_gpu(gpu_id)","b8d2e5e2":"# define optimizer, and set up with model\noptimizer = chainer.optimizers.Adam()\noptimizer.setup(model)\n\nbatchsize = 96\ntrain_iter = chainer.iterators.SerialIterator(train, batchsize)\ntest_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=True)\n\nfrom chainer import training\nfrom chainer.training import extensions\n\n# set epoch\nepoch = 10\nupdater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\ntrainer = training.Trainer(updater, (epoch, 'epoch'), out='mnist')\n\n# validate with 30% train data\ntrainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n\n# logging learning process\ntrainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n# Print Report per 1 poch\ntrainer.extend(extensions.PrintReport(['epoch', 'main\/accuracy', 'validation\/main\/accuracy', 'main\/loss', 'validation\/main\/loss', 'elapsed_time']), trigger=(1, 'epoch'))","ce488a87":"# start training\ntrainer.run()","e8a1ee12":"import json\nwith open('mnist\/log') as f:\n    result = pd.DataFrame(json.load(f))\nresult","0c5b3653":"# \u640d\u5931\u95a2\u6570(loss)\nresult[['main\/loss', 'validation\/main\/loss']].plot()","9efedb3a":"# \u7cbe\u5ea6(accuracy)\nresult[['main\/accuracy', 'validation\/main\/accuracy']].plot()","8f5359d9":"X_test = test_df.iloc[:,1:].values.reshape(-1,1,28,28)\nprint(X_test.shape)\n#X_test = test_df.values.reshape(1,28,28)\nX_test = X_test.astype('float32')","82705dc9":"# predict with test data\n\ndef predict(model, x_dataset):\n    y = model.predictor(x_dataset)\n    return np.argmax(y.data, axis = 1)\n\ny_test = predict(model, X_test)\ny_test","56940c66":"df_y_test = pd.DataFrame({'label':y_test})\ndf_Y_id = test_df.iloc[:,0]\ndf_submit = pd.concat([df_Y_id,df_y_test],axis=1)\ndf_submit.columns = ['id', 'label']\ndf_submit","2d78dc02":"df_submit.to_csv('submission.csv', index=False)","f797cf44":"# Very simple CNN with chainer","e15f4eae":"## run train","f66212e0":"# package import","65995987":"# Prepare data","1c5c2b3c":"# Test and Submit data","3bfc25e5":"---","854a053a":"# plot training summary","82e80bdc":"# Define model and train","4265a571":"## chainer dataset"}}