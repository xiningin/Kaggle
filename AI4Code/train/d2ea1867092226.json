{"cell_type":{"3144ae54":"code","5cf1f3f8":"code","ced67e55":"code","ecd59ffe":"code","41a390ef":"code","aee54d57":"code","b47a6042":"code","7ce1cbae":"code","18e31480":"code","697057e5":"code","d713fb0c":"code","5192e17a":"code","2aeece6e":"code","2971537d":"code","dac5f0c5":"code","a5c3ef78":"code","451239a0":"code","6a6f01ca":"code","467d2048":"code","398dbfe0":"code","780bdbb2":"code","b8156a8c":"code","df06b244":"markdown","1f09ccb4":"markdown","756c6bce":"markdown","e8189bf8":"markdown","6e5b1033":"markdown","dbbaf1a5":"markdown","ebf024db":"markdown","260232c8":"markdown","56b2d4b0":"markdown","0e2706b1":"markdown","f9ebb396":"markdown","eecf6d69":"markdown","f3e63688":"markdown","ec15ad02":"markdown","e13a15d2":"markdown","0dca6fcb":"markdown","9c860816":"markdown","fe99f2f0":"markdown","768d6f80":"markdown","e9d9c617":"markdown"},"source":{"3144ae54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cf1f3f8":"import requests\nurl = \"http:\/\/182.18.164.20\/transformer_api\/current_voltage\/867322031102411\"\nuser = \"admin\"\npasswd = \"admin@123\"\nauth_values = (user, passwd)\nresponse = requests.get(url, auth=auth_values)","ced67e55":"cv = pd.DataFrame.from_dict(response.json(), orient='columns')\ncv.head()","ecd59ffe":" cv.isnull().sum()","41a390ef":"cv['DeviceTimeStamp_'] = pd.to_datetime(cv['DeviceTimeStamp'])\ncv.head()","aee54d57":"import datetime\nx=cv['DeviceTimeStamp_'].max()\ny=cv['DeviceTimeStamp_'].min()\ndays = datetime.timedelta(7)\nweek=x-days","b47a6042":"cvlastweek=cv[cv['DeviceTimeStamp_']>=week]\ncvlastweek","7ce1cbae":"cvlastweek = cvlastweek.iloc[::-1]\ncvlastweek=cvlastweek.reset_index()\ncvlastweek","18e31480":"#ARIMA\nfrom pandas.plotting import autocorrelation_plot\nautocorrelation_plot(cvlastweek['IL1'])\n#pyplot.show()","697057e5":"#SARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nsari=SARIMAX(cvlastweek['IL1'],order=(1,1,1))\nres=sari.fit(disp=False)\nres.plot_diagnostics()\npred = res.get_prediction(start=0, dynamic=True)\ncon=pred.conf_int()\nprint(res.summary())\nax = cvlastweek[0:]['IL1'].plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7,\nfigsize=(14, 4))\nax.set_xlabel('row number')\nax.set_ylabel('IL1')\nplt.legend()\nfore=pred.predicted_mean\ntruth=cvlastweek[0:]['IL1']\nrmse=((fore-truth)*2).mean()*0.5\nprint(\"The rmse is {}\".format(round(rmse,2)))\nplt.show()","d713fb0c":"# Split data into train \/ test sets \ntrain = cvlastweek.iloc[:len(cvlastweek)-100] \ntest = cvlastweek.iloc[len(cvlastweek)-100:] # set 1 day(100 datapoints) for testing \n  \n# Fit a SARIMAX(3, 0, 0)x(2, 1, 0, 100) on the training set \nfrom statsmodels.tsa.statespace.sarimax import SARIMAX \n  \nmodel = SARIMAX(train['IL1'], order = (3, 0, 0), seasonal_order =(2, 1, 0, 100)) \n  \nresult = model.fit() \nresult.summary() ","5192e17a":"start = len(train) \nend = len(train) + len(test) - 1\n  \n# Predictions for one-year against the test set \npredictions = result.predict(start, end, typ = 'levels').rename(\"Predictions\") \n  \n# plot predictions and actual values \npredictions.plot(legend = True) \ntest['IL1'].plot(legend = True)","2aeece6e":"from sklearn.metrics import mean_squared_error\nerror = mean_squared_error(test['IL1'], predictions)\nprint('Test MSE: %.3f' % error)\nrmse_inut = np.sqrt(mean_squared_error(test['IL1'], predictions))\nprint('Test RMSE: %.3f' % rmse_inut)","2971537d":"# Train the model on the full dataset \nmodel = SARIMAX(cvlastweek['IL1'],order = (3, 0, 0),seasonal_order =(2, 1, 0, 100)) \nresult = model.fit() \n  \n# Forecast for the next 3 years \nforecast = result.predict(start = len(cvlastweek), end = (len(cvlastweek)-1) + 100,typ = 'levels').rename('Forecast') \n  \n# Plot the forecast values \ncvlastweek['IL1'].plot(figsize = (12, 5), legend = True) \nforecast.plot(legend = True) ","dac5f0c5":"cv_hist = cvlastweek[['DeviceTimeStamp_', 'IL1']]\ncv_hist","a5c3ef78":"fc = forecast.to_frame()\nfuture_time_stamps=[]\nts=x\nfor i in range(0, 100):\n    ts = ts + datetime.timedelta(minutes = 15)\n    future_time_stamps.append(ts)","451239a0":"fc['DeviceTimeStamp_'] = np.array(future_time_stamps)","6a6f01ca":"fault_query = cvlastweek[cvlastweek['IL1'] > 180]","467d2048":"fault_query","398dbfe0":"fault_query_future = fc[fc['Forecast'] > 180]\nfault_query_future","780bdbb2":"msg=''\nif(len(fault_query_future)>0):\n    msg = 'Fault may occur in the next 24 hours'\nelse:\n    msg = 'Fault may not occur in the next 24 hours'","b8156a8c":"import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n#import chart_studio.plotly as py\nimport plotly.offline as pyoff\nimport plotly.graph_objs as go\nplot_data = [\n    go.Scatter(\n        x=cvlastweek['DeviceTimeStamp_'],\n        y=cvlastweek['IL1'],\n        name='Historical IL1'\n    ),\n    go.Scatter(\n        x=fc['DeviceTimeStamp_'],\n        y=fc['Forecast'],\n        name='Forecast'\n    ),\n    go.Scatter(\n        x=fault_query['DeviceTimeStamp_'],\n        y=fault_query['IL1'],\n        mode='markers',\n        name='Alarm',\n        marker= dict(size= 7,\n            line= dict(width=1),\n            color= 'Blue',\n            opacity= 0.8\n           )\n    ),\n    go.Scatter(\n        x=fault_query_future['DeviceTimeStamp_'],\n        y=fault_query_future['Forecast'],\n        mode='markers',\n        name='Predicted Alarm',\n        marker= dict(size= 7,\n            line= dict(width=1),\n            color= 'red',\n            opacity= 0.8\n           )\n    )\n]\nplot_layout = go.Layout(\n        title='Current, Device Id: 867322031102411, rmse = '+str(rmse_inut)+', '+str(msg),\n        xaxis_title='Time',\n        yaxis_title='IL1',\n        plot_bgcolor='rgba(0,0,0,0)'\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\n#fig.update_layout(xaxis=dict(rangeslider=dict(visible=True), type=\"linear\"))\npyoff.iplot(fig)","df06b244":"# ARIMA Model for Time Series Forecasting\nARIMA stands for autoregressive integrated moving average model and is specified by three order parameters: (p, d, q).\n \n# AR(p) Autoregression \u2013\nA regression model that utilizes the dependent relationship between a current observation and observations over a previous period.An auto regressive (AR(p)) component refers to the use of past values in the regression equation for the time series.\n\n# I(d) Integration \u2013\nUses differencing of observations (subtracting an observation from observation at the previous time step) in order to make the time series stationary. Differencing involves the subtraction of the current values of a series with its previous values d number of times.\n\n# MA(q) Moving Average \u2013\nA model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations. A moving average component depicts the error of the model as a combination of previous error terms. The order q represents the number of terms to be included in the model.\n\n# Types of ARIMA Model\n**ARIMA:**Non-seasonal Autoregressive Integrated Moving Averages\n**\nSARIMA:**Seasonal ARIMA\n\n**SARIMAX**:Seasonal ARIMA with exogenous variables\n\n# Pyramid Auto-ARIMA\nThe \u2018auto_arima\u2019 function from the \u2018pmdarima\u2019 library helps us to identify the most optimal parameters for an ARIMA model and returns a fitted ARIMA model.","1f09ccb4":"Now, we make the above graph more interactive and Dashboard Friendly.","756c6bce":"Incorporating a user Friendly Message","e8189bf8":"# Prediction","6e5b1033":"# Using Auto ARIMA to find the best hyperparameters for Optimal performance\n\nfrom pmdarima import auto_arima \nimport warnings \nwarnings.filterwarnings(\"ignore\") \n  \n\nstepwise_fit = auto_arima(cvlastweek['IL1'], start_p = 1, start_q = 1, \n                          max_p = 3, max_q = 3, m = 10, \n                          start_P = 0, seasonal = True, \n                          d = None, D = 1, trace = True, \n                          error_action ='ignore',   # we don't want to know if an order does not work \n                          suppress_warnings = True,  # we don't want convergence warnings \n                          stepwise = True)           # set to stepwise \n\nstepwise_fit.summary()\n\nOutput:\n![image.png](attachment:image.png)\n","dbbaf1a5":"# Please feel free to provide Valuable Feedback.. and I needed help in getting the Confidence Intervals, if anyone knows, please comment below!\n# Thank you!","ebf024db":"Clearing Null values","260232c8":"# Forecasting for the Next Day (100 data points)","56b2d4b0":"# Validation of the Model","0e2706b1":"Extracting only previous week's data for further analysis","f9ebb396":"Converting String into DateTime format","eecf6d69":"**Extracting Historical Data**","f3e63688":"# Reading and Parsing the API Output with Python\nTo handle the API output, you need to import two Python libraries:\n\n1. Connect to the URL as if you are opening it in browser \u2013 figuratively.\n2. Read the output.\n3. Parse JSON \u2013 convert the string to JSON.\n4. Extract data.","ec15ad02":"# Requirements:\nTo Create an Analytical dashboard to monitor Various Transformers. (Predictive Analytics using ARIMA time series) \n\n# Parameters of the Transformer:\nThis data is collected via IoT devices which is being updated every 15 minutes and this data can be accessed through API's\nParameters Description:\n\n**CurrentVoltage:**\n\n**VL1**- Phase Line 1\n\n**VL2**- Phase Line 2\n\n**VL3**- Phase Line 3\n\n**IL1**- Current Line 1\n\n**IL2**- Current Line 2\n\n**IL3**- Current Line 3\n\n**VL12**- Voltage line 1 2\n\n**VL23**- Voltage line 2 3\n\n**VL31**- Voltage line 3 1\n\n**INUT**- Neutral Current\n\nIn this kernel we will be analyzing IL1 for one device","e13a15d2":"# Time Series Forecasting:\nTime Series forecasting is the process of using a statistical model to predict future values of a time series based on past results.\n\n# Components of a Time Series:\n**Trend:** \n\nThe trend shows a general direction of the time series data over a long period of time. A trend can be increasing(upward), decreasing(downward), or horizontal(stationary).\n\n**Seasonality:**\n\nThe seasonality component exhibits a trend that repeats with respect to timing, direction, and magnitude. Some examples include an increase in water consumption in summer due to hot weather conditions, or an increase in the number of airline passengers during holidays each year.\n\n**ETS Decomposition:**\n\nETS Decomposition is used to separate different components of a time series. The term ETS stands for Error, Trend, and Seasonality.\n\n**Irregular Variation:**\n\nThese are the fluctuations in the time series data which become evident when trend and cyclical variations are removed. These variations are unpredictable, erratic, and may or may not be random.\n\n**Cyclical Component:**\n\nThese are the trends with no set repetition over a particular period of time. A cycle refers to the period of ups and downs, booms and slums of a time series, mostly observed in business cycles. These cycles do not exhibit a seasonal variation but generally occur over a time period of 3 to 12 years depending on the nature of the time series.","0dca6fcb":"Reversing the Data Frame in a serial order","9c860816":"# Fault Detection\n\nWe assume the threshold of IL1 to be greater than **180 Amperes**, beyond which the transformer tends to fail.\nSo, we filter all the values above 180 from the DataFrame.","fe99f2f0":"**Converting Forecast Values into a presentable DataFrame**","768d6f80":"# Metrics \n**Root Mean Square Error (RMSE)** is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.\n![image.png](attachment:image.png)","e9d9c617":"# Final Output to be Integrated with Dashboard\n\nThe Graph indicates all the previous faults indicated by the alarm in Blue and shows if a fault may occur in the future in Red."}}