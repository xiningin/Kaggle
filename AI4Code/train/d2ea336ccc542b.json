{"cell_type":{"b7c2699f":"code","729ddc07":"code","090e3cd1":"code","9b1d6280":"code","f91427c2":"code","de6d976e":"code","9b85f749":"code","39b97e43":"code","90076f42":"code","42dbbf96":"code","07689762":"code","efe43964":"code","f06af8be":"code","10c882f6":"code","e92dfcde":"code","169c4040":"code","c21de0e3":"code","812b7ec8":"code","e4619ac7":"code","89629a5a":"code","ab1467d3":"code","9a9420de":"code","3df42f8d":"code","a12339d2":"code","56efd975":"code","449b523a":"code","c006f4e5":"code","a16bd42e":"code","2bbec466":"code","b1ad0246":"code","168167e9":"code","b28aa551":"code","15dd6a22":"code","6419004e":"code","3aabeeed":"code","608f0e8e":"code","6e330e58":"code","0ce2d330":"code","388d654d":"code","52bf91f7":"code","0ea1dd8e":"code","6d06c42d":"code","bf8df9c3":"code","dbb944c6":"code","c6f09821":"code","ea8935e7":"code","1983502c":"code","5dae897e":"code","dfd957f2":"code","5df4ea3a":"code","470ad3ba":"code","8471f049":"code","b1eb149c":"code","7ae4f7a8":"markdown","0b12493c":"markdown","b89aa3b2":"markdown","cd4a9863":"markdown","8c8ef409":"markdown","52ffc1b0":"markdown","3efc6281":"markdown"},"source":{"b7c2699f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","729ddc07":"df = pd.read_csv('..\/input\/painter-by-numbers-resized\/artist_info_full.csv')\ndf.head()","090e3cd1":"TOP_N = 5","9b1d6280":"df['style'].value_counts()[0:TOP_N]","f91427c2":"style_enc_dict = {}\nfor i, style in enumerate(df['style'].value_counts()[0:TOP_N].index.tolist()):\n    style_enc_dict[style] = i\nprint(style_enc_dict)","de6d976e":"def get_key(my_dict, val): \n    for key, value in my_dict.items(): \n        if val == value:\n            return key","9b85f749":"style_df = df[df['style'].isin(style_enc_dict.keys())]","39b97e43":"style_df.head()","90076f42":"style_df['style'].value_counts()","42dbbf96":"style_df['style'].update(style_df['style'].map(style_enc_dict))","07689762":"style_df['style'].value_counts()","efe43964":"sum(style_df['style'].value_counts())","f06af8be":"from sklearn.model_selection import train_test_split","10c882f6":"y = style_df['style']\ny.head()","e92dfcde":"style_df.drop(labels=['style'], axis=1, inplace=True)\nstyle_df.head()","169c4040":"X = style_df","c21de0e3":"X_part, X_not_used, y_part, y_not_used = train_test_split(\\\n                                                    X, y,\\\n                                                    test_size=0.75, shuffle=True,\\\n                                                    stratify = y, random_state=42)","812b7ec8":"print(X_part.shape,y_part.shape)","e4619ac7":"X_train, X_test, y_train, y_test = train_test_split(\\\n                                                    X_part, y_part,\\\n                                                    test_size=0.20, shuffle=True,\\\n                                                    stratify = y_part, random_state=42)","89629a5a":"print(X_train.shape,y_train.shape)","ab1467d3":"X_train.head()","9a9420de":"y_train.value_counts()","3df42f8d":"y_test.value_counts()","a12339d2":"X_train.head()","56efd975":"train_df = X_train.join(y_train)\ntrain_df.head()","449b523a":"test_df = X_test.join(y_test)\ntest_df.head()","c006f4e5":"import torch\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nfrom PIL import Image\nfrom torchvision import transforms, models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport random\nimport shutil \nimport cv2\nfrom tqdm import tqdm","a16bd42e":"!pip install knockknock","2bbec466":"from knockknock import telegram_sender\n\nCHAT_ID: int = 266478885\n@telegram_sender(token=\"647225942:AAF-biI_UdXDVOwhqBjFRcELwbTzdeidn0w\", chat_id=CHAT_ID)\ndef train_your_nicest_model(time_value=2):\n    import time\n    time.sleep(time_value)\n    return {'loss': 0.9} # Optional return value","b1ad0246":"train_your_nicest_model()","168167e9":"RANDOM_SEED = 42","b28aa551":"random.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True","15dd6a22":"filepath = '..\/input\/painter-by-numbers-resized\/'\nclass ImagesDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform = None,\n                 loader = torchvision.datasets.folder.default_loader):\n        self.df = df\n        self.transform = transform\n        self.loader = loader\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        target = row['style']\n        path = filepath + row['filename']\n        img = self.loader(path)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n\n    def __len__(self):\n        n, _ = self.df.shape\n        return n","6419004e":"# what transformations should be done with our images\ntrain_transforms = transforms.Compose([\n    transforms.RandomAffine(degrees=10, scale=(1.1, 1.3)),\n    transforms.RandomCrop((224, 224)),\n    transforms.RandomHorizontalFlip(),\n#     transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.RandomCrop((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","3aabeeed":"# initialize our dataset at first\ndataset = ImagesDataset(\n    df = train_df,\n    transform = train_transforms\n)\n\nbatch_size = 16\nvalidation_split = 0.2\nshuffle_dataset = True\n# Creating data indices for training and validation splits:\ndataset_size = len(train_df)\n\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset:\n    np.random.seed(RANDOM_SEED)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, \n                                           sampler = train_sampler)\nval_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size,\n                                                sampler = valid_sampler)","608f0e8e":"len(train_dataloader), len(train_indices)","6e330e58":"X_batch, y_batch = next(iter(train_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);\nplt.title(get_key(style_enc_dict, int(y_batch[0])))\nplt.show()","0ce2d330":"def show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    \n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\niter_stop = 10\ni = 0\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=get_key(style_enc_dict, y_item))\n    i += 1\n    if i > iter_stop:\n        break","388d654d":"# def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n#     '''Calculate F1 score. Can work with gpu tensors\n    \n#     The original implmentation is written by Michal Haltuf on Kaggle.\n    \n#     Returns\n#     -------\n#     torch.Tensor\n#         `ndim` == 1. 0 <= val <= 1\n    \n#     Reference\n#     ---------\n#     - https:\/\/www.kaggle.com\/rejpalcz\/best-loss-function-for-f1-score-metric\n#     - https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n#     - https:\/\/discuss.pytorch.org\/t\/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification\/28265\/6\n    \n#     '''\n#     assert y_true.ndim == 1\n#     assert y_pred.ndim == 1 or y_pred.ndim == 2\n    \n#     if y_pred.ndim == 2:\n#         y_pred = y_pred.argmax(dim=1)\n        \n    \n#     tp = (y_true * y_pred).sum().to(torch.float32)\n#     tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n#     fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n#     fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n    \n#     epsilon = 1e-7\n    \n#     precision = tp \/ (tp + fp + epsilon)\n#     recall = tp \/ (tp + fn + epsilon)\n    \n#     f1 = 2* (precision*recall) \/ (precision + recall + epsilon)\n#     f1.requires_grad = is_training\n#     return f1","52bf91f7":"@telegram_sender(token=\"647225942:AAF-biI_UdXDVOwhqBjFRcELwbTzdeidn0w\", chat_id=CHAT_ID)\ndef model_print(epoch, num_epochs):\n    return \"Epoch: \" + str(epoch) + \"\/\" + str(num_epochs)","0ea1dd8e":"train_accuracy_history = []\ntrain_loss_history = []\n# train_roc_auc_history = []\n\n\nval_accuracy_history = []\nval_loss_history = []\n# val_roc_auc_history = []\n\nres_model = None\n@telegram_sender(token=\"647225942:AAF-biI_UdXDVOwhqBjFRcELwbTzdeidn0w\", chat_id=CHAT_ID)\ndef train_model(model, loss, optimizer, num_epochs):\n    min_val_loss = 200.0\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}:'.format(epoch, num_epochs - 1), flush=True)\n        model_print(epoch, num_epochs - 1)\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                dataloader = val_dataloader\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.\n            running_acc = 0.\n            # running_roc_auc = 0.\n            \n            \n            # Iterate over data.\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                # forward and backward\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n                # running_roc_auc += f1_loss(labels.data, preds_class).mean()\n                \n            epoch_loss = running_loss \/ len(dataloader)\n            epoch_acc = running_acc \/ len(dataloader)\n            # epoch_roc_auc = running_roc_auc \/ len(dataloader)\n            \n            if (phase == 'train'):\n                train_accuracy_history.append(epoch_acc)\n                train_loss_history.append(epoch_loss)\n                # train_roc_auc_history.append(epoch_roc_auc)\n                \n            elif (phase == 'val'):\n                if epoch_loss < min_val_loss:\n                    min_val_loss = epoch_loss\n                    with open('top_model', 'wb') as f:\n                        torch.save(model, f)\n                val_accuracy_history.append(epoch_acc)\n                val_loss_history.append(epoch_loss)\n                # val_roc_auc_history.append(epoch_roc_auc)\n                \n            print('{} loss: {:.4f} acc: {:.4f}'.format(phase, epoch_loss, \\\n                                                       epoch_acc), flush=True)\n    print('top model with min_val_loss:', min_val_loss)\n    return 'Success'","6d06c42d":"model = models.resnet50(pretrained=True)\n\n# Disable grad for all conv layers\n# for param in model.parameters():\n#     t = param\n#     param.requires_grad = False\n\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, TOP_N)\n# model.bn = torch.nn.BatchNorm1d(num_ftrs)\n# model.fc = torch.nn.Linear(num_ftrs, int(num_ftrs \/ 2))\n# num_ftrs = model.fc.in_features\n\n# model.act1 = torch.nn.LeakyReLU()\n# model.fc2 = torch.nn.Linear(num_ftrs, TOP_N)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=5.0e-3)\n\n# Decay LR by a factor of 0.1 every 10 epochs\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 20)","bf8df9c3":"train_model(model, loss, optimizer, num_epochs=20);","dbb944c6":"plt.plot(train_accuracy_history, label='train_acc')\nplt.plot(val_accuracy_history, label='val_acc')\nplt.legend()\nplt.title('Accuracy');","c6f09821":"plt.plot(train_loss_history, label='train_loss')\nplt.plot(val_loss_history, label='val_loss')\nplt.legend()\nplt.title('Loss');","ea8935e7":"# plt.plot(train_roc_auc_history, label='train_f1')\n# plt.plot(val_roc_auc_history, label='val_f1')\n# plt.legend()\n# plt.title('f1');","1983502c":"X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\\\n                                                    X, y,\\\n                                                    test_size = 0.20, shuffle = True,\\\n                                                    stratify = y, random_state = RANDOM_SEED)","5dae897e":"test_df_full = X_test_full.join([y_test_full])\ntest_df_full.head()","dfd957f2":"dataset = ImagesDataset(\n    df = test_df_full,\n    transform = val_transforms\n)\n\ntest_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size)","5df4ea3a":"X_batch, y_batch = next(iter(test_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);\nplt.title(get_key(style_enc_dict, int(y_batch[0])))\nplt.show()","470ad3ba":"# Load the best saved model.\nwith open('top_model', 'rb') as f:\n    model = torch.load(f)\nmodel.eval()\n\ntest_labels = []\ntest_predictions = []\ntest_predictions_class = []\ntest_batch_loss = 0.0\ntest_batch_acc = 0.0\n\nfor inputs, labels in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    for element in labels:\n        test_labels.append(int(element))\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n        loss_value = loss(preds, labels)\n        preds_class = preds.argmax(dim=1)\n        for element in preds_class:\n            test_predictions_class.append(int(element))\n    test_batch_loss += loss_value.item()\n    test_batch_acc += (preds_class == labels.data).float().mean()\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    \ntest_predictions = np.concatenate(test_predictions)\n\ntest_loss = test_batch_loss \/ len(test_dataloader)\ntest_acc = test_batch_acc \/ len(test_dataloader)","8471f049":"print('test_loss:', test_loss)\nprint('test_acc:', float(test_acc))","b1eb149c":"from IPython.display import FileLink\nFileLink(r'top_model')","7ae4f7a8":"### checking dataset","0b12493c":"### Encoding style names","b89aa3b2":"### Import libraries","cd4a9863":"### default libraries from kaggle","8c8ef409":"### Freezing random seeds","52ffc1b0":"### Adding telegram bot","3efc6281":"## Style classification (top-<TOP_N> styles)"}}