{"cell_type":{"174d7272":"code","23daaf9c":"code","5270c6c3":"code","7e3927fd":"code","505d5fc2":"code","2c9d97bc":"code","2659a36e":"code","45b803c9":"code","ccda6982":"code","61fce943":"code","2ebaf1d3":"code","ee7b5b75":"code","2ec46de3":"code","4e8a0168":"code","9f40f4e4":"code","dec04169":"code","ed3be6a0":"code","8e1d02e8":"code","157645a6":"code","ef00168f":"code","9d9f7796":"code","4a915d25":"code","cf277e85":"code","214fefdd":"code","287ed81c":"code","8e12bba1":"code","a34209ae":"code","60107da6":"code","09d59e4d":"code","df6e5904":"code","3caad0d2":"code","bf2ee08f":"code","864bd707":"code","5ee3728e":"code","cb2cdd6d":"code","371e6684":"code","9c6f7c3c":"code","dcd55a68":"code","33923bb9":"code","74380edf":"code","6a20ca9d":"code","16ce1eab":"code","d163c9ef":"code","61b4c372":"code","04fb869a":"code","25f86191":"code","b0afd793":"code","b7cbe263":"code","d84de587":"code","05fadb34":"code","9e226367":"code","a1bd8faa":"code","d0e327a5":"code","f81f446c":"code","a245917c":"code","b32e5b1b":"code","85d442a6":"code","246d4c40":"code","e7378b4b":"code","3f986aed":"code","b1dc5f95":"code","1ba85f99":"code","61e95620":"code","fb73fa2b":"code","83cca3ff":"code","8fb41807":"markdown","fb2e7ff9":"markdown","c7ca2d53":"markdown","379f718f":"markdown","bd90b9e7":"markdown","25d07bc7":"markdown","99b41cbd":"markdown","6da6a922":"markdown","a0a6ed7f":"markdown","f5f8ccb1":"markdown","54657648":"markdown","c4b6358f":"markdown","9f8d2390":"markdown","e0c8e294":"markdown","e14a7bcb":"markdown","c7cc7b2a":"markdown","b5835df1":"markdown","7ab9f86f":"markdown","bcec5d64":"markdown","418dc25c":"markdown","88c1fd0b":"markdown","3dc8c488":"markdown","ed8a31d8":"markdown","d11d56d0":"markdown","003e384d":"markdown","0564e2c2":"markdown","d67bfbc4":"markdown","3e46ddfb":"markdown","14470fdb":"markdown"},"source":{"174d7272":"%matplotlib inline\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","23daaf9c":"train_df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","5270c6c3":"train_df.tail()","7e3927fd":"test_df.head()","505d5fc2":"print(\"The train dataset size is: {} \".format(train_df.shape)) \nprint(\"The test dataset size is : {} \".format(test_df.shape))","2c9d97bc":"train_df.SalePrice.describe()","2659a36e":"categorical_feature = train_df.select_dtypes(include=[np.object])\nnumeric_feature = train_df.select_dtypes(include=[np.number])\nlen(categorical_feature.dtypes), len(numeric_feature.dtypes)","45b803c9":"correlation = numeric_feature.corr()\nprint (correlation['SalePrice'].sort_values(ascending=False)[:5], '\\n')\nprint (correlation['SalePrice'].sort_values(ascending=False)[-5:])","ccda6982":"corr = correlation.corr()\nplt.subplots(figsize=(10, 8))\nsns.heatmap(corr, square = True, vmax = 0.8)\nplt.title(\"The Correlation of the Numeric Features with SalePrice\", y = 1, size = 16);","61fce943":"top_feature = correlation.index[(correlation['SalePrice'] > 0.5)]\nplt.subplots(figsize=(10, 8))\ntop_corr = train_df[top_feature].corr()\nsns.heatmap(top_corr, annot=True, annot_kws={\"size\": 10}, fmt='.1f', cmap='RdGy', linewidths=.5)\nplt.show()","2ebaf1d3":"fig, ax = plt.subplots()\nax.scatter(x = train_df['GrLivArea'], y = train_df['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","ee7b5b75":"fig, ax = plt.subplots()\nax.scatter(x = train_df['OverallQual'], y = train_df['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('OverallQual', fontsize=13)\nplt.show()","2ec46de3":"#Extract the SalePrice out\ny = train_df['SalePrice'].values","4e8a0168":"#Combining train and test dataset and drop SalePrice\ncombine_df = pd.concat([train_df.drop(['SalePrice'], axis=1), test_df], axis=0)","9f40f4e4":"#Have a look over the basic details\ndef basic_details(combine_df):\n    view = pd.DataFrame()\n    view['Missing values'] = combine_df.isnull().sum()\n    view['Unique values'] = combine_df.nunique()\n    view['Data Types'] = combine_df.dtypes\n    return view\nbasic_details(combine_df)","dec04169":"missing = combine_df.isnull().sum()\nmissing = missing [missing > 0]\nmissing.sort_values(inplace = True)\nplt.figure(figsize=(12, 4))\nplt.title(\"The Missing Values\", y = 1, size = 16);\nmissing.plot.bar()","ed3be6a0":"# fill up MSZoning with the mode value\ncombine_df['MSZoning'] = combine_df['MSZoning'].fillna(combine_df['MSZoning'].mode()[0])","8e1d02e8":"# LotFrontage : Since the area of each street connected to the house property most \n#likely have a similar area to other houses in its neighborhood, we can fill in \n#missing values by the median LotFrontage of the neighborhood.\ncombine_df[\"LotFrontage\"] = combine_df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","157645a6":"# from the data description file, NA = No Alley Access\ncombine_df[\"Alley\"] = combine_df[\"Alley\"].fillna(\"None\")","ef00168f":"# fill up NA values with mode\ncombine_df['Utilities'] = combine_df['Utilities'].fillna('AllPub')","9d9f7796":"# since both Exterior1st and 2nd only has 2 missing value, substitute with mode\ncombine_df['Exterior1st'] = combine_df['Exterior1st'].fillna(combine_df['Exterior1st'].mode()[0])\ncombine_df['Exterior2nd'] = combine_df['Exterior2nd'].fillna(combine_df['Exterior2nd'].mode()[0])","4a915d25":"# fill up MasVnrType with the mode value\ncombine_df[\"MasVnrType\"] = combine_df[\"MasVnrType\"].fillna(combine_df['MasVnrType'].mode()[0])\ncombine_df[\"MasVnrArea\"] = combine_df[\"MasVnrArea\"].fillna(combine_df['MasVnrArea'].mode()[0])","cf277e85":"# for these columns, NA = No Basement\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    combine_df[col] = combine_df[col].fillna('None')","214fefdd":"# for these columns, NA is likely to be 0 due to no basement\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    combine_df[col] = combine_df[col].fillna(0)","287ed81c":"# substitue NA value here with mode\ncombine_df['Electrical'] = combine_df['Electrical'].fillna(combine_df['Electrical'].mode()[0])","8e12bba1":"# substitute NA value with mode\ncombine_df['KitchenQual'] = combine_df['KitchenQual'].fillna('TA')","a34209ae":"# if there is no value, assume Typ, typical is also mode value\ncombine_df['Functional'] = combine_df['Functional'].fillna('typ')","60107da6":"# NA = No Fireplace\ncombine_df['FireplaceQu'] = combine_df['FireplaceQu'].fillna('None')","09d59e4d":"# for these columns, NA = No Garage\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    combine_df[col] = combine_df[col].fillna('None')","df6e5904":"# as there is no garage, NA value for this column is set to zero\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    combine_df[col] = combine_df[col].fillna(0)","3caad0d2":"# NA = no pool\ncombine_df['PoolQC'] = combine_df['PoolQC'].fillna('None')","bf2ee08f":"# NA = no fence\ncombine_df['Fence'] = combine_df['Fence'].fillna('None')","864bd707":"#Misc Feature, NA = None\ncombine_df['MiscFeature'] = combine_df['MiscFeature'].fillna('None')","5ee3728e":"#sale type, only have 1 NA value. substitute it with mode value\ncombine_df['SaleType'] = combine_df['SaleType'].fillna(combine_df['SaleType'].mode()[0])","cb2cdd6d":"# checking for any null value left\ncombine_df.isnull().sum().sum()","371e6684":"# MSSubClass = The building class\ncombine_df['MSSubClass'] = combine_df['MSSubClass'].astype(str)\n\n#Changing OverallCond into a categorical variable\ncombine_df['OverallCond'] = combine_df['OverallCond'].astype(str)\ncombine_df['OverallQual'] = combine_df['OverallQual'].astype(str)","9c6f7c3c":"combine_df['Porches'] = (combine_df['OpenPorchSF'] + combine_df['3SsnPorch'] \n+combine_df['EnclosedPorch'] + combine_df['ScreenPorch'] + combine_df['WoodDeckSF'])","dcd55a68":"combine_df['HouseSize'] = (combine_df['TotalBsmtSF'] + combine_df['1stFlrSF'] + combine_df['2ndFlrSF'])","33923bb9":"combine_df['Bathrooms'] = combine_df['FullBath'] + combine_df['BsmtFullBath']\ncombine_df['Half_Bathrooms'] = combine_df['HalfBath'] + combine_df['BsmtHalfBath']","74380edf":"combine_df['Pool'] = combine_df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ncombine_df['Fireplace'] = combine_df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","6a20ca9d":"combine_df = combine_df.drop(['PoolQC'], axis=1)","16ce1eab":"combine_df = combine_df.drop(['Street'], axis=1)","d163c9ef":"combine_df['Garage'] = combine_df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ncombine_df['Basement'] = combine_df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)","61b4c372":"combine_df = combine_df.drop(['Id'], axis=1)\ncombine_dummies = pd.get_dummies(combine_df)","04fb869a":"result = combine_dummies.values","25f86191":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nresult = scaler.fit_transform(result)","b0afd793":"#creating matrices for sklearn:\nX = result[:train_df.shape[0]]\ntest_values = result[train_df.shape[0]:]","b7cbe263":"# import train test split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","d84de587":"from sklearn.linear_model import LinearRegression, Lasso, Ridge\n\nclf = LinearRegression()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_train_pred = clf.predict(X_train)","05fadb34":"from sklearn.metrics import r2_score\n\nprint(\"Train acc: \" , r2_score(y_train, y_train_pred))\nprint(\"Test acc: \", r2_score(y_test, y_pred))","9e226367":"from sklearn.linear_model import Lasso\n\nLs = Lasso()\nLs.fit(X_train, y_train)\ny_pred2 = Ls.predict(X_test)\ny_train_pred2 = Ls.predict(X_train)","a1bd8faa":"print(\"Train acc: \" , r2_score(y_train, y_train_pred2))\nprint(\"Test acc: \", r2_score(y_test, y_pred2))","d0e327a5":"from sklearn.linear_model import Ridge\n\nr = Ridge()\nr.fit(X_train, y_train)\ny_pred3 = r.predict(X_test)\ny_train_pred3 = r.predict(X_train)","f81f446c":"print(\"Train acc: \" , r2_score(y_train, y_train_pred))\nprint(\"Test acc: \", r2_score(y_test, y_pred3))","a245917c":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=200, p = 1)\nknn.fit(X_train, y_train) ","b32e5b1b":"print(\"Train accuracy: \" , knn.score(X_train , y_train))\nprint(\"Test accuracy: \" , knn.score(X_test , y_test))","85d442a6":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)","246d4c40":"print(\"Train accuracy: \" , model.score(X_train,y_train))\nprint(\"Test accuracy: \" , model.score(X_test,y_test))","e7378b4b":"predictions = model.predict(X_test)\npredictions","3f986aed":"#Evaluation\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test,predictions))","b1dc5f95":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nbag = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n                        n_estimators=3, random_state=0, max_features=.2,\n                        max_samples=.2).fit(X_train,y_train)","1ba85f99":"print(\"Train accuracy: \" , bag.score(X_train,y_train))\nprint(\"Test accuracy: \" , bag.score(X_test,y_test))","61e95620":"from sklearn.ensemble import RandomForestRegressor\n\nbag = RandomForestRegressor(n_estimators=200, random_state=0, max_features=.7)\nbag.fit(X_train , y_train)","fb73fa2b":"print(\"Train accuracy: \" , bag.score(X_train,y_train))\nprint(\"Test accuracy: \" , bag.score(X_test,y_test))","83cca3ff":"submit = pd.DataFrame(test_df[\"Id\"])\nsubmit[\"SalePrice\"] = bag.predict(test_values)\n\nsubmit.head(2)\nsubmit.to_csv('Submission.csv', index=False)","8fb41807":"# Kaggle Competition - House Prices: Advanced Regression Techniques ","fb2e7ff9":"### Outliars:","c7ca2d53":"As we can see, we have a total of 81 features, where 43 are categorical and 38 are numerical.","379f718f":"**Filling up the missing values:**","bd90b9e7":"### KNN ","25d07bc7":"Dummies: ","99b41cbd":"### 2. Data cleaning\nIn this stage, we will clean our data by the following:\n\n- Combining our two datasets.\n\n- Filling the missing values.\n\n- Creating new features for analysis.\n\n- Drop some features.","6da6a922":"### Correlation:","a0a6ed7f":"We can now rank our evaluation of all the models that we use and choose the best one, which is in this case: **Random Forest Regressor**","f5f8ccb1":"### 1. Data Exploration\nWe will start by acquiring the training and testing datasets into Pandas DataFrames.","54657648":"### Ridge","c4b6358f":"### Evaluation","9f8d2390":"Scaling:","e0c8e294":"Now, there are no missing values! Now data is cleaned and we can start the next step in feature engineering.","e14a7bcb":"### Statistics:","c7cc7b2a":"### Lasso","b5835df1":"### Submission","7ab9f86f":"### 3. Modeling","bcec5d64":"As we can see, OverallQual is highly correlated with SalePrice. ","418dc25c":"**The most important features relative to SalePrice:**","88c1fd0b":"### Bagging and Decision Tree Classifier","3dc8c488":"Since there are many missing values, we need to know the relationship between missing values and Sales Price. ","ed8a31d8":"### Linear Regression","d11d56d0":"**Missing Values:**","003e384d":"Looking at the documentation there are several numerical columns that should be considered as categorical. Let's straighten that out:","0564e2c2":"### Logistic Regression","d67bfbc4":"Checking whether there are any null values left","3e46ddfb":"**Adding new features:**","14470fdb":"### Random Forest Regressor"}}