{"cell_type":{"2c43355a":"code","7567edc0":"code","bf87c908":"code","b95c70f5":"code","b174f618":"code","a5f11fb5":"code","68158030":"code","697fc07f":"code","91a3b62f":"code","c745d386":"code","f7714f66":"code","9c0679cb":"code","15873c80":"code","df21a184":"markdown","26e8accb":"markdown","46990a9d":"markdown","99c19ae2":"markdown","00966445":"markdown","dbe95e5b":"markdown","78bedc4b":"markdown","83ea1f24":"markdown","0853925b":"markdown"},"source":{"2c43355a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7567edc0":"import keras\nfrom keras.datasets import mnist\n#load mnist dataset from keras default mnist dataset\n(X_train, y_train), (X_test, y_test) = mnist.load_data() ","bf87c908":"import matplotlib.pyplot as plt\nfig = plt.figure()\nfor i in range(9):\n  plt.subplot(3,3,i+1)\n  plt.tight_layout()\n  plt.imshow(X_train[i], cmap='gray', interpolation='none')\n  plt.title(\"Digit: {}\".format(y_train[i]))\n  plt.xticks([])\n  plt.yticks([])\nfig","b95c70f5":"#reshaping image data\nimg_rows=28\nimg_cols=28\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n#more reshaping\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train \/= 255\nX_test \/= 255\nprint('X_train shape:', X_train.shape) #X_train shape: (60000, 28, 28, 1)","b174f618":"import keras\n#set number of categories\nnum_category = 10\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_category)\ny_test = keras.utils.to_categorical(y_test, num_category)","a5f11fb5":"##model building\nimport keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nmodel = keras.Sequential()\n#convolutional layer with relu unit activation\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n#32 convolution filters used each of size 3x3\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n#64 convolution filters used each of size 3x3\n#choosing the best features via pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#randomly turning neurons on and off to improve convergence\nmodel.add(Dropout(0.25))\n#flatten since too many dimensions, we only want a classification output\nmodel.add(Flatten())\n#fully connected to get all relevant data\nmodel.add(Dense(128, activation='relu'))\n#one more dropout for convergence' sake :) \nmodel.add(Dropout(0.5))\n#output a softmax to squash the matrix into output probabilities\nmodel.add(Dense(num_category, activation='softmax'))","68158030":"After the architecture of the model is defined, the model needs to be compiled. Here, we are using categorical_crossentropy loss function as it is a multi-class classification problem. Since all the labels carry similar weight we prefer accuracy as performance metric. A popular gradient descent technique called AdaDelta is used for optimization of the model parameters.","697fc07f":"\n#categorical ce since we have multiple classes (10) \nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])","91a3b62f":"batch_size = 128\nepochs = 10\n#model training\nmodel_log = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_test, y_test))","c745d386":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])","f7714f66":"\nfig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(model_log.history['accuracy'])\nplt.plot(model_log.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(model_log.history['loss'])\nplt.plot(model_log.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\nfig","9c0679cb":"result=model.predict(X_test[0].reshape(1, img_rows, img_cols, 1))\n","15873c80":"import matplotlib.pyplot as plt\nfig = plt.figure()\nfor i in range(1):\n  plt.figure()\n  plt.tight_layout()\n  plt.imshow(result, cmap='gray', interpolation='none')\n  plt.title(\"Digit: {}\".format(y_test[i]))\n  plt.xticks([])\n  plt.yticks([])\nfig","df21a184":"Here X_train contains 60,000 training images\u2019 data each of size 28x28 and y_train contains their corresponding labels. Similarly, X_test contains 10,000 testing images\u2019 data each of dimension 28x28 and y_test contains their corresponding labels. Let\u2019s visualize few data from training to get a better understanding of data","26e8accb":"Now the model needs to be trained with training data to be able to recognize the handwritten digits.","46990a9d":"As can be seen here, at left top corner the image of \u20185\u2019 is stored is X_train[0] and y_train[0] contains label \u20185\u2019. Our deep learning model should be able to only take the handwritten image and predict the actual digit written.\nNow, to prepare the data we need some processing on the images like resizing images, normalizing the pixel values etc.","99c19ae2":"the label data i.e. y_train and y_test need to be converted into categorical formats like label \u20183\u2019 should be converted to one hot encoding","00966445":"we need to define the architecture of the model and compile it with necessary optimizer function, loss function and performance metrics.","dbe95e5b":"Import libraries first","78bedc4b":"Now lets evaluate our model in terms of performance.","83ea1f24":"Lets predict data randomly to check!","0853925b":"Visualize acc and loss"}}