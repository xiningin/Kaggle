{"cell_type":{"b0c01213":"code","362dc9b3":"code","6d867638":"code","ded97909":"code","58f5b6d6":"code","46fc1e01":"code","2d9a33fc":"code","bc6364ba":"code","f30c19b4":"code","e97c0298":"code","12d333ec":"code","017046e4":"code","4f5a4b0c":"code","12d6dae3":"markdown","3f97d841":"markdown","6ef6fd50":"markdown","59382c3b":"markdown","c0b75943":"markdown","b2cddb8a":"markdown","a450c681":"markdown","0a6cd7f3":"markdown","624add77":"markdown","b251df57":"markdown","3aa38652":"markdown","86a14817":"markdown","4d831e4f":"markdown"},"source":{"b0c01213":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","362dc9b3":"# store data into variables\nsample_data = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/sample_submission.csv')\neval_data = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/eval.csv')\ntrain_data = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/train.csv')","6d867638":"# check for missing data in the training set\nmissing_train_data = train_data.isna().sum()\nprint(missing_train_data)\n\n# check for missing data in the eval(test) set\nmissing_eval_data = eval_data.isna().sum()\nprint(missing_eval_data)","ded97909":"train_data.describe()","58f5b6d6":"from sklearn.preprocessing import LabelEncoder\n\n# let's create an encoder to be used convert esrb_ratings into ints\nencoder = LabelEncoder().fit(['E', 'ET', 'M', 'T'])\n\nX = train_data\nX = X.drop(['esrb_rating', 'title', 'id'], axis=1)\nprint(\"X:\\n\", X)\n\ny = pd.DataFrame({'esrb_rating_encoded':encoder.transform(train_data['esrb_rating'])})\nprint(\"y:\\n\", y)\n\n# set up train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 42)\n\n# set up eval data\nX_eval = eval_data\nX_eval = X_eval.drop('id', axis=1)\nprint(\"X_eval:\\n\", X_test)\n\n# create y_eval by copying over the esrb_ratings from the sample_data \ny_eval = pd.DataFrame({'esrb_rating_encoded':encoder.transform(sample_data['esrb_rating'])})\nprint(\"y_eval:\\n\", y_test)","46fc1e01":"X_test.describe()","2d9a33fc":"from sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression(random_state=42).fit(X_train, y_train.values.ravel())\n\npredictions = lr_model.predict(X_test)\n\nlr_df = pd.DataFrame({'Actual': y_test.values.ravel(), 'Predicted': predictions})\nprint(lr_df.describe())\n\nscores = cross_val_score(lr_model, X_test, y_test.values.ravel(), cv=5)\nprint(scores)","bc6364ba":"from sklearn import svm\n\nsvm_model = svm.SVC().fit(X_train, y_train.values.ravel())\n\npredictions = svm_model.predict(X_test)\n\nsvm_df = pd.DataFrame({'Actual': y_test.values.ravel(), 'Predicted': predictions})\nprint(svm_df.describe())\n\nscores = cross_val_score(svm_model, X_test, y_test.values.ravel(), cv=5)\nprint(scores)","f30c19b4":"from sklearn.tree import DecisionTreeClassifier\n\ndtc_model = DecisionTreeClassifier(random_state=42).fit(X_train, y_train.values.ravel())\n\npredictions = dtc_model.predict(X_test)\n\ndtc_df = pd.DataFrame({'Actual': y_test.values.ravel(), 'Predicted': predictions})\nprint(dtc_df.describe())\n\nscores = cross_val_score(dtc_model, X_test, y_test.values.ravel(), cv=5)\n\nprint(scores)","e97c0298":"from sklearn.ensemble import RandomForestClassifier\n\nrfc_model = RandomForestClassifier(max_depth=2, random_state=42).fit(X_train, y_train.values.ravel())\n\npredictions = rfc_model.predict(X_test)\n\nrfc_df = pd.DataFrame({'Actual': y_test.values.ravel(), 'Predicted': predictions})\nprint(rfc_df.describe())\n\nscores = cross_val_score(rfc_model, X_test, y_test.values.ravel(), cv=5)\n\nprint(scores)","12d333ec":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train.values.ravel())\n\npredictions = knn_model.predict(X_test)\n\nknn_df = pd.DataFrame({'Actual': y_test.values.ravel(), 'Predicted': predictions})\nprint(knn_df.describe())\n\nscores = cross_val_score(knn_model, X_test, y_test.values.ravel(), cv=5)\n\nprint(scores)","017046e4":"fpredictions = svm_model.predict(X_eval)\nfinal_df = pd.DataFrame({'Actual': y_eval.values.ravel(), 'Predicted': fpredictions})\nprint(final_df.describe())\n\nscores = cross_val_score(svm_model, X_test, y_test.values.ravel(), cv=5)\nprint(scores)","4f5a4b0c":"output = pd.DataFrame({'id':sample_data['id'], 'esrb_rating':encoder.inverse_transform(final_df['Predicted'])})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\nprint(output)","12d6dae3":"**We didn't find any missing data so we are free to continue without having to handle it**","3f97d841":"**Random Forest model**","6ef6fd50":"# Feature Engineering","59382c3b":"**Support Vector Machine**","c0b75943":"# Missing Data","b2cddb8a":"# Submission","a450c681":"**We use the svm model as our final form because it performed the best overall**","0a6cd7f3":"**Outliers don't seem to be an issue with a semi regular distribution of boolean values over all columns**","624add77":"**K Nearest Neighbors model**","b251df57":"# Load data","3aa38652":"# Models\n**Logistic Regression model**","86a14817":"# Outliers","4d831e4f":"**Decision Tree model**"}}