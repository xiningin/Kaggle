{"cell_type":{"d79d4b7b":"code","3fc588e7":"code","0b06c98c":"code","5ec92289":"code","9dd16284":"code","0834165f":"code","9d588d6e":"code","5eb0cfa2":"code","49344709":"code","f287022a":"code","e10bc12d":"code","403de349":"code","2d04fb79":"code","6741b348":"code","644e237f":"code","1d4ee4a6":"markdown","7dd7670a":"markdown","a4372a4d":"markdown","ddabea90":"markdown","d5519fd4":"markdown","0ca1bc09":"markdown"},"source":{"d79d4b7b":"# Displying image\n\nfrom IPython.display import Image\nImage(\"..\/input\/dtdata\/DT.PNG\")","3fc588e7":"# Importing libraries\n\nimport pandas as pd","0b06c98c":"# Reading file\n\nprint(r\"Reading 'daily_weather.csv' file...\")\ndf=pd.read_csv(\"..\/input\/dtdata\/daily_weather.csv\")\nprint(\"Reading few records from the dataset\")\ndf.head()","5ec92289":"# Informatin about dataset\n\nprint(\"Informatin about dataset.\")\ndf.info()","9dd16284":"# Listing all the records having NaN\n\nprint(\"Listing all the records having NaN\")\ndf[df.isnull().any(axis=1)]","0834165f":"# Dropping the Column 'Number' as it is not useful\n\ndf.drop('number',axis=1,inplace=True)\ndf.info()\nprint(r\"The column 'number' is removed but the count of records of each column is different due to presece of NaN\")","9d588d6e":"# Dropping all the records having NaN\n\nprint(\"Removing all the records having NaN\")\ndf.dropna(inplace=True)\n\ndf.info()\nprint(\"Now the count of all the records in each column is equal i.e. 1064\")","5eb0cfa2":"# Creating copy of the original dataset for processing\n\nprint(\"Creating copy of the original dataset for processing\")\ndf2=df.copy()\n\nprint(\"Assigning the records haviing relative_humidity_3pm > 25\")\ndf2['humidityval']=(df2['relative_humidity_3pm']>25)*1\n\ndf2.head()","49344709":"# Dropping the column 'relative_humidity_3pm' form the df2\n\nprint(r\"Dropping the column 'relative_humidity_3pm' form the df2\")\ndf2.drop('relative_humidity_3pm',axis=1, inplace=True)\ndf2.head()","f287022a":"# Assigning dataframs to variable\n\nprint(\"Assigning dataframs to variable.\")\ny=df2['humidityval']\nx=df2.drop('humidityval', axis=1)\ndf2.head()","e10bc12d":"# Importing libraries\n\nprint(\"Importing libraries\")\nfrom sklearn.model_selection import train_test_split\n\nprint(\"Spliting the dataset\")\ntrainx, testx, trainy, testy=train_test_split(x,y,test_size=0.33)\nprint(\"Spliting the dataset completed\")","403de349":"# Importing libraries for DecisionTreeClassifier\n\nprint(\"Importing libraries for DecisionTreeClassifier\")\nfrom sklearn.tree import DecisionTreeClassifier\n\nprint(\"Creating instace of the model\")\ndtcModel=DecisionTreeClassifier()\n\nprint(\"Training the model\")\ndtcModel.fit(trainx,trainy)\nprint(\"Model Trained\")\n\n# Predicting the values\n\nprint(\"Predicting the values..\")\npredictedOp=dtcModel.predict(testx)\nprint(\"Predicting the values completd.\")\n\n# Checking the accuracy\n\nprint(\"Checking the accuracy\")\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy is: %s\" % accuracy_score(testy,predictedOp))\n\n# Printing confusion matrix\n\nfrom sklearn.metrics import confusion_matrix\nprint(\"Confusion Matrix: \\n %s\" % confusion_matrix(testy,predictedOp))","2d04fb79":"# Importing libraries for RandomForestClassifier\n\nprint(\"Importing libraries for RandomForestClassifier\")\nfrom sklearn.ensemble import RandomForestClassifier\n\nprint(\"Creating instace of the model\")\nrfcModel=RandomForestClassifier(n_estimators=30)\n\nprint(\"Training the model\")\nrfcModel.fit(trainx,trainy)\nprint(\"Model Trained\")\n\n# Predicting the values\n\nprint(\"Predicting the values..\")\npredictedOpRf=rfcModel.predict(testx)\nprint(\"Predicting the values completd.\")\n\n# Checking the accuracy\n\nprint(\"Checking the accuracy\")\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy is: %s\" % accuracy_score(testy,predictedOpRf))\n\n# Printing confusion matrix\n\nfrom sklearn.metrics import confusion_matrix\nprint(\"Confusion Matrix: \\n %s\" % confusion_matrix(testy,predictedOpRf))","6741b348":"# Difference in prediction value between Decision Tree and Random Forest algorithm\n\nprint (\"Difference in prediction value between Decision Tree and Random Forest algorithm\")\nprint(\"Accuracy is for Decision Tree: %s\" % accuracy_score(testy,predictedOp))\nprint(\"Accuracy is for Random Forest: %s\" % accuracy_score(testy,predictedOpRf))\nprint(\"Confusion Matrix Decision Tree: \\n %s\" % confusion_matrix(testy,predictedOp))\nprint(\"Confusion Matrix Random Forest: \\n %s\" % confusion_matrix(testy,predictedOpRf))","644e237f":"print(\"Notebook completd!\")","1d4ee4a6":"## Decision Tree Model","7dd7670a":"# **Random Forest Algorithm**\n\nAbout: A simple practical example of a machine learning algorithm: Random Forest\n\nRandom forest: It is a supervised learning algorithm which is used for both classification as well as regression, which form the majority of current machine learning systems. The Random Forest algorithm creates decision trees on data samples and then gets the prediction from each of them. Finally, it selects the best solution by means of voting. Here, voting means selection of the prediction for which majority tree predicted. It is an ensemble method which is better than a single decision tree because it reduces the over-fitting by averaging the result.\n\nRandom forest is a flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. It is also one of the most used algorithms, because of its simplicity and diversity.\n\nRandom forest adds additional randomness to the model, while growing the trees. Instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a wide diversity that generally results in a better model.\n\nIn simple words, random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.","a4372a4d":"# Reading and Processing Dataset","ddabea90":"# Importing libraries","d5519fd4":"## Random Forest Model","0ca1bc09":"# Model building and Predicting"}}