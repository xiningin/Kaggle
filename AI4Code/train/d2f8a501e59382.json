{"cell_type":{"08b71759":"code","7eff4675":"code","d27ee86a":"code","0b98b46d":"code","da960bd9":"code","c2caa56e":"code","b5943ef4":"code","2c135de0":"code","35096959":"code","1a058f83":"code","b39850c7":"code","44f05af3":"code","c253d8be":"code","896c766e":"code","855ed665":"code","79ab3bf1":"code","70f8cbbd":"markdown","e41bc559":"markdown"},"source":{"08b71759":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7eff4675":"import matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport tensorflow.keras as keras\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array,load_img\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport pandas as pd\nsns.set_style(\"whitegrid\")","d27ee86a":"train_dir = '..\/input\/withwithout-mask\/maskdata\/maskdata\/train'\ntest_dir = '..\/input\/withwithout-mask\/maskdata\/maskdata\/test'","0b98b46d":"categories = []\nfilenames = os.listdir(\"..\/input\/withwithout-mask\/maskdata\/maskdata\/test\")\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'with_mask':\n        categories.append(1)\n    else: # nonmask\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\nprint(df.head(20))","da960bd9":"df.category.value_counts()","c2caa56e":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255\n)","b5943ef4":"train_images = train_generator.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_directory(\n    test_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False\n)","2c135de0":"inputs = tf.keras.Input(shape=(224, 224, 3))\nx = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(32, activation='relu')(x)\nx = tf.keras.layers.Dense(32, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nprint(model.summary())","35096959":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        )\n    ]\n)","1a058f83":"results = model.evaluate(test_images, verbose=0)\nprint(\"    Loss: {:.5f}\".format(results[0]))\nprint(\"Accuracy: {:.3f}%\".format(results[1] * 100))","b39850c7":"history.history.keys()","44f05af3":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])","c253d8be":"plt.plot(history.history['loss'])","896c766e":"plt.plot(history.history['val_loss'])","855ed665":"sample_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255\n)\n\nsample_images = sample_generator.flow_from_directory(\n    test_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42\n)","79ab3bf1":"samples = sample_images.next()\n\npredictions = np.squeeze(model.predict(samples[0]) >= 0.5).astype(np.int)\nlabels = samples[1].astype(np.int)\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.imshow(samples[0][i])\n    plt.axis('off')\n    plt.title((\"NO MASK\" if predictions[i] == 1 else \"MASK\"), color=('blue' if labels[i] == predictions[i] else 'red'))\n\nplt.show()","70f8cbbd":"**Visualize the result**","e41bc559":"**Callbacks provide a way to execute code and interact with the training model process automatically**"}}