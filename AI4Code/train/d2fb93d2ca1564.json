{"cell_type":{"2723e91e":"code","35979b8a":"code","6c1acdfa":"code","ff55781f":"code","40b16fa1":"code","d94b1257":"code","84f9dec2":"code","1161dc78":"code","fc588d51":"code","4903db7f":"code","77422984":"code","8348329b":"code","e6ade3cd":"code","62bc0a2e":"code","f57e0b52":"code","116104d4":"code","ac3a3d61":"code","21cc36d2":"code","4665209a":"code","dbbbb5de":"code","a0759980":"code","b1e5e0e2":"code","4d4baef3":"code","3b4cec14":"code","38e99b58":"code","792b2dcd":"code","f1477fa4":"code","25984100":"code","3f9413cd":"code","e62add4e":"code","7ca6e898":"code","dfe980c0":"code","3898665e":"code","3259bee7":"code","fb273bde":"markdown","620d5551":"markdown","45fd5985":"markdown","52309386":"markdown","f3866966":"markdown","9dec4aa6":"markdown","34215364":"markdown","454943e1":"markdown","7d509a06":"markdown","43d4275c":"markdown","a1da6738":"markdown","a8ad6ed4":"markdown","bda2f6e9":"markdown","9410fff3":"markdown","0ee05df0":"markdown","3f562531":"markdown","2e72f6e3":"markdown","7664cffa":"markdown","e7e7073f":"markdown","c49c7453":"markdown","886b7047":"markdown","1e5e98e0":"markdown","c01447e3":"markdown","7be8c599":"markdown","a4b219f1":"markdown","46fe457e":"markdown","3082b40b":"markdown"},"source":{"2723e91e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom subprocess import check_output\nprint (check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\ndata = pd.read_csv ('..\/input\/avocado.csv')","35979b8a":"data.info()","6c1acdfa":"data.describe()","ff55781f":"data.corr()","40b16fa1":"f, ax = plt.subplots (figsize=(10,10))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt='.2f', ax=ax, cmap=\"PiYG\")\nplt.show() #to clear the statements appearing by default\n#cmap=\"PiYG\":to set the color. Some other options: \"YlGnBu\" , \"Blues\", \"BuPu\", \"Greens\"\n#annot=True :It gives us correlation values inside the boxes\n#linewidths= .5 :Thickness of line between boxes\n#fmt= '.2f' :It gives how many will be written of correlation values after comma","d94b1257":"data.head(10)","84f9dec2":"data.columns","1161dc78":"data['AveragePrice'].plot(color = 'm', label = 'avg price',linewidth=2,alpha = 0.4,grid = True, linestyle = '-', figsize=(25,6)) #alpha:opacity\nplt.legend(loc='upper right') # legend = puts label into plot\nplt.yticks(np.arange(0.1,3.5,0.2))  #to set the range of y axis - (min, max, )\nplt.xticks(np.arange(1000,18500,1000)) \nplt.xlabel('Sample Number') \nplt.ylabel('Feature Value of the Sample')\nplt.title('Line Plot for Avg Price Values')            \nplt.show()","fc588d51":"data.plot(kind='scatter', x='Total Bags', y='Total Volume', alpha=0.5, c='r',figsize=(8,8))\nplt.xlabel('total bags')\nplt.ylabel('total vol')\nplt.title('bags - vol scatter')\nplt.show()","4903db7f":"data.AveragePrice.plot(kind='hist', bins = 20, figsize =(8,8), color='y', EdgeColor='m')\n#bins = number of bar in figure\nplt.xlabel('Avg Price')\nplt.show()\n","77422984":"x = data['AveragePrice']>1.0\ndata[x]","8348329b":"data[data['AveragePrice']==data['AveragePrice'].max()]","e6ade3cd":"data[np.logical_and(data['AveragePrice']<1,data['type']=='organic')]","62bc0a2e":"data[(data['AveragePrice']<1) & (data['type']=='organic')]","f57e0b52":"#tuple is a data type \ndef tuple_ex():\n    \"\"\" This part that is to explain the functions is called docstrings\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuple_ex()\nprint(a,b,c)","116104d4":"x = 2\ndef f():\n    x = 3\n    return x\nprint(x)      # x = 2 global scope\nprint(f())    # x = 3 local scope","ac3a3d61":"x = 5\ndef f():\n    y = 2*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x","21cc36d2":"import builtins\ndir(builtins)","4665209a":"def square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())    ","dbbbb5de":"def f(a, b=1)\n\n#If b is not assigned to another value, then b=1.","a0759980":"def f (*args)\n\n#we can define as many as different variables each time.\n\ndef f(**kwargs)\n#flexible argument for dictinary","b1e5e0e2":"#without lambda:\ndef f(x):\n    return x**2\nprint (f(5))\n\n#with lambda:\nf= lambda x: x**2\nprint (f(4))","4d4baef3":"number_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))","3b4cec14":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z) #we created the zip object here.\nz_list = list(z)\nprint(z_list)\nprint(\"\")\n\n#unzip example\nun_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) # unzip returns tuble\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))","38e99b58":"# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","792b2dcd":"# lets classify avocado prices whether they are expensive or affordable. Our threshold is average price.\nthreshold = sum(data.AveragePrice)\/len(data.AveragePrice)\nprint(threshold)\ndata[\"price_level\"] = [\"expensive\" if i > threshold else \"affordable\" for i in data.AveragePrice]\ndata.loc[15000:15010,[\"price_level\",\"AveragePrice\"]] # we will learn loc more detailed later","f1477fa4":"data_new=data.head()\n#data_new\nmelted = pd.melt(frame=data_new, id_vars = 'AveragePrice', value_vars=['Total Volume', 'Total Bags'])\nmelted","25984100":"melted.pivot(index = 'AveragePrice', columns = 'variable',values='value')","3f9413cd":"#axis=0 means vertical:    \n\ndata1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1, data2], axis=0, ignore_index=True) #ignore_index=True means ignore the real index and assign new\nconc_data_row #calling the new table","e62add4e":"#axis=1 means horizaontal\n\ndata1 = data['AveragePrice'].head()\ndata2 = data['Total Volume'].head()\nconc_data_col = pd.concat([data1, data2], axis=1) \nconc_data_col ","7ca6e898":"data.dtypes","dfe980c0":"#let's change the data tyoe of all the inputs under 4046 from float to category\ndata['4046']=data['4046'].astype('category')\ndata.dtypes","3898665e":"#How many inputs do we have for each category?\ndata['region'].value_counts(dropna=False) #dropna=False to show the NaN values, as well.","3259bee7":"data1=data\ndata1[\"region\"].dropna(inplace=True)  #to drop NaN values\nassert data[\"region\"].notnull().all() #to check if we have NaN valur. As we already droped them, it returns (True), not an Erroe\ndata[\"region\"].fillna('empty', inplace=True) #to fill NaN values with \"empty\"","fb273bde":"1-Filtering Pandas Data Frame","620d5551":"**PANDAS**","45fd5985":"Alternative for logical_and:","52309386":"Scatter Plot:\nScatter is better when there is correlation between two variables","f3866966":"Lambda function: \n\nfast way of writing a function.","9dec4aa6":"We will write a melt() method. We will make data visualisation with seaborn library later on using melt(). ","34215364":"List Comprehension","454943e1":"2 - Filtering Pandas with logical_and:","7d509a06":"How can we learn what is built in scope?\n\nWe don't prefer using the below as the variable name. Because it may unnecesserily confuse the kernel and cause errors.","43d4275c":"Concatenating:\n\nWe will join to dataframes","a1da6738":" **MATLAB**\n \nWe will continue with creating 2D graphs. We will use Matlab library for this purpose. There are different kinds of graphs we can create. \n\nHere is Line Plot: \nLine plot is better when x axis is time. ","a8ad6ed4":"Missing Data and Testing with Assert","bda2f6e9":"  We do not have any NaN values in this dataset. But if we had, we might drop the NaN values.","9410fff3":"**CLEANING DATA**\n\nBox plot:","0ee05df0":"Nested functions:\n\nFunction inside of another function.","3f562531":"**Phyton Data Science Toolbox**\n\nIn this section, we will make some practice to go over the fundamental conceps. \n\nTuple and docstring","2e72f6e3":"Default arguments:","7664cffa":"zip(): and unzip(): methods","e7e7073f":"Let's have a look at the data at a high level: ","c49c7453":"Flexible arguments:","886b7047":"Histogram:\nHistogram is better when we need to see distribution of numerical data.","1e5e98e0":"Anonymous Function:\n\nLambda function for lists.\n\nWe use map(func, seq) here. ","c01447e3":"  The kernel first checks if there is any local scope. If there is, it is used. If not, then the global scope is used. If none of the two is found, then built in scope is checked.","7be8c599":"Scope\n\n* global\n* local\n* built-in","a4b219f1":"Datatypes:","46fe457e":"Reverse of melt():","3082b40b":"**Let's Start:**\n\nThis is my first kernel on Kaggle and I analyzed the avocado prices. \n\nLet's start with importing the libraries that we will use:"}}