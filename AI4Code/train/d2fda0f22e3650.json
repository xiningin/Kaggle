{"cell_type":{"fd3a3ec0":"code","c2a07abe":"code","ce3ab470":"code","fcc35c2d":"code","2b1c4c4f":"code","d232378a":"code","cf750925":"code","56946398":"code","415c1411":"code","6298fec1":"code","a62b24ca":"code","890b4a20":"code","e0295af9":"code","d4349c26":"code","413fe970":"code","11db0b13":"code","8d67b103":"code","7c57a92b":"code","5a8d2625":"code","750c2a92":"code","623461a2":"code","fcad62ab":"code","e00f0349":"code","10e4706f":"code","ae5f27c7":"code","060ceaf3":"code","83760813":"code","d9f7cb7e":"code","866bde54":"code","3f8e77d1":"code","20eab330":"code","907cc89c":"code","21f878cc":"code","b3e8d0b6":"code","3b582e94":"code","78a81388":"code","818e1113":"code","92c92c27":"code","cf624370":"code","5498be7c":"code","8836af28":"code","53aa5f2e":"code","546236e9":"code","d0ccb6ce":"code","af087f7a":"code","587a1de9":"code","d206f317":"code","8425488c":"code","37d9b490":"code","47a8ba03":"code","98d5df64":"code","6d8b9823":"code","0e7a7d97":"code","92631433":"code","a001e7a1":"code","62a5f308":"markdown","4f34ce01":"markdown","4dd13d82":"markdown","292ac471":"markdown","ec714ab6":"markdown","0f398322":"markdown","8b903a8f":"markdown","6f5f7a58":"markdown","62e68e93":"markdown","fadc9797":"markdown","19a08075":"markdown","ae52b06d":"markdown","cbde02c2":"markdown","a5d6a447":"markdown","60cf09ce":"markdown","07c1c0ca":"markdown","f1b93373":"markdown","b83fd92a":"markdown","1a8ef1cb":"markdown","5317f5b5":"markdown","6d86d263":"markdown","df6e734c":"markdown","369256f9":"markdown","aa70f509":"markdown","d3275094":"markdown"},"source":{"fd3a3ec0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c2a07abe":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n%matplotlib inline","ce3ab470":"churn=pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","fcc35c2d":"churn.columns.values","2b1c4c4f":"churn.dtypes","d232378a":"# change totalcharges's type(object) to float64","cf750925":"churn['TotalCharges']=pd.to_numeric(churn['TotalCharges'],errors = 'coerce')","56946398":"churn.isnull().sum()","415c1411":"churn.dropna(inplace=True)","6298fec1":"# delete the first column (customerID)\nchurn.head()\nchurn_d=churn.iloc[:,1:]","a62b24ca":"# transfrom yes,no to 1,0\nchurn_d['Churn'].replace(to_replace='Yes',value=1,inplace=True) \nchurn_d['Churn'].replace(to_replace='No',value=0,inplace=True)","890b4a20":"#get_dummy \nchurn_dum= pd.get_dummies(churn_d)\nchurn_dum.columns.values","e0295af9":"sns.countplot(x=\"Churn\",data=churn)","d4349c26":"plt.figure(figsize=(15,8)) \nchurn_corr = churn_dum.corr()['Churn'].sort_values(ascending=False).plot(kind='bar', \n                                                                         title ='Correlation between Churn & variables'\n                                                                        )\nchurn_corr.set_xlabel('category',fontsize=20) \nchurn_corr.set_ylabel('correlation',fontsize=20)","413fe970":"plt.figure(figsize=(10,8), dpi= 80) \nsns.heatmap(churn.corr(), xticklabels=churn.corr().columns, \n            yticklabels=churn.corr().columns, cmap='RdYlGn', center=0, annot=True)","11db0b13":"# more exploration ","8d67b103":"for item in churn['Contract'].unique():\n    print(item)","7c57a92b":"contract_types = (churn['Contract'].value_counts(normalize=True) * 100).keys().tolist() \ncontract_propotion = (churn['Contract'].value_counts(normalize=True) * 100).values.tolist()\nfor i in range(3):\n    contract_propotion[i]=round(contract_propotion[i],2)\ntext= ['{} %'.format(x) for x in contract_propotion]\nprint(contract_types)","5a8d2625":"month_to_month =churn.loc[churn['Contract']=='Month-to-month'] \nm2m = int(round((month_to_month['Churn'].value_counts(normalize=True) * 100)['Yes']))\none_year =churn.loc[churn['Contract']=='One year'] \noney = int(round((one_year['Churn'].value_counts(normalize=True) * 100)['Yes']))\ntwo_year =churn.loc[churn['Contract']=='Two year'] \ntwoy = int(round((two_year['Churn'].value_counts(normalize=True) * 100)['Yes']))\nchurn_rate = [m2m, oney, twoy] \nretention_rate = [100 - m2m, 100 - oney, 100 - twoy]\nprint(contract_types,'\\n',contract_propotion,'\\n',churn_rate,'\\n',retention_rate)","750c2a92":"#Visulize the result above \n\nplt.figure(figsize=(8,6)) \nchurn_label=['{} %'.format(x) for x in churn_rate] \nretention_label=['{} %'.format(x) for x in retention_rate]\np1=plt.bar(contract_types,churn_rate,color='yellow', hatch=\"*\") \np2=plt.bar(contract_types, retention_rate,bottom=churn_rate,color='#FFE4C4')\nplt.ylim(0,100) \nplt.ylabel('churn and retention rate') \nplt.xlabel('contract type')","623461a2":"import plotly.express as px \nfig = px.histogram(churn, x=\"Churn\", y=\"MonthlyCharges\", color='Churn', facet_col=\"Contract\", histfunc='avg')\nfig.update_layout(title_text='Average Monthly Cost by Contract Type')\nfig.show()","fcad62ab":"#Tenure: Number of months the customer has stayed with the company\nchurn[\"tenure\"].describe()","e00f0349":"fig, a1=plt.subplots(nrows=1,ncols=1,sharey=True,figsize=(8,4))\nfor type in contract_types:\n    for ai in [a1]:\n        for title in ['M-to-M','One-year','Two-year']:\n            a=sns.distplot(churn[churn['Contract']==type]['tenure'],ax=ai)\n            a.set_xlabel('Tenure_month')\n            a.set_ylabel('proportion of customer') \n            a.set_title('Churn & Tenure')\nfig.legend(labels=['M-to-M','one-year','two-year'])","10e4706f":"# build a list of service including all...\n\nservice=['PhoneService','MultipleLines','InternetService','OnlineSecurity', \n         'OnlineBackup','DeviceProtection', 'TechSupport','StreamingTV','StreamingMovies']","ae5f27c7":"fig,axes=plt.subplots(nrows=3,ncols=3,figsize=(12,10)) \n\nfor i,item in enumerate(service):\n    if i <3:\n        ax=churn[item].value_counts().plot(kind='bar',ax=axes[i,0]) \n    if i >= 3 and i < 6:\n        ax=churn[item].value_counts().plot(kind='bar',ax=axes[i-3,1]) \n    if i>=6:\n        ax=churn[item].value_counts().plot(kind='bar',ax=axes[i-6,2]) \n    ax.set_title(item)","060ceaf3":"churn_dum.head() # get_dummy before","83760813":"# choose variables \nx=churn_dum.drop(columns=['Churn']) \ny=churn_dum['Churn'] \n#normalization \nfrom sklearn.preprocessing import MinMaxScaler \nfeatures=x.columns.values \nscaler=MinMaxScaler(feature_range=(0,1)) \nscaler.fit(x) \nx=pd.DataFrame(scaler.transform(x)) \nx.columns=features","d9f7cb7e":"from sklearn.model_selection import train_test_split \nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=101)","866bde54":"from sklearn.linear_model import LogisticRegression \nmodel=LogisticRegression() \nresult=model.fit(x_train,y_train)\n\nfrom sklearn import metrics\nlg_pred=model.predict(x_test)\nprint(metrics.accuracy_score(y_test,lg_pred))","3f8e77d1":"from sklearn.metrics import classification_report \nlg_report= classification_report(y_test, lg_pred) \nprint(lg_report)","20eab330":"from sklearn.ensemble import RandomForestClassifier \nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=101) \nmodel_r=RandomForestClassifier(n_estimators=100,random_state=50, oob_score=True) \nmodel_r.fit(x_train,y_train) \nrf_pred=model_r.predict(x_test)\nprint(metrics.accuracy_score(y_test,rf_pred))","907cc89c":"rf_report=classification_report(y_test, rf_pred)\nprint(rf_report)","21f878cc":"rand_score =[] \nfor i in range(1,102):\n    i_loop= RandomForestClassifier(n_estimators=i, random_state=101) \n    i_loop.fit(x_train,y_train) \n    loop_pre=i_loop.predict(x_test) \n    rand_score.append(metrics.accuracy_score(y_test,loop_pre))","b3e8d0b6":"plt.plot(range(1,102),rand_score)\nplt.xlabel(\"Range\") \nplt.ylabel(\"accuracy score\")\nplt.show()","3b582e94":"model_r=RandomForestClassifier(n_estimators=79,random_state=101, oob_score=True)\nmodel_r.fit(x_train,y_train) \nrf_new_pred=model_r.predict(x_test)\nprint(metrics.accuracy_score(y_test,rf_new_pred))","78a81388":"# only a little bit improvement ","818e1113":"rf_new_report=classification_report(y_test, rf_new_pred)\nprint(rf_new_report)","92c92c27":"rand_coef=model_r.feature_importances_ \nweight=pd.Series(rand_coef,index=x.columns.values)\nweight.sort_values(ascending=False)[:10]","cf624370":"from sklearn.svm import SVC\nsvc_model = SVC(random_state=101)\nsvc_model.fit(x_train, y_train) \naccuracy_svc = svc_model.score(x_test, y_test)\nprint(accuracy_svc)","5498be7c":"svm_pred=svc_model.predict(x_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nsvm_report=classification_report(y_test,svm_pred) \nprint(svm_report)","8836af28":"x_train.head() # has been standardalized","53aa5f2e":"import keras","546236e9":"from keras.models import Sequential \nfrom keras.layers import Dense \nfrom keras import optimizers \nmodel_nn = Sequential() \nsgd= optimizers.SGD(lr=0.01) # (set learning rate)\n# first time, no gradient descend, so might be the reason learning rate is too fast, thus...set it as 0.01","d0ccb6ce":"model_nn.add(Dense(45, activation= 'relu', input_dim=45)) \nmodel_nn.add(Dense(22, activation='relu'))\nmodel_nn.add(Dense(11, activation='relu')) \nmodel_nn.add(Dense(6, activation='relu')) \nmodel_nn.add(Dense(1,activation='sigmoid'))","af087f7a":"model_nn.compile(loss='binary_crossentropy',optimizer='SGD',metrics=['accuracy']) \nhistory= model_nn.fit(x_train, y_train,\n                      batch_size=30, epochs=50, validation_data=(x_test,y_test))","587a1de9":"result_1=model_nn.evaluate(x_test,y_test)\nresult_1","d206f317":"history_dict=history.history\nhistory_dict.keys()","8425488c":"loss_value=history_dict['loss'] \nval_loss_values= history_dict['val_loss']","37d9b490":"plt.clf() \nepochs=range(1,len(loss_value)+1)\nplt.plot(epochs,loss_value,'bo',label='Training loss') \nplt.plot(epochs,val_loss_values,'b',label='Validation loss') \nplt.title('Training and validation loss') \nplt.xlabel('Epochs') \nplt.ylabel('loss')\nplt.legend()","47a8ba03":" # Accroding to the graph, it is reasonable to use epochs=50 where has the least loss ","98d5df64":"nn_pred = model_nn.predict(x_test)\nnn_pred[1:5]","6d8b9823":"def threshold(nn_pred):\n    lst_threshold=[] \n    for i in nn_pred:\n        if i >=0.5:\n            i=1 \n            lst_threshold.append(i)\n        else: \n            i=0 \n            lst_threshold.append(i)\n    return lst_threshold","0e7a7d97":"nn_pred_new = threshold(nn_pred) \nnn_pred_new[1:5]","92631433":"nn_report=classification_report(y_test,nn_pred_new)\nprint(nn_report)","a001e7a1":"print('\\n--------------------Logistic Regression-----------------\\n',lg_report, \n      '\\n----------------------Random Forest---------------------\\n',rf_report, \n      '\\n----------------- Support Vector Machine----------------\\n',svm_report, \n      '\\n---------------------Neural Network---------------------\\n',nn_report)","62a5f308":"# Churn & Charge & Contract","4f34ce01":"\nfor report precision, recall and f1,\nClassification metrics can't handle a mix of binary and continuous targets !!!!\n\nbuild threshold rule for neural network","4dd13d82":"same: TOTAL charges, tenure and monthlycharges, contract .. are highly possive related with churn result \n\nseems no change for recall and f1 LOL","292ac471":"Top 3 positive correlated variables : contract month_to_month, online_security_No, tech_support_No, \nTop 3 negative correlated variables:  tenure, contract_2_year, internet_servive_no, streaming_service_NO \n\nSome interetsing things:\n\n1.contract_month_to_month and contract_2year have totally di\ufb00erent in\ufb02uences.\n\n2.monthly charge and total_charge have opposite e\ufb00ects on churn\n\n3.total_charge and tenure has strong relationship (0.83)\n\n4.absence of online security and tech support seem to be positively correlated with churn\n\n5.customer with no internet service are less likely to churn. \n\n6.difference among payment methods.\n\n...","ec714ab6":"# I would explore and find the most appropiate tree numbers (n_estomators)","0f398322":"in the view of accuracy: **Neural network(0.8109)> SVM (0.8085) > logistic regression (0.8076)>random forest(0.7981)**\nIn fact, i think the four models are all good predictor (over 0.8). however,because the **data is imbalanced!**, i prefer \nto compare the  recall and f1-score rather than accuracy!!\n\nbesides, the **precision is more important than recall in this customer churn prediction project, **\nfor we take more care on dicovering the targeted customers precisely and make e\ufb00ective strategies.( precision: P=TP\/(TP+FP) )\nand classifing loyal customers into churn group would not make any loss.\n\nThus, logistic regression and support vector machine, neural network are a little bit better. ","8b903a8f":"# Random Forest ","6f5f7a58":"# Churn & Tenure & Contract","62e68e93":"# Distribution of our target value : churn ","fadc9797":" # Churn & Contract","19a08075":"# check type and null value ","ae52b06d":"the area of yellow with star represents churn rate. According to the bar chart, people with month to month contract are much easier to churn.\nM2M > 2 year > 1 year","cbde02c2":"# SVM","a5d6a447":"# Neural Network","60cf09ce":"# In this project, I had finished some EDA process,and Utilized four predictive models( logistic regression, Support vector machine, random forest and neural network) and evaluate.","07c1c0ca":"# Churn & Service ","f1b93373":"# Correlation Analysis","b83fd92a":"nomatter which type of contract customer chooses, increasing average monthly charges, much easier to churn, ","1a8ef1cb":"from all the figures above (except phone service)\nabsence of online security and tech support ... and etc. seem to be abviously positively correlated with churn. \nthat when this service == 'Yes', they are less likely to churn \n\ndata visualization results are accord with the result (1,2,3,4) of correlation analysis, \nAfter EDA, I would build some classification model and evaluate.\n\n(Logistic model, random forest, support vector machine, neural netwrok)","5317f5b5":"install plotly from terminal\n\n****pip install plotly\n\nhttps:\/\/plot.ly\/python\/plotly-express\/","6d86d263":"the result shows that majority of cutsomers have month_month contract(55.11%)\nThen visualize the churn rate for different groups.","df6e734c":"# 79 trees around","369256f9":"From the result, the dataset is imbalance, which would make our accuracy measurement untenable, when \nwe evaluate the model, we prefer to use recall or f1 to judge.","aa70f509":"for people who only has a monthly contract tend to has a shorter tenure and longer in a two year contract,\n\nlonger time, more loyal, \n\nso we might need to adjust some strategies for the short contract with conditions and terms.","d3275094":"# logistic model "}}