{"cell_type":{"06cfcc92":"code","218026bf":"code","0f14bd1a":"code","606ab2ce":"code","ee429ace":"code","122e71c4":"code","fefc7ccd":"code","4bc0bb27":"code","dadbba60":"code","5590bd55":"code","537666e3":"code","251e498d":"code","2dc4bf66":"code","c6651945":"code","983ab739":"code","7cb51f25":"code","7110c1ba":"code","02d0b240":"code","cebb3e1a":"code","30de82f5":"code","d1e8eb04":"code","a16d9ed0":"code","60540e8b":"code","86d0d833":"code","4431c136":"code","19d43c60":"code","6cf60c39":"code","4e685092":"code","6d3539d0":"code","1747cc7d":"code","bdb5dd5d":"code","401f9154":"code","a0cbdd0f":"code","cfb57e80":"code","2a19c53a":"code","70c73824":"code","f754a900":"code","f06374ce":"code","c8776af6":"markdown","0dfea004":"markdown","dc2513b0":"markdown","67b29fec":"markdown","949f8ae3":"markdown","f42f9800":"markdown","2692be4e":"markdown","514559bb":"markdown","f86e5720":"markdown"},"source":{"06cfcc92":"# Import packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # visulization","218026bf":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","0f14bd1a":"# Preview\ntrain.head()","606ab2ce":"# Features\ntrain.info()","ee429ace":"# We can use following code to make a basic profile of datasets in the beginning.\n# (It will take some time to run.)\n# import pandas_profiling\n# pandas_profiling.ProfileReport(train)","122e71c4":"# Describe data\ntrain.describe()","fefc7ccd":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","4bc0bb27":"train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","dadbba60":"train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","5590bd55":"train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","537666e3":"# Visualization\nimport seaborn as sns\ng = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","251e498d":"grid = sns.FacetGrid(train, col='Survived', row='Pclass', height=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","2dc4bf66":"grid = sns.FacetGrid(train, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","c6651945":"grid = sns.FacetGrid(train, col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","983ab739":"train = train.drop(['Name','Ticket', 'Cabin'], axis=1)\ntest = test.drop(['Name','Ticket', 'Cabin'], axis=1)\n\n# Drop the useless features and features with missing values","7cb51f25":"combine = [train,test]\nfor dataset in combine:\n# convert Sex feature to a new feature where female=1 and male=0\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n    \ntrain.head()","7110c1ba":"for dataset in combine:\n# convert Embarked feature to a numeric feature\n    freq_port = train.Embarked.dropna().mode()[0]\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain.head()","02d0b240":"for dataset in combine:\n# convert Embarked feature to a numeric feature\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain.head()","cebb3e1a":"train = train.drop(['SibSp','Parch','FamilySize'], axis=1)\ntest = test.drop(['SibSp','Parch','FamilySize'], axis=1)","30de82f5":"# Guess Age values using median values for Age across sets of Pclass and Gender feature combinations.\nguess_ages = np.zeros((2,3))\n\ncombine = [train,test]\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n            age_guess = guess.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain.head()","d1e8eb04":"train['AgeBand'] = pd.cut(train['Age'], 5)\ntrain[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","a16d9ed0":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain.head()","60540e8b":"train = train.drop(['AgeBand'], axis=1)\ncombine = [train, test]\ntrain.head()","86d0d833":"train['FareBand'] = pd.qcut(train['Fare'], 4)\ntrain[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","4431c136":"combine = [train, test]\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n\ntrain = train.drop(['FareBand'], axis=1)\n    \ntrain.head(10)","19d43c60":"train['Fare'] = train['Fare'].astype(int)\ntest['Fare'] = test['Fare'].fillna(test['Fare'].mode()[0])\ntest['Fare'] = test['Fare'].astype(int)\ncombine = [train, test]","6cf60c39":"X_train = train.drop(\"Survived\", axis=1).drop(\"PassengerId\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","4e685092":"# Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","6d3539d0":"coeff_df = pd.DataFrame(X_train.columns)\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","1747cc7d":"# Support Vector Machines\n\nfrom sklearn.svm import SVC, LinearSVC\nsvc = SVC(gamma = 'auto')\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","bdb5dd5d":"# k-Nearest Neighbor\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","401f9154":"# Gaussian Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","a0cbdd0f":"# Stochastic Gradient Descent\n\nfrom sklearn.linear_model import SGDClassifier\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","cfb57e80":"# Decision Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","2a19c53a":"# Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","70c73824":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', \n              'Stochastic Gradient Decent', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, \n              acc_sgd,  acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","f754a900":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","f06374ce":"submission.to_csv('submission.csv', index=False)","c8776af6":"Some certain values of SibSp and Parch have no correlation with survival rate.","0dfea004":"# Load and explore data","dc2513b0":"The higher fare, the higher survival rate,especially for females.","67b29fec":"<li>Pclass varies in terms of Age distribution of passengers.<\/li>\n<li>Most of the infants in Pclass=2 and Pclass=3.<\/li>\n<li>Young passengers in Pclass = 3 are mostly unable to suvive.","949f8ae3":"# Preprocession","f42f9800":"The survival pattern of sex when Embarked  = Q is totally oppoiste to the the pattern of other two.","2692be4e":"Pclass = 1 had the highest survival rate.","514559bb":"# Model","f86e5720":"Sex=female had very high survival rate at 74%."}}