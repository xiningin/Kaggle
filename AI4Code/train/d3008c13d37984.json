{"cell_type":{"f0b39e83":"code","7921cd5b":"code","1774a95b":"code","25e07d0e":"code","313464f4":"code","9b39b065":"code","674644f2":"code","135a680d":"code","aaba8743":"code","dae72062":"code","e16fc995":"code","f3e8adef":"code","5a4459dc":"code","87d1b265":"code","8e78f014":"code","302c35e7":"code","ae04a22d":"code","1ea9629a":"code","bdc3044b":"code","004f0a77":"code","5b846f71":"code","b4b4164c":"code","023e2faa":"code","e75c7ab2":"code","fca8c97a":"code","26f33cd7":"code","853574da":"code","eb4097c5":"code","f797ca51":"code","504ceb9a":"code","4e9d2b5e":"code","7294c065":"code","8b4bba97":"code","24e31c05":"code","1761e5c7":"code","6c832786":"code","c37ac33b":"markdown","b4637586":"markdown","e00f2789":"markdown","2a3e4575":"markdown"},"source":{"f0b39e83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7921cd5b":"import matplotlib.pyplot as plt\nimport seaborn\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,MaxPooling2D,Dropout,Dense,Flatten,BatchNormalization,Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import VGG16\nfrom keras.callbacks import ModelCheckpoint\n%matplotlib inline\nimport glob\nimport cv2","1774a95b":"infected = glob.glob('..\/input\/cell_images\/cell_images\/Parasitized\/*.png')\nuninfected = glob.glob('..\/input\/cell_images\/cell_images\/Uninfected\/*.png')","25e07d0e":"print('Total number of Infected Cell Images are ',len(infected),' shape of first image is ',cv2.imread(infected[0]).shape)\nprint('Total number of Uninfected Cell Images are ',len(uninfected),' shape of the first image is ',cv2.imread(uninfected[0]).shape)","313464f4":"plt.figure(figsize=(12,5))\nfor i in range(1,5):\n    plt.subplot(1,4,i)\n    value = np.random.randint(100)\n    image = cv2.imread(infected[value])\n    plt.imshow(image)\n    plt.title('Infected Image')\n    plt.xticks([])\n    plt.yticks([])","9b39b065":"plt.figure(figsize=(12,5))\nfor i in range(1,5):\n    plt.subplot(1,4,i)\n    value = np.random.randint(100)\n    image = cv2.imread(uninfected[value])\n    plt.imshow(image)\n    plt.title('Uninfected Image')\n    plt.xticks([])\n    plt.yticks([])","674644f2":"augmentor = ImageDataGenerator(rescale=1.\/255,zoom_range=0.2,shear_range=0.2,horizontal_flip=True,validation_split=0.2)","135a680d":"train_generator = augmentor.flow_from_directory('..\/input\/cell_images\/cell_images\/',batch_size=64,\n                                                target_size = (96,96),class_mode = 'binary',subset = 'training')\ntest_generator = augmentor.flow_from_directory('..\/input\/cell_images\/cell_images\/',batch_size=64,target_size=(96,96),\n                                              class_mode='binary',subset='validation')","aaba8743":"model1 = Sequential()\nmodel1.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Dropout(0.2))\nmodel1.add(Convolution2D(32,(3,3),activation='relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Dropout(0.2))\nmodel1.add(Convolution2D(64,(3,3),activation='relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Dropout(0.2))\nmodel1.add(Flatten())\nmodel1.add(Dense(64,activation='relu'))\nmodel1.add(Dropout(0.2))\nmodel1.add(Dense(1,activation='sigmoid'))\nmodel1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","dae72062":"model1.summary()","e16fc995":"history_custom = model1.fit_generator(train_generator,steps_per_epoch=2000,\n                              epochs = 5,validation_data=test_generator,validation_steps=64)","f3e8adef":"values  = history_custom.history\nvalidation_loss = values['val_loss']\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\ntraining_loss = values['acc']\nepochs = range(5)","5a4459dc":"plt.plot(epochs,training_loss,label = 'Training Loss')\nplt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.title('Epochs vs Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","87d1b265":"plt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.title('Epochs vs Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","8e78f014":"model2 = Sequential()\nmodel2.add(Convolution2D(32,(5,5),activation='relu',input_shape = (96,96,3)))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(2,2))\nmodel2.add(Dropout(0.2))\nmodel2.add(Convolution2D(32,(5,5),activation='relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(2,2))\nmodel2.add(Dropout(0.2))\nmodel2.add(Convolution2D(64,(5,5),activation='relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(2,2))\nmodel2.add(Dropout(0.2))\nmodel2.add(Flatten())\nmodel2.add(Dense(64,activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(1,activation='sigmoid'))\nmodel2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","302c35e7":"model2.summary()","ae04a22d":"history_custom = model2.fit_generator(train_generator,steps_per_epoch=2000,\n                              epochs = 5,validation_data=test_generator,validation_steps=64)","1ea9629a":"values  = history_custom.history\nvalidation_loss = values['val_loss']\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\ntraining_loss = values['acc']\nepochs = range(5)","bdc3044b":"plt.plot(epochs,training_loss,label = 'Training Loss')\nplt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.title('Epochs vs Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","004f0a77":"plt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.title('Epochs vs Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","5b846f71":"model3 = Sequential()\nmodel3.add(Convolution2D(32,(5,5),activation='tanh',input_shape = (96,96,3)))\nmodel3.add(BatchNormalization())\nmodel3.add(MaxPooling2D(2,2))\nmodel3.add(Dropout(0.2))\nmodel3.add(Convolution2D(32,(5,5),activation='tanh'))\nmodel3.add(BatchNormalization())\nmodel3.add(MaxPooling2D(2,2))\nmodel3.add(Dropout(0.2))\nmodel3.add(Convolution2D(64,(5,5),activation='tanh'))\nmodel3.add(BatchNormalization())\nmodel3.add(MaxPooling2D(2,2))\nmodel3.add(Dropout(0.2))\nmodel3.add(Flatten())\nmodel3.add(Dense(64,activation='tanh'))\nmodel3.add(Dropout(0.2))\nmodel3.add(Dense(1,activation='sigmoid'))\nmodel3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","b4b4164c":"model3.summary()","023e2faa":"history_custom = model2.fit_generator(train_generator,steps_per_epoch=2000,\n                              epochs = 5,validation_data=test_generator,validation_steps=64)","e75c7ab2":"values  = history_custom.history\nvalidation_loss = values['val_loss']\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\ntraining_loss = values['acc']\nepochs = range(5)","fca8c97a":"plt.plot(epochs,training_loss,label = 'Training Loss')\nplt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.title('Epochs vs Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","26f33cd7":"plt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.title('Epochs vs Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","853574da":"vgg16 = VGG16(weights = 'imagenet',include_top = False,input_shape = (96,96,3))","eb4097c5":"vgg16.summary()","f797ca51":"for layers in vgg16.layers[:-4]:\n    layers.trainable = False","504ceb9a":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(1,activation = 'sigmoid'))","4e9d2b5e":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","7294c065":"callback = ModelCheckpoint('model_vgg16.h5',monitor='val_acc',mode = 'max',save_best_only=True)\ncalls = [callback]","8b4bba97":"history = model.fit_generator(train_generator,\n                              steps_per_epoch=2000,\n                              epochs=5,\n                              validation_data=test_generator,\n                              validation_steps=64,\n                              callbacks = calls)","24e31c05":"values  = history.history\nvalidation_loss = values['val_loss']\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\ntraining_loss = values['acc']\nepochs = range(5)","1761e5c7":"plt.plot(epochs,training_loss,label = 'Training Loss')\nplt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.title('Epochs vs Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","6c832786":"plt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.title('Epochs vs Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","c37ac33b":"**Freezing all the layers except the last four layers as we want to genralise the model on our custom dataset.**","b4637586":"**Using Data Augmentation to give more variety of Images to the model so that it can genralize better**","e00f2789":"**Using VGG16 Pretrained model as well to compare the model training**","2a3e4575":"**Here we can see that the images which are infected with Malaria are having a Red blood spot in the Cell Image whereas the Cells which are not infected are clear. This is one the model important feature we will try to capture using CNN as they are powerful in feature extraction especially from Images.**"}}