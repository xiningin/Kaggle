{"cell_type":{"d5ae937b":"code","ae793c49":"code","5e15b0b6":"code","b394a123":"code","9d225be7":"code","928e482c":"code","34c185ba":"code","49a4bf78":"code","bb8a9887":"code","57488035":"code","ec6a973a":"code","82423c53":"code","33c75746":"code","19a9f39f":"code","3e5df6f9":"code","b78bf028":"code","930344ec":"code","e68be4ce":"code","119d8bcf":"code","ff785df6":"code","e3adc4f9":"code","bcd18869":"code","6c670358":"code","009a09e7":"code","24e44812":"code","e85ff8d0":"code","de413ce8":"code","47311755":"code","ae16fef6":"code","0e6a3d46":"code","31718b53":"code","d6eac46f":"code","1568bbf3":"code","6e995f86":"code","44c1ae10":"code","faa7ec94":"code","2c2e2fb8":"code","8c40064b":"code","40ca597f":"code","e74ece4d":"code","11a1eabf":"markdown"},"source":{"d5ae937b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ae793c49":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","5e15b0b6":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ncombined_data = pd.concat([train_data, test_data])","b394a123":"# Let's check what we have\ncombined_data.head()","9d225be7":"# Let's see the number points, # of features and kinds of dtypes we have\nprint(\"# of data points: {}\".format(len(combined_data)))\n\nprint(\"# of features: {}\".format(len(combined_data.columns)-1))\nprint(\"Unique data types: {}\".format(combined_data.dtypes.unique()))\n","928e482c":"# Since we had python objects let's see the categorical features\ncombined_data.select_dtypes(include=['O']).columns.tolist()","34c185ba":"# Let's see if any features contain null\/NaN values\nprint(combined_data.isnull().any())","49a4bf78":"print(combined_data.isnull().any(axis=1).sum(), '\/', len(combined_data))","bb8a9887":"combined_data.info()","57488035":"print(train_data.Age.isnull().sum(), '\/', len(train_data))\nprint(test_data.Age.isnull().sum(), '\/', len(test_data))","ec6a973a":"# We have 38% of survival rate\n# Passengers are 29.6 years old on average\n# Average fare was 32$\ntrain_data.describe()","82423c53":"train_data.describe(include=['O'])","33c75746":"train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\ntrain_data['Embarked'].fillna(train_data['Embarked'].value_counts().index[0], inplace=True)\ntrain_data['Fare'].fillna(train_data['Fare'].value_counts().index[0], inplace=True)\n\ntest_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\ntest_data['Embarked'].fillna(train_data['Embarked'].value_counts().index[0], inplace=True)\ntest_data['Fare'].fillna(train_data['Fare'].value_counts().index[0], inplace=True)","19a9f39f":"train_data[[\"Embarked\", \"Survived\"]].groupby([\"Embarked\"]).mean()","3e5df6f9":"train_data[['Pclass', 'Survived']].groupby([\"Pclass\"]).mean()","b78bf028":"train_data[['Sex', 'Survived']].groupby([\"Sex\"]).mean()","930344ec":"train_data.drop(['Cabin', 'Name', 'Ticket'], axis=1, inplace=True)\ntest_data.drop(['Cabin', 'Name', 'Ticket'], axis=1, inplace=True)","e68be4ce":"train_data = pd.get_dummies(train_data, drop_first=True)\ntest_data = pd.get_dummies(test_data, drop_first=True)","119d8bcf":"train_data.head()","ff785df6":"\ntest_data.head()","e3adc4f9":"train_data.iloc[:,2:].columns.tolist()\ntest_data.columns.tolist()","bcd18869":"features = train_data.iloc[:,2:].columns.tolist()\ntarget = train_data.loc[:, 'Survived'].name","6c670358":"from scipy.stats import pearsonr\ncorrelations = {}\n\nfor feature in features:\n    data_temp = train_data[[feature,target]]\n    x1 = data_temp[feature].values\n    x2 = data_temp[target].values\n    key = feature + ' vs ' + target\n    correlations[key] = pearsonr(x1,x2)[0]","009a09e7":"correlations = pd.DataFrame(correlations, index = ['Value']).T","24e44812":"correlations.loc[correlations['Value'].abs().sort_values(ascending=False).index]","e85ff8d0":"train_data.plot.scatter(x='Fare', y='Pclass')","de413ce8":"train_data.plot.scatter(x='Fare', y='Survived')","47311755":"print(len(train_data[train_data['Fare'] > 400]), '\/', len(train_data))\nprint(len(train_data[(train_data['Fare'] > 80) & (train_data['Fare'] < 200)]), '\/', len(train_data))\nprint(len(train_data[(train_data['Fare'] > 0) & (train_data['Fare'] < 80)]), '\/', len(train_data))","ae16fef6":"train_data['Age'].plot.hist(stacked=True)","0e6a3d46":"train_data['Age'].plot.hist(by=train_data['Survived'])","31718b53":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(8, 512)\n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 2)\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\nmodel = Net()\nprint(model)","d6eac46f":"import torch.optim as optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(),lr=0.01)","1568bbf3":"X_train = train_data.iloc[:,2:].values\ny_train = train_data.loc[:, 'Survived'].values","6e995f86":"from torch.autograd import Variable\n\nbatch_size = 64\nn_epochs = 10000\nbatch_no = len(X_train) \/\/ batch_size\ntrain_loss = 0\ntrain_loss_min = np.Inf\nfor epoch in range(n_epochs):\n    for i in range(batch_no):\n        start = i*batch_size\n        end = start+batch_size\n        x_var = Variable(torch.FloatTensor(X_train[start:end]))\n        y_var = Variable(torch.tensor(y_train[start:end]))\n        \n        optimizer.zero_grad()\n        output = model(x_var)\n        loss = criterion(output,y_var)\n        loss.backward()\n        optimizer.step()\n        \n        values, labels = torch.max(output, 1)\n        num_right = np.sum(labels.data.numpy() == y_train[start:end])\n        train_loss += loss.item()*batch_size\n    \n    train_loss = train_loss \/ len(X_train)\n    if train_loss <= train_loss_min:\n        print(\"Validation loss decreased ({:6f} ===> {:6f}). Saving the model...\".format(train_loss_min,train_loss))\n        torch.save(model.state_dict(), \"model.pt\")\n        train_loss_min = train_loss\n    \n    if epoch % 100 == 0:\n        print(\"Epoch: {} \\tTrain Loss: {} \\tTrain Accuracy: {}\".format(epoch+1, train_loss,num_right \/ len(y_train[start:end]) ))","44c1ae10":"model.load_state_dict(torch.load('model.pt'))","faa7ec94":"X_test = test_data.iloc[:,1:].values\nX_test_var = Variable(torch.FloatTensor(X_test), requires_grad=False) \nwith torch.no_grad():\n    test_result = model(X_test_var)\nvalues, labels = torch.max(test_result, 1)\nsurvived = labels.data.numpy()","2c2e2fb8":"survived","8c40064b":"submission = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': survived})","40ca597f":"submission.head()","e74ece4d":"submission.to_csv('DNN_Submission', index=False)","11a1eabf":"# EDA"}}