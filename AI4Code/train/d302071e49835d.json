{"cell_type":{"afbb259f":"code","f3b9b8bc":"code","3aaa6c3f":"code","5ce97417":"code","16140c89":"code","b5c824e2":"code","e3dd360d":"code","5d2047f2":"code","89393689":"code","1049b2d8":"code","87cf403a":"code","76594205":"code","e07be513":"code","9d05f8b3":"code","41aa0e4f":"code","cc0e067d":"code","26c2cb99":"code","9bb9141c":"code","2e40eafa":"code","eb760c50":"code","948aa9e3":"code","886b48f7":"code","fed3655d":"code","9dfd7548":"code","070df526":"code","34b2b5a2":"code","a052ef75":"code","0eaab7c8":"code","88f2e76a":"code","6e9e917a":"code","7563a043":"code","7a98db2f":"code","ad6c9efe":"code","e741a1ca":"code","29a4db94":"code","c33cec80":"code","aa013869":"code","a853e8ab":"code","4e60bebd":"code","141e29bb":"code","76a62573":"code","dceaa178":"code","c674e81b":"code","8cf1b56e":"code","a0b96d18":"code","4a38a5ef":"code","e8bcd171":"code","32e09423":"code","373cbd24":"code","af2281a5":"code","c94f3313":"code","4d94073f":"code","63c61b9a":"code","924a7fcb":"markdown","baa5be7f":"markdown","af9aef76":"markdown","66a9002a":"markdown","7d1c7232":"markdown","0095a76b":"markdown","d34a3dbc":"markdown","327d2d0d":"markdown","b36578f6":"markdown","e017c53a":"markdown","b614a7da":"markdown","ccd3e000":"markdown","9a9558be":"markdown","6fe7179d":"markdown","ddfe009c":"markdown"},"source":{"afbb259f":"!pip show  -q\n!pip install -q efficientnet\n# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043e\u0431\u0432\u044f\u0437\u043a\u0443 \u043f\u043e\u0434 keras \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, albuminations\n!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor -q","f3b9b8bc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pickle\nimport csv\nimport os\nimport random\nfrom kaggle_datasets import KaggleDatasets\nimport zipfile\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom keras.callbacks import Callback\nfrom keras.regularizers import l2\nfrom keras import optimizers\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom keras.applications.xception import Xception\nfrom keras.layers import *\nimport efficientnet.tfkeras as efn\n\nimport tensorflow.keras as keras\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nfrom tensorflow.keras.preprocessing import image\nfrom keras.callbacks import LearningRateScheduler,EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n\n\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport csv\nimport sys\nimport os\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","3aaa6c3f":"print()","5ce97417":"# Checking the GPU.\n!nvidia-smi","16140c89":"# \u0412 \u0441\u0435\u0442\u0430\u043f \u0432\u044b\u043d\u043e\u0448\u0443 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438, \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0439 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c\nEPOCHS               = 11  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 64 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.2 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 20%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\n\n\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/sf-dl-car-classification\/'\nOUT_PATH = '.\/car'\nPATH = \"\/kaggle\/working\/car\"\nMODEL = \"efficient-b5\"\nMODEL_PATH = '\/kaggle\/working'","b5c824e2":"os.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\n\nimport tensorflow\ntensorflow.random.set_seed(RANDOM_SEED)\n","e3dd360d":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    print(data_zip)\n    with zipfile.ZipFile(f\"{DATA_PATH}{data_zip}\",\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","5d2047f2":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","89393689":"train_df.info()","1049b2d8":"train_df.Category.value_counts()","87cf403a":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(f'{OUT_PATH}\/train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","76594205":"image = PIL.Image.open(OUT_PATH+'\/train\/0\/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","e07be513":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations","9d05f8b3":"# \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0447\u0435\u043d\u044c \u0432\u0430\u0436\u043d\u0430 \u043a\u043e\u0433\u0434\u0430 \u0443 \u043d\u0430\u0441 \u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 (\u043a\u0430\u043a \u0432 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435)\n# \u041f\u043e\u0438\u0433\u0440\u0430\u0439\u0441\u044f \u0442\u0443\u0442 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 \u0447\u0442\u043e\u0431 \u043f\u043e\u043d\u044f\u0442\u044c \u0447\u0442\u043e \u043a \u0447\u0435\u043c\u0443. \n# \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0434\u043e\u043a\u0430 https:\/\/keras.io\/preprocessing\/image\/\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1.\/255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","41aa0e4f":"# \"\u0417\u0430\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0435\u043c\" \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 generator\n\ntrain_generator = train_datagen.flow_from_directory(\n    OUT_PATH+'\/train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    OUT_PATH+'\/train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe(\n    dataframe=sample_submission,\n    directory=OUT_PATH+'\/test_upload',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# \u043a\u0441\u0442\u0430\u0442\u0438, \u0442\u044b \u0437\u0430\u043c\u0435\u0442\u0438\u043b, \u0447\u0442\u043e \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0448\u0435\u043d\u0430 \u043c\u044b \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0434\u0440\u0443\u0433\u043e\u0439 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 flow_from_dataframe? \n# \u041a\u0430\u043a \u0442\u044b \u0434\u0443\u043c\u0430\u0435\u0448\u044c, \u043f\u043e\u0447\u0435\u043c\u0443?","cc0e067d":"def make_callbacks():\n    \n    callback_early_stopping = EarlyStopping(monitor='accuracy',patience=2, verbose=1)\n    callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5,min_lr=1e-10,patience=0,verbose=1)\n    callback_learing_rate = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x),\n    path_checkpoint = 'checkpoint.keras'\n    callback_checkpoint = ModelCheckpoint(f'{MODEL}_best.hdf5' , monitor = ['val_acc'] , verbose = 1  , mode = 'max') #ModelCheckpoint(filepath=path_checkpoint,monitor='val_loss',verbose=1,save_weights_only=True, save_best_only=True)\n\n    return [callback_checkpoint,\n            callback_learing_rate,\n                 callback_reduce_lr]\n\ncallbacks = make_callbacks()","26c2cb99":"# \u041a\u0441\u0442\u0430\u0442\u0438 \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0435\u0449\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0441\u0435\u0442\u0435\u0439...\n#base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\nbase_model = efn.EfficientNetB5(weights='imagenet', include_top=False, input_shape=input_shape)","9bb9141c":"base_model.summary()","2e40eafa":"# \u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0432\u0435\u0441\u0430 EfficientNetB5 \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \"\u0433\u043e\u043b\u043e\u0432\u0443\". \n# \u0414\u0435\u043b\u0430\u0435\u043c \u044d\u0442\u043e \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u0445\u043e\u0440\u043e\u0448\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0430 Imagenet \u043d\u0435 \u0437\u0430\u0442\u0438\u0440\u0430\u043b\u0438\u0441\u044c \u0432 \u0441\u0430\u043c\u043e\u043c \u043d\u0430\u0447\u0430\u043b\u0435 \u043d\u0430\u0448\u0435\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nbase_model.trainable = False","eb760c50":"# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043d\u043e\u0432\u0443\u044e \"\u0433\u043e\u043b\u043e\u0432\u0443\" (head)\n\nmodel=M.Sequential()\nmodel.add(base_model)\nmodel.add(L.GlobalAveragePooling2D(),) # \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0432\u0441\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 \u0435\u0434\u0438\u043d\u044b\u0439 \u0432\u0435\u043a\u0442\u043e\u0440 \n\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","948aa9e3":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","886b48f7":"# \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0441\u043b\u043e\u0435\u0432\nprint(len(model.layers))\nlen(model.trainable_variables)\n# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","fed3655d":"model.summary()","9dfd7548":"callbacks = make_callbacks()","070df526":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples \/\/ train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples \/\/ test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks\n)\n","34b2b5a2":"model.save(f'{MODEL}_last.hdf5')\nmodel.load_weights(f'{MODEL}_best.hdf5')","a052ef75":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","0eaab7c8":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","88f2e76a":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission_base_effnet_b5.csv', index=False)\nprint('Save submit')","6e9e917a":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","7563a043":"#base_model.trainable = True\n\n# Fine-tune from this layer onwards\n#fine_tune_at = len(base_model.layers)\/\/2\n\n# Freeze all the layers before the `fine_tune_at` layer\n#for layer in base_model.layers[:fine_tune_at]:\n#    layer.trainable =  False","7a98db2f":"#len(base_model.trainable_variables)","ad6c9efe":"# Check the trainable status of the individual layers\n#for layer in model.layers:\n#    print(layer, layer.trainable)","e741a1ca":"#EPOCHS               = 8  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 16 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU","29a4db94":"#model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","c33cec80":"#callbacks = make_callbacks()","aa013869":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n#history = model.fit(\n#        train_generator,\n#        steps_per_epoch = len(train_generator),\n#        validation_data = test_generator, \n#        validation_steps = len(test_generator),\n#        epochs = EPOCHS,\n#        callbacks = callbacks\n#)","a853e8ab":"#model.save(f'{MODEL}_last_finetuning.hdf5')\n#model.load_weights(f'{MODEL}_best.hdf5')","4e60bebd":"#scores = model.evaluate_generator(test_generator, verbose=1)\n#print(\"Accuracy: %.2f%%\" % (scores[1]*100))","141e29bb":"base_model.trainable = True\n\nLR=0.000001\nEPOCHS = 11\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])\ncallbacks = make_callbacks()\n# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples \/\/ train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples \/\/ test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks\n)","76a62573":"model.save(f'{MODEL}_no_frost.hdf5')\nmodel.load_weights(f'{MODEL}_best.hdf5') ","dceaa178":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","c674e81b":"test_sub_generator.samples","8cf1b56e":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","a0b96d18":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","4a38a5ef":"submission.head()","e8bcd171":"model.load_weights(f'{MODEL}_best.hdf5') ","32e09423":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=220, width=200),\n        albumentations.CenterCrop(height=200, width=220),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n      \ntest_datagen = ImageDataAugmentor( \n    rescale=1.\/255,\n    augment = AUGMENTATIONS,\n    validation_split=VAL_SPLIT,\n)","373cbd24":"test_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=OUT_PATH+'\/test_upload',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","af2281a5":"tta_steps = 10 # \u0431\u0435\u0440\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0438\u0437 10 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","c94f3313":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","4d94073f":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission_TTA.csv', index=False)\nprint('Save submit')","63c61b9a":"# Clean OUT_PATH\nimport shutil\nshutil.rmtree(OUT_PATH)","924a7fcb":"# Model","baa5be7f":"# Car classification\n![](http:\/\/img1.joyreactor.cc\/pics\/post\/\u0430\u0432\u0442\u043e\u043f\u0440\u043e\u043c-\u0432\u0430\u0437-\u043b\u0438\u043c\u0443\u0437\u0438\u043d-\u0432\u0430\u0442\u0435\u0440\u043c\u0430\u0440\u043a-351083.jpeg)\n\n### \u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f - \u0431\u0435\u0440\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u043d\u0430 imagenet \u0441\u0435\u0442\u044c Efficientnet-b5 \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u0434 \u043d\u0430\u0448\u0443 \u0437\u0430\u0434\u0430\u0447\u0443.\n\u041f\u043e \u0445\u043e\u0434\u0443 \u043a\u0435\u0440\u043d\u0435\u043b\u0430 \u044f \u0431\u0443\u0434\u0443 \u0434\u0430\u0432\u0430\u0442\u044c \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438 \u0438 \u043f\u043e\u0434\u0441\u043a\u0430\u0437\u043a\u0438 (\u0433\u0434\u0435 \u0447\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0434\u043a\u0440\u0443\u0442\u0438\u0442\u044c \u0438 \u0447\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0435\u0449\u0435 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c, \u0447\u0442\u043e\u0431 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0441\u043a\u043e\u0440).  \n\u041c\u043d\u043e\u0433\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u044b \u043d\u0435 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c ;)\n\n\u0423\u0434\u0430\u0447\u0438 \u0438 \u041f\u043e\u0435\u0445\u0430\u043b\u0438!","af9aef76":"# EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","66a9002a":"# Setup","7d1c7232":"### \u043f\u043e\u0434\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u0441\u0435\u0442\u044c efficient-b5","0095a76b":"# \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u044b \u0432\u0435\u0441\u043e\u0432 FineTuning","d34a3dbc":"### Data augmentation","327d2d0d":"### datagen","b36578f6":"# Test Time Augmentation\n\nhttps:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d\n\n\u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u043e\u0434\u043d\u043e\u0439 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0432 \u0440\u0430\u0437\u043d\u043e\u043c \u0432\u0438\u0434\u0435. \u0412\u0437\u044f\u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438\u0437 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435.","e017c53a":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e, \u0431\u0435\u0437 \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u043a\u0438","b614a7da":"## Fit\n* \u0414\u043b\u044f \u043f\u0440\u043e - \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0435\u0445\u043d\u0438\u043a\u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f Learning Rate\n#### \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440:\n* https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6\n* http:\/\/teleported.in\/posts\/cyclic-learning-rate\/","ccd3e000":"# Callbacks","9a9558be":"# Data","6fe7179d":"# \u0412\u044b\u0432\u043e\u0434\n* Debug \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f\n* transfer learning \u0438 fine-tuning\n* \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 LR, optimizer\n* \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043d\u044b \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 (\u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438, \u0431\u0430\u0442\u0447 \u0438 \u0442.\u0434.)\n* SOTA \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u0441\u0435\u0442\u0435\u0439 - EfficientNetB5\n* \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 Batch Normalization \u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0430 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u201c\u0433\u043e\u043b\u043e\u0432\u044b\u201d\n* \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u044b \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 callback Keras https:\/\/keras.io\/callbacks\/\n* TTA (Test Time Augmentation)","ddfe009c":"# Submission"}}