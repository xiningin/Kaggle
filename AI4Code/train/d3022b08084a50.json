{"cell_type":{"88bd0108":"code","d40fe21e":"code","d366d6e6":"code","3c080bbf":"code","10c0f06e":"code","df11e129":"code","86b22b74":"code","0cba18cb":"code","5e46ffbe":"code","0261c45a":"code","51d40b53":"code","88df730d":"code","bc73acc1":"code","d5834499":"markdown","aa1f9ebd":"markdown"},"source":{"88bd0108":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#import the libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Data Visualization \nimport seaborn as sns  #Python library for Vidualization\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d40fe21e":"#Import the dataset\n\ndataset = pd.read_csv('..\/input\/Mall_Customers.csv')\n\n#Exploratory Data Analysis\n#As this is unsupervised learning so Label (Output Column) is unknown\n\ndataset.head(10) #Printing first 10 rows of the dataset\n","d366d6e6":"#total rows and colums in the dataset\ndataset.shape","3c080bbf":"dataset.info() # there are no missing values as all the columns has 200 entries properly","10c0f06e":"#Missing values computation\ndataset.isnull().sum()","df11e129":"### Feature selection for the model\n#Considering only 2 features (Annual income and Spending Score) and no Label available\nX= dataset.iloc[:, [3,4]].values\n","86b22b74":"#Building the Model\n#KMeans Algorithm to decide the optimum cluster number , KMeans++ using Elbow Mmethod\n#to figure out K for KMeans, I will use ELBOW Method on KMEANS++ Calculation\nfrom sklearn.cluster import KMeans\nwcss=[]\n\n#we always assume the max number of cluster would be 10\n#you can judge the number of clusters by doing averaging\n###Static code to get max no of clusters\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\n    #inertia_ is the formula used to segregate the data points into clusters","0cba18cb":"#Visualizing the ELBOW method to get the optimal value of K \nplt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","5e46ffbe":"#If you zoom out this curve then you will see that last elbow comes at k=5\n#no matter what range we select ex- (1,21) also i will see the same behaviour but if we chose higher range it is little difficult to visualize the ELBOW\n#that is why we usually prefer range (1,11)\n##Finally we got that k=5\n\n#Model Build\nkmeansmodel = KMeans(n_clusters= 5, init='k-means++',max_iter = 300, n_init = 10, random_state=0)\n\ny_means= kmeansmodel.fit_predict(X)\n\n#For unsupervised learning we use \"fit_predict()\" wherein for supervised learning we use \"fit_tranform()\"\n#y_kmeans is the final model . Now how and where we will deploy this model in production is depends on what tool we are using.\n#This use case is very common and it is used in BFS industry(credit card) and retail for customer segmenattion.","0261c45a":"#Visualizing all the clusters \n\nplt.scatter(X[y_means == 0, 0], X[y_means == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_means == 1, 0], X[y_means == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_means == 2, 0], X[y_means == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_means == 3, 0], X[y_means == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_means == 4, 0], X[y_means == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n# I have changed centroids\ncenters = kmeansmodel.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=400, alpha=0.7, label = 'Centroids');\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()\n","51d40b53":"###Model Interpretation \n#Cluster 1 (Red Color) -> earning high but spending less\n#cluster 2 (Blue Colr) -> average in terms of earning and spending \n#cluster 3 (Green Color) -> earning high and also spending high [TARGET SET]\n#cluster 4 (cyan Color) -> earning less but spending more\n#Cluster 5 (magenta Color) -> Earning less , spending less\n\n\n######We can put Cluster 3 into some alerting system where email can be send to them on daily basis as these re easy to converse ######\n#wherein others we can set like once in a week or once in a month\n\n# Thank you and please upvote for the motivation","88df730d":"x= dataset.iloc[:, [2,4]].values\nwcss=[]\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","bc73acc1":"kmeansmodel = KMeans(n_clusters= 4, init='k-means++',max_iter = 300, n_init = 10, random_state=0)\n\ny_means= kmeansmodel.fit_predict(x)\n\nplt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(x[y_means == 2, 0], x[y_means == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(x[y_means == 3, 0], x[y_means == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n\n# I have changed centroids\ncenters = kmeansmodel.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=400, alpha=0.7, label = 'Centroids');\nplt.title('Clusters of customers')\nplt.xlabel(' Age ')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","d5834499":"Thanks to Vijay Choudhary and his kernel \n* [KMeans Clustering in Customer Segmentation](https:\/\/www.kaggle.com\/vjchoudhary7\/kmeans-clustering-in-customer-segmentation)\n","aa1f9ebd":"I have fixed the problem with cluster centers :\n*  changed plt.scatter(kmeans.clustercenters[:, 0], kmeans.clustercenteroids[:, 1], s = 300, c = 'yellow', label='Centroids')\n with this one:\n>      centers = kmeansmodel.cluster_centers_  \n>      plt.scatter(centers[:, 0], centers[:, 1], c='black', s=400, alpha=0.7, label = 'Centroids');\n* added clustering for age and spending score"}}