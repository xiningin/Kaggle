{"cell_type":{"8600d4ce":"code","b1a906ce":"code","08f242cf":"code","25d6a9fb":"code","ce710d95":"code","1cb7795b":"code","53963eb6":"code","71863054":"code","6b2a3a86":"code","6569eaf8":"code","4b9eb622":"code","b1133876":"code","6d417fa9":"code","a4c6bb68":"code","f6fd165c":"code","dfed2cf1":"code","bc4f2059":"code","b984a51c":"code","b8e27be3":"code","dfe6ac3f":"code","99638018":"code","2269779d":"code","6a7bf353":"code","8c0cde81":"code","4aab5343":"markdown","efa2bfb8":"markdown","8663d101":"markdown","1a1c834e":"markdown","4e01227a":"markdown","602b0f6c":"markdown","4f43d17f":"markdown","ef639c3b":"markdown","fd77c775":"markdown","0d7d279f":"markdown","97ccb08b":"markdown","05aa3e15":"markdown","6d73821c":"markdown","27b107d9":"markdown","0992fbee":"markdown","f448b509":"markdown","daa8c59e":"markdown","f13a798f":"markdown","925cf8f9":"markdown","10df803a":"markdown","8c4b0ee8":"markdown","bb1b3587":"markdown","6e5e11d2":"markdown","e2ee950e":"markdown","4259cc0d":"markdown","9eae0b55":"markdown","afb15dc2":"markdown"},"source":{"8600d4ce":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, roc_curve, confusion_matrix\nfrom mlxtend.classifier import StackingClassifier\nfrom xgboost import XGBClassifier\n\nwarnings.filterwarnings('ignore')\ndefaultcolor = '#66ccff'\npd.options.display.float_format = '{:.2f}'.format\nrc={'savefig.dpi': 75, 'figure.autolayout': False, 'figure.figsize': [12, 8], 'axes.labelsize': 18,\\\n   'axes.titlesize': 18, 'font.size': 18, 'lines.linewidth': 2.0, 'lines.markersize': 8, 'legend.fontsize': 16,\\\n   'xtick.labelsize': 16, 'ytick.labelsize': 16}\nsns.set(style='ticks',rc=rc)\nsns.set_palette('husl')","b1a906ce":"df = pd.read_csv('..\/input\/heart.csv')\ndf.head()","08f242cf":"df.describe()","25d6a9fb":"fig, ax = plt.subplots()\nsns.countplot(df.target, ax=ax)\nfor i,p in enumerate(ax.patches):\n    ax.annotate('{:.2f}%'.format(df['target'].value_counts().apply(lambda x: 100*x\/df['target'].value_counts().sum())[i]), (p.get_x()+0.32, p.get_height()+1)).set_fontsize(15)\nax.set_ylabel(\"\")\nax.set_xlabel(\"\")\nax.set_title(\"Target distribution\");","ce710d95":"fig, ax = plt.subplots(figsize=[15,15])\ndf.hist(ax=ax, bins=30, color='b');","1cb7795b":"fig, ax = plt.subplots(figsize=[20,15])\nsns.heatmap(df.corr(), ax=ax, cmap='Blues', annot=True);\nax.set_title(\"Pearson correlation coefficients\", size=20);","53963eb6":"fig, ax = plt.subplots()\ndf.groupby(['age', 'target']).size().reset_index().pivot(index='age', columns='target', values=0).fillna(0).plot.bar(stacked=True, ax=ax)\nax.set_title(\"Distribution of the target according to the age\")\nax.set_xlabel(\"\");","71863054":"fig, ax = plt.subplots()\nsns.scatterplot(x='age', y='thalach', data=df[df.target==1], color='b', ax=ax)\nsns.scatterplot(x='age', y='thalach', data=df[df.target==0], color='r', ax=ax)\nax.legend(['1', '0']);","6b2a3a86":"sns.heatmap(df.groupby(['exang', 'cp']).size().reset_index().pivot(columns='exang', index='cp', values=0), cmap='Blues', fmt='g', annot=True);","6569eaf8":"fig, ax = plt.subplots()\nsns.boxplot(x='slope', y='thalach', data=df, ax=ax);\nax.set_title(\"Thalach distribution by slope values\");","4b9eb622":"sns.violinplot(x='cp', y='thalach', data=df);","b1133876":"sns.boxplot(x='slope', y='oldpeak', data=df);","6d417fa9":"X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df.target, test_size=0.2, random_state=56)","a4c6bb68":"models = {\n    'CART': DecisionTreeClassifier(),\n    'SVC': SVC(probability=True),\n    'XGB': XGBClassifier(n_jobs=-1),\n    'GNB': GaussianNB(),\n    'LDA': LinearDiscriminantAnalysis(),\n    'LR': LogisticRegression(),\n    'KNN': KNeighborsClassifier()\n}","f6fd165c":"def cv_report(models, X, y):\n    results = []\n    for name in models.keys():\n        model = models[name]\n        scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n        print(\"Accuracy: %.3f (+\/- %.3f) [%s]\" %(scores.mean(), scores.std(), name))","dfed2cf1":"cv_report(models, X_train, y_train)","bc4f2059":"xgb_params = {\n    'max_depth': [2,3,4],\n    'n_estimators': [50, 100, 400, 1000],\n    'learning_rate': [0.1, 0.01, 0.05]\n}\n\nxg_grid = GridSearchCV(models['XGB'], xgb_params, cv=5)\nmodels['XGB_Grid'] = xg_grid","b984a51c":"cv_report(models, X_train, y_train)","b8e27be3":"lr_params = [{\n                'penalty': ['l2'],\n                'C': (0.1, 0.5, 1.0, 1.5, 2.0),\n                'solver': ['newton-cg', 'lbfgs', 'sag'],\n                'max_iter': [50, 100, 200, 500]\n            },\n            {\n                'penalty': ['l1', 'l2'],\n                'C': (0.1, 0.5, 1.0, 1.5, 2.0),\n                'solver': ['liblinear', 'saga']\n            }\n]\n\nlr_grid = GridSearchCV(models['LR'], lr_params, cv=5)\nmodels['LR_Grid'] = lr_grid","dfe6ac3f":"cv_report(models, X_train, y_train)","99638018":"models['LR_Grid'].fit(X_train, y_train)","2269779d":"predictions = models['LR_Grid'].predict(X_test)","6a7bf353":"print(\"Accuracy of the model: {:.2f}%\".format(100*accuracy_score(predictions, y_test)))","8c0cde81":"fig, ax = plt.subplots()\nax.set_title(\"Confusion Matrix\")\nsns.heatmap(confusion_matrix(y_test, predictions), annot=True, cmap='Blues');","4aab5343":"### Age distribution","efa2bfb8":"#### Some useful functions","8663d101":"Let's try to get quick insights about the data","1a1c834e":"We can see we have a good separtion here between 1 and 0, which is good for our model.","4e01227a":"## Imports and configurations","602b0f6c":"We have a farely well distrubited dataset so we won't have to worry to much with the model \"remebering\" the train targets.","4f43d17f":"First thing that can be noticed is that for ages between 40 and 50 the proportion of target=1 is pretty high comparing to pepole with ages ranging from 57 to 67. ","ef639c3b":"Here is a figure representing the ST segment.","fd77c775":"#### Hyperparameters tunneling using gridsearch","0d7d279f":"# Heart Disease UCI","97ccb08b":"As we can see the baseline models already had a good performance, let's try to improve them.","05aa3e15":"### Thalach and cp","6d73821c":"Looks like we don't have a big difference between 0 and 1 but when slope=2 the thalach distribution get's narrower and higher.","27b107d9":"### Slope and oldpeak","0992fbee":"Let's use the tunneled LR for predicting in the test set","f448b509":"## Baseline models","daa8c59e":"#### Let's first split into training and testing and create a dictionary with the most common models","f13a798f":"We can see a clear correlation between these two features, why is that?\n\nAfter searching around in the internet we can found out that both of them are metrics to evaluate the ST segment and having an low oldpeak means you probably will have a high slope.\n\nThere is a lot of bilbiography on the internet about those features. ","925cf8f9":"<img src='https:\/\/www.teachingmedicine.com\/media\/lessons\/images\/Screen%20Shot%202014-06-01%20at%204_12_09%20PM.png'><\/img>\n\n<p>Extracted from <a href='https:\/\/www.teachingmedicine.com\/Lesson.aspx?l_id=139'>teachingmedicine<\/a><\/p>","10df803a":"##### XGBoost","8c4b0ee8":"## Overall look at the data trying to find any quick insight","bb1b3587":"##### Logistic Regression","6e5e11d2":"This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The \"goal\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.\n\nCan we find a corrleation between the features and the presence of heart dieases?","e2ee950e":"## Features descriptions\n\nAttribute Information: \n- 1. age: age\n- 2. sex: sex\n- 3. cp: chest pain type (4 values) \n- 4. trespbps: resting blood pressure \n- 5. chol: serum cholestoral in mg\/dl \n- 6. fbs: fasting blood sugar > 120 mg\/dl\n- 7. restecg: resting electrocardiographic results (values 0,1,2)\n- 8. thalach: maximum heart rate achieved \n- 9. exang: exercise induced angina \n- 10. oldpeak: ST depression induced by exercise relative to rest \n- 11. slope: the slope of the peak exercise ST segment \n- 12. ca: number of major vessels (0-3) colored by flourosopy \n- 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect","4259cc0d":"### Slope and thalach correlation","9eae0b55":"### Target and cp","afb15dc2":"## Exploratory data analysis"}}