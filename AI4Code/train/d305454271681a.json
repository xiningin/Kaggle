{"cell_type":{"c15a5f09":"code","82570378":"code","937a23f9":"code","f4c59683":"code","58433126":"code","852f0464":"code","ae738e9d":"code","8da6f3b0":"code","9803f3ff":"code","b5085617":"code","d229a5f2":"code","b01d0ff6":"code","fac39259":"code","401d868e":"code","e2d21f80":"code","7ecffc48":"code","e4f01aaf":"code","33ffd758":"code","25052e93":"code","f2bc4bb0":"code","edfa8de1":"code","4f189d24":"code","2a4c41ec":"code","310223cb":"code","6e43e5b0":"code","a05fc3a1":"code","b7e3f839":"code","768650b9":"code","5639bef2":"code","a5bb338c":"code","383b22a4":"code","365c3ec8":"code","a6dd9d9e":"code","11f8020c":"code","522225d9":"markdown","98a695e2":"markdown","869a3537":"markdown","f291c996":"markdown","e1164c2b":"markdown","6225643d":"markdown","f3c2db06":"markdown"},"source":{"c15a5f09":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm.notebook import tqdm\nimport gc\nimport matplotlib.pyplot as plt","82570378":"from bayes_opt import BayesianOptimization\nimport warnings","937a23f9":"import catboost\n\ncatboost.__version__","f4c59683":"# \/kaggle\/input\/ef-msu-2021-autumn-inclass\/sample_submission.csv\n# \/kaggle\/input\/ef-msu-2021-autumn-inclass\/train.csv\n# \/kaggle\/input\/ef-msu-2021-autumn-inclass\/test.csv","58433126":"train = pd.read_csv(\"\/kaggle\/input\/ef-msu-2021-autumn-inclass\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/ef-msu-2021-autumn-inclass\/test.csv\")\n\ntrain_y = train['many_orders']\n\ntest_ids = test[\"id\"]","852f0464":"%%time\n\nfor col in ['center_type', 'category', 'cuisine']:\n    le = LabelEncoder()\n    train[col] = le.fit_transform(train[col])\n    test[col] = le.transform(test[col])","ae738e9d":"def int_params(params):\n    for p in params:\n        if p in ['num_leaves', 'max_depth', 'n_estimators', 'min_child_samples', 'random_state']:\n            params[p] = int(np.round(params[p], decimals = 0))\n    return params\n\n\n\ndef get_best_params(df_train_, seed_cv_, seed_bo_, target_name='many_orders', init_points=5, n_iter=5):\n\n    def auc_evaluate(**params):\n        warnings.simplefilter('ignore')\n    \n        params = int_params(params)\n\n        clf = CatBoostClassifier(**params, n_estimators=10000, thread_count=-1, random_state=seed_cv_, eval_metric=\"AUC\",\n                                 cat_features=[\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"])\n\n        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed_cv_)\n\n        test_pred_proba = np.zeros(df_train_.shape[0])\n\n        feats = df_train_.drop([target_name], axis=1).columns\n\n        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df_train_[feats], df_train_[target_name])):\n\n            train_x, train_y = df_train_[feats].iloc[train_idx], df_train_[target_name].iloc[train_idx]\n            valid_x, valid_y = df_train_[feats].iloc[valid_idx], df_train_[target_name].iloc[valid_idx]\n\n            clf.fit(train_x, train_y, \n                    eval_set=(valid_x, valid_y),\n                    verbose=False, early_stopping_rounds=50)\n\n            test_pred_proba[valid_idx] = clf.predict_proba(valid_x)[:,1]        \n\n        metric_test = roc_auc_score(df_train_[target_name], test_pred_proba)\n\n        return metric_test\n\n    params = {\n          'learning_rate': (.001, .5), \n          'colsample_bylevel': (0.3, 1),\n          'subsample': (0.3, 1), \n          'max_depth': (3, 15), \n          'reg_lambda': (.0, 1.), \n          'min_child_samples': (10, 1000),\n    }\n    \n    bo = BayesianOptimization(auc_evaluate, params, random_state=seed_bo_)\n    bo.maximize(init_points=init_points, n_iter=n_iter)\n\n    return bo.max","8da6f3b0":"# %%time\n\n# # init_points \u0438 n_iter \u0441\u0442\u043e\u0438\u0442 \u0434\u0435\u043b\u0430\u0442\u044c \u043f\u043e\u0431\u043e\u043b\u044c\u0448\u0435, \u0437\u0434\u0435\u0441\u044c \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0438\u0435 \u0447\u0438\u0441\u043b\u0430 \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u0434\u043e\u043b\u0433\u043e \u0441\u0447\u0438\u0442\u0430\u043b\u043e\u0441\u044c\n# bo = get_best_params(df_train_=train.drop(['id', 'rating'], axis=1), seed_cv_=42, seed_bo_=42, init_points=5, n_iter=2) ","9803f3ff":"# bo","b5085617":"train[\"many_orders\"].value_counts()","d229a5f2":"def cv_and_predict(\n    df_train,\n    df_test,\n    train_y,\n    model_kf,\n    n_splits=5,\n    random_state=42,\n    verbose=True,\n    model_type=None,\n):\n    \"\"\"\n    \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0438 \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u0430 \u043d\u0430 \u0442\u0435\u0441\u0442\n\n    :param df_train: \u0422\u0440\u0435\u0439\u043d-\u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\n    :param df_test: \u0422\u0435\u0441\u0442-\u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\n    :param train_y: \u041e\u0442\u0432\u0435\u0442\u044b \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\n    :param model_kf: \u041c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043c\u044b \u0445\u043e\u0442\u0438\u043c \u0443\u0447\u0438\u0442\u044c\n    :param n_splits: \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043f\u043b\u0438\u0442\u043e\u0432 \u0434\u043b\u044f KFold\n    :param random_state: random_state \u0434\u043b\u044f KFold\n    :param verbose: \u0414\u0435\u043b\u0430\u0435\u043c \u043b\u0438 print'\u044b\n    :param model_type: \u0422\u0438\u043f \u043c\u043e\u0434\u0435\u043b\u0438\n\n    :return: pred_test: \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442; oof_df: OOF \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f; metric_OOF: \u043c\u0435\u0442\u0440\u0438\u043a\u0430 OOF \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435\n    \"\"\"\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n    # \u0412 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0435 oof_df \u0431\u0443\u0434\u0443\u0442 \u0445\u0440\u0430\u043d\u0438\u0442\u044c\u0441\u044f \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0439 \u0442\u0430\u0440\u0433\u0435\u0442 \u0442\u0440\u0435\u0439\u043d\u0430 \u0438 OOF \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0440\u0435\u0439\u043d.\n    # \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c prediction_oof \u043d\u0443\u043b\u044f\u043c\u0438 \u0438 \u0431\u0443\u0434\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0432 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n    oof_df = pd.DataFrame()\n    oof_df[\"target\"] = train_y\n    oof_df[\"prediction_oof\"] = np.zeros(oof_df.shape[0])\n\n    # \u0421\u043f\u0438\u0441\u043e\u043a \u0441 \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\u0438 \u043f\u043e \u0444\u043e\u043b\u0434\u0430\u043c\n    metrics = list()\n\n    # \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442. \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043d\u0443\u043b\u044f\u043c\u0438 \u0438 \u0431\u0443\u0434\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0432 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438.\n    # \u041d\u0430\u0448\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0431\u0443\u0434\u0443\u0442 \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u0435\u043c n_splits \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n    pred_test = np.zeros(len(df_test))\n\n    # \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f\n    for i, (train_index, valid_index) in enumerate(kf.split(df_train, train_y)):\n        if verbose:\n            print(f\"fold_{i} started\")\n\n        X_train = df_train.loc[train_index]\n        y_train = train_y.loc[train_index].values\n\n        X_valid = df_train.loc[valid_index]\n        y_valid = train_y.loc[valid_index].values\n\n        if model_type == \"cbs\":\n            model_kf.fit(\n                X_train,\n                y_train,\n                eval_set=(X_valid, y_valid),\n                plot=True,\n            )\n            \n        elif model_type == 'lgbm':\n            model_kf.fit(\n                X_train, \n                y_train, \n                eval_set=[(X_valid, y_valid)],\n                eval_metric='auc',                          \n                verbose=25, \n                early_stopping_rounds=50\n            )\n            \n        elif model_type == 'xgb':         \n            model_kf.fit(\n                X_train, \n                y_train, \n                eval_set=[(X_valid, y_valid)],\n                eval_metric='auc',                          \n                verbose=25, \n                early_stopping_rounds=50\n            )\n\n        else:\n            model_kf.fit(X_train, y_train)\n\n        prediction = model_kf.predict_proba(df_test)[:, 1]\n        pred_test += prediction \/ n_splits\n\n        prediction_kf = model_kf.predict_proba(X_valid)[:, 1]\n        oof_df.loc[valid_index, \"prediction_oof\"] = prediction_kf\n\n        cur_metric = roc_auc_score(y_valid, prediction_kf)\n        metrics.append(cur_metric)\n\n        if verbose:\n            print(f\"metric_{i}: {cur_metric}\")\n            print()\n            print(\"_\" * 90)\n            print()\n\n    metric_OOF = roc_auc_score(train_y, oof_df[\"prediction_oof\"])\n\n    if verbose:\n        print(f\"metric_OOF: {metric_OOF}\")\n        print(f\"metric_AVG: {np.mean(metrics)}\")\n        print(f\"metric_std: {np.std(metrics)}\")\n        print()\n        print(\"*\" * 90)\n        print()\n\n    return pred_test, oof_df, metric_OOF","b01d0ff6":"model_cbs = CatBoostClassifier(\n    learning_rate=0.9,\n    random_state=1337,\n    thread_count=-1,\n    iterations=100,\n    cat_features=[\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"],\n    verbose=25,\n    eval_metric=\"AUC\",\n    od_type=\"Iter\",\n    od_wait=50,\n    use_best_model=True,\n)","fac39259":"%%time\n\npred_test, oof_df, metric_OOF = cv_and_predict(train.drop(['many_orders', 'id', 'rating'], axis=1),\n                                               test.drop(['id', 'rating'], axis=1), \n                                               train_y=train['many_orders'], model_kf=model_cbs, model_type='cbs')","401d868e":"train.head()","e2d21f80":"%%time\n\nfor col in [\n    'center_id', 'meal_id', 'checkout_price', 'base_price', 'emailer_for_promotion', 'homepage_featured', \n    'city_code', 'region_code', 'center_type', 'op_area', 'category', 'cuisine'\n]:\n    temp = train[col].value_counts().to_dict()\n    train[col + '_freq_counts'] = train[col].astype(float).map(temp) \/ len(train)\n    test[col + '_freq_counts'] = test[col].astype(float).map(temp) \/ len(train)","7ecffc48":"train.head()","e4f01aaf":"model_cbs = CatBoostClassifier(\n    learning_rate=0.9,\n    random_state=1337,\n    thread_count=-1,\n    iterations=100,\n    cat_features=[\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"],\n    verbose=25,\n    eval_metric=\"AUC\",\n    od_type=\"Iter\",\n    od_wait=50,\n    use_best_model=True,\n)","33ffd758":"%%time\n\npred_test, oof_df, metric_OOF = cv_and_predict(train.drop(['many_orders', 'id', 'rating'], axis=1),\n                                               test.drop(['id', 'rating'], axis=1), \n                                               train_y=train['many_orders'], model_kf=model_cbs, model_type='cbs')","25052e93":"LOWER_BOUND = 0.001\nHIGHER_BOUND = 0.999","f2bc4bb0":"df_test_preds = test.copy()\ndf_test_preds['preds'] = pred_test\ndf_test_preds = df_test_preds[(df_test_preds['preds'] <= LOWER_BOUND) | (df_test_preds['preds'] >= HIGHER_BOUND)]\ndf_test_preds['many_orders'] = (df_test_preds['preds'] > 0.5) * 1\ndf_test_preds_y = df_test_preds['many_orders'].tolist()\ndf_test_preds = df_test_preds.drop(['preds', 'many_orders', 'id', 'rating'], axis=1).reset_index(drop=True)\n\ndf_test_preds","edfa8de1":"def cv_and_predict_w_pseudolabeling(\n    df_train,\n    df_test,\n    train_y,\n    model_kf,\n    n_splits=5,\n    random_state=42,\n    verbose=True,\n    model_type=None,\n    pseudolabeled_df=None,\n    pseudolabeled_df_y=None\n):\n    \"\"\"\n    \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0438 \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u0430 \u043d\u0430 \u0442\u0435\u0441\u0442\n\n    :param df_train: \u0422\u0440\u0435\u0439\u043d-\u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\n    :param df_test: \u0422\u0435\u0441\u0442-\u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\n    :param train_y: \u041e\u0442\u0432\u0435\u0442\u044b \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\n    :param model_kf: \u041c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043c\u044b \u0445\u043e\u0442\u0438\u043c \u0443\u0447\u0438\u0442\u044c\n    :param n_splits: \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043f\u043b\u0438\u0442\u043e\u0432 \u0434\u043b\u044f KFold\n    :param random_state: random_state \u0434\u043b\u044f KFold\n    :param verbose: \u0414\u0435\u043b\u0430\u0435\u043c \u043b\u0438 print'\u044b\n    :param model_type: \u0422\u0438\u043f \u043c\u043e\u0434\u0435\u043b\u0438\n    :param pseudolabeled_df: \u0414\u0430\u0442\u0430\u0441\u0435\u0442 \u0441 \u043f\u0441\u0435\u0432\u0434\u043e\u043b\u0435\u0439\u0431\u043b\u0430\u043c\u0438\n    :param pseudolabeled_df_y: \u041f\u0441\u0435\u0432\u0434\u043e\u043b\u0435\u0439\u0431\u043b\u044b\n\n    :return: pred_test: \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442; oof_df: OOF \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f; metric_OOF: \u043c\u0435\u0442\u0440\u0438\u043a\u0430 OOF \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435\n    \"\"\"\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n    # \u0412 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0435 oof_df \u0431\u0443\u0434\u0443\u0442 \u0445\u0440\u0430\u043d\u0438\u0442\u044c\u0441\u044f \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0439 \u0442\u0430\u0440\u0433\u0435\u0442 \u0442\u0440\u0435\u0439\u043d\u0430 \u0438 OOF \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0440\u0435\u0439\u043d.\n    # \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c prediction_oof \u043d\u0443\u043b\u044f\u043c\u0438 \u0438 \u0431\u0443\u0434\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0432 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n    oof_df = pd.DataFrame()\n    oof_df[\"target\"] = train_y\n    oof_df[\"prediction_oof\"] = np.zeros(oof_df.shape[0])\n\n    # \u0421\u043f\u0438\u0441\u043e\u043a \u0441 \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\u0438 \u043f\u043e \u0444\u043e\u043b\u0434\u0430\u043c\n    metrics = list()\n\n    # \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442. \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043d\u0443\u043b\u044f\u043c\u0438 \u0438 \u0431\u0443\u0434\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0432 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438.\n    # \u041d\u0430\u0448\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0431\u0443\u0434\u0443\u0442 \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u0435\u043c n_splits \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n    pred_test = np.zeros(len(df_test))\n\n    # \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f\n    for i, (train_index, valid_index) in enumerate(kf.split(df_train, train_y)):\n        if verbose:\n            print(f\"fold_{i} started\")\n\n        X_train = df_train.loc[train_index]\n        y_train = train_y.loc[train_index].to_list()\n        \n        if pseudolabeled_df is not None and pseudolabeled_df_y is not None:\n            X_train = pd.concat([X_train, pseudolabeled_df]).reset_index(drop=True)\n            y_train.extend(pseudolabeled_df_y)\n\n        X_valid = df_train.loc[valid_index]\n        y_valid = train_y.loc[valid_index].to_list()\n\n        if model_type == \"cbs\":\n            model_kf.fit(\n                X_train,\n                y_train,\n                eval_set=(X_valid, y_valid),\n                plot=True,\n            )\n        else:\n            model_kf.fit(X_train, y_train)\n\n        prediction = model_kf.predict_proba(df_test)[:, 1]\n        pred_test += prediction \/ n_splits\n\n        prediction_kf = model_kf.predict_proba(X_valid)[:, 1]\n        oof_df.loc[valid_index, \"prediction_oof\"] = prediction_kf\n\n        cur_metric = roc_auc_score(y_valid, prediction_kf)\n        metrics.append(cur_metric)\n\n        if verbose:\n            print(f\"metric_{i}: {cur_metric}\")\n            print()\n            print(\"_\" * 90)\n            print()\n\n    metric_OOF = roc_auc_score(train_y, oof_df[\"prediction_oof\"])\n\n    if verbose:\n        print(f\"metric_OOF: {metric_OOF}\")\n        print(f\"metric_AVG: {np.mean(metrics)}\")\n        print(f\"metric_std: {np.std(metrics)}\")\n        print()\n        print(\"*\" * 90)\n        print()\n\n    return pred_test, oof_df, metric_OOF","4f189d24":"model_cbs = CatBoostClassifier(\n    learning_rate=0.9,\n    random_state=1337,\n    thread_count=-1,\n    iterations=100,\n    cat_features=[\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"],\n    verbose=25,\n    eval_metric=\"AUC\",\n    od_type=\"Iter\",\n    od_wait=50,\n    use_best_model=True,\n)","2a4c41ec":"%%time\n\npred_test, oof_df, metric_OOF = cv_and_predict_w_pseudolabeling(train.drop(['many_orders', 'id', 'rating'], axis=1),\n                                               test.drop(['id', 'rating'], axis=1), \n                                               train_y=train['many_orders'], model_kf=model_cbs, model_type='cbs',\n                                               pseudolabeled_df=df_test_preds, pseudolabeled_df_y=df_test_preds_y)","310223cb":"params_lgbm = {\n    'boosting_type': 'goss',\n    'learning_rate': 0.3,\n    'n_estimators': 100,                \n    'metric': 'auc',\n    'seed': 1337,\n    'max_depth': -1,\n    'verbose': 0,\n    'n_jobs': -1,\n    'silent': True,\n\n    'importance_type': 'gain',\n}\n\nparams_cbs = {\n    'learning_rate': 0.9,\n    'random_state': 1337,\n    'thread_count': -1,\n    'iterations': 100,\n    'cat_features': [\"city_code\", \"region_code\", \"center_type\", \"category\", \"cuisine\"],\n    'verbose': 25,\n    'eval_metric': \"AUC\",\n    'od_type': \"Iter\",\n    'od_wait': 50,\n    'use_best_model': True\n}\n\nparams_xgb = {\n    'learning_rate': 0.9,\n    'random_state': 1337,\n    'n_jobs': -1,\n    'iterations': 100,\n    'verbose': 25,\n    'eval_metric': \"auc\",\n}\n\nmodel_lgbm = LGBMClassifier(**params_lgbm)\nmodel_cbs = CatBoostClassifier(**params_cbs)\nmodel_xgb = XGBClassifier(**params_xgb)","6e43e5b0":"%%time\n\npred_test_xgb, oof_df_xgb, metric_OOF_xgb = cv_and_predict(train.drop(['many_orders', 'id', 'rating'], axis=1),\n                                               test.drop(['id', 'rating'], axis=1),\n                                               train_y=train['many_orders'], model_kf=model_xgb, model_type='xgb')","a05fc3a1":"%%time\n\npred_test_cbs, oof_df_cbs, metric_OOF_cbs = cv_and_predict(train.drop(['many_orders', 'id', 'rating'], axis=1),\n                                               test.drop(['id', 'rating'], axis=1), \n                                               train_y=train['many_orders'], model_kf=model_cbs, model_type='cbs')","b7e3f839":"%%time\n\npred_test_lgbm, oof_df_lgbm, metric_OOF_lgbm = cv_and_predict(train.drop(['many_orders', 'id', 'rating'], axis=1),\n                                               test.drop(['id', 'rating'], axis=1), \n                                               train_y=train['many_orders'], model_kf=model_lgbm, model_type='lgbm')","768650b9":"test_preds = pd.DataFrame()\ntest_preds['lgbm'] = pred_test_lgbm\ntest_preds['cbs'] = pred_test_cbs\ntest_preds['xgb'] = pred_test_xgb\n\noofs_algos = oof_df_lgbm.copy()\noofs_algos = oofs_algos.rename({'prediction_oof': 'lgbm'}, axis=1)\noofs_algos['cbs'] = oof_df_cbs['prediction_oof']\noofs_algos['xgb'] = oof_df_xgb['prediction_oof']\noofs_algos","5639bef2":"oofs_algos.corr(method='spearman')","a5bb338c":"oofs_algos_mean = oofs_algos[['lgbm', 'cbs', 'xgb']].mean(axis=1)\noofs_algos_mean","383b22a4":"roc_auc_score(train_y, oofs_algos_mean)","365c3ec8":"from sklearn.linear_model import LogisticRegression\nmodel_lr = LogisticRegression(random_state=1337, n_jobs=-1)","a6dd9d9e":"%%time\n\npred_test_stack, oof_df_stack, metric_OOF_stack = cv_and_predict(oofs_algos[['lgbm', 'cbs', 'xgb']],\n                                               test_preds, \n                                               train_y=train['many_orders'], model_kf=model_lr, model_type=None)","11f8020c":"submission = pd.DataFrame()\nsubmission[\"id\"] = test_ids\nsubmission[\"many_orders\"] = pred_test_stack\nsubmission.to_csv(\"submission.csv\", index=False)","522225d9":"# Feature Engineering\n\nmake your data better suited to the problem at hand","98a695e2":"https:\/\/www.kaggle.com\/learn\/feature-engineering\n\nUnderstand the features. Refer to your dataset's data documentation, if available.\nResearch the problem domain to acquire domain knowledge. If your problem is predicting house prices, do some research on real-estate for instance. Wikipedia can be a good starting point, but books and journal articles will often have the best information.\nStudy previous work. Solution write-ups from past Kaggle competitions are a great resource.\nUse data visualization. Visualization can reveal pathologies in the distribution of a feature or complicated relationships that could be simplified. Be sure to visualize your dataset as you work through the feature engineering process.","869a3537":"## Counts","f291c996":"# BayesOpt\n\nhttps:\/\/github.com\/fmfn\/BayesianOptimization","e1164c2b":"# Modeling","6225643d":"# Ensembling","f3c2db06":"## Pseudo-Labeling"}}