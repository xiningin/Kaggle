{"cell_type":{"1c187269":"code","af496208":"code","2d2d6b77":"code","cfe0daa5":"code","903765c4":"code","94b41af5":"code","c1336fea":"code","a30318b3":"code","a9d41ea9":"code","a9338093":"code","e7ced1f6":"code","2b093fba":"code","d6b3906d":"code","c1971658":"code","ff52c8a6":"code","d790f8e0":"code","150609ab":"code","d8a09bf9":"code","7d031b74":"code","8b3cbc04":"code","43d5226e":"code","f6426457":"code","e260ab26":"code","52ea8eb1":"code","3eed30d5":"code","3ca11740":"code","5284d4a5":"code","f5a7af45":"code","d633edf6":"code","496978af":"code","a3ceb18a":"code","b0476ac3":"code","3c271f99":"code","09b09ffd":"code","e82fc23b":"code","5f1f8f2a":"code","47b557ab":"code","150bf026":"code","23117fd3":"code","fa61b577":"code","018e37ed":"markdown","31294e8e":"markdown","2c312b3c":"markdown","54a94cd2":"markdown","c18a8bad":"markdown","1ea4673f":"markdown","45ccfcc3":"markdown","ea2073a7":"markdown","6bbc1b56":"markdown","1e396eeb":"markdown","183dbb7f":"markdown","b9ee5a5f":"markdown","39eb2cc6":"markdown","b1838365":"markdown","2c8a0600":"markdown","79894e66":"markdown","c462c50a":"markdown","4cf5f048":"markdown","45b5d9ac":"markdown","4d8fe7f8":"markdown","2396670d":"markdown","0cfd91fd":"markdown","b8c1346a":"markdown","5690c0b3":"markdown","776f0e11":"markdown"},"source":{"1c187269":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","af496208":"# Read the data into a pandas dataframe\ndf = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')\n# Store a copy of the original dataframe\ndf_with_predictions = df.copy()","2d2d6b77":"# Eyeball the data\nprint(df.info())\ndf.head()","cfe0daa5":"# Remove whitespaces in the headers\ndf.rename(columns=lambda x: x.strip(), inplace=True) \n\n# Drop the column labelled 'Serial No.'. It does not affect our analysis because it is a nominal value.\ndf.drop(columns={'Serial No.'}, inplace=True)\ndf.head()","903765c4":"# Display a description of the dataframe\ndf.describe()","94b41af5":"# Eyeball the correlation between all columns using sns.pairplot\nsns.pairplot(df, kind='scatter', hue='University Rating', palette='husl')","c1336fea":"# Eyeball the correlation between all columns using sns.heatmap\nfig, ax = plt.subplots(figsize=(10,8))\nsns.heatmap(df.corr(), ax=ax, annot=True, linewidths=1, fmt='.2f',\n            cmap=\"viridis\", vmin=0, vmax=1)\nplt.show()","a30318b3":"df.corr()['Chance of Admit'].round(1)","a9d41ea9":"df.drop(columns={'LOR', 'Research'}, inplace=True)\ndf.head()","a9338093":"df_preprocessed = df.copy()\ndf_preprocessed.head(10)","e7ced1f6":"# Display the shape of the dataframe\ndf_preprocessed.shape","2b093fba":"df['Chance of Admit'].median()","d6b3906d":"# Create the targets\ntargets = np.where(df['Chance of Admit'] >= df['Chance of Admit'].median(), 1, 0)\ntargets.shape","c1971658":"# Adding the column 'Probability of Acceptance' to our dataframe\ndf['Probability of Acceptance'] = targets\ndf.head()","ff52c8a6":"targets.sum()\/len(targets)","d790f8e0":"# create a checkpoint\n# drop column 'Chance of Admit' to avoid multicollinearity\ndata_with_targets = df.drop(['Chance of Admit'], axis=1)\ndata_with_targets.head()","150609ab":"# Display the shape of the dataframe\ndata_with_targets.shape","d8a09bf9":"# Select the inputs\ninputs = data_with_targets.iloc[:, :-1]\ninputs.head()","7d031b74":"# Splitting the data into train and test sets with a 80-20 split percentage\nx_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=.2, shuffle=True, random_state=20)","8b3cbc04":"# Displaying the train and test datasets and targets\nprint(x_train, y_train)\nprint(x_test, y_test)","43d5226e":"# Displaying the shape of the train and test datasets and targets\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","f6426457":"# Create a logistic regression object\nlog_reg = LogisticRegression()\n# Fit the data to the model\nlog_reg.fit(x_train, y_train)","e260ab26":"# Display the accuracy of the model\nlog_reg.score(x_train, y_train)","52ea8eb1":"# Accuracy means that x% of the model outputs match the targets\nmodel_outputs = log_reg.predict(x_train)\nmodel_outputs","3eed30d5":"y_train","3ca11740":"model_outputs == y_train","5284d4a5":"# Model accuracy\nnp.sum(model_outputs == y_train) \/ len(model_outputs)","f5a7af45":"# Intercept value\nlog_reg.intercept_","d633edf6":"# Coefficient value\nlog_reg.coef_","496978af":"feature_name = inputs.columns.values\nsummary_table = pd.DataFrame(columns=['Feature Name'], data=feature_name)\nsummary_table['Coefficient'] = np.transpose(log_reg.coef_)\nsummary_table.head()","a3ceb18a":"# Adding the intercept value to the summary table\nsummary_table.index += 1\nsummary_table.loc[0] = ['Intercept', log_reg.intercept_[0]]\nsummary_table.sort_index(inplace=True)\nsummary_table.head()","b0476ac3":"# Finding the odds ratio\nsummary_table['Odds_ratio'] = np.exp(summary_table.Coefficient)\nsummary_table","3c271f99":"log_reg.score(x_test, y_test)","09b09ffd":"# Predict the probability of an output being 0 (first column) or 1 (second column)\npredicted_proba = log_reg.predict_proba(x_test)\npredicted_proba","e82fc23b":"# Shape of the test-data set\npredicted_proba.shape","5f1f8f2a":"# Slice out the values from the second column\nprobability_admit = predicted_proba[:,1]\nprobability_admit","47b557ab":"# Predicted values\npred = log_reg.predict(x_test)\npred","150bf026":"predicted_value = log_reg.predict(x_test)\npredicted_value","23117fd3":"df_with_predicted_outcomes = inputs.copy()\n\nprobability_admit = pd.DataFrame(probability_admit)\ndf_with_predicted_outcomes['Probability'] = probability_admit\n\npredicted_value = pd.DataFrame(predicted_value)\ndf_with_predicted_outcomes['Prediction'] = predicted_value","fa61b577":"# Display the final dataframe with predictions\ndf_with_predicted_outcomes.head(10)","018e37ed":"### I have used the median to balance the dataset, thereby, making it implicitly stable and rigid. Rougly half the values are 0's and the other half are 1's. This will prevent our model from learning to output one of the values exclusively.","31294e8e":"## Creating a summary table","2c312b3c":"### Targets are chosen based on the median values of Chance of Admit. The values above the median are assumed to have a high probability of being accepted into a graduate program.","54a94cd2":"### A balance of 45% - 55% is sufficient to perform regression.","c18a8bad":"## Eyeball the correlation between all columns using sns.pairplot and sns.heatmap","1ea4673f":"# This kernel is designed to predict the chance of a candidate being accepted into a graduate program using a Logistic Regression model. This process is broken down into two parts:\n# 1. Part I consists of an exploratory data analysis and\n# 2. Part II implements machine learning using logistic regression.","45ccfcc3":"### Correlation values of all the columns with Chance of Admit - The features which are strongly correlated are the  GRE Score, TOEFL score, University Rating, SOP and CGPA.","ea2073a7":"## Analysing the data","6bbc1b56":"### Based on the correlation of all the features on the heatmap with Chance of Admit, drop those features that have a low correlation; any correlation with a value < 70%.","1e396eeb":"### Create checkpoint - The final preprocessed dataframe contains only those features that have a correlation of atleast 70% with the chance of admit column of the dataframe.","183dbb7f":"# Preprocessing the data","b9ee5a5f":"# Interpreting the coefficients and odds ratio\n\n### Since the inputs are unscaled, the Coefficient column and the Odds_ratio column of the summary table provide an accurate measure of the importance of each feature. Features that have a coefficient value of 0 and odds ratio of 1 are insginificant with regard to affecting the chance of being admitted to a graduate program. \n### Therefore, by this interpretation, one can observe that the two most significant features influencing the chance of being admitted are a candidate's CPGA and SOP, followed by university rating.","39eb2cc6":"## Create the targets","b1838365":"# Testing the model","2c8a0600":"# The Dataframe named 'data_with_predicted_outcomes' shows the probability of a candidate being accepted into a graduate program. The accuracy of this model is 78%. Prospective students can use this model as a tool while shortlisting their colleges.","79894e66":"## Split the data into train & test sets","c462c50a":"# Part II - Implementing Machine Learning","4cf5f048":"# Part I - Exploratory Data Analysis","45b5d9ac":"## Create the Dataframe with predictions","4d8fe7f8":"## Finding the intercept and coefficients ","2396670d":"## Select the inputs for regression","0cfd91fd":"## Manually checking the accuracy","b8c1346a":"## Logistic Regression with sklearn","5690c0b3":"### Logistic regression: log odds = b0 + b1X1 + b2X2 + b3X3 + ... + bnXn","776f0e11":"# Import the required libraries"}}