{"cell_type":{"8e9e6bb4":"code","f8d17f8f":"code","02fe3e66":"code","38d7ae24":"code","742451d1":"code","cfa86edd":"code","e315faca":"code","b530f2ed":"code","bde10c23":"code","743af86f":"code","a2dc1c24":"code","793d2d9a":"code","e8209f0e":"code","d5d50cbd":"code","ec7fd7f8":"code","5c485ed4":"code","4495c571":"code","91d57f9a":"code","3ab69669":"markdown","ec908975":"markdown","521dcfbf":"markdown","05363839":"markdown","5eca8094":"markdown","81693c3c":"markdown","064cf1f0":"markdown","7b6b44f9":"markdown","9183151e":"markdown","27728564":"markdown","354ce5db":"markdown","f2da6f61":"markdown","2d83d88e":"markdown","4346d44f":"markdown","8e276930":"markdown","dd9e6c76":"markdown","da5fca30":"markdown"},"source":{"8e9e6bb4":"import numpy as np\nimport pandas as pd","f8d17f8f":"train = pd.read_csv(\"\/kaggle\/input\/human-activity-recognition-with-smartphones\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/human-activity-recognition-with-smartphones\/test.csv\")","02fe3e66":"columns = train.columns\n\n# Removing '()' from column names\ncolumns = columns.str.replace('[()]','')\ncolumns = columns.str.replace('[-]', '')\ncolumns = columns.str.replace('[,]','')\n\ntrain.columns = columns\ntest.columns = columns\n\ntest.columns","38d7ae24":"y_train = train.Activity\nX_train = train.drop(['subject', 'Activity'], axis=1)\ny_test = test.Activity\nX_test = test.drop(['subject', 'Activity'], axis=1)\nprint('Training data size : ', X_train.shape)\nprint('Test data size : ', X_test.shape)\n","742451d1":"train.head(3)","cfa86edd":"labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']","e315faca":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","b530f2ed":"from datetime import datetime\ndef perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True, cm_cmap=plt.cm.Greens):\n    \n    \n    # to store results at various phases\n    results = dict()\n    \n    # time at which model starts training \n    train_start_time = datetime.now()\n    print('training the model..')\n    model.fit(X_train, y_train)\n    print('Done \\n \\n')\n    train_end_time = datetime.now()\n    results['training_time'] =  train_end_time - train_start_time\n    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n    \n    \n    # predict test data\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred = model.predict(X_test)\n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n   \n\n    # calculate overall accuracty of the model\n    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n    \n    # confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(8,8))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n    plt.show()\n    \n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_report = metrics.classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_report'] = classification_report\n    print(classification_report)\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return results\n    \n    ","bde10c23":"def print_grid_search_attributes(model):\n    # Estimator that gave highest score among all the estimators formed in GridSearch\n    print('--------------------------')\n    print('|      Best Estimator     |')\n    print('--------------------------')\n    print('\\n\\t{}\\n'.format(model.best_estimator_))\n\n\n    # parameters that gave best results while performing grid search\n    print('--------------------------')\n    print('|     Best parameters     |')\n    print('--------------------------')\n    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n\n\n    #  number of cross validation splits\n    print('---------------------------------')\n    print('|   No of CrossValidation sets   |')\n    print('--------------------------------')\n    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n\n\n    # Average cross validated score of the best estimator, from the Grid Search \n    print('--------------------------')\n    print('|        Best Score       |')\n    print('--------------------------')\n    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n\n    \n    ","743af86f":"from sklearn import linear_model\nfrom sklearn import metrics\n\nfrom sklearn.model_selection import GridSearchCV","a2dc1c24":"\n# start Grid search\nparameters = {'C':[0.01, 0.1, 1, 10, 20, 30], 'penalty':['l2','l1']}\nlog_reg = linear_model.LogisticRegression()\nlog_reg_grid = GridSearchCV(log_reg, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)\nlog_reg_grid_results =  perform_model(log_reg_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n","793d2d9a":"plt.figure(figsize=(8,8))\nplt.grid(b=False)\nplot_confusion_matrix(log_reg_grid_results['confusion_matrix'], classes=labels, cmap=plt.cm.Greens, )\nplt.show()","e8209f0e":"# observe the attributes of the model \nprint_grid_search_attributes(log_reg_grid_results['model'])","d5d50cbd":"from sklearn.svm import LinearSVC","ec7fd7f8":"parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}\nlr_svc = LinearSVC(tol=0.00005)\nlr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, n_jobs=-1, verbose=1)\nlr_svc_grid_results = perform_model(lr_svc_grid, X_train, y_train, X_test, y_test, class_labels=labels)","5c485ed4":"print_grid_search_attributes(lr_svc_grid_results['model'])","4495c571":"from sklearn.tree import DecisionTreeClassifier\nparameters = {'max_depth':np.arange(3,10,2)}\ndt = DecisionTreeClassifier()\ndt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=-1)\ndt_grid_results = perform_model(dt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(dt_grid_results['model'])","91d57f9a":"print('\\n                     Accuracy     Error')\nprint('                     ----------   --------')\nprint('Logistic Regression : {:.04}%       {:.04}%'.format(log_reg_grid_results['accuracy'] * 100,\\\n                                                  100-(log_reg_grid_results['accuracy'] * 100)))\n\nprint('Linear SVC          : {:.04}%       {:.04}% '.format(lr_svc_grid_results['accuracy'] * 100,\\\n                                                        100-(lr_svc_grid_results['accuracy'] * 100)))\n\nprint('DecisionTree        : {:.04}%        {:.04}% '.format(dt_grid_results['accuracy'] * 100,\\\n                                                        100-(dt_grid_results['accuracy'] * 100)))","3ab69669":"### In the real world, domain-knowledge, EDA and feature-engineering matter most.","ec908975":"## Obtain the train and test data","521dcfbf":"## Predictions of Human Activity Recognition(96%+)\n","05363839":"#  2. Linear SVC with GridSearch","5eca8094":"As We have already discussed about EDA of Human Actitvity Recognition\n\nyou refer this link for EDA of Human Activity Recognition\n-->https:\/\/www.kaggle.com\/abheeshthmishra\/eda-of-human-activity-recognition\/comments#1163894","81693c3c":"here We will try to implement some classical machine learning algorithm and observe how our model perform \n\nwe will implement these classical machine learning algorithms\n1. Logistic Regression with Grid Search\n2. Linear SVC with GridSearch\n3. Decision Trees with GridSearchCV\n","064cf1f0":"### Function to plot the confusion matrix","7b6b44f9":"\n# 4. Comparing all models","9183151e":"### Generic function to run any model specified","27728564":"# Conclusion :","354ce5db":"### Labels that are useful in plotting confusion matrix","f2da6f61":"# 3. Decision Trees with GridSearchCV","2d83d88e":"### Importing libraries","4346d44f":" ### ****We can choose ___Logistic regression___ or ___Linear SVC___ or try other classical algorithms.****","8e276930":"### Method to print the gridsearch Attributes","dd9e6c76":"# 1. Logistic Regression with Grid Search","da5fca30":"# Let's model with our data"}}