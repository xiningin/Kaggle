{"cell_type":{"5328e1d6":"code","6a515a03":"code","aacd92a1":"code","e0a5fe82":"code","5ee1ceb5":"code","f2d83c00":"code","7aedd351":"code","c62943bd":"code","18b6a5d4":"code","8a846572":"code","5879244a":"code","76467c43":"code","d5f19224":"code","95379da8":"markdown","0fbce6e5":"markdown","8a36f7c9":"markdown","0d18a911":"markdown","90672203":"markdown","ac680b21":"markdown","54c72cf6":"markdown","e236ee4b":"markdown","df363cb0":"markdown","61a28a25":"markdown","2cb244d7":"markdown"},"source":{"5328e1d6":"import numpy as np\nimport pandas as pd \nimport torch\nfrom torch import optim\nimport torch.nn as nn\nfrom PIL import Image","6a515a03":"df = pd.read_csv('..\/input\/traffic-sign-dataset-classification\/labels.csv',sep=',')","aacd92a1":"import os\n\nclass_ids = []\nfilenames = []\n\n# Start with Test\nfor file in os.listdir(\"..\/input\/traffic-sign-dataset-classification\/traffic_Data\/TEST\/\"):\n    if file.endswith(\".png\"):\n        filenames.append(\"..\/input\/traffic-sign-dataset-classification\/traffic_Data\/TEST\/\" + file)\n        classname = file.split(\"_\")[0].lstrip('0')\n        if classname == \"\":\n            classname = \"0\"\n        class_ids.append(classname)","e0a5fe82":"classes = df[\"ClassId\"]\n\nfor index, value in classes.items():\n    for file in os.listdir(os.path.join(\"..\/input\/traffic-sign-dataset-classification\/traffic_Data\/DATA\/\", str(value))):\n        if file.endswith(\".png\"):\n            filenames.append(os.path.join(\"..\/input\/traffic-sign-dataset-classification\/traffic_Data\/DATA\/\", str(value), file))\n            classname = file.split(\"_\")[0].lstrip('0')\n            if classname == \"\":\n                classname = \"0\"\n            class_ids.append(classname)","5ee1ceb5":"df = pd.DataFrame(list(zip(class_ids, filenames)), columns =['classid', 'filename'])\nprint(df.head())","f2d83c00":"from torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n  def __init__(self, X, y, BatchSize, transform):\n    super().__init__()\n    self.BatchSize = BatchSize\n    self.y = y\n    self.X = X\n    self.transform = transform\n    \n  def num_of_batches(self):\n    \"\"\"\n    Detect the total number of batches\n    \"\"\"\n    return math.floor(len(self.list_IDs) \/ self.BatchSize)\n\n  def __getitem__(self,idx):\n    class_id = self.y[idx]\n    img = Image.open(self.X[idx])\n    img = self.transform(img)\n    return img, torch.tensor(int(class_id))\n\n  def __len__(self):\n    return len(self.X)","7aedd351":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\n\n# Shuffle dataframe\ndf = df.sample(frac=1)\n\nX = df.iloc[:,1]\ny = df.iloc[:,0]\n\ntransform = transforms.Compose([\n                transforms.Resize([256,256]),\n                transforms.RandomRotation(20, fill=256),\n                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n                transforms.ToTensor(),\n                transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n                transforms.Normalize([0.5], [0.5])\n            ])\n\ntest_transform = transforms.Compose([\n                              transforms.Resize([256,256]),\n                              transforms.ToTensor(),\n                              transforms.Normalize((0.5,), (0.5,)),\n                              ])\n\ntrain_ratio = 0.90\nvalidation_ratio = 0.05\ntest_ratio = 0.05\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, stratify = y, random_state = 0)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio\/(test_ratio + validation_ratio), random_state = 0)\n\ndataset_stages = ['train', 'val', 'test']\n\nbatch_size = 32\nimage_datasets = {'train' : CustomDataset(X_train.values, y_train.values, batch_size, transform), 'val' : CustomDataset(X_val.values, y_val.values, batch_size, test_transform), 'test' : CustomDataset(X_test.values, y_test.values, batch_size, test_transform)}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=image_datasets[x].BatchSize,\n                                            shuffle=True, num_workers=0)\n            for x in dataset_stages}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}","c62943bd":"import matplotlib.pyplot as plt\nnparray = image_datasets['train'][2][0].cpu().numpy() \nimage = transforms.ToPILImage()(image_datasets['train'][2][0].cpu()).convert(\"RGB\")\ndisplay(image)","18b6a5d4":"import time\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n            num_batches = 0\n            outputs = None\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                # Loading Bar\n                if (phase == 'train'):\n                    num_batches += 1\n                    percentage_complete = ((num_batches * batch_size) \/ (dataset_sizes[phase])) * 100\n                    percentage_complete = np.clip(percentage_complete, 0, 100)\n                    print(\"{:0.2f}\".format(percentage_complete), \"% complete\", end=\"\\r\")\n\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs.float(), labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        # TODO: try removal\n                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                \n                predicted = torch.max(outputs.data, 1)[1] \n                running_correct = (predicted == labels).sum()\n                running_corrects += running_correct\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            \n            epoch_acc = running_corrects \/ dataset_sizes[phase]\n            #epoch_acc = sum(epoch_acc) \/ len(epoch_acc)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc.item()))\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    return model","8a846572":"from torchvision import models\nfrom torch.optim import lr_scheduler","5879244a":"model_ft = models.squeezenet1_1(pretrained=True)\nmodel_ft.classifier._modules[\"1\"] = nn.Conv2d(512, 58, kernel_size=(1, 1))\nmodel_ft.num_classes = 58\nfor param in model_ft.parameters():\n    param.requires_grad = False\nfor param in model_ft.classifier.parameters():\n    param.requires_grad = True","76467c43":"criterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\nmodel_ft = train_model(model_ft.to(device), criterion, optimizer_ft, exp_lr_scheduler, 24)","d5f19224":"from sklearn.metrics import accuracy_score \n\naccuracy_scores = []\n\nrunning_corrects = 0\noutputs = None\nfor inputs, labels in dataloaders['test']:\n    model_ft.eval()\n    \n    inputs = inputs.to(device)\n    labels = labels.to(device)\n\n    outputs = model_ft(inputs)\n    \n    predicted = torch.max(outputs.data, 1)[1] \n    running_correct = (predicted == labels).sum()\n    running_corrects += running_correct\n\naccuracy = running_corrects \/ dataset_sizes['test']\nprint(\"Accuracy: \" + str(accuracy.item()))","95379da8":"# Create a Training Function","0fbce6e5":"# Instantiate the Datasets\n\nWe will form them into torch dataloaders to make the data easier to work with. We are also going to put in a minor amount of image augmentation in the train dataset.","8a36f7c9":"# Conclusion\n\nWhile accuracy may not be truly amazing this is still a good level of accuracy. I am very happy having achieved my aim of quickly creating code for a visual classification problem. ","0d18a911":"# **Introduction**\n\nThis notebook is my work on getting squeezenet working on a classification problem in a reasonable amount of time. I am mainly training to get faster in doing this to new problems.\n\nI have changed the test train split here to fit with my workflow.\n\n# Import Necessary Libraries","90672203":"# Load up Squeezenet\n\n","ac680b21":"# Create the Custom Dataset Class\n\nWe need this to be able to load the image and label into the model we will create. So we will create a custom dataset to handle this","54c72cf6":"# Run on Test Set","e236ee4b":"# Test image from dataset","df363cb0":"# Train Model","61a28a25":"# Load Data","2cb244d7":"# Create a DataFrame with Filenames For Training\n\nI want there to be just one large dataframe with the file locations and class ids that will be easy to create a custom dataset with."}}