{"cell_type":{"bb666f11":"code","60d58e63":"code","d129fff3":"code","da715d99":"code","4b8d92d3":"code","821cceba":"code","fb1b7858":"code","46b3be84":"code","d71b54dc":"code","d7283620":"code","4ff2e94d":"code","3c8907fb":"code","9a9c339d":"code","8609b25e":"markdown","6731225f":"markdown","d03fa980":"markdown","0482feaf":"markdown","6cdeafdf":"markdown","47ff3cb6":"markdown","c2626f42":"markdown","a8b2a842":"markdown","0fc42b6d":"markdown"},"source":{"bb666f11":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\ndef get_null_observations(dataframe, column):\n    return dataframe[pd.isnull(dataframe[column])]\n\ndef delete_null_observations(dataframe, column):\n    fixed_df = dataframe.drop(get_null_observations(dataframe,column).index)\n    return fixed_df\n    \ndef get_missing_data_table(dataframe):\n    total = dataframe.isnull().sum()\n    percentage = dataframe.isnull().sum() \/ dataframe.isnull().count()\n    \n    missing_data = pd.concat([total, percentage], axis='columns', keys=['TOTAL','PERCENTAGE'])\n    return missing_data.sort_index(ascending=True)\n\ndf = pd.read_csv('..\/input\/train_V2.csv')\ndf.head()","60d58e63":"get_missing_data_table(df)","d129fff3":"df = delete_null_observations(dataframe=df, column='winPlacePerc')\nget_missing_data_table(df)","da715d99":"# Adding team features\ndf_team_dict = (df.groupby('groupId', as_index = True)\n          .agg({'Id':'count', 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).to_dict()\n\nteamKills = []\nteamSize = []\n\nfor teamId in df['groupId']:\n    teamKills.append(df_team_dict['teamKills'][teamId])\n    teamSize.append(df_team_dict['teamSize'][teamId])\n\ndf['teamKills'] = teamKills\ndf['teamSize'] = teamSize\ndf.head()","4b8d92d3":"# Adding match features\ndf_team = (df.groupby('groupId', as_index = False)\n          .agg({'Id':'count', 'matchId':lambda x: x.unique()[0], 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).reset_index()\n\ndf_match = (df_team.groupby('matchId', as_index = True)\n           .agg({'teamSize':'sum', 'teamKills':'sum'})\n           .rename(columns={'teamSize':'matchSize', 'teamKills':'matchKills'})).to_dict()\nmatchSize = []\nmatchKills = []\n\nfor matchId in df['matchId']:\n    matchSize.append(df_match['matchSize'][matchId])\n    matchKills.append(df_match['matchKills'][matchId])\n\ndf['matchSize'] = matchSize\ndf['matchKills'] = matchKills\ndf.head()","821cceba":"#Drop insignificant features\ndf.drop(['Id'], axis='columns', inplace=True)\ndf.drop(['groupId'], axis='columns', inplace=True)\ndf.drop(['matchId'], axis='columns', inplace=True)\ndf.head()","fb1b7858":"# matchDuration boxplot\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nsn.boxplot(data=df['matchDuration'], ax= ax)\nax.set(title='Match Duration Box Plot')\nplt.show()","46b3be84":"# Delete Outliers according to matchDuration\nprevious_record_size = df.shape[0]\n\nh_spread = df['matchDuration'].quantile(.75) - df['matchDuration'].quantile(.25)\nlimit = df['matchDuration'].quantile(.25) - 2 * h_spread\ndf.drop(df[df['matchDuration'] < limit].index, inplace=True)\n\nnew_record_size = df.shape[0]\nprint('Total records deleted: {} ({:.7%} of previous record size)'.format(previous_record_size - new_record_size, 1 - new_record_size \/ previous_record_size))","d71b54dc":"# Delete Outliers according to rideDistance and roadKills\nprevious_record_size = df.shape[0]\n\ndf.drop(df.query('rideDistance == 0 and roadKills > 0').index, inplace=True)\n\nnew_record_size = df.shape[0]\nprint('Total records deleted: {} ({:.7%} of previous record size)'.format(previous_record_size - new_record_size, 1 - new_record_size \/ previous_record_size))","d7283620":"# Label encode matchType\n\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ndf['matchType'] = encoder.fit_transform(df['matchType'])\n\ndf.head()","4ff2e94d":"# X and y split\ny = df['winPlacePerc'].values\nX = df.drop(['winPlacePerc'], axis='columns').values","3c8907fb":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n#LightGBM\nimport lightgbm as lgb\n\n# create dataset for lightgbm\nlgb_train = lgb.Dataset(X_train, y_train, categorical_feature=[12])\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n# set matchType\n\nparams = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"mae\",\n        \"n_estimators\":15000,\n        \"early_stopping_rounds\":100,\n        \"num_leaves\" : 31, \n        \"learning_rate\" : 0.05, \n        \"bagging_fraction\" : 0.9,\n        \"bagging_seed\" : 0, \n        \"num_threads\" : 4,\n        \"colsample_bytree\" : 0.7\n        }\n\nmodel = lgb.train(params,\n                lgb_train,\n                num_boost_round=20,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=5,\n                verbose_eval=1000)","9a9c339d":"df_test = pd.read_csv('..\/input\/test_V2.csv')\ndf_test['matchType'] = encoder.transform(df_test['matchType'])\ndf_test_team_dict = (df_test.groupby('groupId', as_index = True)\n          .agg({'Id':'count', 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).to_dict()\n\nteamKills_test = []\nteamSize_test = []\n\nfor teamId in df_test['groupId']:\n    teamKills_test.append(df_test_team_dict['teamKills'][teamId])\n    teamSize_test.append(df_test_team_dict['teamSize'][teamId])\n\ndf_test['teamKills'] = teamKills_test\ndf_test['teamSize'] = teamSize_test\n\ndf_team_test = (df_test.groupby('groupId', as_index = False)\n          .agg({'Id':'count', 'matchId':lambda x: x.unique()[0], 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).reset_index()\n\ndf_match_test = (df_team_test.groupby('matchId', as_index = True)\n           .agg({'teamSize':'sum', 'teamKills':'sum'})\n           .rename(columns={'teamSize':'matchSize', 'teamKills':'matchKills'})).to_dict()\nmatchSize_test = []\nmatchKills_test = []\n\nfor matchId in df_test['matchId']:\n    matchSize_test.append(df_match_test['matchSize'][matchId])\n    matchKills_test.append(df_match_test['matchKills'][matchId])\n\ndf_test['matchSize'] = matchSize_test\ndf_test['matchKills'] = matchKills_test\n\nX_testdata = df_test.drop(['Id','groupId','matchId'], axis='columns').values\n\ndf_test['winPlacePerc'] = model.predict(X_testdata, num_iteration=model.best_iteration)\nsubmission = df_test[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)\nprint('Done!')","8609b25e":"## LightGBM Model\n\nA LightGBM model is used to predict the target *winPlacePerc*,  the model use 15000 iterations, 70% of features and 90% of training data per tree","6731225f":"## Feature Engenieering: Team and Match Features\nGrouping records by *groupId* and *matchId* the features *teamKills* (Sum of kills in the team), *teamSize* (Total number of players in the team), *matchKills* and *matchSize* are created. ","d03fa980":"## Imports: Dataset, Libraries and Usefull Functions\n\nFor this notebook, I'll use two functions that are from a kind of EDA framework that I always use and that its open to contributions on [GitHub](https:\/\/github.com\/Bielos\/EDA-Framework).","0482feaf":"## Test Data Prediction and Submit","6cdeafdf":"# PUBG Finish Placement Prediction\n\nAutor: Daniel Martinez Bielostotzky","47ff3cb6":"## Preprocessing: Missing Values\n\nTo check the integrity of the data, the missing values and data types are displayed.\n### Missing Vales\nUsing *get_missing_data_table* we can see that the training dataset has only one record with a missing value in the 'winPlacePerc' column since it is the target column no completion method can be applied.","c2626f42":"## Feature Selection and Outliers\n\nFeatures that represent IDs are meaningless for any model so they are dropped out. ","a8b2a842":"## Table of contents\n* **Imports: Dataset, Libraries and Usefull Functions**\n* **Preprocessing: Missing Values**\n* **Feature Engenieering: Team and Match Features**\n* **Feature Selection and Outliers**\n* **LightGBM Model**\n* **Test Data Prediction and Submit**","0fc42b6d":"### Outliers\nSome records may be rare cases and may affect the generalization power of the model because they are just noise.\n\nThe outliers to be deleted are:\n1.  Records with low *matchDuration* (According to box plot) \n1. Players with 0 *rideDistance* and *roadKills* greater than 0"}}