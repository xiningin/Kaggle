{"cell_type":{"a62a0407":"code","611e3561":"code","622de261":"code","8eb05e91":"code","11a0639e":"code","b1a297b2":"code","d695800c":"code","fa927ea9":"code","0f7872f2":"code","96abe7ac":"code","ee117e67":"code","f4f32758":"code","d8a07ea6":"code","0737c67f":"code","3d80ba1e":"code","ee40571c":"code","dfad92b1":"code","89453cf2":"code","8ca86452":"code","8c5e7360":"code","f6523155":"code","6552b8c7":"code","847c65f3":"code","66b6d360":"code","aef0e3db":"code","6328a972":"code","0b2ece2d":"code","a556ff24":"code","c8184cb2":"code","a0e33beb":"code","ad421abb":"code","f46e1fb6":"code","3ae8e681":"code","4540adac":"code","26113ef3":"code","d248b6b5":"code","d9420c66":"code","b0c74679":"code","15ae9577":"code","c1427226":"code","cd86d23a":"code","b7713689":"code","d7869217":"markdown","3d57216f":"markdown","55693e28":"markdown","f0b11bdb":"markdown","a924169e":"markdown","accd0123":"markdown","6f6c1487":"markdown","f937af64":"markdown","a5dbb01e":"markdown","b2ed1db6":"markdown","2d6fbedf":"markdown","876b9c2d":"markdown","ab1fc7c5":"markdown","92acf016":"markdown"},"source":{"a62a0407":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","611e3561":"import tensorflow as tf\nfrom pathlib import Path\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.feature_extraction import text\nimport matplotlib.pyplot as plt\nimport string\nimport re","622de261":"df = pd.read_csv(\"\/kaggle\/input\/taylor-swift-song-lyrics-all-albums\/05-1989_deluxe.csv\", delimiter=',', encoding='utf8')\ndf.head()","8eb05e91":"df1 = pd.read_csv(\"\/kaggle\/input\/taylor-swift-song-lyrics-all-albums\/06-reputation.csv\", delimiter=',', encoding='utf8')\ndf1.head()","11a0639e":"df.isnull().sum()","b1a297b2":"# Get Title Counts\ndf['track_title'].value_counts().sort_index()","d695800c":"shake = df[(df['track_title']=='Shake It Off')].reset_index(drop=True)\nshake.head()","fa927ea9":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\n# Filter Data with more than 3 words\nshake = shake[shake['lyric'].apply(lambda x: len(x.split(\" \")) > 3)]","0f7872f2":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\n# Punctuation Regex\npunct = re.compile(r'[!\\\\\"#$%&\\'()*+,-.\/:;<=>?@\\[\\]^_`{|}~0-9]+')","96abe7ac":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\n#Get Frequency Counts after processing => Lowercase + remove numbers, punctuation + strip whitespace\ncv = text.CountVectorizer(lowercase=True,preprocessor=lambda x: punct.sub(\"\",x.strip()).lower(),stop_words='english')","ee117e67":"op = cv.fit_transform(shake[\"lyric\"])","f4f32758":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\nshake_freq = pd.DataFrame(op.toarray(),columns=cv.get_feature_names())","d8a07ea6":"shake_freq.head()","0737c67f":"freq_words = shake_freq.sum(axis=0)","3d80ba1e":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nfreq_words.sort_values(ascending=False)","ee40571c":"wc = WordCloud(width=600,height=300).generate_from_frequencies(freq_words)","dfad92b1":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nplt.rcParams[\"figure.figsize\"] = (20,5)\nplt.imshow(wc);","89453cf2":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\n#Store processed text in a new column\nshake['cleaned_lyric'] = shake['lyric'].apply(lambda x: punct.sub(\"\",x.strip()).lower())","8ca86452":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\n# Join lines of a song by title\nshake_song = shake.groupby('track_title',sort=False).apply(lambda x: \" \".join(x['cleaned_lyric']))","8c5e7360":"shake_song.iloc[0]","f6523155":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","6552b8c7":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nnum_words = 5000\noov_token = '<UNK>'\npad_type = 'post'\ntrunc_type = 'post'","847c65f3":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\ntokenizer = Tokenizer(num_words=num_words,oov_token=oov_token)","66b6d360":"tokenizer.fit_on_texts(shake_song)","aef0e3db":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nseqs = tokenizer.texts_to_sequences(shake_song)","6328a972":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nn_grams = 11\ngram_seqs = []\nn_seqs = len(seqs)\nfor i in seqs:\n    n_i = len(i)\n    for j in range(n_i-n_grams):\n        gram_seqs.append(i[j:j+n_grams])","0b2ece2d":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nlabels = [i[-1] for i in gram_seqs]\ninputs = [i[:-1] for i in gram_seqs]","a556ff24":"from sklearn.preprocessing import OneHotEncoder\n#from keras.utils import to_categorical  #Import Error\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import Model\nfrom keras.layers import Dense, Embedding, LSTM, Input, Bidirectional","c8184cb2":"encoded_labels = to_categorical(labels,num_classes=num_words)","a0e33beb":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nclass lyrics_generator(Model):\n    def __init__(self):\n        super(lyrics_generator,self).__init__()\n        self.embedding = Embedding(num_words,64,input_length=n_grams-1)\n        self.lstm = Bidirectional(LSTM(20))\n        self.dense = Dense(num_words,activation='softmax')\n    \n    def call(self,x):\n        x = self.embedding(x)\n        x = self.lstm(x)\n        x = self.dense(x)\n        return x\n    \n    def model(self):\n        x = Input(shape=(n_grams-1))\n        return Model(inputs=[x], outputs=self.call(x))","ad421abb":"#Code by https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/config\/threading\/set_inter_op_parallelism_threads\n#Then I set num_threads = None since it has to be defined.\n\ntf.config.threading.set_inter_op_parallelism_threads(\n    num_threads=None\n)","f46e1fb6":"m = lyrics_generator()","3ae8e681":"dataset = tf.data.Dataset.from_tensor_slices((inputs,encoded_labels)).batch(64)","4540adac":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nm.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n          ,loss=tf.keras.losses.CategoricalCrossentropy()\n         ,metrics=[tf.keras.metrics.CategoricalAccuracy()])","26113ef3":"m.model().summary()","d248b6b5":"#Epochs was 200, I tried to reduce to 100, then I gave it up . \n\nhistory = m.fit(dataset,epochs=200,verbose=0)","d9420c66":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\nprint(\"Loss: {} and Accuracy: {}\".format(history.history['loss'][-1],history.history['categorical_accuracy'][-1]))","b0c74679":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\ndef write_lyric(text,text_length=10):\n    for i in range(text_length):\n        seqs_test = tokenizer.texts_to_sequences([text])\n        seqs_test = pad_sequences(seqs_test,maxlen=n_grams-1,value=1)\n        pred_probs = m(seqs_test)\n        index = tf.argmax(pred_probs,axis=1)[0].numpy()\n        word = tokenizer.index_word[index]\n        text = text+\" \"+word\n    return text","15ae9577":"write_lyric(\"haters gonna hate\")","c1427226":"#Code by Akhil Teja https:\/\/www.kaggle.com\/enforcer007\/hamilton-lyrics-tensorflow-python\n\n\nwrite_lyric(\"fakers gonna fake\")","cd86d23a":"write_lyric(\"got nothing in my brain \")","b7713689":"write_lyric(\"heartbreakers gonna break\")","d7869217":"#That part of the lyric is Not correct. It was suppose to be Fake, Fake, Fake","3d57216f":"#Shake it Off\n\n\"Shake It Off is a song by American singer Taylor Swift. The song, as its title implies, talks about Swift\u2019s success in ignoring the false rumors peddled about her by the media and her distracters.\"\n\nRead more at: https:\/\/www.songmeaningsandfacts.com\/meaning-shake-off-taylor-swift\/","55693e28":"#It's time to Shake along.","f0b11bdb":"#Wrong again. My algorithms are Not good singers.","a924169e":"#I clicked  above a 2nd time since the message appeared again below.","accd0123":"That's all with shake it off.","6f6c1487":"#Taylor Swift - Shake It Off Disney Style\nhttps:\/\/www.youtube.com\/watch?v=XorCG9p_nP4\n\nThe Clean Cut: Group performs 'Shake It Off' with a Disney twist in Provo park\nhttps:\/\/www.deseret.com\/2015\/5\/11\/20564594\/the-clean-cut-group-performs-shake-it-off-with-a-disney-twist-in-provo-park","f937af64":"![](https:\/\/media0.giphy.com\/media\/3oKGzavIa33jEzoloI\/200w.webp?cid=ecf05e478somnm1w4z9sr0552r61cv6upgpslgph9udy6w96&rid=200w.webp&ct=g)https:\/\/giphy.com\/search\/shake-it-off","a5dbb01e":"![](https:\/\/media2.giphy.com\/media\/xTiTnkXtcChzWcTXt6\/200w.webp?cid=ecf05e478somnm1w4z9sr0552r61cv6upgpslgph9udy6w96&rid=200w.webp&ct=g)https:\/\/giphy.com\/search\/shake-it-off","b2ed1db6":"<iframe width=\"956\" height=\"538\" src=\"https:\/\/www.youtube.com\/embed\/XorCG9p_nP4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>","2d6fbedf":"#Track Titles","876b9c2d":"#I had to include that snippet to avoid: \"Tune using inter_op_parallelism_threads for best performance.\"","ab1fc7c5":"#Above: None of the MLIR Optimization Passes are enabled (registered 2)","92acf016":"#Reputation (album name). ...Ready for it?"}}