{"cell_type":{"65f07245":"code","d9a9dfb0":"code","250a410c":"code","dcdfc775":"code","0b9d6c99":"code","fdbdba3d":"code","3ac4b780":"code","dc782f85":"code","6c7227fe":"code","5511a46b":"code","dc07839b":"code","1b334201":"code","c1d72090":"code","f99426c8":"code","d0824c93":"markdown","7bcd4ef5":"markdown","735ed7c0":"markdown","751dbad9":"markdown","2585fd79":"markdown","189d37f1":"markdown","db3a52c4":"markdown","5cfb7fb0":"markdown","979e20ef":"markdown","822a9b2c":"markdown","e6964e60":"markdown","a4bc9631":"markdown","1a69d6df":"markdown","22497f45":"markdown","8fe3ccca":"markdown","b4a178d4":"markdown","05735aaf":"markdown","d8c16538":"markdown","d2271cda":"markdown"},"source":{"65f07245":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nimport re\nimport operator\nimport math\nimport random\nrandom.seed(42)\n\nimport warnings\n\nfrom deap import gp\nfrom deap import algorithms\nfrom deap import base\nfrom deap import creator\nfrom deap import tools","d9a9dfb0":"warnings.filterwarnings(\"ignore\")","250a410c":"def Pset(names):\n    # Define new functions\n    def ifelse(input, output1, output2):\n        return output1 if input else output2\n \n    def or_(left, right):\n        return int(left) | int(right)\n        \n    def and_(left, right):\n        return int(left) & int(right)\n    \n    def xor_(left, right):\n        return int(left) ^ int(right)\n\n    def abs_(input):\n        return abs(input)\n    \n    def pDiv(left, right):\n        try:\n            return left \/ right\n        except ZeroDivisionError:\n            return 1\n\n    def pPow_(left, right):\n        try:\n            return abs(left) ** min(float(right),8)\n        except ZeroDivisionError:\n            return 1\n        except OverflowError:\n            return 1\n    \n    pset = gp.PrimitiveSet(\"MAIN\", len(names))\n    pset.addPrimitive(pDiv, 2)\n    #pset.addPrimitive(pPow_, 2)\n    pset.addPrimitive(abs_, 1)\n    pset.addPrimitive(operator.add, 2)\n    pset.addPrimitive(operator.sub, 2)\n    pset.addPrimitive(operator.mul, 2)\n    pset.addPrimitive(operator.neg, 1)\n    #pset.addPrimitive(ifelse, 3)\n    #pset.addPrimitive(operator.lt, 2)\n    #pset.addPrimitive(operator.le, 2)\n    #pset.addPrimitive(operator.eq, 2)\n    #pset.addPrimitive(operator.ne, 2)\n    #pset.addPrimitive(operator.gt, 2)\n    #pset.addPrimitive(operator.ge, 2)\n    #pset.addPrimitive(operator.not_, 1) \n    #pset.addPrimitive(and_, 2)\n    #pset.addPrimitive(or_, 2)\n    #pset.addPrimitive(xor_, 2)\n    pset.addPrimitive(math.floor, 1)\n    pset.addPrimitive(math.tanh, 1)\n    pset.addPrimitive(math.sin, 1)\n    pset.addPrimitive(math.cos, 1)\n    pset.addPrimitive(max, 2)\n    pset.addPrimitive(min, 2)\n\n    #for i in range(25):\n    #    pset.addEphemeralConstant(f\"c{i}\", lambda: round(random.random()+0.001,2))\n        \n    #pset.addTerminal(False)\n    #pset.addTerminal(True)\n    pset.addTerminal(2.0)\n    pset.addTerminal(1.0)\n    pset.addTerminal(0.5)\n    pset.addTerminal(0.4)\n    pset.addTerminal(0.3)\n    pset.addTerminal(0.2)\n    pset.addTerminal(0.1)\n    pset.addTerminal(0.05)\n    pset.addTerminal(0.02)\n    pset.addTerminal(0.01)    \n\n    # Rename arguments with columns names\n    for i, a in enumerate(pset.arguments):\n        new_name = names[i]\n        pset.arguments[i] = new_name\n        pset.mapping[new_name] = pset.mapping[a]\n        pset.mapping[new_name].value = new_name\n        del pset.mapping[a]\n\n    return pset","dcdfc775":"def mydeap(mungedtrain, target):\n\n    inputs = mungedtrain.values.tolist()\n    outputs = target.values.tolist()\n\n    pset = Pset(list(mungedtrain.columns))\n    \n    creator.create(\"FitnessMin\", base.Fitness, weights=(1.0,))\n    creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)\n    \n    toolbox = base.Toolbox()\n    toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n    toolbox.register(\"compile\", gp.compile, pset=pset)\n    \n    def evalSymbReg(individual):\n        # Transform the tree expression in a callable function\n        func = toolbox.compile(expr=individual)\n        # Evaluate the accuracy\n        return sum(round(1.-(1.\/(1.+np.exp(-func(*in_))))) == out for in_,\n                   out in zip(inputs, outputs))\/len(mungedtrain),\n    \n    toolbox.register(\"evaluate\", evalSymbReg)\n    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n    toolbox.register(\"mate\", gp.cxOnePoint)\n    toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n    toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n    #toolbox.register(\"map\", dtm.map)\n    \n    toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=37))\n    toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=37))\n   \n    random.seed(42)\n\n    pop = toolbox.population(n=600)\n    hof = tools.HallOfFame(1)\n    \n    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n    stats_size = tools.Statistics(len)\n    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n    mstats.register(\"avg\", np.mean)\n    #mstats.register(\"std\", np.std)\n    #mstats.register(\"min\", np.min)\n    mstats.register(\"max\", np.max)\n    \n    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.6, mutpb=0.3, ngen=500,\n                                   stats=mstats, halloffame=hof, verbose=True)\n\n    print(hof[0])\n    print(hof[0].fitness.values)\n    return hof[0], toolbox","0b9d6c99":"def Outputs(data):\n    return np.round(1.-(1.\/(1.+np.exp(-data))))","fdbdba3d":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n            return title_search.group(1)\n    return \"\"\n\ndef PrepData(data):\n    data['IsNull'] = data.isnull().sum(axis=1)\n    data['Ticket'] = data['Ticket'].str.lower().replace('\\W', '')\n    # Sex\n    data.Sex.fillna(0, inplace=True)\n    data.loc[data.Sex != 'male', 'Sex'] = 1\n    data.loc[data.Sex == 'male', 'Sex'] = 0\n    data['NameLen'] = data['Name'].apply(len)\n    bin_num = 4\n    data['NameLen'] = pd.qcut(data['NameLen'], bin_num,labels=list(range(bin_num))).astype(float)   \n    # Feature that tells whether a passenger had a cabin on the Titanic\n    data['Has_Cabin'] = data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n    # Create new feature FamilySize as a combination of SibSp and Parch\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n    # Create new feature IsAlone from FamilySize\n    data['isFamily'] = 1\n    data.loc[data['isFamily'] == 1, 'notAlone'] = 0\n    # Create a new feature Title, containing the titles of passenger names\n    data['Title'] = data['Name'].apply(get_title)\n    # Group all non-common titles into one single grouping \"Rare\"\n    mapping = {'Mlle': 'Rare', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Rare', 'Rev': 'Mr',\n               'Don': 'Mr', 'Mme': 'Rare', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\n               'Capt': 'Mr', 'Countess': 'Rare', 'Ms': 'Miss', 'Dona': 'Rare'}\n    data.replace({'Title': mapping}, inplace=True)\n    # Mapping titles\n    title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Rare\": 4}\n    data['Title'] = data['Title'].map(title_mapping)\n    data['Title'] = data['Title'].fillna(0)\n    # Remove all NULLS in the Embarked column\n    data['Embarked'].fillna(method='backfill', inplace=True)\n    # Mapping Embarked\n    data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    # Remove all NULLS in the Fare column and create a new feature\n    data['Fare'] = data['Fare'].fillna(train['Fare'].median())\n    # Mapping Fare\n    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare'] = 2\n    data.loc[ data['Fare'] > 31, 'Fare'] = 3\n    data['Fare'] = data['Fare'].astype(int)\n    # Cabin\n    data.Cabin.fillna('0', inplace=True)\n    data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = 1\n    data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = 2\n    data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = 3\n    data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = 4\n    data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = 5\n    data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = 6\n    data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = 7\n    data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = 8\n    data['Cabin'] = data['Cabin'].astype(int)\n    # Fillna Age\n    grouped = data.groupby(['Sex','Pclass', 'Title'])\n    data['Age'] = grouped['Age'].apply(lambda x: x.fillna(x.median()))\n    data['Age'] = data['Age'].astype(int)\n    # select females and masters (boys)\n    boy = (data['Name'].str.contains('Master')) | ((data['Sex']==0) & (data['Age']<13))\n    female = data['Sex']==1\n    boy_or_female = boy | female   \n    # no. females + boys on ticket\n    n_ticket = data[boy_or_female].groupby('Ticket').Survived.count()\n    # survival rate amongst females + boys on ticket\n    tick_surv = data[boy_or_female].groupby('Ticket').Survived.mean()\n    data['Boy'] = (data['Name'].str.contains('Master')) | ((data['Sex']==0) & (data['Age']<13))   \n    # if ticket exists in training data, fill NTicket with no. women+boys\n    # on that ticket in the training data.\n    data['NTicket'] = data['Ticket'].replace(n_ticket)\n    # otherwise NTicket=0\n    data.loc[~data.Ticket.isin(n_ticket.index),'NTicket']=0\n    # if ticket exists in training data, fill TicketSurv with\n    # women+boys survival rate in training data  \n    data['TicketSurv'] = data['Ticket'].replace(tick_surv)\n    # otherwise TicketSurv=0\n    data.loc[~data.Ticket.isin(tick_surv.index),'TicketSurv']=0\n    data['TicketSurv'].fillna(0, inplace=True)\n    # Mapping Age\n    data.loc[ data['Age'] <= 16, 'Age'] = 5\n    data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n    data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n    data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n    data.loc[ data['Age'] > 64, 'Age'] = 4\n    tfidf_vec = TfidfVectorizer(max_features=15, token_pattern=\"\\w+\")\n    svd = TruncatedSVD(n_components=10)\n    tfidf_array = svd.fit_transform(tfidf_vec.fit_transform(data[\"Name\"]))\n    for i in range(tfidf_array.shape[1]):\n        data.insert(len(data.columns), column = 'Name_' + str(i), value = tfidf_array [:,i])\n    tfidf_vec = TfidfVectorizer(max_features=5, analyzer=\"char\")\n    svd = TruncatedSVD(n_components=3)\n    tfidf_array = svd.fit_transform(tfidf_vec.fit_transform(data[\"Ticket\"]))\n    for i in range(tfidf_array.shape[1]):\n        data.insert(len(data.columns), column = 'Ticket_' + str(i), value = tfidf_array [:,i])\n    data['Ticket'] = data['Ticket'].str.extract('(\\d+)', expand=False).fillna(0).astype(float)\n    data['Ticket'] = np.round(np.log1p(data['Ticket'])*10)\n    data.drop(['Name'],1,inplace=True)\n    return data.astype(float)","3ac4b780":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\", dtype={\"Age\": np.float64}, index_col='PassengerId' )\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\", dtype={\"Age\": np.float64}, index_col='PassengerId')","dc782f85":"# test_data_with_labels = pd.read_csv('..\/input\/titanic-test-data\/titanic.csv')\n# test_data = pd.read_csv('..\/input\/titanic\/test.csv')\n# for i, name in enumerate(test_data_with_labels['name']):\n#     if '\"' in name:\n#         test_data_with_labels['name'][i] = re.sub('\"', '', name)\n        \n# for i, name in enumerate(test_data['Name']):\n#     if '\"' in name:\n#         test_data['Name'][i] = re.sub('\"', '', name)\n# survived = []\n\n# for name in test_data['Name']:\n#     survived.append(int(test_data_with_labels.loc[test_data_with_labels['name'] == name]['survived'].values[-1]))\n\n# test['Survived'] = survived ","6c7227fe":"df = pd.concat((train,test),0)\ntarget = df['Survived'].astype(float)\ndf = PrepData(df)\n\ndf['Ticket'] = df['Ticket'].astype(int).astype('category')\n\ncol_to_use = ['Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'Age', \n              'NameLen', 'Has_Cabin', 'Cabin', 'FamilySize', 'isFamily', \n              'Title', 'TicketSurv', 'NTicket', 'Boy',\n              'Ticket_0', 'Ticket_1', 'Ticket_2',\n              'Name_0', 'Name_1', 'Name_2', 'Name_3', 'Name_4',\n              'Name_5', 'Name_6', 'Name_7', 'Name_8', 'Name_9']\n\ndf = pd.get_dummies(df[col_to_use])\ndf[col_to_use] += 0.0\n\nmungedtrain = df.copy()\nmungedtest = df[train.shape[0]:].copy()\nmytrain = mungedtrain.values.tolist()\nmytest = mungedtest.values.tolist()","5511a46b":"#GP Train\nGPhof, Tbox = mydeap(mungedtrain, target)","dc07839b":"test = test.reset_index()\nGPfunc = Tbox.compile(expr=GPhof)\ntestPredictions = Outputs(np.array([GPfunc(*x) for x in mytest]))\ntest['Survived'] = np.round(testPredictions).astype(int)\ntest[['PassengerId','Survived']].to_csv('gp_submit.csv', index=False)","1b334201":"# test_data_with_labels = pd.read_csv('..\/input\/titanic-test-data\/titanic.csv')\n# test_data = pd.read_csv('..\/input\/titanic\/test.csv')\n# for i, name in enumerate(test_data_with_labels['name']):\n#     if '\"' in name:\n#         test_data_with_labels['name'][i] = re.sub('\"', '', name)\n        \n# for i, name in enumerate(test_data['Name']):\n#     if '\"' in name:\n#         test_data['Name'][i] = re.sub('\"', '', name)\n# survived = []\n\n# for name in test_data['Name']:\n#     survived.append(int(test_data_with_labels.loc[test_data_with_labels['name'] == name]['survived'].values[-1]))\n\n# test['Survived'] = survived ","c1d72090":"# GPfunc = Tbox.compile(expr=GPhof)\n# testPredictions = Outputs(np.array([GPfunc(*x) for x in mytest]))\n# test['Survived'] = np.round(testPredictions).astype(int)\n# test[['PassengerId','Survived']].to_csv('gp_submit.csv', index=False)","f99426c8":"# testPrediction = np.round(testPredictions).astype(int)\n# print(\"Score :\",accuracy_score(survived,testPredictions))\n# # test['Survived'] = testPrediction\n# # test[['PassengerId','Survived']].to_csv('gp_submit.csv', index=False)","d0824c93":"Prepare inputs and outputs, initializing Deap global variables to use eaSimple(simplest evolutionary algorithm):\n- Create an individual containing the genotype and a fitness\n- Create toolbox to register some parameters specific to the evolution process\n\nFirst, a toolbox instance is created (in some problem types like coevolution, you may consider creating more than one toolbox). Then, we can register any parameters. The first lines register how to create an individual (by calling gp.genHalfAndHalf with the previously defined primitive set), and how to create the population (by repeating the individual initialization).\n\n- We may now introduce the evaluation function\n\nWhich will receive an individual as input, and return the corresponding fitness. This function uses the compile function previously defined to transform the individual into its executable form \u2013 that is, a program. After that, the evaluation is only simple maths, where the difference between the values produced by the evaluated individual and the real values are squared and summed to compute the MSE (Mean Squared Error), which is returned as the fitness of the individual.\n\n- Afterwards, we register the evaluation function. We also choose the selection method (a tournament of size 5), the mate method (one point crossover with uniform probability over all the nodes), and the mutation method (a uniform probability mutation which may append a new full sub-tree to a node).\n\n- Then, we decorate the mate and mutate method to limit the height of generated individuals. \n\nThis is done to avoid an important draw back of genetic programming : bloat. Koza in his book on genetic programming suggest to use a max depth of 17.\n\n- \u0421reating the population\n\nThe hall of fame is a specific structure which contains the n best individuals.\n\n- Statistics are often useful in evolutionary programming\n\nDEAP offers a simple class which can handle most of the \u201cboring work\u201d. In this case, we want to compute the mean and maximum of both the individuals fitness and size. For that we\u2019ll use a MultiStatistics object.\n\n- Calling a complete algorithm. In this case, we\u2019ll use eaSimple()","7bcd4ef5":"## Genetic Algorithm","735ed7c0":"## Creating the primitives set","751dbad9":"Define function for geting title from passenger name and function for data preparation","2585fd79":"## Import data","189d37f1":"## Predictions","db3a52c4":"Thanks to Paulo Pinto - https:\/\/www.kaggle.com\/paulorzp - https:\/\/www.kaggle.com\/paulorzp\/titanic-gp-model-training\n\nThanks to Ashwini Swain - https:\/\/www.kaggle.com\/ash316 - https:\/\/www.kaggle.com\/ash316\/eda-to-prediction-dietanic","5cfb7fb0":"Here, as we have a multy dimension regression problem, there are a lot of inputs, but it could have as many as you want. By default, those inputs are named \u201cARGx\u201d, where \u201cx\u201d is a number, but we renamed them.","979e20ef":"## Training genetic program","822a9b2c":"# Creating a Genetic Programming program","e6964e60":"## Ignore pandas warnings","a4bc9631":"## Cheking score","1a69d6df":"## Defining function for outputs","22497f45":"# Import libraries","8fe3ccca":"One of the most crucial aspect of a GP program is the choice of the primitives set. They should make good building blocks for the individuals so the evolution can succeed. In this problem, we use which are basic arithmetic functions and define dividing, power of number, sqrt, and absolute of a number to prevent some errors.\n\nThe number following the function is the arity of the primitive, that is the number of entries it takes.","b4a178d4":"## Train, target ","05735aaf":"### True labels for test data \nThanks Tarun Paparaju - https:\/\/www.kaggle.com\/tarunpaparaju for this method\n\nYou can find original notebook here - https:\/\/www.kaggle.com\/tarunpaparaju\/titanic-competition-how-top-lb-got-their-score","d8c16538":"## Creating all variables needed for training and testing","d2271cda":"# Data preparation"}}