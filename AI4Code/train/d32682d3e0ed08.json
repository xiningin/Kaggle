{"cell_type":{"6abfd3b2":"code","03a977a9":"code","d18b2872":"code","67d32361":"code","455dcca8":"code","1ae446be":"code","14859250":"code","e46ad1c3":"code","39b6148d":"code","6315b0ce":"code","2c70131b":"code","2bab3c68":"code","e4e80307":"code","3df4730a":"code","71d9d6c3":"code","3210862a":"code","c81dc490":"code","227108e5":"code","34c92c16":"code","898733ef":"code","30e15bec":"markdown","3118f606":"markdown","863e97d8":"markdown","d78e9f97":"markdown","8595d11b":"markdown","db2f94fe":"markdown","af38ed67":"markdown","30eb7e38":"markdown","97a0b47e":"markdown","2271cb19":"markdown","58ea2816":"markdown","d9db6b04":"markdown","a5a6aa12":"markdown","aeef4c9c":"markdown","400d0c41":"markdown"},"source":{"6abfd3b2":"import os\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\n\n\nDOWNLOAD_ROOT = \"http:\/\/vision.stanford.edu\/aditya86\/ImageNetDogs\/\"\nFILENAME = \"images.tar\"\nfilepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\ndata_dir = Path(filepath).parent \/ \"Images\"\ndata_dir","03a977a9":"# We have one class per sub-directories\nclass_names = os.listdir(data_dir)\nn_classes = len(os.listdir(data_dir))\n\nn_images = 0\nfor i in range(n_classes):\n    n_images += len(os.listdir(data_dir \/ class_names[i]))\nprint(\"Number of images: \", n_images)\nprint(\"Number of classes: \", n_classes)","d18b2872":"class_names[:10]","67d32361":"# map each classe name to an index\nclass_indices = np.arange(120) + 1\nclass_indices","455dcca8":"from PIL import Image\n\nchihuahuas = list(data_dir.glob(\"*Chihuahua\/*\"))\nImage.open(chihuahuas[0])","1ae446be":"Image.open(chihuahuas[1])","14859250":"weimaraners = list(data_dir.glob(\"*Weimaraner\/*\"))\nImage.open(weimaraners[0])","e46ad1c3":"Image.open(weimaraners[1])","39b6148d":"# this funtion takes from each category 20% for validation, 20% for testing, and\n# the rest for training. This way we are sure to not introduce a sampling bias,\n# because we have a relatively small dataset (20,580 images) compared to the number of classes (120)\ndef filepaths(data_dir, test_ratio=0.2, validation_ratio=0.2):\n    \"\"\"\n    Takes the dataset directory as input and returns \n    the filepaths for training, validation, and testing\n    \"\"\"\n    test_ratio = test_ratio\n    validation_ration = validation_ratio\n\n    train_filepaths = []\n    valid_filepaths = []\n    test_filepaths = []\n\n    path = os.path.join(\"\/root\/.keras\/datasets\/\", \"Images\/\" )\n    for i in range(n_classes):\n        img_per_cat = os.listdir(data_dir \/ class_names[i])\n        # ex: 'n02097130-giant_schnauzer\/n02097130_5175.jpg'\n        img_per_cat = np.array([os.path.join(class_names[i], s) for s in img_per_cat])\n        \n        total_size = len(img_per_cat) # ex. 157\n        test_size = int(total_size * test_ratio) # ex. 31\n        validation_size = int(total_size * validation_ratio) # ex. 31\n        train_size = total_size - test_size - validation_size # ex. 95\n\n        rnd_indices = np.random.permutation(total_size)\n\n        train_filepaths.append(img_per_cat[rnd_indices[:train_size]])\n        valid_filepaths.append(img_per_cat[rnd_indices[train_size:-test_size]])\n        test_filepaths.append(img_per_cat[rnd_indices[-test_size:]])\n\n    # make each path like this: \n    # '\/root\/.keras\/datasets\/Images\/n02097130-giant_schnauzer\/n02097130_4464.jpg'\n    train_filepaths = np.array([path + s for s in np.hstack(train_filepaths)])\n    valid_filepaths = np.array([path + s for s in np.hstack(valid_filepaths)])\n    test_filepaths = np.array([path + s for s in np.hstack(test_filepaths)])\n\n    return (train_filepaths, valid_filepaths, test_filepaths)\n\n(train_filepaths, valid_filepaths, test_filepaths) = filepaths(data_dir)\ntrain_filepaths.shape, valid_filepaths.shape, test_filepaths.shape","6315b0ce":"train_filepaths[:5]","2c70131b":"norm_layer = layers.experimental.preprocessing.Rescaling(1.\/255)","2bab3c68":"train_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\ntrain_dataset = train_dataset.shuffle(1000)\nfor i in train_dataset.take(3):\n    print(i)","e4e80307":"tf.data.experimental.cardinality(train_dataset).numpy()","3df4730a":"img_height = 150\nimg_width = 150\n\ndef get_label(file_path):\n    \"\"\"Takes the label from the file path\"\"\"\n    parts = tf.strings.split(file_path, os.path.sep)\n    one_hot = parts[-2] == class_names\n    return tf.argmax(one_hot)\n\ndef preprocess(file_path):\n    label = get_label(file_path)\n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [img_height, img_width])\n    return img, label","71d9d6c3":"def create_dataset(filepaths, batch_size=32, buffer_size=1000):\n    ds = tf.data.Dataset.list_files(filepaths, seed=42)\n    ds = ds.map(preprocess, num_parallel_calls=5)\n    ds = ds.map(lambda x, y: (norm_layer(x), y), num_parallel_calls=5)\n    ds = ds.shuffle(buffer_size)\n    ds = ds.batch(batch_size)\n    return ds.prefetch(1)","3210862a":"train_set = create_dataset(train_filepaths) \nvalid_set = create_dataset(valid_filepaths)\ntest_set = create_dataset(test_filepaths)","c81dc490":"for X_batch, y_batch in train_set.take(1):\n    print(X_batch.shape)\n    print(y_batch)","227108e5":"plt.figure(figsize=(10, 10))\nfor X_batch, y_batch in train_set.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(X_batch[i].numpy())\n        label = y_batch[i]\n        plt.title(\"Class: \" + class_names[label][10:])\n        plt.axis(\"off\")\n","34c92c16":"model = models.Sequential([\n    layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\", \n                  input_shape=(img_height, img_width, 3)),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n    layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(2048, activation=\"relu\"),\n    layers.Dense(n_classes, activation=\"softmax\") # 120\n])\noptimizer = keras.optimizers.Adam(lr=0.001)\nmodel.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\"])\n\nmodel.summary()","898733ef":"epochs = 20\nmodel.fit(train_set, epochs=epochs, validation_data=valid_set)","30e15bec":"# Import libraries","3118f606":"In this project we use the [Stanford Dogs Dataset](https:\/\/www.kaggle.com\/jessicali9530\/stanford-dogs-dataset) to build a neural network that can automatically index images.\n\nThe dataset contains:\n* 120 categories of dogs\n* 20,580 images\n\nIn this part we are going to build a neural network from scratch and see what performance can we achieve. In the next part we will use a pretrained model.","863e97d8":"# Standardizing the data\n\nWe will use the `Rescaling` layer to standardize pixel values between 0 and 1.\n\nWe can apply it to the dataset by calling the map function or we can include it inside the model definition (which simplify deployment). We will use the first option.\n\n\n\n","d78e9f97":"Putting everything together:","8595d11b":"# Create and compile the model\n\n","db2f94fe":"# Building an input pipeline using tf.data","af38ed67":"Our model seems to be too simple for this task. Let's stop here and try a pretrained model instead","30eb7e38":"And some Weimaraner:","97a0b47e":"# Loading and Preprocessing Data\n\nBasacilly, we can preprocess the data with tf.data pipline or in preprocessing layers within the model.\n\ntf.data makes it easy to apply efficient preprocessing piplines. Howerver, the trained model will still expect preprocessed data.\n\nOn the other hand, adding preprocessing layers within the model makes the model **portable** and we will only have to write preprocessing code once for both training and inference. This is the recommended option if the model needs to be deployed.\n\nIn this part, I am going to use the first option (tf.data), but in the next part, we will use the second option since I plan to deploy the model as a REST API.\n\nFirst, let's create a simple function that returns 3 lists each containing the training, validation, and testing file paths:\n","2271cb19":"# Visualizing the data","58ea2816":"Let's check the number of images and classes that we have","d9db6b04":"# Showing some images","a5a6aa12":"Let's write a short function that converts a file path to a tensor image and its label:","aeef4c9c":"We can see the length of the dataset like this:","400d0c41":"**Ressources**\n\n* The [tensorflow](https:\/\/tensorflow.org\/tutorials\/images\/classification) image classification \n tutorial\n\n* [Chapter 13 \u2013 Loading and Preprocessing Data with TensorFlow](https:\/\/github.com\/ageron\/handson-ml2\/blob\/master\/13_loading_and_preprocessing_data.ipynb) notebook"}}