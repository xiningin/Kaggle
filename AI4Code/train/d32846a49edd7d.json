{"cell_type":{"eedff065":"code","bab99784":"code","e9270a35":"code","bddb051d":"code","f804e0d6":"code","83e1e2e2":"code","92a715e2":"code","62fc9885":"code","a5b030ba":"code","b7d9f457":"code","2eeb6eb1":"code","f65566a8":"code","1752aaf8":"code","fcbe197d":"code","1ba7d736":"code","e1cee6c2":"code","8e4a037e":"code","ba8fe134":"code","33137b8d":"code","328ebf97":"code","01f3a763":"markdown","d463de51":"markdown","1294b1ea":"markdown","190a0c98":"markdown","83ac40d2":"markdown","e5a0ae1b":"markdown","49f558ac":"markdown","b9bc7aac":"markdown"},"source":{"eedff065":"!pip install imutils","bab99784":"# import the necessarry packages\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom imutils import paths\nimport pandas as pd\nimport numpy as np \nimport imutils\nimport cv2\nimport os","e9270a35":"def image_to_feature_vector(image, size=(32, 32)):\n\t# resize the image to a fixed size, then flatten the image into a list of raw pixel intensities\n\treturn cv2.resize(image, size).flatten()","bddb051d":"def extract_color_histogram(image, bins=(8, 8, 8)):\n\t# extract a 3D color histogram from the HSV color space using\n\t# the supplied number of `bins` per channel\n\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n\t\t[0, 180, 0, 256, 0, 256])\n\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n\tif imutils.is_cv2():\n\t\thist = cv2.normalize(hist)\n\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n\t# personally hate the way this is done\n\telse:\n\t\tcv2.normalize(hist, hist)\n\t# return the flattened histogram as the feature vector\n\treturn hist.flatten()","f804e0d6":"!ls \"\/kaggle\/working\/train\"","83e1e2e2":"!unzip \"..\/input\/dogs-vs-cats\/train.zip\"","92a715e2":"!unzip \"..\/input\/dogs-vs-cats\/test1.zip\"","62fc9885":"dataset = \"\/kaggle\/working\/train\"\nneighbors = 2","a5b030ba":"# grab the list of images that we'll be describing\nprint(\"[INFO] describing images...\")\nimagePaths = list(paths.list_images(dataset))\nprint(\"[INFO] dataset has {} images\".format(len(imagePaths)))","b7d9f457":"# initialize the raw pixel intensities matrix, the features matrix, and labels list\nrawImages = []\nfeatures = []\nlabels = []","2eeb6eb1":"# loop over the input images\nfor (i, imagePath) in enumerate(imagePaths):\n\t# load the image and extract the class label (assuming that our\n\t# path as the format: \/path\/to\/dataset\/{class}.{image_num}.jpg\n\timage = cv2.imread(imagePath)\n\tlabel = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n    \n\t# extract raw pixel intensity \"features\", followed by a color\n\t# histogram to characterize the color distribution of the pixels\n\t# in the image\n\tpixels = image_to_feature_vector(image)\n\thist = extract_color_histogram(image)\n    \n\t# update the raw images, features, and labels matricies, respectively\n\trawImages.append(pixels)\n\tfeatures.append(hist)\n\tlabels.append(label)\n    \n\t# show an update every 1,000 images\n\tif i > 0 and i % 1000 == 0:\n\t\tprint(\"[INFO] processed {}\/{}\".format(i, len(imagePaths)))","f65566a8":"# show some information on the memory consumed by the raw images matrix and features matrix\nrawImages = np.array(rawImages)\nfeatures = np.array(features)\nlabels = np.array(labels)\nprint(\"[INFO] pixels matrix: {:.2f}MB\".format(\n\trawImages.nbytes \/ (1024 * 1000.0)))\nprint(\"[INFO] features matrix: {:.2f}MB\".format(\n\tfeatures.nbytes \/ (1024 * 1000.0)))","1752aaf8":"# partition the data into training and testing splits, using 75%\n# of the data for training and the remaining 25% for testing\n(trainRI, testRI, trainRL, testRL) = train_test_split(\n\trawImages, labels, test_size=0.25, random_state=42)\n(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n\tfeatures, labels, test_size=0.25, random_state=42)","fcbe197d":"# train and evaluate a k-NN classifer on the raw pixel intensities\nprint(\"[INFO] evaluating raw pixel accuracy...\")\nmodel = KNeighborsClassifier(n_neighbors=neighbors,\n\tn_jobs=-1)\nmodel.fit(trainRI, trainRL)\nacc = model.score(testRI, testRL)\nprint(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))","1ba7d736":"# train and evaluate a k-NN classifer on the raw pixel intensities\nprint(\"[INFO] evaluating raw pixel accuracy...\")\nmodel = KNeighborsClassifier(n_neighbors=neighbors,\n\tn_jobs=-1)\nmodel.fit(trainFeat, trainLabels)\nacc = model.score(testFeat, testLabels)\nprint(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))","e1cee6c2":"testDataset = \"..\/working\/test1\"","8e4a037e":"# initialize the raw pixel intensities matrix, the features matrix, and labels list\ntestPaths = list(paths.list_images(testDataset))\ntestImages = []\ntestFeatures = []\n# testLabels = []","ba8fe134":"# loop over the input images\nfor (i, imagePath) in enumerate(testPaths):\n\t# load the image and extract the class label (assuming that our\n\t# path as the format: \/path\/to\/dataset\/{class}.{image_num}.jpg\n\timage = cv2.imread(imagePath)\n# \tlabel = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n    \n\t# extract raw pixel intensity \"features\", followed by a color\n\t# histogram to characterize the color distribution of the pixels\n\t# in the image\n\tpixels = image_to_feature_vector(image)\n\thist = extract_color_histogram(image)\n    \n\t# update the raw images, features, and labels matricies, respectively\n\ttestImages.append(pixels)\n\ttestFeatures.append(hist)\n# \ttestLabels.append(label)\n    \n\t# show an update every 1,000 images\n\tif i > 0 and i % 1000 == 0:\n\t\tprint(\"[INFO] processed {}\/{}\".format(i, len(testPaths)))","33137b8d":"pred = model.predict(testFeatures)\npred = np.array([0 if x == \"dog\" else 1 for x in pred ])","328ebf97":"pred","01f3a763":"### Let\u2019s apply the k-NN classifier to the raw pixel intensities:","d463de51":"### Next, we need to take our data partition it into two splits \u2014 one for training and another for testing:","1294b1ea":"### You might be curious how much memory our rawImages  and features  matrices take up \u2014 the following code block will tell us when executed:","190a0c98":"### Next, we are going to define two methods to take an input image and convert it to a feature vector, or a list of numbers that quantify the contents of an image. The first method can be seen below:","83ac40d2":"As the figure above demonstrates, by utilizing raw pixel intensities we were able to reach 53.55% accuracy. On the other hand, applying k-NN to color histograms achieved a slightly better 58.27% accuracy.\n\nIn both cases, we were able to obtain > 50% accuracy, demonstrating there is an underlying pattern to the images for both raw pixel intensities and color histograms.\n\nHowever, that 58% accuracy leaves much to be desired.\n\nAnd as you might imagine, color histograms aren\u2019t the best way to distinguish between a dog and a cat:\n\nThere are brown dogs. And there are brown cats.\nThere are black dogs. And there are black cats.\nAnd certainly a dog and cat could appear in the same environment (such as a house, park, beach, etc.) where the background color distributions are similar.\nBecause of this, utilizing strictly color is not a great choice for characterizing the difference between dogs and cats \u2014 but that\u2019s okay. The purpose of this blog post was simply to introduce the concept of image classification using the k-NN algorithm.\n","e5a0ae1b":"### We are now ready to prepare our images for feature extraction:","49f558ac":"### Let\u2019s move on to extracting features from our dataset:","b9bc7aac":"### We then define our second method, this one called extract_color_histogram :"}}