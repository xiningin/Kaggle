{"cell_type":{"20548097":"code","fc1eb92c":"code","7ca2590b":"code","eea7c541":"code","8aa65b63":"code","f0e666de":"code","136b0c45":"code","76d29688":"code","6552d97a":"code","71b7089c":"code","e484a9c1":"code","ffb7dbe5":"code","b75711f3":"code","798930d7":"code","b14d0d21":"code","b6295203":"code","7f6ea200":"code","aee0fc28":"markdown","2cdc4137":"markdown","33eff59f":"markdown","b801c425":"markdown","1f484b5c":"markdown","b3e2a19b":"markdown","34753039":"markdown","15a7dafc":"markdown","a1b160ba":"markdown","cadd3a3f":"markdown","62d70c0e":"markdown","22ab66bf":"markdown"},"source":{"20548097":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc1eb92c":"import matplotlib.pyplot as plt\nimport PIL\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\n\nprint(f'tensorflow version: {tf.__version__}')","7ca2590b":"# Working path\nPATH_DATASET = '\/kaggle\/input\/dataset-bart-or-homer\/dataset_personagens\/dataset_personagens'\nprint('List dir:')\nfor file in os.listdir(PATH_DATASET):\n  print(file)","eea7c541":"train_dir = os.path.join(PATH_DATASET, 'training_set')\nvalidation_dir = os.path.join(PATH_DATASET, 'test_set')\n\ntrain_bart_dir = os.path.join(train_dir, 'bart')\ntrain_homer_dir = os.path.join(train_dir, 'homer')\nvalidation_bart_dir = os.path.join(validation_dir, 'bart')\nvalidation_homer_dir = os.path.join(validation_dir, 'homer')\n\nnum_bart_tr = len(os.listdir(train_bart_dir))\nnum_homer_tr = len(os.listdir(train_homer_dir))\n\nnum_bart_val = len(os.listdir(validation_bart_dir))\nnum_homer_val = len(os.listdir(validation_homer_dir))\n\ntotal_train = num_bart_tr + num_homer_tr\ntotal_val = num_bart_val + num_homer_val\n\nprint('total training bart images:', num_bart_tr)\nprint('total training homer images:', num_homer_tr)\n\nprint('total validation bart images:', num_bart_val)\nprint('total validation homer images:', num_homer_val)\nprint(\"--\")\nprint(\"Total training images:\", total_train)\nprint(\"Total validation images:\", total_val)","8aa65b63":"img_bart = os.path.join(train_bart_dir, os.listdir(train_bart_dir)[5])\nPIL.Image.open(img_bart)","f0e666de":"img_homer = os.path.join(train_homer_dir, os.listdir(train_homer_dir)[13])\nPIL.Image.open(img_homer)","136b0c45":"BATCH_SIZE = 32\nIMG_SIZE = (160, 160)\n\n# dados treino com aumento do conjunto de imagems\ntrain_image_gen = ImageDataGenerator(rescale = 1.\/255,\n                               rotation_range = 7,\n                               horizontal_flip = True,\n                               shear_range = 0.2,\n                               height_shift_range = 0.05,\n                               zoom_range = 0.2)\n\nval_image_gen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_data_gen = train_image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n                                                     directory=train_dir,\n                                                     shuffle=True,\n                                                     target_size=IMG_SIZE,\n                                                     class_mode='binary')\n\nval_data_gen = val_image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n                                                 directory=validation_dir,\n                                                 shuffle=True,\n                                                 target_size=IMG_SIZE,\n                                                 class_mode='binary')","76d29688":"sample_training_images, _ = next(val_data_gen)\n\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","6552d97a":"plotImages(sample_training_images[:5])","71b7089c":"\nmodel = keras.Sequential([\n    layers.Conv2D(16, 3, padding='same', activation='elu', input_shape=(160, 160 ,3)),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding='same', activation='elu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding='same', activation='elu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(512, activation='elu'),\n    layers.Dropout(0.2),\n    layers.Dense(512, activation='elu'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=keras.optimizers.Adam(1e-3),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","e484a9c1":"# Mostra o progresso do treinamento imprimindo um \u00fanico ponto para cada epoch completada\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.>>', end='')\n\nsteps_per_epoch = train_data_gen.samples \/\/ train_data_gen.batch_size\nvalidation_steps = val_data_gen.samples \/\/ val_data_gen.batch_size\nepochs=100\n    \nhistory = model.fit(\n    train_data_gen,\n    epochs=epochs, \n    steps_per_epoch=steps_per_epoch,\n    validation_data=val_data_gen,\n    validation_steps=validation_steps,\n    callbacks=[PrintDot()],\n    verbose=0\n    )","ffb7dbe5":"# Dataframe results model\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.describe()","b75711f3":"def subplots(df, vline=None):\n  cols_names = df.columns.tolist()\n  cases = list(range(len(cols_names[:-1])))\n  plot_params = {\n      'axes.titlesize': 12,\n      'xtick.labelsize': 9,\n      'ytick.labelsize': 9,\n      }\n  with plt.rc_context(plot_params):\n    with plt.style.context('seaborn-darkgrid'):\n      fig, axs = plt.subplots(2, 2, figsize=(8, 4), constrained_layout=True, sharex=True)\n      for ax, i in zip(axs.flat, cases):\n          ax.set_title(cols_names[:-1][i])\n          ax.plot(df['epoch'],  df[cols_names[:-1][i]])\n          #vline = ax.axvline(x=2, color='#7fb800')\n          x = ax.axvline(x=vline, color='#ffb400') if vline != None else False\n      fig.text(0.5, -0.05, 'epoch', ha='center')\n\nsubplots(hist)","798930d7":"eval_results = model.evaluate(val_data_gen)\nprint('Testing set Accuracy: {:.2f}'.format(eval_results[1]))\nprint('Testing set Accuracy: {:2.2%}'.format(eval_results[1]))","b14d0d21":"test_bart = os.path.join(train_bart_dir, os.listdir(train_bart_dir)[5])\nhomer_test = os.path.join(train_homer_dir, os.listdir(train_homer_dir)[13])\ninv_map = {train_data_gen.class_indices[k] : k for k in train_data_gen.class_indices}\ninv_map","b6295203":"imagem_teste = image.load_img(homer_test,\n                              target_size = (160,160))\nimagem_teste = image.img_to_array(imagem_teste)\nimagem_teste \/= 255\nimagem_teste = np.expand_dims(imagem_teste, axis = 0)\n\nprevisao = model.predict(imagem_teste).flatten()\nprev_name = tf.where(previsao < 0.5, 0, 1).numpy()\n\ninv_map[prev_name[0]], previsao","7f6ea200":"img1, nome = next(val_data_gen)\npred = model.predict(img1).flatten()\npred = tf.where(pred < 0.5, 0, 1)\nplt.imshow(img1[0])\ntitle = inv_map[pred.numpy()[0]]\nplt.title(f'Predict name: {title}')\nplt.axis(\"off\")\nplt.show()","aee0fc28":"**Resumo**:\n\nOs Simpsons \u00e9 uma s\u00e9rie de anima\u00e7\u00e3o e sitcom norte-americana criada por Matt Groening para a Fox Broadcasting Company. A s\u00e9rie \u00e9 uma par\u00f3dia sat\u00edrica do estilo de vida da classe m\u00e9dia dos Estados Unidos (como cultura, sociedade e televis\u00e3o) e aspectos da condi\u00e7\u00e3o humana, atrav\u00e9s da fam\u00edlia protagonista, que consiste de Homer Jay Simpson, Marjorie (Marge) Bouvier Simpson, Bartholomew (Bart) Simpson, Elisabeth (Lisa) Marie Simpson e Margareth (Maggie) Simpson, cuja vida se passa na fict\u00edcia cidade de Springfield. \n\n<center><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/pt\/e\/e6\/The_Simpsons_promo.png\"><\/center>\n      <center>The SimpsonsTM. Todos os direitos reservados a 20th Century Fox, Gracie Films e principalmente a Rede Fox e a Matt Groening. Copyright, 1989-2013<\/center>","2cdc4137":"# Introdu\u00e7\u00e3o\n\nClassifica\u00e7\u00e3o de imagem Bart e Homer\nDataset images personagens do programa **Os Simpsons**\n\nObjetivo:\n* Criar Rede Neural capaz de classificar\/reconhecer personagens Bart e Homer\n1. Rede Neural Convolucional (CNN)\n2. Treinamento\n3. Resultados\n4. Avalia\u00e7\u00e3o\n5. Exemplo\n\n","33eff59f":"# Treinamento da Rede Neural","b801c425":"## Visualiza\u00e7\u00e3o dos personagens","1f484b5c":"# Verifica\u00e7\u00e3o dos dados","b3e2a19b":"### Pr\u00e9-processamento e Aumento de dados de imagem","34753039":"# Resultados do modelo","15a7dafc":"# Exemplo - Teste Previs\u00e3o com um imagem","a1b160ba":"# Criar Modelo de ***DeepLearning***\n\nRede Neural Convolucional (CNN)","cadd3a3f":"##  Preparar o conjunto de dados\/images ***(Bart e Homer)***","62d70c0e":"# Separa\u00e7\u00e3o Dados de treino e teste\/valida\u00e7\u00e3o","22ab66bf":"# Avalia\u00e7\u00e3o"}}