{"cell_type":{"06145345":"code","59f077d3":"code","825b31ed":"code","0fe35d9e":"code","275cac3d":"code","67779cbc":"code","e1480d2c":"code","c6a12a87":"code","ed4471f4":"code","9ac2658d":"code","2308db0d":"code","a9a3a3f8":"code","e4a6b15a":"code","af0d6516":"code","14b367c4":"code","72dfcdb6":"code","cbc68424":"code","94f5edcd":"code","d7f9624f":"code","166e1887":"code","695b0391":"code","49f831a9":"code","dd8edc89":"code","622e527e":"code","cede1112":"code","9c259ac9":"code","a82755f8":"code","60e320f2":"code","20580ead":"code","2a836d7c":"code","f3a94dc7":"code","bace36d1":"code","a9e79a33":"code","3750e491":"code","a59507b4":"code","212888fb":"code","b227f46b":"code","9dbeee74":"code","6eaaa232":"code","6f3e74ce":"code","0fb563f2":"code","56d3d345":"code","9675b8fa":"code","68e101d9":"code","9ff29b87":"code","32db08b6":"code","450d6ed3":"code","32a5b66d":"code","a40b7ead":"code","2b672056":"code","1fcfc86c":"code","b2303608":"code","b8871636":"code","aab80d3f":"code","0d9d8767":"code","ae1b2e8a":"code","6fb41d62":"code","59381238":"code","f4961323":"code","d0b03919":"markdown","2a8f6e2a":"markdown","5079c98a":"markdown","8ac07b0d":"markdown","9c0de3cb":"markdown","ab938827":"markdown","d0ce58c7":"markdown","fe1f2f9e":"markdown","eae15aa6":"markdown","202052d3":"markdown","0833fe6d":"markdown","6ce932bb":"markdown","75fea9ff":"markdown","518f9310":"markdown","60d55e59":"markdown","771bbfd1":"markdown","16d22f41":"markdown"},"source":{"06145345":"import pandas as pd\nimport numpy as np\nimport pylab\nimport statistics\nfrom statistics import mean\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom array import array\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom pandas import Series,DataFrame\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","59f077d3":"train = pd.read_csv('..\/input\/survivants-du-titanic\/train.csv', sep = ',')\ntest = pd.read_csv('..\/input\/survivants-du-titanic\/test.csv', sep =',')\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nPassengerId = test['PassengerId']","825b31ed":"train.head()","0fe35d9e":"def plot_correlation_map( train ):\n    corr = train.corr()\n    _ , ax = plt.subplots( figsize =( 8 , 8 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(\n        corr, \n        cmap = cmap,\n        square=True, \n        cbar_kws={ 'shrink' : .9 }, \n        ax=ax, \n        annot = True, \n        annot_kws = { 'fontsize' : 12 }\n    )\nplot_correlation_map(train)","275cac3d":"def plot_cat(data, x_axis, y_axis, hue):\n    plt.figure()    \n    sns.barplot(x=x_axis, y=y_axis, hue=hue, data=data)\n    sns.set_context(\"notebook\", font_scale=1.6)\n    plt.legend(loc=\"upper right\", fontsize=\"medium\")\nplot_cat(train,\"Sex\", \"Survived\", None) ","67779cbc":"plot_cat(train,\"Pclass\", \"Survived\", \"Sex\") \nplot_cat(train,\"Pclass\", \"Survived\", None)","e1480d2c":"# On observe qu'une grande majorit\u00e9 des victimes provient de la 3eme classe. (pas surprenant).\n# En premi\u00e8re classe, le ratio est invers\u00e9.","c6a12a87":"pd.isnull(train).sum() #donn\u00e9es manquantes","ed4471f4":"train.head(2)","9ac2658d":"train.shape","2308db0d":"# On index le dataframe avec la variable 'Passengerld' car elle n'apporte aucune information int\u00e9ressante","a9a3a3f8":"train.set_index('PassengerId', inplace =True, drop =True )","e4a6b15a":"train.columns","af0d6516":"train.dtypes","14b367c4":"train.count()","72dfcdb6":"def parse_model_0(X):\n    target = X.Survived\n    X=X[['Fare','SibSp','Parch']] #(Valeurs ayant des donn\u00e9es compl\u00e8tes)\ud83d\ude0a\n    return X, target","cbc68424":"X,y = parse_model_0(train.copy())","94f5edcd":"X.head(2)","d7f9624f":"def compute_score(clf, X, y):\n    xval = cross_val_score(clf, X, y, cv = 5)\n    return mean(xval) \n#le jeu de donn\u00e9es \u00e9tant tr\u00e8s petit, le score varie beaucoup. On prend donc la moyenne)","166e1887":"lr = LogisticRegression()\ncompute_score( lr , X , y )","695b0391":"train1 = pd.get_dummies(train, columns=['Pclass'])","49f831a9":"def parse_model_1(X):\n    target = X.Survived\n    X=X[['Fare','SibSp','Parch','Pclass_1','Pclass_2','Pclass_3']] \n    return X, target","dd8edc89":"X,y = parse_model_1(train1.copy())","622e527e":"def compute_score(clf, X, y):\n    xval = cross_val_score(clf, X, y, cv = 5)\n    return mean(xval) \n#le jeu de donn\u00e9es \u00e9tant tr\u00e8s petit, le score varie beaucoup. On prend donc la moyenne)","cede1112":"X.head(2)","9c259ac9":"lr = LogisticRegression()\ncompute_score(lr,X,y)","a82755f8":"lr = LogisticRegression()\nlr.fit(X,y)\nprint (lr.coef_)","60e320f2":"# 2 possibilit\u00e9s. On va donc bin\u00e9ariser le sex.","20580ead":"train2 = pd.get_dummies(train1, columns=['Sex'])","2a836d7c":"def parse_model_2(X):\n    target = X.Survived\n    X=X[['Fare','SibSp','Parch','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male']] #(Valeurs ayant des donn\u00e9es compl\u00e8tes)\ud83d\ude0a\n    return X, target","f3a94dc7":"X,y = parse_model_2(train2.copy())","bace36d1":"def compute_score(clf, X, y):\n    xval = cross_val_score(clf, X, y, cv = 5)\n    return mean(xval) \n#le jeu de donn\u00e9es \u00e9tant tr\u00e8s petit, le score varie beaucoup. On prend donc la moyenne)","a9e79a33":"X.head(2)","3750e491":"lr = LogisticRegression()\ncompute_score(lr,X,y)","a59507b4":"# On augmente de 10 points. Le Sex \u00e9tait donc une variable tr\u00e8s importante (\"Les femmes d'abord\"\ud83d\ude04)","212888fb":"# On va remplacer les valeurs manquantes par la m\u00e9diane","b227f46b":"train[\"Age\"].fillna(train[\"Age\"].median(), inplace=True)\n# convert from float to int\ntrain2['Age'] = train['Age'].astype(int)","9dbeee74":"def parse_model_3(X):\n    target = X.Survived\n    X = X[['Age','Fare','SibSp','Parch','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male']]\n    return X, target","6eaaa232":"X,y = parse_model_3(train2.copy())","6f3e74ce":"X.head(2)","0fb563f2":"def compute_score(clf, X, y):\n    xval = cross_val_score(clf, X, y, cv = 5)\n    return mean(xval) \n#le jeu de donn\u00e9es \u00e9tant tr\u00e8s petit, le score varie beaucoup. On prend donc la moyenne)","56d3d345":"lr = LogisticRegression()\ncompute_score(lr,X,y)","9675b8fa":"# La variable 'Age' a \u00e9t\u00e9 mal utilis\u00e9. Elle fait baisser le score. Il pourrait \u00eatre interessant de faire des cat\u00e9gories: \n#Poussins [0,8] - Benjamin[9,12] - Minimes[13,15] - Cadet[15,18] - Junior[19,35] - Senior[35,60] - V\u00e9t\u00e9ran[61,90]","68e101d9":"rf = RandomForestClassifier()\ncompute_score(rf,X,y)","9ff29b87":"# On pourra ajouter les autres variables:\n#'Name': On peut s'interresser au rang social en donnant du poids au titre ((Dr, Major, Miss...))\ud83e\uddd0\n#'Cabin': Trop d'informations manquantes\ud83d\ude22","32db08b6":"from sklearn.model_selection import train_test_split","450d6ed3":"X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2, random_state=42)","32a5b66d":"clf = LGBMClassifier(n_estimators=200, max_depth=2)","a40b7ead":"clf.fit(X_train,y_train)","2b672056":"scores = cross_val_score(clf,X,y,scoring='f1', cv=5)\nprint('FScore')\nprint(np.mean(scores))\nprint(np.std(scores))","1fcfc86c":"%%time\nscores = cross_val_score(clf,X,y,scoring='recall', cv=5)\nprint('Recall')\nprint(np.mean(scores))\nprint(np.std(scores))","b2303608":"scores = cross_val_score(clf,X,y,scoring='precision', cv=5)\nprint('Precision')\nprint(np.mean(scores))\nprint(np.std(scores))","b8871636":"%%time\nscores = cross_val_score(clf,X,y, cv=5)\nprint('Accuracy')\nprint(np.mean(scores))\nprint(np.std(scores))","aab80d3f":"scores = cross_val_score(clf,X,y,scoring='roc_auc', cv=5)\nprint('AUC')\nprint(np.mean(scores))\nprint(np.std(scores))","0d9d8767":"# Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_pred_rf = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)","ae1b2e8a":"# Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nY_pred = logreg.predict(X_test)\nlogreg.score(X_train, y_train)","6fb41d62":"# Support Vector Machines\nsvc = SVC()\nsvc.fit(X_train, y_train)\nY_pred = svc.predict(X_test)\nsvc.score(X_train, y_train)","59381238":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\nY_pred = knn.predict(X_test)\nknn.score(X_train, y_train)","f4961323":"# get Correlation Coefficient for each feature using Logistic Regression\ncoeff_train = DataFrame(train.columns.delete(0))\ncoeff_train.columns = ['Features']\ncoeff_train[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n\n# preview\ncoeff_train","d0b03919":"### On augmente de 2 points avec la Class","2a8f6e2a":"## Visualisation des donn\u00e9es\n","5079c98a":"### Variable 'Sex'","8ac07b0d":"### Premier mod\u00e8le sur les donn\u00e9es compl\u00e8tes (model_0)","9c0de3cb":"#### Un score de 0.674548857768335 \u00e0 am\u00e9liorer","ab938827":"### Variable 'Class'","d0ce58c7":"### Score \u00e0 l'aide du Random forest: le mod\u00e8le n'\u00e9tant pas lin\u00e9aire.","fe1f2f9e":"## donn\u00e9es manquantes","eae15aa6":"# Nettoyage des donn\u00e9es","202052d3":"## Importation des librairies","0833fe6d":"# On va entrainer le mod\u00e8le: train\/test","6ce932bb":"# Excellent score \u263a\ufe0f","75fea9ff":"On va travailler uniquement sur les valeurs compl\u00e8tes (qui n'ont besoin d'aucune modification): 'Fare','Sibsp','Parch'.","518f9310":"### Variable 'Age'","60d55e59":"#### Correspond au poids de chaque variable dans la r\u00e9gression.\n#### 'Fare' influe peu. Par contre La 'Class_3' a une grande influence (n\u00e9gative: bcp de morts) 'Parch' et 'Class_1' on une inflence positive.","771bbfd1":"## Importation des donn\u00e9es brutes\n","16d22f41":"#                            -  Titanic by William SECK  -\n"}}