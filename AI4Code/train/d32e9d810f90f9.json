{"cell_type":{"47fd1544":"code","7c120628":"code","8772b928":"code","24fd90dc":"code","bf959822":"code","97248542":"code","1369a84b":"code","065b6921":"code","349dbb7e":"code","d5d36502":"code","46e8a6b9":"code","8d387f35":"code","e5352def":"code","6f83491b":"code","4e982e70":"code","5983cbfd":"code","8bf4a87d":"code","6bed4205":"code","030a8ada":"code","71cb5ad0":"code","3944e26b":"code","574eb4ef":"code","c6b36ca8":"code","f79c1a9a":"code","6d660893":"code","752062c1":"code","9d7667ce":"code","16820c6e":"code","14af1ec3":"code","d5c17270":"markdown","c3546d82":"markdown","e76502b3":"markdown","2b96aba4":"markdown","04ba2eb5":"markdown","24f87356":"markdown","43d37b4a":"markdown","faa9e9cc":"markdown","7d5993f9":"markdown","25198a7d":"markdown","07f1c623":"markdown","ddc6fe41":"markdown"},"source":{"47fd1544":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn import preprocessing\nfrom sklearn.metrics import r2_score\nimport sklearn\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport math\n%matplotlib inline\n\n\nboston_df = pd.DataFrame(load_boston().data,columns = load_boston().feature_names)\n\nboston = sklearn.datasets.load_boston(return_X_y=False)\ndataf = pd.DataFrame(boston.data)\n\ny = load_boston().target\nx = load_boston().data\n\nboston_df.head(5)","7c120628":"boston_df[\"Price\"] = y\nboston_df.head()","8772b928":"print(boston.DESCR)","24fd90dc":"boston_df.describe()","bf959822":"fig,ax = plt.subplots(figsize= (7,5))\nax.scatter(boston_df.CRIM,boston_df.Price,s=3)","97248542":"boston_df[boston_df.CRIM >30]","1369a84b":"for i in range(len(x)-9):\n    if x[i][0] > 30:\n        x = np.delete(x,i,0)\n        y = np.delete(y,i,0)\n#outliers deleted\nfor i in range(len(x)-9):\n    if x[i][0] > 30:\n        print(\"True\")","065b6921":"boston_df.drop(index=[380,398,404,405,410,414,418,427],inplace=True)","349dbb7e":"fig,ax = plt.subplots(figsize= (7,5))\nax.scatter(boston_df.Price,boston_df.ZN,s=3)","d5d36502":"len(boston_df[boston_df.ZN > 80])","46e8a6b9":"fig,ax = plt.subplots(figsize= (7,5))\nax.scatter(boston_df.Price,boston_df.B,s=3)","8d387f35":"len(boston_df[boston_df.B < 150])","e5352def":"fig,ax = plt.subplots(figsize= (7,5))\nax.scatter(boston_df.Price,boston_df.INDUS,s=3)","6f83491b":"boston_df[boston_df.INDUS > 27.5]","4e982e70":"x = np.delete(x,489,0)\ny = np.delete(y,490,0)","5983cbfd":"boston_df.drop(index=[489,490],inplace=True)","8bf4a87d":"boston_df.corr('pearson')","6bed4205":"kendall = abs(boston_df.corr(method=\"kendall\").Price).to_dict()\npearson = abs(boston_df.corr(method=\"pearson\").Price).to_dict()\nspearman = abs(boston_df.corr(method=\"spearman\").Price).to_dict()\n\nprint(\"\\t\\tPearson\\t\\tKendall\\t\\tSpearman\")\nfor p,k,s in zip(pearson.items(),kendall.items(),spearman.items()):\n    print(\"\\t{}\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(p[0],p[1],k[1],s[1]))","030a8ada":"kendall = abs(boston_df.corr(method=\"kendall\").Price).to_dict()\npearson = abs(boston_df.corr(method=\"pearson\").Price).to_dict()\nspearman = abs(boston_df.corr(method=\"spearman\").Price).to_dict()\n\nprint(\"\\t\\tPearson\\t\\tKendall\\t\\tSpearman\")\nfor p,k,s in zip(pearson.items(),kendall.items(),spearman.items()):\n    if p[1] >.50 or s[1] > .50 or k[1] > .50:\n        print(\"\\t{}\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(p[0],p[1],k[1],s[1]))\n    ","71cb5ad0":"temp = abs(boston_df.corr('pearson').Price).to_dict()\nfrom collections import Counter\nvar = Counter(temp)\ntop_features = var.most_common(4)\ndel top_features[0]\nprint(top_features)","3944e26b":"fig1,ax1 = plt.subplots()\nfig1.set_size_inches(12,7.5)\nax1.set_ylabel('Price')\nax1.set_xlabel('Low status Popolation %')\nax1.set_title('Relationship Between Price and Low status Population')\nc = boston_df['Price']\nplt.scatter(boston_df.LSTAT, boston_df.Price, c=c, cmap = 'copper_r', alpha =0.6)  \ncbar = plt.colorbar()\ncbar.set_label('Price')","574eb4ef":"boston_df[\"LSTAT\"].to_frame().boxplot()","c6b36ca8":"boston_df[boston_df.LSTAT > 4]","f79c1a9a":"fig1,ax1 = plt.subplots()\nfig1.set_size_inches(12,7.5)\nax1.set_ylabel('Price')\nax1.set_xlabel('Number of Rooms')\nax1.set_title('Relationship Between Price and Number of Rooms')\nc = boston_df['Price']\nplt.scatter(boston_df.RM, boston_df.Price,c=c, \n            cmap = 'autumn_r', alpha =0.5)  \ncbar = plt.colorbar()\ncbar.set_label('Price')","6d660893":"fig1,ax1 = plt.subplots()\nfig1.set_size_inches(12,7.5)\nax1.set_ylabel('Price')\nax1.set_xlabel('Commercial Businesses')\nax1.set_title('Relationship Between Price and Industires in the town')\nc = boston_df['Price']\nplt.scatter(boston_df.INDUS, boston_df.Price,c=c, \n            cmap = 'copper_r', alpha =0.5)  \ncbar = plt.colorbar()\ncbar.set_label('Price')","752062c1":"#Train and Test set split into 80% and 20% respectively\nx_train, x_rest, y_train, y_rest = train_test_split(x,y,test_size = .4,random_state =0)\n\n#Rest of the 40% set split into equal parts of Train and Validation set \nx_test, x_val, y_test, y_val = train_test_split(x_train,y_train,test_size = .5,random_state = 0)\n\n#Therefore : Train = 60%, Test = 20% and Validation = 20%\nprint(len(x_train),len(y_train))\nprint(len(x_val),len(y_val))\nprint(len(x_test),len(y_test))","9d7667ce":"#preprocessing is necessary for SDG Regressor\n\nscaler = preprocessing.StandardScaler().fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)\nx_val = scaler.transform(x_val)\n\ny_train = y_train.reshape(-1)\ny_test = y_test.reshape(-1)\ny_val = y_val.reshape(-1)","16820c6e":"clf_sdg = SGDRegressor(max_iter= 5000,eta0=0.0001,learning_rate='constant')\n#learning rate is default = 0.01 as constant = eta0\n\nclf_sdg.fit(x_train,y_train)\n\ny_hat_test = clf_sdg.predict(x_test)\ny_hat_val = clf_sdg.predict(x_val)\ny_hat_train = clf_sdg.predict(x_train)\n\ntest_score = clf_sdg.score(x_test,y_test)\ntrain_score = clf_sdg.score(x_train,y_train)\nval_score = clf_sdg.score(x_val,y_val)","14af1ec3":"print(\"R2-score Train: \\t\\t%.2f\" % r2_score(y_hat_train , y_train) )\nprint(\"R2-score Test: \\t\\t\\t%.2f\" % r2_score(y_hat_test , y_test) )\nprint(\"R2-score Validation: \\t\\t%.2f\" % r2_score(y_hat_val , y_val) )\nprint(\"------------------------------------\")\nprint(\"Train score : \\t\\t\\t%.2f\"%train_score)\nprint(\"Test score : \\t\\t\\t%.2f\"%test_score)\nprint(\"Validation Score : \\t\\t%.2f\"%val_score)\n\nprint(\"RMSE test : %3f\"%math.sqrt(mean_squared_error(y_test,y_hat_test)))\nprint(\"RMSE train : %3f\"%math.sqrt(mean_squared_error(y_train,y_hat_train)))\nprint(\"RMSE val : %3f\"%math.sqrt(mean_squared_error(y_val,y_hat_val)))\nprint(\"MAE test : %3f\"%(mean_absolute_error(y_test,y_hat_test)))\nprint(\"MAE train : %3f\"%(mean_absolute_error(y_train,y_hat_train)))\nprint(\"MAE val : %3f\"%(mean_absolute_error(y_val,y_hat_val)))","d5c17270":"# Investigation to improve ML model by Exlporatory Data Analysis\n\n## Dataset : Boston Housing Data","c3546d82":"Let's explore top three features with highest correlation to the Price of a house in Boston.","e76502b3":"### Removing outliers from ZN","2b96aba4":"We can see a lot of outliers in this distribution which will affect our model","04ba2eb5":"Outliers :\n* suspected in CRIM as mean is 3.6, 75th percentile is 3.6 but max is 88. (Removed)\n* ZN as mean is 11.1, 75th percentile is 12.5 but max is 100 (Not removed due significant number of points)\n* suspected in B as min is .32 but 25th percentile is 376 with mean as 356 (Not-Removed as corr is very low < 20%)\n* suspected in INDUS as min is < 1 but 25th percentile is 5 and mean is 11","24f87356":"As per the Pearson Correlation Coefficient third most effective feature is Pupil-Teacher Ratio but Kendall and Spearman Rank coefficeints clearly show that proportion of non-retail business acres per town has a higher correlation. (INDUS) ","43d37b4a":"\nI will choose to remove the outliers altogether, instead of renormalizing them in any other way.","faa9e9cc":"### Outliers in B","7d5993f9":"<a href=\"https:\/\/colab.research.google.com\/github\/JARACH-209\/DataAnalytics\/blob\/master\/DataAnalysis_BostonHousing.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","25198a7d":"### Top 3 factors that affect the price are :\n* Percentage of low status population\n* Numeber of Rooms in house\n* INDUS : Commercial businesses in town\n\n(As per Pearson correlation PT ratio is 3rd but Kendall and Spearman show that INDUS is 3rd most effective feature)","07f1c623":"Decided not to remove any points from ZN","ddc6fe41":"### Removing outliers from CRIM"}}