{"cell_type":{"42708323":"code","ebd1666a":"code","3856eb5c":"code","60272774":"code","2b582666":"code","c6a39023":"code","0ca69540":"code","8396f544":"code","f9708537":"code","2df835ce":"code","14968212":"code","ce338ed6":"markdown","001d2219":"markdown","3a659977":"markdown","ead47b21":"markdown","788a3a1e":"markdown","4b90fade":"markdown","7f3087ee":"markdown","304a7a5a":"markdown","c86b55ca":"markdown"},"source":{"42708323":"import pandas as pd\nimport os,cv2\nfrom IPython.display import Image\nfrom keras.preprocessing import image\nfrom keras import optimizers\nfrom keras import layers,models\nfrom keras.applications.imagenet_utils import preprocess_input\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import DenseNet121, DenseNet169, DenseNet201\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nprint(os.listdir(\"..\/input\"))\n\nimport numpy as np","ebd1666a":"input_path = '..\/input\/'\ntrain_path = input_path + 'train\/train\/'\ntest_path = input_path + 'test\/test\/'\n\ntrain_dir=\"..\/input\/train\/train\"\ntest_dir=\"..\/input\/test\/test\"\ntrain_df=pd.read_csv('..\/input\/train.csv')\n\ntest_df=pd.read_csv('..\/input\/sample_submission.csv')\n\ntrain_id = train_df['id']\nlabels = train_df['has_cactus']\ntest_id = test_df['id']","3856eb5c":"x_train, x_val, y_train, y_val = train_test_split(train_id, labels, test_size=0.2)","60272774":"def get_images(ids, filepath):\n    arr = []\n    for img_id in ids:\n        img = plt.imread(filepath + img_id)\n        arr.append(img)\n    \n    arr = np.array(arr).astype('float32')\n    arr = arr \/ 255\n    return arr","2b582666":"x_train = get_images(ids=x_train, filepath=train_path)\nx_val = get_images(ids=x_val, filepath=train_path)\ntest = get_images(ids=test_id, filepath=test_path)\n\nimg_dim = x_train.shape[1:]","c6a39023":"fig, ax = plt.subplots(nrows=2, ncols=3)\nax = ax.ravel()\nplt.tight_layout(pad=0.2, h_pad=2)\n\nfor i in range(6):\n    ax[i].imshow(x_train[i])\n    ax[i].set_title('has_cactus = {}'.format(y_train.iloc[i]))","0ca69540":"batch_size = 64\nepochs = 30\nsteps = x_train.shape[0] \/\/ batch_size","8396f544":"inputs = Input(shape=img_dim)\n\ndensenet121 = DenseNet121(weights='imagenet', include_top=False)(inputs)\n\nflat1 = Flatten()(densenet121)\ndense1 = Dense(units=256, use_bias=True)(flat1)\nbatchnorm1 = BatchNormalization()(dense1)\nact1 = Activation(activation='relu')(batchnorm1)\ndrop1 = Dropout(rate=0.5)(act1)\n\nout = Dense(units=1, activation='sigmoid')(drop1)\n\nmodel = Model(inputs=inputs, outputs=out)\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","f9708537":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=2, mode='max')\n\nimg_aug = ImageDataGenerator(rotation_range=20, vertical_flip=True, horizontal_flip=True)\nimg_aug.fit(x_train)\n\nmodel.fit_generator(img_aug.flow(x_train, y_train, batch_size=batch_size), \n                    steps_per_epoch=steps, epochs=epochs, \n                    validation_data=(x_val, y_val), callbacks=[reduce_lr], \n                    verbose=2)","2df835ce":"test_pred = model.predict(test, verbose=2)","14968212":"test_df['has_cactus'] = test_pred\ntest_df.to_csv('submission.csv', index=False)","ce338ed6":"## Define batch size, epochs and steps","001d2219":"## Create submission file","3a659977":"## Load libraries","ead47b21":"## Define model","788a3a1e":"## Plot data","4b90fade":"## Load images","7f3087ee":"## Get predictions","304a7a5a":"## Split data into training and validation sets","c86b55ca":"## Read csv data"}}