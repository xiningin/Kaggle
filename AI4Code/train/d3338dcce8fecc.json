{"cell_type":{"f1720929":"code","64c29170":"code","2d447db3":"code","cfdf7df0":"code","d5854213":"code","23ecf085":"code","88dd60f2":"code","0fd55a25":"code","5ff57dda":"code","52ccbcd1":"code","1e57ef8e":"code","8bfd2669":"code","7a2f6fad":"code","aa8e14b5":"code","73ac32d5":"code","99e4d7e9":"code","a1ed4e1e":"code","e79c5aad":"code","f89b3c8a":"code","d5c53117":"code","02b799fb":"code","fed34192":"code","8e332a61":"code","c48e0c20":"code","15e66e78":"code","3f34f683":"code","836a852e":"code","ca22e6a7":"code","88c853b6":"code","043fec49":"code","e379eeaa":"code","57c1159b":"code","14d429a6":"code","eb5eb117":"code","cd9a43e2":"code","2e782d59":"markdown","7524abd8":"markdown","9f1a17b3":"markdown","7e3a103e":"markdown"},"source":{"f1720929":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64c29170":"df=pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","2d447db3":"df.head()","cfdf7df0":"df.isnull().any()","d5854213":"df.describe()","23ecf085":"df.info()","88dd60f2":"cor=df.corr()\ncor","0fd55a25":"import seaborn as sns","5ff57dda":"sns.heatmap(cor)","52ccbcd1":"t=abs(cor['DEATH_EVENT'])","1e57ef8e":"colls=t[t>0.1]\ncolls.index","8bfd2669":"#features=['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']","7a2f6fad":"x=df.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11]]\ny=df.DEATH_EVENT","aa8e14b5":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.2)\nx_train.shape","73ac32d5":"from sklearn.preprocessing import StandardScaler\ns=StandardScaler()","99e4d7e9":"x_train=s.fit_transform(x_train)\nx_test=s.transform(x_test)","a1ed4e1e":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam","e79c5aad":"#initializing the model\nmodel=Sequential()\n","f89b3c8a":"#adding first layer(input layer)\nmodel.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu',input_dim=12))","d5c53117":"#adding second layer\n\nmodel.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))","02b799fb":"#adding third layer\n\nmodel.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))","fed34192":"#adding fourth layer(output layer)\n\nmodel.add(Dense(units=1,kernel_initializer='he_uniform',activation='sigmoid'))","8e332a61":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","c48e0c20":"model.fit(x_train,y_train,batch_size=30,epochs=300)","15e66e78":"pred=model.predict(x_test)\npred=(pred>0.5)","3f34f683":"from sklearn.metrics import confusion_matrix,accuracy_score","836a852e":"print(confusion_matrix(y_test,pred))","ca22e6a7":"print(accuracy_score(y_test,pred))","88c853b6":"from keras.wrappers.scikit_learn import KerasClassifier","043fec49":"def create_my_model(batchsize,epochs):\n    mymodel=Sequential()\n    mymodel.add(Dense(6,input_dim=12,activation='relu'))\n    mymodel.add(Dense(6,input_dim=12,activation='relu'))\n    mymodel.add(Dense(1,activation='sigmoid'))\n    mymodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n    return mymodel","e379eeaa":"model1=KerasClassifier(build_fn=create_my_model)","57c1159b":"batchsize=[10,20,30,40,60,80,100]\nepochs=[500,1000,1500]","14d429a6":"parameter_grid=dict(batch_size=batchsize,epochs=epochs)","eb5eb117":"from sklearn.model_selection import RandomizedSearchCV","cd9a43e2":"mygrid=RandomizedSearchCV(model,parameter_grid,n_jobs=-1,cv=3)","2e782d59":"# building ANN model","7524abd8":"# data preprocessing","9f1a17b3":"# and find your best estimators","7e3a103e":"# importing suitable libraries"}}