{"cell_type":{"ce4f1a9c":"code","a441350f":"code","cf34f8b3":"code","f076d31e":"code","e6184170":"code","7bd7a98c":"code","1864d33a":"code","27900664":"code","013d5ab2":"code","7b235012":"code","95571e21":"code","10e376be":"code","ca9d6477":"code","0bf3892d":"code","b97110b6":"code","3f9af2e0":"code","f10c4c45":"code","7aa5f63b":"code","df1a05b0":"code","6fcadab2":"code","1e7ddc7a":"markdown","da6187d6":"markdown","79222fcf":"markdown","11c3aafb":"markdown","30a0b5ae":"markdown","b56ecfef":"markdown","68f8520c":"markdown","04c71ca6":"markdown","f3efbb2c":"markdown","3c305792":"markdown","1438765c":"markdown","d345df32":"markdown","8dcc7e67":"markdown","069fce59":"markdown","da64427d":"markdown","6ec93dbf":"markdown"},"source":{"ce4f1a9c":"import os\nimport zipfile\nimport random\nimport shutil\nfrom shutil import copyfile\nfrom os import getcwd\nimport pathlib\nimport datetime\nfrom distutils.dir_util import copy_tree\n\nimport cv2\nfrom PIL import Image\n\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.models import model_from_json\nfrom sklearn.model_selection import train_test_split\n\n\nimport matplotlib.pylab as plt\nimport numpy as np\n\n#Write twice, because sometimes it does not work the first time, especially if you are switching back to notebook\n%matplotlib notebook\n%matplotlib notebook","a441350f":"# This is already done. No need to copy the images again!\nfromDir = \"..\/input\/microsoft-catsvsdogs-dataset\/PetImages\"\ntoDir = \"\/kaggle\/working\/CatsAndDogs\/Pet_images_new\"\n\ncopy_tree(fromDir, toDir)","cf34f8b3":"current_working_dir = os.getcwd()\n\npath_to_images = pathlib.Path(os.path.join(current_working_dir, 'CatsAndDogs','Pet_images_new'))\n\n#current_working_dir = pathlib.Path('..','input','microsoft-catsvsdogs-dataset') #os.getcwd()\n#path_to_images = pathlib.Path(os.path.join(current_working_dir, 'PetImages'))\nDogs_dir = os.path.join(path_to_images, 'Dog')\nCats_dir = os.path.join(path_to_images, 'Cat')\n\nprint(len(os.listdir(Dogs_dir)))\nprint(len(os.listdir(Cats_dir)))\n\n\ndog_image_fnames = os.listdir(Dogs_dir)\ncat_image_fnames = os.listdir(Cats_dir)\n","f076d31e":"num_skipped = 0\nfor folder_name in (\"Cat\", \"Dog\"):\n    folder_path = os.path.join(path_to_images, folder_name)\n    for fname in os.listdir(folder_path):\n        fpath = os.path.join(folder_path, fname)\n        try:\n            fobj = open(fpath, \"rb\")\n            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n        finally:\n            fobj.close()\n\n        if not is_jfif:\n            num_skipped += 1\n            # Delete corrupted image\n            os.remove(fpath)\n\nprint(\"Deleted %d images\" % num_skipped)","e6184170":"#remove 0 size images and non jpg images\nimport os\n\nj=0\nfor catagory in os.listdir(path_to_images):\n    sub_dir = os.path.join(path_to_images, catagory)\n    for name in os.listdir(sub_dir):\n        fpath = os.path.join(sub_dir,name)\n        if name.split('.')[1] == 'jpg':\n            if os.path.getsize(fpath) <= 0:\n                if os.path.isfile(fpath) == False:\n                    print(fpath)\n                os.remove(fpath)\n            elif os.path.getsize(fpath) > 0:\n                j +=1\n        if name.split('.')[1] != 'jpg':\n            print(fpath)\n            os.remove(fpath)\nprint(j)","7bd7a98c":"#Count total images\nimage_count = len(list(path_to_images.glob('*\/*.jpg')))\nprint(image_count)","1864d33a":"#Check below files in both Cat and Dog folder and remove those which are non-cat\/dog images\nfile_names_of_bad_images = ['5673.jpg','4688.jpg','12376.jpg','1043.jpg','8456.jpg',\n                      '9517.jpg','7377.jpg','1773.jpg','8736.jpg','10712.jpg','7564.jpg']\n\n# remove and copy bad images to a separate folder bad_images and plot below.","27900664":"\n# path_bad_images = pathlib.Path(os.path.join(current_working_dir, 'CatsAndDogs','bad_images'))\n# bad_images = os.listdir(path_bad_images)\n# print(len(bad_images))","013d5ab2":"# plt.figure(figsize=(8,8))\n# for i in np.arange(9):\n#     img = Image.open(os.path.join(path_bad_images,bad_images[i]))\n#     ax = plt.subplot(3, 3, i + 1)\n#     plt.imshow(img)\n#     #plt.title(class_names[labels[i]])\n#     plt.axis(\"off\")","7b235012":"batch_size = 64  # max 1000 of these images can fit in gpu memory\nnew_img_size = (200,200)\ndata_split = 0.2 #0.0005\nseed_value = 42\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    path_to_images,\n    validation_split=data_split,\n    subset=\"training\",\n    seed=seed_value,\n    image_size=new_img_size,\n    batch_size=batch_size)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    path_to_images,\n    validation_split=data_split,\n    subset=\"validation\",\n    seed=seed_value,\n    image_size=new_img_size,\n    batch_size=batch_size)","95571e21":"class_names = train_ds.class_names\nprint(class_names)\n","10e376be":"\nplt.figure(figsize=(8,8))\nfor images, labels in val_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","ca9d6477":"model = tf.keras.models.Sequential([\n    layers.experimental.preprocessing.Rescaling(1.\/255,input_shape=(new_img_size[0],new_img_size[1],3)),\n    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.3),\n    \n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n    tf.keras.layers.Dropout(0.35),\n    #tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['acc']) #SGD(lr=0.007, momentum=0.9), #RMSprop(lr=0.0001), #Adam(lr=0.001)\n#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n\n#print(model.summary())","0bf3892d":"class MyThresholdCallback(tf.keras.callbacks.Callback):\n    def __init__(self, threshold):\n        super(MyThresholdCallback, self).__init__()\n        self.threshold = threshold\n\n    def on_epoch_end(self, epoch, logs=None): \n        val_acc = logs[\"val_acc\"]\n        if val_acc >= self.threshold:\n            self.model.stop_training = True\n\nearly_stopping_callback = MyThresholdCallback(threshold=0.951)\n\nlogdir = os.path.join(\n    \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nmodelfname = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.h5'\n\n\nmodel_folder = pathlib.Path(os.path.join(current_working_dir, 'CatsAndDogs','model'))\nmcp_save = tf.keras.callbacks.ModelCheckpoint(os.path.join(model_folder, modelfname), save_best_only=True, monitor='val_loss', mode='min')\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n\nprint(logdir)\n# # ======= Go to the logs folder within the current project. ===========\n# # ======= Open a terminal, activate correct env, run following command to launch tensorboard\n# # tensorboard --port=6007 --logdir ~\/CatsAndDogs\/logs\n# # =====================================================================\n\nepochs = 300\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs,\n    verbose=1,\n    callbacks=[tensorboard_callback, mcp_save, early_stopping_callback]\n)\n\n#model.save(os.path.join(model_folder, modelfname))\n","b97110b6":"# PLOT LOSS AND ACCURACY\n\nacc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=np.arange(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.figure()\nplt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.legend()\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.figure()\nplt.plot(epochs, loss, 'r', label=\"Training Loss\")\nplt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\nplt.legend()\n\nplt.title('Training and validation loss')\n\n# Desired output. Charts with training and validation metrics. No crash :)","3f9af2e0":"mkdir -p \/kaggle\/working\/CatsAndDongs\/model","f10c4c45":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(pathlib.Path(os.path.join(current_working_dir, 'CatsAndDogs','model','model_structure.json')), \"w\") as json_file:\n    json_file.write(model_json)","7aa5f63b":"# load json and create model\njson_file = open(pathlib.Path(os.path.join(current_working_dir, 'CatsAndDogs','model','model_structure.json')), 'r')\nloaded_model_json = json_file.read()\njson_file.close()\n\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(pathlib.Path(os.path.join(current_working_dir, 'CatsAndDogs','model','model_structure.json',modelfname)))\nprint(\"Loaded model from disk\")\n \n# evaluate loaded model on test data\nloaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","df1a05b0":"for images, labels in val_ds.take(1):\n    i = random.randint(0,10)\n\nimg_array = keras.preprocessing.image.img_to_array(images[i])\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\n\ntrue_class = np.array(labels[i])\npredicted_class = model.predict_classes(img_array)[0]\npredictions = model.predict(img_array)\nscore = predictions[0]\n\nprint(\"Prediction: \",class_names[predicted_class[0]], \" | Truth: \", class_names[true_class])\nprint(\"Score: \", np.round(score,2))\n\nplt.figure()\nplt.imshow(images[i].numpy().astype(\"uint8\"))\nplt.title(class_names[true_class])\nplt.axis(\"off\")\n","6fcadab2":"## If downloaded image is a cat then set i =0, else set i=1\n# i=0\n# img_name = r\"Coronavirus-and-Cats-Science-Roundup-Catipilla.jpg\"\n# path_to_Downloaded_images = pathlib.Path(current_working_dir, 'CatsAndDogs', 'online_test_images')\n# img_file_path = os.path.join(path_to_Downloaded_images,img_name)\n\n# img = keras.preprocessing.image.load_img( img_file_path, target_size=new_img_size)\n\n# img_array = keras.preprocessing.image.img_to_array(img)\n# img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n\n# predicted_class = loaded_model.predict_classes(img_array)[0]\n# predictions = loaded_model.predict(img_array)\n# score = predictions[0]\n\n# print(\"Prediction: \",class_names[predicted_class[0]], \" | Truth: \", class_names[i])\n# print(\"Score: \", np.round(score,2))\n\n# plt.figure()\n# plt.imshow(img)\n# plt.title(class_names[i])\n# plt.axis(\"off\")","1e7ddc7a":"## Inspect some images\n\nTake 1 batch from the validation dataset and plot.","da6187d6":"# Create model\n\n\nUse at least 3 layers. We will try two models, first a shallow one, second with more layers. \nFor this task yous should expect the shallow model causing an under fit. It is indicative in the loss curve. \nYou may see that the training_loss and accuracy does not improve after a while.\n\nNote also that, we have included on-the-fly image augmentation in the first two layers.\nFurthermore, we use dropout for regularization, to avoid over fitting. We do not want high dropout in the initial layers. It is set to a relatively higher value after flattening the convolution layer outputs.\n\nAnd finally, since we are using ReLu activation function, using kernel_initializer='he_uniform' is highly recommended.\n","79222fcf":"## Set path of the dataset\n\nThe images are under two folders, \/Cat and \/Dog. I do not wish to create separate train and validation folders and copy the images into it. Instead I will write a custom data feeder that will read images, perform preprocessing and feed to the model. We will perform on-the-fly augmentation within the model (by adding extra layers at the start).","11c3aafb":"Move the data to working directory, because input directory is read-only.","30a0b5ae":"## Remove non- cat\/dog images\n\nAfter carefully inspecting the images, I found some images that are neither cats nor dogs. These images may cause the problems in training. If they appear in validation dataset, they may cause spikes in validation loss curve.\nSome examples are plotted below.","b56ecfef":"# Conclusions\n\nWe have developed Convolutional Neural Network based model without using any pre-trained models or transfer learning methods. \nAchieves accuracy of ~95% on validation dataset. The original dataset had many corrupted files, that needed to be removed. Custom image feeder as well as callbacks are created.","68f8520c":"## Test on validation set images","04c71ca6":"# CNN based classification of Cat and Dog WITHOUT transfer learning: 95% validation accuracy","f3efbb2c":"## Test on online\/downloaded images\n\nYou have to download some images from the web.","3c305792":"## Create callbacks","1438765c":"Use the data set: https:\/\/www.kaggle.com\/shaunthesheep\/microsoft-catsvsdogs-dataset?select=PetImages","d345df32":"## Save and Load best model","8dcc7e67":"# Predictions","069fce59":"## Create data feeder\n\n* Resize images\n* define data split fraction\n* batch size\n* seed to shuffle and randomly dividing the training and validation dataset","da64427d":"**Abstract**\n\nThe purpose of this script is to understand various stages of building a good CNN model. Using transfer learning techniques, one can achieve nearly 100% accuracy for this task. However, in this script I will try to build a model from scratch that leads a reasonable accuracy. The final result shows close to 95% on validation dataset.\n\nKey highlights:\n\n* Create a model from scratch without transfer learning.\n* Gain insights on how the depth and width of the model affects the loss curve\n* Create your own data feeder\n* Write custom callbacks for saving best model or early stopper\n* Prediction on any online\/downloaded images","6ec93dbf":"## Delete corrupted images\n\nThere are roughly ~1800 corrupt images. "}}