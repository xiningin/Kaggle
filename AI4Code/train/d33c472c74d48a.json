{"cell_type":{"87d4bba2":"code","318af23a":"code","ffef784e":"code","ad741073":"code","70e57142":"code","cecd3aed":"code","6fc49494":"code","3a3286ca":"code","de15a94e":"code","0d5e2f1c":"code","a2bd3621":"code","68e07dc1":"code","9aebf6df":"code","0b7211f1":"code","05ba6723":"code","f055d311":"code","fb8b99ff":"code","56c21618":"code","7943df73":"code","33c13fb4":"code","73276574":"code","514dfae8":"code","bba79a93":"code","99eaf3a4":"code","fe098833":"code","677e032a":"code","a4086b5c":"code","ed9b2cbc":"code","7deb1adc":"code","5ad6099a":"code","4399d4fd":"code","6d827859":"code","638c5026":"code","2a8e16ac":"code","a3e45bf5":"code","3c164319":"code","08647bbb":"code","954fa5ca":"code","14c795cf":"code","e43db13c":"code","f6def06c":"code","eaca67d7":"code","1007c58e":"code","b16be4fb":"code","5d6eb55d":"code","0078876a":"code","c184b374":"code","32e16b0d":"code","1d0639e2":"code","72937f01":"code","aaffa8b3":"markdown","7786ecfe":"markdown","4eaedaa4":"markdown","bbf710c8":"markdown","7584b9b5":"markdown","ed198aa7":"markdown","5c41828c":"markdown","30fd2fe5":"markdown","3c4c21e2":"markdown","0a572b6e":"markdown","655f37cd":"markdown","37326148":"markdown","3a314537":"markdown","ab9dfd81":"markdown","44317630":"markdown","ebd6c31f":"markdown","5103187c":"markdown","e97c6851":"markdown","5f754eb0":"markdown","82f0e77a":"markdown","534b7da0":"markdown","ed411b63":"markdown","b2042598":"markdown","40b7d248":"markdown","770ddbec":"markdown","c8f77311":"markdown","59705191":"markdown","be01406d":"markdown","0b9aba87":"markdown","01bb2fa2":"markdown","7ba4c207":"markdown","798ab233":"markdown","5f42ac48":"markdown","14d47828":"markdown","3c9868d0":"markdown","50d2a518":"markdown","264f8381":"markdown","df9f3ada":"markdown","407c35ae":"markdown"},"source":{"87d4bba2":"import pandas as pd\nimport numpy as np\n\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')","318af23a":"df = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndf.head()","ffef784e":"df.shape","ad741073":"df.info()","70e57142":"df.describe()","cecd3aed":"df.isna().sum()","6fc49494":"#set color for data visualization\nsns.set(rc={\"axes.facecolor\":\"#EAE0D5\",\"figure.facecolor\":\"#EAE0D5\", \"grid.color\":\"#C6AC8F\",\n            \"axes.edgecolor\":\"#C6AC8F\", \"axes.labelcolor\":\"#0A0908\", \"xtick.color\":\"#0A0908\",\n            \"ytick.color\":\"#0A0908\"})\n\npalettes = ['#9B856A', '#475962', '#598392', '#124559', '#540B0E']\ncmap = colors.ListedColormap(['#9B856A', '#124559', '#475962', '#598392'])","3a3286ca":"sns.pairplot(data=df, y_vars='bmi', x_vars=['age', 'avg_glucose_level'], hue='Residence_type',\n             size=5, palette=['#9B856A', '#475962'])","de15a94e":"df['gender'].value_counts()","0d5e2f1c":"plt.figure(figsize=(8,5))\nsns.boxplot(data=df, x='gender', y='bmi', palette=palettes)","a2bd3621":"df = df[df['gender'] != 'Other']","68e07dc1":"#total number of male and female in dataset\nvalue = df['gender'].value_counts().sort_values().values\n\n#percentage of male and female\npercent = (df['gender'].value_counts()*100\/len(df)).sort_values().values\n\nidx = df['gender'].value_counts().sort_values().index.values","9aebf6df":"plt.figure(figsize=(8,5))\nax = sns.barplot(data=df, x=idx, y=percent, palette=palettes, edgecolor=palettes)\n\n#set y axis to percentage\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\n\nax.set_title('Distribution of Gender in Dataset', weight='bold', fontsize=14)\nax.set_xlabel('gender')\nax.set_ylabel('% of gender')\n\n#place text in barplot\nfor i,v in enumerate(percent):\n    #(x position, y position, text, ...)\n    ax.text(i, v-10, 'Total:{}\\n{:.2f}%'.format(value[i],v), horizontalalignment='center', weight='bold', color='white', fontsize=14)","0b7211f1":"sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap=cmap)","05ba6723":"df.drop(['id', 'bmi'], axis=1, inplace=True)","f055d311":"ax = sns.kdeplot(data=df, x='age', palette=palettes, color='#475962', fill=True)\n\nax.annotate('Highest Density', weight='bold', xy=(50,0.016), xytext=(-10,0.015),\n            arrowprops=dict(facecolor='#475962', edgecolor='#475962', shrink=0.05))","fb8b99ff":"sns.jointplot(data=df, x='age', y='heart_disease', hue='stroke', kind='kde', fill=False, palette=['#9B856A', '#475962'])","56c21618":"sns.jointplot(data=df, x='age', y='avg_glucose_level', hue='stroke', kind='kde', fill=False, palette=['#9B856A', '#475962'])","7943df73":"g = sns.FacetGrid(data=df, row='work_type', col='Residence_type', hue='stroke',\n                  size=2.5, aspect=2, palette=palettes)\ng.map(plt.scatter, 'age', 'avg_glucose_level', edgecolor='#EAE0D5', lw=0.2)","33c13fb4":"df[df['stroke'] == 1]['age'].sort_values()","73276574":"df.drop(df.index[[162,245]], inplace=True)","514dfae8":"ax = sns.violinplot(data=df, x='hypertension', y='age', hue='gender', split=True, palette=palettes)","bba79a93":"ax = sns.countplot(data=df, x='stroke', hue='gender', palette=palettes, edgecolor=palettes)\n\nfor patch in ax.patches:\n    clr = patch.get_facecolor()\n    patch.set_edgecolor(clr)","99eaf3a4":"smoke = df['smoking_status'].value_counts()","fe098833":"fig, ax = plt.subplots(figsize =(8, 5))\nwedges, texts, autotexts = ax.pie(x=smoke, autopct=\"%.2f%%\", labels=smoke.index, explode=[0,0.15,0,0], colors=palettes,\n        radius=1.5, wedgeprops={ 'linewidth' : 1, 'edgecolor' : '#EAE0D5' }, textprops=dict(fontsize=14))\n\nax.set_title('Distribution of Smoking Status in Dataset', y=1.3, weight='bold', fontsize=14)\n\nfor autotext in autotexts:\n    autotext.set_color('white')\n    autotext.set_weight('bold')","677e032a":"ax = sns.countplot(data=df, hue='work_type', y='smoking_status', palette=palettes, orient='h')\n\n#to change edgecolor\nfor patch in ax.patches:\n    clr = patch.get_facecolor()\n    patch.set_edgecolor(clr)\n\nax.legend(bbox_to_anchor=(1.4, 0.4))\nsns.despine()","a4086b5c":"sns.boxplot(data=df, x='smoking_status', y='age', palette=palettes)","ed9b2cbc":"def smoke(text):\n    if text == 'never smoked' or text == 'Unknown':\n        return 'never smoked'\n    else:\n        return 'smoke'","7deb1adc":"df['smoking_status'] = df['smoking_status'].apply(smoke)","5ad6099a":"ax = sns.barplot(data=df, x='smoking_status', y='heart_disease', hue='hypertension', palette=palettes, ci=None)\n\n#to change edgecolor\nfor patch in ax.patches:\n    clr = patch.get_facecolor()\n    patch.set_edgecolor(clr)\n\nsns.despine()","4399d4fd":"ax = sns.barplot(data=df, x='smoking_status', y='stroke',\n            palette=palettes, edgecolor=palettes, ci=None)\n\nax.set_title('Chance of Getting Stroke Based on Smoking Behavior', y=1.1, weight='bold', fontsize=14)","6d827859":"data_prob = pd.crosstab(index=df['stroke'], columns=df['smoking_status'], normalize='index')\ndata_prob = data_prob*100\ndata_prob","638c5026":"ax = data_prob.plot.bar(rot=0, stacked=True, color=palettes, edgecolor='#EAE0D5')\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_title('Distribution of Smoking Status Based on Whether They Have Stroke or Not', x=0.6, y=1.1, weight='bold', fontsize=14)\nax.set_ylabel('% of smoking_status')\n\nfor i,ns in enumerate(data_prob['never smoked']):\n    ax.text(i, ns\/2, '{:.2f}%'.format(ns), ha='center', fontsize=13, weight='bold', color='white')\n\nfor i,s in enumerate(data_prob['smoke']):\n    ax.text(i, 100-s\/2, '{:.2f}%'.format(s), ha='center', fontsize=13, weight='bold', color='white')\n            \nax.legend(bbox_to_anchor=(1.05, 1))\nsns.despine()","2a8e16ac":"#get all object features\nobj_feat = df.dtypes[df.dtypes == 'O'].index.values","a3e45bf5":"le = LabelEncoder()\n\nfor i in obj_feat:\n    df[i] = le.fit_transform(df[i])","3c164319":"df.head()","08647bbb":"X = df.drop('stroke', axis=1)\ny = df['stroke']","954fa5ca":"scaler = StandardScaler()\n\nscaler.fit(X)\nX_scaled = scaler.transform(X)\nX = pd.DataFrame(X_scaled, columns=X.columns)","14c795cf":"X.head()","e43db13c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)","f6def06c":"all_model = [LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(),\n            RandomForestClassifier(), BernoulliNB(), SVC()]","eaca67d7":"recall = []\naccuracy = []\n\nfor model in all_model:\n    cv = cross_val_score(model, X_train, y_train, scoring='recall', cv=10).mean()\n    recall.append(cv)\n\n    cv = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=10).mean()\n    accuracy.append(cv)","1007c58e":"model = ['LogisticRegression', 'KNeighborsClassifier', 'DecisionTreeClassifier',\n         'RandomForestClassifier', 'BernoulliNB', 'SVC']\n\nscore = pd.DataFrame({'Model': model, 'Accuracy': accuracy, 'Recall': recall})\nscore.style.background_gradient(cmap=cmap,high=1,axis=0)","b16be4fb":"dtc = DecisionTreeClassifier()\n\ndtc.fit(X_train, y_train)","5d6eb55d":"pred = dtc.predict(X_test)","0078876a":"print(confusion_matrix(y_test, pred, labels=(1,0)))\nprint(classification_report(y_test, pred))","c184b374":"pd.DataFrame(dtc.feature_importances_, index=X.columns, columns=['Feature Importance']).sort_values(by='Feature Importance').plot.bar(color=palettes, edgecolor='#EAE0D5')","32e16b0d":"def prediction(feat_value):\n    scaled = scaler.transform(feat_value)\n    return dtc.predict(feat_value)","1d0639e2":"prediction([[1, 65, 1, 0, 1, 3, 1, 200, 1]])","72937f01":"prediction([[0, 40, 0, 0, 1, 0, 0, 160, 0]])","aaffa8b3":"<a id=\"4\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Data Preprocessing<\/p>","7786ecfe":"In this entire work, we build a machine learning model to predict whether someone has high risk of getting stroke or not. We decided using Decision Tree Classifier as our final model since it has the highest recall score and good accuracy score as well. From analysis we did earlier from our model, glucose level in the body and age have the main role to determine the output","4eaedaa4":"<a id=\"5\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Modeling<\/p>","bbf710c8":"**Additional information:**\n* axes.facecolor --> set color for background inside x and y axis\n* figure.facecolor --> set color for background outside x and y axis where labels placed\n* grid.color --> set color for grid line\n* axes.edgecolor --> set color for line x and y axis\n* axes.labelcolor --> set color for labels in the plot\n* xtick.color --> set color for the values of x axis\n* ytick.color --> set color for the values of y axis","7584b9b5":"We know that id column completely has no correlation to predict stroke. Furthermore, correlation between bmi and stroke is very low (under 0.05). So, we drop both of the features","ed198aa7":"From the plot above, people mostly has bmi score in range 10 to 60 and there is no difference for people who live in urban or rural area. All data are equally distributed","5c41828c":"Performance of each model is shown in the table above. In this particular case, it's better to have a high recall since we don't want to predict someone has no stroke, but he actually has stroke. From this consideration, We choose Decision Tree Classifier as our final model\n\nHowever, because of the imbalanced dataset, the average model performance is not quite good to develop in the real world due to the mean of recall score is very low","30fd2fe5":"**Scenario 2**\n* Gender: Female (0)\n* Age: 40\n* Hypertension: False (0)\n* Heart_disease: False (0)\n* Ever_married: True (1)\n* Work_type: Govt_job (0)\n* Residence_type: Rural (0)\n* Avg_glucose_level: 160\n* Smoking_status: Never_smoked (0)","3c4c21e2":"For this particular dataset, avg_glucose_level and age are the most important features to determine if someone has high risk or low risk of getting stroke. The higher glucose level in blood, the higher the risk for getting stroke and likewise the older people","0a572b6e":"<a id=\"3\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Data Cleaning and EDA<\/p>","655f37cd":"<a id=\"1\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Importing Libraries<\/p>","37326148":"**In this part we are focus on 2 things:**\n1. Handle the missing values (whether fill or drop the data), remove irrelevant features, get rid the outliers\n2. Get some insights and patterns by visualizing the data\n\nSo, let's jump into the process!\nFirst of all, we need to get the information necessary in order to get better understanding about the dataset we got already","3a314537":"**If you find this notebook useful, please upvote**\n\n**Thanks**","ab9dfd81":"If we look at the visualization, total number of female who got stroke is bigger than male","44317630":"We end up getting the output 1 (high risk) for scenario 1 and output 0 (low risk) for scenario 2","ebd6c31f":"**A thing we get from each plot**\n* In this dataset, majority of people are around 40 and 60 years old\n* Older people more likely to get heart disease than people under 40 years old\n* People above 50 years old have more chance to get stroke","5103187c":"So, we are going to import some common libraries such as numpy, pandas, matplotlib, seaborn, and scikit-learn to build our model","e97c6851":"<p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Table of Contents<\/p>\n\n**What is covered in this notebook?**\n* [Importing Libraries](#1)\n* [Load Dataset](#2)\n* [Data Cleaning and EDA](#3)\n* [Data Preprocessing](#4)\n* [Modeling](#5)\n* [Feature Importance](#6)\n* [Try To Predict](#7)\n* [Conclusion](#8)","5f754eb0":"**Some interesting insights:**\n* Stroke doesn't look where people live. Distribution of stroke in the urban area is similar to rural area\n* 2 children have stroke","82f0e77a":"Let's see what we can get from the plot below. Is there something interesting?","534b7da0":"<a id=\"7\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Try to Predict<\/p>","ed411b63":"Oh look, there is 1 data apart from Male and Female. Let's see if there is a relation between gender and bmi hopefully we can classify the Other gender to either Female or Male","b2042598":"**From information above, we can summarize:**\n* There are categorical features in the data. So we need to encode them into numeric features later on \n* Only 1 column that has missing values, that is bmi column\n* Minority of the sample are infants or children less than 1 year old","40b7d248":"<a id=\"2\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Load Dataset<\/p>","770ddbec":"From above plot there's no chance to know wheter the other gender is Female or Male because bmi for both of them is similar. So, we drop the Other gender","c8f77311":"Let's have a look at the correlation among the features (Excluding the categorical attributes at this point)","59705191":"Seems like heart disease is more likely to occur to someone with hypertension and smokers have more chance to get hypertension","be01406d":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Feature Importance<\/p>","0b9aba87":"In this part, we are going to encode object features using dummy variables as well as performing feature scalling to dataset","01bb2fa2":"**We want to try predicting the output using 2 scenarios provided below**","7ba4c207":"Because those children are outlier, i think we can get rid both of them from our dataset","798ab233":"Let's explore age column in our dataset","5f42ac48":"Well, smoking increases the risk of stroke by around 2.5%","14d47828":"Next, let's focus on smoking status column. We will try to do some visualizations to get better understanding about the effect of smoking","3c9868d0":"Those 3 plots above show us there's unknown smoking status that might influence our model. Fortunately we got some insight from relation between smoking status and work type plot. As we can see that unknown status has a big number of children and we can assume that children never smoke. So, with that assumtion we can categorize unknown status to never smoked status\n\n**The next step, we will replace the status in the following manner:**\n* smokes and formerly smoked --> smoke\n* never smoked and unknown --> never smoked","50d2a518":"Next, we want to know the distribution of gender in our dataset","264f8381":"We will use 6 models for predicting categorical output, with the help of cross validation we evaluate the performance of each model using recall and accuracy score. By simply taking the mean of both scores, we know which model has the highest score indicating it has the best performance for this particular case\n\n**Metrics we use:**\n* Accuracy --> Ratio of correctly predicted observation to the total observations\n* Recall --> Ratio of correctly predicted positive observations to the all observations in actual class","df9f3ada":"<a id=\"8\"><\/a>\n# <p style=\"background-color:#EAE0D5;font-family:Gill Sans;color:#6B705C;font-size:40px;text-align:center;border-radius:100px 100px\">Conclusion<\/p>","407c35ae":"**Scenario 1**\n* Gender: Male (1)\n* Age: 65\n* Hypertension: True (1)\n* Heart_disease: False (0)\n* Ever_married: True (1)\n* Work_type: Self-employed (3)\n* Residence_type: Urban (1)\n* Avg_glucose_level: 200\n* Smoking_status: Smoke (1)"}}