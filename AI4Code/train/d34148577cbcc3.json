{"cell_type":{"f1cba8a0":"code","363aa928":"code","ae87edc0":"code","ae01a194":"code","061c723e":"code","790320b5":"code","e420e23b":"code","8291de15":"code","f23462ef":"code","0d2c81c7":"code","311c638a":"code","63b97c0d":"code","51a60a21":"code","b3a5a247":"code","1eb4c975":"code","e7274572":"code","8ba028ce":"code","cd7a8f50":"code","f2714246":"code","7a406a76":"code","b7c39e80":"code","30e1cf31":"code","cbbb8fca":"code","95dd0c86":"code","5737e7d1":"code","602f9b3d":"code","dae38643":"code","52c00ea5":"code","ec5273c0":"code","ce41ecbc":"code","46a9c4d2":"code","4cbf397c":"code","c5acdf57":"code","db29fcb4":"code","91e44b21":"code","a484b3a7":"code","17d6357a":"code","4fc168f9":"code","ddbb0b21":"code","fa685861":"code","6fc5f831":"code","dc2f4057":"code","e557ec5f":"code","13ab6194":"code","316f2a92":"code","c7db88b6":"code","b7b79c20":"markdown","afba9fc9":"markdown","7c4e7cdb":"markdown","b592cd43":"markdown","d2dd784e":"markdown","a09ee14e":"markdown","d119cb3f":"markdown","adae232a":"markdown","64635ef1":"markdown","17dca7dd":"markdown","7b9cd536":"markdown"},"source":{"f1cba8a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","363aa928":"import os\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport seaborn as sns\nimport math as m\nfrom scipy import stats\nimport matplotlib.pyplot as plt","ae87edc0":"train = pd.read_csv('\/kaggle\/input\/avhranalytics\/train_jqd04QH.csv')\ntest = pd.read_csv('\/kaggle\/input\/avhranalytics\/test_KaymcHn.csv')","ae01a194":"train.head()","061c723e":"train.shape,test.shape","790320b5":"train.apply(lambda x: (len(x.unique()))) ","e420e23b":"test.apply(lambda x: (len(x.unique()))) ","8291de15":"combine = train.append(test,sort=False)\ncombine.shape","f23462ef":"combine.isnull().sum()","0d2c81c7":"train['target'].value_counts(normalize=True)","311c638a":"sns.countplot(train['target'])","63b97c0d":"plt.figure(figsize=(24, 6))\nplt.subplot(121)\nsns.countplot(combine['company_size'],order = combine['company_size'].value_counts(dropna=False).index)\nplt.subplot(122)\nsns.countplot(combine['company_type'],order = combine['company_type'].value_counts(dropna=False).index)","51a60a21":"combine['company_size'].fillna('unknown', inplace=True)","b3a5a247":"combine['company_type'].fillna('unknown', inplace=True)","1eb4c975":"plt.figure(figsize=(20, 6))\nplt.subplot(121)\nsns.countplot(combine['gender'],order = combine['gender'].value_counts(dropna=False).index)\nplt.subplot(122)\nsns.countplot(combine['relevent_experience'],order = combine['relevent_experience'].value_counts(dropna=False).index)","e7274572":"combine['gender'].fillna('Male', inplace=True)","8ba028ce":"combine[\"gender\"] = combine[\"gender\"].map({'Male':2,  'Female':1, 'Other':0})","cd7a8f50":"plt.figure(figsize=(22, 6))\nplt.subplot(121)\nsns.countplot(combine['last_new_job'],order = combine['last_new_job'].value_counts(dropna=False).index)\nplt.subplot(122)\nsns.countplot(combine['experience'],order = combine['experience'].value_counts(dropna=False).index)","f2714246":"combine['last_new_job'].fillna('1', inplace=True) #using Mode Option for fill Nan Values as there are very less null values","7a406a76":"combine['last_new_job'].replace('>4','6', inplace=True)\ncombine['last_new_job'].replace('never','0' ,inplace=True)\ncombine['last_new_job']=combine['last_new_job'].astype(int)","b7c39e80":"combine['experience'].fillna('>20', inplace=True) #using Mode Option for fill Nan Values as there are very less null values","30e1cf31":"combine['experience'].replace('>20','25', inplace=True)\ncombine['experience'].replace('<1','0' ,inplace=True)\ncombine['experience']=combine['last_new_job'].astype(int)","cbbb8fca":"plt.figure(figsize=(22, 6))\nplt.subplot(131)\nsns.countplot(combine['education_level'],order = combine['education_level'].value_counts(dropna=False).index)\nplt.subplot(132)\nsns.countplot(combine['enrolled_university'],order = combine['enrolled_university'].value_counts(dropna=False).index)\nplt.subplot(133)\nsns.countplot(combine['major_discipline'],order = combine['major_discipline'].value_counts(dropna=False).index)","95dd0c86":"combine['education_level'].value_counts(dropna=False)","5737e7d1":"combine['education_level'].fillna(train['education_level'].mode()[0], inplace=True) #Missing Value is less than 10% of Mode Value Itself","602f9b3d":"plt.figure(figsize=(22, 6))\ncity_tier_counts = (combine.groupby(['target'])['education_level'].value_counts(dropna=False,normalize=True).rename('percentage').mul(100).reset_index().sort_values('target'))\nsns.barplot(x=\"education_level\", y=\"percentage\", hue=\"target\", data=city_tier_counts)","dae38643":"combine[\"education_level\"] = combine[\"education_level\"].map({'Graduate':0, 'Masters':1, 'High School':2, 'Phd':3, 'Primary School':4})","52c00ea5":"combine.enrolled_university.value_counts(dropna=False)","ec5273c0":"combine['enrolled_university'].fillna(train['enrolled_university'].mode()[0], inplace=True) #Missing Value is less than 3% of Mode Value Itself","ce41ecbc":"plt.figure(figsize=(22, 6))\ncity_tier_counts = (combine.groupby(['target'])['enrolled_university'].value_counts(dropna=False,normalize=True).rename('percentage').mul(100).reset_index().sort_values('target'))\nsns.barplot(x=\"enrolled_university\", y=\"percentage\", hue=\"target\", data=city_tier_counts)","46a9c4d2":"combine[\"enrolled_university\"] = combine[\"enrolled_university\"].map({'no_enrollment':1, 'Full time course':4, 'Part time course':2})","4cbf397c":"combine.major_discipline.value_counts(dropna=False)","c5acdf57":"combine['major_discipline'].fillna(train['major_discipline'].mode()[0], inplace=True)","db29fcb4":"plt.figure(figsize=(20, 6))\ncity_tier_counts = (combine.groupby(['target'])['major_discipline'].value_counts(dropna=False,normalize=True).rename('percentage').mul(100).reset_index().sort_values('target'))\nsns.barplot(x=\"major_discipline\", y=\"percentage\", hue=\"target\", data=city_tier_counts)","91e44b21":"combine.isnull().sum()","a484b3a7":"cat_col = combine.dtypes.loc[combine.dtypes=='object'].index\ncategorical_variables=cat_col.tolist()\ncategorical_variables","17d6357a":"from sklearn import metrics, preprocessing, model_selection\nfor col in categorical_variables:\n    print(col)\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(combine[col].values.astype('str')))\n    combine[col] = lbl.transform(list(combine[col].values.astype('str')))","4fc168f9":"display(combine.columns),train.shape","ddbb0b21":"train_features = combine.drop(['enrollee_id', 'target'], axis = 1)[:18359]\ntarget = combine['target'][:18359]\ntest_features = combine.drop(['enrollee_id','target'], axis = 1)[18359:]","fa685861":"train_features.shape,target.shape,test_features.shape","6fc5f831":"from sklearn import metrics, preprocessing, model_selection\nimport lightgbm as lgb","dc2f4057":"train_X=train_features\ntrain_y=target\ntest_X=test_features","e557ec5f":"def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None, dep=8, seed=0, data_leaf=200):\n    params = {}\n    params[\"objective\"] = \"binary\"\n    params['metric'] = 'auc'\n    params[\"max_depth\"] = dep\n    params[\"num_leaves\"] = 31\n    params[\"min_data_in_leaf\"] = data_leaf\n    params[\"learning_rate\"] = 0.01\n    params[\"bagging_fraction\"] = 0.9\n    params[\"feature_fraction\"] = 0.5\n    params[\"feature_fraction_seed\"] = seed\n    params[\"bagging_freq\"] = 1\n    params[\"bagging_seed\"] = seed\n    params[\"lambda_l2\"] =5\n    params[\"lambda_l1\"] = 5\n    params[\"verbosity\"] = -1\n    num_rounds = 25000\n\n    plst = list(params.items())\n    lgtrain = lgb.Dataset(train_X, label=train_y)\n\n    if test_y is not None:\n        lgtest = lgb.Dataset(test_X, label=test_y)\n        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest], early_stopping_rounds=200, verbose_eval=500)\n    else:\n        lgtest = lgb.DMatrix(test_X)\n        model = lgb.train(params, lgtrain, num_rounds)\n\n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n\n    loss = 0\n    if test_y is not None:\n        loss = metrics.roc_auc_score(test_y, pred_test_y)\n        print(loss)\n        return model, loss, pred_test_y, pred_test_y2\n    else:\n        return model, loss, pred_test_y, pred_test_y2","13ab6194":"print(\"Building model..\")\ncv_scores = []\npred_test_full = 0\npred_train = np.zeros(train_X.shape[0])\nn_splits = 5\n#kf = model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=7988)\ngkf = model_selection.GroupKFold(n_splits=n_splits)\nmodel_name = \"lgb\"\nfor dev_index, val_index in gkf.split(train_X, combine['target'][:18359].values, combine['enrollee_id'][:18359].values):\n    dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val = 0\n    pred_test = 0\n    n_models = 0.\n\n    model, loss, pred_v, pred_t = runLGB(dev_X, dev_y, val_X, val_y, test_X, dep=8, seed=2019)\n    pred_val += pred_v\n    pred_test += pred_t\n    n_models += 1\n    \n    model, loss, pred_v, pred_t = runLGB(dev_X, dev_y, val_X, val_y, test_X, dep=7, data_leaf=100, seed=9873)\n    pred_val += pred_v\n    pred_test += pred_t\n    n_models += 1\n    \n    model, loss, pred_v, pred_t = runLGB(dev_X, dev_y, val_X, val_y, test_X, dep=9, data_leaf=150, seed=4568)\n    pred_val += pred_v\n    pred_test += pred_t\n    n_models += 1\n    \n    pred_val \/= n_models\n    pred_test \/= n_models\n    \n    loss = metrics.roc_auc_score(val_y, pred_val)\n        \n    pred_train[val_index] = pred_val\n    pred_test_full += pred_test \/ n_splits\n    cv_scores.append(loss)\n#     break\nprint(np.mean(cv_scores))","316f2a92":"fig, ax = plt.subplots(figsize=(10,10))\nlgb.plot_importance(model, max_num_features=100, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance\", fontsize=15)\nplt.show()","c7db88b6":"sample = pd.read_csv('\/kaggle\/input\/avhranalytics\/sample_submission_sxfcbdx.csv')\nsample[\"target\"] = pred_test_full\nsample.to_csv(\"Solution.csv\", index=False)","b7b79c20":"Missing Value is nearly 10% of data, so we can keep Nan values as Unknow,  but here the other datas are less than 3% of Mode of major_discipline, so I am replacing Nan as Mode Values\n","afba9fc9":"### Bivariate Analysis","7c4e7cdb":"# HR_Analytics-AV Hackathon","b592cd43":"The Company_Type more 30 % of values are Missing Value is greater, it is good to consider as a seperate variable","d2dd784e":"As the data contains Almost 90% of males, Nan Values can be replaces as Males, else we can use Not revelaed(I have tried but there is no change in Model Performance)","a09ee14e":"Train and Test having the same number of unique values, we can combine the dataset and use for further Analysis","d119cb3f":"> ### **EDA - Target Exploration**","adae232a":"### Univariate Analysis","64635ef1":"The company_size Missing Value is greater than any of sum of other values, it is good to consider as a seperate variable","17dca7dd":"### Importing Libraries","7b9cd536":"### Label Encoding"}}