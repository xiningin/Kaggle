{"cell_type":{"a9fc0dd0":"code","a21e0ce7":"code","a51421e2":"code","3700d8d8":"code","a13d9432":"code","31bc6f7c":"code","67827047":"code","1bdea825":"code","60b858a6":"code","c4f3827a":"code","905043d4":"code","fa4c1d66":"code","e5ea5b1b":"code","19160ded":"code","365bb5d2":"code","c5e536bc":"code","27c6446e":"code","a03b5f73":"code","c6753065":"code","b6d1113b":"code","df4b61fb":"code","8b09a7b6":"markdown","92591dd1":"markdown","d900e44f":"markdown","5c08b5a0":"markdown","9e2227d5":"markdown","08f0f942":"markdown","725c004b":"markdown","624b6063":"markdown"},"source":{"a9fc0dd0":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nimport re\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","a21e0ce7":"train_df = pd.read_csv('..\/input\/lt-vehicle-loan-default-prediction\/train.csv')\ntest_df = pd.read_csv('..\/input\/lt-vehicle-loan-default-prediction\/test.csv')","a51421e2":"train_df","3700d8d8":"train_df.info()","a13d9432":"test_df","31bc6f7c":"test_df.info()","67827047":"def encode_dates(df, column):\n    df = df.copy()\n    df[column] = pd.to_datetime(df[column], format='%d-%m-%y')\n    df[column + '_year'] = df[column].apply(lambda x: x.year)\n    df[column + '_month'] = df[column].apply(lambda x: x.month)\n    df[column + '_day'] = df[column].apply(lambda x: x.day)\n    df = df.drop(column, axis=1)\n    return df\n\ndef encode_durations(df, column):\n    df = df.copy()\n    df[column + '_yrs'] = df[column].apply(lambda x: re.search(r'\\d+(?=yrs)', x).group(0)).astype(np.int)\n    df[column + '_mon'] = df[column].apply(lambda x: re.search(r'\\d+(?=mon)', x).group(0)).astype(np.int)\n    df = df.drop(column, axis=1)\n    return df\n\ndef onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=column)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","1bdea825":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop UniqueID and MobileNo_Avl_Flag columns\n    df = df.drop(['UniqueID', 'MobileNo_Avl_Flag'], axis=1)\n    \n    # Drop high-cardinality columns\n    df = df.drop(['supplier_id', 'Current_pincode_ID', 'Employee_code_ID'], axis=1)\n    \n    # Encode missing employment values as Unemployed\n    df['Employment.Type'] = df['Employment.Type'].fillna(\"Unemployed\")\n    \n    # Extract date features\n    df = encode_dates(df, column='Date.of.Birth')\n    df = encode_dates(df, column='DisbursalDate')\n    \n    # Drop DisbursalDate_year\n    df = df.drop('DisbursalDate_year', axis=1)\n    \n    # Extract duration features\n    df = encode_durations(df, column='AVERAGE.ACCT.AGE')\n    df = encode_durations(df, column='CREDIT.HISTORY.LENGTH')\n    \n    # One-hot encode categorical features\n    for column in ['branch_id', 'manufacturer_id', 'Employment.Type', 'State_ID', 'PERFORM_CNS.SCORE.DESCRIPTION']:\n        df = onehot_encode(df, column)\n    \n    return df","60b858a6":"X_train = preprocess_inputs(train_df)\nX_test = preprocess_inputs(test_df)","c4f3827a":"X_train","905043d4":"X_test","fa4c1d66":"y_train = train_df['loan_default']\nX_train = X_train.drop('loan_default', axis=1)","e5ea5b1b":"for column in X_train.columns:\n    if column not in X_test.columns:\n        print(column)","19160ded":"for column in X_test.columns:\n    if column not in X_train.columns:\n        print(column)","365bb5d2":"def adjust_columns(X_train, X_test):\n    train_columns = []\n    test_columns = []\n    \n    # Get X_train columns not present in X_test\n    for column in X_train.columns:\n        if column not in X_test.columns:\n            train_columns.append(column)\n    \n    # Get X_test columns not present in X_train\n    for column in X_test.columns:\n        if column not in X_train.columns:\n            test_columns.append(column)\n    \n    # Remove test_columns from X_test\n    X_test = X_test.copy()\n    X_test = X_test.drop(test_columns, axis=1)\n    \n    # Add train_columns and fill with 0's\n    for column in train_columns:\n        column_index = list(X_train.columns).index(column)\n        X_test.insert(loc=column_index, column=column, value=0)\n    \n    return X_test","c5e536bc":"X_test = adjust_columns(X_train, X_test)","27c6446e":"(X_train.columns == X_test.columns).all()","a03b5f73":"scaler = MinMaxScaler()\nscaler.fit(X_train)\n\nX_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)","c6753065":"skf = StratifiedKFold(n_splits=5)\n\nresults = []\n\nfor train_idx, test_idx in skf.split(X_train, y_train):\n    model = LogisticRegression()\n    model.fit(X_train.iloc[train_idx, :], y_train.iloc[train_idx])\n    result = model.score(X_train.iloc[test_idx, :], y_train.iloc[test_idx])\n    results.append(result)","b6d1113b":"for i, result in enumerate(results):\n    print(\"Fold {}: {:.2f}%\".format(i + 1, result * 100))","df4b61fb":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\ny_pred","8b09a7b6":"## Adjust X_test dummy columns to match X_train  \n  \nWe can see that after one-hot encoding, there are some columns present in X_train that aren't present in X_test and vice versa.  \nWe can correct this with a simple function.","92591dd1":"## Evaluation with StratifiedKFold","d900e44f":"# Preprocessing","5c08b5a0":"## Generating X_test predictions  \n  \nWe can assume our predictions are ~78% accurate.","9e2227d5":"# Task for Today  \n\n***\n\n## Car Loan Default Prediction  \n  \nGiven *data about vehicle loans*, let's try to predict if a given loanee will **default** or not.  \n  \nWe will use a logistic regression model to make our predictions.","08f0f942":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/xHKEcMkR9d8","725c004b":"# Getting Started","624b6063":"# Training"}}