{"cell_type":{"5cb79d3f":"code","11247fa3":"code","bdd6ec91":"code","56908539":"code","be352c75":"code","44880094":"code","485db442":"code","4b493f83":"code","58a1a87e":"code","27fd44d0":"code","af0ecf74":"code","1c6f8018":"code","4f767f87":"code","2fe9a680":"code","5d98d42a":"code","bf216e95":"code","7ee0dcea":"markdown","c914cbb6":"markdown"},"source":{"5cb79d3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re # regular expression\nimport nltk # Natural Language Toolkit\nfrom nltk.tokenize import TweetTokenizer\nimport emoji\nimport random\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11247fa3":"nltk.download('punkt')","bdd6ec91":"!pip install -U nltk==3.4","56908539":"from nltk.lm.preprocessing import padded_everygram_pipeline\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.lm import MLE","be352c75":"data = pd.read_csv(\"..\/input\/large-random-tweets-from-pakistan\/Random Tweets from Pakistan- Cleaned- Anonymous.csv\",encoding_errors = 'ignore')\n\ndata = data['full_text']\ndata = data.dropna()","44880094":"data.head(100)","485db442":"print('Tweet before preprocessing and tokenization: \\n', data[100])","4b493f83":"# Removing Urdu language\nreg = re.compile(r'[\\u0600-\\u06ff]+', re.UNICODE)\ndata = data.apply(lambda x: re.sub(reg, \"\", x))\n\n# removing extra spaces\ndata = data.apply(lambda x: re.sub(r'[  ]+', \" \", x))\n\n# converting to lowercase letters\ndata = data.apply(lambda x: x.strip().lower())\n\n# remove hyperlinks\ndata = data.apply(lambda x: re.sub(r'https?:\\\/\\\/.*[\\r\\n]*', '', x))\n\n# removing @Mentions\ndata = data.apply(lambda x:re.sub(r'@.+?\\s', '', x))\n\n\n# removing extra symbols\ndata = data.apply(lambda x: re.sub(r'#', '', x))\ndata = data.apply(lambda x: re.sub(r'rt : ', '', x))\ndata = data.apply(lambda x: re.sub(r'\\n', ' ', x))\n\n# Dropping duplicates\ndata = data.drop_duplicates()\n\n# Tokenizing text\ntokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n                           reduce_len=True)\ndata = data.apply(tokenizer.tokenize)\n\n# removing emoji\ndef clean(x):\n    return [y for y in x if not emoji.is_emoji(y)]\n\n# removing tweets with less than 3 words\ndata = data.apply(clean)\ndata = data.apply(lambda x:np.nan if len(x)<3 else x)\ndata.dropna(inplace = True)\n\nprint('Tweet After preprocessing and tokenization: \\n', data[100])","58a1a87e":"# Preprocess the tokenized text for 3-grams language modelling\nn_gram_size = 3\ntrain_data, padded_sents = padded_everygram_pipeline(n_gram_size, data)","27fd44d0":"# tranining a probablistic model using maximum liklihood estimation\nmodel = MLE(n_gram_size)\nmodel.fit(train_data, padded_sents)\nprint(model.vocab)\nlen(model.vocab)","af0ecf74":"print(model.vocab.lookup(['here', 'is', 'a', 'solution', 'for','it'])) \nprint(model.vocab.lookup(['cant','fainde','blabla','and', 'blablabla']))","1c6f8018":"print(\"\",model.counts)","4f767f87":"# frequencies of occurences\nprint(\"Count of unigram 'karachi': \",model.counts['karachi'])\nprint(\"Count of bigram 'is\/karachi': \",model.counts[['karachi']]['is'])\nprint(\"Count of trigram 'a\/karachi is': \",model.counts[['karachi', 'is']]['a'])","2fe9a680":"# probablities of occurences\nprint(\"probability of 'karachi' given <s>: \",model.score('karachi'))\nprint(\"probability of 'is' given 'karachi': \",model.score('is',['karachi']))\nprint(\"probability of 'a' given 'karachi is': \",model.score('a',['karachi','is']))","5d98d42a":"# Using our 3-gram language to generate text\n# max number of tokens\nlength = 20\nrand_seed=random.randint(0,100)\n\ngen_tweet =' '.join(model.generate(length,random_seed=rand_seed ))\n\n# removing extra ending tokens generated by model\nre.sub('[<\/s>]+','',gen_tweet)","bf216e95":"model.perplexity('karachi')","7ee0dcea":"# Perplexity","c914cbb6":"# Generate random tweet"}}