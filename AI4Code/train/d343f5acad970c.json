{"cell_type":{"f0b06c7a":"code","5c7164c5":"code","fa98feb6":"code","ff966b08":"code","652b685e":"code","51bdab62":"code","295ef247":"code","aa60b3e0":"code","d520a141":"code","36df1e3c":"code","d49325f4":"code","019c236d":"code","f652c9fd":"code","d5dd38cb":"code","ec29deb0":"code","4c7bafa4":"code","9a949cce":"code","372a573d":"code","72a725ab":"code","5ca803e1":"markdown"},"source":{"f0b06c7a":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=Smokum&effect=3d';      \n    <\/style><h1 class='font-effect-3d' \n    style='font-family:Smokum; color:#ff5511; font-size:35px;'>\n    %s<\/h1>\"\"\"%str))","5c7164c5":"dhtml('Code Modules, Functions, & Classes')","fa98feb6":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch,time,copy,urllib,zipfile\nfrom torchvision.datasets import CIFAR10 as tcifar10\nfrom torchvision import transforms,utils,models\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nfrom torch.utils.data.dataset import Subset\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nimport tensorflow.image as timage\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","ff966b08":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","652b685e":"@register_line_magic\ndef display_examples(d):\n    if d=='1': loaders=dataloaders\n    if d=='2': loaders=dataloaders2\n    for images,labels in loaders['valid']:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        images=np.transpose(images,(0,2,3,1))\/2.+.5\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size,3))\n        break","51bdab62":"def model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev).long()\n        logits=model(features)\n        _,pred_labels=torch.max(logits,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()\/num_examples*100\ndef epoch_loss(model,data_loader):\n    model.eval()\n    curr_loss,num_examples=0.,0\n    with torch.no_grad():\n        for features,targets in data_loader:\n            features=features.to(dev)\n            targets=targets.to(dev).long()\n            logits=model(features)\n            loss=tnnf.cross_entropy(logits,targets,\n                                    reduction='sum')\n            num_examples+=targets.size(0)\n            curr_loss+=loss\n        return curr_loss\/num_examples","295ef247":"dhtml('Data')","aa60b3e0":"img_size=64\nclasses=('plane','car','bird','cat','deer',\n          'dog','frog','horse','ship','truck')\nrandom_seed=12; batch_size=128\ntrain_ids=torch.arange(0,44000)\nvalid_ids=torch.arange(44000,50000)\ntr0=(.5,.5,.5)\ntrans=transforms\\\n.Compose([transforms.Resize((img_size,img_size)),\n          transforms.ToTensor(),\n          transforms.Normalize(tr0,tr0)])\ntrain_valid=tcifar10(root='data',train=True,\n                     download=True,\n                     transform=trans)\ntrain=Subset(train_valid,train_ids)\nvalid=Subset(train_valid,valid_ids)\ntest=tcifar10(root='data',train=False, \n              transform=trans)\ndataloaders={'train':tdl(dataset=train,shuffle=True, \n                         batch_size=batch_size), \n             'valid':tdl(dataset=valid,shuffle=True, \n                         batch_size=batch_size),\n             'test':tdl(dataset=test,shuffle=True, \n                        batch_size=batch_size)}","d520a141":"%display_examples 1","36df1e3c":"fpath='https:\/\/olgabelitskaya.github.io\/' # from my website \nzf='LetterColorImages_123.h5.zip'\ninput_file=urllib.request.urlopen(fpath+zf)\noutput_file=open(zf,'wb'); \noutput_file.write(input_file.read())\noutput_file.close(); input_file.close()\nzipf=zipfile.ZipFile(zf,'r')\nzipf.extractall(''); zipf.close()\nf=h5py.File(zf[:-4],'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')\nx=timage.resize(x,[img_size,img_size])\/255\nx=2*np.transpose(x.numpy(),(0,3,1,2))-1\nprint(x.mean(),x.std())\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\nrandom_seed=23\ntrain2=TData(x_train,y_train)\nvalid2=TData(x_valid,y_valid)\ntest2=TData(x_test,y_test)\ndataloaders2={'train':tdl(dataset=train2,shuffle=True, \n                          batch_size=batch_size), \n              'valid':tdl(dataset=valid2,shuffle=True, \n                          batch_size=batch_size),\n              'test':tdl(dataset=test2,shuffle=True, \n                         batch_size=batch_size)}","d49325f4":"%display_examples 2","019c236d":"dhtml('VGG16')","f652c9fd":"model=models.vgg16(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad=False\nmodel.classifier[3].requires_grad=True\nmodel","d5dd38cb":"dhtml('Training')","ec29deb0":"@register_line_magic\ndef train_run(pars):\n    [epochs,n]=pars.split()\n    epochs=int(epochs); n=int(n)\n    if n==1: loaders=dataloaders\n    if n==2: loaders=dataloaders2\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) \\\n        in enumerate(loaders['train']):        \n            features=features.to(dev)\n            targets=targets.to(dev).long()\n            logits=model(features)\n            cost=tnnf.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%100:\n                print ('Epoch: %03d\/%03d | Batch: %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids,\n                         len(loaders['train']),cost))\n        model.eval()\n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d'%(epoch+1,epochs))\n            print('train acc\/loss: %.2f%%\/%.2f valid acc\/loss: %.2f%%\/%.2f'%\\\n                  (model_acc(model,loaders['train']),\n                   epoch_loss(model,loaders['train']),\n                   model_acc(model,loaders['valid']),\n                   epoch_loss(model,loaders['valid'])))","4c7bafa4":"num_classes=10\nmodel.classifier[6]=tnn.Sequential(\n    tnn.Linear(4096,512),tnn.ReLU(),\n    tnn.Dropout(.5),tnn.Linear(512,num_classes))\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters())","9a949cce":"%train_run 15 1","372a573d":"#model=models.vgg16(pretrained=True)\n#for param in model.parameters():\n#    param.requires_grad=False#model.classifier[3].requires_grad=True\n#num_classes=33\n#model.classifier[6]=tnn.Sequential(\n#    tnn.Linear(4096,256),tnn.ReLU(),\n#    tnn.Dropout(.5),tnn.Linear(256,num_classes))\n#model=model.to(dev)\n#optimizer=torch.optim.Adam(model.parameters())","72a725ab":"#%train_run 3 2","5ca803e1":"[Google Colaboratory Version](https:\/\/colab.research.google.com\/drive\/1PxqVoIvUkv-bYDMTGtCNYNji3-ObqNWz)"}}