{"cell_type":{"cd9053f4":"code","4730ea44":"code","cfaaf998":"code","a0805521":"code","e4691a96":"code","7f74a721":"code","6046492d":"code","1f79d054":"code","6b209bbc":"code","bf626291":"code","3dc27f01":"code","0b9f9beb":"code","38e40e51":"code","33d8bc47":"code","f481306f":"code","f7e00e77":"code","23289278":"code","e6b59160":"code","490f2fb7":"code","a252a2fe":"code","ad6c7c5c":"code","9d5fc212":"code","85065fdf":"code","b1230254":"code","3323bd52":"code","fdb7d293":"code","74861a1a":"code","43b9ae25":"code","96253db8":"code","ee031028":"code","abfcf0d4":"code","c55bb487":"code","5c6af574":"code","c4a82986":"code","08e337e5":"code","ddcf49ce":"code","ab98832d":"code","f18c19ab":"code","a578e0cb":"code","62b10096":"code","56d351c8":"code","2f5b6cd4":"code","1e58581f":"code","ea3a81e9":"code","1266ad9d":"code","8f2cb94d":"code","cc5dd5bf":"code","5b79e5ae":"code","bf96fe86":"code","3b3ea6c0":"code","b65febf0":"code","42680cc8":"markdown","a345e7a0":"markdown","c25f1749":"markdown","777ecb3a":"markdown","715b91bf":"markdown","03b69c06":"markdown","8b0782ee":"markdown","3b1dc5f0":"markdown","60437c6b":"markdown","aebf50df":"markdown","74a63594":"markdown","bd89e69d":"markdown","6c48f5fd":"markdown","166bea7d":"markdown","04208760":"markdown","e4a4f5e1":"markdown","0bbb419e":"markdown","9e0387a1":"markdown","9895475a":"markdown","c4cefe38":"markdown","b1c81ae9":"markdown","51015603":"markdown","552d1639":"markdown","2ed8c5bb":"markdown","9da2716a":"markdown","fc0695e6":"markdown","d4d33614":"markdown","5a6ff5e3":"markdown","293ea1ef":"markdown","fc67e5bf":"markdown","c4ebece3":"markdown","9cefd30a":"markdown","60f0c2fd":"markdown","59c58719":"markdown","14c1a4d8":"markdown","3504e72b":"markdown","c71cf99c":"markdown","64a00b45":"markdown","c6424826":"markdown","49cde3c5":"markdown","fec4d756":"markdown","025ca9c3":"markdown","4d98b1c2":"markdown","b1c12370":"markdown","d7e1f3c1":"markdown","8d915a00":"markdown","00aa5d41":"markdown","2b06b25d":"markdown","48de3c1b":"markdown","2aba89fd":"markdown","76268803":"markdown","ebc97e2c":"markdown"},"source":{"cd9053f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4730ea44":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score","cfaaf998":"df = pd.read_csv('\/kaggle\/input\/automobile-dataset\/Automobile_data.csv')\ndf.head()","a0805521":"df.isnull().sum(axis=0)","e4691a96":"df.info()","7f74a721":"for col in df.columns:\n    if('?' in df[col].values):\n        print(col + \" = \" + str(len(df[df[col]=='?'])))","6046492d":"# Converting price column type to numeric & Dropping '?' entries from price column \ndf['price'] = df['price'].replace('?',np.nan)\ndf['price'] = pd.to_numeric(df['price'])\ndf = df[df['price'].notna()]\n\n# Dropping '?' from num-of-doors column \ndf['num-of-doors'] = df['num-of-doors'].replace('?',np.nan)\ndf = df[df['num-of-doors'].notna()]\ndf.info()","1f79d054":"# Converting column type to numeric and replacing '?' with mean value\nnum_col = ['normalized-losses', 'bore',  'stroke', 'horsepower', 'peak-rpm']\nfor col in num_col:\n    df[col] = df[col].replace('?', np.nan)\n    df[col] = pd.to_numeric(df[col])\n    df[col].fillna(df[col].mean(), inplace=True)\ndf.head(10)","6b209bbc":"print(\"Columns in our dataset: \" , df.columns)","bf626291":"print(\"List of Numerical features: \" , df.select_dtypes(include=np.number).columns.tolist())\nprint(\"List of Categorical features: \" , df.select_dtypes(include=['object']).columns.tolist())","3dc27f01":"corr = df[['symboling', 'normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', \n           'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']].corr()\nf,axes = plt.subplots(1,1,figsize = (15,15))\nsns.heatmap(corr,square=True,annot = True,linewidth = .5,center = 2,ax = axes)\n","0b9f9beb":"num = df.select_dtypes(include=np.number)\nnumcorr = num.corr()\nf,ax = plt.subplots(figsize=(15,3))\nsns.heatmap(numcorr.sort_values(by=['price'], ascending=False).head(1))\nplt.title(\" Numerical features correlation with price\", weight='bold', fontsize=20)\n\nplt.show()","38e40e51":"Num = numcorr['price'].sort_values(ascending=False).to_frame()\ncm = sns.light_palette(\"cyan\", as_cmap=True)\ns = Num.style.background_gradient(cmap=cm)\ns","33d8bc47":"plt.figure(figsize=(10,3))\nplt.scatter(x=df['engine-size'], y=df['price'], color='blue', alpha=0.6)\nplt.title('Engine-size vs Price', weight='bold', fontsize=16)\nplt.xlabel('Engine-size', weight='bold', fontsize=12)\nplt.ylabel('Price', weight='bold', fontsize=12)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.show()","f481306f":"plt.figure(figsize=(10,3))\nplt.scatter(x=df['horsepower'], y=df['price'], color='blue', alpha=0.6)\nplt.title('Horsepower vs Price', weight='bold', fontsize=16)\nplt.xlabel('Horsepower', weight='bold', fontsize=12)\nplt.ylabel('Price', weight='bold', fontsize=12)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.show()","f7e00e77":"sns.displot(df['normalized-losses'])\nplt.show()\n\nsns.displot(df['wheel-base'], rug=True)\nplt.show()\n","23289278":"sns.jointplot(data = df, x=df['engine-size'], y=df['horsepower'], kind=\"hex\")\nplt.show()","e6b59160":"sns.jointplot(data = df, x=df['engine-size'], y=df['horsepower'], hue=\"engine-location\")\nplt.show()","490f2fb7":"df.rename(columns={'body-style': 'bodystyle'}, inplace=True)\n\n# Figure Size\nfig, ax = plt.subplots(figsize=(9,6))\n\n# Horizontal Bar Plot\ntitle_cnt=df.bodystyle.value_counts().sort_values(ascending=False).reset_index()\nmn= ax.barh(title_cnt.iloc[:,0], title_cnt.iloc[:,1],edgecolor='black', color=sns.color_palette('pastel',len(title_cnt)))\n\n\n\n\n# Remove axes splines\nfor s in ['top','bottom','left','right']:\n    ax.spines[s].set_visible(False)\n\n# Remove x,y Ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Add padding between axes and labels\nax.xaxis.set_tick_params(pad=5)\nax.yaxis.set_tick_params(pad=10)\n\n# Add x,y gridlines\nax.grid(b=True, color='grey', linestyle='-.', linewidth=1, alpha=0.2)\n\n# Show top values \nax.invert_yaxis()\n\n# Add Plot Title\nax.set_title('Most frequent car body style',weight='bold',\n             loc='center', pad=10, fontsize=16)\nax.set_xlabel('Count', weight='bold')\n\n# Add annotation to bars\nfor i in ax.patches:\n    ax.text(i.get_width()+1, i.get_y()+0.5, str(round((i.get_width()), 2)),\n            fontsize=10, fontweight='bold', color='grey')\nplt.yticks(weight='bold')\nplt.xticks(weight='bold')\n\n\nplt.show()\n# Show Plot\nplt.show()","a252a2fe":"# Figure Size\nfig, ax = plt.subplots(figsize=(9,6))\n\n# Horizontal Bar Plot\ntitle_cnt=df.make.value_counts().sort_values(ascending=False).reset_index()\nmn= ax.barh(title_cnt.iloc[:,0], title_cnt.iloc[:,1],edgecolor='black', color=sns.color_palette('pastel',len(title_cnt)))\n\n\n\n\n# Remove axes splines\nfor s in ['top','bottom','left','right']:\n    ax.spines[s].set_visible(False)\n\n# Remove x,y Ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Add padding between axes and labels\nax.xaxis.set_tick_params(pad=5)\nax.yaxis.set_tick_params(pad=10)\n\n# Add x,y gridlines\nax.grid(b=True, color='grey', linestyle='-.', linewidth=1, alpha=0.2)\n\n# Show top values \nax.invert_yaxis()\n\n# Add Plot Title\nax.set_title('Car type',weight='bold',\n             loc='center', pad=10, fontsize=16)\nax.set_xlabel('Count', weight='bold')\n\n# Add annotation to bars\nfor i in ax.patches:\n    ax.text(i.get_width()+1, i.get_y()+0.5, str(round((i.get_width()), 2)),\n            fontsize=10, fontweight='bold', color='grey')\nplt.yticks(weight='bold')\nplt.xticks(weight='bold')\n\n\nplt.show()\n# Show Plot\nplt.show()","ad6c7c5c":"df.rename(columns={'drive-wheels': 'drivewheels'}, inplace=True)\n\n# Figure Size\nfig, ax = plt.subplots(figsize=(9,6))\n\n# Horizontal Bar Plot\ntitle_cnt=df.drivewheels.value_counts().sort_values(ascending=False).reset_index()\nmn= ax.barh(title_cnt.iloc[:,0], title_cnt.iloc[:,1],edgecolor='black', color=sns.color_palette('pastel',len(title_cnt)))\n\n\n\n\n# Remove axes splines\nfor s in ['top','bottom','left','right']:\n    ax.spines[s].set_visible(False)\n\n# Remove x,y Ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Add padding between axes and labels\nax.xaxis.set_tick_params(pad=5)\nax.yaxis.set_tick_params(pad=10)\n\n# Add x,y gridlines\nax.grid(b=True, color='grey', linestyle='-.', linewidth=1, alpha=0.2)\n\n# Show top values \nax.invert_yaxis()\n\n# Add Plot Title\nax.set_title('Drive wheels',weight='bold',\n             loc='center', pad=10, fontsize=16)\nax.set_xlabel('Count', weight='bold')\n\n# Add annotation to bars\nfor i in ax.patches:\n    ax.text(i.get_width()+1, i.get_y()+0.5, str(round((i.get_width()), 2)),\n            fontsize=10, fontweight='bold', color='grey')\nplt.yticks(weight='bold')\nplt.xticks(weight='bold')\n\n\nplt.show()\n# Show Plot\nplt.show()","9d5fc212":"# For statistical description of numerical columns\ndf.describe() ","85065fdf":"# Numerical Columns\ndf.select_dtypes(include=np.number).columns.tolist()","b1230254":"# Taking first 6 columns\nnumeric_cols = ['symboling', 'normalized-losses', 'wheel-base', 'length', 'width', 'height'] \nplt.figure(figsize=(12,8))\nplt.title(\"Numerical Variables in Automobile Dataset\")\ndf[numeric_cols].boxplot(color='blue')\nplt.show()","3323bd52":"# Taking rest of the numeric columns\nnumeric_cols = ['curb-weight', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']\nplt.figure(figsize=(12,15))\nplt.title(\"Numerical Variables in Automobile Dataset\")\ndf[numeric_cols].boxplot(color='blue')\nplt.show()","fdb7d293":"df.rename(columns={'normalized-losses': 'normalizedlosses', 'peak-rpm': 'peakrpm'}, inplace=True)\ndf.columns","74861a1a":"df['normalizedlosses'].unique()","43b9ae25":"df['normalizedlosses'] = df['normalizedlosses'].replace(256.0, np.nan)\ndf['normalizedlosses'].fillna(df['normalizedlosses'].mean(), inplace=True)\ndf['normalizedlosses'] = df['normalizedlosses'].replace(231.0, np.nan)\ndf['normalizedlosses'].fillna(df['normalizedlosses'].mean(), inplace=True)\ndf['normalizedlosses'].unique()","96253db8":"df['peakrpm'].unique()","ee031028":"df[df.peakrpm == 6600.0]","abfcf0d4":"# Dropping both entries\ni = df[((df.peakrpm == 6600.0))].index\ndf = df.drop(i)","c55bb487":"df.select_dtypes(include=['object']).copy().head()","5c6af574":"print(df[\"num-of-doors\"].value_counts())\nprint(df[\"num-of-cylinders\"].value_counts())","c4a82986":"cleanup_nums = {\"num-of-doors\":     {\"four\": 4, \"two\": 2},\n                \"num-of-cylinders\": {\"four\": 4, \"six\": 6, \"five\": 5, \"eight\": 8,\n                                  \"two\": 2, \"twelve\": 12, \"three\":3 }}\ndf = df.replace(cleanup_nums)\ndf.head()","08e337e5":"print(df['bodystyle'].unique())\nprint(df['drivewheels'].unique())","ddcf49ce":"df = pd.get_dummies(df, columns=[\"bodystyle\", \"drivewheels\"], prefix=[\"body\", \"drive\"])\ndf.head()","ab98832d":"df[\"engine-type\"].value_counts()","f18c19ab":"df[\"OHC_Code\"] = np.where(df[\"engine-type\"].str.contains(\"ohc\"), 1, 0)\ndf[[\"make\", \"engine-type\", \"OHC_Code\"]].head()","a578e0cb":"from sklearn.preprocessing import OrdinalEncoder\n\nord_enc = OrdinalEncoder()\ndf[\"make_code\"] = ord_enc.fit_transform(df[[\"make\"]])\ndf[[\"make\", \"make_code\"]].head(11)","62b10096":"print(df.columns)","56d351c8":"df.select_dtypes(include=np.number).columns.tolist()","2f5b6cd4":"feed = df[['symboling', 'normalizedlosses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'bore', 'stroke', \n           'compression-ratio', 'horsepower', 'peakrpm', 'city-mpg', 'highway-mpg', 'price', 'num-of-doors', 'num-of-cylinders', 'body_convertible', \n           'body_hardtop', 'body_hatchback', 'body_sedan', 'body_wagon', 'drive_4wd', 'drive_fwd', 'drive_rwd', 'OHC_Code', 'make_code']]\nfeed.info()","1e58581f":"# Taking all independent variable columns\ndf_train_x = feed.drop('price',axis = 1)\ndf_train_x.describe()","ea3a81e9":"# Target variable column\ndf_train_y = feed['price']\ndf_train_y.describe","1266ad9d":"x_train, x_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size=0.15, random_state=42)","8f2cb94d":"reg = LinearRegression().fit(x_train, y_train)\npredictions = reg.predict(x_test)","cc5dd5bf":"print(\"r2_score is : \" , r2_score(y_test, predictions))","5b79e5ae":"sns.regplot(x = y_test, y = predictions)","bf96fe86":"from sklearn.ensemble import GradientBoostingRegressor\nreg = GradientBoostingRegressor().fit(x_train, y_train)\npredictions = reg.predict(x_test)","3b3ea6c0":"print(\"r2_score is : \" , r2_score(y_test, predictions))","b65febf0":"sns.regplot(x = y_test, y = predictions)","42680cc8":"**Removing '?' and changing data type**","a345e7a0":"## **r2_score of Linear Regression**","c25f1749":"Hypothesis Testing\n\nFollowing we have three sections with the testings for hypothesis of relations between price and fuel type, aspiration and drive wheels.\nFuel Type\n\nThe fuel of a vehicle is the liquid that supplies the engine. In this dataset we have two types of fuel: diesel and gas.\n\ntable(Auto.Price$fuel.type)\n\n## \n## diesel    gas \n##     20    185\n\nsort(tapply(Auto.Price$price, Auto.Price$fuel.type, mean, na.rm=TRUE), decreasing=TRUE)\n\n##   diesel      gas \n## 15838.15 12916.41\n\nAt first, we notice that the type gas has fewer observations (20 out of 205, ~10%) when compared to diesel type (185 out of 205, ~90%).\n\nBy analyzing the price for each type, we see that they are very close and possibly our test may be inconclusive. To assert this hypothesis, we do a Welch Two Sample t-test, defining the following null and alternative hypothesis:\n\n    Null Hypothesis - H0: Mean price of diesel is equal to the mean price of gas\n    Alternative Hypothesis - HA: Mean price of diesel is different than the mean price of gas\n\nt.test(Auto.Price$price[Auto.Price$fuel.type == 'diesel'], \n       Auto.Price$price[Auto.Price$fuel.type == 'gas'], \"two.sided\", 0, FALSE, FALSE, 0.95)\n\n## \n##  Welch Two Sample t-test\n## \n## data:  Auto.Price$price[Auto.Price$fuel.type == \"diesel\"] and Auto.Price$price[Auto.Price$fuel.type == \"gas\"]\n## t = 1.5943, df = 23.611, p-value = 0.1242\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -863.9723 6707.4546\n## sample estimates:\n## mean of x mean of y \n##  15838.15  12916.41\n\nWith a not so small p-value, we can not reject the null hypothesis. But this does not mean that we can accept the null hypothesis, since there are two possible reasons as to why we failed: the alternative hypothesis was false to begin with; or we did not collect enough evidence for the alternative hypothesis.\nAspiration\n\nAspiration basically relates to how the engine\u2019s internal combustion works, being, for example, power enhanced with chargers. In our dataset there are only two types of aspiration: std (standard) or turbo (with turbocharger).\n\ntable(Auto.Price$aspiration)\n\n## \n##   std turbo \n##   168    37\n\nsort(tapply(Auto.Price$price, Auto.Price$aspiration, mean, na.rm=TRUE), decreasing=TRUE)\n\n##    turbo      std \n## 16254.81 12542.18\n\nWe can notice that turbo has fewer observations (37 out of 205, ~18%) than std (168 out of 205, ~82%), but these do not seem to be too extreme to affect our results.\n\nAlso, by analyzing the price for each type of aspiration, we see that turbo has a higher mean price than std. To assert this hypothesis, we do a Welch Two Sample t-test, defining the following null and alternative hypothesis:\n\n    Null Hypothesis - H0: Mean price of turbo is lesser or equal than the mean price of std\n    Alternative Hypothesis - HA: Mean price of turbo is greater than the mean price of std\n\nt.test(Auto.Price$price[Auto.Price$aspiration == 'turbo'], \n       Auto.Price$price[Auto.Price$aspiration == 'std'], \"greater\", 0, FALSE, FALSE, 0.95)\n\n## \n##  Welch Two Sample t-test\n## \n## data:  Auto.Price$price[Auto.Price$aspiration == \"turbo\"] and Auto.Price$price[Auto.Price$aspiration == \"std\"]\n## t = 3.0693, df = 64.602, p-value = 0.001568\n## alternative hypothesis: true difference in means is greater than 0\n## 95 percent confidence interval:\n##  1694.08     Inf\n## sample estimates:\n## mean of x mean of y \n##  16254.81  12542.18\n\nWith a very small p-value, we can reject the null hypothesis, confirming our finding that the mean price of turbo aspiration is greater than the mean price of the std aspiration.\nDrive Wheels\n\nDrive wheels essentially dictates the traction of the cars, into 4 wheels (4wd), two forward wheels (fwd) or two rear wheels (rwd). Observing the variable drive.wheels, we see it has exactly three levels: 4wd, fwd and rwd.\n\ntable(Auto.Price$drive.wheels)\n\n## \n## 4wd fwd rwd \n##   9 120  76\n\nsort(tapply(Auto.Price$price, Auto.Price$drive.wheels, mean, na.rm=TRUE), decreasing=TRUE)\n\n##      rwd      4wd      fwd \n## 19757.61 10241.00  9244.78\n\nWe can also notice that the level 4wd has very few observations (9 out of 205, ~4%) and for this reason may be hard to account while making sure to not overfit. Therefore, we will only compare rwd and fwd.\n\nBy analyzing the price for each level, we see that rwd has a higher mean price than fwd. The following plot also seems to confirm this hypothesis.\n\nlibrary(ggplot2)\nggplot(Auto.Price[Auto.Price$drive.wheels %in% c('fwd','rwd'),], aes(price)) + \n    geom_histogram(binwidth=1000, na.rm=TRUE) + facet_grid(. ~ drive.wheels) + \n    labs(title = \"Histogram of Price by Drive Wheels fwd and rwd\") + labs(x = \"Price (US$)\", y = \"Frequency\")\n\nTo assert this hypothesis, we do a Welch Two Sample t-test, defining the following null and alternative hypothesis:\n\n    Null Hypothesis - H0: Mean price of rwd is lesser or equal than the mean price of fwd\n    Alternative Hypothesis - HA: Mean price of rwd is greater than the mean price of fwd\n\nt.test(Auto.Price$price[Auto.Price$drive.wheels == 'rwd'], \n       Auto.Price$price[Auto.Price$drive.wheels == 'fwd'], \"greater\", 0, FALSE, FALSE, 0.95)\n\n## \n##  Welch Two Sample t-test\n## \n## data:  Auto.Price$price[Auto.Price$drive.wheels == \"rwd\"] and Auto.Price$price[Auto.Price$drive.wheels == \"fwd\"]\n## t = 9.6178, df = 86.907, p-value = 1.232e-15\n## alternative hypothesis: true difference in means is greater than 0\n## 95 percent confidence interval:\n##  8695.536      Inf\n## sample estimates:\n## mean of x mean of y \n##  19757.61   9244.78\n\nWith a very small p-value, we can reject the null hypothesis, confirming our finding that the mean price of rwd drive wheel is greater than the mean price of the fwd drive wheel.","777ecb3a":"## (a) Checking Outliers","715b91bf":"## Observations:\nNow we start analysing our dataset but before that we need to do some data preprocessing in order to handle missing values and outliers. As you can there are some '?' in normalized-losses column. ","03b69c06":"**Observations:**\n* There are 41 '?' in normalized losses column\n* Others have 2-4 entries with '?'.\n\n**To handle**\n* We will drop '?' entries of price column & num-of-doors column.\n* We will replace '?' with mean value for every other column.","8b0782ee":"## (a) Find and Replace: num-of-doors & num-of-cylinders\nThere are two columns of data where the values are words used to represent numbers: the number of cylinders and number of doors on the car. ","3b1dc5f0":"## **r2_score of Gradient Boosting Regressor**","60437c6b":"\nInitially we had 205 entries, and now we have 201 entries because we've dropped 4 '?' entries from price column and 2 entries from num-of-doors column.","aebf50df":"## (a) Checking for missing values","74a63594":"**Observations:**\n* All columns have 205 non null entries but as we saw in head entries '?' are present which are actually missing values only.\n* Columns with numerical values are of object type. For e.g normalized-losses, bore, stroke, horsepower, peak-rpm, price.","bd89e69d":"This seems like a duplicate entry. Among independent variables only body-style is different. Let's remove these 2 entries.","6c48f5fd":"# **3. Data Preprocessing (Cleaning) \ud83e\uddf9**","166bea7d":"# **(B) Gradient Boosting Regressor Model**","04208760":"# **6. Building Machine Learning Model** \ud83e\udd16","e4a4f5e1":"## **Gradient Boosting Regressor with r2 score of 0.93 performed better than Linear Regression with r2 score of 0.90**","0bbb419e":"## (c) Univariate Distribution \nPicking one continuous variable and checking its distribution.","9e0387a1":"# **(A) Linear Regression Model**","9895475a":"**Example of a strong correlation between 2 numerical features: price and horsepower**","c4cefe38":"**Boxplot for Visualizing Outliers**","b1c81ae9":"# **1. Importing Necessary Libraries** \ud83d\udcda","51015603":"In normalized-losses column most of the values are below 200 but maximum value is 256 that's weird!\nLet's visualize the numerical quantities in our dataset as boxplots, to have a better sense of the outliers.","552d1639":"## (b) Handling Outliers","2ed8c5bb":"## (b) Dummy Variable Encoding for body-style column and drive-wheels","9da2716a":"For the sake of discussion, maybe all we care about is whether or not the engine is an Overhead Cam (OHC) or not. In other words, the various versions of OHC are all the same for this analysis.","fc0695e6":"Let's dig in more into the data, those are just the numerical features. I assume that categorical features will be very important like body-style.","d4d33614":"Interesting! The engine-size,curb-weight, horsepower have the highest correlation values with the price.\n**Example of a strong correlation between 2 numerical features: price and engine-size**","5a6ff5e3":"## (c) Custom Binary Encoding for engine-type","293ea1ef":"* **For normalized-losses outliers: Replace with mean value.**\n* **For peak-rpm: Remove outlier entry.**","fc67e5bf":"## (d) Ordinal Encoding for make column","c4ebece3":"## Visualization","9cefd30a":"## (e) Visualization for Categorical Variables","60f0c2fd":"**2 outliers in normalized-losses column.**","59c58719":"## (b) Correlation between numerical features and target Price","14c1a4d8":"## (b) Splitting of Training & Testing sets","3504e72b":"## (a) Preparing Training and Testing datasets","c71cf99c":"# **Selecting Necessary Columns for ML Model**","64a00b45":"## (a) Correlation Between Numerical Features","c6424826":"**No missing values.**","49cde3c5":"# **2. Loading Automobile Dataset** \ud83d\udcca","fec4d756":"# **4. Exploratory Data Analysis** \ud83d\udcc9","025ca9c3":"**Printing all categorical variable columns**","4d98b1c2":"**Now we'll fit our linear regression & Gradient Boosting Regressor models on these numerical variables.**","b1c12370":"**1 outlier in peak-rpm**","d7e1f3c1":"Label encoding is simply converting each value in a column to a number.","8d915a00":"# **5. Feature Engineering** \u2699\ufe0f","00aa5d41":"# **Computation for Categorical Variables**","2b06b25d":"**Checking total entries with '?' in each column**","48de3c1b":"**To have a better idea, we sort the features according to their correlation with the price variable**","2aba89fd":"## (d) Bivariate Distribution","76268803":"## (b) Handling Missing Values","ebc97e2c":"# Task Details \ud83d\udcdd\nPredict the price of the car based on the features in the dataset.\n\n# Evaluation \u2714\ufe0f\nA model with good r2 score"}}