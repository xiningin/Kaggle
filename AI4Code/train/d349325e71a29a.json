{"cell_type":{"24ebec80":"code","3e4d51e2":"code","d9ec2d42":"code","b45ed45b":"code","11b11553":"code","6289e0b7":"code","8704d051":"code","4d786470":"code","0b502acd":"code","50ae1f0f":"code","ab32d218":"code","5a4b3346":"code","242e5eed":"code","392a1817":"code","da4c227d":"code","992097b5":"code","5321a045":"code","4ee67446":"code","16c9dac0":"code","b7b9bdce":"code","fe63dde7":"code","a57f765f":"code","00545656":"code","3fd5b745":"code","74c0cbbf":"code","ab734cea":"code","13d0b995":"code","6d996d1b":"code","ee35a53d":"code","e3663795":"code","c8253bc2":"code","1b248ffe":"code","28788994":"code","0e4e5146":"markdown","ad471648":"markdown","da131b87":"markdown","00dffda3":"markdown","dd1b5ebd":"markdown","d28d3fd0":"markdown","bf5a0f48":"markdown","dc4e9763":"markdown","771ac4db":"markdown","a9834196":"markdown","e029e569":"markdown","ce9cab9e":"markdown","e6e71f5f":"markdown","75502e14":"markdown","4ca03482":"markdown","075c3517":"markdown"},"source":{"24ebec80":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nimport re\nimport sys\nimport warnings\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\n","3e4d51e2":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom tensorflow.keras.layers import Bidirectional, GRU, Conv1D, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score","d9ec2d42":"train = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip')\ntest = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')","b45ed45b":"train.head()","11b11553":"print(\"Check for missing values in Train dataset\")\nnull_check=train.isnull().sum()\nprint(null_check)\nprint(\"Check for missing values in Test dataset\")\nnull_check=test.isnull().sum()\nprint(null_check)\nprint(\"filling NA with \\\"unknown\\\"\")\ntrain[\"comment_text\"].fillna(\"unknown\", inplace=True)\ntest[\"comment_text\"].fillna(\"unknown\", inplace=True)\n","6289e0b7":"data = train\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\ndef cleanHtml(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', str(sentence))\n    return cleantext\ndef cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]',r' ',cleaned)\n    cleaned = cleaned.strip()\n    cleaned = cleaned.replace(\"\\n\",\" \")\n    return cleaned\ndef keepAlpha(sentence):\n    alpha_sent = \"\"\n    for word in sentence.split():\n        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n        alpha_sent += alpha_word\n        alpha_sent += \" \"\n    alpha_sent = alpha_sent.strip()\n    return alpha_sent\ndata['comment_text'] = data['comment_text'].str.lower()\ndata['comment_text'] = data['comment_text'].apply(cleanHtml)\ndata['comment_text'] = data['comment_text'].apply(cleanPunc)\ndata['comment_text'] = data['comment_text'].apply(keepAlpha)","8704d051":"from nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nstop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\nre_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\ndef removeStopWords(sentence):\n    global re_stop_words\n    return re_stop_words.sub(\" \", sentence)\ndata['comment_text'] = data['comment_text'].apply(removeStopWords)","4d786470":"train = data\nprint(train.shape)\n","0b502acd":"train.head()","50ae1f0f":"test.head()","ab32d218":"data = test\n\ndata['comment_text'] = data['comment_text'].str.lower()\ndata['comment_text'] = data['comment_text'].apply(cleanHtml)\ndata['comment_text'] = data['comment_text'].apply(cleanPunc)\ndata['comment_text'] = data['comment_text'].apply(keepAlpha)\ndata['comment_text'] = data['comment_text'].apply(removeStopWords)\n\ntest = data\nprint(test.shape)","5a4b3346":"test.head()","242e5eed":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_train = train[\"comment_text\"]\nlist_sentences_test = test[\"comment_text\"]","392a1817":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","da4c227d":"maxlen = 200\nX_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\nprint(X_train.shape)\nprint(y.shape)\nprint(X_test.shape)","992097b5":"X_train, X_val, y_train, y_val = train_test_split(X_train, y, train_size=0.8, random_state=233)","5321a045":"class RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))","4ee67446":"def model():\n    inputs = Input(shape=(maxlen,), name=\"input\")\n    layer = Embedding(max_features, 128, name=\"embedding\")(inputs)\n    layer = Bidirectional(GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name=\"bi_gru_0\"))(layer)\n    layer = Conv1D(64, kernel_size = 3, padding = \"valid\", activation='relu', name=\"conv1d_0\")(layer)\n    layer = GlobalAveragePooling1D(name=\"avg_pool_0\")(layer)\n    layer = Dense(32,name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5,name=\"fc1_dropout\")(layer)\n    layer = Dense(6,name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs,outputs=layer)\n    return model","16c9dac0":"model = model()\nmodel.summary()","b7b9bdce":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                  optimizer='adam',\n                  metrics=['accuracy'])","fe63dde7":"checkpoint_path = os.path.join(\"..\/input\/output\/\",\"lstm-custom-embeddings-v4.hdf5\")\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 verbose=1, monitor='val_accuracy',save_best_only=True, mode='max')\n\n\nra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)","a57f765f":"batch_size = 64\nepochs = 3\nhistory = model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),shuffle=True, callbacks=[cp_callback,ra_val])","00545656":"y_pred = model.predict(X_test,batch_size=1024,verbose=1)","3fd5b745":"'''\nsubmission = pd.read_csv(os.path.join(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/\",\"sample_submission.csv.zip\"))\nsubmission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\nsubmission.to_csv(os.path.join(\"..\/input\/toxic-comment-challenge-submission\/\",'submission.csv'), index=False)\n'''","74c0cbbf":"test_labels = pd.read_csv(os.path.join(\"..\/input\/jigsaw-toxic-comment-classification-challenge\",\"test_labels.csv.zip\"))","ab734cea":"test_set = test.join(test_labels.set_index(\"id\"),on=\"id\")","13d0b995":"test_set.head()","6d996d1b":"test_set = test_set[test_set.obscene!=-1]","ee35a53d":"test_set.head()","e3663795":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny_test = test_set[list_classes].values\nlist_sentences_test = test_set[\"comment_text\"]","c8253bc2":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_test))\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","1b248ffe":"maxlen = 200\nX_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\nprint(y_test.shape)\nprint(X_test.shape)","28788994":"model.evaluate(X_test,y_test)","0e4e5146":"Check for any null values in the training or test set and fill them up","ad471648":"Read in the necessary libraries","da131b87":"Load in the training labels","00dffda3":"For the testing kaggle had marked the labels of certain samples in the test labels to be -1 since they were not used for testing. So it is necessary to eliminate those rows from the test set and test labels. To do that I join the test sentences and the test labels based on the id column and then eliminate the test labels that are labelled -1.","dd1b5ebd":"As you can see I got an accuracy of 99.76%","d28d3fd0":"Code for implementing AUC-ROC evaluation","bf5a0f48":"Clean the data by removing any html tags, cleaning any punctuations, special characters, IP addresses.","dc4e9763":"Read in the training and testing data","771ac4db":"Tokenize the training and test data","a9834196":"Apply the same preprocessing functions to test data","e029e569":"Split into training and validation sets","ce9cab9e":"Make the length of input sequences to be 200 words","e6e71f5f":"Check pointing the model based on validation accuracy and creating a callback for AUC-ROC evaluation","75502e14":"remove any stopwords from the data","4ca03482":"Define the model. We will be training our embeddings. It is followed by a bidirectional GRU layer. Then a Conv1D layer and then a Global avg pooling layer. A dense layer of 32 neurons is connected to it which has a relu activation and the final layer has 6 neurons and sigmoid activation.","075c3517":"Since I am posting this notebook after the competition is over I had access to the test labels and I evaluated my model on them"}}