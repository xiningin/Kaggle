{"cell_type":{"5eac7f37":"code","bc2e8358":"code","d67aca5c":"code","d2304f8c":"code","77a4682a":"code","1bdbccbe":"code","950224a6":"code","db179d57":"code","9f28b1f0":"code","9b348380":"code","8828b565":"code","16aa1ec2":"code","c6b41d04":"code","67b22634":"code","1976bee4":"code","cbff173d":"code","d975c551":"markdown","942b7345":"markdown"},"source":{"5eac7f37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc2e8358":"dataset = pd.read_csv(\"..\/input\/mushroom-classification\/mushrooms.csv\")\ndataset.head()","d67aca5c":"dataset.shape","d2304f8c":"sns.heatmap(dataset.isnull(),yticklabels=False,cbar=False,cmap='viridis')","77a4682a":"columns = dataset.columns\ncolumns\nfor i in columns:\n    print(i,\": \",dataset[i].unique())","1bdbccbe":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\nX = dataset.drop(['class'],axis=1)\ny = dataset['class']\n\ncategorical_cols_X = [cname for cname in X.columns if \n                    X[cname].dtype == \"object\"]\ngood_label_cols = ['class']\n\nlabel_y_train = dataset.drop(categorical_cols_X, axis=1)\nordinal_encoder = OrdinalEncoder()\nlabel_y_train[good_label_cols] = ordinal_encoder.fit_transform(dataset[good_label_cols])\n\nX_train, X_test, y_train, y_test = train_test_split(X,label_y_train,train_size=0.8, test_size=0.2,random_state=0)\n\nlabel_X_train = X_train\nlabel_X_test = X_test\nlabel_X_train[categorical_cols_X] = ordinal_encoder.fit_transform(X_train[categorical_cols_X])\nlabel_X_test[categorical_cols_X] = ordinal_encoder.transform(X_test[categorical_cols_X])","950224a6":"X_test","db179d57":"y_train.tail()","9f28b1f0":"model = RandomForestClassifier()\nmodel.fit(label_X_train, y_train)\npreds = model.predict(label_X_test)\nprint(mean_absolute_error(y_test, preds))","9b348380":"y_test","8828b565":"# preds = model.predict(label_X_test)\npreds","16aa1ec2":"result = pd.DataFrame({'class': preds })\nresult.tail()","c6b41d04":"X_test.reset_index(drop=True, inplace=True)\nresult.reset_index(drop=True, inplace=True)\n\nsubmission = pd.concat([result,X_test],axis=1)\nsubmission.head()","67b22634":"X_test.reset_index(drop=True, inplace=True)\ny_test.reset_index(drop=True, inplace=True)\n\ntesting = pd.concat([y_test,X_test],axis=1)\ntesting.head()","1976bee4":"dataset.head()","cbff173d":"from sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_test,preds)\nprint(\"Random Forest Classifier Accuracy Value: {:.2f}\".format(accuracy))","d975c551":"# Mushroom Classification using Random Forest Classifier\n___\n\n### Task Details\nPerform Mushroom Classification using Random Forest Classification.\n\n### Evaluation\nThe notebook which gives highest accuracy.","942b7345":"___\n# Ordinal Encoder\n\nBy using Ordinal Encoder, we can change the data type of an object to numerical.\nBecause of all the dataset is an object, both X and y is transformed by Ordinal Encoder."}}