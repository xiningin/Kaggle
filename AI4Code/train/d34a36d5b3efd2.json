{"cell_type":{"74006e80":"code","d4adc673":"code","724733c3":"code","7bd9b9ca":"code","3b2261d2":"code","e1d03717":"code","bcc53670":"code","b19cc234":"code","40bbf88f":"code","192fd33b":"code","1f866890":"code","8522584e":"code","66ba8337":"code","661a0a9d":"code","2437e3e4":"code","1094eb19":"code","bcdb5d97":"code","666f8b6e":"code","cb7d1bdf":"code","eda65708":"code","ee0fe926":"code","6a9c147a":"code","11ece978":"code","5fe724e6":"code","efa46691":"code","a8d5ea69":"code","71b1eeed":"code","c0def1b2":"code","4c28d4fb":"code","77854853":"code","5234be8d":"code","7fe408cc":"code","00d22bba":"code","e338d52c":"code","a7669956":"code","60af0625":"code","43bf831d":"code","8efbf3a3":"code","05a58b1e":"code","0e28cd7a":"code","2fb1c5ae":"code","9d217729":"code","5f2c4988":"code","17968c52":"code","ed901515":"code","c8d2efc4":"code","9ad62bb5":"code","5b8f9c1b":"code","3333d90c":"code","05b322f8":"code","7f9d9551":"code","fb814e7f":"code","49a898b3":"code","0cf077cf":"code","254b7ee6":"code","259299aa":"markdown","d540f5e2":"markdown","3e26c670":"markdown","390ae04c":"markdown","5572c525":"markdown","2ee3ec40":"markdown","8fbd4306":"markdown","61dce713":"markdown","b22a4fc8":"markdown","88f7b4eb":"markdown","0ff60384":"markdown","3fc7ff84":"markdown","739df631":"markdown","f56dd814":"markdown","d9a9d387":"markdown","63c3914e":"markdown","b94bf1fd":"markdown","a31761e1":"markdown","18250f18":"markdown","5faf9cc2":"markdown"},"source":{"74006e80":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\n\n# Prediction tasks\nimport datetime\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\nfrom keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom keras.preprocessing.sequence import TimeseriesGenerator\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d4adc673":"# Global confirmed cases\nconfirmed_file = \"\/kaggle\/input\/ece657aw20asg4coronavirus\/time_series_covid19_confirmed_global.csv\"\nconfirmed = pd.read_csv(confirmed_file)\n\n# Global deaths\ndeaths_file = \"..\/input\/ece657aw20asg4coronavirus\/time_series_covid19_deaths_global.csv\"\ndeaths = pd.read_csv(deaths_file)\n\n# Global recovered\nrecovered_file = \"..\/input\/ece657aw20asg4coronavirus\/time_series_covid19_recovered_global.csv\"\nrecovered = pd.read_csv(recovered_file)","724733c3":"confirmed.head()","7bd9b9ca":"deaths.head()","3b2261d2":"recovered.head()","e1d03717":"# Some functions to help out with\ndef plot_predictions(test,predicted):\n    plt.plot(test, color='red',label='Real Confirmed')\n    plt.plot(predicted, color='blue',label='Predicted Confirmed')\n    plt.title('Confirmed Cases')\n    plt.xlabel('Time')\n    plt.ylabel('Confirmed Cases')\n    plt.legend()\n    plt.show()\n\ndef return_rmse(test,predicted):\n    rmse = math.sqrt(mean_squared_error(test, predicted))\n    print(\"The root mean squared error is {}.\".format(rmse))","bcc53670":"countries=['Brazil', 'Canada', 'Germany']\ny = confirmed.loc[confirmed['Country\/Region']=='Italy'].iloc[0,4:]\ns = pd.DataFrame({'Italy':y})\nfor c in countries:    \n    #pyplot.plot(range(y.shape[0]),y,'r--')\n    s[c] = confirmed.loc[confirmed['Country\/Region']==c].iloc[0,4:]\n#pyplot.plot(range(y.shape[0]),y,'g-')\ns.plot.line()","b19cc234":"country = 'Italy'\ny1 = confirmed.loc[confirmed['Country\/Region']==country].iloc[0,4:]\ny2 = deaths.loc[confirmed['Country\/Region']==country].iloc[0,4:]\ny3 = recovered.loc[confirmed['Country\/Region']==country].iloc[0,4:]\n\ndf = pd.DataFrame({'Confirmed':y1, 'Deaths':y2, 'Recovered':y3})\ndf.plot.line()","40bbf88f":"# choose country and build data\ncountry = 'Italy'\n\ndata = confirmed.loc[confirmed['Country\/Region']==country].iloc[0,4:]\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata = pd.DataFrame(data=data.values,columns=['Confirmed'],index=dti)","192fd33b":"# do train\/test split\nn_days_toPredict = 5\n\ntrain_data = data[:len(data)-n_days_toPredict]\ntest_data = data[len(data)-n_days_toPredict:]","1f866890":"# plot train\/test data\ndata['Confirmed'][:train_data.index[-1]].plot(figsize=(16,4),legend=True)\ndata['Confirmed'][train_data.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","8522584e":"# LSTM architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data)\nscaled_train_data = scaler.transform(train_data)\nscaled_test_data = scaler.transform(test_data)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data,scaled_train_data, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)","66ba8337":"# plot loss \nlosses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_lstm)), losses_lstm)","661a0a9d":"# do predictions \nlstm_predictions_scaled = []\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_data)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)","2437e3e4":"# transform predictions\nprediction = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaled),columns=['PREDICTED Confirmed'],index=test_data.index)","1094eb19":"return_rmse(test_data,prediction)","bcdb5d97":"plot_predictions(test_data,prediction)","666f8b6e":"plt.plot(train_data, label='Historical Confirmed')\nplt.plot(prediction, label='Predicted Confirmed')\nplt.plot(test_data, label='Actual Confirmed')\nplt.legend();","cb7d1bdf":"global_cases = confirmed.iloc[:,4:].sum(axis=0)\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata2 = pd.DataFrame(data=global_cases.values,columns=['Confirmed'],index=dti)","eda65708":"# do train\/test split\nn_days_toPredict = 5\n\ntrain_dataG = data2[:len(data2)-n_days_toPredict]\ntest_dataG = data2[len(data2)-n_days_toPredict:]","ee0fe926":"# plot train\/test data\ndata2['Confirmed'][:train_dataG.index[-1]].plot(figsize=(16,4),legend=True)\ndata2['Confirmed'][train_dataG.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","6a9c147a":"# LSTM architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_dataG)\nscaled_train_dataG = scaler.transform(train_dataG)\nscaled_test_dataG = scaler.transform(test_dataG)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_dataG,scaled_train_dataG, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)","11ece978":"# plot loss \nlosses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_lstm)), losses_lstm)","5fe724e6":"# do predictions \nlstm_predictions_scaledG = []\n\nbatch = scaled_train_dataG[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_dataG)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaledG.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)","efa46691":"# transform predictions\nprediction_global = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaledG),columns=['PREDICTED Confirmed'],index=test_dataG.index)","a8d5ea69":"return_rmse(test_dataG,prediction_global)","71b1eeed":"plot_predictions(test_dataG,prediction_global)","c0def1b2":"plt.plot(train_dataG, label='Historical Confirmed')\nplt.plot(prediction_global, label='Predicted Confirmed')\nplt.plot(test_dataG, label='Actual Confirmed')\nplt.legend();","4c28d4fb":"# forecast length\nforecast_length = 5\n\ntrain_data_forecast = data2\n\n# LSTM architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data_forecast)\nscaled_train_data_forecast = scaler.transform(train_data_forecast)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data_forecast,scaled_train_data_forecast, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)\n\n# predictions\n\nlstm_predictions_scaled_forecast = []\n\nbatch = scaled_train_data_forecast[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(forecast_length):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled_forecast.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n    \nprediction_forecast = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaled_forecast),columns=['PREDICTED Confirmed'],index=pd.date_range('2020-04-18', periods=forecast_length, freq='D'))","77854853":"plt.plot(train_data_forecast, label='Historical Confirmed')\nplt.plot(prediction_forecast, label='Predicted Confirmed')\nplt.legend();","5234be8d":"# choose country and build data\ncountry = 'Italy'\n\ndata = confirmed.loc[confirmed['Country\/Region']==country].iloc[0,4:]\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata = pd.DataFrame(data=data.values,columns=['Confirmed'],index=dti)","7fe408cc":"# do train\/test split\nn_days_toPredict = 5\n\ntrain_data = data[:len(data)-n_days_toPredict]\ntest_data = data[len(data)-n_days_toPredict:]","00d22bba":"# plot train\/test data\ndata['Confirmed'][:train_data.index[-1]].plot(figsize=(16,4),legend=True)\ndata['Confirmed'][train_data.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","e338d52c":"# GRU architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data)\nscaled_train_data = scaler.transform(train_data)\nscaled_test_data = scaler.transform(test_data)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data,scaled_train_data, length=n_input, batch_size=1)\n\ngru_model = Sequential()\ngru_model.add(GRU(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50, return_sequences = True))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50))\ngru_model.add(Dropout(0.2))\ngru_model.add(Dense(units = 1))\ngru_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\ngru_model.fit(generator, epochs = 30)","a7669956":"# plot loss \nlosses_gru = gru_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_gru)), losses_gru)","60af0625":"# do predictions \ngru_predictions_scaled = []\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_data)):   \n    gru_pred = gru_model.predict(current_batch)[0]\n    gru_predictions_scaled.append(gru_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[gru_pred]],axis=1)","43bf831d":"# transform predictions\nprediction_gru = pd.DataFrame(scaler.inverse_transform(gru_predictions_scaled),columns=['PREDICTED Confirmed'],index=test_data.index)","8efbf3a3":"return_rmse(test_data,prediction_gru)","05a58b1e":"plot_predictions(test_data,prediction_gru)","0e28cd7a":"plt.plot(train_data, label='Historical Confirmed')\nplt.plot(prediction_gru, label='Predicted Confirmed')\nplt.plot(test_data, label='Actual Confirmed')\nplt.legend();","2fb1c5ae":"global_cases = confirmed.iloc[:,4:].sum(axis=0)\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata2 = pd.DataFrame(data=global_cases.values,columns=['Confirmed'],index=dti)","9d217729":"# do train\/test split\nn_days_toPredict = 5\n\ntrain_dataG = data2[:len(data2)-n_days_toPredict]\ntest_dataG = data2[len(data2)-n_days_toPredict:]","5f2c4988":"# plot train\/test data\ndata2['Confirmed'][:train_dataG.index[-1]].plot(figsize=(16,4),legend=True)\ndata2['Confirmed'][train_dataG.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","17968c52":"# GRU architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_dataG)\nscaled_train_dataG = scaler.transform(train_dataG)\nscaled_test_dataG = scaler.transform(test_dataG)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_dataG,scaled_train_dataG, length=n_input, batch_size=1)\n\ngru_model = Sequential()\ngru_model.add(GRU(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50, return_sequences = True))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50))\ngru_model.add(Dropout(0.2))\ngru_model.add(Dense(units = 1))\ngru_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\ngru_model.fit(generator, epochs = 30)","ed901515":"# plot loss \nlosses_gru = gru_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_gru)), losses_gru)","c8d2efc4":"# do predictions \ngru_predictions_scaledG = []\n\nbatch = scaled_train_dataG[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_dataG)):   \n    gru_pred = gru_model.predict(current_batch)[0]\n    gru_predictions_scaledG.append(gru_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[gru_pred]],axis=1)","9ad62bb5":"# transform predictions\nprediction_global_gru = pd.DataFrame(scaler.inverse_transform(gru_predictions_scaledG),columns=['PREDICTED Confirmed'],index=test_dataG.index)","5b8f9c1b":"return_rmse(test_dataG,prediction_global_gru)","3333d90c":"plot_predictions(test_dataG,prediction_global_gru)","05b322f8":"plt.plot(train_dataG, label='Historical Confirmed')\nplt.plot(prediction_global_gru, label='Predicted Confirmed')\nplt.plot(test_dataG, label='Actual Confirmed')\nplt.legend();","7f9d9551":"# forecast length\nforecast_length = 5\n\ntrain_data_forecast = data2\n\n# GRU architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data_forecast)\nscaled_train_data_forecast = scaler.transform(train_data_forecast)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data_forecast,scaled_train_data_forecast, length=n_input, batch_size=1)\n\ngru_model = Sequential()\ngru_model.add(GRU(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50, return_sequences = True))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50))\ngru_model.add(Dropout(0.2))\ngru_model.add(Dense(units = 1))\ngru_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\ngru_model.fit(generator, epochs = 30)\n\n# predictions\n\ngru_predictions_scaled_forecast = []\n\nbatch = scaled_train_data_forecast[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(forecast_length):   \n    gru_pred = gru_model.predict(current_batch)[0]\n    gru_predictions_scaled_forecast.append(gru_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[gru_pred]],axis=1)\n    \nprediction_forecast_gru = pd.DataFrame(scaler.inverse_transform(gru_predictions_scaled_forecast),columns=['PREDICTED Confirmed'],index=pd.date_range('2020-04-18', periods=forecast_length, freq='D'))","fb814e7f":"plt.plot(train_data_forecast, label='Historical Confirmed')\nplt.plot(prediction_forecast_gru, label='Predicted Confirmed')\nplt.legend();","49a898b3":"# Italy\nplt.plot(train_data['2020-03-22':], label='Historical Confirmed')\nplt.plot(prediction, label='Predicted Confirmed by LSTM')\nplt.plot(prediction_gru, label='Predicted Confirmed by GRU')\nplt.plot(test_data, label='Actual Confirmed')\nplt.title(\"Italy\")\nplt.legend();","0cf077cf":"# global\nplt.plot(train_dataG['2020-03-22':], label='Historical Confirmed')\nplt.plot(prediction_global, label='Predicted Confirmed by LSTM')\nplt.plot(prediction_global_gru, label='Predicted Confirmed by GRU')\nplt.plot(test_dataG, label='Actual Confirmed')\nplt.title(\"Global\")\nplt.legend();","254b7ee6":"results = pd.DataFrame(data=np.zeros((2,4)),columns=['RMSE Italy LSTM','RMSE Italy GRU','RMSE Global LSTM','RMSE Globale GRU'],index=['Absolute RMSE','Relative RMSE'])\n# Absolute RMSE\n# LSTM\nresults.iloc[0,0] = resultsrmse_Italy_lstm = math.sqrt(mean_squared_error(prediction,test_data))\nresults.iloc[0,2] = math.sqrt(mean_squared_error(prediction_global,test_dataG))\n# GRU\nresults.iloc[0,1] = resultsrmse_Italy_gru = math.sqrt(mean_squared_error(prediction_gru,test_data))\nresults.iloc[0,3] = math.sqrt(mean_squared_error(prediction_global_gru,test_dataG))\n\n# LSTM\nresults.iloc[1,0] = results.iloc[0,0] \/ test_data.mean().values[0]\nresults.iloc[1,2] = results.iloc[0,2] \/ test_dataG.mean().values[0]\n# GRU\nresults.iloc[1,1] = results.iloc[0,1] \/ test_data.mean().values[0]\nresults.iloc[1,3] = results.iloc[0,3] \/ test_dataG.mean().values[0]\n\nresults","259299aa":"## Comparison","d540f5e2":"This kernel is created to face some of the current challenges about the Coronavirus related to time series data and machine learning. It provides some basic visualizations and compares different deep learning approaches to predict the confirmed cases caused by COVID-19. In detail, Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) models are considered.","3e26c670":"## Predictions of confirmed cases using GRU\n","390ae04c":"## Some visualization","5572c525":"## Libraries","2ee3ec40":"## Data import","8fbd4306":"### Numerical Comparison","61dce713":"## Using the whole dataset and doing the forecast for global cases\n\n**CAUTION:** Update daterange index for predicitons, if data is updated before.","b22a4fc8":"There will always be a number of 5 days to be predicted.","88f7b4eb":"The LSTM model can achieve reasonable accuracy, but differs significantly between several runs. It tends to show a more flattening effect than the actual development. Also, the global data tends to perform better on several runs.","0ff60384":"### Global Confirmed Cases","3fc7ff84":"### Italy","739df631":"# Assignment 4 - Coronavirus\n\nCreated by _Waterloo Warriors_\n\nMohammad Dib\n\nDaniel Weber","f56dd814":"### Visual Comparison","d9a9d387":"The results in the table above shows that in both cases (Italy and Global) the GRU model gave better results. Additionally, it is worth noting the best results, by a significent margin, were achieved using the global data and the GRU model.     ","63c3914e":"### Global Confirmed Cases","b94bf1fd":"There will always be a number of 5 days to be predicted.","a31761e1":"The GRU model achieved high accuracy, also the global data performed better.","18250f18":"## Predictions of confirmed cases using LSTM\n\nAccording to https:\/\/www.kaggle.com\/thebrownviking20\/intro-to-recurrent-neural-networks-lstm-gru, https:\/\/www.kaggle.com\/vanshjatana\/machine-learning-on-coronavirus and https:\/\/www.kaggle.com\/azizovitic\/sarima-lstm-for-novel-corona-virus-2019-dataset\n\n### Confirmed Cases in Italy","5faf9cc2":"### Using the whole dataset and doing the forecast for global cases\n\n**CAUTION:** Update daterange index for predicitons, if data is updated before."}}