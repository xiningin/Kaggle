{"cell_type":{"e53e25a8":"code","8cd8a20c":"code","d8ca70e2":"code","285e6d08":"code","a67af6d4":"code","5f4df671":"code","8dcf5569":"code","b8cc38c6":"code","158972e8":"code","28c28ba1":"code","d0b43bf7":"code","070d57b4":"markdown","b8746470":"markdown","aebf67ab":"markdown","ea32cda6":"markdown","08b43d46":"markdown","b004bd56":"markdown","528aa832":"markdown"},"source":{"e53e25a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cd8a20c":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n#\ub79c\ub364 \uc528\ub4dc\ub97c \uc138\uac1c \uc124\uc815,\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","d8ca70e2":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\n#batchsize\ub294 \uc5bc\ub9cc\ud07c\uc77c\ub54c \ub04a\uc5b4\uc11c \ud560\uc9c0, \uc5d0\ud3ec\ud06c\ub294 \ubc18\ubcf5\ud560 \ud69f\uc218 \nlearning_rate = 1e-2\ntraining_epochs = 15  #15\ub85c \uc124\uc815 \nbatch_size = 30","285e6d08":"train_data=pd.read_csv('mnist_train_label.csv',header=None, usecols=range(0,785))\ntest_data=pd.read_csv('mnist_test.csv',header=None, usecols=range(0,784))","a67af6d4":"x_train_data=train_data.loc[:,1:785]\ny_train_data=train_data.loc[:,0]\n\nx_train_data=np.array(x_train_data)\ny_train_data=np.array(y_train_data)\n\nx_train_data=torch.FloatTensor(x_train_data)\ny_train_data=torch.LongTensor(y_train_data)\n\nprint(x_train_data)\nprint(y_train_data)\n\ntrain_dataset = torch.utils.data.TensorDataset(x_train_data, y_train_data)\ndata_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True,          #\uc154\ud50c\uc740 \ub370\uc774\ud130\ub97c \uc11e\uc74c \n                                          drop_last=True)","5f4df671":"linear = torch.nn.Linear(784,10,bias=True)\ntorch.nn.init.normal_(linear.weight)\nmodel = torch.nn.Sequential(linear).to(device) # 'cuda'","8dcf5569":"loss = torch.nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","b8cc38c6":"total_batch = len(data_loader)\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        # (1000, 1, 28, 28) \ud06c\uae30\uc758 \ud150\uc11c\ub97c (1000, 784) \ud06c\uae30\uc758 \ud150\uc11c\ub85c \ubcc0\ud615\n        X = X.view(-1, 28*28).to(device)\n        # one-hot encoding\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc74c\n        Y = Y.to(device)\n        #%debug\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Learning finished')","158972e8":"with torch.no_grad():\n\n  x_test_data=test_data.loc[:,:]\n  x_test_data=np.array(x_test_data)\n  x_test_data=torch.from_numpy(x_test_data).float().to(device)\n\n \n \n \n  prediction = model(x_test_data)\n  correct_prediction = torch.argmax(prediction, 1)\n  \n  print(correct_prediction","28c28ba1":"correct_prediction = correct_prediction.cpu().numpy().reshape(-1,1)\nsubmit=pd.read_csv('submission.csv')\nprint(correct_prediction)\n\n\nfor i in range(len(correct_prediction)):\n  submit['Category'][i]= correct_prediction[i].item()\n\n\nsubmit","d0b43bf7":"submit.to_csv('2.csv',index=False,header=True)\n\n! kaggle competitions submit -c 2020-ai-exam-fashionmnist-1 -f 2.csv -m \"Message\"","070d57b4":"\uc81c\ucd9c \uc591\uc2dd\uc744 \ubd88\ub7ec\uc640\uc11c \uc608\uce21 \uac12\uc744 \ub123\uae30 ","b8746470":"\ubaa8\ub378 \ud559\uc2b5\ud558\uae30 ","aebf67ab":"\ud310\ub2e4\uc2a4\ub85c \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30 ","ea32cda6":"\ub2e8\uc77c \ub808\uc774\uc5b4 \uc124\uc815\ud558\uae30 ","08b43d46":"\uc5d0\ud3ec\ud06c \uac12 15\ub85c \uace0\uc815 , \ub098\uba38\uc9c0 \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130\ub4e4\ub3c4 \uc124\uc815 ","b004bd56":"\uc608\uce21 \uac12 \uad6c\ud558\uae30 ","528aa832":"csv\ub85c \ubcc0\ud658 \ud6c4 \uc81c\ucd9c\ud558\uae30 "}}