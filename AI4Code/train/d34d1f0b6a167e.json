{"cell_type":{"12df937e":"code","5ecc864f":"code","da5546b2":"code","48957f7b":"code","cdcf8047":"code","1b20aefd":"code","051ef501":"code","47cc2bbd":"code","0eb77b5c":"code","c4f57c00":"code","3a3286c3":"code","3ab1f705":"code","cb60798e":"markdown","305ad625":"markdown","eb17cf08":"markdown","dfdaaf77":"markdown","da1abc39":"markdown","2999348b":"markdown","fc2a6264":"markdown"},"source":{"12df937e":"# Code you have previously used to load data\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom learntools.core import *\n\n\n\n# Path of the file to read. We changed the directory structure to simplify submitting to a competition\niowa_file_path = '..\/input\/train.csv'\niowa_test_file_path = '..\/input\/test.csv'\n\ntrain_data = pd.read_csv(iowa_file_path)\ntest_data = pd.read_csv(iowa_test_file_path)\n# Create target object and call it y\ny = train_data.SalePrice\ntrain_features = train_data.drop(['SalePrice'], axis = 1)\n# Create X\n#features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n#X = home_data[features]","5ecc864f":"# fill in missing numeric values\nfrom sklearn.impute import SimpleImputer\n\n#Impute\ntrain_data_num = train_features.select_dtypes(exclude=['object'])\ntest_data_num = test_data.select_dtypes(exclude=['object'])\nimputer = SimpleImputer()\ntrain_num_cleaned = imputer.fit_transform(train_data_num)\ntest_num_cleaned = imputer.transform(test_data_num)\n\n#columns rename after imputing\ntrain_num_cleaned = pd.DataFrame(train_num_cleaned)\ntest_num_cleaned = pd.DataFrame(test_num_cleaned)\n\ntrain_num_cleaned.columns = train_data_num.columns\ntest_num_cleaned.columns = test_data_num.columns","da5546b2":"# string columns: transform to dummies\ntrain_data_str = train_data.select_dtypes(include=['object'])\ntest_data_str = test_data.select_dtypes(include=['object'])\ntrain_str_dummy = pd.get_dummies(train_data_str)\ntest_str_dummy = pd.get_dummies(test_data_str)\ntrain_dummy, test_dummy = train_str_dummy.align(test_str_dummy, \n                                                join = 'left', \n                                                axis = 1)","48957f7b":"print(train_num_cleaned.columns)\nprint(train_num_cleaned.index)\nprint(test_num_cleaned.columns)\nprint(test_num_cleaned.index)\nprint(train_dummy.columns)\nprint(train_dummy.index)\nprint(test_dummy.columns)\nprint(test_dummy.index)","cdcf8047":"# convert numpy to pandas DataFrame\ntrain_num_cleaned = pd.DataFrame(train_num_cleaned)\ntest_num_cleaned = pd.DataFrame(test_num_cleaned)","1b20aefd":"# joining numeric and string data\ntrain_all_clean = pd.concat([train_num_cleaned, train_dummy], axis = 1)\ntest_all_clean = pd.concat([test_num_cleaned, test_dummy], axis = 1)","051ef501":"# detect NaN in already cleaned test data \n# (there could be completely empty columns)\ncols_with_missing = [col for col in test_all_clean.columns\n                                if test_all_clean[col].isnull().any()]\nfor col in cols_with_missing:\n    print(col, test_all_clean[col].describe())","47cc2bbd":"# since there are empty columns in test we need to drop them in train and test\ntrain_all_clean_no_nan = train_all_clean.drop(cols_with_missing, axis = 1)\ntest_all_clean_no_nan = test_all_clean.drop(cols_with_missing, axis = 1)","0eb77b5c":"# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(train_all_clean_no_nan, y, random_state=1)\n\n# Specify Model\niowa_model = DecisionTreeRegressor(random_state=1)\n# Fit Model\niowa_model.fit(train_X, train_y)\n\n# Make validation predictions and calculate mean absolute error\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n# Using best value for max_leaf_nodes\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\niowa_model.fit(train_X, train_y)\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n# Define the model. Set random_state to 1\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(train_X, train_y)\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n","c4f57c00":"# To improve accuracy, create a new Random Forest model which you will train on all training data\nrf_model_on_full_data = RandomForestRegressor()\n\n# fit rf_model_on_full_data on all data from the training data\nrf_model_on_full_data.fit(train_all_clean_no_nan, y)\n","3a3286c3":"test_X = test_all_clean_no_nan\n\n# make predictions which we will submit. \ntest_preds = rf_model_on_full_data.predict(test_X)","3ab1f705":"output = pd.DataFrame({'Id': test_data.Id,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","cb60798e":"# Make Predictions\nRead the file of \"test\" data. And apply your model to make predictions","305ad625":"# Introduction\nMachine learning competitions are a great way to improve your data science skills and measure your progress. \n\nIn this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this micro-course.\n\nThe steps in this notebook are:\n1. Build a Random Forest model with all of your data (**X** and **y**)\n2. Read in the \"test\" data, which doesn't include values for the target.  Predict home values in the test data with your Random Forest model.\n3. Submit those predictions to the competition and see your score.\n4. Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard.","eb17cf08":"**[Machine Learning Micro-Course Home Page](https:\/\/www.kaggle.com\/learn\/machine-learning)**\n\n---\n","dfdaaf77":"# Creating a Model For the Competition\n\nBuild a Random Forest model and train it on all of **X** and **y**.  ","da1abc39":"# Test Your Work\nAfter filling in the code above:\n1. Click the **Commit and Run** button. \n2. After your code has finished running, click the small double brackets **<<** in the upper left of your screen.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n3. Go to the output tab at top of your screen. Select the button to submit your file to the competition.  \n4. If you want to keep working to improve your model, select the edit button. Then you can change your model and repeat the process.\n\nCongratulations, you've started competing in Machine Learning competitions.\n\n# Continuing Your Progress\nThere are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n\nThe best way to improve your model is to add features.  Look at the list of columns and think about what might affect home prices.  Some features will cause errors because of issues like missing values or non-numeric data types. \n\nLevel 2 of this micro-course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n\n\n# Other Micro-Courses\nThe **[Pandas Micro-Course](https:\/\/kaggle.com\/Learn\/Pandas)** will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n\nYou are also ready for the **[Deep Learning](https:\/\/kaggle.com\/Learn\/Deep-Learning)** micro-course, where you will build models with better-than-human level performance at computer vision tasks.","2999348b":"---\n**[Machine Learning Micro-Course Home Page](https:\/\/www.kaggle.com\/learn\/machine-learning)**\n\n","fc2a6264":"## Recap\nHere's the code you've written so far. Start by running it again."}}