{"cell_type":{"2efc6573":"code","297838fb":"code","3af26bce":"code","173d32c5":"code","02989583":"code","efafaa77":"code","32b2e279":"code","9526dff1":"markdown","f3873715":"markdown","fe08d5b0":"markdown","602f84ed":"markdown"},"source":{"2efc6573":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","297838fb":"segReport_df = pd.read_csv(\"..\/input\/traffic-flow-data-in-ho-chi-minh-city-viet-nam\/segment_reports.csv\", index_col=\"_id\", \n                            parse_dates=[\"updated_at\"])\nsegment_df = pd.read_csv(\"..\/input\/traffic-flow-data-in-ho-chi-minh-city-viet-nam\/segments.csv\", index_col=\"_id\",\n                         parse_dates=[\"created_at\", \"updated_at\"])","3af26bce":"from math import ceil\n\ndef transform_LOS(segment_id, velocity):\n    max_velocity = segment_df.loc[segment_id, \"max_velocity\"]\n    if max_velocity is None:\n        max_velocity = 50\n    \n    # Transform to label\n    labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n    threshold = 35\n    if max_velocity >= 70:\n        threshold = 45\n    elif max_velocity >= 60:\n        threshold = 40\n\n    t = max(threshold - velocity, 0)\n    return labels[min(ceil(t \/ 5), 5)]\n\ndef transform_report(row):\n    \"\"\"\n    @Params:\n        dt: Timestamp object of Pandas\n    @Return:\n        dict: {\"date\", \"period_{hour}_{00|30}\"}\n    \"\"\"\n    LOS = transform_LOS(row[\"segment_id\"], row[\"velocity\"])\n    dt = row[\"updated_at\"]\n    intervals = list(range(24))\n    h = dt.hour\n    m = \"00\" if dt.minute < 30 else \"30\"\n    p_name = f\"period_{h}_{m}\"\n    return dt.date(), dt.weekday(), p_name, LOS","173d32c5":"dates = []\nweekdays = []\np_names = []\nLOSes = []\n\nfor _, row in segReport_df.iterrows():\n    date, weekday, p_name, LOS = transform_report(row)\n    dates.append(date)\n    weekdays.append(weekday)\n    p_names.append(p_name)\n    LOSes.append(LOS)\n\nsegReport_df[\"date\"] = dates\nsegReport_df[\"weekday\"] = weekdays\nsegReport_df[\"period\"] = p_names\nsegReport_df[\"LOS\"] = LOSes","02989583":"def major_voting(labels):\n    unique_labels = set(labels)\n    count_labels = [labels.count(label) for label in unique_labels]\n\n    sorted_labels = sorted(zip(unique_labels, count_labels), key=lambda x: x[1])\n    if len(sorted_labels) > 1 and sorted_labels[0][1] == sorted_labels[1][1]:\n        print(\"Oh no, many majors?\")\n    return sorted_labels[0][0]\n\ndef mean_voting(labels):\n    l = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n    values = {\"A\":0, \"B\":1, \"C\":2, \"D\":3, \"E\":4, \"F\":5}\n    mean = sum(values[label] for label in labels) \/ len(labels)\n    return l[min(round(mean), 5)]","efafaa77":"compress_LOS = segReport_df.groupby(by=[\"segment_id\", \"date\", \"weekday\", \"period\"])[\"LOS\"].apply(list)\ncompress_LOS = pd.DataFrame(compress_LOS).reset_index()\ncompress_LOS[\"LOS\"] = compress_LOS[\"LOS\"].apply(mean_voting)","32b2e279":"compress_LOS","9526dff1":"## Do it!","f3873715":"## Transformation magic","fe08d5b0":"## Divide into periods may cause a period has many LOS labels, so need to mitigate this by setting a major label","602f84ed":"## Now the data should be good (maybe)"}}