{"cell_type":{"8dd41651":"code","471761ee":"code","85f8938c":"code","c779ae6d":"code","3ae7d8ad":"code","569346b9":"code","c210ecd8":"code","0b744439":"code","6875a035":"code","1ae95e57":"code","678f6835":"code","2ef61753":"code","8747aa23":"code","599eff4e":"code","c3ec5270":"code","201fc9a2":"code","4049f4a4":"code","0fad986c":"code","abd2cf9b":"code","08eccaa9":"code","f0e9e5b4":"code","ff237978":"code","3140562f":"code","fc31c33b":"code","b10c9185":"code","fd46ad0b":"code","fdc6c33c":"code","72f4a97d":"code","21d6768c":"code","60bde88c":"code","43c93f2e":"code","10b1d7b7":"code","1350ac71":"code","5b371586":"code","6fea35e8":"markdown","72b987ff":"markdown","65e70a1b":"markdown","94f1629f":"markdown","f6d88d98":"markdown","c43c1bdb":"markdown","fcb4d60a":"markdown","07afb5a6":"markdown","7ecaf95e":"markdown","d78e4128":"markdown","71943a62":"markdown","091f7484":"markdown","3b73f8a6":"markdown","4a1f9d65":"markdown","8b941c0b":"markdown","caaceb37":"markdown"},"source":{"8dd41651":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","471761ee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","85f8938c":"train_data = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/test.csv')","c779ae6d":"train_data.head()","3ae7d8ad":"train_data.info()","569346b9":"test_data.head()","c210ecd8":"test_data.info()","0b744439":"train_data.describe()","6875a035":"sns.countplot(x='price_range', data=train_data)\nplt.show()","1ae95e57":"corr = train_data.corr()\ncorr['price_range'].sort_values(ascending=False)","678f6835":"plt.figure(figsize=(14,10))\nsns.heatmap(corr,annot=True, fmt='.2f')\nplt.show()","2ef61753":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn import preprocessing\n\nfrom sklearn.feature_selection import RFE\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n","8747aa23":"def testing_model(x_train, x_test, y_train, y_test, model):\n  model.fit(x_train, y_train)\n  y_predict = model.predict(x_test)\n    \n  conv_matrix = confusion_matrix(y_test, y_predict)\n  sns.heatmap(conv_matrix, cmap= 'coolwarm', annot=True, fmt='.0f' )\n  print('                 Confusion matrix \\n')\n  plt.show()\n    \n  print('                 Classification report \\n')\n  print(classification_report(y_test, y_predict))\n","599eff4e":"X_train = train_data.iloc[:, :-1]\nY_train = train_data['price_range']\n\nx_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.3, random_state=10) \n\nscaler =  preprocessing.StandardScaler()\nscaler.fit(X_train)\nnorm_x_train = scaler.transform(x_train)\nnorm_x_test = scaler.transform(x_test)","c3ec5270":"tree = DecisionTreeClassifier(random_state=10)\ntesting_model(norm_x_train, norm_x_test, y_train, y_test, tree)","201fc9a2":"tree = DecisionTreeClassifier(random_state=10)\nrfe_tree = RFE(tree, n_features_to_select=4, verbose=1)\ntesting_model(norm_x_train, norm_x_test, y_train, y_test, rfe_tree)","4049f4a4":"rfe_tree.support_","0fad986c":"X_train.iloc[:, rfe_tree.support_].head()","abd2cf9b":"pca = PCA(n_components=5)\npca.fit(X_train)\npca_features = pca.transform(X_train)\n\nx_train, x_test, y_train, y_test = train_test_split(pca_features, Y_train, test_size = 0.3, random_state=10) \n\nscaler =  preprocessing.StandardScaler()\nscaler.fit(pca_features)\nnorm_x_train = scaler.transform(x_train)\nnorm_x_test = scaler.transform(x_test)","08eccaa9":"log = LogisticRegression(solver='lbfgs', max_iter=1000)\ntesting_model(x_train, x_test, y_train, y_test, log)","f0e9e5b4":"tree = DecisionTreeClassifier(random_state=10)\ntesting_model(x_train, x_test, y_train, y_test, tree)","ff237978":"rfe_tree.support_","3140562f":"X_train = train_data.iloc[:, :-1]\nX_corr = X_train.iloc[:, rfe_tree.support_]\nX_train = X_train.drop(X_corr.columns, axis=1)","fc31c33b":"pca = PCA(n_components=2)\npca.fit(X_train)\npca_features = pca.transform(X_train)\npca_features","b10c9185":"X_train = pd.concat([X_corr, pd.DataFrame(pca_features)], axis=1)\nX_train.head()","fd46ad0b":"x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.30, random_state=10) \n\nscaler =  preprocessing.StandardScaler()\nscaler.fit(X_train)\nnorm_x_train = scaler.transform(x_train)\nnorm_x_test = scaler.transform(x_test)","fdc6c33c":"log = LogisticRegression(random_state=10, max_iter=10000)\ntesting_model(x_train, x_test, y_train, y_test, log)","72f4a97d":"tree = DecisionTreeClassifier(random_state=10)\ntesting_model(x_train, x_test, y_train, y_test, tree)","21d6768c":"forest = RandomForestClassifier(random_state = 10)\ntesting_model(x_train, x_test, y_train, y_test, forest)","60bde88c":"from sklearn.model_selection import GridSearchCV","43c93f2e":"log = LogisticRegression(max_iter = 5000)\ngrid_param = {\n                'C': [0.7, 0.9, 1, 1.1, 1.2, 1.3],\n              }\n\ngridsearch = GridSearchCV(log, grid_param, cv=5, verbose=0,n_jobs=-1)\nbest_model = gridsearch.fit(x_train,y_train)\n\nprint(best_model.best_estimator_)\nprint('\\n Accuracy: ',best_model.score(x_test,y_test))","10b1d7b7":"tree = DecisionTreeClassifier()\ngrid_param = {\n                'max_depth': range(4, 20),\n                'min_samples_leaf' : range(2, 10),\n                'min_samples_split': range(2, 10),\n                'splitter': ['best','random']\n              }\n\ngridsearch = GridSearchCV(tree, grid_param, cv=5, verbose=0,n_jobs=-1)\nbest_model = gridsearch.fit(x_train,y_train)\n\nprint(best_model.best_estimator_)\nprint('\\n Accuracy: ',best_model.score(x_test,y_test))","1350ac71":"forest = RandomForestClassifier()\ngrid_param = {\n                'n_estimators': range(3, 24, 3),\n                'min_samples_split': range(2, 10)\n              }\n\ngridsearch = GridSearchCV(forest, grid_param, cv=5, verbose=0,n_jobs=-1)\nbest_model = gridsearch.fit(x_train,y_train)\n\nprint(best_model.best_estimator_)\nprint('\\n Accuracy: ',best_model.score(x_test,y_test))","5b371586":"svc = SVC()\ngrid_param = {\n                'kernel': ['linear','rbf']\n              }\n\ngridsearch = GridSearchCV(svc, grid_param, cv=5, verbose=0,n_jobs=-1)\nbest_model = gridsearch.fit(x_train,y_train)\n\nprint(best_model.best_estimator_)\nprint('\\n Accuracy',best_model.score(x_test,y_test))","6fea35e8":"# Features selection (RFE)","72b987ff":"## SVC","65e70a1b":"## Logistic Regression","94f1629f":"# Load The Dataset","f6d88d98":"## Logistic Regression","c43c1bdb":"## Decision Tree","fcb4d60a":"# Classification","07afb5a6":"## PCA + RFE","7ecaf95e":"## Logistic  Regression","d78e4128":"# Features extraction (PCA)","71943a62":"## Random Forest","091f7484":"## Decision Tree","3b73f8a6":"## Decision Tree","4a1f9d65":"# Grid Search","8b941c0b":"## Random Forest","caaceb37":"# Data Analysis"}}