{"cell_type":{"30d6408f":"code","0a048ff1":"code","ffb0bb10":"code","ba5f5580":"code","114ade09":"code","402d5a7a":"code","052edb9f":"code","1209ef53":"code","6960f7fd":"code","e989a9b5":"code","63139bc1":"code","739b641b":"code","38eead9f":"code","90770489":"code","13f15ddb":"code","afba2db4":"code","fbe7b69d":"code","7449c1eb":"code","f5cf9b69":"code","acba1a8b":"code","d0899085":"code","9beb99d6":"code","0ea0fb33":"code","80059f9a":"code","de343b93":"code","b6655827":"code","89d1c3fb":"code","8efc9d2f":"code","95f45a6e":"code","24676f9e":"code","a768577d":"code","8324691c":"markdown","c83cef13":"markdown","5742791f":"markdown","6e91ed33":"markdown","9c58a5c8":"markdown","b3b67956":"markdown","be5d7924":"markdown"},"source":{"30d6408f":"import numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn as nn\nimport albumentations as A\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\n\n\nfrom torch.utils.data import Dataset,DataLoader\nimport torchvision\nfrom torchvision import models,datasets,transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nfrom albumentations.core.composition import Compose,OneOf\nfrom albumentations.augmentations.transforms import CLAHE , GaussNoise ,ISONoise\n\nfrom albumentations.pytorch import ToTensorV2\n\nfrom pytorch_lightning import Trainer,seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import model_checkpoint, EarlyStopping\n\n\nfrom sklearn.model_selection import StratifiedKFold\n\n\nimport time\nimport os\nimport copy","0a048ff1":"!pip install timm","ffb0bb10":"class CFG:\n    \n    seed = 42\n    model_name = 'resnet50'\n    pretrained = False\n    img_size = 640\n    num_classes = 12\n    batch_size = 32\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","ba5f5580":"PATH = \"..\/input\/plant-pathology-2021-fgvc8\/\"\n\ntrain_path =  PATH+'train_images\/'\ntest_path = PATH+'test_images\/'","114ade09":"df_train = pd.read_csv(PATH+'train.csv')","402d5a7a":"df_train","052edb9f":"df_train['labels'].value_counts()","1209ef53":"list(df_train['labels'].value_counts().keys())","6960f7fd":"lbl_dict = dict(zip(list(df_train['labels'].value_counts().keys()),range(12)))","e989a9b5":"lbl_dict","63139bc1":"df_train1= df_train.copy()","739b641b":"df_train1['labels'] = df_train['labels'].map(lbl_dict)","38eead9f":"def get_transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])","90770489":"class PlantPatho(Dataset):\n    \n    def __init__(self,df,transform=None):\n        \n        self.image_id = df['image'].values\n        self.labels = df['labels'].values\n        \n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self,idx):\n        \n        image_id = self.image_id[idx]\n        label = self.labels[idx]\n        \n        image_path = train_path + image_id \n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        \n        augmented = self.transform(image=image)\n        \n        image = augmented['image']\n        \n        #image = np.transpose(image,(2,0,1)).astype(np.float32)\n        \n        return {'image':image ,'label':label}","13f15ddb":"train_dataset = PlantPatho(df_train1,get_transform('train'))","afba2db4":"?torch.utils.data.DataLoader","fbe7b69d":"train_loader = DataLoader(train_dataset,batch_size=CFG.batch_size,shuffle=False,num_workers=4)","7449c1eb":"for x in train_dataset:\n    print(x['image'][0].shape)\n    break\n    ","f5cf9b69":"for data in train_loader:\n    print(data)\n    break","acba1a8b":"model_ft = models.resnet18(pretrained=True)","d0899085":"num_ftrs =  model_ft.fc.in_features","9beb99d6":"model_ft.fc = nn.Linear(num_ftrs,12)","0ea0fb33":"model_ft.fc ","80059f9a":"model_ft = model_ft.to(CFG.device)","de343b93":"criterion = nn.CrossEntropyLoss()","b6655827":"optimizer = optim.SGD(model_ft.parameters(),lr=0.001,momentum=0.9)","89d1c3fb":"optimizer","8efc9d2f":"exp_lr_scheduler = lr_scheduler.StepLR(optimizer,step_size = 7,gamma=0.1)","95f45a6e":"def train_model(data_loader,model,criterion,optimizer,sheduler,device,num_epochs=25):\n    \n    since = time.time()\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    \n    for epoch in range(num_epochs):\n        \n        print('Epoch {}\/{}'.format(epoch,num_epochs-1))\n        print('='*15)\n        \n        ## Each Epoch have training and Validation Phase\n        \n        for phase in ['train']:\n            \n            if phase=='train':\n                \n                model.train()\n                \n            else:\n                \n                model.eval()\n                \n            running_loss = 0.0\n            running_corrects = 0\n            \n            ## Iterate over the data\n            i=0 \n            \n            for data in data_loader:\n                \n                \n                image = data['image'][i].to(device)\n                labels =data['label'][i].to(device)\n                \n                i=i+1\n                \n                # Zero the optimizer gradients \n                \n                optimizer.zero_grad()\n                \n                \n                ## Forword Pass\n                \n                with torch.set_grad_enabled(phase=='train'):\n                    \n                    output = model(image)\n                    \n                    _,preds = torch.max(output,1)\n                    \n                    loss = criterion(output,labels)\n                    \n                    \n                    if phase=='train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                # statistics\n                running_loss += loss.item() * image.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n                \n            if phase=='train':\n                \n                sheduler.step()\n                \n            epoch_loss = running_loss \/ ((len(train_dataset)\/CFG.batch_size))\n            epoch_acc = running_corrects.double()\/ ((len(train_dataset)\/CFG.batch_size))\n                                                    \n                                                    \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n                                         \n    time_elapsed = time.time() - since\n        \n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n                                         \n    return model\n    ","24676f9e":"model_ft = train_model(train_loader,model_ft, criterion, optimizer, exp_lr_scheduler,CFG.device,num_epochs=25)","a768577d":"i=0\nfor data in train_loader:\n    \n    print(data['image'][i])\n    i=i+1\n    \n    break ","8324691c":"## Data Class","c83cef13":"### Let see how the image tensor looks like ","5742791f":"### Referance -- Plant Pathology 2020 - Pytorch\n\nhttps:\/\/www.kaggle.com\/pestipeti\/plant-pathology-2020-pytorch\nhttps:\/\/www.kaggle.com\/akasharidas\/plant-pathology-2020-in-pytorch\n","6e91ed33":"# Model Training","9c58a5c8":"### Decay LR by a factor of 0.1 every 7 epochs","b3b67956":"# Observe that all parameters are being optimized","be5d7924":"## Finetuning and Convert the Pretrained model - RESNET18"}}