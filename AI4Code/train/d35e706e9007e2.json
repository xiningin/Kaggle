{"cell_type":{"7a12ac06":"code","861d625f":"code","62749088":"code","bc816a8d":"code","845e45bd":"code","5cd44af8":"code","9a77f27e":"code","9311ed88":"code","4ad20de8":"code","9190fd92":"code","ffaa7531":"code","44a635a5":"code","8a783384":"code","5767b7bd":"code","bed292bb":"code","4498e966":"code","d48f814d":"code","388edc78":"code","e43b6b2c":"code","4970a842":"code","b36919b2":"code","ef488853":"code","b60c6d77":"code","67c37013":"code","ba70f9ad":"code","156a87a8":"code","64121a83":"code","5a20f56c":"code","8a7372bb":"code","597d8c65":"code","6e6d755b":"code","51f05eb5":"code","3241a726":"code","db590397":"code","9590b7e6":"code","78960d2b":"code","c195c2f2":"code","a35d7afd":"code","870a5a42":"code","7ca00393":"markdown","00dc36fa":"markdown","d4d135a4":"markdown","4a2b9d7b":"markdown","fd872431":"markdown"},"source":{"7a12ac06":"# Importing the library\nimport pandas as pd\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# training set\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntrain.head()","861d625f":"# test dataset\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntest.head()","62749088":"train.shape","bc816a8d":"train.info()","845e45bd":"import seaborn as sns\ncorrelations = train.corr()\nsns.heatmap(correlations)","5cd44af8":"# Lets define a custom function to get a better view\n# custom function to set the style for heatmap\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_correlation_heatmap(df):\n    corr = df.corr()\n    sns.set(style=\"white\")\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n\n    f, ax = plt.subplots(figsize=(11, 9))\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    plt.show()\n    \nplot_correlation_heatmap(train)","9a77f27e":"# Calling the dataframe.pivot_table() function for assists\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10\npclass_pivot = train.pivot_table(index = \"assists\", values = \"winPlacePerc\")\npclass_pivot.plot.bar()\nplt.show()","9311ed88":"# Calling the dataframe.pivot_table() function for boosts\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10\npclass_pivot = train.pivot_table(index = \"boosts\", values = \"winPlacePerc\")\npclass_pivot.plot.bar()\nplt.show()","4ad20de8":"# Calling the dataframe.pivot_table() function for DBNOs\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10\npclass_pivot = train.pivot_table(index = \"DBNOs\", values = \"winPlacePerc\")\npclass_pivot.plot.bar()\nplt.show()","9190fd92":"# Calling the dataframe.pivot_table() function for kills\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10\npclass_pivot = train.pivot_table(index = \"kills\", values = \"winPlacePerc\")\npclass_pivot.plot.bar()\nplt.show()","ffaa7531":"# predictors  = [ \"assists\",\n#                 \"boosts\",\n#                 \"damageDealt\",        \n#                 \"DBNOs\",              \n#                 \"headshotKills\",      \n#                 \"heals\",     \n#                 \"killPlace\",          \n#                 \"killPoints\",         \n#                 \"kills\",              \n#                 \"killStreaks\",\n#                 \"longestKill\",        \n#                 \"maxPlace\",           \n#                 \"numGroups\",          \n#                 \"revives\",            \n#                 \"rideDistance\",       \n#                 \"roadKills\",          \n#                 \"swimDistance\",       \n#                 \"teamKills\",          \n#                 \"vehicleDestroys\",    \n#                 \"walkDistance\",       \n#                 \"weaponsAcquired\",    \n#                 \"winPoints\"]\n\n# x_train = train[predictors]\n# x_train.head()","44a635a5":"# Some Feature Engineering\ntrain[\"distance\"] = train[\"rideDistance\"]+train[\"walkDistance\"]+train[\"swimDistance\"]\n# train[\"healthpack\"] = train[\"boosts\"] + train[\"heals\"]\ntrain[\"skill\"] = train[\"headshotKills\"]+train[\"roadKills\"]\ntrain.head()","8a783384":"test[\"distance\"] = test[\"rideDistance\"]+test[\"walkDistance\"]+test[\"swimDistance\"]\n# test[\"healthpack\"] = test[\"boosts\"] + test[\"heals\"]\ntest[\"skill\"] = test[\"headshotKills\"]+test[\"roadKills\"]\ntest[\"distance\"].head()","5767b7bd":"predictors  = [ \"kills\",\n                \"maxPlace\",\n                \"numGroups\",\n                \"distance\",\n                \"boosts\",\n                \"heals\",\n                \"revives\",\n                \"killStreaks\",\n                \"weaponsAcquired\",\n                \"winPoints\",\n                \"skill\",\n                \"assists\",\n                \"damageDealt\",\n                \"DBNOs\",\n                \"killPlace\",\n                \"killPoints\",\n                \"vehicleDestroys\",\n                \"longestKill\"\n               ]\nx_train = train[predictors]\nx_train.head()","bed292bb":"y_train = train[\"winPlacePerc\"]\ny_train.head()","4498e966":"# # Using Random Forest Regressor\n# from sklearn.ensemble import RandomForestRegressor\n# regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n# regressor.fit(x_train, y_train)","d48f814d":"# # Finding the cross validation score with 10 folds\n# from sklearn.model_selection import cross_val_score\n# scores = cross_val_score(regressor, x_train, y_train, cv=10)\n# print(scores)","388edc78":"# accuracy = scores.mean()\n# print(accuracy)","e43b6b2c":"# from sklearn.feature_selection import RFECV\n# regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n# selector = RFECV(regressor, cv = 10)\n# selector.fit(x_train, y_train)\n\n# optimized_predictors = x_train.columns[selector.support_]\n# print(optimized_predictors)","4970a842":"# predictors = train[optimized_predictors]\n# regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n# regressor.fit(predictors, y_train)","b36919b2":"# # Finding the cross validation score with 10 folds\n# from sklearn.model_selection import cross_val_score\n# scores = cross_val_score(regressor, x_train, y_train, cv=10)\n# print(scores)","ef488853":"# accuracy = scores.mean()\n# print(accuracy)","b60c6d77":"# import lightgbm as lgb\n# from sklearn.feature_selection import RFECV\n# regressor = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n#                               learning_rate=0.05, n_estimators=720,\n#                               max_bin = 55, bagging_fraction = 0.8,\n#                               bagging_freq = 5)\n\n# selector = RFECV(regressor, cv = 10)\n# selector.fit(x_train, y_train)\n\n# optimized_predictors = x_train.columns[selector.support_]\n# print(optimized_predictors)","67c37013":"import lightgbm as lgb\nregressor = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 20, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.8)\nregressor.fit(x_train, y_train)","ba70f9ad":"# Finding the cross validation score with 10 folds\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(regressor, x_train, y_train, cv=10)\nprint(scores)","156a87a8":"accuracy = scores.mean()\nprint(accuracy)","64121a83":"x_test = test[predictors]\nx_test.head()","5a20f56c":"y_predict = regressor.predict(x_test)\nprint(y_predict)","8a7372bb":"y_predict[y_predict > 1] = 1\ntest['winPlacePercPredictions'] = y_predict\n\naux = test.groupby(['matchId','groupId'])['winPlacePercPredictions'].agg('mean').groupby('matchId').rank(pct=True).reset_index()\naux.columns = ['matchId','groupId','winPlacePerc']\ntest = test.merge(aux, how='left', on=['matchId','groupId'])\n    \nsubmission = test[['Id','winPlacePerc']]","597d8c65":"submission.to_csv(\"kill_them_all.csv\", index=False)","6e6d755b":"lgb.plot_importance(regressor, max_num_features=20, figsize=(10, 8));\nplt.title('Feature importance');","51f05eb5":"# Lets take the top 10 features\nimportant_predictors  = [ \"kills\",\n                \"maxPlace\",\n                \"numGroups\",\n                \"distance\",\n                \"killStreaks\",\n                \"weaponsAcquired\",\n                \"winPoints\",\n                \"killPlace\",\n                \"killPoints\",\n                \"longestKill\"\n               ]\nx_train = train[important_predictors]\nx_train.head()","3241a726":"regressor = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 20, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.8)\nregressor.fit(x_train, y_train)","db590397":"x_test = test[important_predictors]\nx_test.head()","9590b7e6":"y_predict = regressor.predict(x_test)\nprint(y_predict)","78960d2b":"y_predict[y_predict > 1] = 1\ntest['winPlacePercPredictions'] = y_predict\n\naux = test.groupby(['matchId','groupId'])['winPlacePercPredictions'].agg('mean').groupby('matchId').rank(pct=True).reset_index()","c195c2f2":"aux.columns = ['matchId','groupId','winPlacePerc']\ntest = test.merge(aux, how='left', on=['matchId','groupId'])\ntest.head()","a35d7afd":"# Finding the cross validation score with 10 folds\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(regressor, x_train, y_train, cv=10)\nprint(scores)","870a5a42":"accuracy = scores.mean()\nprint(accuracy)","7ca00393":"We will use scikit-learn's inbuilt feature selection classes. We will be using the feature_selection.RFECV class which performs recursive feature elimination with cross-validation.\n\nThe RFECV class starts by training a model using all of your features and scores it using cross validation. It then uses the logit coefficients to eliminate the least important feature, and trains and scores a new model. At the end, the class looks at all the scores, and selects the set of features which scored highest.","00dc36fa":"**Visualisations**\n\nThere are alot of ways to visualize but lets use the simple ones.","d4d135a4":"**Importing the Dataset**","4a2b9d7b":"**Feature Importance**\nLets find the importance of features.","fd872431":"Hey guys,\n\nThis is a work in progress Kernel.  Happy Learning :D\n\nMe being a big fan of PUBG. Let's find out if we can predict the ways to kill them all and the best stratergy for Winner Winner Chicken Dinner :D"}}