{"cell_type":{"4a1c4483":"code","136a15a4":"code","23296cfa":"code","b0aa23c7":"code","e9ca0ba8":"code","63a1122d":"code","179f3e4d":"code","926d304e":"code","d5eb6a56":"code","0ea32bf5":"code","47d2e913":"code","315e1ace":"code","2768fd9e":"code","1f76778d":"code","40fc3421":"code","e2676d82":"code","0d678155":"code","328258aa":"code","cb085eb4":"code","bbb71a09":"code","e9026115":"code","0ef0f91e":"code","f1cedc55":"code","e5644ee9":"code","0d1dfff5":"code","9dd4b287":"code","175fb8d8":"code","1b2f2114":"code","701e7c67":"code","fcb88166":"code","7df5f75a":"code","ef782675":"code","ae71262b":"code","65d9d4ac":"code","f4e4729f":"code","975d0d83":"code","aa864f7e":"code","0960f17c":"code","747e0f6b":"code","226564d4":"code","4a106eae":"code","934e7d46":"code","1a7f7b71":"code","3f6809f0":"markdown","3064a15b":"markdown","c7e4e139":"markdown","f9345b85":"markdown","72871c27":"markdown","7b026dc2":"markdown","ef0f550b":"markdown","3f5c8f37":"markdown","70762240":"markdown","3fcfca4b":"markdown","00e8f975":"markdown","6f054476":"markdown","3c0e101c":"markdown","c2844bab":"markdown"},"source":{"4a1c4483":"!pip install quickdataanalysis==0.0.7","136a15a4":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.pipeline import make_pipeline\nfrom quickdataanalysis import data_analysis as qd","23296cfa":"root_path = '\/kaggle\/input\/titanic\/'","b0aa23c7":"train = os.path.join(root_path,'train.csv')\ntest = os.path.join(root_path,\"test.csv\")\n# submission = os.path.join(root_path,'gender_submission.csv')","e9ca0ba8":"df_train = pd.read_csv(train)\ndf_test = pd.read_csv(test)\n# df_submission = pd.read_csv(subission)","63a1122d":"df_train.head()","179f3e4d":"df_train.info()","926d304e":"df_train.describe()","d5eb6a56":"drop_cols = [\"Cabin\",\"Embarked\",\"Ticket\",\"Name\",\"PassengerId\"]\ndf_train = df_train.drop(drop_cols,axis=1)\ndf_test = df_test.drop(drop_cols,axis=1)","0ea32bf5":"fig, ax = plt.subplots(figsize=(20,10)) \ndf_train_corr = df_train.corr()\nsns.heatmap(df_train_corr,xticklabels=df_train_corr.columns,yticklabels=df_train_corr.columns,annot=True,ax=ax)","47d2e913":"df_train[\"Sex\"].value_counts().plot.bar(rot=0,color={\"red\",\"blue\"},title=\"gender distrbution\")","315e1ace":"#creating dummies for train dataset\ncols = [\"Sex\"]\ndf_train = qd.create_dummies(df_train,cols)","2768fd9e":"#creating dummies for test dataset\ndf_test = qd.create_dummies(df_test,cols)","1f76778d":"df_train['Age'] = df_train['Age'].interpolate()\ndf_test['Fare'] = df_test['Fare'].interpolate()\ndf_test['Age'] = df_test['Age'].interpolate()","40fc3421":"total_male = qd.column_value_count(df_train[\"male\"] ,1 )\ntotal_female = qd.column_value_count(df_train[\"female\"] ,1)\nprint(f\"Total male onboard = {total_male} \\n \\nTotal female onboard = {total_female}\")","e2676d82":"#getting the male & female surviver count\nsurvived_female = qd.column_value_count(df_train[((df_train[\"female\"]== 1) & (df_train[\"Survived\"]==1))][\"female\"],1)\nsurvived_male = qd.column_value_count(df_train[((df_train[\"male\"]== 1) & (df_train[\"Survived\"]==1))][\"male\"],1)","0d678155":"plot = df_train[\"female\"].value_counts().plot.pie(figsize=(11, 6),title=f\"no of female survived is {survived_female}\",legend=True)","328258aa":"plot = df_train[\"male\"].value_counts().plot.pie(figsize=(11, 6),title=f\"no of male survived is {survived_male}\",legend=True)","cb085eb4":"pclass1 = qd.column_value_count(df_train[((df_train[\"Pclass\"]==1) & (df_train[\"Survived\"]==1) )][\"Pclass\"],1)\npclass2 = qd.column_value_count(df_train[((df_train[\"Pclass\"]==2) & (df_train[\"Survived\"]==1) )][\"Pclass\"],2)\npclass3 = qd.column_value_count(df_train[((df_train[\"Pclass\"]==3) & (df_train[\"Survived\"]==1) )][\"Pclass\"],3)","bbb71a09":"fig, axes = plt.subplots(nrows=1, ncols=3)\nfig.tight_layout(w_pad = 5,pad =1)\n((df_train[\"Pclass\"]==1) & (df_train[\"Survived\"]==1) ).value_counts().plot.bar(legend=True,color=\"orange\",title=f\"Passenger Class 1 - {pclass1}\",ax=axes[0])\n((df_train[\"Pclass\"]==2) & (df_train[\"Survived\"]==1) ).value_counts().plot.bar(legend=True,color=\"red\",title=f\"Passenger Class 2 - {pclass2}\",ax=axes[1])\n((df_train[\"Pclass\"]==3) & (df_train[\"Survived\"]==1) ).value_counts().plot.bar(legend=True,color=\"blue\",title=f\"Passenger Class 3 - {pclass3}\",ax=axes[2])","e9026115":"#seperating the target variable from the dataset\nx = df_train.drop(\"Survived\",axis=1)\ny = df_train[\"Survived\"]","0ef0f91e":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33, random_state=42)","f1cedc55":"#list of model that we will be using\nknn = KNeighborsClassifier()\nsvm = SVC()\nrandom_forest = RandomForestClassifier()\nregression = LogisticRegression(max_iter=10000)","e5644ee9":"x,y = x_train,y_train\nknn.fit(x,y)\nsvm.fit(x,y)\nrandom_forest.fit(x,y)\nregression.fit(x,y)","0d1dfff5":"Y_pred_knn = knn.predict(x_test)\nY_pred_svm = svm.predict(x_test)\nY_pred_random_forest = random_forest.predict(x_test)\nY_pred_regression = regression.predict(x_test)","9dd4b287":"print(\"Knn Preformance\")\nprint(metrics.classification_report(y_test, Y_pred_knn))","175fb8d8":"print(\"svm Preformance\")\nprint(metrics.classification_report(y_test, Y_pred_svm))","1b2f2114":"print(\"Random Forest Preformance\")\nprint(metrics.classification_report(y_test, Y_pred_random_forest))","701e7c67":"print(\"Logistic Regression Preformance\")\nprint(metrics.classification_report(y_test, Y_pred_regression))","fcb88166":"!pip install pycaret","7df5f75a":"from pycaret.classification import *","ef782675":"clf1 = setup(df_train, target ='Survived', log_experiment = True, experiment_name = 'titanic survivor prediction')","ae71262b":"# compare all baseline models and select top 5\ntop5 = compare_models(n_select = 5)","65d9d4ac":"# tune top 5 base models\ntuned_top5 = [tune_model(i) for i in top5]","f4e4729f":"# ensemble top 5 tuned models\nbagged_top5 = [ensemble_model(i) for i in tuned_top5]","975d0d83":"cat = create_model(\"catboost\")","aa864f7e":"cat_pred_new = predict_model(cat, data = df_test)","0960f17c":"rf = create_model(\"rf\")","747e0f6b":"plot_model(rf)","226564d4":"plot_model(rf,plot=\"learning\")","4a106eae":"plot_model(rf,plot=\"feature\")","934e7d46":"plot_model(rf,plot=\"class_report\")","1a7f7b71":"df_test_submit = pd.read_csv(test)\nres = pd.DataFrame({\"PassengerId\":df_test_submit[\"PassengerId\"],\"Survived\":cat_pred_new['Label']})\nres.to_csv(\"submission.csv\",index=False)","3f6809f0":"# <strong style=\"color:#AB47BC\"> 4 Fitting the data<\/strong> <a id=\"4\"> <\/a>","3064a15b":"# This is an <strong style=\"color:#8E44AD\"> absolute begineer notebook <\/strong> && <strong style=\"color:#F39C12\"> my first kaggle submission <\/strong>\n\n## This kernal will walk you through the basics of PyCaret and will compare how it performs with the traditional models\n\n# <strong style=\"color:#FFBD33\"> Context <\/strong> \n(click to navigate)\n\n## [1. Data loading](#0)    \n## [2. Data Cleaning](#2) \n## [3. Data visualization - ploting the coorelation heatmap](#3) \n## [4. Fitting the data](#4)    \n## [5. Performace analysis of different models](#5) \n## [6. Submission](#6)\n\n\nList of models used - SVM, KNN, Random Forest, Logistic Regression\n\nUsed four differenct classifiers to check their performaces.\n\n## <strong style=\"color:#CC3399\"> \u2699\u2699 Update <\/strong>\n\n# [\ud83c\udfa9\ud83c\udfa9 Let's do some magic with PyCaret \ud83d\udd2e\ud83d\udd2e](#1)\n\n\n**Feel free to leave a comment and if you like it do upvote!!!!** <\/br>\n**That will encourge me to submit lot of notebooks**","c7e4e139":"## Classifier Accuracy (approx.)\n\n1. KNN              -   69%      \n2. SVM               -  67%      \n3. **Random Forest      - 82%**      \n4. Logistic Regression - 81%     ","f9345b85":"# <strong style=\"color:#AB47BC\"> 2 Data Cleaning<\/strong> <a id=\"2\"> <\/a>","72871c27":"# <strong style=\"color:#AB47BC\"> 5 Performance Analysis of different models<\/strong> <a id=\"5\"> <\/a>","7b026dc2":"<h3 style=\"color:#34495E\"> \u2728\u2728 Thanks for reading out my kernal till the very end \u2728\u2728 <\/h3>\n\n<h3 style=\"color:#34495E\"> Let's me know what can be improved in the comments <br><br> If you liked it please do consider <span style=\"color:#2E86C1\">upvoting!!\ud83d\ude0e <\/span> ","ef0f550b":"# <strong style=\"color:#AB47BC\">3 Data visualization - ploting the coorelation heatmap <\/strong> <a id=\"3\"> <\/a>","3f5c8f37":"# using quickdataanalysis to create dummies with ease","70762240":"# A single line of code to set things up","3fcfca4b":"# Feature Importance","00e8f975":"# <strong style=\"color:#AB47BC\"> 6 Submission <\/strong> <a id=\"6\"> <\/a>","6f054476":"# <strong style=\"color:#000066\"> \ud83c\udfa9\ud83c\udfa9 Let's do some magic with PyCaret \ud83d\udd2e\ud83d\udd2e<\/strong> <a id=\"1\"> <\/a>\n","3c0e101c":"# <strong style=\"color:#AB47BC\"> 1 Data Loading<\/strong> <a id=\"0\"> <\/a>","c2844bab":"I have create a package **quickdataanalysis** for easy implementation of data analysis\nDo install it and check my github repo for the code https:\/\/github.com\/Santhoshkumard11\/quickdataanalysis"}}