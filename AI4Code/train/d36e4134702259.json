{"cell_type":{"05885615":"code","c089d3d9":"code","5a09e15e":"code","cbd99ace":"code","a94ea49b":"code","5dc663d4":"code","fe7dbbba":"code","eacf841a":"code","534ca61f":"code","faeb034d":"code","860ecced":"code","67cb1af0":"code","106771b8":"code","d1eafed6":"code","7cc11f10":"code","6f6442fc":"code","58b26c82":"code","367f5411":"code","ae01d3b2":"code","4dc8a4ae":"code","a7adae48":"code","fd36ac05":"code","20906a1a":"markdown","b1fe3176":"markdown","ee6a3160":"markdown","ea58fefa":"markdown","4be9a564":"markdown","f4ea4637":"markdown","a9bb0318":"markdown","38c86c63":"markdown","ec0a1575":"markdown","e0d40694":"markdown","8796eabf":"markdown"},"source":{"05885615":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2, os\nfrom PIL import Image\nfrom tqdm import tqdm \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.utils import shuffle\nfrom sklearn import decomposition\nfrom scipy.spatial import distance as dist\n\nimport albumentations\nimport pretrainedmodels\n\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n#from pytorchtools import EarlyStopping\n#from pytorchtools import EarlyStopping\n#from pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nfrom torchvision import transforms, models\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport torch.optim as optim\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","c089d3d9":"train_dataset_path = \"\/kaggle\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST\" \n\nCATEGORIES    = ['EOSINOPHIL','LYMPHOCYTE','MONOCYTE','NEUTROPHIL']\n\nfor k in range(3):\n    i=0\n    plt.figure(figsize=(25,15))\n    for category in CATEGORIES:\n        plt.subplot(5, 5, i+1)\n        plt.yticks([])\n        plt.xticks([])\n        path=train_dataset_path + '\/' + category\n        image_p=os.listdir(path)\n        plt.title(category , color='tomato').set_size(15)\n        plt.axis('off')\n        image = cv2.imread(os.path.join(path, image_p[k])) \n        image = image[:, :, [2, 1, 0]] \n        plt.imshow(image)\n        i+=1","5a09e15e":"DATADIR = ['\/kaggle\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TRAIN', '\/kaggle\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST']\nCATEGORIES = ['EOSINOPHIL','LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']","cbd99ace":"image_label = []\n\ndef create_training_data():\n    for datadir in DATADIR:\n        for categories in CATEGORIES:\n            path = os.path.join(datadir, categories)\n            n_class = CATEGORIES.index(categories)\n            for images in os.listdir(path):\n                try:\n                    image_path = os.path.join(path, images)\n\n                    image_label.append([image_path, n_class])\n                except Exception as e:\n                    pass\n\ncreate_training_data()\n","a94ea49b":"df = pd.DataFrame(image_label, columns=['image_name', 'label'])\ndf = df.sample(frac=1).reset_index(drop=True)\ndf.head()","5dc663d4":"count = df.label.value_counts()\nsns.barplot(x=count.index, y=count.values)","fe7dbbba":"Xtrain, xvalid, Ytrain, yvalid = train_test_split(df.image_name, df.label, test_size=.20)\nprint(Xtrain.shape, xvalid.shape, Ytrain.shape, yvalid.shape)","eacf841a":"class Custom_Dataset:\n    def __init__(self, images, targets, train_data=False):\n        self.features = images\n        self.targets = targets\n\n        if train_data:\n            self.aug = albumentations.Compose([\n                                albumentations.Resize(128, 128, always_apply=True),\n                                albumentations.ShiftScaleRotate(shift_limit=0.0625,\n                                                                scale_limit=0.1,\n                                                                rotate_limit=5,\n                                                                p=0.9),\n                                #albumentations.RandomBrightnessContrast(always_apply=False),\n                                albumentations.RandomRotate90(always_apply=False),\n                                albumentations.HorizontalFlip(),\n                                albumentations.VerticalFlip(),\n                                albumentations.Normalize(mean=(0.485, 0.456, 0.406), \n                                                         std=(0.229, 0.224, 0.225), \n                                                         always_apply=True)              \n                                                ])\n\n        else:\n            self.aug = albumentations.Compose([\n                                albumentations.Resize(128, 128, always_apply=True),\n                                albumentations.Normalize(mean=(0.485, 0.456, 0.406), \n                                                         std=(0.229, 0.224, 0.225),\n                                                         always_apply=True) \n                                ])                       \n            \n\n    def __len__(self):\n        return len(self.targets) \n\n\n    def __getitem__(self, idx):\n        image = self.features[idx]\n        image = cv2.imread(image)\n        image = cv2.resize(image, (128,128)).astype(float)\n        #image = image.reshape(128, 128, 3).astype(float)\n        #image = Image.fromarray(image).convert(\"RGB\")\n        image = self.aug(image=np.array(image))['image']\n        image = np.transpose(image, (2, 0, 1)).astype(np.float) \n\n        return {\n            'image': torch.tensor(image, dtype=torch.float),\n            'label': torch.tensor(self.targets[idx], dtype=torch.long)\n        }\n    ","534ca61f":"train_feature_label = Custom_Dataset(\n                                    images=Xtrain.values, \n                                    targets=Ytrain.values,\n                                    train_data=True\n                                    )\nvalid_feature_label = Custom_Dataset(\n                                    images=xvalid.values,\n                                    targets=yvalid.values, \n                                    train_data=False\n                                    )\n\n","faeb034d":"train_loader = DataLoader(\n                        dataset = train_feature_label,\n                        batch_size = 32,\n                        shuffle = True, \n                        num_workers = 4\n                        )     \nvalid_loader = DataLoader(\n                        dataset = valid_feature_label,\n                        batch_size = 32,\n                        shuffle = False\n                        ) \n","860ecced":"class Resnet34(nn.Module):\n    \n    def __init__(self):\n        super(Resnet34, self).__init__()\n        self.model = pretrainedmodels.__dict__['resnet34'](pretrained='imagenet')  \n        self.l0 = nn.Linear(512, 4)\n\n    def forward(self, x):\n        bs, c, h, w = x.shape\n        x = self.model.features(x) \n        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n        op_layer_one = self.l0(x)\n        return op_layer_one\n","67cb1af0":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = Resnet34()\nmodel.to(device) ","106771b8":"optimizer = optim.Adam(model.parameters(), lr=0.001) \ncriterion = nn.CrossEntropyLoss()\nscheduler = ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.3, verbose=True) \n","d1eafed6":"def train(Xtrain, data_loader, model, device, optimizer, criterion, scheduler):\n    model.train()\n    \n    total = 0\n    train_loss = 0\n    correct = 0\n\n\n    for bi, data in tqdm(enumerate(data_loader), total=int(len(Xtrain)\/data_loader.batch_size)):\n        image = data['image']\n        grapheme_root = data['label']\n        \n        image = image.to(device, dtype=torch.float)\n        targets = grapheme_root.to(device, dtype=torch.long) \n        \n\n        optimizer.zero_grad()\n        outputs = model(image)\n        loss = criterion(outputs, targets)\n        \n        #model.cleargrads()\n        loss.backward()\n        optimizer.step()\n        \n\n        ##########\n        #outputs = torch.sigmoid(outputs)\n        #outputs[outputs >= 0.5] = 1\n        #accuracy = accuracy_score(targets, outputs.detach().numpy()) \n        #acc += accuracy\n        ##########\n        \n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n        \n\n        \n    train_acc = correct \/ total\n    #train_accuracy.append(train_acc) \n\n    train_loss = train_loss\/total\n    #train_losses.append(train_loss)\n\n    print(\"Epoch: {}  \\tTraining Acc: {:.6f}  \\tTraining Loss: {:.6f}\".format(epoch+1, train_acc, train_loss)) \n    return train_acc, train_loss\n\n\n\n\ndef evaluation(xvalid, data_loader, model, device, criterion):\n    model.eval()\n    \n    total = 0\n    valid_loss = 0\n    correct = 0\n\n\n    for bi, data in tqdm(enumerate(data_loader), total=int(len(xvalid)\/ data_loader.batch_size)):\n        image = data['image']\n        grapheme_root = data['label']\n\n        image = image.to(device, dtype=torch.float)\n        targets = grapheme_root.to(device, dtype=torch.long)\n\n        outputs = model(image)\n        loss = criterion(outputs, targets)\n\n        ###############\n        #outputs = torch.sigmoid(outputs)\n        #outputs[outputs >= 0.5] = 1   \n        #accuracy = accuracy_score(targets, outputs.detach().numpy())\n        #acc += accuracy\n        ###############\n        \n        #acc += (outputs == targets).float().sum()   \n        #valid_loss += loss.item() * image.size(0)\n        \n        \n        valid_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n        \n        \n\n    valid_acc = correct\/ total\n    #valid_accuracy.append(valid_acc)\n\n    valid_loss = valid_loss \/ total\n    #valid_losses.append(valid_loss)\n\n\n    print(\"Epoch: {} \\tValidation Acc: {:.6f}  \\tValidation Loss: {:.6f}\".format(epoch+1, valid_acc, valid_loss))\n    return valid_acc, valid_loss\n","7cc11f10":"# Training the model\ntrain_accuracy = []\ntrain_losses = []\nvalid_accuracy = []\nvalid_losses = []\n\nfor epoch in range(10):\n    train_acc, train_loss = train(Xtrain, train_loader, model, device, optimizer, criterion, scheduler)\n    valid_acc, valid_loss = evaluation(xvalid, valid_loader, model, device, criterion)\n    train_accuracy.append(train_acc)\n    train_losses.append(train_loss)\n    valid_accuracy.append(valid_acc)\n    valid_losses.append(valid_loss) \n\n    #early_stopping(valid_loss, model) \n    #if early_stopping.early_stop:\n        #break \n\nprint(\"Final train accuracy is :\", np.mean(train_accuracy))\nprint(\"Final train loss is :\", np.mean(train_losses))\nprint(\"Final valid accuracy is :\", np.mean(valid_accuracy))\nprint(\"Final valid loss is :\", np.mean(valid_losses))\n","6f6442fc":"# Saving Model\ntorch.save(model.state_dict(), 'Blood_Classification.pth')","58b26c82":"DATADIR = \"\/kaggle\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST_SIMPLE\"\nCATEGORIES = ['EOSINOPHIL','LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n\ntest_image_label = []\n\n\ndef create_test_data():\n    for categories in CATEGORIES:\n        path = os.path.join(DATADIR, categories)\n        n_class = CATEGORIES.index(categories)\n        for images in os.listdir(path):\n            try:\n                image_path = os.path.join(path, images)\n\n                test_image_label.append([image_path, n_class])\n            except Exception as e:\n                pass\n\ncreate_test_data()\n","367f5411":"test_df = pd.DataFrame(test_image_label, columns=['image_name', 'label'])\ntest_df = test_df.sample(frac=1).reset_index(drop=True)\ntest_df.head()","ae01d3b2":"test_feature_label = Custom_Dataset(\n                                    images=test_df.image_name.values,\n                                    targets=test_df.label.values,\n                                    train_data=False\n                                    )","4dc8a4ae":"test_loader = DataLoader(\n                        dataset = test_feature_label,\n                        batch_size = 10,\n                        shuffle = False\n                        ) ","a7adae48":"# Loading Model\nmodel_trained = Resnet34()\nmodel_trained.load_state_dict(torch.load('.\/Blood_Classification.pth'))","fd36ac05":"model.eval()\n\ntest_loss = 0\ntotal = 0\ncorrect = 0\n\nwith torch.no_grad():\n    for idx, data in enumerate(test_loader):\n        images = data['image']\n        labels = data['label']\n        \n        images = images.to(device, dtype=torch.float) \n        targets = labels.to(device, dtype=torch.long) \n        \n        outputs = model_trained(images)\n        loss = criterion(outputs, targets)\n        \n        test_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n        \n    print(\"Test Accuracy of The Model is :\", correct\/total) ","20906a1a":"# Model Training","b1fe3176":"# Dividing Dataset","ee6a3160":"# Custom Dataset","ea58fefa":"# Some Visualization","4be9a564":"# Model","f4ea4637":"# Path of the Images and Labels","a9bb0318":"# Test Data Preprocessing","38c86c63":"# Optimizer, Scheduler, EarlyStopping","ec0a1575":"# Model Saving","e0d40694":"# Training and Evaluation","8796eabf":"# DataLoader"}}