{"cell_type":{"45d3be32":"code","6acafb16":"code","6551cf9b":"code","7a54f438":"code","a9973599":"code","db460aab":"code","c94f20b1":"code","9328d59f":"code","befb176c":"code","eec48762":"code","09df82fd":"code","079eea99":"code","903986dd":"code","f5e3b99e":"code","511673a9":"code","41cfba4b":"code","fde8cd93":"code","0c59c6b7":"code","afc99d69":"code","9cca26f1":"code","b42616d9":"code","3ec26777":"code","638d2179":"code","b12b6664":"code","e1c6c340":"code","0ed6943d":"code","bc8d2b85":"code","61cc9361":"code","fa4ec48c":"code","8dcb8630":"code","8e25d1cf":"code","dd80a9ba":"code","5a3602d3":"code","baa436c9":"code","f98e49ad":"code","4295754a":"code","ad674298":"code","6c09f8fc":"code","d1c97bd0":"code","82c0fa35":"code","0146a777":"code","cd504d11":"code","84053ad6":"markdown","53e1aa13":"markdown","b3844f7d":"markdown","fa989a07":"markdown","e80e333e":"markdown","96e148be":"markdown","ceea8a88":"markdown","77b605c7":"markdown","8bdaef90":"markdown","20fb3c97":"markdown","fdaa2e86":"markdown","672b87fa":"markdown","146db8cc":"markdown","f504f06c":"markdown","8ab6bba7":"markdown","cec74f41":"markdown","fbdcdcd6":"markdown","1cb26bb2":"markdown","a374157b":"markdown","355c63dc":"markdown","73723573":"markdown","1005adb7":"markdown","f42f05f7":"markdown","9ca7fadb":"markdown"},"source":{"45d3be32":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report,accuracy_score,confusion_matrix,auc,roc_auc_score,precision_score,recall_score","6acafb16":"train_data = pd.read_csv('..\/input\/train_2v.csv')\ntest_data = pd.read_csv('..\/input\/test_2v.csv')","6551cf9b":"train_data.shape","7a54f438":"test_data.head()","a9973599":"print ('Train Data Shape: {}'.format(train_data.shape))\n\nprint ('Test Data Shape: {}'.format(test_data.shape))","db460aab":"train_data.describe()","c94f20b1":"train_data.isnull().sum()\/len(train_data)*100","9328d59f":"test_data.isnull().sum()\/len(test_data)*100","befb176c":"joined_data = pd.concat([train_data,test_data])","eec48762":"print ('Joined Data Shape: {}'.format(joined_data.shape))","09df82fd":"joined_data.isnull().sum()\/len(joined_data)*100","079eea99":"train_data[\"bmi\"]=train_data[\"bmi\"].fillna(train_data[\"bmi\"].mean())","903986dd":"train_data.head()","f5e3b99e":"label = LabelEncoder()\ntrain_data['gender'] = label.fit_transform(train_data['gender'])\ntrain_data['ever_married'] = label.fit_transform(train_data['ever_married'])\ntrain_data['work_type']= label.fit_transform(train_data['work_type'])\ntrain_data['Residence_type']= label.fit_transform(train_data['Residence_type'])","511673a9":"train_data_without_smoke = train_data[train_data['smoking_status'].isnull()]\ntrain_data_with_smoke = train_data[train_data['smoking_status'].notnull()]","41cfba4b":"train_data_without_smoke.drop(columns='smoking_status',axis=1,inplace=True)","fde8cd93":"train_data_without_smoke.head()","0c59c6b7":"train_data_with_smoke.head()","afc99d69":"train_data_with_smoke['smoking_status']= label.fit_transform(train_data_with_smoke['smoking_status'])","9cca26f1":"train_data_with_smoke.head()\ntrain_data_with_smoke.shape","b42616d9":"train_data_with_smoke.corr('pearson')","3ec26777":"train_data_with_smoke['stroke'].value_counts()","638d2179":"train_data_without_smoke['stroke'].value_counts()","b12b6664":"ros = RandomOverSampler(random_state=0)\nsmote = SMOTE()","e1c6c340":"X_resampled, y_resampled = ros.fit_resample(train_data_with_smoke.loc[:,train_data_with_smoke.columns!='stroke'], \n                                            train_data_with_smoke['stroke'])","0ed6943d":"train_data_without_smoke.loc[:,train_data_without_smoke.columns!='stroke'].columns","bc8d2b85":"print ('ROS Input Data Shape for Smoke Data: {}'.format(X_resampled.shape))\nprint ('ROS Output Data Shape for Smoke Data: {}'.format(y_resampled.shape))","61cc9361":"X_resampled_1, y_resampled_1 = ros.fit_resample(train_data_without_smoke.loc[:,train_data_without_smoke.columns!='stroke'], \n                                            train_data_without_smoke['stroke'])","fa4ec48c":"print ('ROS Input Data Shape for Non Smoke Data: {}'.format(X_resampled_1.shape))\nprint ('ROS Output Data Shape for Non Smoke Data: {}'.format(y_resampled_1.shape))","8dcb8630":"X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2)\nprint(X_train.shape)\nprint(X_test.shape)","8e25d1cf":"X_train_1,X_test_1,y_train_1,y_test_1 = train_test_split(X_resampled_1,y_resampled_1,test_size=0.2)\nprint(X_train_1.shape)\nprint(X_test_1.shape)","dd80a9ba":"dtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\n\npred = dtree.predict(X_test)\nprint(classification_report(y_test,pred))\nprint (accuracy_score(y_test,pred))\nprint (confusion_matrix(y_test,pred))\n\nprecision = precision_score(y_test,pred)\nrecall = recall_score(y_test,pred)\nprint( 'precision = ', precision, '\\n', 'recall = ', recall)\n\ny_pred_proba = dtree.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n\nimpFeatures = pd.DataFrame(dtree.feature_importances_ ,index=train_data_with_smoke.loc[:,train_data_with_smoke.columns!='stroke'].columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\nprint (impFeatures)","5a3602d3":"dtree_nosmoke = DecisionTreeClassifier()\ndtree_nosmoke.fit(X_train_1,y_train_1)\n\npred = dtree_nosmoke.predict(X_test_1)\nprint(classification_report(y_test_1,pred))\nprint ('Accuracy: {}'.format(accuracy_score(y_test_1,pred)))\nprint ('COnfusion Matrix: \\n {}'.format(confusion_matrix(y_test_1,pred)))\n\nprecision = precision_score(y_test_1,pred)\nrecall = recall_score(y_test_1,pred)\nprint( 'precision = ', precision, '\\n', 'recall = ', recall)\n\ny_pred_proba = dtree_nosmoke.predict_proba(X_test_1)[::,1]\nfpr, tpr, _ = roc_curve(y_test_1,  y_pred_proba)\nauc = roc_auc_score(y_test_1, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n\nimpFeatures = pd.DataFrame(dtree_nosmoke.feature_importances_ ,index=train_data_without_smoke.loc[:,train_data_without_smoke.columns!='stroke'].columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\nprint (impFeatures)","baa436c9":"log = LogisticRegression(penalty='l2', C=0.1)\nlog.fit(X_train,y_train)\n\npred = log.predict(X_test)\nprint(classification_report(y_test,pred))\nprint (accuracy_score(y_test,pred))\nprint (confusion_matrix(y_test,pred))\n\nprecision = precision_score(y_test,pred)\nrecall = recall_score(y_test,pred)\nprint( 'precision = ', precision, '\\n', 'recall = ', recall)\n\ny_pred_proba = log.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\nimpFeatures = pd.DataFrame(log.coef_[0] ,index=train_data_with_smoke.loc[:,train_data_with_smoke.columns!='stroke'].columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\nprint (impFeatures)","f98e49ad":"logg = LogisticRegression(penalty='l2', C=0.1)\nlogg.fit(X_train_1,y_train_1)\n\npred = logg.predict(X_test_1)\nprint(classification_report(y_test_1,pred))\nprint (accuracy_score(y_test_1,pred))\nprint (confusion_matrix(y_test_1,pred))\n\nprecision = precision_score(y_test_1,pred)\nrecall = recall_score(y_test_1,pred)\nprint( 'precision = ', precision, '\\n', 'recall = ', recall)\n\ny_pred_proba = logg.predict_proba(X_test_1)[::,1]\nfpr, tpr, _ = roc_curve(y_test_1,  y_pred_proba)\nauc = roc_auc_score(y_test_1, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n\nimpFeatures = pd.DataFrame(logg.coef_[0] ,index=train_data_without_smoke.loc[:,train_data_without_smoke.columns!='stroke'].columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\nprint (impFeatures)","4295754a":"ran = RandomForestClassifier(n_estimators=50,random_state=0)\nran.fit(X_train_1,y_train_1)\n\npred = ran.predict(X_test_1)\nprint(classification_report(y_test_1,pred))\nprint (accuracy_score(y_test_1,pred))\nprint (confusion_matrix(y_test_1,pred))\n\nprecision = precision_score(y_test_1,pred)\nrecall = recall_score(y_test_1,pred)\nprint( 'precision = ', precision, '\\n', 'recall = ', recall)\n\ny_pred_proba = ran.predict_proba(X_test_1)[::,1]\nfpr, tpr, _ = roc_curve(y_test_1,  y_pred_proba)\nauc = roc_auc_score(y_test_1, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n\n\nimpFeatures = pd.DataFrame((ran.feature_importances_) ,index=train_data_without_smoke.loc[:,train_data_without_smoke.columns!='stroke'].columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\nprint (impFeatures)","ad674298":"feat_importances = pd.Series(ran.feature_importances_, index=train_data_without_smoke.loc[:,train_data_without_smoke.columns!='stroke'].columns)\nfeat_importances.plot(kind='barh')","6c09f8fc":"test_data[\"bmi\"]=test_data[\"bmi\"].fillna(test_data[\"bmi\"].mean())","d1c97bd0":"test_data.drop(axis=1,columns=['smoking_status'],inplace=True)","82c0fa35":"label = LabelEncoder()\ntest_data['gender'] = label.fit_transform(test_data['gender'])\ntest_data['ever_married'] = label.fit_transform(test_data['ever_married'])\ntest_data['work_type']= label.fit_transform(test_data['work_type'])\ntest_data['Residence_type']= label.fit_transform(test_data['Residence_type'])\npred = ran.predict(test_data)","0146a777":"prediction = pd.DataFrame(pred,columns=['Pred'])","cd504d11":"prediction['Pred'].value_counts()","84053ad6":"### Predicted Value. Model Predicted 10 strokes for the test data","53e1aa13":"### Decision Tree Classifier with Smoking Status","b3844f7d":"#### In both cases we can see we are dealing with imbalanced data set, if we go ahead with that there is a high possibility that it ML algorithm will predict no stroke for all data. So we need to make the data more balanced\n\n#### I am using ROSE method to deal with that and make data more balanced which generates artificial data to make the set more balanced","fa989a07":"## Prediction Stroke Patients","e80e333e":"#### So we can see that Age, hypertension, heart disease, Residence type, Avg Glucose level, BMI and Smoking status comes as significate variable here. A few of them are intuitive as well, but Gender, Marriage status and Work Status are some which we can ignore.","96e148be":"### Joined Data has bmi 3.33% data is missing and smoking_status is 30.7% missing","ceea8a88":"### Handling Categorical Variables","77b605c7":"### Import Files. Train Dataset and Test Dataset. Target Variable is 'Stroke'","8bdaef90":"### Import Libraries","20fb3c97":"### Random Forest Classifier with Smoking Status","fdaa2e86":"## Applying Model\n","672b87fa":"### Missing Values for Train and Test Data","146db8cc":"### Data Cleaning","f504f06c":"## Data Preprocessing","8ab6bba7":"### Conclusion\nOverall we used logistic regression to forecast weather a patient can have stroke or not. We has to deal with imbalanced data which is common in such healthcare problems. For improving the model we could try out other ways of dealing with imbalanced data like SMOTE.\n\nAlso we could have dealt with missing data of smoke status in other ways as well for e.g. Age less than 10 or 15 years patients could have been tagged as never_smoked etc.\n\nFinally just one thought on why the 2 models were so different, one of the reasons could be the age distribution of the 2 data set. Median age of Smoke dataset was 48 while that of Non smoke dataset was 21. These are some ways Logistic model could have been improved.","cec74f41":"### Missing Data for Joined Data","fbdcdcd6":"### Handling Imbalanced Data\n#### Now lets look at the number of positive and negative cases we have for stroke data","1cb26bb2":"### Feature Importance with random Forest","a374157b":"### Description of Train Data ","355c63dc":"### Logistic Regression Classifier without Smoking Status","73723573":"### Datasets Shape","1005adb7":"### Logistic Regression Classifier with Smoking Status","f42f05f7":"### Train Test Split of the balanced Data","9ca7fadb":"### Decision Tree Classifier without Smoking Status"}}