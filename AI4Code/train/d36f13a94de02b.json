{"cell_type":{"f3a030cc":"code","ae069372":"code","72637d98":"code","0776703c":"code","361ff19b":"code","482e2ca6":"code","e1ea3a32":"code","b02753a5":"code","7ca85028":"code","403c2ad4":"code","4c312c56":"code","31870791":"code","3b357ca7":"code","30bfd395":"code","42fb01dd":"code","8ffd04c2":"code","8c9963cf":"code","dece794a":"code","e3b00b4d":"code","b13abbf3":"code","25319cdc":"code","8955dca5":"code","68fa3f66":"markdown","e7883855":"markdown","7aec75d3":"markdown","45c936f6":"markdown","7c176be6":"markdown"},"source":{"f3a030cc":"# Importing the essential libraries for the exercise.\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\n# Linking the directory to access the dataset.\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ae069372":"# Reading the data, and exploring its characteristics.\npath = \"..\/input\/democratic-debate-transcripts-2020\/debate_transcripts_v2_2020-02-23.csv\"\ndata = pd.read_csv(path, encoding = \"ISO-8859-1\")\ndata[0:5]","72637d98":"# Dictionary of the debates.\ndebate_names = data[\"debate_name\"]\nnumber_of_debates = len(set(debate_names))\nprint(\"Total number of democratic debates:\", number_of_debates, \"debates\")\n\n# Dictionary of number of sections.\ndebate_section = data[\"debate_section\"]\nnumber_of_sections = len(set(debate_section))\nprint(\"Maximum number of sections in the debates:\", number_of_sections, \"sections\")\n\n# Dictionary of name of speakers.\ndem_speakers = data[\"speaker\"]\nnumber_of_speakers = len(set(dem_speakers))\nprint(\"Total number of democratic speakers:\",number_of_speakers, \"speakers\")\n\n# Mean duration of speech.\nprint(\"The average speaking time is:\",np.mean(data[\"speaking_time_seconds\"]), \"seconds\")","0776703c":"# Sorted dictionary of debates.\ndebs = dict()\nfor i in debate_names:\n    debs[i] = debs.get(i, 0) + 1\n\ndebates = {k: v for k, v in sorted(debs.items(), key=lambda item: item[1])}\n \n# Sorted dictionary of sections.\nsecs = dict()\nfor i in debate_section:\n    secs[i] = secs.get(i, 0) + 1\n\nsections = {k: v for k, v in sorted(secs.items(), key=lambda item: item[1])}\n\n# Sorted dictionary of speakers.\nspkrs = dict()\nfor i in dem_speakers:\n    spkrs[i] = spkrs.get(i, 0) + 1\n\nspeakers = {k: v for k, v in sorted(spkrs.items(), key=lambda item: item[1])}","361ff19b":"# Plot of debates\nimport matplotlib.pyplot as plt\n\nplt.bar(list(debates.keys()), debates.values(), color='red')\nplt.title(\"Histogram of Debates\")\nplt.xticks(rotation = 90)\nplt.rcParams[\"figure.figsize\"] = (10,10)","482e2ca6":"# Plot of speakers' activity\nplt.bar(list(speakers.keys()), speakers.values(), color='green')\nplt.title(\"Histogram of Speakers' Activity\")\nplt.xticks(rotation=90)\nplt.rcParams[\"figure.figsize\"] = (20,20)","e1ea3a32":"import spacy\nnlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\nrandom_state = 0\n\n# Taking into consideration only nouns so as to identify the topics.\ndef only_nouns(texts):\n    output = []\n    for doc in nlp.pipe(texts):\n        noun_text = \" \".join(token.lemma_ for token in doc if token.pos_ == 'NOUN')\n        output.append(noun_text)\n    return output","b02753a5":"# Merging the nouns-only list to the dataset.\ndata_new = only_nouns(data[\"speech\"])\nspeech_nouns = pd.DataFrame(data_new)\ndata[\"Index\"] = data.index\nspeech_nouns[\"Index\"] = speech_nouns.index\ndemocrat_data = pd.merge(data, speech_nouns, on=\"Index\")\ndemocrat_data.columns = [\"debate_name\", \"debate_section\", \"speaker\", \"speech\", \"speaking_time_seconds\", \"index\", \"speech_nouns\"]\ndemocrat_data = democrat_data.drop([\"index\"], axis=1)\ndemocrat_data.head()","7ca85028":"# Number of topics to extract\nn_topics = 10\n\n# Vectorization of the nouns.\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nvec = TfidfVectorizer(max_features=5000, stop_words=\"english\", max_df=0.95, min_df=2)\nfeatures = vec.fit_transform(democrat_data.speech_nouns)\n\n# Non-negative matrix factorization.\nfrom sklearn.decomposition import NMF\ncls = NMF(n_components=n_topics, random_state=random_state)\ncls.fit(features)","403c2ad4":"# List of unique words\nfeature_names = vec.get_feature_names()\n\n# Number of top words per topic\nn_top_words = 20\n\nfor i, topic_vec in enumerate(cls.components_):\n    print(i, end=' ')\n    for fid in topic_vec.argsort()[-1:-n_top_words-1:-1]:\n        print(feature_names[fid], end=' ')\n    print()","4c312c56":"import string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\ndemocrat_speeches = list()\nlines = data[\"speech\"].tolist()\n\nfor line in lines:\n    tokens = word_tokenize(line)\n    # lowercase\n    tokens = [word.lower() for word in tokens]\n    # remove punctuation\n    table = str.maketrans(\"\",\"\", string.punctuation)\n    strip = [w.translate(table) for w in tokens]\n    # remove remaining non-alphabets\n    words = [word for word in strip if word.isalpha()]\n    # filter stop-words\n    stop_words = set(stopwords.words('english'))\n    words = [w for w in words if not w in stop_words]\n    democrat_speeches.append(words)","31870791":"import gensim\n\n# Train word2vec model\nmodel = gensim.models.Word2Vec(sentences = democrat_speeches, size = 100, window = 5, workers = 4, min_count = 1)\n# Vocab size\nwords = list(model.wv.vocab)\nprint(\"Vocabulary size: \", len(words))","3b357ca7":"print(\"Talked issue #1: Tax\")\nmodel.wv.most_similar(\"tax\")","30bfd395":"print(\"Talked issue #2: Healthcare\")\nmodel.wv.most_similar(\"healthcare\")","42fb01dd":"print(\"Talked issue #3: Rebuttals\")\nmodel.wv.most_similar(\"rebuttal\")","8ffd04c2":"print(\"Talked issue #4: Policy\")\nmodel.wv.most_similar(\"policy\")","8c9963cf":"print(\"Talked issue #5: Law\")\nmodel.wv.most_similar(\"law\")","dece794a":"print(\"Talked issue #6: Immigration\")\nmodel.wv.most_similar(\"immigration\")","e3b00b4d":"print(\"Talked issue #7: Impeachment\")\nmodel.wv.most_similar(\"impeachment\")","b13abbf3":"print(\"Talked issue #8: Climate\")\nmodel.wv.most_similar(\"climate\")","25319cdc":"print(\"Talked issue #9: Class\")\nmodel.wv.most_similar(\"class\")","8955dca5":"print(\"Talked issue #10: Racism\")\nmodel.wv.most_similar(\"racism\")","68fa3f66":"## Topic Modeling with Non-negative Matrix Factorization","e7883855":"## Highlights of the Democratic debates 2020:\n\n1. Joe Biden and Elizabeth Warren gave more speeches that every other congressmen\/congresswomen\n2. All the candidates spoke for an average duration of 17 seconds.\n3. The most common topics of discussion were: \n                         (1) Wealth and tax returns of the candidates\n                         (2) Healthcare provisions for the community\n                         (3) Follow-up, opening, closing, and rebuttals \n                         (4) Changes in policies, and the associated dilemmas\n                         (5) Judiciary, and law\n                         (6) Deportation issues, and the economic impacts\n                         (7) Impeachment of the President\n                         (8) Climate change\n                         (9) Various classes in the society (higher, lower, and middle) and respective issues\n                         (10) Gun laws, and racism\n                         \nThe analysis of the democratic debates show that the debates generally center around the wealth status of the candidates and the respective follow-ups\/rebuttals\/rivalries. The second most prioritized topic is \"Healthcare\", which is a prime concern for people of all demographics. The ethical dilemmas within the conducts of the American society are less discussed, due to possible lobbying efforts and differing points of view (when the party members know certain topics are too controversial, they tend to not mention it voluntarily in their speeches, but it seems they are asked questions regarding those topics by other members\/audience).","7aec75d3":"# Analyzing the Democratic Debates of 2020\n\nThe following exercise involves some exploratory data analysis, and topic modeling in order to identify congressmen\/congresswomen-level statistics, and the topics that they tend to speak about.","45c936f6":"## Exploratory Data Analysis","7c176be6":"## Sentiment clarification with Word2Vec Embedding"}}