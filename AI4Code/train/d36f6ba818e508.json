{"cell_type":{"c1873e5f":"code","05829e51":"code","58c30ead":"code","79f0369c":"code","892cd2af":"code","1a8cf58f":"code","3902793a":"code","d031f437":"code","103fd958":"code","4359f7bc":"code","60e22aa5":"code","979db52e":"code","a7aef2d7":"code","540839a7":"code","2a83c596":"code","5dc6c85b":"code","229bf8c3":"code","9730293d":"code","f6569e81":"code","31e6c993":"code","c9126fa6":"code","7d8a4a11":"code","5a8cb7aa":"code","91098e60":"code","2634e50e":"code","c5d6a10f":"code","a9a0c41c":"code","71e15446":"code","66564314":"code","62458da4":"code","51b1517c":"code","5a8c1829":"code","df0c6c10":"code","f0c855b1":"code","6ad82577":"code","dca346ba":"code","d5ecba8c":"code","c4ae9875":"code","ba455a2b":"code","a6032538":"code","9a1fc0db":"code","7dcf6958":"markdown","ca749b26":"markdown","db88652f":"markdown","a8ef4516":"markdown","5e379bbb":"markdown","df16b84e":"markdown","e28ca1f7":"markdown","d1ffe485":"markdown","6bf5cde6":"markdown","ca7bb9f3":"markdown","4d11367d":"markdown","316652b4":"markdown","01a2b705":"markdown","a27f2036":"markdown"},"source":{"c1873e5f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05829e51":"\ndata = '\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv'\n\ndf = pd.read_csv(data)\ndf.head()","58c30ead":"# checking shape of data\ndf.shape","79f0369c":"# checking data info\ndf.info()","892cd2af":"# checking target column values counts\ndf['RainTomorrow'].value_counts()","1a8cf58f":"# Plotting count of target column\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.countplot('RainTomorrow',data=df)\nplt.title(\"Target Count\")","3902793a":"# checking null values\ndf.isna().sum()","d031f437":"# dropping NA values from target column\nprint(df.shape)\ndf.dropna(subset=['RainTomorrow'],inplace = True)\ndf = df.reset_index(drop=True)\nprint(df.shape)","103fd958":"categorical = [ i for i in df.columns if df[i].dtype =='O']\ninteger = [i for i in df.columns if df[i].dtype !='O']\nprint('Categorical data types columns:',categorical)\nprint('Integer data types columns:',integer)\n","4359f7bc":"# checking NAN values in data type integer\ndf[integer].isna().sum()","60e22aa5":"# checking NAN values in data type categorical\ndf[categorical].isna().sum()","979db52e":"# Convertig Date column in to date format and splitting it into year,month and date\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['year'] = df['Date'].dt.year\ndf['month'] = df['Date'].dt.month\ndf['day'] = df['Date'].dt.day\ndf.drop('Date',axis = 1,inplace = True)\ndf.head()","a7aef2d7":"df[['year', 'month','day']] = df[['year', 'month','day']].astype('string')\nprint(df.year.dtypes)","540839a7":"# checking for outliers in numerical data type columns\n# first we will analyze outliers using box plot\nfor i in integer:\n    plt.figure(figsize=(5,5))\n    fig = df.boxplot(column=i)\n    fig.set_ylabel('i')\n\n","2a83c596":"# now we will use IQR method to remove outliers from the required columns\nfrom scipy import stats\nq1 = df.MinTemp.quantile(0.25)\nq3 = df.MinTemp.quantile(0.75)\niqr = q3-q1\nlowerbound = q1 - 1.5 * iqr\nupperbound = q3 + 1.5 * iqr\ndf.drop(df[ (df.MinTemp > upperbound) | (df.MinTemp < lowerbound) ].index , inplace=True)","5dc6c85b":"# checking boxplot for MinTemp\nplt.figure(figsize=(5,5))\nfig = df.boxplot(column='MinTemp')\nfig.set_ylabel('MinTemp')","229bf8c3":"# removing outliers from the remaining columns\nl1 = ['MaxTemp', 'Rainfall', 'Evaporation', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\nfor i in l1:\n    q1 = df[i].quantile(0.25)\n    q3 = df[i].quantile(0.75)\n    iqr = q3-q1\n    lowerbound = q1 - 1.5 * iqr\n    upperbound = q3 + 1.5 * iqr\n    df.drop(df[ (df[i] > upperbound) | (df[i] < lowerbound) ].index , inplace=True)","9730293d":"# converting them again in integer\ndf[['year', 'month','day']] = df[['year', 'month','day']].astype('int')\nprint(df.year.dtypes)\n","f6569e81":"# new columns with data type integer\ninteger1 = [i for i in df.columns if df[i].dtype !='O']\nprint(integer1)","31e6c993":"from sklearn.model_selection import train_test_split\nX = df.drop(['RainTomorrow'], axis=1)\ny = df['RainTomorrow']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train.shape, X_test.shape","c9126fa6":"# replacing integer NAN values with Median \nfor df in [X_train, X_test]:\n    for col in integer1:\n        col_median=X_train[col].median()\n        df[col].fillna(col_median, inplace=True)","7d8a4a11":"# checking values in X_train\nX_train[integer1].isnull().sum()","5a8cb7aa":"# checking values in X_test\nX_test[integer1].isnull().sum()","91098e60":"# replcaing NAN values with the mode in categorical data types\nfor df1 in [X_train, X_test]:\n    df1['WindGustDir'].fillna(X_train['WindGustDir'].mode()[0], inplace=True)\n    df1['WindDir9am'].fillna(X_train['WindDir9am'].mode()[0], inplace=True)\n    df1['WindDir3pm'].fillna(X_train['WindDir3pm'].mode()[0], inplace=True)\n    df1['RainToday'].fillna(X_train['RainToday'].mode()[0], inplace=True)","2634e50e":"categorical1 = [i for i in X_train.columns if X_train[i].dtype == 'O']\n# As Location column don't have any NAN values\ncategorical1.remove('Location')\n# checking NAN values in X_train\nX_train[categorical1].isnull().sum()","c5d6a10f":"# checking NAN values in X_test\nX_test[categorical1].isnull().sum()","a9a0c41c":"# Encoding Rain Today column\nfrom sklearn import preprocessing\n \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n \n# Encode labels in column 'species'.\nX_train['RainToday'] = label_encoder.fit_transform(X_train['RainToday'])\n\nX_test['RainToday'] = label_encoder.transform(X_test['RainToday'])\n \nprint(X_train['RainToday'].unique())\nprint(X_train.columns)","71e15446":"# Encode categorical variables\nX_train = pd.concat([X_train[integer1], X_train['RainToday'],\n                     pd.get_dummies(X_train.Location), \n                     pd.get_dummies(X_train.WindGustDir),\n                     pd.get_dummies(X_train.WindDir9am),\n                     pd.get_dummies(X_train.WindDir3pm)], axis=1)\nX_train.head()","66564314":"# Encode categorical variables\nX_test = pd.concat([X_test[integer1], X_test['RainToday'],\n                     pd.get_dummies(X_test.Location), \n                     pd.get_dummies(X_test.WindGustDir),\n                     pd.get_dummies(X_test.WindDir9am),\n                     pd.get_dummies(X_test.WindDir3pm)], axis=1)\nX_test.head()","62458da4":"# data Normalization\ncols = X_train.columns\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)\nX_train = pd.DataFrame(X_train, columns=[cols])\nX_test = pd.DataFrame(X_test, columns=[cols])","51b1517c":"def fit_and_evaluate(model):\n    # Train the model\n    model.fit(X_train, y_train)\n    score = model.score(X_test,y_test)\n    \n    # Return the performance metric\n    return score","5a8c1829":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(solver='liblinear', random_state=0)\nlog_score = fit_and_evaluate(logreg)\nprint('Logistic Regression Performance on the test set: score = %0.4f' % log_score)","df0c6c10":"# Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nnaive = GaussianNB()\nnaive_score = fit_and_evaluate(naive)\nprint('Naive Bayes Performance on the test set: score = %0.4f' % naive_score)","f0c855b1":"# Random Forest Classification\nfrom sklearn.ensemble import RandomForestClassifier\nrandom = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\nrandom_score = fit_and_evaluate(random)\n\nprint('Random Forest Performance on the test set: Score = %0.4f' % random_score)","6ad82577":"# calculating confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_head_logreg = logreg.predict(X_test)\ncm_logreg = confusion_matrix(y_test,y_head_logreg)\nprint(cm_logreg)","dca346ba":"# calculating sensitivity and specificity\nsensitivity = (cm_logreg[0,0]\/(cm_logreg[0,0] + cm_logreg[1,0]))\nprint(\"sensitivity:\",sensitivity)\nspecificity = (cm_logreg[1,1]\/(cm_logreg[1,1]+cm_logreg[0,1]))\nprint(\"specificity:\",specificity)","d5ecba8c":"TP = cm_logreg[0,0]\nTN = cm_logreg[1,1]\nFP = cm_logreg[0,1]\nFN = cm_logreg[1,0]","c4ae9875":"# print precision score\n\nprecision = TP \/ float(TP + FP)\n\n\nprint('Precision : {0:0.4f}'.format(precision))\n","ba455a2b":"classification_error = (FP + FN) \/ float(TP + TN + FP + FN)\n\nprint('Classification error : {0:0.4f}'.format(classification_error))","a6032538":"from sklearn.metrics import roc_curve\ny_pred1 = logreg.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred1, pos_label = 'Yes')\n\nfrom sklearn.metrics import roc_auc_score\n\nROC_AUC = roc_auc_score(y_test, y_pred1)\nprint(ROC_AUC)","9a1fc0db":"# weightage to the column in Logistic Regression Algorithm\nimport eli5 #for purmutation importance\nfrom eli5.sklearn import PermutationImportance\nl2=[]\nl1 = X_train.columns.tolist()\nfor i in range(len(l1)):\n    l2.append(l1[i][0])\n    \nperm = PermutationImportance(logreg, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = l2)","7dcf6958":"Checking Random Forest Algorithm","ca749b26":"Checking NAN values in the integer data types and replacing them with the Median values of the column","db88652f":"As we can see that now outliers are removed from this MinTemp, similary like this we will remove the outliers from all the other columns.","a8ef4516":"Permutation importance\u00a0is the first tool for understanding a machine-learning model, and it involves shuffling individual variables in the validation data (after a model has been fit) and seeing the effect on accuracy.","5e379bbb":"Since Logistic Regression gives the best accuracy score so we will calculate confusion matrix, sensitivity,specificity and auc_score on the Logistic Regression","df16b84e":"Checking Logistic Regression Algorithm","e28ca1f7":"**Data Normalization**","d1ffe485":"**Model Training**","6bf5cde6":"***I'm fresh to the field of data science. Please leave me feedback so that I can improve. Thank you for your time and consideration.***","ca7bb9f3":"**Exploratory data analysis**","4d11367d":"Checking Naive Bayes Algorithm","316652b4":"**LOADING DATA**","01a2b705":"**Splitting the Data**","a27f2036":"As we can see from the above output that data has lot of NAN values and we need to treat them for our model.First we will divide the data in category and integer datatypes"}}