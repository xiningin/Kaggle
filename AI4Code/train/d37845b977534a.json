{"cell_type":{"bb26064d":"code","547cf0b4":"code","fe39deea":"code","61b1f554":"code","cb28e458":"code","6adadf8e":"code","59d21d3d":"code","104f8804":"code","c9f392d0":"code","b6f16532":"code","7e534998":"code","2758f53f":"code","b53604e4":"code","74ba0fe8":"code","851515f5":"code","25ffd091":"code","bb08db7d":"code","0f54240b":"code","3e71a955":"code","08738820":"code","6067de50":"code","fa399efa":"code","da2ff686":"code","b414d566":"code","21db0b2a":"code","8df20526":"markdown","f0b16277":"markdown","d4b5ecc2":"markdown","b8d80016":"markdown","426c349b":"markdown","278746ac":"markdown","5dd1f148":"markdown","8ad4feb3":"markdown","57040bf4":"markdown","2b6816cb":"markdown","ceea11cf":"markdown"},"source":{"bb26064d":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import (Input, Model, layers, losses, optimizers, metrics, utils, models)\n\nsns.set_style('darkgrid')","547cf0b4":"# CONSTANTS\nDATA_PATH = '..\/input\/sports-classification'\nTRAIN_PATH = os.path.join(DATA_PATH, 'train')\nVAL_PATH = os.path.join(DATA_PATH, 'valid')\nTEST_PATH = os.path.join(DATA_PATH, 'test')\n\nIMAGE_SIZE = (224, 224)\nIMAGE_SHAPE = (224, 224, 3)\nNUM_CLASSES = len(os.listdir(TEST_PATH))\n\n# HYPERPARAMETERS\nBATCH_SIZE = 32\nEPOCHS = 50\nLEARNING_RATE = 1e-3","fe39deea":"data_generator = image.ImageDataGenerator(rescale = 1.\/255)\ntrain_generator = data_generator.flow_from_directory(directory= TRAIN_PATH,\n                                                    target_size=IMAGE_SIZE,\n                                                    color_mode= 'rgb',\n                                                    class_mode= 'categorical',\n                                                    batch_size= BATCH_SIZE)\nval_generator = data_generator.flow_from_directory(directory= VAL_PATH,\n                                                    target_size=IMAGE_SIZE,\n                                                    color_mode= 'rgb',\n                                                    class_mode= 'categorical',\n                                                    batch_size= BATCH_SIZE)\ntest_generator = data_generator.flow_from_directory(directory= TEST_PATH,\n                                                    target_size=IMAGE_SIZE,\n                                                    color_mode= 'rgb',\n                                                    class_mode= 'categorical',\n                                                    batch_size= BATCH_SIZE,\n                                                    shuffle= False)","61b1f554":"def get_cnn_model(IMAGE_SHAPE):\n    \"\"\"\n    creates and returns a CNN model.\n    \"\"\"\n    # Define the tensors for the two input images\n    input_layer = Input(IMAGE_SHAPE)\n    x = layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\")(input_layer)\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    x = layers.Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\")(x)\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    x = layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\")(x)\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    x = layers.Flatten()(x)\n    outputs = layers.Dense(NUM_CLASSES, name=\"final_dense\", activation='softmax')(x)\n    return Model(input_layer, outputs)","cb28e458":"model = get_cnn_model(IMAGE_SHAPE)\nmodel.summary()","6adadf8e":"model.compile(optimizer = optimizers.Adam(LEARNING_RATE), \n                loss = losses.categorical_crossentropy, \n                metrics = ['accuracy'])","59d21d3d":"history = model.fit(train_generator, validation_data= val_generator, epochs = EPOCHS)","104f8804":"plt.figure(figsize = (18,12))\nplt.subplot(2,2,1)\nplt.title('Training Loss')\nplt.plot(history.history['loss'], color = 'tab:orange')\nplt.subplot(2,2,2)\nplt.title('Training Accuracy')\nplt.plot(history.history['accuracy'], color = 'tab:blue')\nplt.subplot(2,2,3)\nplt.title('Validation Loss')\nplt.plot(history.history['val_loss'], color = 'tab:orange')\nplt.subplot(2,2,4)\nplt.title('Validation Accuracy')\nplt.plot(history.history['val_accuracy'], color = 'tab:blue');","c9f392d0":"model.save('model1')","b6f16532":"model.evaluate(test_generator)","7e534998":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input","2758f53f":"train_data_generator = image.ImageDataGenerator(\n                                            rotation_range=30,\n                                            zoom_range=0.15,\n                                            width_shift_range=0.2,\n                                            height_shift_range=0.2,\n                                            shear_range=0.15,\n                                            horizontal_flip=True,\n                                            fill_mode=\"nearest\",\n                                            preprocessing_function=preprocess_input\n                                            )\n\ntest_data_generator = image.ImageDataGenerator(\n                                            preprocessing_function=preprocess_input\n                                            )\n\ntrain_generator = train_data_generator.flow_from_directory(directory= TRAIN_PATH,\n                                                    target_size=IMAGE_SIZE,\n                                                    color_mode= 'rgb',\n                                                    class_mode= 'categorical',\n                                                    batch_size= BATCH_SIZE)\nval_generator = train_data_generator.flow_from_directory(directory= VAL_PATH,\n                                                    target_size=IMAGE_SIZE,\n                                                    color_mode= 'rgb',\n                                                    class_mode= 'categorical',\n                                                    batch_size= BATCH_SIZE)\ntest_generator = test_data_generator.flow_from_directory(directory= TEST_PATH,\n                                                    target_size=IMAGE_SIZE,\n                                                    color_mode= 'rgb',\n                                                    class_mode= 'categorical',\n                                                    batch_size= BATCH_SIZE)","b53604e4":"class ModifiedMobileNet():\n    '''\n    This class creates the mobilenet model.\n    '''\n    def __init__(self, input_shape, nb_classes):\n        self.input_shape = input_shape\n        self.nb_classes = nb_classes\n        \n    def get_model(self, unfreeze_layers = None, lr_rate = 0.001):\n        # load base model\n        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=self.input_shape)\n        \n        # freezing the layers\n        for layer in (base_model.layers) if not unfreeze_layers else (base_model.layers[:-int(unfreeze_layers)]):\n            layer.trainable = False\n            \n        inputs = Input(shape=self.input_shape)\n        x = base_model(inputs, training=False)\n        x = layers.GlobalAveragePooling2D()(x)\n        x = layers.Dense(128, activation='relu')(x)\n        x = layers.Dropout(0.1)(x)\n        x = layers.Dense(128, activation='relu')(x)\n        x = layers.Dropout(0.1)(x)\n        outputs = layers.Dense(self.nb_classes, activation='softmax')(x)\n        model = Model(inputs, outputs)\n        \n        # model compilation\n        optimizer = optimizers.Adam(learning_rate=lr_rate)\n        model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n        return model","74ba0fe8":"mobilenet = ModifiedMobileNet(input_shape= IMAGE_SHAPE, nb_classes= NUM_CLASSES)\nmodel = mobilenet.get_model(unfreeze_layers=0, lr_rate= LEARNING_RATE)","851515f5":"model.compile(optimizer = optimizers.Adam(LEARNING_RATE), \n                loss = losses.categorical_crossentropy, \n                metrics = ['accuracy'])","25ffd091":"history = model.fit(train_generator, validation_data= val_generator, epochs = EPOCHS)","bb08db7d":"model.save('model2')","0f54240b":"model.evaluate(test_generator)","3e71a955":"test_generator = data_generator.flow_from_directory(directory= TEST_PATH,\n                                                    target_size=IMAGE_SIZE,\n                                                    color_mode= 'rgb',\n                                                    class_mode= 'sparse',\n                                                    batch_size= 365,\n                                                    shuffle= False)","08738820":"test_images, test_labels = test_generator.next()","6067de50":"default_model = models.load_model('model1\/')\nimproved_model = models.load_model('model2\/')","fa399efa":"default_predictions= default_model.predict(test_images).argmax(axis = 1)\nimproved_predictions= improved_model.predict(test_images).argmax(axis = 1)","da2ff686":"from sklearn.metrics import precision_score, recall_score","b414d566":"def_precision, def_recall = (precision_score(test_labels, default_predictions, average= 'weighted'),\n                            recall_score(test_labels, default_predictions, average= 'weighted'))\nimp_precision, imp_recall = (precision_score(test_labels, improved_predictions, average= 'weighted'),\n                            recall_score(test_labels, improved_predictions, average= 'weighted'))","21db0b2a":"colors = ['tab:blue', 'tab:orange', 'tab:blue', 'tab:orange']\ncustomPalette = sns.set_palette(sns.color_palette(colors))\nplt.figure(figsize = (12,6))\nplt.title('Precision & Recall Comparision\\nDefault and Improved Model')\nf = sns.barplot(x = list(range(4)), y = [def_precision, imp_precision, def_recall, imp_recall], palette=customPalette)\nplt.xticks(f.get_xticks(), labels = ['default precision', 'improved precision', 'default recall', 'improved recall']);","8df20526":"Let's check the Precision and Recall of Both architectures.  \nSince there are 73 classes, we will calculated weighted Precision and Recall for ease of understanding.","f0b16277":"# Sport-73 Classification","d4b5ecc2":"That's it for this one. Thanks!\nAny comments, suggestions or corrections are welcome.\n\nFollow me on Twitter [@capeandcode](https:\/\/www.twitter.com\/capeandcode).      \n\nConnect with me [here](https:\/\/prashantbrahmbhatt.bio.link\/).","b8d80016":"Fixing some constants that may need multiple times.","426c349b":"First, we are going to try with a simple CNN architecture and see how it does","278746ac":"Creating the image data generators.","5dd1f148":"As we can see, the results look horrible and whatever we are doing is not working. \nWe should now try with some transfer learning and see if previous learning helps with the results.\n\n- We will be using MobileNet architecture with some added modifications.\n- Image augmentation can also be useful for the model, especially one with 73 classes.","8ad4feb3":" We'll keep the base MobileNet frozen completely and only the added layers will learn from our dataset.","57040bf4":"Let's just add two Dense layers to the architecture.","2b6816cb":"We can observe from the above plots how much we have improved by using the knowledge that MobileNet already has with some new learning from the added dense layers.","ceea11cf":"Let's do the imports"}}