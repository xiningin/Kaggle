{"cell_type":{"ece2eb32":"code","de8c75b6":"code","4179666e":"code","91fdc98e":"code","9400351b":"code","f12283c8":"code","cdc1f6ed":"code","2aa1f15a":"code","b1400cfd":"code","887cf551":"code","2420a000":"code","dc85c79e":"code","f6b357b9":"code","08c87e20":"code","b53c0ad1":"code","c8104851":"code","8f0a5257":"code","58e20e06":"code","e1c4c68d":"code","cb499c63":"code","e6cd8eba":"code","e41591fd":"code","a32bd35a":"code","9f7d8dce":"markdown","e7c586a0":"markdown","a0afa83d":"markdown","29752566":"markdown","aed5ea55":"markdown","f0b5d252":"markdown","29fe1d92":"markdown","ee3411a7":"markdown","7e958547":"markdown","9506f3b1":"markdown","3a58c6ee":"markdown","646769ba":"markdown","0494ea2e":"markdown","84cd803f":"markdown"},"source":{"ece2eb32":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport gc\nimport os\nimport PIL\n\nfrom scipy import stats\nfrom multiprocessing import Pool\nfrom PIL import ImageOps, ImageFilter\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud\nfrom textwrap import wrap\n\n\ntqdm.pandas()","de8c75b6":"train_path = '..\/input\/train\/'\ntrain_df = pd.read_csv('..\/input\/train.csv')\nlabel_df = pd.read_csv('..\/input\/labels.csv')\n\nprint('Files loaded!')","4179666e":"train_df['num_labels'] = train_df['attribute_ids'].apply(lambda x: len(x.split()))","91fdc98e":"train_df.head()","9400351b":"label_df.head()","f12283c8":"train_df.shape, label_df.shape","cdc1f6ed":"category_map = {}\n\ndef fetch_categories(x):\n    categories = x.split()\n    for category in categories:\n        category = int(category)\n        if category not in category_map.keys():\n                category_map[category] = 0\n        category_map[category] += 1 \ncol = train_df['attribute_ids'].apply(lambda x: fetch_categories(x))","2aa1f15a":"category_df = pd.DataFrame.from_dict(category_map, orient='index', columns=['count']).reset_index().rename(\n    columns={'index': 'attribute_id'})\ncategory_df.head()","b1400cfd":"label_df = label_df.merge(category_df, how='left', on='attribute_id')\nlabel_df = label_df.sort_values(by='count', ascending=False)\nlabel_df.head()","887cf551":"top_20_samples = label_df[:20].copy().reset_index()\nplt.figure(figsize=(10,5))\nsns.barplot(top_20_samples['count'], top_20_samples.index, orient='h')\nplt.title('Number of samples for category (top 20)')\nplt.xlabel('Number of samples')\nplt.ylabel('Categories')\nplt.show()","2420a000":"label_df['is_culture'] = label_df['attribute_name'].apply(lambda x: 1 if 'culture' in x else 0)\nattribute_count = label_df['is_culture'].value_counts()\n\nsns.barplot(['Tag', 'Culture'], attribute_count.values, alpha=0.8)\nplt.title('Culture\/Tag')\nplt.xlabel('attribute type')\nplt.ylabel('Frequency')","dc85c79e":"culture_df = label_df[label_df['is_culture'] == 1].copy()\ntag_df = label_df[label_df['is_culture'] != 1].copy()","f6b357b9":"plt.figure(figsize=(20,15))\n\nplt.subplot(1,2,1)\nax1 = sns.barplot(x=culture_df[:20]['count'],\n                  y=culture_df[:20]['attribute_name'], orient=\"h\")\nplt.title('Label Counts by Culture (Top 20)',fontsize=15)\nplt.xlim((0, culture_df['count'].max()*1.15))\nplt.yticks(fontsize=15)\n\nfor p in ax1.patches:\n    ax1.annotate(f'{int(p.get_width())}\\n{p.get_width() * 100 \/ train_df.shape[0]:.2f}%',\n                (p.get_width(), p.get_y() + p.get_height() \/ 2.), \n                ha='left', \n                va='center', \n                fontsize=12, \n                color='black',\n                xytext=(7,0), \n                textcoords='offset points')\n\nplt.subplot(1,2,2)    \nax2 = sns.barplot(x=tag_df[:20]['count'],\n                  y=tag_df[:20]['attribute_name'], orient=\"h\")\nplt.title('Label Counts by Tag (Top 20)',fontsize=15)\nplt.xlim((0, tag_df['count'].max()*1.15))\nplt.yticks(fontsize=15)\n\nfor p in ax2.patches:\n    ax2.annotate(f'{int(p.get_width())}\\n{p.get_width() * 100 \/ train_df.shape[0]:.2f}%',\n                (p.get_width(), p.get_y() + p.get_height() \/ 2.), \n                ha='left', \n                va='center', \n                fontsize=12, \n                color='black',\n                xytext=(7,0), \n                textcoords='offset points')\n\nplt.tight_layout()\nplt.show()\n","08c87e20":"def plot_image_for_attribute(attribute_id, idx, rows=10, cols=3):\n    global cnt\n    plt.figure(figsize=(15,6))\n\n    # str contains logic would fail for ids <=109 because of regex matching\n    img_ids = train_df[train_df['attribute_ids'].str.contains(attribute_id)][:cols][['id', 'attribute_ids']]\n\n    for img_id, attr_ids in zip(img_ids['id'].values, img_ids['attribute_ids'].values):\n        attr_ids = attr_ids.split()\n        title = ''\n        for attr_id in attr_ids:\n            title += label_df.loc[int(attr_id)]['attribute_name'] + ' '\n\n        img = PIL.Image.open(f'{train_path}{img_id}.png')\n        plt.subplot(rows, cols, idx)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title((\"\\n\".join(wrap(title, 40))))\n        idx += 1\n\ndef plot_img_for_attribute_ids(attribute_ids, num_imgs=3):\n    n_rows = len(attribute_ids)\n    n_cols = num_imgs\n    idx = 1\n    for attr_id in attribute_ids:\n        print(attr_id, idx)\n        plot_image_for_attribute(str(attr_id), idx, n_rows, n_cols)\n        idx += n_cols \n    plt.show()","b53c0ad1":"attr_ids = culture_df[:2]['attribute_id'].values\nplot_img_for_attribute_ids(attr_ids)","c8104851":"attr_ids = tag_df[:2]['attribute_id'].values\nplot_img_for_attribute_ids(attr_ids)","8f0a5257":"plt.figure(figsize=(20,8))\n\nax = sns.countplot(train_df['num_labels'])\nplt.xlabel('Number of Labels')\nplt.title('Number of Labels per Image', fontsize=20)\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height() * 100 \/ train_df.shape[0]:.3f}%',\n            (p.get_x() + p.get_width() \/ 2., p.get_height()), \n            ha='center', \n            va='center', \n            fontsize=11, \n            color='black',\n            xytext=(0,7), \n            textcoords='offset points')","58e20e06":"img_ids = train_df.groupby(by='num_labels').first().reset_index()\nimg_ids = img_ids[img_ids['num_labels']>6]\nimg_ids.shape","e1c4c68d":"img_ids.head()","cb499c63":"plt.figure(figsize=(20, 10))\nidx = 1\nfor img_id, attr_ids in zip(img_ids['id'].values, img_ids['attribute_ids'].values):\n        attr_ids = attr_ids.split()\n        title = ''\n        for attr_id in attr_ids:\n            title += label_df.loc[int(attr_id)]['attribute_name'] + ' '\n\n        img = PIL.Image.open(f'{train_path}{img_id}.png')\n        plt.subplot(3, 3, idx)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title((\"\\n\".join(wrap(title, 40))))\n        idx += 1\nplt.subplots_adjust(hspace=1, wspace=0)\nplt.show()","e6cd8eba":"img_ids = label_df[label_df['count'] == 1]\nprint(img_ids.shape)\nimg_ids.head(15)","e41591fd":"img_ids = label_df[label_df['count'] <= 5]\nprint(img_ids.shape)\nimg_ids.head()","a32bd35a":"sparse_data_imgs = img_ids.groupby('count')['is_culture'].value_counts().to_frame().reset_index(level='count').rename(columns={\n    'is_culture': 'is_culture_count', 'count': 'num_labels'}).reset_index()\n\nsns.barplot(x='num_labels', y='is_culture_count', data=sparse_data_imgs, hue='is_culture', alpha=0.8)\nplt.title('Culture\/Tag')\nplt.xlabel('Num Labels')\nplt.ylabel('Frequency')","9f7d8dce":"## Next Steps:\n*  Dig into overlap of such categories which have **<= 5** sample in train set\n*  Figure out similarity between attributes from **culture & tag** categories\n*  Figure out for which types of images pretrained models are performing very poorly by revisting the wrongly classfied samples\n*  Try to figure out which are the types of images causing this issue & why for ex: attribute similarity like **tag::men\/tag::women** case\n*  Do much extensive EDA","e7c586a0":"Interesting, images with **num_labels > 8** could be really difficult for model to figure out because of mutliple ambiguous components. Let's visualize them and see if this hypothesis could be true.","a0afa83d":"### Beginner to EDA\n\nIn this kernel I tried to understand what all properties do the samples for every attribute have. How imbalanced the data is. Tried to look for basic differences in the distribution of samples for both **culture & tag** categories. Some code snippets in this kernel were taken from [here (EDA wei)](https:\/\/www.kaggle.com\/chewzy\/eda-weird-images-with-new-updates)\n\nPlease leave your suggestions in the kernel comments.","29752566":"Let's have a look at the numbers for maximum samples belonging to a class for both **culture** and **tag**. As we can see from **top 20** of both the classes the data for every category is very less. From our previous charts we saw that there were so many classes with just 1 sample in train set.\n\nThis idea was taken from [here](https:\/\/www.kaggle.com\/chewzy\/eda-weird-images-with-new-updates)","aed5ea55":"## Next Steps:\n*  Dig into all attribute id which have **<= 5 samples** in the dataset, with how many categories such samples are tagged","f0b5d252":"Please upvote if you find it insightful\/ interesting! :)","29fe1d92":"Let's see how top 2 categories from each type **culture** & **tag** looks like","ee3411a7":"### Work in Progress..","7e958547":"From above visualisations we can see that model can easily make mistakes for **tag::men & tag::women**. Similarly we can look for categories which can be ambiguous for the model. Another example of such ambiguity could be **tag::flowers & tag::trees**.","9506f3b1":"## Dig into number of labels for images","3a58c6ee":"## Target Variables","646769ba":"Interesting, as we can see there is only **1 tag type** category which has a single sample for it. ","0494ea2e":"As we can see there are so many classes with imbalanced number of samples in the dataset. Gradually the number of samples for categories keep decreasing with some number of the categories having only 1 sample.\nLet's try to see what type of images are these **culture** or **tags**.","84cd803f":"Let's see how the number of **culture and tag** categories look for all images with **<=5** labels."}}