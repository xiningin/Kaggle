{"cell_type":{"70d3fc9e":"code","614a8f1b":"code","32c26d6e":"code","d5701387":"code","d59ae336":"code","d4f0f4da":"code","176f60c5":"code","3b9bb723":"code","64f12cf7":"code","78549d7e":"code","995d3091":"code","86397c6f":"code","0016ff23":"code","a40deaeb":"code","e226969c":"code","6f105f02":"code","defc890f":"code","4c36c0b2":"code","609b68df":"code","31ef0b54":"code","6041690d":"code","8de9e08a":"code","b3ee9a35":"code","88c7b268":"code","cfc1b52d":"code","2fc3ef90":"code","78860008":"code","534973a9":"code","3deb1e49":"code","0dcc2c4d":"code","725d90e4":"code","40eed47e":"code","321c6428":"code","c871e9e2":"code","d4924f9f":"code","40c451f2":"code","50d45fee":"code","aeac63fc":"code","1999af6e":"code","84ded692":"markdown","5d03790c":"markdown","9954d093":"markdown","48657255":"markdown"},"source":{"70d3fc9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","614a8f1b":"#import seaborn as sns\n#train[train['Gender']=='Male']['Response'].sum()\n#train[train['Gender']=='Female']['Response'].sum()\n#col=['Gender','Response']\n#sns.pairplot(train[col])\n#col=train.columns\n#print(col)\n#col=[ 'Gender', 'Age', 'Driving_License', 'Region_Code',\n#       'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium',\n#       'Policy_Sales_Channel', 'Vintage', 'Response']\n\n#sns.pairplot(train[col])\n#col=['Response','Vintage']\n\n#sns.pairplot(train[col])\n#import matplotlib.pyplot as plt \n#var = 'Vehicle_Age'\n#data = pd.concat([train['Response'], train[var]], axis=1)\n#data.plot.scatter(x=var, y='Vehicle_Age', ylim=(0,1));\n\n#train[train['Response']==0]['Vehicle_Age'].unique()\n\n#train[train['Response']==1]['Vehicle_Age'].unique()\n\n#print(len(train[train['Previously_Insured']==1][train['Response']==0]))\n#print(len(train[train['Previously_Insured']==1]))\n#col=['Annual_Premium','Response']\n#sns.distplot(train[col])\n\n","32c26d6e":"#print(\"The number of classes before fit {}\".format(Counter(target)))\n#print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))","d5701387":"#X_train_ns['Response'].sum()\n \n#target=X_train_ns['Response']\n#X_train_ns=X_train_ns.drop(['Response'],axis=1)","d59ae336":"'''\nfrom imblearn.under_sampling import NearMiss\nns=NearMiss(0.8)\nX_train_ns,y_train_ns=ns.fit_sample(X_train_ns,target)\nprint(\"The number of classes before fit {}\".format(Counter(target)))\nprint(\"The number of classes after fit {}\".format(Counter(y_train_ns)))\n\n'''","d4f0f4da":"#X_train_ns","176f60c5":"'''\nprint(len(train[train['Driving_License']==1][target==0]))\nprint(len(train[train['Driving_License']==0][target==0]))\nprint(len(train[train['Driving_License']==1][target==1]))\nprint(len(train[train['Driving_License']==0][target==1]))\n\nprint(len(train[train['Previously_Insured']==1][target==0]))\nprint(len(train[train['Previously_Insured']==0][target==0]))\nprint(len(train[train['Previously_Insured']==1][target==1]))\nprint(len(train[train['Previously_Insured']==0][target==1]))\n\nprint(len(train[train['Gender']==1][target==0]))\nprint(len(train[train['Gender']==0][target==0]))\nprint(len(train[train['Gender']==1][target==1]))\nprint(len(train[train['Gender']==0][target==1]))\n\n'''","3b9bb723":"#target=pd.concat([target,train['Driving_License']],axis=1)\n","64f12cf7":"#from imblearn.under_sampling import NearMiss\n#nm=NearMiss()\n#train_new,target_new=nm.fit_sample(train,target)","78549d7e":"train=pd.read_csv('..\/input\/janatahack-crosssell-prediction\/train.csv')\ntest=pd.read_csv('..\/input\/janatahack-crosssell-prediction\/test.csv')","995d3091":"\ntarget=train['Response']\ntrain=train.drop(['Response','id'],axis=1)\na={'Male':0,'Female':1}\ntrain['Gender']=train['Gender'].map(a)\na={'> 2 Years':0, '1-2 Year':2, '< 1 Year':1}\ntrain['Vehicle_Age']=train['Vehicle_Age'].map(a)\na={'Yes':1,'No':0}\ntrain['Vehicle_Damage']=train['Vehicle_Damage'].map(a)\n\n\n\na={'Male':0,'Female':1}\ntest['Gender']=test['Gender'].map(a)\na={'> 2 Years':0, '1-2 Year':2, '< 1 Year':1}\ntest['Vehicle_Age']=test['Vehicle_Age'].map(a)\na={'Yes':1,'No':0}\ntest['Vehicle_Damage']=test['Vehicle_Damage'].map(a)\n\nids=test['id']\ntest=test.drop(['id'],axis=1)","86397c6f":"#for i in train.columns:\n#    print(train[i].unique())\n#print(len(train.iloc[:,7].unique()))\n#import seaborn as sns\nlen(train['Vintage'].unique())\n","0016ff23":"train['Vintage'][train['Vintage']<150]=1\ntrain['Vintage'][train['Vintage']>=150]=0","a40deaeb":"\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\n\nos=RandomOverSampler(0.75)\ntrain_new,target_new=os.fit_sample(train,target)\n","e226969c":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(train,target,test_size=0.2,random_state=3)","6f105f02":"import numpy as np\nfrom sklearn.neighbors import LocalOutlierFactor\n#x = np.array([[0,0],[0,1],[1,1],[3,0]])\nclf = LocalOutlierFactor(n_neighbors=20,algorithm='auto',leaf_size=30,metric='minkowski',p=2,metric_params=None)\ny_pred = clf.fit_predict(X_train)\nscores = clf.negative_outlier_factor_\nprint(-scores)","defc890f":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n#y_pred=clf.predict(X_test)\n\nprint(confusion_matrix(y_train,y_pred))\nprint(accuracy_score(y_train,y_pred))\nprint(classification_report(y_train,y_pred))\n","4c36c0b2":"from sklearn.ensemble import IsolationForest\nIsolationForest(n_estimators=100, max_samples=len(X), contamination=outlier_fraction,random_state=state, verbose=0)","609b68df":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\nrfc=RandomForestClassifier()\nrfc.fit(X_train,y_train)\n\n","31ef0b54":"y_pred=rfc.predict(X_test)\n\nprint(confusion_matrix(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\n","6041690d":"train['Vintage'].unique().max()","8de9e08a":"a","b3ee9a35":"from imblearn.combine import SMOTETomek\nos=SMOTETomek(0.75)\nX_train_ns,y_train_ns=os.fit_sample(train,target)\n#print(\"The number of classes before fit {}\".format(Counter(y_train)))\n#print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_train_ns,y_train_ns,test_size=0.4,random_state=3)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\n\n\n\n\n\n#from xgboost import XGBClassifier\n#from sklearn.metrics import accuracy_score\n#lr=XGBClassifier()\n#lr.fit(X_train,y_train)\n","88c7b268":"rfc=RandomForestClassifier()\nrfc.fit(X_train,y_train)\n\n","cfc1b52d":"X_train.columns","2fc3ef90":"feature_imp = pd.Series(rfc.feature_importances_,index=X_train.columns).sort_values(ascending=False)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Creating a bar plot\nsns.barplot(x=feature_imp, y=feature_imp.index)\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","78860008":"cols=['Previously_Insured','Vintage','Age','Vehicle_Damage','Annual_Premium','Policy_Sales_Channel','Region_Code','Gender','Vehicle_Age']\nX_train=X_train[cols]\nrfc1=RandomForestClassifier()\nrfc1.fit(X_train,y_train)","534973a9":"X_test=X_test[cols]","3deb1e49":"y_pred=rfc1.predict(X_test)\n\nprint(confusion_matrix(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","0dcc2c4d":"predictions=rfc.predict_proba(test)[:,1]\n\noutput = pd.DataFrame({'id': ids, 'Response': predictions})\noutput.to_csv('my_submission7.csv', index=False)\nprint(\"Your submission was successfully saved!\")","725d90e4":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test,y_pred)","40eed47e":"pr=rfc.predict(test)\n\n\n\noutput = pd.DataFrame({'id': ids, 'Response': pr})\noutput.to_csv('my_submission3.csv', index=False)\nprint(\"Your submission was successfully saved!\")","321c6428":"from sklearn.metrics import roc_auc_score\nns_auc = roc_auc_score(y_test,pred)\nns_auc","c871e9e2":"from sklearn.metrics import confusion_matrix\nns_auc = confusion_matrix(y_test,pred)","d4924f9f":"ns_auc","40c451f2":"#true positive rate or sensitivity or recall\nns_auc[0][0] \/ (ns_auc[0][0] + ns_auc[1][0])","50d45fee":"#true negatice rate or inverted specificity\nns_auc[0][1] \/ (ns_auc[0][1] + ns_auc[1][1])","aeac63fc":"print(\"no with labels as 0\",len(target)-target.sum())\nprint(\"no wth label as 1\",target.sum())","1999af6e":"target.sum()\/(len(target)-target.sum())","84ded692":"# **Python Code **","5d03790c":"# **SMOTETOMEK**","9954d093":"# **Oversampling**","48657255":"# **Data Stats **\n"}}