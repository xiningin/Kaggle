{"cell_type":{"de78be7d":"code","e9943fd0":"code","c64a013b":"code","b236ea56":"code","baf7fb25":"code","2a6ce33b":"code","bf6a9c3e":"code","9cc217f5":"code","3bd9334b":"code","a1d40eb6":"code","e7b144d6":"code","df4dde10":"code","bf5fb5ca":"code","d786cbd2":"code","603460e0":"code","e20e8dd4":"code","e87c387e":"code","f4824162":"code","0d81b1d8":"code","970aa18c":"code","cd1481e4":"code","d0ec456e":"code","69376281":"code","4300a066":"code","c01284a0":"code","72c360ac":"code","f8664fc5":"code","b5f501b0":"code","8943d34b":"code","f55fd46f":"code","15e4e2ba":"code","f2207628":"code","08df0bde":"code","16e3852e":"code","004306f5":"code","7cec09d6":"code","43254592":"code","ccb92c25":"code","6c9643b8":"code","7f49531c":"code","8bbb9b81":"code","73a00ec5":"code","10ba4b42":"code","8b1caf12":"code","85f3517b":"code","722d2f24":"code","fa645fa0":"code","a8e359b6":"code","0c9bc727":"markdown","bd499ab0":"markdown","8816e6c1":"markdown","34d5b9dc":"markdown","8073cc60":"markdown","4fa3315c":"markdown"},"source":{"de78be7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e9943fd0":"train=pd.read_csv(r\"\/kaggle\/input\/fake-news\/train.csv\")\ntest=pd.read_csv(r\"\/kaggle\/input\/fake-news\/test.csv\")","c64a013b":"train.head(10)","b236ea56":"test.head()","baf7fb25":"###Drop Nan Values\ntrain=train.dropna()\n","2a6ce33b":"## Get the Independent Features\n\nX=train.drop('label',axis=1)","bf6a9c3e":"## Get the Dependent features\ny=train['label']","9cc217f5":"X.shape","3bd9334b":"y.shape","a1d40eb6":"\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","e7b144d6":"\n### Vocabulary size\nvoc_size=5000","df4dde10":"messages=X.copy()","bf5fb5ca":"messages['title'][1]","d786cbd2":"messages.reset_index(inplace=True)","603460e0":"import nltk\nimport re\nfrom nltk.corpus import stopwords","e20e8dd4":"nltk.download('stopwords')","e87c387e":"### Dataset Preprocessing\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\n\ndef data_preprocessing(messages):\n    corpus = []\n    for i in range(0, len(messages)):\n    \n        review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n        review = review.lower()\n        review = review.split()\n    \n        review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n        review = ' '.join(review)\n        corpus.append(review)\n        #corpus\n    return [one_hot(words,voc_size)for words in corpus] \n\n\nonehot_repr=data_preprocessing(messages)","f4824162":"\n#onehot_repr","0d81b1d8":"sent_length=20\ndef embedding_representation(onehot_repr):\n    \n    embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n    return embedded_docs\n\nembedded_docs=embedding_representation(onehot_repr)\n","970aa18c":"embedded_docs[0]","cd1481e4":"from tensorflow.keras.layers import Dropout\n\n#create model\n\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n    \n","d0ec456e":"print(model.summary())","69376281":"len(embedded_docs),y.shape","4300a066":"\nimport numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","c01284a0":"\nX_final.shape,y_final.shape","72c360ac":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","f8664fc5":"### Finally Training\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","b5f501b0":"y_pred=model.predict_classes(X_test)","8943d34b":"from sklearn.metrics import confusion_matrix","f55fd46f":"\nconfusion_matrix(y_test,y_pred)","15e4e2ba":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","f2207628":"test.head()","08df0bde":"test_messages=test.copy()\ntest_messages = test_messages.fillna(' ')\n","16e3852e":"test_messages['title'].head()","004306f5":"test_messages['title'].isnull().sum()","7cec09d6":"len(test_messages['title'])","43254592":"test_messages.reset_index(inplace=True)","ccb92c25":"test_onehot_repr=data_preprocessing(test_messages)","6c9643b8":"test_embedded_docs=embedding_representation(test_onehot_repr)","7f49531c":"test_embedded_docs","8bbb9b81":"\ntest_final=np.array(test_embedded_docs)","73a00ec5":"test_final","10ba4b42":"model_prediction = model.predict_classes(test_final)","8b1caf12":"model_prediction=model_prediction.ravel()","85f3517b":"model_prediction","722d2f24":"submission = pd.DataFrame({'id':test_messages['id'], 'label':model_prediction})\nsubmission.shape","fa645fa0":"submission.head()","a8e359b6":"submission.to_csv('submit.csv', index = False)","0c9bc727":"# Test Data Prediction","bd499ab0":"## Embedding Representation","8816e6c1":"## Creating model","34d5b9dc":"## Onehot Representation","8073cc60":"\n# Performance Metrics And Accuracy","4fa3315c":"## Model Training"}}