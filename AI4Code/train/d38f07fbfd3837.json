{"cell_type":{"77a996dc":"code","036bd9a5":"code","fd9591d9":"code","cad6c76c":"code","55cf32ec":"code","a4a61de0":"code","756931b4":"code","9468490d":"code","910e0021":"code","f6ef079b":"code","7d15e49f":"code","28f50db4":"code","338848cd":"code","172f7481":"code","105f16b5":"code","eab9a85d":"code","2368ee7b":"code","3ce98342":"markdown","481259f6":"markdown","46521c3c":"markdown","d7ca821d":"markdown","83aca5fd":"markdown","ad5a1b14":"markdown","6a7d05de":"markdown","5cff6ceb":"markdown","3a4b8fd6":"markdown","04ecd923":"markdown","4db4e595":"markdown","06262fe5":"markdown","d6966f60":"markdown","678339c7":"markdown","39de774f":"markdown","e95d64b7":"markdown","710a34f5":"markdown","2f160791":"markdown"},"source":{"77a996dc":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#ignore warning messages\nimport warnings\nwarnings.filterwarnings('ignore')\nimport plotly\nplotly.offline.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom wordcloud import WordCloud\ndf= pd.read_csv(\"..\/input\/trump-tweets\/trumptweets.csv\")","036bd9a5":"df.head()","fd9591d9":"df.drop(['id','link'],axis=1,inplace=True)\ndf.shape","cad6c76c":"year=[]\nmonth=[]\ndate=[]\nhour=[]\nminute=[]\nsecond=[]\nfor x in df['date']:\n    year.append(int(x.split(\"-\")[0]))\n    month.append(int(x.split(\"-\")[1]))\n    date.append(int(x.split(\"-\")[2].split(\" \")[0]))\n    hour.append(int(x.split(\"-\")[2].split(\" \")[1].split(\":\")[0]))\n    minute.append(int(x.split(\"-\")[2].split(\" \")[1].split(\":\")[1]))\n    second.append(int(x.split(\"-\")[2].split(\" \")[1].split(\":\")[2]))\n\ndf['year']=year\ndf['month']=month\ndf['dates']=date\ndf['hour']=hour\ndf['minute']=minute\ndf['second']=second\ndf.drop(['date'],axis=1,inplace=True)","55cf32ec":"import re\ncontent=[]\nfor tweet in df[\"content\"]:\n    content.append(re.sub('\\@\\S+','',tweet))","a4a61de0":"# loading stop words from nltk library\nimport nltk\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\ndef preprocessing(total_text, index, column):\n    if type(total_text) is not int:\n        string = \"\"\n        #Removing link\n        url_pattern = r'((http|ftp|https):\\\/\\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:\/~\\+#]*[\\w\\-\\@?^=%&amp;\/~\\+#])?'\n        total_text = re.sub(url_pattern, ' ', total_text)\n        # replace every special char with space\n        #total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', total_text)\n        # replace multiple spaces with single space\n        total_text = re.sub('\\s+',' ', total_text)\n        #total_text=total_text.replace('realdonaldtrump','').replace('donald','').replace('trump','')\n        # converting all the chars into lower-case.\n        total_text = total_text.lower()\n        \n        for word in total_text.split():\n        # if the word is a not a stop word then retain that word from the data\n            if not word in stop_words:\n                word=(word)\n                string += word + \" \"\n        \n        df[column][index] = string\n\nfor index, row in df.iterrows():\n    if type(row['content']) is str:\n        preprocessing(row['content'], index, 'content')","756931b4":"Category=df['hour'].value_counts().sort_index()\ndata = [go.Pie(\n        labels = Category.index,\n        values = Category.values,\n        hoverinfo = 'label+value',\n)]\nplotly.offline.iplot(data, filename='active_category')","9468490d":"year_country = df['year'].value_counts().reset_index(name='counts')\n\nfig = px.bar(year_country, x='index', y='counts',\n             hover_data=['index', 'counts'], color='counts',\n             labels={'label':'year v\/s number'}, height=400)\nfig.show()","910e0021":"Category=(df['year'].value_counts()\/365).sort_index()\nCategory\n\nfrom plotly.subplots import make_subplots\ntrace1=go.Scatter(x=Category.index,y=Category.values,mode='lines+markers',name='average tweet in a day')\ndata=[trace1]\nlayout = go.Layout(title=\"\", height=500,width=900, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data,layout=layout)\nfig.show()","f6ef079b":"print(df.iloc[df['retweets'].idxmax()]['content'])\nprint(df.iloc[df['retweets'].idxmax()]['year'])","7d15e49f":"print(df.iloc[df['favorites'].idxmax()]['content'])\nprint(df.iloc[df['favorites'].idxmax()]['year'])","28f50db4":"from collections import Counter\nimport re\nmention_df=df.dropna(subset=[\"mentions\"])\nmentions=[]\nfor x in mention_df[\"mentions\"]:\n    x=x.replace(\"@\",\"\")\n    #x=re.sub(r'[\\s]+',' ',)\n    if not x.strip()==\"\":\n        mentions.append(x)\n\nTop_ten_mentions=Counter(mentions).most_common(10)\n\nname=[]\nnumber=[]\nfor x in Top_ten_mentions:\n    name.append(x[0])\n    number.append(x[1])\n\nfig = go.Figure(data=[go.Bar(x=name, y=number)])\n\nfig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title_text='Number v\/s name mentions')\nfig.show()","338848cd":"president_date=president_year=df[((df['year']>=2017) &(df['month']>1))]\nprint(df.iloc[president_date['favorites'].idxmax()]['content'])\nprint(df.iloc[president_date['favorites'].idxmax()]['year'])","172f7481":"president_date=president_year=df[((df['year']>=2017) &(df['month']>1))]\nprint(df.iloc[president_date['retweets'].idxmax()]['content'])\nprint(df.iloc[president_date['retweets'].idxmax()]['year'])","105f16b5":"business_year=df[((df['year']<=2017))]\nfrom sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer().fit(business_year['content'])\nbag_of_words = vec.transform(business_year['content'])\nsum_words = bag_of_words.sum(axis=0) \nwords_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\nimport squarify\n\ny =dict(words_freq[:30])\n\nfig = plt.figure(figsize=(15, 15))\nsquarify.plot(sizes = y.values(), label = y.keys(), color=sns.color_palette(\"RdGy\", n_colors=20),\n             linewidth=4, text_kwargs={'fontsize':14, 'fontweight' : 'bold'})\nplt.title('Top 30 words', position=(0.5, 1.0+0.03), fontsize = 20, fontweight='bold')\nplt.axis('off')\nplt.show()","eab9a85d":"compain_year=df[(df['year'] == 2016) & (df['month'] >5) | (df['year'] == 2017) &(df['month']==1)]\nfrom sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer().fit(compain_year['content'])\nbag_of_words = vec.transform(compain_year['content'])\nsum_words = bag_of_words.sum(axis=0) \nwords_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\nimport squarify\n\ny =dict(words_freq[:30])\n\nfig = plt.figure(figsize=(15, 15))\nsquarify.plot(sizes = y.values(), label = y.keys(), color=sns.color_palette(\"RdGy\", n_colors=20),\n             linewidth=4, text_kwargs={'fontsize':14, 'fontweight' : 'bold'})\nplt.title('Top 30 words', position=(0.5, 1.0+0.03), fontsize = 20, fontweight='bold')\nplt.axis('off')\nplt.show()","2368ee7b":"president_year=df[((df['year']>=2017) &(df['month']>1))]\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer().fit(president_year['content'])\nbag_of_words = vec.transform(president_year['content'])\nsum_words = bag_of_words.sum(axis=0) \nwords_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\nimport squarify\n\ny =dict(words_freq[:30])\n\nfig = plt.figure(figsize=(15, 15))\nsquarify.plot(sizes = y.values(), label = y.keys(), color=sns.color_palette(\"RdGy\", n_colors=20),\n             linewidth=4, text_kwargs={'fontsize':14, 'fontweight' : 'bold'})\nplt.title('Top 30 words', position=(0.5, 1.0+0.03), fontsize = 20, fontweight='bold')\nplt.axis('off')\nplt.show()","3ce98342":"#### 2.3 preprocessing of tweet text\n* remove url","481259f6":"# Trump Tweet Ananlysis\n## Table of content\n* 1.Reading csv\n* 2.Preprocessing\n    * 2.1 Extracting the year,month,dates,hour,minute,second from date coloumn\n    * 2.2 Removing tag names from tweets\n    * 2.3 preprocessing of tweet text\n* 3.Most active hour on twitter\n* 4. Number of tweet \n* 5.Average number of tweet in a day\n* 6.Most retweeted tweet\n* 7.Most Like tweets\n* 8.Most liked tweet durning Presidential year\n* 9.Most retweeted tweet durning presidential year\n* 10.Word priority\n  * 10.1 Business year\n  * 10.2 compain year\n  * 10.3 presidential year","46521c3c":"#### 11.2 Durning election campaign","d7ca821d":"#### 11.3 Durning presidentail year","83aca5fd":"### 11.Word priority","ad5a1b14":"### 1. Reading csv","6a7d05de":"### 4. Number of tweet ","5cff6ceb":"#### 2.2. Removing tag names from tweets","3a4b8fd6":"#### 11.1 Durning Business Year","04ecd923":"\n### 3. Most active hour on twitter","4db4e595":"### 6.Most retweeted tweet","06262fe5":"### 5.Average number of tweet in a day per year","d6966f60":"### 8.Most tag names from tweets","678339c7":"### 7.Most Like tweets ","39de774f":"### 2.Preprocessing","e95d64b7":"### 10.Most retweeted tweet durning presidential year","710a34f5":"#### 2.1 Extracting the year,month,dates,hour,minute,second from date coloumn","2f160791":"### 9.Most liked tweet durning Presidential year"}}