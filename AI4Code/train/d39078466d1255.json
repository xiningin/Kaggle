{"cell_type":{"c710feb6":"code","add3f92d":"code","f139b143":"code","ab032a16":"code","9c6bba03":"code","5f557977":"code","24367b05":"code","43d383e7":"code","e3acf2b1":"code","e8587b1e":"code","0ea4df2a":"code","ac152607":"code","08b637af":"code","46d8806d":"code","eeed7017":"code","a7b9af5e":"code","e2a0754c":"code","c90b3dff":"code","f64a8fbb":"code","2462fb4d":"code","bdae13bf":"code","ea2eff6d":"markdown","8596e377":"markdown","38ee4310":"markdown","ad887944":"markdown","28109f29":"markdown","af07f239":"markdown","8936a50e":"markdown","33741913":"markdown","b29f6974":"markdown","da67c924":"markdown","01e9ff36":"markdown","427f6443":"markdown","88f0b1df":"markdown","ce8aa826":"markdown","7a391973":"markdown","c343119a":"markdown","f25323be":"markdown","7d00f523":"markdown","499bd8e1":"markdown","4f1271f6":"markdown","4670635c":"markdown","65d2448d":"markdown","9097d402":"markdown","00ae279b":"markdown","a2700311":"markdown"},"source":{"c710feb6":"import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD\nfrom torch.utils.data.dataset import Dataset\nfrom torchvision import transforms as T\nfrom torch.utils.data import DataLoader\nimport torch\nfrom torch import optim\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport cv2\nfrom PIL import Image\nimport time\nfrom copy import deepcopy\nimport tarfile","add3f92d":"random_seed = 42\ntorch.backends.cudnn.enDatasetable = False\ntorch.manual_seed(random_seed)","f139b143":"def copy(SHARE=0.1, path=\"classification_dataset\/train_\/\", moveto=\"classification_dataset\/test_\/\"):\n    \n    '''copy files from one directory to other one with size proportion '''\n\n    files = os.listdir(path) # find list of all files\n    random_list = np.random.choice(files, int(len(files) * SHARE), replace=False) # take random files\n    random_list.sort() # sort data\n    for f in random_list: # iterate and concat file path + file name\n        src = path + f\n        dst = moveto + f\n        shutil.move(src, dst) # move ramdom files to test directory from train\n    # check the num of files copied\n    number_files = len(os.listdir(moveto))\n    print(number_files)\n\n# RUN ONLY ONE TIME on your local machine and set paths before (create folders)\n# copy(SHARE=0.2)","ab032a16":"# prepare objects \ntrain_tar = '..\/input\/ .... train_.tar.xz'\ntest_tar = '..\/input\/ ... test_.tar.xz'\n\n# function to extarct \ndef read_tar_to_array(file):\n    '''Read tar file and convert jpg to array witj cv2.\n    From file name extarct labels and convert into array'''\n    # Source https:\/\/www.kaggle.com\/gbonesso\/deep-learning-cnn#Extract-images-and-labels-from-images-in-tar.gz-file\n    tar = tarfile.open(file, \"r:xz\")\n    # lists to store\n    image_list = []\n    label_list = []\n    # iterate over tar file\n    for tarinfo in tar:\n        tar.extract(tarinfo.name) # creare an object with tar info\n        if(tarinfo.name[-4:] == '.jpg'): # select only jpg files\n            image_list.append(Image.open(tarinfo.name).convert(\"RGB\"))\n#             image_list.append(np.array(cv2.imread(tarinfo.name, cv2.IMREAD_COLOR))) # transfrom with cv2 photo fils into arrays\n            label_list.append(tarinfo.name.split('_\/')[1]) # split lables from file names \n\n# # You may need it if you run on your local comp \n#         \"if(tarinfo.isdir()):\n#             os.rmdir(tarinfo.name) # check is name exist\n#         else:\n#             os.remove(tarinfo.name)\"\n\n    tar.close() #close tar\n    labels = np.array([i.split('_', 1)[0] for i in label_list]) # slit one more time and covert to array \n    \n    return image_list, labels\n\n# convert tar arhive file into PIL obj, extract labels\n#test_img, test_labels = read_tar_to_array(test_tar)\n#train_img, train_labels = read_tar_to_array(train_tar)\n\n# check the lenght of the train test files\n#len(test_img), len(test_labels), len(train_img), len(train_labels)","9c6bba03":"class BrazillianCoins(Dataset):\n    \n    def __init__(self, root_dir):\n        \n        \"\"\" Data set class for images with tranforming, resizing and preparing them to feed CNN by Torch lib\"\"\"\n        \n        # tranform img. Could be 128 * 96 (as 460 to 380 pic size)\n        self.transforms = T.Compose([T.Resize((128, 128)), T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]) \n        # set the root dir path\n        self.data = os.listdir(root_dir)\n        # save direct root path\n        self.root_dir = root_dir\n                \n    def __getitem__(self, idx):\n        # dict for target\n#         class_dic = {'5':0, '10':1, '25':2, '50':3, '100':4, '85': 5, '20':6} \n        class_dic = dict(list(zip( list(map(str,list(range(5, 180, 5)))),range(0, 35)))) # generate dict for 35 classes \n        # file by index for getitem\n        filename = self.data[idx] \n        # img path for iterate\n        img_path = os.path.join(self.root_dir + filename) \n        # tranform img to grayscale\n        img = Image.open(img_path).convert(\"RGB\") # ot 'L'\n        # get label from filename spit \n        label = filename.split('_')[0] \n        # class selector\n        target = class_dic[label]\n        # apply transformations\n        img = self.transforms(img) \n        \n        return img, target\n    \n    def __len__(self):\n        return len(self.data)","5f557977":"# init train instance regression_dataset\ntrain = BrazillianCoins(root_dir='..\/input\/br-coins\/classification_dataset\/all\/') # 3K pictures\ntest = BrazillianCoins(root_dir='..\/input\/br-coins\/regression_sample\/regression_sample\/') # 900 pictures","24367b05":"(train[0][0]).size(), (test[0][0]).size(), train[0][1]","43d383e7":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\nimshow(train[0][0])","e3acf2b1":"class CNN(nn.Module):\n    \n    def __init__(self, kernels=[3, 3], poolings=[2, 2], channels=[3, 16, 32], \n               paddings=[2, 2], strides=[2, 2], linear_sizes=[32, 32]):\n        \"\"\"\n          Define your NN here.\n          Args:\n            kernels: default [3, 3]. \n              Defines kernel size for each of two convolutional layers.\n              Kernel's width equals its height.\n            poolings: default [2, 2].\n              Deifnes kernel size for each of two pooling layers.\n            channels: default [32, 64]. \n              Defines amount of output channels for each of two convolutional layers.\n            padding: default [1, 1]. \n              Defines padding size for each of two convolutional layers.\n            strides: default [2, 2]. \n              Defines stride size for each of two convolutional layers.\n            linear_sizes: default [32, 32]. \n              Defines layer size for each of fully-connected layers.\n        \"\"\"\n        super(CNN, self).__init__()\n        self.kernels = kernels\n        self.channels = channels\n        self.paddings = paddings\n        self.strides = strides\n        self.max_pooling = poolings\n        self.linear_sizes = linear_sizes\n        self.relu = F.relu\n\n        \"\"\" set CNN structure \"\"\"\n        # set firest 2d layers\n        self.layer_2d_0 = nn.Conv2d(in_channels=self.channels[0], out_channels=self.channels[1], \\\n                      kernel_size=self.kernels[0], stride=self.strides[0], padding=self.paddings[0])\n        # set max pooling\n        self.max_1 = nn.MaxPool2d(self.max_pooling[0])\n         # set firest 2d layers\n        self.layer_2d_1 = nn.Conv2d(in_channels=self.channels[1], out_channels=self.channels[2], \\\n                      kernel_size=self.kernels[1], stride=self.strides[1], padding=self.paddings[1])\n        # set max pooling\n        self.max_2 = nn.MaxPool2d(self.max_pooling[1])\n        # set linear layers \n        self.layer_1 = nn.Linear(in_features=2048, out_features=128, bias=True)\n        self.layer_2 = nn.Linear(in_features=128, out_features=35, bias=True) # 35 classes\n        # flatter layer\n        self.flatten = nn.Flatten(start_dim=1, end_dim=-1) # or we can use .view\n        self.dropout = nn.Dropout(0.5) \n\n        \"\"\" Workflow for hight and wigth and channels for img \n        m1 = 128 - 3 +1 +2 \/ 2 = 64 (64*64, 3 channel)\n        max_pool = 64\/2 = 32 (32*32, 16 channel)\n        m2 = 32 - 3 +1 +2 \/ 2 = (16*16, 32 channel)\n        max_pool = 16\/2 = 8\n        flattern = [8*8*32] = 2048 neurons\n        linear1 = [2048, 128] neurons, size pict\n        linear2 = [128, 35] classs\n        \"\"\"\n\n    def forward(self, X):\n        \"\"\"\n          Forward propagation of your NN.\n\n          Args:\n            X: imput data\n          Returns\n            outputs: nn's output (logits)\n        \"\"\"\n        # First convolution layer\n        a = self.max_1(self.relu(self.layer_2d_0(X)))\n        # second conv layer\n        b = self.max_2(self.relu(self.layer_2d_1(a)))\n        # flatter layer before linear layers\n        c = b.view(-1, 2048) # or flatter self.flatten(X)\n        # dropout\n        d = self.dropout(c)\n        # first linear layer\n        i = self.layer_1(d)\n        # dropout\n        f = self.dropout(i)\n        # second lineat layer\n        logits = self.layer_2(f)\n        # Softmax probs with logits\n        probs = F.softmax(logits, dim=1)\n        \n        return logits, probs ","e8587b1e":"# set your batch size \nbatch_size = 512\n\n# load train and test into Pytorch format (tensors)\ntrain_ = DataLoader(train, batch_size=batch_size, shuffle=True)\ntest_ = DataLoader(test, batch_size=batch_size, shuffle=True)\n\n# Create dict for selectors\nloaders = {'train' : train_, 'test': test_}\nsizes = {'train': len(train), 'test': len(test)}","0ea4df2a":"# our class instance\nmodel = CNN()\n# CUDA - for ones who can run on his local machine\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# transfer model to device\nmodel.to(device)","ac152607":"# test with one image \ntest_img = train[0][0] # by index 0\ntest_img = test_img.unsqueeze(0)\n\nlogits, probs = model.forward(test_img)\ndisplay('Logits of the last linear layer {} \\n with probability {} of class'.format(logits, probs))","08b637af":"class FCNN(nn.Module):\n    '''Fully connected NN'''\n    \n    def __init__(self, hidden_sizes=[64, 64]):\n        \"\"\"\n          Define your NN here. \n\n          Args:\n            hidden_sizes: default [64, 64]. \n              Defines layer size for each of hidden layers (layer between input layer\n              and output layer).\n        \"\"\"\n        super(FCNN, self).__init__()\n        self.activation = F.relu\n        self.hidden_size = hidden_sizes\n        self.input = nn.Linear(in_features=49152, out_features=self.hidden_size[0]) # 128 * 128 * n channel\n        self.hidden = nn.Linear(in_features=self.hidden_size[0], out_features=self.hidden_size[1])\n        self.hidden_0 = nn.Linear(in_features=self.hidden_size[0], out_features=self.hidden_size[1])\n        self.output = nn.Linear(in_features=self.hidden_size[1], out_features=35) # 35 classes\n\n    def forward(self, X):\n        \"\"\"\n          Forward propagation of your NN.\n\n          Args:\n            X: imput data\n          Returns\n            output: nn's output (logits)\n            probs: probabilities of classes by softmax function\n        \"\"\"\n    \n    def forward(self, X):\n        # input # z = W*X + b  \n        x = X.view(-1, 49152) # channals * with * lengh\n        x = self.input(x)       \n        a = self.activation(x) # a = f(z)\n        \n        # First z1 = W*A + b\n        z = self.hidden(a) \n        a = self.activation(z) # a1 = f(z1)\n        \n        # Second \n        z = self.hidden_0(a)\n        a = self.activation(z) # a1 = f(z1)\n        \n        # out \n        logits = self.output(a) # output = w*a1 + b\n        probs = F.softmax(logits, dim=1)\n        \n        return logits, probs","46d8806d":"# intializate model instance \nmodel_f = FCNN()\n# CUDA if you have it\ndevice_f = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# set to device other model\nmodel_f.to(device_f)","eeed7017":"# take any image\ntest_img = train[0][0] # by index 0\ntest_img = test_img.unsqueeze(0)\n\nprobs = model_f.forward(test_img)\ndisplay('Logits of the last linear layer {} \\n with probability {} of class'.format(logits, probs))","a7b9af5e":"def train_model(model, loaders, num_epochs, lr, checkpoint_step=None, eval_step=None): # set our parameters\n     \n    best_model_ = deepcopy(model.state_dict()) # we make copy of each model settings\n    best_acc = 0\n    epoch_acc_list = []\n    epoch_loss_list = []\n    \n    # instances of optimazer and criterion\n    optimizer = SGD(model.parameters(), lr=lr) # As most of NN we use Gradient Desent\n    criterion = nn.CrossEntropyLoss() # It is our loss function, like MSE :)\n    \n    for epoch in range(num_epochs): # we run over epoch.\n        print('Epoch # {}'.format(epoch))\n        now = time.time()  # let us calculate the time - so it is starting point\n        \n        for stage in loaders: # in the begginng we set dict - train and test. now we use them to differ two stage - train and test\n            if stage == 'train': # we use Pytorch methods to train\n                model.train()\n            else:\n                model.eval() # and evaluate results with test data\n            \n            current_loss = 0 # set to zero current (in epoh loss and acuracy)\n            current_acuracy = 0\n            \n            for data, target in loaders[stage]: # for each stage (train, test) we load data with our loaders (see the dicts above)\n                data = data.to(device) # send them to devices - data and target values\n                targets = target.to(device)\n                \n                optimizer.zero_grad() # set out initial weight of the model to zero\n                \n                with torch.set_grad_enabled(stage == 'train'): # check if the stage is Train one\n                      \n                    outputs, probs = model(data) # calculate the logits and probabilities\n                    _, preds = torch.max(outputs, 1) # convert them to value\n                    loss = criterion(outputs, targets) # calculate the loss \n                \n                    if stage == 'train': # backprop as usually in NN and updating weights\n                        loss.backward()\n                        optimizer.step()\n                        \n                    # current acc and loss\n                    current_loss += loss.item() * data.size(0)\n                    current_acuracy += torch.sum(preds == targets.data)\n                    \n                # calculate loss and acc for per epoh \n                epoch_loss = current_loss \/ sizes[stage]\n                epoch_acc = current_acuracy.double() \/ sizes[stage]\n                \n                # add to list \n                epoch_acc_list.append(epoch_acc)\n                epoch_loss_list.append(epoch_loss)\n            \n            # here we set the # of times to save model\n            if epoch % checkpoint_step == 1:\n                torch.save(model.state_dict(), 'train_valid_epoch{}.pt'.format(epoch+1))\n                \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(stage, epoch_loss, epoch_acc))\n            \n            # deep copy of the model with higt accuracy and with # step to eval\n            # The idea is next - is stage is test:\n                # we compare best accuracy (it must grow with each epoch) \n                # and each evalulation step we calculate model perfomance on test set\n            #  We save time by this. And it the end we save best model\n            if stage == 'test' and epoch_acc > best_acc and epoch % eval_step == 0:\n                best_acc = epoch_acc\n                best_model_ = deepcopy(model.state_dict())\n                \n        # time diff\n        time_passed = time.time() - now\n        print('Training complete in {:.0f}m {:.0f}s'.format(time_passed \/\/ 60, time_passed % 60))\n        print('Best val Acc: {:4f}'.format(best_acc))\n        print('----------------------')\n        \n        # load best model with its weights\n        model.load_state_dict(best_model_)\n        \n    return model, epoch_loss_list, epoch_acc_list","e2a0754c":"# run \n# model is CNN, loaders is our data (train and test), lr is learning rate\n# checkpoint_step - how often we save model \n# and eval_step is how often we evaluate it on test set\nmodel_cnn = train_model(model, loaders, num_epochs=5, lr=0.01, checkpoint_step=2, eval_step=3)","c90b3dff":"plt.plot(model_cnn[2], label=['test_loss'])\nplt.plot(model_cnn[1], label=['test_accouracy'])\nplt.ylabel('Values of loss and accuracy')\nplt.title('Loss and accuracy')\nplt.legend(['Accuracy', 'Loss'])\nplt.show();","f64a8fbb":"# linear NN model \nmodel_f = train_model(model_f, loaders, num_epochs=5, lr=0.1, checkpoint_step=2, eval_step=3)","2462fb4d":"plt.plot(model_f[2], label=['test_loss'])\nplt.plot(model_f[1], label=['test_accouracy'])\nplt.ylabel('Values of loss and accuracy')\nplt.title('Loss and accuracy')\nplt.legend(['Accuracy', 'Loss'])\nplt.show();","bdae13bf":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n    class_dic = dict(list(zip( list(map(str,list(range(5, 180, 5)))),range(0, 35))))\n    \n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(loaders['test']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs, preds = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(list(class_dic.keys())[list(class_dic.values()).index(preds[j])]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    \n    return model.train(mode=was_training)\n\nvisualize_model(model_cnn[0])","ea2eff6d":"# Plot the dynamic of loss and accuracy","8596e377":"## Test and compare performance we set other NN class - Linear one","38ee4310":"# Build Convolutional Neural Network (CNN) and Linear Neural Network (LNN) from scratch for image classification in Brazilian coins dataset","ad887944":"# 2. Load data into Kaggle enviroment, Normalize and convert it intoTensor, extract labels.\n\nHere is class for that task","28109f29":"# 1. Load all data on your comp, unzip in one directory. \nUse function to ramdomly split all files into two sub directories (train and test) with certain proportion on your local machine\n\nYou can run on your local machine to randomly split data set at prefered proportion. \n\nYou **do not need to** do it Kaggle!","af07f239":"Here we have received logits (values of CNN before calculating probabilities) and probabilities.\n\nAnd of course it is **random guess,** because we have not train our network yet.\n\nBut model is working and ready.","8936a50e":"### Here we can observe all our settings and check arhitecture of CNN","33741913":"Clearly we see the coin. If it possible for CNN to learn what coin it is? (5, 10 or 25 cents)","b29f6974":"### Check shapes of instances and target \nWe select first photo. They are tensors already","da67c924":"### Here we set initial values and instances inherited from DataLoader Pytorch class","01e9ff36":"### Use can use tar files in Kaggle input directory to work directly with zipped files\nBut it did not work well for me, so I use unzipped version","427f6443":"### Initiate the model and test it with one picture","88f0b1df":"We select kernel (2 x 2), change channels during convolutional layers, set pooling, padding, strides.","ce8aa826":"### Let us test this model (linear) as well\n\nAnd it is also random guess - we just check the class ","7a391973":"So our arhitecture is like this:\n* 1 Convolutional layer + relu + max pooling\n* 2 Convolutional layer + relu + max pooling\n* layer to transform results into one vector (with size 2048)\n* Dropout\n* Fully connected\n* Dropout\n* Fully connected\n* Calculate probabilities\n\n> In the class you may find how we calculated output size (2048 neurons) - see ''' Workflow .. '''","c343119a":"## Let us run Linear model ","f25323be":"### Plot the graph again","7d00f523":"# 8. Conclusion\n\nWriting models for neural networks requires good topic knowledge, even for ready-made libraries as Pytorch.\n\nHere, the researcher has a large number of opportunities and this, in turn, is a significant challenge.\n\nAlthough the results of both models are far from ideal, we can already make a comparison - a linear model (unexpectedly), showed a little better results (0.29 LNN accuracy versus 0.17 CNN)\n\nWith bigger data-set (and more computation power) + more accurate network tuning, the accuracy of the CNN, i suppose, might be higher. \n\nAnd of course we can get more accuracy for both models if we adjust the learning speed, layers, sizes of batches and other model parameters in more detail. \n\nFor such experiments, we will need additional kaggle resources (like GPU), which I plan to use for other tasks.\n\nThank you for your time, I will be happy to answer questions and I would be grateful if you find errors or suggest how to improve the model\/code.","499bd8e1":"### Notice that we need to set different setting for Linear NN \n\n49152 neurons input layer - because we need to multiply channels and picture size (we set them to 128 x 128 in 1 steps)","4f1271f6":"# 3. Create class from *torch.utils.data.Dataset* module","4670635c":"### Let us see how the picture looks like","65d2448d":"## How well CNN model performed?\n\nlet us try to find photo of one class","9097d402":"### Again we may check our settings\n\nWe can see clear difference from the first model","00ae279b":"## Task is classify what is shown on the photo - 5, 10, 25, 50 or 100 cent coin?\n\nIf there is several coins on one photo, task is classify the other possible classes (altogether 35 classes)\n\n### Plan \n1. Optional. Load all data on your comp, unzip in one directory. \nUse function to ramdomly split all files into two sub directories (train and test) with certain proportion on your local machine.\n2. Load tar data into Kaggle enviroment, convert it into numpy array, extract labels.\n3. Create class from *torch.utils.data.Dataset*.a\n4. Load you data with class.\n5. Build class of *CNN* and LNN.\n6. Train network with train dataset and validate on test one. We save model in training loop each *n* epochs.\n7. Plot results.\n8. Conclusion.\n\nUseful links from Pytorch:\n  * [Creating and loading your own dataset](https:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html)\n  * [Convolutional layer in Pytorch](https:\/\/pytorch.org\/docs\/stable\/nn.html#conv2d)\n","a2700311":"# 6. Train network with train dataset and validate on test one. We save model in training loop each *n* epochs.\n\nHere is function to iterate over our models. \n\nIt is bit complicated and took me a lot of time to run correctly. I will try to explain what every line of code does.\n\nFor mode information you may go to the Pytorch tutorials, especially this one https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html"}}