{"cell_type":{"ce3b8cca":"code","03375a6f":"code","9d2f76ef":"code","38f13d6c":"code","6dc3ba9d":"code","a72b6cf4":"code","29bf3da6":"code","fa9347cd":"code","030d5211":"code","d599db9b":"code","b4cd5dd9":"code","be170d7d":"code","0930b12f":"code","b8218e92":"code","fe363160":"code","8132fb1a":"code","ad94b3dc":"code","4a35ca7d":"code","acf0b9ef":"code","6b611ce5":"code","ce6c480c":"code","b06834d9":"code","a03e3485":"code","6abe8191":"code","b01dc38d":"markdown"},"source":{"ce3b8cca":"# Import Modules\nimport glob\nimport os.path as osp\nimport random\nimport numpy as np\nimport json\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# torch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision\nfrom torchvision import models,transforms","03375a6f":"# set random seed\ntorch.manual_seed(1234)\nnp.random.seed(1234)\nrandom.seed(1234)","9d2f76ef":"# define label to name & name to id\nlabel2name = {\n    'n0':'alouatta_palliata',\n    'n1':'erythrocebus_patas',\n    'n2':'cacajao_calvus',\n    'n3':'macaca_fuscata',\n    'n4':'cebuella_pygmea',\n    'n5':'cebus_capucinus',\n    'n6':'mico_argentatus',\n    'n7':'saimiri_sciureus',\n    'n8':'aotus_nigriceps',\n    'n9':'trachypithecus_johnii',\n}\nname2id = {\n    'alouatta_palliata':0,\n    'erythrocebus_patas':1,\n    'cacajao_calvus':2,\n    'macaca_fuscata':3,\n    'cebuella_pygmea':4,\n    'cebus_capucinus':5,\n    'mico_argentatus':6,\n    'saimiri_sciureus':7,\n    'aotus_nigriceps':8,\n    'trachypithecus_johnii':9,\n}","38f13d6c":"class ImageTransform():\n    '''\n    This is image transform class. This class's action differs depending on the 'train' or 'val'. \n    It resize image size and normarize image color.\n    Attributes\n    -----------\n    resize:int\n        img size after resize\n\n    mean : (R,G,B)\n        average of each channel\n    \n    std : (R,G,B)\n        standard deviation of each channel\n    '''\n    def __init__(self,resize,mean,std):\n        self.data_transform = {\n            'train':transforms.Compose([\n                transforms.RandomResizedCrop(resize,scale=(0.5,1.0)),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize(mean,std)\n            ]),\n            'val':transforms.Compose([\n                transforms.Resize(resize),\n                transforms.CenterCrop(resize),\n                transforms.ToTensor(),\n                transforms.Normalize(mean,std)\n            ])\n        }\n\n    def __call__(self,img,phase='train'):\n        return self.data_transform[phase](img)","6dc3ba9d":"# make data path list\ndef make_datapath_list(phase):\n    rootpath = '\/kaggle\/input\/10-monkey-species\/'\n    target_path = osp.join(rootpath+phase+'\/**\/**\/*.jpg')\n    path_list = []\n    for path in glob.glob(target_path):\n        path_list.append(path)    \n    return path_list","a72b6cf4":"train_list = make_datapath_list(phase='training')\nval_list = make_datapath_list(phase='validation')","29bf3da6":"class Dataset(data.Dataset):\n    '''\n    Attributes\n    -------------\n    file_list:list\n        data path list\n    transform: object\n        ImageTransform object\n    phase: \n        'train' or 'val'\n    '''\n    def __init__(self,file_list,transform=None,phase='train'):\n        self.file_list = file_list\n        self.transform = transform\n        self.phase = phase\n    \n    def __len__(self):\n        return len(self.file_list)\n    \n    def __getitem__(self,index):\n        '''\n        get after preprocessing image tensor and label \n        '''\n        # \n        img_path = self.file_list[index]\n        img = Image.open(img_path) \n\n        # preprocessing\n        img_transformed = self.transform(img,self.phase) # torch.Size([3,224,224])\n\n        # get image label from file name\n        arr = img_path.split('\/')\n        label = arr[-2]\n        name = label2name[label]\n\n        # transform label to number\n        label_num = name2id[name]\n\n        return img_transformed,label_num","fa9347cd":"size = 224\n\n# when we use pretrain models, we should normarize image following mean value and std value.\n# reference : https:\/\/pytorch.org\/docs\/master\/torchvision\/models.html\nmean = (0.485,0.456,0.406)\nstd = (0.229,0.224,0.225)\n\n# make train dataset and val dataset\ntrain_dataset = Dataset(file_list=train_list,transform=ImageTransform(size,mean,std),phase = 'train') \nval_dataset = Dataset(file_list=val_list,transform=ImageTransform(size,mean,std),phase = 'val')","030d5211":"# check move\nindex = 0\nprint(train_dataset.__getitem__(index)[0].size())\nprint(train_dataset.__getitem__(index)[1])","d599db9b":"# define mini batch size\nbatch_size = 32\n\n# make dataloader\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\nval_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n\n# put in dict \ndataloaders_dict = {'train':train_dataloader,'val':val_dataloader}","b4cd5dd9":"# check move\nbatch_iterator = iter(dataloaders_dict['train']) # convert iterator\ninputs,labels = next(batch_iterator) # extract first items\nprint(inputs.size())\nprint(labels)","be170d7d":"# load pretrain VGG-16 model\nuse_pretrained = True # use pretrain parameter\nnet = models.vgg16(pretrained=use_pretrained)\n\n# final output layer \nnet.classifier[6] = nn.Linear(in_features=4096,out_features=10)","0930b12f":"# set train mode\nnet.train()\n\n# set loss\ncriterion = nn.CrossEntropyLoss()\n\n# fine tuning \nparam_to_update_1 = []\nparam_to_update_2 = []\nparam_to_update_3 = []\n\n# learn parameter list\nupdate_param_names_1 = ['features']\nupdate_param_names_2 = ['classifier.0.weight','classifier.0.bias','classifier.3.weight','classifier.3.bias']\nupdate_param_names_3 = ['classifier.6.weight','classifier.6.bias']\n","b8218e92":"# fix parameter\nfor name,param in net.named_parameters():\n    print(name)\n    if update_param_names_1[0] in name:\n        param.requires_grad = True\n        param_to_update_1.append(param)\n    elif name in update_param_names_2:\n        param.requires_grad = True\n        param_to_update_2.append(param)\n    elif name in update_param_names_3:\n        param.requires_grad = True\n        param_to_update_3.append(param)\n    else:\n        param.requires_grad = False","fe363160":"# set optimizer\noptimizer = optim.SGD([\n    {'params':param_to_update_1,'lr':1e-4},\n    {'params':param_to_update_2,'lr':5e-4},\n    {'params':param_to_update_3,'lr':1e-3},\n    ],momentum=0.9)","8132fb1a":"def train_model(net,dataloaders_dict,criterion,optimizer,num_epochs):\n    # init\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    print('use device:',device)\n    net.to(device)\n    \n    # \n    history_train_loss = []\n    history_train_acc = []\n    history_val_loss = []\n    history_val_acc = []\n\n    torch.backends.cudnn.benchmark = True\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1,num_epochs))\n        print('-------------------------------------')\n\n        for phase in ['train','val']:\n            if phase == 'train':\n                net.train()\n            else:\n                net.eval()\n            \n            epoch_loss = 0.0\n            epoch_corrects = 0\n\n            # pick mini batch from dataloader\n            for inputs,labels in tqdm(dataloaders_dict[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # init optimizer\n                optimizer.zero_grad()\n                # calculate forward\n                with torch.set_grad_enabled(phase=='train'):\n                    outputs = net(inputs)\n                    loss = criterion(outputs,labels) # calculate loss\n                    _,preds = torch.max(outputs,1) # predict label\n\n                    # backward (train only)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    \n                    # update loss sum\n                    epoch_loss += loss.item() * inputs.size(0)\n                    # correct answer count \n                    epoch_corrects += torch.sum(preds == labels.data)\n            # show loss and correct answer rate per epoch \n            epoch_loss = epoch_loss \/ len(dataloaders_dict[phase].dataset)\n            epoch_acc = epoch_corrects.double() \/ len(dataloaders_dict[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase,epoch_loss,epoch_acc))\n            if phase == 'train':\n                history_train_loss.append(epoch_loss)\n                history_train_acc.append(epoch_acc)\n            else:\n                history_val_loss.append(epoch_loss)\n                history_val_acc.append(epoch_acc)\n    return history_train_loss,history_train_acc,history_val_loss,history_val_acc\nnum_epochs=10\ntrain_loss,train_acc,val_loss,val_acc = train_model(net,dataloaders_dict,criterion,optimizer,num_epochs=num_epochs)","ad94b3dc":"import matplotlib.pyplot as plt","4a35ca7d":"plt.plot(train_loss)\nplt.plot(val_loss)\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'val'])\nplt.show()","acf0b9ef":"plt.plot(train_acc)\nplt.plot(val_acc)\nplt.title('Model Acc')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'val'])\nplt.show()","6b611ce5":"save_path = '.\/model.pth'\ntorch.save(net.state_dict(),save_path)","ce6c480c":"load_path = '.\/model.pth'\nload_weights = torch.load(load_path)\nnet.load_state_dict(load_weights)","b06834d9":"from sklearn.metrics import classification_report\n\npred = []\nY = []\nX = []\nfor i, (x,y) in enumerate(val_dataloader):\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    net.to(device)\n    x = x.to(device)\n    y = y.to(device)\n    with torch.no_grad():\n        output = net(x)\n    pred += [int(l.argmax()) for l in output]\n    Y += [int(l) for l in y]\n    X += [l.cpu() for l in x]\n\nprint(classification_report(Y, pred,target_names=[v for v in label2name.values()]))","a03e3485":"i=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(Y)):\n    if(Y[i]==pred[i]):\n        prop_class.append(i)\n    if(len(prop_class)==8):\n        break\n\ni=0\nfor i in range(len(Y)):\n    if(Y[i]!=pred[i]):\n        mis_class.append(i)\n    if(len(mis_class)==8):\n        break","6abe8191":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(X[prop_class[count]].numpy().transpose(1,2,0))\n        ax[i,j].set_title(\"Predicted : \"+str(label2name['n{}'.format(pred[prop_class[count]])])+\"\\n\"+\"Actual : \"+str(label2name['n{}'.format(pred[prop_class[count]])]))\n        plt.tight_layout()\n        count+=1","b01dc38d":"# Check Result"}}