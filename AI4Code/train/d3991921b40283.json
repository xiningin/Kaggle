{"cell_type":{"ab3d1c00":"code","1961efcd":"code","446bf532":"code","3d44177d":"code","036fc74d":"code","2133260b":"code","7822d139":"code","e847273b":"code","f260de62":"code","515a9b48":"code","b143c842":"code","7506a123":"code","6af135c8":"code","b1c608f5":"code","d70de362":"code","08df0132":"code","8b013964":"code","6f01158c":"code","f3c062d0":"code","d20efb26":"code","1a50b260":"code","e6d45a25":"code","eebf69e0":"code","b590ae50":"code","6fb55e34":"code","f53e380e":"code","84a22d2c":"code","ea1890b6":"code","8346c2c5":"code","db176379":"code","da6cc519":"code","16bd604c":"code","963e883c":"code","54d6dfa9":"code","28f250bd":"code","d5dfe8d8":"code","19a320bf":"code","cff8dda2":"code","d17b57fe":"code","7297641a":"code","50616b55":"code","afdfb005":"code","2cf67016":"code","8cb2a3f9":"code","a5b129d9":"code","098e86b4":"code","57f91d13":"code","bb26b56f":"code","db3eaebc":"code","f6cc0a8d":"code","bc00a934":"code","b5d1b372":"code","09250157":"code","9f149dc1":"code","5ca40ad0":"code","d99a282a":"code","143c56af":"code","35932a75":"code","b41f0e20":"code","c09e4710":"code","fea07ec4":"code","b4c51097":"code","12ef4cdc":"code","da4d3f6f":"code","285908d6":"code","ea5c3102":"code","4fbfa666":"code","73ec3ae9":"code","1195dcea":"code","d5d49a03":"code","dff8e21b":"markdown","6fc65029":"markdown","e3a59098":"markdown","78fa3609":"markdown","d525ac9a":"markdown","c809c109":"markdown","cfc11e8f":"markdown","810d52aa":"markdown","43b1b26e":"markdown","1d986002":"markdown","783907e7":"markdown","b2761545":"markdown","61d84edb":"markdown","8789cec5":"markdown","b5224076":"markdown","23441898":"markdown","80875c8d":"markdown","9acafd76":"markdown","3a928ab7":"markdown","d87970cc":"markdown","8ddc1ba6":"markdown","f651fbcd":"markdown","d25962a7":"markdown"},"source":{"ab3d1c00":"from numpy.random import seed\nseed(101)\nfrom tensorflow import set_random_seed\nset_random_seed(101)\n\nimport pandas as pd\nimport numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.layers.core import Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","1961efcd":"# Train\n# normal\nprint(len(os.listdir('..\/input\/chest_xray\/chest_xray\/train\/NORMAL')))\n# pneumonia\nprint(len(os.listdir('..\/input\/chest_xray\/chest_xray\/train\/PNEUMONIA')))\n","446bf532":"# Val\n# normal\nprint(len(os.listdir('..\/input\/chest_xray\/chest_xray\/val\/NORMAL')))\n# pneumonia\nprint(len(os.listdir('..\/input\/chest_xray\/chest_xray\/val\/PNEUMONIA')))","3d44177d":"# Test\n# normal\nprint(len(os.listdir('..\/input\/chest_xray\/chest_xray\/test\/NORMAL')))\n# pneumonia\nprint(len(os.listdir('..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA')))","036fc74d":"os.listdir('..\/input\/chest_xray\/chest_xray\/test')","2133260b":"# create a list of files in each folder\ntrain_normal_list = os.listdir('..\/input\/chest_xray\/chest_xray\/train\/NORMAL')\ntrain_pneu_list = os.listdir('..\/input\/chest_xray\/chest_xray\/train\/PNEUMONIA')\nval_normal_list = os.listdir('..\/input\/chest_xray\/chest_xray\/val\/NORMAL')\nval_pneu_list = os.listdir('..\/input\/chest_xray\/chest_xray\/val\/PNEUMONIA')\ntest_normal_list = os.listdir('..\/input\/chest_xray\/chest_xray\/test\/NORMAL')\ntest_pneu_list = os.listdir('..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA')","7822d139":"def assign_pneu_type(x):\n    x = str(x)\n    if 'virus' in x:\n        return 'viral'\n    if 'bacteria' in x:\n        return 'bacterial'","e847273b":"# TRAIN_NORMAL\n# create the dataframe\ndf_train_normal = pd.DataFrame(train_normal_list, columns=['image_id'])\n# delete the entry named .DS_Store\ndf_train_normal = df_train_normal[df_train_normal['image_id'] != '.DS_Store']\n# create a new target column\ndf_train_normal['target'] = 'normal'\n\n# TRAIN_PNEU\n# create the dataframe\ndf_train_pneu = pd.DataFrame(train_pneu_list, columns=['image_id'])\n# delete the entry named .DS_Store\ndf_train_pneu = df_train_pneu[df_train_pneu['image_id'] != '.DS_Store']\n# create a target column that's a copy of the image column\ndf_train_pneu['target'] = df_train_pneu['image_id']\n# apply the function to this target column\ndf_train_pneu['target'] = df_train_pneu['target'].apply(assign_pneu_type)\n\n# VAL_NORMAL\n# create the dataframe\ndf_val_normal = pd.DataFrame(val_normal_list, columns=['image_id'])\n# delete the entry named .DS_Store\ndf_val_normal = df_val_normal[df_val_normal['image_id'] != '.DS_Store']\n# create a new target column\ndf_val_normal['target'] = 'normal'\n\n\n# VAL_PNEU\n# create the dataframe\ndf_val_pneu = pd.DataFrame(val_pneu_list, columns=['image_id'])\n# delete the entry named .DS_Store\ndf_val_pneu = df_val_pneu[df_val_pneu['image_id'] != '.DS_Store']\n# create a target column that's a copy of the image column\ndf_val_pneu['target'] = df_val_pneu['image_id']\n# apply the function to this target column\ndf_val_pneu['target'] = df_val_pneu['target'].apply(assign_pneu_type)\n\n\n# TEST_NORMAL\n# create the dataframe\ndf_test_normal = pd.DataFrame(test_normal_list, columns=['image_id'])\n# delete the entry named .DS_Store\ndf_test_normal = df_test_normal[df_test_normal['image_id'] != '.DS_Store']\n# create a new target column\ndf_test_normal['target'] = 'normal'\n\n\n# TEST_PNEU\n# create the dataframe\ndf_test_pneu = pd.DataFrame(test_pneu_list, columns=['image_id'])\n# delete the entry named .DS_Store\ndf_test_pneu = df_test_pneu[df_test_pneu['image_id'] != '.DS_Store']\n# create a target column that's a copy of the image column\ndf_test_pneu['target'] = df_test_pneu['image_id']\n# apply the function to this target column\ndf_test_pneu['target'] = df_test_pneu['target'].apply(assign_pneu_type)\n","f260de62":"# Concat the dataframes\ndf_data = \\\npd.concat([df_train_normal,df_train_pneu,df_val_normal,df_val_pneu,df_test_normal,\n           df_test_pneu],axis=0).reset_index(drop=True)\n\n# shuffle\ndf_data = shuffle(df_data)\n\ndf_data.shape","515a9b48":"# Check the target distribution\ndf_data['target'].value_counts()","b143c842":"df_data.head()","7506a123":"# Create a new directory\nbase_dir = 'base_dir'\nos.mkdir(base_dir)\n\n\n#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n\n# now we create 3 folders inside 'base_dir':\n\n# train\n    # normal\n    # bacterial\n    # viral\n\n# val\n    # normal\n    # bacterial\n    # viral\n\n\n# create a path to 'base_dir' to which we will join the names of the new folders\n# train_dir\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n# val_dir\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\n\n# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n# Inside each folder we create seperate folders for each class\n\n# create new folders inside train_dir\nnormal = os.path.join(train_dir, 'normal')\nos.mkdir(normal)\nbacterial = os.path.join(train_dir, 'bacterial')\nos.mkdir(bacterial)\nviral = os.path.join(train_dir, 'viral')\nos.mkdir(viral)\n\n\n\n# create new folders inside val_dir\nnormal = os.path.join(val_dir, 'normal')\nos.mkdir(normal)\nbacterial = os.path.join(val_dir, 'bacterial')\nos.mkdir(bacterial)\nviral = os.path.join(val_dir, 'viral')\nos.mkdir(viral)\n","6af135c8":"os.listdir('base_dir\/train_dir')","b1c608f5":"y = df_data['target']\n\ndf_train, df_val = train_test_split(df_data, test_size=0.15, random_state=101, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","d70de362":"# check df_train class distribution\ndf_train['target'].value_counts()","08df0132":"# check df_val class distribution\ndf_val['target'].value_counts()","8b013964":"df_data.head()","6f01158c":"# Set the image_id as the index in df_data\ndf_data.set_index('image_id', inplace=True)","f3c062d0":"# Get a list of images in each of the folders\ntrain_normal_list = os.listdir('..\/input\/chest_xray\/chest_xray\/train\/NORMAL')\ntrain_pneu_list = os.listdir('..\/input\/chest_xray\/chest_xray\/train\/PNEUMONIA')\nval_normal_list = os.listdir('..\/input\/chest_xray\/chest_xray\/val\/NORMAL')\nval_pneu_list = os.listdir('..\/input\/chest_xray\/chest_xray\/val\/PNEUMONIA')\ntest_normal_list = os.listdir('..\/input\/chest_xray\/chest_xray\/test\/NORMAL')\ntest_pneu_list = os.listdir('..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA')\n\n# Get a list of train and val images\ntrain_list = list(df_train['image_id'])\nval_list = list(df_val['image_id'])\n\n# Transfer the train images\n\nfor image in train_list:\n    \n    fname = image\n    label = df_data.loc[image,'target']\n    \n    if fname in train_normal_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/train\/NORMAL', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n    if fname in train_pneu_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/train\/PNEUMONIA', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    \n    if fname in val_normal_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/val\/NORMAL', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    \n    if fname in val_pneu_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/val\/PNEUMONIA', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n        \n    if fname in test_normal_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/test\/NORMAL', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    \n    if fname in test_pneu_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n        \n        \n\n\n# Transfer the val images\n\nfor image in val_list:\n    \n    fname = image\n    label = df_data.loc[image,'target']\n    \n    if fname in train_normal_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/train\/NORMAL', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n    if fname in train_pneu_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/train\/PNEUMONIA', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    \n    if fname in val_normal_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/val\/NORMAL', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    \n    if fname in val_pneu_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/val\/PNEUMONIA', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    \n    if fname in test_normal_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/test\/NORMAL', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    \n    if fname in test_pneu_list:\n        # source path to image\n        src = os.path.join('..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n        \n\n\n","d20efb26":"# check how many train images we have in each folder\n\nprint(len(os.listdir('base_dir\/train_dir\/normal')))\nprint(len(os.listdir('base_dir\/train_dir\/bacterial')))\nprint(len(os.listdir('base_dir\/train_dir\/viral')))","1a50b260":"# check how many val images we have in each folder\n\nprint(len(os.listdir('base_dir\/val_dir\/normal')))\nprint(len(os.listdir('base_dir\/val_dir\/bacterial')))\nprint(len(os.listdir('base_dir\/val_dir\/viral')))","e6d45a25":"\nclass_list = ['normal','bacterial','viral']\n\nfor item in class_list:\n    \n    # We are creating temporary directories here because we delete these directories later\n    # create a base dir\n    aug_dir = 'aug_dir'\n    os.mkdir(aug_dir)\n    # create a dir within the base dir to store images of the same class\n    img_dir = os.path.join(aug_dir, 'img_dir')\n    os.mkdir(img_dir)\n\n    # Choose a class\n    img_class = item\n\n    # list all images in that directory\n    img_list = os.listdir('base_dir\/train_dir\/' + img_class)\n\n    # Copy images from the class train dir to the img_dir e.g. class 'bacterial'\n    for fname in img_list:\n            # source path to image\n            src = os.path.join('base_dir\/train_dir\/' + img_class, fname)\n            # destination path to image\n            dst = os.path.join(img_dir, fname)\n            # copy the image from the source to the destination\n            shutil.copyfile(src, dst)\n\n\n    # point to a dir containing the images and not to the images themselves\n    path = aug_dir\n    save_path = 'base_dir\/train_dir\/' + img_class\n\n    # Create a data generator\n    datagen = ImageDataGenerator(\n        rotation_range=10,\n        width_shift_range=0.05,\n        height_shift_range=0.05,\n        zoom_range=0.05,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\n    batch_size = 50\n\n    aug_datagen = datagen.flow_from_directory(path,\n                                           save_to_dir=save_path,\n                                           save_format='jpg',\n                                                    target_size=(224,224),\n                                                    batch_size=batch_size)\n    \n    \n    # Generate the augmented images and add them to the training folders\n    \n    ###########\n    \n    num_aug_images_wanted = 5000 # total number of images we want to have in each class\n    \n    ###########\n    \n    num_files = len(os.listdir(img_dir))\n    num_batches = int(np.ceil((num_aug_images_wanted-num_files)\/batch_size))\n\n    # run the generator and create augmented images\n    for i in range(0,num_batches):\n\n        imgs, labels = next(aug_datagen)\n        \n    # delete temporary directory with the raw image files\n    shutil.rmtree('aug_dir')","eebf69e0":"# Check how many train images we now have in each folder.\n# This is the original images plus the augmented images.\n\nprint(len(os.listdir('base_dir\/train_dir\/normal')))\nprint(len(os.listdir('base_dir\/train_dir\/bacterial')))\nprint(len(os.listdir('base_dir\/train_dir\/viral')))","b590ae50":"# Check how many val images we have in each folder.\n\nprint(len(os.listdir('base_dir\/val_dir\/normal')))\nprint(len(os.listdir('base_dir\/val_dir\/bacterial')))\nprint(len(os.listdir('base_dir\/val_dir\/viral')))","6fb55e34":"# plots images with labels within jupyter notebook\n# source: https:\/\/github.com\/smileservices\/keras_utils\/blob\/master\/utils.py\n\ndef plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)\/\/rows if len(ims) % 2 == 0 else len(ims)\/\/rows + 1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n        \nplots(imgs, titles=None) # titles=labels will display the image labels","f53e380e":"# End of Data Preparation\n### ===================================================================================== ###\n# Start of Model Building\n","84a22d2c":"train_path = 'base_dir\/train_dir'\nvalid_path = 'base_dir\/val_dir'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\nimage_size = 224\n\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\nval_steps = np.ceil(num_val_samples \/ val_batch_size)","ea1890b6":"train_batches = ImageDataGenerator(\n    preprocessing_function= \\\n    keras.applications.mobilenet.preprocess_input).flow_from_directory(\n                                                    train_path,\n                                                    target_size=(image_size,image_size),\n                                                    batch_size=train_batch_size,\n                                                    class_mode='categorical')\nvalid_batches = ImageDataGenerator(\n    preprocessing_function= \\\n    keras.applications.mobilenet.preprocess_input).flow_from_directory(\n                                                    valid_path,\n                                                    target_size=(image_size,image_size),\n                                                    batch_size=val_batch_size,\n                                                    class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_batches = ImageDataGenerator(\n    preprocessing_function= \\\n    keras.applications.mobilenet.preprocess_input).flow_from_directory(\n                                                    valid_path,\n                                                    target_size=(image_size,image_size),\n                                                    batch_size=val_batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=False)","8346c2c5":"# create a copy of a mobilenet model\n\nmobile = keras.applications.mobilenet.MobileNet()","db176379":"mobile.summary()","da6cc519":"type(mobile.layers)","16bd604c":"# How many layers does MobileNet have?\nlen(mobile.layers)","963e883c":"# CREATE THE MODEL ARCHITECTURE\n\n# Exclude the last 5 layers of the above model.\n# This will include all layers up to and including global_average_pooling2d_1\nx = mobile.layers[-6].output\n\n# Create a new dense layer for predictions\n# 3 corresponds to the number of classes\nx = Dropout(0.25)(x)\npredictions = Dense(3, activation='softmax')(x)\n\n# inputs=mobile.input selects the input layer, outputs=predictions refers to the\n# dense layer we created above.\n\nmodel = Model(inputs=mobile.input, outputs=predictions)","54d6dfa9":"model.summary()","28f250bd":"# We need to choose how many layers we actually want to be trained.\n\n# Here we are freezing the weights of all layers except the\n# last 40 layers in the new model.\n# The last 40 layers of the model will be trained.\n\nfor layer in model.layers[:-40]:\n    layer.trainable = False","d5dfe8d8":"model.compile(Adam(lr=0.001), loss='categorical_crossentropy', \n              metrics=[categorical_accuracy])","19a320bf":"# Get the labels that are associated with each index\nprint(valid_batches.class_indices)","cff8dda2":"# Add weights to try to make the model more sensitive to a specific class\n\nclass_weights={\n    0: 1.0, # bacterial\n    1: 1.0, # normal\n    2: 1.0, # viral\n}","d17b57fe":"filepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_batches, steps_per_epoch=train_steps, \n                              #class_weight=class_weights,\n                    validation_data=valid_batches,\n                    validation_steps=val_steps,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)","7297641a":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","50616b55":"# Here the the last epoch will be used.\n\nval_loss, val_cat_acc = \\\nmodel.evaluate_generator(test_batches, \n                        steps=val_steps)\n\nprint('val_loss:', val_loss)\nprint('val_cat_acc:', val_cat_acc)","afdfb005":"# Here the best epoch will be used.\n\nmodel.load_weights('model.h5')\n\nval_loss, val_cat_acc = \\\nmodel.evaluate_generator(test_batches, \n                        steps=val_steps)\n\nprint('val_loss:', val_loss)\nprint('val_cat_acc:', val_cat_acc)","2cf67016":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training cat acc')\nplt.plot(epochs, val_acc, 'b', label='Validation cat acc')\nplt.title('Training and validation cat accuracy')\nplt.legend()\nplt.figure()","8cb2a3f9":"# Get the labels of the test images.\n\ntest_labels = test_batches.classes","a5b129d9":"# We need these to plot the confusion matrix.\ntest_labels","098e86b4":"# Print the label associated with each class\ntest_batches.class_indices","57f91d13":"# make a prediction\npredictions = model.predict_generator(test_batches, steps=val_steps, verbose=1)","bb26b56f":"predictions.shape","db3eaebc":"# Source: Scikit Learn website\n# http:\/\/scikit-learn.org\/stable\/auto_examples\/\n# model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n# selection-plot-confusion-matrix-py\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","f6cc0a8d":"test_labels.shape","bc00a934":"# argmax returns the index of the max value in a row\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))","b5d1b372":"test_batches.class_indices","09250157":"# Define the labels of the class indices. These need to match the \n# order shown above.\ncm_plot_labels = ['bacterial', 'normal', 'viral']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","9f149dc1":"# Get the filenames, labels and associated predictions\n\n# This outputs the sequence in which the generator processed the test images\ntest_filenames = test_batches.filenames\n\n# Get the true labels\ny_true = test_batches.classes\n\n# Get the predicted labels\ny_pred = predictions.argmax(axis=1)","5ca40ad0":"from sklearn.metrics import classification_report\n\n# Generate a classification report\n\n\nreport = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n\nprint(report)","d99a282a":"# Get the filenames, labels and associated predictions\n\ntest_filenames = test_batches.filenames\ntest_labels = test_batches.classes\npreds = predictions.argmax(axis=1)\n\n","143c56af":"# check the lengths of these lists\nprint(len(test_filenames))\nprint(len(test_labels))\nprint(len(preds))","35932a75":"# Put the above into a dataframe\npred_dict = {'filenames': test_filenames, 'labels': test_labels, 'predictions': preds}\ndf_preds = pd.DataFrame(pred_dict)\n\ndf_preds.head()","b41f0e20":"# get the indices for the labels\ntest_batches.class_indices","c09e4710":"# filter out rows where the label was bacterial (0) and the model predicted viral (2)\ndf_1 = df_preds[(df_preds['labels'] == 0) & (df_preds['predictions'] == 2)]\n\n# reset the index\ndf_1.reset_index(inplace=True, drop=True)\n\ndf_1.head()","fea07ec4":"img_0 = val_dir + '\/' + df_1.loc[0, 'filenames']\nimg_1 = val_dir + '\/' + df_1.loc[1, 'filenames']\nimg_2 = val_dir + '\/' + df_1.loc[2, 'filenames']\nimg_3 = val_dir + '\/' + df_1.loc[3, 'filenames']","b4c51097":"# These are 4 bacterial pneumonia images that the model mis-classified as viral pneumonia.\n\nplt.figure(figsize=(10,10))\n\nplt.subplot(2,2,1)\nplt.imshow(plt.imread(img_0), cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,2,2)\nplt.imshow(plt.imread(img_1), cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,2,3)\nplt.imshow(plt.imread(img_2), cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,2,4)\nplt.imshow(plt.imread(img_3), cmap='gray')\nplt.axis('off')","12ef4cdc":"# Now let's print some true viral pneumonia images\n\ndf_2 = df_preds[(df_preds['labels'] == 2) & (df_preds['predictions'] == 2)]\n\n# reset the index\ndf_2.reset_index(inplace=True, drop=True)\n\ndf_2.head()","da4d3f6f":"img_0 = val_dir + '\/' + df_2.loc[0, 'filenames']\nimg_1 = val_dir + '\/' + df_2.loc[1, 'filenames']\nimg_2 = val_dir + '\/' + df_2.loc[2, 'filenames']\nimg_3 = val_dir + '\/' + df_2.loc[3, 'filenames']\n\nplt.figure(figsize=(10,10))\n\n\nplt.subplot(2,2,1)\nplt.imshow(plt.imread(img_0), cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,2,2)\nplt.imshow(plt.imread(img_1), cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,2,3)\nplt.imshow(plt.imread(img_2), cmap='gray')\nplt.axis('off')\n\nplt.subplot(2,2,4)\nplt.imshow(plt.imread(img_3), cmap='gray')\nplt.axis('off')","285908d6":"# End of Model Building\n### ===================================================================================== ###\n# Convert the Model from Keras to Tensorflow.js\n","ea5c3102":"!pip install tensorflowjs","4fbfa666":"# create a directory to store the model files\nos.mkdir('tfjs_dir')\n\n# convert to Tensorflow.js\nimport tensorflowjs as tfjs\n\ntfjs.converters.save_keras_model(model, 'tfjs_dir')","73ec3ae9":"# check the the directory containing the model is available\n!ls","1195dcea":"# view the files that make up the tensorflow.js model\nos.listdir('tfjs_dir')","d5d49a03":"# Delete the image data directory we created to prevent a Kaggle error.\n# Kaggle allows a max of 500 files to be saved.\n\nshutil.rmtree('base_dir')","dff8e21b":"### Evaluate the model using the val set\u00b6","6fc65029":"### Set Up the Generators","e3a59098":"### Resources","78fa3609":"I think this is where domain knowledge would be very helpful. A radiologist would be able to look at these two sets of images and tell us what is the similarity between them that the model is detecting. \n\n*In bacterial pneumonia, there will likely be a much more visible presence of fluid in the lungs than viral pneumonia.* Is the model predicting bacterial instead of viral because it's seeing signs of fluid or is something else confusing it? It's a mystery.","d525ac9a":"### Plot the Training Curves","c809c109":"### Copy the train images into aug_dir\naug_dir is where we temporarily store images from a given class before feeding them into the generator for augmentation.\u00b6 \n\nWe will not be augmenting on the fly. We will create augmented images, store them in folders together with the raw images and then feed these into the generators. I found that working this way makes the training process run faster. ","cfc11e8f":"**Introduction**\n\nThis model predicts whether or not a child has pneumonia and if so, is it bacterial or viral pneumonia. This kernel is part of an end to end ml solution - starting with a model and ending with a live web app. A user is able to submit a chest x-ray and get an instant prediction. The app was created using Tensorflow.js.\n\n All javascript, html and css files needed to construct the app are available on github.<br>\n\nWeb App: http:\/\/child.test.woza.work\/<br>\nGithub: https:\/\/github.com\/vbookshelf\/Child-Pneumonia-Diagnoser<br>\n\nThis Kaggle dataset was set up as a binary classification problem - pneumonia or no pneumonia. I found that the images had file names containing normal, bacteria or virus so I extracted these and used them as target classes to create a 3 class classification problem - Normal, Viral, Bacterial.\n\nThis solution uses transfer learning applied to a MobileNet model. All training was done in this kernel. MobileNet was designed for the web. It is small (aprox. 35MB) and runs fast. \n\n**Findings**<br>\n\nFrom the resulting confusion matrix and classification report it appears that the model is very good at predicting whether or not pneumonia is present, however it also seems to be more likely to predict bacterial pneumonia than viral pneumonia. Initially I was going to try to reduce this sensitivity to bacterial pneumonia but I decided not to do this. Because bacterial pneumonia is more serious than viral pneumonia I left the model as is.\n\nOne piece of information that would be good to have is an estimate of human level performance on this task. An F1 score of a Radiologist's ability on this dataset would allow a realistic assessment to be made of this model's performance. The developers of [CheXNet](https:\/\/stanfordmlgroup.github.io\/projects\/chexnet\/) used this approach to determine their model's performance. They computed the average F1 score of 4 Radiologists and compared it to CheXNet's F1 score.\n","810d52aa":"### Visualize 50 augmented images","43b1b26e":"### Create a Dataframe containing all images","1d986002":"### Train the Model\u00b6","783907e7":"Many thanks to Paul Mooney for posting this dataset. \n\nThank you for reading.","b2761545":"### Check how many files in each folder\nNote: In some folders there is a non image file called  '.DS_Store'","61d84edb":"### Convert the model\nNote: Do not load a saved model and try to convert it. It will not work.","8789cec5":"### Create Train and Val Sets","b5224076":"### Install Tensorflow.js","23441898":"### Transfer the Images into the Folders","80875c8d":"### Create a Classification Report","9acafd76":"There seems to be many instances where the model found it hard to diffrentiate between bacterial pneumonia images and viral pneumonia images. Is this because these images are similar in some way? Lets print some images and take a look.","3a928ab7":"Excellent tutorial series by deeplizard on how to use Mobilenet with Tensorflow.js<br>\nhttps:\/\/www.youtube.com\/watch?v=HEQDRWMK6yY\n\nTutorial by Minsuk Heo on Accuracy, Precision and F1 Score<br>\nhttps:\/\/www.youtube.com\/watch?v=HBi-P5j0Kec\n\nTutorial by Data School on how to evaluate a classifier<br>\nhttps:\/\/www.youtube.com\/watch?v=85dtiMz9tSo\n\nTensorflow.js gallery of projects<br>\nhttps:\/\/github.com\/tensorflow\/tfjs\/blob\/master\/GALLERY.md\n\n","d87970cc":"### Display Some Incorrect Predictions","8ddc1ba6":"### Create a Confusion Matrix","f651fbcd":"### Modify MobileNet Model","d25962a7":"### Create the directory structure\nThe original dataset directory structure was set up to support a binary classification problem. Because we will be predicting 3 classes we need to change this structure. In these folders we will store the images that will later be fed to the Keras generators."}}