{"cell_type":{"2236cafa":"code","6410ee3b":"code","251d182e":"code","5a1ff8d6":"code","e4c224bc":"code","abf7f6da":"code","794deb95":"code","b271b323":"code","c86111e3":"code","bb828cc7":"code","926b726a":"code","c2d05504":"code","a6daec21":"code","766b1bc0":"code","7892c43c":"code","a921e403":"code","0980a368":"markdown","5d7b7806":"markdown","c5daf614":"markdown","1b58f432":"markdown","192be779":"markdown","69d08df6":"markdown","47290e63":"markdown","8ef64ccd":"markdown","f701a343":"markdown","21bde135":"markdown","5d28ca26":"markdown","0b3b9fd5":"markdown","ffd0b1ea":"markdown","67b20097":"markdown","1c9dfa32":"markdown"},"source":{"2236cafa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6410ee3b":"data = pd.read_csv('..\/input\/brasilian-houses-to-rent\/houses_to_rent.csv')","251d182e":"data.head()","5a1ff8d6":"data.drop('Unnamed: 0',axis = 1 , inplace = True)","e4c224bc":"data['floor'] = data['floor'].replace('-', 0)","abf7f6da":"data ['animal'] = data['animal'].replace('acept', 1)\ndata ['animal'] = data['animal'].replace('not acept', 0)\ndata['furniture'] = data['furniture'].replace('furnished' , 1)\ndata['furniture'] = data['furniture'].replace('not furnished' , 0)","794deb95":"data.drop('hoa',axis = 1 , inplace =True)\ndata.drop('total',axis = 1 , inplace = True)\ndata.drop('property tax',axis = 1 , inplace = True)\ndata.drop('fire insurance',axis = 1 , inplace = True)","b271b323":"import re\ndata['rent amount'] = data['rent amount'].map(lambda x: re.sub(r'\\D+', '', x))\nx = data.drop('rent amount' , axis = 1)\ny = data['rent amount']\nx = x.values\ny = y.values\nx = x.astype(float)\ny = y.astype(float)","c86111e3":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import ExtraTreeRegressor \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error","bb828cc7":"x_train,x_test,y_train,y_test = train_test_split(x , y , test_size = 0.2)","926b726a":"regressor = LinearRegression()\nregressor.fit(x_train,y_train)\ny_pred = regressor.predict(x_test)","c2d05504":"print(\"regressor score in Training\", regressor.score(x_train , y_train))\nrscore = r2_score(y_test,y_pred)\nprint(\"r2score is\", rscore)\nmae = mean_absolute_error(y_test,y_pred)\nprint(\"mean absolute error is\",mae)\nmse = mean_squared_error(y_test,y_pred)\nprint(\"root mean squared error is\",np.sqrt(mse))","a6daec21":"regressor = GradientBoostingRegressor()\nregressor.fit(x_train,y_train)\ny_pred = regressor.predict(x_test)\n#print(\"regressor name\",regressor.__str__)\nprint(\"regressor score in Training\", regressor.score(x_train , y_train))\nrscore = r2_score(y_test,y_pred)\nprint(\"r2score is\", rscore)\nmae = mean_absolute_error(y_test,y_pred)\nprint(\"mean absolute error is\",mae)\nmse = mean_squared_error(y_test,y_pred)\nprint(\"root mean squared error is\",np.sqrt(mse))\n","766b1bc0":"regressor = RandomForestRegressor()\nregressor.fit(x_train,y_train)\ny_pred = regressor.predict(x_test)\n#print(\"regressor name\",regressor.__str__)\nprint(\"regressor score in Training\", regressor.score(x_train , y_train))\nrscore = r2_score(y_test,y_pred)\nprint(\"r2score is\", rscore)\nmae = mean_absolute_error(y_test,y_pred)\nprint(\"mean absolute error is\",mae)\nmse = mean_squared_error(y_test,y_pred)\nprint(\"root mean squared error is\",np.sqrt(mse))","7892c43c":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n","a921e403":"model = Sequential()\nmodel.add(Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(15  ,kernel_initializer = 'normal' , activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(15 , kernel_initializer = 'normal' , activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(15 , kernel_initializer = 'normal' , activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, kernel_initializer='normal' , activation='linear'))\n# Compile model\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\nmodel.fit(x_train , y_train , epochs = 150 , batch_size=5)\ny_pred = model.predict(x_test)\n\nmae = mean_absolute_error(y_test,y_pred)\nprint(\"mean absolute error is\",mae)\nmse = mean_squared_error(y_test,y_pred)\nprint(\"root mean squared error is\",np.sqrt(mse))","0980a368":"Conclusion : RMSE in this deep model is way lower than even Rondom Forest ","5d7b7806":"# 1. Linear Regression ","c5daf614":"# Important Note:\nBecause we dont know how property tax and hoa calculated and sometimes taxes are going to be half of total then we must drop them for having a better model and it is more make sense to predict rent amount","1b58f432":"# Neural Network With Keras","192be779":"# Gradient Boosting Regressor","69d08df6":"Conclusion : its is not a good model so we go further and make more models","47290e63":"after removing first column we should take care of rest .\nfor \"floor\" column we can drop rows with '-' value or there is a second way to make them 0 . \nI prefer second one ... ","8ef64ccd":"# **Data Preprocessing**","f701a343":"# Random Forest","21bde135":"Train and test split","5d28ca26":"Conclusion : well score in this model is high but it is like overfited cause RMSE in this model is lower than Gradint Boosting","0b3b9fd5":"Conclusion : it is better model than linear regression with lower MAE adn RMSE but its not good yet","ffd0b1ea":"Well Unnamed: 0 Should remove","67b20097":"Transforming animal and furniture column from categorical variable to numeric","1c9dfa32":"# Importing Libraries"}}