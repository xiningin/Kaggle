{"cell_type":{"a0ce6767":"code","f52db0c3":"code","62b7d7e6":"code","36521808":"code","76fa7069":"code","e7675a97":"code","b926db07":"code","16b35639":"code","bbd600be":"code","d4f501b3":"code","0806cede":"code","be8ae4fb":"code","90242132":"code","eb49c106":"code","61768db1":"code","84456bc9":"code","c4d94e27":"code","679274f2":"code","95f31e27":"code","55d4159b":"code","36deee47":"code","d540e7ba":"code","71f46c70":"code","0a336ac6":"code","4b7dc023":"code","679f1639":"code","73b23c11":"code","d92977f8":"code","03bbc691":"code","b037d5f4":"code","16dfd706":"code","a78dc4b6":"code","69cf6332":"code","4672a24c":"code","8719fa73":"code","03dac6df":"code","9b4003c4":"code","1ba26fe2":"code","bcc90914":"code","dbf3cc9f":"code","02e57ba5":"code","4078877e":"code","5d6dce49":"code","9f79b58b":"code","f2859ef6":"code","feb8033d":"code","2508828b":"code","f872e530":"code","6c923fbe":"code","bf0857a8":"code","c0232c4e":"code","be34338a":"code","c3d61404":"code","68899381":"code","7b5edb80":"code","405c71d2":"code","747f49d5":"code","871b2b0f":"code","18199956":"code","f22b0f69":"code","35b38d2c":"code","ec03a348":"code","ff2c6792":"code","b8b968f3":"code","f59d59e9":"code","de3cfac3":"code","2083cb61":"code","86f5aaec":"code","391daead":"code","eefe7169":"code","8f030103":"code","15fe8d70":"code","71b2feed":"code","8e84bf71":"code","7486387d":"code","3e912fec":"code","03560bf0":"code","16186b52":"code","06f3bd55":"code","1de43e13":"code","85ff332d":"code","4b1d56ec":"code","a67efb53":"code","985f7e9d":"code","a8051537":"code","8119d1c0":"code","b3148125":"code","e665dae9":"code","4f2ec4a6":"code","eda5a90e":"code","a83fd374":"code","b49b6917":"code","76c5d7ac":"code","a12d4aff":"code","14565a40":"code","581fafcd":"code","8c48ac41":"code","9923315d":"code","87285a6d":"code","bb04b8f2":"code","3d433b40":"code","ac5f0555":"code","3461da0e":"code","907dd905":"code","51985b07":"code","eda93a6e":"code","b947c20e":"code","3565d3a9":"code","fcf56db6":"code","9a37838d":"code","aa0c1c77":"code","4d20bed1":"code","cd961bad":"code","7895b6db":"code","92c4da85":"code","dc0e373d":"code","1351bc0d":"code","4c8da056":"code","0efaeb44":"code","38a97f75":"code","8fe426c3":"code","8d50e996":"code","15fabc36":"code","dacab9ee":"code","862606da":"code","2b47d9e9":"code","72dbec97":"code","af240c64":"code","3407ea43":"code","cf5f28b5":"code","8d15849c":"code","26f214f8":"code","582c44e6":"code","27fbd9c5":"code","be41a651":"code","f917c0b4":"code","5b275083":"code","a775e541":"markdown","a8db0f81":"markdown","d1dd2d4b":"markdown","fa72c5b1":"markdown","51b6c7ed":"markdown","996dfb2b":"markdown","f4c3f564":"markdown","d8148d62":"markdown","b402e7e0":"markdown","7ecfab08":"markdown","97f4ecd1":"markdown","9e52651e":"markdown","b42470a3":"markdown","e79e8e89":"markdown","ef86ac7f":"markdown","59beadc8":"markdown","1cb95381":"markdown","1a0832b1":"markdown","35467e1a":"markdown","0e797a7e":"markdown","3991b804":"markdown","1934723c":"markdown","b50f6bfe":"markdown","41e8b722":"markdown","837a2184":"markdown","3b74853f":"markdown","cfff5afb":"markdown","5b896fb1":"markdown","8d244b11":"markdown","060efd5c":"markdown","ea4eece9":"markdown","4c7aaedb":"markdown","3d991c84":"markdown","a804d166":"markdown","5ff89725":"markdown","3bce0172":"markdown","2716e818":"markdown","56de2487":"markdown","7080e038":"markdown","aba78164":"markdown","b2ef1d8e":"markdown","e829d1c2":"markdown","f0e9645e":"markdown","4b0effec":"markdown","e6b31bce":"markdown","b7051b1c":"markdown","3af2404e":"markdown","6fb717e2":"markdown","93e089d4":"markdown","fa2d2087":"markdown","403ee843":"markdown","6f13cc0d":"markdown","94acf7b3":"markdown","c074da72":"markdown"},"source":{"a0ce6767":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ntelco = pd.read_csv('..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ntelco.head()\n\n","f52db0c3":"telco.dtypes","62b7d7e6":"#Chek if there is any column with null values\ntelco.info()","36521808":"telco.isna().sum()","76fa7069":"#Get a overview of each column\ntelco.describe()","e7675a97":"#Get maximum values\ntelco.max()","b926db07":"#Get minimum values\ntelco.min()","16b35639":"#Checking unique values\ntelco.nunique()","bbd600be":"print('Empty cells in TotalCharges: ', len(telco[telco['TotalCharges']==' ']))","d4f501b3":"#number of rows\nnrows_before=len(telco) \n#removing empty cells from TotalCharges (remove associeted rows)\ntelco=telco[telco['TotalCharges']!=' ']\n#Number of rows after remove emptys TotalCharges\nnrows_after=len(telco)\n#Reset inted\ntelco.reset_index(inplace=True)\ntelco.drop('index', axis=1, inplace=True)\n#Lost data\nprint((\"lost data: {0:.3f} %\").format(100*(1-nrows_after\/nrows_before)))","0806cede":"telco[\"TotalCharges\"] = telco[\"TotalCharges\"].astype(float)\n","be8ae4fb":"print(\"TotalCharges type:\", telco[\"TotalCharges\"].dtypes)","90242132":"#Checking columns with 3 different unique values \ncheck_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingMovies']\nfor c in check_cols:\n    print( c + '=', telco[c].unique())\n","eb49c106":"telco[\"SeniorCitizen\"] = telco[\"SeniorCitizen\"].replace(to_replace=[0, 1], value=['No', 'Yes'])","61768db1":"print(\"SeniorCitizen unquies: \", telco[\"SeniorCitizen\"].unique())","84456bc9":"#Replace 'No internet service','No phone service' to 'No'\ntelco.replace(['No internet service','No phone service'],'No', inplace=True)\n","c4d94e27":"for c in check_cols:\n    print( c + '=', telco[c].unique())","679274f2":"for c in telco.columns:\n    print( c + '=', telco[c].unique())","95f31e27":"#Separation of categorical and numerical columns\ncat_cols = telco.select_dtypes(include='object')\nnum_cols = telco.select_dtypes(exclude='object')","55d4159b":"sns.clustermap(num_cols.corr(),linecolor='white',cmap='coolwarm',annot=True, figsize=(15,15))\nsns.set_context(\"paper\", font_scale=2)   ","36deee47":"sns.pairplot(telco, hue='Churn', palette='coolwarm', size=5)\n","d540e7ba":"f, axes = plt.subplots(nrows=1,ncols=3, squeeze=True,figsize=(30, 8))\n\nsns.distplot(telco['MonthlyCharges'], ax=axes[0])\n\nsns.distplot(telco['TotalCharges'],  ax=axes[1])\n\nsns.distplot(telco['tenure'], ax=axes[2])\n","71f46c70":"#TotalCharges vS  Churn\ng = sns.FacetGrid(telco, hue=\"Churn\", size=8, aspect=2,legend_out=True)\ng = (g.map(sns.distplot, \"TotalCharges\", kde=False).add_legend())\n","0a336ac6":"#MonthlyCharges vS  Churn\ng = sns.FacetGrid(telco, hue=\"Churn\", size=8, aspect=2,legend_out=True)\ng = (g.map(sns.distplot, \"MonthlyCharges\", kde=False).add_legend())","4b7dc023":"#Tenure vS  Churn\ng = sns.FacetGrid(telco, hue=\"Churn\", size=8, aspect=2,legend_out=True)\ng = (g.map(sns.distplot, \"tenure\", kde=False).add_legend())","679f1639":"import math\nf, axes = plt.subplots(nrows=math.ceil(len(cat_cols.columns[1:])\/2),ncols=2,figsize=(30, 40))\ngraf_count = []\ni=0\nj=0\nfor col in cat_cols.columns[1:]:\n    graf_count.append(sns.countplot(x=col,data=telco, ax=axes[i,j],palette=\"Paired\"))\n    j=j+1\n    if j==2:\n        i=i+1\n        j=0\ngraf_count.append(sns.boxplot(x=\"TotalCharges\", y=\"Churn\", data=telco, whis=np.inf))\nsns.set_context(\"paper\", font_scale=1.5)      \nsns.set_style(\"white\")\nsns.despine()\n\ntotal = float(len(telco)) \nplt.subplots_adjust(bottom=0.1, right=0.8, top=0.9, hspace = 0.5)\n\n\nfor g in graf_count:\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(100*height\/total),\n            ha=\"center\") \n","73b23c11":"telco.head()","d92977f8":"#Tenure to Categorical\ndef tenure_cat(telco) :\n    \n    if telco[\"tenure\"] <= 12 :\n        return \"0-1_year\"\n    elif (telco[\"tenure\"] > 12) & (telco[\"tenure\"] <= 24):\n        return \"1-2_year\"\n    elif (telco[\"tenure\"] > 24) & (telco[\"tenure\"] <= 36):\n        return \"2-3_year\"\n    elif (telco[\"tenure\"] > 36) & (telco[\"tenure\"] <= 48):\n        return \"3-4_year\"\n    elif (telco[\"tenure\"] > 48) & (telco[\"tenure\"] <= 60):\n        return \"4-5_year\"\n    elif telco[\"tenure\"] > 60:\n        return \"5-6_year\"\n\ntelco[\"tenure_years\"] = telco.apply(lambda t:tenure_cat(t), axis = 1)","03bbc691":"telco.head()","b037d5f4":"telco['tenure_years'].value_counts().sort_index().index\nfig = plt.gcf()\nfig.set_size_inches(16, 10)\nsns.set_context(context='paper', font_scale=2)\ng=sns.countplot(x=\"tenure_years\", data=telco, palette=\"magma\", order=telco['tenure_years'].value_counts().sort_index().index)\ntotal = float(len(telco)) \n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n    height + 3,'{:1.2f}%'.format(100*height\/total), ha=\"center\") ","16dfd706":"cat_cols = telco.select_dtypes(include='object')\nnum_cols = telco.select_dtypes(exclude='object')\ncat_cols=cat_cols.drop(\"customerID\", axis=1)\n","a78dc4b6":"telco=pd.get_dummies(data = telco,columns =  cat_cols.columns, drop_first=True)\ntelco.head()","69cf6332":"telco.describe()","4672a24c":"sns.set_context(\"paper\", font_scale=1)  \nsns.clustermap(telco.corr(),linecolor='white',cmap='coolwarm', figsize=(20,15), annot=True)","8719fa73":"from sklearn.preprocessing import StandardScaler\n\n#Normalize the mesure (numerical columns)\nscale = StandardScaler()\nscale.fit_transform(num_cols)","03dac6df":"#scale\nscaled_features = scale.transform(num_cols)\n#Create a panda DF with scaled features\ntelco_feat = pd.DataFrame(scaled_features, columns= num_cols.columns)\n#Concat this new DF with Telco DF\ntelco_feat = pd.concat([telco_feat, telco.drop(['tenure','MonthlyCharges','TotalCharges'], axis=1)], axis=1)\n#Move Target columns to the last column position\n","9b4003c4":"telco_feat['Churn'] = telco_feat['Churn_Yes']\ntelco_feat.drop('Churn_Yes', axis=1, inplace=True)\n\ntelco_feat.rename(columns={'InternetService_Fiber optic':'InternetService_Fiber_Optic',\n                          'PaymentMethod_Credit card (automatic)':'PaymentMethod_Credit_card_Auto',\n                          'PaymentMethod_Electronic check':'PaymentMethod_Electronic_Check',\n                          'PaymentMethod_Mailed check':'PaymentMethod_Mailed_check',\n                           'Contract_One year':'Contract_One_year',\n                           'Contract_Two year':'Contract_Two_year'\n                          }, \n                 inplace=True)","1ba26fe2":"telco_feat.info()","bcc90914":"telco_feat.describe()","dbf3cc9f":"fig = plt.figure(figsize=(20,10))\nax = fig.add_axes([0,0,1,1])\n\n#Bart plot\ntelco_feat.corr()['Churn'].sort_values(ascending = False).plot(kind='bar', cmap='RdGy', )\n\n#Change font size\nfor item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n             ax.get_xticklabels() + ax.get_yticklabels()):\n    item.set_fontsize(12)\n\nax.axhline(0, color='black')\n    \ntotal=len(telco_feat.corr()['Churn'])","02e57ba5":"telco=telco_feat","4078877e":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report,confusion_matrix \n%matplotlib inline","5d6dce49":"X_train, X_test, y_train, y_test = train_test_split(telco.drop(['customerID','Churn'],axis=1),telco['Churn'],\n                                                    test_size=0.30)","9f79b58b":"max_depth=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]","f2859ef6":"#GridSearch \nparameters = {\n    'n_estimators'      : [100,150,200,250,500],\n    'max_depth'         : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n    'random_state'      : [0],\n}\ngrid_rfc = GridSearchCV(RandomForestClassifier(), parameters, refit=True, verbose=3, scoring='accuracy', cv=5, n_jobs=4) ","feb8033d":"grid_rfc.fit(X_train, y_train)","2508828b":"#RESULTS\nchurn = {'rfc':[grid_rfc.best_params_,grid_rfc.best_score_]}\nprint('Parametros', grid_rfc.best_params_)\nprint('Accuracy', grid_rfc.best_score_)\nprint('Estimator:', grid_rfc.best_estimator_)","f872e530":"rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=9, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n            oob_score=False, random_state=0, verbose=0, warm_start=False)","6c923fbe":"rfc.fit(X_train,y_train)","bf0857a8":"pred = rfc.predict(X_test)","c0232c4e":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['rfc'][1])","be34338a":"cm=confusion_matrix(y_test,pred)","c3d61404":"df_cm = pd.DataFrame(cm, index = ['Churn','All'],\n                  columns = ['Churn','All'])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","68899381":"cv_scores = []\nfor i in max_depth:\n    \n    rfc_e = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=i, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n            oob_score=False, random_state=0, verbose=0, warm_start=False)\n    scores = cross_val_score(rfc_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","7b5edb80":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal_k = max_depth[MSE.index(min(MSE))]\nprint(\"The optimal number of Max Depth is:\", optimal_k)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(max_depth, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number of Max Depth')\nplt.ylabel('Misclassification Error')\nplt.show()\n","405c71d2":"from sklearn.neighbors import KNeighborsClassifier\nk_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]","747f49d5":"parameters = {\n    'n_neighbors'      : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n    'weights'         : ['uniform','distance'],\n    'metric'      : ['euclidean', 'manhattan'],\n}","871b2b0f":"grid_knn = GridSearchCV(KNeighborsClassifier(), parameters, refit=True, verbose=3, scoring='accuracy', cv=5, n_jobs=4) ","18199956":"grid_knn.fit(X_train,y_train)","f22b0f69":"#RESULTS\nchurn = {'Knn':[grid_knn.best_params_,grid_knn.best_score_]}\nprint('Parametros', grid_knn.best_params_)\nprint('Accuracy', grid_knn.best_score_)\nprint('Estimator:', grid_knn.best_estimator_)","35b38d2c":"knn=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n           metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n           weights='uniform')","ec03a348":"knn.fit(X_train,y_train)","ff2c6792":"pred = knn.predict(X_test)","b8b968f3":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['Knn'][1])","f59d59e9":"cm=confusion_matrix(y_test,pred)\ndf_cm = pd.DataFrame(cm, index = ['Churn','All'],\n                  columns = ['Churn','All'])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","de3cfac3":"cv_scores = []\nfor i in k_range:\n    \n    knn_e = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n           metric_params=None, n_jobs=1, n_neighbors=i, p=2,\n           weights='uniform')\n    scores = cross_val_score(knn_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","2083cb61":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal_k = k_range[MSE.index(min(MSE))]\nprint(\"The optimal number of neighbors is:\", optimal_k)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(k_range, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.show()\n","86f5aaec":"#XGBoosts\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV","391daead":"gamma = [0, 0.001, 0.01, 0.1,1 , 2, 5]","eefe7169":"param_grid = {\n   'max_depth': [3,4],\n   'n_estimators': [100,150],\n   'nthread': [8],\n   'subsample': [0,0.9, 1.0],\n   'gamma': [0, 0.001, 0.01, 0.1,1 , 2, 5],\n   'min_child_weight': [1, 5, 10]\n}\n","8f030103":"grid_gb = GridSearchCV(XGBClassifier(), param_grid=param_grid, refit=True, verbose=3, scoring='accuracy', n_jobs=4)","15fe8d70":"grid_gb.fit(X_train, y_train)","71b2feed":"#RESULTS\nif 'churn' in globals():\n    churn['xgb'] = [grid_gb.best_params_,grid_gb.best_score_]\nelse:\n    churn = {'xgb':[grid_gb.best_params_,grid_gb.best_score_]}\n\nprint('Parametros', grid_gb.best_params_)\nprint('Accuracy', grid_gb.best_score_)\nprint('Estimator:', grid_gb.best_estimator_)","8e84bf71":"xgb = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n       gamma=2, learning_rate=0.1, max_delta_step=0, max_depth=4,\n       min_child_weight=1, missing=None, n_estimators=100, nthread=8,\n       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=1, seed=0, silent=True, subsample=1.0)","7486387d":"xgb.fit(X_train,y_train)","3e912fec":"pred = xgb.predict(X_test)","03560bf0":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['xgb'][1])","16186b52":"cm=confusion_matrix(y_test,pred)\ndf_cm = pd.DataFrame(cm, index = ['Churn','All'],\n                  columns = ['Churn','All'])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","06f3bd55":"cv_scores = []\nfor i in gamma:\n    \n    xgb_e = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n       gamma=i, learning_rate=0.1, max_delta_step=0, max_depth=4,\n       min_child_weight=1, missing=None, n_estimators=100, nthread=8,\n       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=1, seed=0, silent=True, subsample=1.0)\n    scores = cross_val_score(xgb_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","1de43e13":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = gamma[MSE.index(min(MSE))]\nprint(\"The optimal gamma is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(gamma, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Gamma number')\nplt.ylabel('Misclassification Error')\nplt.show()","85ff332d":"from sklearn.svm import LinearSVC\nC = [0.1, 1, 10, 100,500,1000]","4b1d56ec":"param_grid = {'C': [0.1, 1, 10, 100,500,1000]}\ngrid_lsvm = GridSearchCV(LinearSVC(),param_grid,refit=True,verbose=3,scoring='accuracy', n_jobs=4)","a67efb53":"grid_lsvm.fit(X_train,y_train)","985f7e9d":"churn['LinearSVC'] = [grid_lsvm.best_params_,grid_lsvm.best_score_]\nprint('Parametros', grid_lsvm.best_params_)\nprint('Accuarcy', grid_lsvm.best_score_)\nprint('Estimator:', grid_lsvm.best_estimator_)","a8051537":"lsvc=LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)","8119d1c0":"lsvc.fit(X_train,y_train)","b3148125":"pred = lsvc.predict(X_test)","e665dae9":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['LinearSVC'][1])","4f2ec4a6":"cm=confusion_matrix(y_test,pred)\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\nplt.figure(figsize = (15,10))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","eda5a90e":"cv_scores = []\nfor i in C:\n    \n    lsvc_e = LinearSVC(C=i, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)\n    scores = cross_val_score(lsvc_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","a83fd374":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = C[MSE.index(min(MSE))]\nprint(\"The optimal C is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(C, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number os Cs')\nplt.ylabel('Misclassification Error')\nplt.show()","b49b6917":"from sklearn.svm import SVC","76c5d7ac":"Csvc = [1,10,100,1000]","a12d4aff":"param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['rbf']}","14565a40":"grid_svc = GridSearchCV(SVC(),param_grid,refit = True, verbose=3)","581fafcd":"grid_svc.fit(X_train,y_train)","8c48ac41":"if 'churn' in globals():\n    churn['SVC'] = [grid_svc.best_params_,grid_svc.best_score_]\nelse:\n    churn = {'SVC':[grid_svc.best_params_,grid_svc.best_score_]}\n \nprint('Parametros', grid_svc.best_params_)\nprint('Accuarcy', grid_svc.best_score_)\nprint('Estimator:', grid_svc.best_estimator_)","9923315d":"svm = SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)","87285a6d":"svm.fit(X_train,y_train)","bb04b8f2":"pred = svm.predict(X_test)","3d433b40":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['SVC'][1])","ac5f0555":"cm=confusion_matrix(y_test,pred)\nplt.figure(figsize = (15,10))\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\n\nsns.heatmap(df_cm, annot=True, cmap='Blues')","3461da0e":"cv_scores = []\nfor i in Csvc:\n    \n    svc_e = SVC(C=i, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n    scores = cross_val_score(svc_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","907dd905":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = Csvc[MSE.index(min(MSE))]\nprint(\"The optimal C is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(Csvc, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number os Cs')\nplt.ylabel('Misclassification Error')\nplt.show()","51985b07":"from sklearn.linear_model import LogisticRegression","eda93a6e":"Clog = [0.001,0.01,0.1,1,10,100,1000]","b947c20e":"grid_values = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}","3565d3a9":"grid_log = GridSearchCV(LogisticRegression(),param_grid=grid_values,refit = True, verbose=3)","fcf56db6":"grid_log.fit(X_train, y_train)","9a37838d":"if 'churn' in globals():\n    churn['log'] = [grid_log.best_params_,grid_log.best_score_]\nelse:\n    churn = {'log':[grid_log.best_params_,grid_log.best_score_]}\n \nprint('Parametros', grid_log.best_params_)\nprint('Accuarcy', grid_log.best_score_)\nprint('Estimator:', grid_log.best_estimator_)","aa0c1c77":"lr = LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)","4d20bed1":"lr.fit(X_train,y_train)","cd961bad":"pred=lr.predict(X_test)","7895b6db":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['log'][1])","92c4da85":"cm=confusion_matrix(y_test,pred)\nplt.figure(figsize = (15,10))\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\n\nsns.heatmap(df_cm, annot=True, cmap='Blues')","dc0e373d":"cv_scores = []\nfor i in Clog:\n    \n    log_e = LogisticRegression(C=i, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n    scores = cross_val_score(log_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","1351bc0d":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = Clog[MSE.index(min(MSE))]\nprint(\"The optimal C is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(Clog, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number os Cs')\nplt.ylabel('Misclassification Error')\nplt.show()","4c8da056":"import keras\nfrom keras.layers import Dense, Dropout\nfrom keras.models import Sequential\nfrom IPython.display import SVG\nfrom keras.optimizers import Adam\nfrom keras import regularizers\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras import losses\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\n#import pydot\nfrom imblearn.over_sampling import SMOTE","0efaeb44":"os = SMOTE(random_state = 0,  k_neighbors=10)\n\n#Train set\nX_smote_os,y_smote_os = os.fit_sample(X_train,y_train)\nX_smote_os = pd.DataFrame(data = X_smote_os,columns= telco.drop(['customerID','Churn'], axis=1).columns)\ny_smote_os  = pd.DataFrame(data = y_smote_os,columns=[\"Churn\"])\n\nX_matrix_smote = X_smote_os.as_matrix()\ny_matrix_smote =y_smote_os.as_matrix()\n\n#Test set\nX_smote_os_test,y_smote_os_test = os.fit_sample(X_test,y_test)\nX_smote_os_test = pd.DataFrame(data = X_smote_os_test,columns= telco.drop(['customerID','Churn'], axis=1).columns)\ny_smote_os_test  = pd.DataFrame(data = y_smote_os_test,columns=[\"Churn\"])\n\nX_matrix_smote_test = X_smote_os.as_matrix()\ny_matrix_smote_test =y_smote_os.as_matrix()","38a97f75":"n_cols=X_matrix_smote.shape[1]\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(n_cols,), activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(4, activation='softmax'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","8fe426c3":"history = model.fit(X_matrix_smote, y_matrix_smote, epochs=150, batch_size=10)\n","8d50e996":"predictions   = model.predict(X_matrix_smote_test)\nscore = model.evaluate(X_matrix_smote_test, y_matrix_smote_test, verbose=0)","15fabc36":"print('Test loss:', score[0])\nprint('Test accuracy:', score[1])","dacab9ee":"y_pred = (predictions > 0.5)\nprint(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_matrix_smote_test, y_pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_matrix_smote_test, y_pred))","862606da":"cm = confusion_matrix(y_matrix_smote_test, y_pred)\nplt.figure(figsize = (15,10))\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\n\nsns.heatmap(df_cm, annot=True, cmap='Blues')","2b47d9e9":"plt.figure(figsize=(15,10))\nplt.subplot(211)\nplt.plot(history.history['acc'], marker='o', markerfacecolor='black', markersize=2)\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n\n# Plot training & validation loss values\nplt.subplot(212)\nplt.plot(history.history['loss'], marker='o', markerfacecolor='black', markersize=2)\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n","72dbec97":"from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import plot_importance","af240c64":"def model_evaluate(model,train_x,test_x,train_y,test_y,name) :\n    model.fit(train_x,train_y)\n    predictions  = model.predict(test_x)\n    \n    predictions  = model.predict(test_x)\n    accuracy     = accuracy_score(test_y,predictions)\n    recallscore  = recall_score(test_y,predictions)\n    precision    = precision_score(test_y,predictions)\n    auc          = cross_val_score(model,test_x,test_y, scoring='roc_auc').mean()\n    f1score      = f1_score(test_y,predictions) \n        \n    df = pd.DataFrame({\"0_Model\"           :  name,\n                       \"1_Accuracy_score\"  : [accuracy],\n                       \"2_Recall_score\"    : [recallscore],\n                       \"3_Precision\"       : [precision],\n                       \"4_f1_score\"        : [f1score],\n                       \"5_Area_under_curve\": [auc]                  \n                      })\n    \n    \n    return df","3407ea43":"ml_models = np.array([rfc, knn, xgb, lr, lsvc, svm])","cf5f28b5":"names=np.array(['RandomForestClassifier', 'KNeighborsClassifier', 'XGBClassifier','LogisticRegression','LinearSVC', 'SVC'])","8d15849c":"results = pd.DataFrame()\ni=0","26f214f8":"recallscore  = recall_score(y_matrix_smote_test,y_pred)\nprecision    = precision_score(y_matrix_smote_test,y_pred)\nf1score      = f1_score(y_matrix_smote_test,y_pred) \nauc = roc_auc_score(y_matrix_smote_test,y_pred)","582c44e6":"keras_model_result=pd.DataFrame({\"0_Model\"           : 'KerasSequencial',\n                       \"1_Accuracy_score\"  : [score[1]],\n                       \"2_Recall_score\"    : [recallscore],\n                       \"3_Precision\"       : [precision],\n                       \"4_f1_score\"        : [f1score],\n                       \"5_Area_under_curve\": [auc]                  \n                      })","27fbd9c5":"for l in  ml_models:\n    results=results.append(model_evaluate(l ,X_train,X_test,y_train,y_test,names[i]))\n    i = i+1","be41a651":"results=results.append(keras_model_result).reset_index().drop('index', axis=1)","f917c0b4":"def highlight_max(s):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    if s.dtype == 'float64':\n        return ['background-color: yellow' if v else '' for v in is_max]\n    else:\n        return ['background-color: white' if v else '' for v in is_max]","5b275083":"results.style.apply(highlight_max)","a775e541":"<h3>Evaluating machine learning models<\/h3>","a8db0f81":"After loading the file, we could notice that some columns are categorical and some are numerical. So, the first step it checks if it has some inconsistent data (missing values, wrong measurements, etc.)","d1dd2d4b":"<h3>4.6 Logistic Regression <\/h3>","fa72c5b1":"Applying GridSearch to find better parameters:","51b6c7ed":"<h3>4.5 Suport Vector Machine<\/h3>","996dfb2b":"Another problem pointed out was the ambiguous columns. The next step is to check these columns\n\n","f4c3f564":"Checking performance:","d8148d62":"Renaming and fixing some columns names","b402e7e0":"Checking the best estimator:","7ecfab08":"<h3>3.3 Normalization<\/h3>","97f4ecd1":"Applying GridSearch to find better parameters:","9e52651e":"<h3>4.2 KNeighborsClassifier<\/h3>","b42470a3":"<h3>2.2.3 Transformation: replace to (yes,no) (SeniorCitizen)<\/h3>\nThis transformation will just be temporary for some exploratory data analysis","e79e8e89":"<h3>2.2 Transform<\/h3>\n<h3>2.2.1 Transformation: Removing rows with empty cells (Total Charges)<\/h3>\nFirst, remove rows where TotalCharges column has empty cells.","ef86ac7f":"<h3>2.3.2 Correlation of numeric variables and Churn distribution<\/h3>","59beadc8":"Before starting some data visualization, it\u2019s necessary to fix some issues and <b>transform<\/b> the data set (making it easy to manipulate).","1cb95381":"<h3>Results<\/h3>","1a0832b1":"Note that most of the churn values are in Total Charges <100.","35467e1a":"Applying GridSearch to find better parameters:","0e797a7e":"<p>After checking the max, min and unique values, it is possible to see some data inconsistencies. TotalCharges has empty cells. Some columns have three different values but their max and min are 'yes' or 'no'. In this case, these columns might have some ambiguous values that can be replaced by 'yes' or 'no'.<\/p>\n\n<ul>\n<li> MultipleLines         = 3<\/li>\n<li> InternetService       = 3<\/li>\n<li> OnlineSecurity        = 3<\/li>\n<li> OnlineBackup          = 3<\/li>\n<li> DeviceProtection      = 3<\/li>\n<li> TechSupport           = 3<\/li>\n<li> StreamingTV           = 3<\/li>\n<li> StreamingMovies       = 3<\/li>\n<li> Contract              = 3<\/li>\n<\/ul>    ","3991b804":"This notebook will include 2 tasks (Inicial Data Exploration and Extract, Transform,\tLoad)\n\n<h3>1. Initial Data Exploration<\/h3>\n<ul>\n<li> Identify quality issues (e.g. missing values, wrong measurements, \u2026)<\/li>\n<li>Assess feature quality \u2013 how relevant is a certain measurement (e.g. use correlation matrix)<\/li>\n<li>Get an idea on the value distribution of your data using statistical measures and visualizations<\/li>\n<\/ul>    \n\n<h3>2. Extract,\tTransform,\tLoad\t(ETL) <\/h3>\n\n<ul> \n<li>Accessing the data source;<\/li>\n<li>Transforming data source; <\/li>\n<\/ul>\n    ","1934723c":"there is no NaN values.","b50f6bfe":"As you can see, tenure and Totalcharges have a close correlation. Also, TotalCharges and MonthlyCharge have a relevant correlation.","41e8b722":"<h3>3. Feature\tCreation<\/h3>\n    \n<ul>\n<li>Filling of empty fields based on its value distribution<\/li>\n<li>Imputed time-series quantization Time series often contain streams with measurements at different timestamps<\/li>\n<li>Scaling \/ Normalizing \/ Centering<\/li>\n<li>Filtering - Sometimes imputing values doesn\u2019t perform well<\/li>\n<li>Discretizing - Continuous fields might confuse the model<\/li>\n<\/ul>    \n\nLooking again at the tenure, it can be separated into different boxes and create a new category column. In this case, it has been separated by intervals of years:\n\n<ul>\n<li>0-1 year (0-12 months)<\/li>\n<li>1-2 year (12-24 months)<\/li>\n<li>2-3 year (24-36 months)<\/li>\n<li>3-4 year (36-48 months)<\/li>\n<li>4-5 year (48-60 months)<\/li>\n<li>5-6 year (60-72 months)<\/li>\n<\/ul>    \n","837a2184":"Checking the best estimator:","3b74853f":"Checking the best estimator:","cfff5afb":"Notice the correlation between Total Charges X Tenure and Total Charges X Monthly Charges.","5b896fb1":"<h3>2.2.4 Transformation: Replacing ambiguous values<\/h3>\n\nAs you can see, No 'Internet Service\/No phone service' is equivalent to 'no'. For these cases, they will be replaced. For now, Internet Service column will not be modified.","8d244b11":"Training the Model:","060efd5c":"<h3>2.3.5 Categorical columns comparison<\/h3>","ea4eece9":"<h3>3.2 Creating Dummy columns (One-hot-encoding) <\/h3>\nNext task is create some dummy columns ","4c7aaedb":"Applying GridSearch to find better parameters:","3d991c84":"<h3>4.7 Deep Learning - Model training<\/h3>","a804d166":"<h3>6. Evaluating Models<\/h3>\n<ul>\n<li>Performance\tis\tevaluated.<\/li>\n<li>Metrics\t<\/li>\n    \n<\/ul>    ","5ff89725":"A normalization is applied to the numeric columns (Total Charges, Tenure, Month Charges)","3bce0172":"Checking the best estimator:","2716e818":"<h3>4.3 XGBoosts<\/h3>","56de2487":"<h3>4.4 Linear Suport Vector Machine<\/h3>","7080e038":"Analyzing column-only values again:","aba78164":"<h3>2.2.2 Transformation: Converting to float (Total Charges)<\/h3>\nThe amount of lost data is really small and it will not impact in the model. The next step is to convert TotalCharges to float (considering its format is a string).","b2ef1d8e":"Splitting the dataset in train and test 30% (Test size)","e829d1c2":"<h3>2.3 Exploratory analysis and data visualization <\/h3>\n<h3>2.3.1 Heatmap - correlation of numerical variables<\/h3>","f0e9645e":"Notice total charges are an object type. It might need to be converted to the appropriate type.","4b0effec":"Applying GridSearch to find better parameters:","e6b31bce":"<h3>Fucntion to evauluete models (machine learning)<\/h3>","b7051b1c":" <h3>2.3.4 Checking distribution between numeric columns and Churn<\/h3>","3af2404e":"<h3>4. Model Definition and Training<\/h3>\n<ul>\n<li>Selecting model performance indicator<\/li>\n<li>Implementing algorithm<\/li>\n<li>Appling additional iteration<\/li>\n<li>Training<\/li>\n<\/ul>\n","6fb717e2":"<h1>Description<\/h1>\n<h2>Context<\/h2>\n\n<p> Customer churn occurs when customers or subscribers stop doing business with a company or service. Also known as customer attrition, customer churn is a critical metric because it is much less expensive to retain existing customers than it is to acquire new customers \u2013 earning business from new customers means working leads all the way through the sales funnel, utilizing your marketing and sales resources throughout the process. Customer retention, on the other hand, is generally more cost-effective, as you have already earned the trust and loyalty of existing customers.  <\/p>\n\n<h2>Goal<\/h2>\n<p>\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]]<\/p>\n\n<h2>Content<\/h2>\n\n<p>Each row represents a customer; each column contains customer\u2019s attributes described in the column Metadata.\nThe data set includes information about:\n<\/p>\n\n<ul>\n<li>Customers who left within the last month \u2013 the column is called Churn\n<li>Services that each customer has signed up for \u2013 phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n<li>Customer account information \u2013 how long they\u2019ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n<li>Demographic info about customers \u2013 gender, age range, and if they have partners and dependents\n<\/ul>\n<h2>Source:<\/h2>\n<a href=\"https:\/\/www.kaggle.com\/blastchar\/telco-customer-churn\">https:\/\/www.kaggle.com\/blastchar\/telco-customer-churn<\/a>\n  ","93e089d4":"<h3>2.1 Extraction<\/h3> \nThe data set is in csV format. It was updated as an IBM Cloud Object Storage. It was used pandas dataframe to manipulate the data extracted.","fa2d2087":"Checking the best estimator:","403ee843":"Cheking the correlation between Churn and the other variables","6f13cc0d":"<h3>2.3.3 Distribution of numeric columns<\/h3>","94acf7b3":"Applying GridSearch to find better parameters:","c074da72":"Checking the best estimator:"}}