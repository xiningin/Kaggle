{"cell_type":{"8a86e442":"code","345ba383":"code","555c9a19":"code","20f8d2f1":"code","54cae416":"code","36ed6039":"code","43458af3":"code","c4fbbcdb":"code","5f0f5a1f":"code","e7d5319d":"code","8ff503e9":"code","243b6703":"code","17a45379":"code","a9636738":"code","70c30bbd":"code","e511ca93":"code","b5f787af":"code","bf449e47":"code","9a3d2935":"code","bfafbe98":"code","8461cdca":"code","d67ddddf":"code","54975f7a":"code","33f32808":"code","d0eb7268":"code","f933c574":"code","90af7045":"code","65fb68ee":"code","c518ec40":"code","e91e7251":"code","e67a4a64":"code","81961357":"code","4399e423":"code","7a871157":"code","fc923daa":"code","10110eb0":"code","ba1f7311":"code","38b2d5a5":"code","6f712fe5":"code","d70f947e":"code","ff6eb795":"code","1dcb8567":"code","60f5b32e":"code","1bb07384":"code","2be699b4":"code","a99d195d":"code","3691aaec":"code","fe87f5d1":"code","78e302e3":"code","1aa993df":"code","aa1a45d7":"code","7314dfd4":"code","0abbff9d":"code","db0c4ef4":"code","1de46551":"code","78416230":"code","b89eafc3":"code","856c226b":"code","82846fce":"code","3d0bf30b":"code","c42e3ebb":"code","855691f3":"code","155d7bb9":"code","7645da02":"code","2a90e1fb":"code","41e98a12":"code","c2451cae":"code","9f08b14a":"code","0cfcacdf":"code","4883d916":"code","d96d10d8":"code","00bc6b02":"code","2208cfdf":"code","e6b42e18":"code","037218e5":"code","028400a1":"code","bebde264":"code","ee749fee":"code","99778d3e":"code","735615fd":"markdown","64eb218a":"markdown","9a9ded50":"markdown","5bd0c124":"markdown","8347ac5b":"markdown","a8ca773a":"markdown","81406284":"markdown","ed930875":"markdown","c82280fa":"markdown","6a579e4c":"markdown","61b82fe2":"markdown","3952d20f":"markdown","09179c4e":"markdown","d60b4a9a":"markdown","bc695589":"markdown","b672eaa9":"markdown","92dc1bfd":"markdown","9f7788de":"markdown","811262e2":"markdown","e473f2f5":"markdown","5afb8a47":"markdown","2449815a":"markdown","928db1fd":"markdown","255f5fac":"markdown","e4953b50":"markdown","36891ccc":"markdown","b0f91dd5":"markdown","606e0518":"markdown","236e7dfa":"markdown","3760fd93":"markdown","af0688c8":"markdown","b864e4d8":"markdown","486d9b7f":"markdown","838c6ec0":"markdown","e4204020":"markdown","199181f7":"markdown","1192ca4a":"markdown","c2db502b":"markdown","ed4ff8c2":"markdown","16f6e026":"markdown","5915a352":"markdown","4e213a69":"markdown","35420d54":"markdown","862dc541":"markdown","7f87af0b":"markdown","3c9e81bc":"markdown","bead9997":"markdown","b5299f49":"markdown","5f26fb7c":"markdown","f99e5a52":"markdown","8c9f6f67":"markdown","13fc0f4b":"markdown","6e33a468":"markdown","a3e506f9":"markdown","c7d86d6e":"markdown","318eff25":"markdown","b27c3c42":"markdown","49850644":"markdown","47971047":"markdown","f9d59f9d":"markdown","0a8c683d":"markdown","d2920169":"markdown","74c0379a":"markdown","dea548f0":"markdown","dfdad909":"markdown"},"source":{"8a86e442":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","345ba383":"file = open('\/kaggle\/input\/ict-lesson\/files\/adult.data', 'r')","555c9a19":"def chr_int(a):\n    if a.isdigit():\n        return int(a)\n    else:\n        return 0\n                \ndata=[]\nfor line in file:\n     data1=line.split(', ')\n     if len(data1)==15:\n        data.append([chr_int(data1[0]),data1[1],chr_int(data1[2]),data1[3],chr_int(data1[4]),data1[5],data1[6],\\\n            data1[7],data1[8],data1[9],chr_int(data1[10]),chr_int(data1[11]),chr_int(data1[12]),data1[13],\\\n            data1[14]])\n","20f8d2f1":"print (data[1:2])","54cae416":"df = pd.DataFrame(data) #  Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes \n\ndf.columns = ['age', 'type_employer', 'fnlwgt', 'education', \n                \"education_num\",\"marital\", \"occupation\", \"relationship\", \"race\",\"sex\",\n                \"capital_gain\", \"capital_loss\", \"hr_per_week\",\"country\",\"income\"]\ndf.head()","36ed6039":"df.tail()","43458af3":"df.shape","c4fbbcdb":"counts = df.groupby('country').size()\n\nprint (counts) ","5f0f5a1f":"counts = df.groupby('age').size() # grouping by age\nprint (counts) ","e7d5319d":"print(counts[counts==counts.max()])\n","8ff503e9":"ml = df[(df.sex == 'Male')] # grouping by sex\nml.shape","243b6703":"ml1 = df[(df.sex == 'Male')&(df.income=='>50K\\n')]\nml1.shape","17a45379":"fm =df[(df.sex == 'Female')]\nfm.shape","a9636738":"fm1 =df[(df.sex == 'Female')&(df.income=='>50K\\n')]\nfm1.shape","70c30bbd":"df1=df[(df.income=='>50K\\n')]\n\nprint ('The rate of people with high income is: ', int(len(df1)\/float(len(df))*100), '%.' )\nprint ('The rate of men with high income is: ', int(len(ml1)\/float(len(ml))*100), '%.' )\nprint ('The rate of women with high income is: ', int(len(fm1)\/float(len(fm))*100), '%.' )\n","e511ca93":"df1=df[(df.income=='>50K\\n')]\n\nprint ('The rate of people with high income is: ', int(len(df1)\/float(len(df))*100), '%.' )\nprint ('The rate of men with high income is: ', int(len(ml1)\/float(len(ml))*100), '%.' )\nprint ('The rate of women with high income is: ', int(len(fm1)\/float(len(fm))*100),'%.' )","b5f787af":"print ('The average age of men is: ', ml['age'].mean(), '.' )\nprint ('The average age of women is: ', fm['age'].mean(), '.')","bf449e47":"print ('The average age of high-income men is: ', ml1['age'].mean(), '.' )\nprint ('The average age of high-income women is: ', fm1['age'].mean(), '.')","9a3d2935":"ml_mu = ml['age'].mean()\nfm_mu = fm['age'].mean()\nml_var = ml['age'].var()\nfm_var = fm['age'].var()\nml_std = ml['age'].std()\nfm_std = fm['age'].std()\n","bfafbe98":"print ('Statistics of age for men: mu:', ml_mu, 'var:', ml_var, 'std:', ml_std)\nprint ('Statistics of age for women: mu:', fm_mu, 'var:', fm_var, 'std:', fm_std)","8461cdca":"ml_mu_hr = ml['hr_per_week'].mean()\nfm_mu_hr = fm['hr_per_week'].mean()\nml_var_hr = ml['hr_per_week'].var()\nfm_var_hr = fm['hr_per_week'].var()\nml_std_hr = ml['hr_per_week'].std()\nfm_std_hr = fm['hr_per_week'].std()","d67ddddf":"print ('Statistics of hours per week for men: mu:', ml_mu_hr, 'var:', ml_var_hr, 'std:', ml_std_hr)\nprint ('Statistics of hours per week for women: mu:', fm_mu_hr, 'var:', fm_var_hr, 'std:', fm_std_hr)\n","54975f7a":"ml_median= ml['age'].median()\nfm_median= fm['age'].median()\n\nprint (\"Median age per men and women: \", ml_median, fm_median)","33f32808":"ml_median_age= ml1['age'].median()\nfm_median_age= fm1['age'].median()\n\nprint (\"Median age per men and women with high-income: \", ml_median_age, fm_median_age)","d0eb7268":"ml_median_hr= ml['hr_per_week'].median()\nfm_median_hr= fm['hr_per_week'].median()\nprint (\"Median hours per week per men and women: \", ml_median_hr, fm_median_hr)\n","f933c574":"import matplotlib.pyplot as plt\nml_age=ml['age']\nml_age.hist(density=0, histtype='stepfilled', bins=20)\n","90af7045":"fm_age=fm['age']\nfm_age.hist(density=0, histtype='stepfilled', bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Female samples',fontsize=15)\nplt.show()","65fb68ee":"import seaborn as sns\nfm_age.hist(density=0, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\nml_age.hist(density=0, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Samples',fontsize=15)\nplt.show()","c518ec40":"fm_age.hist(density=1, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\nml_age.hist(density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('PMF',fontsize=15)\nplt.show()","e91e7251":"ml_age.hist(density=1, histtype='stepfilled', bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","e67a4a64":"fm_age.hist(density=1, histtype='stepfilled', bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","81961357":"ml_age.hist(density=1, histtype='step', cumulative=True, linewidth=3.5, bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","4399e423":"fm_age.hist(density=1, histtype='step', cumulative=True, linewidth=3.5, bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","7a871157":"ml_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5)   # default number of bins = 10\nfm_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75))\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","fc923daa":"ml_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20)\nfm_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20, color=sns.desaturate(\"indianred\", .75))\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","10110eb0":"print (\"The mean sample difference is \", ml_age.mean() - fm_age.mean())","ba1f7311":"df['age'].median()","38b2d5a5":"len(df[(df.income == '>50K\\n') & (df['age'] < df['age'].median() - 15)])","6f712fe5":"len(df[(df.income == '>50K\\n') & (df['age'] > df['age'].median() + 35)])","d70f947e":"df2 = df.drop(df.index[(df.income=='>50K\\n') & (df['age']>df['age'].median() +35) & (df['age'] > df['age'].median()-15)])\n\ndf2.shape","ff6eb795":"ml1_age=ml1['age']\nfm1_age=fm1['age']","1dcb8567":"ml2_age = ml1_age.drop(ml1_age.index[(ml1_age >df['age'].median()+35) & (ml1_age>df['age'].median() - 15)])\n\nfm2_age = fm1_age.drop(fm1_age.index[(fm1_age > df['age'].median()+35) & (fm1_age > df['age'].median()- 15)])","60f5b32e":"mu2ml = ml2_age.mean()\nstd2ml = ml2_age.std()\nmd2ml = ml2_age.median()\n\n# Computing the mean, std, median, min and max for the high-income male population\n\nprint (\"Men statistics: Mean:\", mu2ml, \"Std:\", std2ml, \"Median:\", md2ml, \"Min:\", ml2_age.min(), \"Max:\",ml2_age.max())","1bb07384":"mu3ml = fm2_age.mean()\nstd3ml = fm2_age.std()\nmd3ml = fm2_age.median()\n\n# Computing the mean, std, median, min and max for the high-income female population\nprint (\"Women statistics: Mean:\", mu2ml, \"Std:\", std2ml, \"Median:\", md2ml, \"Min:\", fm2_age.min(), \"Max:\",fm2_age.max())","2be699b4":"print ('The mean difference with outliers is: %4.2f.'% (ml_age.mean() - fm_age.mean()))\nprint (\"The mean difference without outliers is: %4.2f.\"% (ml2_age.mean() - fm2_age.mean()))","a99d195d":"plt.figure(figsize=(13.4,5))\n\ndf.age[(df.income == '>50K\\n')].plot(alpha=.25, color='blue')\ndf2.age[(df2.income == '>50K\\n')].plot(alpha=.45,color='red')\n\nplt.ylabel('Age')\nplt.xlabel('Samples')","3691aaec":"import numpy as np\n\ncountx,divisionx = np.histogram(ml2_age, normed=True)\ncounty,divisiony = np.histogram(fm2_age, normed=True)\nimport matplotlib.pyplot as plt\n\nval = [(divisionx[i]+divisionx[i+1])\/2 for i in range(len(divisionx)-1)]\n\nplt.plot(val, countx-county,'o-')\nplt.title('Differences in promoting men vs. women')\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Differences',fontsize=15)\nplt.show()","fe87f5d1":"print (\"Remember:\\n We have the following mean values for men, women and the difference:\\nOriginally: \", ml_age.mean(), fm_age.mean(),  ml_age.mean()- fm_age.mean()) # The difference between the mean values of male and female populations.)\nprint (\"For high-income: \", ml1_age.mean(), fm1_age.mean(), ml1_age.mean()- fm1_age.mean()) # The difference between the mean values of male and female populations.)\nprint (\"After cleaning: \", ml2_age.mean(), fm2_age.mean(), ml2_age.mean()- fm2_age.mean()) # The difference between the mean values of male and female populations.)\n\nprint (\"\\nThe same for the median:\")\nprint (\"Originally: \",ml_age.median(), fm_age.median(), ml_age.median()- fm_age.median()) # The difference between the mean values of male and female populations.)\nprint (\"For high-income: \",ml1_age.median(), fm1_age.median(), ml1_age.median()- fm1_age.median()) # The difference between the mean values of male and female populations.)\nprint (\"After cleaning: \",ml2_age.median(), fm2_age.median(), ml2_age.median()- fm2_age.median()), # The difference between the mean values of male and female populations.)","78e302e3":"def skewness(x):\n    res=0\n    m=x.mean()\n    s=x.std()\n    for i in x:\n        res+=(i-m)*(i-m)*(i-m)\n    res\/=(len(x)*s*s*s)\n    return res\n\nprint (\"The skewness of the male population is:\", skewness(ml2_age))\nprint (\"The skewness of the female population is:\", skewness(fm2_age))","1aa993df":"def pearson(x):\n    return 3*(x.mean()-x.median())\/x.std()\n\nprint (\"The Pearson's coefficient of the male population is:\", pearson(ml2_age))\nprint (\"The Pearson's coefficient of the female population is:\", pearson(fm2_age))","aa1a45d7":"ml1 = df[(df.sex == 'Male')&(df.income=='>50K\\n')]\n\nml2 = ml1.drop(ml1.index[(ml1['age']>df['age'].median() +35)&(ml1['age']> df['age'].median()- 15)])\n\nfm2 = fm1.drop(fm1.index[(fm1['age']> df['age'].median() + 35)& (fm1['age']> df['age'].median() - 15)])\n\nprint (ml2.shape, fm2.shape)","7314dfd4":"print (\"Men grouped in 3 categories:\")\nprint (\"Young:\",int(round(100*len(ml2_age[ml2_age<41])\/float(len(ml2_age.index)))),\"%.\")\nprint (\"Elder:\", int(round(100*len(ml2_age[ml2_age >44])\/float(len(ml2_age.index)))),\"%.\")\nprint (\"Average age:\", int(round(100*len(ml2_age[(ml2_age>40) & (ml2_age< 45)])\/float(len(ml2_age.index)))),\"%.\")","0abbff9d":"print (\"Women grouped in 3 categories:\")\nprint (\"Young:\",int(round(100*len(fm2_age[fm2_age <41])\/float(len(fm2_age.index)))),\"%.\")\nprint (\"Elder:\", int(round(100*len(fm2_age[fm2_age >44])\/float(len(fm2_age.index)))),\"%.\")\nprint (\"Average age:\", int(round(100*len(fm2_age[(fm2_age>40) & (fm2_age< 45)])\/float(len(fm2_age.index)))),\"%.\")","db0c4ef4":"print (\"The male mean:\", ml2_age.mean())\nprint (\"The female mean:\", fm2_age.mean())","1de46551":"ml2_young = len(ml2_age[(ml2_age<41)])\/float(len(ml2_age.index))\nfm2_young  = len(fm2_age[(fm2_age<41)])\/float(len(fm2_age.index))\nprint (\"The relative risk of female early promotion is: \", 100*(1-ml2_young\/fm2_young))","78416230":"ml2_elder = len(ml2_age[(ml2_age>44)])\/float(len(ml2_age.index))\nfm2_elder  = len(fm2_age[(fm2_age>44)])\/float(len(fm2_age.index))\nprint (\"The relative risk of male late promotion is: \", 100*ml2_elder\/fm2_elder)","b89eafc3":"l = 3\nx=np.arange(0,2.5,0.1)\ny= 1- np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential CDF: $\\lambda$ =%.2f'% l ,fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","856c226b":"\nfrom __future__ import division\nimport scipy.stats as stats\n\nl = 3\nx=np.arange(0,2.5,0.1)\ny= l * np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential PDF: $\\lambda$ =%.2f'% l, fontsize=15)\nplt.xlabel('x', fontsize=15)\nplt.ylabel('PDF', fontsize=15)\nplt.show()","82846fce":"l = 0.25\n\nx=np.arange(0,25,0.1)\ny= l * np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential: $\\lambda$ =%.2f' %l ,fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('PDF',fontsize=15)\nplt.show()","3d0bf30b":"u=6 # mean\ns=2 # standard deviation\n\nx=np.arange(0,15,0.1)\n\ny=(1\/(np.sqrt(2*np.pi*s*s)))*np.exp(-(((x-u)**2)\/(2*s*s)))\n\nplt.plot(x,y,'-')\nplt.title('Gaussian PDF: $\\mu$=%.1f, $\\sigma$=%.1f'%(u,s),fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('Probability density',fontsize=15)\nplt.show()","c42e3ebb":"fig, ax = plt.subplots(1, 4, sharey=True, squeeze=True, figsize=(14, 5))\nx = np.linspace(0, 1, 100)\nfor i in range(4):\n    f = np.mean(np.random.random((10000, i+1)), 1)\n    m, s = np.mean(f), np.std(f, ddof=1)\n    fn = (1\/(s*np.sqrt(2*np.pi)))*np.exp(-(x-m)**2\/(2*s**2))  # normal pdf            \n    ax[i].hist(f, 40, density=True, color=[0, 0.2, .8, .6]) \n    ax[i].set_title('n=%d' %(i+1))\n    ax[i].plot(x, fn, color=[1, 0, 0, .6], linewidth=5)\nplt.suptitle('Demonstration of the central limit theorem for a uniform distribution', y=1.05)\nplt.show()","855691f3":"from scipy.stats.distributions import norm\n\n# Some random data\ny = np.random.random(15) * 10\nx = np.linspace(0, 10, 100)\n\nx1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\nx2 = np.random.normal(6, 3, 10)\ny = np.r_[x1, x2] # r_ Translates slice objects to concatenation along the first axis.\nx = np.linspace(min(y), max(y), 100)\n\n# Smoothing parameter\ns = 0.4\n\n# Calculate the kernels\nkernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n\nplt.plot(x, kernels, 'k:')\nplt.plot(x, kernels.sum(1), 'r')\nplt.plot(y, np.zeros(len(y)), 'go', ms=10)","155d7bb9":"from scipy.stats import kde\n\nx1 = np.random.normal(-1, 0.5, 15)\n\n# parameters: (loc=0.0, scale=1.0, size=None)\n\nx2 = np.random.normal(6, 1, 10)\ny = np.r_[x1, x2]\n\n# r_ Translates slice objects to concatenation along the first axis.\n\nx = np.linspace(min(y), max(y), 100)\ns = 0.4   # Smoothing parameter\n\nkernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n\n# Calculate the kernels\ndensity = kde.gaussian_kde(y)\n\nplt.plot(x, kernels, 'k:')\nplt.plot(x, kernels.sum(1), 'r')\nplt.plot(y, np.zeros(len(y)), 'bo', ms=10)","7645da02":"xgrid = np.linspace(x.min(), x.max(), 200)\nplt.hist(y, bins=28, density=True)\nplt.plot(xgrid, density(xgrid), 'r-')","2a90e1fb":"# Create a bi-modal distribution with a mixture of Normals.\n\nx1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\nx2 = np.random.normal(6, 3, 10)\n\n# Append by row\nx = np.r_[x1, x2]\n\n# r_ Translates slice objects to concatenation along the first axis.\nplt.hist(x, bins=18, density=True)","41e98a12":"density = kde.gaussian_kde(x)\nxgrid = np.linspace(x.min(), x.max(), 200)\nplt.hist(x, bins=18, density=True)\nplt.plot(xgrid, density(xgrid), 'r-')","c2451cae":"x = np.random.normal(0.0, 1.0, 10000)\na = plt.hist(x,50,density='True')","9f08b14a":"print ('The empirical mean of the sample is ', x.mean())","0cfcacdf":"NTs=200\nmu=0.0\nvar=1.0\nerr = 0.0\nNPs=1000\nfor i in range(NTs):\n    x = np.random.normal(mu, var, NPs)\n    err += (x.mean()-mu)**2\n\nprint ('MSE: ', err\/NTs)","4883d916":"def Cov(X, Y):\n    def _get_dvis(V):\n        return [v - np.mean(V) for v in V]\n    dxis = _get_dvis(X)\n    dyis = _get_dvis(Y)\n    return np.sum([x * y for x, y in zip(dxis, dyis)])\/len(X)\n\nX = [5, -1, 3.3, 2.7, 12.2]\nX= np.array(X)\nY = [10, 12, 8, 9, 11]\n\nprint (\"Cov(X, X) = %.2f\" % Cov(X, X))\nprint (\"Var(X) = %.2f\" % np.var(X))\n\nprint (\"Cov(X, Y) = %.2f\" % Cov(X, Y))","d96d10d8":"MAXN=100\nMAXN=40\n\nX=np.array([[1,9],[3, 2], [5,3],[5.5,4],[6,4],[6.5,4],[7,3.5],[7.5,3.8],[8,4],\n[8.5,4],[9,4.5],[9.5,7],[10,9],[10.5,11],[11,11.5],[11.5,12],[12,12],[12.5,12],[13,10]])","00bc6b02":"plt.subplot(1,2,1)\nplt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\nplt.xlabel('Economic growth(T)',fontsize=15)\nplt.ylabel('Stock market returns(T)',fontsize=15)\nplt.gcf().set_size_inches((20,6))","2208cfdf":"X=np.array([[1,8],[2, 7], [3,6],[4,8],[5,8],[6,7],[7,7],[8,5],[9,5],[10,6],[11,4],[12,5],[13,3],[14,2],[15,2],[16,1]])\n\nplt.subplot(1,2,1)\nplt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\nplt.xlabel('World Oil Production(T)',fontsize=15)\nplt.ylabel('Gasoline prices(T)',fontsize=15)\nplt.gcf().set_size_inches((20,6))","e6b42e18":"def Corr(X, Y):\n    assert len(X) == len(Y)\n    return Cov(X, Y) \/ np.prod([np.std(V) for V in [X, Y]])\n\nprint (\"Corr(X, X) = %.5f\" % Corr(X, X))\n\nY=np.random.random(len(X))\n\nprint (\"Corr(X, Y) = %.5f\" % Corr(X, Y))","037218e5":"def list2rank(l):\n    #l is a list of numbers\n    # returns a list of 1-based index; mean when multiple instances\n    return [np.mean([i+1 for i, sorted_el in enumerate(sorted(l)) if sorted_el == el]) for el in l]\n\nl = [7, 1, 2, 5]\nprint (\"ranks: \", list2rank(l))\n\ndef spearmanRank(X, Y):\n    # X and Y are same-length lists\n    print (list2rank(X) )\n    print (list2rank(Y))\n    return Corr(list2rank(X), list2rank(Y))\n\nX = [10, 20, 30, 40, 1000]\nY = [-70, -1000, -50, -10, -20]\nplt.plot(X,'ro')\nplt.plot(Y,'go')\n\nprint (\"Pearson rank coefficient: %.2f\" % Corr(X, Y))\nprint (\"Spearman rank coefficient: %.2f\" % spearmanRank(X, Y))","028400a1":"X=np.array([[10.0, 8.04,10.0, 9.14, 10.0, 7.46, 8.0, 6.58],\n[8.0,6.95, 8.0, 8.14, 8.0, 6.77, 8.0, 5.76],\n[13.0,7.58,13.0,8.74,13.0,12.74,8.0,7.71],\n[9.0,8.81,9.0,8.77,9.0,7.11,8.0,8.84],\n[11.0,8.33,11.0,9.26,11.0,7.81,8.0,8.47],\n[14.0,9.96,14.0,8.10,14.0,8.84,8.0,7.04],\n[6.0,7.24,6.0,6.13,6.0,6.08,8.0,5.25],\n[4.0,4.26,4.0,3.10,4.0,5.39,19.0,12.50],\n[12.0,10.84,12.0,9.13,12.0,8.15,8.0,5.56],\n[7.0,4.82,7.0,7.26,7.0,6.42,8.0,7.91],\n[5.0,5.68,5.0,4.74,5.0,5.73,8.0,6.89]])","bebde264":"plt.subplot(2,2,1)\nplt.scatter(X[:,0],X[:,1],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)","ee749fee":"plt.subplot(2,2,2)\nplt.scatter(X[:,2],X[:,3],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\nplt.subplot(2,2,3)\nplt.scatter(X[:,4],X[:,5],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)","99778d3e":"plt.subplot(2,2,4)\nplt.scatter(X[:,6],X[:,7],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\nplt.gcf().set_size_inches((10,10))","735615fd":"5. How many items are there for USA? and for Mexico?\n\nThere are 29170 items for USA.\nThere are 643 items for Mexico.","64eb218a":"Examples:\n\n* Measures of size of living tissue (length, height, skin area, weight);\n* The length of inert appendages (hair, claws, nails, teeth) of biological specimens, in the direction of growth; presumably the thickness of tree bark also falls under this category;\n* Certain physiological measurements, such as blood pressure of adult humans.","9a9ded50":"The relative risk is the ratio of two probabilities. In order to get the relative risk  of early promotion, we need to consider the fraction of both probabilities.","5bd0c124":"# 4.1  Getting acquainted with data","8347ac5b":"# 4.3.1 Sample and Estimated Mean, Variance and Standard Scores\nIn continuation, we will deal with point estimators that are single numerical estimates of parameters of a population.","a8ca773a":"10. Describe an explain the result.\n\nTo avoid outlier we calculated median, which is giving middle value of a sample. Comparing calculated medians to means there is slightly diffrence for age per men and women and age per men and women with high income:\n\nage men and women:\n* mean: men - 39,4 women - 36,86\n* median: men - 38 women - 35\n\nage men and women with high income:\n* mean: men - 44,6 women - 42,13\n* median: men - 44 women - 41\n\nBigger diffrence occurs for hours per week per men and women:\n* mean: men - 42,43 women - 36,41\n* median: men - 40 women - 40\nIt could mean that there are low outiers values of hours worked for women or high outiers values of hours worked for men.","81406284":"11. Show the graphics and an explain the result.\n\nThe bigest amount of samples for women are in range 18-33 years. The highest bar if for approximately for 18-23 years and reach about 2500 samples. This reslut shows that the most samples came from young women. ","ed930875":"21. Explain the result\n\nSkewness of female and male population is in both cases positive. It means that it is skews right, so for high income the population go futher on the elderly side. For women coefficient is equal 0.39 and for men coefficient is equal 0.27. Bigger skewness means that it turns more.","c82280fa":"13. Show the graphics and an explain the result.\n\nBy changing the parameter density to true, the graph become normalized. Thanks to that we know how much propable is to be at each age for for women(blue bars) and men (indianred bars). ","6a579e4c":"**4.2.1.1 Mean**","61b82fe2":"7. Describe an explain the result.\n\nWe calculated diffrent ratios: \n* ratio between people with high income and size of dataframe is equal 24%, \n* ratio between women with high income and size of dataframe is equal 10%, \n* ratio between men with high income and size of dataframe is equal 30%.\n\nOn this basics we can deduce that men with have high income are 3 times more than women\n","3952d20f":"21. What do you obtained as result?","09179c4e":"# Exploring data collections using descriptive statistics\nNotebook created according to instruction from website: http:\/\/vargas-solar.com\/data-centric-smart-everything\/hands-on\/exploring-data-collections-using-descriptive-statistics\/","d60b4a9a":"**4.2.1.8 Relative Risk**\n\nLet\u2019s say that a person is \u201cearly\u201d promoted if he\/she is promoted before the age of 41, \u201con time\u201d if he\/she is promoted of age 41, 42, 43 or 44, and \u201clate\u201d promoted if he\/she is ascended to get income bigger than 50K after being 44 years old. Let us compute the probability of being early, on time and late promoted for men and women:","bc695589":"Let us see what is happening near the mode:","b672eaa9":"4. Describe an explain the result.\n\n\ndf.shape is property which return the number of rows and columns. In our case it is 32561 rows and 15 columns.","92dc1bfd":"**Definition**: Estimation is the process of inferring the parameters (e.g. mean) of a distribution from a statistic of samples drown from a population.\n\nFor example: What is the estimated mean \u03bc\u0302 of the following normal data?\n\nWe can use our definition of empirical mean:","9f7788de":"# 4.2.6      Kernel Density\nIn many real problems, we may not be interested in the parameters of a particular distribution of data, but just a continuous representation of the data. In this case, we should estimate the distribution non-parametrically (i.e., making no assumptions about the form of the underlying distribution) using kernel density estimation.","811262e2":"# 4.2 Explanatory Data Analysis\nThe data that come from performing a particular measurement on all the subjects in a sample represent our observations for a single characteristic like country, age, education, etc.\n\nObjective: to visualize and summarize the sample distribution, thereby allowing us to make tentative assumptions about the population distribution.","e473f2f5":"15. Show the graphics and an explain the result.\n\nIt is the same result as in point no. 13 but only for women. Interpreting the graphics we know how much propable is to be at each age for women.","5afb8a47":"Split people according to their gender into two groups: men and women.","2449815a":"**4.2.3.1 Outliner Treatment**","928db1fd":"# 4.2.3 Outliers\nOuliers are data samples with a value that is far from the central tendency.","255f5fac":"SciPy implements a Gaussian KDE that automatically chooses an appropriate bandwidth. Let\u2019s create a bi-modal distribution of data that is not easily summarized by a parametric distribution:","e4953b50":"**4.2.5.2 Normal distribution**\nThe normal, or Gaussian distribution is the most used one because it describes a lot of phenomena and because it is amenable for analysis. ","36891ccc":"19. Show the graphics and an explain the result.\n\nGraph presents cumulative propability function for age of men(blue) and women (indianared). We can deduce that its higer propapbility to choose younger sample for women than for men.  \n","b0f91dd5":"# **4.2.1 Summarizing the Data**\nThe data in can be categoricalfor which a simple tabulation of the frequency of each category is the best non-graphical exploration for data analysis. For example, we can ask what is the proportion of high- income professionals in our database:","606e0518":"There is still some evidence for our hypothesis!","236e7dfa":"When \u03c1=0, we cannot say that there is no relationship between the variables!\n\nPearson\u2019s coefficient only measures linear correlations!","3760fd93":"12. Show the graphics and an explain the result.\n\nWe can see histogram for men and women age on the same plot. It is diffrent than previous because size of bins changed. Now for women are 2 times more bins than for men. ","af0688c8":"# 4.2.5 Continuous Distribution\nThe distributions we have considered up to now are based on empirical observations and thus are called empirical distributions. As an alternative, we may be interested in considering distributions that are defined by a continuous function and are called continuous distributions.","b864e4d8":"**4.2.5.3 Central limit theorem**\nThe normal distribution is also important, because it is involved in the Central Limit Theorem:\n\nTake the mean of n random samples from ANY arbitrary distribution with a well-defined standard deviation \u03c3 and mean \u03bc. As n gets bigger the distribution of the sample mean will always converge to a Gaussian (normal) distribution with mean \u03bc and standard deviation \u03c3n\u221a.\n\nColloquially speaking, the theorem states the distribution of an average tends to be normal, even when the distribution from which the average is computed is decidedly non-normal. This explains the ubiquity of the Gaussian distribution in science and statistics.\n\n**Example:** Uniform Distribution\nThe uniform distribution is obviously non-normal. Let us call it the parent distribution.\n\nTo compute an average, two samples are drawn (n=2), at random, from the parent distribution and averaged. Then another sample of two is drawn and another value of the average computed. This process is repeated, over and over, and averages of two are computed.\n\nRepeatedly taking more elements (n=3,4\u2026) from the parent distribution, and computing the averages, produces a normal probability density.","486d9b7f":"**4.3.1.5 Pearson\u2019s correlation**","838c6ec0":"We obtained mean squared error for 200 normal distributions with 1000 elements. The MSE is a measure of the quality of an estimator. If it values are closer to zero, it is better.","e4204020":"14. Show the graphics and an explain the result\n\nIt is the same result as in point no. 13 but witch increased number of bins to 20 and selected only age of men. Interpreting the graphics we know how much propable is to be at each age for men","199181f7":" There are a lot of real world events that can be described with this distribution.\n\n* The time until a radioactive particle decays,\n* The time it takes before your next telephone call,\n* The time until default (on payment to company debt holders) in reduced form credit risk modeling.","1192ca4a":"# 4.2     Estimation\nAn important aspect when working with statistical data is being able to use estimates to approximate the values of unknown parameters of the dataset. In this section, we will review different kinds of estimators (estimated mean, variance, standard score, etc.).","c2db502b":"Let\u2019s see how many outliers we can detect in our example:","ed4ff8c2":"8. Describe an explain the result.\n\n    * Average age of men in dataframe is greater than average age of women by 2.6\n    * Average age of high-income men is greater than average age of high-income women age by 2.5 \n\nWhat's more people with high income are older.","16f6e026":"In fact, the library SciPy3 implements a Gaussian kernel density estimation that automatically chooses the appropriate bandwidth parameter for the kernel. Thus, the final construction of the density estimate will be obtained by:","5915a352":"18. Show the graphics and an explain the result.\n\nThe graph cosist two propability desnsity with 10 bars for each. Thanks to that we know how much propable is to be at each age for for women(blue bars) and men (indianred bars). ","4e213a69":"Let us compare visually the age distributions before and after removing the outliers:","35420d54":"**4.2.1.5 Data distributions**\n","862dc541":"Let us imagine that we have a set of data measurements without knowing their distribution and we need to estimate the continuous representation of their distribution. In this case, we can consider a Gaussian kernel to generate the density around the data. Let us consider a set of random data generated by a bimodal normal distribution. If we consider a Gaussian kernel around the data, the sum of those kernels can give us a continuous function that when normalized would approximate the density of the distribution:","7f87af0b":"17. Show the graphics and an explain the result.\n\nIt's the same case as in 16 but for women. Graphic presents distribution function which describes the probability that a random women age with a given probability distribution will be found to have a value less than or equal to that women age.","3c9e81bc":"1. What is the obtained result? What did you ask for in the previous command? Explain.\n\nObtained result is second row of database. It seems like we ask for rows from 1 to 2, but last number of row is not included. Database rows starts from 0, so we get second row (1 is included).","bead9997":"21. What does the figure shows?\n\nFigure present Kernel density estimation, which is mixture of two Gaussians centered around -1 and 6, shown with solid red curve.","b5299f49":"Exercise: Obtain for the Anscombe's quartet [2] given in the figures bellow, the different estimators (mean, variance, covariance for each pair, Pearson's correlation and Spearman's rank correlation.","5f26fb7c":"6. What is the age of the most represented people?\n\nThe age of the most represented people is 36 years old.\n","f99e5a52":"**4.2.1.3 Sample Median**","8c9f6f67":"9. Describe an explain the result.\n\nThe mean, variance and standard deviation of age and hours per week for women and men were calculated. \n\nMean of women's and men's age is the same as in previous point. Standard deviation for women is a little lower. That means that the spread of age for women is closer to mean value.\n\nMean of hours per week for men (42.42) is higher than for women(36.41). This impiles that men work longer. It may be the reason why more men have higher salaries. Standard deviation is almost equal for both genders.\n\n","13fc0f4b":"**4.3.1.4 Covariance**\n\nCovariance is a measure of the tendency of two variables to vary together.\n\nIf we have two series X and Y with X={xi} and Y={yi}, and they vary together, their deviations xi\u2212\u03bcX and yi\u2212\u03bcY tend to have the same sign.\n\nIf we multiply them together, the product is positive, when the deviations have the same sign, and negative, when they have the opposite sign. So, adding up the products gives a measure of the tendency to vary together.[](http:\/\/)","6e33a468":"If we think that outliers correspond to errors, an option is to trim the data by discarting the highest and lowest values.","a3e506f9":"**4.2.5.1 Exponential distribution**\nThe parameter \u03bb determines the shape of the distribution, the mean of the distribution is 1\/\u03bb and its variance is 1\/\u03bb2. The median is ln(2)\/\u03bb.","c7d86d6e":"**4.2.1.2 Sample Variance**","318eff25":"Focus on high-income professionals separated by sex","b27c3c42":"10. Show the graphics and an explain the result.\n\nThe bigest amount of samples for men are in range 27-45 years. The highest bar if for approximately for 34 years and reach about 2500 samples.","49850644":"2. Describe an explain the result.\n \nDataframe was created and columns were named in order to better visiualise the datebase. Then thanks to function df.head() first 5 rows of dataframe were displayed. ","47971047":"Let us create some examples of positive and negative correlations like those showing the relations of stock market with respect to the economic growth or the gasoline prices with respect to the world oil production:","f9d59f9d":"**4.2.1.7 Measuring Asymmetry**","0a8c683d":"**4.3.2.6 Spearsman\u2019s rank correlation**\n\nPearson\u2019s correlation works well if the relationship between variables is linear and if the variables are roughly normal. But it is not robust in the presence of outliers.\n\nSpearman\u2019s rank correlation is an alternative that mitigates the effect of outliers and skewed distributions. To compute Spearman\u2019s correlation, we have to compute the rank of each value, which is its index in the sorted sample.\n\nFor example, in the sample {7, 1, 2, 5} the rank of the value 5 is 3, because it appears third if we sort the elements.\n\nThen, we compute the Pearson\u2019s correlation, but for the ranks.","d2920169":"**Discussion**\n\nAfter exploring the data, we obtained some apparent effects that support our initial assumptions. For example, the mean age for men in our dataset is 39.4 years; while for women, is 36.8 years. When analyzing the high-income salaries, the mean age for men increased to 44.6 years; while for women, increased to 42.1 years. When the data were cleaned from outliers, we obtained mean age for high-income men: 44.3, and for women: 41.8. Moreover, histograms and other statistics show the skewness of the data and the fact that women used to be promoted a little bit earlier than men, in general.","74c0379a":"3. Describe and explain the result. Compare with the previous one.\n\nWith command df.tail() we can display 5 last rows of dataframe, whereas previous command df.head() displays first 5 rows.","dea548f0":"20. Explain the result.\n\nDifference in mean samples is equal 2.57 year. Thats mean that each female participant in survey is approximately 2.57 younger that men who also participated. Futhermore, it could mean that women start working earlier.","dfdad909":"16. Show the graphics and an explain the result.\n\nGraphic presents distribution function which describes the probability that a random men age with a given probability distribution will be found to have a value less than or equal to that man age."}}