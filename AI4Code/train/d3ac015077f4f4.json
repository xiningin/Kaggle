{"cell_type":{"c1c182fa":"code","10969986":"code","52929e66":"code","b7467e61":"code","e51efc39":"code","18e769d0":"code","0282def9":"code","27397885":"code","3e9dd43c":"code","835b86b1":"code","4dbbbd37":"code","42b9b6b8":"code","105eceee":"code","2f04a1da":"code","39f0939c":"code","56e6aa91":"code","31aeddfd":"code","34b30ec0":"code","48ac8c30":"code","77f40333":"code","99da0ed3":"code","fc08d96f":"code","5cce134c":"code","6b74b914":"code","15f74aef":"code","aa7d308c":"code","ddbd755a":"code","03c04a20":"code","acec2bb1":"code","6dfd5c5d":"code","84cc03dd":"code","55be73ca":"code","8a21fa6a":"code","736ee200":"markdown","3b311228":"markdown","0b9b7f3c":"markdown","4ffedd3f":"markdown","07254483":"markdown","1ed3debe":"markdown","d402622d":"markdown","7760fa34":"markdown","bdb84ee2":"markdown","0670c2ab":"markdown","3733574e":"markdown","fa7356e4":"markdown","cb76484d":"markdown","a834ac94":"markdown","f698d78e":"markdown","7e5da34b":"markdown","2c6122bc":"markdown","149ae4a8":"markdown","b358578a":"markdown","f222c82b":"markdown","2ac8ffa4":"markdown","d1d8c8d4":"markdown","9ff00f28":"markdown","23faf6bf":"markdown","08ac46bc":"markdown","5d4b581a":"markdown","afbb3da9":"markdown","51aa99bc":"markdown","8e206e93":"markdown","ca68b3c9":"markdown","7f8cafab":"markdown","870c0df8":"markdown","dd5a8265":"markdown","7ad91310":"markdown","140e1d66":"markdown","1c3b46de":"markdown","e18838cc":"markdown","38030c00":"markdown"},"source":{"c1c182fa":"import pandas as pd\nimport seaborn as sb\nfrom matplotlib import pyplot as plt\nimport numpy as np","10969986":"activities = pd.read_csv('..\/input\/strava-ride-or-run-classification\/activities_Miguel__Training-Validation.csv',index_col=0)\nprint(activities.info())\nactivities.head()","52929e66":"social_features = [\n     'kudos_count',\n     'comment_count',\n     'athlete_count',\n     'total_photo_count',\n]\n\nperformance_features = [\n     'distance',\n     'moving_time',\n     'elapsed_time',\n     'max_speed',\n     'total_elevation_gain',\n     'elev_high',\n     'elev_low',\n     'achievement_count',\n     'pr_count',\n]","b7467e61":"activities.drop(\n    activities[\n        (activities['type']!='Run') &\n        (activities['type']!='Ride')\n    ].index,\n    inplace = True\n)\n\nactivities.drop('average_speed',axis=1,inplace=True)","e51efc39":"performance_pair_plot = sb.pairplot(\n    activities,\n    vars = performance_features,\n    hue = 'type',\n    diag_kind = 'hist',\n    palette = 'colorblind'\n)","18e769d0":"performance_pair_plot = sb.pairplot(\n    activities,\n    vars = social_features,\n    hue = 'type',\n    diag_kind = 'hist',\n    palette = 'colorblind'\n)","0282def9":"activities_performance = activities[performance_features]\nactivities_performance.head()","27397885":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaled_performance = scaler.fit_transform(activities_performance)","3e9dd43c":"from sklearn.decomposition import PCA","835b86b1":"pca = PCA(n_components=9)\nperformance_pca = pca.fit_transform(scaled_performance)","4dbbbd37":"plt.figure(figsize=(8,6));\nsb.scatterplot(x = performance_pca[:,0],y = performance_pca[:,1],hue=activities['type'],cmap='plasma');\nplt.xlabel('First principal component');\nplt.ylabel('Second Principal Component');","42b9b6b8":"plt.figure(figsize=(12,6))\nsb.barplot(\n    y = pca.explained_variance_ratio_,\n    x = [f'Component {n+1}' for n in range(pca.n_components) ]\n)\nplt.ylabel('Ratio of explained variance');","105eceee":"components_dataframe = pd.DataFrame(\n    pca.components_,\n    columns = performance_features,\n    index = [f'Component {n+1}' for n in range(pca.n_components_) ]\n)\ncomponents_dataframe","2f04a1da":"ann = components_dataframe.applymap(\n    lambda x:{-1:'-',1:'+'}.get(np.sign(x).astype('int'),'0')\n)\n\nplt.figure(figsize=(15,10))\nsb.heatmap(\n    components_dataframe.applymap(np.abs),\n    annot = ann,\n    fmt = '',\n    cmap = 'rocket'\n);\nax = plt.gca()\nax.tick_params(axis='x', labelrotation=60)\nfor label in ax.xaxis.get_ticklabels():\n    label.set_horizontalalignment('right')","39f0939c":"sb.scatterplot(y = activities_performance['distance'],x = performance_pca[:,0],hue=activities['type']);","56e6aa91":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\n# Define a pipeline to search for the best PCA truncation\n# The concatenated steps in the pipeline are : scale->pca transform -> logistic classifier\npipe = Pipeline(steps=[('scaler',StandardScaler()),('pca', PCA()), ('logistic', LogisticRegression(max_iter=10000, tol=0.1))])","31aeddfd":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    activities_performance,\n#     pd.get_dummies(activities['type'])['Ride'],\n    activities['type'],\n    test_size=0.25,\n    random_state=42\n)","34b30ec0":"fig,[ax1,ax2] = plt.subplots(ncols=2,figsize = (10,5),sharey=True)\nsb.countplot(x = y_train,ax = ax1)\nax1.set_title('Training')\nsb.countplot(x = y_test,ax = ax2)\nax2.set_title('Test');","48ac8c30":"pipe.fit( X_train, y_train );","77f40333":"y_predictions = pipe.predict(X_test)","99da0ed3":"from sklearn.metrics import plot_confusion_matrix, confusion_matrix, classification_report","fc08d96f":"plt.figure(figsize=(6,6))\nplot_confusion_matrix(pipe,X_test,y_test,ax=plt.gca());","5cce134c":"print(\n    classification_report(y_test,y_predictions)\n)","6b74b914":"fig,[[ax1,ax2],[ax3,ax4]] = plt.subplots(ncols=2,nrows=2,figsize = (15,15),sharey='row',sharex='row')\n\n# Scatter plots for distance and elevation gain \n\n#Scatter plot for true classes\nsb.scatterplot(\n    x = X_test['distance'],\n    y = X_test['total_elevation_gain'],\n    hue = y_test,\n    ax = ax1\n)\nax1.set_title('True classes');\n\n#Scatter plot for predicted classes\nsb.scatterplot(\n    x = X_test['distance'],\n    y = X_test['total_elevation_gain'],\n    hue = y_predictions,\n    ax = ax2\n)\nax2.set_title('Predicted');\n\n# Scatter plots for 2 first PC\nX_test_transformed = pipe[:-1].transform(X_test) #I am applying the pipe line until the pc step\n\n#Scatter plot for true classes\nsb.scatterplot(\n    x = X_test_transformed[:,0],\n    y = X_test_transformed[:,1],\n    hue = y_test,\n    ax = ax3\n)\nax3.set_title('True classes');\nax3.set_xlabel('First PC')\nax3.set_ylabel('Second PC')\n\n#Scatter plot for predicted classes\nsb.scatterplot(\n    x = X_test_transformed[:,0],\n    y = X_test_transformed[:,1],\n    hue = y_predictions,\n    ax = ax4\n)\nax4.set_title('Predicted');\nax4.set_xlabel('First PC')\n\nfig.suptitle('Compare predictions with true classes');","15f74aef":"from sklearn.model_selection import GridSearchCV","aa7d308c":"param_grid = {'pca__n_components':[1,2,3,4,5,6,7,8,9]}\ngrid = GridSearchCV(\n    pipe,\n    param_grid = param_grid,\n    verbose = 3,\n    scoring = 'f1_weighted'\n)","ddbd755a":"grid.fit(X_train,y_train);","03c04a20":"print(\n    '\\n'.join(   f'{ind}: {val}' for ind,val in grid.best_params_.items() ) \n)","acec2bb1":"results = pd.DataFrame(grid.cv_results_)\nresults","6dfd5c5d":"fig, (ax0,ax1) = plt.subplots(nrows=2,sharex=True,figsize=(6,8))\n\n# Plot of the explained variance ratio of every component\nax0.plot(\n    np.arange(1, pipe['pca'].n_components_ + 1),\n    pipe['pca'].explained_variance_ratio_,\n    'k-o',\n    linewidth=2\n)\nax0.axvline(grid.best_params_['pca__n_components'],ls='--',c='k',label = 'Chosen number\\n of components')\n\nax0.legend(prop=dict(size=12))\nax0.set_ylabel('PCA explained variance ratio')\n\n# Plot of the score as a function of the number of components\nresults.plot(\n    x = 'param_pca__n_components',\n    y = 'mean_test_score',\n    yerr = 'std_test_score',\n    style='-o',\n    c = 'k',\n    capsize=4,\n    ax = ax1,\n    legend = False\n)\nax1.set_ylabel('classes weighted average of f1 score')\n\n\nax1.set_xlabel('n components');","84cc03dd":"plt.figure(figsize=(6,6))\nplot_confusion_matrix(grid,X_test,y_test,ax=plt.gca());","55be73ca":"test_data = pd.read_csv('..\/input\/strava-data\/strava_full_data.csv')","8a21fa6a":"test_data.columns","736ee200":"# Start by importing the modules I will use","3b311228":"Make a PCA decomposition fit and transform the data","0b9b7f3c":"### Pair plot of social data","4ffedd3f":"# Motivation\n\nI am currently learning some data science with python. I am following this course in udemy:\n\n> [Python for Data Science and Machine Learning Bootcamp](https:\/\/www.udemy.com\/course\/python-for-data-science-and-machine-learning-bootcamp\/)\n\n\nIn this notebook I want to practice some of the concepts and skills that I have learned so far:\n\n- Some general exploratory data analysis (EDA)\n- Principal Component Analysis\n- Logistic Regressin\n- Grid search cross validation (CV)\n\n## Some background\n\nI am an amateur cyclist and occasional runner who uses *STRAVA* every time I get on my bike or put my trainers on. In case you don't know it, [*STRAVA*](https:\/\/www.strava.com\/) (which is Swedish for \"strive\") is an app that allows you to monitor and register your trainings and then share them with other users in a social network style. *STRAVA* is mostly used by cyclist and running folk.\n\nEvery time you register an activity it keeps track of data like distance, moving time, elevation gain, average speed, heart rate, and so on. Thanks to their API, it is relatively easy to obtain your activities data, provided you are a registered user of course. Explainining how to get all your activities data is out of the scope of this notebook (although I plan on uploading a notebook about it in the future), however, if you are curious about that, check the following links\n\n- [1 - Intro and accessing Strava API with Postman - Strava API for Beginners](https:\/\/www.youtube.com\/watch?v=sgscChKfGyg)\n\n- [3 - Using Strava API with Python - Strava API for Beginners\n](https:\/\/www.youtube.com\/watch?v=2FPNb1XECGs)\n\n- [Strava API v3 reference](https:\/\/developers.strava.com\/docs\/reference\/)\n\n## The task\n\nI will provide a dataset of my activities and the objective will be to train an logistic regression model\nthat works only with a few principal components that is capable to predict if an activity was of type 'Ride' or type 'Run'. The task may not be very challenging, but I think is a good exercise for a beginner working in a field that is of my interest. Additionaly I want to perform a grid search CV to optimize the number of components and then use my model to perform predictions with other peoples strava datasets.","07254483":"Let's see what the data looks like after being transformed to principal components","1ed3debe":"## As usual, split my data in train and test sets. X will be the performance data and y the type of the activity","d402622d":"### Complete results in a dataframe","7760fa34":"## Start with some pair plots of the data set\n### Pair plot of performance data","bdb84ee2":"# Principal Component Analysis\n\nI will start by defining a data frame for the performance data","0670c2ab":"### Plot of the ratio of the components to the explained variance","3733574e":"# Load the data\n\nthe data of my activities is on the csv file called ```activities_Miguel__Training-Validation.csv``` ","fa7356e4":"## Meaning of the columns\n\nI grouped some of the columns in two groups: performance_features and social_features.\n\n#### Performance features\n\nDistances and heigths are in meters, while time is on seconds (it is called international system of units)\n\n- distance: distance of the activity.\n- moving_time: time where you are actually doing something (coffee stops don't count).\n- elapsed_time: total time STRAVA is registering.\n- total_elevation_gain: positive amount of climbing.\n- achievement_count: number of time you get a 3rd, 2nd or personal record in a segment.\n- pr_count: number of personal records.\n- max_speed: in meters\/s. I will not use average_speed because it is just distance\/moving_time.\n- elev_high: maximumn height reached.\n- elev_low: minimum\n\n\n#### social features\n- kudos_count: A kudo is the name in strava for the likes given by friends.\n- comment_count: number of comments.\n- athlete_count: if this was a group activity then it is the number of companions in the activity. If it is a solo activiy then it is 0.\n- total_photo_count: Total number of photos uploaded in an activity.\n\nThen there is the column that I will use for classification: **type**. **type** stands for the sport of the activity: Ride, Run, Walk, Hike, Surf,.... Since I am only interested in classifying Rides or Runs I will just keep those two labels\n\n","cb76484d":"## Fit the grid estimator","a834ac94":"# Grid Search CV","f698d78e":"### Plot of the score as a function of the number of components","7e5da34b":"Then I will scale the dataframe of performance to 0 mean and unit standard deviation","2c6122bc":"The optimal number of principal components seem to be 4. 5, 6, and 9 give also nice results but 4 is simpler to evaluate.","149ae4a8":"The two classes are not very well balanced. I need to run more often.","b358578a":"### Distribution of classes in the train and test sets","f222c82b":"## Fit the pipeline","2ac8ffa4":"### Visualize the predictions for two selected features and the 2 first principal components","d1d8c8d4":"### Plot of the confusion matrix","9ff00f28":"# Some exploratory data analysis of my strava activities ","23faf6bf":"It looks like we can describe the 70% variance with the first 3 components","08ac46bc":"## Results of the grid search\n\n### Best hyperparameters ( number of PCs)","5d4b581a":"### Classification report","afbb3da9":"## Build the grid estimator.\n\nA neat feature of pipelines is that they can crosvalidated for different hyperparameters in a really simple way. You just have to introduce the values of the parameters for different steps of the pipeline with the following convention\n\n```python\nparam_grid = {\n    '<step_name>_<parameter_name>':'<list of values>',\n    ...\n}\n```","51aa99bc":"distance, moving time and elevation gain are of great importance for the first component, whihc explains almost the 50% of the variance","8e206e93":"## Evaluate the performance of the model","ca68b3c9":"The value of the first PC is a good indicator of the type of activity","7f8cafab":"# Logistic regression with principal components\n\n\nI will train a logistic classifier that classifies the activities according to their type: Run and Ride. However,\nI want a model that classifies the activities according to the values of some of the first principal components,\ninstead of using all the features as input directly. In order to do this the data needs to be scaled, then transformed to\nthe principal components and finally inserted in the logistic classifier.\n\nThe easiest way of doing this in sklearn is by using a pipeline, i.e., a concatenation of different transformers and an estimator at the end.","870c0df8":"### Relation of the components to the original data\n\nTo interpret the principal components, it is useful to see how the different features contribute to each of them. This information is in the loadings of the principal components. I will make a dataframe with the loadings of the PCs","dd5a8265":"Keep only rides and run and since average_speed = distance \/ moving_time, I will also drop this column because it does not add more information","7ad91310":"## Test the optimal estimator with the test dataset","140e1d66":"As can be seen, the model performs reasonably well. Do not stop there and see if it can be improved by selecting the optimal number of components. I will do this with a gridsearch CV","1c3b46de":"A heat map will help to see the contribution of each feature in the components. I make a heat map showing the absolute value of the loadings and a + or - sign, indicating if the component value increases or decreases withe the corresponding feature","e18838cc":"# Test the model with external data","38030c00":"## Make some predictions"}}