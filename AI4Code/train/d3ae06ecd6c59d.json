{"cell_type":{"b88827b0":"code","b3c67c14":"code","1e51d30f":"code","3fef63af":"code","0a1cb73f":"code","2089d873":"code","c3ae40c6":"markdown","ddcc9109":"markdown","22abe1ce":"markdown","684a2ef0":"markdown","bdfd170d":"markdown","12ec8f32":"markdown"},"source":{"b88827b0":"### Import libraries\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nfrom keras.applications.densenet import preprocess_input, DenseNet201\n## define params\ntrain_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\nimg_size = 256\nbatch_size = 64","b3c67c14":"ids = train_df['image_name'].values\n# Takes the id of each image\nn_batches = len(ids) \/\/ batch_size + 1\n# Number of batches = length of ids divided by batch size + 1","1e51d30f":"## Resize to square\ndef resize_to_square(im):\n    # Old size\n    old_size = im.shape[:2] # old_size is in (height, width) format\n    ratio = float(img_size)\/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    # We use this new size to resize images\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    # Delta width is the change in width\n    ## Same for delta height\n    top, bottom = delta_h\/\/2, delta_h-(delta_h\/\/2)\n    left, right = delta_w\/\/2, delta_w-(delta_w\/\/2)\n    ## Define top and bottom dim\n    ## Define left and right too\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n    ## Square image\n    return new_im\n\ndef load_image(path, ids):\n    image = cv2.imread(f'{path}{ids}-1.jpg') # read new image\n    new_image = resize_to_square(image) # resize to square\n    new_image = preprocess_input(new_image) # now preprocess inputs for DenseNet\n    return new_image","3fef63af":"from keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K\n\n# input image\ninp = Input((256,256,3))\n# DenseNet model\nbackbone = DenseNet121(input_tensor = inp, include_top = False)\n# To make sure we do not load the full thing\n# we load the densenet output\nx = backbone.output\n# Make the output smaller (from 1024 output params)\nx = GlobalAveragePooling2D()(x)\n# Expands dimensions (very useful)\nx = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n# Finally pools to 4\nx = AveragePooling1D(4)(x)\n# final output\nout = Lambda(lambda x: x[:,:,0])(x)\n\nm = Model(inp,out)","0a1cb73f":"features = {}\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_pets = ids[start:end]\n    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n    for i,pet_id in enumerate(batch_pets):\n        try:\n            batch_images[i] = load_image(\"..\/input\/siim-isic-melanoma-classification\/train_images\/\", pet_id)\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,ids in enumerate(batch_pets):\n        features[ids] = batch_preds[i]","2089d873":"train_feats = pd.DataFrame.from_dict(features, orient='index')\ntrain_feats.to_csv('train_feats.csv') # convert to csv","c3ae40c6":">> **Summary of above cell:**\n+ It defines inputs and basic parameters such as batch size and image size.","ddcc9109":">> **Summary of above cell:**\n+ Defines ids (list of images)\n+ Sets number of batches.","22abe1ce":">> Summary of above cell:\n+ Applies our model to extract features\n+ Predicts the features\n+ Creats a dataframe for our features","684a2ef0":"Welcome. In this notebook I shall give a detailed overview of the popular tabular approach that a lot of people that are using. I used Dieter's notebook as a baseline and I will give you an overview of what this actually is.","bdfd170d":">> Summary of above cell:\n+ Resizes to square:\n    + This defines all the necessary parameters for a resize (the dimensions and length of images(\n+ Loads image","12ec8f32":">> Summary of above cell:\n+ Defines model with DenseNet\n+ Post-processes input from 1024"}}