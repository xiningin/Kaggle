{"cell_type":{"e9117170":"code","639efe74":"code","ef7fed0c":"code","451e2766":"code","573f76d1":"code","7a5140fa":"code","66c7d9a6":"code","3031beb6":"code","fc930ce4":"code","2223acd8":"code","9bc19cc4":"code","d50fc136":"code","0cd1fad4":"code","fa19143e":"code","ae21d001":"code","249422a7":"code","04f3f4b2":"code","570e6e82":"code","46c33ff4":"code","3838590d":"code","f2685b87":"markdown","24fdf633":"markdown","33d0416a":"markdown","2f6c6578":"markdown","9a6166ac":"markdown","bcc26c46":"markdown","31503b8b":"markdown","11dacc61":"markdown","a8849870":"markdown","a700d889":"markdown","329513e0":"markdown"},"source":{"e9117170":"# to open files\nimport pandas as pd\n\n# for numerical operations\nimport numpy as np\n\n# sci-kit learn to measure distances\nfrom sklearn.metrics.pairwise import pairwise_distances","639efe74":"header = ['user_id', 'item_id', 'rating', 'timestamp']\nmovielens_data = pd.read_csv('..\/input\/movielens-100k-dataset\/ml-100k\/u.data', sep='\\t', names=header)\nmovielens_data.head()","ef7fed0c":"movielens_data.shape","451e2766":"n_users, n_movies  = movielens_data['user_id'].nunique(), movielens_data['item_id'].nunique()\nn_users, n_movies","573f76d1":"# We can also use panda's pivot_table to create this 2D matrix. But I'll keep it simple by doing it mannually.\n# https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.pivot_table.html\n\ntrain_data_matrix = np.zeros((n_users, n_movies))\n\nfor line in movielens_data.itertuples():\n    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n    \ntrain_data_matrix.shape","7a5140fa":"train_data_matrix","66c7d9a6":"user_distances = pairwise_distances(train_data_matrix, metric=\"cosine\")\n\n# \".T\" below is to transpose our 2D matrix.\ntrain_data_matrix_transpose = train_data_matrix.T\nmovie_distances = pairwise_distances(train_data_matrix_transpose, metric=\"cosine\")\n\nuser_distances.shape, movie_distances.shape","3031beb6":"user_distances","fc930ce4":"movie_distances","2223acd8":"user_similarity = 1 - user_distances\nmovie_similarity = 1 - movie_distances","9bc19cc4":"user_similarity","d50fc136":"movie_similarity","0cd1fad4":"idx_to_movie = {}\n\nwith open('..\/input\/movielens-100k-dataset\/ml-100k\/u.item', 'r', encoding=\"ISO-8859-1\") as f:\n    for line in f.readlines():\n        info = line.split('|')\n        idx_to_movie[int(info[0])-1] = info[1]\n\nmovie_to_idx = {v: k for k, v in idx_to_movie.items()}","fa19143e":"idx_to_movie[0], idx_to_movie[1], idx_to_movie[2], idx_to_movie[3] ","ae21d001":"movie_to_idx['Toy Story (1995)'], movie_to_idx['GoldenEye (1995)'], movie_to_idx['Four Rooms (1995)'], movie_to_idx['Get Shorty (1995)'] ","249422a7":"# What we do is, we just that movie's column & sort it by value.\n# Those value represents \"similarity\" so, we just need to sort it & pick first \"k\" values.\n\ndef top_k_movies(similarity, mapper, movie_idx, k=6):\n    return [mapper[x] for x in np.argsort(similarity[movie_idx,:])[:-k-2:-1]]","04f3f4b2":"favorite_movie_name = 'Batman Forever (1995)'\nmovie_index = movie_to_idx[favorite_movie_name]\nmovie_index","570e6e82":"how_much_movie_to_show = 7\n\nmovies = top_k_movies(movie_similarity, idx_to_movie, movie_index, k = how_much_movie_to_show)\nmovies[1:how_much_movie_to_show + 1]","46c33ff4":"favorite_movie_name = 'Star Wars (1977)'\nmovie_index = movie_to_idx[favorite_movie_name]\nmovie_index","3838590d":"how_much_movie_to_show = 7\n\nmovies = top_k_movies(movie_similarity, idx_to_movie, movie_index, k = how_much_movie_to_show)\nmovies[1:how_much_movie_to_show + 1]","f2685b87":"## Again, good recommendations.<br>\"Return of the Jedi (1983)\" & \"Empire Strikes Back, The (1980)\" are also \"Star Wars\" movies.\n\n### Our goal from this lesson was to learn very basic method which we can use to recommend items.<br> We learned simple yet effective methods which we can use in recommendation.\n\n# Summary\n\n* We saw 2 types of recommendation \"User based\" & \"Item based\"\n* We saw, how to create 2D matrix which we can use to create distances between each movie & user.\n* We learned, we can use cosine distance to calculate distance between them.\n* We saw how we can recommend movies to a user by finding k nearest movies from that movie which user like.\n\n## Upvote this kernel if you have learned something from it.\n## Tell me if you have any kind of doubts \/ questions in comment section below.\n\n## See you in the next lesson \ud83d\udc4b","24fdf633":"We can see, `user_distances` & `movie_distances` are square matrices as expected.<br>\n### user_distances is distance of each user with other users & movie_distances is distance of each movie with other movies.\n\n## What do we mean by \"distance\" here?\n\n### \"Distance\" here means, how much far two user are far from each other in terms of their favorite movies.<br>\nLike, let say, <br>\n* User **A** likes 6 movies with 5 rating to each of them. <br>\n* User **B** likes 4 movies with 5 ratings.<br><br>\n\nNow, all 4 of those movies, are from 6 movies which user **A** likes. <br>\nSo, distance between user **B** & user **A** is less compared to user **C** whose favorite movies have no intersection with **A** or **B**.\n\n![collaborative filtering](https:\/\/distilledai.com\/wp-content\/uploads\/2020\/04\/collaborative-filtering.png)\n<br><br>\n* Here we can see, user **E**'s choices are matching with user **B** & **C** higher compared to others.<br>\n* So, distance between them will be lower compared to others.<br><br>\n\n* Similarly, item **3** is more matching with **4** compared to others.<br>\n* So, distance will be lower between them.","33d0416a":"## Cool !!\n\n## What a Recommendation..<br>\n\n### \"Batman Forever (1995)\" movie is similar to \"Batman (1989)\" & \"Batman Returns (1992)\"<br>And \"Cliffhanger (1993)\" is also an Action movie.<br>\n\n### Let's find similar movies to \"Star Wars (1977)\" movie.\n","2f6c6578":"Let's read the data","9a6166ac":"### Now, Above matrices represents \"similarities\".\n\nNow, let's open file which contain all the movie's names.","bcc26c46":"### Above values represent \"distances\"<br>So, let's make \"similarity\" matrices from them.<br>We can calculate \"similarity\" just by subtracting every value from 1.","31503b8b":"This 2D matrix have `943` rows & `1682` columns.<br>\n### Each raw represents a user, each column represents a movie.<br>\n\nWhiever movie a user have seen, that values for that user will be the rating of that movie, given by that user. Other values will be zero for that user.<br>\n\nFor e.g.<br>\nLet's say user **A** have watched `5` movies out of total `1682` movies.<br>\nSo, user **A**'s raw will have `5` non-zero values filled with ratings of those `5` movies.<br>\nAll other `1677` columns (`1682` - `5`) will be `0` in that user's raw.<br><br>\n\n### Now, let's calculate user_distances & movie_distances.<br>\n* `user_distances` is, distances of a user with every other user.<br>\n* `movie_distances` is, distances of a movie with every other movie.<br>\n\n### We will use cosine similarity to measure distance.\nWhy?<br>\nBecause, cosine distance works comparatively good on vectors than euclidean etc. metrics.<br>\nHere's the formula which is used to calculate cosine distance.<br>\n![cosine-distance](https:\/\/distilledai.com\/wp-content\/uploads\/2020\/04\/cosine-similarity.png)","11dacc61":"In the [previous lesson](https:\/\/www.kaggle.com\/prashantkikani\/are-you-being-sarcastic-sarcasm-detection-nlp\/), we learned basics of Natual Language Processing(NLP) by trying to solve Sarcasm detection problem & hands-on experience with Python code.\n\nToday in this lesson, we will learn the basics of recommendation by recommending Movies to users !<br>\nLogic will be same to recommend TV shows.<br>\n\n![recommendation](https:\/\/qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/06\/everything_is_reco_800px_web.jpg)\n<center>Netflix recommendation to it's users<\/center>\n<br>\nWe will use [MovieLens](https:\/\/movielens.org\/) dataset to recommend movies.<br><br>\nTechnique we are going to use is known as \"Collaborative filtering\" in technical terms.\n\n## Let's first understand how recommendation works in a nutshell.\n\nWe use simple heuristics to suggest items. Like,\n\n* User based\n    * Let\u2019s say we want to show recommendations to user **A**.\n    * In this method, we try to find a similar user **B** who also tends to like items that user **A** likes.\n    * So, we recommend user **B**\u2018s other liked items to user **A**.\n    * Logic behind this is, similar people may like similar items.\n    ![user-based](https:\/\/miro.medium.com\/max\/700\/0*o0zVW2O6Rv-LI5Mu.png)\n* Item based\n    * Let\u2019s say one user buy item **P**.\n    * Now, from all the user\u2019s data, there\u2019s one item **S** which users bought almost all time whenever item **P** get bought.\n    * So, we recommend item **S** to users whenever they buy item **P**.\n    * Logic behind this is, similar items may be sold together.\n    ![item-based](https:\/\/miro.medium.com\/max\/667\/1*oYpMnPQFZaiZQizgVWBpoA.png)\n\nAbove 2 methods are very basic ones. But they shows how simple recom mendation algorithms work.<br>\n### Latest recommendation systems we see in day to day lives in Netflix & Amazon uses much more data like user's personal information etc.<br>\n\nLet's learn by coding now.\n","a8849870":"* `idx_to_movie` is a dictionary which maps movie_index to movie name<br>\n* `movie_to_idx` is a dictionary which maps movie name to movie_index<br>\n<br>\nNow, let's write a function to given a movie name, find `k` closest movies to it.","a700d889":"### We can see we have 100k ratings from 943 unique users to 1682 unique movies.\nNow let's create a sparse 2D matrix with user ID & item ID(movie ID).","329513e0":"## Let's find out similar movies of \"Batman Forever\" movie.<br>\n### We can recommend these movies to users who like \"Batman Forever\" movie."}}