{"cell_type":{"42ed3597":"code","c891f12c":"code","651ab68d":"code","bbc09170":"code","3fc98217":"code","2490722d":"code","2423c774":"code","42b6faf0":"code","bc55df54":"code","8b53aaf4":"code","3a64c45c":"code","31f2d3a7":"code","4c0fedcf":"code","601a698c":"code","e7a26b5e":"code","e90db308":"code","06962e4a":"code","d34c8ca1":"code","695ea397":"code","ddee23ed":"code","c1a9dbde":"code","f84a5b9e":"code","307f34af":"code","c80b81e3":"code","1875f4d3":"code","d1326345":"code","d5d60b1c":"code","a5ba7760":"code","82c525f7":"code","476bf0e6":"code","e2f91abf":"code","6348a10f":"code","09c32f98":"code","679c98df":"code","32d8a175":"code","4bf61a46":"code","32e0f7c1":"code","31e8e65e":"code","2bbdb259":"code","221f4df5":"code","9196e3f1":"code","a8621510":"code","20bf3793":"code","fc2973a9":"code","120a42c7":"code","d113cd54":"code","9758303a":"code","1d590b2f":"code","a43732a0":"code","0cfeedd3":"code","f118c181":"code","db5ee5aa":"code","4bd0a559":"code","f5880335":"code","5c6ffd50":"markdown","ff567e0b":"markdown","35d9dbc8":"markdown","3366dc56":"markdown","42e7dfc8":"markdown","55542da8":"markdown","2819d010":"markdown","f149b287":"markdown","2cd67970":"markdown","a79c94c0":"markdown","4e20325b":"markdown","402b8c53":"markdown","e7d8e40a":"markdown","9bc24a50":"markdown","c507c5cd":"markdown","3d6d2b2c":"markdown","1d644962":"markdown","9cd1f537":"markdown","22c0ad30":"markdown","aeafd641":"markdown","cea96aef":"markdown","3852f471":"markdown","54004762":"markdown","3c3b247b":"markdown","e9f40276":"markdown","f03f17e4":"markdown","5a8848b1":"markdown","55078ea4":"markdown","57e33ca5":"markdown","5db51316":"markdown","0e1e3c28":"markdown","4a4a39da":"markdown","61713f46":"markdown","36186b8b":"markdown","ea7f1d26":"markdown","df5d6e9a":"markdown","e9f38d87":"markdown","b5191f75":"markdown"},"source":{"42ed3597":"BALANCING = False\nMODEL_USE = 3\n# 0 is run all model(it takes quite long)\n# 1 is Model from original train dataset,\n# 2 is Model from original train dataset and description,\n# 3 Model with images features and above, yet to be implemented","c891f12c":"import os\nprint(os.listdir(\"..\/input\"))","651ab68d":"from sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import make_scorer\ndef kappa(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","bbc09170":"import pandas as pd\nimport numpy as np\n\nbreeds = pd.read_csv('..\/input\/breed_labels.csv')\ncolors = pd.read_csv('..\/input\/color_labels.csv')\ntrain = pd.read_csv('..\/input\/train\/train.csv')\ntest = pd.read_csv('..\/input\/test\/test.csv')\nsub = pd.read_csv('..\/input\/test\/sample_submission.csv')\nstates = pd.read_csv('..\/input\/state_labels.csv')\n\n# train['dataset_type'] = 'train'\n# test['dataset_type'] = 'test'","3fc98217":"train.head(10)","2490722d":"train.info()","2423c774":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')","42b6faf0":"train['AdoptionSpeed'].value_counts()","bc55df54":"train['AdoptionSpeed'].value_counts().sort_index().plot('barh')\nplt.title('Adoption speed classes comparison');","8b53aaf4":"train['Type'].value_counts().sort_index().plot('barh')","3a64c45c":"train['Age'].describe()","31f2d3a7":"plt.hist(train['Age'],bins=list(range(0,60,1)))","4c0fedcf":"# Gender distribution\ntrain['Gender'].value_counts().rename({1:'Male',2:'Female', 3:'Mixed (Group of pets)'}).plot(kind='barh')\n# plt.yticks(fontsize='xx-large')\nplt.title('Gender distribution', fontsize='xx-large')","601a698c":"states","e7a26b5e":"states_to_ID = states.set_index('StateName')\nstate_value_counts = train['State'].value_counts(ascending=False)\nstate_distribution = states_to_ID['StateID'].map(state_value_counts).sort_values(ascending=False)\nstate_distribution\n","e90db308":"train['State'] = train['State'].replace(41401, 41326)# convert Kuala Lumpur to Selangor ","06962e4a":"train['PhotoAmt'].describe()","d34c8ca1":"train['PhotoAmt'].plot(kind='hist', \n                          bins=30, \n                          xticks=list(range(31)))\nplt.title('Photo Amount distribution')\nplt.xlabel('Photos')","695ea397":"train['VideoAmt'].describe()","ddee23ed":"train['VideoAmt'].plot(kind='hist', \n                          bins=8, \n                          xticks=list(range(9)))\nplt.title('Video Amount distribution')\nplt.xlabel('Video')","c1a9dbde":"train['Description'] = train['Description'].fillna('')\ntest['Description'] = test['Description'].fillna('')\ntrain['desc_len'] = train['Description'].apply(lambda x: len(x))","f84a5b9e":"train['desc_len'].describe()","307f34af":"test['desc_len'] = test['Description'].apply(lambda x: len(x))\ntest['desc_len'].describe()","c80b81e3":"# Clean up DataFrames\n# Will try to implement these into the model later\ntarget_train = train['AdoptionSpeed']\ncleaned_train = train.drop(columns=['Name', 'RescuerID', 'Description', 'PetID', 'AdoptionSpeed'])\ntest_pet_ID = test['PetID']\ntest_X = test.drop(columns=['Name', 'RescuerID', 'Description', 'PetID'])\n","1875f4d3":"cleaned_train.head()","d1326345":"target_train.isnull().values.any()","d5d60b1c":"test_X.isnull().values.any()","a5ba7760":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import cohen_kappa_score, make_scorer\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.svm import SVC\n\nseed = 42","82c525f7":"class EnsembleModel:\n    \n    def __init__(self,balancing=False):\n        self.balance_ratio = 5 if balancing else 1\n        self.rf_model = RandomForestClassifier()\n        self.lgb_model = lgb.LGBMClassifier()\n        self.rand_forest_params= {\n            'bootstrap': [True, False],\n            'max_depth': [20,30],\n            'min_samples_leaf': [20, 30],\n            'min_samples_split': [8,10],\n            'n_estimators': [200,250],\n            'random_state' : [seed]\n        }\n        self.lgb_params = {'objective' : ['multi:softprob'],\n              'eta' : [0.01],\n              'max_depth' : [6,7],\n              'num_class' : [5],\n              'num_leaves':[40,50],\n              'lambda' : [0.75],\n              'reg_alpha':[1e-5, 1e-2],\n              'silent': [1]\n        }\n        self.svm = SVC()\n        self.svm_params = {'kernel':['linear'],\n                           'C':[0.5,0.75],\n                           'gamma': ['auto'],\n                           'decision_function_shape':['ovo','ovr'],\n                           #'shrinking':[True,False]\n                          }\n\n        self.rf_best_param = None\n        self.lgb_best_param = None\n        self.svm_best_param = None\n        self.columns = None\n        \n    \n    def set_scorer(self,kappa):\n        self.kappa = kappa\n        self.scorer = make_scorer(kappa)\n        \n    def set_param(self,rf_param,lgb_param,svm_param):\n        self.rf_best_param = rf_param\n        self.lgb_best_param = lgb_param\n        self.svm_best_param = svm_param\n    \n    def tune_best_param(self,x_train,y_train):\n        weights_train = [self.balance_ratio if i==0 else 1 for i in y_train.tolist()]\n        \n        svm_gridsearch = GridSearchCV(self.svm, self.svm_params,\n                                      cv=3,\n                                      scoring=self.scorer,verbose=1, \n                                      refit=True\n                                     )\n        svm_gridsearch.fit(x_train, y_train, sample_weight = weights_train)\n        self.svm = svm_gridsearch.best_estimator_\n        self.svm_best_param = svm_gridsearch.best_params_\n        print('tuning for svm finished')\n        \n        rf_gridsearch = GridSearchCV(estimator = self.rf_model, \n                                      param_grid = self.rand_forest_params, \n                                      cv = 5, \n                                      n_jobs = -1, \n                                      verbose = 1, \n                                      scoring=self.scorer)\n        rf_gridsearch.fit(x_train, y_train, sample_weight = weights_train)\n        print('tuning for rf finished')\n        self.rf_model = rf_gridsearch.best_estimator_\n        self.rf_best_param = rf_gridsearch.best_params_\n        \n        lgb_gridsearch = GridSearchCV(self.lgb_model, self.lgb_params, n_jobs=-1, \n                   cv=5, \n                   scoring=self.scorer,\n                   verbose=1, refit=True)\n        lgb_gridsearch.fit(x_train, y_train, sample_weight = weights_train)\n        print('tuning for lgb finished')\n        self.lgb_model = lgb_gridsearch.best_estimator_\n        self.lgb_best_param = lgb_gridsearch.best_params_\n        \n        \n        \n        print('best param for rf is:')\n        print(self.rf_best_param)\n        print('best param for lgb is:')\n        print(self.lgb_best_param)\n        print('best param for svm is:')\n        print(self.svm_best_param)\n    \n    # let's try combining the 3 models together by averging\n    def _avg(self,y_1,y_2,y_3):\n        return np.rint((y_1 + y_2)\/2.0).astype(int)\n\n    def re_fit_with_best_param(self,X,y):\n        if self.rf_best_param == None or self.lgb_best_param == None or self.svm_best_param == None: \n            print('use tune_best_param() method to get best param first')\n            return\n        weights_train = [self.balance_ratio if i==0 else 1 for i in y.tolist()]\n        self.rf_model = RandomForestClassifier()\n        self.lgb_model =  lgb.LGBMClassifier()\n        self.svm = SVC()\n        self.rf_model.set_params(**self.rf_best_param)\n        self.lgb_model.set_params(**self.lgb_best_param)\n        self.svm.set_params(**self.svm_best_param)\n        self.rf_model.fit(X,y,sample_weight=weights_train)\n        self.lgb_model.fit(X,y,sample_weight=weights_train)\n        self.svm.fit(X,y,sample_weight=weights_train)\n        print('refit finished')\n    \n    def validate(self,x_valid, y_valid):\n        rf_score = self.kappa(self.rf_model.predict(x_valid), y_valid)\n        print('{} score: {}'.format('rf', round(rf_score, 4)))\n        lgb_score = self.kappa(self.lgb_model.predict(x_valid), y_valid)\n        print('{} score: {}'.format('lgb', round(lgb_score, 4)))\n        svm_score = self.kappa(self.svm.predict(x_valid), y_valid)\n        print('{} score: {}'.format('svm', round(svm_score, 4)))\n        score = kappa(self._avg(self.lgb_model.predict(x_valid), self.rf_model.predict(x_valid), self.svm.predict(x_valid)) , y_valid)\n        print('{} score on validation set: {}'.format('combiner', round(score, 4)))\n        self.columns = x_valid.columns\n\n    def predict(self,test_X):\n        rf_result = self.rf_model.predict(test_X)\n        lgb_result = self.lgb_model.predict(test_X)\n        svm_result = self.svm.predict(test_X)\n        final_result = self._avg(rf_result,lgb_result,svm_result)\n        return final_result\n\n\n    def get_feature_importance(self):\n        rf_feature_importances = pd.DataFrame({'Feature':self.columns.tolist(),'importance':self.rf_model.feature_importances_.tolist()})\n        lgb_feature_importances = pd.DataFrame({'Feature':self.columns.tolist(),'importance':self.lgb_model.feature_importances_.tolist()})\n        svm_feature_importances = pd.DataFrame({'Feature':self.columns.tolist(),'importance':self.svm.coef_.tolist()})\n        overall_feature_importance = pd.merge(rf_feature_importances, lgb_feature_importances, svm_feature_importances, on='Feature', how='outer')\n        overall_feature_importance['avg_importance'] = (overall_feature_importance['importance_x'] + overall_feature_importance['importance_y']+ overall_feature_importance['importance_z'])\/3\n        overall_feature_importance = overall_feature_importance.sort_values(by=['avg_importance'], ascending=False)\n        return overall_feature_importance\n","476bf0e6":"# Clean up DataFrames\n# Will try to implement these into the model later\ntarget_train = train['AdoptionSpeed']\ncleaned_train = train.drop(columns=['Name', 'RescuerID', 'Description', 'PetID', 'AdoptionSpeed'])\ntest_pet_ID = test['PetID']\ntest_X = test.drop(columns=['Name', 'RescuerID', 'Description', 'PetID'])\n","e2f91abf":"x_train, x_valid, y_train, y_valid = train_test_split(cleaned_train, \n                                                      target_train, \n                                                      test_size=0.2, \n                                                      random_state=seed)\n\n","6348a10f":"if MODEL_USE == 1 or MODEL_USE==0:\n    first_model = EnsembleModel(balancing=True)\n    first_model.set_scorer(kappa)\n    first_model.tune_best_param(x_train, y_train)\n    first_model.validate(x_valid, y_valid)","09c32f98":"import json\nfilename = os.listdir(\"..\/input\/train_sentiment\")[1]\nfilename = \"..\/input\/train_sentiment\/\"+filename\nwith open(filename, 'r') as f:\n    sentiment = json.load(f)\nsentiment  ","679c98df":"def load_desc_sentiment(path):\n    all_desc_sentiment_files = os.listdir(path)\n    count_file = len(all_desc_sentiment_files)\n    desc_sentiment_df = pd.DataFrame(columns=['PetID','desc_senti_magnitude','desc_senti_score'])\n    current_file_index = 1\n    for filename in all_desc_sentiment_files:\n        with open(path+filename, 'r') as f:\n            sentiment_json = json.load(f)\n            petID = filename.split('.')[0]\n            magnitude = sentiment_json['documentSentiment']['magnitude']\n            score = sentiment_json['documentSentiment']['score']\n            desc_sentiment_df = desc_sentiment_df.append({'PetID': petID, 'desc_senti_magnitude':magnitude,'desc_senti_score':score}, \\\n                                                         ignore_index=True)\n            if current_file_index % 1000 == 0 or current_file_index == count_file :\n                print('current progress: %d file of %d loaded' %(current_file_index,count_file))\n            current_file_index += 1\n    return desc_sentiment_df","32d8a175":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD,PCA\ntfv = TfidfVectorizer(min_df=2,  max_features=None,\n        strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n        )\ntfv.fit(train['Description'])\ndesc_X_train =  tfv.transform(train['Description'])\ndesc_X_test = tfv.transform(test['Description'])\nprint(desc_X_train.shape)\nprint(desc_X_test.shape)","4bf61a46":"svd = TruncatedSVD(n_components=5)\nsvd.fit(desc_X_train)\n# print(svd.explained_variance_ratio_.sum())\n# print(svd.explained_variance_ratio_)\ndesc_X_train = svd.transform(desc_X_train)\ndesc_X_test = svd.transform(desc_X_test)\nprint(\"desc_X_train (svd):\", desc_X_train.shape)\nprint(\"desc_X_test (svd):\", desc_X_test.shape)","32e0f7c1":"train_desc_sentiment_df = load_desc_sentiment(\"..\/input\/train_sentiment\/\")\ntest_desc_sentiment_df = load_desc_sentiment(\"..\/input\/test_sentiment\/\")","31e8e65e":"# train_desc_sentiment_df['score_times_mag'] = train_desc_sentiment_df['desc_senti_magnitude'] * train_desc_sentiment_df['desc_senti_score']\n# test_desc_sentiment_df['score_times_mag'] = test_desc_sentiment_df['desc_senti_magnitude'] * test_desc_sentiment_df['desc_senti_score']","2bbdb259":"train_desc_sentiment_df.head(5)","221f4df5":"desc_X_train = pd.DataFrame(desc_X_train, columns=['desc_{}'.format(i) for i in range(svd.n_components)])\ndesc_X_test = pd.DataFrame(desc_X_test, columns=['desc_{}'.format(i) for i in range(svd.n_components)])\ntrain_with_desc = pd.concat([train,desc_X_train],axis=1)\ntest_with_desc = pd.concat([test,desc_X_test],axis=1)","9196e3f1":"target_train = train_with_desc['AdoptionSpeed']\njoint_train = train_with_desc.merge(train_desc_sentiment_df, how='left',left_on=['PetID'],right_on=['PetID'])\ncleaned_train = joint_train.drop(columns=['Name', 'RescuerID', 'Description', 'PetID', 'AdoptionSpeed'])\ncleaned_train.fillna(0.0,inplace=True)\n\ntest_pet_ID = test_with_desc['PetID']\njoint_test = test_with_desc.merge(test_desc_sentiment_df, how='left',left_on=['PetID'],right_on=['PetID'])\ntest_X = joint_test.drop(columns=['Name', 'RescuerID', 'Description', 'PetID'])\ntest_X.fillna(0.0, inplace=True)\n\nx_train, x_valid, y_train, y_valid = train_test_split(cleaned_train, \n                                                      target_train, \n                                                      test_size=0.2, \n                                                      random_state=seed)","a8621510":"if MODEL_USE == 2 or MODEL_USE==0:\n    second_model = EnsembleModel(balancing=True)\n    second_model.set_scorer(kappa)\n    second_model.tune_best_param(x_train, y_train)\n    second_model.validate(x_valid,y_valid)","20bf3793":"def add_meta_feature(path,df):\n    vertex_xs = []\n    vertex_ys = []\n    bounding_confidences = []\n    bounding_importance_fracs = []\n    dominant_blues = []\n    dominant_greens = []\n    dominant_reds = []\n    dominant_pixel_fracs = []\n    dominant_scores = []\n    label_descriptions = []\n    label_scores = []\n    nf_count = 0\n    nl_count = 0\n    pet_id = df['PetID']\n    for pet in pet_id:\n        try:\n            with open(path + pet + '-1.json', 'r') as f:\n                data = json.load(f)\n            vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n            vertex_xs.append(vertex_x)\n            vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n            vertex_ys.append(vertex_y)\n            bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n            bounding_confidences.append(bounding_confidence)\n            bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n            bounding_importance_fracs.append(bounding_importance_frac)\n            dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n            dominant_blues.append(dominant_blue)\n            dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n            dominant_greens.append(dominant_green)\n            dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n            dominant_reds.append(dominant_red)\n            dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n            dominant_pixel_fracs.append(dominant_pixel_frac)\n            dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n            dominant_scores.append(dominant_score)\n            if data.get('labelAnnotations'):\n                label_description = data['labelAnnotations'][0]['description']\n                label_descriptions.append(label_description)\n                label_score = data['labelAnnotations'][0]['score']\n                label_scores.append(label_score)\n            else:\n                nl_count += 1\n                label_descriptions.append('nothing')\n                label_scores.append(-1)\n        except FileNotFoundError:\n            nf_count += 1\n            vertex_xs.append(-1)\n            vertex_ys.append(-1)\n            bounding_confidences.append(-1)\n            bounding_importance_fracs.append(-1)\n            dominant_blues.append(-1)\n            dominant_greens.append(-1)\n            dominant_reds.append(-1)\n            dominant_pixel_fracs.append(-1)\n            dominant_scores.append(-1)\n            label_descriptions.append('nothing')\n            label_scores.append(-1)\n    print(nf_count)\n    print(nl_count)\n    df.loc[:, 'vertex_x'] = vertex_xs\n    df.loc[:, 'vertex_y'] = vertex_ys\n    df.loc[:, 'bounding_confidence'] = bounding_confidences\n    df.loc[:, 'bounding_importance'] = bounding_importance_fracs\n    df.loc[:, 'dominant_blue'] = dominant_blues\n    df.loc[:, 'dominant_green'] = dominant_greens\n    df.loc[:, 'dominant_red'] = dominant_reds\n    df.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\n    df.loc[:, 'dominant_score'] = dominant_scores\n    df.loc[:, 'label_description'] = label_descriptions\n    df.loc[:, 'label_score'] = label_scores\n#     df = df.drop(['label_description'])\n    return df\n\n\n\nif MODEL_USE == 3 or MODEL_USE==0:\n    train_with_meta = add_meta_feature('..\/input\/train_metadata\/', train_with_desc)\n    target_train = train_with_meta['AdoptionSpeed']\n    cleaned_train = train_with_meta.drop(columns=['Name', 'RescuerID', 'Description', 'PetID', 'AdoptionSpeed', 'label_description'])\n    cleaned_train.fillna(0.0,inplace=True)\n    \n    test_with_meta = add_meta_feature('..\/input\/test_metadata\/', test_with_desc)\n    test_pet_ID = test_with_desc['PetID']\n    test_X = test_with_meta.drop(columns=['Name', 'RescuerID', 'Description', 'PetID', 'label_description'])\n    test_X.fillna(0.0, inplace=True)\n\n    x_train, x_valid, y_train, y_valid = train_test_split(cleaned_train, \n                                                          target_train, \n                                                          test_size=0.2, \n                                                          random_state=seed)\n\n","fc2973a9":"x_train.shape","120a42c7":"# Metadata:\n# train_df_ids = train[['PetID']]\n# train_df_metadata = pd.DataFrame(train_metadata_files)\n# train_df_metadata.columns = ['metadata_filename']\n# train_metadata_pets = train_df_metadata['metadata_filename'].apply(lambda x: x.split('\/')[-1].split('-')[0])\n# train_df_metadata = train_df_metadata.assign(PetID=train_metadata_pets)\n# print(len(train_metadata_pets.unique()))\n\n# pets_with_metadatas = len(np.intersect1d(train_metadata_pets.unique(), train_df_ids['PetID'].unique()))\n# print('fraction of pets with metadata: {:.3f}'.format(pets_with_metadatas \/ train_df_ids.shape[0]))","d113cd54":"if MODEL_USE == 3 or MODEL_USE==0:\n    third_model = EnsembleModel(balancing=True)\n    third_model.set_scorer(kappa)\n    third_model.tune_best_param(x_train, y_train)\n    third_model.validate(x_valid,y_valid)","9758303a":"model = None\nif MODEL_USE == 1:\n    model = first_model\nif MODEL_USE == 2: \n    model = second_model\nif MODEL_USE == 0 or MODEL_USE == 3: # if all 3 model is enabled, we just use the 3rd model\n    model = third_model","1d590b2f":"# overall_feature_importance = model.get_feature_importance()\n# overall_feature_importance.head(5)\n# overall_feature_importance.drop(['importance_x','importance_y'],axis=1).set_index('Feature').plot(kind='bar')\n","a43732a0":"model.re_fit_with_best_param(cleaned_train,target_train)","0cfeedd3":"final_result = model.predict(test_X)","f118c181":"submission_df = pd.DataFrame(data={'PetID' : test_pet_ID.tolist(), \n                                   'AdoptionSpeed' : final_result})\nsubmission_df.head(5)","db5ee5aa":"submission_df.to_csv('submission.csv', index=False)","4bd0a559":"len(model.svm.coef_.ravel())","f5880335":"model.lgb_model.feature_importances_","5c6ffd50":"# Some Flags may be used to control process","ff567e0b":"# Modelling <a class=\"anchor\" id=\"model0\"><\/a>\n\ntraining.csv already contain some features. the other feaures are from images and description of the pet. In order to test the importance of the features from mages and description, I will do modelling in mulitiple steps.\n\n## Model Selection <a class=\"anchor\" id=\"selection\"><\/a>\nFrom Model, here I will select Random Forest and XGBoost to ensemble. Random Forest is to **reduce variance** and XGBoost is to **reduce bias**. Together they can get better result. ","35d9dbc8":"we can see most people uploaded only 1 video of the pet","3366dc56":"# Result and Submission <a class=\"anchor\" id=\"result\"><\/a>","42e7dfc8":"## Description Length","55542da8":"### State <a class=\"anchor\" id=\"state\"><\/a>\nRefer to the states(or city) in Malaysia. Pet's in larger city may have more chances to be adopted","2819d010":"# Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"><\/a>\n\nFrom this chapter you can get some deeper insight about the data. From the data introduction we can know that the data is actually very easy to combine and transform. Train and Test is the main data,  breeds, colors, states files are only id to name mapping files, they don't contain extra information. The extra information is on description and images of pets, but PetFinder.my had already convert them into sentiment data, which will be easy to integrate with the main data file. Let's dive deep down to the main data.\n\n## Data loading<a class=\"anchor\" id=\"loading\"><\/a>\nFirst, Let's load Tabular data first\n","f149b287":"# Maintainance Log\n\n| Time       | version | remark                                                                |  Score  | commit version |\n|------------|---------|-----------------------------------------------------------------------|\n| 2019-01-20 | v1.0.0    | basic models only using features from train.csv, combiner model used  | **0.343**  | - |\n| 2019-01-20 | v1.0.1   | do balancing on class 0  |  0.339 | -|\n| 2019-01-21 | v1.1.0   | add length of description as a feature to test  |  0.338 | -|\n| 2019-01-21 | v1.1.1   | add regularization for xgb |  0.343 |  v12 |\n    | 2019-01-24 | v2.0.0 | add features from descritption, refactored the code  |  0.337 | v13|\n     | 2019-01-24 | v2.0.1| cancel balancing |  0.329 | v15|\n      | 2019-01-28 | v2.1.0| use tf-idf to extract feature from description text |   | v16|\n    | TBD | v3.0.0 | add features from images  |  - | -|\n","2cd67970":"# Introduction <a class=\"anchor\" id=\"Introduction\"><\/a>","a79c94c0":"## Model with description sentiments <a class=\"anchor\" id=\"model2\"><\/a>\nLet's examinate how a description sentiment file looks like:","4e20325b":"Marvelous! Combiner model do give us better result! on validation set\nAcutually you can play with more models and tune the best params to score the top leaderboard","402b8c53":"### Photo amount and video amount distribution <a class=\"anchor\" id=\"amount\"><\/a>","e7d8e40a":"## Output <a class=\"anchor\" id=\"output\"><\/a>\nOutput will be submission.csv, should include these 2 columns: \n\n*PetID, AdoptionSpeed*\n","9bc24a50":"There is no record for Perlis, so the value above is NaN\n\n","c507c5cd":"we can see maximum 30 photos are uploaded for a pet.  Let's plot all possible photo numbers","3d6d2b2c":"75% are under 12 months. But for better understanding, let's cap at 60 months and see their distribution","1d644962":"we can see that class 0 has much fewer amount than the others. In another word, only a small percentage of pets were adopted within 7 days(That's the reason why they held this the competition). **Balancing technique need to be taken when modelling**\n\n### Type <a class=\"anchor\" id=\"type\"><\/a>\n\nWhat's the second column you want to inspect? In my opinion, it should be 'Type'\n","9cd1f537":"\nAs I know, Kuala Lumpur is a city of the state of Selangor. So  we may need to convert cities into states","22c0ad30":"## Ranking Criteria <a class=\"anchor\" id=\"ranking\"><\/a>\nAs Shown in [evalution tab](https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction#evaluation),  the result will be scored based on the quadratic weighted kappa and highest score ranking higher. The implementation is as below:","aeafd641":"# Data Cleaning <a class=\"anchor\" id=\"clean\"><\/a>\nwe need to drop these columns\n* 'AdoptionSpeed'. It had been used as target\n* 'Name', 'RescuerID', 'PetID'. they won't be helpful from basic understanding.\n* 'Description'. it had been transformed into sentiments\n","cea96aef":"## Model with images features and above<a class=\"anchor\" id=\"model3\"><\/a>\nTo be implemented in version 3.0\n","3852f471":"### AdoptionSpeed <a class=\"anchor\" id=\"adoptionspeed\"><\/a>\nFirst of all, let's see target distribution, it is always the first thing to look into when you get data, the purposes are:\n* Get to know the amount of the each classes\n* Identify the skewness of the classes, do balancing on training data if necessary","54004762":"## Main Data Exploration<a class=\"anchor\" id=\"mainEDA\"><\/a>","3c3b247b":"We can see that the age of the pet are mostly below 20 months.\n\nOne interesting finding is that people prefer to input YEAR rather than MONTH when filling the pet's age, so there are peaks at every 12 months\n","e9f40276":"where (1 = Dog, 2 = Cat), as explained in the [Data Fields explanation](https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\/data). We can see that they have  similar amount\n\n","f03f17e4":"next we need to check if there are null values inside the traing and testing dataframe","5a8848b1":"# Feature Importance and Conclusion <a class=\"anchor\" id=\"importance\"><\/a>\n\nLet's analyze the feature importance ","55078ea4":"\n\n## Model from original train dataset <a class=\"anchor\" id=\"model1\"><\/a>\n\n### Data Cleaning <a class=\"anchor\" id=\"clean\"><\/a>\nwe need to drop these columns\n* 'AdoptionSpeed'. It had been used as target\n* 'Name', 'RescuerID', 'PetID'. they won't be helpful from basic understanding.\n* 'Description'. it had been transformed into sentiments\n","57e33ca5":" The model are trained on 80% of the training set (20% was left out for validation. now we will use the best param obtained in previous step to train on the full dataset","5db51316":"### Age <a class=\"anchor\" id=\"age\"><\/a>\nAge may be an important factor on the adoptablity of the pet, let's dive deep into it\n","0e1e3c28":"### Gender <a class=\"anchor\" id=\"gender\"><\/a>\n","4a4a39da":"# Table of Content:\n* [Introduction](#introduction)\n    * [Input](#input)\n    * [Ranking Criteria](#ranking)\n    * [Output](#output)\n* [Exploratory Data Analysis](#eda)\n    * [Data loading](#loading)\n    * [Main Data Exploration](#mainEDA)\n        * [AdoptionSpeed](#adoptionspeed)\n        * [Type](#type)\n        * [Age](#age)\n        * [Gender](#gender)\n        * [State](#state)\n        * [Photo amount and video amount distribution](#amount)\n* [Modelling](#model0)\n    * [Model Selection](#selection)\n    * [Model from original train dataset](#model1)\n    * [Model with description sentiments](#model2)\n    * [Model with images features and above](#model3)\n* [Feature Importance and Conclusion](#importance)\n* [Result and Submission](#result)","61713f46":"Entities in the json are too complex to use, but we can see that *documentSentiment': {'magnitude': 0.8, 'score': 0.4}* is easy to use. File name format is PetID.json, Let's use these 2 variables","36186b8b":"This Kernel is created to explain everything in competition [PetFinder.my](https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction), it encourage everyone to develop algorithms to predict the adoptability of pets, guide shelters and rescuers around the world on improving their pet profiles' appeal, reducing animal suffering and euthanization.\n\nMeanwhile, I will add my ideas and explanations in between, to tell the reader while I perform such action in such step.\n\nFinally, I will mention my future working direction in the last chapter, hopefully it can give you some inspiration\n\nThe kernel is still updating. Your upvotes and folks will be my best motivation.\n","ea7f1d26":"here are the information provided by the offical, I assumed that you have already read the [data introduction](https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\/data).  I listed them down here for short.\n### File descriptions \n* train.csv - Tabular\/text data for the training set\n* test.csv - Tabular\/text data for the test set\n* sample_submission.csv - A sample submission file in the correct format\n* breed_labels.csv - Contains Type, and BreedName for each BreedID. Type 1 is dog, 2 is cat.\n* color_labels.csv - Contains ColorName for each ColorID\n* state_labels.csv - Contains StateName for each StateID\n* Images - pets' photos\n* Image Metadata - analysis on Face Annotation, Label Annotation, Text Annotation and Image Properties. \n* Sentiment Data - profile's description  analysis on sentiment and key entities. \n\ndetailed analysis of the data will be done at [next chapter](#eda).","df5d6e9a":"### Model Tuning\n\nFrom Version 2.0, we make the model ensembling as a class so that it will be easier to replicate.","e9f38d87":"## Input <a class=\"anchor\" id=\"input\"><\/a>\nFirst, Let's look into what data they have provided","b5191f75":"The data is really clean! Isn't it? it saved our valuable time. Thanks PetFinder.my for cleaning for us"}}