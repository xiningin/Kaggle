{"cell_type":{"f63b71ca":"code","50cfea89":"code","31b3df95":"code","8b7f6f71":"code","10ae3e98":"code","3bad81d5":"code","526e3b18":"code","fb0d0dca":"code","138853c6":"code","61cf01b6":"code","1f9233ed":"code","d0b7b691":"code","ba2a707a":"code","70360bbc":"code","91bcdbe6":"code","5f542150":"code","b01f699f":"code","65c76de1":"code","84ccc1cb":"code","96046ff1":"code","8fd866d8":"code","97adf497":"code","ceaad0bb":"code","179526e5":"code","6efbb53b":"code","00079fa2":"code","63ab3baa":"code","29ea371a":"code","b0c5d60b":"code","2bb24e76":"code","6135f0fe":"code","0cb499cb":"code","83256c6a":"code","0ee2a71a":"code","086df196":"code","0a5e94b9":"code","d5a33679":"code","5c748545":"code","9c1d0f67":"code","1bae17e7":"code","70784ef2":"code","9cb07575":"code","b6704d6f":"code","42c9fab6":"code","6d4a22de":"code","a57e0f86":"code","777130ee":"code","9070a23f":"code","34dab882":"code","76422c74":"code","8e0363ed":"code","475b14f0":"code","86a0157c":"code","3d08def1":"code","3e31a595":"code","91ee5584":"code","07967b6f":"code","71d3ba93":"code","977bc9c3":"code","19b2294c":"markdown","3dfdfff5":"markdown","4b9c843d":"markdown","24106e5b":"markdown","56fa1259":"markdown","2a4ddf85":"markdown","31a11a0a":"markdown","f391b56c":"markdown","e10d6c44":"markdown","be7d22d6":"markdown","4907f9af":"markdown","b7c03c6f":"markdown","f540fea8":"markdown","04da014c":"markdown","7a77bce0":"markdown","3d483110":"markdown","dfc5bce5":"markdown","1138437a":"markdown","0e70c769":"markdown","47ce182e":"markdown","266fe61f":"markdown","47404700":"markdown","6e09ae0d":"markdown","0c64a9f2":"markdown","95d5a9e0":"markdown","b7d80b7d":"markdown","c7235df2":"markdown","7db8acf0":"markdown","494730c5":"markdown","fb02276a":"markdown","1cc6bf9b":"markdown"},"source":{"f63b71ca":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")","50cfea89":"df = pd.read_csv(\"\/kaggle\/input\/spotifyclassification\/data.csv\")\ndf.head(n=5)","31b3df95":"df = df.drop('Unnamed: 0',axis=1)","8b7f6f71":"#The shape of the data\nprint(\"shape of the dataset: \",df.shape)","10ae3e98":"#Checking the number of unique values in each column\ndict = {}\nfor i in list(df.columns):\n    dict[i]=df[i].value_counts().shape[0]\npd.DataFrame(dict,index=['Unique count']).T","3bad81d5":"df.info()","526e3b18":"df.describe()","fb0d0dca":"pd.DataFrame(df.isnull().sum(),columns=['null'])","138853c6":"# Classifying data into numerical and categorical variables.\ndata_numerical=df[['acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']]\ndata_categorical=df[['key','mode','time_signature','target']]","61cf01b6":"# Skewness and kurtosis\ns_k=[]\nfor i in data_numerical.columns:\n    s_k.append([i,data_numerical[i].skew(),data_numerical[i].kurt()])\nskew_kurt=pd.DataFrame(s_k,columns=['Columns','Skewness','Kurtosis'])\nskew_kurt","1f9233ed":"plt.style.use('ggplot')\nfig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'acousticness'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'acousticness'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for acousticness',weight='bold')\n\nplt.show()","d0b7b691":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'danceability'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'danceability'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for danceability',weight='bold')\n\nplt.show()","ba2a707a":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'duration_ms'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'duration_ms'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for duration',weight='bold')\n\nplt.show()","70360bbc":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'energy'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'energy'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for energy',weight='bold')\n\nplt.show()","91bcdbe6":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'instrumentalness'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'instrumentalness'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for instrumentalness',weight='bold')\n\nplt.show()","5f542150":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'liveness'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'liveness'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for liveness',weight='bold')\n\nplt.show()","b01f699f":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'loudness'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'loudness'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for loudness',weight='bold')\n\nplt.show()","65c76de1":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'speechiness'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'speechiness'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for speechiness',weight='bold')\n\nplt.show()","84ccc1cb":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'tempo'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'tempo'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for tempo',weight='bold')\n\nplt.show()","96046ff1":"fig, ax = plt.subplots(figsize = (12,6))\nfig.patch.set_facecolor('#f6f5f7')\nax.set_facecolor('#f6f5f5')\nsns.kdeplot(df.loc[(df['target']==1),'valence'], color='r',\n            shade=True, Label='Liked')\n  \nsns.kdeplot(df.loc[(df['target']==0),'valence'], color='b',\n            shade=True, Label='Not Liked')\nfor i in [\"top\",\"right\"]:\n    ax.spines[i].set_visible(False)\nplt.title('Kde Plots for valence',weight='bold')\n\nplt.show()","8fd866d8":"plt.figure(figsize=(15,20))\nplt.subplot(3,2,1)\nsns.scatterplot(data=df,x=df['acousticness'],y=df['danceability'],hue=df['target'],palette=\"OrRd\",style=df['target'])\nplt.title('Scatterplot for acousticness vs danceability')\nplt.subplot(3,2,2)\nsns.scatterplot(data=df,x=df['duration_ms'],y=df['energy'],hue=df['target'],palette=\"OrRd\",style=df['target'])\nplt.title('Scatterplot for duration_ms vs enery')\nplt.subplot(3,2,3)\nsns.scatterplot(data=df,x=df['instrumentalness'],y=df['liveness'],hue=df['target'],palette=\"OrRd\",style=df['target'])\nplt.title('Scatterplot for instrumentalness vs liveness')\nplt.subplot(3,2,4)\nsns.scatterplot(data=df,x=df['loudness'],y=df['speechiness'],hue=df['target'],palette=\"OrRd\",style=df['target'])\nplt.title('Scatterplot for loudness vs speechiness')\nplt.subplot(3,2,5)\nsns.scatterplot(data=df,x=df['tempo'],y=df['valence'],hue=df['target'],palette=\"OrRd\",style=df['target'])\nplt.title('Scatterplot for tempo vs valence')\n\nplt.show()","97adf497":"plt.figure(figsize=(10,6))\nsns.heatmap(data_numerical.corr(),annot=True,cmap='OrRd')\nplt.show()","ceaad0bb":"fig=plt.figure(figsize=(20,15),dpi=100)\nsns.pairplot(data=df,hue='target',size=2,palette='OrRd')\nplt.show()","179526e5":"fig=plt.figure(figsize=(20,23))\nbackground_color = '#f6f5f7'\nfig.patch.set_facecolor(background_color) \nfor indx,val in enumerate(data_categorical.columns):\n    ax=plt.subplot(4,2,indx+1)\n    ax.set_facecolor(background_color)\n    ax.set_title(val,fontweight='bold',fontfamily='serif')\n    for i in ['top','right']:\n        ax.spines[i].set_visible(False)\n    ax.grid(linestyle=':',axis='y')\n    sns.countplot(data_categorical[val],palette='OrRd')","6efbb53b":"data_cat=df[['key','mode','time_signature']]\nfig=plt.figure(figsize=(20,23))\nbackground_color = '#f6f5f7'\nfig.patch.set_facecolor(background_color) \nfor indx,val in enumerate(data_cat.columns):\n    ax=plt.subplot(4,2,indx+1)\n    ax.set_facecolor(background_color)\n    ax.set_title(val,fontweight='bold',fontfamily='serif')\n    for i in ['top','right']:\n        ax.spines[i].set_visible(False)\n    ax.grid(linestyle=':',axis='y')\n    sns.countplot(data_cat[val],palette='OrRd_r',hue=df['target'])","00079fa2":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr(),annot=True,cmap='OrRd')\nplt.show()","63ab3baa":"df.head(n=3)","29ea371a":"df['artist'].value_counts().plot()\nplt.show()","b0c5d60b":"plt.figure(figsize=(15,8))\nsns.boxplot(data=df ,orient=\"h\",color='crimson')\nplt.show()","2bb24e76":"from sklearn.preprocessing import LabelEncoder\ncols = ['song_title','artist']\ndf[cols] = df[cols].apply(LabelEncoder().fit_transform)\ndf.head(n=5)","6135f0fe":"from scipy import stats\nzscore = np.abs(stats.zscore(df))\nprint(zscore)","0cb499cb":"threshold = 3\nprint(np.where(zscore > 3))","83256c6a":"df = df[(zscore<3).all(axis=1)]","0ee2a71a":"x = df.drop('target',axis=1)\ny = df['target']","086df196":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=0)","0a5e94b9":"# Standardizing our training and testing data.\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","d5a33679":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix","5c748545":"log_reg = LogisticRegression()\nlog_reg.fit(x_train,y_train)\n\nlog_acc=accuracy_score(y_test,log_reg.predict(x_test))\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,log_reg.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,log_reg.predict(x_test))*100))","9c1d0f67":"plt.figure(figsize=(6,4))\ndf_ = pd.DataFrame(confusion_matrix(y_test, log_reg.predict(x_test)), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","1bae17e7":"y_pred= log_reg.predict(x_test).ravel()\n\nfrom sklearn.metrics import roc_curve\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(figsize=(8,6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Logistic (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","70784ef2":"d_tree = DecisionTreeClassifier()\nd_tree.fit(x_train,y_train)\n\nd_acc=accuracy_score(y_test,d_tree.predict(x_test))\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,d_tree.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,d_tree.predict(x_test))*100))","9cb07575":"plt.figure(figsize=(6,4))\ndf_ = pd.DataFrame(confusion_matrix(y_test, d_tree.predict(x_test)), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","b6704d6f":"y_pred= d_tree.predict(x_test).ravel()\n\nfrom sklearn.metrics import roc_curve\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(figsize=(8,6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Decision (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","42c9fab6":"r_for = RandomForestClassifier()\nr_for.fit(x_train,y_train)\n\nr_acc=accuracy_score(y_test,r_for.predict(x_test))\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,r_for.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,r_for.predict(x_test))*100))","6d4a22de":"plt.figure(figsize=(6,4))\ndf_ = pd.DataFrame(confusion_matrix(y_test, r_for.predict(x_test)), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","a57e0f86":"y_pred= r_for.predict(x_test).ravel()\n\nfrom sklearn.metrics import roc_curve\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(figsize=(8,6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Random forest (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","777130ee":"k_nei = KNeighborsClassifier()\nk_nei.fit(x_train,y_train)\n\nk_acc = accuracy_score(y_test,k_nei.predict(x_test))\n\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_train,k_nei.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,k_nei.predict(x_test))*100))","9070a23f":"plt.figure(figsize=(6,4))\ndf_ = pd.DataFrame(confusion_matrix(y_test, k_nei.predict(x_test)), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","34dab882":"y_pred= k_nei.predict(x_test).ravel()\n\nfrom sklearn.metrics import roc_curve\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(figsize=(8,6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='K_nei (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","76422c74":"s_vec = SVC()\ns_vec.fit(x_train,y_train)\n\ns_acc = accuracy_score(y_test,s_vec.predict(x_test))\n\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_train,s_vec.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,s_vec.predict(x_test))*100))","8e0363ed":"plt.figure(figsize=(6,4))\ndf_ = pd.DataFrame(confusion_matrix(y_test, s_vec.predict(x_test)), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","475b14f0":"y_pred= s_vec.predict(x_test).ravel()\n\nfrom sklearn.metrics import roc_curve\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(figsize=(8,6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='SVC (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","86a0157c":"g_clf = GaussianNB()\ng_clf.fit(x_train,y_train)\n\ng_acc = accuracy_score(y_test,g_clf.predict(x_test))\n\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_train,g_clf.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,g_clf.predict(x_test))*100))","3d08def1":"plt.figure(figsize=(6,4))\ndf_ = pd.DataFrame(confusion_matrix(y_test, g_clf.predict(x_test)), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","3e31a595":"y_pred= g_clf.predict(x_test).ravel()\n\nfrom sklearn.metrics import roc_curve\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(figsize=(8,6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='gaussian (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","91ee5584":"x_clf = XGBClassifier()\nx_clf.fit(x_train,y_train)\n\nx_acc = accuracy_score(y_test,x_clf.predict(x_test))\n\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_train,x_clf.predict(x_train))*100))\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_test,x_clf.predict(x_test))*100))","07967b6f":"plt.figure(figsize=(6,4))\ndf_ = pd.DataFrame(confusion_matrix(y_test, x_clf.predict(x_test)), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","71d3ba93":"models = pd.DataFrame({\n    'Model': ['Logistic','KNN', 'SVC',  'Decision Tree ',\n             'Random Forest',  'Gaussian','xgboost'],\n    'Score': [ log_acc,k_acc, s_acc, d_acc, r_acc, g_acc,x_acc]\n})\n\nmodels.sort_values(by = 'Score', ascending = False)","977bc9c3":"plt.figure(figsize=(15,6))\nsns.barplot(x='Model',y='Score',data=models)\nplt.show()","19b2294c":"> **Observations:**\n* 2 key is more than any other in our data\n* The number of songs with time_signature 4.0 are to high\n* target is distributed equally\n* the number of songs of mode is more in major more than minor","3dfdfff5":"# <span style=\"color:Crimson;\">Summary Statistics<\/span>","4b9c843d":"https:\/\/open.spotify.com\/playlist\/1lXkBYLNc7DwttQmiwZwrz?si=eZNJni-dRnaUJn0hF0dUFQ \n\n\ud83d\ude02\ud83d\ude0dThis is my best playlist on spotify","24106e5b":"* Highly skewed towards left","56fa1259":"* highly skewed towards right","2a4ddf85":"# <span style=\"color:Crimson;\">checking null values<\/span>","31a11a0a":"## Numerical Variable analysis","f391b56c":"* highly skewed towards right","e10d6c44":"* Normally skewed little bit towards right","be7d22d6":"* highly skewed towards left","4907f9af":"# <span style=\"color:Crimson;\">Data Description<\/span>","b7c03c6f":"* highly skewed towards left","f540fea8":"> **Observations:**\n* No strong correlation between our features.","04da014c":"# <center> Spotify Song Attributes | EDA and Prediction\n    \n![image.png](https:\/\/c.tenor.com\/d_IO8M1rCD0AAAAC\/listening-to-music-jerry.gif)\n ","7a77bce0":"# <span style=\"color:Crimson;\">Exploratory Data Analysis<\/span>","3d483110":"* energy and loudness have high corelation among all","dfc5bce5":"**KNeighborsClassifier**","1138437a":"* **acousticness:** A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n\n* **Danceability:** Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable\n\n* **Duration_ms:** The duration of the track in milliseconds.\n\n* **Energy:** Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n\n* **Instrumentalness:** Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n\n* **Key:** The key the track is in. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n\n* **Liveness:** Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n\n* **Loudness:** The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.\n\n* **mode:** Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n\n* **Speechiness:** Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n\n* **Tempo:** The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n\n* **Time_signature:** An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n\n* **valence:** A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n* **Target:**  \"1\" meaning I like it and \"0\" for songs I don't like\n\n* **Song_Title:** song title\n\n* **Artist:** artist of song","0e70c769":"* highly Skewed to left","47ce182e":"## Splitting the data into training and testing sets","266fe61f":"> **Observations**\n\n* Highest liveness is -0.30 and lowest is 0.19\n* maximum enery 0.97","47404700":"we don't need unamed: 0","6e09ae0d":"* If the skewness is between -0.5 & 0.5, the data are nearly symmetrical.If the skewness is between -1 & -0.5 (negative skewed) or between 0.5 & 1(positive skewed), the data are slightly skewed.If the skewness is lower than -1 (negative skewed) or greater than 1 (positive skewed), the data are extremely skewed.\n* Kurtosis is a statistical measure, whether the data is heavy-tailed or light-tailed in a normal distribution\n\n> **Observations**\n* acousticness,durations_ms,instrumentalness,liveness,loudness,energy,danceability and speechiness are extremely skewed","0c64a9f2":"## Univariate Analysis of Categorical Variables","95d5a9e0":"# <span style=\"color:Crimson;\">Training models<\/span>","b7d80b7d":"## Correlation plot for numerical variables","c7235df2":"## Analysing Categorical Variables with target","7db8acf0":"> **Observations:**\n\n\n* There are few outliers in acousticness vs danceability and loudness vs speechiness.\n\n* The acousticness vs danceability and duration_ms vs enery group is heavily distributed between 0-0.2 and 0.2-0.4.","494730c5":"> **Observations**\n* Total artists are 1343\n* Total 12 keys","fb02276a":"# <span style=\"color:Crimson;\">Importing Libraries<\/span>","1cc6bf9b":"* Highly towards left"}}