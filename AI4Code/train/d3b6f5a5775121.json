{"cell_type":{"395e71c3":"code","e7f399db":"code","993285c8":"code","5260bb9f":"code","10292f2a":"code","50274a80":"code","92f56e71":"code","067984f9":"code","d063f2d3":"code","8063bed6":"code","7540e8d7":"code","1fb4567e":"code","a87b34ae":"code","1e410366":"code","a5187b9e":"code","26b105a4":"code","eedf3e2c":"code","3cfb2abd":"code","d64b0db8":"code","20ff8fcb":"markdown","6ca097e4":"markdown","33721a31":"markdown","c929a547":"markdown","2cc1651c":"markdown","50de34aa":"markdown","c6c29850":"markdown","08701d51":"markdown","537f6d3c":"markdown","b4b6bdc5":"markdown","bcf5589b":"markdown","dd6d304a":"markdown","442ef2ed":"markdown","25a05a52":"markdown","29671df9":"markdown","fa16fa22":"markdown","c74ba669":"markdown","bf5c7c73":"markdown","a2797cd9":"markdown","cbf4840d":"markdown","e6cd61ea":"markdown"},"source":{"395e71c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import tree\n\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7f399db":"df = pd.read_csv(dirname + '\/train.csv')\ndf.sample(10)","993285c8":"df.shape","5260bb9f":"df['Exited'].value_counts(normalize=True).plot.barh();","10292f2a":"df.drop(columns=['RowNumber', \"CustomerId\", 'Surname'], inplace=True)","50274a80":"plt.rcParams[\"figure.figsize\"] = (15,7)\n\nfig, ax =plt.subplots(1,2)\nsns.heatmap(df.corr(method='spearman'), ax=ax[0]).set_title('Spearman');\nsns.heatmap(df.corr(method='pearson'), ax=ax[1]).set_title('Pearson');\nfig.show()","92f56e71":"df.head()","067984f9":"df['Gender'].value_counts(normalize=True).plot.barh();","d063f2d3":"df['NumOfProducts'].value_counts(normalize=True).plot.barh();","8063bed6":"df['Geography'].value_counts(normalize=True).plot.barh();","7540e8d7":"sns.histplot(df['Balance']);","1fb4567e":"sns.histplot(df['EstimatedSalary']);","a87b34ae":"X_train, X_val, y_train, y_val = train_test_split(df.drop(columns='Exited'), df['Exited'], random_state=42, test_size=0.2)","1e410366":"def pre_process_knn(df, std_scaler=None):\n    \"\"\"\n    Realiza o pre-processamento de nosso dataset para que ele seja utilizado pelo modelo kNN\n    \n    Parametros:\n    df -> DataFrame do Pandas com dados do treino\n    std_scaler -> Transformador de escala do SkLearn. Deve ser passado por par\u00e2metro apenas na etapa de valida\u00e7\u00e3o \/ teste.\n    \n    Retorno:\n    df -> DataFrame do Pandas\n    std_scaler -> Scaler ajustado para os dados do treino\n    \"\"\"\n    return_std_scaler = False\n    \n    countries_pre_processed = pd.get_dummies(df['Geography'])\n    num_products_pre_processed = pd.get_dummies(df['NumOfProducts'])\n    num_products_pre_processed = pd.get_dummies(df['Gender'])\n\n    df = pd.concat([df, countries_pre_processed, num_products_pre_processed], axis=1)\n    df.drop(columns=['Geography', \"NumOfProducts\", 'Gender'], inplace=True)\n    \n    # O codigo do if so sera executado durante o treino.\n    # No teste, passaremos o std_scaler por parametro.    \n    if (std_scaler is None):\n        std_scaler = StandardScaler().fit(df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']])\n        return_std_scaler = True\n    \n    df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']] = std_scaler.transform(df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']])\n    \n    # Preencheremos os nulos com a m\u00e9dia da coluna\n    df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']] = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']].fillna(df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']].mean())\n    \n    if (return_std_scaler):\n        return df, std_scaler\n    else:\n        return df","a5187b9e":"X_train_processed_knn, std_scaler = pre_process_knn(X_train)\n\n# Treinamento\nknn = KNeighborsClassifier()\nknn.fit(X_train_processed_knn, y_train)\n\n# Validacao\nX_val_preprocessed_knn = pre_process_knn(X_val, std_scaler=std_scaler)\n\nroc_auc_score(y_val, knn.predict_proba(X_val_preprocessed_knn)[:, 1])","26b105a4":"def pre_process_nb(df):\n    \"\"\"\n    Realiza o pre-processamento de nosso dataset para que ele seja utilizado pelo modelo Naive Bayes\n    \n    Parametros:\n    df -> DataFrame do Pandas com dados do treino\n    \n    Retorno:\n    df -> DataFrame do Pandas\n    \"\"\"\n    return_std_scaler = False\n    \n    countries_pre_processed = pd.get_dummies(df['Geography'])\n    num_products_pre_processed = pd.get_dummies(df['NumOfProducts'])\n    num_products_pre_processed = pd.get_dummies(df['Gender'])\n\n    df = pd.concat([df, countries_pre_processed, num_products_pre_processed], axis=1)\n    df.drop(columns=['Geography', \"NumOfProducts\", 'Gender'], inplace=True)\n      \n    # Preencheremos os nulos com a m\u00e9dia da coluna\n    df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']] = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']].fillna(df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']].mean())\n    \n    return df","eedf3e2c":"X_train_processed_nb = pre_process_nb(X_train)\n\n# Treinamento\nnb_clf = GaussianNB()\nnb_clf.fit(X_train_processed_nb, y_train)\n\n# Validacao\nX_val_preprocessed_nb = pre_process_nb(X_val)\n\nroc_auc_score(y_val, nb_clf.predict_proba(X_val_preprocessed_nb)[:, 1])","3cfb2abd":"def pre_process_decision_tree(df):\n    \"\"\"\n    Realiza o pre-processamento de nosso dataset para que ele seja utilizado pelo modelo Decision Tree\n    \n    Parametros:\n    df -> DataFrame do Pandas com dados do treino\n    \n    Retorno:\n    df -> DataFrame do Pandas\n    \"\"\"\n    return_std_scaler = False\n    \n    countries_pre_processed = pd.get_dummies(df['Geography'])\n    num_products_pre_processed = pd.get_dummies(df['NumOfProducts'])\n    num_products_pre_processed = pd.get_dummies(df['Gender'])\n\n    df = pd.concat([df, countries_pre_processed, num_products_pre_processed], axis=1)\n    df.drop(columns=['Geography', \"NumOfProducts\", 'Gender'], inplace=True)\n      \n    # Preencheremos os nulos com a m\u00e9dia da coluna\n    df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']] = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']].fillna(df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']].mean())\n    \n    return df","d64b0db8":"X_train_processed_decision_tree = pre_process_decision_tree(X_train)\n\n# Treinamento\nnb_clf = tree.DecisionTreeClassifier()\nnb_clf.fit(X_train_processed_decision_tree, y_train)\n\n# Validacao\nX_val_preprocessed_decision_tree = pre_process_decision_tree(X_val)\n\nroc_auc_score(y_val, nb_clf.predict_proba(X_val_preprocessed_decision_tree)[:, 1])","20ff8fcb":"### Number of Products\nA vari\u00e1vel \u00e9 absurdamente desbalanceada. ","6ca097e4":"### Train-test-split","33721a31":"### kNN","c929a547":"Neste caso, temos um desbalanceamento relevante entre os dados. Isso n\u00e3o ser\u00e1 t\u00e3o importante nesse baseline, mas \u00e9 absurdamente necess\u00e1rio que voc\u00ea leve isso em considera\u00e7\u00e3o nas itera\u00e7\u00f5es seguintes do pipeline.","2cc1651c":"# Getting Started\n\nO objetivo deste notebook \u00e9 fornecer um bom headstart para os que ainda n\u00e3o come\u00e7aram e, tamb\u00e9m, oferecer um padr\u00e3o legal de compara\u00e7\u00e3o entre os c\u00f3digos subemetidos daqui pra frente.\n\nEstamos exatamente no meio da competi\u00e7\u00e3o :D","50de34aa":"### Naive Bayes","c6c29850":"## Data fields\n- RowNumber - Row Numbers from 1 to 10000\n- CustomerId - Unique Ids for bank customer identification\n- Surname - Customer's last name\n- CreditScore - Credit score of the customer\n- Geography - The country from which the customer belongs\n- Gender - Male or Female\n- Age - Age of the customer\n- Tenure - Number of years for which the customer has been with the bank\n- Balance - Bank balance of the customer\n- NumOfProducts - Number of bank products the customer is utilising\n- HasCrCard - Binary Flag for whether the customer holds a credit card with the bank or not\n- IsActiveMember - Binary Flag for whether the customer is an active member with the bank or not\n- EstimatedSalary - Estimated salary of the customer in Dollars\n- Exited - Binary flag 1 if the customer closed account with bank and 0 if the customer is retained","08701d51":"## Distribui\u00e7\u00f5es problem\u00e1ticas?\nTenho a suspeita de que as vari\u00e1veis `Balance` e `EstimatedSalary` possuam uma distribui\u00e7\u00e3o com muitos outliers ou, pelo menos, problem\u00e1tica","537f6d3c":"## Problemas com a an\u00e1lise acima\n\nRepare que, em nossa an\u00e1lise, n\u00e3o foram consideradas vari\u00e1veis categ\u00f3ricas e tamb\u00e9m n\u00e3o levamos em considera\u00e7\u00e3o que algumas vari\u00e1veis podem ter distribui\u00e7\u00f5es muito extremas, como \"Balance\" ou \"EstimatedSalary\". Vamos olhar um pouco mais para essas vari\u00e1veis agora.","b4b6bdc5":"Repare na coluna do \"Exited\". Ela pode mostrar algumas coisas interessantes sobre as vari\u00e1veis que podem ser mais importantes no processo de classifica\u00e7\u00e3o. Fora isso, nada salta muito aos olhos.","bcf5589b":"Pronto! Com isso, definimos ent\u00e3o que nosso baseline ser\u00e1 nosso classificador Naive Bayes simples utilizado acima com uma AUC de 0.7565518144021566!\n\nAgora \u00e9 com voc\u00ea. Continue esse notebook, tenha ideias de novas features e tratamento de dados, al\u00e9m de novos pipelinies e ensembles. Boa sorte ;)","dd6d304a":"## Balanceamento do Target\nPelo gr\u00e1fico abaixo \u00e9 poss\u00edvel ver que estamos trabalhando sob um regime de extremo desbalanceamento. Isso afetar\u00e1 a m\u00e9trica a ser utilizada (por isso usamos a AUC) e a forma que realizaremos o treinamento de nossos algoritmos.","442ef2ed":"## Finding correlations","25a05a52":"### Geography","29671df9":"## Remo\u00e7\u00e3o de features n\u00e3o importantes\nA princ\u00edpio, vamos remover as features `RowNumber`, `Surname` e `CustomerId` porque assimiremos que a distribui\u00e7\u00e3o dos dados que queremos prever n\u00e3o pode ser discriminada pelas duas features, isto \u00e9: ningu\u00e9m vai encerrar sua conta num banco pela posi\u00e7\u00e3o que ocupava no banco de dados da institui\u00e7\u00e3o (`RowNumber` e `CustomerId`) nem pelo sobrenome que possui (`Surname`). ","fa16fa22":"### Decision Tree","c74ba669":"## Tamanho da base e n\u00famero de features","bf5c7c73":"### Gender\nRelativamente balanceada","a2797cd9":"Como eu imaginava, essas duas features possuem distribui\u00e7\u00f5es com outliers e formatos estranhos. Isso pode ser um problema, mas com um pouco de feature engineering e tratamento, talvez voc\u00ea consiga sair bem dessa. Voc\u00ea consegue pensar em algo?","cbf4840d":"## Baselines\n\nUm baseline \u00e9 um modelo simples que possibilita ter um base de compara\u00e7\u00e3o, para saber se seu algoritmo est\u00e1 indo bem ou mal em determinada tarefa. Esse modelo pode ser um modelo de machine learning, uma m\u00e9trica estat\u00edstica ou uma heur\u00edstica baseada em experi\u00eancia mesmo. Por exemplo, se a nossa m\u00e9trica fosse Accuracy, poder\u00edamos instanciar nosso baseline como sendo simplesmente \"um modelo que sempre prediz 0\", pois como vimos no come\u00e7o do Notebook, nossas classes s\u00e3o absurdamente desbalanceadas, ent\u00e3o s\u00f3 com esse modelo simples ter\u00edamos 80% de Accuracy. \n\nMeu baseline aqui ser\u00e1 feito da seguinte maneira: vou instanciar 3 modelos de machine learning e definir como meu baseline aquele que tiver melhor AUC no treino, simples assim :)","e6cd61ea":"Como uma boa pr\u00e1tica, vamos verificar a correla\u00e7\u00e3o entre as vari\u00e1veis para checar se algo salta aos olhos. Como temos poucas vari\u00e1veis, vamos simplesmente plotar as correla\u00e7\u00f5es de \"Spearman\" e \"Pearson\" lado a lado. "}}