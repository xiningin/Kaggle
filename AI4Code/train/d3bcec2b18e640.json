{"cell_type":{"dcb983b8":"code","0376277e":"code","7fbecadb":"code","3c51cf93":"code","5524efd4":"code","3d1c1fa6":"code","925f67db":"code","f3f571cf":"code","865a15d2":"code","41f913dc":"code","01bc03c7":"code","8aeb4e07":"code","1852dda4":"code","811a969a":"code","535cd04b":"code","dc1e0cce":"code","79b511bd":"code","94a40748":"code","fa99be54":"code","93a6e9ab":"code","03cc186b":"code","32a577d2":"code","3329fbc8":"code","56ecb10a":"code","e8aaf13e":"code","126f0a73":"code","641d8a47":"markdown","42d3d680":"markdown","71b1ff4f":"markdown","96b7e2d7":"markdown","44eb7b30":"markdown"},"source":{"dcb983b8":"import os\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend as K\nfrom tensorflow.python.keras.utils.vis_utils import plot_model","0376277e":"SEED=777\nNUM_CLASSES=10\nMARGIN=1.0\nEPOCH=20\nBATCH_SIZE=64\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nseed_everything(SEED)","7fbecadb":"def load_data():\n    train = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\n    test = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\n    \n    train_labels = train.pop('label')\n    train_images = [train.iloc[idx].values.reshape(28,28) for idx in range(len(train))]\n    train_images = np.array(train_images)\n\n    test_labels = test.pop('label')\n    test_images = [test.iloc[idx].values.reshape(28,28) for idx in range(len(test))]\n    test_images = np.array(test_images)\n    \n    return train_images, train_labels, test_images, test_labels\n\ntrain_images, train_labels, test_images, test_labels = load_data()","3c51cf93":"print(train_images.shape, train_labels.shape)\nprint(test_images.shape, test_labels.shape)","5524efd4":"plt.imshow(train_images[0], cmap='gray')","3d1c1fa6":"def create_pairs(x, digit_indices):\n    '''\n    Positive and negative pair creation.\n    Alternates between positive and negative pairs.\n    '''\n    pairs = []\n    labels = []\n    n = min([len(digit_indices[d]) for d in range(NUM_CLASSES)]) - 1\n    for d in range(NUM_CLASSES):\n        for i in range(n):\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n            pairs += [[x[z1], x[z2]]]\n            inc = random.randrange(1, NUM_CLASSES)\n            dn = (d + inc) % NUM_CLASSES\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n            pairs += [[x[z1], x[z2]]]\n            labels += [1, 0]\n    return np.array(pairs), np.array(labels)\n\ndef make_pair_dataset(images, labels):\n    digit_indices = [np.where(labels == i)[0] for i in range(NUM_CLASSES)]\n    pairs, y = create_pairs(images, digit_indices)\n    return pairs, y","925f67db":"tr_pairs, tr_y = make_pair_dataset(train_images, train_labels)\nte_pairs, te_y = make_pair_dataset(test_images, test_labels)","f3f571cf":"print(tr_pairs.shape, tr_y.shape)\nprint(te_pairs.shape, te_y.shape)","865a15d2":"# Label 1 for pairs of images with the same label, 0 for pairs of images with different labels\nplt.subplot(2,2,1)\nplt.imshow(tr_pairs[0][0], cmap='gray')\nplt.title(\"positive pair {}\".format(tr_y[0]))\n\nplt.subplot(2,2,2)\nplt.imshow(tr_pairs[0][1], cmap='gray')\nplt.title(\"positive pair {}\".format(tr_y[0]))\n\nplt.subplot(2,2,3)\nplt.imshow(tr_pairs[2][0], cmap='gray')\nplt.title(\"negative pairs {}\".format(tr_y[1]))\n\nplt.subplot(2,2,4)\nplt.imshow(tr_pairs[2][1], cmap='gray')\nplt.title(\"negative pairs {}\".format(tr_y[1]))\n\nplt.tight_layout()\nplt.show()","41f913dc":"#tr_pairs[:, 0] = tr_pairs[:, 0] \/ 255.0\n#tr_pairs[:, 1] = tr_pairs[:, 1] \/ 255.0\ntr_y = tr_y.astype(np.float32)\n#te_pairs[:, 0] = te_pairs[:, 0] \/ 255.0\n#te_pairs[:, 1] = te_pairs[:, 1] \/ 255.0\nte_y = te_y.astype(np.float32)\n\nx_tra, x_val, y_tra, y_val = train_test_split(tr_pairs, tr_y, test_size=0.2, stratify=tr_y, random_state=SEED)\n\nprint(x_tra.shape, y_tra.shape)\nprint(x_val.shape, y_val.shape)","01bc03c7":"# a = tf.constant([[1, 2],\n#                  [3, 4]], dtype='float')\n# b = tf.constant([[1, 1],\n#                  [1, 1]], dtype='float') # Could have also said `tf.ones([2,2])`\n# sum_square = K.sum(K.square(a - b), axis=1, keepdims=True) #(batch, 128) -> (batch, 1)\n# sum_square","8aeb4e07":"# K.maximum(sum_square, K.epsilon()) # min_value = epsilon \n# K.sqrt(K.maximum(sum_square, K.epsilon()))","1852dda4":"def init_base_network():\n    input = Input(shape=(28,28,), name='base_input')\n    x = Flatten(name='flatten_input')(input)\n    x = BatchNormalization()(x)\n    x = Dense(128, activation='relu',name='base_dense_1')(x)\n    x = Dropout(0.1, name='base_dropout_1')(x)\n    x = Dense(128, activation='relu',name='base_dense_2')(x)\n    x = Dropout(0.1, name='base_dropout_2')(x)\n    x = Dense(128, activation='relu',name='base_dense_3')(x)\n    return Model(inputs=input, outputs=x)\n\ndef euclidean_distance(vects):\n    x,y = vects\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True) #(batch, 128) -> (batch, 1)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n    \ndef eucl_dist_output_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1) #(batch_size, 1)\n\ndef build_model():\n    base_network = init_base_network()\n    input_1 = Input(shape=(28,28), name='input_1')\n    input_2 = Input(shape=(28,28), name='input_2')\n    vec1 = base_network(input_1)\n    vec2 = base_network(input_2)\n    \n    distance = Lambda(euclidean_distance,\n                      output_shape=eucl_dist_output_shape,\n                      name='output_layer'\n                     )([vec1, vec2])\n    model = Model(inputs=[input_1, input_2], outputs=distance)\n    return model","811a969a":"plot_model(init_base_network(),show_shapes=True, show_layer_names=True)","535cd04b":"model = build_model()\nplot_model(model, show_shapes=True, show_layer_names=True)","dc1e0cce":"def contrastive_loss_with_margin(margin):\n    def contrastive_loss(y_true, y_pred):\n        square_pred = K.square(y_pred) # If y_true=1, learn to make y_pred (Euclidean distance) smaller\n        margin_square = K.square(K.maximum(margin - y_pred, 0)) # If y_true=0, learn to make y_pred (Euclidean distance) greater than the margin\n        return K.mean(y_true * square_pred + (1-y_true) * margin_square)\n    return contrastive_loss","79b511bd":"opt = Adam(learning_rate=1e-4)\nloss = contrastive_loss_with_margin(MARGIN)\nmodel.compile(optimizer=opt, loss=loss)","94a40748":"history= model.fit([x_tra[:,0], x_tra[:, 1]], y_tra, epochs=EPOCH, batch_size=BATCH_SIZE, \n                    validation_data=([x_val[:, 0], x_val[:, 1]], y_val))","fa99be54":"def plot_history(history):\n    plt.title('Train\/validation loss')\n    plt.plot(history.history['loss'], label = 'training loss')\n    plt.plot(history.history['val_loss'], label = 'validation loss')\n    plt.grid()\n    plt.legend()\n    plt.show()\n\nplot_history(history)","93a6e9ab":"def compute_accuracy(y_true, y_pred):\n    pred = y_pred.ravel() < 0.5\n    return np.mean(y_true == pred)\n\nprint('Train accuracy: ', compute_accuracy(y_tra, model.predict([x_tra[:, 0], x_tra[:, 1]])))\nprint('Valid accuracy: ', compute_accuracy(y_val, model.predict([x_val[:, 0], x_val[:, 1]])))\nprint('Test accuracy: ', compute_accuracy(te_y, model.predict([te_pairs[:, 0], te_pairs[:, 1]])))","03cc186b":"pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]]).ravel()","32a577d2":"# Check image distance\nfor idx, dist in enumerate(pred[:10]):\n    print(f'distance: {dist}')\n    img1, img2 = te_pairs[idx, 0], te_pairs[idx, 1]\n    fig, ax = plt.subplots(1,2)\n    ax[0].imshow(img1, cmap='gray',)\n    ax[1].imshow(img2, cmap='gray',)\n    plt.show()","3329fbc8":"model.layers[2].name","56ecb10a":"# get image embeddings\nbase_network = model.layers[2]\nembeddings = base_network.predict(train_images)","e8aaf13e":"import seaborn as sns\nsns.set()\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2, random_state=SEED)\npca_embeddings = pca.fit_transform(embeddings)","126f0a73":"pal = sns.color_palette(\"hls\",len(train_labels.unique()))\n#pal\nsns.scatterplot(x=pca_embeddings[:,0], y=pca_embeddings[:, 1], hue=train_labels, palette=pal)","641d8a47":"# Split dataset","42d3d680":"# Model","71b1ff4f":"# Config","96b7e2d7":"# Show image embeddings","44eb7b30":"# Make dataset"}}