{"cell_type":{"857084a5":"code","fcad99ba":"code","d757604c":"code","636d817c":"code","fac0da6d":"code","95fd364c":"code","c797c00b":"code","0188f47e":"code","811cff26":"code","60b8ebe0":"code","b8429b59":"code","58088990":"code","9a498dfb":"code","e991c855":"code","1e1b63ec":"code","6cd67a78":"code","28354e05":"code","b762390e":"code","ec1e0c62":"code","13595c0f":"code","d5927fcf":"code","591ad86f":"code","3b2fe572":"markdown","0276caf1":"markdown","ad02154a":"markdown","bd401aa6":"markdown","6fc62f82":"markdown","a50b786c":"markdown","4c178060":"markdown","d69598e3":"markdown","0ea48665":"markdown","4d59f498":"markdown","24125f8c":"markdown","fe55db9f":"markdown","e84d94ef":"markdown","27470997":"markdown","f1af149b":"markdown"},"source":{"857084a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","fcad99ba":"train_identity = pd.read_csv('..\/input\/train_identity.csv')\ntrain_transaction = pd.read_csv('..\/input\/train_transaction.csv')","d757604c":"## Function to reduce the DF size. Re-used from  https:\/\/www.kaggle.com\/kabure\/extensive-eda-and-modeling-xgb-hyperopt\/notebook\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","636d817c":"train_identity = reduce_mem_usage(train_identity)\ntrain_transaction = reduce_mem_usage(train_transaction)","fac0da6d":"train_transaction.head()","95fd364c":"total = len(train_transaction)\nax = sns.countplot(x='isFraud', data=train_transaction)\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\") ","c797c00b":"f, axes = plt.subplots(1, 2, figsize=(18, 6))\ncard4_ax = sns.countplot(x='card4', hue='isFraud', data=train_transaction, ax=axes[0])\ncard6_ax = sns.countplot(x='card6', hue='isFraud', data=train_transaction, ax=axes[1])\nfor ax in axes:\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/total*100),\n                ha=\"center\") ","0188f47e":"# cards 1,2,3,5 \nf, axes = plt.subplots(4, 1, figsize=(18, 8))\ncard1_ax = sns.distplot(train_transaction['card1'], ax=axes[0])\ncard2_ax = sns.distplot(train_transaction['card2'].dropna(), ax=axes[1])\ncard3_ax = sns.distplot(train_transaction['card3'], ax=axes[2], kde=False)\ncard4_ax = sns.distplot(train_transaction['card5'].dropna(), ax=axes[3])","811cff26":"f, axes = plt.subplots(1, 2, figsize=(18, 6))\naddr1 = sns.distplot(train_transaction['addr1'].dropna(), ax=axes[0], kde=False)\naddr2 = sns.distplot(train_transaction['addr2'], ax=axes[1], kde=True)","60b8ebe0":"g = sns.FacetGrid(train_transaction, col=\"isFraud\")\ng.map(sns.distplot, \"addr1\")","b8429b59":"g = sns.FacetGrid(train_transaction, col=\"isFraud\")\ng.map(sns.distplot, \"addr2\")","58088990":"#correlation between addr1 and addr2\n# copied the code from https:\/\/towardsdatascience.com\/the-search-for-categorical-correlation-a1cf7f1888c9\nfrom scipy import stats as ss\ndef cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))\n\ncramers_v(train_transaction['addr1'], train_transaction['addr2'])","9a498dfb":"ax = sns.countplot(x='ProductCD', hue='isFraud', data=train_transaction )\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\", fontsize=10) ","e991c855":"sns.boxenplot(x=\"ProductCD\", y='TransactionAmt', hue='isFraud',data=train_transaction.sample(2000))","1e1b63ec":"f, axes = plt.subplots(1, 2, figsize=(18, 12))\n\nsns.set(color_codes=True)\np_email = sns.countplot(y='P_emaildomain', data=train_transaction, ax=axes[0])\nr_email = sns.countplot(y='R_emaildomain', data=train_transaction, ax=axes[1])","6cd67a78":"p_df = train_transaction['P_emaildomain'].value_counts()\np_df = p_df.reset_index()\np_df.columns = ['emaildomain', 'count']\np_df = p_df[p_df['count'] > 2000]\n\nr_df = train_transaction['R_emaildomain'].value_counts()\nr_df = r_df.reset_index()\nr_df.columns = ['emaildomain', 'count']\nr_df = r_df[r_df['count'] > 800]","28354e05":"f, axes = plt.subplots(1, 2, figsize=(18, 12))\n\n#sns.set(color_codes=True)\np_email = sns.countplot(y='P_emaildomain', data=train_transaction[train_transaction['P_emaildomain'].isin(p_df['emaildomain'].values)], hue = 'isFraud', ax=axes[0])\nr_email = sns.countplot(y='R_emaildomain', data=train_transaction[train_transaction['R_emaildomain'].isin(r_df['emaildomain'].values)], hue = 'isFraud', ax=axes[1])","b762390e":"col_ls =  ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\nf, axes = plt.subplots(3, 3, figsize=(18, 12))\ncount = 0\nfor i in range(3): # rows loop\n    for j in range(3): # cols loop\n        mplot = sns.countplot(x=col_ls[count], hue = 'isFraud', data=train_transaction, ax=axes[i,j])\n        count += 1 # to loop over col-names\n        \nfor ax_r in axes:\n    for ax in ax_r:\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x()+p.get_width()\/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(height\/total*100),\n                    ha=\"center\") ","ec1e0c62":"g = sns.FacetGrid(train_transaction, col=\"isFraud\")\ng.map(sns.kdeplot, \"TransactionAmt\")","13595c0f":"# since the distribution is very skwed, lets check for the amounts greate than 10000\n\ntr_amt = train_transaction[train_transaction['TransactionAmt'] > 10000]\ntr_amt","d5927fcf":"sns.distplot(train_transaction[train_transaction['TransactionAmt'] <= 6000]['TransactionAmt'])","591ad86f":"#lets check for the distribution for the transactin amoutn < 1000 as most of the transactions have amount less than 100\ng = sns.FacetGrid(train_transaction[train_transaction['TransactionAmt'] <= 1000], col=\"isFraud\")\ng.map(sns.kdeplot, \"TransactionAmt\", )","3b2fe572":"* M1 - 53% of the transactions have value 'T'. Very few transactions (25) have a value of 'F'. Rest all are Nan. Also, there are no fradulent transactions for the category of 'F' \n* Almost all the columns M1-M9 (except M6) have 50% Nan values.","0276caf1":"#### Lets Analyze Transaction Amount distribution","ad02154a":"only 2 transactions with amount > 10000 present and both are not Fraud","bd401aa6":"Lets see the ratio of Fraud and Non Fraud instances in the data","6fc62f82":"Analysis of email domains","a50b786c":"### Following are the Categorical Features in Transaction table\n* ProductCD\n* card1 - card6\n* addr1, addr2\n* P_emaildomain[](http:\/\/)\n* R_emaildomain\n* M1 - M9","4c178060":"Lets explore ProductCD column","d69598e3":"Data is very skewed. only 3.5% of the data is Fraud","0ea48665":"Lets check the distributions for addr1 and addr2 columns","4d59f498":"Most transactions are on Visa and Master Card. Also on debit and credit cards.\nThere are no transactions at all for charge card type and no fraud transaction on the category of 'debit or credit'","24125f8c":"There are no transactions for most of the domains. Lets filter out for the common domains and check for Fraud or non-Fraud transactions","fe55db9f":"As can be seen, fraudulent transactions exist in very few P_emaildomain and R_emaildomain categories.","e84d94ef":"addr2 with value 87 has more transactions**","27470997":"Lets analyze M1 to M9 columns","f1af149b":"* Card4 column is giving the details of type of Card - Visa, Master etc \n* Card 6 refers to debit or credit. \n* Lets see the percentage of Fraud transactions for each category"}}