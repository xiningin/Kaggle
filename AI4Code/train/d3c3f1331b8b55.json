{"cell_type":{"b3cfe098":"code","f58ee71d":"code","e20a6b39":"code","eb56f470":"code","e9c41b97":"code","24265262":"code","1f15daec":"code","1443626f":"code","78102093":"code","89018616":"code","f39a60b4":"code","64cc54d6":"code","3ea9d6f5":"code","558be802":"code","22faf42d":"code","1cca9fd7":"code","b55cf55d":"code","13c0b9fc":"code","28f5c483":"code","539e9e25":"code","7c5f8727":"code","f70ea93f":"code","ba965d05":"code","a4981aba":"code","30b793c6":"code","bccb0a70":"code","38ffa941":"code","0bfa923c":"code","4c144a17":"markdown","9442cd54":"markdown","57d040e8":"markdown","0c0da39d":"markdown","ef5050f1":"markdown","4e870b47":"markdown","75ebb93e":"markdown","9d3e72c7":"markdown","3ff78566":"markdown","76cc8db6":"markdown","92e961b1":"markdown","61f687a8":"markdown","dd053854":"markdown","4867276e":"markdown","b322359e":"markdown","db351fb8":"markdown","0dec4980":"markdown","5594d9d1":"markdown","4be184e6":"markdown","1e8043df":"markdown"},"source":{"b3cfe098":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n","f58ee71d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras import layers, models\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.image as mpimg\nimport zipfile\nimport os\nimport re","e20a6b39":"# DATASET_ZIP = 'data\/tamil_characters.zip'\nIMAGE_SHAPE = (120, 120, 1)","eb56f470":"# with zipfile.ZipFile(DATASET_ZIP, 'r') as z:\n#   z.extractall('data')\n# os.rename('data\/shuffled', 'data\/train')","e9c41b97":"TRAIN_PATH = '\/kaggle\/input\/tamil-handwritten-characters-dataset\/shuffled'\nprint('Number of images in the dataset: ', len(os.listdir(TRAIN_PATH)))","24265262":"files = os.listdir(TRAIN_PATH)\ntarget = []\nfor filename in os.listdir(TRAIN_PATH):\n  substr = re.search('_(.+?)t', filename)\n  if(substr):\n    category = substr.group(1)\n    target.append(category)\n\n# Create a DataFrame\ndf = pd.DataFrame({\n    'filename': files,\n    'category': target\n})","1f15daec":"print('Number of unique characters: {}'.format(df['category'].unique()))\ndf.head()","1443626f":"for each in df['category'].unique():\n  filename = df[df['category'] == each]['filename'].iloc[0]\n  plt.figure()\n  img = mpimg.imread(os.path.join(TRAIN_PATH, filename))\n  plt.imshow(img)\n  plt.title(filename)\n  plt.show()","78102093":"# Map Tamil Character Category values to its equivalent Unicode characters\nMAP = {\n    '000':u'\\u0B85', \n    '001':u'\\u0B86', \n    '002':u'\\u0B87', \n    '003':u'\\u0B88', \n    '004':u'\\u0B89', \n    '005':u'\\u0B8A', \n    '006':u'\\u0B8E', \n    '007':u'\\u0B8F', \n    '008':u'\\u0B90', \n    '009':u'\\u0B92', \n    '010':u'\\u0B93', \n    '155':u'\\u0B94'\n    }","89018616":"MAP.items()","f39a60b4":"df['category'].value_counts().plot.bar()","64cc54d6":"# Drop the class with less data\ndf.drop(df[df['category'] == '155'].index, inplace = True) ","3ea9d6f5":"df['category'].value_counts()","558be802":"for filename in df[df['category']=='006']['filename']:\n  plt.figure()\n  img = mpimg.imread(os.path.join(TRAIN_PATH, filename))\n  plt.imshow(img)\n  plt.title(filename)\n  plt.show()","22faf42d":"# height, width, depth = im_data.shape\nheight, width, depth = [], [], []\nfor filename in df['filename']:\n  img = mpimg.imread(os.path.join(TRAIN_PATH, filename))\n  h, w, d = img.shape\n  height.append(h)\n  width.append(w)\n  depth.append(d)\n\ndim_df = pd.DataFrame({\n    'height': height,\n    'width': width,\n    'depth': depth\n})","1cca9fd7":"dim_df.describe()","b55cf55d":"train_df, val_df = train_test_split(df, test_size=0.2, random_state=28) \ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","13c0b9fc":"print('Train Dataset Size: ', len(train_df))\nprint('Validation Dataset Size: ', len(val_df))\n\n\ntrain_df['category'].value_counts().plot.bar()\nplt.title('Train Dataset Data Distribution')\nplt.show()\n\nplt.figure()\n\nval_df['category'].value_counts().plot.bar()\nplt.title('Validation Dataset Data Distribution')\nplt.show()","28f5c483":"batch_size = 5\nepoch = 50\n\ntrain_count = train_df.shape[0]\nval_count = val_df.shape[0]\n\ntrain_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    # rotation_range = 10,\n    # width_shift_range = 0.2,\n    # height_shift_range = 0.2,\n    # shear_range = 0.2,\n    horizontal_flip=False,\n    fill_mode='nearest', \n    )\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    train_df,\n    directory = TRAIN_PATH,\n    x_col = 'filename',\n    y_col = 'category',\n    class_mode = 'categorical',\n    target_size = IMAGE_SHAPE[:2],\n    batch_size = batch_size,\n    color_mode='grayscale'\n)\n\nval_gen = train_datagen.flow_from_dataframe(\n    val_df,\n    directory = TRAIN_PATH,\n    x_col = 'filename',\n    y_col = 'category',\n    class_mode = 'categorical',\n    target_size = IMAGE_SHAPE[:2],\n    batch_size = batch_size,\n    color_mode='grayscale'\n) ","539e9e25":"def build_model():\n  model = models.Sequential()\n\n  model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=IMAGE_SHAPE))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n  model.add(layers.Dropout(0.2))\n\n  model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n  model.add(layers.Dropout(0.2))\n\n  model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n  model.add(layers.Dropout(0.2))\n\n  model.add(layers.Conv2D(64, (6, 6), activation='relu'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n  model.add(layers.Dropout(0.2))\n  \n  model.add(layers.Flatten())\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.BatchNormalization())\n  model.add(layers.Dense(11, activation='softmax'))\n\n  model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n  return model\n\nmodel = build_model()","7c5f8727":"model.summary()","f70ea93f":"from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nearlystop = EarlyStopping(patience=10)\nlrreducuction = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=2, verbose=1, min_lr=0.000005)\nfilepath = \"checkpoint.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\ncallbacks = [earlystop, lrreducuction, checkpoint]","ba965d05":"history = model.fit(\n    train_gen,\n    epochs=epoch,\n    steps_per_epoch = train_count \/\/ batch_size,\n    validation_data = val_gen,\n    validation_steps = val_count \/\/ batch_size,\n    callbacks = callbacks\n)","a4981aba":"model.save_weights(\"tamil_char.h5\")","30b793c6":"model.save(\"tamil_handwritten_char.h5\")","bccb0a70":"epoch_xaxis = range(1, len(history.history['accuracy'])+1)\n\nplt.plot(epoch_xaxis, history.history['accuracy'], 'r', label='Training Accuracy')\nplt.plot(epoch_xaxis, history.history['val_accuracy'], 'b', label='Validation Accuracy')\nplt.title('Training vs Validation Accuracy')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epoch_xaxis, history.history['loss'], 'r', label='Training Loss')\nplt.plot(epoch_xaxis, history.history['val_loss'], 'b', label='Validation Loss')\nplt.title('Training vs Validation Loss')\nplt.legend()\nplt.show()","38ffa941":"sample_test = val_df.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(os.path.join(TRAIN_PATH,filename), target_size=IMAGE_SHAPE)\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()\n\n","0bfa923c":"for index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    print(filename + ' ==> ' + MAP[category])\n","4c144a17":"### Createing a Dataframe\nCreate a dataframe that contains the image file names and its associated class.\n","9442cd54":"The model has a validation accuracy of 97.33%, which is not bad for such a small dataset.\n\nI arrived at this accuracy after tweaking the model for several hours.\n\nSystematically using feedback from validation data to improve the model, will cause information leaks. Even though the model wasnt trained on the validation dataset, due to this process some amount of data will leak to the model and it will start optimizing towards validation data.\n\nI'm not sure how this model will perform in real time. I will build an interface as the next step of this project, so that we could test this  model's performance in real time.","57d040e8":"## Data Preparation","0c0da39d":"Extract the data:","ef5050f1":"Randomly visualizing all image datapoints of one of the class to get an intuitive understanding of the dataset.","4e870b47":"Few handwritten characters are too ambiguous here.\n\nFor example, u37_006t01.tiff and u25_006t04.tiff are labeled as '006', but they also resemble class '000'.","75ebb93e":"### Build a Deep Learning model with CNN","9d3e72c7":"There are twelve vowels in Tamil, and there are twelve target values here.\n\nWe know that there are twelve classes, one for each charcter, but we dont know which class maps to which character. So, lets print one image of each class, and use that to create a dictionary that maps the class with the unicode value of that character.","3ff78566":"### Map class with Unicode String\n\nCreating a dictionary, that maps the class with the character's unicode string.","76cc8db6":"# Tamil Handwritten Character Recognition\n\nIn this project, I will build a model that will predict handwritten characters in Tamil Language.\nThe Dataset used here is **Isolated Tamil Handwritten Characters** created by HP Labs. Please check [here](http:\/\/lipitk.sourceforge.net\/hpl-datasets.htm).\n\nThis dataset contains images of Handwritten images of Tamil vowels (or Uyir Eluthukkal). \n\nGoal of this project is to build a model that predicts new handwritten tamil characters.\n\nIf you like this notebook, I would highly appreciate if you would hit that upvote button.\n\nThis project is done as a part of #100MLProjects, where I build 100 projects with the goal to get proficient in Machine Learning, Deep Learning. Learn more about #100MLProjects here: https:\/\/github.com\/laxmena\/100MLProjects\n","92e961b1":"## Visualizing Validation vs Training Accuracy and Loss","61f687a8":"The model didnt overfit, and has reached covergence.\n\n- Validation Accuracy: 97.33%\n- Validation loss: 0.1091","dd053854":"Lets visualize the distribution of data in the dataset:","4867276e":"### Model Training","b322359e":"The image dimensions in this dataset vary by a significant amount.\nThe standard deviation is really long.\n\nThe image data should be regularized before feeding it into the neural network. From the summary above, I think 120x120 shape will be a better option.\n","db351fb8":"### Splitting the Data into Training and Validation Dataset","0dec4980":"The data is not evenly distributed among all classes, and class '155' has only one image associated with it in the dataset.\n\nSo, Let's remove this class due to insufficient data.","5594d9d1":"### Create Callbacks\n","4be184e6":"### Create Training and validation Image Data Generators","1e8043df":"## CNN Model"}}