{"cell_type":{"f778cf4c":"code","71319055":"code","e2cd29c7":"code","dcb96fef":"code","5f7a6e2b":"code","b20a2d60":"code","0e960c40":"code","531f12f8":"code","ded373a5":"code","5b939e61":"code","1244b4b9":"code","bffbd7f5":"code","cf4cce02":"code","1cea3f29":"code","df01de1e":"code","34ffe9fc":"code","cd98c5af":"code","d9d96a11":"code","aab1f970":"code","6a408f51":"code","49684d49":"code","970a3f85":"code","9b169783":"code","4b830d94":"code","986e7125":"code","d0ed7854":"code","58f6ba3f":"code","a39285d9":"code","765d82e6":"code","ecc8740c":"code","4fceb04e":"code","fa4804ed":"code","f527bff1":"markdown","aa608311":"markdown","174fddc2":"markdown","8c93c483":"markdown","80654d2b":"markdown","aa40010d":"markdown","030c8e76":"markdown","4ed3f1ba":"markdown","d3555a30":"markdown","ad0d0060":"markdown","fab93cf0":"markdown","621350c5":"markdown","26bc4bb4":"markdown","3730767b":"markdown","985e8f2f":"markdown","4c39cf2b":"markdown","1919e4ca":"markdown","e9a81596":"markdown","fceb241a":"markdown","f16a9b1d":"markdown","eb858bf5":"markdown","0da16e55":"markdown","71c7f0be":"markdown","d8da6de5":"markdown","87e0567e":"markdown","1bc639f8":"markdown","b6b167f6":"markdown","29890a8d":"markdown","5e1564cc":"markdown","9f27c7e1":"markdown","344d06e3":"markdown","0a7f15c3":"markdown","f738ca35":"markdown","e65d9845":"markdown","3ba36a49":"markdown"},"source":{"f778cf4c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport re\n\nfrom wordcloud import WordCloud,STOPWORDS\n%matplotlib inline","71319055":"data = pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv')\ndata.drop(\"Unnamed: 0\",1,inplace = True)","e2cd29c7":"data.shape","dcb96fef":"data.head(10)","5f7a6e2b":"data.tail(10)","b20a2d60":"data.info()","0e960c40":"data.replace(to_replace =-1 , value=np.nan,inplace=True)\ndata.replace(to_replace ='-1' , value=np.nan,inplace=True)\ndata.replace(to_replace =-1.0 , value=np.nan,inplace=True)","531f12f8":"def FindingMissingValues(dataFrame):\n    for col in dataFrame.columns:\n        print('{0:.2f}% or {1} values are Missing in {2} Column'.format(dataFrame[col].isna().sum()\/len(dataFrame)*100,dataFrame[col].isna().sum(),col),end='\\n\\n')\n\nFindingMissingValues(data)","ded373a5":"data.drop(['Easy Apply','Competitors'],1,inplace = True)","5b939e61":"data['Job Domain'] = data['Job Title'].apply(lambda x: re.search(r',.*',x).group().replace(',','') if(bool(re.search(r',.*',x))) else x )\ndata['Job Role'] = data['Job Title'].apply(lambda x: re.search(r'.*,',x).group().replace(',','') if(bool(re.search(r',.*',x))) else x )","1244b4b9":"\ndata['Min Salary'] = 0\ndata['Max Salary'] = 0\n\nfor x in range(len(data)):\n    \n    if(type(data.iloc[x,1])==float):\n        data.iloc[x,15] = np.nan\n        data.iloc[x,16] = np.nan\n    else:\n        cleanSal = data.iloc[x,1].replace('(Glassdoor est.)','').strip().split('-')\n    \n    if('K' in cleanSal[0]):\n        data.iloc[x,15] = float(cleanSal[0].replace('$','').replace('K',''))*1000\n    \n        \n    if('K' in cleanSal[1]):\n        data.iloc[x,16]= float(cleanSal[1].replace('$','').replace('K',''))*1000\n    ","bffbd7f5":"data.drop('Job Description',1,inplace=True)","cf4cce02":"data['Company Name'] = data['Company Name'].apply(lambda x: re.sub(r'\\n.*','',str(x)))","1cea3f29":"\ndata['MaxEmpSize'] = 0\n\nfor x in range(len(data)):\n    emp = data.iloc[x,6]\n    \n    try:\n        if(type(emp)==float or emp == 'Unknown'): #type(np.nan)== float\n            data.iloc[x,16] =  np.nan\n        elif('+' in emp):\n            data.iloc[x,16] = float(emp.replace('+','').replace('employees','').strip())\n        elif('employees' in emp):\n            data.iloc[x,16] = float(emp.replace('employees','').strip().split('to')[1])\n    except(Exception)as e:\n        print(e,emp)\n","df01de1e":"\ndata['MaxRevenue'] = 0\n\nfor x in range(len(data)):\n    rev = data.iloc[x,11]\n    \n    if(rev == 'Unknown \/ Non-Applicable' or type(rev)==float):\n        data.iloc[x,17] = np.nan\n    elif(('million' in rev) and ('billion' not in rev)):\n        maxRev = rev.replace('(USD)','').replace(\"million\",'').replace('$','').strip().split('to')\n        if('Less than' in maxRev[0]):\n            data.iloc[x,17] = float(maxRev[0].replace('Less than','').strip())*100000000\n        else:\n            if(len(maxRev)==2):\n                data.iloc[x,17] = float(maxRev[1])*100000000\n            elif(len(maxRev)<2):\n                data.iloc[x,17] = float(maxRev[0])*100000000\n    elif(('billion'in rev)):\n        maxRev = rev.replace('(USD)','').replace(\"billion\",'').replace('$','').strip().split('to')\n        if('+' in maxRev[0]):\n            data.iloc[x,17] = float(maxRev[0].replace('+','').strip())*1000000000\n        else:\n            if(len(maxRev)==2):\n                data.iloc[x,17] = float(maxRev[1])*1000000000\n            elif(len(maxRev)<2):\n                data.iloc[x,17] = float(maxRev[0])*1000000000\n        ","34ffe9fc":"data.drop(['Job Title','Salary Estimate','Size','Revenue'],1,inplace = True)\ndata.head(10)","cd98c5af":"data.describe().transpose()","d9d96a11":"data.describe(include='object').transpose()","aab1f970":"dataAnalyst = data[data['Job Role']=='Data Analyst']\n\nfig = go.Figure()\n\nfig.add_trace(go.Box(y=dataAnalyst['Min Salary'],name='Min Salary',boxmean='sd'))\nfig.add_trace(go.Box(y=dataAnalyst['Max Salary'],name='Max Salary',boxmean='sd'))\n\nfig.update_layout(title='Minimum and Maximum Salary of Data Analyst',height=800)\n\nfig.show()","6a408f51":"industry = data.groupby(['Industry'])['MaxRevenue'].mean()\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=industry.index,y=industry,mode='lines+markers',marker = dict(color = 'rgba(255,0, 0, 1.0)',size=12)))\n\nfig.show()","49684d49":"industry = industry[industry>20000000000]\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=industry.index,y=industry,mode='lines+markers',marker=dict(color='rgba(255,0,0,1.0)',size=12)))\n\nfig.update_layout(title='Industry Type Which have Mean Revenue Greater than 20Billion',\n                 yaxis=dict(title='Billion Dollars'),\n                  xaxis=dict(title='Industry Type')\n                 )\n\nfig.show()","970a3f85":"sector = data.groupby(['Sector']).mean()\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x=sector.index,y=sector['Min Salary'],name='Mininum Mean Salary',text=sector['Min Salary'],textposition='auto' ))\nfig.add_trace(go.Bar(x=sector.index,y=sector['Max Salary'],name='Maximum Mean Salary',text=sector['Min Salary'],textposition='auto'))\n\nfig.update_layout(title='Mean Salary',barmode='stack')\n\nfig.show()","9b169783":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=sector.index,y=sector['Rating'],name='Rating',text=sector['Rating'],\n                         mode='markers',\n                         marker=dict(size=sector['Rating']*8,color=sector['Rating'])\n                        ))\n\nfig.update_layout(title='Sectors with Average Rating',\n                 xaxis=dict(title='Sectors'),\n                 yaxis=dict(title='Average Rating'))\n\nfig.show()","4b830d94":"fig = go.Figure()\n\nsector.dropna(inplace=True)\nfig.add_trace(go.Scatter(x=sector.index,y=sector['MaxRevenue'],name='MaxRevenue',text=sector['Rating'],\n                         mode='markers',\n                         marker=dict(size=sector['MaxRevenue']**0.15,color=sector['MaxRevenue'])\n                        ))\n\nfig.update_layout(title='Sector with Average Revenue',\n                 xaxis=dict(title='Sectors'),\n                 yaxis=dict(title='Average MaxRevenue'))\n\nfig.show()","986e7125":"data2 = data.dropna()\nfig = px.sunburst(data2, path=['Sector','Location','Job Role'], values='Min Salary',height=800)\nfig.update_layout(title='Sector -> Location -> JobRole -> Min Salary')\nfig.show()","d0ed7854":"from wordcloud import WordCloud\n\ndef WordCloudMaking(data,col):\n    invester = data[col][~pd.isnull(data[col])]\n\n    wordCloud = WordCloud(width=500,height= 300).generate(' '.join(invester))\n\n    plt.figure(figsize=(19,9))\n\n    plt.axis('off')\n    plt.title(data[col].name,fontsize=20)\n    plt.imshow(wordCloud)\n    plt.show()\nWordCloudMaking(data,'Job Role')","58f6ba3f":"WordCloudMaking(data,'Job Domain')","a39285d9":"WordCloudMaking(data,'Industry')","765d82e6":"WordCloudMaking(data,'Sector')","ecc8740c":"WordCloudMaking(data,'Company Name')","4fceb04e":"WordCloudMaking(data,'Type of ownership')","fa4804ed":"location = data[data['Job Role']=='Data Analyst']['Location'].value_counts()\nfig = px.pie(location,names=location.index,values=location,height=800)\nfig.update_traces(textposition='inside',textinfo='label+percent',hole=.4)\n\nfig.update_layout(annotations=[dict(text='Locations with Maximum Data Analyst',showarrow=False)])\n\nfig.show()","f527bff1":"# What is Min and Max Salary Distribution of Data Analyst\n","aa608311":"Job Description Column have huge amount of text data which is not required for this EDA so we will drop this column ***(But we will use this in next Version)***\n\nAnd we also know that If a Person is Appointed as Data Analyst or for any Job Role then he or she must have great idea about that role ","174fddc2":"> Info method shows that there are no null value but if we observe the dataset heading and tail we will come to know that instead of null value they have put -1 ","8c93c483":"# Which type of sector have best Salary and Rating","80654d2b":"# Importing Libraries and Reading Data","aa40010d":"# Which Sector is leading in Data Analyst","030c8e76":"In Revenue Col it's provide revenue in range and also in two different Unit Millions and Billions\n\nWhere if 500M we will replace it as  500000000 and for 5 Billion 5000000000\n\nand also we will take only the max Revenue in Max Revenue Col\n","4ed3f1ba":"# Visualization Part","d3555a30":"# Which Sector have Highest Average Revenue","ad0d0060":"# We will Perform EDA on following questions\n\n\n* What is Min and Max Salary Distribution of Data Analyst\n* Which type of Industry have High Revenue\n* Which type of sector have best Salary and Rating\n* Which type of Sector have Good Average Rating\n* Which Sector have Highest Average Revenue\n* Which location(city) have highest Data Analyst or does it's play any important role in Job\n* For which Job Role People mostly apply\n* For which Stream(Domain) People mostly apply\n* For which Industry People mostly apply\n* Which Sector is leading in Data Analyst\n* Which Company have most Data Analyst\n* Which type of OwnerShip do company have\n* Which city have highest Data Analyst","fab93cf0":"**Industry Type Which have Mean Revenue Greater than 20Billion**","621350c5":"# Which type of OwnerShip do company have","26bc4bb4":"![Screenshot-2019-08-22-at-22.15.17.png](attachment:Screenshot-2019-08-22-at-22.15.17.png)","3730767b":"# For which Job Role People mostly apply","985e8f2f":"In Employees Column\n\nIt show the range of employe, so we will only keep max number of emp for better EDA in  new column MaxEmpSize","4c39cf2b":"# Which location(city) have highest Data Analyst or does it's play any important role in Job ","1919e4ca":"# For which Industry People mostly apply","e9a81596":"**so lets do one thing we will replace -1 with np.nan so we can calculate the missing values in dataset for better observation**","fceb241a":"**Reading Last Ten Data from dataset**","f16a9b1d":"We have Successfully cleaned the data now we can remove some column \n\n* Job Title\n* Salary Estimate\n* Size\n* Revenue\n\nbecause we have successfully extracted usefull data","eb858bf5":"**If you guys have any suggestion(s) please comment down below it will help me to improve my skill**","0da16e55":"# Which type of Sector have Good Average Rating","71c7f0be":"Checking Datatype and Not Null Values in Dataset","d8da6de5":"# Which city have highest Data Analyst","87e0567e":"**Reading Top Ten Data from dataset**","1bc639f8":"# For which Stream(Domain) People mostly apply","b6b167f6":"In Job Title Column We can point one thing that **Job Role** is been define before \",\" and **Domain** or **Branch** for Job is Define after \",\"\n\nSo we simply split these in two different columns namely **Job Domain** and **Job Role**","29890a8d":"# Which Company have most Data Analyst","5e1564cc":"# DATA CLEANSING","9f27c7e1":"# Dataset Acknowledgement\n\n\n\nAmidst the pandemic many people lost their jobs, with this dataset it is possible to hone the job search so that more people in need can find employment.This dataset was created by picklesueat and contains more than 2000 job listing for data analyst positions, with features such as:\n\n* Salary Estimate\n* Location\n* Company Rating\n* Job Description\n* and more.\n\n","344d06e3":"**96.45% or 2173 values are Missing in Easy Apply Column** \n\n**76.88% or 1732 values are Missing in Competitors Column**\n\nThere are more than 50% values are missing in these 2 Column \n\nso we will simply drop the Column becaue there are not enough data to do Forward,Backward, Mean, Median , Mode or Imputer Fill","0a7f15c3":"Salary Estimate have salary range **Min to Max**\n\nwe will divide this column into two columns one will be  ***Min Salary*** and another will be ***Max Salary***\nand also convert the data type from object to  into float64\n\nwhere K = 1000Dollors   (for this dataset $) so we will simply mutiply 1000 where salary is listed with \"K\" for simple Calculation\n","f738ca35":"pic credit - google images","e65d9845":"In Company Column we can see that data have ***\\n3.8*** as suffix where 3.8 is rating of company and we will eliminate this and only keep the Company name in that column because we already have a seprate Rating Column","3ba36a49":"# Which type of Industry have high Revenue "}}