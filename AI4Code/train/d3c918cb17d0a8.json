{"cell_type":{"37acb45b":"code","8e3ad555":"code","8b1f3973":"code","4d70f0a7":"code","a4d5073d":"code","8c538d6e":"code","8832f483":"code","f194c780":"code","2dafd68a":"code","472c8770":"code","4e7ddb77":"markdown"},"source":{"37acb45b":"import pandas as pd\nimport numpy as np\nfrom keras.utils import np_utils\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, mean_squared_error, make_scorer, roc_auc_score\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')","8e3ad555":"# All categorical features encoded onehot \ndef preprocess(df):\n    categorical_cols = [c for c in df.columns if 'cat' in c]\n    numerical_cols = [c for c in df.columns if 'cat' not in c]\n    \n    onehot_encoded_df = pd.get_dummies(df[categorical_cols])\n    numerical_df = df[numerical_cols]\n    \n    return pd.concat([numerical_df, onehot_encoded_df], axis=1)","8b1f3973":"train_df = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')","4d70f0a7":"train_size = train_df.shape[0]\ntest_size = test_df.shape[0]\nall_data = pd.concat([train_df, test_df])","a4d5073d":"all_data = preprocess(all_data)\ntrain_data = all_data[:train_size]\ntest_data = all_data[train_size:].drop(columns=['target'])","8c538d6e":"y = train_data.target.values\nX = train_data.drop(columns=['id', 'target'])\nX_ = test_data.drop(columns='id')","8832f483":"params = {\n    'lambda': 0.0001,\n    'learning_rate': 0.007930236488607134,\n    'max_bin': 270,\n    'max_depth': 98,\n    'metric': 'auc',\n    'min_data_in_leaf': 60,\n    'n_estimators': 20000,\n    'num_leaves': 263,\n    'objective': 'binary',\n    'sub_feature': 0.2098021977637481\n}","f194c780":"folds = KFold(n_splits = 50, shuffle=True)\noof = np.zeros(X.shape[0])\npredictions = np.zeros(X_.shape[0])","2dafd68a":"for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    print(\"Fold {}\".format(fold_))\n    X_train = X.iloc[trn_idx]\n    y_train = y[trn_idx]\n    X_test = X.iloc[val_idx]\n    y_test = y[val_idx]\n    clf = lgb.LGBMClassifier(**params, random_state=42)\n    clf.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)],\n        eval_metric='auc', early_stopping_rounds=250, verbose=250  )\n    predictions += clf.predict_proba(X_, num_iteration=clf.best_iteration_)[:,1] \/ folds.n_splits","472c8770":"submission = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsubmission = pd.concat([submission, pd.DataFrame(predictions)], axis=1).drop(columns='target')\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission.csv', index=False)","4e7ddb77":"LightGBM with CV\n* This notebook scores aprox. 0.89200 (depends on random seed)\n* To optimze parameters use this script: https:\/\/www.kaggle.com\/jmargni\/tabular-mar-lightgbm-hyperopt\n* LightGBM parameters are from hyperopt result with loss of -0.89918 using the link above. Obtaining loss values near -1 will improve final score.\n* Find the best parameters combination and climb to the top. Good luck!!! ;-)\n\n"}}