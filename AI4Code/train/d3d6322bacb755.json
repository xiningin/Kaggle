{"cell_type":{"7b828982":"code","aa2552c6":"code","e041b8ee":"code","6fe715b5":"code","da32b736":"code","33e1d209":"code","7e9858e9":"code","40797c4d":"code","8c18c03a":"code","e42c5ccd":"code","573610c0":"code","7aaf0409":"code","240a6678":"code","54e5dc7c":"code","7956d982":"code","8c24bd06":"code","f62ac549":"code","0672fef2":"code","148da7f2":"code","a817d31c":"code","91d53764":"code","5167dfe0":"code","3a2e1c71":"code","d4efcf9a":"code","417b689e":"code","78b14cc9":"code","63c0bb27":"code","95797f11":"markdown","4f7baea2":"markdown","26945f4b":"markdown","23dcb75a":"markdown","3e575076":"markdown","ae6d8f5c":"markdown","82f33985":"markdown","e3b2622a":"markdown","46500138":"markdown","1f065eb8":"markdown","7b1c2e00":"markdown","57a72a07":"markdown"},"source":{"7b828982":"try:\n    import spacy\nexcept:\n    !pip install spacy\ntry:\n    import spacy_langdetect\nexcept:\n    !pip install spacy-langdetect\ntry:\n    import flair\nexcept:\n    !pip install flair\ntry:\n    import geonamescache\nexcept:\n    !pip install geonamescache\ntry:\n    import spacy_fastlang\nexcept:    \n    !pip install spacy_fastlang\n    #!pip install sense2vec==1.0.0a1\ntry:\n    import gensim\nexcept:\n    !pip install gensim\ntry:\n    import wordcloud\nexcept:\n    !pip install wordcloud\ntry:\n    import nltk\nexcept:\n    !pip install nltk\n\ntry:\n    import visualise_spacy_tree\nexcept:\n    !pip install visualise-spacy-tree\n\ntry:\n    import textacy\nexcept:\n    !pip install textacy\n\n!python -m spacy download en_core_web_sm\n!python -m spacy download en_core_web_md","aa2552c6":"import pandas as pd\n\nimport requests\nimport spacy\nfrom spacy.lang.en import English\nfrom spacy.matcher import PhraseMatcher\nfrom spacy.tokens import Doc, Span, Token\nfrom spacy.pipeline import EntityRuler\nfrom spacy.pipeline import merge_entities\nimport csv\nimport re\nimport ast\nfrom langdetect import detect\nimport numpy as np\n\nfrom nltk.tokenize import sent_tokenize\nimport nltk\nnltk.download(\"punkt\")\nimport visualise_spacy_tree\nimport textacy\n\nfrom IPython.display import Image,display\n\nimport os","e041b8ee":"all_countries = pd.read_csv(\"..\/input\/country-aliases\/all_countries_with_aliases.csv\")","6fe715b5":"all_countries.head()","da32b736":"all_countries_aliases = dict()\nfor idx, r in all_countries[~all_countries.Aliases.isna()].iterrows():\n    a = dict()\n    a['alpha_2_code'] = r['Alpha-2 code']\n    a['alpha_3_code'] = r['Alpha-3 code']\n    a['name'] = r['Name']\n    all_countries_aliases.update({r['Name'].lower():a})\n    \n    cnames = r['Aliases'].split(' # ')\n    if len(cnames) > 0:\n        for c in cnames:\n            if len(c.strip())>3:\n                a = dict()\n                a['alpha_2_code'] = r['Alpha-2 code']\n                a['alpha_3_code'] = r['Alpha-3 code']\n                a['name'] = r['Name']\n                all_countries_aliases.update({c.strip().lower():a})","33e1d209":"all_patterns = list()\nfor k in all_countries_aliases.keys():\n    c_patterns = k.split()\n\n    \n    c_patterns_list = []\n    for c in c_patterns:\n        d = dict()\n        d['LOWER'] = c\n        c_patterns_list.append(d)\n    \n    \n    pattern_dict = dict()\n    pattern_dict[\"label\"] = \"GPE\" # Geopolitical entity\n    pattern_dict[\"pattern\"] = c_patterns_list\n    pattern_dict[\"id\"] = all_countries_aliases[k]['alpha_3_code']\n    \n    all_patterns.append(pattern_dict)","7e9858e9":"eu = [\"Belgium\",\n    \"Bulgaria\",\n    \"Denmark\",\n    \"Germany\",\n    \"Estonia\",\n    \"Finland\",\n    \"France\",\n    \"Greece\",\n    \"Ireland\",\n    \"Italy\",\n    \"Croatia\",\n    \"Latvia\",\n    \"Lithuania\",\n    \"Luxembourg\",\n    \"Malta\",\n    \"Netherlands\",\n    \"Austria\",\n    \"Poland\",\n    \"Portugal\",\n    \"Romania\",\n    \"Sweden\",\n    \"Slovakia\",\n    \"Slovenia\",\n    \"Spain\",\n    \"Czech Republic\",\n    \"Hungary\",\n    \"United Kingdom\",\n    \"Cyprus\"]\n\neea_c = eu+[\n    \"Iceland\",\n    \"Liechtenstein\",\n    \"Norway\",\"Switzerland\"\n]\n\nschengen = [\"Austria\", \"Belgium\", \"Czech Republic\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Iceland\", \"Italy\", \"Latvia\",\n            \"Liechtenstein\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\"]\n\nscandinavian = [\"Denmark\",\"Norway\",\"Sweden\"]\n\neum = []\nfor c in eu:\n    #print(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n    eum.append(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n\neea = []\nfor c in eea_c:\n    #print(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n    eea.append(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n\nsch = []\nfor c in schengen:\n    #print(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n    sch.append(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n\nsvc = []\nfor c in scandinavian:\n    #print(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n    svc.append(all_countries[all_countries['Name'].str.contains(c)]['Alpha-3 code'].values[0])\n    \nneum = list(set(all_countries['Alpha-3 code'].unique()).difference(set(eum)))\nnsch = list(set(all_countries['Alpha-3 code'].unique()).difference(set(sch)))\nneu = list(set(all_countries['Alpha-3 code'].unique()).difference(set(eea)))","40797c4d":"all_patterns.extend([{'label': 'GPE',\n  'pattern': [{'LOWER': 'republic'}, {'LOWER': 'of'}, {'LOWER': 'costarica'}],\n  'id': 'CRI'},\n  {'label': 'GPE',\n  'pattern': [{'LOWER': 'saint'}, {'LOWER': 'christopher'}, {'LOWER': 'and'}, {'LOWER': 'nevis'}],\n  'id': 'KNA'}, \n{'label': 'GPE',\n  'pattern': [{'LOWER': 'vatican'}, {'LOWER': 'city'}],\n  'id': 'VAT'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'vatican'}],\n  'id': 'VAT'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'member'}, {'LOWER': 'states'}, {'LOWER': 'of'},{'LOWER': 'the'}, {'LOWER': 'european'}, {'LOWER': 'union'}],\n  'id': 'EUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'eu'}, {'LOWER': 'member'}, {'LOWER': 'state'}],\n  'id': 'EUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'european'}, {'LOWER': 'union'}, {'LOWER': 'member'}, {'LOWER': 'states'}],\n  'id': 'EUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'european'}, {'LOWER': 'union'}],\n  'id': 'EUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'eu'}, {'LOWER': 'member'}, {'LOWER': 'states'}],\n  'id': 'EUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'eu'}],\n  'id': 'EUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'schengen'}],\n  'id': 'SCH'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'south-korea'}],\n  'id': 'KOR'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'uk'}],\n  'id': 'GBR'},\n {'label': 'GPE',\n  'pattern': [{'LOWER': 'great'}, {'LOWER': 'britain'}],\n  'id': 'GBR'},\n {'label': 'GPE',\n  'pattern': [{'LOWER': 'great'}, {'LOWER': 'britain'}, {'LOWER': 'and'}, {'LOWER': 'northern'}, {'LOWER': 'ireland'}],\n  'id': 'GBR'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'tunesia'}],\n  'id': 'TUN'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'scandinavian'}, {'LOWER': 'countries'}],\n  'id': 'SVC'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'hongkong'}],\n  'id': 'HKG'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'usa'}],\n  'id': 'USA'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'uae'}],\n  'id': 'ARE'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'u.s.a'}],\n  'id': 'USA'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'u.s.'}],\n  'id': 'USA'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'prc'}],\n  'id': 'CHN'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'third'},{'LOWER': 'country'}],\n  'id': 'NEU'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'third'},{'LOWER': 'countries'}],\n  'id': 'NEU'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'third-country'}],\n  'id': 'NEU'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'non-eu'}],\n  'id': 'NEUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'non'},{'LOWER': 'eu'}],\n  'id': 'NEUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'non-european'},{'LOWER': 'union'},{'LOWER': 'member'},{'LOWER': 'states'}],\n  'id': 'NEUM'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'non-schengen'}],\n  'id': 'NSCH'},\n{'label': 'GPE',\n  'pattern': [{'LOWER': 'non'},{'LOWER': 'schengen'}],\n  'id': 'NSCH'}])","8c18c03a":"all_patterns[0]","e42c5ccd":"# EUM - European Member State\n# SCH - Schengen\n# SVC - Scandinavian\n# NEU - third country\n# NEUM - Non- EU Member State\n# NSCH - Non schengen\neuropean_regions =  ['EUM','SCH','SVC','NEU','NEUM','NSCH']","573610c0":"european_regions_dt = {'EUM':eum,'SCH':sch,'SVC':svc,'NEU':neu,'NEUM':neum,'NSCH':nsch}","7aaf0409":"nlp = spacy.load('en_core_web_sm')\nruler = nlp.add_pipe(\"entity_ruler\")\nruler.add_patterns(all_patterns)","240a6678":"nlp.add_pipe(\"merge_entities\")","54e5dc7c":"doc1 = nlp(\"Japanese nationals are allowed entry. Foreigners with Japanese residency are allowed to re-enter from Angola, Botswana, Eswatini, Democratic Republic of the Congo, Lesotho, Malawi, Mozambique, Namibia, South Africa, Zambia and Zimbabwe. All other inbound non-Japanese nationals are banned from entry regardless of their departure country until 28 February.\".lower())\nprint([(ent.text, ent.label_, ent.ent_id_) for ent in doc1.ents])","7956d982":"spacy.displacy.render(doc1, style='ent',jupyter=True)","8c24bd06":"spacy.displacy.render(doc1, style='dep',jupyter=True)","f62ac549":"img_ = visualise_spacy_tree.create_png(doc1)\ndisplay(Image(img_))","0672fef2":"# Adding stop words\nnew_stop_words = [\"create\",\"source\",\"euecyiyn\",'etczyoyx','tel']\n\n# Add airport codes to stop words\n#new_stop_words.extend([ac.lower() for ac in list(apt_covid_notam_lt_df.airportCode.values)])\n\n\nfor new_word in new_stop_words:\n    nlp.vocab[new_word].is_stop = True\n\nmapping = {\"acc\": \"area control\", \"acft\": \"aircraft\", \"ad\": \"aerodrome\", \"aic\": \"aeronautical information circular\",\n           \"aip\": \"aeronautical information publication\", \"ais\": \"aeronautical information services\",\n           \"alt\": \"altitude\", \"altn\": \"alternate\", \"ap\": \"airport\", \"aro\": \"air traffic services reporting office\",\n           \"arr\": \"arrival\", \"atc\": \"air traffic control\", \"ats\": \"air traffic services\", \"attn\": \"attention\",\n           \"auth\": \"authorized\", \"avbl\": \"available\", \"bfr\": \"before\", \"cat\": \"category\", \"chg\": \"change\",\"civ\":\"civil\",\n           \"clsd\": \"closed\", \"cov\": \"cover\", \"cta\": \"control area\", \"ctc\": \"contact\", \"ctr\": \"control zone\",\n           \"dem.\": \"democratic\", \"dep\": \"depart\", \"emerg\": \"emergency\", \"enr\": \"en route\", \"exc\": \"except\",\n           \"fed.\": \"federation\", \"fir\": \"flight information region\", \"fis\": \"flight information service\",\n           \"flt\": \"flight\", \"flts\": \"flights\", \"flw\": \"follows\", \"fm\": \"from\", \"fpl\": \"filed flight plan\",\n           \"fri\": \"friday\", \"gen\": \"general\", \"hr\": \"hour\", \"intl\": \"international\", \"isl.\": \"islands\",\n           \"ldg\": \"landing\", \"mil\": \"military\", \"mon\": \"monday\", \"op\": \"operation\",\"ops\": \"operations\", \n           \"opr\": \"operating\",\"pax\": \"passenger\",\n           \"ppr\": \"prior permission required\", \"ref\": \"refernce to\", \"rep.\": \"republic\", \"req\": \"request\",\n           \"rffs\": \"rescue and fire fighting services\", \"rmk\": \"remark\", \"rte\": \"route\", \"rwy\": \"runway\",\n           \"sat\": \"saturday\", \"ser\": \"service\", \"svc\": \"service message\", \"taf\": \"terminal aerodrome forecast\",\n           \"tfc\": \"traffic\", \"thu\": \"thursday\", \"tma\": \"terminal control area\", \"tue\": \"tuesday\",\n           \"twr\": \"aerodrome control tower\", \"vfr\": \"visual flight rules\"}","148da7f2":"def clean_message_keep_punct(message):\n    #############################\n    ## mapping, lower, language #\n    #############################\n    message = re.sub(r'(http|https|www)\\S+', '', message)\n    \n    # Mapping short terms to actual word\n    for s_, w in mapping.items():\n        message = re.sub(r'\\b{}\\b'.format(s_),w,message)\n    \n    # If a country has NOTAMs in two languages, the english text starts with the phrase \"english text\/english version\"\n    if \"english text\" in message:\n        #print(\"TEXT\")\n        e_t = []\n        for m_ in message.split(\"english text\"):\n            for sent_ in sent_tokenize(m_):\n                if detect(sent_) == \"en\":\n                    e_t.append(sent_)\n        message = \"\".join(e_t)\n\n    elif \"english version\" in message:\n        #print(\"VERSION\")\n        e_t = []\n        for m_ in message.split(\"english version\"):\n            for sent_ in sent_tokenize(m_):\n                if detect(sent_) == \"en\":\n                    e_t.append(sent_)\n        \n        message = \"\".join(e_t)\n        #message = message.split(\"english version\")[1]\n    elif detect(message) != \"en\":\n        message = \"\"\n\n    #Start of string other than character or digit\n    #message = re.sub(r'[^ 0-9a-z]', ' ', message)\n    #message = message.translate(message.maketrans('', '', string.punctuation)) #extra punctuations removal\n    message = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(message))\n    \n    # Replace numbered points with comma\n    message = re.sub(\"(\\s\\d+\\.)\",\", \", str(message))\n    # Remove unnecessary white space\n    message = \" \".join(message.split())\n    \n    return message","a817d31c":"pos_verbs_to_filter = [\"permit\",\"allow\", \"accept\",\"open\",\"lift\",\"exempt\"]\nneg_verbs_to_filter = [\"ban\", \"exclude\", \n                   \"refuse\",\"expel\", \"deny\", \"prohibit\", \"cancel\",\"suspend\",\"close\",\"forbid\"]\nrestrict_verb = [\"restrict\"]\n\nneg_nouns = [\"suspension\",\"cancellation\",\"ban\"]\npos_nouns = [\"opening\",\"enter\",\"resumption\",\"exemption\",\"exempt\",\"alleviation\"]\n\n# If the country border is closed to all countries the following nouns and noun_chunks are commonly used\nnouns_to_filter = [\"passenger\", \"foreigner\", \"traveller\", \"flight\",\"airport\",\"arrival\",\"departure\"]\nnoun_chunks_ = [\"all borders\",\"all flights\",\"civil flight\",\"civil flights\",\"all airports\",\"the border\",\"general aviation\",\"ga\",\"commercial flights\",\"all international\"]\n\nna_extension = [\"shall hold a negative covid-19 test\",\"unless belong to one of the following\",\"this does not apply\"]","91d53764":"ex1 = nlp(\"All inbound travellers, including Japanese nationals, must present a negative pre-travel COVID-19 certificate from a test taken within 72 hours of departure. Those without a negative pre-travel COVID-19 certificate, have been denied entry. Certificate formats can be found here.\".lower())\nspacy.displacy.render(ex1, style=\"ent\", jupyter=True)","5167dfe0":"ex1 = nlp(\"passenger restrictions: all flight arriving\/departing to\/from italy must comply with the requirements of the president of the ministerial council of 11 jun, flight to\/from states and territories other than - member states of the european union - member states of the schengen agreement - united kingdom of great britain and northern ireland - andorra, principaly of monaco - republic of san marino and vatican city state are still prohibited till 30\/06\/2020 for those flights prohibited exceptions are reported in art 6 of the same decree\")\nspacy.displacy.render(ex1, style=\"ent\", jupyter=True)","3a2e1c71":"{'GBR': 'open', 'AND': 'open', 'MCO': 'open', 'SMR': 'open', 'VAT': 'open', 'NEUM': 'close', 'NSCH': 'close'}","d4efcf9a":"ex1 = nlp(\"all international flights from or to morocco are suspended until further notice except over flight and cargo.\")\nspacy.displacy.render(ex1, style=\"ent\", jupyter=True)","417b689e":"def all_country_closure(c,other_countries_in_this_sentence):\n    '''\n    look for the nouns and identify if the word \"all\" is associated with it. \n    Then label the restriction as \"all\" countries\n    '''\n    countries = []\n    if (c.lemma_ == \"to\") | (c.lemma_ == \"for\")| (c.lemma_ == \"from\"):\n        for c_ in c.children:\n            if c_.lemma_ in nouns_to_filter:\n                for c__ in c_.children:\n                    if (c__.lemma_ == \"all\")& (len(other_countries_in_this_sentence) == 0):\n                        countries = \"all\"\n    if c.lemma_ in nouns_to_filter:\n        for c_ in c.children:\n            if (c_.lemma_ == \"all\")& (len(other_countries_in_this_sentence) == 0):\n                countries = \"all\"\n    #print(countries)\n    if len(countries) != 0:\n        return countries\n    else:\n        return None\n\ndef country_restrictions(message):\n    each_country = dict()\n    master_dict= dict()\n    each_country = []\n    relevant_messages = []\n\n    current_country = 'Belgium'\n\n    doc = nlp(message) \n    print(doc)\n    # Get all country names mentioned in the message\n    other_countries = [t.ent_id_ for t in doc if (t.ent_type_ == \"GPE\") & (t.ent_id_ != '') & (t.ent_id_ != current_country)]\n#     print(other_countries)\n    #nltk sent tokenise is better\n    for sent_ in sent_tokenize(doc.text):\n        doc_ = nlp(sent_)\n    #for doc_ in doc.sents:\n        tag = []\n        tag_single = \"\"\n        countries = []\n        countries_dt = {}\n        specific_country = []\n        for t in doc_:\n            other_countries_in_this_sentence = [t.ent_id_ for t in doc_ if (t.ent_type_ == \"GPE\") & (t.ent_id_ != '') & (t.ent_id_ != current_country)]\n            # If one of the positive verbs is present then we tag it as open unless a negation is present in the children\n            # Sometimes open is used as adjective int he sentence\n            if ((t.pos_ == \"VERB\") & ((t.lemma_ in pos_verbs_to_filter))) | ((t.pos_ == \"ADJ\") & (t.lemma_ == \"open\")):\n                tag_ = \"open\"\n                # if negation is present in one of the children associated with the verb we invert the tag\n                for c_ in t.children:\n                    if c_.dep_ == \"neg\":\n                        tag_ = \"close\"\n#                     print(c_)\n                    countries_ = all_country_closure(c_,other_countries_in_this_sentence)\n                    if countries_ is not None:\n                        countries.append(countries_)\n                        countries_dt[countries_] = tag_\n                tag.append(tag_)\n                tag_single = tag_\n                for potential_country in t.subtree:\n                    if (potential_country.ent_type_==\"GPE\")&(potential_country.ent_id_ != '')& (potential_country.ent_id_ != current_country)& ('following' not in [tc.text for tc in potential_country.lefts]):\n                        specific_country.append(potential_country.ent_id_)\n\n            # If one of the negative verbs is present then we tag it as close unless a negation is present in the children\n            elif ((t.pos_ == \"VERB\") & (t.lemma_ in neg_verbs_to_filter)):\n                tag_ = \"close\"\n                # if negation is present in one of the children associated with the verb we invert the tag\n                for c_ in t.children:\n                    if c_.dep == \"neg\":\n                        tag_ = \"open\"\n\n                    countries_ = all_country_closure(c_,other_countries_in_this_sentence)\n                    print(countries_)\n                    if countries_ is not None:\n                        countries.append(countries_)\n                        countries_dt[countries_] = tag_\n                tag.append(tag_)\n                tag_single = tag_\n                for potential_country in t.subtree:\n                    if (potential_country.ent_type_==\"GPE\")&(potential_country.ent_id_ != '')& (potential_country.ent_id_ != current_country)& ('following' not in [tc.text for tc in potential_country.lefts]):\n                        specific_country.append(potential_country.ent_id_)\n\n            # If one of the positive nouns is present then we tag it as open unless a negation is present in the children\n            if ((t.pos_ == \"NOUN\") & (t.lemma_ in pos_nouns)):\n                tag_ = \"open\"\n                # if negation is present in one of the children associated with the noun we invert the tag\n                for c_ in t.children:\n                    if c_.dep_ == \"neg\":\n                        tag_ = \"close\"\n                    countries_ = all_country_closure(c_,other_countries_in_this_sentence)\n                    if countries_ is not None:\n                        countries.append(countries_)\n                        countries_dt[countries_] = tag_\n                tag.append(tag_)\n                tag_single = tag_\n                for potential_country in t.subtree:\n                    if (potential_country.ent_type_==\"GPE\")&(potential_country.ent_id_ != '')& (potential_country.ent_id_ != current_country)& ('following' not in [tc.text for tc in potential_country.lefts]):\n                        specific_country.append(potential_country.ent_id_)\n\n            # If one of the negative nouns is present then we tag it as close unless a negation is present in the children\n            elif ((t.pos_ == \"NOUN\") & (t.lemma_ in neg_nouns)):\n                tag_ = \"close\"\n                # if negation is present in one of the children associated with the verb we invert the tag\n                for c_ in t.children:\n                    if c_.dep == \"neg\":\n                        tag_ = \"open\"\n                    countries_ = all_country_closure(c_,other_countries_in_this_sentence)\n                    if countries_ is not None:\n                        countries.append(countries_)\n                        countries_dt[countries_] = tag_\n                tag.append(tag_)\n                tag_single = tag_\n                for potential_country in t.subtree:\n                    if (potential_country.ent_type_==\"GPE\")&(potential_country.ent_id_ != '')& (potential_country.ent_id_ != current_country)& ('following' not in [tc.text for tc in potential_country.lefts]):\n                        specific_country.append(potential_country.ent_id_)\n\n            #if ((t.pos_ == \"VERB\") & (t.lemma_ in restrict_verb)):\n            #    tag_ = 'restrict'\n            #    tag.append('restrict')\n            #    tag_single = tag_\n\n            # In cases where the complete restriction is mentioned using one of the noun chunks we identify those mentions and then label the restriction to \"all\" countries\n            for current_nc in doc_.noun_chunks: \n                for nc_ in noun_chunks_:\n                    if nc_ == current_nc.text:\n                        for vs in current_nc.root.ancestors:\n                            if ((vs.pos_ == \"VERB\")& ((t.lemma_ in pos_verbs_to_filter)| (t.lemma_ in pos_verbs_to_filter)))& (len(other_countries_in_this_sentence) == 0):\n                                countries.append(\"all\")\n                                countries_dt[\"all\"] = tag_single\n                            if ((vs.pos_ == \"NOUN\")& ((t.lemma_ in pos_nouns)| (t.lemma_ in neg_nouns)))& (len(other_countries_in_this_sentence) == 0):\n                                countries.append(\"all\")\n                                countries_dt[\"all\"] = tag_single\n\n        # Potential country tags\n        if ((tag_single == \"open\")|(tag_single == \"close\")) & (len(specific_country)>0):\n            for sc in specific_country:\n                countries_dt[sc] = tag_single\n\n        # In some messages the word \"non\" is used to denote negation for countries. These mentions are identified and the tag is inverted\n        for ix,sus_c in enumerate(doc_):\n            if (sus_c.ent_type_==\"GPE\")&(sus_c.ent_id_ != '')& (sus_c.ent_id_ != current_country) &(sus_c.ent_id_ not in countries_dt.keys())& ('following' not in [tc.text for tc in sus_c.lefts]):\n                country_prefix = ''\n                for ix_ in range(ix-5,ix):\n                    # Negation for NON mentions\n                    if (doc_[ix_].lemma_ == \"non\"):\n                        if sus_c.ent_id_ in ['EUM','SCH']:\n                            country_prefix = \"N\"\n                        else:\n                            country_prefix = \"negate\"\n                if country_prefix == \"N\":\n                    countries.append('N'+sus_c.ent_id_)\n                    countries_dt['N'+sus_c.ent_id_] = tag_single#f_tag\n                elif country_prefix == \"negate\":\n                    countries.append(sus_c.ent_id_)\n                    if tag_single == \"open\":\n                        countries_dt[sus_c.ent_id_] = \"close\"#f_tag\n                    elif tag_single == \"close\":\n                        countries_dt[sus_c.ent_id_] = \"open\"\n                    else:\n                        countries_dt[sus_c.ent_id_] = \"na\"\n                else:\n                    countries.append(sus_c.ent_id_)\n                    if tag_single == \"open\":\n                        countries_dt[sus_c.ent_id_] = \"open\"#f_tag\n                    elif tag_single == \"close\":\n                        countries_dt[sus_c.ent_id_] = \"close\"\n                    else:\n                        countries_dt[sus_c.ent_id_] = \"na\"\n\n        # Negation for exceptions\n        # Tag is inverted for countries that precede with one of the following words: except, exception, outside, out, other, unless\n        negation_countries =[]\n        for idx,s in enumerate(doc_):\n            if (s.lemma_ ==\"except\")|(s.lemma_ == \"exception\")|(s.lemma_ == \"outside\")|(s.lemma_ == \"out\")|(s.lemma_ == \"other\")|(s.lemma_ == \"unless\")|(s.lemma_ == \"apart\"):\n                for _ in range(idx+1,idx+25):\n                    #print(_)\n                    try:\n                        if (doc_[_].ent_type_==\"GPE\")&(doc_[_].ent_id_ != '')& (doc_[_].ent_id_ != current_country)& ('following' not in [tc.text for tc in doc_[_].lefts]):\n                            for child in doc_[_].subtree:\n                                if (child.ent_type_==\"GPE\")&(child.ent_id_ != '')& (child.ent_id_ != current_country):\n                                    # print(child,child.ent_id_,countries_dt[child.ent_id_])\n                                    negation_countries.append(child.ent_id_)\n                    except Exception as e:\n                        pass\n                        #print(str(e))\n        if len(negation_countries) > 0:\n            #print(\"NEGATION\")\n            for neg_country in set(negation_countries):\n                if neg_country in countries_dt.keys():\n                    if (\"EUM\" in neg_country)|(\"SCH\" in neg_country):\n                        countries_dt[\"N\"+ neg_country] = countries_dt[neg_country]\n                        del countries_dt[neg_country]\n                    elif countries_dt[neg_country] == 'open':\n                        countries_dt[neg_country] = 'close'\n                    elif countries_dt[neg_country] == 'close':\n                        countries_dt[neg_country] = 'open'\n                    else:\n                        countries_dt[neg_country] == 'na'\n\n        #if the exact intent of the restriction is uncles tag it as \"na\"\n        for s in na_extension:\n                if s in doc_.text:\n                    tag.append(\"na\")\n\n        # To overocme contradicting messages we set the flag to na\n        if (len(set(tag)) >1) &(len(countries_dt.keys()) > 0):\n            for key_, value_ in countries_dt.items():\n                countries_dt[key_] = \"na\"\n\n        # consolidate the restrictions by country\n        if len(countries_dt.keys()) > 0 :\n            each_country.append(countries_dt)\n    return each_country","78b14cc9":"def integrate_restriction_to_dataframe(each_country):\n    master_dict = dict()\n    for i in each_country:\n        for main_c in i.keys():\n            master_dict[main_c] = dict()\n            for dt in each_country:\n                for k,v in dt.items():\n                    if not k in master_dict[main_c].keys():\n                        master_dict[main_c][k] = []\n                    master_dict[main_c][k].append(v)\n\n\n    # Remove 'all' if other country is mentioned\n    for country__ in master_dict.keys():\n        if (len(master_dict[country__].keys()) > 1) & ('all' in master_dict[country__].keys()):\n                master_dict[country__].pop(\"all\")\n    \n    for country__ in master_dict.keys():\n        non_eu_countries = {'NEU','NEUM','NSCH'}.intersection(set(master_dict[country__].keys()))\n        set_all_non_eu_to_na = 0\n        if len(non_eu_countries) > 0:\n            for cc in non_eu_countries:\n                if (set(master_dict[country__][cc]) == {'na'})|(set(master_dict[country__][cc]) == {'restrict'}) | (len(set(master_dict[country__][cc])) >1):\n                    #print(master_dict[country__][cc],cc)\n                    #print(\"NEU--\")\n                    set_all_non_eu_to_na = 1\n\n            if set_all_non_eu_to_na == 1:\n                for cc in non_eu_countries:\n                    #print(country__,cc)\n                    #print(master_dict[country__][cc])\n                    master_dict[country__][cc] = ['na']\n\n    for country__ in master_dict.keys():\n        eu_countries = {'EUM','SCH'}.intersection(set(master_dict[country__].keys()))\n        set_all_eu_to_na = 0\n        if len(eu_countries) > 0:\n            for cc in eu_countries:\n                if (set(master_dict[country__][cc]) == {'na'})|(set(master_dict[country__][cc]) == {'restrict'}) | (len(set(master_dict[country__][cc])) >1):\n                    #print(master_dict[country__][cc],cc)\n                    #print(\"EU--\")\n                    set_all_eu_to_na = 1\n\n        if set_all_eu_to_na == 1:\n            for cc in eu_countries:\n                #print(country__)\n                #print(master_dict[country__][cc],cc)\n                master_dict[country__][cc] = ['na']\n\n    res_dt = dict()\n\n    for k in master_dict.keys():\n        res_dt[k] = dict()\n        european_c_ = list(set(european_regions).intersection(set(master_dict[k].keys())))\n        if len(european_c_) > 0:\n            for e_c_ in european_c_:\n                countries = european_regions_dt[e_c_]\n                for ec_ in countries:\n                    #if :\n                    #    res_dt[k][ec_] = -1#\"conditions\" #-1#\n                    if set(master_dict[k][e_c_]) == {'open'}:\n                        res_dt[k][ec_] = 3#\"open\" #1#\n                    elif set(master_dict[k][e_c_]) == {'close'}:\n                        res_dt[k][ec_] = 0#\"close\" #0#\n                    elif (set(master_dict[k][e_c_]) == {\"na\"})|(set(master_dict[k][e_c_]) == {\"restrict\"})|(len(set(master_dict[k][e_c_])) > 1):\n                        res_dt[k][ec_] = 1#\"other\" #-2#\n\n\n        if \"all\" in master_dict[k].keys():\n            for all_c in all_countries['Alpha-3 code'].unique():\n                #if :\n                #    res_dt[k][all_c] = -1#\"conditions\" #-1#\n                if set(master_dict[k][\"all\"]) == {'open'}:\n                    res_dt[k][all_c] = 3#\"open\" #1#\n                elif set(master_dict[k][\"all\"]) == {'close'}:\n                    res_dt[k][all_c] = 0#\"close\" #0#\n                elif (set(master_dict[k][\"all\"]) == {\"na\"})|(set(master_dict[k][\"all\"]) == {\"restrict\"})|(len(set(master_dict[k][\"all\"])) > 1):\n                    res_dt[k][all_c] = 1#\"other\" #-2#\n\n                #restrictions_dict[cc][all_c]['message'].append(relevant_messages)\n\n        for sub_o in master_dict[k].keys():\n            if (sub_o not in european_regions) &(sub_o != 'all'):\n                #if len(set(master_dict[k][sub_o])) > 1:\n                #    res_dt[k][sub_o] = 2#\"special\" #2#\n                if set(master_dict[k][sub_o]) == {'open'}:\n                    res_dt[k][sub_o] = 3#\"open\" #1#\n                elif set(master_dict[k][sub_o]) == {'close'}:\n                    res_dt[k][sub_o] = 0#\"close\" #0#\n                elif (set(master_dict[k][sub_o]) == {\"na\"})|(set(master_dict[k][sub_o]) == {\"restrict\"}) |(len(set(master_dict[k][sub_o])) > 1) :\n                    res_dt[k][sub_o] = 2\n                #elif (set(master_dict[k][sub_o]) == {\"na\"})|(set(master_dict[k][sub_o]) == {\"restrict\"}):\n                #    res_dt[k][sub_o] = -2#\"other\" #-2#\n                #restrictions_dict[cc][k]['message'].append(relevant_messages)\n        res_dt[k][k] = 4#'home' #3#\n        res_dt[k]['XYZ'] = 0\n\n    res_df = pd.DataFrame(res_dt)\n\n    closure_df = pd.DataFrame()\n    for col_c in res_df.columns:\n\n        df_ = pd.DataFrame(res_df[col_c])\n        df_['home'] = col_c\n        df_.reset_index(inplace=True)\n        df_.rename(columns={'index':'other',col_c:'restriction'},inplace=True)\n        closure_df = pd.concat([closure_df,df_])\n    \n\n    return closure_df","63c0bb27":"message = \"Non-essential travel is banned from non-European Union (EU)\/Schengen Area countries, except for fully vaccinated travellers. Travellers from 'white list' countries - Bahrain, Chile, Colombia, Kuwait, Peru, Rwanda and the United Arab Emirates (UAE), Hong Kong, Indonesia, Macau, New Zealand, Qatar, Saudi Arabia, South Korea, Taiwan and Uruguay - are exempt from the ban. Transit from a non-Schengen country through Belgium to another Schengen country is only permitted for EU\/Schengen nationals and for essential travel.\"\n# message = clean_message_keep_punct(message)\neach_country_dict = country_restrictions(message)\nprint(each_country_dict)\nclosure_df = integrate_restriction_to_dataframe(each_country_dict)\nprint(closure_df)","95797f11":"# **2. Extract the meaning of the sentence**\n* Identity if the countries mentioned in the document are allowed or not\n* Steps carried out:\n> 1. Identitfy commonly used nouns, verbs, noun chunks and special adverbs such as \"other than\", etc.\n> 2. Create rules to extract the intent of the sentence. For example, identifying if the sentence is about banning countries or opening up.\n> 3. Add results to a table.","4f7baea2":"After extending the patterns for GPE entity we are able to identify most of the countries mentioned as shown above.\nBelow is a dependency plot of the words in the NOTAMS message:","26945f4b":"# **1. Identity the countries' names or international organisations and tag it**\n* Identification of country names:\n> - Collect all aliases of country names\n> - Create a pattern to tag it with country code as the id\n> - Merge country names to single entity","23dcb75a":"Creating patterns to identity group of countries such as the EU and add it to the entity ruler so that such words would be tagged as GPE","3e575076":"**Identify commonly used nouns, verbs, noun chunks and special adverbs**\n* The commonly used nouns and verbs were determined using tags and counter.\n* Other commonly used phrases and words will be added manually. E.g. \"other than\"\n* Once we identified the verbs and nouns, we group them into two categories: positive and negative\n* For restrictions that used phrases such as \"this does not apply\", etc. We don't label the restriction as open\/close but as \"na\", denoting not known ","ae6d8f5c":"Converting the results to a dataframe:\n\n* As we are extracting the information from each sentence, some countries might have contradicting tags (both open and close associated to the same country. In such cases we simply label the restriction as \"1\"(restriction) if regions such as EU, Scandinavia or as \"2\" (special) for country specific mention\n\n* The restriction levels used are given below:\n\n> * 4 - home\n> * 3 - open\n> * 2 - special\n> * 1 - restriction\n> * 0 - close","82f33985":"**In the above sentence, the airport is identified as \"open\" for negative tested travellers.**","e3b2622a":"**Merge entities of GPE and ORG into single tokens**","46500138":"*Note: NORP is nationalities*","1f065eb8":"**References**\n* https:\/\/emergentalliance.org\/information-extraction-from-travel-restrictions-data\/\n* https:\/\/github.com\/emergent-analytics\/workstreams\/tree\/ad852f91f2ce1645013406eb81a3ba235f385631\/Mobility%20and%20Tourism%20-%20WS2\/airport_restrictions","7b1c2e00":"NOTE: for restrictions that have conditions that are not exactly known will be classified as NA","57a72a07":"**Create Rules**\n> 1. Use phrase matcher!\n> <nouns> from <GPE> are <verbs> to land <GPE>\n> 2. Look for verbs of interest:\n    1. Filter sentences\n    2. Check if verbs match\n    3. Get GPEs\n    4. See if words such as other than, except are present\n    \n**Identify complete closure to international flights**\n* Check if nouns or noun_chunks are present in the doc.\n    \n**Identification of airport close\/open to specific countries**\n\n* Check if positive\/negative verbs are present\n* Check if positive\/negative nouns are present\n* Check if negation is associated with the verb\/noun\n* Identify exceptions in the sentences\n* Extract the country mention in the message\n* Associate the identified tag (open\/close\/na) with the countries mentioned in the message"}}