{"cell_type":{"4f1cfd02":"code","95bc481e":"code","f62a6ffa":"code","86c30c8c":"code","837e5bf3":"code","954cb183":"code","862d4c1a":"code","55aa3649":"code","cdf9b80b":"code","bb884878":"markdown","c359dea0":"markdown","76387919":"markdown","b0850de9":"markdown","0f38a018":"markdown","c281154e":"markdown","f8932052":"markdown"},"source":{"4f1cfd02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95bc481e":"from sklearn.impute import SimpleImputer\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n\n#clean train data\nmedian = train_data[\"Age\"].median()\ntrain_data[\"Age\"].fillna(median, inplace=True)\nmedian = train_data[\"Fare\"].median()\ntrain_data[\"Fare\"].fillna(median, inplace=True)\n\ntrain_data.head(6)","f62a6ffa":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\n#clean TEST data\nmedian = test_data[\"Age\"].median()\ntest_data[\"Age\"].fillna(median, inplace=True)\nmedian = test_data[\"Fare\"].median()\ntest_data[\"Fare\"].fillna(median, inplace=True)\n\ntest_data.head(6)","86c30c8c":"from sklearn.model_selection import train_test_split\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Fare\"]\nlabels = train_data[\"Survived\"]\nfeatures = pd.get_dummies(train_data[features])\n\nx_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.5, random_state = 1)","837e5bf3":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\n\nparams = [\n    {'max_depth': [3, 4,5], 'max_features': [4,6], 'n_estimators': [10,20,50]},\n]\nm = RandomForestClassifier(random_state=1)\nmodel_grid_search = GridSearchCV(m, params, cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True), scoring='f1', return_train_score=False)\n\nscores = []\nmodel_grid_search.fit(x_train, y_train)\nprint(model_grid_search.best_params_)\n\ndf = pd.DataFrame(model_grid_search.cv_results_)\ndf[['param_max_depth','param_max_features', 'param_n_estimators','mean_test_score']]\n\n#WHY THIS CODE ALWAYS GIVES ME DIFFERENT PARAMETERS?!\n# https:\/\/www.youtube.com\/watch?v=HdlDYng8g9s&feature=youtu.be&t=321&ab_channel=codebasics\n# https:\/\/stats.stackexchange.com\/questions\/439485\/how-to-evaluate-whether-model-is-overfitting-or-underfitting-when-using-cross-va\n# https:\/\/towardsdatascience.com\/one-potential-cause-of-overfitting-that-i-never-noticed-before-a57904c8c89d","954cb183":"#Evaluation\ndef evaluate_accuracy(model, y_test, predictions):\n    # Compute how well we performed\n    correct = 0\n    incorrect = 0\n    total = 0\n    for actual, predicted in zip(y_test, predictions):\n        total += 1\n        if actual == predicted:\n            correct += 1\n        else:\n            incorrect += 1\n        \n    # Print results\n    print(f\"Results for model {type(model).__name__}\")\n    print(f\"Correct: {correct}\")\n    print(f\"Incorrect: {incorrect}\")\n    print(total)\n    print(f\"Accuracy: {100 * correct \/ total:.2f}%\")","862d4c1a":"model_base = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel_base.fit(pd.get_dummies(x_train),y_train)\npredictions = model_base.predict(x_test)\n\nevaluate_accuracy(model_base, y_test, predictions)","55aa3649":"# {'max_depth': 4, 'max_features': 4, 'n_estimators': 10}\n# model_gscv = RandomForestClassifier(max_depth=3, max_features=6, n_estimators=20, random_state=1)\nmodel_gscv = RandomForestClassifier(max_depth=5, max_features=6, n_estimators=10, random_state=1)\nmodel_gscv.fit(pd.get_dummies(x_train),y_train)\npredictions_gscv = model_gscv.predict(x_test)\n\nevaluate_accuracy(model_gscv, y_test, predictions_gscv)\n","cdf9b80b":"features_sub = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Fare\"]\nx_train_sub = pd.get_dummies(train_data[features_sub])\ny_train_sub = train_data[\"Survived\"]\nmodel_submit = RandomForestClassifier(max_depth= 5, max_features= 6, n_estimators= 10, random_state=1)\nmodel_submit.fit(x_train_sub, y_train_sub)\n\npredictions_submit = model_submit.predict(pd.get_dummies(test_data[features_sub]))\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_submit})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","bb884878":"<br>CleanData","c359dea0":"**Best Model, score: 0.78229******","76387919":"**Submit**","b0850de9":"**Split Train data**","0f38a018":"**Find The Best Pameters using Grid Search**","c281154e":"<b>Some notations on the data set<\/b><br>\n\nsibsp Number of Siblings\/Spouses Aboard<br>\nparch Number of Parents\/Children Aboard<br>\nfare is ticket price","f8932052":"**GridsearchCV**"}}