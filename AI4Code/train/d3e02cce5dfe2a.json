{"cell_type":{"da70f967":"code","8f1fc8fd":"code","b80a9071":"code","b7a8e58a":"code","6692b999":"code","80c87fc8":"code","4ffba299":"code","e7d3ff17":"code","dd8fdc2e":"code","dbace9d2":"code","98d13c49":"code","af68f81b":"code","417f50d8":"code","684d4bb9":"code","82e26e89":"code","be00f35c":"code","ae941cc4":"markdown","1e4b87b3":"markdown","06916fe1":"markdown","1df8532d":"markdown","792cd80e":"markdown","f122c6ad":"markdown","d65a0a08":"markdown"},"source":{"da70f967":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n# tf.keras stuff\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import backend\nfrom tensorflow.keras import models","8f1fc8fd":"# loading data\ntrain_raw = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_raw = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(\"Training dataset has\", train_raw.shape[0], \"rows\/instances and\", train_raw.shape[1], \"columns\/features.\")\nprint(\"Testing dataset has\", test_raw.shape[0], \"rows\/instances and\", test_raw.shape[1], \"columns\/features.\")","b80a9071":"# splitting target variable from training data\nX_train_full = train_raw.drop('label', axis=1)\ny_train_full = train_raw['label']","b7a8e58a":"X_valid, X_train = X_train_full[:5000] \/ 255., X_train_full[5000:] \/ 255.\ny_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n\nprint(\"Training dataset has\", X_train.shape[0], \"rows\/instances and\", X_train.shape[1], \"columns\/features.\")\nprint(\"Validation dataset has\", X_valid.shape[0], \"rows\/instances and\", X_valid.shape[1], \"columns\/features.\")","6692b999":"class ExponentialLearningRate(callbacks.Callback):\n    def __init__(self, factor):\n        self.factor = factor\n        self.rates = []\n        self.losses = []\n    \n    def on_batch_end(self, batch, logs):\n        self.rates.append(backend.get_value(self.model.optimizer.lr))\n        self.losses.append(logs[\"loss\"])\n        backend.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)","80c87fc8":"# list of layers to be used in model\nlayers_list = [\n    layers.InputLayer(input_shape=[784]),\n    layers.Dense(300, activation=\"relu\"),\n    layers.Dense(100, activation=\"relu\"),\n    layers.Dense(10, activation=\"softmax\")\n]\n\nmodel = models.Sequential(layers_list)","4ffba299":"# compiling model\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizers.SGD(lr=1e-3), metrics=[\"accuracy\"])\n\nexp_lr = ExponentialLearningRate(factor=1.005)","e7d3ff17":"history = model.fit(X_train, y_train, epochs=1, \n          validation_data=(X_valid, y_valid), \n          callbacks=[exp_lr])","dd8fdc2e":"# plotting loss as function of learning rate\nplt.plot(exp_lr.rates, exp_lr.losses)\nplt.gca().set_xscale('log')\nplt.hlines(min(exp_lr.losses), min(exp_lr.rates), max(exp_lr.rates))\nplt.axis([min(exp_lr.rates), max(exp_lr.rates), 0, exp_lr.losses[0]])\nplt.xlabel(\"Learning rate\")\nplt.ylabel(\"Loss\")","dbace9d2":"backend.clear_session()","98d13c49":"model = models.Sequential(layers_list)\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizers.SGD(lr=2e-1), metrics=[\"accuracy\"])","af68f81b":"early_stopping_cb = callbacks.EarlyStopping(patience=20)    # stopping training early if validation loss isn't improving\ncheckpoint_cb = callbacks.ModelCheckpoint(\"mnist_model.h5\", save_best_only=True)    # save best model only\n\nhistory = model.fit(X_train, y_train, epochs=100, \n          validation_data=(X_valid, y_valid), \n          callbacks=[early_stopping_cb, checkpoint_cb])","417f50d8":"# rollback to best model\nmodel = models.load_model(\"mnist_model.h5\")","684d4bb9":"# feature scaling test data\nX_test = test_raw \/ 255.","82e26e89":"final_pred = model.predict_classes(X_test)","be00f35c":"# create submission file\nmy_submission = pd.DataFrame({'ImageId': np.array(range(1,28001)), 'Label': final_pred})\nmy_submission.to_csv(\"submission.csv\", index=False)","ae941cc4":"# Submission","1e4b87b3":"Creating a validation set and also scaling the features to 0-1 range for simplicity.","06916fe1":"# Load and prepare the data","1df8532d":"# Create the model","792cd80e":"Now, we will create final model with optimal learning rate.","f122c6ad":"First, train for only one epoch to check optimal learning rate.","d65a0a08":"Creating a custom callback for keras model. It will increase the learning rate by a factor at each batch end."}}