{"cell_type":{"009df150":"code","8fdcd4a3":"code","4a027d81":"code","d8f4be16":"code","0d539585":"code","23000b70":"code","50f5a7e0":"code","6f8d09e4":"code","97fe4353":"code","0ab90a1e":"code","bf5b8436":"code","e4320b3f":"code","f5b41182":"code","3fd4fa81":"code","f9b117cf":"code","59a5ed6f":"code","1c4385ec":"code","bf656f08":"code","41820df0":"code","99937023":"code","8b028849":"code","a1f31754":"markdown","fd809d6f":"markdown"},"source":{"009df150":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8fdcd4a3":"train=pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\ntest=pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")","4a027d81":"train.head()","d8f4be16":"train=train[['text','target']]","0d539585":"X=train.drop('target',axis=1)\ny=train['target']","23000b70":"print(X.shape)\nprint(y.shape)","50f5a7e0":"tf.__version__\n","6f8d09e4":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom keras.layers import Dropout","97fe4353":"vocab_size=5000\n","0ab90a1e":"train.isnull().sum()","bf5b8436":"\nimport nltk\nimport re\nfrom nltk.corpus import stopwords","e4320b3f":"from nltk.stem import WordNetLemmatizer \nlemmatizer = WordNetLemmatizer()\ncorpus = []\nfor i in range(0, len(train)):\n    review = re.sub('[^a-zA-Z]', ' ', train['text'][i])\n    review = review.lower()\n    review = review.split()\n    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\ncorpus[0]    ","f5b41182":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr[0]","3fd4fa81":"\nsent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs[0])","f9b117cf":"embedding_vector_features=40\nfrom tensorflow.keras.layers import Dropout\n## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","59a5ed6f":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","1c4385ec":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.30, random_state=42)","bf656f08":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)\n","41820df0":"y_pred=model.predict_classes(X_test)\n","99937023":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)*100","8b028849":"# test=test[['text']]\n# test","a1f31754":"will continue working on accuracy and make predictions for the test data ...","fd809d6f":"somehow after using dropout accuracy is a bit lower .."}}