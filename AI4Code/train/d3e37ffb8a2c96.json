{"cell_type":{"038c18e8":"code","c39b498a":"code","2c2a508f":"code","25d59e33":"code","428b3562":"code","6be02778":"code","7255880e":"code","f9805004":"code","492eb325":"code","ce7c5406":"code","af557272":"code","b6c86e22":"code","02179864":"code","15832c73":"code","e6b67dc3":"code","795d985c":"code","0f651da5":"code","95034757":"code","28d08b7e":"code","15fa16b3":"code","28060ac1":"code","4b568260":"code","7881c0ba":"code","d3e8341e":"code","a79014f4":"code","82191519":"code","8fb06f21":"code","7b44ec88":"code","58075c62":"code","57e8b618":"code","227bb2a8":"code","f6eb206c":"code","f3162641":"code","bef148fd":"code","b842e77c":"code","2658ef99":"code","f0ae68af":"code","9f1bd5a6":"code","a59ca9cd":"code","3ad74889":"code","16a7f713":"code","f9eb9572":"code","acb00a74":"code","0a11fbd4":"code","b8367c17":"markdown","40d1eed3":"markdown","c17729ce":"markdown","9e1e2a65":"markdown","099671a9":"markdown","f11ec163":"markdown","9525c5f6":"markdown","aea9af9d":"markdown","cc5235b5":"markdown","5a65274f":"markdown","66fd97f9":"markdown","3168ba6a":"markdown","cb127e56":"markdown","6e6b88f7":"markdown","29f603d8":"markdown","be6d9cbf":"markdown"},"source":{"038c18e8":"import pandas as pd\nimport numpy as np\nimport math\nimport time\nimport os\nfrom skimage import io, transform\nimport PIL","c39b498a":"# Config\ndata_dir = '..\/input\/petfinder-pawpularity-score\/'\nglobal_batch_size = 32\nworkers = 2\nnp.random.seed(10)\nprint(os.listdir(data_dir))\nprint(os.listdir(f'{data_dir}train')[0:4])","2c2a508f":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torchvision import datasets, transforms\n\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ExponentialLR\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler","25d59e33":"train_df = pd.read_csv(f'{data_dir}train.csv')","428b3562":"train_df.head()","6be02778":"train_df.info()","7255880e":"# Annotations\nnp.array(train_df.iloc[2, 1:13])","f9805004":"# Scores\ntrain_df.iloc[2, 13]","492eb325":"n, bins, patches = plt.hist(train_df.iloc[:, 13], 50, density=True, facecolor='g', alpha=0.75)\n\nplt.xlabel('Pawpularity')\nplt.ylabel('Frequency')\nplt.title('Pawpularity Histogram')\nplt.xlim(0, 100)\n# plt.ylim(0, 0.03)\nplt.grid(True)\nplt.show()","ce7c5406":"class PawpularityDataset(Dataset):\n    \"\"\"Dataset connecting animal images to the score and annotations\"\"\"\n\n    def __init__(self, csv_file, img_dir, transform=transforms.ToTensor()):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            img_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n\n        self.annotations_csv = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations_csv)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.img_dir,\n                                self.annotations_csv.iloc[idx, 0])\n\n        # load each image in PIL format for compatibility with transforms\n        image = PIL.Image.open(img_name + '.jpg')\n        \n        # Columns 1 to 12 contain the annotations\n        annotations = np.array(self.annotations_csv.iloc[idx, 1:13])\n        annotations = annotations.astype('float')\n        # Column 13 has the scores\n        score = np.array(self.annotations_csv.iloc[idx, 13])\n        score = torch.tensor(score.astype('float')).view(1)\n\n        # Apply the transforms\n        image = self.transform(image)\n\n        sample = [image, annotations, score]\n        return sample","af557272":"## Define transforms with image augmentation on the training set\nimg_transforms = transforms.Compose([transforms.Resize(255),\n                                     transforms.CenterCrop(224),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.RandomRotation(20),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                          std=[0.229, 0.224, 0.225])])\n\nimg_transforms_valid = transforms.Compose([transforms.Resize(255),\n                                           transforms.CenterCrop(224),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                std=[0.229, 0.224, 0.225])])","b6c86e22":"# Load the dataset\ntrain_dataset = PawpularityDataset(f'{data_dir}train.csv', f'{data_dir}train', transform=img_transforms)\ntrain_dataset.img_dir","02179864":"dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)","15832c73":"# Batch size of 8\nimages, annotations, scores = next(iter(dataloader))\nprint(images.shape)\nprint(scores.shape)\nprint(annotations.shape)","e6b67dc3":"# Helper function to de-normalize and plot images\ndef im_convert(tensor):\n    \"\"\" Display a tensor as an image. \"\"\"\n    \n    image = tensor.to(\"cpu\").clone().detach()\n    image = image.numpy().squeeze()\n    image = image * np.array((0.229, 0.224, 0.225)).reshape(3, 1, 1) + np.array((0.485, 0.456, 0.406)).reshape(3, 1, 1)\n    img = (image * 255).astype(np.uint8) # unnormalize\n    \n\n    return plt.imshow(np.transpose(img, (1, 2, 0)))","795d985c":"im_numpy = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(20, 10))\n# display 20 images\nfor idx in np.arange(8):\n    ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\n    im_convert(images[idx])\n    ax.set_title(scores[idx].item())","0f651da5":"import torch.nn as nn\nimport torch.nn.functional as func\nimport torch.optim as optim","95034757":"# Calculate the dense layer input size\n# Padding of 1 and of 3 means no change in the image dimensions apart from pooling\n\nsdim = 224\/2\/2\/2\/2\/2 #maxpoolin layers reduce xy dimensions by 2\nprint(sdim)\nprint(sdim*sdim*256+12) # add in the annotations","28d08b7e":"class Regression(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # covolutional layers\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        \n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n        \n        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)\n        self.conv5 = nn.Conv2d(64, 64, 3, padding=1)\n        \n        self.conv6 = nn.Conv2d(64, 128, 3, padding=1)\n        self.conv7 = nn.Conv2d(128, 128, 3, padding=1)\n        \n        self.conv8 = nn.Conv2d(128, 256, 3, padding=1)\n        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n        \n        # maxpooling layer\n        self.maxpool = nn.MaxPool2d(2, 2)\n        \n        # Dense layers\n        self.fc1 = nn.Linear(12556, 512)\n        \n        # regression output\n        self.fc4 = nn.Linear(512, 1)\n        \n        # dropout\n        self.dropout = nn.Dropout(0.3)\n    \n    def limit_range(self, x):\n        x = torch.where(x > 100.0, 100.0, x)\n        x = torch.where(x < 0.0 , 0.0, x)\n        return x\n        \n    def forward(self, data):\n        \n        img = data['images']\n        ann = data['annotations']\n        # Conv layers\n        x = self.maxpool(func.relu(self.conv1(img)))\n        \n        x = func.relu(self.conv2(x))\n        x = self.maxpool(func.relu(self.conv3(x)))\n        \n        x = func.relu(self.conv4(x))\n        x = self.maxpool(func.relu(self.conv5(x)))\n        \n        x = func.relu(self.conv6(x))\n        x = self.maxpool(func.relu(self.conv7(x)))\n        \n        x = func.relu(self.conv8(x))\n        x = self.maxpool(func.relu(self.conv9(x)))\n        \n        \n        # flatten and combine with annotations\n        x = x.view(x.shape[0], -1)\n        x = torch.cat((x, ann.float()), 1)\n        x = self.dropout(x)\n        \n        # Dense layers\n        x = self.dropout(func.relu(self.fc1(x)))\n        x = self.fc4(x).double()\n        \n        # Limit output to the 0 to 100 range\n        x = torch.sigmoid(x)*100\n        # x = self.limit_range(x)\n        \n        return x","15fa16b3":"# Define a custom weight initialization\n\ndef init_weights(m):\n    classname = m.__class__.__name__\n    \n    if classname.find('Linear') != -1:\n        n = m.in_features\n        y = 1.\/np.sqrt(n)\n        m.weight.data.normal_(0.0, y)\n        m.bias.data.fill_(0)","28060ac1":"# Create the model and initalize loss function and optimizer\n\nmodel = None\ntorch.manual_seed(13)\nmodel = Regression()\n\n#Custom initialization\nmodel.apply(init_weights)\n\ncriterion = nn.MSELoss(reduction='sum')\n\n#Adam with L2 regularization\noptimizer = optim.AdamW(model.parameters(), lr=0.00007, weight_decay=0.2)\n\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = [1, 3, 6, 10], gamma=0.4)","4b568260":"# Load a small batch to test out the forward pass\n\ntrain_dataset = PawpularityDataset(f'{data_dir}train.csv', f'{data_dir}train', transform=img_transforms)\ndataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\nimages, annotations, scores = next(iter(dataloader))","7881c0ba":"# Test out the forward pass on a single batch\n# RMSE before any training (with random parameters): \nwith torch.no_grad():\n    train_loss = 0.0\n    output = model({'images': images, 'annotations': annotations})\n    loss = criterion(output, scores)\n    math.sqrt(loss.item()\/64)","d3e8341e":"print(torch.mean(output))\nprint(torch.std(output))","a79014f4":"print(model)","82191519":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\ndevice = torch.cuda.get_device_name()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print(f'CUDA is available!  Training on GPU {device}...')","8fb06f21":"## Load and set up the final training and validation dataset (use different transforms)\n\ntrain_data = PawpularityDataset(f'{data_dir}train.csv', f'{data_dir}train', transform=img_transforms)\nvalid_data = PawpularityDataset(f'{data_dir}train.csv', f'{data_dir}train', transform=img_transforms_valid)\n\nnp.random.seed(13)\n\n# obtain random indices that will be used for traingin\/validation split\nvalid_size = 0.1\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=global_batch_size,\n                                           sampler=train_sampler, num_workers=workers,\n                                           pin_memory=True) \nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=global_batch_size,\n                                           sampler=valid_sampler, num_workers=workers,\n                                           pin_memory=True) \n\nprint(len(train_loader)*global_batch_size)\nprint(len(valid_loader)*global_batch_size)","7b44ec88":"# number of epochs to train the model\n# Use 40 epochs\n\nif train_on_gpu:\n    model.cuda()\n\nn_epochs = 40\n\nvalid_loss_min = np.Inf # track change in validation loss\n\ntrain_losses, valid_losses = [], []\n\nfor epoch in range(1, n_epochs+1):\n    \n    start = time.time()\n    current_lr = scheduler.get_last_lr()[0]\n    \n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    # put in training mode (enable dropout)\n    model.train()\n    for images, annotations, scores in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        # the annotations get added in the dense layers\n        output = model({'images': images, 'annotations': annotations})\n        # print(output.dtype)\n        # print(scores.dtype)\n        # calculate the batch loss\n        loss = criterion(output, scores)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()\n        \n    ######################    \n    # validate the model #\n    ######################\n    # eval mode (no dropout)\n    model.eval()\n    with torch.no_grad():\n        for images, annotations, scores in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if train_on_gpu:\n                images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model({'images': images, 'annotations': annotations})\n            # calculate the batch loss\n            loss = criterion(output, scores)\n            # update average validation loss \n            valid_loss += loss.item()\n    \n    # calculate RMSE\n    train_loss = math.sqrt(train_loss\/len(train_loader.sampler))\n    valid_loss = math.sqrt(valid_loss\/len(valid_loader.sampler))\n    \n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n        \n    # increment learning rate decay\n    scheduler.step()\n    \n    # print training\/validation statistics \n    # print(f'Epoch: {e}, {float(time.time() - start):.3f} seconds, lr={optimizer.lr}')\n    print('Epoch: {}, time: {:.3f}s, lr: {:.6f} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, float(time.time() - start), current_lr, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'pawpularity_best_model.pt')\n        valid_loss_min = valid_loss","58075c62":"# Load the best performing model on the validation set\nmodel.load_state_dict(torch.load('pawpularity_best_model.pt'))","57e8b618":"# get the distribution of predictions\n\npredictions = []\nscore_list = []\n\nmodel.eval()\nwith torch.no_grad():\n    for images, annotations, scores in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model({'images': images, 'annotations': annotations})\n        predictions.extend(list(output.cpu().detach().numpy().reshape(len(output),)))\n        score_list.extend(list(scores.cpu().detach().numpy().reshape(len(scores),)))\n        \n\npreds_df = pd.DataFrame({'preds': predictions})\npreds_df.describe()","227bb2a8":"# Manually Check RMSE\ndiffs = np.array(score_list) - np.array(predictions)\nprint(math.sqrt((diffs @ diffs)\/len(valid_loader.sampler)))\n","f6eb206c":"# Check that manually increasing the variance doesn't help\n# Currently slightly increasing the std dev manually actually does reduce validation error\n\nmean = np.mean(np.array(predictions))\nstddev = np.std((np.array(predictions)))\nprint(mean, stddev)\nupdated_normalized = 1.5*(predictions-mean)\/stddev\nnew_predictions = updated_normalized+predictions\n\ndiffs = np.array(score_list) - np.array(new_predictions)\nprint(math.sqrt((diffs @ diffs)\/len(valid_loader.sampler)))","f3162641":"# Histogram of validation predictions \n\nn, bins, patches = plt.hist(predictions, 50, density=True, facecolor='g', alpha=0.75)\n\nplt.xlabel('Pawpularity')\nplt.ylabel('Frequency')\nplt.title('Predicted Pawpularity Histogram')\nplt.xlim(0, 100)\nplt.ylim(0, .2)\nplt.grid(True)\nplt.show()","bef148fd":"# Histogram of validation set actual scores\n\nn, bins, patches = plt.hist(train_df.iloc[valid_idx, 13], 50, density=True, facecolor='g', alpha=0.75)\n\nplt.xlabel('Pawpularity')\nplt.ylabel('Frequency')\nplt.title('Actual Pawpularity Histogram')\nplt.xlim(0, 100)\nplt.ylim(0, .2)\nplt.grid(True)\nplt.show()","b842e77c":"# Plot the losses\nfig = plt.figure()\nax = plt.axes()\nax.plot(list(range(1, len(train_losses))), train_losses[1:])\nax.plot(list(range(1, len(valid_losses))), valid_losses[1:]);\nprint(f'best score: {valid_loss_min}')","2658ef99":"images, annotations, scores = next(iter(valid_loader))\nimages, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()","f0ae68af":"output_plot = model({'images': images, 'annotations': annotations}).cpu()\nimages, annotations, scores = images.cpu(), annotations.cpu(), scores.cpu()","9f1bd5a6":"# plot the images in the batch, along with the corresponding labels and predictions\n\nfig = plt.figure(figsize=(20, 10))\n# display 20 images\nfor idx in np.arange(12):\n    ax = fig.add_subplot(3, 4, idx+1, xticks=[], yticks=[])\n    im_convert(images[idx])\n    ax.set_title(f'Act: {round(scores[idx].item())} Pred: {round(output_plot[idx].item())}')","a59ca9cd":"test_df = pd.read_csv(f'{data_dir}test.csv')\ntest_df.head(10)","3ad74889":"# Load the best performing model on the validation set\nmodel.load_state_dict(torch.load('pawpularity_best_model.pt'))","16a7f713":"class PawpularityTestDataset(Dataset):\n    \"\"\"Dataset connecting dog images to the score and annotations\"\"\"\n\n    def __init__(self, csv_file, img_dir, transform=transforms.ToTensor()):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            img_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n\n        self.annotations_csv = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations_csv)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.img_dir,\n                                self.annotations_csv.iloc[idx, 0])\n\n        # load each image in PIL format for compatibility with transforms\n        image = PIL.Image.open(img_name + '.jpg')\n\n        annotations = np.array(self.annotations_csv.iloc[idx, 1:13])\n        annotations = annotations.astype('float')\n\n        # Apply the transforms\n        image = self.transform(image)\n\n        sample = [image, annotations]\n        return sample","f9eb9572":"## Load the test dataset\ntest_data = PawpularityTestDataset(f'{data_dir}test.csv', f'{data_dir}test', transform=img_transforms_valid)\n\nbatch_size = min(len(test_data), 32)\n\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=workers) ","acb00a74":"# Step through with a reasonable batch size and build up the output dataset\n\nmodel.eval()\noutputs = []\nfor images, annotations in test_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        images, annotations = images.cuda(), annotations.cuda()\n    test_output = model({'images': images, 'annotations': annotations})\n    outputs.extend(list(test_output.cpu().detach().numpy().reshape(len(test_output),)))\n    \nimg_names = list( test_df.iloc[:, 0].values)\noutputs = [round(x, 2) for x in outputs]\n\noutput_df = pd.DataFrame({'Id': img_names, 'Pawpularity': outputs})\noutput_df.head(10)","0a11fbd4":"# Write the output in the required format\noutput_df.to_csv('submission.csv', index=False)","b8367c17":"### Train the model","40d1eed3":"## Pawpularity CNN from Scratch in Pytorch\n\nThis notebook implements a CNN with 9 convolutional layers and 2 fully connected layers from base pytorch, with no pretrained models or weights used.  Since pawpularity is bounded between 1 and 100 the final layer's activation is the sigmoid function * 100, and MSE is used as the loss function for optimization.  \n\n\nThe final competition evaluation metric is the square root of MSE or \n$ \\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $","c17729ce":"**Load and check out the dataset**","9e1e2a65":"**Look at the annotations**","099671a9":"**Custom dataset class to attach annotations and scores to the images**","f11ec163":"**Look at some images**","9525c5f6":"### Load Dependencies","aea9af9d":"**Define global image transforms**","cc5235b5":"### Load and Explore data","5a65274f":"### Use the model to predict the test dataset","66fd97f9":"### Show examples of images and predicted vs. actual scores","3168ba6a":"### Diagnostics and performance","cb127e56":"### Set up the cnn structure","6e6b88f7":"The range could still be a lot greater, and the model is failing completely at predicting the highest ranked images that get a score of 100.  ","29f603d8":"**Model training loop**","be6d9cbf":"**Dataset setup**"}}