{"cell_type":{"dde1bb50":"code","2f076a25":"code","792fcadf":"code","80119850":"code","6246d6f1":"code","aaae7dd7":"code","86bbc729":"code","c4b1f376":"code","d123f306":"code","be3abccf":"code","ed02e0a4":"code","25f6784f":"code","27dee30c":"code","cdc45635":"code","f84ef671":"code","adf08007":"code","8400cf16":"code","ea80c84b":"code","f2c85284":"code","805fc241":"code","a50bfb88":"code","4c3d2dbd":"markdown","05af80ef":"markdown","556cb403":"markdown"},"source":{"dde1bb50":"!pip install alibi","2f076a25":"import matplotlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical\nfrom alibi.explainers import AnchorImage","792fcadf":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nprint('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)","80119850":"idx = 0\nplt.imshow(x_train[idx]);","6246d6f1":"x_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255\nx_train = np.reshape(x_train, x_train.shape + (1,))\nx_test = np.reshape(x_test, x_test.shape + (1,))\nprint('x_train shape:', x_train.shape, 'x_test shape:', x_test.shape)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\nprint('y_train shape:', y_train.shape, 'y_test shape:', y_test.shape)","aaae7dd7":"def model():\n    x_in = Input(shape=(28, 28, 1))\n    x = Conv2D(filters=64, kernel_size=2, padding='same', activation='relu')(x_in)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    x = Conv2D(filters=32, kernel_size=2, padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    x = Flatten()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x_out = Dense(10, activation='softmax')(x)\n\n    cnn = Model(inputs=x_in, outputs=x_out)\n    cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return cnn","86bbc729":"cnn = model()\ncnn.summary()","c4b1f376":"cnn.fit(x_train, y_train, batch_size=64, epochs=3)","d123f306":"# Evaluate the model on test set\nscore = cnn.evaluate(x_test, y_test, verbose=0)\nprint('Test accuracy: ', score[1])","be3abccf":"def superpixel(image, size=(4, 7)):\n    segments = np.zeros([image.shape[0], image.shape[1]])\n    row_idx, col_idx = np.where(segments == 0)\n    for i, j in zip(row_idx, col_idx):\n        segments[i, j] = int((image.shape[1]\/size[1]) * (i\/\/size[0]) + j\/\/size[1])\n    return segments","ed02e0a4":"segments = superpixel(x_train[idx])\nplt.imshow(segments);","25f6784f":"predict_fn = lambda x: cnn.predict(x)","27dee30c":"image_shape = x_train[idx].shape\nexplainer = AnchorImage(predict_fn, image_shape, segmentation_fn=superpixel)","cdc45635":"i = 4\nimage = x_test[i]\nplt.imshow(image[:,:,0]);","f84ef671":"cnn.predict(image.reshape(1, 28, 28, 1)).argmax()","adf08007":"explanation = explainer.explain(image, threshold=.95, p_sample=.8, seed=0)","8400cf16":"plt.imshow(explanation.anchor[:,:,0]);","ea80c84b":"i = 10\nimage = x_test[i]\nplt.imshow(image[:,:,0]);","f2c85284":"cnn.predict(image.reshape(1, 28, 28, 1)).argmax()","805fc241":"explanation = explainer.explain(image, threshold=.95, p_sample=.8, seed=0)","a50bfb88":"plt.imshow(explanation.anchor[:,:,0]);","4c3d2dbd":"Explanation:\n\nSimilarly to the first example, the anchor explanations have been done on the image of a handwritten number '0' from the MNIST Image Dataset, which is shown in terms of the superpixels up above. \n\nUpon generating the anchor explanation for that image, we get the image shown below, which shows us all the pixels of the original image that were sufficient for the model to make the prediction that the digit in the image was '0'. We get two dense pixel areas that are unique on the left and right side. No other digit has curved lines on the central left and central right side. Therefore, we can conclude that the digit is '0'.\n\nTherefore, we can say that, if only the pixels shown in the Anchors explanation were present in the original image, the model would still make the same prediction that the digit was '0' as these pixels are sufficient for the model to make that prediction. ","05af80ef":"Anchors for MNIST","556cb403":"Explanation: \n\nThe anchor explanations have been done on the image of a handwritten number '4' from the MNIST Image Dataset, which is shown in terms of the superpixels up above. \n\nUpon generating the anchor explanation for that image, we get the image shown below, which shows us all the pixels of the original image that were sufficient for the model to make the prediction that the digit in the image was '4'. We get two dense pixel areas that are unique. Upon closer inspection, we realise that, generally speaking, no other digit has pixels on both of the areas shown in the Anchors explanation. There might have been some overlap with other digits if only one area was shown in the Anchors explanation. \n\nTherefore, we can say that, if only the pixels shown in the Anchors explanation were present in the original image, the model would still make the same prediction that the digit was '4' as these pixels are sufficient for the model to make that prediction. "}}