{"cell_type":{"c86ba7b5":"code","6dd72817":"code","c6aeaaba":"code","e531d102":"code","ff81267b":"code","1a8516bd":"code","c304ce0b":"code","3573407d":"code","a984f925":"code","d1cbc91e":"code","f77bac7e":"code","08e017dc":"code","f50c3e70":"code","f17f08f5":"code","ee979fa2":"code","83eeef6a":"code","94271698":"code","a596c9f1":"code","7333281b":"code","6c7cd9c0":"code","119f54d3":"code","964d6231":"code","385885fb":"code","6724fd45":"code","9133c7ca":"code","9e1e95be":"code","8f01b885":"code","45ae5983":"code","d277f38f":"code","f620c940":"code","6460ddb9":"code","fb370d43":"code","b224c507":"code","c1387fef":"code","17e05365":"code","17a69266":"code","8d73fc3d":"code","4db5e071":"code","98b21793":"code","1f408b36":"code","fc32c521":"code","f0b94f2b":"code","99459f2b":"code","54bb2a66":"code","eb47f4d0":"code","3b413afe":"code","293c0057":"code","1b6202f0":"code","11c1a30c":"code","ec41db7a":"code","7634de8a":"code","4d850fec":"code","f394d5af":"code","1d669811":"code","d0fe06fe":"code","3b2dae42":"code","849e08e6":"code","fc87e930":"code","a87bf8ea":"code","26518c49":"code","ff34257d":"code","a25e39eb":"code","145b56d4":"code","af56c94e":"code","0f9d94fe":"code","b11a4e14":"code","59aebff7":"code","75d92931":"code","e892ddc5":"code","617596e7":"code","f1286038":"code","77e8752c":"code","07376626":"code","534af233":"code","b325b155":"code","f5d23fc7":"code","c8cf50e5":"code","12cbb578":"code","5d991de3":"markdown","688142d9":"markdown","13213b24":"markdown","23351a4f":"markdown","8cbf6049":"markdown","cea01344":"markdown","99c64bd9":"markdown","98f8b75d":"markdown","9952099c":"markdown","1177811d":"markdown","1688594f":"markdown","da218cc8":"markdown","c171b2db":"markdown","ba0ac605":"markdown","b1d9a308":"markdown","92c9b75c":"markdown","3a12634a":"markdown","af8c837e":"markdown","ed8386ce":"markdown","0b4f6618":"markdown","211823d2":"markdown","1b4fe69a":"markdown","16a6b6d1":"markdown","2c8a69ef":"markdown","3e5fe8d7":"markdown","56bed167":"markdown","c5d84780":"markdown","92f74630":"markdown","69f3cf9c":"markdown","138a558b":"markdown","f37dd237":"markdown","c36922ec":"markdown","1f35576f":"markdown","779fa41e":"markdown","72e6c0ca":"markdown","68802772":"markdown","91cef7ab":"markdown","ea76a841":"markdown","0cfcd818":"markdown","a4fbd8a5":"markdown","46057237":"markdown","bbd71281":"markdown","04c5b6c1":"markdown","b70480d4":"markdown","555adf32":"markdown","13d3cc96":"markdown","a4d07c93":"markdown","40cc0ae6":"markdown","8c8c64b9":"markdown","a41271ea":"markdown","3970502f":"markdown","949cd3f6":"markdown"},"source":{"c86ba7b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npd.set_option('display.max_rows', 10000)\npd.set_option('display.max_columns', 100)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6dd72817":"path = \"\/kaggle\/input\/ecommerce-data\/data.csv\"","c6aeaaba":"df = pd.read_csv(path,header= 0,encoding=\"ISO-8859-1\", dtype = {'CustomerID': str,'InvoiceID': str})","e531d102":"df_clean = df.copy()\ndf.head()","ff81267b":"df.tail()","1a8516bd":"df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])","c304ce0b":"df_clean.InvoiceDate = df_clean.InvoiceDate.astype(str)\ndf_clean.head()","3573407d":"df_clean['InvoiceDate'] = df_clean['InvoiceDate'].apply(lambda x: x.replace('2011','2020'))\ndf_clean = df_clean[~df_clean.InvoiceDate.str.contains('2010')]\ndf_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])","a984f925":"df_clean = df_clean.drop(columns = 'Country')\ndf_clean = df_clean.reset_index(drop=True)","d1cbc91e":"df_clean.head()","f77bac7e":"missing_percentage = df_clean.isnull().sum() \/ df_clean.shape[0] * 100\nmissing_percentage","08e017dc":"df_clean[df_clean['Description'].isnull()].head()","f50c3e70":"df_clean[df_clean.Description.isnull()].UnitPrice.value_counts()","f17f08f5":"df_clean = df_clean[df_clean['Description'].notnull()]\ndf_clean.Description.isna().value_counts()","ee979fa2":"df_clean[df_clean['UnitPrice']==0.0].head()","83eeef6a":"df_clean = df_clean[df_clean['UnitPrice']!=0.0]\n(df_clean['UnitPrice']==0.0).value_counts()","94271698":"df_clean.describe()","a596c9f1":"df_clean = df_clean[(df_clean['UnitPrice']>0) & (df_clean['Quantity'] > 0)]","7333281b":"df_clean.describe()","6c7cd9c0":"df_clean.head()","119f54d3":"print('number of duplicates: {}'.format(df_clean.duplicated().sum()))","964d6231":"data = df_clean.drop_duplicates()","385885fb":"print('number of duplicates: {}'.format(data.duplicated().sum()))\ndata.shape","6724fd45":"data[data.UnitPrice > 200].head() #to check it fully, remove the head()","9133c7ca":"data[(data.StockCode == 'DOT') | (data.StockCode == 'M') | (data.StockCode == 'AMAZONFEE')].shape","9e1e95be":"sns.boxplot(y=data.UnitPrice)","8f01b885":"data = data[(data.StockCode != 'DOT') & (data.StockCode != 'M') & (data.StockCode != 'AMAZONFEE')].copy()\nsns.boxplot(y=data.UnitPrice)","45ae5983":"data[data.UnitPrice>200].head()","d277f38f":"data = data[(data.StockCode != 'B') & (data.StockCode != 'POST')].copy()\nsns.boxplot(y=data.UnitPrice)","f620c940":"data[data.UnitPrice>200].head()","6460ddb9":"data.describe()","fb370d43":"data[data.Quantity>500].head()","b224c507":"data['des_len'] = data.Description.apply(lambda x: len(x))\ndata.head()","c1387fef":"data.des_len.describe()","17e05365":"data[data.des_len < 10].head()","17a69266":"data['noinvo_len'] = data.InvoiceNo.apply(lambda x: len(x))\ndata.head()","8d73fc3d":"data.noinvo_len.describe()","4db5e071":"data = data.drop(columns = ['des_len', 'noinvo_len'])\ndata.head()","98b21793":"value = {'CustomerID':'Guest'}\ndata = data.fillna(value = value)\ndata[data.CustomerID == 'Guest'].head()","1f408b36":"data['TotalPrice'] = data.Quantity * data.UnitPrice\ndata.shape","fc32c521":"data2 = data.groupby(['InvoiceNo','InvoiceDate','CustomerID']).sum()\ndata2 = data2.drop(columns = 'UnitPrice')\ndata2.head()","f0b94f2b":"data2.describe()","99459f2b":"from scipy.stats import skew","54bb2a66":"skew(data2.TotalPrice)","eb47f4d0":"data2 = data2.query('TotalPrice >= 0 and TotalPrice <= 518.593623 + 1799.695926')\n#we use 0 because the mean-stddev is minus, so instead we just use zero","3b413afe":"data2.describe()","293c0057":"sns.boxplot(data2.TotalPrice)","1b6202f0":"sns.displot(data2.TotalPrice)","11c1a30c":"skew(data2.Quantity)","ec41db7a":"data2 = data2.query('Quantity >= 0  and Quantity <= 220.835074 + 248.776217')\ndata2.describe()","7634de8a":"print(skew(data2.TotalPrice))\nprint(skew(data2.Quantity))","4d850fec":"sns.boxplot(data2.TotalPrice)","f394d5af":"data2 = data2.reset_index()\ninvoice = data2['InvoiceNo'].tolist()","1d669811":"data = data[data.InvoiceNo.isin(invoice)]","d0fe06fe":"data.head()","3b2dae42":"data.describe()","849e08e6":"#first we make a new column named month\ndata['Month'] = data.InvoiceDate.dt.to_period('M')\ndata.head()","fc87e930":"#f, ax = plt.subplots(figsize=(20, 6))","a87bf8ea":"data = data[data.CustomerID != 'Guest']","26518c49":"user_month = data.groupby('Month').CustomerID.nunique().reset_index()\nuser_month.columns = ['month','total_user']\nuser_month.head()","ff34257d":"f, ax = plt.subplots(figsize=(15, 6))\n\nsns.lineplot(data = user_month)\nplt.xlabel('Month')\nplt.ylabel('Unique User')\nplt.title('Unique User by Month')","a25e39eb":"data_cust = data[['CustomerID','InvoiceDate','Quantity','UnitPrice','TotalPrice','StockCode']]\ndata_cust.head()","145b56d4":"#total unique item bought per cust\ntotal_bought = data_cust.groupby('CustomerID').StockCode.nunique().reset_index()\ntotal_bought.columns = ['cust_id','total_product']\ntotal_bought.head()","af56c94e":"#total transaction value\ntotal_trx = data_cust.groupby('CustomerID').TotalPrice.sum().reset_index()\ntotal_trx.columns = ['cust_id','total_trx']\ntotal_trx.head()","0f9d94fe":"data.InvoiceDate.max()","b11a4e14":"#Day since last transactions happen\ndata['LastTrx'] = (pd.to_datetime('2020-12-09 12:50:00') - data.InvoiceDate).dt.days\ndata.tail()","59aebff7":"cus_recent_trx = data.groupby('CustomerID').LastTrx.min().reset_index()\ncus_recent_trx.columns = ['cust_id','recent_trx']\ncus_recent_trx.head()","75d92931":"#buying frequency in a year\ncus_frequency = data_cust.groupby('CustomerID').InvoiceDate.nunique().reset_index()\ncus_frequency.columns = ['cust_id','freq']\ncus_frequency.head()","e892ddc5":"#merge the 4 table\ncust = pd.DataFrame()\ncust['cust_id'] = cus_recent_trx.cust_id\ncust = cust.merge(total_bought, on='cust_id')\ncust = cust.merge(total_trx, on='cust_id')\ncust = cust.merge(cus_recent_trx, on='cust_id')\ncust = cust.merge(cus_frequency, on='cust_id')\ncust.head()","617596e7":"from sklearn.cluster import KMeans","f1286038":"# Calculate sum of squared distances\nssd = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(cust)\n    ssd.append(km.inertia_)","77e8752c":"# Plot sum of squared distances \/ elbow method\nplt.figure(figsize=(10,6))\nplt.plot(K, ssd, 'bx-')\nplt.xlabel('k')\nplt.ylabel('ssd')\nplt.title('Elbow Method For Optimal k')\nplt.show()","07376626":"kmeans = KMeans(n_clusters=4)\nmodel = kmeans.fit(cust)","534af233":"pred = model.labels_\ncust['Cluster'] = pred\ncust.head()","b325b155":"plt.figure(figsize=(10,6))\n\nsns.scatterplot(data=cust, x=\"total_trx\", y=\"recent_trx\", hue=\"Cluster\")\nplt.title('Cluster by Total Transaction and Recencys')\nplt.show()","f5d23fc7":"customers = cust.groupby('Cluster').mean().reset_index()\ncustomers.sort_values('total_trx')","c8cf50e5":"contribution = cust.groupby('Cluster').total_trx.sum().reset_index()\ncontribution['Contribution (%)'] = (contribution.total_trx\/contribution.total_trx.sum())*100\ncontribution","12cbb578":"sns.displot(data=cust,x='Cluster')","5d991de3":"# Customer Classification","688142d9":"Based on the data, for now we know that our customer are mainly a reseller.","13213b24":"before we remove them, let's make a box plot to make sure are they an extreme outliers","23351a4f":"From \"Customers\" & \"Contribution\" Table, now we can classify our customer based on which cluster they belong. Let's determine what kind of customers is in each cluster.\n\nCluster 0: Low unique product, low spending, not recent trx, low freq, high contribution --> **Seasonal Customer**\n\nCluster 1: Low unique product, low spending, not recent trx, low freq, high contribution --> **Seasonal Customer**\n\nCluster 2: medium unique product, medium spending, recent trx, medium freq, high contribution --> **Loyal Customer**\n\nCluster 3: high unique product, very high spending, recent trx, high freq, low contribution --> **Dropshipper**\n","8cbf6049":"check the number of null value in description","cea01344":"from the table, most of the description also have 0 unit price, we absolutely want to remove this kind of data. let's check if all null description have 0 unit price.","99c64bd9":"From the graph we know that most our customer is from cluster 0 and 1","98f8b75d":"Just based on curiosity, let's check the data that have a large unitprice","9952099c":"I want to know who is our customer really is, based on their purchase behavior. Let's group them so how much our customer for each time purchase.","1177811d":"ok since it looks pretty much all right, now we have a smaller scope and we will focus on this kind of customer ","1688594f":"For clustering, let's group them based on their purchase behavior","da218cc8":"from the graph, we know that overall, we have a good unique user each month. Keep in mind that in december, we only collect data upto December 9th.","c171b2db":"since we want to see the customer\/user, let's drop 'Guest' User","ba0ac605":"As stated in the study case, we have a limited budget. Thus, before rolling out promo, let's narrow our scope to focus more only to our majority of customer. So let's see the outliers and remove them.","b1d9a308":"ok after checking, it looks fine.","92c9b75c":"remove all the rest from UnitPrice that has 0 value, because it's not normal","3a12634a":"# Conclusion\n\nFrom our the insight that we got, we know that:\n1. Most of our customer are reseller\n2. From further classification, we know that our best customers are seasonal customer, and our loyal customer are medium spender reseller\n3. Based on this fact, we want to focus our budget to strengthen our business by targeting those kind of customers.\n\n\n# Proposed Action\n\n**Proposed Idea 1:**\n\n**Idea:** Make a VIP based membership\n\n**Goals:** To reward the customer in cluster 2 with more benefit (discount, free shipping, etc.) so we can keep them, and also become selling point to the customer that outside that cluster\n\n**Proposed Idea 2:**\n \n**Idea:** Rollout seasonal promotion like seasonal discount, bundle offers, etc.\n\n**Goals:** To attract more new customer and to keep the loyal one to keep using our service.\n\n**Proposed Idea 3:**\n\n**Idea:** Make a seasonal personalization like seasonal\/holiday item category, push notification on trending items, etc.\n\n**Goals:** To help our customer navigate through our website, so the chance of converting is much higher.","af8c837e":"next thing i want to do, is looking from some potential odd description by using the descrption length","ed8386ce":"let's also remove the outlier in quantity","0b4f6618":"# DSI Case","211823d2":"remove negative value","1b4fe69a":"# **Data Mining**","16a6b6d1":"Before moving forward, i want to replace null value in customer id to guest, just in case.","2c8a69ef":"check the % of missing value to get a glimpse","3e5fe8d7":"**Objectives:** \n* user acqusition & user retention through new program or offer\n    1. how new user use and get to know ecom\n    2. how to keep new user and old user stay\n\n**Approach:**\n* Data deep dive to know our customer more and then we go from there","56bed167":"To sum up our cluster, let's make another table to see what majority of the cluster looks like.","c5d84780":"ok the item with stockcode POST and B are suspicious to. For the same reason as before, we will remove them too.","92f74630":"Enriching Data:\n\nAdding 'TotalPrice' column","69f3cf9c":"next, let's see from the invoice number","138a558b":"# Timeseries Trend","f37dd237":"# **Cleaning**","c36922ec":"# Insights so far\n\n* We know that majority of our customer were a reseller\n* We have a good amount of unique user each month, with the trend of upward through the end of the year\n\n# Action\n\nFrom the information that we have, in order to reach our goals, we want to roll out promotion. But before that happen, we have to know to whom will we target the promotion. To answer it, first we do clustering to know our customer even more.","1f35576f":"To determine the optimal number of clusters, we have to select the value of k at the \u201celbow\u201d ie the point after which the distortion\/inertia start decreasing in a linear fashion.\n\nIn this case, we select K = 4","779fa41e":"# Customer Segmentation","72e6c0ca":"can be concluded that all null description have 0 unit, so we have to remove them all","68802772":"Let's see what our customer distribution looks like","91cef7ab":"this boxplot indicates that there's still something suspicious going on, so we will check again","ea76a841":"ok there's stil something quite off, the max quantity, let's check it.","0cfcd818":"Data is highly skewed, let's remove the outlier with this formula: mean-stddev <= data <= mean+stddev","a4fbd8a5":"from the large unitprice data, we can see that most of them were DOT, M, and there is this \"AMAZONFEE\" that have super large unitprice","46057237":"Ok now let's filter our main table, only with the data that we already sort before.","bbd71281":"As stated in the study case, we have a limited budget. So before rolling out promo, let's narrow our scope to focus more only to our majority of customer.","04c5b6c1":"next, remove duplicate value","b70480d4":"plot the total user each month","555adf32":"oke everything looks fine","13d3cc96":"For this case purpose, change the year and month so the data we have ranging from January 2020 to December 2020","a4d07c93":"everything looks normal","40cc0ae6":"During the COVID-19 pandemic in 2020, the total sales increase in e-commerce increased by 37% in **Indonesia**. Due to increasingly fierce competition between competitors, you and your Product Manager are in discussion regarding how to stay afloat and compete in the e-commerce industry. After that, you decide to make an innovation or offer so that users will still choose you as their online shopping media.\n\nFor that, you are assigned to perform transaction-related analysis of user data. However, the problem is that the company is doing efficiency in terms of managing promotional funds in 2021. As a data analyst, what insights and recommendations can you give to the company?","8c8c64b9":"# K-means Clustering","a41271ea":"Remove country as we assume all is in Indonesia","3970502f":"As you can see, the box which is majority of the data can't be seen, so removing the extreme outliers can be our option. In real life case, I think the best choice is to verify to the data collection, are they really customer purchase or not. But since we can't do that now, let's assume that these isn't customer purchase (since the stockcode itself is suspicious). Let's remove them.","949cd3f6":"ok this looks fine"}}