{"cell_type":{"98336849":"code","3f425f98":"code","b62b1d33":"code","64217565":"code","491b002f":"code","20619d86":"code","5d68d32b":"code","f855757c":"code","90ccf0be":"code","ec464a0e":"code","99cf930e":"code","3ef6e163":"code","ab535a86":"code","b410cadd":"code","86ff84b4":"code","2ab91b30":"code","6146445a":"code","2b1b015a":"code","5ba83089":"markdown","e43b00d2":"markdown","8eb9f237":"markdown","9ae64fff":"markdown","24f9593d":"markdown","58f86675":"markdown","0a27d352":"markdown","83eb42a9":"markdown","bcb5b300":"markdown","814a24d5":"markdown","4beca101":"markdown","a35bf1f0":"markdown","45603c69":"markdown","294c7d25":"markdown","af7f917d":"markdown","f14ebbd6":"markdown","20a33c2b":"markdown","6623904e":"markdown","c1b66a9c":"markdown","a87d5d4b":"markdown","30acec19":"markdown"},"source":{"98336849":"# do the necessary imports\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nimport glob\nimport os\nfrom PIL import Image\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimage_size = (100,100)\nimage_row_size = image_size[0] * image_size[1]","3f425f98":"class CatDogDataset(Dataset):\n    def __init__(self, path, transform = None):\n        self.classes = os.listdir(path)\n        self.path = [f'{path}\/{classname}' for classname in self.classes]\n        \n        self.file_list = [glob.glob(f'{x}\/*') for x in self.path]\n        self.transform = transform\n        \n        files = []\n        for i, classname in enumerate(self.classes):\n            for filename in self.file_list[i]:\n                files.append([i, classname, filename])\n        self.file_list = files\n        files = None\n        \n    \n    def __len__(self):\n        return len(self.file_list)\n    \n    def __getitem__(self, idx):\n        filename = self.file_list[idx][2]\n        classCategory = self.file_list[idx][0]\n        \n        im = Image.open(filename)\n        if self.transform:\n            im = self.transform(im)\n        return im.view(-1), classCategory\n        ","b62b1d33":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntransform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])","64217565":"train = CatDogDataset('..\/input\/dogs-cats-images\/dataset\/training_set\/', transform)","491b002f":"test = CatDogDataset('..\/input\/dogs-cats-images\/dataset\/test_set\/', transform)","20619d86":"# Visualize the Image from the dataset\n\ndef imshow(source):\n    plt.figure(figsize=(10,10))\n    imt = (source.view(-1, image_size[0], image_size[0]))\n    imt = imt.numpy().transpose([1,2,0])\n    imt = (std * imt + mean).clip(0,1) #clip to remove noise # de-normalize by multiplying with std and mean\n    plt.subplot(1,2,2)\n    plt.imshow(imt)\n","5d68d32b":"shuffle = True\nbatch_size = 64\nnum_workers = 0\ndataloader = DataLoader(dataset = train,\n                       shuffle = shuffle,\n                       batch_size = batch_size,\n                       num_workers = num_workers)","f855757c":"shuffle_test = False\nbatch_size = 64\nnum_workers = 0\ntestloader = DataLoader(dataset = test,\n                       shuffle = shuffle_test,\n                       batch_size = batch_size,\n                       num_workers = 0)","90ccf0be":"class MyModel(nn.Module):\n    def __init__(self, in_feature):\n        super(MyModel, self).__init__()\n        self.fc1 = nn.Linear(in_features = in_feature, out_features= 1024)\n        self.fc2 = nn.Linear(in_features = 1024, out_features = 512)\n        self.fc3 = nn.Linear(in_features = 512, out_features = 256)\n        self.fc4 = nn.Linear(in_features = 256, out_features = 128)\n        self.fc5 = nn.Linear(in_features = 128, out_features = 64)\n        self.fc6 = nn.Linear(in_features = 64, out_features = 32)\n        self.fc7= nn.Linear(in_features = 32, out_features = 2)\n        \n        \n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = F.relu(self.fc5(x))\n        x = F.relu(self.fc6(x))\n        x = self.fc7(x)\n        x = nn.LogSoftmax(dim = 1)(x)\n        return x","ec464a0e":"model = MyModel(image_row_size*3)\nprint(model)","99cf930e":"device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")","3ef6e163":"device","ab535a86":"model.to(device)","b410cadd":"# Hyper-Parameters\n\ncriterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr =0.003)\n\nepochs = 10\n","86ff84b4":"# train the model\ntraininglosses = []\ntestinglosses = []\ntestaccuracy = []\ntotalsteps = []\nepochs = 10\nsteps = 0\nrunning_loss = 0\nprint_every = 5\n\n\nfor epoch in range(epochs):  # epochs loop\n    for ii, (inputs, labels) in enumerate(dataloader):  # batch loop within an epoch\n        \n        # increment the step count\n        steps += 1\n        \n        #Move the input and label tensors to the GPU\n        inputs, labels = inputs.to(device), labels.to(device)  # shifting the inputs & labels to GPU if available\n        \n        optimizer.zero_grad()    # always clear the optimizer from previous step\n        \n        outputs = model.forward(inputs)   # obtain outputs for the inputs\n        loss = criterion(outputs, labels)   # calculate loss\n        loss.backward()                       # calculate gradients\n        optimizer.step()                       # take optimizer step to adjust the weights\n        \n        running_loss += loss.item()\n        \n        if steps % print_every == 0:           # validation\/test score\n            test_loss = 0\n            accuracy = 0\n            model.eval() # IMPORTANT -> SET YOUR MODEL TO EVAL MODE WHEN EVALUATING THE MODEL TO ENSURE THE GRADIENTS ARE NOT CHANGED\n            with torch.no_grad():\n                for inputs, labels in testloader:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    outputs_val = model.forward(inputs)\n                    \n                    loss_val = criterion(outputs_val, labels)\n                    test_loss += loss_val.item()\n                    \n                    # Calculate accuracy\n                    ps = torch.exp(outputs_val)\n                    top_p, top_class = ps.topk(1, dim = 1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n                    \n            traininglosses.append(running_loss\/print_every)  # overall loss for the training averaged by the number of steps to be taken into consideration\n            testinglosses.append(test_loss\/len(testloader))\n            testaccuracy.append(accuracy\/ len(testloader))\n            \n            totalsteps.append(steps)\n            \n            print(f'Device {device}..'\n                 f\"Epoch {epoch+1}\/{epochs}.. \"\n                  f\"Step {steps}.. \"\n                  f\"Train loss: {running_loss\/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss\/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy\/len(testloader):.3f}\")\n            \n            running_loss = 0\n            model.train()  #switch back to train mode\n                    \n            ","2ab91b30":"import matplotlib.pyplot as plt\n\nplt.plot(totalsteps, traininglosses, label = 'Train Loss')\nplt.plot(totalsteps, testinglosses, label = 'Test Loss')\nplt.plot(totalsteps, testaccuracy, label = 'Test Accuracy')\nplt.legend()\nplt.grid()\nplt.show()","6146445a":"checkpoint = {\n    'parameters' : model.parameters, \n    'state_dict' : model.state_dict()\n}","2b1b015a":"torch.save(checkpoint, '.\/catvdog.pth')","5ba83089":"For GPU mode, this should show device type as 'cuda'","e43b00d2":"The process is manual. Your Neural Network would need an iterable Dataset. <br>\nThanks to the PyTorch's DataLoader","8eb9f237":"### Simple Neural Networks \/ Feed Forward Networks in PyTorch","9ae64fff":"### Dataset Description","24f9593d":"So, as of now, you haven't used Dataset class. <br>\nFor images, you'll implement (or a OOPs term -> override) three methods\/functions <br>\n1. __init__() <br>\n2. __len__() <br>\n3. __getitem__() <br>\n","58f86675":"## Task\n<br>\nOur task is to perform classfication of cats and dogs using Simple Neural Networks.","0a27d352":"### Making Neural Network Model","83eb42a9":"In this notebook we'll learn about working with simple neural networks on Cats and Dogs Dataset. <br>\nLink to the previous notebook on Logistic Regression -> https:\/\/www.kaggle.com\/superficiallybot\/getting-started-with-pytorch-series-part-3 <br>","bcb5b300":"### Visualizing the Accuracy, Training Loss & Testing Loss","814a24d5":"### Please UPVOTE if you liked my notebook and add your valuable inputs in the comment section.","4beca101":"Cats and Dogs Dataset. The Dataset is split into test set and training set. <br>\nAbout 4000 images are present in the training set for each of the class. <br>\nAbout 1000 images are present in the test set for eacch of the class. <br>","a35bf1f0":"## DataSet Loading","45603c69":"### Please UPVOTE if you like my efforts and appreciate and support me for contributing more towards Kaggle Community.","294c7d25":"## Getting Started With PyTorch Series - Part 4","af7f917d":"### Instantiate the NN Class","f14ebbd6":"1. Set the device to train on. <br>\n2. shift the model to \"GPU\" if availble <br>\n3. Criterion and optimizer instantiation <br>\n4. Train the model","20a33c2b":"### Save the model parameters and state","6623904e":"### Creating DataLoader\nHelps you iterate over the dataset","c1b66a9c":"### Train Model","a87d5d4b":"We finally achieved a score of about 64 % on Test Data using Simple Neural Networks. That is wonderful. <br>You will observe how the performance boosts when we delve into Convolution Neural Networks.","30acec19":"Switch to \"GPU\" mode if available when training. "}}