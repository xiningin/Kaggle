{"cell_type":{"fcf9b098":"code","1fd28ab7":"code","09faa875":"code","ab4700ea":"code","3d90563b":"code","c3b2c9e1":"code","c0cd11c4":"code","7d7f6906":"code","fb17bef1":"code","9750cdb8":"code","a01a022b":"code","80fbfea8":"code","66d37b06":"code","0d2e1979":"code","addcda51":"code","bbc46c4a":"code","214237c4":"code","c10abe17":"code","46955028":"code","c1dd7776":"code","63b17c0a":"code","95729c18":"code","1b9992d8":"code","65156324":"code","6362c7db":"code","9e3d8853":"code","5a6cfa2e":"code","b55ce511":"code","0d36171c":"markdown","cf590fa9":"markdown","e32ee8ad":"markdown","4ff330b0":"markdown","a307eaa5":"markdown","65310985":"markdown","1902796c":"markdown","798cfef1":"markdown","20352639":"markdown","7c0db496":"markdown"},"source":{"fcf9b098":"import h2o\nfrom h2o.automl import H2OAutoML\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.model_selection import train_test_split","1fd28ab7":"h2o.init()","09faa875":"nltk.download('punkt')","ab4700ea":"df = pd.read_csv('https:\/\/github.com\/srivatsan88\/YouTubeLI\/blob\/master\/dataset\/consumer_compliants.zip?raw=true',compression='zip',sep=',',quotechar='\"')\ndf","3d90563b":"complaints_df = df[['Consumer complaint narrative','Product','Company']].rename(columns={'Consumer complaint narrative':'complaints'})\ncomplaints_df","c3b2c9e1":"target = {'Debt collection':0, 'Credit card or prepaid card':1, 'Mortgage':2, 'Checking or savings account':3, 'Student loan':4, 'Vehicle loan or lease':5}","c0cd11c4":"complaints_df['target'] = complaints_df['Product'].map(target)","7d7f6906":"X_train, X_test = train_test_split(complaints_df,test_size=0.2,random_state=111)","fb17bef1":"#stemmer = PorterStemmer()\nstemmer = nltk.stem.SnowballStemmer('english')","9750cdb8":"nltk.download('stopwords')\nstop_words = set(nltk.corpus.stopwords.words('english'))","a01a022b":"def tokenize(text):\n  tokens = [word for word in nltk.word_tokenize(text) if (len(word)>3 and len(word.strip('Xx\/'))>2 and len(re.sub('\\d+','',word.strip('Xx\/')))>2 )]\n  tokens = map(str.lower, tokens)\n  stems = [stemmer.stem(item) for item in tokens if (item not in stop_words) ]\n  return stems","80fbfea8":" vectorizer_tf = TfidfVectorizer(tokenizer=tokenize,stop_words=None, max_df=0.75, max_features=1000, lowercase=False, ngram_range=(1,2))\n train_vectors = vectorizer_tf.fit_transform(X_train.complaints)","66d37b06":"train_vectors.A","0d2e1979":"print(vectorizer_tf.get_feature_names())","addcda51":"test_vectors = vectorizer_tf.transform(X_test.complaints)","bbc46c4a":"train_df = pd.DataFrame(train_vectors.toarray(),columns=vectorizer_tf.get_feature_names())\ntrain_df = pd.concat([train_df,X_train['target'].reset_index(drop=True)],axis=1)\ntrain_df","214237c4":"test_df = pd.DataFrame(test_vectors.toarray(),columns=vectorizer_tf.get_feature_names())\ntest_df = pd.concat([test_df,X_test['target'].reset_index(drop=True)],axis=1)\ntest_df","c10abe17":"h2o_train_df = h2o.H2OFrame(train_df)\nh2o_test_df = h2o.H2OFrame(test_df)","46955028":"h2o_train_df['target'] = h2o_train_df['target'].asfactor()\nh2o_test_df['target'] = h2o_test_df['target'].asfactor()","c1dd7776":"aml = H2OAutoML(max_models=10,seed=10,exclude_algos=['StackedEnsemble'],verbosity=\"info\",nfolds=0,balance_classes=True,max_after_balance_size=0.3)","63b17c0a":"x = vectorizer_tf.get_feature_names()\ny = 'target'","95729c18":"aml.train(x=x, y=y, training_frame=h2o_train_df, validation_frame=h2o_test_df)","1b9992d8":"aml.leaderboard","65156324":"pred = aml.leader.predict(h2o_test_df)","6362c7db":"aml.leader.model_performance(h2o_test_df)","9e3d8853":"model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\nout = h2o.get_model([mid for mid in model_ids if \"XGBoost\" in mid][0])","5a6cfa2e":"out","b55ce511":"out.convert_H2OXGBoostParams_2_XGBoostParams()","0d36171c":"Convert the data frame object to h20 object","cf590fa9":"In this demo we will use Text classification","e32ee8ad":"For classification problem target has to be an enumeration. If it is an integer then it will treat it as regression problem","4ff330b0":"H20 Runs on java","a307eaa5":"Parameters used by h2o","65310985":"**H2o AutoML**","1902796c":"Custom tokenization function","798cfef1":"For tfidf we want huge vector size to handle it. We can use Dense Vectorizations like word2vec(it understands semmantics of word also)","20352639":"Due to imalance datasets some classes has more error","7c0db496":"Initialize the H2o object"}}