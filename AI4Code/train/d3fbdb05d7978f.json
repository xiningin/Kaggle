{"cell_type":{"982bd123":"code","86391bfd":"code","9dfd0060":"code","6c335ab7":"code","1d2d3c8d":"code","1152a64b":"code","072f3b45":"code","a50a53b3":"code","8a16ea0f":"code","30fbfc6a":"code","7bfe748a":"code","65c9ac65":"code","932e1c35":"code","bf85d925":"code","895921d3":"code","0b91313c":"code","43c32f81":"code","9a9fb69d":"code","cebeeef2":"code","ed329dfe":"code","5cab667c":"code","9dd7cd4c":"code","437b1f49":"code","a493864b":"code","4c575ff5":"code","2a503861":"code","55d918d7":"markdown","8a2183c6":"markdown","de751c18":"markdown","191cb723":"markdown","aac4b3d5":"markdown","5c185a59":"markdown","222bf455":"markdown","11a30f8e":"markdown","31c4b565":"markdown","aa60d09d":"markdown","2763d493":"markdown","9e62171a":"markdown","f9b63e91":"markdown","133b4a13":"markdown","c0353522":"markdown","81a77fce":"markdown","c227b102":"markdown","d628c462":"markdown","7f64adfd":"markdown"},"source":{"982bd123":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Machine Learning\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.impute import SimpleImputer\n# from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","86391bfd":"# Read the data to a pandas data frame\nX_train = pd.read_csv('..\/input\/train.csv', index_col='PassengerId')\nX_test = pd.read_csv('..\/input\/test.csv', index_col='PassengerId')\nprint(\"Data loaded:\", X_train.shape, X_test.shape)","9dfd0060":"# A glimpse on a few rows.\nX_train.head()\n#X_test.head()","6c335ab7":"# Column names, types and amount of Nulls\n#X_train.info()\nX_test.info()","1d2d3c8d":"# Summary of numerical features\nX_train.describe()\n#X_test.describe()","1152a64b":"# Summary of non numerical features\n#X_train.describe(include=['O'])\nX_test.describe(include=['O'])","072f3b45":"#X_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#X_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#X_train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\nX_train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","a50a53b3":"#g = sns.FacetGrid(X_train, col='Pclass', row='Embarked')\n#g = sns.FacetGrid(X_train, col='Survived', row='Pclass')\ng = sns.FacetGrid(X_train, col='Survived', row='Embarked')\n#g = sns.FacetGrid(X_train, col='Sex', row='Embarked')\n#g = sns.FacetGrid(X_train, col='Pclass', row='Embarked')\n#g = sns.FacetGrid(X_train, col='Survived', row='Parch')\n#g = sns.FacetGrid(X_train, col='Survived', row='SibSp')\n\ng.map(plt.hist, 'Fare', bins=20)\n#g.map(plt.hist, 'Pclass')","8a16ea0f":"#ax1 = X_train.plot.scatter(x=\"Age\", y=\"Fare\", c=\"Survived\", colormap=\"viridis\")\n#ax1 = X_train.plot.scatter(x=\"Age\", y=\"Pclass\", c=\"Survived\", colormap=\"viridis\")\nax1 = X_train.plot.scatter(x=\"Age\", y=\"SibSp\", c=\"Survived\", colormap=\"viridis\")","30fbfc6a":"X_train['Sex'] = X_train['Sex'].map({'female':1, 'male':0}).astype(int)\nX_test['Sex'] = X_test['Sex'].map({'female':1, 'male':0}).astype(int)\n\nX_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()","7bfe748a":"X_train[X_train.Embarked.isnull()]","65c9ac65":"X_train[(X_train.Survived > 0) & (X_train.Sex > 0) & (X_train.Pclass < 2) & (X_train.SibSp < 1) & (X_train.Parch < 1) & (X_train.Fare > 50)]","932e1c35":"# Determining the most frequent port\nfreq_port = X_train.Embarked.dropna().mode()[0]\nfreq_port","bf85d925":"# Filling the empty values\nX_train['Embarked'] = X_train['Embarked'].fillna(freq_port)\nX_test['Embarked'] = X_test['Embarked'].fillna(freq_port) #no empty value","895921d3":"# Converting categorical to numerical\nX_train['Embarked'] = X_train['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype(int)\nX_test['Embarked'] = X_test['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype(int)","0b91313c":"X_train = X_train.drop(['Ticket', 'Cabin'], axis=1)\nX_test = X_test.drop(['Ticket', 'Cabin'], axis=1)\n\nprint(\"Features dropped: \", X_train.shape, X_test.shape)","43c32f81":"#pd.crosstab(X_train.Name.str.extract(' ([A-Za-z]+)\\.', expand=False), X_train['Survived'])\n#pd.crosstab(X_train.Name.str.extract(' ([A-Za-z]+)\\.', expand=False), X_train['Sex'])\npd.crosstab(X_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False), X_test['Sex'])","9a9fb69d":"#Create a new feature called Title\nX_train['Title'] = X_train.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\nX_test['Title'] = X_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n#Replace the Title with a more common name\nX_train['Title'] = X_train['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\nX_test['Title'] = X_test['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\nX_train['Title'] = X_train['Title'].replace(['Mlle'], 'Miss')\nX_train['Title'] = X_train['Title'].replace(['Ms'], 'Miss')\nX_train['Title'] = X_train['Title'].replace(['Mme'], 'Mrs')\nX_test['Title'] = X_test['Title'].replace(['Mlle'], 'Miss')\nX_test['Title'] = X_test['Title'].replace(['Ms'], 'Miss')\nX_test['Title'] = X_test['Title'].replace(['Mme'], 'Mrs')\n\n# Survival rate per title\nX_train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","cebeeef2":"# Mapping the titles and replacing\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nX_train['Title'] = X_train['Title'].map(title_mapping)\nX_train['Title'] = X_train['Title'].fillna(0)\nX_test['Title'] = X_test['Title'].map(title_mapping)\nX_test['Title'] = X_test['Title'].fillna(0)\n\n# Survival rate per title\nX_train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","ed329dfe":"X_train = X_train.drop(['Name'], axis=1)\nX_test = X_test.drop(['Name'], axis=1)\n\nprint(\"Features dropped: \", X_train.shape, X_test.shape)\nprint(\"New columns:\\nX_train: \", X_train.columns, \"\\nX_test:\", X_test.columns)","5cab667c":"# Create an empty array\nguess_ages = np.zeros((2,3))\n\nfor i in range(0, 2):\n    for j in range(0, 3):\n        guess_df = X_train[(X_train['Sex'] == i) & \\\n                            (X_train['Pclass'] == j+1)]['Age'].dropna()\n        age_guess = guess_df.median()\n\n        # Convert random age float to nearest .5 age\n        guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \nfor i in range(0, 2):\n    for j in range(0, 3):\n        X_train.loc[ (X_train.Age.isnull()) & (X_train.Sex == i) & (X_train.Pclass == j+1),\\\n                'Age'] = guess_ages[i,j]\n\nX_train['Age'] = X_train['Age'].astype(int)\n\nfor i in range(0, 2):\n    for j in range(0, 3):\n        guess_df = X_test[(X_test['Sex'] == i) & \\\n                            (X_test['Pclass'] == j+1)]['Age'].dropna()\n        age_guess = guess_df.median()\n\n        # Convert random age float to nearest .5 age\n        guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \nfor i in range(0, 2):\n    for j in range(0, 3):\n        X_test.loc[ (X_test.Age.isnull()) & (X_test.Sex == i) & (X_test.Pclass == j+1),\\\n                'Age'] = guess_ages[i,j]\n\nX_test['Age'] = X_test['Age'].astype(int)\n\n# Check amount of nulls in each df.\nX_train.info()\nprint('-'*20)\nX_test.info()","9dd7cd4c":"X_train['Fare'].fillna(X_train['Fare'].dropna().median(), inplace=True)\nX_train.info()","437b1f49":"# Separate target from predictors\ny_train = X_train.Survived              \nX_train = X_train.drop(['Survived'], axis=1)\nprint(\"Survival separated:\", X_train.shape, X_test.shape, y_train.shape)","a493864b":"# Select categorical columns with relatively low cardinality\nlow_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and \n                        X_train[cname].dtype == \"object\"]\n\n# Select numeric columns\nnumeric_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\nX_train = X_train[my_cols].copy()\nX_test = X_test[my_cols].copy()\n\n# One-hot encode the data with pandas\nX_train = pd.get_dummies(X_train)\nX_test = pd.get_dummies(X_test)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)\nX_train.shape, X_test.shape, y_train.shape","4c575ff5":"def get_score(n_estimators):\n    my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()), #the imputer is obsolete if you ran all the data wrangling code\n                                    ('model', XGBRegressor(n_estimators=n_estimators,\n                                                              learning_rate=0.39\n                                                          ))\n                             ])\n    scores = -1 * cross_val_score(my_pipeline, X_train, y_train,\n                                  cv=10,\n                                  scoring='neg_mean_absolute_error')\n    return scores.mean()\n\nresults = {}\nfor i in range(40,55):\n    results[i*1] = get_score(i*1)\n\nplt.plot(results.keys(), results.values())\nplt.show()\n\nn_estimators_best = min(results, key=results.get)\nprint(get_score(n_estimators_best), \"from:\", n_estimators_best)","2a503861":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()), #the imputer is obsolete if you ran all the data wrangling code\n                              ('model', XGBRegressor(n_estimators=48,\n                                                              learning_rate=0.39))\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X_train, y_train)\n\n# Preprocessing of test data, fit model\npreds_test = my_pipeline.predict(X_test)\n\n# Save test predictions to file\noutput = pd.DataFrame({'PassengerId': X_test.index,\n                       'Survived': preds_test.round(decimals=0, out=None).astype(int)})\noutput.to_csv('submission.csv', index=False)","55d918d7":"Converting categorical Title to ordinal.","8a2183c6":"## Data Visualization\nHistograms showing the survival distribution per non categorical feature.","de751c18":"### Embarked\nFor the Embarked feature we idenfy that the train dataset has 2 missing values. Here we will fit it with the most frequent value.","191cb723":"Now we can drop the Name feature:","aac4b3d5":"## Data Wrangling\nAs a first step let's transform the easily identifiable categorical features in numerical: Sex and Embarked.","5c185a59":"We can also plot the numerical features agains each other to find how they relate.","222bf455":"Separating the feature we want to predict from the train set.","11a30f8e":"### Name -> Title\nWorking on the Name feature we will test correlations between the title and the survival rate.","31c4b565":"Removing the high cardinality features and one-hot encoding the low cardinality ones. *This part of the code is obsolete if you run all the data wrangling code.*","aa60d09d":"Now that the this feature has no empty values let's map it from categorical to numerical.","2763d493":"### Ticket and Cabin\nWe will drop the Ticket and Cabin features due to it's high cardinality and little relation to the survival rate.","9e62171a":"### Fare\nFilling the empty value in the test dataset","f9b63e91":"### Age\nCompleting the numerical continuous feature based on Pclass and Gender features","133b4a13":"Based of the fact that similar entries embarked in both 'S' and 'C' ports, we will choose the most frequent.","c0353522":"Pivoting the categorical data against survival rate.","81a77fce":"### Sex categorical to numerical\nWe will start by the Sex feature. Female will be 1 and male will be 0.","c227b102":"## Data Exploration\nFirst let's have a look at what we have in our datasets.","d628c462":"## Modeling\nBuilding the function that will test the best parameters in a pipeline that will input the empty values and apply the model. Using cross validation, ploting the results and choosing the best parameters.","7f64adfd":"## Predicting\nFitting the model with the best parameters and preparing the submission csv"}}