{"cell_type":{"0f6129a9":"code","448fdd47":"code","027b3596":"code","47668df9":"code","ba752910":"code","e519ea7e":"code","2ce21c9f":"code","921c0983":"code","f2fe824b":"code","b84e4898":"code","7ea8efca":"code","d6510378":"code","8e650d88":"code","ad5e91ba":"code","dd85f0e4":"code","b8b7b0d6":"code","aa7e8ec9":"code","3345d689":"code","1483b457":"markdown","4a113bf9":"markdown","78413a23":"markdown"},"source":{"0f6129a9":"import os\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.applications import Xception, VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers, regularizers\nfrom keras.layers import Dropout\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nimport shutil\nimport random","448fdd47":"os.chdir('\/kaggle\/input\/chest-xray-pneumonia')","027b3596":"PATH = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/'","47668df9":"train_dir = os.path.join(PATH, 'train')\nval_dir = os.path.join(PATH, 'val')\ntest_dir = os.path.join(PATH, 'test')","ba752910":"train_p = 0\ntrain_n = 0\nval_p = 0\nval_n = 0\ntest_p = 0\ntest_n = 0\n\n# train directory\nfor folder in os.listdir(train_dir):\n    if folder == \"PNEUMONIA\":\n        for image_file in os.listdir(train_dir + os.sep + folder):\n            train_p += 1\n    elif folder == \"NORMAL\":\n        for image_file in os.listdir(train_dir + os.sep + folder):\n            train_n += 1\n            \n# test directory\nfor folder in os.listdir(test_dir):\n    if folder == \"PNEUMONIA\":\n        for image_file in os.listdir(test_dir + os.sep + folder):\n            \n            test_p += 1\n    elif folder == \"NORMAL\":\n        for image_file in os.listdir(test_dir + os.sep + folder):\n            test_n += 1\n            \n# validation directory\nfor folder in os.listdir(val_dir):\n    if folder == \"PNEUMONIA\":\n        for image_file in os.listdir(val_dir + os.sep + folder):\n            val_p += 1\n    elif folder == \"NORMAL\":\n        for image_file in os.listdir(val_dir + os.sep + folder):\n            val_n += 1\n            \n","e519ea7e":"# plot the distributions\ndata = [[train_p, test_p],\n[train_n, test_n]]\nX = np.arange(2)\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\nax.bar(X + 0.25, data[1], color = 'r', width = 0.25)\n\nplt.show()\n\n","2ce21c9f":"# display some xray screens\nfig, ax = plt.subplots(2,3, figsize=(15,7))\nax = ax.ravel()\nplt.tight_layout()\nfor i, _set in enumerate(['train','test','val']):\n    set_path = PATH +_set\n    ax[i].axis('off')\n    ax[i].imshow(plt.imread(set_path+'\/NORMAL\/'+os.listdir(set_path+'\/NORMAL')[0]))\n    ax[i].set_title('File: {} - Condition: Healthy'.format(_set))\n    ax[i+3].axis('off')\n    ax[i+3].imshow(plt.imread(set_path+'\/PNEUMONIA\/'+os.listdir(set_path+'\/PNEUMONIA')[0]))\n    ax[i+3].set_title('File: {} - Condition: Infected'.format(_set))","921c0983":"# data augmentation helps prevent overfitting with small dataset\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255) # do not augment the test data\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# generates the training images from the folder they are stored\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224,224),\n    batch_size=20,\n    class_mode='binary',\n    shuffle=True\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(224,224),\n    batch_size=20,\n    class_mode='binary'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(224,224),\n    batch_size=20,\n    class_mode='binary'\n)\n","f2fe824b":"conv_base = Xception(weights='imagenet',\n                 include_top = False,\n                 input_shape=(224,224,3)\n                 )","b84e4898":"model = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(Dropout(0.3))\nmodel.add(layers.Dense(256,kernel_regularizer=regularizers.l1(1e-4), activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.summary()","7ea8efca":"# need to freeze the base for initial training\nprint(\"number of trainable weights before freezing convolutional base\", len(model.trainable_weights))\nconv_base.trainable = False\nprint(\"number of trainabe weights after freezing convolutional base\", len(model.trainable_weights))","d6510378":"early_stop = EarlyStopping(monitor = 'val_loss', patience = 3)","8e650d88":"model.compile(loss='binary_crossentropy',\n             optimizer=optimizers.Adam(lr=1e-5),\n             metrics=['accuracy'])\n\nhistory = model.fit(\n    train_generator,\n    epochs = 60,\n    validation_data=test_generator,\n    callbacks=[early_stop],\n    verbose=0\n)\n","ad5e91ba":"history.history.keys()","dd85f0e4":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, label='Training acc', color='blue')\nplt.plot(epochs, val_acc, label=\"Validation acc\", color='red')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, label='Training loss', color='blue')\nplt.plot(epochs, val_loss, label=\"Validation loss\", color='red')\nplt.title('Training and validation loss')\nplt.legend()\n\n\nplt.show()","b8b7b0d6":"print(\"Maximum Validation Accuracy\",max(val_acc))","aa7e8ec9":"test_loss, test_acc = model.evaluate(val_generator, steps=50)\nprint('test acc', test_acc)","3345d689":"model.save('\/kaggle\/working\/model_1.h5')","1483b457":"Here we are going to get the class distribution for each subset of the data","4a113bf9":"Below we are attempting to build a model that accurately classifies an x-ray scan as positive for pneumonia or one wthat is not. Below I implement a convolutional neural network that built using transfer learning with the Xception model that was trained with the imagenet dataset. For the first portion of the model training I froze the convolutional base (Xception base) and trained a new densely connected classifer on top of it. This transfer learning technique is useful for situations like this one where the dataset is as small as it is. The convolutional base is the part of the model that extracts features from images and generally speaking the features that are found, especially in the bottom convolutional layers, are simple features such as edges, corners, and things that can be easily generlized to different types of input images. The last few convolutional layers are the ones that learn the more complicated features that tend to be task specific. In order to fine tune the model after the initial training, I then unfreeze the final block of the convolutional base (block14) and compile the already one time trained model again with an extremely low learning rate. The idea behind this fine tuning step is to maintain the already learned features present in the convolutional base learned from the imagenet dataset but manipulate and change the last convolutional layer feature mapping to better fit our task which is to find pneumonia in x-ray images. The fine tuning exded up leading to over fitting of the training data so in the final implmentation I left this part out.","78413a23":"Below we can see the training dataset on the left and the validation dataset on the right with the blue representing the x-ray images positive for pneumonia and the red representing the normal x-ray images."}}