{"cell_type":{"b5a01d64":"code","7ea1fedf":"code","bad55483":"code","84668e54":"code","1c19469c":"code","1094e746":"code","16caae21":"code","1316ed4c":"code","559a7bd0":"code","254ae6d3":"code","9f1ebd3c":"code","92a0a7e7":"markdown","844d2f32":"markdown"},"source":{"b5a01d64":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ea1fedf":"import matplotlib.pyplot as plt \nimport seaborn as sns \nimport time \nimport os \nimport gc \nfrom tqdm import tqdm \nfrom statistics import mean \n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nimport torch \nimport torch.nn as nn \nfrom torch.utils.data import Dataset, DataLoader ","bad55483":"event_type = {\n    0: \"cart\", \n    1: \"view\",\n    2: \"click\",\n    3: \"conversion\"\n}\n\n\nconfig = dict(\n    competition = \"opt-recommend\",\n    train = True, \n    model_name = \"nn\",\n    \n    epoch = 100, \n    batch_size = 1560, \n    seed = 42, \n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\", \n    lr = 0.01,\n    debug = True,\n    n_fold = 4 \n)\n\nparams = {\n    \"embeddings\": 2 if config[\"debug\"] else 64\n}\n","84668e54":"%%time\n\ndf = pd.read_csv(\"..\/input\/opt-recommendation-engine\/train (1)\/train\/train_A.tsv\", nrows=300_000, sep=\"\\t\", usecols=[\"user_id\", \"product_id\", \"event_type\"])\n\ndf[\"event\"] = df[\"event_type\"].apply(lambda x: event_type[int(x)])\ndf.drop(\"event_type\", axis=1, inplace=True)\ndf = pd.crosstab([df.user_id, df.product_id], df.event)\ndf[\"recommend\"] = df.cart * 0.75 + df.click * 0.5 + df.view * 0.25 + df.conversion * 1.0\ndf.drop([\"cart\", \"click\", \"conversion\", \"view\"], axis=1, inplace=True)\ndf[\"user_id\"] = [c for c, _ in df.index]\ndf[\"product_id\"] = [c for _, c in df.index]\ndf.reset_index(drop=True, inplace=True)\ndf.index.name = \"id\"\ndf = df[[\"user_id\", \"product_id\", \"recommend\"]]\ndf.head()","1c19469c":"recommend = df.recommend.value_counts()\nsns.histplot(recommend.values, bins=100)\nplt.xticks(np.arange(0, 100, 1))\nplt.show()","1094e746":"popular = df.groupby(\"product_id\").mean().sort_values(\"recommend\", ascending=False)[:10]\npopular.plot(kind=\"barh\", cmap=\"jet\") \nplt.title(\"most popular product_id TOP 10\")\nplt.show()","16caae21":"class RecommendEncoder:\n    def __init__(self, ser: pd.Series):\n        self.word2index = {}\n        self.index2word = {}\n        self.ser = ser \n        self.vocab_len = len(self.word2index)\n        \n        self._get_vocab()\n        \n    def _get_vocab(self):\n        for user in self.ser.to_list():\n            if user not in self.word2index:\n                self.word2index[user] = len(self.word2index)\n            else:\n                continue \n        self.index2word = {v: k for k, v in self.word2index.items()}\n        assert len(self.word2index) == len(self.index2word)\n        \n    def fit_transform(self, x: str):\n        return self.word2index[x]\n    \n    def inverse_transform(self, x: int):\n        return self.index2word[x]\n    \n\nuser_vocab = RecommendEncoder(df[\"user_id\"])\nproduct_vocab = RecommendEncoder(df[\"product_id\"])","1316ed4c":"class RecommendDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.user_vocab = user_vocab\n        self.product_vocab = product_vocab\n        \n    def __getitem__(self, idx):\n        df = self.df.iloc[idx]\n        user = self.user_vocab.fit_transform(df[\"user_id\"])\n        user = torch.tensor([user], dtype=torch.long)\n        product = self.product_vocab.fit_transform(df[\"product_id\"])\n        product = torch.tensor([product], dtype=torch.long)\n        label = torch.tensor(df[\"recommend\"], dtype=torch.float)\n        return user, product, label \n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    \nclass RecommendModel(nn.Module):\n    def __init__(self, vocab_user=user_vocab.vocab_len, vocab_prd=product_vocab.vocab_len, embedding_dim=params[\"embeddings\"]):\n        super(RecommendModel, self).__init__()\n        self.emb_user = nn.Embedding(vocab_user, embedding_dim)\n        self.emb_product = nn.Embedding(vocab_prd, embedding_dim)\n        self.fc = nn.Sequential(\n            nn.Linear(embedding_dim*2, embedding_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.1),\n            nn.Linear(embedding_dim, 1)\n        )\n        \n    def forward(self, u, p):\n        u = self.emb_user(u)[:, 0, :]\n        p = self.emb_product(p)[:, 0, :]\n        out = torch.cat((u, p), -1)\n        out = self.fc(out)\n        return out \n    ","559a7bd0":"class Trainer:\n    def __init__(self, df):\n        self.user_vocab = user_vocab\n        self.product_vocab = product_vocab \n        self.model = RecommendModel()\n        \n        self.main(df.copy())\n\n    def mae(self, pred, corr):\n        return np.mean(np.abs(pred - corr))\n\n    def save_model(self, model, fold):\n        os.makedirs(\"models\", exist_ok=True)\n        torch.save(model.state_dict(), f\"models\/{str(fold+1)}.pth\")\n\n    def train_fn(self, dl, model, criterion, optimizer, is_train=True):\n        if is_train:\n            model.train()\n        else:\n            model.eval()\n\n        total_loss = []\n        for u, p, l in tqdm(dl):\n            u = u.to(config[\"device\"])\n            p = p.to(config[\"device\"])        \n            l = l.to(config[\"device\"])        \n\n            if is_train:\n                y = model(u, p)\n                loss = criterion(y.view(-1), l)\n                optimizer.zero_grad()\n                optimizer.step()\n            else:\n                with torch.no_grad():\n                    y = model(u, p)\n                    loss = criterion(y.view(-1), l)\n\n            total_loss.append(loss.item())\n        return np.mean(np.array(total_loss))\n\n    def fit(self, train_dl, val_dl, fold):\n        model = self.model \n        criterion = nn.L1Loss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n\n        best_model, best_loss = None, np.inf \n\n        for e in range(1 if config[\"debug\"] else config[\"epoch\"]):\n            ts = time.time()\n            tr_loss = self.train_fn(train_dl, model, criterion, optimizer)\n            va_loss = self.train_fn(val_dl, model, criterion, optimizer, False)\n\n            if best_loss > va_loss:\n                best_model = model \n                best_loss = va_loss \n            now = time.time()\n            print(f\"fold: {fold+1} | epoch: {e+1} | tr loss: {tr_loss:.2f} | va loss: {va_loss:.3f} | dilation: {now-ts}s\")\n            \n        torch.cuda.empty_cache()\n        gc.collect()\n        return best_model \n    \n    def predict(self, val_dl, model):\n        model.eval()\n        pred = []\n        for u, p, l in tqdm(val_dl):\n            u = u.to(config[\"device\"])\n            p = p.to(config[\"device\"])        \n            l = l.to(config[\"device\"])        \n            \n            y = model(u, p)\n            y = y.view(-1).detach().cpu().numpy().tolist()\n            \n            for yy in y:\n                pred.append(yy)\n            del u, p, l \n        return pred \n\n\n    def main(self, train):\n        predict_val, val_idx = [], []\n        train[\"rank\"] = pd.cut(train[\"recommend\"], bins=10, labels=False)\n        \n        kf = StratifiedKFold(n_splits=2 if config[\"debug\"] else config[\"n_fold\"], random_state=config[\"seed\"], shuffle=True)\n        for fold, (tr, va) in enumerate(kf.split(train, train[\"rank\"])):\n            print(f\"================================fold: {fold+1}=========================================\")\n            train_ds = RecommendDataset(train.iloc[tr])\n            val_ds = RecommendDataset(train.iloc[va])\n            \n            train_dl = DataLoader(train_ds, \n                                 batch_size=config[\"batch_size\"], \n                                 shuffle=True, drop_last=True, \n                                 num_workers=3, pin_memory=True)\n            \n            val_dl = DataLoader(val_ds, \n                                 batch_size=config[\"batch_size\"], \n                                 shuffle=False, drop_last=False, \n                                 num_workers=3, pin_memory=True)\n            \n            model = self.fit(train_dl, val_dl, fold)\n            self.save_model(model, fold)\n            \n            pred = self.predict(val_dl, model)\n            predict_val.append(pred)\n            val_idx.append(va)\n            gc.collect()\n        predict_val = np.concatenate(predict_val, 0)\n        val_idx = np.concatenate(val_idx, 0)\n        val_idx = np.argsort(val_idx)\n        predict_val = predict_val[val_idx]\n        \n        print(\"\\n\")\n        print(\"##############################################################################################\")\n        print(f\"CV SCORE: {self.mae(predict_val, train['recommend'].values.ravel())}\")\n        print(\"##############################################################################################\")\n        print(\"\\n\")\n        ","254ae6d3":"class Recommendation(object):\n    \"\"\"\n    \u7279\u5b9a\u306e\u30e6\u30fc\u30b6\u30fc\u3092\u6307\u5b9a\u3059\u308b\u3002\n    \u57cb\u3081\u8fbc\u307f\u7a7a\u9593\u3067\u8868\u73fe\u3055\u308c\u305f\u30d9\u30af\u30c8\u30eb\u3092\u30d9\u30fc\u30b9\u3068\u3057\u3066\u985e\u4f3c\u5ea6\u3092\u7b97\u51fa\u3059\u308b(\u5354\u8abf\u6027)\n    \n    \u4e0a\u4f4d\uff12\uff10\u540d\u304b\u3089\u306e\u63a8\u85a6\u5546\u54c1\u3092\u30b3\u30b5\u30a4\u30f3\u3068\u7d44\u307f\u5408\u308f\u305b\u3066\u6700\u3082\u8a55\u4fa1\u5024\u306e\u9ad8\u3044\u5546\u54c1\u3092\uff12\uff12\u500b\u8fd4\u3059\u3002\n    \"\"\"\n    def __init__(self, user_id: str, df=df):\n        self.user_id = user_id \n        self.user_vocab = user_vocab\n        self.model = RecommendModel()\n        self.model_path = os.listdir(\"models\/\") \n        self.user2vector = []\n        self.df = df \n        self.result = None \n        \n        self.inference()\n        self.main()\n        \n    def load_model(self, fold):\n        if config[\"debug\"]:\n            model = RecommendModel()\n            model = model.emb_user \n            model.eval()\n        else:\n            model = self.model.load_state_dict(torch.load(self.model_path[fold], map_location={\"cuda:0\": \"cpu\"}))\n            model = model.emb_user \n            model.eval()\n        return model.to(config[\"device\"])\n        \n    def inference(self):\n        with torch.no_grad():\n            for fold in range(2 if config[\"debug\"] else config[\"n_fold\"]):\n                model = self.load_model(fold)\n                pred = []\n                for _, user in self.user_vocab.word2index.items():\n                    user_tensor = torch.tensor([user], dtype=torch.long)\n\n                    y = model(user_tensor)\n                    y = y.view(-1).detach().cpu().numpy()\n                    pred.append(y)\n                self.user2vector.append(np.array(pred))\n        self.user2vector = np.mean(self.user2vector, 0)\n        \n    def find_similar_user(self):\n        current_user = self.user_vocab.word2index[self.user_id]\n        current_user_vector = self.user2vector[current_user]\n        \n        similar_user_list, similar_list = [], []\n        for i, v in enumerate(self.user2vector):\n            if i == current_user:\n                continue \n            cos = cosine_similarity(v.reshape(1, -1), current_user_vector.reshape(1, -1))[0][0]\n            similar_user_list.append(self.user_vocab.index2word[i])\n            similar_list.append(cos)\n            \n        dfs = pd.DataFrame({\"similar_user\": similar_user_list, \"similar\": similar_list}).sort_values(\"similar\", ascending=False)[:20]\n        dfs[\"current_user\"] = self.user_id \n        return dfs \n        \n    def main(self) -> pd.DataFrame:\n        similar_df = self.find_similar_user()\n        \n        for i, (user, cosine) in enumerate(zip(similar_df[\"similar_user\"].to_list(), similar_df[\"similar\"].to_list())):\n            x = self.df[self.df[\"user_id\"] == user].sort_values(\"recommend\", ascending=False)[:22]\n            x = x[[\"product_id\", \"recommend\"]]\n            x[\"recommend\"] = x[\"recommend\"] * cosine \n            \n            if i == 0:\n                result_df = x \n            else:\n                result_df = pd.concat([result_df, x])\n                \n        result_df = result_df.groupby(\"product_id\").mean().sort_values(\"recommend\", ascending=False)[:22]\n        result_df[\"recommend\"] = [c for c in range(22)]\n        self.result = result_df \n        gc.collect()","9f1ebd3c":"if __name__ == \"__main__\":\n    if config[\"train\"]:\n        Trainer(df)\n    result = Recommendation(\"0000000_A\")\n    display(result.result)","92a0a7e7":"# Create Model","844d2f32":"# Recommendation System "}}