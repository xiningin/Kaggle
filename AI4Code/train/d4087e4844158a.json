{"cell_type":{"7eecc0db":"code","20953e9c":"code","2cff4927":"code","010adbf9":"code","60ebad3b":"code","60828c78":"code","b531c86a":"code","9485762d":"code","a2126113":"code","51b62c04":"code","417d2392":"code","6dae3c57":"code","1c134c76":"code","da00908f":"code","acee945f":"code","d48e5af6":"code","98328fdb":"code","ea07a9f1":"code","52aa1551":"code","ce94008a":"code","144c376d":"code","9cbf230b":"code","808b9c1f":"code","d003a6fb":"code","1d24a981":"code","e54722b7":"code","9e3c0f18":"code","ad43ee02":"code","99cdcb5c":"code","c65f44ec":"code","88c1b448":"code","b89b6d83":"code","c5d83fd5":"code","9f5cc5f8":"code","73257f2a":"code","86f314bd":"code","54aa10a7":"code","d00f0b1f":"code","2d337a59":"code","c340e7c9":"code","d34400fb":"code","3b08a07f":"code","50e53810":"code","0c5207ce":"code","557ce9c4":"code","54bec1f3":"code","421fa4d9":"code","cca587ba":"code","99e21ff3":"code","e4d4dc16":"code","8a7bf2de":"code","6c4fcd76":"code","3a7bfd57":"code","9fef770c":"code","1a30243c":"code","b7c88515":"code","58853460":"code","8c964ee6":"code","81a09f0d":"code","23beeeb5":"code","e1465219":"code","39763221":"code","25f22ddf":"code","a6f1dfb6":"code","2db4e4bc":"code","ab032bff":"code","fb9ac21d":"code","3bb5b98b":"code","5f5cab93":"code","e531f34f":"code","39215728":"code","11c72fa7":"code","e2342c85":"code","c97c4628":"code","ac038cce":"code","7d57857d":"code","ba16ee05":"code","ebf233d8":"code","c3ee4239":"code","f40e0b4c":"code","2b691dad":"code","c65b81b7":"code","4a7a6adf":"code","4b1d006d":"code","d3498dd2":"code","83b80dc0":"code","e3991283":"code","c70ddbf5":"code","9f765519":"code","96323adc":"code","dc908508":"code","e390f9b9":"code","a19e8608":"code","6de237f4":"code","783753d1":"code","6ef98236":"code","603dea77":"code","04953f53":"code","f2448a90":"code","371a7261":"code","2747fc38":"code","6fbdfb1a":"code","93d7d29e":"code","458ba01d":"code","54d283df":"code","6c55d6ef":"code","f0457093":"code","74f12897":"code","1175c1dc":"code","46bf3474":"code","36cec967":"code","a3c88173":"code","14059580":"code","9bdb9b6d":"code","d4579993":"code","fbe11188":"code","4f7e8e6b":"code","067bfa88":"code","52ab4404":"code","6126854f":"code","1811e009":"code","f8219ae9":"code","8d94a7d3":"code","398fcd50":"code","b493fbdc":"code","cb5261fe":"code","d04f720e":"code","b9dc246f":"code","a9a0e6dc":"code","59113538":"code","eabd40d0":"code","ad7c36ce":"code","2a11b717":"code","7f99dcfe":"code","22d3d7b3":"code","7634bafb":"code","ec4b5aab":"code","32baa683":"code","b6994cca":"code","501fbfce":"code","a348a9e7":"code","4950a4dc":"code","dc9fea4e":"code","124f94ea":"code","d0d66e3e":"code","c4abdddd":"code","d24ba2e5":"code","06d71e01":"code","637778c3":"code","985faefc":"code","15c1b821":"code","36ae977c":"code","d91a3ebc":"code","84e6f55a":"code","db49c4c8":"code","de107fc5":"markdown","950aee3f":"markdown","529c9193":"markdown","28827bea":"markdown","c5b4759a":"markdown","1493f74c":"markdown","0288b423":"markdown","4e8a5f2b":"markdown","853547e1":"markdown","c2771d2b":"markdown","71fdacc5":"markdown","5b72deca":"markdown","5e6cadba":"markdown","7b07a079":"markdown","a2bb0da9":"markdown","e98fd4f1":"markdown","3e3a1d1c":"markdown","bce5e8a3":"markdown","3ea8e892":"markdown","0b4df9c6":"markdown","6bf33dce":"markdown","d2a8ff9f":"markdown","01f65434":"markdown","68cb0f25":"markdown","4678dd5d":"markdown","0ea5fa9d":"markdown","b2ba430c":"markdown","c268b4ef":"markdown","12c9e200":"markdown","d3f956c9":"markdown","d0f6a9c8":"markdown","0436719d":"markdown","aca237cd":"markdown","c1d63b2a":"markdown","65d149a5":"markdown","c74ecef0":"markdown","b40e4ce2":"markdown","8f4337ea":"markdown","5fab52f3":"markdown","e37149fb":"markdown","9059fa97":"markdown","e513709f":"markdown","099f047f":"markdown","92b14b29":"markdown","e14a5991":"markdown","b5180838":"markdown","21a9b94f":"markdown","4c59e1b5":"markdown","306ae0fa":"markdown","1a92bac9":"markdown","e43a6e8d":"markdown","07aed1cd":"markdown","ce3ca8b8":"markdown","eda8d387":"markdown","931add87":"markdown","771fbc91":"markdown","7f3d7071":"markdown","bdc77990":"markdown","14e42c68":"markdown","ceac2f5f":"markdown","a32eb8c6":"markdown","763d9826":"markdown","05a3d602":"markdown"},"source":{"7eecc0db":"# Import our libraries we are going to use for our data analysis.\nimport tensorflow as tf\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Plotly visualizations\nfrom plotly import tools\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\n\n# For oversampling Library (Dealing with Imbalanced Datasets)\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom IPython.display import HTML\nimport warnings; warnings.simplefilter('ignore')\n\n\n% matplotlib inline\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\ndata_file = \"..\/\/input\/loan_test.csv\"\ndf = pd.read_csv(data_file,low_memory=False, index_col=0)","20953e9c":"df.head()","2cff4927":"df.info()","010adbf9":"df.isnull().head()","60ebad3b":"df.isnull().sum()","60828c78":"df.emp_length_int.mean()","b531c86a":"# fill in missing values with a specified value\ndf['emp_length_int'].fillna(value='6.05', inplace=True)","9485762d":"df.isnull().sum()","a2126113":"df.delinq_2yrs.mean()","51b62c04":"# fill in missing values with a specified value\ndf['delinq_2yrs'].fillna(value='0.314', inplace=True)","417d2392":"df.drop('emp_length', axis=1, inplace=True)","6dae3c57":"df.isnull().sum()","1c134c76":"df.isnull().sum()","da00908f":"df.drop('inq_last_6mths', axis=1, inplace=True)","acee945f":"df.isnull().sum()","d48e5af6":"df.annual_income.mean()","98328fdb":"# fill in missing values with a specified value\ndf['annual_income'].fillna(value='75027.58', inplace=True)","ea07a9f1":"df.isnull().sum()","52aa1551":"df.open_acc.mean()","ce94008a":"# fill in missing values with a specified value\ndf['open_acc'].fillna(value='11.55', inplace=True)","144c376d":"df.pub_rec.mean()","9cbf230b":"# fill in missing values with a specified value\ndf['pub_rec'].fillna(value='0.19', inplace=True)","808b9c1f":"df.revol_util.mean()","d003a6fb":"# fill in missing values with a specified value\ndf['revol_util'].fillna(value='55.06', inplace=True)","1d24a981":"df.total_acc.mean()","e54722b7":"# fill in missing values with a specified value\ndf['total_acc'].fillna(value='25.26', inplace=True)","9e3c0f18":"df.isnull().sum()","ad43ee02":"df.collections_12_mths_ex_med.mean()","99cdcb5c":"# fill in missing values with a specified value\ndf['collections_12_mths_ex_med'].fillna(value='0.014', inplace=True)","c65f44ec":"df.acc_now_delinq.head(10)","88c1b448":"df.acc_now_delinq.mean()","b89b6d83":"# fill in missing values with a specified value\ndf['acc_now_delinq'].fillna(value='0.00', inplace=True)","c5d83fd5":"df['final_d'] = pd.to_numeric(df.final_d.str.replace('\/',''))","9f5cc5f8":"df.final_d.head(10)","73257f2a":"df.final_d.median()","86f314bd":"# fill in missing values with a specified value\ndf['final_d'].fillna(value='1012016', inplace=True)","54aa10a7":"df['next_pymnt_d'] = pd.to_numeric(df.next_pymnt_d.str.replace('\/',''))","d00f0b1f":"df.next_pymnt_d.median()","2d337a59":"# fill in missing values with a specified value\ndf['next_pymnt_d'].fillna(value='1022016', inplace=True)","c340e7c9":"df.isnull().sum()","d34400fb":"df['last_credit_pull_d'] = pd.to_numeric(df.last_credit_pull_d.str.replace('\/',''))","3b08a07f":"df.last_credit_pull_d.median()","50e53810":"# fill in missing values with a specified value\ndf['last_credit_pull_d'].fillna(value='1012016', inplace=True)","0c5207ce":"df.isnull().sum()","557ce9c4":"df.income_category.unique()","54bec1f3":"# fill in missing values with a specified value\ndf['income_category'].fillna(value='Low', inplace=True)","421fa4d9":"df.isnull().sum()","cca587ba":"# create the 'income_cat' dummy variable using the 'map' method\ndf['income_cat'] = df.income_category.map({'Low':1, 'Medium':2, 'High':3})","99e21ff3":"df.income_cat.mean()","e4d4dc16":"df.interest_payments.unique()","8a7bf2de":"# create the 'interest_payments' dummy variable using the 'map' method\ndf['interest_payment_cat'] = df.interest_payments.map({'Low':1, 'High':2})","6c4fcd76":"df.loan_condition.unique()","3a7bfd57":"# create the 'loan_condition' dummy variable using the 'map' method\ndf['loan_condition_cat'] = df.loan_condition.map({'Good Loan':0, 'Bad Loan':1})","9fef770c":"df.application_type.unique()","1a30243c":"# create the 'application_type' dummy variable using the 'map' method\ndf['application_type_cat'] = df.application_type.map({'INDIVIDUAL':1, 'JOINT':2})","b7c88515":"df.purpose.isnull()","58853460":"df.loan_status.unique()","8c964ee6":"# create the 'verification_status' dummy variable using the 'map' method\ndf['loan_status_cat'] = df.loan_status.map({'Fully Paid':1, \n                                            'Charged Off':2, \n                                            'Current':3,\n                                           'Default':4, \n                                            'Late (31-120 days)':5, \n                                            'In Grace Period':6,\n                                           'Late (16-30 days)':7, \n                                            'Does not meet the credit policy. Status:Fully Paid':8, \n                                            'Does not meet the credit policy. Status:Charged Off':9,\n                                           'Issued':10})","81a09f0d":"df.isnull().sum()","23beeeb5":"df.verification_status.unique()","e1465219":"# create the 'verification_status' dummy variable using the 'map' method\ndf['verification_status_cat'] = df.verification_status.map({'Verified':1, 'Source Verified':2, 'Not Verified':3})","39763221":"df.home_ownership.unique()","25f22ddf":"# create the 'verification_status' dummy variable using the 'map' method\ndf['home_ownership_cat'] = df.home_ownership.map({'RENT':1, 'OWN':2, 'MORTGAGE':3, 'OTHER':4, 'NONE':5, 'ANY':6})","a6f1dfb6":"df.grade.unique()","2db4e4bc":"# create the 'grade' dummy variable using the 'map' method\ndf['grade_cat'] = df.grade.map({'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7})","ab032bff":"df.term.unique()","fb9ac21d":"# create the 'term' dummy variable using the 'map' method\ndf['term_cat'] = df.term.map({' 36 months':1, ' 60 months':2})","3bb5b98b":"df['income_cat'] = df['income_cat'].astype(int)","5f5cab93":"df['home_ownership_cat'] = df['home_ownership_cat'].astype(int)\ndf['verification_status_cat'] = df['verification_status_cat'].astype(int)","e531f34f":"df['loan_status_cat'] = df['loan_status_cat'].astype(int)","39215728":"# create the 'purpose' dummy variable using the 'map' method\ndf['purpose_cat'] = df.purpose.map({'credit_card':1, 'car':2, \n                                            'small_business':3, 'other':4,\n                                            'wedding':5, 'debt_consolidation':6,\n                                            'home_improvement':7, 'major_purchase':8,\n                                            'medical':9, 'moving':10,\n                                            'vacation':11, 'house':12,\n                                            'renewable_energy':13, 'educational':14})","11c72fa7":"df.isnull().sum()","e2342c85":"df['application_type_cat'] = df['application_type_cat'].astype(int)\ndf['interest_payment_cat'] = df['interest_payment_cat'].astype(int)\ndf['loan_condition_cat'] = df['loan_condition_cat'].astype(int)\ndf['purpose_cat'] = df['purpose_cat'].astype(int)\ndf['grade_cat'] = df['grade_cat'].astype(int)\ndf['term_cat'] = df['term_cat'].astype(int)","c97c4628":"# We have 67429 loans categorized as bad loans\nbadloans_df = df.loc[df[\"loan_condition\"] == \"Bad Loan\"]","ac038cce":"# loan_status cross\nloan_status_cross = pd.crosstab(badloans_df['region'], badloans_df['loan_status']).apply(lambda x: x\/x.sum() * 100)\nnumber_of_loanstatus = pd.crosstab(badloans_df['region'], badloans_df['loan_status'])","7d57857d":"number_of_loanstatus","ba16ee05":"df.loan_condition_cat.unique()","ebf233d8":"# multiple aggregation functions can be applied simultaneously\nstat1=df.groupby('year').loan_amount.agg(['count', 'mean', 'min', 'max'])","c3ee4239":"df1 = pd.DataFrame(stat1)\ndf1","f40e0b4c":"a = df1.plot(kind='bar', title='Loan statistics by year ')","2b691dad":"# multiple aggregation functions can be applied simultaneously\nstat2=df.groupby('region').loan_amount.agg(['count', 'mean', 'min', 'max'])\ndf2 = pd.DataFrame(stat2)\ndf2","c65b81b7":"b=df2.plot(kind='bar', title='Loan by Region')","4a7a6adf":"df.loan_condition.head(10)","4b1d006d":"badloans_df = df.loc[df[\"loan_condition_cat\"] == 1]\ngoodloans_df = df.loc[df[\"loan_condition_cat\"] == 0]","d3498dd2":"# loan_status cross\nloan_status_cross_region = pd.crosstab(badloans_df['region'], badloans_df['loan_condition_cat']).apply(lambda x: x\/x.sum() * 100)\nloan_status_cross_region","83b80dc0":"l = loan_status_cross_region.plot(kind='bar', title='Bad Loan percent by Region')","e3991283":"# loan_status cross\nloan_status_cross_year = pd.crosstab(badloans_df['year'], badloans_df['loan_condition_cat']).apply(lambda x: x\/x.sum() * 100)\nloan_status_cross_year","c70ddbf5":"m = loan_status_cross_year.plot(kind='bar', title='Bad Loan percent by Year')","9f765519":"loan_status=df[df.loan_condition_cat== 1].emp_length_int.value_counts()","96323adc":"v = loan_status.plot(kind='bar', title='Bad Loan percent by employment lenght')","dc908508":"loan_status=df[df.loan_condition_cat== 1].home_ownership_cat.value_counts()\na = df.home_ownership_cat.unique()\nb = df.home_ownership.unique()\nc = pd.DataFrame(a,b)\nc","e390f9b9":"j = loan_status.plot(kind='bar', title='Bad Loan percent by Home Owner')","a19e8608":"a = df.income_category.unique()\nb = df.income_cat.unique()\nc = pd.DataFrame(a,b)\nc","6de237f4":"loan_status=df[df.loan_condition_cat== 1].income_cat.value_counts()\nloan_status.plot(kind='bar', title='Bad Loan percent by Income Category')","783753d1":"a = df.application_type.unique()\nb = df.application_type_cat.unique()\nc = pd.DataFrame(a,b)\nc","6ef98236":"loan_status=df[df.loan_condition_cat== 1].application_type_cat.value_counts()\nt = loan_status.plot(kind='bar', title='Bad Loan percent by Application Type')","603dea77":"a = df.purpose.unique()\nb = df.purpose_cat.unique()\nc = pd.DataFrame(a,b)\nc","04953f53":"loan_status=df[df.loan_condition_cat== 1].purpose_cat.value_counts()\nloan_status.plot(kind='bar', title='Bad Loan percent by Purpose Type')","f2448a90":"a = df.interest_payments.unique()\nb = df.interest_payment_cat.unique()\nc = pd.DataFrame(a,b)\nc","371a7261":"loan_status=df[df.loan_condition_cat== 1].interest_payment_cat.value_counts()\nloan_status.plot(kind='bar', title='Bad Loan percent by interest payment category Type')","2747fc38":"a = df.grade.unique()\nb = df.grade_cat.unique()\nc = pd.DataFrame(a,b)\nc","6fbdfb1a":"loan_status=df[df.loan_condition_cat== 1].grade_cat.value_counts()\nloan_status.plot(kind='bar', title='Bad Loan percent by interest Grade Type')","93d7d29e":"# loan_status cross\nloan_status_cross_region = pd.crosstab(badloans_df['region'], badloans_df['loan_condition_cat']).apply(lambda x: x\/x.sum() * 100)\nloan_status_cross_region","458ba01d":"loan_status_cross_region.plot(kind='bar', title='Bad Loan by Region')","54d283df":"#df.interest_rate\n# calculate the mean beer servings for each continent\nstat4 = df.groupby('region').interest_rate.mean()\nstat4","6c55d6ef":"stat4.plot(kind='bar', x='region', y='interest rate', title='Average interest rates charged by  Banks')","f0457093":"stat4 = df.groupby('year').interest_rate.mean()\nstat4\n","74f12897":"stat4.plot(kind='bar', x='year', y='interest rate', title='Average interest rates by year charged to customers ')","1175c1dc":"stat4 = df.groupby('year').dti.mean()\nstat4","46bf3474":"stat4.plot(kind='bar', x='year', y='debt income ratio ', title='Average debt income ratio per year charged to customers ')","36cec967":"stat4 = df.groupby('region').dti.mean()\nstat4","a3c88173":"stat4.plot(kind='bar', x='Region', y='debt income ratio ', title='Average debt income ratio per year charged to customers ')","14059580":"df.income_cat.unique()","9bdb9b6d":"f, ax = plt.subplots(1,2, figsize=(16,8))\n\ncolors = [\"#D72626\", \"#ffd733\", \"#42e31f\"]\nlabels =\"Low\", \"Medium\", \"High\"\n\nplt.suptitle('Information on Loan Conditions by income category', fontsize=20)\n\ndf[\"income_cat\"].value_counts().plot.pie(explode=[0,0.25,0], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n                                             labels=labels, fontsize=12, startangle=70)\n\npalette = [\"#42e31f\", \"#D72626\", \"#ffd733\"]\n\nsns.barplot(x=\"year\", y=\"income_cat\", hue=\"loan_condition\", data=df, palette=palette, estimator=lambda x: len(x) \/ len(df) * 100)\nax[1].set(ylabel=\"(%)\")","d4579993":"# create a list of features\nfeature_cols = ['emp_length_int', 'annual_income','loan_amount',\n                'interest_rate','dti','home_ownership_cat',\n               'income_cat','total_pymnt','purpose_cat','grade_cat',\n               'application_type_cat','term_cat','year']","fbe11188":"X = df[feature_cols]\ny = df.loan_condition_cat","4f7e8e6b":"# import class, instantiate estimator, fit with all data\nfrom sklearn.ensemble import RandomForestClassifier\nrfclf = RandomForestClassifier(n_estimators=100, max_features=3, oob_score=True, random_state=1)\nrfclf.fit(df[feature_cols], df.loan_condition_cat)","067bfa88":"# compute the feature importances\na = pd.DataFrame({'feature':feature_cols, 'importance':rfclf.feature_importances_})","52ab4404":"model = RandomForestClassifier(n_estimators=100, max_features=3, oob_score=True, random_state=1)\nmodel.fit(X, y)\n\nfeature_importance = model.feature_importances_","6126854f":"feature_importance = rfclf.feature_importances_\nfeatures = feature_cols\nplt.figure(figsize=(16, 6))\nplt.yscale('log', nonposy='clip')\n\nplt.bar(range(len(feature_importance)), feature_importance, align='center')\nplt.xticks(range(len(feature_importance)), features, rotation='vertical')\nplt.title('Feature importance')\nplt.ylabel('Importance')\nplt.xlabel('Features')\nplt.show()","1811e009":"# create a list of features\nfeature_cols = ['emp_length_int', 'annual_income','loan_amount',\n                'interest_rate','dti','home_ownership_cat',\n               'income_cat','total_pymnt','purpose_cat','grade_cat',\n               'application_type_cat','term_cat','year']","f8219ae9":"from sklearn.cross_validation import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\n# define a function that accepts a list of features and returns testing RMSE\ndef train_test_rmse(feature_cols):\n    X = df[feature_cols]\n    y = df.loan_condition_cat\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n    linreg = LinearRegression()\n    linreg.fit(X_train, y_train)\n    y_pred = linreg.predict(X_test)\n    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))","8d94a7d3":"# compare different sets of features\nprint (train_test_rmse(['emp_length_int','annual_income','loan_amount','interest_rate','dti','home_ownership_cat']))\n","398fcd50":"print (train_test_rmse(['emp_length_int','annual_income','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','grade_cat','application_type_cat','term_cat','year']))","b493fbdc":"print (train_test_rmse(['emp_length_int','annual_income','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','grade_cat','application_type_cat','term_cat']))","cb5261fe":"print (train_test_rmse(['emp_length_int','annual_income','loan_amount','interest_rate','dti','home_ownership_cat','income_cat','total_pymnt','purpose_cat','grade_cat','application_type_cat','term_cat','year']))","d04f720e":"# create a list of features\nfeature_cols = ['emp_length_int', 'annual_income','loan_amount',\n                'interest_rate','dti','home_ownership_cat',\n               'income_cat','total_pymnt','purpose_cat','grade_cat',\n               'application_type_cat','term_cat','year']","b9dc246f":"X = df[feature_cols]\ny = df.loan_condition_cat","a9a0e6dc":"## Modeling process\n# spilt X and y into training and testing sets\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","59113538":"# train a logistic regression model on the training set\nfrom sklearn.linear_model import LogisticRegression\nLogreg = LogisticRegression()\nLogreg.fit(X_train, y_train)","eabd40d0":"# make class prediction for the testing set\ny_pred_class = Logreg.predict(X_test)","ad7c36ce":"# calculate Accuracy\nfrom sklearn import metrics\nprint((metrics.accuracy_score(y_test, y_pred_class))*100)","2a11b717":"# examine the class distribution of the testing set (using panda series method)\ny_test.value_counts()","7f99dcfe":"y_test.mean()","22d3d7b3":"# calculate the percentage of zeros\nprint ((1- y_test.mean())*100)","7634bafb":"# claculate null accuracy ( for binary classification problem coded as 0\/1)\nprint (max(y_test.mean(), 1- y_test.mean()))","ec4b5aab":"# print the first 25 true and predicted responses\nfrom __future__ import print_function\nprint('True:', y_test.values[100:250])\nprint('Pred:', y_pred_class[100:250])","32baa683":"from sklearn.cross_validation import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n# use train\/test split with different random_state values\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n\n# check classification accuracy of KNN with K=5\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint ((metrics.accuracy_score(y_test, y_pred))*100)","b6994cca":"# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\nfrom sklearn.cross_validation import cross_val_score\nknn = KNeighborsClassifier(n_neighbors=5)\nscores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\nprint (scores)","501fbfce":"# use average accuracy as an estimate of out-of-sample accuracy\nprint ((scores.mean())*100)","a348a9e7":"# search for an optimal value of K for KNN\nk_range = range(1, 31)\nk_scores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n    k_scores.append(scores.mean())\nprint (k_scores)","4950a4dc":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')","dc9fea4e":"# 30-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\nknn = KNeighborsClassifier(n_neighbors=30)\nscores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\nprint (scores.mean())","124f94ea":"# 10-fold cross-validation with the best KNN model\nknn = KNeighborsClassifier(n_neighbors=2)\nprint ((cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())*100)","d0d66e3e":"# 10-fold cross-validation with logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nprint ((cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())*100)","c4abdddd":"# import class, instantiate estimator, fit with all data\nfrom sklearn.ensemble import RandomForestClassifier\nrfclf = RandomForestClassifier(n_estimators=100, max_features=3, oob_score=True, random_state=1)\nrfclf.fit(df[feature_cols], df.loan_condition_cat)","d24ba2e5":"#compute the feature importances\na = pd.DataFrame({'feature':feature_cols, 'importance':rfclf.feature_importances_})","06d71e01":"model = RandomForestClassifier(n_estimators=100, max_features=3, oob_score=True, random_state=1)\nmodel.fit(X, y)\n\nfeature_importance = model.feature_importances_\n","637778c3":"# compute the out-of-bag classification accuracy\nprint('Mean squared error or classification error also known classification accuracy:',(rfclf.oob_score_)*100,'Percent')","985faefc":"# create a list of features\nfeature_cols = ['emp_length_int', 'annual_income','loan_amount',\n                'interest_rate','dti','home_ownership_cat',\n               'income_cat','total_pymnt','purpose_cat','grade_cat',\n               'application_type_cat','term_cat','year']","15c1b821":"## Modeling process\n# spilt X and y into training and testing sets\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","36ae977c":"# import class, instantiate estimator, fit with all data\nfrom sklearn.ensemble import RandomForestClassifier\nrfclf = RandomForestClassifier(n_estimators=100, max_features=3, oob_score=True, random_state=1)\nrfclf.fit(X_train, y_train)","d91a3ebc":"#compute the feature importances\na = pd.DataFrame({'feature':X_train, 'importance':rfclf.feature_importances_})","84e6f55a":"model = RandomForestClassifier(n_estimators=100, max_features=3, oob_score=True, random_state=1)\nmodel.fit(X_train, y_train)\n\nfeature_importance = model.feature_importances_\n","db49c4c8":"# compute the out-of-bag classification accuracy\nprint('Mean squared error or classification error also known classification accuracy:',(rfclf.oob_score_)*100,'Percent')","de107fc5":"#### How do we choose which features to include in the model? We're going to use **train\/test split** (and eventually **cross-validation**).\n\nWhy not use of **p-values** or **R-squared** for feature selection?\n\n- Linear models rely upon **a lot of assumptions** (such as the features being independent), and if those assumptions are violated, p-values and R-squared are less reliable. Train\/test split relies on fewer assumptions.\n- Features that are unrelated to the response can still have **significant p-values**.\n- Adding features to your model that are unrelated to the response will always **increase the R-squared value**, and adjusted R-squared does not sufficiently account for this.\n- p-values and R-squared are **proxies** for our goal of generalization, whereas train\/test split and cross-validation attempt to **directly estimate** how well the model will generalize to out-of-sample data.\n\n","950aee3f":"# Description","529c9193":"## Data Munging","28827bea":"## Model evaluation (Random forest)","c5b4759a":"### Classification Accuracy (Logistic Regression)","1493f74c":"# Model Selection","0288b423":"## Feature selection\n- In machine learning and statistics, feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant features (variables, predictors) for use in model construction.","4e8a5f2b":"# Visualisation","853547e1":"- we have created a bunch of train\/test splits, calculated the testing accuracy for each, \n- and averaged the results together and That's the essense of **cross-validation!**","c2771d2b":"The Data set is borrowed from Lending Club \n<a src=\"https:\/\/en.wikipedia.org\/wiki\/Lending_Club\"> Lending Club Information <\/a>","71fdacc5":"#### Compare different sets of features by using Step Backward ","5b72deca":"#### Bad Loan percent by employment lenght","5e6cadba":"The central idea and coding  is abstract  from Kevin mark ham youtube video seriese, Introduction to machine learning with scikit-learn video series. You can find link under resources section. References:*From the video series: [Introduction to machine learning with scikit-learn](https:\/\/github.com\/justmarkham\/scikit-learn-videos)*\n","7b07a079":"### Model selection\n**Goal:** Compare the best KNN model with logistic regression","a2bb0da9":"## Conclusion:\n- We are really happy with the result the Mean squared error or classification error also known classification accuracy: ***95.86039336067228*** Percent which is nearly 96 percent. So, we can conclude our study with confirming that we could predict Bad Loan by using given Loan data with an accuracy of 97 %.","e98fd4f1":"Now we will have a closer look at the <b> operative side <\/b> of business by state. This will give us a clearer idea in which state we have a higher operating activity. This will allow us to ask further questions such as Why do we have a higher level of operating activity in this state? Could it be because of economic factors? or the risk level is low and returns are fairly decent? Let's explore!\n\n<h4> What we need to know: <\/h4>\n<ul>\n<li> We will focus on <b>three key metrics<\/b>: Loans issued by state (Total Sum), Average interest rates charged to customers and average annual income of all customers by state. <\/li>\n<li> The purpose of this analysis is to see states that give high returns at a descent risk. <\/li>\n","3e3a1d1c":"#### Average interest rates charged to customers","bce5e8a3":"#### Bad Loan percent by Housing status","3ea8e892":"## Similarity  Search:\n\nWe will start by exploring the distribution of the loan amounts and see when did the loan amount issued increased significantly. <br>\n\n<h4> What we need to know: <\/h4> <br>\n<ul>\n<li> Understand what amount was <b>mostly issued<\/b> to borrowers. <\/li>\n<li> Which <b>year<\/b> issued the most loans. <\/li>\n<li> The distribution of loan amounts is a <b>multinomial distribution <\/b>.<\/li>\n<\/ul>","0b4df9c6":"#### The Number of Bad Loans =  67429\n\n#### The Number of Good Loans = 819950\n\n#### -------------------------------------\n#### Total Number of Loan = 887,379\n\n#### The percentage of bad loan in 887,379 is 7.60 % aproximately","6bf33dce":"## Resources\nReferences:*From the video series: [Introduction to machine learning with scikit-learn](https:\/\/github.com\/justmarkham\/scikit-learn-videos)*\n- scikit-learn documentation: [Cross-validation](http:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html), [Model evaluation](http:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html)\n- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/2439)\n- Section 5.1 of [An Introduction to Statistical Learning](http:\/\/www-bcf.usc.edu\/~gareth\/ISL\/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https:\/\/www.youtube.com\/watch?v=nZAM5OXrktY) (14 minutes), [Cross-validation the right and wrong ways](https:\/\/www.youtube.com\/watch?v=S06JpVoNaA0) (10 minutes)\n- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http:\/\/scott.fortmann-roe.com\/docs\/MeasuringError.html)\n- Machine Learning Mastery: [An Introduction to Feature Selection](http:\/\/machinelearningmastery.com\/an-introduction-to-feature-selection\/)\n- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https:\/\/github.com\/cs109\/content\/blob\/master\/lec_10_cross_val.ipynb)\n- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http:\/\/www.jcheminf.com\/content\/pdf\/1758-2946-6-10.pdf)","d2a8ff9f":"#### Comparing models with train\/test split and RMSE","01f65434":"### Parameter tuning\n**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN","68cb0f25":"- Filling Null values with mean values","4678dd5d":"- Null accuracy : accuracy that could be achieved by always predicting the most frequent class","0ea5fa9d":"## Result Confirmation with train data","b2ba430c":"#### Bad Loan percent by Application Type","c268b4ef":"--------------------------The End ----------------------------------","12c9e200":"# what is dti?\n\n- A debt income ratio (often abbreviated DTI) is the percentage of a consumer's monthly gross income that goes toward paying debts. (Speaking precisely, DTIs often cover more than just debts; they can include principal, taxes, fees, and insurance premiums as well.","d3f956c9":"### KNN Neighbors","d0f6a9c8":"- The loan grade bellow the 'B' type is very bad loan","0436719d":"### Classification Accuracy. \n- Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.\n\n- The accuracy paradox for predictive analytics states that predictive models with a given level of accuracy may have greater predictive power than models with higher accuracy. It may be better to avoid the accuracy metric in favor of other metrics such as precision and recall.","aca237cd":"# Conclusion","c1d63b2a":"In this section, we will see what is the amount of bad loans Irish Fake Bank has declared so far, of course we have to understand that there are still loans that are at a risk of defaulting in the future. \n","65d149a5":"#### Comparing the true and predicted response values","c74ecef0":"- Missing Values\n- Rename columns\n- Data Transformation\n- Coding,en-coding,decoding\n- Outlier\n- Anamolies","b40e4ce2":"#### Bad Loan from 2007 to 2015","8f4337ea":"- What is the classification accuracy?\n- Classification Accuracy. Classification accuracy is our starting point. It is the number of correct predictions - made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage","5fab52f3":"#### Root-mean-square error\n- Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.","e37149fb":"- Looking at the graph above, we see that some features are used rearly , while some impact the performance greatly. We can reduce the number of features by taking a subset of the most important features.","9059fa97":"# Declaration","e513709f":"# Acknowledgement \n\n- I would like to thanks Kaggle.com to provide such a wonderful plate form to this analysis. I would wish to express my thanks and appreciation to  Mr. Kevin Mark Ham for such a wonderful video series. Which helps people like us to understand machine learning. I also like to share my gratitude to Mr. Alexander Bachmann, Lending Club II Risk analysis and metrics, that help me and others to understand risk analysis and I would like to thank all Kaggle users who download and vote for this analysis.\n\n- This Analysis is based upon Alexander Bachmann, Lending Club II Risk analysis and metrics\n\n[Lending Club II Risk analysis and metrics](https:\/\/www.kaggle.com\/janiobachmann\/lending-club-risk-analysis-and-metrics)*","099f047f":"#### Bad Loan percent by interest Grade Type","92b14b29":"- Classification Accuracy : percentage of correct prediction","e14a5991":"- From the above result we are selecting KNN Neighbours with K=1 \n- which is produce a better mean accuracy which is 87.63 percent aproximately. \n- As compare to logistic regression. \n- The logistic regression offer mean accuracy of 92.38 which is approximately 3.99 percent that is slightly high. \n- So, because of that result, this study will use logistic regression for our predictions.","b5180838":"#### 'Average interest rates by year","21a9b94f":"#####  Why we calculate feature importance scores?\n- we reduce the feature set. The new pruned features contain all features that have an importance score greater than a certain number.","4c59e1b5":"#### Bad Loan percent by Income Status","306ae0fa":"#### Good Loan represent by 0, and Bad Loan represent by 1","1a92bac9":"- id\tA unique LC assigned ID for the loan listing.\n\n- initial_list_status\tThe initial listing status of the loan. Possible values are \u2013 W, F\n\n- inq_last_6mths\tThe number of inquiries in past 6 months (excluding auto and mortgage inquiries)\n\n- \n- installment\tThe monthly payment owed by the borrower if the loan originates.\n\n- int_rate\tInterest Rate on the loan\n\n- is_inc_v\tIndicates if income was verified by LC, not verified, or if the income source was verified\n\n- issue_d\tThe month which the loan was funded\n\n- last_credit_pull_d\tThe most recent month LC pulled credit for this loan\n\n- last_fico_range_high\tThe upper boundary range the borrower\u2019s last FICO pulled belongs to.\n\n- last_fico_range_low\tThe lower boundary range the borrower\u2019s last FICO pulled belongs to.\n\n- last_pymnt_amnt\tLast total payment amount received\n\n- last_pymnt_d\tLast month payment was received\n- loan_amnt\tThe listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n- loan_status\tCurrent status of the loan\n- member_id\tA unique LC assigned Id for the borrower member.\n- mths_since_last_delinq\tThe number of months since the borrower's last delinquency.\n- mths_since_last_major_derog\tMonths since most recent 90-day or worse rating\n- mths_since_last_record\tThe number of months since the last public record.\n- next_pymnt_d\tNext scheduled payment date\n- open_acc\tThe number of open credit lines in the borrower's credit file.\n- out_prncp\tRemaining outstanding principal for total amount funded\n- out_prncp_inv\tRemaining outstanding principal for portion of total amount funded by investors\n- policy_code\t\"publicly available policy_code=1\n- new products not publicly available policy_code=2\"\n- pub_rec\tNumber of derogatory public records\n- purpose\tA category provided by the borrower for the loan request. \n- pymnt_plan\tIndicates if a payment plan has been put in place for the loan\n- recoveries\tpost charge off gross recovery\n- revol_bal\tTotal credit revolving balance\n- revol_util\tRevolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n- sub_grade\tLC assigned loan subgrade\n- term\tThe number of payments on the loan. Values are in months and can be either 36 or 60.\n- title\tThe loan title provided by the borrower\n- total_acc\tThe total number of credit lines currently in the borrower's credit file\n- total_pymnt\tPayments received to date for total amount funded\n- total_pymnt_inv\tPayments received to date for portion of total amount funded by investors\n- total_rec_int\tInterest received to date\n- total_rec_late_fee\tLate fees received to date\n- total_rec_prncp\tPrincipal received to date\n- url\tURL for the LC page with listing data.\n- verified_status_joint\tIndicates if the co-borrowers' joint income was verified by LC, not verified, or if the income source was verified\n- zip_code\tThe first 3 numbers of the zip code provided by the borrower in the loan application.\n- open_acc_6m\tNumber of open trades in last 6 months\n- open_il_6m\tNumber of currently active installment trades\n- open_il_12m\tNumber of installment accounts opened in past 12 months\n- open_il_24m\tNumber of installment accounts opened in past 24 months\n- mths_since_rcnt_il\tMonths since most recent installment accounts opened\n- total_bal_il\tTotal current balance of all installment accounts\n- il_util\tRatio of total current balance to high credit\/credit limit on all install acct\n- open_rv_12m\tNumber of revolving trades opened in past 12 months\n- open_rv_24m\tNumber of revolving trades opened in past 24 months\n- max_bal_bc\tMaximum current balance owed on all revolving accounts\n- all_util\tBalance to credit limit on all trades\n- total_rev_hi_lim  \tTotal revolving high credit\/credit limit\n- inq_fi\tNumber of personal finance inquiries\n- total_cu_tl\tNumber of finance trades\n- inq_last_12m\tNumber of credit inquiries in past 12 months\n- acc_now_delinq\tThe number of accounts on which the borrower is now delinquent.\n- tot_coll_amt\tTotal collection amounts ever owed\n- tot_cur_bal\tTotal current balance of all accounts\n","e43a6e8d":"### Bad Loan percent by Purpose Type","07aed1cd":"- The following graphs display the higher value of k is better for our model accuracy and with K=1 \n- we will get max of 87.63 percent of accuracy which is ok.\n- we have chnged the value of k= 30 to confirm the result. The obtained result confirmed the graph result which predicted that the heigher value of K will produce a bettere result.","ce3ca8b8":"**Conclusion:**\n\n- Classification accuracy is the **easiest classification metric to understand**\n- But, it does not tell you the **underlying distribution** of response values\n- And, it does not tell you what **\"types\" of errors** your classifier is making","eda8d387":"## Method Of K-cross Validation\n\n1. Split the dataset into K **equal** partitions (or \"folds\").\n2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n3. Calculate **testing accuracy**.\n4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy.","931add87":"### What is DTI?\nA debt income ratio (often abbreviated DTI) is the percentage of a consumer's monthly gross income that goes toward paying debts. (Speaking precisely, DTIs often cover more than just debts; they can include principal, taxes, fees, and insurance premiums as well.","771fbc91":"- System Predict Good loan = 204841 and Bad Loan =  17004","7f3d7071":"#### Bad Loan percent by interest payment","bdc77990":"####  Bad Loans issued by state (Total Sum)","14e42c68":"- LoanStatNew\tDescription\n\n- addr_state\tThe state provided by the borrower in the loan application\n\n- annual_inc\tThe self-reported annual income provided by the borrower during registration.\n\n- annual_inc_joint\tThe combined self-reported annual income provided by the co-borrowers during registration\n\n- application_type\tIndicates whether the loan is an individual application or a joint application with two co-borrowers\n\n- collection_recovery_fee\tpost charge off collection fee\n\n- collections_12_mths_ex_med\tNumber of collections in 12 months excluding medical collections\n\n- delinq_2yrs\tThe number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n\n- desc\tLoan description provided by the borrower\n\n- dti\tA ratio calculated using the borrower\u2019s total monthly debt payments on the total debt obligations, - - - excluding mortgage and the requested LC loan, divided by the borrower\u2019s self-reported monthly income.\n\n- dti_joint\tA ratio calculated using the co-borrowers' total monthly payments on the total debt obligations, - excluding mortgages and the requested LC loan, divided by the co-borrowers' combined self-reported monthly income\n\n- earliest_cr_line\tThe month the borrower's earliest reported credit line was opened\n\n- emp_length\tEmployment length in years. Possible values are between 0 and 10 where 0 means less than one year \n\n- and 10 means ten or more years. \n\n- emp_title\tThe job title supplied by the Borrower when applying for the loan.*\n\n- fico_range_high\tThe upper boundary range the borrower\u2019s FICO at loan origination belongs to.\n\n- fico_range_low\tThe lower boundary range the borrower\u2019s FICO at loan origination belongs to.\n\n- funded_amnt\tThe total amount committed to that loan at that point in time.\n\n- funded_amnt_inv\tThe total amount committed by investors for that loan at that point in time.\n\n- grade\tLC assigned loan grade\n\n- home_ownership\tThe home ownership status provided by the borrower during registration. Our values are: RENT, OWN, MORTGAGE, OTHER.\n","ceac2f5f":"df.drop('earliest_cr_line', axis=1, inplace=True)\ndf.drop('mths_since_last_delinq', axis=1, inplace=True)\ndf.drop('mths_since_last_record', axis=1, inplace=True)\ndf.drop('last_pymnt_d', axis=1, inplace=True)\ndf.drop('mths_since_last_record', axis=1, inplace=True)","a32eb8c6":"# Data Set ","763d9826":"#### DTI by Region","05a3d602":"#### Cross-validation \n- Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it. In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples."}}