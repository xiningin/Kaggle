{"cell_type":{"9eb13b91":"code","b8603d94":"code","591d3948":"code","0da79325":"code","3cc37a5b":"code","74adf2c9":"code","53664e1b":"code","0d454fa8":"code","553ac144":"code","74945766":"code","047b1d98":"code","0efdf76f":"code","cdc5b5e2":"code","cce472b8":"code","26a50da4":"code","47e6dd83":"code","6efc6007":"code","f3277b98":"code","963067bc":"code","ae32e484":"code","035bcfef":"code","1755432f":"code","f326d8e5":"code","6239f7ac":"code","270152a3":"markdown","c948d5ad":"markdown"},"source":{"9eb13b91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b8603d94":"import pandas as pd\nimport numpy as np\n\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation","591d3948":"df = pd.read_csv('\/kaggle\/input\/disneyland-reviews\/DisneylandReviews.csv', encoding='latin-1')\ndf.head()","0da79325":"data = df['Review_Text']","3cc37a5b":"data.shape","74adf2c9":"## To save some computation time we are slicing some data\ndata = data[0:2000]","53664e1b":"# Tokenization\n\ntokens = []\nfor i in data:\n    words = word_tokenize(i)\n    tokens.extend(words)\n    \nprint(tokens[0:50])","0d454fa8":"# Lower case\n\nlower = [i.lower() for i in tokens]\nprint(lower[0:50])","553ac144":"# Remove punctuations\n\npun_filtered = [j for j in lower if j not in punctuation]\nprint(pun_filtered[0:50])","74945766":"# Removing stop words\n\nstop = set(stopwords.words('english'))\nstop_filtered = [l for l in pun_filtered if l not in stop]\nprint(stop_filtered[0:50])","047b1d98":"# Stemming\nfrom nltk.stem import PorterStemmer\n\npor = PorterStemmer()\nstemm = list(map(lambda x: por.stem(x), stop_filtered))\nprint(stemm[0:50])","0efdf76f":"# Lemmitization\nfrom nltk.stem import LancasterStemmer\n\nlan = LancasterStemmer()\nlemm = list(map(lambda x: lan.stem(x), stop_filtered))\nprint(lemm[0:50])","cdc5b5e2":"# Part of speech\n\npos = nltk.pos_tag(stop_filtered)\nprint(pos[0:50])","cce472b8":"# Bag of Words\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","26a50da4":"vec = CountVectorizer()\nvec.fit(stop_filtered)","47e6dd83":"dic = vec.vocabulary_\n\n## getting first 10 elements from BoW (dictionary)\nitems = dic.items()\nelem = list(items)[:10]\nelem","6efc6007":"# Getting document-term matrix\ndt = vec.transform(stop_filtered)\ndt.shape","f3277b98":"# Binary Bag of Words\n\nb_vec = CountVectorizer(binary=True)\nb_vec.fit(stop_filtered)","963067bc":"dic_b = b_vec.vocabulary_\n\nitem = dic_b.items()\nelements = list(item)[:10]\nelements","ae32e484":"dt_b = b_vec.transform(stop_filtered)\ndt_b.toarray()","035bcfef":"# N-gram (Bigram, Trigram)\n\ncv = CountVectorizer(ngram_range=(1,1)) ## only unigram\nuni = cv.fit(stop_filtered)\nv = uni.vocabulary_\n#print(v)","1755432f":"# TF-IDF\n\ntf_idf = TfidfVectorizer(use_idf=True,\n                        smooth_idf=True,\n                        ngram_range=(0,1),\n                        stop_words='english')\n\ntf_idf.fit(stop_filtered)\nlen(tf_idf.vocabulary_)","f326d8e5":"tf_idf_vector = tf_idf.transform(stop_filtered)\ntf_idf_vector.shape","6239f7ac":"# Word2Vec\n\n","270152a3":"### Data Preprocessing ","c948d5ad":"### Techniques of Encodings\n    - Bag of Words\n    - Binary bag of words\n    - Bigram, trigram\n    - TF-IDF"}}