{"cell_type":{"a860afec":"code","f3674b69":"code","1a8e94e8":"code","939e2c6c":"code","f67269be":"code","18d07018":"code","8d5cc1ce":"code","9e7254e1":"code","84b501b0":"code","b558593b":"code","d0c33a3a":"code","54e31ffc":"code","0f669af3":"code","bbea122e":"markdown","eb308fed":"markdown","d1ea9b04":"markdown","eab09da1":"markdown","15391759":"markdown","a3380867":"markdown","0fe111c2":"markdown","7f9e8c52":"markdown","4d1b5252":"markdown","1be26937":"markdown","a9a99445":"markdown"},"source":{"a860afec":"from pathlib import Path\nimport json\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib import colors\nfrom collections import Counter\nimport networkx as nx","f3674b69":"class ArcGraph():\n    def __init__(self, diag = True):\n        self.G = None\n        self.diag = diag\n        \n        \n        \n    def to_graph(self, im):\n        G = nx.Graph()\n        I,J = im.shape\n        for i in range(I):\n            for j in range(J):\n                if not im[i,j]:\n                    continue\n                G.add_node((i,j))\n                edges = []\n                if i >= 1:\n                    if im[i,j] == im[i-1,j]:\n                        edges.append( ( (i,j), (i-1,j) ) )\n                    if j >= 1:\n                        if im[i,j] == im[i,j-1]:\n                            edges.append( ( (i,j), (i,j-1) ) )\n                        if im[i,j] == im[i-1,j-1] and self.diag:\n                            edges.append( ( (i,j), (i-1,j-1) ) )\n                    if j < J-1:\n                        if im[i,j] == im[i,j+1]:\n                            edges.append( ( (i,j), (i,j+1) ) )\n                        if im[i,j] == im[i-1,j+1] and self.diag:\n                            edges.append( ( (i,j), (i-1,j+1) ) )\n                \n                if i < I-1:\n                    if im[i,j] == im[i+1,j]:\n                        edges.append( ( (i,j), (i+1,j) ) )\n                    if j >= 1:\n                        if im[i,j] == im[i+1,j-1] and self.diag:\n                            edges.append( ( (i,j), (i+1,j-1) ) )\n                    if j < J-1:\n                        if im[i,j] == im[i+1,j+1] and self.diag:\n                            edges.append( ( (i,j), (i+1,j+1) ) )\n                G.add_edges_from(edges)\n        self.G = G\n        return self.G","1a8e94e8":"def plot_one(ax, i,train_or_test,input_or_output, task):\n#     cmap = colors.ListedColormap(\n#         ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n#          '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n#     norm = colors.Normalize(vmin=0, vmax=9)\n    \n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)\n\ndef plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(axs[0,i],i,'train','input', task=task)\n        plot_one(axs[1,i],i,'train','output', task=task)        \n    plt.tight_layout()\n    plt.show()        \n        \n#     num_test = len(task['test'])\n#     fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n#     if num_test==1: \n#         plot_one(axs[0],0,'test','input')\n#         plot_one(axs[1],0,'test','output')     \n#     else:\n#         for i in range(num_test):      \n#             plot_one(axs[0,i],i,'test','input')\n#             plot_one(axs[1,i],i,'test','output')  \n    plt.tight_layout()\n    plt.show() ","939e2c6c":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)","f67269be":"data_path = Path('..\/input\/abstraction-and-reasoning-challenge')\ntraining_path = data_path \/ 'training'\nevaluation_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'","18d07018":"def read_task(task_file, train = True):\n    task_file = (training_path if train else evaluation_path)\/task_file\n    with task_file.open() as f:\n        return json.load(f)","8d5cc1ce":"task = read_task(\"025d127b.json\")\nplot_task(task)","9e7254e1":"task_in = np.array(task[\"train\"][0][\"input\"], dtype = np.uint8) ","84b501b0":"arc_graph =  ArcGraph(diag = True) # Make the grah builder\ngraph = arc_graph.to_graph(task_in) # Convert the image into Networkx graph, \n                                 # two arbitrary cells are linked if they share the same color and are close to each other on the grid","b558593b":"nx.draw(graph, pos= nx.spring_layout(graph))","d0c33a3a":"communities = list(nx.community.k_clique_communities(graph,2 ))\nlen(communities)","54e31ffc":"plt.figure(figsize=(12,6))\nplt.subplot(\"131\")\nplt.imshow(task_in, cmap = cmap, norm=norm)\nplt.title(\"Main task\")\nfor k,community in enumerate(communities, 1):\n    im = np.zeros(task_in.shape, dtype=int) # A zeros filled image\n    # The clique is assigned a rank k\n    plt.subplot(f\"13{k+1}\")\n    plt.title(f\"Object {k}\")\n    for i,j in community:\n        im[i,j] = k\n    plt.imshow(im, cmap=cmap, norm = norm)","0f669af3":"task_files =np.array( list(training_path.glob(\"*\")))\nnp.random.shuffle(task_files)\nNPLOTS = 30\nplot_count = 0\nfor task_file in task_files:\n    \n    task = read_task(task_file.name)\n    task_in = np.array(task[\"train\"][0][\"input\"], dtype = np.uint8)\n    \n    graph = arc_graph.to_graph(task_in)\n    \n    communities = sorted(nx.community.k_clique_communities(graph,2 ), key= lambda x: -len(x))\n    if  len(communities) < 3: # Keep only interesting figures\n        continue\n    \n    n = min(7, len(communities)) # Only plot the first objects\n    fig, ax = plt.subplots(1,n+1, squeeze=False, figsize=(12,6))\n    ax[0,0].imshow(task_in, cmap=cmap, norm=norm)\n    ax[0,0].set_title(\"Main task\")\n    for k,community in enumerate(communities[:n] , 1):\n        im = np.zeros(task_in.shape, dtype=int)# A zeros filled image\n        for i,j in community:\n            im[i,j] = 1\n        ax[0,k].imshow(im, cmap=cmap, norm = norm)\n        ax[0,k].set_title(f\"Object {k}\")\n    plt.show()\n    plot_count += 1\n    if plot_count > NPLOTS:\n        break\n    print(task_file.name,flush=True)","bbea122e":"# A tiny recall on graph theory","eb308fed":"# Extract more objects","d1ea9b04":"> By looking at the graph's plot, we could easily identify the 2 objects. Those objects could be extracted using [networkx](https:\/\/networkx.github.io\/) and its  [k-clique-communities algorithm](https:\/\/networkx.github.io\/documentation\/stable\/reference\/algorithms\/generated\/networkx.algorithms.community.kclique.k_clique_communities.html#networkx.algorithms.community.kclique.k_clique_communities). Note that we could also extract those objects as the graph's [connected components](https:\/\/networkx.github.io\/documentation\/stable\/reference\/algorithms\/component.html#connectivity) .\n\n> Let's recall that the graph consists of the task grid cells. Two arbitrary celles $(i_1,j_1), (i_2,j_2)$ are considered as linked when they are neighbour and does share the same color (which must be different from  the backgroud color).","eab09da1":"In this kernel, I will be using graph analysis (**netwrokx**) to extract ARC grid's objects as communities. This allows extremely precise and relatively fast object extraction from the tasks. ","15391759":"## Plotting","a3380867":"# Object detection as graph community analylis","0fe111c2":"As expected, 2 communties (objects) are found :) ! Let's plot them...","7f9e8c52":"## Arcgrah","4d1b5252":"> The task **025d127b** contains  2 objects. If we could extract them, then their colors and positions can be inferred based on additional statistics.","1be26937":"...TODO","a9a99445":"# Utils"}}