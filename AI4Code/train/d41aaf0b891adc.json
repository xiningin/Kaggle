{"cell_type":{"4a67202b":"code","d19b0015":"code","62b27b1a":"code","ee6cc067":"code","9bd0c07d":"code","0385de9f":"code","6c8b5c43":"code","2895cf17":"code","edd88b79":"code","7716e3f4":"code","9d75e2c9":"code","176a6966":"code","fb6342f1":"code","c194242c":"code","01b988f0":"code","ed604305":"code","a775a796":"markdown","09bb6a19":"markdown"},"source":{"4a67202b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d19b0015":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport cv2\nimport enum\nimport math\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_absolute_error, roc_auc_score\nfrom tqdm import tqdm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom joblib import dump, load\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","62b27b1a":"PATH = '..\/input\/petfinder-pawpularity-score'\ntrain = pd.read_csv(os.path.join(PATH, 'train.csv'))\ntest = pd.read_csv(os.path.join(PATH, 'test.csv'))\nsub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))","ee6cc067":"train.shape # sub.shape, test.shape","9bd0c07d":"train.head() ","0385de9f":"test.head()","6c8b5c43":"sub.head()","2895cf17":"plt.rcParams[\"figure.figsize\"] = (15,6)\nax = sns.boxplot(x=train.Pawpularity, whis=[5, 95], color='red')","edd88b79":"dataplot = sns.heatmap(train.corr(), cmap=\"BuPu\", annot=True, color='red')\nplt.show()","7716e3f4":"columns = [col for col in train.columns if col not in ['Id', 'Pawpularity', 'bins'] ]","9d75e2c9":"IMG_PATH = [os.path.join(PATH, 'train\/'+idx+'.jpg')  for idx in train.Id]\ndef visualize_image(figsize=(16, 16), n_images=2):\n    plt.figure(figsize=figsize)\n    w = int(n_images ** .5)\n    h = math.ceil(n_images \/ w) \n    all_names = IMG_PATH\n    image_names = random.sample(all_names, n_images)\n    for ind, image_name in enumerate(image_names):   \n            img = cv2.imread(image_name)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n            plt.subplot(w, h, ind + 1)\n            plt.imshow(img)\n            plt.axis(\"off\")          \n    plt.show()","176a6966":"visualize_image(n_images=25)","fb6342f1":"xgb_params= {\"n_estimators\": 30000,\"max_depth\": 20,\"objective\":\"reg:squarederror\",\"n_jobs\": 4,\"seed\": 3001,'tree_method': \"gpu_hist\",\"gpu_id\": 0,\"eval_metric\": \"rmse\",  \"subsample\": 0.7,\"colsample_bytree\": 0.7,\"learning_rate\": 0.05}","c194242c":"def random_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nclass Config(enum.Enum):\n    SEED = 3001\n    N_FOLDS = 25\n    EARLY_STOP = 300\nrandom_seed(Config.SEED.value)","01b988f0":"rmse_score = []\n\ntargets = train['Pawpularity'].values\n\nnum_bins = int(np.floor(1 + np.log2(len(train))))\n\ntrain.loc[:, \"bins\"] = pd.cut(train[\"Pawpularity\"], bins=num_bins, labels=False)\n\nkf = StratifiedKFold(n_splits = Config.N_FOLDS.value, shuffle=True, random_state=Config.SEED.value)    \n        \noof = np.zeros((train.shape[0],))\ntest_preds = 0\n\nfor f, (train_idx, val_idx) in tqdm(enumerate(kf.split(X=train, y=train.bins.values))):\n        df_train, df_val = train.iloc[train_idx][columns], train.iloc[val_idx][columns]\n        train_target, val_target = targets[train_idx], targets[val_idx]\n        \n        model = xgb.XGBRegressor(**xgb_params)\n        \n        model.fit(\n            df_train[columns], \n            train_target,\n            eval_set=[(df_val[columns], val_target)],\n            early_stopping_rounds=Config.EARLY_STOP.value,\n            verbose=500\n        )\n        \n        oof_tmp = model.predict(df_val[columns])\n        test_tmp = model.predict(test[columns])\n        \n        oof[val_idx] = oof_tmp\n        test_preds += test_tmp\/Config.N_FOLDS.value\n        rmse = mean_squared_error(val_target, oof_tmp, squared=False)\n        rmse_score.append(rmse)\n        print(f'FOLD: {f} RMSE: {rmse} Mean RMSE: {np.mean(rmse_score)}')","ed604305":"sub['Pawpularity'] = test_preds\nsub.to_csv('submission.csv', index=False)","a775a796":"#### Did it work?\nWe will be adapted into AI tools that will guide shelters and rescuers around the world to improve the appeal of their pet profiles, automatically enhancing photo quality and recommending composition improvements. As a result, stray dogs and cats can find their \"furever\" homes much faster. With a little assistance from the Kaggle community, many precious lives could be saved and more happy families created.\n\n#### What did you not understand about this process?\nWell, everything provides in the competition data page. I've no problem while working on it. If you guys don't understand the thing that I'll do in this notebook then please comment on this notebook.\n\n#### What else do you think you can try as part of this approach?\nIn this competition, our task is to predict engagement with a pet's profile based on the photograph for that profile.","09bb6a19":"#### What are you trying to do in this notebook?\nIn this notebook, we\u2019ll analyze raw images and metadata to predict the \u201cPawpularity\u201d of pet photos. We'll train and test our model on PetFinder.my's thousands of pet profiles. Winning versions will offer accurate recommendations that will improve animal welfare.\n\n#### Why are you trying it?\nPetFinder.my is Malaysia\u2019s leading animal welfare platform, featuring over 180,000 animals with 54,000 happily adopted. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n\nCurrently, PetFinder.my uses a basic Cuteness Meter to rank pet photos. It analyzes picture composition and other factors compared to the performance of thousands of pet profiles. While this basic tool is helpful, it's still in an experimental stage and the algorithm could be improved."}}