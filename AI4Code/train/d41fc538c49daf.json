{"cell_type":{"dd6c55fa":"code","5ff1fcb1":"code","254f4a5c":"code","6537367a":"code","ad9594ba":"code","f907481b":"code","eec34a04":"code","dd19955a":"code","380e51c9":"code","0f17ea80":"code","e47a7f3c":"code","5f916835":"code","15147fc1":"code","f1ae4efe":"code","3050bbd3":"code","b4398c68":"code","4cf8fc16":"code","f54f4366":"code","3f4d4808":"code","a1d1523b":"code","ca4c8dfa":"code","7a030467":"markdown","e0a1fd78":"markdown","44646241":"markdown","4df92293":"markdown","c4dea38e":"markdown","62637192":"markdown","6d58b0bc":"markdown","d5b92fbd":"markdown","7b6c0306":"markdown","f0dc905f":"markdown","b9832067":"markdown","35dd788c":"markdown","88ffe2c7":"markdown","413a4762":"markdown"},"source":{"dd6c55fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5ff1fcb1":"import warnings\nwarnings.filterwarnings('ignore') # Ignore comman warnings\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","254f4a5c":"print(os.listdir(\"..\/input\/\"))","6537367a":"settings = {\n    'EPOCHS':10,\n    'BATCH_SIZE' : 30\n}","ad9594ba":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n","f907481b":"train_data.columns","eec34a04":"train_data.shape","dd19955a":"def show_image(train_image, label, index):\n    image_shaped = train_image.values.reshape(28,28)\n    plt.subplot(4, 5, index+1)\n    plt.imshow(image_shaped, cmap=plt.cm.gray)\n    plt.title(label)\n\n\nplt.figure(figsize=(18, 8))\nsample_image = train_data.sample(20).reset_index(drop=True)\nprint(len(sample_image))\nlabel = sample_image['label']\nimage_pixel = sample_image.drop('label', axis = 1)\nfor index, row in sample_image.iterrows():\n    label = row['label']\n    image_pixels = row.drop('label')\n    show_image(image_pixels, label, index)\nplt.tight_layout()","380e51c9":"from keras import layers, models\n\ndef prepareModel():\n    model = models.Sequential()\n    model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28,28,1)))\n    model.add(layers.MaxPooling2D(2,2))\n    model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n    model.add(layers.MaxPooling2D(2,2))\n    model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(64, activation = 'relu'))\n    model.add(layers.Dense(10, activation = 'softmax'))\n    \n    return model\n\n","0f17ea80":"model = prepareModel()\nmodel.summary()","e47a7f3c":"from sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nXtrain = train_data.drop(columns=['label']).values.reshape(train_data.shape[0],28,28,1).astype('float')\/255\nYtrain = to_categorical(train_data['label'])\n\nx_validation = Xtrain[:1000]\nx = Xtrain[1000:]\ny_validation = Ytrain[:1000]\ny = Ytrain[1000:]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\nx_validation.shape","5f916835":"model.compile(\noptimizer = 'rmsprop',\nloss = 'categorical_crossentropy',\nmetrics = ['accuracy']\n)","15147fc1":"trainedModel = model.fit(\n    x_train,y_train,\n    epochs = settings['EPOCHS'],\n    batch_size = settings['BATCH_SIZE'],\n    validation_data = (x_validation,y_validation )\n)","f1ae4efe":"trainedModel.history","3050bbd3":"test_loss,test_acc = model.evaluate(x_test, y_test)","b4398c68":"print(\"Test Loss:{loss},Accuracy :{acc}\".format(loss = test_loss,acc = test_acc))","4cf8fc16":"loss = trainedModel.history['loss']\nval_loss = trainedModel.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'bo', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'g', label = 'Validation Loss')\nplt.title(\"Training and Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","f54f4366":"acc = trainedModel.history['accuracy']\nval_acc = trainedModel.history['val_accuracy']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, acc, 'bo', label = 'Training Accuracy')\nplt.plot(epochs, val_acc, 'g', label = 'Validation Accuracy')\nplt.title(\"Training and Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","3f4d4808":"test_digit_data = test_data.values.reshape(test_data.shape[0],28,28,1).astype(\"float32\") \/ 255\npredictions = model.predict(test_digit_data)\nresults = np.argmax(predictions, axis = 1) ","a1d1523b":"plt.figure(figsize=(10, 8))\nsample_test = test_data.head(10)\nfor index, image_pixels in sample_test.iterrows():\n    label = results[index]\n    show_image(image_pixels, label, index)\nplt.tight_layout()","ca4c8dfa":"submissions = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmissions['Label'] = results\nsubmissions.to_csv('submission.csv', index = False)\n","7a030467":"## Build Our Convolutional Network:\nThe fundamental difference between a densely connected layer and a convolutional layer is this: Dense layers learn global patterns in their input feature space whereas convolutional layers learn local patterns.\nNote, a convent takes as input tensor of shape(image_height, image_width,image_channel),so we will configure the convent to process inputs of size(28,28,1) and pass it in first layer which is configured in 32 output_depth,and (3,3) hieght and width windows.example:**Conv2D**(output_depth,(window_height,window_width)).\nMaxPooling: Maxpooling consists of extracting windows from the input feature map and outputting the max value of each channel.we We can see in model.summary that the size of the feature map is halved after every maxpooling.\n**Flatten** Platten layer convent tensor into a vector that can be fed into a fully connected neural network classifier.\n**Softmax**: In the last layer we use softmax, because softmax is used for multiclass\n","e0a1fd78":"## Check Directory whare data is located:\nHere we can see that Data is located in \"digit-recognizer\"","44646241":"## Model Summary","4df92293":"## Display some Images:\nWe are displaying some images from traing set\n","c4dea38e":"## Set Data for Testing pupose","62637192":"## Set some configuration which can be used in algorithm;\nIt is a good practice to make setting dictionary for all constants which are used multiple times","6d58b0bc":"# Amazing Accuracy:Hurrrrrrrrrrrrrraaaaaaaaaaaaaaaaaaaaaaaah","d5b92fbd":"## Check Dataset","7b6c0306":"## Import data\nImport given data in train and test set","f0dc905f":"# Set how is our prediction","b9832067":"## Now Submit our Model","35dd788c":"## Below are the steps that we will follow to gain heighr accuracy.\n1. Load all require modules\n2. Import datasets\n3. Analyse and visualise some given digits from training set\n4. Split Data set into\n* training set\n* Validation set\n5.  Make our CNN Model\n6. Plot Loss and accuracy Graph\n7. test the test data\n8. Summit the model","88ffe2c7":"## Data Preprocessing\nsplit data into train and test set. we are alos deviding data by 255 in order to make all pixel in same range","413a4762":"## Now Plot loss and accuracy Graph: Evaluate"}}