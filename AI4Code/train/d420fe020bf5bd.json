{"cell_type":{"807e8a0c":"code","fe14f0ec":"code","13dd40a6":"code","c7a56a77":"code","d9d5a0bd":"code","6ab11150":"code","09d86880":"code","53152cff":"code","4dfbdb46":"code","94c04340":"code","25543b82":"code","2daa32a7":"code","28796dde":"code","ec4d3ef7":"code","638a40d5":"code","99517a4f":"code","2584a10a":"code","7ad812b2":"code","27c0ee90":"code","2f0ee291":"code","663d7057":"code","abef1726":"code","b1b3de19":"code","6b22b21a":"code","7ed575e3":"markdown","0c952c87":"markdown","ac4a1881":"markdown","31780b77":"markdown","e315cd33":"markdown","50d03554":"markdown","43dbe9ef":"markdown","f5b4ee8a":"markdown","8a375879":"markdown"},"source":{"807e8a0c":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline","fe14f0ec":"df = pd.read_csv(\"..\/input\/kaggle-join-data-with-preproces\/data.csv\",index_col=0)","13dd40a6":"df.head()","c7a56a77":"df.info()","d9d5a0bd":"from sklearn.preprocessing import StandardScaler","6ab11150":"scaler = StandardScaler()","09d86880":"scaler.fit(df.drop('Survived',axis=1))","53152cff":"scaled_features = scaler.transform(df.drop('Survived',axis=1))","4dfbdb46":"df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\ndf_feat.head()","94c04340":"from sklearn.model_selection import train_test_split","25543b82":"X_train, X_test, y_train, y_test = train_test_split(scaled_features,df['Survived'],\n                                                    test_size=0.319)\n","2daa32a7":"from sklearn.neighbors import KNeighborsClassifier","28796dde":"knn = KNeighborsClassifier(n_neighbors=1)","ec4d3ef7":"knn.fit(X_train,y_train)","638a40d5":"pred = knn.predict(X_test)","99517a4f":"from sklearn.metrics import classification_report,confusion_matrix","2584a10a":"print(confusion_matrix(y_test,pred))","7ad812b2":"print(classification_report(y_test,pred))","27c0ee90":"error_rate = []\n\n# Will take some time\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","2f0ee291":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","663d7057":"# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\nknn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=1')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","abef1726":"# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=9\nknn = KNeighborsClassifier(n_neighbors=9)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=9')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","b1b3de19":"# NOW WITH K=13\nknn = KNeighborsClassifier(n_neighbors=13)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=13')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","6b22b21a":"# NOW WITH K=19\nknn = KNeighborsClassifier(n_neighbors=19)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=19')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","7ed575e3":"## Standardize the Variables\n\n","0c952c87":" #                            Thanks !","ac4a1881":"# K Nearest Neighbors with Python\n\n\n\n","31780b77":"## Import Libraries\n\n","e315cd33":"## Get the Data\nclean data from my titanic kernel\n\nSet index_col=0 to use the first column as the index.","50d03554":"## Train Test Split","43dbe9ef":"## Predictions and Evaluations\n","f5b4ee8a":"## Using KNN\n\n","8a375879":"## Choosing a K Value\n\nLet's go ahead and use the elbow method to pick a good K Value:"}}