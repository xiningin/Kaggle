{"cell_type":{"b11f96ec":"code","385a709e":"code","9349fe7a":"code","316b7a18":"code","1fe90aed":"code","c1724647":"code","124f60d6":"code","f2c805d6":"code","68b9f73a":"code","a2fdf148":"code","2f2ae10f":"code","7f9ec4bb":"code","c88fd96b":"code","2c30592d":"code","7f3f4033":"code","b7382edb":"code","dbd2f49d":"code","b6584537":"code","c0efc1b8":"code","0be1b55e":"code","dc29da72":"code","5756388b":"code","6abdc358":"code","294b184a":"code","c7af9bf9":"code","90dda987":"code","b9884e4d":"code","f22e69f6":"code","77bc109a":"code","ee701f7e":"code","81ab246c":"code","af82cd40":"code","45d7ecbc":"code","42287c77":"code","d57757d5":"code","058114ba":"code","8c806852":"code","131f4bd3":"code","eb4ceb3c":"code","4671f0a0":"code","32803006":"code","e704998f":"code","aab2ad50":"code","39c28e7d":"code","293f2a30":"code","c038d25c":"code","f3c09fe4":"code","614989c4":"markdown","c37ac950":"markdown","a6abb043":"markdown","3e5abce5":"markdown","ffc01b5f":"markdown","5c2adb9f":"markdown","cec688b9":"markdown"},"source":{"b11f96ec":"import pandas as pd\nimport numpy as np\nimport datetime\nimport random\nimport time\nimport os\nimport gc\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss, confusion_matrix, classification_report\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import mode, skew, kurtosis\n\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#----------\npd.options.display.max_rows = 50\npd.options.display.max_columns = 50\n\nimport warnings\nwarnings.simplefilter('ignore')","385a709e":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\n\nall_df = pd.concat([train, test]).reset_index(drop=True)","9349fe7a":"train.value_counts('target')","316b7a18":"cat_features = ['feature_' + str(i) for i in range(0,75)]\ncnt_features = []","1fe90aed":"all_features = cat_features + cnt_features","c1724647":"train_c5417329_and_c86 = all_df.iloc[:200000].copy()","124f60d6":"train_c54173_and_c29 = all_df[all_df['target'].isin(['Class_9','Class_2','Class_3','Class_7', 'Class_1', 'Class_4', 'Class_5'])]\ntrain_c541_and_c73 = all_df[all_df['target'].isin(['Class_7', 'Class_3', 'Class_5', 'Class_4', 'Class_1'])]\ntrain_c54_and_c1 = all_df[all_df['target'].isin(['Class_5', 'Class_4', 'Class_1'])]","f2c805d6":"train_c8_and_c6 = all_df[(all_df['target'] == \"Class_6\") | (all_df['target'] == 'Class_8')]\ntrain_c2_and_c9 = all_df[(all_df['target'] == \"Class_9\") | (all_df['target'] == 'Class_2')]\ntrain_c7_and_c3 = all_df[(all_df['target'] == \"Class_3\") | (all_df['target'] == 'Class_7')]\ntrain_c5_and_c4 = all_df[(all_df['target'] == \"Class_4\") | (all_df['target'] == 'Class_5')]","68b9f73a":"mapping541732986 = {'Class_5': 0, 'Class_4': 0, 'Class_1': 0, 'Class_7': 0, 'Class_3': 0, 'Class_2': 0, 'Class_9': 0, 'Class_8': 1, 'Class_6': 1}\ntrain_c5417329_and_c86.replace({'target': mapping541732986}, inplace=True)","a2fdf148":"mapping5417329 = {'Class_5': 0, 'Class_4': 0, 'Class_1': 0, 'Class_7': 0, 'Class_3': 0, 'Class_2': 1, 'Class_9': 1}\ntrain_c54173_and_c29.replace({'target': mapping5417329}, inplace=True)\nmapping54173 = {'Class_5': 0, 'Class_4': 0 , 'Class_1': 0, 'Class_7': 1, 'Class_3': 1}\ntrain_c541_and_c73.replace({'target': mapping54173}, inplace=True)\nmapping541 = {'Class_5': 0, 'Class_4': 0, 'Class_1': 1}\ntrain_c54_and_c1.replace({'target': mapping541}, inplace=True)","2f2ae10f":"mapping86 = {'Class_8': 0, 'Class_6': 1}\nmapping29 = {'Class_2': 0, 'Class_9': 1}\nmapping73 = {'Class_7': 0, 'Class_3': 1}\nmapping54 = {'Class_5': 0, 'Class_4': 1}\n\ntrain_c8_and_c6.replace({'target': mapping86}, inplace=True)\ntrain_c2_and_c9.replace({'target': mapping29}, inplace=True)\ntrain_c7_and_c3.replace({'target': mapping73}, inplace=True)\ntrain_c5_and_c4.replace({'target': mapping54}, inplace=True)","7f9ec4bb":"c5417329c86 = train_c5417329_and_c86[all_features].to_numpy()\nc54173c29 = train_c54173_and_c29[all_features].to_numpy()\nc541c73 = train_c541_and_c73[all_features].to_numpy()\nc54c1 = train_c54_and_c1[all_features].to_numpy()\nt541732986 = train_c5417329_and_c86[['target']].to_numpy()\nt5417329 = train_c54173_and_c29[['target']].to_numpy()\nt54173 = train_c541_and_c73[['target']].to_numpy()\nt541 = train_c54_and_c1[['target']].to_numpy()","c88fd96b":"c8c6 = train_c8_and_c6[all_features].to_numpy()\nc2c9 = train_c2_and_c9[all_features].to_numpy()\nc7c3 = train_c7_and_c3[all_features].to_numpy()\nc5c4 = train_c5_and_c4[all_features].to_numpy()\ntest_npy = all_df.iloc[train.shape[0]:][all_features].to_numpy()\nt86 = train_c8_and_c6[['target']].to_numpy()\nt29 = train_c2_and_c9[['target']].to_numpy()\nt73 = train_c7_and_c3[['target']].to_numpy()\nt54 = train_c5_and_c4[['target']].to_numpy()","2c30592d":"def model(cat_shape=(75,)):\n    cat_input = tf.keras.layers.Input(shape=cat_shape, name='cat_input')\n        \n    x1 = tf.keras.layers.Embedding(512, 8, name='Embedding')(cat_input)\n    x1 = tf.keras.layers.Flatten(name='Flatten')(x1)\n    \n    x = tf.keras.layers.Dropout(0.4, name='dropout_concatenated')(x1)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(128, activation='relu', name='dense1')(x)\n    x = tf.keras.layers.Dense(64, activation='relu', name='dense2')(x)\n    x = tf.keras.layers.Dense(32, activation='relu', name='dense3')(x)\n    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n    \n    model = tf.keras.Model(cat_input, outputs)\n    \n    metrics = ['accuracy', tf.keras.metrics.BinaryCrossentropy(\n        from_logits=False,\n        label_smoothing=0,\n        name='binary_crossentropy'\n    )]\n    \n    loss = tf.keras.losses.BinaryCrossentropy(\n                from_logits=False,\n                label_smoothing=0,\n                reduction='auto',\n                name='binary_crossentropy'\n    )\n    \n    optimizer = tfa.optimizers.AdamW(\n        weight_decay=1e-7,\n        learning_rate=1e-4,\n        beta_1=0.9,\n        beta_2=0.999,\n        epsilon=1e-07,\n        amsgrad=True,\n        name='AdamW',\n    )\n    \n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    \n    return model\n\nmodel().summary()","7f3f4033":"scheduler_cb = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=2,\n    verbose=0,\n    mode='auto',\n    min_delta=0.0001,\n    cooldown=0,\n    min_lr=0\n)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    min_delta=0,\n    patience=5,\n    verbose=1,\n    mode='auto',\n    baseline=None,\n    restore_best_weights=True\n)","b7382edb":"K.clear_session()\nhistory541732986 = []\nmodel541732986 = model(cat_shape=c5417329c86[:, :len(cat_features)].shape[1])\nlog_dir = \"logs541732986\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir541732986', histogram_freq=1)\n\nhistory541732986.append(\n    model541732986.fit(\n        x=c5417329c86[:, :len(cat_features)],\n        y=t541732986,\n        steps_per_epoch=1000,\n        batch_size=256,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n    )\n)","dbd2f49d":"dfr = pd.DataFrame()\nall_df_all_features = all_df[all_features]\nall_df_numpy = all_df_all_features.to_numpy()","b6584537":"pred541732986 = pd.Series(model541732986.predict(all_df_numpy[:, :len(cat_features)]).flatten())","c0efc1b8":"dfr['Class_86'] = pred541732986\ndfr['Class_5417329'] = 1 - pred541732986","0be1b55e":"K.clear_session()\nhistory5417329 = []\nmodel5417329 = model(cat_shape=c54173c29[:, :len(cat_features)].shape[1])\nlog_dir = \"logs5417329\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir5417329', histogram_freq=1)\n\nhistory5417329.append(\n    model5417329.fit(\n        x=c54173c29[:, :len(cat_features)],\n        y=t5417329,\n        steps_per_epoch=1000,\n        batch_size=128,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n    )\n)","dc29da72":"pred5417329 = pd.Series(model5417329.predict(all_df_numpy[:, :len(cat_features)]).flatten())","5756388b":"dfr['Class_29'] = pred5417329\ndfr['Class_54173'] = 1 - pred5417329","6abdc358":"K.clear_session()\nhistory54173 = []\nmodel54173 = model(cat_shape=c541c73[:, :len(cat_features)].shape[1])\nlog_dir = \"logs54173\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir54173', histogram_freq=1)\n\nhistory54173.append(\n    model54173.fit(\n        x=c541c73[:, :len(cat_features)],\n        y=t54173,\n        steps_per_epoch=1000,\n        batch_size=64,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n    )\n)","294b184a":"pred54173 = pd.Series(model54173.predict(all_df_numpy[:, :len(cat_features)]).flatten())","c7af9bf9":"dfr['Class_73'] = pred54173\ndfr['Class_541'] = 1 - pred54173","90dda987":"K.clear_session()\nhistory86 = []\nmodel86 = model(cat_shape=c8c6[:, :len(cat_features)].shape[1])\nlog_dir = \"logs86\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir86', histogram_freq=1)\n\nhistory86.append(\n    model86.fit(\n        x=c8c6[:, :len(cat_features)],\n        y=t86,\n        steps_per_epoch=1000,\n        batch_size=128,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n    )\n)","b9884e4d":"pred86 = pd.Series(model86.predict(all_df_numpy[:, :len(cat_features)]).flatten())","f22e69f6":"dfr['Class_6'] = pred86\ndfr['Class_8'] = 1- pred86","77bc109a":"history29 = []\nmodel29 = model(cat_shape=c2c9[:, :len(cat_features)].shape[1])\nlog_dir = \"logs29\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir29', histogram_freq=1)\n\nhistory29.append(\n    model29.fit(\n        x=c2c9[:, :(len(cat_features))],\n        y=t29,\n        steps_per_epoch=1000,\n        batch_size=64,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n        #verbose=CFG['verbose']\n    )\n)","ee701f7e":"pred29 = pd.Series(model29.predict(all_df_numpy[:, :len(cat_features)]).flatten())","81ab246c":"dfr['Class_9'] = pred29\ndfr['Class_2'] = 1 - pred29","af82cd40":"history73 = []\nmodel73 = model(cat_shape=c7c3[:, :len(cat_features)].shape[1])\nlog_dir = \"logs73\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir73', histogram_freq=1)\n\nhistory73.append(\n    model73.fit(\n        x=c7c3[:, :(len(cat_features))],\n        y=t73,\n        steps_per_epoch=1000,\n        batch_size=32,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n    )\n)","45d7ecbc":"pred73 = pd.Series(model73.predict(all_df_numpy[:, :len(cat_features)]).flatten())","42287c77":"dfr['Class_3'] = pred73\ndfr['Class_7'] = 1 - pred73","d57757d5":"history54 = []\nmodel54 = model(cat_shape=c5c4[:, :len(cat_features)].shape[1])\nlog_dir = \"logs54\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir54', histogram_freq=1)\n\nhistory54.append(\n    model54.fit(\n        x=c5c4[:, :(len(cat_features))],\n        y=t54,\n        steps_per_epoch=1000,\n        batch_size=16,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n    )\n)","058114ba":"pred54 = pd.Series(model54.predict(all_df_numpy[:, :len(cat_features)]).flatten())","8c806852":"dfr['Class_4'] = pred54\ndfr['Class_5'] = 1 - pred54","131f4bd3":"history541 = []\nmodel541 = model(cat_shape=c54c1[:, :len(cat_features)].shape[1])\nlog_dir = \"logs541\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='log_dir541', histogram_freq=1)\n\nhistory541.append(\n    model541.fit(\n        x=c54c1[:, :(len(cat_features))],\n        y=t541,\n        steps_per_epoch=1000,\n        batch_size=32,\n        epochs=50,\n        validation_split=0.2,\n        callbacks=[scheduler_cb, early_stopping_cb, tensorboard_cb]\n    )\n)","eb4ceb3c":"pred541 = pd.Series(model541.predict(all_df_numpy[:, :len(cat_features)]).flatten())","4671f0a0":"dfr['Class_1'] = pred541\ndfr['Class_54'] = 1 - pred541","32803006":"dfr.head(30)","e704998f":"df = dfr.copy()\n#df['id'] = [i for i in range(0,100000)]\n#df = df.set_index('id')\ndisplay(df)\nresult = pd.DataFrame()\nresult['Class_1'] = dfr['Class_5417329'] * dfr['Class_54173'] * dfr['Class_541'] * dfr['Class_1']\nresult['Class_2'] = dfr['Class_5417329'] * dfr['Class_29'] * dfr['Class_2'] \nresult['Class_3'] = dfr['Class_5417329'] * dfr['Class_54173'] * dfr['Class_73'] * dfr['Class_3'] \nresult['Class_4'] = dfr['Class_5417329'] * dfr['Class_54173'] * dfr['Class_541'] * dfr['Class_54'] * dfr['Class_4'] \nresult['Class_5'] = dfr['Class_5417329'] * dfr['Class_54173'] * dfr['Class_541'] * dfr['Class_54'] * dfr['Class_5'] \nresult['Class_6'] = dfr['Class_86'] * dfr['Class_6'] \nresult['Class_7'] = dfr['Class_5417329'] * dfr['Class_54173'] * dfr['Class_73'] * dfr['Class_7'] \nresult['Class_8'] = dfr['Class_86'] * dfr['Class_8'] \nresult['Class_9'] = dfr['Class_5417329'] * dfr['Class_29'] * dfr['Class_9'] \nresult","aab2ad50":"display(result.head(10))\ntrain['target'].head(10)","39c28e7d":"ohe = OneHotEncoder()\ntmp = [int(i)-1 for i in (train['target'].str.split('_',expand=True))[1]]\ntrain['predicted'] = np.argmax(result.iloc[:200000].to_numpy(), axis=1).flatten().reshape(-1,1)\ntrain_true = ohe.fit_transform(np.array(tmp).reshape(-1,1))\nprint(log_loss(train_true,  result.iloc[:200000].to_numpy()))\ndisplay( train[tmp != train['predicted']][['target', 'predicted']].value_counts())\n#test_pred.shape\n#sample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\n#print(sample)","293f2a30":"display(result.iloc[2])\ndisplay(train.iloc[2])","c038d25c":"#sub = pd.DataFrame(test_pred.data, columns=['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\nsub = result.iloc[200000:].copy()\nsub.insert(0, 'id', [id for id in range(200000,300000,1)])\nprint(sub)\ncsv = 'submission_hierarchy_of_classifiers3.csv'\nsub.to_csv(csv, index = False)","f3c09fe4":"from IPython.display import FileLink\nFileLink(csv)","614989c4":"The idea behind using hierarchy of binary classifiers is that the set of classes in training data has similar set of examples for a set of pair of classes. For eg.\n\n* Class_6    51811    &    Class_8    51763\n* Class_9    25542    &    Class_2    24431\n* Class_3    14798    &    Class_7    14769\n* Class_1     9118\n* Class_4     4704    &    Class_5     3064\n\nSo, I use a hierarchy of classifiers to classify into different classses\n\n                                68_vs_9273145\n                                   \/    \\\n                                  \/      \\\n                              6_vs_8    92_vs_73145\n                                          \/     \\\n                                         \/       \\\n                                     9_vs_2     73_vs_145\n                                                 \/     \\\n                                                \/       \\\n                                              7_vs_3    1_vs_45\n                                                         \/    \\\n                                                        \/      \\\n                                                        1     4_vs_5","c37ac950":"# Extract train data and corresponding targets for the hierarchy of models","a6abb043":"# Load Data","3e5abce5":"# Train the models","ffc01b5f":"# Define the Model, Losses, Metrics and Callbacks","5c2adb9f":"# LIBRARIES","cec688b9":"# Hierarchy of binary classifiers\n---\n\n## Reference\n* [Simple Keras embedding in 10 folds](https:\/\/www.kaggle.com\/pourchot\/simple-keras-embedding-in-10-folds) by [@pourchot](https:\/\/www.kaggle.com\/pourchot)\n* [Combining discrete and continuous features in neural networks](https:\/\/www.kaggle.com\/hiro5299834\/tps06-nn-w-discrete-and-continuous-features) by [@bizen](https:\/\/www.kaggle.com\/hiro5299834)"}}