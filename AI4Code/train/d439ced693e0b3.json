{"cell_type":{"ea0d14e7":"code","af9fdcbe":"code","2a2866da":"code","1f058bfe":"code","eb1d87bf":"code","f687bd15":"code","26d5103d":"code","2cb10219":"code","5fdec4a0":"code","4209dc9a":"code","0dee0630":"code","26e25ea9":"code","b2792f57":"code","57039111":"code","572f030a":"code","deb86cda":"code","8385467e":"code","17aa53eb":"code","23fcb514":"code","db74856e":"markdown","c9751e5a":"markdown","cfb0e3e7":"markdown","e9a04951":"markdown","aa9df8d7":"markdown","72c6ca4b":"markdown","5c540f2c":"markdown","f4af2a16":"markdown","33109e2d":"markdown","72197690":"markdown","125b5e25":"markdown","adbe15be":"markdown","e8230e95":"markdown","df1093dc":"markdown","efb3f3b4":"markdown","bd5a8513":"markdown"},"source":{"ea0d14e7":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport time\nimport glob\nimport imageio\nfrom IPython import display\nimport cv2\nimport pathlib\nimport zipfile\nimport torch\nimport sys\nimport pandas as pd \n\nimport torchvision\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset\nfrom torchvision.utils import make_grid\nimport torch.optim as optim\nfrom torchvision.datasets import MNIST\n\nfrom skimage import io, transform\n\n!pip install torchsummary\nfrom torchsummary import summary\n\nfrom torch.utils.tensorboard import SummaryWriter","af9fdcbe":"# Decide which device we want to run on\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","2a2866da":"class Generator(nn.Module):\n\n    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n        super(Generator, self).__init__()\n        \n        self.z_dim = z_dim\n        \n        self.gen = nn.Sequential(\n            \n            self.get_generator_block(z_dim, \n                                     hidden_dim * 4,\n                                     kernel_size=3, \n                                     stride=2),\n            \n            self.get_generator_block(hidden_dim * 4, \n                                     hidden_dim * 2,\n                                     kernel_size=4,\n                                     stride = 1),\n            \n            self.get_generator_block(hidden_dim * 2,\n                                     hidden_dim ,\n                                     kernel_size=3,\n                                     stride = 2,\n                                    ),\n\n            self.get_generator_final_block(hidden_dim,\n                                           im_chan,\n                                           kernel_size=4,\n                                           stride=2)\n            \n\n        )\n        \n        \n    def get_generator_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return nn.Sequential(\n                nn.ConvTranspose2d(input_channel, output_channel, kernel_size, stride, padding),\n                nn.BatchNorm2d(output_channel),\n                nn.ReLU(inplace=True),\n        )\n    \n    \n    def get_generator_final_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return  nn.Sequential(\n                nn.ConvTranspose2d(input_channel, output_channel, kernel_size, stride, padding),\n                nn.Tanh()\n            )\n    \n    \n    def forward(self, noise):\n        x = noise.view(len(noise), self.z_dim, 1, 1)\n        return self.gen(x)\n    \n    \n    \nsummary(Generator(100).to(device), (100,))\nprint(Generator(100))","1f058bfe":"class Critic(nn.Module):\n\n    def __init__(self, im_chan=1, hidden_dim=16):\n        super(Critic, self).__init__()\n        self.disc = nn.Sequential(\n            self.get_critic_block(im_chan,\n                                         hidden_dim * 4,\n                                         kernel_size=4,\n                                         stride=2),\n            \n            self.get_critic_block(hidden_dim * 4,\n                                         hidden_dim * 8,\n                                         kernel_size=4,\n                                         stride=2,),\n            \n            self.get_critic_final_block(hidden_dim * 8,\n                                               1,\n                                               kernel_size=4,\n                                               stride=2,),\n\n        )\n\n        \n    def get_critic_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return nn.Sequential(\n                nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),\n                nn.BatchNorm2d(output_channel),\n                nn.LeakyReLU(0.2, inplace=True)\n        )\n    \n    \n    def get_critic_final_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return  nn.Sequential(\n                nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),\n            )\n    \n    def forward(self, image):\n        return self.disc(image)\n    \nsummary(Critic().to(device) , (1,28,28))\nprint(Critic())","eb1d87bf":"def get_noise(n_samples, z_dim, device='cpu'):\n    return torch.randn(n_samples,z_dim,device=device)","f687bd15":"z_dim = 100\nbatch_size = 128\n\nfixed_noise = get_noise(batch_size, z_dim, device=device)\n\ntrain_transform = transforms.Compose([\n    transforms.ToTensor(),\n])\n\ndataloader = DataLoader(\n    MNIST('.', download=True, transform=train_transform),\n    batch_size=batch_size,\n    shuffle=True)","26d5103d":"start = time.time()\ndataiter = iter(dataloader)\nimages,labels = dataiter.next()\nprint ('Time is {} sec'.format(time.time()-start))\n\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(make_grid(images.to(device), padding=2, normalize=True).cpu(),(1,2,0)))\n\nprint('Shape of loading one batch:', images.shape)\nprint('Total no. of batches present in trainloader:', len(dataloader))","2cb10219":"lr = 0.0002\nbeta_1 = 0.5 \nbeta_2 = 0.999\n\ndef weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    if isinstance(m, nn.BatchNorm2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n        torch.nn.init.constant_(m.bias, 0)\n\n        \ngen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n\ncrit  = Critic().to(device) \ncrit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(beta_1, beta_2))\n\ngen = gen.apply(weights_init)\ncrit = crit.apply(weights_init)        ","5fdec4a0":"# test = get_noise(batch_size, z_dim, device=device)\n# test_gan = gen(test)\n# grid_img = np.transpose(make_grid(test_gan[0].to(device), padding=2, normalize=True).cpu().detach(),(1,2,0))\n\n# plt.figure(figsize=(8,8))\n# plt.axis(\"off\")\n# plt.title(\"Training Images\")\n# plt.imshow(grid_img)","4209dc9a":"def gradient_penalty(gradient):\n    gradient = gradient.view(len(gradient), -1)\n\n    gradient_norm = gradient.norm(2, dim=1)\n    \n    penalty = torch.mean((gradient_norm - 1)**2)\n    return penalty","0dee0630":"def get_gen_loss(crit_fake_pred):\n    gen_loss = -1. * torch.mean(crit_fake_pred)\n    return gen_loss","26e25ea9":"def get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda):\n    crit_loss = torch.mean(crit_fake_pred) - torch.mean(crit_real_pred) + c_lambda * gp\n    return crit_loss","b2792f57":"def get_gradient(crit, real, fake, epsilon):\n\n    mixed_images = real * epsilon + fake * (1 - epsilon)\n\n    mixed_scores = crit(mixed_images)\n    \n    gradient = torch.autograd.grad(\n        inputs=mixed_images,\n        outputs=mixed_scores,\n        grad_outputs=torch.ones_like(mixed_scores), \n        create_graph=True,\n        retain_graph=True,\n        \n    )[0]\n    return gradient","57039111":"def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), show_fig=False, epoch=0):\n    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.axis('off')\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    if show_fig:\n        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n        \n    plt.show()","572f030a":"n_epochs = 10\ncur_step = 0\ntotal_steps = 0\nstart_time = time.time()\ncur_step = 0\n\ngenerator_losses = []\ncritic_losses = []\n\nC_mean_losses = []\nG_mean_losses = []\n\nc_lambda = 10\ncrit_repeats = 5\ndisplay_step = 50\n\nfor epoch in range(n_epochs):\n    cur_step = 0\n    start = time.time()\n    for real, _ in dataloader:\n        cur_batch_size = len(real)\n        real = real.to(device)\n\n        mean_iteration_critic_loss = 0\n        for _ in range(crit_repeats):\n            ### Update critic ###\n            crit_opt.zero_grad()\n            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n            fake = gen(fake_noise)\n            crit_fake_pred = crit(fake.detach())\n            crit_real_pred = crit(real)\n\n            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n            gradient = get_gradient(crit, real, fake.detach(), epsilon)\n            gp = gradient_penalty(gradient)\n            crit_loss = get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda)\n\n            # Keep track of the average critic loss in this batch\n            mean_iteration_critic_loss += crit_loss.item() \/ crit_repeats\n            # Update gradients\n            crit_loss.backward(retain_graph=True)\n            # Update optimizer\n            crit_opt.step()\n        critic_losses += [mean_iteration_critic_loss]\n\n        ### Update generator ###\n        gen_opt.zero_grad()\n        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n        fake_2 = gen(fake_noise_2)\n        crit_fake_pred = crit(fake_2)\n        \n        gen_loss = get_gen_loss(crit_fake_pred)\n        gen_loss.backward()\n\n        # Update the weights\n        gen_opt.step()\n\n        # Keep track of the average generator loss\n        generator_losses += [gen_loss.item()]\n        \n        cur_step += 1\n        total_steps += 1\n        \n        print_val = f\"Epoch: {epoch}\/{n_epochs} Steps:{cur_step}\/{len(dataloader)}\\t\"\n        print_val += f\"Epoch_Run_Time: {(time.time()-start):.6f}\\t\"\n        print_val += f\"Loss_C : {mean_iteration_critic_loss:.6f}\\t\"\n        print_val += f\"Loss_G : {gen_loss:.6f}\\t\"  \n        print(print_val, end='\\r',flush = True)\n\n        ### Visualization code ###\n#         if cur_step % display_step == 0 and cur_step > 0:\n#             print()\n#             gen_mean = sum(generator_losses[-display_step:]) \/ display_step\n#             crit_mean = sum(critic_losses[-display_step:]) \/ display_step\n#             print(f\"Step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n#             show_tensor_images(fake)\n#             show_tensor_images(real)\n#             step_bins = 20\n#             num_examples = (len(generator_losses) \/\/ step_bins) * step_bins\n#             plt.plot(\n#                 range(num_examples \/\/ step_bins), \n#                 torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n#                 label=\"Generator Loss\"\n#             )\n#             plt.plot(\n#                 range(num_examples \/\/ step_bins), \n#                 torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n#                 label=\"Critic Loss\"\n#             )\n#             plt.legend()\n#             plt.show()\n\n    print()\n    gen_mean = sum(generator_losses[-cur_step:]) \/ cur_step\n    crit_mean = sum(critic_losses[-cur_step:]) \/ cur_step\n    \n    C_mean_losses.append(crit_mean)\n    G_mean_losses.append(gen_mean)\n    \n    print_val = f\"Epoch: {epoch}\/{n_epochs} Total Steps:{total_steps}\\t\"\n    print_val += f\"Total_Time : {(time.time() - start_time):.6f}\\t\"\n    print_val += f\"Loss_C : {mean_iteration_critic_loss:.6f}\\t\"\n    print_val += f\"Loss_G : {gen_loss:.6f}\\t\"\n    print_val += f\"Loss_C_Mean : {crit_mean:.6f}\\t\"\n    print_val += f\"Loss_G_Mean : {gen_mean:.6f}\\t\"\n    print(print_val)\n    \n    fake_noise = fixed_noise\n    fake = gen(fake_noise)\n    \n    show_tensor_images(fake, show_fig=True,epoch=epoch)\n    \n    cur_step = 0\n    ","deb86cda":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(generator_losses,label=\"G-Loss\")\nplt.plot(critic_losses,label=\"C-Loss\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","8385467e":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_mean_losses,label=\"G-Loss\")\nplt.plot(C_mean_losses,label=\"C-Loss\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","17aa53eb":"anim_file = 'WGAN-GAN.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\n\n!pip install -q git+https:\/\/github.com\/tensorflow\/docs\nimport tensorflow_docs.vis.embed as embed\nembed.embed_file(anim_file)","23fcb514":"def show_new_gen_images(tensor_img, num_img=25):\n    tensor_img = (tensor_img + 1) \/ 2\n    unflat_img = tensor_img.detach().cpu()\n    img_grid = make_grid(unflat_img[:num_img], nrow=5)\n    plt.imshow(img_grid.permute(1, 2, 0).squeeze(),cmap='gray')\n    plt.show()\n\nnum_image = 25\nnoise = get_noise(num_image, z_dim, device=device)\nwith torch.no_grad():\n    fake_img = gen(noise)\n\nshow_new_gen_images(fake_img.reshape(num_image,1,28,28))","db74856e":"# Animated GIF Create & Show","c9751e5a":"# Device Mode","cfb0e3e7":"# MNIST Dataset Load","e9a04951":"# Noise Creator Function","aa9df8d7":"# Generator","72c6ca4b":"# Critic \/ Discriminator","5c540f2c":"# After Tranning Loss Visualization","f4af2a16":"# Wasserstein GAN (WGAN)","33109e2d":"# Model Training Process","72197690":"# Loaded Data Visualization","125b5e25":"# Loss","adbe15be":"# Resources\n\n[ProteinGAN](https:\/\/colab.research.google.com\/github\/https-deeplearning-ai\/GANs-Public\/blob\/master\/ProteinGAN.ipynb)\n\n[GAN to WGAN ](https:\/\/lilianweng.github.io\/lil-log\/2017\/08\/20\/from-GAN-to-WGAN.html)\n\n[Improved Training of Wasserstein GANs (Gulrajani et al., 2017)](https:\/\/arxiv.org\/abs\/1704.00028)\n\n[Wasserstein GAN (Arjovsky, Chintala, and Bottou, 2017))](https:\/\/arxiv.org\/abs\/1701.07875)","e8230e95":"# Gradient Penalty","df1093dc":"# Testing WGAN","efb3f3b4":"# Optimizer","bd5a8513":"# Import Packages"}}