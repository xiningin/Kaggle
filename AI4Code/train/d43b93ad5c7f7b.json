{"cell_type":{"66e929a8":"code","1ea48a62":"code","c510ef42":"code","ecc6f02c":"code","06a8ed6c":"code","bf5d02db":"code","41dbd675":"code","8bdf3236":"code","c647a19e":"code","401d9034":"code","39b7c416":"markdown","341387d6":"markdown","c97e2b4b":"markdown","83795ef0":"markdown","2895f843":"markdown","85d51a5c":"markdown"},"source":{"66e929a8":"import os\nfrom scipy import stats\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans","1ea48a62":"path = '..\/input\/tabular-playground-series-sep-2021'\n# Input data files are available in the \"..\/input\/\" directory.\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c510ef42":"def load_data(source, dtypes, path=path):\n    ''' load tables '''\n    assert source in ['train', 'test']\n    df = pd.read_csv(f'{path}\/{source}.csv', index_col=\"id\", dtype= dtypes)\n    return df","ecc6f02c":"%%time\ntrain = load_data('train', None)\nprint(f\"Data shape: {train.shape}\")\ntrain.sample(2)","06a8ed6c":"target_name = \"claim\"\nfeatures = [col for col in train.columns if col not in [target_name]]","bf5d02db":"mns = MinMaxScaler()\nmns.fit(train)\ntrain_scaled = mns.transform(train)\ntrain_scaled = pd.DataFrame(train_scaled, columns=train.columns)","41dbd675":"SSD_DIFF_TH = 6000\nMULTIMODAL_TH = 100000\nMODE_SKEW_TH = 0.8\nMODE_KURTOSIS_TH = -1.4\nMEAN_SKEW_TH = 0.4","8bdf3236":"def optimum_filler(df, col_name, ssd_dif_threshold, multimodal_threshold, mode_skew_threshold, mode_kurtosis_threshold, mean_skew_threshold):\n    skew = stats.skew(df[col_name].values, nan_policy=\"omit\").mean()\n    kurtosis = stats.kurtosis(df[col_name].values, nan_policy=\"omit\").mean()\n        \n    K = range(1,4)\n    Sum_of_squared_distance = []\n    data = df[col_name].dropna().values.reshape(-1, 1)\n    km = None\n    nomal_flag = True\n    \n    # Using KMeans to test the different cluster configurations.\n    for k in K:\n        km = KMeans(n_clusters=k)\n        km = km.fit(data.reshape(-1, 1))\n        Sum_of_squared_distance.append(km.inertia_)\n        ssd_dif = np.abs(np.diff(Sum_of_squared_distance[-2:]))\n        \n        if len(ssd_dif) == 0:\n            pass\n        elif ssd_dif > ssd_dif_threshold:\n            # print(f\"Break on k: {k}\")\n            nomal_flag = False\n            break\n    \n    if not nomal_flag:\n        unique, counts = np.unique(km.labels_, return_counts=True)\n        counts_dif = np.abs(np.diff(counts[-2:]))\n        \n        \n        if counts_dif > multimodal_threshold:\n            if (-mode_skew_threshold < skew < mode_skew_threshold) and kurtosis < mode_kurtosis_threshold:\n                return \"Mode\"\n            else:\n                return \"Median\"\n        else:\n                return \"Mode\"\n        \n    else:\n        return \"Mean\"","c647a19e":"%time\nfill_nan_dic = {}\nfor col_name in tqdm(features):\n    name_nanfill =  optimum_filler(train_scaled, col_name, SSD_DIFF_TH, MULTIMODAL_TH, MODE_SKEW_TH, MODE_KURTOSIS_TH, MEAN_SKEW_TH)\n    fill_nan_dic[col_name] = name_nanfill","401d9034":"fill_nan_dic","39b7c416":"# Upload data","341387d6":"# Statistics","c97e2b4b":"### Elbow Method to determine number of clusters","83795ef0":"### Scaling data set","2895f843":"* **Skewness** is a measure of symmetry, or more precisely, the lack of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.\n    * If the skewness is between -0.5 and 0.5, the data are fairly symmetrical.\n    * If the skewness is between -1 and -0.5(negatively skewed) or between 0.5 and 1(positively skewed), the data are moderately skewed.\n    * If the skewness is less than -1(negatively skewed) or greater than 1(positively skewed), the data are highly skewed.\n        \n        \n\n* **Kurtosis** is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution.\n    * Mesokurtic: This distribution has kurtosis statistic similar to that of the normal distribution. It means that the extreme values of the distribution are similar to that of a normal distribution characteristic. This definition is used so that the standard normal distribution has a kurtosis of three.\n    * Leptokurtic (Kurtosis > 3): Distribution is longer, tails are fatter. Peak is higher and sharper than Mesokurtic, which means that data are heavy-tailed or profusion of outliers. Outliers stretch the horizontal axis of the histogram graph, which makes the bulk of the data appear in a narrow (\u201cskinny\u201d) vertical range, thereby giving the \u201cskinniness\u201d of a leptokurtic distribution.\n\n    * Platykurtic: (Kurtosis < 3): Distribution is shorter, tails are thinner than the normal distribution. The peak is lower and broader than Mesokurtic, which means that data are light tailed or lack of outliers. The reason for this is because the extreme values are less than that of the normal distribution.","85d51a5c":"# Creating fill nan Dictionary\n1. **KMeans** to test the different cluster configurations.\n2. **Elbow Method** to check if there are more than one cluster:\n    * NO: Fill nan values with **MEAN** is the better solution.\n    * YES: Check if the data is equally distributed between clusters.\n        * YES: Fill nan values with **MODE** is the better solution.\n        * NO: Play with Kurtosis and skewness to determine if it is better to fill de nan values with **MODE**, **MEDIAN**."}}