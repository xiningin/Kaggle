{"cell_type":{"253d5da4":"code","d51146c5":"code","874dc0d1":"code","d8d0619f":"code","cbb92317":"code","9a48c328":"code","5d65410b":"code","2230ade8":"code","829b7512":"code","15eb02d3":"code","3c92475e":"code","d55a346e":"code","3f590ebc":"code","b180d10f":"code","464b2e76":"code","20007fd8":"code","de2973d5":"code","09599708":"code","8ca42bde":"code","f9b35e8d":"code","0b15a756":"code","2035f3a3":"code","8791db04":"code","a1558961":"code","4b0e19ae":"code","590111d0":"code","a9c30bee":"code","ed14f9a3":"code","04c4a4f5":"code","155ea6a4":"code","4c893ecd":"code","3da5fe95":"code","616fcef6":"code","bde0948d":"code","f6b0137c":"code","250c7825":"code","d45ff031":"code","e31c104c":"code","7329d7b0":"code","76bd66d9":"code","aac4683b":"code","c3219214":"code","602c5ecd":"code","29e52c2e":"code","22ac5342":"code","d4097e51":"code","355cdf7d":"code","d34d3150":"code","850c99de":"code","d3f2e1b7":"code","71438122":"code","3ede0f4c":"code","e0b8de10":"code","0cb01f59":"code","ba662b88":"code","595e735a":"code","fa8e2e16":"code","27eb37ca":"code","0c2b9336":"code","2da9665c":"code","4d316b8c":"code","7d0cb5a3":"code","ff2853b3":"code","e602f79f":"code","54170e94":"code","d6024f39":"code","aba1ec95":"code","47a029d7":"code","e2e12a70":"code","14248e2a":"code","f2d6b6b6":"code","440f2e0f":"code","51f6d52f":"code","327e25ae":"code","140dde3f":"code","43b24fcc":"code","0331eaff":"code","22128c47":"code","051be987":"code","c41ef737":"markdown","24588b27":"markdown","b00bbb02":"markdown","83949c3e":"markdown","3cf4d6da":"markdown","0462de37":"markdown","18f11021":"markdown","8d7bac58":"markdown","ed6b1cd2":"markdown","56bd76a4":"markdown","f4df4c0d":"markdown","eb35f8b5":"markdown","107766fb":"markdown","b285a0e6":"markdown","e4122b29":"markdown","3e69535f":"markdown","4d02580e":"markdown","de133de7":"markdown","bef01037":"markdown","4da0ba73":"markdown","ba595fb5":"markdown","7d6c58ab":"markdown","c7f96ed4":"markdown","e469e7fe":"markdown","ea28fe5b":"markdown","9c8026c6":"markdown","551c96b4":"markdown","2e66dc05":"markdown","7afbbbb8":"markdown","c988d094":"markdown","66db5274":"markdown","a38057c2":"markdown","ce1190a5":"markdown","4b977ae1":"markdown","35e0b986":"markdown","dd794326":"markdown","41f979c4":"markdown","4a95e949":"markdown","507c297d":"markdown","df0a381d":"markdown","30ee719c":"markdown","064acbaf":"markdown","c86c26fd":"markdown","22ff2fb5":"markdown","2c7b97b4":"markdown","bdaf2663":"markdown","bad32670":"markdown","84d253d6":"markdown","5af15fa9":"markdown","19f6828f":"markdown","83442f66":"markdown","b8e1b769":"markdown","3815cce9":"markdown","8e7cfcb8":"markdown","d1e9eb1f":"markdown"},"source":{"253d5da4":"# pandas and numpy for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Suppress warnings from pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')","d51146c5":"# Read in bureau\nbureau = pd.read_csv('..\/input\/bureau.csv')\nbureau.head()","874dc0d1":"# Groupby the client id (SK_ID_CURR), count the number of previous loans, and rename the column\nprevious_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\nprevious_loan_counts.head()","d8d0619f":"# Join to the training dataframe\ntrain = pd.read_csv('..\/input\/application_train.csv')\ntrain = train.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n\n# Fill the missing values with 0 \ntrain['previous_loan_counts'] = train['previous_loan_counts'].fillna(0)\ntrain.head()","cbb92317":"# Plots the disribution of a variable colored by value of the target\ndef kde_target(var_name, df):\n    \n    # Calculate the correlation coefficient between the new variable and the target\n    corr = df['TARGET'].corr(df[var_name])\n    \n    # Calculate medians for repaid vs not repaid\n    avg_repaid = df.ix[df['TARGET'] == 0, var_name].median()\n    avg_not_repaid = df.ix[df['TARGET'] == 1, var_name].median()\n    \n    plt.figure(figsize = (12, 6))\n    \n    # Plot the distribution for target == 0 and target == 1\n    sns.kdeplot(df.ix[df['TARGET'] == 0, var_name], label = 'TARGET == 0')\n    sns.kdeplot(df.ix[df['TARGET'] == 1, var_name], label = 'TARGET == 1')\n    \n    # label the plot\n    plt.xlabel(var_name)\n    plt.ylabel('Density')\n    plt.title('%s Distribution' % var_name)\n    plt.legend()\n    \n    # print out the correlation\n    print('The correlation between %s and the TARGET is %0.4f' % (var_name, corr))\n    # Print out average values\n    print('Median value for loan that was not repaid = %0.4f' % avg_not_repaid)\n    print('Median value for loan that was repaid =     %0.4f' % avg_repaid)","9a48c328":"kde_target('EXT_SOURCE_3', train)","5d65410b":"kde_target('previous_loan_counts', train)","2230ade8":"# Group by the client id, calculate aggregation statistics\nbureau_agg = bureau.drop(columns = ['SK_ID_BUREAU']).groupby('SK_ID_CURR', as_index = False).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\nbureau_agg.head()","829b7512":"# List of column names\ncolumns = ['SK_ID_CURR']\n\n# Iterate through the variables names\nfor var in bureau_agg.columns.levels[0]:\n    # Skip the id name\n    if var != 'SK_ID_CURR':\n        \n        # Iterate through the stat names\n        for stat in bureau_agg.columns.levels[1][:-1]:\n            # Make a new column name for the variable and stat\n            columns.append('bureau_%s_%s' % (var, stat))","15eb02d3":"bureau_agg.columns = columns\nbureau_agg.head()","3c92475e":"# Merge with the training data\ntrain = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\ntrain.head()","d55a346e":"# List of new correlations\nnew_corrs = []\n\n# Iterate through the columns \nfor col in columns:\n    # Calculate correlation with the target\n    corr = train['TARGET'].corr(train[col])\n    \n    # Append the list as a tuple\n\n    new_corrs.append((col, corr))","3f590ebc":"# Sort the correlations by the absolute value\n# Make sure to reverse to put the largest values at the front of list\nnew_corrs = sorted(new_corrs, key = lambda x: abs(x[1]), reverse = True)\nnew_corrs[:15]","b180d10f":"kde_target('bureau_DAYS_CREDIT_mean', train)","464b2e76":"def agg_numeric(df, group_var, df_name):\n    \"\"\"Aggregates the numeric values in a dataframe. This can\n    be used to create features for each instance of the grouping variable.\n    \n    Parameters\n    --------\n        df (dataframe): \n            the dataframe to calculate the statistics on\n        group_var (string): \n            the variable by which to group df\n        df_name (string): \n            the variable used to rename the columns\n        \n    Return\n    --------\n        agg (dataframe): \n            a dataframe with the statistics aggregated for \n            all numeric columns. Each instance of the grouping variable will have \n            the statistics (mean, min, max, sum; currently supported) calculated. \n            The columns are also renamed to keep track of features created.\n    \n    \"\"\"\n    # Remove id variables other than grouping variable\n    for col in df:\n        if col != group_var and 'SK_ID' in col:\n            df = df.drop(columns = col)\n            \n    group_ids = df[group_var]\n    numeric_df = df.select_dtypes('number')\n    numeric_df[group_var] = group_ids\n\n    # Group by the specified variable and calculate the statistics\n    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n\n    # Need to create new column names\n    columns = [group_var]\n\n    # Iterate through the variables names\n    for var in agg.columns.levels[0]:\n        # Skip the grouping variable\n        if var != group_var:\n            # Iterate through the stat names\n            for stat in agg.columns.levels[1][:-1]:\n                # Make a new column name for the variable and stat\n                columns.append('%s_%s_%s' % (df_name, var, stat))\n\n    agg.columns = columns\n    return agg","20007fd8":"bureau_agg_new = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_agg_new.head()","de2973d5":"bureau_agg.head()","09599708":"# Function to calculate correlations with the target for a dataframe\ndef target_corrs(df):\n\n    # List of correlations\n    corrs = []\n\n    # Iterate through the columns \n    for col in df.columns:\n        print(col)\n        # Skip the target column\n        if col != 'TARGET':\n            # Calculate correlation with the target\n            corr = df['TARGET'].corr(df[col])\n\n            # Append the list as a tuple\n            corrs.append((col, corr))\n            \n    # Sort by absolute magnitude of correlations\n    corrs = sorted(corrs, key = lambda x: abs(x[1]), reverse = True)\n    \n    return corrs","8ca42bde":"categorical = pd.get_dummies(bureau.select_dtypes('object'))\ncategorical['SK_ID_CURR'] = bureau['SK_ID_CURR']\ncategorical.head()","f9b35e8d":"# \u6c42\u548c\u4e0e\u5f52\u4e00\u5316\ncategorical_grouped = categorical.groupby('SK_ID_CURR').agg(['sum', 'mean'])\ncategorical_grouped.head()","0b15a756":"categorical_grouped.columns.levels[0][:10]","2035f3a3":"categorical_grouped.columns.levels[1]","8791db04":"group_var = 'SK_ID_CURR'\n\n# Need to create new column names\ncolumns = []\n\n# Iterate through the variables names\nfor var in categorical_grouped.columns.levels[0]:\n    # Skip the grouping variable\n    if var != group_var:\n        # Iterate through the stat names\n        for stat in ['count', 'count_norm']:\n            # Make a new column name for the variable and stat\n            columns.append('%s_%s' % (var, stat))\n\n#  Rename the columns\ncategorical_grouped.columns = columns\n\ncategorical_grouped.head()","a1558961":"train = train.merge(categorical_grouped, left_on = 'SK_ID_CURR', right_index = True, how = 'left')\ntrain.head()","4b0e19ae":"train.shape","590111d0":"train.iloc[:5, 123:]","a9c30bee":"def count_categorical(df, group_var, df_name):\n    \"\"\"Computes counts and normalized counts for each observation\n    of `group_var` of each unique category in every categorical variable\n    \n    Parameters\n    --------\n    df : dataframe \n        The dataframe to calculate the value counts for.\n        \n    group_var : string\n        The variable by which to group the dataframe. For each unique\n        value of this variable, the final dataframe will have one row\n        \n    df_name : string\n        Variable added to the front of column names to keep track of columns\n\n    \n    Return\n    --------\n    categorical : dataframe\n        A dataframe with counts and normalized counts of each unique category in every categorical variable\n        with one row for every unique value of the `group_var`.\n        \n    \"\"\"\n    # Select the categorical columns\n    categorical = pd.get_dummies(df.select_dtypes('object'))\n\n    # Make sure to put the identifying id on the column\n    categorical[group_var] = df[group_var]\n\n    # Groupby the group var and calculate the sum and mean\n    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n    \n    column_names = []\n    \n    # Iterate through the columns in level 0\n    for var in categorical.columns.levels[0]:\n        # Iterate through the stats in level 1\n        for stat in ['count', 'count_norm']:\n            # Make a new column name\n            column_names.append('%s_%s_%s' % (df_name, var, stat))\n    \n    categorical.columns = column_names\n    \n    return categorical","ed14f9a3":"bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_counts.head()","04c4a4f5":"# Read in bureau balance\nbureau_balance = pd.read_csv('..\/input\/bureau_balance.csv')\nbureau_balance.head()","155ea6a4":"# Counts of each type of status for each previous loan\nbureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_counts.head()","4c893ecd":"# \u5904\u7406\u6570\u503c\u578b\u53d8\u91cf\nbureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_agg.head()","3da5fe95":"# Dataframe grouped by the loan\nbureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n\n# Merge to include the SK_ID_CURR\nbureau_by_loan = bureau_by_loan.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], on = 'SK_ID_BUREAU', how = 'left')\n\nbureau_by_loan.head()","616fcef6":"bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')\nbureau_balance_by_client.head()","bde0948d":"# Free up memory by deleting old objects\nimport gc\ngc.enable()\ndel train, bureau, bureau_balance, bureau_agg, bureau_agg_new, bureau_balance_agg, bureau_balance_counts, bureau_by_loan, bureau_balance_by_client, bureau_counts\ngc.collect()","f6b0137c":"# Read in new copies of all the dataframes\ntrain = pd.read_csv('..\/input\/application_train.csv')\nbureau = pd.read_csv('..\/input\/bureau.csv')\nbureau_balance = pd.read_csv('..\/input\/bureau_balance.csv')","250c7825":"bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_counts.head()","d45ff031":"bureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_agg.head()","e31c104c":"bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_counts.head()","7329d7b0":"bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_agg.head()","76bd66d9":"# Dataframe grouped by the loan\nbureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n\n# Merge to include the SK_ID_CURR\nbureau_by_loan = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how = 'left')\n\n# Aggregate the stats for each client\nbureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')","aac4683b":"original_features = list(train.columns)\nprint('Original Number of Features: ', len(original_features))","c3219214":"# Merge with the value counts of bureau\ntrain = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the stats of bureau\ntrain = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the monthly information grouped by client\ntrain = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')","602c5ecd":"new_features = list(train.columns)\nprint('Number of features using previous loans from other institutions data: ', len(new_features))","29e52c2e":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","22ac5342":"missing_train = missing_values_table(train)\nmissing_train.head(10)","d4097e51":"missing_train_vars = list(missing_train.index[missing_train['% of Total Values'] > 90])\nlen(missing_train_vars)","355cdf7d":"# Read in the test dataframe\ntest = pd.read_csv('..\/input\/application_test.csv')\n\n# Merge with the value counts of bureau\ntest = test.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the stats of bureau\ntest = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the value counts of bureau balance\ntest = test.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')","d34d3150":"print('Shape of Testing Data: ', test.shape)","850c99de":"train_labels = train['TARGET']\n\n# Align the dataframes, this will remove the 'TARGET' column\ntrain, test = train.align(test, join = 'inner', axis = 1)\n\ntrain['TARGET'] = train_labels\n\nprint('Training Data Shape: ', train.shape)\nprint('Testing Data Shape: ', test.shape)","d3f2e1b7":"missing_test = missing_values_table(test)\nmissing_test.head(10)","71438122":"missing_test_vars = list(missing_test.index[missing_test['% of Total Values'] > 90])\nlen(missing_test_vars)","3ede0f4c":"missing_columns = list(set(missing_test_vars + missing_train_vars))\nprint('There are %d columns with more than 90%% missing in either the training or testing data.' % len(missing_columns))","e0b8de10":"# Drop the missing columns\ntrain = train.drop(columns = missing_columns)\ntest = test.drop(columns = missing_columns)","0cb01f59":"train.to_csv('train_bureau_raw.csv', index = False)\ntest.to_csv('test_bureau_raw.csv', index = False)","ba662b88":"# Calculate all correlations in dataframe\ncorrs = train.corr()\n\ncorrs = corrs.sort_values('TARGET', ascending = False)\n\n# Ten most positive correlations\npd.DataFrame(corrs['TARGET'].head(10))","595e735a":"# Ten most negative correlations\npd.DataFrame(corrs['TARGET'].dropna().tail(10))","fa8e2e16":"kde_target(var_name='bureau_DAYS_CREDIT_mean', df=train)","27eb37ca":"kde_target(var_name='bureau_CREDIT_ACTIVE_Active_count_norm', df=train)","0c2b9336":"# Set the threshold\nthreshold = 0.8\n\n# Empty dictionary to hold correlated variables\nabove_threshold_vars = {}\n\n# For each column, record the variables that are above the threshold\nfor col in corrs:\n    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])","2da9665c":"# Track columns to remove and columns already examined\ncols_to_remove = []\ncols_seen = []\ncols_to_remove_pair = []\n\n# Iterate through columns and correlated columns\nfor key, value in above_threshold_vars.items():\n    # Keep track of columns already examined\n    cols_seen.append(key)\n    for x in value:\n        if x == key:\n            next\n        else:\n            # Only want to remove one in a pair\n            if x not in cols_seen:\n                cols_to_remove.append(x)\n                cols_to_remove_pair.append(key)\n            \ncols_to_remove = list(set(cols_to_remove))\nprint('Number of columns to remove: ', len(cols_to_remove))","4d316b8c":"train_corrs_removed = train.drop(columns = cols_to_remove)\ntest_corrs_removed = test.drop(columns = cols_to_remove)\n\nprint('Training Corrs Removed Shape: ', train_corrs_removed.shape)\nprint('Testing Corrs Removed Shape: ', test_corrs_removed.shape)","7d0cb5a3":"train_corrs_removed.to_csv('train_bureau_corrs_removed.csv', index = False)\ntest_corrs_removed.to_csv('test_bureau_corrs_removed.csv', index = False)","ff2853b3":"import lightgbm as lgb\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nimport gc\n\nimport matplotlib.pyplot as plt","e602f79f":"def model(features, test_features, encoding = 'ohe', n_folds = 5):\n    \n    \"\"\"Train and test a light gradient boosting model using\n    cross validation. \n    \n    Parameters\n    --------\n        features (pd.DataFrame): \n            dataframe of training features to use \n            for training a model. Must include the TARGET column.\n        test_features (pd.DataFrame): \n            dataframe of testing features to use\n            for making predictions with the model. \n        encoding (str, default = 'ohe'): \n            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n            n_folds (int, default = 5): number of folds to use for cross validation\n        \n    Return\n    --------\n        submission (pd.DataFrame): \n            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n            predicted by the model.\n        feature_importances (pd.DataFrame): \n            dataframe with the feature importances from the model.\n        valid_metrics (pd.DataFrame): \n            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n        \n    \"\"\"\n    \n    # Extract the ids\n    train_ids = features['SK_ID_CURR']\n    test_ids = test_features['SK_ID_CURR']\n    \n    # Extract the labels for training\n    labels = features['TARGET']\n    \n    # Remove the ids and target\n    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n    \n    \n    # One Hot Encoding\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        \n        # Align the dataframes by the columns\n        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n        \n        # No categorical indices to record\n        cat_indices = 'auto'\n    \n    # Integer label encoding\n    elif encoding == 'le':\n        \n        # Create a label encoder\n        label_encoder = LabelEncoder()\n        \n        # List for storing categorical indices\n        cat_indices = []\n        \n        # Iterate through each column\n        for i, col in enumerate(features):\n            if features[col].dtype == 'object':\n                # Map the categorical features to integers\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n\n                # Record the categorical indices\n                cat_indices.append(i)\n    \n    # Catch error if label encoding scheme is not valid\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n        \n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    \n    # Extract feature names\n    feature_names = list(features.columns)\n    \n    # Convert to np arrays\n    features = np.array(features)\n    test_features = np.array(test_features)\n    \n    # Create the kfold object\n    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n    \n    # Empty array for feature importances\n    feature_importance_values = np.zeros(len(feature_names))\n    \n    # Empty array for test predictions\n    test_predictions = np.zeros(test_features.shape[0])\n    \n    # Empty array for out of fold validation predictions\n    out_of_fold = np.zeros(features.shape[0])\n    \n    # Lists for recording validation and training scores\n    valid_scores = []\n    train_scores = []\n    \n    # Iterate through each fold\n    for train_indices, valid_indices in k_fold.split(features):\n        \n        # Training data for the fold\n        train_features, train_labels = features[train_indices], labels[train_indices]\n        # Validation data for the fold\n        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n        \n        # Create the model\n        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n                                   class_weight = 'balanced', learning_rate = 0.05, \n                                   reg_alpha = 0.1, reg_lambda = 0.1, \n                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n        \n        # Train the model\n        model.fit(train_features, train_labels, eval_metric = 'auc',\n                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n                  early_stopping_rounds = 100, verbose = 200)\n        \n        # Record the best iteration\n        best_iteration = model.best_iteration_\n        \n        # Record the feature importances\n        feature_importance_values += model.feature_importances_ \/ k_fold.n_splits\n        \n        # Make predictions\n        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] \/ k_fold.n_splits\n        \n        # Record the out of fold predictions\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n        \n        # Record the best score\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        \n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        \n        # Clean up memory\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n        \n    # Make the submission dataframe\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    \n    # Make the feature importance dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    \n    # Overall validation score\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    \n    # Add the overall scores to the metrics\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    \n    # Needed for creating dataframe of validation scores\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    \n    # Dataframe of validation scores\n    metrics = pd.DataFrame({'fold': fold_names,\n                            'train': train_scores,\n                            'valid': valid_scores}) \n    \n    return submission, feature_importances, metrics","54170e94":"def plot_feature_importances(df):\n    \"\"\"\n    Plot importances returned by a model. This can work with any measure of\n    feature importance provided that higher importance is better. \n    \n    Args:\n        df (dataframe): feature importances. Must have the features in a column\n        called `features` and the importances in a column called `importance\n        \n    Returns:\n        shows a plot of the 15 most importance features\n        \n        df (dataframe): feature importances sorted by importance (highest to lowest) \n        with a column for normalized importance\n        \"\"\"\n    \n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] \/ df['importance'].sum()\n\n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    # Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df","d6024f39":"train_control = pd.read_csv('..\/input\/application_train.csv')\ntest_control = pd.read_csv('..\/input\/application_test.csv')","aba1ec95":"submission, fi, metrics = model(train_control, test_control)","47a029d7":"metrics","e2e12a70":"fi_sorted = plot_feature_importances(fi)","14248e2a":"submission.to_csv('control.csv', index = False)","f2d6b6b6":"submission_raw, fi_raw, metrics_raw = model(train, test)","440f2e0f":"metrics_raw","51f6d52f":"fi_raw_sorted = plot_feature_importances(fi_raw)","327e25ae":"top_100 = list(fi_raw_sorted['feature'])[:100]\nnew_features = [x for x in top_100 if x not in list(fi['feature'])]\n\nprint('%% of Top 100 Features created from the bureau data = %d.00' % len(new_features))","140dde3f":"submission_raw.to_csv('test_one.csv', index = False)","43b24fcc":"submission_corrs, fi_corrs, metrics_corr = model(train_corrs_removed, test_corrs_removed)","0331eaff":"metrics_corr","22128c47":"fi_corrs_sorted = plot_feature_importances(fi_corrs)","051be987":"submission_corrs.to_csv('test_two.csv', index = False)","c41ef737":"# \u7c7b\u522b\u53d8\u91cf\n\u5bf9\u4e8e\u79bb\u6563\u7684\u5b57\u7b26\u4e32\u53d8\u91cf\uff0c\u6211\u4eec\u4e0d\u80fd\u8ba1\u7b97\u7edf\u8ba1\u91cf\uff0c\u4f8b\u5982\u5747\u503c\u548c\u6700\u5927\u503c\uff0c\u5b83\u4eec\u4ec5\u9002\u7528\u4e8e\u6570\u503c\u53d8\u91cf\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u5c06\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u7c7b\u522b\u7684\u503c\u8ba1\u6570\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u6709\u4ee5\u4e0b\u6570\u636e\u8868\uff1a\n\nSK_ID_CURR | Loan type |  \n-|-|-\n1 | home |\n1 | home |\n1 |\thome |\n1 | credit |\n2 | credit |\n3 | credit |\n3 | cash |\n3 |\tcash |\n4 | credit | \n4 | home |\n4 | home |\n\n\u6bcf\u4e2a\u7c7b\u522b\u8d37\u6b3e\u6570\u91cf\u5982\u4e0b\uff1a\n\nSK_ID_CURR | credit count | cash count | home count | total count\n-|-|-|-|-\n1 | 1 | 0 | 3 | 4 |\n2|\t1|\t0|\t0|\t1|\n3|\t1|\t2|\t0|\t3|\n4|\t1|\t0|\t2|\t3|\n\n\u7136\u540e\u5bf9\u5404\u4e2a\u7c7b\u522b\u8ba1\u6570\u8fdb\u884c\u5f52\u4e00\u5316\uff1a\n\nSK_ID_CURR | credit count | cash count | home count | total count|credit count norm|cash count norm|\thome count norm\n-|-|-|-|-|-|-|\n1 | 1 | 0 | 3 | 4 |0.25|\t0|\t0.75|\n2|\t1|\t0|\t0|\t1|1.00|\t0|\t0|\n3|\t1|\t2|\t0|\t3|0.33|\t0.66|\t0|\n4|\t1|\t0|\t2|\t3|0.33|\t0|\t0.66|**","24588b27":"sum\u5217\u8bb0\u5f55\u8ba1\u6570\uff0c\u800cmean\u5217\u8bb0\u5f55\u5f52\u4e00\u5316\u540e\u7684\u8ba1\u6570\u3002\n\n\u6211\u4eec\u53ef\u4ee5\u5c06\u6b64\u6570\u636e\u6846\u5408\u5e76\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u3002","b00bbb02":"# \u76f8\u5173\u6027\n\u9996\u5148\u8ba9\u6211\u4eec\u770b\u4e00\u4e0b\u53d8\u91cf\u4e0e\u76ee\u6807\u7684\u76f8\u5173\u6027\u3002\u53ef\u4ee5\u770b\u5230\uff0c\u6211\u4eec\u521b\u5efa\u7684\u4efb\u4f55\u53d8\u91cf\u90fd\u5177\u6709\u6bd4\u6700\u521d\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u5df2\u5b58\u5728\u7684\u53d8\u91cf\u66f4\u5927\u7684\u76f8\u5173\u6027\u3002","83949c3e":"\u6ca1\u6709\u65b0\u53d8\u91cf\u4e0eTARGET\u6709\u663e\u8457\u7684\u76f8\u5173\u6027\u3002 \u6211\u4eec\u53ef\u4ee5\u770b\u4e00\u4e0b\u6700\u9ad8\u76f8\u5173\u6027\u53d8\u91cfbureau_DAYS_CREDIT_mean\u7684KDE\u56fe\u3002","3cf4d6da":"The control scores **0.745** when submitted to the competition.","0462de37":"\u6211\u4eec\u53ef\u4ee5\u4ece\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e2d\u5220\u9664\u8fd9\u4e9b\u5217\uff0c\u7136\u540e\u5bf9\u5220\u9664\u8fd9\u4e9b\u53d8\u91cf\u540e\u5c06\u6027\u80fd\u4e0e\u4fdd\u6301\u8fd9\u4e9b\u53d8\u91cf\uff08\u6211\u4eec\u4e4b\u524d\u4fdd\u5b58\u7684\u539f\u59cbcsv\u6587\u4ef6\uff09\u7684\u6027\u80fd\u8fdb\u884c\u6bd4\u8f83\u3002","18f11021":"# \u805a\u5408\u6570\u503c\u5217\n\u4e3a\u4e86\u4f7f\u7528bureau\u8868\u4e2d\u7684\u6570\u503c\u4fe1\u606f\uff0c\u6211\u4eec\u8ba1\u7b97\u8868\u4e2d\u6240\u6709\u6570\u503c\u5217\u7684\u7edf\u8ba1\u7279\u5f81\u3002\u6211\u4eec\u6309\u5ba2\u6237id\u8fdb\u884c \u5206\u7ec4\uff0c\u7136\u540e\u5728\u5206\u7ec4\u7684\u6570\u636e\u4e0a\u8fdb\u884c \u805a\u5408\uff0c\u7ed3\u679c\u5408\u5e76\u5230\u8bad\u7ec3\u8868\u4e2d\u3002","8d7bac58":"**Test Two scores 0.753 when submitted to the competition.**","ed6b1cd2":"# \u4e0b\u4e00\u6b65\n\u6211\u4eec\u73b0\u5728\u53ef\u4ee5\u5728\u5176\u4ed6\u6570\u636e\u96c6\u4e2d\u4f7f\u7528\u6211\u4eec\u5728\u6b64\u7b14\u8bb0\u672c\u4e2d\u5f00\u53d1\u7684\u7279\u5f81\u3002\u6211\u4eec\u7684\u6a21\u578b\u4e2d\u8fd8\u67094\u4e2a\u5176\u4ed6\u6570\u636e\u6587\u4ef6\u53ef\u4f9b\u4f7f\u7528\uff01\u5728\u4e0b\u4e00\u4e2a\u7b14\u8bb0\u672c\u4e2d\uff0c\u6211\u4eec\u5c06\u628a\u8fd9\u4e9b\u6570\u636e\u6587\u4ef6\uff08\u5305\u542bHome Credit\u7684\u5148\u524d\u8d37\u6b3e\u4fe1\u606f\uff09\u4e2d\u7684\u4fe1\u606f\u5408\u5e76\u5230\u6211\u4eec\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u3002\u7136\u540e\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u76f8\u540c\u7684\u6a21\u578b\u5e76\u8fd0\u884c\u66f4\u591a\u5b9e\u9a8c\u6765\u786e\u5b9a\u6211\u4eec\u7684\u7279\u5f81\u5de5\u7a0b\u7684\u6548\u679c\u3002","56bd76a4":"\u6211\u4eec\u6240\u6709\u7684\u52aa\u529b\u5de5\u4f5c\u90fd\u8f6c\u5316\u4e3a\u6bd4\u539f\u59cb\u6d4b\u8bd5\u6570\u636e\u9ad80.014 ROC AUC\u7684\u6539\u8fdb\u3002 \u5220\u9664\u9ad8\u5171\u7ebf\u53d8\u91cf\u4f1a\u7565\u5fae\u964d\u4f4e\u6027\u80fd\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u8003\u8651\u4e0d\u540c\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002 \u6b64\u5916\uff0c\u6211\u4eec\u53ef\u4ee5\u8bf4\uff0c\u6211\u4eec\u6784\u5efa\u7684\u4e00\u4e9b\u7279\u5f81\u662f\u6a21\u578b\u5224\u65ad\u6700\u91cd\u8981\u7684\u7279\u5f81\u4e4b\u4e00\u3002","f4df4c0d":"\u6211\u4eec\u770b\u5230\u6709\u8bb8\u591a\u5217\u5177\u6709\u8f83\u9ad8\u7684\u7f3a\u5931\u503c\u767e\u5206\u6bd4\u3002\u6ca1\u6709\u660e\u786e\u7684\u9608\u503c\u6765\u5220\u9664\u7f3a\u5931\u503c\uff0c\u6700\u4f73\u7684\u884c\u52a8\u65b9\u6848\u53d6\u51b3\u4e8e\u5177\u4f53\u95ee\u9898\u3002\u5728\u8fd9\u91cc\uff0c\u4e3a\u4e86\u51cf\u5c11\u7279\u5f81\u7684\u6570\u91cf\uff0c\u6211\u4eec\u5c06\u5220\u9664\u8bad\u7ec3\u6216\u6d4b\u8bd5\u6570\u636e\u4e2d\u7f3a\u5931\u503c\u8d85\u8fc790\uff05\u7684\u5217\u3002","eb35f8b5":"# \u7ed3\u679c\n\u5b8c\u6210\u6240\u6709\u8fd9\u4e9b\u5de5\u4f5c\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u8bf4\u5305\u542b\u989d\u5916\u4fe1\u606f\u786e\u5b9e\u63d0\u9ad8\u4e86\u6027\u80fd\uff01\u8ba9\u6211\u4eec\u6b63\u5f0f\u603b\u7ed3\u4e00\u4e0b\uff1a\n\nExperiment| Train AUC|\tValidation AUC|\tTest AUC\n-|-|-|-|\nControl|\t0.815|\t0.760|\t0.745|\nTest One|\t0.837|\t0.767|\t0.759|\nTest Two|\t0.826|\t0.765|\t0.753|","107766fb":"\u5728\u5220\u9664\u7f3a\u5931\u503c\u4e4b\u524d\uff0c\u6211\u4eec\u5c06\u5728\u6d4b\u8bd5\u6570\u636e\u4e2d\u627e\u5230\u7f3a\u5931\u7684\u503c\u767e\u5206\u6bd4\u3002 \u7136\u540e\uff0c\u6211\u4eec\u5c06\u5220\u9664\u8bad\u7ec3\u6216\u6d4b\u8bd5\u6570\u636e\u4e2d\u7f3a\u5931\u503c\u8d85\u8fc790\uff05\u7684\u4efb\u4f55\u5217\u3002 \u73b0\u5728\u8ba9\u6211\u4eec\u8bfb\u5165\u6d4b\u8bd5\u6570\u636e\uff0c\u6267\u884c\u76f8\u540c\u7684\u64cd\u4f5c\uff0c\u5e76\u67e5\u770b\u6d4b\u8bd5\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u3002 \u6211\u4eec\u5df2\u7ecf\u8ba1\u7b97\u4e86\u6240\u6709\u8ba1\u6570\u548c\u805a\u5408\u7edf\u8ba1\u6570\u636e\uff0c\u56e0\u6b64\u6211\u4eec\u53ea\u9700\u8981\u5c06\u6d4b\u8bd5\u6570\u636e\u4e0e\u9002\u5f53\u7684\u6570\u636e\u5408\u5e76\u3002","b285a0e6":"\u4e3a\u4e86\u786e\u4fdd\u51fd\u6570\u6309\u9884\u671f\u5de5\u4f5c\uff0c\u6211\u4eec\u5e94\u8be5\u4e0e\u624b\u5de5\u6784\u5efa\u7684\u805a\u5408\u6570\u636e\u8868\u8fdb\u884c\u6bd4\u8f83\u3002","e4122b29":"## \u5904\u7406\u5176\u4ed6\u6570\u636e\u8868\nbureau balance \u5305\u542b\u6bcf\u4e2a\u5ba2\u6237\u4ee5\u524d\u5728\u5176\u4ed6\u91d1\u878d\u673a\u6784\u7684\u8d37\u6b3e\u7684\u6708\u5ea6\u4fe1\u606f\u3002\u6211\u4eec\u5c06\u9996\u5148\u6309SK_ID_BUREAU\uff08\u5373\u5148\u524d\u8d37\u6b3e\u7684ID\uff09\u5bf9\u6570\u636e\u5e27\u8fdb\u884c\u5206\u7ec4\uff0c\u800c\u4e0d\u662f\u6309\u5ba2\u6237\u7684ID(ID SK_ID_CURR)\u5206\u7ec4\u3002\u8fd9\u5c06\u4e3a\u6bcf\u7b14\u8d37\u6b3e\u63d0\u4f9b\u4e00\u884c\u6570\u636e\u3002 \u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u6309SK_ID_CURR\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u8ba1\u7b97\u6bcf\u4e2a\u5ba2\u6237\u8d37\u6b3e\u7684\u6c47\u603b\u3002\u6700\u7ec8\u7ed3\u679c\u5c06\u662f\u6bcf\u4e2a\u5ba2\u6237\u4e00\u884c\u6570\u636e\uff0c\u5e76\u8ba1\u7b97\u5176\u8d37\u6b3e\u7684\u7edf\u8ba1\u6570\u636e\u3002","3e69535f":"\u6211\u4eec\u6700\u7ec8\u5728\u6b64\u56de\u5408\u4e2d\u6ca1\u6709\u5220\u9664\u4efb\u4f55\u5217\uff0c\u56e0\u4e3a\u6ca1\u6709\u5217\u7f3a\u5931\u503c\u8d85\u8fc790\uff05\u7684\u5217\u3002 \u6211\u4eec\u53ef\u80fd\u5fc5\u987b\u5e94\u7528\u53e6\u4e00\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u6765\u51cf\u5c11\u7ef4\u5ea6\u3002","4d02580e":"**Test one scores 0.759 when submitted to the competition.**","de133de7":"\u6b64\u5217\u7684\u5b9a\u4e49\u662f\uff1a\u5728\u5176\u4ed6\u91d1\u878d\u673a\u6784\u7533\u8bf7\u4e0a\u4e00\u7b14\u8d37\u6b3e\u5230\u5728Home Credit\u7533\u8bf7\u8d37\u6b3e\u4e4b\u95f4\u7684\u5929\u6570\u3002 \u56e0\u6b64\uff0c\u8f83\u5927\u7684\u8d1f\u6570\u8868\u793a\u8d37\u6b3e\u5728\u5f53\u524d\u8d37\u6b3e\u7533\u8bf7\u4e4b\u524d\u5f88\u4e45\u6ca1\u7533\u8bf7\u8fc7\u8d37\u6b3e\u3002\u6211\u4eec\u770b\u5230\u8fd9\u4e2a\u53d8\u91cf\u7684\u5e73\u5747\u503c\u4e0etarget\u4e4b\u95f4\u5b58\u5728\u6781\u5176\u5fae\u5f31\u7684\u6b63\u76f8\u5173\u5173\u7cfb\uff0c\u8fd9\u610f\u5473\u7740\u8fc7\u53bb\u5f88\u4e45\u6ca1\u7533\u8bf7\u8d37\u6b3e\u7684\u5ba2\u6237\u66f4\u6709\u53ef\u80fd\u5728Home Credit\u507f\u8fd8\u8d37\u6b3e\u3002\u867d\u7136\u8fd9\u79cd\u76f8\u5173\u6027\u5f88\u5f31\uff0c\u5b83\u4e5f\u6709\u53ef\u80fd\u662f\u566a\u58f0\u3002","bef01037":"\u91cd\u8981\u6027\u524d100\u7684\u7279\u5f81\u4e2d\u8d85\u8fc7\u4e00\u534a\u662f\u7531\u6211\u4eec\u5236\u4f5c\u7684\uff01\u8fd9\u5e94\u8be5\u8ba9\u6211\u4eec\u76f8\u4fe1\uff0c\u6211\u4eec\u6240\u505a\u7684\u6240\u6709\u52aa\u529b\u90fd\u662f\u503c\u5f97\u7684\u3002","4da0ba73":"\u770b\u8d77\u6765\u6211\u4eec\u6784\u5efa\u7684\u4e00\u4e9b\u7279\u5f81\u5728\u6700\u91cd\u8981\u7684\u7279\u5f81\u4e2d\u3002 \u8ba9\u6211\u4eec\u627e\u4e00\u4e0b\u5236\u4f5c\u7684\u524d100\u4e2a\u6700\u91cd\u8981\u7279\u5f81\u7684\u767e\u5206\u6bd4\u3002\u4f46\u662f\uff0c\u6211\u4eec\u9700\u8981\u4e0e\u72ec\u70ed\u7f16\u7801\u7684\u539f\u59cb\u7279\u5f81\u8fdb\u884c\u6bd4\u8f83\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u4e0e\u539f\u59cb\u7279\u5f81\u8fdb\u884c\u6bd4\u8f83\u3002\u8fd9\u4e9b\u5df2\u7ecf\u8bb0\u5f55\u5728fi\u4e2d\uff08\u6765\u81ea\u539f\u59cb\u6570\u636e\uff09\u3002","ba595fb5":"\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528EXT_SOURCE_3\u53d8\u91cf\u6765\u6d4b\u8bd5\u8fd9\u4e2a\u51fd\u6570\uff0c\u6211\u4eec\u5728\u4e4b\u524d\u7684notebook\u4e2d\u53d1\u73b0\u5b83\u662f\u6700\u91cd\u8981\u7684\u53d8\u91cf\u4e4b\u4e00\u3002","7d6c58ab":"# \u91cd\u65b0\u7528\u51fd\u6570\u6267\u884c\n \u8ba9\u6211\u4eec\u91cd\u7f6e\u6240\u6709\u53d8\u91cf\uff0c\u7136\u540e\u4f7f\u7528\u6211\u4eec\u6784\u5efa\u7684\u51fd\u6570\u4ece\u5934\u5f00\u59cb\u6267\u884c\u6b64\u64cd\u4f5c\u3002","c7f96ed4":"### Test Two","e469e7fe":"### Control\n\u4efb\u4f55\u5b9e\u9a8c\u7684\u7b2c\u4e00\u6b65\u662f\u5efa\u7acb\u4e00\u4e2a\u63a7\u5236\u53d8\u91cf\u3002 \u4e3a\u6b64\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u4e0a\u9762\u5b9a\u4e49\u7684\u51fd\u6570\uff08\u5b9a\u4e49\u6a21\u578b\uff09\u548c\u5355\u4e2a\u4e3b\u6570\u636e\u6e90\uff08application\u8868\uff09\u3002","ea28fe5b":"\u5bf9\u4e8e\u8fd9\u4e9b\u9ad8\u5ea6\u76f8\u5173\u53d8\u91cf\u5bf9\u4e2d\u7684\u6bcf\u4e00\u5bf9\uff0c\u6211\u4eec\u53ea\u60f3\u5220\u9664\u5176\u4e2d\u4e00\u4e2a\u53d8\u91cf\u3002 \u4ee5\u4e0b\u4ee3\u7801\u901a\u8fc7\u4ec5\u6dfb\u52a0\u6bcf\u5bf9\u4e2d\u7684\u4e00\u4e2a\u6765\u521b\u5efa\u8981\u5220\u9664\u7684\u53d8\u91cf\u96c6\u3002","9c8026c6":"## \u6838\u5bc6\u5ea6\u4f30\u8ba1\u56fe\n\u6838\u5bc6\u5ea6\u4f30\u8ba1\u56fe\u663e\u793a\u5355\u4e2a\u53d8\u91cf\u7684\u5206\u5e03\uff08\u5c06\u5176\u89c6\u4e3a\u5e73\u6ed1\u7684\u76f4\u65b9\u56fe\uff09\u3002\u8981\u53d8\u91cf\u5728\u4e0d\u540ctarget\u503c\u4e0b\u7684\u5206\u5e03\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636etarget\u4e0d\u540c\u7684\u53d6\u503c\u5bf9\u5206\u5e03\u8fdb\u884c\u4e0d\u540c\u7684\u7740\u8272\u3002","551c96b4":"### \u5171\u7ebf\u53d8\u91cf\uff08Collinear Variables\uff09","2e66dc05":"\u73b0\u5728\u6211\u4eec\u9700\u8981\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u805a\u5408\u8d37\u6b3e\u4fe1\u606f\u3002\u9996\u5148\u5c06\u6570\u636e\u8868\u5408\u5e76\u5728\u4e00\u8d77\uff0c\u7531\u4e8e\u6240\u6709\u53d8\u91cf\u90fd\u662f\u6570\u5b57\uff0c\u6211\u4eec\u53ea\u9700\u8981\u518d\u6b21\u805a\u5408\u7edf\u8ba1\u6570\u636e\uff0c\u6309SK_ID_CURR\u8fdb\u884c\u5206\u7ec4\u3002","7afbbbb8":"### Aggregated Stats of Bureau Balance by Client","c988d094":"\u4e0e\u76ee\u6807\u7684\u6700\u9ad8\u76f8\u5173\u53d8\u91cf\u662f\u6211\u4eec\u521b\u5efa\u7684\u53d8\u91cf\u3002 \u7136\u800c\uff0c\u4ec5\u4ec5\u56e0\u4e3a\u53d8\u91cf\u662f\u76f8\u5173\u7684\u5e76\u4e0d\u610f\u5473\u7740\u5b83\u5c06\u662f\u6709\u7528\u7684\uff0c\u6211\u4eec\u5fc5\u987b\u8bb0\u4f4f\uff0c\u5982\u679c\u6211\u4eec\u751f\u6210\u6570\u767e\u4e2a\u65b0\u53d8\u91cf\uff0c\u4e00\u4e9b\u53d8\u91cf\u5c06\u4e0e\u76ee\u6807\u76f8\u5173\uff0c\u4ec5\u4ec5\u662f\u56e0\u4e3a\u968f\u673a\u566a\u58f0\u3002\n\n\u770b\u8d77\u6765\u786e\u5b9e\u6709\u51e0\u4e2a\u65b0\u521b\u5efa\u7684\u53d8\u91cf\u53ef\u80fd\u6709\u7528\u3002 \u4e3a\u4e86\u8bc4\u4f30\u53d8\u91cf\u7684\u201c\u6709\u7528\u6027\u201d\uff0c\u6211\u4eec\u5c06\u67e5\u770b\u6a21\u578b\u8fd4\u56de\u7684\u7279\u5f81\u91cd\u8981\u6027\u3002\u6211\u4eec\u53ef\u4ee5\u521b\u5efa\u4e24\u4e2a\u65b0\u521b\u5efa\u7684\u53d8\u91cf\u7684kde\u56fe\u770b\u770b\u3002","66db5274":"### Test One","a38057c2":"\u6211\u4eec\u9700\u8981\u5bf9\u8fd9\u4e9b\u5217\u91cd\u65b0\u547d\u540d\u3002","ce1190a5":"### Aggregated stats of Bureau Balance dataframe by loan","4b977ae1":"# \u5c06\u8ba1\u7b97\u51fa\u7684\u7279\u5f81\u63d2\u5165\u8bad\u7ec3\u6570\u636e\u8868\u4e2d","35e0b986":"### Counts of Bureau Dataframe","dd794326":"### Aggregated Stats of Bureau Dataframe","41f979c4":"# \u5904\u7406\u6d4b\u8bd5\u6570\u636e","4a95e949":"## \u5904\u7406\u7c7b\u522b\u53d8\u91cf\u7684\u51fd\u6570\n\u628a\u7c7b\u522b\u53d8\u91cf\u7684\u5904\u7406\u5c01\u88c5\u6210\u51fd\u6570","507c297d":"* client_bureau_balance_MONTHS_BALANCE_mean_mean\uff1a\u5bf9\u4e8e\u6bcf\u7b14\u8d37\u6b3e\uff0c\u8ba1\u7b97MONTHS_BALANCE\u7684\u5e73\u5747\u503c\u3002 \u7136\u540e\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u8ba1\u7b97\u6240\u6709\u8d37\u6b3e\u7684\u8be5\u503c\u7684\u5e73\u5747\u503c\u3002\n* client_bureau_balance_STATUS_X_count_norm_sum\uff1a\u5bf9\u4e8e\u6bcf\u7b14\u8d37\u6b3e\uff0c\u8ba1\u7b97STATUS == X\u7684\u51fa\u73b0\u6b21\u6570\u9664\u4ee5\u8d37\u6b3e\u7684\u603bSTATUS\u503c\u7684\u6570\u91cf\u3002 \u7136\u540e\uff0c\u5bf9\u6bcf\u4e2a\u5ba2\u6237\u8d37\u6b3e\u7684\u503c\u6c42\u548c\u3002","df0a381d":"\u7531\u6b64\u5f88\u96be\u5224\u65ad\u8fd9\u4e2a\u53d8\u91cf\u662f\u5426\u91cd\u8981\u3002 \u76f8\u5173\u7cfb\u6570\u6781\u5f31\uff0c\u5206\u5e03\u51e0\u4e4e\u6ca1\u6709\u660e\u663e\u5dee\u5f02\u3002\n\n\u63a5\u4e0b\u6765\u6211\u4eec\u7ee7\u7eed\u4ecebureau\u8868\u4e2d\u521b\u5efa\u4e00\u4e9b\u53d8\u91cf\uff0c\u5bf9\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6570\u503c\u5217\u8fdb\u884c min\uff0cmax\uff0cmean\u8fd0\u7b97\u3002","30ee719c":"\u5bf9\u5217\u8fdb\u884c\u91cd\u547d\u540d","064acbaf":"### \u7f3a\u5931\u503c\n\u5220\u9664\u5177\u6709\u592a\u591a\u7f3a\u5931\u503c\u7684\u5217\u3002","c86c26fd":"# \u76f8\u5173\u7cfb\u6570\u51fd\u6570","22ff2fb5":"# \u7528r\u503c\u8bc4\u4f30\u65b0\u53d8\u91cf\u7684\u6709\u7528\u6027\n\u4e3a\u4e86\u5224\u65ad\u4e00\u4e2a\u65b0\u53d8\u91cf\u662f\u5426\u6709\u7528\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u65b0\u53d8\u91cf\u548ctarget\u7684\u76ae\u5c14\u68ee\u76f8\u5173\u7cfb\u6570\uff08r\u503c\uff09\u3002r\u503c\u53ef\u4ee5\u8861\u91cf\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u867d\u7136\u4ed6\u4e0d\u662f\u8861\u91cf\u4e00\u4e2a\u53d8\u91cf\u662f\u5426\u6709\u7528\u7684\u6700\u4f73\u6307\u6807\uff0c\u4f46\u662f\u5b83\u53ef\u4ee5\u7ed9\u51fa\u53d8\u91cf\u662f\u5426\u6709\u52a9\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u7b2c\u4e00\u4e2a\u8fd1\u4f3c\u4f30\u8ba1\u3002r\u503c\u7edd\u5bf9\u503c\u8d8a\u5927\uff0c\u8868\u660e\u65b0\u53d8\u91cf\u8d8a\u6709\u53ef\u80fd\u5f71\u54cdtarget\u503c\u3002\n\n\u6211\u4eec\u8fd8\u53ef\u4ee5\u4f7f\u7528\u6838\u5bc6\u5ea6\u4f30\u8ba1\uff08KDE\uff09\u56fe\u6765\u76f4\u89c2\u5730\u89c2\u5bdf\u53d8\u91cf\u4e0e\u76ee\u6807\u7684\u5173\u7cfb\u3002","2c7b97b4":"# \u6570\u503c\u805a\u5408\u51fd\u6570\n","bdaf2663":"These results are better than the control, but slightly lower than the raw features.","bad32670":"# \u6a21\u578b","84d253d6":"### Value counts of Bureau Balance dataframe by loan","5af15fa9":"# \u7b80\u4ecb\n\u5728\u672c\u90e8\u5206\uff0c\u6211\u4eec\u63a2\u7d22\u4e3aHome Credit Default Risk\u7ade\u8d5b\u9898\u76ee\u624b\u5de5\u521b\u5efa\u7279\u5f81\u3002\u5728\u524d\u4e00\u4e2anotebook\u4e2d\uff0c\u6211\u4eec\u4ec5\u4f7f\u7528\u8d37\u6b3e\u7533\u8bf7\u6570\u636e\u6765\u6784\u5efa\u6a21\u578b\u3002\u6211\u4eec\u4ece\u8fd9\u4e9b\u6570\u636e\u4e2d\u83b7\u5f97\u7684\u6700\u4f73\u6a21\u578b\u5728\u6392\u884c\u699c\u4e0a\u83b7\u5f97\u4e86\u5927\u7ea60.74\u7684\u5206\u6570\u3002\u4e3a\u4e86\u5f97\u5230\u66f4\u9ad8\u7684\u5206\u6570\uff0c\u6211\u4eec\u9700\u8981\u5229\u7528\u5176\u4ed6\u6570\u636e\u8868\u4e2d\u7684\u4fe1\u606f\u3002\u8fd9\u91cc\uff0c\u6211\u4eec\u4f1a\u4f7f\u7528\u8868 bureau \u548c bureau_balance,\u8fd9\u4e24\u4e2a\u8868\u8fbe\u542b\u4e49\u5982\u4e0b\uff1a\n* bureau: \u5ba2\u6237\u5728\u4ee5\u524d\u5728\u5176\u4ed6\u91d1\u878d\u673a\u6784\u7684\u8d37\u6b3e\u8bb0\u5f55\n* bureau_balance: \u5ba2\u6237\u4ee5\u524d\u5728\u5176\u4ed6\u7ecf\u878d\u673a\u6784\u7684\u8d37\u6b3e\u7684\u6708\u5ea6\u6570\u636e\u8bb0\u5f55\n\n\u624b\u52a8\u7279\u5f81\u5de5\u7a0b\u662f\u4e00\u4e2a\u7e41\u7410\u7684\u8fc7\u7a0b\uff0c\u901a\u5e38\u4f9d\u8d56\u4e8e\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u7531\u4e8e\u6211\u5bf9\u4fe1\u8d37\u9886\u57df\u7684\u4e13\u4e1a\u77e5\u8bc6\u6709\u9650\uff0c\u6211\u5c06\u52a0\u5165\u5c3d\u53ef\u80fd\u591a\u7684\u4fe1\u606f\u5230\u6700\u7ec8\u7684\u8bad\u7ec3\u8868\u4e2d\u3002\u6211\u4eec\u7684\u60f3\u6cd5\u662f\uff0c\u6a21\u578b\u5c06\u4f1a\u77e5\u9053\u54ea\u4e9b\u7279\u5f81\u91cd\u8981\uff0c\u54ea\u4e9b\u4e0d\u91cd\u8981\uff0c\u800c\u4e0d\u9700\u8981\u6211\u4eec\u81ea\u5df1\u6765\u505a\u51b3\u5b9a\u3002\u57fa\u672c\u4e0a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u662f\u5c3d\u53ef\u80fd\u591a\u5730\u521b\u5efa\u7279\u5f81\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u5168\u90e8\u4ea4\u7ed9\u6a21\u578b\u4f7f\u7528\uff01\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u4e2d\u7684\u7279\u5f81\u91cd\u8981\u6027\u6216PCA\u7b49\u5176\u4ed6\u6280\u672f\u6765\u6267\u884c\u7279\u5f81\u964d\u7ef4\u3002","19f6828f":"\u51fa\u73b0\u4e86\u8fc7\u62df\u5408\u73b0\u8c61\uff0c\u56e0\u4e3a\u8bad\u7ec3\u5206\u6570\u6bd4\u9a8c\u8bc1\u5206\u6570\u9ad8\u5f88\u591a\u3002 \u6211\u4eec\u53ef\u4ee5\u5728\u540e\u9762\u7684\u7b14\u8bb0\u672c\u4e2d\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff08\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7\u4f7f\u7528reg_lambda\u548creg_alpha\u4ee5\u53ca\u63d0\u524d\u505c\u6b62\u5728\u6b64\u6a21\u578b\u4e2d\u91c7\u53d6\u4e86\u4e00\u4e9b\u6b63\u5219\u5316\u63aa\u65bd\uff09\u3002","83442f66":"* control: only the data in the **application** files.\n* test one: the data in the application files with all of the data recorded from the **bureau** and **bureau_balance** files\n* test two: the data in the application files with all of the data recorded from the **bureau** and **bureau_balance** files with highly correlated variables removed.","b8e1b769":"## \u805a\u5408\u503c\u4e0etarget\u4e4b\u95f4\u7684\u76f8\u5173\u6027","3815cce9":"# \u5ba2\u6237\u4e4b\u524d\u7684\u8d37\u6b3e\u8bb0\u5f55\u8ba1\u6570\n\u4e3a\u4e86\u8bf4\u660e\u624b\u5de5\u7279\u5f81\u5de5\u7a0b\u7684\u4e00\u822c\u8fc7\u7a0b\uff0c\u6211\u4eec\u9996\u5148\u7b80\u5355\u5730\u4e86\u89e3\u4e00\u4e2a\u5ba2\u6237\u4ee5\u524d\u5728\u5176\u4ed6\u91d1\u878d\u673a\u6784\u8d37\u6b3e\u7684\u6570\u91cf\u3002","8e7cfcb8":"\u9996\u5148\uff0c\u5bf9\u6570\u636e\u7c7b\u578b\u4e3a\u2018object'\u7684\u5217\u8fdb\u884cone_hot\u7f16\u7801","d1e9eb1f":"# \u7279\u5f81\u5de5\u7a0b\u6210\u679c\n\u5b8c\u6210\u6240\u6709\u8fd9\u4e9b\u5de5\u4f5c\u4e4b\u540e\uff0c\u73b0\u5728\u6211\u4eec\u60f3\u770b\u770b\u6211\u4eec\u521b\u5efa\u7684\u53d8\u91cf\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u4e00\u4e0b\u7f3a\u5931\u503c\u7684\u767e\u5206\u6bd4\uff0c\u53d8\u91cf\u4e0e\u76ee\u6807\u7684\u76f8\u5173\u6027\uff0c\u4ee5\u53ca\u53d8\u91cf\u4e0e\u5176\u4ed6\u53d8\u91cf\u7684\u76f8\u5173\u6027\u3002\u53d8\u91cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u53ef\u4ee5\u663e\u793a\u6211\u4eec\u662f\u5426\u5177\u6709\u5171\u7ebf\u53d8\u91cf\uff0c\u5373\u5f7c\u6b64\u9ad8\u5ea6\u76f8\u5173\u7684\u53d8\u91cf\u3002\u901a\u5e38\uff0c\u6211\u4eec\u5e0c\u671b\u5220\u9664\u4e00\u5bf9\u5171\u7ebf\u53d8\u91cf\u4e2d\u7684\u4e00\u4e2a\u3002\u6211\u4eec\u8fd8\u53ef\u4ee5\u4f7f\u7528\u7f3a\u5931\u503c\u7684\u767e\u5206\u6bd4\u6765\u5220\u9664\u7f3a\u5931\u503c\u8fc7\u591a\u7684\u53d8\u91cf\u3002\n\n\u7279\u5f81\u9009\u62e9\u5c06\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u7126\u70b9\uff0c\u56e0\u4e3a\u51cf\u5c11\u7279\u5f81\u7684\u6570\u91cf\u53ef\u4ee5\u5e2e\u52a9\u6a21\u578b\u5728\u8bad\u7ec3\u671f\u95f4\u66f4\u597d\u5730\u5b66\u4e60\uff0c\u5e76\u4e14\u66f4\u597d\u5730\u6cdb\u5316\u5230\u6d4b\u8bd5\u6570\u636e\u3002\u201c\u7ef4\u5ea6\u7684\u8bc5\u5492\u201d\u662f\u7531\u4e8e\u5177\u6709\u592a\u591a\u7279\u5f81\uff08\u7ef4\u5ea6\u592a\u9ad8\uff09\u800c\u5bfc\u81f4\u7684\u95ee\u9898\u3002\u968f\u7740\u53d8\u91cf\u6570\u91cf\u7684\u589e\u52a0\uff0c\u5b66\u4e60\u8fd9\u4e9b\u53d8\u91cf\u4e0e\u76ee\u6807\u503c\u4e4b\u95f4\u5173\u7cfb\u6240\u9700\u7684\u6570\u636e\u70b9\u6570\u91cf\u5448\u6307\u6570\u589e\u957f\u3002"}}