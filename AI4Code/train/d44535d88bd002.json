{"cell_type":{"da296a3b":"code","db47112e":"code","f7f4f9e3":"code","0bfb4e08":"code","470889a4":"code","f063b227":"code","6637876e":"code","cd4c9616":"code","4e4990d8":"code","4e97e6b8":"code","b4bfe735":"code","e27ab571":"code","924c2823":"code","8e1691fa":"code","a3647142":"code","fe642df7":"code","6b19db4b":"code","fbdcd63c":"code","7090b276":"code","265ce9ce":"code","dac473cf":"code","8f2d2fe0":"code","46f1946a":"code","9f607449":"code","c6bd2635":"code","feb10468":"code","c2d03262":"code","063e00f7":"code","00eac784":"code","808718a3":"code","af8694d4":"code","9ad9cdd9":"code","b7c505a7":"code","df563c53":"code","e1668763":"code","90d5ffa3":"code","45f51ae5":"code","162a3306":"code","f8572e0a":"code","b6d7cdfd":"code","17b31e4f":"code","102a617b":"code","7e017ac0":"code","f3c40fac":"code","3a500c37":"code","31de09b3":"code","ef29879e":"code","ed2c9882":"code","9bb4440a":"code","208f2ed9":"code","7fbbce88":"code","0e537845":"code","20258f88":"code","fcf14f87":"code","4824de08":"code","fafc598e":"code","9d18371f":"code","f0a9d487":"code","664e8f00":"code","482fac95":"code","2be7f3f9":"code","3d7caf28":"markdown","80dd28ec":"markdown","756df8ec":"markdown","e455d476":"markdown","fee6a14f":"markdown","33000e9a":"markdown","a959f5fc":"markdown","db04d281":"markdown","3add4c0a":"markdown","bc8c0469":"markdown","c692cdc4":"markdown","c14a5afe":"markdown","3041f234":"markdown","a60875b9":"markdown","511abcdc":"markdown","278d1bbd":"markdown","ab7721e9":"markdown","a5811fe6":"markdown","ee2e332e":"markdown","1cd62992":"markdown","5e5eaa36":"markdown","7f587b69":"markdown","b9642de4":"markdown","46f5e5fd":"markdown","e955c486":"markdown","b948cc64":"markdown","06e45492":"markdown","22459c20":"markdown","0b4b36c4":"markdown","b5f677cf":"markdown","2f07077a":"markdown","5b13a637":"markdown","983d1fbf":"markdown","2a28fb36":"markdown","8d23b120":"markdown","ef2de04c":"markdown","216c9986":"markdown","642a8782":"markdown","200c8c7e":"markdown","816eb93f":"markdown","1e5d6849":"markdown","d0239e74":"markdown","94dcb432":"markdown","edee6131":"markdown","59cd31f0":"markdown","564c09fa":"markdown","7faa24bb":"markdown","4d60289d":"markdown","5d6ad4ac":"markdown","c9b9c946":"markdown","a5113124":"markdown","cda21f27":"markdown","f71bcc9c":"markdown","d9bc3fad":"markdown","9c0b16e5":"markdown","ae445069":"markdown","afc73b63":"markdown","da48ff6e":"markdown","14834c06":"markdown","865ab534":"markdown","1622e6ce":"markdown","a172a15a":"markdown","d8cbfda1":"markdown"},"source":{"da296a3b":"import os\nimport re\nimport pandas as pd\nimport numpy as np\nimport shutil\nfrom IPython.display import display, HTML\nimport plotly.express as px\n\nPATH = '\/kaggle\/input\/the-ontario-sunshine-list-raw-data\/'\nYEARS = range(1996, 2020)\n\npx.defaults.template = 'plotly_white'\npx.defaults.color_discrete_sequence = ['steelblue']\nMODE_BAR_BUTTONS = ['toImage', 'zoom2d', 'pan2d', 'select2d', 'lasso2d',\n                    'zoomIn2d', 'zoomOut2d', 'autoScale2d', 'resetScale2d',\n                    'toggleSpikelines', 'hoverClosestCartesian', 'hoverCompareCartesian']\nCONFIG = {\n    'modeBarButtonsToRemove': ['pan2d', 'select2d', 'lasso2d', 'toggleSpikelines']\n}","db47112e":"filenames = os.listdir(PATH)\nfilenames","f7f4f9e3":"pd.read_csv(PATH + 'en-2018-pssd-compendium.csv', nrows=5)","0bfb4e08":"pd.read_csv(PATH + 'en-2018-pssd-compendium-20191223.csv', nrows=5)","470889a4":"filenames","f063b227":"p = re.compile('(?:^|-)(\\d{4})\\D')","6637876e":"def read_csv(filename):\n    try:\n        return pd.read_csv(PATH + filename, encoding='utf-8')\n    except UnicodeDecodeError:\n        return pd.read_csv(PATH + filename, encoding='latin1')","cd4c9616":"pss = {}\nfor filename in filenames:\n    if filename == 'en-2018-pssd-compendium.csv':\n        pss[2017] = read_csv(filename)\n        continue\n    m = p.search(filename)\n    year = int(m.group(1))\n    pss[year] = read_csv(filename)","4e4990d8":"for year in YEARS:\n    display(HTML(pss[year].describe(include='all').to_html()))","4e97e6b8":"refcols = pss[2019].columns\nfor year in YEARS:\n    if not refcols.equals(pss[year].columns):\n        print(year, pss[year].columns.tolist(), sep='\\n', end='\\n\\n')\n\nprint(\"2019\", refcols.tolist(), sep='\\n')","b4bfe735":"pss[1996].head()","e27ab571":"pss[1996]['Unnamed: 8'].notna().any()","924c2823":"pss[1996].drop(columns='Unnamed: 8', inplace=True)","8e1691fa":"for year in YEARS:\n    pss[year].columns = refcols","a3647142":"for year in YEARS:\n    print(year, pss[year].dtypes, sep='\\n', end='\\n\\n')","fe642df7":"pss[2016]['Calendar Year'].nunique()","6b19db4b":"wrong_year = pss[2016][pss[2016]['Calendar Year'] != '2016']\nwrong_year.shape[0]","fbdcd63c":"wrong_year.head(20)","7090b276":"pss_comb = pd.concat([pss[year] for year in YEARS]).copy()","265ce9ce":"pss_comb[pss_comb['Last Name'].str.contains('Fagan', case=False) & pss_comb['First Name'].str.contains('Thomas', case=False)]","dac473cf":"pss_comb[pss_comb['Last Name'].str.contains('leblanc', case=False) & pss_comb['First Name'].str.contains('Laurie', case=False)]","8f2d2fe0":"pss_comb[pss_comb['Last Name'].str.contains('levac', case=False) & pss_comb['First Name'].str.contains('jody', case=False)]","46f1946a":"pss[2016].loc[pss[2016]['Calendar Year'] != '2016', 'Job Title'] = wrong_year['Job Title'].str.cat(wrong_year['Calendar Year'], sep='; ')\npss[2016].loc[pss[2016]['Calendar Year'] != '2016', 'Calendar Year'] = '2016'\npss[2016]['Calendar Year'] = pss[2016]['Calendar Year'].astype('int')\npss[2016].dtypes","9f607449":"for year in YEARS:\n    if pss[year]['Calendar Year'].nunique() > 1:\n        print(year, pss[year]['Calendar Year'].unique(), sep='\\n')","c6bd2635":"wrong_year_2015 = pss[2015][pss[2015]['Calendar Year'] != 2015]\nwrong_year_2015","feb10468":"pss[2015].loc[wrong_year_2015.index, 'Calendar Year'] = 2015","c2d03262":"pss_comb = pd.concat([pss[year] for year in YEARS]).copy().reset_index(drop=True)\n\nsalary_nonnum = pss_comb['Salary Paid'].str.extractall('([^$\\d.,\\s])').drop_duplicates()\nsalary_nonnum","063e00f7":"tax_ben_nonnum = pss_comb['Taxable Benefits'].str.extractall('([^$\\d.,\\s])').drop_duplicates()\ntax_ben_nonnum","00eac784":"idx = tax_ben_nonnum.reset_index(level='match', drop=True).index\npss_comb.loc[idx, 'Taxable Benefits'].unique()","808718a3":"for year in YEARS:\n    pss[year]['Salary Paid'] = (pss[year]['Salary Paid']\n                                .replace('[$,]', '', regex=True)\n                                .replace('-', np.nan)\n                                .astype('float')\n                               )\n    pss[year]['Taxable Benefits'] = (pss[year]['Taxable Benefits']\n                                     .replace('[$,]', '', regex=True)\n                                     .replace('-', np.nan)\n                                     .astype('float')\n                                    )","af8694d4":"for year in YEARS:\n    pss[year] = pss[year].convert_dtypes()\n    print(year, pss[year].dtypes, sep='\\n', end='\\n\\n')","9ad9cdd9":"for year in YEARS:\n    if pss[year].isna().sum().sum() != 0:\n        print(year, pss[year].isna().sum(), sep='\\n', end='\\n\\n')","b7c505a7":"pss[2015]['Taxable Benefits'].eq(0).sum()","df563c53":"pss_comb = (pd.concat([pss[year] for year in YEARS])\n            .copy()\n            .reset_index(drop=True)\n           )\nno_tax_ben = (pss_comb\n              .loc[pss_comb['Taxable Benefits'].eq(0), 'Calendar Year']\n              .value_counts()\n              .reindex(list(YEARS), fill_value=0)\n              .to_frame()\n              .reset_index()\n              .rename(columns={'index': 'Calendar Year', 'Calendar Year': 'Number of employees'})\n             )","e1668763":"fig = px.scatter(no_tax_ben, x='Calendar Year', y='Number of employees')\nfig.update_traces(mode='lines+markers',\n                  hovertemplate=\n                  '<b>%{x}<\/b><br>'+\n                  'Number of employees: <b>%{y}<\/b>'\n                 )\nfig.update_layout(title='Number of employees that did not receive taxable benefits by calendar year',\n                  xaxis_title='Calendar Year',\n                  yaxis_title=\"Number of employees\",\n                  yaxis_tickformat=',',\n                  hoverlabel_bgcolor=\"white\",\n                  hoverlabel_font_size=14,\n                  hovermode=\"x\",\n                  yaxis_zerolinecolor='grey',\n                  yaxis_zerolinewidth=1\n                 )\nfig.show(config=CONFIG)","90d5ffa3":"pss[2015]['Taxable Benefits'].fillna(0.0, inplace=True)\nno_tax_ben.loc[no_tax_ben['Calendar Year'].eq(2015), 'Number of employees'] = pss[2015]['Taxable Benefits'].eq(0).sum()","45f51ae5":"fig = px.scatter(no_tax_ben, x='Calendar Year', y='Number of employees')\nfig.update_traces(mode='lines+markers',\n                  hovertemplate=\n                  '<b>%{x}<\/b><br>'+\n                  'Number of employees: <b>%{y}<\/b>'\n                 )\nfig.update_layout(title='Number of employees that did not receive taxable benefits by calendar year',\n                  xaxis_title='Calendar Year',\n                  yaxis_title=\"Number of employees\",\n                  yaxis_tickformat=',',\n                  hoverlabel_bgcolor=\"white\",\n                  hoverlabel_font_size=14,\n                  hovermode=\"x\",\n                  yaxis_zerolinecolor='grey',\n                  yaxis_zerolinewidth=1\n                 )\nfig.show(config=CONFIG)","162a3306":"null_2016 = pss[2016][pss[2016]['Taxable Benefits'].isna()]\nnull_2016","f8572e0a":"pss_comb[pss_comb['Last Name'].eq('Malenfant') & pss_comb['First Name'].eq('James')]","b6d7cdfd":"pss[2016].loc[null_2016.index, 'Taxable Benefits'] = 0.0","17b31e4f":"null_2013 = pss[2013][pss[2013]['First Name'].isna()]\nnull_2013","102a617b":"pss_comb[pss_comb['Last Name'].str.contains('^li$', case=False) & pss_comb['Employer'].str.contains('eHealth') & pss_comb['Job Title'].str.contains('privacy', case=False)]","7e017ac0":"pss2013 = pd.read_csv(PATH + 'pssd-en-2013.csv', na_filter=False)\npss2013[pss2013['Last Name'].str.contains('^li$', case=False) & pss2013['Employer'].str.contains('eHealth') & pss2013['Job Title'].str.contains('privacy', case=False)]","f3c40fac":"pss[2013].loc[null_2013.index, 'First Name'] = 'NA'","3a500c37":"null_1998 = pss[1998][pss[1998]['First Name'].isna()]\nnull_1998","31de09b3":"pss_comb[pss_comb['Last Name'].str.contains('donnelly', case=False) & pss_comb['Employer'].str.contains('hydro', case=False)]","ef29879e":"pss1998 = pd.read_csv(PATH + 'en-1998-pssd.csv', encoding='latin1', na_filter=False)\npss1998[pss1998['Last Name'].str.contains('donnelly', case=False) & pss1998['Employer'].str.contains('hydro', case=False)]","ed2c9882":"pss[1998][pss[1998]['First Name'].str.len().eq(2)].head()","9bb4440a":"pss[1998].loc[null_1998.index, 'First Name'] = 'NA'","208f2ed9":"null_1997 = pss[1997][pss[1997]['Job Title'].isna()]\nnull_1997","7fbbce88":"pss_comb[pss_comb['Last Name'].str.contains('walker', case=False) & pss_comb['Employer'].str.contains('ontario hydro', case=False)]","0e537845":"pss[1997].loc[null_1997.index, 'Job Title'] = 'Maintenance Superintendent'","20258f88":"null_1996 = pss[1996][pss[1996]['First Name'].isna()]\nnull_1996","fcf14f87":"pss_comb[pss_comb['Last Name'].str.contains('yearwood', case=False) & pss_comb['Calendar Year'].le(2010)]","4824de08":"pss1996 = pd.read_csv(PATH + 'en-1996-pssd.csv', encoding='latin1', na_filter=False)\npss1996[pss1996['Last Name'].str.contains('yearwood', case=False)]","fafc598e":"pss[1996][pss[1996]['First Name'].str.len().eq(2)].head()","9d18371f":"pss[1996].loc[null_1996.index, 'First Name'] = 'NA'","f0a9d487":"pss_comb = pd.concat([pss[year] for year in YEARS]).copy()","664e8f00":"pss_comb[pss_comb['Last Name'].str.contains('malenfant', case=False) & pss_comb['First Name'].str.contains('andrew', case=False)]","482fac95":"pss_comb","2be7f3f9":"pss_comb.sort_values(['Calendar Year', 'Sector', 'Employer', 'Last Name', 'First Name']).to_csv('pssd.csv', index=False)","3d7caf28":"We will look for \"James Malenfant\" in other years in hopes of being able to impute this value.","80dd28ec":"<a id=\"concat-data\"><\/a>\n[Return to table of contents](#table-of-contents)","756df8ec":"# Renaming columns","e455d476":"# Missing values","fee6a14f":"Finally, we convert the columns that have data type `object` to `string`. We may do so by calling `convert_dtypes()` on each dataframe. This will convert the columns to the best possible data types. The [Pandas documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/getting_started\/basics.html#dtypes) explains why this is a good idea:\n\n> Pandas has two ways to store strings.\n> 1. object dtype, which can hold any Python object, including strings.\n> 1. StringDtype, which is dedicated to strings.\n> \n> Generally, we recommend using StringDtype.\n> Finally, arbitrary objects may be stored using the object dtype, but should be avoided to the extent possible (for performance and interoperability with other libraries and methods).","33000e9a":"We sort the data as a final step before writing the data to a CSV file.","a959f5fc":"Since they have the same job title, \"Walker, D G\" from 1997 and \"Walker, G\" from 1998 seem to be the same person. The other \"Walker, G\" has the job title \"Maintenance Superintendent\" in 1998, which is one year after \"Walker, G J\" in 1997. My best guess then, is to say that \"Walker, G J\" has job title \"Maintenance Superintendent\". This [external page](https:\/\/www.ontariosunshinelist.com\/people\/fqpyng) seems to support my claim.","db04d281":"The Salary Paid and Taxable Benefits columns should have type `float` but it looks like they are currently strings because of the dollar signs and commas. We will fix this later.\n\nFirst, we will make sure that the column names of all dataframes match.\n\nSecond, we will deal with the data types of the columns. As mentioned above, we expect the Salary Paid and Taxable Benefits columns to have type `float`. The Calendar Year column should have type `int` and the rest of the columns should have type `string`.\n\nThen, we will check for missing values and see if there is a good way of imputing them. Finally, we will explore the possibility of concatenating the dataframes. After all, they should have the same number of columns, the same column names and data types, and one dataframe is easier to work with than 24 separate ones.","3add4c0a":"It seems as if every employee received some amount of taxable benefits in 2015. This seems unlikely, but we could take a look at the data from other years and compare.","bc8c0469":"Apart from the 6980 in the 2015 dataframe, there are not many missing values. Let's first find out why there are so many missing values in the Taxable Benefits column in 2015. Maybe those missing values are supposed to be zeros.","c692cdc4":"The dash only appears in the form \"$-\".\n\nOnce we have replaced all dollar signs and commas, we will replace all dashes with `np.nan` since these are missing values.","c14a5afe":"Unfortunately, 65 rows are affected. We need all values in the Calendar Year column to be 2016, meaning that we need to get rid of the current values somehow. It seems as though they are job titles. For example, the third row has value \"Deputy Minister\" in the Calendar Year column. The corresponding job title is \"Housing\", which surely cannot be a job title. On the other hand, we see that the row below it has job title \"Director\". But, the value in the Calendar Year column is \"seconded to Stevenson Memorial Hospital as CEO\".\n\nFrom the [2015 salary disclosure page](https:\/\/www.ontario.ca\/page\/public-sector-salary-disclosure-2015-all-sectors-and-seconded-employees):\n>Someone who is \u201cseconded\u201d has a job in a public sector organization (other than an Ontario government ministry), but currently works within a government ministry. The organization pays the person\u2019s salary and benefits and the ministry reimburses the organization.\n\nSince the dataframes at least have the same column names at this point, we will concatenate them to make our job easier for this section.","3041f234":"This is not helpful. Let's find out what the original value of the first name was.","a60875b9":"<a id=\"missing-values\"><\/a>\n[Return to table of contents](#table-of-contents)","511abcdc":"Again, a first name of \"NA\" was interpreted to be a missing value by the `pd.read_csv` function. This is the last missing value. If we had many missing values, we would have to deal with them in a less cumbersome way. For example, we could specify that we only want empty strings to be interpreted as missing values when reading in the data with `pd.read_csv`.\n\nJust like before, we'll keep the original first name of \"NA\", since it's not uncommon to have 2 letter initials in the 1996 data.","278d1bbd":"<a id=\"renaming-columns\"><\/a>\n[Return to table of contents](#table-of-contents)","ab7721e9":"# Write to CSV","a5811fe6":"Had we dropped the Calendar Year column before examining it closely, we would have lost job title information for 65 rows in the 2016 dataframe. Therefore, it is always a good idea to examine a column before dropping it when cleaning data.\n\nBefore moving on, we will take a look at the Calendar Year values in each dataframe to make sure that there are no surprises.","ee2e332e":"## Table of contents\n\n<p style=\"line-height: 1.6em;\">\n    <a href=\"#loading-data\">1. Loading the data<\/a><br>\n    <a href=\"#renaming-columns\">2. Renaming columns<\/a><br>\n    <a href=\"#data-types\">3. Data types<\/a><br>\n    <a href=\"#missing-values\">4. Missing values<\/a><br>\n    <a href=\"#concat-data\">5. Concatenating the dataframes<\/a><br>\n    <a href=\"#write-to-csv\">6. Writing to CSV<\/a><br>\n<\/p>","1cd62992":"The data spans from 1996 to 2019 and as we saw throughout this notebook, there were many inconsistencies. Here is just one of many examples:","5e5eaa36":"<a id=\"data-types\"><\/a>\n[Return to table of contents](#table-of-contents)","7f587b69":"The plot makes more sense now. The number of employees that did not receive taxable benefits in 2015 is between the corresponding values for 2014 and 2016.","b9642de4":"<a id=\"table-of-contents\"><\/a>","46f5e5fd":"Each column now has the desired data type. Since we are writing this data to a CSV, we will need to convert the data types again when we explore this data in a different notebook. So, why convert data types here? We ran into several issues while attempting to do so. The idea is to take care of those issues here instead of in an analysis notebook.","e955c486":"I think this is a good example because it displays several inconsistencies. It is clear that these records all belong to the same person. In the Sector column, some rows use the ampersand (&) instead of the word \"and\". In the Last Name and First Name columns, some values are in upper case while others are not. Also, in 2019, the first name is just \"Andrew\" instead of \"Andrew Derek\".\n\nIt would be nice if each person were given some sort of unique id. This way, even is a person's name changes, or if we see something like the example above, we would be able to easily tell whether two people on the list are the same person.\n\nIt is much easier to work with one dataframe as opposed to 24 and the calendar year column can always be used to separate the data again if needed. Another reason one CSV file is preferred over 24 is that file descriptions and column descriptions in the resulting dataset will only need to be specified one time instead of 24 times. I will also add a note in the dataset description about the inconsistency of the data across calendar years.","b948cc64":"It looks like the Calendar Year column in the 2015 dataframe has values other than 2015. Another important lesson: if we had assumed that there were no mistakes in the Calendar Year column, we could make some serious errors. For example, if we decided to concatenate the dataframes and perform a groupby operation on the Calendar Year column, then several rows would be incorrectly grouped into 2016, 2017, and 2018.","06e45492":"This notebook was used to clean Ontario's public sector salary disclosure data (also known as the Ontario sunshine list). The cleaned dataset can be found [here](https:\/\/www.kaggle.com\/sahidvelji\/the-ontario-sunshine-list), and an EDA of the 2019 data can be found [here](https:\/\/www.kaggle.com\/sahidvelji\/the-ontario-sunshine-list-2019-eda).","22459c20":"Unfortunately, we discover more inconsistencies. Quickly scrolling through the output tells us that for most dataframes, the Calendar Year column has data type `int`, except for the 2016 dataframe. Also, the dataframes for 2012 and 2013 have type `float` for the Salary Paid and Taxable Benefits columns while the other dataframes have type `object` for these columns.\n\nLet's find out why the Calendar Year column in the 2016 dataframe doesn't have type `int`.","0b4b36c4":"In 2011, 2013, and 2018, the job titles are of the form \"English \/ French\", unlike the other years. Even worse, in 2011, both the employer and job title are of the form \"English \/ French\" but in 2013, only the job title is. Even the name columns are inconsistent: from 2007 to 2013, the first and last names are in upper case, unlike 2014 to 2019. From 2014 to 2017, the first name column has an initial \"J.\", which is not consistent with the rest of the years.\n\nThis one gives us an idea. We could append the string in the Calendar Year column to the job title column, separated by a semicolon, as in 2015.","b5f677cf":"That should do it. The year appears either at the beginning of the filename or after a dash. The character following the year is either a dash, a dot, or an underscore. This means we have a non-numeric character following the year. The regular expression was constructed based on these observations: first we match the beginning of a string or a dash in a non-capturing group. Then, we match 4 digits in a capturing group. This is followed by a single non-numeric digit.\n\nUnfortunately, we encounter a `UnicodeDecodeError` if we try to load the data with the standard utf-8 encoding for some of the files. Instead, we'll use latin1 encoding if the default fails. The error occurs due to characters such as \"\u00e9\" in the data.","2f07077a":"Just like before, a first name of \"NA\" was marked as a missing value. Donnelly's first name is probably not \"NA\" though. It's more likely that these are initials. It's not uncommon in the 1998 data to have 2 letter initials in the First Name column.","5b13a637":"# Data types","983d1fbf":"There are numerous inconsistencies:\n\n- There is an extra column in the 1996 dataframe. \n- The 2001 dataframe has Surname instead of Last Name and Position instead of Job Title. \n- There are trailing whitespaces in the Salary Paid column in the 2009, 2010, and 2011 dataframes.\n- In the 2014 dataframe, the second words of \"Last name\", \"Job title\", and \"Calendar year\" are not capitalized. \n\nWe will first examine the extra column in the 1996 dataframe and drop it if appropriate.","2a28fb36":"Let's take a closer look at a few people's job titles and corresponding calendar year values in attempt to find a solution to this problem.","8d23b120":"That doesn't look promising. We expect a single unique value for the Calendar Year column, but we have 38 unique values instead.","ef2de04c":"Now that the Calendar Year column has the same data type across all dataframes, we will move on to examine the Salary Paid and Taxable Benefits columns. We already saw that we need to remove dollar signs and commas. But, is that everything? We will check for other non-numeric characters. In the two code cells below, we search for any non-numeric characters excluding dollar signs, commas, periods, and spaces.","216c9986":"While downloading the data from the government of Ontario website, I realized that the filenames were inconsistent. Even worse, there are two files that appear to both be data from 2018: `en-2018-pss-compendium.csv` and `en-2018-pss-compendium-20191223.csv`. Let's examine these two files.","642a8782":"This unnamed column is filled with `NaN` values, meaning that we can safely drop this column.","200c8c7e":"It turns out that `en-2018-pss-compendium.csv` is actually data from 2017 and `en-2018-pss-compendium-20191223.csv` is data from 2018. The input directory is read-only data, so we cannot rename files here. However, we will use a dictionary to organize the files by year after loading them into dataframes. First, we'll create a regular expression to extract the year from each filename. ","816eb93f":"Fagan's job title in 2016 is very likely \"Member\", just as in subsequent years.","1e5d6849":"Based on the record from 1999, we can safely assume that Donnelly's first initial is \"N\". However, just as we saw above, it may be the case that `pd.read_csv` marked Donnelly's first name as a missing value.","d0239e74":"We can safely assume that Li's first name is Na based on the record from 2014. It looks like the first name \"NA\" was marked as a missing value in the 2013 data. The first name \"Na\" in the 2014 data was not marked as a missing value. From the `pandas.read_csv` [documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_csv.html):\n\n> **na_values: scalar, str, list-like, or dict, optional**   \n> Additional strings to recognize as NA\/NaN. If dict passed, specific per-column NA values. By default the following values are interpreted as NaN: \u2018\u2019, \u2018#N\/A\u2019, \u2018#N\/A N\/A\u2019, \u2018#NA\u2019, \u2018-1.#IND\u2019, \u2018-1.#QNAN\u2019, \u2018-NaN\u2019, \u2018-nan\u2019, \u20181.#IND\u2019, \u20181.#QNAN\u2019, \u2018<NA>\u2019, \u2018N\/A\u2019, \u2018NA\u2019, \u2018NULL\u2019, \u2018NaN\u2019, \u2018n\/a\u2019, \u2018nan\u2019, \u2018null\u2019.\n    \nThis means that LI's first name \"NA\" in the 2013 data was likely never really a missing value to begin with. Let's find out what the original first name value was in 2013. We can do so by passing the argument `False` to the `na_filter` parameter when calling `pd.read_csv`.","94dcb432":"# Loading the data","edee6131":"Based on the above plot, we can reasonably assume that the missing values for the 2015 Taxable Benefits column must be zeros. We will fill in the missing values and then plot the data again.","59cd31f0":"# Concatenating the dataframes","564c09fa":"Now that every dataframe has the same number of columns, let's rename all columns to match the columns of the 2019 dataframe.","7faa24bb":"Here, we will examine the data types of the columns and ensure that they match across all dataframes.","4d60289d":"Indeed we see that the first name was originally \"NA\", but was marked as a missing value. We will set the missing first name to \"NA\" instead of \"Na\" in order to be consistent, since names in the 2013 data seem to be in upper case only.","5d6ad4ac":"Since James Malenfant does not usually receive taxable benefits, it is reasonable to assume that he didn't receive taxable benefits in 2016 either.","c9b9c946":"The 2016 data has one missing value in the Taxable Benefits column.","a5113124":"Only a few of the rows are affected. Since this data was released in 2016 for the calendar year 2015, the above values don't make sense. We will correct these now.","cda21f27":"We will check to make sure that every dataframe has the same column names using the 2019 columns as a reference.","f71bcc9c":"Now we have a dictionary where each key is a calendar year and the value is the corresponding dataframe. The `describe` method is a useful way of displaying a summary table of the data. Examining all 24 tables one by one wouldn't be very efficient but we'll display the tables here for reference purposes anyways.","d9bc3fad":"It is clear that in 2016, Laurie Leblanc's job title should be \"Deputy Minister\". So, we could replace \"Housing\" with \"Deputy Minister\". But, the problem is that this is not a general solution. For example, is Dora Cavallo-Medved's (in the wrong_year dataframe, third row from the bottom) job title \"Sessional Lecturer I\" or \"Course Developer\"?","9c0b16e5":"The 1996 data has one missing value in the First Name column.","ae445069":"It looks like we have dashes in the Taxable Benefits column. We will need to remove these before converting to this column to the `float` data type. Before we do so, we should take a look at how the dash appears in the data.","afc73b63":"The 1997 data has one missing value in the Job Title column.","da48ff6e":"The 1998 data has one missing value in the first name column.","14834c06":"<a id=\"write-to-csv\"><\/a>\n[Return to table of contents](#table-of-contents)","865ab534":"# Cleaning The Ontario Sunshine List Data","1622e6ce":"Therefore, we'll set the missing first name to \"NA\", as it was originally.","a172a15a":"The 2013 data has one missing value in the First Name column.","d8cbfda1":"The Calendar Year column may seem redundant because of the file name. For example, we know that all of the data in `tbs-pssd-compendium-en-utf8-2019.csv` is for the calendar year 2019. However, we will not drop this column yet in case we later want to concatenate the dataframes."}}