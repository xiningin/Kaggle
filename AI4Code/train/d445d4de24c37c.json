{"cell_type":{"e944e3cf":"code","808ff320":"code","96447506":"code","6857ec01":"code","792a6a74":"code","ccf37d3d":"code","afc6a884":"code","43a5b4d6":"code","c6773a9a":"code","2a487aa0":"code","8bac076f":"code","dcccbfcd":"code","b994bc45":"code","9de22843":"code","7e55d590":"code","cae41daa":"code","12ee7e7d":"code","3a83b1ec":"code","412236e7":"code","51a5df33":"code","d3bfab06":"code","9fe5caaf":"code","d4707403":"code","32df7892":"code","f554f106":"code","0fc98d80":"code","3966aac7":"code","4d1d25b4":"code","7c7f55b8":"code","4cd208ee":"code","7f3dce54":"code","98189bfd":"code","b56f9e11":"code","ab59b148":"code","c3241912":"code","b9d373d3":"code","1642c56c":"code","b1400158":"code","a4ad390a":"code","33534d80":"code","c89a97d7":"code","68e0fc71":"code","ae0fd8eb":"code","d3d578c2":"code","dfa27a54":"code","660164ba":"code","3a05a368":"code","c75835f3":"code","b0f5c3f4":"code","a8958d30":"code","46ffd8ed":"code","9ec26e77":"code","bdd8d39b":"code","e23f38a0":"code","09b6c7cb":"code","6cfe1537":"code","6880698a":"code","f57706dc":"code","196f4a8b":"code","db4c1871":"code","c63b338b":"code","0ebd0e64":"code","3b56b7e3":"code","d1533349":"code","c4bd8206":"code","658d822f":"code","b8891d92":"code","117beb51":"code","9aff3543":"code","c56d6632":"code","4f6a000d":"code","5c148c9b":"code","2c90a258":"code","f81f41b0":"code","eed9ce56":"code","816eed9d":"code","87d61b81":"code","a18c28e3":"code","4128c120":"code","8b7da0e0":"code","50bbf89d":"code","43f26519":"code","388076aa":"code","4bb3001c":"code","99304537":"code","5d26a418":"code","886807fd":"code","9bb88698":"code","c5784e08":"code","7d97ce8b":"code","734bbc82":"markdown","8ab42f2d":"markdown","e01bd505":"markdown","1b44f375":"markdown","16d58071":"markdown","2699702d":"markdown","33b848ad":"markdown","b60f6e28":"markdown","f7a619fb":"markdown","a9d3f40d":"markdown","ad987831":"markdown","656349ee":"markdown","b69a5408":"markdown","0018cdc0":"markdown","53cb8064":"markdown","4de13ded":"markdown","9717ef96":"markdown","ca9c79d4":"markdown","40ce2aea":"markdown","08923917":"markdown","1b4b16ce":"markdown","a0df3c6e":"markdown","976f21e8":"markdown","b40c40ae":"markdown","1e722953":"markdown","4ee4e2ae":"markdown","717bb97a":"markdown","1916c8cc":"markdown"},"source":{"e944e3cf":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import skew\nimport matplotlib.pyplot as plt","808ff320":"traindata=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntestdata=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","96447506":"traindata.head()","6857ec01":"traindata.shape  , testdata.shape","792a6a74":"traindata.columns","ccf37d3d":"traindata.info()","afc6a884":"traindata.describe()","43a5b4d6":"traindata['SalePrice'].describe()","c6773a9a":"sns.distplot(traindata['SalePrice']);","2a487aa0":"print('Skewness :%f' %traindata['SalePrice'].skew())","8bac076f":"print('Kurtosis : %f' %traindata['SalePrice'].kurt())","dcccbfcd":"traindata.corr()","b994bc45":"corrmat = traindata.corr()\nplt.figure(figsize=(12,12))\nsns.heatmap(corrmat,square = True )","9de22843":"corrmat=traindata.corr()\ntop_corr=corrmat.index[abs(corrmat['SalePrice'])>0.5]\nplt.figure(figsize=(10,10))\nsns.heatmap(traindata[top_corr].corr() ,annot=True)","7e55d590":"traindata.corr()['SalePrice']","cae41daa":"col=['SalePrice','OverallQual' , 'GrLivArea' , 'GarageArea' ,'TotalBsmtSF', '1stFlrSF','FullBath', 'YearBuilt']\nsns.pairplot(traindata[col])","12ee7e7d":"Y=traindata.SalePrice\ntraindata=traindata.drop(['SalePrice'],axis=1)\ntraindata.shape","3a83b1ec":"AllData=pd.concat([traindata ,testdata],axis=0)\nAllData.shape","412236e7":"total= AllData.isnull().sum().sort_values(ascending = False)\npercent= (AllData.isnull().sum()\/AllData.isnull().count()).sort_values(ascending= False)\nmissingdata = pd.concat([total,percent],axis=1,keys=['total','percent'])\nmissingdata.head(40)","51a5df33":"AllData= AllData.drop(['PoolQC' , 'MiscFeature' ,'Alley' ,'Fence','Id',  'FireplaceQu','1stFlrSF','GrLivArea','GarageCars'],axis=1)","d3bfab06":"AllData.shape","9fe5caaf":"Garage_feature=['GarageYrBlt','GarageCond','GarageType','GarageFinish','GarageQual']\nBasment_feature=['BsmtExposure','BsmtFinType2','BsmtQual','BsmtCond','BsmtFinType1']\nfor i in Garage_feature:\n    AllData[i].fillna(0,inplace=True )\n\nfor i in Basment_feature:\n    AllData[i].fillna(0,inplace=True )\n\nAllData['LotFrontage'].fillna(AllData['LotFrontage'].mean(),inplace=True)\nAllData['MasVnrArea'].fillna(AllData['MasVnrArea'].mean(),inplace=True)\nAllData['MasVnrType'].fillna(0,inplace=True )\nAllData['Electrical'].fillna(AllData['Electrical'].mode()[0],inplace=True)\n\n\nAllData['BsmtHalfBath'].fillna(0,inplace=True )\nAllData['Utilities'].fillna('AllPub',inplace=True )\nAllData['Functional'].fillna('Typ',inplace=True )\n#testdata['BsmtHalfBath'].fillna(0,inplace=True )\nAllData['BsmtFinSF1'].fillna(traindata['BsmtFinSF1'].mode()[0],inplace=True)\nAllData['BsmtFinSF2'].fillna(traindata['BsmtFinSF2'].mode()[0],inplace=True)\nAllData['KitchenQual'].fillna(traindata['KitchenQual'].mode()[0],inplace=True)\nAllData['TotalBsmtSF'].fillna(traindata['TotalBsmtSF'].mode()[0],inplace=True)\nAllData['Exterior2nd'].fillna(traindata['Exterior2nd'].mode()[0],inplace=True)\n#testdata['GarageCars'].fillna(traindata['GarageCars'].mode()[0],inplace=True)\nAllData['Exterior1st'].fillna(traindata['Exterior1st'].mode()[0],inplace=True)\nAllData['GarageArea'].fillna(traindata['GarageArea'].mode()[0],inplace=True)\nAllData['SaleType'].fillna(traindata['SaleType'].mode()[0],inplace=True)\nAllData['MSZoning'].fillna(traindata['MSZoning'].mode()[0],inplace=True)\nAllData['BsmtFullBath'].fillna(traindata['BsmtFullBath'].mode()[0],inplace=True)\nAllData['BsmtUnfSF'].fillna(traindata['BsmtUnfSF'].mode()[0],inplace=True)","d4707403":"AllData['GarageYrBlt'] = 2021-AllData['GarageYrBlt']\nAllData['YearBuilt'] = 2021-AllData['YearBuilt']\nAllData['YearRemodAdd'] = 2021-AllData['YearRemodAdd']\nAllData['YrSold'] = 2021-AllData['YrSold']\nAllData[['GarageYrBlt','YearBuilt','YearRemodAdd','YrSold']].head()","32df7892":"AllData.isnull().sum().max()","f554f106":"numerical_feature=AllData.select_dtypes(exclude=['object']).columns\ncataorical_feature=AllData.select_dtypes(include=['object']).columns\nnumerical_feature","0fc98d80":"len(numerical_feature)","3966aac7":"len(cataorical_feature)","4d1d25b4":"All_num = AllData[numerical_feature]\nAll_cat = AllData[cataorical_feature]\nAll_num.shape","7c7f55b8":"# checkin skewmess of all features\nskewness = All_num.apply(lambda x: skew(x))\nskewness.sort_values(ascending=False)","4cd208ee":"skewness_Y=skew(Y)\nskewness_Y","7f3dce54":"skewness=skewness[abs(skewness)>0.5]\nskewness.index","98189bfd":"All_num[skewness.index]=np.log1p(All_num[skewness.index])\nY=np.log1p(Y)","b56f9e11":"All_cat.shape","ab59b148":"All_cat=pd.get_dummies(All_cat,drop_first=True)\nAll_cat","c3241912":"AllData_1=pd.concat([All_cat,All_num],axis=1)","b9d373d3":"AllData_1.shape","1642c56c":"sns.boxplot(Y)","b1400158":"AllData_1['LotArea'].describe()","a4ad390a":"def outlier(z):\n    upper_limit= AllData_1[z].mean()+ 3* AllData_1[z].std()\n    lower_limit=  AllData_1[z].mean()- 3* AllData_1[z].std()\n    AllData_1[z]=np.where( AllData_1[z]>upper_limit ,upper_limit,\n                   np.where( AllData_1[z]<lower_limit, lower_limit ,\n                             AllData_1[z]\n                   )\n        )\n    print('Upperlimit : {} and lowerlimit : {} and Columns name is: {}'.format(upper_limit,lower_limit,z))\n    ","33534d80":"for i in numerical_feature:\n    outlier(i)\n    \n\n  ","c89a97d7":"AllData_1['LotArea'].describe()","68e0fc71":"Y.describe()","ae0fd8eb":"Y","d3d578c2":"max_limit= Y.mean()+ 3*Y.std()\nmin_limit= Y.mean()- 3*Y.std()\nprint(min_limit , max_limit)\nY=np.where( Y > max_limit , max_limit ,\n                   np.where( Y< min_limit, min_limit ,\n                             Y\n                   )\n        )","dfa27a54":"Y","660164ba":"traindata.shape ,testdata.shape","3a05a368":"traindata_1=AllData_1.iloc[:1460,:]\n#pd.concat([traindata_1,Y],axis=1)\ntraindata_1","c75835f3":"testdata_1=AllData_1.iloc[1460:,:]\ntestdata_1","b0f5c3f4":"X = traindata_1","a8958d30":"from sklearn.ensemble import RandomForestRegressor","46ffd8ed":"RFR =RandomForestRegressor(n_jobs=-1,random_state=1)","9ec26e77":"from sklearn.model_selection import GridSearchCV","bdd8d39b":"para={\n    'max_depth':[2,5,10,50,100,150],\n    'min_samples_leaf':[2,5,7,50,100,200],\n    'n_estimators':[5,10,30,50,100,200]\n}","e23f38a0":"%%time\ngrid_serch=GridSearchCV(estimator=RFR,\n                       param_grid=para,\n                      cv=5,\n                      n_jobs=-1, scoring=\"neg_mean_squared_error\" ,verbose=1\n                      )","09b6c7cb":"grid_serch.fit(X,Y)","6cfe1537":"rfbest_estimator=grid_serch.best_estimator_\nrfbest_estimator","6880698a":"rfbest_estimator.feature_importances_","f57706dc":"imp_fea=pd.DataFrame({\n    'variable':X.columns,\n    'imp': rfbest_estimator.feature_importances_\n})\nfeature=imp_fea.sort_values(by='imp',ascending= False)\nfeature.head(50)","196f4a8b":"from sklearn.preprocessing import StandardScaler","db4c1871":"sc=StandardScaler()","c63b338b":"col=X.columns\nX=pd.DataFrame(sc.fit_transform(X))\nX.columns = col\nX","0ebd0e64":"col=testdata_1.columns\ntestdata_1=pd.DataFrame(sc.fit_transform(testdata_1))\ntestdata_1.columns = col\ntestdata_1","3b56b7e3":"from sklearn. linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split as tts","d1533349":"from sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split as tts","c4bd8206":"x_train,x_test,y_train,y_test=tts(X,Y,test_size=0.2,random_state=42)","658d822f":"x_train","b8891d92":"lm = LinearRegression()\nlm.fit(x_train, y_train)\n\nrfe = RFE(lm, 50) # running RFE\nrfe = rfe.fit(x_train, y_train)","117beb51":"col = x_train.columns[rfe.support_]\ncol","9aff3543":"# Creating X_train & X_test dataframes with RFE selected variables\nx_train_rfe = x_train[col]\nx_test_rfe = x_test[col]\nlm.fit(x_train_rfe,y_train)\ny_pred_rfe=lm.predict(x_test_rfe)\nmean_squared_error(y_test,y_pred_rfe)","c56d6632":"\nparams = {'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, \n                    9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n\nridge = Ridge()\n\nfolds = 5\nridge_model_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nridge_model_cv.fit(x_train_rfe, y_train)","4f6a000d":"ridge_cv_results = pd.DataFrame(ridge_model_cv.cv_results_)\nridge_cv_results[['param_alpha', 'mean_train_score', 'mean_test_score', 'rank_test_score']].sort_values(by = ['rank_test_score'])","5c148c9b":"#checking the value of optimum number of parameters\nprint(ridge_model_cv.best_params_)","2c90a258":"# Building the model with alpha\nridge = Ridge(alpha=ridge_model_cv.best_params_['alpha'])\n\nridge.fit(x_train_rfe, y_train)\ny_train_pred = ridge.predict(x_train_rfe)\ny_test_pred = ridge.predict(x_test_rfe)\n\nprint(r2_score(y_true=y_train,y_pred=y_train_pred))\nprint(r2_score(y_true=y_test,y_pred=y_test_pred))","f81f41b0":"params = {'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, \n                    9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n\nridge = Ridge()\n\nfolds = 5\nridge_model_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nridge_model_cv.fit(x_train, y_train)","eed9ce56":"ridge_cv_results = pd.DataFrame(ridge_model_cv.cv_results_)\nridge_cv_results[['param_alpha', 'mean_train_score', 'mean_test_score', 'rank_test_score']].sort_values(by = ['rank_test_score'])","816eed9d":"#checking the value of optimum number of parameters\nprint(ridge_model_cv.best_params_)","87d61b81":"# Building the model with alpha\nridge = Ridge(alpha=ridge_model_cv.best_params_['alpha'])\n\nridge.fit(x_train, y_train)\ny_train_pred = ridge.predict(x_train)\ny_test_pred = ridge.predict(x_test)\n\nprint(r2_score(y_true=y_train,y_pred=y_train_pred))\nprint(r2_score(y_true=y_test,y_pred=y_test_pred))","a18c28e3":"mean_squared_error(y_test,y_test_pred)","4128c120":"model_param = list(ridge.coef_)\nmodel_param.insert(0,ridge.intercept_)\ncols = x_train.columns\nmodel_rigi_coe=pd.DataFrame(list(zip(model_param ,col)))\nmodel_rigi_coe.head()","8b7da0e0":"lasso = Lasso()\n\nfolds = 10\nlasso_model_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nlasso_model_cv.fit(x_train, y_train)","50bbf89d":"lasso_cv_results = pd.DataFrame(lasso_model_cv.cv_results_)\nlasso_cv_results[['param_alpha', 'mean_train_score', 'mean_test_score', 'rank_test_score']].sort_values(by = ['rank_test_score'])","43f26519":"#checking the value of optimum number of parameters\nprint(lasso_model_cv.best_params_)","388076aa":"\nlasso = Lasso(alpha=lasso_model_cv.best_params_['alpha'])\n\nlasso.fit(x_train, y_train)\ny_train_pred = lasso.predict(x_train)\ny_test_pred = lasso.predict(x_test)\n\nprint(r2_score(y_true=y_train,y_pred=y_train_pred))\nprint(r2_score(y_true=y_test,y_pred=y_test_pred))","4bb3001c":"mean_squared_error(y_test,y_test_pred)","99304537":"testdata_1.isnull().sum().sort_values(ascending=False)\n","5d26a418":"testdata_1['GarageYrBlt'].fillna(traindata['GarageYrBlt'].mode()[0],inplace=True)\ntestdata_1.isnull().sum().sort_values(ascending=False)","886807fd":"y_pred=lasso.predict(testdata_1)\ny_pred_final=np.exp(y_pred)","9bb88698":"submission=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsubmission.head()","c5784e08":"submission.iloc[:, 1] =y_pred_final\nsubmission.to_csv('submission.csv', index=False)","7d97ce8b":"y_pred_final[0]","734bbc82":"#### From the above heatmap of correlaion we can say that OverallQual , GrLivArea , GarageCars, GarageArea , TotalBsmtSF, 1stFlrSF are highly related with SalePrice\nIf we take look at multicolinearity then \n1. TotalBsmtSF  vs 1stFlrSF \n2. TotRmsAbvGrd vs GrLivArea\n3. GrageArea vs GrageCars","8ab42f2d":"First we seperate the Numerical and Catagorical Variabel","e01bd505":"**Building model using Ridge Regression with RFE feature**","1b44f375":"### Missing Value \nFirst we will look at missing valves in our traindata set ","16d58071":"**So for Final Prediction we use Lasso Regression**","2699702d":"Kurtosis is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a normal distribution. In other words, kurtosis identifies whether the tails of a given distribution contain extreme values(Outlier).","33b848ad":"'GrLivArea' , 'GarageArea' ,'TotalBsmtSF', '1stFlrSF','FullBath' show linear relationship with SalePrice","b60f6e28":"### Checking and removing Outliers","f7a619fb":"**Finding :**\nThe optimal lambda value in case of Ridge and Lasso is as below:\n\nRidge - 5.0\n\nLasso - 0.005\n\nThe Mean Squared error in case of Ridge and Lasso are:\n\nRidge - 0.02255\n\nLasso - 0.01906\n\n\nThe r2_score for test data in case of Ridge and Lasso are:\n\nRidge - 87.9%\n\nLasso - 89.02%","a9d3f40d":"### Scaling the Data","ad987831":" As we can see PoolQC , MiscFeature ,Alley\t,Fence, has  most missing value more than 80% so we willdrop this feature  as well as  FireplaceQu . And due to multicolinearity we will derop 1stFlrSF','GrLivArea','GrageCars' this feature","656349ee":"from above graph we can say that SalePrice is positively skewed , let  calulate the skewness and Kurtosis ","b69a5408":"As we can see  in LotArea max: 10.624562  and min is : 7.565269 . so this how capping done And insted of droping the outlier we will replace it from this processes we will not lose the information ","0018cdc0":"### Lets look at depended variabel i.e SalePrice","53cb8064":"Using RFE for Initial Feature Selection","4de13ded":"#### Lets plot the scatter plot  OverallQual , GrLivArea , GarageCars, GarageArea , TotalBsmtSF, 1stFlrSF  and saleprice ","9717ef96":"### Lets take a look at correlation for trainindata set","ca9c79d4":"**Building model using Ridge Regression with all Data**","40ce2aea":"In dataset if there is no garage availabel to  house then entry shows as NA so we will fill this value as 0 it mean it has no garage  and same goes for BsmtExposure and BsmtFinType2\t","08923917":"### Dealing with categorical variabel","1b4b16ce":"##### As we can see from boxplot the are many outlier in SalePrice .We will use Z-score tretment for detectin and removin the outliers","a0df3c6e":"### we will select the feature whos skewness >0.5","976f21e8":"### Skweness\nLets Chek the skwenees of feature of traindata fix the skwness as we know while doing the regression Normality is one of the assumption","b40c40ae":"As we can see  in LotArea max: 12.279537  and min is : 7.170888 after processing this we will see the result","1e722953":"### Shape or dimentions of train and test data","4ee4e2ae":"### Linear model make some assumption :\n1. Linear Relationship\n2. No auto-correlation between error term \n3. No milticollinearity between independent variabel\n4. Normal Distribution of error term\n5. Homoscedasticity\n\nwe will take this assumption into consideartion while  bulding the model","717bb97a":"**Building model using Lasso Regression**","1916c8cc":"## Importing the data"}}