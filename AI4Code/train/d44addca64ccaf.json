{"cell_type":{"10595b7e":"code","c7ffcbec":"code","cbda92fe":"code","f013ec5d":"code","13c1c454":"code","2a608677":"code","25f56c53":"code","1bf21b58":"code","d484834d":"code","bfbae48c":"code","37e4306e":"code","1c0109fb":"markdown","2bdd9094":"markdown","09ebc3a6":"markdown","b9dc5258":"markdown","a782fc8f":"markdown","ebedb9eb":"markdown","901da438":"markdown","24edeed7":"markdown","36bd83b0":"markdown","e9526c4d":"markdown","266b939b":"markdown"},"source":{"10595b7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c7ffcbec":"import tensorflow as tf\n\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n","cbda92fe":"train_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\n\n\n\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","f013ec5d":"data_labels = train_data['label']\n\ny = data_labels\n\ndata_new = train_data.drop(['label'], axis=1)\n\ndata_arr = np.array(data_new).reshape(-1,28,28)\n\ndata_clean = data_arr \/ 255.0\n\ndata = data_clean\n\nX = data\n\ntest_new = test\n\ntest_arr = np.array(test_new).reshape(-1,28,28)\n\ntest_clean = test_arr \/ 255.0\n\ntest_data = test_clean\n","13c1c454":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(data[i], cmap=plt.cm.binary)\n    plt.xlabel(data_labels[i])\nplt.show()","2a608677":"X_train, X_test, y_train, y_test = train_test_split(X, y , random_state=1, test_size=0.2)","25f56c53":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10)\n])","1bf21b58":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","d484834d":"model.fit(X_train, y_train, epochs=20)","bfbae48c":"test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","37e4306e":"pred = model.predict(test_data)\n\noutput = pd.DataFrame()\n\noutput['ImageId'] = list(range(1,28001))\n\npredictions = []\nfor p in pred:\n    predictions.append(np.argmax(p))\n \noutput['Label'] = predictions\n\noutput.to_csv(\"my_submission.csv\", index=False)\n\n","1c0109fb":"* Visualization","2bdd9094":"* Make predictions","09ebc3a6":"* Compile the model","b9dc5258":"Data split into tarin and test splits","a782fc8f":"* import required libraries","ebedb9eb":"* Data collection and preparation","901da438":"# Building the Model","24edeed7":"Evaluate the model","36bd83b0":"* Data collection","e9526c4d":"* Setting up layers","266b939b":"* Train the model"}}