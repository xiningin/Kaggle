{"cell_type":{"51281531":"code","46616bdb":"code","0e8be4c7":"code","2425f1b0":"code","1c1f83bd":"code","3163b3cf":"code","2005e1ab":"code","4dcaa3bf":"code","fe491815":"code","7c504265":"code","8d0dc78b":"code","d12ded5c":"code","d11362c7":"code","51d34dd2":"code","8bc1ea60":"code","d0226711":"code","d71f1297":"code","c921d520":"code","2b2a15b5":"code","813d1e4a":"code","d7d9ceaa":"markdown","a894559b":"markdown","052de689":"markdown","5c04f76d":"markdown","5f7c7900":"markdown","1d2ab85f":"markdown","5a3a60eb":"markdown","5b7a4c76":"markdown"},"source":{"51281531":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Algrithms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46616bdb":"#Importing Dataset\ndf=pd.read_csv('..\/input\/Social_Network_Ads.csv')","0e8be4c7":"#Checking Dataset\ndf.head(10)","2425f1b0":"#Cheking Datatypes and other info\ndf.info()","1c1f83bd":"#Checking Shape\ndf.shape","3163b3cf":"#Checking for missing values\ndf.isnull().sum()","2005e1ab":"#Summarizing Dataset\ndf.describe()","4dcaa3bf":"df=df.drop(['User ID'],axis=1)","fe491815":"sns.barplot(x=df['Gender'],y=df['Age'])","7c504265":"plt.figure(figsize=(20,5))\nsns.barplot(x=df['Age'],y=df['EstimatedSalary'])","8d0dc78b":"sns.barplot(x=df['Purchased'],y=df['Age'])","d12ded5c":"X=df[['Age','EstimatedSalary']]\ny=df['Purchased']","d11362c7":"#splitting Dataset\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=1\/3,random_state=0)","51d34dd2":"#Feature Scaling\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.transform(X_test)","8bc1ea60":"#Fitting K-NN to training set\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)","d0226711":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)","d71f1297":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","c921d520":"accuracy=accuracy_score(y_test,y_pred)\nprint(\"Accuracy of Model is: \", accuracy)","2b2a15b5":"\n# Visualising the Training set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('K-NN (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","813d1e4a":"# Visualising the Test set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('K-NN (Test set)')\nplt.xlabel('Age')","d7d9ceaa":"We dropped User ID column because it does'nt require for predication","a894559b":"Above Graph showing count of Purchased age wise","052de689":"# Visualizing Data","5c04f76d":"From above, age of Buyer is between 18 and 60.And mean ages is 37.6.\n\n","5f7c7900":"# Splitting Data for Modelling","1d2ab85f":"The Dataset have 5 columns. First column is not necessary for prediction, other 3 columns are predictors and the last one is Target. There is one categorical variable Gender which would be encoded.","5a3a60eb":"Salary of a perosn with age is shown above","5b7a4c76":"There's No missing value means our dataset is cleaned."}}