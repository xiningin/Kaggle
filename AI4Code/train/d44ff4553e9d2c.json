{"cell_type":{"7dabf771":"code","45af7dde":"code","c4937eed":"code","c8f935b8":"code","02c21abd":"code","312699f0":"code","1feb50a6":"code","cd136038":"code","5cc89cf6":"code","85f8c488":"code","b4c5230e":"code","ff313006":"code","089be56e":"code","6b2043fc":"code","4e9ed547":"code","f367ea6b":"code","0a748ee0":"code","5bcdcf69":"code","1c944a20":"code","ce9ffa92":"code","dd2d7b50":"markdown","9d0ad662":"markdown","6693d755":"markdown","437288cf":"markdown","21e67ea2":"markdown","ddfe0f50":"markdown","10bc997d":"markdown","12997d2a":"markdown","cc2a183e":"markdown","d3dc3233":"markdown","b4999ab7":"markdown","45decbb7":"markdown"},"source":{"7dabf771":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas_profiling import ProfileReport # Quick EDA (explorative data analysis)\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","45af7dde":"# File names for train, test and random submission\ntrain_csv = \"train.csv\"\ntest_csv = \"test.csv\"\nrandom_submission_csv = \"random_submission.csv\" ","c4937eed":"# Load the csv's to dataframes and show them\n\ndf_random_submission = pd.read_csv(os.path.join(dirname, random_submission_csv))\ndf_train = pd.read_csv(os.path.join(dirname, train_csv))\ndf_test = pd.read_csv(os.path.join(dirname, test_csv))\n\ndisplay(df_train)\ndisplay(df_test)\ndisplay(df_random_submission)","c8f935b8":"# Setting minimal=False in the following line will give you richer information \nprofile = ProfileReport(df_train, title=\"Train Set Profiling Report\",  minimal=True) \nprofile.to_widgets()","02c21abd":"# Survival rate in each Pclass\ndf_train.groupby(\"Pclass\")[\"Survived\"].mean().plot(kind=\"barh\")","312699f0":"# Do more analysis\n","1feb50a6":"# This cell is just for demostration purpose. Skip\/delete as needed.\n# Suppose you think that survival rate is higher if Tickets starts with \"CA\" \ndf_train[\"Ticket_CA\"] = df_train[\"Ticket\"].apply(lambda x: int(x.startswith(\"CA\")))\ndf_test[\"Ticket_CA\"] = df_test[\"Ticket\"].apply(lambda x: int(x.startswith(\"CA\")))\n\ndf_train[\"Ticket_CA\"].describe()","cd136038":"# Do more engineering\n","5cc89cf6":"# Modify as needed\nfeature_cols = [ 'Pclass', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Fare']","85f8c488":"# Create dataframes with the necessary columns\ndf_train_feature = df_train[feature_cols]\ndf_test_feature = df_test[feature_cols]","b4c5230e":"# Get columns with any null values\ntrain_null_cols = df_train_feature.columns[df_train_feature.isnull().sum() > 0]\ntest_null_cols = df_test_feature.columns[df_test_feature.isnull().sum() > 0]\nnull_cols = sorted(list(set(train_null_cols).union(set(test_null_cols))))\nprint(null_cols)","ff313006":"# Check the data types of null columns\ndf_train_feature[null_cols].dtypes","089be56e":"# Fill in the average value for Age and Fare\nnumeric_cols = [\"Age\", \"Fare\"]\nmean_vals = df_train_feature[numeric_cols].mean()\nmean_dict = dict(zip(numeric_cols, mean_vals))\nprint(mean_dict)\n\ndf_train_feature.fillna(mean_dict, inplace=True)\ndf_test_feature.fillna(mean_dict, inplace=True)","6b2043fc":"# Check if null values are filled\nprint(df_train_feature.columns[df_train_feature.isnull().sum() > 0])\nprint(df_test_feature.columns[df_test_feature.isnull().sum() > 0])","4e9ed547":"# One-hot encode the string variables\n# Hint: Make sure train and test sets have identical columns after encoding\ndf_train_encoded = pd.get_dummies(df_train_feature)\ndf_test_encoded = pd.get_dummies(df_test_feature)\n\n\ndisplay(df_train_encoded)\ndisplay(df_test_encoded)","f367ea6b":"# Modify below to your favorite algorithm\nlr = LogisticRegression(solver='liblinear')\nlr.fit(X=df_train_encoded, y=df_train[\"Survived\"])","0a748ee0":"pred = lr.predict(df_test_encoded)","5bcdcf69":"display(pred)","1c944a20":"df_submit = pd.DataFrame(columns=['PassengerId', 'Survived'])\ndf_submit[\"PassengerId\"] = df_test[\"PassengerId\"]\ndf_submit[\"Survived\"] = pred","ce9ffa92":"# Files named submission.csv gets submitted automatically by pressing the Submit button on right column\ndf_submit.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","dd2d7b50":"# Create submission file","9d0ad662":"# Train a model\n\n- Use any algorithm you want to get better predictions\n- You can also tune your hyperparameters if necessary","6693d755":"# Load data","437288cf":"# Import libraries and set parameters","21e67ea2":"# (Optional) Encode string variables to numeric features\n\n- Some model algorithms require all input features to be numeric\n- We need to encode the string features to numeric features","ddfe0f50":"# Feature selection\n\n- Select features you want to include in the predictive model based on your EDA results","10bc997d":"# (Optional) Feature engineering\n\n- If you found anything interesting during EDA, let's create features from your findings to make better predictions","12997d2a":"# (Optional) Handle missing values\n\n- Some algorithms don't allow missing values in their inputs -> Impute them with appropriate values\n- Modify the imputation method below as needed","cc2a183e":"# Make predictions","d3dc3233":"# Profiling\n\n- This is a profiling report of the train set\n- Take a look into it and see if you can find some interesting stuff on the data","b4999ab7":"# EDA (Explorative Data Analsis)\n\n- Dig into the data to see if you can find any relationship with the features and the target variable (i.e. Survived)\n- Be creative. Come up with hypotheses and verify them with data.\n- If you are uncomfortable with coding, feel free to download the datasets and explore with your favorite tool (e.g. Excel)","45decbb7":"# Starter Code"}}