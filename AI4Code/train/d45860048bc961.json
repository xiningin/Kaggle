{"cell_type":{"946cc74a":"code","347fd383":"code","c83a1dad":"code","5fb5dc06":"code","5a3a4eae":"code","d6faf6c5":"code","765edd4c":"code","0c570321":"code","37514efd":"code","2bbb1f47":"code","0e853833":"code","796afa58":"code","e2d3bd00":"code","f61578dc":"code","f6f8bdf5":"code","0a3c4822":"code","00ff891b":"code","eaed0658":"code","8a09f222":"code","250e6415":"code","d5fc8493":"code","11196d3f":"code","4ce13239":"code","ced7e57a":"code","67eb7448":"code","7377b64f":"code","8a3d1362":"code","6cd199f0":"code","9c42dfd1":"code","a1b8008d":"code","cc27645e":"code","a5721505":"code","0c406a15":"code","9c0ccfe6":"code","7398f05b":"code","c88c2758":"code","10ceb0b5":"code","6929f759":"code","4af81011":"code","e73fa145":"code","6bbe4178":"markdown","dcff7d40":"markdown","31d51ba4":"markdown","61754ed4":"markdown","0c52b180":"markdown","43acc50f":"markdown","db912563":"markdown","0794788f":"markdown","a1dabdae":"markdown","4b9e16d5":"markdown","34c0a4fa":"markdown","8c74fbf2":"markdown","51077644":"markdown","5fabef7f":"markdown"},"source":{"946cc74a":"# Mounting drive with colab\n# from google.colab import drive\n# drive.mount('\/content\/drive')","347fd383":"pip install hist","c83a1dad":"#importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport hist","5fb5dc06":"#Loading the dataset\ndf=pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')","5a3a4eae":"#First 5 columns\ndf.head()","d6faf6c5":"print(f\"The shape of the data is {df.shape}\")","765edd4c":"#The Null rows basically signifies that this was question with multiple answers, and we have done a One Hot Encoding\n# of all the choices available, so its natural that there might be some null values in each column\ndf.isnull().sum()","0c570321":"#first 20 questions\nfor i in df.iloc[0][1:20]:\n  print(i)","37514efd":"#column names\ncolumns=df.columns[1:]","2bbb1f47":"#Utility functions\ndef pie_chart(column_name,df,numb):\n  df_new=df[column_name]\n  labels=df_new.value_counts().keys()[0:-1]\n  data=df_new.value_counts().values[0:-1]\n  plt.figure(figsize=(7,7))\n  plt.title(str(df.iloc[0][numb+1]))\n  plt.pie(data,labels=labels,shadow=True,autopct='%1.1f%%')\n  plt.show()\n\ndef bar_chart(column_name,df,numb):\n  df_new=df[column_name]\n  plt.figure(figsize=(7,7))\n  plt.title(str(df.iloc[0][numb+1]))\n  df_new.value_counts()[0:20].plot(kind=\"barh\")\n  plt.show()","0e853833":"# Q1 What is your age (# years)?\n                  \npie_chart(columns[0],df,0)","796afa58":"# Q2 What is your gender? - Selected Choice\n\nbar_chart(columns[1],df,1)","e2d3bd00":"# Q3 In which country do you currently reside?\n\nbar_chart(columns[2],df,2)","f61578dc":"# Q4 What is the highest level of formal education that\n# you have attained or plan to attain within the next 2 years?\n\npie_chart(columns[3],df,3)","f6f8bdf5":"# Q5 Select the title most similar to your current role (or most recent title if retired)\n\npie_chart(columns[4],df,4)","0a3c4822":"# Q6 For how many years have you been writing code and\/or programming?\n\npie_chart(columns[5],df,5)","00ff891b":"#Q7 What programming languages do you use on a regular basis?\n\n\ndef fav_language():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,13):\n    data.append(df['Q7_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q7_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n  for i in range(0,len(data)):\n    temp=((data[i]\/sum(data))*100).round(2)\n    legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"What programming languages do you use on a regular basis?\")\n  plt.pie(data,shadow=True)\n  plt.legend(legend_labels)\n  plt.show()\n\nfav_language()","eaed0658":"df[df['Q3']=='India']['Q5'].value_counts()","8a09f222":"df[df['Q3']=='India']['Q4'].value_counts()","250e6415":"#This implies that most of the data scientists in India have a bachelor's or a master's degree. However, in India\n# we can assume that the bachelors's degree refers to btech \n\ndf[(df['Q5']==\"Data Scientist\") & (df['Q3']=='India')]['Q4'].value_counts()","d5fc8493":"df[df['Q3']=='India']['Q1'].value_counts()","11196d3f":"#next 52 questions\nfor i in df.iloc[0][20:72]:\n  print(i)","4ce13239":"#Q8 What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice\n#Python is by farthe most popular langauge followed by R and SQL\n\nplt.title(df['Q8'].value_counts().keys()[-1])\ndf['Q8'].value_counts()[0:-1].plot(kind='bar')\nplt.show()","ced7e57a":"#Q9 Which of the following integrated development environments (IDE's) do you use on a regular basis?\n\ndef fav_IDE():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,13):\n    data.append(df['Q9_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q9_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n  # for i in range(0,len(data)):\n  #   temp=((data[i]\/sum(data))*100).round(2)\n  #   legend_labels.append(str(labels[i])+\"- \"+str(temp[0]))\n  plt.figure(figsize=(7,7))\n  plt.title(\"Which of the following integrated development environments (IDE's) do you use on a regular basis?\")\n  plt.pie(data,shadow=True,autopct='%1.1f%%',labels=labels)\n  plt.show()\n\nfav_IDE()","67eb7448":"#Q10 Which of the following hosted notebook products do you use on a regular basis?\n\ndef fav_hostedNotebook():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,17):\n    data.append(df['Q10_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q10_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n  for i in range(0,len(data)):\n    temp=((data[i]\/sum(data))*100).round(2)\n    legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"Which of the following hosted notebook products do you use on a regular basis?\")\n  plt.pie(data,shadow=True,labels=labels,rotatelabels=185)\n  plt.show()\n\nfav_hostedNotebook()","7377b64f":"# Q11 What type of computing platform do you use most often for your data science projects? \n\npie_chart(columns[50],df,50)","8a3d1362":"#Q12 Which types of specialized hardware do you use on a regular basis? \n\ndef fav_hardware():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,6):\n    data.append(df['Q12_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q12_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n  for i in range(0,len(data)):\n    temp=((data[i]\/sum(data))*100).round(2)\n    legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"Which types of specialized hardware do you use on a regular basis?\")\n  plt.pie(data,shadow=True,labels=labels,autopct='%1.1f%%')\n  plt.show()\n\nfav_hardware()","6cd199f0":"columns[69]","9c42dfd1":"# Q13 Approximately how many times have you used a TPU (tensor processing unit)?\n\npie_chart(columns[57],df,57)","a1b8008d":"#Q14 What data visualization libraries or tools do you use on a regular basis?\n\ndef fav_visLib():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,11):\n    data.append(df['Q14_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q14_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n  for i in range(0,len(data)):\n    temp=((data[i]\/sum(data))*100).round(2)\n    legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"Which types of specialized hardware do you use on a regular basis?\")\n  plt.pie(data,shadow=True,labels=labels,autopct='%1.1f%%')\n  plt.show()\n\nfav_visLib()","cc27645e":"columns[70]","a5721505":"# Q15 For how many years have you used machine learning methods?\n\npie_chart(columns[70],df,70)","0c406a15":"#next all questions\nfor i in df.iloc[0][72:]:\n  print(i)","9c0ccfe6":"#Q16 Which of the following machine learning frameworks do you use on a regular basis?\n\ndef fav_mlFramework():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,18):\n    data.append(df['Q16_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q16_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n#   for i in range(0,len(data)):\n#     temp=((data[i]\/sum(data))*100).round(2)\n#     legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"Which of the following machine learning frameworks do you use on a regular basis?\")\n  plt.pie(data,shadow=True,labels=labels,rotatelabels=185)\n  plt.show()\n\nfav_mlFramework()\n","7398f05b":"#Q17 Which of the following ML algorithms do you use on a regular basis?\n\ndef fav_mlAlgo():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,11):\n    data.append(df['Q17_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q17_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n#   for i in range(0,len(data)):\n#     temp=((data[i]\/sum(data))*100).round(2)\n#     legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"Which of the following ML algorithms do you use on a regular basis?\")\n  plt.pie(data,shadow=True,labels=labels,autopct=\"%1.1f\")\n  plt.show()\n\nfav_mlAlgo()\n","c88c2758":"#Q18 Which categories of computer vision methods do you use on a regular basis?\n\ndef fav_CvAlgo():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,7):\n    data.append(df['Q18_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q18_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n#   for i in range(0,len(data)):\n#     temp=((data[i]\/sum(data))*100).round(2)\n#     legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"Which categories of computer vision methods do you use on a regular basis?\")\n  plt.pie(data,shadow=True,labels=labels,autopct=\"%1.1f\")\n  plt.show()\n\nfav_CvAlgo()\n","10ceb0b5":"# Q19 Which of the following natural language processing (NLP) methods do you use on a regular basis?\n\ndef fav_CvAlgo():\n  data=[]\n  labels=[]\n  legend_labels=[]\n  for i in range(1,6):\n    data.append(df['Q19_Part_'+str(i)].value_counts()[0:1].values[0])\n    labels.append(df['Q19_Part_'+str(i)].value_counts()[0:1].keys()[0])\n\n#   for i in range(0,len(data)):\n#     temp=((data[i]\/sum(data))*100).round(2)\n#     legend_labels.append(str(labels[i])+\"- \"+str(temp))\n  plt.figure(figsize=(7,10))\n  plt.title(\"Which of the following natural language processing (NLP) methods do you use on a regular basis?\")\n  plt.pie(data,shadow=True,labels=labels,autopct=\"%1.1f\")\n  plt.show()\n\nfav_CvAlgo()\n","6929f759":"# Q25 What is your current yearly compensation (approximate $USD)?\nbar_chart(columns[126],df,126)","4af81011":"plt.figure(figsize=(20,7))\nplt.subplot(121)\ndf[df['Q3']=='India'][columns[126]].value_counts().plot(kind=\"barh\")\nplt.title(\"Compensation in India\")\nplt.subplot(122)\ndf[df['Q3']=='United States of America'][columns[126]].value_counts().plot(kind=\"barh\")\nplt.title(\"Compensation in US\")","e73fa145":"#Its clear that the compensation for data scientist is double that of data analyst\nplt.figure(figsize=(20,7))\nplt.subplot(121)\ndf[(df['Q3']=='India') & (df['Q5']==\"Data Scientist\")][columns[126]].value_counts().plot(kind=\"barh\")\nplt.title(\"Compensation in India for Data Scientist\")\nplt.subplot(122)\ndf[(df['Q3']=='India') & (df['Q5']==\"Data Analyst\")][columns[126]].value_counts().plot(kind=\"barh\")\nplt.title(\"Compensation in India for Data Analyst\")","6bbe4178":"Lets start looking at the questions one by one, and for each question we will derive some basic informations","dcff7d40":"Lets look at the yearly compensation for India vs USA","31d51ba4":"<h1> In the same way other questions can be analyzed and visualized<br><br>Thank You<\/h1><br><br>\nIf you have any queries or suggestions, you can ping me on my linkedIn : https:\/\/www.linkedin.com\/in\/nilaykush\/\n","61754ed4":"<ul>\n<li>Python is by far the popular programming language for data scientists followed by R and SQL. \n<li>The most favourite IDE is Jupyter notebook followed by VS Code and Pycharm. However, many people also use google colab and kaggle notebooks because they have similar interface as jupyter notebook, and theyalso provide with free GPU and TPU service upto a limit, which might be very beneficial for small projects and for begineers.\n<li> Most of the people use laptop for their projects or a personal computer. Also, most of the high laptops come with inbuilt Nvidia GPUs.\n<li>Matplotlib is the most used visualization library followed by seaborn and plotify.\n<li> The machine learning and deep learning methods have earned more popularity in the recent 3-4 years, this implies that it is a pretty indemand skill right now in the market.\n ","0c52b180":"Lets look at the data scientist and data analyst compenstation in India","43acc50f":"<h1> Section 1 <\/h1>","db912563":"<h1>Section 3<\/h1>","0794788f":"<h1> 2nd section <\/h2>","a1dabdae":"42+ questions and 25,973 responses\n\nNote :- Responses to multiple choice questions (only a single choice can be selected) were recorded in individual columns. Responses to multiple selection questions (multiple choices can be selected) were split into multiple columns (with one column per answer choice","4b9e16d5":"By just looking at both the plots its completely clear what is the diffrence between the annual compenstation in India vs in US. The 0-999$ can be assumed as the compenstation for a students","34c0a4fa":"The important points from Section 4 are:\n\n<ul>\n<li>Scikit-learn, keras and pytorch are the most popular framework, however though xg boost is a boosting library yet it gives tough competition to the state of the art frameworks like keras and torch.\n<li> The most popular ML algorithm is Linear\/Logistic regression followed by ensemble based methods. Deep learning techniques like MLPs, CNN, etc are also getting popularity due to their ability to work on large amount of data.\n<li>In Computer Vision, pre-trained models like VGG, Inception are very popular for Image classfication, whereas for Object detection yoloV3,RetineNet,GAN,etc.\n<li> In NLP, Word Embedding methods are currently in use, however huge amount of research is going on in the field of NLP and state of the art transformer based model like GPT3,Bert,etc are getting popularity.\n<li> There is very large margin differnce between the compensation in US vs the compensation in India. \n","8c74fbf2":"Now lets create some more queries by combining the two or more features\n\nQ1. Which is your current role wrt country and wrt data scienece\n\nQ2. what is your highest level of formal education wrt country\n\nQ3. Age and geneder wrt country","51077644":"<b>Note :- when I write data science or data scientist I refer to all the related fields also like data analyst,ML engineer etc.<\/b>\n\nFrom above analysis we can see that the graeter percentage of the data is between the age group of 18-30. The number of males in data science and ML sector is more than the female and other geneder by a pretty big margin. \n\n<b>India has the greatest number of data dcience professionals or students. This means we can expect India to  become as a data science hub in the mere future.<\/b>\n\nData Scientist is the most liked role followed software engineer. The greater number of data scientists in the world have a master's degree.\n","5fabef7f":"<h1>Section 4<\/h1>"}}