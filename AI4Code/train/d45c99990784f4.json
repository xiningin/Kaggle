{"cell_type":{"f7bc1220":"code","56643697":"code","b406c8c7":"code","78be9350":"code","13ad817f":"code","2ebe80f4":"code","ff9f9d45":"code","54c0952d":"code","801bb583":"code","51eef356":"code","a5122053":"code","ed16add8":"code","1625ccc5":"code","31eb91a9":"code","fafd1cb1":"code","862e7cd8":"code","ab1ae983":"code","82f4922c":"code","c36a3959":"code","bdae93f1":"code","f91f5ee2":"code","0b065b7c":"code","75152409":"code","1589bc3b":"code","89ada830":"code","5dc0d37a":"code","2190fd42":"code","6f10ffc4":"code","c68c9f9f":"code","2653b1c4":"code","1a184173":"code","55c6677e":"code","2704b19b":"code","d8056fea":"code","3cc4aecb":"code","95325298":"code","4cf7ad69":"code","e83615c3":"code","b8c19b08":"code","74ebaf38":"code","99896c3d":"code","57aafbb0":"code","ec51f271":"code","4ee3a235":"code","89d225be":"code","b89849d5":"code","687b932e":"code","403a3ace":"code","e565d410":"code","cff88f56":"code","e664460a":"code","6a19d3a2":"code","71484551":"code","19103898":"code","8786f122":"code","08696490":"code","b626a7e9":"code","f3cac91a":"code","e29892e9":"code","bc0c7940":"code","f3cd6442":"code","22ce7453":"code","cb46c9a8":"code","a25bf47a":"code","826f4db9":"code","42da238e":"code","9bf8f41e":"code","e1f02652":"code","2fdd64af":"code","af1e8abe":"code","04a6e5a0":"code","af9fb482":"code","a829ef86":"code","2e66aa9b":"code","2c310ad5":"code","092b1e07":"code","2f884161":"code","ba2bf3dc":"code","8a080f4a":"code","da96f900":"code","1b82c03b":"code","d414ec4e":"code","12c3f7dd":"code","58bf6b43":"code","83fcfece":"code","ce7457a2":"code","ddc9ac66":"code","d8ce8fef":"code","0ee3f49a":"code","6a92a18e":"code","023dd8fb":"code","45415991":"code","7232d8f4":"code","354fd959":"code","0649f95b":"code","953c704a":"code","1663b42e":"code","5d9f3c0f":"code","1e4b849b":"code","25b6367d":"code","b6ffb99a":"code","2bf26b41":"code","875e3815":"code","24d577c4":"markdown","cbe60127":"markdown","7ccf5f22":"markdown","b8e48f1a":"markdown","071ab03a":"markdown","1e1a9348":"markdown","15ab554c":"markdown","8a868e81":"markdown","ede99d41":"markdown","2539eeac":"markdown","86c35463":"markdown","a38e815c":"markdown","369cbf9b":"markdown","84e6a370":"markdown","883bb252":"markdown","2e33103a":"markdown","a5682a5e":"markdown","961a403c":"markdown","8197e0fe":"markdown"},"source":{"f7bc1220":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","56643697":"# necessary package\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport imblearn\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.style.use('tableau-colorblind10')\nimport seaborn as sns\nfrom plotnine import *\nimport plotly.graph_objects as go\nimport plotly.express as px","b406c8c7":"df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndf.head()","78be9350":"df.info()","13ad817f":"len(df['CLIENTNUM'].unique())","2ebe80f4":"# Correcting Data Type\n## string \n\n","ff9f9d45":"# drop columns\ndf = df.drop(columns = ['CLIENTNUM', \n              'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', \n             'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])\ndf.info()\n","54c0952d":"# Data Distribution + Sample Selection\n\ncat_col = [x for x in df.columns if df[x].dtype == 'O']\nnum_col = [x for x in df.columns if x not in cat_col]\n\nprint('cat_col : {} \\n\\\nnum_col : {}'.format(len(cat_col), len(num_col)))","801bb583":"## categorical data\n# var = 'Gender'\n# tmp = df[var].value_counts().reset_index()\n# plt.bar(tmp['index'], tmp[var])\n# plt.title(var)\n\nfig = plt.figure(figsize=(10, 8))\nfig.subplots_adjust(hspace=0.8, wspace=0.8)\nfor i,var in enumerate(cat_col):\n    tmp = df[var].value_counts().reset_index()\n    ax = fig.add_subplot(2, 3, i+1)\n    ax.bar(tmp['index'], tmp[var], color='black')\n    ax.set_title(var)\n    ax.set_xticklabels(tmp['index'], rotation=90)\n","51eef356":"# df['Attrition_Flag'].value_counts()\n1627\/(1627+8500)","a5122053":"query = (df['Education_Level'] == 'Unknown') \ndf[query]['Attrition_Flag'].value_counts()","ed16add8":"# df['Marital_Status'].value_counts()\n# 749\/10127\nquery = (df['Marital_Status'] == 'Unknown') \ndf[query]['Attrition_Flag'].value_counts()","1625ccc5":"query = (df['Income_Category'] == 'Unknown') \ndf[query]['Attrition_Flag'].value_counts()","31eb91a9":"# df.groupby(['Card_Category'])['Attrition_Flag'].value_counts()\ndf['Card_Category'].value_counts()\n# 9436\/10127","fafd1cb1":"# numerical data\n# var = 'Customer_Age'\n# tmp = df[var].value_counts().reset_index()\n# plt.hist(df[var], color='black')\n# plt.title(var)\n\nfig = plt.figure(figsize=(10, 12))\nfig.subplots_adjust(hspace=0.8, wspace=0.8)\nfor i,var in enumerate(num_col):\n    ax = fig.add_subplot(5, 3, i+1)\n    ax.hist(df[var], color='black')\n    ax.set_title(var)","862e7cd8":"# fig.savefig('.\/fig2.png')","ab1ae983":"# Avg_Utilization_Ratio \u0e40\u0e17\u0e48\u0e32\u0e01\u0e31\u0e1a 0 \u0e19\u0e35\u0e48\u0e04\u0e37\u0e2d\u0e44\u0e21\u0e48\u0e43\u0e0a\u0e49\u0e1a\u0e31\u0e15\u0e23\u0e40\u0e25\u0e22\u0e2b\u0e23\u0e2d \u0e41\u0e25\u0e49\u0e27\u0e40\u0e1b\u0e34\u0e14\u0e17\u0e33\u0e44\u0e21 \u0e2b\u0e23\u0e37\u0e2d\u0e40\u0e1e\u0e34\u0e48\u0e07\u0e2a\u0e21\u0e31\u0e04\u0e23 ?? \ndf[df['Avg_Utilization_Ratio'] == 0]['Months_on_book'].sort_values()","82f4922c":"len(num_col) ","c36a3959":"## Relationship between 2 variables\nplt.figure(figsize=(12,10))\nsns.heatmap(df[num_col].corr(), vmin=-1.0, vmax=1.0, linewidths=0.5, cmap='icefire', annot=True, fmt='.2f')\n# plt.savefig","bdae93f1":"df[num_col].info()","f91f5ee2":"# Sample Selection \n## Marital_Status == 'Unknown'\n# df = df[df['Marital_Status'] != 'Unknown']","0b065b7c":"df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndf.head()","75152409":"# define features types\ndemog_features = ['Customer_Age', 'Gender', 'Dependent_count', 'Education_Level', \n                 'Marital_Status', 'Income_Category']\n\nrelate_features = ['Card_Category', 'Months_on_book', 'Total_Relationship_Count', \n                     'Credit_Limit']\n\nbehavior_features = ['Months_Inactive_12_mon', 'Contacts_Count_12_mon', \n                     'Total_Revolving_Bal', 'Avg_Open_To_Buy', \n                    'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', \n                    'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\n\n","1589bc3b":"# segmentation : clustering customers by their Demographic and Relationship with Bank\nsegment_frame = df[['CLIENTNUM'] + demog_features + relate_features]\n\n# retrieve data for clustering \ncat_var = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', \n          'Card_Category']\nnum_var = [x for x in segment_frame.columns.tolist() if x not in cat_var + ['CLIENTNUM']]\n\nX_num = segment_frame[num_var].values\nenc = OneHotEncoder()\nX_cat = enc.fit_transform(segment_frame[cat_var]).toarray()\nX = np.concatenate((X_num, X_cat), axis=1)\n\nprint(X.shape)","89ada830":"X[:, 4:]","5dc0d37a":"from sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\n\nprint(__doc__)\n\n# Generating the sample data from make_blobs\n# This particular setting has one distinct cluster and 3 clusters placed close\n# together.\n# X =  \n\nrange_n_clusters = [3, 4, 5]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) \/ n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.nipy_spectral(cluster_labels.astype(float) \/ n_clusters)\n    ax2.scatter(X[:, 0], X[:, 2], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 2], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                    s=50, edgecolor='k')\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","2190fd42":"# selected k (k=4)\nclusterer = KMeans(n_clusters=3, random_state=10)\ncluster_labels = clusterer.fit_predict(X)\n\n","6f10ffc4":"segment_frame['customer_group'] = cluster_labels\nsegment_frame","c68c9f9f":"# demog + relate by group\nsegment_frame['customer_group'].value_counts()","2653b1c4":"cat_var = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', \n          'Card_Category', 'Months_on_book', 'Total_Relationship_Count']\n\n\n\nfig = plt.figure(figsize=(14, 12))\nfig.subplots_adjust(hspace=1.0, wspace=0.4)\nfor i,var in enumerate(cat_var):\n    ax = fig.add_subplot(3, 3, i+1)\n    ax = sns.heatmap(pd.crosstab(segment_frame['customer_group'], \n                                 segment_frame[var], normalize='index'), \n                     cmap='Greens', linewidths=0.5)\n    ax.set_title(var)\n    ","1a184173":"num_var = ['Customer_Age', 'Dependent_count', 'Credit_Limit']\n\nfig = plt.figure(figsize=(14, 4))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nfor i,var in enumerate(num_var):\n    ax = fig.add_subplot(1, 3, i+1)\n    ax = sns.boxplot(data=segment_frame, x='customer_group', y=var)\n    ax.set_title(var)\n    ","55c6677e":"# Create customer profile table\ncustomer_profile = pd.merge(df[['CLIENTNUM'] + behavior_features], \n                            segment_frame[['CLIENTNUM', 'customer_group']], \n                            on='CLIENTNUM')\ncustomer_profile = customer_profile.drop(columns=['CLIENTNUM'])\ncustomer_profile.head()","2704b19b":"behavior_features","d8056fea":"# visualize behavior using radar plot for each group\nfig = px.parallel_coordinates(customer_profile, color='customer_group', \n                             dimensions=['Avg_Open_To_Buy', 'Avg_Utilization_Ratio', \n                                         'Total_Trans_Amt', 'Total_Trans_Ct'\n                                        ])\nfig.show()\n\n\n","3cc4aecb":"\n# radar\ntmp = customer_profile.groupby('customer_group').mean()\ntmp = tmp.apply(lambda x: x\/x.max(), axis=0)\n\n# tmp\nvar = tmp.columns.tolist()[1:]\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatterpolar(r = tmp.iloc[0, 1:].values.tolist(), \n                             theta = var, \n                             fill ='toself', \n                             name = 'Group 0'))\nfig.add_trace(go.Scatterpolar(r = tmp.iloc[1, 1:].values.tolist(), \n                             theta = var, \n                             fill ='toself', \n                             name = 'Group 1'))\nfig.add_trace(go.Scatterpolar(r = tmp.iloc[2, 1:].values.tolist(), \n                             theta = var, \n                             fill ='toself', \n                             name = 'Group 2'))\n\nfig.update_layout(polar=dict(radialaxis=dict(visible=True)), showlegend=True)\nfig.show()\n\n# data = pd.DataFrame(dict(r = tmp.iloc[0, 1:].values.tolist(), \n#                         theta = var))\n# fig = px.line_polar(data, r='r', theta='theta', \n#                     line_close=True)\n# fig.show()\n","95325298":"df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndf.head()","4cf7ad69":"# drop columns\ndf = df.drop(columns = ['CLIENTNUM', \n              'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', \n             'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])\ndf.info()\n","e83615c3":"# Customer_Age : <20, 20-30, 30-40, 40-50, 50-60, >60\nconverter = lambda x: '<30' if (x <= 30) else \\\n                        ('30-40' if (x > 30 and x <= 40) else \\\n                        ('40-50' if (x > 40 and x <= 50) else \\\n                        ('50-60' if (x > 50 and x <= 60) else \\\n                        '>60')))\n\n\ntmp = df['Customer_Age'].apply(converter)\ndf['Customer_Age_Binning'] = tmp\n\ntmp2 = df.groupby('Customer_Age_Binning')['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\ntmp2['Customer_Age_Binning'] = pd.Categorical(tmp2['Customer_Age_Binning'], \n                                              categories=['<30','30-40','40-50','50-60','>60'], \n                                              ordered=True)\nfig_age_bin = ggplot(tmp2) +\\\n                geom_col(aes(x='Customer_Age_Binning', y='Frequency_of_Loans', fill='Attrition_Flag'))\nfig_age_bin","b8c19b08":"# Months_on_book\nvar = 'Months_on_book'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_mob_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_mob_bin\n","74ebaf38":"# ggsave(fig_mob_bin, '.\/fig4_mob_binning.png')","99896c3d":"# Credit_Limit\nvar = 'Credit_Limit'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_creditlim_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_creditlim_bin\n","57aafbb0":"# Total_Revolving_Bal\nvar = 'Total_Revolving_Bal'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_revolve_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_revolve_bin\n","ec51f271":"# ggsave(fig_revolve_bin, '.\/fig6_revolve_binning.png')","4ee3a235":"# Avg_Open_To_Buy\nvar = 'Avg_Open_To_Buy'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_opentobuy_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_opentobuy_bin\n","89d225be":"# Total_Amt_Chng_Q4_Q1, \n\nvar = 'Total_Amt_Chng_Q4_Q1'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_amtq4q1_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_amtq4q1_bin","b89849d5":"# ggsave(fig_amtq4q1_bin, '.\/fig6_amtq4q1_binning.png')\n","687b932e":"# Total_Trans_Amt \n\nvar = 'Total_Trans_Amt'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_transamt_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_transamt_bin","403a3ace":"# ggsave(fig_transamt_bin, '.\/fig9_transamt_binning.png')\n","e565d410":"# Total_Trans_Ct\n\nvar = 'Total_Trans_Ct'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_transct_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_transct_bin","cff88f56":"# ggsave(fig_transct_bin, '.\/fig10_transct_binning.png')","e664460a":"# Total_Ct_Chng_Q4_Q1,\nvar = 'Total_Ct_Chng_Q4_Q1'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_ctq4q1_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_ctq4q1_bin","6a19d3a2":"# Avg_Utilization_Ratio\nvar = 'Avg_Utilization_Ratio'\nvar_binning = var + '_Binning'\ntmp = pd.qcut(df[var], q=4)\ndf[var_binning] = tmp\n\ntmp2 = df.groupby(var_binning)['Attrition_Flag'].value_counts()\ntmp2 = pd.DataFrame(tmp2)\ntmp2 = tmp2.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\ntmp2 = tmp2.reset_index()\n\nfig_utilize_bin = ggplot(tmp2) +\\\n                        geom_col(aes(x=var_binning, y='Frequency_of_Loans', \n                                    fill='Attrition_Flag'))\nfig_utilize_bin","71484551":"df.head()","19103898":"df.info()","8786f122":"df['Attrition_Flag'].value_counts()","08696490":"df['Card_Category'].value_counts()","b626a7e9":"df[df['Avg_Utilization_Ratio'] == 0]['Attrition_Flag'].value_counts()","f3cac91a":"selected_feature = ['Attrition_Flag', \n                   'Gender', 'Customer_Age_Binning', 'Dependent_count', 'Education_Level', 'Marital_Status', 'Income_Category', \n                   'Months_on_book_Binning', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', \n                   'Credit_Limit_Binning', 'Total_Revolving_Bal_Binning', 'Avg_Open_To_Buy_Binning', 'Total_Amt_Chng_Q4_Q1_Binning', \n                   'Total_Trans_Amt_Binning', 'Total_Trans_Ct_Binning', 'Total_Ct_Chng_Q4_Q1_Binning', 'Avg_Utilization_Ratio_Binning']\n\ndf = df[selected_feature]\ndf.info()","e29892e9":"iv_list = []\n\n# loop\nfor var in selected_feature[1:]:\n    new_var = var + '_woe'\n    # create woe table\n    tmp = df.groupby(var)['Attrition_Flag'].value_counts()\n    tmp = pd.DataFrame(tmp)\n    tmp = tmp.rename(columns={'Attrition_Flag':'Frequency_of_Loans'})\n    tmp = tmp.reset_index()\n    woe_table = tmp.pivot(index=var, columns='Attrition_Flag', values='Frequency_of_Loans')\n\n    # calculate WOE&IV\n    num_attrited = woe_table['Attrited Customer'].sum()\n    num_existing = woe_table['Existing Customer'].sum()\n\n    woe_table['DB'] = woe_table['Attrited Customer']\/num_attrited\n    woe_table['DG'] = woe_table['Existing Customer']\/num_existing\n    woe_table['perc_diff'] = woe_table['DG']-woe_table['DB']\n    woe_table['woe'] = np.log(woe_table['DG']\/woe_table['DB'])\n\n    # store IV value\n    iv_data = {'var':var, \n               'iv':(woe_table['perc_diff']*woe_table['woe']).sum()}\n    iv_list.append(iv_data)\n\n    # transform categorical into woe\n    df[new_var] = pd.merge(df, woe_table, how='left', left_on=var, \n                                right_index=True)['woe']\n\n","bc0c7940":"df.head()","f3cd6442":"# IV\niv_table = pd.DataFrame(iv_list)\niv_table = iv_table.sort_values('iv', ascending=True).reset_index(drop=True)\niv_table['var'] = pd.Categorical(iv_table['var'], categories=iv_table['var'].unique().tolist(), \n                                 ordered=True)\niv_table","22ce7453":"iv_table = iv_table.rename(columns={'iv':'information value'})\niv_table.head()","cb46c9a8":"ggplot(iv_table) +\\\n    geom_col(aes(x='var', y='information value'), fill='black') +\\\n    geom_hline(yintercept=0.3, linetype='dashed', color='red', size=1.0) +\\\n    theme(axis_title_y = element_blank()) +\\\n    coord_flip()\n","a25bf47a":"#  \nselected_features = iv_table[iv_table['information value'] >= 0.3]['var'].unique().tolist()[::-1]\nselected_features","826f4db9":"org_df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\norg_df.head()\n\nvar = ['Attrition_Flag', \n       'Total_Trans_Ct',\n       'Total_Trans_Amt',\n       'Total_Revolving_Bal',\n       'Total_Ct_Chng_Q4_Q1',\n       'Avg_Utilization_Ratio',\n       'Months_Inactive_12_mon']\n\norg_df[var]","42da238e":"tmp = pd.melt(org_df[var], id_vars='Attrition_Flag')\n\nggplot(tmp, aes(x='Attrition_Flag', y='value', fill='Attrition_Flag')) +\\\n    geom_boxplot() +\\\n    facet_wrap('variable', scales='free_y') +\\\n    theme(subplots_adjust={'wspace':0.40, 'hspace':0.25}, \n          axis_text_x=element_blank(), \n         axis_title_x=element_blank(), \n         axis_title_y=element_blank(), \n         figure_size=(16,8))\n    \n","9bf8f41e":"org_df.groupby('Attrition_Flag')[var].agg([np.mean, np.std])","e1f02652":"# df\nselected_features_woe = [x + '_woe' for x in selected_features]\ndf = df[['Attrition_Flag'] + selected_features_woe]\ndf.info()","2fdd64af":"df['Attrition_Flag'].value_counts()","af1e8abe":"# split train\/test 80:20\nX = df[selected_features_woe]\ny = df['Attrition_Flag']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n                                                    test_size=0.20, \n                                                    random_state=42)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n","04a6e5a0":"print('train : {}\\ntest : {}'.format(Counter(y_train), Counter(y_test)))","af9fb482":"# oversampling\nsmote =  imblearn.over_sampling.SMOTE(sampling_strategy='auto', \n                                   k_neighbors=5, \n                                   random_state=42)\n\nX_res, y_res = smote.fit_resample(X_train, y_train)\nprint('Resampled dataset shape {}'.format(Counter(y_res)))\n","a829ef86":"df_train = pd.concat([X_res, pd.DataFrame({'Attrition_Flag':y_res})], axis=1)\ndf_train.head()\n","2e66aa9b":"df_train.info()","2c310ad5":"df_train.columns","092b1e07":"formula = 'Attrition_Flag ~ 0 + Total_Trans_Ct_Binning_woe +\\\n                            Total_Trans_Amt_Binning_woe +\\\n                            Total_Revolving_Bal_Binning_woe +\\\n                            Total_Ct_Chng_Q4_Q1_Binning_woe +\\\n                            Avg_Utilization_Ratio_Binning_woe +\\\n                            Months_Inactive_12_mon_woe'\n\n\nmodel1 = smf.glm(data = df_train, formula=formula, family=sm.families.Binomial()).fit()\nprint(model1.summary())\n","2f884161":"# prediction \nmodel1.mu","ba2bf3dc":"# Goodness of Fit : I use Hosmer-Lemeshow test instead Deviance due to our target variable was binary response \n## https:\/\/en.wikipedia.org\/wiki\/Hosmer%E2%80%93Lemeshow_test\n\n# H-L component\nobs = pd.get_dummies(df_train['Attrition_Flag'])\nprob =  pd.DataFrame({'prob':model1.mu})\nq_prob = pd.DataFrame({'q_prob':pd.qcut(prob['prob'], q=10)})\nhl_frame = pd.concat([obs, prob, q_prob], axis=1)\n\n# H-L statframe\nhl_pivotframe = hl_frame.groupby('q_prob').agg({'Attrited Customer':'sum', \n                                                'Existing Customer':'sum', \n                                                'prob':'mean'})\n\n# calculate H-L\nhl_pivotframe['obs_all'] = hl_pivotframe.iloc[:, 0] + hl_pivotframe.iloc[:, 1]\nhl_pivotframe['expect_1'] = hl_pivotframe['prob'] * hl_pivotframe['obs_all']\nhl_pivotframe['expect_0'] = hl_pivotframe['obs_all'] - hl_pivotframe['expect_1']\n\nhl_pivotframe['HL'] = ((hl_pivotframe['Attrited Customer'] - hl_pivotframe['expect_1'])**2\/hl_pivotframe['expect_1']) +\\\n                        ((hl_pivotframe['Existing Customer'] - hl_pivotframe['expect_0'])**2\/hl_pivotframe['expect_0'])\nhl_pivotframe\n\n","8a080f4a":"# calculate H-L stat and p-value\nhl_stat = hl_pivotframe['HL'].sum()\np_value = 1 - stats.chi2.cdf(hl_stat, 8)\nprint('H-L = {}\\np-value = {}'.format(hl_stat, p_value))\n","da96f900":"ggplot(hl_pivotframe) +\\\n    geom_point(aes(x='Attrited Customer', y='expect_1')) +\\\n    labs(title='Logistic Regression (model1) for training dataset:\\nobserved vs expected prob.')\n    ","1b82c03b":"# Checking Overdispersion \nprint('estimated phi_hat : {}'.format(model1.pearson_chi2\/model1.df_resid))\n","d414ec4e":"# Filter Influencer\ninfl = model1.get_influence(observed=False)\nsumm_df = infl.summary_frame()\nthreshold = 4\/(df_train.shape[0] - len(model1.params))\ninfl_index = summ_df['cooks_d'] > threshold\n","12c3f7dd":"ggplot(summ_df) +\\\n    geom_point(aes(x=summ_df.index, y=summ_df['cooks_d']), alpha=0.5) +\\\n    geom_hline(yintercept=threshold, linetype='dashed', color='red', size=1.0)","58bf6b43":"# remove Avg_Utilization_Ratio_Binning_woe\ndf_train = df_train.drop(columns='Avg_Utilization_Ratio_Binning_woe')","83fcfece":"df_train[~infl_index]['Attrition_Flag'].value_counts()","ce7457a2":"# Filter influencer\nnewdf_train = df_train[~infl_index]\nnewdf_train.head()","ddc9ac66":"newdf_train.info()","d8ce8fef":"# fitting new model (model2)\nformula = 'Attrition_Flag ~ 0 + Total_Trans_Ct_Binning_woe +\\\n                            Total_Trans_Amt_Binning_woe +\\\n                            Total_Revolving_Bal_Binning_woe +\\\n                            Total_Ct_Chng_Q4_Q1_Binning_woe +\\\n                            Months_Inactive_12_mon_woe'\n\n\nmodel2 = smf.glm(data = newdf_train, formula=formula, family=sm.families.Binomial()).fit()\nprint(model2.summary())\n","0ee3f49a":"# Goodness of Fit : I use Hosmer-Lemeshow test instead Deviance due to our target variable was binary response \n## https:\/\/en.wikipedia.org\/wiki\/Hosmer%E2%80%93Lemeshow_test\n\n# H-L component\nobs = pd.get_dummies(newdf_train['Attrition_Flag'])\nprob =  pd.DataFrame({'prob':model2.mu})\nq_prob = pd.DataFrame({'q_prob':pd.qcut(prob['prob'], q=10)})\nhl_frame = pd.concat([obs, prob, q_prob], axis=1)\n\n# H-L statframe\nhl_pivotframe = hl_frame.groupby('q_prob').agg({'Attrited Customer':'sum', \n                                                'Existing Customer':'sum', \n                                                'prob':'mean'})\n\n# calculate H-L\nhl_pivotframe['obs_all'] = hl_pivotframe.iloc[:, 0] + hl_pivotframe.iloc[:, 1]\nhl_pivotframe['expect_1'] = hl_pivotframe['prob'] * hl_pivotframe['obs_all']\nhl_pivotframe['expect_0'] = hl_pivotframe['obs_all'] - hl_pivotframe['expect_1']\n\nhl_pivotframe['HL'] = ((hl_pivotframe['Attrited Customer'] - hl_pivotframe['expect_1'])**2\/hl_pivotframe['expect_1']) +\\\n                        ((hl_pivotframe['Existing Customer'] - hl_pivotframe['expect_0'])**2\/hl_pivotframe['expect_0'])\nhl_pivotframe\n","6a92a18e":"# calculate H-L stat and p-value\nhl_stat = hl_pivotframe['HL'].sum()\np_value = 1 - stats.chi2.cdf(hl_stat, 8)\nprint('H-L = {}\\np-value = {}'.format(hl_stat, p_value))\n\n\nggplot(hl_pivotframe) +\\\n    geom_point(aes(x='Attrited Customer', y='expect_1')) +\\\n    labs(title='Logistic model for train dataset:\\nobserved vs expected prob.')\n    ","023dd8fb":"# Checking Overdispersion \nprint('estimated phi_hat : {}'.format(model1.pearson_chi2\/model1.df_resid))\n","45415991":"# Finalize Model\nlr_model = model2","7232d8f4":"lr_model.summary()","354fd959":"y_test = y_test.replace({'Attrited Customer':1, 'Existing Customer':0})","0649f95b":"# remove Avg_Utilization_Ratio_Binning_woe\nX_test = X_test.drop(columns='Avg_Utilization_Ratio_Binning_woe')\nX_test.head()","953c704a":"# predict\ny_pred = lr_model.predict(X_test)\n","1663b42e":"threshold = 0.5\nprediction = (y_pred > threshold).values.astype('int')","5d9f3c0f":"# confusion matrix\ncm = confusion_matrix(y_test, prediction)\n# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n# disp.plot(cmap='Greens') \n\nfig = plt.figure(figsize=(7, 7))\n\nax = sns.heatmap(cm, annot=True, fmt='d', \n                 cbar=False, cmap='Greens', linewidth=0.5)\nax.set_title('Confusion Matrix using LR\\n\\\n                F1 : {}\\n\\\n                Precision : {}\\n\\\n                Recall : {}'.format(np.round(f1_score(y_test, prediction),2), \n                                   np.round(precision_score(y_test, prediction),2), \n                                   np.round(recall_score(y_test, prediction),2)))\n\n\n","1e4b849b":"print('Accuracy of lr_model : {}'.format(accuracy_score(y_test, prediction)))\nprint('F1 Score of lr_model : {}'.format(f1_score(y_test, prediction)))\nprint('Precision of lr_model : {}'.format(precision_score(y_test, prediction)))\nprint('Recall of lr_model : {}'.format(recall_score(y_test, prediction)))","25b6367d":"# Precision-Recall Curve\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n\nplt.plot(recall, precision, marker='.', c='black', label='Logistic Regression')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()\n","b6ffb99a":"# roc-auc\nlr_auc = np.round(roc_auc_score(y_test, y_pred), 2)\nlr_fpr, lr_tpr, _ = roc_curve(y_test, y_pred)\n\nplt.figure(figsize=(7, 7))\nplt.plot(lr_fpr, lr_tpr, marker='.', c='black', label='LR auc = {}'.format(lr_auc))\n\nplt.title('ROC ')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()\n","2bf26b41":"tmp = pd.DataFrame({'Attrition_Flag':y_test, \n                   'y_pred':y_pred})\ntmp = tmp.sort_values('y_pred').reset_index(drop=True)\ntmp['id'] = [*range(1, tmp.shape[0]+1)]\ntmp['Attrition_Flag'] = tmp['Attrition_Flag'].astype('str')\n# tmp.head()\n\nggplot(tmp) +\\\n    geom_col(aes(x='id', y='y_pred', fill='Attrition_Flag')) +\\\n    labs(title='Probability of Customer Churn') +\\\n    coord_flip() +\\\n    scale_fill_manual(values = (\"black\", \"red\")) +\\\n    theme_light()\n    \n# theme(axis_title_y = element_blank()) +\\","875e3815":"# Threshold Comparison : 0.5, 0.6, 0.7, 0.8\n\n\nthresholds = [0.5, 0.6, 0.7, 0.8]\n\nfig = plt.figure(figsize=(10,10))\nfig.subplots_adjust(hspace=0.5, wspace=0.4)\nfor i,thr in enumerate(thresholds):\n    prediction = (y_pred > thr).values.astype('int')\n    cm = confusion_matrix(y_test, prediction)\n    \n    ax = fig.add_subplot(2, 2, i+1)\n    ax = sns.heatmap(cm, annot=True, fmt='d', \n                    cbar=False, cmap='Greens', linewidth=0.5)\n    ax.set_title('Confusion Matrix using LR with threshold {}\\n\\\n                    F1 Score : {}\\n\\\n                    Precision : {}\\n\\\n                    Recell : {}'.format(thr, \n                                       np.round(f1_score(y_test, prediction),2), \n                                       np.round(precision_score(y_test, prediction),2), \n                                       np.round(recall_score(y_test, prediction),2)))\n    ","24d577c4":"## Load Data","cbe60127":"Overdispersion not found","7ccf5f22":"## Churner Profile","b8e48f1a":"### Binning","071ab03a":"## Churn Prediction Model\n* Dealing with imbalance data using SMOTE\n* Logistic Regression\n* Diagnosis\n* Evaluation\n","1e1a9348":"Note\n* imbalance data (Attrited Customer 16.00%)\n* Unknown data (Education_Level, Marital_Status, Income_Category)\n* Blue Card almost entire data sets","15ab554c":"Based on the results of Wald's test, we omit the variable <br>Avg_Utilization_Ratio_Binning_woe because p-value > 0.05.","8a868e81":"## Customer Profile","ede99d41":"From the H-L test, it was found that the overall model had Goodness of Fit.","2539eeac":"### Evaluation","86c35463":"note:\nfrom all diagnosis I will\n1. remove Avg_Utilization_Ratio_Binning_woe from the model\n2. Filter influencer\nthen fitting the new model","a38e815c":"## Exploration\n","369cbf9b":"### WOE","84e6a370":"## Feature Engineering\n* Binning : Customer_Age, Months_on_book, Credit_Limit, Total_Revolving_Bal, <br>Avg_Open_To_Buy, Total_Amt_Chng_Q4_Q1, Total_Trans_Amt, Total_Trans_Ct, <br>Total_Ct_Chng_Q4_Q1, Avg_Utilization_Ratio\n* Weight of Evidence\n","883bb252":"### Logistic Regression\n* GLM \n* Diagnosis : Goodness of Fit, Overdispersion, Influence\n* Evaluation\n\nref.<br>\nhttps:\/\/www.statsmodels.org\/stable\/examples\/notebooks\/generated\/glm_formula.html <br>\nhttps:\/\/www.statsmodels.org\/stable\/examples\/notebooks\/generated\/influence_glm_logit.html <br>\n","2e33103a":"#### Diagnosis","a5682a5e":"## Feature Selection","961a403c":"## Dataprep","8197e0fe":"### SMOTE on training data\n* use typical k (k=5)"}}