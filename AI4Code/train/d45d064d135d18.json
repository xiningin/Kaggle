{"cell_type":{"8eb6849d":"code","b4d21284":"code","8db775de":"code","84f4dcac":"code","bc4eae54":"code","7ad61e4b":"code","94c3aff2":"code","f67efcb4":"code","6faf959f":"code","98313969":"code","cce88db1":"code","9fda58ce":"code","1e7175de":"code","87539071":"code","b38c232c":"code","8ed307b5":"code","778bbb33":"code","4133c739":"code","5e9ba0aa":"code","a57856ce":"code","92c9e813":"code","bccd0619":"code","0522ce73":"code","f1c80144":"markdown","986871e6":"markdown","d2a763db":"markdown","302a4994":"markdown","a6d26041":"markdown","3dd57946":"markdown","e225468e":"markdown","68c822d6":"markdown"},"source":{"8eb6849d":"# Importacao das bibliotecas e funcoes a serem utilizadas\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","b4d21284":"from sklearn.preprocessing import RobustScaler, OneHotEncoder\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report","8db775de":"# Importacao dos dados de treino e teste\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/train_data.csv\",\n                         sep=r'\\s*,\\s*',\n                         engine='python',\n                         na_values=\"?\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/test_data.csv\",\n                        sep=r'\\s*,\\s*',\n                        engine='python',\n                        na_values=\"?\")","84f4dcac":"# Altera o nome de algumas features\ntrain_data.columns = train_data.columns.str.replace('.', \"_\");\ntest_data.columns = test_data.columns.str.replace('.', \"_\");","bc4eae54":"# Exclusao das colunas de Id, inuteis para analise\ntrain_data.drop(columns=[\"Id\"], axis=1, inplace=True)\ntest_data.drop(columns=[\"Id\"], axis=1, inplace=True)","7ad61e4b":"train_data.columns","94c3aff2":"train_data.dtypes","f67efcb4":"# Checa o n\u00ba de dados faltantes nos conjuntos p\/ exclusao dos mesmos\ntrain_data.isna().sum()","6faf959f":"test_data.isna().sum()","98313969":"train_data.dropna(axis=0, inplace=True)","cce88db1":"# Definicao da funcao de analise dos dados\ndef analyze(data):\n  \"\"\"\n  data: dataframe a ser analisado\n  \"\"\"\n    # Dado um dataframe, separa as colunas numericas das demais    \n  numerical_data = data.select_dtypes(exclude=['object'])\n  categorical_data = data.select_dtypes(include=['object'])\n    \n    # Para cada coluna numerica, plota sua distribuicao (histograma)\n  for num_col in numerical_data:\n    _, ax = plt.subplots(1, 1, figsize=(12,8))\n    ax.hist(data[num_col], edgecolor='k', linewidth=1.2)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title(f'Distribution of {num_col} attribute')\n    plt.show()\n\n    # Para cada coluna nao numerica (categorica), sao plotados graficos de barra    \n  for cat_col in categorical_data:\n    data[cat_col].value_counts().plot(kind='bar', \n                                      title=f'Distribution of {cat_col} attribute', \n                                      ylabel='Frequency', \n                                      logy=True)\n    plt.show()\n\n  # Mostra-se o heatmap do conjunto, a fim de analisar dependencias entre as\n  # features     \n  data_corr = data.copy()\n  data_corr['income'] = data['income'].map({'<=50K': 0, '>50K': 1})\n  tmp = data_corr.select_dtypes(exclude=['object'])\n  fig, ax = plt.subplots(figsize=(12,8))\n  _ = sns.heatmap(tmp.corr(method='pearson'), annot=True, ax=ax)\n  plt.show()            ","9fda58ce":"analyze(train_data)","1e7175de":"# Definicao das funcoes de encode e pre-processamento\ndef encode_attribute(att):\n  \"\"\"\n  att: atributo a ser codificado via o metodo OneHot\n  \"\"\"\n  encoder = OneHotEncoder(sparse=False)\n  encoded_att = encoder.fit_transform(X=att)\n  return encoded_att\n\ndef preprocess(data):\n  \"\"\"\n  data: conjunto de dados a serem pre-processados\n  \"\"\"\n  # Definicao das colunas a serem excluidas e juntadas      \n  cols_to_drop = [\"workclass\", \"education\", \"race\", \n                  \"relationship\", \"marital_status\", \"native_country\", \n                  \"occupation\"]   \n     \n  cols_to_merge = {\"capital_balance\": [\"capital_gain\", \"capital_loss\"]}\n   \n  data.drop(columns=cols_to_drop, axis=1, inplace=True)\n    \n  for key in cols_to_merge.keys():\n    tmp = cols_to_merge[key]\n    data[key] = data[tmp[0]] - data[tmp[1]]\n    data.drop(columns=tmp, axis=1, inplace=True)\n\n  # Definicao das colunas a serem escaladas para um range aceitavel sem outliers    \n  scaler = RobustScaler()\n  cols_to_scale = data.drop(columns=['education_num']).select_dtypes(include=['int64', 'float64']).columns   \n  data[cols_to_scale] = scaler.fit_transform(data[cols_to_scale].values) \n    \n  # Trasnformacao da feature sexo em uma variavel binaria\n  data['sex'] = data['sex'].map({'Male': 1, 'Female': 0})","87539071":"preprocess(train_data)\npreprocess(test_data)","b38c232c":"train_data.head()","8ed307b5":"def create_classifiers(X, y):\n  \"\"\"\n  X: dados de entrada de treinamento dos modelos\n  y: dados de saida de treinamento dos modelos\n  \"\"\"      \n\n  # Criacao de todos os modelos e tunagem de seus hiperparametros via\n  # GridSearchCV      \n  print(30*'-')\n  print('Creating LDA classifier') \n  LDA = LinearDiscriminantAnalysis(solver='eigen')\n  LDA_param_grid = {'shrinkage': np.linspace(0.1, 1, 100)}\n  LDA_grid = GridSearchCV(LDA, LDA_param_grid, scoring='accuracy', cv=3, \n                          n_jobs=-1, verbose=1)\n  LDA_grid.fit(X, y)\n    \n  print(30*'-')\n  print('Creating QDA classifier') \n  QDA = QuadraticDiscriminantAnalysis()\n  QDA_param_grid = {'reg_param': np.linspace(0.1, 1, 100)}\n  QDA_grid = GridSearchCV(QDA,  QDA_param_grid, scoring='accuracy', cv=3, \n                            n_jobs=-1, verbose=1)\n  QDA_grid.fit(X, y)\n    \n  print(30*'-')\n  print('Creating SVC classifier') \n  SVC_param_grid = {'C': np.linspace(0.1, 1.5, 100)}\n  SVC_ = SVC(random_state=10, probability=True)\n  SVC_grid = GridSearchCV(SVC_, SVC_param_grid, scoring='accuracy', cv=3, \n                          n_jobs=-1, verbose=1)\n  SVC_grid.fit(X, y)\n    \n  print(30*'-')\n  print('Creating Decision Tree classifier') \n  DT_param_grid = {'max_depth': list(range(5,100))}\n  DT = DecisionTreeClassifier()\n  DT_grid = GridSearchCV(DT, DT_param_grid, \n                         scoring='accuracy', cv=3, \n                         n_jobs=-1, verbose=1)\n  DT_grid.fit(X, y)\n    \n    \n  output = {'LDA': [LDA_param_grid, LDA_grid], \n            'QDA': [QDA_param_grid, QDA_grid], \n            'SVC': [SVC_param_grid, SVC_grid], \n            'DT': [DT_param_grid, DT_grid]}\n    \n  return output  \n\ndef display_training_results(output):\n  \"\"\"\n  output: sa\u00edda da fun\u00e7\u00e3o create_classifiers()\n  \"\"\" \n  # Demonstracao dos resultados dos treinos obtidos para os diversos classificadores\n  # elaborados\n  pairs = {}\n  for name, grids in output.items():\n    opt_clf, opt_score = grids[1].best_estimator_, grids[1].best_score_\n    pairs[opt_score] = opt_clf\n    print(100*'-')\n    print(f'Training results for the {name} classifier\\n')\n    print(f\"Opt. classifier: {opt_clf}\\nMean accuracy: {opt_score:.4}\\nError rate: {1-opt_score:.4}\")\n    fig, ax = plt.subplots(1, 1, figsize=(10,8))\n    ax.errorbar(*grids[0].values(), grids[1].cv_results_['mean_test_score'],\n                yerr=grids[1].cv_results_['std_test_score'], \n                ecolor='red', elinewidth=1, fmt='--ko')\n    ax.set_xlabel('Hyperparameter value')\n    ax.set_ylabel('Mean accuracy')\n    ax.set_title(f'Mean accuracy of the {name} classifier')\n    plt.show()\n  print(80*'-')\n  print(f'Best classifier:{pairs[max(pairs.keys())]}\\nBest mean accuracy: {max(pairs.keys()):.4}')\n  print(80*'-')\n\ndef display_classification_reports(X, y, output):\n  \"\"\"\n  X: dados de entrada de treinamento\n  y: dados de sa\u00edda de treinamento\n  output: saida da funcao creat_classifiers()\n  \"\"\"\n  # Demonstra o relatorio de classificacao dos melhores classificadores obtidos\n  # na fase de treinamento\n  for name, grids in output.items():\n    print(80*'-')\n    print(f'Classification report for the {name} classifier')\n    opt_clf = grids[1].best_estimator_\n    y_hat = opt_clf.predict(X)\n    print(classification_report(y, y_hat))","778bbb33":"X_train, y_train = train_data.loc[:, train_data.columns != 'income'], train_data['income']","4133c739":"out = create_classifiers(X_train, y_train)","5e9ba0aa":"display_training_results(out)","a57856ce":"display_classification_reports(X_train, y_train, out)","92c9e813":"DT_clf = out['DT'][1].best_estimator_\ny_hat = DT_clf.predict(test_data)\nfinal_results = pd.DataFrame()\nfinal_results[0] = test_data.index\nfinal_results[1] = y_hat\nfinal_results.columns = ['Id', 'Income']","bccd0619":"final_results.head()","0522ce73":"final_results.to_csv('submission.csv', index=False)","f1c80144":"# Desenvolvimento dos classificadores","986871e6":"Os algoritmos de classifica\u00e7\u00e3o escolhidos para esse EP foram: LDA, QDA, SVM e Decision Tree. Os hiperpar\u00e2metros dos modelos foram encontrados atrav\u00e9s do GridSearchCV, que desenvolve diversos classificadores para uma malha de par\u00e2metros e retorna o \u00f3timo sob a m\u00e9trica escolhida.\n\nO desenvolvimento dos classificadores foi realizado utilizando a acur\u00e1cia como m\u00e9trica.","d2a763db":"# Classifica\u00e7\u00e3o do conjunto de teste\n\nUtilizando o algoritmo com melhor desempenho na m\u00e9trica considerada, a classifica\u00e7\u00e3o do conjunto de testes \u00e9 realizada abaixo.","302a4994":"Conforme \u00e9 poss\u00edvel observar, para a m\u00e9trica considerada o algoritmo Decision Tree obteve um melhor resultado m\u00e9dio. Al\u00e9m disso, em conjunto com o classificador LDA, apresentou menores desvios padr\u00f5es para os diversos hiperpar\u00e2metros testados.\n\nA partir dos _reports_ gerados, \u00e9 poss\u00edvel tamb\u00e9m concluir que a DT desenvolvida tamb\u00e9m apresenta um desempenho razo\u00e1vel nas outras m\u00e9tricas existentes. Dessa forma, esse classificador ser\u00e1 utilizado para gerar a classifica\u00e7\u00e3o final.","a6d26041":"Este notebook \u00e9 dedicado para o segundo exerc\u00edcio programa da disciplina PMR3508. O objetivo geral \u00e9 desenvolver classificadores para o banco de dados Adults presente na plataforma Kaggle.\n\nO notebook \u00e9 organizado de forma que em um primeiro momento \u00e9 realizada uma breve an\u00e1lise explorat\u00f3ria e pr\u00e9-processamento dos dados, e posteriormente o desenvolvimento dos classificadores. A fim de manter a atividade concisa, foram desenvolvidas fun\u00e7\u00f5es que realizam tais tarefas, a saber: \n\n\n\n*   **analyze()**: \u00e9 respons\u00e1vel por fazer uma breve an\u00e1lise explorat\u00f3ria dos dados, plotando histogramas, gr\u00e1ficos de barra, etc;\n*   **encode_attribute()**: \u00e9 respons\u00e1vel pelo _encode_ de um atributo sob a forma OneHot;\n*   **preprocess()**: realiza o pr\u00e9-processamento dos dados atrav\u00e9s da retirada e combina\u00e7\u00e3o das _features_ do _dataset_; \n*   **create_classifiers()**: cria os classificadores que ser\u00e3o utilizados e os treina utilizando o _dataset_ fornecido;\n*   **display_training_results()**: demonstra os resultados do treinamento dos classificadores, dando enfoque \u00e0 m\u00e9trica de avalia\u00e7\u00e3o preferida;\n*   **display_classification_reports()**: demonstra relat\u00f3rios contendo todas as m\u00e9tricas de classifica\u00e7\u00e3o de cada algoritmo escolhido, visando uma compara\u00e7\u00e3o entre os mesmos.","3dd57946":"# An\u00e1lise explorat\u00f3ria e pr\u00e9-processamento dos dados","e225468e":"# PMR3508-2021-2-42\n","68c822d6":"Esta se\u00e7\u00e3o \u00e9 dedicada \u00e0 an\u00e1lise inicial dos dados e seu pr\u00e9-processamento. Como essas atividades foram o foco parcial do primeiro EP, nesse caso n\u00e3o ser\u00e3o t\u00e3o aprofundadas."}}