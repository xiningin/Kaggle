{"cell_type":{"1ea99ff2":"code","6d9a4669":"code","bd5acf5f":"code","8439d07d":"code","ee8dd2eb":"code","43f203d0":"code","4ee8f3dc":"code","de71210b":"code","aaa238ed":"code","69265152":"code","1bf844c7":"code","3ec7ee52":"code","6522c9f1":"code","8f9f5427":"code","cdc7502b":"code","d230afe0":"code","6af3a8d4":"code","8554e546":"code","7ece344d":"code","d6427de2":"code","eedfb0b9":"code","33dbe1d8":"code","2c5e3623":"code","65149db8":"code","5bb5cae3":"markdown","047c4c71":"markdown","878945dc":"markdown","d62f008e":"markdown","9eadb94e":"markdown","691e62dc":"markdown","8d90eab0":"markdown","b300b736":"markdown","9b0975ca":"markdown","e1ab81bd":"markdown","621bb9f1":"markdown","c44580ee":"markdown","def5a0f5":"markdown","3158a8af":"markdown","0cca6f60":"markdown","8573cabd":"markdown","b9924a62":"markdown","7fe4b911":"markdown","8dff0279":"markdown","f1f6b59e":"markdown","e1d1a772":"markdown","3b4e140e":"markdown","18a78174":"markdown","fbbc7441":"markdown","734bfa88":"markdown","e4f614da":"markdown","1a5efdc6":"markdown","a673f9e6":"markdown","58f0020c":"markdown","32c6cd3a":"markdown"},"source":{"1ea99ff2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random # generate pseudo-random numbers\nimport os # operational system\nfrom PIL import Image # python imaging library\nimport glob # unix style pathname pattern expansion\n\n# Import Pytorch\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# We need the display function from IPython for Jupyter Notebook\/Colab\nfrom IPython.display import display\n\n#Install EfficientNet\n!pip install efficientnet_pytorch\nfrom efficientnet_pytorch import EfficientNet\n\n# A package to make beautiful progress bars :) \nfrom tqdm.notebook import tqdm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d9a4669":"class Dataset(torch.utils.data.Dataset):\n  'Characterizes a dataset for PyTorch'\n  def __init__(self, path_labels, path_images='\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/training_images\/', transform=None):\n        'Initialization'\n        \n        # The attribute dataset is a dataframe with the data in csv defined by path_labels\n        # The csv contains the name of images in the first column and their labels in the second\n        self.dataset = pd.read_csv(path_labels, sep=\" \", header=None)\n        self.path_labels = path_labels\n        self.path_images = path_images\n        self.transform = transform\n\n  def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.dataset)\n\n  def __getitem__(self, index):\n        'Generates one sample of data'\n\n        # Load data and get label\n        X = Image.open(self.path_images + self.dataset[0][index]).convert('RGB') # Open image at index and convert to RGB\n        y = self.dataset[1][index] # Get the label of the image at the index\n        if(self.transform):\n            X = self.transform(X) # Apply transformations on the image if defined\n\n        return X, y","bd5acf5f":"train_dataset = Dataset('\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/train.txt')\n\nvalid_dataset = Dataset('\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/val.txt')","8439d07d":"for i in range(10):\n  n = random.randrange(len(train_dataset))\n  print(\"Label = \", train_dataset[n][1], \": \")\n  display(train_dataset[n][0])","ee8dd2eb":"def train_and_eval(net, criterion, optimizer, train_dl, val_dl, hidden=False):\n    '''\n    Train and evaluate a neural network\n    -- Inputs:\n    net: neural network\n    criterion: loss function\n    optimizer: optimizer function\n    train_dl: train dataset data loader\n    val_dl: val dataset data loader\n    '''\n    \n    epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []\n\n    for e in range(N_EPOCHS):\n        print(\"EPOCH:\", e)\n\n        ### TRAINING LOOP\n        running_loss = 0\n        running_accuracy = 0\n\n        # Put the network in training mode\n        net.train()\n\n        for i, batch in enumerate(tqdm(train_dl)):\n\n            # Get a batch from the dataloader\n            x = batch[0]\n            labels = batch[1]\n\n            # Move the batch to GPU\n            x = x.cuda()\n            labels = labels.cuda()\n\n            # Compute the network output\n            if hidden:\n                y, hidden = net(x)\n            else:\n                y = net(x)\n\n            # Compute the loss\n            loss = criterion(y, labels)\n\n            # Reset the gradients\n            optimizer.zero_grad()\n\n            # Compute the gradients\n            loss.backward()\n\n            # Apply one step of the descent algorithm to update the weights\n            optimizer.step()\n\n            # Compute some statistics\n            with torch.no_grad(): # disables gradient calculations\n                running_loss += loss.item()\n                running_accuracy += (y.max(1)[1] == labels).sum().item()\n\n        print(\"Training accuracy:\", running_accuracy\/float(len(train_set)),\n              \"Training loss:\", running_loss\/float(len(train_set)))\n\n        epoch_loss.append(running_loss\/len(cd_train_set))\n        epoch_acc.append(running_accuracy\/len(cd_train_set))\n\n        ### VALIDATION LOOP\n        # Put the network in validation mode\n        net.eval()\n\n        running_val_loss = 0\n        running_val_accuracy = 0\n\n        for i, batch in enumerate(tqdm(val_dl)):\n\n            with torch.no_grad(): # disables gradient calculations\n                # Get a batch from the dataloader\n                x = batch[0]\n                labels = batch[1]\n\n                # Move the batch to GPU\n                x = x.cuda()\n                labels = labels.cuda()\n\n                # Compute the network output\n                if hidden:\n                    y, hidden = net(x)\n                else:\n                    y = net(x)\n\n                # Compute the loss\n                loss = criterion(y, labels)\n\n                running_val_loss += loss.item()\n                running_val_accuracy += (y.max(1)[1] == labels).sum().item()\n\n        print(\"Validation accuracy:\", running_val_accuracy\/float(len(val_set)),\n              \"Validation loss:\", running_val_loss\/float(len(val_set)))\n\n        epoch_val_loss.append(running_val_loss\/len(val_set))\n        epoch_val_acc.append(running_val_accuracy\/len(val_set))","43f203d0":"def generate_output(name, net, transform):\n    'Generates csv file to submit to the leaderboard'\n    \n    # Get image names and create output file\n    names = sorted(glob.glob(\"\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/test_images\/*\"))\n    f = open(name + '.csv', 'w')\n    f.write(\"name,class\\n\")\n    \n    print(\"Generation of the result csv file (on the test dataset) in progress...\\n\")\n    \n    for i in tqdm(range(len(names))):\n    # For each image in the test set\n        img = Image.open(names[i]).convert('RGB') # load image\n        pred = nn.functional.softmax(net(transform(img).unsqueeze(0).cuda()), dim=1).max(1)[1].item() # classify image with the neural network\n        f.write(os.path.basename(names[i])+','+str(pred)+'\\n') # write to the output file\n    f.close()\n    \n    print(\"The csv file has been correctly generated\")","4ee8f3dc":"# net, convert, criterion, optimizer = resNet()\n\n# # Create Datasets\n# train_set = Dataset('\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/train.txt', transform=convert)\n# val_set = Dataset('\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/val.txt', transform=convert)\n\n# # Create Data Loaders\n# train_dl = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n# val_dl = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True, num_workers=8)\n\n# train_and_eval(net, criterion, optimizer, train_dl, val_dl)\n\n# generate_output('resNet', net, convert)","de71210b":"def resNet():\n    LEARNING_RATE = 0.001\n    N_EPOCHS = 13\n    \n    # Define the neural network\n    net = torchvision.models.resnet18()\n    num_ftrs = net.fc.in_features\n    net.fc = nn.Linear(num_ftrs, 102)\n    \n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = torchvision.transforms.Compose([torchvision.transforms.Resize((299,299)), torchvision.transforms.ToTensor()])\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","aaa238ed":"def inception_v3():\n    # When running this model, set the hidden parameter from the train_and_eval function to true\n    \n    N_EPOCHS = 20\n\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'inception_v3', pretrained=True)\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","69265152":"def googleNet():\n    N_EPOCHS = 9\n\n    net = torchvision.models.googlenet(pretrained=True)\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","1bf844c7":"def vgg19():\n    N_EPOCHS = 20\n\n    net = torchvision.models.vgg19(pretrained=True)\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","3ec7ee52":"def wideNet():\n    N_EPOCHS = 20\n\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'wide_resnet101_2', pretrained=True)\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","6522c9f1":"def alexNet():\n    N_EPOCHS = 20\n\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'alexnet', pretrained=True)\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","8f9f5427":"\"\"\" \nCreates an Xception Model as defined in:\nFrancois Chollet\nXception: Deep Learning with Depthwise Separable Convolutions\nhttps:\/\/arxiv.org\/pdf\/1610.02357.pdf\nThis weights ported from the Keras implementation. Achieves the following performance on the validation set:\nLoss:0.9173 Prec@1:78.892 Prec@5:94.292\nREMEMBER to set your image size to 3x299x299 for both test and validation\nnormalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                  std=[0.5, 0.5, 0.5])\nThe resize parameter of the validation transform should be 333, and make sure to center crop at 299x299\n\"\"\"\n\nimport math\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom torch.nn import init\n\n__all__ = ['xception']\n\nmodel_urls = {\n    'xception':'https:\/\/www.dropbox.com\/s\/1hplpzet9d7dv29\/xception-c0a72b38.pth.tar?dl=1'\n}\n\n\nclass SeparableConv2d(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n        super(SeparableConv2d,self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n    \n    def forward(self,x):\n        x = self.conv1(x)\n        x = self.pointwise(x)\n        return x\n\n\nclass Block(nn.Module):\n    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n        super(Block, self).__init__()\n\n        if out_filters != in_filters or strides!=1:\n            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n            self.skipbn = nn.BatchNorm2d(out_filters)\n        else:\n            self.skip=None\n        \n        self.relu = nn.ReLU(inplace=True)\n        rep=[]\n\n        filters=in_filters\n        if grow_first:\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(out_filters))\n            filters = out_filters\n\n        for i in range(reps-1):\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(filters))\n        \n        if not grow_first:\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(out_filters))\n\n        if not start_with_relu:\n            rep = rep[1:]\n        else:\n            rep[0] = nn.ReLU(inplace=False)\n\n        if strides != 1:\n            rep.append(nn.MaxPool2d(3,strides,1))\n        self.rep = nn.Sequential(*rep)\n\n    def forward(self,inp):\n        x = self.rep(inp)\n\n        if self.skip is not None:\n            skip = self.skip(inp)\n            skip = self.skipbn(skip)\n        else:\n            skip = inp\n\n        x+=skip\n        return x\n\nclass Xception(nn.Module):\n    \"\"\"\n    Xception optimized for the ImageNet dataset, as specified in\n    https:\/\/arxiv.org\/pdf\/1610.02357.pdf\n    \"\"\"\n    def __init__(self, num_classes=1000):\n        \"\"\" Constructor\n        Args:\n            num_classes: number of classes\n        \"\"\"\n        super(Xception, self).__init__()\n\n        \n        self.num_classes = num_classes\n\n        self.conv1 = nn.Conv2d(3, 32, 3,2, 0, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n        self.bn2 = nn.BatchNorm2d(64)\n        #do relu here\n\n        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n\n        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n\n        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n\n        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n\n        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n        self.bn3 = nn.BatchNorm2d(1536)\n\n        #do relu here\n        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n        self.bn4 = nn.BatchNorm2d(2048)\n\n        self.fc = nn.Linear(2048, num_classes)\n\n\n\n        #------- init weights --------\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        #-----------------------------\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        x = self.block6(x)\n        x = self.block7(x)\n        x = self.block8(x)\n        x = self.block9(x)\n        x = self.block10(x)\n        x = self.block11(x)\n        x = self.block12(x)\n        \n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.relu(x)\n        \n        x = self.conv4(x)\n        x = self.bn4(x)\n        x = self.relu(x)\n\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x","cdc7502b":"def xception():\n    N_EPOCHS = 20\n\n    net = Xception(pretrained=True)\n    net.load_state_dict(model_zoo.load_url(model_urls['xception']))\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","d230afe0":"def denseNet():\n    N_EPOCHS = 20\n\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'densenet121', pretrained=True)\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","6af3a8d4":"def efficientNet():\n    N_EPOCHS = 20\n\n    net = EfficientNet.from_pretrained('efficientnet-b0')\n\n    # Move model to the GPU\n    net = net.cuda()\n    \n    # Define images transformations (pre processing)\n    convert = transforms.Compose([\n        transforms.Resize(299),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n\n    # Negative log likelihood loss\n    criterion = nn.CrossEntropyLoss(reduction=\"mean\").cuda()\n\n    # Stochastic Gradient Descent\n    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n    \n    return net, convert, criterion, optimizer","8554e546":"class SAM(torch.optim.Optimizer):\n    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n\n        defaults = dict(rho=rho, **kwargs)\n        super(SAM, self).__init__(params, defaults)\n\n        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n        self.param_groups = self.base_optimizer.param_groups\n\n    @torch.no_grad()\n    def first_step(self, zero_grad=False):\n        grad_norm = self._grad_norm()\n        for group in self.param_groups:\n            scale = group[\"rho\"] \/ (grad_norm + 1e-12)\n\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                e_w = p.grad * scale\n                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n                self.state[p][\"e_w\"] = e_w\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def second_step(self, zero_grad=False):\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n\n        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n\n        if zero_grad: self.zero_grad()\n\n    def step(self, closure=None):\n        raise NotImplementedError(\"SAM doesn't work like the other optimizers, you should first call `first_step` and the `second_step`; see the documentation for more info.\")\n\n    def _grad_norm(self):\n        norm = torch.norm(\n                    torch.stack([\n                        p.grad.norm(p=2)\n                        for group in self.param_groups for p in group[\"params\"]\n                        if p.grad is not None\n                    ]),\n                    p=2\n               )\n        return norm","7ece344d":"import torch.nn.functional as F\n\n\ndef smooth_crossentropy(pred, gold, smoothing=0.1):\n    n_class = pred.size(1)\n\n    one_hot = torch.full_like(pred, fill_value=smoothing \/ (n_class - 1))\n    one_hot.scatter_(dim=1, index=gold.unsqueeze(1), value=1.0 - smoothing)\n    log_prob = F.log_softmax(pred, dim=1)\n\n    return F.kl_div(input=log_prob, target=one_hot, reduction='none').sum(-1)","d6427de2":"class StepLR:\n    def __init__(self, optimizer, learning_rate: float, total_epochs: int):\n        self.optimizer = optimizer\n        self.total_epochs = total_epochs\n        self.base = learning_rate\n\n    def __call__(self, epoch):\n        if epoch < self.total_epochs * 3\/10:\n            lr = self.base\n        elif epoch < self.total_epochs * 6\/10:\n            lr = self.base * 0.2\n        elif epoch < self.total_epochs * 8\/10:\n            lr = self.base * 0.2 ** 2\n        else:\n            lr = self.base * 0.2 ** 3\n\n        for param_group in self.optimizer.param_groups:\n            param_group[\"lr\"] = lr\n\n    def lr(self) -> float:\n        return self.optimizer.param_groups[0][\"lr\"]","eedfb0b9":"net = EfficientNet.from_pretrained('efficientnet-b5')\n\npreprocess = transforms.Compose([\n    transforms.Resize(299),\n    transforms.CenterCrop(299),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ncd_train_set = Dataset('\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/train.txt', transform=preprocess)\ncd_val_set = Dataset('\/kaggle\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/val.txt', transform=preprocess)\n\ncd_train_dl = torch.utils.data.DataLoader(cd_train_set, batch_size=16, shuffle=True, num_workers=8)\ncd_val_dl = torch.utils.data.DataLoader(cd_val_set, batch_size=16, shuffle=True, num_workers=8)","33dbe1d8":"# Move model to the GPU\nnet = net.cuda()\n\nbase_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\noptimizer = SAM(net.parameters(), base_optimizer, lr=0.1, momentum=0.9)\nscheduler = StepLR(optimizer, 0.1, 20)","2c5e3623":"## NUMBER OF EPOCHS TO TRAIN\nN_EPOCHS = 10\n\nepoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []\n\nfor e in range(N_EPOCHS):\n  \n    print(\"EPOCH:\",e)\n\n    ### TRAINING LOOP\n    running_loss = 0\n    running_accuracy = 0\n\n    ## Put the network in training mode\n    net.train()\n\n    for batch in tqdm(cd_train_dl):\n        y, labels=(b.cuda() for b in batch)\n        \n        # Compute the network output\n        predictions = net(y)\n        # Compute the loss\n        loss =  smooth_crossentropy(predictions, labels).cuda()\n        loss.mean().backward()\n        optimizer.first_step(zero_grad=True)\n        \n        # Compute the gradients\n        smooth_crossentropy(net(y), labels).mean().backward()\n        optimizer.second_step(zero_grad=True)\n        ## Compute some statistics\n        with torch.no_grad():\n            running_accuracy += (torch.argmax(predictions.data, 1) == labels).sum().item()\n            scheduler(e)\n\n    print(\"Training accuracy:\", running_accuracy\/float(len(cd_train_set)))\n\n    epoch_loss.append(running_loss\/len(cd_train_set))\n    epoch_acc.append(running_accuracy\/len(cd_train_set))\n\n    ### VALIDATION LOOP\n    ## Put the network in validation mode\n    net.eval()\n\n    running_val_loss = 0\n    running_val_accuracy = 0\n\n    for i, batch in enumerate(tqdm(cd_val_dl)):\n        with torch.no_grad():\n            y, labels=(b.cuda() for b in batch)\n            # Compute the network output\n            predictions = net(y)\n            # Compute the loss\n            loss = smooth_crossentropy(predictions, labels)\n            running_val_accuracy += (torch.argmax(predictions, 1) == labels).sum().item()\n\n    print(\"Validation accuracy:\", running_val_accuracy\/float(len(cd_val_set)))\n\n    epoch_val_loss.append(running_val_loss\/len(cd_val_set))\n    epoch_val_acc.append(running_val_accuracy\/len(cd_val_set))","65149db8":"generate_output('EfficientNet5Sam', net, preprocess)","5bb5cae3":"# Insect Pest Recognition - Kaggle challenge\n***SPIRE Florian, STUART Thuany, JOSHUA NELSON Dhivin*** \/ (M1 EIT Data Science)","047c4c71":"# Import Libraries","878945dc":"## Modeling functions","d62f008e":"### Inception_v3","9eadb94e":"We display 10 images randomly with their labels just to get an idea of the dataset.","691e62dc":"We have defined a function that returns *neural network, tranformations, loss function, and optimizer* for each setting. To train, evaluate, generate output and run the settings, we have created other support functions.","8d90eab0":"### Train and Evaluate","b300b736":"### EfficientNet","9b0975ca":"### AlexNet","e1ab81bd":"1. EfficientNet with SAM + smooth_crossentropy + stepLR *(around 70% accuracy on the validation set)*\n2. EfficientNet *(around 65%)*\n3. Xception *(around 65%)*\n4. GoogleNet *(around 63%)*\n5. Inception_v3 \/ v4 *(around 61%)*\n6. ResNet *(around 46%)*\n7. AlexNet\n8. DenseNet\n9. WideNet","621bb9f1":"In order to put together the functions above to assess a setting, we run the routine below. This is an example for resNet. One can assess other neural networks by replacing the function on the first line.","c44580ee":"Because Xception is not included in PyTorch, we have used the implementation from this [repository](https:\/\/github.com\/tstandley\/Xception-PyTorch\/blob\/master\/xception.py).","def5a0f5":"## Neural Networks Settings","3158a8af":"### Xception","0cca6f60":"## **[You can check here the performances we registered for different models, batch sizes, size of layers etc.](https:\/\/unice-my.sharepoint.com\/:x:\/g\/personal\/florian_spire_etu_unice_fr\/EWmarnwAW0pNk7knzgK_GxABBbFR3J4msKGRMtLF0DMlkQ?e=5xfbfz)**","8573cabd":"# Modeling","b9924a62":"# The Dataset class\n\nWe define a class that extends PyTorch's Dataset class and is used to load and store an entire dataset while applying initial transformations in the images.","7fe4b911":"## EfficientNet-B5 with SAM + smooth_crossentropy + stepLR","8dff0279":"# Final ranking of the different models we tried on our dataset","f1f6b59e":"Here we define the functions that generate the neural network configurations that we have tested.","e1d1a772":"### Vgg19","3b4e140e":"### Run Model","18a78174":"### GoogleNet","fbbc7441":"### DenseNet","734bfa88":"### ResNet","e4f614da":"# Import train and validation datasets\n\nWe import the train and valiation datasets. We will use the validation dataset to test the accuracy of the trained models in unseen data to tune hyperparameters before the final assessment with the test set.","1a5efdc6":"Finally, we have arrived at our best accuracy by using efficientNet-B5 with Sharpness-Aware Minimization, smooth crossentropy and stepLR. \n\n*You can find [here](https:\/\/github.com\/davda54\/sam) the documentation and implementation we used for the \"Sharpness-Aware Minimization\" and [here](https:\/\/arxiv.org\/pdf\/1905.11946.pdf) the documentation for efficientNet*","a673f9e6":"### WideNet","58f0020c":"### Generate output csv file","32c6cd3a":"Our approach to the modeling was to try several known neural networks with a few tranformations and test which one would give the best accuracy with the insect dataset.\n\nWe will describe below some settings that we have tried and our chosen setting. \n\n**At the end of the notebook you will find an Excel file with most of the performances we registered (with different models, optimizers, batch sizes, size of layers etc.) and a ranking of the best models we found for the dataset of this competition.**"}}