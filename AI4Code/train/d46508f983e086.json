{"cell_type":{"9bb4185b":"code","f5a53b84":"code","c522bb63":"code","3c2dcb1b":"code","703f032d":"code","d5ce6754":"code","e29ad818":"code","cd15973a":"code","569e7fd5":"code","810103bd":"code","809eeecb":"code","5599eaad":"code","c2e13c79":"code","d4e82cd1":"code","cdba5323":"code","274cff21":"markdown","795684a3":"markdown","4c5e900d":"markdown","a2b4c3ba":"markdown","adbd3917":"markdown","8469b116":"markdown","43a87192":"markdown","46e6e9a5":"markdown","98cbbd9e":"markdown"},"source":{"9bb4185b":"import numpy as np \nimport pandas as pd\nimport os\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","f5a53b84":"direc = Path('..\/input\/large-shoe-dataset-ut-zappos50k\/ut-zap50k-images\/ut-zap50k-images')\nfilepaths = list(direc.glob(r'**\/**\/**\/*.jpg'))\nLabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],filepaths))\n\n\nfilepaths = pd.Series(filepaths, name='FilePaths').astype(str)\nLabels = pd.Series(Labels, name='Labels').astype(str)\n\nimg_df = pd.merge(filepaths, Labels, right_index = True, left_index = True)\n\n\n#Resampling it\nimg_df.head()","c522bb63":"fp = filepaths.str.split(pat=\"\/\", n = 8, expand = True)\n\nLabel1 = fp[5]+\" - \"+fp[6]\nLabel1 = pd.DataFrame(Label1)\nLabel1 = Label1.rename(columns = {0:'Label1'})\n\nimg_df2 = pd.concat([img_df, Label1], axis=1)\nimg_df2 = img_df2.drop('Labels', axis=1)\nimg_df2","3c2dcb1b":"import matplotlib.pyplot as plt\nf,a = plt.subplots(nrows=5, ncols=8,figsize=(13, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(a.flat):\n    ax.imshow(plt.imread(img_df2.FilePaths[i]))\n    ax.set_title(img_df2.Label1[i])\n    \nplt.tight_layout()\nplt.show()","703f032d":"print(f\" Count of Rows : {img_df2.shape[0]} \\n Count of Columns : {img_df2.shape[1]} \")","d5ce6754":"img_df2['Label1'].value_counts(ascending=True)","e29ad818":"img_df2 = img_df2.groupby('Label1').filter(lambda x : len(x)>=100)","cd15973a":"img_df2['Label1'].value_counts(ascending=True)","569e7fd5":"plt.figure(figsize=(10,8))\nplt.pie(img_df2['Label1'].value_counts(ascending=True), labels=img_df2['Label1'].unique(),autopct='%1.2f',textprops=dict(color=\"w\"))\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.title(\"Shoe Types\")\nplt.show()\n","810103bd":"train_ratio = 0.70\nvalidation_ratio = 0.15\ntest_ratio = 0.15\n\n\nx_train, x_test = train_test_split(img_df2, test_size=1 - train_ratio, stratify=img_df2['Label1'])\nx_val, x_test = train_test_split(x_test, test_size=test_ratio\/(test_ratio + validation_ratio),stratify=x_test['Label1']) \n\nprint(f'Shape of Training Data : ',x_train.shape)\nprint(f'Shape of Testing Data : ',x_test.shape)\nprint(f'Shape of Validation Data : ',x_val.shape)\nx_test = x_test.copy()","809eeecb":"img_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n\nimg_size=(224, 224)    \n\nx_train = img_datagen.flow_from_dataframe(dataframe = x_train, x_col='FilePaths', y_col='Label1', target_size=img_size, color_mode='rgb',class_mode='categorical',batch_size=32,seed=42)\nx_test = img_datagen.flow_from_dataframe(dataframe = x_test, x_col='FilePaths', y_col='Label1', target_size=img_size,color_mode='rgb',class_mode='categorical',batch_size=32,seed=42)\nx_val = img_datagen.flow_from_dataframe(dataframe = x_val, x_col='FilePaths', y_col='Label1', target_size=img_size, color_mode='rgb',class_mode='categorical',batch_size=32,seed=42)","5599eaad":"model = keras.Sequential([\n\n    # First Convolutional Block\n    tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n                  # give the input dimensions in the first layer\n                  # [height, width, color channels(RGB)]\n                 input_shape=[224, 224, 3]),\n    tf.keras.layers.MaxPool2D(),\n\n    # Second Convolutional Block\n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n    tf.keras.layers.MaxPool2D(),\n\n    # Third Convolutional Block\n    tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n    tf.keras.layers.MaxPool2D(),\n\n    # Classifier Head\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(740, activation=\"relu\"),\n    tf.keras.layers.Dense(15, activation=\"softmax\"),\n])\nmodel.summary()\n\nmodel.compile(optimizer=\"adam\",\n             loss=\"binary_crossentropy\",\n             metrics=[\"accuracy\"])","c2e13c79":"Callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\nmodel_fit = model.fit(x_train,\n                      validation_data = x_val, \n                      epochs = 10, callbacks=Callback)","d4e82cd1":"print('Model summary :')\nprint()\nmodel.summary()","cdba5323":"test_accuracy = model.evaluate(x_test)[1] * 100\nprint('Test accuracy is : ',test_accuracy, '%' )","274cff21":"**Augmenting the Image Dataset**","795684a3":"**Testing Model**","4c5e900d":"**Large Shoe Dataset (UT Zappos50k)**\n\n* Data Importing\n* Defining Labels (Classes)\n* Train, Validation and Test\n* Augmenting the Image Dataset\n* Building a Model\n* Testing Model","a2b4c3ba":"**Classes (Labels) are trained with many images. Usually around 100 images are sufficient to train a class.\nTherefore I set the minimum amount of class as 100.**","adbd3917":"**Building a Model**","8469b116":"**Defining Labels (Classes)**","43a87192":"**Defining Train, Validation and Test**","46e6e9a5":"**Below we can see the pie chart of Classes that are about to be trained and tested for accuracy**","98cbbd9e":"**Data Importing**"}}