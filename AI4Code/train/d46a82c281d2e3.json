{"cell_type":{"b143e17d":"code","0d361191":"code","8e5af1b0":"code","45a6f8cb":"code","a0652884":"code","58ed7736":"code","0004defb":"code","ce085ee1":"code","9c4b1356":"code","2ff2623a":"code","220d2afe":"code","27d0eed2":"code","d1e57853":"code","7e8a65ab":"code","778da866":"code","4a84a771":"code","216bfeec":"code","d2270dd3":"code","362bbee2":"code","00b85a69":"code","3ee125d6":"code","8ee17b40":"code","5d7253bc":"code","810b3267":"code","13320844":"code","953301fe":"code","d5f0a1e6":"code","ef88906c":"code","58ef7676":"code","520e6431":"code","6b9e63ba":"code","f50931dc":"code","954c3980":"code","ec81299e":"code","56851fdb":"code","2c8911e8":"code","8e261e1c":"code","43026a6c":"code","4028ae90":"code","072462d8":"code","7dd65ec0":"code","1a59c48b":"code","f4abefdd":"code","4b3ea19e":"code","508fb052":"code","2917b938":"code","8b19ff1e":"code","5c7e2975":"code","a1789ada":"code","8ca1f46f":"code","7be11c5d":"code","ad185db3":"markdown","a72f3cdf":"markdown","b4336dcb":"markdown","715b25bd":"markdown","3b540b16":"markdown","1b9d64e8":"markdown","30bfb798":"markdown","8c43d2e0":"markdown","3f03d1db":"markdown","c2a3477c":"markdown","7329bbf0":"markdown","9964ab1a":"markdown","b2078510":"markdown"},"source":{"b143e17d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0d361191":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn import ensemble, tree, linear_model, preprocessing\nimport missingno as msno\nimport pandas_profiling\nimport plotly.express as px","8e5af1b0":"District_wise = pd.read_csv('..\/input\/education-in-india\/2015_16_Districtwise.csv')\nState_wise_elementry = pd.read_csv('..\/input\/education-in-india\/2015_16_Statewise_Elementary.csv')\nState_wise_secondary = pd.read_csv('..\/input\/education-in-india\/2015_16_Statewise_Secondary.csv')\n","45a6f8cb":"District_wise_met = pd.read_csv('..\/input\/education-in-india\/2015_16_Districtwise_Metadata.csv')\nState_wise_elementry_met = pd.read_csv('..\/input\/education-in-india\/2015_16_Statewise_Elementary_Metadata.csv')\nState_wise_secondary_met = pd.read_csv('..\/input\/education-in-india\/2015_16_Statewise_Secondary_Metadata.csv')\n","a0652884":"District_wise.head()","58ed7736":"District_wise_met.head()","0004defb":"District_wise_total = pd.DataFrame()","ce085ee1":"i=0\nfor name in District_wise_met['Description']:\n    if 'Total' in name:\n        District_wise_total[District_wise_met.iloc[i][1]] = District_wise[District_wise_met.iloc[i][0]]\n    i=i+1","9c4b1356":"District_wise_total['Schools_By_Category: Total']\/(District_wise_total['Schools_by_Category:_Government: Total']+District_wise_total['Schools_by_Category:_Private_: Total']+District_wise_total['Schools_by_Category:_Madarsas_&_Unrecognised: Total'])","2ff2623a":"District_wise.head()","220d2afe":"District_wise_new = pd.DataFrame()","27d0eed2":"District_wise_new['STATNAME'] = District_wise['STATNAME']","d1e57853":"District_wise_new['DISTNAME'] = District_wise['DISTNAME']","7e8a65ab":"District_wise_new = pd.concat([District_wise_new, District_wise_total], axis = 1 )","778da866":"District_wise_grouped = District_wise_new.groupby(by = 'STATNAME')","4a84a771":"State_wise_sum = District_wise_grouped.sum()","216bfeec":"State_wise_sum.head()","d2270dd3":"State_wise_sum.index","362bbee2":"State_wise_sum['People_per_School'] = State_wise_sum['Basic_data_from_Census_2011: Total_Population(in_1000\\'s)']\/State_wise_sum['Schools_By_Category: Total']","00b85a69":"ax = sns.barplot(y=State_wise_sum.index, x='People_per_School', data = State_wise_sum  )\n#ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n#plt.tight_layout()\n\nplt.figure(figsize=(16,4))","3ee125d6":"State_wise_sum.head()","8ee17b40":"State_wise_fac = pd.DataFrame()\nfor name in State_wise_sum.columns[21:31]:\n    \n    State_wise_fac[name] = State_wise_sum[name]","5d7253bc":"State_wise_fac['Total_Schools'] = State_wise_sum['Schools_By_Category: Total']\nState_wise_fac['Population_school_serves'] = State_wise_sum['People_per_School']","810b3267":"for name in State_wise_fac.columns[0:8]:\n    State_wise_fac[name] = State_wise_fac[name]\/State_wise_fac['Total_Schools']","13320844":"State_wise_fac['Fraction_of_required_ramps'] = State_wise_fac['Schools_with_Ramp_(where_needed): Total']\/State_wise_fac['Schools_where_Ramp_is_Required: Total']","953301fe":"State_wise_fac = State_wise_fac.drop(['Schools_with_Ramp_(where_needed): Total','Schools_where_Ramp_is_Required: Total'], axis =1)","d5f0a1e6":"State_wise_fac.head()","ef88906c":"pd.plotting.scatter_matrix(State_wise_fac, alpha = 0.3, figsize = (21,12), diagonal = 'kde')","58ef7676":"df_std","520e6431":"df_std[:,1]","6b9e63ba":"State_wise_fac_scaled = pd.DataFrame()\ni=0\nfor name in State_wise_fac.columns:\n    State_wise_fac_scaled[name] = df_std[:,i]\n    i=i+1","f50931dc":"State_wise_fac.head()","954c3980":"temp = State_wise_fac\ntemp['Schools_with_Computer: Total'] = np.log(State_wise_fac['Schools_with_Computer: Total'])\ntemp['Total_Schools'] = np.log(State_wise_fac['Total_Schools'])\ntemp['Population_school_serves'] =  np.log(State_wise_fac['Population_school_serves'])","ec81299e":"pd.plotting.scatter_matrix(temp, alpha = 0.3, figsize = (21,12), diagonal = 'kde')","56851fdb":"temp.head()","2c8911e8":"temp.drop(['Schools_with_Girls\\'_Toilet: Total','Schools_with_Drinking_Water: Total'], inplace = True, axis=1)","8e261e1c":"temp['Schools_with_Boys\\'_Toilet: Total'] = np.arcsin(temp['Schools_with_Boys\\'_Toilet: Total'])","43026a6c":"std_scale = preprocessing.StandardScaler().fit(temp)\ndf_std = std_scale.transform(temp)\ndf_std","4028ae90":"temp = pd.DataFrame()\ni=0\nfor name in State_wise_fac.columns:\n    temp[name] = df_std[:,i]\n    i=i+1","072462d8":"temp.head()","7dd65ec0":"pd.plotting.scatter_matrix(temp, alpha = 0.3, figsize = (21,12), diagonal = 'kde')","1a59c48b":"plt.subplots(figsize=(12,9))\nsns.heatmap(abs(temp.cov()), vmax=0.9)","f4abefdd":"from sklearn.decomposition import PCA\npca = PCA(n_components=temp.shape[1]).fit(temp)\n","4b3ea19e":"#Fitting the PCA algorithm with our Data\npca = PCA().fit(temp)\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\n#plt.title('Pulsar Dataset Explained Variance')\nplt.show()","508fb052":"pca = PCA(n_components=5)\ntransformed_temp = pca.fit_transform(temp)","2917b938":"transformed_temp[:,1]","8b19ff1e":"for_train = pd.DataFrame()\ni=0\nfor name in ['1','2','3','4','5']:\n    for_train[name] = transformed_temp[:,i]\n    i=i+1","5c7e2975":"for_train.head()","a1789ada":"from sklearn.cluster import KMeans \nfrom sklearn import metrics \nfrom scipy.spatial.distance import cdist \n\ndistortions = [] \ninertias = [] \nmapping1 = {} \nmapping2 = {} \nK = range(1,10) \n  \nfor k in K: \n    #Building and fitting the model \n    kmeanModel = KMeans(n_clusters=k).fit(for_train) \n    kmeanModel.fit(for_train)     \n      \n    distortions.append(sum(np.min(cdist(for_train, kmeanModel.cluster_centers_, \n                      'euclidean'),axis=1)) \/ for_train.shape[0]) \n    inertias.append(kmeanModel.inertia_) \n  \n    mapping1[k] = sum(np.min(cdist(for_train, kmeanModel.cluster_centers_, \n                 'euclidean'),axis=1)) \/ for_train.shape[0] \n    mapping2[k] = kmeanModel.inertia_ ","8ca1f46f":"for key,val in mapping1.items(): \n    print(str(key)+' : '+str(val)) ","7be11c5d":"\nplt.plot(K, distortions, 'bx-') \nplt.xlabel('Values of K') \nplt.ylabel('Distortion') \nplt.title('The Elbow Method using Distortion') \nplt.show() ","ad185db3":"21 - All_whetherd roads 31 -- establishment","a72f3cdf":"Finding out the sum various states data which is already grouped.","b4336dcb":"Therefore Goverment, Private and Unrecoganized are 3 catagories of Schools based on ownership.","715b25bd":"For doing a primitive analysis we are taking out the total number of schools in various categories.","3b540b16":"Grouping the data frame on the basics of States.","1b9d64e8":"Schools_with_Computer: Total,Total_Schools,Population_school_serves","30bfb798":"Going through the metadata of the data files.","8c43d2e0":"Reading in the Data","3f03d1db":"This plot shows us the average number of people dependend per school in the particular state.","c2a3477c":"Going through the basic structure of Data.","7329bbf0":"Finding out what is the average number of persons avilable per school in various states.","9964ab1a":"Checking how Schools are classified on the basis of their Ownership.","b2078510":"***Importing Libraries***"}}