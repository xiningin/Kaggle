{"cell_type":{"bb629937":"code","676059eb":"code","f7be01e5":"code","28ee2bb8":"code","57f24cdf":"code","9b6d3ab7":"code","5ecb25c8":"code","02788d4b":"code","1efe2016":"code","3162ed46":"code","a922b469":"code","90e46058":"code","e5f4fe0d":"code","f767b758":"code","724fec95":"code","4958876a":"code","78373a7f":"code","95f85c5d":"code","32013dcf":"code","0d09795b":"code","9761e3b6":"markdown","41869e05":"markdown","9de61a7f":"markdown","0b169d88":"markdown","1416e01a":"markdown","c0cb3c95":"markdown","ec060833":"markdown","1db35f3c":"markdown","c3fbad35":"markdown","e708cda1":"markdown","5c938c97":"markdown","f5d9ecd2":"markdown","7953229d":"markdown","6c6aec71":"markdown","eefb97a4":"markdown","8410b2aa":"markdown","12ec75fb":"markdown"},"source":{"bb629937":"import numpy as np \nimport pandas as pd \nimport sklearn.utils as skutils\nimport sklearn.model_selection as skmodelsel\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D","676059eb":"df = pd.read_csv('..\/input\/CylinderVolume.csv')   #Training Dataset\ndf = skutils.shuffle(df)\ndfTrain, dfValid = skmodelsel.train_test_split(df, test_size=0.2)\ndfTrain.head()","f7be01e5":"dfTrain.plot(x='radius',y='volume',kind='scatter')","28ee2bb8":"dfTrain.plot(x='height',y='volume',kind='scatter')","57f24cdf":"#%matplotlib notebook\nplt3D = plt.figure().gca(projection='3d')\nplt3D.scatter(dfTrain['radius'], dfTrain['height'], dfTrain['volume'])\nplt3D.set_xlabel('radius')\nplt3D.set_ylabel('height')\nplt3D.set_zlabel('volume')\nplt.show()","9b6d3ab7":"def extractFeatures(df):\n    df_Features=df.loc[:,['radius','height']]\n    df_Label=df.loc[:,['volume']]\n    X=df_Features.values\n    Y=df_Label.values\n    return X,Y","5ecb25c8":"X,Y=extractFeatures(dfTrain)","02788d4b":"SMean=np.min(X,axis=0)    #using Min-Max Normalization\nSDev=np.max(X,axis=0)\ndef NormalizeInput(X,SMean,SDev):   \n    XNorm=(X-SMean)\/SDev\n    return XNorm","1efe2016":"XNorm=NormalizeInput(X,SMean,SDev)","3162ed46":"def mapFeature(X,degree):\n    \n    sz=X.shape[1]\n    if (sz==2):\n        sz=(degree+1)*(degree+2)\/2\n        sz=int(sz)\n    else:\n         sz=degree+1\n    out=np.ones((X.shape[0],sz))     #Adding Bias W0\n\n    sz=X.shape[1]\n    if (sz==2):\n        X1=X[:, 0:1]\n        X2=X[:, 1:2]\n        col=1\n        for i in range(1,degree+1):        \n            for j in range(0,i+1):\n                out[:,col:col+1]= np.multiply(np.power(X1,i-j),np.power(X2,j))    \n                col+=1\n        return out\n    else:\n        for i in range(1,degree+1):        \n            out[:,i:i+1]= np.power(X,i)\n    \n    return out","a922b469":"degree=3\ninputX=mapFeature(XNorm,degree)  ","90e46058":"batchSize=len(Y)         #no of Examples\niterations = 10000\nalpha = 1000000000\nbeta1=0.99\nbeta2=0.999\nlearningDecayRate=0.9998\nepsilon=0.0000000001\nfeatureCount=inputX.shape[1] \nweights=np.zeros((featureCount, 1)) #initialize Weight Paramters\nvDW=np.zeros((featureCount, 1))\nsDW=np.zeros((featureCount, 1))\nlossList=np.zeros((iterations,1),dtype=float)  #for plotting loss curve","e5f4fe0d":"\nfor k in range(iterations):\n    #nth iteration\n    t=k+1\n    \n    #Hypothesis\n    hypothesis=np.matmul( inputX,weights)           \n    \n    #Loss\n    loss=hypothesis-Y  \n    \n    \n    #derivative\n    dW=np.matmul(inputX.T,loss)  #Derivative\n   \n    #learning Rate decrease as training progresses \n    alpha=alpha*learningDecayRate\n    \n    #gradient Update\n    vDW = (beta1) *vDW+ (1-beta1) *dW        #Momentum  \n    sDW = (beta2) *sDW+ (1-beta2) *(dW**2)   #RMSProp\n    \n    vDWc =vDW\/(1-beta1**t)\n    sDWc =sDW\/(1-beta2**t)\n    \n    #weights=weights - (alpha\/batchSize)*vDW     #Momentum   \n    #weights=weights - (alpha\/batchSize)*dW\/np.sqrt(csDW+epsilon)     #RMSProp \n    weights=weights - (alpha\/batchSize)*(vDWc\/(np.sqrt(sDWc)+epsilon)) #Adam          \n    \n    \n    #Compute Loss for Plotting\n    newLoss=np.matmul( inputX,weights)-Y\n    newLossSqr=np.multiply(newLoss,newLoss)\n    lossList[k]=(1.0\/(2.0*batchSize))* np.sum(newLossSqr)\n\nprint(\"{0:.15f}\".format(lossList[iterations-1][0]))","f767b758":"plt.plot(lossList[9000:10000],color='r')\n","724fec95":"def predict(X,weights,SMean,SDev,degree):\n    XNorm=NormalizeInput(X,SMean,SDev)\n    inputX=mapFeature(XNorm,degree)\n    PY=np.matmul(inputX, weights)\n    return PY\n","4958876a":"def getRMSE(aY,pY):\n    Error=aY- pY\n    ErrorSqr=Error**2\n    MSE=ErrorSqr.mean()\n    RMSE=np.sqrt(MSE)\n    return RMSE","78373a7f":"pY=predict(X, weights,SMean,SDev,degree)  # Predict with bias feature added\nprint(\"{0:.15f}\".format(getRMSE(Y, pY)))","95f85c5d":"vX,vY=extractFeatures(dfValid)\npY=predict(vX, weights,SMean,SDev,degree)  # Predict with bias feature added\nprint(\"{0:.15f}\".format(getRMSE(vY, pY)))","32013dcf":"radius=189\nheight=177\npi=3.14159265358979   #Same as Excel Function correct upto 15 decimal places\nVolume=pi*radius**2*height\nprint(\"{0:.10f}\".format(Volume))","0d09795b":"pY=predict([[radius,height]], weights,SMean,SDev,degree)  # Predict with bias feature added\nprint(\"{0:.10f}\".format(pY[0][0]))","9761e3b6":"<h2> Model Final Verification (Try different values Manually)","41869e05":"<H1>Read Data from CSV","9de61a7f":"<h5>Normalize Input    ","0b169d88":"<h5>RMSE on Training Data","1416e01a":"<h5> Initialization","c0cb3c95":"<h1>Regression with Momentum ( RMS Prop, Adam)","ec060833":"<h1> Training","1db35f3c":"<h5>Using Polynomial Regresion of degree 3 in two variables x and y<\/h5>\n<p>\n$h(x) = w_0 + w_1 x+ w_2 y + w_3 x^2 + w_4 x y + w_5 y^2 + w_6 y^3  + w_7 x y^2 + w_8 x^2 y + w_9 x^3 $\n  \n<\/p> ","c3fbad35":"<h5> RMSE on Validation Data","e708cda1":"<h5> Gradient Descent Updates","5c938c97":"<h3>Cylinder Volume Prediction<\/h3>\n<p> As a chanllage we gernerated Training data with some radius and height using formula \n    $volume=\\pi r^2 h$   where r is radius and h is height. Now we will train using either algo and will try to predict new data. As we try to fit the data, it converages very slow and requires some momentum algorithm like RMS Prop OR Adam.","f5d9ecd2":"<h5>Add Polynomial Features","7953229d":"<h3>Gradient Descent<\/h3>\n   Normally we update gradient as\n<p>$W := W - \\alpha  DW $\n\n<h3>With Momentum<\/h3>\n    <p>$\\beta1:=0.9$\n    <p>$vDW:=\\beta1  (vDW) +(1-\\beta1) DW$\n    <p>$W := W - \\alpha  (vDW) $\n\n<h3>With RMS Prop<\/h3>\n    <p>$\\beta2:=0.99$\n    <p>$sDW:=\\beta2  (sDW) +(1-\\beta2) (Dw)^2$\n    <p>$W := W - \\alpha \\frac{DW}{\\sqrt{sDW}}  $\n <h3>With Adam<\/h3>\n     <p>$\\beta1:=0.9$\n    <p>$\\beta2:=0.99$\n     <p>$vDW:=\\beta1 (vDW) +(1-\\beta1) (DW) $\n    <p>$sDW:=\\beta2  (sDW) +(1-\\beta2) (DW)^2 $ \n     <p> Bias Correction  \n    <p>$vDWc:=\\frac{vDW}{(1-\\beta1^k)} $     where K is iteration \n    <p>$sDWc:=\\frac{sDW}{(1-\\beta2^k)} $     \n    <p>$W := W - \\alpha \\frac{vDWc}{\\sqrt{sDWc}}$\n    ","6c6aec71":"<h1> Prediction\/RMSE Evaluation","eefb97a4":"<h1>Plot Loss Curve","8410b2aa":"<h5> Visualize Data","12ec75fb":"<h1>Extract Input Feature to <b>X <\/b>and Label to <b>y<\/b>"}}