{"cell_type":{"a8a713e8":"code","baede996":"code","c9ae4793":"code","50571393":"code","9f378198":"code","c78adaa7":"code","de39ce9f":"code","cd21c074":"code","22d87756":"code","543dc4d9":"code","c09d39cb":"code","7a1de4e5":"code","8f632879":"code","c5b837d0":"code","fd4db062":"code","0d27a10a":"code","10f723e2":"code","82d0ac59":"code","957b3a3a":"code","38052c4a":"code","80e2b788":"code","4a3dd7f1":"code","8a03f992":"code","753d9cbc":"code","8f86c98c":"code","f92e839a":"code","fa11dd1a":"code","39bc2232":"code","9530a10b":"code","5feef085":"code","750096dc":"code","427190c8":"code","addc926e":"code","df93d7d4":"code","943164f1":"code","68ddc9e0":"code","e6a18daf":"code","c6584516":"code","9821007b":"code","bf19d0e9":"code","44d025c4":"code","e3187d5d":"code","284d2981":"code","392ed5cf":"code","595a40f6":"code","24fcb94a":"code","4c517764":"code","d7006093":"code","d09359ac":"code","364f1c3c":"code","bad40a2c":"code","46162f46":"code","4bf750dc":"code","282b7376":"code","7fe49fd2":"code","32f7974c":"code","058c1dbf":"code","a954e647":"code","20a1dd58":"code","1e0d9a4b":"code","b94af211":"code","c1c392e5":"code","a70f7c52":"code","4ef0bff4":"code","312b3962":"code","bd229f1c":"code","66f7403f":"code","97230cb6":"code","f0a47d07":"code","eb0cd381":"code","e20daedf":"code","aec260a6":"code","f3c79d8c":"code","1c08ef16":"code","a05701ca":"code","ed0ca046":"code","8ffe048c":"code","c8bcbd10":"code","fe92ad71":"code","042f5036":"code","4b55fe44":"code","bcd2e12b":"code","7655b657":"code","95972d7d":"code","b2c8346c":"code","2de70637":"code","1bf8e152":"code","117f82f7":"code","bf1dd67f":"code","bacceae9":"markdown","04a73da8":"markdown","54c2ee09":"markdown","15f58076":"markdown","6b560f7d":"markdown","b67c6843":"markdown","5ee3183c":"markdown","13e9671d":"markdown","167c8e49":"markdown","2b2c50bd":"markdown","51ffa2fd":"markdown","187e2486":"markdown","0dd6a00c":"markdown","9bc5bdce":"markdown","dd77ece5":"markdown","2b8ad8a9":"markdown","f0fa8b15":"markdown","49388859":"markdown","834fce41":"markdown","5b2b80c5":"markdown","b62f3c54":"markdown","87209f70":"markdown","7c191eab":"markdown","099d4f65":"markdown","03fc2435":"markdown","c875b49e":"markdown","bfb98f3f":"markdown","d85e5c62":"markdown","a295c87e":"markdown","f13b0b65":"markdown","a59b3f82":"markdown","4ec0b05a":"markdown","5bffaf13":"markdown","9e157835":"markdown","8d674a3d":"markdown"},"source":{"a8a713e8":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","baede996":"import os\nimport os.path\nfrom pathlib import Path\nimport glob","c9ae4793":"from PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","50571393":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers","9f378198":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve","c78adaa7":"from keras.optimizers import RMSprop,Adam,Optimizer,Optimizer","de39ce9f":"from tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model","cd21c074":"from warnings import filterwarnings\n\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","22d87756":"Train_Data_Path = Path(\"..\/input\/urecamain\/Train\")\nTest_Data_Path = Path(\"..\/input\/urecamain\/Test\")\nValidation_Data_Path = Path(\"..\/input\/urecamain\/Vali\")","543dc4d9":"Train_JPG_Path = list(Train_Data_Path.glob(r\"*\/*.jpg\"))","c09d39cb":"Test_JPG_Path = list(Test_Data_Path.glob(r\"*\/*.jpg\"))","7a1de4e5":"Validation_JPG_Path = list(Validation_Data_Path.glob(r\"*\/*.jpg\"))","8f632879":"Train_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Train_JPG_Path))","c5b837d0":"print(\"FIRE COUNT: \", Train_JPG_Labels.count(\"Fire\"))\nprint(\"NON FIRE COUNT: \", Train_JPG_Labels.count(\"Non-Fire\"))","fd4db062":"Test_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Test_JPG_Path))","0d27a10a":"print(\"FIRE COUNT: \", Test_JPG_Labels.count(\"Fire\"))\nprint(\"NON FIRE COUNT: \", Test_JPG_Labels.count(\"Non-Fire\"))","10f723e2":"Validation_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Validation_JPG_Path))","82d0ac59":"print(\"FIRE COUNT: \", Validation_JPG_Labels.count(\"Fire\"))\nprint(\"NON FIRE COUNT: \", Validation_JPG_Labels.count(\"Non-Fire\"))","957b3a3a":"Train_JPG_Path_Series = pd.Series(Train_JPG_Path,name=\"JPG\").astype(str)\nTrain_JPG_Labels_Series = pd.Series(Train_JPG_Labels,name=\"CATEGORY\")","38052c4a":"Test_JPG_Path_Series = pd.Series(Test_JPG_Path,name=\"JPG\").astype(str)\nTest_JPG_Labels_Series = pd.Series(Test_JPG_Labels,name=\"CATEGORY\")","80e2b788":"Validation_JPG_Path_Series = pd.Series(Validation_JPG_Path,name=\"JPG\").astype(str)\nValidation_JPG_Labels_Series = pd.Series(Validation_JPG_Labels,name=\"CATEGORY\")","4a3dd7f1":"Main_Train_Data = pd.concat([Train_JPG_Path_Series,Train_JPG_Labels_Series],axis=1)","8a03f992":"print(Main_Train_Data.head(-1))","753d9cbc":"Main_Train_Data[\"CATEGORY\"].replace({\"Non-Fire\":\"No_Fire\"},inplace=True)","8f86c98c":"print(Main_Train_Data.head(-1))","f92e839a":"Main_Test_Data = pd.concat([Test_JPG_Path_Series,Test_JPG_Labels_Series],axis=1)","fa11dd1a":"print(Main_Test_Data.head(-1))","39bc2232":"Main_Test_Data[\"CATEGORY\"].replace({\"Non-Fire\":\"No_Fire\"},inplace=True)","9530a10b":"print(Main_Test_Data.head(-1))","5feef085":"Main_Validation_Data = pd.concat([Validation_JPG_Path_Series,Validation_JPG_Labels_Series],axis=1)","750096dc":"print(Main_Validation_Data.head(-1))","427190c8":"Main_Validation_Data[\"CATEGORY\"].replace({\"Non-Fire\":\"No_Fire\"},inplace=True)","addc926e":"print(Main_Validation_Data.head(-1))","df93d7d4":"Main_Train_Data = Main_Train_Data.sample(frac=1).reset_index(drop=True)\nMain_Test_Data = Main_Test_Data.sample(frac=1).reset_index(drop=True)\nMain_Validation_Data = Main_Validation_Data.sample(frac=1).reset_index(drop=True)","943164f1":"print(Main_Train_Data.head(-1))\nprint(\"---\"*20)\nprint(Main_Test_Data.head(-1))\nprint(\"---\"*20)\nprint(Main_Validation_Data.head(-1))","68ddc9e0":"plt.style.use(\"dark_background\")","e6a18daf":"sns.countplot(Main_Train_Data[\"CATEGORY\"])\nplt.show()","c6584516":"sns.countplot(Main_Test_Data[\"CATEGORY\"])\nplt.show()","9821007b":"sns.countplot(Main_Validation_Data[\"CATEGORY\"])\nplt.show()","bf19d0e9":"Main_Train_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","44d025c4":"Main_Test_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","e3187d5d":"Main_Validation_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","284d2981":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Train_Data[\"JPG\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Train_Data[\"CATEGORY\"][0])","392ed5cf":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Train_Data[\"JPG\"][1888])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Train_Data[\"CATEGORY\"][1888])","595a40f6":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Test_Data[\"JPG\"][1005])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Test_Data[\"CATEGORY\"][1005])","24fcb94a":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Validation_Data[\"JPG\"][26])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Validation_Data[\"CATEGORY\"][26])","4c517764":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Train_Data[\"JPG\"][i]))\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","d7006093":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Test_Data[\"JPG\"][i]))\n    ax.set_title(Main_Test_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","d09359ac":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Validation_Data[\"JPG\"][i]))\n    ax.set_title(Main_Validation_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","364f1c3c":"Train_Generator = ImageDataGenerator(rescale=1.\/255,\n                                    zoom_range=0.7,\n                                    shear_range=0.7,\n                                    rotation_range=50,\n                                    horizontal_flip=True,\n                                     brightness_range=[0.2,0.9],\n                                     vertical_flip=True)","bad40a2c":"Test_Val_Generator = ImageDataGenerator(rescale=1.\/255,validation_split=0.5)","46162f46":"example_Image = Main_Train_Data[\"JPG\"][30]\nLoad_Image = image.load_img(example_Image,target_size=(210,210))\nArray_Image = image.img_to_array(Load_Image)\nArray_Image = Array_Image.reshape((1,) + Array_Image.shape)","4bf750dc":"i = 0\nfor batch in Train_Generator.flow(Array_Image,batch_size=5):\n    plt.figure(i)\n    Image = plt.imshow(image.img_to_array(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\nplt.show()","282b7376":"Train_IMG_Set = Train_Generator.flow_from_dataframe(dataframe=Main_Train_Data,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   color_mode=\"grayscale\",\n                                                   class_mode=\"categorical\",\n                                                   subset=\"training\",\n                                                   seed=42,\n                                                   batch_size=16)","7fe49fd2":"Test_IMG_Set = Test_Val_Generator.flow_from_dataframe(dataframe=Main_Test_Data,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   color_mode=\"grayscale\",\n                                                   class_mode=\"categorical\",\n                                                   seed=42,\n                                                   batch_size=16)","32f7974c":"Validation_IMG_Set = Test_Val_Generator.flow_from_dataframe(dataframe=Main_Validation_Data,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   color_mode=\"grayscale\",\n                                                   class_mode=\"categorical\",\n                                                      subset=\"validation\",\n                                                   seed=42,\n                                                   batch_size=16)","058c1dbf":"for data_batch,label_batch in Train_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","a954e647":"for data_batch,label_batch in Validation_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","20a1dd58":"for data_batch,label_batch in Test_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","1e0d9a4b":"print(\"TRAIN: \")\nprint(Train_IMG_Set.class_indices)\nprint(Train_IMG_Set.classes[0:5])\nprint(Train_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_IMG_Set.class_indices)\nprint(Validation_IMG_Set.classes[0:5])\nprint(Validation_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")\nprint(Test_IMG_Set.class_indices)\nprint(Test_IMG_Set.classes[0:5])\nprint(Test_IMG_Set.image_shape)","b94af211":"Call_Back_Early = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n                                                   patience=5,\n                                                   mode=\"min\")","c1c392e5":"Call_Back_Check = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                     save_best_only=True,\n                                                     filepath=\".\/my_model\")","a70f7c52":"%mkdir my_model","4ef0bff4":"Model_One = Sequential()\n\n#\nModel_One.add(Conv2D(32,(3,3),activation=\"relu\",\n                 input_shape=(256,256,1)))\nModel_One.add(MaxPooling2D((2,2)))\nModel_One.add(Dropout(0.2))\n#\nModel_One.add(Conv2D(64,(3,3),activation=\"relu\",\n                 strides=(2,2)))\nModel_One.add(MaxPooling2D((2,2)))\nModel_One.add(Dropout(0.2))\n#\nModel_One.add(Conv2D(128,(3,3),activation=\"relu\",\n                 strides=(2,2)))\nModel_One.add(MaxPooling2D((2,2)))\nModel_One.add(Dropout(0.2))\n#\nModel_One.add(Conv2D(128,(3,3),activation=\"relu\",\n                 strides=(2,2)))\nModel_One.add(MaxPooling2D((2,2)))\nModel_One.add(Dropout(0.2))\n\n#\nModel_One.add(Flatten())\nModel_One.add(Dropout(0.5))\nModel_One.add(Dense(512,activation=\"relu\"))\nModel_One.add(Dense(2,activation=\"softmax\"))","312b3962":"Model_One.compile(optimizer=RMSprop(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","bd229f1c":"CNN_Model_One = Model_One.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                            callbacks=[Call_Back_Check,Call_Back_Early],\n                      epochs=50)","66f7403f":"Model_Results = Model_One.evaluate(Test_IMG_Set,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","97230cb6":"plt.plot(CNN_Model_One.history[\"accuracy\"])\nplt.plot(CNN_Model_One.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","f0a47d07":"Dict_Summary_One = pd.DataFrame(CNN_Model_One.history)\nDict_Summary_One.plot()","eb0cd381":"Prediction_One = Model_One.predict(Test_IMG_Set)\nPrediction_One = Prediction_One.argmax(axis=-1)","e20daedf":"print(Prediction_One)","aec260a6":"Model_Two = Sequential()\n\nModel_Two.add(Conv2D(12,(3,3),activation=\"relu\",\n                 input_shape=(256,256,1)))\nModel_Two.add(BatchNormalization())\nModel_Two.add(MaxPooling2D((2,2)))\n\n#\nModel_Two.add(Conv2D(24,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel_Two.add(Dropout(0.2))\nModel_Two.add(MaxPooling2D((2,2)))\n\n\n#\nModel_Two.add(TimeDistributed(Flatten()))\nModel_Two.add(Bidirectional(LSTM(32,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\nModel_Two.add(Bidirectional(GRU(32,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\n\n#\nModel_Two.add(Flatten())\nModel_Two.add(Dense(512,activation=\"relu\"))\nModel_Two.add(Dropout(0.5))\nModel_Two.add(Dense(256,activation=\"relu\"))\nModel_Two.add(Dropout(0.5))\nModel_Two.add(Dense(2,activation=\"softmax\"))","f3c79d8c":"Model_Two.compile(optimizer=RMSprop(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","1c08ef16":"CNN_Model_Two = Model_Two.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                            callbacks=[Call_Back_Check,Call_Back_Early],\n                      epochs=50)","a05701ca":"Model_Results_Two = Model_Two.evaluate(Test_IMG_Set,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results_Two[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results_Two[1])","ed0ca046":"plt.plot(CNN_Model_Two.history[\"accuracy\"])\nplt.plot(CNN_Model_Two.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","8ffe048c":"Dict_Summary_Two = pd.DataFrame(CNN_Model_Two.history)\nDict_Summary_Two.plot()","c8bcbd10":"Prediction_Two = Model_Two.predict(Test_IMG_Set)\nPrediction_Two = Prediction_Two.argmax(axis=-1)","fe92ad71":"print(Prediction_Two)","042f5036":"Model_Three = tf.keras.models.Sequential([\n  # inputs \n  tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n  tf.keras.layers.Flatten(input_shape=(256,)),\n  # hiddens layers\n    \n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  # output layer\n  tf.keras.layers.Dense(2,activation=\"softmax\")\n])","4b55fe44":"Model_Three.compile(optimizer=RMSprop(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","bcd2e12b":"CNN_Model_Three = Model_Three.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                            callbacks=[Call_Back_Check,Call_Back_Early],\n                      epochs=50)","7655b657":"Model_Prediction_Three = Model_Three.evaluate(Test_IMG_Set,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Prediction_Three[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Prediction_Three[1])","95972d7d":"plt.plot(CNN_Model_Three.history[\"accuracy\"])\nplt.plot(CNN_Model_Three.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","b2c8346c":"Dict_Summary_Three = pd.DataFrame(CNN_Model_Three.history)\nDict_Summary_Three.plot()","2de70637":"Prediction_Three = Model_Three.predict(Test_IMG_Set)\nPrediction_Three = Prediction_Three.argmax(axis=-1)","1bf8e152":"print(Prediction_Three)","117f82f7":"FINAL_PRED = 0.33 * (Prediction_One + Prediction_Two + Prediction_Three)","bf1dd67f":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Test_Data[\"JPG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{FINAL_PRED[i]}\")\nplt.tight_layout()\nplt.show()","bacceae9":"# SHUFFLING","04a73da8":"# CALLBACK","54c2ee09":"#### IMAGE GENERATOR","15f58076":"# APPLYING GENERATOR AND TRANSFORMATION TO TENSOR","6b560f7d":"# PACKAGES AND LIBRARIES","b67c6843":"# CNN - RCNN","5ee3183c":"# CNN WITH Conv2D","13e9671d":"#### VALIDATION","167c8e49":"# FULLY-CONNECTED","2b2c50bd":"#### TRAIN-TEST-VALIDATION PATH","51ffa2fd":"#### JPG PATH","187e2486":"#### PATH PROCESS","0dd6a00c":"# COMMUNITY METHODS","9bc5bdce":"# DETERMINATION TRAIN AND TEST DATA","dd77ece5":"#### TEST","2b8ad8a9":"#### TRAIN","f0fa8b15":"#### TRAIN","49388859":"#### MODEL LAYERS","834fce41":"#### GENERAL","5b2b80c5":"#### VALIDATION","b62f3c54":"# TRANSFORMATION TO DATAFRAME STRUCTURE","87209f70":"#### IMAGE PROCESS","7c191eab":"#### ACCURACY CONTROL","099d4f65":"# VISUALIZATION","03fc2435":"#### TEST","c875b49e":"#### IMAGE SET CHECKING","bfb98f3f":"# PATH & LABELS","d85e5c62":"#### Context\n* The title of the research paper is \"Detection of fire using surveillance camera footage\"\n\n#### Content\n* This dataset contains 10,003 images that have been classified into 3 different sets (Training, Validation, and Test). The ratio in which they have been spilt is 3 : 1 : 1. Out of the 5003 images that contain fire, 2,567 images have been synthetically generated by superimposing images of fire on videos of roads in Singapore","a295c87e":"#### IGNORING WARNINGS","f13b0b65":"# HISTORY","a59b3f82":"#### JPG LABELS","4ec0b05a":"#### SCALER & TRANSFORMATION","5bffaf13":"# TRANSFORMATION TO SERIES STRUCTURE","9e157835":"#### HOW GENERATOR APPLIED IMAGE LOOK LIKE","8d674a3d":"#### OPTIMIZER"}}