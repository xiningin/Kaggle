{"cell_type":{"3c34a6d1":"code","79b584b4":"code","4e00c1fc":"code","18233fa8":"code","d2f3ed8a":"code","f20f4790":"code","c5c6b5ca":"code","955116f2":"code","e75e731f":"code","d82f6421":"code","af31df3e":"code","575d6882":"code","e651dc1c":"code","4f8ad2a4":"code","b3cc316c":"code","596e7e60":"code","67afd4a0":"code","653d54b3":"code","94434fb9":"code","708831ed":"code","0f2d509b":"code","82a110e8":"code","5d7c566f":"code","d2d54cde":"code","072a218a":"code","550255c1":"code","6863171a":"code","7d7daa4d":"code","8239473c":"code","92edffb6":"code","67f328ef":"code","6c7931c9":"code","ed5b0470":"code","92f58885":"code","90565d4b":"code","4c772f45":"code","638a93a5":"markdown","8829d545":"markdown","6268cfc6":"markdown","b70914c2":"markdown","b2192c9c":"markdown","6ccfb86d":"markdown","a9c4e005":"markdown"},"source":{"3c34a6d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","79b584b4":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import neural_network\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport missingno as msno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas import Series, DataFrame\nimport lightgbm as lgb\n#import optuna.integration.lightgbm as lgb","4e00c1fc":"sample_submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')","18233fa8":"df_train = pd.DataFrame(train)\ndf_test = pd.DataFrame(test)","d2f3ed8a":"df_all = pd.concat([df_train.drop(columns='Survived'),df_test],ignore_index=True)","f20f4790":"df_all","c5c6b5ca":"df_all.info()","955116f2":"# Search for missing data\n\nmsno.matrix(df=df_all, figsize=(20,14), color=(0,.3,.3))","e75e731f":"Embarked2 = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == \"S\":\n        Embarked2.append(1)\n    elif df_all[\"Embarked\"][i] == \"C\":\n        Embarked2.append(2)\n    elif df_all[\"Embarked\"][i] == \"Q\":\n        Embarked2.append(3)\n    else:\n        Embarked2.append(4)\ndf_all = df_all.drop(columns=\"Embarked\")\ndf_all[\"Embarked\"] = Embarked2","d82f6421":"df_all[\"FamilySize\"] = df_all[\"SibSp\"] + df_all[\"Parch\"] + 1","af31df3e":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"FamilySize\"][i] == 1:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"isAlone\"] = ary","575d6882":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"FamilySize\"][i] == 2:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"isPair\"] = ary","e651dc1c":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == 1:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"English\"] = ary","4f8ad2a4":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == 2:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"French\"] = ary","b3cc316c":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == 3:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"Irish\"] = ary","596e7e60":"# String label to categorical values\n\nfor i in range(df_all.shape[1]):\n    if df_all.iloc[:,i].dtypes == object:\n        lbl = LabelEncoder()\n        lbl.fit(list(df_all.iloc[:,i].values))\n        df_all.iloc[:,i] = lbl.transform(list(df_all.iloc[:,i].values))","67afd4a0":"df_all","653d54b3":"df_all.info()","94434fb9":"# Missing data (Age, Fare) fill in median\nfor column in df_all.columns:\n    df_all[column] = df_all[column].fillna(df_all[column].median())","708831ed":"df_all","0f2d509b":"df_all.info()","82a110e8":"df_train = pd.merge(df_all.iloc[df_train.index[0]:df_train.index[-1]+1],df_train['Survived'],left_index=True,right_index=True)\ndf_test = df_all.iloc[df_train.index[-1]+1:]","5d7c566f":"df_train_corr = df_train.corr()\ndf_train_corr","d2d54cde":"plt.figure(figsize=(20,10))\nsns.heatmap(df_train_corr, vmin=-1, vmax=1, center=0, square=False, annot=True, cmap='coolwarm');","072a218a":"predictor_cols = []\nfor i in df_train_corr:\n    if df_train_corr[i]['Survived'] > 0.01 or df_train_corr[i]['Survived'] < -0.01:\n        innerName = df_train_corr[i].name\n        if innerName != 'Survived':\n            predictor_cols.append(innerName)\npredictor_cols","550255c1":"x = DataFrame(df_train[predictor_cols])\nt = DataFrame(df_train['Survived'])\n\nx = np.array(x)\nt = np.array(t)\nt = t.ravel()\n\nx = x.astype('float32')\nt = t.astype('int32')","6863171a":"# scaling\nfeatures = preprocessing.minmax_scale(x[:, :])\n\n# split data for train and test\nx_train, x_test, t_train, t_test = train_test_split(features, t.ravel(), test_size=0.2)","7d7daa4d":"#clf = neural_network.MLPClassifier(max_iter=200,\n#                                   hidden_layer_sizes=(100,),\n#                                   activation=\"relu\",\n#                                   solver=\"adam\",\n#                                   alpha=0.0001,\n#                                   tol=0.0001,\n#                                   verbose=True)\n#clf.fit(x_train, t_train)","8239473c":"# LightGBM\nlgb_train = lgb.Dataset(x_train, t_train)\nlgb_test = lgb.Dataset(x_test, t_test)\nparams = {\n    'objective': 'binary',\n    \"metric\":\"binary_logloss\",\n    \"learning_rate\":0.01\n}\n\ngbm = lgb.train(\n    params,\n    train_set = lgb_train,\n    valid_sets = [lgb_train, lgb_test],\n    num_boost_round = 20000,\n    early_stopping_rounds = 100,\n    verbose_eval = 100\n)","92edffb6":"#predict = clf.predict(x_test)\n#accuracy = accuracy_score(t_test, predict)\n#precision = precision_score(t_test, predict)\n#recall = recall_score(t_test, predict)\n#f1 = f1_score(t_test, predict)","67f328ef":"#accuracy","6c7931c9":"testData = DataFrame(df_test[predictor_cols])\ntestData = np.array(testData)\ntestData = testData.astype('float32')\n\n# scaling\ntestData = preprocessing.minmax_scale(testData[:, :])","ed5b0470":"#result = clf.predict(testData)","92f58885":"prediction = gbm.predict(testData, num_iteration=gbm.best_iteration)\n\nresult = np.where(prediction < 0.51, 0, 1)","90565d4b":"outputArray = []\nPassengerId = 100000\nfor i in range(len(result)):\n    predict = result[i]\n    innerArray = [PassengerId, predict]\n    outputArray.append(innerArray)\n    PassengerId += 1\ndf = pd.DataFrame(outputArray, columns=['PassengerId', 'Survived'])\ndf.to_csv(path_or_buf='submission.csv', index=False)","4c772f45":"df","638a93a5":"# 7. Make submission file","8829d545":"# 4. Extract items with high correlation coefficient","6268cfc6":"# 6. Prediction","b70914c2":"# 3. Check the correlation for each item","b2192c9c":"# 2. Preprocessing","6ccfb86d":"# 5. Modeling","a9c4e005":"# 1. Import data"}}