{"cell_type":{"f853cad7":"code","e0dcdc98":"code","1d43491f":"code","6f54c3ec":"code","f41815b6":"code","b7f83fd0":"code","5f67aff7":"code","db1da6b4":"code","773ff92b":"code","2ec339b2":"code","1b653886":"code","8e22fc4c":"code","f3dbebdb":"code","e3343d52":"code","c11d22f0":"code","fd1727ab":"code","8c983a89":"code","54a97bf3":"code","2d872183":"code","57f59e1d":"code","5d44b657":"code","1ed50f32":"code","ba3b1f51":"code","5329245f":"code","04493f9a":"code","4244fca8":"code","90d8ea05":"code","d8208cd2":"code","18b229a4":"code","73f66548":"code","cee618a3":"code","e5cf8df9":"code","02555f94":"code","a4846576":"code","b3db2928":"code","a2039d07":"code","6bf92677":"code","7443fe64":"code","b56a020c":"code","a348da0c":"code","2facce74":"code","27cba99b":"code","fc14eb59":"code","26e2a367":"code","2752ae59":"code","9073a8a8":"code","448e3e75":"code","86091f5e":"code","568aa0e5":"code","e7cc14d0":"code","9ac897e0":"code","ba4cfce9":"code","53a3f050":"code","ecc98b11":"code","9a8832ae":"markdown","26b9f3e4":"markdown","0d959540":"markdown","01b8271d":"markdown","47a47e03":"markdown","1bd0ffef":"markdown","26ce5e8f":"markdown","b23c744b":"markdown","e6468be2":"markdown","284ab8d0":"markdown","3f2286ba":"markdown","406fba37":"markdown","ffff56b9":"markdown","d903e23f":"markdown","80edd6ca":"markdown"},"source":{"f853cad7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0dcdc98":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain.head()","1d43491f":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.head()","6f54c3ec":"train.isnull()","f41815b6":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","b7f83fd0":"train.describe()","5f67aff7":"train.info()","db1da6b4":"tcopy = train.copy()\ntcopy.head()","773ff92b":"tcopy.columns","2ec339b2":"tcopy_cat = tcopy[['Survived','Pclass','Sex','Ticket','Cabin', 'Embarked']]\ntcopy_num = tcopy[['Age','SibSp','Parch','Fare']]","1b653886":"for i in tcopy_cat.columns:\n    plt.figure(figsize=((9,5)))\n    sns.barplot(tcopy_cat[i].value_counts().index,tcopy_cat[i].value_counts(),data= tcopy).set_title(i)\n    plt.show()","8e22fc4c":"for i in tcopy_num.columns:\n    plt.figure(figsize=((9,5)))\n    plt.hist(tcopy_num[i])\n    plt.title(i)\n    plt.show()","f3dbebdb":"plt.figure(figsize=((9,5)))\nsns.heatmap(tcopy_num.corr())","e3343d52":"tcopy.isnull().sum()","c11d22f0":"mean_age = tcopy.groupby('Pclass')['Age'].mean()\nmean_age","fd1727ab":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 38\n        elif Pclass == 2:\n            return 30\n        else:\n            return 25\n    else:\n        return Age","8c983a89":"train['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)","54a97bf3":"train['Age'] = train['Age'].astype(int)","2d872183":"train.info()","57f59e1d":"dummy_embarked = pd.get_dummies(train['Embarked'],prefix='Embarked_',drop_first=True,dtype=int)\ntrain = pd.concat((train.drop('Embarked',axis=1),dummy_embarked),axis=1)\ntrain.head()","5d44b657":"sex_embarked = pd.get_dummies(train['Sex'],prefix='Sex_',drop_first=True,dtype=int)\ntrain = pd.concat((train.drop('Sex',axis=1),sex_embarked),axis=1)\ntrain.head()","1ed50f32":"train = train.drop(['Name','Ticket','Cabin'],axis=1)\ntrain.head()","ba3b1f51":"train['log_fare'] = np.log(train['Fare']+1).round()\ntrain = train.drop('Fare',axis=1)\ntrain.head()","5329245f":"X = train.drop('Survived',axis=1)\ny = train['Survived']\nprint(X.shape)\ny.shape","04493f9a":"X = X.drop('PassengerId',axis=1)","4244fca8":"from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV","90d8ea05":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)","d8208cd2":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\nfrom sklearn.pipeline import Pipeline","18b229a4":"steps = [('scaler', StandardScaler()),\n        ('lr', LogisticRegression())]\npipeline = Pipeline(steps)\npipeline.fit(X_train,y_train)\ny_pred= pipeline.predict(X_test)\nprint(round(accuracy_score(y_test,y_pred)*100,2))\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","73f66548":"grid_param={'lr__C':[0.1,0.03,0.07],\n              'lr__penalty':['l1','l2',]}\ngridlr = GridSearchCV(pipeline,grid_param,cv =5,n_jobs = -1, verbose = 1)\ngridlr.fit(X_train,y_train)\nprint(gridlr.best_params_)\nprint(gridlr.best_score_)","cee618a3":"lr= gridlr.best_estimator_\nprint(confusion_matrix(y_test, lr.predict(X_test)))\nprint(classification_report(y_test, lr.predict(X_test)))\nlr_score=round(accuracy_score(y_test,lr.predict(X_test))*100,2)\nprint(lr_score)","e5cf8df9":"steps = [('scaler', StandardScaler()),\n        ('KNN', KNeighborsClassifier())]\npipeline = Pipeline(steps)\npipeline.fit(X_train,y_train)\ny_pred= pipeline.predict(X_test)\nprint(round(accuracy_score(y_test,y_pred)*100,2))\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","02555f94":"grid_param={'KNN__n_neighbors':[3,4,5,6,7]}\ngridknn = GridSearchCV(pipeline,grid_param,cv =5,n_jobs = -1, verbose = 1)\ngridknn.fit(X_train,y_train)\ny_prey=gridknn.predict(X_test)\nprint(accuracy_score(y_test,y_prey))\nprint(gridknn.best_params_)\nprint(gridknn.best_score_)","a4846576":"knn= gridknn.best_estimator_\nprint(confusion_matrix(y_test, knn.predict(X_test)))\nprint(classification_report(y_test, knn.predict(X_test)))\nknn_score=round(accuracy_score(y_test,knn.predict(X_test))*100,2)\nprint(knn_score)","b3db2928":"steps = [('scaler', StandardScaler()),\n        ('tree', DecisionTreeClassifier())]\npipeline = Pipeline(steps)\npipeline.fit(X_train,y_train)\ny_pred= pipeline.predict(X_test)\nprint(round(accuracy_score(y_test,y_pred)*100,2))\nprint(classification_report(y_test,y_pred))","a2039d07":"grid_param={'tree__criterion' : ['gini', 'entropy'],\n    'tree__max_depth' : [3, 5, 7, 10],\n    'tree__splitter' : ['best', 'random'],\n    'tree__min_samples_leaf' : [1, 2, 3, 5, 7]}\ngridtree = GridSearchCV(pipeline,grid_param,cv =5,n_jobs = -1, verbose = 1)\ngridtree.fit(X_train,y_train)\ny_pre= pipeline.predict(X_test)\nprint(accuracy_score(y_test,y_pre))\nprint(gridtree.best_params_)\nprint(gridtree.best_score_)","6bf92677":"tree= gridtree.best_estimator_\nprint(confusion_matrix(y_test, tree.predict(X_test)))\nprint(classification_report(y_test, tree.predict(X_test)))\ntree_score = round(accuracy_score(y_test,tree.predict(X_test))*100,2)\nprint(tree_score)","7443fe64":"steps = [('scaler', StandardScaler()),\n        ('GBC', GradientBoostingClassifier())]\npipeline = Pipeline(steps)\npipeline.fit(X_train,y_train)\ny_pred= pipeline.predict(X_test)\nprint(round(accuracy_score(y_test,y_pred)*100,2))\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","b56a020c":"grid_param={'GBC__criterion' : ['friedman_mse', 'mse'],\n    'GBC__max_depth' : [3, 5, 7, 10],\n    'GBC__min_samples_leaf' : [1, 2, 3, 5, 7]}\ngridgbc = GridSearchCV(pipeline,grid_param,cv =5,n_jobs = -1, verbose = 1)\ngridgbc.fit(X_train,y_train)\nprint(gridgbc.best_params_)\nprint(gridgbc.best_score_)","a348da0c":"gbc=gridgbc.best_estimator_\ngbc.fit(X_train,y_train)\ny_pre=gbc.predict(X_test)\ngbc_score = round(accuracy_score(y_test,y_pre)* 100,2)\nprint(gbc_score)\nprint(confusion_matrix(y_test,y_pre))\nprint(classification_report(y_test,y_pre))","2facce74":"model_result = pd.DataFrame({'Model' : ['Logistic Regression', 'KNeighborsClassifier', 'Decision Tree Classifier','GradientBoostingClassifier'], \n                             'Score_before tuning' : [81.56,80.45,78.21,82.12], \n                             'After_tuning':[lr_score,knn_score,tree_score,gbc_score]})\nprint(model_result.sort_values(by='After_tuning', ascending=False))","27cba99b":"test.isna().sum()","fc14eb59":"test.describe()","26e2a367":"mean_testage = test.groupby('Pclass')['Age'].mean()\nmean_testage","2752ae59":"def impute_testage(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 41\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","9073a8a8":"test['Age'] = test[['Age','Pclass']].apply(impute_testage,axis=1)\ntest['Age'] = test['Age'].astype(int)\ntest.info()","448e3e75":"test['Fare'].mean()","86091f5e":"test['Fare']= test['Fare'].fillna(36)\ntest.isna().sum()","568aa0e5":"test.head()","e7cc14d0":"test_sexdummies = pd.get_dummies(test['Sex'],drop_first=True,dtype=int)\ntest_embarkeddummies = pd.get_dummies(test['Embarked'],drop_first=True,dtype=int)\ntest = pd.concat((test,test_sexdummies,test_embarkeddummies), axis=1)","9ac897e0":"test.head()","ba4cfce9":"test = test.drop(['Name','Ticket','Cabin','Sex','Embarked'],axis=1)\ntest.head()","53a3f050":"test['log_fare'] = np.log(test['Fare']+1).round()\ntest = test.drop('Fare',axis=1)\ntest.head()","ecc98b11":"pid = test['PassengerId']\npredictions = gbc.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : pid, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)\nprint('Your submission was successfully saved!')","9a8832ae":"### **Splitting Data**","26b9f3e4":"### **Feature Engineerinng on Test Data**","0d959540":"### **Creating submission file**","01b8271d":"##  **Contents**\n* Importing libraries\n* Reading CSV files\n* Data Analysis\n* Data Visualization\n* Feature Engineering\n* Splitting Data\n* Comparing Models\n* Test Data\n* Feature Engineerinng on Test Data\n* Creating submission file\n","47a47e03":"### **Data Analysis**","1bd0ffef":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTSqQS6E_AcElZoHy_tUDh5xhRkeir6Hxvd7Q&usqp=CAU)","26ce5e8f":"### **Test Data**","b23c744b":"### **Comparing Models**","e6468be2":"### **Feature Engineering**","284ab8d0":"#### **GradientBoostingClassifier gives the best result of 82.68%**","3f2286ba":"# **Titanic Survival Predictions**","406fba37":"### **Importing libraries**","ffff56b9":"### **Data Visualization**","d903e23f":"### **Columns meaning**\n\n**pclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower**\n\n**age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5**\n\n**sibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)**\n\n**parch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.**","80edd6ca":"### **Reading CSV files**"}}