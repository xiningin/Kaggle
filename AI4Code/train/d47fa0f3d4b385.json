{"cell_type":{"3d2734ac":"code","9d93ef5f":"code","5d1713a1":"code","1cf459c8":"code","2a2d6a34":"code","d659346a":"code","59a9baa6":"code","eb323795":"code","d0836ded":"code","e8caecfc":"code","9b573349":"code","3609e68b":"code","16d08ca3":"code","c485fb8f":"code","6c4e431a":"code","75c72edf":"code","6c89ca14":"code","1fac13ed":"code","89b33c83":"code","caab0e76":"code","926748b7":"code","ec8152ed":"code","bac36fbf":"code","f6b6ecf1":"code","fc1a2383":"code","2eda4bc1":"code","40bafd6d":"code","cae50b7e":"code","d4106364":"code","67fefade":"code","6186a2f2":"code","80082649":"code","2ea829a3":"code","f71c4956":"code","e29dc522":"code","9cf55650":"code","5097cf97":"code","4b4e48a1":"code","7613fa70":"code","48abddb4":"code","f6c2407c":"code","ae44b95d":"code","2a7ef811":"code","3e4f0a97":"code","32cc701d":"code","35192de5":"code","49722a1a":"code","9b0032e9":"code","8f042e3f":"code","85d1fcb6":"code","2717c00b":"code","4fc43d08":"code","9cd6fe89":"code","4c72994f":"markdown","ab4cdcc5":"markdown","ba75331e":"markdown","f9cf1973":"markdown"},"source":{"3d2734ac":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nplt.rcParams['figure.figsize']=[10,6]","9d93ef5f":"df=pd.read_csv('..\/input\/playstore-analysis\/googleplaystore.csv')\ndf.head(4)","5d1713a1":"df.drop(['Current Ver','Android Ver'],axis=1,inplace=True)","1cf459c8":"df.isnull().sum()","2a2d6a34":"#Since Rating is the target feature, we can't replace NaN values with Mean\/Median values. \n#Therefore, we drop all all rows that have Null values\ndf.dropna(inplace=True)\ndf.reset_index(inplace=True)\ndf.isnull().sum()","d659346a":"def getnumber(s):\n    number=\"\"\n    for i in s:\n        if i>='0' and i<='9':\n            number+=i\n        if i=='.':\n            number+=i\n    if number==\"\":\n        print('No digits')\n    else:\n        return float(number)\n## This function returns all the digits from a string ","59a9baa6":"def getalphabet(s):\n    alphabet=\"\"\n    for i in s:\n        if i>='a' and i<='z':\n            alphabet+=i\n        elif i>='A' and i<='Z':\n            alphabet+=i\n    return alphabet\n## This function returns all the alphabets from a string ","eb323795":"size_index = df.columns.get_loc('Size')\ninstalls_index = df.columns.get_loc('Installs')\nrows,columns=df.shape\nall_sizes=[]\nfor i in range(0,rows):\n    all_sizes.append(getalphabet(df.iloc[i,size_index]))\nprint(set(all_sizes))","d0836ded":"## So we understand that few apps have sizes 'Varieswithdevice'.Hence, we check if such values have any integers associated with it.\nvwd_index=[]\nfor i in range(0,len(all_sizes)):\n    if all_sizes[i]=='Varieswithdevice':\n        vwd_index.append(i)\nfor i in vwd_index:\n    print(df.iloc[i,size_index])\nprint('Number of missing\/ambiguous size values:',len(vwd_index))","e8caecfc":"## 1637 of 9366 values don't have size data. Initially, we remove the rows with missing sizes.\n## After analysis, if we find that there's not a strong correlation between size and ratings, we remove the size column altogether\ndata=df.copy()\nfor i in vwd_index:\n    data.drop(index=i,inplace=True)","9b573349":"rows,columns=data.shape\nall_sizes=[]\nfor i in range(0,rows):\n    all_sizes.append(getalphabet(data.iloc[i,size_index]))\nprint(set(all_sizes))","3609e68b":"## Now we have all the sizes in either KB or MB. We now convert MB to KB and everything from String to Int.\nfor i in range(0,rows):\n    if getalphabet(data.iloc[i,size_index])=='M':\n        data.iloc[i,size_index]=getnumber(data.iloc[i,size_index])*1000\n    else:\n        data.iloc[i,size_index]=getnumber(data.iloc[i,size_index])   ","16d08ca3":"for i in range(0,rows):\n    data.iloc[i,installs_index]=getnumber(data.iloc[i,installs_index])","c485fb8f":"data.drop('index',axis=1,inplace=True)","6c4e431a":"price_index = data.columns.get_loc('Price')\nfor i in range(0,rows):\n    data.iloc[i,price_index]=getnumber(data.iloc[i,price_index])","75c72edf":"print('Maximum app rating=',data['Rating'].max())\nprint('Minimum app rating=',data['Rating'].min())","6c89ca14":"data.head(4)","1fac13ed":"## Dropping values where number of installs are less than the number of reviews.\ndata.drop(data[data.Installs<data.Reviews].index,axis=0,inplace=True)","89b33c83":"## Checking if all the Free apps have price = 0\ndata[data.Type=='Free'].Price.sum()  ##The sum of prices of all the Free apps should be 0.","caab0e76":"plt.boxplot(data[data.Type!='Free'].Price,vert=False)","926748b7":"## From the BoxPlot we can definitely see that the Prices above 50$ are obvious outliers. Therefore we first remove those and then compute the quartiles of the remaining data.\ndata.drop(data[data.Price>50].index,axis=0,inplace=True)\nplt.boxplot(data[data.Type!='Free'].Price,vert=False)","ec8152ed":"#we remove records with over 10 million reviews\ndata.drop(data[data.Reviews>data['Reviews'].quantile(0.95)].index,axis=0,inplace=True)\nplt.boxplot(data.Reviews,vert=False)","bac36fbf":"data['Rating'].plot.hist(bins=8,rwidth=0.99)\nplt.xlabel('App rating')\nplt.ylabel('Number of Apps')","f6b6ecf1":"## Majority of the apps have higher ratings.(most between 4.0 to 4.5)\ndata['Size'].plot.hist(bins=8,rwidth=0.99)\nplt.xlabel('App size (in KB)')\nplt.ylabel('Number of Apps')","fc1a2383":"sns.lmplot(x=\"Price\",y=\"Rating\",hue='Type',data=data,fit_reg=False)","2eda4bc1":"## Apparently,there is no strong correlation between Ratings and Price.Majority of the paid apps have a higher rating.\nsns.jointplot(x=data[data.Type=='Paid']['Price'],y=data[data.Type=='Paid']['Rating'],data=data,kind=\"kde\")","40bafd6d":"data[data.Type=='Free']['Rating'].plot.hist(bins=8) ##Checking out the trend for Free Apps","cae50b7e":"sns.jointplot(x='Size',y='Rating',data=data,kind='scatter')\n#We can conclude that the percentage of large apps having high ratings(>4) is more!","d4106364":"sns.jointplot(x='Reviews',y='Rating',data=data,kind='scatter') #Similar to the Price vs Rating graph. For higher number of reviews, the rating is always greater than 3.5","67fefade":"sns.boxplot(x=\"Content Rating\",y=\"Rating\",data=data)","6186a2f2":"sns.countplot(x='Content Rating',data=data)","80082649":"#We reduce some of the categories by clubbing similar ones together\ncategory_index=data.columns.get_loc('Category')\nrows,columns=data.shape\nfor i in range(0,rows):\n    if data.iloc[i,category_index]=='ART_AND_DESIGN' or data.iloc[i,category_index]=='BEAUTY':\n        data.iloc[i,category_index]='Art'\n    if data.iloc[i,category_index]=='BOOKS_AND_REFERENCE' or data.iloc[i,category_index]=='COMICS' or data.iloc[i,category_index]=='LIBRARIES_AND_DEMO' or data.iloc[i,category_index]=='NEWS_AND_MAGAZINES':\n        data.iloc[i,category_index]='Books'\n    if data.iloc[i,category_index]=='BUSINESS' or data.iloc[i,category_index]=='FINANCE':\n        data.iloc[i,category_index]='Money'\n    if data.iloc[i,category_index]=='SPORTS' or data.iloc[i,category_index]=='GAME':\n        data.iloc[i,category_index]='Sport\/Game'\n    if data.iloc[i,category_index]=='HEALTH_AND_FITNESS' or data.iloc[i,category_index]=='LIFESTYLE' or data.iloc[i,category_index]=='MEDICAL':\n        data.iloc[i,category_index]='Health'\n    if data.iloc[i,category_index]=='MAPS_AND_NAVIGATION' or data.iloc[i,category_index]=='TRAVEL_AND_LOCAL' or data.iloc[i,category_index]=='WEATHER':\n        data.iloc[i,category_index]='Maps\/Travel'\n    if data.iloc[i,category_index]=='SOCIAL' or data.iloc[i,category_index]=='DATING':\n        data.iloc[i,category_index]='Social'","2ea829a3":"set(data['Category'])","f71c4956":"sns.boxplot(x=\"Category\",y=\"Rating\",data=data)","e29dc522":"data.drop(['Genres','Last Updated'],axis=1,inplace=True)\ndata.head()","9cf55650":"data.drop(data[data.Installs>data['Installs'].quantile(0.95)].index,axis=0,inplace=True)\nplt.scatter(data['Reviews'],data['Installs'])","5097cf97":"data['Installs'].quantile(0.95)","4b4e48a1":"data['Reviews'].max()","7613fa70":"category_variables = pd.get_dummies(data['Category'])\ncategory_variables.drop('Art',axis=1,inplace=True)\ndata = pd.concat([data,category_variables],axis=1)\ndata.drop('Category',axis=1,inplace=True)\ndata.head()","48abddb4":"conrating_variables = pd.get_dummies(data['Content Rating'])\nconrating_variables.drop('Everyone',axis=1,inplace=True)\ndata = pd.concat([data,conrating_variables],axis=1)\ndata.drop('Content Rating',axis=1,inplace=True)\ndata.head()","f6c2407c":"X_data=data[['Reviews','Size','Installs']]\ny=data['Rating']\nX_data","ae44b95d":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(X_data)\nX=scaler.transform(X_data)\nX=pd.DataFrame(data=X,columns=['Rev','Size_new','Inst'],index=X_data.index)\nX=pd.concat([data,X],axis=1)\nX","2a7ef811":"X.drop(['Reviews','Size','Installs'],axis=1,inplace=True)\nX.head(3)","3e4f0a97":"X=X.drop('Rating',axis=1)\nX","32cc701d":"X.drop('Type',axis=1,inplace=True)\nX.drop('App',axis=1,inplace=True)","35192de5":"from sklearn.neighbors import KNeighborsRegressor\nknr=KNeighborsRegressor(20)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\nrf_random = RandomForestRegressor()\ny_test","49722a1a":"rf_random.fit(X_train,y_train)\npredictions=rf_random.predict(X_test)\npredictions","9b0032e9":"#results=pd.DataFrame(data=y_test,columns='Y_test_actual',index=range(len(y_test)))\n#results\ny_test.reset_index(drop=True,inplace=True)","8f042e3f":"y_test","85d1fcb6":"results=pd.DataFrame(columns=['Y_test_actual','Predicted'])\nresults['Y_test_actual']=y_test\nresults['Predicted']=predictions","2717c00b":"results","4fc43d08":"sns.jointplot(x='Y_test_actual',y='Predicted',data=results,kind=\"reg\")\nplt.plot([1,5],[1,5])\nplt.show()","9cd6fe89":"plt.scatter(y_test,predictions)\nplt.plot([1,5],[1,5])","4c72994f":"#### Checking for Null Value and Dropping","ab4cdcc5":"#### Defining 2 functions for Data Formatting for 'Size' and 'Installs'","ba75331e":"### Performing bivariate analysis","f9cf1973":"### Performing Univariate Analysis and Outlier detection\/removal"}}