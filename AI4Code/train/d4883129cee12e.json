{"cell_type":{"32b65078":"code","0a8e8a70":"code","b2ce3a65":"code","c3444512":"code","ad0dfa83":"code","bdb7c5b3":"code","d3c375fe":"code","9c512cd8":"code","956cfb01":"code","c280069b":"code","11683e55":"code","a3cfc56c":"code","028ac094":"code","4d6aae15":"code","854ae293":"code","febf6d90":"code","c7f275b9":"code","58632aba":"code","1e5cb45f":"code","0e1545c6":"code","97de6aee":"code","e49a5310":"code","ad52e48f":"code","c017c1c9":"code","1b0b4961":"code","d7d6c087":"code","e234f90e":"code","02584c7f":"code","834e5e1b":"code","7f8a5d71":"code","ce254ded":"code","2978d58a":"code","150b4549":"code","2e01dada":"code","18ef576f":"code","1c826d1e":"code","766fbb63":"code","e75d1276":"code","f36504f2":"code","b1b51826":"code","e5ab8f67":"code","a10b5cb4":"code","d5b8a728":"code","bc4a7a31":"code","889378bb":"markdown","dfc37ef8":"markdown","36ff2122":"markdown","7e7e07f4":"markdown","6f016b6a":"markdown","1dd8c06c":"markdown","b7a6c03e":"markdown","9ea8b136":"markdown","8553696a":"markdown","c55dc90f":"markdown","9bae0904":"markdown","7f5770ea":"markdown","f63a09d2":"markdown","0695307c":"markdown"},"source":{"32b65078":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a8e8a70":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport warnings\nimport scipy.stats\nwarnings.filterwarnings('ignore')","b2ce3a65":"#I called our dataset and visualized it with the data.head() command.\ndata = pd.read_csv(\"\/kaggle\/input\/diabates\/diabetes.csv\")\ndata.head()","c3444512":"#I decided whether it is true or false by looking at the types in the data set.\ndata.info()","ad0dfa83":"#Statistical data brought.\ndata.describe()","bdb7c5b3":"#Of the 768 patients, 500 are not sick.\ndata.shape","d3c375fe":"#I looked for empty data, lost data.\ndata.isna().sum()","9c512cd8":"#Values \u200b\u200blike glucose,bloodpressure etc. can not be 0, I have to regulate them.\ndata.eq(0).sum()  ","956cfb01":"#Missing Data Imputation Using Regression\n\n\ndef ImputeZeroValuesWithRegression(dataset):\n\n  columnsToBeImputed = ['Glucose','Insulin','SkinThickness','BMI']\n  for column in columnsToBeImputed:\n\n    test_df = dataset[dataset[column]==0]\n\n\n    y_train= dataset[column]\n    x_train= dataset.drop(column,axis=1)\n\n    X_test = test_df.drop(column, axis=1)\n\n    lr=LinearRegression()\n    lr.fit(x_train,y_train)\n    y_pred=lr.predict(X_test)\n\n\n    dataset.loc[dataset[column]==0,column] = y_pred\n\n  return dataset\ndf=ImputeZeroValuesWithRegression(dataset=data)","c280069b":"df","11683e55":"#I changed the 0 values.\n#I filled with linear regression.","a3cfc56c":"#I changed the values \u200b\u200bof the table.\n#NaN instead of 0\ndata[[\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"\n    ]]=data[[\n    \"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]].replace(0,np.NaN) \n    ","028ac094":"#filling in the missing values\ndata.fillna(data.mean(),inplace=True)\n","4d6aae15":"#I filled the empty spaces with average.\ndata.head()","854ae293":"#I changed 0 values.\n#I filled it with average.","febf6d90":"#scatter plots of features\ndef scatter(ax,axis,name,title):\n  sns.countplot(name,data=data,ax=ax[axis[0]][axis[1]])\n  ax[axis[0],axis[1]].set_title(title)\n\nf,ax=plt.subplots(4,2,figsize=(20,15))\nplt.suptitle(\"Scatter plots of features\")\n\nfeatures = (((0,0),\"Pregnancies\",\"Pregnancy chart feature\"),((0,1),\"Glucose\",\"Glucose chart feature\"),((1,0),\"BloodPressure\",\"BloodPressure chart feature\"),((1,1),\"SkinThickness\",\"SkinThickness chart feature\")\n,((2,0),\"Insulin\",\"Insulin chart feature\"),((2,1),\"BMI\",\"BMI chart feature\"),((3,0),\"DiabetesPedigreeFunction\",\"DiabetesPedigreeFunction chart feature\"),((3,1),\"Age\",\"Age\" \"chart feature\"))\n\nfor axis, name, title in features:\n  scatter(ax,axis,name,title)\n","c7f275b9":"#order of importance\nx=data[['Glucose', 'BMI', 'Age', 'Pregnancies', 'SkinThickness',\n       'Insulin', 'DiabetesPedigreeFunction']]\ny=data.iloc[:,8]\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_) \n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(20).plot(kind='bar')\nplt.show()","58632aba":"#I saw glucose affect more diabetes.","1e5cb45f":"#The measure of the relationship between them.\ndata.corr()","0e1545c6":"#I tried to show each feature among itself.\nsns.heatmap(data.corr(),annot=True)","97de6aee":"#clustering\nx=data[['Glucose', 'BMI', 'Age', 'Pregnancies', 'SkinThickness',\n       'Insulin', 'DiabetesPedigreeFunction']]\ny=data.iloc[:,8]\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.10,random_state=0)\nkmeans = KMeans(n_clusters=2, random_state=0).fit(x)\nkmeans.labels_\ncount = 0\nfor first,second in zip(y,kmeans.labels_):\n  #print(first,second)\n  if first==second:\n      count+=1\n\nprint(count)\nprint(\"Accuracy: \",(count \/ len(y)) * 100)","e49a5310":"#creation of algorithms.\nx=data[['Glucose', 'BMI', 'Age', 'Pregnancies', 'SkinThickness',\n       'Insulin', 'DiabetesPedigreeFunction']]\ny=data.iloc[:,8]","ad52e48f":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.10,random_state=0)","c017c1c9":"#log reg.\nlog_reg = LogisticRegression(random_state=1, max_iter=1000)","1b0b4961":"log_reg.fit(x_train,y_train)","d7d6c087":"y_pred=log_reg.predict(x_test)","e234f90e":"#predict for Logistic Reg.\ny_pred","02584c7f":"print(\"Logistic Regression Classifier Training Accuracy: \",log_reg.score(x_test,y_test))","834e5e1b":"#randomforest\nforest=RandomForestClassifier(n_estimators=20,criterion=\"entropy\",random_state=0)\nforest.fit(x_train,y_train)","7f8a5d71":"#predict for forest classifier.\ny_pred=forest.predict(x_test)\n","ce254ded":"y_pred","2978d58a":"print(\"Random Forest Classifier Training Accuracy: \",forest.score(x_test,y_test))","150b4549":"#knn\nKNN=KNeighborsClassifier(n_neighbors=1)\nKNN.fit(x_train,y_train)","2e01dada":"#predict for KNN.\ny_pred=KNN.predict(x_test)","18ef576f":"from sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","1c826d1e":"print(\"KNN classifier training accuracy: \",KNN.score(x_test,y_test))","766fbb63":"#performance\nKNN_predict =[0 for _ in range(len(y_test)) ]\nlog_reg_predict=[0 for _ in range(len(y_test)) ]\nforest_predict=[0 for _ in range(len(y_test)) ]","e75d1276":"model1=KNN.fit(x_train,y_train)\nmodel2=log_reg.fit(x_train,y_train)\nmodel3=forest.fit(x_train,y_train)","f36504f2":"KNN_predict=model1.predict_proba(x_test)\nlog_reg_predict=model2.predict_proba(x_test)\nforest_predict=model3.predict_proba(x_test)","b1b51826":"KNN_predict=KNN_predict[:,1]\nlog_reg_predict=log_reg_predict[:,1]\nforest_predict=forest_predict[:,1]","e5ab8f67":"KNN_auc=roc_auc_score(y_test,KNN_predict)\nlog_reg_auc=roc_auc_score(y_test,log_reg_predict)\nforest_auc=roc_auc_score(y_test,forest_predict)","a10b5cb4":"print(\"KNN:ROC AUC=%.3f\"%(KNN_auc))\nprint(\"log_reg:ROC AUC=%.3f\"%(log_reg_auc))\nprint(\"forest:ROC AUC=%.3f\"%(forest_auc))","d5b8a728":"KNN_fpr,KNN_tpr,_=roc_curve(y_test,KNN_predict)\nlog_reg_fpr,log_reg_tpr,_=roc_curve(y_test,log_reg_predict)\nforest_fpr,forest_tpr,_=roc_curve(y_test,forest_predict)","bc4a7a31":"pyplot.plot(KNN_fpr,KNN_tpr,linestyle=\"--\",label=\"KNN\")\npyplot.plot(log_reg_fpr,log_reg_tpr,marker=\".\",label=\"log_reg\")\npyplot.plot(forest_fpr,forest_tpr,marker=\".\",label=\"forest\")\npyplot.legend()\npyplot.show()","889378bb":"## Classification Task:KNN Classifier","dfc37ef8":"## Libraries","36ff2122":"## Clustering","7e7e07f4":"## Order of importance","6f016b6a":"#### This is the most efficient analysis method, as the most area is under logistic regression. \n#### I hope you like it. Please upvote the notebook. Thanks :)","1dd8c06c":"## Classification Task:Random Forest","b7a6c03e":"## Change 0 values (Linear Regression)","9ea8b136":"## Classification Task:Logistic Regression","8553696a":"## Editing Data","c55dc90f":"# Diabetes","9bae0904":"## Correlation Analysis","7f5770ea":"## scatter features","f63a09d2":"## Compare Performance","0695307c":"## Change value (mean)"}}