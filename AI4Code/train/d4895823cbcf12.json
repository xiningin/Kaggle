{"cell_type":{"0a5d0563":"code","ffc93097":"code","2fc24af2":"code","7c7c414b":"code","24330953":"code","ef734d5f":"code","a3bcbdfc":"code","621ef135":"code","b5a76847":"code","d3f7e48c":"code","406d081c":"code","c9c39f1c":"code","b7b5847f":"code","4cd4717a":"code","61673f05":"code","e1c8b783":"code","27cd666d":"code","fa9bd291":"markdown","6871c5aa":"markdown","d08ff904":"markdown","0fef4113":"markdown","dab7c8b4":"markdown","a4bd8ba2":"markdown","d5a33a8c":"markdown","402c30db":"markdown","a7269753":"markdown","7b5ee6b6":"markdown","ee5dfdd8":"markdown","3f3c4ccf":"markdown","0e419bb1":"markdown"},"source":{"0a5d0563":"!pip install imutils\n# Using shapes example from Mask R-CNN tutorial, code builds for older versions of ts and keras, so:\n#!pip install tensorflow==1.14.0  # add older version of TF\n#!pip install keras==2.2.4 # older version of Keras\n#!pip install -U scikit-image==0.16.2 # due to some warning with newer version\n\n!pip install pycocotools\n\n# import libs\nimport os\nimport re\nimport sys\nimport cv2\nimport glob \nimport time\nimport json\nimport math\nimport random\nimport imutils\nimport itertools\nimport matplotlib\nimport numpy as np # linear algebra\nimport skimage.draw\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport PIL.ImageDraw as ImageDraw\nfrom imgaug import augmenters as iaa\n\nfrom IPython.display import clear_output\n\n!git clone https:\/\/github.com\/matterport\/Mask_RCNN.git # load Mask R-CNN code implementation\n!git clone https:\/\/github.com\/rastislavkopal\/brain-tumor-segmentation.git # load manually annotated data from git repo\n    \n    \n!rm -rf brain-tumor-segmentation\/.git\/\n!rm -rf Mask_RCNN\/.git\/\n\nclear_output()","ffc93097":"# Import libraries needed for Mask R-CNN \n\n# Root directory of the project\nROOT_DIR = os.path.abspath(\".\/Mask_RCNN\")\n#!python setup.py -q install\n\n# Import Mask RCNN\nsys.path.append(ROOT_DIR)  # To find local version of the library\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log\n\n%matplotlib inline \n\n# Directory to save logs and trained model\nMODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\nDEFAULT_LOGS_DIR = 'logs' \n\n# Local path to trained weights file\nCOCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n# Download COCO trained weights from Releases if needed\nif not os.path.exists(COCO_MODEL_PATH):\n    utils.download_trained_weights(COCO_MODEL_PATH)\n\n# Import COCO config  \nsys.path.append(os.path.join(ROOT_DIR, 'samples\/coco\/'))\nimport coco\n\nplt.rcParams['figure.facecolor'] = 'white'\n\nDATASET_DIR = '.\/brain-tumor-segmentation\/brain_tumor_data\/'\n    \nclear_output()","2fc24af2":"examples = [Image.open(DATASET_DIR + 'train\/100.jpg'),Image.open(DATASET_DIR + 'train\/116.jpg'),Image.open(DATASET_DIR+'train\/221.jpg')]\nexamplesSeg = ['100.jpg20477','116.jpg10596','221.jpg19584']\n\n## print some example images from train directory\nfig = plt.figure(figsize=(10,14))\n\nfor i in range(0, len(examples)):\n    a = fig.add_subplot(1, 3, i+1)\n    imgplot = plt.imshow(examples[i])\n    a.set_title('Example '+str(i))\n\n## print segment examples for images from json annotations file\nwith open(DATASET_DIR+'train\/annotations.json') as json_file:\n    data = json.load(json_file)\n    for i in range(0,len(examplesSeg)):\n        # load regions from json file and transform them into (x,y) coordinates\n        coord = list(zip(data[examplesSeg[i]]['regions'][0]['shape_attributes']['all_points_x'],data[examplesSeg[i]]['regions'][0]['shape_attributes']['all_points_y'])) \n        image = Image.new(\"RGB\", np.asarray(examples[i]).shape[0:2])\n        draw = ImageDraw.Draw(image)\n        draw.polygon((coord), fill=200)\n        a = fig.add_subplot(2, 3, 3+i+1)\n        imgplot = plt.imshow(image)\n        a.set_title('Segment for example ' + str(i))\n","7c7c414b":"# show number of data for each dir \ndef showDataLayout():\n    values = dict()\n    for file in os.listdir(DATASET_DIR):\n        values[str(file)] = len(os.listdir('.\/brain-tumor-segmentation\/brain_tumor_data\/' + file))\n    plt.title('Number of images per folder')\n    plt.bar(range(len(values)), list(values.values()), align='center',color=[ 'green','red', 'blue'])\n    plt.xticks(range(len(values)), list(values.keys()))\n    plt.show()\n        \n    \nshowDataLayout()","24330953":"class TrainConfig(Config):\n    \"\"\"Configuration for training on the brain tumor dataset.\n    Derives from the base Config class and overrides values specific\n    to the brain tumor dataset.\n    \"\"\"\n    # Give the configuration a recognizable name\n    NAME = \"tumor_detect\"\n\n    # Train on 1 GPU and 1 images per GPU. 1 Image per CPU since the images are \n    # of bigger size. ### Batch size is 8 (GPUs * images\/GPU).\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\n    NUM_CLASSES = 1 + 1  # background + 1 class of tumor\n\n    \n    DETECTION_MIN_CONFIDENCE = 0.7   \n\n    LEARNING_RATE = 0.001\n\n    # Use a small epoch since the data is simple\n    STEPS_PER_EPOCH = 100\n\n    # use small validation steps since the epoch is small\n    VALIDATION_STEPS = 5\n    \nconfig = TrainConfig()\nconfig.display()","ef734d5f":"class TumorDataset(utils.Dataset):\n    \"\"\"Generates the brain tumors dataset and json annotations. \n    \"\"\"\n    def load_brain_tumor_images(self, dataset_dir, folder):\n        self.add_class(\"tumor\", 1, \"tumor\")\n        \n        assert folder in [\"train\", \"val\", 'test']\n        \n        dataset_dir = os.path.join(dataset_dir,folder)\n        \n        annotations = json.load(open(os.path.join(dataset_dir,'annotations.json')))\n        \n        annotations = list(annotations.values())\n        annotations = [a for a in annotations if a['regions']]\n        \n        for i in annotations:\n            polygons = [r['shape_attributes'] for r in i['regions']] # get segmented regions from json file\n            \n            image_path = os.path.join(dataset_dir, i['filename']) # load correspending image for loaded json object and save it's size\n            image = skimage.io.imread(image_path)\n            height, width = image.shape[:2]\n\n            # set jsons's 'filename' property as unique identifier since its same as original image name\n            # using only 'tumor' class\/object\n            self.add_image('tumor', image_id=i['filename'], width=width, height=height, path=image_path, polygons=polygons)\n\n            \n    def load_image(self, image_id):\n        \"\"\"Generate an image from the specs of the given image ID.\n        This function loads the image from a file with given image_id\n        \"\"\"\n        info = self.image_info[image_id]\n        fp = info['path']\n        image = imread(fp)\n        # If grayscale. Convert to RGB for consistency.\n        if len(image.shape) != 3 or image.shape[2] != 3:\n            image = np.stack((image,) * 3, -1)\n        return image\n    \n   # info = self.image_info[image_id]\n   # bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n   # image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n   # image = image * bg_color.astype(np.uint8)\n   # for shape, color, dims in info['shapes']:\n   #     image = self.draw_shape(image, shape, dims, color)\n   # return image\n    \n\n    def load_mask(self, image_id):\n        \"\"\"Return instance masks for brain image of the given ID.\n        \"\"\"\n        # If not a tumor dataset image, delegate to parent class.\n        image_info = self.image_info[image_id]\n        if image_info[\"source\"] != \"tumor\":\n            return super(self.__class__).load_mask(image_id)\n\n        # Convert polygons to a bitmap mask of shape\n        # [height, width, instance_count] \n        mask = np.zeros([image_info[\"height\"], image_info[\"width\"], len(image_info[\"polygons\"])],dtype=np.uint8)\n        for i, p in enumerate(image_info[\"polygons\"]):\n            # Get indexes of pixels inside the polygon and set them to 1\n            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n            mask[rr, cc, i] = 1\n\n        # Return mask, and array of class IDs of each instance. Since we have\n        # one class ID only, we return an array of 1s\n        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n\n    def image_reference(self, image_id):\n        \"\"\"Return the path of the image.\"\"\"\n        info = self.image_info[image_id]\n        if info[\"source\"] == \"tumor\":\n            return info[\"path\"]\n        else:\n            super(self.__class__).image_reference(self, image_id)\n            ","a3bcbdfc":"# Train dataset generator\ndataset_train = TumorDataset()\ndataset_train.load_brain_tumor_images(DATASET_DIR,'train')\ndataset_train.prepare()\n\n# Validation dataset\ndataset_val = TumorDataset()\ndataset_val.load_brain_tumor_images(DATASET_DIR,'val')\ndataset_val.prepare()\n\n# Test dataset\ndataset_test = TumorDataset()\ndataset_test.load_brain_tumor_images(DATASET_DIR,'test')\ndataset_test.prepare()","621ef135":"# Create model in training mode\nmodel = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n\n# Which weights to start with?\ninit_with = \"coco\"  # imagenet, coco, or last\n\nif init_with == \"imagenet\":\n    model.load_weights(model.get_imagenet_weights(), by_name=True)\nelif init_with == \"coco\":\n    # Load weights trained on MS COCO, but skip layers that\n    # are different due to the different number of classes\n    # See README for instructions to download the COCO weights\n    model.load_weights(COCO_MODEL_PATH, by_name=True,\n                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n                                \"mrcnn_bbox\", \"mrcnn_mask\"])\nelif init_with == \"last\":\n    # Load the last model you trained and continue training\n    model.load_weights(model.find_last(), by_name=True)","b5a76847":"# Train the head branches\n# Passing layers=\"heads\" freezes all layers except the head\n# layers. You can also pass a regular expression to select\n# which layers to train by name pattern.\nmodel.train(dataset_train, dataset_val, \n            learning_rate=config.LEARNING_RATE, \n            epochs=18, \n            layers='heads')\n\n# Save weights not needed since -> callbacks save after every epoch","d3f7e48c":"class InferenceConfig(TrainConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(mode=\"inference\", \n                          config=inference_config,\n                          model_dir=MODEL_DIR)\n\n# Get path to saved weights \/\/ specify path or load last\nmodel_path = model.find_last()\n\n# Load trained weights\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)","406d081c":"def display_image(dataset, ind):\n    plt.figure(figsize=(5,5))\n    plt.imshow(dataset.load_image(ind))\n    plt.xticks([])\n    plt.yticks([])\n    plt.title('Original Image')\n    plt.show()","c9c39f1c":"def get_ax(rows=1, cols=1, size=7):\n    \"\"\"Return a Matplotlib Axes array to be used in\n    all visualizations in the notebook. Provide a\n    central point to control graph sizes.\n    \n    Change the default size attribute to control the size\n    of rendered images\n    \"\"\"\n    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n    return ax","b7b5847f":"def predict_and_plot_differences(dataset, img_id):\n    original_image, image_meta, gt_class_id, gt_box, gt_mask =\\\n        modellib.load_image_gt(dataset, config, \n                               img_id, use_mini_mask=False)\n\n    results = model.detect([original_image], verbose=0)\n    r = results[0]\n\n    visualize.display_differences(\n        original_image,\n        gt_box, gt_class_id, gt_mask,\n        r['rois'], r['class_ids'], r['scores'], r['masks'],\n        class_names = ['tumor'], title=\"\", ax=get_ax(),\n        show_mask=True, show_box=True)","4cd4717a":"display_image(dataset_val, 0)\npredict_and_plot_differences(dataset_val, 0)","61673f05":"display_image(dataset_val, 1)\npredict_and_plot_differences(dataset_val, 1)","e1c8b783":"display_image(dataset_val, 2)\npredict_and_plot_differences(dataset_val, 2)","27cd666d":"display_image(dataset_val, 3)\npredict_and_plot_differences(dataset_val, 3)","fa9bd291":"# Training the network","6871c5aa":"# Dataset example\n* Brain images with its segment of tumor undetneath","d08ff904":"# Override the Mask R-CNN Dataset class \n**Create a synthetic dataset for our own brain tumor dataset**\n\nExtend the Dataset class and add a method to load the shapes dataset, load_shapes(), and override the following methods:\n* load_image()\n* load_mask()\n* image_reference()","0fef4113":"# MRI brain tumor segmentation\n **Using Mask R-CNN for brain tumor detection and segmentation**\n \n Following the [Mask R-CNN](https:\/\/github.com\/matterport\/Mask_RCNN\/blob\/master\/samples\/shapes\/train_shapes.ipynb) tutorial to perform configurations and set up model ","dab7c8b4":"# Create training,validation and test data generators","a4bd8ba2":"# Training configurations for our model","d5a33a8c":"# Define Model \n**We are going to use the 'Coco' weights**","402c30db":"# Import libraries and setup environment","a7269753":"**Recreate the model in inference mode**","7b5ee6b6":"# Data preprocessing \/\/ TODO\n* Background removal via finding extreme point in contours [explained here](https:\/\/www.pyimagesearch.com\/2016\/04\/11\/finding-extreme-points-in-contours-with-opencv\/)\n* Skull removal to not detect bones -> eyes, etc","ee5dfdd8":"# Results - Detection","3f3c4ccf":"# Results - Evaluation","0e419bb1":"**Number of data used for training**\n* Bar chart of dataset size for each folder train\/test\/val"}}