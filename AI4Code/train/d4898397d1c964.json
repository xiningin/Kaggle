{"cell_type":{"af595890":"code","383f09d7":"code","def8a4c9":"code","2ef83714":"code","8131770c":"code","9f5084b8":"code","7c1ffa2b":"code","40fe77af":"code","1e3d746a":"code","a21d983d":"code","5ac1bf55":"code","4afeb116":"code","eefca2a7":"code","852060e0":"code","c2468682":"code","c6120c19":"code","89a23371":"code","87189e1c":"code","3af713b7":"code","cc77c612":"code","449139b7":"code","4a637d26":"code","dae14c07":"code","6c4f438a":"code","59319ad3":"code","56b9133f":"code","14ec760f":"code","6bed9d35":"code","ea90df39":"code","ff61e9fc":"code","5959aef6":"code","04a7913d":"code","42e927d6":"code","b8a5a2a0":"code","9590b555":"code","5cadc7b7":"code","62af4c16":"code","4ceeae77":"code","536787ba":"code","1739a115":"code","454d8b09":"code","fdb24d86":"markdown","d7e5a14b":"markdown","006c5038":"markdown","4ff47b80":"markdown","a6e01bcc":"markdown","d31d7617":"markdown","75337721":"markdown","d19d9ba8":"markdown","1dc99123":"markdown","248e8541":"markdown"},"source":{"af595890":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport plotly.offline as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nplt.rc(\"font\", size=15)\nimport warnings\nwarnings.simplefilter(action='ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","383f09d7":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","def8a4c9":"test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","2ef83714":"train.head()","8131770c":"test.head()","9f5084b8":"all_data=pd.concat([train,test], axis=0)\nall_data.shape","7c1ffa2b":"all_data.describe()","40fe77af":"all_data.info()","1e3d746a":"cat_data, num_data =[],[]\nfor i in all_data.columns:\n    j = all_data.dtypes[i]\n    if j=='object':\n        cat_data.append(i)\n    else:\n        num_data.append(i)\n    \nprint(\"categorical Data:\\n{}\".format(cat_data))\nprint(\"categorical Data:\\n{}\".format(len(cat_data)))\nprint(\"Numerical Data:\\n{}\".format(num_data))\nprint(\"Numerical Data:\\n{}\".format(len(num_data)))","a21d983d":"for col in all_data.select_dtypes('O').columns:\n    print('We have {} unique value in {} column :{}'.format(len(all_data[col].unique()),col,all_data[col].unique()))\n    print('-*'*50)","5ac1bf55":"year = [feature for feature in num_data if 'Mo' in feature or 'Yr' in feature or 'Year' in feature]\nyear","4afeb116":"print('categorical columns Unique values count\\n')\nfor col in cat_data:\n    print(col,'-'*(30-len(col)),'>',len(all_data[col].unique()))","eefca2a7":"plt.figure(figsize=(20,6));\nsns.heatmap(all_data.isnull(),yticklabels=False, cbar=False, cmap='mako')","852060e0":"def percentofdata(sepdata,allData):\n    variable =[feature for feature in sepdata if allData[feature].isnull().sum()]\n    for feature in variable:\n        print(\"{}: {}%\".format(feature,np.round(allData[feature].isnull().mean(),3)))","c2468682":"print(\"--------Categorical Data %--------\")\npercentofdata(cat_data,all_data)","c6120c19":"print(\"--------Numerical Data %--------\")\npercentofdata(num_data,all_data)","89a23371":"# Fill the Miscellaneous Features with none value\nall_data.fillna({'Alley': 'None', 'Fence':'None', 'MiscFeature':'None', \n           'PoolQC':'None', 'FireplaceQu':'None', 'MasVnrType':'None'}, inplace = True)\n\n#Fill the basement(Categorical) with none value.\nall_data.fillna({'BsmtQual':'None', 'BsmtCond':'None',\n           'BsmtExposure':'None', 'BsmtFinType1':'None',\n           'BsmtFinType2':'None'},inplace=True)\n\n#Fill the Basement Columns(Numerical) with value 0 in empty field. \nBsmt_con = ['MasVnrArea','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n            'TotalBsmtSF', 'BsmtFullBath','BsmtHalfBath','BsmtFinSF1', \n            'BsmtFinSF2', 'BsmtUnfSF']\nfor Bsmt in Bsmt_con:\n    all_data[Bsmt].fillna(0, inplace=True) \n    \n#Fill the missing Garage columns(Categorical) with none value.\nall_data.fillna({'GarageType':'None','GarageCond': 'None', 'GarageQual':'None', \n           'GarageQual':'None', 'GarageFinish': 'None'}, inplace=True)\n\n#Fill the Missing Garage Columns(Numerical) with none value\nall_data.fillna({'GarageCars':0, 'GarageArea': 0}, inplace = True)\n\n#Replacing Other categorical missing variable with its mode\nall_data['MSZoning']=all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data['Electrical']=all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['Functional']=all_data['Functional'].fillna(all_data['Functional'].mode()[0])\nall_data['KitchenQual']=all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['SaleType']=all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['Utilities']=all_data['Utilities'].fillna(all_data['Utilities'].mode()[0])\nall_data['LotFrontage']=all_data['LotFrontage'].fillna(all_data['LotFrontage'].mean())\nall_data['GarageYrBlt']=all_data['GarageYrBlt'].fillna(all_data['GarageYrBlt'].median())\n\nall_data['Exterior1st'].fillna('Other' ,inplace=True)\nall_data['Exterior2nd'].fillna('Other' ,inplace=True)","87189e1c":"plt.figure(figsize=(20,6));\nsns.heatmap(all_data.isnull(),yticklabels=False, cbar=False, cmap='mako')","3af713b7":"corr =all_data.corr()\ncorr.sort_values(['SalePrice'], ascending= False, inplace=True)\nprint(corr.SalePrice)","cc77c612":"# most correlated features\ncorrplot = train.corr()\nhighCorrFeatures = corrplot.index[abs(corrplot[\"SalePrice\"])>0.5]\nplt.figure(figsize=(14,8))\ng = sns.heatmap(train[highCorrFeatures].corr(),annot=True,cmap=\"cubehelix\")","449139b7":"catNum = [feature for feature in num_data if len(all_data[feature].unique())<20 and feature not in year+['Id']]","4a637d26":"contineousNum = [feature for feature in num_data if len(all_data[feature]) and feature not in year+['Id']+catNum]\n\n","dae14c07":"plt.figure(figsize=(25, 15))\nheatmap =sns.heatmap(all_data[contineousNum].corr(), annot = True,  cmap=\"crest\")\nheatmap.set_title('Correlation Heatmap');","6c4f438a":"year_features = ['GarageYrBlt', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n\nplt.figure(figsize=(15, 8))\nsns.set(font_scale= 1.2)\nsns.set_style('whitegrid')\n\nfor i, features in enumerate(year_features):\n    plt.subplot(2, 2, i+1)\n    plt.scatter(data=train, x=features, y='SalePrice', color =\"blue\")  \n    plt.xlabel(features)\n    plt.ylabel('SalePrice')\n    \nsns.despine()","59319ad3":"plt.figure(figsize=(14, 8))\nsns.kdeplot(data=train,x=\"SalePrice\", hue =\"MoSold\", fill=True,common_norm=False, palette=\"husl\", alpha=.5, linewidth=1)","56b9133f":"Quality_features = [ 'RoofMatl', 'ExterQual', 'BsmtQual', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'GarageQual']\n\nplt.figure(figsize=(30, 20))\nsns.set(font_scale= 1.2)\nsns.set_style('darkgrid')\n\nfor i, feature in enumerate(Quality_features):\n    plt.subplot(3, 4, i+1)\n    sns.barplot(data=train, x=feature, y='SalePrice', palette=\"ch:.10\")  \n    \n    \nsns.despine()","14ec760f":"Quality_features = [ 'RoofMatl', 'ExterQual', 'BsmtQual', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'GarageQual']\n\nplt.figure(figsize=(30, 20))\nsns.set(font_scale= 1.2)\nsns.set_style('darkgrid')\n\nfor i, feature in enumerate(Quality_features):\n    plt.subplot(3, 4, i+1)\n    sns.barplot(data=train, x=feature, y='SalePrice', palette=\"ch:.10\")  \n    \n    \nsns.despine()","6bed9d35":"all_data.LotFrontage[(all_data.LotFrontage >= 160)] = 160\nall_data.LotArea[(all_data.LotArea >= 75000)] = 75000\nall_data.MasVnrArea[(all_data.MasVnrArea >= 1000)] = 1000\nall_data.BsmtFinSF1[(all_data.BsmtFinSF1 >= 2500)] = 2500\nall_data.TotalBsmtSF[(all_data.TotalBsmtSF >= 3000)] = 3000\nall_data['1stFlrSF'][(all_data['1stFlrSF'] >= 3000)] = 3000\nall_data.GrLivArea[(all_data.GrLivArea >= 3500)] = 3500\nall_data.GarageArea[(all_data.GarageArea >= 1500)] = 1500","ea90df39":"plt.figure(figsize=(10, 5))\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nsns.distplot(all_data.iloc[:len(train)]['SalePrice'] , fit=norm, color='maroon');\n(mu, sigma) = norm.fit(all_data.iloc[:len(train)]['SalePrice'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')","ff61e9fc":"plt.figure(figsize=(10, 5))\nall_data['SalePrice'] = np.log1p(all_data.iloc[:len(train)]['SalePrice'])\nsns.distplot(all_data.iloc[:len(train)]['SalePrice'] , fit=norm, color='maroon')\n(mu, sigma) = norm.fit(all_data.iloc[:len(train)]['SalePrice'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')","5959aef6":"#if it is more than 1 or -1 it is highly skewed and between 0.5 and 1 it is moderatly skewed, between 0.5 and 0 it is almost symmetric\nskewed_clm = all_data[contineousNum].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_clm= skewed_clm[skewed_clm > 0.75]\nskewed_clm= skewed_clm.index\n\nall_data[skewed_clm] = np.log1p(all_data[skewed_clm])","04a7913d":"all_data =pd.get_dummies(all_data, columns=cat_data, drop_first=True)\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\ndel all_data['TotalBsmtSF']\ndel all_data['1stFlrSF']\ndel all_data['2ndFlrSF']","42e927d6":"from sklearn.model_selection import train_test_split\nnew_train = all_data.iloc[:1460,:]\nnew_test = all_data.iloc[1460:,:]\nx = new_train.drop(['SalePrice'], axis=1)\ny = new_train['SalePrice']\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42) # 75% training and 25% test","b8a5a2a0":"from sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb","9590b555":"def print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)","5cadc7b7":"lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005])\nlasso.fit(X_train, y_train)\n\ntest_pred = lasso.predict(X_test)\ntrain_pred = lasso.predict(X_train)\n\nprint('Test set evaluation:\\n')\nprint_evaluate(y_test, test_pred)\nprint('*'*30)\nprint('Train set evaluation:\\n')\nprint_evaluate(y_train, train_pred)","62af4c16":"from yellowbrick.regressor import PredictionError\nvis = PredictionError(lasso)\nvis.fit(X_train, y_train)\nvis.score(X_train, y_train)\nvis.show()","4ceeae77":"from yellowbrick.regressor import ResidualsPlot\nvis = ResidualsPlot(lasso)\nvis.fit(X_train, y_train)\nvis.score(X_train, y_train)\nvis.show()","536787ba":"lasso.fit(X_train, y_train)\ntrain_pred = np.expm1(lasso.predict(X_train))\npred = np.expm1(lasso.predict(X_test))\nprint('Test set evaluation:\\n')\nprint_evaluate(np.expm1(y_test), pred)\nprint('*'*30)\nprint('Train set evaluation:\\n')\nprint_evaluate(np.expm1(y_train),train_pred)","1739a115":"final_test=new_test.copy()\nX = new_test.drop(['SalePrice'], axis=1)\nY = new_test[['SalePrice']]","454d8b09":"final_test['SalePrice'] = np.expm1(lasso.predict(X))\nfinal_test['Id'] = new_test['Id']\n\nlogistic_submission = final_test[['Id','SalePrice']]\n\nlogistic_submission.to_csv(\"submission.csv\", index=False)\n\nlogistic_submission.tail()","fdb24d86":"**Data Transformation**","d7e5a14b":"**Attribute**","006c5038":"### **Categorical in Number**","4ff47b80":"**outliers**","a6e01bcc":"###**Missing Value**","d31d7617":"### **Correlation**","75337721":"### Continous Number","d19d9ba8":"### **Tarin-Test Data**","1dc99123":"### **Separating DataSet**\n\nDivide the dataset into two part based on Categorical data and Numerical Data For Better Transfomation","248e8541":"### **Importing Libraries**"}}