{"cell_type":{"98812835":"code","3ab634e5":"code","cc47ae02":"code","20529128":"code","cba215ed":"code","7db26057":"code","97bc30f9":"code","b4215377":"code","91797aae":"code","04d24aec":"code","40c621c3":"code","f44dcc5a":"code","ec07e01b":"code","da8bed29":"code","86b21f3b":"code","c1cdfeb5":"code","2427042b":"code","2b9bca0e":"code","a13c440f":"code","22382e3b":"code","b7c71a79":"code","041254f8":"code","18f8299e":"code","577de14c":"code","f6f279b2":"code","7cdac819":"markdown","7cf1d24b":"markdown"},"source":{"98812835":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import Lasso, LassoCV\nimport matplotlib.image as mpimg\nfrom sklearn import preprocessing\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3ab634e5":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv') #\u8a13\u7df4\u30c7\u30fc\u30bf\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv') #\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\nhouces = pd.concat([train,test],sort=False)\n","cc47ae02":"quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\nquantitative.remove('SalePrice')\nquantitative.remove('Id')\nqualitative = [f for f in train.columns if train.dtypes[f] == 'object']","20529128":"missing = houces.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","cba215ed":"# \u307e\u305a\u6587\u5b57\u5217\u7cfb\u306e\u6b20\u640d\u5024\u3092\u4fdd\u7ba1\u3057\u3066\u3044\u304f\u3002\n# \u6570\u304c\u5c11\u306a\u304f\u3066\u3001\u7121\u8996\u3067\u304d\u305d\u3046\u306a\u3084\u3064\u3068\u3001\u6b20\u640d\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u610f\u5473\u304c\u3042\u308a\u305d\u3046\u306a\u3084\u3064\u3067\u51e6\u7406\u3092\u5909\u3048\u3066\u307f\u308b\u3002\n# \u5e73\u5747\u3067\u88dc\u5b8c\nfor col in ('LotFrontage','GarageCars'):\n    train[col]=train[col].fillna(train[col].mean())\n    test[col]=test[col].fillna(train[col].mean())\n\n# 0\u3067\u88dc\u5b8c\nfor col in ('MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','GarageYrBlt','GarageCars','GarageArea'):\n    train[col]=train[col].fillna(0)\n    test[col]=test[col].fillna(0)\n","7db26057":"# \u6700\u983b\u5024\u3067\u88dc\u5b8c\nfor col in ('MSZoning','Exterior1st','Exterior2nd','KitchenQual','SaleType','Functional'):\n    train[col]=train[col].fillna(train[col].mode()[0])\n    test[col]=test[col].fillna(test[col].mode()[0])\n\n# None\u3067\u88dc\u5b8c\nfor col in ('Alley','Utilities','MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1',\n            'BsmtFinType2','Electrical','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond',\n           'PoolQC','Fence','MiscFeature'):\n    train[col]=train[col].fillna('None')\n    test[col]=test[col].fillna('None')\n   ","97bc30f9":"corr = train.corr()\ncol = corr.nlargest(11,'SalePrice')['SalePrice'].index\n","b4215377":"plt.figure(figsize=(10,20))\n\nprice = train['SalePrice']\n\nplt.subplot(4,2,1)\nplt.scatter(price, train['OverallQual'])\n\nplt.subplot(4,2,2)\nplt.scatter(price, train['TotalBsmtSF'])\n\nplt.subplot(4,2,3)\nplt.scatter(price, train['GrLivArea'])\n\nplt.subplot(4,2,4)\nplt.scatter(price, train['GarageCars'])\n\nplt.subplot(4,2,5)\nplt.scatter(price, train['FullBath'])\n\nplt.subplot(4,2,6)\nplt.scatter(price, train['YearBuilt'])\n\nplt.subplot(4,2,7)\nplt.scatter(price, train['YearRemodAdd'])\n\nplt.show()","91797aae":"train = train.drop(train[(train['OverallQual']<5) & (train['SalePrice']>200000)].index)\ntrain = train.drop(train[(train['OverallQual']<10) & (train['SalePrice']>500000)].index)\ntrain = train.drop(train[(train['TotalBsmtSF']>4500)].index)\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\ntrain = train.drop(train[(train['YearBuilt']<2000) & (train['SalePrice']>600000)].index)\n","04d24aec":"plt.figure(figsize=(10,20))\n\nprice = train['SalePrice']\n\nplt.subplot(4,2,1)\nplt.scatter(price, train['OverallQual'])\n\nplt.subplot(4,2,2)\nplt.scatter(price, train['TotalBsmtSF'])\n\nplt.subplot(4,2,3)\nplt.scatter(price, train['GrLivArea'])\n\nplt.subplot(4,2,4)\nplt.scatter(price, train['GarageCars'])\n\nplt.subplot(4,2,5)\nplt.scatter(price, train['FullBath'])\n\nplt.subplot(4,2,6)\nplt.scatter(price, train['YearBuilt'])\n\nplt.subplot(4,2,7)\nplt.scatter(price, train['YearRemodAdd'])\n\nplt.show()","40c621c3":"# \u76ee\u7684\u5909\u6570\u304c\u6b63\u898f\u5206\u5e03\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u78ba\u8a8d\u3059\u308b\nax = sns.distplot(train['SalePrice'])\nplt.show()\n\n\nplt.figure(figsize=(20,10))\n\nprice = train['SalePrice']\n\nplt.subplot(2,4,1)\nplt.hist(train['OverallQual'])\n\nplt.subplot(2,4,2)\nplt.hist(train['TotalBsmtSF'])\n\nplt.subplot(2,4,3)\nplt.hist(train['GrLivArea'])\n\nplt.subplot(2,4,4)\nplt.hist(train['GarageCars'])\n\nplt.subplot(2,4,5)\nplt.hist(train['FullBath'])\n\nplt.subplot(2,4,6)\nplt.hist(train['YearBuilt'])\n\nplt.subplot(2,4,7)\nplt.hist(train['YearRemodAdd'])\nplt.show()","f44dcc5a":"# \u30e9\u30d9\u30eb\u30a8\u30f3\u30b3\u30fc\u30c9\nfrom sklearn.preprocessing import LabelEncoder\ntrain_id = train['Id']\ntest_id = test['Id']\ntrain = train.drop('Id',axis=1)\ntest = test.drop('Id',axis=1)\n\n\nfor i in range(train.shape[1]):\n    if train.iloc[:,i].dtypes == object:\n        lbl = LabelEncoder()\n        lbl.fit(list(train.iloc[:,i].values) + list(test.iloc[:,i].values))\n        train.iloc[:,i] = lbl.transform(list(train.iloc[:,i].values))\n        test.iloc[:,i] = lbl.transform(list(test.iloc[:,i].values))","ec07e01b":"# \u6b63\u898f\u5316\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncol_train = list(train.columns)\ncol_train_bis = list(train.columns)\n\ncol_train_bis.remove('SalePrice')\n\nmat_train = np.matrix(train)\nmat_test  = np.matrix(test)\nmat_new = np.matrix(train.drop('SalePrice',axis = 1))\nmat_y = np.array(train.SalePrice).reshape((1449,1))\n\nprepro_y = preprocessing.MinMaxScaler()\nprepro_y.fit(mat_y)\n\nprepro = preprocessing.MinMaxScaler()\nprepro.fit(mat_train)\n\nprepro_test = preprocessing.MinMaxScaler()\nprepro_test.fit(mat_new)\n\ntrain = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\ntest  = pd.DataFrame(prepro_test.transform(mat_test),columns = col_train_bis)\n\ntrain.head()","da8bed29":"# \u76ee\u7684\u5909\u6570\u304c\u6b63\u898f\u5206\u5e03\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u78ba\u8a8d\u3059\u308b\nax = sns.distplot(train['SalePrice'])\nplt.show()\n\nplt.figure(figsize=(20,10))\n\nprice = train['SalePrice']\n\nplt.subplot(2,4,1)\nplt.hist(train['OverallQual'])\n\nplt.subplot(2,4,2)\nplt.hist(train['TotalBsmtSF'])\n\nplt.subplot(2,4,3)\nplt.hist(train['GrLivArea'])\n\nplt.subplot(2,4,4)\nplt.hist(train['GarageCars'])\n\nplt.subplot(2,4,5)\nplt.hist(train['FullBath'])\n\nplt.subplot(2,4,6)\nplt.hist(train['YearBuilt'])\n\nplt.subplot(2,4,7)\nplt.hist(train['YearRemodAdd'])\nplt.show()","86b21f3b":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\n \n# \u8aac\u660e\u5909\u6570\u3068\u76ee\u7684\u5909\u6570\u306b\u5206\u5272\ny_train = train[\"SalePrice\"].values\n \n# \u5b66\u7fd2\u5bfe\u8c61\u5916\u3092\u5916\u3059\n# COLUMNS = list(train.columns)\n# COLUMNS.remove('SalePrice')\n \n# \u5b66\u7fd2\u5bfe\u51e6\u306e\u307f\u62bd\u51fa\nCOLUMNS = ['OverallQual','TotalBsmtSF','GrLivArea','GarageCars','FullBath','YearBuilt','YearRemodAdd']\n \nx_train = train[COLUMNS].values\nx_test = test[COLUMNS].values\n \nx_train.shape[1]","c1cdfeb5":"average_mae_history = [np.mean([x[i] for x in mae_all_scores]) for i in range(num_epochs)]\naverage_loss_history = [np.mean([x[i] for x in loss_all_scores]) for i in range(num_epochs)]\naverage_val_loss_history = [np.mean([x[i] for x in val_loss_all_scores]) for i in range(num_epochs)]\n\nplt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\nplt.grid(True)\nplt.title('val mean absolute error')\nplt.show()\n\nplt.plot(range(1, len(average_loss_history) + 1), average_loss_history, color = \"red\", label=\"loss\")\nplt.plot(range(1, len(average_val_loss_history) + 1), average_val_loss_history, color = \"blue\", label=\"val_loss\")\nplt.legend()\nplt.title('Loss')\nplt.grid(True)\nplt.show()","2427042b":"from keras import models\nfrom keras import layers\nimport keras.optimizers\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.layers import Dropout \nfrom keras.wrappers.scikit_learn import KerasRegressor\n#k\u5206\u5272\u4ea4\u5dee\u691c\u8a3c\n\nk = 5\nnum_val_data = len(x_train) \/\/ k#\u691c\u8a3c\u30c7\u30fc\u30bf\u6570\nnum_epochs = 50\nbatch_size = 32\n\nmae_all_scores = []\nloss_all_scores = []\nval_loss_all_scores = []\n\nfor i in range(k):\n    print(i+1, \"\u56de\u76ee\")\n\n    #\u691c\u8a3c\u30c7\u30fc\u30bf\u3068\u30e9\u30d9\u30eb\n    val_data = x_train[i*num_val_data: (i+1)*num_val_data]\n    val_targets = y_train[i*num_val_data: (i+1)*num_val_data]\n\n    #\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30e9\u30d9\u30eb\n    partial_train_data = np.concatenate([x_train[: i*num_val_data], x_train[(i+1)*num_val_data: ]], axis = 0)\n    partial_train_targets = np.concatenate([y_train[: i*num_val_data], y_train[(i+1)*num_val_data: ]], axis = 0)\n\n    model = models.Sequential()\n    model.add(layers.Dense(16, activation=\"relu\", input_shape=(len(COLUMNS), )))\n    model.add(layers.Dense(16, activation=\"relu\"))\n    model.add(layers.Dense(1))\n    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n\n   \n    history = model.fit(partial_train_data, partial_train_targets, \n                        epochs=num_epochs, \n                        batch_size=batch_size, \n                        validation_data=(val_data, val_targets), \n                        verbose = 0\n                       )\n\n    mae_history = history.history[\"val_mae\"]\n    loss_history = history.history[\"loss\"]\n    val_loss_history = history.history[\"val_loss\"]\n\n    mae_all_scores.append(mae_history)\n    loss_all_scores.append(loss_history)\n    val_loss_all_scores.append(val_loss_history)\n\n\n\nprint(\"\u7d42\u4e86\")","2b9bca0e":"ans = model.predict(x_test)\nprint(ans.shape)\n\ndf_sub_pred = pd.DataFrame(ans).rename(columns={0: \"SalePrice\"})\ndf_sub_pred = pd.concat([test_id, df_sub_pred[\"SalePrice\"]], axis=1)\n\n\ndf_sub_pred.to_csv(\"house_pred_minmax.csv\", index=False)\ndf_sub_pred.head()","a13c440f":"# \u6b63\u898f\u5316\u3057\u3066\u305f\u306e\u3092\u623b\u3059\npredictions = prepro_y.inverse_transform(np.array(ans).reshape(1459,1))\n\ndf_sub_pred = pd.DataFrame(predictions).rename(columns={0: \"SalePrice\"})\ndf_sub_pred = pd.concat([test_id, df_sub_pred[\"SalePrice\"]], axis=1)\n\ndf_sub_pred.to_csv(\"house_pred_minmax.csv\", index=False)","22382e3b":"df_sub_pred.head()","b7c71a79":"# XGBoost\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\n\ntr_x,va_x,tr_y,va_y=train_test_split(x_train,y_train,test_size=0.2)\n\ndtrain = xgb.DMatrix(tr_x,label=tr_y)\ndvalid = xgb.DMatrix(va_x,label=va_y)\ndtest = xgb.DMatrix(x_test)\n\nwatchlist=[(dtrain,'train'),(dvalid,'eval')]\n\n# max_depth \u5404\u30c4\u30ea\u30fc\u306e\u6df1\u3055\n# n_estimators \u69cb\u7bc9\u3059\u308b\u30c4\u30ea\u30fc\u306e\u6570\n# 3\u3064\u305a\u3064\u6307\u5b9a\u3057\u3066\u3001\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3057\u3066\u3082\u3089\u3046\n\nxgb_model = xgb.XGBRegressor(objective='reg:squarederror')\nreg_xgb = GridSearchCV(xgb_model,\n                   {'max_depth': [2,4,6],\n                    'n_estimators': [50,100,200]}, verbose=0)\nmodel = reg_xgb.fit(tr_x, tr_y)\n\n\n# xgb_model = xgb.XGBRegressor(objective='reg:squarederror',evals=watchlist)\n# reg_xgb = GridSearchCV(xgb_model,\n#                    {'max_depth': [2,4,6],\n#                     'n_estimators': [50,100,200]}, verbose=0)\n# model = reg_xgb.fit()\n\n","041254f8":"# va = model.predict(va_x)\n# score = log_loss(va_y,va)\n# print(score)","18f8299e":"pred = reg_xgb.predict(x_test)\n","577de14c":"predictions = prepro_y.inverse_transform(np.array(pred).reshape(1459,1))\ndf_sub_pred = pd.DataFrame(predictions).rename(columns={0: \"SalePrice\"})\ndf_sub_pred = pd.concat([test_id, df_sub_pred[\"SalePrice\"]], axis=1)\n\ndf_sub_pred.to_csv(\"xgb.csv\", index=False)","f6f279b2":"df_sub_pred.head()","7cdac819":"* \u767d\u3044\u307b\u3069\u76f8\u95a2\u304c\u3042\u308b\u306e\u3067\u3001\u3069\u3061\u3089\u304b\u4e00\u65b9\u304c\u3042\u308c\u3070\u60c5\u5831\u3068\u3057\u3066\u306f\u5341\u5206\u304b\u306a\u3041\u3063\u3066\u8003\u3048\u308b\u3002\n* SalePrice\u304c\u7d50\u5c40\u91cd\u8981\u3060\u304b\u3089(\u76ee\u7684\u5909\u6570\u3060\u304b\u3089)\u3001\u305d\u308c\u306b\u6ce8\u76ee\u3057\u3066\u307f\u3088\u3046\u304b\u306a\u3041\u3063\u3066\u8003\u3048\u308b\u3002","7cf1d24b":"\u5916\u308c\u5024\u3082\u78ba\u8a8d\u3057\u3068\u304f"}}