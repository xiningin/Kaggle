{"cell_type":{"eb090cc3":"code","d8cfc9b7":"code","e1deaed1":"code","b24992d4":"code","8c25370b":"code","f1884c96":"code","f2ea929e":"code","c99db3ba":"code","785c03c1":"code","04d84f33":"code","82beb6b8":"code","9a28764c":"code","97d0cb3d":"code","d8deb397":"code","03f8cb6f":"code","24bbdc6f":"code","c9c64e95":"code","9e13bd51":"code","ab718b43":"code","82bff571":"code","15e6529f":"code","bd79281f":"code","1211313b":"code","472a221a":"code","c52eb2ba":"code","ddcf6d48":"code","e775927e":"code","46a04acf":"code","ec4654ef":"code","9066b8b6":"code","cf306c46":"code","74f46135":"code","b43571ed":"code","1d49aa05":"code","2b1746f6":"code","b68969c0":"code","5ad3c919":"code","d9f7208a":"code","faa111d2":"code","8881cf34":"code","7ef8ed9b":"code","b42b2318":"code","5eeab1cd":"code","94ec8766":"code","4a5204a1":"code","62696636":"code","ffb7a38d":"code","7d62f231":"code","c8933036":"code","fbc11c3e":"code","2d883918":"code","fb2b4194":"code","2519f89a":"code","eaca41c1":"code","b20afc54":"code","d65f5592":"code","54a45d01":"code","487235c9":"code","aca09327":"code","106403cd":"code","ae10b8f2":"code","0d6718d6":"code","e44a90fc":"code","3f685c69":"code","d94963b6":"code","6f58c1d5":"code","8ad81c95":"code","9dd30f10":"code","19866d35":"code","e6ebbc42":"code","952f0ee1":"code","9b52e86c":"code","8bbe674a":"code","3220c070":"code","03f01c02":"code","179acda0":"code","317cd52f":"code","f5287d5f":"code","5b48c5f1":"code","0466c628":"code","038e1f57":"code","55523e88":"code","00faa97e":"code","0589cf55":"code","f916b904":"code","22320fa3":"code","98c57004":"code","e4e306c3":"code","cc215924":"code","6c9f7825":"code","1523f70a":"code","861af1bb":"code","08684800":"code","5db0201a":"code","7606c3a2":"code","d52b5671":"markdown","8fb38f00":"markdown","c185b57a":"markdown","28eac817":"markdown","602e1881":"markdown","a00fc155":"markdown","b3e97f4b":"markdown","de936a9d":"markdown","83c357c3":"markdown","aac5f96b":"markdown","fda5a962":"markdown","21efa8ef":"markdown","6cd72c61":"markdown","75dff2a7":"markdown","ebf9b62e":"markdown","0e064e24":"markdown","5d3569b5":"markdown","91c541bc":"markdown","87f086e3":"markdown","d971668e":"markdown","fb91d605":"markdown","a4e8d9c7":"markdown","c389d7ac":"markdown","c46338ff":"markdown","a0d00952":"markdown","20fd0abd":"markdown","edd7860e":"markdown","1bdbc4c2":"markdown","9105e745":"markdown","cc2687d9":"markdown","13669f1a":"markdown","78efa1cb":"markdown","9f378b7f":"markdown","5197cb6e":"markdown","68f839e3":"markdown","0ae9be55":"markdown","cca303d3":"markdown","486a1793":"markdown","ee209df0":"markdown","096b412b":"markdown","ef1592df":"markdown","accae6a7":"markdown","aea4c03f":"markdown","88d6ea40":"markdown","1f10a435":"markdown"},"source":{"eb090cc3":"import pandas as pd\nimport numpy as np","d8cfc9b7":"path = '..\/input\/bookcrossing-dataset\/Book reviews\/Book reviews\/'","e1deaed1":"# Load data\nbooks = pd.read_csv(path + 'BX_Books.csv', sep=';')\n\nbook_ratings = pd.read_csv(path + 'BX-Book-Ratings.csv', sep=';')\n\nusers = pd.read_csv(path + 'BX-Users.csv', sep=';')","b24992d4":"print(books.shape)\n\nprint(book_ratings.shape)\n\nprint(users.shape)","8c25370b":"books.head()","f1884c96":"book_ratings.head()","f2ea929e":"users.head()","c99db3ba":"books.info()","785c03c1":"users.info()","04d84f33":"book_ratings.info()","82beb6b8":"# Some names of columns look quite fancy to me, so I will rename them\n\nbooks.rename(columns = {'ISBN': 'book_id',\n                        'Book-Title': 'title',\n                        'Book-Author': 'author',\n                        'Year-Of-Publication': 'published',\n                        'Publisher': 'publisher',\n                        'Image-URL-S': 'image_small',\n                        'Image-URL-M': 'image_medium',\n                        'Image-URL-L': 'image_large'\n                       }, inplace = True)\n\nusers.rename(columns = {'User-ID': 'user_id',\n                        'Location': 'location',\n                        'Age': 'age',\n                       }, inplace = True)\n\nbook_ratings.rename(columns = {'User-ID': 'user_id',\n                               'ISBN': 'book_id',\n                               'Book-Rating': 'score',\n                       }, inplace = True)","9a28764c":"# Let's import data visualization tools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as exp ","97d0cb3d":"books.head()","d8deb397":"# Let's validate published year column\nbooks['published'].agg(['mean', 'min', 'max', 'nunique'])","03f8cb6f":"# Get ids of that books, so I can drop them from 2 tables\nzero_year = books[(books['published'] == 0) | (books['published'] > 2021)]['book_id'].values\n\nbooks = books[~books['book_id'].isin(zero_year)].copy()\nbook_ratings = book_ratings[~book_ratings['book_id'].isin(zero_year)].copy()","24bbdc6f":"books[['title', 'author', 'published', 'publisher']].nunique()","c9c64e95":"by_year_published = books.groupby('published')['book_id'].count()","9e13bd51":"byYearPlot = go.Scatter(x=by_year_published.index, y=by_year_published.values, name = \"Published books\")\n\nlayout = go.Layout(\n    title = \"Books publisher over years\",\n    xaxis_title = \"Years\",\n    yaxis_title = \"Quantity\",\n)\n\nfigure = go.Figure(data = [byYearPlot] , layout = layout)\nfigure.show() ","ab718b43":"# Top Authors by Books published\nby_author = books.groupby('author')['book_id'].count()\n\nby_author","82bff571":"# Well, before EDA I should remove this kind of errors.\nto_rem = books[books['author'].str.count(\"^[\ufffd?\u00a2\u00b2'].*\")>0]['book_id'].values\n\nbooks = books[~books['book_id'].isin(to_rem)].copy()\nbook_ratings = book_ratings[~book_ratings['book_id'].isin(to_rem)].copy()","15e6529f":"book_ratings.shape","bd79281f":"by_author = books.groupby('author')['book_id'].count()\nby_author = by_author.sort_values(ascending = False)\nby_author[:10]","1211313b":"fig = exp.bar(x=by_author.index[:30], y = by_author.values[:30], title = 'Books published by Authors', template = 'ggplot2')\n\nfig.update_xaxes(type='category', tickangle= 45)\n\nfig.show()","472a221a":"by_publisher = books.groupby('publisher')['book_id'].count()\n\nby_publisher = by_publisher.sort_values(ascending = False)","c52eb2ba":"figure = go.Figure(data = [go.Pie(labels = by_publisher.index[:10], \n                                  values = by_publisher.values,\n                                  textinfo='label+percent',\n                                  title= 'Ten publsihers with most published books.' \n                                 )])\n\nfigure.show()","ddcf6d48":"print(f'Ten most popular publishers published: {sum(by_publisher.values[:10])}, Others: {sum(by_publisher.values[11:])}')","e775927e":"books.tail()","46a04acf":"import nltk\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\n\nstopwords.words('english')\nprint(stopwords.words() [620:680])\n# Here I want to split every title of book to words and check whereas this word length greater than 3 or it's not in stop words.\n# If everything is fine, then I will add that word into array.","ec4654ef":"from collections import Counter\nresults = Counter()\nbooks['title'].str.lower().str.split().apply(results.update)","9066b8b6":"most_common = dict(results.most_common(1000))\n\nto_replace = ['(', ')', '*', '((', '))']\nown_stop_words = ['book', 'guide', 'novel']\n\ntop_words = {}\n\nfor k, v in most_common.items():\n    \n    for err in to_replace:\n        k = k.replace(err, \"\")\n        \n    if (len(k) > 3) and (k not in stopwords.words()) and (k not in own_stop_words):\n        top_words[k] = v\n        ","cf306c46":"# top_words, Sort dictionary by values\ntop_words = dict(sorted(top_words.items(), key=lambda item: item[1])[::-1][:20])","74f46135":"figure = go.Figure(data = [go.Pie(labels = list(top_words.keys()), \n                                  values = list(top_words.values()),\n                                  textinfo='label+percent',\n                                  title= 'Twenty most used words in book titles.' \n                                 )])\n\nfigure.show()","b43571ed":"# As year range I will take from 1980 to 2005. Also due to huge amount of authors I will take to 10 for each year\n\ntarget = books[(books['published'] > 1979) & (books['published'] < 2005)]\nby_authors_over_years = target.groupby(['published', 'author'])['book_id'].count()","1d49aa05":"by_authors_over_years = by_authors_over_years.reset_index()","2b1746f6":"by_author_over_years_top = pd.DataFrame(columns=['year', 'author', 'book_id'])\n\nfor year in range(1980, 2005):\n    by_author_over_years_top = pd.DataFrame(np.vstack([by_author_over_years_top, by_authors_over_years[by_authors_over_years['published'] == year].sort_values(by = 'book_id', ascending = False)[:20]]))","b68969c0":"by_author_over_years_top.rename(columns={0: 'published', 1: 'author', 2: 'count'}, inplace=True)\nby_author_over_years_top.head()","5ad3c919":"fig = exp.bar(by_author_over_years_top, x = 'published',\n              y = 'count',\n              color = 'author', title=\"Published books authors by years\",\n              template = 'ggplot2')\nfig.show()","d9f7208a":"# Let's import plotly itself + io\nimport plotly\nimport plotly.io as pio\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","faa111d2":"# This time I am getting only 5 authors for each year\nby_author_over_years_top = pd.DataFrame(columns=['year', 'author', 'book_id'])\n\nfor year in range(1980, 2005):\n    by_author_over_years_top = pd.DataFrame(np.vstack([by_author_over_years_top, by_authors_over_years[by_authors_over_years['published'] == year].sort_values(by = 'book_id', ascending = False)[:5]]))\n    \nby_author_over_years_top.rename(columns={0: 'published', 1: 'author', 2: 'count'}, inplace=True)\nby_author_over_years_top.head(6)","8881cf34":"fig = go.Figure(\n    data = [ # Here all code until updatemenus goes like base point, from where bar started before clicking 'play' button\n        go.Bar(\n        x = by_author_over_years_top[:5]['count'], y = by_author_over_years_top[:5]['author'], orientation = 'h',\n        text = by_author_over_years_top[:5]['count'], textfont = {'size': 18}, textposition = 'inside',  \n        insidetextanchor='middle', width = 0.9\n        )],\n    layout = go.Layout(\n        xaxis = dict(range = [0, 40], autorange = False, title=dict(text='Authors with most published books in year', font=dict(size=18))),\n        yaxis = dict(range= [-0.5, 5.5], autorange=False,tickfont=dict(size=14)),\n        title = dict(text = '5 Authors with most published books in 1984', font=dict(size=28), x=0.5, xanchor='center'),\n\n        updatemenus=[dict(\n            type=\"buttons\",\n            buttons=[dict(label=\"Play\",\n                          method=\"animate\",\n                          args=[None,\n                          {\"frame\": {\"duration\": 1500, \"redraw\": True},\n                          \"transition\": {\"duration\":400,\n                          \"easing\": \"linear\"}}]\n            )]\n        )]\n    ),\n    frames=[\n            go.Frame(\n                data=[\n                        go.Bar(x= by_author_over_years_top[i:i+5]['count'].values, \n                               y= by_author_over_years_top[i:i+5]['author'].values,\n                               orientation='h',\n                               text = by_author_over_years_top[i:i+5]['count'].values\n                               )\n                    ],\n                layout=go.Layout(\n                        xaxis=dict(range=[0, 40], autorange=False),\n                        yaxis=dict(range=[-0.5, 5.5], autorange=False,tickfont=dict(size=14)),\n                        title=dict(text='5 Authors with most published books in '+str(by_author_over_years_top.loc[i, 'published']),\n                        font=dict(size=28)), \n                    )\n            )\n        for i in range(0, 125, 5)\n    ]\n)\n\npio.show(fig)","7ef8ed9b":"# Before I move on other files I want to remove NA values from books file\nbooks.isnull().sum()","b42b2318":"to_drop = books.loc[(books['author'].isna()) | (books['publisher'].isna()), 'book_id'].values\n\nbooks = books[~books['book_id'].isin(to_drop)].copy()\n\nbook_ratings = book_ratings[~book_ratings.isin(to_drop)].copy()","5eeab1cd":"users.tail()","94ec8766":"# This code below should easily break location format into pieces,\n# but it may happen in some Utopia, we have some values that splitted into 1 or 9 values, let's check that values\n\n#loc_detailed = ['city', 'region', 'country']\n#for i in range(3):\n#    users[loc_detailed[i]] = users['location'].apply(lambda x: x.split(', ')[i])","4a5204a1":"# Checking the outliers in location column\nc = 0\nfor location in users['location']:\n    \n    splitted = location.split(', ')\n    \n    length = len(splitted)\n    \n    if length != 3:\n        c+=1 # Number of outliers\n        #print(splitted)","62696636":"# To check whereas this value is in format I am seeking for\ndef is_format(value):\n    return len(value.split(', ')) == 3","ffb7a38d":"# Removing that outliers\nformatted = users[users['location'].apply(lambda x: is_format(x))].copy()\n\nformatted.shape","7d62f231":"users.shape","c8933036":"# This time it works fine\nloc_detailed = ['city', 'region', 'country']\nfor i in range(3):\n    formatted[loc_detailed[i]] = formatted['location'].apply(lambda x: x.split(', ')[i].capitalize())","fbc11c3e":"formatted.tail()","2d883918":"# First let's work values by city, region, country and then try to visualize data in World map.\n# By Cities\nby_city = formatted.groupby('city')['user_id'].count()","fb2b4194":"by_city.head()","2519f89a":"# Looks like I should remove errors in this file again.","eaca41c1":"formatted = formatted[formatted['city'].apply(lambda x: x.isalnum())].copy()","b20afc54":"by_city = pd.DataFrame(formatted.groupby('city')['user_id'].count())","d65f5592":"by_city = by_city.sort_values(by = ['user_id'], ascending = False)[:30]\n\nfigure = go.Figure(data = [go.Pie(labels = list(by_city.index), \n                                  values = list(by_city['user_id'].values),\n                                  textinfo='label+percent',\n                                  title= 'Thirty most popular cities' \n                                 )])\n\nfigure.show()","54a45d01":"by_countries = pd.DataFrame(formatted.groupby('country')['user_id'].count())\n\nby_countries = by_countries.sort_values(by = ['user_id'], ascending = False)[:20]\n\n\nfigure = go.Figure(data = [go.Pie(labels = list(by_countries.index), \n                                  values = list(by_countries['user_id'].values),\n                                  textinfo='label+percent',\n                                  title= 'Thirty most popular countries' \n                                 )])\n\nfigure.show()","487235c9":"formatted.groupby('age')['user_id'].count()","aca09327":"# Sorry babies and elders\nformatted = formatted[(formatted['age'] > 10) & (formatted['age'] < 100)].copy()","106403cd":"by_age = formatted.groupby('age')['user_id'].count()","ae10b8f2":"fig = exp.bar(x = by_age.index, y=by_age.values,\n             color= by_age.values,\n             height=400,\n             title = 'Distributions of reviews by age')\nfig.show()","0d6718d6":"formatted['age'].describe()","e44a90fc":"# This one actually not best practice, I guess I should create smth like function\nformatted.loc[formatted['country'] == 'United states', 'country'] = 'United States'\nformatted.loc[formatted['country'] == 'Usa', 'country'] = 'United States'\nformatted.loc[formatted['country'] == 'United kingdom', 'country'] = 'United Kingdom'\nformatted.loc[formatted['country'] == 'New zealand', 'country'] = 'New Zealand'\nformatted.loc[formatted['country'] == 'Iran', 'country'] = 'Iran (Islamic Republic of)'\nformatted.loc[formatted['country'] == 'South africa', 'country'] = 'South Africa'\nformatted.loc[formatted['country'] == 'Czech republic', 'country'] = 'Czech Republic'\nformatted.loc[formatted['country'] == 'South korea', 'country'] = 'Korea, Republic of'\nformatted.loc[formatted['country'] == 'Vietnam', 'country'] = 'Viet Nam'\nformatted.loc[formatted['country'] == 'Costa rica', 'country'] = 'Costa Rica'\nformatted.loc[formatted['country'] == 'United arab emirates', 'country'] = 'United Arab Emirates'\nformatted.loc[formatted['country'] == 'Saudi arabia', 'country'] = 'Saudi Arabia'\nformatted.loc[formatted['country'] == 'Bosnia and herzegovina', 'country'] = 'Bosnia and Herzegovina'\nformatted.loc[formatted['country'] == 'England', 'country'] = 'United Kingdom'\nformatted.loc[formatted['country'] == 'Scotland', 'country'] = 'United Kingdom'\nformatted.loc[formatted['country'] == 'Hong kong', 'country'] = 'Hong Kong'","3f685c69":"import geopandas as gpd\n\n# With the help of gpd, read world map file\nworld_data = gpd.read_file(r'..\/input\/world-map-files\/World_Map.shp')","d94963b6":"formatted['country'] = formatted['country'].apply(lambda x: x.replace('\"', \"\"))","6f58c1d5":"# Create new dataframe \nby_countries = pd.DataFrame(formatted.groupby('country')['user_id'].count().sort_values(ascending = False))\n\nby_countries = by_countries.reset_index()\nby_countries = by_countries.rename(columns = {'user_id': 'count'})","8ad81c95":"by_countries = by_countries[(by_countries['country'].isin(world_data['NAME']))].copy()","9dd30f10":"# Drop countries that we don't find longitude and latitude\n\nformatted = formatted[formatted['country'].isin(world_data['NAME'])].copy()","19866d35":"by_countries = by_countries.rename(columns = {'country': 'NAME'})\n\n# merge two dataframes by Name column\ncomb = world_data.merge(by_countries, on = 'NAME')","e6ebbc42":"ax = comb.plot(\n    column = 'count',\n    cmap = 'OrRd',\n    figsize = (12, 10),\n    legend = True,\n    scheme = 'user_defined',\n    classification_kwds = {'bins': [10, 100, 500, 1000, 2000, 5000, 10000, 20000]},\n    edgecolor = 'black',\n    linewidth = 0.4,\n    \n)\n# Remove axes\nax.set_axis_off()\n\nax.set_title('World map by users in this dataset')\n\n# Move the legend\nax.get_legend().set_bbox_to_anchor((0.18, 0.6))","952f0ee1":"countries = pd.read_csv('..\/input\/country-geo\/country_centroids_az8.csv')","9b52e86c":"countries.head()","8bbe674a":"countries = countries[['sovereignt' ,'income_grp', 'economy', 'Longitude', 'Latitude']].copy()","3220c070":"def rename_country(old, new):\n    formatted.loc[formatted['country'] == old, 'country'] = new\n    \nrename_country('United States', 'United States of America')","03f01c02":"rename_country('Iran (Islamic Republic of)', 'Iran')\nrename_country('Viet Nam', 'Vietnam')\nrename_country('Korea, Republic of', 'South Korea')\nrename_country('Congo', 'Democratic Republic of the Congo')","179acda0":"formatted = formatted[formatted['country'].isin(countries['sovereignt'].unique())].copy()","317cd52f":"formatted.shape","f5287d5f":"countries = countries.rename(columns = {'sovereignt': 'country'})","5b48c5f1":"# There some duplicates in counties table, so i'll keep last one\ncountries = countries.drop_duplicates(subset='country', keep=\"last\")","0466c628":"formatted = pd.merge(formatted, countries, on=\"country\")\n\nformatted.head()","038e1f57":"formatted.shape","55523e88":"# Let's remove unnecessary columns\nformatted.drop(['location', 'city', 'region', 'country'], axis = 1, inplace = True)","00faa97e":"# Finally, I am going to merge users with book reviews table\n# For this purpose, first I should remove users from book_reviews who were removed from users table\n\nbook_ratings = book_ratings[book_ratings['user_id'].isin(formatted['user_id'].unique())].copy()","0589cf55":"book_ratings.shape","f916b904":"user_reviews = pd.merge(formatted, book_ratings, on=\"user_id\")","22320fa3":"user_reviews.head(3)","98c57004":"by_income = user_reviews.groupby('income_grp')['score'].mean()\n\nby_income","e4e306c3":"fig = exp.bar(x=by_income.index, y = by_income.values, title = 'Average scores by income groups', template = 'ggplot2')\n\nfig.show()","cc215924":"by_eco = user_reviews.groupby('economy')['score'].mean()\n\nby_eco","6c9f7825":"fig = exp.bar(x=by_eco.index, y = by_eco.values, title = 'Average scores by economy', template = 'ggplot2')\n\nfig.show()","1523f70a":"# Now I can convert income_grp and economy to numerical columns (I will just remove text except leading digits and convert to int)\n\nuser_reviews['income_grp'] = user_reviews['income_grp'].apply(lambda x: int(x.split('.')[0]))","861af1bb":"user_reviews['economy'] = user_reviews['economy'].apply(lambda x: int(x.split('.')[0]))","08684800":"user_reviews.dtypes","5db0201a":"# Let's check distributions of scores\nscores = user_reviews.groupby('score')['user_id'].count()","7606c3a2":"fig = exp.bar(x=scores.index, y = scores.values, title = 'Number of reviews to each score', template = 'ggplot2')\n\nfig.show()","d52b5671":"Let's try this pie chart again, but this time with countries","8fb38f00":"Let's remove this data also (I am removing all this outliers just because I've a lot of data, but some cases I might replace it with means or try to fix misspells)","c185b57a":"![newplot%20%2812%29.png](attachment:newplot%20%2812%29.png)","28eac817":"As we can't see results of plotly in github, I will paste static images of results.","602e1881":"![newplot%20%2810%29.png](attachment:newplot%20%2810%29.png)","a00fc155":"Once again, I should change some country names in users table, so two dataframes can be merged successfully","b3e97f4b":"After some attempts, I decided to download longitude and latitude from another file. There we can also get some useful attributes of country like: income group of this country, subregion, scalerank and e.t.c. I will get them also with lat\/long and in next steps try to test hypothesis (e.g. how people from different regions tend to rate books).","de936a9d":"![newplot%20%281%29.png](attachment:newplot%20%281%29.png)","83c357c3":"![newplot%20%285%29.png](attachment:newplot%20%285%29.png)","aac5f96b":"Missing values:\n    1. Books: Book author (1 value), Publisher (2 values)\n    2. Users: Age (110762 values)\n    3. Book-Ratings: None\n    ","fda5a962":"Looks like I removed half of the book ratings table.","21efa8ef":"EDA on books file finished, Next is users file.","6cd72c61":"Books table","75dff2a7":"Now, let's try this with publishers","ebf9b62e":"Finally let's play around with book title","0e064e24":"Here is static version for Github.","5d3569b5":"![newplot%20%284%29.png](attachment:newplot%20%284%29.png)","91c541bc":"Attributes description of every file:\n    1. Books\n    ISBN: book's unique id\n    Book-Title: Title of book\n    Book-Author: Author of book\n    Publisher: Organization that published book\n    Year-Of-Publication: published year\n    Image-URL-S: url of book's image small size\n    Image-URL-M: url of book's image medium size\n    Image-URL-L: url of book's image large size\n        \n    2. Users\n    User-ID: unique id for user\n    Location: physicall address of user (city, state, country)\n    Age: age of this user\n    \n    3. Book-Ratings:\n    User-ID: id of user who rated\n    ISBN: id of book that was rated\n    Book-Rating: score that user gives to book (from 1 to 10)","87f086e3":"![newplot.png](attachment:newplot.png)","d971668e":"However, other scores are also enough for us (review scores except 0 look tiny compating to 0 score, but mostly there 10000+ reviews for each of them)","fb91d605":"It looks like at the stage of data collecting, publisher loaded as title also, but other words look pretty fair for me.","a4e8d9c7":"With the help of Plotly, you can easily zoom in, or zoom out, by selecting period that you are interested","c389d7ac":"![newplot%20%283%29.png](attachment:newplot%20%283%29.png)","c46338ff":"For now, I am not interested in images of books, so I will work with title, author, published, publisher columns.","a0d00952":"Here we can see 5601 rows are not standard values, so for next steps I will just remove them, but for final result I will try to save as many as possible","20fd0abd":"It looks very beautiful for me, but I have another option that may seem to you more understandable. Below static version for github.","edd7860e":"We can see here, that books in this dataset mostly were published in period of 1980 and 2004.","1bdbc4c2":"Well... this sh*t can be done eternal, so let's move on with what we have.","9105e745":"![newplot%20%289%29.png](attachment:newplot%20%289%29.png)","cc2687d9":"Static version for Github","13669f1a":"Finally, World Map part","78efa1cb":"Check data in files","9f378b7f":"Here I will get income, economy and longitude with latitude.","5197cb6e":"If I will load files correctly then shapes of files will be: Books (271379, 8); Book-Ratings (1149780, 3); Users(278858, 3)","68f839e3":"This chart says everything for itself. Before moving from this table, I would like to perform related to authors with most published books for every year in range and e.t.c.","0ae9be55":"![newplot%20%288%29.png](attachment:newplot%20%288%29.png)","cca303d3":"Static version for Github","486a1793":"It looks like mostly users gave 0 as score. I don't respond validness of this scores, cause even for bad book I would give 1 to 3, but there a lot of zeros.","ee209df0":"![newplot%20%282%29.png](attachment:newplot%20%282%29.png)","096b412b":"![newplot%20%286%29.png](attachment:newplot%20%286%29.png)","ef1592df":"Let's divide location column to city\/region\/country columns. I am not sure about region column, but firstly let's check data ;)","accae6a7":"Looks like mostly people are aged between 18 and 38. We can also check that with intervals","aea4c03f":"![newplot%20%287%29.png](attachment:newplot%20%287%29.png)","88d6ea40":"There empty values for this column, which were replace with 0. Also there books that 'were published' in future. There almost 4000 books out of 270,000 so I will drop them.","1f10a435":"Bar on above is interactive, but it doesn't move or make some actions. In code below, I will try to create racing bar Graph, taking 5 Authors with most published books in respective year. As in previous bar, I will get only books that were published from 1980 up to 2005."}}