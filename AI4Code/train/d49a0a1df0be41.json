{"cell_type":{"f0f9c11c":"code","0394812f":"code","4576c697":"code","49f31126":"code","3fb6bc01":"code","35719454":"code","2a6e0c62":"code","5198d636":"code","c6e499d4":"code","3558f9d0":"code","fda5ed03":"code","555e5c07":"code","23b143fc":"code","7eaf7f14":"code","2c41c390":"code","4c5b8b5e":"code","f5c2d1e2":"code","8b331beb":"code","4dcac547":"code","2c8f0a4d":"code","ea328a87":"code","0fd1c880":"code","aa202764":"code","c24eff6a":"code","f18f4e5d":"code","02987d60":"code","bed46ede":"code","d14f2818":"code","28b2a11e":"code","43d72cb3":"code","2942893f":"code","a14aa482":"code","8c028eee":"code","43681de2":"code","f171f3e0":"code","ae3fa131":"code","e518f154":"code","e4f46195":"code","b5666209":"code","149dde7a":"code","ef0c9a6d":"code","f13df310":"code","eefc854a":"code","629620e4":"code","f20cdce3":"code","d88f6c4c":"code","b9c728bd":"markdown","2b491bd6":"markdown","6ebfad4b":"markdown","a7afcbff":"markdown","92128b76":"markdown","00ecf9fb":"markdown","c0d4a40a":"markdown"},"source":{"f0f9c11c":"#importing packages\n%matplotlib inline\nimport scipy.stats as stats\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')","0394812f":"df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","4576c697":"#shape\nprint('This data frame has {} rows and {} columns.'.format(df.shape[0], df.shape[1]))","49f31126":"#peek at data\ndf.sample(5)","3fb6bc01":"#info\ndf.info()","35719454":"#numerical summary -> only non-anonymized columns of interest\npd.set_option('precision', 3)\ndf.loc[:, ['Time', 'Amount']].describe()","2a6e0c62":"#visualizations of time and amount\nplt.figure(figsize=(10,8))\nplt.title('Distribution of Time Feature')\nsns.distplot(df.Time)","5198d636":"plt.figure(figsize=(10,8))\nplt.title('Distribution of Monetary Value Feature')\nsns.distplot(df.Amount)","c6e499d4":"#fraud vs. normal transactions \ncounts = df.Class.value_counts()\nnormal = counts[0]\nfraudulent = counts[1]\nperc_normal = (normal\/(normal+fraudulent))*100\nperc_fraudulent = (fraudulent\/(normal+fraudulent))*100\nprint('There were {} non-fraudulent transactions ({:.3f}%) and {} fraudulent transactions ({:.3f}%).'.format(normal, perc_normal, fraudulent, perc_fraudulent))","3558f9d0":"plt.figure(figsize=(8,6))\nsns.barplot(x=counts.index, y=counts)\nplt.title('Count of Fraudulent vs. Non-Fraudulent Transactions')\nplt.ylabel('Count')\nplt.xlabel('Class (0:Non-Fraudulent, 1:Fraudulent)')","fda5ed03":"corr = df.corr()\ncorr","555e5c07":"#heatmap\ncorr = df.corr()\nplt.figure(figsize=(12,10))\nheat = sns.heatmap(data=corr)\nplt.title('Heatmap of Correlation')","23b143fc":"#skewness\nskew_ = df.skew()\nskew_","7eaf7f14":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler2 = StandardScaler()\n#scaling time\nscaled_time = scaler.fit_transform(df[['Time']])\nflat_list1 = [item for sublist in scaled_time.tolist() for item in sublist]\nscaled_time = pd.Series(flat_list1)","2c41c390":"#scaling the amount column\nscaled_amount = scaler2.fit_transform(df[['Amount']])\nflat_list2 = [item for sublist in scaled_amount.tolist() for item in sublist]\nscaled_amount = pd.Series(flat_list2)","4c5b8b5e":"#concatenating newly created columns w original df\ndf = pd.concat([df, scaled_amount.rename('scaled_amount'), scaled_time.rename('scaled_time')], axis=1)\ndf.sample(5)","f5c2d1e2":"#dropping old amount and time columns\ndf.drop(['Amount', 'Time'], axis=1, inplace=True)","8b331beb":"#manual train test split using numpy's random.rand\nmask = np.random.rand(len(df)) < 0.9\ntrain = df[mask]\ntest = df[~mask]\nprint('Train Shape: {}\\nTest Shape: {}'.format(train.shape, test.shape))","4dcac547":"train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)","2c8f0a4d":"#how many random samples from normal transactions do we need?\nno_of_frauds = train.Class.value_counts()[1]\nprint('There are {} fraudulent transactions in the train data.'.format(no_of_frauds))","ea328a87":"#randomly selecting 442 random non-fraudulent transactions\nnon_fraud = train[train['Class'] == 0]\nfraud = train[train['Class'] == 1]","0fd1c880":"selected = non_fraud.sample(no_of_frauds)\nselected.head()","aa202764":"#concatenating both into a subsample data set with equal class distribution\nselected.reset_index(drop=True, inplace=True)\nfraud.reset_index(drop=True, inplace=True)","c24eff6a":"subsample = pd.concat([selected, fraud])\nlen(subsample)","f18f4e5d":"#shuffling our data set\nsubsample = subsample.sample(frac=1).reset_index(drop=True)\nsubsample.head(10)","02987d60":"new_counts = subsample.Class.value_counts()\nplt.figure(figsize=(8,6))\nsns.barplot(x=new_counts.index, y=new_counts)\nplt.title('Count of Fraudulent vs. Non-Fraudulent Transactions In Subsample')\nplt.ylabel('Count')\nplt.xlabel('Class (0:Non-Fraudulent, 1:Fraudulent)')","bed46ede":"#taking a look at correlations once more\ncorr = subsample.corr()\ncorr = corr[['Class']]\ncorr","d14f2818":"#negative correlations smaller than -0.5\ncorr[corr.Class < -0.5]","28b2a11e":"#positive correlations greater than 0.5\ncorr[corr.Class > 0.5]","43d72cb3":"#visualizing the features w high negative correlation\nf, axes = plt.subplots(nrows=2, ncols=4, figsize=(26,16))\n\nf.suptitle('Features With High Negative Correlation', size=35)\nsns.boxplot(x=\"Class\", y=\"V3\", data=subsample, ax=axes[0,0])\nsns.boxplot(x=\"Class\", y=\"V9\", data=subsample, ax=axes[0,1])\nsns.boxplot(x=\"Class\", y=\"V10\", data=subsample, ax=axes[0,2])\nsns.boxplot(x=\"Class\", y=\"V12\", data=subsample, ax=axes[0,3])\nsns.boxplot(x=\"Class\", y=\"V14\", data=subsample, ax=axes[1,0])\nsns.boxplot(x=\"Class\", y=\"V16\", data=subsample, ax=axes[1,1])\nsns.boxplot(x=\"Class\", y=\"V17\", data=subsample, ax=axes[1,2])\nf.delaxes(axes[1,3])","2942893f":"#visualizing the features w high positive correlation\nf, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,9))\n\nf.suptitle('Features With High Positive Correlation', size=20)\nsns.boxplot(x=\"Class\", y=\"V4\", data=subsample, ax=axes[0])\nsns.boxplot(x=\"Class\", y=\"V11\", data=subsample, ax=axes[1])","a14aa482":"#Only removing extreme outliers\nQ1 = subsample.quantile(0.25)\nQ3 = subsample.quantile(0.75)\nIQR = Q3 - Q1\n\ndf2 = subsample[~((subsample < (Q1 - 2.5 * IQR)) |(subsample > (Q3 + 2.5 * IQR))).any(axis=1)]","8c028eee":"len_after = len(df2)\nlen_before = len(subsample)\nlen_difference = len(subsample) - len(df2)\nprint('We reduced our data size from {} transactions by {} transactions to {} transactions.'.format(len_before, len_difference, len_after))","43681de2":"from sklearn.manifold import TSNE\n\nX = df2.drop('Class', axis=1)\ny = df2['Class']","f171f3e0":"#t-SNE\nX_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)","ae3fa131":"# t-SNE scatter plot\nimport matplotlib.patches as mpatches\n\nf, ax = plt.subplots(figsize=(24,16))\n\n\nblue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\nred_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n\nax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\nax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\nax.set_title('t-SNE', fontsize=14)\n\nax.grid(True)\n\nax.legend(handles=[blue_patch, red_patch])\n","e518f154":"def warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn","e4f46195":"# train test split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","b5666209":"X_train = X_train.values\nX_validation = X_test.values\ny_train = y_train.values\ny_validation = y_test.values","149dde7a":"print('X_shapes:\\n', 'X_train:', 'X_validation:\\n', X_train.shape, X_validation.shape, '\\n')\nprint('Y_shapes:\\n', 'Y_train:', 'Y_validation:\\n', y_train.shape, y_validation.shape)","ef0c9a6d":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","f13df310":"##Spot-Checking Algorithms\n\nmodels = []\n\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('SVM', SVC()))\nmodels.append(('XGB', XGBClassifier()))\nmodels.append(('RF', RandomForestClassifier()))\n\n#testing models\n\nresults = []\nnames = []\n\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=42)\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n    results.append(cv_results)\n    names.append(name)\n    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n    print(msg)","eefc854a":"#Compare Algorithms\n\nfig = plt.figure(figsize=(12,10))\nplt.title('Comparison of Classification Algorithms')\nplt.xlabel('Algorithm')\nplt.ylabel('ROC-AUC Score')\nplt.boxplot(results)\nax = fig.add_subplot(111)\nax.set_xticklabels(names)\nplt.show()","629620e4":"#visualizing RF\nmodel = RandomForestClassifier(n_estimators=10)\n\n# Train\nmodel.fit(X_train, y_train)\n# Extract single tree\nestimator = model.estimators_[5]\n\nfrom sklearn.tree import export_graphviz\n# Export as dot file\nexport_graphviz(estimator, out_file='tree.dot', \n                feature_names = X.columns.tolist(),\n                class_names = ['0',' 1'],\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\n\n# Convert to png using system command (requires Graphviz)\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree.png')","f20cdce3":"y_pred=model.predict(X_validation)","d88f6c4c":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))","b9c728bd":"**Dimensionality Reduction**","2b491bd6":"**Classification Algorithms**","6ebfad4b":"**Splitting Data into Train and Test**","a7afcbff":"Around 88 dollars is the mean of all credit card transactions in this data set. The biggest transaction had a monetary value of around 25,691 dollars.","92128b76":"**Creating a subsample data set with balanced class distributions**","00ecf9fb":"**Extreme Outlier Removal**","c0d4a40a":"**Scaling Amount and Time**"}}