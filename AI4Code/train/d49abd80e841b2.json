{"cell_type":{"a2a7e602":"code","adefe3f4":"code","211e9442":"code","8f742350":"code","46b44911":"code","c86fcbf0":"code","30178d67":"code","e89ee748":"code","ceb438ba":"code","cc892d2b":"code","14ba64e3":"code","c39e289c":"code","9a51d9f9":"code","1609c1e2":"code","16133d5b":"code","b9e3ace6":"code","c7128569":"code","599bac0f":"code","311d9c7f":"code","38276dba":"code","91f18399":"code","35ed45d3":"code","750a8374":"code","7b173099":"code","0db7f224":"code","6f645ee8":"code","fcd05ab4":"code","152b66b2":"code","f61c72a2":"code","4a32ae7e":"code","19b1f50e":"code","665ad5b1":"code","c0fe4003":"code","43accdcc":"code","da5aacb9":"code","094b9c4a":"code","b5bc1f9f":"code","f1d3daf2":"code","b31c874a":"code","1c541388":"code","287f9d11":"code","56272941":"code","2f867bae":"code","a90fc32d":"code","d58e4f02":"code","5caa7d53":"code","e7d1002f":"code","02e647ec":"code","964c1aeb":"code","3a64ba2c":"code","3df05b2f":"code","a782e096":"code","262c7f20":"code","2407a64a":"code","5bd183a3":"code","d713dbde":"code","3638007a":"code","5306551c":"code","77409d8b":"code","320100c4":"code","298caa84":"code","c879e0e3":"code","ef6fd3de":"code","7c9e1d09":"code","dfb33652":"code","19eb7de9":"code","514bc94b":"code","50ab2f63":"code","84e2a769":"code","443e2261":"code","d88be763":"code","03c36ba1":"code","1a6147c8":"code","9c750120":"code","25b5e9ba":"code","aa71851f":"code","486ea167":"code","a6db7d73":"code","ec7c1a43":"code","4d77bfe9":"code","05d14acf":"code","1cf84e72":"markdown","32859dfb":"markdown","cc406122":"markdown","1aa81ef0":"markdown","e6d93f6d":"markdown","ae08d580":"markdown","b886242b":"markdown","3fda04e4":"markdown","6a03dbd5":"markdown","3b9ed83e":"markdown","bad67769":"markdown","b7db82d1":"markdown","ffed37d8":"markdown","8c209f4e":"markdown","8773a20c":"markdown","32358290":"markdown","999b7784":"markdown","9baaa796":"markdown","c476a7f0":"markdown","42aa802d":"markdown","772ead1c":"markdown","3a0174ba":"markdown","96e7f43d":"markdown","aadfdb87":"markdown","134c78f3":"markdown","53c37adb":"markdown","a2f6cb03":"markdown","400af6a8":"markdown","62c8e4c3":"markdown","ef54e0fe":"markdown","c6e49760":"markdown","256c75e1":"markdown","4bb3ca7a":"markdown","6350c208":"markdown","bf6464b8":"markdown","b2ec57a0":"markdown","d068f54a":"markdown","5fdb3fa3":"markdown","1f1701a4":"markdown","5780f57b":"markdown","3ad1147f":"markdown","5f6f1477":"markdown","6a84d9e7":"markdown","395c781b":"markdown","3f0ad5c5":"markdown","c632af56":"markdown","2439ce6b":"markdown","6c5bb701":"markdown","4d50ff23":"markdown","5928b6d8":"markdown","159344f8":"markdown","e9275117":"markdown","458fa184":"markdown","d64cd203":"markdown","eac6ab71":"markdown","b0523975":"markdown"},"source":{"a2a7e602":"# Included the infographic of the most common attributes of a data science\n# Main reason is to get attention of reader so that it increases the chance of viewer\n# to continue reading. \n# Used this format of infographic as I expect a lot of viewers are already familiar with\n# format so already in their frame in a positive light\n\n\n# Note as have limited experience with python there will be many cases where my code is inefficient and will need to clean it up\n# A lot of issues trying to get formating right as committed notebook is different to interactive version\n\n#Not able to access image in following method so used Ipython.display\n# ****<img  src=\"..\/input\/imagefilesforkagglesurvey\/anatomyofkaggler.png\" >\n\n\n\nfrom IPython.display import Image\nfrom IPython.core.display import HTML \nPATH = \"..\/input\/imagefilesforkagglesurvey\/\"\nImage(filename = PATH + \"anatomyofkaggler2.png\")\n\n","adefe3f4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline  \n\ndfmain = pd.read_csv('..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv')\ndfmain = dfmain.drop(dfmain.index[0]) # Remove the first line of text which has question text\ndfmain['genderid'] = dfmain.groupby('Q1').ngroup().add(1)\ndfmain['formaleducationid'] = dfmain.groupby('Q4').ngroup().add(1)\n# Start with a wordcloud of most of information from multipleChoiceResponses.csv\n# Main idea to be communicated is main function of data scientist is to get meaning from\n# data using tools and process that can reproduce similar results. The main different from\n# a data scientist with a normal scientist is that we are not trying to reproduce same results\n# but acquire more meaning which in result able us to use the data more effectively i.e predictions\n\n\n# So using story is start off with looking at all the data and the then acquired meaning to it in a systematic way\n\n\n#Using wordcloud as gives reader understanding of type of responses in survey and not until\n# able to drill down into questions and domain knowledge of what is a data scientist able to \n# get more meaning from data the finally be able to differentiate kagglers in terms of \n# what most data scientists uses compared to what is a good differntiater for data scientist\n\n\n# Using very ineffeciant way to get data for wordcloud to get around outputs \n# was getting from from the function that didnt corrolate with data it was working with\n\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS \nfrom collections import Counter\nfrom os import path\nfrom PIL import Image\nimport numpy as np\nimport os\nd = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\nthoughtbubble_mask = np.array(Image.open(path.join(d, \"..\/input\/imagefilesforkagglesurvey\/Thought-Bubble-PNG2.png\")))\nexplosion_mask = np.array(Image.open(path.join(d, \"..\/input\/imagefilesforkagglesurvey\/explosion.png\")))\n\ncomment_words = ' '\nstopwords = set(STOPWORDS) \n\n\n# Identified what questions go in four main categories will be working with and adding all\n# responses in different list. This occurs first as main wordcloud will use all responses bas\n# on categories to be used.\n\n\n\n\nstopwords = stopwords.union({'NAN', '0','-1', 'nan','1','etc.)','years', 'years)','and\/or','I'})\ndfwordmain = dfmain.copy()\ndfwordmain['Q2'] = dfwordmain.apply(lambda row: 'age(' + row['Q2'] +')', axis = 1)\ndfwordmain['Q8'] = dfwordmain.apply(lambda row: 'experienceRole(' + str(row['Q8']) +')', axis = 1)\ndfwordmain['Q9'] = dfwordmain.apply(lambda row: 'income(' +str(row['Q9']) +')', axis = 1)\ndfwordmain['Q25'] = dfwordmain.apply(lambda row: 'experienceML(' +str(row['Q25']) +')', axis = 1)\ndfcloud = pd.DataFrame()\ndfcloud['cloudtext'] = dfwordmain.iloc[:,[1,3,4,5,6,7,9,11,12,125,126,127,128,291,292,293,\n        294,295,296,297,298,299,300,301,302,303,305,307,308,309,310,311,312,313,314,315,316,317,\n                                          318,319,320,321,32,323,324,325,326]].stack().values\n\n\ndfcloud['cloudtext'] = dfcloud.apply(lambda row: str(row['cloudtext']) , axis = 1)\nmy_list=dfcloud[dfcloud['cloudtext'] != '-1']['cloudtext'].tolist()\nmy_list2  = [model for word in my_list for model in word.split(' ')]\nmy_listPersonal = [x for x in my_list2 if x not in stopwords]  \n\ndfwordmain = dfmain.copy()\n\ndfcloud2 = pd.DataFrame()\ndfcloud3 = pd.DataFrame()\ndfcloud2['cloudtext'] = dfwordmain.iloc[:,21:108].stack().values\ndfcloud3['cloudtext'] = dfwordmain.iloc[:,129:193].stack().values\ndfcloud= pd.concat([dfcloud2, dfcloud3], ignore_index=True)\ndfcloud['cloudtext'] = dfcloud.apply(lambda row: str(row['cloudtext']) , axis = 1)\nmy_list=dfcloud[dfcloud['cloudtext'] != '-1']['cloudtext'].tolist()\n# Thought-Bubble-PNG2\nmy_list2  = [model for word in my_list for model in word.split(' ')]\n\n# Stopword works randomly in wordcloud function so created on method of removing common words\nmy_listTools = [x for x in my_list2 if x not in stopwords]\n\ndfwordmain = dfmain.copy()\ndfcloud2 = pd.DataFrame()\ndfcloud3 = pd.DataFrame()\ndfcloud2['cloudtext'] = dfwordmain.iloc[:,109:124].stack().values\ndfcloud3['cloudtext'] = dfwordmain.iloc[:,194:275].stack().values\ndfcloud= pd.concat([dfcloud2, dfcloud3], ignore_index=True)\n\ndfcloud['cloudtext'] = dfcloud.apply(lambda row: str(row['cloudtext']) , axis = 1)\nmy_list=dfcloud[dfcloud['cloudtext'] != '-1']['cloudtext'].tolist()\n\nmy_list2  = [model for word in my_list for model in word.split(' ')]\nmy_listData = [x for x in my_list2 if x not in stopwords]\n\ndfwordmain = dfmain.copy()\ndfcloud2 = pd.DataFrame()\ndfcloud3 = pd.DataFrame()\ndfcloud2['cloudtext'] = dfwordmain.iloc[:,[12,13,14,15,16,17,18,19,20,335,336,337,338,338,340,341,342,343,344,345,346,347,348,349,350,\n                                          355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371]].stack().values\ndfcloud3['cloudtext'] = dfwordmain.iloc[:,385:393].stack().values\ndfcloud= pd.concat([dfcloud2, dfcloud3], ignore_index=True)\n\ndfcloud['cloudtext'] = dfcloud.apply(lambda row: str(row['cloudtext']) , axis = 1)\nmy_list=dfcloud[dfcloud['cloudtext'] != '-1']['cloudtext'].tolist()\n\nmy_list2  = [model for word in my_list for model in word.split(' ')]\nmy_listModel = [x for x in my_list2 if x not in stopwords]\n\n#Will put the above in a fuction if have enought time\n\n\nmy_listall = my_listPersonal.copy()\nmy_listall.extend(my_listTools)\nmy_listall.extend(my_listData)\nmy_listall.extend(my_listModel)\n","211e9442":"# Uses WordCould to create a good visual of what are the main words from the survey\n\nword_could_dict=Counter(my_listall)\n\n\nwordcloud = WordCloud(\n                          background_color='white',                         \n                          max_words=400,\n                          max_font_size=None, \n                          repeat=False,\n                          mask=explosion_mask ,\n                          random_state=42,\n                          stopwords=['that','the']\n                         ).fit_words(word_could_dict)\n# Had to use fit_words otherwise would only include a small subset of the words\n\nplt.figure(figsize=(14,14))\n\n# Thought carl jung quote reflects an important part data science in how using bayesion methods \n# and known priors enables us to make more accurate understanding\/meaning\/predictions \n# with the data at hand\nplt.title('The least of things with a meaning is worth more in life than the greatest of things without it.\u2013 Carl Jung')\nplt.imshow(wordcloud) #, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()\n\n\n# Nearly 3 million words that the world cloud is working with found using len(my_listall)\n\n\n# Shaped the wordcloud as an explosion to represent the chaos of first  looking at data \n# with no real frame of reference","8f742350":"from IPython.display import Image\nImage(filename = PATH + \"predictdatascientist3.png\")\n\n# I consider the following infographic the most important story in this notebook\n\n\n# Used the particular infographic as it included both a male and female which represent\n# the results from analsys of the differences. \n# Used same format as first infographic to be consistent\n# Main issue I have with this notebook is when to display this infographic ","46b44911":"#Five main categories based on my understanding of short term memory and presentations\n# So grouped main areas in the five categories and looked for a base venn diagram using\n# Google images. Found the one below and just edited out words and included categories\n# and title for this notebook\n \nImage(filename = PATH + \"surveycategories.png\", width=600)\n","c86fcbf0":"\n# Converted main Q26 into values as original place was to create notebook the predicts if kaggler is a data scientist\n# Using the most important features as the story. \ndef update_typeofds(selfidentifytext):\n   \n  selfid = 0\n  if selfidentifytext == 'Definitely not':\n    selfid = 1\n  if selfidentifytext == 'Probably not':\n    selfid = 2\n  if selfidentifytext == 'Maybe':\n    selfid = 3\n  if selfidentifytext == 'Probably yes':\n    selfid = 4\n  if selfidentifytext == 'Definitely yes':\n    selfid = 5  \n \n  \n  return selfid\n\n# After going through each of the question and dislaying a graph found it to be easier to use a function\n# This is mainly for question broken up into parts and being able to include all question in one dataframe\n\ndef groupbydataforgraph(groupbyonetext, groupbytwotext,graphcolumnnames):\n  \n  dfreturn = df.groupby([groupbyonetext, groupbytwotext]).size().reset_index()\n  dfreturn.columns = graphcolumnnames\n  \n  return dfreturn\n\n#Key Fucntion to determine if identified as Data Scientist and what data can work with\ndef update_isdatascientist(selfidentifytext):\n    selfid = 'Not a Data Scientist'\n  \n    if selfidentifytext == 'Probably yes':\n        selfid = 'Identify as Data Scientist'\n    if selfidentifytext == 'Definitely yes':\n        selfid = 'Identify as Data Scientist'  \n    if selfidentifytext == 'Probably not':\n        selfid = 'Not a Data Scientist'\n    if selfidentifytext == 'Definitely not':\n        selfid = 'Not a Data Scientist'  \n \n  \n    return selfid\n\n\n# Used for question 34 and 35. Feel like my limited knowledge of python\n# was a big drawback in plotting responses to those questions. Hopefully later versions of \n# this notebook reflect my growth\n\ndef update_percentcat(percenttouse):\n#     print(percenttouse)\n    categorycheck = ''\n    if not pd.isnull(percenttouse):\n        checknumber = float(percenttouse)\n#         print('checknumber',checknumber)\n        categorycheck = '0'\n        if (checknumber > 0) and (checknumber <= 20):\n             categorycheck = '1-20'     \n        if (checknumber > 20) and (checknumber <= 40):\n             categorycheck = '21-40'   \n        if (checknumber > 40) and (checknumber <= 60):\n             categorycheck = '41-60'    \n        if (checknumber > 61) and (checknumber <= 80):\n             categorycheck = '61-80'               \n        if (checknumber > 80) and (checknumber <= 100):\n             categorycheck = '81-100' \n#         if (checknumber > 50) and (checknumber <= 75):\n#              categorycheck = '51-75'     \n#         if (checknumber > 75) and (checknumber <= 100):\n#              categorycheck = '76-100'  \n    return categorycheck\n\n\n\ndfmain['selfidentifyid'] = dfmain.apply(lambda row: update_typeofds(row['Q26']), axis = 1)\ndfmain['selfgroupid'] = dfmain.apply(lambda row: update_isdatascientist(row['Q26']), axis = 1)\ndfmain['isstudentid'] = dfmain.apply(lambda x: 'Student' if x['Q6'] == 'Student' else 'Non Student', axis = 1)\n","30178d67":"dfmain['Q26'].fillna(value='No response', inplace = True)\ndfidentify = dfmain.groupby(['Q26']).size().sort_values(ascending = False).reset_index()\ndfidentify.columns = ['Identify', 'Count']\nplt.figure(figsize=(9,6))\ncolors = ['grey','yellowgreen', 'gold', 'lightcoral', 'lightskyblue','blue']\nexplode = (0,0.12,0.2, 0, 0, 0)\nax = plt.pie(dfidentify['Count'], labels = dfidentify['Identify'], colors = colors,explode = explode,\n            autopct='%1.1f%%', shadow=True, startangle=105)\n","e89ee748":"df = dfmain[(dfmain['selfgroupid'] != 'Maybe')]\ndfidentify = df.groupby(['selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfidentify.columns = ['Identify', 'Count']\nplt.figure(figsize=(9,6))\ncolors = [ 'gold', 'lightskyblue']\nexplode = (0,0.12,0.2, 0, 0, 0)\nax = plt.pie(dfidentify['Count'], labels = dfidentify['Identify'], colors = colors,\n            autopct='%1.1f%%', shadow=True, startangle=105)\n\n","ceb438ba":"# Make data in a readable format for plots. \n# As length of answers may be to long to display without overlapping need a way to wrap text, \n# I was not able to find a wrap function so wrapped the answers\n# This occurrs for a lot of questions so the following code will be replaced once I find method for doing it all in one go\n\ndf['Q4'] = df['Q4'].str.wrap(20)\ndf['Q9'] = df['Q9'].str.wrap(30)\ndf['Q10'] = df['Q10'].str.wrap(30)\n\ndf['Q42_Part_4'] = df['Q42_Part_4'].str.wrap(30)\n\n","cc892d2b":"# word_could_dict=Counter(my_list)\nword_could_dict=Counter(my_listPersonal)\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=400,\n                          max_font_size=None, \n                          repeat=False,\n                          mask=thoughtbubble_mask ,\n                          random_state=42\n                         ).fit_words(word_could_dict)\n\n\nplt.figure(figsize=(14,11))\nplt.title('If you haven\u2019t found it yet, keep looking. \u2013 Steve Jobs')\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()\n\n# Wrapped number groupings aroud text i.e age(25-29 so reader can derive more meaning from the word cloud\n# Shaped as a thought bubble over water","14ba64e3":"\n# Questions used for Personal information are \n\n# What is your gender? - Selected Choice\n# What is your age (# years)?\n# In which country do you currently reside?\n# What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\n# Which best describes your undergraduate major? - Selected Choice\n# How many years of experience do you have in your current role?\n# What is your current yearly compensation (approximate $USD)?\n# How long have you been writing code to analyze data?\n# For how many years have you used machine learning methods (at work or in school)?\n# On which online platforms have you begun or completed data science courses?\n# On which online platform have you spent the most amount of time? - Selected Choice\n# Who\/what are your favorite media sources that report on data science topics?\n# How do you perceive the quality of online learning platforms and in-person bootcamps as compared to the quality of the education provided by traditional brick and mortar institutions? - Online learning platforms and MOOCs:\n# How do you perceive the quality of online learning platforms and in-person bootcamps as compared to the quality of the education provided by traditional brick and mortar institutions? - In-person bootcamps:\n# Which better demonstrates expertise in data science: academic achievements or independent projects? - Your views:\n# What barriers prevent you from making your work even easier to reuse and reproduce?\n\n\n#Questions and variable names may not match categories as first exercies was go through each question and chart it\n# Due to time constraits went straight from charting to adding information into an excel spreadsheet about main\n# attributes found from each chart which is show in Results section\n# Kaggle notebook is much harder to move cells around the jupyter notebook\n# Actually started writing in Google Colab than moved to Jupyter notebook and than Kaggle, all good learning experience but time consuming\n","c39e289c":"\ntotal = float(len(df))\n#Just showing results between males and females to be more concise\ndfdsbygender =  df[(df.genderid < 3)].groupby(['Q1','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfdsbygender.columns = ['Gender','Identify', 'Count']\ndfdsbygender.head(20)\n# dfdsbygender.groupby(level=[0]).apply(lambda x: x \/ x.sum())\n\nplt.figure(figsize=(9,6))\nplt.title('Self Identification by Gender')\nax = sns.barplot(y = dfdsbygender['Count'], x = dfdsbygender['Gender'], hue = dfdsbygender['Identify'])\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\") \n","9a51d9f9":"# Chosen the top six so plot is more readable\ndfdsbyeducation =  df[(df['Q4'] != 'I prefer not to answer')].groupby(['Q4', 'selfgroupid']).size().sort_values(ascending = False).reset_index().head(6)\ndfdsbyeducation.columns = ['Education','Identify', 'Count']\n\n\nplt.figure(figsize=(12,6))\nplt.title('Self Identification by Education')\nax = sns.barplot(y = dfdsbyeducation['Count'], x = dfdsbyeducation['Education'], hue = dfdsbyeducation['Identify'])\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\") \n\n\n","1609c1e2":"dfdsbyeducation =  df[(df['Q4'] != 'I prefer not to answer')].groupby(['Q4', 'selfgroupid']).size().sort_values(ascending = False).head(6)\ndfplot = dfdsbyeducation.groupby(level=[0]).apply(lambda x: x \/ x.sum()).reset_index()\ndfplot.columns = ['Education','Identify', 'Percent']\n\n\nplt.figure(figsize=(9,6))\nplt.title('Self Identification as Percent of Type of Education')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Education'], hue = dfplot['Identify'])","16133d5b":"dfdoctor = df[(df['Q4'] == 'Doctoral degree') & (df.genderid < 3)].groupby(['selfgroupid','Q1']).size()\ndfplot  = dfdoctor.groupby(level=[0]).apply(lambda x: x \/ x.sum()).reset_index()\ndfplot.columns = ['Identify','Gender', 'Percent']\nplt.figure(figsize=(9,6))\nplt.title('Self Identification by Gender with Doctorates')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Gender'], hue = dfplot['Identify'])","b9e3ace6":"dfcountry = df.groupby(['Q3','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfcountry.columns = ['Country','Identify', 'Count']\n\n\nplt.figure(figsize=(12,16))\nplt.title('Self Identification by Country')\nax = sns.barplot(x = dfcountry['Count'], y = dfcountry['Country'], hue = dfcountry['Identify'])\n\n","c7128569":"dfcountry = df.groupby(['Q3','selfgroupid']).size().sort_values(ascending = False)\ndfplot  = dfcountry.groupby(level=[0]).apply(lambda x: x \/ x.sum()).reset_index()\ncountriestouse = ['United States of America','India','Australia','China','Brazil','Canada', 'Japan','Singapore','Romania']\n\ndfplot = dfplot[(dfplot['selfgroupid'] == 'Identify as Data Scientist') & (dfplot['Q3'].isin(countriestouse))]\ndfplot.columns = ['Country','Identify', 'Percent']\n\n\nplt.figure(figsize=(12,8))\nplt.title('Percentage of Kagglers by Country that identify as Data Scientist')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Country'])\n\n\n","599bac0f":"employmentgroups = ['Data Scientist','Software Engineer','Student',\n                    'Not employed','Consultant','Business Analyst',\n                   'Data Engineer','Research Assistant','Manager ']\n\ndfemployment = df.groupby(['Q6','selfgroupid']).size()\ndfemployment   = dfemployment.groupby(level=[0]).apply(lambda x: x \/ x.sum()).rename('Percent').reset_index().sort_values('Percent', ascending = False)\ndfplot  = dfemployment[(dfemployment['selfgroupid'] == 'Identify as Data Scientist')].head(5)\ndfplot.columns = ['Employment', 'Identify', 'Percent']\nplt.figure(figsize=(12,8))\nplt.title('Percentage of Kagglers by Occupation that identify as Data Scientist')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Employment'])","311d9c7f":"dfemployment = df.groupby(['Q6','selfgroupid']).size()\ndfemployment   = dfemployment.groupby(level=[0]).apply(lambda x: x \/ x.sum()).rename('Percent').reset_index()\ndfplot  = dfemployment[(dfemployment['selfgroupid'] == 'Identify as Data Scientist')].sort_values('Percent', ascending = True).head(5)\ndfplot.columns = ['Employment', 'Identify', 'Percent']\nplt.figure(figsize=(12,7))\nplt.title('Percentage of Kagglers by Occupation that identify as Data Scientist')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Employment'])","38276dba":"dfemployment = df.groupby(['Q2','selfgroupid']).size()\ndfemployment   = dfemployment.groupby(level=[0]).apply(lambda x: x \/ x.sum()).rename('Percent').reset_index()\ndfplot  = dfemployment[(dfemployment['selfgroupid'] == 'Identify as Data Scientist')].sort_values('Percent', ascending = False).head(5)\ndfplot.columns = ['Employment', 'Identify', 'Percent']\nplt.figure(figsize=(12,7))\nplt.title('Percentage of Kagglers by Age that identify as Data Scientist')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Employment'])","91f18399":"dfplot = df.groupby(['Q2','selfgroupid']).size().sort_values(ascending = False).reset_index()\n# dfemployment   = dfemployment.groupby(level=[0]).apply(lambda x: x \/ x.sum()).rename('Percent').reset_index()\n# dfplot  = dfemployment[(dfemployment['selfgroupid'] == 'Identify as Data Scientist')].sort_values(ascending = True).reset_index().head(5)\ndfplot.columns = ['Age Group', 'Identify', 'Percent']\nplt.figure(figsize=(12,7))\nplt.title('Count of Kagglers by Age Group that identify as Data Scientist')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Age Group'], hue = dfplot['Identify'])\n","35ed45d3":"dfemployment = df.groupby(['Q2','selfgroupid']).size()\ndfemployment   = dfemployment.groupby(level=[0]).apply(lambda x: x \/ x.sum()).rename('Percent').reset_index()\ndfplot  = dfemployment[(dfemployment['selfgroupid'] == 'Identify as Data Scientist')].sort_values('Percent', ascending = True).head(5)\ndfplot.columns = ['Age Group', 'Identify', 'Percent']\nplt.figure(figsize=(12,7))\nplt.title('Percentage of Kagglers by Age Group that identify as Data Scientist')\nax = sns.barplot(y = dfplot['Percent'], x = dfplot['Age Group'])","750a8374":"dfrecommendedlanguage = df.groupby(['Q23','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['Percent Group', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Approximately what percent of your time at work or school is spent actively coding?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['Percent Group'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","7b173099":"dfrecommendedlanguage = df.groupby(['Q39_Part_1','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Perceive the quality of online learning platforms and in-person bootcamps as compared to the quality of the education provided by traditional brick and mortar institutions? ')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","0db7f224":"dfplot = df.groupby(['Q9','selfgroupid']).size().sort_values(ascending = False).reset_index().head(28)\n# dfemployment   = dfemployment.groupby(level=[0]).apply(lambda x: x \/ x.sum()).rename('Percent').reset_index()\n# dfplot  = dfemployment[(dfemployment['selfgroupid'] == 'Identify as Data Scientist')].sort_values(ascending = True).reset_index().head(5)\ndfplot.columns = ['Yearly Compensation', 'Identify', 'Percent']\nplt.figure(figsize=(12,7))\nplt.title('Count of Kagglers by Yearly Income that identify as Data Scientist')\nax = sns.barplot(x = dfplot['Percent'], y = dfplot['Yearly Compensation'], hue = dfplot['Identify'])","6f645ee8":"dfplot = df.groupby(['Q10','selfgroupid']).size().sort_values(ascending = False).reset_index().head(28)\n# dfemployment   = dfemployment.groupby(level=[0]).apply(lambda x: x \/ x.sum()).rename('Percent').reset_index()\n# dfplot  = dfemployment[(dfemployment['selfgroupid'] == 'Identify as Data Scientist')].sort_values(ascending = True).reset_index().head(5)\ndfplot.columns = ['', 'Identify', 'Percent']\nplt.figure(figsize=(12,7))\nplt.title('Does your current employer incorporate machine learning methods into their business?')\nax = sns.barplot(x = dfplot['Percent'], y = dfplot[''], hue = dfplot['Identify'])","fcd05ab4":"dfrecommendedlanguage = df.groupby(['Q37','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['Online Platform', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('On which online platform have you spent the most amount of time? ')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['Online Platform'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","152b66b2":"workcolumns = ['', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q38_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q38_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q38_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q38_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q38_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q38_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q38_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q38_Part_11','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_12','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_14','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q38_Part_15','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_16','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_17','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q38_Part_18','selfgroupid',workcolumns),                   \n#                    groupbydataforgraph('Q38_Part_19','selfgroupid',workcolumns),\n#                    groupbydataforgraph('Q38_Part_20','selfgroupid',workcolumns),\n#                    groupbydataforgraph('Q38_Part_21','selfgroupid',workcolumns)              \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('Who\/what are your favorite media sources that report on data science topics?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE[''], hue = dfIDE['Identify'])","f61c72a2":"dfrecommendedlanguage = df.groupby(['Q39_Part_2','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('How do you perceive the quality of online learning platforms and in-person bootcamps as compared to the quality of the education provided by traditional brick and mortar institutions?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage[''], hue = dfrecommendedlanguage['Identify'])","4a32ae7e":"df['Q24'] = df['Q24'].str.wrap(20)\n\ndfrecommendedlanguage = df.groupby(['Q24','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('How long have you been writing code to analyze data?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","19b1f50e":"df['Q40'] = df['Q40'].str.wrap(30)\ndfrecommendedlanguage = df.groupby(['Q40','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Which better demonstrates expertise in data science: academic achievements or independent projects?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","665ad5b1":"df['Q35_Part_1cat'] = df.apply(lambda row: update_percentcat(row['Q35_Part_1']), axis = 1)\ndf['Q35_Part_2cat'] = df.apply(lambda row: update_percentcat(row['Q35_Part_2']), axis = 1)\ndf['Q35_Part_3cat'] = df.apply(lambda row: update_percentcat(row['Q35_Part_3']), axis = 1)\ndf['Q35_Part_4cat'] = df.apply(lambda row: update_percentcat(row['Q35_Part_4']), axis = 1)\ndf['Q35_Part_5cat'] = df.apply(lambda row: update_percentcat(row['Q35_Part_5']), axis = 1)\ndf['Q35_Part_6cat'] = df.apply(lambda row: update_percentcat(row['Q35_Part_6']), axis = 1)\n\ndfInfluenceProducts = df.groupby(['Q35_Part_1cat','selfgroupid']).size().reset_index()\ndfInfluenceProducts.columns = ['Percent', 'Identify', 'Count']\ndfInfluenceProducts['Category'] = 'Self-Taught'\ndfWorkflows = df.groupby(['Q35_Part_2cat','selfgroupid']).size().reset_index()\ndfWorkflows.columns = ['Percent', 'Identify', 'Count']\ndfWorkflows['Category'] = 'Online'\ndfinfrastructure = df.groupby(['Q35_Part_3cat','selfgroupid']).size().reset_index()\ndfinfrastructure.columns = ['Percent', 'Identify', 'Count']\ndfinfrastructure['Category'] = 'Work'\ndfprototype = df.groupby(['Q35_Part_4cat','selfgroupid']).size().reset_index()\ndfprototype.columns = ['Percent', 'Identify', 'Count']\ndfprototype['Category'] = 'University'\ndfresearch = df.groupby(['Q35_Part_5cat','selfgroupid']).size().reset_index()\ndfresearch.columns = ['Percent', 'Identify', 'Count']\ndfresearch['Category'] = 'Kaggle Competitions'\ndfnoneactivities = df.groupby(['Q35_Part_6cat','selfgroupid']).size().reset_index()\ndfnoneactivities.columns = ['Percent', 'Identify', 'Count']\ndfnoneactivities['Category'] = 'Other'\n\n\ndfrole = pd.concat([dfWorkflows,  dfprototype, dfInfluenceProducts,  dfresearch, dfinfrastructure,  dfnoneactivities], ignore_index=True)\ndfrole2 = dfrole[(dfrole['Percent'] != '')]\n\n\nplt.figure(figsize=(11,7))\nplt.title('What percentage of your current machine learning\/data science training falls under each category?')\n\n\nax = sns.lineplot(y = dfrole2['Count'], x = dfrole2['Percent'], hue = dfrole2['Category'])","c0fe4003":"plt.figure(figsize=(11,7))\n# plt.title('Select any activities that make up an important part of your role at work')\ng = sns.catplot(x=\"Category\", y=\"Count\",\n                hue=\"Percent\", col=\"Identify\",\n                 data=dfrole2, kind=\"point\",\n                height=6,  aspect=1.6);","43accdcc":"# Questions relating to modelling are\n# Select any activities that make up an important part of your role at work:\n# Approximately what percent of your time at work or school is spent actively coding?\n# During a typical data science project at work or school, approximately what proportion of your time is devoted to the following?\n# What percentage of your current machine learning\/data science training falls under each category?\n# What metrics do you or your organization use to determine whether or not your models were successful?\n# In what circumstances would you explore model insights and interpret your model's predictions? \n# Approximately what percent of your data projects involve exploring model insights?\n# What methods do you prefer for explaining and\/or interpreting decisions that are made by ML models?\n# Do you consider ML models to be \"black boxes\" with outputs that are difficult or impossible to explain?\n\n","da5aacb9":"word_could_dict=Counter(my_listModel)\n\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          \n                          max_words=250,\n                          max_font_size=None, \n                          repeat=False,\n                          mask=thoughtbubble_mask ,\n                          random_state=42,\n                          stopwords=['that','the']\n                         ).fit_words(word_could_dict)\n\n\nplt.figure(figsize=(11,11))\nplt.imshow(wordcloud) #, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","094b9c4a":"\ndf['Q11_Part_1'] = df['Q11_Part_1'].str.wrap(30)\ndf['Q11_Part_2'] = df['Q11_Part_2'].str.wrap(30)\ndf['Q11_Part_3'] = df['Q11_Part_3'].str.wrap(30)\ndf['Q11_Part_4'] = df['Q11_Part_4'].str.wrap(30)\ndf['Q11_Part_5'] = df['Q11_Part_5'].str.wrap(30)\ndf['Q11_Part_6'] = df['Q11_Part_6'].str.wrap(30)\n\ndfInfluenceProducts = df.groupby(['Q11_Part_1','selfgroupid']).size().reset_index()\ndfInfluenceProducts.columns = ['Role', 'Identify', 'Count']\ndfWorkflows = df.groupby(['Q11_Part_2','selfgroupid']).size().reset_index()\ndfWorkflows.columns = ['Role', 'Identify', 'Count']\ndfinfrastructure = df.groupby(['Q11_Part_3','selfgroupid']).size().reset_index()\ndfinfrastructure.columns = ['Role', 'Identify', 'Count']\ndfprototype = df.groupby(['Q11_Part_4','selfgroupid']).size().reset_index()\ndfprototype.columns = ['Role', 'Identify', 'Count']\ndfresearch = df.groupby(['Q11_Part_5','selfgroupid']).size().reset_index()\ndfresearch.columns = ['Role', 'Identify', 'Count']\ndfnoneactivities = df.groupby(['Q11_Part_6','selfgroupid']).size().reset_index()\ndfnoneactivities.columns = ['Role', 'Identify', 'Count']\n\n\ndfrole = pd.concat([dfWorkflows,  dfprototype, dfInfluenceProducts,  dfresearch, dfinfrastructure,  dfnoneactivities], ignore_index=True)\n\nplt.figure(figsize=(11,9))\nplt.title('Select any activities that make up an important part of your role at work')\n\n\nax = sns.barplot(x = dfrole['Count'], y = dfrole['Role'], hue = dfrole['Identify'])\n","b5bc1f9f":"workcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q42_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q42_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q42_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q42_Part_4','selfgroupid',workcolumns)            \n                   ], ignore_index=True)\n\n\nplt.figure(figsize=(12,8))\nplt.title('What metrics do you or your organization use to determine whether or not your models were successful?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","f1d3daf2":"dfrecommendedlanguage = df.groupby(['Q41_Part_3','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\n\nplt.figure(figsize=(8,7))\nplt.title('Importance of Reproducibility in data science')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","b31c874a":"df['Q49_Part_1'] = df['Q49_Part_1'].str.wrap(30)\ndf['Q49_Part_2'] = df['Q49_Part_2'].str.wrap(30)\ndf['Q49_Part_3'] = df['Q49_Part_3'].str.wrap(30)\ndf['Q49_Part_4'] = df['Q49_Part_4'].str.wrap(30)\ndf['Q49_Part_5'] = df['Q49_Part_5'].str.wrap(30)\ndf['Q49_Part_11'] = df['Q49_Part_11'].str.wrap(30)\n\n\n\n\n\n\nworkcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q49_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q49_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q49_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q49_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q49_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q49_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q49_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q49_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q49_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q49_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q49_Part_11','selfgroupid',workcolumns)                  \n\n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,12))\nplt.title('What tools and methods do you use to make your work easy to reproduce? ')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","1c541388":"dfrecommendedlanguage = df.groupby(['Q46','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Approximately what percent of your data projects involve exploring model insights?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","287f9d11":"df['Q45_Part_1'] = df['Q45_Part_1'].str.wrap(30)\ndf['Q45_Part_2'] = df['Q45_Part_2'].str.wrap(30)\ndf['Q45_Part_3'] = df['Q45_Part_3'].str.wrap(30)\ndf['Q45_Part_4'] = df['Q45_Part_4'].str.wrap(30)\ndf['Q45_Part_5'] = df['Q45_Part_5'].str.wrap(30)\ndf['Q45_Part_6'] = df['Q45_Part_6'].str.wrap(30)\n\n\n\nworkcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q45_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q45_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q45_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q45_Part_4','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q45_Part_5','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q45_Part_6','selfgroupid',workcolumns) \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('In what circumstances would you explore model insights and interpret your models predictions? ')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","56272941":"df['Q50_Part_3'] = df['Q50_Part_3'].str.wrap(30)\ndf['Q50_Part_4'] = df['Q50_Part_4'].str.wrap(30)\ndf['Q50_Part_5'] = df['Q50_Part_5'].str.wrap(30)\ndf['Q50_Part_6'] = df['Q50_Part_6'].str.wrap(30)\n\nworkcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q50_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q50_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q50_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q50_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q50_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q50_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q50_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q50_Part_8','selfgroupid',workcolumns)                 \n\n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('What barriers prevent you from making your work even easier to reuse and reproduce?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","2f867bae":"df['Q34_Part_1cat'] = df.apply(lambda row: update_percentcat(row['Q34_Part_1']), axis = 1)\ndf['Q34_Part_2cat'] = df.apply(lambda row: update_percentcat(row['Q34_Part_2']), axis = 1)\ndf['Q34_Part_3cat'] = df.apply(lambda row: update_percentcat(row['Q34_Part_3']), axis = 1)\ndf['Q34_Part_4cat'] = df.apply(lambda row: update_percentcat(row['Q34_Part_4']), axis = 1)\ndf['Q34_Part_5cat'] = df.apply(lambda row: update_percentcat(row['Q34_Part_5']), axis = 1)\ndf['Q34_Part_6cat'] = df.apply(lambda row: update_percentcat(row['Q34_Part_6']), axis = 1)\n\n\ndfInfluenceProducts = df.groupby(['Q34_Part_1cat','selfgroupid']).size().reset_index()\ndfInfluenceProducts.columns = ['Percent', 'Identify', 'Count']\ndfInfluenceProducts['Category'] = 'Gathering Data'\ndfWorkflows = df.groupby(['Q34_Part_2cat','selfgroupid']).size().reset_index()\ndfWorkflows.columns = ['Percent', 'Identify', 'Count']\ndfWorkflows['Category'] = 'Cleaning Data'\ndfinfrastructure = df.groupby(['Q34_Part_3cat','selfgroupid']).size().reset_index()\ndfinfrastructure.columns = ['Percent', 'Identify', 'Count']\ndfinfrastructure['Category'] = 'Visualizing data'\ndfprototype = df.groupby(['Q34_Part_4cat','selfgroupid']).size().reset_index()\ndfprototype.columns = ['Percent', 'Identify', 'Count']\ndfprototype['Category'] = 'Model Selection'\ndfresearch = df.groupby(['Q34_Part_5cat','selfgroupid']).size().reset_index()\ndfresearch.columns = ['Percent', 'Identify', 'Count']\ndfresearch['Category'] = 'Model into production'\ndfnoneactivities = df.groupby(['Q34_Part_6cat','selfgroupid']).size().reset_index()\ndfnoneactivities.columns = ['Percent', 'Identify', 'Count']\ndfnoneactivities['Category'] = 'Finding Insights'\n\n\ndfrole = pd.concat([dfWorkflows,  dfprototype, dfInfluenceProducts,  dfresearch, dfinfrastructure,  dfnoneactivities], ignore_index=True)\ndfrole2 = dfrole[(dfrole['Percent'] != '')]\n\n\nplt.figure(figsize=(11,7))\nplt.title('Select any activities that make up an important part of your role at work')\n\n\nax = sns.lineplot(y = dfrole2['Count'], x = dfrole2['Percent'], hue = dfrole2['Category'])","a90fc32d":"dfplot = df.groupby(['Q34_Part_1','selfgroupid']).size().reset_index()\ndfplot.columns = ['Percent', 'Identify', 'Count']\n\nplt.figure(figsize=(11,7))\n# plt.title('Select any activities that make up an important part of your role at work')\ng = sns.catplot(x=\"Percent\", y=\"Count\",\n                hue=\"Category\", col=\"Identify\",\n                 data=dfrole2, kind=\"bar\",\n                height=6,  aspect=1.6);","d58e4f02":"# What is the primary tool that you use at work or school to analyze data? \n# Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? \n# Which of the following hosted notebooks have you used at work or school in the last 5 years? \n# Which of the following cloud computing services have you used at work or school in the last 5 years?\n# Which of the following cloud computing services have you used at work or school in the last 5 years?\n# What specific programming language do you use most often? - Selected Choice\n# What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice\n# Which of the following cloud computing products have you used at work or school in the last 5 years \n# What tools and methods do you use to make your work easy to reproduce? \n","5caa7d53":"\nword_could_dict=Counter(my_listTools)\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=250,\n                          max_font_size=None, \n                          repeat=False,\n                          mask=thoughtbubble_mask ,\n                          random_state=42\n                         ).fit_words(word_could_dict)\n\n\nplt.figure(figsize=(11,14))\nplt.title('Word Cloud of Answers relating to Tools\/Skills Questions')\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","e7d1002f":"df['Q12_MULTIPLE_CHOICE'] = df['Q12_MULTIPLE_CHOICE'].str.wrap(30)\ndfprimarytool = df[(df['Q12_MULTIPLE_CHOICE'] != 'Other')].groupby(['Q12_MULTIPLE_CHOICE','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfprimarytool.columns = ['PrimaryTool', 'Identify', 'Count']\n\nplt.figure(figsize=(17,7))\nplt.title('What is the primary tool that you use at work or school to analyze data?')\nax = sns.barplot(y = dfprimarytool['Count'], x = dfprimarytool['PrimaryTool'], hue = dfprimarytool['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","02e647ec":"\nworkcolumns = ['IDE', 'Identify', 'Count']\n\ndfIDE = pd.concat([groupbydataforgraph('Q13_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q13_Part_2','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q13_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q13_Part_13','selfgroupid',workcolumns),               \n                   groupbydataforgraph('Q13_Part_6','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q13_Part_7','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q13_Part_9','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q13_Part_10','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q13_Part_11','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q13_Part_12','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q13_Part_4','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q13_Part_8','selfgroupid',workcolumns) \n                    \n                   \n                   \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(11,9))\nplt.title('Which of the following integrated development environments (IDEs) have you used at work or school in the last 5 years?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['IDE'], hue = dfIDE['Identify'])","964c1aeb":"workcolumns = ['Hosted Notebooks', 'Identify', 'Count']\n\ndfIDE = pd.concat([groupbydataforgraph('Q14_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q14_Part_2','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q14_Part_3','selfgroupid',workcolumns), \n#                    groupbydataforgraph('Q14_Part_4','selfgroupid',workcolumns),               \n                   groupbydataforgraph('Q14_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q14_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q14_Part_7','selfgroupid',workcolumns),                      \n#                    groupbydataforgraph('Q14_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q14_Part_9','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q14_Part_10','selfgroupid',workcolumns)\n                   \n                   \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('Which of the following hosted notebooks have you used at work or school in the last 5 years? ')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['Hosted Notebooks'], hue = dfIDE['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=33)","3a64ba2c":"workcolumns = ['Cloud', 'Identify', 'Count']\n\ndfIDE = pd.concat([groupbydataforgraph('Q15_Part_2','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q15_Part_1','selfgroupid',workcolumns), \n                   \n                   groupbydataforgraph('Q15_Part_3','selfgroupid',workcolumns), \n#                    groupbydataforgraph('Q15_Part_4','selfgroupid',workcolumns),               \n                   groupbydataforgraph('Q15_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q15_Part_6','selfgroupid',workcolumns) \n\n                   \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('Which of the following cloud computing services have you used at work or school in the last 5 years?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['Cloud'], hue = dfIDE['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=33)","3df05b2f":"workcolumns = ['default', 'Identify', 'Count']\n\ndfIDE = pd.concat([                   groupbydataforgraph('Q27_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q27_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q27_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q27_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q27_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q27_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q27_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q27_Part_11','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_12','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_14','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q27_Part_15','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_16','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_17','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_18','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q27_Part_19','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q27_Part_20','selfgroupid',workcolumns)                \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,14))\nplt.title('Which of the following cloud computing products have you used at work or school in the last 5 years')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","a782e096":"workcolumns = ['Programming', 'Identify', 'Count']\n\ndfIDE = pd.concat([groupbydataforgraph('Q16_Part_2','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q16_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q16_Part_4','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q16_Part_3','selfgroupid',workcolumns), \n\n                   groupbydataforgraph('Q16_Part_9','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q16_Part_10','selfgroupid',workcolumns),\n#                    groupbydataforgraph('Q16_Part_11','selfgroupid',workcolumns), \n#                    groupbydataforgraph('Q16_Part_12','selfgroupid',workcolumns),                     \n#                    groupbydataforgraph('Q16_Part_15','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q16_Part_14','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q16_Part_7','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q16_Part_16','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q16_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q16_Part_8','selfgroupid',workcolumns),    \n               \n                   groupbydataforgraph('Q16_Part_6','selfgroupid',workcolumns),                    \n               \n                   groupbydataforgraph('Q16_Part_5','selfgroupid',workcolumns)                    \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('What programming languages do you use on a regular basis?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['Programming'], hue = dfIDE['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=43)","262c7f20":"dfprimarylanguage = df.groupby(['Q17','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfprimarylanguage.columns = ['Primarylanguage', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('What specific programming language do you use most often? ')\nax = sns.barplot(x = dfprimarylanguage['Count'], y = dfprimarylanguage['Primarylanguage'], hue = dfprimarylanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)\n","2407a64a":"dfrecommendedlanguage = df.groupby(['Q18','selfgroupid']).size().sort_values(ascending = False).reset_index().head(8)\ndfrecommendedlanguage.columns = ['Recommendedlanguage', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('What programming language would you recommend an aspiring data scientist to learn first?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['Recommendedlanguage'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)\n\n","5bd183a3":"# Questions relating to Machine Learning\n# What machine learning frameworks have you used in the past 5 years?\n# Of the choices that you selected in the previous question, which ML library have you used the most?\n# Does your current employer incorporate machine learning methods into their business?\n# Which of the following machine learning products have you used at work or school in the last 5 years? \n# What percentage of your current machine learning\/data science training falls under each category? \n# How do you perceive the importance of the following topics? \n# What do you find most difficult about ensuring that your algorithms are fair and unbiased? \n\nworkcolumns = ['Framework', 'Identify', 'Count']\n\ndfIDE = pd.concat([groupbydataforgraph('Q19_Part_2','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q19_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q19_Part_4','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q19_Part_3','selfgroupid',workcolumns), \n\n                   groupbydataforgraph('Q19_Part_9','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q19_Part_10','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q19_Part_11','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q19_Part_12','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q19_Part_15','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q19_Part_14','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q19_Part_7','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q19_Part_16','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q19_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q19_Part_8','selfgroupid',workcolumns),    \n               \n                   groupbydataforgraph('Q19_Part_6','selfgroupid',workcolumns),                    \n               \n                   groupbydataforgraph('Q19_Part_5','selfgroupid',workcolumns)                    \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('What machine learning frameworks have you used in the past 5 years?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['Framework'], hue = dfIDE['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=43)","d713dbde":"dfrecommendedlanguage = df.groupby(['Q20','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Of the choices that you selected in the previous question, which ML library have you used the most?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)\n","3638007a":"# Group up the answers into different questions types\n\n\n\ndfrecommendedlanguage = df.groupby(['Q41_Part_1','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\n\nplt.figure(figsize=(8,7))\nplt.title('Importance of Fairness and bias in ML algorithms')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","5306551c":"df['Q25'] = df['Q25'].str.wrap(20)\ndfrecommendedlanguage = df.groupby(['Q25','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('For how many years have you used machine learning methods (at work or in school)?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","77409d8b":"workcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([ groupbydataforgraph('Q28_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q28_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q28_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q28_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q28_Part_11','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_12','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_14','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q28_Part_15','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_16','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_17','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_18','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q28_Part_19','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_20','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_21','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_22','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q28_Part_23','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_24','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q28_Part_25','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_26','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_27','selfgroupid',workcolumns),  \n                   groupbydataforgraph('Q28_Part_28','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_29','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q28_Part_30','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_31','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_32','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q28_Part_33','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_34','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q28_Part_35','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_36','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q28_Part_37','selfgroupid',workcolumns),  \n                   groupbydataforgraph('Q28_Part_38','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_39','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_40','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q28_Part_41','selfgroupid',workcolumns),                 \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,14))\nplt.title('Which of the following machine learning products have you used at work or school in the last 5 years?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","320100c4":"dfrecommendedlanguage = df.groupby(['Q43','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Approximately what percent of your data projects involved exploring unfair bias in the dataset and\/or algorithm?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","298caa84":"df['Q44_Part_1'] = df['Q44_Part_1'].str.wrap(30)\ndf['Q44_Part_2'] = df['Q44_Part_2'].str.wrap(30)\ndf['Q44_Part_3'] = df['Q44_Part_3'].str.wrap(30)\ndf['Q44_Part_4'] = df['Q44_Part_4'].str.wrap(30)\ndf['Q44_Part_5'] = df['Q44_Part_5'].str.wrap(30)\ndf['Q44_Part_6'] = df['Q44_Part_6'].str.wrap(30)\n\n\nworkcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q44_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q44_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q44_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q44_Part_4','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q44_Part_5','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q44_Part_6','selfgroupid',workcolumns) \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('What do you find most difficult about ensuring that your algorithms are fair and unbiased? ')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","c879e0e3":"df['Q48'] = df['Q48'].str.wrap(30)\n\ndfrecommendedlanguage = df.groupby(['Q48','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Do you consider ML models to be \"black boxes\" with outputs that are difficult or impossible to explain?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","ef6fd3de":"dfrecommendedlanguage = df.groupby(['Q41_Part_2','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(8,7))\nplt.title('Importance of Being able to explain ML model outputs and\/or predictions')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","7c9e1d09":"workcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q47_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q47_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q47_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q47_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q47_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q47_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q47_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q47_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q47_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q47_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q47_Part_11','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q47_Part_12','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q47_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q47_Part_14','selfgroupid',workcolumns)                   \n\n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('What methods do you prefer for explaining and\/or interpreting decisions that are made by ML models? ')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","dfb33652":"word_could_dict=Counter(my_listData)\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=250,\n                          max_font_size=None, \n                          repeat=False,\n                          mask=thoughtbubble_mask ,\n                          random_state=42\n                         ).fit_words(word_could_dict)\n\n\nplt.figure(figsize=(11,11))\nplt.title('If we have data, let\u2019s look at data. If all we have are opinions, let\u2019s go with mine. \u2013 Jim Barksdale,')\n\nplt.imshow(wordcloud) #, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","19eb7de9":"# Questions relating to Data\n# What data visualization libraries or tools have you used in the past 5 years?\n# Which of the following relational database products have you used at work or school in the last 5 years? \n# Which of the following big data and analytics products have you used at work or school in the last 5 years?\n# Which types of data do you currently interact with most often at work or school?\n# Where do you find public datasets?\n# Approximately what percent of your data projects involved exploring unfair bias in the dataset and\/or algorithm?\n","514bc94b":"workcolumns = ['default', 'Identify', 'Count']\n\ndfIDE = pd.concat([groupbydataforgraph('Q21_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q21_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q21_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q21_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q21_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q21_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q21_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q21_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q21_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q21_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q21_Part_11','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q21_Part_12','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q21_Part_13','selfgroupid',workcolumns)                    \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('What Data visualization libraries or tools have you used in the past 5 years? ')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","50ab2f63":"dfrecommendedlanguage = df.groupby(['Q22','selfgroupid']).size().sort_values(ascending = False).reset_index()\ndfrecommendedlanguage.columns = ['default', 'Identify', 'Count']\n\nplt.figure(figsize=(11,9))\nplt.title('Of the choices that you selected in the previous question, which specific data visualization library or tool have you used the most?')\nax = sns.barplot(x = dfrecommendedlanguage['Count'], y = dfrecommendedlanguage['default'], hue = dfrecommendedlanguage['Identify'])\n# plt.setp(ax.get_xticklabels(), rotation=75)","84e2a769":"workcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q29_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q29_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q29_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q29_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q29_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q29_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q29_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q29_Part_11','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_12','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_14','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q29_Part_15','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_16','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_17','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_18','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q29_Part_19','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_20','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_21','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q29_Part_22','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q29_Part_23','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q29_Part_24','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q29_Part_25','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q29_Part_26','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q29_Part_27','selfgroupid',workcolumns)                  \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,14))\nplt.title('Which of the following relational database products have you used at work or school in the last 5 years?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","443e2261":"workcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q30_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q30_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q30_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q30_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q30_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q30_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q30_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q30_Part_11','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_12','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_13','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_14','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q30_Part_15','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_16','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_17','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_18','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q30_Part_19','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_20','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q30_Part_21','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q30_Part_22','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q30_Part_23','selfgroupid',workcolumns)                 \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,14))\nplt.title('Which of the following big data and analytics products have you used at work or school in the last 5 years?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","d88be763":"workcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q31_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q31_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q31_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q31_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q31_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q31_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q31_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q31_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q31_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q31_Part_10','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q31_Part_11','selfgroupid',workcolumns)                 \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('Which types of data do you currently interact with most often at work or school?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","03c36ba1":"df['Q33_Part_4'] = df['Q33_Part_4'].str.wrap(30)\ndf['Q33_Part_5'] = df['Q33_Part_5'].str.wrap(30)\ndf['Q33_Part_6'] = df['Q33_Part_6'].str.wrap(30)\n\nworkcolumns = ['default', 'Identify', 'Count']\ndfIDE = pd.concat([groupbydataforgraph('Q33_Part_1','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q33_Part_2','selfgroupid',workcolumns),                   \n                   groupbydataforgraph('Q33_Part_3','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q33_Part_4','selfgroupid',workcolumns),                      \n                   groupbydataforgraph('Q33_Part_5','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q33_Part_6','selfgroupid',workcolumns), \n                   groupbydataforgraph('Q33_Part_7','selfgroupid',workcolumns),                     \n                   groupbydataforgraph('Q33_Part_8','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q33_Part_9','selfgroupid',workcolumns),\n                   groupbydataforgraph('Q33_Part_10','selfgroupid',workcolumns)               \n                   ], ignore_index=True)\n\n\n\nplt.figure(figsize=(12,8))\nplt.title('Where do you find public datasets?')\nax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","1a6147c8":"\n# maybe do a violin for 34 and 35\n\n\nworkcolumns = ['percentwork', 'Identify', 'Count']\n\ndfgatheringdata =  groupbydataforgraph('Q34_Part_1','selfgroupid',workcolumns)\ndfgatheringdata['typework'] = 'GatheringData'\ndfcleaningdata =  groupbydataforgraph('Q34_Part_2','selfgroupid',workcolumns)\ndfcleaningdata['typework'] = 'CleaningData'\n\ndfgatheringdata.head(20)\ndfIDE = pd.concat([ dfgatheringdata, dfcleaningdata     ], ignore_index=True)\n\n# with sns.axes_style(style=None):\n#     sns.violinplot(\"age_dec\", \"split_frac\", hue=\"gender\", data=data,\n#                    split=True, inner=\"quartile\",\n#                    palette=[\"lightblue\", \"lightpink\"]);\n\n# plt.figure(figsize=(12,8))\n# ax = sns.barplot(x = dfIDE['Count'], y = dfIDE['default'], hue = dfIDE['Identify'])","9c750120":"\ndfGender = df[((df['Q1'] == 'Male') & (df['selfgroupid'] == 'Identify as Data Scientist'))].groupby(['Q1','selfgroupid']).size().reset_index()\ndfGender.columns = ['default', 'Identify', 'Count']\ndfGender['Category'] = 'Personal'\ndfAge = df[((df['Q2'] == '25-29') & (df['selfgroupid'] == 'Identify as Data Scientist'))].groupby(['Q2','selfgroupid']).size().reset_index()\ndfAge.columns = ['default', 'Identify', 'Count']\ndfAge['Category'] = 'Personal'\ndfAge.iloc[0,0] = 'Age 25-29'\ndfCountry = df[((df['Q3'] == 'United States of America') & (df['selfgroupid'] == 'Identify as Data Scientist'))].groupby(['Q3','selfgroupid']).size().reset_index()\ndfCountry.columns = ['default', 'Identify', 'Count']\ndfCountry['Category'] = 'Personal'\ndfeducation = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q4','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfeducation.columns = ['default', 'Identify', 'Count']\ndfeducation['Category'] = 'Personal'\ndfemployed = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q6','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfemployed.columns = ['default', 'Identify', 'Count']\ndfemployed['Category'] = 'Personal'\ndfemployed.iloc[0,0] = 'Employed as Data Scientist'\ndfcoding = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q23','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfcoding.columns = ['default', 'Identify', 'Count']\ndfcoding['Category'] = 'Personal'\ndfcoding.iloc[0,0] = '50% to 70% Coding'\ndfonline = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q38_Part_4','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfonline.columns = ['default', 'Identify', 'Count']\ndfonline['Category'] = 'Personal'\ndftimeml = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q37','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndftimeml.columns = ['default', 'Identify', 'Count']\ndftimeml['Category'] = 'Personal'\ndfuseml = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q10','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfuseml.columns = ['default', 'Identify', 'Count']\ndfuseml['Category'] = 'Personal'\ndfonlineplatform = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q24','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfonlineplatform.columns = ['default', 'Identify', 'Count']\ndfonlineplatform['Category'] = 'Personal'\n\n\n\ndfPersonal = pd.concat([dfGender,dfAge,dfCountry,dfeducation,dfemployed,dfcoding,dfonline,dftimeml,dfuseml,dfonlineplatform], ignore_index=True)\ndfplot = dfPersonal.sort_values(by=['Count'], ascending = False)\nplt.figure(figsize=(11,9))\nplt.title('Comparison of most common personal attributes that consider themselves as Data Scientists')\n\n\nax = sns.barplot(x = dfplot['Count'], y = dfplot['default'])","25b5e9ba":"dfQ12_MULTIPLE_CHOICE = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q12_MULTIPLE_CHOICE','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ12_MULTIPLE_CHOICE.columns = ['default', 'Identify', 'Count']\ndfQ12_MULTIPLE_CHOICE['Category'] = 'Tools'\ndfQ13_Part_1 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q13_Part_1','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ13_Part_1.columns = ['default', 'Identify', 'Count']\ndfQ13_Part_1['Category'] = 'Tools'\ndfQ14_Part_1 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q14_Part_1','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ14_Part_1.columns = ['default', 'Identify', 'Count']\ndfQ14_Part_1['Category'] = 'Tools'\ndfQ15_Part_2 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q15_Part_2','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ15_Part_2.columns = ['default', 'Identify', 'Count']\ndfQ15_Part_2['Category'] = 'Tools'\ndfQ17 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q17','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ17.columns = ['default', 'Identify', 'Count']\ndfQ17['Category'] = 'Tools'\ndfrecommendlanguage = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q18','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfrecommendlanguage.columns = ['default', 'Identify', 'Count']\ndfrecommendlanguage['Category'] = 'Tools'\ndfrecommendlanguage.iloc[0,0] = 'Recommneded Python'\n\ndfTools = pd.concat([dfQ15_Part_2,dfQ12_MULTIPLE_CHOICE,dfQ13_Part_1,dfQ14_Part_1,dfQ17,dfrecommendlanguage], ignore_index=True)\ndfplot = dfTools.sort_values(by=['Count'], ascending = False)\nplt.figure(figsize=(11,9))\nplt.title('Comparison of most common Languages and Software attributes that consider themselves as Data Scientists')\n\nax = sns.barplot(x = dfplot['Count'], y = dfplot['default'])\n","aa71851f":"dfQ31_Part_6 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q31_Part_6','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ31_Part_6.columns = ['default', 'Identify', 'Count']\ndfQ31_Part_6['Category'] = 'Data'\ndfQ21_Part_2 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q21_Part_2','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ21_Part_2.columns = ['default', 'Identify', 'Count']\ndfQ21_Part_2['Category'] = 'Data'\ndfQ29_Part_10 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q29_Part_10','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ29_Part_10.columns = ['default', 'Identify', 'Count']\ndfQ29_Part_10['Category'] = 'Data'\ndfQ30_Part_10 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q30_Part_10','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ30_Part_10.columns = ['default', 'Identify', 'Count']\ndfQ30_Part_10['Category'] = 'Data'\n# dfQ17 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q17','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\n# dfQ17.columns = ['default', 'Identify', 'Count']\n# dfQ17['Category'] = 'Personal'\ndfQ33_Part_4 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q33_Part_4','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ33_Part_4.columns = ['default', 'Identify', 'Count']\ndfQ33_Part_4['Category'] = 'Data'\ndfQ33_Part_4.iloc[0,0] = 'Use Data Aggregrator'\n\ndfData = pd.concat([dfQ31_Part_6,dfQ21_Part_2,dfQ29_Part_10,dfQ30_Part_10,dfQ33_Part_4], ignore_index=True)\ndfplot = dfData.sort_values(by=['Count'], ascending = False)\nplt.figure(figsize=(11,9))\nplt.title('Most common Data attributes that consider themselves as Data Scientists')\nplt.ylabel('')\nax = sns.barplot(x = dfplot['Count'], y = dfplot['default'])","486ea167":"dfreproducityimportance = df[((df['Q41_Part_3'] == 'Very important') & (df['selfgroupid'] == 'Identify as Data Scientist'))].groupby(['Q41_Part_3','selfgroupid']).size().reset_index()\ndfreproducityimportance.columns = ['default', 'Identify', 'Count']\ndfreproducityimportance.iloc[0,0] = 'Reproducity is very important'\ndfreproducityimportance['Category'] = 'Model'\ndfQ49_Part_6 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q49_Part_6','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ49_Part_6.columns = ['default', 'Identify', 'Count']\ndfQ49_Part_6['Category'] = 'Model'\ndfpercentmodelinsight = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q46','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfpercentmodelinsight.columns = ['default', 'Identify', 'Count']\ndfpercentmodelinsight.iloc[0,0] = '10-20% Project is Model Insights'\ndfpercentmodelinsight['Category'] = 'Model'\ndfbarriertoreproceduce = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q50_Part_2','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfbarriertoreproceduce.columns = ['default', 'Identify', 'Count']\ndfbarriertoreproceduce.iloc[0,0] = 'Barrier to reproduce is its time consuming'\ndfbarriertoreproceduce['Category'] = 'Model'\ndfmetrics = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q42_Part_1','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfmetrics.columns = ['default', 'Identify', 'Count']\ndfmetrics['Category'] = 'Model'\ndfmlwork = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q11_Part_3','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfmlwork.columns = ['Model', 'Identify', 'Count']\ndfmlwork['Category'] = 'Personal'\n\n\n\ndfModel = pd.concat([dfreproducityimportance,dfpercentmodelinsight,dfQ49_Part_6,dfbarriertoreproceduce,dfmetrics,dfmlwork], ignore_index=True)\ndfplot = dfModel.sort_values(by=['Count'], ascending = False)\nplt.figure(figsize=(11,9))\nplt.title('Comparison of most common Model attributes that consider themselves as Data Scientists')\n\n\nax = sns.barplot(x = dfplot['Count'], y = dfplot['default'])","a6db7d73":"dfQ28_Part_19 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q28_Part_19','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ28_Part_19.columns = ['default', 'Identify', 'Count']\ndfQ28_Part_19['Category'] = 'Machine Learning'\ndfQ43 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q43','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ43.columns = ['default', 'Identify', 'Count']\ndfQ43.iloc[0,0] = '0-10% exploring unfair bias'\ndfQ43['Category'] = 'Machine Learning'\ndfQ48 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q48','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ48.columns = ['default', 'Identify', 'Count']\ndfQ48['Category'] = 'Machine Learning'\ndfQ47_Part_8 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q47_Part_8','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ47_Part_8.columns = ['default', 'Identify', 'Count']\ndfQ47_Part_8['Category'] = 'Machine Learning'\ndfQ25 = df[((df['Q25'] == '1-2 years') & (df['selfgroupid'] == 'Identify as Data Scientist'))].groupby(['Q25','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ25.columns = ['default', 'Identify', 'Count']\ndfQ25.iloc[0,0] = '1-2 years using ML'\ndfQ25['Category'] = 'Machine Learning'\ndfQ19_Part_1 = df[(df['selfgroupid'] == 'Identify as Data Scientist')].groupby(['Q19_Part_1','selfgroupid']).size().sort_values(ascending = False).head(1).reset_index()\ndfQ19_Part_1.columns = ['default', 'Identify', 'Count']\ndfQ19_Part_1['Category'] = 'Machine Learningl'\n\n\ndfMachineLearning = pd.concat([dfQ28_Part_19,dfQ19_Part_1,dfQ47_Part_8,dfQ48,dfQ43,dfQ25], ignore_index=True)\ndfplot = dfMachineLearning.sort_values(by=['Count'], ascending = False)\nplt.figure(figsize=(11,9))\nplt.title('Most common Machine Learning attributes that consider themselves as Data Scientists')\n\nax = sns.barplot(x = dfplot['Count'], y = dfplot['default'])","ec7c1a43":"dfall = pd.concat([dfModel.head(3),dfData.head(3),dfPersonal.head(5), dfMachineLearning.head(3),dfTools.head(4)], ignore_index=True)\ndfplot = dfall.sort_values(by=['Count'], ascending = False)\nplt.figure(figsize=(11,9))\nplt.title('Most common attributes for self identified Data Scientists')\n\n\nax = sns.barplot(x = dfplot['Count'],  y = dfplot['default'])\n","4d77bfe9":"\n\nfrom IPython.display import Image\nfrom IPython.core.display import HTML \nPATH = \"..\/input\/imagefilesforkagglesurvey\/\"\nImage(filename = PATH + \"anatomyofkaggler2.png\")","05d14acf":"from IPython.display import Image\nImage(filename = PATH + \"predictdatascientist3.png\")","1cf84e72":"Similar to what was found previously except interesting that when going to primary language there is a significant droppoff in R use as a programming language.","32859dfb":"This notebook will consider 'Definitely yes' and 'Probably Yes' to be considered as self identification as a Data Scientist. 'Definitely not', 'Maybey' and 'Probably not' as an indicator that that kaggler does not see themseleves as a Data Scientist.  Reason being is that this notebook is under the assumption that the term 'probably' is significant.\n\n","cc406122":"So all statistics that will be show will be now working with this subset of data to see if there are any significant questions that illicit responses that can favour self identification as a data scientist","1aa81ef0":"<a id=\"summary1\"><\/a>\n\n## 4.1 Summary of common features of a Self Identified Kaggler\n\n### 4.1.1 Kagglers Personal Information \n\nA male aged 25-29 years old who lives in USA.\nHas a Master's degree and employed as a Data Scientist.\nFavourite source for Data Science topics is Kaggle Forums and completed courses on Coursera  \nHas been using machine learning methods for around two years, coding for 3 years and spends around fifty to seventy percent of their time on coding. \nConsiders reproduction of code time-consuming and thinks that independent project are more important than academic achievements.","e6d93f6d":"<a id=\"Analysis\"><\/a>\n# 3.0 Analysis\n\nBy now all questions have been placed in categories and this notebook will now will go through each of the categories and display a plot by each question on the responses by Self-Identification.  \n\nThe most common attributes of a self identified Data Scientist is found this way. \n\nInformation for the Predict a Kaggler infographic is derived from the differences between 'Identify as a Data Scientits' and 'Not a Data Scientist'\n\nFirst category will look at are descriptive questions about kagglers. ","ae08d580":"Largest group is 25-29 the most significant being 18-21 in non selecting a Data Scientist","b886242b":"Recently started using ML methods is the most common,  Well established ML methods is a good indicator and Don't use ML methods is not","3fda04e4":"Accuracy is the most common but the the metric for Revenue and Business Goals is a good indicator","6a03dbd5":"<a id='DefinitionofDataScience'><\/a>\n## 2.3 Definition of Data Science\n\nKagglers have different views of what is a data scientist is which matches the varying definitions on the internet. \n\nThis notebook will  reduce the definition to its core components which is data and science which are . \n\n-> Data is facts and statistics collected together for reference or analysis.\n\n-> Science is gaining a body of knowledge in a systematic way. \n\n\nTo get more meaning from the data the notebook will now check the survey questions and see if it can be reduced into sub categories for further analysis.\n\n\n\n\n\n","3b9ed83e":"Majority is to analzye and understand data to influence product or business decisions where the better indicator is in building or running a machine learning service. Non of these activities is a good indicator that they are not a data scientist","bad67769":"Python is the most used where R is the best indicator and Java\/C is the best indicator for not.","b7db82d1":"<a id='references'><\/a>\n# 5.0 References\n\nStorytelling the 2018 Kaggle Survey, accessed December 2018\nhttps:\/\/www.kaggle.com\/kaggle\/kaggle-survey-2018\n\nData Science in Industry. Anatomy Of A Data Scientist Infographic, accessed December 2018\nhttps:\/\/elearninginfographics.com\/anatomy-data-scientist-infographic\/\n\nProbability for data scientists - Devopedia, accessed December 2018\nhttps:\/\/devopedia.org\/data-science\n\nCREATE-IoT methodology, accessed December 2018\nhttps:\/\/wiki.european-iot-pilots.eu\/index.php?title=File:Areas_of_knowledge.png\n\n\n","ffed37d8":"Majority of kagglers who identify as Data Scientist have Masters degrees but a Doctoral degree is a better indicator where as a Bachelors degree is significant in the kaggler saying that they are not a data scientist\n\nSo far having a doctoral degree is the best indicator of a kaggler self identifying as a data scientist","8c209f4e":"<a id=\"MachineLearning\"><\/a>\n## Machine Learning","8773a20c":"\n<a id='MainPurpose'><\/a>\n# 1.0 Purpose\n\n\n1.1 The purpose of this notebook are to:\n\n-> Using information from the 2018 Kaggle ML & Data Science Survey analyse the relationship between kagglers who identify as Data Scientist with kagglers who dont. So Identify the main features that differentiates kagglers by self-identification\n\n-> Explore what it is to be a data scientist using a subset of the data science community represented in the 2018 Kaggle ML & Data Science Survey\n   \n-> Create a data story using two infographics in a kaggler notebook for consideration in the 2018 Kaggle ML & DS Survey Challenge\n    \n    \n    \n   \n","32358290":"Majority still use Scikit Learn but now tensorflow becomes an indicator for people that dont see themselves as a Data Scientist.  Xgboost is the best indicator","999b7784":"<a id=\"summary2\"><\/a>\n\n## 4.3 Summary of features with large variances between Self Identified Kaggler Data Scientist and the Rest of Survey participants\n\n### 4.3.1 Kagglers Personal Information \n\nA person who lives in the USA\nHas a Doctoral degree\nEmployed as a Data Scientist \nSalary ranges between $150,000 to $200,000. \nFavorite source for Data Science topics is ArXiv & Preprints and completed courses on Coursera. \nHas been using machine learning methods for around seven years, \nCoding experience is over five years with over fifty percent of their time is spent on coding.  \n\n#### Common features of kagglers who dont identify as a Data Scientist\nBachelors degree \nEmployed as a salesperson w\nSpent less than one year in coding and machine learning \nNever considered reproducing their code.\n\n### 4.3.2 Languages, Tools, and Software\nThe primary tool to analyze data is local or hosted development environments (Rstudio JupyterLab)\nThe most used development environment is Rstudio. The hosted notebook is Kaggle Kernels \nCloud computing services are Amazon Web Services\nThe programming language used most often is Python\nProgramming language recommend to aspiring data scientist is R\nCloud computing products are AWS Cloud computing products\n\n\n#### Common features of kagglers who dont identify as a Data Scientist\nPimary tool for analysis is basic statistical software i.e Excel, Google Sheets, \nUses predominately Visual Studio, Java, Typescript \nDoesn't use Cloud products. \n\n### 4.3.3 Wrangling and Visualizing Data \nData Visualization libraries or tools are ggplot2 and Seaborn\nRelations Database products are PostgreSQL\nBig data and analytics products are Databricks\nTime-series is data that currently interact with most often\nFind public datasets by collecting own data i.e web scraping\nSpend 80-90 percent of data projects are involved in exploring unfair bias in the dataset and\/or algorithm?\n\n#### Common features of kagglers who dont identify as a Data Scientist\nDoes not use data visualization libraries \nUses predominately  numerical data with Microsoft access, Microsoft Analysis Service \nDoesn't work with public data\n\n\n### 4.3.4 Methods and Modeling\nAn important part of their role is to build and\/or run a machine learning service that operationally improves my product or workflows\nMetrics that consider revenue and business goals is the most important metric for a successful model.\nSpend 70% to 80% of data projects involve exploring model insights\nExamine feature importance and individual model coefficients to explain\/interpret decision made by ML models \nConfident that they can explain the outputs of most if not all ML models\nTools and methods to make work easy to reproduce is to define all random seeds and share data and code using containers i.e docker\n\n#### Common features of kagglers who dont identify as a Data Scientist\nDoesnt use ML Models\n\n### 4.3.5 Machine Learning \nUse of xgboost as a machine learning framework \nThe employer has well-established ML methods within the last two years.\nUses Rapidminer-Cloudera Machine learning products\nSignificant machine learning\/data science training is through kaggle competitions\nFind difficulty in lack of communication between individuals who collect the data and individuals who analyze the data when trying to ensure that algorithms are fair and unbiased \n\n#### Common features of kagglers who dont identify as a Data Scientist\nUses Tensorflow as a Machine  learning framework a\nEmployer doesn't use ML methods\n","9baaa796":"<a id=\"Results\"><\/a>\n# 4.0 Results\n","c476a7f0":"<a id='SystematicApproachtoStoryTelling'> <\/a>\n## 2.2 Systematic Approach to Story Telling\n\nBelow is the methodolgy of creating this notebook\n\n-> A quick glance over the type of questions and files given from  the Survey\n\n-> Established that this notebook will be about kagglers who self-identify as Data Scientist and what differentiates them from all kagglers\n\n-> Group multiple choice questions into a practicable number of categories\n\n-> Create a function for self-identification that can be easily be changed after further analysis.\n\n->  Do an analysis of each question to see on what is the most common answer for a Data Scientist plus the differences\n\n->  Add most common answers, differences into each of the categories to be used for presentation purposes\n\n-> Identified that best way to tell a simple story is for the two infographics of all main details using  the analysis the responses to questions\n\n-> Found two good infographics to be amended using Gimp.\n\n-> Clean up code, infographics and notebook (Continuing)\n\nBelow is the best story in this notebook which shows the significant difference between kagglers that identify as Data Scientist and other kagglers who responded to the survey.","42aa802d":"AWS Computer Cloud is the most used and also a good indicator for a data scientist","772ead1c":"Majority say code should be well documentated and human readable","3a0174ba":"<a id=\"MethodsandModelling\"><\/a>\n## 3.2 Methods and Modelling \n\n","96e7f43d":"<a id=\"LanguagesToolsSoftware\"><\/a>\n## Languages, Software and Tools\n","aadfdb87":"Majority did not want to disclose their yearly income and this was a good indicator for not being a data scientist. Best indicator for data scientist is salary from $150,000-$200,000","134c78f3":"People recommending SQL is a good indicator that they dont consider themselves as a Data Scientist","53c37adb":"Age group 18-21 is a good indicator of not identifying as a Data Scientist","a2f6cb03":"Due to the low numbers of kagglers over 70, I have not included the attribute in the infographic","400af6a8":"# Table of Contents\n\n### [1.0 Purpose](#MainPurpose)<br>\n\n### [2.0 Background](#BackgroundTitle)<br>\n[  2.1 Find Meaning from the Responses](#FindMeaning) <br>\n[  2.2 Systematic Approach to Story Telling](#SystematicApproachtoStoryTelling) <br>\n[  2.3 Definition of Data Science](#DefinitionofDataScience) <br>\n[  2.4 Details on the Survey Questions](#DetailsontheSurveyQuestions) <br>\n[  2.5 Self Identification](#SelfIdentification) <br>\n\n\n### [3.0 Analysis](#Analysis) <br>\n[3.1 Personal Information](#personalinformation) <br>\n[3.2 Methods and Modelling](#MethodsandModelling)<br>\n[3.3 Machine Learning](#MachineLearning) <br>\n[3.4 Languages, Tools and Software](#LanguagesToolsSoftware)<br>\n[3.5 Wrangling and Visualizing Data](#WranglingAndVisualizingData) <br>\n\n\n### [4.0 Results](#Results)<br>\n[4.1 Summary of common features of a Self Identified Kaggler](#summary1)<br>\n[4.2  Infographic of the most common atributes of self identified Kaggler Data Scientist](#story1)<br>\n[4.3  Summary of features with large variances between Self Identified Kaggler Data Scientist and the Rest of Survey participants](#summary2)<br>\n[4.4 The main STORY](#story2)<br>\n\n### [5.0 References](#references)\n\n","62c8e4c3":"Use of Coursera as online platform is the most common and also the best indicator. edX and Udacity is not","ef54e0fe":"<a id='DetailsontheSurveyQuestions'> <\/a>\n## 2.4 Details on the Survey Questions\n\nThis report is limited to answers from the multipleChoiceResponses.csv. \n\n\n\nThere are 395 actual questions in multipleChoiceResponses.csv and after analysing the questions they can be clustered around 50 areas in which I have reduced to five categories which are:\n\n-> [Personal Information](#personalinformation)\n\n-> [Languages, Tools and Software](#LanguagesToolsSoftware)\n\n-> [Wrangling and Visualizing Data](#WranglinganVisualizing Data) \n\n-> [Methods and Modeling](#MethodandModeling)\n\n-> [Machine Learning](#MachineLearning) \n\n\n\n\n\n\n","c6e49760":"<a id=\"WranglingAndVisualizingData\"><\/a>\n## Wrangling And Visualizing Data","256c75e1":"\n### 4.1.3 Wrangling and Visualizing Data \nData Visualization libraries or tools is Matplotlib\nRelations Database products is MySQL\nBig data and analytics products is Google BigQuery\nNumerical Data is data that kaggler interacts with most often\nFind public datasets using Dataset aggregator i.e \nSpend 0-10 percent of data projects are involved in exploring unfair bias in the dataset and\/or algorithm?","4bb3ca7a":"\n### 4.1.2 Languages, Tools and Software\n\nPrimary tool to analyze data is local or hosted development environments (Rstudio JupyterLab)\nMost used development environment is Jupitor\/Python \nHosted notebook is Kaggle Kernels \nCloud computing services is Amazon Web Services\nCloud computing products is AWS Cloud computing products\nProgramming language used most often is Python\nProgramming language recommend to aspiring data scientist is Python","6350c208":"AWS is the most used and also the best indicator of identifying as a Data Scientist. No using cloud providers is an indicator of not.","bf6464b8":"<a id = 'FindMeaning'>  <\/a>\n## 2.1 Find Meaning from the Responses\nThe world cloud shown above has nearly three million words from the responses in the 2018 Kaggle Survey. It is a good reflection of responses from the multiple choice questions but to get more meaning this notebook will break the questions into categories.\n\nThe notebooks main goal is to  differentiates between self identified kaggler data scientist with other kagglers.  \n\nSo the notebook focuses on questions about Data Science and what features are unique for a data scientist.","b2ec57a0":"Jupitor\/Python is most prevalent but RStudio is best indicator that they identify as a data scientist. Use of Visual Studio is indicator that dont identify as a Data Scientist","d068f54a":"USA kagglers are more likely to identify themselves as Data Scientist","5fdb3fa3":"Majority of kagglers who identify as Data Scientist come from USA and India where Singapore is significant in terms of having more kagglers saying that they are not Data Scientists","1f1701a4":"<a id='SelfIdentification'> <\/a>\n## 2.5 Self Identification\n\nThe main outcome of this notebook is to show the differences between kagglers that see themselves at data scientist compared to those that do not and how does this match up with the definitions of a data scientist\n\nThere are 23,859 number of responses from the survey but the self-identification question (Q26) has only 18,480 records. This notebook will be focusing on Q26 which is \"Do you consider yourself to be a data scientist?\" where the possible answers are 'Definitely not', 'Probably not','Maybe','Probably yes'  and 'Definitely yes'. \n     \n\n\n","5780f57b":"Actualy surprising how similar the patterns are so when in more details still could find much difference. But the difference are Self identified data scientis do more cleaning and Model building\/model selection. Major differentice is in the amount of time putting models into production. This Chart questions my whole premise and needs to be looked at later.","3ad1147f":"### 4.1.5 Machine Learning \nUse Scikit Learn and tensorflow as it machine learning framework \nEmployer has started using ML methods within the last two years.\nSignificant machine learning\/data science training self-taught\nUses SAS-Cloudera Machine learning products\nFind difficulty in collecting enough data about groups that may be unfairly targeted when trying to make sure that algorithms are fair and unbaised \nSee reproducibility in Data Science as more important the Fairness and bias in ML algorithms and being able to  explain ML modest outputs and predictions.","5f6f1477":"Majority use Scikit Learn and tensorflow but best indicator and one that use Xgboost, lightgbm and randomForest ","6a84d9e7":"<a id='BackgroundTitle'><\/a>\n# 2.0 Background\n\nKaggle launced the first Data Science Survey Challenge for their annual Survey in 2018 which is to  tell a  rich story about a subset of the data science and machine learning community.\n\nThe challenge was taken and this notebook is the result of that challenge. \n\n","395c781b":"The males and females follow similar distribution so gender does not seem to have an effect on self identification. Only a slight increase of males self identifying as Data Scientists\n","3f0ad5c5":"<a id=\"story1\"><\/a>\n### 4.2 Infographic of the most common atributes of self identified Kaggler Data Scientist <br>","c632af56":"50-74% of time coding is most common, over 50% is a good indicator and 1-24% is not","2439ce6b":"\n\n\n### 4.1.4 Methods and Modelling\nImportant part of their role is to analyze and understand data to influence product or business decisions\nAccuracy is the most important metric for a succesful model.\nSpend 10% to 20% of data projects involve exploring model insights\nUse plots of predicted vs actual results to explain\/interpret decision made by ML models \nConfident that the can explain the outputs of  many  but not all ML models\nTools and methods to make work easy to reproduce is well documentated and human readable\n\n\n","6c5bb701":"<a id=\"story2\"><\/a>\n### 4.4 The main STORY ","4d50ff23":"The answers to this plot is confusing as the total for none is the most significant but my understanding is that the data is from a kagglers survey which means that majority would have at least used a kaggle kernel","5928b6d8":"It seems when breaking down responses of kagglers with PHD's there is a difference in identifying if they are a Data Scientist. Females are over represented in terms of doctoral degrees but dont identify as Data Scientist to the same degree as males. \nDecided not to include this in the infographic but am guessing it is significant","159344f8":"Data Scientist more likely to use local or hosted development environment where the use of Basic statistical software is good indicator that they are not a Data Scientist","e9275117":"As expected majority of people employed as Data Scientist see themselves as Data Scientist. ","458fa184":"Kaggle Forums is the most common,  arXiv  Preprints is good indicator and Twitter and Cloud AI Adventrures is not","d64cd203":"<a id=\"personalinformation\"><\/a>\n## 3.1 Kaggler Personal Information\n\n\n\nBelows is a word cloud in relation to responses concerning descriptions\n\n","eac6ab71":"Salesperson and Developer Advocate are good indicators for not being a Data Scientist.","b0523975":"Reproducity is very important for  the majority of kagglers where not having an opinion is a good indicator of negative"}}