{"cell_type":{"861d4941":"code","39ad1394":"code","205fc67e":"code","3fd967e2":"code","f97efd3a":"code","0cd7813b":"code","59dbe41c":"code","8f63c067":"code","8aa4e66d":"code","d302c81a":"code","e0b6f1ff":"code","7edfa847":"code","e9434698":"code","46e633be":"code","66be140a":"code","f8519196":"code","1654898c":"code","fa0428f8":"code","da2dd66b":"code","cb0ace48":"code","207fb2e8":"code","96846118":"code","b2cd613f":"code","cb0c22bd":"code","fae59a82":"code","0615665b":"code","6c6b99e6":"code","84e917ed":"code","bb73dfbc":"code","dcb5a2e3":"code","bd8f2ff0":"code","ae9d44ed":"code","f83b31f8":"code","3b22a011":"code","9232e7a7":"code","8c37cacc":"code","0d776528":"code","7aa5bb3a":"code","94e5efbb":"code","74c6c1a0":"code","3f8e6599":"code","a48d0447":"code","d18747e5":"code","30e5bcce":"code","2627937c":"code","89c635b6":"code","89aca4c4":"code","d1402738":"code","53d9c366":"code","be650b90":"code","332adfc9":"code","6ea068c7":"code","444b1707":"code","9a3acd74":"code","a0a822b6":"code","848335a8":"code","742fbde2":"code","401bc0ea":"code","4582aa3c":"code","fcad2823":"code","ed55081a":"code","c2d2efe4":"code","3bc52ac2":"code","4ccc4eb5":"code","8155c6e6":"code","6d2605d4":"code","d0caeb5e":"code","caa9e179":"code","40a30cf3":"code","d9b5b700":"markdown","ab79ddcc":"markdown","a612a1e2":"markdown","2abded16":"markdown","ee5fac6f":"markdown","f2794b15":"markdown","e3f361b9":"markdown","253972c4":"markdown","31bcd1f7":"markdown","eff68e9f":"markdown","e48bf11c":"markdown","971a9eb1":"markdown","b8218112":"markdown","ad3b2a36":"markdown","285633e0":"markdown","20a1e759":"markdown","eafa2386":"markdown","7a3624b0":"markdown","928ebb56":"markdown","20df6e23":"markdown","6855500c":"markdown","6ed8f60e":"markdown","e5a8ddf6":"markdown","6e04cd77":"markdown","676e329f":"markdown","42c4459d":"markdown","518ca02e":"markdown","8408645e":"markdown","089cc0c5":"markdown","baee4c52":"markdown","cf376d64":"markdown","17e8e143":"markdown","14a8b530":"markdown","8ed2bd7c":"markdown","52a22165":"markdown","340ef617":"markdown","1ddd89b9":"markdown","f568c4d9":"markdown","d6137028":"markdown","8ae30dc6":"markdown","2c7b9358":"markdown","ecd7da3f":"markdown","7e1f6718":"markdown","c6542355":"markdown","1533499d":"markdown","a5e6fcfd":"markdown","1c11581b":"markdown","b63272b8":"markdown","1b880159":"markdown","d237659b":"markdown","4b1ed6eb":"markdown","30ddbcaa":"markdown","26e05738":"markdown","3e2af63f":"markdown","9e3b1ac9":"markdown","265dfd3c":"markdown","bca93e91":"markdown","5aea92b8":"markdown","587e3d01":"markdown","2281ba83":"markdown","548ffb30":"markdown","0e19da11":"markdown","fb41ad4d":"markdown","c474ae3b":"markdown","ca7af4de":"markdown","5869b92c":"markdown","c2b8554d":"markdown","3a8d1f07":"markdown","c3aa4c82":"markdown","dd0513e0":"markdown","194d71e2":"markdown","9c56874b":"markdown","52ef059c":"markdown","6dd68d3f":"markdown","59ff1160":"markdown","bd984ff9":"markdown","d25fa976":"markdown","2caa3621":"markdown","464e588a":"markdown","8b7d5c1d":"markdown","0c1f7caa":"markdown","f4f5cbd7":"markdown","69a939bb":"markdown","ab5a57d9":"markdown","83b155f9":"markdown","3f5dd3c3":"markdown"},"source":{"861d4941":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Importing the numpy and pandas \nimport numpy as np\nimport pandas as pd \n\n# Importing matplotlib and seaborn \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# Setting the columns and row for visibility\npd.set_option('display.max_columns', 500)\npd.set_option(\"display.max_rows\",500)\n\n#Importing stats models\nimport statsmodels.api as sm\n\n# Importing sklearn\nimport sklearn\n# For train test split\nfrom sklearn.model_selection import train_test_split\n# For mean squared error\nfrom sklearn.metrics import mean_squared_error\n# for Rsquare\nfrom sklearn.metrics import r2_score\n# for Linear regression class\nfrom sklearn.linear_model import LinearRegression\n# for minmaxscalar\nfrom sklearn.preprocessing import MinMaxScaler\n# for RFE\nfrom sklearn.feature_selection import RFE\n# For calculate VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","39ad1394":"# Reading the data\n\nbike_sharing = pd.read_csv(\"..\/input\/bike-sharing\/day.csv\")\nbike_sharing.head()","205fc67e":"# Checking the shape of the dataframe\n\nbike_sharing.shape","3fd967e2":"# Checking the info() of bike sharing data frame\n\nbike_sharing.info()","f97efd3a":"# Checking the null values in the dataframe\n\nbike_sharing.isnull().sum().sort_values(ascending=False)","0cd7813b":"# checking the summary of numarical columns in the bike_sharing dataframe\n\nbike_sharing.describe()","59dbe41c":"# Checking the column names of bike_sharing dataframe\n\nbike_sharing.columns","8f63c067":"# Dropping the 'instant' column as it is index which has nothing to do with 'cnt' column\nbike_sharing.drop('instant',axis=1,inplace=True)\n\n# Dropping dteday as we have already have month and weekday columns to work with\nbike_sharing.drop('dteday',axis=1,inplace=True)\n\n# Dropping casual and registered columnsa as as we have cnt column which is sum of the both that is the target column\nbike_sharing.drop('casual',axis=1,inplace=True)\nbike_sharing.drop('registered',axis=1,inplace=True) \n\n\nbike_sharing.head()","8aa4e66d":"# Checking the value counts of the 'season' column\n\nbike_sharing.season.value_counts()","d302c81a":"# Checking the value counts of the 'yr' column\n\nbike_sharing.yr.value_counts()","e0b6f1ff":"# Checking the value counts of the 'mnth' column\n\nbike_sharing.mnth.value_counts()","7edfa847":"# Checking the value counts of the 'holiday' column\n\nbike_sharing.holiday.value_counts()","e9434698":"# Checking the value counts of the 'weekday' column\n\nbike_sharing.weekday.value_counts()","46e633be":"# Checking the value counts of the 'workingday' column\n\nbike_sharing.workingday.value_counts()","66be140a":"# Checking the value counts of the 'weathersit' column\n\nbike_sharing.weathersit.value_counts()","f8519196":"# Checking the value counts of the 'temp' column\n\nbike_sharing.temp.value_counts()","1654898c":"# Checking the value counts of the 'atemp' column\n\nbike_sharing.atemp.value_counts()","fa0428f8":"# Checking the value counts of the 'hum' column\n\nbike_sharing.hum.value_counts()","da2dd66b":"# Checking the value counts of the 'windspeed' column\n\nbike_sharing.windspeed.value_counts()","cb0ace48":"# Checking the value counts of the 'cnt' column\n\nbike_sharing.cnt.value_counts()","207fb2e8":"# convertng season,weathersit,mnth & weekday columns in to catagories\n\nbike_sharing.season.replace({1:'spring', 2:'summer', 3:'fall', 4:'winter'},inplace=True)\nbike_sharing.mnth.replace({1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr',5:\"May\",\n                           6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"},inplace=True)\nbike_sharing.weathersit.replace({1:'Clear',2:\"Cloudy\",3:\"Light Rain + Thunderstorm\",4:\"Heavy Rain + Thunderstorm\"},inplace=True)\nbike_sharing.weekday.replace({0:\"Sun\",1:\"Mon\",2:\"Tue\",3:\"Wed\",4:\"Thu\",5:\"Fri\",6:\"Sat\"},inplace=True)\n\nbike_sharing.head(10)","96846118":"# Perforing univariate analysis for numerical columns using boxplot\n\ncol = ['temp', 'atemp', 'hum', 'windspeed','cnt']\nplt.figure(figsize=[20,15])\nfor i in enumerate(col):\n    plt.subplot(2,3,i[0]+1)\n    sns.boxplot(data=bike_sharing,y=i[1])\n    \nplt.show()","b2cd613f":"col = ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\nplt.figure(figsize=[20,15])\nfor i in enumerate(col):\n    plt.subplot(2,4,i[0]+1)\n    bike_sharing[[i[1]]].value_counts().plot.bar()\n    plt.xlabel(i[1])\n    \nplt.show()","cb0c22bd":"# Ploting the scatterplot for numerical variable with target variable 'cnt'\n\ncol = ['temp', 'atemp', 'hum', 'windspeed']\nplt.figure(figsize=[20,12])\nfor i in enumerate(col):\n    plt.subplot(2,2,i[0]+1)\n    sns.regplot(data=bike_sharing,x=i[1],y='cnt',line_kws={\"color\":'red'})\n    \nplt.show()","fae59a82":"# Ploting the boxplot for categorical variable with target variable 'cnt'\n\ncol = ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\nplt.figure(figsize=[20,12])\nfor i in enumerate(col):\n    plt.subplot(2,4,i[0]+1)\n    sns.boxplot(data=bike_sharing,x=i[1],y='cnt')\n    \nplt.show()","0615665b":"# Ploting the pair plot\n\nsns.pairplot(bike_sharing);","6c6b99e6":"# checking the heat map\n\nplt.figure(figsize=[15,8])\nfig = sns.heatmap(bike_sharing.corr(),cmap='hot_r',\n            annot=True,linecolor='black',linewidths=0.01,annot_kws={\"fontsize\":12},fmt=\"0.2f\")\n\ntop, bottom = fig.get_ylim()\nfig.set_ylim(top+0.1,bottom-0.1)\n\nleft, right = fig.get_xlim()\nfig.set_xlim(left-0.1,right+0.1) \n\nplt.yticks(fontsize=13,rotation=0)\nplt.xticks(fontsize=13,rotation=90);","84e917ed":"# Creating dummy columns for 'season','mnth','weekday','weathersit' variables\n\nbike_sharing = pd.get_dummies(data=bike_sharing,columns=['season','mnth','weekday','weathersit'],drop_first=True)","bb73dfbc":"# Checking wether dummy columns has been created or not\n\nbike_sharing.head()","dcb5a2e3":"# Checking the info()\n\nbike_sharing.info()","bd8f2ff0":"# Checking the shape of the dataframe before splitting\n\nbike_sharing.shape","ae9d44ed":"# y to contain only the target variable 'cnt'\ny = bike_sharing.pop('cnt')\n\n# X to contain all the features except target variable\nX = bike_sharing\n\n# Train Test split with 70:30 ratio\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=100)","f83b31f8":"# Checking the independent variable\nX.head()","3b22a011":"# Checking the shape of all splitted dataframe\n\nprint(\"X_train shape - \",X_train.shape)\nprint(\"X_test shape - \",X_test.shape)\nprint(\"y_train shape - \",y_train.shape)\nprint(\"y_test shape - \",y_test.shape)","9232e7a7":"# List of features to be scaled\nnum_vars = ['temp','atemp','hum','windspeed']\n\n# using MinMaxScalar to scale the variables\nscalar = MinMaxScaler()\n\n# Fitting and Transforming the training dataframe\nX_train[num_vars] = scalar.fit_transform(X_train[num_vars])","8c37cacc":"# Inspecting the training dataset for scaling\n\nX_train.head()","0d776528":"# Checking the describe function for scalar\n\nX_train.describe()","7aa5bb3a":"# Build a Linear Regression model using sklearn for RFE\nlr = LinearRegression()\nlr.fit(X_train,y_train)","94e5efbb":"# Running RFE with the output number of the variable (columns) equal to 15\nrfe = RFE(lr,15)\nrfe.fit(X_train,y_train)","74c6c1a0":"# Features that selected by RFE and their weights\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","3f8e6599":"#list of RFE selected columns\n\nX_train.columns[rfe.support_]","a48d0447":"#list of RFE not selected columns\n\nlist(X_train.columns[~rfe.support_])","d18747e5":"# Creating Function for model building using statsmodel api - Takes the columns to be selected for model as a feature\ndef model_bulding(cols):\n    # adding constant to the X_train dataframe\n    X_train_sm = sm.add_constant(X_train[cols])\n    # fitting the model using OLS method\n    lm = sm.OLS(y_train,X_train_sm).fit()\n    print(lm.summary())\n    return lm","30e5bcce":"def get_vif(cols):\n    df1 = X_train[cols]\n    vif = pd.DataFrame()\n    vif['Features'] = df1.columns\n    vif['VIF'] = [variance_inflation_factor(df1.values, i) for i in range(df1.shape[1])]\n    vif['VIF'] = round(vif['VIF'],2)\n    print(vif.sort_values(by='VIF',ascending=False))","2627937c":"# Taking 15 columns supported by RFE for regression\nX_train_rfe = X_train[list(X_train.columns[rfe.support_])]\nX_train_rfe.shape","89c635b6":"# Plotting heat map for overall fetaures\n\nplt.figure(figsize=[20,13])\nfig = sns.heatmap(bike_sharing.corr(),cmap='hot_r',\n            annot=True,linecolor='black',linewidths=0.01,annot_kws={\"fontsize\":10},fmt=\"0.2f\")\n\ntop, bottom = fig.get_ylim()\nfig.set_ylim(top+0.1,bottom-0.1)\n\nleft, right = fig.get_xlim()\nfig.set_xlim(left-0.1,right+0.1) \n\nplt.yticks(fontsize=10,rotation=0)\nplt.xticks(fontsize=10,rotation=90);","89aca4c4":"# Building Model_1 with feture selected by RFE\n\ncols = list(X_train.columns[rfe.support_])\n\nmodel_bulding(cols)\nget_vif(cols)","d1402738":"# Building Model_2 without 'hum'\n\ncols = ['yr', 'holiday', 'workingday', 'temp', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n       'mnth_Jul', 'mnth_Sep', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\nmodel_bulding(cols)\nget_vif(cols)","53d9c366":"# Building Model_3 without 'temp'\n\ncols = ['yr', 'holiday', 'workingday', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n       'mnth_Jul', 'mnth_Sep', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\nmodel_bulding(cols)\nget_vif(cols)","be650b90":"# Building Model_4 without 'mnth_Jul'\n\ncols = ['yr', 'holiday', 'workingday', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n        'mnth_Sep', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\nmodel_bulding(cols)\nget_vif(cols)","332adfc9":"# Building Model_5 without 'season_winter'\n\ncols = ['yr', 'workingday', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n        'mnth_Sep', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\nmodel_bulding(cols)\nget_vif(cols)","6ea068c7":"# Model_6: replacing `mnth_Sep` with `temp` because they are correlating with each other\n\ncols = ['yr', 'workingday', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n        'temp', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\nmodel_bulding(cols)\nget_vif(cols)","444b1707":"# Creating function to get intercept and coefficients using LinearRegression\n\ndef build_model_sk(X,y):\n    lr1 = LinearRegression()\n    lr1.fit(X,y)\n    return lr1\n","9a3acd74":"# Building the final model using sklearn\n\ncols = ['yr', 'workingday', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n        'temp', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\n# Build with model with above columns\n\nlr = build_model_sk(X_train[cols],y_train)\nprint(lr.intercept_,lr.coef_)","a0a822b6":"# predicting the model on trianing dataset\ny_train_pred = lr.predict(X_train[cols])\n\n# Ploting distribution plot for chrcking the distribution of error terms\nsns.distplot(y_train-y_train_pred,bins=10)\nplt.title(\"Error Distribution on the training dataset\")\nplt.xlabel(\"Errors\");","848335a8":"# Actual vs Predicted\n\nc = [i for i in range(0,len(X_train),1)]\nplt.figure(figsize=[10,5])\nplt.plot(c,y_train, color=\"blue\")\nplt.plot(c,y_train_pred, color=\"red\")\nplt.legend([\"Actual_train\",\"Predicted_train\"],loc=\"lower right\")\nplt.suptitle('Actual vs Predicted', fontsize = 15)\nplt.xlabel('Index')\nplt.ylabel('Demands');","742fbde2":"# Checking error term pattern\n\nc = [i for i in range(0,len(X_train),1)]\nplt.figure(figsize=[10,5])\nplt.plot(c,y_train-y_train_pred)\nplt.suptitle('Error Terms', fontsize = 15)\nplt.xlabel('Index')\nplt.ylabel('y_train-y_train_pred')\nplt.show()","401bc0ea":"#Printint R-squared Value using sklearn\n\nr2_score(y_train,y_train_pred)","4582aa3c":"# Checking the relationship by scaatter plot\n\nresidual = (y_train - y_train_pred)\nplt.figure(figsize=[8,5])\nsns.scatterplot(y_train,residual)\nplt.ylabel(\"y_train\")\nplt.xlabel(\"Residual\")\nplt.show()","fcad2823":"# List of features to be scaled\nnum_vars = ['temp','atemp','hum','windspeed']\n\n# Test data to be transformed only, no fitting\nX_test[num_vars] = scalar.transform(X_test[num_vars])","ed55081a":"# Columns from our final model\ncols = ['yr', 'workingday', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n        'temp', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\n# Predicting the values for test data\ny_test_pred = lr.predict(X_test[cols])","c2d2efe4":"# Finding the R2 value for test dataset usking sklearn\n\nr2_score(y_test,y_test_pred)","3bc52ac2":"# % of difference between train model r2 and test model r2\n\nprint(\"% Difference between r2 score for test and train model is\",\n      str(round((r2_score(y_train,y_train_pred) - r2_score(y_test,y_test_pred))*100,2))+'%')","4ccc4eb5":"# Plotting y_test and y_test_pred to understand the spread\n\nplt.figure(figsize=[8,5])\nplt.scatter(y_test, y_test_pred)\nplt.title('y_test vs y_test_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_test_pred', fontsize = 16);","8155c6e6":"#Function to plot Actual vs Predicted\n#Takes Actual and PRedicted values as input along with the scale and Title to indicate which data\ndef plot_act_pred(act,pred,scale,dataname):\n    c = [i for i in range(1,scale,1)]\n    fig = plt.figure(figsize=(14,5))\n    plt.plot(c,act, color=\"blue\", linewidth=2.5, linestyle=\"-\")\n    plt.plot(c,pred, color=\"red\",  linewidth=2.5, linestyle=\"-\")\n    plt.legend(['Actual_test','Predicted_test'],loc = 'lower right')\n    fig.suptitle('Actual and Predicted - '+dataname, fontsize=20)              # Plot heading \n    plt.xlabel('Index', fontsize=18)                                           # X-label\n    plt.ylabel('Counts', fontsize=16)                                          # y-label","6d2605d4":"#Plot Actual vs Predicted for Test Data\nplot_act_pred(y_test,y_test_pred,len(y_test)+1,'Test Data')","d0caeb5e":"# Ploting distribution plot for chrcking the distribution of error terms\nsns.distplot(y_test-y_test_pred,bins=10)\nplt.title(\"Error Distribution on the test dataset\")\nplt.xlabel(\"Errors\");","caa9e179":"# Error terms\n\nc = [i for i in range(1,220,1)]\nfig = plt.figure(figsize=(14,5))\nplt.plot(c,y_test-y_test_pred, color=\"blue\", marker='o', linewidth=2.5, linestyle=\"\")\nfig.suptitle('Error Terms', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                      # X-label\nplt.ylabel('Counts - Predicted Counts', fontsize=16);  # Y-label","40a30cf3":"# Getting the summary of final model\n\ncols = ['yr', 'workingday', 'windspeed',\n       'season_spring', 'season_summer', 'season_winter', 'mnth_Jan',\n        'temp', 'weekday_Sat', 'weathersit_Cloudy',\n       'weathersit_Light Rain + Thunderstorm']\n\nmodel_bulding(cols)","d9b5b700":"**<font color='blue'>Inference:**\n- Looks like `temp` and `atemp` are highly correlating with each other and also their correlation with `cnt` is the same\n- There is a positive correlation between `temp,atemp,yr and `cnt`\n- There is a negative correlation between `windspeed, hum,workingday & holiday` and `cnt`\n- For `season,weathersit,mnth and weekday` dummy variable to be created for further analysis and model building ","ab79ddcc":"## <font color='blue'>Table of Contents\n    \n- [1. Problem Statement](#1.-Problem-Statement)\n    - [1.1 Business Goal](#1.1-Business-Goal)\n    \n    \n- [2. Reading and Understanding the data](#2.-Reading-and-Understanding-the-data)\n    - [2.1 Importing the necessary libraries](#2.1-Importing-the-necessary-libraries)\n    - [2.2 Reading the data](#2.2-Reading-the-data)\n    - [2.3 Understanding the data](#2.3-Understanding-the-data)\n        - [2.3.1 Inspecting the various aspects of the bike_sharing dataset](#2.3.1-Inspecting-the-various-aspects-of-the-bike_sharing-dataset)\n        - [2.3.2 Data Cleaning](#2.3.2-Data-Cleaning)\n    \n    \n    \n- [3. Exploratory Data Analysis](#3.-Exploratory-Data-Analysis)\n    - [3.1 Univariate Analysis](#3.1-Univariate-Analysis)\n        - [3.1.1 Checking all the columns](#3.1.1-Checking-all-the-columns)\n        - [3.1.2 Converting the categorical variables from the numerical category into categories](#3.1.2-Converting-the-categorical-variables-from-the-numerical-category-into-categories)\n        - [3.1.3 Univariate Analysis on Numerical columns](#3.1.3-Univariate-Analysis-on-Numerical-columns)\n        - [3.1.4 Univariate Analysis on Categorical columns](#3.1.4-Univariate-Analysis-on-Categorical-columns)\n    - [3.2 Bivariate Analysis](#3.2-Bivariate-Analysis)\n        - [3.2.1 Bivariate Analysis on numerical columns](#3.2.1-Bivariate-Analysis-on-numerical-columns)\n        - [3.2.2 Bivariate Analysis on Categorical columns](#3.2.2-Bivariate-Analysis-on-Categorical-columns)\n    - [3.3 Multivariate Analysis](#3.3-Multivariate-Analysis)\n        - [3.3.1 Pairplot for all the columns](#3.3.1-Pairplot-for-all-the-columns)\n        - [3.3.2 Heatmap for all the columns](#3.3.2-Heatmap-for-all-the-columns)\n\n    \n    \n- [4. Data Preparation for Linear Regression](#4.-Data-Preparation-for-Linear-Regression)\n    - [4.1 Creating dummy variables for all categorical variables](#4.1-Creating-dummy-variables-for-all-categorical-variables)\n    - [4.2 Creating train test split](#4.2-Creating-train-test-split)\n    - [4.3 Feature scaling for continuous variables](#4.3-Feature-scaling-for-continuous-variables)\n    \n    \n- [5. Feature Selection and Model Building](#5.-Feature-Selection-and-Model-Building)\n    - [5.1 Automated Feature Selection - using RFE](#5.1-Automated-Feature-Selection---using-RFE)\n    - [5.2 Manual Feature Elimination - using p-value & VIF](#5.2-Manual-Feature-Elimination---using-p-value-&-VIF)\n        - [5.2.1 Creating a Function for Model building](#5.2.1-Creating-a-Function-for-Model-building)\n        - [5.2.2 Creating a Function for VIF](#5.2.2-Creating-a-Function-for-VIF)\n    - [5.3 Model Building](#5.3-Model-Building)\n\n    \n- [6. Residual Analysis](#6.-Residual-Analysis)\n    - [6.1 Error Distribution](#6.1-Error-Distribution)\n    - [6.2 Pattern checking for Actual Vs Predicted](#6.2-Pattern-checking-for-Actual-Vs-Predicted)\n    - [6.3 Checking the error term pattern](#6.3-Checking-the-error-term-pattern)\n    - [6.4 Checking the $R^2$ value using sklearn](#6.4-Checking-the-$R^2$-value-using-sklearn)\n    - [6.5 Checking the relationship between y_train and residuals](#6.5-Checking-the-relationship-between-y_train-and-residuals)\n    \n    \n- [7. Predictions and evaluation on the test data](#7.-Predictions-and-evaluation-on-the-test-data)\n    - [7.1 Predictions on the test dataset](#7.1-Predictions-on-the-test-dataset)\n    - [7.2 $R^2$ value for test predictions](#7.2-$R^2$-value-for-test-predictions)\n    - [7.3 Model Evaluation](#7.3-Model-Evaluation)\n        - [7.3.1 Checking the relationship between Actual Vs Predicted](#7.3.1-Checking-the-relationship-between-Actual-Vs-Predicted)\n        - [7.3.2 Checking the pattern between actual and predicted](#7.3.2-Checking-the-pattern-between-actual-and-predicted)\n        - [7.3.3 Checking distribution of Error term](#7.3.3-Checking-distribution-of-Error-term)\n    \n    \n- [8. Final Model Interpretation](#8.-Final-Model-Interpretation)\n    \n    \n- [9. Recommendations for the company](#9.-Recommendations-for-the-company)","a612a1e2":"**<font color='blue'>Inference:**\n- There is no significant difference in `season`,'yr`,`weekday` \n- There is less demand in `holiday`,`non-workingday`,`Rainy` days\n- Less demand in `Feb` month compared to other months","2abded16":"**<font color='blue'>Inference:**\n\n- `'temp', 'atemp', 'hum', 'windspeed', 'cnt'` are the numerical column\n- `'season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit'` are the categorical column\n- `'yr','holiday' and 'workingday'` are Binary Catagorical variable","ee5fac6f":"### <font color='blue'>7.1 Predictions on the test dataset","f2794b15":"### <font color='blue'>2.3 Understanding the data","e3f361b9":"---\n\n## <font color='blue'>2. Reading and Understanding the data","253972c4":"#### <font color='blue'>5.2.1 Creating a Function for Model building","31bcd1f7":"**<font color='blue'>Inference:**\n- $R^2$ value is the same as we obtained for our final model","eff68e9f":"**<font color='blue'>Interpretation:**\n- As per the `Prob (F-statistic)`, the value is practically `zero` so that the overall model is `significant`\n- As per the p-values, all the features are having a p-value less than `0.05` so all the features are `significant`\n- As per the `VIF`, the feature `temp` is having the `VIF` value of `7.08` which is very high so we can drop this feature","e48bf11c":"**<font color='blue'>Inference:**\n- Seems like there is no relationship between `y_train (Target variable)` and `Residuals`","971a9eb1":"**<font color='blue'>Inference:**\n- The error terms are independent of each other","b8218112":"**<font color='blue'>Inference:**\n- There are no outliers overall except `windspeed and hum`\n- We can keep the outliers as it's for further analysis","ad3b2a36":"#### <font color='blue'>Model_3: Rebuilding the model without `temp`","285633e0":"**<font color='blue'>Interpretation:**\n- As per the `Prob (F-statistic)`, the value is practically `zero` so that the overall model is `significant`\n- As per the `p-values`, all the features are having a `p-value` less than `0.05` so all the features are `significant`\n- As per the `VIF`, the feature `hum` is having a `VIF` value of `29.39` which is very high so we can drop this feature","20a1e759":"#### <font color='blue'>7.3.1 Checking the relationship between Actual Vs Predicted","eafa2386":"#### <font color='blue'>3.2.1 Bivariate Analysis on numerical columns","7a3624b0":"### <font color='blue'>3.3 Multivariate Analysis","928ebb56":"### <font color='blue'>2.1 Importing the necessary libraries","20df6e23":"### <font color='blue'>4.2 Creating train test split","6855500c":"**<font color='blue'>Inference:**\n- As we can see the error terms are randomly distributed and there is no pattern which means the output is explained well by the model and there are no other parameters that can explain the model better.","6ed8f60e":"**<font color='blue'>Interpretation:**\n- As we noticed after replacing the feature from `mnth_sep` to `temp`, the `Adj. R-squared` value has improved from `0.774` to `0.826`\n- As per the `Prob (F-statistic)`, the value is practically `zero` so that the overall model is `significant`\n- As per the p-values, all the features are having a p-value of less than `0.05` all the features are `significant`\n- As per the `VIF`, the feature `temp` is having the `VIF` value of `5.32` which is high but we can keep this feature since it is important feature\n- We can conclude that this is our final model","e5a8ddf6":"### <font color='blue'>4.3 Feature scaling for continuous variables","6e04cd77":"#### <font color='blue'>3.1.3 Univariate Analysis on Numerical columns","676e329f":"#### <font color='blue'>3.2.2 Bivariate Analysis on Categorical columns","42c4459d":"- To make all features in the same scale interpret easily (for coefficients)\n- The columns are continuous to be scaled are `temp,atemp,hum & windspeed`\n- Here we will use MinMaxScalar for scaling","518ca02e":"---\n\n## <font color='blue'>1. Problem Statement","8408645e":"#### <font color='blue'>2.3.2 Data Cleaning\n    \n**Dropping the unnecessary columns**:\n- **`instant`** can be removed because it is just a row instance identifier.\n- **`dteday`** can be removed as we have some of the date features like mnth and year and weekday already in other columns and also for this analysis we will not consider the day to day trend in demand for bikes.\n- **`casual`** and **`registered`** variables describe the target variable **`cnt`** in a very trivial way **`cnt = casual + registered`**, which leads to data leakage.","089cc0c5":"#### <font color='blue'>3.1.1 Checking all the columns","baee4c52":"The `bike_sharing` dataset has 730 rows and 16 columns","cf376d64":"---\n## <font color='blue'>9. Recommendations for the company","17e8e143":"### <font color='blue'>7.3 Model Evaluation","14a8b530":"A bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\n- Which variables are significant in predicting the demand for shared bikes.\n- How well those variables describe the bike demands\n\n\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors. \n\n\n### <font color='blue'>1.1 Business Goal\n    \nWe are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. ","8ed2bd7c":"**<font color='blue'>Inference:**\n- Errors terms are normally distributed and centred around mean 0\n- So we can make Predictions","52a22165":"### <font color='blue'>2.2 Reading the data","340ef617":"---\n## <font color='blue'>6. Residual Analysis\n    \nIn this segment, we will check the assumptions of the linear regression model on error terms\n- Error terms being independent of each other\n- Error terms normally distributed\n- Error terms having a constant variance","1ddd89b9":"---\n## <font color='blue'>5. Feature Selection and Model Building","f568c4d9":"**<font color='blue'>Inference:**\n- Season **`Fall`** has the highest demand for rental bikes, whereas the **`Spring`** has the lowest demand\n- The demand for the rental bike has increased in **`2019`** as compared to **`2018`**\n- There is high demand in **`Sep`** where as in **`Dec`** has the lowest demand, because in **`Dec`** usually it will be heavy snow\n- There is a low demand for **`holidays`** compared to **`non-holidays`**\n- There is not much of a difference in demand between **`weekdays`**\n- There is not much of a difference in demand between **`working`** and **`non-working days`**\n- There is high demand in **`Clear weather`**, whereas low demand during **`Light Rain + Thunderstorm days`**, there are no users renting the bike during **`Heavy snow`**\n- There is high demand in **`September`** month\n- There are no noticeable outliers in the data","d6137028":"##### <font color='blue'>Model Interpretation:\n\n- **`yr`** -  The demand for bike-sharing is increasing by year on year\n    \n    \n- **`temp`** - The rise in `temperature` the demand for the bike also increases\n    \n    \n- **`holiday`** - The bike demand may fall on `holidays`\n    \n    \n- **`windspeed`** - The bike demand may fall if the `wind speed` is high\n    \n    \n- **`Season_spring`** - The bike demand may fall during the `spring season`\n    \n    \n- **`Mnth_Jan`** - The bike demand may fall during the `January` month of the year\n    \n\n- **`weathersit_Cloudy & weathersit_Light Rain + Thunderstorm`** - The bike demand may fall during the `Rainy` season","8ae30dc6":"As per the Data dictionary, we can convert `season,weathersit,mnth & weekday` columns into categories","2c7b9358":"**<font color='blue'>Interpretation:**\n- As per the `Prob (F-statistic)`, the value is practically `zero` so that the overall model is `significant`\n- As per the p-values, the feature `mnth_Jul` has a p-value of `0.651` which is `insignificant` so we can drop this feature\n- As per the `VIF`, all the `VIF` values are less than `5`, so there is no high multicollinearity in this model","ecd7da3f":"#### <font color='blue'>Model_5: Rebuilding the model without `holiday `","7e1f6718":"As per the dataset, there are no null values, so missing value treatment is not needed","c6542355":"#### <font color='blue'>3.3.2 Heatmap for all the columns","1533499d":"### <font color='blue'>3.1 Univariate Analysis","a5e6fcfd":"**<font color='blue'>Inference:**\n- Actual and Predicted both are following almost the same pattern in the test dataset, so this model seems to fit well","1c11581b":"- The company should focus on expanding their business during summer & clear weather season\n\n\n- Based on previous data it is expected to have a boom in the number of users once the situation comes back to normal, compared to 2019.\n\n\n- There would be fewer bookings during Light Snow or Rain, they could probably use this time to service the bikes without having a business impact.\n\n\n- Hence when the situation comes back to normal, the company should come up with new offers during spring when the weather is pleasant and also advertise a little for September as this is when business would be at its best.\n\n\n**<font color='blue'>Conclusion**:\n\nSignificant variables to predict the demand for shared bikes\n\n- Year (2019)\n- temp\n- holiday\n- windspeed\n- Season\n- Months\n- weathersit (Cloudy,Light rain & Thunderstorm)\n\n---","b63272b8":"### <font color='blue'>6.1 Error Distribution","1b880159":"# <font color='brown'><center> Bike Sharing - Using Multiple Linear Regression","d237659b":"---\n## <font color='blue'>8. Final Model Interpretation","4b1ed6eb":"### <font color='blue'>6.4 Checking the $R^2$ value using sklearn","30ddbcaa":"**<font color='blue'>Inference:**\n- Errors are normally distributed, centred around mean 0","26e05738":"### <font color='blue'>6.2 Pattern checking for Actual Vs Predicted","3e2af63f":"#### <font color='blue'>Model_2: Rebuilding the model without `hum`","9e3b1ac9":"#### <font color='blue'>Model_4: Rebuilding the model without `mnth_Jul`","265dfd3c":"### <font color='blue'>6.3 Checking the error term pattern","bca93e91":"**<font color='blue'>Interpretation:**\n- As per the `Prob (F-statistic)`, the value is practically `zero` so that the overall model is `significant`\n- As per the p-values, all the features are having a p-value of less than `0.05` all the features are `significant`\n- As per the `VIF`, all the `VIF` values are less than `5`, so there is no high multicollinearity in this model\n- We can try replacing the `mnth_sep` with `temp` because both features correlate with each other it seems `temp` is an important feature","5aea92b8":"---\n\n## <font color='blue'>3. Exploratory Data Analysis","587e3d01":"#### <font color='blue'>Model_6: Rebuilding the model with replacing `mnth_Sep` with `temp` because they are correlating with each other","2281ba83":"**<font color='blue'>Inference:**\n- There is a positive correlation between `temp & atemp` and `cnt`\n- There is a negative correlation between `windspeed & hum` and `cnt`","548ffb30":"### <font color='blue'>3.2 Bivariate Analysis","0e19da11":"### <font color='blue'>6.5 Checking the relationship between `y_train` and `residuals`","fb41ad4d":"#### <font color='blue'>3.3.1 Pairplot for all the columns","c474ae3b":"**`yr, holiday, workingday`** are Binary categorical variables, we can keep as it is for model building","ca7af4de":"**<font color='blue'>Inference:**\n- $R^2$ value for predictions on test data (0.79) is almost the same as R2 value of train data(0.819). This is a good R-squared value\n- The difference between the $R^2$ values is less than `5%`\n- Hence we can see our model is performing well even on unseen data (test data)","5869b92c":"As we can see the `min` and `max` values for all the columns are in between 0 and 1, so the required variable has been scaled properly, we can start building the model for the training dataset","c2b8554d":"---\n## <font color='blue'>4. Data Preparation for Linear Regression","3a8d1f07":"**<font color='blue'>Inference:**\n- We can observe that the variance of the residuals (error terms) is constant across predictions. i.e. the error term does not vary much as the value of the predictor variable changes.","c3aa4c82":"#### <font color='blue'>3.1.4 Univariate Analysis on Categorical columns","dd0513e0":"### <font color='blue'>5.1 Automated Feature Selection - using RFE","194d71e2":"### <font color='blue'>7.2 $R^2$ value for test predictions","9c56874b":"#### <Font color='blue'>3.1.2 Converting the categorical variables from the numerical category into categories","52ef059c":"#### <font color='blue'>7.3.2 Checking the pattern between actual and predicted","6dd68d3f":"### <font color='blue'>4.1 Creating dummy variables for all categorical variables\n\nHere except `yr,holiday & workingday` (already in binary form) we can create the dummy variables","59ff1160":"<div>\n<img src=\"https:\/\/storage.googleapis.com\/gweb-uniblog-publish-prod\/original_images\/image1_hH9B4gs.jpg\" width='1000'>\n<\/div>","bd984ff9":"### <font color='blue'>5.2 Manual Feature Elimination - using p-value & VIF","d25fa976":"### <font color='blue'>5.3 Model Building","2caa3621":"---\n## <font color='blue'>7. Predictions and evaluation on the test data","464e588a":"**<font color='blue'>We can see that the equation for best fitted line is:**\n\n$$cnt(demand) = 1656.5419 + 2048.1066\\times{\\text{yr}} + 3893.6182\\times{\\times{temp}} + 487.6967\\times{\\text{workingday}} -1424.8209\\times{\\text{windspeed}}-650.4761\\times{\\text{season_spring}}+312.0586\\times{\\text{season_summer}}+617.6858\\times{\\text{season_winter}}-382.3078\\times{\\text{mnth_Jan}}+582.6714\\times{\\text{weekday_Sat}}-664.7305\\times{\\text{weathersit_Cloudy}}-2482.0611\\times{\\text{weathersit_Light Rain + Thunderstorm}}$$","8b7d5c1d":"#### <font color='blue'>5.2.2 Creating a Function for VIF","0c1f7caa":"#### <font color='blue'>Model_1: With all RFE selected Features","f4f5cbd7":"#### <font color='blue'>7.3.3 Checking distribution of Error term ","69a939bb":"**<font color='blue'>Inference:**\n- Actual and Predicted both are following almost the same pattern in the training dataset, so this model seems to fit well","ab5a57d9":"we can start build the model using `RFE` selected 15 features","83b155f9":"#### <font color='blue'>2.3.1 Inspecting the various aspects of the `bike_sharing` dataset","3f5dd3c3":"**<font color='blue'>Interpretation:**\n- As per the `Prob (F-statistic)`, the value is practically `zero` so that the overall model is `significant`\n- As per the p-values, the feature `holiday` has a p-value of `0.081` which is `insignificant` so we can drop this feature\n- As per the `VIF`, all the `VIF` values are less than `5`, so there is no high multicollinearity in this model"}}