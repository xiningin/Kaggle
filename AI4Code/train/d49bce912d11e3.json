{"cell_type":{"12b16c9e":"code","40a79317":"code","92975e81":"code","1a86fc2e":"code","80a281be":"code","f34380d0":"code","853c479b":"code","fdf3398e":"code","9b32fae6":"code","2f382611":"code","2af2112c":"code","f83418d9":"code","961e458b":"code","dce0e389":"code","da6f3056":"code","434c5272":"code","d1fe593a":"code","4c8535de":"code","6d19b6e8":"code","28d42370":"code","395a4c78":"code","26f1ed93":"code","bb58d6e4":"code","ac186a99":"code","c10596a5":"code","ff378b19":"code","1d1d4440":"code","332be783":"code","7118475f":"code","0d192396":"code","1460ae92":"code","111ccc8b":"markdown","57b6d6e3":"markdown","d5b67aef":"markdown","7bc7a7b3":"markdown","c0945f44":"markdown","3c4ed8bd":"markdown","77c1478b":"markdown","c135dc2c":"markdown","7be8e74a":"markdown","9f222329":"markdown","1aef9115":"markdown","cea37a6a":"markdown","261fc04e":"markdown","5ddf7354":"markdown"},"source":{"12b16c9e":"import numpy as np\nimport pandas as pd\nimport os\nimport email\nimport email.policy\nfrom bs4 import BeautifulSoup\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#Let's explore the directory segmentation\nos.listdir('\/kaggle\/input\/ham-and-spam-dataset\/')","40a79317":"ham_filenames = [name for name in sorted(os.listdir('\/kaggle\/input\/ham-and-spam-dataset\/ham\/')) if len(name) > 20]\nspam_filenames = [name for name in sorted(os.listdir('\/kaggle\/input\/ham-and-spam-dataset\/spam')) if len(name) > 20]","92975e81":"#How's the dataset structure? How many ham\/spam emails does it contain?\n\nprint('Total ham emails: ',len(ham_filenames))\nprint('Total spam emails: ',len(spam_filenames))\nprint('Spam percentage: ',100*(len(spam_filenames)\/(len(ham_filenames)+len(spam_filenames))))","1a86fc2e":"#Let's load an email to see how it looks like:\n\n#Using email.parser: https:\/\/docs.python.org\/3\/library\/email.parser.html\n#\"The email package provides a standard parser that understands most email document structures, including MIME documents\"\n\nwith open(os.path.join('\/kaggle\/input\/ham-and-spam-dataset\/ham\/', ham_filenames[0]), \"rb\") as file:\n    ham_email =  email.parser.BytesParser(policy=email.policy.default).parse(file)\n\nprint('Header field names: ',ham_email.keys())\nprint('\\n -------------------------------------- \\n')\nprint('Message field values: ',ham_email.values())\nprint('\\n -------------------------------------- \\n')\nprint('Message content:',ham_email.get_content()[:500])","80a281be":"#Let's extract some email fields\n\nemail_subject = ham_email.get_all('Subject')\nemail_from = ham_email.get_all('From')\nemail_to = ham_email.get_all('To')\n\nprint('Email from: ',email_from)\nprint('Email to: ',email_to)\nprint('Email subject: ',email_subject)","f34380d0":"def upload_ham(filename):\n    \"\"\"This function process a ham email file located at a specified directory and returns it as an email object\"\"\"\n    directory = '\/kaggle\/input\/ham-and-spam-dataset\/ham\/'\n    with open(os.path.join(directory, filename), \"rb\") as file:\n        return email.parser.BytesParser(policy=email.policy.default).parse(file)\n\ndef upload_spam(filename):\n    \"\"\"This function process a spam email file located at a specified directory and returns it as an email object\"\"\"\n    directory = '\/kaggle\/input\/ham-and-spam-dataset\/spam\/'\n    with open(os.path.join(directory, filename), \"rb\") as file:\n        return email.parser.BytesParser(policy=email.policy.default).parse(file)\n    \nham_emails = [upload_ham(filename=name) for name in ham_filenames]\nspam_emails = [upload_spam(filename=name) for name in spam_filenames]","853c479b":"#Checking if everything was uploaded properly:\n\nprint(ham_emails[0].get_all('Subject'))\nprint(ham_emails[0].get_content())\nprint('\\n\\n -----------------------------------------------------------\\n\\n')\nprint(spam_emails[1].get_all('Subject'))\nprint(spam_emails[1].get_content())","fdf3398e":"#Let's research about what email content types are:\n\nham_email_types = []\nspam_email_types = []\n\nfor i in range(len(ham_filenames)):\n    ham_email_types.append(ham_emails[i].get_content_type())\n\nfor i in range(len(spam_filenames)):\n    spam_email_types.append(spam_emails[i].get_content_type())\n\nprint('Ham content types: ',set(ham_email_types))\nprint('Spam content types: ',set(spam_email_types))","9b32fae6":"#We need to identify what the multipart emails are structured of\n\ndef email_content_type(email):\n    \"\"\"This function returns the content type of an email and if it has a multipart shape then returns the multiparts type\"\"\"\n    if isinstance(email, str):\n        return email\n    payload = email.get_payload()\n    if isinstance(payload, list):\n        return \"multipart({})\".format(\", \".join([email_content_type(sub_email) for sub_email in payload]))\n    else:\n        return email.get_content_type()","2f382611":"ham_email_types = []\nspam_email_types = []\n\nfor i in range(len(ham_filenames)):\n    ham_email_types.append(email_content_type(ham_emails[i]))\n\nfor i in range(len(spam_filenames)):\n    spam_email_types.append(email_content_type(spam_emails[i]))\n\nprint('Ham content types: ',set(ham_email_types))\nprint('Spam content types: ',set(spam_email_types))","2af2112c":"#Now that we've identified what are the email content types, we need to transform all html emails to plain format.\n\nfrom bs4 import BeautifulSoup\nhtml = spam_emails[1].get_content()\nsoup = BeautifulSoup(html)\nprint(soup.get_text().replace('\\n\\n',''))","f83418d9":"#Let's build a function with the previous process to convert all html emails into plain text\n\ndef html_to_plain(email):\n    soup = BeautifulSoup(email.get_content())\n    return soup.get_text().replace('\\n\\n','').replace('\\n',' ') ","961e458b":"#Now all emails which have\/contain HTML tags will be converted to plain text\n\ndef email_to_plain(email):\n    content_type = email_content_type(email)\n    for part in email.walk(): \n        #The .walk() documentation at https:\/\/docs.python.org\/3\/library\/email.message.html\n        #\"The walk() method is an all-purpose generator which can be used to iterate over all \n        #the parts and subparts of a message object tree, in depth-first traversal order.\"\n        partContentType = part.get_content_type()\n        if partContentType not in ['text\/plain','text\/html']:\n            continue\n        try:\n            partContent = part.get_content()\n        except: \n            partContent = str(part.get_payload())\n        if partContentType == 'text\/plain':\n            return partContent\n        else:\n            return html_to_plain(part)","dce0e389":"#Let's test this out.\nemail_test1 = email_to_plain(spam_emails[1])\nemail_test2 = email_to_plain(spam_emails[227])\nprint(email_test1)\nprint('\\n\\n')\nprint(email_test2[:1000])","da6f3056":"#Spam email #226 contains an unknown encoding so we will remove it from the list\ndel spam_emails[226]","434c5272":"ham_dataset = []\nspam_dataset = []\n\n#Ham processing\nfor i in range(len(ham_emails)):\n    ham_dataset.append(email_to_plain(ham_emails[i]))\nham_dataset = pd.DataFrame(ham_dataset,columns=['Email content'])\nham_dataset['Label'] = 0\n\n#Spam processing\nfor i in range(len(spam_emails)):\n    spam_dataset.append(email_to_plain(spam_emails[i]))\nspam_dataset = pd.DataFrame(spam_dataset,columns=['Email content'])\nspam_dataset['Label'] = 1\n\ndataset = pd.concat([ham_dataset,spam_dataset])\ndataset.head()","d1fe593a":"#We will shuffle the data and also reset indexes\ndataset = dataset.dropna()\ndataset = dataset.sample(frac=1).reset_index(drop=True)\ndataset.head()","4c8535de":"#Removing special chars because they just add noise and make the models poor when predicting.\nfor i in range(len(dataset)):\n    dataset.at[i,'Email content'] = dataset.loc[i]['Email content'].replace('!','').replace('?','').replace(',','').replace('[','').replace(']','').replace('(','').replace(')','').replace('...','')\n    dataset.at[i,'Email content'] = dataset.loc[i]['Email content'].replace('>','').replace('<','').replace('\\n',' ').replace('-','').replace('+','').replace('#','')\ndataset.head()","6d19b6e8":"def input_preprocessing(text):\n    text = text.replace('!','').replace('?','').replace(',','').replace('[','').replace(']','').replace('(','').replace(')','').replace('...','')\n    text = text.replace('>','').replace('<','').replace('\\n',' ').replace('-','').replace('+','').replace('#','')\n    return text","28d42370":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(dataset['Email content'],dataset['Label'],shuffle=True,random_state=0)","395a4c78":"#checking if everything went OK.\nprint (len(X_train),len(X_test),len(y_train),len(y_test))","26f1ed93":"pd.DataFrame(list(zip(X_train,y_train)))","bb58d6e4":"!pip install transformers==2.10.0","ac186a99":"!pip install simpletransformers","c10596a5":"from simpletransformers.classification import ClassificationModel\nimport pandas as pd\n\n\n# Train and Evaluation data needs to be in a Pandas Dataframe containing at least two columns. If the Dataframe has a header, it should contain a 'text' and a 'labels' column. If no header is present, the Dataframe should contain at least two columns, with the first column is the text with type str, and the second column in the label with type int.\n# train_data = [['Example sentence belonging to class 1', 1], ['Example sentence belonging to class 0', 0], ['Example eval senntence belonging to class 2', 2]]\ntrain_df = pd.DataFrame(list(zip(X_train,y_train)))\n\n# eval_data = [['Example eval sentence belonging to class 1', 1], ['Example eval sentence belonging to class 0', 0], ['Example eval senntence belonging to class 2', 2]]\neval_df = pd.DataFrame(list(zip(X_test,y_test)))\n\n# Create a ClassificationModel\nmodel = ClassificationModel('bert', 'bert-base-cased', num_labels=3, args={'reprocess_input_data': True, 'overwrite_output_dir': True},use_cuda=False)\n# You can set class weights by using the optional weight argument\n\n# Train the model\nmodel.train_model(train_df)\n\n# Evaluate the model\nresult, model_outputs, wrong_predictions = model.eval_model(eval_df)\n\npredictions, raw_outputs = model.predict(X_test.to_list())","ff378b19":"result","1d1d4440":"predictions, raw_outputs = model.predict(X_test.to_list())","332be783":"y_predicted= predictions","7118475f":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nmatrix = confusion_matrix(y_test, y_predicted)","0d192396":"import seaborn as sns\nconf_matrix = pd.DataFrame(matrix, index = ['Ham','Spam'],columns = ['Ham','Spam'])\n#Normalizing\nconf_matrix = conf_matrix.astype('float') \/ conf_matrix.sum(axis=1)[:, np.newaxis]\nplt.figure(figsize = (15,15))\nsns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})","1460ae92":"email_test = ['Dear Sergio, Flash Sale at Walmart! 25% OFF all weekend!']\nprediction = model.predict(email_test)\n\nif prediction == 0:\n    print('The email has not been flagged as SPAM.')\nelse:\n    print('The email has been flagged as SPAM.')","111ccc8b":"# Model training and selection\n\nI am going to experiment with bert models from huggingface","57b6d6e3":"# Building the dataset to train the model\nEssentially we'll create a dataframe with the emails' content and their particular label. This will allow us to implement NLP to feed a ML model","d5b67aef":"# Data Importing\nNow that we've explored how the data is structured, we are going to import all emails to be processed later on the notebook.","7bc7a7b3":"# Data exploration","c0945f44":"# Project description","3c4ed8bd":"## Dataset structure","77c1478b":"The below function will be used later on the notebook to process the prediction inputs.","c135dc2c":"We're gonna implement some NLP in order to facilitate the model to predict well.","7be8e74a":"import os, sys, shutil\nimport time\nimport gc\nfrom contextlib import contextmanager\nfrom pathlib import Path\nimport random\nimport numpy as np, pandas as pd\nfrom tqdm import tqdm, tqdm_notebook\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(f'[{name}] done in {time.time() - t0:.0f} s')\n\nUSE_APEX = True\n\nif USE_APEX:\n    with timer('install Nvidia apex'):\n        # Installing Nvidia Apex\n        os.system('git clone https:\/\/github.com\/NVIDIA\/apex; cd apex; pip install -v --no-cache-dir' + \n                  ' --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\/')\n        os.system('rm -rf apex\/.git') # too many files, Kaggle fails\n        from apex import amp","9f222329":"## Confusion Matrix","1aef9115":"# **Converting emails to plain text**\nIn the previous output you could notice that there are some emails with HTML format. We need them to be plain text format.","cea37a6a":"Adapted from the notebook of sergio virahonda","261fc04e":"## Model testing","5ddf7354":"For this opportunity we're going to explore **Ham and Spam emails from SpamAssasin** provided at https:\/\/www.kaggle.com\/veleon\/ham-and-spam-dataset - It contains several email files all readable by Python Email library. I'll import all of them, explore them, determine commonly used words in Spam emails, will train some models based on the files in order to find the best that fits the data and finally start predicting."}}