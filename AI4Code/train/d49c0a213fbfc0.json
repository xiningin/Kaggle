{"cell_type":{"2a821035":"code","3df15e53":"code","26f577fc":"code","ed02c1ff":"code","5ed59b53":"code","e4d57d60":"code","0f21d5bc":"code","9026f4e9":"code","4a501366":"code","4e7b1c26":"code","7ff9adc2":"code","29c570ca":"code","d3373b1f":"code","50a3a817":"code","38f63857":"code","109e5960":"code","020fdc5d":"code","b53f655c":"code","19027a1e":"code","f7465f2f":"code","a54e5410":"code","d85ec567":"code","74bbb99b":"code","0cac8bd1":"code","f68b582c":"code","9aa30997":"code","870e5ac4":"code","917aa4c7":"code","b0c70fd9":"code","7195baf7":"code","8f962bd9":"code","6d08ba9d":"code","eb98e72c":"code","f372a318":"code","c6ccca1f":"code","25be36e0":"code","1052b63c":"code","16701dc5":"code","6ec6b6a2":"code","38ccc11f":"code","d3a1028c":"code","44c06d43":"code","db542d87":"code","fdad0168":"code","47dc23fd":"code","415c64dd":"code","1cd7b0c3":"markdown","b78a3d35":"markdown","cd8c0188":"markdown","2eef4675":"markdown","0f2975ad":"markdown","7eef78da":"markdown","48e57d7f":"markdown","25588ba3":"markdown","94693de4":"markdown"},"source":{"2a821035":"# Important Libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\n\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\npd.set_option('max_columns', 200)","3df15e53":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","26f577fc":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","ed02c1ff":"train.shape","5ed59b53":"test.shape","e4d57d60":"train.head()","0f21d5bc":"test.head()","9026f4e9":"train.columns","4a501366":"# to know the missing values in columns\nprint(train.info())\nprint('**'* 50)\nprint(test.info())","4e7b1c26":"# Now removing the columns with large number of missing values from training set\ndrop_columns = ['FireplaceQu','PoolQC','Fence','MiscFeature','BsmtUnfSF']\ntrain.drop(drop_columns, axis = 1, inplace = True)\ntest.drop(drop_columns, axis = 1, inplace = True)","7ff9adc2":"train['LotFrontage'].fillna(train['LotFrontage'].median(), inplace = True)\ntrain['MasVnrArea'].fillna(train['MasVnrArea'].median(), inplace = True)","29c570ca":"fill_col = ['Alley','MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n            'GarageType','GarageFinish','GarageCond']\nboth_col = [train,test]\nfor col in both_col:\n    col[fill_col] = col[fill_col].fillna('None')","d3373b1f":"colfil = ['LotFrontage','MasVnrArea','BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','GarageCars', \n            'GarageArea']\nfor coll in colfil:\n    test[coll].fillna(test[coll].median(), inplace = True)","50a3a817":"both_col = [train, test]\nfor col in both_col:\n    col['YrBltAndRemod'] = col['YearBuilt'] + col['YearRemodAdd']\n    col['TotalSF'] = col['TotalBsmtSF'] + col['1stFlrSF'] + col['2ndFlrSF']\n    col['Total_sqr_footage'] = (col['BsmtFinSF1'] + col['BsmtFinSF2'] +\n                                 col['1stFlrSF'] + col['2ndFlrSF'])\n\n    col['Total_Bathrooms'] = (col['FullBath'] + (0.5 * col['HalfBath']) +\n                               col['BsmtFullBath'] + (0.5 *col['BsmtHalfBath']))\n\n    col['Total_porch_sf'] = (col['OpenPorchSF'] + col['3SsnPorch'] +\n                              col['EnclosedPorch'] + col['ScreenPorch'] +\n                              col['WoodDeckSF'])","38f63857":"both_col = [train,test]\nfor col in both_col:\n    col['haspool'] = col['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n    col['has2ndfloor'] = col['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n    col['hasgarage'] = col['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n    col['hasbsmt'] = col['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n    col['hasfireplace'] = col['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","109e5960":"train.shape","020fdc5d":"test.shape","b53f655c":"drop_col = ['Exterior2nd','GarageYrBlt','Condition2','RoofMatl','Electrical','HouseStyle','Exterior1st',\n            'Heating','GarageQual','Utilities','MSZoning','Functional','KitchenQual']\ntrain.drop(drop_col, axis = 1,inplace = True)\ntest.drop(drop_col, axis = 1,inplace = True)","19027a1e":"train.shape","f7465f2f":"test.shape","a54e5410":"train.info()","d85ec567":"test.info()","74bbb99b":"# to know the correlation between the each columns in dataset\nplt.figure(figsize=(30,10))\nsns.heatmap(test.corr(),cmap='coolwarm',annot = True)\nplt.show()","0cac8bd1":"x_t = train.drop(['SalePrice'], axis = 1)\ny_t = train['SalePrice']","f68b582c":"# to convert a categorical into one hot encoding\nhot_one= pd.get_dummies(x_t)","9aa30997":"hot_one.shape","870e5ac4":"x_train ,x_test ,y_train ,y_test = train_test_split(hot_one, y_t, test_size = 0.3, random_state = 0)","917aa4c7":"model = RandomForestRegressor(n_estimators = 300, random_state = 0)\nmodel.fit(x_train,y_train)","b0c70fd9":"dtr_pred = model.predict(x_test)","7195baf7":"from IPython.display import Image\nImage(\"..\/input\/kaggle\/Screenshot-2019-05-16-at-6.43.11-PM-850x262.png\")","8f962bd9":"\nprint('RMSE:', np.sqrt(mean_squared_log_error(y_test, dtr_pred)))","6d08ba9d":"# how the model predicts against the actual known value\nplt.figure(figsize=(15,8))\nplt.scatter(y_test,dtr_pred, c='green')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","eb98e72c":"hot_two = pd.get_dummies(test)","f372a318":"hot_two.shape","c6ccca1f":"hot_two.head()","25be36e0":"test_prediction = model.predict(hot_two)","1052b63c":"test_pred = pd.DataFrame(test_prediction, columns=['SalePrice'])","16701dc5":"test_pred.head()","6ec6b6a2":"from sklearn import ensemble\nmodell = ensemble.GradientBoostingRegressor(n_estimators = 3000, max_depth = 5,max_features='sqrt', min_samples_split = 10,\n          learning_rate = 0.005,loss = 'huber',min_samples_leaf=15,random_state =42)\nmodell.fit(x_train, y_train)","38ccc11f":"pred = modell.predict(x_test)","d3a1028c":"print('RMSE:', np.sqrt(mean_squared_log_error(y_test, pred)))","44c06d43":"# how the model predicts against the actual known value\nplt.figure(figsize=(15,8))\nplt.scatter(y_test,pred, c='red')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","db542d87":"test_pred_2 = modell.predict(hot_two)","fdad0168":"test_pred = pd.DataFrame(test_pred_2, columns=['SalePrice'])","47dc23fd":"test_pred.head()","415c64dd":"# Gradient Boosting has the low error as compare with Random Forest Regression\nout = pd.DataFrame({'Id': hot_two['Id'], 'SalePrice': test_pred_2})\nout.to_csv('submission.csv', index=False,header=True)","1cd7b0c3":"## 1. Import all Essential Libraries","b78a3d35":"## 2. Load Data","cd8c0188":"# Advanced Regression Techniques","2eef4675":"## 6.  Run the Gradient Boosting Regression Model","0f2975ad":"## 4. Splitting a Dataset into Train Data and Test Data","7eef78da":"**Root Mean Squared Logarithmic Error** : In case of Root mean squared logarithmic error, we take the log of the predictions and actual values. So basically, what changes are the variance that we are measuring. RMSLE is usually used when we don\u2019t want to penalize huge differences in the predicted and the actual values when both predicted and true values are huge numbers.\n\n\n\n\nIf both predicted and actual values are small: RMSE and RMSLE are same.\nIf either predicted or the actual value is big: RMSE > RMSLE\nIf both predicted and actual values are big: RMSE > RMSLE (RMSLE becomes almost negligible)","48e57d7f":"1. Import all Essential Libraries\n2. Load Data\n3. Feature Engineering on DataSet\n4. Splitting a Dataset into Train Data and Test Data\n5.  Run the Random Forest Regression Model\n6.  Run the Gradient Boosting Regression Model\n","25588ba3":"## 3. Feature Engineering on DataSet","94693de4":"## 5.  Run the Random Forest Regression Model\n"}}