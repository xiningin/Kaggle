{"cell_type":{"fbee25eb":"code","6bb7f719":"code","67a6f075":"code","74d01728":"code","e32c516c":"code","c78f0a93":"code","48ad8625":"code","169810ea":"code","a8db2a0b":"code","463f40aa":"code","d6a56c55":"code","e252a56b":"code","87ee5e0a":"code","fbd68cdc":"code","04229d27":"code","a9d3a529":"code","f4f9c3e2":"code","6c1d6471":"code","c53b2b2f":"code","007bcead":"code","9adc8674":"code","46473413":"code","2a4cac8c":"code","5d499a2e":"markdown","2d4460b9":"markdown","2e48d19a":"markdown","b86aac59":"markdown","38bc7039":"markdown","80fcf083":"markdown","a3895ed3":"markdown","428da4a1":"markdown","fbad043b":"markdown","8b7af1f8":"markdown"},"source":{"fbee25eb":"'''Install pyspark'''\n!pip install pyspark","6bb7f719":"import math\nimport numpy as np \nimport pandas as pd  \nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import isnan, when, count, col, isnull, asc, desc, mean\n\n'''Create a spark session'''\nspark = SparkSession.builder.master(\"local\").appName(\"DataWrangling\").getOrCreate()\n'''Set this configuration to get output similar to pandas'''\nspark.conf.set('spark.sql.repl.eagerEval.enabled', True)","67a6f075":"df = spark.read.csv('..\/input\/titanic\/train.csv',header=True)\ndf.limit(5)","74d01728":"'''Find the count of a dataframe'''\ndf.count()","e32c516c":"df.groupBy('Sex').count()","c78f0a93":"df.select('Embarked').distinct()","48ad8625":"'''Select a single column'''\ndf.select('Survived').limit(2)","169810ea":"df.select('Survived', 'Age', 'Ticket').limit(5)","a8db2a0b":"'''Find the count of missing values'''\ndf.select([count(when(isnull(column), column)).alias(column) for column in df.columns])","463f40aa":"'''Find not null values of 'Age' '''\ndf.filter(col('Age').isNotNull()).limit(5)","d6a56c55":"'''Another way to find not null values of 'Age' '''\ndf.filter(\"Age is not NULL\").limit(5)","e252a56b":"'''Find the null values of 'Age' '''\ndf.filter(col('Age').isNull()).limit(5)","87ee5e0a":"'''Another way to find null values of 'Age' '''\ndf.filter(\"Age is NULL\").limit(5)","fbd68cdc":"'''Find the mean of the column \"Age\" '''\nmean_ = df.select(mean(col('Age'))).take(1)[0][0]\nmean_ = math.ceil(mean_)","04229d27":"'''Find the value counts of Cabin and select the mode'''\ndf.groupBy(col('Cabin')).count().sort(desc(\"count\")).limit(5)","a9d3a529":"'''Find the mode of'''\nembarked_mode = df.groupBy(col('Embarked')).count().sort(desc(\"count\")).take(1)[0][0]","f4f9c3e2":"'''Fill the missing values'''\ndf = df.fillna({'Age':mean_,'Cabin':'C23','Embarked':embarked_mode})","6c1d6471":"'''Drop a single column'''\ndf.drop('Age').limit(5)","c53b2b2f":"'''Drop multiple columns'''\ndf.drop('Age', 'Parch','Ticket').limit(5)","007bcead":"'''Sort age in descending order'''\ndf.sort(desc('Age')).limit(5)","9adc8674":"'''Sort \"Parch\" column in ascending order and \"Age\" in descending order'''\ndf.sort(asc('Parch'),desc('Age')).limit(5)","46473413":"'''Finding the mean age of male and female'''\ndf.groupBy('Sex').agg(mean('Age'))","2a4cac8c":"'''Finding the mean Fare of male and female'''\ndf.groupBy('Sex').agg(mean('Fare'))","5d499a2e":"# Filtering null and not null values","2d4460b9":"# Find the count of missing values","2e48d19a":"![spark.png](attachment:spark.png)\n# Apache Spark\n* Apache Spark is an analytics engine and framework to perform cluster computing. The inherent nature of Spark is parallel processing which allows it to complete the tasks in the fastest way possible. \n* Spark is **polyglot** which means it can be run on top of many programming languages such as Java, Scala, Python, and R.\n* Spark runs everywhere. Spark runs on Hadoop, Apache Mesos, Kubernetes, standalone, or in the cloud. It can access diverse data sources.\n* Spark uses DAG (Directed Acyclic Graph) to schedule tasks.\n\n[Reference](https:\/\/spark.apache.org\/)\n\n\n\n## Spark Session\n* The entry point to programming Spark with the Dataset and DataFrame API.\n* Spark Session helps us to create and manipulate DataFrames.","b86aac59":"# Select specific set of columns in a dataframe","38bc7039":"# Dropping columns","80fcf083":"# Count of values in a column","a3895ed3":"# Filling in missing values","428da4a1":"# Sorting columns","fbad043b":"# Find distinct values of a column in a dataframe","8b7af1f8":"# Groupby and aggregation"}}