{"cell_type":{"7154f910":"code","d277c7ad":"code","326791a3":"code","dddf07f7":"code","4c2083cb":"code","8cf8a183":"code","50df256f":"code","4ef69d28":"code","46599be3":"code","70ad4590":"code","41b1e261":"code","71ca8284":"code","5f065756":"code","7986ba81":"code","d32b7eee":"code","ba173bf4":"code","3e2c9406":"code","2b3beec9":"code","97a1af52":"code","535634f3":"code","26b89ff0":"code","62e56d30":"code","11484b39":"code","e810e729":"code","aaae89ef":"code","bdf5c682":"code","c66d7cfa":"code","9ce0b016":"code","f18f4986":"code","30b2b039":"code","67bec5a7":"code","b0d8de3c":"code","ed65f1da":"code","b77ca3ea":"code","29a5834b":"code","724c457f":"code","aeb67b6a":"code","0e681405":"code","ed6ecd5d":"code","fc8adc06":"code","f7130eb7":"code","f9993f5e":"code","b5031bb9":"code","d0a2b1fa":"code","fc8e8798":"code","e22e0ade":"code","8df91a58":"code","533c065e":"code","9954d27d":"code","e80a141c":"code","cdb61ea0":"code","19ddb34d":"code","7ccdc376":"code","6865e896":"code","90edd0a9":"code","21da9e62":"code","bd89120c":"code","760670fa":"code","271c172d":"code","165c66e6":"code","d923b78d":"code","3093c52c":"code","f2034696":"code","f267cb3d":"code","80b17e41":"code","da250b80":"code","0d29837b":"code","ac77153e":"code","5fcb5407":"code","e8a6ad0c":"code","aba57063":"code","21966e95":"code","3891485d":"code","62985cc7":"code","e403ec5d":"code","3df3e194":"code","30381850":"code","aeea9a9f":"code","b451a434":"code","2faf9166":"code","2558020d":"code","483b42ba":"code","f3552504":"code","e0c0568f":"code","5d8cd8da":"code","1ef0d497":"markdown","5fbd7719":"markdown","a9c1aea5":"markdown","b2cfed25":"markdown","d73e5168":"markdown","f2e279b3":"markdown","a9c3f97c":"markdown","632da7af":"markdown","348d94f4":"markdown","03654daa":"markdown","3cf42f92":"markdown","099460ca":"markdown","f0c8b000":"markdown","1a0ee592":"markdown","84158120":"markdown","a3e98433":"markdown","f4a86d4e":"markdown","01860e8f":"markdown","13154ba8":"markdown","7dfccccb":"markdown","de9396b7":"markdown","f6bf7910":"markdown","73156c09":"markdown","83a12bf9":"markdown","ac3748fc":"markdown","914fe395":"markdown","d6aedc22":"markdown","34657e63":"markdown","fdb3a799":"markdown","72e2c6d6":"markdown","5114760e":"markdown","9264ee0b":"markdown","d1593ab8":"markdown","a556d30e":"markdown","c90c7043":"markdown","726d50f5":"markdown","c8b52b8d":"markdown","9dee4a50":"markdown","b8e8e18f":"markdown","24429174":"markdown","1e6538af":"markdown","2f1caba6":"markdown","78933445":"markdown","52e05ac5":"markdown","fe242ebf":"markdown","7dabc987":"markdown","104a0fe2":"markdown","07c7bfd4":"markdown","733557e0":"markdown","4ed91237":"markdown","8b94e6be":"markdown","a8929dd4":"markdown","a8803d82":"markdown","db1a6e1f":"markdown","8c3f9296":"markdown","2beeb4f9":"markdown","ab905909":"markdown","72a80567":"markdown","474e0311":"markdown","5abac131":"markdown","5fde74f2":"markdown","8c8ad690":"markdown","a2a0417c":"markdown","8c21f882":"markdown","f329b746":"markdown","26c88dcc":"markdown","fec7f4c3":"markdown","15639230":"markdown","314f65dc":"markdown","626f05a8":"markdown","76d128d7":"markdown","bbd15561":"markdown","6850ca84":"markdown","1ed9c08b":"markdown","e67c856d":"markdown","5c4e91e2":"markdown","1344add1":"markdown","55b5fa84":"markdown","cccea49b":"markdown","f09bbfe5":"markdown","976b7523":"markdown","f35b206d":"markdown","dcce1568":"markdown","864103ef":"markdown","c7d96f68":"markdown","a8d0b1d9":"markdown","718a5833":"markdown","ed4bfb4f":"markdown","e2cc75b4":"markdown","4a52cb98":"markdown","e8ba7e88":"markdown","84a83656":"markdown","501c83a7":"markdown"},"source":{"7154f910":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import chi2_contingency\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, make_scorer\nfrom scikitplot.metrics import plot_roc\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d277c7ad":"df = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ndf.head()","326791a3":"df.shape","dddf07f7":"df.columns","4c2083cb":"df.info()","8cf8a183":"df.isnull().sum()","50df256f":"df['city'].value_counts()","4ef69d28":"plt.figure(figsize=(10,7))\n\ndf['city'].value_counts()[:20].sort_values(ascending=True).plot(kind='barh')\nplt.title('Value Counts of Cities')\nplt.xlabel('Frequency')\nplt.ylabel('City Name');","46599be3":"df['gender'].value_counts()","70ad4590":"# Change pandas na to an actual na value.\ndf['gender'].fillna('na', inplace=True)","41b1e261":"df[df['gender'] == 'na']","71ca8284":"plt.figure(figsize=(15,7))\n\nplt.subplot(121)\nsns.countplot(data=df, x='gender')\nplt.title('Count of Gender')\nplt.xlabel('Gender')\nplt.ylabel('Frequency');\n\nplt.subplot(122)\nsns.barplot(data=df, x='gender', y='target')\nplt.title('Gender Proportion of Job Change')\nplt.xlabel('Gender')\nplt.ylabel('Proportion');","5f065756":"gender_table = pd.crosstab(df['gender'], df['target'])\ngender_table","7986ba81":"pd.crosstab(df['gender'], df['target'], normalize='index')","d32b7eee":"stat, p, dof, expected = chi2_contingency(gender_table)\n\n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Dependent (reject H0)') \nelse: \n    print('Independent (H0 holds true)') ","ba173bf4":"df['relevent_experience'].value_counts()","3e2c9406":"# replace the value has relevent experience to \"yes\" and no relevent experience to \"no\" in the column.\ndf['relevent_experience'] = df['relevent_experience'].replace('Has relevent experience', 'yes')\ndf['relevent_experience'] = df['relevent_experience'].replace('No relevent experience', 'no')\n","2b3beec9":"plt.figure(figsize=(15,7))\n\nplt.subplot(121)\nsns.countplot(data=df, x='relevent_experience')\nplt.title('Relevant Experience Counts')\nplt.xlabel('Has Relevant Experience')\nplt.ylabel('Count');\n\nplt.subplot(122)\nsns.barplot(data=df, x='relevent_experience', y='target')\nplt.title('Relevant Experience Proportion of Job Change')\nplt.xlabel('Has Relevant Experience')\nplt.ylabel('Proportion');\n","97a1af52":"exp_table = pd.crosstab(df['relevent_experience'], df['target'])","535634f3":"pd.crosstab(df['relevent_experience'], df['target'], normalize = 'index')","26b89ff0":"stat, p, dof, expected = chi2_contingency(exp_table)\n\n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Dependent (reject H0)') \nelse: \n    print('Independent (H0 holds true)') ","62e56d30":"df['enrolled_university'].value_counts()","11484b39":"df['enrolled_university'].fillna('na', inplace=True)","e810e729":"df['enrolled_university'].value_counts()","aaae89ef":"plt.figure(figsize=(15,7))\n\nplt.subplot(121)\nsns.countplot(data=df, x='enrolled_university')\nplt.title('University Course Counts')\nplt.xlabel('University Enrollment')\nplt.ylabel('Count');\n\n\nplt.subplot(122)\nsns.barplot(data=df, x='enrolled_university', y='target')\nplt.title('University Course Proportion of Job Change')\nplt.xlabel('University Enrollment')\nplt.ylabel('Proportion');","bdf5c682":"enrolled_table = pd.crosstab(df['enrolled_university'],df['target'])\npd.crosstab(df['enrolled_university'],df['target'], normalize = 'index')","c66d7cfa":"stat, p, dof, expected = chi2_contingency(enrolled_table)\n\n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Dependent (reject H0)') \nelse: \n    print('Independent (H0 holds true)') ","9ce0b016":"df['education_level'].value_counts()","f18f4986":"df['education_level'].fillna('na', inplace=True)","30b2b039":"df['education_level'].value_counts()","67bec5a7":"plt.figure(figsize=(15,7))\n\nplt.subplot(121)\nsns.countplot(data=df, x='education_level')\nplt.title('Education Level Counts')\nplt.xlabel('Education Level')\nplt.ylabel('Count');\n\n\nplt.subplot(122)\nsns.barplot(data=df, x='education_level', y='target')\nplt.title(' Education level Proportion of Job Change')\nplt.xlabel('Education Level')\nplt.ylabel('Proportion');\n","b0d8de3c":"edu_table = pd.crosstab(df['education_level'],df['target'])","ed65f1da":"pd.crosstab(df['education_level'],df['target'], normalize = 'index')","b77ca3ea":"stat, p, dof, expected = chi2_contingency(edu_table)\n\n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Dependent (reject H0)') \nelse: \n    print('Independent (H0 holds true)') ","29a5834b":"df['major_discipline'].value_counts()","724c457f":"df['major_discipline'].fillna('na', inplace=True)","aeb67b6a":"plt.figure(figsize=(15,7))\n\nplt.subplot(121)\nsns.countplot(data=df, x='major_discipline')\nplt.title('Counts of Majors')\nplt.xlabel('Major')\nplt.ylabel('Count');\n\nplt.subplot(122)\nsns.barplot(data=df, x='major_discipline', y='target')\nplt.title('Proportion of Majors of Job Change')\nplt.xlabel('Major')\nplt.ylabel('Frequency');","0e681405":"major_table = pd.crosstab(df['major_discipline'],df['target'])","ed6ecd5d":"pd.crosstab(df['major_discipline'],df['target'], normalize = 'index')","fc8adc06":"stat, p, dof, expected = chi2_contingency(major_table)\n\n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Dependent (reject H0)') \nelse: \n    print('Independent (H0 holds true)') ","f7130eb7":"df['company_size'].value_counts()","f9993f5e":"df['company_size'].fillna('na', inplace=True)","b5031bb9":"plt.figure(figsize=(15,7))\n\nplt.subplot(121)\nsns.countplot(data=df, y='company_size')\nplt.title('Company Size Counts')\nplt.xlabel('Count')\nplt.ylabel('Company Size');\n\nplt.subplot(122)\nsns.barplot(data=df, y='company_size', x='target')\nplt.title('Company Size Proportions of Job Change')\nplt.xlabel('Proportion')\nplt.ylabel('Company Size');","d0a2b1fa":"comp_size_table = pd.crosstab(df['company_size'],df['target'])\npd.crosstab(df['company_size'],df['target'], normalize = 'index')","fc8e8798":"stat, p, dof, expected = chi2_contingency(comp_size_table)\n\n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Dependent (reject H0)') \nelse: \n    print('Independent (H0 holds true)') ","e22e0ade":"df['company_type'].value_counts()","8df91a58":"df['company_type'].fillna('na', inplace=True)","533c065e":"plt.figure(figsize=(22,7))\n\nplt.subplot(121)\nsns.countplot(data=df, y='company_type')\nplt.title('Types of company Counts')\nplt.xlabel('Count')\nplt.ylabel('Company Type');\n\nplt.subplot(122)\nsns.barplot(data=df, y='company_type', x='target')\nplt.title('Types of company proprtion of Job Change')\nplt.xlabel('Proportion')\nplt.ylabel('Company Type');","9954d27d":"comp_type_table = pd.crosstab(df['company_type'],df['target'])\npd.crosstab(df['company_type'],df['target'], normalize = 'index')","e80a141c":"stat, p, dof, expected = chi2_contingency(comp_type_table)\n\n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Dependent (reject H0)') \nelse: \n    print('Independent (H0 holds true)') ","cdb61ea0":"df['city_development_index'].describe()","19ddb34d":"plt.hist(data=df, x='city_development_index');","7ccdc376":"plt.figure(figsize=(22,7))\n\nplt.subplot(121)\nplt.hist(data=df[df['target'] == 0], x='city_development_index')\n\nplt.subplot(122)\nplt.hist(data=df[df['target'] == 1], x='city_development_index');","6865e896":"plt.figure(figsize=(10,10))\nsns.boxplot(data=df, x='target', y='city_development_index')","90edd0a9":"no_change_df = df[df['target'] == 0]\nchange_df =  df[df['target'] == 1]","21da9e62":"stats.kruskal(no_change_df['city_development_index'], change_df['city_development_index'])","bd89120c":"df['experience'].value_counts()","760670fa":"df['experience'] = df['experience'].replace('>20', 21)\ndf['experience'] = df['experience'].replace('<1', 21)\ndf['experience'] = df['experience'].fillna(np.random.choice(df['experience']))","271c172d":"df['experience'] = df['experience'].astype('float64')","165c66e6":"df['experience'].describe()","d923b78d":"plt.hist(data=df, x='experience');","3093c52c":"plt.figure(figsize=(22,7))\n\nplt.subplot(121)\nplt.hist(data=df[df['target'] == 0], x='experience')\n\nplt.subplot(122)\nplt.hist(data=df[df['target'] == 1], x='experience');","f2034696":"plt.figure(figsize=(10,10))\nsns.boxplot(data=df, x='target', y='experience')","f267cb3d":"no_change_df = df[df['target'] == 0]\nchange_df =  df[df['target'] == 1]\n\nstats.kruskal(no_change_df['experience'], change_df['experience'])","80b17e41":"df['last_new_job'].value_counts()","da250b80":"df['last_new_job'] = df['last_new_job'].replace('>4', 5)\ndf['last_new_job'] = df['last_new_job'].replace('never', 0)\ndf['last_new_job'] = df['last_new_job'].fillna(np.random.choice(df['last_new_job']))\ndf['last_new_job'] = df['last_new_job'].astype('float64')","0d29837b":"plt.hist(data=df, x='last_new_job');","ac77153e":"plt.figure(figsize=(22,7))\n\nplt.subplot(121)\nplt.hist(data=df[df['target'] == 0], x='last_new_job')\n\nplt.subplot(122)\nplt.hist(data=df[df['target'] == 1], x='last_new_job');","5fcb5407":"plt.figure(figsize=(10,10))\nsns.boxplot(data=df, x='target', y='last_new_job');","e8a6ad0c":"no_change_df = df[df['target'] == 0]\nchange_df =  df[df['target'] == 1]\n\nstats.kruskal(no_change_df['last_new_job'], change_df['last_new_job'])","aba57063":"df['training_hours'].describe()","21966e95":"plt.hist(data=df, x='training_hours');","3891485d":"plt.figure(figsize=(22,7))\n\nplt.subplot(121)\nplt.hist(data=df[df['target'] == 0], x='training_hours')\n\nplt.subplot(122)\nplt.hist(data=df[df['target'] == 1], x='training_hours');","62985cc7":"plt.figure(figsize=(10,10))\nsns.boxplot(data=df, x='target', y='training_hours')","e403ec5d":"no_change_df = df[df['target'] == 0]\nchange_df =  df[df['target'] == 1]\n\nstats.kruskal(no_change_df['training_hours'], change_df['training_hours'])","3df3e194":"df[['male', 'other_gender', 'na_gender']] = pd.get_dummies(df['gender'])[['Male', 'Other', 'na']]\ndf['yes_relevant_experience'] = pd.get_dummies(df['relevent_experience'])['yes']\ndf[['no_enrollment', 'Full time course', 'Part time course']] = pd.get_dummies(df['enrolled_university'])[['no_enrollment', 'Full time course', 'Part time course']]\ndf[['Graduate','High School','Phd','Primary School','na_edu_level']] = pd.get_dummies(df['education_level'])[['Graduate','High School','Phd','Primary School','na']]\ndf[['Humanities', 'Other', 'Business Degree','Arts', 'No Major', 'na_major']] = pd.get_dummies(df['major_discipline'])[['Humanities', 'Other', 'Business Degree','Arts', 'No Major', 'na']]\ndf[['csize_na', 'csize_50-99', 'csize_100-500', 'csize_10000+', 'csize_1000-4999', 'csize_<10', 'csize_500-999', 'csize_5000-9999']] = pd.get_dummies(df['company_size'])[['na', '50-99', '100-500', '10000+', '1000-4999', '<10', '500-999', '5000-9999']]\ndf[['ctype_Pvt Ltd', 'ctype_Funded Startup', 'ctype_Public Sector', 'ctype_Early Stage Startup', 'ctype_NGO', 'ctype_Other']] = pd.get_dummies(df['company_type'])[['Pvt Ltd', 'Funded Startup', 'Public Sector', 'Early Stage Startup', 'NGO','Other']]","30381850":"X = df[['city_development_index','experience','last_new_job','training_hours', 'male', 'other_gender',\n       'na_gender', 'yes_relevant_experience', 'no_enrollment',\n       'Full time course', 'Part time course', 'Graduate', 'High School',\n       'Phd', 'Primary School', 'na_edu_level', 'Humanities', 'Other',\n       'Business Degree', 'Arts', 'No Major', 'na_major', 'csize_na',\n       'csize_50-99', 'csize_100-500', 'csize_10000+', 'csize_1000-4999',\n       'csize_<10', 'csize_500-999', 'csize_5000-9999', 'ctype_Pvt Ltd',\n       'ctype_Funded Startup', 'ctype_Public Sector',\n       'ctype_Early Stage Startup', 'ctype_NGO', 'ctype_Other']]\n\ny = df['target']\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.20, random_state=0)","aeea9a9f":"y_train.value_counts()","b451a434":"print('All Positive model equals:',3827\/y_train.size)\n\nprint('All Negative model equals:',11499\/y_train.size)","2faf9166":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","2558020d":"def fit_model(model):\n    \n    model.fit(X_train, y_train)\n    val_preds = model.predict(X_val)\n    print(pd.DataFrame(confusion_matrix(y_val,val_preds),\\\n            columns=[\"Predicted No\", \"Predicted Yes\"],\\\n            index=[\"No\",\"Yes\"]))\n    print('\\n')\n    print(classification_report(y_val, val_preds))\n    \n    probs = model.predict_proba(X_val)\n    probs = probs[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_val, probs)\n    plot_roc_curve(fpr,tpr)\n    print('auc score: '+ str(roc_auc_score(y_val,val_preds)))\n    ","483b42ba":"log_model = LogisticRegression(max_iter=1000)\n\nfit_model(log_model)","f3552504":"knn_model = KNeighborsClassifier(n_neighbors=50)\n\nfit_model(knn_model)","e0c0568f":"tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=5, max_leaf_nodes=10 )\n\nfit_model(tree_model)","5d8cd8da":"rf_model = RandomForestClassifier(n_estimators=100)\n\nfit_model(rf_model)","1ef0d497":"Then change the data type to a float so it is numerical.","5fbd7719":"Pvt Ltd takes up 3 times more than any other value put together. For job change proprtions, there is a close tie between early stage startups and other types of companies.","a9c1aea5":"## Continious Variables\n\n### City development index","b2cfed25":"We get an accuracy score of 77%, 2 percent points higher than the baseline model.","d73e5168":"We create a table of counts for gender and the target.","f2e279b3":"Now we check it out!","a9c3f97c":"It looks like job changers are more likely to change having less experience years.\n\nLets do a Kruskal Wallace test to see if that difference is significant.","632da7af":"Most records have a difference of 1 year between jobs.","348d94f4":"We reject the null hypothesis because p is lower than .05 so major will be used for our model.","03654daa":"Graduates make up more than half of every other value put together however, when it comes to the proportion of job change people, it only has a small lead. ","3cf42f92":"Most people are not enrolled in university, while no enrollments also have the lowest percentage of people seeking a job change. People enrolled in full time courses have the highest proportion of people seeking a job change and na values come in second place.\n\nWe use a chi-squared test to test these differences.","099460ca":"## Objective\n\nIn this analysis we examine the factors involved with people in a company's training program and create a model to predict which people are more likely to change jobs. The aim of this project is not to achieve the highest accuracy rating possible but to build a model using simple classification methods. More robust models are outside the scope of this project. This is because it is important to get a better understanding of the data using simpler models first before using more complex models. Further, it may be that the simpler models may solve the problem and also have the benefit of providing more interpretable results than the complex models. \n\n## The Data\n\nWe use the data set provided by the \"HR Analytics: Job Change of Data Scientists\" Kaggle competition. This data set has 19158 rows and 14 columns.\n\n\nColumns are as follows:\n\n- enrollee_id : Unique ID for candidate\n\n- city: City code\n\n- city_ development _index : Developement index of the city (scaled)\n\n- gender: Gender of candidate\n\n- relevent_experience: Relevant experience of candidate\n\n- enrolled_university: Type of University course enrolled if any\n\n- education_level: Education level of candidate\n\n- major_discipline :Education major discipline of candidate\n\n- experience: Candidate total experience in years\n\n- company_size: No of employees in current employer's company\n\n- company_type : Type of current employer\n\n- lastnewjob: Difference in years between previous job and current job\n\n- training_hours: training hours completed\n\n- target: 0 \u2013 Not looking for job change, 1 \u2013 Looking for a job change","f0c8b000":"We reject the null hypothesis because we definitely have a p value lower than .05. It looks like university enrollment will be a good feature to add to our model.","1a0ee592":"Males take up most of the data set being thirteen times more than females.\n\nNow we take a look at a table of proprtions.","84158120":"We see here that na values have a count higher than females and higher than other values. In the proportion bar graph we see that na gender values certainly have a higher percent of employee job change than any other value.\n\nLets take a closer look.","a3e98433":"After cleaning, we visualize the variable.","f4a86d4e":"The results of the test are significant with a p-value lower than .05. We will use this feature in our model.","01860e8f":"People with relevant experience is more than double the amount of people without it. People without relevant experience are more than 10% more likely to be looking for another job.\n\nTo make sure of this difference we do another chi-squared test.","13154ba8":"Decision tree classifier gives us an accuracy score of 79%, four percent higher than the baseline model.","7dfccccb":"This function efficiently trains each model on the training data and makes predictions for our validation set.","de9396b7":"Na values have the highest number and take up more than half of 50-99 company sizes in the data set. People who have a missing value for their company size are also twice more likely to change jobs than any other value.","f6bf7910":"We reject the null hypothesis because we definitely have a p value lower than .05. It looks like company type will be a good feature to add to our model.","73156c09":"Most companies in the data set are between 50 and 99 people.\n\n\nWe choose to fill missing values with na and use na as a value in this column.","83a12bf9":"# Cleaning and EDA\n\n## Initial Exploration","ac3748fc":"There does not seem to be any differences in the distributions.\n\nLet's try a boxplot.","914fe395":"### Decision Tree Classifier","d6aedc22":"Here we get the top 20 cities. city 103 has the most records with above 4,000. City 21 follows by with almost 3,000 records.\n\nWe chose not to use this variable as a predictor because we do not know which cities these actually are and what their significance may be. ","34657e63":"### Relevant Experience\n\nRelevant experience is the relevant experience of the candidate. Whether they have any or do not have any relevant experience.\n\n","fdb3a799":"We choose to keep the missing data here and use it as a variable.","72e2c6d6":"### Last New Job\n\nDifference in years between previous job and current job.","5114760e":"We do not see much of a difference in the histogram distrubtions.\n\nLets try a box plot!","9264ee0b":"## Model Selection\n\n### Defining model functions","d1593ab8":"### Education Level","a556d30e":"The distribution of the not looking for jobs histogram on the left seems to be very similar to the distribution of all the records. The job changers have a very high amount of records between .6 and .7 .","c90c7043":"## Import Libraries and Read Data","726d50f5":"### K-nearest Neighbors","c8b52b8d":" ### training_hours\n \n The number of hours of training for employee's current position.","9dee4a50":"Most of the records have a city development index higher than .9.","b8e8e18f":"Again the distributions look very similar.","24429174":"We reject the null hypothesis because we definetly have a p value lower than .05. It looks like gender will be a good feature to add to our model.","1e6538af":"This is a function to plot the ROC curve for each model.","2f1caba6":"Nothing too out of the ordinary looking here.\n\nLets plot the data!","78933445":"### City Development Index","52e05ac5":"Depsite the differences being smaller, we still reject the null hypothesis because we definitely have a p value lower than .05. Education level should be a good predictor.","fe242ebf":"Enrolled University tells us whether a person is in a full time course, part time course, or not enrolled in a university course.","7dabc987":"# Conclusion\n\nOut of all the models that we tried, the decision tree outperformed the rest. It out-performed the baseline model accuracy by 4%, logistic regression accuracy by 2%, K-nearest neighbors by 4%, and random forest classifier by 4%. This means that if we want to predict which candidates would be most likely to change jobs based on our features, we would use the Decision Tree Model.\n\n\n## Next Steps\nWe could choose to deploy this model for real-world use however, given our accuracy rates, it might be wise to try more complex models in order to get a better accuracy rate. Deep-learning models for example may give better results however,that is outside the scope of this project.","104a0fe2":"In this Kruskal Wallace test, we get a p-value greater than .05. We fail to reject the Null-Hypothesis. This means that there are no significant differences between job changers and non-job changers with training hours so training hours will not be used for the model.","07c7bfd4":"Education level of the candidate (Phd, Masters, Graduate, High School, Primary School)","733557e0":"Since the all negative model has a higher accuracy we will be using it for our baseline. This means that out model must beat an accuracy score of 75.03%.","4ed91237":"Here, we have 2 numeric variables and the rest are categorical variables. last_new_job and experience columns will later be changed to numeric data types giving us 4 numeric variables total.","8b94e6be":"Then we check na values in the dataframe for insights.","a8929dd4":"We are going to change >20 to 21, and <1 to 0 so we can have a consistent data type and the values can be readable to our model. \n\nWe also choose to fill missing values with na and use na as a value in this column.","a8803d82":"It seems that people who change jobs seem to have lower year differences. Maybe people who have had longer gaps may not want to change jobs again. \n\nWe do another Kruskal Wallace test.","db1a6e1f":"### Company Size","8c3f9296":"Stem degrees in the data set are more than 7 times larger than any other major put together. Proportionally, stem degrees, business degrees, and other degrees are almost the same.","2beeb4f9":"### Establishing Baseline Performance\n\nTo understand if our model holds any weight, we need to establish a baseline model to test our models against.","ab905909":"# Predicting Data Science Job Changes","72a80567":"### Logistic Regression","474e0311":"We have a very small p-value that is below 0.05, so we reject the null hypothesis. This shows statistical significance so it should be a good variable to use for our model.","5abac131":"Most people are not enrolled in a university course.","5fde74f2":"### Company Type\nCompany type has 6 values (Pvt Ltd, Funded Startup, Public Sector, Early Stage Startup, NGO, Other).","8c8ad690":"We replace the value that has relevent experience to \"yes\" and no relevent experience to \"no\" to simplify things. ","a2a0417c":"When comparing both graphs we see that in the job changers histogram, there is a high frequency of records between 1-7 years of job experience and then another spike at 20 years and over. ","8c21f882":"Company Size is measured as a categorical variable with values(<10, 10\/49, 50-99, 100-500, 500-999, 1000-4999, 5000-9999, 1000+).","f329b746":"This box plot shows a pretty large difference between the means of job changers to non job changers.\n\nLet's do a statstical test to make sure of this.\n\nHere we us a Kruskal Wallace Test to see if there is a statistically significant difference.","26c88dcc":"Lastly, we try a random forest classifier, giving us an accuracy score of 78%, 3 points higher than the baseline.","fec7f4c3":"## Model Fitting","15639230":"We reject the null hypothesis because we definetly have a p value lower than .05. It looks like relevant experience will be a good feature to add to our model.","314f65dc":"There are 123 different cities in this data set.","626f05a8":"### Major\n\nCollege majors are put into general categories (STEM, Humanities, Other, Business Degree, Arts, No Major)","76d128d7":"The number of people with relevant experience is more than double the amount of no relevant experience people.","bbd15561":"We are going to go through each variable seperately, clean it, perform EDA, and prepare it for modeling. Starting with categorical variables and ending with numeric variables. It should be noted that for all our categorical missing values, we choose to keep them and use them for the analysis. This is because there is a lot of valuable information in missing data and deleting it could change the character of the data set. For the numeric variables, missing data is filled in with random samples of that column because there is a very small number of missing values. ","6850ca84":"Private companies take up most of the data set.\n\nWe choose to fill missing values with na and use na as a value in this column.\n\n","1ed9c08b":"Plot the counts and proportions.","e67c856d":"With proportions we see that females are more likely to change jobs than men. More importantly, we see that missing values have the highest proportion of job changers.","5c4e91e2":"With Knn, we get an accuracy score of 75%, which is the same as the baseline model.","1344add1":"# Model Building\n\n## Model Preparation\n\nTo prepare the model we must get dummy variables for all the categorical variables.","55b5fa84":"### Enrolled University","cccea49b":"## Categorical Variables\n\n### City","f09bbfe5":"Stem majors definitely make up the most of the data set.\n\nWe choose to fill missing values with na and use na as a value in this column. ","976b7523":"There is a median of 47 training hours and most records are between 0 and 50 training hours.\n\nNext we plot the distributions for job changers and non job changers.","f35b206d":"### Experience\n\nExperience is measured in years of experience going from less than 1 to more than 20.","dcce1568":"Most people in the dataset are graduates.\n\n\nWe choose to fill missing values with na and use na as a value in this column. ","864103ef":"We see that a little over half of the columns contain missing values so we will have to work with them in each column going forward. ","c7d96f68":"It looks like gender may play a part in predicting job changes so we do a chi squared test to test for statstical signficance of this.","a8d0b1d9":"na makes up 386 records in the data set.\n\nlets plot it!","718a5833":"We assign the features to our X value and the target to our y value. Then we split the data to our training and validation sets.","ed4bfb4f":"We reject the null hypothesis because we definetly have a p value lower than .05. It looks like company size will be a good feature to add to our model.","e2cc75b4":"We will need to clean this up a bit:\n- Replace >4 to 5, and never to 0 years between jobs.\n- We fill missing data with random samples taken from the existing data set.\n- We change the data type to a float so it is numerical.","4a52cb98":"The highst distribution of records in the data set have 20 or more years of experience followed by 4,5,and 6 years of experience.\n\nLets look at job changers vs non-job changers.","e8ba7e88":"We have a very small p-value that is below 0.05, so we reject the null hypothesis. This shows statistical significance so it should be a great variable to use for our model.","84a83656":"We choose to fill missing values with na and use na as a value in this column. ","501c83a7":"### Random Forest Classifier"}}