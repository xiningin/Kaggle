{"cell_type":{"4d5f5dbf":"code","5e2b1838":"code","c198d305":"code","06234df5":"code","7ec1ab6a":"code","d3017899":"code","0b9223d5":"code","8ede272d":"code","6ce06bf8":"code","d936f6a0":"code","776bb32e":"code","92c02314":"code","1bab5d78":"code","3c20024e":"code","e297998d":"code","037cbae9":"code","a9f86139":"code","3f25195d":"code","3e1c05e4":"code","8e3264b1":"code","0935c51c":"code","bdd23396":"code","47099048":"code","9cd4dd3e":"code","adfe79f7":"code","8eba7fe5":"code","acd7378d":"code","fd2238b4":"code","ef0b36f5":"code","b13ae7a9":"code","8a8e264f":"code","b86e00ef":"code","fe19c7f5":"code","b62f7cef":"code","962433ed":"code","1d6d1cbf":"code","e8ffdb5e":"code","b9a1e758":"code","dd8c00f5":"code","84584c55":"markdown","0a1a0698":"markdown","5daf35b1":"markdown","0102bfca":"markdown","adfa8888":"markdown","982d5c39":"markdown","60d30af4":"markdown","0aca21f3":"markdown","82bbb517":"markdown","328a8dae":"markdown","6453818a":"markdown","bb39a79e":"markdown","152d17f5":"markdown"},"source":{"4d5f5dbf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\n%matplotlib inline","5e2b1838":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c198d305":"data = pd.read_csv(\"..\/input\/breast-cancer-dataset\/dataR2.csv\")","06234df5":"data.info()","7ec1ab6a":"pd.options.display.float_format = \"{:.2f}\".format\ndata.describe()","d3017899":"classes = data['Classification']\nax = sns.countplot(x=classes, data=data)","0b9223d5":"sns.set_style('white')\nsns.set_context('notebook')\nsns.pairplot(data, hue='Classification', palette='bwr', height=2)","8ede272d":"label_encoder = LabelEncoder()\ndata['Classification'] = label_encoder.fit_transform(data['Classification'])","6ce06bf8":"data.head()","d936f6a0":"corr = data.corr()\nplt.subplots(figsize=(10,8))\nsns.heatmap(corr, annot= True)","776bb32e":"X = data.drop(['Classification'], axis=1)\ny = data['Classification'].values.reshape(-1, 1)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)","92c02314":"classes_test=pd.DataFrame(y_test.reshape(-1,1))\nclasses_test[0].value_counts()","1bab5d78":"def plot_roc(roc_auc, false_positive_rate, true_positive_rate):\n  plt.figure(figsize=(6, 6))\n  plt.title('Receiver Operating Characteristics')\n  plt.plot(false_positive_rate, true_positive_rate, color='red', label='AUC = {:.2f}'.format( roc_auc))\n  plt.legend(loc = 'lower right')\n  plt.plot([0, 1], [0, 1], linestyle='--')\n  plt.axis('tight')\n  plt.ylabel('True Positive Rtae')\n  plt.xlabel('False Positive Rtae')","3c20024e":"solvers = ['svd', 'lsqr', 'eigen']\nparameters = dict(solver=solvers)\nlda = GridSearchCV(\n    LinearDiscriminantAnalysis(), parameters, cv=5,scoring='accuracy'\n    )\nlda.fit(X, y.ravel())\nlda_opt = lda.best_estimator_","e297998d":"print(lda.best_params_)\nprint(lda.best_score_)","037cbae9":"lda = LinearDiscriminantAnalysis(solver='lsqr')\nlda.fit(X_train, y_train.ravel())\nlda_pred = lda.predict(X_test)","a9f86139":"metrics.accuracy_score(lda_pred, y_test)","3f25195d":"confusion_matrix = metrics.confusion_matrix(y_test, lda_pred)\nconfusion_matrix","3e1c05e4":"false_positive_rate_lda, true_positive_rate_lda, thresholds = metrics.roc_curve(\n    y_test, lda_pred\n    )\nroc_auc_log_lda = metrics.auc(false_positive_rate_lda, true_positive_rate_lda)\nplot_roc(roc_auc_log_lda, false_positive_rate_lda, true_positive_rate_lda)","8e3264b1":"kernels = ['linear', 'poly', 'rbf', 'sigmoid']\nshrinkings = [True, False]\nprob = [True, False]\nparameters = dict(\n    kernel=kernels, shrinking=shrinkings, probability=prob\n    )\nsvc = GridSearchCV(svm.SVC(), parameters, cv=5, scoring='accuracy')\nsvc.fit(X, y.ravel())\nsvc_opt = svc.best_estimator_","0935c51c":"print(svc.best_params_)\nprint(svc.best_score_)","bdd23396":"svc = svm.SVC(kernel='linear', probability=True)\nsvc.fit(X_train, y_train.ravel())\nsvc_pred = svc.predict(X_test)","47099048":"metrics.accuracy_score(svc_pred, y_test)","9cd4dd3e":"confusion_matrix = metrics.confusion_matrix(y_test, svc_pred)\nconfusion_matrix","adfe79f7":"false_positive_rate_svm, true_positive_rate_svm, thresholds = metrics.roc_curve(\n    y_test, svc_pred\n    )\nroc_auc_log_svm = metrics.auc(false_positive_rate_svm, true_positive_rate_svm)\nplot_roc(roc_auc_log_svm, false_positive_rate_svm, true_positive_rate_svm)","8eba7fe5":"algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\nneighbors = range(5, 16, 2)\nparameters=dict(algorithm=algorithm, n_neighbors=neighbors)\nknn = GridSearchCV(\n    KNeighborsClassifier(), parameters, cv=5,scoring='accuracy')\nknn.fit(X, y.ravel())\nknn_opt = knn.best_estimator_\nprint(knn.best_params_)\nprint(knn.best_score_)","acd7378d":"knn = KNeighborsClassifier(algorithm = 'auto', n_neighbors=11)\nknn.fit(X_train, y_train.ravel())\nknn_pred = knn.predict(X_test)\nscore = metrics.accuracy_score(knn_pred, y_test)\nconfusion_matrix = metrics.confusion_matrix(y_test, knn_pred)\nprint(score)\nprint(confusion_matrix)","fd2238b4":"false_positive_rate_knn, true_positive_rate_knn, thresholds = metrics.roc_curve(\n    y_test, knn_pred\n    )\nroc_auc_log_knn = metrics.auc(false_positive_rate_knn, true_positive_rate_knn)\nplot_roc(roc_auc_log_knn, false_positive_rate_knn, true_positive_rate_knn)","ef0b36f5":"criterions = ['gini', 'entropy']\nparameters = dict(criterion=criterions)\ndtc = GridSearchCV(\n    DecisionTreeClassifier(), parameters, cv=5, scoring='accuracy'\n)\ndtc.fit(X, y.ravel())\ndtc_opt = dtc.best_estimator_\nprint(dtc.best_params_)\nprint(dtc.best_score_)","b13ae7a9":"dtc = DecisionTreeClassifier(criterion='entropy')\ndtc.fit(X_train, y_train.ravel())\ndtc_pred = dtc.predict(X_test)\nscore = metrics.accuracy_score(dtc_pred, y_test)\nconfusion_matrix = metrics.confusion_matrix(y_test, dtc_pred)\nprint(score)\nprint(confusion_matrix)","8a8e264f":"false_positive_rate_dtc, true_positive_rate_dtc, thresholds = metrics.roc_curve(\n    y_test, dtc_pred\n    )\nroc_auc_log_dtc = metrics.auc(false_positive_rate_dtc, true_positive_rate_dtc)\nplot_roc(roc_auc_log_dtc, false_positive_rate_dtc, true_positive_rate_dtc)","b86e00ef":"bagging = BaggingClassifier(n_estimators=500)\nbagging.fit(X_train, y_train.ravel())\nbagging_pred = bagging.predict(X_test)\nconfusion_matrix = metrics.confusion_matrix(y_test, bagging_pred)\nscore = metrics.accuracy_score(bagging_pred, y_test)\nprint(score)\nprint(confusion_matrix)","fe19c7f5":"false_positive_rate_bagging, true_positive_rate_bagging, thresholds = metrics.roc_curve(\n    y_test, bagging_pred\n    )\nroc_auc_log_bagging = metrics.auc(false_positive_rate_bagging, true_positive_rate_bagging)\nplot_roc(roc_auc_log_bagging, false_positive_rate_bagging, true_positive_rate_bagging)","b62f7cef":"parameters = {\n    'n_estimators': [10, 100, 250, 500]\n}\nrfc = GridSearchCV(\n    RandomForestClassifier(), parameters, cv=5, scoring='accuracy'\n)\nrfc.fit(X, y.ravel())\nrfc_opt = rfc.best_estimator_\nprint(rfc.best_params_)\nprint(rfc.best_score_)","962433ed":"rfc = RandomForestClassifier(n_estimators=250)\nrfc.fit(X_train, y_train.ravel())\nrfc_pred = rfc.predict(X_test)\nconfusion_matrix = metrics.confusion_matrix(y_test, rfc_pred)\nscore = metrics.accuracy_score(rfc_pred, y_test)\nprint(score)\nprint(confusion_matrix)","1d6d1cbf":"false_positive_rate_rfc, true_positive_rate_rfc, thresholds = metrics.roc_curve(\n    y_test, rfc_pred\n    )\nroc_auc_log_rfc = metrics.auc(false_positive_rate_rfc, true_positive_rate_rfc)\nplot_roc(roc_auc_log_rfc, false_positive_rate_rfc, true_positive_rate_rfc)","e8ffdb5e":"parameters = {\n    'n_estimators': [10, 100, 250, 500],\n    'loss': ['deviance', 'exponential'],\n    'criterion': ['friedman_mse', 'mse', 'mae'],\n    'max_depth': np.arange(3, 10)\n}\nboosting = GridSearchCV(\n    GradientBoostingClassifier(), parameters, cv=5, scoring='accuracy'\n)\nboosting.fit(X, y.ravel())\nboosting_opt = boosting.best_estimator_\nprint(boosting.best_params_)\nprint(boosting.best_score_)","b9a1e758":"gbc = GradientBoostingClassifier(\n    n_estimators=500, criterion='mse', loss='exponential'\n    )\ngbc.fit(X_train, y_train.ravel())\ngbc_pred = gbc.predict(X_test)\nconfusion_matrix = metrics.confusion_matrix(y_test, gbc_pred)\nscore = metrics.accuracy_score(gbc_pred, y_test)\nprint(score)\nprint(confusion_matrix)","dd8c00f5":"false_positive_rate_gbc, true_positive_rate_gbc, thresholds = metrics.roc_curve(\n    y_test, gbc_pred\n    )\nroc_auc_log_gbc = metrics.auc(false_positive_rate_gbc, true_positive_rate_gbc)\nplot_roc(roc_auc_log_gbc, false_positive_rate_gbc, true_positive_rate_gbc)","84584c55":"### Dataset description\nBreast cancer datasets contain information about the tumor. There are 10 predictors, all quantitative and one binary variable, indicating the presence or absence of breast cancer.\n\nPredictors are anthropometric data and parameters that can be collected during a routine blood test.\n\nPrediction models based on these predictors, if accurate, can potentially be used as a breast cancer biomarker.\n\nDataset columns:\n\nPredictors:\n   1. Age (years)\n   2. BMI (kg\/m2)\n   3. Glucose (mg\/dL)\n   4. Insulin (\u00b5U\/mL)\n   5. HOMA\n   6. Leptin (ng\/mL)\n   7. Adiponectin (\u00b5g\/mL)\n   8. Resistin (ng\/mL)\n   9. MCP-1(pg\/dL)\n   \nLabels: 1 for person healthy 2 for person patient","0a1a0698":"### k-nearest neighbors KNN","5daf35b1":"### Dataset splitting Train\/Test","0102bfca":"### Explore the dataset","adfa8888":"### Boosting","982d5c39":"### Plot ROC function","60d30af4":"### Import libraries","0aca21f3":"Hi! In this notebook, we will be exercising many classification models using **GridSearch** to choose the best parameters.","82bbb517":"### Linear discriminant analysis LDA","328a8dae":"### Support Vector Machine SVM","6453818a":"### Bagging","bb39a79e":"### Random forest","152d17f5":"### Decision tree"}}