{"cell_type":{"452b6e05":"code","f8b525c9":"code","a981746c":"code","3b2539d4":"code","89953170":"code","e659584d":"code","ea0691e2":"code","c45bec61":"code","48d771b2":"code","b7312849":"code","689efc1c":"code","e83906e8":"code","81dd75f9":"code","01a52278":"code","1375db38":"code","3180f280":"markdown","bcd80397":"markdown","416f7f20":"markdown","b0fea663":"markdown","fe8f6f01":"markdown","659dd291":"markdown","73a8e4a6":"markdown","3a02ff68":"markdown","765f220d":"markdown","321dd46a":"markdown","3aff2723":"markdown"},"source":{"452b6e05":"import numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline","f8b525c9":"train = pd.read_csv('..\/input\/infopulsehackathon\/train.csv', index_col='Id')\ntest = pd.read_csv('..\/input\/infopulsehackathon\/test.csv', index_col='Id')\n\ntrain.head()","a981746c":"from sklearn.preprocessing import OneHotEncoder","3b2539d4":"X = train.drop(columns = 'Energy_consumption')\ny = train['Energy_consumption']","89953170":"ohe = OneHotEncoder()\nohe_cols = train.loc[:,train.dtypes == 'object'].columns\n\nohe_data = pd.DataFrame(ohe.fit_transform(train[ohe_cols]).toarray(), dtype=int)\ntrain = pd.concat([train.drop(columns = ohe_cols), ohe_data], axis=1)\n\nohe_data = pd.DataFrame(ohe.transform(test[ohe_cols]).toarray(), dtype=int)\nX_test = pd.concat([test.drop(columns = ohe_cols), ohe_data], axis=1)\n\ntrain.head()","e659584d":"X = train.drop(columns = 'Energy_consumption')\ny = train['Energy_consumption']","ea0691e2":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score","c45bec61":"ridge = Ridge(alpha=100, random_state=42)\nmse = -cross_val_score(ridge, X, y, scoring='neg_mean_squared_error', cv=5, n_jobs=-100).mean()\nmae = -cross_val_score(ridge, X, y, scoring='neg_mean_absolute_error', cv=5, n_jobs=-100).mean()\nr2 = cross_val_score(ridge, X, y, scoring='r2', cv=5, n_jobs=-100).mean()\nprint(f'mean_squared_error : {mse}\\nmean_absolute_error : {mae}\\nr2 : {r2}')","48d771b2":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold","b7312849":"X_adv = X.append(X_test).reset_index(drop=True)\ny_adv = pd.Series(0, index= X_adv.index)\ny_adv.iloc[X.shape[0]:] = 1\n\nskf = StratifiedKFold(shuffle=True, n_splits=5, random_state=42)","689efc1c":"log_reg = LogisticRegression(C=10, random_state=42)\ncross_val_score(log_reg, X_adv, y_adv, scoring='roc_auc', cv=skf.split(X_adv, y_adv), n_jobs=-1).mean()","e83906e8":"ridge.fit(X,y)","81dd75f9":"prediction = ridge.predict(X_test)\nprediction[prediction < 0] = 0","01a52278":"print('Train target distribution')\ny.hist(bins=30)\n\nplt.show()\n\nprint('Test Prediction distribution')\npd.Series(prediction).hist(bins=30);","1375db38":"sub = pd.read_csv('..\/input\/infopulsehackathon\/sample_submission.csv', index_col='Id')\nsub['Energy_consumption'] = prediction\nsub.to_csv('submission.csv')\nsub","3180f280":"# Read Data","bcd80397":"# Fit","416f7f20":"# Submission","b0fea663":"# Data Preprocesing","fe8f6f01":"# Vizualize","659dd291":"# Prediction","73a8e4a6":"# Validation","3a02ff68":"### Adversarial Dataset creation","765f220d":"# Conclusion <br>\nIn this kernel we have implemented simple linear model approach. Nevertheless MSE loss is quite a large number, but R2 score shows ~0.61, which means that our model is adequate. The last, but not the least: adversarial validation result shows 0.5 auc, which means that our cv result is lb-consistent.","321dd46a":"# Adversarial Validation","3aff2723":"### Adversarial result"}}