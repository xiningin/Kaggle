{"cell_type":{"cade24d6":"code","baa0c48f":"code","58f11b6d":"code","e7953ab4":"code","05414d63":"code","d9a1e218":"code","4343336f":"code","9aaf7317":"code","414cda02":"code","68ebff91":"code","970197ac":"code","d950a4ac":"markdown"},"source":{"cade24d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","baa0c48f":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds","58f11b6d":"train_data, validation_data, test_data = tfds.load(\n    name=\"imdb_reviews\", \n    split=('train[:60%]', 'train[60%:]', 'test'),\n    as_supervised=True)","e7953ab4":"train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\ntrain_examples_batch","05414d63":"train_labels_batch","d9a1e218":"embedding = \"https:\/\/tfhub.dev\/google\/tf2-preview\/gnews-swivel-20dim\/1\"\nhub_layer = hub.KerasLayer(embedding, input_shape=[], \n                           dtype=tf.string, trainable=True)\nhub_layer(train_examples_batch[:3])","4343336f":"model = tf.keras.Sequential()\nmodel.add(hub_layer)\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.summary()","9aaf7317":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","414cda02":"history = model.fit(train_data.shuffle(10000).batch(512),\n                    epochs=25,\n                    validation_data=validation_data.batch(512),\n                    verbose=1)","68ebff91":"results = model.evaluate(test_data.batch(512), verbose=2)\n\nfor name, value in zip(model.metrics_names, results):\n  print(\"%s: %.3f\" % (name, value))","970197ac":"import matplotlib.pyplot as plt\n\ndef plotmodelhistory(history): \n    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n    # summarize history for accuracy\n    axs[0].plot(history.history['accuracy']) \n    axs[0].plot(history.history['val_accuracy']) \n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['train', 'validate'], loc='upper left')\n    # summarize history for loss\n    axs[1].plot(history.history['loss']) \n    axs[1].plot(history.history['val_loss']) \n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['train', 'validate'], loc='upper left')\n    plt.show()\n\n# list all data in history\nprint(history.history.keys())\n\nplotmodelhistory(history)","d950a4ac":"0 is a negative review, and 1 is a positive review."}}