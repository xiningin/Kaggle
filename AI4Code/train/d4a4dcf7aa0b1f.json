{"cell_type":{"b7d4e807":"code","e771fe1d":"code","930bed63":"code","a15eded8":"code","c33c6aeb":"code","47329fa2":"code","666ab6d7":"code","2ba507fd":"code","de55e27d":"markdown"},"source":{"b7d4e807":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport numpy\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.metrics.pairwise import euclidean_distances\n\n\nx,y = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant= 0, n_clusters_per_class=1, random_state=60)\nX_train, X_test, y_train, y_test = train_test_split(x,y,stratify=y,random_state=42) \nprint(X_train)\n\n# del X_train,X_test","e771fe1d":"print(y_train, y_test)","930bed63":"%matplotlib inline\nimport matplotlib.pyplot as plt\ncolors = {0:'red', 1:'blue'}\nplt.scatter(X_test[:,0], X_test[:,1],c=y_test)\nplt.show()","a15eded8":"from sklearn.metrics import accuracy_score\nimport random \nfrom tqdm import tqdm\n\ndef random_params_range_1_to_len(params_range):\n    sort_values = random.sample(range(1, params_range),10)\n    sort_values.sort()\n    return sort_values\n\ndef RandomSerachCV(x_train, y_train, classifier, params, folds):\n    trainscores = []\n    testscores  = [] \n    \n    #Randomly selected numbers from params_range\n    params_list= random_params_range_1_to_len(params_range)\n    #printing the random paramter values\n    print(params_list)\n    \n    params = {'n_neighbors': params_list}\n    \n    for k in tqdm(params['n_neighbors']):\n        \n        trainscores_folds = []\n        testscores_folds  = []\n        \n        for j in range(0, folds): #fold = [1,2,3]\n            #formulae for finding length\n            Values = (len(x_train)\/ (folds))\n            #covert into integer values\n            boundary = int(Values)\n            \n            \n            test_indices=list(set(list(range((boundary*j), (boundary*(j+1))))))\n            train_indices = list(set(list(range(0, len(x_train)))) - set(test_indices))\n            # selecting the data points based on the train_indices and test_indices\n            \n            X_train = x_train[train_indices]\n            Y_train = y_train[train_indices]\n            X_test  = x_train[test_indices]\n            Y_test  = y_train[test_indices]\n\n            classifier.n_neighbors = k\n            classifier.fit(X_train,Y_train)\n\n            Y_predicted = classifier.predict(X_test)\n            testscores_folds.append(accuracy_score(Y_test, Y_predicted))\n\n            Y_predicted = classifier.predict(X_train)\n            trainscores_folds.append(accuracy_score(Y_train, Y_predicted))\n        trainscores.append(np.mean(np.array(trainscores_folds)))\n        testscores.append(np.mean(np.array(testscores_folds)))\n    return trainscores,testscores,params","c33c6aeb":"from sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nneigh = KNeighborsClassifier()\nparams_range = 50\nfolds = 3\ntestscores, trainscores, params = RandomSerachCV(X_train, y_train, neigh, params_range, folds)\nprint(params)\nprint(trainscores)\nprint(testscores)\nplt.plot(params['n_neighbors'],trainscores, label='train cruve')\nplt.plot(params['n_neighbors'],testscores, label='test cruve')\nplt.title('Hyper-parameter VS accuracy plot')\nplt.legend()\nplt.show()","47329fa2":"# taking it from reference \ndef plot_decision_boundary(X1, X2, y, clf):\n        # Create color maps\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n\n    x_min, x_max = X1.min() - 1, X1.max() + 1\n    y_min, y_max = X2.min() - 1, X2.max() + 1\n    \n    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    plt.figure()\n    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n    # Plot also the training points\n    plt.scatter(X1, X2, c=y, cmap=cmap_bold)\n    \n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.title(\"2-Class classification (k = %i)\" % (clf.n_neighbors))\n    plt.show()","666ab6d7":"from matplotlib.colors import ListedColormap\nneigh = KNeighborsClassifier(n_neighbors = 10)\nneigh.fit(X_train, y_train)\nplot_decision_boundary(X_train[:, 0], X_train[:, 1], y_train, neigh)","2ba507fd":"from matplotlib.colors import ListedColormap\nneigh = KNeighborsClassifier(n_neighbors = 50)\nneigh.fit(X_train, y_train)\nplot_decision_boundary(X_train[:, 0], X_train[:, 1], y_train, neigh)","de55e27d":"# Implementing Custom RandomSearchCV"}}