{"cell_type":{"c384747f":"code","91648fcf":"code","1a01203e":"code","1ce4b162":"code","6be9aa94":"code","145b6cf5":"code","587364c8":"code","e5594cc9":"code","d0830d0e":"code","fdd85e1a":"code","b3a3548b":"code","da86154a":"code","ee26bcc4":"code","ac2122f6":"code","b62146c4":"code","33af18a2":"code","2dee21c6":"code","b5a6f2d0":"code","0d1cf28a":"code","0aca9a9c":"code","99624ba5":"code","adc7e4a6":"code","b046966e":"code","d6d1e25e":"markdown","e32eec2e":"markdown","468acbdd":"markdown","37c69011":"markdown"},"source":{"c384747f":"import numpy as np \nimport pandas as pd \nfrom pandas import set_option\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n","91648fcf":"filename = (\"..\/input\/housing.csv\")\nnames = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'CM', 'UA40', 'DIS', 'RAD', 'IMPOSTO', 'PROF_ALUNO', 'B', 'LSTAT', 'MEDV']\ndf = pd.read_csv(filename, delim_whitespace=True, names=names)","1a01203e":"df.head()","1ce4b162":"df.shape","6be9aa94":"# Observa-se que a base n\u00e3o contempla valores missing\n\ndf.info()","145b6cf5":"# Verificando os tipos das colunas\nprint('========Contagem==========')\nprint(df.dtypes.value_counts())\nprint('==========================')\nprint('=======Percentual=========')\nprint(df.dtypes.value_counts(normalize=True).apply(\"{:.2%}\".format))\nprint('==========================')","587364c8":"# Vizualiza\u00e7\u00e3o gr\u00e1fica dos tipos de colunas\n\nf, axes=plt.subplots(1,2, figsize=(15,6))\nplt.suptitle('Caracteristicas das colunas', ha='center', fontsize=14)\nP=df.dtypes.value_counts().plot.pie(autopct='%1.2f%%',ax=axes[0], label='',title='Tipos Colunas - Distr Percentual', legend=True)\nbplot = df.dtypes.value_counts().plot(kind='bar',ax=axes[1],rot=0)\nfor b in bplot.patches:\n    bplot.annotate(format(b.get_height(),'.0f'), \\\n                   (b.get_x() + b.get_width() \/ 2., \\\n                   b.get_height()), \\\n                   ha = 'center',\\\n                   va = 'center',\\\n                   xytext = (0, 7),\\\n                   textcoords = 'offset points')    \nplt.title('Tipos Colunas - Contagem')\nplt.xlabel('')\nplt.yticks([])\nplt.ylabel('Frequ\u00eancia',labelpad=3)\n\nsns.despine(left=True)","e5594cc9":"df.describe()","d0830d0e":"df.isnull().sum().max()","fdd85e1a":"#verificando visualmente a distribui\u00e7\u00e3o dos valores missing\nmsno.matrix(df,figsize=(12,5))","b3a3548b":"#Valores missing no data frame DF\ndf.isnull().sum().to_frame('Qtd. Missing')","da86154a":"# Identificando Outliers nos campos\n\nfrom scipy import stats\n\nfig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor k,v in df.items():\n    sns.boxplot(y=k, data=df, ax=axs[index])\n    index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","ee26bcc4":"# Percentual de outliers de cada campo\n\nfor k, v in df.items():\n        q1 = v.quantile(0.25)\n        q3 = v.quantile(0.75)\n        irq = q3 - q1\n        v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n        perc = np.shape(v_col)[0] * 100.0 \/ np.shape(df)[0]\n        print(\"Outliers da coluna %s = %.2f%%\" % (k, perc))","ac2122f6":"# Verificando a taxa de criminalidade nos agrupamentos de Proximidade ao Rio e de Acessibilidade \u00e0s rodovias radiais\n\nsns.set(rc={'figure.figsize':(16.7,8.27)})\nsns.swarmplot(x='CHAS', y='CRIM', data=df,hue='RAD')\nplt.title('Taxa de Criminalidade por Proximidade ao Rio e Acessibilidade \u00e0s rodovias')\nplt.xlabel('\u00c1rea Beira Rio (1 = Proximo, 0 = Distante)',labelpad=10)\nplt.ylabel('Taxa de Criminalidade',labelpad=10)","b62146c4":"# Avaliando o n\u00edvel de correla\u00e7\u00e3o das vari\u00e1veis explicativas com a vari\u00e1vel resposta\n\nplt.figure(figsize=(20, 10))\nsns.heatmap(df.corr().abs(),  annot=True)","33af18a2":"from sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler()\ncolumn_sels = ['LSTAT', 'INDUS', 'NOX', 'PROF_ALUNO', 'CM', 'IMPOSTO']\nx = df.loc[:,column_sels]\ny = df['MEDV']\nx = pd.DataFrame(data=min_max_scaler.fit_transform(x), columns=column_sels)\nfig, axs = plt.subplots(ncols=3, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor i, k in enumerate(column_sels):\n    sns.regplot(y=y, x=x[k], ax=axs[i])\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","2dee21c6":"X = df[['LSTAT', 'INDUS', 'NOX', 'PROF_ALUNO', 'CM', 'IMPOSTO']]\ny = df['MEDV']","b5a6f2d0":"# Dividindo os dados em um conjunto de treinamento e um conjunto de testes. \n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","0d1cf28a":"from sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\n\nlm.fit(X_train,y_train)","0aca9a9c":"# Printando a intercep\u00e7\u00e3o\nprint(lm.intercept_)","99624ba5":"coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])\ncoeff_df","adc7e4a6":"predictions = lm.predict(X_test)\n\nplt.scatter(y_test,predictions)\n","b046966e":"from sklearn.metrics import r2_score\n\nr2_score(y_test, predictions)","d6d1e25e":"**1. Defini\u00e7\u00e3o da fonte de dados** \n\nFoi definida com fonte de dados os registro que descrevem a regi\u00e3o metropolitana da cidade de Boston. \n\nOs dados foram extra\u00eddos da \u00c1rea Estat\u00edstica Metropolitana Padr\u00e3o de Boston (SMSA) em 1970. \n\nOs atributos s\u00e3o definidos da seguinte forma (retirado do UCI Machine Learning Repository)\n\n    1. CRIM: taxa de criminalidade per capita por cidade \n\n    2. ZN: propor\u00e7\u00e3o de terrenos residenciais zoneados para lotes com mais de 25.000 p\u00e9s quadrados \n\n    3. INDUS: propor\u00e7\u00e3o de acres comerciais n\u00e3o varejistas por cidade \n\n    4. CHAS: vari\u00e1vel fict\u00edcia Charles River (= 1 se limite de \u00e1rea de rio; 0 caso contr\u00e1rio) \n\n    5. NOX: concentra\u00e7\u00e3o de \u00f3xidos n\u00edtricos (partes por 10 milh\u00f5es) 1https: \/\/ archive .ics.uci.edu \/ ml \/ datasets \/ Habita\u00e7\u00e3o 123 20.2. Carregar o conjunto de dados 124 \n\n    6. CM: n\u00famero m\u00e9dio de c\u00f4modos por habita\u00e7\u00e3o \n\n    7. UA40: propor\u00e7\u00e3o de unidades ocupadas pelo propriet\u00e1rio constru\u00eddas antes de 1940 \n\n    8. DIS: dist\u00e2ncias ponderadas para cinco centros de emprego de Boston \n\n    9. RAD: \u00edndice de acessibilidade \u00e0s rodovias radiais \n\n    10 IMPOSTO: taxa de imposto de propriedade de valor integral por $ 10.000 \n\n    11 PROF_ALUNO: rela\u00e7\u00e3o professor-aluno por cidade \n\n    12. B: propor\u00e7\u00e3o de negros por cidade por 1000 habitantes \n\n    13. LSTAT: porcentagem de propriet\u00e1rios de resid\u00eancias considerados \"classe baixa\" (trabalhadores pobres) \n\n    14. MEDV: Valor mediano de resid\u00eancias ocupadas pelo propriet\u00e1rio em $ 1000.","e32eec2e":"Verifica-se que as maiores taxas de criminalidade est\u00e3o aonde h\u00e1 maior acessibilidade \u00e0s rodovias e mais distantes do rio.","468acbdd":"## Curso de P\u00f3s Gradua\u00e7\u00e3o em Ci\u00eancia de Dados\n## IESB - Asa Sul\nAlunos:\n\nCarlos Wilson Gomes de Barros - 1831133120\n\nGustavo de Sousa Santos - 1831133117","37c69011":"Em rela\u00e7\u00e3o a vari\u00e1vel resposta \"valor mediano das resid\u00eancias\", as vari\u00e1veis CM e LSTAT s\u00e3o fortemente correlacionadas, as vari\u00e1veis INDUS, NOX e IMPOSTO t\u00eam correla\u00e7\u00e3o moderada e as vari\u00e1veis CRIM, ZN, UA40, DIS e B t\u00eam correla\u00e7\u00e3o fraca. Apenas a vari\u00e1vel CHAS tem correla\u00e7\u00e3o muito fraca\n\nA partir dos dados de Correla\u00e7\u00e3o, podemos afirmar que as vari\u00e1veis LSTAT, INDUS, NOX, CM, IMPOSTO e PROF_ALUNO t\u00eam boa correla\u00e7\u00e3o com a vari\u00e1vel de sa\u00edda MEDV. Essas vari\u00e1veis precisamos considerar quando otimizamos nosso valor preditivo"}}