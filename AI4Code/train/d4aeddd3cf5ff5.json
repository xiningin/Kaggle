{"cell_type":{"39695e6b":"code","725acbf4":"code","a649b8d7":"code","668c763b":"code","baccefe9":"code","d915dd49":"code","42d4e9be":"code","b9ab391f":"code","87a71a53":"code","ba44b015":"code","1b2b859d":"code","ab2105c5":"code","275b6426":"code","7db32e6b":"code","a323b768":"code","5175ba18":"code","5b3c7f97":"code","c7e38cda":"code","b1abbd27":"code","6fc5a9b1":"code","14fd86ca":"code","200fcf57":"markdown","f01acb6b":"markdown","727f2d52":"markdown","3bbca768":"markdown"},"source":{"39695e6b":"from keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error \nfrom matplotlib import pyplot as plt\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport warnings \nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nfrom xgboost import XGBRegressor","725acbf4":"def get_data():\n    #get train data\n    train_data_path ='..\/input\/house-prices-dataset\/train.csv'\n    train = pd.read_csv(train_data_path)\n    \n    #get test data\n    test_data_path ='..\/input\/house-prices-dataset\/test.csv'\n    test = pd.read_csv(test_data_path)\n    \n    return train , test\n\ndef get_combined_data():\n  #reading train data\n  train , test = get_data()\n\n  target = train.SalePrice\n  train.drop(['SalePrice'],axis = 1 , inplace = True)\n\n  combined = train.append(test)\n  combined.reset_index(inplace=True)\n  combined.drop(['index', 'Id'], inplace=True, axis=1)\n  return combined, target\n\n#Load train and test data into pandas DataFrames\ntrain_data, test_data = get_data()\n\n#Combine train and test data to process them together\ncombined, target = get_combined_data()","a649b8d7":"combined.describe()","668c763b":"def get_cols_with_no_nans(df,col_type):\n    '''\n    Arguments :\n    df : The dataframe to process\n    col_type : \n          num : to only get numerical columns with no nans\n          no_num : to only get nun-numerical columns with no nans\n          all : to get any columns with no nans    \n    '''\n    if (col_type == 'num'):\n        predictors = df.select_dtypes(exclude=['object'])\n    elif (col_type == 'no_num'):\n        predictors = df.select_dtypes(include=['object'])\n    elif (col_type == 'all'):\n        predictors = df\n    else :\n        print('Error : choose a type (num, no_num, all)')\n        return 0\n    cols_with_no_nans = []\n    for col in predictors.columns:\n        if not df[col].isnull().any():\n            cols_with_no_nans.append(col)\n    return cols_with_no_nans","baccefe9":"num_cols = get_cols_with_no_nans(combined , 'num')\ncat_cols = get_cols_with_no_nans(combined , 'no_num')","d915dd49":"print ('Number of numerical columns with no nan values :',len(num_cols))\nprint ('Number of nun-numerical columns with no nan values :',len(cat_cols))","42d4e9be":"combined = combined[num_cols + cat_cols]\ncombined.hist(figsize = (12,10))\nplt.show()","b9ab391f":"train_data = train_data[num_cols + cat_cols]\ntrain_data['Target'] = target\n\nC_mat = train_data.corr()\nfig = plt.figure(figsize = (15,15))\n\nsb.heatmap(C_mat, vmax = .8, square = True)\nplt.show()","87a71a53":"def oneHotEncode(df,colNames):\n    for col in colNames:\n        if( df[col].dtype == np.dtype('object')):\n            dummies = pd.get_dummies(df[col],prefix=col)\n            df = pd.concat([df,dummies],axis=1)\n\n            #drop the encoded column\n            df.drop([col],axis = 1 , inplace=True)\n    return df","ba44b015":"print('There were {} columns before encoding categorical features'.format(combined.shape[1]))\ncombined = oneHotEncode(combined, cat_cols)\nprint('There are {} columns after encoding categorical features'.format(combined.shape[1]))","1b2b859d":"def split_combined():\n    global combined\n    train = combined[:1460]\n    test = combined[1460:]\n\n    return train , test ","ab2105c5":"train, test = split_combined()","275b6426":"NN_model = Sequential()","7db32e6b":"NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))","a323b768":"NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))","5175ba18":"NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\nNN_model.summary()","5b3c7f97":"checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \ncheckpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list = [checkpoint]","c7e38cda":"NN_model.fit(train, target, epochs=30, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)","b1abbd27":"# Load wights file of the best model :\nwights_file = '.\/Weights-073--21732.46875.hdf5' # choose the best checkpoint \nNN_model.load_weights(wights_file) # load it\nNN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])","6fc5a9b1":"def make_submission(prediction, sub_name):\n  my_submission = pd.DataFrame({'Id':pd.read_csv('test.csv').Id,'SalePrice':prediction})\n  my_submission.to_csv('{}.csv'.format(sub_name),index=False)\n  print('A submission file has been made')","14fd86ca":"predictions = NN_model.predict(test)","200fcf57":"input layer","f01acb6b":"Second : Make the Deep Neural Network\n\n    Define a sequential model\n    Add some dense layers\n    Use 'relu' as the activation function in the hidden layers\n    Use a 'normal' initializer as the kernal_intializer\n\n        Initializers define the way to set the initial random weights of Keras layers.\n\n    We will use mean_absolute_error as a loss function\n    Define the output layer with only one node\n    Use 'linear 'as the activation function for the output layer\n","727f2d52":"output layer","3bbca768":"compile the network"}}