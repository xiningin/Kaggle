{"cell_type":{"f737e53b":"code","ca0691c3":"code","38eefa63":"code","c8dfa09e":"code","0364b948":"code","dc617a74":"code","a9ca7d2b":"code","ef2ad232":"code","3aa014e3":"code","3e8910a5":"code","88031bd2":"code","7392ef4e":"code","2ff40dac":"code","1d0713c6":"code","fd3a4f55":"code","ea52d213":"code","6439fcbd":"code","4f806143":"code","239e1fdd":"code","12a2b953":"markdown","138c420c":"markdown","a66a2f00":"markdown","57e25cef":"markdown"},"source":{"f737e53b":"from tensorflow.keras.layers import Input,Dense ,Dropout\nimport numpy as np  \nimport pandas as pd\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.layers import Input,Dense,Dropout,LeakyReLU \nfrom tensorflow.keras.models import Sequential\nfrom matplotlib import pyplot as plt\nimport gc\nfrom sklearn.impute import SimpleImputer\nimport scipy.stats as spstats","ca0691c3":"path=\"\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/\"\ntest=pd.read_csv('\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv')\ntrain=pd.read_csv('\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv')\n\n","38eefa63":"sample_train=pd.read_csv('\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/train\/1004561781.csv')\nsample_train","c8dfa09e":"sample_train.isnull().sum()","0364b948":"fig , axs = plt.subplots(nrows=2,ncols=5)\nfig.set_size_inches(50,7)\nfig.subplots_adjust(hspace=1)\n\nfor col,ax in zip(sample_train.columns, axs.flatten()):\n    ax.plot(range(len(sample_train[col])),sample_train[col])\n    ax.set_title(col)","dc617a74":"def extract(dir_=\"train\"):\n    \n    if dir_==\"train\":\n        data=pd.read_csv(\"\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv\")\n    elif dir_==\"test\":\n        data=pd.read_csv(\"\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv\")\n    else:\n        raise KeyError(\"noob\")\n        \n    i=0\n    \n    for seg_id in data['segment_id']:\n        \n        f = pd.read_csv(f\"\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/{dir_}\/{seg_id}.csv\")\n\n        # Fill NaN\n        f.interpolate(axis=0,inplace=True)\n\n\n        for sensor in f.columns:\n\n            data.loc[i:i+1,f'{sensor}_mean']=f[f'{sensor}'].mean(axis=0)\n            data.loc[i,f'{sensor}_std']=f[f'{sensor}'].std(axis=0)\n            data.loc[i,f'{sensor}_max']=f[f'{sensor}'].max(axis=0)\n            data.loc[i,f'{sensor}_min']=f[f'{sensor}'].min(axis=0)\n            data.loc[i,f'{sensor}_mad']=f[f'{sensor}'].mad(axis=0)\n            data.loc[i,f'{sensor}_skew']=f[f'{sensor}'].skew(axis=0)\n            data.loc[i,f'{sensor}_kurt']=f[f'{sensor}'].kurt(axis=0)\n            data.loc[i,f'{sensor}_var']=f[f'{sensor}'].var(axis=0)\n            data.loc[i,f'{sensor}_median']=f[f'{sensor}'].median(axis=0)\n\n            data.loc[i,f'{sensor}_nunique']=f[f'{sensor}'].nunique()\n\n            data.loc[i,f'{sensor}_q005'] = f[f'{sensor}'].quantile(0.05)\n            data.loc[i,f'{sensor}_q010'] = f[f'{sensor}'].quantile(0.1 )\n            data.loc[i,f'{sensor}_q030'] = f[f'{sensor}'].quantile(0.3 )\n            data.loc[i,f'{sensor}_q070'] = f[f'{sensor}'].quantile(0.7 )\n            data.loc[i,f'{sensor}_q090'] = f[f'{sensor}'].quantile(0.9 )\n            data.loc[i,f'{sensor}_q095'] = f[f'{sensor}'].quantile(0.95)\n            data.loc[i,f'{sensor}_q999'] = f[f'{sensor}'].quantile(0.999)\n            data.loc[i,f'{sensor}_q87'] = f[f'{sensor}'].quantile(0.8)\n            data.loc[i,f'{sensor}_q13'] = f[f'{sensor}'].quantile(0.13)  \n            data.loc[i,f'{sensor}_q01'] = f[f'{sensor}'].quantile(0.01)\n            data.loc[i,f'{sensor}_q001'] = f[f'{sensor}'].quantile(0.001)\n\n            #f[f'{sensor}_pctchange'e(f[f'{sensor}]).pct_change(period=)\n            #f[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n            #f[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n            #f[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n           # data.iloc[i,[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n\n            x_abs=np.abs(f[f'{sensor}'])\n            data.loc[i,f'{sensor}_q999_abs'] = np.quantile(x_abs, 0.999)\n            data.loc[i,f'{sensor}_q99_abs']  = np.quantile(x_abs, 0.99)\n            data.loc[i,f'{sensor}_q95_abs']  = np.quantile(x_abs, 0.95)\n            data.loc[i,f'{sensor}_q87_abs']  = np.quantile(x_abs, 0.87)\n            data.loc[i,f'{sensor}_q13_abs']  = np.quantile(x_abs, 0.13)\n            data.loc[i,f'{sensor}_q05_abs']  = np.quantile(x_abs, 0.05)\n            data.loc[i,f'{sensor}_q01_abs']  = np.quantile(x_abs, 0.01)\n            data.loc[i,f'{sensor}_q001_abs'] = np.quantile(x_abs, 0.001)\n\n            z = np.fft.fft(f[f'{sensor}'].fillna(0))\n            fft_real = np.real(z)\n            fft_imag = np.imag(z)\n            data.loc[i,f'{sensor}_fft_real_mean'] = fft_real.mean()\n            data.loc[i,f'{sensor}_fft_real_std']  = fft_real.std()\n            data.loc[i,f'{sensor}_fft_real_max']= fft_real.max()\n            data.loc[i,f'{sensor}_fft_real_min']= fft_real.min()\n            data.loc[i,f'{sensor}_fft_real_median'] = np.median(fft_real)\n            data.loc[i,f'{sensor}_fft_real_skew'] = spstats.skew(fft_real)\n            data.loc[i,f'{sensor}_fft_real_kurtosis']= spstats.kurtosis(fft_real)\n\n            data.loc[i,f'{sensor}_fft_imag_mean'] = fft_imag.mean()\n            data.loc[i,f'{sensor}_fft_imag_std']= fft_imag.std()\n            data.loc[i,f'{sensor}_fft_imag_max'] = fft_imag.max()\n            data.loc[i,f'{sensor}_fft_imag_min'] = fft_imag.min()\n            data.loc[i,f'{sensor}_fft_imag_median']= np.median(fft_imag)\n            data.loc[i,f'{sensor}_fft_imag_skew'] = spstats.skew(fft_imag)\n            data.loc[i,f'{sensor}_fft_imag_kurtosis']= spstats.kurtosis(fft_imag)\n\n            #roll = f.rolling(300)\n            #roll_300_mean = roll.mean()\n            #roll_300_max = roll.max()\n            #roll_300_min = roll.min()\n            #roll_300_dist = roll_300_max - roll_300_min\n            #roll_300_dist_diff =roll_300_dist.diff()\n\n            #data.loc[i,f'{sensor}_roll_300_dist_min']=roll_300_dist.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_dist_max']=roll_300_dist.max(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_dist_diff_max']=roll_300_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_dist_diff_min']=roll_300_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_mean_min']=roll_300_dist.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_mean_max']=roll_300_dist.max(axis=0)\n\n\n            #roll = f.rolling(3000)\n            #roll_3000_mean = roll.mean()\n            #roll_3000_max = roll.max()\n            #roll_3000_min = roll.min()\n            #roll_3000_dist = roll_3000_max - roll_3000_min\n            #roll_3000_dist_diff = roll_3000_dist.diff()\n\n            #data.loc[i,f'{sensor}_roll_3000_dist_max']=roll_3000_dist.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_dist_min']=roll_3000_dist.max(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_dist_diff_max']=roll_3000_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_dist_diff_min']=roll_3000_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_mean_min']=roll_300_mean.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_mean_max']=roll_300_mean.max(axis=0)\n        i+=1\n    data.fillna(0)\n    return data","a9ca7d2b":"train_data=pd.read_csv('\/kaggle\/input\/volcaniceruptiondatasets\/train_data.csv')\ntrain_data=train_data.iloc[:,1:]\ntrain_data.fillna(0,inplace=True)","ef2ad232":"train_data","3aa014e3":"X_test=pd.read_csv('\/kaggle\/input\/volcaniceruptiondatasets\/test_data.csv')\nX_test.drop([\"time_to_eruption\"],axis=1,inplace=True)\nX_test.fillna(0,inplace=True)\nX_test=X_test.iloc[:,2:]","3e8910a5":"#imputer=SimpleImputer(strategy=\"mean\")\n#pd.DataFrame(imputer.fit_transform(train_data.iloc[:,2:]))\n#test_data_imp=pd.DataFrame(imputer.fit_transform(test_data))","88031bd2":"features = list(train_data.drop([\"segment_id\", \"time_to_eruption\"], axis=1).columns)","7392ef4e":"scaler=StandardScaler()\nscaler.fit(train_data[features])","2ff40dac":"train_data[features]=pd.DataFrame(scaler.transform(train_data[features]))\nX_test=scaler.transform(X_test)","1d0713c6":"X_train=train_data[features]\ny_train=train_data[\"time_to_eruption\"]","fd3a4f55":"X_train","ea52d213":"y_train","6439fcbd":"X_train.shape","4f806143":"import lightgbm as lgbm\ntarget_name = [\"time_to_eruption\"]\n\nsub_preds = np.zeros(X_test.shape[0])\n\nmodel = lgbm.LGBMRegressor(n_estimators=3000,metric=\"mse\",num_leaves=400,random_state=42,max_bins=3000)\n\nmodel.fit(X_train, y_train, eval_set= [(X_train, y_train)], eval_metric=\"mae\", verbose=12)\n\nsub_preds += model.predict(X_test)","239e1fdd":"submission = pd.DataFrame()\nsubmission['segment_id'] = test[\"segment_id\"]\nsubmission['time_to_eruption'] = sub_preds\nsubmission.to_csv('submission.csv', header=True, index=False)","12a2b953":"# Features Scaling","138c420c":"bruh dw ik that i overfitted","a66a2f00":":D","57e25cef":"# Feature Extraction"}}