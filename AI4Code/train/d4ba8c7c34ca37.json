{"cell_type":{"d899b9dd":"code","889b6ce4":"code","ea6ac549":"code","cd9f5e27":"code","93af861f":"code","5ac8d2c4":"code","3f6c961f":"code","6df2a614":"code","42000cc8":"code","f388860e":"code","1e8cbf93":"code","c7efbb57":"code","0790844b":"code","42f96965":"code","35bd8940":"markdown"},"source":{"d899b9dd":"import numpy as np\nimport pandas as pd \nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Dropout\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","889b6ce4":"train_df=pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_train.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_test.csv')\n","ea6ac549":"train_df.head(10)","cd9f5e27":"Y_train=train_df['label']\nX_train=train_df.drop('label',axis=1)\n\nY_test=test_df['label']\nX_test=test_df.drop('label',axis=1)\n","93af861f":"X_train = X_train.values.reshape(-1,28,28)\nX_test = X_test.values.reshape(-1,28,28)\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train[i],cmap=plt.get_cmap('gray'))\n    plt.xlabel(Y_train[i])\nplt.show()","5ac8d2c4":"sns.countplot(Y_train)\nplt.title(\"Frequency of each label\")","3f6c961f":"X_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)","6df2a614":"X_train = X_train\/255.0\nX_test = X_test\/255.0","42000cc8":"from sklearn.preprocessing import LabelBinarizer\nlabel_binrizer = LabelBinarizer()\nY_train = label_binrizer.fit_transform(Y_train)\nY_test = label_binrizer.fit_transform(Y_test)","f388860e":"print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)","1e8cbf93":"print(Y_train)","c7efbb57":"model=Sequential()\nmodel.add(Conv2D(filters = 128, kernel_size = (4,4), padding = \"Same\", activation = \"relu\", input_shape = (28,28,1)))\n\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (4,4), padding = \"Same\", activation = \"relu\" ))\n\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (4,4), padding = \"Same\", activation = \"relu\" ))\n\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (4,4), padding = \"Same\", activation = \"relu\" ))\n\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units = 512, activation = \"relu\"))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units =24, activation = \"softmax\"))\n\nmodel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n\nmodel.summary()\n","0790844b":"# training the model and saving metrics in history\nhistory = model.fit(X_train, Y_train,\n          batch_size=128, epochs=10,\n          verbose=2,\n          validation_data=(X_test, Y_test))","42f96965":"# plotting the metrics\nfig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\n\nplt.subplot(2,1,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\n\nplt.tight_layout()\n","35bd8940":"Reshaping, Normalisation and Encoding"}}