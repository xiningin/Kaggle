{"cell_type":{"e3f6be6e":"code","af912499":"code","655c968f":"code","2542b84a":"code","e84bc185":"code","9848d691":"code","9b249fcb":"code","d33500ee":"code","d9152e35":"code","b8fe9ce3":"code","e1b3568b":"code","148370f2":"code","58a2ecea":"code","499e89a4":"code","2833382f":"code","3b4bdf24":"code","f8b8da3a":"code","b912fef5":"code","7e61df7d":"code","d66f0adc":"code","6c0bb07e":"code","a5f34177":"code","52be2ef3":"code","7afa49f7":"code","7206205d":"code","2f32997b":"code","ce72d77e":"code","0544f692":"code","22ed65c1":"code","2f79537f":"code","239217ba":"code","34ccb788":"code","4beb97e5":"code","3951724f":"code","f681b8c3":"code","5747b0f2":"code","9f856a60":"code","d5b0acd5":"markdown","315284a5":"markdown","0e2e693e":"markdown","9f830960":"markdown","3df0408d":"markdown","4462c1ea":"markdown","917f4c1d":"markdown","779d4761":"markdown","c9071323":"markdown","ee6c824d":"markdown","769978bd":"markdown","1636fcd7":"markdown","1115ae59":"markdown","50a19e77":"markdown"},"source":{"e3f6be6e":"%matplotlib inline\nimport os\nimport gc\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nDATA_DIR = '..\/input\/'\n\nhex2dec = lambda x: int(x, 16)","af912499":"train = pd.read_csv(DATA_DIR+'train.csv')","655c968f":"cols = [\n    \"f190486d6\",\"58e2e02e6\",\"eeb9cd3aa\",\"9fd594eec\",\"6eef030c1\",\"15ace8c9f\",\n    \"fb0f5dbfe\",\"58e056e12\",\"20aa07010\",\"024c577b9\",\"d6bb78916\",\n    \"b43a7cfd5\",\"58232a6fb\"\n]\nrows = np.array([2072,3493,379,2972,2367,4415,2791,3980,194,1190,3517,811,4444])-1","2542b84a":"tmp = train.loc[rows, [\"ID\",\"target\"]+cols]\nprint('original shape', tmp.shape)\ntmp","e84bc185":"df_cand_col = train.loc[rows, :]\ndf_cand_col = df_cand_col.iloc[:, 2:]\ndf_cand_col","9848d691":"df_new = train.loc[rows, cols]","9b249fcb":"def bf_search(df_new, df_cand):\n    cnt = 0\n    head_curr = df_new.values[1:, 0]\n    tail_curr = df_new.values[:-1, -1]\n    while True:\n        for c in df_cand.columns:\n            if c in df_new:\n                continue\n            elif np.all(\n                df_cand[c].iloc[:-1].values==head_curr\n            ) and len(df_cand[c].unique())>1:\n                df_new.insert(0, c, df_cand[c].values)\n                head_curr = df_new.values[1:, 0]\n                print(c, 'found head!', 'new shape', df_new.shape)\n                cnt += 1\n                break\n            elif np.all(\n                df_cand[c].iloc[1:].values==tail_curr\n            ) and len(df_cand[c].unique())>1:\n                df_new[c] = df_cand[c].values\n                tail_curr = df_new.values[:-1, -1]\n                print(c, 'found tail!', 'new shape', df_new.shape)\n                cnt += 1\n                break\n            else:\n                continue\n        if cnt==0:\n            break\n        else:\n            cnt = 0\n            continue\n    return df_new","d33500ee":"print('Column searching ...')\ndf_new = bf_search(df_new, df_cand_col)","d9152e35":"df_new","b8fe9ce3":"df_new = df_new.T.copy()\ndf_new","e1b3568b":"df_cand_row = train[df_new.index].T.copy()\ndf_cand_row.head()","148370f2":"print('Row searching ...')\ndf_new = bf_search(df_new, df_cand_row)","58a2ecea":"df_new = df_new.T.copy()\ndf_new","499e89a4":"df_cand_col = train.loc[df_new.index, :]\ndf_cand_col = df_cand_col.iloc[:, 2:]\ndf_cand_col","2833382f":"print('Column searching (second time) ...')\ndf_new = bf_search(df_new, df_cand_col)","3b4bdf24":"print('new shape', df_new.shape)\ntrain.loc[df_new.index, [\"ID\",\"target\"]+df_new.columns.tolist()]","f8b8da3a":"print(f'Row indexes({df_new.shape[0]})\\n', df_new.index.values.tolist())\nprint(f'Column indexes({df_new.shape[1]})\\n', df_new.columns.values.tolist())","b912fef5":"for i, c in enumerate(df_new.columns):\n    print(\n        'No.', i, 'Column Name', c, \n        'subset count',\n        (df_new[c].values==1563411.76).sum(), \n        'train count',\n        (train[c].values==1563411.76).sum()\n    )","7e61df7d":"res_cnt = dict((c, (train[c].values==1563411.76).sum()) for c in train.columns[2:])\nres_cnt = pd.DataFrame.from_dict(res_cnt, orient='index', columns=['strange_number_cnt'])\nres_cnt = res_cnt.sort_values('strange_number_cnt', 0, False)\nres_cnt.head(50).T","d66f0adc":"res_cnt.head(10)","6c0bb07e":"for i, c in enumerate(df_new.T.columns):\n    print(\n        'No.', i, 'Row Name', c, \n        'subset count',\n        (df_new.T[c].values==1563411.76).sum(), \n        'train count',\n        (train.T[c].values==1563411.76).sum()\n    )","a5f34177":"tmp = train.iloc[:, 2:].values\nres_t_cnt = dict((idx, (tmp[i, :]==1563411.76).sum()) for i,idx in enumerate(train.index))\nres_t_cnt = pd.DataFrame.from_dict(res_t_cnt, orient='index', columns=['strange_number_cnt'])\nres_t_cnt = res_t_cnt.sort_values('strange_number_cnt', 0, False)\nres_t_cnt.head(50).T","52be2ef3":"head_row_indexes = res_t_cnt[res_t_cnt['strange_number_cnt']>24].index.tolist()\nhead_row_indexes","7afa49f7":"mask = res_t_cnt['strange_number_cnt']>0 \nmask&=res_t_cnt['strange_number_cnt']<8\ntail_row_indexes = res_t_cnt.loc[mask].index.tolist()\ntail_row_indexes","7206205d":"pd.concat([\n    train.loc[head_row_indexes, ['target']+df_new.columns.tolist()], \n    train.loc[df_new.index, ['target']+df_new.columns.tolist()],\n    train.loc[tail_row_indexes, ['target']+df_new.columns.tolist()], \n])","2f32997b":"df_new = pd.concat([\n    train.loc[head_row_indexes, df_new.columns.tolist()], \n    train.loc[df_new.index, df_new.columns.tolist()],\n    train.loc[tail_row_indexes, df_new.columns.tolist()], \n])","ce72d77e":"def row_bf_search(df_new):\n    df_new = df_new.T.copy()\n    df_cand_row = train[df_new.index].T.copy()\n    print('Row searching ...')\n    df_new = bf_search(df_new, df_cand_row)\n    df_new = df_new.T.copy()\n    return df_new\ndef column_bf_search(df_new):\n    df_cand_col = train.loc[df_new.index, :]\n    df_cand_col = df_cand_col.iloc[:, 2:]\n    print('Column searching ...')\n    df_new = bf_search(df_new, df_cand_col)\n    return df_new","0544f692":"df_new = column_bf_search(df_new)","22ed65c1":"df_new = row_bf_search(df_new)","2f79537f":"res_cnt[:10]","239217ba":"train.loc[df_new.index, ['target']+df_new.columns.tolist()+['fc99f9426','91f701ba2'] + res_cnt.index.values[:6].tolist()[::-1]]","34ccb788":"train.loc[df_new.index[-10:], df_new.columns.tolist()[-2:]+['fc99f9426', '91f701ba2'] + res_cnt.index.values[:6].tolist()[::-1]]","4beb97e5":"train.loc[df_new.index[:8], ['f190486d6', '58e2e02e6']].T","3951724f":"train.loc[df_new.index[-2:], df_new.columns.tolist()[-2:]+['fc99f9426', '91f701ba2']+res_cnt.index.values[:6].tolist()[::-1]]","f681b8c3":"df_new_new = train.loc[df_new.index, df_new.columns.tolist()+['fc99f9426','91f701ba2'] + res_cnt.index.values[:6].tolist()[::-1]]\ndf_new_new.shape","5747b0f2":"print(f'Row indexes({df_new_new.shape[0]})\\n', df_new_new.index.values.tolist())\nprint(f'Column indexes({df_new_new.shape[1]})\\n', df_new_new.columns.values.tolist())","9f856a60":"train.loc[df_new_new.index, ['ID', 'target']+df_new_new.columns.tolist()]","d5b0acd5":"### From row values (in reverse order), it seems 'fc99f9426', '91f701ba2' is consistent with other columns \n### Thus, in our limited analysis, the new df_new is","315284a5":"### Check the table above\n### Seems 540000.00 disappeared from column '1db387535'\n###      And 1015000.00\t disappeared from column 'fc99f9426'\n### Thus the time series is becoming not *serious* from here...\n### Another question, what about the order of 'fc99f9426','91f701ba2'? Which's first?","0e2e693e":"## Good! This is our new df_new and we got to search once more!","9f830960":"### Transpose the new result \n### and use the same method to search rows","3df0408d":"### Search in a brute-force way","4462c1ea":"## Hmm, seems something is wrong\n### at column: ['1db387535', 'fc99f9426','91f701ba2']\n### from ~last 10 rows","917f4c1d":"## Hmm, seems no same values. OK, we start from rows!","779d4761":"### The original result","c9071323":"## There's a strange long tail of number ***1563411.76*** pointed out by [S D](https:\/\/www.kaggle.com\/johnfarrell\/giba-s-property-extended-result\/comments#358945)\n## Thanks [S D](https:\/\/www.kaggle.com\/sdoria) for this new idea!\n## Let's check it","ee6c824d":"## No good... But wait! Let's check it!\n### Here, we still can't identify the true order of the columns with the same count 30\n### Just for example take a look at 'fc99f9426','91f701ba2' at first\n### We add 'fc99f9426','91f701ba2' and the first 6 columns with count 31~36","769978bd":"### Generate a subset candidates with same rows to search extendable columns","1636fcd7":"### For the final result consist many uncertains and hypothesis\n### Be careful of using this !!!\n### Any comments and advices are welcome !!!\n### Please point out if there's something wrong!!!","1115ae59":"## Giba's Property\n\n- https:\/\/www.kaggle.com\/titericz\/the-property-by-giba (kernel)\n- https:\/\/www.kaggle.com\/c\/santander-value-prediction-challenge\/discussion\/61329 (post)\n\n#### This kernel is just to extend giba's result in a *stupid* brute-force way\n### The updated part is based on [S D's comment](https:\/\/www.kaggle.com\/johnfarrell\/giba-s-property-extended-result\/notebook#358945)","50a19e77":"## Sad... there are *2* columns with the same count 30!\n- 91f701ba2\n- fc99f9426\n\n## What about the row-wise?"}}