{"cell_type":{"6985e7ab":"code","5819dbf2":"code","b0783aff":"code","a9b7a5c5":"code","80905292":"code","329356fe":"code","1af9ba72":"code","8caf3c8b":"code","f1ed7724":"code","89a103bc":"code","3ae6ff35":"code","827b8003":"code","5aaa49a9":"code","81d9a2d2":"code","48a4a4e2":"code","9dcdef96":"code","cc76623e":"code","14356a0f":"code","4621eb6a":"code","64510a52":"code","d798c7b5":"code","33a8bcf9":"code","ca88de82":"code","35b27675":"code","5e603659":"code","56fee40a":"markdown","c00025ca":"markdown","dc1a390d":"markdown","c16ad484":"markdown","d6bf4b0b":"markdown","0e3d153c":"markdown","729db901":"markdown","39434092":"markdown","fb4ead51":"markdown","d41e2224":"markdown","a2f10c38":"markdown","f44f82c4":"markdown","c3231bc6":"markdown","fe655981":"markdown","a03b5b02":"markdown","7366c374":"markdown","967646e0":"markdown","33e6f314":"markdown","ab2fb007":"markdown","63e94e5e":"markdown","80e0fe7d":"markdown","69753421":"markdown","1d074f21":"markdown","07bf7b38":"markdown","113e993f":"markdown","e7304512":"markdown","adce1ac9":"markdown"},"source":{"6985e7ab":"from IPython.display import Image\nImage(\"..\/input\/american_sign_language.PNG\")","5819dbf2":"import time\nfrom time import perf_counter as timer\nstart = timer()","b0783aff":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"..\/input\"))","a9b7a5c5":"train = pd.read_csv('..\/input\/sign_mnist_train.csv')\ntest = pd.read_csv('..\/input\/sign_mnist_test.csv')\ntrain.head()","80905292":"train.shape","329356fe":"Image(\"..\/input\/amer_sign2.png\")","1af9ba72":"labels = train['label'].values","8caf3c8b":"unique_val = np.array(labels)\nnp.unique(unique_val)","f1ed7724":"plt.figure(figsize = (18,8))\nsns.countplot(x =labels)","89a103bc":"from sklearn.preprocessing import LabelBinarizer\nlabel_binrizer = LabelBinarizer()\nlabels = label_binrizer.fit_transform(labels)\nlabels","3ae6ff35":"train.drop('label', axis = 1, inplace = True)","827b8003":"images = train.values\nprint(images.dtype, np.round(images.min(), 4), np.round(images.max(), 4), images.shape)","5aaa49a9":"plt.style.use('grayscale')\nfig, axs = plt.subplots(1, 5, figsize=(15, 4), sharey=True)\nfor i in range(5): \n        axs[i].imshow(images[i].reshape(28,28))\nfig.suptitle('Grayscale images')","81d9a2d2":"images =  images\/255","48a4a4e2":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3, stratify = labels, random_state = 7)","9dcdef96":"x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","cc76623e":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout","14356a0f":"num_classes = 24\nbatch_size = 125\nepochs = 50","4621eb6a":"model = Sequential()\nmodel.add(Conv2D(64, kernel_size=(4,4), activation = 'relu', input_shape=(28, 28 ,1), padding='valid' ))\nmodel.add(Dropout(0.4))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, kernel_size = (4, 4), activation = 'relu', padding='valid' ))\nmodel.add(Dropout(0.4))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(num_classes, activation = 'softmax'))\nmodel.compile(loss = keras.losses.categorical_crossentropy, optimizer='nadam',\n              metrics=['accuracy'])","64510a52":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(shear_range = 0.25,\n                                   zoom_range = 0.15,\n                                   rotation_range = 15,\n                                   brightness_range = [0.15, 1.15],\n                                   width_shift_range = [-2,-1, 0, +1, +2],\n                                   height_shift_range = [ -1, 0, +1],\n                                   fill_mode = 'reflect')\ntest_datagen = ImageDataGenerator()","d798c7b5":"history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)","33a8bcf9":"plt.style.use('tableau-colorblind10')\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.ylim(0.80, 1.05)\nplt.title(\"Accuracy\")\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['train','test'])\nplt.show()","ca88de82":"test_labels = test['label']\ntest.drop('label', axis = 1, inplace = True)\ntest_images = test.values\/255\ntest_images = np.array([np.reshape(i, (28, 28)) for i in test_images])\ntest_images = np.array([i.flatten() for i in test_images])\ntest_labels = label_binrizer.fit_transform(test_labels)\ntest_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\ntest_images.shape","35b27675":"y_pred = model.predict(test_images)\nfrom sklearn.metrics import accuracy_score\ny_pred = y_pred.round()\naccuracy_score(test_labels, y_pred)","5e603659":"end = timer()\nelapsed_time = time.gmtime(end - start)\nprint(\"Elapsed time:\")\nprint(\"{0} minutes {1} seconds.\".format(elapsed_time.tm_min, elapsed_time.tm_sec))","56fee40a":"An accuracy may fluctuate due to randomness of applyed methods. \n\n### My time count","c00025ca":"We are to normalize the data before applying CNN. Our data values range is from 0 to 255, so to normalize I divide every entry by 225.\n","dc1a390d":"The original MNIST image dataset of handwritten digits is a popular benchmark for image-based machine learning methods but researchers have renewed efforts to update it and develop drop-in replacements that are more challenging for computer vision and original for real-world applications. As noted in one recent replacement called the Fashion-MNIST dataset, the Zalando researchers quoted the startling claim that \"Most pairs of MNIST digits (784 total pixels per sample) can be distinguished pretty well by just one pixel\". To stimulate the community to develop more drop-in replacements, the Sign Language MNIST is presented here and follows the same CSV format with labels and pixel values in single rows. The American Sign Language letter database of hand gestures represent a multi-class problem with 24 classes of letters (excluding J and Z which require motion).\n\nThe full introduction can be seen here: \n[https:\/\/www.kaggle.com\/datamunge\/sign-language-mnist\/home](https:\/\/www.kaggle.com\/datamunge\/sign-language-mnist\/home)","c16ad484":"Now let us take out the image information from `train` object and put in into numpy array. What is a data type, range and dimensions?","d6bf4b0b":"What are our data dimensions?","0e3d153c":"As you can see all output numbers are about the same.\n\nFor our CNN network  I'm to create an output array with Label Binarizer from the labels.","729db901":"Our `train` set is reworked to reduce a data size. In particular all images are in grayscale and their sizes are 28 * 28 pixels. I will show pictures  in a few steps.","39434092":"Is our data balanced?","fb4ead51":"## Data Preprocessing\nLet us start to extract information from our data. At first I take a look at labels.","d41e2224":"Now I need to reshape our rows as square tables because I want to use a Convolution Neural Network method.","a2f10c38":"Importing necessary modules:","f44f82c4":"## About the Data","c3231bc6":"Here goes the CNN in all its beauty!","fe655981":"You see below how accuracy values improve with each epoch.","a03b5b02":"Now I drop the label column from the 'train' set and will work with the rest of data.","7366c374":"Let us see provided images using first 5 rows. ","967646e0":"## Convolutional Neural Network Model, or CNN\nFor CNN I am using keras library here.","33e6f314":"And now it runs!","ab2fb007":"Let's validate with the test data. At first it must be preprocessed in the same way as our data for model fitting. It means that  we are to remove its label column,  divide all values by 225 and rows should be reshaped as square arrays.","63e94e5e":"This part is for image augmentation during model fitting.","80e0fe7d":"Here we can look at original photographs:","69753421":"Here are predictions and an accuracy on our provided test set.","1d074f21":"# Convolutional Neural Networks with Image Augmentation","07bf7b38":"For validation during a model fitting we need to divide our train set in two parts. ","113e993f":"This type of computations may be long, so I start with timer setting to know how much time the script will take.","e7304512":" ## Data Load and Check","adce1ac9":"Setting a number of classes,  a batch size and a number of epochs."}}