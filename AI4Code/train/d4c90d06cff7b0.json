{"cell_type":{"c841ea3e":"code","e174fa68":"code","7160bb75":"code","3aa83ec6":"code","3962dd6c":"code","5120faa5":"code","17e84c76":"code","7d02d3d4":"code","e62ea527":"code","0e34206a":"code","9672d06f":"code","f3df6218":"code","fff2649f":"code","db7b71bb":"code","75336081":"code","9a4e8fe8":"code","2e2be1fe":"code","baa6ced3":"code","9699134a":"code","75cc7995":"code","fb45424f":"code","bc1b8130":"code","4964db3c":"code","b55e10be":"markdown","decd4427":"markdown","5ef740a5":"markdown","c9646363":"markdown","9699ce39":"markdown","2ce3465b":"markdown","70e718e0":"markdown","3c742045":"markdown","59f00c41":"markdown","6398afea":"markdown","a8b9bdb2":"markdown"},"source":{"c841ea3e":"!pip install git+https:\/\/github.com\/Ritvik19\/pyradox.git","e174fa68":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import sin, cos, pi\nimport cv2, os\nfrom tqdm.auto import tqdm\n\nfrom tensorflow.keras import layers, callbacks, utils, applications, optimizers, Input\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom pyradox import convnets","7160bb75":"class config:\n    NUM_EPOCHS = 100\n    BATCH_SIZE = 64","3aa83ec6":"print(\"Contents of input\/facial-keypoints-detection directory: \")\n!ls ..\/input\/facial-keypoints-detection\/\n\nprint(\"\\nExtracting .zip dataset files to working directory ...\")\n!unzip -u ..\/input\/facial-keypoints-detection\/test.zip\n!unzip -u ..\/input\/facial-keypoints-detection\/training.zip\n\nprint(\"\\nCurrent working directory:\")\n!pwd\nprint(\"\\nContents of working directory:\")\n!ls","3962dd6c":"%%time\n\ntrain_file = 'training.csv'\ntest_file = 'test.csv'\nidlookup_file = '..\/input\/facial-keypoints-detection\/IdLookupTable.csv'\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\nidlookup_data = pd.read_csv(idlookup_file)","5120faa5":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","17e84c76":"train_data.head()","7d02d3d4":"test_data.head()","e62ea527":"idlookup_data.head()","0e34206a":"print(\"Length of train data:\", len(train_data))","9672d06f":"train_data.isnull().sum()","f3df6218":"clean_train_data = train_data.dropna()\nprint(\"clean_train_data shape:\", np.shape(clean_train_data))\n\nunclean_train_data = train_data.fillna(method = 'ffill')\nprint(\"unclean_train_data shape:\", np.shape(unclean_train_data))","fff2649f":"%%time\n\ndef load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)\/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop('Image',axis = 1)\n    keypoint_features = []\n    for idx, sample_keypoints in keypoint_data.iterrows():\n        keypoint_features.append(sample_keypoints)\n    keypoint_features = np.array(keypoint_features, dtype = 'float')\n    return keypoint_features\n\nclean_train_images = load_images(clean_train_data)\nprint(\"Shape of clean_train_images:\", np.shape(clean_train_images))\nclean_train_keypoints = load_keypoints(clean_train_data)\nprint(\"Shape of clean_train_keypoints:\", np.shape(clean_train_keypoints))\ntest_images = load_images(test_data)\nprint(\"Shape of test_images:\", np.shape(test_images))\n\ntrain_images = clean_train_images\ntrain_keypoints = clean_train_keypoints\nfig, axis = plt.subplots()\nplot_sample(clean_train_images[19], clean_train_keypoints[19], axis, \"Sample image & keypoints\")\n\nunclean_train_images = load_images(unclean_train_data)\nprint(\"Shape of unclean_train_images:\", np.shape(unclean_train_images))\nunclean_train_keypoints = load_keypoints(unclean_train_data)\nprint(\"Shape of unclean_train_keypoints:\", np.shape(unclean_train_keypoints))\ntrain_images = np.concatenate((train_images, unclean_train_images))\ntrain_keypoints = np.concatenate((train_keypoints, unclean_train_keypoints))","db7b71bb":"print(\"\\nClean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(clean_train_images[i], clean_train_keypoints[i], axis, \"\")\nplt.show()\n\nprint(\"Unclean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(unclean_train_images[i], unclean_train_keypoints[i], axis, \"\")\nplt.show()","75336081":"inputs = Input(shape=(96, 96, 1))\nx = layers.Convolution2D(3, (1, 1), padding='same')(inputs)\nx = layers.LeakyReLU(alpha = 0.1)(x)\nx = convnets.MobileNetV3(config='small')(x)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.1)(x)\noutputs = layers.Dense(30)(x)\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.summary()","9a4e8fe8":"utils.plot_model(model, show_shapes=True, expand_nested=True)","2e2be1fe":"es = callbacks.EarlyStopping(\n    monitor='loss', patience=30, verbose=1, mode='min', baseline=None, restore_best_weights=True\n)\n\nrlp = callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-15, mode='min', verbose=1\n)\n\nmodel.compile(\n    optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc']\n)\n\nhistory = model.fit(\n    train_images, train_keypoints, epochs=int(1.5*config.NUM_EPOCHS), batch_size=config.BATCH_SIZE, \n    validation_split=0.05, callbacks=[es, rlp]\n)","baa6ced3":"sns.set_style('darkgrid')\n\nfig, ax = plt.subplots(3, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['mae', 'val_mae']].plot(ax=ax[0])\ndf[['loss', 'val_loss']].plot(ax=ax[1])\ndf[['acc', 'val_acc']].plot(ax=ax[2])\nax[0].set_title('Model MAE', fontsize=12)\nax[1].set_title('Model Loss', fontsize=12)\nax[2].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","9699134a":"%%time\n\nes = callbacks.EarlyStopping(\n    monitor='loss', patience=30, verbose=1, mode='min', baseline=None, restore_best_weights=True\n)\n\nrlp = callbacks.ReduceLROnPlateau(\n    monitor='loss', factor=0.5, patience=5, min_lr=1e-15, mode='min', verbose=1\n)\n\n\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=history.history['lr'][-1]), loss='mean_squared_error', metrics=['mae', 'acc']\n)\n\nhistory = model.fit(\n    train_images, train_keypoints, epochs=int(3.5*config.NUM_EPOCHS), batch_size=config.BATCH_SIZE, callbacks=[es, rlp]\n)","75cc7995":"fig, ax = plt.subplots(3, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['mae']].plot(ax=ax[0])\ndf[['loss']].plot(ax=ax[1])\ndf[['acc']].plot(ax=ax[2])\nax[0].set_title('Model MAE', fontsize=12)\nax[1].set_title('Model Loss', fontsize=12)\nax[2].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","fb45424f":"%%time\n \ntest_preds = model.predict(test_images)","bc1b8130":"fig = plt.figure(figsize=(20,16))\nfor i in range(20):\n    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n    plot_sample(test_images[i], test_preds[i], axis, \"\")","4964db3c":"feature_names = list(idlookup_data['FeatureName'])\nimage_ids = list(idlookup_data['ImageId']-1)\nrow_ids = list(idlookup_data['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","b55e10be":"# Model","decd4427":"## Training the model","5ef740a5":"**Find columns having Null values and their counts**","c9646363":"#### We can observe that approx. 68% of data is missing for several keypoints","9699ce39":"# Loading Data","2ce3465b":"## Exploring Data","70e718e0":"## Visualize Train images & corresponding Keypoints","3c742045":"## Predicting on Test Set","59f00c41":"## Generating Submission File","6398afea":"## Visualizing Test Predictions","a8b9bdb2":"### Fit the model on full dataset"}}