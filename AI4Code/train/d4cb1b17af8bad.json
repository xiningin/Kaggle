{"cell_type":{"bfa176df":"code","a4934ae0":"code","535431bf":"code","9300c90f":"code","8bfba98d":"code","442298b6":"code","4f359e77":"code","98398c29":"code","01dfd2f5":"code","4cf06983":"code","456246dc":"code","7d514f79":"code","fe949988":"code","a73b04f6":"code","06934d7f":"code","ff265452":"code","5d30a290":"code","5861c70e":"code","3ea5ee39":"code","19186677":"code","64039511":"code","9bee3036":"code","809a8cd3":"code","61b7e74f":"code","4f1c9a98":"code","2ec22f05":"code","ffe128dd":"code","8b554f5c":"code","b58a55db":"code","23907abc":"code","2e8c89bb":"code","77e0c0af":"code","f76fcb8b":"code","635991d9":"code","25b580fd":"code","3a6e1514":"code","fb2d1806":"code","68259ecc":"code","6be1b3b3":"code","1f7eb9ad":"code","2629c123":"code","908ffbdf":"code","6e1d6cf0":"code","ef131b13":"code","4ff7f53a":"code","865677e8":"code","c6acd4c2":"code","7b97dcef":"code","ad52706b":"code","3c0fd765":"markdown","6fe6b1c8":"markdown","b02e5185":"markdown","e8feda54":"markdown","8695936d":"markdown","777068a9":"markdown","8037af27":"markdown","fc6d2c6d":"markdown","e4453897":"markdown","700ca2c8":"markdown","b5b90a24":"markdown","b3a3aad8":"markdown","f12022ac":"markdown","3f452984":"markdown"},"source":{"bfa176df":"import os\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n%matplotlib inline\n\nfiles = [[path+f for f in os.listdir(path)[:10]] for path in [f'..\/input\/catvsdog-small-dataset\/dogs-vs-cat-small\/train\/{x}\/' for x in ['cats', 'dogs']]]\n\nfig, axs = plt.subplots(4, 5, figsize=(15,15), subplot_kw={'xticks': [], 'yticks': []})\n\nfor ax, img in zip(axs.flatten(), [item for sublist in files for item in sublist]):\n    ax.imshow(load_img(img))\n    ax.set_title(img.split('\/')[-1])","a4934ae0":"import numpy as np\nimport pandas as pd\nimport keras, tensorflow\nimport time\n\nprint('Keras', keras.__version__)\nprint('TensorFlow', tensorflow.__version__)","535431bf":"from keras.models import Sequential\nfrom keras.layers import Input, Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\ninput_tensor = Input(shape=(150,150,3))\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(150,150,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nprint(model.summary())","9300c90f":"model.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","8bfba98d":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_dir      = '..\/input\/catvsdog-small-dataset\/dogs-vs-cat-small\/train'\nvalidation_dir = '..\/input\/catvsdog-small-dataset\/dogs-vs-cat-small\/validation'\ntest_dir = '..\/input\/catvsdog-small-dataset\/dogs-vs-cat-small\/test'\n\ntrain_samples      = 2000\nvalidation_samples = 1000\n\ntarget_size    = (150,150)  # all images will be resized to 150x150\nbatch_size     = 20\n\n# rescale and augment training data\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n# rescale validation data\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='binary')","442298b6":"epochs = 30\n\nstart_time = time.time()\nhistory_simple = model.fit(\n    train_generator,\n    steps_per_epoch=train_samples \/\/ batch_size,\n    epochs=epochs,\n    verbose=2,\n    validation_data=validation_generator,\n    validation_steps=validation_samples \/\/ batch_size)\nprint(\"--- took %d:%.2d minutes ---\" % divmod(time.time() - start_time, 60))","4f359e77":"def plot_history(history, acc_line=None, title=None, acc_lim=[0.5,1.0]):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n    if title:\n        fig.suptitle(title, fontsize=16)\n    \n    ax1.plot(history.history['accuracy'])\n    ax1.plot(history.history['val_accuracy'])\n    if acc_line:\n        ax1.axhline(y=acc_line, linewidth=2, linestyle='dashed', color='lightgrey')\n    ax1.set_title('Model Accuracy')\n    ax1.set_ylabel('Accuracy')\n    ax1.set_xlabel('Epoch')\n    #ax1.set_yticks(np.arange(0., 1.1, .1))\n    ax1.set_ylim(acc_lim)\n    ax1.legend(['Train', 'Test'])\n    ax1.grid(b=True, which='major', color='lightgrey', linestyle='dotted')\n    \n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_title('Model Loss')\n    ax2.set_ylabel('Loss')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylim([0, 1.2])\n    ax2.legend(['Train', 'Test'])\n    ax2.grid(b=True, which='major', color='lightgrey', linestyle='dotted')","98398c29":"plot_history(history_simple, acc_line=0.8, title='Simple ConvNet')","01dfd2f5":"test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n    shuffle = False,\n    class_mode='binary')","4cf06983":"test_loss, test_acc = model.evaluate (test_generator, steps = 50)","456246dc":"print (test_acc)","7d514f79":"from keras.applications.vgg16 import VGG16\n\nbase_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))","fe949988":"def get_bottleneck_features(model, image_dir, target_size, samples, batch_size=20):\n    datagen   = ImageDataGenerator(rescale=1. \/ 255)\n    generator = datagen.flow_from_directory(image_dir,\n                                            target_size=target_size,\n                                            batch_size=batch_size,\n                                            class_mode=None,\n                                            shuffle=False)\n    return model.predict(generator, samples \/\/ batch_size)\n\ntrain_data_vgg16 = get_bottleneck_features(base_model_vgg16, train_dir, target_size, train_samples, batch_size)\nprint('created bottleneck features for training:', train_data_vgg16.shape)\n\nvalidation_data_vgg16 = get_bottleneck_features(base_model_vgg16, validation_dir, target_size, validation_samples, batch_size)\nprint('created bottleneck features for validation:', validation_data_vgg16.shape)\n\ntrain_labels = np.array([0] * (train_samples \/\/ 2) + [1] * (train_samples \/\/ 2))\nvalidation_labels = np.array([0] * (validation_samples \/\/ 2) + [1] * (validation_samples \/\/ 2))","a73b04f6":"from keras.models import Model\nfrom keras.layers import Input, Flatten, Dense, Dropout\n\ndef get_top_model(input_shape):\n    input = Input(input_shape)\n    x = Flatten()(input)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    prediction = Dense(1, activation='sigmoid')(x)\n    return Model(inputs=input, outputs=prediction)\n\ntop_model_vgg16 = get_top_model(train_data_vgg16.shape[1:])\n\ntop_model_vgg16.compile(loss='binary_crossentropy',\n                        optimizer='rmsprop',\n                        metrics=['accuracy'])","06934d7f":"epochs = 30\n\nstart_time = time.time()\nhistory_vgg16_top = top_model_vgg16.fit(train_data_vgg16, train_labels,\n                                        verbose=2,\n                                        epochs=epochs,\n                                        batch_size=batch_size,\n                                        validation_data=(validation_data_vgg16, validation_labels))\nprint(\"--- took %d:%.2d minutes ---\" % divmod(time.time() - start_time, 60))","ff265452":"model_weigths_file = 'bottleneck_fc_model_vgg16.h5'\ntop_model_vgg16.save_weights(model_weigths_file)","5d30a290":"plot_history(history_vgg16_top, acc_line=0.9, title='Pre-trained VGG16 with no augmentation', acc_lim=[0.75,1.0])","5861c70e":"from keras.models import Sequential\nfrom keras.layers import Input, Flatten, Dense, Dropout","3ea5ee39":"# load pre-trained VGG16 network (without classfication layers)\nbase_model_vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150,150,3))\nprint('Model loaded.')\n\n# set all but the last conv block to non-trainable (weights will not be updated)\nfor layer in base_model_vgg16.layers[:15]:\n    layer.trainable = False\n\n# create a classifier model to put on top of the convolutional model\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=base_model_vgg16.output_shape[1:]))\ntop_model.add(Dense(256, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(1, activation='sigmoid'))\ntop_model.load_weights(model_weigths_file)\n\n# add the model on top of the convolutional base\nmodel = Model(inputs = base_model_vgg16.input, outputs = top_model(base_model_vgg16.output))","19186677":"from keras import optimizers\n\n# compile model with a very slow learning rate\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(lr=1e-5),\n              metrics=['accuracy'])","64039511":"epochs = 30\n\nstart_time = time.time()\nhistory_tuned = model.fit(\n    train_generator,\n    steps_per_epoch=train_samples \/\/ batch_size,\n    epochs=epochs,\n    verbose=2,\n    validation_data=validation_generator,\n    validation_steps=validation_samples \/\/ batch_size)\nprint(\"--- took %d:%.2d minutes ---\" % divmod(time.time() - start_time, 60))","9bee3036":"plot_history(history_tuned, acc_line=0.93, title='Pre-trained VGG16 + pre-trained top model', acc_lim=[0.75,1.0])","809a8cd3":"test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n    shuffle = False,\n    class_mode='binary')","61b7e74f":"test_loss, test_acc = model.evaluate (test_generator, steps = 50)","4f1c9a98":"print (test_acc)","2ec22f05":"from keras.models import Model\nfrom keras.layers import Flatten, Dense, Dropout\n\n# build the VGG16 network\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n\n# freeze convolutional layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(1, activation='sigmoid')(x)\n\nmodel_vgg16base = Model(inputs=base_model.input, outputs=predictions)\n\nprint(model_vgg16base.summary())","ffe128dd":"model_vgg16base.compile(loss='binary_crossentropy',\n                        optimizer='rmsprop',\n                        metrics=['accuracy'])","8b554f5c":"epochs = 30\n\nstart_time = time.time()\nhistory_vgg16base = model_vgg16base.fit(\n    train_generator,\n    steps_per_epoch=train_samples \/\/ batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_samples \/\/ batch_size)\nprint(\"--- took %d:%.2d minutes ---\" % divmod(time.time() - start_time, 60))","b58a55db":"plot_history(history_vgg16base, acc_line=0.9, title='Pre-trained VGG16', acc_lim=[0.75, 1.0])","23907abc":"test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n    shuffle = False,\n    class_mode='binary')","2e8c89bb":"test_loss, test_acc = model_vgg16base.evaluate (test_generator, steps = 50)","77e0c0af":"print (test_acc)","f76fcb8b":"from keras.applications.inception_v3 import InceptionV3\n\n# load pre-trained weights and add global average pooling layer\nbase_model_incv3 = InceptionV3(weights='imagenet', input_shape=(150,150,3), include_top=False, pooling='avg')\n\n# freeze convolutional layers\nfor layer in base_model_incv3.layers:\n    layer.trainable = False\n\n# define classification layers\nx = Dense(256, activation='relu')(base_model_incv3.output)\nx = Dropout(0.5)(x)\npredictions = Dense(1, activation='sigmoid')(x)\n\nmodel_incv3 = Model(inputs=base_model_incv3.input, outputs=predictions)\n#print(model_incv3.summary())","635991d9":"model_incv3.compile(loss='binary_crossentropy',\n                    optimizer=optimizers.RMSprop(lr=0.0001),\n                    metrics=['accuracy'])","25b580fd":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.inception_v3 import preprocess_input\n\ndef prep(image):\n    # copy image to prevent overwriting\n    return preprocess_input(image.copy())\n\ntrain_datagen = ImageDataGenerator(\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        preprocessing_function=prep)\n\ntest_datagen = ImageDataGenerator(preprocessing_function=prep)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='binary')","3a6e1514":"epochs = 30\n\nstart_time = time.time()\nhistory_incv3 = model_incv3.fit(\n    train_generator,\n    steps_per_epoch=train_samples \/\/ batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_samples \/\/ batch_size)\nprint(\"--- took %d:%.2d minutes ---\" % divmod(time.time() - start_time, 60))","fb2d1806":"plot_history(history_incv3, acc_line=0.95, title=\"Pre-trained InceptionV3\", acc_lim=[0.75,1.0])","68259ecc":"test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n    shuffle = False,\n    class_mode='binary')","6be1b3b3":"test_loss, test_acc = model_incv3.evaluate (test_generator, steps = 50)","1f7eb9ad":"print (test_acc)","2629c123":"from keras.applications.resnet50 import ResNet50, preprocess_input\n\nbase_model = ResNet50(weights = 'imagenet', include_top = False, pooling = 'avg')","908ffbdf":"model = Sequential()\nmodel.add(base_model)\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.layers[0].trainable = False\nprint(model.summary())","6e1d6cf0":"model.compile(loss='binary_crossentropy',\n                    optimizer=optimizers.RMSprop(lr=0.0001),\n                    metrics=['accuracy'])","ef131b13":"def prep(image):\n    # copy image to prevent overwriting\n    return preprocess_input(image.copy())\n\ntrain_datagen = ImageDataGenerator(\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        preprocessing_function=prep)\n\ntest_datagen = ImageDataGenerator(preprocessing_function=prep)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='binary')","4ff7f53a":"epochs = 30\n\nstart_time = time.time()\nhistory_resnet50 = model.fit(\n    train_generator,\n    steps_per_epoch=train_samples \/\/ batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_samples \/\/ batch_size)\nprint(\"--- took %d:%.2d minutes ---\" % divmod(time.time() - start_time, 60))","865677e8":"plot_history(history_resnet50, acc_line=0.97, title=\"Pre-trained ResNet-50\", acc_lim=[0.85,1.0])","c6acd4c2":"test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n    shuffle = False,\n    class_mode='binary')","7b97dcef":"test_loss, test_acc = model.evaluate (test_generator, steps = 50)","ad52706b":"print (test_acc)","3c0fd765":"## ResNet50","6fe6b1c8":"### Provide Training and Test as Validation Image Using ImageDataGenerator","b02e5185":"### Provide Training and Validation Images using ImageDataGenerator\n\n**Caution**: InceptionV3 requires a different image preprocessing than VGG.","e8feda54":"## Training a Small ConvNet from Scratch\n\nA classic setup of three convolution layers with a ReLU activation, followed by max-pooling layers. On top two fully-connected layers and a single node with sigmoid activation for binary classification (cat or dog).","8695936d":"### Extract Bottleneck Features\n","777068a9":"### Show Example Images","8037af27":"# Cats vs. Dogs: Transfer Learning with little data\n\nCompare the performance of VGG16 and other pretrained Convolutional Nets (InceptionV3 and ResNet50).","fc6d2c6d":"### Train a Classifier with Bottleneck Features\n\nClassifier Setup: A dense layer with 256 neurons plus Dropout of 0.5 with a final layer of one neuron.","e4453897":"### Investigating Model Accuracy\n\nThe results can vary due to the random initialization. But the (validation) accuracy should be more or less close to 80%. Looking at the graphs we ses that the training accuracy continuously improves while the validation accuracy does not change much after ~15 epochs - a clear sign for overfitting.","700ca2c8":"### Create VGG16 model with pre-trained weights","b5b90a24":"### Use Pre-trained InceptionV3 Model","b3a3aad8":"### Prepare Model Training Setup","f12022ac":"### Create VGG16 model with pre-trained weights\n\n**Important**: Exclude the top layers (the dense classfication layers) because we are only interested in the output of the convolutional layers.","3f452984":"## Using bottleneck features of a pre-trained VGG16 network\n\nWe will be using VGG16 with pre-trained weights based on ImageNet divided into two steps:\n\n  * compute bottleneck features for all 2000 training images and 1000 validation images of cats and dogs\n  * create new binary classifier and train it with bottleneck features.\n\n**Note: there is no data augmentation applied - so expect to see more overfitting.**"}}