{"cell_type":{"b64accb8":"code","e73ce6e9":"code","b2d0f8b7":"code","8e17f0f7":"code","0c83fc2e":"code","2bb3fbcb":"code","10b6fae0":"code","f797b006":"code","1681df3f":"code","ed2af7ef":"code","ba0fecc8":"code","bca2a034":"code","d5a369e1":"code","7889f58d":"code","2fbe1c22":"code","52dc77de":"code","1aff35d1":"code","30307c0b":"code","dc9df50b":"code","7dda89f4":"code","a39c74bb":"code","d2aad1e9":"code","9d17eabf":"code","04a040b0":"markdown","73d7df17":"markdown","5d1aedf1":"markdown","8a2b18d2":"markdown","990367e7":"markdown","50741c33":"markdown","abf65c70":"markdown","d928b1f7":"markdown","4a3f83e4":"markdown","2f208a23":"markdown","89854ebf":"markdown","9565cf33":"markdown","efa8063c":"markdown","0cf2a410":"markdown","faf1b429":"markdown","520ad1eb":"markdown","afd59109":"markdown","6794cd85":"markdown","91995f24":"markdown","521e6d1f":"markdown"},"source":{"b64accb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport sklearn.linear_model as linear_model\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e73ce6e9":"adult = pd.read_csv('..\/input\/adult-income-dataset\/adult.data',names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nnadult = adult.dropna()","b2d0f8b7":"adult.shape\nadult.head()","8e17f0f7":"test_adult = pd.read_csv('..\/input\/adult-income-dataset\/adult.test',names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nntest_adult = test_adult.dropna()\nntest_adult.shape","0c83fc2e":"del nadult[\"Education\"]\ndel ntest_adult[\"Education\"]","2bb3fbcb":"def number_encode_features(df):\n    result = df.copy()\n    encoders = {}\n    for column in result.columns:\n        if result.dtypes[column] == np.object:\n            encoders[column] = preprocessing.LabelEncoder()\n            result[column] = encoders[column].fit_transform(result[column])\n    return result, encoders\nencoded_data, encoders = number_encode_features(nadult)\ntrain_encoded_data, train_encoders = number_encode_features(ntest_adult)\nsns.heatmap(encoded_data.corr(), square=True)\nplt.show()\nencoded_data.corr()","10b6fae0":"X_train, y_train = encoded_data[[\"Age\", \"Workclass\", \"fnlwgt\",\"Education-Num\", \"Martial Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\"Hours per week\", \"Country\"]], encoded_data[\"Target\"]\nX_test, y_test = train_encoded_data[[\"Age\", \"Workclass\", \"fnlwgt\",\"Education-Num\", \"Martial Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\"Hours per week\", \"Country\"]], train_encoded_data[\"Target\"]\nscaler = preprocessing.StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_test = scaler.transform(X_test)","f797b006":"cls = linear_model.LogisticRegression()\n\ncls.fit(X_train, y_train)\ny_pred = cls.predict(X_test)\naccuracy_score(y_test, y_pred)","1681df3f":"cross_val_model = linear_model.LogisticRegression()\nscores = cross_val_score(cross_val_model, X_train, y_train, cv=5)\nprint(np.mean(scores))","ed2af7ef":"from sklearn.tree import DecisionTreeClassifier\nArX_train, Ary_train = encoded_data[[\"Age\", \"Workclass\", \"fnlwgt\",\"Education-Num\", \"Martial Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\"Hours per week\", \"Country\"]], encoded_data[\"Target\"]\nArX_test, Ary_test = train_encoded_data[[\"Age\", \"Workclass\", \"fnlwgt\",\"Education-Num\", \"Martial Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\"Hours per week\", \"Country\"]], train_encoded_data[\"Target\"]","ba0fecc8":"clf = DecisionTreeClassifier(criterion=\"gini\")\nclf.fit(ArX_train,Ary_train)\ny_pred = clf.predict(ArX_test)\naccuracy_score(Ary_test, y_pred)","bca2a034":"clf = DecisionTreeClassifier(criterion=\"gini\",max_depth=9)\nclf.fit(ArX_train,Ary_train)\ny_pred = clf.predict(ArX_test)\naccuracy_score(Ary_test, y_pred)","d5a369e1":"from sklearn.naive_bayes import GaussianNB\nNBX_train, NBy_train = encoded_data[[\"Age\", \"Workclass\", \"fnlwgt\",\"Education-Num\", \"Martial Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\"Hours per week\", \"Country\"]], encoded_data[\"Target\"]\nNBX_test, NBy_test = train_encoded_data[[\"Age\", \"Workclass\", \"fnlwgt\",\"Education-Num\", \"Martial Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\"Hours per week\", \"Country\"]], train_encoded_data[\"Target\"]\nscaler = preprocessing.StandardScaler()\nNBX_train = pd.DataFrame(scaler.fit_transform(NBX_train), columns=NBX_train.columns)\nNBX_test = scaler.transform(NBX_test)","7889f58d":"gnb = GaussianNB()\ngnb.fit(NBX_train, NBy_train)\ny_pred = gnb.predict(NBX_test)\naccuracy_score(NBy_test, y_pred)","2fbe1c22":"\nscores = cross_val_score(gnb, NBX_train, NBy_train, cv=5)\nprint(np.mean(scores))","52dc77de":"import pandas as pd\ntest_data = pd.read_csv(\"..\/input\/atividade-3-pmr3508\/test.csv\",\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\ntrain_data = pd.read_csv(\"..\/input\/atividade-3-pmr3508\/train.csv\",\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\ntest_data.head()\n\n","1aff35d1":"train_data.shape","30307c0b":"train_data, test_data = train_data.dropna(), test_data.dropna()\n","dc9df50b":"X1_train, y1_train = train_data[['longitude','latitude','median_age','total_rooms','total_bedrooms', 'median_income','population']], train_data['median_house_value']\nX1_test = test_data[['longitude','latitude','median_age','total_rooms','total_bedrooms', 'median_income','population']]\nX1_train = pd.DataFrame(scaler.fit_transform(X1_train), columns=X1_train.columns)\nX1_test = scaler.transform(X1_test)","7dda89f4":"from sklearn.linear_model import LinearRegression\nclr = LinearRegression()\nclr.fit(X1_train,y1_train)\nscores = cross_val_score(clr, X1_train, y1_train, cv=5)\nprint(np.mean(scores))","a39c74bb":"knn = KNeighborsClassifier(n_neighbors=50)\nknn.fit(X1_train,y1_train)\nscores = cross_val_score(knn, X1_train, y1_train, cv=5)\nprint(np.mean(scores))","d2aad1e9":"clf = DecisionTreeClassifier(criterion=\"gini\",max_depth=9)\nclf.fit(X1_train,y1_train)\nscores = cross_val_score(clf, X1_train, y1_train, cv=5)\nprint(np.mean(scores))","9d17eabf":"cls.fit(X1_train,y1_train)\nscores = cross_val_score(cls, X1_train, y1_train, cv=5)\nprint(np.mean(scores))","04a040b0":"A maior acur\u00e1cia obtida foi ao utilizar \u00e1rvores de decis\u00e3o, j\u00e1 que para problemas mais simples apresenta uma alta efici\u00eancia. \nA acur\u00e1cia ao utilizar o m\u00e9todo Naive Bayes foi a menor, enquanto a regress\u00e3o logistica apresentou bons resultados. \nComparando os 3 classificadores, uso de \u00e1rvores de decis\u00e3o se mostrou o mais efetivo em termos de acur\u00e1cia.\n\n","73d7df17":"A fun\u00e7\u00e3o .fit_predict possui a capacidade de detec\u00e7\u00e3o de outliers\n","5d1aedf1":"Para Test data:","8a2b18d2":"Usando valida\u00e7\u00e3o cruzada.","990367e7":"Usando valida\u00e7\u00e3o cruzada","50741c33":"Como a coluna de education \u00e9 inutil, ela \u00e9 removida","abf65c70":"Usando Regress\u00e3o Linear e Cross-validation","d928b1f7":"Visualizando as primeiras 5 linhas da tabela gerada do objeto adult, e seu n\u00famero de linhas e colunas","4a3f83e4":"Usando entropy e limitando a altura da \u00e1rvore a fim de evitar overfittings\n","2f208a23":"Utilizando \u00c1rvores de decis\u00e3o, n\u00e3o \u00e9 necess\u00e1rio a normaliza\u00e7\u00e3o dos dados.","89854ebf":"Iniciando a tabela \"Adult\" a partir do arquivo .csv,indentificando a sepera\u00e7\u00e3o de dados como um espa\u00e7o uma virgula um espa\u00e7o, e definindo os dados faltantes como pontos de interroga\u00e7\u00e3o. Para treino, \u00e9 usada a tabela sem os dados faltante com nome \"nadult\"\n","9565cf33":"**ATIVIDADE EXTRA**","efa8063c":"Usando KNN","0cf2a410":"Utilizando regress\u00e3o logistica","faf1b429":"A maior acur\u00e1cia foi obtida utilizando regress\u00e3o linear, enquanto as outras tr\u00eas obtiveram resultados abaixo de 10%","520ad1eb":"Transformando as categorias em n\u00fameros e obtendo uma matriz de correla\u00e7\u00f5es.","afd59109":"Usando \u00c1rvores de decis\u00e3o","6794cd85":"Usando Gaussian Naive-Bayes, admitindo que a todas as vari\u00e1veis sejam independentes e siguam uma distribui\u00e7\u00e3o normal.","91995f24":"Existe uma alta correla\u00e7\u00e3o de target com : idade, sexo, ganho de capital,n\u00famero de educa\u00e7\u00e3o perda de capital, e horas por semana","521e6d1f":"Normalizando os dados"}}