{"cell_type":{"fc9f29c5":"code","6913e150":"code","8e03dbc0":"code","a7e5317d":"code","1965413f":"code","e3a7f50b":"code","12b87e6e":"code","0bf6ca7b":"code","6db51d2f":"code","d421a361":"code","35675328":"code","b0586180":"code","6af505eb":"code","b8c85624":"code","7f6289b4":"code","c553d716":"code","5458d7f8":"code","9f7f87e6":"code","142c6d30":"code","acddea0c":"code","a63ff826":"code","f1b9425b":"code","27f5586c":"code","b7aee641":"code","09582750":"code","c2ee15d5":"code","8069330a":"markdown","3b3c8add":"markdown","c4cc6f74":"markdown","5689f173":"markdown","1246c8a9":"markdown","913eeda8":"markdown","f81a5d88":"markdown","56875896":"markdown","09fcbe16":"markdown","1f04fbb0":"markdown","b4257b19":"markdown","4722575d":"markdown"},"source":{"fc9f29c5":"import keras\nimport tensorflow as tf\nimport keras.layers as layers\nimport numpy as np\nfrom numpy import save, load\nimport os\nfrom tensorflow import convert_to_tensor as tens\nfrom keras import backend as K\nfrom cv2 import getGaborKernel as Gabor\nfrom functools import reduce\nfrom matplotlib import pyplot as plt\nfrom math import sqrt\nimport itertools\nimport re\nfrom PIL import Image\nfrom random import choice, shuffle\nimport shutil\n","6913e150":"n_filters = 64\nn_orientations = 4\n\nksizes = [(i, i) for i in range(7,38, 2)]\nthetas = [0 , 45, 90, 135]\ngammas = [0.3] * 16\nsigmas = [2.8, 3.6, 4.5, 5.4, 6.3, 7.3, 8.2, 9.2, 10.2, 11.3, 12.3, 13.4, 14.6, 15.8, 17., 18.2]\nlambdas = [3.5, 4.6, 5.6, 6.8, 7.9, 9.1, 10.3, 11.5, 12.7, 14.1, 15.4, 16.8, 18.2, 19.7, 21.2, 22.8]\n\nall_filters = [[(size, sigma, theta, lambd, gamma) for theta in thetas] \n               for size, gamma, sigma, lambd in zip(ksizes, gammas, sigmas, lambdas)]\nall_filters = reduce(lambda x,y: x+y, all_filters, [])","8e03dbc0":"class GaborInitializer(tf.keras.initializers.Initializer):\n    def __init__(self, size, sigma, theta, lambd, gamma):\n        self.ksize = size\n        self.sigma = sigma\n        self.theta = theta\n        self.lambd = lambd\n        self.gamma = gamma\n\n    def __call__(self, dtype=None):\n        return tens(Gabor(self.ksize, self.sigma, self.theta, self.lambd, self.gamma))\n\n    def get_config(self):  # To support serialization\n        return {'ksize': self.ksize, 'sigma': self.sigma, 'theta': self.theta, 'lambda': self.lambd, 'gamma': self.gamma}","a7e5317d":"def conv2d_with_gabor(filters, trainable=False, shape=(1,256,256,1)):\n    layer = layers.Conv2D(len(filters), filters[0][0], kernel_initializer='zeros', padding='same')\n    initalize = layer(np.zeros(shape))\n    new_weights = np.stack([GaborInitializer(*filt)() for filt in filters]).transpose((1,2,0))[:,:,np.newaxis,:]\n    layer.set_weights([new_weights, layer.get_weights()[-1]])\n    layer.trainable = trainable\n    return layer","1965413f":"for i, filt in enumerate(all_filters):\n    plt.subplot(8,8,i+1)\n    plt.imshow(GaborInitializer(*filt)(), cmap='gray')\n    plt.axis(\"off\")","e3a7f50b":"max_pooling_size = list(range(8,23,2))","12b87e6e":"def preprocess_model(filters, n_filters, n_orientations, max_pooling_size, shape=(256,256,1)):\n    inp = keras.Input(shape=shape)\n    pre_process_s1 = [layers.Concatenate(axis=-2)\n                      ([K.expand_dims(\n                          conv2d_with_gabor(filters[n_orientations*j:n_orientations*(j+1)], trainable=False)(inp),\n                                      axis=-2) \n                        for j in (i, i+1)]) \n                      for i in range(0,n_filters\/\/n_orientations,2)]\n    pre_process_c1 = layers.Concatenate(axis=-2)([(layers.MaxPooling3D(pool_size=(ksize, ksize, 2), strides=(1,1,2), padding=\"same\")(i)) \n                      for i, ksize in zip(pre_process_s1, max_pooling_size)])\n    processor = keras.Model(inp, pre_process_c1)\n    return processor","0bf6ca7b":"processor = preprocess_model(all_filters, n_filters, n_orientations, max_pooling_size)","6db51d2f":"directory = '..\/input\/cat-and-dog'","d421a361":"test_photos_dogs = sorted([i for i in os.listdir(directory+'\/test_set\/test_set\/dogs') if re.findall('.jpg', i)])","35675328":"test_photos_cats = sorted([i for i in os.listdir(directory+'\/test_set\/test_set\/cats') if re.findall('.jpg', i)])","b0586180":"train_photos_dogs = sorted([i for i in os.listdir(directory+'\/training_set\/training_set\/dogs') if re.findall('.jpg', i)])","6af505eb":"train_photos_cats = sorted([i for i in os.listdir(directory+'\/training_set\/training_set\/cats') if re.findall('.jpg', i)])","b8c85624":"print(len(test_photos_dogs), len(test_photos_cats), len(train_photos_dogs), len(train_photos_cats))","7f6289b4":"filename = choice(test_photos_dogs)\nimage = np.array(Image.open(directory + '\/test_set\/test_set\/dogs\/'+filename))\nimage = tf.image.rgb_to_grayscale(image)\nimage = tf.image.resize(image, (256,256))\nimage = image * 1\/255\nnew_image = processor(image[np.newaxis]).numpy()[0]\nplt.figure(figsize=(10,10))\nfor i in range(8):\n    plt.subplot(8, 5, 5*i+1)\n    plt.imshow(image[:,:,0], cmap='gray')\n    plt.title('original')\n    plt.axis('off')\n    for j in range(4):\n        plt.subplot(8, 5, 5*i + j + 2)\n        plt.imshow(new_image[:,:,i,j], cmap='gray')\n        plt.axis('off')","c553d716":"def convert_some_pictures(processor, path, files, out_dirc):\n    for filename in files:\n        image = np.array(Image.open(path + filename))\n        image = tf.image.rgb_to_grayscale(image)\n        image = tf.image.resize(image, (256,256))\n        image = image * 1\/255\n        new_filename = out_dirc + re.findall('(.*).jpg', filename)[0] + '.npy'\n        new_image = processor(image[np.newaxis]).numpy()[0]\n        with open(new_filename, 'wb') as f:\n            save(f, new_image)\n        print('Converted:', new_filename)","5458d7f8":"def delete_files_in_directory(directory):\n    for filename in os.listdir(directory):\n        os.remove(directory + filename)","9f7f87e6":"def call_convert(processor, directory, filenames, output, zip_name):\n    convert_some_pictures(processor, directory, filenames, output)\n    print('Done converting!')\n    shutil.make_archive(zip_name, 'zip', output)\n    print(f'Done Zipping! Check for {zip_name}.')\n    delete_files_in_directory(output)\n    print('Done erasing photos!')","142c6d30":"os.makedirs('..\/working\/cat-and-dog-processed')","acddea0c":"for i in range(len(test_photos_dogs)\/\/500 + 1):\n    call_convert(processor, directory+'\/test_set\/test_set\/dogs\/', test_photos_dogs[i*500:(i+1)*500], '..\/working\/cat-and-dog-processed\/', f'test_dog_{i*500}_{(i+1)*500}')","a63ff826":"for i in range(len(test_photos_cats)\/\/500 + 1):\n    call_convert(processor, directory+'\/test_set\/test_set\/cats\/', test_photos_cats[i*500:(i+1)*500], '..\/working\/cat-and-dog-processed\/', f'test_cat_{i*500}_{(i+1)*500}')","f1b9425b":"for i in range(len(train_photos_dogs)\/\/500 + 1):\n    call_convert(processor, directory+'\/training_set\/training_set\/dogs\/', train_photos_dogs[i*500:(i+1)*500], '..\/working\/cat-and-dog-processed\/', f'train_dog_{i*500}_{(i+1)*500}')","27f5586c":"for i in range(len(train_photos_cats)\/\/500 + 1):\n    call_convert(processor, directory+'\/training_set\/training_set\/cats\/', train_photos_cats[i*500:(i+1)*500], '..\/working\/cat-and-dog-processed\/', f'train_cat_{i*500}_{(i+1)*500}')","b7aee641":"class NumpyDirectoryGeneratorSequence(Sequence):\n    def __init__(self, dct_label, dtype='.npy', randomize=True, random_seed=1331, validation_split=None, is_validation=False, batch_size=32):\n        self.directories = dct_label\n        self.dtype = dtype\n        self.randomize = randomize\n        self.seed = random_seed\n        self.validation_split = validation_split\n        self.is_validation = is_validation\n        self.batch_size = batch_size\n        self.x = self.y = None\n        self._create_files()\n        \n    def _create_files(self):\n        files = []\n        for directory,label in self.directories.items():\n            files += [(directory+ ('' if directory[-1] == '\/' else '\/') +i, label) \n                           for i in os.listdir(directory) \n                           if re.findall(self.dtype, i)]\n        if self.randomize:\n            seed(self.seed)\n            shuffle(files)\n        if self.validation_split:\n            if self.is_validation:\n                files = files[floor(len(files) - len(files)*self.validation_split):]\n            else:\n                files = files[:floor(len(files) - len(files)*self.validation_split)]\n                \n        self.x, self.y = zip(*files)\n        self.y = np.array(self.y)\n    \n    def __len__(self):\n        return ceil(self.y.shape[0] \/ self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch_x_pre, batch_y = self.x[idx * self.batch_size:(idx + 1) * self.batch_size], self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_x = [np.load(file) for file in batch_x_pre]\n        return np.array(batch_x), batch_y","09582750":"train_cat1 = \"..\/input\/processed-cat-0-to-2000\/\"\ntrain_cat2 = \"..\/input\/processed-cat-train-2000-to-end\/\"\ntrain_dog1 = \"..\/input\/processed-dog-train-0-to-1999\/\"\ntrain_dog2 = \"..\/input\/processed-dog-train-2000-to-end\/\"\ntrain_dct = {dirc+i:0 for dirc in (train_cat1, train_cat2) for i in os.listdir(dirc)}\ntrain_dct.update({dirc+i:1 for dirc in (train_dog1, train_dog2) for i in os.listdir(dirc)})","c2ee15d5":"test_dct = {\"..\/input\/processed-test-cats-and-dogs\/test_cat_0_500\": 0, \"..\/input\/processed-test-cats-and-dogs\/test_cat_1000_end\": 0, \n           \"..\/input\/processed-test-cats-and-dogs\/test_cat_500_1000\": 0, \"..\/input\/processed-test-cats-and-dogs\/test_dog_0_499\": 1,\n           \"..\/input\/processed-test-cats-and-dogs\/test_dog_1000_end\": 1, \"..\/input\/processed-test-cats-and-dogs\/test_dog_500_999\": 1}","8069330a":"# Gabor Filters","3b3c8add":"# Conversion Funcs","c4cc6f74":"Creates a Conv2D layer with a Gabor filter kernel","5689f173":"# MaxPooling sizes","1246c8a9":"# Example of a converted image","913eeda8":"# Generator to Read Dataset\n\nWon't work here because files aren't uploaded to input.\nCopy to your script.","f81a5d88":"Parameters:","56875896":"# A Preprocessing Model","09fcbe16":"How they look:","1f04fbb0":"# List of files to convert","b4257b19":"# Convert\nThe files weight too much, so after finishing each batch, download the created zip files (might take some time), restart the kernel, and run the next batch.","4722575d":"# An V1-like Image Preprocessing Algorithm\n\nThe idea and parameters are taken from [\"Robust Object Recognition with Cortex-Like Mechanisms\" (Serre et al.)](https:\/\/mcgovern.mit.edu\/wp-content\/uploads\/2019\/01\/04069258.pdf).\nThe idea is converting a single gray-scaled image (of size 256X256 for example) to distinct texture features by using Gabor filters convolution and MaxPooling (resulting in a matrix of 256X256X8X4).\nNotice that the algorithm in the article includes two more layers.\n\nThis script is converting a Cat and Dog dataset into zip files containing numpy files, each with a single processed image.\nThese files weight way too much, so please read the instructions if you want to use it.\n\nThis script is part of [another project.](https:\/\/www.kaggle.com\/royurbach\/doodling-l5pc-model-and-cats-vs-dogs)"}}