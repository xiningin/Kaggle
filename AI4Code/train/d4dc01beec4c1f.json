{"cell_type":{"db7c5b91":"code","d98fd7f1":"code","e144984b":"code","1393a02e":"code","f54ccb36":"code","7487e4e4":"code","21966df7":"code","5f09865d":"code","2f938537":"code","c74a1d7f":"code","4dbb299e":"code","aa7488b3":"code","e20d5191":"code","018aeb66":"code","57d90c5a":"code","baa59424":"code","0351dafe":"code","77b5e3e6":"code","0a88976c":"code","d075b61a":"code","6d6271b7":"code","929b9912":"code","6e81d73a":"code","9acba44d":"code","c3d85ae8":"code","36af39a0":"code","b63f28ba":"code","53153c5e":"code","687c8206":"code","16628859":"code","636f5fa6":"code","10460a8c":"code","e534902c":"code","44f1a5ee":"code","cb341254":"code","82fc064a":"code","6dc23667":"code","1c43d25f":"code","b6f9d298":"code","0416b82c":"code","f91aa17d":"code","4aa01f35":"code","a48f4eb0":"code","51ef4ae1":"code","72b793ac":"code","9726a0ac":"markdown","631849db":"markdown","3c0163f0":"markdown","8fbf4b27":"markdown","b180617a":"markdown","26f5dd5b":"markdown"},"source":{"db7c5b91":"import numpy as np\nimport pandas as pd\n\ndef calc_map_k(gt: pd.DataFrame, preds: pd.DataFrame, k=3) -> float:\n    # filter first k elements of ground truth\n    gt = gt[gt.order <= k]\n    # filter first k elements of predictions\n    preds = preds[preds.order <= k]\n    # join ground truth and predictions by user_id and order, fill missed values from predictions by some non-existent value\n    joined = gt.merge(preds, how=\"left\", on=['user_id', \"order\"]).fillna(-12345)\n    # create indicator of right predictions\n    joined[\"is_right\"] = (joined.item_id_x == joined.item_id_y).astype(int)\n    # calculate cumulative sum of all right predictions before current order\n    joined[\"is_right_cum\"] = joined.groupby(\"user_id\").is_right.cumsum()\n    # normalize it by order (precision@k)\n    joined[\"p@k\"] = joined[\"is_right_cum\"] \/ joined[\"order\"]\n    # add relevance mask\n    joined[\"p@k_masked\"] = joined[\"p@k\"] * joined[\"is_right\"]\n    # calculate mean user based (average precision @ k)\n    ap = joined.groupby(\"user_id\")[\"p@k_masked\"].mean()\n    # calculate mean average precision @ k\n    return ap.mean()","d98fd7f1":"from tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set(style='white')\n%matplotlib inline\n\nfrom matplotlib import rcParams\n\n# figure size in inches\nrcParams['figure.figsize'] = 16, 8\n\nfrom sklearn import decomposition","e144984b":"train = pd.read_csv('..\/input\/for-made-1\/train.csv')\ntrain.head()","1393a02e":"plt.hist(train.groupby('user_id').item_id.count().values, bins=65)\nplt.show()","f54ccb36":"test = pd.read_csv('..\/input\/for-made-1\/test.csv')\ntest.head()","7487e4e4":"submission = pd.read_csv('..\/input\/for-made-1\/sample-submission.csv', index_col=False)\nsubmission.head()","21966df7":"user_f = pd.read_csv('..\/input\/for-made-1\/user-features.csv', index_col='user_id')\nuser_f.head()","5f09865d":"sns.heatmap(user_f.corr(), annot = True, cmap='coolwarm')\nplt.show()","2f938537":"plt.hist(user_f['0'], bins=40)\nplt.show()","c74a1d7f":"user_f['0'] = ((user_f['0']*-1 + 1)**0.15 -0.65)*2\n\nplt.hist(user_f['0'], bins=40)\nplt.show()","4dbb299e":"d = {}\nfor i in train.user_id.unique():\n    d[i] = [0 for i in range(191)]","aa7488b3":"for i in tqdm(train.index):\n    key = train.iloc[i].user_id\n    val = train.iloc[i].item_id\n    d[key][val] = 1","e20d5191":"matt = [d[i] for i in train.user_id.unique()]","018aeb66":"from catboost import CatBoostRegressor\n\npred_less = []\n\nfor i in tqdm(range(191)):\n    y = [val[i] for val in matt]\n    \n    cat = CatBoostRegressor(iterations=50, silent=True, depth=4, l2_leaf_reg=9, learning_rate=0.05)\n    cat.fit(user_f, y)\n    \n    pred_less.append(cat.predict(user_f))","57d90c5a":"pred_ = np.array(pred_less).T","baa59424":"tmp_train = train.copy()\npredict = submission.copy()\n\nd = {}\nfor user in tmp_train.user_id.unique():\n    d[user] = tmp_train[tmp_train.user_id == user].item_id\n\nfor j in predict.index:\n    user = predict.iloc[j].user_id\n    \n    most = pred_[user].argsort()[::-1]\n    \n    if user not in d:\n        continue\n\n    for i in most:\n        if i not in d[user].values and i not in [150, 90]:\n            break\n\n    predict.iloc[j].item_id = i","0351dafe":"predict.to_csv('submission_catboost.csv', index=False) # \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 383","77b5e3e6":"import sys\nsys.path.append('..\/input\/iterative-stratification\/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","0a88976c":"from scipy import stats\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pylab as pl\ncolor = sns.color_palette()\n%matplotlib inline \n\nfrom matplotlib import rcParams\n\n# figure size in inches\nrcParams['figure.figsize'] = 16, 8","d075b61a":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.filterwarnings('ignore')","6d6271b7":"def set_seed(seed):\n    torch.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)","929b9912":"n_splits = 2 # 8\nnstarts = 1 # 8\n\nnfolds = n_splits\nnepochs = 30 # 150\nbatch_size = 64 # 32\nval_batch_size = batch_size * 4\n\ncriterion = nn.BCELoss()\n\nkfold = MultilabelStratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","6e81d73a":"class MoaModel(nn.Module):\n    def __init__(self, num_features):\n        super(MoaModel, self).__init__()\n        self.hidden_size = [764, 1146, 1528, 1910]\n        self.dropout_value = [0.09, 0.19, 0.24, 0.29]\n\n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dense1 = nn.Linear(num_features, self.hidden_size[0])\n        \n        self.batch_norm2 = nn.BatchNorm1d(self.hidden_size[0])\n        self.dropout2 = nn.Dropout(self.dropout_value[0])\n        self.dense2 = nn.Linear(self.hidden_size[0], self.hidden_size[1])\n\n        self.batch_norm3 = nn.BatchNorm1d(self.hidden_size[1])\n        self.dropout3 = nn.Dropout(self.dropout_value[1])\n        self.dense3 = nn.Linear(self.hidden_size[1], self.hidden_size[2])\n\n        self.batch_norm4 = nn.BatchNorm1d(self.hidden_size[2])\n        self.dropout4 = nn.Dropout(self.dropout_value[2])\n        self.dense4 = nn.Linear(self.hidden_size[2], self.hidden_size[3])\n\n        self.batch_norm5 = nn.BatchNorm1d(self.hidden_size[3])\n        self.dropout5 = nn.Dropout(self.dropout_value[3])\n        self.dense5 = nn.utils.weight_norm(nn.Linear(self.hidden_size[3], 191))\n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        x = F.leaky_relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x = F.leaky_relu(self.dense2(x))\n\n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        x = F.leaky_relu(self.dense3(x))\n\n        x = self.batch_norm4(x)\n        x = self.dropout4(x)\n        x = F.leaky_relu(self.dense4(x))\n\n        x = self.batch_norm5(x)\n        x = self.dropout5(x)\n        x = F.sigmoid(self.dense5(x))\n        return x","9acba44d":"# dataset class\nclass MoaDataset(Dataset):\n    def __init__(self, df, targets, feats_idx, mode='train'):\n        self.mode = mode\n        self.feats = feats_idx\n        print(feats_idx)\n        self.data = df[:, feats_idx]\n        if mode=='train':\n            self.targets = targets\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(self.targets[idx])\n        elif self.mode == 'test':\n            return torch.FloatTensor(self.data[idx]), 0","c3d85ae8":"user_f = pd.read_csv('..\/input\/for-made-1\/user-features.csv', index_col='user_id')\n\nuser_f['0'] = np.log(user_f['0']*-1 + 1) - np.log(user_f['0']*-1 + 1).mean()\nuser_f['1'] = np.log(user_f['1'] + 0.65) - np.log(user_f['1'] + 0.65).mean()","36af39a0":"from sklearn import preprocessing\n\ncolumns = user_f.columns\n\nscaler = preprocessing.StandardScaler().fit(user_f[columns])\nuser_f[columns] = scaler.transform(user_f[columns])","b63f28ba":"user_f.describe()","53153c5e":"user_f.shape","687c8206":"data_ = pd.read_csv('..\/input\/for-made-1\/train.csv')\ndata = data_.copy()","16628859":"y = np.zeros((15000, 191))\ny.shape","636f5fa6":"for i in range(len(data)):\n    y[data.iloc[i].user_id][data.iloc[i].item_id] = 1","10460a8c":"user_f.shape, y.shape","e534902c":"Y = pd.DataFrame(y, columns=['_' + str(i) for i in range(191)])\nY.head()","44f1a5ee":"X = pd.DataFrame(user_f, columns=[str(i) for i in range(16)])\nX.head()","cb341254":"# \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\ntmp = train.groupby('user_id').count()[['order']]\ntmp.order = np.where(tmp.order < 38, tmp.order + 27, tmp.order)\ntmp.order = np.where(tmp.order < 38, tmp.order + 20, tmp.order)\n\nfrom sklearn import preprocessing\n\ncolumns = user_f.columns\n\nscaler = preprocessing.StandardScaler().fit(tmp[['order']])\ntmp.order = scaler.transform(tmp[['order']])\n\n\nX['16'] = tmp.order\nX.head()","82fc064a":"plt.hist(X['16'], bins=28)\nplt.show()","6dc23667":"sns.heatmap(X.corr(), annot = True, cmap='coolwarm')\nplt.show()","1c43d25f":"target_columns = Y.columns\n\ntop_feats = X.columns\n\ntargets = target_columns\n\ntrain_targets = Y.values\ntrain = X.values\ntest = train.copy()\n\nntargets= train_targets.shape[1]\ntop_feats = range(len(top_feats))","b6f9d298":"train.shape, test.shape, train_targets.shape","0416b82c":"for seed in range(nstarts):\n    print(f'Train seed {seed}')\n    set_seed(seed)\n    \n    for n, (tr, te) in enumerate(kfold.split(train_targets, train_targets)):\n        print(f'Train fold {n+1}')\n        xtrain, xval = train[tr], train[te]\n        ytrain, yval = train_targets[tr], train_targets[te]\n        \n        train_set = MoaDataset(xtrain, ytrain, top_feats)\n        val_set = MoaDataset(xval, yval, top_feats)\n        \n        dataloaders = {\n            'train': DataLoader(train_set, batch_size=batch_size, shuffle=True),\n            'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False)\n        }\n        \n        model = MoaModel(len(top_feats)).to(device)\n        checkpoint_path = f'repeat:{seed}_Fold:{n+1}.pt'\n        optimizer = optim.Adam(model.parameters(), weight_decay=1e-5)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n        best_loss = {'train': np.inf, 'val': np.inf}\n        \n        for epoch in range(nepochs):\n            epoch_loss = {'train': 0.0, 'val': 0.0}\n            \n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()\n                else:\n                    model.eval()\n                \n                running_loss = 0.0\n                \n                for i, (x, y) in enumerate(dataloaders[phase]):\n                    x, y = x.to(device), y.to(device)\n                    \n                    optimizer.zero_grad()\n                    \n                    with torch.set_grad_enabled(phase=='train'):\n                        preds = model(x)\n                        loss = criterion(preds, y)\n                        \n                        if phase=='train':\n                            loss.backward()\n                            optimizer.step()\n                        \n                    running_loss += loss.item() \/ len(dataloaders[phase])\n                \n                epoch_loss[phase] = running_loss\n            \n            print(\"Epoch {}\/{}   -   loss: {:5.5f}   -   val_loss: {:5.5f}\".format(epoch+1, nepochs, epoch_loss['train'], epoch_loss['val']))\n            \n            scheduler.step(epoch_loss['val'])\n            \n            if epoch_loss['val'] < best_loss['val']:\n                best_loss = epoch_loss\n                torch.save(model.state_dict(), checkpoint_path)","f91aa17d":"oof = np.zeros((len(train), nstarts, ntargets))\noof_targets = np.zeros((len(train), ntargets))\npreds = np.zeros((len(test), ntargets))","4aa01f35":"def mean_log_loss(y_true, y_pred):\n    metrics = []\n    for i, target in enumerate(targets):\n        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n    return np.mean(metrics)","a48f4eb0":"for seed in range(nstarts):\n    print(f\"Inference for seed {seed}\")\n    seed_targets = []\n    seed_oof = []\n    seed_preds = np.zeros((len(test), ntargets, nfolds))\n    \n    for n, (tr, te) in enumerate(kfold.split(train_targets, train_targets)):\n        xval, yval = train[te], train_targets[te]\n        fold_preds = []\n        \n        val_set = MoaDataset(xval, yval, top_feats)\n        test_set = MoaDataset(test, None, top_feats, mode='test')\n        \n        dataloaders = {\n            'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False),\n            'test': DataLoader(test_set, batch_size=val_batch_size, shuffle=False)\n        }\n        \n        checkpoint_path = f'repeat:{seed}_Fold:{n+1}.pt'\n        model = MoaModel(len(top_feats)).to(device)\n        model.load_state_dict(torch.load(checkpoint_path))\n        model.eval()\n        \n        for phase in ['val', 'test']:\n            for i, (x, y) in enumerate(dataloaders[phase]):\n                if phase == 'val':\n                    x, y = x.to(device), y.to(device)\n                elif phase == 'test':\n                    x = x.to(device)\n                \n                with torch.no_grad():\n                    batch_preds = model(x)\n                    \n                    if phase == 'val':\n                        seed_targets.append(y)\n                        seed_oof.append(batch_preds)\n                    elif phase == 'test':\n                        fold_preds.append(batch_preds)\n                    \n        fold_preds = torch.cat(fold_preds, dim=0).cpu().numpy()\n        seed_preds[:, :, n] = fold_preds\n        \n    seed_targets = torch.cat(seed_targets, dim=0).cpu().numpy()\n    seed_oof = torch.cat(seed_oof, dim=0).cpu().numpy()\n    seed_preds = np.mean(seed_preds, axis=2)\n    \n    print(\"Score for this seed {:5.5f}\".format(mean_log_loss(seed_targets, seed_oof)))\n    oof_targets = seed_targets\n    oof[:, seed, :] = seed_oof\n    preds += seed_preds \/ nstarts\n\noof = np.mean(oof, axis=1)\nprint(\"Overall score is {:5.5f}\".format(mean_log_loss(oof_targets, oof)))","51ef4ae1":"tmp_train = train.copy()\npredict = submission.copy()\n\nd = {}\nfor user in range(15000):\n    d[user] = data_[data_.user_id == user].item_id\n\nfor j in predict.index:\n    user = predict.iloc[j].user_id\n    \n    most = preds[user].argsort()[::-1]\n    \n    if user not in d:\n        continue\n\n    for i in most:\n        if i not in d[user].values and i not in [150, 90]:\n            break\n\n    predict.iloc[j].item_id = i","72b793ac":"predict.to_csv('submission_nn.csv', index=False)  # \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 396","9726a0ac":"<a id=\"220\"><\/a>\n## Multilabel Neural Network","631849db":"<a id=\"210\"><\/a>\n## Catboost","3c0163f0":"## \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","8fbf4b27":"A. \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430  \n\n\u0415\u0441\u0442\u044c \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043d\u043e\u0432\u043e\u0441\u0442\u043d\u043e\u0439 \u0441\u0430\u0439\u0442, \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u044b \u0440\u0430\u0437\u043d\u044b\u0435 \u0441\u0442\u0430\u0442\u044c\u0438. \u0421\u0435\u0439\u0447\u0430\u0441 \u0437\u0434\u0435\u0441\u044c \u043d\u0435\u0442 \u043a\u0430\u043a\u043e\u0439-\u0442\u043e \u0441\u0435\u0440\u044c\u0435\u0437\u043d\u043e\u0439 \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b, \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044e \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442\u0441\u044f \u0432\u0441\u0435 \u043d\u0435\u0434\u0430\u0432\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u044c\u0438 \u043f\u043e \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u043e\u0441\u0442\u0438.\n\n\u0412 \u0432\u0430\u0448\u0435\u043c \u0440\u0430\u0441\u043f\u043e\u0440\u044f\u0436\u0435\u043d\u0438\u0438 \u0438\u043c\u0435\u044e\u0442\u0441\u044f \u0434\u0430\u043d\u043d\u044b\u0435 \u043e \u0442\u043e\u043c, \u043a\u0430\u043a\u0438\u0435 \u0441\u0442\u0430\u0442\u044c\u0438 (item_id) \u043e\u0442\u043a\u0440\u044b\u0432\u0430\u043b \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c (user_id) \u0438 \u043f\u043e\u0440\u044f\u0434\u043e\u043a (order), \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u043d\u0438 \u0431\u044b\u043b\u0438 \u043e\u0442\u043a\u0440\u044b\u0442\u044b. \u041f\u043e\u0440\u044f\u0434\u043e\u043a \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f \u0441 1 (\u0441\u0430\u043c\u043e\u0435 \u0440\u0430\u043d\u043d\u0435\u0435 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435) \u0438 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0441\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c.\n\n\u041e\u0431\u0443\u0447\u0430\u044e\u0449\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0430 \u0442\u0440\u0435\u043c\u044f \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u043c\u0438 [user_id, item_id, order], \u0433\u0434\u0435 user_id \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f, item_id \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0438 order \u2014 \u043f\u043e\u0440\u044f\u0434\u043a\u043e\u0432\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u043f\u043e\u0441\u0435\u0449\u0435\u043d\u043d\u043e\u0439 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b.\n\n\u041a\u0440\u043e\u043c\u0435 \u0442\u043e\u0433\u043e, \u0432 \u0432\u0430\u0448\u0435\u043c \u0440\u0430\u0441\u043f\u043e\u0440\u044f\u0436\u0435\u043d\u0438\u0438 \u0438\u043c\u0435\u044e\u0442\u0441\u044f \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f. \u041a\u043e\u043b\u043e\u043d\u043a\u0438 0-15 \u2014 \u043e\u0431\u0435\u0437\u043b\u0438\u0447\u0435\u043d\u043d\u0430\u044f \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435, \u043a\u043e\u043b\u043e\u043d\u043a\u0430 user_id \u2014 \u043a\u043b\u044e\u0447, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u043c\u043e\u0436\u043d\u043e \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u0430\u043c \u0438 \u0444\u0438\u0447\u0438 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f. \u041d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u0432\u0430\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 3 \u0441\u0430\u0439\u0442\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u0441\u0435\u0442\u0438\u0442 \u043a\u0430\u0436\u0434\u044b\u0439 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u0438\u0437 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0433\u043e \u0432\u044b\u0431\u043e\u0440\u043a\u0438. \u0410\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u043e \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u043c \u0434\u0430\u043d\u043d\u044b\u043c, \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0432 \u043d\u0435\u0439 \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f \u0441 1 \u0438 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0441\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c: order=1 \u043e\u0437\u043d\u0430\u0447\u0430\u0435\u0442, \u0447\u0442\u043e \u044d\u0442\u043e \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u043f\u043e\u0441\u0435\u0449\u0435\u043d\u043d\u044b\u0439 \u0441\u0430\u0439\u0442 \u043f\u043e\u0441\u043b\u0435 \u043e\u043a\u043e\u043d\u0447\u0430\u043d\u0438\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435.\n\n\u0424\u0430\u0439\u043b sample-submission.csv \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u043f\u0440\u0438\u043c\u0435\u0440 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0441\u0438\u0441\u0442\u0435\u043c\u0443. \u0412 \u0432\u0430\u0448\u0435\u043c \u0441\u0430\u0431\u043c\u0438\u0442\u0435 \u0434\u043e\u043b\u0436\u043d\u044b \u0431\u044b\u0442\u044c \u043a\u043e\u043b\u043e\u043d\u043a\u0438 \u0441 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u043c user_id, \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0430\u0439\u0442\u0435\u043c\u0430 \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f item_id \u0438 \u043a\u043e\u043b\u043e\u043d\u043a\u0430 order, \u043e\u043f\u0438\u0441\u044b\u0432\u0430\u044e\u0449\u0430\u044f \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0430\u0439\u0442\u0435\u043c\u043e\u0432, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u0438\u0445 \u0443\u0432\u0438\u0434\u0438\u0442. \u041d\u0435 \u0437\u0430\u0431\u044b\u0432\u0430\u0439\u0442\u0435, \u0447\u0442\u043e \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u0432 \u0441\u0430\u0431\u043c\u0438\u0442\u0435 \u0434\u043e\u043b\u0436\u0435\u043d \u043d\u0430\u0447\u0438\u043d\u0430\u0442\u044c\u0441\u044f \u0441 1 \u0438 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0442\u044c\u0441\u044f \u0441 \u043a\u0430\u0436\u0434\u044b\u043c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435\u043c.\n\n\u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0434\u043b\u044f \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u043d\u0438\u044f \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \u0440\u0430\u043d\u0436\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f mean average precision at k (MAP@k) \u043f\u0440\u0438 k=3. \u0422\u043e \u0435\u0441\u0442\u044c \u0432 \u043c\u0435\u0442\u0440\u0438\u043a\u0435 \u0431\u0443\u0434\u0443\u0442 \u0443\u0447\u0430\u0441\u0442\u0432\u043e\u0432\u0430\u0442\u044c \u0442\u043e\u043b\u044c\u043a\u043e 3 \u043f\u0435\u0440\u0432\u044b\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f. \u041d\u0430 \u043b\u0438\u0434\u0435\u0440\u0431\u043e\u0440\u0434\u0435 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \u0443\u043c\u043d\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u043d\u0430 10000, \u0442\u043e \u0435\u0441\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u0433\u043b\u044f\u0434\u0435\u0442\u044c \u043a\u0430\u043a 10000 * MAP@k.\n\n\u0427\u0442\u043e\u0431\u044b \u0440\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u0443\u044e \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e \u043c\u043e\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c.\n\n\u041d\u0430 \u0432\u0445\u043e\u0434 \u043d\u0430\u043c \u043f\u0440\u0438\u0445\u043e\u0434\u044f\u0442 \u0434\u0432\u0430 pd.DataFrame gt \u0438 preds \u0441 \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u043c\u0438 [user_id, item_id, order]. gt \u2013 ground truth, \u0442\u043e \u0435\u0441\u0442\u044c \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u0430 preds \u2013 \u043d\u0430\u0448\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f. \u0422\u043e\u0433\u0434\u0430 \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0448\u0430\u0433\u0438 \u0434\u043b\u044f \u0440\u0430\u0441\u0447\u0435\u0442\u0430 \u043c\u0435\u0442\u0440\u0438\u043a\u0438.\n\n1. \u041e\u0442\u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432\u0430\u0442\u044c gt \u0438 preds \u043f\u043e \u043a\u043e\u043b\u043e\u043d\u043a\u0435 order, \u0447\u0442\u043e\u0431\u044b \u0435\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0431\u044b\u043b\u043e \u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u0435 k (\u043f\u043e\u0440\u044f\u0434\u043a\u0430 k \u0432 MAP@k).\n\n2. \u0421\u0434\u0436\u043e\u0439\u043d\u0438\u0442\u044c \u0434\u0432\u0430 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430 \u043f\u043e user_id \u0438 order. \u0417\u0434\u0435\u0441\u044c \u043d\u0430\u043c \u0432\u0430\u0436\u043d\u043e \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u0442\u043e\u043c, \u043a\u0430\u043a\u043e\u0439 item_id \u043d\u0430 \u043a\u0430\u043a\u043e\u043c \u043c\u0435\u0441\u0442\u0435 \u0431\u044b\u043b \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f.\n\n\u041f\u043e\u0441\u043b\u0435 \u044d\u0442\u0438\u0445 \u0448\u0430\u0433\u043e\u0432 \u043c\u044b \u0433\u043e\u0442\u043e\u0432\u044b \u043a \u0440\u0430\u0441\u0447\u0435\u0442\u0443 \u043c\u0435\u0442\u0440\u0438\u043a \u043f\u043e \u0442\u0440\u0435\u043c \u0432\u044b\u0448\u0435\u043e\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u043c \u0448\u0430\u0433\u0430\u043c \u0434\u043b\u044f \u0440\u0430\u0441\u0447\u0435\u0442\u0430 MAP@k\n\n3. \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0432 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u043d\u044b\u0439 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c (joined) \u043a\u043e\u043b\u043e\u043d\u043a\u0443 is_right, \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0449\u0443\u044e, \u0447\u0442\u043e \u043d\u0430 \u0442\u0435\u043a\u0443\u0449\u0435\u043c \u043c\u0435\u0441\u0442\u0435 \u043e\u0442\u0432\u0435\u0442 \u0431\u044b\u043b \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u043c. 4. \u0422\u0430\u043a \u043a\u0430\u043a \u0434\u043b\u044f \u0440\u0430\u0441\u0447\u0435\u0442\u0430 precision@k \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0437\u043d\u0430\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u0441\u0435\u0445 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0445 \u0441\u043e\u0431\u044b\u0442\u0438\u0439 \u0434\u043e \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u043c\u043e\u043c\u0435\u043d\u0442\u0430, \u0442\u043e \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u043a\u0443\u043c\u0443\u043b\u044f\u0442\u0438\u0432\u043d\u0443\u044e \u0441\u0443\u043c\u043c\u0443 \u043a\u043e\u043b\u043e\u043d\u043a\u0438 is_right \u0432 \u0440\u0430\u0437\u0440\u0435\u0437\u0435 \u043f\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\u043c. \u041d\u0430\u0437\u043e\u0432\u0435\u043c \u0435\u0435 is_right_cum.\n\n5. \u0422\u0435\u043f\u0435\u0440\u044c \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c precision@k \u043f\u043e\u0434\u0435\u043b\u0438\u0432 \u043a\u043e\u043b\u043e\u043d\u043a\u0443 is_right_cum \u043d\u0430 order. \u0422\u043e \u0435\u0441\u0442\u044c \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u0443\u0433\u0430\u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u043e\u0431\u044b\u0442\u0438\u0439 \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u0441\u0435\u0445 \u0441\u043e\u0431\u044b\u0442\u0438\u0439 \u0434\u043e \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u043c\u043e\u043c\u0435\u043d\u0442\u0430.\n\n6. \u0412 AP@k \u0443\u0447\u0430\u0441\u0442\u0432\u0443\u044e\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 precision@k, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432 \u0442\u0435\u043a\u0443\u0449\u0438\u0439 \u043c\u043e\u043c\u0435\u043d\u0442 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0431\u044b\u043b \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u0443\u0433\u0430\u0434\u0430\u043d \u043e\u0442\u0432\u0435\u0442. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0435\u0449\u0435 \u043e\u0434\u043d\u0443 \u043a\u043e\u043b\u043e\u043d\u043a\u0443 p@k_masked, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043f\u0435\u0440\u0435\u043c\u043d\u043e\u0436\u0435\u043d\u0438\u0435\u043c p@k \u043d\u0430 is_right.\n\n7. \u041f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0432 \u0440\u0430\u0437\u0440\u0435\u0437\u0435 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f \u043f\u043e \u043a\u043e\u043b\u043e\u043d\u043a\u0435 p@k_masked, \u043f\u043e\u043b\u0443\u0447\u0438\u043c AP@k \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f.\n\n8. \u0422\u0435\u043f\u0435\u0440\u044c \u0432\u043e\u0437\u044c\u043c\u0435\u043c \u0433\u043b\u043e\u0431\u0430\u043b\u044c\u043d\u043e\u0435 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u043f\u043e AP@k \u0438 \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u043c\u0435\u0442\u0440\u0438\u043a\u0443 MAP@k.\n\n\u041d\u0438\u0436\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d \u043f\u0440\u0438\u043c\u0435\u0440 \u0438\u043c\u043f\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u043e\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u043b\u044f \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0439 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438.","b180617a":"<a id=\"0\"><\/a>\n# \u0417\u0430\u0434\u0430\u043d\u0438\u0435","26f5dd5b":"# \u0411\u044b\u0441\u0442\u0440\u0430\u044f \u043d\u0430\u0432\u0438\u0433\u0430\u0446\u0438\u044f\n* [\u0417\u0430\u0434\u0430\u043d\u0438\u0435](#0)   \n\n* [ 0. CatBoost](#210)\n  \n* [ 1. Multilabel Neural Network](#220)"}}