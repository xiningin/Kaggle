{"cell_type":{"144acc1f":"code","54f6b609":"code","b3958f61":"code","4383db44":"code","632766ef":"code","c130fb18":"code","db6dee2a":"code","e2fd3fb3":"code","b0ffeaa1":"code","666c6568":"code","b6f67fd3":"code","e657a1f6":"code","303545ab":"code","34f6fc04":"code","35dbe509":"code","0179fd9e":"code","3b615e56":"code","fb02b10a":"code","afded876":"code","ba463ce1":"code","cd971889":"code","b695f5af":"code","21ac8b74":"code","0a4333ee":"code","ffb4ca28":"code","8ba07b4c":"code","6e7f604c":"code","ae773b67":"code","8c0cf317":"code","10a747b2":"code","e84c9da7":"code","d5c410d1":"code","ca149539":"code","80c099c3":"code","6092ab2c":"code","84daa93f":"code","d6eb8e65":"code","9f1b888f":"code","5952d5e4":"code","9a014ea8":"code","e5df66c9":"code","5969e158":"code","2575fde1":"code","d4b9f063":"code","da2698c9":"code","34db594f":"code","2395fec3":"code","19be4d50":"code","25a3bd27":"code","89d93374":"code","f289ce7d":"code","51955bed":"code","a3fe9dba":"code","718545cf":"code","f49663e3":"code","814da555":"code","173cbbc7":"code","14080818":"code","0f03b660":"code","1951ad10":"code","8258d75e":"code","d0b7e3b4":"code","09d465da":"code","f0cf0847":"code","e7df0523":"code","40b9329b":"code","79efa69a":"code","3763def8":"code","e63493e2":"code","415b1f36":"code","e84e7bf8":"code","1cf04568":"code","2dcef724":"code","a3a0aa9f":"code","217585d6":"code","0897daa2":"code","f9198462":"code","c886d961":"code","e0a78efc":"code","2f594609":"code","30e01fb6":"code","b3c2d58c":"code","b820b75a":"code","1fd12611":"code","9a8302f3":"code","7e96b7d5":"code","16ad0985":"code","0eaca6d4":"code","44807310":"code","133a8a8e":"code","347851c9":"code","345efbce":"code","dbcdb70f":"code","60accdd3":"code","301dd687":"code","4296645a":"code","c758111c":"code","cc4f7c13":"code","3d2e8ae0":"code","b5fa0997":"code","b89f9dc3":"markdown","9960b899":"markdown","d2d32f47":"markdown","ab783312":"markdown","6d504e21":"markdown","e7a63b36":"markdown"},"source":{"144acc1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nimport warnings\n\nwarnings.filterwarnings('ignore')\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","54f6b609":"def initial_df(file, columns, option):\n    df = pd.read_csv(file, skiprows=[0])\n    if option == 'drop':\n        df = df.drop(columns=columns)\n    elif option == 'extract':\n        df = df[columns]\n    \n    return df","b3958f61":"standard_df = initial_df(\"..\/input\/soccer-reference\/standard data\/team data.csv\", \n                         ['# Pl', 'MP', 'Starts', 'Min', 'Gls', 'Ast', 'PK', 'PKatt', 'CrdR', 'CrdY', 'xG', 'npxG', 'xA'],\n                        'drop')\nstandard_df.head()","4383db44":"shooting_df = initial_df(\"..\/input\/soccer-reference\/shooting\/team.csv\", ['Squad', 'SoT%', 'SoT\/90', 'SoT', 'G\/SoT', 'npxG\/Sh'], 'extract')\nshooting_df.head()","632766ef":"possession_df = initial_df(\"..\/input\/soccer-reference\/possession\/team.csv\", ['Squad', 'Succ%', 'Rec%'], 'extract')\npossession_df.head()","c130fb18":"playingTime_df = initial_df(\"..\/input\/soccer-reference\/playing time\/team.csv\", ['Squad', 'PPM', '+\/-90', 'xG+\/-90'], 'extract')\nplayingTime_df.head()","db6dee2a":"passing_df = initial_df(\"..\/input\/soccer-reference\/passing\/team.csv\", \n                        ['Squad', 'Cmp%', 'Cmp%.1', 'Cmp%.2', 'Cmp%.3'],\n                       'extract')\npassing_df.head()","e2fd3fb3":"goalkeeping_df = initial_df(\"..\/input\/soccer-reference\/goalkeeping\/team.csv\", \n                            ['Squad', 'GA90', 'Save%'],\n                           'extract')\ngoalkeeping_df.head()","b0ffeaa1":"goalShotCreation_df = initial_df(\"..\/input\/soccer-reference\/goal and shot creation\/team.csv\", ['Squad', 'SCA90', 'GCA90'], 'extract')\ngoalShotCreation_df.head()","666c6568":"defence_df = initial_df(\"..\/input\/soccer-reference\/defensive actions\/team.csv\", ['Squad', 'Tkl%', '%'], 'extract')\ndefence_df.head()","b6f67fd3":"adv_goalkeeping_df = initial_df(\"..\/input\/soccer-reference\/advanced goalkeeping\/team.csv\", \n                                ['Squad', '\/90', 'Cmp%', 'Launch%', 'AvgLen', 'Launch%.1', 'AvgLen.1', 'Stp%', '#OPA\/90', 'AvgDist'],\n                               'extract')\nadv_goalkeeping_df.head()","e657a1f6":"miscellaneous_df = initial_df('..\/input\/soccer-reference\/Miscellaneous.csv', ['Squad', 'Won%'], 'extract')\nmiscellaneous_df.head()","303545ab":"ranking_df = pd.read_csv('..\/input\/soccer-reference\/soccer-spi\/spi_global_rankings.csv')[['name', 'off', 'def', 'spi']]\nranking_df.head()","34f6fc04":"# combine all involved features\naggregate = standard_df.merge(shooting_df, left_on='Squad', right_on='Squad', suffixes=('_std', '_sht'))\naggregate = aggregate.merge(possession_df, left_on='Squad', right_on='Squad', suffixes=('', '_psn'))\naggregate = aggregate.merge(playingTime_df, left_on='Squad', right_on='Squad', suffixes=('', '_pTime'))\naggregate = aggregate.merge(passing_df, left_on='Squad', right_on='Squad', suffixes=('', '_psg'))\naggregate = aggregate.merge(goalkeeping_df, left_on='Squad', right_on='Squad', suffixes=('', '_gkp'))\naggregate = aggregate.merge(goalShotCreation_df, left_on='Squad', right_on='Squad', suffixes=('', '_gsc'))\naggregate = aggregate.merge(defence_df, left_on='Squad', right_on='Squad', suffixes=('', '_dfc'))\naggregate = aggregate.merge(adv_goalkeeping_df, left_on='Squad', right_on='Squad', suffixes=('', '_agk'))","35dbe509":"for i in range(len(aggregate)):\n    x = str(aggregate['Squad'].iloc[i]).split(' ')\n    if len(x) == 2:\n        aggregate['Squad'].iloc[i] = x[1]\n    elif len(x) == 3:\n        aggregate['Squad'].iloc[i] = x[1] + ' ' + x[2]","0179fd9e":"def name_changer(df, col):\n    df[col].loc[df[col]== 'Atl\u00e9tico Madrid'] = 'Atletico Madrid'\n    df[col].loc[df[col]== 'Dortmund'] = 'Borussia Dortmund'\n    df[col].loc[df[col]== 'Inter'] = 'Internazionale'\n    df[col].loc[df[col]== 'Leverkusen'] = 'Bayer Leverkusen'\n    df[col].loc[df[col]== 'Paris S-G'] = 'Paris Saint-Germain'\n    df[col].loc[df[col]== 'RB Salzburg'] = 'FC Salzburg'\n    df[col].loc[df[col]== 'Red Star'] = 'Red Star Belgrade'\n    df[col].loc[df[col]== 'Shakhtar'] = 'Shakhtar Donetsk'\n    df[col].loc[df[col]== 'Tottenham'] = 'Tottenham Hotspur'\n    df[col].loc[df[col]== 'Zenit'] = 'Zenit St Petersburg'\n    df[col].loc[df[col]== 'Loko Moscow'] = 'Lokomotiv Moscow'","3b615e56":"name_changer(aggregate, 'Squad')","fb02b10a":"# aggregate = aggregate.merge(ranking_df, left_on='Squad', right_on='name')\n# aggregate = aggregate.drop(columns=['name'])","afded876":"aggregate.columns","ba463ce1":"# preview\nimport seaborn as sns\n\nmask = np.tril(aggregate.corr())\nsns.heatmap(aggregate.corr(), mask=mask)","cd971889":"fixtures = pd.read_csv('..\/input\/soccer-reference\/fixtures.csv')[:-6]\nfixtures = fixtures[['Home', 'Score', 'Away']].dropna()\nfixtures['Home_Score'] = 0\nfixtures['Away_Score'] = 0\nfor i in range(len(fixtures)):\n    x = str(fixtures['Score'].iloc[i]).split('\u2013')\n    fixtures['Home_Score'].iloc[i] = x[0]\n    fixtures['Away_Score'].iloc[i] = x[1]","b695f5af":"fixtures['Score'].value_counts().plot.barh()","21ac8b74":"Score = fixtures['Score']","0a4333ee":"for i in range(len(fixtures)):\n    x = str(fixtures['Home'].iloc[i]).split(' ')\n    y = str(fixtures['Away'].iloc[i]).split(' ')\n    if len(x) == 2:\n        fixtures['Home'].iloc[i] = x[0]\n    elif len(x) == 3:\n        fixtures['Home'].iloc[i] = x[0] + \" \" + x[1]\n        \n    if len(y) == 2:\n        fixtures['Away'].iloc[i] = y[1]\n    elif len(y) == 3:\n        fixtures['Away'].iloc[i] = y[1] + \" \" + y[2]","ffb4ca28":"name_changer(fixtures, 'Home')\nname_changer(fixtures, 'Away')","8ba07b4c":"fixtures = fixtures.merge(aggregate, left_on='Home', right_on='Squad')\nfixtures = fixtures.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))","6e7f604c":"fixtures = fixtures.drop(columns=['Squad_Home', 'Squad_Away', 'Score'])\nfixtures.head()","ae773b67":"fixtures[['Home_Score', 'Away_Score']].apply(pd.Series.value_counts).sum(axis=1)","8c0cf317":"future_games = pd.read_csv('..\/input\/soccer-reference\/fixtures.csv')[-6:][['Home', 'Away']].dropna()\n\nfor i in range(len(future_games)):\n    x = str(future_games['Home'].iloc[i]).split(' ')\n    y = str(future_games['Away'].iloc[i]).split(' ')\n    if len(x) == 2:\n        future_games['Home'].iloc[i] = x[0]\n    elif len(x) == 3:\n        future_games['Home'].iloc[i] = x[0] + \" \" + x[1]\n        \n    if len(y) == 2:\n        future_games['Away'].iloc[i] = y[1]\n    elif len(y) == 3:\n        future_games['Away'].iloc[i] = y[1] + \" \" + y[2]\n        \nname_changer(future_games, 'Home')\nname_changer(future_games, 'Away')\n\nfuture_games = future_games.merge(aggregate, left_on='Home', right_on='Squad')\nfuture_games = future_games.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\nfuture_games = future_games.drop(columns=['Squad_Home', 'Squad_Away'])","10a747b2":"future_games","e84c9da7":"from sklearn.decomposition import PCA\n\n# squads = aggregate['Squad']\nX = fixtures.drop(columns=['Home', 'Away', 'Home_Score', 'Away_Score'])\nfor k in range(2, 20, 2):\n    pca = PCA(n_components=k, svd_solver='randomized')\n    pca.fit(X)\n    print(\"the cumulative variance of {} PCs is {}\".format(k, pca.explained_variance_ratio_.sum()))","d5c410d1":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n\nX = fixtures.drop(columns=['Home', 'Away', 'Home_Score', 'Away_Score'])\ny = fixtures[['Home_Score', 'Away_Score']].astype(int)\npca = PCA(n_components=14, svd_solver='randomized')\nX = pca.fit_transform(X)\nclf = MultiOutputRegressor(LogisticRegression(random_state=0)).fit(X, y)\n\nmean_squared_error(clf.predict(X), y)","ca149539":"import xgboost as xgb\n\nxgb_model = MultiOutputRegressor(xgb.XGBClassifier(random_state=42))\nxgb_model.fit(X, y)\ny_pred = xgb_model.predict(X)\nmse=mean_squared_error(y, y_pred)\nmse","80c099c3":"from sklearn.tree import DecisionTreeClassifier\n\nclf = MultiOutputRegressor(DecisionTreeClassifier(random_state=0))\nclf.fit(X, y)\nmean_squared_error(y, clf.predict(X))","6092ab2c":"from sklearn.mixture import GaussianMixture\n\ngmm = MultiOutputRegressor(GaussianMixture(n_components=2))\ngmm.fit(X, y)\nmean_squared_error(y, gmm.predict(X))","84daa93f":"from sklearn.model_selection import KFold\n\ndef CVKFold(k, X, y, model):\n    np.random.seed(1)\n    #reproducibility\n    \n    highest_accuracy = float('inf')\n\n    kf = KFold(n_splits = k,shuffle =True)\n    #CV loop\n    \n    test_accuracies = []\n    \n    for train_index,test_index in kf.split(X):#generation of the sets\n    #generate the sets    \n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        multi_model = MultiOutputRegressor(model)\n        # model fitting\n        multi_model.fit(X_train,y_train)\n        y_test_pred = multi_model.predict(X_test)\n    \n        test_accuracy = mean_squared_error(y_test_pred, y_test)\n        test_accuracies.append(test_accuracy)\n        \n    print(multi_model.get_params()['estimator'])\n    print(\"The average accuracy is \" + str(sum(test_accuracies) \/ len(test_accuracies)))\n    print()","d6eb8e65":"models = [LogisticRegression(random_state=0), xgb.XGBClassifier(random_state=42), DecisionTreeClassifier(random_state=0), GaussianMixture(n_components=2)]\n\nfor model in models:\n    CVKFold(5, X, y, model)","9f1b888f":"from bayes_opt import BayesianOptimization\nfrom sklearn.model_selection import cross_val_score\n\ndef xgb_cv(eta, min_child_weight, max_depth, gamma, subsample, colsample_bytree, alpha, n_estimators, learning_rate):\n    val = np.mean(cross_val_score(MultiOutputRegressor(xgb.XGBClassifier(eta=float(eta), \n                                                   min_child_weight=float(min_child_weight),\n                                                   max_depth=int(max_depth),\n                                                   gamma=float(gamma),\n                                                   subsample=float(subsample),\n                                                   colsample_bytree=float(colsample_bytree),\n                                                   alpha=float(alpha),\n                                                   n_estimators=int(n_estimators),\n                                                   learning_rate=learning_rate,\n                                                   seed=42)),\n                         X, y, cv=5))\n    \n    return val","5952d5e4":"bo = BayesianOptimization(\n             xgb_cv,\n             {'eta': (0.01, 0.3),\n             'min_child_weight': (1, 25),\n             'max_depth': (3, 10),\n             'gamma': (0.0, 1.0),\n             'subsample': (0.5, 1),\n             'colsample_bytree': (0.5, 1),\n             'alpha': (0.0, 2.0),\n             'n_estimators': (10, 100),\n             'learning_rate': (0.0001, 0.1)})","9a014ea8":"bo.maximize()","e5df66c9":"bo.max","5969e158":"xgb_optimized = xgb.XGBClassifier(alpha=bo.max['params']['alpha'], colsample_bytree=bo.max['params']['colsample_bytree'], eta=bo.max['params']['eta'], \n                                  gamma=bo.max['params']['gamma'], max_depth=int(bo.max['params']['max_depth']), \n                                  min_child_weight=bo.max['params']['min_child_weight'], subsample=bo.max['params']['subsample'], \n                                  n_estimators=int(bo.max['params']['n_estimators']),\n                                  learning_rate=bo.max['params']['learning_rate'], random_state=42)\nCVKFold(5, X, y, xgb_optimized)","2575fde1":"future_games_pca = pca.transform(future_games.drop(columns=['Home', 'Away']))","d4b9f063":"xgb_optimized = MultiOutputRegressor(xgb_optimized)\nxgb_optimized.fit(X, y)\npredicted_results = xgb_optimized.predict(future_games_pca)","da2698c9":"predicted_results[:4]","34db594f":"def winner_judgment(fixtures, home, away, legs=False, home_prev=None, away_prev=None):\n    '''\n    input:\n    home: the scores of home team at the current fixture\n    away: the scores of away team at the current fixture\n    legs: flag if it is a two-leg competition\n    home_prev: the scores of home team in the previous battle if there exists one\n    away_prev: the scores of away team in the previous battle if there exists one\n    '''\n    if legs is not True:\n        if home > away:\n            return fixtures['Home']\n        elif home < away:\n            return fixtures['Away']\n        else:\n            return fixtures['Away'] if random.random() > 0.5 else fixtures['Home']\n    else:\n        if home + home_prev > away + away_prev:\n            return fixtures['Home']\n        elif home + home_prev < away + away_prev:\n            return fixtures['Away']\n        elif home_prev > away:\n            return fixtures['Home']\n        else:\n            return fixtures['Away'] if random.random() > 0.5 else fixtures['Home']","2395fec3":"leg_1 = None\nfor i in range(4):\n    leg_1 = pd.concat([leg_1, fixtures[(fixtures['Home']==future_games['Away'].iloc[i]) & (fixtures['Away']==future_games['Home'].iloc[i])]], ignore_index=True)","19be4d50":"leg_1 = leg_1[['Home', 'Away', 'Home_Score', 'Away_Score']]","25a3bd27":"winners = []\nfor i in range(4):\n    winners.append(winner_judgment(future_games[['Home', 'Away']].iloc[i], predicted_results[i][0], predicted_results[i][1], True, \n                                   int(leg_1['Away_Score'].iloc[i]), int(leg_1['Home_Score'].iloc[i])))","89d93374":"winners","f289ce7d":"# quarter finals\n\nquarterFinals = pd.DataFrame({'Home': [winners[1], 'Atletico Madrid', winners[3], 'Paris Saint-Germain'],\n                             'Away': [winners[0], 'RB Leipzig', winners[2], 'Atalanta']})\nquarterFinals = quarterFinals.merge(aggregate, left_on='Home', right_on='Squad')\nquarterFinals = quarterFinals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\nquarterFinals = quarterFinals.drop(columns=['Squad_Home', 'Squad_Away'])\nquarterFinals","51955bed":"quarterFinals_pca = pca.transform(quarterFinals.drop(columns=['Home', 'Away']))\nquarterFinalPrediction = xgb_optimized.predict(quarterFinals_pca)","a3fe9dba":"quarterFinalPrediction","718545cf":"semi_qualifiers = []\nfor i in range(4):\n    semi_qualifiers.append(winner_judgment(quarterFinals[['Home', 'Away']].iloc[i], quarterFinalPrediction[i][0], quarterFinalPrediction[i][1]))","f49663e3":"semi_qualifiers","814da555":"# semi-finals\n\nsemiFinals = pd.DataFrame({'Home': [semi_qualifiers[2], semi_qualifiers[3]],\n                             'Away': [semi_qualifiers[0], semi_qualifiers[1]]})\nsemiFinals = semiFinals.merge(aggregate, left_on='Home', right_on='Squad')\nsemiFinals = semiFinals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\nsemiFinals = semiFinals.drop(columns=['Squad_Home', 'Squad_Away'])\nsemiFinals","173cbbc7":"semiFinals_pca = pca.transform(semiFinals.drop(columns=['Home', 'Away']))\nsemiFinalsPrediction = xgb_optimized.predict(semiFinals_pca)\nsemiFinalsPrediction","14080818":"finalists = []\nfor i in range(2):\n    finalists.append(winner_judgment(semiFinals[['Home', 'Away']].iloc[i], semiFinalsPrediction[i][0], semiFinalsPrediction[i][1]))","0f03b660":"finalists","1951ad10":"# Final\n\nFinals = pd.DataFrame({'Home': [finalists[1]],\n                             'Away': [finalists[0]]})\nFinals = Finals.merge(aggregate, left_on='Home', right_on='Squad')\nFinals = Finals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\nFinals = Finals.drop(columns=['Squad_Home', 'Squad_Away'])\nFinals","8258d75e":"Finals_pca = pca.transform(Finals.drop(columns=['Home', 'Away']))\nFinalPrediction = xgb_optimized.predict(Finals_pca)","d0b7e3b4":"FinalPrediction","09d465da":"print('19\/20 UCL:')\nprint(winner_judgment(Finals[['Home', 'Away']].iloc[0], FinalPrediction[0][0], FinalPrediction[0][1]))","f0cf0847":"fixtures['Score'] = Score.reset_index()['Score']\n# fixtures = fixtures.dropna(subset=['Score'])","e7df0523":"fixture_info = fixtures[['Home', 'Away', 'Home_Score', 'Away_Score']]\nfixtures = fixtures.drop(columns=['Home', 'Away', 'Home_Score', 'Away_Score'])","40b9329b":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nfixtures['Score'] = le.fit_transform(fixtures['Score'].astype(str))","79efa69a":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(random_state=42)\nfixtures, Score_ = ros.fit_resample(fixtures.drop(columns=['Score']), fixtures['Score'])","3763def8":"fixtures['Score'] = le.inverse_transform(Score_)","e63493e2":"fixtures['Score'].value_counts().plot.barh()","415b1f36":"fixtures['Home_Score'] = 0\nfixtures['Away_Score'] = 0\nfor i in range(len(fixtures)):\n    x = str(fixtures['Score'].iloc[i]).split('\u2013')\n    fixtures['Home_Score'].iloc[i] = x[0]\n    fixtures['Away_Score'].iloc[i] = x[1]","e84e7bf8":"X = fixtures.drop(columns=['Score', 'Home_Score', 'Away_Score'])\ny = fixtures[['Home_Score', 'Away_Score']].astype(int)\n\nX = pca.fit_transform(X) ","1cf04568":"for model in models:\n    CVKFold(5, X, y, model)","2dcef724":"def xgb_cv(eta, min_child_weight, max_depth, gamma, subsample, colsample_bytree, alpha, n_estimators, learning_rate):\n    val = np.mean(cross_val_score(MultiOutputRegressor(xgb.XGBClassifier(eta=float(eta), \n                                                   min_child_weight=float(min_child_weight),\n                                                   max_depth=int(max_depth),\n                                                   gamma=float(gamma),\n                                                   subsample=float(subsample),\n                                                   colsample_bytree=float(colsample_bytree),\n                                                   alpha=float(alpha),\n                                                   n_estimators=int(n_estimators),\n                                                   learning_rate=learning_rate,\n                                                   seed=42)),\n                         X, y, cv=5))\n    \n    return val","a3a0aa9f":"overSampled_bo = BayesianOptimization(\n             xgb_cv,\n             {'eta': (0.01, 0.3),\n             'min_child_weight': (1, 25),\n             'max_depth': (3, 5),\n             'gamma': (0.0, 1.0),\n             'subsample': (0.5, 1),\n             'colsample_bytree': (0.5, 1),\n             'alpha': (0.0, 2.0),\n             'n_estimators': (90, 100),\n             'learning_rate': (0.0001, 0.1)})","217585d6":"overSampled_bo.maximize()","0897daa2":"overSampled_bo.max","f9198462":"overSampled_xgb_optimized = xgb.XGBClassifier(alpha=overSampled_bo.max['params']['alpha'], colsample_bytree=overSampled_bo.max['params']['colsample_bytree'], \n                                              eta=overSampled_bo.max['params']['eta'], gamma=overSampled_bo.max['params']['gamma'], \n                                              max_depth=int(overSampled_bo.max['params']['max_depth']), min_child_weight=overSampled_bo.max['params']['min_child_weight'], \n                                              subsample=overSampled_bo.max['params']['subsample'], n_estimators=int(overSampled_bo.max['params']['n_estimators']),\n                                              learning_rate=overSampled_bo.max['params']['learning_rate'], random_state=42)\nCVKFold(5, X, y, overSampled_xgb_optimized)","c886d961":"overSampled_xgb_optimized = MultiOutputRegressor(overSampled_xgb_optimized)\noverSampled_xgb_optimized.fit(X, y)\npredicted_results = overSampled_xgb_optimized.predict(future_games_pca)\npredicted_results[:4]","e0a78efc":"winners = []\nfor i in range(4):\n    winners.append(winner_judgment(future_games[['Home', 'Away']].iloc[i], predicted_results[i][0], predicted_results[i][1], True, \n                                   int(leg_1['Away_Score'].iloc[i]), int(leg_1['Home_Score'].iloc[i])))","2f594609":"winners","30e01fb6":"quarterFinals = pd.DataFrame({'Home': [winners[1], 'Atletico Madrid', winners[3], 'Paris Saint-Germain'],\n                             'Away': [winners[0], 'RB Leipzig', winners[2], 'Atalanta']})\nquarterFinals = quarterFinals.merge(aggregate, left_on='Home', right_on='Squad')\nquarterFinals = quarterFinals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\nquarterFinals = quarterFinals.drop(columns=['Squad_Home', 'Squad_Away'])\nquarterFinals","b3c2d58c":"quarterFinals_pca = pca.transform(quarterFinals.drop(columns=['Home', 'Away']))\nquarterFinalPrediction = overSampled_xgb_optimized.predict(quarterFinals_pca)","b820b75a":"quarterFinalPrediction","1fd12611":"semi_qualifiers = []\nfor i in range(4):\n    semi_qualifiers.append(winner_judgment(quarterFinals[['Home', 'Away']].iloc[i], quarterFinalPrediction[i][0], quarterFinalPrediction[i][1]))","9a8302f3":"semi_qualifiers","7e96b7d5":"semiFinals = pd.DataFrame({'Home': [semi_qualifiers[2], semi_qualifiers[3]],\n                             'Away': [semi_qualifiers[0], semi_qualifiers[1]]})\nsemiFinals = semiFinals.merge(aggregate, left_on='Home', right_on='Squad')\nsemiFinals = semiFinals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\nsemiFinals = semiFinals.drop(columns=['Squad_Home', 'Squad_Away'])\nsemiFinals","16ad0985":"semiFinals_pca = pca.transform(semiFinals.drop(columns=['Home', 'Away']))\nsemiFinalsPrediction = overSampled_xgb_optimized.predict(semiFinals_pca)\nsemiFinalsPrediction","0eaca6d4":"finalists = []\nfor i in range(2):\n    finalists.append(winner_judgment(semiFinals[['Home', 'Away']].iloc[i], semiFinalsPrediction[i][0], semiFinalsPrediction[i][1]))","44807310":"finalists","133a8a8e":"Finals = pd.DataFrame({'Home': [finalists[1]],\n                             'Away': [finalists[0]]})\nFinals = Finals.merge(aggregate, left_on='Home', right_on='Squad')\nFinals = Finals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\nFinals = Finals.drop(columns=['Squad_Home', 'Squad_Away'])\nFinals","347851c9":"Finals_pca = pca.transform(Finals.drop(columns=['Home', 'Away']))\nFinalPrediction = overSampled_xgb_optimized.predict(Finals_pca)","345efbce":"FinalPrediction","dbcdb70f":"print('19\/20 UCL:')\nprint(winner_judgment(Finals[['Home', 'Away']].iloc[0], FinalPrediction[0][0], FinalPrediction[0][1]))","60accdd3":"proba = {'Manchester City': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Bayern Munich': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Paris Saint-Germain': {'qtr': 500, 'semi': 0, 'final': 0, 'champion': 0},\n        'Real Madrid': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Juventus': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Lyon': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Barcelona': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Napoli': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Chelsea': {'qtr': 0, 'semi': 0, 'final': 0, 'champion': 0},\n        'Atalanta': {'qtr': 500, 'semi': 0, 'final': 0, 'champion': 0},\n        'RB Leipzig': {'qtr': 500, 'semi': 0, 'final': 0, 'champion': 0},\n        'Atletico Madrid': {'qtr': 500, 'semi': 0, 'final': 0, 'champion': 0}}","301dd687":"def simulate():\n    overSampled_bo = BayesianOptimization(\n             xgb_cv,\n             {'eta': (0.01, 0.3),\n             'min_child_weight': (1, 25),\n             'max_depth': (3, 5),\n             'gamma': (0.0, 1.0),\n             'subsample': (0.5, 1),\n             'colsample_bytree': (0.5, 1),\n             'alpha': (0.0, 2.0),\n             'n_estimators': (90, 100),\n             'learning_rate': (0.0001, 0.1)})\n    overSampled_bo.maximize()\n    overSampled_xgb_optimized = xgb.XGBClassifier(alpha=overSampled_bo.max['params']['alpha'], colsample_bytree=overSampled_bo.max['params']['colsample_bytree'], \n                                                  eta=overSampled_bo.max['params']['eta'], gamma=overSampled_bo.max['params']['gamma'], \n                                                  max_depth=int(overSampled_bo.max['params']['max_depth']), min_child_weight=overSampled_bo.max['params']['min_child_weight'], \n                                                  subsample=overSampled_bo.max['params']['subsample'], n_estimators=int(overSampled_bo.max['params']['n_estimators']),\n                                                  learning_rate=overSampled_bo.max['params']['learning_rate'], random_state=42)\n    overSampled_xgb_optimized = MultiOutputRegressor(overSampled_xgb_optimized)\n    overSampled_xgb_optimized.fit(X, y)\n    # round of 16\n    predicted_results = overSampled_xgb_optimized.predict(future_games_pca)\n    winners = []\n    for i in range(4):\n        winner = winner_judgment(future_games[['Home', 'Away']].iloc[i], predicted_results[i][0], predicted_results[i][1], True, \n                                       int(leg_1['Away_Score'].iloc[i]), int(leg_1['Home_Score'].iloc[i]))\n        winners.append(winner)\n        proba[winner]['qtr'] += 1\n\n    # quarter finals\n    quarterFinals = pd.DataFrame({'Home': [winners[1], 'Atletico Madrid', winners[3], 'Paris Saint-Germain'],\n                                 'Away': [winners[0], 'RB Leipzig', winners[2], 'Atalanta']})\n    quarterFinals = quarterFinals.merge(aggregate, left_on='Home', right_on='Squad')\n    quarterFinals = quarterFinals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\n    quarterFinals = quarterFinals.drop(columns=['Squad_Home', 'Squad_Away'])\n    quarterFinals_pca = pca.transform(quarterFinals.drop(columns=['Home', 'Away']))\n    quarterFinalPrediction = overSampled_xgb_optimized.predict(quarterFinals_pca)\n    semi_qualifiers = []\n    for i in range(4):\n        semi_quafier = winner_judgment(quarterFinals[['Home', 'Away']].iloc[i], quarterFinalPrediction[i][0], quarterFinalPrediction[i][1])\n        semi_qualifiers.append(semi_quafier)\n        proba[semi_quafier]['semi'] += 1\n\n    # semi finals\n    semiFinals = pd.DataFrame({'Home': [semi_qualifiers[2], semi_qualifiers[3]],\n                                 'Away': [semi_qualifiers[0], semi_qualifiers[1]]})\n    semiFinals = semiFinals.merge(aggregate, left_on='Home', right_on='Squad')\n    semiFinals = semiFinals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\n    semiFinals = semiFinals.drop(columns=['Squad_Home', 'Squad_Away'])\n    semiFinals_pca = pca.transform(semiFinals.drop(columns=['Home', 'Away']))\n    semiFinalsPrediction = overSampled_xgb_optimized.predict(semiFinals_pca)\n    finalists = []\n    for i in range(2):\n        finalist = winner_judgment(semiFinals[['Home', 'Away']].iloc[i], semiFinalsPrediction[i][0], semiFinalsPrediction[i][1])\n        finalists.append(finalist)\n        proba[finalist]['final'] += 1\n\n    # final\n    Finals = pd.DataFrame({'Home': [finalists[1]],\n                                 'Away': [finalists[0]]})\n    Finals = Finals.merge(aggregate, left_on='Home', right_on='Squad')\n    Finals = Finals.merge(aggregate, left_on='Away', right_on='Squad', suffixes=('_Home', '_Away'))\n    Finals = Finals.drop(columns=['Squad_Home', 'Squad_Away'])\n    Finals_pca = pca.transform(Finals.drop(columns=['Home', 'Away']))\n    FinalPrediction = overSampled_xgb_optimized.predict(Finals_pca)\n    champion = winner_judgment(Finals[['Home', 'Away']].iloc[0], FinalPrediction[0][0], FinalPrediction[0][1])\n    proba[champion]['champion'] += 1","4296645a":"for i in range(500):\n    simulate()","c758111c":"teams = [_ for _ in proba] * 4\nstages =  np.reshape([[_] * 12 for _ in proba['Lyon']], (1, 48)).tolist()[0]","cc4f7c13":"for team in proba.items():\n  for stage in team[1].items():\n    proba[team[0]][stage[0]] = proba[team[0]][stage[0]] \/ 500\n    \npossibilities = pd.DataFrame({'Team': teams,\n                              'Stage': stages,\n                              'Possibility': [proba[teams[i]][stages[i]] for i in range(48)]})\npossibilities = possibilities.pivot(\"Team\", \"Stage\", \"Possibility\")","3d2e8ae0":"possibilities = possibilities.rename(columns={'champion': 'Champion', 'final': 'Final', 'qtr': 'Quarter Final', 'semi': 'Semi Final'})\npossibilities = possibilities.sort_values(by=['Champion', 'Final', 'Quarter Final', 'Semi Final'], ascending=False)\npossibilities = possibilities[['Quarter Final', 'Semi Final', 'Final', 'Champion']]","b5fa0997":"import seaborn as sns\n\nax = sns.heatmap(possibilities, annot=True, cmap=\"YlGnBu\")","b89f9dc3":"# Parameter Tuning","9960b899":"# Model comparison","d2d32f47":"# Oversampling","ab783312":"# Probability\n---\nThe params tuned by Bayesian Optimization are not stable, running it more than once could generate a value closer to a stable one","6d504e21":"# Preprocessing","e7a63b36":"# Dimensionality Reduction"}}