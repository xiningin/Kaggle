{"cell_type":{"18086728":"code","05ae63af":"code","3b087d24":"code","e325500e":"code","f7191c1c":"code","00991222":"code","824fce59":"code","07629a61":"code","61517e13":"code","40a8bc68":"code","ebf51a49":"code","ae1665a3":"code","0b70e860":"code","30172284":"code","d9d26c9c":"code","198dba40":"code","941ba181":"code","d608ba00":"code","ae799f62":"code","a9218aae":"code","e08d5d7e":"code","453316d2":"code","ac32db71":"code","b3cdcdfc":"code","93e8767c":"code","56bcfd2a":"code","fbb7577b":"code","61dd1a91":"code","6f4f3f3a":"code","8b71e7f9":"code","8101a62b":"code","cbbe8c61":"code","4f07d21b":"code","69441d53":"code","d341f396":"code","370ff64c":"code","819c5c8e":"code","0b57b2af":"code","0ee1b344":"code","e7269dbb":"code","316f8db3":"markdown","80d14c54":"markdown","e77e9931":"markdown","96d9c8a8":"markdown","abe3142f":"markdown","5df4ad39":"markdown","703647b4":"markdown","77f4a591":"markdown","ccfb30bb":"markdown","4c0ff7f4":"markdown","d5679058":"markdown","24b279bc":"markdown","7e472892":"markdown","3f632d09":"markdown","1e9d6d22":"markdown","743ed597":"markdown","b0e65357":"markdown","19898ba4":"markdown","0d0151e9":"markdown","6f083a63":"markdown","ea8d137a":"markdown","38b75ed0":"markdown","d84b763b":"markdown","d7432999":"markdown","984e0a79":"markdown","e4115201":"markdown"},"source":{"18086728":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# regression models\nfrom sklearn.preprocessing import StandardScaler # for feature scaling\nfrom sklearn.pipeline import Pipeline # for using pipeline\nfrom sklearn.linear_model import LinearRegression # for linear regression\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import Ridge # for ridge regression\nfrom sklearn.linear_model import Lasso # for lasso regression\nfrom sklearn.svm import SVR # for support vector regression\nfrom sklearn.tree import DecisionTreeRegressor # for decisiton tree regression\nfrom sklearn.ensemble import RandomForestRegressor # for random forest regression\n# hyptertuning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint\n# extra\nimport pandas_profiling\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\nfrom IPython.core.display import display, HTML\nsns.set_style('darkgrid')\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","05ae63af":"insurance_dataset = pd.read_csv(\"\/kaggle\/input\/insurance\/insurance.csv\")","3b087d24":"insurance_dataset.head()","e325500e":"pandas_profiling.ProfileReport(insurance_dataset)","f7191c1c":"insurance_dataset.info()","00991222":"plt.figure(figsize=(10,10))\nsns.distplot(insurance_dataset.age)\nplt.show()","824fce59":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.barplot(x=insurance_dataset.sex.value_counts().index , y= insurance_dataset.sex.value_counts().values)\nplt.subplot(1,2,2)\nsns.boxenplot(x=\"sex\",y=\"charges\",data=insurance_dataset)\nplt.show()","07629a61":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.distplot(insurance_dataset.bmi)\nplt.subplot(1,2,2)\nsns.boxenplot(x=\"children\",y=\"charges\",data=insurance_dataset)\nplt.show()","61517e13":"plt.figure(figsize=(10,10))\nsns.distplot(insurance_dataset.children)\nplt.show()","40a8bc68":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.barplot(x=insurance_dataset.smoker.value_counts().index , y= insurance_dataset.smoker.value_counts().values)\nplt.subplot(1,2,2)\nsns.boxenplot(x=\"smoker\",y=\"charges\",data=insurance_dataset)\nplt.show()","ebf51a49":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.barplot(x=insurance_dataset.region.value_counts().index , y= insurance_dataset.region.value_counts().values)\nplt.subplot(1,2,2)\nsns.boxenplot(x=\"region\",y=\"charges\",data=insurance_dataset)\nplt.show()","ae1665a3":"plt.figure(figsize=(25,10))\nsns.boxenplot(x=\"age\" , y=\"charges\", data = insurance_dataset)\nplt.show()","0b70e860":"plt.figure(figsize=(25,10))\nsns.barplot(x=\"age\" , y=\"charges\", data = insurance_dataset)\nplt.show()","30172284":"plt.figure(figsize=(10,10))\nsns.scatterplot(x=\"charges\",y=\"age\",data=insurance_dataset,hue=\"smoker\")\nplt.show()","d9d26c9c":"insurance_dataset.isnull().sum()","198dba40":"insurance_dataset = pd.get_dummies(insurance_dataset)\ninsurance_dataset.head()","941ba181":"X =insurance_dataset.drop(\"charges\",axis =1).values\ny =insurance_dataset[\"charges\"].values.reshape(-1,1)","d608ba00":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 40)","ae799f62":"print(\"Shape of X_train: \",X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \",y_train.shape)\nprint(\"Shape of y_test\",y_test.shape)","a9218aae":"plt.figure(figsize=(10,10))\nsns.pairplot(insurance_dataset,vars=['age','bmi','children','charges'],hue='smoker_yes')\nplt.plot()","e08d5d7e":"Linear_regression = LinearRegression()\nLinear_regression.fit(X_train,y_train)","453316d2":"# K-fold Cross validation \n# cv = number of folds of the dataset\ncv_result = cross_val_score(estimator=Linear_regression,X=X,y=y,cv=10)\nprint(\"CV(K-fold) result(mean of 10) :\",cv_result.mean())\n\n# Pridicting on Train set result\n# calculate R2 score\ny_pridicted_train = Linear_regression.predict(X_train)\nR2_score_linearregression_train = r2_score(y_train,y_pridicted_train)\nprint(\"R2 Score : \",R2_score_linearregression_train)\n\n# Pridicting on Test set result\ny_pridicted_test = Linear_regression.predict(X_test)\nR2_score_linearregression_test = r2_score(y_test,y_pridicted_test)\nprint(\"R2 Score : \",R2_score_linearregression_test)\n\n# Root mean square error\nfrom math import sqrt\nrmse = sqrt(mean_squared_error(y_test, y_pridicted_test))\nprint(\"RMSE : \",rmse)","ac32db71":"# convert to 1-D Array\n#y_train.ravel()","b3cdcdfc":"Linear_model_graph = pd.DataFrame({\"y_train\":y_train.ravel(),\"y_pridicted_train\":y_pridicted_train.ravel()})\nplt.figure(figsize=(20,5))\nsns.lineplot(x=Linear_model_graph.index[:40],y=Linear_model_graph.y_train[:40])\nsns.lineplot(x=Linear_model_graph.index[:40],y=Linear_model_graph.y_pridicted_train[:40])\nplt.xlabel(\"value\")\nplt.ylabel(\"index\")\nplt.title(\"original and pridicted value\")\nplt.show()","93e8767c":"poly_model_graph = pd.DataFrame({\"y_train\":y_test.ravel(),\"y_pridicted_train\":y_pridicted_test.ravel()})\nplt.figure(figsize=(20,5))\nsns.scatterplot(x=poly_model_graph.index,y=poly_model_graph.y_train,marker='+')\nsns.scatterplot(x=poly_model_graph.index,y=poly_model_graph.y_pridicted_train,marker='o')\nplt.xlabel(\"value\")\nplt.ylabel(\"index\")\nplt.title(\"original and pridicted value\")\nplt.show()","56bcfd2a":"from sklearn.preprocessing import PolynomialFeatures # for adding polynomial features\npoly_regression = PolynomialFeatures(degree=2)\nX_train_poly = poly_regression.fit_transform(X_train)\npoly_regression.fit(X_train_poly,y_train)\n\nregressor_poly2 = LinearRegression()\nregressor_poly2.fit(X_train_poly,y_train)","fbb7577b":"# predicting cross validation \ncv_regressot_poly2 = cross_val_score(estimator=regressor_poly2,X=poly_regression.fit_transform(X),y=y,cv=10)\n\n# R2 score train\ny_priediction_poly2_train  = regressor_poly2.predict(X_train_poly)\nr2_score_y_train = r2_score(y_train,y_priediction_poly2_train)\nprint(\"r2_score_y_train : \", r2_score_y_train )\n\n# R2 score test\ny_priediction_poly2_test  = regressor_poly2.predict(poly_regression.fit_transform(X_test))\nr2_score_y_test = r2_score(y_test,y_priediction_poly2_test)\nprint(\"r2_score_y_test : \",r2_score_y_test)\n\n# root mean square error\nfrom math import sqrt \nrmse_test = sqrt(mean_squared_error(y_priediction_poly2_test,y_test))\nprint(\"rmse_test :\",rmse_test)","61dd1a91":"poly_model_graph = pd.DataFrame({\"y_train\":y_test.ravel(),\"y_pridicted_train\":y_priediction_poly2_test.ravel()})\nplt.figure(figsize=(20,5))\nsns.lineplot(x=poly_model_graph.index[:40],y=poly_model_graph.y_train[:40])\nsns.lineplot(x=poly_model_graph.index[:40],y=poly_model_graph.y_pridicted_train[:40])\nplt.xlabel(\"value\")\nplt.ylabel(\"index\")\nplt.title(\"original and pridicted value\")\nplt.show()","6f4f3f3a":"poly_model_graph = pd.DataFrame({\"y_train\":y_test.ravel(),\"y_pridicted_train\":y_priediction_poly2_test.ravel()})\nplt.figure(figsize=(20,5))\nsns.scatterplot(x=poly_model_graph.index,y=poly_model_graph.y_train,marker='+')\nsns.scatterplot(x=poly_model_graph.index,y=poly_model_graph.y_pridicted_train,marker='o')\nplt.xlabel(\"value\")\nplt.ylabel(\"index\")\nplt.title(\"original and pridicted value\")\nplt.show()","8b71e7f9":"def ridge_regression(X_data,y_data,X_test,y_test, alpha):\n    \n    #fit ridge regression \n    ridge_reg = Ridge(alpha=alpha,normalize=True)\n    ridge_reg.fit(X_data,y_data)\n    \n    y_pred_train = ridge_reg.predict(X_data)\n    y_pred_test = ridge_reg.predict(X_test)\n    \n#     #plot graph\n    \n#     poly_model_graph = pd.DataFrame({\"y_data\":y_data.ravel(),\"y_pridicted_train\":y_pred_train.ravel()})\n#     plt.figure(figsize=(20,5))\n#     sns.lineplot(x=poly_model_graph.index[:80],y=poly_model_graph.y_data[:80])\n#     sns.lineplot(x=poly_model_graph.index[:80],y=poly_model_graph.y_pridicted_train[:80])\n#     plt.xlabel(\"value\")\n#     plt.ylabel(\"index\")\n#     plt.title(\"original and pridicted value in train dataset at alpha = {}\".format(alpha))\n#     plt.show()\n   \n#     poly_model_graph = pd.DataFrame({\"y_data\":y_test.ravel(),\"y_pridicted_train\":y_pred_test.ravel()})\n#     plt.figure(figsize=(20,5))\n#     sns.lineplot(x=poly_model_graph.index[:80],y=poly_model_graph.y_data[:80])\n#     sns.lineplot(x=poly_model_graph.index[:80],y=poly_model_graph.y_pridicted_train[:80])\n#     plt.xlabel(\"value\")\n#     plt.ylabel(\"index\")\n#     plt.title(\"original and pridicted value in train dataset at alpha = {}\".format(alpha))\n#     plt.show()\n    \n    #check errors\n    print(\"\\n\\nfor alpha = {}\".format(alpha))\n    \n    # R2 score train\n    r2_score_y_train = r2_score(y_train,y_pred_train)\n    print(\"r2_score_y_train : \", r2_score_y_train )\n\n    # R2 score test\n    r2_score_y_test = r2_score(y_test,y_pred_test)\n    print(\"r2_score_y_test : \",r2_score_y_test)\n\n    # root mean square error\n    from math import sqrt \n    rmse_test = sqrt(mean_squared_error(y_pred_test,y_test))\n    print(\"rmse_test :\",rmse_test)\n    rmse_test = sqrt(mean_squared_error(y_pred_train,y_data))\n    print(\"rmse_train :\",rmse_test)\n    \n    return [r2_score_y_train,r2_score_y_test,rmse_test] , ridge_reg.coef_","8101a62b":"r2_train_score_r = []\nr2_test_score_r = []\nrms_score_r = []\ncofficient_r = []\nfor Alpha in [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]:\n    temp , coff = ridge_regression(X_train,y_train,X_test,y_test,Alpha)\n    r2_train_score_r.append(temp[0])\n    r2_test_score_r.append(temp[1])\n    rms_score_r.append(temp[2])\n    cofficient_r.append(coff)","cbbe8c61":"graph = pd.DataFrame({\"Alpha\":[\"1e-15\", \"1e-10\", \"1e-8\", \"1e-4\",\"1e-3\",\"1e-2\",\" 1\",\" 5\",\" 10\",\" 20\"],\"R2 score for train\":r2_train_score_r,\n                      \"R2 score for test\":r2_test_score_r,\"Rmse\":rms_score_r})\nplt.figure(figsize=(20,10))\nplt.subplot(2,1,1)\nsns.lineplot(x=graph.Alpha,y=graph[\"R2 score for train\"],label=\"R2 score for train\")\nsns.lineplot(x=graph.Alpha,y=graph[\"R2 score for test\"],label=\"R2 score for test\")\nplt.subplot(2,1,2)\nsns.lineplot(x=graph.Alpha,y=graph[\"Rmse\"],label=\"RMSE\")\nplt.show()","4f07d21b":"#disply cofficient\ncofficient_dataframe = pd.DataFrame()","69441d53":"def lasso_regression(X_train,y_train,X_test,y_test,alpha):\n    lasso_reg = Lasso(alpha=alpha,normalize=True)\n    lasso_reg.fit(X_train,y_train)\n    \n    y_pred_train = lasso_reg.predict(X_train)\n    \n    y_pred_test = lasso_reg.predict(X_test)\n    \n    #check errors\n    print(\"\\n\\nfor alpha = {}\".format(alpha))\n    \n    # R2 score train\n    r2_score_y_train = r2_score(y_train,y_pred_train)\n    print(\"r2_score_y_train : \", r2_score_y_train )\n\n    # R2 score test\n    r2_score_y_test = r2_score(y_test,y_pred_test)\n    print(\"r2_score_y_test : \",r2_score_y_test)\n\n    # root mean square error\n    from math import sqrt \n    rmse_test = sqrt(mean_squared_error(y_pred_test,y_test))\n    print(\"rmse_test :\",rmse_test)\n    rmse_test = sqrt(mean_squared_error(y_pred_train,y_train))\n    print(\"rmse_train :\",rmse_test)\n    return [r2_score_y_train,r2_score_y_test,rmse_test] , lasso_reg.coef_","d341f396":"r2_train_score_l = []\nr2_test_score_l = []\nrms_score_l = []\ncofficient_l = []\nfor Alpha in [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]:\n    temp , coff = lasso_regression(X_train,y_train,X_test,y_test,Alpha)\n    r2_train_score_l.append(temp[0])\n    r2_test_score_l.append(temp[1])\n    rms_score_l.append(temp[2])\n    cofficient_l.append(coff)","370ff64c":"graph_1 = pd.DataFrame({\"Alpha\":[\"1e-15\", \"1e-10\", \"1e-8\", \"1e-4\",\"1e-3\",\"1e-2\",\" 1\",\" 5\",\" 10\",\" 20\"],\"R2 score for train\":r2_train_score_l,\n                      \"R2 score for test\":r2_test_score_l,\"Rmse\":rms_score_l})\nplt.figure(figsize=(20,10))\nplt.subplot(2,1,1)\nsns.lineplot(x=graph_1.Alpha,y=graph_1[\"R2 score for train\"],label=\"R2 score for train\")\nsns.lineplot(x=graph_1.Alpha,y=graph_1[\"R2 score for test\"],label=\"R2 score for test\")\nplt.subplot(2,1,2)\nsns.lineplot(x=graph_1.Alpha,y=graph_1[\"Rmse\"],label=\"RMSE\")\nplt.show()","819c5c8e":"plt.figure(figsize=(10,5))\nsns.lineplot(x=graph_1.Alpha,y=r2_train_score_l,label=\"r2_train_score_lasso\")\nsns.lineplot(x=graph_1.Alpha,y=r2_train_score_r,label=\"r2_train_score_ridge\")\nplt.show()","0b57b2af":"plt.figure(figsize=(10,5))\nsns.lineplot(x=graph_1.Alpha,y=r2_test_score_l,label=\"r2_test_score_lasso\")\nsns.lineplot(x=graph_1.Alpha,y=r2_test_score_r,label=\"r2_test_score_ridge\")\nplt.show()","0ee1b344":"plt.figure(figsize=(10,5))\nsns.lineplot(x=graph_1.Alpha,y=rms_score_l,label=\"Rmse lesso\")\nsns.lineplot(x=graph_1.Alpha,y=rms_score_r,label=\"Rmse ridge\")\nplt.show()","e7269dbb":"Elastic_regression = ElasticNet()\nElastic_regression.fit(X_train,y_train)\n\ny_predicted_train = Elastic_regression.predict(X_train)\n\ny_predicted_test = Elastic_regression.predict(X_test)\n\n# R2 score train\nr2_score_y_train = r2_score(y_train,y_predicted_train)\nprint(\"r2_score_y_train : \", r2_score_y_train )\n\n# R2 score test\nr2_score_y_test = r2_score(y_test,y_predicted_test)\nprint(\"r2_score_y_test : \",r2_score_y_test)\n\n# root mean square error\nfrom math import sqrt \nrmse_test = sqrt(mean_squared_error(y_predicted_test,y_test))\nprint(\"rmse_test :\",rmse_test)\nrmse_test = sqrt(mean_squared_error(y_predicted_train,y_train))\nprint(\"rmse_train :\",rmse_test)","316f8db3":"# MODELS","80d14c54":"elastic regression used when data is highly correlated","e77e9931":"* number of smoker is less \n* smokers are have to get high insurance compare to ","96d9c8a8":"# ELASTIC REGRESSION<a id='5'><\/a>","abe3142f":"## r2 train score","5df4ad39":"## IMPORT DATASET","703647b4":"* bmi column in Dataset is normalized data","77f4a591":"* Those are smoker they are getting less chares compare to non-smoker","ccfb30bb":"[Pandas Profiling (overview pandas DataFrame)](#6)","4c0ff7f4":"##  [Linear Regression](#1)\n##  [Polynomial Regression](#2)\n##  [Ridge Regression](#3)\n##  [Lasso Regression](#4)\n##  [Elastic Regression](#5)","d5679058":"* All ages are between 20 to 63\n* age of 20 are higher compare to other","24b279bc":"* **age** : age of person \n* **sex** : gender of person\n* **bmi** : Body mass index (BMI) is a value derived from the mass (weight) and height of a person.\n* **children** : number of child covered by helth insurance\n* **smoker** : person smokes or not\n* **region** : perdon's residential area\n* **charges** : charges can be given by insurance","7e472892":"## r2 train score","3f632d09":"### IMPORT LIBERARYS","1e9d6d22":"* children dataset is natural ","743ed597":"* we can see that at high ages charges are also increse\n* at age between 24-34 male charge is higher then female\n* also 40-56 male charge higher ","b0e65357":"## GRAPH PRIDICTEING AND ORIGINAL","19898ba4":"# COMPARISION BETWEEN LASSO AND RIDGE<a id='4'><\/a>","0d0151e9":"## POLYNOMIAL REGRESSION<a id='2'><\/a>","6f083a63":"## OVERVIEW OF DATA","ea8d137a":"## LINEAR REGRESSION<a id='1'><\/a>","38b75ed0":"* all regin are almost same distributed","d84b763b":"## Pandas Profiling<a id='6'><\/a>","d7432999":"* there is not any null value in Dataset","984e0a79":"# RIDGE REGRESSION<a id='3'><\/a>","e4115201":"* number of male and female in dataset are almost equal"}}