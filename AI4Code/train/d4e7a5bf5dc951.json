{"cell_type":{"055a15c3":"code","1dec8463":"code","06be31dc":"code","5c8bd43d":"code","af032c0b":"code","f59de676":"code","e0e874f9":"code","3d40c3cf":"code","49ac8639":"code","e900208b":"code","6557056e":"code","7c1bd574":"code","795729d2":"code","6a926ed3":"code","ff3c1eaa":"code","6035b367":"code","1d69d7c1":"code","caf8ffad":"code","060494d6":"code","0e93a990":"code","fc2bf1c3":"code","a7087c59":"code","3680c8ce":"code","8b106a96":"code","29190c99":"code","246cefd8":"code","9231e2de":"code","6397477e":"code","bb07637a":"code","6a6c4fc7":"code","e7540aae":"code","eec0d559":"code","410fb7a2":"code","92b864f4":"code","734716b1":"code","18e70560":"code","7c946107":"code","c09c5411":"code","9a0d182a":"code","b0225275":"code","d6b258f0":"code","1af71de1":"code","ce121b8e":"code","7c71cb4b":"code","8b57f728":"code","997f8907":"code","ecfe0ede":"code","15dd9fcf":"code","9c8208a6":"code","742f4a0d":"code","0e9b7d17":"code","6f008bff":"code","b5436f25":"code","8afa1848":"code","92036fb3":"markdown","259d08c5":"markdown","d2ddf8c1":"markdown","bf3e3a72":"markdown","ab370d8d":"markdown","27c0da70":"markdown","62e64274":"markdown","d270da07":"markdown","cceb01fc":"markdown","e3d55b9c":"markdown","58b190da":"markdown"},"source":{"055a15c3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport riiideducation\n# import dask.dataframe as dd\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score","1dec8463":"train = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n                   usecols=[1, 2, 3, 4, 5, 7, 8, 9],\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'task_container_id': 'int16',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )","06be31dc":"#removing True or 1 for content_type_id\n\ntrain = train[train.content_type_id == False]\n\n#arrange by timestamp\n\ntrain = train.sort_values(['timestamp'], ascending=True).reset_index(drop = True)","5c8bd43d":"#getting final results ready for later, so we can clear memory\nresults_c_final = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c_final.columns = [\"answered_correctly_content\"]\n\nresults_u_final = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nresults_u_final.columns = ['answered_correctly_user', 'sum', 'count']","af032c0b":"results_t_final = train[['task_container_id','answered_correctly']].groupby(['task_container_id']).agg(['mean', 'sum'])\nresults_t_final.columns = ['answered_correctly_task', 'sum_task']","f59de676":"#saving value to fillna\ntime_mean = train.prior_question_elapsed_time.mean()\n#print(time_mean)","e0e874f9":"train.loc[(train.timestamp == 0)].answered_correctly.mean()","3d40c3cf":"train.loc[(train.timestamp != 0)].answered_correctly.mean()","49ac8639":"train.loc[(train.timestamp < 1000000) & (train.timestamp > 0)].answered_correctly.mean()","e900208b":"train.prior_question_had_explanation.value_counts()","6557056e":"train.answered_correctly.mean()","7c1bd574":"train.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)","795729d2":"validation = pd.DataFrame()","6a926ed3":"for i in range(4):\n    last_records = train.drop_duplicates('user_id', keep = 'last')\n    train = train[~train.index.isin(last_records.index)]\n    validation = validation.append(last_records)","ff3c1eaa":"len(train)","6035b367":"len(validation)","1d69d7c1":"validation.answered_correctly.mean()","caf8ffad":"train.answered_correctly.mean()","060494d6":"X = pd.DataFrame()","0e93a990":"for i in range(15):\n    last_records = train.drop_duplicates('user_id', keep = 'last')\n    train = train[~train.index.isin(last_records.index)]\n    X = X.append(last_records)","fc2bf1c3":"len(X)","a7087c59":"len(train)","3680c8ce":"X.answered_correctly.mean()","8b106a96":"train.answered_correctly.mean()","29190c99":"results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content\"]\n\nresults_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nresults_u.columns = [\"answered_correctly_user\", 'sum', 'count']","246cefd8":"results_t = train[['task_container_id','answered_correctly']].groupby(['task_container_id']).agg(['mean', 'sum'])\nresults_t.columns = ['answered_correctly_task', 'sum_task']","9231e2de":"#clearing memory\n#del(train)\n","6397477e":"X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c, on=['content_id'], how=\"left\")","bb07637a":"X = pd.merge(X, results_t, on=['task_container_id'], how='left')","6a6c4fc7":"validation = pd.merge(validation, results_u, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_c, on=['content_id'], how=\"left\")","e7540aae":"validation = pd.merge(validation, results_t, on=['task_container_id'], how='left')","eec0d559":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\n\nX.prior_question_had_explanation.fillna(False, inplace = True)\nvalidation.prior_question_had_explanation.fillna(False, inplace = True)\n\nvalidation[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(validation[\"prior_question_had_explanation\"])\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])","410fb7a2":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","92b864f4":"X = X[['answered_correctly_user', 'answered_correctly_content', 'sum', 'count', \n       'answered_correctly_task', 'sum_task', 'prior_question_elapsed_time', \n       'prior_question_had_explanation_enc']]\nX_val = X_val[['answered_correctly_user', 'answered_correctly_content', 'sum', 'count',\n               'answered_correctly_task', 'sum_task', 'prior_question_elapsed_time', \n               'prior_question_had_explanation_enc']]","734716b1":"#X['answered_correctly_user'].mean()","18e70560":"#X['answered_correctly_content'].mean()","7c946107":"#X['answered_correctly_content'].mode()","c09c5411":"#X['answered_correctly_task'].mean()","9a0d182a":"#X.isnull().sum()","b0225275":"#X['sum'].mode()","d6b258f0":"#X['count'].mode()","1af71de1":"X['answered_correctly_user'].fillna(0.5,  inplace=True)\nX['answered_correctly_content'].fillna(0.6,  inplace=True)\nX['prior_question_elapsed_time'].fillna(time_mean, inplace = True)\nX['prior_question_had_explanation_enc'].fillna(0, inplace = True)","ce121b8e":"X_val['answered_correctly_user'].fillna(0.5,  inplace=True)\nX_val['answered_correctly_content'].fillna(0.6,  inplace=True)\nX_val['prior_question_elapsed_time'].fillna(time_mean, inplace = True)\nX_val['prior_question_had_explanation_enc'].fillna(0, inplace = True)","7c71cb4b":"X['sum'].fillna(4.0, inplace = True)\nX['count'].fillna(0, inplace = True)","8b57f728":"X_val['count'].fillna(0, inplace = True)\nX_val['sum'].fillna(4.0, inplace = True)","997f8907":"import lightgbm as lgb\n\nparams = {\n    'objective': 'binary',\n    'max_bin': 1000,\n    'learning_rate': 0.01,\n    'num_leaves': 80\n}\n\nlgb_train = lgb.Dataset(X, y)\nlgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)","ecfe0ede":"model = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=25,\n    num_boost_round=20000,\n    early_stopping_rounds=50\n)","15dd9fcf":"#y_pred = model.predict(X_val)\n#y_true = np.array(y_val)\n#roc_auc_score(y_true, y_pred)","9c8208a6":"#y_predt = model.predict(X)\n#y_truet = np.array(y)\n#roc_auc_score(y_truet, y_predt)","742f4a0d":"import matplotlib.pyplot as plt\nimport seaborn as sns","0e9b7d17":"#displaying the most important features\nlgb.plot_importance(model)\nplt.show()","6f008bff":"env = riiideducation.make_env()","b5436f25":"iter_test = env.iter_test()","8afa1848":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, results_u_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_c_final, on=['content_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_t_final, on=['task_container_id'],  how=\"left\")\n    test_df['answered_correctly_user'].fillna(0.5,  inplace=True)\n    test_df['answered_correctly_content'].fillna(0.6,  inplace=True)\n    test_df['sum'].fillna(4.0, inplace=True)\n    test_df['count'].fillna(0, inplace=True)\n    test_df['prior_question_elapsed_time'].fillna(time_mean, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'answered_correctly_content', 'sum', 'count', \n                                                            'answered_correctly_task', 'sum_task', 'prior_question_elapsed_time', \n                                                            'prior_question_had_explanation_enc']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","92036fb3":"## Creating Validation Set (Most Recent Answers by User) ##","259d08c5":"## Aggregating and Shaping Data ##","d2ddf8c1":"We will have to look out for signs of over-fitting.","bf3e3a72":"## Making Predictions for New Data ##","ab370d8d":"## Examining Feature Importance ##","27c0da70":"## Data Exploration ##","62e64274":"## Modeling ##","d270da07":"## Reading Data and Importing Libraries ##","cceb01fc":"Are early questions fundamentally different? The best answer I could get was: not really","e3d55b9c":"Does it make sense to use last questions as validation? Why is the rate of correct answers so low?","58b190da":"## Extracting Training Data ##"}}