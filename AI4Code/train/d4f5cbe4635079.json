{"cell_type":{"5067334d":"code","1c806c88":"code","0b6d0f82":"code","8ba34b79":"code","a70809f2":"code","eeb2f1f9":"code","d3157ee5":"code","97adab6c":"code","e36d0fa5":"code","673c6fc3":"code","1f55700f":"code","7fb027a6":"code","3fd9e6d5":"code","b5e5ac59":"code","1550ea7a":"code","77b99396":"code","f06452ee":"code","ef8c0d63":"code","cb116f71":"code","61691a0f":"markdown","f989fc42":"markdown","09436930":"markdown","a403da33":"markdown","6c56c824":"markdown","987a5b6f":"markdown","e34db702":"markdown","bb177db6":"markdown","7eaa7296":"markdown","1b019a89":"markdown","c763bdc1":"markdown"},"source":{"5067334d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.options.display.max_columns = None","1c806c88":"data = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/train.csv\")","0b6d0f82":"data.head()","8ba34b79":"x = data.iloc[:,1:51]\ny = data.iloc[:,-1]\n\nx_test_data = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/test.csv\")\nx_test_new = x_test_data.iloc[:,1:51]\n","a70809f2":"x.head()","eeb2f1f9":"x.describe()","d3157ee5":"x.isna().sum()","97adab6c":"pd.crosstab(x.iloc[:,0],y)","e36d0fa5":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx = sc.fit_transform(x)\nx_test_new = sc.fit_transform(x_test_new)","673c6fc3":"from sklearn.decomposition import PCA\npca = PCA().fit(x)\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 51, step=1)\ny1 = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, y1, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 60, step=1)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()","1f55700f":"from sklearn.decomposition import PCA\npca = PCA(n_components = 47)\nx = pca.fit_transform(x)\nx_test_new = pca.transform(x_test_new)","7fb027a6":"from xgboost import XGBClassifier\nclassifier = XGBClassifier(n_estimators = 10000,predictor = 'gpu_predictor',tree_method = 'gpu_hist',learning_rate = 0.01,max_depth=29,max_leaves = 31,eval_metric = 'mlogloss',verbosity = 3)","3fd9e6d5":"classifier.fit(x,y)","b5e5ac59":"y_pred_proba = classifier.predict_proba(x_test_new)","1550ea7a":"output = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/sample_submission.csv\")","77b99396":"output_df = pd.DataFrame(y_pred_proba, columns=['class_1', 'class_2', 'class_3', 'class_4'])","f06452ee":"output_df = pd.concat([x_test_data.id,output_df],axis = 1)","ef8c0d63":"output_df.head()","cb116f71":"output_df.to_csv('OutputXGB.csv', index=False)","61691a0f":"**Applying Principal Component Analysis(PCA)**\n\n\nThis is being done to reduce the dimensions to required dimensions, number decided above.","f989fc42":"**Applying XGBoost Classifier to predict the output probabilities**","09436930":"**Doing some preliminary analysis to see the following observations-**\n\n* We have 49 feature columns\n* No missing data present in dataset (No NA, nulls)\n* Max values are positive though dataset does contain negative values also\n* Data type for all columns is homogeneous - Integer\n* Large number of zeros present for all the classes","a403da33":"**Plotting a graph of Cumulative variance vs No. of components**\n\nThis is being done to use only the number of relevant component features which affect the outcome.\nThreshold being selected as 95%","6c56c824":"**Importing Relevant Libraries for Exploration, Plotting and use of Models through our analysis!**","987a5b6f":"**Using Standard Scalar to Scale the dataset on a similar range**","e34db702":"**Splitting the dataset into independent and dependent variables**","bb177db6":"**Open for advice and suggestions on how to improve my score and to learn new techniques.**","7eaa7296":"**Predicting Probabilities of output for the test data**","1b019a89":"**Importing the dataset**","c763bdc1":"**Running some initial analysis!\nSeeing given data has 51 columns-**\n\n* 1 column forID\n* 49 columns for features\n* 1 column Classification into 4 classes\n\n**Can conclude that this is a Supervised learning, multi class classification problem**"}}