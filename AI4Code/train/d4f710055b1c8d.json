{"cell_type":{"6d789abf":"code","72d1315c":"code","fe2600c1":"code","1ba18f82":"code","d1b75c29":"code","78cc3ef1":"code","86a257bd":"code","b53643ba":"code","dbbe8e40":"code","3025328f":"code","18ac9ee7":"code","a683e4be":"code","991decef":"code","c0565e4a":"code","a121c62a":"code","f8aeea5d":"code","10762804":"code","24489dd9":"code","0227ebe4":"code","0b4648b1":"code","6c8152a2":"code","cd2ffb2b":"code","478782c1":"code","bc555f6f":"code","230a0f3f":"code","dc4da5c1":"code","1c6596ae":"code","18ecc4f8":"code","ae847301":"code","3ecdac45":"code","578f4290":"code","8d48d335":"code","b56238f2":"code","ef462b68":"code","6bc6835d":"code","d8013fe2":"code","8ab5c1ff":"code","ad06d42c":"code","6a2df5a6":"code","8ba0edbb":"code","677a0a8c":"code","a24cdf08":"code","9eefc41e":"code","7e254443":"markdown","d288e90b":"markdown","984bbb5f":"markdown","73ab842a":"markdown","ffa64eef":"markdown","7289d8c8":"markdown","fae43db9":"markdown"},"source":{"6d789abf":"!pip install feedparser\nimport feedparser","72d1315c":"!pip install vaderSentiment\nimport vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer","fe2600c1":"phrases = [\n\"I would feel the same in your situation, but we will sort this out\",\n\"I know how frustrating it can be \u2013 let\u2019s see how I can help you\",\n\"I completely understand how frustrating it is\",\n\"I appreciate how difficult it is\",\n\"We will work to resolve the problem. You just enjoy your (birthday\/holidays\/Christmas break, etc.), and I will be in touch shortly.\",\n\"We are keen to resolve this as much as you are\",\n\"If I were in your position, I would feel exactly the same\",\n\"I appreciate you bringing this to our attention\u2026\",\n\"I will contact you as soon as we have had an update.\",\n\"Definitely, you are making perfect sense.\",\n\"I can assure you that this will absolutely happen.\",\n\"We will help you get this issue resolved.\",\n\"Apologies for the wait, I appreciate your patience.\",\n\"Don\u2019t worry, I can see why you did that.\",\n\"Yes, that would certainly frustrate me too.\",\n\"What I would do in this situation i\"\n\"How do you feel about fear\",\n\"I know others who have been in your situation and what we did to successfully help them\",\n\"Just so we know what we\u2019re aiming for, what would be the best-case scenario for you.\",\n\"Absolutely, I can certainly fix that for you.\",\n\"I will quickly put this into action for you and then everything will be back to normal.\",\n\"Just so I can clarify and help you.\",\n\"I\u2019m afraid that we cannot offer you X, but what I can do for you\",\n\"I am going to take care of this for you.\",\n\"That does sound frustrating, let\u2019s see what I can do to help.\",    \n\"I love the team and how they played last night \ud83d\udc98\" ,\n\"What a fine day I am having today :-) :-)\",\n\"I am laughing like crazy lol\",\n\"He was not very good at the play\",\n\"He is kinda bored\",\n]\n\nreadSentiment = SentimentIntensityAnalyzer()","1ba18f82":"for txt in phrases:\n  print(readSentiment.polarity_scores(txt))","d1b75c29":"def getSentiment(phrase):\n  s = readSentiment.polarity_scores(phrase)\n  if s['compound'] <= -0.05:\n    sentiment = 0\n  elif s['compound'] >= 0.05:\n    sentiment = 1\n  else:\n    sentiment = 2\n  return sentiment, s","78cc3ef1":"t1 = getSentiment(\"He is kinda bored\")\nt1","86a257bd":"t1 = getSentiment(\"The book was good\")\nt1","b53643ba":"t1 = getSentiment(\"Taco's Tuesday\")\nt1","dbbe8e40":"sentiments = ['Negative', 'Positive', 'Neutral']\nfor txt in phrases:\n  print(sentiments[getSentiment(txt)[0]], ' - ', txt)","3025328f":"sources = [\n          \"http:\/\/rss.cnn.com\/rss\/edition_travel.rss\",\n          \"http:\/\/rss.cnn.com\/rss\/edition_world.rss\",\n          \"http:\/\/rss.cnn.com\/rss\/money_news_international.rss\",\n          \"http:\/\/rss.cnn.com\/rss\/edition_technology.rss\",\n          \"http:\/\/rss.cnn.com\/rss\/edition_entertainment.rss\"\n          'https:\/\/www.espn.com\/espn\/rss\/nfl\/news',\n          'https:\/\/www.espn.com\/espn\/rss\/nba\/news',\n          'https:\/\/www.espn.com\/espn\/rss\/rpm\/news',\n          'https:\/\/www.espn.com\/espn\/rss\/soccer\/news',\n          'https:\/\/www.espn.com\/espn\/rss\/mlb\/news',\n          'https:\/\/www.espn.com\/espn\/rss\/nhl\/news',\n          'https:\/\/www.espn.com\/espn\/rss\/poker\/master',\n           'http:\/\/rss.cnn.com\/rss\/edition_sport.rss',\n           'http:\/\/rss.cnn.com\/rss\/edition_football.rss',\n           'http:\/\/rss.cnn.com\/rss\/cnn_latest.rss',\n           'http:\/\/rss.cnn.com\/rss\/edition_space.rss',\n           'http:\/\/rss.cnn.com\/rss\/edition.rss',\n           'http:\/\/rss.cnn.com\/rss\/edition_africa.rss',\n           'http:\/\/rss.cnn.com\/rss\/edition_americas.rss'\n\n          \n]\nfeeds = []\nfor s in sources:\n  feed = feedparser.parse(s)\n  feeds.append(feed)","18ac9ee7":"titles = []\nsummaries = []\nfor feed in feeds:\n  for content in feed.entries:\n    titles.append(content.title)\n    try:\n      summaries.append(content.summary)\n    except:\n      summaries.append(content.title)","a683e4be":"for txt in titles:\n  print(sentiments[getSentiment(txt)[0]], ' - ', txt)","991decef":"import spacy\nfrom  spacy.lang.en.stop_words import STOP_WORDS\nnlp = spacy.load('en_core_web_sm')\nimport re\nimport string","c0565e4a":"def cleaningText(original, show=False):\n  txt = original\n  txt = txt.lower() # lowercase\n  txt = re.sub('@','',txt) # remove @ \n  txt = re.sub('\\[.*\\]','',txt) # remove contents between brackets\n  txt = re.sub('<.*?>+','',txt) # remove contents between less and more signs\n  txt = re.sub('https?:\/\/\\S+|www\\.\\S+', '', txt) # remove URLs\n  txt = re.sub(re.escape(string.punctuation), '', txt) # remove punctuation\n  txt = re.sub(r'[^a-zA-Z ]+', '', txt) # remove numbers\n  txt = re.sub('\\n', '', txt) # remove line break\n  txt = str(txt).strip()\n  if show:\n    print('ORIGINAL: ', original)\n    print('   TEXT CLEANNED: ', txt)\n  return txt","a121c62a":"titlesClean = [cleaningText(title) for title in titles]","f8aeea5d":"for txt in titlesClean:\n  print(sentiments[getSentiment(txt)[0]], ' - ', txt)","10762804":"import pandas as pd","24489dd9":"sent = []\nfor txt in titles:\n  sent.append(getSentiment(txt)[0])\n\ndfT = pd.DataFrame()\ndfT['title'] = titles\ndfT['titleClean'] = titlesClean\ndfT['sentimentTitle'] = sent","0227ebe4":"dfT.head()","0b4648b1":"dfTitle = dfT[['sentimentTitle','title']].groupby('sentimentTitle').count()\ndfTitle","6c8152a2":"import plotly.express as px","cd2ffb2b":"dfTitle.values.reshape(-1)","478782c1":"colors=['orange', 'Darkblue', 'Darkred']\npx.pie(names=sentiments, values=dfTitle.values.reshape(-1), title='Sentiment Analysis - Titles', \n       color_discrete_sequence=colors)","bc555f6f":"summariesClean = [cleaningText(summary) for summary in summaries]","230a0f3f":"sent = []\nfor txt in summaries:\n  sent.append(getSentiment(txt)[0])\n\ndfS = pd.DataFrame()\ndfS['summary'] = summaries\ndfS['summaryClean'] = summariesClean\ndfS['sentimentSummary'] = sent","dc4da5c1":"dfSummary = dfS[['sentimentSummary','summary']].groupby('sentimentSummary').count()\ndfSummary","1c6596ae":"colors=['Darkblue', 'orange', 'Darkred']\npx.pie(names=sentiments, values=dfSummary.values.reshape(-1), title='Sentiment Analysis - Summaries', \n       color_discrete_sequence=colors)","18ecc4f8":"def tokenizeStr(original):\n  txt2 = nlp(original) # creating a word's list\n  txt2 = [token.lemma_ for token in txt2 if not nlp.vocab[token.text].is_stop]\n  punct = string.punctuation\n  stopwords = list(STOP_WORDS)\n  ws = string.whitespace\n  txt2 = [word for word in txt2 if word not in stopwords and word not in punct if len(word)>2]\n  return txt2","ae847301":"# Example tokenizing sentence and \ntokenizeStr('Home sweet Home'), tokenizeStr(\"Choose a study category to start\")","3ecdac45":"[a*b for b in range(1,3) for a in range(4,6)]","578f4290":"wordsT = [word for i in range(0, len(dfT)-1) for word in tokenizeStr(dfT.iloc[i].titleClean) if str(word).strip() != '']\nwordsTn = pd.value_counts(wordsT)","8d48d335":"wordsS = [word for i in range(0, len(dfS)-1) for word in tokenizeStr(dfS.iloc[i].summaryClean) if str(word).strip() != '']\nwordsSn = pd.value_counts(wordsS)","b56238f2":"wordlist = pd.value_counts(wordsT+wordsS)","ef462b68":"topW = pd.DataFrame(data={'tag': wordlist.index, 'count':wordlist.values})","6bc6835d":"topW[:10]","d8013fe2":"px.bar(topW[:10], y='tag', x='count', orientation='h', \n       title='Top 10 words', color='tag')","8ab5c1ff":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)","ad06d42c":"wordcloud = WordCloud(width = 800, height = 600, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(' '.join(dfT.title)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('words from titles')\n  \nplt.show() ","6a2df5a6":"wordcloud = WordCloud(width = 800, height = 600, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(' '.join(dfS['summaryClean'])) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('words from summaries')\n  \nplt.show() ","8ba0edbb":"wordcloud = WordCloud(width = 800, height = 600, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(' '.join(dfT[dfT.sentimentTitle == 1].title)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('words from titles - sentiment Positive')\n  \nplt.show() ","677a0a8c":"wordcloud = WordCloud(width = 800, height = 600, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(' '.join(dfT[dfT.sentimentTitle == 0].title)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('words from titles - sentiment negative')\n  \nplt.show()","a24cdf08":"wordcloud = WordCloud(width = 800, height = 600, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(' '.join(dfS[dfS.sentimentSummary == 1].summaryClean)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('words from summaries - sentiment positive')\n  \nplt.show()","9eefc41e":"wordcloud = WordCloud(width = 800, height = 600, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(' '.join(dfS[dfS.sentimentSummary == 0].summaryClean)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('words from summaries - sentiment negative')\n  \nplt.show()","7e254443":"**Analysing Words**","d288e90b":"**Conclusion 01**\n\nThe news title brought a more neutral feeling than the summary. Depending on a newsroom, this can be a strategy.","984bbb5f":"# **Sentiment analysis**","73ab842a":"**Analysing Summaries**","ffa64eef":"**Only Positive in titles and summaries**","7289d8c8":"# **Online Texts**\n\nLet's get some news headlines (titles) on CNN and ESPN by RSS feeds","fae43db9":"**Analysing TITLES**"}}