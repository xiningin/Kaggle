{"cell_type":{"738f9ae2":"code","f2dafaee":"code","8a2cb880":"code","a83af177":"code","ddbc9656":"code","d6c7806f":"code","6ad59b16":"code","8c686d25":"code","dd3f5173":"code","d7c21cba":"code","72bc3c2d":"code","880e9983":"code","d74149e4":"code","ab82ab03":"code","fc0e5ef3":"code","91a9ef2c":"code","68e98172":"code","c63e6445":"code","bcdce9ff":"code","7168fd4f":"code","c4104df6":"code","8dc7b7fc":"code","9a611e94":"code","c051db78":"code","71999e0e":"code","c7e4701f":"code","9ecc2782":"code","39df8d85":"code","47f32723":"code","17e58942":"code","0108bbbe":"code","1db6c187":"code","0e0ddb19":"code","dc1a70a6":"code","5457ea63":"code","143c1a83":"code","543ed4cf":"code","371acbd0":"code","a24ceb5b":"code","e6bca518":"code","f5f1e1bf":"code","403890bd":"code","4b95f0ce":"code","fec0fe40":"code","951b9299":"code","7acb0d57":"code","4d841019":"markdown","76e76e86":"markdown","1b59ccf4":"markdown","64bbc83b":"markdown","451ae859":"markdown","aa92a84d":"markdown","5ddb0623":"markdown","64498491":"markdown","fd745604":"markdown","f2c2dd63":"markdown","b1c43a03":"markdown","deb65df4":"markdown","d06529a8":"markdown","b21c95de":"markdown","2e2429ad":"markdown","344b7876":"markdown","394ce069":"markdown","8b77e7b5":"markdown","be6a080a":"markdown","5fa7b29b":"markdown","db93405f":"markdown","151fc40b":"markdown","3310c20c":"markdown"},"source":{"738f9ae2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas_profiling\nimport time\nimport csv\nfrom datetime import datetime\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Display more data on screen\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', 100)\n\nimport folium\nfrom folium.plugins import HeatMap\n\n\n%matplotlib inline","f2dafaee":"##Procedure to reduce memory consuption of dataframes. Borrowed from https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n","8a2cb880":"df_listings = pd.read_csv('..\/input\/rio-de-janeiro-brazil-airbnb-data\/listings.csv')\ndf_calendar = pd.read_csv('..\/input\/rio-de-janeiro-brazil-airbnb-data\/calendar.csv')\ndf_reviews = pd.read_csv('..\/input\/rio-de-janeiro-brazil-airbnb-data\/reviews.csv')\n#df_neighbourhoods = pd.read_csv('..\/input\/rio-de-janeiro-brazil-airbnb-data\/neighbourhoods.csv')\n\ndf_listings = reduce_mem_usage(df_listings)\ndf_calendar = reduce_mem_usage(df_calendar)\ndf_reviews = reduce_mem_usage(df_reviews)","a83af177":"print(len(df_listings), len(df_calendar), len(df_reviews))","ddbc9656":"df_listings.head(2)","d6c7806f":"## Check null values percentages\ndf_listings.isna().mean().sort_values(ascending=True)","6ad59b16":"## remove useless columns, mainly URL ones, but keeping information whereas \n## property has that information or not.\ndf_listings = df_listings.drop(['scrape_id', 'listing_url', 'last_scraped', \n                                'host_acceptance_rate', 'license', \n                                'neighbourhood_group_cleansed', \n                                'jurisdiction_names'], axis=1)\nurl_columns = [c for c in df_listings.columns if '_url' in c]\nfor c in url_columns:\n    df_listings['has_' + c] = df_listings[c].isnull()\n\ndf_listings = df_listings.drop(url_columns, axis=1)","8c686d25":"def convert_price_to_float(col):\n    return col.str.replace('$', '').str.replace(',', '', regex = 'true').astype(float)\n\ndf_listings.price = convert_price_to_float(df_listings.price)\ndf_listings.monthly_price = convert_price_to_float(df_listings.monthly_price)\ndf_listings.weekly_price = convert_price_to_float(df_listings.weekly_price)\ndf_listings.cleaning_fee   = convert_price_to_float(df_listings.cleaning_fee)\ndf_listings.security_deposit   = convert_price_to_float(df_listings.security_deposit)\ndf_listings.extra_people   = convert_price_to_float(df_listings.extra_people)","dd3f5173":"df_listings.property_type.value_counts()","d7c21cba":"df_listings.room_type.hist()","72bc3c2d":"## There's a property with 200 bathrooms and another with 69 beds. Excluding \n## data for visualization\n\ndf_listings[(df_listings.bathrooms<10)&(df_listings.beds<20)][['bathrooms','bedrooms'\n                ,'beds', 'number_of_reviews', 'reviews_per_month', 'availability_30',\n                'availability_60','availability_90','availability_365']].hist(\n    figsize=(10, 10), bins=20);","880e9983":"df_listings.minimum_nights.describe()","d74149e4":"import seaborn as sns\nselected_cols = ['price', 'security_deposit', 'cleaning_fee', 'weekly_price', 'monthly_price']\n\nfig, axes = plt.subplots(1, len(selected_cols))\nfor i, col in enumerate(selected_cols):\n    ax = sns.boxplot(y=df_listings[col], ax=axes.flatten()[i], showfliers = False)\n    #ax.set_ylim(df_listings[col].min(), df_listings[col].max())\n    ax.set_ylabel(col + ' \/ Unit')\nfig.tight_layout()\nplt.show()\n","ab82ab03":"df_listings.groupby('neighbourhood_cleansed')['price'].describe().sort_values('50%', ascending=False).head(100)","fc0e5ef3":"## Show top expensive properties\ndf_listings.sort_values('price', ascending=False).head(10)","91a9ef2c":"#Rio de Janeiro coordinates https:\/\/www.latlong.net\/place\/rio-de-janeiro-brazil-27580.html\nrio_map = folium.Map([-22.9032, -43.1929], zoom_start=8) \nHeatMap(df_listings[['latitude','longitude']].dropna(), \n        radius=10, gradient={0.2:'green',0.4:'purple',0.6:'orange',1.0:'red'}).add_to(rio_map)\n\n\n## Commented because browser wasn't showing markers\n#df_listings.sample(frac=0.1).apply(lambda row:folium.Marker(location=[row[\"latitude\"], row[\"longitude\"]], \n#                                         popup=row['name']).add_to(rio_map), axis=1)\n\ndisplay(rio_map)","68e98172":"df_listings_clean = df_listings.groupby(\"neighbourhood_cleansed\").filter(lambda x: len(x) >= 20)\n","c63e6445":"selected_numerical_features = ['host_response_time', 'host_response_rate', \n                               'host_verifications', 'bathrooms',\n                               'bedrooms', 'beds', 'number_of_reviews', \n                               'review_scores_rating', 'reviews_per_month' ]\nselected_categorical_features = ['host_is_superhost', 'host_identity_verified', \n                                 'neighbourhood_cleansed', \n                                 'property_type', 'room_type', 'bed_type', \n                                 'instant_bookable', 'cancellation_policy', \n                                 'has_picture_url',  'has_thumbnail_url', \n                                 'has_host_thumbnail_url']\n","bcdce9ff":"# Code from https:\/\/seaborn.pydata.org\/examples\/many_pairwise_correlations.html\ncorr = df_listings_clean[selected_numerical_features + ['price']].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(8, 6))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, center=0, vmin=-1, vmax=1, annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","7168fd4f":"#This library allows analysis of categorical features correlation\n!pip install dython","c4104df6":"from dython.nominal import associations\nassociations(df_listings_clean[selected_categorical_features + ['price']], figsize=(12,12));","8dc7b7fc":"fig = plt.gcf()\nfig.set_size_inches( 16, 30)\n\n\nsns.boxplot(y = 'neighbourhood_cleansed', x='price', data=df_listings_clean, orient='h', \n            showfliers = False, width=1);","9a611e94":"fig = plt.gcf()\nfig.set_size_inches( 16, 30)\n\nsns.boxplot(y = 'neighbourhood_cleansed', x='reviews_per_month', \n            data=df_listings_clean, orient='h', \n            showfliers = False, width=1);","c051db78":"df_listings_clean.reviews_per_month.describe()","71999e0e":"df_listings_clean['price_level'] = pd.cut(df_listings_clean.price, \n                                          bins=[0,100,300,500,1000,999999],\n                                          labels=['Low','Mid','High','Very High','Overpriced'])","c7e4701f":"fig = plt.gcf()\nfig.set_size_inches( 8, 6)\n\nsns.boxplot(y = 'price_level', x='reviews_per_month', data=df_listings_clean, orient='h',\n            showfliers = False, width=1);","9ecc2782":"fig = plt.gcf()\nfig.set_size_inches( 8, 6)\n\nsns.boxplot(y = 'price_level', x='review_scores_rating', data=df_listings_clean, orient='h', \n            showfliers = False, width=1);","39df8d85":"df_calendar.price = convert_price_to_float(df_calendar.price)\ndf_calendar.adjusted_price = convert_price_to_float(df_calendar.adjusted_price)\n#df_calendar.date = df_calendar.date.apply(lambda x : datetime.strptime(x , '%Y-%m-%d'))\ndf_calendar.date = pd.to_datetime(df_calendar.date, format='%Y-%m-%d')","47f32723":"df_calendar.head()","17e58942":"import matplotlib.dates as mdates\nmyFmt = mdates.DateFormatter('%m\/%y')\n\n\nfig, axes = plt.subplots(5,5, sharex=True, sharey=False, figsize=(20,15))\n\nfor i, ax in enumerate(axes.flatten()):\n    sample_id = np.random.choice(df_listings.id.unique(),1)[0]\n    df_plot = df_calendar[df_calendar.listing_id == sample_id]\n    ax.plot(df_plot['date'], df_plot['adjusted_price'])\n    ax.xaxis.set_major_formatter(myFmt)\nplt.show()","0108bbbe":"df_plot = df_calendar[['date', 'adjusted_price']].groupby(by='date', as_index=False).mean()\nplt.figure(figsize=(8, 6))\nplt.title('Average price over time for all properties in Rio de Janeiro')\nplt.plot(df_plot['date'], df_plot['adjusted_price'])\n","1db6c187":"## Load a previously stored data instead of scrap again\nexternal_data_loaded=False\ntry:\n    df_rio_neighbourhood_apartment_avg_prices = pd.read_csv(\n        '..\/input\/d\/vabatista\/airbnb-rio-de-janeiro\/rio_neighbourhood_appartment_avg_prices.csv')\n    external_data_loaded=True\nexcept:\n    print('File didnt exists yet')","0e0ddb19":"# This library scraps one of the most important web sites of real state in Brazil, Zap Imoveis (https:\/\/www.zapimoveis.com.br\/)\n!pip install zapimoveis_scraper","dc1a70a6":"import zapimoveis_scraper as zap\nimport unidecode\n\nif not external_data_loaded:\n    neighborhood_apartment_avg_prices = {}\n    neighborhood_list = df_listings.neighbourhood_cleansed.unique()\n\n    for neighborhood in neighborhood_list:\n        print(\"Querying Zap Imoveis for\", neighborhood)\n\n        neighborhood_apartment_avg_prices[neighborhood] = 0\n        ## calculate the average only with the first page of search engine (20 records at most)\n        counter = 0\n        ## this is the way zap im\u00f3veis passes neighbourhood names as parameter\n        unaccented_string = unidecode.unidecode(neighborhood).replace(' ','-').lower()\n        try:\n            for offer in zap.search(localization=\"rj+rio-de-janeiro++\" + unaccented_string, acao='venda', \n                                    tipo='apartamentos', num_pages=1):\n                try:\n                    if len(offer.total_area_m2)>0 and int(offer.total_area_m2) > 0 and \\\n                            len(offer.price)>0:\n                        neighborhood_apartment_avg_prices[neighborhood] = \\\n                                neighborhood_apartment_avg_prices[neighborhood] + \\\n                                float(offer.price) \/ int(offer.total_area_m2)\n                        counter = counter + 1\n                except:\n                    #print(offer.price, offer.total_area_m2)\n                    continue\n            neighborhood_apartment_avg_prices[neighborhood] = neighborhood_apartment_avg_prices[neighborhood] \/ counter\n            ## rest a while to not be blocked by Zap Imoveis\n            time.sleep(5)         \n        except Exception as err:\n            ## some neighbourhood names has abreviations on zap imoveis. For instance: Santa Teresa is Sta Teresa. \n            print(\"Couldn't find neighborhood with this name.\", neighborhood, err)\n            \n\n    with open('.\/rio_neighbourhood_appartment_avg_prices.csv', 'w') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow([\"neighborhood\", \"avg_price_per_sqfeet\"])\n        for key, value in neighborhood_apartment_avg_prices.items():\n            writer.writerow([key, value])\n    df_rio_neighbourhood_apartment_avg_prices = pd.read_csv('.\/rio_neighbourhood_appartment_avg_prices.csv')","5457ea63":"df_rio_neighbourhood_apartment_avg_prices.sort_values('avg_price_per_sqfeet', ascending=False).head(5)","143c1a83":"df_rio_neighbourhood_apartment_avg_prices = df_rio_neighbourhood_apartment_avg_prices[\n    df_rio_neighbourhood_apartment_avg_prices.avg_price_per_sqfeet>0]","543ed4cf":"df_listings_model = df_listings\n\ndf_listings_model['price_level'] = pd.cut(df_listings_model.price, \n                                          bins=[0,100,300,500,1000,999999], \n                                          labels=['Low','Mid','High','Very High','Overpriced'])\ndf_listings_model = df_listings_model[((df_listings_model.property_type == 'Apartment')&\n                                       (df_listings_model.neighbourhood_cleansed.isin(\n                                           df_rio_neighbourhood_apartment_avg_prices.neighborhood.unique()))&\n                                       (df_listings_model.price_level!='Overpriced'))]\ndf_listings_model = df_listings_model.groupby(\"neighbourhood_cleansed\").filter(lambda x: len(x) >= 20)","371acbd0":"df_listings_model.price.fillna(0, inplace=True)\ndf_listings_model.reviews_per_month.fillna(0, inplace=True)\ndf_listings_model['property_performance'] = df_listings_model.price * 7 * df_listings_model.reviews_per_month","a24ceb5b":"df_listings_model.bathrooms.fillna(1, inplace=True)\ndf_listings_model.bedrooms.fillna(1, inplace=True)\ndf_listings_model['estimated_size'] = df_listings_model.bathrooms * 3.5 + df_listings_model.bathrooms * 10 + 4 + 15","e6bca518":"df_listings_model = df_listings_model[['id','price', 'reviews_per_month', 'estimated_size', 'property_performance', 'price_level', 'neighbourhood_cleansed']]\ndf_listings_model = df_listings_model.merge(df_rio_neighbourhood_apartment_avg_prices, how='left', left_on='neighbourhood_cleansed', right_on='neighborhood')\n\ndf_listings_model['cost'] = df_listings_model.estimated_size * df_listings_model.avg_price_per_sqfeet\ndf_listings_model.loc[df_listings_model.price==0, 'price'] = 1 #avoid division by 0\ndf_listings_model['number_of_bookings_to_pay'] = df_listings_model.cost \/ df_listings_model.price","f5f1e1bf":"df_listings_model.head(10)","403890bd":"df_listings_model['price_performance'] = df_listings_model['property_performance'] \/ df_listings_model['price']","4b95f0ce":"fig = plt.gcf()\nfig.set_size_inches( 16, 30)\n\nsns.boxplot(y = 'neighbourhood_cleansed', x='price_performance', \n            data=df_listings_model, orient='h', showfliers = False, width=1);","fec0fe40":"fig = plt.gcf()\nfig.set_size_inches( 16, 30)\n\nsns.boxplot(y = 'neighbourhood_cleansed', x='number_of_bookings_to_pay', \n            data=df_listings_model, orient='h', showfliers = False, width=1);","951b9299":"fig = plt.gcf()\nfig.set_size_inches( 16, 30)\n\nsns.boxplot(y = 'neighbourhood_cleansed', x='property_performance', \n            data=df_listings_model, orient='h', showfliers = False, width=1);","7acb0d57":"df_listings_model[df_listings_model.neighborhood=='Ipanema'].head(20)","4d841019":"# Is it a good deal to buy an apartment in Rio and rent it using Airbnb platform?\n\nThis jupyter notebook uses data from <a href=\"http:\/\/insideairbnb.com\/get-the-data.html\">Inside Airbnb<\/a> collected from 2019 to 2020.\n\nI created a hypothetical situation where I want to buy an apartment in Rio de Janeiro (my home city) to make it available for rent on Airbnb and I want to answer the following questions:\n\n* What are the best neighborhoods to invest in a rental property on Airbnb?\n* What are the most and least desired features by tenants?\n* Which comments are most associated with the best ratings and the ones associated with the worst, so I can take care of this to provide a good experience to guests?","76e76e86":"### Assumptions\n\nHere are my assumptions:\n\n* reviews per month are a proxy for number of bookings and I'll multiply it by one week (7 days) times price as the performance of each property.\n* availability are more a concern of the hosts about their properties than a market issue, so I won't deal with it.\n* for simplification, I'll assume the mean price \/ squared feet I collected from Zap Imoveis is a reasonable measure for apartments in each location, but I know it's imprecise.\n","1b59ccf4":"### Price Boxplot by neighborhood","64bbc83b":"# 2. Analysis of features's relation to price and booking\n\nAt this point I'm interested in analyze how features influence the property price for rental. \nI'll filter neighborhoods with less than 20 properties, because most of my studies are focused on choosing a neighborhoods to buy an apartment and having few informantion gives more noise than information.","451ae859":"<img align=\"center\" src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/9\/96\/PanoramaRio.jpg\/1920px-PanoramaRio.jpg\" \/>","aa92a84d":"Now I'll merge the data with Zap imoveis and calculate an estimate cost of each property and also a total number of days of bookings necessary to pay for that.","5ddb0623":"### Analyze Calendar data","64498491":"### Performance \/ Price Index\n\nNow I'll create a concept of Performance over price index with the previous concepts","fd745604":"### Map with properties","f2c2dd63":"I'll drop few data from my analysis:\n* neighborhood I couldn't got prices from Zap Imoveis Site\n* listings that aren't apartment\n* Neighborhood with few properties ","b1c43a03":"# 3. Summary of findings on properties's data\n\n* 'name', 'summary', 'space', 'description', 'neighborhood_overview', 'notes', 'transit', 'access', 'interaction', 'house_rules' are all descritive features of the property. Name and Description are only ones with low missing rates (~ 2%) followed by summary (~ 6.1%). Others have more than 40% of missing values. Data have both Portuguese and English information.\n\n* The most expensive properties are for olimpics purposes and are clearly overpriced even been large houses or apartments. They are candidates to be excluded from analysis.\n\n* Jo\u00e1, Itanhang\u00e1, Vila Militar e S\u00e3o Conrado are neighboardhoods which presents wider ranges in prices.\n\n* There's a concentration of no available or available all the time in properties. Others properties between these situation are probably used by owners and rented only when they travel. \n\n* Several neightboardhoods have very few listings. They are also candidates to be excluded from further analysis\n\n* There's no single feature that has strong correlation alone with prices.\n\n* Majority of properties are apartments, my focus in this study. Also, I can say that at least 50% of data has no more than 3 bedrooms, 3 bathrooms and 4 beds.\n\n* Number of reviews by month suggests that hosts rents theirs properties around once every 2 months usually. Since average minimum number of days is 4.7, is reasonable to presume that they rent their property at least one week every 2 months at least. Properties with lower prices are booked more often.\n\n* Looking at some sample of data, hosts don't have a single price strategy. Some fixed price over time, others vary all the time and others just rise prices on important dates such as Carnival or New Year's eve. But averanging all properties, it's clear that over the weekends the prices rises.\n\n* The price of the property seems to have little effect on reviews. ","deb65df4":"* Listings contains the properties and summary information about rental\n* Calendar contains information about availability of each property along time\n* Reviews contains detailed information of reviews for each property","d06529a8":"### Average Price over time for all properties","b21c95de":"# 4. Obtaining (external) data of property real state offers","2e2429ad":"### Measure of size\n\nNow I need somehow to measure the size of each property. The feature squared_feet from data is useless since it's not filled, but I can use these three below\n<pre>\nfeature            % of nulls\nbathrooms           0.001523\nbedrooms            0.001285\nbeds                0.001285\n<\/pre>\n\nThis site (https:\/\/www.homify.com.br\/livros_de_ideias\/5994421\/tamanho-ideal-de-quarto-como-definir-na-hora-de-construir) suggests that a bedroom has in average 10 squared feets. A bathroom has 3-4 (https:\/\/www.uol.com.br\/universa\/noticias\/redacao\/2012\/11\/26\/banheiros-de-29-m-a-1245-m-veja-como-deixa-los-funcionais-na-moda-e-ampliar-a-sensacao-de-espaco.htm). I would assume that every apartment has also a kitchen (4 sq2) and living room (15sq2).","344b7876":"### Plot histograms of some categorical features","394ce069":"## TODO: Analyze relationship between features and review ratings and comments. ","8b77e7b5":"# 1. Basic dataset exploration\n\nHere I import data and make basic analysis of features, nulls, counts, etc. to get sense of data","be6a080a":"### Correlation Matrix with selected features","5fa7b29b":"### My conclusion so far:\n\nLooking into graphs above and the imperfect data I collected, Ipanema seems to be the best option to invest. It has a good performance on booking and best performance over price index. The problem is that property in this neighborhood is too expensive and to get a loan from bank you already had to have money to buy part of it. \nSo, better try another afortable neighborhood :-)","db93405f":"### Analyze the effect of price category on other aspects\n\nLet's first binarize the price into a new column","151fc40b":"# 5. Create a Model to estimate which is the best price\/performance to buy a property","3310c20c":"### Plot samples of prices over time"}}