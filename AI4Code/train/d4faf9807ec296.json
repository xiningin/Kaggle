{"cell_type":{"b76c92af":"code","69662ec2":"code","88681f4a":"code","ae973376":"code","04bf0a08":"code","6f6ebafd":"code","99884a76":"code","5c870490":"code","0912a6d7":"code","ed44d337":"code","76eab90c":"code","53d2d205":"code","a6b3a7bf":"code","7791a92d":"code","609d5e14":"code","9972b146":"code","edb3594e":"code","1b7ca568":"code","c0a9bea5":"code","af49203d":"code","eb042541":"code","c0dde289":"code","35784f86":"code","02cbb72b":"code","da7ea642":"code","5a94db5b":"code","5a73d679":"code","1bd976ac":"markdown","691069c1":"markdown","e649c4dc":"markdown","e1fecfb8":"markdown","480bd44e":"markdown","9fd89b39":"markdown"},"source":{"b76c92af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","69662ec2":"fake_data = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/Fake.csv\")\ntrue_data = pd.read_csv(\"\/kaggle\/input\/fake-and-real-news-dataset\/True.csv\")","88681f4a":"fake_data.head(5)\n","ae973376":"true_data.head(5)","04bf0a08":"#Creating labels for classification \nfake_data[\"Label\"] = 0\ntrue_data[\"Label\"] = 1","6f6ebafd":"#Taking a sample of the data (You can also take fully but will take longer time according to CPU Power)\ndata = pd.concat([fake_data.iloc[:2000,:],true_data.iloc[:2000,:]], axis=0,ignore_index = True)","99884a76":"data.head()","5c870490":"data.shape","0912a6d7":"data.subject.unique()","ed44d337":"data.isnull().sum()","76eab90c":"#Dropping unnecessary variables\ndata.drop([\"title\",\"subject\",\"date\"], axis=1, inplace=True)","53d2d205":"data.head()","a6b3a7bf":"data.text[6]","7791a92d":"#Creating independent and dependent variables\nX = data.drop([\"Label\"],axis=1)\ny = data[\"Label\"]","609d5e14":"X.head()","9972b146":"y.head()","edb3594e":"X.columns","1b7ca568":"from nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer","c0a9bea5":"ps = PorterStemmer()\ncorpus=[]\nfor i in range(0,len(X)):\n    review = re.sub(\"[^a-zA-Z]\",\" \",X[\"text\"][i])\n    review = review.lower()\n    review = review.split()\n    review = [ps.stem(word) for word in review if word not in stopwords.words(\"english\")]\n    review = \" \".join(review)\n    corpus.append(review)","af49203d":"vector = TfidfVectorizer(max_features =5000, ngram_range=(1,3))\nX = vector.fit_transform(corpus).toarray()","eb042541":"X.shape","c0dde289":"y.shape","35784f86":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","02cbb72b":"X_train.shape","da7ea642":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nclassifier=MultinomialNB()\n\nclassifier.fit(X_train, y_train)\npred = classifier.predict(X_test)\n\nscore = metrics.accuracy_score(y_test, pred)","5a94db5b":"print(\"Accuracy of the model: {}%\".format(score*100))","5a73d679":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncm = metrics.confusion_matrix(y_test, pred)\nmetrics.plot_confusion_matrix(classifier,X_test,y_test)","1bd976ac":"# 3.*Word Vectorization*","691069c1":"# *We see that the model has successfully classified the fake and real news with an accuracy of 98%*","e649c4dc":"# 2.*Stemming and removing stop words*","e1fecfb8":"# 5.*Model Evaluation*","480bd44e":"# 1. *Data Preprocessing*\n","9fd89b39":"# 4.*Model Building*"}}