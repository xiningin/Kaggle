{"cell_type":{"ea80108e":"code","fbecf723":"code","1e18a0b0":"code","c3efa28f":"code","69edae0e":"code","4c4802ad":"code","92c06ce8":"code","2137b2c4":"code","75437a9a":"code","7c2f33c0":"code","cf4d213d":"code","367e8b07":"code","7c4abc03":"code","8a778247":"code","cf832e6c":"code","349fb8ae":"code","e62fbfa5":"code","4d5c24f6":"code","63d81ed7":"code","28283e82":"code","cef77b77":"code","ad370749":"code","e57cf033":"code","13c52495":"code","2d2f7569":"markdown","42d6159d":"markdown","d899ede9":"markdown","f28fcead":"markdown","b1c15212":"markdown"},"source":{"ea80108e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Embedding, Input, LSTM, Bidirectional, GlobalMaxPool1D, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Any results you write to the current directory are saved as output.","fbecf723":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsubm = pd.read_csv('..\/input\/sample_submission.csv')","1e18a0b0":"train.head()","c3efa28f":"train.shape","69edae0e":"train_length = train.comment_text.apply(len)\ntrain_length.head()","4c4802ad":"plt.figure(figsize = (12, 5))\nplt.hist(train_length, bins = 60, alpha = 0.5, color = 'r')\nplt.show()","92c06ce8":"print(\"max length : \", np.max(train_length))\nprint(\"min length : \", np.min(train_length))\nprint(\"mean length : \", np.mean(train_length))\nprint(\"75 % percentile : \", np.percentile(train_length, 75))\nprint(\"85 % percentile : \", np.percentile(train_length, 85))\nprint(\"std length : \", np.std(train_length))","2137b2c4":"print(train.comment_text.isna().sum())\nprint(test.comment_text.isna().sum())","75437a9a":"X = train.comment_text\ny = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\ntest = test.comment_text","7c2f33c0":"y[:5]","cf4d213d":"num_words = 20000\nmax_len = 150\nemb_size = 128","367e8b07":"tok = Tokenizer(num_words = num_words)\ntok.fit_on_texts(list(X))","7c4abc03":"X = tok.texts_to_sequences(X)\ntest = tok.texts_to_sequences(test)","8a778247":"X[0]","cf832e6c":"X = sequence.pad_sequences(X, maxlen = max_len)\nX_test = sequence.pad_sequences(test, maxlen = max_len)","349fb8ae":"X[0]","e62fbfa5":"def model():\n    inp = Input(shape = (max_len, ))\n    layer = Embedding(num_words, emb_size)(inp)\n    layer = Bidirectional(LSTM(50, return_sequences = True, recurrent_dropout = 0.15))(layer)\n    layer = GlobalMaxPool1D()(layer)\n    layer = Dropout(0.2)(layer)\n    layer = Dense(50, activation = 'relu')(layer)\n    layer = Dropout(0.2)(layer)\n    layer = Dense(6, activation = 'sigmoid')(layer)\n    model = Model(inputs = inp, outputs = layer)\n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n    return model","4d5c24f6":"model = model()\nmodel.summary()","63d81ed7":"file_path = 'save_best'\ncheckpoint = ModelCheckpoint(file_path, monitor = 'val_loss', verbose = 1, save_best_only=True)\nearly_stop = EarlyStopping(monitor = 'val_loss', patience = 1)","28283e82":"hist = model.fit(X, y, batch_size = 32, epochs = 2, validation_split = 0.2, callbacks = [checkpoint, early_stop])","cef77b77":"vloss = hist.history['val_loss']\nloss = hist.history['loss']\n\nx_len = np.arange(len(loss))\n\nplt.plot(x_len, vloss, marker='.', c='red', label='vloss')\nplt.plot(x_len, loss, marker='.', c='blue', label='loss')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.grid()\nplt.show()","ad370749":"vacc = hist.history['val_acc']\nacc = hist.history['acc']\n\nx_len = np.arange(len(vacc))\n\nplt.plot(x_len, vacc, marker='.', c='red', label='vacc')\nplt.plot(x_len, acc, marker='.', c='blue', label='acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.grid()\nplt.show()","e57cf033":"y_test = model.predict(X_test)","13c52495":"subm[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_test\n\nsubm.to_csv(\"sub.csv\", index=False)","2d2f7569":"** preprocssing with keras Tokenizer **","42d6159d":"load datas!","d899ede9":"** create callbacks **","f28fcead":"** check data with simple EDA **","b1c15212":"** now, make model! **"}}