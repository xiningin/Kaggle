{"cell_type":{"919e8435":"code","40a34b33":"code","71230866":"code","997e9f6c":"code","6c94cb99":"code","8b0dd6b4":"code","84985b96":"code","def0850c":"code","68e5fe8b":"code","8e3bb9df":"code","7ce793e8":"code","13490218":"code","fd3d7249":"code","0adc5681":"code","65fc7340":"code","788a69d8":"code","6e7fc2f4":"code","48921ce2":"code","e3f26fe5":"code","d46e6c33":"code","358ff166":"code","a0fb2ee5":"code","ddf766bf":"code","5e9a6181":"code","1e2702c6":"code","161e2eee":"code","21cee2ca":"code","44ba0c24":"code","9a703e09":"code","43f46f4b":"code","b07dd95b":"code","10d2dd24":"code","f59f1ae0":"code","5010a32f":"code","752e258f":"code","b6bcc052":"code","8fc17aeb":"code","9d4bce6b":"code","3eb2ec67":"code","0d4d38aa":"code","97879688":"code","1c2374da":"code","f128d9b2":"code","d65bd255":"code","23be2887":"code","7505a6be":"code","2c11e457":"code","1f541740":"code","ddb0bf69":"code","b02afb5f":"code","dd5c5cbe":"code","f7108360":"code","1b93dbf5":"code","736a27b5":"code","d3efacb2":"code","ab34d773":"code","ba67e16b":"code","5cab6c3d":"code","f86def40":"code","1779e6be":"code","f6bc0d4d":"code","928ac1b1":"code","abe36f4b":"code","e65fa8a4":"code","2860185d":"code","2d91757c":"code","bebdeb56":"code","14dc8ed6":"code","f3fb5faa":"code","5d25caf3":"code","b3116fa7":"code","42d7ca59":"code","7aa486b2":"code","b5ed1524":"code","00fcffcc":"code","1fc29834":"code","132b6f0f":"code","5ab9e04a":"code","9dc6dae3":"code","bd9408d1":"code","750463b9":"code","6a6c3a1b":"code","3d01d273":"code","76870595":"code","5926eee2":"code","25278528":"code","40fc0ddf":"markdown","ea48fdf9":"markdown","e6faacc4":"markdown","6127ad99":"markdown","72c91982":"markdown","35281847":"markdown","9c1e8713":"markdown","2a3a65a4":"markdown","5523ae7e":"markdown","8ce85cd9":"markdown","c1216314":"markdown","a9c7f6d8":"markdown"},"source":{"919e8435":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","40a34b33":"train_data=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data=pd.read_csv(\"..\/input\/titanic\/test.csv\")","71230866":"train_data.shape\n","997e9f6c":"train_data.count()","6c94cb99":"train_data.info()","8b0dd6b4":"train_data.describe()","84985b96":"total=train_data.isnull().sum().sort_values(ascending=False)\n\npercent=train_data.isnull().sum()\/train_data.isnull().count()\n\nmissing_data=pd.concat([total,percent],axis=1,keys=['Total','Percent'])\nmissing_data\n","def0850c":"\ntrain_data['Age']=train_data['Age'].fillna(train_data['Age'].mode().iloc[0])\ntrain_data['Age']","68e5fe8b":"train_data['Embarked']=train_data['Embarked'].fillna(train_data['Embarked'].mode().iloc[0])\ntrain_data['Embarked']","8e3bb9df":"\ntrain_data=train_data.drop('Name',axis=1)\ntrain_data=train_data.drop('Ticket',axis=1)\ntrain_data=train_data.drop('PassengerId',axis=1)\ntrain_data=train_data.drop(train_data.columns[train_data.apply(lambda col: col.isnull().sum()\/col.isnull().count() > 0.3)], axis=1)\ntrain_data","7ce793e8":"train_data.info()","13490218":"#train_data['Age'].value_counts()","fd3d7249":"#train_data['Pclass']=train_data['Pclass'].astype('object')","0adc5681":"#train_data['Survived']=train_data['Survived'].astype('object')","65fc7340":"train_data.info()","788a69d8":"train_num=train_data.select_dtypes(include=['int64','float64'])\ntrain_num\n#seperate numerical and categorical data","6e7fc2f4":"train_cat=train_data.select_dtypes(include=['object'])\ntrain_cat\n#categorical data","48921ce2":"\nfor i in train_num.columns:\n    sns.histplot(data=train_num[i], kde=True,line_kws={\"color\":\"r\",\"lw\":2})\n    #set(xlim=(0,15),ylim=(0,100))\n    plt.show()","e3f26fe5":"#train_data['Age'].describe()","d46e6c33":"#train_data['Age'].median()","358ff166":"print(\"Skewness for Age:\",train_data['Age'].skew())","a0fb2ee5":"print(\"Skewness for Fare:\",train_data['Fare'].skew())\n","ddf766bf":"log_fare=np.log(train_data['Fare'])\nprint(\"Skewness for Fare after log transformation:\",log_fare.skew())\n\nsns.histplot(data=log_fare, kde=True,line_kws={\"color\":\"r\",\"lw\":2})","5e9a6181":"train_data['Fare']=log_fare\ntrain_num['Fare']=log_fare","1e2702c6":"for i in train_cat.columns:\n    sns.barplot(train_cat[i].value_counts().index,train_cat[i].value_counts()).set_title(i)\n    plt.show()\n    ","161e2eee":"train_data[train_data['Survived']==1].count()['Survived']\/train_data.count()['Survived']","21cee2ca":"train_data[train_data['Survived']==0].count()['Survived']\/train_data.count()['Survived']","44ba0c24":"train_data[train_data['Sex']=='male'].count()['Sex']\/train_data.count()['Sex']","9a703e09":"train_data[train_data['Sex']=='female'].count()['Sex']\/train_data.count()['Sex']","43f46f4b":"train_data[train_data['Embarked']=='S'].count()['Embarked']\/train_data.count()['Embarked']","b07dd95b":"train_data[train_data['Embarked']=='Q'].count()['Embarked']\/train_data.count()['Embarked']","10d2dd24":"train_data[train_data['Embarked']=='C'].count()['Embarked']\/train_data.count()['Embarked']","f59f1ae0":"#sns.barplot(x = \"Survived\", y = \"Pclass\", hue = \"Pclass\", data = train_data)\n#plt.show()\n","5010a32f":"#!pip install scikit-learn --upgrade\nfrom sklearn.preprocessing import LabelEncoder\ncols=['Sex','Embarked']\nle=LabelEncoder()\nfor col in cols:\n    train_data[col]=le.fit_transform(train_data[col])\ntrain_data.head()","752e258f":"train_data.info()","b6bcc052":"train_data.shape","8fc17aeb":"\n    sns.boxplot(x=train_data['Survived'])\n    Q1=train_data['Survived'].quantile(0.25)\n    Q3=train_data['Survived'].quantile(0.75)\n    IQR=Q3-Q1\n    print(\"IQR for Survived,:\",IQR)\n    upper=Q1+1.5*IQR\n    lower=Q1-1.5*IQR\n    print('upper',upper)\n    print('lower',lower)\n    print(train_data[(train_data['Survived'] < (lower) )|(train_data['Survived'] > (upper))])\n    #train_data=train_data[(train_data['Survived'] > (lower) )&(train_data['Survived'] < (upper))]\n\n    #print(train_num[i] < (Q1 - 1.5 * IQR)) |(train_num[i] > (Q3 + 1.5 * IQR))\n    plt.show()","9d4bce6b":"train_data.shape","3eb2ec67":"for i in train_data.columns:    \n    sns.boxplot(x=train_data[i])\n    Q1=train_data[i].quantile(0.25)\n    Q3=train_data[i].quantile(0.75)\n    IQR=Q3-Q1\n    print(\"IQR for\",i,\":\",IQR)\n    upper=Q1+1.5*IQR\n    lower=Q1-1.5*IQR\n    print('upper',upper)\n    print('lower',lower)\n    print(train_data[(train_data[i] < (lower) )|(train_data[i] > (upper))])\n    #train_data=train_data[(train_data[i] < (lower) )&(train_data[i] > (upper))]\n\n    #print(train_num[i] < (Q1 - 1.5 * IQR)) |(train_num[i] > (Q3 + 1.5 * IQR))\n    plt.show()","0d4d38aa":"train_data","97879688":"train_data.corr(method='pearson', min_periods=1)","1c2374da":"train_data","f128d9b2":"corrmat=train_data.corr()\nf,ax=plt.subplots(figsize=(12,9))\nsns.heatmap(corrmat,vmax=.8,square=True)","d65bd255":"corr=train_data.corr()\nplt.figure(figsize=(15,9))\nsns.heatmap(corr,annot=True,cmap='coolwarm')","23be2887":"import scipy.stats as stats\n\n#calculate point-biserial correlation\nprint('Correlation between age and survived',stats.pointbiserialr(train_data['Survived'], train_data['Age']))\n#p-value is more than 0.05 and thus age and survived independent.\nprint(stats.pointbiserialr(train_data['Survived'], train_data['Sex']))\n","7505a6be":"#point-biserial correlation\n#print('Correlation between fare and survived',stats.pointbiserialr(train_data['Survived'], train_data['Fare']))\n#p-value is more than 0.05 and thus age and survived independent.","2c11e457":"#point-biserial correlation\n#print('Correlation between Sipsp and survived',stats.pointbiserialr(train_data['Survived'], train_data['SibSp']))\n#p-value is more than 0.05 and thus age and survived independent.","1f541740":"#train_data['Survived'].corr(train_data['SibSp'])","ddb0bf69":"#point-biserial correlation\n#print('Correlation between Parch and survived',stats.pointbiserialr(train_data['Survived'], train_data['Parch']))\n#p-value is more than 0.05 and thus Parch and survived are dependent.","b02afb5f":"sns.set()\ni=['Survived','Age','Parch','SibSp','Fare','Pclass','Sex','Embarked']\nsns.pairplot(data=train_data[i],size=2.5)\nplt.show","dd5c5cbe":"#pd.pivot_tables(train_data,index='Pclass',values='Survived')\npclass=train_data[[\"Pclass\", \"Survived\"]].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\npclass","f7108360":"train_data[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","1b93dbf5":"train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","736a27b5":"train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).count().sort_values(by='Survived', ascending=False)","d3efacb2":"train_data[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ab34d773":"train_data[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ba67e16b":"train_data[[\"Age\", \"Survived\"]].groupby(['Age'], as_index=False).count().sort_values(by='Survived', ascending=True)\n","5cab6c3d":"train_data[[\"Age\", \"Survived\"]].groupby(['Age'], as_index=False).mean().sort_values(by='Survived', ascending=False)\npd.set_option('display.max_rows', train_data[[\"Age\", \"Survived\"]].groupby(['Age'], as_index=False).mean().sort_values(by='Survived', ascending=False).shape[0]+1)\nprint(train_data[[\"Age\", \"Survived\"]].groupby(['Age'], as_index=False).mean().sort_values(by='Survived', ascending=False))","f86def40":"train_data.info()","1779e6be":"\n#sns.catplot(x=\"Survived\",y=\"Age\",data=train_data)","f6bc0d4d":"#sns.catplot(x=\"Survived\",y=\"Fare\",data=train_data)","928ac1b1":"train_data.info()","abe36f4b":"#pip install -U scikit-learn","e65fa8a4":"train_data.info()","2860185d":"x=train_data.drop(columns=['Survived'],axis=1)\nx","2d91757c":"train_data.info()","bebdeb56":"y=train_data[['Survived']]\ny","14dc8ed6":"from sklearn import * #.model_selection train_test_split, cross_val_score\nfrom sklearn.model_selection import cross_validate\ndef classify(model):\n    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42)\n    x_test=x_test.replace([np.inf, -np.inf], 0)\n    x_train=x_train.replace([np.inf, -np.inf], 0)\n    y_test=y_test.replace([np.inf, -np.inf], 0)\n    x_train=y_train.replace([np.inf, -np.inf], 0)\n    model.fit(x_train,y_train)\n    #print('Accuracy: ',model.score(x_test,y_test))\n    score=cross_validate(model,x,y,cv=5)\n    print(score)\n    print('CV score: ',np.mean(score))\n    ","f3fb5faa":"x_train.info()","5d25caf3":"pd.set_option('display.max_rows',x_train.shape[0]+1)\nprint(x_train)","b3116fa7":"x_test","42d7ca59":"y_test","7aa486b2":"#y_train","b5ed1524":"#x_train = x_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)","00fcffcc":"#y_train = y_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)","1fc29834":"#np.isnan(x_train.any()) #and gets False\nnp.isfinite(x_train.all())","132b6f0f":"np.isfinite(x_test.all())","5ab9e04a":"np.any(np.isnan(y_test))","9dc6dae3":"np.all(np.isfinite(y_test))","bd9408d1":"x_test.info()","750463b9":"x_test=x_test.replace([np.inf, -np.inf], 0)\n","6a6c3a1b":"#train_data = train_data.reset_index()","3d01d273":"\nmodel = LogisticRegression()\n#model.fit(x_train,y_train)\nclassify(model)","76870595":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\n#model.fit(x_train,y_train)\nclassify(model)","5926eee2":"pred = model.predict(x_test)\npred\n","25278528":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(x_train, y_train)\nY_pred = svc.predict(x_test)\nacc_svc = round(svc.score(x_train, y_train) * 100, 2)\nacc_svc","40fc0ddf":"dataframe.count() can be used to find the number of rows in each variable.","ea48fdf9":"Lets first import the data.Use read_csv() to import the data.","e6faacc4":"Skewness for Fare is very high and thus we use the log transformation to make the Fare column follow nearly normal distribution.","6127ad99":"**FIND MISSING VALUES**","72c91982":"**REMOVE UNWANTED COLUMNS**\n1. Remove Cabin column as it has a lot of missing values.\n2. Remove Ticket column as it may not help in our analysis.\n3. Remove name column as it may not help in our analysis.\n4. Remove PassengerID as it may not help in our analysis.\n\n","35281847":"dataframe.describe() can be used to get the statistical summary of the data.","9c1e8713":"Box plot for detecting outliers.","2a3a65a4":"Histogram for Age follows a nearly normal distribution\nHistogram for Fare is right skewed.","5523ae7e":"Calculate the skewness for Age. Age follows nearly normal distribution with 0.66 skewness.\n","8ce85cd9":"dataframe.shape can be used to find the number of rows and columns in the data.","c1216314":"There are a lot of missing values in the Cabin column.77% of the values are missing. It is best to just drop this column as it may not help in our analysis and can lead to false conclusions.\nAge column also has some missing values. In case of Age column we can replace the missing values with any of the measure of central tendency. Here, I'm using mode value for age column to replace the null values. \nThere are 2 missing values for Embarked column which are replaced with the mode value of the Embarked column.","a9c7f6d8":"dataframe.info() can be used to find the information of the columns like non null count and datatype.\nIn this case there are a total of 12 columns.2 float,5 int and 5 object"}}