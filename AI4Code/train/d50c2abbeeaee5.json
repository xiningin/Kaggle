{"cell_type":{"a8013c8a":"code","9bb0f61a":"code","85c0a619":"code","dbc75c22":"code","3cb96265":"code","5f70c3b7":"code","70b0f435":"code","0f4d6d75":"code","af1f3af0":"code","fae6f16d":"code","83fb14db":"code","4519b80f":"code","e39d82ee":"code","a92101e9":"code","43ebc21b":"code","32b9060d":"markdown"},"source":{"a8013c8a":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt \nimport seaborn as sns","9bb0f61a":"files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n        \nfiles","85c0a619":"def create_dataset():\n    data = pd.read_csv(files[0])\n    data.columns = data.columns.str.replace(' |-', '_', regex=True).str.lower()\n    data[\"class\"] = np.where(data[\"class\"] == \"e\", 1, 0)\n    return data\n\ndf = create_dataset()\ndf.head()","dbc75c22":"cols, unique_vals = df.columns, []\n\nfor col in cols:\n    counter = len(df[col].unique())\n    unique_vals.append([col, counter])\n    \nvals_df = pd.DataFrame(unique_vals, columns=[\"column\", \"unique_values\"])\nvals_df","3cb96265":"cap_shapes = {\"b\": \"bell\", \"c\": \"conical\", \"x\": \"convex\", \"f\": \"flat\", \"k\": \"knobbed\" , \"s\": \"sunken\"}\nsurfaces = {\"f\": \"fibrous\",  \"g\": \"grooves\", \"y\": \"scaly\", \"s\": \"smooth\"}\n\ndef column_summary(data, column, mapper=None):\n    # Get summary stats for the column\n    temp = data.groupby(column)[\"class\"].agg([\"sum\", \"count\"]).reset_index()\n    temp[\"percent_edible\"] = temp[\"sum\"].div(temp[\"count\"]).round(2)\n    \n    if mapper is None:\n        x_axis = temp[column]\n    else:\n        x_axis = temp[column].map(mapper)\n    # Create plots based off the data\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n    ax1.bar(x_axis, temp[\"sum\"], label=\"Edible Count\")\n    ax2.bar(x_axis, temp[\"percent_edible\"], label=\"Edible Percent\")\n    ax1.set_title(f\"{column} Edible Count\")\n    ax2.set_title(f\"{column} Edible Percent\")\n    \n    return plt.show()\n\n\ncolumn_summary(df, \"cap_shape\", mapper=cap_shapes)\nprint(\"\\n\\n\")\ncolumn_summary(df, \"cap_surface\", mapper=surfaces)\n# show edible ","5f70c3b7":"column_summary(df, \"cap_color\")\nprint(\"\\n\\n\")\ncolumn_summary(df, \"odor\")","70b0f435":"column_summary(df, \"gill_color\")\nprint(\"\\n\\n\")\ncolumn_summary(df, \"stalk_root\")","0f4d6d75":"column_summary(df, \"stalk_surface_above_ring\")\nprint(\"\\n\\n\")\ncolumn_summary(df, \"stalk_color_below_ring\")","af1f3af0":"column_summary(df, \"population\")\nprint(\"\\n\\n\")\ncolumn_summary(df, \"habitat\")","fae6f16d":"def transfomations(data):\n    # Turn features with only 2 values into binary features 1 or 0 to represent each class.\n    data[\"bruises\"] = np.where(data[\"bruises\"] == \"t\", 1, 0)\n    data[\"gill_attachment\"] = np.where(data[\"gill_attachment\"] == \"f\", 1, 0)\n    data[\"gill_spacing\"] = np.where(data[\"gill_spacing\"] == \"c\", 1, 0)\n    data[\"gill_size\"] = np.where(data[\"gill_size\"] == \"b\", 1, 0)\n    data[\"stalk_shape\"] = np.where(data[\"stalk_shape\"] == \"t\", 1, 0)\n    data[\"cap_surface\"] = np.where(data[\"cap_surface\"] == \"f\", 1, 0)\n    data[\"cap_color\"] = np.where(data[\"cap_color\"].isin([\"r\", \"u\", \"w\", \"c\"]), 1, 0)\n    data[\"odor\"] = np.where(data[\"odor\"].isin([\"a\", \"l\", \"n\"]), 1, 0)\n    data[\"gill_color\"] = np.where(data[\"gill_color\"].isin([\"e\", \"k\", \"n\", \"o\", \"u\", \"w\", \"y\"]), 1, 0)\n    data[\"stalk_surface\"] = np.where(data[\"stalk_surface_above_ring\"].isin([\"f\", \"s\", \"y\"]), 1, 0)\n    data[\"veil_color\"] = np.where(data[\"veil_color\"] == \"y\", 0, 1)\n    data[\"ring_number\"] = np.where(data[\"ring_number\"] == \"n\", 0, 1)\n    data[\"ring_type\"] = np.where(data[\"ring_type\"].isin([\"f\", \"p\"]), 1, 0)\n    data[\"spore_print_color\"] = np.where(data[\"spore_print_color\"].isin([\"h\", \"r\", \"w\"]), 0, 1)\n    \n    # Turn features with multiple useful classes into range of values \/ dummies\n    cap_mapper = {\"b\": 2, \"c\": 0, \"x\": 1, \"f\": 1, \"k\":  0, \"s\": 2}\n    root_mapper = {\"?\": 0, \"b\": 1, \"c\": 2, \"e\": 1, \"r\": 2}\n    stalk_color_mapper = {\"b\": 0, \"c\": 0, \"e\": 2, \"g\": 2, \"n\": 1, \"o\": 2, \"p\": 1, \"w\": 1, \"y\": 0}\n    population_mapper = {\"a\": 2, \"c\": 2, \"n\": 2, \"s\": 1, \"v\": 0, \"y\": 1}\n    habitat_mapper = {\"d\": 1, \"g\": 1, \"l\": 0, \"m\": 2, \"p\": 0, \"u\": 0, \"w\": 2}\n    data[\"cap_shape\"] = data[\"cap_shape\"].map(cap_mapper)\n    data[\"stalk_root\"] = data[\"stalk_root\"].map(root_mapper)\n    data[\"stalk_color\"] = data[\"stalk_color_above_ring\"].map(stalk_color_mapper)\n    data[\"population\"] = data[\"population\"].map(population_mapper)\n    data[\"habitat\"] = data[\"habitat\"].map(habitat_mapper)\n    \n    # Drop redundant features \n    redundant = [\"veil_type\", \"stalk_surface_above_ring\", \"stalk_surface_below_ring\", \"stalk_color_above_ring\", \n                \"stalk_color_below_ring\"]\n    data = data.drop(redundant, axis=1)\n    \n    return data\n\n\ndf = transfomations(df)\ndf.head()","83fb14db":"print(\"Percent Null: \")\n(df.isnull().sum() \/ len(df)).plot()","4519b80f":"def heatmapper(data, method=\"pearson\"):\n    # \n    heat_data = data.corr(method=method).round(2)\n    mask = np.triu(np.ones_like(heat_data, dtype=bool))\n    \n    # Create the plot \n    fig = plt.figure(figsize=(20, 10))\n    sns.heatmap(heat_data, annot=True, mask=mask, cmap='viridis')\n    plt.title(f\"{method} correlation\")\n    return plt.show()\n\n\nheatmapper(df)","e39d82ee":"# Odor is very highly correlated to class (target field), start with using a single field as x?\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report\n\n\ndef binary_classifier(data):\n    \n    X = np.array(df[\"odor\"]).reshape(-1, 1)\n    y = np.array(df[\"class\"]).reshape(-1, 1)\n    \n    X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=25, random_state=66)\n    \n    # create and fit the model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    \n    # Generate predictions\n    train_preds = model.predict(X_train)\n    eval_preds = model.predict(X_eval)\n    \n    # return the errors \n    train_precision = precision_score(y_train, train_preds)\n    eval_precision = precision_score(y_eval, eval_preds)\n    cr = classification_report(y_eval, eval_preds)\n    return train_precision, eval_precision, cr\n\n\nx = binary_classifier(df)\nprint(f\"Train precision: {round(x[0], 2)}\")\nprint(f\"Eval precision: {round(x[1], 2)}\")\nprint(\"\\n\")\nprint(x[2])","a92101e9":"def all_feat_classifier(data):\n    \n    X = df.drop([\"class\"], axis=1)\n    y = df[\"class\"]\n    \n    X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=25, random_state=66)\n    \n    # create and fit the model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    \n    # Generate predictions\n    train_preds = model.predict(X_train)\n    eval_preds = model.predict(X_eval)\n    \n    # return the errors \n    train_precision = precision_score(y_train, train_preds)\n    eval_precision = precision_score(y_eval, eval_preds)\n    cr = classification_report(y_eval, eval_preds)\n    return train_precision, eval_precision, cr\n\n\nx = all_feat_classifier(df)\nprint(f\"Train precision: {round(x[0], 2)}\")\nprint(f\"Eval precision: {round(x[1], 2)}\")\nprint(\"\\n\")\nprint(x[2])","43ebc21b":"def cross_val(data):\n    \n    X = df.drop([\"class\"], axis=1)\n    y = df[\"class\"]\n    \n    # create and fit the model\n    model = LogisticRegression()\n\n    # return the errors \n    scores = cross_val_score(model, X, y, cv=5, scoring='precision')\n    mean_score = np.mean(scores).round(2)\n    min_score = np.min(scores).round(2)\n    max_score = np.max(scores).round(2)\n    \n    return {\"mean\": mean_score, \"min\": min_score, \"max\": max_score}\n\n\nx = cross_val(df)\nx","32b9060d":"The data has a lot of categorical data, start converting into binary\/ dummy data where appropriate. The class is the target variable"}}