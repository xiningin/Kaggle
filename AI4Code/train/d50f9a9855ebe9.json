{"cell_type":{"8b85832b":"code","8537d460":"code","dc680875":"code","3366322f":"code","4acac05c":"code","4af3d22c":"code","76ce6a54":"code","a85ac8a5":"code","d61a03f6":"code","52ee3140":"code","6344f7d7":"code","96546c0d":"code","aba65fc6":"code","3b18abe5":"markdown","a3fed787":"markdown"},"source":{"8b85832b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8537d460":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nimport pandas as pd","dc680875":"X = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nX_test = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\nY = X[\"SalePrice\"]\nX = X.drop([\"SalePrice\"], axis=1)","3366322f":"X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, random_state=1)","4acac05c":"def score(X_train, X_valid, Y_train, Y_valid):\n    model = RandomForestRegressor(random_state=1)\n    model.fit(X_train, Y_train)\n    print(Y_valid.shape, X_valid.shape)\n    return mean_absolute_error(Y_valid, model.predict(X_valid))","4af3d22c":"num_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\ncat_cols = [col for col in X.columns if X[col].dtype == 'object']","76ce6a54":"numerical_transformer = SimpleImputer(strategy='constant')\n\ncat_trans = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('cat', OneHotEncoder(handle_unknown='ignore')),\n])\n\ntransf = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, num_cols),\n    ('cat', cat_trans, cat_cols),\n])","a85ac8a5":"estimators = [5, 50, 100, 200, 500, 1000]","d61a03f6":"for i in estimators:\n    model = RandomForestRegressor(n_estimators=100, max_depth=i, random_state=1)\n\n    pipeline = Pipeline(steps=[\n        ('preprocessor', transf),\n        ('model', model)\n    ])\n\n    pipeline.fit(X_train, Y_train)\n    \n    print(mean_absolute_error(Y_valid, pipeline.predict(X_valid)))","52ee3140":"model = RandomForestRegressor(n_estimators=100, max_depth=50, random_state=1)\n\npipeline = Pipeline(steps=[\n    ('preprocessor', transf),\n    ('model', model)\n])\n\npipeline.fit(X, Y)","6344f7d7":"mean_absolute_error(Y_valid, pipeline.predict(X_valid))","96546c0d":"test_preds = pipeline.predict(X_test)","aba65fc6":"df = pd.DataFrame({\n    \"Id\": X_test[\"Id\"],\n    \"SalePrice\": test_preds\n}).to_csv(\"submission.csv\", index=False)","3b18abe5":"# Creating a model (Random Forest)","a3fed787":"Create a pipline"}}