{"cell_type":{"32970f41":"code","2c107cff":"code","1f144070":"code","0f06f513":"code","4601f0ee":"code","41d6f1d5":"code","90f13c49":"code","bd1eb140":"code","96d5ca28":"code","a2e8f6ea":"code","f8391bd7":"code","8175feae":"code","b3de16fa":"code","fd98e686":"code","9956dfea":"code","f0ce1429":"code","e6912aea":"code","3977f65a":"code","4f6f7ec4":"code","fe6b0eb6":"code","86eaedb9":"code","97b7b291":"code","078b8ba7":"code","51942c06":"code","b8167f12":"code","db183a8d":"code","a2642a1d":"code","9ec60ef7":"code","82d8ffb3":"code","d81e8e9c":"code","12f7be3c":"code","ff43fe98":"code","659b781e":"code","f0e40294":"code","ff820475":"code","f78af1fa":"code","b436589e":"code","47370fbe":"code","8cd6795e":"code","94d8994b":"code","832572c6":"code","52002357":"code","091445eb":"code","f2ec99cc":"code","adae3fcf":"code","c30f36f5":"code","83a42a9d":"code","3a705dff":"code","c6622800":"code","c28774f9":"code","340d5059":"code","e1a79e95":"code","7e6b3472":"code","bc7f97d4":"code","351e1a0a":"code","c2535e49":"code","6c2a1094":"code","1af50240":"code","9b8eb8fe":"code","e3a031ee":"code","efe1aecd":"code","f690518e":"code","c38aaf74":"code","43674e39":"code","9e47d2a4":"code","fe53435f":"code","d2567ef2":"code","aca38fa5":"code","bde31c37":"code","52a5127d":"code","e8a6ccfa":"code","e1b59ba9":"code","e0712cad":"code","99e6233e":"code","2c7fb33d":"code","e3cabcdc":"code","149b2c94":"code","50c307d1":"code","15bc7ccf":"code","01536a37":"code","37bfa0f1":"code","1722231a":"code","8c49af97":"code","eaba4506":"code","083c1ce9":"code","ffe5a49d":"code","e1aa1386":"code","ec6aaa77":"code","1d24a45e":"code","b64649c8":"code","f36fc7ae":"code","52d47c9c":"code","258c034c":"code","9e298363":"code","f947f006":"code","1d0506a8":"code","c5fdfc96":"code","5831b9af":"code","f60b8d30":"code","87aac54b":"code","e299e913":"code","db2270f7":"code","04fb6fef":"code","48ec8e5b":"markdown","950ab864":"markdown","c398ef13":"markdown","2a70aebf":"markdown","8c0f0d1b":"markdown","dae7b879":"markdown","2cd5c176":"markdown","ea266390":"markdown","5d93313c":"markdown","9b0d6dc8":"markdown","4d468c18":"markdown","d08c2713":"markdown","d63eb827":"markdown","c2ecbae4":"markdown","14e415b9":"markdown","b096477b":"markdown","acd79af9":"markdown","2f635d02":"markdown","25a3270d":"markdown","be859f59":"markdown","6a38ea4d":"markdown","1c9ac7da":"markdown","1ac6e9d7":"markdown","c128c388":"markdown","9dc6848f":"markdown","c4be3c4a":"markdown","d052f436":"markdown","17160185":"markdown","fd1cba86":"markdown","00a99b9f":"markdown","420f3f56":"markdown","18fafb1e":"markdown","c32fd463":"markdown","1ca515a3":"markdown","8b30c4bf":"markdown","5813faf6":"markdown","7e287809":"markdown","5eb32692":"markdown","206960dd":"markdown","c12de036":"markdown","5f1b079b":"markdown","62a3951a":"markdown","23832369":"markdown","2c4dcfc6":"markdown","f31986d6":"markdown","144ef73c":"markdown","c78f792c":"markdown","3239d891":"markdown","067108b0":"markdown","32c2a510":"markdown","9d27748f":"markdown","4d254d92":"markdown","5d0fbb70":"markdown","b7fefd15":"markdown","c8705de0":"markdown"},"source":{"32970f41":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2c107cff":"bankchurners = pd.read_csv(\"\/kaggle\/input\/credit-card-customers\/BankChurners.csv\")\nbankchurners","1f144070":"bankchurners.columns","0f06f513":"# in data description, it says ignore last 2 columns(Naive_Bayes_Class..)\n# see here: https:\/\/www.kaggle.com\/sakshigoyal7\/credit-card-customers\n# so that I'm dropping them\nbankchurners.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n       'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1, inplace=True)","4601f0ee":"bankchurners.info()","41d6f1d5":"bankchurners.isnull().sum()","90f13c49":"bankchurners.describe()","bd1eb140":"bankchurners._get_numeric_data()","96d5ca28":"# Droping CLIENTNUM columns because Client numberis unique identifier for the customer holding the account\n# So this number doesn't really effect our churn prediction.\nbankchurners.drop(['CLIENTNUM'], axis=1, inplace=True)","a2e8f6ea":"# All columns\ncols = bankchurners.columns\n# Find numerical columns\nnum_cols = bankchurners._get_numeric_data().columns\nnum_cols","f8391bd7":"# Categorical Columns\ncategorical = list(set(cols) - set(num_cols))\ncategorical","8175feae":"# Plot categorical columns\ndef pltCountplot(cat, df):\n    \n    fig, axis = plt.subplots(len(cat) \/\/ 2, 2, figsize=(20,16))  \n\n    index = 0\n    sns.set()\n    for i in range(len(cat) \/\/ 2):\n            \n        for j in range(2):\n\n            ax = sns.countplot(cat[index], data=df, ax=axis[i][j]);\n        \n            #for item in ax.get_xticklabels():\n            #    item.set_rotation(15)\n\n            for p in ax.patches:\n                height = p.get_height()\n                ax.text(p.get_x()+p.get_width(), height + 3, '{:1.2f}%'.format(height\/len(df)*100), ha=\"center\", fontsize=14) \n            \n            index += 1","b3de16fa":"# Plot categorical columns\npltCountplot(categorical, bankchurners);","fd98e686":"bankchurners['Attrition_Flag'].value_counts()","9956dfea":"# as we can see here, only 16.07% of customers who have churned.\nsns.countplot('Attrition_Flag', data=bankchurners)","f0ce1429":"# Plot categorical columns with different y\ndef pltcrosstab(cat, df):\n    \n    fig, axis = plt.subplots((len(cat) \/\/ 3), 3, figsize=(16,8))  \n    fig.tight_layout()\n\n    index = 0\n    sns.set()\n    for i in range((len(cat) \/\/ 3)):\n            \n        for j in range(3):\n            \n            # Since we have 11 numerical columns, some plots will be empty\n            if index == len(cat):\n                break\n            \n            ax = pd.crosstab(df[cat[index]], df['Attrition_Flag']).plot(kind='bar', ax=axis[i][j])\n        \n            for item in ax.get_xticklabels():\n                item.set_rotation(20)\n\n            for p in ax.patches:\n                height = p.get_height()\n                ax.text(p.get_x()+p.get_width(), height + 3, '{:1.2f}%'.format(height\/len(df)*100), ha=\"center\", fontsize=8) \n            \n            index += 1\n            \n    plt.subplots_adjust(wspace=0.2, hspace=0.4)","e6912aea":"# Plot categorical columns with different Attrition_Flag\npltcrosstab(categorical, bankchurners);","3977f65a":"# Check distribution of numerical features\nbankchurners.hist(figsize=(30,16), xrot=15, bins=int(bankchurners.shape[0]**0.5));","4f6f7ec4":"from scipy.stats import norm\ndef plotDistPlot(df, columns):\n    fig, ax = plt.subplots(len(columns)\/\/3, 3,figsize=(20, 12))\n    \n    index = 0\n    for i in range(2):\n        for j in range(3):\n            sns.distplot(df.loc[:, columns[index]],\n                         hist=True,\n                         fit=norm,\n                         kde=True,\n                         ax=ax[i][j])\n            ax[i][j].set_title(columns[index])\n            ax[i][j].legend(labels=['Normal', 'Actual'])\n            index += 1","fe6b0eb6":"some_columns = ['Customer_Age','Credit_Limit','Months_on_book','Avg_Utilization_Ratio','Avg_Open_To_Buy','Total_Trans_Amt']\nplotDistPlot(bankchurners, some_columns)","86eaedb9":"bankchurners.plot(kind='box', figsize = (18,10), rot=30, showfliers=False);","97b7b291":"# Check distribution of numerical features\nsns.pairplot(bankchurners, hue='Attrition_Flag', height=2.5)","078b8ba7":"sns.pairplot(bankchurners, vars=['Total_Trans_Amt','Total_Trans_Ct'], hue='Attrition_Flag', height=2.5)","51942c06":"num_cols = bankchurners._get_numeric_data().columns\ncorr_data = bankchurners.loc[:, num_cols].corr()\n\nplt.figure(figsize=(20,12))\nsns.heatmap(corr_data.abs(), annot=True, fmt='.3f',cmap='coolwarm',square=True)\nplt.show()","b8167f12":"# tag churned users as 1, rest as 0 and rename column\nbankchurners['Attrition_Flag'].replace(('Existing Customer','Attrited Customer'), (0,1), inplace=True)","db183a8d":"bankchurners.rename(columns={'Attrition_Flag':'churn'}, inplace=True)","a2642a1d":"bankchurners['Income_Category'].value_counts()","9ec60ef7":"bankchurners['churn'].value_counts()","82d8ffb3":"# If I remove unknown data from income_category, i'm losing 11% of my data, so I'm leaving it.\nbankchurners[bankchurners['Income_Category']!='Unknown']['churn'].value_counts()","d81e8e9c":"# If I removed all 'unknown' data, I lose more than %30 of my data, so I'm going to leave them\nbankchurners[(bankchurners['Income_Category']!='Unknown') & (bankchurners['Education_Level']!='Unknown') & (bankchurners['Marital_Status']!='Unknown')]['churn'].value_counts()","12f7be3c":"# Wanted to order income category because I didn't want to increase my feature column numbers by getting dummies from income category\nbankchurners_df = bankchurners.copy()\nbankchurners_df['Income_Category'] = bankchurners_df['Income_Category'].replace({'Unknown': 0 ,'Less than $40K':1, '$40K - $60K':2, \n                                                      '$80K - $120K':3, '$60K - $80K':4, '$120K +':5})","ff43fe98":"bankchurners_df.info()","659b781e":"categorical = bankchurners_df.select_dtypes(include='object').columns\nbankchurners_df = pd.get_dummies(bankchurners_df, columns = categorical, drop_first=True)","f0e40294":"bankchurners_df.info()","ff820475":"# Examine the correlations between the features and the target.\ncorr = bankchurners_df.select_dtypes(include=[np.number]).corr()\nprint (corr['churn'].sort_values(ascending=False)[:5], '\\n')\nprint (corr['churn'].sort_values(ascending=False)[-5:])","f78af1fa":"# Check corralated features with eachother\ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.select_dtypes(include=[np.number]).columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    corr = df.select_dtypes(include=[np.number]).corr()\n    au_corr = corr.abs().unstack()\n    labels_to_drop = get_redundant_pairs(df.select_dtypes(include=[np.number]))\n    #From corrolation table, drop the diagonals(which gives 1 corr)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Absolute Correlations\")\nprint(get_top_abs_correlations(bankchurners_df, 10))","b436589e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler","47370fbe":"# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\n# stratify=y preserve the proportion of target as in orginal dataset in the train and test datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\n# set the model\nlogreg = LogisticRegression()\n\n# fit model\nlogreg.fit(X_train, y_train)","8cd6795e":"# Baseline accuracy = proportion of the majority class\nprint('Baseline Accuracy: ',1. - y_train.mean())\nprint('Train Accuracy :',logreg.score(X_train, y_train))\nprint('Test Accuracy: ',logreg.score(X_test, y_test))","94d8994b":"# confusion matrix\ny_pred = logreg.predict(X_test)\ncf = metrics.confusion_matrix(y_test, y_pred)\npd.DataFrame(cf, columns=['pred neg','pred pos'], index=['actual neg','actual pos'])","832572c6":"from IPython import display\ndef confisuon_matrix_summary(y_test, model, treshold):\n    \n    model_pred_proba = model.predict_proba(X_test)[:,1]\n    cf = metrics.confusion_matrix(y_true=y_test, y_pred=model_pred_proba > treshold)\n    cm = pd.DataFrame(cf, columns=['pred neg','pred pos'], index=['actual neg','actual pos'])\n    \n    display.display(cm)\n    \n    print('Classification treshold is ', treshold)\n    # Recall, also known as the sensitivity, hit rate, or the true positive rate (TPR), is the proportion of the total amount of relevant instances that were actually retrieved. \n    # It answers the question \u201cWhat proportion of actual positives was identified correctly?\u201d\n    print('True Positive Rate\/Recall = TP\/(TP+FN) :', cf[1][1] \/ (cf[1][1] + cf[1][0]))     #same as metrics.recall_score(y_test,y_pred)\n    print('False Positive Rate = FP\/(FP+TN) :', cf[0][1] \/ (cf[0][1] + cf[0][0]))\n    # Accuracy - ratio of correctly predicted observation to the total observations.\n    print('Accuracy = (TP+TN)\/total :', (cf[1][1]+cf[0][0])\/(cf[1][1]+cf[0][0]+cf[0][1]+cf[1][0]))\n    # Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations\n    # It answers the question \u201cWhat proportion of positive identifications was actually correct?\u201d\n    print('Precision = TP\/(TP+FP) :',  (cf[1][1]\/(cf[1][1]+cf[0][1])))   #same as metrics.precision_score(y_test,y_pred)\n    \nconfisuon_matrix_summary(y_test, logreg, 0.5)","52002357":"from IPython import display\n# normalise confusion matrix with 'weighted'(calculate metrics for each label) precisions\ndef verify_performance(y_true, y_pred, model, display_matrix=True):\n    print(f\"Weighted Average Precision: {metrics.precision_score(y_true, y_pred, average='weighted'):.4f}\")  \n    confusion_matrix = pd.DataFrame(\n        metrics.confusion_matrix(y_true, y_pred, normalize='true'),\n        index=model.classes_, columns=model.classes_).round(2)\n      \n    display.display(pd.Series(\n        np.diagonal(confusion_matrix.T), \n        index=confusion_matrix.index, \n        name='individual precision').to_frame().T)\n  \n    if display_matrix:\n        display.display(confusion_matrix)\n        \nverify_performance(y_test, y_pred, logreg)","091445eb":"# We can vary the classification threshold for our model to get different predictions.\n# By setting a lower probability threshold we will predict more positive classes. Which means we will predict more true positives, but fewer true negatives.\n\n# confusion matrix (changing threshold to 0.4)\nconfisuon_matrix_summary(y_test, logreg, 0.4)","f2ec99cc":"logreg_pred_proba = logreg.predict_proba(X_test)[:,1]\nverify_performance(y_test, logreg_pred_proba > .4, logreg)","adae3fcf":"# Examine the intercept.\nlogreg.intercept_","c30f36f5":"# Examine the coefficients.\n# The higher the coefficient, the higher the \u201cimportance\u201d of a feature.\n\ncoefficients = list(zip(X_train.columns, logreg.coef_[0]))\ncoefficients","83a42a9d":"# K-folds Cross Validation\nfrom sklearn.model_selection import cross_val_score\n\ndef cross_val_accuracy_precision(model, X, y):\n    acc = []\n    precisions=[]\n    recalls=[]\n    for n in range(5,10):\n\n        # Note the results will vary each run since we take a different\n        # subset of the data each time (since shuffle=True)\n        scores = np.mean(cross_val_score(model, X, y, cv=n, scoring='accuracy'))\n        acc.append(scores)\n        p = np.mean(cross_val_score(model, X, y, cv=n, scoring=metrics.make_scorer(metrics.precision_score, average='weighted')))\n        precisions.append(p)\n        r = np.mean(cross_val_score(model, X, y, cv=n, scoring=metrics.make_scorer(metrics.recall_score, average='weighted')))\n        recalls.append(r)\n        print('Mean of Accuracy for all ', str(n), ' folds: ', 'Accuracy: ', scores)\n        print('Mean of Precision ', str(n), ' folds: ', 'Precision: ', p)\n        print('Mean of Recall ', str(n), ' folds: ', 'Recall: ', r)\n        \n    # plot to see clearly\n    plt.plot(range(5,10), acc)\n    plt.xlabel('n split')\n    plt.ylabel('Mean of Accuracy for all folds')\n    plt.show();\n    plt.plot(range(5,10), precisions)\n    plt.xlabel('n split')\n    plt.ylabel('Weighted Average Precision')\n    plt.show();\n    plt.plot(range(5,10), recalls)\n    plt.xlabel('n split')\n    plt.ylabel('Weighted Average Recall')\n    plt.show();\n    \nlogreg_cv=LogisticRegression()\ncross_val_accuracy_precision(logreg_cv, X, y)","3a705dff":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\npipe = Pipeline([('classifier' , LogisticRegression())])\n# pipe = Pipeline([('classifier', RandomForestClassifier())])\n\n# Create param grid.\n\nparam_grid = [\n    {'classifier' : [LogisticRegression()],\n     'classifier__penalty' : ['l1', 'l2'],\n    'classifier__C' : np.logspace(-4, 4, 20),\n    'classifier__solver' : ['liblinear']}]\n\nclf = GridSearchCV(pipe, \n                   param_grid = param_grid, \n                   cv = 5, \n                   scoring=metrics.make_scorer(metrics.recall_score), # maximise recall to minimise FN\n                   return_train_score=True,\n                   n_jobs=-1,\n                   verbose=True)\nclf.fit(X, y)  \nclf.best_estimator_","c6622800":"# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\n# set the model\nlogreg = LogisticRegression(C=3792.690190732246, penalty='l1',\n                                    solver='liblinear')\n\n# fit model\nlogreg.fit(X_train, y_train)","c28774f9":"confisuon_matrix_summary(y_test, logreg, 0.5)       ","340d5059":"verify_performance(y_test, y_pred, logreg)","e1a79e95":"# RidgeClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.preprocessing import StandardScaler\n\n# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nridge = RidgeClassifier()\nridge.fit(X_train, y_train)","7e6b3472":"print('Train Accuracy :',ridge.score(X_train, y_train))\nprint('Test Accuracy: ',ridge.score(X_test, y_test))","bc7f97d4":"# Baseline accuracy = proportion of the majority class\n1. - y_train.mean()","351e1a0a":"from IPython import display\ndef confisuon_matrix_summary_ridge(y_test, model):\n    # confusion matrix\n    y_pred = model.predict(X_test)\n    cf = metrics.confusion_matrix(y_test, y_pred)\n    cm = pd.DataFrame(cf, columns=['pred neg','pred pos'], index=['actual neg','actual pos'])\n\n    display.display(cm)\n    \n    print('Classification treshold is 0.5')\n    # Recall, also known as the sensitivity, hit rate, or the true positive rate (TPR), is the proportion of the total amount of relevant instances that were actually retrieved. \n    # It answers the question \u201cWhat proportion of actual positives was identified correctly?\u201d\n    print('True Positive Rate\/Recall = TP\/(TP+FN) :', cf[1][1] \/ (cf[1][1] + cf[1][0]))     #same as metrics.recall_score(y_test,y_pred)\n    print('False Positive Rate = FP\/(FP+TN) :', cf[0][1] \/ (cf[0][1] + cf[0][0]))\n    # Accuracy - ratio of correctly predicted observation to the total observations.\n    print('Accuracy = (TP+TN)\/total :', (cf[1][1]+cf[0][0])\/(cf[1][1]+cf[0][0]+cf[0][1]+cf[1][0]))\n    # Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations\n    # It answers the question \u201cWhat proportion of positive identifications was actually correct?\u201d\n    print('Precision = TP\/(TP+FP) :',  (cf[1][1]\/(cf[1][1]+cf[0][1])))   #same as metrics.precision_score(y_test,y_pred)\nconfisuon_matrix_summary_ridge(y_test, ridge)","c2535e49":"y_pred = ridge.predict(X_test)\nverify_performance(y_test, y_pred, ridge)","6c2a1094":"from sklearn.pipeline import make_pipeline\nacc = []\nprecisions=[]\nfor n in range(5,10):\n    \n    pipe = make_pipeline(StandardScaler(), RidgeClassifier())\n\n    # Note the results will vary each run since we take a different\n    # subset of the data each time (since shuffle=True)\n    scores = np.mean(cross_val_score(pipe, X, y, cv=n, scoring='accuracy'))\n    acc.append(scores)\n    p= np.mean(cross_val_score(pipe, X, y, cv=n, scoring=metrics.make_scorer(metrics.precision_score, average='weighted')))\n    precisions.append(p)\n    print('Mean of Accuracy for all ', str(n), ' folds: ', 'Scores: ', scores)\n    print('Mean of Precision ', str(n), ' folds: ', 'Precision: ', p)\n\n# plot to see clearly\nplt.plot(range(5,10), acc)\nplt.xlabel('n split')\nplt.ylabel('Mean of Accuracy for all folds')\nplt.show();\nplt.plot(range(5,10), precisions)\nplt.xlabel('n split')\nplt.ylabel('Weighted Average Precision')\nplt.show();","1af50240":"# Parameter Tuning with ridge error\ndef rmse_ridge(ridge_model):\n    ridge_model.fit(X_train, y_train)\n    ridge_pre = ridge_model.predict(X_test)\n    squared = np.square(ridge_pre-y_test)\n    ridge_error = np.sqrt(np.sum(squared)\/len(y_test))\n    return(ridge_error)\n\nalphas = [0.01, 0.02, 0.1, 0.3, 1, 3, 5, 10, 20, 30,40,100]\ncv_ridge = [rmse_ridge(RidgeClassifier(alpha = alpha )).mean() \n            for alpha in alphas]\n\ncv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \" Parameter tuning - Ridge\")\ncv_ridge.min()","9b8eb8fe":"import joblib\njoblib.parallel_backend('threading')\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\n\npipe=make_pipeline(StandardScaler(),RidgeClassifier()) #, class_weight='balanced'\n\ngrid_search = GridSearchCV(\n    pipe, \n    {'ridgeclassifier__alpha': range(0,100)},  # Tried [0, 0.001, 0.01, 0.1, 0.5, 1, 1.5, 100] as well\n    cv=StratifiedKFold(10, random_state=10, shuffle=True),\n    scoring=metrics.make_scorer(metrics.recall_score), # maximise recall to minimise FN\n    return_train_score=True,\n    n_jobs=-1,\n    verbose=3)\n\n#X_sc = scaler.transform(X)  # can use this if I don't use pipe\ngrid_search.fit(X, y)\ngrid_search.best_estimator_","e3a031ee":"# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Ridge with alpha = 0\nridge = RidgeClassifier(alpha=0) #, class_weight='balanced'\nridge.fit(X_train, y_train)","efe1aecd":"print('Train Accuracy :',ridge.score(X_train, y_train))\nprint('Test Accuracy: ',ridge.score(X_test, y_test))","f690518e":"confisuon_matrix_summary_ridge(y_test, ridge)","c38aaf74":"y_pred = ridge.predict(X_test)\nverify_performance(y_test, y_pred, ridge)","43674e39":"# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Ridge with alpha = 0\nridge = RidgeClassifier(alpha=0, class_weight='balanced')\nridge.fit(X_train, y_train)","9e47d2a4":"print('Train Accuracy :',ridge.score(X_train, y_train))\nprint('Test Accuracy: ',ridge.score(X_test, y_test))","fe53435f":"confisuon_matrix_summary_ridge(y_test, ridge)","d2567ef2":"y_pred = ridge.predict(X_test)\nverify_performance(y_test, y_pred, ridge)","aca38fa5":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\n\n# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nknn = KNeighborsClassifier(n_neighbors=14)\nknn.fit(X_train, y_train)","bde31c37":"print('Train Accuracy :',knn.score(X_train, y_train))\nprint('Test Accuracy: ',knn.score(X_test, y_test))","52a5127d":"most_freq_class = y_train.value_counts().index[0]\n#Compute null accuracy.\ny_test.value_counts()[most_freq_class] \/ len(y_test)","e8a6ccfa":"confisuon_matrix_summary(y_test, knn, 0.5)","e1b59ba9":"knn_pred_proba = knn.predict_proba(X_test)[:,1]\nverify_performance(y_test, knn_pred_proba > .5, knn)","e0712cad":"scores = []\nfor k in range(1,101):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train,y_train)\n    pred = knn.predict(X_test)\n    # Score with accuracy\n    score = float(sum(pred == y_test)) \/ len(y_test)\n    scores.append([k, score])","99e6233e":"#maximize accuracy\ndata = pd.DataFrame(scores,columns=['k','score'])\ndata.plot.line(x='k',y='score');","2c7fb33d":"scores = []\nfor k in range(1,101):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train,y_train)\n    pred = knn.predict(X_test)\n    # Score with precision\n    score = metrics.precision_score(y_test,knn.predict(X_test))\n    scores.append([k, score])","e3cabcdc":"#miximize precision\ndata = pd.DataFrame(scores,columns=['k','score'])\ndata.plot.line(x='k',y='score');","149b2c94":"# Calculate TRAINING ERROR and TESTING ERROR for K=1 through 100\n\nk_range = list(range(1, 101))\ntraining_error = []\ntesting_error = []\n\n# Find test accuracy for all values of K between 1 and 100 (inclusive).\nfor k in k_range:\n\n    # Instantiate the model with the current K value.\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    \n    # Calculate training error (error = 1 - accuracy).\n    y_pred_class = knn.predict(X_train)\n    training_accuracy = metrics.accuracy_score(y_train, y_pred_class)\n    training_error.append(1 - training_accuracy)\n    \n    # Calculate testing error.\n    y_pred_class = knn.predict(X_test)\n    testing_accuracy = metrics.accuracy_score(y_test, y_pred_class)\n    testing_error.append(1 - testing_accuracy)","50c307d1":"# Create a DataFrame of K, training error, and testing error.\ncolumn_dict = {'K': k_range, 'training error':training_error, 'testing error':testing_error}\ndf = pd.DataFrame(column_dict).set_index('K').sort_index(ascending=False)\ndf.head()","15bc7ccf":"# Plot the relationship between K (HIGH TO LOW) and TESTING ERROR.\n# Best k number is where Testing error is min\ndf.plot(y='testing error');\nplt.xlabel('Value of K for KNN');\nplt.ylabel('Error (lower is better)');","01536a37":"min(list(zip(testing_error, k_range)))","37bfa0f1":"# Plot the relationship between K (HIGH TO LOW) and both TRAINING ERROR and TESTING ERROR.\ndf.plot();\nplt.xlabel('Value of K for KNN');\nplt.ylabel('Error (lower is better)');\n","1722231a":"from sklearn.pipeline import make_pipeline\nk_scores = []\n\n# choose k between 1 to 49, step 2 to get odds\n# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\nfor k in range(1, 100):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    pipe = make_pipeline(StandardScaler(), knn)\n    cv=StratifiedKFold(5, random_state=10, shuffle=True)\n    scores = cross_val_score(pipe, X, y, cv=cv, scoring=metrics.make_scorer(metrics.recall_score)) #scoring=metrics.make_scorer(metrics.precision_score)\n    k_scores.append(scores.mean())\n\n# plot to see clearly\nplt.plot(range(1, 100), k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Recall')\nplt.show();","8c49af97":"max_acc = max(k_scores)\nfor i, acc in zip(range(1, 100), k_scores):\n    if acc == max_acc:\n        print('k: ', i)\n        print('max_recall: ', acc)","eaba4506":"# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)","083c1ce9":"print('Train Accuracy :',knn.score(X_train, y_train))\nprint('Test Accuracy: ',knn.score(X_test, y_test))","ffe5a49d":"confisuon_matrix_summary(y_test, knn, 0.5)","e1aa1386":"knn_pred_proba = knn.predict_proba(X_test)[:,1]\nverify_performance(y_test, knn_pred_proba > .5, knn)","ec6aaa77":"from sklearn.ensemble import RandomForestClassifier\n\n# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\n#Create a Random Forest Classifier\nrfc=RandomForestClassifier(n_estimators=100, random_state = 42)\n\n#Train the model using the training sets\nrfc.fit(X_train,y_train)","1d24a45e":"print('Train Accuracy :',metrics.accuracy_score(y_train, rfc.predict(X_train)))\nprint('Test Accuracy: ',metrics.accuracy_score(y_test, rfc.predict(X_test)))","b64649c8":"confisuon_matrix_summary(y_test, rfc, 0.5)","f36fc7ae":"rfc_pred_proba = rfc.predict_proba(X_test)[:,1]\nverify_performance(y_test, rfc_pred_proba > .5, rfc)","52d47c9c":"n_estimators = [100, 200, 300]\nmax_depth = [5, 10,  25]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 5, 10]\n#ccp_alpha = [0, 0.01, 0.1, 1]\n\nhyperF = dict(n_estimators = n_estimators, \n              max_depth = max_depth, \n              min_samples_split = min_samples_split, \n              min_samples_leaf = min_samples_leaf)\n             # ccp_alpha = ccp_alpha)\n\ngrid_search = GridSearchCV(RandomForestClassifier(), \n                           hyperF, \n                           cv=StratifiedKFold(5, random_state=10, shuffle=True),\n                           scoring=metrics.make_scorer(metrics.recall_score),\n                           verbose = 3, \n                           n_jobs = -1)\n\ngrid_search.fit(X, y)\ngrid_search.best_estimator_","258c034c":"grid_search.best_estimator_","9e298363":"from sklearn.ensemble import RandomForestClassifier\n\n# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\n#Create a Random Forest Classifier\nrfc=RandomForestClassifier(n_estimators=200, \n                           max_depth=25, \n                          # min_samples_leaf=5, \n                           min_samples_split=5, \n                           random_state = 42)\n\n#Train the model using the training sets \nrfc.fit(X_train,y_train)","f947f006":"print('Train Accuracy :',metrics.accuracy_score(y_train, rfc.predict(X_train)))\nprint('Test Accuracy: ',metrics.accuracy_score(y_test, rfc.predict(X_test)))","1d0506a8":"confisuon_matrix_summary(y_test, rfc, 0.5)","c5fdfc96":"print('Train Accuracy :',metrics.accuracy_score(y_train, rfc.predict(X_train)))\nprint('Test Accuracy: ',metrics.accuracy_score(y_test, rfc.predict(X_test)))","5831b9af":"confisuon_matrix_summary(y_test, rfc, 0.5)","f60b8d30":"rfc_pred_proba = rfc.predict_proba(X_test)[:,1]\nverify_performance(y_test, rfc_pred_proba > .5, rfc)","87aac54b":"import xgboost as xgb\n\n# set x and y\nX = bankchurners_df.drop('churn', axis = 1)\ny = bankchurners_df['churn']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, stratify=y)\n\n# Create xgboost model\nm_xgb = xgb.XGBClassifier(n_estimators=200,\n                       max_depth=2, random_state=42)\n\n#Train the model using the training sets\nm_xgb.fit(X_train,y_train)","e299e913":"print('Train Accuracy :',metrics.accuracy_score(y_train, m_xgb.predict(X_train)))\nprint('Test Accuracy: ',metrics.accuracy_score(y_test, m_xgb.predict(X_test)))","db2270f7":"confisuon_matrix_summary(y_test, m_xgb, 0.5)","04fb6fef":"xgb_pred_proba = m_xgb.predict_proba(X_test)[:,1]\nverify_performance(y_test, xgb_pred_proba > .5, rfc)","48ec8e5b":"#### Get dummies for rest of the categorical features.","950ab864":"## Import Libraries & Data","c398ef13":"Now built the model with k=1 to find best recall for KNN.","2a70aebf":"# *Exploratory Data Analysis*","8c0f0d1b":"Let's start with simple KNN model.","dae7b879":"# Result","2cd5c176":"First let's built and try it on simple model.","ea266390":"### Ridge Classifier","5d93313c":"#### Parameter Tuning with GridSearch","9b0d6dc8":"`Months_on_book` seems like correlated with `Customer_Age` .\n\n`Total Transaction Count` is correlated with `Total Transaction Amount`.","4d468c18":"Let's see if we can improve our model by changing our parameters!","d08c2713":"![download.jpeg](attachment:download.jpeg)","d63eb827":"* **Maximize recall:** best value found in **alpha = 0**\n* **Maximize precision:** best value found **in alpha = 97**\n* **Maximize accuracy:** best value found **in alpha = 5**\n\nLet's run the model with those alphas to see if we going to get any better recall, precision or accuracy.","c2ecbae4":"## Feature Engineering","14e415b9":"Change categorical Attrition_Flag feature to numerical feature and rename it as churn.","b096477b":"Let's start with simple random forest mode. I'm bit scared that It'll overfit but c'est la vie.. :)","acd79af9":"XGBoost gave the best recall score, precision and accuracy!","2f635d02":"**Maximize precision:** best value found in **k=99**","25a3270d":"We got this! Recall: 0.9164, Precision: 0.9395, Accuracy: 0.9770 is pretty good model! I haven't tuned the model but it could be done for next step. Result seems very good!","be859f59":"### Logistic Regression","6a38ea4d":"Logistic Regresion:\n* **Recall**: 0.5773\n* **Precison** Score: 0.7669\n* **Accuracy**: 0.9040\n\nRidge Classifier:\n* **Recall**: 0.4742\n* **Precison** Score: 0.8772\n* **Accuracy**: 0.9048\n\nKNN:\n* **Recall**: 0.5012\n* **Precison** : 0.6017\n* **Accuracy**: 0.8665\n\nRandom Forest:\n* **Recall**: 0.8402\n* **Precison** : 0.9395\n* **Accuracy**: 0.9656\n\nXGBoost:\n* **Recall**: 0.9164\n* **Precison** : 0.9395\n* **Accuracy**: 0.9770\n\n","1c9ac7da":"We can see in the card category, generally clients use Blue card.","1ac6e9d7":"Oh awesome, we are getting somewhere! Recall is 0.823 yeey! Let's tune this bad boi and see if we can increase this!","c128c388":"This one is interesting that found in above pairplot of numerical columns, people who churned from credit card service, had less transaction count and transaction amount!\n","9dc6848f":"I can't complain for this at all! 0.84 recall score and 0.9395 precison and 0.9656 accuracy is pretty good! \n\nBut almost there, lastly I want to try it with more advanced model! Queen XGBoost!","c4be3c4a":"As we can see here, dataset is not equally distribute according to Attrition_Flag. Only **16.07%** of customers who have churned among 10k clients.","d052f436":"We didn't get better recall value, actualy it was worse than previous logistic regression model(recall was 0.5773 in logreg) and now we got 0.4742 recall with ridge. Let's look at another model!","17160185":"### KNN Classifier","fd1cba86":"## List Variables","00a99b9f":"Convert income category to numerical values(preferred to give order depending on their income category instead of get dummies to avoid increasing the dataset size)","420f3f56":"# Predict Credit Card Churning Customers","18fafb1e":"![algorithms.jpg](attachment:algorithms.jpg)","c32fd463":"Here we can see all numerical columns and Attrition_Flag distribution","1ca515a3":"0.5012 is not what we are looking for, I believe we can find better recall! Let's look at another model!","8b30c4bf":"### XGBoost","5813faf6":"* **Problem Statement:** A bank manager is uncomfortable with more and more customers leaving their credit card services. \n\n* **Goal:** Predict customers who are likely drop off from credit card services(going to churn) for a bank so that they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction.\n\n* **Advantage:** Data is clean, so relatively less time to spend on data cleaning and more time on modelling\n\n* **Disadvantage:** Data is unbalanced; only 16.07% of customers churned. Thus, it's a bit difficult to train our model to predict churning customers.\n","7e287809":"## Check Correlation","5eb32692":"#### Examine the correlations between the features and the target.","206960dd":"Now let's try to tune parameters and see if we going to get better recall.","c12de036":"## Modelling","5f1b079b":"#### Parameter Tuning with GridSearch","62a3951a":"![2u8f8m.jpg](attachment:2u8f8m.jpg)","23832369":"Yup! It did overfit, but good new is test set prediction doesn't look bad at all!","2c4dcfc6":"#### Check corralated features with eachother","f31986d6":"## About Data\n**10127 rows x 21 columns**\n\n**7 categorical features**\n* Customer_id\n* Attrition_Flag (1: Existing Customer, 0: Attrited Customer): The Customer leave or not\n* Gender (1: Male, 0: Female)\n* Education_Level (Graduate , High School, Unknown, Uneducated, College, Post-Graduate, Doctorate)\n* Marital_Status (Married, Single, Unknown, Divorced)\n* Income_Category (Less than 40K, 40K - 60K, 80K - 120K, 60K - 80K, Unknown, 120K +) in dollar\n* Card_Category (Blue, Silver, Gold, Platinum)\n\n**14 numerical features:**\n* Customer_Age: Customer's Age in Years\n* Dependent_count: Number of dependents\n* Months_on_book: Period of relationship with bank\n* Total_Relationship_Count: Total no. of products held by the customer\n* Months_Inactive_12_mon: No. of months inactive in the last 12 months\n* Contacts_Count_12_mon: No. of Contacts in the last 12 months\n* Credit_Limit: Credit Limit on the Credit Card\n* Total_Revolving_Bal: Total Revolving Balance on the Credit Card\n* Avg_Open_To_Buy: Open to Buy Credit Line (Average of last 12 months)\n* Total_Amt_Chng_Q4_Q1: Change in Transaction Amount (Q4 over Q1)\n* Total_Trans_Amt: Total Transaction Amount (Last 12 months)\n* Total_Trans_Ct: Total Transaction Count (Last 12 months)\n* Total_Ct_Chng_Q4_Q1: Change in Transaction Count (Q4 over Q1)\n* Avg_Utilization_Ratio: Average Card Utilization Ratio\n","144ef73c":"### Random Forest","c78f792c":"We can see in above plots, with different attrention_flag, how our categorical values change and also can see in which categiries we seeing churning customers the most.\n\n* **%93.17** of churned clients have Blue card\n* **%35.15** of churned clients have less than $40K \n* **%46.28** of churned clients are married\n* **%30.88** of churned clients have graduate education level","3239d891":"**Maximize recall:** scoring=metrics.make_scorer(metrics.recall_score) best value found in **k=1**\n\n**Maximize precision:** scoring=metrics.make_scorer(metrics.precision_score) best value found in **k=99**\n\n**Maximize accuracy:** scoring='accuracy' best value found in** k=5 and 7**","067108b0":"This isn't the best recall, let's check another model!","32c2a510":"**Maximize accuracy:** best value found in **k=5**","9d27748f":"Let's create simple Ridge model","4d254d92":"Let's try out new model with better parameters to get better recall score.","5d0fbb70":"Seems like chaning treshtold didn't increase out precision, let's try another algorithm","b7fefd15":"I am going to apply **5 Supervised Machine Learning models** on the given dataset to predict churning customers.\n\nThe strategy is to apply default model first with no tuning of the hyperparameter and then tuned them with different hyperparameter values and compare them by their \"**Recall**\" value because goal is to **decrease False Negative number** because **we don\u2019t want to lose any client**. If client churns, we want to predict correctly (as churned = 1). High Recall\/Sensitivity has a low False Negative rate, so that we want to increase Recall.\n\nThe models used are as follows: \n1. **Logistic Regression**\n2. **Ridge Classifier**\n3. **KNeighborsClassifier**\n4. **Random Forest**\n5. **XGBoost**","c8705de0":"Training error decreases as model complexity increases (lower value of K).\n\nTesting error is minimized at the optimum model complexity."}}