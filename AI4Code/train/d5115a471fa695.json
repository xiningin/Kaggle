{"cell_type":{"666e0cec":"code","856bbce0":"code","542bbacc":"code","99a9b3d6":"code","5258a3db":"code","523495b4":"code","7b215fe3":"code","8844e61f":"code","5226ae25":"code","ed9bec83":"code","666e7b4b":"code","6fd77449":"code","500a4b64":"code","f0b30415":"code","2f2397ff":"code","efcb4013":"code","9f6bbdd5":"code","e4a2aa8d":"code","af14cf2b":"code","41ce30d7":"code","6003239a":"code","893fd53b":"code","b84be189":"code","89b69fc1":"code","922a7805":"code","aad35040":"code","27009ff3":"code","46f38dc9":"code","e790d8f3":"code","af31edd1":"code","3554ed88":"code","0ef5250b":"code","1a3cf35a":"code","bf286d96":"code","58d30ac2":"code","6f87b661":"code","7448f1dd":"code","e89dce5e":"code","c0458220":"code","dad549cd":"code","f3e113eb":"code","ce3b9910":"code","10bc256d":"code","5b1ab5d1":"code","86806830":"code","d3112293":"code","1bbae324":"code","9c78a5a0":"code","498c185d":"code","42737daf":"code","9e38a844":"code","f0105973":"code","4684ad1c":"code","62f77980":"code","11c62423":"code","852a9881":"code","803ff2a6":"code","4ccbc406":"code","d6b52dd9":"code","37aeede2":"code","1df681fb":"code","d0461ee9":"code","001fce85":"code","9eb065b7":"code","8e6e217a":"code","e5987810":"code","635e5202":"code","da5f3bc2":"code","bf4c724e":"code","9b28d6f2":"code","eb263a1c":"code","488e4547":"code","2bcbf0d1":"code","3d07f5b9":"code","01f91c18":"code","9e8e7daf":"code","63846a31":"code","8fa0d2e9":"code","4536c6f5":"code","e175ea2b":"code","a5b0dfb6":"code","edb77337":"code","aa9c8cfc":"code","8285626c":"code","1b64966e":"code","c2a0ed69":"code","9f2e2260":"code","16a6c577":"code","b15bfe50":"markdown","0d3f442c":"markdown","31cc6cfd":"markdown","de006f63":"markdown","710e41f9":"markdown","b88f2014":"markdown","f0684876":"markdown","5f5d14e0":"markdown","e7355bdf":"markdown","1549cfd3":"markdown","7b74cb2e":"markdown","0317d8e5":"markdown","69ef20d2":"markdown","aab43b4a":"markdown","bc2d4182":"markdown","c3a342f8":"markdown","33474100":"markdown","031be854":"markdown","87f6edf7":"markdown","4b3cb037":"markdown","b4d59d14":"markdown","95698314":"markdown","e21e529c":"markdown","fdfc6c3e":"markdown","6989feec":"markdown","4db48dbf":"markdown","bc398dea":"markdown","9ac81ca4":"markdown","f0326e98":"markdown","2e798e98":"markdown","dca6348e":"markdown","cf6a0d75":"markdown","e9fb1687":"markdown","99b0dcc9":"markdown","869ee83d":"markdown","ca3fa8b8":"markdown","e65360a2":"markdown","900e309d":"markdown","df02e514":"markdown","96cdd47e":"markdown","dad88cce":"markdown","20aa6194":"markdown","44522fd3":"markdown","8dd3970f":"markdown","4addbf1f":"markdown","24ec16c2":"markdown","48437f73":"markdown","15c34fd7":"markdown","23fe3836":"markdown","75fc8531":"markdown","95c65d0c":"markdown","dbce0894":"markdown","584b6324":"markdown","dc1083b0":"markdown","aef5430f":"markdown","07332288":"markdown","d074bbcf":"markdown","1eac71e2":"markdown","9ccf8c48":"markdown","c91fd606":"markdown","a724e4fd":"markdown","61a5ce69":"markdown","fe60bfce":"markdown","cad7e98a":"markdown","bca6b94c":"markdown"},"source":{"666e0cec":"from IPython.display import Image\nImage(\"..\/input\/images\/Images\/Covid-19.png\")","856bbce0":"import pandas as pd\n# import requests\n# import bs4\n# from urllib.request import Request, urlopen\n# from urllib.request import urlopen as uReq\n# from bs4 import BeautifulSoup as soup\n# import pandas as pd","542bbacc":"pd.read_excel('..\/input\/covid-predictions\/covid_data\/Data\/meta\/covid_data.xlsx')","99a9b3d6":"# Use this code in your notebook and it'll fetch data directly from ncov2019 website. For this notebook. I'm using a copy \n#of the same\n\n# # grabbing the url\n\n# url = \"https:\/\/ncov2019.live\/\"\n# req = Request(url, headers={\"User-Agent\" : \"Mozilla\/5.0\"})\n\n# webpage = urlopen(req).read()\n\n# #parsing it as lxml\n# pagesoup = soup(webpage,\"lxml\")\n\n\n#finding the relevant tags to scrap the data from website\n\n# website_name = pagesoup.find('a',class_ = \"navbar-brand\")\n# link = \"https:\/\/ncov2019.live\/\"\n# Markdown('<strong>{}<\/strong>{}'.format(website_name.text,link))\n\n#some quick facts from the website\n\n# quickfacts = pagesoup.find('div', class_ = \"container--wrap bg-navy-4\")\n# Markdown('<strong align=\"center\">{}<\/strong>'.format(quickfacts))","5258a3db":"# Use this code in your notebook and it'll fetch data directly from ncov2019 website. For this notebook. I'm using a copy \n#of the same\n\n# # grabbing latest worldwide data\n\n# url = \"https:\/\/ncov2019.live\/data\/world\"\n\n# r = requests.get(url)\n# df_list = pd.read_html(r.text)            #this parse all html tables from a webpage to alist\n# world_df = df_list[2]\n# world_df","523495b4":"#Saved Data\n\nworld_df = pd.read_csv('..\/input\/covid-predictions\/covid_data\/Data\/Covid-19\/ncov2019_data.csv')\nworld_df.head()","7b215fe3":"# We will now sort the countries based on total confirmed cases column\n\nworld_df = world_df.sort_values(\"Confirmed\" , ascending = False)\n\n\n\n#Lets get top 10 affected countries\n\n# world_df.head(10)\n","8844e61f":"world_df.info()","5226ae25":"#We can also visualize the same using seaborn\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ed9bec83":"plt.figure(figsize=(15,10))\nsns.heatmap(world_df.isnull())","666e7b4b":"import plotly.express as px\n# import chart_studio.plotly as py\nimport plotly.graph_objs as go \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot","6fd77449":"init_notebook_mode (connected = True)","500a4b64":"# plotting world_df based on confirmed cases by country names.\n\nworld_fig = px.bar(world_df, x = 'Name' , y = 'Confirmed')\nworld_fig.show()","f0b30415":"# Lets plot top 20 countries based on confirmed cases.\n\nworld_fig = px.bar(world_df.head(20), x = \"Name\" , y = 'Confirmed')\nworld_fig.show()","2f2397ff":"# Lets see how many people have died with respect to countries. (For top 20 countries)\n\nworld_fig = px.bar(world_df.head(20), x = 'Name', y = 'Confirmed', color = \"Deceased\")\nworld_fig.show()","efcb4013":"# lets grab the world_df based on deceased column.\nworld_df.sort_values('Deceased',ascending = False)","9f6bbdd5":"# lets replace unknown values to 0.\n\nworld_df['Deceased'].replace(\"Unknown\", 0,inplace=True)\nworld_df['Deceased'] = pd.to_numeric(world_df['Deceased'])          #convert column from type object to int64\nworld_df['Deceased']","e4a2aa8d":"# now again lets grab world_df based on deceased column.\n\nworld_df.sort_values('Deceased',ascending = False)","af14cf2b":"# lets again try ro visualize world_df based on death poll for top 20 countries.\n\nworld_fig = px.bar(world_df.sort_values('Deceased', ascending=False).head(20), x = 'Name' , y = 'Deceased')\nworld_fig.show()\n","41ce30d7":"# lets visualize the death toll based on total confirmed case\n\nimport plotly.graph_objects as go\n\n\n# for grouped barplot using Deceased numbers per country and total number of cases per country.\n\nfig = go.Figure(data = [\ngo.Bar(\n    x = world_df['Name'],\n    y = world_df[\"Deceased\"].head(20),\n    name = \"Deceased\",\n    marker_color = \"indianred\"\n),\ngo.Bar(\n    x = world_df['Name'],\n    y = world_df['Confirmed'].head(20),\n    name = 'Confirmed',\n    marker_color = \"lightsalmon\"\n)\n])\n\n# Here we modify the tickangle of the xaxis, resulting in rotated labels.\nfig.update_layout(barmode='group')\nfig.show()","6003239a":"# lets visualize the recovered case based in relation to total confirmed case\n\nimport plotly.graph_objects as go\n\n\n# for grouped barplot using recovered cases per country and total number of cases per country.\n\nfig = go.Figure(data = [\ngo.Bar(\n    x = world_df['Name'],\n    y = world_df[\"Recovered\"].head(20),\n    name = \"Recovered\",\n    marker_color = \"indianred\"\n),\ngo.Bar(\n    x = world_df['Name'],\n    y = world_df['Confirmed'].head(20),\n    name = 'Confirmed',\n    marker_color = \"lightsalmon\"\n)\n])\n\n# Here we modify the tickangle of the xaxis, resulting in rotated labels.\nfig.update_layout(barmode='group')\nfig.show()","893fd53b":"# replace unknown values from the column\n\nworld_df['Tests'].replace(\"Unknown\", 0, inplace=True)\nworld_df['Tests'] = pd.to_numeric(world_df['Tests'])          #convert column from type object to int64\n\n\n\n#Now lets plot the data\n\nworld_fig = px.bar(world_df.sort_values('Tests', ascending=False).head(20), x = 'Name' , y = 'Tests')\nworld_fig.show()","b84be189":"# lets visualize the confirmed case based in relation to total population\n\nimport plotly.graph_objects as go\n\n\n# for grouped barplot using confirmed cases per country and population per country.\n\nfig = go.Figure(data = [\ngo.Bar(\n    x = world_df['Name'],\n    y = world_df[\"Confirmed\"].head(20),\n    name = \"Confirmed\",\n    marker_color = \"indianred\"\n),\ngo.Bar(\n    x = world_df['Name'],\n    y = world_df['Population'].head(20),\n    name = 'Population',\n    marker_color = \"lightsalmon\"\n)\n])\n\n# Here we modify the tickangle of the xaxis, resulting in rotated labels.\nfig.update_layout(barmode='group')\nfig.show()","89b69fc1":"#Mortality calculation\n\nworld_df['mortality'] = world_df[['Confirmed','Deceased']].apply(lambda x: (x['Deceased']*100\/x['Confirmed']),axis=1 )\n\n#Recovery calculation\n\nworld_df['Recovered'] = pd.to_numeric(world_df['Recovered'],errors='coerce')\nworld_df['recovery'] = world_df[['Confirmed','Recovered']].apply(lambda x: (x['Recovered']*100\/x['Confirmed']),axis=1 )","922a7805":"def recovery_mortality_plot():\n    \n    name = ['recovery','mortality']\n    Value=[True,False]\n    \n    for i,j in zip(name,Value):\n        \n        world_fig = px.bar(world_df.sort_values(i, ascending=j).head(50), x = 'Name' , y = i)\n        world_fig.show()\n        \nrecovery_mortality_plot()","aad35040":"#something worng with the country names. plotly uses standard ISO-3_codes. Lets try to create a column for country codes\n\nprint(\"{} countries in the list.\". format(world_df['Name'].nunique()))","27009ff3":"!pip install country_converter","46f38dc9":"import country_converter as coco","e790d8f3":"# Creating a list and appending all the names from world_df column.\n\nNames = []\nfor i in range(1,215):\n    Names.append(world_df.iloc[i]['Name'][3:])\n\n# Insert Total at index 0. we left that because it doesn't contain any start in it.\n\nNames.insert(0,'TOTAL')","af31edd1":"standard_names = coco.convert(names= Names, to='ISO3')","3554ed88":"map_data = world_df[world_df['Name']!='TOTAL']\nprint(map_data.nunique())\nprint(len(map_data))","0ef5250b":"# Adding the ISO3 code in a new world_df['Code'] column.\n\nmap_data = map_data[:215]\nmap_data['code'] = standard_names\n\nmap_data['code'] = map_data['code'].shift(-1)\n\n# Removing countries of which ISO3 code is not available\n\nchoropleth_data = map_data[map_data['code'] != \"NaN\"]\n# choropleth_data","1a3cf35a":"#lets again try to plot the data using choropleth dataframe.\n\n# For using choropleth first we have to make a dictionary\n\ndata = dict(\n        type = 'choropleth',\n        locations = choropleth_data['code'],\n        z = choropleth_data['Confirmed'],\n        text = choropleth_data['Deceased'],\n        marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n        colorbar = {'title' : \"Confirmed Cases\"}\n        )","bf286d96":"# Now create a layout for the graph\n\nlayout = dict(\n    \n    title = 'World COVID-19 Stats',\n    width=1080,\n    height=900,\n    geo = dict(\n        showframe = False,\n        projection = {'type':'mercator'}\n    )\n    )","58d30ac2":"# Finally we will pass both layout and data dictionary to generate the map.\nchoromap = go.Figure(data = [data],layout = layout)\nchoromap.show()","6f87b661":"# Use this code in your notebook and it'll fetch data directly from ncov2019 website. For this notebook. I'm using a copy \n#of the same\n\n# #grabbing latest canada specific data\n\n# url = \"https:\/\/ncov2019.live\/data\/canada\"\n\n# r = requests.get(url)\n# df_list = pd.read_html(r.text) # this parses all the tables in webpages to a list\n# canada_df = df_list[2]\n# canada_df","7448f1dd":"#Saved Data\n\ncanada_df = pd.read_csv('..\/input\/covid-predictions\/covid_data\/Data\/Covid-19\/ncov2019_canadadata.csv')","e89dce5e":"canada_fig = px.bar(canada_df.sort_values('Confirmed'),x='Name',y='Confirmed',color=\"Deceased\")\ncanada_fig.show()","c0458220":"canada_fig = px.bar(canada_df.sort_values('Recovered'), x = 'Name', y = 'Recovered',color='Confirmed')\ncanada_fig.show()","dad549cd":"fig = go.Figure(data = [\n    go.Bar(\n    x = canada_df['Name'],\n    y = canada_df['Recovered'],\n    name = \"Recovered\"\n    ),\n    \n    go.Bar(\n    x = canada_df['Name'],\n    y = canada_df['Confirmed'],\n    name = \"Confirmed\"\n    )\n])\n\nfig.update_layout(barmode = \"group\")\nfig.show()","f3e113eb":"fig = go.Figure(data = [\n    go.Bar(\n    x = canada_df['Name'],\n    y = canada_df['Deceased'],\n    name = \"Deceased\"\n    ),\n    \n    go.Bar(\n    x = canada_df['Name'],\n    y = canada_df['Confirmed'],\n    name = \"Confirmed\"\n    )\n])\n\nfig.update_layout(barmode = \"group\")\nfig.show()","ce3b9910":"fig = go.Figure(data = [\n    go.Bar(\n    x = canada_df['Name'],\n    y = canada_df['Recovered'],\n    name = \"Recovered\"\n    ),\n    \n    go.Bar(\n    x = canada_df['Name'],\n    y = canada_df['Deceased'],\n    name = \"Deceased\"\n    )\n])\n\nfig.update_layout(barmode = \"group\")\nfig.show()","10bc256d":"# converting columns to int64 format from object dtype\n# canada_df['Deceased'].replace({'Unknown':0},inplace=True)\n# canada_df[['Deceased','Recovered']] = canada_df[['Deceased','Recovered']].apply(pd.to_numeric,errors='ignore')","5b1ab5d1":"#Mortality calculation\n\ncanada_df['mortality'] = canada_df[['Confirmed','Deceased']].apply(lambda x: (x['Deceased']*100\/x['Confirmed']),axis=1 )\n\n#Recovery calculation\n\ncanada_df['Recovered'] = pd.to_numeric(canada_df['Recovered'],errors='coerce')\ncanada_df['recovery'] = canada_df[['Confirmed','Recovered']].apply(lambda x: (x['Recovered']*100\/x['Confirmed']),axis=1 )","86806830":"def recovery_mortality_plot():\n    \n    name = ['recovery','mortality']\n    Value=[True,False]\n    \n    for i,j in zip(name,Value):\n        \n        canada_fig = px.bar(canada_df.sort_values(i, ascending=j).head(50), x = 'Name' , y = i)\n        canada_fig.show()\n        \nrecovery_mortality_plot()","d3112293":"# import confirmed cases data\n\nconfirmed_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')\n\n#Getting all the dates\ncols = confirmed_df.keys()\nconfirmed = confirmed_df.loc[:4,cols[4]:cols[-1]]\n\ndates = confirmed.keys()","1bbae324":"worldcases = []\n\nfor i in ((dates)):\n    \n    confirmed_sum = confirmed[i].sum()\n    \n    worldcases.append(confirmed_sum)","9c78a5a0":"import numpy as np\nimport random\nimport math\nimport time\nfrom sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport datetime","498c185d":"days_in_future = 10\nfuture_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forcast[:-10]","42737daf":"start = '1\/20\/2020'\nstart_date = datetime.datetime.strptime(start, '%m\/%d\/%Y')\nfuture_forcast_dates = []\nfor i in range(len(future_forcast)):\n    future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime('%m\/%d\/%Y'))","9e38a844":"days_from_1_20 = np.array([i for i in range(len(dates))]).reshape(-1,1)","f0105973":"X_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(days_from_1_20[50:], worldcases[50:], test_size=0.15, shuffle=False) ","4684ad1c":"svm_confirmed = SVR(shrinking=True, kernel='poly',gamma=0.01,epsilon=1,degree=3,C=0.1)\nsvm_confirmed.fit(X_train_confirmed,y_train_confirmed)\nsvm_pred = svm_confirmed.predict(future_forcast)","62f77980":"svm_test_pred = svm_confirmed.predict(X_test_confirmed)\nplt.figure(figsize=(20,15))\nplt.plot(y_test_confirmed)\nplt.plot(svm_test_pred)\nplt.legend(['Test Data', 'SVM Predictions'])\nprint('MAE:', mean_absolute_error(svm_test_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(svm_test_pred, y_test_confirmed))","11c62423":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","852a9881":"print('Mean absolute percentage error of SVM is ',mean_absolute_percentage_error(y_test_confirmed,svm_test_pred))","803ff2a6":"# transform our data for polynomial regression\npoly = PolynomialFeatures(degree=5)\npoly_X_train_confirmed = poly.fit_transform(X_train_confirmed)\npoly_X_test_confirmed = poly.fit_transform(X_test_confirmed)\npoly_future_forcast = poly.fit_transform(future_forcast)","4ccbc406":"# polynomial regression\nlinear_model = LinearRegression(normalize=True, fit_intercept=False)\nlinear_model.fit(poly_X_train_confirmed, y_train_confirmed)\ntest_linear_pred = linear_model.predict(poly_X_test_confirmed)\nlinear_pred = linear_model.predict(poly_future_forcast)\nprint('MAE:', mean_absolute_error(test_linear_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(test_linear_pred, y_test_confirmed))\n","d6b52dd9":"print('Mean absolute percentage error of LR is ', mean_absolute_percentage_error(y_test_confirmed,test_linear_pred))","37aeede2":"plt.figure(figsize=(20,15))\nplt.plot(y_test_confirmed)\nplt.plot(test_linear_pred)\nplt.legend(['Test Data', 'Polynomial Regression Predictions'])","1df681fb":"# confirmed_df.head()","d0461ee9":"# Transposing the row for time series analysis\n\nconfirmed_df = confirmed_df.T\nconfirmed_df = confirmed_df.rename(columns=confirmed_df.iloc[1])\n# confirmed_df","001fce85":"confirmed_df = confirmed_df[4:]\n# confirmed_df","9eb065b7":"confirmed_df['Total_cases'] = confirmed_df.sum(axis=1)","8e6e217a":"# converting the index column to date\n\nconfirmed_df.reset_index(level=0,inplace=True)\n# confirmed_df","e5987810":"confirmed_df['dates'] = pd.to_datetime(confirmed_df['index'])\n# confirmed_df.info()","635e5202":"time_series_analysis_df = confirmed_df[['Total_cases','dates']]\n# time_series_analysis_df","da5f3bc2":"# Now we will set the dates column as the index of the dataframe to allow us really explore the our data.\n\ntime_series_analysis_df = time_series_analysis_df.set_index('dates')\ntime_series_analysis_df","bf4c724e":"from pandas import read_csv\nfrom matplotlib import pyplot\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nplt.style.use('fivethirtyeight')","9b28d6f2":"#save your file\n\n# path = r'C:\\Users\\yrsin\\Desktop\\Fall2020\\databasemanagement\\Homework\\CPSC-671\\covid_data\\Data\\Covid-19'\n# time_series_analysis_df.to_csv(path+'\\series.csv')","eb263a1c":"# load dataset\nseries = pd.read_csv('..\/input\/covid-predictions\/covid_data\/Data\/Covid-19\/series.csv', header=0, index_col=0)\nvalues = series.values\n# plot dataset\npyplot.plot(values)\npyplot.title('Total Cases')\npyplot.show()","488e4547":"# forecast monthly births with xgboost\nfrom numpy import asarray\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\nfrom matplotlib import pyplot\n\n# transform a time series dataset into a supervised learning dataset\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n\tn_vars = 1 if type(data) is list else data.shape[1]\n\tdf = DataFrame(data)\n\tcols = list()\n\t# input sequence (t-n, ... t-1)\n\tfor i in range(n_in, 0, -1):\n\t\tcols.append(df.shift(i))\n\t# forecast sequence (t, t+1, ... t+n)\n\tfor i in range(0, n_out):\n\t\tcols.append(df.shift(-i))\n\t# put it all together\n\tagg = concat(cols, axis=1)\n\t# drop rows with NaN values\n\tif dropnan:\n\t\tagg.dropna(inplace=True)\n\treturn agg.values\n\n# split a univariate dataset into train\/test sets\ndef train_test_split(data, n_test):\n\treturn data[:-n_test, :], data[-n_test:, :]\n\n# fit an xgboost model and make a one step prediction\ndef xgboost_forecast(train, testX):\n\t# transform list into array\n\ttrain = asarray(train)\n\t# split into input and output columns\n\ttrainX, trainy = train[:, :-1], train[:, -1]\n\t# fit model\n\tmodel = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n\tmodel.fit(trainX, trainy)\n\t# make a one-step prediction\n\tyhat = model.predict(asarray([testX]))\n\treturn yhat[0]\n\n# walk-forward validation for univariate data\ndef walk_forward_validation(data, n_test):\n\tpredictions = list()\n\t# split dataset\n\ttrain, test = train_test_split(data, n_test)\n\t# seed history with training dataset\n\thistory = [x for x in train]\n\t# step over each time-step in the test set\n\tfor i in range(len(test)):\n\t\t# split test row into input and output columns\n\t\ttestX, testy = test[i, :-1], test[i, -1]\n\t\t# fit model on history and make a prediction\n\t\tyhat = xgboost_forecast(history, testX)\n\t\t# store forecast in list of predictions\n\t\tpredictions.append(yhat)\n\t\t# add actual observation to history for the next loop\n\t\thistory.append(test[i])\n\n\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n\t# estimate prediction error\n\terror = mean_absolute_error(test[:, -1], predictions)\n\treturn error, test[:, -1], predictions\n\n# load the dataset\nseries = read_csv('..\/input\/covid-predictions\/covid_data\/Data\/Covid-19\/series.csv', header=0, index_col=0)\nvalues = series.values\n# transform the time series data into supervised learning\ndata = series_to_supervised(values, n_in=10)\n# evaluate\nmae, y, yhat = walk_forward_validation(data, 71)\nprint('MAE: %.3f' % mae)\n# plot expected vs preducted\npyplot.plot(y, label='Expected')\npyplot.plot(yhat, label='Predicted')\npyplot.xlabel(\"Forecasting from September\")\npyplot.legend()\npyplot.show()","2bcbf0d1":"print('Mean absolute percentage error of XGBosst is',mean_absolute_percentage_error(y,yhat))","3d07f5b9":"from pandas import concat\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nfrom matplotlib import pyplot\nimport numpy\nfrom pandas import datetime","01f91c18":"X = time_series_analysis_df.values\ntrain, test = X[0:230], X[230:]\nprint(train.shape, test.shape)\n\n# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n\t# make prediction\n\tpredictions.append(history[-1])\n\t# observation\n\thistory.append(test[i])\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\n\nprint('RMSE: %.3f' % rmse)\nprint(mean_absolute_percentage_error(test,predictions))\nfrom matplotlib import pyplot\n\n# line plot of observed vs predicted\npyplot.plot(test,label='Test')\npyplot.plot(predictions, label = 'Predictions')\nplt.legend(labels=('Test','Predictions'))\npyplot.show()","9e8e7daf":"def parser(x):\n    return datetime.strptime(x,'%Y-%m-%d')\n\ndef timeseries_to_supervised(data, lag=1):\n    df = pd.DataFrame(data)\n    columns = [df.shift(i) for i in range(1, lag+1)]\n    columns.append(df)\n    df = concat(columns, axis=1)\n    df.fillna(0, inplace=True)\n    return df\n\ndef difference(dataset, interval=1):\n\tdiff = list()\n\tfor i in range(interval, len(dataset)):\n\t\tvalue = dataset[i] - dataset[i - interval]\n\t\tdiff.append(value)\n\treturn Series(diff)\n\ndef inverse_difference(history, yhat, interval=1):\n\treturn yhat + history[-interval]\n\ndef scale(train, test):\n\t# fit scaler\n\tscaler = MinMaxScaler(feature_range=(-1, 1))\n\tscaler = scaler.fit(train)\n\t# transform train\n\ttrain = train.reshape(train.shape[0], train.shape[1])\n\ttrain_scaled = scaler.transform(train)\n\t# transform test\n\ttest = test.reshape(test.shape[0], test.shape[1])\n\ttest_scaled = scaler.transform(test)\n\treturn scaler, train_scaled, test_scaled\n \n# inverse scaling for a forecasted value\ndef invert_scale(scaler, X, value):\n\tnew_row = [x for x in X] + [value]\n\tarray = numpy.array(new_row)\n\tarray = array.reshape(1, len(array))\n\tinverted = scaler.inverse_transform(array)\n\treturn inverted[0, -1]\n\n# fit an LSTM network to training data\ndef fit_lstm(train, batch_size, nb_epoch, neurons):\n\tX, y = train[:, 0:-1], train[:, -1]\n\tX = X.reshape(X.shape[0], 1, X.shape[1])\n\tmodel = Sequential()\n\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n\tmodel.add(Dense(1))\n\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n\tfor i in range(nb_epoch):\n\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n\t\tmodel.reset_states()\n\treturn model\n \n# make a one-step forecast\ndef forecast_lstm(model, batch_size, X):\n\tX = X.reshape(1, 1, len(X))\n\tyhat = model.predict(X, batch_size=batch_size)\n\treturn yhat[0,0]\n\n\nseries = pd.read_csv('..\/input\/covid-predictions\/covid_data\/Data\/Covid-19\/series.csv', header = 0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\nprint(series.head())\n\n\nraw_values = series.values\ndiff_values = difference(raw_values, 1)\n \n# transform data to be supervised learning\nsupervised = timeseries_to_supervised(diff_values, 1)\nsupervised_values = supervised.values\n \n# split data into train and test-sets\ntrain, test = supervised_values[0:230], supervised_values[230:]\n \n# transform the scale of the data\nscaler, train_scaled, test_scaled = scale(train, test)\n \n# fit the model\nlstm_model = fit_lstm(train_scaled, 1, 1500, 1)\n# forecast the entire training dataset to build up state for forecasting\ntrain_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\nlstm_model.predict(train_reshaped, batch_size=1)\n \n# walk-forward validation on the test data\npredictions = list()\nfor i in range(len(test_scaled)):\n\t# make one-step forecast\n\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n\tyhat = forecast_lstm(lstm_model, 1, X)\n\t# invert scaling\n\tyhat = invert_scale(scaler, X, yhat)\n\t# invert differencing\n\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n\t# store forecast\n\tpredictions.append(yhat)\n\texpected = raw_values[len(train) + i + 1]\n\tprint('day=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n \n# report performance\nrmse = sqrt(mean_squared_error(raw_values[231:], predictions))\nprint('Test RMSE: %.3f' % rmse)\n# line plot of observed vs predicted\npyplot.plot(raw_values[231:])\npyplot.plot(predictions)\npyplot.xlabel('Forecasting from September')\npyplot.show()","63846a31":"print('Mean absolute percentage error of LSTM is ',mean_absolute_percentage_error(raw_values[231:], predictions))","8fa0d2e9":"import matplotlib\nimport statsmodels.api as sm\ndecomposition = sm.tsa.seasonal_decompose(time_series_analysis_df,model='additive')\nfir = decomposition.plot()\nmatplotlib.rcParams['figure.figsize']=[20.0,15.0]","4536c6f5":"import itertools","e175ea2b":"p = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\nprint('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))","a5b0dfb6":"# Use this for parameter selection\n\n# for param in pdq:\n#     for param_seasonal in seasonal_pdq:\n#         try:\n#             mod = sm.tsa.statespace.SARIMAX(time_series_analysis_df,\n#                                             order=param,\n#                                             seasonal_order=param_seasonal,\n#                                             enforce_stationarity=False,\n#                                             enforce_invertibility=False)\n#             results = mod.fit()\n#             print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n#         except:\n#             continue","edb77337":"mod = sm.tsa.statespace.SARIMAX(time_series_analysis_df,\n                                order=(1, 1, 1),\n                                seasonal_order=(1, 1, 1, 12),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults = mod.fit()\nprint(results.summary().tables[1])","aa9c8cfc":"results.plot_diagnostics(figsize=(16, 8))\nplt.show()","8285626c":"pred = results.get_prediction(start=pd.to_datetime('2020-09-01'), dynamic=False)\npred_ci = pred.conf_int()\nax = time_series_analysis_df.plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.2)\nax.set_xlabel('Date')\nax.set_ylabel('Number of cases')\nplt.legend()\nplt.show()","1b64966e":"y_forecasted = pred.predicted_mean\n# print(y_forecasted)\n# time_series_analysis_df['Total_cases']['2020-09-01':]\ny_truth = time_series_analysis_df['Total_cases']['2020-09-01':]\nmse = ((y_forecasted - y_truth) ** 2).mean()\nprint('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))","c2a0ed69":"print('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))","9f2e2260":"mean_absolute_percentage_error(y_truth,y_forecasted)","16a6c577":"pred_uc = results.get_forecast(steps=100)\npred_ci = pred_uc.conf_int()\nax = time_series_analysis_df['Total_cases'].plot(label='Total_cases', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_title('COVID-19')\nax.set_xlabel('Date')\nax.set_ylabel('Total Cases')\nplt.legend()\nplt.show()","b15bfe50":"#### Mean Absolute percentage error","0d3f442c":" - Here we can see the Death toll is very low as compared to confirmed cases, which is because most of the people recover from COVID-19. Early estimates predicted that the overall COVID-19 recovery rate is between 97% and 99.75%.\n - Mortality rate calculated  = 3.4% (802.318k\/23.09665M)","31cc6cfd":"#### Lets see relation between total confirmed cases to recovered cases.","de006f63":"## World COVID-19 Stats","710e41f9":"#### Lets see many coulmns are missing values.","b88f2014":" - Quebec has maximum number of confirmed cases and twice as many deceased people than ontario. <a href = \"https:\/\/www.ctvnews.ca\/health\/coronavirus\/quebec-leads-canada-in-coronavirus-deaths-so-why-is-it-starting-to-reopen-1.4928940\"> Quebec leads Canada in Coronavirus deaths<\/a>\n - In this article I also found one more interesting thing that Alberta has done more testing per capita, and along with good policies the death polls remains below 500.\n - There a some provinces where there were less to no cases, and no death has been reported, because quite a few people live there.","f0684876":"#### Lets visualize Canada's Data and see which province has been worst effected.\n1. We'll use the same above canada_df for visualization purpose.\n2. We are going to use this dataframe because it's the latest data and our script we'll update the data every time we run the cell based on the website mentioned above.\n3. I'm going to use plotly for visualization purpose as it generates graphs which are interactive and user friendly.","5f5d14e0":" - Perfecto!. Now we can see that column has been cleared off all the \"Unknown\".","e7355bdf":" - Recovery rate canada wide is 88% which is 21% higher than the worldwide recovery rate. This also brings in another factor the geographical location a patient is in and how is the healthcare system there.\n - Alberta's recovery rate is also 89% which is close to overall recovery rate.   ","1549cfd3":" - The column contains many unknown values.\n - We'll replace all the unknown values with zero.\n - Then we will arrange the column in descending order for visualization purpose.","7b74cb2e":"#### Time Series Forecasting with Arima (Autoregressive Integrated Moving Average)\n\nWith the notation ARIMA(p, d, q), ARIMA models are denoted. The seasonality, pattern, and noise in the data account for these three parameters","0317d8e5":" - China on first position that was unexpected. I was expecting United States.\n - As you can see the countries who are vastly testing their people have a upper hand on curbing the spread of virus by implementing policies.","69ef20d2":"## Persistance model for timeseries forecasting","aab43b4a":"#### Lets see who has implemented testing vastly.","bc2d4182":"- From these graphs we can see that overall recovery rate for canada is more than **~84%**. **Alberta** is very close with recovery rate of **~83%**.\n- **Manitoba** has very lowest recovery rate **~50%**. Highest recovery rate is in **PEI**, which can be attributed to low population.\n- Average mortality rate is close to **~4.5%**.\n- Highest mortality rate is observerd in **Quebec**. **Alberta** is in bottom **5** in terms of mortality rate.","c3a342f8":"#### Future Forecasting","33474100":"#### Convert integer into datetime for better visualization","031be854":"# Context\n\n### Novel Coronavirus 2019 (nCoV-2019) is a virus which affects respiratory system and was first discovered in wuhan, China. Some early reports suggested that virus may have been transmitted from animal to person. As we know whole world has been shutdown  because of the widespread cases. At this time it's unclear how easily or sustainably this virus is spreading between people.","87f6edf7":"#### Lets plot world data using Choropleth Map","4b3cb037":"## Canada COVID-19 Stats","b4d59d14":"#### Click on the link for more information.\n\n - United States tops the chart. <a href = \"https:\/\/www.sciencemag.org\/news\/2020\/04\/united-states-leads-coronavirus-cases-not-pandemic-response\" > If you want to know why United States leads in coronvirus cases, but not pandemic response<\/a>\n - Brazil also surpasses 100,000 deaths and becomes the one of the worst affected countries. <a href = \"https:\/\/www.ctvnews.ca\/health\/coronavirus\/death-became-normal-brazil-surpasses-100-000-deaths-from-covid-19-1.5056757\" >'Death became normal': Brazil surpasses 100,000 deaths from COVID-19<\/a>\n - Mexico's death toll also reached 59.106k and many young people are dying of COVID-19 <a href = \"https:\/\/www.forbes.com\/sites\/nathanielparishflannery\/2020\/07\/24\/why-are-so-many-young-people-dying-of-covid-19-in-mexico-city\/#148bc1f22792\">Why Are So Many Young People Dying Of Covid-19 In Mexico City?<\/a>\n - India has also reached 56k and there are many questions about India's rising COVID-19 infection <a href =\"https:\/\/www.bbc.com\/news\/world-asia-india-53018351\">Five key questions about India's rising Covid-19 infections<\/a>","95698314":"#### Plot number of confirmed cases.","e21e529c":" -  Here we can see that trend is continously going up, **Total number of cases grew from 10 million in month of july to 40 million in the month of october.**\n - The increase in the number of the cases can be attributed to some of the severly affected country mentioned above in the discussion.\n - The sesonality shows us a sinusoidal trend which can be attributed to continous increasing trend in the number of confirmed cases.\n - we can see some noise components in later months of **august, september, and october** which can be attributed to poorly affected countries above mentioned.","fdfc6c3e":"## Model for predicting the number of confirmed cases.","6989feec":"#### Lets visualize the death toll in relation to total confirmed case","4db48dbf":"#### lets explore the Confirmed cases in relation to total population","bc398dea":"## Linear Regression model","9ac81ca4":"#### lets calculate mortality rate.","f0326e98":"#### Sorting the data on number of confirmed cases","2e798e98":"#### Lets import all the dependencies for scrapping the website","dca6348e":"#### Lets import seaborn as well as matplotlib","cf6a0d75":"#### We will scrap worldwide covid cases.\n1. We'll use pandas read.html which lets us read the webpage table without much of complexity.\n2. Convert the table into dataframe for further processing.\n3. In the header of the list generated you see a number \"1\", which was used in the original website as a filter for arranging data in ascending or descending order.","e9fb1687":"#### XGBoost","99b0dcc9":"## Support Vector Machine Model","869ee83d":" - Now we can see United states holds number 1 position. (cough cough \"we don't wear masks\" - americans)\n - Brazil and India comes at the second and third position surpassing Russia respectively.","ca3fa8b8":" - We are using the XGBoost model on the dataset when making one-step forecasts for the data from September month.\n - We will use previous 10 time steps as input to the model and default model hyperparameters, except we will change the loss to 'reg:sqarederror' and use 1,000 trees in the ensemble.","e65360a2":"#### Validation of forecasts","900e309d":"#### Mean Absolute percentage error\nI prefer to use mean absolute percent error because it gives an simple percentage to communicate that shows how off the predictions are. MAPE is not included in Sklearn, so a custom feature must be used.","df02e514":"# Current Cases (WorldWide)\n### To know how bad the world has been affected lets get some information on current situation.","96cdd47e":" - This graph shows a small percentage of people are affected by the novel coronavirus. <a href = \"https:\/\/www.canada.ca\/en\/public-health\/services\/publications\/diseases-conditions\/people-high-risk-for-severe-illness-covid-19.html\">\n    People who are at high risk for severe illness from COVID-19<\/a>","dad88cce":"#### lets visualize the recovered cases based on total confirmed case","20aa6194":"#### LSTM in Keras","44522fd3":" - Here the color of each bar corrosponds to how many people have died.\n - We cannot make out which country has most number of deceased people in a descending order.","8dd3970f":"The persistence forecast is where the observation from the prior time step (t-1) is used to predict the observation at the current time step (t).\n\nWe can implement this by taking the last observation from the training data and history accumulated by walk-forward validation and using that to predict the current time step.","4addbf1f":"#### Dataset used","24ec16c2":" - **Future Forecasting**\n - We used Arima model from stats to predict future values as mean absolute percentage error of ARIMA model is very low **~0.098%**\n - Our model predicts that in the month of **Jan2021** we will have around [60million, 90million] cases.\n - As we move further in the future the confidence interval of prediction drops because this model doesn't take into account various policies that have been implemented by countries to curb the spread the of the virus. ","48437f73":"#### Train Test Split","15c34fd7":"#### The country converter (coco) - a Python package for converting country names between different classifications schemes.\n<a href = \"https:\/\/pypi.org\/project\/country-converter\/\">For more info please click here<\/a>.","23fe3836":"Batch Size: 1\nEpochs: 1500\nNeurons: 1","75fc8531":" - Here we can see how many person recovered in relation to total cases registered.\n - Recovery rate  = 67% (15.4827M\/23.09665M), this contradicts early predicted value of recovery rate which was 97%.\n - Recovery rate and mortality rate are based on how well a country is implementing the testing of its people. <a href = \"https:\/\/www.who.int\/news-room\/commentaries\/detail\/estimating-mortality-from-covid-19\">Estimating mortality from COVID-19<\/a>","95c65d0c":"## Canada COVID-19 Stats","dbce0894":" - We can zoom in the graph, thats the beauty of plotly.","584b6324":"#### Fitting the model","dc1083b0":" - **Martinique, Belgium, France** has lowest recovery rate among countries.\n - Yemen has highest mortality rate **~30%**, which is one of the highest in the world and five times the global average. <a href = \"https:\/\/www.bmj.com\/content\/370\/bmj.m2997\">Covid-19: Deaths in Yemen are five times global average as healthcare collapses<\/a>","aef5430f":"The Long Short-Term Memory network (LSTM) is a type of Recurrent Neural Network (RNN).\n\nA benefit of this type of network is that it can learn and remember over long sequences and does not rely on a pre-specified window lagged observation as input.\n\nIn Keras, this is referred to as stateful, and involves setting the \u201cstateful\u201d argument to \u201cTrue\u201d when defining an LSTM layer.\n\nBy default, an LSTM layer in Keras maintains state between data within one batch. A batch of data is a fixed-sized number of rows from the training dataset that defines how many patterns to process before updating the weights of the network. State in the LSTM layer between batches is cleared by default, therefore we must make the LSTM stateful. This gives us fine-grained control over when state of the LSTM layer is cleared, by calling the reset_states() function.\n\nThe LSTM layer expects input to be in a matrix with the dimensions: [samples, time steps, features].\n\nSamples: These are independent observations from the domain, typically rows of data.\nTime steps: These are separate time steps of a given variable for a given observation.\nFeatures: These are separate measures observed at the time of observation.\nWe have some flexibility in how the Total cases dataset is framed for the network. We will keep it simple and frame the problem as each time step in the original sequence is one separate sample, with one timestep and one feature.\n\nGiven that the training dataset is defined as X inputs and y outputs, it must be reshaped into the Samples\/TimeSteps\/Features format, for example:","07332288":"#### Lets calculate recovery rate in Canada and Alberta specifically","d074bbcf":"#### Additive model \n 1. This model is used when the time series level does not vary with the variations around the trend. Here, the time series components are simply added together using the formula:\n     - y(t) = Level(t) + Trend(t) + Seasonality(t) + Noise(t)","1eac71e2":"#### Parameter Selection","9ccf8c48":"Two Datasets are used:\n\n1. Dataset obtained using ncov2019.live website\n2. Time series Data from https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv'\n\n\n - For the purpose of this notebook i have saved the data after scrapping it from the first source as it was not working in the kaggle notebbook.\n - If you want to get latest model predictions than please uncomment the section stating (# Use this code in your notebook and it'll fetch data directly from ncov2019 website. For this notebook. I'm using a copy of the same). and comment the section stating (#Saved Data)\n \n - If you have any Queries please leave a comment","c91fd606":"The above output suggests that SARIMAX(1, 1, 1)x(1, 1, 1, 12) yields the lowest AIC value.","a724e4fd":"#### Lets get Latest Canada's information.\n1. We'll use the pandas read.html which lets us read the webpage table without much of complexity.\n2. We can also use the lsit to convert it to a dataframe.\n3. In the header of the list generated you see a number \"1\", which was used in the original website as a filter for arranging data in ascending or descending order.","61a5ce69":"#### Mean Absolute percentage error\n","fe60bfce":" - Mortality rate of overall canada is 7% (9118\/126.804k)\n - Mortality rate of Alberta is 1.8% which is quite astounding. Alberta is implementing policies very efficiently and because of that it has such a low mortality rate.\n - Highest mortality rate is of Quebec 8.9%.\n - Second highest mortality rate is of ontario 6.5%","cad7e98a":"#### We'll use plotly express for visualization.\n1. It generates graphs which are interactive and user friendly.\n2. We can use zoom in and zoom out feature for proper understanding to a specific part of graph.","bca6b94c":"#### Now we'll try to explore the world_df in more details.(based on number of Deceased People)"}}