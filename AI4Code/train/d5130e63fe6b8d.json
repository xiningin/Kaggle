{"cell_type":{"e9224c9b":"code","c5cc5dfe":"code","817c4091":"code","3a833410":"code","53c2bc31":"code","1d7b5c4d":"code","3ace701d":"code","b265fd6d":"code","1e785bd6":"code","8a139650":"code","80c51148":"code","2e939ad8":"code","58a4b295":"code","9417b015":"code","81fa168f":"code","834f65e9":"code","25a0f292":"code","6a22ffe1":"code","ea48667b":"code","b70acaf8":"code","8a26a449":"code","af151a21":"code","febd7abd":"code","9611a488":"code","ea0abd1a":"code","682e186d":"code","3df10a2d":"code","fd563abe":"code","182c5459":"code","ef1e1415":"code","f4e683ff":"code","260d3cca":"code","35bee42b":"code","bc535ebe":"code","7befe9a6":"code","49f5aa5f":"markdown","da2be215":"markdown","47cc25f0":"markdown","ec39171e":"markdown","47064244":"markdown"},"source":{"e9224c9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c5cc5dfe":"import warnings\nwarnings.filterwarnings('ignore')\n\nfrom imblearn.over_sampling import SMOTE\nimport matplotlib.pyplot as plt, seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score,\\\nRandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import accuracy_score, recall_score, confusion_matrix, plot_roc_curve,\\\nplot_confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\n\nimport math\n\nfrom sklearn.pipeline import Pipeline\n\nfrom hyperopt import hp,fmin,tpe,STATUS_OK,Trials","817c4091":"df = pd.read_csv('\/kaggle\/input\/water-potability\/water_potability.csv')\ndf.head()","3a833410":"null = (df.isnull().sum()\/len(df))*100\nprint('Percentage of null values \\n\\n',null)","53c2bc31":"null_index = null[null.values<15].index\nfor i in null_index:\n    df[i] = df[i].fillna(df[i].median())\n    \ndf.head()","1d7b5c4d":"null = (df.isnull().sum()\/len(df))*100\nprint('Percentage of null values \\n\\n',null)","3ace701d":"null_index = null[null.values>15].index\n\nfor i in null_index:\n    df = df[~df[i].isnull()]","b265fd6d":"df.info()","1e785bd6":"df.Potability.value_counts()","8a139650":"X = df.iloc[:,:-1]\ny = df.Potability\n\nsmote = SMOTE(random_state=72)\nX_smote, y_smote = smote.fit_resample(X,y)\n\ndf = pd.concat([X_smote,y_smote], axis=1)\ndf.head()","80c51148":"df.Potability.value_counts()","2e939ad8":"df.info()","58a4b295":"df.Potability.value_counts()","9417b015":"# sns.pairplot(df)","81fa168f":"outlier_cols = df.columns[:-1]\n\nplt.figure(figsize=(20,8))\nfor i in enumerate(outlier_cols):\n    plt.subplot(3,3,i[0]+1)\n    sns.boxplot(df[i[1]])\nplt.show()","834f65e9":"df.shape","25a0f292":"train, test = train_test_split(df, train_size=0.7, random_state=100)\n\nX_train = train.drop('Potability', axis=1)\ny_train = train.Potability\n\nX_test = test.drop('Potability', axis=1)\ny_test = test.Potability\n\n\n\n","6a22ffe1":"scaler = MinMaxScaler()\nX_train[X_train.columns] = scaler.fit_transform(X_train[X_train.columns])\nX_test[X_test.columns] = scaler.transform(X_test[X_test.columns])","ea48667b":"X_train.describe()","b70acaf8":"X_test.describe()","8a26a449":"lr = LogisticRegression()\nfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=100)\ncv_score = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","af151a21":"lg_reg = LogisticRegression()\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=60)\nhyper_Param = {'penalty' :['l1', 'l2', 'elasticnet', 'none'],\n              'C':[0,0.0001,0.01,0.2,0.4,0.6,0.8]}\n\ngrid = GridSearchCV(estimator=lg_reg, param_grid=hyper_Param, cv=folds, scoring='accuracy',\n                   verbose=1, return_train_score=True)\ngrid.fit(X_train, y_train)","febd7abd":"grid.best_score_","9611a488":"xb = xgb.XGBClassifier(random_state=20,eval_metric='mlogloss')\nfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=100)\ncv_score = cross_val_score(estimator=xb, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","ea0abd1a":"xb = xgb.XGBClassifier(random_state=20,eval_metric='mlogloss')\nfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=100)\nhyper_Params = {'n_estimators':[100,200,300,400],\n                'learning_rate': [0.05,0.08,0.1,0.2,0.3],\n               'max_depth': [3,5,7,10,13,15,20],\n               'gamma': [0,0.1,0.3,0.5,0.7],\n               'reg_lambda':[0.1,0.2,0.4,0.6,0.8]}\n\nrnd_xb = RandomizedSearchCV(estimator=xb, param_distributions=hyper_Params, n_iter=10, n_jobs=-1, cv=folds,\n                        scoring='accuracy', verbose=3)\nrnd_xb.fit(X_train, y_train)","682e186d":"rnd_xb.best_score_","3df10a2d":"sv = SVC()\nfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=100)\ncv_score = cross_val_score(estimator=sv, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","fd563abe":"sv = SVC()\nfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=100)\n# hyper_Params = {'C':[0.000000001,0.000001,0.0001,0.01,0.1],\n#                'gamma':[0.00001,0.00001,0.001,0.1]}\nhyper_Params = [ {'kernel': ['rbf','poly','linear'],\n                    'gamma': [1e-2, 1e-3, 1e-4, 0.1, 0.2, 0.5, 0.8,0.85,0.9,1],\n                     'C': [1, 10, 100, 1000]}]\n\nrnd_svc = RandomizedSearchCV(estimator=sv, param_distributions=hyper_Params, n_iter=100, n_jobs=-1, cv=folds,\n                        scoring='accuracy', verbose=3)\nrnd_svc.fit(X_train, y_train)","182c5459":"rnd_svc.best_score_","ef1e1415":"rf = RandomForestClassifier(random_state=60)\nfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=100)\ncv_score = cross_val_score(estimator=rf, X=X_train, y=y_train, cv=folds, scoring='accuracy')\ncv_score.mean()","f4e683ff":"rf = RandomForestClassifier(random_state=60)\nfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=100)\n\nhyper_Params = {'criterion':['gini','entropy'],\n               'min_samples_split':[50,60,100],\n               'min_samples_leaf':[10,15,25,30],\n               'max_depth':[2,4,7,10,15]}\n\ngrid_rf = GridSearchCV(estimator=rf, param_grid=hyper_Params, n_jobs=-1, cv=folds,\n                        scoring='accuracy', verbose=3)\ngrid_rf.fit(X_train, y_train)","260d3cca":"grid_rf.best_score_","35bee42b":"models = []\n\nlr = Pipeline([('lr', grid.best_estimator_)])\nmodels.append(('lr',lr))\n\nxb = Pipeline([('xb', rnd_xb.best_estimator_)])\nmodels.append(('xb',xb))\n\nsv = Pipeline([('sv', rnd_svc.best_estimator_)])\nmodels.append(('sv',sv))\n\nrf = Pipeline([('rf', RandomForestClassifier(random_state=60))])\nmodels.append(('rf',rf))\n\n\nvote = VotingClassifier(models, voting='hard')\n\nvote.fit(X_train,y_train)\ny_pred = vote.predict(X_test)\naccuracy_score(y_test, y_pred)","bc535ebe":"plot_confusion_matrix(vote, X_test, y_test)\nplt.show()","7befe9a6":"conf = confusion_matrix(y_test,y_pred)\n\nspecificity = conf[0,0]\/conf[0].sum()\nprint('Specificity =',round(specificity*100,2),'%')\nprint('Accuracy =',round(accuracy_score(y_test, y_pred)*100,2),'%')","49f5aa5f":"## XGBoost","da2be215":"## Splitting and scaling data","47cc25f0":"## SVM","ec39171e":"## Random Forest","47064244":"## Logistic Regression"}}