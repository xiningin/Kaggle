{"cell_type":{"fce37949":"code","5f32f981":"code","2eea8c91":"code","f5961b5d":"code","2c64548d":"code","ea233e4a":"code","f772f384":"markdown","7d6c368d":"markdown","d89c2098":"markdown","a661367f":"markdown"},"source":{"fce37949":"import os, numpy as np\nfrom PIL import Image \n\nTRAIN_IMG = os.listdir('..\/input\/severstal-steel-defect-detection\/train_images')\nTEST_IMG = os.listdir('..\/input\/severstal-steel-defect-detection\/test_images')\nprint('Original train count =',len(TRAIN_IMG),', Original test count =',len(TEST_IMG))\nprint('New train count = 1801 , New test count = 1801')\nos.system('rm -rf ..\/tmp')\nos.mkdir('..\/tmp\/')\nos.mkdir('..\/tmp\/train_images\/')\nr = np.random.choice(TRAIN_IMG,len(TEST_IMG),replace=False)\nfor i,f in enumerate(r):\n    img = Image.open('..\/input\/severstal-steel-defect-detection\/train_images\/'+f)\n    # select crop starting point randomly\n    for i_start in range(0,1600-256+1,64):\n        img = img.crop((i_start, 0, i_start+256, 256))\n        img.save('..\/tmp\/train_images\/crop_'+str(i_start)+f)\nos.mkdir('..\/tmp\/test_images\/')\nfor i,f in enumerate(TEST_IMG):\n    img = Image.open('..\/input\/severstal-steel-defect-detection\/test_images\/'+f)\n    for i_start in range(0,1600-256+1,64):\n        img = img.crop((i_start, 0, i_start+256, 256))\n        img.save('..\/tmp\/test_images\/crop_'+str(i_start)+f)","5f32f981":"import pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.callbacks import LearningRateScheduler\nimport matplotlib.pyplot as plt, time\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2eea8c91":"from keras import applications\nbase_model = applications.Xception(weights=None, input_shape=(256, 256, 3), include_top=False)\nbase_model.load_weights('..\/input\/keras-pretrained-models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\nbase_model.trainable = False\nx = base_model.output\nx = layers.Flatten()(x)\nx = layers.Dense(1024, activation=\"relu\")(x)\nx = layers.Dropout(0.5)(x)\npredictions = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(input = base_model.input, output = predictions)\nmodel.compile(loss='binary_crossentropy', optimizer = \"adam\", metrics=['accuracy'])","f5961b5d":"img_dir = '..\/tmp\/'\nimg_height = 256; img_width = 256\nbatch_size = 16; nb_epochs = 5\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n    horizontal_flip=True,\n    validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(\n    img_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n    img_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation') # set as validation data\n\nannealer = LearningRateScheduler(lambda x: 0.0001 * 0.95 ** x)\nh = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ batch_size,\n    epochs = nb_epochs,\n    callbacks = [annealer],\n    verbose=1)","2c64548d":"plt.figure(figsize=(15,5))\nplt.plot(h.history['acc'],label='Train ACC')\nplt.plot(h.history['val_acc'],label='Val ACC')\nplt.title('TRAIN COMPARED WITH TEST. Training History')\nplt.legend()\nplt.show()","ea233e4a":"! rm -r ..\/tmp\n# COMPARE 1801 RANDOM TRAIN WITH 1801 RANDOM TRAIN\nTRAIN_IMG = os.listdir('..\/input\/severstal-steel-defect-detection\/train_images')\nos.mkdir('..\/tmp\/')\nos.mkdir('..\/tmp\/train_images\/')\nr = np.random.choice(TRAIN_IMG,3602,replace=False)\nfor i,f in enumerate(r[:1801]):\n    img = Image.open('..\/input\/severstal-steel-defect-detection\/train_images\/'+f)\n    img.save('..\/tmp\/train_images\/'+f)\nos.mkdir('..\/tmp\/test_images\/')\nfor i,f in enumerate(r[1801:]):\n    img = Image.open('..\/input\/severstal-steel-defect-detection\/train_images\/'+f)\n    img.save('..\/tmp\/test_images\/'+f)\n    \n# BUILD XCEPTION CLASSIFIER\nbase_model = applications.Xception(weights=None, input_shape=(256, 256, 3), include_top=False)\nbase_model.load_weights('..\/input\/keras-pretrained-models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\nbase_model.trainable = False\nx = base_model.output\nx = layers.Flatten()(x)\nx = layers.Dense(1024, activation=\"relu\")(x)\nx = layers.Dropout(0.5)(x)\npredictions = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(input = base_model.input, output = predictions)\nmodel.compile(loss='binary_crossentropy', optimizer = \"adam\", metrics=['accuracy'])\n\n# DATA PIPELINE\nimg_dir = '..\/tmp\/'\nimg_height = 256; img_width = 256\nbatch_size = 32; nb_epochs = 15\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n    horizontal_flip=True,\n    validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(\n    img_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n    img_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation') # set as validation data\n\n# TRAIN CLASSIFIER\nannealer = LearningRateScheduler(lambda x: 0.0001 * 0.95 ** x)\nh = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ batch_size,\n    epochs = nb_epochs,\n    callbacks = [annealer],\n    verbose=2)\n\n# PLOT RESULTS\nplt.figure(figsize=(15,5))\nplt.plot(h.history['acc'],label='Train ACC')\nplt.plot(h.history['val_acc'],label='Val ACC')\nplt.title('TRAIN COMPARED WITH TRAIN. Training History')\nplt.legend()\nplt.show()","f772f384":"# Prepare Images\nIn this kernel we randomly select 1801 training images. Then we have an equal number of train and test images. Note that if we compare 1801 random train images with a different 1801 random train images, then a classifier cannot do better than 50% detection. See Appendix. ","7d6c368d":"# Build Adversarial Classifier\nTo distinguish train images from test images, we will use pretrained Xception.","d89c2098":"# Conclusion\nThis is concerning. What is different between the training images and test images that a classifier can tell them apart with 85% accuracy? Note that if we compare a random 1801 training images with another random 1801 training images, a classifier can not distinquish the two groups better than 50%. See Appendix below.\n\n# Appendix\nFor comparision, we demonstrate that a classifier cannot distinquish one random group of 1801 training images from another random group of 1801 training images better than 50%. Therefore it is significant that we can distinquish train from test with 85% accuracy.","a661367f":"The Original kernel has been adapted to use 256x256 crops taken in steps of 64 px. When using the full image the author observed that the Test and validation images could be distinguished by a classifier. For the 256x256 crops that does not seem to be the case.\n\n# Steel Adversarial Validation\nIn this kernel, we compare the training images to the test images for Kaggle's \"Steel Defect Detection\" competition. We observe that there is a significant difference. If you select an image at random with 50\/50 chance of being train or test, a classifier can distinquish whether it is a train or test image with 85% accuracy! Why is that?"}}