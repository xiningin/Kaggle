{"cell_type":{"42a4c6a6":"code","3323c54d":"code","e07a3206":"code","1ef7d520":"code","4d47a86e":"code","2533e915":"code","74b3cbb4":"code","86c893eb":"code","b6a970a9":"code","1abe865e":"code","59a2da52":"code","dc29cc11":"code","8916b92a":"code","acb62044":"code","746e9ba7":"code","9dbd5744":"markdown","d8381947":"markdown"},"source":{"42a4c6a6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nfrom scipy import signal\n\n%matplotlib inline","3323c54d":"%%time\ntrain = pd.read_csv('..\/input\/train.csv', \n                    dtype={'acoustic_data': np.int16, \n                           'time_to_failure': np.float32})","e07a3206":"rows = 150000\n\nnum_segments = int(np.floor(train.shape[0] \/ rows))\ndt = 0.0375\/rows\n# sampling_frequency is the upper bound of the frequency\nsampling_frequency = np.ceil(1\/dt)\nprint(\"Total {0:d} segments, time step {1:.1e} seconds, sampling frequency {2:0.0f} Mhz.\"\\\n      .format(num_segments, dt, sampling_frequency\/\/1e6))","1ef7d520":"def get_spectrum(input_signal, window=100):\n    \"\"\"\n    returns the Fourier power spectrum for a given signal segment\n    output is a pandas Series \n    output.index is the frequencies\n    output.values is the amplitudes for each frequencies\n    default moving average window is 10\n    \"\"\"\n    input_signal = np.asarray(input_signal.values, dtype='float32')\n    \n    # Remove the mean  \n    input_signal -= input_signal.mean()  \n    \n    # Estimate power spectral density using a periodogram.\n    frequencies , power_spectrum = signal.periodogram(\n        input_signal, sampling_frequency, scaling='spectrum')    \n    \n    # Run a running windows average of 10-points to smooth the signal (default). \n    power_spectrum = pd.Series(power_spectrum, index=frequencies).rolling(window=window).mean()        \n    \n    return pd.Series(power_spectrum)\n\ndef get_segment_spectrum(segment_df, \n                         max_frequency = 300000, min_frequency = 100,\n                         step = 10, window = 10):\n    \"\"\"\n    get the Fourier power spectrum of a given segment.\n    returns the quake_time, frequencies, and power_spectrum\n    \"\"\"\n    \n    quake_time = segment_df['time_to_failure'].values[-1]\n    \n    _power_spectrum = get_spectrum(segment_df['acoustic_data'], window=window).dropna() \n    # drop the null values\n\n    # Keep only frequencies < max_frequency (larger frequencies have a negligible contribution).\n    # and > min_frequency (some low frequency is outlier)\n    _power_spectrum = _power_spectrum[_power_spectrum.index < max_frequency]\n    _power_spectrum = _power_spectrum[_power_spectrum.index > min_frequency]\n    \n    # Keep one every 10 samples by default\n    power_spectrum=_power_spectrum.values[::step]\n    frequencies=_power_spectrum.index.values[::step]    \n    \n    return quake_time, frequencies, power_spectrum","4d47a86e":"## perform above for all segments\n# since the frequencies retrieved is changing, initialization is none\nwindow = 200\nstep = 5\nquake_times = np.array([])       \npower_spectrums = np.array([])\nmax_frequency = 350000\nmin_frequency = 0\n\nfor k in tqdm_notebook(range(num_segments)):\n    segment = train.iloc[k*rows : k*rows+rows]\n    quake_time, frequencies, power_spectrum = \\\n    get_segment_spectrum(segment, \n                         max_frequency=max_frequency,\n                         min_frequency=min_frequency,\n                         step=step,window=window)    \n    quake_times = np.append(quake_times, quake_time)\n    power_spectrums = np.append(power_spectrums, power_spectrum)\n    \npower_spectrums = power_spectrums.reshape(num_segments,-1)","2533e915":"X_train = power_spectrums\/(np.sum(power_spectrums, axis=1)[:,np.newaxis])\nX_train = pd.DataFrame(X_train)\ny_train = quake_times","74b3cbb4":"submission = pd.read_csv('..\/input\/sample_submission.csv', \n                         index_col='seg_id')\nX_test = pd.DataFrame(columns=X_train.columns, \n                      dtype=np.float64, \n                      index=submission.index)","86c893eb":"for seg_id in tqdm_notebook(X_test.index):\n    seg = pd.read_csv('..\/input\/test\/' + seg_id + '.csv')\n    seg['time_to_failure'] = 0\n    _, frequencies, seg_spectrum = \\\n    get_segment_spectrum(seg, \n                         max_frequency=max_frequency,\n                         min_frequency=min_frequency,\n                         step=step,window=window)\n    X_test.loc[seg_id] = seg_spectrum\/seg_spectrum.sum()","b6a970a9":"fig, ax = plt.subplots(4,2,figsize=(20,16))\nax = ax.reshape(-1)\nidx = np.random.randint(1, X_train.shape[0]+1, size=8)\nfor i in range(8):\n    ax[i].plot(frequencies,X_train.iloc[idx[i],:])\n    ax[i].set_ylabel('Energy')","1abe865e":"# averaging\nwindow_freq = 10\nX_tr_reduced = X_train.copy().groupby(X_train.columns \/\/ window_freq, axis=1).mean()\nX_tst_reduced = X_test.copy().groupby(X_test.columns \/\/ window_freq, axis=1).mean()\nfrequencies = pd.Series(frequencies)\nfreq_reduced = frequencies.groupby(frequencies.index \/\/ window_freq).mean()","59a2da52":"import lightgbm as lgb\n\nparams = {'num_leaves': 40,\n         'min_data_in_leaf': 12, \n         'objective':'huber',\n         'max_depth': -1,\n         'learning_rate': 0.05,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.95,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.91,\n         \"lambda_l1\": 0.6,\n         \"verbosity\": -1,\n         \"nthread\": -1}","dc29cc11":"from sklearn.model_selection import KFold\n\nn_fold = 6\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=1127)","8916b92a":"X_train = X_tr_reduced\nX_test = X_tst_reduced\ny_train = y_train.reshape(-1)\npredictions = np.zeros(len(X_test))\ny_oof = np.zeros(len(X_train))\ny_tr_pred = np.zeros(len(X_train))\n#run model\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train,y_train)):\n    strLog = \"fold {}\".format(fold_)\n    print(strLog)\n    \n    X_tr, X_val = X_train.iloc[trn_idx], X_train.iloc[val_idx]\n    y_tr, y_val = y_train[trn_idx], y_train[val_idx]\n\n    model = lgb.LGBMRegressor(**params, n_estimators = 10000, n_jobs = -1)\n    model.fit(X_tr, y_tr, \n              eval_set=[(X_tr, y_tr), (X_val, y_val)], \n              eval_metric='mae',\n              verbose=1000, \n              early_stopping_rounds=1000)\n\n    #predictions\n    y_oof[val_idx] = model.predict(X_train.iloc[val_idx], num_iteration=model.best_iteration_)\n    y_tr_pred += model.predict(X_train, num_iteration=model.best_iteration_) \/ folds.n_splits\n    predictions += model.predict(X_test, num_iteration=model.best_iteration_) \/ folds.n_splits","acb62044":"_, ax = plt.subplots(4,2,figsize=(20,16))\nax = ax.reshape(-1)\nnum_steps = 500\n\nfor i in range(8):\n    ax[i].plot(y_train[i*num_steps:i*num_steps+num_steps], color='blue', linewidth=3, label='y_train');\n    ax[i].plot(y_tr_pred[i*num_steps:i*num_steps+num_steps], color='g', label='LGB training');\n    ax[i].plot(y_oof[i*num_steps:i*num_steps+num_steps], color='r', label='LGB oof');\n    ax[i].set_ylim([-0.2, 16])","746e9ba7":"submission['time_to_failure'] = predictions\nsubmission.to_csv('submission.csv')","9dbd5744":"# LightGBM model","d8381947":"# Gradient boosting using power spectra\n\nReferences:\n* [LANL Earthquake EDA and Prediction](https:\/\/www.kaggle.com\/gpreda\/lanl-earthquake-eda-and-prediction\/notebook)\n* [LightGBM gradient boosting framework](https:\/\/lightgbm.readthedocs.io\/en\/latest\/Python-API.html#lightgbm.LGBMRegressor)\n* [Energy spectra retrieving using FFT](https:\/\/www.kaggle.com\/scaomath\/lanl-earthquake-spectral-analysis-using-fft)"}}