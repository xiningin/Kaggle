{"cell_type":{"4f265d58":"code","73d7b334":"code","7ad809ec":"code","4fcc3a53":"code","40e0ea97":"code","247c8732":"code","63a1d404":"code","44b2be9d":"code","3ba0e908":"code","03999db0":"code","1817eb37":"code","3e25e831":"code","23545f97":"code","f48de82b":"markdown","c87bb13a":"markdown","71b298f8":"markdown","32c67d6f":"markdown","4680b9b6":"markdown","9c9af973":"markdown"},"source":{"4f265d58":"!pip install --no-deps '..\/input\/timm-package\/timm-0.1.26-py3-none-any.whl' > \/dev\/null\n!pip install --no-deps '..\/input\/pycocotools\/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > \/dev\/null","73d7b334":"from colorama import Fore, Style","7ad809ec":"import sys\nsys.path.insert(0, \"..\/input\/timm-efficientdet-pytorch-fixdiv\")\nsys.path.insert(0, \"..\/input\/omegaconf\")\nsys.path.insert(0, \"..\/input\/weightedboxesfusion\")\n\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom torch.utils.data import Dataset,DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport gc\nfrom matplotlib import pyplot as plt\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchEval\nfrom effdet.efficientdet import HeadNet\nfrom ensemble_boxes import *\n\nprint(f'{Fore.GREEN} successfully installed! {Style.RESET_ALL}')","4fcc3a53":"IMG_WIDTH, IMG_HEIGHT = 256, 256\nIMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)\nTEST_DATA_PATH = '..\/input\/charaters-for-detection-classification\/real_world_test\/'\nWEIGHTS_PATH = '..\/input\/efficientdet-trained-model-for-ocr\/best-checkpoint-004epoch\/best-checkpoint-004epoch.bin'","40e0ea97":"def get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=256, width=256, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)","247c8732":"class DatasetRetriever(Dataset):\n\n    def __init__(self, image_ids, transforms=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        image = cv2.imread(f'{TEST_DATA_PATH}\/{image_id}.png', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","63a1d404":"def get_file_name(file_name_with_extension):\n    return os.path.splitext(file_name_with_extension)[0]","44b2be9d":"def collate(batch):\n    return tuple(zip(*batch))","3ba0e908":"dataset = DatasetRetriever(\n    image_ids=np.array([path.split('\/')[-1][:-4] for path in glob(f'{TEST_DATA_PATH}\/*.png')]),\n    transforms=get_valid_transforms()\n)\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)\n","03999db0":"def load_net(checkpoint_path):\n    config = get_efficientdet_config('tf_efficientdet_d5')\n    net = EfficientDet(config, pretrained_backbone=False)\n\n    config.num_classes = 1\n    config.image_size=256\n    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n\n    checkpoint = torch.load(checkpoint_path,map_location='cpu') #remove map_loc... if running on gpu\n    net.load_state_dict(checkpoint['model_state_dict'])\n\n    del checkpoint\n    gc.collect()\n\n    net = DetBenchEval(net, config)\n    net.eval();\n    return net.cpu() #.cuda\n\nnet = load_net(WEIGHTS_PATH)","1817eb37":"def make_predictions(images, score_threshold=0.22):\n    images = torch.stack(images).cpu().float() #.cuda\n    predictions = []\n    with torch.no_grad():\n        det = net(images, torch.tensor([1]*images.shape[0]).float().cpu()) #cuda\n        for i in range(images.shape[0]):\n            boxes = det[i].detach().cpu().numpy()[:,:4]    \n            scores = det[i].detach().cpu().numpy()[:,4]\n            indexes = np.where(scores > score_threshold)[0]\n            boxes = boxes[indexes]\n            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n            predictions.append({\n                'boxes': boxes[indexes],\n                'scores': scores[indexes],\n            })\n    return [predictions]\n\ndef run_wbf(predictions, image_index, image_size=IMG_WIDTH, iou_thr=0.44, skip_box_thr=0.43, weights=None):\n    boxes = [(prediction[image_index]['boxes']\/(image_size-1)).tolist()  for prediction in predictions]\n    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    boxes = boxes*(image_size-1)\n    return boxes, scores, labels","3e25e831":"def get_images(data_loader, num_images):\n    images = []\n    for j, (img, name) in enumerate(data_loader):\n        if (j < num_images):\n            images.append(img[0])\n        else:\n            break\n    return tuple(images)","23545f97":"import matplotlib.pyplot as plt\nimport time\n\nnum_test_images = 10\nimages = get_images(data_loader, num_test_images)\n\npredict_start_time = time.time()\npredictions = make_predictions(images)\npredict_finish_time =_finish_time = time.time()\npredict_time = predict_finish_time - predict_start_time\nprint(f'it took {Fore.CYAN}', predict_time,f' seconds{Style.RESET_ALL} for the model predict', num_test_images, 'images')\nprint('Average=', predict_time \/ num_test_images,'seconds')\n#fig, ax = plt.subplots(10, figsize=(16, 16))\n\nfor i in range(num_test_images):\n    sample = images[i].permute(1,2,0).cpu().numpy()\n    boxes, scores, labels = run_wbf(predictions, image_index=i)\n    boxes = boxes.astype(np.int32).clip(min=0, max=511)\n\n\n    for box in boxes:\n        cv2.rectangle(sample, (box[0], box[1]), (box[2], box[3]), (1, 0, 0), 1)\n    plt.imshow(sample)\n    plt.show()\n    #ax[i].imshow(sample)","f48de82b":"**Hello**! This is the second and the last part of an OCR project. Here we are going to use previously written [notebook](https:\/\/www.kaggle.com\/ivankalinchuk\/ocr-efficientdet-with-pytorch-part-1-2-training) (part 1 of 2), where we learned how to train an EfficientDet model with PyTorch. Having learned our model, we have weights, which need to be loaded into a model.","c87bb13a":"# EfficientDet: small step for an optimizer gient giant leap datascientists\n### **Real world problem** | **Object detection** | **PyTorch** | **Optical character detection**","71b298f8":"The next cell is one of the most delightful one. We predict! Also I've added a time module so as to calculate execution time, but you are free to delete it, as it's optional. ","32c67d6f":"**Import all apropriate libraries**","4680b9b6":"Lets set up some constants for our project, so as to make it more undestandable and easy to manage.","9c9af973":"As we already have a model trained, we just need a function, which returns an object of pytorch model with loaded weights."}}