{"cell_type":{"6b3f2270":"code","e221d779":"code","1fffb2b3":"code","5597a9f8":"code","fdb11f86":"code","22dc582f":"code","f9d4b145":"code","2891b503":"code","14ed0f58":"code","94073e19":"code","57fdba34":"code","713f0afe":"code","86f0d0f5":"code","6c1d8029":"code","a3ddb99d":"code","9ecbf2db":"markdown","b400b823":"markdown","ce1ee53d":"markdown","956281de":"markdown","97aa556d":"markdown"},"source":{"6b3f2270":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","e221d779":"data = pd.read_csv(\"\/kaggle\/input\/graduate-admissions\/Admission_Predict.csv\")\ndata.head()","1fffb2b3":"data.info()","5597a9f8":"from sklearn.preprocessing import MinMaxScaler # Scaling values.\nmms = MinMaxScaler()\nscaledData = pd.DataFrame(mms.fit_transform(data.iloc[:,1:7]), columns = [\"GRE Score\",\"TOEFL Score\",\"University Rating\",\"SOP\",\"LOR\",\"CGPA\"])\nnewData = pd.concat((scaledData,data.iloc[:,7:9]),axis = 1)\nnewData","fdb11f86":"X = newData.iloc[:,:-1]\ny = newData.iloc[:,-1]","22dc582f":"from sklearn.model_selection import train_test_split ,GridSearchCV \nX_train, X_test, y_train ,y_test = train_test_split(X,y,random_state = 44, test_size = 0.2) #Splitting data.","f9d4b145":"from xgboost import XGBRegressor\nXGBR = XGBRegressor()","2891b503":"modelParams = {\"max_depth\": [2,3,5,10,30],\n              \"subsample\": [0.5,0.75,1],\n              \"colsample_bytree\":[0.5,0.75,1],\n              \"colsample_bylevel\":[0.5,0.75,1],\n              \"min_child_weight\": [1,5,25],\n              \"n_estimators\": [10,50,100,250,500],\n              \"learning_rate\":[0.01,0.1,0.25]} ","14ed0f58":"XGBGridSearch = GridSearchCV(XGBR, modelParams,verbose = 2,n_jobs = -1,cv = 5) #n_jobs = -1 means use all cores for training\nXGBGridSearch.fit(X_train,y_train)","94073e19":"XGBGridSearch.best_params_","57fdba34":"XGBR2 = XGBRegressor(colsample_bylevel= 0.5,\n colsample_bytree= 0.75,\n learning_rate= 0.01,\n max_depth= 2,\n min_child_weight= 5,\n n_estimators= 500,\n subsample= 0.75) # Training with best parameters.","713f0afe":"XGBR2.fit(X_train,y_train)\ny_pred = XGBR2.predict(X_test)","86f0d0f5":"XGBR2.fit(X_train,y_train)\ny_pred2 = XGBR2.predict(X_train)","6c1d8029":"from sklearn.metrics import r2_score\nprint(f\"test set r2 value:{r2_score(y_test, y_pred)} train set r2 value{r2_score(y_train, y_pred2)}\")","a3ddb99d":"print(pd.DataFrame(np.vstack((y_test.to_numpy(),y_pred)).T,columns = [\"Actual values\",\"Predicted values\"]))\n","9ecbf2db":"No null values good.","b400b823":"As you can see I also predicted X_train for check how model overfitted. We had 0.79 r2 score at test data and 0.83 r2 score at train data. Model didn't overfit and we had similar scores in both train and test set.GridSearch approximately took 30 minutes to find best params you may drop some values from ModelParams for faster Gridsearch.I am going to also create a dataframe for both predictions to see how we predicted. If you have any questions I am here to answer it. Thanks for your time.","ce1ee53d":"We have 9 columns.Serial no column is needless for training. So we are going to drop it. For faster training we can scale data into range(0-1). After preprocessing we'll have 7 column in x_train and 1 column at y_train. To test model i am going to split data. I set test_size to 0.2 because we have 800 row total in data.","956281de":"XGBRegressor has couple important parameters. In this dict(modelParams) i set couple parameters for gridsearch.","97aa556d":"# Graduate Admissions:Quick Analyze with XGBoost and Hyperparameter tuning\n\n![](https:\/\/www.wes.org\/wp-content\/uploads\/2017\/10\/blog_20171031_iStock_36808402.jpg)\n\nIn this notebook i am going to analyze Graduate Admission file with few lines of code. First i am going to scale data then optimize the model with GridSearchCv.Lets jump into code."}}