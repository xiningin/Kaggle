{"cell_type":{"63d8825b":"code","99e1378d":"code","706323bb":"code","5f1554dc":"code","431c00d3":"code","e0ed3bb6":"code","0ecdcbeb":"code","81191d99":"code","2e640a31":"code","63f195a8":"code","996df539":"code","8caa5d0d":"code","602cabe9":"code","5f12341c":"code","90a63574":"code","3444f9a5":"code","238be88c":"code","9e9525c5":"code","a1bfdc76":"code","536237f6":"code","766091fb":"code","a8c529a9":"code","62c44dd4":"code","d857263b":"markdown"},"source":{"63d8825b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\n\npd.set_option('display.max_rows', 500)\ndropcol = []","99e1378d":"\ntrain = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv')\nalldata = pd.concat([train, test], sort=False)\n\n#\uc0c8\ub85c\uc6b4 \ubcc0\uc218 \ub9cc\ub4e4\uae30\nalldata['Old'] = alldata['YrSold'] - pd.concat([alldata['YearBuilt'], \n                                               alldata['YearRemodAdd']], axis=1).max(axis=1)\nalldata['TotalSF'] = alldata['TotalBsmtSF']+alldata['GrLivArea']\nalldata['TotalSF2'] = alldata['TotalSF'] + alldata['GarageArea']\nalldata['Overal'] = alldata['OverallCond'] + alldata['OverallQual']\nalldata['Overal'] = alldata['OverallQual'] * alldata['TotalSF2']\n\nalldata = alldata.drop(['Id'], axis=1)\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\n\n#\uba85\ubaa9\ubcc0\uc218 \uacb0\uce21\uac12 \ucc98\ub9ac\nalldata['MasVnrType'] = alldata['MasVnrType'].fillna(alldata['MasVnrType'].mode()[0])\nalldata['BsmtExposure'] = alldata['BsmtExposure'].fillna(alldata['BsmtExposure'].mode()[0])\nalldata['Electrical'] = alldata['Electrical'].fillna(alldata['Electrical'].mode()[0])\nalldata['GarageFinish'] = alldata['GarageFinish'].fillna(alldata['GarageFinish'].mode()[0])\n\nfor i in alldata.columns:\n    if (alldata[i].dtype=='object'):\n        alldata[i] = alldata[i].fillna(\"NA\")\n    else: alldata[i] = alldata[i].fillna(alldata[i].mean())\n\nalldata['MSSubClass'] = alldata['MSSubClass'].astype(object)\nalldata = pd.get_dummies(alldata)\n#pd.DataFrame(alldata.corr().sort_values(['SalePrice']))\nY = alldata['SalePrice']\nalldata = alldata.drop(['SalePrice'], axis=1)","706323bb":"for i in range(0,len(alldata.columns)):\n    if alldata[alldata.columns[i]].value_counts().sort_values().iloc[0] < 15:\n        if len(alldata[alldata.columns[i]].value_counts())==2:\n            print(alldata.columns[i], alldata[alldata.columns[i]].value_counts().sort_values().iloc[0])\n            dropcol.append(alldata.columns[i])\nalldata = alldata.drop(dropcol, axis=1)","5f1554dc":"# alldrop = alldata.drop([1298, 523, 462, 632, 30, 1324], axis=0)\n\n\n# for i in alldrop.columns:\n#     for j in alldrop.columns:\n#         if i!=j:\n#             if abs(pd.concat([Y.drop([1298, 523, 462, 632, 30, 1324], axis=0), \n#                               pd.concat([alldrop[j], alldrop[i]], axis=1).max(axis=1)], axis=1).corr()['SalePrice'].iloc[1]) > 0.6:\n#                 print(i,j,pd.concat([Y.drop([1298, 523, 462, 632, 30, 1324], axis=0), \n#                                      pd.concat([alldrop[j], alldrop[i]], axis=1).max(axis=1)], \n#                                     axis=1).corr()['SalePrice'].iloc[1])","431c00d3":"# for ne in [200, 500, 700, 1000, 2000]:\n#     for md in [10,20,None]:\n#         rf = RandomForestRegressor(n_estimators=ne, max_depth=md, max_features=None)\n#         rf.fit(pd.DataFrame(alldata[:len(train)]).fillna(-1), train['SalePrice'])\n#         print(ne, md, np.sqrt(-cross_val_score(rf, pd.DataFrame(alldata[:len(train)]).fillna(-1), \n#                                            train['SalePrice'], n_jobs=-1, cv=10, \n#                                            scoring='neg_mean_squared_error').mean()))","e0ed3bb6":"# for ne in [200, 500, 700, 1000, 2000]:\n#     for nl in [5,10,20,None]:\n#         import lightgbm as lgb\n#         lgb=lgb.LGBMRegressor(n_estimators=ne, num_leaves=nl)\n#         lgb.fit(pd.DataFrame(alldata[:len(train)]).fillna(-1), train['SalePrice'])\n#         print(ne, nl, np.sqrt(-cross_val_score(lgb, pd.DataFrame(alldata[:len(train)]).fillna(-1), \n#                                            train['SalePrice'], n_jobs=-1, cv=10, \n#                                            scoring='neg_mean_squared_error').mean()))","0ecdcbeb":"train2 = alldata2[:len(train)]","81191d99":"rf = RandomForestRegressor(n_estimators=1000, max_depth=20, max_features=None)\nrf.fit(pd.DataFrame(alldata[:len(train)]).fillna(-1), train['SalePrice'])\n#np.sqrt(-cross_val_score(rf, train2, Y, n_jobs=-1, cv=5, scoring='neg_mean_squared_error' ).mean())","2e640a31":"from catboost import CatBoostRegressor\ncb = CatBoostRegressor(iterations=4000)\ncb.fit(pd.DataFrame(alldata[:len(train)]).fillna(-1), train['SalePrice'])","63f195a8":"import xgboost as xgb\nxgb = xgb.XGBRegressor(n_estimators=1000, max_depth=10,objective ='reg:squarederror')\nxgb.fit(pd.DataFrame(alldata[:len(train)]).fillna(-1), train['SalePrice'])\n# np.sqrt(-cross_val_score(xgb, train2, Y, n_jobs=-1, cv=5, scoring='neg_mean_squared_error' ).mean())","996df539":"import lightgbm as lgb\nlgb=lgb.LGBMRegressor(n_estimators=900, num_leaves=9)\nlgb.fit(pd.DataFrame(alldata[:len(train)]).fillna(-1), train['SalePrice'])\n# np.sqrt(-cross_val_score(lgb, train2, Y, n_jobs=-1, cv=5, scoring='neg_mean_squared_error' ).mean())","8caa5d0d":"# plt.figure(figsize=(20,12))\n# sns.scatterplot(train['ExterQual'], train['SalePrice'])","602cabe9":"from sklearn.preprocessing import StandardScaler, RobustScaler\nss=RobustScaler()\nalldata2 = ss.fit_transform(alldata)","5f12341c":"alldata2 = pd.DataFrame(alldata2).fillna(0)","90a63574":"#462, 523, 1298, 1190, 1061, 691, 1182, 632, 1324\n#1298, 523, 462, 632, 30, 1324\nstats = pd.DataFrame(np.zeros(1460))","3444f9a5":"# # outlier detection\n# for i in set(range(1,1460))-set([1182, 691, 1169]):\n#     train2 = alldata2[:len(train)].drop([1182,691,1169, i], axis=0)\n#     Y = np.log(train['SalePrice']).drop([1182,691,1169, i], axis=0)\n#     from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n#     ridge = RidgeCV(alphas=[12])\n#     stat = np.sqrt(-cross_val_score(ridge, train2, Y, n_jobs=-1, cv=4, scoring='neg_mean_squared_error').mean())\n#     if stat<0.074:\n#         print(i, stat)\n#     if i%300 == 0:\n#         print(i, stat)\n#     stats.loc[i] = stat\n\n# stats.sort_values([0])[:5]","238be88c":"train2 = alldata2[:len(train)].drop([1182,691,1169, 1298], axis=0)\nY = np.log(train['SalePrice']).drop([1182,691,1169, 1298], axis=0)","9e9525c5":"#train2 = alldata2[:len(train)].drop([1298, 523, 462, 632, 30, 1324], axis=0)\n#Y = np.log(train['SalePrice']).drop([1298, 523, 462, 632, 30, 1324], axis=0)\ntest2 = alldata2[len(train):]\n\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nridge = RidgeCV(alphas=[15])\n\nnp.sqrt(-cross_val_score(ridge, train2, Y, n_jobs=-1, cv=5, scoring='neg_mean_squared_error' ).mean())","a1bfdc76":"from sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.00008, normalize=True)\nnp.sqrt(-cross_val_score(lasso, train2, Y, n_jobs=-1, cv=10, scoring='neg_mean_squared_error' ).mean())","536237f6":"# ela = ElasticNetCV(max_iter=1e8, alphas=0.001, cv=5, l1_ratio=0.8)\n# np.sqrt(-cross_val_score(ela, train2, Y, n_jobs=-1, cv=5, scoring='neg_mean_squared_error' ).mean())","766091fb":"ridge.fit(train2, Y)\nlasso.fit(train2, Y)\n# ela.fit(train2, Y)","a8c529a9":"T1 = pd.DataFrame(alldata[len(train):]).fillna(-1)\nresult = (np.exp(ridge.predict(test2))*0.40)+(np.exp(\n    lasso.predict(test2))*0.05)+(cb.predict(T1)*0.47)+(\n    lgb.predict(T1)*0.05)+(xgb.predict(T1)*0.015)+(rf.predict(T1)*0.015)\n","62c44dd4":"sub = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/sample_submission.csv\")\nsub['SalePrice'] = result\nsub.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","d857263b":"* \ub354\ubbf8\ubcc0\uc218, \uacb0\uce21\uac12 \ucc98\ub9ac, \uc0c8\ub85c\uc6b4 \ubcc0\uc218 \uc0dd\uc131\n* \ud2b8\ub9ac\ubca0\uc774\uc2a4 \ubaa8\ub378, \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\n* \uc815\uaddc\ud654 \uc120\ud615\ud68c\uadc0, \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd, \uc544\uc6c3\ub77c\uc774\uc5b4 \ub514\ud14d\uc158\uc774\ub791 \uc81c\uac70\n* \uc559\uc0c1\ube14, \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd, \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\n\n\uc810\uc218\uc62c\ub9ac\uae30\n1. \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd, \uc2a4\ud0dc\ud0b9 \ud14c\ud06c\ub2c9\n2. \ud06c\ub85c\uc2a4 \ubc38\ub9ac\ub370\uc774\uc158"}}