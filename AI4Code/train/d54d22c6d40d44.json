{"cell_type":{"2860e1fb":"code","fff07d2c":"code","0243822a":"code","18f17c5b":"code","13e3c892":"code","26c9f9ae":"code","5a608a46":"markdown"},"source":{"2860e1fb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport copy\nimport glob\nimport random\nfrom random import random as rd\nimport gc","fff07d2c":"df_train = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\")\nunique_pressures = df_train[\"pressure\"].unique()\nsorted_pressures = np.sort(unique_pressures)\ntotal_pressures_len = len(sorted_pressures)\n\ndef find_nearest(prediction):\n    insert_idx = np.searchsorted(sorted_pressures, prediction)\n    if insert_idx == total_pressures_len:\n        return sorted_pressures[-1]\n    elif insert_idx == 0:\n        return sorted_pressures[0]\n    lower_val = sorted_pressures[insert_idx - 1]\n    upper_val = sorted_pressures[insert_idx]\n    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val\n\ndef set_seed(seed = 2021):\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\ndef wc(input_list):\n    l = []\n    allow = [1336,1579]\n    for i in range(len(input_list)):\n        public_lb_score = int(input_list[i].split(\"\/\")[-1].split(\".\")[1].split(\" \")[0]) \n#         public_lb_score = int(input_list[i].split(\"\/\")[-1].split(\"_\")[1].split(\".\")[0])\n        if public_lb_score in allow:\n            print(public_lb_score)\n            l.append(public_lb_score)\n            input_list[i] = (pd.read_csv(input_list[i]).pressure).ravel()\n        else:\n            continue\n    output = 0\n    l_sum = sum(l)\n    if len(input_list) == 1:\n        output = input_list[0]\n    else:\n        weight1 = (l[1] \/ l_sum) + 0.1\n        weight2= 1 - weight1\n        output += input_list[0] * weight1 + input_list[1] * weight2\n    return output\n\ndef g(dp):\n# input: the dataset path of the prediction result files\n# file name format: public lb score or pulbic lb score + name, e.g., 0.335 LSTM baseline\n\n    # get all the files to blend\n    l = []\n    allow = [1336,1579]\n    for i in glob.iglob(f'{dp}\/*'):\n        file_lb = int(i.split(\"\/\")[-1].split(\".\")[1].split(\" \")[0])\n        if file_lb in allow:\n            l.append(i)\n        else:\n            continue\n    file_count = len(l)\n#     loop_time = 500 \/\/ file_count\n    loop_time = 125\n    # calculate the number of files in the input dataset\n    # and split them 2 by 2\n#     splits = file_count \/\/ 2\n    splits = 2\n    # sort the file based on their public lb score\n    l.sort()\n    flist = []\n    # create a file list\n    # append the 2 by 2 files as one element\n    # in the last loop, append all the files which are not necessarily 2 files\n    for i in range(splits):\n        if i == splits - 1:\n            flist.append(l[i * round(len(l) \/ splits): ])\n        else:\n            flist.append(l[i * round(len(l) \/ splits): (i + 1) * round(len(l) \/ splits)])\n    # transfrom each element in the file list into one blended prediction\n    for i in range(len(flist)):   \n        flist[i] = wc(flist[i])\n    pred_list = []\n    # loop a large number of times\n    # to converge the result into a stable expected value\n    for i in range(loop_time):      \n        weight = []        \n        set_seed(i)\n        # create a weight list with the same length as the file list\n        for i in range(len(flist)):\n            weight.append(rd())  \n        weight_sum = sum(weight)\n        # normalize the weights\n        for i in range(len(weight)):\n            weight[i] \/= weight_sum\n        weight.sort(reverse = True)\n        temp = 0\n        # assign each weights to each blended prediction\n        for i in range(len(flist)):\n            temp += flist[i] * weight[i]\n        pred_list.append(temp)\n        del temp\n        gc.collect()\n    output = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/sample_submission.csv\")\n    output.pressure = np.median(np.vstack(pred_list), axis = 0)\n    output[\"pressure\"] = output[\"pressure\"].apply(find_nearest)\n    output.to_csv(f'rwb {loop_time} loops.csv',index=False)","0243822a":"g('..\/input\/ventilator-pressure-high-score-submissions')","18f17c5b":"# df_test = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')","13e3c892":"# testpreds = []\n# preds0 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds0.npy')\n# preds1 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds1.npy')\n# preds2 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds2.npy')\n# preds3 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds3.npy')\n# preds4 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds4.npy')\n# preds5 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds5.npy')\n# preds6 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds6.npy')\n# preds7 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds7.npy')\n# preds8 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds8.npy')\n# preds9 = np.load('..\/input\/spectral-10folds-fastai-preds\/train_10folds_preds9.npy')\n\n# testpreds.append(preds0)\n# testpreds.append(preds1)\n# testpreds.append(preds2)\n# testpreds.append(preds3)\n# testpreds.append(preds4)\n# testpreds.append(preds5)\n# testpreds.append(preds6)\n# testpreds.append(preds7)\n# testpreds.append(preds8)\n# testpreds.append(preds9)","26c9f9ae":"# preds_fold = np.array(testpreds)\n# df_test['pressure'] = np.median(preds_fold, axis=0)\n# df_test[['id', 'pressure']].to_csv('submission.csv', index=False)","5a608a46":"# Reference: \n* https:\/\/www.kaggle.com\/cdeotte\/ensemble-folds-with-median-0-153 by Chris Deotte\n* https:\/\/www.kaggle.com\/snnclsr\/a-dummy-approach-to-improve-your-score-postprocess by Sinan Calisir\n* Public notebooks with score less than 0.158"}}