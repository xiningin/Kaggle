{"cell_type":{"6d8d7e67":"code","6bdb2a68":"code","67e2a57b":"code","b1fc62f0":"code","21cd3f60":"code","28787156":"code","21da0a43":"code","86187d20":"code","781c3eb8":"code","9c03efae":"code","d8ea0b02":"code","25b82c5f":"code","fb623641":"code","0b1a40eb":"code","a78a81cf":"code","41253fda":"code","20bb5437":"code","f0b8c495":"code","f046b723":"code","0e3a1cbd":"code","a2b5c869":"code","f0a52d91":"code","bb504dea":"code","08ad18ba":"code","e0187aff":"code","f8b4a541":"code","888b3e05":"code","d2577f33":"code","fc09a791":"code","fa5c801e":"code","bd9dca68":"code","e4400afd":"code","097c9e53":"code","1151618d":"code","cb7fbb32":"code","813b60b4":"code","8b750c85":"code","2251ba2f":"code","871ed0e6":"code","c794058d":"code","2aaf9492":"code","1d9cd445":"code","89ca172c":"code","dc57ab64":"code","5d1726fa":"code","9254fae2":"code","4b7f9dbb":"code","185586ed":"code","17f7ad11":"code","d20ab74b":"code","6ac71f1b":"code","9a011af3":"code","99c3797a":"code","9802cf30":"code","1594b0ed":"code","449e9e7d":"code","1a6ee913":"code","ce5d4d19":"code","ad0361ab":"code","ce1df974":"code","5d7f84be":"code","8cb2ea15":"code","c6cb45ce":"code","3f95b8cc":"code","3e3300b6":"code","77c9a173":"code","6e9316fa":"code","bad68d07":"code","af6dee43":"code","a1bfb0d6":"code","97ae1401":"code","376175ad":"code","20d49784":"code","2c71156f":"code","141bc051":"code","c20a91f5":"code","7525cf01":"code","2b9cac8b":"code","51fd6c03":"code","48b3db55":"code","a4f69c39":"markdown","70eb9819":"markdown","098a7416":"markdown","2774feb7":"markdown","eef5e671":"markdown","2b770d31":"markdown","dceaab5e":"markdown","69ed09a8":"markdown","5a69b1b5":"markdown","029f8904":"markdown","0b98f2bd":"markdown","812a159c":"markdown","60c1d18b":"markdown","2d3c0fae":"markdown","8d44acac":"markdown","1dbf2e82":"markdown","36fe368b":"markdown","17615cee":"markdown","70dfa541":"markdown","04d6c169":"markdown","3a3ad8a6":"markdown","6515fe05":"markdown","abfce3cd":"markdown","85aa969e":"markdown","73c28793":"markdown","c88e3612":"markdown","fe6b3bec":"markdown","93105eba":"markdown","5ce0a852":"markdown","f8f9b125":"markdown","d5c03311":"markdown","ff827813":"markdown","927cf1c0":"markdown","6f20e3e0":"markdown","31d2b19d":"markdown","e0a7913f":"markdown","8606427b":"markdown","cfba856f":"markdown","8b55239b":"markdown","b75ad104":"markdown","ec1faaaa":"markdown","f42e4046":"markdown","c354b9b2":"markdown","909abc52":"markdown","a90b52ed":"markdown","71089639":"markdown","7fa7c6d6":"markdown","60768cc2":"markdown","d2fe860c":"markdown","54b31a55":"markdown","52ffbde1":"markdown"},"source":{"6d8d7e67":"#\u00daltima execu\u00e7\u00e3o\nimport datetime\nprint(datetime.datetime.now())\ntoday = datetime.datetime.now().strftime('%d\/%m\/%Y')","6bdb2a68":"# imports\nimport numpy as np\nimport pandas as pd\nimport os\nimport numpy as np\n\n# bokeh packages\nfrom bokeh.io import output_file,show,output_notebook,push_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource,HoverTool,CategoricalColorMapper\nfrom bokeh.layouts import row,column,gridplot\nfrom bokeh.models.widgets import Tabs,Panel\nfrom bokeh.models import GeoJSONDataSource\noutput_notebook()\n\n# plotly packages\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.graph_objs import *\n\nimport json\nimport geopandas as gpd\nimport plotly.graph_objects as go\nimport unidecode","67e2a57b":"data = pd.read_csv('\/kaggle\/input\/corona-virus-brazil\/brazil_covid19.csv')\ndata.head()","b1fc62f0":"data.tail()","21cd3f60":"print(min(data['date']))\nprint(max(data['date']))","28787156":"## S\u00edntese di\u00e1ria\ndf2 = data.groupby(['date'])['cases','deaths'].agg('sum')\ndf2.head()","21da0a43":"### Atualizando com antiga vers\u00e3o do dataset\nold = pd.read_csv('\/kaggle\/input\/corona-virus-brazil\/brazil_covid19_old.csv')\nold = old.groupby(['date'])['suspects'].agg('sum')\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = old.index,\n        ticktext = old.index\n    ),\n    xaxis_title=\"Data\",\n    yaxis_title = \"Quantidade\"\n)\nsuspeitos = old.loc[:'2020-03-21']\nfig = px.bar(title='Casos suspeitos -- Descontinuado a partir de 21\/03\/2020', x=suspeitos.index, y=suspeitos)\nfig['layout'].update(layout)\nfig.show()","86187d20":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.graph_objs import *\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n)\n\nfig = make_subplots(rows=2, cols=1,subplot_titles=('Casos Confirmados at\u00e9 ' + today, '\u00d3bitos at\u00e9 '+ today))\nfig.append_trace(go.Bar(name='Confirmados', x=df2.index, y=df2['cases']), row=1, col=1)\nfig.append_trace(go.Bar(name='\u00d3bitos', x=df2.index, y=df2['deaths']), row=2, col=1)\n\nfig.update_xaxes(title_text=\"Data\", row=1, col=1)\nfig.update_yaxes(title_text=\"Quantidade\", row=1, col=1)\nfig.update_xaxes(title_text=\"Data\", row=2, col=1)\nfig.update_yaxes(title_text=\"Quantidade\", row=2, col=1)\n\nfig['layout'].update(layout)\n\nfig.show()","781c3eb8":"import plotly.graph_objects as go\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title=\"Visualiza\u00e7\u00e3o Conjunta de Casos e \u00d3bitos at\u00e9 \" + today,\n)\n\nfig = go.Figure(data=[\n    go.Bar(name='Confirmados', x=df2.index, y=df2['cases']),\n    go.Bar(name='\u00d3bitos', x=df2.index, y=df2['deaths'])\n])\nfig.update_xaxes(title_text='Data')\nfig.update_yaxes(title_text='Quantidade')\nfig.update_layout(barmode='stack')\nfig['layout'].update(layout)\n\nfig.show()","9c03efae":"# utils\ndef remove_accents(a):\n    unaccented_string = unidecode.unidecode(a)\n    return unaccented_string","d8ea0b02":"#data.drop('hour',axis= 1, inplace=True)\natual = max(data['date'])\ndf3 = data.loc[data['date'] == max(data['date'])].groupby(['state'])['cases','deaths'].agg('sum')\ndf4 = pd.DataFrame({\"name\": df3.index, 'cases': df3['cases'], 'deaths':df3['deaths']})\ndf4.index = range(0,27)\n\nbrazil = gpd.read_file('\/kaggle\/input\/brazil-states-geojson\/brazil.geojson')\n\ndf4['name'] = df4['name'].apply(remove_accents)\ndf4 = df4.sort_values('name')\nbrazil['name'] = brazil['name'].apply(remove_accents)\nbrazil = brazil.sort_values('name')\n\npop_states = brazil.merge(df4, left_on = 'name', right_on = 'name')\ngeosource = GeoJSONDataSource(geojson = pop_states.to_json())\nmerged_json = json.loads(pop_states.to_json())\njson_data = json.dumps(merged_json)\ngeosource = GeoJSONDataSource(geojson = json_data)","25b82c5f":"from bokeh.io import output_notebook, show, output_file\nfrom bokeh.plotting import figure\nfrom bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar\nfrom bokeh.palettes import brewer\nfrom bokeh.palettes import magma,viridis,cividis\nfrom bokeh.layouts import row\n\ndef myplot3(geosource,tema, complemento = '',jump = 1,high = 100):\n    \n    tipo = '\u00d3bitos'\n    palette = magma(256)\n    if tema.startswith('case'):\n        tipo = 'Casos'\n        palette = viridis(256)[:248]\n    elif tema.startswith('letalidade'):\n        tipo = 'Letalidade'\n        palette = cividis(256)[:248]\n    elif tema.startswith('leitospor100mil'):\n        tipo = 'Leitos de UTI por 100 mil habitantes'\n        palette = magma(256)\n    elif tema.startswith('leitos'):\n        tipo = 'Leitos de UTI'\n        palette = viridis(256)[:248]\n    elif tema.startswith('testesRapidos'):\n        tipo = 'Testes R\u00e1pidos'\n        palette = viridis(256)[:248]\n    elif tema.startswith('testesRTPCR'):\n        tipo = 'Testes RT-PCR'\n        palette = magma(256)\n        \n        \n    palette = palette[::-1]\n    color_mapper = LinearColorMapper(palette = palette, low = 0, high = high)\n\n    #Define custom tick labels for color bar.\n    if (not tema.startswith('letalidade')):\n        d = {}\n        for i in range(0,int(high),jump):\n            d[str(i)] = str(i)\n\n            \n        d[str(int(high) + 1)] = '>' + str(int(high) + 1)\n                \n        hover = HoverTool(tooltips = [ ('Estado','@name'),('Quantidade', '@{'+tema+'}{%d}')], formatters={'@{'+ tema +'}' : 'printf'})\n    elif (tema.startswith('leitos') or tema.startswith('teste')):\n        d = {}\n        for i in np.arange(0, high+1, jump):\n            d[str(round(i,2))] = str(round(i,2))\n        d[str(high + 1)] = '>'+ str(high + 1)\n        hover = HoverTool(tooltips = [ ('Estado','@name'),('Quantidade', '@{'+tema+'}{%d}')], formatters={'@{'+ tema +'}' : 'printf'})\n    else:\n        d = {}\n        for i in np.arange(0, high+0.5, jump):\n            d[str(round(i,2))] = str(round(i,2))\n        d[str(round(high + 0.5,2))] = '>'+ str(round(high + 0.5,2))\n        hover = HoverTool(tooltips = [ ('Estado','@name'),('Taxa', '@{'+tema+'}{%.2f%%}')], formatters={'@{'+ tema +'}' : 'printf'})\n    \n    \n    tick_labels = d\n    #Create color bar. \n    color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8,width = 300, height = 20,\n    border_line_color=None,location = (0,0), orientation = 'horizontal', major_label_overrides = tick_labels)\n\n\n\n    #Create figure object.\n    p = figure(title = tipo + complemento + ' em {0}'.format((datetime.datetime.now()).strftime('%d\/%m\/%Y')), plot_height = 430 , plot_width = 330, toolbar_location = None, tools =[hover])\n    p.xgrid.grid_line_color = None\n    p.ygrid.grid_line_color = None\n    p.xaxis.visible = False\n    p.yaxis.visible = False\n\n\n    p.patches('xs','ys', source = geosource,fill_color = {'field' :str(tema), 'transform' : color_mapper},\n              line_color = 'black', line_width = 0.25, fill_alpha = 1)\n\n    p.add_layout(color_bar, 'below')\n    return p\n","fb623641":"show(row(myplot3(geosource = geosource,tema = 'cases',jump = 2000, high = max(df4['cases'])),\n         myplot3(geosource = geosource,tema = 'deaths', jump = 1000, high = max(df4['deaths']))))","0b1a40eb":"populacao = pd.read_csv('\/kaggle\/input\/dadosbrasil\/populacao.csv',sep=\";\")\npopulacao['name'] = populacao['name'].apply(remove_accents)\npopulacao = populacao.sort_values('name')\npopulacao = populacao.merge(df4, left_on = 'name', right_on = 'name')\npopulacao['casespor100mil'] = (populacao['cases']\/populacao['populacao'])*100000\npopulacao['deathspor100mil'] = (populacao['deaths']\/populacao['populacao'])*100000\npopulacao['leitospor100mil'] = (populacao['leitos']\/populacao['populacao'])*100000\npopulacao['letalidade'] = round(populacao['deaths']\/populacao['cases'],3)*100\n\n# Abertura do mapa\nbrazil = gpd.read_file('\/kaggle\/input\/brazil-states-geojson\/brazil.geojson')\n## mesclagem das bases\nbrazil['name'] = brazil['name'].apply(remove_accents)\nbrazil = brazil.sort_values('name')\npop_states = brazil.merge(populacao, left_on = 'name', right_on = 'name')\n# Input GeoJSON source that contains features for plotting\ngeosource = GeoJSONDataSource(geojson = pop_states.to_json())\n\nimport json\n\n#Read data to json.\nmerged_json = json.loads(pop_states.to_json())\njson_data = json.dumps(merged_json)","a78a81cf":"show(row(myplot3(geosource = geosource,tema = 'casespor100mil',jump = 10, high = max(populacao['casespor100mil']), complemento = ' por 100 mil habitantes '),\n         myplot3(geosource = geosource,tema = 'deathspor100mil', jump = 2, high = max(populacao['deathspor100mil']), complemento = ' por 100 mil habitantes ')))","41253fda":"letalidade = sum(df4['deaths'])\/sum(df4['cases'])\nprint(\"Taxa de Letalidade em \" + today + \": {0:6.3f}%\".format(letalidade*100))","20bb5437":"df2['letalidade'] = df2['deaths']\/df2['cases']\ndf2.fillna(0,inplace=True)\ndf2 = df2.reset_index()","f0b8c495":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Letalidade ao Longo do Tempo\",\n    xaxis_title=\"Data\",\n    yaxis_title=\"Taxa de Letalidade\",\n    yaxis_tickformat = '.2%')\n\nfig = go.Figure(data=[\n    go.Scatter(x=df2['date'], y=df2['letalidade'])])\nfig['layout'].update(layout)\n\nfig.show()","f046b723":"show(myplot3(geosource = geosource,tema = 'letalidade', jump = 0.5, high = max(populacao['letalidade']), complemento = ''))","0e3a1cbd":"show(row(myplot3(geosource = geosource,tema = 'leitos', jump = 1, high = max(populacao['leitos']), complemento = ''),myplot3(geosource = geosource,tema = 'leitospor100mil', jump = 1, high = max(populacao['leitospor100mil']), complemento = '')))","a2b5c869":"populacao['pib'] = [int(x.replace('.','')) for x in populacao['pib']]","f0a52d91":"populacao['pib'].corr(populacao['leitos'])","bb504dea":"populacao['populacao'].corr(populacao['leitos'])","08ad18ba":"newData = pd.read_csv('\/kaggle\/input\/testdata\/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(populacao, left_on = 'name', right_on = 'name')\nnewData['pibpercapita'].corr(newData['leitos'])","e0187aff":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"PIB per capita versus Leitos de UTI\",\n    xaxis_title=\"PIB per capita\",\n    yaxis_title=\"Leitos de UTI\")\n\nfig = go.Figure(data=[\n    go.Scatter(x=newData['pibpercapita'], y=newData['leitos'],mode='markers')])\nfig['layout'].update(layout)\n\nfig.show()","f8b4a541":"populacao['idhm'] = [float(x.replace(',','.')) for x in populacao['idhm']]\npopulacao['idhm'].corr(populacao['leitos'])","888b3e05":"newData = pd.read_csv('\/kaggle\/input\/testdata\/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(populacao, left_on = 'name', right_on = 'name')\nnewData['pibpercapita'].corr(newData['letalidade'])","d2577f33":"newData['letalidade'].corr(newData['leitos'])","fc09a791":"newData = pd.read_csv('\/kaggle\/input\/testdata\/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(df4, left_on = 'name', right_on = 'name')\nnewData['cases'].corr(newData['pibpercapita'])","fa5c801e":"## Cases on March 31\/2020 per state\ndata = pd.read_csv('\/kaggle\/input\/corona-virus-brazil\/brazil_covid19.csv')\ndf3 = data.loc[data['date'] == '2020-03-31'].groupby(['state'])['cases','deaths'].agg('sum')\ndf3 = df3.reset_index()\ndf3['name'] = df3['state'].apply(remove_accents)\ndf3.drop(['state'],axis=1,inplace=True)\nnewData = pd.read_csv('\/kaggle\/input\/testdata\/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(df3, left_on = 'name', right_on = 'name')\nnewData['cases'].corr(newData['testesRapidos'])","bd9dca68":"newData['cases'].corr(newData['testesRTPCR'])","e4400afd":"newData['deaths'].corr(newData['testesRapidos'])","097c9e53":"newData['deaths'].corr(newData['testesRTPCR'])","1151618d":"subset = populacao[['name','pib']]\nnewData = newData.merge(subset, left_on = 'name', right_on = 'name')\nnewData['testesRapidos'].corr(newData['pib'])","cb7fbb32":"newData['testesRTPCR'].corr(newData['pib'])","813b60b4":"newData['pib'].corr(newData['cases'])","8b750c85":"newData['pib'].corr(newData['deaths'])","2251ba2f":"populacao = pd.read_csv('\/kaggle\/input\/dadosbrasil\/populacao.csv',sep=\";\")\npopulacao['name'] = populacao['name'].apply(remove_accents)\npopulacao = populacao.sort_values('name')\nnewData = newData.merge(populacao,left_on='name', right_on='name')","871ed0e6":"newData['casescapita'] = (newData['cases']\/newData['populacao'])\nnewData['deathscapita'] = (newData['deaths']\/newData['populacao'])","c794058d":"newData['testesRapidos'].corr(newData['casescapita'])","2aaf9492":"newData['testesRapidos'].corr(newData['deathscapita'])","1d9cd445":"newData['testesRTPCR'].corr(newData['casescapita'])","89ca172c":"newData['testesRTPCR'].corr(newData['deathscapita'])","dc57ab64":"# Abertura do mapa\nbrazil = gpd.read_file('\/kaggle\/input\/brazil-states-geojson\/brazil.geojson')\nbrazil['name'] = brazil['name'].apply(remove_accents)\nbrazil = brazil.sort_values('name')\n## mesclagem das bases\npop_states = brazil.merge(newData, left_on = 'name', right_on = 'name')\n# Input GeoJSON source that contains features for plotting\ngeosource = GeoJSONDataSource(geojson = pop_states.to_json())","5d1726fa":"print(\"Dados de 31\/03\/2020, ignorar cabe\u00e7alho -- Data from 03\/31\/2020, ignore header\")\nshow(row(myplot3(geosource = geosource,tema = 'testesRapidos', jump = 100, high = max(newData['testesRapidos']), complemento = ''),myplot3(geosource = geosource,tema = 'testesRTPCR', jump = 100, high = max(newData['testesRTPCR']), complemento = '')))","9254fae2":"import plotly.graph_objects as go\ndf2 = data.groupby(['date'])['cases','deaths'].agg('sum')\ndf2 = df2.reset_index()\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"S\u00e9rie temporal de Casos\",\n    xaxis_title=\"Data\",\n    yaxis_title=\"Quantidade\",\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=df2['date'], y=df2['cases'])\n    \n])\nfig['layout'].update(layout)\n\nfig.show()","4b7f9dbb":"dfy = df2.copy()\ndfy.drop(['date','deaths'],axis=1,inplace = True)\ndfy = dfy.reset_index()\ndfy['dias'] = dfy['index']\n\n# Cases double by rate every 2 days\ndef casesDouble(rate, doubleDays):\n    supposedCases = [1]\n    for i in range(len(doubleDays)-1):\n        supposedCases.append(rate*supposedCases[-1])\n    return supposedCases\n\ndoubleDays = list(range(0,max(dfy['dias']),2))\ndfSupposed = pd.DataFrame({'dias':doubleDays,'2x':casesDouble(2,doubleDays),'3x':casesDouble(3,doubleDays),'1.5x':casesDouble(1.5,doubleDays)})","185586ed":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Suposi\u00e7\u00e3o do crescimento de casos a cada 2 dias (Escala logar\u00edtmica)\",\n    xaxis_title=\"Dias desde o primeiro caso\",\n    yaxis_title=\"Quantidade (escala log)\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    ),\n    yaxis_type=\"log\"\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dfy['dias'], y=dfy['cases'], name='Casos Reais',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['2x'], name = '2x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['3x'], name = '3x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['1.5x'], name = '1.5x',mode=\"lines+markers\")\n])\n\nfig['layout'].update(layout)\n\nfig.show()","17f7ad11":"dfy = df2.copy()\ndfy.drop(['date','deaths'],axis=1,inplace = True)\ndfy = dfy.reset_index()\ndfy['dias'] = dfy['index']\n\n# Cases double by rate every 3 days\ndef casesDouble(rate, doubleDays):\n    supposedCases = [1]\n    for i in range(len(doubleDays)-1):\n        supposedCases.append(rate*supposedCases[-1])\n    return supposedCases\n\ndoubleDays = list(range(0,max(dfy['dias']),3))\ndfSupposed = pd.DataFrame({'dias':doubleDays,'2x':casesDouble(2,doubleDays),'3x':casesDouble(3,doubleDays),'1.5x':casesDouble(1.5,doubleDays)})","d20ab74b":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Suposi\u00e7\u00e3o do crescimento de casos a cada 3 dias (Escala logar\u00edtmica)\",\n    xaxis_title=\"Dias desde o primeiro caso\",\n    yaxis_title=\"Quantidade (escala log)\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    ),\n    yaxis_type=\"log\"\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dfy['dias'], y=dfy['cases'], name='Casos Reais',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['2x'], name = '2x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['3x'], name = '3x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['1.5x'], name = '1.5x',mode=\"lines+markers\")\n])\n\nfig['layout'].update(layout)\n\nfig.show()","6ac71f1b":"import plotly.graph_objects as go\nimport datetime\nimport numpy as np\n\ndf2['date'] = pd.to_datetime(df2['date'])\ndf2 = df2.loc[df2['date'] >= '02-26-2020']\ndf2['dias'] = range(1,len(df2) + 1,1)\n\n## Treino\ndias_train = df2['dias'][:int(0.9*len(df2))]\ncases_train = df2['cases'][:int(0.9*len(df2))]\n\n## Teste\ndias_test = df2['dias'][int(0.9*len(df2)):]\ncases_test =  df2['cases'][int(0.9*len(df2)):]\n\nprevisao = len(df2) - len(dias_test)\n\nprint(\"Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dias\" % (len(df2),len(dias_train),len(dias_test)))","9a011af3":"from sklearn.linear_model import LinearRegression\n\nreg = LinearRegression().fit(dias_train.values.reshape(-1,1), cases_train)\ny_previsto = reg.predict(dias_test.values.reshape(-1,1))","99c3797a":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Estimador linear para o n\u00famero de casos\",\n    xaxis_title=\"Dias desde a primeira notifica\u00e7\u00e3o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train, y=df2['cases'][:int(0.9*len(df2))], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=df2['cases'][int(0.9*len(df2)):], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(df2['cases']),\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao + 0.5],\n    y=[2],\n    text=[\"In\u00edcio da previs\u00e3o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","9802cf30":"from sklearn.metrics import mean_squared_error, r2_score\nprint(\"Erro m\u00e9dio quadr\u00e1tico: \",mean_squared_error(cases_test,y_previsto))\nprint(\"R^2 Score: \", r2_score(cases_test,y_previsto))","1594b0ed":"import plotly.graph_objects as go\nimport datetime\nimport numpy as np\n\ndf2['date'] = pd.to_datetime(df2['date'])\ndf2 = df2.loc[df2['date'] >= '02-26-2020']\ndf2['dias'] = range(1,len(df2) + 1,1)\nlog_y_data = np.log(df2['cases'])\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title=\"Log Casos versus Dias\"\n)\n\nfig = go.Figure(data=[go.Scatter(name='log Casos',x=df2['dias'], y=log_y_data, mode='markers'),\n                     go.Scatter(name='Refer\u00eancia',x=df2['dias'], y=df2['dias'], line=dict(color='firebrick', width=0.5,\n                              dash='dash'))])\nfig['layout'].update(layout)\n\nfig.show()","449e9e7d":"import plotly.graph_objects as go\nimport datetime\nimport numpy as np\n\nlog_y_data = np.log(df2['cases'])\n\ncases_train_log = log_y_data[:int(0.9*len(df2))]\ncases_test_log = log_y_data[int(0.9*len(df2)):]\n\nprint(\"Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dias\" % (len(df2),len(dias_train),len(dias_test)))","1a6ee913":"# Treino do modelo (interpola\u00e7\u00e3o da curva)\ncurve_fit = np.polyfit(dias_train, cases_train_log, 1)\ny_train = (np.exp(curve_fit[1]) * np.exp(curve_fit[0]*dias_train)).astype(int)\ny_estimado = (np.exp(curve_fit[1]) * np.exp(curve_fit[0]*dias_test)).astype(int)","ce5d4d19":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Estimador exponencial para o n\u00famero de casos\",\n    xaxis_title=\"Dias desde a primeira notifica\u00e7\u00e3o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train, y=df2['cases'][:int(0.9*len(df2))], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=y_estimado, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=df2['cases'][int(0.9*len(df2)):], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(y_estimado),\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao + 0.5],\n    y=[2],\n    text=[\"In\u00edcio da previs\u00e3o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","ad0361ab":"from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nprint(\"Erro m\u00e9dio quadr\u00e1tico: \",mean_squared_error(cases_test_log,y_estimado))\nprint(\"R^2 Score: \", r2_score(cases_test,y_estimado))","ce1df974":"## Treino\ndias_train = df2['dias'][:-1]\ncases_train = df2['cases'][:-1]\n\n## Teste\ndias_test = df2['dias'][-1:]\ncases_test =  df2['cases'][-1:]\n\nprevisao = len(df2) - len(dias_test)\n\nprint(\"Novo Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dia\" % (len(df2),len(dias_train),len(dias_test)))","5d7f84be":"from sklearn.neural_network import MLPRegressor\n# Treino da rede neural\nmlp = MLPRegressor(hidden_layer_sizes=(200,200),activation='relu',solver='lbfgs',max_iter=1000, shuffle=True)\nmlp.fit(X=dias_train.values.reshape(-1,1),y=cases_train.values.ravel())","8cb2ea15":"y_previsto = mlp.predict(dias_test.values.reshape(-1,1))","c6cb45ce":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Estimador baseado em RNA MLP para o n\u00famero de casos\",\n    xaxis_title=\"Dias desde a primeira notifica\u00e7\u00e3o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train, y=df2['cases'][:-1], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=df2['cases'][-1:], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(df2['cases']) + 100,\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao - 0.5],\n    y=[2],\n    text=[\"In\u00edcio da previs\u00e3o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","3f95b8cc":"print(\"Erro M\u00e9dio Absoluto: {0:6.3f} casos\".format(mean_absolute_error(cases_test,y_previsto)))","3e3300b6":"import matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\ndf3 = None\ndf3 = df2.copy()\ndf3.head()\ndf3.set_index('dias',inplace=True)\ndf3.drop(['date','deaths'],axis=1,inplace=True)","77c9a173":"sm.graphics.tsa.plot_acf(df3.values.squeeze(), lags=10)\nplt.show()","6e9316fa":"sm.graphics.tsa.plot_pacf(df3.values.squeeze(), lags=10)\nplt.show()","bad68d07":"df3['yesterday'] = df3['cases'].shift(1,fill_value=0)\ndf3.reset_index(level=0, inplace=True)\ndf3.head()","af6dee43":"## Treino\ndias_train = df3[['dias','yesterday']][:-1]\ncases_train = df3['cases'][:-1]\n\n## Teste\ndias_test = df3[['dias','yesterday']][-1:]\ncases_test =  df3['cases'][-1:]\n\nprevisao = len(df3) - len(dias_test)\n\nprint(\"Novo Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dia\" % (len(df2),len(dias_train),len(dias_test)))","a1bfb0d6":"from sklearn.neural_network import MLPRegressor\n# Treino da rede neural\nmlp = MLPRegressor(hidden_layer_sizes=(200,200),activation='relu',solver='lbfgs',max_iter=1000, shuffle=True)\nmlp.fit(X=dias_train.values,y=cases_train.values.ravel())","97ae1401":"y_previsto = mlp.predict(dias_test.values)","376175ad":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"RNA MLP para previs\u00e3o um dia \u00e0 frente com dia anterior nos atributos\",\n    xaxis_title=\"Dias desde a primeira notifica\u00e7\u00e3o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 4\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train['dias'], y=df3['cases'][:-1], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test['dias'], y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test['dias'], y=df3['cases'][-1:], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(df2['cases']) + 100,\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao - 0.5],\n    y=[2],\n    text=[\"In\u00edcio da previs\u00e3o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","20d49784":"print(\"Erro M\u00e9dio Absoluto: {0:6.3f} casos\".format(mean_absolute_error(cases_test,y_previsto)))","2c71156f":"df3.tail()","141bc051":"from sklearn.neural_network import MLPRegressor\n\n# Para uso nos dias que fiz previs\u00e3o \u00e0 posteriori\n#df3.drop(df3.tail(1).index,inplace=True) \n\ntomorrow = max(df3['dias']) + 1\ntoday_cases = df3.loc[df3['dias'] == max(df3['dias'])]['cases']\n\nresults = []\nfor i in range(20):\n\n    # Treino da rede neural\n    mlp = MLPRegressor(hidden_layer_sizes=(200,200),activation='relu',solver='lbfgs',max_iter=3000, shuffle=True)\n    mlp.fit(X=df3[['dias','yesterday']].values,y=df3['cases'].values.ravel())\n    \n\n    x = pd.Series([tomorrow,int(today_cases)]).values.reshape(1,-1)\n    tomorrow_cases = mlp.predict(x)\n    results.append(tomorrow_cases)","c20a91f5":"tomorrow_data = (datetime.datetime.now()).strftime('%d\/%m\/%Y')\nprint(\"Previs\u00e3o de casos para {0} no Brasil, a conferir na coletiva di\u00e1ria das 17h30min: {1}\".format(tomorrow_data,int(min(results))))","7525cf01":"y_true = [9056, 10278, 11130, 12056,14347, 15927, 17857, 19638, 20727, 22169, 23430, 25262, 28320, 30425, 33682, 36599, 38654, 40581, 43079, 45757, 52995, 58509, 63584, 66501, 71886, 78162, 85380, 91589, 96396,101147,107780, 114715,125218, 135106, 145328, 155939, 162699, 168331, 177589, 188974, 202918, 218223, 233142, 241080, 254220, 271628, 291579, 310087, 330890, 347398, 363211, 374898, 391222, 411821, 438238, 465166, 498440, 514849, 526447, 555393,584016, 614941]\ny_previsto = [9152, 10432, 11766, 12521, 13379, 15316, 17943, 20071, 21923, 21919, 24097, 25353, 27010, 30788, 32730, 36598, 39721, 41664, 43517, 45985, 52806, 56585, 62838, 66246, 71186, 77052,83951, 91967,98552, 103467, 107909,111746,122221, 133920, 144682, 155719, 167089, 173487, 178559, 188156, 200292, 215428, 232085, 248059, 255226, 268995, 287681, 309425, 329081, 351431, 368255, 384151, 394788, 411194, 431782, 461557, 490163, 526460, 542052,551830,582685, 612518] \n\nprint(\"Raiz do Erro M\u00e9dio Quadr\u00e1tico (RMSE): {0:6.4f}\".format(mean_squared_error(y_true,y_previsto)**0.5))\nprint(\"R2-Score: {0:6.4f}\".format(r2_score(y_true,y_previsto)))","2b9cac8b":"# Cria\u00e7\u00e3o dos r\u00f3tulos para o eixo x com datas\nlabels = []\nstart_date = datetime.date(2020, 4, 3)\nend_date = datetime.date.today()\ndelta = datetime.timedelta(days=1)\nwhile start_date < end_date:\n    labels.append(start_date.strftime('%d\/%m\/%Y'))\n    start_date += delta\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Visualizando previs\u00f5es one-day-ahead realizadas com o modelo proposto\",\n    xaxis_title=\"Datas\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3,\n        tickangle = 295\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=labels, y=y_true, name='Casos Reais',mode=\"lines+markers\"),\n    go.Scatter(x=labels, y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n])\n\nfig['layout'].update(layout)\n\nfig.show()","51fd6c03":"residuos = []\ndatas = []\ninicio = datetime.datetime.now() - datetime.timedelta(days=len(y_true))\nfor (x,y) in zip(y_true,y_previsto):\n    r = (x-y)\n    residuos.append(r)\n    datas.append(inicio.strftime('%d\/%m\/%Y'))\n    inicio += datetime.timedelta(days=1)","48b3db55":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Visualiza\u00e7\u00e3o dos Res\u00edduos\",\n    xaxis_title=\"Dia da Previs\u00e3o\",\n    yaxis_title=\"Res\u00edduos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3,\n        tickangle = 295\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=datas, y=residuos, name='Residuos',mode=\"markers\")\n])\nfig.add_shape(\n        # Horizontal Line\n        dict(\n            type=\"line\",\n            x0= 0,\n            y0= 0,\n            x1= len(y_true),\n            y1=0,\n            name = \"Reta Zero\",\n            line=dict(\n                width=3,\n                dash= \"dash\"\n            ),\n            \n))\n\nfig.add_trace(go.Scatter(\n    x=[len(y_true)],\n    y=[300],\n    text=[\"Reta Zero\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","a4f69c39":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Qual a distribui\u00e7\u00e3o geogr\u00e1fica dos casos confirmados?\n### \ud83c\uddfa\ud83c\uddf8 Question: What is the confirmed cases geographic distribution?","70eb9819":"#### \ud83c\udde7\ud83c\uddf7 Parte 5: Prepara\u00e7\u00e3o do Holdout\n\n#### \ud83c\uddfa\ud83c\uddf8 Step 5: Holdout preparation","098a7416":"#### \ud83c\udde7\ud83c\uddf7 Parte 1: Organizando os dados\n#### \ud83c\uddfa\ud83c\uddf8 Step 1: Tidying the data","2774feb7":"#### \ud83c\udde7\ud83c\uddf7 Parte 6: Treino da mesma MLP com nova estrat\u00e9gia\n#### \ud83c\uddfa\ud83c\uddf8 Step 6: Training the same MLP architecture using this new strategy","eef5e671":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Qual a incid\u00eancia de casos e \u00f3bitos por Estado, a cada 100 mil habitantes?\n### \ud83c\uddfa\ud83c\uddf8 Question: What is the incidence of confirmed cases and deaths by State, every 100 thousand habitants?","2b770d31":"# \ud83c\udde7\ud83c\uddf7 Este projeto foi descontinuado em 08\/06\/2020\n# \ud83c\uddfa\ud83c\uddf8 This project has been discontinued in June 8th, 2020\n\n---\n\n# \ud83c\udde7\ud83c\uddf7 Panorama do COVID-19 no Brasil\/ \ud83c\uddfa\ud83c\uddf8 COVID-19 in Brazil: An Overview\n\n\ud83c\udde7\ud83c\uddf7 O objetivo deste notebook \u00e9 analisar os dados dispon\u00edveis na base de dados brasileira sobre o COVID-19 [dispon\u00edvel aqui](https:\/\/www.kaggle.com\/unanimad\/corona-virus-brazil\/kernels) e, por meio de perguntas e respostas de alto-n\u00edvel, colaborar para a an\u00e1lise da situa\u00e7\u00e3o. O c\u00f3digo produzido \u00e9 uma maneira de atestar como as respostas foram obtidas, estando livre para consultas, revis\u00e3o e sugest\u00f5es de melhorias ou outras investiga\u00e7\u00f5es por meio do painel de discuss\u00e3o.\n\n**Disclaimer\/Aviso Legal**: Essas informa\u00e7\u00f5es devem servir aos interessados como uma primeira orienta\u00e7\u00e3o. As informa\u00e7\u00f5es gerais aqui contidas, no entanto, n\u00e3o fornecem qualquer garantia. Desse modo, est\u00e1 exclu\u00edda a garantia ou responsabilidade de qualquer tipo, por exemplo, de precis\u00e3o, confiabilidade, completude e atualidade das informa\u00e7\u00f5es. \n\n---\n\n\ud83c\uddfa\ud83c\uddf8 The objective of this notebook is to analyze the data available in the Brazilian COVID-19 database [available here](https:\/\/www.kaggle.com\/unanimad\/corona-virus-brazil\/kernels) and, through questions and high-level answers, collaborate in the analysis of the situation. The code produced attests how the answers were obtained, open for queries, reviews, suggestions for improvements, or new investigations through the discussions panel.\n\n**Disclaimer\/Legal warning**: The information here contained should serve as first guidance. The general information here contained does not provide any guarantees, however. Therefore, it is excluded the guarantee or responsibility of any kind, such as precision, reliability, completeness, and currentness of the information.\n\n\n**Ello\u00e1 B. Guedes**  \nebgcosta@uea.edu.br  \nwww.elloaguedes.com  \n\n**J\u00falio B. Guedes**  \njulio.costa@ccc.ufcg.edu.br  \n[COVID-19 Timeline](https:\/\/juliobguedes.codes\/covid)\n\n---\n\n## \ud83c\udde7\ud83c\uddf7 Confira nosso outro projeto de an\u00e1lise do COVID-19 em \u00e2mbito global\n\nSiga o link: https:\/\/juliobguedes.codes\/covid\n\n## \ud83c\uddfa\ud83c\uddf8 Check out our project on COVID-19 worldwide timeline\n\nClick here: https:\/\/juliobguedes.codes\/covid","dceaab5e":"\ud83c\udde7\ud83c\uddf7 **Conclus\u00e3o**: O n\u00famero de casos parecem crescer 1,5 vezes a cada dois dias por muito tempo dentre o per\u00edodo observado.\n\ud83c\uddfa\ud83c\uddf8 **Conclusion**: The number of cases seems to grow 1.5 times every two days during the most part of days observed.","69ed09a8":"#### \ud83c\udde7\ud83c\uddf7 Parte 2: Obtendo o ACF\n\nObserve: a s\u00e9rie \u00e9 muito bem autocorrelacionada com janela (lag) = 1\n\n#### \ud83c\uddfa\ud83c\uddf8 Step 2: Obtaining the autocorrelation function\n\nObserve: The time series is very well autocorrelated with lag = 1.","5a69b1b5":"# Agradecimento\n\nA autora Ello\u00e1 B. Guedes agradece o apoio financeiro provido pela FAPEAM no \u00e2mbito do Projeto PPP 04\/2017.\n\n![](http:\/\/www.fapeam.am.gov.br\/downloads\/57415\/)","029f8904":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Qual a incid\u00eancia di\u00e1ria de casos suspeitos, confirmados e mortes no per\u00edodo?\n\n**Resposta**: Os gr\u00e1ficos a seguir mostram esta informa\u00e7\u00e3o para casos suspeitos, confirmados e \u00f3bitos. Note que a escala de cada gr\u00e1fico \u00e9 diferente, mas que a ordem de crescimento em todos segue de maneira ascendente.\n\nEm 20\/03\/2020, o Minist\u00e9rio da Sa\u00fade passa a declarar estado de transmiss\u00e3o comunit\u00e1ria do COVID-19 no Pa\u00eds e, com isso, casos suspeitos deixam de ser contabilizados. Vide: [Estad\u00e3o, 20\/03\/2020, 19h27min](https:\/\/saude.estadao.com.br\/noticias\/geral,ministerio-da-saude-declara-estado-de-transmissao-comunitaria-de-coronavirus-em-todo-o-pais,70003242077)\n\n### \ud83c\uddfa\ud83c\uddf8 Question: What is the daily incidence of suspected, confirmed and death cases in this period?\n\n**Asnwer**: The plots below show this information for suspected, confirmed and death cases. Note that the scale of each plot is different, but the growth rate is ascending in all of them.\n\nIn March 20th, 2020 the Brazilian Health Ministry declared the state of comunitary transmission of COVID-19 and suspected cases stop being accounted for. If you want to know more, please see the news at [Estadao, March 20th, 2020, 7:27PM](https:\/\/saude.estadao.com.br\/noticias\/geral,ministerio-da-saude-declara-estado-de-transmissao-comunitaria-de-coronavirus-em-todo-o-pais,70003242077).","0b98f2bd":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Em que ordem o n\u00famero de casos est\u00e1 crescendo a cada dois dias?\n\n- Vamos come\u00e7ar a an\u00e1lise pelo primeiro dia em que houve casos confirmados\n- Iremos representar as linhas que denotam diferentes ordens crescimento de casos\n- Come\u00e7aremos a an\u00e1lise a partir do 27o. dia, que \u00e9 onde foi registrado o primeiro caso\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How much is the number of cases rising every two days?\n\n- Let's start our analysis from the day where the first case happened\n- We will denote lines that illustrate distinct growth orders\n- Our analysis will start from day 27, where the first case was reported","812a159c":"### \ud83c\udde7\ud83c\uddf7 Visualizando real versus previs\u00e3o a partir de 03\/04\/2020\n\n### \ud83c\uddfa\ud83c\uddf8 Visualizing ground truth versus prediction starting in April 3rd, 2020","60c1d18b":"### \ud83c\udde7\ud83c\uddf7 Links \u00dateis \/ \ud83c\uddfa\ud83c\uddf8 Useful links\n\n* https:\/\/docs.bokeh.org\/en\/latest\/docs\/user_guide\/geo.html  \n* https:\/\/towardsdatascience.com\/walkthrough-mapping-basics-with-bokeh-and-geopandas-in-python-43f40aa5b7e9  \n* https:\/\/pt.wikipedia.org\/wiki\/Lista_de_unidades_federativas_do_Brasil_por_popula%C3%A7%C3%A3o\n* http:\/\/www.atlasbrasil.org.br\/2013\/data\/rawData\/publicacao_atlas_municipal_pt.pdf\n* http:\/\/portal.cfm.org.br\/images\/PDF\/leitosdeutiestados2018.pdf\n* https:\/\/www.ssp.sp.gov.br\/fale\/estatisticas\/answers.aspx?t=6\n* https:\/\/github.com\/codeforamerica\/click_that_hood\/blob\/master\/public\/data\/brazil-states.geojson\n* https:\/\/docs.python.org\/3\/library\/datetime.html","2d3c0fae":"#### \ud83c\udde7\ud83c\uddf7 Parte 3: Obtendo tamb\u00e9m o PACF\n\nTamb\u00e9m nota-se que a s\u00e9rie \u00e9 muito bem parcialmente auto-correlacionada com lag = 1\n\n#### \ud83c\uddfa\ud83c\uddf8 Step 3: Obtaining the partial autocorrelation function\n\nIt is also noticeable that the series is very well partially autocorrelated with lag = 1.","8d44acac":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Como foi a modifica\u00e7\u00e3o da letalidade ao longo do tempo em \u00e2mbito nacional?\n\n**M\u00e9todo**: Calcular a taxa de letalidade dia a dia  \n**Considera\u00e7\u00f5es**: Observa-se que a taxa de letalidade vem crescendo vertiginosamente!\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How the lethality changed with time, in national scope?\n\n**Method**: Calculate the lethality rate each day.  \n**Considerations**: Its observed that the lethality rate grows vertiginously!  ","1dbf2e82":"### \ud83c\udde7\ud83c\uddf7 Os testes foram distribu\u00eddos para os Estados com maior PIB? \n\n- Considerando dados por estado coletados em 31\/03\/2020\n\n### \ud83c\uddfa\ud83c\uddf8 Have the tests been distributed to the states with the highest GDP?\n\n- Considering data from state available in 03\/31\/2020\n","36fe368b":"### \ud83c\udde7\ud83c\uddf7 Visualizando os Res\u00edduos\n\n- Os res\u00edduos na previs\u00e3o s\u00e3o a diferen\u00e7a entre os valores previstos e observados ao quadrado\n- Resultam em pontos que s\u00e3o comparados com a reta-0\n- A reta-0 representa o modelo perfeito, em que a dist\u00e2ncia entre o valor previsto e observado \u00e9 zero\n- Visualizar os res\u00edduos ajuda a interpretar visualmente a qualidade do modelo\n\n### \ud83c\uddfa\ud83c\uddf8 Visualizing the residuals\n\n- The residual in the prediction are the square of the difference between the predicted ($x'$) and the real ($x$) values: $(x' - x)^2$\n- The result is a set of points that are compared with the line-0\n- The line-0 represents the perfect model, in which the distance between every predicted and real value is zero.\n- Visualizing the residual values helps to visually understand the quality of the model\n\n","17615cee":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Como se comporta uma estimador baseado em Rede Neural Artificial Multi-Layer Perceptron para um dia \u00e0 frente?\n\n* **Hip\u00f3tese**: RNAs MLPs s\u00e3o aproximadoras universais de qualquer fun\u00e7\u00e3o  \n* **Metodologia**: Treinar com n-1 dias para prever o dia seguinte\n* **Avalia\u00e7\u00e3o de performance**: \n    1. Erro m\u00e9dio absoluto que, para uma \u00fanica amostra, se reduz a: $\\left| x_i - \\hat{x}_i \\right|$\n* **Busca de par\u00e2metros**: Foi feita de maneira ad-hoc em rela\u00e7\u00e3o ao n\u00famero de neur\u00f4nios nas camadas ocultas e \u00e0 fun\u00e7\u00e3o de ativa\u00e7\u00e3o. V\u00e1rios testes foram realizados. O otimizador escolhido leva em conta que h\u00e1 poucos dados dispon\u00edveis sobre o problema. O n\u00famero de itera\u00e7\u00f5es at\u00e9 a converg\u00eancia foi continuamente aumentado at\u00e9 atingir valores satisfat\u00f3rios.\n* **Precau\u00e7\u00f5es**: N\u00e3o h\u00e1 'lookahead'\n* **Conclus\u00e3o**: \u00c9 um estimador excelente para o problema!!\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How an estimator based in an Artificial Neural Network Multi-Layer Perceptron performs predicting a day ahead?\n\n* **Hypothesis**: Artificial Neural Networks (ANNs) Multi-layer Perceptrons (MLPs) can approximate any function.  \n* **Methodology**: Train with n-1 days and predict the last day.\n* **Performance Evaluation**: \n    1. Mean Absolute Error that, for a single sample, reduces to $\\left| x_i - \\hat{x}_i \\right|$\n* **Parameter Search**: It was done in an ad-hoc manner in relation to the number of neurons in each hidden layer and the activation function. Many tests have been carried out. The optimizer was chosen considering that there is little data available. The number of epochs until the convergence increases until reaching satisfactory values.\n* **Precautions**: There is no lookahead.\n* **Conclusion**: It is an excelent estimator for the problem!!\n","70dfa541":"# \ud83c\udde7\ud83c\uddf7 Estrat\u00e9gia de distribui\u00e7\u00e3o de testes \/ \ud83c\uddfa\ud83c\uddf8 Test distribution strategy\n\n- \ud83c\udde7\ud83c\uddf7 [De acordo com o Minist\u00e9rio da Sa\u00fade](http:\/\/https:\/\/saude.gov.br\/noticias\/agencia-saude\/46632-comeca-hoje-a-distribuicao-de-500-mil-testes-rapidos-para-todo-o-pais), em 01\/04\/2020 houve a distribui\u00e7\u00e3o de 500 mil testes para a popula\u00e7\u00e3o, em todos os estados\n- Os testes foram de dois tipos:  \n    1. *Testes r\u00e1pidos*: Com resultados obtidos em cerca de 20min, s\u00e3o indicados apenas para os profissionais dos servi\u00e7os de sa\u00fade e da seguran\u00e7a. Devem ser feitos ap\u00f3s o s\u00e9timo dia do in\u00edcio dos sintomas e detectam a presen\u00e7a de anticorpos contra o v\u00edrus SARS-CoV-2;\n    2. *TESTES RT-PCR*: Baseados em Biologia Molecular, eles identificam o COVID-19 em seus est\u00e1gios iniciais. Tais testes s\u00e3o usados para casos graves internados.\n- De acordo com o governo, h\u00e1 mais testes a caminho.  \n  \n\n- \ud83c\uddfa\ud83c\uddf8 [According to the Ministry of Health](http:\/\/https:\/\/saude.gov.br\/noticias\/agencia-saude\/46632-comeca-hoje-a-distribuicao-de-500-mil-testes-rapidos-para-todo-o-pais), on April 1st,2020, 500 thousand tests were distributed to the population, in all states\n- The tests were of two types:\n\u00a0\u00a0\u00a0\u00a0 1. *Rapid tests*: With results obtained in about 20 minutes, they are indicated only for health and safety professionals. They must be done after the seventh day of the onset of symptoms and detect the presence of antibodies against the SARS-CoV-2 virus;\n\u00a0\u00a0\u00a0\u00a0 2. *RT-PCR TESTS*: Based on Molecular Biology, they identify COVID-19 in its early stages. Such tests are used for severe hospitalized cases.","04d6c169":"# \ud83c\udde7\ud83c\uddf7 Examinando a S\u00e9rie Temporal de Casos e Prevendo o N\u00famero de Casos \/ \ud83c\uddfa\ud83c\uddf8 Examinating the Time Series of Cases and Predicting the Number of Cases\n\n\ud83c\udde7\ud83c\uddf7 Vamos ignorar agora a distribui\u00e7\u00e3o geogr\u00e1fica e considerar apenas o quantitativo de casos.\n\n\ud83c\uddfa\ud83c\uddf8 Let's ignore for now the geographic distribution and consider only the quantitative aspect of cases.\n","3a3ad8a6":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Qual a taxa de letalidade por Estado?\n### \ud83c\uddfa\ud83c\uddf8 Question: What is the lethality rate by State?\n","6515fe05":"### \ud83c\udde7\ud83c\uddf7 A taxa de letalidade pelo COVID-19 em cada Estado \u00e9 correlacionada com o PIB per capita?\n\n- Se o PIB total \u00e9 alto, mas o PIB per capita \u00e9 baixo, h\u00e1 grande desigualdade na popula\u00e7\u00e3o\n- Nesses casos, ao examinar o PIB per capita, temos uma vis\u00e3o melhor das condi\u00e7\u00f5es de vida da popula\u00e7\u00e3o e como isso impacta na sa\u00fade e qualidade de vida\n- Ser\u00e1 que este indicador socio-econ\u00f4mico se correlaciona com a letalidade que estamos vendo agora em cada Estado?\n- Essa quest\u00e3o foi brilhantemente sugerida por [Claudio de Pizzo](http:\/\/https:\/\/www.kaggle.com\/claudiodipizzo)\n- **Conclus\u00e3o**: Existe uma fraca correla\u00e7\u00e3o negativa, isto \u00e9, quanto maior o PIB per capita, menor \u00e9 a letalidade, mas n\u00e3o h\u00e1 tanta for\u00e7a nessa rela\u00e7\u00e3o\n\n### \ud83c\uddfa\ud83c\uddf8 Does the letality rate due to COVID-19 is correlated with GDP per capita among states?\n\n- If the total GDP is high, but the GDP per capita is low, there is great inequality in the population\n- In these cases, when examining the GDP per capita, we have a better view of the living conditions of the population and how it impacts on health and quality of life.\n- Does this socio-economic indicator correlate with the lethality that we are seeing now in each state?\n- This question was  brilliantly suggested by [Claudio de Pizzo](http:\/\/https:\/\/www.kaggle.com\/claudiodipizzo)\n- **Conclusion**: There is a weak negative correlation, i.e, as higher the GDP per capita, the lower the letality, but there is very few strenght in this relation","abfce3cd":"### \ud83c\udde7\ud83c\uddf7 A taxa de letalidade pelo COVID-19 em cada Estado \u00e9 correlacionada com o n\u00famero de leitos de UTI dispon\u00edveis?\n\n- Se h\u00e1 um bom n\u00famero de leitos, \u00e9 prov\u00e1vel que a popula\u00e7\u00e3o seja bem amparada, diminuindo a perda de vidas.\n- **Conclus\u00e3o**: Existe uma fraca correla\u00e7\u00e3o positiva, o que \u00e9 um pouco contradit\u00f3rio. Provavelmente, na pr\u00e1tica, estas duas vari\u00e1veis n\u00e3o est\u00e3o correlacionadas.\n\n### \ud83c\uddfa\ud83c\uddf8 Does the letality rate due to COVID-19 is correlated with the number of ICU beds among states?\n\n- If there is plenty ICU beds, it is likely that the population is having good health support, which might decrease deaths\n- **Conclusion**: There is a weak positive correlation, which is somewhat contradictory. In practice, these two variables may not be correlated at all.","85aa969e":"### \ud83c\udde7\ud83c\uddf7 Os testes foram distribu\u00eddos para os Estados com n\u00famero de casos e \u00f3bitos per capita?\n\n- Considerando dados por estado coletados em 31\/03\/2020\n\n### \ud83c\uddfa\ud83c\uddf8 Have the tests been distributed to the states with higher cases and deaths per capita?\n\n- Considering data from state available in 03\/31\/2020\n","73c28793":"## \ud83c\udde7\ud83c\uddf7 An\u00e1lise da Letalidade\/ \ud83c\uddfa\ud83c\uddf8 Lethality Analysis","c88e3612":"- \ud83c\udde7\ud83c\uddf7 Antes de concluir, resta a pergunta: os estados com maior PIB tem maior n\u00famero de casos e \u00f3bitos?\n- \ud83c\uddfa\ud83c\uddf8 Before concluding, the question remains: do the states with the highest GDP have a higher number of cases and deaths?","fe6b3bec":"### \ud83c\udde7\ud83c\uddf7 Pergunta: O n\u00famero de leitos de UTI tem rela\u00e7\u00e3o com o PIB per capita?\n\n- Seguindo a mesma estrat\u00e9gia anterior, apenas checando os fatores de desigualdade social.\n- Essa quest\u00e3o foi brilhantemente sugerida por [Claudio de Pizzo](http:\/\/https:\/\/www.kaggle.com\/claudiodipizzo)  \n- **Conclus\u00e3o**: Tal correla\u00e7\u00e3o parece mesmo fraca. Intrigante!\n\n### \ud83c\uddfa\ud83c\uddf8 Question: Is the number of UCI units related to PIB per capita?\n\n- Following the same strategy as before, just checking the factors of social inequality.\n- This question was  brilliantly suggested by [Claudio de Pizzo](http:\/\/https:\/\/www.kaggle.com\/claudiodipizzo)\n- **Conclusion**: Such correlation seems to be weak. Intriguing!","93105eba":"### \ud83c\udde7\ud83c\uddf7 Como foi a distribui\u00e7\u00e3o geogr\u00e1fica dos testes disponibilizados em 01\/04\/2020?\n### \ud83c\uddfa\ud83c\uddf8 How was the geographic distribution of the tests made available on April 1st, 2020?","5ce0a852":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Como se comporta uma estimador baseado em regress\u00e3o exponencial para o n\u00famero de casos?\n\n* **Holdout**: Treinar com 90% dos dados (90% dos primeiros dias) e testar nos 10% restantes\n* **Avalia\u00e7\u00e3o de performance**: Raiz do erro m\u00e9dio quadr\u00e1tico e R^2 Score\n* **Precau\u00e7\u00f5es**: N\u00e3o h\u00e1 'lookahead'\n* **Conclus\u00e3o**: N\u00e3o \u00e9 um bom estimador para o problema. O valor de R^2 negativo e alto revela que este estimador \u00e9 pior que uma reta horizontal para o cen\u00e1rio\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How a exponencial estimator performs when predicting the number of cases?\n\n* **Holdout**: Training with 90% of the data (90% first days) and test with the last 10%.\n* **Performance Evaluation**: RMSE (Root Mean Squared Error) and $R^2$ Score.\n* **Precautions**: There is no lookahead.\n* **Conclusion**: It is not a good estimator for the problem. The highly negative R^2 Score reveals that the estimator is worst than a horizontal line for the scenario. \n","f8f9b125":"# \ud83c\udde7\ud83c\uddf7 Considera\u00e7\u00f5es Finais \/ \ud83c\uddfa\ud83c\uddf8 Final Remarks\n\n- \ud83c\udde7\ud83c\uddf7 A utiliza\u00e7\u00e3o de conhecimentos sobre a auto-correla\u00e7\u00e3o total e parcial da s\u00e9rie foi a melhor estrat\u00e9gia para previs\u00e3o um dia \u00e0 frente\n- Utilizou-se dados dos casos do dia anterior para auxiliar no aprendizado dos padr\u00f5es impl\u00edcitos no crescimento da s\u00e9rie\n- O melhor modelo obtido foi uma Rede Neural Multi Layer Perceptron com duas camadas ocultas e 200 neur\u00f4nios em cada camada, fun\u00e7\u00e3o de ativa\u00e7\u00e3o 'relu'e otimizador LBFGS em virtude da pequena quantidade de dados\n- A RNA se mostrou bastante tolerante aos ru\u00eddos e capturou adequadamente flutua\u00e7\u00f5es que n\u00e3o est\u00e3o nos dados em si, tais como: \n   - Chegada de mais kits de testes\n   - Subnotifica\u00e7\u00e3o\n   - Notifica\u00e7\u00e3o tardia\n   \n\n- \ud83c\uddfa\ud83c\uddf8 The use of knowledge about autocorrelation and partial autocorrelation was the best strategy to predict a day ahead.\n- The number of cases in the previous day was used to help the models to learn implicit patterns in the series growth.\n- The best model obtained was an ANN MLP with two hidden layers and 200 neurons each, using `relu` as the activation function and `LBFGS` as the optimizer, in virtue of the small amount of data.\n- The ANN has shown tolerance to noise and appropriately captured fluctuations that are not in the data itself, such as:\n    * The arrival of more testing kits\n    * Subnotification\n    * Late notification","d5c03311":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Qual a taxa de letalidade do Coronav\u00edrus no Brasil?\n\n**Resposta**:\n\n- Qual a taxa de letalidade no Brasil, obtida com os dados mais recentes dispon\u00edveis?\n- O c\u00e1lculo da taxa de letalidade \u00e9 dado por:\n\n$$\n\\textrm{Taxa de letalidade} =  \\frac{\\sum \\textrm{\u00f3bitos}}{\\sum \\textrm{casos}}\n$$\n\n### \ud83c\uddfa\ud83c\uddf8 Question: What is the lethality rate of Coronavirus in Brazil?\n\n**Answer**:  \n- What is the lethality rate in Brazil, calculated with the most recent data?\n- The lethality rate is calculated by:\n\n$$\n\\textrm{Lethality rate} = \\frac{\\sum \\textrm{deaths}}{\\sum \\textrm{cases}}\n$$\n","ff827813":"# Data Analytics\n\n- \ud83c\udde7\ud83c\uddf7 An\u00e1lise de dados sobre os casos, \u00f3bitos, propor\u00e7\u00f5es, distribui\u00e7\u00e3o geogr\u00e1fica, etc.\n- Base de dados atualizada diariamente e oriunda daqui: https:\/\/www.kaggle.com\/unanimad\/corona-virus-brazil\n\n---\n\n- \ud83c\uddfa\ud83c\uddf8 Data analysis over the confirmed cases, deaths, proportions, geographic distribuition, etc\n- Database daily updated acquired here: https:\/\/www.kaggle.com\/unanimad\/corona-virus-brazil","927cf1c0":"# \ud83c\udde7\ud83c\uddf7 Confira minha participa\u00e7\u00e3o no PyData Manaus\n\n<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/VXDU3nzFTTw?controls=0&amp;start=334\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>\n\n","6f20e3e0":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Como se comporta um estimador bastante simples, baseado em regress\u00e3o linear, para prever o n\u00famero de casos?\n\n\n* **Holdout**: Treinar com 90% dos dados (90% dos primeiros dias) e testar nos 10% restantes\n* **Avalia\u00e7\u00e3o de performance**: Raiz do erro m\u00e9dio quadr\u00e1tico e $R^2$ Score\n* **Precau\u00e7\u00f5es**: N\u00e3o h\u00e1 'lookahead'\n* **Conclus\u00e3o**: Como esperado, n\u00e3o h\u00e1 como uma regress\u00e3o linear capturar bem o formato da tend\u00eancia de crescimento. Portanto, o regressor subestima o n\u00famero de casos em rela\u00e7\u00e3o ao cen\u00e1rio real.\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How a simple estimator, based on linear regression, performs when predicting the number of cases?\n\n* **Holdout**: Training with 90% of the data (90% first days) and test with the last 10%.\n* **Performance Evaluation**: RMSE (Root Mean Squared Error) and $R^2$ Score.\n* **Precautions**: There is no lookahead.\n* **Conclusion**: As expected, it is not possible for a linear regression to capture the format and tendency of growth. Therefore, the regressor underestimates the number of cases when compared to the real scenario.\n","31d2b19d":"### \ud83c\udde7\ud83c\uddf7 Pergunta: E quanto ao IDH-M?\n\nO IDH-M data de 2017.\n\nA correla\u00e7\u00e3o encontra-se na categoria moderada (de 0,5 a 0,7), mas pr\u00f3ximo ao limiar inferior, sugindo fraqueza.  \nAssim, v\u00ea-se que a prepoder\u00e2ncia de outros aspectos da qualidade de vida aferidos no IDH-M sejam mais relevantes que os leitos de UTI. De fato, quando examina-se a composi\u00e7\u00e3o do IDH-M, esta hip\u00f3tese \u00e9 corroborada. Ver links \u00fateis no final.\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How about the cities' GDP?\n\nThe data for this analysis is from 2017.\n\nThe correlation is moderate (from 0.5 to 0.7), but closer to the lowest boundary, suggesting a week correlation.  \nTherefore, it is possible to see the dominance of other aspects of life quality that are more relevant in the cities' GDP than the number of ICU beds. In fact, when analyzing the composing of the cities' GDP, this hypothesis is corroborated. Check the useful links at the end.","e0a7913f":"| **Data da Previs\u00e3o** | **N\u00famero de Casos Previstos** | **N\u00famero de Casos Real** | **Observa\u00e7\u00e3o**|\n| --- | --- | ---| --- |  \n| 03\/04\/2020 | 9152 | 9056 |  |\n| 04\/04\/2020 | 10432 | 10278 |   | \n| 05\/04\/2020 | 11766 | 11130|    |\n| 06\/04\/2020 |  12521     |12056 |  |\n| 07\/04\/2020 |  13379     |  14347   |  |\n| 08\/04\/2020 | 15316     | 15927    |   |\n| 09\/04\/2020 | 17943 | 17857 | A posteriori em 10\/04  |\n| 10\/04\/2020 | 20071 | 19638 |  |\n| 11\/04\/2020 | 21923      |20727      |  |\n| 12\/04\/2020 |  21919     | 22169       |  |\n| 13\/04\/2020 | 24097   |   23430   |  |\n| 14\/04\/2020 | 25353     | 25262   |  |\n| 15\/04\/2020 | 27010      | 28320 |      |\n| 16\/04\/2020 | 30788   | 30425    | A posteriori em 17\/04  |\n| 17\/04\/2020 | 32730   | 33682    |  |\n| 18\/04\/2020 |36598       | 36599      | A posteriori em 20\/04 - Erro por um caso! |\n| 19\/04\/2020| 39721         |   38654      | A posteriori em 20\/04  | \n| 20\/04\/2020| 41664     |40581     | A posteriori em 22\/04 |\n| 21\/04\/2020|  43517       |    43079     | A posteriori em 22\/04    | \n| 22\/04\/2020|  45985       |  45757  |    | \n| 23\/04\/2020|   48708         |   49492    | (Buffer de testes divulgado de uma vez s\u00f3?)   |\n| 24\/04\/2020| 52806 |   52995 |   |\n| 25\/04\/2020| 56585 | 58509  |   |\n| 26\/04\/2020| 62838      | 63584    |    |\n| 27\/04\/2020| 66246   |  66501  |    | \n| 28\/04\/2020| 71186 | 71886 | |\n| 29\/04\/2020| 77052      | 78162   |.  |\n| 30\/04\/2020| 83951       | 85380   |.  |\n|01\/05\/2020 | 91967  | 91589   |   | \n| 02\/05\/2020 | 98552 | 96396 | | \n| 03\/05\/2020 | 103467 | 101147 | A posteriori em 04\/05|\n| 04\/05\/2020 | 107909 | 107780  | | \n| 05\/05\/2020|  111746   | 114715  | (Erro no preenchimento do dataset? -- Corrigido!)|\n| 06\/05\/2020|  122221  | 125218    |.    | \n| 07\/05\/2020 | 133920     | 135106   |.  |\n| 08\/05\/2020 | 144682 |145328  |. |\n| 09\/05\/2020 | 155719 |155939  |. |\n| 10\/05\/2020 |167089   | 162699  |  | \n| 11\/05\/2020 | 173487   |168331  |  .| \n| 12\/05\/2020| 178559    |177589   |. |\n| 13\/05\/2020|  188156 | 188974 | . |\n| 14\/05\/2020| 200292 | 202918 | .|\n| 15\/05\/2020| 215428 | 218223 | .|\n| 16\/05\/2020|  232085   | 233142   |.   |\n| 17\/05\/2020|248059      | 241080    | (A posteriori em 18\/05\/2020) |\n| 18\/05\/2020|255226    |254220  |. |\n| 19\/05\/2020| 268995  |271628   |.  |\n| 20\/05\/2020|287681    |291579    |.    |  \n| 21\/05\/2020| 309425 | 310087 | | \n| 22\/05\/2020| 329081 | 330890 | |\n| 23\/05\/2020| 351431 | 347398 | (A posteriori em 24\/05\/2020) | \n| 24\/05\/2020| 368255 | 363211 | | \n| 25\/05\/2020| 384151| 374898| |\n| 26\/05\/2020| 394788| 391222 |(A posteriori em 27\/05\/2020) |\n| 27\/05\/2020| 411194| 411821 | |\n| 28\/05\/2020|431782      |438238     |.  |\n| 29\/05\/2020| 461557     |  465166    |.  |\n|30\/05\/2020|  490163    |  498440    |.  |\n| 31\/05\/2020| 526460     |  514849    |.  |\n| 01\/06\/2020| 542052    | 526447   |. | \n| 02\/06\/2020| 551830 | 555383 | .|\n| 03\/06\/2020|582685  | 584016  | (A posteriori em 04\/06\/2020) |\n| 04\/06\/2020|612518  | 614941  | (Mudan\u00e7a no hor\u00e1rio de divulga\u00e7\u00e3o dos resultados)  |\n| 05\/06\/2020 |645351  |.   |.  |\n","8606427b":"### \ud83c\udde7\ud83c\uddf7 E a cada 3 dias?\n### \ud83c\uddfa\ud83c\uddf8 And every 3 days?","cfba856f":"# \ud83c\udde7\ud83c\uddf7 Palpite para o futuro: N\u00famero de casos amanh\u00e3\/ \ud83c\uddfa\ud83c\uddf8 Guessing the future: Number of cases tomorrow\n\n - \ud83c\udde7\ud83c\uddf7 Obtido automaticamente a partir do mesmo modelo retreinado com todos os dados\n - Ser\u00e3o realizadas 20 execu\u00e7\u00f5es, para minimizar o vi\u00e9s estoc\u00e1stico da inicializa\u00e7\u00e3o aleat\u00f3ria dos pesos\n - Ser\u00e1 considerada a previs\u00e3o mais otimista, com o menor n\u00famero de casos\n \n \n - \ud83c\uddfa\ud83c\uddf8 Automatically obtained using the same model retrained with all the data\n - Will be run 20 times, to minimize the stochastic bias of the random weight initialization\n - The most optimistic prediction will be considered, with the lowest amount of cases","8b55239b":"### \ud83c\udde7\ud83c\uddf7 Pergunta: A tend\u00eancia de crescimento dos casos \u00e9 de ordem exponencial?\n\n* Modifica\u00e7\u00e3o: Quantidade de dias desde o primeiro caso versus casos no dia\n* Vamos fazer um scatterplot do logaritmo dos casos versus o n\u00famero de dias.\n* Caso tenda a uma reta, h\u00e1 fortes evid\u00eancias positivas para a pergunta em quest\u00e3o\n* **Conclus\u00e3o**: Considerando os dados atuais, n\u00e3o estamos fortemente em ordem exponencial, embora a tend\u00eancia ainda seja crescente. H\u00e1 que se salientar que esta conclus\u00e3o baseia-se apenas nos dados dispon\u00edveis no dataset e pode estar havendo subnotifica\u00e7\u00e3o de casos em raz\u00e3o de dificuldades na ampla testagem.\n\n### \ud83c\uddfa\ud83c\uddf8 Question: The cases growth tendency is exponencial?\n\n* Modification: Number of days since the first case vs. Number of cases in the day.\n* Let's make a scatter plot of the logarithm of cases versus the number of days.\n* If it tends to a straight line, there are strong positive evidences to the standing question.\n* **Conclusion**: Considering the current version of the data, there is no strength in the exponential tendency, even that the tendency is growing. We need to point out that this conclusion is based only on the data available in the dataset, and sub notification might be occurring due to difficulties in extensive wide testing.","b75ad104":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Como se comporta uma estimador baseado em Rede Neural Artificial Multi-Layer Perceptron para um dia \u00e0 frente + ACF da s\u00e9rie temporal?\n\n* **Hip\u00f3teses**:\n    1. RNAs MLPs s\u00e3o aproximadoras universais de qualquer fun\u00e7\u00e3o  \n    2. Algumas s\u00e9ries temporais s\u00e3o auto-correlacionadas\n* **Metodologia**: \n    1. Calcular o ACF da S\u00e9rie Temporal\n    2. Defasar a s\u00e9rie temporal conforme o resultado anterior\n    3. Treinar a mesma arquitetura de RNA MLP anterior com n-1 dias para prever o dia seguinte\n* **Avalia\u00e7\u00e3o de performance**: \n    1. Erro m\u00e9dio absoluto que, para uma \u00fanica amostra, se reduz a: $\\left| x_i - \\hat{x}_i \\right|$\n* **Precau\u00e7\u00f5es**: N\u00e3o h\u00e1 'lookahead'\n* **Conclus\u00e3o**:\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How an ANN MLP estimator performs in the task of predicting a day ahead + Time Series ACF?\n\n* **Hypothesis**:\n    1. ANN MLPs can approximate any function.\n    2. Some Time Series are autocorrelated.\n* **Methodology**: \n    1. Calculate the autocorrelation function of the Time Series.\n    2. Lag the Time Series based on the previous result.\n    3. Train an MLP with the same architecture that we used in the last example using $n-1$ days and predict the $n-th$ day.\n* **Performance Evaluation**: \n    1. Mean Absolute Error that, for a single sample, reduces to $\\left| x_i - \\hat{x}_i \\right|$\n* **Precau\u00e7\u00f5es**: There is no lookahead.\n* **Conclusion**:","ec1faaaa":"### \ud83c\udde7\ud83c\uddf7 Os testes foram distribu\u00eddos para os Estados com maior n\u00famero de \u00f3bitos? \n\n- Considerando dados por estado coletados em 31\/03\/2020\n- **Conclus\u00e3o**: As mesmas conclus\u00f5es anteriores se aplicam.\n\n### \ud83c\uddfa\ud83c\uddf8 Have the tests been distributed to the states with the highest number of deaths?\n\n- Considering data from state available in 03\/31\/2020\n- **Conclusion**: The same conclusions as above apply.","f42e4046":"### \ud83c\udde7\ud83c\uddf7 Os testes foram distribu\u00eddos para os Estados com maior n\u00famero de casos? \n\n- Vamos considerar o n\u00famero de casos por estado em 31\/03\/2020\n- **Conclus\u00e3o**: No caso dos testes r\u00e1pidos, h\u00e1 fortes evid\u00eancias que o n\u00famero de casos foi determinante para a estrat\u00e9gia de distribui\u00e7\u00e3o dos mesmos. No caso dos testes RT-PRC, n\u00e3o h\u00e1 igual for\u00e7a de evid\u00eancia na afirma\u00e7\u00e3o.\n\n### \ud83c\uddfa\ud83c\uddf8 Have the tests been distributed to the states with the highest number of cases?\n\n- Let's consider the number of cases per state in 03\/31\/2020\n- **Conclusion**: In the case of rapid tests, there is strong evidence that the number of cases was decisive in  distribution strategy. In the case of RT-PRC tests, there is no equal strength of evidence in the statement.","c354b9b2":"- \ud83c\udde7\ud83c\uddf7 **Conclus\u00e3o**: Na minha opini\u00e3o, a distribui\u00e7\u00e3o de testes poderia ter sido ainda melhor, considerando a propor\u00e7\u00e3o de doentes e \u00f3bitos nos estados, n\u00e3o o quantitativo geral.\n- \ud83c\uddfa\ud83c\uddf8 **Conclusion**: In my opinion, the distribution of tests could have been even better, considering the proportion of patients and deaths in the states, not the general number.","909abc52":"\ud83c\udde7\ud83c\uddf7 **Conclus\u00e3o**: Por muito tempo, o n\u00famero de casos pareceu mais que dobrar a cada tr\u00eas dias!  \n\ud83c\uddfa\ud83c\uddf8 **Conclusion**: For a long time the number of cases seemed to more than double every three days!","a90b52ed":"- \ud83c\udde7\ud83c\uddf7 **Conclus\u00e3o**: Estados com maior PIB receberam maior quantidade de testes porque tamb\u00e9m registraram maior n\u00famero de casos e \u00f3bitos. A distribui\u00e7\u00e3o de testes na ocasi\u00e3o parece ter considerado o panorama dispon\u00edvel de maneira consistente e estrat\u00e9gica.\n- \ud83c\uddfa\ud83c\uddf8 **Conclusion**: Higher GDP states received more tests because they also recorded a higher number of cases and deaths. The distribution of tests at the time seems to have considered the panorama available in a consistent and strategic way.","71089639":"### \ud83c\udde7\ud83c\uddf7 Pergunta: A qual per\u00edodo de tempo os dados se referem?\n\n**Resposta**:  \n\n### \ud83c\uddfa\ud83c\uddf8 To which period of time the data refers to?\n\n**Answer**:  ","7fa7c6d6":"#### \ud83c\udde7\ud83c\uddf7 Parte 4: Preparando os dados\n\nCom vistas a obter a seguinte prepara\u00e7\u00e3o dos dados\n* Atributos preditores: \n    1. Dia $t$\n    2. N\u00famero de casos no dia $t$\n    3. N\u00famero de casos no dia $t - 1$\n* Atributo alvo: n\u00famero de casos no dia $t + 1$\n\n#### \ud83c\uddfa\ud83c\uddf8 Step 4: Preparing the data\n\nLooking forward to obtaining the following preparation of data:\n* Features:\n    1. Day $t$\n    2. Number of cases in $t$\n    3. Number of cases in $t - 1$\n* Target variable: number of cases in $t + 1$","60768cc2":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Os Estados com maior PIB tamb\u00e9m mais investem mais em leitos de UTI no SUS?\n\nVamos analisar esta pergunta por meio da correla\u00e7\u00e3o do PIB com o n\u00famero de leitos existentes. Se a correla\u00e7\u00e3o for positiva e forte, h\u00e1 uma boa evid\u00eancia de que isto, de fato, ocorra, pois viria a demonstrar um retorno para popula\u00e7\u00e3o por meio de um bom servi\u00e7o de sa\u00fade.\n\nA correla\u00e7\u00e3o resultou em 0.97, indicando fortes evid\u00eancias a favor desta hip\u00f3tese.\n\n### \ud83c\uddfa\ud83c\uddf8 Question: The States with the highest GDP also invest more in ICU beds in Public Health?\n\n**Clarification**: SUS is an abbreviation of Sistema \u00danico de Sa\u00fade, which stands for Unique Health System. SUS is the primary public health care in Brazil.\n\nLet us analyze this question through the correlation between GDP and the number of ICU beds. If it is a positive strong correlation, there is good evidence that this, in fact, occurs, since it demonstrates a return to the population by a good health system.","d2fe860c":"### \ud83c\udde7\ud83c\uddf7 O n\u00famero de casos de COVID-19 em cada Estado \u00e9 correlacionado com o PIB per capita?\n\n- Ser\u00e1 que o PIB per capita alto favorece a diminui\u00e7\u00e3o da contamina\u00e7\u00e3o? Pode haver uma indica\u00e7\u00e3o de que acesso a recursos materiais favore\u00e7a acesso \u00e0 saneamento, educa\u00e7\u00e3o e outros elementos que podem ser estrat\u00e9gicos para uma menor exposi\u00e7\u00e3o ao v\u00edrus?\n- Essa quest\u00e3o foi brilhantemente sugerida por [Claudio de Pizzo](http:\/\/https:\/\/www.kaggle.com\/claudiodipizzo)\n- **Conclus\u00e3o**: Existe uma fraca correla\u00e7\u00e3o positiva, n\u00e3o \u00e9 poss\u00edvel supor tal hip\u00f3tese.\n\n### \ud83c\uddfa\ud83c\uddf8 Is the number of COVID-19 cases per State is correlated with GDP per capita?\n\n- Does the high GDP per capita favor the reduction of contamination? Could there be an indication that access to material resources favors access to sanitation, education and other elements that may be strategic for less exposure to the virus?\n- This question was  brilliantly suggested by [Claudio de Pizzo](http:\/\/https:\/\/www.kaggle.com\/claudiodipizzo)\n- **Conclusion**: There is a weak positive correlation, therefore it is not possible to suppose such hypothesis.","54b31a55":"# \ud83c\udde7\ud83c\uddf7 Rela\u00e7\u00e3o com Indicadores S\u00f3cio-Economicos \/ \ud83c\uddfa\ud83c\uddf8 Relation with Socio-Economic Indicators\n\n- \ud83c\udde7\ud83c\uddf7 As an\u00e1lises a seguir contemplam aspectos de indicadores s\u00f3cio-econ\u00f4micos e recursos dispon\u00edveis para o combate ao COVID-19 em cada estado\n\n- \ud83c\uddfa\ud83c\uddf8  The following analisis contemplate socio-economic indicators and resources available to fight COVID-19 in each state\n","52ffbde1":"### \ud83c\udde7\ud83c\uddf7 Pergunta: Quantos leitos de UTI do SUS h\u00e1 por Estado?\n\n- Os dados obtidos neste sentido s\u00e3o de 2018 e n\u00e3o contemplam atualiza\u00e7\u00f5es recentes, decorrente dos hospitais de campanha que est\u00e3o sendo constru\u00eddos, por exemplo.\n- Este dado auxilia a estimar os recursos para enfrentamento dos casos mais graves.\n- Dados de UTI de 2018 extra\u00eddos do site do Conselho Federal de Medicina. Conferir nos links \u00fateis.  \n- Os leitos de UTI somam todos os tipos, desde adulto nos graus I a III, infantil I a III, neonatal I a III, queimados, coronariana e outros.\n\n### \ud83c\uddfa\ud83c\uddf8 Question: How many ICU beds each state have?\n\n- The data obtained in this matter are from 2018 and have no recent updates, from field hospitals being built, for instance.\n- This data helps estimating the resources to face the most serious cases.\n- The ICU data of 2018 were extracted from the Federal Council of Medicine. Check the useful links.\n- The ICU beds number is the sum of every type of ICU: Adult I to III, Infant I to III, neonatal I to III, burns, coronary, and others."}}