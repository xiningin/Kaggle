{"cell_type":{"7c9daf2f":"code","f7607537":"code","56072545":"code","4462c704":"code","6711c54a":"code","70294a58":"code","cc782eb0":"code","700c6885":"code","b029803f":"code","28dafaa9":"code","7377a3af":"code","05c4c13d":"code","768cf49b":"code","4293085e":"code","81c0cc52":"code","3526a640":"code","605a170a":"code","4f7f212d":"code","076d5034":"code","41de54e4":"code","a72f5dda":"code","64beb601":"code","b73518bd":"code","6cf62d5c":"code","2f4ff115":"code","88ef31ca":"code","25cd1fe0":"code","a23e4ac7":"code","fc200322":"code","05bea7ba":"code","00da9804":"code","af601fd3":"code","6387e3d1":"code","0ee60942":"code","860789c0":"code","54fc5a22":"code","79e59379":"code","d9c3d092":"code","8d8dbf16":"code","bc37d764":"code","9a83b80a":"code","ba18524f":"code","ce73673d":"code","e4013aa6":"code","cfa9d2d3":"code","9838cd66":"code","a1fab72c":"code","d01276c3":"code","6673780d":"code","f3896365":"code","d138b575":"code","d6657204":"code","6ab75452":"code","d373c62c":"code","9e460f01":"code","64828bba":"code","a18fade0":"code","b02a5dc2":"markdown","23b2912d":"markdown","6d4d5890":"markdown","7b1649c2":"markdown","71a981fe":"markdown","ba06400d":"markdown","6bbe7928":"markdown","723f910e":"markdown","b5747f9f":"markdown","caaed83f":"markdown","a3a9da6a":"markdown","0b84f7e5":"markdown","905945a1":"markdown","cc75a396":"markdown","151cc4a3":"markdown","f6e75ef3":"markdown","851c4fff":"markdown","6cda484f":"markdown","f57f24d7":"markdown","67df1418":"markdown","0445d21c":"markdown","0930b9c8":"markdown","b7d138b3":"markdown","e8fb247d":"markdown","9eaf9353":"markdown","b1dce406":"markdown","b48789db":"markdown","1de48630":"markdown","2a56c180":"markdown","c7897dc6":"markdown","b72f4ae8":"markdown","bed48d1c":"markdown","7c9f8081":"markdown","336dcb2a":"markdown","656d9af8":"markdown","d054cde3":"markdown","f99209dd":"markdown","0d5d2612":"markdown"},"source":{"7c9daf2f":"import warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom collections import Counter\nfrom matplotlib import pyplot as plt\n\nwarnings.filterwarnings('ignore')","f7607537":"train = pd.read_excel('..\/input\/book-price-machinehack\/Data_Train.xlsx')\ntest = pd.read_excel('..\/input\/book-price-machinehack\/Data_Test.xlsx')","56072545":"train.drop_duplicates(inplace=True)","4462c704":"train.head()","6711c54a":"combined = pd.concat([train, test], sort=False)\ncombined.reset_index(drop=True, inplace=True)","70294a58":"combined['Title'] = combined['Title'].str.lower()","cc782eb0":"# title_split = combined['Title'].str.split('\\(').str.join('--')\\\n#                                .str.split('\\)').str.join('--')\\\n#                                .str.split('--',expand=True,n=2)\n\n# combined['subtitle'] = title_split[1].fillna('None')\n# combined['Title'] = title_split[0]","700c6885":"combined[['EditionBinding','EditionType1']] = \\\n    combined['Edition'].str.split(',\u2013 ',expand=True)","b029803f":"edition_binding_dict = combined['EditionBinding'].value_counts().to_dict()\n\ncombined['EditionBinding'] = combined['EditionBinding'].apply(lambda x: \\\n        (x if edition_binding_dict[x] > 9 else 'other'))","28dafaa9":"def split_edition_1(x):\n    j_arr = []\n    date = ''\n\n    for j in x.split(', '):\n        if not any(k.isnumeric() for k in j):\n            j_arr.append(j.strip())\n        else:\n            date = j\n\n    if ''.join(j_arr) != '':\n        ed = ', '.join(j_arr)\n    else:\n        ed = 'other'\n\n    if ed != 'Import' and ed != 'Illustrated' and ed \\\n        != 'Special Edition' and ed != 'Unabridged' and ed \\\n        != 'Student Edition' and ed != 'Box set' and ed \\\n        != 'International Edition' and ed != 'Abridged':\n        ed_ret = 'other'\n    else:\n        ed_ret = ed\n\n    return (ed_ret, date)","7377a3af":"combined['EditionType'],combined['EditionDate'] = \\\n    zip(*combined['EditionType1'].apply(split_edition_1))","05c4c13d":"def split_edition_date(x):\n    (mon, year) = ('', '')\n    if len(x.split()) == 1:\n        year = int(x)\n    elif len(x.split()) == 2:\n        mon = x.split()[0]\n        year = int(x.split()[1])\n    elif len(x.split()) == 3:\n        mon = x.split()[1]\n        year = int(x.split()[2])\n    return (mon, year)","768cf49b":"combined['EditionMon'], combined['EditionYear'] = \\\n    zip(*combined['EditionDate'].apply(split_edition_date))","4293085e":"def bin_edition_mon(x):\n    x = x.lower()\n    if x == 'jan' or x == 'feb' or x == 'mar':\n        return 'first'\n    elif x == 'apr' or x == 'may' or x == 'jun':\n        return 'second'\n    elif x == 'jul' or x == 'aug' or x == 'sep':\n        return 'third'\n    elif x == '':\n        return ''\n    else:\n        return 'fourth'","81c0cc52":"combined['EditionMon'] = combined['EditionMon'].apply(bin_edition_mon)\n\ncombined['Mon_null'] = combined['EditionMon'].apply(lambda x: \\\n        ('not_null' if x != '' else 'null'))\ncombined['Year_null'] = combined['EditionYear'].apply(lambda x: \\\n        ('not_null' if x != '' else 'null'))","3526a640":"combined['EditionMon'].replace('', combined['EditionMon'].mode()[0],\n                               inplace=True)\ncombined['EditionYear'].replace('', combined['EditionYear'].mode()[0],\n                                inplace=True)","605a170a":"combined['Reviews'] = combined['Reviews'].apply(lambda x: \\\n        float(x.split()[0]))","4f7f212d":"combined['Ratings'] = combined['Ratings'].apply(lambda x: \\\n        int(''.join(x.split()[0].split(','))))","076d5034":"combined['RatingPerReview'] = round(combined['Ratings']\n                                    \/ combined['Reviews'], 2)","41de54e4":"combined['Review_Year_Impact'] = combined['Reviews'] \\\n    * combined['EditionYear'].apply(lambda x: 2019 - x)","a72f5dda":"author_replacements = {' & ':', ',\"0\":\"other\",\"2\":\"other\",'A. P. J. Abdul Kalam':'A.P.J. Abdul Kalam','APJ Abdul Kalam':'A.P.J. Abdul Kalam','Agrawal P. K.': 'Agrawal P.K','Ajay K Pandey': 'Ajay K. Pandey','Aravinda Anantharaman': 'Aravinda Anatharaman','Arthur Conan Doyle': 'Sir Arthur Conan Doyle','B A Paris': 'B. A. Paris','E L James': 'E. L. James','E.L. James':'E. L. James','Eliyahu M Goldratt': 'Eliyahu M. Goldratt','Ernest Hemingway': 'Ernest Hemmingway','Frank Miler': 'Frank Miller','Fyodor Dostoevsky': 'Fyodor Dostoyevsky','George R R Martin': 'George R. R. Martin','George R.R. Martin':'George R. R. Martin','H. G. Wells': 'H.G. Wells','Johann Wolfgang Von Goethe': 'Johann Wolfgang von Goethe','John Le Carr\u00e9': 'John le Carr\u00e9','Judith McNaught': 'Judith Mcnaught','Keith Giffen': 'Kieth Giffen','Ken Hultgen': 'Ken Hultgren','Kentaro Miura': 'Kenturo Miura','Kohei Horikoshi': 'Kouhei Horikoshi','M.K Gandhi': 'M.K. Gandhi','Matthew K Manning': 'Matthew Manning','Michael Crichton': 'Micheal Crichton','N.K Aggarwala': 'N.K. Aggarwala','Oxford University Press (India)': 'Oxford University Press India','P D James': 'P. D. James','Paramahansa Yogananda': 'Paramhansa Yogananda','R K Laxman': 'R. K. Laxman','R.K. Laxman': 'R. K. Laxman','R. M. Lala': 'R.M. Lala','Raina Telgemaeier': 'Raina Telgemeier','Rajaraman': 'Rajaraman V','Rajiv M. Vijayakar': 'Rajiv Vijayakar','Ramachandra Guha': 'Ramchandra Guha','Rene Goscinny': 'Ren\u00e9 Goscinny','Richard P Feynman': 'Richard P. Feynman','S Giridhar': 'S. Giridhar','S Hussain Zaidi': 'S. Hussain Zaidi','S. A. Chakraborty': 'S. Chakraborty','Santosh Kumar K': 'Santosh Kumar K.',\"S.C. Gupta\" : \"S. C. Gupta\",'Shiv Prasad Koirala': 'Shivprasad Koirala','Shivaprasad Koirala': 'Shivprasad Koirala','Simone De Beauvoir': 'Simone de Beauvoir','Sir Arthur Conan Doyle': 'Arthur Conan Doyle',\"Terry O' Brien\": \"Terry O'Brien\",'Thich Nhat Hahn': 'Thich Nhat Hanh','Trinity College Lond': 'Trinity College London',\"Trinity College London Press\" : \"Trinity College London\",'Ursula K. Le Guin': 'Ursula Le Guin','Willard A Palmer': 'Willard A. Palmer','Willard Palmer': 'Willard A. Palmer','William Strunk Jr': 'William Strunk Jr.','Yashavant Kanetakr': 'Yashavant Kanetkar','Yashavant P. Kanetkar': 'Yashavant Kanetkar','Yashwant Kanetkar': 'Yashavant Kanetkar','et al': 'et al.',' et al': 'et al.','Peter Clutterbuck': ' Peter Clutterbuck','Scholastic': 'Scholastic ','Ullekh N. P.': 'Ullekh N.P.','Shalini Jain': 'Dr. Shalini Jain','Kevin Mitnick': 'Kevin D. Mitnick'}\ncombined['Author'] = combined['Author'].replace(author_replacements,regex=True)","64beb601":"combined['Authors_count'] = combined['Author'].apply(lambda x: \\\n        len(x.split(',')))","b73518bd":"author_avg_review_dict = round(combined[combined.Authors_count== 1]\n                               .groupby('Author',sort=False)['Reviews']\n                               .mean(), 2).to_dict()","6cf62d5c":"def check_author(x):\n    reviews = []\n    for name in x.split(', '):\n        try:\n            reviews.append(author_avg_review_dict[name])\n        except:\n            pass\n    if len(reviews) != 0:\n        return sum(reviews) \/ len(reviews)\n    else:\n        return ''","2f4ff115":"combined['AuthorAvgReview'] = combined['Author'].apply(check_author)\ncombined['AuthorAvgReview'] = combined[['Reviews', 'AuthorAvgReview']]\\\n        .apply(lambda x: (x[0] if x[1] == '' else x[1]), axis=1)","88ef31ca":"combined['Count_Author_Title'] = combined['Author'].map(combined.groupby('Author',sort=False)['Title'].apply(lambda x: len(x.unique())).to_dict())","25cd1fe0":"combined['MEAN_Title_Authors_count'] = round(combined\n                                            .groupby('Title',sort=False)['Authors_count']\n                                            .transform('mean'), 2)\n\ncombined['MEAN_Ttle_Reviews'] = round(combined\n                                      .groupby('Title',sort=False)['Reviews']\n                                      .transform('mean'), 2)\n\ncombined['Title_count'] = combined.groupby('Title',sort=False)['Title']\\\n                                  .transform('count')","a23e4ac7":"title_cat_dict = combined[combined.Authors_count == 1]\\\n                 .groupby('Title',sort=False)['BookCategory']\\\n                 .apply(lambda x: ', '.join(x)).to_dict()\ncombined['TitleCategories'] = combined['Title'].map(title_cat_dict)\ncombined['TitleCategories'] = combined[['BookCategory','TitleCategories']]\\\n                              .apply(lambda x: (x[0] if pd.isna(x[1]) else x[1]),axis=1)","fc200322":"title_genre_dict = combined[combined.Authors_count == 1]\\\n                   .groupby('Title',sort=False)['Genre']\\\n                   .apply(lambda x: ', '.join(x)).to_dict()\ncombined['TitleGenres'] = combined['Title'].map(title_genre_dict)\ncombined['TitleGenres'] = combined[['Genre', 'TitleGenres']]\\\n                          .apply(lambda x: (x[0] if pd.isna(x[1]) else x[1]), axis=1)","05bea7ba":"author_cat_dict = combined[combined.Authors_count==1]\\\n                 .groupby('Author',sort=False)['BookCategory']\\\n                 .apply(lambda x: ', '.join(x)).to_dict()\ncombined['AuthorCategories'] = combined['Author'].map(author_cat_dict)\ncombined['AuthorCategories'] = combined[['BookCategory','AuthorCategories']]\\\n                               .apply(lambda x: x[0] if pd.isna(x[1]) else x[1],axis=1)","00da9804":"author_genre_dict = combined[combined.Authors_count==1]\\\n                    .groupby('Author',sort=False)['Genre']\\\n                    .apply(lambda x: ', '.join(x)).to_dict()\ncombined['AuthorGenres'] = combined['Author'].map(author_genre_dict)\ncombined['AuthorGenres'] = combined[['Genre','AuthorGenres']]\\\n                           .apply(lambda x: x[0] if pd.isna(x[1]) else x[1],axis=1)","af601fd3":"combined['TitleGenres'] = combined['TitleGenres'].str.replace(' & ',', ')\ncombined['AuthorGenres'] = combined['AuthorGenres'].str.replace(' & ',', ')\ncombined['Genre'] = combined['Genre'].str.replace(' & ',', ')","6387e3d1":"combined['EditionYearBin'] = pd.qcut(combined['EditionYear'],5,labels=False)","0ee60942":"from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()\ncombined[['BookCategory','EditionBinding','EditionMon','EditionType','EditionYearBin','Mon_null','Year_null',]] = \\\ncombined[['BookCategory','EditionBinding','EditionMon','EditionType','EditionYearBin','Mon_null','Year_null',]]\\\n    .apply(enc.fit_transform)","860789c0":"from sklearn.feature_extraction.text import CountVectorizer\n\ntc_vectorizer = CountVectorizer(lowercase=True, tokenizer=lambda x: \\\n                                 x.split(', '))\ntitle_categories_vector = tc_vectorizer.fit_transform(combined['TitleCategories']).toarray()\ndf_title_categories = pd.DataFrame(data=title_categories_vector,\n                      columns=tc_vectorizer.get_feature_names())","54fc5a22":"ac_vectorizer = CountVectorizer(lowercase=True, \n                                 tokenizer=lambda x: x.split(', '))\nauthor_categories_vector = ac_vectorizer.fit_transform(combined['AuthorCategories']).toarray()\ndf_author_categories = pd.DataFrame(data=author_categories_vector,\n                      columns=ac_vectorizer.get_feature_names())","79e59379":"tg_vectorizer = CountVectorizer(max_features=10, lowercase=True,\n                                tokenizer=lambda x: x.split(', '))\ntitle_genres_vector = tg_vectorizer.fit_transform(combined['TitleGenres']).toarray()\ndf_title_genres = pd.DataFrame(data=title_genres_vector,\n                     columns=tg_vectorizer.get_feature_names())","d9c3d092":"ag_vectorizer = CountVectorizer(max_features=10, lowercase=True,\n                                    tokenizer=lambda x: x.split(', '))\nauthor_genres_vector = ag_vectorizer.fit_transform(combined['AuthorGenres']).toarray()\ndf_author_genres = pd.DataFrame(data=author_genres_vector,\n                         columns=ag_vectorizer.get_feature_names())","8d8dbf16":"title_vectorizer = CountVectorizer(max_features=10, lowercase=True)\ntitle_vector = title_vectorizer.fit_transform(combined['Title']).toarray()\ndf_title = pd.DataFrame(data=title_vector,\n                        columns=title_vectorizer.get_feature_names())","bc37d764":"vectorizer_author = CountVectorizer(max_features=10, lowercase=True,\n                                    tokenizer=lambda x: x.split(', '))\nvector_author = vectorizer_author.fit_transform(combined['Author']).toarray()\ndf_author = pd.DataFrame(data=vector_author,\n                         columns=vectorizer_author.get_feature_names())","9a83b80a":"vectorizer_genre = CountVectorizer(max_features=10,\n                                   lowercase=True, tokenizer=lambda x: x.split(', '))\nvector_genre = vectorizer_genre.fit_transform(combined['Genre']).toarray()\ndf_genre = pd.DataFrame(data=vector_genre,\n                        columns=vectorizer_genre.get_feature_names())","ba18524f":"vectorizer_synopsis = CountVectorizer(max_features=10,\n                                      stop_words='english', \n                                      strip_accents='ascii', \n                                      lowercase=True)\nvector_synopsis = vectorizer_synopsis.fit_transform(combined['Synopsis']).toarray()\ndf_synopsis = pd.DataFrame(data=vector_synopsis,\n                           columns=vectorizer_synopsis.get_feature_names())","ce73673d":"combined.drop(columns=[\n    'Title',\n    'Author',\n    'Genre',\n    'Synopsis',\n    'Edition',\n    'EditionDate',\n    'EditionType1',\n    'AuthorCategories',\n    'AuthorGenres',\n    'TitleGenres',\n    'TitleCategories'\n    ], inplace=True)","e4013aa6":"print('No. of Features:',combined.shape[1])","cfa9d2d3":"df = pd.concat([\n    combined,# dummy encoded features\n    df_author, # author count encoded\n    df_genre, # genre count encoded\n    df_title, # title count encoded\n    df_synopsis, # synopsis count encoded\n    df_author_genres, # author_genres count encoded\n    df_title_genres, # title_genres count encoded\n    df_author_categories, # author_categories count encoded\n    df_title_categories, # title_categories count encoded\n    ], axis=1)\ndf.reset_index(drop=True, inplace=True)","9838cd66":"# feature correlations\n# corr = df.corr()\n# corr = corr[(corr.Price>-0.005) & (corr.Price< 0.005)]\n# corr = pd.concat([corr[corr.index],corr.Price],axis=1)\n# plt.figure(figsize=(10,10))\n# sns.heatmap(corr, xticklabels=corr.columns,\n#                     yticklabels=corr.columns,\n#                     vmin=-0.1, vmax=0.1\n#             )","a1fab72c":"print('No. of Features(final):',df.shape[1])","d01276c3":"train = df[df['Price'].notna()]\ntest = df[df['Price'].isna()]\ntest.drop(['Price'], axis=1, inplace=True)","6673780d":"# train = train[(train['Price'] <= 12000) \n#             & (train['EditionYear']>= 1980) \n#             & (train['Ratings'] < 680)]\ntrain = train[train['Price'] <= 12000]","f3896365":"X = train.loc[:, train.columns != 'Price'].values\nX = X.astype(float)\n\n# Dependent Variable\n\ny = np.log1p(train['Price'].values)\ny = y.astype(float)\n\n# Test - (Independent Variables)\n\ntest = test.loc[:].values\ntest = test.astype(float)","d138b575":"import xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.metrics import make_scorer\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.model_selection \\\n    import cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble \\\n    import RandomForestRegressor, VotingRegressor, AdaBoostRegressor","d6657204":"def score(y_true, y_pred):\n    y_pred = np.exp(y_pred) - 1\n    for i in range(len(y_pred)):\n        if y_pred[i] < 0:\n            y_pred[i] = 0\n    y_true = np.exp(y_true) - 1\n    error = np.square(np.log10(y_pred + 1) - np.log10(y_true\n                      + 1)).mean() ** 0.5\n    score = 1 - error\n    return score","6ab75452":"rf = RandomForestRegressor(random_state=0,bootstrap=False,max_features='sqrt')\n\ncvs = cross_val_score(rf, X, y, cv=5,verbose=2,n_jobs=-1,\n                      scoring=make_scorer(score,greater_is_better=True))\nmean_score = sum(cvs)\/len(cvs)\n# print(\"Average Score:\",mean_score)","d373c62c":"lgbm = lgb.LGBMRegressor(random_state=0,n_jobs=-1)\n\ncvs = cross_val_score(lgbm, X, y, cv=5,verbose=2,n_jobs=-1,\n                      scoring=make_scorer(score,greater_is_better=True))\nmean_score = sum(cvs)\/len(cvs)\n# print(\"Average Score:\",mean_score)","9e460f01":"xgb = XGBRegressor(n_jobs=-1)\n\ncvs = cross_val_score(xgb, X, y, cv=5,verbose=2,n_jobs=-1,\n                        scoring=make_scorer(score,greater_is_better=True))\nmean_score = sum(cvs)\/len(cvs)\n# print(\"Average Score:\",mean_score)","64828bba":"vr = VotingRegressor([('xgb', xgb), ('rf', rf), ('lgbm', lgbm)])\n\ncvs = cross_val_score(vr, X, y, cv=5,verbose=50,n_jobs=-1,\n                        scoring=make_scorer(score,greater_is_better=True))\nmean_score = sum(cvs)\/len(cvs)\n# print(\"Average Score:\",mean_score)","a18fade0":"# vr.fit(X, y)\n# Y_pred2 = vr.predict(test)\n# Y_pred2 = np.exp(Y_pred2)-1\n\n# for i in range(len(Y_pred2)):\n#      if Y_pred2[i] < 0:\n#         Y_pred2[i] = 0\n\n# pd.DataFrame(Y_pred2, columns = ['Price'])\\\n#     .to_excel(\"predictions.xlsx\", index=False)","b02a5dc2":"*Tried extracting subtitle from Title but didn't help*","23b2912d":"\n**Splitting Edition** - *to Edition Binding type and other feature*","6d4d5890":"**Imputing Month and Year** - *by most common values*","7b1649c2":"*making columns to mark null values*","71a981fe":"#### VotingRegressor","ba06400d":"**Extracting Reviews & Ratings** - *converting to numerical data*","6bbe7928":"**Various Categories of a book**","723f910e":"**Average Author reviews**","b5747f9f":"**Splitting Edition date** - *extracting Month & Year*","caaed83f":"**Feature correlations**","a3a9da6a":"**Binning Edition Year ** - *by distribution over years*","0b84f7e5":"**Various Genre books written by an author**","905945a1":"# Model Training","cc75a396":"**Splitting Edition remainder part** - *extracting edition date and edition type*","151cc4a3":"**Author Name Cleaning**","f6e75ef3":"# Feature Cleaning & Extraction","851c4fff":"**Binning Edition Binding** - *combined edition binding ( with occurence < 9 --> \"other\" )*","6cda484f":"## Dummy & Count Encoding","f57f24d7":"**Various Category books written by an author**","67df1418":"**Ratings and Reviews Ratio**","0445d21c":"**Importing Libraries**","0930b9c8":"**Combining Dataset(Train + Test)** - _for cleaning and feature engineering_","b7d138b3":"# Feature Engineering \n*Engineering new features*","e8fb247d":"**Importing libraries**","9eaf9353":"# Train \/ Test \/ Val Split","b1dce406":"**Importing Data**","b48789db":"**RMLSE scoring func**","1de48630":"**No. of Authors of a book**","2a56c180":"#### LGBMRegressor","c7897dc6":"**Impact of Book Age on Reviews**","b72f4ae8":"#### RandomForestRegressor","bed48d1c":"#### XGBRegressor","7c9f8081":"**Binning Month** - *combining quaterly*","336dcb2a":"# Final Predictions","656d9af8":"# Predict The Price Of Books\n> [Machine Hack Hackathon](https:\/\/www.machinehack.com\/course\/predict-the-price-of-books\/)\n\n<img src=\"https:\/\/www.machinehack.com\/wp-content\/uploads\/2019\/09\/gregory-culmer-e8ThqioFqgs-unsplash.jpg\" width=\"50%\" height=\"50%\">\n<br>\n<b>Size of training set:<\/b> 6237 records\n<br>\n<b>Size of test set:<\/b> 1560 records\n<br>\n<b>FEATURES:<b>\n<ul>\n    <li>Title: <i>The title of the book<\/i>\n    <li>Author: <i>The author(s) of the book.<\/i>\n    <li>Edition: <i>The edition of the book eg (Paperback,\u2013 Import, 26 Apr 2018)<\/i>\n    <li>Reviews: <i>The customer reviews about the book<\/i>\n    <li>Ratings: <i>The customer ratings of the book<\/i>\n    <li>Synopsis: <i>The synopsis of the book<\/i>\n    <li>Genre: <i>The genre the book belongs to<\/i>\n    <li>BookCategory: <i>The department the book is usually available at.<\/i>\n    <li>Price: <i>The price of the book (Target variable)<\/i>\n<\/ul>","d054cde3":"**No. of occurences of a Title**\n<br>\n**Average:** \n- Book - Author Count\n- Title - reviews","f99209dd":"**No. of Books from an Author**","0d5d2612":"**Various Genres of a book**"}}