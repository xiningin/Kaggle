{"cell_type":{"69ec9203":"code","f11fc200":"code","83f2393e":"code","35eb3c68":"code","5b4bcddd":"code","304a9291":"code","4bbc904a":"code","c6dcfdcd":"code","fa6eccb0":"code","01fd55fc":"code","1c8aa3d9":"code","0f4e3b5b":"code","aab7a4bf":"code","e0966e2b":"code","74956374":"code","6bd424ac":"code","60c82361":"code","8ca9699f":"code","49e512ad":"code","8e5e7a99":"code","0a02fb2c":"code","6586e702":"code","6c886f61":"code","084e3932":"code","720494c8":"code","0658321a":"code","55e71f14":"code","f14e82b8":"code","faba99d8":"code","5c9f8f53":"markdown","665052e4":"markdown","722aafb7":"markdown","13abe923":"markdown","a585f6d9":"markdown","c1ad28e9":"markdown","7b403446":"markdown","db075810":"markdown","dd3147ac":"markdown","4a59cfc8":"markdown","1c70207c":"markdown","ba03f39f":"markdown","a6e22ff0":"markdown","2706d65a":"markdown","64e050a4":"markdown","28639d81":"markdown","e2548a92":"markdown","d8919fc8":"markdown"},"source":{"69ec9203":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f11fc200":"import gc\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\n\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing","83f2393e":"df_train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ndf_test = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\n\nprint('Training Set Shape = {}'.format(df_train.shape))\nprint('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() \/ 1024**2))\nprint('Test Set Shape = {}'.format(df_test.shape))\nprint('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() \/ 1024**2))","35eb3c68":"df_train.head(10)","5b4bcddd":"x=df_train.target.value_counts()\nsns.barplot(x.index, x)\nplt.gca().set_ylabel('tweets')","304a9291":"def count_emoji(text):\n    emoji_pattern = re.compile(\"[:=;<][^a-z ]+\")\n    #this is a pretty crappy regex but it'll do for now\n    return len(emoji_pattern.findall(text))\n\ncount_emoji(\"Omg another Earthquake :( :( :()\")","4bbc904a":"df_train['emoji_only'] = df_train['text'].apply(lambda x: count_emoji(x))","c6dcfdcd":"fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10,5))\nemoji_ct = df_train[df_train['target'] == 1]['emoji_only']\nax1.hist(emoji_ct, color='red')\nax1.set_title('disaster tweets')\nemoji_ct = df_train[df_train['target']==0]['emoji_only']\nax2.hist(emoji_ct, color='blue')\nax2.set_title('not disaster tweets')\nfig.suptitle('Emojis in tweets')\nplt.show()","fa6eccb0":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=df_train[df_train['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster tweets')\ntweet_len=df_train[df_train['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Characters in tweets')\nplt.show()","01fd55fc":"def count_punctuation(text):\n    punct_pattern = re.compile(\"[!,.?]+\")\n    #this is a pretty crappy regex but it'll do for now\n    punctuation_list = ''.join([item for sublist in punct_pattern.findall(text) for item in sublist])\n    return len(punctuation_list)\n\n\ncount_punctuation(\"Omg another Earthquake!!!!!!\")","1c8aa3d9":"df_train['punct_ct'] = df_train['text'].apply(lambda x: count_punctuation(x))","0f4e3b5b":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_punct=df_train[df_train['target']==1]['punct_ct']\nax1.hist(tweet_punct,color='red')\nax1.set_title('disaster tweets')\ntweet_punct=df_train[df_train['target']==0]['punct_ct']\nax2.hist(tweet_punct,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Punctuation in tweets')\nplt.show()","aab7a4bf":"!pip install pyspellchecker\n\nfrom spellchecker import SpellChecker\n","e0966e2b":"spell = SpellChecker()\ndef percentage_spelled_correct(text):\n    misspelled_words = spell.unknown(text.split())\n    correct_words = len(text.split()) - len(misspelled_words)\n    return correct_words \/ len(text.split())\n\ntext = 'corect me pls'\npercentage_spelled_correct(text)","74956374":"df_train['percent_spelled_correctly'] = df_train['text'].apply(lambda x: percentage_spelled_correct(x))","6bd424ac":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_punct=df_train[df_train['target']==1]['percent_spelled_correctly']\nax1.hist(tweet_punct,color='red')\nax1.set_title('disaster tweets')\ntweet_punct=df_train[df_train['target']==0]['percent_spelled_correctly']\nax2.hist(tweet_punct,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Misspellings in tweets')\nplt.show()","60c82361":"def count_hashtags(text):\n    punct_pattern = re.compile(\"#[a-zA-Z1-9]+\")\n    #this is a pretty crappy regex but it'll do for now\n    punctuation_list = punct_pattern.findall(text)\n    return len(punctuation_list)\n\n\ncount_hashtags(\"Omg another Earthquake!!!!!! #stuff #things\")","8ca9699f":"df_train['hashtag_count'] = df_train['text'].apply(lambda x: count_hashtags(x))","49e512ad":"column='hashtag_count'\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_punct=df_train[df_train['target']==1][column]\nax1.hist(tweet_punct,color='red')\nax1.set_title('disaster tweets')\ntweet_punct=df_train[df_train['target']==0][column]\nax2.hist(tweet_punct,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Hashtags in tweets')\nplt.show()","8e5e7a99":"def percentage_capitalized(text):\n    cap_ct = 0\n    uncap_ct = 0\n    for char in text:\n        if char.isupper():\n            cap_ct +=1\n        elif char.islower():\n            uncap_ct +=1\n    return cap_ct \/ (cap_ct + uncap_ct)\n\n\ntext = 'THIS IS SUPER URGENT!! ok maybe not THAT urgent'\npercentage_capitalized(text)","0a02fb2c":"df_train['percent_capitalized'] = df_train['text'].apply(lambda x: count_hashtags(x))","6586e702":"column='percent_capitalized'\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_punct=df_train[df_train['target']==1][column]\nax1.hist(tweet_punct,color='red')\nax1.set_title('disaster tweets')\ntweet_punct=df_train[df_train['target']==0][column]\nax2.hist(tweet_punct,color='green')\nax2.set_title('Not disaster tweets')\nfig.suptitle('capitalization in tweets')\nplt.show()","6c886f61":"def remove_punct_and_lower(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.lower().translate(table)\n\nspell = SpellChecker()\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)\n\ndf_train['text'] = df_train['text'].apply(lambda x: remove_punct_and_lower(x))\ndf_test['text'] = df_test['text'].apply(lambda x: remove_punct_and_lower(x))\nprint('got here')\n# df_train['text'] = df_train['text'].apply(lambda x: correct_spellings(x))\n# df_test['text'] = df_test['text'].apply(lambda x: correct_spellings(x))\n","084e3932":"count_vectorizer = feature_extraction.text.CountVectorizer()\n\n## let's get counts for the first 5 tweets in the data\nexample_train_vectors = count_vectorizer.fit_transform(df_train[\"text\"][0:5])","720494c8":"## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\nprint(example_train_vectors[0].todense().shape)\nprint(example_train_vectors[0].todense())","0658321a":"train_vectors = count_vectorizer.fit_transform(df_train[\"text\"])\n\n## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n# i.e. that the train and test vectors use the same set of tokens.\ntest_vectors = count_vectorizer.transform(df_test[\"text\"])\n\n## Our vectors are really big, so we want to push our model's weights\n## toward 0 without completely discounting different words - ridge regression \n## is a good way to do this.\nclf = linear_model.RidgeClassifier()\n\n","55e71f14":"scores = model_selection.cross_val_score(clf, train_vectors, df_train[\"target\"], cv=3, scoring=\"f1\")\nscores","f14e82b8":"clf.fit(train_vectors, df_train[\"target\"])\nsample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = clf.predict(test_vectors)\nsample_submission.head()","faba99d8":"sample_submission.to_csv(\"submission.csv\", index=False)","5c9f8f53":"Can we track whether or not the tweet is about a disaster based on the emoji content alone? ","665052e4":"Not much of a relationship here- a slight decrease in emojis when there is a disaster, but not by much.","722aafb7":"meh, not a very strong connection here. Difficult to tell due to the different X scales but I don't think this is worth pursuing.","13abe923":"No decent connection :'( I also did a bit of cleaning up to make the graphical analysis easier to move around. Now it only has two points of change instead of three. Progress!","a585f6d9":"# Emoji link?","c1ad28e9":"# Building Vectors","7b403446":"# Data cleaning\n\nNow that we have determined that factors like misspellings, capitalizations, and punctuation don't have any noticable effects on the result, I think it is safe to clean the data from this potential sources of error. This should make our ML a bit cleaner since we no longer have a different feature for 'FIRE' and 'fire' and whatnot.","db075810":"# Count Hashtags","dd3147ac":"# Import required packages","4a59cfc8":"This isn't showing a connection, but it is important to know that, since we haven't removed punctuation, this is counting all #hashtags as misspelled words. ","1c70207c":"Nothing interesting here.","ba03f39f":"# Disaster or no?","a6e22ff0":"# Punctuation count","2706d65a":"# Length of tweet","64e050a4":"# Check out the data\n","28639d81":"# Load in training and test data","e2548a92":"# % of misspelled words","d8919fc8":"# Capitalization in a tweet"}}