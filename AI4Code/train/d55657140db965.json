{"cell_type":{"c5fe0206":"code","99b152a1":"code","fee26b73":"code","bed8c8b9":"code","de19a1f6":"code","b2334491":"code","2df86a17":"code","c6d77f5e":"code","0dfcc649":"code","dc38d263":"code","1e954d3a":"code","fd4e40fc":"code","8bd4e400":"code","fa72c2c0":"code","c2892088":"code","063b2999":"code","6a48bc20":"code","7dd292ec":"code","3120ae14":"markdown","4f3e8709":"markdown","61b79ae1":"markdown","9f5959d1":"markdown","9fb7d862":"markdown","e7441256":"markdown","7143fd32":"markdown","e8a01250":"markdown","0518f4a0":"markdown"},"source":{"c5fe0206":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPooling2D , Flatten , Dropout , BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport os","99b152a1":"labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 224\ndef datafunc(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","fee26b73":"train = datafunc('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\ntest = datafunc('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test')\nval = datafunc('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val')","bed8c8b9":"trainlabel = []\nfor img in train:\n    if(img[1] == 0):\n        trainlabel.append(\"Pneumonia\")\n    else:\n        trainlabel.append(\"Normal\")\nsns.countplot(trainlabel)        ","de19a1f6":"plt.figure(figsize = (5,5))\nplt.imshow(train[0][0], cmap='gray')\nplt.title(labels[train[0][1]])\n\nplt.figure(figsize = (5,5))\nplt.imshow(train[-1][0], cmap='gray')\nplt.title(labels[train[-1][1]])","b2334491":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\nx_test = []\ny_test = []\n\nfor feature, label in train:\n    x_train.append(feature)\n    y_train.append(label)\n\nfor feature, label in test:\n    x_test.append(feature)\n    y_test.append(label)\n    \nfor feature, label in val:\n    x_val.append(feature)\n    y_val.append(label)","2df86a17":"x_train = np.array(x_train)\/255.0\nx_test = np.array(x_test)\/255.0\nx_val = np.array(x_val)\/255.0","c6d77f5e":"x_train = x_train.reshape(-1,img_size,img_size,1)\nx_test = x_test.reshape(-1,img_size,img_size,1)\nx_val = x_val.reshape(-1,img_size,img_size,1)","0dfcc649":"y_train=np.array(y_train)\ny_test=np.array(y_test)\ny_val=np.array(y_val)","dc38d263":"datagen= ImageDataGenerator(\n            rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n            zoom_range = 0.2, # Randomly zoom image \n            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n            height_shift_range=0.1)","1e954d3a":"datagen.fit(x_train)","fd4e40fc":"model = Sequential()\n\nmodel.add(Conv2D(input_shape=(224,224,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))","8bd4e400":"model.add(Flatten())\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units=2, activation=\"softmax\"))","fa72c2c0":"from keras.optimizers import Adam\nopt = Adam(lr=0.001)\nmodel.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\nmodel.summary()","c2892088":"from keras.callbacks import ModelCheckpoint, EarlyStopping\ncheckpoint = ModelCheckpoint(\"vgg16.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\nhistory = model.fit(datagen.flow(x_train,y_train, batch_size = 32) ,epochs = 100 , validation_data = datagen.flow(x_test, y_test),callbacks=[checkpoint,early])","063b2999":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","6a48bc20":"predictions = model.predict_classes(x_test)\ncm = confusion_matrix(y_test,predictions)\ncm","7dd292ec":"print(history.history.keys())\n#  \"Accuracy\"\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# \"Loss\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","3120ae14":"# **IMPORTING THE LIBRARIES**","4f3e8709":"# **LOAD THE DATA**","61b79ae1":"# **VGG16 ARCHITECTURE**","9f5959d1":"# **RESULTS FROM TRAINING**","9fb7d862":"# **PREPROCESS THE DATA**","e7441256":"# **VISULAIZE THE RESULT**","7143fd32":"# **ORGANIZE THE DATA**","e8a01250":"# **TRAINING FROM SCRATCH**","0518f4a0":"# **VISUALIZE THE TRAIN DATA**"}}