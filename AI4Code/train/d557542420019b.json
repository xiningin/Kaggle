{"cell_type":{"b3049f0d":"code","8b08bb19":"code","7a3f23b9":"code","1f78e4b2":"code","19195495":"code","63b1ba23":"code","01c50958":"code","f9916d91":"code","3053b24e":"code","62740089":"code","9f9aacf0":"code","5f6c6b4d":"code","96d93086":"code","d8836d7e":"code","25f2bbc3":"code","e5ca17e4":"code","61a935b5":"code","25d31e0f":"code","f63bcdf6":"code","50e689d8":"code","11ff0a99":"code","26808c7d":"code","f86f7035":"code","2efa34fa":"code","1fc0cf6c":"code","129dd273":"code","33a1d2be":"code","6e3badb5":"code","d813beee":"code","801d1df4":"code","331d1bfd":"code","3fc6a6b3":"code","c4e2b6a5":"code","e6857901":"code","0ff470c0":"code","65c3de16":"code","1b9166ca":"code","178e25ac":"code","f1787b6f":"code","c3d78f9e":"code","3cf091b9":"code","3a91a9be":"code","6aa0c797":"code","8e9394d5":"code","e778e5f9":"code","d2b3e5a0":"code","3882249b":"code","ec8848f0":"code","d62a0f1b":"code","beb83e52":"code","44f579fc":"code","e4770739":"code","74e88b1d":"code","71646063":"code","0f5f3f97":"code","03e168e6":"code","16f0dedf":"markdown","d3c91f99":"markdown","f14bf8da":"markdown","46019767":"markdown","62690c80":"markdown"},"source":{"b3049f0d":"import numpy as np \nimport pandas as pd","8b08bb19":"movies_df = pd.read_csv(\"..\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv\")\ncredit_df = pd.read_csv(\"..\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv\")","7a3f23b9":"movies_df.head()","1f78e4b2":"credit_df.head()","19195495":"credit_df.iloc[1]","63b1ba23":"movies_df= movies_df.merge(credit_df, on='title')\nmovies_df.head()","01c50958":"movies_df.info()","f9916d91":"movies_df.spoken_languages.nunique()","3053b24e":"imp_cols = [\"genres\", \"id\",\"keywords\",\"title\", \"overview\", \"cast\",\"crew\"]\nmovies_df= movies_df[imp_cols]\nmovies_df.head()","62740089":"movies_df.isnull().sum()","9f9aacf0":"movies_df=movies_df.dropna()\nmovies_df.isnull().sum()","5f6c6b4d":"#for checking the duplicated column\nmovies_df.duplicated().sum()","96d93086":"movies_df.iloc[0].genres","d8836d7e":"#def convert(col):\n#    L = []\n#    for i in col:\n#        L.append(i['name'])\n#    return L","25f2bbc3":"# to convert the strings into the list we can use a module \nimport ast\ndef convert(col):\n    L=[]\n    for i in ast.literal_eval(col):\n        L.append(i['name'])\n    return L\n    ","e5ca17e4":"movies_df['genres'] = movies_df['genres'].apply(convert)","61a935b5":"movies_df.head()","25d31e0f":"movies_df.iloc[0].keywords","f63bcdf6":"movies_df[\"keywords\"]= movies_df[\"keywords\"].apply(convert)\nmovies_df.head()","50e689d8":"## for getting the first 3 cast in list \ndef convert_cast(col):\n    L=[]\n    counter =0\n    for i in ast.literal_eval(col):\n        if counter != 3:\n            L.append(i['name'])\n            counter=counter+1\n        else:\n            break\n    return L\n    ","11ff0a99":"movies_df[\"cast\"]= movies_df['cast'].apply(convert_cast)","26808c7d":"movies_df.head()","f86f7035":"movies_df.crew[0]","2efa34fa":"def fetch_dir(col):\n    L=[]\n    for i in ast.literal_eval(col):\n        if i['job']=='Director':\n            L.append(i[\"name\"])\n            break\n    return L","1fc0cf6c":"movies_df[\"crew\"]=movies_df[\"crew\"].apply(fetch_dir)","129dd273":"movies_df.head()","33a1d2be":"movies_df[\"overview\"]=movies_df[\"overview\"].apply(lambda x:x.split())","6e3badb5":"movies_df.head(10)","d813beee":"## transformation\n## lets remove tha spaces between a single entity\n\n#for movie genre\nmovies_df[\"genres\"]=movies_df[\"genres\"].apply(lambda x:[ i.replace(\" \",\"\") for i in x])","801d1df4":"movies_df[\"keywords\"]= movies_df[\"keywords\"].apply(lambda x: [i.replace(\" \",\"\") for i in x])\nmovies_df[\"cast\"]= movies_df[\"cast\"].apply(lambda x: [i.replace(\" \",\"\") for i in x])\nmovies_df[\"crew\"]= movies_df[\"crew\"].apply(lambda x: [i.replace(\" \",\"\") for i in x])                                                              ","331d1bfd":"movies_df[\"tags\"]= movies_df[\"overview\"]+movies_df[\"genres\"]+ movies_df[\"keywords\"]+ movies_df[\"cast\"]+movies_df[\"crew\"]","3fc6a6b3":"movies_df.columns","c4e2b6a5":"new_df= movies_df[[\"id\",\"title\",'tags']]","e6857901":"new_df.head()","0ff470c0":"new_df[\"tags\"]= new_df[\"tags\"].apply(lambda x: \" \".join(x))","65c3de16":"new_df.tags[0]","1b9166ca":"new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x:x.lower())","178e25ac":"new_df.head(3)","f1787b6f":"### applying steming to make the similar words same \n'''\n'before stemming\n[\"love\", \"lovely\",\"loving\"]\n\nafter stemming \n[\"love\", \"love\", \"love\"]\n'''\n!pip install nltk","c3d78f9e":"import nltk\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()","3cf091b9":"def stem(text):\n    y=[]\n    \n    for i in text.split():\n        y.append(ps.stem(i))\n    return \" \".join(y)","3a91a9be":"new_df[\"tags\"]= new_df[\"tags\"].apply(stem)","6aa0c797":"##vectorizing the tags and removing the stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv =CountVectorizer(max_features= 5000, stop_words=\"english\")","8e9394d5":"vectors = cv.fit_transform(new_df[\"tags\"]).toarray()","e778e5f9":"vectors[0]","d2b3e5a0":"cv.get_feature_names()","3882249b":"from sklearn.metrics.pairwise import cosine_similarity","ec8848f0":"similarity = cosine_similarity(vectors)","d62a0f1b":"##to get the highest similarity movie we cant just sort the similarity, bc this would lose the index relation with tha other movies so in place of direct sort weare gonna apply enumer\nsorted(list(enumerate(similarity[0])), reverse = True , key = lambda x:x[1])[1:6]","beb83e52":"def recommend(movie):\n    movie_index = new_df[new_df['title']==movie].index[0]\n    distances = similarity[movie_index]\n    movies_list = sorted(list(enumerate(distances)), reverse= True, key= lambda x:x[1])[1:6]\n    \n    for i in movies_list:\n        print(new_df.iloc[i[0]].title)","44f579fc":"recommend('Avatar')","e4770739":"recommend('Titanic')","74e88b1d":"import pickle ","71646063":"pickle.dump(new_df,open(\"movie.pkl\",\"wb\"))","0f5f3f97":"pickle.dump(new_df.to_dict(), open(\"movie_dict.pkl\", \"wb\"))","03e168e6":"pickle.dump(similarity, open(\"similarity.pkl\", \"wb\"))","16f0dedf":"we can merge these dataframe using the title column","d3c91f99":"we are making a content based recommendator system. so lets filter the columns that will be important in the recommendation system\n","f14bf8da":"we will calculate the cosine distance instead of euclidian distanace Euclidian distance is not reliable in high dimension","46019767":"## lets merge the dataframe","62690c80":"### lets try to make a dataframe which has just a three columns those are- id, title, tag\nthis tag column is the merge column of the overview, genre,keywords, cast, crew"}}