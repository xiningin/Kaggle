{"cell_type":{"ad71f2bc":"code","4de2a9f0":"code","b8e6f774":"code","f72f363b":"code","df6a6fdf":"code","9947624d":"code","4034c055":"code","c3b55233":"code","aa7268d5":"code","9f4904b5":"code","a4383333":"code","dd63239c":"code","6908eaec":"code","148ba67a":"code","81be4d87":"code","ef376653":"code","48615d72":"code","266720ef":"code","c32c2a39":"code","d1a46ed8":"code","6ea3789a":"code","a28965cb":"code","fd70cf52":"code","93a85ec5":"code","cac1d4f3":"code","3c432af4":"code","045f08cb":"code","c6022a62":"code","cdc1a87d":"code","d057d9b2":"code","ba3b3aad":"code","5ec0d98c":"code","61398004":"code","943339fa":"code","e383125d":"code","c23e88b6":"code","8f3e761c":"code","c33fcea6":"code","53fa9be5":"code","f7271d4a":"code","00083d73":"code","3bc30ed7":"code","8e9584aa":"code","35f2d198":"code","7baa3d61":"code","a3c5f936":"code","3d06d15f":"code","85b75e9b":"code","d4b9c941":"code","ad5953d6":"code","ba5517c9":"code","71f459db":"code","99e1dbef":"code","5f9be877":"code","1b0625d2":"code","47bbad6f":"code","95f560d7":"code","5671a4cd":"code","5535bb79":"code","1a2b789e":"code","676d7fd8":"code","1e7b4b51":"code","05a1f766":"code","5a1db582":"code","f442d3fe":"code","b36c692e":"code","bf15ec0d":"markdown","7f71534b":"markdown","ad7269dc":"markdown","b23b54a0":"markdown","b4b360fb":"markdown","d94c40ec":"markdown","d0f6ce2b":"markdown","2fe5e698":"markdown","fe7862ab":"markdown","2ff3ae67":"markdown","405fa4fb":"markdown","a349e3d9":"markdown","14129fc0":"markdown","a98e6df6":"markdown","bc794807":"markdown","110b9f3a":"markdown","5fd040f9":"markdown","743815c4":"markdown","241c69bb":"markdown","62d49741":"markdown","4efd0cef":"markdown","5204ab5e":"markdown","e85c87dc":"markdown","d5d663cd":"markdown","63901358":"markdown","307cc2f6":"markdown","7052d466":"markdown","6331b9ea":"markdown","7e958bef":"markdown","1753e588":"markdown","67124a17":"markdown","b3ab6132":"markdown","00cbdda0":"markdown","d8a436f1":"markdown","98000342":"markdown","805083ee":"markdown","a71a438b":"markdown","99299190":"markdown","d6c91bc8":"markdown","98e8f2bb":"markdown","7520586e":"markdown","3bfc8424":"markdown","c1f9422f":"markdown","b3382830":"markdown","da62f1a0":"markdown","61f9e81c":"markdown","ca242bee":"markdown","e12b10df":"markdown","7dce402f":"markdown","8ef68fb7":"markdown","ad16715f":"markdown","8c9c021d":"markdown","20718800":"markdown","7c9d6f92":"markdown","1765c4b4":"markdown","fdd68dd1":"markdown","d27c55f3":"markdown","27e45de9":"markdown"},"source":{"ad71f2bc":"# import required modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.mixture import GaussianMixture as GMM\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import rcParams\n%matplotlib inline","4de2a9f0":"# load raw data file into pandas dataframe\nmall_df = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\nmall_df.head()","b8e6f774":"mall_df.info()","f72f363b":"# mall_df.profile_report()","df6a6fdf":"# display the statistical summary of the numerical varibles\n# CustomerID is dropped temporarily as it does not provide useful information\nmall_df.describe().drop(columns='CustomerID')","9947624d":"# rename columns\nmall_df.rename(columns={'Age': 'age', 'Annual Income (k$)': 'annual_income(k$)', 'Gender': 'gender', 'Spending Score (1-100)':'spending_score'}, inplace=True)","4034c055":"# plot a distribution plot to better visulaize the distribution range\nsns.set_style('white')\nplt.figure(figsize=(15, 12))\nplt.subplot(2, 2, 1)\nsns.histplot(mall_df['age'], kde=True)\nplt.title('Distribution of Age', fontsize=20)\nplt.xlabel('Range of Age', fontsize=16)\nplt.ylabel('Count', fontsize=16)\n\nplt.subplot(2, 2, 2)\nsns.histplot(mall_df['annual_income(k$)'], kde=True)\nplt.title('Distribution of Annual Income', fontsize=20)\nplt.xlabel('Range of Annual Income', fontsize=16)\nplt.ylabel('Count', fontsize=16)\n\nplt.subplot(2, 2, 3)\nsns.histplot(mall_df['spending_score'],kde=True)\nplt.title('Distribution of Spending Score', fontsize=20)\nplt.xlabel('Range of Spending Score', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","c3b55233":"sns.set_style('whitegrid')\ncolumns = ['age', 'annual_income(k$)', 'spending_score']\nnumber_of_columns = 3\nnumber_of_rows = len(columns)-1\/number_of_columns\nplt.figure(figsize=(3*number_of_columns,5*number_of_rows))\nfor i in range(0,len(columns)):\n    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n    sns.boxplot(y=columns[i], data=mall_df ,color='green')\n    plt.tight_layout()","aa7268d5":"# in order to ensure the skewness of the data, i performed a normality test using df.skew()\nmall_df.skew(axis = 0, skipna = True)","9f4904b5":"# check the distribution of male and female population in the dataset\nsns.set_style('white')\nlabels = ['Female', 'Male']\nsize = mall_df['gender'].value_counts()\ncolors = ['lightcoral', 'lightsteelblue']\nexplode = [0, 0.05]\n\nplt.figure(figsize=(7, 7))\nplt.pie(size, colors=colors, explode=explode, labels=labels, shadow=True, autopct='%.2f%%', \n        textprops={'fontsize':16})\nplt.title('Proportion of Gender', fontsize=20)\nplt.axis('off')\nplt.legend(fontsize=15)\nplt.show()","a4383333":"# histplot to compare the number of male and female based on age and annual_income\nfig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 8))\n\nsns.histplot(data=mall_df, x='age', hue='gender', binwidth=10, multiple='stack', ax=ax0)\nsns.histplot(data=mall_df, x='annual_income(k$)', hue='gender', binwidth=10, multiple='stack', ax=ax1);","dd63239c":"# countplot showing the distribution of spending score \n# as this might be an important statistic for the marketing team\nplt.figure(figsize=(10,8))\nsns.histplot(x='spending_score', data=mall_df, hue='gender', binwidth=5, multiple='stack')\nplt.title('Distribution of Spending Score',fontsize=24)\nplt.xlabel('Spending Score (1-100)', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","6908eaec":"# I plotted multiple boxplots to compare the different attributes between male and female customers\nsns.set_style('white')\nplt.figure(figsize=(20,6))\nplt.subplot(1,3,1)\nsns.boxplot(x='gender', y='age', data=mall_df, palette='rocket_r')\nplt.title('Boxplot of Gender vs Age', fontsize=26)\nplt.xlabel('Gender', fontsize=20)\nplt.ylabel('Age', fontsize=20)\n\nplt.subplot(1,3,2)\nsns.boxplot(x='gender', y='annual_income(k$)', data=mall_df, palette='rocket_r')\nplt.title('Gender vs Annual Income', fontsize=26)\nplt.xlabel('Gender', fontsize=20)\nplt.ylabel('Annual Income (k$)', fontsize=20)\n\nplt.subplot(1,3,3)\nsns.boxplot(x='gender', y='spending_score', data=mall_df, palette='rocket_r')\nplt.title('Gender vs Spending Score', fontsize=26)\nplt.xlabel('Gender', fontsize=20)\nplt.ylabel('Spending Score (1-100)', fontsize=20)\n\nplt.show()","148ba67a":"sns.lmplot(\n    data=mall_df,\n    x='spending_score', \n    y='age', \n    hue='gender',\n    aspect=1.5,\n    scatter_kws={'s': 5, 'alpha': 0.6});","81be4d87":"# pairplot to visualize the relationship and trend between the numerical variables\ngrid = sns.PairGrid(mall_df, hue='gender', diag_sharey=False, palette='rocket_r')\ngrid.map_upper(sns.scatterplot, s=15)\ngrid.map_lower(sns.kdeplot)\ngrid.map_diag(sns.kdeplot, lw=1);\ngrid.fig.suptitle('Pairplot of Numerical Variables hue Gender', y=1.08, fontsize=20)\nplt.show()","ef376653":"# plot a 3dimensional scatter plot to obseve the relationship between gender, annual income and spending score\nimport plotly.graph_objects as go\nimport plotly.express as px\nfig = px.scatter_3d(x=mall_df['annual_income(k$)'], y=mall_df['spending_score'], z=mall_df['age'], color=mall_df['gender'], title='Annual Income vs Spending Score with Age')\nfig.show()","48615d72":"# plot heatmap to observe the relationship between the variables to check for multicollinearity\nsns.set_style('white')\nplt.figure(figsize=(8, 6))\nsns.heatmap(mall_df.corr(), annot=True)\nplt.title('Relationship between Numerical Variables\\n', fontsize=20)\nplt.show()","266720ef":"# drop unuseful column\nmall_df.drop(columns=['CustomerID'], axis=1, inplace=True)","c32c2a39":"mallDf = mall_df.drop(columns=['gender'])\nmallDf.head()","d1a46ed8":"# before training the model, i perform scaling on the numerical variables as they have different unit of measurement\nstdScaler = StandardScaler()\nX_numerical = mallDf.values\nstdScaler.fit(X_numerical)\nX_transform = stdScaler.transform(X_numerical)","6ea3789a":"X_df = pd.DataFrame({'age': X_transform[:,0],\n                     'annual_income(k$)': X_transform[:,1],\n                     'spending_score': X_transform[:,2]})\nX_df.head()","a28965cb":"# extract required data (annual_income and spending score data)\nX_df2 = X_df[['annual_income(k$)','spending_score']]","fd70cf52":"# truncated denrogram\nsns.set_style('white')\nplt.figure(figsize=(12,8))\ndendrogram = sch.dendrogram(sch.linkage(X_df, method='ward'), truncate_mode='lastp', p=20, show_contracted=True)\nplt.title('Dendrogam', fontsize=20)\nplt.xlabel('Customers', fontsize=16)\nplt.ylabel('Ecuclidean Distance', fontsize=16)\nplt.hlines(8, 2, 198, colors='grey')\nplt.show()","93a85ec5":"# using agglomerative clustering to predict the customer segmentation after obtaining the best n_clusters using dendrogram\nn_cluster, silhouette, db = [], [], []\n\nfor i in range(2,11):      \n    n_cluster.append(i)\n    ag = AgglomerativeClustering(n_clusters=i, affinity='euclidean', linkage='ward')\n    ag_pred = ag.fit_predict(X_df)  \n    silhouette.append(metrics.silhouette_score(X_df, ag_pred, metric='euclidean').round(3))\n    db.append(str(metrics.davies_bouldin_score(X_df, ag_pred).round(3)))\n\nscore = pd.DataFrame({'n_clusters': n_cluster, 'Silhouette score': silhouette, 'Davies Bouldin Score': db}).sort_values(by='Silhouette score', ascending=False)\nscore.head()","cac1d4f3":"# find the optimal k value using the elbow method\nsns.set_style('white')\ndistortions = [] \nK = range(1,11)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k)\n    kmeanModel.fit(X_df)\n    # inertia --> how tight the cluster is\n    distortions.append(kmeanModel.inertia_)\n    \nfig, ax = plt.subplots(figsize=(10,6))\nax = sns.lineplot(x=K, y=distortions, marker='o', ax=ax)\nax.set_title('Elbow Method Showing The Optimal k', fontsize=20)\nax.set_xlabel('Number of Clusters (k)', fontsize=16)\nax.set_ylabel('Distortion', fontsize=16)\nax.axvline(6, ls='--', c='red')\nplt.grid()\nplt.show()","3c432af4":"# find the optimal number of clusters using silhouette score and davies bouldin index\nk, silhouette, db = [], [], []\n\nfor i in range(2,11):      \n    k.append(i)\n    kmeans_labels = KMeans(n_clusters=i,random_state=123).fit_predict(X_df)     \n    silhouette.append(metrics.silhouette_score(X_df,kmeans_labels, metric='euclidean').round(3))\n    db.append(str(metrics.davies_bouldin_score(X_df,kmeans_labels).round(3)))\n    \nscore = pd.DataFrame({'n_clusters': k, 'Silhouette score': silhouette, 'Davies Bouldin Index': db}).sort_values(by='Silhouette score', ascending=False)\nscore.head()","045f08cb":"KM6_clusters = KMeans(n_clusters=6, init='k-means++').fit(X_df) # initialise and fit K-Means model\n\nKM6_clustered = X_df.copy()\nKM6_clustered.loc[:,'Cluster'] = KM6_clusters.labels_ # append labels to points","c6022a62":"fig1, (axes) = plt.subplots(1,2,figsize=(12,5))\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=KM6_clustered,\n                hue='Cluster', ax=axes[0], palette='Set1', legend='full', s=100)\nsns.scatterplot(x='age', y='spending_score', data=KM6_clustered,\n                hue='Cluster', palette='Set1', ax=axes[1], legend='full', s=100)\n\n# plotting centroids\naxes[0].scatter(KM6_clusters.cluster_centers_[:,1], KM6_clusters.cluster_centers_[:,2], c='blue', s=100, alpha=0.5)\naxes[1].scatter(KM6_clusters.cluster_centers_[:,0], KM6_clusters.cluster_centers_[:,2], c='blue', s=100, alpha=0.5)\nfig1.suptitle('K-Means_6', fontsize=20)\naxes[0].set_xlabel('Annual Income', fontsize=16)\naxes[0].set_ylabel('Spending Score', fontsize=16)\naxes[1].set_xlabel('Age', fontsize=16)\naxes[1].set_ylabel('Spending Score', fontsize=16)\nplt.show()","cdc1a87d":"KM6_clust_sizes = KM6_clustered.groupby('Cluster').size().to_frame()\nKM6_clust_sizes.columns = ['KM6_size']\nKM6_clust_sizes","d057d9b2":"trace1 = go.Scatter3d(\n    x=X_df['age'],\n    y=X_df['spending_score'],\n    z=X_df['annual_income(k$)'],\n    mode='markers',\n    marker=dict(\n        color=KM6_clustered['Cluster'], \n        size=10,\n        line=dict(\n            color=KM6_clustered['Cluster'],\n            width= 12),\n    opacity=0.8))\ndata = [trace1]\nlayout = go.Layout(\n    title='Clusters',\n    scene = dict(\n            xaxis=dict(title='Age'),\n            yaxis=dict(title='Spending Score'),\n            zaxis=dict(title='Annual Income')))\nfig = go.Figure(data=data, layout=layout)\nfig.show()","ba3b3aad":"sns.set_style('white')\ndistortions = [] \nK = range(1,11)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k)\n    kmeanModel.fit(X_df2)\n    # inertia --> how tight the cluster is\n    distortions.append(kmeanModel.inertia_)\n    \nfig, ax = plt.subplots(figsize=(10,6))\nax = sns.lineplot(x=K, y=distortions, marker='o', ax=ax)\nax.set_title('Elbow Method Showing The Optimal k', fontsize=20)\nax.set_xlabel('Number of Clusters (k)', fontsize=16)\nax.set_ylabel('Distortion', fontsize=16)\nax.axvline(5, ls='--', c='red')\nplt.grid()\nplt.show()","5ec0d98c":"# find the optimal number of clusters using silhouette score and davies bouldin index\nk, silhouette, db = [], [], []\n\nfor i in range(2,11):      \n    k.append(i)\n    kmeans_labels = KMeans(n_clusters=i,random_state=123).fit_predict(X_df2)     \n    silhouette.append(metrics.silhouette_score(X_df2,kmeans_labels, metric='euclidean').round(3))\n    db.append(str(metrics.davies_bouldin_score(X_df2,kmeans_labels).round(3)))\n    \nscore = pd.DataFrame({'n_clusters': k, 'Silhouette score': silhouette, 'Davies Bouldin Score': db}).sort_values(by='Silhouette score', ascending=False)\nscore.head()","61398004":"KM5_clusters = KMeans(n_clusters=5, init='k-means++').fit(X_df2) # initialise and fit K-Means model\nKM5_clustered = X_df2.copy()\nKM5_clustered.loc[:,'Cluster'] = KM5_clusters.labels_ # append labels to points","943339fa":"fig2 = plt.figure(figsize=(10,6))\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=KM5_clustered,\n                hue='Cluster', palette='Set1', legend='full', s=100)\nplt.scatter(KM5_clusters.cluster_centers_[:,0], KM5_clusters.cluster_centers_[:,1], c='blue', s=100, alpha=0.5)\nplt.title('KMM_5 Based On Annual Income and Spending Score', fontsize=20)\nplt.xlabel('Annual Income(k$)', fontsize=16)\nplt.ylabel('Spending Score', fontsize=16)\nplt.show()","e383125d":"KM5_clust_sizes = KM5_clustered.groupby('Cluster').size().to_frame()\nKM5_clust_sizes.columns = [\"KM5_size\"]\nKM5_clust_sizes","c23e88b6":"# function that returns the set of X configurations with shorter distance\ndef selectBest(arr:list, X:int)->list:\n    dx = np.argsort(arr)[:X]\n    return arr[dx]","8f3e761c":"n_clusters = np.arange(2, 11)\nsilhouette_arr = []\nsilhouette_err = []\niterations = 20\nfor n in n_clusters:\n    tmp_silhouette = []\n    for i in range(iterations):\n        gmm = GMM(n, n_init=2).fit(X_df) \n        labels = gmm.predict(X_df)\n        silhouette = metrics.silhouette_score(X_df, labels, metric='euclidean')\n        tmp_silhouette.append(silhouette)\n    val = np.mean(selectBest(np.array(tmp_silhouette), int(iterations\/5)))\n    err = np.std(tmp_silhouette)\n    silhouette_arr.append(val)\n    silhouette_err.append(err)","c33fcea6":"# visulize the silhouette scores for different number of clusters\nsns.set_style('white')\nplt.figure(figsize=(10,6))\nplt.errorbar(n_clusters, silhouette_arr, yerr=silhouette_err, ecolor='red', elinewidth=2)\nplt.title('Silhouette Scores', fontsize=20)\nplt.xticks(n_clusters)\nplt.xlabel('Number of Clusters', fontsize=16)\nplt.ylabel('Score', fontsize=16)\nplt.show()","53fa9be5":"n_clusters=np.arange(2,11)\nresults1 = pd.DataFrame(columns=['Number of Cluster','Silhouette Score','Davies Bouldin Score'])\nfor n in n_clusters:       \n        gmm_cluster = GMM(n_components=n,random_state=123)\n        clusters = gmm_cluster.fit_predict(X_df)\n        if len(np.unique(clusters))>=2:\n            results1 = results1.append({\n                                      'Number of Cluster':n,\n                                      'Silhouette Score':metrics.silhouette_score(X_df,clusters),\n                                      'Davies Bouldin Score':metrics.davies_bouldin_score(X_df,clusters)},ignore_index=True)","f7271d4a":"display(results1.sort_values(by=['Silhouette Score'], ascending=False)[:5])","00083d73":"gmm5_model = GMM(n_components=5, covariance_type='spherical', random_state=123)\nGMM5_clusters = gmm5_model.fit_predict(X_df)\nGMM5_clustered = X_df.copy()\nGMM5_clustered.loc[:,'Cluster'] = GMM5_clusters # append labels to points","3bc30ed7":"fig3, (axes) = plt.subplots(1,2,figsize=(12,5))\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=GMM5_clustered,\n                hue='Cluster', ax=axes[0], palette='Set1', legend='full', s=100)\nsns.scatterplot(x='age', y='spending_score', data=GMM5_clustered,\n                hue='Cluster', palette='Set1', ax=axes[1], legend='full', s=100)\n\nfig3.suptitle('GMM_5', fontsize=20)\naxes[0].set_xlabel('Annual Income', fontsize=16)\naxes[0].set_ylabel('Spending Score', fontsize=16)\naxes[1].set_xlabel('Age', fontsize=16)\naxes[1].set_ylabel('Spending Score', fontsize=16)\nplt.show()","8e9584aa":"trace2 = go.Scatter3d(\n    x=X_df['age'],\n    y=X_df['spending_score'],\n    z=X_df['annual_income(k$)'],\n    mode='markers',\n    marker=dict(\n        color=GMM5_clustered['Cluster'], \n        size=10,\n        line=dict(\n            color=GMM5_clustered['Cluster'],\n            width= 12),\n    opacity=0.8))\ndata = [trace2]\nlayout = go.Layout(\n    title='Clusters',\n    scene = dict(\n            xaxis=dict(title='Age'),\n            yaxis=dict(title='Spending Score'),\n            zaxis=dict(title='Annual Income')))\nfig = go.Figure(data=data, layout=layout)\nfig.show()","35f2d198":"GMM5_clust_sizes = GMM5_clustered.groupby('Cluster').size().to_frame()\nGMM5_clust_sizes.columns = ['GMM5_size']\nGMM5_clust_sizes","7baa3d61":"covariance_param=['full','tied','diag','spherical']\nn_clusters=np.arange(2,11)\nresults2 = pd.DataFrame(columns=['Covariance Type','Number of Cluster','Silhouette Score','Davies Bouldin Score'])\nfor covariance in covariance_param:\n    for n in n_clusters:       \n        gmm_cluster = GMM(n_components=n,covariance_type=covariance,random_state=123)\n        clusters = gmm_cluster.fit_predict(X_df)\n        if len(np.unique(clusters))>=2:\n            results2 = results2.append({'Covariance Type':covariance,\n                                      'Number of Cluster':n,\n                                      'Silhouette Score':metrics.silhouette_score(X_df,clusters),\n                                      'Davies Bouldin Score':metrics.davies_bouldin_score(X_df,clusters)},ignore_index=True)","a3c5f936":"display(results2.sort_values(by=['Silhouette Score'], ascending=False)[:5])","3d06d15f":"gmm7_model = GMM(n_components=7, covariance_type='spherical', random_state=123)\nGMM7_clusters = gmm7_model.fit_predict(X_df)\nGMM7_clustered = X_df.copy()\nGMM7_clustered.loc[:,'Cluster'] = GMM7_clusters # append labels to points","85b75e9b":"fig4, (axes) = plt.subplots(1,2,figsize=(12,5))\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=GMM7_clustered,\n                hue='Cluster', ax=axes[0], palette='Set1', legend='full', s=100)\nsns.scatterplot(x='age', y='spending_score', data=GMM7_clustered,\n                hue='Cluster', palette='Set1', ax=axes[1], legend='full', s=100)\n\nfig4.suptitle('GMM_7', fontsize=20)\naxes[0].set_xlabel('Annual Income', fontsize=16)\naxes[0].set_ylabel('Spending Score', fontsize=16)\naxes[1].set_xlabel('Age', fontsize=16)\naxes[1].set_ylabel('Spending Score', fontsize=16)\nplt.show()","d4b9c941":"trace2 = go.Scatter3d(\n    x=X_df['age'],\n    y=X_df['spending_score'],\n    z=X_df['annual_income(k$)'],\n    mode='markers',\n    marker=dict(\n        color=GMM7_clustered['Cluster'], \n        size=10,\n        line=dict(\n            color=GMM7_clustered['Cluster'],\n            width= 12),\n    opacity=0.8))\ndata = [trace2]\nlayout = go.Layout(\n    title='Clusters',\n    scene = dict(\n            xaxis=dict(title='Age'),\n            yaxis=dict(title='Spending Score'),\n            zaxis=dict(title='Annual Income')))\nfig = go.Figure(data=data, layout=layout)\nfig.show()","ad5953d6":"GMM7_clust_sizes = GMM7_clustered.groupby('Cluster').size().to_frame()\nGMM7_clust_sizes.columns = ['GMM7_size']\nGMM7_clust_sizes","ba5517c9":"results = pd.DataFrame(columns=['Eps','Min_Samples','Number of Cluster','Silhouette Score','Davies Bouldin Score'])\nfor epsilon in range(1,12):\n    for min_sample in range(6,12):\n        dbscan_cluster = DBSCAN(eps=epsilon*0.5, min_samples=min_sample)\n        clusters = dbscan_cluster.fit_predict(X_df)\n        if len(np.unique(clusters))>=2:\n            results = results.append({'Eps':epsilon*0.5,\n                                      'Min_Samples':min_sample,\n                                      'Number of Cluster':len(np.unique(clusters)),\n                                      'Silhouette Score':metrics.silhouette_score(X_df,clusters),\n                                      'Davies Bouldin Score':metrics.davies_bouldin_score(X_df,clusters)},ignore_index=True)\nresults.sort_values(by='Silhouette Score', ascending=False).head()","71f459db":"DBS2_clustering = DBSCAN(eps=1.01, min_samples=9).fit(X_df)\nDBSCAN2_clustered = X_df.copy()\nDBSCAN2_clustered.loc[:,'Cluster'] = DBS2_clustering.labels_ # append labels to points","99e1dbef":"outliers = DBSCAN2_clustered[DBSCAN2_clustered['Cluster']==-1]\nfig4, (axes) = plt.subplots(1,2,figsize=(12,5))\n\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=DBSCAN2_clustered[DBSCAN2_clustered['Cluster']!=-1],\n                hue='Cluster', ax=axes[0], palette='Set1', legend='full', s=100)\nsns.scatterplot(x='age', y='spending_score', data=DBSCAN2_clustered[DBSCAN2_clustered['Cluster']!=-1],\n                hue='Cluster', palette='Set1', ax=axes[1], legend='full', s=100)\n\naxes[0].scatter(outliers['annual_income(k$)'], outliers['spending_score'], s=20, label='outliers', c='k')\naxes[1].scatter(outliers['age'], outliers['spending_score'], s=20, label='outliers', c='k')\n\nfig4.suptitle('DBSCAN_2', fontsize=20)\naxes[0].set_xlabel('Annual Income', fontsize=16)\naxes[0].set_ylabel('Spending Score', fontsize=16)\naxes[1].set_xlabel('Age', fontsize=16)\naxes[1].set_ylabel('Spending Score', fontsize=16)\nplt.setp(axes[0].get_legend().get_texts(), fontsize='10')\nplt.setp(axes[1].get_legend().get_texts(), fontsize='10')\naxes[0].legend()\naxes[1].legend()\nplt.show()","5f9be877":"DBS2_clust_sizes = DBSCAN2_clustered.groupby('Cluster').size().to_frame()\nDBS2_clust_sizes.columns = ['DBS2_size']\nDBS2_clust_sizes","1b0625d2":"results2 = pd.DataFrame(columns=['Eps','Min_Samples','Number of Cluster','Silhouette Score','Davies Bouldin Score'])\n\ndbscan_cluster2 = DBSCAN(eps=0.5, min_samples=7)\ndbcluster = dbscan_cluster2.fit(X_df)\nresults2 = results2.append({'Eps':0.5,\n                              'Min_Samples':7,\n                              'Number of Cluster':len(np.unique(dbcluster.labels_)),\n                              'Silhouette Score':metrics.silhouette_score(X_df,dbcluster.labels_),\n                              'Davies Bouldin Score':metrics.davies_bouldin_score(X_df,dbcluster.labels_)},ignore_index=True)\nresults2.sort_values(by='Silhouette Score', ascending=False).head()","47bbad6f":"DBS5_clustering_imp = DBSCAN(eps=0.5, min_samples=7).fit(X_df)\nDBS5_clustered_imp = X_df.copy()\nDBS5_clustered_imp.loc[:,'Cluster'] = DBS5_clustering_imp.labels_ # append labels to points","95f560d7":"outliers = DBS5_clustered_imp[DBS5_clustered_imp['Cluster']==-1]\nfig5, (axes) = plt.subplots(1,2,figsize=(12,5))\n\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=DBS5_clustered_imp[DBS5_clustered_imp['Cluster']!=-1],\n                hue='Cluster', ax=axes[0], palette='Set1', legend='full', s=100)\nsns.scatterplot(x='age', y='spending_score', data=DBS5_clustered_imp[DBS5_clustered_imp['Cluster']!=-1],\n                hue='Cluster', palette='Set1', ax=axes[1], legend='full', s=100)\n\naxes[0].scatter(outliers['annual_income(k$)'], outliers['spending_score'], s=20, label='outliers', c='k')\naxes[1].scatter(outliers['age'], outliers['spending_score'], s=20, label='outliers', c='k')\n\nfig5.suptitle('DBSCAN_5', fontsize=20)\naxes[0].set_xlabel('Annual Income', fontsize=16)\naxes[0].set_ylabel('Spending Score', fontsize=16)\naxes[1].set_xlabel('Age', fontsize=16)\naxes[1].set_ylabel('Spending Score', fontsize=16)\nplt.setp(axes[0].get_legend().get_texts(), fontsize='10')\nplt.setp(axes[1].get_legend().get_texts(), fontsize='10')\naxes[0].legend()\naxes[1].legend()\nplt.show()","5671a4cd":"DBS5_clust_sizes_imp = DBS5_clustered_imp.groupby('Cluster').size().to_frame()\nDBS5_clust_sizes_imp.columns = ['DBS5_size']\nDBS5_clust_sizes_imp","5535bb79":"fig1","1a2b789e":"fig2 = plt.figure(figsize=(10,6))\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=KM5_clustered,\n                hue='Cluster', palette='Set1', legend='full', s=100)\nplt.scatter(KM5_clusters.cluster_centers_[:,0], KM5_clusters.cluster_centers_[:,1], c='blue', s=100, alpha=0.5)\nplt.title('KMM_5 Based On Annual Income and Spending Score', fontsize=20)\nplt.xlabel('Annual Income(k$)', fontsize=16)\nplt.ylabel('Spending Score', fontsize=16)\nplt.show()","676d7fd8":"fig3","1e7b4b51":"fig4","05a1f766":"fig5","5a1db582":"clusters = pd.concat([KM6_clust_sizes,KM5_clust_sizes,GMM5_clust_sizes,GMM7_clust_sizes,DBS2_clust_sizes,DBS5_clust_sizes_imp],axis=1, sort=False)\nclusters","f442d3fe":"# dataframe showing the scores for different algorithm\nfinal_result = pd.DataFrame({'Algorithms': ['Hier_6','KM_6','KM_5','GMM_5','GMM_7','GMM_7_imp','DBS_2','DBS_5'], \n                             'Silhouette Score': [0.420,0.427,0.555,0.396,0.395,0.414,0.314,0.224], \n                             'Davies Bouldin Index': [0.852,0.824,0.572,0.871,1.01,0.933,1.985,1.509]})\nfinal_result.set_index('Algorithms')\nfinal_result.sort_values(by='Silhouette Score', ascending=False)","b36c692e":"# KM_5 customers segmentation based on annual_income and spending_score\nfig2 = plt.figure(figsize=(10,6))\nsns.scatterplot(x='annual_income(k$)', y='spending_score', data=KM5_clustered,\n                hue='Cluster', palette='Set1', legend='full', s=100)\nplt.scatter(KM5_clusters.cluster_centers_[:,0], KM5_clusters.cluster_centers_[:,1], c='blue', s=100, alpha=0.5)\nplt.title('KMM Based On Annual Income and Spending Score', fontsize=20)\nplt.xlabel('Annual Income(k$)', fontsize=16)\nplt.ylabel('Spending Score', fontsize=16)\nplt.show()","bf15ec0d":"### Insights from dendrogram\n1. From the dendrogram above, the longest vertical line that is not intersected by any line horizontally is cut through at y=8, and we are left with 6 clusters.","7f71534b":"### a) Find the optimal number of clusters using Silhouette score and DBI","ad7269dc":"### Insights from implot\n1. There is a linear dependency between `'spending score'` and `'age'`. \n2. Younger customers tend to have higher spending score and spending score decreases when age goes up.\n3. Therefore, we will try to cluster the customers based on this 2 features later on.","b23b54a0":"# Reading Dataset\nThe [dataset](https:\/\/www.kaggle.com\/vjchoudhary7\/customer-segmentation-tutorial-in-python) consists of the basic data about the customers like Customer ID, age, gender, annual income and spending score.\nSpending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data.\n\n## Data Dictionary\n|Columns|Description|\n|:---|:---|\n|CustomerID| unique identifier assigned to the customer|\n|Genre| gender of the customer|\n|Age| age of the customer|\n|Annual Income (k$)| income of the customer per year|\n|Spending Score (1-100)| score assigned by the mall based on customer behavior and spending nature|","b4b360fb":"### Insights from Boxplot\nBoxplot is plotted to better visualize the distribution of numerical columns along with its outliers.\n1. Outliers is observed in `'annual_income'`.","d94c40ec":"### Insights\n1. DBSCAN created 7 clusters included 'outliers' cluster (-1). \n\n2. here are 3 outliers. The graph above shows that the outliers do not meet distance and minimum samples requirements to be recognised as a cluster.\n\n3. The cluster size is extremely uneven as clusters -1 has only 3 customers while cluster 0 has 197.\n\n4. This does not aid in clustering the customers. Therefore, I tried to decrease the epsilon value during the model improvement state, to see if the number of clusters will increase. ","d0f6ce2b":"### Insight\n- The shape of the dataset is `(200,4)`, which comprises 200 rows and 5 columns.\n- No null values are found in the columns.\n- The features are numerical variables except for the `'Genre'` attribute, with an `object` data type, which means that the values contain either string or mixed numeric and non-numeric datas.","2fe5e698":"## Descriptive Summary\nI print a concise summary of the dataset using `.info()`.","fe7862ab":"### GMM_5","2ff3ae67":"### Insights\n1. After trying the different combinations of epsilon and min_samples, I found that using epsilon=0.5 and min_samples=7, the optimal number of clusters is 5, with a Silhouette score of 0.224 and DBI of 1.51. \n\n2. Even though the number of clusters have increased, the Silouette sore is comsidered low as compared to the rest of the algorithms. Hence, we can say that DBSCAN is not a good model in segmenting the customers.","405fa4fb":"### 4.2.2 Segmentation using annual income and spending score","a349e3d9":"### Insights from 3D scatter plot\n1. The confusion is now solved. 6 clusters is due to a splitted cluster by age in the cluster located in the middle where customers have moderate annual income and spending score.\n\n2. In other words, there are two distinct age groups who earn average income and spend moderately in the mall.","14129fc0":"### Insights from distribution plot\n1. From the distribution plot, we can see that there are more young and middle-aged customers as compared to the older-aged customers.\n2. Customers with lower annual income frequent the mall more than customers with higher annual income.\n3. Spending score is almost normally distributed.","a98e6df6":"# 4. Modelling","bc794807":"### Insights\n1. It shows that n_cluster=6 is the optimal number of customer segments, which has an identical result as hierarchical clustering.\n\n2. The Silhouette score suggest that there are 6 clusters of customers while DBI suggest that there are 7.\n\n3. Then, i went on to verify the correctness of the number of clusters suggested by the elbow method and the silhouette score (n_clusters=6) by plotting multiple scatter plots to observe if the clusters are clearly separated. At the same time, we can also identify the important features that helps to catogorize the customers.","110b9f3a":"### Insights from Silhouette score\nIn GMM, n_components (the number of mixture components) is set to `default = 1`.\nThe covariance_type {'full', 'tied', 'diag', 'spherical'}, is set to `default = 'full'`.\n\n1. The suggested number of clusters is 7 as it has the higest silhouette score and low variance (error). The Silhouette score n_cluster=5 is very close to n_cluster=7.\n\n2. Next, let\u2019s look at the performance metrics according to changing parameters.","5fd040f9":"### c) Finding the significant features","743815c4":"### a) Finding the optimal number of clusters using elbow method","241c69bb":"# Problem Statement\n- As the owner of the mall and you want to understand your customers so that appropriate directions can be given to the marketing team for them to plan their strategy accordingly.\n\n- By the end of this case study, you would be able to answer below questions.\n    - How to achieve customer segmentation using unsupervised machine learning algorithm in Python?\n    - Who are your target customers with whom you can start marketing strategy?","62d49741":"### Comparing Silhouette Score and DBI","4efd0cef":"## Graphical Summary","5204ab5e":"### Insights from Fig2\n1. K-Means algorithm generated the following 5 clusters:\n\n    - cluster 0: clients with high annual income and high spending score\n    - cluster 1: clients with medium annual income and medium spending score\n    - cluster 2: clients with low annual income and low spending score\n    - cluster 3: clients with low annual income and high spending score\n    - cluster 4: clients with high annual income and low spending score","e85c87dc":"### Insights \n1. The highest Silhoutte coefficient and lowest DBI give a robust indication that n_cluster=5 is the best split for the customers, if 'age' is not taken into account. \n\n2. Now, let's try out a more complex model, GMM which do not require us to specify the optimal number of clusters as it will determine automatically.","d5d663cd":"### Insights from pairplot and 3D scatter plot\n- The pairplot shows that `'gender'` has no direct relation to segmenting customers. Male and female customers are almost equally spreaded. Therefore, we can drop it and move on with other features.\n- There is no significant relationship between all the features.\n- However, the `'age'` vs `'spending score'` plot in R1C3 shows 2 distinct groups of customers (top left corner and bottom right corner).\n- `'annual income'` and `'spending score'` plot in R2C3 seems to form five dense regions: 4 regions at the corners and one in the center.\n- These might be the clusters to segment the customers.","63901358":"# 2. Data Preprocessing\nAfter performing EDA, the modifications required are:\n1. Dropping columns that do not provide useful information.","307cc2f6":"### Insights from pie chart\n1. The female population clearly outweighs the male counterpart. There are 6% more female customers who frequent the mall as compared to that of male.\n2. Almost even distribution.","7052d466":"## Metrics\n1. Silhouette Score\n> The silhouette score is a measure of the average similarity of the objects within a cluster and their distance to the other objects in the other clusters.\n> The more the score is near to one, the better the clustering is.\n\n2. Akaike information criterion (AIC) and Bayesian information criterion (BIC) Score\n> The optimal number of clusters is the value that minimizes the AIC or BIC.\n\n3. The Elbow Method\n> A simple (but not very robust) visual method to estimate the optimal number of clusters k.\n> The idea behind the elbow method is to identify the value of k where the score begins to decrease most rapidly before the curve reached a plateau.However, it can get confusing sometimes.\n\n4. Davies-Bouldin Index\n> Based on a ratio between \u201cwithin-cluster\u201d and \u201cbetween-cluster\u201d distances:\n> The optimal clustering has the smallest DBI value.","6331b9ea":"### Insights \n1. Spherical covariance type with 7 clusters scores the best Silhouette score and outperforms GMM_5.","7e958bef":"# 3. Feature Engineering","1753e588":"### 4.1.1 Segmentation using age, annual income and spending score","67124a17":"### b) Finding the optimal number of clusters using Silhouette Score and DBI","b3ab6132":"## Customer Profile","00cbdda0":"# 1. Exploratory Data Analysis","d8a436f1":"### a) Finding the optimal number of clusters using elbow method","98000342":"### Insights from histogram\n1. `20-30`, `30-40` are the most common age groups. (dominated by female customers)\n2. Most of the customers earn between `50k` and `80k` dollar annually.\n3. A huge part of customers earn only `20k` dollar annually.","805083ee":"# 5. Conclusion","a71a438b":"## 4.2 Clustering using K-means\n- K-means clustering is an example of exclusive clustering. A data point can exist only in one cluster. This can also be referred to as \u201chard\u201d clustering. \n\n- Despite the simplicity (both mathematical and coding), k-means has some drawbacks includes:\n\n    - a negligent edge of each cluster, because the priorities are set on the center of the cluster, not on its borders\n    - an inability to create a structure of a dataset with objects that can be classified to multiple clusters in equal measure\n    > This can be solved by using the improved version of K-means algorithm, GMM.\n    - a need to guess the optimal k number, or a need to make preliminary calculations to specify this gauge.\n    > This can be solved by using the DBSCAN and GMM.\n    \n- However, before moving on to the more complex model, we'll first cluster the customers using a simpler algorithm.","99299190":"### 4.2.1 Segmentation using age, annual income and spending score","d6c91bc8":"### Insights\n1. n_clusters = 6 has the highest Silhouette Score and but does not have the lowest DBI. \n\n2. For this scenario, we will be focusing on Silhouette score more than DBI as Silhouette score can estimate more accurately when the clusters are spherical in-shape. As DBI score is calculating the ratio of \"within cluster\" over \"between cluster\", it might not be accurate in this case as all the data points are very close to one another.\n\n3. Therefore, 6 clusters is the suggested k values for clustering based on age, annual income and spending score.\n\n3. Next, I utilised one of the simplest and popular unsupervised machine learning algorithms, K-Means (a centroid-based clustering algorithm) to further validate the accuracy of the result returned by hierarchical clustering.","98e8f2bb":"### Comparing Cluster Sizes","7520586e":"### b) Finding the optimal number of clusters using Silhouette and DB scores","3bfc8424":"### Insights from Final Scores\n1. Finally, I have tried four algorithms with different configurations, they are Hierarchical Custering, K_means, GMM, and DBSCAN. \n\n2. We can conclude that when the customers are segmented according to 'age', 'annual_income' and 'spending_score', there are more likely to be 6 different clusters of customers in the mall.\n\n2. If 'age' is not considered when grouping the customers, there will be 5 clusters.In addition, when using 5 clusters, we are getting 5 different groups of customers that separates well from each other and the marketing team could run different campaigns on each customer group.\n\n3. Based on the comparison, K-Means outperforms all the algorithms tested as it has the best Silhouette score and Davies Bouldin Index. For this reason, this algorithm is more suitable for customer segmentation. Let\u2019s try to understand behaviours or labels of the customers.","c1f9422f":"From the above comparisons, it is clear that DBSCAN failed to generate reasonable clusters. It is due to its problems in recognising clusters of various densities (which are present in this case).\n\nIn turn, K-Means and Affinity Propagation algorithms created reasonable 6 clusters.","b3382830":"### b) Finding the optimal number of clusters using Silhouette score and DBI","da62f1a0":"## 4.1 Hierarchical clustering\n- Firstly, we'll be using Agglomerative clustering, a 'bottoms-up approach'. Its data points are isolated as separate groupings initially, then they are merged together iteratively on the basis of similarity until one cluster has been achieved.\n\n- One disadvantage of using hierarchical clustering is that the complexity of the algorithm may turn out to be excessive or simply inapplicable for datasets with little to no hierarchy. On top of that, you won't get a precise structure using the hierarchical algorithm.\n\n- Therefore, we might need another more advanced model to support the result returned by the hierarchical clustering model.","61f9e81c":"### 4.4.1 Model Improvement","ca242bee":"## 4.3 Gaussian Mixture Model (GMM)\n- A probability clustering model which helps us solve density estimation or 'soft' clustering problems. In probabilistic clustering, data points are clustered based on the likelihood that they belong to a particular distribution. \n\n- K-Means only considers the mean to update the centroid while GMM takes into account the mean as well as the variance of the data.\n\n- Unlike the centroid-based models, the EM algorithm allows the points to classify for two or more clusters.","e12b10df":"### Insights from boxplot\n1. *Gender vs Age*:  Most of the male customers are from the age group of approximately 28 to 51 while female are from the age group of about 29 to 48.\n\n2. *Gender vs Annual Income*: Genarally, males receive higher pay than females. But the number of males and females are equal in number when it comes to low annual income.\n\n3. *Gender vs Spending Score*: It is clearly visible that most of the males have a spending score of around 25k dollar to 70k dollar whereas females have a spending score of around 35k dollar to 75k dollar.\n\n4. The boxplot above shows the contrast of the spending behaviour between males and females. Generally, women spend slightly more than men.","7dce402f":"### Insights from heatmap\n1. The heat map above reflects the most correlated features with beige color and least correlated features with dark purple color.\n\n2. From the heat map, we can observe that the features do not have strong correlation between one another. This signifies that the features do not show the same trend, so multicollinearity does not occur.","8ef68fb7":"### a) Finding the optimal number of clusters using dendrogram","ad16715f":"Unsupervised Learning\nMall Customer Segmentation Project\n<b>Name:<\/b> Sih Jia Qi <br>","8c9c021d":"### Insights from histogram (spending score)\n1. The countplot above shows that most customers have a spending score between `45 and 60`. \n\n2. However, there are customers with a spending score of 1. On the other extreme, several customers have a spending score of 99. This seems to suggest that the mall provides goods and services that suit the needs of various types of customers.\n\n3. Spending scores by gender can be grouped into a few modes:\n    - between 0 and 20 (men dominate)\n    - between 25 and 40 (women dominate)\n    - between 45 and 60 (women dominate)\n    - between 65 and 70 (men dominates)\n    - between 70 and 100 (women dominates)","20718800":"### d) Visualizing customer clusters using 3D scatter plot","7c9d6f92":"### Insights\n1. K-Means algorithm generated the following 6 clusters:\n\n    - cluster 0: younger clients with **medium** annual and **medium** spending score\n    - cluster 1: clients with **low** annual income and **high** spending score\n    - cluster 2: younger clients with **medium** annual and **medium** spending score\n    - cluster 3: clients with **high** annual income and **high** spending score\n    - cluster 4: clients with **low** annual income and **low** spending score\n    - cluster 5: clients with **high** annual income and **low** spending score\n\n2. The scatter plot of 'Age vs Spending Score'(R1C2) shows that the clusters overlapped one another. There are no distinct groups in terms of customers age.\n\n3. By looking at the scatter plot of 'Annual income vs Spending Score'(R1C1), it can be seen that the clusters located at the center do not show distinct separations. There are mixed of data points from different clusters. Yet, it is obvious that there are 5 clearly separated clusters in the plot.\n\n3. Therefore, the optimal number of clusters are more likely to be 5 if the customers are clustered according to their 'annual income' and 'spending score'.\n\n4. Next, I plotted a 3D scatter plot to look into the data points in the 'annual_income' vs 'spending_score' plot, to find out the reason of the overlapping part in the middle of the cluster.\n","1765c4b4":"To answer the question \"Who are your target customers with whom you can start marketing strategy?\", we have decided to have 5 clusters, meaning 5 customer groups. But who are people in these groups?\n\n- Group 1: Poor and not-spender - customers with low income and low spending score (cluster #4)\n- Group 2: Poor and spender - customers with low income, but spending a lot (cluster #2)\n- Group 3: Neutral - customers with mid income and mid spending score (cluster #0)\n- Group 4: Rich and not-spender - customers with high income and low spending score (cluster #1)\n- Group 5: Rich and spender - customers with high income and high spending score (cluster #3)","fdd68dd1":"### GMM_7","d27c55f3":"## 4.4 DBSCAN\n- A density-based clustering algorithm. \n- DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is good for data which contains clusters of a similar density. \n- Parameters tuning: a positive number epsilon and a natural number minPoints.\n\n- The clusters determined with DBSCAN can have arbitrary shapes, thereby are extremely accurate. Besides, the number of clusters is determined automatically.\n\n- Still, even such a masterpiece as DBSCAN has a drawback. If the dataset consists of variable density clusters, the method shows poor results. ","27e45de9":"### Insights from .skew() result\nAs a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n\n1. From the result obtained, the features are approximately symmetric, therefore we do not need to deskew them."}}