{"cell_type":{"d3210f84":"code","4182f320":"code","81a9fc83":"code","c5f7aee7":"code","91524147":"code","726908f6":"code","6cdcc9e3":"code","16cbbad8":"code","af254feb":"code","64261f9a":"code","1a04fa20":"code","a8755927":"code","f8bf6fc2":"code","a159d19f":"code","001edb9f":"code","0f7d0589":"code","7573a769":"code","f41b2b09":"code","f6f3d187":"code","0370feae":"code","35c9491f":"code","e18e9822":"code","65f33ee7":"code","335816b7":"code","f70cab79":"code","93c01ce9":"code","f0bca09e":"code","0802aee3":"code","8c8ad840":"code","09b72cc8":"code","cbfbff7e":"code","324c0641":"code","bd45e5d9":"code","0f9f9e7a":"code","a8cf0cef":"code","b5334776":"code","3337704c":"code","0b63b0b0":"code","8a3723ae":"code","771d0922":"code","7af2f201":"code","72ff0b9a":"code","13ec4997":"code","2411529a":"code","2b0669b9":"code","fff4fa56":"code","00c2b407":"code","889aa2de":"code","4593acdb":"code","34de6151":"code","769e68b9":"code","a2400da7":"code","d56f4511":"code","68bf6c94":"code","80026bc6":"code","688e1978":"code","63869ee6":"code","4e8466ca":"code","79a29c7a":"code","999b4394":"code","8d0a2ba5":"code","cc930192":"code","d75b9d87":"code","7a418a4f":"code","4087955b":"code","f0bc13ad":"code","572eaff5":"code","0f3f6344":"markdown","0b84982a":"markdown","95b3339d":"markdown","cf93dd91":"markdown","89c8cba2":"markdown","11c80f24":"markdown","9f666d78":"markdown","e3769db1":"markdown","16042410":"markdown","f47e20e2":"markdown","3416e9b0":"markdown","5e13f176":"markdown","96ffe0de":"markdown","302ad1cf":"markdown","236ffa8a":"markdown","e432f28c":"markdown","ccf89593":"markdown","d69e6fe4":"markdown","16f39f97":"markdown","5703dba6":"markdown","8438362e":"markdown","784324f9":"markdown","380d9225":"markdown","e6191979":"markdown","9d0e3a82":"markdown","90e387e8":"markdown","ae59951e":"markdown","f9b3fea1":"markdown","4eae7e43":"markdown","0b7196cf":"markdown"},"source":{"d3210f84":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","4182f320":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data.head()","81a9fc83":"test_data = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_data.head()","c5f7aee7":"submission_data = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission_data.head()","91524147":"print(train_data.isnull().sum())\nprint()\nprint('train_data shape -->',train_data.shape)\nprint()\nprint()\nprint(test_data.isnull().sum())\nprint()\nprint('test_data shape -->',test_data.shape)","726908f6":"train_data.drop('Cabin', axis = 1, inplace = True)\ntest_data.drop('Cabin', axis = 1, inplace = True)","6cdcc9e3":"print(train_data.isnull().sum())\nprint()\nprint('train_data shape -->',train_data.shape)\nprint()\nprint()\nprint(test_data.isnull().sum())\nprint()\nprint('test_data shape -->',test_data.shape)","16cbbad8":"train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.')    \ntest_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.')","af254feb":"train_data.head()","64261f9a":"train_data['Title'].value_counts()","1a04fa20":"all_data = [train_data, test_data]","a8755927":"for data in all_data:\n    data.loc[(data['Age'].isnull()) & (data['Title'] == 'Mr'), 'Age'] = data[data['Title'] == 'Mr']['Age'].mean()\n    data.loc[(data['Age'].isnull()) & (data['Title'] == 'Mrs'), 'Age'] = data[data['Title'] == 'Mrs']['Age'].mean()\n    data.loc[(data['Age'].isnull()) & (data['Title'] == 'Miss'), 'Age'] = data[data['Title'] == 'Miss']['Age'].mean()\n    data.loc[(data['Age'].isnull()) & (data['Title'] == 'Master'), 'Age'] = data[data['Title'] == 'Master']['Age'].mean()\n    data.loc[(data['Age'].isnull()) & (data['Title'] == 'Dr'), 'Age'] = data[data['Title'] == 'Dr']['Age'].mean()\n    data.loc[(data['Age'].isnull()) & (data['Title'] == 'Rev'), 'Age'] = data[data['Title'] == 'Rev']['Age'].mean()\n    data.loc[(data['Age'].isnull()), 'Age'] = data['Age'].mean()","f8bf6fc2":"print(train_data.isnull().sum())\nprint()\nprint('train_data shape -->',train_data.shape)\nprint()\nprint()\nprint(test_data.isnull().sum())\nprint()\nprint('test_data shape -->',test_data.shape)","a159d19f":"train_data['Embarked'].value_counts()","001edb9f":"train_data['Embarked'] = train_data['Embarked'].fillna('S')\ntest_data['Embarked'] = test_data['Embarked'].fillna('S')","0f7d0589":"train_data['Embarked'].value_counts()","7573a769":"print(train_data.isnull().sum())\nprint()\nprint('train_data shape -->',train_data.shape)\nprint()\nprint()\nprint(test_data.isnull().sum())\nprint()\nprint('test_data shape -->',test_data.shape)","f41b2b09":"test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean())","f6f3d187":"print(train_data.isnull().sum())\nprint()\nprint('train_data shape -->',train_data.shape)\nprint()\nprint()\nprint(test_data.isnull().sum())\nprint()\nprint('test_data shape -->',test_data.shape)","0370feae":"drop_list = ['PassengerId', 'Name', 'Ticket', 'Title']\ntrain_data.drop(drop_list, axis = 1, inplace = True)\ntest_data.drop(drop_list, axis = 1, inplace = True)","35c9491f":"print(train_data.info())\nprint()\nprint()\nprint(test_data.info())","e18e9822":"train_data.head()","65f33ee7":"fig, ax = plt.subplots(figsize = (10, 10))\nsns.heatmap(train_data.corr(), cmap = 'BuPu', cbar = True, annot = True, linewidth = 0.5, ax = ax)\nplt.show()","335816b7":"train_data['Pclass'].value_counts()","f70cab79":"sns.catplot(x = 'Pclass', y= 'Survived', kind = 'bar', data = train_data)","93c01ce9":"train_data['Embarked'].value_counts()","f0bca09e":"sns.catplot(x = 'Embarked', y= 'Survived', kind = 'bar', data = train_data)","0802aee3":"train_data['Sex'].value_counts()","8c8ad840":"sns.catplot(x = 'Sex', y= 'Survived', kind = 'bar', data = train_data)","09b72cc8":"train_data['SibSp'].value_counts()","cbfbff7e":"sns.catplot(x = 'SibSp', y= 'Survived', kind = 'bar', data = train_data)","324c0641":"train_data['Parch'].value_counts()","bd45e5d9":"sns.catplot(x = 'Parch', y= 'Survived', kind = 'bar', data = train_data)","0f9f9e7a":"fig, ax = plt.subplots(figsize = (10, 10))\nsns.histplot(x = train_data['Age'],  bins=20, hue = train_data['Survived'])\nplt.show()","a8cf0cef":"sns.catplot(x = 'Pclass', y = 'Survived', data = train_data, kind = 'point', hue = 'Sex')","b5334776":"sns.catplot(x = 'Embarked', y = 'Survived', data = train_data, kind = 'point', hue = 'Sex')","3337704c":"sns.factorplot(x = 'Sex', y = 'Survived', data = train_data, kind = 'point', col = 'SibSp')","0b63b0b0":"sns.scatterplot(y = 'Age', x = 'Fare', data = train_data, hue = 'Survived')","8a3723ae":"print(train_data.shape)\nprint(test_data.shape)","771d0922":"train_data.head()","7af2f201":"test_data.head()","72ff0b9a":"train_data_2 = pd.get_dummies(train_data)\ntrain_data_2.head()","13ec4997":"test_data_2 = pd.get_dummies(test_data)\ntest_data_2.head()","2411529a":"print(train_data_2.shape)\nprint(test_data_2.shape)","2b0669b9":"X_train = train_data_2.drop('Survived', axis = 1).values\ny_train = train_data_2['Survived'].values.reshape((-1, 1))\nX_test = test_data_2.values\ny_test = submission_data.drop('PassengerId', axis = 1).values.reshape((-1, 1))\n\nprint('x train shape {}'.format(X_train.shape))\nprint('y train shape {}'.format(y_train.shape))\nprint('x test  shape {}'.format(X_test.shape))\nprint('y test  shape {}'.format(y_test.shape))","fff4fa56":"logistic_model = LogisticRegression(solver = 'liblinear')","00c2b407":"logistic_model.fit(X_train, y_train)\ny_pred = logistic_model.predict(X_test)\nprint(logistic_model.score(X_train,y_train)*100)\nprint(accuracy_score(y_test, y_pred)*100)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","889aa2de":"SVC_class = SVC(C = 0.1, kernel = 'linear')","4593acdb":"SVC_class.fit(X_train,y_train)\ny_pred = SVC_class.predict(X_test)\nprint(SVC_class.score(X_train,y_train)*100)\nprint(accuracy_score(y_test, y_pred)*100)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","34de6151":"tree_class = DecisionTreeClassifier(criterion='gini', max_depth=3, splitter='best', random_state=1)","769e68b9":"tree_class.fit(X_train, y_train)\ny_pred = tree_class.predict(X_test)\nprint(tree_class.score(X_train,y_train)*100)\nprint(accuracy_score(y_test, y_pred)*100)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","a2400da7":"Random_class = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=3, random_state = 33)","d56f4511":"Random_class.fit(X_train, y_train)\ny_pred = Random_class.predict(X_test)\nprint(Random_class.score(X_train,y_train)*100)\nprint(accuracy_score(y_test, y_pred)*100)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","68bf6c94":"Voting_class = VotingClassifier(estimators=[('SVC_class', SVC_class),('tree_class', tree_class), ('logistig_model', logistic_model), ('Random_class', Random_class)], \n                                voting='hard')","80026bc6":"Voting_class.fit(X_train, y_train)\ny_pred = Voting_class.predict(X_test)\nprint(Voting_class.score(X_train,y_train)*100)\nprint(accuracy_score(y_test, y_pred)*100)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","688e1978":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=1)\nX_sm_train , y_sm_train = sm.fit_resample(X_train,y_train)\nX_sm_test , y_sm_test = sm.fit_resample(X_test,y_test)","63869ee6":"logistic_model_2 = LogisticRegression(solver = 'liblinear')","4e8466ca":"logistic_model_2.fit(X_sm_train, y_sm_train)\ny_pred = logistic_model_2.predict(X_sm_test)\nprint(logistic_model_2.score(X_sm_train,y_sm_train)*100)\nprint(accuracy_score(y_sm_test, y_pred)*100)\nprint(confusion_matrix(y_sm_test, y_pred))\nprint(classification_report(y_sm_test, y_pred))","79a29c7a":"SVC_class_2 = SVC(C = 0.1, kernel = 'linear')","999b4394":"SVC_class_2.fit(X_sm_train, y_sm_train)\ny_pred = SVC_class_2.predict(X_sm_test)\nprint(SVC_class_2.score(X_sm_train,y_sm_train)*100)\nprint(accuracy_score(y_sm_test, y_pred)*100)\nprint(confusion_matrix(y_sm_test, y_pred))\nprint(classification_report(y_sm_test, y_pred))","8d0a2ba5":"tree_class_2 = DecisionTreeClassifier(criterion='gini', max_depth=2, splitter='best', random_state=33)","cc930192":"tree_class_2.fit(X_sm_train,y_sm_train)\ny_pred = tree_class_2.predict(X_sm_test)\nprint(tree_class_2.score(X_sm_train,y_sm_train)*100)\nprint(accuracy_score(y_sm_test, y_pred)*100)\nprint(confusion_matrix(y_sm_test, y_pred))\nprint(classification_report(y_sm_test, y_pred))","d75b9d87":"Random_class_2 = RandomForestClassifier(n_estimators=400, criterion='gini', max_depth=2, random_state = 33)","7a418a4f":"Random_class_2.fit(X_sm_train,y_sm_train)\ny_pred = Random_class_2.predict(X_sm_test)\nprint(Random_class_2.score(X_sm_train,y_sm_train)*100)\nprint(accuracy_score(y_sm_test, y_pred)*100)\nprint(confusion_matrix(y_sm_test, y_pred))\nprint(classification_report(y_sm_test, y_pred))","4087955b":"Voting_class_2 = VotingClassifier(estimators=[('tree_class', tree_class_2), ('logistig_model', logistic_model_2), ('SVC_class_2', SVC_class_2), ('Random_class', Random_class_2)], \n                                voting='hard')","f0bc13ad":"Voting_class_2.fit(X_sm_train,y_sm_train)\ny_pred = Voting_class_2.predict(X_sm_test)\nprint(Voting_class_2.score(X_sm_train,y_sm_train)*100)\nprint(accuracy_score(y_sm_test, y_pred)*100)\nprint(confusion_matrix(y_sm_test, y_pred))\nprint(classification_report(y_sm_test, y_pred))","572eaff5":"print('The classification report for the best model before scalling')\nprint('.....................SVC classifier.........................')\nprint(classification_report(y_test,SVC_class.predict(X_test)))\nprint()\nprint('.................Decision Tree Classifier...................')\nprint('The classification report for the best model after scalling')\nprint(classification_report(y_sm_test, tree_class_2.predict(X_sm_test)))","0f3f6344":"# ***Decision Tree Classifier After Scaling***","0b84982a":"**In the end, we found SVC and Decision tree is the best algorithm.**<br>\n**with accurecy score = 100.00 %**<br>\n**and with f1_score = 100.00 %**<br>","95b3339d":"# Cabin column NaN\n**We can see the most values in the Cabin column have a NaN values**<br>\n**SO, It will better to remove the Cabin column**<br>\n**Because, it's difficult to treat**<br>","cf93dd91":"**The number of children who survived drowning is greater than the number of children who drowned**<br>\n**This is due to the parents trying to save them**<br>\n**and we can the the number of drowned passengers whose have age between 30 to 40 is more than survived passenger in the same age range by double**","89c8cba2":"# Age column NaN\n**In the next few line, we will try to treat the NaN values in the Age coulmn**<br>\n**As we know, we can predict the age for any person by knowing it's name Title ('Mr', 'Mrs', 'Miss', 'Dr', etc...)**<br>\n**So, we will extract the name titels from the passengers names**\n","11c80f24":"# ***Random Forest After Scaling***","9f666d78":"# ***SVC After Scaling***","e3769db1":"**We know in the previous figures the all femals and passenger in First class have a better survival chance**<br>\n**This figure shows**<br>\n**Almost all females in the first class survive from drowning**<br>\n**and the females in the second class has a very high chane**","16042410":"# **Loading train and Data**\n","f47e20e2":"# Spliting the data into training and test","3416e9b0":"# **Detecting Data imbalancing**","5e13f176":"**The previous chart is very interesting.** <br>\n**Females have a very high survival chance compared to male**<br>\n**Females survival chance is more than 70%**<br>\n**Men's chance of survival does not exceed 20%.**<br>\n**This could be due to men trying to save their own women,**<br>\n**such as wives, mothers and their daughters**<br>\n**They would rather save them from drowning than save themselves**","96ffe0de":"# ***Voting Classifier***","302ad1cf":"# Fare column NaN\n**In this column, we have only one NaN values**<br>\n**We will replace it by the Fare mean**","236ffa8a":"# ***Random Forest Classifier***","e432f28c":"**We know in the previous figures the all femals and passenger in C Embarked have a better survival chance**<br>\n**This figure shows**<br>\n**females in the C Embarked have a high survival chance**<br>","ccf89593":"# Dummy variables\n**Convert categorical variables into dummy**","d69e6fe4":"# ***Decision Tree Classifier***","16f39f97":"# Visualization of Data\n**We will create some figure to know more about data** <br>\n**and discover,** <br>\n**if we want another data processing operations** <br>","5703dba6":"# **Dealing with NAN values**`","8438362e":"# ***Voting Classifier After Scaling***","784324f9":"**first class passengers have better survival chance than second.**<br>\n**And, second class passengers have better survival chance than third.**<br>\n ","380d9225":"\n**Passengers with high-priced tickets have a higher chance of survival compared to passenger with low-priced ticketd**","e6191979":"# ***SVM classifier***","9d0e3a82":"**We can see in the previous figure**<br>\n**the C Embarked passenger have better survival chance.**","90e387e8":"# ***Logistic Regression After Scaling***","ae59951e":"# Drop coulmns operation\n**'PassengerId' coulumn in our database have a unique number for every client**.<br>\n**'Name' and 'Ticket' columns will have no effect in our prediction**<br>\n**'Title' coulmn used in predicted the Age missing values,** <br>\n**so we will not need it anymore**","f9b3fea1":"# Embarked column NaN\n**In this column, we have only two NaN values**<br>\n**We can remove the two records to solve the NaN value problem**<br>\n**but We have little data**<br>\n**So**<br>\n**We solve it by replace the the NaN values by the most frequent value**","4eae7e43":"# ***Logistic Regression***","0b7196cf":"# ***Now we will compare between the best algorithm before scalling and the best after scalling***"}}