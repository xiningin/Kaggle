{"cell_type":{"513fa172":"code","7c447f90":"code","d2459482":"code","a39df1e7":"code","536a8199":"code","d8c906c1":"code","783aba56":"code","91d61ab9":"code","7ac86329":"code","5b4719cc":"code","2769c3b8":"code","b84a2649":"code","929f78d4":"code","326df21d":"code","52b4185b":"code","a9b5ba10":"code","518efa67":"code","023af9d9":"code","2f1c5053":"markdown","1fac768a":"markdown","a8173ef7":"markdown","51216208":"markdown","447a6069":"markdown","3b9f62df":"markdown","b77ba786":"markdown","40cd09fe":"markdown","0fe8db90":"markdown"},"source":{"513fa172":"from __future__ import division, print_function\n\nimport numpy as np\n\ntry:\n    from pylab import plt\nexcept ImportError:\n    print('Unable to import pylab. R_pca.plot_fit() will not work.')\n\ntry:\n    # Python 2: 'xrange' is the iterative version\n    range = xrange\nexcept NameError:\n    # Python 3: 'range' is iterative - no need for 'xrange'\n    pass\n\n\nclass R_pca:\n\n    def __init__(self, D, mu=None, lmbda=None):\n        self.D = D\n        self.S = np.zeros(self.D.shape)\n        self.Y = np.zeros(self.D.shape)\n\n        if mu:\n            self.mu = mu\n        else:\n            self.mu = np.prod(self.D.shape) \/ (4 * np.linalg.norm(self.D, ord=1))\n\n        self.mu_inv = 1 \/ self.mu\n\n        if lmbda:\n            self.lmbda = lmbda\n        else:\n            self.lmbda = 1 \/ np.sqrt(np.max(self.D.shape))\n\n    @staticmethod\n    def frobenius_norm(M):\n        return np.linalg.norm(M, ord='fro')\n\n    @staticmethod\n    def shrink(M, tau):\n        return np.sign(M) * np.maximum((np.abs(M) - tau), np.zeros(M.shape))\n\n    def svd_threshold(self, M, tau):\n        U, S, V = np.linalg.svd(M, full_matrices=False)\n        return np.dot(U, np.dot(np.diag(self.shrink(S, tau)), V))\n\n    def fit(self, tol=None, max_iter=1000, iter_print=100):\n        iter = 0\n        err = np.Inf\n        Sk = self.S\n        Yk = self.Y\n        Lk = np.zeros(self.D.shape)\n\n        if tol:\n            _tol = tol\n        else:\n            _tol = 1E-7 * self.frobenius_norm(self.D)\n\n        #this loop implements the principal component pursuit (PCP) algorithm\n        #located in the table on page 29 of https:\/\/arxiv.org\/pdf\/0912.3599.pdf\n        while (err > _tol) and iter < max_iter:\n            Lk = self.svd_threshold(\n                self.D - Sk + self.mu_inv * Yk, self.mu_inv)                            #this line implements step 3\n            Sk = self.shrink(\n                self.D - Lk + (self.mu_inv * Yk), self.mu_inv * self.lmbda)             #this line implements step 4\n            Yk = Yk + self.mu * (self.D - Lk - Sk)                                      #this line implements step 5\n            err = self.frobenius_norm(self.D - Lk - Sk)\n            iter += 1\n            if (iter % iter_print) == 0 or iter == 1 or iter > max_iter or err <= _tol:\n                print('iteration: {0}, error: {1}'.format(iter, err))\n\n        self.L = Lk\n        self.S = Sk\n        return Lk, Sk\n\n    def plot_fit(self, size=None, tol=0.1, axis_on=True):\n\n        n, d = self.D.shape\n\n        if size:\n            nrows, ncols = size\n        else:\n            sq = np.ceil(np.sqrt(n))\n            nrows = int(sq)\n            ncols = int(sq)\n\n        ymin = np.nanmin(self.D)\n        ymax = np.nanmax(self.D)\n        print('ymin: {0}, ymax: {1}'.format(ymin, ymax))\n\n        numplots = np.min([n, nrows * ncols])\n        plt.figure()\n\n        for n in range(numplots):\n            plt.subplot(nrows, ncols, n + 1)\n            plt.ylim((ymin - tol, ymax + tol))\n            plt.plot(self.L[n, :] + self.S[n, :], 'r')\n            plt.plot(self.L[n, :], 'b')\n            if not axis_on:\n                plt.axis('off')","7c447f90":"import numpy as np\nimport pandas as pd   \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('max_columns', 150)\nimport random\nX_ = np.loadtxt(\"\/kaggle\/input\/iot-sensordata\/Xdados.txt\") # X have 14.400rows x 52 sensors\n\nX=pd.DataFrame(X_, columns=['s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23','s24','s25','s26','s27','s28','s29','s30','s31','s32','s33','s34','s35','s36','s37','s38','s39','s40','s41','s42','s43','s44','s45','s46','s47','s48','s49','s50','s51','s52']) \nprint(X.shape)\nX.to_csv('Xdados.csv',index=False)\nX.head() ","d2459482":"# generate low rank synthetic data\nN = 100\nnum_groups = 3\nnum_values_per_group = 40\np_missing = 0.2\n\nDs = []\nfor k in range(num_groups):\n    d = np.ones((N, num_values_per_group)) * (k + 1) * 10\n    Ds.append(d)\n\nD = np.hstack(Ds)\n\n# decimate 20% of data \nn1, n2 = D.shape\nS = np.random.rand(n1, n2)\nD[S < 0.2] = 0\n\n\n\n# use R_pca to estimate the degraded data as L + S, where L is low rank, and S is sparse\nrpca = R_pca(D)\nL, S = rpca.fit(max_iter=10000, iter_print=100)\n\n# visually inspect results (requires matplotlib)\nrpca.plot_fit()\nplt.show()","a39df1e7":"names=X.columns[13]\nx = X[names]","536a8199":"x.shape","d8c906c1":"x.values.reshape(-1,1)","783aba56":"x.values.reshape(-1,1).shape","91d61ab9":"# use R_pca to estimate the degraded data as L + S, where L is low rank, and S is sparse\nrpca = R_pca(x.values.reshape(-1,1))\nL, S= rpca.fit(max_iter=1000, iter_print=100)\n","7ac86329":"principalDf = pd.DataFrame(data = L, columns = ['rpca'])\nsensor = 's14'\ndf = pd.merge(left=principalDf, right=X[sensor], left_on=principalDf.index, right_on=X[sensor].index)","5b4719cc":"def scale(A):\n    return (A-np.min(A))\/(np.max(A) - np.min(A))","2769c3b8":"df['sensor_scores'] = S\ndf['sensor_escoragem_escalado'] = scale(S)","b84a2649":"plt.figure(figsize=(12, 8))\nplt.hist(df['sensor_scores'], bins=100);","929f78d4":"plt.figure(figsize=(12, 8))\nplt.hist(df['sensor_escoragem_escalado'], bins=100);","326df21d":"q1_pc1, q3_pc1 = df['sensor_scores'].quantile([0.25, 0.75])\niqr_pc1 = q3_pc1 - q1_pc1\n# Calculate upper and lower bounds for outlier for pc1\nlower_pc1 = q1_pc1 - (1.5*iqr_pc1)\nupper_pc1 = q3_pc1 + (1.5*iqr_pc1)\n    # Filter out the outliers from the pc1\ndf['sensor_anomalia'] = ((df['sensor_scores']>upper_pc1) | (df['sensor_scores']<lower_pc1)).astype('int')","52b4185b":"fig, axes = plt.subplots(nrows=2, figsize=(15,10))\naxes[0].plot(df[sensor], color='blue')\naxes[1].plot(np.array(S).ravel(), color='red')\n\naxes[0].set_title('Dados originais', fontsize=20)\naxes[1].set_title('Score de Anomalia', fontsize=20)\n\n# axes[0].grid()\n# axes[1].grid()\nplt.tight_layout()\nplt.show()","a9b5ba10":"# visualization\na = X.loc[df['sensor_anomalia'] == 1] \n_ = plt.figure(figsize=(18,6))\n_ = plt.plot(df[sensor], color='blue', label='Normal')\n_ = plt.plot(a[sensor], linestyle='none', marker='X', color='red', markersize=12, label='Anomalia')\n_ = plt.xlabel('Series')\n_ = plt.ylabel('leitura do Sensor')\n_ = plt.title('Anomalias do Sensor 1')\n_ = plt.legend(loc='best')\nplt.show();","518efa67":"N = X.shape[0]\nplt.scatter(range(N),df['sensor_escoragem_escalado'][:N].cumsum(),marker='1',label='RPCA ')\nplt.xlabel('Dados do sensor')\nplt.ylabel('Anomalias encontradas')\nplt.legend()\nplt.show()","023af9d9":"#2 -- Distributions of Predicted Probabilities of both classes\nlabels=['Positivo','negativo']\nplt.hist(df[df['sensor_anomalia']==1]['sensor_escoragem_escalado'], density=False, bins=100,\n             alpha=.5, color='green',  label=labels[0])\nplt.hist(df[df['sensor_anomalia']==0]['sensor_escoragem_escalado'], density=False, bins=100,\n             alpha=.5, color='red', label=labels[1])\nplt.axvline(.5, color='blue', linestyle='--', label='Fronteira de Decis\u00e3o')\n# plt.xlim([0,1])\nplt.title('Distribui\u00e7\u00e3o dos Valores', size=13)\nplt.xlabel('Valores normalizados', size=13)\nplt.ylabel('Amostra (normalizados)', size=13)\nplt.legend(loc=\"upper right\")","2f1c5053":"## Ocorr\u00eancias de anomalias no sensor","1fac768a":"Plotando scores normalizados","a8173ef7":"Plotando as anomalias do sensor 14","51216208":"Plotando as anomalias do sensor 14","447a6069":"Distribui\u00e7\u00e3o dos scores das anomalias do sensor","3b9f62df":"Anomaly analysis","b77ba786":"RPCA in single time series","40cd09fe":"## Robust-PCA\n\nA Python implementation of R-PCA using principle component pursuit by alternating directions. The theory and implementation of the algorithm is described here: https:\/\/arxiv.org\/pdf\/0912.3599.pdf (doi > 10.1145\/1970392.1970395)","0fe8db90":"Temos os scores bem ordenados, consideraremos score por volta de 0.8 como anomalia."}}