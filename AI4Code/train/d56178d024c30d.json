{"cell_type":{"60f180f2":"code","7b649563":"code","6269b7ed":"code","4d655455":"code","55ccf1d3":"code","9c583e35":"code","95f27f59":"code","419e5509":"code","923a8bea":"code","f364e4dd":"code","ee2af429":"code","e45e89bb":"code","4d291514":"code","cb712518":"code","68b31216":"code","0d675a89":"code","58cb2beb":"code","6225ea05":"code","7f3d66bc":"markdown","5ae49d9d":"markdown","03d05c39":"markdown","4cd7d6df":"markdown","ce4b46bf":"markdown","afd56abc":"markdown","869475bc":"markdown","14be7f81":"markdown","f723ffcb":"markdown","9442f853":"markdown","016831ab":"markdown","296ec137":"markdown","d8277a04":"markdown"},"source":{"60f180f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport numpy as np # linear algebra\nfrom numpy import random # random choice\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time # for process execution time\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Pytorch Library\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom   torchvision import datasets\nimport torchvision.transforms as transforms\n\n#Matplolib Library\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain_on_gpu = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","7b649563":"batch_size    = 64    # How many samples per batch to load\nepochs        = 15    # How many times will the model train\nlr            = 0.001 # Learning Rate\nvalid_size    = 0.1   # % of the train set that is assigned for the valid_loader\ndropout_rate  = 0.25  # Chance for dropping out neural network units","6269b7ed":"class DatasetMNIST(Dataset):\n    def __init__(self, file_path, shape=(1,28,28), test=False):\n        self.data  = pd.read_csv(file_path)\n        self.shape = shape\n        \n        if test:\n            zeros = np.zeros(self.data.shape[0])\n            self.data.insert(0, 'label', pd.Series(zeros))\n            \n        print(\"Path file: \" + str(file_path))\n        print(self.data.shape)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = self.data.iloc[index, 1:].values\n        image = (image-0.5)\/0.5\n        image = image.astype(np.float32)\n        image = image.reshape(self.shape)\n        label = self.data.iloc[index, 0]\n        \n        image = torch.from_numpy(image).float()\n        \n\n        return image, label","4d655455":"train_data = DatasetMNIST(file_path=\"..\/input\/digit-recognizer\/train.csv\")\ntest_data  = DatasetMNIST(file_path=\"..\/input\/digit-recognizer\/test.csv\", test=True)","55ccf1d3":"# Split to get Train and Validation Data\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# Set Data Loaders\ntrain_loader  = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\nvalid_loader  = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\ntest_loader   = DataLoader(test_data, batch_size=batch_size)\n\nprint(\"Train Data Length: {}\".format(int(len(train_data) - len(train_data)*valid_size)))\nprint(\"Valid Data Length: {}\".format(int(len(train_data) * valid_size)))\nprint(\"Test  Data Length: {}\".format(len(test_data)))","9c583e35":"dataiter       = iter(train_loader)\nimages, labels = dataiter.next()\n\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    ax.set_title(str(labels[idx].item()))","95f27f59":"''' \n    Layers\n    - hi: hidden layer for the i-th fully connect layer\n    - conv_bni: batch normalization for the i-th convolutional layer\n    - out: output -> 10 units\n'''\nclass Net(nn.Module):\n    \n    def __init__(self, h1=950, h2=300, h3=50, out=10, dropout_rate=0.2):\n        super(Net, self).__init__()\n\n        #Convolutional Layers\n        self.conv1 = nn.Conv2d(in_channels=1,out_channels=15,kernel_size=(5,5), padding=(2,2))\n        self.conv2 = nn.Conv2d(in_channels=15,out_channels=60,kernel_size=(5,5),padding=(1,1))\n        \n        self.maxPool  = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n\n        #Fully Connect Layers\n        self.fc1 = nn.Linear(60*6*6, h1)\n        self.fc2 = nn.Linear(h1, h2)\n        self.fc3 = nn.Linear(h2, h3)\n        self.fc4 = nn.Linear(h3, out)\n\n        #Batchnorm Convolutional Layers\n        self.conv_bn1 = nn.BatchNorm2d(15)\n        self.conv_bn2 = nn.BatchNorm2d(60)\n\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, x):\n\n        #Convolutional Layers\n        x = self.conv1(x)\n        x = self.conv_bn1(x)\n        x = self.maxPool(F.relu(x))\n        x = self.dropout(x)\n\n        x = self.conv2(x)\n        x = self.conv_bn2(x)\n        x = self.maxPool(F.relu(x))\n        x = self.dropout(x)\n\n        #Flatten\n        x = x.view(-1, 60*6*6)\n        \n        #Fully Connected Layers\n\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n\n        x = self.fc3(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n\n\n        x = self.fc4(x)\n        x = F.log_softmax(x, dim=1)\n\n        return x\n\nNet()","419e5509":"#Method Xavier\ndef weights_init_xavier_uniform(m):\n    classname = m.__class__.__name__\n    #for every Lineal layer in a model\n    if classname.find('Linear')!=-1:\n        nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0)\n\n#Method He\ndef weights_init_he_uniform(m):\n    classname = m.__class__.__name__\n    #for every Lineal layer in a model\n    if classname.find('Linear')!=-1:\n        nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n        m.bias.data.fill_(0)","923a8bea":"def model_evaluation(net, epochs=10, lr=0.001, optim_method=\"Adam\"):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=lr) if optim_method == \"SGD\" else optim.Adam(net.parameters(),lr=lr)\n\n    #-- Initialize Lists --#\n    train_losses     = []\n    valid_losses     = []\n    train_accuracies = []\n    valid_accuracies = []\n  \n    time_av = 0 # acumulator for training average time\n    for epoch in range(epochs):\n        \n        train_loss     = 0\n        train_accuracy = 0\n\n        ####### TRAINING ########\n        start_time = time.time()\n        net.train()\n        for input, label in train_loader:\n            \n            input, label = input.to(device), label.to(device) # transfer data to current device (cuda\/cpu)\n\n            optimizer.zero_grad()                                               \n            output = net(input)\n            loss   = criterion(output, label)\n            loss.backward()\n            optimizer.step()\n            \n            #-- Accuracy --#\n            ps = torch.exp(output)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == label.view(*top_class.shape)\n\n            train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n            train_loss     += loss.item()\n\n        ######## VALIDATION #######\n        else:\n            valid_loss     = 0\n            valid_accuracy = 0\n            with torch.no_grad():\n                net.eval()\n                for input, label in valid_loader:\n                    \n                    input, label = input.to(device), label.to(device) # transfer data to current device (cuda\/cpu)\n                    \n                    output = net(input)\n                    loss   = criterion(output, label)\n                    \n                    #-- Accuracy --#\n                    ps = torch.exp(output)                    \n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == label.view(*top_class.shape) \n                    \n                    valid_accuracy += torch.mean(equals.type(torch.FloatTensor))\n                    valid_loss     += loss.item()\n            \n            #-- Save Current Accuracies and Losses --#\n            train_losses.append(train_loss\/len(train_loader))\n            valid_losses.append((valid_loss\/len(valid_loader)))\n            train_accuracies.append( (train_accuracy\/len(train_loader)) )\n            valid_accuracies.append( (valid_accuracy\/len(valid_loader)) )\n            \n            exe_time = time.time() - start_time # epoch executed time\n            time_av += exe_time # save current executed time\n            \n            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTraining Accuracy: {:.6f}% \\tValid Accuracy: {:.6f}% \\tExcecuted Time: {:.3f}s'.format(\n              epoch+1,\n              train_loss\/len(train_loader),\n              valid_loss\/len(valid_loader),\n              train_accuracy*100\/len(train_loader),\n              valid_accuracy*100\/len(valid_loader),\n              exe_time\n              ))\n      \n    valid_acc = valid_accuracy \/ len(valid_loader) # process mean accuracy\n\n    return (train_losses, valid_losses, train_accuracies, valid_accuracies, valid_acc, time_av\/epochs)","f364e4dd":"model = Net(dropout_rate=dropout_rate)\nmodel.apply(weights_init_xavier_uniform)\nmodel.to(device) # transfer model to curren device (cuda\/device)\ntrain_losses, valid_losses, train_accuracies, valid_accuracies, valid_acc, time_av = model_evaluation(net=model, epochs=epochs, lr=lr)","ee2af429":"def print_performance(epochs, train_loss, valid_acc, time):\n    print(\"After {} epochs:\".format(epochs))\n    print(\"Train Loss: {:.6f}\".format(train_loss))\n    print(\"Validation Accuracy: {:.6f}%\".format(valid_acc*100))\n    print(\"Average Time: {:.2f}s\".format(time))\n\nprint_performance(epochs, train_losses[-1], valid_acc, time_av)","e45e89bb":"# plot loss and accuracy\ndef plot_loss_accuracy(title_1, title_2, top_list=[], bottom_list=[], x1='accuracy', y1='epoch', x2='accuracy', y2='epoch'):\n    fig = plt.figure(figsize=(18, 6))\n    colors = ['#0027F2','#FF6005','#E42F48 ','#8B44E4 ', '#F8DD00']\n    plt.subplot(1,2,1)\n    labels_loss = []\n    for i, (model_loss, label_loss) in enumerate(top_list, 0):\n        plt.plot(model_loss, color=colors[i])\n        labels_loss.append(label_loss)      \n    plt.title(title_1)\n    plt.ylabel(y1)\n    plt.xlabel(x1)\n    plt.grid(linestyle='--')\n    plt.legend(labels_loss, loc='upper right')\n\n    plt.subplot(1,2,2)\n    labels_accs = []\n    for i, (model_accs, label_accs) in enumerate(bottom_list, 0):\n        plt.plot(model_accs, color=colors[i])\n        labels_accs.append(label_accs)\n    plt.title(title_2)\n    plt.ylabel(y2)\n    plt.xlabel(x2)\n    plt.grid(linestyle='--')\n    plt.legend(labels_accs, loc='lower right')\n    plt.tight_layout()\n\n# plot prediction\ndef plot_prediction(ps):\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(np.arange(10))\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()","4d291514":"loss_list = [\n      (train_losses, 'Training Loss'),\n      (valid_losses, 'Validation Loss')\n]\n\naccuracy_list = [\n      (train_accuracies, 'Training Accuracy'),\n      (valid_accuracies, 'Validation Accuracy')\n]\n\nplot_loss_accuracy(title_1=\"Plot 1.1 - Model Loss\", title_2='Plot 1.2 - Model Accuracy', top_list=loss_list, bottom_list=accuracy_list, x1='epoch', y1='loss', x2='epoch', y2='accuracy')","cb712518":"# Visualize Test Data\nimages,_ = next(iter(test_loader))\nimg = images[random.randint(len(images)-1)]\n\nplt.imshow(np.squeeze(image))","68b31216":"images,_ = next(iter(test_loader))\nimg = images[random.randint(len(images)-1)].reshape(1,1,28,28)\nwith torch.no_grad():\n    logps = model(img.to(device))\n\nps = torch.exp(logps).cpu()\nplot_prediction(ps)","0d675a89":"correct = 0\ntotal = 0\nlabels = []\nwith torch.no_grad():\n    model.eval()\n    for input,_ in test_loader:\n        input = input.to(device)\n        outputs = model(input)\n        _, predicted = torch.max(outputs.data, 1)\n        \n        for i in range(len(predicted)):        \n            labels.append(predicted[i].cpu().numpy())","58cb2beb":"# Save Predictions in data frame\ndf = pd.DataFrame(data={'ImageId':range(1,len(test_data)+1), 'Label':labels}) # submission dataframe\nprint(df)","6225ea05":"df.to_csv(\"submission.csv\", index=False)","7f3d66bc":"# Arquitecture of Model\nLa arquitectura del modelo a entrenar se dise\u00f1\u00f3 usando 2 convoluciones y 4 capas lineales completamente conectadas.\nEl modelo con mejor rendimiento, obtenido a trav\u00e9s de la experimentaci\u00f3n, se presenta a continuaci\u00f3n.","5ae49d9d":"## Final Prediction","03d05c39":"# Initialization Methods\nDurante la experimentaci\u00f3n se probaron 2 m\u00e9todos de inicializaci\u00f3n, de los cuales se termin\u00f3 usando la inicializaci\u00f3n por el m\u00e9todo de *xavier uniform*","4cd7d6df":"# Train the Model\nSe defini\u00f3 una funci\u00f3n de entrenamiento para as\u00ed poder ser utilizada con diversos modelos\n__Par\u00e1metros:__\n1. net: Modelo Predictivo\n2. epochs: (int) n\u00famero de \u00e9pocas para entrenar\n3. lr: (float) coeficiente de aprendizaje\n4. optim_method: (string - 'Adam') m\u00e9todo de optimizaci\u00f3n de los hiperpar\u00e1metros","ce4b46bf":"# Hyperparameters\nAqu\u00ed se establece la definici\u00f3n de los par\u00e1metros generales del entrenamiento para mayor conveniencia en la configuraci\u00f3n del modelo","afd56abc":"# Final Test\nA partir de aqu\u00ed se trabaja con el Test Loader, para realizar las predicciones con valores reales, mostrar la efectividad del modelo y guardar la informaci\u00f3n para ser enviada","869475bc":"# Pre-processing Data\n\nPara la carga de los datasets se define una clase llamada *DatasetMNIST*, del mismo tipo *torch.utils.data.Dataset* donde se lee un archivo csv en la ruta indicada.\nLa funci\u00f3n *__getitem__* es usada por los iteradores, de forma que al obtener los datos estos pasan por un proceso de transformaci\u00f3n para ser enviados de tipo *FloatTensor*","14be7f81":"# Visualize Data","f723ffcb":"## Saving Predicted Values\nLos datos predecidos por el modelo son guardados en una lista para luego ser pasados al archivo csv que ser\u00e1 enviado","9442f853":"# Import Libraries","016831ab":"## Print Model Performance","296ec137":"# <center>DIGIT RECONIZER - MNIST COMPETITION<\/center>\n### <center>Project 1 - Emerging Computing - UNIMET<\/center>\n\n***\n**Profesor:** Nicolas Araque Volk\n\n**Participants:**\n-    Marcos De Andrade Rozic | **e-mail:** marcos.deandrade@correo.unimet.edu.ve\n-    Samuel Boada Calderon   | **e-mail:** samuel.boada@correo.unimet.edu.ve","d8277a04":"# Plot Loss & Accuracy\nPara el an\u00e1lisis del modelo se grafic\u00f3 el comportamiento de la p\u00e9rdida y la exactitud para determinar a trav\u00e9s de esta si se presentaba un comportamiento de overfitting o underfitting para, de esta forma, poder ajustar los par\u00e1metros y el dise\u00f1o del modelo"}}