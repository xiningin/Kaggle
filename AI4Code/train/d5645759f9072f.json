{"cell_type":{"7b69d586":"code","7b868a7f":"code","eef2d435":"code","b0c4451c":"code","49ebdae1":"code","059e6587":"code","5b0858a1":"code","63ae844b":"code","17693f3b":"code","f8d64840":"code","4aae395c":"code","aea36a18":"code","28bbcb75":"markdown","746fda5d":"markdown","75b50f47":"markdown","1c2daa5b":"markdown","19918f40":"markdown","0f1a04c9":"markdown","1b5b1014":"markdown","c95c5282":"markdown","91dbc0b3":"markdown","4b28ca4e":"markdown"},"source":{"7b69d586":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","7b868a7f":"datagen = ImageDataGenerator(\n        rotation_range = 40,        # random rotation angle\n        width_shift_range=0.2,      # random horizontal translation\n        height_shift_range = 0.2,   # random vertical translation\n        rescale = 1.\/255,           # normalization\n        shear_range = 0.2,          # random clipping\n        zoom_range = 0.2,           # random amplification\n        horizontal_flip = True,     # flip horizontally\n        fill_mode='nearest'         # fill style\n)","eef2d435":"# load image\nimg = load_img('..\/input\/cat-and-dog\/training_set\/training_set\/cats\/cat.1.jpg')\nx = img_to_array(img)\nprint(x.shape)\n\n# we need add new dimention to the array\nx = x.reshape((1,) + x.shape)\nprint(x.shape)","b0c4451c":"'''\ni = 0\n# generate 20 images\n# flow: random generate 20 images\nfor batch in datagen.flow(x, batch_size=1, save_to_dir='temp', save_prefix='cat', save_format='jpeg'):\n    # 20 times\n    i += 1\n    if i > 20:\n        break\n        \n'''","49ebdae1":"import numpy as np\nfrom keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os","059e6587":"model = Sequential()\nmodel.add(Convolution2D(input_shape=(150,150,3), filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(Convolution2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n\nmodel.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n\nmodel.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.5))\n# final result is 2 categories \nmodel.add(Dense(2,activation='softmax'))\n\nadam = Adam(lr=1e-4)\n\nmodel.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","5b0858a1":"from keras.utils.vis_utils import plot_model\nimport matplotlib.pyplot as plt\n\nplot_model(model,to_file='model.png',show_shapes=True,show_layer_names='False',rankdir='TB')\nplt.figure(figsize=(20,20))\nimg = plt.imread('model.png')\nplt.imshow(img)\nplt.axis('off')\nplt.show()","63ae844b":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True\n        ) \n\n# The test set only needs normalization\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","17693f3b":"batch_size = 32\n\n# this size here \uff08150,150\uff09 corresponds to the input size in the convolutional neural network\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/cat-and-dog\/training_set\/training_set',\n        target_size=(150,150),\n        batch_size=batch_size\n        )\n\ntest_generator = test_datagen.flow_from_directory(\n        '..\/input\/cat-and-dog\/test_set\/test_set',\n        target_size=(150,150),\n        batch_size=batch_size\n        )","f8d64840":"totalFileCount_1 = sum([len(files) for root,dirs, files in os.walk('..\/input\/cat-and-dog\/training_set\/training_set')])\ntotalFileCount_1","4aae395c":"totalFileCount_2 = sum([len(files) for root,dirs, files in os.walk('..\/input\/cat-and-dog\/test_set\/test_set')])\ntotalFileCount_2","aea36a18":"model.fit_generator(\n        train_generator,\n        steps_per_epoch=totalFileCount_1\/batch_size,\n        epochs=50,\n        validation_data=test_generator,\n        validation_steps=totalFileCount_2\/batch_size\n        )\n\nmodel.save('CNN1.h5')","28bbcb75":"Define CNN model","746fda5d":"- rotation_range:0 ~ 180 degrees, used to specify the angle of randomly selected pictures\n- width_shift & height_shift\uff1aSpecify the degree of random movement in the horizontal and vertical directions. \n- shear_range:For the degree of shear transformation, refer to shear transformation\n- rescale\uff1aThe rescale value will be multiplied by the whole image before performing other processing. Our image is an integer from 0 to 255 in RGB channel. This operation may make the image value too high or too low, so we set this value as a number between 0 and 1.\n\n- zoom_range:Used for random amplification\n- horizontal_flip:Flip the image horizontally randomly\uff08Does not affect the meaning of the picture itself\uff09\n- fill_mode:How to fill new pixels when pixel filling is needed, such as rotation, horizontal and vertical shift","75b50f47":"- You can randomly generate a picture for many times, and you can save it in your local file for viewing. When you have a small number of samples, you can use this method to help you increase the number of training sets.\n\n![image.png](attachment:image.png)","1c2daa5b":"## Introduction of image data preprocessing","19918f40":"generate train data sets and test data sets","0f1a04c9":"## Cat and dog classification by using CNN model","1b5b1014":"Count the number of train_set file","c95c5282":"Load librarys ","91dbc0b3":"count the number of test_set file","4b28ca4e":"Model visualization"}}