{"cell_type":{"6b71e9ad":"code","e5ad6546":"code","70b374e4":"code","d969b77d":"code","9be11304":"code","5601b5a6":"code","9b4ee2ca":"code","9121df88":"markdown","1d934e57":"markdown"},"source":{"6b71e9ad":"import torch\ntorch.__version__, torch.version.cuda  # 1.9, 10.2","e5ad6546":"%%time\n%%capture\n#@title install dependencies\n# manual pip installation is faster than conda\n!pip install trimesh==3.9.33 einops==0.3.2 scipy==1.5.2 \\\n             siren-pytorch==0.1.5 usd-core==21.8 \\\n             git+https:\/\/github.com\/openai\/CLIP.git@04f4dc2ca1ed0acc9893bd1a3b526a7e02c4bb10 \\\n             git+https:\/\/github.com\/NVIDIAGameWorks\/kaolin@838d982cb0765de75d3c5de15083d80b849fa737","70b374e4":"#@title get text2mesh\n!git clone https:\/\/github.com\/threedle\/text2mesh\n%cd text2mesh","d969b77d":"#@title settings\nobj_path = \"data\/source_meshes\/person.obj\"  #@param {type: \"string\"}\nn_iter = 750  #@param {type: \"integer\"}\nprompt = \"a 3D rendering of a ninja in unreal engine\"\noutput_dir = \".\/results\"","9be11304":"#@markdown WIP: you can look at the intermediate results in the text2mesh\/results directory\n!python main.py --run branch \\\n                --obj_path {obj_path} \\\n                --output_dir {output_dir} \\\n                --prompt \"{prompt}\" \\\n                --sigma 12.0  --clamp tanh --n_normaugs 4 --n_augs 1 --normmincrop 0.1 --normmaxcrop 0.4 \\\n                --geoloss --colordepth 2 --normdepth 2 --frontview --frontview_std 4 --clipavg view \\\n                --lr_decay 0.9 --clamp tanh --normclamp tanh  --maxcrop 1.0 --save_render --seed 29 \\\n                --n_iter {n_iter}  --learning_rate 0.0005 --normal_learning_rate 0.0005 --standardize --no_pe --symmetry --background 1 1 1","5601b5a6":"#@export the results\nimport matplotlib.pyplot as plt\nimport importlib\nimport PIL\nimportlib.reload(PIL.TiffTags)\nimport cv2\nimport os\n\n\nframes = []\nfor i in range(0, n_iter, 100):\n    img = cv2.imread(os.path.join(output_dir, f\"iter_{i}.jpg\"))\n    frames.append(img)\n    plt.figure(figsize=(20, 4))\n    plt.axis(\"off\")\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.show()","9b4ee2ca":"#@title create video\nfrom IPython.display import display, HTML\nfrom base64 import b64encode\nfrom tqdm.auto import tqdm\nimport cv2\nfps = 2\n\n\nvideo = cv2.VideoWriter(\"video.avi\", 0, fps, frames[0].shape[:2][::-1]);\nfor im in tqdm(frames):\n    video.write(im)\nvideo.release()\n!ffmpeg -y -i video.avi -pix_fmt yuv420p video.mp4 2> \/dev\/null\nmp4 = open(\"video.mp4\", \"rb\").read()\ndata_url = \"data:video\/mp4;base64,\" + b64encode(mp4).decode()\ndisplay(HTML(f\"\"\"\n<video width={frames[0].shape[1]} controls>\n      <source src=\"{data_url}\" type=\"video\/mp4\">\n<\/video>\n\"\"\"))","9121df88":"# text2mesh\n\nPort of [text2mesh by threedle](https:\/\/github.com\/threedle\/text2mesh). No custom patches.\n\nNote: this Kaggle notebook includes CUDA version metadata so it should either be copied with Copy&Edit on Kaggle or used in a CUDA 10.2 environment.","1d934e57":"installation, takes 10-15 minutes"}}