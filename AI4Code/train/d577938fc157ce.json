{"cell_type":{"c7d63c66":"code","7487af48":"code","f88b5d1d":"code","047c4464":"code","85f511f1":"code","43d5d1fa":"code","6acf36fe":"code","c7e6e565":"code","837a9a3c":"code","890e2c02":"code","fc4cfcbd":"code","8bdb5d38":"code","c654c697":"code","839aac5f":"code","f88a1627":"code","1aacbf41":"code","d53e28cf":"code","01f4d0d8":"code","b15b1e61":"code","d0a18700":"code","7fba1619":"code","98323c1f":"code","16fdfc73":"code","7ffab02d":"code","ace3c709":"markdown","0b82ab20":"markdown","136d172b":"markdown","4d0b0078":"markdown","23665ac2":"markdown","85c5079a":"markdown","a774682e":"markdown"},"source":{"c7d63c66":"import os\nimport pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nfrom PIL import Image\nfrom glob import glob\nfrom skimage.io import imread\nfrom os import listdir\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nimport cv2\nimport copy\nfrom random import shuffle\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom imblearn.metrics import sensitivity_specificity_support\nfrom imgaug import augmenters as iaa\nimport imgaug as ia\nimport tensorflow as tf\n\n# import numpy as np\n# import matplotlib.pyplot as plt\nfrom itertools import cycle\n\n# from sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import label_binarize\n# from sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.metrics import roc_auc_score\n\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.utils.vis_utils import plot_model\nfrom keras.optimizers import SGD,Adam\nimport numpy as np\n\n# from keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout,concatenate\nfrom keras.layers import Conv2D, MaxPooling2D, Input, Flatten, BatchNormalization\nfrom keras.layers import Input\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard,CSVLogger\n# import tools\nimport gc\nfrom sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix\nfrom keras.models import Model\nimport keras\n# import channel_attention","7487af48":"folder = os.listdir(\"..\/input\/lung-colon-normal\/trainable_normal\")\nprint(folder)","f88b5d1d":"base_path = \"..\/input\/lung-colon-normal\/trainable_normal\"\ntotal_images = 0\nimage_class =[]\nfor n in range(len(folder)):\n  image_path = os.path.join(base_path, folder[n]) \n  print(image_path)\n  # class_path = patient_path + \"\/\" + str(c) + \"\/\"\n  subfiles = os.listdir(image_path)\n  print(len(subfiles))\n  image_class.append(len(subfiles))\n  total_images += len(subfiles)\nprint(\"The number of total images are:{}\".format(total_images))  \nprint(image_class)","047c4464":"data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"path\", \"target\"])\n\nk = 0\nfor n in range(len(folder)):\n    class_id = folder[n]\n    final_path = os.path.join(base_path,class_id) \n    subfiles = os.listdir(final_path)\n    for m in range(len(subfiles)):\n      image_path = subfiles[m]\n      data.iloc[k][\"path\"] = os.path.join(final_path,image_path)\n      data.iloc[k][\"target\"] = class_id\n      k += 1  \n\ndata.head()","85f511f1":"data['target'].unique()","43d5d1fa":"# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ndata['target_label'] = labelencoder.fit_transform(data['target'])\ndata = data.sample(frac=1).reset_index(drop=True)\ndata","6acf36fe":"data.iloc[1000,:]","c7e6e565":"data.groupby(\"target_label\").size()","837a9a3c":"# cancer_perc = data.groupby(\"patient_id\").target.value_counts()\/ data.groupby(\"patient_id\").target.size()\n# cancer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.distplot(data.groupby(\"target_label\").size(), ax=ax[0], color=\"Orange\", kde=False)\nax[0].set_xlabel(\"Number of images\")\nax[0].set_ylabel(\"Frequency\");\n\nsns.countplot(data.target, palette=\"Set2\", ax=ax[1]);\nax[1].set_xlabel(\"Names of Class\")\nax[1].set_title(\"Data Distribution\");","890e2c02":"data.info()","fc4cfcbd":"data.describe()","8bdb5d38":"data.target_label","c654c697":"X = data.path\ny = data.target_label\nX_train, X_test_sub ,y_train,y_test_sub= train_test_split(X,y, test_size=0.3, random_state=0,shuffle = True)\nprint(X_train.shape)\nprint(X_test_sub.shape)","839aac5f":"X_test,X_valid,y_test,y_valid = train_test_split(X_test_sub, y_test_sub, test_size=0.5, random_state=0 , shuffle =False)\nprint(X_test.shape)\nprint(X_valid.shape)","f88a1627":"fig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(y_train, ax=ax[0], palette=\"Reds\")\nax[0].set_title(\"Train data\")\nsns.countplot(y_valid, ax=ax[1], palette=\"Blues\")\nax[1].set_title(\"Dev data\")\nsns.countplot(y_test, ax=ax[2], palette=\"Greens\");\nax[2].set_title(\"Test data\");","1aacbf41":"data.path.values","d53e28cf":"target_label_map = {k:v for k,v in zip(data.path.values,data.target_label.values)}","01f4d0d8":"def chunker(seq, size):\n    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\ndef get_seq():\n    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n    seq = iaa.Sequential(\n        [\n            # apply the following augmenters to most images\n            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n            iaa.Flipud(0.2), # vertically flip 20% of all images\n            sometimes(iaa.Affine(\n                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n                rotate=(-10, 10), # rotate by -45 to +45 degrees\n                shear=(-5, 5), # shear by -16 to +16 degrees\n                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n            )),\n            # execute 0 to 5 of the following (less important) augmenters per image\n            # don't execute all of them, as that would often be way too strong\n            iaa.SomeOf((0, 5),\n                [\n                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n                    iaa.OneOf([\n                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n                    ]),\n                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n                    # search either for all edges or for directed edges,\n                    # blend the result with the original image using a blobby mask\n                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n                    ])),\n                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n                    iaa.OneOf([\n                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n                    ]),\n                    iaa.Invert(0.01, per_channel=True), # invert color channels\n                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n                    # either change the brightness of the whole image (sometimes\n                    # per channel) or change the brightness of subareas\n                    iaa.OneOf([\n                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n                        iaa.FrequencyNoiseAlpha(\n                            exponent=(-1, 0),\n                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n                            second=iaa.ContrastNormalization((0.9, 1.1))\n                        )\n                    ]),\n                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n                ],\n                random_order=True\n            )\n        ],\n        random_order=True\n    )\n    return seq\n\ndef data_gen(list_files, target_label_map, batch_size, augment=False):\n    seq = get_seq()\n    while True:\n        # shuffle(list_files)\n        for batch in chunker(list_files, batch_size):\n            X = [cv2.resize(cv2.imread(x),(224,224),interpolation=cv2.INTER_CUBIC) for x in batch]\n            # for x in X:\n            #   X.append(cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC))\n            # X = [cv2.resize(x,(224,224,3)) for x in X]\n            Y = [target_label_map[x] for x in batch]\n            # print(Y)\n            Y = to_categorical(Y, num_classes = 5)\n            # print(Y)\n            if augment:\n                X = seq.augment_images(X)\n            X = [preprocess_input(x) for x in X]\n                \n            yield np.array(X), np.array(Y)\n    ","b15b1e61":"adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0009)\nsgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n\ninput_tensor = Input(shape=(224,224, 3))\n#backbone\n\nbase_model = tf.keras.applications.ResNet50(input_tensor= input_tensor, weights='imagenet', include_top=False)\nbase_output = base_model.output\nprint(base_output.shape)\n# channel-attention\n# x = squeeze_excitation_layer(base_output, 2048, ratio=4, concate=False)\n# x = BatchNormalization()(x)\n\n# #concat\n# x = concatenate([base_output, x], axis=3)\n# spp\n\ngap = GlobalAveragePooling2D()(base_output)\nx = Flatten()(base_output)\nx = concatenate([gap,x])\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\npredict = Dense(5, activation='softmax')(x)\nmodel = Model(inputs=input_tensor, outputs=predict)\n\nfor layer in (base_model.layers):\n    layer.trainable = False\n\n# for l in model.layers:\n#   print(l.name)","d0a18700":"model.compile(optimizer=adam,\n              \n                  loss='categorical_crossentropy',\n                  metrics=[keras.metrics.categorical_accuracy])\nmodel.summary()","7fba1619":"!pip install ipython-autotime\n \n%load_ext autotime","98323c1f":"batch_size=32\nhistory = model.fit_generator(\n    data_gen(X_train, target_label_map, batch_size, augment=True),\n    validation_data=data_gen(X_valid, target_label_map, batch_size),\n    epochs=50, \n    verbose = 1,\n    #callbacks=callbacks,\n    steps_per_epoch=  int(len(X_train)\/\/batch_size),\n    validation_steps= int(len(X_valid)\/\/ batch_size)\n)","16fdfc73":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, save_model, load_model\n\nfilepath = '.\/'","7ffab02d":"tf.keras.models.save_model(\n    model,\n    filepath,\n    overwrite=True,\n    include_optimizer=True,\n    save_format=None,\n    signatures=None,\n    options=None\n)","ace3c709":"cm = confusion_matrix(Y_true, Y_pred_classes)\n\nprint(cm)\n\n\nclssrep = classification_report(Y_true, Y_pred_classes)\n    # CLssrep.append(clssrep)\nprint(clssrep)\n\n\ndf_cm = pd.DataFrame(cm, index = folder, columns= folder )\nfig = plt.figure(figsize = (10,7))\n\nheatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize= 14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize= 14)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nclassification_accuracy = accuracy(cm)\nprint(\"Classification Accuracy:{0:0.6f}\".format(classification_accuracy))\n\n[Precision,Sensitivity,F1_score,_] = precision_recall_fscore_support(Y_true, Y_pred_classes, average='weighted')\n[_, Specificity,_] = sensitivity_specificity_support(Y_true, Y_pred_classes, average='weighted')\n\n\n\n    \nprint('Precision : {0:0.6f}'.format(Precision))\nprint('Sensitivity : {0:0.6f}'.format(Sensitivity))\nprint('Specificity : {0:0.6f}'.format(Specificity))\nprint('F1_score : {0:0.6f}'.format(F1_score))","0b82ab20":"p1 ,p2 = data_gen1(X_valid,target_label_map,3750) \nscore = model.evaluate(p1,p2, verbose=0)\nprint('Model Accuracy:', score[1],'\\n')","136d172b":"y_test = to_categorical(Y_true, num_classes = 5)\ny_pred = to_categorical(Y_pred_classes ,num_classes =5)\n# print(y_test)\n# print(y_pred)\nn_classes =5\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i],y_pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    # print(roc_auc[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\nlw = 2\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr \/= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(figsize =(12,10))\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","4d0b0078":"X_test_final,y_test_final = data_gen1(X_test,target_label_map,3500)\nprint(y_test_final.shape) \ny_pred = model.predict(X_test_final)\nprint(y_pred.shape)\nY_pred_classes = np.argmax(y_pred,axis=1) \nprint(Y_pred_classes.shape)\nY_true = np.argmax(y_test_final,axis=1)\nprint(Y_true.shape) \n","23665ac2":"def accuracy(confusion_matrix):\n    diagonal_sum = confusion_matrix.trace()\n    sum_of_all_elements = confusion_matrix.sum()\n    return diagonal_sum \/ sum_of_all_elements ","85c5079a":"# def plot_learning_curve(history):\nplt.figure(figsize=(16,6))\nplt.subplot(1,2,1)\nplt.plot(history.history['categorical_accuracy'])\nplt.plot(history.history['val_categorical_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\n    # plt.savefig('.\/accuracy_curve.png')\n    #plt.clf()\n    # summarize history for loss\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\n# plt.savefig('.\/loss_curve.png')","a774682e":"def data_gen1(list_files, target_label_map, batch_size, augment=False):\n    seq = get_seq()\n    while True:\n        # shuffle(list_files)\n        for batch in chunker(list_files, batch_size):\n          X = [cv2.resize(cv2.imread(x),(224,224),interpolation=cv2.INTER_CUBIC) for x in batch]\n            # for x in X:\n            #   X.append(cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC))\n            # X = [cv2.resize(x,(224,224,3)) for x in X]\n          Y = [target_label_map[x] for x in batch]\n            # print(Y)\n          Y = to_categorical(Y, num_classes = 5)\n            # print(Y)\n          if augment:\n            X = seq.augment_images(X)\n          X = [preprocess_input(x) for x in X]\n                \n          return np.array(X), np.array(Y)"}}