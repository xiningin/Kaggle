{"cell_type":{"88db4cb2":"code","90f7c9d2":"code","08e76cae":"code","0e5cc489":"code","2045d089":"code","271b4993":"code","42344611":"code","5b769ad0":"code","76941825":"code","83643cae":"code","0ab33f33":"code","b2fc0783":"code","65ab91ee":"code","42381ee5":"code","472c4fea":"markdown","58fc50fb":"markdown","b8c0b46d":"markdown","c3078c64":"markdown"},"source":{"88db4cb2":"# Code you have previously used to load data\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\n\n\n\n# Path of the file to read. We changed the directory structure to simplify submitting to a competition\niowa_file_path = '..\/input\/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\n","90f7c9d2":"iowa_target = home_data.SalePrice\niowa_predictors = home_data.drop(['SalePrice'], axis=1)\n\n# For the sake of keeping the example simple, we'll use only numeric predictors. \niowa_numeric_predictors = iowa_predictors.select_dtypes(exclude=['object'])\n\niowa_numeric_predictors.head()","08e76cae":"#Load test data and do one hot encoding on both datasets before imputations\n# path to file you will use for predictions\ntest_data_path = '..\/input\/test.csv'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\n\n#one hot encoding\nohe_training = pd.get_dummies(iowa_predictors)\nohe_test = pd.get_dummies(test_data)\ncur_train, cur_test = ohe_training.align(ohe_test, join='inner', axis=1)","0e5cc489":"from sklearn.impute import SimpleImputer\n\n#new_data = iowa_numeric_predictors.copy()\n#new_data = iowa_predictors.copy()\nnew_data = cur_train.copy()\n\n# make new columns indicating what will be imputed\ncols_with_missing = list(col for col in new_data.columns \n                                 if new_data[col].isnull().any())\nfor col in cols_with_missing:\n    print(col)\n    new_data[col + '_was_missing'] = new_data[col].isnull()\n\nmy_imputer = SimpleImputer()\nnew_data_imputed = pd.DataFrame(my_imputer.fit_transform(new_data))\nnew_data_imputed.columns = new_data.columns\n#new_data.columns","2045d089":"#tester code block. delete later\ncur_test.columns","271b4993":"# path to file you will use for predictions\n#test_data_path = '..\/input\/test.csv'\n\n# read test data file using pandas\n#test_data = pd.read_csv(test_data_path)\n\n#new_test = test_data[iowa_numeric_predictors.columns]\nnew_test = cur_test\n\nfor col in cols_with_missing:\n    print(col)\n    new_test[col + '_was_missing'] = new_test[col].isnull()\n\n#new_test.head()\n# Imputation\n#my_imputer = SimpleImputer()\nnew_test_imput = pd.DataFrame(my_imputer.fit_transform(new_test))\nnew_test_imput.columns = new_test.columns\ntest_X = new_test_imput\n","42344611":"#One hot encoding while aligning the train and test datas\n#one_hot_encoded_training_predictors = pd.get_dummies(new_data_imputed)\n#one_hot_encoded_test_predictors = pd.get_dummies(test_X)\n#final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n#                                                                    join='left', \n#                                                                    axis=1)\nfinal_train = new_data_imputed\nfinal_test = test_X\n#list(final_train.columns)","5b769ad0":"X = new_data_imputed\ny = iowa_target\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n#list(train_X.columns)","76941825":"#One hot encoding just for testing purposes\n#one_hot_encoded_training_predictors = pd.get_dummies(train_X)\n#one_hot_encoded_test_predictors = pd.get_dummies(val_X)\n#train_X, val_X = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n#                                                                    join='left', \n#                                                                    axis=1)","83643cae":"from xgboost import XGBRegressor\n\n#note to self: n_estimators=140 was earlier optimized\niowa_model_xgb = XGBRegressor(n_estimators=250)\n#iowa_model_xgb.fit(train_X, train_y, early_stopping_rounds=20, \n#                   eval_set=[(val_X, val_y)], verbose=True)\niowa_model_xgb.fit(train_X, train_y)\n\npredictions_xgb = iowa_model_xgb.predict(val_X)\nxgb_val_mae = mean_absolute_error(predictions_xgb, val_y)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(xgb_val_mae))","0ab33f33":"# Specify Model\niowa_model = DecisionTreeRegressor(random_state=1)\n# Fit Model\niowa_model.fit(train_X, train_y)\n\n# Make validation predictions and calculate mean absolute error\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n# Using best value for max_leaf_nodes\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\niowa_model.fit(train_X, train_y)\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n# Define the model. Set random_state to 1\nrf_model = RandomForestRegressor(random_state=1, n_estimators=100)\nrf_model.fit(train_X, train_y)\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n","b2fc0783":"#using support vector regression\n#clf = SVR()\n#clf.fit(train_X, train_y)\n#svm_pred = clf.predict(val_X)\n#svm_mae = mean_absolute_error(svm_pred, val_y)\n#print(svm_mae)","65ab91ee":"# To improve accuracy, create a new Random Forest model which you will train on all training data\n#rf_model_on_full_data = RandomForestRegressor(random_state=1, n_estimators=100)\nrf_model_on_full_data = XGBRegressor(n_estimators=250)\n\n# fit rf_model_on_full_data on all data from the \nrf_model_on_full_data.fit(final_train, y)\n","42381ee5":"#Making predictions\ntest_preds = rf_model_on_full_data.predict(test_X)\n\n# The lines below shows you how to save your data in the format needed to score it in the competition\noutput = pd.DataFrame({'Id': test_data.Id,\n                       'SalePrice': test_preds})\n\noutput.to_csv('submission.csv', index=False)","472c4fea":"# Creating a Model For the Competition\n\nBuild a Random Forest model and train it on all of **X** and **y**.  ","58fc50fb":"Below code loads the train file and the test file.","b8c0b46d":"### This kernel is being written and constructed as a part of the Kaggle course on Machine Learning. It improvises on the results of random forest regression.","c3078c64":"# Make Predictions\nRead the file of \"test\" data. And apply your model to make predictions"}}