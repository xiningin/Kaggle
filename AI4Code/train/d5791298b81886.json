{"cell_type":{"14157763":"code","dee83750":"code","9b4e4f87":"code","cfe34feb":"code","22de1366":"code","e6f825df":"code","fc882fe9":"code","1c2819b2":"code","ff3323f6":"code","a377e856":"code","1a6f439f":"code","0622ed69":"code","bd03e9d6":"code","c337452e":"code","8023bcdc":"code","3e6226c7":"code","f13cd210":"code","92c2fee7":"code","ee12a152":"code","7885a49e":"code","2c59c38e":"code","a4d70b7f":"code","76ddfe73":"code","4b515f55":"code","22320b37":"code","ae11f24b":"code","a13fd2fb":"code","8eec16e9":"code","fba61b0e":"code","26f073e1":"code","e91e9404":"code","a37d4f17":"code","aacc9a19":"code","eacd1911":"code","cb8c61f5":"code","cb60d022":"code","e97f70a6":"code","11348ff9":"code","9fbbcbd8":"code","c799ebff":"code","6a4321fe":"code","13478f73":"code","f7d785de":"code","d06fbc56":"code","b8e709ec":"code","da0e2cc5":"code","3e2c1f59":"code","0169b33a":"code","0cd230f1":"code","0c3fdc46":"code","bacfab4b":"code","e0a0782d":"code","0d01101c":"code","6ac8198f":"code","4cdebd90":"code","385943fa":"code","f4e66db4":"code","be11cfb1":"markdown","19dea58e":"markdown","e474e05b":"markdown","155fca25":"markdown","fdec0f5f":"markdown","994f4eb8":"markdown","cd6ef7a8":"markdown"},"source":{"14157763":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math as math\nimport datetime as dt\nimport sklearn\nimport plotly\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly import __version__\nprint(__version__)\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('precision', 5)\npd.options.display.float_format = '{:20,.2f}'.format\nnp.set_printoptions(suppress =True) \n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport tqdm\nfrom tqdm import tqdm\n","dee83750":"pd.read_csv('..\/input\/elo-merchant-category-recommendation\/historical_transactions.csv', nrows=50).head(5)","9b4e4f87":"pd.read_csv('..\/input\/elo-merchant-category-recommendation\/merchants.csv', nrows=50).head(3)","cfe34feb":"pd.read_csv('..\/input\/elo-merchant-category-recommendation\/new_merchant_transactions.csv', nrows=50).head(3)","22de1366":"pd.read_csv('..\/input\/elo-merchant-category-recommendation\/train.csv', nrows=50).head(3)","e6f825df":"pd.read_csv('..\/input\/elo-merchant-category-recommendation\/test.csv', nrows=50).head(3)","fc882fe9":"pd.read_csv('..\/input\/elo-merchant-category-recommendation\/sample_submission.csv', nrows=50).head(3)","1c2819b2":"pd.read_excel('..\/input\/elo-merchant-category-recommendation\/Data_Dictionary.xlsx')","ff3323f6":"pd.read_csv('..\/input\/ecommerce-data\/data.csv', nrows=50).head(3)","a377e856":"# df_train = pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/train.csv\", nrows = 10000)\n# df_test = pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/test.csv\", nrows = 10000)\n# df_historical =pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/historical_transactions.csv\",parse_dates=['purchase_date'])\n# df_new =pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/new_merchant_transactions.csv\",parse_dates=['purchase_date'], nrows = 10000)","1a6f439f":"df_train = pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/test.csv\")\ndf_historical =pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/historical_transactions.csv\",parse_dates=['purchase_date'])\ndf_new =pd.read_csv(\"..\/input\/elo-merchant-category-recommendation\/new_merchant_transactions.csv\",parse_dates=['purchase_date'])","0622ed69":"df_historical.head(2)","bd03e9d6":"len(df_historical.card_id.unique())","c337452e":"df_new.head(2)","8023bcdc":"df_historical=df_historical.loc[df_historical.authorized_flag==\"Y\",]\ndf_historical.purchase_amount += 0.75\ndf_new.purchase_amount += 0.75","3e6226c7":"def groupby_mean(x):\n    return x.mean()\n\ndef groupby_count(x):\n    return x.count()\n\ndef purchase_duration(x):\n    return (x.max() - x.min()).days\n\ndef avg_frequency(x):\n    return (x.max() - x.min()).days\/x.count()\n\ngroupby_mean.__name__ = 'avg'\ngroupby_count.__name__ = 'count'\npurchase_duration.__name__ = 'purchase_duration'\navg_frequency.__name__ = 'purchase_frequency'\n\ndef get_max(cols):\n    return max(cols[0],cols[1])","f13cd210":"df_Agg_Monetary = df_historical.groupby('card_id').agg({'purchase_amount':sum})\ndf_Agg_Monetary.columns = ['Monetary']\nprint(df_Agg_Monetary.shape)\ndf_Agg_Monetary.head()","92c2fee7":"df_Agg_Frequency = df_historical.groupby('card_id').agg({'card_id': groupby_count,'purchase_date': groupby_count})\ndf_Agg_Frequency['Frequency'] = df_Agg_Frequency[['card_id','purchase_date']].apply(get_max,axis = 1)\nprint(df_Agg_Frequency.shape)\ndf_Agg_Frequency.head()","ee12a152":"table_max_date = max(df_historical['purchase_date'])\nprint(table_max_date)\n\n# x = df_historical['purchase_date'][0]\n# (table_max_date-x).days","7885a49e":"df_Agg_Recency = df_historical.groupby(['card_id']).agg({'purchase_date':max})\ndf_Agg_Recency['Recency'] = df_Agg_Recency['purchase_date'].apply(lambda x:(table_max_date-x).days)\nprint(df_Agg_Recency.shape)\ndf_Agg_Recency.head(10)","2c59c38e":"df_rfm = pd.merge(pd.merge(df_Agg_Recency, df_Agg_Frequency, left_index=True, right_index=True), \n                           df_Agg_Monetary, left_index=True, right_index=True)\ndf_rfm.drop(columns=['purchase_date_x', 'card_id', 'purchase_date_y'], inplace=True)\ndf_rfm.head(5)","a4d70b7f":"plt.figure(figsize=(12,8))\ncounts, bin_edges = np.histogram(np.log1p(df_rfm['Recency']), bins=10, density = True)\npdf = counts\/(sum(counts))\nprint(pdf);\nprint(bin_edges);\ncdf = np.cumsum(pdf)\nplt.plot(bin_edges[1:],pdf);\nplt.plot(bin_edges[1:], cdf)\nplt.xlabel('log_Recency', fontsize=12)\nplt.ylabel('Percentage', fontsize=12)\nplt.title('Recency Cumulative Frequency Distribution',fontsize=15)","76ddfe73":"plt.figure(figsize=(12,8))\ncounts, bin_edges = np.histogram(np.log1p(df_rfm['Frequency']), bins=10, density = True)\npdf = counts\/(sum(counts))\nprint(pdf);\nprint(bin_edges);\ncdf = np.cumsum(pdf)\nplt.plot(bin_edges[1:],pdf);\nplt.plot(bin_edges[1:], cdf)\nplt.xlabel('log_Frequency', fontsize=12)\nplt.ylabel('Percentage', fontsize=12)\nplt.title('Frequency Cumulative Frequency Distribution',fontsize=15)","4b515f55":"plt.figure(figsize=(12,8))\ncounts, bin_edges = np.histogram(np.log1p(df_rfm['Monetary']), bins=10, density = True)\npdf = counts\/(sum(counts))\nprint(pdf);\nprint(bin_edges);\ncdf = np.cumsum(pdf)\nplt.plot(bin_edges[1:],pdf);\nplt.plot(bin_edges[1:], cdf)\nplt.xlabel('log_Monetary', fontsize=12)\nplt.ylabel('Percentage', fontsize=12)\nplt.title('Monetary Cumulative Frequency Distribution',fontsize=15)","22320b37":"plt.close();\nsns.set_style(\"whitegrid\");\nsns.pairplot(df_rfm, size=3);\nplt.show()","ae11f24b":"# fig = ff.create_scatterplotmatrix(df_rfm, height=800, width=800)\n# iplot(fig, filename='Basic Scatterplot Matrix')","a13fd2fb":"# df_StateRFM['Frequency'] = np.round(df_StateRFM['Frequency'])\n# data = [go.Choropleth(\n#     colorscale = scl,\n#     autocolorscale = False,\n#     locations = df_StateRFM['State'],\n#     z = df_StateRFM['Frequency'].astype(float),\n#     locationmode = 'USA-states',\n#     marker = go.choropleth.Marker(\n#         line = go.choropleth.marker.Line(\n#             color = 'rgb(255,255,255)',\n#             width = 2\n#         )),\n#     colorbar = go.choropleth.ColorBar(\n#         title = \"Frequency Count\")\n# )]\n\n# layout = go.Layout(\n#     title = go.layout.Title(\n#         text = 'State wise Frequency Value '\n#     ),\n#     geo = go.layout.Geo(\n#         scope = 'usa',\n#         projection = go.layout.geo.Projection(type = 'albers usa'),\n#         showlakes = True,\n#         lakecolor = 'rgb(255, 255, 255)'),\n# )\n\n# fig = go.Figure(data = data, layout = layout)\n# iplot(fig, filename = 'd3-cloropleth-map')","8eec16e9":"# df_StateRFM['Recency'] = np.round(df_StateRFM['Recency'])\n# data = [go.Choropleth(\n#     colorscale = scl,\n#     autocolorscale = False,\n#     locations = df_StateRFM['State'],\n#     z = df_StateRFM['Recency'].astype(float),\n#     locationmode = 'USA-states',\n#     marker = go.choropleth.Marker(\n#         line = go.choropleth.marker.Line(\n#             color = 'rgb(255,255,255)',\n#             width = 2\n#         )),\n#     colorbar = go.choropleth.ColorBar(\n#         title = \"Recency Count\")\n# )]\n\n# layout = go.Layout(\n#     title = go.layout.Title(\n#         text = 'State wise Recency Value '\n#     ),\n#     geo = go.layout.Geo(\n#         scope = 'usa',\n#         projection = go.layout.geo.Projection(type = 'albers usa'),\n#         showlakes = True,\n#         lakecolor = 'rgb(255, 255, 255)'),\n# )\n\n# fig = go.Figure(data = data, layout = layout)\n# iplot(fig, filename = 'd3-cloropleth-map')","fba61b0e":"df_rfm.quantile(q=[0.1,0.25,0.4,0.5,0.75,0.9])","26f073e1":"threshold_M = int(df_rfm.median()['Monetary'])+1\nprint(threshold_M)\nthreshold_F = df_rfm.Frequency.quantile(0.75)\nprint(threshold_F)\nthreshold_R = df_rfm.Recency.quantile(0.40)\nprint(threshold_R)","e91e9404":"df_rfm['threshold_R'] = df_rfm['Recency'].apply(lambda x: x < threshold_R)\ndf_rfm['threshold_F'] = df_rfm['Frequency'].apply(lambda x: x > threshold_F)\ndf_rfm['threshold_M'] = df_rfm['Monetary'].apply(lambda x: x > threshold_M)\ndf_rfm[['threshold_R', 'threshold_F', 'threshold_M']] = df_rfm[['threshold_R', 'threshold_F', 'threshold_M']].apply(lambda x: x.astype(int), axis=1)\ndf_rfm['IsLoyal'] = 'NA'\ndf_rfm['Segment'] = 'NA'\ndf_rfm.head(10)","a37d4f17":"def Loyalty_assign(x):\n    if((x[5]==1) & (x[4]==1)):\n        return 'Loyal'\n       \n    elif((x[3]==1) & (x[4]==0)):\n        return 'Loyal'\n         \n    else:\n        return 'Not Loyal'\n    \ndef Segment_assign(x):\n    if((x[5]==1) & (x[3]==1) & (x[4]==1)):\n        return 'Champions'\n       \n    elif((x[5]==1) & (x[3]==1) & (x[4]==0)):\n        return 'Future Champions'\n         \n    elif((x[5]==1) & (x[3]==0) & (x[4]==1)):\n        return 'Very Valuable'\n         \n    elif((x[5]==1) & (x[3]==0) & (x[4]==0)):\n        return 'Hibernating'\n         \n    elif((x[5]==0) & (x[3]==1) & (x[4]==1)):\n        return 'Active'\n         \n    elif((x[5]==0) & (x[3]==1) & (x[4]==0)):\n        return 'About to Sleep'\n         \n    elif((x[5]==0) & (x[3]==0)):\n        return 'Lost'","aacc9a19":"df_rfm['Segment'] = df_rfm.apply(Segment_assign, axis=1)\ndf_rfm['IsLoyal'] = df_rfm.apply(Loyalty_assign, axis=1)\ndf_rfm.head()","eacd1911":"df_rfm['IsLoyal'].value_counts()","cb8c61f5":"df_rfm['Segment'].value_counts()","cb60d022":"df_rfm.reset_index(inplace=True)\ndf_rfm.head(1)","e97f70a6":"df_Segment = df_rfm.groupby('Segment', as_index=False).agg({'Monetary':sum, 'card_id':groupby_count, 'Frequency':sum})\ndf_Segment.columns = ['Segment','Monetary', 'No_Cards', 'Frequency']\ndf_Segment","11348ff9":"df_Loyal = df_rfm.groupby('IsLoyal', as_index=False).agg({'Monetary':sum, 'card_id':groupby_count, 'Frequency':sum})\ndf_Loyal.columns = ['Loyality','Monetary', 'No_Cards', 'Frequency']\ndf_Loyal","9fbbcbd8":"groups = df_Segment['Segment'].values.tolist()\namount = df_Segment['Monetary'].values.tolist()\n#colors = ['red', 'yellow', 'green', 'orange']\n\ntrace = go.Pie(labels=groups, values=amount, hoverinfo='label+percent', textinfo='value', textfont=dict(size=25),\n       pull=.4,hole=.2,marker=dict(line=dict(color='#000000', width=3)))\n\niplot([trace])","c799ebff":"groups = df_Loyal['Loyality'].values.tolist()\namount = df_Loyal['Monetary'].values.tolist()\n#colors = ['red', 'yellow', 'green', 'orange']\n\ntrace = go.Pie(labels=groups, values=amount, hoverinfo='label+percent', textinfo='value', textfont=dict(size=25),\n       pull=.4,hole=.2,marker=dict(line=dict(color='#000000', width=3)))\n\niplot([trace])","6a4321fe":"groups = df_Segment['Segment'].values.tolist()\nNo_Company = df_Segment['No_Cards'].values.tolist()\nDistinct_Frequency = df_Segment['Frequency'].values.tolist()\n#colors = ['blue','red', 'yellow', 'pink','violet','green', 'orange']\n\n#trace2 = go.Bar(x=groups,y=No_Company,name='Companies', marker=dict(color=colors))\n\ntrace1 = go.Bar(x=groups,y=Distinct_Frequency,name='Frequency')\ntrace2 = go.Bar(x=groups,y=No_Company,name='Cards\/Customers')\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='stack')\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='stacked-bar')","13478f73":"groups = df_Loyal['Loyality'].values.tolist()\nNo_Company = df_Loyal['No_Cards'].values.tolist()\nDistinct_Frequency = df_Loyal['Frequency'].values.tolist()\n#colors = ['blue','red', 'yellow', 'pink','violet','green', 'orange']\n\n#trace2 = go.Bar(x=groups,y=No_Company,name='Companies', marker=dict(color=colors))\n\ntrace1 = go.Bar(x=groups,y=Distinct_Frequency,name='Frequency')\ntrace2 = go.Bar(x=groups,y=No_Company,name='Cards\/Customers')\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='stack')\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='stacked-bar')","f7d785de":"# df_rfm.set_index('card_id', inplace=True)\n# df_rfm.head(1)","d06fbc56":"rank_df = df_rfm[['Recency','Frequency', 'Monetary']].rank(method='first')\nrank_df.head(2)","b8e709ec":"normalized_df = (rank_df - rank_df.mean()) \/ rank_df.std()\nnormalized_df.head(2)","da0e2cc5":"from sklearn.cluster import KMeans\ndata = normalized_df[['Recency', 'Frequency', 'Monetary']]\n\nsse = {}\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(data)\n    data[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","3e2c1f59":"from sklearn.metrics import silhouette_score","0169b33a":"print(normalized_df.shape)","0cd230f1":"# for n_cluster in tqdm([2,3,4,5]):\n#     kmeans = KMeans(n_clusters=n_cluster, max_iter=100).fit(normalized_df[['Recency', 'Frequency', 'Monetary']])\n    \n#     silhouette_avg = silhouette_score(normalized_df[['Recency', 'Frequency', 'Monetary']], kmeans.labels_)\n    \n#     print('Silhouette Score for %i Clusters: %0.4f' % (n_cluster, silhouette_avg))","0c3fdc46":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=4,max_iter=1000).fit(normalized_df[['Recency', 'Frequency', 'Monetary']])\nprint(kmeans.labels_)\nprint(kmeans.cluster_centers_)","bacfab4b":"from collections import Counter\nz = kmeans.labels_\nCounter(z)","e0a0782d":"normalized_df['Cluster'] = kmeans.labels_\nnormalized_df.head()","0d01101c":"df_kmeans_rfm = df_rfm[['Recency','Frequency', 'Monetary']].copy()\ndf_kmeans_rfm['Cluster'] = kmeans.labels_\nprint(df_kmeans_rfm['Cluster'].value_counts())\ndf_kmeans_rfm.head(5)","6ac8198f":"# trace1 = go.Scatter3d(\n#     x=normalized_df['Recency'],\n#     z=normalized_df['Monetary'],\n#     y=normalized_df['Frequency'],\n#     mode='markers',\n#     marker=dict(size=12,color=df_kmeans_rfm['Cluster'],))\n\n# data = [trace1]\n\n# layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n\n# fig = go.Figure(data=data, layout=layout)\n# iplot(fig, filename='3d-scatter-colorscale')","4cdebd90":"colors = ['red', 'yellow', 'green', 'orange']\n\nfor i in ['Monetary']:\n    trace = go.Pie(labels=df_kmeans_rfm['Cluster'], values=df_kmeans_rfm[i], \n           hoverinfo='label+percent', textinfo='value', textfont=dict(size=15),\n           marker=dict(colors=colors, line=dict(color='#000000', width=3)))\n    iplot([trace])","385943fa":"df_kmeans_rfm.head(5)","f4e66db4":"for col in [\"Recency\",\"Frequency\",\"Monetary\"]:\n    print()\n    plt.figure(figsize=(14,8))\n    ax = sns.boxplot(x=\"Cluster\", y=col, data=normalized_df)\n    plt.title('Cluster\/Segment wise Difference in Purchase '+col,fontsize=15)\n    plt.show()\n    print()","be11cfb1":"### Thresholds for R | F | M","19dea58e":"### Reading the Data","e474e05b":"### Aggregation by card-id (At Customer Level). Can also compute at Item Level RFM and Store Level RFM or even website visit & activity based RFM etc depending on availability of Data","155fca25":"## 1. Simple Rule Based Approach - The Business Analyst Way","fdec0f5f":"### Checking for Purchase, Return and Rebate Transactions (if any)","994f4eb8":"## As the purchase_amount variable is normalized it is not possible to check if the transaction if a Purchase\/Return\/Rebate one","cd6ef7a8":"## 2. Clustering Algorithms Based Segmentation"}}