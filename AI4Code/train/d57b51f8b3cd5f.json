{"cell_type":{"04019da9":"code","117f99a3":"code","732f8cd4":"code","5af6069b":"code","c19cb0b4":"code","fd127e2e":"code","cad2f6f5":"code","6a56d8dd":"code","fbafbd54":"code","cb715c20":"code","21eb48f3":"code","d4991f4d":"code","b8f23d43":"code","d323060f":"code","75b82f18":"code","3ae96c1a":"code","c23a6e0c":"code","39d0b9d9":"code","3207c174":"code","c535d37b":"code","cad35085":"code","82f74ee2":"code","8b01df18":"code","7207cbde":"code","d809eaee":"code","066962d3":"code","e32d3838":"code","02c7becc":"code","9318d77e":"code","032a7e97":"code","2feb9aa3":"code","b5682ff5":"code","9a4dba8f":"code","9bf60505":"code","aca20e8f":"code","5b39f7df":"code","4b489233":"code","71eb17e9":"code","3ff5aa7b":"code","a63995c6":"code","991058da":"code","0ca8936f":"code","66ef3c88":"code","5524024f":"code","77e08174":"code","6c80f337":"code","48b3db79":"code","6a21fa54":"code","403f69e5":"code","77274161":"code","5efae21b":"code","96dc1ba5":"code","f3c46245":"code","9d61d0a3":"code","62802805":"code","4464943d":"code","aa02a0e2":"code","61613ea4":"code","3c474fd6":"code","82a88a07":"code","d411269b":"code","cc4db86d":"code","2e96573c":"code","c6e6444a":"code","2022f2ac":"code","9fad3678":"code","8ab126c4":"code","bf0de69d":"code","63b59524":"markdown","4eac7120":"markdown","59f191d4":"markdown","662a9e18":"markdown","92e1219f":"markdown","ee0c0006":"markdown","69337d75":"markdown","c476ac9b":"markdown","aa3a678e":"markdown","fbb89e0d":"markdown","35d28dd3":"markdown"},"source":{"04019da9":"import riiideducation\n# import dask.dataframe as dd\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nenv = riiideducation.make_env()","117f99a3":"train = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n                   usecols=[1, 2, 3, 4, 5, 7, 8, 9],\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'task_container_id': 'int16',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )","732f8cd4":"#reading in question df\nquestions_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv',                         \n                            usecols=[0, 3],\n                            dtype={'question_id': 'int16',\n                              'part': 'int8'}\n                          )","5af6069b":"#reading in lecture df\nlectures_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/lectures.csv')","c19cb0b4":"lectures_df['type_of'] = lectures_df['type_of'].replace('solving question', 'solving_question')\n\nlectures_df = pd.get_dummies(lectures_df, columns=['part', 'type_of'])\n\npart_lectures_columns = [column for column in lectures_df.columns if column.startswith('part')]\n\ntypes_of_lectures_columns = [column for column in lectures_df.columns if column.startswith('type_of_')]","fd127e2e":"lectures_df.head()","cad2f6f5":"# merge lecture features to train dataset\ntrain_lectures = train[train.content_type_id == True].merge(lectures_df, left_on='content_id', right_on='lecture_id', how='left')","6a56d8dd":"train_lectures.head()","fbafbd54":"# collect per user stats\nuser_lecture_stats_part = train_lectures.groupby('user_id')[part_lectures_columns + types_of_lectures_columns].sum()","cb715c20":"user_lecture_stats_part.head()","21eb48f3":"# add boolean features\nfor column in user_lecture_stats_part.columns:\n    bool_column = column + '_boolean'\n    user_lecture_stats_part[bool_column] = (user_lecture_stats_part[column] > 0).astype(int)","d4991f4d":"user_lecture_stats_part.head()","b8f23d43":"#clearing memory\ndel(train_lectures)","d323060f":"#removing True or 1 for content_type_id\n\ntrain = train[train.content_type_id == False].sort_values('timestamp').reset_index(drop = True)","75b82f18":"train[(train.task_container_id == 9999)].tail()","3ae96c1a":"train[(train.content_type_id == False)].task_container_id.nunique()","c23a6e0c":"#saving value to fillna\nelapsed_mean = train.prior_question_elapsed_time.mean()\n","39d0b9d9":"group1 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['count'])\ngroup1.columns = ['avg_questions']\ngroup2 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['nunique'])\ngroup2.columns = ['avg_questions']\ngroup3 = group1 \/ group2","3207c174":"group3['avg_questions_seen'] = group3.avg_questions.cumsum()","c535d37b":"group3.iloc[0].avg_questions_seen","cad35085":"results_u_final = train.loc[train.content_type_id == False, ['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_final.columns = ['answered_correctly_user']\n\nresults_u2_final = train.loc[train.content_type_id == False, ['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\nresults_u2_final.columns = ['explanation_mean_user']","82f74ee2":"results_u2_final.explanation_mean_user.describe()","8b01df18":"train = pd.merge(train, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')","7207cbde":"results_q_final = train.loc[train.content_type_id == False, ['question_id','answered_correctly']].groupby(['question_id']).agg(['mean'])\nresults_q_final.columns = ['quest_pct']","d809eaee":"results_q2_final = train.loc[train.content_type_id == False, ['question_id','part']].groupby(['question_id']).agg(['count'])\nresults_q2_final.columns = ['count']","066962d3":"question2 = pd.merge(questions_df, results_q_final, left_on = 'question_id', right_on = 'question_id', how = 'left')","e32d3838":"question2 = pd.merge(question2, results_q2_final, left_on = 'question_id', right_on = 'question_id', how = 'left')","02c7becc":"question2.quest_pct = round(question2.quest_pct,5)","9318d77e":"display(question2.head(), question2.tail())","032a7e97":"train.head()","2feb9aa3":"len(train)","b5682ff5":"len(train)","9a4dba8f":"train.answered_correctly.mean()","9bf60505":"prior_mean_user = results_u2_final.explanation_mean_user.mean()","aca20e8f":"train.loc[(train.timestamp == 0)].answered_correctly.mean()","5b39f7df":"train.loc[(train.timestamp != 0)].answered_correctly.mean()","4b489233":"train.drop(['timestamp', 'content_type_id', 'question_id', 'part'], axis=1, inplace=True)","71eb17e9":"len(train)","3ff5aa7b":"validation = train.groupby('user_id').tail(5)\ntrain = train[~train.index.isin(validation.index)]\nlen(train) + len(validation)","a63995c6":"validation.answered_correctly.mean()","991058da":"train.answered_correctly.mean()","0ca8936f":"results_u_val = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_val.columns = ['answered_correctly_user']\n\nresults_u2_val = train[['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\nresults_u2_val.columns = ['explanation_mean_user']","66ef3c88":"X = train.groupby('user_id').tail(18)\ntrain = train[~train.index.isin(X.index)]\nlen(X) + len(train) + len(validation)","5524024f":"X.answered_correctly.mean()","77e08174":"train.answered_correctly.mean()","6c80f337":"results_u_X = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_X.columns = ['answered_correctly_user']\n\nresults_u2_X = train[['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\nresults_u2_X.columns = ['explanation_mean_user']","48b3db79":"#clearing memory\ndel(train)","6a21fa54":"X = pd.merge(X, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\nX = pd.merge(X, results_u_X, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_u2_X, on=['user_id'], how=\"left\")\n\nX = pd.merge(X, user_lecture_stats_part, on=['user_id'], how=\"left\")","403f69e5":"validation = pd.merge(validation, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\nvalidation = pd.merge(validation, results_u_val, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_u2_val, on=['user_id'], how=\"left\")\n\nvalidation = pd.merge(validation, user_lecture_stats_part, on=['user_id'], how=\"left\")","77274161":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\n\nX.prior_question_had_explanation.fillna(False, inplace = True)\nvalidation.prior_question_had_explanation.fillna(False, inplace = True)\n\nvalidation[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(validation[\"prior_question_had_explanation\"])\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])","5efae21b":"#reading in question df\n#question2 = pd.read_csv('\/kaggle\/input\/question2\/question2.csv)","96dc1ba5":"content_mean = question2.quest_pct.mean()\n\nquestion2.quest_pct.mean()\n#there are a lot of high percentage questions, should use median instead?","f3c46245":"#filling questions with no info with a new value\nquestion2.quest_pct = question2.quest_pct.mask((question2['count'] < 3), .65)\n\n\n#filling very hard new questions with a more reasonable value\nquestion2.quest_pct = question2.quest_pct.mask((question2.quest_pct < .2) & (question2['count'] < 21), .2)\n\n#filling very easy new questions with a more reasonable value\nquestion2.quest_pct = question2.quest_pct.mask((question2.quest_pct > .95) & (question2['count'] < 21), .95)","9d61d0a3":"X = pd.merge(X, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\nvalidation = pd.merge(validation, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\nX.part = X.part - 1\nvalidation.part = validation.part - 1","62802805":"X.head()","4464943d":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\nX.head()\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","aa02a0e2":"X = X[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part',\n       'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7',\n       'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter',\n       'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean',\n       'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']]\nX_val = X_val[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen',\n               'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part',\n               'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7',\n               'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter',\n               'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean',\n               'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']]","61613ea4":"\n# Filling with 0.5 for simplicity; there could likely be a better value\nX['answered_correctly_user'].fillna(0.65,  inplace=True)\nX['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\nX['quest_pct'].fillna(content_mean, inplace=True)\n\nX['part'].fillna(4, inplace = True)\nX['avg_questions_seen'].fillna(1, inplace = True)\nX['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\nX['prior_question_had_explanation_enc'].fillna(0, inplace = True)\n\nX['part_1'].fillna(0, inplace = True)\nX['part_2'].fillna(0, inplace = True)\nX['part_3'].fillna(0, inplace = True)\nX['part_4'].fillna(0, inplace = True)\nX['part_5'].fillna(0, inplace = True)\nX['part_6'].fillna(0, inplace = True)\nX['part_7'].fillna(0, inplace = True)\nX['type_of_concept'].fillna(0, inplace = True)\nX['type_of_intention'].fillna(0, inplace = True)\nX['type_of_solving_question'].fillna(0, inplace = True)\nX['type_of_starter'].fillna(0, inplace = True)\nX['part_1_boolean'].fillna(0, inplace = True)\nX['part_2_boolean'].fillna(0, inplace = True)\nX['part_3_boolean'].fillna(0, inplace = True)\nX['part_4_boolean'].fillna(0, inplace = True)\nX['part_5_boolean'].fillna(0, inplace = True)\nX['part_6_boolean'].fillna(0, inplace = True)\nX['part_7_boolean'].fillna(0, inplace = True)\nX['type_of_concept_boolean'].fillna(0, inplace = True)\nX['type_of_intention_boolean'].fillna(0, inplace = True)\nX['type_of_solving_question_boolean'].fillna(0, inplace = True)\nX['type_of_starter_boolean'].fillna(0, inplace = True)","3c474fd6":"X_val['answered_correctly_user'].fillna(0.65,  inplace=True)\nX_val['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\nX_val['quest_pct'].fillna(content_mean,  inplace=True)\n\nX_val['part'].fillna(4, inplace = True)\nX_val['avg_questions_seen'].fillna(1, inplace = True)\nX_val['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\nX_val['prior_question_had_explanation_enc'].fillna(0, inplace = True)\n\nX_val['part_1'].fillna(0, inplace = True)\nX_val['part_2'].fillna(0, inplace = True)\nX_val['part_3'].fillna(0, inplace = True)\nX_val['part_4'].fillna(0, inplace = True)\nX_val['part_5'].fillna(0, inplace = True)\nX_val['part_6'].fillna(0, inplace = True)\nX_val['part_7'].fillna(0, inplace = True)\nX_val['type_of_concept'].fillna(0, inplace = True)\nX_val['type_of_intention'].fillna(0, inplace = True)\nX_val['type_of_solving_question'].fillna(0, inplace = True)\nX_val['type_of_starter'].fillna(0, inplace = True)\nX_val['part_1_boolean'].fillna(0, inplace = True)\nX_val['part_2_boolean'].fillna(0, inplace = True)\nX_val['part_3_boolean'].fillna(0, inplace = True)\nX_val['part_4_boolean'].fillna(0, inplace = True)\nX_val['part_5_boolean'].fillna(0, inplace = True)\nX_val['part_6_boolean'].fillna(0, inplace = True)\nX_val['part_7_boolean'].fillna(0, inplace = True)\nX_val['type_of_concept_boolean'].fillna(0, inplace = True)\nX_val['type_of_intention_boolean'].fillna(0, inplace = True)\nX_val['type_of_solving_question_boolean'].fillna(0, inplace = True)\nX_val['type_of_starter_boolean'].fillna(0, inplace = True)","82a88a07":"import lightgbm as lgb\n\nparams = {\n    'objective': 'binary',\n    'boosting' : 'gbdt',\n    'max_bin': 800,\n    'learning_rate': 0.0175,\n    'num_leaves': 80\n}\n\nlgb_train = lgb.Dataset(X, y, categorical_feature = ['part', 'prior_question_had_explanation_enc'])\nlgb_eval = lgb.Dataset(X_val, y_val, categorical_feature = ['part', 'prior_question_had_explanation_enc'], reference=lgb_train)","d411269b":"model = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=50,\n    num_boost_round=10000,\n    early_stopping_rounds=12\n)","cc4db86d":"y_pred = model.predict(X_val)\ny_true = np.array(y_val)\nroc_auc_score(y_true, y_pred)","2e96573c":"import matplotlib.pyplot as plt\nimport seaborn as sns","c6e6444a":"#displaying the most important features by split\nlgb.plot_importance(model)\nplt.show()","2022f2ac":"#displaying the most important features by gain\nlgb.plot_importance(model, importance_type = 'gain')\nplt.show()","9fad3678":"iter_test = env.iter_test()","8ab126c4":"for (test_df, sample_prediction_df) in iter_test:\n    test_df['task_container_id'] = test_df.task_container_id.mask(test_df.task_container_id > 9999, 9999)\n    test_df = pd.merge(test_df, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n    test_df = pd.merge(test_df, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n    test_df = pd.merge(test_df, results_u_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_u2_final, on=['user_id'],  how=\"left\")\n    \n    test_df = pd.merge(test_df, user_lecture_stats_part, on=['user_id'], how=\"left\")\n    test_df['part_1'].fillna(0, inplace = True)\n    test_df['part_2'].fillna(0, inplace = True)\n    test_df['part_3'].fillna(0, inplace = True)\n    test_df['part_4'].fillna(0, inplace = True)\n    test_df['part_5'].fillna(0, inplace = True)\n    test_df['part_6'].fillna(0, inplace = True)\n    test_df['part_7'].fillna(0, inplace = True)\n    test_df['type_of_concept'].fillna(0, inplace = True)\n    test_df['type_of_intention'].fillna(0, inplace = True)\n    test_df['type_of_solving_question'].fillna(0, inplace = True)\n    test_df['type_of_starter'].fillna(0, inplace = True)\n    test_df['part_1_boolean'].fillna(0, inplace = True)\n    test_df['part_2_boolean'].fillna(0, inplace = True)\n    test_df['part_3_boolean'].fillna(0, inplace = True)\n    test_df['part_4_boolean'].fillna(0, inplace = True)\n    test_df['part_5_boolean'].fillna(0, inplace = True)\n    test_df['part_6_boolean'].fillna(0, inplace = True)\n    test_df['part_7_boolean'].fillna(0, inplace = True)\n    test_df['type_of_concept_boolean'].fillna(0, inplace = True)\n    test_df['type_of_intention_boolean'].fillna(0, inplace = True)\n    test_df['type_of_solving_question_boolean'].fillna(0, inplace = True)\n    test_df['type_of_starter_boolean'].fillna(0, inplace = True)\n    \n    test_df['answered_correctly_user'].fillna(0.65,  inplace=True)\n    test_df['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\n    test_df['quest_pct'].fillna(content_mean,  inplace=True)\n    test_df['part'] = test_df.part - 1\n\n    test_df['part'].fillna(4, inplace = True)\n    test_df['avg_questions_seen'].fillna(1, inplace = True)\n    test_df['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    \n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen',\n                                                            'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part',\n                                                            'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7',\n                                                            'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter',\n                                                            'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean',\n                                                            'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","bf0de69d":"#students don't appear in every task container ID what can I do about this, can't always follow sequentially?","63b59524":"## Data Exploration ##","4eac7120":"## Making Predictions for New Data ##","59f191d4":"Does it make sense to use last questions as validation? Why is the rate of correct answers so low?\nI am convinced there is a better way to match the test data.","662a9e18":"## Creating Validation Set (Most Recent Answers by User) ##","92e1219f":"## Extracting Training Data ##","ee0c0006":"## Modeling ##","69337d75":"## Merging Data ##","c476ac9b":"This notebook is mostly based on https:\/\/www.kaggle.com\/dwit392\/lgbm-iii and slightly modified from https:\/\/www.kaggle.com\/takamotoki\/lgbm-iii-part2\n\n\n== modification from LGBM III part2 ==\n\n- add lecture features : This idea comes from the following notebook: https:\/\/www.kaggle.com\/pavelvpster\/riiid-fe-target-encoding-keras\n\n- lgb parameters : num_boost_round 1300 ==> 10000, early_stopping_rounds 8 ==> 12","aa3a678e":"## Examining Feature Importance ##","fbb89e0d":"## Reading Data and Importing Libraries ##","35d28dd3":"Affirmatives (True) for content_type_id are only for those with a different type of content (lectures). These are not real questions."}}