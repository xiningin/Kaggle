{"cell_type":{"cf08853f":"code","f859cb7a":"code","d9a122d7":"code","a1680d46":"code","3a61484b":"code","1017d509":"code","699187c8":"code","fd8b9858":"code","a1d24c15":"code","710180a5":"code","5d275054":"code","9d880e1d":"code","7dd39ee1":"code","b82b771a":"code","77136bac":"code","e6561685":"code","fee3f3bc":"code","48eaa64a":"code","f1cd9a66":"code","708eb018":"code","9ffd1f0c":"markdown","cc5cafa6":"markdown","f4319198":"markdown","7a0b6ddd":"markdown","6b92be9e":"markdown","3b3f4a61":"markdown","98089864":"markdown","80ec96a9":"markdown","35651802":"markdown","142faa57":"markdown","de873bb1":"markdown","6ae5a658":"markdown","7d07f8af":"markdown"},"source":{"cf08853f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f859cb7a":"!pip install tensorflow-datasets","d9a122d7":"import tensorflow as tf\nimport tensorflow_datasets as tfds","a1680d46":"data = tfds.load('yelp_polarity_reviews', split='train', shuffle_files=True)","3a61484b":"reviews = []\npolarity = []\n\nfor i in data.take(20000):\n    reviews.append((i['text'].numpy().decode(\"utf-8\")))\n    polarity.append(int(i['label']))","1017d509":"reviews[3]","699187c8":"def clean_text(review):\n    cleaned = review.replace(\"\\\\n\", \" \")\n    cleaned = cleaned.replace(\"\\'\", \"'\")\n    cleaned = cleaned.replace(\"\\\\r\", \" \")\n    cleaned = cleaned.replace(\"\\\\\"\"\", \" \")\n    return cleaned","fd8b9858":"reviews = [clean_text(review) for review in reviews]","a1d24c15":"reviews[3]","710180a5":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nvocab_size = 10000\nmax_length = 200\n\ntokenizer = Tokenizer(num_words = vocab_size)\ntokenizer.fit_on_texts(reviews)","5d275054":"sequences = tokenizer.texts_to_sequences(reviews)\npadded_sequences = pad_sequences(sequences, max_length, padding = 'post')","9d880e1d":"padded_sequences","7dd39ee1":"from sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split(padded_sequences, polarity)\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y)","b82b771a":"len(train_x), len(train_y)","77136bac":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 64, input_length=max_length-1))\nmodel.add(Bidirectional(LSTM(20, return_sequences = True)))\nmodel.add(Bidirectional(LSTM(20)))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","e6561685":"model.summary()","fee3f3bc":"model.fit(np.array(train_x), np.array(train_y), epochs = 3, verbose = 1, \n          validation_data = (np.array(val_x), np.array(val_y)))","48eaa64a":"print(\"Accuracy: \", model.evaluate(np.array(test_x), np.array(test_y))[1])","f1cd9a66":"tokenizer.sequences_to_texts([test_x[0]])","708eb018":"np.round(max(model.predict(test_x[0])))","9ffd1f0c":"The model returned a 1, which means it identified it as positive. Yay!","cc5cafa6":"Let's evaluate our model on the test set:","f4319198":"To get the data, we can download it directly using the Tensorflow Datasets (TFDS) package. TFDS has a wide variety of image, audio, text, and other kinds of datasets that can easily be donwloaded and used. For more information, visit: https:\/\/www.tensorflow.org\/datasets\/overview","7a0b6ddd":"In this notebook, we are going to perform a sentiment analysis on Yelp Reviews, which means we're going to train a model to \"read\" a review and determine if it's a positive or negative review.","6b92be9e":"Now, we split our data into training, testing, and validation sets. For more information about each of these, visit: https:\/\/towardsdatascience.com\/train-validation-and-test-sets-72cb40cba9e7","3b3f4a61":"We have to make sure all of the input into our Tensorflow model is the same size, so we pad the sequences to all be the same length.","98089864":"Let's look at a review in the test set.","80ec96a9":"The review looks pretty positive. Let's see what the model thinks:","35651802":"Looking through, the reviews have some escape sequences (\"\\\\n\", etc) in the text. I'll remove these to make the analysis better.","142faa57":"The data comes in a tensor form, but I want to save the reviews as strings and the labels as integers (0 for negative, and 1 for positive).","de873bb1":"Let's take a look at a review.","6ae5a658":"Now, we build our Tensorflow model. For text data, we usually use an Embedding layer. I've also chosen to use bidirectional LSTM layers, but there are many different kinds of layers that you could use.","7d07f8af":"That's better. Now, I'm going to use Keras preprocessing layers to tokenize the reviews (turn the text into an array of numbers). For more information about the Tokenizer, visit: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/text\/Tokenizer"}}