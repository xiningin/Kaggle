{"cell_type":{"cdd43702":"code","90c964c1":"code","494229af":"code","24f9623a":"code","bc261f64":"code","08be6549":"code","3b09bb16":"code","81459050":"code","63360839":"code","efab6570":"code","00456739":"code","e8266a8d":"code","4b6efb46":"code","b5964730":"code","e65e98d3":"code","5780c0a8":"code","46323034":"code","4b526650":"code","989efbc4":"code","d8b833ff":"code","f69c2958":"code","f6694bd3":"code","85cc0d65":"code","ec9e3c46":"code","027b0e33":"code","4599b1f2":"code","2628096d":"code","344e149c":"code","93e48b87":"markdown"},"source":{"cdd43702":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","90c964c1":"\nimport matplotlib.pyplot as plt #for plotting things\nimport cv2\nfrom PIL import Image\nimport tensorflow as tf \n\n# Keras Libraries\nimport random\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras import optimizers\n","494229af":"tf.random.set_seed(2)\nnp.random.seed(1)\n","24f9623a":"base_dir = ('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images')","bc261f64":"Uninfected_dir=os.path.join(base_dir,'Uninfected')","08be6549":"par_dir=os.path.join(base_dir,'Parasitized')","3b09bb16":"print(len(os.listdir(Uninfected_dir)))\nprint(len(os.listdir(par_dir)))","81459050":"for i in range (1,8):\n    rand_norm= np.random.randint(0,len(os.listdir(Uninfected_dir)))\n    unin_pic = os.listdir(Uninfected_dir)[rand_norm]\n    \n    print('uninfected title: ',unin_pic)\n\n\n    #print(rand_norm)\n\n\n    norm_address=os.path.join(Uninfected_dir,unin_pic)\n\n    #print(norm_address)\n\n    norm_load = Image.open(norm_address) #Loading image\n\n    #f = plt.figure(figsize= (10,10))\n    img_plot = plt.imshow(norm_load,cmap='gray') #showing image\n    print(norm_load.size)\n    i=i+1\n","63360839":"#Data input\n\nIMG_SIZE=64\nCATEGORIES = ['Parasitized', 'Uninfected']\ndataset = []\n\ndef generate_data():\n    for category in CATEGORIES:\n        path = f'..\/input\/cell-images-for-detecting-malaria\/cell_images\/{category}'\n        class_id = CATEGORIES.index(category)\n        for image in os.listdir(path):\n            try:\n                image_array = cv2.imread(os.path.join(path, image))\n                image_array = cv2.resize(image_array, (IMG_SIZE , IMG_SIZE),3)\n                dataset.append([image_array, class_id])\n            except Exception as e:\n                print(e)\n                \n    random.shuffle(dataset)\n                \n\n","efab6570":"datas = []\nlabels = []\nfor img in os.listdir(par_dir):\n    try:\n        img_read = plt.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\/' + img)\n        img_resize = cv2.resize(img_read, (50, 50),3)\n        img_array = np.array(img_resize)\n        datas.append([img_array,1])\n        \n    except Exception as e:\n                print(e)\n        \nfor img in os.listdir(Uninfected_dir):\n    try:\n        img_read =plt.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected\/' + img)\n        img_resize = cv2.resize(img_read, (50, 50),3)\n        img_array = np.array(img_resize)\n        datas.append([img_array,0])\n        \n        labels.append(0)\n    except Exception as e:\n                print(e)","00456739":"random.shuffle(datas)\n\ndata = []\nlabels = []\nfor features, label in datas:\n    data.append(features)\n    labels.append(label)\nprint(labels)    \n    ","e8266a8d":"#Data preprocess\n\ndata = np.array(data)\nlabels=np.array(labels)\n#data.reshape(data.shape[0], 50, 50, 3)\n\nprint(data.shape)","4b6efb46":"train_data, og_data, train_labels, og_labels = train_test_split(data, \n                                                          labels,\n                                                          test_size=0.2,random_state=101\n                                                                   )\n\nvalidation_data,test_data , validation_labels,test_labels = train_test_split(og_data, \n                                                                    og_labels,\n                                                                    test_size=0.2,random_state=101)","b5964730":"print(train_labels.shape)\nprint(train_data.shape)\nprint(validation_data.shape)\nprint(test_data.shape)","e65e98d3":"model=tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(50,50,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n     tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    \n    \n     tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    \n    tf.keras.layers.Flatten(),\n   \n    tf.keras.layers.Dense(128, activation='relu'), \n     tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(512, activation='relu'), \n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(2, activation='softmax')  \n    \n])\n","5780c0a8":"model.summary()","46323034":"train_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=45,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\nvalidation_datagen= ImageDataGenerator(rescale=1.\/255)","4b526650":"train_genarator=train_datagen.flow(\ntrain_data,\ntrain_labels,\nbatch_size=48\n)\n\nvalid_genarator=validation_datagen.flow(\nvalidation_data,\nvalidation_labels,\nbatch_size=30\n\n)","989efbc4":"opt=tf.keras.optimizers.RMSprop(\n    learning_rate=0.0001 \n)\n\nmodel.compile(optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n              \n              metrics=['accuracy'])\n","d8b833ff":"history=model.fit(train_genarator,validation_data=valid_genarator,epochs=10,shuffle=False)","f69c2958":"x=model.predict(test_data)\n\n\n","f6694bd3":"test_datagen=ImageDataGenerator(rescale=1.\/255)\ntest_gen=test_datagen.flow(test_data,test_labels,batch_size=1,shuffle=False)","85cc0d65":"print(x[0:10])","ec9e3c46":"print(test_labels[0:10])","027b0e33":"model.evaluate(test_gen)","4599b1f2":"x=model.predict_classes(test_data)","2628096d":"print(x[0:10])","344e149c":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='Training Acc.')\nplt.plot(epochs, val_acc, 'b', label='Validation Acc.')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","93e48b87":"> "}}