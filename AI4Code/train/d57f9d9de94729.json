{"cell_type":{"f349c11d":"code","7bb4b718":"code","84c6e414":"code","fcd00b7a":"code","ba61b1d6":"code","56d13fed":"code","856b1325":"code","4c680891":"code","719b4882":"code","57bb2a1b":"code","2b9c6440":"code","b9ff788b":"code","dad6d0d8":"code","43203d2d":"code","03117ce6":"code","b76c1f4b":"code","46183e95":"code","5c087cba":"code","fe41a292":"code","dd52e701":"code","e3c62865":"code","fcd2a083":"code","1d42e039":"code","fa116bb0":"code","07f98908":"code","c653aa2e":"code","44c1dcbd":"code","4f88c7db":"code","e6539ab0":"code","c168c669":"code","a0de6a37":"code","f9afd802":"markdown"},"source":{"f349c11d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport pydicom\nfrom tqdm import tqdm\nfrom tensorflow.keras.utils import to_categorical","7bb4b718":"path = \"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv\"\ndf = pd.read_csv(path)\ndf.head(10)","84c6e414":"len(df)","fcd00b7a":"#path_1 = \"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/47ed17dcb2cbeec15182ed335a8b5a9e.dicom\"\n#dicom = pydicom.read_file(path_1)","ba61b1d6":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    \"\"\" Convert dicom file to numpy array \n    \n    Args:\n        path (str): Path to the dicom file to be converted\n        voi_lut (bool): Whether or not VOI LUT is available\n        fix_monochrome (bool): Whether or not to apply monochrome fix\n        \n    Returns:\n        Numpy array of the respective dicom file \n        \n    \"\"\"\n    dicom = pydicom.read_file(path)      # Use the pydicom library to read the dicom file\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":#MONOCHROME1\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.float32)#uint8\n        \n    return data","56d13fed":"root = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/'\next = '.dicom'\n\ndata = read_xray(root + df.image_id[64] + ext)\nplt.imshow(data, 'gray');","856b1325":"data.shape","4c680891":"data = df\nk = np.random.randint(0,len(data))  #selecting random integer for plotting XRAY\n","719b4882":"img_id = data.image_id[k]\nimg_id","57bb2a1b":"class_name = data.class_name[k]\nclass_name","2b9c6440":"img_id+ext","b9ff788b":"img_path = os.path.join(root, img_id+ext)\n#dicom_pixel = read_xray(img_path)","dad6d0d8":"def show_xray(data, root=root, ext=ext):\n    fig, axs = plt.subplots(3,3, figsize=(16,18))\n    \n    for i in range(9):\n        k = np.random.randint(0,len(data))  #selecting random integer for plotting XRAY\n        img_id = data.image_id[k]\n        class_name = data.class_name[k]\n        \n        img_path = os.path.join(root, img_id+ext)\n        dicom_pixel = read_xray(img_path)\n        \n        axs[i\/\/3,i%3].imshow(dicom_pixel, cmap='gray')\n        axs[i\/\/3,i%3].title.set_text(class_name)\n    plt.show()\n\n#show_xray(df)","43203d2d":"#used label encoder\ncode = {'Aortic enlargement':0 ,'Atelectasis':1,'Calcification':2,'Cardiomegaly':3,'Consolidation':4,\n        'ILD':5,'Infiltration':6,'Lung Opacity':7,'Nodule\/Mass':8,\n        'Other lesion':9,'Pleural effusion':10,'Pleural thickening':11,'Pneumothorax':12,'Pulmonary fibrosis':13,'No finding':14}\n\ndef getcode(n) : \n    for x , y in code.items() : \n        if n == y : \n            return x ","03117ce6":"import glob\nroot = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/'\nimg_path = glob.glob('\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/*.*')\nlen(img_path)","b76c1f4b":"dicom_pixel = read_xray(img_path[5620])","46183e95":"plt.imshow(dicom_pixel, 'gray')","5c087cba":"img_path[500]","fe41a292":"images_batch = np.random.choice(df.index, size=16)\nimages_batch","dd52e701":"data = df.index\nprint(data[15010])","e3c62865":"path = \"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv\"\ndf_1 = pd.read_csv(path)\nroot = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/'\next = '.dicom'\ndata = df_1\nX_train = []\ny_train = []\ni=0\ns=128\nfor file in tqdm(data.index): \n    img_id = data.image_id[file]#take image ID\n    #class_name = data.class_name[file]\n    idx = data.class_id[file]#take image class ID (0 1 .....14)\n    \n    img_path = os.path.join(root, img_id+ext)\n    dicom_pixel = read_xray(img_path)\n    \n    image_array = cv2.resize(dicom_pixel , (s,s), interpolation = cv2.INTER_AREA)\n    \n    X_train.append(list(image_array))\n    y_train.append(idx)#code[class_name]\n    if (file == 1):\n        break\n'''    else:\n        i=i+1'''","fcd2a083":"# define the shape of low resolution image (LR) for resize\npath = \"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv\"\ndf_1 = pd.read_csv(path)\ndata = df_1\nroot = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/'\next = '.dicom'\nimage_shape = (224, 224)\nimg_path = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/*.*'\ndef sample_images(batch_size, image_shape):\n    \n    # create the list of all images, which are inside of data_dir catalogue\n    #all_images = glob.glob(data_dir)\n    \n    # select a random batch with images\n    images_batch = np.random.choice(15000, size=batch_size)#total_images\n\n    X_train = []\n    y_train = []\n\n    for img in images_batch:\n        # take the numpy ndarray from the current image\n        img_id = data.image_id[img]\n        idx = data.class_id[img]#take image class ID (0 1 .....14)\n        img_path = os.path.join(root, img_id+ext)\n        dicom_pixel = read_xray(img_path)\n        image_array = cv2.resize(dicom_pixel , image_shape, interpolation = cv2.INTER_AREA)\n        X_train.append(list(image_array))\n        y_train.append(idx)#code[class_name]\n        \n    X_train=np.array(X_train)\n    X_train = X_train.reshape(-1,224,224,1)\n    y_train=to_categorical(y_train)\n    # convert lists into numpy ndarrays\n    return X_train, y_train","1d42e039":"len(images_batch)","fa116bb0":"batch_size = 8\n(X_train,y_train)= sample_images(batch_size, image_shape)","07f98908":"import tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D,BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import SGD,Adam,RMSprop,Adagrad\nfrom keras.regularizers import l1\nimport numpy as np\nnp.random.seed(512)\n\ns = 224\nmodel = Sequential()\n#model.add(BatchNormalization(input_shape=(s,s,1)))\nmodel.add(Conv2D(16, kernel_size=(3,3), padding='same', activation='relu',input_shape=(s,s,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#,activity_regularizer=l1(0.000001)\n\nmodel.add(Conv2D(32, kernel_size=(3,3),padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3),padding='same', activation='relu'))#\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128, kernel_size=(3,3),padding='same', activation='relu')) \nmodel.add(Conv2D(64, kernel_size=(3,3),padding='same', activation='relu'))\n\nmodel.add(Conv2D(256, kernel_size=(3,3),padding='same', activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3,3),padding='same', activation='relu'))#64,101\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.08))\n\nmodel.add(Flatten())\nmodel.add(Dense(2024, activation='relu'))\nmodel.add(Dropout(0.13))\n\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.13))\n\nmodel.add(Dense(4096, activation='relu'))\n#model.add(Dropout(0.11))\nmodel.add(Dense(2024, activation='relu'))#1024\n#model.add(Dropout(0.11))\nmodel.add(Dense(15, activation='softmax'))\n\n\n\n#=========================================================================================\n\nmodel.summary()\n\nopt = Adam(learning_rate=0.00001)\n# Compile the model\nmodel.compile(loss=tensorflow.keras.losses.categorical_crossentropy, optimizer=opt, metrics=[\"categorical_accuracy\"]) #categorical_accuracy\n# plot model architecture\nplot_model(model, show_shapes=True, to_file='Covid-19_Model.png')","c653aa2e":"#del model","44c1dcbd":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n#ModelCheckpoint means save best weights\nmodel_chkpt = ModelCheckpoint('best_mod.h5', save_best_only=True, monitor='accuracy')\nlearning_rate_reduction1 = ReduceLROnPlateau(monitor='val_loss', \n                                             patience=2, verbose=1, factor=0.5,mode=\"min\", min_lr=0.0000001)\nlearning_rate_reduction2 = ReduceLROnPlateau(monitor='loss', \n                                             patience=2, verbose=1, factor=0.5,mode=\"min\", min_lr=0.000001)\n\nearly_stopping = EarlyStopping(monitor='val_categorical_accuracy', restore_best_weights=False, patience=20)#val_loss,val_categorical_accuracy\ncallbacks1=[early_stopping,learning_rate_reduction2,learning_rate_reduction1]","4f88c7db":"#del history","e6539ab0":"#(X_train,y_train)= sample_images(batch_size, image_shape)","c168c669":"FAST_RUN=True\n#if FAST_RUN else 6\nbatch_size1=128\nbatch_size2=8\nbatch_size3=64\nepochs1=32\nfor epoch in range(epochs1):\n    print(epoch)\n    (X_train,y_train)= sample_images(batch_size1, image_shape)\n    (X_test,y_test)= sample_images(batch_size3, image_shape)\n    history = model.fit(X_train, y_train ,epochs=2,validation_data=(X_test, y_test),\n                        batch_size=batch_size2, shuffle=True, callbacks=callbacks1)#, verbose=1\n    print(\"========================================================================================\")\n    \n#validation_data=(X_test, y_test),validation_split=0.20,","a0de6a37":"fig, ax = plt.subplots(1,2, figsize=(12, 3))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","f9afd802":"0 - Aortic enlargement\n1 - Atelectasis\n2 - Calcification\n3 - Cardiomegaly\n4 - Consolidation\n5 - ILD\n6 - Infiltration\n7 - Lung Opacity\n8 - Nodule\/Mass\n9 - Other lesion\n10 - Pleural effusion\n11 - Pleural thickening\n12 - Pneumothorax\n13 - Pulmonary fibrosis\n14 - No finding"}}