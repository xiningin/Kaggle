{"cell_type":{"becb236d":"code","452bd6c8":"code","0aad20f0":"code","b57e86cc":"code","3d62e3ec":"code","2f3825fe":"code","17d38ada":"code","fac94152":"code","ef4f9181":"code","4a322766":"code","9c30c0c5":"code","9748b270":"code","df68a477":"code","35e55279":"code","70b631b8":"code","90e1cc18":"code","65f5a70b":"code","c86a1434":"markdown"},"source":{"becb236d":"# libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport numpy as np\nimport time\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn import metrics","452bd6c8":"train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')","0aad20f0":"sub = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","b57e86cc":"train['last_value_u_in'] = train.groupby('breath_id')['u_in'].transform('last')\ntrain['u_in_lag1'] = train.groupby('breath_id')['u_in'].shift(1)\ntrain['u_out_lag1'] = train.groupby('breath_id')['u_out'].shift(1)\ntrain['u_in_lag_back1'] = train.groupby('breath_id')['u_in'].shift(-1)\ntrain['u_out_lag_back1'] = train.groupby('breath_id')['u_out'].shift(-1)\ntrain['u_in_lag2'] = train.groupby('breath_id')['u_in'].shift(2)\ntrain['u_out_lag2'] = train.groupby('breath_id')['u_out'].shift(2)\ntrain['u_in_lag_back2'] = train.groupby('breath_id')['u_in'].shift(-2)\ntrain['u_out_lag_back2'] = train.groupby('breath_id')['u_out'].shift(-2)\ntrain['u_in_lag3'] = train.groupby('breath_id')['u_in'].shift(3)\ntrain['u_out_lag3'] = train.groupby('breath_id')['u_out'].shift(3)\ntrain['u_in_lag_back3'] = train.groupby('breath_id')['u_in'].shift(-3)\ntrain['u_out_lag_back3'] = train.groupby('breath_id')['u_out'].shift(-3)\ntrain['log+1'] = (train['u_in']+1).transform(np.log)\ntrain['log'] = (train['u_in']-train['u_in'].min()+1) .transform(np.log)\ntrain = train.fillna(0)","3d62e3ec":"train['R__C'] = train[\"R\"].astype(str) + '__' + train[\"C\"].astype(str)\n\n# max value of u_in and u_out for each breath\ntrain['breath_id__u_in__max'] = train.groupby(['breath_id'])['u_in'].transform('max')\ntrain['breath_id__u_out__max'] = train.groupby(['breath_id'])['u_out'].transform('max')\n\n# difference between consequitive values\ntrain['u_in_diff1'] = train['u_in'] - train['u_in_lag1']\ntrain['u_out_diff1'] = train['u_out'] - train['u_out_lag1']\ntrain['u_in_diff2'] = train['u_in'] - train['u_in_lag2']\ntrain['u_out_diff2'] = train['u_out'] - train['u_out_lag2']\n# from here: https:\/\/www.kaggle.com\/yasufuminakama\/ventilator-pressure-lstm-starter\ntrain.loc[train['time_step'] == 0, 'u_in_diff'] = 0\ntrain.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n\n# difference between the current value of u_in and the max value within the breath\ntrain['breath_id__u_in__diffmax'] = train.groupby(['breath_id'])['u_in'].transform('max') - train['u_in']\ntrain['breath_id__u_in__diffmean'] = train.groupby(['breath_id'])['u_in'].transform('mean') - train['u_in']\n\n# OHE\ntrain = train.merge(pd.get_dummies(train['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\ntrain = train.merge(pd.get_dummies(train['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\ntrain = train.merge(pd.get_dummies(train['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\n# https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\ntrain['u_in_cumsum'] = train.groupby(['breath_id'])['u_in'].cumsum()\ntrain['time_step_cumsum'] = train.groupby(['breath_id'])['time_step'].cumsum()\n","2f3825fe":"test['last_value_u_in'] = test.groupby('breath_id')['u_in'].transform('last')\ntest['u_in_lag1'] = test.groupby('breath_id')['u_in'].shift(1)\ntest['u_out_lag1'] = test.groupby('breath_id')['u_out'].shift(1)\ntest['u_in_lag_back1'] = test.groupby('breath_id')['u_in'].shift(-1)\ntest['u_out_lag_back1'] = test.groupby('breath_id')['u_out'].shift(-1)\ntest['u_in_lag2'] = test.groupby('breath_id')['u_in'].shift(2)\ntest['u_out_lag2'] = test.groupby('breath_id')['u_out'].shift(2)\ntest['u_in_lag_back2'] = test.groupby('breath_id')['u_in'].shift(-2)\ntest['u_out_lag_back2'] = test.groupby('breath_id')['u_out'].shift(-2)\ntest['u_in_lag3'] = test.groupby('breath_id')['u_in'].shift(3)\ntest['u_out_lag3'] = test.groupby('breath_id')['u_out'].shift(3)\ntest['u_in_lag_back3'] = test.groupby('breath_id')['u_in'].shift(-3)\ntest['u_out_lag_back3'] = test.groupby('breath_id')['u_out'].shift(-3)\ntest['log+1'] = (test['u_in']+1).transform(np.log)\ntest['log'] = (test['u_in']-train['u_in'].min()+1) .transform(np.log)\ntest = test.fillna(0)\ntest['R__C'] = test[\"R\"].astype(str) + '__' + test[\"C\"].astype(str)\n\ntest['breath_id__u_in__max'] = test.groupby(['breath_id'])['u_in'].transform('max')\ntest['breath_id__u_out__max'] = test.groupby(['breath_id'])['u_out'].transform('max')\n\ntest['u_in_diff1'] = test['u_in'] - test['u_in_lag1']\ntest['u_out_diff1'] = test['u_out'] - test['u_out_lag1']\ntest['u_in_diff2'] = test['u_in'] - test['u_in_lag2']\ntest['u_out_diff2'] = test['u_out'] - test['u_out_lag2']\ntest.loc[test['time_step'] == 0, 'u_in_diff'] = 0\ntest.loc[test['time_step'] == 0, 'u_out_diff'] = 0\n\ntest['breath_id__u_in__diffmax'] = test.groupby(['breath_id'])['u_in'].transform('max') - test['u_in']\ntest['breath_id__u_in__diffmean'] = test.groupby(['breath_id'])['u_in'].transform('mean') - test['u_in']\n\ntest = test.merge(pd.get_dummies(test['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\ntest = test.merge(pd.get_dummies(test['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\ntest = test.merge(pd.get_dummies(test['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\ntest['u_in_cumsum'] = test.groupby(['breath_id'])['u_in'].cumsum()\ntest['time_step_cumsum'] = test.groupby(['breath_id'])['time_step'].cumsum()","17d38ada":"#Bins of u_in to minimise categories\nbins = [0,2,4,8,10, 12, 15,18, 20,25, 30,35,50]\nlabels = [1,2,3,4,5,6,7,8,9,10,11,12]\ntrain['bin_u_in'] = pd.cut(train['u_in'], bins=bins, labels=labels)","fac94152":"bins = [0,2,4,8,10, 12, 15,18, 20,25, 30,35,50]\nlabels = [1,2,3,4,5,6,7,8,9,10,11,12]\ntest['bin_u_in'] = pd.cut(test['u_in'], bins=bins, labels=labels)","ef4f9181":"train['time_step'].describe()","4a322766":"#Time step is an integral feature which enforces target values to change with higher degree\ntrain['time_step_std'] = 7.659778e-01 - train['time_step']\ntrain['time_step_diff'] = train['time_step'] - train['time_step'].shift(1)\ntrain['time_step_u_in'] = train['time_step'] * train['u_in']","9c30c0c5":"test['time_step_std'] = 7.659778e-01 - train['time_step']\ntest['time_step_diff'] = test['time_step'] - test['time_step'].shift(1)\ntest['time_step_u_in'] = test['time_step'] * test['u_in']","9748b270":"# from numba import cuda\nscores = []\nfeature_importance = pd.DataFrame()\nmodels = []\ncolumns = [col for col in train.columns if col not in ['id', 'breath_id', 'pressure']]\nX = train[columns]\ny = train['pressure']\n\nparams = {'objective': 'regression',\n          'learning_rate': 0.2,\n          \"boosting_type\": \"gbdt\",\n          \"metric\": 'mae',\n          'n_jobs': -1,\n          'min_data_in_leaf':32,\n          'num_leaves':1024,\n         }","df68a477":"folds = GroupKFold(n_splits=5)\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y, groups=train['breath_id'])):\n    print(f'Fold {fold_n} started at {time.ctime()}')\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    model = lgb.LGBMRegressor(**params, n_estimators=10000)\n    model.fit(X_train, y_train, \n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            verbose=1000, early_stopping_rounds=15)\n    score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n    \n    models.append(model)\n    scores.append(score)\n\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = columns\n    fold_importance[\"importance\"] = model.feature_importances_\n    fold_importance[\"fold\"] = fold_n + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)","35e55279":"print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","70b631b8":"feature_importance[\"importance\"] \/= 5\ncols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n    by=\"importance\", ascending=False)[:50].index\n\nbest_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\nplt.figure(figsize=(16, 12));\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\nplt.title('LGB Features (avg over folds)');","90e1cc18":"for model in models:\n    sub['pressure'] += model.predict(test[columns])\nsub['pressure'] \/= 5","65f5a70b":"sub.to_csv('sub_addedOF.csv', index=False)","c86a1434":"Feature Engineering replicated from ANDREW LUKYANENKO with additional 3 features that I have added. This is probably the Fastest model that will generate a holding score of 0.561 based on Parameter tuning using KFold and Feature Engineering that I have tried.\nNote: The model can be fine tuned."}}