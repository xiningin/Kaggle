{"cell_type":{"c939cb63":"code","22e5f257":"code","425f6dfc":"code","0fb47d36":"code","eb80df69":"code","d28ef691":"code","263ef4d4":"code","c3bd5a7b":"code","ec8e20c7":"code","532b1312":"code","69cc6820":"code","2df65979":"code","fd69b966":"code","e4a4c05d":"code","e2aa6fef":"code","2d834f0c":"code","56ced491":"code","28317d5f":"code","bc1f463e":"code","97fed69d":"code","3eea549f":"code","cf0ad211":"code","619e4280":"code","a8e81530":"code","1458c776":"code","d430361a":"code","9bd24a5b":"code","a495eb31":"code","c3f67e19":"code","7132af73":"code","d0e3f5e1":"code","44e92d4d":"code","d2ce84d7":"markdown","0703bc3e":"markdown","156e0964":"markdown","d0bd06cf":"markdown","2676fcec":"markdown","0d31e9b8":"markdown","b9599f03":"markdown","0d8674c9":"markdown","1e01762b":"markdown","14a25be5":"markdown","4c0172d7":"markdown","e9c43e76":"markdown","dd0cbcb8":"markdown","6473eaf1":"markdown","2f7681df":"markdown","172494fe":"markdown","cc0a3c41":"markdown","d6093186":"markdown","863f8e6f":"markdown","93cc6e5e":"markdown","2f805627":"markdown","cf8b6d92":"markdown","da4b84f8":"markdown","3936a7eb":"markdown","5e0419d5":"markdown","242c8917":"markdown","86bc041a":"markdown"},"source":{"c939cb63":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings('ignore')","22e5f257":"df = pd.read_csv('..\/input\/yeast-transcriptomics\/SC_expression.csv')\ndf.head()","425f6dfc":"# are there missing values? No.\ndf.isna().sum().sum()","0fb47d36":"df.T.describe()","eb80df69":"# we remove the first column, it's uneeded\ndf = df.iloc[:,1:]","d28ef691":"#correlation heatmap\nplt.figure(figsize=(10,6));\nsns.heatmap(df.corr());","263ef4d4":"#clustermap\nsns.clustermap(df.corr(),cmap='vlag');","c3bd5a7b":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom mpl_toolkits import mplot3d\n\n\nsc = MinMaxScaler()\nscaled = sc.fit_transform(df.T.values)\n\npca = PCA()\ndecomp = pca.fit_transform(scaled)\n\nsns.scatterplot(decomp[:,0],decomp[:,1]);\n\n#explained variance\nplt.figure(figsize=(15,3));\nsns.barplot(x=np.arange(pca.explained_variance_ratio_.shape[0])+1, \n            y=pca.explained_variance_ratio_,color='Grey');\nplt.title('Explained Variance');\n\n#cumulative explained variance\nplt.figure(figsize=(5,3));\nsns.lineplot(x=np.arange(pca.explained_variance_ratio_.shape[0])+1, \n             y=pca.explained_variance_ratio_.cumsum());\nplt.title('Cumulative Explained Variance');","ec8e20c7":"from sklearn.manifold import Isomap,LocallyLinearEmbedding,MDS,SpectralEmbedding,TSNE\n\niso = Isomap().fit_transform(scaled)\nlle = LocallyLinearEmbedding().fit_transform(scaled)\nmds = MDS().fit_transform(scaled)\nse = SpectralEmbedding().fit_transform(scaled)\ntsne = TSNE().fit_transform(scaled)\nltsa = LocallyLinearEmbedding(method='ltsa').fit_transform(scaled)\n\n\nplt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1]);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1]);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1]);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1]);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1]);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1]);\nplt.legend(loc='best');\nplt.title('LTSA');","532b1312":"from scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import linkage\nfrom sklearn.cluster import AgglomerativeClustering as agglo\nfrom sklearn.metrics import silhouette_samples\nfrom matplotlib import cm","69cc6820":"dend=dendrogram(linkage(scaled, method='ward'))\nplt.show();","2df65979":"ag=agglo(n_clusters=5, affinity='euclidean',linkage='complete')\nclusters=ag.fit_predict(scaled)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(decomp[:,0], decomp[:,1], hue=clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(scaled,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)\/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)\/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","fd69b966":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('LTSA');","e4a4c05d":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples","e2aa6fef":"inertia=[]\n\nfor i in range(1,11):\n    km=KMeans(n_clusters=i,random_state=33)\n    km.fit(scaled)\n    inertia.append(km.inertia_)\n    \nsns.lineplot(range(1,11),inertia);","2d834f0c":"km=KMeans(n_clusters=2, random_state=33)\nclusters=km.fit_predict(scaled)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(decomp[:,0], decomp[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(scaled,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)\/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)\/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.title('Silhouette Graph');\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","56ced491":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('LTSA');","28317d5f":"km=KMeans(n_clusters=3, random_state=33)\nclusters=km.fit_predict(scaled)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(decomp[:,0], decomp[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(scaled,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)\/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)\/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.title('Silhouette Graph');\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","bc1f463e":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('LTSA');","97fed69d":"km=KMeans(n_clusters=4, random_state=33)\nclusters=km.fit_predict(scaled)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(decomp[:,0], decomp[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(scaled,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)\/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)\/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.title('Silhouette Graph');\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","3eea549f":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('LTSA');","cf0ad211":"km=KMeans(n_clusters=5, random_state=33)\nclusters=km.fit_predict(scaled)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(decomp[:,0], decomp[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(scaled,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)\/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)\/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.title('Silhouette Graph');\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","619e4280":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('LTSA');","a8e81530":"from sklearn.cluster import SpectralClustering\n\nspect = SpectralClustering(n_clusters=5,random_state=33, assign_labels='discretize')\nspect.fit_predict(scaled)\nclusters=spect.labels_\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x=decomp[:,0], y=decomp[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));","1458c776":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('LTSA');","d430361a":"from sklearn.cluster import DBSCAN\n\ndb = DBSCAN(eps=10)\ndb.fit_predict(scaled)\nclusters=db.labels_\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x=decomp[:,0], y=decomp[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(scaled,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)\/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)\/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.title('Silhouette Graph');\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","9bd24a5b":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=clusters);\nplt.legend(loc='best');\nplt.title('LTSA');","a495eb31":"from sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import pairwise\n\n# run GMM\ngmm = GaussianMixture(n_components=4,random_state=42)\ngmm.fit(decomp)\n\n#calculate clusters and plot results\ngmm_means = gmm.means_\ndistances = pairwise.euclidean_distances(decomp,gmm_means)\ngmm_labels = np.argmin(distances,axis=1)\nsns.scatterplot(decomp[:,0],decomp[:,1],hue=gmm_labels);","c3f67e19":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=gmm_labels);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=gmm_labels);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=gmm_labels);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=gmm_labels);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=gmm_labels);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=gmm_labels);\nplt.legend(loc='best');\nplt.title('LTSA');","7132af73":"from Bio.Cluster import somcluster\n\n#run algorithm\nsom_id, som_data = somcluster(decomp, nxgrid=2, nygrid=2, niter=10000,inittau=0.8)\n\n#calculate labels and plot the results\nsom_labels = []\nfor t in som_id:\n    if (t[0] == 0) & (t[1] == 0): som_labels.append(0)\n    elif (t[0] == 0) & (t[1] == 1): som_labels.append(1)\n    elif (t[0] == 1) & (t[1] == 0): som_labels.append(2)\n    else: som_labels.append(3)\n        \nsns.scatterplot(x=decomp[:,0],y=decomp[:,1],hue=som_labels)","d0e3f5e1":"plt.figure(figsize=(14,14))\nplt.subplot(3,2,1)\nsns.scatterplot(x=iso[:,0],y=iso[:,1], hue=som_labels);\nplt.legend(loc='best');\nplt.title('Isomap');\n\nplt.subplot(3,2,2)\nsns.scatterplot(x=lle[:,0],y=lle[:,1], hue=som_labels);\nplt.legend(loc='best');\nplt.title('Locally Linear Embedding');\n\nplt.subplot(3,2,3)\nsns.scatterplot(x=mds[:,0],y=mds[:,1], hue=som_labels);\nplt.legend(loc='best');\nplt.title('MDS');\n\nplt.subplot(3,2,4)\nsns.scatterplot(x=se[:,0],y=se[:,1], hue=som_labels);\nplt.legend(loc='best');\nplt.title('Spectral Embedding');\n\nplt.subplot(3,2,5)\nsns.scatterplot(x=tsne[:,0],y=tsne[:,1], hue=som_labels);\nplt.legend(loc='best');\nplt.title('t-SNE');\n\nplt.subplot(3,2,6)\nsns.scatterplot(x=ltsa[:,0],y=ltsa[:,1], hue=som_labels);\nplt.legend(loc='best');\nplt.title('LTSA');","44e92d4d":"print('sample assigned to grid-point: ',som_id[0])\nsns.heatmap(som_data[:,:,0],cmap='inferno',annot=True);","d2ce84d7":"Other Dimensionality Reduction Visualizations","0703bc3e":"## Gaussian Mixture Model","156e0964":"On the cell below (drawn for the first sample), the heatmap represents the four-point grid of our SOM. As a sample is fed into it, the neurons get activated, and the one with the highest activation is where the sample is assigned to.","d0bd06cf":"The last clustering technique we will examine is Kohonen's Self-Organizing Map. It is a neural network where the neurons are spread across a grid and connected to every input. As data samples come in, the neurons \"compete\" to be activated, with only one neuron being activated for each sample. Each neuron represents one cluster, and each sample is assigned to the neuron which is activated.  \n\nThere is some level of stochasticity involved in this algorithm, and it may produce different results each time it is run.\n\nLet's try it out for 4 clusters and see what it looks like.","2676fcec":"4 clusters","0d31e9b8":"## DBSCAN","b9599f03":"[The silhouette graphs use code taken from Sebastian Raschka's book *Python Machine Learning*]","0d8674c9":"Agglomerative clustering is popular in bioinformatics because you can visualize the clusters as dendrograms, giving explainability to the task. You start by treating each sample as an individual cluster, then merge the closest cluster-pairs until they are merged into one, or into a predefined number of clusters.","1e01762b":"We have a gene expression dataset, and we will cluster similar genes together.\n\nAfter some simple initial exploration we will apply six clustering algorithms: Agglomerative\/hierarchical, k-means, spectral clustering, DBSCAN, Gaussian Mixture Model, and Self-Organising Maps. Sort descriptions of the algorithm will be given in each section.\n\nTo visualize the clustering results we will be using seven dimensionality reduction techniques: PCA, Isomap, Locally Linear Embedding, LTSA, MDS, Spectral Embedding, and t-SNE.","14a25be5":"3 clusters","4c0172d7":"# Clustering","e9c43e76":"The dark blue region in the above silhouette graph represents samples the algorithm considered as particularly noisy, outliers. These samples are assigned to cluster number -1.","dd0cbcb8":" 2 clusters","6473eaf1":"PCA","2f7681df":"The elbow graph above suggests that the optimal number of clusters is 2 (we are looking for the point where the line takes a sharp turn), but this is too few.\n\nWe will go ahead and try out different cluster numbers.","172494fe":"## Spectral Clustering","cc0a3c41":"From the above graph,it seems that five clusters (imagine an horizontal line at around y=60) might be a good choice. Let's do the clustering.","d6093186":"## Data Exploration and Visualization","863f8e6f":"A GMM tries to compute a mixture of multi-dimensional probability distributions that best model the data. It assumes ellipsoid, rather than spherical, cluster shapes. Strictly speaking, it not a clustering but a density estimation algorithm, although widely used for clustering as well.","93cc6e5e":"K-means is the most common clustering algorithm. You start by randomly picking *k* center points and assigning each sample to the nearest centroid. You then move the centroids to the centers of their sample-populations and repeat the process, assigning samples to the closest point, moving the point to the center of each new population until, ideally, equillibrium is reached.","2f805627":"Spectral clustering is a type of kernelized k-means that takes more flexible shapes (k-means assumes spherical cluster shapes) by transforming the data into higher-dimensional representations.","cf8b6d92":"# Yeast Gene Clustering","da4b84f8":"## Agglomerative","3936a7eb":"5 clusters","5e0419d5":"DBSCAN is a density-based clustering method. It does not perform the clustering based on distances, but on density (ie. how many points lie inside an area). It does not assume spherical clusters, and is insensitive to outliers.","242c8917":"## Self-Organising Maps","86bc041a":"## K-means"}}