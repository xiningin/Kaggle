{"cell_type":{"776c234d":"code","d0e2b9bc":"code","ec6a68a8":"code","95dc2d39":"code","ff6ed8fe":"code","055f33ed":"code","c442c457":"code","021d0e46":"code","3c78b701":"code","9ba0ae1b":"code","35961408":"code","ab37d949":"code","02c318ba":"code","c25fd350":"code","fbf8a94e":"code","9d5de4cd":"code","683e6938":"code","30785b10":"code","61b7e47a":"code","52969949":"code","d78867d0":"code","b13e48b1":"code","121c97f6":"code","90d1650e":"code","2178c93c":"code","d3276bbe":"code","c322ee06":"code","8ab10c2c":"code","06fc34bd":"code","90172b04":"code","aea9b1c5":"code","5b7749d1":"markdown","f2fd587c":"markdown","25b75e87":"markdown","a4bd3fee":"markdown","4ca543cf":"markdown","cec3d8fe":"markdown","6bab9f1d":"markdown","9b51a3dd":"markdown","61ba6a2b":"markdown","d7d2e175":"markdown","e2940be0":"markdown","69727aa0":"markdown","031612ab":"markdown","baccbbf5":"markdown","afb28ef4":"markdown","ef9883e8":"markdown","b6638d83":"markdown","52916cef":"markdown","1bc1bdd3":"markdown","8e3e3b8c":"markdown","bb1aa9ca":"markdown","25393614":"markdown","8ede75a4":"markdown","7ce3f8f3":"markdown","0e5cb50c":"markdown","c975d21c":"markdown","58f05c1d":"markdown","9b0c78ab":"markdown","f4678e8d":"markdown","8546c589":"markdown"},"source":{"776c234d":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport itertools\nimport warnings\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix\n\nwarnings.filterwarnings('ignore')","d0e2b9bc":"review = pd.read_csv(\"..\/input\/scotch_review.csv\")\nreview.shape","ec6a68a8":"review.head()","95dc2d39":"review.rename(columns={'Unnamed: 0':'S No'},inplace=True)","ff6ed8fe":"review.head()\n","055f33ed":"review.info()","c442c457":"review['category'].unique()","021d0e46":"plt.figure(figsize=(8,8))\nsns.distplot(review['review.point'],color='red')\nplt.title('Distribution of review points over 5 categories')\nplt.xlabel('Points')\nplt.ylabel('Freq')","3c78b701":"plt.figure(figsize=(8,8))\np=sns.boxplot(review['category'],review['review.point'],palette=sns.color_palette(palette='Set3'))\np.set_xticklabels(p.get_xticklabels(),rotation=90)\nplt.title(\"Boxplot of Review Vs Category\",size=16)\nplt.xlabel('Category',size=10)\nplt.ylabel('Review Score',size=10)","9ba0ae1b":"review_length = pd.DataFrame(review.groupby('category')['description'].count().sort_values(ascending=False))\nreview_length.reset_index(inplace = True)\nreview_length.head()","35961408":"plt.figure(figsize=(10,6))\nsns.barplot(review_length.category, review_length.description,palette=sns.color_palette(palette='cool'))\nplt.xticks(rotation='vertical')\nplt.ylabel('Number of Words', fontsize=12)\nplt.xlabel('Category Name', fontsize=12)\nplt.title('Total Review Count by Category')\nplt.show()","ab37d949":"##Code inspiration - https:\/\/www.kaggle.com\/sudalairajkumar\/simple-feature-engg-notebook-spooky-author\n\ngrouped_df = review.groupby('category')\nfor name, group in grouped_df:\n    print(\"Author name : \", name)\n    cnt = 0\n    for ind, row in group.iterrows():\n        print(row[\"description\"])\n        print(\"\\n\")\n        cnt += 1\n        if cnt == 2:\n            break\n    \n    print(\"\\n\\n\")","02c318ba":"### Create a list for each category\n\nSMS=review[review.category==\"Single Grain Whisky\"]['description'].values\nBSW=review[review.category=='Blended Scotch Whisky']['description'].values\nBMSW=review[review.category=='Blended Malt Scotch Whisky']['description'].values\nSGW=review[review.category=='Single Grain Whisky']['description'].values\nGSW=review[review.category=='Grain Scotch Whisky']['description'].values","c25fd350":"#Creating a function for worcloud \n#Code inspiration:https:\/\/www.kaggle.com\/duttadebadri\/analysing-the-olympics-for-last-120-yrs\/notebook & Nick Brooks from comments ..\n\nfrom wordcloud import WordCloud,STOPWORDS\nstopwords=set(STOPWORDS)\ndef show_wordcloud(data,title=None):\n    wc=WordCloud(background_color=\"black\", max_words=10000,stopwords=STOPWORDS, max_font_size= 40)\n    wc.generate(\" \".join(data))\n    fig=fig = plt.figure(figsize=[8,5], dpi=80)\n    plt.axis('off')\n    if title:\n        fig.suptitle(title,fontsize=16)\n        fig.subplots_adjust(top=1)\n        plt.imshow(wc.recolor( colormap= 'Pastel2' , random_state=17), alpha=1,interpolation='bilinear')\n        plt.show()\n        \n\n        \n","fbf8a94e":"show_wordcloud(SMS,title=\"Wordcloud for Single Grain Whisky\")","9d5de4cd":"show_wordcloud(BSW,title=\"Wordcloud for Blended Scotch Whisky\")","683e6938":"show_wordcloud(BMSW,title=\"Wordcloud for Blended Malt Scotch Whisky\")","30785b10":"show_wordcloud(SGW,title=\"Wordcloud for Single Grain Whisky\")","61b7e47a":"show_wordcloud(GSW,title=\"Wordcloud for Grain Scotch Whisky\")","52969949":"### Creating the features \n\nreview['count_word']=review[\"description\"].apply(lambda x: len(str(x).split()))\nreview['count_stopwords']=review['description'].apply(lambda x:len([w for w in str(x).lower().split() if w in stopwords]))\nreview['count_punct']=review['description'].apply(lambda x:len([p for p in str(x) if p in string.punctuation]))","d78867d0":"plt.figure(figsize=(15,12))\n\nplt.subplot(221)\ng = sns.boxplot(x=review['category'],y=review['count_word'],palette=sns.color_palette(palette=\"Set1\"))\ng.set_title(\"Distribution of words in each sentences by category\", fontsize=15)\ng.set_xticklabels(g.get_xticklabels(),rotation=90)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Count\", fontsize=12)\n\nplt.subplot(222)\ng1 = sns.boxplot(x=review['category'],y=review['count_stopwords'],palette=sns.color_palette(palette=\"dark\"))\ng1.set_title(\"Distribution of stopwords in each sentences by category\", fontsize=15)\ng1.set_xticklabels(g1.get_xticklabels(),rotation=90)\ng1.set_xlabel(\"\")\ng1.set_ylabel(\"Count\", fontsize=12)\n\nplt.subplots_adjust(wspace = 1, hspace = 0.6,top = 0.9)","b13e48b1":"review.head()","121c97f6":"### Code inspiration - 1.https:\/\/www.kaggle.com\/juanumusic\/to-predict-or-not-to-predict-python-tutorial - Very neat and exploratory kernel.Do check out.\n### 2.https:\/\/stackoverflow.com\/questions\/47557417\/understanding-text-feature-extraction-tfidfvectorizer-in-python-scikit-learn\n\n\n### Creating count vectoriser:\nvect=CountVectorizer(ngram_range=(1,1),analyzer='word',stop_words=stopwords,token_pattern=r'\\w{1,}')\nreview_vect = vect.fit_transform(review['description'])\nreview_vect.get_shape()","90d1650e":"tf_idf=TfidfVectorizer(ngram_range=(1,1),stop_words=stopwords,analyzer='word',token_pattern=r'\\w{1,}')\nreview_tfidf=tf_idf.fit_transform(review['description'])\nreview_tfidf.get_shape()","2178c93c":"### Split into train and test data:\n## Count Vectorizer model:\nx_train_vec,x_test_vec,y_train_vec,y_test_vec=train_test_split(review_vect,review['category'],train_size=0.8,random_state=100)","d3276bbe":"### Applying the Multinomial Logistic Regression :\n\nlogit=LogisticRegression(class_weight='balanced',multi_class='multinomial',solver='lbfgs')\nlogit.fit(x_train_vec,y_train_vec)\nlogit.get_params()\n","c322ee06":"### Test over the data:\npredictions=logit.predict(x_test_vec)\n\n##Checking the accuracy:\nprint(\"Accuracy Score with count Vectorizer: {:0.3f}\".format(accuracy_score(predictions,y_test_vec)))\n","8ab10c2c":"conf_matrix_vec=confusion_matrix(y_test_vec,predictions)\n\n### Confusion Matrix: \n\n### Code Source - http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Greens):\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if 'd' else '0'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","06fc34bd":"np.set_printoptions(precision=2)\nplt.figure(figsize=(8,8))\nplot_confusion_matrix(conf_matrix_vec, classes=['Blended Scotch Whisky', 'Single Malt Scotch','Blended Malt Scotch Whisky', 'Grain Scotch Whisky','Single Grain Whisky'],\n                      title='Confusion matrix for Count Vectorizer Model')\nplt.show()","90172b04":"## We implement similar approach with TFIDF.\n# Split into train and test:\n\nx_train_tf,x_test_tf,y_train_tf,y_test_tf=train_test_split(review_tfidf,review['category'],train_size=0.8,random_state=100)\n\n### Applying the Multinomial Logistic Regression :\n\nlogit=LogisticRegression(class_weight='balanced',multi_class='multinomial',solver='lbfgs')\nlogit.fit(x_train_tf,y_train_tf)\n#logit.get_params()\n\n### Test over the data:\npredictions=logit.predict(x_test_tf)\n\n##Checking the accuracy:\nprint(\"Accuracy Score with count Vectorizer: {:0.3f}\".format(accuracy_score(predictions,y_test_tf)))\n","aea9b1c5":"conf_matrix_vec=confusion_matrix(y_test_tf,predictions)\n\n\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(8,8))\nplot_confusion_matrix(conf_matrix_vec, classes=['Blended Scotch Whisky', 'Single Malt Scotch','Blended Malt Scotch Whisky', 'Grain Scotch Whisky','Single Grain Whisky'],\n                      title='Confusion matrix for TFIDF Model')\nplt.show()","5b7749d1":"We find that there are 5 unique categories in the dataframe.Lets understand about the distribution of review points.","f2fd587c":"### Modelling with Count Vectorizer","25b75e87":"### Category Distribution:","a4bd3fee":"Coming to distribution of words,we find that the median is not varying much across the categories.Same effect is observed in the case of stopwords.","4ca543cf":"### Objective of the notebook:\nIn this notebook, let us try to create a model that will identify the category of the wine based on the reviews.\n\nAs a first step, we will do some basic data visualization and cleaning before we delve deep into the model.","cec3d8fe":"### Multinomial Logistic Regression:","6bab9f1d":"We find that Single Malt Scotch has had maximum representation where as for other categories reviews are too .","9b51a3dd":"### Check with test data and visualise the metrics:","61ba6a2b":"## Conclusion:","d7d2e175":"From all these wordclouds,we understand that the review words do not differ much . Vanilla,apple,sweet,flavor have appeared in almost all the reviews.","e2940be0":"Lets analyze the frequency distribution of each of the category of whinery to understand if they are significantly different.","69727aa0":"* Median review score for each of the whisky category is above 85.\n\n* Not much outliers are detected except for Single Malt Scotch where there are many outliers at lower end.Probably,this wine might not have found good takers.\n\n* Maximum review score hovers well above 95 by Blended Scotch Whisky.","031612ab":"### Comparision:","baccbbf5":"**Thanks for reading my kernel.If you like pls upvote.Appreciate your comments too.**","afb28ef4":"# Wine Reviews Analysis","ef9883e8":"From both the models, we find that at the level of accuracy there is only 0.2% difference.In the confusion matrix we understand that there is a slight improvement in predicting single malt scotch from its reviews.","b6638d83":"### Word Frequency Distribution:","52916cef":"The distribution is almost a normal curve where the mode is centered around 85-90 .","1bc1bdd3":"Preview the data again:","8e3e3b8c":"#### Unique Categories:","bb1aa9ca":"In this kernel,a basic take on how to classify wine categories from their reviews was discussed.Multiclass logit model was applied to two text based features - Count Vectorizer and Term Frequency-Inverse Document Frequency Models.Some ways to improve the model could be to include the derived features like word count,stopword count etc we created during our EDA.Multinomial Naive Bayes,KNN,Decision Tree algorithms can be applied to study which algorithm performs better.","25393614":"We build two models- Count Vectorizer and TFIDF and compare the accuracy.The data used for training are only text based features - namely the description column.","8ede75a4":"Before deep diving into wordcloud,let us try to print few reviews for each of the categories to get an fair overview of what to expect in wordcloud.","7ce3f8f3":"### Word Cloud for each category:","0e5cb50c":"### Modelling :","c975d21c":"### Review Count Vs Category","58f05c1d":"We achieve an accuracy of 86.9%.Lets visualise the confusion matrix.","9b0c78ab":"### Loading the libraries and dataset ","f4678e8d":"### Modelling with TFIDF :","8546c589":"From the glimpse of the data,column 1 can be renamed to S.No."}}