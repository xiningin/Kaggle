{"cell_type":{"23f367fd":"code","b7ccfdb7":"code","496a072b":"code","d190af80":"code","b81cf29c":"code","c233715c":"code","4944d96b":"code","ce89bcc9":"code","f3ae0570":"code","459e6fce":"code","17b7ade5":"code","18fce37e":"code","4846a408":"code","94b448ff":"code","792254c6":"code","a602e285":"code","dd64c88c":"code","60f5a6f9":"code","ad571ae7":"code","0b18ab7c":"code","9c8f2017":"code","1264a770":"code","03e1985c":"code","7024b889":"code","55a46e7f":"code","40532d73":"code","b92ba220":"code","c03ebb4c":"code","92c23ff0":"code","de662903":"code","458c3a0f":"code","e9abea7f":"code","45b88a6c":"code","1ebc8bb1":"code","7e007436":"code","83ba59c9":"code","37fa21e7":"code","2dbd9df9":"code","7c637f3d":"code","753ff503":"code","480264b7":"markdown","562c1d5e":"markdown","a5404a33":"markdown","f25909a1":"markdown","4285d4e8":"markdown","b549c04b":"markdown","8443c8cb":"markdown","52fd6ae6":"markdown","64c8fdc1":"markdown","e2765ee3":"markdown","7dcface2":"markdown","45c07a35":"markdown","402d561d":"markdown"},"source":{"23f367fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7ccfdb7":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\n\nfrom datetime import datetime\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","496a072b":"import warnings\nwarnings.filterwarnings('ignore')","d190af80":"matplotlib.rcParams.update({'font.size': 14})","b81cf29c":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","c233715c":"TRAIN_DATASET_PATH = '..\/input\/real-estate-price-prediction-moscow\/train.csv'\nTEST_DATASET_PATH = '..\/input\/real-estate-price-prediction-moscow\/test.csv'","4944d96b":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntrain_df.tail()","ce89bcc9":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\ntrain_df = reduce_mem_usage(train_df)\n\ntrain_df.info()","f3ae0570":"train_df.describe()","459e6fce":"test_df = pd.read_csv(TEST_DATASET_PATH)\ntest_df.tail()","17b7ade5":"train_df['Id'] = train_df['Id'].astype(str)\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(str)","18fce37e":"class DataPreprocessing:\n    \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n    def __init__(self):\n        \"\"\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043a\u043b\u0430\u0441\u0441\u0430\"\"\"\n        self.medians = None\n        self.social_3_max = None\n        self.mean_life = None\n        \n    def fit(self, X):\n        \"\"\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\"\"\"       \n        # \u0420\u0430\u0441\u0447\u0435\u0442 \u043c\u0435\u0434\u0438\u0430\u043d\n        self.medians = X.median()\n        self.social_3_max = X['Social_3'].quantile(.975)\n        self.mean_life = (X['LifeSquare'].median()) \/ (X['Square'].median())\n    \n    def transform(self, X):\n        \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n        # Healthcare_1\n        # \u0423\u0434\u0430\u043b\u0438\u043c \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c, \u0433\u0434\u0435 \u043d\u0435\u0442 \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u044b \u0434\u0430\u043d\u043d\u044b\u0445\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n        #Square\n        # \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043c \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u0443\u044e \u043e\u0431\u0449\u0443\u044e \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u0440\u0430\u0432\u043d\u0443\u044e 20\n        X['Square_outlier'] = 0\n        X.loc[X['Square']<20, 'Square_outlier'] = 1\n        X.loc[X['Square']<20, 'Square'] = 20\n        \n        # LifeSquare\n        # \u0416\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043d\u0435 \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0435 400 \u0438 \u043c\u0435\u043d\u044c\u0448\u0435 12. \u0417\u0430\u043c\u0435\u043d\u0438\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u043d\u0443\u044e \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043d\u0430 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0435 \u043e\u0431\u0449\u0435\u0439 \u043a \u0436\u0438\u043b\u043e\u0439\n        X['LifeSquare_outlier'] = X['LifeSquare'].isna() * 1\n        X.loc[(X['LifeSquare']>400) | (X['LifeSquare']<12) | (X['LifeSquare']>X['Square']), 'LifeSquare_outlier'] = 1\n        X.loc[(X['LifeSquare'].isnull()) | (X['LifeSquare']<12), 'LifeSquare'] = X.Square * self.mean_life\n        X.loc[X['LifeSquare']>400, 'LifeSquare'] = 400\n        X.loc[(X.LifeSquare>X.Square), 'Square'] = X.LifeSquare\n        \n        #KitchenSquare\n        # \u0417\u0430\u043c\u0435\u043d\u0438\u043c \u043d\u0430 10% \u043e\u0442 \u043e\u0431\u0449\u0435\u0439 \u043f\u043b\u043e\u0449\u0430\u0434\u0438 \u0432\u044b\u0431\u0440\u043e\u0441\u043d\u0443\u044e \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0443\u0445\u043d\u0438\n        X['Kitchen_outlier'] = 0\n        X.loc[(X.KitchenSquare>100), 'Kitchen_outlier'] = 1\n        X.loc[(X.KitchenSquare>100), 'KitchenSquare'] = X.Square * 0.1\n           \n        # Rooms\n        # \u0417\u0430\u043c\u0435\u043d\u0438\u043c \u043d\u0430 \u043c\u0435\u0434\u0438\u0430\u043d\u0443 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b \u0441 0 \u043a\u043e\u043c\u043d\u0430\u0442\n        X['Rooms_outlier'] = 0\n        X.loc[X['Rooms'] == 0, 'Rooms_outlier'] = 1\n        X.loc[X['Rooms'] == 0, 'Rooms'] = self.medians['Rooms']\n        \n        # Social_3\n        # \u0417\u0430\u043c\u0435\u043d\u0438\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043a\u0432\u0430\u043d\u0442\u0438\u043b\u0435\u0439\n        X.loc[(X.Social_3>self.social_3_max), 'Social_3'] = self.medians['Social_3']\n        \n        # HouseFloor, Floor\n        # \u0417\u0430\u043c\u0435\u043d\u0438\u043c \u044d\u0442\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u0442\u0430\u043c, \u0433\u0434\u0435 \u0432 \u0434\u043e\u043c\u0435 0 \u044d\u0442\u0430\u0436\u0435\u0439 \u0438\u043b\u0438 \u044d\u0442\u0430\u0436 \u0431\u043e\u043b\u044c\u0448\u0435 \u0436\u0442\u0430\u0436\u043d\u043e\u0441\u0442\u0438 \u0434\u043e\u043c\u0430\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        \n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\\\n                                            .apply(lambda x: random.randint(1, x))\n        \n        # HouseYear\n        # \u0418\u0441\u043a\u043b\u044e\u0447\u0438\u043c \u0434\u043e\u043c\u0430 \u0438\u0437 \u0431\u0443\u0434\u0443\u0449\u0435\u0433\u043e\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # FloorYear\n        # \u0417\u0430\u043c\u0435\u043d\u0438\u043c \u043d\u0430 \u043c\u0435\u0434\u0438\u0430\u043d\u0443 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c \u044d\u0442\u0430\u0436\u043d\u043e\u0441\u0442\u0438 \u0434\u043e\u043c\u043e\u0432, \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u044b\u0445 \u0440\u0430\u043d\u044c\u0448\u0435 1980 \u0433\u043e\u0434\u0430, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0443\u043a\u0430\u0437\u0430\u043d\u043e \u0431\u043e\u043b\u0435\u0435 50 \u044d\u0442\u0430\u0436\u0435\u0439\n        X.loc[(X['HouseFloor']>50)&(X['HouseYear']<1990), 'Floor'] = self.medians['HouseFloor']\n                \n        return X","4846a408":"train_preprocessor = DataPreprocessing()\ntrain_preprocessor.fit(train_df)\ntrain_preprocessor.transform(train_df)\ntrain_df.describe()","94b448ff":"train_df.replace(['A', 'B'], [1, 0], inplace=True)","792254c6":"train_df['price_for_metr'] = train_df.Price\/train_df.Square","a602e285":"med_price_by_district_metr = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'price_for_metr':'median'}).rename(columns={'price_for_metr':'MedPriceByDistrict'})\n\nmed_price_by_district_metr","dd64c88c":"train_df = train_df.merge(med_price_by_district_metr, on=['DistrictId', 'Rooms'], how='left')\ntrain_df","60f5a6f9":"def age_to_cat(X):\n\n    X['age_cat'] = 0\n\n    X.loc[X['HouseYear'] >= 2016, 'age_cat'] = 1  \n    X.loc[(X['HouseYear'] < 2016) & (X['HouseYear'] >= 2011), 'age_cat'] = 2\n    X.loc[(X['HouseYear'] < 2011) & (X['HouseYear'] >= 1996), 'age_cat'] = 3\n    X.loc[X['HouseYear'] < 1996, 'age_cat'] = 4\n\n    return X\n\nage_to_cat(train_df)\n\ntrain_df.head()","ad571ae7":"train_df['limit_floor'] = 0\n\ntrain_df.loc[(train_df['Floor']==1)|(train_df['Floor']==train_df['HouseFloor']), 'limit_floor'] = 1\n\ntrain_df.head()","0b18ab7c":"class FeatureGenetator():\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447\"\"\"\n    \n    def __init__(self):\n        self.med_price_by_district_metr = None\n                \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        \n        # Target encoding\n        ## District, Rooms\n        df = X.copy()\n            \n        if y is not None:\n            df['Price'] = y.values\n            \n            df['price_for_metr']=df.Price\/df.Square\n            \n            self.med_price_by_district_metr = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'price_for_metr':'median'})\\\n                                            .rename(columns={'price_for_metr':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district_metr['MedPriceByDistrict'].median()\n            \n         \n        \n    def transform(self, X):\n        \n        # Ecology\n        X.replace(['A', 'B'], [1, 0], inplace=True)\n                        \n        # Target encoding\n        if self.med_price_by_district_metr is not None:\n            X = X.merge(self.med_price_by_district_metr, on=['DistrictId', 'Rooms'], how='left')\n            X['MedPriceByDistrict'].fillna(self.med_price_by_district_median, inplace=True)\n            \n        # Floor_cat\n        X['limit_floor'] = 0\n\n        X.loc[(X['Floor']==1)|(X['Floor']==X['HouseFloor']), 'limit_floor'] = 1\n         \n        # Age_cat   \n        X['age_cat'] = 0\n\n        X.loc[X['HouseYear'] >= 2016, 'age_cat'] = 1  \n        X.loc[(X['HouseYear'] < 2016) & (X['HouseYear'] >= 2011), 'age_cat'] = 2\n        X.loc[(X['HouseYear'] < 2011) & (X['HouseYear'] >= 1996), 'age_cat'] = 3\n        X.loc[X['HouseYear'] < 1996, 'age_cat'] = 4\n\n        return X","9c8f2017":"train_df.columns.tolist()","1264a770":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear', 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3', 'Helthcare_2', 'Shops_1', 'Shops_2']\nnew_feature_names = ['Square_outlier', 'LifeSquare_outlier', 'Kitchen_outlier', 'Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier', 'MedPriceByDistrict', 'age_cat', 'limit_floor']\ntarget_name = 'Price'","03e1985c":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\nX = train_df.drop(columns=target_name)\ny = train_df[target_name]","7024b889":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=42)","55a46e7f":"preprocessor = DataPreprocessing()\npreprocessor.fit(X_train)\n\nX_train = preprocessor.transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ntest_df = preprocessor.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","40532d73":"features_gen = FeatureGenetator()\nfeatures_gen.fit(X_train, y_train)\n\nX_train = features_gen.transform(X_train)\nX_valid = features_gen.transform(X_valid)\ntest_df = features_gen.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","b92ba220":"X_train = X_train[feature_names + new_feature_names]\nX_valid = X_valid[feature_names + new_feature_names]\ntest_df = test_df[feature_names + new_feature_names]","c03ebb4c":"X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()","92c23ff0":"from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import mean_squared_error as mse, r2_score as r2","de662903":"gb_model = GradientBoostingRegressor(criterion='mse',\n                                     max_depth=5,\n                                     min_samples_leaf=10,\n                                     random_state=42,  \n                                     n_estimators=200)\ngb_model.fit(X_train, y_train)","458c3a0f":"y_train_preds = gb_model.predict(X_train)\ny_test_preds = gb_model.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","e9abea7f":"cv_score = cross_val_score(gb_model, X_train, y_train, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=21))\ncv_score","45b88a6c":"cv_score.mean()","1ebc8bb1":"feature_importances = pd.DataFrame(zip(X_train.columns, gb_model.feature_importances_), \n                                   columns=['feature_name', 'importance'])\n\nfeature_importances.sort_values(by='importance', ascending=False)","7e007436":"test_df.shape","83ba59c9":"test_df","37fa21e7":"submit = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/sample_submission.csv')\nsubmit.head()","2dbd9df9":"predictions = gb_model.predict(test_df)\npredictions","7c637f3d":"submit['Price'] = predictions\nsubmit.head()","753ff503":"submit.to_csv('rf_submit.csv', index=False)","480264b7":"**\u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435**","562c1d5e":"**\u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438**\n\n\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435","a5404a33":"**\u041e\u0442\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432**","f25909a1":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044e \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430 \u0434\u043e\u043c\u0430, \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u0432 \u0434\u043e\u043c\u0430 \u043d\u0430 4 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438","4285d4e8":"\u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","b549c04b":"**\u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432**","8443c8cb":"**\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445**","52fd6ae6":"\u0412\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","64c8fdc1":"**\u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 train \u0438 test**","e2765ee3":"\u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f","7dcface2":"\u0417\u0430\u043c\u0435\u043d\u0438\u043c A, B \u0432 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f\u0445 Ecology_2,3 \u0438 Shops_2 \u043d\u0430 0 \u0438 1","45c07a35":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u0438\u043b\u0438 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u044d\u0442\u0430\u0436\u0430","402d561d":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043d\u043e\u0433\u043e \u043c\u0435\u0442\u0440\u0430"}}