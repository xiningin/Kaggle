{"cell_type":{"15808b6f":"code","1a97653e":"code","4079512e":"code","c1e34e3d":"code","11930996":"code","63c399c7":"code","e8799fbc":"code","45a01f17":"code","2a06835d":"code","08426ed5":"code","ba592e80":"code","ae8819c1":"code","6a99de98":"code","0546cf07":"code","c86e825f":"code","c60adac5":"code","7e7086a0":"code","9539442e":"code","9c255e37":"code","32a3106b":"code","76fe022d":"code","74128eac":"code","7ea94004":"code","6ced9997":"code","1212fd84":"code","920da141":"code","21bb58bb":"code","99df3bbe":"code","30550aae":"code","05087983":"code","e57e7b27":"code","8c647bcb":"code","54fb0d35":"code","47488afc":"code","f4bf02c4":"code","ba5a6889":"code","4fa4fa50":"code","868239b9":"code","134ce579":"code","2bc5a5af":"markdown","8d334dd2":"markdown","1acd4128":"markdown","dda74b9a":"markdown","b39dab86":"markdown","968a5bf7":"markdown","a73e0020":"markdown","a5d57d5f":"markdown","068dd5ea":"markdown","68ecb4a5":"markdown","71050838":"markdown","380db2d5":"markdown","87939f09":"markdown"},"source":{"15808b6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_predict, cross_val_score, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\n\nimport os\n%matplotlib inline\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1a97653e":"dtrain = pd.read_csv('..\/input\/ghouls-goblins-and-ghosts-boo\/train.csv.zip')\ndtest = pd.read_csv('..\/input\/ghouls-goblins-and-ghosts-boo\/test.csv.zip')","4079512e":"dtrain.head()","c1e34e3d":"dtrain.info()","11930996":"dtrain.shape","63c399c7":"dtrain.describe()","e8799fbc":"f,ax = plt.subplots(1,4, figsize=(15,3))\n\nsns.distplot(dtrain['bone_length'], ax = ax[0])\nsns.distplot(dtrain['rotting_flesh'], ax = ax[1], color = 'r')\nsns.distplot(dtrain['hair_length'], ax = ax[2], color = 'g')\nsns.distplot(dtrain['has_soul'], ax = ax[3], color = 'purple')\n\nplt.show()","45a01f17":"f,ax = plt.subplots(1,4, figsize=(15,3))\n\nsns.distplot(np.log(dtrain['bone_length']), ax = ax[0])\nsns.distplot(np.log(dtrain['rotting_flesh']), ax = ax[1], color = 'r')\nsns.distplot(np.log(dtrain['hair_length']), ax = ax[2], color = 'g')\nsns.distplot(np.log(dtrain['has_soul']), ax = ax[3], color = 'purple')\n\nplt.show()","2a06835d":"sns.pairplot(data=dtrain.iloc[:,1:], hue = 'type')","08426ed5":"sns.heatmap(dtrain.drop('id', axis = 1).corr(), square = True, annot = True)","ba592e80":"dtrain['type'].unique()","ae8819c1":"label_encoder = LabelEncoder()\ndtrain['type'] = label_encoder.fit_transform(dtrain['type'])\n# 0 : Ghost\n# 1 : Ghoul\n# 2 : Goblin","6a99de98":"dtrain['type'].unique()","0546cf07":"dtrain['color'].unique()","c86e825f":"d_color = dtrain['color']","c60adac5":"dtrain['clear'] = [1 if d_color[i] == 'clear' else 0 for i in range(len(d_color))]\ndtrain['green'] = [1 if d_color[i] == 'green' else 0 for i in range(len(d_color))]\ndtrain['black'] = [1 if d_color[i] == 'black' else 0 for i in range(len(d_color))]\ndtrain['white'] = [1 if d_color[i] == 'white' else 0 for i in range(len(d_color))]\ndtrain['blue'] = [1 if d_color[i] == 'blue' else 0 for i in range(len(d_color))]\ndtrain['blood'] = [1 if d_color[i] == 'blood' else 0 for i in range(len(d_color))]","7e7086a0":"d_color2 = dtest['color']","9539442e":"dtest['clear'] = [1 if d_color2[i] == 'clear' else 0 for i in range(len(d_color2))]\ndtest['green'] = [1 if d_color2[i] == 'green' else 0 for i in range(len(d_color2))]\ndtest['black'] = [1 if d_color2[i] == 'black' else 0 for i in range(len(d_color2))]\ndtest['white'] = [1 if d_color2[i] == 'white' else 0 for i in range(len(d_color2))]\ndtest['blue'] = [1 if d_color2[i] == 'blue' else 0 for i in range(len(d_color2))]\ndtest['blood'] = [1 if d_color2[i] == 'blood' else 0 for i in range(len(d_color2))]","9c255e37":"dtrain.head()","32a3106b":"dtest.head()","76fe022d":"train = dtrain.copy()\ny = train['type']\nx = train.drop(['id', 'color','type'], axis = 1)","74128eac":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, VotingClassifier","7ea94004":"x_train, x_test, y_train, y_test = train_test_split(x,y,train_size = 0.8, random_state = 0) \nfold = KFold(n_splits = 5)","6ced9997":"scoring = {'accuracy' : make_scorer(accuracy_score), \n           'precision' : make_scorer(precision_score),\n           'recall' : make_scorer(recall_score), \n           'f1_score' : make_scorer(f1_score)}","1212fd84":"ensembles=[]\nensembles.append(('rfc',RandomForestClassifier(n_estimators=10)))\nensembles.append(('abc',AdaBoostClassifier(n_estimators=10)))\nensembles.append(('bc',BaggingClassifier(n_estimators=10)))\nensembles.append(('etc',ExtraTreesClassifier(n_estimators=10)))\n\nresults=[]\nnames=[]\nfor name,model in ensembles:\n    result = cross_val_score(model,x_train,y_train,cv=fold,scoring='accuracy')\n    results.append(result)\n    names.append(name)\n    msg=\"%s : %f (%f)\"%(name,result.mean(),result.std())\n    print(msg)","920da141":"# Random Forest Tuning\nn_estimators=[10,20,30,40,50]\nmax_depth =  [4,6,8,10,12,24]\n\nparam_grid=dict(n_estimators=n_estimators, max_depth=max_depth)\n\nmodel=RandomForestClassifier()\n\nfold=KFold(n_splits=10,random_state=0)\n\ngrid=GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=fold)\ngrid_result=grid.fit(x_train,y_train)\n\nprint(\"Best: %f using %s \"%(grid_result.best_score_,grid_result.best_params_))","21bb58bb":"rf_best_params = grid_result.best_params_","99df3bbe":"# AdaBoost Tuning\nn_estimators=[10,20,30,40,50]\nlearning_rate =  [1.0, 0.1, 0.05, 0.01, 0.001]\nparam_grid=dict(n_estimators=n_estimators, learning_rate=learning_rate)\n\n\nmodel=AdaBoostClassifier()\n\ngrid=GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=fold)\ngrid_result=grid.fit(x_train,y_train)\n\nprint(\"Best: %f using %s \"%(grid_result.best_score_,grid_result.best_params_))","30550aae":"ab_best_params = grid_result.best_params_","05087983":"# Bagging Tuning\nn_estimators=[10,20,30,40,50]\nmax_features =  [2,4,6,8,10]\n\nparam_grid=dict(n_estimators=n_estimators, max_features=max_features)\n\nmodel=BaggingClassifier()\n\ngrid=GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=fold)\ngrid_result=grid.fit(x_train,y_train)\n\nprint(\"Best: %f using %s \"%(grid_result.best_score_,grid_result.best_params_))","e57e7b27":"bc_best_params = grid_result.best_params_","8c647bcb":"# Extra Trees Tuning\nn_estimators=[10,20,30,40,50]\nmax_depth =  [4,6,8,10,12,24]\n\nparam_grid=dict(n_estimators=n_estimators, max_depth=max_depth)\n\nmodel=ExtraTreesClassifier()\n\ngrid=GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=fold)\ngrid_result=grid.fit(x_train,y_train)\n\nprint(\"Best: %f using %s \"%(grid_result.best_score_,grid_result.best_params_))","54fb0d35":"et_best_params = grid_result.best_params_","47488afc":"rf = RandomForestClassifier(**rf_best_params)\net = ExtraTreesClassifier(**et_best_params)\nbc = BaggingClassifier(**bc_best_params)\nab = AdaBoostClassifier(rf, **ab_best_params)\n\nvc = VotingClassifier(estimators=[('et', et), ('rf', rf), ('bc', bc), ('ab', ab)], voting='soft')\n","f4bf02c4":"vc.fit(x_train, y_train)\ny_pred = vc.predict(x_test)\nvc_acc = accuracy_score(y_pred, y_test)\nprint(\"Accuracy score: \", vc_acc)","ba5a6889":"# It's time to predict the data\ny_pred = vc.predict(dtest.drop(['id','color'], axis = 1))\ny_pred","4fa4fa50":"sub = pd.read_csv('..\/input\/ghouls-goblins-and-ghosts-boo\/sample_submission.csv.zip')\nsub['type'] = y_pred\nsub['type'] = sub['type'].map({\n    0:'Ghost',\n    1:'Ghoul',\n    2:'Goblin'\n})","868239b9":"sub","134ce579":"# submit\nsub.to_csv('submission.csv', index = False)","2bc5a5af":"## Exploratory Data Analysis","8d334dd2":"## Feature Engineering","1acd4128":"What about their correlation?","dda74b9a":"The distribution has negative skewness then. Now let's plot them with scatter plot.","b39dab86":"From the above, we can get some information:\n* `hair_length` and `has_soul` have a good positive correlation\n* We also know that `rotting_flesh` has negative correlation with all other features","968a5bf7":"Now it's time to build our model","a73e0020":"We do label encoding to make the ML learn easier.","a5d57d5f":"The `type` feature is in number now. So it's time to encode the `color` feature.","068dd5ea":"## Data Preprocessing","68ecb4a5":"Seems like their distribution is quiet normal. Let see if we use log transformation to our data.","71050838":"First, let's check the distribution","380db2d5":"based on our tuning, Let's use VotingClassifier.","87939f09":"## Modelling"}}