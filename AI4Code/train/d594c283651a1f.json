{"cell_type":{"3a01f5ab":"code","bf8af64f":"code","65d3392d":"code","acb65d95":"code","beffbcdb":"code","3190048e":"code","dd15f0d2":"code","0e757fa4":"code","cfa9f3ee":"code","348ff030":"code","0d851ea4":"code","3f95a2b0":"code","d3c2fb63":"code","d6cd4882":"code","5945d8fa":"code","ce62f150":"code","2e8455c7":"code","9209096b":"code","7360f91e":"code","aa40b90b":"code","fd1f932e":"markdown","497e6b95":"markdown","7fbaa510":"markdown","01d4b37e":"markdown","281911a0":"markdown","b43d4fc8":"markdown","8e308989":"markdown","d03fdcd9":"markdown"},"source":{"3a01f5ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bf8af64f":"!wget https:\/\/raw.githubusercontent.com\/Iamsdt\/60daysofudacity\/master\/day22\/Helper.py","65d3392d":"os.listdir(\"..\/input\/seefood\")","acb65d95":"from PIL import Image\ndata_dir = \"..\/input\/seefood\"\npath = data_dir + \"\/train\/hot_dog\/1000288.jpg\"\nImage.open(path)","beffbcdb":"import Helper\nimport torch\nfrom torchvision import datasets, transforms,models\nfrom torch.utils.data import DataLoader\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transform = transforms.Compose([\n                                transforms.Resize(255),\n                                transforms.RandomResizedCrop(224),\n                                transforms.CenterCrop(224),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ColorJitter(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\ntest_transform = transforms.Compose([\n                                transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntrain_data = datasets.ImageFolder(data_dir+\"\/train\", transform=train_transform)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=64,shuffle=True)\n\ntest_data = datasets.ImageFolder(data_dir+\"\/test\", transform=test_transform)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=64)\n\nprint(len(train_loader))\nprint(len(test_loader))","3190048e":"classes = os.listdir(data_dir+\"\/train\")\nclasses","dd15f0d2":"Helper.visualize(test_loader, classes)","0e757fa4":"model = models.densenet161(pretrained=True)\nmodel.classifier","cfa9f3ee":"model = Helper.freeze_parameters(model)","348ff030":"import torch.nn as nn\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2208, out_features=2208),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=2208, out_features=1024),\n  nn.ReLU(),\n  nn.Dropout(p=0.3),\n  nn.Linear(in_features=1024, out_features=8),\n  nn.LogSoftmax(dim=1)  \n)\n    \nmodel.classifier = classifier\nmodel.classifier","0d851ea4":"import torch.optim as optim\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)","3f95a2b0":"epoch = 5+5","d3c2fb63":"model, train_loss, test_loss = Helper.train(model, train_loader, test_loader, epoch, optimizer, criterion)","d6cd4882":"model = Helper.load_latest_model(model)","5945d8fa":"Helper.check_overfitted(train_loss, test_loss)","ce62f150":"Helper.test(model, test_loader)","2e8455c7":"Helper.test_per_class(model, test_loader, criterion, classes)","9209096b":"from PIL import Image\n\ndef test(file):\n  ids = train_loader.dataset.class_to_idx\n\n  with Image.open(file) as f:\n      img = test_transform(f).unsqueeze(0)\n      with torch.no_grad():\n          out = model(img.to(device)).cpu().numpy()\n          for key, value in ids.items():\n              if value == np.argmax(out):\n                    #name = classes[int(key)]\n                    print(f\"Predicted Label: {key} and value {value}\")\n          plt.imshow(np.array(f))\n          plt.show()","7360f91e":"from PIL import Image\nfrom matplotlib import pyplot as plt\nname = os.listdir(data_dir+\"\/test\/hot_dog\")[6]\nfile = data_dir+'\/test\/hot_dog\/'+name\nprint(file)\n\ntest(file)","aa40b90b":"name = os.listdir(data_dir+\"\/test\/not_hot_dog\")[6]\nfile = data_dir+'\/test\/not_hot_dog\/'+name\nprint(file)\n\ntest(file)","fd1f932e":"# see sample Image","497e6b95":"#  Testing","7fbaa510":"# Load model","01d4b37e":"# Visualize","281911a0":"# Training","b43d4fc8":"# Load helper method","8e308989":"# Prepare Data","d03fdcd9":"# Test single image"}}