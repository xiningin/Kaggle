{"cell_type":{"c5338825":"code","aa2fe25f":"code","13041db0":"code","aefc4ab8":"code","a64ea863":"code","87d9d9d6":"code","ada5196c":"code","ebbd4990":"code","50ff67ea":"code","75ffdc2a":"code","0cbcad30":"code","5bb07785":"code","8cac2a53":"code","d3d2a606":"code","6bc1c14e":"code","a2aaaa89":"code","a49cfb33":"code","a78e82a1":"code","4aef2ffa":"code","ce213622":"code","0f466f56":"code","7c8209f6":"code","a70c00bd":"code","49bcc6f0":"code","702b167f":"code","ff9759ad":"code","4c4c734a":"code","824e0f10":"code","806db263":"code","760ed094":"code","5e6a169e":"code","b79dd079":"code","5d66b05e":"code","839b7c6a":"code","42e97162":"code","efd7b859":"code","4afbbab9":"code","85e65ac9":"code","4d3b5658":"code","35527941":"code","5ba5bc82":"code","30646a55":"code","e5ef1d86":"code","4dc09408":"markdown","fd786c29":"markdown","2f871f34":"markdown","1df71ee8":"markdown","281b482c":"markdown","8fbe4907":"markdown","b2349147":"markdown","9758e6f8":"markdown","f9cbce2f":"markdown","c6a5e305":"markdown","ca303153":"markdown","f29b9830":"markdown","f8261034":"markdown","ace7e980":"markdown","878504e8":"markdown","3d66d921":"markdown","c34c7029":"markdown","8e861a2a":"markdown","651c758b":"markdown","12251e10":"markdown","21191001":"markdown","96da724c":"markdown","4aa2acea":"markdown","0371c928":"markdown","4a6d150b":"markdown","01b51710":"markdown","e32fcd75":"markdown","c2e16fa6":"markdown","2cfc181e":"markdown","ceb8302b":"markdown","aa7525ee":"markdown","d688688c":"markdown","6cd96c40":"markdown","5038ac7f":"markdown","ec227fe0":"markdown","5c18b5bf":"markdown","1e327cee":"markdown","3c302ddf":"markdown","f8bc2503":"markdown","02a543cb":"markdown","7f6aed8b":"markdown","a3c403cb":"markdown","b0fe80c0":"markdown","3a5e9612":"markdown","89a71847":"markdown"},"source":{"c5338825":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom datetime import datetime","aa2fe25f":"from google.colab import drive\ndrive.mount('\/content\/drive')","13041db0":"#Import the data set\ndf = pd.read_csv('\/content\/drive\/MyDrive\/ratings_Electronics.csv', header=None) #There are no headers in the data file\n\ndf.columns = ['user_id', 'prod_id', 'rating', 'timestamp'] #Adding column names\n\ndf = df.drop('timestamp', axis=1) #Dropping timestamp\n\ndf_copy = df.copy(deep=True) #Copying the data to another dataframe","aefc4ab8":"# see few rows of the imported dataset\ndf.head()","a64ea863":"# Check the number of rows and columns\nrows, columns = df.shape\nprint(\"No of rows: \", rows) \nprint(\"No of columns: \", columns) ","87d9d9d6":"#Check Data types\ndf.dtypes","ada5196c":"# Find number of missing values in each column\n(df.isna().sum()\/df.shape[0])*100","ebbd4990":"# Summary statistics of 'rating' variable\ndf['rating'].describe()","50ff67ea":"#Create the plot and provide observations\n\nplt.figure(figsize = (12,6))\ndf['rating'].value_counts(1).plot(kind='bar')\nplt.xlabel('Rating')\nplt.ylabel('Count')\nplt.show()","75ffdc2a":"# Number of unique user id and product id in the data\nprint('Number of unique USERS in Raw data = ', df['user_id'].nunique())\nprint('Number of unique ITEMS in Raw data = ', df['prod_id'].nunique())","0cbcad30":"# Top 10 users based on rating\nmost_rated = df.groupby('user_id').size().sort_values(ascending=False)[:10]\nmost_rated","5bb07785":"counts = df['user_id'].value_counts()\ndf_final = df[df['user_id'].isin(counts[counts >= 50].index)]","8cac2a53":"print('The number of observations in the final data =', len(df_final))\nprint('Number of unique USERS in the final data = ', df_final['user_id'].nunique())\nprint('Number of unique PRODUCTS in the final data = ', df_final['prod_id'].nunique())","d3d2a606":"#Creating the interaction matrix of products and users based on ratings and replacing NaN value with 0\nfinal_ratings_matrix = df_final.pivot(index = 'user_id', columns ='prod_id', values = 'rating').fillna(0)\nprint('Shape of final_ratings_matrix: ', final_ratings_matrix.shape)\n\n#Finding the number of non-zero entries in the interaction matrix \ngiven_num_of_ratings = np.count_nonzero(final_ratings_matrix)\nprint('given_num_of_ratings = ', given_num_of_ratings)\n\n#Finding the possible number of ratings as per the number of users and products\npossible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]\nprint('possible_num_of_ratings = ', possible_num_of_ratings)\n\n#Density of ratings\ndensity = (given_num_of_ratings\/possible_num_of_ratings)\ndensity *= 100\nprint ('density: {:4.2f}%'.format(density))\n\nfinal_ratings_matrix.head()","6bc1c14e":"#Calculate the average rating for each product \naverage_rating = df_final.groupby('prod_id').mean()['rating']\n\n#Calculate the count of ratings for each product\ncount_rating = df_final.groupby('prod_id').count()['rating']\n\n#Create a dataframe with calculated average and count of ratings\nfinal_rating = pd.DataFrame({'Avg Rating': average_rating, 'Rating count': count_rating})\n\n#Sort the dataframe by average of ratings\nfinal_rating = final_rating\nfinal_rating.sort_values(by='Rating count', ascending=False, inplace=True)\n\nfinal_rating.head()","a2aaaa89":"#defining a function to get the top n products based on highest average rating and minimum interactions\ndef top_n_products(final_rating, n, min_interaction):\n    \n    #Finding movies with minimum number of interactions\n    recommendations = final_rating[final_rating['Rating count'] > min_interaction]\n    \n    #Sorting values w.r.t average rating \n    recommendations.sort_values(by='Avg Rating', ascending=False, inplace=True)\n    \n    return recommendations.index[:n]\n","a49cfb33":"list(top_n_products(final_rating, 5, 50))","a78e82a1":"list(top_n_products(final_rating, 5, 100))","4aef2ffa":"final_ratings_matrix.head()","ce213622":"final_ratings_matrix['user_index'] = np.arange(0, final_ratings_matrix.shape[0])\nfinal_ratings_matrix.set_index(['user_index'], inplace=True)\n\n# Actual ratings given by users\nfinal_ratings_matrix.head()","0f466f56":"# defining a function to get similar users\ndef similar_users(user_index, interactions_matrix):\n    similarity = []\n    for user in range(0, interactions_matrix.shape[0]):\n        \n        #finding cosine similarity between the user_id and each user\n        sim = cosine_similarity([final_ratings_matrix.loc[user_index]], [final_ratings_matrix.iloc[user]])\n        \n        #Appending the user and the corresponding similarity score with user_id as a tuple\n        similarity.append((user, sim))\n        \n    similarity.sort(key=lambda x: x[1], reverse=True)\n    most_similar_users = [tup[0] for tup in similarity] #Extract the user from each tuple in the sorted list\n    similarity_score = [tup[1] for tup in similarity] ##Extracting the similarity score from each tuple in the sorted list\n   \n    #Remove the original user and its similarity score and keep only other similar users \n    most_similar_users.remove(user)\n    similarity_score.remove(similarity_score[0])\n       \n    return most_similar_users, similarity_score","7c8209f6":"similar = similar_users(3, final_ratings_matrix)[0][0:10]\nsimilar","a70c00bd":"#Print the similarity score\nsimilar_users(3, final_ratings_matrix)[1][0:10]","49bcc6f0":"similar = similar_users(1521, final_ratings_matrix)[0][0:10]\nsimilar","702b167f":"#Print the similarity score\nsimilar_users(1521, final_ratings_matrix)[1][0:10]","ff9759ad":"# defining the recommendations function to get recommendations by using the similar users' preferences\ndef recommendations(user_index, num_of_products, interactions_matrix):\n    \n    #Saving similar users using the function similar_users defined above\n    most_similar_users = similar_users(user_index, interactions_matrix)[0]\n    \n    #Finding product IDs with which the user_id has interacted\n    prod_ids = set(list(interactions_matrix.columns[np.where(interactions_matrix.loc[user_index] > 0)]))\n    recommendations = []\n    \n    observed_interactions = prod_ids.copy()\n    for similar_user in most_similar_users:\n        if len(recommendations) < num_of_products:\n            \n            #Finding 'n' products which have been rated by similar users but not by the user_id\n            similar_user_prod_ids = set(list(interactions_matrix.columns[np.where(interactions_matrix.loc[similar_user] > 0)]))\n            recommendations.extend(list(similar_user_prod_ids.difference(observed_interactions)))\n            observed_interactions = observed_interactions.union(similar_user_prod_ids)\n        else:\n            break\n    \n    return recommendations[:num_of_products]","4c4c734a":"recommendations(3, 5, final_ratings_matrix)","824e0f10":"recommendations(1521, 5, final_ratings_matrix)","806db263":"from scipy.sparse.linalg import svds # for sparse matrices\n\n# Singular Value Decomposition\nU, s, Vt = svds(final_ratings_matrix, k = 50) # here k is the number of latent features\n\n# Construct diagonal array in SVD\nsigma = np.diag(s)","760ed094":"U.shape #checking the shape of the U matrix","5e6a169e":"sigma.shape #checking the shape of the sigma matrix","b79dd079":"Vt.shape #checking the shape of the Vt matrix","5d66b05e":"all_user_predicted_ratings = np.dot(np.dot(U, sigma),Vt) \n\n# Predicted ratings\npreds_df = pd.DataFrame(abs(all_user_predicted_ratings), columns = final_ratings_matrix.columns)\npreds_df.head()","839b7c6a":"# Recommend the items with the highest predicted ratings\n\ndef recommend_items(user_index, interactions_matrix, preds_df, num_recommendations):\n    \n    # Get and sort the user's ratings from the actual and predicted interaction matrix\n    sorted_user_ratings = interactions_matrix.loc[user_index].sort_values(ascending=False)\n    sorted_user_predictions = preds_df.loc[user_index].sort_values(ascending=False)\n\n    #Creating a dataframe with actual and predicted ratings columns\n    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis=1)\n    temp.index.name = 'Recommended Products'\n    temp.columns = ['user_ratings', 'user_predictions']\n    \n    #Filtering the dataframe where actual ratings are 0 which implies that the user has not interacted with that product\n    temp = temp.loc[temp.user_ratings == 0]   \n    \n    #Recommending products with top predicted ratings\n    temp = temp.sort_values('user_predictions', ascending=False) #Sort the dataframe by user_predictions in descending order\n    print('\\nBelow are the recommended products for user(user_id = {}):\\n'.format(user_index))\n    print(temp['user_predictions'].head(num_recommendations))","42e97162":"#Enter 'user index' and 'num_recommendations' for the user\nuser_index = 121\nnum_recommendations = 5\nrecommend_items(user_index, final_ratings_matrix, preds_df, num_recommendations)","efd7b859":"#Enter 'user_index' and 'num_recommendations' for the user #\nuser_index = 465\nnum_recommendations = 5\nrecommend_items(user_index, final_ratings_matrix, preds_df, num_recommendations)","4afbbab9":"# Actual ratings given by the users\nfinal_ratings_matrix.head()","85e65ac9":"# Find average actual rating for each item\nfinal_ratings_matrix.mean()","4d3b5658":"# Predicted ratings \npreds_df.head()","35527941":"# Find average predicted rating for each item\npreds_df.mean()","5ba5bc82":"#create a dataframe containing average actual ratings and avearge predicted ratings for each product\nrmse_df = pd.concat([final_ratings_matrix.mean(), preds_df.mean()], axis=1)\n\nrmse_df.columns = ['Avg_actual_ratings', 'Avg_predicted_ratings']\n\nrmse_df.head()","30646a55":"#Calculate and print RMSE using the mean_square_error function\nRMSE = np.sqrt((sum((rmse_df['Avg_actual_ratings']-rmse_df['Avg_predicted_ratings'])**2))\/rmse_df.shape[0] )\nprint('\\nRMSE SVD Model = {} \\n'.format(RMSE))","e5ef1d86":"# Enter 'user_index' and 'num_recommendations' for the user #\nuser_index = 100\nnum_recommendations = 10 \nrecommend_items(user_index, final_ratings_matrix, preds_df, num_recommendations)","4dc09408":"Now, let's regenerate the original matrix using U, Sigma, and Vt matrices. The resulting matrix would be the predicted ratings for all users and products","fd786c29":"### Data preparation  (1 mark)","2f871f34":"#### Summary Statistics","1df71ee8":"We have applied two technique to recommend products to users. Now, let's build one more recommendation system using matrix factorization (SVD).","281b482c":"# Project- Recommendation Systems: Amazon product reviews\n\n###### Durga P. Dulal - MIT Applied Data Science #####\n\n\n\nWelcome to the project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model. \n\n--------------\n### Context: \n--------------\n\nOnline E-commerce websites like Amazon, Flipkart uses different recommendation models** to provide personalized suggestions to different users. Amazon currently uses item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n\n----------------\n### Objective:\n----------------\n\nBuild a recommendation system to recommend products to customers based on their previous ratings for other products.\n\n--------------\n### Dataset:\n--------------\n\nThe Amazon dataset contains the following attributes:\n\n- **userId:** Every user identified with a unique id\n- **productId:** Every product identified with a unique id\n- **Rating:** Rating of the corresponding product by the corresponding user\n- **timestamp:** Time of the rating (ignore this column for this exercise)","8fbe4907":"#### Finding out top 10 similar users to the user index 3 and their similarity score","b2349147":"#### Recommend 5 products to user index 3 based on similarity based collaborative filtering","9758e6f8":"#### Recommending top 5 products with 50 minimum interactions based on popularity","f9cbce2f":"- The most common rating (stars) given to products by users is 5.\n- About **78% of ratings are positive with 5 or 4 stars** \n- About 22% of ratings has 3 or below stars","c6a5e305":"We have recommended the top 5 products by using popularity recommendation system. Now, let's build a recommendation system using collaborative filtering","ca303153":"### Rank Based Recommendation System (10 marks)","f29b9830":"#### Checking for missing values","f8261034":"**Let's take a subset of the dataset (by only keeping the users who have given 50 or more ratings) to make the dataset less sparse and easy to work with.**","ace7e980":"- The dataframe **df_final has users who have rated 50 or more items**\n- **We will use df_final to build recommendation systems**","878504e8":"#### Shape of the data","3d66d921":"#### Evaluation of the Model based Collaborative Filtering (SVD)","c34c7029":"**Conclusion:**\n\nIn this project, Durga's recommend **personlized products** to the different customers using following recommendation models   \n\n**Rank Based** Recommendation System (Popularity based)\n  - Recommended products\/items based on popularity\/trend. \n  - Algorithm look for products\/movies that are currently trending\/most popular \n\n**Collaborative Filtering based** Recommendation System\n-   Based on similar users, that is calculated using **Cosine Similarity** and recommend products rated by the similar users.\n\n**Model based Collaborative Filtering: Singular Value Decomposition {(matrix factorization (SVD)}**\n-  Sparsity & scalability are the two biggest problems with the collaborative filtering method. So we use the singular value decomposition, which is the matrix-factorization technique. It reduces the original sparse matrix to low-dimensional matrices with latent features & less sparsity. It tells us how much a user agrees with a set of latent features and how much a movie\/product fits into that set of latent features.\n\n- It is also known as a personalized recommendation system, the recommendations are based on the user's past behavior, and it is not dependent on any additional information.\n\nHence, we **learned the merits and drawbacks** of these recommendation systems and when to use which type of recommendation system.\n","8e861a2a":"### Conclusion (2 marks)","651c758b":"**Recommending top 5 products to user id 121**","12251e10":"#### Checking the number of unique users and items in the dataset","21191001":"### Evaluate the model (10 marks)","96da724c":"#### Checking the rating distribution\n\nCheck the distribution of ratings and **provide observations** from the plot ","4aa2acea":"#### Recommend top 10 products to the user id 100","0371c928":"#### Recommend 5 products to user index 1521 based on similarity based collaborative filtering","4a6d150b":"### Recommendation (2 marks)","01b51710":"#### Users with most number of ratings","e32fcd75":"We have found similar users for a given user. Now, let's create **a function to recommend products** to the user using the ratings given by similar users.","c2e16fa6":"- Even with the subset of users and products, the current number of ratings is just **0.17%** of the possible number of ratings. This implies that the data is **highly sparse**.\n- We will build recommendation systems to recommend products to users with which they have not interacted.","2cfc181e":"### Model based Collaborative Filtering: Singular Value Decomposition  (15 marks)","ceb8302b":"**Here, user_id (index) is of the object data type. We will replace the user_id by numbers starting from 0 to 1539 (for all user ids) so that the index is of integer type and represents a user id in the same format**","aa7525ee":"### Collaborative Filtering based Recommendation System (15 marks)","d688688c":"**Recommending the 5 products to user index 465**","6cd96c40":"#### Recommending top 5 products with 100 minimum interactions based on popularity","5038ac7f":"### Exploratory Data Analysis (5 marks)","ec227fe0":"Now that we have explored and preprocessed the data, let's build the first recommendation system","5c18b5bf":"### Loading data","1e327cee":"**We have seen above that the interaction matrix is highly sparse. SVD is best to apply on a large sparse matrix. Note that for sparse matrices, we can use the sparse.linalg.svds() function to perform the decomposition**\n\nAlso, we will use **k=50 latent features** to predict rating of products","3c302ddf":"#### Finding out top 10 similar users to the user index 1521 and their similarity score","f8bc2503":"- There are **42,01,696 users and 4,76,002 products** in the dataset","02a543cb":"#### Checking the density of the rating matrix","7f6aed8b":"Now, let's define a **function to get similar users** for a particular user","a3c403cb":"- The highest number of ratings by a user is 520 which is far from the actual number of products present in the data. We can build a recommendation system to recommend products to users which they have not interacted with.","b0fe80c0":"### Importing Libraries","3a5e9612":"We have the prediction of ratings but we need to create a **function to recommend products** to the users on the basis of predicted ratings for each product","89a71847":"#### Data types"}}