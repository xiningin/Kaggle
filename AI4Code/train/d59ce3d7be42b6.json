{"cell_type":{"5a21d733":"code","39e96202":"code","0ded3b68":"code","fb18a2b2":"code","c0a25d43":"code","5ad9ad8a":"code","81e3fddb":"code","2665db5e":"code","625ec391":"code","18d59369":"code","380194d1":"code","e4788fc7":"code","1b37fe35":"code","ee29e666":"code","9349d7f9":"code","18bf3e23":"code","cb1e13e6":"code","7e5952a7":"code","bb6fbc38":"code","174b7d23":"code","dfba831c":"code","580ddc75":"code","277beeb2":"code","b564921a":"code","418308e3":"code","a6569fb9":"code","514efa97":"code","e57a42d3":"code","ccb42cd7":"code","ff51e90e":"code","5005ab7f":"code","aaa11d40":"code","d9627186":"code","dd79b2cd":"code","f8840f31":"code","7cde17b2":"code","1f5f38f2":"code","1f7232a7":"code","219294f9":"code","adb306a9":"code","1d940182":"code","5dc2e0e7":"code","a08a05af":"code","7aa983ca":"code","6f9fd7ad":"code","87661b2f":"code","c75c1fb7":"code","8ef96bb8":"code","c67b060a":"code","5ec8c45b":"code","55d96711":"markdown","28cdff59":"markdown","b2af5702":"markdown","82d8c88d":"markdown","2028c6ab":"markdown","d46b74f8":"markdown","78c07bc6":"markdown","67e2b729":"markdown","1a601a39":"markdown","9a5c6a88":"markdown","da860de5":"markdown","c23ba637":"markdown","45831f60":"markdown","677c6c7b":"markdown","4accb5fe":"markdown","f7ddd8f3":"markdown","5d40fd6f":"markdown","1f00a8e5":"markdown","a2c4b382":"markdown","98cf4b3b":"markdown","c932257b":"markdown","46c09bbd":"markdown","88d44291":"markdown","bf6157b0":"markdown","5bcd78bb":"markdown","b1182f88":"markdown","d77feb62":"markdown","e30a6a60":"markdown"},"source":{"5a21d733":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport cufflinks as cf\nimport plotly.offline\nimport pandas_profiling\nfrom plotly.offline import iplot, init_notebook_mode\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\n\nimport pprint\n\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer\nimport json\nimport re, string, unicodedata\nfrom bs4 import Comment\nfrom collections import OrderedDict\nfrom wordcloud import WordCloud\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n","39e96202":"cf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\ninit_notebook_mode(connected=True)\n","0ded3b68":"apps = pd.read_csv(\"..\/input\/googleplaystore.csv\")\nreviews = pd.read_csv(\"..\/input\/googleplaystore_user_reviews.csv\")","fb18a2b2":"apps.head()","c0a25d43":"apps.shape","5ad9ad8a":"apps.isnull().sum()","81e3fddb":"apps = apps.drop_duplicates(['App'],keep='last')","2665db5e":"trace2 = go.Bar(\n    x=apps.sort_values(['Rating'],ascending=False)['App'][:30],\n    y=apps.sort_values(['Rating'],ascending=False)['Rating'][:30],\n    name='Top 30 apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","625ec391":"apps.sort_values(['Rating'],ascending=False)[['App','Rating']][:30]","18d59369":"apps['Rating'] = apps['Rating'].apply(lambda x : 5 if x > 5 else x)","380194d1":"trace2 = go.Bar(\n    x=apps.sort_values(['Rating'],ascending=False)['App'][:30],\n    y=apps.sort_values(['Rating'],ascending=False)['Rating'][:30],\n    name='Top 30 apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","e4788fc7":"np.mean(apps['Rating'].mean())","1b37fe35":"np.median(apps['Rating'].mean())","ee29e666":"apps.Rating.iplot(kind='box')","9349d7f9":"apps.iplot(kind='histogram',columns=['Rating'])\n","18bf3e23":"apps.head()","cb1e13e6":"apps['Reviews'] = apps['Reviews'].apply(lambda x: float(x[:-1]) * 1000000 if 'M' in x else float(x))","7e5952a7":"trace2 = go.Bar(\n    x=apps.sort_values(['Reviews'],ascending=False)['App'][:30],\n    y=apps.sort_values(['Reviews'],ascending=False)['Reviews'][:30],\n    name='Top Reviewed apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","bb6fbc38":"np.mean(apps['Reviews'].mean())","174b7d23":"np.median(apps['Reviews'].mean())","dfba831c":"apps['Installs'].unique()","580ddc75":"apps['Installs'] = apps['Installs'].fillna(0)\napps['Installs'] = apps['Installs'].apply(lambda x: 0 if x == 'Free' else x.replace(',', '')[:-1])","277beeb2":"apps['Installs'] = apps['Installs'].apply(lambda x: 0 if x == '' else float(x))","b564921a":"trace2 = go.Bar(\n    x=apps.sort_values(['Installs'],ascending=False)['App'][:30],\n    y=apps.sort_values(['Installs'],ascending=False)['Installs'][:30],\n    name='Top Installed apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","418308e3":"apps['Reviews'].corr( apps['Installs'])\n","a6569fb9":"plt.figure(figsize = (14,12))\nsns.regplot(x = 'Reviews', y ='Installs', data = apps)","514efa97":"apps['Category'].unique()","e57a42d3":"category = apps.groupby(['Category']).count().reset_index().sort_values(['App'], ascending = False)\n\n\ntrace2 = go.Bar(\n    x=category['Category'],\n    y=category['App'],\n    name='Top Installed apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","ccb42cd7":"percent_category = round(category['App'], 2)\n\nprint(\"Category percentual: \")\n#print(percent_category\/percent_category.sum() * 100,2)\n\ntypes = round(category['App']\/ len(category['App']) * 100,2)\n\nlabels = list(category['Category'][:10])\nvalues = list(types[:10].values)\n\ntrace1 = go.Pie(labels=labels, values=values, marker=dict(colors=['red']), text=percent_category.values)\n\nlayout = go.Layout(title=\"Percentual of Categories\", \n                   legend=dict(orientation=\"h\"));\n\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","ff51e90e":"plt.figure(figsize = (14,12))\ng1 = sns.countplot(x='Content Rating', data = apps)\ng1.set_title(\"Content Ratings Count\", fontsize=20)\ng1.set_xlabel(\"Content Rating\", fontsize=15)\ng1.set_ylabel(\"Count\", fontsize=15)\n\nplt.show()","5005ab7f":"type_of_apps = apps.groupby(['Type']).count().reset_index()[['Type','Installs']]","aaa11d40":"pprint.pprint(type_of_apps)","d9627186":"type_of_apps = type_of_apps[type_of_apps['Type']!='0']","dd79b2cd":"plt.figure(figsize = (12,10))\nplt.bar(type_of_apps['Type'],type_of_apps['Installs'])\nplt.title(\"Paid v\/s Free installs\", fontsize=20)\nplt.xlabel(\"Type\", fontsize=15)\nplt.ylabel(\"Count\", fontsize=15)\n\nplt.show()","f8840f31":"reviews.head()","7cde17b2":"reviews.shape","1f5f38f2":"def remove_non_ascii(words):\n        \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n        new_words = []\n        for word in words:\n            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n            new_words.append(new_word)\n        return new_words\n\ndef to_lowercase(words):\n        \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n        new_words = []\n        for word in words:\n            new_word = word.lower()\n            new_words.append(new_word)\n        return new_words\n\ndef remove_punctuation(words):\n        \"\"\"Remove punctuation from list of tokenized words\"\"\"\n        new_words = []\n        for word in words:\n            new_word = re.sub(r'[^\\w\\s]', '', word)\n            if new_word != '':\n                new_words.append(new_word)\n        return new_words\n\ndef replace_numbers(words):\n        \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n        p = inflect.engine()\n        new_words = []\n        for word in words:\n            if word.isdigit():\n                new_word = p.number_to_words(word)\n                new_words.append(new_word)\n            else:\n                new_words.append(word)\n        return new_words\n\ndef remove_stopwords(words):\n        \"\"\"Remove stop words from list of tokenized words\"\"\"\n        new_words = []\n        for word in words:\n            if word not in stopwords.words('english'):\n                new_words.append(word)\n        return new_words\n\ndef lemmatize_verbs(words):\n        \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n        lemmatizer = WordNetLemmatizer()\n        lemmas = []\n        for word in words:\n            lemma = lemmatizer.lemmatize(word, pos='v')\n            lemmas.append(lemma)\n        return lemmas\n\ndef normalize(words):\n        words = remove_non_ascii(words)\n        words = to_lowercase(words)\n        words = remove_punctuation(words)\n        #words = replace_numbers(words)\n        words = remove_stopwords(words)\n        return words","1f7232a7":"%%time\n\ndocuments=[]\nfor i in range(reviews.shape[0]):\n            if( pd.isnull(reviews['Translated_Review'][i])==True):\n                continue\n            words = reviews['Translated_Review'][i].split()\n            words = normalize(words)\n            words=\" \".join(words)\n            documents.append(words)\n            \n    ","219294f9":"len(documents)","adb306a9":"#Bag of Words\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 3000)#filter non relevant words #keep max 3000\nX=cv.fit_transform(documents).toarray()","1d940182":"print(X.shape)","5dc2e0e7":"words = cv.inverse_transform(X)\nfrom collections import Counter\ncounts={}\nfor word in words:\n    for w in word:\n        if w in counts:\n            counts[w] +=1\n        else:\n            counts[w] = 1\nOrderedDict(sorted(counts.items(),reverse=True, key=lambda t: t[1]))","a08a05af":"#Wordcloud\nplt.figure(figsize = (16, 10))\nwordcloud = WordCloud(background_color=\"white\",width=1000,height=1000,\n                max_words=30,relative_scaling=0.5,normalize_plurals=False).generate_from_frequencies(counts)\n\nplt.imshow(wordcloud)\nplt.title('Top used words')\nplt.axis(\"off\")\nplt.show()","7aa983ca":"plt.figure(figsize = (16, 10))\ng1 = sns.countplot(x='Sentiment', data = reviews)\ng1.set_title(\"Sentiment Analysis\", fontsize=20)\ng1.set_xlabel(\"Sentiment\", fontsize=15)\ng1.set_ylabel(\"Count\", fontsize=15)\n\nplt.show()","6f9fd7ad":"#reviews['Sentiment'] = reviews['Sentiment'].map({'Positive':1,'Negative':0})\nsentiments = pd.crosstab(reviews.App, reviews.Sentiment).reset_index()\n","87661b2f":"trace2 = go.Bar(\n    x=sentiments.sort_values(['Positive'],ascending=False)['App'][:30],\n    y=sentiments.sort_values(['Positive'],ascending=False)['Positive'][:30],\n    name='Top Reviewed apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","c75c1fb7":"trace2 = go.Bar(\n    x=sentiments.sort_values(['Negative'],ascending=False)['App'][:30],\n    y=sentiments.sort_values(['Negative'],ascending=False)['Negative'][:30],\n    name='Top Reviewed apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","8ef96bb8":"trace2 = go.Bar(\n    x=sentiments.sort_values(['Neutral'],ascending=False)['App'][:30],\n    y=sentiments.sort_values(['Neutral'],ascending=False)['Neutral'][:30],\n    name='Top Reviewed apps'\n)\n\nd = [trace2]\nlayout = go.Layout(\n    barmode='group'\n)\n\nfig = go.Figure(data=d, layout=layout)\niplot(fig)","c67b060a":"reviews.groupby(['App']).mean()['Sentiment_Polarity'].nlargest(30).iplot(kind='bar',\n                                                                     xTitle='App', yTitle='Sentiment Polarity',\n                                                                     title='Apps with most Sentiment_Polarity',colors = 'red')","5ec8c45b":"reviews.groupby(['App']).mean()['Sentiment_Subjectivity'].nlargest(30).iplot(kind='bar',\n                                                                     xTitle='App', yTitle='Sentiment Subjectivity',\n                                                                     title='Apps with most Sentiment Subjectivity',colors = 'green')","55d96711":"#### Most reviewed Apps","28cdff59":"### Lets see which category dominates the playstore","b2af5702":"### Positive vs Negative Sentiments","82d8c88d":"### Lets see the Content Rating","2028c6ab":"## Import the Data","d46b74f8":"#### Removing the duplicated rows ","78c07bc6":"#### Avg and Median of Ratings","67e2b729":"### Free v\/s Paid apps","1a601a39":"##### we need to clean and make the scale same for all the values in the column","9a5c6a88":"#### We can't say more installs lead to more reviews but there is a bit of correlation","da860de5":"### Apps that got most neutral, positve and negative sentiments","c23ba637":"### Reviews v\/s Installs","45831f60":"## EDA","677c6c7b":"# Next - Prediction","4accb5fe":"#### Facebook and its other applications has the highest reviews","f7ddd8f3":"### Avg Sentiment_Polarity and Sentiment_Subjectivity**","5d40fd6f":"#### Most installed applications","1f00a8e5":"### Most common words","a2c4b382":"#### Lets create bag of words for the reviews","98cf4b3b":"#### Seems like the app 'Life Made WI-Fi Touchscreen Photo Frame' has incorrect ratings. Assuming 5 is the higest rating we will change any rating above 5 to 5.","c932257b":"#### Top Rated Apps","46c09bbd":"#### Family, Game, Tools dominates the most","88d44291":"#### Histogram is a bit skewed towards the right and there are few apps that have ratings less than 3","bf6157b0":"## Load the Libraries","5bcd78bb":"## User Reviews","b1182f88":"####  Most applications are for everyone","d77feb62":"#### few of the apps does not have any ratings","e30a6a60":"#### Let us first see the apps on the Google Play store"}}