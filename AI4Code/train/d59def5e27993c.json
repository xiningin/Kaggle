{"cell_type":{"9e07a440":"code","a3f3aef6":"code","cab138f2":"code","8987d915":"code","5b7a5178":"code","455a32c6":"code","e4a4e420":"code","b8ed2c92":"code","e75cb73a":"code","ac95b083":"code","25ba2fa2":"code","3f0d3494":"code","28ed0a15":"code","d69f8139":"code","ebd3f7bd":"code","e3f2e7aa":"code","5e58b09a":"code","5942edc5":"code","19c379f6":"code","769eb39b":"code","a18b085f":"code","3ad083c9":"code","7bf2d3b7":"code","506b9913":"code","3451ef46":"markdown"},"source":{"9e07a440":"!pip install -Uqq fastai","a3f3aef6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom torch.utils.data import Dataset\nimport torch\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom fastai.data.core import DataLoaders\nfrom fastai.learner import Learner\nfrom fastai.callback.progress import ProgressCallback\nfrom fastai.optimizer import OptimWrapper\nfrom torch import optim\nfrom fastai.losses import MSELossFlat, L1LossFlat\nfrom fastai.callback.schedule import Learner\nfrom fastai.callback.tracker import EarlyStoppingCallback, ReduceLROnPlateau, SaveModelCallback\nfrom fastai.data.transforms import IndexSplitter\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import KFold\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport random\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cab138f2":"df = pd.read_csv('\/kaggle\/input\/ventilator-pressure-prediction\/train.csv')\ndf_test = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')","8987d915":"# max_size = 100","5b7a5178":"# df = df[df.breath_id < max_size]","455a32c6":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] \/df['count']\n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['u_in_lag'] = df['u_in_lag']*df['breath_id_lagsame']\n    df['u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['u_in_lag2'] = df['u_in_lag2']*df['breath_id_lag2same']\n    df['u_out_lag2'] = df['u_out'].shift(2).fillna(0)\n    df['u_out_lag2'] = df['u_out_lag2']*df['breath_id_lag2same']\n    #df['u_in_lag'] = df['u_in'].shift(2).fillna(0)\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['RC'] = df['R']+df['C']\n    df = pd.get_dummies(df)\n    return df\n\n\ntrain = add_features(df)\ntest = add_features(df_test)","e4a4e420":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure','id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2'], axis=1)","b8ed2c92":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","e75cb73a":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","ac95b083":"idx = list(range(len(train)))","25ba2fa2":"# train_input, valid_input = train[:3000], train[3000:4000]\n# train_targets, valid_targets = targets[:3000], targets[3000:4000]","3f0d3494":"train.shape[-2:]","28ed0a15":"class VentilatorDataset(Dataset):\n    def __init__(self, data, target):\n        self.data = torch.from_numpy(data).float()\n        if target is not None:\n            self.targets = torch.from_numpy(target).float()\n                \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if hasattr(self, 'targets'): return self.data[idx], self.targets[idx]\n        else: return self.data[idx]","d69f8139":"class RNNModel(nn.Module):\n    def __init__(self, input_size=25):\n        hidden = [500, 400, 300, 200]\n        super().__init__()\n        self.lstm1 = nn.LSTM(input_size, hidden[0],\n                             batch_first=True, bidirectional=True)\n        self.lstm2 = nn.LSTM(2 * hidden[0], hidden[1],\n                             batch_first=True, bidirectional=True)\n        self.lstm3 = nn.LSTM(2 * hidden[1], hidden[2],\n                             batch_first=True, bidirectional=True)\n        self.lstm4 = nn.LSTM(2 * hidden[2], hidden[3],\n                             batch_first=True, bidirectional=True)\n        self.fc1 = nn.Linear(2 * hidden[3], 50)\n        self.selu = nn.SELU()\n        self.fc2 = nn.Linear(50, 1)\n        self._reinitialize()\n\n    def _reinitialize(self):\n        \"\"\"\n        Tensorflow\/Keras-like initialization\n        \"\"\"\n        for name, p in self.named_parameters():\n            if 'lstm' in name:\n                if 'weight_ih' in name:\n                    nn.init.xavier_uniform_(p.data)\n                elif 'weight_hh' in name:\n                    nn.init.orthogonal_(p.data)\n                elif 'bias_ih' in name:\n                    p.data.fill_(0)\n                    # Set forget-gate bias to 1\n                    n = p.size(0)\n                    p.data[(n \/\/ 4):(n \/\/ 2)].fill_(1)\n                elif 'bias_hh' in name:\n                    p.data.fill_(0)\n            elif 'fc' in name:\n                if 'weight' in name:\n                    nn.init.xavier_uniform_(p.data)\n                elif 'bias' in name:\n                    p.data.fill_(0)\n\n    def forward(self, x):\n        x, _ = self.lstm1(x)\n        x, _ = self.lstm2(x)\n        x, _ = self.lstm3(x)\n        x, _ = self.lstm4(x)\n        x = self.fc1(x)\n        x = self.selu(x)\n        x = self.fc2(x)\n\n        return x","ebd3f7bd":"# next(model.parameters())","e3f2e7aa":"batch_size = 512\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\ntest_dataset = VentilatorDataset(test, None)\ntest_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)","5e58b09a":"########################## Experimenting with one fold","5942edc5":"train_index=list(range(int(0.95*len(train)))) ## Change to have reasonable train\/valid dataset\nvalid_index=list(range(int(0.95*len(train)), len(train)))\n\ntrain_input, valid_input = train[train_index], train[valid_index]\ntrain_targets, valid_targets = targets[train_index], targets[valid_index]\n\ntrain_dataset = VentilatorDataset(train_input, train_targets)\nvalid_dataset = VentilatorDataset(valid_input, valid_targets)\n\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle=False)\n\ndls = DataLoaders(train_loader, valid_loader)\nmodel = RNNModel()\n","19c379f6":"learn = Learner(dls, model, loss_func=L1LossFlat())\nlearn.lr_find()","769eb39b":"del df\ngc.collect()","a18b085f":"learn.fit_one_cycle(350, lr_max=2e-3, cbs=[ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=10), SaveModelCallback(every_epoch=True)])\npreds = []\nwith torch.no_grad():\n    for data in test_loader:\n        pred = model(data.to('cuda')).squeeze(-1).flatten()\n        preds.extend(pred.detach().cpu().numpy())\n# preds_fold.append(preds)\ndf_test['pressure'] = preds\ndf_test[['id', 'pressure']].to_csv('submission.csv', index=False)","3ad083c9":"########################################################################## Uncomment code below KFold Prediction","7bf2d3b7":"# kf = KFold(n_splits=5, shuffle=True)\n# preds_fold = []\n        \n# for fold, (train_index, valid_index) in enumerate(kf.split(idx)):\n#     preds = []\n#     model = RNNModel().to('cuda')\n#     print(\"FOLD:\", fold)\n#     print(train_index)\n#     print(valid_index)\n\n#     train_input, valid_input = train[train_index], train[valid_index]\n#     train_targets, valid_targets = targets[train_index], targets[valid_index]\n\n#     train_dataset = VentilatorDataset(train_input, train_targets)\n#     valid_dataset = VentilatorDataset(valid_input, valid_targets)\n    \n#     train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n#     valid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle=False)\n    \n#     dls = DataLoaders(train_loader, valid_loader)\n#     learn = Learner(dls, model, loss_func=MSELossFlat())\n#     learn.fit_one_cycle(1, lr_max=2e-3)\n    \n#     with torch.no_grad():\n#         for data in test_loader:\n#             pred = model(data.to('cuda')).squeeze(-1).flatten()\n#             preds.extend(pred.detach().cpu().numpy())\n#     preds_fold.append(preds)","506b9913":"# preds_fold = np.array(preds_fold)\n# df_test['pressure'] = np.median(preds_fold, axis=0)\n# df_test[['id', 'pressure']].to_csv('submission.csv', index=False)","3451ef46":"### Introduction\n\nIn this notebook, I'm trying to integrate the public notebook for Ventillator Pressure Competition written in Pytorch to Fastai. The reason is to leverage high level API of fastai to avoid repetitive pattern ( for example fititing with a scheduler learning rate, adding some callback  like ReduceLROnPlateau )\n"}}