{"cell_type":{"99142ef5":"code","47b635d3":"code","8a0d2540":"code","aacec11d":"code","6e6f3ac4":"code","20622358":"code","cea87afb":"code","99aff3a2":"code","3ca8761b":"code","02460a6f":"code","e1c58920":"code","204d60ec":"code","e210cbf8":"code","585bc7c8":"code","8e47f216":"code","22b9bbff":"code","217bfaec":"code","db408ca0":"code","2b3ec513":"code","137544bc":"code","3ead9743":"code","f1a3491d":"code","abcb7db1":"code","91902414":"code","40ecb432":"code","d47dbf27":"code","f74cdb37":"code","1886a0b1":"code","07c2e97a":"code","7603b910":"code","f49630fe":"markdown","43537503":"markdown","0bbf4fa5":"markdown","412e8499":"markdown","b22332d4":"markdown","208c8113":"markdown","2c2f1328":"markdown","b6ed30b4":"markdown","9baa8f7a":"markdown","d31b29e3":"markdown","06806067":"markdown","17a2b4e2":"markdown","75f8a3eb":"markdown","71102eb9":"markdown","3c093d93":"markdown","396a2519":"markdown","8c95229c":"markdown","401d7d57":"markdown","1d6448cb":"markdown","a63b9fa8":"markdown","b31bc18c":"markdown","98d0b743":"markdown","fee7e087":"markdown","7faa3177":"markdown","063ce293":"markdown","bdafc336":"markdown"},"source":{"99142ef5":"import os\nimport numpy as np\nimport pandas as pd\n%pylab inline","47b635d3":"multipleCh_init=pd.read_csv('..\/input\/multipleChoiceResponses.csv')","8a0d2540":"Femme=multipleCh_init[multipleCh_init.Q1=='Female']\nX=Femme[['Q2','Q24','Q4','Q9','Q23','Q5','Q17','Q3']] \nX=X.dropna() #It is necessary to eliminate rows with nan values\n# We are going to ignore females which did not respond specifically to all questions. \nX=X[X.Q4.str.contains('I prefer not to answer')==False]\nX=X[X.Q9.str.contains('I do not wish to disclose my approximate yearly compensation')==False]\nX=X[X.Q3.str.contains('I do not wish to disclose my location')==False]\nX.head()","aacec11d":"a=multipleCh_init[['Q2','Q24','Q4','Q9','Q23','Q5','Q17','Q3']].iloc[0,:]\nfor i in range(a.shape[0]):\n    print(X.columns[i],a[i])","6e6f3ac4":"X.shape # shape of the survey","20622358":"n=X.shape[0]     #number of respondents\np=X.shape[1]-3   # number of variables in which we are going to perform PCA\nX1=np.zeros((n,p)) \nX1.shape","cea87afb":"X.Q2.unique() ","99aff3a2":"for i in range(0,n):\n    if(X.Q2.iloc[i]=='80+'):\n        X1[i,0]=90\n    else:\n        lower=int(X.Q2.iloc[i][0]+X.Q2.iloc[i][1])\n        upper=int(X.Q2.iloc[i][3]+X.Q2.iloc[i][4])\n        X1[i,0]=(upper+lower)\/2\n    ","3ca8761b":"X.Q24.unique()","02460a6f":"import re\nfor i in range(0,n):\n    if(X.Q24.iloc[i]=='40+'):\n        X1[i,1]=45.0    \n    elif(len([float(s) for s in re.findall(r'-?\\d+\\.?\\d*', X.Q24.iloc[i])])>0): \n        #re.findall finds the caracters that correspond to numbers in a string\n        a=[float(s) for s in re.findall(r'-?\\d+\\.?\\d*', X.Q24.iloc[i])]\n        a=np.absolute(a)\n        prom=np.sum(a)\/2\n        X1[i,1]=prom\n    else:\n        X1[i,1]=0.0     ","e1c58920":"X.Q4.unique()","204d60ec":"for i in range(0,n):\n    if(X.Q4.iloc[i]=='Bachelor\u2019s degree' or X.Q4.iloc[i]=='Professional degree' ):\n        X1[i,2]=1.0\n    elif(X.Q4.iloc[i]=='Master\u2019s degree'):\n        X1[i,2]=2.0\n    elif(X.Q4.iloc[i]=='Doctoral degree'):\n        X1[i,2]=3.0\n    else:\n        X1[i,2]=0.0    ","e210cbf8":"X.Q9.unique()","585bc7c8":"for i in range(0,n):\n    if(X.Q9.iloc[i]=='500,000+'):\n        X1[i,3]=750000 \n    else:\n        a=[float(s) for s in re.findall(r'-?\\d+\\.?\\d*', X.Q9.iloc[i])]\n        #re.findall finds the caracters that correspond to numbers in a string\n        a=np.absolute(a)\n        prom=np.sum(a[0:2])\/2\n        X1[i,3]=prom*1000","8e47f216":"X.Q23.unique()","22b9bbff":"for i in range(0,n):\n    a=[float(s) for s in re.findall(r'-?\\d+\\.?\\d*', X.Q23.iloc[i])]\n    #re.findall finds the caracters that correspond to numbers in a string\n    a=np.absolute(a)\n    prom=np.mean(a)\n    X1[i,4]=prom","217bfaec":"for i in range (p):                 \n        prom=np.mean(X1[:,i])\n        desv=np.std(X1[:,i]) \n        X1[:,i]=(X1[:,i]-prom)\/desv","db408ca0":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit(X1)","2b3ec513":"pca.explained_variance_ratio_","137544bc":"z=pca.fit_transform(X1) #matrix containing the projections over the components","3ead9743":"componentes=pca.components_ \n# The components are displayed by rows and in order\n#of fraction of exlained variance\ncomponentes","f1a3491d":"vectors_c1c2=np.zeros((5,2))#array containing the first and second component for the five features\nvectors_c1c2[:,0]=componentes[0,:]\nvectors_c1c2[:,1]=componentes[1,:]\nvectors_c1c3=np.zeros((5,2))#array containing the first and third component for the five features\nvectors_c1c3[:,0]=componentes[0,:]\nvectors_c1c3[:,1]=componentes[2,:]\nvectors_c2c3=np.zeros((5,2))#array containing the second and third component for the five features\nvectors_c2c3[:,0]=componentes[1,:]\nvectors_c2c3[:,1]=componentes[2,:]","abcb7db1":"vectors_c1c2","91902414":"import matplotlib.pyplot as plt\ncolors=np.array(['red','blue','orange','black','green'])\nfig=plt.figure(figsize=(7,17))\nax=plt.subplot(3,1,1)\norigin = [0], [0]\nax.scatter(z[:,0],z[:,1])\nplt.xlabel(\"1st component\")\nplt.ylabel(\"2nd component\")\n#This generates the vectors corresponding to each feature in the corresponding components:\nfor i in range(vectors_c1c2.shape[0]):\n    plt.quiver(*origin,vectors_c1c2[i,0],vectors_c1c2[i,1], scale=2.5,label=X.columns[i],color=colors[i])\nplt.legend()\nplt.subplot(3,1,2)\norigin = [0], [0]\nplt.scatter(z[:,0],z[:,2])\nplt.xlabel(\"1st component\")\nplt.ylabel(\"3rd component\")\n#This generates the vectors corresponding to each feature in the corresponding components:\nfor i in range(vectors_c1c2.shape[0]):\n    plt.quiver(*origin,vectors_c1c3[i,0],vectors_c1c3[i,1], scale=7.0,label=X.columns[i],color=colors[i])\nplt.legend()\nplt.subplot(3,1,3)\norigin = [0], [0]\nplt.scatter(z[:,1],z[:,2])\nplt.xlabel(\"2nd component\")\nplt.ylabel(\"3rd component\")\n#This generates the vectors corresponding to each feature in the corresponding components:\nfor i in range(vectors_c1c2.shape[0]):\n    plt.quiver(*origin,vectors_c2c3[i,0],vectors_c2c3[i,1], scale=5.0,label=X.columns[i],color=colors[i])\nplt.legend()\n","40ecb432":"print('Q23:'+multipleCh_init.Q23.iloc[0])\nprint('Q4:'+multipleCh_init.Q4.iloc[0])","d47dbf27":"def histo(nombres):  #nombres= variable for which we want to generate the histogram \n    a=np.unique(nombres) #gets all posible values for the variable\n    cont=np.zeros(len(a)) # we are  going to count the # of apperances for every possible value\n    l=list(nombres) # we transform to list, to use the function count\n    for i in range(len(a)):           \n        cont[i]= l.count(a[i])   \n    mas=a[cont>5] # we will keep the ones that have more than 5 appearences in order to make\n    #histograms better visualy (5 is totally arbitrary)\n    nombres_mas=[]\n    for i in range(len(nombres)):\n        if(nombres[i] in mas):\n            nombres_mas.append(nombres[i])\n    h=plt.hist(nombres_mas,bins=len(mas),density=True)\n    plt.xticks(rotation='vertical')\n    ","f74cdb37":"def graficas(variable):\n    figura=plt.figure(figsize=(26,25))\n    limits=[-2.5,-1.0,0.0,1.0,2.5]\n    for i in range(len(limits)-1):\n        var_corte=X[str(variable)][(z[:,1]>limits[i]) & (z[:,1]<limits[i+1])]\n        var_corte1=np.array(var_corte)\n        plt.subplot(4,1,i+1)\n        h=histo(var_corte1)\n        plt.title(\"[\"+str(limits[i])+\",\"+str(limits[i+1])+\"]\") #on the top of every histogram\n        #is shown the corresponding interval from the second component\n        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=2.5)","1886a0b1":"print('on the top of every histogram is shown the corresponding interval from the second component ') \n#is shown the corresponding interval from the second component )\nprint('Q3:'+multipleCh_init.Q3.iloc[0])\ngraficas('Q3')#on the top of every histogram \n#is shown the corresponding interval from the second component \n#(remenber, this component) has an important weight from the feature of question Q23","07c2e97a":"print('on the top of every histogram is shown the corresponding interval from the second component ') \nprint('Q17:'+multipleCh_init.Q17.iloc[0])\ngraficas('Q17')#on the top of every histogram \n#is shown the corresponding interval from the second component","7603b910":"print('on the top of every histogram is shown the corresponding interval from the second component ') \nprint('Q5:'+multipleCh_init.Q5.iloc[0])\ngraficas('Q5')#on the top of every histogram \n#is shown the corresponding interval from the second component","f49630fe":"For Bob the grouping correponding to the second component seemed less predictable and more interesting. ' Peter must have thought the same thing' thought Bob. He called again to the T-shirts agency and no one answered. Using this grouping was the best shot Bob had to keep his job.Being  sure about his work, Bob decided to use  more information in order to know things about the members of each grouping, so that he could serve the better, and also for curiosity.FirSt, he made a function that generates histograms:","43537503":"Bob took the mean value for every possibe numerical range(including <1 year).For woman that had been programming for more than 40 years he took a mean value of 45 years arbitrarily. To the other cases he assigned the value 0. He called again to the T-shirt agency and no one answered.","0bbf4fa5":"For every range of ages in Q2, Bob took the mean value:","412e8499":"From the previous histograms, Bob concluded that for the women that spent less  time coding, the  proportion of the languages R and SQl users was more important than for other groups. ","b22332d4":"With more that 1500 respondents and 8 varibles in the survey, for Bob it was very hard to decide how to make the groups. How many groups? By age? by Higher level of education? While exploring the data in his office, he found a paper in a drawer, that said:'PCA first 5 columns'. Bob, instantaneously had the idea of performing a PCA on the survey.","208c8113":"The question Q17 was:","2c2f1328":"The question Q5 was:","b6ed30b4":"According to the previous histograms, Bob  concluded that in every group there was a majority of women from the United States; and in a second instance, from India. Besides, he observed that chinese women had the tendency to be more moderated with the time they spend actively coding( they  have a bigger proportion in the second histogram). ","9baa8f7a":"Again, taking averages on ranges:","d31b29e3":"Again,Bob took the mean value for every range of compensation. For persons that earn more than 500000 he took a mean value of 750000 years arbitrarily","06806067":"To perform PCA, Bob needed to normalize the data:","17a2b4e2":"At the end, Bob did a great jod and he was hired for the next event: 'Young people in data science and machine learning' ","75f8a3eb":"These are the fractions of the data explained by each component:","71102eb9":"To convert these possible answers , Bob considered the definition of higher education as indicated in the following link: http:\/\/www.euroeducation.net\/prof\/usa.htm\nBachelor and Porfessional degrees= level 1\nMaster degree = level 2\nDoctoral degree =level 3\nTo the other 2 entries he assigned the value of 0.\n","3c093d93":"The question Q3 was:","396a2519":"Based on those 3 graphs, Bob decided to make 4 groups. Observing the first graph, Bob decided to make the groups as following:\n- from -2.5 to -1 on the second component\n- from -1 to 0 on the second component\n- from 0 to 1 on the second component\n- from 1to 2.5 on the second component\n\nWhy on the second component? Bob  observed that four groups could be seen clearly in the 3 graphs. Also, he could see that the first component had an important weight from the feature corresponding to the quetion Q4; and that the second component had an important weight from the feature corresponding to the quetion Q23 . According to that,for a point with a high value on the second component, the corresponding woman spends more time actively coding ","8c95229c":"From the previous histograms, Bob concluded that for the group in which women spent less time coding (1st histogram) the proportion of women having a major in business  disciplines and engineering was bigger than for the other 3 groups.","401d7d57":"These are the possible answers for Q4: ","1d6448cb":"And here are the components:","a63b9fa8":"These are the possible age ranges in Q2:","b31bc18c":"And finally he made the histograms for the 3 remaining variables of the survey and taking into account the 4 groups defined previously. ","98d0b743":"These are the possible values for Q9:","fee7e087":"These are the possible answers for Q24:","7faa3177":"In the 1st international convention 'Women in data science and Machine Learning', Bob, the event organizer, needed to update about the work that had been done by the previous organizer, who was fired under dark circumstances. The previous organizer, had divided the attendants in  groups,in order to make teams to develop a sports competition during the convention. According to one dude that was in charge of the beverages of the event, Bob\u00b4s boss asked the previous organizer to find a creative way to find those groups. At his disposal, previous organizer had the survey the attendants had to fill out during their inscription. Here is the survey and the corresponding questions:","063ce293":"According to beverages dude,Peter, the angry previous organizer,tried not to leave any clue about how the groups were made and he had already designed and payed for the teams T-shirts which should have specific names printed based on the way he made the groups. Bob called the T-shirts agency but no one answered; it was friday afternoon, and probably they would not answer until monday, the day of the convention. Bob had to know which were the groups because ha had to organize other things based on that, and he couldn\u00b4t change the groups because there was some money that would be lost.According to beverages dude, the boss hated to lose money. ","bdafc336":"And finally, the possible values for Q23 are:"}}