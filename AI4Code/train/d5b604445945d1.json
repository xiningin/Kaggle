{"cell_type":{"356bab91":"code","2635982c":"code","42b04698":"code","2897691d":"code","039b77f9":"code","c92eaa73":"code","e8cacc8a":"code","b11df147":"markdown","0ce42e32":"markdown","dfc5fe08":"markdown","0de8f82b":"markdown","51cc8778":"markdown","0c20d256":"markdown","ba0f4761":"markdown","b1a5137b":"markdown","4273259b":"markdown","b70ea8be":"markdown"},"source":{"356bab91":"# import the Azure ML libs.\n\n!pip install azureml\n!pip install azureml.core\n!pip install azureml.widgets","2635982c":"import azureml.core\nimport azureml.widgets \nprint(\"Ready to use Azure ML\", azureml.core.VERSION)","42b04698":"from azureml.core import Workspace\n\n## in this segment you should replace the 3-parameters values according to the workspace available in the subscription\n## ths experiment will not work beyond this point if these values are not appropriatly inserted.\n## HENCE, THE Notebook Execution will terminate\n\n## Example - \n    ## ws = Workspace.get(name=\"<<MLSERVICENAME>>\", subscription_id='<<GUID - ML Service ID>>', resource_group='<<Hosting Azure Resource Group>>')\n\n# Pulling values from Kaggle Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nMLServiceName = user_secrets.get_secret(\"MLServiceName\")\naz_resource_grp = user_secrets.get_secret(\"az_resource_grp\")\nsub_id = user_secrets.get_secret(\"sub_id\")\n\n## Instanciating the Workspace object.\nws = Workspace.get(name=MLServiceName, subscription_id=sub_id, resource_group=az_resource_grp)\nprint(ws.name, \"loaded\")","2897691d":"import os, shutil\n\n# Create a folder for the experiment files\nfolder_name = 'experiment-files'\nexperiment_folder = '.\/' + folder_name\nos.makedirs(experiment_folder, exist_ok=True)\n\n#Copy the datast in the experiment folder so that it is made locally available to the model when it runs frm the script\nshutil.copy('..\/input\/iris-flower-dataset\/IRIS.csv', os.path.join(folder_name, \"IRIS.csv\"))","039b77f9":"%%writefile $folder_name\/iris_simple_experiment.py\nfrom azureml.core import Run\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\nimport os\n\n# Get the experiment run context -  we are going to pass this configuration later\nrun = Run.get_context()\n\n# load the data from a local file\ndata = pd.read_csv('IRIS.csv')\nX = data[['sepal_length', 'sepal_width','petal_length','petal_width']].values\nX=StandardScaler().fit_transform(X)\nY= (data['species']).map(lambda x: 0 if x=='Iris-setosa' else (1 if x=='Iris-versicolor' else 2))\n\n#Split data into train and test set\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state=1234)\n# fit the model\nmodel = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X_train,Y_train)\n\nY_pred = model.predict(X_test)\naccuracy = np.average(Y_test == Y_pred)\nprint(\"accuracy: \" + str(accuracy))\nrun.log(\"Accuracy\", np.float(accuracy))\n\n# Save the trained model in the outputs folder\n\nos.makedirs(\"outputs\", exist_ok=True)\njoblib.dump(value=model, filename='outputs\/iris_simple_model.pkl')\n# Complete the run\nrun.complete()","c92eaa73":"from azureml.core import Experiment, RunConfiguration, ScriptRunConfig\nfrom azureml.widgets import RunDetails\n\n# create a new RunConfig object\nexperiment_run_config = RunConfiguration()\nexperiment_run_config.environment.python.user_managed_dependencies = True\n\n# Create a script config\nsrc = ScriptRunConfig(source_directory=experiment_folder, \n                      script='iris_simple_experiment.py',\n                      run_config=experiment_run_config) \n\n# submit the experiment\nexperiment = Experiment(workspace = ws, name = 'iris-simple-experiment')\nrun = experiment.submit(config=src)\n\nRunDetails(run).show()\n\nrun.wait_for_completion()","e8cacc8a":"# Get logged metrics\nmetrics = run.get_metrics()\nfor key in metrics.keys():\n        print(key, metrics.get(key))\nprint('\\n')\nfor file in run.get_file_names():\n    print(file)","b11df147":"### Digging into Iris-Simple-Experiment's run.\nThe dashboard displays the snapshot of model experiment ran - \n\n![image.png](attachment:image.png)","0ce42e32":"> <u>**NOTE:**<\/u> the code below will create the experiment file in the \"experiment-files\" folder created above. Also it will upload the sample dataset from the input directory to the experiment folder so that it is available to the experiment script, as defined below, at the time of training the model.","dfc5fe08":"### Observations\n1. Line\\#11: Get the context of run configuration when the experiment is running the script.\n1. Create the output of the model in the Output folder (experiment-files)\n\n### Define RunConfig & ScriptRunConfig\nFrom here I am going to define:\n* <u>**RunConfig:**<\/u> Defines the Python code execution environment for the script - in this case, it will automatically create a Conda environment with some default Python packages installed. But here it will be using existine Kaggle runtime environment.\n* <u>**ScriptRunConfig:**<\/u> Identifies the Python script file to be run in the experiment, and the environment in which to run it.","0de8f82b":"### Snapshot\nDetails of files uploaded in the folder. \n![image.png](attachment:image.png)\n\n","51cc8778":"### View Experiment Results\n\nAfter the experiment has been finished, you can use the **run** object to get information about the run and its outputs:","0c20d256":"### Experiment's Output\nObserve the model file in pickle(pkl) format.\n![image.png](attachment:image.png)","ba0f4761":"### What Next - \nIn the next few notebooks I will look into more advance concepts of Azure Machine learning service API\n* Estimatior API  - Which will be used to encapsulate both RunConfiguration and ScriptRunConfiguration in single object.\n* Estimator API support various kind of python frameworks Scikit-Learn, Tensorflow, PyTorch.\n* Parameterize the Experiment Script to pass runtime values of the model variables.\n* Registering model in Azure ML for later infrencing.","b1a5137b":"### Connect to Your Workspace\nLook into the **[previous notebook](https:\/\/www.kaggle.com\/pankaj1234\/azure-machine-learning-introduction)** to understand this concept.\n","4273259b":"## ML Experiment Script File\n\nI am going to use an <u>**experiment script file**<\/u> to encapsulate the code for model defination, training and prediction. In this example, I will use a simple dataset the famous IRIS. I will run an experiment to explore the data, extracting statistics, visualizations, and data samples. Also I will train a simple logistic regression model. \nIn this experiment most importantly I will cover the concepts of <u>**experiment script, RunConfiguration and ScriptConfiguration**<\/u> to log details of the each run.","b70ea8be":"** IMPORTANT NOTE - **\n> Please proceed with this example **_iff_** you are familier with foundation of Microsoft Azure public cloud. \n> In this notebook, the basics of Microsoft Azure and its development methodology is not covered. As it will be beyond the scope of this notebook.\n\n\n# Azure Machine Learning Series - Introduction II\n\n\nIn the <u>first notebook<\/u> I have already discussed about the nitty-gritty of Azure ML service. In the notebook we have covered -\n#### PART 1: [Azure Machine Learning service - Introduction](https:\/\/www.kaggle.com\/pankaj1234\/azure-machine-learning-introduction) \n* Creating an instance of Azure ML service\n* Downloading libraries\/dependencies (in Kaggle environment)\n* Various methods to connect to Azure ML service workspace: using config file and using get() method.\n* Simple ML experiment -  for data exploration. Capture the details from the experiment, logging and preserving the run details from the experiment. \n* Overview of Azure ML Service Dashboard. Experiment Dashboard.\n\n#### This is my second notebook\nIn this notebook I will cover more about more advanced configurations by inheriting the learnings from the previous notebook:\n* Here I will create an **experiment script** to encapsulate a core functionality expected from a model training and execution.\n* The Machine Learning Service expects - environment and run configuration where the model should be to running."}}