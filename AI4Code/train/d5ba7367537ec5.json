{"cell_type":{"8bfdaff3":"code","29a92a29":"code","6c67d624":"code","287d8a80":"code","9c0d3f38":"code","09892abb":"code","69595b18":"code","e6de38c7":"code","9a6a3ab2":"code","ceb1bd7e":"code","5656fc40":"code","5b62e803":"code","cd7c85df":"code","3e8cf49f":"code","b7dd098f":"code","71e3382b":"code","1c15e793":"code","3325f945":"code","ae7161c0":"code","4bc1fbe6":"code","764d9bc3":"code","f7424367":"code","a6968241":"code","a35d7e57":"code","6b8154b7":"code","df6bb535":"code","848142f2":"code","8892bc98":"code","be6637d3":"code","89187544":"code","6345a9f6":"code","e1877d7c":"code","9c015143":"code","09d21c73":"code","fab705a3":"code","2430fb71":"code","c769ff35":"code","35f1370a":"code","990af805":"code","4c2026a9":"code","1efbc06f":"code","d8b3d3ba":"code","8405d017":"code","1d996454":"code","afb51f95":"code","4a44a1c3":"code","93279a3c":"markdown","64d5adcf":"markdown","0cb643b2":"markdown","c72f121e":"markdown","fce3a57d":"markdown","86cb403c":"markdown","4088fb9a":"markdown","618f4527":"markdown","02f15802":"markdown","9ea7a40b":"markdown","7f15b9de":"markdown","697912f4":"markdown","9493d7d2":"markdown","eb7392eb":"markdown","5de75e56":"markdown","ed77b3a8":"markdown","6d5d11db":"markdown","6451dc6d":"markdown","e26f4a4c":"markdown","df5a7b6a":"markdown","e1fc9122":"markdown","1224f356":"markdown","15c15a86":"markdown","1fc95ce5":"markdown","668e4519":"markdown","35433ac7":"markdown","a76f82f2":"markdown","013e9d5f":"markdown","9e905f84":"markdown","41932246":"markdown","6581c7b1":"markdown"},"source":{"8bfdaff3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","29a92a29":"# important python libraries for machine learning\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt # visualizing data\nimport seaborn as sns # visualizing data with stunning default theme\nimport sklearn # contain algorithms\nplt.rcParams[\"figure.figsize\"] = (20,10)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# load dataset from input directory\ndf = pd.read_csv(\"..\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv\") \ndf.head()\n","6c67d624":"df.shape","287d8a80":"df.groupby('area_type')['area_type'].agg('count')","9c0d3f38":"#dropping some columns\ndf2 = df.drop(['area_type','society','balcony','availability'],axis='columns')\ndf2.head()","09892abb":"#before dropping null value, lets check it column-wise\ndf2.isnull().sum()","69595b18":"# We can fill the missing-values using median but\n# here the missing values are less compare to dataset size, so we are dropping\ndf3 = df2.dropna()\ndf3.isnull().sum()","e6de38c7":"#to drop duplicate values\ndf4 = df3.drop_duplicates()\nprint(\"Dataset size before dropping duplicate values: {} and after {}\".format(df3.shape, df4.shape))","9a6a3ab2":"#lets check size column\ndf4['size'].unique()","ceb1bd7e":"#from above analysis, we found the datatype inappropriate for ml-model\n#4-Bedroom and 4 BHK are same and so on. We create new column with integer type and \n# convert the given size-column. We don't drop size column for later use.\ndf4['bhk'] = df4['size'].apply(lambda x: int(x.split(' ')[0]))\ndf4.head()\n","5656fc40":"df4['bhk'].unique()","5b62e803":"df4.total_sqft.unique()","cd7c85df":"# the above analysis shows an inappropriate data in total_sqft column\ndef is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","3e8cf49f":"# we use ~ negative opperator to show the inappropriate data\ndf4[~df4['total_sqft'].apply(is_float)].head(10)","b7dd098f":"def convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens)==2:\n        return (float(tokens[0]) + float(tokens[1]))\/2\n    try:\n        return float(x)\n    except:\n        return None","71e3382b":"df5 = df4.copy()\ndf5['total_sqft'] = df5['total_sqft'].apply(convert_sqft_to_num)\ndf5.head()","1c15e793":"df5.isnull().sum()","3325f945":"# dropping the created missing values with our convert_sqft_to_num\ndf5=df5.dropna()\ndf5.isnull().sum()","ae7161c0":"df6 = df5.copy()\n# the given price is in lac unit and we are converting it into rupees\ndf6[\"price_per_sqft\"] = df6['price']*100000\/df6['total_sqft']\ndf6.head()","4bc1fbe6":"len(df6.location.unique())","764d9bc3":"# 1298 is high dimensionality problem. if we apply one hot-encoding on this,\n# we will get high number of feature.\n# we will check the number of rows for each category and will make some threshold\n# for keeping the category. Obviously categories with less rows(samples)\n# will be placed in 'other' category.\ndf6.location = df6.location.apply(lambda x: x.strip()) # remove leading or end spaces\nlocation_stats = df6.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_stats","f7424367":"len(location_stats[location_stats <= 10])","a6968241":"# we add all these 1057 unique categories with less or equal to 10 rows into 'other' category\nlocation_stats_less_than_ten = location_stats[location_stats<=10]\ndf6.location = df6.location.apply(lambda x: 'other' if x in location_stats_less_than_ten else x)\ndf6.location.head(10)","a35d7e57":"df6[df6.total_sqft\/df6.bhk <300].head()","6b8154b7":"# to remove the outiers\ndf7 = df6[~(df6.total_sqft\/df6.bhk <300)]\nprint(\"Data Size before outlier removal: {} and after: {}\".format(df6.shape, df7.shape))","df6bb535":"df7.price_per_sqft.describe()","848142f2":"def remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('location'):\n        m = np.mean(subdf.price_per_sqft)\n        st = np.std(subdf.price_per_sqft)\n        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft <=(m+st))]\n        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n    return df_out","8892bc98":"df8 = remove_pps_outliers(df7)\ndf8.shape","be6637d3":"def plot_scatter_chart(df,location):\n    bhk2 = df[(df.location == location) & (df.bhk==2)]\n    bhk3 = df[(df.location == location) & (df.bhk==3)]\n    plt.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft,bhk2.price, color='blue', label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price\")\n    plt.title(location)\n    plt.legend()\n\n# we can check for different locations\nplot_scatter_chart(df8,'Rajaji Nagar')","89187544":"def remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft < (stats['mean'])].index.values)\n    return df.drop(exclude_indices, axis='index')\n\ndf9=remove_bhk_outliers(df8)\ndf9.shape","6345a9f6":"# let re-check the price using our defined scatter plot function\nplot_scatter_chart(df9,'Rajaji Nagar')","e1877d7c":"plt.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df9.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")","9c015143":"# lets first check if there is any such case\ndf9[df9.bath>df9.bhk+2]","09d21c73":"#lets remove the rows that doesn't satisfy the threshold of bathrooms\ndata = df9[df9.bath<df9.bhk+2]\ndata.shape","fab705a3":"data = data.drop(['size','price_per_sqft'], axis=1)\ndata.head()","2430fb71":"dummies = pd.get_dummies(data.location)\ndummies.head(3)","c769ff35":"# to avoid dummy trap, we will drop one column from dummy data \n# and consider 0 value instead of that column value\ndata2 = pd.concat([data,dummies.drop('other',axis='columns')], axis='columns')\ndata2.head(3)","35f1370a":"# now we can drop location column because that is converted into numeric\ndata3 = data2.drop('location',axis='columns')\ndata3.head(3)","990af805":"X = data3.drop('price',axis=\"columns\")\nY = data3.price\nprint(\"Depented Features: {}    Independent Feature: {}\".format(X.shape, Y.shape))","4c2026a9":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10)","1efbc06f":"from sklearn.linear_model import LinearRegression\n#build model\nlr_clf = LinearRegression()\n# training our model\nlr_clf.fit(X_train,Y_train)\n#testing our model\nlr_clf.score(X_test, Y_test)","d8b3d3ba":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\ncross_val_score(LinearRegression(), X, Y, cv=cv)","8405d017":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,Y):\n    algos = {\n        'linear_regression' : {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n                }\n             },\n             'lasso':{\n                 'model': Lasso(),\n                 'params': {\n                     'alpha': [1,2],\n                     'selection': ['random', 'cyclic']\n                     }\n                  },\n              'decision_tree': {\n                  'model': DecisionTreeRegressor(),\n                  'params': {\n                      'criterion': ['mse', 'friedman_mse'],\n                      'splitter': ['best', 'random']\n                      }\n                  }\n              }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score = False)\n        gs.fit(X,Y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n            })\n            \n    return pd.DataFrame(scores, columns=['model','best_score', 'best_params'])\n    \nfind_best_model_using_gridsearchcv(X,Y)","1d996454":"# lr_cfr is already trained\n# we write a function to predict prices for some data\ndef predict_price(location,area,bathroom, bedroom):\n    loc_index = np.where(X.columns==location)[0][0]\n    \n    x=np.zeros(len(X.columns))\n    x[0] = area\n    x[1] = bathroom\n    x[2] = bedroom\n    if loc_index >=0:\n        x[loc_index] = 1\n    return lr_clf.predict([x])[0]\n\npredict_price('1st Phase JP Nagar',1000,3,3)","afb51f95":"import pickle\nmodel_file = \"banglore_home_prices_model.pickle\"\nwith open(model_file,'wb') as f:\n    pickle.dump(lr_clf,f)","4a44a1c3":"import json\ncolumns = {\n    'data_columns' : [col.lower() for col in X.columns]\n    }\nwith open('columns.json', 'w') as f:\n    f.write(json.dumps(columns))","93279a3c":"#### **evaluate machine learning model using k-fold cross-validation**","64d5adcf":"#### **Now we check price per sqft if that is feasible or not**","0cb643b2":"### **TO find path of dataset**","c72f121e":"### **Use Histogram to find the distribution of data w.r.t price_per_sqft**","fce3a57d":"### **Outlier Detection and Removal**  \nOutliers are the data points which are data errors but some time they represent extrem variation.\nWe can use techniques like:\n* Standard deviation\n* Domain knowledge","86cb403c":"### **To check the price for 2 and 3 bedroom in same location and equal area**  \nIn this step, we can learn how to think about cleaning the dataset with outliers and wrong data.\nSo we will check that if the area is same but 2-bedroom cost is high than 3-bedroom, it means there are still false data in our dataset.","4088fb9a":"#### **To check categories in a are_type column**  \nIt is helpful to analyze the dataset for categorical balance of data.","618f4527":"#### **Let, we have been told for a room per sqft threshold as 300**  \nAs a data-scientist we will check our dataset for outliers which includes rooms with less then the \ngiven threshold. We will remove such samples from data considering as inappropiate.","02f15802":"#### **To check the number of unique categories in location column**","9ea7a40b":"We can compare the plot_scatter_chart function for our df8 and new dataframe df9 as shown above. We have removed all the samples with false information.","7f15b9de":"#### **Spliting the data for training and testing**","697912f4":"#### **To remove columns**  \nTo make the project simple for beginners, we assume *areatype, society, balcony, availability* columns unuseful and remove these columns.","9493d7d2":"#### **To transform the column into appropriate datatype or category**","eb7392eb":"We got other missing values on applying our function because we put None for values with units like meters etc and just convert simple value or range value(x1-x2) into float","5de75e56":"#### **We also store the columns name for later use in website**\n","ed77b3a8":"The above detail shows that according to the selected areas there isn't any area with such min or max area per sqft price. It clearly shows the variation in the given data.","6d5d11db":"## **Data Cleaning**  \nIn this process, we handle the Null\/missing values and duplicate values.","6451dc6d":"It is found that Linear Regression model performs well and should be selected for price prediction","e26f4a4c":"## **Building Machine-Learning Model**  \nYet, we have sting for location column which cannot be interpreted through machine-learning model. To convert the text into numeric values, we use one hot-encoding technique using pandas dummy.","df5a7b6a":"## **How to build a real estate price prediction website**  \n\nThis data science project series walks through step by step process of how to build a real estate price prediction website.  \n\n#### **Step-1:**  \nWe will first build a model using sklearn and linear regression using banglore home prices dataset from kaggle.  \n[Bengaluru House Price Dataset](https:\/\/www.kaggle.com\/amitabhajoy\/bengaluru-house-price-data)\n#### **Step-2:**  \nSecond step would be to write a python flask server that uses the saved model to serve http requests.  \n#### **Step-3:**\nThird component is the website built in html, css and javascript that allows user to enter home square ft area, bedrooms etc and it will call python flask server to retrieve the predicted price. \n\n#### **Summary**\nDuring model building we will cover almost all data science concepts such as data load and cleaning, outlier detection and removal, feature engineering, dimensionality reduction, gridsearchcv for hyperparameter tunning, k fold cross validation etc.  \nTechnology and tools wise this project covers;  \n*  Python\n*  Numpy and Pandas for data cleaning\n*  Matplotlib for data visualization\n*  Sklearn for model building\n*  Jupyter notebook, visual studio code and pycharm as IDE\n*  Python flask for http server\n*  HTML\/CSS\/Javascript for UI  ","e1fc9122":"#### **Separating the dependent and independent features**","1224f356":"### **To export(save) the model into pickle file to use in website for prediction**","15c15a86":"Now we remove those bedroom appertments whose price_per_sqft is less then the mean of 1-less bedroom appartments.","1fc95ce5":"#### **Using GridSearchCV method to find best algorithm for our model**","668e4519":"## **Feature Engineering**  \nIn this step, we add new feature which will be helpful for outlier detection and removal later-on.\nWe will also refine categorical data in location column for one hot-encoding later-on.","35433ac7":"#### **We check number of bathroom in the dataset for outliers**\nLets we finalize in team meeting to remove the samples(rows) with \nnumber_of_bathrooms > number_of_bedrooms + 2","a76f82f2":"#### **Training and testing Linear Regression model**","013e9d5f":"#### **Now our data is much clean**  \nWe will remove the features(columns) that are unnecessary for machine learning model.\nSuch as 'size' and price_per_sqft. We need these for outlier detection but aren't useful for ml-model. ","9e905f84":"### **Importing required libraries and loading data**","41932246":"## **Building House Price Prediction Model**","6581c7b1":"#### **To check total_sqft column**"}}