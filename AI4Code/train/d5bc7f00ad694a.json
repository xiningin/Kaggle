{"cell_type":{"094a30b5":"code","5d1ee542":"code","8386ab38":"code","215e0a96":"code","5cc0e003":"code","a66f1493":"code","d02d6e90":"code","d907e48a":"code","c49386ba":"code","0f7f11a1":"code","fdcdb281":"code","43b77feb":"code","bf72b821":"code","f37d9f1c":"code","1f8d0cdf":"code","bf64147d":"code","620dd008":"code","109f73e1":"code","4a258464":"code","c6569c88":"code","29d8e307":"code","9e0eec6a":"code","42bb89f9":"code","43945b8d":"code","852f5353":"code","638de2e9":"code","ba24d062":"code","a3503e63":"code","c758df79":"code","5617d90a":"code","5d42c190":"code","b13bbf93":"code","2bea7af0":"code","a6cce527":"code","5825de71":"code","ee5ebc42":"code","659a007c":"code","e2c5d789":"code","26e2bd07":"code","ef7d2b63":"code","d93fb662":"code","115351e3":"code","0547cc40":"code","c21bbc51":"code","baa38d76":"code","7adcfd77":"markdown","d0345ba9":"markdown","351025f0":"markdown","03d1eb9f":"markdown","c6d04606":"markdown","a7ce1ca8":"markdown","63add829":"markdown","781487d0":"markdown","915c0aa4":"markdown","d0e8cec5":"markdown","674c7ac0":"markdown","37fafd27":"markdown","4b72ddcc":"markdown","28cc0b02":"markdown","1cd9fd7d":"markdown","24011b61":"markdown","3974afd3":"markdown","24f91a31":"markdown","56399199":"markdown","7ae34087":"markdown","e5927a3c":"markdown","5a587763":"markdown","ead086a5":"markdown","d5eff16c":"markdown","5ea65e6a":"markdown","98f0b178":"markdown","7cc106b2":"markdown","3d7a0a68":"markdown","9baf72dd":"markdown","528188d1":"markdown","d46bebcb":"markdown","0ec36dca":"markdown","b6c1bc27":"markdown","b1fb3171":"markdown"},"source":{"094a30b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d1ee542":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')","8386ab38":"fishmarket = pd.read_csv('..\/input\/fish-market\/Fish.csv')\nfishmarket.head()","215e0a96":"fishmarket.shape","5cc0e003":"fishmarket.describe()","a66f1493":"fishmarket.info()","d02d6e90":"[any(i[1:] < 0)for i in fishmarket.values]","d907e48a":"fishmarket.all()","c49386ba":"fishmarket.loc[fishmarket['Weight']==0]\n\n    ","0f7f11a1":"'In this exercise i chose to impute the data'\nfishmarket.loc[fishmarket['Weight'] == 0, 'Species'] = 'XRoach'\nfishmarket.iloc[40]","fdcdb281":"def five_factor_mean(len1, len2, len3, height, width):\n    return np.mean([len1, len2, len3, height, width])\n\nfishmarket['Mean'] = fishmarket.apply(lambda row: five_factor_mean(row['Length1'], row['Length2'], \n                                                            row['Length3'], row['Height'], \n                                                            row['Width']), axis=1)\nfishmarket.head()\n\n    \n    ","43b77feb":"sorted_df = fishmarket.sort_values('Mean', ascending=True)\nsorted_df.head(43)","bf72b821":"fishmarket.loc[fishmarket['Species'] =='Roach']","f37d9f1c":"'''Based on the data from tables above, it would be a good guess to fill in the value of 110\nfor the zero value'''\nfishmarket['Species'].iloc[40] = 'Roach'\nfishmarket['Weight'].iloc[40] = 110\nfishmarket.head(41)","1f8d0cdf":"new_length_names = {'Length1' : 'Standard length',\n                    'Length2': 'Fork length',\n                    'Length3': 'Total length'} \nfishmarket.rename(columns=new_length_names, inplace=True)\nfishmarket.head()\n","bf64147d":"mean_values = fishmarket.describe().iloc[1]\n","620dd008":"def histo_boxplot(df, col):\n    plt.figure(figsize=(20,8))\n\n    plt.subplot(1,2,1)\n    plt.title(f'{col} Distribution Plot')\n    sns.distplot(df[f'{col}'])\n    \n    plt.axvline(mean_values[f'{col}'])\n\n    plt.subplot(1,2,2)\n    plt.title(f'{col} Price Spread')\n    sns.boxplot(y=df[f'{col}'])\n\n    plt.show()\n\nfor col in fishmarket.columns[1:-1]:\n    histo_boxplot(fishmarket, col)\n\n\n    \n    ","109f73e1":"specie_count = fishmarket.groupby('Species').count()['Weight']\nsorted_count = specie_count.sort_values(ascending=False)\nspecie_weight = fishmarket.groupby('Species').sum()['Weight']\nsorted_count","4a258464":"def specie_plot():\n    plt.style.use('seaborn')\n    labels1 = specie_weight.index\n    labels2 = sorted_count.index\n    fig, (ax1, ax2) = plt.subplots(1,2)\n    \n    \n    ax1.bar(sorted_count.index, sorted_count)\n    ax1.set_title('Count of Species')\n    ax1.set_xlabel('Species')\n    ax1.set_ylabel('Count')\n    plt.xticks(rotation=45, ha='right')\n    ax1.set_xticklabels(labels2, rotation=45, ha='right')\n    \n    ax2.pie(specie_weight, labels=labels1, shadow=True, autopct='%1.1f%%')\n    ax2.set_title('Weight percentage of species')\n    \n    \n    fig.set_size_inches(10, 10)\n   \n    plt.show() \nspecie_plot()","c6569c88":"specie_mean = fishmarket.groupby('Species').mean()\nsorted_mean = specie_mean.sort_values('Weight', ascending=False)","29d8e307":"\nfig, ax = plt.subplots()\nx_indexes = np.arange(len(sorted_mean.index))   \nspecies = sorted_mean.index\n\nwidth = 0.2\nax.bar(x_indexes-width, sorted_mean['Weight'], label='Weight', width=width)\nax.bar(x_indexes, sorted_mean['Total length'], label='Total length', width=width)\nax.bar(x_indexes+width, sorted_mean['Height'], label='Height', width=width)\nax.bar(x_indexes+(width*2), sorted_mean['Width'], label='Width', width=width)\n\nax.set_title(\"Comparision of species'features\")\nax.set_xlabel('Features')\nax.set_ylabel('Centimeter')\nax.set_yscale('log')\nfig.set_size_inches(10, 12)\n#ax.set_xticklabels(labels=['Pike', 'Bream', 'Whitefish',\n #                          'Perch', 'Roach', 'Parkki',\n #                          'Smelt'])\nplt.xticks(ticks=x_indexes, labels=species, rotation=45)\nplt.legend()\nplt.show()","9e0eec6a":"def scatter(x,fig):\n    plt.style.use('classic')\n    plt.subplot(3,2,fig)\n    plt.scatter(fishmarket[x],fishmarket['Weight'])\n    plt.title(x+' vs Weight')\n    plt.ylabel('Weight')\n    plt.xlabel(x)\n    plt.tight_layout()\n    \n    \nplt.figure(figsize=(10,15))\n\nscatter('Standard length', 1)\nscatter('Fork length', 2)\nscatter('Total length', 3)\nscatter('Height', 4)\nscatter('Width', 5)\n","42bb89f9":"# check correlation coefficient between all numerical features\ndf_for_p = fishmarket.iloc[:, 1:-1]\ncorr = df_for_p.corr(method='pearson')\ncorr","43945b8d":"p_value = {}\nfor col1 in df_for_p.columns:\n    p_li = []\n    for col2 in df_for_p.columns:\n        r, p = stats.pearsonr(df_for_p[f'{col1}'], df_for_p[f'{col2}'])\n        p_li.append(p)\n    p_value[f'{col1}'] = p_li\n            \n\ndf_p = pd.DataFrame(p_value, index=df_for_p.columns)\ndf_p\n        ","852f5353":"# Correlation using heatmap\nplt.style.use('Solarize_Light2')\nplt.figure(figsize = (10, 10))\nsns.heatmap(df_for_p .corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","638de2e9":"final_df = fishmarket[['Species', 'Weight', 'Total length', 'Height', 'Width']]\nspecie_dummies = pd.get_dummies(final_df['Species'], drop_first = True)\nfinal_df = pd.concat([final_df, specie_dummies], axis = 1)\nfinal_df.drop(columns = 'Species', axis = 1, inplace=True)","ba24d062":"final_df","a3503e63":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(final_df, train_size = 0.7, test_size = 0.3, random_state = 42)","c758df79":"df_train.head()","5617d90a":"df_test.head()","5d42c190":"'''This step is optional here, i tried scaling and it did not change the result. I wanted to plot\nthe true weight unit so i'll proceed without scaling the numerical data'''\n# from sklearn.preprocessing import MinMaxScaler\n# scaler = MinMaxScaler()\n# num_vars = ['Weight', 'Total length', 'Height', 'Width']\n# df_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n# df_train.head()","b13bbf93":"y_train = df_train.pop('Weight')\nX_train = df_train","2bea7af0":"import statsmodels.api as sm \ndef build_model(X,y):\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X","a6cce527":"X_train_new = build_model(X_train,y_train)","5825de71":"X_train_new = X_train_new.drop([\"Roach\"], axis = 1)\n","ee5ebc42":"X_train_new = build_model(X_train_new, y_train)","659a007c":"# Drop WItdh feature\nX_train_new = X_train_new.drop([\"Width\"], axis = 1)\n","e2c5d789":"X_train_new = build_model(X_train_new, y_train)","26e2bd07":"# Drop Whitefish feature\nX_train_new = X_train_new.drop([\"Whitefish\"], axis = 1)","ef7d2b63":"X_train_new = build_model(X_train_new, y_train)","d93fb662":"# Drop Perch feature\nX_train_new = X_train_new.drop([\"Perch\"], axis = 1)","115351e3":"X_train_new = build_model(X_train_new, y_train)","0547cc40":"lm = sm.OLS(y_train,X_train_new).fit()\ny_train_weight = lm.predict(X_train_new)","c21bbc51":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_weight), bins = 10)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)   ","baa38d76":"def residual_plot(x, fig): # Do residual plot for each independet variable\n    plt.style.use('classic')\n    plt.subplot(3,2,fig)\n    if x == 'Predicted value' and fig ==6:\n        plt.scatter(y_train, y_train - y_train_weight)\n        plt.axhline(0)\n        plt.title(x+ ' and Residuals')\n        plt.xlabel(x)\n        plt.ylabel('Residuals')\n       \n    elif x != 'const':\n        plt.scatter(X_train_new[f'{x}'], y_train - y_train_weight)\n        plt.axhline(0)\n        plt.title(x+ ' and Residuals')\n        plt.xlabel(x)\n        plt.ylabel('Residuals')\n\nplt.figure(figsize=(10,15))\n\nresidual_plot('Total length', 1)\nresidual_plot('Height', 2)\nresidual_plot('Parkki', 3)\nresidual_plot('Smelt', 4)\nresidual_plot('Pike', 5)\nresidual_plot('Predicted value', 6)\n\n\n        ","7adcfd77":"**Inference**\n- Features: 2 types of length and width show highly positive correlation, linear relationship with weight\n- Height also shows significant positive correlation with height but it seems like there are a considerable amount of heavy fish which does not have great height","d0345ba9":"**3.1 Visualization for categorical data**","351025f0":"**Making decision**: what to do with the zero value:\n1. remove the row containing zero out of the dataframe\n2. impute (make an educated guess about) the zero value \nIn this case i'll choose the second option and fill the weight value \nof the fish with similar characteristics ","03d1eb9f":"\n# Step 3: Visualization","c6d04606":"# Step 6: Build model","a7ce1ca8":"**Inference**\nThe errors seem to be relatively normally distributed","63add829":"> Model 1","781487d0":"**Inference**\n- The plot of target (weight) seems to be positively skewed, suggesting that most of values are below 1000. Also it is worth noting that the mean is much higher than the median, which indicates a strong influence of the bigger values\n- The mean and median of the features are pretty close to each other as the result their distributions are not so skewed to the right like the weight distribution\n- Last but not least, the plot of heigth resembles a bimodal distribution while that of width somewhat approcimates a normal distribution\n","915c0aa4":"> There is no missing value in the dataframw","d0e8cec5":"**For numerical data**","674c7ac0":"> There is no unexpected negative value","37fafd27":"**Inference**\n- The three most popular species are Perch, Bream and Roach\n- the high count of Pearch, Bream and Pike corresponds to its large contribution to total weight\n- Smelt only represents 0.2% of the total weigth\n","4b72ddcc":"> Model 5","28cc0b02":"**This is my first time doing an online data analysis and science project. I hope it is not too bad. i would be really grateful for any comments, escpecially ones on the nonlinear model. Credits: I got the inspiration from [SHALINI GOYAL](http:\/\/www.kaggle.com\/goyalshalini93\/car-price-prediction-linear-regression-rfe)**","1cd9fd7d":"**Linear regression**","24011b61":"# Step 5: train-test split and feature scaling","3974afd3":"Drop Roach because the p value is too high","24f91a31":"> It makes no sense that a fish can weigh nothing","56399199":"# Step 1: import and read the data\n- Using pandas library","7ae34087":"# Step 2: Data cleaning","e5927a3c":"> Model 3","5a587763":"# Step 5: Dummy variables","ead086a5":"**3.1 Visualization for numerical data**","d5eff16c":"**Inference**\n- Total length strongly influences the weight of fish\n- Width and height also influences the weight of fish but not as strongly as total length\n","5ea65e6a":"**Inference**:\n- All features have high positive correlation with Weight\n- Standard length, Fork length and Total length are highly correlated with each other, so we should drop 2 of those features\n- In th\u00eds case i will drop Standard length, Fork length","98f0b178":"> Model 2","7cc106b2":"> Model 4","3d7a0a68":"> According to [this image](http:\/www.google.com\/search?q=3+common+length+measurements+of+fish&sxsrf=AOaemvJ3g4mGbAO6PhLT-XQd690TeLLHbw:1638067796438&tbm=isch&source=iu&ictx=1&fir=0MR9QOw4D8VPeM%252Cp04NTu-edYUxGM%252C_&vet=1&usg=AI4_-kSxJ_3cxEIsJLqTZvANf9WDzi_1OA&sa=X&ved=2ahUKEwjVmf-Ihrr0AhWKA4gKHUyWAlYQ9QF6BAgFEAE&biw=1366&bih=657&dpr=1#imgrc=0MR9QOw4D8VPeM), i make a guess that the feature names of Length1,... should be changed into:\n- Length 1 = Standard length\n- Length 2 = Fork length\n- Length 3 = Total length\n","9baf72dd":"**Take a quick look of the data**","528188d1":"# Step 7: Residual analysis","d46bebcb":"# Step 4: check multicolinearity","0ec36dca":"**Note**\n- i have not learnt about multiple nonlinear regression yet, so i can't further the analyis. But you can certainly try to predict y_test using X_test and plot the results to see how well it does\n","b6c1bc27":"> it looks like there is zero value in column 'Weight'","b1fb3171":"**Inference**\n- It lookes like the the residual plot of Total length has some curvature, which implies that a nonlinear model would predict better the trend"}}