{"cell_type":{"a1a9ed05":"code","a2876e3f":"code","fd176253":"code","e2ffbcb1":"code","4118c2dd":"code","5c11bb1b":"code","d70f0d6d":"code","353eb440":"code","225c81a0":"code","bdbd8507":"code","44f249e5":"code","a59b4d8d":"code","b040cfc8":"code","830cc52f":"code","3abcdde9":"code","00c8c25e":"code","0bf99665":"code","7fe53881":"code","4af86de6":"code","a7da35b8":"code","33604931":"code","c3263ada":"code","32154152":"code","8e86ff55":"code","e03135fa":"markdown","8f26f05c":"markdown","06a87f8f":"markdown","e451238a":"markdown","2814b0f4":"markdown","76d750dc":"markdown","56183d20":"markdown","1022dde9":"markdown","2ac27f8a":"markdown","bc26f736":"markdown","0afd63cd":"markdown","e1d9745a":"markdown","859c488d":"markdown","c3a38ae5":"markdown","587b3edb":"markdown","df49cdcb":"markdown","498f65e6":"markdown","b7b2ded6":"markdown","e206ed21":"markdown","674a6050":"markdown","71d48146":"markdown","2937eb2e":"markdown","55240542":"markdown","2be654dc":"markdown","a57c440f":"markdown","6d1881f1":"markdown","9592dee8":"markdown","6a145fda":"markdown"},"source":{"a1a9ed05":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport plotly.graph_objs as go\nimport plotly.offline as py\n","a2876e3f":"df = pd.read_csv('..\/input\/cyberbullying-classification\/cyberbullying_tweets.csv')\n","fd176253":"df.head()","e2ffbcb1":"df.shape","4118c2dd":"target=df.cyberbullying_type.unique()\ntarget","5c11bb1b":"df.duplicated().sum()","d70f0d6d":"df=df.drop_duplicates()","353eb440":"df.info()","225c81a0":"d = {'not_cyberbullying': 'NO', 'ethnicity': 'Ethnicity','age':'Age','religion':'Religion','other_cyberbullying':'Other','gender':'Gender'}\npy.init_notebook_mode()\ndata = [go.Bar(\n            x = df.cyberbullying_type.map(d).unique(),\n            y = df.cyberbullying_type.value_counts().values,\n            marker= dict(colorscale='RdBu',\n                         color = df.cyberbullying_type.value_counts().values\n                        ),\n            text='Cyberbullying tweets'\n    )]\n\nlayout = go.Layout(\n    title='Target variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')\nplt.show()","bdbd8507":"all_words = df['tweet_text'].str.split(expand=True).unstack().value_counts()\npy.init_notebook_mode()\ndata = [go.Bar(\n            x = all_words.index.values[0:50],\n            y = all_words.values[0:50],\n            marker= dict(colorscale='RdBu',\n                         color = all_words.values[2:100]\n                        ),\n            text='Word counts'\n    )]\n\nlayout = go.Layout(\n    title='Top 50 (Uncleaned) Word frequencies in the training dataset'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')\nplt.show()","44f249e5":"lbl_enc = preprocessing.LabelEncoder()\ny = lbl_enc.fit_transform(df.cyberbullying_type.values)","a59b4d8d":"xtrain, xvalid, ytrain, yvalid = train_test_split(df.tweet_text.values, y, \n                                                  stratify=y, \n                                                  random_state=42, \n                                                  test_size=0.1, shuffle=True)","b040cfc8":"\ntfv = TfidfVectorizer(min_df=1,  max_features=None, \n            strip_accents='unicode', analyzer='word',\n            ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')\n\n\ntfv.fit(list(xtrain) + list(xvalid))\nxtrain_tfv =  tfv.transform(xtrain) \nxvalid_tfv = tfv.transform(xvalid)","830cc52f":"py.init_notebook_mode()\nfeature_names = tfv.get_feature_names()\ncount_vec = np.asarray(xtrain_tfv.sum(axis=0)).ravel()\nzipped = list(zip(feature_names, count_vec))\nx, y = (list(x) for x in zip(*sorted(zipped, key=lambda x: x[1], reverse=True)))\n\nY = np.concatenate([y[0:15], y[-16:-1]])\nX = np.concatenate([x[0:15], x[-16:-1]])\n\n\ndata = [go.Bar(\n            x = x[0:50],\n            y = y[0:50],\n            marker= dict(colorscale='RdBu',\n                         color = y[0:50]\n                        ),\n            text='Word counts'\n    )]\n\nlayout = go.Layout(\n    title='Top 50 Word frequencies after Preprocessing'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')\nplt.show()\n","3abcdde9":"\nclf = LogisticRegression(C=1.0)\nclf.fit(xtrain_tfv, ytrain)\npredictions = clf.predict(xvalid_tfv)\n\nprint ( classification_report(yvalid, predictions,target_names=target))","00c8c25e":"\nclf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\nclf.fit(xtrain_tfv.tocsc(), ytrain)\npredictions = clf.predict(xvalid_tfv.tocsc())\n\nprint ( classification_report(yvalid, predictions,target_names=target))","0bf99665":"ctv = CountVectorizer(analyzer='word',\n            ngram_range=(1, 3), stop_words = 'english')\n\n\nctv.fit(list(xtrain) + list(xvalid))\nxtrain_ctv =  ctv.transform(xtrain) \nxvalid_ctv = ctv.transform(xvalid)","7fe53881":"py.init_notebook_mode()\nfeature_names = ctv.get_feature_names()\ncount_vec = np.asarray(xtrain_ctv.sum(axis=0)).ravel()\nzipped = list(zip(feature_names, count_vec))\nx, y = (list(x) for x in zip(*sorted(zipped, key=lambda x: x[1], reverse=True)))\n\nY = np.concatenate([y[0:15], y[-16:-1]])\nX = np.concatenate([x[0:15], x[-16:-1]])\n\n\ndata = [go.Bar(\n            x = x[0:50],\n            y = y[0:50],\n            marker= dict(colorscale='RdBu',\n                         color = y[0:50]\n                        ),\n            text='Word counts'\n    )]\n\nlayout = go.Layout(\n    title='Top 50 Word frequencies after Preprocessing'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')\nplt.show()\n","4af86de6":"\nclf = LogisticRegression(C=1.0)\nclf.fit(xtrain_ctv, ytrain)\npredictions = clf.predict(xvalid_ctv)\n\nprint ( classification_report(yvalid, predictions,target_names=target))","a7da35b8":"\nclf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\nclf.fit(xtrain_ctv.tocsc(), ytrain)\npredictions = clf.predict(xvalid_ctv.tocsc())\n\nprint ( classification_report(yvalid, predictions,target_names=target))","33604931":"df=df[df['cyberbullying_type']!='other_cyberbullying']\ndf=df[df['cyberbullying_type']!='age']","c3263ada":"new_target=df.cyberbullying_type.unique()","32154152":"lbl_enc = preprocessing.LabelEncoder()\ny = lbl_enc.fit_transform(df.cyberbullying_type.values)\n\nxtrain, xvalid, ytrain, yvalid = train_test_split(df.tweet_text.values, y, \n                                                  stratify=y, \n                                                  random_state=42, \n                                                  test_size=0.1, shuffle=True)\n\nctv = CountVectorizer(analyzer='word',\n            ngram_range=(1, 3), stop_words = 'english')\n\n\nctv.fit(list(xtrain) + list(xvalid))\nxtrain_ctv =  ctv.transform(xtrain) \nxvalid_ctv = ctv.transform(xvalid)\n\nclf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\nclf.fit(xtrain_ctv.tocsc(), ytrain)\npredictions = clf.predict(xvalid_ctv.tocsc())\n\nprint ( classification_report(yvalid, predictions,target_names=new_target))","8e86ff55":"py.init_notebook_mode()\nfeature_names = ctv.get_feature_names()\ncount_vec = np.asarray(xtrain_ctv.sum(axis=0)).ravel()\nzipped = list(zip(feature_names, count_vec))\nx, y = (list(x) for x in zip(*sorted(zipped, key=lambda x: x[1], reverse=True)))\n\nY = np.concatenate([y[0:15], y[-16:-1]])\nX = np.concatenate([x[0:15], x[-16:-1]])\n\n\ndata = [go.Bar(\n            x = x[0:50],\n            y = y[0:50],\n            marker= dict(colorscale='RdBu',\n                         color = y[0:50]\n                        ),\n            text='Word counts'\n    )]\n\nlayout = go.Layout(\n    title='Top 50 Word frequencies after Preprocessing'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')\nplt.show()","e03135fa":"You can read more about LR here https:\/\/programmersought.com\/article\/63567702066\/\n\n\nor here https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html","8f26f05c":"**TRAIN TEST SPLIT**\n","06a87f8f":"# **Libraries**","e451238a":"## Let's visualize the top 50 most frequent words after TFIDF","2814b0f4":"# Count Vectorizer","76d750dc":"**XGB**","56183d20":"Also we have 36 duplicated tweets.Let's delete them","1022dde9":"**Logistic Regression**","2ac27f8a":"You can read more about TF IDF here: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfVectorizer.html","bc26f736":"Hello everyone. This is my first nlp notebook\n\nThis notebook presents such methods of converting text to vector as TF IDF and CountVectorizer, as well as data visualization for a dataframe.\n\n**Neural networks will not be used in this notebook**\n\nTo classify the tweets I used XGBoost and Logistic Regression\n\n\nThe best result showed precision of 0.86\n\nspecial thanks to this notebook https:\/\/www.kaggle.com\/abhishek\/approaching-almost-any-nlp-problem-on-kaggle","0afd63cd":"we have six different classes of cyberbullying","e1d9745a":"## Conclusion","859c488d":"Seeing a bad result for predicting classes 'Age' and 'Other_cyberbullyuing', I  decided to see what the result would be if they were removed","c3a38ae5":"**Logistic Regression**","587b3edb":"**XGB**","df49cdcb":"# Vizualisation","498f65e6":"# Import data","b7b2ded6":"### As a result TF IDF Vectorizer(0.86 0.85 0.85) looks a little better than CountVectorizer(0.86 0.85 0.84) for this dataset","e206ed21":"# Modeling","674a6050":"**Transform target variable**\n\nConverting the format of the target variable from text to numeric","71d48146":"# Without  Age and other cyberbullying tweets","2937eb2e":"## Let's visualize the top 50 most frequent words before processing","55240542":"### The best precision showed XGBoost(0.86)","2be654dc":"<p style='font-family:cursive'>The result improved to 93 percent across all metrics.\nThat's all for now, I'll update my notebook and think about how to increase the result without using neural networks.\n\n<p style='font-family:cursive'>I think something needs to be done with the data of the 'Age' and 'Othercyberbullying' classes.\n    \n<p style='font-family:cursive'>If you have any ideas on this, I will be happy to discuss them with you.<\/p>","a57c440f":"You can read more about XGBoost here https:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/model.html\n\n\nor  here(XGB  tutorial) https:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/index.html","6d1881f1":"## As we can see all six classes have uniform distibution","9592dee8":"You can read about CountVectorizer here: https:\/\/medium.com\/swlh\/understanding-count-vectorizer-5dd71530c1b\n\nor read about hyperparametrs here:https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html","6a145fda":"# TFIDF Vectorizer"}}