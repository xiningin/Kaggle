{"cell_type":{"d11c104f":"code","2ecc49e4":"code","19045845":"code","cf6e0c49":"code","20448d36":"code","8917dbea":"code","f5382c6f":"code","d065b53b":"code","1ac24316":"code","e26044b2":"code","2abb52ab":"code","62eec489":"code","1581f001":"code","ae0b5a21":"code","fb747876":"code","b5577977":"markdown","513acdd0":"markdown","34784394":"markdown","cbe6e9d3":"markdown","6ee28967":"markdown","fb47a51e":"markdown","8b8e22f2":"markdown","2da22975":"markdown"},"source":{"d11c104f":"import pandas as pd\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nimport re\nimport string","2ecc49e4":"dataframes = {\n    \"cooking\": pd.read_csv(\"..\/input\/cooking.csv\"),\n    \"crypto\": pd.read_csv(\"..\/input\/crypto.csv\"),\n    \"robotics\": pd.read_csv(\"..\/input\/robotics.csv\"),\n    \"biology\": pd.read_csv(\"..\/input\/biology.csv\"),\n    \"travel\": pd.read_csv(\"..\/input\/travel.csv\"),\n    \"diy\": pd.read_csv(\"..\/input\/diy.csv\"),\n}","19045845":"print(dataframes[\"robotics\"].iloc[1])","cf6e0c49":"uri_re = r'(?i)\\b((?:https?:\/\/|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}\/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))'\n\ndef stripTagsAndUris(x):\n    if x:\n        # BeautifulSoup on content\n        soup = BeautifulSoup(x, \"html.parser\")\n        # Stripping all <code> tags with their content if any\n        if soup.code:\n            soup.code.decompose()\n        # Get all the text out of the html\n        text =  soup.get_text()\n        # Returning text stripping out all uris\n        return re.sub(uri_re, \"\", text)\n    else:\n        return \"\"","20448d36":"# This could take a while\nfor df in dataframes.values():\n    df[\"content\"] = df[\"content\"].map(stripTagsAndUris)","8917dbea":"print(dataframes[\"robotics\"].iloc[1])","f5382c6f":"def removePunctuation(x):\n    # Lowercasing all words\n    x = x.lower()\n    # Removing non ASCII chars\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    # Removing (replacing with empty spaces actually) all the punctuations\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)","d065b53b":"for df in dataframes.values():\n    df[\"title\"] = df[\"title\"].map(removePunctuation)\n    df[\"content\"] = df[\"content\"].map(removePunctuation)","1ac24316":"print(dataframes[\"robotics\"].iloc[1])","e26044b2":"stops = set(stopwords.words(\"english\"))\ndef removeStopwords(x):\n    # Removing all the stopwords\n    filtered_words = [word for word in x.split() if word not in stops]\n    return \" \".join(filtered_words)","2abb52ab":"for df in dataframes.values():\n    df[\"title\"] = df[\"title\"].map(removeStopwords)\n    df[\"content\"] = df[\"content\"].map(removeStopwords)","62eec489":"print(dataframes[\"robotics\"].iloc[1])","1581f001":"for df in dataframes.values():\n    # From a string sequence of tags to a list of tags\n    df[\"tags\"] = df[\"tags\"].map(lambda x: x.split())","ae0b5a21":"print(dataframes[\"robotics\"].iloc[1])","fb747876":"for name, df in dataframes.items():\n    # Saving to file\n    df.to_csv(name + \"_light.csv\", index=False)","b5577977":"Splitting tags string in a list of tags\n-----------","513acdd0":"Text Preprocessing\n--------\nText preprocessing made on the competition datasets.\nThe preprocessing consists of 4 steps:\n\n 1. **Removing tags and URIs from contents**\n 2. **Removing punctuation from titles and contents**\n 3. **Removing stopwords from titles and contents**\n 4. **Converting the tags from string to a list of tags**\n\nThis type of operations can be used as a first step for any other process regarding the competition.","34784394":"Datasets loading\n---------","cbe6e9d3":"Removing html tags and uris from contents\n-----------","6ee28967":"Removing punctuation from titles and contents\n-----------","fb47a51e":"Saving preprocessed dataframes to csv\n-----------","8b8e22f2":"For simplicity, i'll show an example of the steps of the preprocessing on an item of the robotics dataset","2da22975":"Removing stopwords from titles and contents\n-----------"}}