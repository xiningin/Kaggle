{"cell_type":{"cc0f1c26":"code","f813e5ac":"code","7fcee4a5":"code","d7f84e28":"code","c57ec264":"code","41d512df":"code","1f6db035":"code","aa59ad69":"code","ea5fb98f":"code","8f870a45":"code","1466087e":"code","82b5bd29":"code","40827ac5":"code","9e433267":"markdown","1ae1d7db":"markdown"},"source":{"cc0f1c26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f813e5ac":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt","7fcee4a5":"dataset_path = '\/kaggle\/input\/garbage-classification\/Garbage classification\/Garbage classification\/'\n# os.listdir(dataset_path)","d7f84e28":"img_list = glob.glob(os.path.join(dataset_path,'*\/*.jpg'))","c57ec264":"plt.figure(figsize=(10,10))\nfor i in range(0,4):\n  img = tf.keras.preprocessing.image.load_img(img_list[i+1],target_size=(224,224))\n  img = tf.keras.preprocessing.image.img_to_array(img,dtype=np.uint8)\n  plt.subplot(2,2,i+1)\n  plt.imshow(img)","41d512df":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.2\n)","1f6db035":"train_generator = train_generator.flow_from_directory(\n    dataset_path,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',\n    subset='training',\n    seed=0\n)","aa59ad69":"test_generator = test_generator.flow_from_directory(\n    dataset_path,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',\n    subset='validation',\n    seed=0\n)","ea5fb98f":"model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),include_top=False, weights='imagenet')","8f870a45":"input_layer = model.layers[0].input\ninputs= model.layers[-1].output\nx = tf.keras.layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),activation='relu')(inputs)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(6,activation='softmax')(x)\nmyModel = tf.keras.Model(input_layer,x)","1466087e":"model.trainable=False\n# model.summary() ","82b5bd29":"myModel.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])","40827ac5":"myModel.fit(train_generator,validation_data=test_generator,epochs=10,batch_size=32)","9e433267":"**Image Analysis**","1ae1d7db":"**Imports**"}}