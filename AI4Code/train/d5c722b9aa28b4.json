{"cell_type":{"dec7d6cf":"code","8881e3b7":"code","61faf8bf":"code","51c186dc":"code","3c7ac2b6":"code","deb3ea14":"code","e8880431":"code","77a42c32":"code","390381a2":"code","5e9aee04":"code","f3c9f14e":"code","4b9b07d7":"code","93ed0b74":"markdown","c589ec22":"markdown","042e7ac0":"markdown","ba993f23":"markdown","5bd72e60":"markdown","ad729359":"markdown","0df8c060":"markdown","378f91c1":"markdown","eefbc251":"markdown","e2698dda":"markdown"},"source":{"dec7d6cf":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","8881e3b7":"image_size = (180, 180)\nbatch_size = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/chest-xray-covid19-pneumonia\/Data\/train\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/chest-xray-covid19-pneumonia\/Data\/train\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)","61faf8bf":"train_ds","51c186dc":"class_names = train_ds.class_names\nprint(class_names)","3c7ac2b6":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","deb3ea14":"data_augmentation = keras.Sequential(\n    [\n     layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n     layers.experimental.preprocessing.RandomRotation(0.05),\n     layers.experimental.preprocessing.RandomZoom(0.10)\n    ]\n)","e8880431":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","77a42c32":"train_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","390381a2":"keras.backend.clear_session()\n\ndef make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    x = layers.Conv2D(32, 5, strides=2, padding=\"same\")(x)\n    x = layers.Activation(\"relu\")(x)\n    x = layers.MaxPool2D(3, strides=2, padding=\"same\")(x)\n\n    x = layers.Conv2D(64, 5, padding=\"same\")(x)\n    x = layers.Activation(\"relu\")(x)\n    x = layers.MaxPool2D(3, strides=2, padding=\"same\")(x)\n\n    for size in [128, 256, 512]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2D(size, 5, padding=\"same\")(x)\n        x = layers.MaxPool2D(3, strides=2, padding=\"same\")(x)\n\n    x = layers.Dropout(0.5)(x)\n    x = layers.SeparableConv2D(724, 3, padding=\"same\")(x)\n    x = layers.Activation(\"relu\")(x)\n    x = layers.MaxPool2D(3, strides=2, padding=\"same\")(x)\n\n    x = layers.Flatten()(x)\n    x = layers.Dense(256, activation='relu')(x)\n\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=3)\nkeras.utils.plot_model(model, show_shapes=True)","5e9aee04":"# checkpoint_filepath = '\/content\/content'\n# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n#     filepath=checkpoint_filepath,\n#     save_weights_only=True,\n#     monitor='val_accuracy',\n#     mode='max',\n#     save_best_only=True)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=6,\n    verbose=0,\n    restore_best_weights = True)\n\ndef scheduler(epoch, lr):\n  if epoch < 9:\n    return lr\n  else:\n    return lr * tf.math.exp(-0.008)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)","f3c9f14e":"epochs = 50\n\nmodel.compile(optimizer= keras.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics = [\"accuracy\"])\n\nhistory = model.fit(\n    train_ds, epochs = epochs, \n    callbacks = [early_stop, lr_callback],\n    validation_data = val_ds)","4b9b07d7":"image_path = \"..\/input\/chest-xray-covid19-pneumonia\/Data\/test\/COVID19\/COVID19(460).jpg\"\nimage_path2 = \"..\/input\/chest-xray-covid19-pneumonia\/Data\/test\/NORMAL\/NORMAL(1268).jpg\"\nimage_path3 = \"..\/input\/chest-xray-covid19-pneumonia\/Data\/test\/PNEUMONIA\/PNEUMONIA(3422).jpg\"\nmerged_path = [image_path,image_path2,image_path3]\n\nfor img_path in merged_path:\n    img = keras.preprocessing.image.load_img(\n        img_path, target_size=image_size)\n    img_array = keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0) # Create a batch\n    \n    predictions = model.predict(img_array)\n    score = tf.nn.softmax(predictions[0])\n    \n    print(\n        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n        .format(class_names[np.argmax(score)], 100 * np.max(score)))","93ed0b74":"# **Introduction**\n\n- This workbook attempts to construct a Convlutional Neural Network to classify COVID-19 and Pneumonia using chest x-ray images.","c589ec22":"# **Generate a `Dataset`**","042e7ac0":"# **Visualize the Data**\n- First 9 Images from the dataset","ba993f23":"- The images after random augmentation","5bd72e60":"# **Image Data Augmentation**","ad729359":"# **Define Callbacks**","0df8c060":"# **Train the Model**","378f91c1":"# **Build Model**","eefbc251":"# **Setup**\n\n- Import required packages","e2698dda":"## **Configure the dataset for performance**"}}