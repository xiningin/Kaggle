{"cell_type":{"14af6d89":"code","c28dba53":"code","4a5f9a0f":"code","479354a6":"code","e0f56717":"code","579555aa":"code","6c45e1d0":"code","6ec54557":"code","97f92e4a":"code","df67e7f5":"code","3b4f059e":"code","254afe2b":"code","9ac2eef5":"code","d5ff3546":"code","edefdce4":"code","a2b7d574":"code","d8652161":"code","3fb6c362":"code","558e838a":"code","9eddb714":"code","80b13453":"code","2dfb6038":"code","4984a1be":"code","ab05721d":"code","b6138c0d":"code","96ad207b":"code","a2c9b8ab":"code","3a3c78a0":"code","7acc58d0":"code","4eebdbf6":"code","4e8c42b8":"code","d6e58e3a":"code","fd05675b":"code","9e6dea8b":"markdown","b909069f":"markdown","c180bf43":"markdown","7283cd5c":"markdown","c4aec563":"markdown","ffe4bd4a":"markdown","136d8a1f":"markdown","18c92968":"markdown"},"source":{"14af6d89":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","c28dba53":"!wget https:\/\/warwick.ac.uk\/fac\/cross_fac\/tia\/data\/hovernet\/consep.zip","4a5f9a0f":"import os\nimport zipfile\n\nlocal_zip = '.\/consep.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('.\/consep')","479354a6":"train_dir = '.\/consep\/CoNSeP\/Train'\ntest_dir = '.\/consep\/CoNSeP\/Test'\n\ntrain_images = sorted(os.listdir(train_dir + '\/Images'))\ntest_images = sorted(os.listdir(test_dir + '\/Images'))\ntrain_ground_truth = sorted(os.listdir(train_dir + '\/Labels'))\ntest_ground_truth = sorted(os.listdir(test_dir + '\/Labels'))\n\nprint(train_images[:5])\nprint(train_ground_truth[:5])\nprint('length of trian set: %s'%len(train_images))\nprint('length of test set: %s'%len(test_images))","e0f56717":"# scipy.io libarary to load MatLab files\nimport scipy.io as scpio\nfrom scipy.ndimage import median_filter\n\nplt.figure(figsize=(25,15))\nfor i in range(5):\n    plt.subplot(3,5,i+1)\n    img = plt.imread(os.path.join(train_dir+'\/Images\/',train_images[i]))\n    plt.title(img.shape)\n    plt.imshow(img)\n\n    plt.subplot(3,5,i+6)\n    img = median_filter(img,size = 3)\n    plt.title(img.shape)\n    plt.imshow(img)\n\n    # type_map of the image\n    plt.subplot(3,5,i+11)\n    img_type_map = scpio.loadmat(os.path.join(train_dir+'\/Labels\/',train_ground_truth[i]))['type_map']\n    plt.title(img_type_map.shape)\n    plt.imshow(img_type_map)","579555aa":"# random cropping patches from images with arbitrary size\ndef random_crop(img, target_shape=(256,256),seed=None):\n    n_rows = img.shape[0]\n    n_cols = img.shape[1]\n\n    row_size, col_size = target_shape\n\n    start_row = np.random.RandomState(seed).choice(range(n_rows-row_size))\n    start_col = np.random.RandomState(seed).choice(range(n_cols-col_size))\n\n    return img[start_row:start_row+row_size,start_col:start_col+col_size]","6c45e1d0":"# making images into superpixels (patches)\ndef make_pathces(img, target_shape=(256,256),num_channels=3):\n    n_rows = np.ceil(img.shape[0]\/target_shape[0]).astype('int')\n    n_cols = np.ceil(img.shape[1]\/target_shape[1]).astype('int')\n\n    if img.shape[0]%target_shape[0] != 0:\n        img = np.concatenate((img[:,:],np.flipud(img[(img.shape[0]-(n_rows*target_shape[0])):,:])),axis=0)\n\n    if img.shape[1]%target_shape[1] != 0:\n        img = np.concatenate((img[:,:],np.fliplr(img[:,(img.shape[1]-(n_cols*target_shape[1])):])),axis=1)\n    num_patches = n_cols * n_rows\n\n    if len(img.shape) == 2:\n        patches = np.empty(shape=(n_rows,n_cols,target_shape[0],target_shape[1]))\n    else:\n        patches = np.empty(shape=(n_rows,n_cols,target_shape[0],target_shape[1], num_channels))\n\n    for i in range(0, img.shape[0], target_shape[0]):\n        for j in range(0, img.shape[1], target_shape[1]):\n            patches[i\/\/target_shape[0],j\/\/target_shape[1]] = np.copy(img[i:i+target_shape[0],j:j+target_shape[1]])\n\n    return patches","6ec54557":"img = plt.imread(os.path.join(train_dir+'\/Images\/', train_images[1]))\npatches_test = make_pathces(img)\nprint('shape of the patches of one image: ',patches_test.shape)\n\nplt.figure(figsize=(10,10))\nplt.imshow(img)\nplt.axis('off')\n\nfig, ax= plt.subplots(4, 4)\nfig.set_size_inches(10,10)\nfor i in range(16):\n    ax[i\/\/4][i%4].imshow(patches_test[i\/\/4][i%4])\n    ax[i\/\/4][i%4].axis('off')","97f92e4a":"y_test = scpio.loadmat(os.path.join(train_dir+'\/Labels\/',train_ground_truth[1]))['type_map']\ny_patches_test = make_pathces(y_test)\nprint('shape of the patches of one image: ',y_patches_test.shape)\n\nplt.figure(figsize=(10,10))\nplt.imshow(y_test)\nplt.axis('off')\n\nfig, ax= plt.subplots(4, 4)\nfig.set_size_inches(10,10)\nfor i in range(16):\n    ax[i\/\/4][i%4].imshow(y_patches_test[i\/\/4][i%4])\n    ax[i\/\/4][i%4].axis('off')","df67e7f5":"from tqdm import tqdm\n\nIMG_HEIGHT = 256\nIMG_WIDTH = 256\nnum_patches = 16\nnum_random_cropped_patches = 1\nnum_augmentations = 3\ntotal_num_of_patches = (num_patches + num_random_cropped_patches)*num_augmentations\nn = round(np.sqrt(num_patches))\n   \n# creating the new dataset\nX_train = np.zeros((len(train_images)*total_num_of_patches,IMG_HEIGHT,IMG_WIDTH,3))\nX_test = np.zeros((len(test_images)*num_patches,IMG_HEIGHT,IMG_WIDTH,3))\ny_train = np.zeros((len(train_images)*total_num_of_patches,IMG_HEIGHT,IMG_WIDTH))\ny_test = np.zeros((len(test_images)*num_patches,IMG_HEIGHT,IMG_WIDTH))\n\nindex = 0\n# train set    \nfor inx, img_dir in tqdm(enumerate(train_images)):\n    # importing images\n    full_img_dir = os.path.join(train_dir+'\/Images\/', img_dir)\n    img = plt.imread(full_img_dir)\n\n    # importing masks\n    img_type_map = scpio.loadmat(os.path.join(train_dir+'\/Labels\/',train_ground_truth[inx]))['type_map']\n    img_type_map_patches = make_pathces(img_type_map,target_shape=(IMG_HEIGHT,IMG_WIDTH))\n    \n    # omitting the forth channels of the images\n    if img.shape[2] == 4:\n        img = img[:,:,:3]\n    else:\n        img = img\n    \n    # making the image into 16 equal patches\n    img_patches = make_pathces(img,target_shape=(IMG_HEIGHT,IMG_WIDTH))\n    #add the patches to the dataset\n    for i in range(n):\n        for j in range(n):\n            pos = np.random.choice([1,2,3])# for random rotation choosen from the list (90, 180, 270)\n            X_train[index] = img_patches[i][j]\n            X_train[index+1] = np.rot90(X_train[index], pos)# rotating image and add it to dataset\n            X_train[index+2] = np.fliplr(X_train[index])# flipping the image and add it to dataset\n\n            y_train[index] = img_type_map_patches[i][j]\n            y_train[index+1] = np.rot90(y_train[index], pos)\n            y_train[index+2] = np.fliplr(y_train[index])\n            index += 3\n    #random cropping the image 'num_random_cropped_patches' times\n    for i in range(num_random_cropped_patches):\n        seed = np.random.randint(10000)\n        pos = np.random.choice([1,2,3])\n        X_train[index] = random_crop(img, target_shape=(IMG_HEIGHT,IMG_WIDTH), seed=seed)\n        X_train[index+1] = np.rot90(X_train[index], pos)\n        X_train[index+2] = np.fliplr(X_train[index])\n\n        y_train[index] = random_crop(img_type_map, target_shape=(IMG_HEIGHT,IMG_WIDTH), seed=seed)\n        y_train[index+1] = np.rot90(y_train[index], pos)\n        y_train[index+2] = np.fliplr(y_train[index])\n        index += 3\n\ntest_index = 0\n# test set        \nfor inx, img_dir in tqdm(enumerate(test_images)):\n    # importing images\n    full_img_dir = os.path.join(test_dir+'\/Images\/', img_dir)\n    img = plt.imread(full_img_dir)\n    \n    # importing masks\n    img_type_map = scpio.loadmat(os.path.join(test_dir+'\/Labels\/',test_ground_truth[inx]))['type_map']\n    img_type_map_patches = make_pathces(img_type_map,target_shape=(IMG_HEIGHT,IMG_WIDTH))\n    \n    # omitting the forth channels of the images\n    if img.shape[2] == 4:\n        img = img[:,:,:3]\n    else:\n        img = img\n    \n    # making the image into 16 equal patches\n    img_patches = make_pathces(img,target_shape=(IMG_HEIGHT,IMG_WIDTH))\n    #add the patches to the dataset\n    for i in range(n):\n        for j in range(n):\n            X_test[test_index] = img_patches[i][j]\n\n            y_test[test_index] = img_type_map_patches[i][j]\n            test_index +=1\n\n","3b4f059e":"from tensorflow.keras.utils import to_categorical\n\n# combinning the 3,4,5 classes with each ohter and 6,7 classes likewise\ny_train[np.where(y_train == 4)] = 3\ny_train[np.where((y_train == 5)|(y_train == 6)|(y_train == 7))] = 4\n\ny_test[np.where(y_test == 4)] = 3\ny_test[np.where((y_test == 5)|(y_test == 6)|(y_test == 7))] = 4\n\nnum_classes = 5 # classes + background\ny_train_cat = to_categorical(y_train, num_classes = num_classes)\ny_test_cat = to_categorical(y_test, num_classes = num_classes)","254afe2b":"print('X_train:%s y_train:%s'%(X_train.shape, y_train.shape))\nprint('X_test:%s y_test:%s'%(X_test.shape, y_test.shape))","9ac2eef5":"y_elements_counting = []\nfor i in range(5):\n    y_elements_counting.append(np.count_nonzero(y_train==i))\npd.DataFrame(y_elements_counting)\n\n# claculating class weights\nclass_weights = {\n    0: round(sum(y_elements_counting)\/y_elements_counting[0],3),\n    1: round(sum(y_elements_counting)\/y_elements_counting[1],3),\n    2: round(sum(y_elements_counting)\/y_elements_counting[2],3),\n    3: round(sum(y_elements_counting)\/y_elements_counting[3],3),\n    4: round(sum(y_elements_counting)\/y_elements_counting[4],3),\n}\nprint(class_weights)\n# sample weights\nsample_weights = np.ones((X_train.shape[0],256,256,5))\nsample_weights[:,:,:,0] = class_weights[0]\nsample_weights[:,:,:,1] = class_weights[1]\nsample_weights[:,:,:,2] = class_weights[2]\nsample_weights[:,:,:,3] = class_weights[3]\nsample_weights[:,:,:,4] = class_weights[4]","d5ff3546":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nbatch_size = 32\ndata_gen = ImageDataGenerator(rescale = 1\/255.,)\ntrain_gen = data_gen.flow(X_train, y_train_cat, batch_size = batch_size,shuffle = True, seed=100)\n\ntest_datagen = ImageDataGenerator(rescale = 1\/255.)\ntest_gen = test_datagen.flow(X_test, y_test_cat, batch_size = batch_size,shuffle = False, seed=100)","edefdce4":"!pip install -U segmentation-models","a2b7d574":"%env SM_FRAMEWORK=tf.keras","d8652161":"import segmentation_models as sm\nimport tensorflow as tf\nsm.set_framework('tf.keras')\nsm.framework()\nmodel = sm.Unet('inceptionv3',\n                classes=5, \n                input_shape = (256,256,3), \n                activation='softmax', \n                encoder_freeze=False,\n                )","3fb6c362":"model.summary()","558e838a":"len(model.layers)","9eddb714":"from segmentation_models import metrics\nmodel.compile(optimizer = tf.keras.optimizers.Adam(0.00005,decay=1e-6),\n              loss=sm.losses.DiceLoss(),\n              metrics = [sm.metrics.f1_score,\n                         sm.metrics.iou_score,\n                         ],\n              loss_weights = list(class_weights.values())\n)","80b13453":"batch_size = batch_size\nepochs = 50\nmodel_history = model.fit(train_gen,\n                          steps_per_epoch = X_train.shape[0]\/\/batch_size,\n                          epochs = epochs,\n                          verbose = True,\n                          validation_data = test_gen\n                          )","2dfb6038":"pd.DataFrame(model_history.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.gca().set_ylim(0,2.5)\nplt.show()","4984a1be":"test_gen.reset()\nmodel.evaluate(test_gen)","ab05721d":"y_pred = model.predict(test_gen)\ny_pred.shape","b6138c0d":"print(y_pred.min(), y_pred.max())","96ad207b":"inx = 20\nplt.imshow(test_gen.x[inx])","a2c9b8ab":"print(np.unique(np.argmax(test_gen.y[inx],axis=2)))\nplt.figure(figsize=(25,5))\nfor i in range(6):\n  plt.subplot(1,6,i+1)\n  if i>0:\n    plt.imshow(test_gen.y[inx,:,:,i-1])\n  else:\n    plt.imshow(np.argmax(test_gen.y[inx],axis=2))","3a3c78a0":"print(np.unique(np.argmax(y_pred[inx],axis=2)))\nplt.figure(figsize=(25,5))\nfor i in range(6):\n  plt.subplot(1,6,i+1)\n  if i>0:\n    plt.imshow(y_pred[inx,:,:,i-1])\n  else:\n    plt.imshow(np.argmax(y_pred[inx],axis=2))","7acc58d0":"from sklearn.metrics import ConfusionMatrixDisplay ","4eebdbf6":"# Confusion Matrix\ndef confusion_matrix(y_true, y_pred, num_classes=None):\n    y_true = y_true.reshape(-1)\n    y_pred = y_pred.reshape(-1) \n    if (num_classes is None):\n        num_classes = max(max(y_true), max(y_pred)) + 1\n    cm = num_classes * y_true + y_pred\n    cm = np.bincount(cm, minlength=num_classes*num_classes)\n    cm = cm.reshape(num_classes, num_classes)\n    return cm","4e8c42b8":"cm = confusion_matrix(np.argmax(test_gen.y,axis=3),np.argmax(y_pred,axis=3))","d6e58e3a":"cm_display = ConfusionMatrixDisplay(cm)\nfig, ax = plt.subplots(figsize=(10,10))\ncm_display.plot(ax=ax)","fd05675b":"pixel_accuracy = np.sum(np.diag(cm))\/np.sum(cm)\npixel_accuracy","9e6dea8b":"### Pixel Accuracy","b909069f":"## __Importing Dataset__","c180bf43":"### Confusion Matrix","7283cd5c":"## __Model Evaluation__","c4aec563":"Identifying the cells\u2019 nuclei is the starting point for most analyses because most of the human body\u2019s 30 trillion cells contain a nucleus full of DNA, the genetic code that programs each cell. Identifying nuclei allows researchers to identify each individual cell in a sample, and by measuring how cells react to various treatments, the researcher can understand the underlying biological processes at work.","ffe4bd4a":"Class values: \n1. other\n2. inflammatory\n3. healthy epithelial\n4. dysplastic\/malignant epithelial\n5. fibroblast\n6. muscle\n7. endothelial","136d8a1f":"## __Model Creation__","18c92968":"## __Data Preprocessing and Augmentation__"}}