{"cell_type":{"b7e63c99":"code","83c14689":"code","b0e18a90":"code","a3fea350":"code","a96bff90":"code","d0243d9a":"code","fcc66e6c":"code","4ed02855":"code","8f5c7601":"code","ef1ae78d":"code","816e1497":"code","ec7fe742":"code","ebf1b39b":"code","7cfd9669":"code","d29dce24":"markdown","73bbdc0d":"markdown","6b0668d6":"markdown","387443af":"markdown","ed62e3c5":"markdown"},"source":{"b7e63c99":"import numpy as np # linear algebra\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport os\nimport shutil\nimport multiprocessing as mp\n\nimport cv2\nimport numpy as np\nimport sklearn.metrics as metrics\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.models import load_model\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.utils import to_categorical\nfrom sklearn.utils import class_weight\nfrom keras import layers\nfrom keras.layers import Dense, Dropout, Activation, GlobalAveragePooling2D, MaxPooling2D, Conv2D, Input\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.models import Model\n\nfrom keras.optimizers import SGD\n\n\n\nfrom keras.applications.imagenet_utils import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import ResNet50\n\n%matplotlib inline\n\ntrain_dir = '\/kaggle\/input\/food11\/training'\nvalidation_dir = '\/kaggle\/input\/food11\/validation'\n\ntrain_files = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\nvalidation_files = [f for f in os.listdir(validation_dir) if os.path.isfile(os.path.join(validation_dir, f))]","83c14689":"from scipy import ndimage\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\n# label extraction\ntrain = []\ny_train = []\nvalid = []\ny_valid = []\n\nfor file in train_files:\n    train.append(file)\n    label= file.find(\"_\")\n    y_train.append(int(file[0:label]))\nfor file in validation_files:\n    valid.append(file)\n    label= file.find(\"_\")\n    y_valid.append(int(file[0:label]))","b0e18a90":"cnnInput = np.ndarray(shape=(len(train), 190,190, 3), dtype=np.float32)\nprint('[INFO] Loading training images')\ni=0\nfor file in train:\n    image = cv2.imread(train_dir + \"\/\" + file)  \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # do not normalize for this model, keep 0-255\n    image = image.astype(\"float\")\n    image = cv2.resize(image, dsize=(190, 190), interpolation=cv2.INTER_CUBIC)\n    # no normalization for this model, keep 0-255\n    x = img_to_array(image)\n    x = x.reshape((1, x.shape[0], x.shape[1],\n                                   x.shape[2]))\n\n    cnnInput[i]=x\n    i+=1\nprint('[INFO] Done')","a3fea350":"cnnValidation = np.ndarray(shape=(len(valid), 190,190, 3), dtype=np.float32)\nprint('[INFO] Loading validation images')\ni=0\nfor file in valid:\n    image = cv2.imread(validation_dir + \"\/\" + file)  \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # do not normalize for this model, keep 0-255\n    image = image.astype(\"float\")\n    image = cv2.resize(image, dsize=(190, 190), interpolation=cv2.INTER_CUBIC)\n    # no normalization for this model, keep 0-255\n    x = img_to_array(image)\n    x = x.reshape((1, x.shape[0], x.shape[1],\n                                   x.shape[2]))\n\n    cnnValidation[i]=x\n    i+=1\nprint('[INFO] Done')","a96bff90":"y_train_2 = to_categorical(y_train)\ny_valid_2 = to_categorical(y_valid)","d0243d9a":"vgg_model = VGG19(weights='imagenet', include_top=False)","fcc66e6c":"# make explained variable hot-encoded\ny_train_hot_encoded = to_categorical(y_train)\ny_test_hot_encoded = to_categorical(y_valid)","4ed02855":"class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)","8f5c7601":"# get layers and add average pooling layer\nx = vgg_model.output\nx = GlobalAveragePooling2D()(x)\n\n# add fully-connected layer\nx = Dense(2048, activation='relu')(x)\nx = Dropout(0.3)(x)\n\n# add output layer\npredictions = Dense(11, activation='softmax')(x)\n\nmodel = Model(inputs=vgg_model.input, outputs=predictions)\n\n# freeze pre-trained model area's layer\n#for layer in vgg_model.layers:\n#    layer.trainable = False\n\n# update the weight that are added\n#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n#model.fit(cnnInput, y_train_hot_encoded)\n\n# choose the layers which are updated by training\n#layer_num = len(model.layers)\n#for layer in model.layers[:21]:\n#    layer.trainable = False\n\n#for layer in model.layers[21:]:\n#    layer.trainable = True\n\n# training\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory= model.fit(cnnInput,y_train_hot_encoded, batch_size=64, shuffle=True,\n                    validation_data=(cnnValidation, y_test_hot_encoded),\n                  class_weight=class_weights, epochs=100)\n#history = model.fit(cnnInput, y_train_hot_encoded, batch_size=256, epochs=50, shuffle=True,  validation_split=0.1)","ef1ae78d":"# training\n#history = model.fit(cnnInput, y_train_hot_encoded, batch_size=256, epochs=50, shuffle=True,  validation_split=0.1)","816e1497":"model.summary()","ec7fe742":"# Data augmentation\nfrom keras.preprocessing.image import ImageDataGenerator\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=[.6, 1],\n    vertical_flip=True,\n    horizontal_flip=True)\ntrain_generator = train_datagen.flow(cnnInput, y_train, batch_size=64, seed=11)\nvalid_datagen = ImageDataGenerator()\nvalid_generator = valid_datagen.flow(cnnValidation, y_valid, batch_size=64, seed=11)","ebf1b39b":"train_datagen.fit(cnnInput)\nvalid_datagen.fit(cnnValidation)","7cfd9669":"model.fit_generator(train_datagen.flow(cnnInput, y_train_hot_encoded, batch_size=64), shuffle=True,\n                    validation_data=valid_datagen.flow(cnnValidation, y_test_hot_encoded, batch_size=64),\n                  class_weight=class_weights, epochs=20)","d29dce24":"* We create containers where we store the arrays of the images in the shape (190,190,3)for both training and validation data.\n* We loaded images with PIL library.\n* We chose 190 because of lack of RAM and kernel crashing","73bbdc0d":"We used one hot encoding instead of number of the class for labels. To get an ouput of probabilities for belonging to each class.","6b0668d6":"Here we are going to extract the labels and the names of the file names from training and validation set.","387443af":"In this part, we did data augmentation. Data augmentation is a way of creating new data with modifications:\n\n* different orientations (horizontal_flip and vertical_flip)\n* With shift (randomly shift images horizontally or randomly shift images vertically)\n* Zoom We used this image generator for training and validation, but for validation image generator, we use the original images from validation dataset.","ed62e3c5":"We start by loading the libraries and the Data :\nWe are going to use CNN VGG19, which explain the use of the library keras.  "}}