{"cell_type":{"a991ab84":"code","057495e5":"code","41a51440":"code","a4a42359":"code","04ef2b8d":"code","9f8e28fc":"code","50c46f7d":"code","98ae45a8":"code","9b617695":"code","37ca77a8":"code","e9cdd31a":"code","8160135a":"code","4933ad4c":"code","872bd03c":"code","ca7b003d":"code","cd693f99":"markdown","f801a198":"markdown","9787ef9f":"markdown","1fcd4363":"markdown","47ea6818":"markdown","15657de9":"markdown","693332b4":"markdown","b51b9b7c":"markdown","8972db06":"markdown","782b2c2d":"markdown"},"source":{"a991ab84":"# Importing the libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","057495e5":"dataset = pd.read_csv('..\/input\/data.csv')\nprint(dataset.columns)\nprint(dataset.shape)\ndataset.head(3)","41a51440":"dataset.drop(['Unnamed: 32','id'],axis=1,inplace=True)","a4a42359":"dataset.describe()","04ef2b8d":"dataset['diagnosis'].value_counts()","9f8e28fc":"sns.FacetGrid(dataset,hue='diagnosis',size=6).map(plt.scatter, \"area_mean\", \"smoothness_mean\") \\\n   .add_legend();","50c46f7d":"sns.FacetGrid(dataset,hue='diagnosis',size=6).map(plt.scatter, \"radius_worst\", \"compactness_mean\") \\\n   .add_legend();","98ae45a8":"sns.FacetGrid(dataset,hue='diagnosis',size=6).map(plt.scatter, \"fractal_dimension_mean\", \"compactness_mean\") \\\n   .add_legend();","9b617695":"# Importing libraries for evaluation\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","37ca77a8":"from sklearn.model_selection import train_test_split\nX=dataset.drop('diagnosis',axis=1,inplace=False)\ny=dataset['diagnosis']\nprint(X.head(2))\nprint(y.head(2))\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=455)","e9cdd31a":"from sklearn.linear_model import LogisticRegression\nlm=LogisticRegression()\nlm.fit(X_train,y_train)\ny_pred=lm.predict(X_test)\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n# Accuracy score\nfrom sklearn.metrics import accuracy_score\nprint('accuracy is',accuracy_score(y_pred,y_test))\n","8160135a":"from sklearn.neighbors import KNeighborsClassifier\n#Using cross validation for KNN\nX_t,X_test,y_t,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\nX_train,X_cv,y_train,y_cv=train_test_split(X_t,y_t,test_size=0.3,random_state=42)","4933ad4c":"error_rate=[]\n\nfor i in range(1,100):\n    KNN=KNeighborsClassifier(n_neighbors=i)\n    KNN.fit(X_train,y_train)\n    pred_i=KNN.predict(X_cv)\n    error_rate.append(np.mean(pred_i != y_cv))","872bd03c":"plt.figure(figsize=(20,12))\nplt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)","ca7b003d":"model=KNeighborsClassifier(n_neighbors=5)\nmodel.fit(X_train,y_train)\ny_pred=model.predict(X_test)\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n# Accuracy score\nfrom sklearn.metrics import accuracy_score\nprint('accuracy is',accuracy_score(y_pred,y_test))","cd693f99":"##  Logistic Regression","f801a198":"Choosing the N with lowest error rate i.e 5 or 7","9787ef9f":"## KNN","1fcd4363":"# Discription of the data","47ea6818":"# Applying the ML Algorithms","15657de9":"# Importing the data","693332b4":"## Splitting the data into test and train","b51b9b7c":"the columns id and Unnamed: 32 are droped ","8972db06":"# Data Visualization","782b2c2d":"malignant(Blue points) has more area mean than benign(Orange points)"}}