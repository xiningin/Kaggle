{"cell_type":{"a7cafabd":"code","2fbdba3a":"code","ae0bcefe":"code","8a5fd118":"code","49da4f03":"code","a7e3b8bc":"code","e4232c01":"code","835c10ea":"code","049d1a2b":"code","2ac988c1":"code","d53d48a2":"code","893e3289":"code","dcc06f26":"markdown","7f2c8264":"markdown","f07be786":"markdown","bc011a5d":"markdown","0ea8aa69":"markdown","e9d0a38c":"markdown","098a0090":"markdown","9697f21d":"markdown","5f0cb959":"markdown","5195ff16":"markdown","778bc695":"markdown","8125caa8":"markdown","9cae7253":"markdown","f0b4d4c9":"markdown"},"source":{"a7cafabd":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib as mpl\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ntrain = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv' )\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsubmission = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\n\n\n\nprint(\"shops \\n \")\nprint(shops)\n\nprint(\" \\n \\n \\nitems \\n \")\nprint(items)\n\nprint(\" \\n \\n \\n item_cats \\n \")\nprint(item_cats)\n\nprint(\" \\n \\n \\n submission \\n \")\nprint(submission)\n\nprint(\" \\n \\n \\n train \\n \")\nprint(train)\n\nprint(\" \\n \\n \\n test \\n \" )\nprint(test)\n","2fbdba3a":"traindata = pd.merge(train[['date','shop_id','item_id']], items, how='outer', on='item_id')\ntraindata=traindata.drop_duplicates(subset=['item_category_id', 'shop_id'], keep='first').sort_values(by=['item_category_id'])\ntraindata = traindata[['shop_id','item_category_id']].dropna()\n\n\n\ntestdata = pd.merge(test, items, how='inner', on='item_id')\ntestdata=testdata.drop_duplicates(subset=['item_category_id', 'shop_id'], keep='first').sort_values(by=['item_category_id'])\n\ntestdata = testdata[['shop_id','item_category_id']].dropna()\n\n\n\n\nprint(traindata.head(100))\n\nprint(testdata)\n","ae0bcefe":"from sklearn import svm\n\n\ntrainx = traindata.iloc[:, :1]\ntrainy=traindata.iloc[:, 1:2]\n\ntestx=testdata.iloc[:, :1]\ntesty=testdata.iloc[:, 1:2]\n\nclf = svm.SVC()\nclf.fit(trainx, trainy)\npred=clf.predict(testx)\n\n#print(testy.transpose())\n#print(pred)\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n\nprint(\" \\n\\n accuracy score\")\nprint(accuracy_score(testy, pred))\nprint(\" \\n\\n f1 score\")\n\nf1_score(testy, pred, average =None)","8a5fd118":"\nmydateparser = lambda x: pd.datetime.strptime(x, \"%d.%m.%Y\")\n\ntrain = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv',parse_dates=['date'], date_parser=mydateparser )\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsubmission = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\n\ntrain=train.set_index('date')\nprint(train)\n\n\nmontly  =train.resample('1M').mean()\n\nmontly","49da4f03":"train = train[train.item_id<50]\ntest = test[test.item_id<50]\n\n\n\ntrainx = train[['item_id','shop_id']].iloc[:, :1]\ntrainy=train[['item_id','shop_id']].iloc[:, 1:2]\n\ntestx=test[['item_id','shop_id']].iloc[:, :1]\ntesty=test[['item_id','shop_id']].iloc[:, 1:2]\n\nclf = svm.SVC()\nclf.fit(trainx, trainy)\npred=clf.predict(testx)\n\n#print(testy.transpose())\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n\nprint(\" \\n\\n accuracy score\")\nprint(accuracy_score(testy, pred))","a7e3b8bc":"mydateparser = lambda x: pd.datetime.strptime(x, \"%d.%m.%Y\")\n\ntrain = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv',parse_dates=['date'], date_parser=mydateparser )\n\ntrain=train.set_index('date')\nprint(train)\n","e4232c01":"df=train[train.shop_id==0]\nsns.catplot(x=\"item_id\",y=\"item_price\",data=df)","835c10ea":"df2=train.groupby(['shop_id']).mean()\ndf2['Y\u00fcksekKar']=df2.item_price > 1000\n\ndf2\n\n","049d1a2b":"from sklearn import svm\n\n\ntrainx = df2[['item_cnt_day','Y\u00fcksekKar']].iloc[:49, :1]\ntrainy = df2[['item_cnt_day','Y\u00fcksekKar']].iloc[:49, 1:2]\n\n\n\ntestx = df2[['item_cnt_day','Y\u00fcksekKar']].iloc[49:, :1]\ntesty = df2[['item_cnt_day','Y\u00fcksekKar']].iloc[49:, 1:2]\n\n\n\nclf = svm.SVC()\nclf.fit(trainx, trainy)\npred=clf.predict(testx)\n\n#print(testy.transpose())\n#print(pred)\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n\nprint(\" \\n\\n accuracy score\")\nprint(accuracy_score(testy, pred))","2ac988c1":"\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\n\nX = df2[['item_cnt_day','Y\u00fcksekKar']].iloc[:, :1]\ny = df2[['item_cnt_day','Y\u00fcksekKar']].iloc[:, 1:2]\n\nmodel = Sequential()\nmodel.add(Dense(3, input_dim=1, activation='relu'))\nmodel.add(Dense(2, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n\nmodel.fit(X, y, epochs=100, batch_size=10)\n\n_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","d53d48a2":"df2[['item_cnt_day','Y\u00fcksekKar']].plot()","893e3289":"mydateparser = lambda x: pd.datetime.strptime(x, \"%d.%m.%Y\")\n\ntrain = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv',parse_dates=['date'], date_parser=mydateparser )   #train tablosu date kolonu tarih format\u0131nda olacak \u015fekilde okunur\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\n\ntrain=train.set_index('date')  #date kolonu tarih format\u0131nda okunduktan sonra index yap\u0131l\u0131r\n\ntrain= train[train.item_cnt_day>0]  # yanl\u0131\u015f girilen g\u00fcr\u00fclt\u00fcl\u00fc item bilgileri temizlenir\n\n#traindata = pd.merge(train , items, how='left', on='item_id')    #bu kod ile items tablosu ile train tablosu join yap\u0131l\u0131r  on k\u0131sm\u0131nda belirtilen parametre \u00fczerinden bu ger\u00e7ekle\u015ftirilir. \n#Bu i\u015flem ek g\u00fcr\u00fclt\u00fc olu\u015fturdu\u011fundan performans\u0131 d\u00fc\u015f\u00fcr\u00fcyor o y\u00fczden kullan\u0131lmay\u0131p yorum sat\u0131r\u0131na al\u0131nm\u0131\u015ft\u0131r.\n\n#traindata=traindata.drop_duplicates(subset=['item_category_id', 'shop_id'], keep='first') # tekrar eden veri varsa silinir.\n#traindata = traindata[['shop_id','item_category_id']].dropna()\n\n\n\n\n\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\n\nX = train.iloc[:, :4]    # tablonun ilk 4 kolonu arad\u0131\u011f\u0131m\u0131z sonucun bulunmas\u0131 i\u00e7in verilecek datalar olarak ayarlan\u0131r.\ny = train.iloc[:, 4:5]  # tablonun 5. kolonu tahmin edilmesi istenen k\u0131s\u0131md\u0131r. Yani item say\u0131s\u0131\n\nmodel = Sequential()\nmodel.add(Dense(4, input_dim=4, activation='relu'))   #4 input alan o 4 inputtan 4 d\u00fc\u011f\u00fcml\u00fc gizli katmana ge\u00e7en ilk gizli katman olu\u015fturulur.\nmodel.add(Dense(8, activation='relu'))                #1. gizli katmandan veri alan  8 d\u00fc\u011f\u00fcmden olu\u015fan 2. gizli katman eklenir.\nmodel.add(Dense(1, activation='sigmoid'))             # Gizli katmanlardan 1 d\u00fc\u011f\u00fcml\u00fc \u00e7\u0131k\u0131\u015f katman\u0131na gelindi\u011fi k\u0131s\u0131m eklenir. \n\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   #model i\u00e7in kullan\u0131lacak algoritma ve sonu\u00e7ta \u00e7\u0131kar\u0131lacak do\u011fruluk metri\u011fi belirlenir.\n\n\nmodel.fit(X, y, epochs=2, batch_size=100)     #modelin ka\u00e7 kez e\u011fitilece\u011fi ka\u00e7 epoch dan olu\u015faca\u011f\u0131 ve verilerin ka\u00e7ar ka\u00e7ar verilece\u011fi belirlenir.\n\n_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))     # do\u011fruluk de\u011feri bast\u0131r\u0131l\u0131r.\n\n\n\n","dcc06f26":"# Projenin amac\u0131 kapsam\u0131nda her d\u00fckkan ve her \u00fcr\u00fcn i\u00e7in adet hesaplanmas\u0131 yap\u0131lmak istendi\u011finde train tablosuna join ile yeni veriler eklenir.Ve tablodaki baz\u0131 g\u00fcr\u00fclt\u00fcler temizlenir \u00d6rne\u011fin sat\u0131lan \u00fcr\u00fcn say\u0131s\u0131nda -1 gibi negatif say\u0131lar tabloda olabiliyor. Bu tarz verilerin temizlenmesi.","7f2c8264":"# Yukar\u0131da bahsetti\u011fimiz s\u0131n\u0131flama i\u015fleminin ger\u00e7ekle\u015ftirildi\u011fi b\u00f6l\u00fcm buras\u0131d\u0131r. SVM destek vekt\u00f6r makineleri ile s\u0131n\u0131fland\u0131rma yap\u0131yoruz ve 0,016 gibi \u00e7ok k\u00f6t\u00fc bir sonu\u00e7 elde ediyoruz. Daha sonraki \u00f6rnekte \u00e7ok daha y\u00fcksek de\u011ferlerle daha tahmin edilebilir ve s\u0131n\u0131fland\u0131r\u0131labilir veriler \u00fczerinden \u00e7al\u0131\u015faca\u011f\u0131z.","f07be786":"# S\u0131n\u0131fland\u0131rma yaparken girdi olarak kulland\u0131\u011f\u0131m\u0131z bir d\u00fckkandaki ortalama \u00fcr\u00fcn say\u0131s\u0131n\u0131n \u015firketlere g\u00f6re da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6r\u00fcyoruz buradan d\u00fckkanlardaki sat\u0131lan \u00fcr\u00fcn say\u0131s\u0131n\u0131n genelde 1 ile 1.5 aras\u0131na topland\u0131\u011f\u0131n\u0131 g\u00f6rmekteyiz.","bc011a5d":"# \u015eimdi ise ayn\u0131 i\u015flemi KERAS \u00fczerinden Neural Network  yapay sinir a\u011flar\u0131 ile modelleyelim. 1 giri\u015f 1 \u00e7\u0131k\u0131\u015f ve 2 adet gizli katman\u0131 bulunan bir model tan\u0131ml\u0131yoruz. Yukar\u0131da verdi\u011fimiz verinin ayn\u0131s\u0131n\u0131 veri olarak veriyoruz. 3 vs 2 node olan 2 adet gizli katman\u0131m\u0131z 1 adet girdi ve 1 adet \u00e7\u0131kt\u0131 bilgisi i\u00e7eren d\u00fc\u011f\u00fcm\u00fcm\u00fcz yer al\u0131yor. 100 kez epoch ettiriyoruz ve batch_size \u0131m\u0131z\u0131 10 olarak ayarl\u0131yoruz. Bu \u015fekilde elde etti\u011fimiz sonu\u00e7 %70 lerde kal\u0131yor. \n\n\n\n\n\n# Keras ile nn denememiz svm in classification modellemesine g\u00f6re daha d\u00fc\u015f\u00fck bir do\u011fruluk oran\u0131 veriyor. Bu \u015fekilde 2 farkl\u0131 y\u00f6ntem ile birden fazla \u015fekilde test i\u015flemi ger\u00e7ekle\u015ftiriyoruz.","0ea8aa69":"# SVM  s\u0131n\u0131fland\u0131rma yapt\u0131\u011f\u0131m\u0131zda elde etti\u011fimiz sonu\u00e7 \u00e7ok y\u00fcksek olmasada ilk ba\u015fta yapt\u0131\u011f\u0131m\u0131z \u00e7ok k\u00f6t\u00fc tahminlere g\u00f6re olduk\u00e7a iyi d\u00fczeyde %81 in \u00fczerinde bir do\u011fruluk oran\u0131 ile d\u00fckkanlar\u0131n satt\u0131\u011f\u0131 ortalama \u00fcr\u00fcn \u00fczerinden d\u00fckkanlar\u0131n ortalama \u00fcr\u00fcn fiyat\u0131n\u0131n 1000 tl nin \u00fczerinde olup olmad\u0131\u011f\u0131n\u0131 tahmin ediyor. ","e9d0a38c":"# Train ve test diye bize verilen tablolardan anlaml\u0131 bir sonu\u00e7 alman\u0131n zorlu\u011fu ve \u00f6zellikle test datas\u0131n\u0131n sadece shop ve item id bilgisini i\u00e7ermesi bu iki tabloyu kullanarak yapabilece\u011fimiz i\u015flemleri k\u0131s\u0131tlad\u0131\u011f\u0131 i\u00e7in daha farkl\u0131 \u00e7\u00f6z\u00fcm yollar\u0131na gidiyoruz. Ve sadece \u00e7ok uzun olan train verisini kendi i\u00e7inde test train diye ay\u0131rarak i\u015flem yapman\u0131n daha anlaml\u0131 sonu\u00e7lar almam\u0131z\u0131 sa\u011flayaca\u011f\u0131n\u0131 d\u00fc\u015f\u00fcnerek bu \u015fekilde i\u015flemlere ba\u015fl\u0131yoruz.  ","098a0090":"# Verileri data k\u0131sm\u0131na input olarak kaggle \u00fczerinden \u00e7ekip tablolar\u0131 g\u00f6steriyoruz.","9697f21d":"# **Bu k\u0131s\u0131mda art\u0131k train data \u00fczeinden test ve train datam\u0131z\u0131 olu\u015fturacak ve anlaml\u0131 bir sonu\u00e7 \u00fcretmeye \u00e7al\u0131\u015faca\u011f\u0131z. Verimizi tekrar date indexi  ile tarih format\u0131yla al\u0131yoruz.**","5f0cb959":"# Veriyi daha iyi anlamak i\u00e7in item id ve item fiyatlar\u0131n\u0131 d\u00fckkan id si 0 olan d\u00fckkan \u00fczerinden \u00e7izdirerek  inceliyoruz ve yapaca\u011f\u0131m\u0131z modele karar veriyoruz.","5195ff16":"# \u0130lk olarak uygulad\u0131\u011f\u0131m\u0131z d\u00fckkan id sine g\u00f6re kategori tahmini 0 a yak\u0131n bir do\u011fruluk oran\u0131 verdi\u011fi i\u00e7in ba\u015fka bir deneme yap\u0131yoruz ve bu sefer direk ham veriler \u00fczerinden item id ile shop id yani \u00fcr\u00fcn ile d\u00fckkan tahmini yap\u0131yoruz  fakat bunun do\u011frulu\u011fuda 0.0238 \u00e7\u0131k\u0131yor ve train - test tablosu \u00fczerinden anlaml\u0131 bir \u015feyler \u00e7\u0131kmayaca\u011f\u0131na karar k\u0131l\u0131yoruz.","778bc695":"# D\u00fckkanlar\u0131 kendi i\u00e7erisinde d\u00fckkan idlerine g\u00f6re gruplay\u0131p ortalamalar\u0131n\u0131 al\u0131yoruz. Bu sayede o d\u00fckkanda sat\u0131lan \u00fcr\u00fcnlerin ortalama fiyat\u0131 ve ortalama adedi bilgisini elde etmek istiyoruz. Daha sonda bu d\u00fckkanlardan ortalama \u00fcr\u00fcn fiyat\u0131 1000 liran\u0131n \u00fczerinde olan d\u00fckkanlara Y\u00fcksekKar etiketi ekliyoruz. E\u011fer \u00fcr\u00fcnlerinin ortalamas\u0131 1000 \u00fczerindeyse y\u00fcksekkar de\u011feri true  de\u011filse false \u00e7eklinde olacak. ","8125caa8":"# Eldeki veriyi 2 kolonlu bir hale getiriyoruz d\u00fckkanda sat\u0131lan ortalama \u00fcr\u00fcn adedi \u00fczerinden bu d\u00fckkan\u0131n y\u00fcksek kar diye tabir etti\u011fimiz ortalama \u00fcr\u00fcn fiyat\u0131 1000 tl \u00fcst\u00fcnde bir d\u00fckkan olup olmad\u0131\u011f\u0131n\u0131n tahmin edilmesini istiyoruz. Bunu iki farkl\u0131 y\u00f6ntem ile yapaca\u011f\u0131z \u00f6nce yukar\u0131da da kulland\u0131\u011f\u0131m\u0131z svm ile daha sonra **KERAS** kullanarak yapt\u0131\u011f\u0131m\u0131z ANN sinir a\u011flar\u0131 ile modelleyip elde etti\u011fimiz sonu\u00e7lara bakaca\u011f\u0131z.","9cae7253":"# Train datam\u0131z\u0131 detayl\u0131 g\u00f6rmek ad\u0131na okurken date kolonunu tarih olarak al\u0131nmas\u0131n\u0131 sa\u011fl\u0131yoruz ve daha sonra set index fonksiyonu ile zaman bilgisini index olarak data frame veriyoruz. Veriyi g\u00f6zlemlemek ad\u0131na tablonun 1 ayl\u0131k d\u00f6nemlerinin ortalamas\u0131n\u0131 alarak 3 milyona yak\u0131n veriyi ayl\u0131k olarak g\u00f6steriyoruz.","f0b4d4c9":"# Train datalar\u0131n oldu\u011fu tablo ile items tablosunu birle\u015ftiriyoruz bunun i\u00e7in pandas\u0131n merge fonksiyonunu kulan\u0131yoruz.  Amac\u0131m\u0131z item_id say\u0131s\u0131 \u00e7ok fazla oldu\u011fu i\u00e7in bunu 84 tane olan kategori say\u0131s\u0131 ile s\u0131n\u0131rland\u0131rmak . Train tablosu  test tablosuna benzer hale getirip bu 2 verili tablolar \u00fczerinden bir k\u00fcmeleme yapabilmek. Shop id si \u00fczerinden category id tahmini yapt\u0131rmaya \u00e7al\u0131\u015f\u0131yoruz. \u00c7ok fazla kategori oldu\u011fu i\u00e7in iyi bir sonu\u00e7 beklemiyorum. Daha sonraki k\u0131s\u0131mlarda daha iyi veriler elde edece\u011fiz."}}