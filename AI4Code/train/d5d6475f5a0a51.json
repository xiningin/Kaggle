{"cell_type":{"7af7e841":"code","af5c9eac":"code","e6ab5492":"code","04483ac8":"code","b4083b32":"code","dacf7054":"code","fe7d4cd1":"code","cf4cc558":"code","cf1d7300":"code","e25c064d":"code","25fcdbbf":"code","c3de1827":"code","b4d1c5d5":"code","d0b09f6c":"code","05de5bd0":"code","8457e5a7":"code","43972d80":"code","ebe5fa2e":"code","56856e1f":"code","c56c31a1":"code","f0f423bb":"code","85554a87":"code","78bea7d8":"code","2d004372":"code","c207a2c6":"code","86a36982":"code","4df7df6b":"code","ba0c840e":"code","e515ef1c":"code","d982d583":"code","bdb27d04":"code","11838acf":"code","bd2574ec":"code","241dfe6a":"code","8d48b38f":"code","7dd253a2":"code","5e893232":"code","b776f428":"code","38ec83a4":"code","1f140e12":"code","134fe215":"code","254ce8d4":"code","6f2c7efb":"code","e2c18aa1":"code","5540af3b":"code","e9d4aaac":"code","f3335223":"code","e0d3f933":"code","c1123c7c":"code","f474f406":"code","3b283e01":"code","0ce83a7e":"markdown","0f1db3f8":"markdown","fabccfdd":"markdown","5acca1b2":"markdown","4360d8cb":"markdown","b5778f63":"markdown","857c5bba":"markdown","05618437":"markdown","1f18ca9f":"markdown","063f1d70":"markdown","74c8f1b0":"markdown","d9a05e16":"markdown","b402f792":"markdown"},"source":{"7af7e841":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af5c9eac":"#load data\ntrain = pd.read_csv('..\/input\/hr-ana\/train.csv')\ntest = pd.read_csv('..\/input\/hr-ana\/test.csv')\ntrain.head().T","e6ab5492":"print(\"Shape of Train Dataset: \",train.shape)\nprint(\"Shape of Test Dataset: \",test.shape)","04483ac8":"#EDA\ntrain.info()","b4083b32":"#numerical variables including target\n\nax = train.hist(bins=25, grid=False, figsize=(12,12),color='#006494',zorder=2, rwidth=0.9)\nplt.suptitle(\"Numerical Variables\")","dacf7054":"# categorical features - department\nplt.figure(figsize=(15,4))\nax = sns.countplot(x=\"department\",data=train, palette=\"viridis\",hue=\"is_promoted\", order = train['department'].value_counts().index)\nax.grid(False)\nplt.suptitle(\"Department\")\nplt.show()","fe7d4cd1":"# categorical features - region\nplt.figure(figsize=(15,20))\nax = sns.countplot(y=\"region\",data=train, \n                    palette=\"viridis\", order = train['region'].value_counts().index)\nax.grid(False)\nsns.set(style=\"whitegrid\")\nplt.suptitle(\"Region\")\nplt.show()","cf4cc558":"# categorical features - education\nplt.figure(figsize=(6,4))\nax = sns.countplot(x=\"education\",data=train, palette=\"viridis\",hue=\"is_promoted\", order = train['education'].value_counts().index)\nax.grid(False)\nplt.suptitle(\"Education\")\nplt.show()","cf1d7300":"# categorical features - gender\nplt.figure(figsize=(6,4))\nax = sns.countplot(x=\"gender\",data=train, palette=\"viridis\",hue=\"is_promoted\", order=train['gender'].value_counts().index)\nsns.set(style=\"whitegrid\")\nax.grid(False)\nplt.suptitle(\"Gender\")\nplt.show()","e25c064d":"# categorical features - recruitment_channel\nplt.figure(figsize=(6,4))\nax = sns.countplot(x=\"recruitment_channel\",data=train, palette=\"viridis\",hue=\"is_promoted\", order=train['recruitment_channel'].value_counts().index)\nax.grid(False)\nsns.set(style=\"whitegrid\")\nplt.suptitle(\"Recruitment Channel\")\nplt.show()","25fcdbbf":"train.is_promoted.value_counts(normalize=True)","c3de1827":"train.is_promoted.value_counts()","b4d1c5d5":"#merge train and test for preprocessing\ndf = train\ndf = df.append(test)\ndf.shape","d0b09f6c":"#checking missing values\nprint(\"Education NA: \",(df.education.isna().sum()\/len(df))*100)\nprint(\"Previous Year Rating NA: \",(df.previous_year_rating.isna().sum()\/len(df))*100)","05de5bd0":"df.education.value_counts(normalize=True)","8457e5a7":"#treating na as a new category called missing\ndf['education'] = df['education'].fillna('Missing')\ndf.education.value_counts(normalize=True,dropna=False)","43972d80":"df.previous_year_rating.value_counts(normalize=True)","ebe5fa2e":"df.previous_year_rating.median()","56856e1f":"#replace missing value with median\ndf['previous_year_rating'] = df['previous_year_rating'].fillna(3.0)\ndf.previous_year_rating.value_counts(normalize=True,dropna=False)","c56c31a1":"#onehotencoder -> cat features\nfrom sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(categories='auto')\nohe_arr = ohe.fit_transform(df[['department','region','education','gender','recruitment_channel']]).toarray()\nohe_labels = ohe.get_feature_names(['department','region','education','gender','recruitment_channel'])\nohe_df = pd.DataFrame(ohe_arr, columns= ohe_labels)\nohe_df.head()","f0f423bb":"#drop columns and concat both dataframes\ndf.drop(columns= ['department','region','education','gender','recruitment_channel'], inplace=True)","85554a87":"df.reset_index(inplace=True)\ndf = pd.concat([df,ohe_df],axis=1,join='inner')\ndf.info() ","78bea7d8":"df.drop(columns= ['index'], inplace=True)\ndf.shape","2d004372":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf[['no_of_trainings','age','previous_year_rating','length_of_service','awards_won?','avg_training_score']] = scaler.fit_transform(df[['no_of_trainings','age','previous_year_rating','length_of_service','awards_won?','avg_training_score']])\ndf.head()","c207a2c6":"seed_value = 12321\nimport os\nos.environ['PYTHONHASHSEED']=str(seed_value)\nimport random\nrandom.seed(seed_value)\nnp.random.seed(seed_value)","86a36982":"#separate train and test datasets\ntrain, test = df[~df['is_promoted'].isnull()], df[df['is_promoted'].isnull()]\nprint(\"Shape of Train Dataset: \",train.shape)\nprint(\"Shape of Test Dataset: \",test.shape)","4df7df6b":"train.drop(columns=['employee_id'],inplace=True)\nprint(\"Shape of Train Dataset: \",train.shape)","ba0c840e":"# train valid split\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(train.drop(columns=['is_promoted']),train['is_promoted'], test_size=0.3,random_state=seed_value)\nprint(\"Shape of X Train Dataset: \",X_train.shape)\nprint(\"Shape of Y Train Dataset: \", y_train.shape)\nprint(\"Shape of X Valid Dataset: \",X_valid.shape)\nprint(\"Shape of Y Valid Dataset: \",y_valid.shape)","e515ef1c":"#determine the mutual information\nfrom sklearn.feature_selection import mutual_info_classif\nmutual_info = mutual_info_classif(X_train,y_train)\nmutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","d982d583":"from sklearn.feature_selection import SelectKBest\n\nselect_top40 = SelectKBest(mutual_info_classif,k=40)\nselect_top40.fit(X_train,y_train)\nX_train.columns[select_top40.get_support()]","bdb27d04":"feat_select = X_train.columns[select_top40.get_support()]\nX_train[feat_select].head(5)","11838acf":"#import modules\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB","bd2574ec":"#defining learning classifiers\n\nnames = [\"Nearest_Neighbors\",\"RBF_SVM\", \"Decision_Tree\", \"Random_Forest\",\"AdaBoost\",\"Naive_Bayes\"]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=1, gamma=2),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=100),\n    AdaBoostClassifier(n_estimators=100),\n    GaussianNB()]","241dfe6a":"# calculating models scores\nscores = []\nfor name, clf in zip(names, classifiers):\n    clf.fit(X_train, y_train)\n    score = clf.score(X_valid, y_valid)\n    scores.append(score)\n\nmodels = pd.DataFrame()\nmodels['name'] = names\nmodels['score'] = scores\nmodels.sort_values(by='score',ascending=False)","8d48b38f":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, precision_score,recall_score, f1_score\nimport scikitplot as skplt\n\nadc = AdaBoostClassifier(n_estimators=100)\nadc.fit(X_train, y_train)\npreds_valid = adc.predict(X_valid)\nskplt.metrics.plot_confusion_matrix(y_valid, preds_valid)\nplt.title('Confusion Matrix')\nplt.show()","7dd253a2":"print(\"Accuracy: \",accuracy_score(y_valid,preds_valid))\nprint(\"Recall: \",recall_score(y_valid,preds_valid))\nprint(\"Precision: \",precision_score(y_valid,preds_valid))\nprint(\"F1 Score: \", f1_score(y_valid,preds_valid))","5e893232":"# model only the top_40 features\nadc.fit(X_train[feat_select], y_train)\npreds_valid = adc.predict(X_valid[feat_select])\nskplt.metrics.plot_confusion_matrix(y_valid, preds_valid)\nplt.title('Confusion Matrix - Feature Selection')\nplt.show()","b776f428":"print(\"Accuracy: \",accuracy_score(y_valid,preds_valid))\nprint(\"Recall: \",recall_score(y_valid,preds_valid))\nprint(\"Precision: \",precision_score(y_valid,preds_valid))\nprint(\"F1 Score: \", f1_score(y_valid,preds_valid))","38ec83a4":"#oversampling class 1\n\nfrom imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\nX_ros,y_ros= ros.fit_resample(X_train[feat_select],y_train)\ny_ros.value_counts()#oversampling class 1\n\nfrom imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\nX_ros,y_ros= ros.fit_resample(X_train[feat_select],y_train)\ny_ros.value_counts()","1f140e12":"adc.fit(X_ros[feat_select], y_ros)\npreds_valid = adc.predict(X_valid[feat_select])\nskplt.metrics.plot_confusion_matrix(y_valid, preds_valid)\nplt.title('Confusion Matrix - Oversampling Class 1')\nplt.show()","134fe215":"print(\"Accuracy: \",accuracy_score(y_valid,preds_valid))\nprint(\"Recall: \",recall_score(y_valid,preds_valid))\nprint(\"Precision: \",precision_score(y_valid,preds_valid))\nprint(\"F1 Score: \",f1_score(y_valid,preds_valid))","254ce8d4":"#undersampling - tomek_links\n\nfrom imblearn.under_sampling import TomekLinks\n\nt1 = TomekLinks()\nX_t1,y_t1= t1.fit_resample(X_train[feat_select],y_train)\ny_t1.value_counts()","6f2c7efb":"adc.fit(X_t1[feat_select], y_t1)\npreds_valid = adc.predict(X_valid[feat_select])\nskplt.metrics.plot_confusion_matrix(y_valid, preds_valid)\nplt.title('Confusion Matrix - Tomek links')\nplt.show()","e2c18aa1":"print(\"Accuracy: \",accuracy_score(y_valid,preds_valid))\nprint(\"Recall: \",recall_score(y_valid,preds_valid))\nprint(\"Precision: \",precision_score(y_valid,preds_valid))\nprint(\"F1 Score: \",f1_score(y_valid,preds_valid))","5540af3b":"# neighbourhood cleaning rule\n\nfrom imblearn.under_sampling import NeighbourhoodCleaningRule\n\nncr = NeighbourhoodCleaningRule()\nX_ncr,y_ncr= ncr.fit_resample(X_train[feat_select],y_train)","e9d4aaac":"y_ncr.value_counts()","f3335223":"adc.fit(X_ncr[feat_select], y_ncr)\npreds_valid = adc.predict(X_valid[feat_select])\nskplt.metrics.plot_confusion_matrix(y_valid, preds_valid)\nplt.title('Confusion Matrix - Neighbourhood Cleaning Rule')\nplt.show()","e0d3f933":"print(\"Accuracy: \",accuracy_score(y_valid,preds_valid))\nprint(\"Recall: \",recall_score(y_valid,preds_valid))\nprint(\"Precision: \",precision_score(y_valid,preds_valid))\nprint(\"F1 Score: \",f1_score(y_valid,preds_valid))","c1123c7c":"test.columns","f474f406":"test['is_promoted'] = adc.predict(test[feat_select])\ntest.is_promoted.value_counts()","3b283e01":"#submission\ntest[['employee_id', 'is_promoted']].to_csv('submission.csv', index=False)","0ce83a7e":"## Classification Models","0f1db3f8":"## Categorical Features","fabccfdd":"## Target","5acca1b2":"## Seed","4360d8cb":"## Missing Values","b5778f63":"# EDA","857c5bba":"## Validation Data","05618437":"## Feature Selection","1f18ca9f":"## Desbalanced Target","063f1d70":"# Preprocessing","74c8f1b0":"## Numerical Features","d9a05e16":"## One Hot Encoder","b402f792":"## Normalization"}}