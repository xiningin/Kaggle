{"cell_type":{"1abbc5e2":"code","961cb1bf":"code","487a5435":"code","8bf07c9c":"code","a4ab7996":"code","ea1a41c4":"code","6d536adb":"code","235ea8cf":"code","9b214843":"code","a4ac3259":"code","0444f3ad":"code","0eda27f5":"code","e48bda9d":"code","cd7ee9e2":"code","083199a4":"code","be1be515":"code","110b1201":"code","d2b06d2d":"code","83ff4906":"code","6d6fd6e6":"code","bf9c0e9d":"code","7c340dc5":"code","b8390197":"code","9068e20d":"code","d1983ada":"code","96fd9373":"code","89af5768":"code","d032ddbf":"code","03d4dc8a":"code","09eb4e42":"code","77ffbb91":"markdown","8243720f":"markdown","86220f9a":"markdown"},"source":{"1abbc5e2":"# Imporitng libraries\nimport pandas as pd\nimport os\nimport random\nimport numpy as np\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import clear_output\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\n\n\nrandom.seed(42)","961cb1bf":"# Making a list containing all unique classes in the training set\n\n# Reading the training dataset\ntraining_dataframe = pd.read_csv(\"..\/input\/food-classification\/train_img.csv\")\n\n# Classes column\nclasses = training_dataframe['ClassName'].unique()\n\n# Creating a list containing random classes of size equal of no. of samples in test data\n#random_test_predictions = [random.choice(classes) for i in range(len(test_name_ids))]","487a5435":"training_dataframe.shape","8bf07c9c":"training_dataframe.head()","a4ab7996":"np.unique(training_dataframe[\"ClassName\"], return_counts=True)[1]","ea1a41c4":"plt.figure(figsize=(30,12))\nplt.bar(np.unique(training_dataframe[\"ClassName\"], return_counts=True)[0], np.unique(training_dataframe[\"ClassName\"], return_counts=True)[1])\nplt.xticks(rotation=90, fontsize=18)\nplt.yticks(fontsize=18)\nplt.grid()\nplt.show()","6d536adb":"training_dataframe.drop_duplicates(subset = [\"ClassName\"])[\"ImageId\"]","235ea8cf":"fig, ax = plt.subplots(nrows=13, ncols=5,figsize=(24,15))\n\ncnt = 0\n\nfor i,row in enumerate(ax):\n    for j,col in enumerate(row):\n        try:\n            img = cv2.imread(\"..\/input\/food-classification\/train_images\/train_images\/\" + np.asarray(training_dataframe.drop_duplicates(subset = [\"ClassName\"])[\"ImageId\"])[cnt], cv2.IMREAD_COLOR )\n            ax[i,j].imshow(img[...,::-1])\n            cnt += 1\n        except:\n            pass\nplt.show()","9b214843":"class_names = pd.get_dummies(training_dataframe[\"ClassName\"]).columns","a4ac3259":"class_names","0444f3ad":"y_dev = np.asarray(pd.get_dummies(training_dataframe[\"ClassName\"]))","0eda27f5":"y_dev.shape","e48bda9d":"X_dev = np.asarray(training_dataframe[\"ImageId\"])","cd7ee9e2":"X_dev.shape","083199a4":"train_path = \"..\/input\/food-classification\/train_images\/train_images\/\"","be1be515":"def batch_generator(batch_size, gen_x): \n    batch_features = np.zeros((batch_size,256,256,3))\n    batch_labels = np.zeros((batch_size,61)) \n    while True:\n        for i in range(batch_size):\n            batch_features[i] , batch_labels[i] = next(gen_x)\n        yield batch_features, batch_labels","110b1201":"def generate_data(filelist, img_path, target):\n    while True:\n        for i,j in enumerate(filelist):\n            X_train = cv2.imread(img_path + j, cv2.IMREAD_COLOR )\n            X_train = cv2.resize(X_train, (256,256), interpolation= cv2.INTER_LINEAR )\n\n            y_train = target[i]\n\n            yield X_train, y_train","d2b06d2d":"def create_model():\n    base_model = tf.keras.applications.EfficientNetB1(\n    weights= \"imagenet\", include_top=False, input_shape= (256,256,3)\n    )\n    num_classes=61\n\n    x = base_model.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    predictions = tf.keras.layers.Dense(num_classes, activation= 'softmax')(x)\n    model = tf.keras.Model(inputs = base_model.input, outputs = predictions)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=['acc'])\n    return model","83ff4906":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=1, verbose=1, mode='min',\n    min_delta=0.0001, cooldown=2, min_lr=0\n)","6d6fd6e6":"class PlotLosses(tf.keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n\n        self.fig = plt.figure()\n\n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n\n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.i += 1\n\n        clear_output(wait=True)\n        plt.plot(self.x, self.losses, label=\"loss\")\n        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n        plt.legend()\n        plt.show();\n\nplot_losses = PlotLosses()","bf9c0e9d":"batch_size = 64\nnum_epoch = 10\nskf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_dev, y_dev)\n\n\nfor train_index, val_index in skf.split(X_dev, training_dataframe[\"ClassName\"]):\n    X_train, X_val = X_dev[train_index], X_dev[val_index]\n    y_train, y_val = y_dev[train_index], y_dev[val_index]\n    model = create_model()\n    history = model.fit(x=batch_generator(batch_size, generate_data(X_train, train_path, y_train)), epochs=num_epoch, \n                                steps_per_epoch=(y_train.shape[0]\/batch_size),\n                                validation_data = batch_generator(batch_size, generate_data(X_val, train_path, y_val)),\n                                validation_steps=(y_val.shape[0]\/batch_size),\n                                validation_batch_size=None,\n                                validation_freq=1,\n                                verbose = 1,\n                                callbacks = [plot_losses,reduce_lr]\n                                )\n    y_prob = np.ones((len(X_val),61))\n    for i,j in enumerate(X_val):\n        img = cv2.imread(train_path + j, cv2.IMREAD_COLOR )\n        img_rs = cv2.resize(img, (256,256), interpolation= cv2.INTER_LINEAR )\n        y_prob[i,:] = model.predict(np.expand_dims(img_rs,axis=0))\n        \n    C = confusion_matrix(np.argmax(y_val,axis=1),np.argmax(y_prob,axis=1))\n    C_norm = C \/ C.astype(np.float).sum(axis=1)\n    plt.figure(figsize=(36,24))\n    sns.heatmap(np.round(C_norm,2), annot=True, xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"True classes\", fontsize=20)\n    plt.ylabel(\"Predicted classes\", fontsize=20)\n    plt.xticks(fontsize=18)\n    plt.yticks(fontsize=18)\n    plt.show()","7c340dc5":"batch_size = 64\nnum_epoch = 10\nmodel = create_model()\nhistory = model.fit(x=batch_generator(batch_size, generate_data(X_dev, train_path, y_dev)), epochs=num_epoch, \n                            steps_per_epoch=(y_dev.shape[0]\/batch_size), \n                            verbose = 1\n                            )","b8390197":"!pip install lime --upgrade","9068e20d":"import lime\nfrom lime import lime_image\nimport shap\nimport shap","d1983ada":"f_name = []\npred = []\nfor i in os.listdir(\"..\/input\/food-classification\/test_images\/test_images\/\"):\n    f_name.append(i)\n    img = cv2.imread(\"..\/input\/food-classification\/test_images\/test_images\/\" + i, cv2.IMREAD_COLOR )\n    img = cv2.resize(img, (256,256), interpolation= cv2.INTER_LINEAR )\n    prediction = model.predict(np.expand_dims(img,0))\n    pred.append(class_names[np.argmax(prediction)])\n","96fd9373":"def f(x):\n    tmp = x.copy()\n    return model.predict(tmp)","89af5768":"lime_explainer = lime_image.LimeImageExplainer()\nprint(f\"{np.unique(pred).shape[0]} eplanations\")\nfor i in np.unique(pred):\n    indx = np.where(np.asarray(pred) == i)[0][0]\n    img = cv2.imread(\"..\/input\/food-classification\/test_images\/test_images\/\" + os.listdir(\"..\/input\/food-classification\/test_images\/test_images\/\")[indx], cv2.IMREAD_COLOR )\n    img = cv2.resize(img, (256,256), interpolation= cv2.INTER_LINEAR )\n    lime_explanation = lime_explainer.explain_instance(img.reshape(256, 256, 3), model.predict, top_labels=5, hide_color=0, num_samples=1000)\n    \n    #Select the same class explained on the figures above.\n    ind =  lime_explanation.top_labels[0]\n\n    #Map each explanation weight to the corresponding superpixel\n    dict_heatmap = dict(lime_explanation.local_exp[ind])\n    heatmap = np.vectorize(dict_heatmap.get)(lime_explanation.segments) \n\n    #Plot. The visualization makes more sense if a symmetrical colorbar is used.\n    \n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n    fig.suptitle(\"Classified as: \" + i, fontsize=24)\n    fig.set_figheight(8)\n    fig.set_figwidth(20)\n    ax1.set_title('Original image')\n    ax1.imshow(img[...,::-1])\n    \n    ax2.set_title('Image with LIME heatmap')\n    ax2.imshow(img[...,::-1])\n    ax2.imshow(heatmap, cmap = 'Reds', vmin  = -heatmap.max(), vmax = heatmap.max(), alpha=.6)\n\n\n    #temp, mask = lime_explanation.get_image_and_mask(lime_explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n    #fig, (ax1, ax2) = plt.subplots(1, 2)\n    #fig.suptitle(i)\n    #ax1.imshow(img[...,::-1])\n    #ax2.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\n\n    masker_blur = shap.maskers.Image(\"blur(128,128)\", img.shape)\n    shap_explainer = shap.Explainer(f, masker_blur, output_names=class_names)\n    shap_values = shap_explainer(np.expand_dims(img,0), max_evals=500, batch_size=50, outputs=shap.Explanation.argsort.flip[:4])\n    ax3.set_title('Image with SHAP heatmap')\n    ax3.imshow(img[...,::-1])\n    ax3.imshow(shap_values.values[0,:,:,0,0],alpha=.5, cmap=\"Reds\")\n    plt.show()","d032ddbf":"predictions = pred","03d4dc8a":"# Converting the list to dataframe\n\npredictions_df = pd.DataFrame(predictions, columns=[\"ClassName\"])\npredictions_df","09eb4e42":"# Saving the dataframe to csv\npredictions_df.to_csv(\"submission.csv\", index=False)","77ffbb91":"# <center>Food classifications - classify food types from images<\/center>\n### This notebook uses a dataset comprising 9323 images of 61 different food types\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/i.imgur.com\/S4gVhmT.jpg\" alt=\"AI pregnancy\" style=\"height:500px;margin-top:3rem;\"> <\/div>","8243720f":"## Import and explore the data","86220f9a":"## One-hot encode the labels"}}