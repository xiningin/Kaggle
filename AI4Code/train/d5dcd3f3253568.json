{"cell_type":{"8e7aaabe":"code","36b90674":"code","1d280b80":"code","0f5ddbc3":"code","b6fe2f4f":"code","aa99c542":"code","3f5b1986":"code","b8bf6ac6":"code","e38ea291":"code","2e60fa6d":"code","c111b1ce":"code","13559d19":"code","29571e85":"code","16c918aa":"markdown","fe9e5140":"markdown"},"source":{"8e7aaabe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","36b90674":"#reading the files\ntrain = pd.read_csv(\"..\/input\/learn-together\/train.csv\")\ntest = pd.read_csv(\"..\/input\/learn-together\/test.csv\")\nprint(train.columns)","1d280b80":"#setting aside target values and index\ny = train.Cover_Type\ntest_id = test['Id']","0f5ddbc3":"#do this preprocessing job only once\nimport pickle\n\nif os.path.isfile(\"X.pickle\"):\n    with open( \"X.pickle\", \"rb\" ) as fh1:\n        X = pickle.load(fh1)\n    with open('test.pickle', 'rb') as fh2:\n        test = pickle.load(fh2)\nelse:\n    #dropping Soil_Type7 and Soil_Type15\n    train = train.drop(['Id','Soil_Type7', 'Soil_Type15'], axis = 1)\n    test = test.drop(['Id','Soil_Type7', 'Soil_Type15'], axis = 1)\n\n    #prepare data for training the model\n    X = train.drop(['Cover_Type'], axis = 1)\n\n    #reducing Soil_Type cols to single col \n    X = X.iloc[:, :14].join(X.iloc[:, 14:].dot(range(1,39)).to_frame('Soil_Type1'))\n    test = test.iloc[:, :14].join(test.iloc[:, 14:].dot(range(1,39)).to_frame('Soil_Type1'))\n    #print(X.columns)\n    #reducing Wilderness_Area to single col \n    X = X.iloc[:,:10].join(X.iloc[:,10:-1].dot(range(1,5)).to_frame('Wilderness_Area1')).join(X.iloc[:,-1])\n    test = test.iloc[:,:10].join(test.iloc[:,10:-1].dot(range(1,5)).to_frame('Wilderness_Area1')).join(test.iloc[:,-1])\n    print(X.columns)\n\n    #horizontal and vertical distance to hydrology can be easily combined\n    cols = ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology']\n    X['Distance_to_hydrology'] = X[cols].apply(np.linalg.norm, axis=1)\n    X = X.drop(cols, axis = 1)\n    test['Distance_to_hydrology'] = test[cols].apply(np.linalg.norm, axis=1)\n    test = test.drop(cols, axis = 1)\n\n    #shot in the dark - convert like colour tuples to grayscale\n    cols = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n    weights = pd.Series([0.299, 0.587, 0.114], index=cols)\n    X['Hillshade'] = (X[cols]*weights).sum(1)\n    X = X.drop(cols, axis = 1)\n    test['Hillshade'] = (test[cols]*weights).sum(1)\n    test = test.drop(cols, axis=1)\n\n    #pickling data for quick access\n    with open('X.pickle', 'wb') as fh1:\n        pickle.dump(X, fh1)\n    with open('test.pickle', 'wb') as fh2:\n        pickle.dump(test, fh2)","b6fe2f4f":"#split data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","aa99c542":"#approx measure of roc_auc for multiclass target\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_auc_score\ndef multiclass_roc_auc_score(test, pred, average='micro'):\n    lb = LabelBinarizer()\n    lb.fit(test)\n    test = lb.transform(test)\n    pred = lb.transform(pred)\n    return roc_auc_score(test, pred, average=average)","3f5b1986":"#set parameter values\nparam_grid = {\"n_estimators\":  np.arange(2,50,2),\n              \"max_depth\":  [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n              \"min_samples_split\": np.linspace(0.1, 1.0, 10, endpoint=True), #np.arange(1,150,1),\n              \"min_samples_leaf\": np.linspace(0.1, 0.5, 5, endpoint=True),  #np.arange(1,60,1),\n              \"max_leaf_nodes\": np.arange(5,150,5),\n              \"min_weight_fraction_leaf\": np.arange(0.1,0.4, 0.1)}","b8bf6ac6":"#set the classifier\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(random_state=1)","e38ea291":"#a function for plotting score against each parameter\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\n\ndef evaluate_param(clf, param_grid, metric, metric_abv):\n    data = []\n    for parameter, values in dict.items(param_grid):\n        for value in values:\n            d = {parameter:value}\n            warnings.filterwarnings('ignore') \n            clf = RandomForestClassifier(**d)\n            clf.fit(X_train, y_train)\n            x_pred = clf.predict(X_train)\n            train_score = metric(y_train, x_pred)\n            y_pred = clf.predict(X_val)\n            test_score = metric(y_val, y_pred)\n            data.append({'Parameter':parameter, 'Param_value':value, \n            'Train_'+metric_abv:train_score, 'Test_'+metric_abv:test_score})\n    df = pd.DataFrame(data)\n    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10,5))\n    for (parameter, group), ax in zip(df.groupby(df.Parameter), axes.flatten()):\n        group.plot(x='Param_value', y=(['Train_'+metric_abv,'Test_'+metric_abv]),\n        kind='line', ax=ax, title=parameter)\n        ax.set_xlabel('')\n    plt.tight_layout()\n    plt.show()","2e60fa6d":"from sklearn.metrics import mean_absolute_error\n#evaluate_param(clf, param_grid, mean_absolute_error, 'MAE')","c111b1ce":"#refining the number of search points\nparam_grid2 = {\"n_estimators\": [18,21],\n               'max_leaf_nodes': [150,None],\n               #'max_depth': [None],\n                #'min_samples_split': [2, 5], \n                #'min_samples_leaf': [1, 2],\n              \"max_features\": ['auto','sqrt'],\n              \"bootstrap\": [True, False]}","13559d19":"from sklearn.model_selection import GridSearchCV\n\ngrid_search = GridSearchCV(clf, param_grid=param_grid2, cv=8, \n                            scoring='accuracy')\ngs_result = grid_search.fit(X_train, y_train)\nprint(gs_result.best_params_)\nbest_clf = RandomForestClassifier(gs_result.best_params_)\ny_pred = gs_result.predict(X_val)\nval_mae = mean_absolute_error(y_val,y_pred)\nprint('Seventh try mae: ', val_mae)","29571e85":"test_pred = gs_result.predict(test)\noutput = pd.DataFrame({'Id': test_id, 'Cover_Type': test_pred.astype(int)})\noutput.to_csv('submission.csv', index=False)","16c918aa":"## Seems like I am flogging a dead horse.","fe9e5140":"# Searching for an intuitive way to set the parameters"}}