{"cell_type":{"3ac48a21":"code","bf3bbb09":"code","4ed77870":"code","ba243e46":"code","c38bf6bd":"code","48e5852a":"code","109392d3":"code","9b49b56c":"code","15cba231":"code","66216511":"code","85b8e14d":"code","e076272c":"code","b11e4a8f":"code","4e5922ed":"code","7dfa6c68":"code","3c8336c5":"code","890ad68b":"code","3361d2d4":"code","4c2f4224":"code","b25032df":"code","70db9636":"code","b554ba6a":"code","bbae4384":"code","1ea95918":"code","12e53d94":"code","098a260a":"code","f37c1aa0":"code","2086d4a8":"code","3ed0372e":"code","2796e529":"code","94972e65":"code","588677ac":"code","9c9ed926":"code","654d4dc8":"code","bb8d713a":"code","64e23265":"code","cd78c7ed":"code","0d3b86fe":"code","d6d39ded":"code","a63f5a10":"code","80692b20":"code","f2a25789":"code","e50bf19e":"code","ce5a3eb2":"markdown","0f684d96":"markdown","c0c8a1b5":"markdown","64b7118e":"markdown","635e5d85":"markdown","4c8b9d3e":"markdown","12cf21c8":"markdown","feff239d":"markdown","0fd574d2":"markdown","76784678":"markdown","ca136ef1":"markdown","0da03120":"markdown","37b3aaac":"markdown","4e8487fb":"markdown","f7eb939a":"markdown","08384c82":"markdown","5c898cc8":"markdown","3de7ed6c":"markdown","0c011644":"markdown","899c517d":"markdown","6209f0e7":"markdown","151ddce2":"markdown","4f502967":"markdown","5f475943":"markdown","ab202255":"markdown","ca600757":"markdown","75883cd4":"markdown","b303f588":"markdown","14644b53":"markdown","f9ac7aa4":"markdown","5afec72e":"markdown","bda0fc86":"markdown","2b68c9b3":"markdown","8d020fb3":"markdown","ec30cadf":"markdown","3c719639":"markdown","bb6dd6a9":"markdown","540c029a":"markdown","bf4a8860":"markdown","1e5bfe39":"markdown"},"source":{"3ac48a21":"import pandas as pd\n\ncc = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ncc.shape","bf3bbb09":"cc.columns","4ed77870":"cc.info()","ba243e46":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(30,30))\ncc.hist(ax = ax)","c38bf6bd":"import seaborn as sns\n\nsns.countplot(cc['Class'])","48e5852a":"plt.scatter(cc['Time'], cc['Amount'])","109392d3":"plt.plot(cc['Time'])","9b49b56c":"act_time = cc['Time'].diff()  #getting reverse cumulatives","15cba231":"pd.crosstab(act_time, cc['Class'])","66216511":"##Checking to see if Frauds have some pattern wrt Amount\n\nimport numpy as np\n%matplotlib inline\n\n#total unique values in Amount\nprint('Total unique value',len(cc['Amount'].unique()))\nprint('Maximum Value', cc['Amount'].max())\nprint('Minimum Value', cc['Amount'].min())\n\n#Creating class intervals for Amount\nbins = np.arange(0, 26000, 1000)\nclassint = pd.DataFrame(pd.cut(cc['Amount'], bins = bins))\n\n#Adding the class in the orginial dataset\ncc1 = cc.copy()\ncc1['Classamt']=classint\n\n#Analyzing the frauds wrt the amounts\npd.crosstab(cc1['Classamt'],cc1['Class'])","85b8e14d":"fig, ax = plt.subplots(figsize=(10,10))\ncc.boxplot(ax=ax)","e076272c":"len(cc.columns)","b11e4a8f":"from sklearn.neighbors import LocalOutlierFactor\n\nl = LocalOutlierFactor()\nlfit = l.fit_predict(cc)\nlfit  #-1 = Outlier","4e5922ed":"outliers = np.where(lfit == -1)  \noutliers  #tuple of outliers indices","7dfa6c68":"outliers = np.asarray(outliers)  #Tuple to 2d array\n\ncc2 = cc.copy()\ncc3 = cc2.drop(outliers.flatten(), axis=0)  #Flatten() to convert 2d to 1d array\ncc3","3c8336c5":"from sklearn.preprocessing import StandardScaler\n\nscale = StandardScaler()\ncc3['Amount'] = scale.fit_transform(cc3[['Amount']])","890ad68b":"dupindex = cc3[cc3.duplicated()]\ndupindex.index","3361d2d4":"#Dropping duplicated rows\ncc4 = cc3.drop(dupindex.index)\ncc4.shape","4c2f4224":"cc_cleaned = cc4.copy()\ncc_cleaned.head()","b25032df":"target = cc_cleaned['Class']\nvariables = cc_cleaned.drop('Class', axis = 1)\n\nfrom sklearn.ensemble import ExtraTreesClassifier\ne = ExtraTreesClassifier()\nefit = e.fit(variables,target)\nimportance = efit.feature_importances_","70db9636":"plt.barh(variables.columns, importance)","b554ba6a":"from sklearn.feature_selection import SelectKBest, f_classif\ns = SelectKBest(score_func=f_classif, k=11)\nfeat_selected = s.fit(variables, target)\nfeat_selected.scores_","bbae4384":"impfeat = s.get_support()\ncc_impfeat = variables[variables.columns[impfeat]]\ncc_impfeat.head()","1ea95918":"X = cc_impfeat.copy()\nY = target.copy()","12e53d94":"from imblearn.under_sampling import NearMiss\n\nnm = NearMiss()\nX_res, y_res = nm.fit_resample(X,Y)\nsns.countplot(y_res)\nprint(\"Input Shape:\",X_res.shape, \"\\nTarget Shape:\", y_res.shape)","098a260a":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, random_state=42, train_size=0.5)","f37c1aa0":"from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nsv = SVC(random_state=42)\nknn = KNeighborsClassifier()\nlr = LogisticRegression(random_state=42)\ng = GaussianNB()\ndt = DecisionTreeClassifier(random_state=42)\nrf = RandomForestClassifier(random_state=42)\nmodel = [sv, knn, lr, g, dt, rf]\n\n\nkf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)","2086d4a8":"scores = []\nfor i in model:\n    s = cross_val_score(i, X_res, y_res, cv = kf, n_jobs=-1)\n    m = s.mean()\n    scores.append(m)\nscores","3ed0372e":"plt.barh(['sv', 'knn', 'lr', 'g', 'dt', 'rf'],scores)","2796e529":"from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\nrffit = rf.fit(X_train,y_train)\nrfpred = rf.predict(X_test)\nprint(\"F1 Score:\",f1_score(y_test, rfpred), \"\\nPrecision:\",precision_score(y_test, rfpred))","94972e65":"gfit = g.fit(X_train,y_train)\ngpred = g.predict(X_test)\nprint(\"F1 Score:\",f1_score(y_test, gpred), \"\\nPrecision:\",precision_score(y_test, gpred))","588677ac":"dtfit = dt.fit(X_train,y_train)\ndtpred = dt.predict(X_test)\nprint(\"F1 Score:\",f1_score(y_test, dtpred), \"\\nPrecision:\",precision_score(y_test, dtpred))","9c9ed926":"#__init()__ = g\n#__fit__ = gfit\n#__predicted__ = gpred\n\nprint(\"Training Accuracy:\",gfit.score(X_train,y_train),\"\\nTest Accuracy:\",gfit.score(X_test,y_test))","654d4dc8":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\n\npd.DataFrame(confusion_matrix(y_test,gpred), columns=['Pred0','Pred1'])","bb8d713a":"recall_score(y_test,gpred)","64e23265":"#__init()__ = g\n#__fit__ = gfit\n#__predicted__ = gpred\n\ngrid_param = {'var_smoothing': np.logspace(0,-9,100)}\ngrid_model = GridSearchCV(estimator=g, param_grid=grid_param, scoring='recall', cv=10)\ngrid_fit = grid_model.fit(X_train,y_train)\nbest_model = grid_model.best_estimator_\nprint(\"Best Hyperparameter setting:\",grid_model.best_params_)\nprint(\"Tuned Recall Score:\", grid_model.best_score_)","cd78c7ed":"grid_pred = best_model.predict(X_test)\nconfusion_matrix(y_test,grid_pred)","0d3b86fe":"#Defining function to reduce prob threshold to 0.02\ndef thresh(d):\n    vals = []\n    for i in d:\n        if i > 0.002:\n            vals.append(1)\n        else:\n            vals.append(0)\n    return vals","d6d39ded":"#Tuned Predicted values\n\ngrid_prob = best_model.predict_proba(X_test)\npositive_prob = grid_prob[:,1]\ny_pred = thresh(positive_prob)\n    \nconfusion_matrix(y_test,y_pred)","a63f5a10":"# Vizualizing Y_test\nvalues = y_test.value_counts()\nlabels = ['Not Fraud','Fraud']\nplt.pie(values,labels=labels)","80692b20":"# Vizualizing Tuned Predicted Values\n# y_pred\n\nvalues1 = pd.DataFrame(y_pred).value_counts()\nlabels1 = ['Not Fraud','Fraud']\nplt.pie(values1,labels=labels1)","f2a25789":"#Model Metrics\n\nprint(\"Recall:\",recall_score(y_test,y_pred))\nprint(\"Precision:\",precision_score(y_test,y_pred))\nprint(\"F1:\",f1_score(y_test,y_pred))\nprint(\"Train Score\", best_model.fit(X_train,y_train).score(X_train,y_train))\nprint(\"Test Score\/Accuracy\", best_model.fit(X_train,y_train).score(X_test,y_test))","e50bf19e":"# ROC Curve and AUC\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_roc(y_test,best_model.predict_proba(X_test))\nplt.show()\nprint(\"Area Under Curve:\",roc_auc_score(y_test,positive_prob))","ce5a3eb2":"# Result\n\n1. model = best_model\n2. model score\/accuracy = 95.57%\n2. predictions = y_pred\n3. recall = 94.47%\n5. AUC = 98.35%","0f684d96":"### Model Evaluation","c0c8a1b5":"#________________________________________________________END OF CODE________________________________________________________#","64b7118e":"#_All the variables are normally distributed","635e5d85":"#_Model optimized\n#_False Negatives Reduced","4c8b9d3e":"#### 1. RandomForest","12cf21c8":"#_Duplicatedd records removed","feff239d":"#_Main Focus = False Negative = 13\n#_Hence, checking Recall","0fd574d2":"#_The top 3 Model wrt Accuracy: Gaussian, RandomForest, DecisionTree \n#_Comparing these 3 with their f1-score and Precision","76784678":"#_Recall increased to 94.5%","ca136ef1":"#_False negatives increased\n#_Managing the threshold to reduce false negatives","0da03120":"#### 3. Decision Tree","37b3aaac":"#_There's No extreme fitting","4e8487fb":"## Balancing the Target \n### Undersampling","f7eb939a":"## Model Selection","08384c82":"#### 2. Extracting relevant Features","5c898cc8":"#_Time here is forever increasing since it is a cumulative frequency.","3de7ed6c":"#_Transactions with lower completion time (<10) have more frauds.","0c011644":"## Initial Model\n\n### Modeling \n\n#__init()__ = g\n\n#__fit___ = gfit\n\n#__predicted__ = gpred","899c517d":"#_Target Variable is Unbalanced","6209f0e7":"#### 2. Gaussian","151ddce2":"### Prepared Data","4f502967":"## Data Preparation\n\n### Data Cleaning\n\n#### 1. Outliers","5f475943":"#_There seems to be no specific transaction time span for any particular amount of transcation","ab202255":"## Loading the data","ca600757":"#_Since there are a lot of columns and certain outliers exists in each column...\n#_Considering Loacal Outliers","75883cd4":"## Final Prediction","b303f588":"## Hyper-param Tuning","14644b53":"## Train-Test Split","f9ac7aa4":"#_No null values\n#_All numeric values\n#_Independant variables type: Float","5afec72e":"## Understanding the Data","bda0fc86":"#### 3. Checking for duplicated records","2b68c9b3":"#_To find the pattern of frauds wrt time, need to find time per transaction.","8d020fb3":"#### 2. Standardization\n##### Amount","ec30cadf":"#_Hyperparam tuning aim: Reduce False -ve to improve Recall","3c719639":"#_Threshold = 0.02\n#_For extracting features, k set to 11","bb6dd6a9":"#_All frauds are done for lower amounts i.e. <1000","540c029a":"### Feature Selection\n\n#### 1. Feature Importance","bf4a8860":"# Credi Card Fraud Detection\n\n### Source: Kaggle\n          https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\n\n\n### Contents\n    1. Loading the data\n    2. Understanding the data\n    3. Data Preparation\n       A] Data Imputation\n       B] Feature Selection\n    4. Balancing the Target\n       A] Undersampling\n    5. Model Selection\n    6. Initial Model \n       A] Modeling\n       B] Model Evaluation\n    7. Hyperparameter Tuning\n    8. Final Prediction","1e5bfe39":"#_Selecting Model: GaussianNB()"}}