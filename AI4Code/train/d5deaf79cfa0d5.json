{"cell_type":{"bcb36645":"code","236dd593":"code","99ec0b23":"code","c5fe5e72":"code","89420e18":"code","226804fb":"code","b4848a6a":"code","0c8aa857":"code","df77ede3":"code","3d7fb6b7":"code","df5f8a14":"code","7fce7388":"code","bb9cf65e":"code","66498684":"code","07e6d69d":"code","846dec8d":"code","90aa3c6f":"code","a9c5ea70":"code","74f00a75":"code","74b6378d":"code","35754851":"code","a898d10e":"code","007dba72":"code","248829aa":"code","a592990d":"code","c8ed9dc8":"code","739bbe6c":"code","ba7304ee":"code","d49eee1b":"code","153b8f80":"code","43980dac":"code","9bdbf237":"code","9b7d32a7":"code","7d0a6f58":"code","2bf54091":"code","b808a5da":"code","da90500b":"code","700884d8":"code","d4eeed1e":"code","2401c295":"code","fabd320c":"code","270ef783":"code","30d2d28e":"code","e633dc0a":"code","43f20998":"code","e50896cf":"code","9a45b19f":"code","d36d2e02":"code","8f6eda6d":"code","b89c69e9":"code","882ae95f":"code","fae95a18":"code","9bf932b5":"code","6be0d212":"code","f05cc0b5":"code","13b12ca1":"code","2e464376":"code","f25f6037":"code","91bcee8c":"code","8b87541a":"code","1fb977db":"code","9a34417b":"code","87934a28":"code","421105b1":"code","c3679b37":"code","878bc251":"code","eb3d4304":"code","46de5430":"code","436db58e":"code","0306bc65":"code","d75960ed":"code","69b59165":"markdown","1ffed716":"markdown","0d4fe361":"markdown","19f558ae":"markdown","2c1839c8":"markdown","e9fc8e51":"markdown","bbf48232":"markdown","d72007ec":"markdown","9ba68eaa":"markdown","2bf2f68e":"markdown","c0ddd1bd":"markdown","b3c04ba9":"markdown","024bc6ec":"markdown","6d6f6a88":"markdown","0a599ec1":"markdown","c891930d":"markdown","1672a108":"markdown","8b06d1d3":"markdown","a28f647b":"markdown","9db473da":"markdown","e96afca6":"markdown","ca3fd97f":"markdown","a1a757f5":"markdown","63434089":"markdown","5acadecc":"markdown","c65c844b":"markdown","d0e8a749":"markdown","57c33fda":"markdown"},"source":{"bcb36645":"# Basic packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Statistics packages\nfrom scipy.stats import norm, skew\nfrom scipy.special import boxcox1p\nimport statsmodels.api as sm\n\n# sklearn packages for model creation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\nimport xgboost as xgb\nimport lightgbm as lgb","236dd593":"# Import train and test data from .csv\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntrain.shape","99ec0b23":"ids = test['Id']    # Submissions file requires an Id column\n\n# Drop Id column from train and test set\ntrain.drop(['Id'], inplace = True, axis = 1)\ntest.drop(['Id'], inplace = True, axis = 1)\n\ntrain.head(10)","c5fe5e72":"# Check for missing values in train data\n\nmissing_data = train.isna().sum()\nmissing_data = missing_data.drop(missing_data[missing_data == 0].index)\nmissing_data","89420e18":"# Check for missing values in test data\n\nmissing_test = test.isna().sum()\nmissing_test = missing_test.drop(missing_test[missing_test == 0].index)\nmissing_test","226804fb":"corr_matrix = train.corr()\nf, ax = plt.subplots(figsize = (12,9))\nsns.heatmap(corr_matrix, square = True)","b4848a6a":"sales_corr = corr_matrix['SalePrice'].sort_values(ascending = False)\nsales_corr.drop('SalePrice', axis = 0, inplace = True)\nsales_corr.head(10)","0c8aa857":"train.plot.scatter(x = 'OverallQual', y = 'SalePrice', alpha = 0.4, color = '#00cec9')","df77ede3":"train.plot.scatter(x = 'GarageCars', y = 'SalePrice', alpha = 0.3, color = '#f08700')","3d7fb6b7":"train.plot.scatter(x = 'GarageArea', y = 'SalePrice', alpha = 0.4, color = '#00cec9')","df5f8a14":"train.plot.scatter(x = 'TotalBsmtSF', y = 'SalePrice', alpha = 0.3, color = '#f08700')","7fce7388":"train.plot.scatter(x = '1stFlrSF', y = 'SalePrice', alpha = 0.4, color = '#00cec9')","bb9cf65e":"# Removal of outliers as stated in the Potential Pitfalls section, refer http:\/\/jse.amstat.org\/v19n3\/decock.pdf\n# Houses with GRLIVAREA > 4000 sq ft will be removed - 4 outliers\n\nsns.set_style('darkgrid')\nax = sns.scatterplot(x = train['GrLivArea'], y = train['SalePrice'])\n\ntrain = train[train['GrLivArea'] < 4000]","66498684":"# MSZoning - Replacing NaNs with the commonly occuring value (RL)\n\nsns.set_style('white')\nplt.subplots(figsize = (6, 5))\nsns.set_color_codes('muted')\nax = sns.barplot(x = train['MSZoning'].unique(), y = train.MSZoning.value_counts(), color = 'm', alpha = 0.8)\nax.set(xlabel = 'MSZoning Categories', ylabel = 'Count')\n\ntest.MSZoning = test.MSZoning.fillna('RL')","07e6d69d":"# LotFrontage \n# Houses in the same neighbourhood would probably have similar frontage areas; replace with median\n\ntrain['LotFrontage'] = train.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\ntest['LotFrontage'] = test.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))","846dec8d":"# Alley - Replacing NaNs with 'None'\n\ntrain['Alley'] = train['Alley'].fillna('None')\ntest[\"Alley\"] = test['Alley'].fillna('None')\nprint(train.Alley.isna().sum())\nprint(test.Alley.isna().sum())","90aa3c6f":"# Utilities \n# Dropping column since only 1 record in train set contains 'NoSeWa' with rest as 'AllPub'\n\nprint(train['Utilities'].value_counts())\ntrain.drop(columns = ['Utilities'], inplace = True)\ntest.drop(columns = ['Utilities'], inplace = True)","a9c5ea70":"# Exterior1st - Replacing with most common occurence\n\nprint(train.Exterior1st.mode())\ntest['Exterior1st'] = test.Exterior1st.fillna('VinylSd')\nprint(test.Exterior1st.isna().sum())","74f00a75":"# Exterior2nd - Replacing with most common occurence\n\nprint(train.Exterior2nd.mode())\ntest['Exterior2nd'] = test.Exterior2nd.fillna('VinylSd')\nprint(test.Exterior2nd.isna().sum())","74b6378d":"# MasVnrType - Replacing NaNs with 'None'\n\ntrain['MasVnrType'] = train.MasVnrType.fillna('None')\ntest['MasVnrType'] = test.MasVnrType.fillna('None')","35754851":"# MasVnrArea\n# NaN values in this column all have MasVnrType as None - Hence replacing NaN with 0.0\n\ntrain.MasVnrArea = train.MasVnrArea.fillna(0.0)\ntest.MasVnrArea = test.MasVnrArea.fillna(0.0)","a898d10e":"# BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2\n\ncolumns = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n\nfor col in columns:\n    train[col] = train[col].fillna(\"None\")\n    test[col] = test[col].fillna(\"None\")","007dba72":"# BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath\n\ncolumns = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\n\nfor col in columns:\n    test[col] = test[col].fillna(0)","248829aa":"# Electrical - Replace Nan With the commonly occuring value\n\nprint(train.Electrical.mode())\ntrain.Electrical = train.Electrical.fillna('SBrkr')","a592990d":"# KitchenQual - Replace Nan with commonly occuring value\n\nprint(train.KitchenQual.mode())\ntest.KitchenQual = test.KitchenQual.fillna('TA')","c8ed9dc8":"# Functional - Assuming typical 'Typ'\n\ntest.Functional = test.Functional.fillna('Typ')","739bbe6c":"# FireplaceQu - NaN means no Fireplace \"None\"\n\ntrain['FireplaceQu'] = train['FireplaceQu'].fillna('None')\ntest['FireplaceQu'] = test['FireplaceQu'].fillna('None')","ba7304ee":"# GarageType - NaN means no garage \"None\"\n\ntrain['GarageType'] = train['GarageType'].fillna('None')\ntest['GarageType'] = test['GarageType'].fillna('None')","d49eee1b":"# GarageYrBlt - NaN means no garage, keep year as 0\n\ntrain['GarageYrBlt'] = train['GarageYrBlt'].fillna(0)\ntest['GarageYrBlt'] = test['GarageYrBlt'].fillna(0)","153b8f80":"# GarageFinish - NaN means no garage \"None\"\n\ntrain['GarageFinish'] = train['GarageFinish'].fillna(\"None\")\ntest['GarageFinish'] = test['GarageFinish'].fillna(\"None\")","43980dac":"# GarageCars, GarageArea - NaN means no garage, replace with 0.0\n\ntest = test.fillna({'GarageCars':0.0, \"GarageArea\": 0.0})","9bdbf237":"# GarageQual, GarageCond - NaN means no garage \"None\"\n\nfor col in ['GarageQual','GarageCond']:\n    train[col] = train[col].fillna(\"None\")\n    test[col] = test[col].fillna(\"None\")","9b7d32a7":"# PoolQC, Fence - NaN means no Pool\/Fence, \"None\"\n\nfor col in ['PoolQC', 'Fence']:\n    train[col] = train[col].fillna(\"None\")\n    test[col] = test[col].fillna(\"None\")","7d0a6f58":"# MiscFeature\n\ntrain['MiscFeature'] = train['MiscFeature'].fillna('None')\ntest['MiscFeature'] = test['MiscFeature'].fillna('None')","2bf54091":"# SaleType\n\nprint(train['SaleType'].mode())\ntest['SaleType'].fillna('WD', inplace = True)","b808a5da":"# ExterQual, ExterCond, HeatingQC, KitchenQual\n\nexter_map = {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1}\nfor col in ['ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual']:\n    train[col] = train[col].map(exter_map).astype(int)\n    test[col] = test[col].map(exter_map).astype(int)","da90500b":"# BsmtQual, BsmtCond, FireplaceQu, PoolQC\n\nbsmt_map = {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"None\": 0}\n\nfor col in ['BsmtQual', 'BsmtCond', 'FireplaceQu', 'GarageCond', 'GarageQual', 'PoolQC']:\n    train[col] = train[col].map(bsmt_map).astype(int)\n    test[col] = test[col].map(bsmt_map).astype(int)","700884d8":"# BsmtExposure\n\nexp_map = {'Gd': 3, 'Av': 2, 'Mn': 1, 'No': 0, 'None': 0}\ntrain['BsmtExposure'] = train['BsmtExposure'].map(exp_map).astype(int)\ntest['BsmtExposure'] = test['BsmtExposure'].map(exp_map).astype(int)","d4eeed1e":"# BsmtFinType1, BsmtFinType2\n\nfintype_map = {'GLQ': 6, \"ALQ\": 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0}\nfor col in ['BsmtFinType1', 'BsmtFinType2']:\n    train[col] = train[col].map(fintype_map).astype(int)\n    test[col] = test[col].map(fintype_map).astype(int)","2401c295":"# CentralAir (Necessary...?)\n\nca_map = {'Y': 1, 'N': 0}\ntrain['CentralAir'] = train.CentralAir.map(ca_map)\ntest['CentralAir'] = test.CentralAir.map(ca_map)","fabd320c":"# PavedDrive\n\npd_map = {'Y': 2, 'P': 1, 'N': 0}\ntrain['PavedDrive'] = train.PavedDrive.map(pd_map)\ntest['PavedDrive'] = test.PavedDrive.map(pd_map)","270ef783":"# Fence\n\nfence_map = {'GdPrv': 2, 'MnPrv': 1, 'GdWo': 2, 'MnWw': 1, 'None': 0}\ntrain['Fence'] = train.Fence.map(fence_map)\ntest['Fence'] = test.Fence.map(fence_map)","30d2d28e":"# Street, Alley\n\nstreet_map = {'Grvl': 2, 'Pave': 1, 'None': 0}\nfor col in ['Street', 'Alley']:\n    train[col] = train[col].map(street_map)\n    test[col] = test[col].map(street_map)","e633dc0a":"# LotShape\n\nlot_map = {'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1}\ntrain['LotShape'] = train.LotShape.map(lot_map)\ntest['LotShape'] = test.LotShape.map(lot_map)","43f20998":"# LandSlope\n\nslope_map = {'Gtl': 3, 'Mod': 2, 'Sev': 1}\ntrain['LandSlope'] = train.LandSlope.map(slope_map)\ntest['LandSlope'] = test.LandSlope.map(slope_map)","e50896cf":"# MasVnrType\n\nmason_map = {'BrkCmn': 1, 'BrkFace': 1, 'CBlock': 1, 'Stone': 1, 'None': 0}\ntrain['MasVnrType'] = train.MasVnrType.map(mason_map)\ntest['MasVnrType'] = test.MasVnrType.map(mason_map)","9a45b19f":"# OverallQC - from OverallQual and OverallCond\n\ntrain['OverallQC'] = (train['OverallQual'] + train['OverallCond']) \/ 2\ntest['OverallQC'] = (test['OverallQual'] + test['OverallCond']) \/ 2\n\ntrain.drop(['OverallQual', 'OverallCond'], inplace = True, axis = 1)\ntest.drop(['OverallQual', 'OverallCond'], inplace = True, axis = 1)","d36d2e02":"# ExterQC - from ExterQual and ExterCond\n\ntrain['ExterQC'] = (train['ExterQual'] + train['ExterCond']) \/ 2\ntest['ExterQC'] = (test['ExterQual'] + test['ExterCond']) \/ 2\n\ntrain.drop(['ExterQual', 'ExterCond'], inplace = True, axis = 1)\ntest.drop(['ExterQual', 'ExterCond'], inplace = True, axis = 1)","8f6eda6d":"# GarageQC - from GarageQual and GarageCond\n\ntrain['GarageQC'] = (train['GarageQual'] + train['GarageCond']) \/ 2\ntest['GarageQC'] = (test['GarageQual'] + test['GarageCond']) \/ 2\n\ntrain.drop(['GarageQual', 'GarageCond'], inplace = True, axis = 1)\ntest.drop(['GarageQual', 'GarageCond'], inplace = True, axis = 1)","b89c69e9":"# BsmtQC - from BsmtQual, BsmtCond, BsmtExposure\n\ntrain['BsmtQC'] = (train['BsmtQual'] + train['BsmtCond'] + train['BsmtExposure']) \/ 3\ntest['BsmtQC'] = (test['BsmtQual'] + test['BsmtCond'] + test['BsmtExposure']) \/ 3\n\ntrain.drop(['BsmtQual', 'BsmtCond', 'BsmtExposure'], axis = 1, inplace = True)\ntest.drop(['BsmtQual', 'BsmtCond', 'BsmtExposure'], axis = 1, inplace = True)","882ae95f":"# TopFloorsArea - from 1stFlrSF, 2ndFlrSF\n# TotalSFArea - from GrLivArea, TotalBsmtSF\n\ntrain['TopFloorsArea'] = train['1stFlrSF'] + train['2ndFlrSF']  \ntrain['TotalSFArea'] = train['GrLivArea'] + train['TotalBsmtSF']\ntest['TopFloorsArea'] = test['1stFlrSF'] + test['2ndFlrSF']  \ntest['TotalSFArea'] = test['GrLivArea'] + test['TotalBsmtSF']\n\ntrain.drop(['1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotalBsmtSF'], inplace = True, axis = 1)\ntest.drop(['1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotalBsmtSF'], inplace = True, axis = 1)","fae95a18":"# TotBaths - Total number of bathrooms from BsmtFullBath, BsmtHalfBath, HalfBath, FullBath.\n\ntrain['TotBaths'] = train['BsmtFullBath'] + (0.5 * train['BsmtHalfBath']) + (0.5 * train['HalfBath']) + train['FullBath']\ntest['TotBaths'] = test['BsmtFullBath'] + (0.5 * test['BsmtHalfBath']) + (0.5 * test['HalfBath']) + test['FullBath']\n\ntrain.drop(['BsmtFullBath', 'BsmtHalfBath', 'HalfBath', 'FullBath'], inplace = True, axis = 1)\ntest.drop(['BsmtFullBath', 'BsmtHalfBath', 'HalfBath', 'FullBath'], inplace = True, axis = 1)","9bf932b5":"# TotPorchSF - Total Square feet area of the porch.\n\ntrain['TotPorchSF'] = train['OpenPorchSF'] + train['EnclosedPorch'] + train['3SsnPorch'] + train['ScreenPorch']\ntest['TotPorchSF'] = test['OpenPorchSF'] + test['EnclosedPorch'] + test['3SsnPorch'] + test['ScreenPorch']\n\ntrain.drop(['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'], inplace = True, axis = 1)\ntest.drop(['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'], inplace = True, axis = 1)","6be0d212":"# Dropping the GarageCars, GarageYrBuilt columns.\n\ntrain.drop(['GarageCars', 'GarageYrBlt'], inplace = True, axis = 1)\ntest.drop(['GarageCars', 'GarageYrBlt'], inplace = True, axis = 1)","f05cc0b5":"# Converting the categorical features to Pandas Categorical type.\n# This is done to distinguish them from the numerical features that are to be transformed.\n\ncolumns = ['MSSubClass', 'MSZoning', 'LandContour', 'LotConfig', \n           'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n           'HouseStyle', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n           'RoofMatl', 'Exterior1st', 'Exterior2nd', 'Foundation', \n           'Heating', 'Electrical', 'Functional', 'GarageType', \n           'GarageFinish', 'PavedDrive', 'MiscFeature', 'MoSold', \n           'YrSold', 'SaleType', 'SaleCondition']\n\nnum_train = train.shape[0]\nnum_test = test.shape[0]\n\ny_train = train['SalePrice'].values    # SalePrice \ntrain.drop(['SalePrice'], axis = 1, inplace = True)\n\nall_data = pd.concat([train, test], axis = 0).reset_index(drop = True)\n\nfor col in columns:\n    all_data[col] = pd.Categorical(all_data[col])","13b12ca1":"# Obtaining the column containing numerical features\n\nnum_features = all_data.dtypes[all_data.dtypes != 'category'].index\nprint(num_features)","2e464376":"# Skewness with magnitude 0.5 is considered to be moderate.\n# A skewness magnitude greater than 1 is considered as high.\n\nskewness = all_data[num_features].apply(lambda x: skew(x))\nskewness = skewness[abs(skewness) > 0.5]\nskewed_features = skewness.index","f25f6037":"all_data[skewed_features] = np.log1p(all_data[skewed_features])    ","91bcee8c":"# Using the get_dummies() method from pandas to obtain dummy variables.\n\nfor col in columns:\n    all_data = pd.concat([all_data, pd.get_dummies(all_data[col], prefix = col, drop_first = True)], axis = 1)\n\n# Drop original columns\n\nall_data.drop(columns, inplace = True, axis = 1)\nprint(all_data.shape)\nall_data.head(5)","8b87541a":"X_train = all_data[:num_train]\nX_test = all_data[num_train:]","1fb977db":"scaler = StandardScaler()\nX_train.loc[:, num_features] = scaler.fit_transform(X_train.loc[:, num_features])\nX_test.loc[:, num_features] = scaler.transform(X_test.loc[:, num_features])","9a34417b":"ax = sns.distplot(y_train, fit = norm)\nax.set_title('SalePrice distribution')\nprint(\"Skewness: \", skew(y_train))","87934a28":"sm.qqplot(y_train, line = 's')\nplt.title('QQ Plot')\nplt.show()","421105b1":"y_train = np.log1p(y_train)","c3679b37":"# Plotting the distribution and QQ plot\n\nax = sns.distplot(y_train, fit = norm)\nax.set_title('SalePrice distribution')\n\nsm.qqplot(y_train, line = 's')\nplt.title('After log1p transformation')\nplt.show()","878bc251":"rmse_scorer = make_scorer(mean_squared_error, greater_is_better = False)\n\ndef rmse_cv(model):\n    rmse = np.sqrt(-cross_val_score(model, X_train, y_train, scoring = rmse_scorer, cv = 10))\n    return (rmse)","eb3d4304":"ridge = RidgeCV(alphas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1.0, 3, 6, 10, 30, 60])\nridge.fit(X_train, y_train)\n\nalpha = ridge.alpha_\nprint(\"Estimated alpha value: \",alpha)\n\n# Phase 2 - Ridge\n\nridge = RidgeCV(alphas = [alpha * 0.5, alpha * 0.6, alpha * 0.7, alpha * 0.8, alpha * 0.9, alpha * 1,\n                         alpha * 1.1, alpha * 1.2, alpha * 1.3, alpha * 1.4, alpha * 1.5])\nridge.fit(X_train, y_train)\nalpha = ridge.alpha_\nprint(\"Estimated alpha value (Phase 2):\", alpha)\nprint()\nscore = rmse_cv(ridge)\nprint(\"Mean Ridge Score:\", score.mean())\nprint(\"Std. Deviation:\", score.std())","46de5430":"lasso = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, \n                          0.01, 0.06, 0.1, 0.3, 0.6, 1], random_state = 0, cv = 10, max_iter = 50000)\nlasso.fit(X_train, y_train)\n\nalpha = lasso.alpha_\nprint(\"Estimated alpha value: \", alpha)\n\n# Phase 2 - Lasso\n\nlasso = LassoCV(alphas = [alpha * 0.5, alpha * 0.6, alpha * 0.7, alpha * 0.8, alpha * 0.9, alpha * 1,\n                         alpha * 1.1, alpha * 1.2, alpha * 1.3, alpha * 1.4, alpha * 1.5], random_state = 0, \n                         max_iter = 50000, cv = 10)\nlasso.fit(X_train, y_train)\nalpha = lasso.alpha_\nprint(\"Estimated alpha value (Phase 2):\", alpha)\nprint()\nscore = rmse_cv(lasso)\nprint(\"Mean Lasso Score:\", score.mean())\nprint(\"Std. Deviation:\", score.std())","436db58e":"enet = ElasticNetCV(l1_ratio = [0.1, 0.15, 0.3, 0.55, 0.7, 0.95, 1],\n                         alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, \n                                   0.006, 0.1, 0.3, 0.6, 0.9, 1, 3, 6, 12],\n                   max_iter = 50000, cv = 10)\nenet.fit(X_train, y_train)\nratio = enet.l1_ratio_\nalpha = enet.alpha_\nprint(\"Best l1 ratio:\", ratio)\nprint(\"Best alpha:\", alpha)\n\n# Phase 2 - ElasticNet\n\nenet = ElasticNetCV(l1_ratio = ratio,\n                   alphas = [alpha * 0.5, alpha * 0.6, alpha * 0.7, alpha * 0.8, alpha * 0.9, alpha * 1,\n                         alpha * 1.1, alpha * 1.2, alpha * 1.3, alpha * 1.4, alpha * 1.5], random_state = 0, \n                         max_iter = 50000, cv = 10)\nenet.fit(X_train, y_train)\nratio = enet.l1_ratio_\nalpha = enet.alpha_\nprint(\"Best l1 ratio (Phase 2):\", ratio)\nprint(\"Best alpha (Phase 2):\", alpha)\nprint()\nscore = rmse_cv(enet)\nprint(\"Mean ElasticNet score:\", score.mean())\nprint(\"Std. Deviation:\", score.std())","0306bc65":"y_pred = np.expm1(enet.predict(X_test))\ny_pred ","d75960ed":"# Creating the submissions .csv file\n\nsubmissions = pd.DataFrame({\n    \n    'Id': ids,\n    'SalePrice': y_pred\n})\n\nsubmissions.to_csv('submissions.csv', index = False)","69b59165":"#### Performing log(1+x) transformation on highly skewed features","1ffed716":"The GarageCars and GarageYrBlt columns are dropped, as explained in the observations part of the feature correlation.","0d4fe361":"#### Obtain the QQ Plot ","19f558ae":"#### Lasso Regression","2c1839c8":"#### Ridge Regression","e9fc8e51":"#### Plotting  OverallQual and SalePrice","bbf48232":"## Representing some categories with ordered numbers","d72007ec":"## Target variable: SalePrice","9ba68eaa":"#### Checking the skewness levels","2bf2f68e":"Log transformation works fine on both positively and negatively skewed data, another good transformation that can also be applied is the BoxCox transform.","c0ddd1bd":"## Tranforming highly skewed features","b3c04ba9":"All the preprocessing steps have been successfully completed, now getting ready to obtain the initial split of the X_train and X_test data below.","024bc6ec":"## Model Building ","6d6f6a88":"## Outliers","0a599ec1":"## Feature scaling","c891930d":"#### Fixing the skew with log transformation","1672a108":"#### Observations:\n\n1. SalePrice is highly correlated with Overall Condition.\n2. Area related features like TotalBsmtSF, !stFlrSF, GrLivArea, GarageCars, GarageArea have high impact on SalePrice.\n3. GarageCars and GarageArea are highly correlated; greater the area, more the capacity.\n4. GarageYrBuilt and YearBuilt, this could be because they were mostly built in the same year.\n5. GrLivArea and TotRmsAbvGrd happen to be highly correlated too.","8b06d1d3":"#### ElasticNet Regression","a28f647b":"This notebook is my attempt at applying the regression techniques I learnt by looking through popular kernels.\n\n**References**\n\nhttps:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard - Box Cox transformations and model stacking.\nhttps:\/\/www.kaggle.com\/juliencs\/a-study-on-regression-applied-to-the-ames-dataset - Feature Engineering and advanced Regression techniques.","9db473da":"## Features correlated with SalePrice","e96afca6":"#### Checking the skewness of the target variable","ca3fd97f":"## Correlation of features","a1a757f5":"The below plot shows that the distribution is right skewed or positively skewed.","63434089":"#### Seperating the numerical features from the categorical ones","5acadecc":"The right skew is fixed after log transformation of the target variable with numpy's log1p() function which is basically log(1+x). Log(1+x) is preferred because of the evaluation metric - it is the same as rmse with weights.\nAnd also logarithm of 0 is undefined, so using np.log() could screw things.","c65c844b":"## Dealing with missing data","d0e8a749":"## Creating new features through modification of existing ones","57c33fda":"## One hot encoding categorical features"}}