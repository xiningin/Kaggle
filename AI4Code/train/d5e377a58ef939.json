{"cell_type":{"2d91d2a1":"code","d71ccb69":"code","c57865bd":"code","943ff873":"code","0f4f3f57":"code","97b4d407":"code","65af38f0":"code","c7cff1c7":"code","c08d66e4":"code","d06cd72d":"code","882f59a5":"code","c7116d99":"code","6beb866d":"code","4dacb90f":"code","e7159b19":"code","16973854":"code","8cfd01b6":"code","0f78e363":"code","404ba684":"code","e472b4e4":"code","96647b16":"code","2da4780a":"code","da10d95d":"code","c0dd65f3":"code","771260e5":"code","eb62ff37":"code","03b65f57":"code","08e9632c":"code","17039901":"code","3451a39b":"code","5a25f8ef":"code","3229dd35":"code","ed4513eb":"code","f451a6e9":"code","d62ccf69":"code","c2a3cd22":"code","6f8e5b4a":"code","43a75829":"code","18432934":"code","8c3c84e4":"code","b1649a5f":"code","9d4c0ab8":"code","86270c5c":"code","258530a5":"markdown","b79cefce":"markdown","359b28d5":"markdown","d489bdbb":"markdown","cf7b4328":"markdown","45cda191":"markdown","dedc5aa2":"markdown","52f0f11e":"markdown","fae45d4e":"markdown","f4aceb19":"markdown","93d4073b":"markdown","9cab4132":"markdown"},"source":{"2d91d2a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d71ccb69":"fn = '\/kaggle\/input\/cancer-cell-line-encyclopedia\/ccle.txt\/CCLE.txt'\n# '..\/input\/ccle.txt\/CCLE.txt'\ndf = pd.read_csv(fn, index_col=0)\ndf\n","c57865bd":"#print( type(df.columns[0]))# ,df.columns[0] )\ncell_lines_information = list(df.columns)  # Save full information \n\n# Extract from long information in columns titles just short-standard cell lines names and save them \ncell_lines_names = []\nfor i in range(df.shape[1]):\n    nm = df.columns[i].split(',')[0].split(' ')[2].replace(\"'\", '')\n    cell_lines_names.append(nm)\nprint(len(cell_lines_names), 'First 20 names: ',  cell_lines_names[:20])\n\n\ndf.columns = cell_lines_names\ndf.head(2)","943ff873":"# Extract from long information in columns titles just short-standard cell lines names and save them \ncell_lines_tissues = []\nfor i in range(df.shape[1]):\n    nm = cell_lines_information[i].split(',')[1].split(' ')[2].replace(\"'\", '')\n    cell_lines_tissues.append(nm)\nprint(len(cell_lines_tissues), 'First 20 tissues: ',  cell_lines_tissues[:20])\ns =pd.Series(cell_lines_tissues) \nprint( s.nunique() )\nv = s.value_counts()\nprint(v)\n\n# Truncated tissuse list\nl = list(v[15:].index)\ns2 = s.copy()\ns2[s2.isin(l)] ='other'\ns2.value_counts().shape\ncell_lines_tissues_top_truncated = list(s2.values)\n","0f4f3f57":"cell_lines_gender = []\nfor i in range(df.shape[1]):\n    nm = cell_lines_information[i].split(',')[4].split(' ')[2].replace(\"')\", '')\n    cell_lines_gender.append(nm)\nprint(len(cell_lines_gender), 'First 20 tissues: ',  cell_lines_gender[:20])\ns =pd.Series(cell_lines_gender) \nprint( s.nunique() )\nv = s.value_counts()\nprint(v)","97b4d407":"import matplotlib.pyplot as plt\nimport seaborn  as sns\nfrom sklearn.decomposition import TruncatedSVD # for sparse \nfrom sklearn.decomposition import PCA\nimport time\n\nX = df.values.T\n\nt0 = time.time()\n# svd = TruncatedSVD( n_components=2, n_iter=7, random_state=42)\nreducer1 = PCA()# n_components=2)\nr = reducer1.fit_transform(X)\nprint(time.time() - t0, 'seconds passed')\n\nt0 = time.time()\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues, style =cell_lines_tissues , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('PCA. Visualize cell lines. Color by tissue')#  +str( count_made_zeros ) )\nplt.show()\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","65af38f0":"\nt0 = time.time()\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues_top_truncated , style = cell_lines_gender , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('PCA. Visualize cell lines. Color by tisse. Top tissues and \"other\" group ')#  +str( count_made_zeros ) )\nplt.show()\n\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","c7cff1c7":"\n\nt0 = time.time()\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('PCA. Visualize cell lines. Color by tisse. Top tissues and \"other\" group ')#  +str( count_made_zeros ) )\nplt.show()\n\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","c08d66e4":"v = (reducer1.singular_values_)# plt.title('explained_variance_ratio_') )\n\nfig = plt.figure(figsize = (20,5))\nplt.plot(v,'*-')\nplt.title('singular values')\nplt.show()\nfig = plt.figure(figsize = (20,5))\nplt.plot(v[:200],'*-')\nplt.title('singular values - top 200')\nplt.show()\n\nv=reducer1.explained_variance_ratio_\nfig = plt.figure(figsize = (20,5))\nplt.plot(v,'*-')\nplt.title('explained_variance_ratio_')\nplt.show()\n","d06cd72d":"import matplotlib.pyplot as plt\nimport seaborn  as sns\nfrom sklearn.decomposition import TruncatedSVD # for sparse \nfrom sklearn.decomposition import PCA\nimport umap\nimport time\n\nX = df.values.T\n\nt0 = time.time()\n# svd = TruncatedSVD( n_components=2, n_iter=7, random_state=42)\nreducer1 = PCA()# n_components=2)\nr = reducer1.fit_transform(X)\nprint(time.time() - t0, 'seconds passed')\nreducer2 = umap.UMAP()\nr = reducer2.fit_transform(r[:,:50])\nprint(time.time() - t0, 'seconds passed')\n\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('UMAP (after PCA to 50). Visualize cell lines. Color by tisse. Top tissues and \"other\" group ')#  +str( count_made_zeros ) )\nplt.show()\n\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","882f59a5":"# another analogue of umap which claimed to work a little faster , sometimes produces a little better pictures\n# From SkolTech team \n\n!pip install ncvis\nimport ncvis\n\nvis = ncvis.NCVis()\n#Y = vis.fit_transform(X)","c7116d99":"import matplotlib.pyplot as plt\nimport seaborn  as sns\nfrom sklearn.decomposition import TruncatedSVD # for sparse \nfrom sklearn.decomposition import PCA\nimport time\n\nX = df.values.T\n\nt0 = time.time()\n# svd = TruncatedSVD( n_components=2, n_iter=7, random_state=42)\nreducer1 = PCA()# n_components=2)\nr = reducer1.fit_transform(X)\nprint(time.time() - t0, 'seconds passed')\nreducer2 =  ncvis.NCVis() # umap.UMAP()\nr = reducer2.fit_transform(r[:,:50])\nprint(time.time() - t0, 'seconds passed')\n\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('NCVis (after PCA to 50). Visualize cell lines. Color by tisse. Top tissues and \"other\" group ')#  +str( count_made_zeros ) )\nplt.show()\n\n\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","6beb866d":"!pip install trimap \nimport trimap","4dacb90f":"import matplotlib.pyplot as plt\nimport seaborn  as sns\nfrom sklearn.decomposition import TruncatedSVD # for sparse \nfrom sklearn.decomposition import PCA\nimport time\n\nX = df.values.T\n\nt0 = time.time()\n# svd = TruncatedSVD( n_components=2, n_iter=7, random_state=42)\nreducer1 = PCA()# n_components=2)\nr = reducer1.fit_transform(X)\nprint(time.time() - t0, 'seconds passed')\nreducer2 = trimap.TRIMAP() #  ncvis.NCVis() # umap.UMAP()\nr = reducer2.fit_transform(r[:,:50])\nprint(time.time() - t0, 'seconds passed')\n\n\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('TRIMAP (after PCA to 50). Visualize cell lines. Color by tisse. Top tissues and \"other\" group ')#  +str( count_made_zeros ) )\nplt.show()\n\n\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","e7159b19":"\n\nX = df.values.T\n\n# To speed-up reduce dimensions by PCA first\nX_save = X.copy( )\n#r = pca.fit_transform(X)\n#X = r[:1000,:20]\n\n\n\nimport umap \nfrom sklearn import manifold\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import FactorAnalysis\nfrom sklearn.decomposition import NMF\nfrom sklearn.decomposition import FastICA\nfrom sklearn.decomposition import FactorAnalysis\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.ensemble import RandomTreesEmbedding\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import TruncatedSVD\n\n\nfrom collections import OrderedDict\nfrom functools import partial\nfrom matplotlib.ticker import NullFormatter\n\n\nn_neighbors = 10\nn_components = 2\n# Set-up manifold methods\nLLE = partial(manifold.LocallyLinearEmbedding,\n              n_neighbors, n_components, eigen_solver='auto')\n\nmethods = OrderedDict()\nmethods['PCA'] = PCA()\nmethods['umap'] = umap.UMAP(n_components = n_components)\nmethods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\nmethods['ICA'] = FastICA(n_components=n_components,         random_state=0)\nmethods['FA'] = FactorAnalysis(n_components=n_components, random_state=0)\nmethods['LLE'] = LLE(method='standard')\nmethods['Modified LLE'] = LLE(method='modified')\nmethods['Isomap'] = manifold.Isomap(n_neighbors, n_components)\nmethods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=1)\nmethods['SE'] = manifold.SpectralEmbedding(n_components=n_components,\n                                           n_neighbors=n_neighbors)\nmethods['NMF'] = NMF(n_components=n_components,  init='random', random_state=0) \nmethods['RandProj'] = SparseRandomProjection(n_components=n_components, random_state=42)\n\nrand_trees_embed = make_pipeline(RandomTreesEmbedding(n_estimators=200, random_state=0, max_depth=5), TruncatedSVD(n_components=n_components) )\nmethods['RandTrees'] = rand_trees_embed\nmethods['LatDirAll'] = LatentDirichletAllocation(n_components=n_components,  random_state=0)\nmethods['LTSA'] = LLE(method='ltsa') \nmethods['Hessian LLE'] = LLE(method='hessian') \n\nlist_fast_methods = ['PCA','umap','FA', 'ICA','NMF','RandProj','RandTrees']\nlist_slow_methods = ['t-SNE','LLE','Modified LLE','Isomap','MDS','SE','LatDirAll','LTSA','Hessian LLE']\n\n# transformer = NeighborhoodComponentsAnalysis(init='random',  n_components=2, random_state=0) # Cannot be applied since supervised - requires y \n# methods['LinDisA'] = LinearDiscriminantAnalysis(n_components=n_components)# Cannot be applied since supervised - requires y \n\n\n# Create figure\nfig = plt.figure(figsize=(25, 16))\n\n# Plot results\nc = 0\nfor i, (label, method) in enumerate(methods.items()):\n    if label not in  list_fast_methods :\n        continue\n        \n    t0 = time.time()\n    try:\n        r = method.fit_transform(X.copy())\n    except:\n        print('Got Exception', label )\n        continue \n    t1 = time.time()\n    print(\"%s: %.2g sec\" % (label, t1 - t0))\n    \n    if 0:\n        c+=1\n        fig.add_subplot(2, 3 , c) \n        sns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\n        plt.title(label )\n        plt.legend('')\n\n    else:\n        plt.figure(figsize = (20,12))\n        sns.scatterplot(x=r[:,0],y=r[:,1] , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\n        plt.title(label)# \n        plt.show()\n","16973854":"v = df.mean(axis = 0)\nplt.figure(figsize = (20,4))\n\nplt.plot(v.values)\nplt.title(' Mean expression for cells ') # '\nplt.xlabel('cells')\nplt.grid()\nplt.show()\n\nplt.figure(figsize = (20,4))\nplt.plot(np.sort( v.values) ,'*-')\nplt.title(' Mean expression for cells ') # '\nplt.xlabel('ordered cells')\nplt.grid()\nplt.show()\n\nplt.figure(figsize = (20,4))\nplt.hist(v,bins = 50) #plot(np.sort( v.values) )\nplt.title(' Mean expression for cells ') # '\n#plt.xlabel('ordered genes')\nplt.grid()\nplt.show()\n\nv = df.mean(axis = 1)\nplt.figure(figsize = (20,4))\n\nplt.plot(v.values)\nplt.title(' Mean expression for genes ') # '\nplt.xlabel('genes')\nplt.grid()\nplt.show()\n\nplt.figure(figsize = (20,4))\nplt.plot(np.sort( v.values) , '*-')\nplt.title(' Mean expression for genes ') # '\nplt.xlabel('ordered genes')\nplt.grid()\nplt.show()\n\nplt.figure(figsize = (20,4))\nplt.hist(v,bins = 50) #plot(np.sort( v.values) )\nplt.title(' Mean expression for genes ') # '\n#plt.xlabel('ordered genes')\nplt.grid()\nplt.show()\n","8cfd01b6":"v = df.mean(axis = 1)\nv.sort_values(ascending = False).head(40)","0f78e363":"v.sort_values(ascending = False).tail(20)","404ba684":"\n\nX = df.values\n\n# To speed-up reduce dimensions by PCA first\nX_save = X.copy( )\n#r = pca.fit_transform(X)\n#X = r[:1000,:20]\n\n\n\nimport umap \nfrom sklearn import manifold\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import FactorAnalysis\nfrom sklearn.decomposition import NMF\nfrom sklearn.decomposition import FastICA\nfrom sklearn.decomposition import FactorAnalysis\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.ensemble import RandomTreesEmbedding\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import TruncatedSVD\n\n\nfrom collections import OrderedDict\nfrom functools import partial\nfrom matplotlib.ticker import NullFormatter\n\n\nn_neighbors = 10\nn_components = 2\n# Set-up manifold methods\nLLE = partial(manifold.LocallyLinearEmbedding,\n              n_neighbors, n_components, eigen_solver='auto')\n\nmethods = OrderedDict()\nmethods['PCA'] = PCA()\nmethods['umap'] = umap.UMAP(n_components = n_components)\nmethods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\nmethods['ICA'] = FastICA(n_components=n_components,         random_state=0)\nmethods['FA'] = FactorAnalysis(n_components=n_components, random_state=0)\nmethods['LLE'] = LLE(method='standard')\nmethods['Modified LLE'] = LLE(method='modified')\nmethods['Isomap'] = manifold.Isomap(n_neighbors, n_components)\nmethods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=1)\nmethods['SE'] = manifold.SpectralEmbedding(n_components=n_components,\n                                           n_neighbors=n_neighbors)\nmethods['NMF'] = NMF(n_components=n_components,  init='random', random_state=0) \nmethods['RandProj'] = SparseRandomProjection(n_components=n_components, random_state=42)\n\nrand_trees_embed = make_pipeline(RandomTreesEmbedding(n_estimators=200, random_state=0, max_depth=5), TruncatedSVD(n_components=n_components) )\nmethods['RandTrees'] = rand_trees_embed\nmethods['LatDirAll'] = LatentDirichletAllocation(n_components=n_components,  random_state=0)\nmethods['LTSA'] = LLE(method='ltsa') \nmethods['Hessian LLE'] = LLE(method='hessian') \n\nlist_fast_methods = ['PCA','umap','FA', 'ICA','NMF','RandProj','RandTrees']\nlist_slow_methods = ['t-SNE','LLE','Modified LLE','Isomap','MDS','SE','LatDirAll','LTSA','Hessian LLE']\n\n# transformer = NeighborhoodComponentsAnalysis(init='random',  n_components=2, random_state=0) # Cannot be applied since supervised - requires y \n# methods['LinDisA'] = LinearDiscriminantAnalysis(n_components=n_components)# Cannot be applied since supervised - requires y \n\n\n# Create figure\nfig = plt.figure(figsize=(25, 16))\n\n# Plot results\nc = 0\nfor i, (label, method) in enumerate(methods.items()):\n    if label not in  list_fast_methods :\n        continue\n        \n    t0 = time.time()\n    try:\n        r = method.fit_transform(X.copy())\n    except:\n        print('Got Exception', label )\n        continue \n    t1 = time.time()\n    print(\"%s: %.2g sec\" % (label, t1 - t0))\n    \n    if 0:\n        c+=1\n        fig.add_subplot(2, 3 , c) \n        sns.scatterplot(x=r[:,0],y=r[:,1])# , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\n        plt.title(label )\n        plt.legend('')\n\n    else:\n        plt.figure(figsize = (20,12))\n        sns.scatterplot(x=r[:,0],y=r[:,1] )# , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\n        plt.title(label)# \n        plt.show()\n","e472b4e4":"import matplotlib.pyplot as plt\nimport seaborn  as sns\nfrom sklearn.decomposition import TruncatedSVD # for sparse \nfrom sklearn.decomposition import PCA\nimport time\n\nX = df.values\n\nt0 = time.time()\n# svd = TruncatedSVD( n_components=2, n_iter=7, random_state=42)\nreducer1 = PCA()# n_components=2)\nr = reducer1.fit_transform(X)\nprint(time.time() - t0, 'seconds passed')\nreducer2 =  ncvis.NCVis() # umap.UMAP()\nr = reducer2.fit_transform(r[:,:50])\nprint(time.time() - t0, 'seconds passed')\n\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] )# , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('NCVis (after PCA to 50). Visualize genes')#  +str( count_made_zeros ) )\nplt.show()\n\n\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","96647b16":"import matplotlib.pyplot as plt\nimport seaborn  as sns\nfrom sklearn.decomposition import TruncatedSVD # for sparse \nfrom sklearn.decomposition import PCA\nimport time\n\nX = df.values\n\nt0 = time.time()\n# svd = TruncatedSVD( n_components=2, n_iter=7, random_state=42)\nreducer1 = PCA()# n_components=2)\nr = reducer1.fit_transform(X)\nprint(time.time() - t0, 'seconds passed')\nreducer2 = trimap.TRIMAP() #  ncvis.NCVis() # umap.UMAP()\nr = reducer2.fit_transform(r[:,:50])\nprint(time.time() - t0, 'seconds passed')\n\n\nplt.figure(figsize = (20,12))\nsns.scatterplot(x=r[:,0],y=r[:,1] )# , hue= cell_lines_tissues_top_truncated, style =cell_lines_tissues_top_truncated , s = 250 )# df['drug'] ,  style=df['dose'])\nplt.title('TRIMAP (after PCA to 50). Visualize genes')# ' cell lines. Color by tisse. Top tissues and \"other\" group ')#  +str( count_made_zeros ) )\nplt.show()\n\n\nprint('Finished.', time.time() - t0, 'seconds passed total ') ","2da4780a":"\nimport time\n\nt0 = time.time()\n\nX = df.values.T\nprint(X.shape)\ncm = np.corrcoef(X.T)\n\nprint(time.time() - t0, ' seconds passed ')\n\nprint('Calculated correlation matrix of shape:' , cm.shape )\nv = cm.ravel()\nprint('std',np.std(v),'mean', np.mean(v),'min', np.min(v))","da10d95d":"print('std',np.std(v),'mean', np.mean(v),'min', np.min(v))","c0dd65f3":"import matplotlib.pyplot as plt \nimport time\nt0 = time.time()\nplt.figure(figsize = (20,6))\nplt.hist(v, bins = 100)\nplt.title('Genes pairwise correlations. Count: '+str(len(v)))\nplt.show()\nprint(time.time()-t0,'seconds passed')\n\nif 0: # Cause out of memory\n    plt.plot(np.sort(v) )\n    plt.show()","771260e5":"import seaborn as sns\nt0 = time.time()\nplt.figure(figsize=(10,6));\nsns.heatmap(cm[:10000,:10000])\nplt.show()\nprint(time.time()-t0,'seconds passed')","eb62ff37":"#clustermap\nt0 = time.time()\nsns.clustermap(cm[:1000,:1000],cmap='vlag');\nplt.title('1000 genes correlations clustered ')\nplt.show()\nprint(time.time()-t0,'seconds passed')","03b65f57":"#clustermap\nt0 = time.time()\nsns.clustermap(cm[:3000,:3000],cmap='vlag');\nplt.title('3000 genes correlations clustered ')\nplt.show()\nprint(time.time()-t0,'seconds passed')","08e9632c":"#clustermap\nt0 = time.time()\nsns.clustermap(cm[:6000,:6000],cmap='vlag');\nplt.title('6000 genes correlations clustered ')\nplt.show()\nprint(time.time()-t0,'seconds passed')","17039901":"a,b = np.where(cm < -0.80)\nprint(  len(a) )\n\ngenes_names = list(df.index)\nst = pd.DataFrame()\ntemp_list = []\nfor i in range(len(a)):\n    tmp_hash1 = str(a[i])+'_'+str(b[i])\n    tmp_hash2 = str(b[i])+'_'+str(a[i])\n    if (tmp_hash1 in temp_list) or (tmp_hash2 in temp_list): continue\n    temp_list.append(tmp_hash1)\n    st.loc[i,'Gene1'] = genes_names[a[i]]\n    st.loc[i,'Gene2'] = genes_names[b[i]]\n    st.loc[i,'Correlation'] = cm[ a[i], b[i] ]\n    st.loc[i,'Abs Correlation'] = np.abs( cm[ a[i], b[i] ] )\n    \nprint('top anti-correlated genes')\nst.sort_values('Abs Correlation', ascending = False )\n","3451a39b":"flag_use_mygene = 1\nif flag_use_mygene:\n    !pip install mygene\n    import mygene\n    mg = mygene.MyGeneInfo()\n    \n# Normal result:\n# {'took': 1, 'total': 1, 'max_score': 123.64143, 'hits': [{'_id': '100169890', '_score': 123.64143, 'entrezgene': '100169890', 'name': 'PEG3 antisense RNA 1', 'symbol': 'PEG3-AS1', 'taxid': 9606}]}\n\nq= mg.query('symbol:ABRACADABRA', species='human')\n# Abnormal result - nothing found\n# {'took': 1, 'total': 0, 'max_score': None, 'hits': []}\nq\n\n    ","5a25f8ef":"for i in range(len(st)):\n    IX = st.index[i]\n    g = st['Gene1'].iat[i]\n    q= mg.query('symbol:'+g, species='human')\n    if len(q['hits']) > 0:\n        d = q['hits'][0]\n        st.loc[IX,'Name1'] = d['name']\n        e = d.get( 'entrezgene','')\n        if e != '':\n            inf = mg.getgene(e)\n            st.loc[IX,'N publications1'] = len(inf.get( 'generif', [] ) )\n            st.loc[IX,'type of gene1'] = (inf.get( 'type_of_gene', '' ) )\n            st.loc[IX,'summary1'] = (inf.get( 'summary', '' ) )\n    #print(q)\n    g = st['Gene2'].iat[i]\n    q= mg.query('symbol:'+g, species='human')\n    if len(q['hits']) > 0:\n        d = q['hits'][0]\n        st.loc[IX,'Name2'] = d['name']\n        e = d.get( 'entrezgene','')\n        if e != '':\n            inf = mg.getgene(e)\n            st.loc[IX,'N publications2'] = len(inf.get( 'generif', [] ) )\n            st.loc[IX,'type of gene2'] = (inf.get( 'type_of_gene', '' ) )\n            st.loc[IX,'summary2'] = (inf.get( 'summary', '' ) )\n         \n\n\n    #break\n    \n#st.head(1)\nst.sort_values('Abs Correlation', ascending = False )\n","3229dd35":"genes_names = list(df.index)\n\na,b = np.where(cm > 0.90)\nprint(  len(a)- len(genes_names) )\n\nst = pd.DataFrame()\ntemp_list = []\nfor i in range(len(a)):\n    if a[i] == b[i]: continue\n    tmp_hash1 = str(a[i])+'_'+str(b[i])\n    tmp_hash2 = str(b[i])+'_'+str(a[i])\n    if (tmp_hash1 in temp_list) or (tmp_hash2 in temp_list): continue\n    temp_list.append(tmp_hash1)\n    st.loc[i,'Gene1'] = genes_names[a[i]]\n    st.loc[i,'Gene2'] = genes_names[b[i]]\n    st.loc[i,'Correlation'] = cm[ a[i], b[i] ]\n    st.loc[i,'Abs Correlation'] = np.abs( cm[ a[i], b[i] ] )\n    \nprint('top correlated genes')\nprint(st.shape)\nst.sort_values('Abs Correlation', ascending = False )\n","ed4513eb":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","f451a6e9":"pd.set_option('max_colwidth',80)","d62ccf69":"for i in range(len(st)):\n    IX = st.index[i]\n    g = st['Gene1'].iat[i]\n    q= mg.query('symbol:'+g, species='human')\n    if len(q['hits']) > 0:\n        d = q['hits'][0]\n        st.loc[IX,'Name1'] = d['name']\n        e = d.get( 'entrezgene','')\n        if e != '':\n            inf = mg.getgene(e)\n            st.loc[IX,'N publications1'] = len(inf.get( 'generif', [] ) )\n            st.loc[IX,'type of gene1'] = (inf.get( 'type_of_gene', '' ) )\n            st.loc[IX,'summary1'] = (inf.get( 'summary', '' ) )\n    #print(q)\n    g = st['Gene2'].iat[i]\n    q= mg.query('symbol:'+g, species='human')\n    if len(q['hits']) > 0:\n        d = q['hits'][0]\n        st.loc[IX,'Name2'] = d['name']\n        e = d.get( 'entrezgene','')\n        if e != '':\n            inf = mg.getgene(e)\n            st.loc[IX,'N publications2'] = len(inf.get( 'generif', [] ) )\n            st.loc[IX,'type of gene2'] = (inf.get( 'type_of_gene', '' ) )\n            st.loc[IX,'summary2'] = (inf.get( 'summary', '' ) )\n         \n\n\n    #break\n    \n#st.head(1)\nst.sort_values('Abs Correlation', ascending = False )\n","c2a3cd22":"st['summary1'].iat[0]","6f8e5b4a":"st['summary2'].iat[0]","43a75829":"\nimport time\n\nt0 = time.time()\n\nX = df.values\nprint(X.shape)\ncm = np.corrcoef(X.T)\n\nprint(time.time() - t0, ' seconds passed ')\n\nprint('Calculated correlation matrix of shape:' , cm.shape )\nv = cm.ravel()\nprint('std',np.std(v),'mean', np.mean(v),'min', np.min(v))\n\n\nimport matplotlib.pyplot as plt \nimport time\nt0 = time.time()\nplt.figure(figsize = (20,6))\nplt.hist(v, bins = 100)\nplt.title('Cell pairwise correlations. Count: '+str(len(v)))\nplt.show()\nprint(time.time()-t0,'seconds passed')\n\n","18432934":"#clustermap\nimport seaborn as sns\nt0 = time.time()\nsns.clustermap(cm,cmap='vlag');\nplt.title('Cells correlations clustered ')\nplt.show()\nprint(time.time()-t0,'seconds passed')","8c3c84e4":"list_names = list(df.columns)\n\na,b = np.where(cm > 0.975)\nprint(  len(a)- len(list_names) )\n\nst = pd.DataFrame()\ntemp_list = []\nfor i in range(len(a)):\n    if a[i] == b[i]: continue\n    tmp_hash1 = str(a[i])+'_'+str(b[i])\n    tmp_hash2 = str(b[i])+'_'+str(a[i])\n    if (tmp_hash1 in temp_list) or (tmp_hash2 in temp_list): continue\n    temp_list.append(tmp_hash1)\n    st.loc[i,'Name1'] = list_names[a[i]]\n    st.loc[i,'Name2'] = list_names[b[i]]\n    st.loc[i,'Correlation'] = cm[ a[i], b[i] ]\n    st.loc[i,'Abs Correlation'] = np.abs( cm[ a[i], b[i] ] )\n    \nprint('top correlated')\nprint(st.shape)\nst.sort_values('Abs Correlation', ascending = False )\n","b1649a5f":"I = np.where(np.array(list_names) == 'A549')[0][0]\nI","9d4c0ab8":"v = cm[60,:]\nplt.hist(v)\nplt.show()\npd.Series(v).describe()","86270c5c":"a = np.where(cm[60,:] > 0.93)[0]\na\nfor i in a:\n    print(list_names[i], cm[60,i],cell_lines_tissues[i])","258530a5":"## High negative correlation","b79cefce":"## High positive correlation","359b28d5":"# Genes - Dimensional reduction and visualization ","d489bdbb":"# Top expressed genes ","cf7b4328":"# Genes correlation analysis","45cda191":"# What is about ?\n\nThe dataset contains genes expression matrix for 1037 cell lines. 18874 genes measured.\nBulk gene expression data.\nThis data was obtained from the Broad Institute Cancer Cell Line Encyclopedia https:\/\/portals.broadinstitute.org\/ccle\/data.\n\nHere we make basic EDA (Explanatory Data Analysis).\n\nWhat is done and conclusions:\n\n1\nWe can see that cells from different tissues somewhat tend to group according to tissue. \n\n2 \nWe also analyse genes in the similar manner, however we do not see some cluster patterns \n\n3\nWe analyse genes correlations\nconclusions might be discussed elsewhere or later .\n\n4 \nWe compute correlation for cell lines - we see very strong correlation - 0.85 in average for these data.\nHowever some experiments in other notebook shows that if we take one cell line say - A549 and compate\nsingle - cell averages with bulk from here - correlation would be only 0.61 - much lower than between different cell lines from here. \n\n\n\n","dedc5aa2":"# Transform to short (standard) cell line names, extract tissues, gender","52f0f11e":"# Load","fae45d4e":"# Dimensional reductions and visualizations of cell lines","f4aceb19":"# Average expressions","93d4073b":"# Correlations for cell lines ","9cab4132":"# Look at top correlated for particular cell line A549 - lung cancer"}}