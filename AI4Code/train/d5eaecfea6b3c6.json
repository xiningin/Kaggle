{"cell_type":{"afddf385":"code","b5281199":"code","ff4008a3":"code","ab9636f7":"code","c42917ea":"code","45a7b751":"code","c9a7ec61":"code","4ae3dc76":"code","8710105e":"code","e55d3bdb":"code","b2b25134":"code","4e82c660":"code","999506d5":"code","89cd3e43":"code","18ba2c1c":"code","78cd8109":"code","2a8e1938":"code","9bdaceda":"markdown","816bd890":"markdown","c56f1883":"markdown","649f5c98":"markdown","a966af78":"markdown","74c0871e":"markdown","e57c9952":"markdown","a647bb72":"markdown","90c50d4f":"markdown","1bbef2c2":"markdown","cd68d10a":"markdown","5a2dbf0f":"markdown","c46ac636":"markdown","ba190b2e":"markdown","c0edb32b":"markdown"},"source":{"afddf385":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.decomposition import PCA\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom skimage.feature import hog\nfrom skimage import exposure\nfrom skimage.transform import rotate\nimport pickle\nfrom tqdm import tqdm\nimport timeit\nfrom joblib import Parallel, delayed\nimport os\n%matplotlib inline","b5281199":"def read_file(filename, hist=False):\n    \"\"\"\n      Read csv file.\n      if hist=True, images will be load in Image Histogram, a vector has 256 elements\n    \"\"\"\n    df = pd.read_csv(filename)\n    if hist:\n        pixels = np.empty((df.shape[0], 256))\n        for i in range(df.shape[0]):\n            tmp = df.iloc[i].value_counts(sort=False).reindex(range(0, 256), fill_value=0).to_numpy()\n            pixels[i] = tmp\n    else:\n        pixels = df.drop(columns=['label']).values\n\n    labels = df.label.values\n    pixels = pixels.astype(np.float64)\n    return pixels, labels","ff4008a3":"def save_pickle(data, filename):\n    '''\n        Write data to pickle file\n    '''\n    pickle.dump(data, open(filename, 'wb'))\n\ndef load_pickle(filename):\n    \"\"\"\n        Load data from pickle file\n    \"\"\"\n    return pickle.load(open(filename, 'rb'))","ab9636f7":"def show_image_by_range(pixels, labels, start=0, end=1, img_size=28):\n    \"\"\"\n        Show images in range from start to end.\n    \"\"\"\n    pixels_tmp = pixels.reshape(-1, img_size, img_size, 1)\n    plt.figure(figsize=(12, 12))\n\n    for i in range(start, end):\n        plt.subplot((end - start) \/\/ 4 + 1, 4, i + 1)\n        plt.axis('off')\n        plt.title(labels[i])\n        plt.imshow(pixels_tmp[i, :, :, 0], cmap='gray')\n\n    plt.show()\n\ndef show_image_by_condition(pixels, labels, label_condition=None, numbers=24, img_size=28):\n    \"\"\"\n        Show images by label\n    \"\"\"\n    pixels_tmp = pixels.reshape(-1, img_size, img_size, 1)\n    plt.figure(figsize=(12, 12))\n\n    cnt = 0\n    if label_condition is None:\n        label_condition_set = set(np.unique(y_train))\n    else:\n        label_condition_set = set(label_condition)\n\n    n_images = len(pixels)\n    n_condition = len(label_condition_set)\n    cached_label = set()\n    while cnt < numbers:\n        idx = np.random.randint(0, n_images)\n        if labels[idx] in label_condition_set and (labels[idx] not in cached_label or cnt >= n_condition):\n            cnt += 1\n            cached_label.add(labels[idx])\n            plt.subplot(numbers \/\/ 4 + 1, 4, cnt)\n            plt.axis('off')\n            plt.title(labels[idx])\n            plt.imshow(pixels_tmp[idx, :, :, 0], cmap='gray')\n\n    plt.show()","c42917ea":"# read data from csv file\nX_train, y_train = read_file('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\nX_test, y_test = read_file('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')\n\n# normalize data from 0 to 1 range \nX_train \/= 255\nX_test \/= 255\n\n# Visualize images\nshow_image_by_condition(X_train, y_train, numbers=24)","45a7b751":"# Train baseline model\nstart = timeit.default_timer()\n\nmodel = LogisticRegression(max_iter=10000, solver='lbfgs', multi_class='auto')\nscores = cross_val_score(model, X_train, y_train, cv=5)\n\nend = timeit.default_timer()\nprint(\"Fit time:\", end - start)\nprint(\"Accuracy: %.2f\" % (scores.mean() * 100))","c9a7ec61":"# Read image histogram\nX_train_hist, y_train_hist = read_file('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv', hist=True)","4ae3dc76":"# Train model with histogram features\nstart = timeit.default_timer()\n\nhistogram_model = LogisticRegression(max_iter=10000, solver='lbfgs', multi_class='auto')\nscores = cross_val_score(histogram_model, X_train_hist, y_train_hist, cv=5)\n\nend = timeit.default_timer()\nprint(\"Fit time:\", end - start)\nprint(\"Accuracy: %.2f\" % (scores.mean() * 100))","8710105e":"def extract_hog(img, img_size=28, orientations=9, pixels_per_cell=(2, 2), cells_per_block=(1, 1)):\n    \"\"\"\n        Histogram of Oriented Gradients\n    \"\"\"\n    fd = hog(img.reshape((img_size, img_size)), orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=False)\n\n    return fd\n\ndef call_parallel_extraction(images):\n    \"\"\"\n        Process images parallelly\n    \"\"\"\n    features = Parallel(n_jobs=os.cpu_count())(delayed(extract_hog)(img) for img in tqdm(images))\n    return np.array(features)","e55d3bdb":"# Show hog features\nrepresent_index = 3\nplt.figure(figsize=(15, 15))\nplt.subplot(8, 4, 1)\nplt.imshow(X_train[represent_index].reshape(28, 28), cmap='gray')\nplt.axis('off')\ncnt = 2\nfor n_pixel in range(2, 9):\n    for n_cell in range(1, 5):\n        _, represent_hog = hog(X_train[represent_index: 4].reshape((28, 28)), \\\n                               orientations=9, pixels_per_cell=(n_pixel, n_pixel), \\\n                               cells_per_block=(n_cell, n_cell), visualize=True)\n        plt.subplot(8, 4, cnt + 3)\n        cnt += 1\n        plt.title('pixel=' + str(n_pixel) + ',cell=' + str(n_cell))\n        plt.imshow(represent_hog, cmap='gray')\n        plt.axis('off')\nplt.show()","b2b25134":"# Features extraction using HOG\nX_train_hog = call_parallel_extraction(X_train)\nX_test_hog = call_parallel_extraction(X_test)","4e82c660":"# Train model again\nstart = timeit.default_timer()\n\nmodel = LogisticRegression(max_iter=10000, solver='lbfgs', multi_class='auto')\nmodel.fit(X_train_hog, y_train)\n\nend = timeit.default_timer()\nprint(\"Fit time:\", end - start)\n\ny_pred = model.predict(X_test_hog)\nprint(\"Accuracy: %.2f\" % (accuracy_score(y_test, y_pred) * 100))","999506d5":"# Confusion matrix\ncm = confusion_matrix(y_true=y_test, y_pred = y_pred)\nplt.figure(figsize=(12,12))\nsns.heatmap(cm, annot=True, \n            linewidths=.5, square = True, cmap = 'Blues_r', fmt='0.4g');\n\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","89cd3e43":"show_image_by_condition(X_test, y_test, label_condition=[13, 18], numbers=6)","18ba2c1c":"# Set up hyperparameters\nparams = []\nfor n_component in np.arange(300, 1000, 50):\n    for C_value in np.logspace(-3, 3, 7):\n        params.append({\n        \"pca__n_components\" : n_component,\n        \"clf__estimator__C\" : C_value \n        })\n\nbest_score = 0\nbest_param = None\n\n# Loop through hyperparameters and choose the best fit\nfor param in params:\n    pipeline = Pipeline([\n                      ('pca', PCA()),\n                      ('clf', OneVsOneClassifier(\n                          LogisticRegression(max_iter=10000, solver='lbfgs', multi_class='auto'))\n                      )\n    ])\n\n    pipeline.set_params(**param)\n    start = timeit.default_timer()\n    pipeline.fit(X_train_hog, y_train)\n    stop = timeit.default_timer()\n    print(\"=============\")\n    print(\"Param\", param)\n    print(\"Training time: %.2f\" % (stop - start))\n    curr_score = pipeline.score(X_test_hog, y_test)\n    print(\"Accuracy: %.2f\" % (curr_score * 100))\n    if curr_score > best_score:\n        best_param = param\n        best_score = curr_score\n\nprint(\"Best param:\", best_param)","78cd8109":" CONFIGS = {\n    'C' : 1000,\n    'MAX_ITER' : 10000,\n    'N_COMPONENTS' : 950,\n}\n\ndef train(X_train, y_train, model=None):\n    \"\"\"\n        Build and train model.\n    \"\"\"\n\n    X_train = call_parallel_extraction(X_train)\n\n    print(\"=====TRAINING=====\")\n    if model is None:\n        print(\"Step 0: Initializing model...\")\n        model = Pipeline([\n                            ('pca', PCA(n_components=CONFIGS['N_COMPONENTS'])),\n                            ('clf', OneVsOneClassifier(\n                                LogisticRegression(C=CONFIGS['C'], \n                                                   max_iter=CONFIGS['MAX_ITER'], \n                                                   solver='lbfgs', multi_class='auto')))\n        ])\n\n    print(\"Step 1: Start training model...\")\n    model.fit(X_train, y_train)\n\n    print(\"Finished training model!\")\n    return model\n\ndef predict(X_test, y_test, model=None):\n    \"\"\"\n        Evaluation function.\n    \"\"\"\n\n    X_test = call_parallel_extraction(X_test)\n\n    print(\"=====PREDICTION=====\")\n    if model is None: \n        print(\"Step 0: Start loading model...\")\n        model = load_pickle(CONFIGS['MODEL_PATH'])\n\n    print(\"Step 1: Predicting...\")\n    y_pred = model.predict(X_test)\n\n    print(\"Step 2: Scoring model...\")\n    missed_labels = np.sum(y_pred != y_test)\n    accuracy = accuracy_score(y_test, y_pred)\n\n    print(\"Accuracy: {:.5f}\".format(accuracy))\n    print(\"Missed Label: \", missed_labels)\n\n    print(\"Finished predicting model!\")\n    return accuracy, missed_labels\n","2a8e1938":"# read data from csv file\nX_train, y_train = read_file('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\nX_test, y_test = read_file('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')\n\n# normalize data from 0 to 1 range \nX_train \/= 255\nX_test \/= 255\n\n# train\nmodel = train(X_train, y_train)\n\n# get test score\n_ = predict(X_test, y_test, model)","9bdaceda":"After ran this code, I decided to choose C=1000 and PCA_n_components=950","816bd890":"### Load and save function","c56f1883":"### Feature Extraction: Experiment with Image Histogram","649f5c98":"I build a baseline model with default hyperparameters","a966af78":"### Baseline","74c0871e":"## Utils","e57c9952":"### Feature Extraction: Experiment with Histogram of Oriented Gradient","a647bb72":"## Final","90c50d4f":"## Read and show data","1bbef2c2":"Show feature images to choose size of cell and size of block","cd68d10a":"### Read csv file function","5a2dbf0f":"### Visualization function","c46ac636":"Visualize confusion matrix to see which labels have many misclassified","ba190b2e":"### Find good model hyperparameters","c0edb32b":"## Training and Evaluate"}}