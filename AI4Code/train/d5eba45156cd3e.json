{"cell_type":{"dc906ec6":"code","60fb9167":"code","cf7df898":"code","84b1bed2":"code","d0d83138":"code","c8c40e23":"code","d6e418ef":"code","b135a9a1":"code","8b5639dc":"code","a7c7c27f":"code","b00223eb":"code","cf8cf639":"code","57e17053":"code","a3366ab2":"code","49bfa0b9":"code","f9394e8d":"code","00f8035e":"code","880356dd":"code","e8c33901":"code","34b242dd":"code","295561c2":"code","476a001a":"code","b85847a4":"code","24facefa":"code","59cd3f1b":"code","391646d3":"code","d6bd1d5b":"code","63bd38c3":"code","cfc1abb6":"code","1ff7884b":"code","e7dd6576":"code","168c5e0c":"code","b4ad56d1":"code","1b249a7b":"code","50db2b77":"code","5acdc025":"code","f73d8027":"code","7da1c775":"code","d766249c":"code","8330a9ad":"code","4c1e7200":"code","6e199be0":"markdown","53693ec4":"markdown","cc0792d0":"markdown","a5b019f3":"markdown","30d5cc23":"markdown","cb947cb1":"markdown","3e0139af":"markdown","33fb9261":"markdown","d013bf82":"markdown","7b606ac2":"markdown","9d8c115a":"markdown","419bcf05":"markdown","57ce8c96":"markdown","a6c5735d":"markdown","e4e6e9b4":"markdown","1f333db7":"markdown","6ffc88ab":"markdown","6bc87058":"markdown","1070fec7":"markdown","c6bf4f49":"markdown","fc1aefb5":"markdown","13ebdd8d":"markdown","5cb055a3":"markdown","853c7a2d":"markdown","56eae309":"markdown","103e6307":"markdown","72733dfe":"markdown","a83da5fc":"markdown","e5448ce8":"markdown","755ce993":"markdown","3a86c266":"markdown","c83ea91c":"markdown"},"source":{"dc906ec6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","60fb9167":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import layers,mixed_precision","cf7df898":"def walk_through_dir(directory_name):\n    \n    '''\n    Accepts the dirname as argument and prints the contents of each directory sequentially.\n    It prints the sub-directories and number of images present in each.\n    '''\n    for dirpaths,dirnames,filenames in os.walk(directory_name):\n        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpaths}'\")","84b1bed2":"input_data_dir='..\/input\/100-bird-species'\nwalk_through_dir(input_data_dir)","d0d83138":"def plot_random_image(target_dir):\n    \"\"\"\n    takes the directory as input and prints 5 random images from the randomly choosen class.\n    \"\"\"\n    target_class=random.choice(os.listdir(target_dir))\n    target_folder=os.path.join(target_dir,target_class)\n    random_image=random.sample(os.listdir(target_folder),5)\n \n    plt.figure(figsize=(16,5))\n    for i in range(5):\n        \n        plt.subplot(1,5,i+1)\n        img=tf.io.read_file(os.path.join(target_folder,random_image[i]))\n        img=tf.io.decode_image(img)\n        plt.imshow(img)\n        plt.title(f'{target_class}\\n{img.shape}')\n        plt.axis(False)","c8c40e23":"train_dir='..\/input\/100-bird-species\/train'\nval_dir='..\/input\/100-bird-species\/valid'\ntest_dir='..\/input\/100-bird-species\/test'","d6e418ef":"plot_random_image(train_dir)","b135a9a1":"IMAGE_SIZE=(224,224)\n\ntrain_data=tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    label_mode='categorical',\n    image_size=IMAGE_SIZE\n)\nclass_names=train_data.class_names\nnum_classes=len(class_names)\nval_data=tf.keras.preprocessing.image_dataset_from_directory(\n    val_dir,\n    label_mode='categorical',\n    image_size=IMAGE_SIZE,\n    \n)\ntest_data=tf.keras.preprocessing.image_dataset_from_directory(\n    test_dir,\n    label_mode='categorical',\n    image_size=IMAGE_SIZE,\n    shuffle=False\n)\n\ntrain_data_pf=train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\nval_data_pf=val_data.prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_data_pf=test_data.prefetch(buffer_size=tf.data.AUTOTUNE)","8b5639dc":"data_augmentation=keras.Sequential([\n    layers.RandomFlip('horizontal'),\n    layers.RandomRotation(0.2,fill_mode='nearest'),\n    # layers.Rescaling(scale=1.0\/255)\n],name='Data_Augmentation_Layer')","a7c7c27f":"mixed_precision.set_global_policy('mixed_float16')\n\ninputs=layers.Input(shape=(224,224,3),name='input_layer')\n\nbase_model=keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbase_model.trainable=False\n\nx=data_augmentation(inputs)\n\nx=base_model(x,training=False)\n\nx=layers.GlobalAveragePooling2D(name='Global_Average_Pool_2D')(x)\nnum_classes=len(train_data.class_names)\noutputs=layers.Dense(num_classes,activation='softmax',dtype=tf.float32,name=\"Output_layer\")(x)\n\nmodel=keras.Model(inputs,outputs,name=\"model\")","b00223eb":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy']\n)","cf8cf639":"model.summary()","57e17053":"EPOCHS=5\nhistory_of_model=model.fit(\n    train_data_pf,\n    epochs=EPOCHS,\n    steps_per_epoch=int (0.1*len(train_data_pf)),\n    validation_data=val_data_pf,\n    validation_steps=len(val_data_pf)    \n)","a3366ab2":"model_0_result=model.evaluate(test_data_pf)\nmodel_0_result","49bfa0b9":"def plot_loss_curves(history):\n    \n    '''\n      returns seperate loss curves for training and validation metrics\n    '''\n    train_loss=history.history['loss']\n    val_loss=history.history['val_loss']\n\n    train_accuracy=history.history['accuracy']\n    val_accuracy=history.history['val_accuracy']\n\n    epochs=range(1,len(history.history['loss'])+1)\n    plt.figure(figsize=(20,7))\n  # plot loss data\n    plt.subplot(1,2,1)\n    plt.plot(epochs,train_loss,label=\"training_loss\")\n    plt.plot(epochs,val_loss,label=\"validation_loss\")\n    plt.title(\"Loss curves\")\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.legend()\n  # plt.show()\n\n  # plot accuracy data\n    plt.subplot(1,2,2)\n    plt.plot(epochs,train_accuracy,label=\"training_acc\")\n    plt.plot(epochs,val_accuracy,label=\"validation_acc\")\n    plt.title(\"Accuracy curves\")\n    plt.xlabel('epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()","f9394e8d":"plot_loss_curves(history_of_model)","00f8035e":"mixed_precision.set_global_policy('mixed_float16')","880356dd":"inputs=layers.Input(shape=(224,224,3),name='input_layer')\n\nbase_model=keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbase_model.trainable=False\n\nx=data_augmentation(inputs)\n\nx=base_model(x,training=False)\n\nx=layers.GlobalAveragePooling2D(name='Global_Average_Pool_2D')(x)\nnum_classes=len(train_data.class_names)\noutputs=layers.Dense(num_classes,activation='softmax',dtype=tf.float32,name=\"Output_layer\")(x)\n\nmodel=keras.Model(inputs,outputs,name=\"model\")","e8c33901":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy']\n)","34b242dd":"def create_model_check_point_callback(checkpoint_path,monitor='val_loss'):\n    \"\"\"\n    Takes the path where to save the best model weights obtained during training.\n    \"\"\"\n    model_checkpoint_cb=tf.keras.callbacks.ModelCheckpoint(\n        \n        monitor=monitor,\n        filepath=checkpoint_path,\n        save_best_only=True,\n        save_weights_only=True,\n        save_freq='epoch',\n        verbose=1\n    )\n    return model_checkpoint_cb","295561c2":"ModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model_1.ckpt')\n\nEPOCHS=5\nhistory_of_model_1=model.fit(\n    train_data_pf,\n    epochs=EPOCHS,\n    steps_per_epoch=len(train_data_pf),\n    validation_data=val_data_pf,\n    validation_steps=len(val_data_pf),\n    callbacks=[ModelCheckPoint_model_cb]\n)","476a001a":"#load the best weights saved using modelCheckPoint callback\nmodel.load_weights('.\/ModelCheckPoints\/model_1.ckpt')\nmodel_1_result=model.evaluate(test_data_pf)\nmodel_1_result","b85847a4":"plot_loss_curves(history_of_model_1)","24facefa":"model.summary()","59cd3f1b":"# umfreeze top 10 layers \nmodel.layers[2].trainable=True\nfor layer in model.layers[2].layers[:-10]:\n    layer.trainable=False","391646d3":"# check the number of trainable layers in feature extraction model\nlen(model.layers[2].trainable_variables)","d6bd1d5b":"\nmodel.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    metrics=['accuracy']\n)","63bd38c3":"early_stop_cb=tf.keras.callbacks.EarlyStopping(patience=4,restore_best_weights=True)\nreduce_lr_cb=tf.keras.callbacks.ReduceLROnPlateau(factor=0.2,patience=2,verbose=1,min_lr=1e-7,min_delta=1e-3)","cfc1abb6":"ModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model_2.ckpt')\n\nfine_tune_epochs=EPOCHS+20\nhistory_of_model_2=model.fit(\n    train_data_pf,\n    epochs=fine_tune_epochs,\n    initial_epoch=EPOCHS-1,\n    steps_per_epoch=len(train_data_pf),\n    validation_data=val_data_pf,\n    validation_steps=len(val_data_pf),\n    callbacks=[ModelCheckPoint_model_cb,early_stop_cb,reduce_lr_cb]\n)","1ff7884b":"model_2_val_result=model.evaluate(val_data_pf)\nmodel_2_val_result","e7dd6576":"model_2_test_result=model.evaluate(test_data_pf)\nmodel_2_test_result","168c5e0c":"def plot_and_compare_history(original_history,new_history,initial_epoch):\n    \"\"\"\n    the function accepts the histories of a model before and after fine-tunning.\n    initial_epoch:#epochs used to train the original model.\n    \"\"\"\n    #get original history measurements\n    acc=original_history.history['accuracy']\n    loss=original_history.history['loss']\n    val_acc=original_history.history['val_accuracy']\n    val_loss=original_history.history['val_loss']\n    \n    #combining \n    total_acc=acc+new_history.history['accuracy']\n    total_loss=loss+new_history.history['loss']\n    total_val_acc=val_acc+new_history.history['val_accuracy']\n    total_val_loss=val_loss+new_history.history['val_loss']\n    \n    #make plots\n    plt.figure(figsize=(16,6))\n    plt.subplot(1,2,1)\n    plt.plot(total_acc,label='Training Accuracy')    \n    plt.plot(total_val_acc,label='Validation Accuracy')\n    plt.plot([initial_epoch-1,initial_epoch-1],plt.ylim(),label='Start fine tunning')\n    plt.title(\"Accuracy\")\n    plt.legend(loc='lower right')\n    plt.subplot(1,2,2)\n    plt.plot(total_loss,label='Training loss')\n    plt.plot(total_val_loss,label=\"Validation loss\")\n    plt.plot([initial_epoch-1,initial_epoch-1],plt.ylim(),label='Start fine tunning')\n    plt.title(\"Loss\")\n    plt.legend(loc=\"upper right\")","b4ad56d1":"plot_and_compare_history(history_of_model_1,history_of_model_2,initial_epoch=EPOCHS)","1b249a7b":"# loading the best weights of model_1\nmodel.load_weights('.\/ModelCheckPoints\/model_1.ckpt')","50db2b77":"model.layers[2].trainable=True","5acdc025":"# checking the number of trainable layers in feature extraction model\nlen(model.layers[2].trainable_variables)","f73d8027":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    metrics=['accuracy']\n)","7da1c775":"# callbacks\nModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model_3.ckpt')\nearly_stop_cb=tf.keras.callbacks.EarlyStopping(patience=4,restore_best_weights=True)\nreduce_lr_cb=tf.keras.callbacks.ReduceLROnPlateau(factor=0.2,patience=2,verbose=1,min_lr=1e-7,min_delta=1e-3)\n\nfine_tune_epochs=EPOCHS+20\nhistory_of_model_3=model.fit(\n    train_data_pf,\n    epochs=fine_tune_epochs,\n    initial_epoch=EPOCHS-1,\n    steps_per_epoch=len(train_data_pf),\n    validation_data=val_data_pf,\n    validation_steps=len(val_data_pf),\n    callbacks=[ModelCheckPoint_model_cb,early_stop_cb,reduce_lr_cb]\n)","d766249c":"model_3_val_result=model.evaluate(val_data_pf)\nmodel_3_val_result","8330a9ad":"model_3_test_result=model.evaluate(test_data_pf)\nmodel_3_test_result","4c1e7200":"plot_and_compare_history(history_of_model_1,history_of_model_3,initial_epoch=EPOCHS)","6e199be0":"# 7.3 Define Early Stopping and Reduce Learning Rate callback","53693ec4":"**Inference:This fine-tunning of top 10 layers improved the validation and test accuracy by 1%.**","cc0792d0":"# 5.5 Fit the model","a5b019f3":"# 5 model_0\n* using efficientnetB0 model as the feature extraction layer and training using 10% of the training batches and augmenting the training data","30d5cc23":"# 6.3 Define Model Check Point Callback Function","cb947cb1":"# 1. Importing Libraries","3e0139af":"# 8.2 Recompile the model","33fb9261":"# 6.2 Compile the model","d013bf82":"Inference:`model_0` which was trained on only 10% of the training data batches(of size 32 each) performed very well on\nvalidation and test data, which signifies that the model is learning the patterns very well.\n\nLets scale up and train model_0 using 100% training data using the same architecture.","7b606ac2":"# 5.6 model_0 result","9d8c115a":"# 5.3 Compile the model","419bcf05":"# 8.3 Fit the model","57ce8c96":"# 5.1 Define Data Augmentation Layer","a6c5735d":"# 8.1 unfreezing all layers","e4e6e9b4":"# 7.2 Recompile the model\n* reduce the learning rate so that the model does not overfit the train data and lose the pretained weights of efficientnetB0(learned on imagenet dataset)","1f333db7":"# 5.2 Create the model","6ffc88ab":"# 6.1 Create the model","6bc87058":"# 6. model_1\n* using efficientnetB0 as the feature extraction layer and training using 100% of the training batches and augmenting the training data","1070fec7":"# 8.4 model_3 result","c6bf4f49":"**Inference:`model_1` has performed even better than `model_0` as expected.Both validation and test accuracies are about 97%.Next I will try to improve this by fine-tunning the top layers of the feature extraction model**","fc1aefb5":"# 3.Visualizing the train data","13ebdd8d":"# 6.4 Fit the model","5cb055a3":"# 6.5 model_1 result","853c7a2d":"# 4.Converting the Input Data into batch Datasets","56eae309":"# 2. Input Data Details","103e6307":"# 8.model_3\n* Fine tunning the all layers of the feature extraction model(efficientnetB0) and training until convergence\n","72733dfe":"**Inference:Fine tunning all the layers did not have much of an impact on validation and test data as compared to fine-tunning the top 10 layers.**","a83da5fc":"# 7.1 unfreeze the top 10 layers of the feature extraction model","e5448ce8":"# 7.5 model_2 result","755ce993":"# 7.4 Fit the model","3a86c266":"# 7.model_2\n* Fine tunning the top 10 layers of the feature extraction model(efficientnetB0) and training until convergence","c83ea91c":"# 5.4 model summary"}}