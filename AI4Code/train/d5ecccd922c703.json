{"cell_type":{"4e98d210":"code","ec1a497d":"code","4a7e7708":"code","972ff497":"code","da7361a9":"code","9062be71":"code","c7ae9a68":"code","d450d64d":"code","6797d1f4":"code","3b8a6612":"code","2023ed19":"code","b8a6b0d5":"markdown","b6a8e1e3":"markdown","58ae3832":"markdown","b6f680e3":"markdown","29cd5e4b":"markdown","152b1774":"markdown","3b71e519":"markdown"},"source":{"4e98d210":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ec1a497d":"import numpy as np\nimport pandas as pd\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix","4a7e7708":"#Read the data\ndf=pd.read_csv('..\/input\/fake-news-detection-dataset\/news.csv')\n#Get shape and head\ndf.shape\ndf.head()","972ff497":"df.shape","da7361a9":"df.isnull().sum()","9062be71":"# Get the labels\nlabels=df.label\nlabels.head()","c7ae9a68":"x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)","d450d64d":"#print(x_train.shape)\n#print(x_test.shape)\n#print(y_train.shape)","6797d1f4":"tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n# Fit and transform train set, transform test set\ntfidf_train=tfidf_vectorizer.fit_transform(x_train) \ntfidf_test=tfidf_vectorizer.transform(x_test)","3b8a6612":"pac=PassiveAggressiveClassifier(max_iter=50)\npac.fit(tfidf_train,y_train)\n#Predict on the test set and calculate accuracy\ny_pred=pac.predict(tfidf_test)\nscore=accuracy_score(y_test,y_pred)\nprint(f'Accuracy: {round(score*100,2)}%')","2023ed19":"confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])","b8a6b0d5":"### So with this model, we have 591 true positives, 585 true negatives, 44 false positives, and 47 false negatives.","b6a8e1e3":"### Loading necessary libraries and reading the file","58ae3832":"#### Let\u2019s initialize a TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features.\n\n#### Now, fit and transform the vectorizer on the train set, and transform the vectorizer on the test set.","b6f680e3":"### Next, initializing a PassiveAggressiveClassifier. This is. We\u2019ll fit this on tfidf_train and y_train.\n\n### Then, we\u2019ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics.","29cd5e4b":"### Splitting dataset into training and test set","152b1774":" ### If you want to learn more about TfidfVectorizer , then you can refer [here .](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfVectorizer.html)","3b71e519":"### Got  accuracy of 92.82% with this model. Finally, let\u2019s print out a confusion matrix to gain insight into the number of false and true negatives and positives."}}