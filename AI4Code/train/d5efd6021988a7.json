{"cell_type":{"f31825e1":"code","94d09c4c":"code","4642759c":"code","0d9c178a":"code","7fde3fdc":"code","8767775b":"code","04a17fa8":"code","2e910518":"code","d658efdf":"code","e859e6ba":"code","14094039":"code","47d5a533":"code","8b1e6aa9":"code","376a32d3":"code","b449f9e4":"code","92802d68":"code","fb8f51c6":"code","59ee9e16":"code","b73f5019":"code","a2d875b5":"code","52b8ed86":"code","f369914d":"code","04a9dba1":"code","d7be80af":"code","3a7ee041":"code","e0a7ac4d":"code","516ec3e4":"code","67ed39e5":"code","929504a6":"code","7a305a4b":"code","7559f45d":"code","0ea566f9":"code","3fdd8aba":"code","0b77c1b1":"code","c07228e6":"code","3d0ab5ab":"code","0a46ab1d":"code","89b99248":"code","be0386a4":"code","c32de0af":"code","c73d718f":"code","deb357e2":"code","de6029b8":"code","097d0cfd":"code","67800146":"code","7050662b":"code","c2b3ea45":"markdown","f0599a1f":"markdown","df1b4884":"markdown","1d38c753":"markdown","e8edb3a5":"markdown","4b023e81":"markdown","e4e4ad3e":"markdown","aa5a4f5a":"markdown","c2fc4b4f":"markdown","ad251a16":"markdown","5ab60b98":"markdown","943e2332":"markdown","4a517166":"markdown"},"source":{"f31825e1":"#Importing the important libraries\n\nimport pandas as pd\nimport seaborn as sns\nimport sklearn as sk\nimport matplotlib.pyplot as plt\nimport numpy as np","94d09c4c":"#reading the dataset\n\nleaddf=pd.read_csv(\"..\/input\/leadscoring\/Leadscoring.csv\")","4642759c":"leaddf.head()","0d9c178a":"leaddf.shape","7fde3fdc":"leaddf.describe()","8767775b":"leaddf.columns","04a17fa8":"#checking the null values\n\nleaddf.isna().sum()","2e910518":"#replacing the select with NaN\nfor i in leaddf.columns:\n    leaddf[i]=leaddf[i].replace('Select', value=np.NaN)\n\nleaddf.head()","d658efdf":"#finding percentage of the missing values\nmiss_val=leaddf.isnull().sum()\nmissing=[(c,(leaddf[c].isnull().sum()\/len(leaddf))*100) for c in leaddf]\nmissing=pd.DataFrame(missing, columns=['label','percentage'])\nmissing=missing[missing.percentage>30]\ndisplay(missing.sort_values('percentage', ascending=False))\n\nmissing.count()","e859e6ba":"drop_col=missing.label\ndrop_col\nleaddf=leaddf.drop(drop_col,1)\n\nleaddf.head()","14094039":"#dropping the unwanted columns\nleaddf=leaddf.drop(['Prospect ID','Lead Number','I agree to pay the amount through cheque', 'A free copy of Mastering The Interview'], axis=1)\nleaddf.head()","47d5a533":"#round((leaddf.isna().sum()\/len(leaddf))*100,2)\n\nmiss_val=leaddf.isnull().sum()\nmissing=[(c,(leaddf[c].isnull().sum()\/len(leaddf))*100) for c in leaddf]\nmissing=pd.DataFrame(missing, columns=['label','percentage'])\nmissing=missing[missing.percentage>0]\ndisplay(missing.sort_values('percentage', ascending=False))","8b1e6aa9":"#fixing the missing values\nfor i in missing['label']:\n    print(leaddf[i].value_counts().head())\n    print('--------------------------------------------------')\n#leaddf['Lead Source'].value_counts() #we will impute with the highest occuring value. In this case its \"Google\"","376a32d3":"#now create a list of missing values then replace NaN values\n\nimp_val={'Lead Source':'Google','TotalVisits':'0.0','Page Views Per Visit':'0.0','Last Activity':'Email Opened',\n         'Country':'India','What is your current occupation':'Unemployed',\n         'What matters most to you in choosing a course':'Better Career Prospects'}\nleaddf= leaddf.fillna(value=imp_val)\nleaddf.isna().sum()","b449f9e4":"#there is Google & google source in the lead source list, it represents the same source\n\n#for i in leaddf['Lead Source']:\nleaddf['Lead Source']=leaddf['Lead Source'].apply(lambda x:x.capitalize())\n\nleaddf['Lead Source'].value_counts()","92802d68":"#First analyse the target variable\nconv=leaddf['Converted'].value_counts()\nconv","fb8f51c6":"total=leaddf['Converted'].count()\nprint(f'Percentage of leads converted = {round((conv[1]\/total) *100 ,2)}%')\nprint(f'Percentage of leads not converted = {round((conv[0]\/total) *100 ,2)}%')","59ee9e16":"leaddf['Converted'].plot.hist()","b73f5019":"leaddf['Lead Origin'].astype(str)","a2d875b5":"leaddf['Lead Source'].astype(str)","52b8ed86":"leaddf.dtypes","f369914d":"leaddf['TotalVisits']=pd.to_numeric(leaddf['TotalVisits']).astype(np.int64)\nleaddf['Page Views Per Visit']=pd.to_numeric(leaddf['Page Views Per Visit']).astype(np.int64)","04a9dba1":"binary=['Do Not Call', 'Do Not Email','Newspaper Article','X Education Forums','Newspaper','Digital Advertisement',\n        'Through Recommendations','Receive More Updates About Our Courses','Update me on Supply Chain Content','Get updates on DM Content','Magazine']\n\nfor i in binary:\n    leaddf[i]=leaddf[i].astype('str')","d7be80af":"cat=leaddf.select_dtypes('object').columns\ncat","3a7ee041":"#defining functions for frequently used plots\n\n\ndef barcount_plot(variable):\n    plt.figure(figsize = (10,8))\n    plt.subplot(1,2,1)\n    leaddf[variable].value_counts().plot(kind='bar', colormap='Blues_r')\n    plt.title(f\"Plotting the {variable}\")   \n    plt.subplot(1,2,2)\n    sns.countplot(x=variable, hue='Converted', data=leaddf).tick_params(axis='x', rotation = 90)\n    plt.show()\n\ndef hist_plot(variable):\n    plt.figure(figsize = (15, 12))\n    plt.subplot(1,2,1)\n    plt.hist(leaddf[variable], bins = 200)\n    plt.title(f\"Plotting the {variable}\") \n    plt.xlim(0,25)\n    plt.show()","e0a7ac4d":"for i in cat:\n    barcount_plot(i)\n    #cat_plot(i)\n    ","516ec3e4":"#if you observe the majority of the leads are from India, we can categorise the countries into, India & others\n\n\ndef slots(x):\n    category = \"\"\n    if x == \"India\":\n        category = \"India\"\n    else:\n        category = \"Others\"\n    return category\n\nleaddf['Country'] = leaddf.apply(lambda x:slots(x['Country']), axis = 1)\nleaddf['Country'].value_counts()","67ed39e5":"plt.figure(figsize = (10,8))\nplt.subplot(1,2,1)\nleaddf['Country'].value_counts().plot(kind='bar', colormap='Blues_r')\nplt.title(f\"Plotting the Country\")   \nplt.subplot(1,2,2)\nsns.countplot(x='Country', hue='Converted', data=leaddf).tick_params(axis='x', rotation = 90)\nplt.show()","929504a6":"num=leaddf.select_dtypes('number').columns","7a305a4b":"num","7559f45d":"for i in num:\n    hist_plot(i)","0ea566f9":"cr=leaddf.corr()\nsns.heatmap(cr)","3fdd8aba":"## We can see from the plots that \"Total Visit\" & \"Page views per visit\" has the outliers, lets check them using Boxplots\n\nplt.figure(figsize=(10,8))\nsns.boxplot(x='TotalVisits', y=None, data=leaddf)","0b77c1b1":"def box_plot(variable):\n    plt.figure(figsize=(10,8))\n    sns.boxplot(x=variable, y=None, data=leaddf)\n    plt.show()","c07228e6":"x=['TotalVisits','Page Views Per Visit','Total Time Spent on Website']\nfor i in x:\n    box_plot(i)","3d0ab5ab":"\nbinary=['Do Not Email','Do Not Call','Magazine', 'Search','Newspaper Article','X Education Forums', 'Newspaper', \n        'Digital Advertisement','Through Recommendations', 'Receive More Updates About Our Courses',\n        'Update me on Supply Chain Content', 'Get updates on DM Content']\n\nfor i in binary:\n    category={'Yes':1, 'No':0}\n    leaddf[i]=leaddf[i].map(category)\n    \n\nleaddf.head()","0a46ab1d":"#now we will encode multi category variables using get_dummies\ndummy=pd.get_dummies(leaddf[['Lead Origin','Lead Source','Last Activity','Last Notable Activity',\n                             'What matters most to you in choosing a course','What is your current occupation','Country']], drop_first=True)\ndf_final=pd.concat([leaddf,dummy], axis=1)","89b99248":"df_final.head()","be0386a4":"#dropping the original columns\ndf_final=df_final.drop(['Lead Origin','Lead Source','Last Activity','Last Notable Activity','What matters most to you in choosing a course',\n                        'What is your current occupation','Country'],1)\n\ndf_final.head()","c32de0af":"from sklearn.model_selection import train_test_split","c73d718f":"#we will drop the target column\n\nX=df_final.drop(['Converted'],1)\nX.head()","deb357e2":"y=df_final['Converted']\ny.head()","de6029b8":"#we will split the X & y dataset into train & test\nX_train,y_test,X_test,y_train=train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=10)","097d0cfd":"#Now we will scale the numerical variables\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nnum=['TotalVisits','Total Time Spent on Website','Page Views Per Visit']\nfor i in num:\n    X_train[i]=scaler.fit_transform(X_train[[i]])","67800146":"X_train.head()","7050662b":"cor=df_final.corr()\nplt.figure(figsize=(15,20))\nsns.heatmap(cor)","c2b3ea45":"### Univariate & Bivariate Analysis\n\n#### 1. Categorical Variables","f0599a1f":"10 columns have more than 30% values missing. Lets drop these columns","df1b4884":"#### Now that we have scaled the data, our data is ready for model development.\n\n","1d38c753":"#### Now that we have encoded the data, we need scale the numerical values. Remember, we will be scaling only the trainin set, since we need to perform the test on original dataset","e8edb3a5":"# What is lead scoring?\n\n\nLeads are very crucial for every organisation, these are the easy route for the business. They can be from different sources like employee references, customer references, marketing leads or any other online & offline. However not every lead is a potential opportunity for the organisation, with the help of the lead scoring system, organization will be able to prioritize the leads and make job of the sales rep easier.\n\n# The Dataset\n\nWe have the dataset that contains leads of the organisation generated from various sources and also the data if the lead is converted to business or not.\n\nWe will now explore every variable & how it affects the lead conversion.\n\nSince the target variable is binary, it is a classification problem.\n\n# Exploratory Data Analysis\n","4b023e81":"##### There are total of 9240 rows & 37 columns\n##### \"Converted\" label is our Y variable\n#### Prospect id & lead id are randomly generated number so we will ignore them\n#### \"I agree to pay the amount through cheque\"  & \"A free copy of Mastering The Interview\" are also not relevant to us, we will drop that as well.","e4e4ad3e":"### Encoding Categorical Variables\n\n##### Now we need to encode the categorical variables. Replace binary variables to 0 & 1, use one hot encoder for multi category variables","aa5a4f5a":"As we observe, there are extreme data points in the plots above for \"Total Visits\" & \"Page Views Per Visit\". We cannot frop the outliers, since they will affect the model","c2fc4b4f":"### Checking the outliers","ad251a16":"Now we have succesfully imputed the null values.\n\n","5ab60b98":"### Splitting the dataset: Train-Test Split","943e2332":"#### 2. Numerical Variables","4a517166":"We can see that only 6 Labels are numerical variables and rest of them are categorical in nature"}}