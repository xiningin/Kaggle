{"cell_type":{"2f5391fc":"code","55b1be9d":"code","e3d733b5":"code","28a2fcc6":"code","9192581f":"code","33f5a342":"code","f2a44c2f":"code","f61cbdeb":"code","dab9d966":"code","ae8fb3aa":"code","6fe6cd19":"code","9c33fd72":"code","2a27ffbf":"code","31f574e9":"code","c523b25b":"code","68e18f00":"code","2bf3c993":"code","516e24ba":"code","d0de22ec":"code","c5740a99":"code","32e8bd40":"code","a0c84343":"code","29283429":"code","0582185d":"code","b2ea4f7e":"markdown","4f8fdd2c":"markdown","6847efd7":"markdown","c66bc94c":"markdown","659c874a":"markdown","2ff32878":"markdown","d15454eb":"markdown","5b56fa4c":"markdown","1c7daf36":"markdown","fa608742":"markdown","c167df8c":"markdown","fccb2257":"markdown","ea18d5f2":"markdown","6fd87bdf":"markdown","46127220":"markdown","c78f916b":"markdown","dbc465cb":"markdown","b5cfb772":"markdown","605bae57":"markdown","a99633f0":"markdown"},"source":{"2f5391fc":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nsns.set()\n\nimport os\nprint(os.listdir(\"..\/input\"))","55b1be9d":"path = \"..\/input\"\ntrain_file = pd.read_csv(path+\"\/train.csv\")\ntest_file = pd.read_csv(path+\"\/test.csv\")\nSalePrice = train_file[\"SalePrice\"]\ntest_id = test_file.Id\n\nprint(train_file.shape)\nprint(test_file.shape)\n\n\n\n","e3d733b5":"train_file.isnull().sum().sort_values(ascending=False)","28a2fcc6":"#Remove the ID columns\ntrain = train_file.drop([\"Id\"],axis=1)\ntest = test_file.drop([\"Id\"],axis=1)\n\n\nprint(\"train: \",train.shape)\nprint(\"test: \",test.shape)","9192581f":"num_to_object = [\"MSSubClass\",\"OverallQual\",\"OverallCond\",\"YrSold\"]\nfor col in num_to_object:\n    train[col] = train[col].astype(\"object\")\n    test[col] = test[col].astype(\"object\")","33f5a342":"sns.distplot(train[\"SalePrice\"])\ntitle = \"Skewness: \"+str(train[\"SalePrice\"].skew())[:4]+\" Kurtosis: \"+str(train[\"SalePrice\"].kurt())[:4]\nplt.title(title)","f2a44c2f":"train[\"SalePrice_log\"] = np.log1p(train.SalePrice)\nsns.distplot(train[\"SalePrice_log\"])\ntitle = \"Skewness: \"+str(train[\"SalePrice_log\"].skew())[:4]+\" Kurtosis: \"+str(train[\"SalePrice_log\"].kurt())[:4]\nplt.title(title)","f61cbdeb":"train.drop(\"SalePrice\",axis=1,inplace=True)","dab9d966":"numerical_columns = list(train.select_dtypes([\"float64\",\"int64\"]).columns)\nnumerical_columns.remove(\"SalePrice_log\")\nprint(numerical_columns)\ntrain[numerical_columns].isnull().sum().sort_values(ascending=False)\n#LotFrontage GarageYrBlt MasVnrArea\ntrain[\"LotFrontage\"].fillna(train[\"LotFrontage\"].mean(),inplace=True)\ntrain[\"GarageYrBlt\"].fillna(train[\"GarageYrBlt\"].mean(),inplace=True)\ntrain[\"MasVnrArea\"].fillna(train[\"MasVnrArea\"].mean(),inplace=True)","ae8fb3aa":"print(len(numerical_columns))\nnrows=11\nncols=3\nfig,axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(ncols*3.5,nrows*3))\nnum_col_pear = []\nfor r in range(nrows):\n    for c in range(ncols):\n        idx = r*3+c\n        if idx < len(numerical_columns):\n            sns.regplot(train[numerical_columns[idx]],train[\"SalePrice_log\"],ax=axes[r][c])\n            pearson = stats.pearsonr(train[numerical_columns[idx]],train[\"SalePrice_log\"])\n            num_col_pear.append(abs(pearson[0]))\n            axes[r][c].set_title(\"r:%2f  p-value:%2f\"%(pearson[0],pearson[1]))\n        \nplt.tight_layout()\nplt.show()","6fe6cd19":"num_col_pear = pd.DataFrame({\"Feature\":numerical_columns,\"Pearson\":num_col_pear})\n#check pearson correlation,choose a Threshold value(0.4 here) for filtering\nnum_col_pear.sort_values(by=\"Pearson\",ascending=False)\nweak_pear_col = list(num_col_pear[num_col_pear.Pearson<0.4][\"Feature\"])\nstrong_pear_col = list(num_col_pear[num_col_pear.Pearson>=0.4][\"Feature\"])\n","9c33fd72":"sns.heatmap(train[strong_pear_col+[\"SalePrice_log\"]].corr(),cbar=True, square=True, fmt='.2f',annot=True,annot_kws={\"size\":5})\nplt.xticks(rotation=45)\nplt.yticks(rotation=45)\nplt.show()","2a27ffbf":"train.drop(weak_pear_col,axis=1,inplace=True)\ntest.drop(weak_pear_col,axis=1,inplace=True)\n\ntrain.drop([\"TotRmsAbvGrd\",\"GarageArea\",\"1stFlrSF\"],axis=1,inplace=True)\ntest.drop([\"TotRmsAbvGrd\",\"GarageArea\",\"1stFlrSF\"],axis=1,inplace=True)\n","31f574e9":"object_columns = list(train.select_dtypes([\"object\"]).columns)\n#plot: show boxplot of SalePrice_log and each object column\n#will update later","c523b25b":"unbalance_columns = [] \nfor col in object_columns:\n    temp = train.groupby(col)[\"SalePrice_log\"].count()\/train.shape[0]\n    print(temp)\n    if max(temp.values) > 0.90 or sum(temp.values)<0.10:\n        unbalance_columns.append(col)\n    print(\"#\"*50)\nprint(unbalance_columns)","68e18f00":"train.drop(unbalance_columns,axis=1,inplace=True)\ntest.drop(unbalance_columns,axis=1,inplace=True)\n\n\nobject_nunique = train.select_dtypes([\"object\"]).apply(pd.Series.nunique)\ntwo_label_columns = list(object_nunique.index[object_nunique<=2])\nmulti_label_columns = list(object_nunique.index[object_nunique>2])\n\nfor col in two_label_columns:\n    if train[col].isnull().sum()>0 or test[col].isnull().sum()>0:\n        two_label_columns.remove(col)\n        multi_label_columns.append(col)","2bf3c993":"def RMSE(pred,y):\n    y = list(y)\n    pred = list(pred)\n    sum0 = 0.0\n    for i in range(len(pred)):\n        sum0 += (pred[i]-y[i])*(pred[i]-y[i])\n    return math.sqrt(sum0\/len(pred))","516e24ba":"df_train = train.drop(\"SalePrice_log\",axis=1)\ndf_test = test.copy()\nprint(two_label_columns)\nfor col in two_label_columns:\n    le = LabelEncoder()\n    df_train[col] = le.fit_transform(df_train[col])\n    df_test[col] = le.transform(df_test[col])\n\ndf_train = pd.get_dummies(df_train,columns=multi_label_columns)\ndf_test = pd.get_dummies(df_test,columns=multi_label_columns)\n","d0de22ec":"print(\"df_train:\",df_train.shape)\ndf_train.head()","c5740a99":"print(\"df_test:\",df_test.shape)\ndf_test.head()","32e8bd40":"df_train,df_test = df_train.align(df_test,join=\"inner\",axis=1)","a0c84343":"train_x, test_x, train_y, test_y = train_test_split(df_train,train[\"SalePrice_log\"])","29283429":"rf = RandomForestRegressor(n_estimators=100)\nrf.fit(train_x,train_y)\npred_x = rf.predict(test_x)\nprint(RMSE(pred_x,test_y))\n\nmissing_num_cols = df_test.select_dtypes([\"float64\",\"int64\"]).isnull().sum()\ndf_test_fill = df_test.copy()\nna_col = missing_num_cols[missing_num_cols>0].index\nfor col in na_col:\n    df_test_fill[col].fillna(df_test_fill[col].mean(),inplace=True)\n\npred_rf = np.expm1(rf.predict(df_test_fill))","0582185d":"xgb = XGBRegressor(objective=\"reg:linear\",max_depth=10,learning_rate=0.1)\nxgb.fit(train_x,train_y)\npred_x = xgb.predict(test_x)\nprint(RMSE(pred_x,test_y))\npred_xgb = np.expm1(xgb.predict(df_test))\n","b2ea4f7e":"Heatmap\nJust for strong-relation columns","4f8fdd2c":"**1.Preparation**\n\nImport all the package we will use first","6847efd7":"Obviously, after the log-transformatoin, target data is more like Normal Distribution. That's better for our research below. So we will use SalePrice_log as target column instead of SalePrice","c66bc94c":"Define the function to calculate RMSE","659c874a":"3) Target variable -- SalePrice (check whether it need to be transformed)","2ff32878":"From the plot, we can know maybe some multiple mutual linear problem\n\ncorr > 0.8, we consider it as high-relation columns\n\n[GrLivArea,TotRmsAbvGrd],[GarageArea,GarageCars], [TotalBsmtSF, 1stFlrSF]\n\ncompare their correlation with SalePrice_log,save the higher one, drop the lower one\n\n[GrLivArea 0.70,TotRmsAbvGrd 0.53], [GarageArea 0.65,GarageCars 0.68], [TotalBsmtSF 0.61, 1stFlrSF 0.60]","d15454eb":"Create four dataset with df_train, so we can validate the model precision.","5b56fa4c":"Load the train\/test data","1c7daf36":"**2. EDA and Data cleaning**\n\n 1) Check missing values in train\/test dataset ","fa608742":"2. Xgboost","c167df8c":"Compare above RMSE, choose the best model to predict. ","fccb2257":"2) Transform some columns type based on its defination","ea18d5f2":"We can see that some columns are including so many missing values. Will update this file later.\nDrop the \"Id\" column first","6fd87bdf":"**Regression Models --(RandomForest, Xgboost and so on)**\n\n1. RandomForest","46127220":"5) Object columns","c78f916b":"df_train has 260 columns while df_test has 255 columns. We should keep the columns same","dbc465cb":"LabelEncode for two-class columns, and one-hot for multi-class columns","b5cfb772":"Check distribution of each feature and remove the feature if one class takes more than 90%","605bae57":"**3.Model building**","a99633f0":"4) Numerical Columns"}}