{"cell_type":{"e83856da":"code","fcb93753":"code","1525a2f3":"code","9e02f429":"code","b21652b9":"code","55561f92":"code","aa15923b":"code","62d204ef":"code","791184b9":"code","8d9d67b3":"code","c1c8f2c0":"code","4341a5f2":"code","e828c883":"code","5975a7a6":"code","3357efc5":"code","31fc106d":"code","b144d370":"code","0745bcb7":"code","d2283662":"code","2498f0bf":"code","fa7f8d65":"code","a8e6249d":"code","f9fb788f":"code","94e9b1ff":"code","9ae24f2c":"code","a1e80ace":"code","a0e6f685":"code","8ddcec20":"code","74e802c5":"code","c6f2738b":"code","521ace8e":"code","4820e0be":"code","78b6ea87":"code","69eb0ab9":"code","ac7fb7c1":"code","ed9cb04a":"code","cf2424de":"code","f800b244":"code","2c9689cd":"code","5cda0723":"code","35d294ea":"code","11b7afd5":"code","d090e395":"code","0dc400f2":"code","0886c444":"code","64c66a7b":"code","f298b2e1":"code","8375504b":"code","ddbea9ec":"code","64de886a":"code","6cdd83ff":"code","b645882a":"code","3192f40b":"code","c718dfe9":"code","26855400":"code","56bcc014":"code","8e68845b":"code","1a9bef68":"code","6e97f764":"code","2628e012":"code","dee4be67":"code","c18ded67":"markdown","51f75731":"markdown","1939d1e8":"markdown","28f27db3":"markdown","5138a8b3":"markdown","2fcfbed3":"markdown","f6fb9e1c":"markdown","8400fe90":"markdown","da403e93":"markdown","720ea64b":"markdown","9739b803":"markdown","c892d33b":"markdown","979207a6":"markdown","8eadc36c":"markdown","44ca85c7":"markdown","5f94b769":"markdown","d1a08c57":"markdown","73f0f1b0":"markdown","e27f4a5c":"markdown","f5a696f1":"markdown","af8ae357":"markdown","57f1c944":"markdown","dff6305c":"markdown","a2a0d20b":"markdown","3c757b9a":"markdown","be95636b":"markdown"},"source":{"e83856da":"# import all the required libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix ","fcb93753":"import warnings\nwarnings.filterwarnings('ignore')","1525a2f3":"sns.set_context('talk')\nsns.set_palette('Paired')\nsns.set(style = 'darkgrid')","9e02f429":"# load the dataset\ndata = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","b21652b9":"# display first few records\ndata.head()","55561f92":"# show the number of records and the number of features\ndata.shape","aa15923b":"# get a basic understanding of the dataset\ndata.info()","62d204ef":"# summarise the count, mean, standard deviation, min and max for numeric features\ndata.describe()","791184b9":"# check for null values\ndata.isnull().sum()","8d9d67b3":"# show duplicate rows in the dataset\ndata[data.duplicated(keep = False)]","c1c8f2c0":"# drop the duplicated row\ndata.drop_duplicates(keep = 'first', inplace = True)","4341a5f2":"# check correlations between all variables\ndata.corr()","e828c883":"# plot corr function\nplt.figure(figsize = (13, 7))\nax = sns.heatmap(data.corr(), vmin = -1, vmax = 1, center = 0, cmap = sns.diverging_palette(20, 220, n = 200), annot = True)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 45, horizontalalignment = 'right')\nplt.show()","5975a7a6":"plt.figure(figsize = (15, 8))\nsns.countplot(x = 'age', hue = 'output', data = data).set_title('Heart Disease Frequency for Ages')\nplt.legend(title = 'Output', loc = 'upper right', labels = ['No Heart Disease', 'Hvae Heart Disease'])\nplt.show()","3357efc5":"plt.figure(figsize = (15, 8))\nax = sns.countplot(x = 'sex', hue = 'output', data = data)\nax.set_xticklabels(['Female', 'Male'])\nax.set_title('Heart Disease Frequency for Gender')\nplt.legend(title = 'Output', loc = 'upper left', labels = ['No Heart Disease', 'Hvae Heart Disease'])\nplt.xlabel('Gender')\nplt.show()","31fc106d":"plt.figure(figsize = (15, 8))\nax = sns.countplot(x = 'sex', hue = 'output', data = data)\nax.set_xticklabels(['Female', 'Male'])\nax.set_title('Heart Disease Frequency for Gender')\nplt.legend(title = 'Output', loc = 'upper left', labels = ['No Heart Disease', 'Hvae Heart Disease'])\nplt.xlabel('Gender')\nplt.show()","b144d370":"# plt.figure(figsize = (55, 10))\nplt.figure(figsize = (15, 8))\nax = sns.countplot(x = 'cp', hue = 'output', data = data)\nax.set_xticklabels(['Typical Angina', 'Atypical angina', 'Non-Anginal Pain', 'Asymptomatic'])\nax.set_title('Heart Disease Frequency According to Chest Pain Type')\nplt.legend(title = 'Output', loc = 'upper right', labels = ['No Heart Disease', 'Have Heart Disease'])\nplt.xlabel('Chest Pain Type')\nplt.show()","0745bcb7":"plt.figure(figsize = (15, 8))\nax = sns.countplot(x = 'fbs', hue = 'output', data = data)\nax.set_xticklabels(['False', 'True'])\nax.set_title('Heart Disease Frequency According to Fasting Blood Sugar')\nplt.legend(title = 'Output', loc = 'upper right', labels = ['No Heart Disease', 'Hvae Heart Disease'])\nplt.xlabel('Fasting Blood Sugar > 120 mg\/dl')\nplt.show()","d2283662":"plt.figure(figsize = (15, 8))\nax = sns.countplot(x = 'slp', hue = 'output', data = data)\nax.set_xticklabels(['Up', 'Flat', 'Down'])\nax.set_title('Heart Disease Frequency According to Fasting Blood Sugar')\nplt.legend(title = 'Output', loc = 'upper left', labels = ['No Heart Disease', 'Hvae Heart Disease'])\nplt.xlabel('ST Segment')\nplt.show()","2498f0bf":"plt.figure(figsize = (15, 8))\nax = sns.countplot(x = 'thall', hue = 'sex', data = data)\nax.set_xticklabels(['No Info', 'Fixed Defect', 'Normal', 'Reversible Defect'])\nax.set_title('Heart Disease Frequency According to Blood Disorder')\nplt.legend(title = 'Gender', loc = 'upper left', labels = ['Female', 'Male'])\nplt.xlabel('ST Segment')\nplt.xlabel('Gender')\nplt.show()","fa7f8d65":"fig, axes = plt.subplots(4, 3, figsize = (17, 15))\nfig.suptitle('Outliers Detection')\nsns.boxplot(ax = axes[0,0], x = data['age'])\nsns.boxplot(ax = axes[0,1], x = data['cp'])\nsns.boxplot(ax = axes[0,2], x = data['trtbps'])\nsns.boxplot(ax = axes[1,0], x = data['chol'])\nsns.boxplot(ax = axes[1,1], x = data['fbs'])\nsns.boxplot(ax = axes[1,2], x = data['restecg'])\nsns.boxplot(ax = axes[2,0], x = data['thalachh'])\nsns.boxplot(ax = axes[2,1], x = data['oldpeak'])\nsns.boxplot(ax = axes[2,2], x = data['slp'])\nsns.boxplot(ax = axes[3,0], x = data['caa'])\nsns.boxplot(ax = axes[3,1], x = data['thall'])","a8e6249d":"# create a new dataframe for normalised dataset\nnormalised_data = data.copy()","f9fb788f":"columns_to_scale = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']","94e9b1ff":"ss = StandardScaler()\nnormalised_data[columns_to_scale] = ss.fit_transform(normalised_data[columns_to_scale])","9ae24f2c":"# label data into feature data and target data\nX = normalised_data.iloc[:, :-1]\ny = normalised_data.iloc[:, -1]","a1e80ace":"# split dataset into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","a0e6f685":"# create instance of model\nlr = LogisticRegression(random_state = 42) ","8ddcec20":"# train the model \nlr.fit(X_train, y_train)","74e802c5":"# get y predictions\ny_pred = lr.predict(X_test)","c6f2738b":"# show performance metrics\nprint(classification_report(y_test, y_pred))","521ace8e":"# print the confusion matrix\nprint (confusion_matrix(y_test, y_pred))","4820e0be":"# create instance of model\nnb = GaussianNB()","78b6ea87":"# train the model\nnb.fit(X_train, y_train)","69eb0ab9":"# get y predictions\ny_pred = nb.predict(X_test)","ac7fb7c1":"# print performance report\nprint(classification_report(y_test, y_pred))","ed9cb04a":"# print the confusion matrix\nprint (confusion_matrix(y_test, y_pred))","cf2424de":"# create an instance\nxgb = XGBClassifier(random_state = 42)","f800b244":"# train the model\nxgb.fit(X_train, y_train)","2c9689cd":"# get y predictions\ny_pred = xgb.predict(X_test)","5cda0723":"# print out the accuracy\nprint(classification_report(y_test, y_pred))","35d294ea":"# print the confusion matrix\nprint (confusion_matrix(y_test, y_pred))","11b7afd5":"# create an instance of model\nrf = RandomForestClassifier(random_state=42, n_estimators=500)","d090e395":"# fit the model\nrf.fit(X_train, y_train)","0dc400f2":"# get y predictions\ny_pred = rf.predict(X_test)","0886c444":"# show accuracy report\nprint(classification_report(y_test, y_pred))","64c66a7b":"# print the confusion matrix\nprint (confusion_matrix(y_test, y_pred))","f298b2e1":"# create an instance\ndt = DecisionTreeClassifier(random_state = 42)","8375504b":"# train model \ndt.fit(X_train, y_train)","ddbea9ec":"# get y predictions\ny_pred = dt.predict(X_test)","64de886a":"# print performance report\nprint(classification_report(y_test, y_pred))","6cdd83ff":"# print the confusion matrix\nprint (confusion_matrix(y_test, y_pred))","b645882a":"# create instance of model\nknn = KNeighborsClassifier()","3192f40b":"# train model \nknn.fit(X_train, y_train)","c718dfe9":"# get y predictions\ny_pred = knn.predict(X_test)","26855400":"# print the accuracy\nprint(classification_report(y_test, y_pred))","56bcc014":"# print the confusion matrix\nprint (confusion_matrix(y_test, y_pred))","8e68845b":"# get instance of the model\nsvm = SVC(random_state = 42)","1a9bef68":"# train the model \nsvm.fit(X_train, y_train)","6e97f764":"# get y predictions\ny_pred = svm.predict(X_test)","2628e012":"# show performance report\nprint(classification_report(y_test, y_pred))","dee4be67":"# print the confusion matrix\nprint (confusion_matrix(y_test, y_pred))","c18ded67":"### Outliers Detection","51f75731":"# Dataset Features:\nThe Output (Positive or Negative diagnosis of Heart Disease) is determined by 13 features:\n1. **age:** age of the patient\n2. **sex:** 1 = male, 0 = female (binary)\n3. **cp:** chest pain type (4 values) Value 0: typical angina, Value 1: atypical angina, Value 2: non-anginal pain, Value 3: asymptomatic\n4. **trestbps:** resting blood pressure\n5. **chol:** serum cholesterol in mg\/dl\n6. **fbs:** fasting blood sugar > 120 mg\/dl (binary) (1 = true; 0 = false)\n7. **restecg:** resting electrocardiography results (values 0, 1, 2)\n8. **thalachh:** maximum heart rate achieved\n9. **exng:** exercise induced angina (binary) (1 = yes, 0 = no)\n10. **oldpeak:** = ST depression induced by exercise relative to rest\n11. **slp:** of the peak exercise ST segment (Value 0: up sloping , Value 1: flat , Value 2: down sloping )\n12. **caa:** number of major vessels (values: 0\u20133)\n13. **thall:** maximum heart rate achieved (0 = no-data, 1 = normal, 2 = fixed defect, 3 = reversible defect)","1939d1e8":"## SVM","28f27db3":"From the above box plots, outliers are present in trtbps, chol, thalachh, oldpeak, caa, thall. Yet, I'm not going to remove them because of the sensitivity and risk of medical data as it's different than the other kind of data. The exclusion of outliers has a dramatic impact on the type I error.","5138a8b3":"So there is a positive correlation between chest pain (cp) and the target. On the other hand there is a negative correlation between exercise induced angina (exang) and the target.","2fcfbed3":"Visualise the correlation matrix to see whether the features are positively or negatively correlated with the target (output).","f6fb9e1c":"In this notebook we trying to predict whether a patient should be diagnosed with Heart Disease or not. This is a binary outcome:<br>\n1. **Positive (1):** patient diagnosed with Heart Disease\n1. **Negative (0):** patient not diagnosed with Heart Disease<br>\n\nMultiple machine learning Models will be applied to see which yields greatest accuracy.","8400fe90":"# Modelling","da403e93":"# Data Visualisation","720ea64b":"As there are no null values in data, we will go ahead with finding duplicates.","9739b803":"## Naives Bayes","c892d33b":"___","979207a6":"## Logistic Regression","8eadc36c":"In this notebook 5 different machine learning algorithms will be evaluated on the dataset for prediction analysis: \n\n1. Logistic Regression (Logistic)\n1. Naive Bayes (NaiveBayes)\n1. Classification and Regression Trees or CART (REPTree)\n1. k-Nearest Neighbors or KNN (IBk)\n1. Support Vector Machines or SVM (SMO)\n1. Random Forest and Desion Trees\n1. XGBoost\n\nEach algorithm will be evaluated using classification accuracy, to measure the performance of each model. First step in the data modelling is to label the dataset with X (matrix of independent variables) and y (vector of the dependent variable). Then create an instance of the model to train and fit the model, then calculate predictions of test set in order to get the classification report.","44ca85c7":"# Heart Disease Analysis and Prediction","5f94b769":"# Data Exploration","d1a08c57":"# Data Cleaning","73f0f1b0":"Before providing the dataset to any model, it is essential to check outliers and transform it so that its distribution will have a mean of 0 and a standard deviation of 1.","e27f4a5c":"# Data Preprocessing","f5a696f1":"Since most of the machine learning algorithms use Euclidean distance between two data points in their computations, this is a problem. To suppress this effect, we need to bring all features to the same level of magnitudes. This can be achieved by a method called feature scaling.","af8ae357":"## Random Forest","57f1c944":"## KNN","dff6305c":"## Decision Trees","a2a0d20b":"### Normalisation","3c757b9a":"## XGBoost","be95636b":"Most of the Heart Disease patients are found to have asymptomatic chest pain. These group of people might show atypical symptoms like indigestion, flu or a strained chest muscle."}}