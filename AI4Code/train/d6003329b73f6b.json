{"cell_type":{"bcbf37ce":"code","2c26b4ed":"code","9c3ca437":"code","43d8aeca":"code","e8c134ca":"code","c5835f39":"code","cd9e0f53":"code","3642d10f":"code","273e1d01":"code","f251aff4":"code","1310288b":"code","e26a68b8":"code","4e461fe9":"code","9370d659":"code","fc6cd0f3":"code","90d56fe5":"code","fe389106":"code","3cf367ac":"code","59bad0fa":"code","4c144bb5":"code","cda9cac0":"code","8b7a2a6a":"code","2add649e":"code","0ed9eef1":"markdown","db952b8e":"markdown","48ecc9b8":"markdown","8636e06f":"markdown","ce37cbda":"markdown","b6b472ab":"markdown","4b68d5ee":"markdown","97a12595":"markdown","3fe6dfbc":"markdown","062889ed":"markdown","6175017d":"markdown","958785ed":"markdown","9513c955":"markdown","cd81cb2d":"markdown","cf06aa9f":"markdown","c30b0db4":"markdown","6a6de312":"markdown","c688bf88":"markdown","688e4dc1":"markdown","5b96e5b5":"markdown"},"source":{"bcbf37ce":"import pandas as pd\nx=pd;print(x.__name__, \"version:\", x.__version__)\nimport numpy as np\nx=np;print(x.__name__, \"version:\", x.__version__)\nimport scipy\nx=scipy;print(x.__name__, \"version:\", x.__version__)\nimport sklearn\nx=sklearn;print(x.__name__, \"version:\", x.__version__)\nimport xgboost as xgb\nx=xgb;print(x.__name__, \"version:\", x.__version__)\nimport lightgbm as lgb\nx=lgb;print(x.__name__, \"version:\", x.__version__)\nimport keras\nx=keras;print(x.__name__, \"version:\", x.__version__)\nimport tensorflow as tf\nx=tf;print(x.__name__, \"version:\", x.__version__)\nimport torch\nx=torch;print(x.__name__, \"version:\", x.__version__)\nimport matplotlib\nimport matplotlib.pyplot as plt\nx=matplotlib;print(x.__name__, \"version:\", x.__version__)\nimport seaborn as sns\nx=sns;print(x.__name__, \"version:\", x.__version__)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, mean_squared_error\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\nimport os, sys, math, datetime, shutil, pickle\nfrom IPython.core.interactiveshell import InteractiveShell","2c26b4ed":"if not os.path.isfile(\"..\/working\/data_tools.py\"):\n    shutil.copyfile(src = \"..\/input\/python-modules\/data_tools.py\", dst = \"..\/working\/data_tools.py\")\nimport data_tools as dt","9c3ca437":"InteractiveShell.ast_node_interactivity = \"all\"\n%matplotlib inline\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 10)\nplt.style.use('seaborn-poster')\nsns.set(palette='deep')\nsns.set(context='poster')","43d8aeca":"ScriptName = \"EDA HousePrices\"\nScriptFile = \"eda_houseprices.ipynb\"\nScriptDescription = \"A Jupyter notebook for EDA and basic prediction of house prices\"\n\nrun_first = []\n\nanalysis = dt.Analysis(inputs='..\/input\/house-prices-advanced-regression-techniques')\nanalysis\n\n#Script Input Variables\ninfiles = analysis.inputs\n\ninfile_train = analysis.train\ninfile_test =  analysis.test\noutfile_final = analysis.final_output\nindex = analysis.ids\ntarget = analysis.target\n\nmodel = Ridge(random_state=0, alpha=0.01)\n\nalso_predict = True\ntrain_validation_ratio = 5\n","e8c134ca":"{os.path.splitext(x)[0]:'..\/input\/house-prices-advanced-regression-techniques' + x for x in os.listdir('..\/input\/house-prices-advanced-regression-techniques') if os.path.splitext(x)[1] == '.csv' and x != 'sample_submission.csv'}","c5835f39":"# if not os.path.isfile(ScriptFile):\n#     raise FileNotFoundError(ScriptFile)\n# for file in run_first:\n#     if not os.path.isfile(file):\n#         raise FileNotFoundError(file)\nif not os.path.isfile(infile_train):\n    raise FileNotFoundError(infile_train)\nif not os.path.isfile(infile_test):\n    raise FileNotFoundError(infile_test)\nprint(\"Running:\", ScriptName, \"in file:\", ScriptFile)\nprint(\"Inputs:\", infile_train, infile_test)\nprint(\"Final Output:\", outfile_final)\nprint(\"Model:\", model)","cd9e0f53":"df_train = dt.load_df(infile_train, index=index, name='train')\nfeatures = list(df_train.columns)\nfeatures.remove(target)\ndf_train.head()","3642d10f":"found = 0\nunique = df_train.nunique()\nfor n in [x for x in unique.unique() if len(unique[unique==x]) > 1]:\n    idx = unique[unique==n].index\n    unique_same_size = df_train[idx].apply(pd.factorize)\n    for col1 in idx:\n        for col2 in idx:\n            if col2 != col1:\n                if ((unique_same_size[col2][0]==unique_same_size[col1][0]).all()):\n                    print('col: ', col2, 'equals col:', col1)\n                    found += 1\nif found:\n    print(\"%s Equal factorized columns found\" % found)\nelse:\n    print(\"All columns are distinct\")\nif(1 in unique):\n    print(\"Some columns have just one unique value: %s\" % unique[unique==1])\nelse:\n    print(\"No columns have just one unique value\")","273e1d01":"df_test = dt.load_df(infile_test, index=index, name='test')\ndf_test.head()","f251aff4":"if set(df_test.columns) == set(features):\n    print(\"Train and test sets have same features\")\nelse:\n    if set(df_test.columns) - set(features):\n        print(\"Features in test set that are not in train set:\", set(df_test.columns) - set(features))\n    if set(features) - set(df_test.columns):\n        print(\"Features in test set that are not in train set:\", set(df_test.columns) - set(features))","1310288b":"pvalues = pd.DataFrame(columns=['p'])\npvalues.index.name='Feature'\nfor col in features:\n    if df_train[col].dtype != np.object:\n        d, p = scipy.stats.ks_2samp(df_train[col].values, df_test[col].values)\n        pvalues.loc[col,'p'] = p\n    else:#factorize categorical features over all train\/test data\n        l = len(df_train[col])\n        fl = pd.factorize(list(df_train[col]) + list(df_test[col]))\n        d, p = scipy.stats.ks_2samp(fl[0][:l], fl[0][l:])\n        pvalues.loc[col, 'p'] = p        \nprint(\"Columns in which train distribution differs significantly from test distribution at an alpha of 5%\")\nsignificant = pvalues[pvalues.p <= 0.05]\nsignificant\nif(len(significant) == 0):\n    print(\"Test and Train data likely are identically distributed\")","e26a68b8":"one_hot_features = [x for x in df_train.columns if np.dtype(df_train[x])==np.object and df_train[x].nunique() > 2]\ncol1=dt.one_hot(df=df_train, columns=one_hot_features, abbr=True)\ncol2=dt.one_hot(df=df_test, columns=one_hot_features, abbr=True)\nfeatures = list(df_test.columns)","4e461fe9":"df_ftrain = df_train.copy()\ndf_ftest = df_test.copy()\nfor col in features:\n    l = len(df_train[col])\n    if df_ftrain[col].dtype == np.object:\n        fl = pd.factorize(list(df_train[col]) + list(df_test[col]))[0]\n        df_ftrain[col] = fl[:l]\n        df_ftest[col] = fl[l:]","9370d659":"df_ftrain = df_ftrain.reindex_axis(df_ftrain.corrwith(other=df_ftrain[target]).abs().sort_values(ascending=False).index, axis=1)","fc6cd0f3":"corr = df_ftrain.corr()\nsns.heatmap(corr)","90d56fe5":"corr\nbest_features = [x for x in corr.columns if np.abs(corr.loc[target, x]) >= 0.1]\nif target in best_features:\n    best_features.remove(target)\nbest_features","fe389106":"df_ftrain.fillna(df_ftrain.mean(), inplace=True)\ndf_ftest.fillna(df_ftrain.mean(), inplace=True)\nrs = sklearn.model_selection.ShuffleSplit(n_splits=20, random_state=0, train_size=(train_validation_ratio-1.0)\/train_validation_ratio, test_size=1.0\/train_validation_ratio)\nscores = []\nfor train_idx, test_idx in rs.split(df_train[features], df_train[target]):\n    df_vtrain = df_ftrain.iloc[train_idx]\n    df_vtest = df_ftrain.iloc[test_idx].copy()\n    model = model.fit(df_vtrain[best_features], np.log(1+df_vtrain[target]))\n    df_vtest['PredictedSalePrice'] = model.predict(df_vtest[best_features])\n    score = mean_squared_error(np.log(1+df_vtest[target]), df_vtest['PredictedSalePrice'])\n    scores.append(score)\npd.DataFrame(scores).describe()\nscore = pd.DataFrame(scores).describe().iloc[6,0]\nprint(\"Validation score:\", score)","3cf367ac":"if also_predict:\n    model.fit(df_ftrain[best_features], np.log(1+df_ftrain[target]))","59bad0fa":"if also_predict:\n    df_ftest[target] = model.predict(df_ftest[best_features])","4c144bb5":"if also_predict:\n    result = np.exp(df_ftest[[target]])-1\n    result.head()","cda9cac0":"#os.makedirs(os.path.dirname(outfile_final), exist_ok=True)\n#Kaggle won't let you write to ..\/output, so write to $CWD instead.\noutfile_final = 'submission.csv'\nif also_predict:\n    cols = list(analysis.submission_fields)\n    if analysis.main_id in cols:\n        cols.remove(analysis.main_id)\n    dt.validate_submission(df=result, cols=cols, index=analysis.main_id, mins=[0,0], maxes=[100000000, 100000000])\n    result.to_csv(outfile_final, index=True)","8b7a2a6a":"#useful on home computer, not on Kaggle kernel\n\n# if also_predict:\n#     d = '..\/provisional\/'+datetime.datetime.today().strftime(\"%Y%m%d\") + '_' + str(score)\n#     try:\n#         os.makedirs(d)\n#     except FileExistsError:\n#         print(\"Not making directory:\", d, \"-- directory exists\")\n#     for f in run_first + [ScriptFile]:\n#         try:\n#             shutil.copyfile(f, d + '\/' + f )\n#         except FileExistsError:\n#             print(\"Not copying:\", f, 'to:', d + '\/' + f,'-- file exists' )\n#     f = 'submission.csv'\n#     try:\n#         shutil.copyfile('..\/output\/' + f, d + '\/' + f )\n#     except FileExistsError:\n#         print(\"Not copying ..\/output\/\" + f, 'to:', d + '\/' + f,'-- file exists' )","2add649e":"print(\"Validation score:\", score)\ntry:\n    best_score = pickle.load(open('best_score.p', 'rb'))\n    print(\"Previous best:   \", best_score)\n    if score < best_score:\n        print(\"New best! Improved by: %s%%\" % (math.floor(10000.0*(best_score - score)\/best_score)\/100.0,))\n        best_score = score\n        pickle.dump(best_score, open('best_score.p', 'wb'))\n    elif score == best_score:\n        print(\"Score equals previous best\")\n    else:\n        print(\"Score is worse than previous best\")\nexcept FileNotFoundError:\n    best_score = score\n    pickle.dump(best_score, open('best_score.p', 'wb'))","0ed9eef1":"## Factorize train and test data for further analysis","db952b8e":"## Reorder columns of factorized train data so highest correlation with target value comes first","48ecc9b8":"## Check if train and test data have the same features","8636e06f":"## Input Parameters","ce37cbda":"## Compute and display correlation between columns of training data","b6b472ab":"## Useful Imports","4b68d5ee":"## Check that train and test have similar distributions","97a12595":"## Load training data and get list of features","3fe6dfbc":"## Validation of Input Parameters","062889ed":"## Save result to file","6175017d":"## Fit all the factorized training data to the model","958785ed":"## Set Some Options","9513c955":"## Look for columns with just one unique value and pairs of columns that are the same data","cd81cb2d":"## Validate the model","cf06aa9f":"## Load test data","c30b0db4":"## I added my python utilities module as a \"data file\"; now copy it to the working directory and import it[](http:\/\/)","6a6de312":"# **EDA and Basic Model for Housing Prices**","c688bf88":"## Use model to predict on test set","688e4dc1":"## Process test predictions to match processing of training predictions and generate output dataframe","5b96e5b5":"## Find the best features"}}