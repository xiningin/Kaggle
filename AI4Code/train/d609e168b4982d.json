{"cell_type":{"77f8ee4d":"code","079bb821":"code","2d0bbddc":"code","83c3f583":"code","a2c30449":"code","6f12af54":"code","fc92b612":"code","a06509f0":"code","88d79d02":"code","bbf82bd8":"code","0dc9aa35":"code","5af85e04":"code","94fde43f":"code","f8a1a9de":"code","36103e84":"code","eba1b6e8":"code","58e8e58a":"code","1ad04f2c":"code","97b474da":"code","38b36fce":"code","8bc72081":"code","2991857c":"code","4e48938c":"code","3e6089f8":"code","de16cb5c":"code","81fb773b":"code","844a4efe":"code","8e8e01da":"code","0767d105":"code","d7c04a50":"code","c10394da":"code","3b280d5f":"code","5064ef18":"code","4f124b27":"code","cbbe3416":"code","0655d875":"code","dcf434c4":"code","0a2cb6b8":"code","14c62b32":"code","9587bea1":"code","f660ec8a":"code","b0b018a4":"code","bc486f48":"code","300728ac":"code","6820b943":"code","306fca04":"code","8282b807":"code","58b5f16b":"markdown","f915f61e":"markdown","4ecd4512":"markdown","c8c3718c":"markdown","21e24eed":"markdown","13be5c1b":"markdown","c2f56bba":"markdown"},"source":{"77f8ee4d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport IPython\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","079bb821":"fundamentals= pd.read_csv('..\/input\/nyse\/fundamentals.csv')","2d0bbddc":"fundamentals.head()","83c3f583":"pricesa_data= pd.read_csv('..\/input\/nyse\/prices-split-adjusted.csv')\npricesa_data.head()","a2c30449":"price_data= pd.read_csv('..\/input\/nyse\/prices.csv')\nprice_data.head()","6f12af54":"security_data= pd.read_csv('..\/input\/nyse\/securities.csv')\nsecurity_data.head()","fc92b612":"#Industry-wise tabulation of number of companies given in the fundamentals data\nplt.figure(figsize=(15, 6))\nax = sns.countplot(y='GICS Sector', data=security_data)\nplt.xticks(rotation=45)","a06509f0":"price_data.info()","88d79d02":"len(price_data.symbol.unique())","bbf82bd8":"#let's make a function that'll plot the opening and closing chart for the company chosen\n\ndef chart(ticker):\n    global closing_stock\n    global opening_stock\n    f, axs = plt.subplots(2,2,figsize=(16,8))\n    plt.subplot(212)\n    company = price_data[price_data['symbol']==ticker]\n    company = company.open.values.astype('float32')\n    company = company.reshape(-1, 1)\n    opening_stock = company\n    plt.grid(True)\n    plt.xlabel('Time')\n    plt.ylabel(ticker + \" open stock prices\")\n    plt.title('prices Vs Time')\n    \n    plt.plot(company , 'g')\n    \n    plt.subplot(211)\n    company_close = price_data[price_data['symbol']==ticker]\n    company_close = company_close.close.values.astype('float32')\n    company_close = company_close.reshape(-1, 1)\n    closing_stock = company_close\n    plt.xlabel('Time')\n    plt.ylabel(ticker + \" close stock prices\")\n    plt.title('prices Vs Time')\n    plt.grid(True)\n    plt.plot(company_close , 'b')\n    \n    plt.show()\nticker = input(\"Enter the ticker of the company you want to see the graph for -\")\nchart(ticker)","0dc9aa35":"#make a data-frame that'll have details for the company chosen\nticker_data= price_data[price_data['symbol']==ticker]","5af85e04":"#this checks the amount of data we've for the company chosen\ntrain_dates=list(ticker_data.date.unique())\nprint(f\"Period : {len(ticker_data.date.unique())} days\")\nprint(f\"From : {ticker_data.date.min()} To : {ticker_data.date.max()}\")","94fde43f":"#importing libraries\nimport math\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense , BatchNormalization , Dropout , Activation\nfrom keras.layers import LSTM , GRU\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom keras.optimizers import Adam , SGD , RMSprop","f8a1a9de":"data=ticker_data.copy()","36103e84":"data.head()","eba1b6e8":"data.drop(['symbol','open','low','high','volume'],axis=1,inplace=True)","58e8e58a":"data.head()","1ad04f2c":"data['date'] = pd.to_datetime(data['date'], infer_datetime_format=True)\n","97b474da":"data.index=data.date","38b36fce":"data.drop('date', axis=1,inplace=True)","8bc72081":"data.head()","2991857c":"dataset=data.values","4e48938c":"#scale the dataset\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","3e6089f8":"#we'll use 80% of the data as training data \ntrain = int(len(dataset) * 0.80)\ntest = len(dataset) - train","de16cb5c":"print(train, test)","81fb773b":"train= dataset[:train]\ntest = dataset[len(train):]","844a4efe":"train.shape","8e8e01da":"test.shape","0767d105":"#I'll use past two days data to predict the price for next day. I tried a few numbers and this was giving least error. Therefore, I thought of using this.\nx_train, y_train = [], []\nfor i in range(len(train)-2):\n    x_train.append(dataset[i:i+2,0])\n    y_train.append(dataset[i+2,0])\nx_train, y_train = np.array(x_train), np.array(y_train)","d7c04a50":"x_train.shape","c10394da":"x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\nx_train.shape","3b280d5f":"x_train.shape","5064ef18":"x_test = []\ny_test=[]\nfor i in range(len(test)-2):\n    x_test.append(dataset[len(train)-2+i:len(train)+i,0])\n    y_test.append(dataset[len(train)+i,0])\nx_test = np.array(x_test)\ny_test = np.array(y_test)","4f124b27":"x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\nx_test.shape","cbbe3416":"#I've used a LSTM model to predict the stock price. i checked for various other models but this was giving the least error. Therefore, I've used that\nmodel= Sequential([\n                   LSTM(256, input_shape=(x_train.shape[1],1), return_sequences=True),\n                   Dropout(0.4),\n                   LSTM(256),\n                   Dropout(0.2),\n                   Dense(16, activation='relu'),\n                   Dense(1)\n])\nprint(model.summary())","0655d875":"model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.0005) , metrics = ['mean_squared_error'])","dcf434c4":"history = model.fit(x_train, y_train, epochs=40 , batch_size = 128, validation_data=(x_test, y_test))","0a2cb6b8":"#summarize history for error\nplt.plot(history.history['mean_squared_error'])\nplt.plot(history.history['val_mean_squared_error'])\nplt.title('model mean squared error')\nplt.ylabel('Error')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','test'], loc='upper left')\nplt.show()","14c62b32":"#using the model for x_test and then converting the data to normal price using inverse transform\npredicted_price= model.predict(x_test)\npredicted_price = scaler.inverse_transform(predicted_price)","9587bea1":"len(predicted_price)","f660ec8a":"predicted_price =np.array(predicted_price)\npredicted_price.shape","b0b018a4":"y_test.shape","bc486f48":"#checking the score for our data\ndef model_score(model, X_train, y_train, X_test, y_test):\n    trainScore = model.evaluate(X_train, y_train, verbose=0)\n    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n    testScore = model.evaluate(X_test, y_test, verbose=0)\n    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n    return trainScore[0], testScore[0]\n\nmodel_score(model, x_train, y_train , x_test, y_test)","300728ac":"predicted_price[:10]","6820b943":"y_test = y_test.reshape(y_test.shape[0] , 1)\ny_test = scaler.inverse_transform(y_test)\ny_test[:10]","306fca04":"#comparing the first 10 values of prediction for our data\ndiff = predicted_price-y_test\ndiff[:10]","8282b807":"#plotting the courves for the actual test values and the predicted values. \n#The actual values are represented by the blue line and the predicted value by the red line\nprint(\"Red - Predicted Stock Prices  ,  Blue - Actual Stock Prices\")\nplt.rcParams[\"figure.figsize\"] = (15,7)\nplt.plot(y_test , 'b')\nplt.plot(predicted_price , 'r')\nplt.xlabel('Time')\nplt.ylabel('Stock Prices')\nplt.title('Check the accuracy of the model with time')\nplt.grid(True)\nplt.show()","58b5f16b":"The final plot gives the inference that our model has done pretty well in predicting the stock price for the chosen company(i.e. Microsoft).","f915f61e":"Now, we'll focus on one company for which we want to predict the stock price for. Enter the ticker code of that company and we'll use that for all our analysis and prediction.","4ecd4512":"The profit or loss calculation is usually determined by the closing price of a stock for the day, hence we will consider the closing price as the target variable and drop the other columns.","c8c3718c":"Now, the dtype of date is object. We'll convert that into date-time and will make it as the index for our dataframe.","21e24eed":"Since we just have to predict the stock price for next day, we'll need only 'price_data' because that has the information regarding stock price and that's our point of concern.","13be5c1b":"I will use LSTM to predict the stock price because LSTM stores the past information in predicting the future.","c2f56bba":"Since the MSE and RMSE is quite less for both: the training as well as the test data, our model does a great job."}}