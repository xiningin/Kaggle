{"cell_type":{"1bc0dc41":"code","e8c8ffe5":"code","d35b8e8a":"code","50d22313":"code","033adf04":"code","14bac1c4":"code","25700847":"code","dbe25e15":"code","27a7ec4b":"code","b7707a0e":"code","175d76d7":"code","efb7deb6":"code","069ea7df":"code","5b4b43b2":"code","8d378bfa":"code","24df73ef":"code","0839f61f":"code","737383de":"code","af8bcea6":"code","e02def58":"code","684d0d6f":"code","5daa6a5d":"code","12f27d76":"code","727beb37":"code","7b616964":"code","9f4eb7df":"code","84413adb":"code","10a2df0b":"code","5d35f0aa":"code","7054f126":"code","877219c8":"code","08a31584":"code","29b9f2c9":"code","c551d524":"code","ca3c3e5e":"code","6a78569b":"code","1e291c51":"code","51644470":"code","6f1b69a4":"code","a7c4b245":"code","170fdf8c":"code","bc981a34":"code","45bdd1e5":"code","7b56960f":"code","9cbe1c3d":"code","2c550e12":"code","ae0a8d3d":"code","967b0d5c":"code","af41f96e":"code","98a1881e":"code","8faa4785":"code","7e6c6197":"code","dab8ca4d":"markdown","6626d751":"markdown","56721859":"markdown","61fb18f7":"markdown","b2c046ea":"markdown","2eaef6eb":"markdown","95f807b0":"markdown","8ea18776":"markdown","72522bcc":"markdown","ad532024":"markdown","63d0ab86":"markdown","d3bd9ba8":"markdown","c4e40fbc":"markdown","3e5b1b1a":"markdown","10b97025":"markdown","7005ede9":"markdown","de42e009":"markdown"},"source":{"1bc0dc41":"import sys\nimport scipy\nimport pandas as pd \nimport numpy as np \nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport statsmodels.formula.api as sm\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, Flatten\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e8c8ffe5":"import warnings  \nwarnings.filterwarnings('ignore')","d35b8e8a":"#reading data\nraw_data = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\nraw_data.head()","50d22313":"#Once the set is loaded, check its size and preview each observation to check if everything loaded correctly.:\nraw_data.shape\nprint(str(raw_data.shape[0]) + ' rows.')\nprint(str(raw_data.shape[1]) + ' columns.')","033adf04":"#Checking the types of each variable.:\nraw_data.dtypes","14bac1c4":"#This summary will be our starting point for further analysis.:\nraw_data.describe().T\n","25700847":"raw_data.columns","dbe25e15":"# Drop the id column\nraw_data=raw_data.drop('id', axis=1)\nraw_data.head()\n","27a7ec4b":"nulls_summary = pd.DataFrame(raw_data.isnull().any(), columns=['Nulls'])   \nnulls_summary['Num_of_nulls [qty]'] = pd.DataFrame(raw_data.isnull().sum())   \nnulls_summary['Num_of_nulls [%]'] = round((raw_data.isnull().mean()*100),2)\nnulls_summary","b7707a0e":"str(round(raw_data.isnull().any(axis=1).sum()\/raw_data.shape[0]*100,2))+'% observations contain missing values in the data..'","175d76d7":"#We replace the value of 'Nan'\n#with the median of the other column values present in the dataset.\n\nmedian = raw_data['bmi'].median()\nprint(median)\nraw_data['bmi'].fillna(median, inplace=True)","efb7deb6":"#50% have a body mass index less than or equal to 28.1 and \n#the remaining 50% have a whole body mass index equal to or greater than 28.1.\nraw_data","069ea7df":"#So now no 'Nan' values present in the data\n\nraw_data.isnull().sum()","5b4b43b2":"raw_data.info()","8d378bfa":"#The \"age\" variable:\n# Histogram\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.distplot(raw_data['age'], kde = False, bins = 30, color = '#eb6c6a').set(title = 'Histogram - \"age\"', xlabel = 'age', ylabel = 'number of observations')\nplt.show()","24df73ef":"# Density graph\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.kdeplot(raw_data['age'], shade = True, color = '#eb6c6a').set(title = 'Density graph - \"age\"', xlabel = 'atak', ylabel = '')\nplt.show()","0839f61f":"# Box plot\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.boxplot(raw_data['age'], color = '#eb6c6a').set(title = 'Box plot - \"age\"', xlabel = 'age')\nplt.show()","737383de":"# Test for normality of distribution\n# Assumed significance level alpha = 0.05.\nif(scipy.stats.normaltest(raw_data['age'])[1] < 0.05):\n    print('The variable does not come from the normal distribution, therefore use an alternative assumption.')\nelse:\n    print('The variable fits the normal distribution therefore use this assumption')","af8bcea6":"#The \"bmi\" variable:\n# Histogram\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.distplot(raw_data['bmi'], kde = False, bins = 30, color = '#eb6c6a').set(title = 'Histogram - \"bmi\"', xlabel = 'bmi', ylabel = 'number of observations')\nplt.show()","e02def58":"# Density graph\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.kdeplot(raw_data['bmi'], shade = True, color = '#eb6c6a').set(title = 'Density graph - \"bmi\"', xlabel = 'bmi', ylabel = '')\nplt.show()","684d0d6f":"# Box plot\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.boxplot(raw_data['bmi'], color = '#eb6c6a').set(title = 'Box plot - \"bmi\"', xlabel = 'bmi')\nplt.show()","5daa6a5d":"# Test for normality of distribution\n# Assumed significance level alpha = 0.05.\nif(scipy.stats.normaltest(raw_data['bmi'])[1] < 0.05):\n    print('The variable does not come from the normal distribution, therefore use an alternative assumption')\nelse:\n    print('The variable fits the normal distribution therefore use this assumption')","12f27d76":"#The \"avg_glucose_level\" variable:\n# Histogram\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.distplot(raw_data['avg_glucose_level'], kde = False, bins = 30, color = '#eb6c6a').set(title = 'Histogram - \"avg_glucose_level\"', xlabel = 'avg_glucose_level', ylabel = 'number of observations')\nplt.show()","727beb37":"# Density graph\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.kdeplot(raw_data['avg_glucose_level'], shade = True, color = '#eb6c6a').set(title = 'Density graph - \"avg_glucose_level\"', xlabel = 'avg_glucose_level', ylabel = '')\nplt.show()","7b616964":"# Box plot\nplt.figure(figsize=(13,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.boxplot(raw_data['avg_glucose_level'], color = '#eb6c6a').set(title = 'Box plot - \"avg_glucose_level\"', xlabel = 'avg_glucose_level')\nplt.show()","9f4eb7df":"# Test for normality of distribution\n# Assumed significance level alpha = 0.05.\nif(scipy.stats.normaltest(raw_data['avg_glucose_level'])[1] < 0.05):\n    print('The variable does not come from the normal distribution, therefore use an alternative assumption.')\nelse:\n    print('The variable fits the normal distribution therefore use this assumption.')\n    ","84413adb":"print('Distribution of the \"gender\" variable:')\nprint(raw_data['gender'].value_counts(normalize = True))","10a2df0b":"plt.figure(figsize=(10,7))\nsns.set(font_scale=1.4)\nsns.countplot(raw_data['gender'], palette = 'Blues_d', order = raw_data['gender'].value_counts().index).set(title = 'Density graph - \"gender\"', xlabel = 'gender', ylabel = 'number of observations')\nplt.show()","5d35f0aa":"#The \u201ework_type\u201d variable\n\nprint('Distribution of the \"work_type\" variable:')\nprint(raw_data['work_type'].value_counts(normalize = True))","7054f126":"plt.figure(figsize=(10,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.countplot(raw_data['work_type'], palette = ['#eb6c6a', '#f0918f', '#f2a3a2', '#f5b5b4', '#f7c8c7']).set(title = 'Density graph - \"work_type\"', xlabel = 'work_type', ylabel = 'number of observations')\nplt.show()","877219c8":"#The \u201esmoking_status\u201d variable\n\nprint('Distribution of the \"smoking_status\" variable:')\nprint(raw_data['smoking_status'].value_counts(normalize = True))","08a31584":"plt.figure(figsize=(10,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.countplot(raw_data['smoking_status'], palette = ['#eb6c6a', '#f0918f', '#f2a3a2', '#f5b5b4', '#f7c8c7']).set(title = 'Density graph - \"smoking_status\"', xlabel = 'smoking_status', ylabel = 'number of observations')\nplt.show()\n","29b9f2c9":"#The \u201eResidence_type\u201d variable\n\nprint('Distribution of the \"Residence_type\" variable:')\nprint(raw_data['Residence_type'].value_counts(normalize = True))","c551d524":"plt.figure(figsize=(10,7))\nsns.set(font_scale=1.4, style=\"whitegrid\")\nsns.countplot(raw_data['Residence_type'], palette = \"deep\").set(title = 'Density graph - \"Residence_type\"', xlabel = 'Residence_type', ylabel = 'number of observations')\nplt.show()","ca3c3e5e":"#The \u201eever_married\u201d variable\n\nprint('Distribution of the \"ever_married\" variable:')\nprint(raw_data['ever_married'].value_counts(normalize = True))\n","6a78569b":"plt.figure(figsize=(10,7))\nsns.set(font_scale=1.4,style=\"whitegrid\")\nsns.countplot(raw_data['ever_married'], palette=\"deep\").set(title = 'Density graph - \"ever_married\"', xlabel = 'ever_married', ylabel = 'number of observations')\nplt.show()","1e291c51":"corr_num = pd.DataFrame(scipy.stats.spearmanr(raw_data.select_dtypes(include = ['float', 'int']))[0],\n                        columns = raw_data.select_dtypes(include = ['float', 'int']).columns,\n                        index = raw_data.select_dtypes(include = ['float', 'int']).columns)\n\nplt.figure(figsize=(15,6))\nsns.set(font_scale=1)\nsns.heatmap(corr_num.abs(), cmap=\"Reds\", linewidths=.5).set(title=\"Heatmap of Spearman's rank correlation coefficient\")\nplt.show()","51644470":"def CramersV(tab):\n    a = scipy.stats.chi2_contingency(tab)[0]\/sum(tab.sum())\n    b = min(tab.shape[0]-1, tab.shape[1]-1,)\n    return(np.sqrt(a\/b))\n\ndef CalculateCrammersV(tab):\n    ret = []\n    for m in tab:\n        row = []\n        for n in tab:\n            cross_tab = pd.crosstab(tab[m].values,tab[n].values)\n            row.append(CramersV(cross_tab))\n        ret.append(row)\n    return pd.DataFrame(ret, columns=tab.columns, index=tab.columns)\ncrammer = CalculateCrammersV(raw_data[['gender', 'ever_married', 'work_type','Residence_type','smoking_status']])\n\nplt.figure(figsize=(15,6))\nsns.set(font_scale=1.4)\nsns.heatmap(crammer, cmap=\"Reds\", linewidths=.5).set(title='Heatmap of the Crammer dependency coefficient')\nplt.show()","6f1b69a4":"raw_data = raw_data[raw_data[\"gender\"].str.contains(\"Other\")==False]\n","a7c4b245":"raw_data['gender'] = raw_data['gender'].map({'Male':0, 'Female':1})\nraw_data['Residence_type'] = raw_data['Residence_type'].map({'Urban':0, 'Rural':1})\nraw_data['smoking_status'] = raw_data['smoking_status'].map({'formerly smoked':2, 'never smoked':0, 'smokes':1, 'Unknown':3})\nraw_data['ever_married'] = raw_data['ever_married'].map({'Yes':1, 'No':0})\nraw_data['work_type'] = raw_data['work_type'].map({'Private':0, 'Self-employed': 1, 'Govt_job':2, 'children':3, 'Never_worked':4})\nraw_data.info()","170fdf8c":"#plot heat map\nplt.figure(figsize=(14,10))\nsns.heatmap(raw_data.corr(method='pearson'), annot=True)\nplt.show() ","bc981a34":"sns.catplot(x='stroke', y=\"age\", hue = 'gender', kind=\"box\", data=raw_data)","45bdd1e5":"## Now we want built a model so we split the data into X and Y planes:\nX = raw_data.drop(['stroke'], axis=1)\nY = raw_data.stroke\n\nX.head()\nY.head()","7b56960f":"print(f'X shape: {X.shape}')\nprint(f'Y shape: {Y.shape}')","9cbe1c3d":"#Split the dataset into training and test datasets.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\nX_train.shape, X_test.shape, Y_train.shape, Y_test.shape","2c550e12":"#Build a the base model\nbaseline_model = Sequential()\nbaseline_model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\nbaseline_model.add(Dense(7, activation='relu'))\nbaseline_model.add(Dense(1, activation='sigmoid'))","ae0a8d3d":"baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nbaseline_history = baseline_model.fit(X_train, Y_train, epochs=100, batch_size=30, verbose=0)","967b0d5c":"#Evaluate the accuracy of the model based on the test dataset.\nloss, acc = baseline_model.evaluate(X_test, Y_test, verbose=0)\nprint('Test accuracy: %.3f' % acc)\n","af41f96e":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import KFold\n\n# Define the K-fold Cross Validator\n\nkfold = KFold(n_splits=10, shuffle=True)\nacc_per_fold =[]\nloss_per_fold=[]","98a1881e":"#K-fold Cross Validation model evaluation\nfold_no = 1\n'X shape: {X.shape}'\n\n  ","8faa4785":"for train, test in kfold.split(X, Y):\n    \n  train=[x for x in train.tolist() if x in X.index.values.tolist()]\n  test=[x for x in test.tolist() if x in X.index.values.tolist()]\n  \n  # Define the model architecture\n  model = Sequential()\n  model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n  model.add(Dense(7, activation='relu'))\n  model.add(Dense(1, activation='sigmoid'))\n\n\n  # Compile the model\n  model.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['accuracy'])\n\n  # Generate a print\n  print('------------------------------------------------------------------------')\n  print(f'Training for fold {fold_no} ...')\n  \n  # Fit data to model\n  history = model.fit(X.loc[train], Y.loc[train],\n              batch_size=30,\n              epochs=15,\n              verbose=1)\n  '''We next replace the \u201ctest loss\u201d print with one related to what we\u2019re doing. \n  Also, we increase the fold_no:'''\n  # Generate generalization metrics\n  scores = model.evaluate(X.loc[train], Y.loc[train], verbose=1)\n  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n  acc_per_fold.append(scores[1] * 100)\n  loss_per_fold.append(scores[0])\n\n  # Increase fold number\n  fold_no = fold_no + 1\n# == Provide average scores ==\n  print('------------------------------------------------------------------------')\n  print('Score per fold')\n","7e6c6197":"for i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","dab8ca4d":"I think that is a good test accuracy. Next, let us discuss K-fold Cross\n Validation.","6626d751":"From the map we can see negative correlation between age and work_type,\n  also work_type and bmi. Stroke and age has a positive correlation similarly. Many other variables\n  have such correlation values so we cannot remove any variables.\n  \n  Let see which gender is more at risk to having a stroke. The boxplot will be help for us:","56721859":"Let's now focus on finding the missing values in the set. \n\nLet's check which variables are empty and how many empty variables there are.:","61fb18f7":"**Single variable analysis:\n**\n1) Analysis of numerical variables:\n\nAt this point, we will examine numerical variables. \nWe will focus on analysing the charts to identify possible anomalies and detect outliers. \nAdditionally, we will examine the distribution of the variables using the Scipy library.","b2c046ea":"WOW , nice to see that most of the people quoted don't smoke","2eaef6eb":"'''The goal of this project is to build a model based on 11 predictors (predictive attributes), \nthat allows us to determine the value an outcome variable. \nThe attribute whose outcome value we will predict is \"stroke\", which tells us whether the\npatient has had a stroke or not.\n\nTo calculate the value of \"Stroke\", we will use 11 explanatory variables:\n    1) id: unique identifier\n    2) gender: \"Male\", \"Female\" or \"Other\"\n    3) age: age of the patient\n    4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n    5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n    6) ever_married: \"No\" or \"Yes\"\n    7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n    8) Residence_type: \"Rural\" or \"Urban\"\n    9) avg_glucose_level: average glucose level in blood\n    10) bmi: body mass index\n    11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n'''","95f807b0":"The data consists of more women's data, although the gender difference is not huge.","8ea18776":" 2)Analysis of the relationship between categorical variables:","72522bcc":"**Analysis of dependencies between variables:**\n1) Correlation analysis between numerical variables:","ad532024":"The only variable with 'Nan' values \u200b\u200bis 'bmi' - 201 missing values, \nwhich is approximately 3.93% of all values \u200b\u200bin this column.\nMissing data can be handled as follows:\n1)Delete rows with missing data.\n2)Replacing missing values with estimated data.\n    \nAs mentioned earlier, ignoring rows with missing data can lead to \ninconsistent results, since the deleted data may be critical for \nfurther calculations and may contain important observations.","63d0ab86":"We can see that older females are more at risk to having a stroke.","d3bd9ba8":"The next step is to change the values of the categorical variables to have numerical values.","c4e40fbc":"We can see a large number of people work in the private sector.","3e5b1b1a":"**Categorical variables:**\n    \nThe \u201egender\u201d variable:","10b97025":"Above I used the simplest dense layer, combining all the units of the previous layer with all of the next.\n","7005ede9":"Now we will remove the value \"Other\" from the variable \"Gender\", \nbecause we are only interested in the concrete variable \"Gender\"","de42e009":"The minimal difference between people living in the city and rural."}}