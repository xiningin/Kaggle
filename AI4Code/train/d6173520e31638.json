{"cell_type":{"6dc513e9":"code","1580641f":"code","67761e7d":"code","271fc552":"code","6ce45559":"code","a3a801eb":"code","b4cad58c":"markdown","4d1eeb7c":"markdown","60306a19":"markdown","fc3bae19":"markdown","b228ade9":"markdown"},"source":{"6dc513e9":"import numpy as np\nimport datatable as dt\nimport pandas as pd\nimport tqdm\nimport os\nimport re\nimport logging\n\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=pd.core.common.SettingWithCopyWarning)\n    \nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = [20, 12]  # width, height\n\nimport gc\n\ninput_path = '\/kaggle\/input\/'\nroot_path = os.path.join(input_path, 'jane-street-market-prediction')","1580641f":"%%time\n\ntrain = (dt.fread(os.path.join(root_path, \"train.csv\")).to_pandas()\n        .query('weight > 0')#.pipe(reduce_mem_usage)\n        .reset_index(drop = True))\n\ntrain['action'] = (train.resp > 0).astype(int)\n\nresp_cols = [i for i in train.columns if 'resp' in i]\nmeta_features = dt.fread(os.path.join(root_path, \"features.csv\")).to_pandas()\n\nfeatures_names = [i for i in train.columns if 'feature_' in i]\nfeatures_index = list(map(lambda x: int(re.sub(\"feature_\", \"\", x)), features_names))\nfeatures_tuples = sorted(list(zip(features_names, features_index)), key = lambda x: x[1])\njust_features = [i[0] for i in features_tuples]","67761e7d":"# this is code slightly modified from the sklearn docs here:\n# https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n\nname_dict = {True: 'With_Stacking_Set', \n             False: 'No_Stacking_Set'}\n\ndef plot_cv_indices_stacking(cv, X, y, group, ax, n_splits, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n    \n    cmap_cv = plt.cm.coolwarm\n\n    jet = plt.cm.get_cmap('jet', 256)\n    seq = np.linspace(0, 1, 256)\n    _ = np.random.shuffle(seq)   # inplace\n    cmap_data = ListedColormap(jet(seq))\n\n    # Generate the training\/testing visualizations for each CV split\n    for ii, indices_split in enumerate(cv.split(X=X, y=y, groups=group)):\n        # Fill in indices with the training\/test groups\n        \n        indices = np.array([np.nan] * len(X))\n        indices[indices_split[0]] = 1\n        indices[indices_split[1]] = 0\n        if cv.stacking_mode:\n            indices[indices_split[2]] = -1\n\n        # Visualize the results\n        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n                   vmin=-.2, vmax=1.2)\n\n    # Plot the data classes and groups at the end\n    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n\n    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n               c=group, marker='_', lw=lw, cmap=cmap_data)\n    \n    if cv.stacking_mode:\n        ax.scatter(range(len(X)), [ii + 3.5] * len(X),\n               c=group, marker='_', lw=lw, cmap=cmap_data)\n\n    # Formatting\n    yticklabels = list(range(n_splits)) + ['target', 'day']\n    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n           xlabel='Sample index', ylabel=\"CV iteration\",\n           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n    \n    ax.set_title('{}'.format(name_dict[cv.stacking_mode]), fontsize=15)\n    #ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n    return ax","271fc552":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\nclass PurgedGroupTimeSeriesSplitStacking(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Allows for a gap in groups to avoid potentially leaking info from\n    train into test if the model has windowed or lag features.\n    Provides train\/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    stacking_mode : bool, default=True\n        Whether to provide an additional set to test a stacking classifier or not. \n    max_train_group_size : int, default=Inf\n        Maximum group size for a single training set.\n    max_val_group_size : int, default=Inf\n        Maximum group size for a single validation set.\n    max_test_group_size : int, default=Inf\n        We discard this number of groups from the end of each train split, if stacking_mode = True and None \n        it defaults to max_val_group_size.\n    val_group_gap : int, default=None\n        Gap between train and validation\n    test_group_gap : int, default=None\n        Gap between validation and test, if stacking_mode = True and None \n        it defaults to val_group_gap.\n    \"\"\"\n\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 stacking_mode=True,\n                 max_train_group_size=np.inf,\n                 max_val_group_size=np.inf,\n                 max_test_group_size=np.inf,\n                 val_group_gap=None,\n                 test_group_gap=None,\n                 verbose=False\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_group_size = max_train_group_size\n        self.max_val_group_size = max_val_group_size\n        self.max_test_group_size = max_test_group_size\n        self.val_group_gap = val_group_gap\n        self.test_group_gap = test_group_gap\n        self.verbose = verbose\n        self.stacking_mode = stacking_mode\n        \n    def split(self, X, y=None, groups=None):\n        if self.stacking_mode:\n            return self.split_ensemble(X, y, groups)\n        else:\n            return self.split_standard(X, y, groups)\n        \n    def split_standard(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and validation set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train\/validation set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        val : ndarray\n            The validation set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_splits = self.n_splits\n        group_gap = self.val_group_gap\n        max_val_group_size = self.max_val_group_size\n        max_train_group_size = self.max_train_group_size\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n\n        group_val_size = min(n_groups \/\/ n_folds, max_val_group_size)\n        group_val_starts = range(n_groups - n_splits * group_val_size,\n                                  n_groups, group_val_size)\n        for group_val_start in group_val_starts:\n            train_array = []\n            val_array = []\n\n            group_st = max(0, group_val_start - group_gap - max_train_group_size)\n            for train_group_idx in unique_groups[group_st:(group_val_start - group_gap)]:\n                train_array_tmp = group_dict[train_group_idx]\n                \n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n\n            train_end = train_array.size\n \n            for val_group_idx in unique_groups[group_val_start:\n                                                group_val_start +\n                                                group_val_size]:\n                val_array_tmp = group_dict[val_group_idx]\n                val_array = np.sort(np.unique(\n                                              np.concatenate((val_array,\n                                                              val_array_tmp)),\n                                     axis=None), axis=None)\n\n            val_array  = val_array[group_gap:]\n            \n            \n            if self.verbose > 0:\n                    pass\n                    \n            yield [int(i) for i in train_array], [int(i) for i in val_array]\n            \n    def split_ensemble(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training, validation and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train\/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        val : ndarray\n            The validation set indices for that split (testing indices for base classifiers).\n        test : ndarray\n            The testing set indices for that split (testing indices for final classifier)\n        \"\"\"\n\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n            \n        X, y, groups = indexable(X, y, groups)\n        n_splits = self.n_splits\n        val_group_gap = self.val_group_gap\n        test_group_gap = self.test_group_gap\n        if test_group_gap is None:\n            test_group_gap = val_group_gap\n        max_train_group_size = self.max_train_group_size\n        max_val_group_size = self.max_val_group_size\n        max_test_group_size = self.max_test_group_size\n        if max_test_group_size is None:\n            max_test_group_size = max_val_group_size\n            \n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n\n        group_val_size = min(n_groups \/\/ n_folds, max_val_group_size)\n        group_test_size = min(n_groups \/\/ n_folds, max_test_group_size)\n        \n        group_test_starts = range(n_groups - n_splits * group_test_size, n_groups, group_test_size)\n        train_indices= []\n        val_indices= []\n        test_indices= []\n        \n        for group_test_start in group_test_starts:\n\n            train_array = []\n            val_array = []\n            test_array = []\n            \n            val_group_st = max(max_train_group_size + val_group_gap, \n                               group_test_start - test_group_gap - max_val_group_size)\n\n            train_group_st = max(0, val_group_st - val_group_gap - max_train_group_size)\n\n            for train_group_idx in unique_groups[train_group_st:(val_group_st - val_group_gap)]:\n\n                train_array_tmp = group_dict[train_group_idx]\n\n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n\n            train_end = train_array.size\n\n            for val_group_idx in unique_groups[val_group_st:(group_test_start - test_group_gap)]:\n                val_array_tmp = group_dict[val_group_idx]\n                val_array = np.sort(np.unique(\n                                              np.concatenate((val_array,\n                                                              val_array_tmp)),\n                                     axis=None), axis=None)\n\n            val_array  = val_array[val_group_gap:]\n\n            for test_group_idx in unique_groups[group_test_start:(group_test_start + group_test_size)]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n\n            test_array  = test_array[test_group_gap:]\n\n            yield [int(i) for i in train_array], [int(i) for i in val_array], [int(i) for i in test_array]","6ce45559":"cv = PurgedGroupTimeSeriesSplitStacking(\n    n_splits=5,\n    stacking_mode = True,\n    max_train_group_size=15,\n    max_test_group_size=5,\n    max_val_group_size=5,\n    val_group_gap=2,\n    test_group_gap=1\n)\n\ncv_no_stacking = PurgedGroupTimeSeriesSplitStacking(\n    n_splits=5,\n    stacking_mode = False,\n    max_train_group_size=15,\n    max_val_group_size=5,\n    val_group_gap=2\n)","a3a801eb":"fig, ax = plt.subplots(1, 1)\n\nplot_cv_indices_stacking(cv, train.query('date < 50')[just_features], train.query('date < 50')['action'], train.query('date < 50')['date'], \n                         ax, 5, lw=20);\n\nfig, ax = plt.subplots(1, 1)\n\nplot_cv_indices_stacking(cv_no_stacking, train.query('date < 50')[just_features], train.query('date < 50')['action'], train.query('date < 50')['date'], \n                         ax, 5, lw=20);\n","b4cad58c":"<a id =\"data_load\"><\/a>\n### Load Competition Dataset ","4d1eeb7c":"# About this notebook\n\nIn this notebook I extend the PurgedGroupTimeSeriesSplit to allow an additional set used to validate stacking or ensemble classifiers. \nThe new class is called PurgedGroupTimeSeriesSplitStacking. When using stacking_mode=False it reverts to PurgedGroupTimeSeriesSplit behaviour.\n\n##### Some clarification about terms\n\nIn a stacking classifier context I refer to:\n- training set as the set where we fit the base classifiers\n- validation set as the set where we evaluate base classifier and fit the stacking classifier\/final estimator\n- test\/stacking set as the set where we evaluate the stacking classifier\/final estimator predictions\n\n\n### Notebooks Sections:\n\n0. [*Load Competition Dataset*](#data_load)<br>\n\n1. [*PurgedGroupTimeSeriesSplitStacking Class Definition*](#class_definition)<br>\n\n2. [*PurgedGroupTimeSeriesSplitStacking example on Competition Data*](#class_example)\n\n\n\n### Props to:\n\n1 -  [GroupTimeSeriesSplit](https:\/\/www.kaggle.com\/jorijnsmit\/found-the-holy-grail-grouptimeseriessplit) \n    \n2 - [PurgedGroupTimeSeriesSplit](https:\/\/www.kaggle.com\/marketneutral\/purged-time-series-cv-xgboost-optuna), extension of 1 allowing for gaps between end of training and start of testing\n\n[Here](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.StackingClassifier.html) a reference for StackingClassifiers.","60306a19":"<a id = \"class_example\"><\/a>\n\n### PurgedGroupTimeSeriesSplitStacking example on Competition Data","fc3bae19":"<a id = \"class_definition\"><\/a>\n\n### PurgedGroupTimeSeriesSplitStacking Class Definition\n\nHere (hidden) I write the enhanced PurgedGroupTimeSeriesSplit class. \n","b228ade9":"Here I define two CrossValidation strategies:\n\n- the first one has an additional stacking set\n\n- the second one has no stacking set "}}