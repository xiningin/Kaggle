{"cell_type":{"6ad8775e":"code","c72e6dc0":"code","12fbb34d":"code","e1e39c3c":"code","922ea137":"code","11332a47":"code","f25d7b4e":"code","2571f1db":"code","703e9a98":"code","33db11c7":"code","64ab7d9e":"code","7da28593":"code","3c1e809a":"code","980c9120":"code","147b6c42":"code","f3074b3d":"code","7435ae93":"code","f22cbcd6":"code","7f980759":"code","8b380c89":"code","2145f897":"code","1c08899b":"code","b3587b9c":"code","241d26f5":"code","a49021ff":"code","18d0428b":"code","2a798c1c":"code","a3bbd0bd":"code","f0abfc3c":"code","51acabd9":"code","b1599181":"code","80300f74":"code","ab2fc44f":"code","fe97b7e6":"code","e6196fce":"code","e2fe759d":"code","f9740114":"code","2ce5e7d7":"code","6cb6ef28":"code","faaa20bd":"code","c2555ac8":"code","c40e23a6":"code","085d9a19":"code","fd42a80f":"code","10dbd931":"code","7547b797":"code","c145648a":"code","29d78198":"code","6b877bf0":"code","a6246b8b":"code","6833ce94":"code","44707235":"code","41c6a69d":"code","12e94fe6":"code","4ceebd9a":"code","2b6bce1c":"code","416c8557":"code","9e0ce8a7":"code","099f3e45":"code","5225b0bf":"code","31621e28":"code","295f8c84":"code","f1b02f05":"code","336b21ad":"code","003acaff":"code","429ee923":"code","59d93b77":"code","159cff03":"code","a31a2ab6":"code","ff415cfb":"code","ff0da16b":"code","3efa4e37":"code","27ad297d":"code","50af8e36":"code","1e767edd":"code","0cb832a4":"code","624e134d":"code","e1980f19":"code","8b17b612":"code","37afe30d":"code","01d5746f":"code","1d982c03":"code","938edf31":"code","72e9fb04":"code","80a28489":"code","9e57e42d":"code","d346e4c2":"code","9f41a05b":"code","5e545ab7":"code","32105d5e":"markdown","af1d3f6d":"markdown","1a660925":"markdown","fa698cfb":"markdown","b7447b3a":"markdown","806a831f":"markdown","7393d605":"markdown","169cf71b":"markdown","ce1740cb":"markdown","14c9ee48":"markdown","b49c064c":"markdown","a2f99f51":"markdown","6490544a":"markdown","c7f45eab":"markdown","f48870b4":"markdown","1e7e92a6":"markdown","851cae3b":"markdown","aea453f2":"markdown","08f97f00":"markdown","f45ee623":"markdown","9df52f14":"markdown","d0820a17":"markdown","15bb016b":"markdown","078a7957":"markdown","61b7f6d6":"markdown","354abf3a":"markdown","2e8db850":"markdown","faa06b74":"markdown","3e1f5909":"markdown","239e7d4f":"markdown","07e94790":"markdown","81416653":"markdown","9625bb80":"markdown","004784ca":"markdown","bf5c493f":"markdown","2bb8230d":"markdown","85fc8996":"markdown","646336b1":"markdown","0c45a947":"markdown","5cec81a9":"markdown"},"source":{"6ad8775e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c72e6dc0":"# Importing additional libraries\nimport math\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\n#Model Metric libraries\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","12fbb34d":"# Reading the input files\nraw_train = pd.read_csv('..\/input\/titanic\/train.csv')\nraw_test = pd.read_csv('..\/input\/titanic\/test.csv')","e1e39c3c":"raw_train.head(3)","922ea137":"raw_test.head(3)","11332a47":"df_train = raw_train[['PassengerId','Pclass','Name','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked','Survived']]\ndf_test = raw_test[['PassengerId','Pclass','Name','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked']]","f25d7b4e":"df_train.info()\nprint('*' * 50)\ndf_test.info()","2571f1db":"df_combined = pd.concat([df_train, df_test])\ndf_combined.info()","703e9a98":"df_combined.groupby('Embarked')['Embarked'].count()","33db11c7":"df_train['Age'].fillna(df_combined['Age'].median(), inplace= True)\ndf_test['Age'].fillna(df_combined['Age'].median(), inplace= True)\ndf_test['Fare'].fillna(df_combined['Fare'].median(), inplace= True)\ndf_train['Embarked'].fillna('S', inplace= True)\ndf_combined['Age'].fillna(df_combined['Age'].median(), inplace= True)\ndf_combined['Fare'].fillna(df_combined['Fare'].median(), inplace= True)\ndf_combined['Embarked'].fillna('S', inplace= True)","64ab7d9e":"df_train.info()\nprint('*' * 50)\ndf_test.info()","7da28593":"df_train['Cabin'].unique()","3c1e809a":"df_train['Cabin'].fillna('No Cabin', inplace= True)\ndf_test['Cabin'].fillna('No Cabin', inplace= True)\ndf_combined['Cabin'].fillna('No Cabin', inplace= True)\n\ndef isCabin(x):\n     return 0 if x == 'No Cabin' else 1","980c9120":"df_train['isCabin'] = df_train['Cabin'].apply(isCabin)\ndf_train.head(3)","147b6c42":"df_test['isCabin'] = df_test['Cabin'].apply(isCabin)\ndf_test.tail(3)","f3074b3d":"df_combined['isCabin'] = df_combined['Cabin'].apply(isCabin)\ndf_combined.tail(3)","7435ae93":"df_train.info()\nprint('*' * 50)\ndf_test.info()","f22cbcd6":"for data in df_train:\n    df_train['Prefix'] = df_train['Name'].str.extract(' ([A-Za-z]+)\\.')\n\nfor data in df_train:\n    df_test['Prefix'] = df_test['Name'].str.extract(' ([A-Za-z]+)\\.')\n    \nfor data in df_combined:\n    df_combined['Prefix'] = df_combined['Name'].str.extract(' ([A-Za-z]+)\\.')","7f980759":"df_train.head(3)","8b380c89":"df_test.head(3)","2145f897":"df_train['isAlone'] = np.where((df_train['SibSp'] == 0) & \n                               (df_train['Parch'] == 0),1, 0)\ndf_test['isAlone'] = np.where((df_test['SibSp'] == 0) & \n                               (df_test['Parch'] == 0),1, 0)\ndf_combined['isAlone'] = np.where((df_combined['SibSp'] == 0) & \n                               (df_combined['Parch'] == 0),1, 0)","1c08899b":"df_train.head(3)","b3587b9c":"fig = plt.figure(figsize=(20,20))\ncols = 4\nrows = math.ceil(float(df_combined.shape[1])\/cols)\n\nfor i, column in enumerate(['Pclass','Prefix','Sex','Age','isAlone','Fare','isCabin','Embarked']):\n  ax = fig.add_subplot(rows, cols, i+1)\n  ax.set_title(column)\n  if df_combined.dtypes[column] == np.object:\n    df_combined[column].value_counts().plot(kind='bar', axes=ax)\n  else:\n    df_combined[column].hist(axes=ax)\n    plt.xticks(rotation='vertical')\nplt.subplots_adjust(hspace=0.7,wspace=0.2)\nplt.show()","241d26f5":"fig = plt.gcf();\nfig.set_size_inches(15, 6)\nsns.countplot(x='Survived', data=df_combined, hue='Prefix');","a49021ff":"print(\"Male Survival Rate:\", round(df_combined['Survived'][df_combined['Sex'] == 'male'].value_counts(normalize = True)[1]*100,2))\nprint(\"Females Survival Rate:\", round(df_combined['Survived'][df_combined['Sex'] == 'female'].value_counts(normalize = True)[1]*100,2))","18d0428b":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.countplot(x='Survived', data=df_combined, hue='Sex');","2a798c1c":"print('S Survival Rate:', round(df_combined['Survived'][df_combined['Embarked'] == 'S'].value_counts(normalize = True)[1]*100,2))\nprint('C Survival Rate:', round(df_combined['Survived'][df_combined['Embarked'] == 'C'].value_counts(normalize = True)[1]*100,2))\nprint('Q Survival Rate:', round(df_combined['Survived'][df_combined['Embarked'] == 'Q'].value_counts(normalize = True)[1]*100,2))","a3bbd0bd":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.countplot(x='Survived', data=df_combined, hue='Embarked')","f0abfc3c":"useful_features = df_combined[['Pclass','Age','isAlone','Fare','isCabin','Survived']]\n\nfig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.heatmap(useful_features.corr(), annot=True, cmap=\"YlGnBu\");","51acabd9":"g = df_combined[['Sex','Age']].groupby('Sex')","b1599181":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nbins = [0, 1, 10, 18, 35, 60, 80]\nsns.distplot(g.get_group('female')['Age'], color=\"skyblue\", bins= bins)\nsns.distplot(g.get_group('male')['Age'], color=\"olive\", bins= bins)\nplt.legend(df_combined['Sex'])","80300f74":"def p_type(passenger):\n    age, sex = passenger\n    if age < 18:\n        return 'minor'\n    else:\n        return sex","ab2fc44f":"df_train['Person'] = df_train[['Age','Sex']].apply(p_type, axis= 1)\ndf_test['Person'] = df_test[['Age','Sex']].apply(p_type, axis= 1)\ndf_combined['Person'] = df_combined[['Age','Sex']].apply(p_type, axis= 1)\ndf_combined['Person'].head(10)","fe97b7e6":"print('Minor Survival Rate:', round(df_combined['Survived'][df_combined['Person'] == 'minor'].value_counts(normalize = True)[1]*100,2))\nprint('Female Survival Rate:', round(df_combined['Survived'][df_combined['Person'] == 'female'].value_counts(normalize = True)[1]*100,2))\nprint('Male Survival Rate:', round(df_combined['Survived'][df_combined['Person'] == 'male'].value_counts(normalize = True)[1]*100,2))","e6196fce":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.countplot(x='Survived', data=df_combined, hue='Person');","e2fe759d":"print(\"Class 1 Survival Rate:\", round(df_combined['Survived'][df_combined['Pclass'] == 1].value_counts(normalize = True)[1]*100,2))\nprint(\"Class 2 Survival Rate:\", round(df_combined['Survived'][df_combined['Pclass'] == 2].value_counts(normalize = True)[1]*100,2))\nprint(\"Class 3 Survival Rate:\", round(df_combined['Survived'][df_combined['Pclass'] == 3].value_counts(normalize = True)[1]*100,2))","f9740114":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.countplot(x='Survived', data=df_combined, hue='Pclass');","2ce5e7d7":"print(\"Alone Survival Rate:\", round(df_combined['Survived'][df_combined['isAlone'] == 1].value_counts(normalize = True)[1]*100,2))\nprint(\"With Family Survival Rate:\", round(df_combined['Survived'][df_combined['isAlone'] == 0].value_counts(normalize = True)[1]*100,2))","6cb6ef28":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.countplot(x='Survived', data=df_combined, hue='isAlone');","faaa20bd":"df_train['FareGroup'] = pd.qcut(df_train['Fare'], 4, labels = [1, 2, 3, 4])\ndf_test['FareGroup'] = pd.qcut(df_test['Fare'], 4, labels = [1, 2, 3, 4])\ndf_combined['FareGroup'] = pd.qcut(df_combined['Fare'], 4, labels = [1, 2, 3, 4])","c2555ac8":"print('FareQ1:', round(df_combined['Survived'][df_combined['FareGroup'] == 1].value_counts(normalize = True)[1]*100,2))\nprint('FareQ2:', round(df_combined['Survived'][df_combined['FareGroup'] == 2].value_counts(normalize = True)[1]*100,2))\nprint('FareQ3:', round(df_combined['Survived'][df_combined['FareGroup'] == 3].value_counts(normalize = True)[1]*100,2))\nprint('FareQ4:', round(df_combined['Survived'][df_combined['FareGroup'] == 4].value_counts(normalize = True)[1]*100,2))","c40e23a6":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.countplot(x='Survived', data=df_combined, hue='FareGroup');","085d9a19":"print('Without Cabin:', round(df_combined['Survived'][df_combined['isCabin'] == 0].value_counts(normalize = True)[1]*100,2))\nprint('With Cabin:', round(df_combined['Survived'][df_combined['isCabin'] == 1].value_counts(normalize = True)[1]*100,2))","fd42a80f":"fig = plt.gcf();\nfig.set_size_inches(12, 7)\nsns.countplot(x='Survived', data=df_combined, hue='isCabin');","10dbd931":"fig = plt.gcf();\nfig.set_size_inches(8, 5)\nsns.countplot(x='Survived', data=df_combined);","7547b797":"df_train['FareGroup'] = pd.to_numeric(df_train.FareGroup)\ndf_test['FareGroup'] = pd.to_numeric(df_test.FareGroup)","c145648a":"df_train['FareGroup'] = pd.to_numeric(df_train.FareGroup)\ndf_test['FareGroup'] = pd.to_numeric(df_test.FareGroup)","29d78198":"df_train.drop(['Name','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked'], axis= 1, inplace= True)\ndf_test.drop(['Name','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked'], axis= 1, inplace= True)","6b877bf0":"df_train.info()","a6246b8b":"df_train = pd.get_dummies(df_train, columns=['Pclass','Prefix','Person','isAlone',\n                                             'isCabin','FareGroup'])\ndf_test = pd.get_dummies(df_test, columns=['Pclass','Prefix','Person','isAlone',\n                                           'isCabin','FareGroup'])","6833ce94":"df_train.columns","44707235":"df_train = df_train[['PassengerId', 'Pclass_1', 'Pclass_2',\n                     'Pclass_3', 'Prefix_Capt', 'Prefix_Col', 'Prefix_Countess',\n                     'Prefix_Don', 'Prefix_Dr', 'Prefix_Jonkheer', \n                     'Prefix_Lady', 'Prefix_Major', 'Prefix_Master', \n                     'Prefix_Miss', 'Prefix_Mlle', 'Prefix_Mme', 'Prefix_Mr',\n                     'Prefix_Mrs', 'Prefix_Ms', 'Prefix_Rev', 'Prefix_Sir', \n                     'Person_female', 'Person_male', 'Person_minor', 'isAlone_0', 'isAlone_1', \n                     'isCabin_0', 'isCabin_1', 'FareGroup_1', 'FareGroup_2',\n                     'FareGroup_3', 'FareGroup_4', 'Survived']]\n\ndf_test['Prefix_Capt'] = 0\ndf_test['Prefix_Countess'] = 0\ndf_test['Prefix_Don'] = 0\ndf_test['Prefix_Jonkheer'] = 0\ndf_test['Prefix_Lady'] = 0\ndf_test['Prefix_Major'] = 0\ndf_test['Prefix_Mlle'] = 0\ndf_test['Prefix_Mme'] = 0\ndf_test['Prefix_Ms'] = 0\ndf_test['Prefix_Sir'] = 0\n\ndf_test = df_test[['PassengerId', 'Pclass_1', 'Pclass_2',\n                     'Pclass_3', 'Prefix_Capt', 'Prefix_Col', 'Prefix_Countess',\n                     'Prefix_Don', 'Prefix_Dr', 'Prefix_Jonkheer', \n                     'Prefix_Lady', 'Prefix_Major', 'Prefix_Master', \n                     'Prefix_Miss', 'Prefix_Mlle', 'Prefix_Mme', 'Prefix_Mr',\n                     'Prefix_Mrs', 'Prefix_Ms', 'Prefix_Rev', 'Prefix_Sir', \n                     'Person_female', 'Person_male', 'Person_minor','isAlone_0', 'isAlone_1', \n                     'isCabin_0', 'isCabin_1', 'FareGroup_1', 'FareGroup_2',\n                     'FareGroup_3', 'FareGroup_4']]","41c6a69d":"df_train.info()\nprint('^'*50)\ndf_test.info()","12e94fe6":"df_train.shape","4ceebd9a":"df_test.shape","2b6bce1c":"# split features (X) & target (y)\nX = df_train.drop(['PassengerId','Survived'], axis=1)\ny = df_train['Survived']\n\nprint(X.shape)\nprint(y.shape)","416c8557":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state= 5)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","9e0ce8a7":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(X_train,y_train)","099f3e45":"y_pred_trn_gnb = gnb.predict(X_train)\ny_pred_val_gnb = gnb.predict(X_test)","5225b0bf":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('Gaussian NB Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_gnb))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_gnb, target_names= target_names))\nprint('--' * 50)\nacc_gnb_trn = round(accuracy_score(y_train, y_pred_trn_gnb)*100,2)\nacc_gnb_val = round(accuracy_score(y_test, y_pred_val_gnb)*100,2)\nprint('Training Accuracy: ', acc_gnb_trn)\nprint('Validation Accuracy: ', acc_gnb_val)","31621e28":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors= 9, weights= 'distance')\nknn.fit(X_train,y_train)","295f8c84":"y_pred_trn_knn = knn.predict(X_train)\ny_pred_val_knn = knn.predict(X_test)","f1b02f05":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('KNN Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_knn))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_knn, target_names= target_names))\nprint('--' * 50)\nacc_knn_trn = round(accuracy_score(y_train, y_pred_trn_knn)*100,2)\nacc_knn_val = round(accuracy_score(y_test, y_pred_val_knn)*100,2)\nprint('Training Accuracy: ', acc_knn_trn)\nprint('Validation Accuracy: ', acc_knn_val)","336b21ad":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)","003acaff":"y_pred_trn_logreg = logreg.predict(X_train)\ny_pred_val_logreg = logreg.predict(X_test)","429ee923":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('Logistic Regression Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_logreg))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_logreg, target_names= target_names))\nprint('--' * 50)\nacc_logreg_trn = round(accuracy_score(y_train, y_pred_trn_logreg)*100,2)\nacc_logreg_val = round(accuracy_score(y_test, y_pred_val_logreg)*100,2)\nprint('Training Accuracy: ', acc_logreg_trn)\nprint('Validation Accuracy: ', acc_logreg_val)","59d93b77":"from sklearn.svm import SVC\n\nsvc = SVC(kernel= 'poly', probability= True)\nsvc.fit(X_train,y_train)","159cff03":"y_pred_trn_svc = svc.predict(X_train)\ny_pred_val_svc = svc.predict(X_test)","a31a2ab6":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('SVC Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_svc))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_svc, target_names= target_names))\nprint('--' * 50)\nacc_svc_trn = round(accuracy_score(y_train, y_pred_trn_svc)*100,2)\nacc_svc_val = round(accuracy_score(y_test, y_pred_val_svc)*100,2)\nprint('Training Accuracy: ', acc_svc_trn)\nprint('Validation Accuracy: ', acc_svc_val)","ff415cfb":"from sklearn.tree import DecisionTreeClassifier\n\ndtree = DecisionTreeClassifier(criterion= 'gini', \n                               max_depth= 7)\ndtree.fit(X_train,y_train)","ff0da16b":"y_pred_trn_dtree = dtree.predict(X_train)\ny_pred_val_dtree = dtree.predict(X_test)","3efa4e37":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('Decision Tree Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_dtree))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_dtree, target_names= target_names))\nprint('--' * 50)\nacc_dtree_trn = round(accuracy_score(y_train, y_pred_trn_dtree)*100,2)\nacc_dtree_val = round(accuracy_score(y_test, y_pred_val_dtree)*100,2)\nprint('Training Accuracy: ', acc_dtree_trn)\nprint('Validation Accuracy: ', acc_dtree_val)","27ad297d":"from sklearn.ensemble import RandomForestClassifier\n\nrndf = RandomForestClassifier(n_estimators= 50,\n                              criterion= 'entropy',\n                              max_depth= 7,\n                              max_features= 5,\n                              random_state= 5)\nrndf.fit(X_train,y_train)","50af8e36":"y_pred_trn_rndf = rndf.predict(X_train)\ny_pred_val_rndf = rndf.predict(X_test)","1e767edd":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('Random Forest Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_rndf))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_rndf, target_names= target_names))\nprint('--' * 50)\nacc_rndf_trn = round(accuracy_score(y_train, y_pred_trn_rndf)*100,2)\nacc_rndf_val = round(accuracy_score(y_test, y_pred_val_rndf)*100,2)\nprint('Training Accuracy: ', acc_rndf_trn)\nprint('Validation Accuracy: ', acc_rndf_val)","0cb832a4":"from sklearn.ensemble import AdaBoostClassifier\n\nadab = AdaBoostClassifier()\nadab.fit(X_train,y_train)","624e134d":"y_pred_trn_adab = adab.predict(X_train)\ny_pred_val_adab = adab.predict(X_test)","e1980f19":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('AdaBoost Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_adab))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_adab, target_names= target_names))\nprint('--' * 50)\nacc_adab_trn = round(accuracy_score(y_train, y_pred_trn_adab)*100,2)\nacc_adab_val = round(accuracy_score(y_test, y_pred_val_adab)*100,2)\nprint('Training Accuracy: ', acc_adab_trn)\nprint('Validation Accuracy: ', acc_adab_val)","8b17b612":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier(learning_rate= 0.2,\n                                 n_estimators= 300,\n                                 max_depth= 4)\ngbc.fit(X_train,y_train)","37afe30d":"y_pred_trn_gbc = gbc.predict(X_train)\ny_pred_val_gbc = gbc.predict(X_test)","01d5746f":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint('Gradient Boosting Classifier Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_gbc))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_gbc, target_names= target_names))\nprint('--' * 50)\nacc_gbc_trn = round(accuracy_score(y_train, y_pred_trn_gbc)*100,2)\nacc_gbc_val = round(accuracy_score(y_test, y_pred_val_gbc)*100,2)\nprint('Training Accuracy: ', acc_gbc_trn)\nprint('Validation Accuracy: ', acc_gbc_val)","1d982c03":"import xgboost\n\nxgb = xgboost.XGBClassifier(learning_rate= 0.16,\n                            subsample= 0.5,\n                            max_depth= 4)\nxgb.fit(X_train,y_train)","938edf31":"y_pred_trn_xgb = xgb.predict(X_train)\ny_pred_val_xgb = xgb.predict(X_test)","72e9fb04":"print('XGB Performance')\nprint('--' * 50)\nprint('Confusion Matrix')\nprint(confusion_matrix(y_test, y_pred_val_xgb))\nprint('--' * 50)\ntarget_names = ['Deceased', 'Survived']\nprint('Classification Report')\nprint(classification_report(y_test, y_pred_val_xgb, target_names= target_names))\nprint('--' * 50)\nacc_xgb_trn = round(accuracy_score(y_train, y_pred_trn_xgb)*100,2)\nacc_xgb_val = round(accuracy_score(y_test, y_pred_val_xgb)*100,2)\nprint('Training Accuracy: ', acc_xgb_trn)\nprint('Validation Accuracy: ', acc_xgb_val)","80a28489":"best_model = pd.DataFrame({\n    'Model': ['Gaussian NB', 'KNN', 'Logistic Reg.', 'SVM', 'Decision Tree',\n              'Random Forest', 'AdaBoost', 'Gradient Boost', 'XGBoost'],\n    'Training Accuracy': [acc_gnb_trn, acc_knn_trn, acc_logreg_trn, acc_svc_trn, acc_dtree_trn,\n                 acc_rndf_trn, acc_adab_trn, acc_gbc_trn, acc_xgb_trn],\n    'Validation Accuracy': [acc_gnb_val, acc_knn_val, acc_logreg_val, acc_svc_val, acc_dtree_val,\n                 acc_rndf_val, acc_adab_val, acc_gbc_val, acc_xgb_val]})\n\nbest_model.sort_values(by= 'Validation Accuracy', ascending= False)","9e57e42d":"# Importing libraries for plotting roc_curve\nfrom sklearn.metrics import roc_curve, roc_auc_score","d346e4c2":"classifiers = [GaussianNB(),\n               KNeighborsClassifier(n_neighbors= 9, weights= 'distance'),\n               LogisticRegression(),               \n               SVC(kernel= 'poly', probability= True),                 \n               DecisionTreeClassifier(criterion= 'gini', \n                                      max_depth= 7),\n               RandomForestClassifier(n_estimators= 50,\n                                      criterion= 'entropy',\n                                      max_depth= 7,\n                                      max_features= 5,\n                                      random_state= 5),\n               AdaBoostClassifier(),\n               GradientBoostingClassifier(learning_rate= 0.2,\n                                          n_estimators= 300,\n                                          max_depth= 4),\n               xgboost.XGBClassifier(learning_rate= 0.16,\n                                     subsample= 0.5,\n                                     max_depth= 4)]\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\nfor cls in classifiers:\n    model = cls.fit(X_train, y_train)\n    yproba = model.predict_proba(X_test)[:,1]\n    \n    fpr, tpr, _ = roc_curve(y_test,  yproba)\n    auc = roc_auc_score(y_test, yproba)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\nresult_table.set_index('classifiers', inplace=True)","9f41a05b":"fig = plt.gcf()\nfig.set_size_inches(9, 6)\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color= 'red', linestyle='-')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel('False Positive Rate')\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel('True Positive Rate')\n\nplt.title('AUC - ROC Curve Analysis', fontweight= 'bold', fontsize= 15)\nplt.legend(prop={'size':11}, loc='lower right')\n\nplt.show()","5e545ab7":"# Set ids as PassengerId and predict survival \nids = df_test['PassengerId']\ntest_file = df_test.drop(['PassengerId'], axis= 1)\nfinal_pred = xgb.predict(test_file)\n\n# Set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({'PassengerId' : ids, 'Survived': final_pred})\noutput.to_csv('submission.csv', index=False)\nprint(output)","32105d5e":"Looking at the data and graph above, I dont think Embarked is playing a role in the Survival. It may be sheer chance that C has a higher percentage. Hence, dropping this from the feature list.","af1d3f6d":"### Data Preparation","1a660925":"#### Logistic Regression","fa698cfb":"#### Gaussian NB","b7447b3a":"#### Decision Tree","806a831f":"Now lets understand the impact of the above features on the Survival rate, starting with the categorical features first.","7393d605":"Lets now understand the data.","169cf71b":"So interestingly, class1 passengers had a higher chance of survival.\n\nNow lets see between travelling alone or with family, which one has a higher chance of survival.","ce1740cb":"#### Random Forest","14c9ee48":"#### AdaBoost","b49c064c":"**One Hot Encoding**","a2f99f51":"From the initial analysis, we can remove the Ticket column as it does not seem to contribute to the Survival rate.","6490544a":"Looks like Age is missing for some passengers in both the train and test dataset. Looking into the remaining features, there is no way we can guess the age for the missing values. Filling up the Age column with mean, median etc is not a good idea in my opinion as it is not a very correct approximation for as critical a field as Age.\n\nSo though I would prefer to drop the passengers whose age is missing so as to not confuse the algorithm but I still need to keep these rows else my submission will not pass since it requires all 418 rows!\n\nSo lets fill Age with median Age, Fare with median Fare and Embarked with the highest Emabarked count!","c7f45eab":"Now this sibling, spouse, parents and children can all be clubbed into the concept of whether the passenger travelled with family or not.","f48870b4":"Now lets check the spread of the target variable.","1e7e92a6":"#### XGBoost","851cae3b":"#### Support Vector Machine","aea453f2":"**Points to be noted:**\n\n* **Pclass:** Majority of the data is from class 3, while class 1 and 2 are uniformly spread. \n* **Prefix:** The data is highly skewed in favor of Mr, with some representations from Miss, Mrs and Master.\n* **Sex:** It is not a surprise that Males are more the Females, because we already know that we have a lot of Mr. Good thing is that the Prefix and Sex are in sync.\n* **Age:** Most of the passengers were mostly in their 20s and 30s.\n* **isAlone:** The derived field of isAlone shows something interesting. Majority of the passengers were travelling alone. \n* **Fare:** Most of the fares were low and it could have been guessed since we have more class 3 than class 1 and 2.\n* **isCabin:** Most passengers were without cabins\n* **Embarked:** Most passengers were embarked from S.","08f97f00":"So looks like more people died in our dataset.","f45ee623":"So clearly, if the passenger is a female or minor then chances of survival is higher.","9df52f14":"Looks like XGBClassifier is the best model, so I will go with that as my chosen model.","d0820a17":"And drop the extra unnecessary columns.","15bb016b":"### EDA","078a7957":"Lets convert the object fields to numeric.","61b7f6d6":"#### KNN Classifier","354abf3a":"### Model Evaluation","2e8db850":"Now lets take a look into the numerical features' relation against the Survival rate.","faa06b74":"Travelling with family increases the Survival rate. Probably, because there is someone who is looking after the other person.","3e1f5909":"### Submission File","239e7d4f":"#### Gradient Boosting Classifier","07e94790":"#### AUC - ROC Curve","81416653":"### Model Training","9625bb80":"Pclass, isAlone, Fare and isCabin has some direct relation to the survival rate. So will keep these columns in some form or the other as features.\n\nHowever, Age does not seem to have any direct relation. But it is worth exploring if the passenger is a female or minor, whether they have a higher survival chance or not. If yes, then we might need to account for that as well in our model.","004784ca":"This is also playing a role on the Survival rate, lets keep it on our features list.","bf5c493f":"Let us now visualize the spread of the data across different features using the df_combined.","2bb8230d":"The Name column as such is useless, unless we extract the name prefixes and assign them some numerical values.","85fc8996":"With the Age and Embarked cleaned up, lets see why there are so many values mising in Cabin.","646336b1":"Mr was the largest group on the passengers list and they are 3rd on the Survival list. Looks like this has some influence on Survival rate. So lets keep this on our features list for our models.","0c45a947":"Looks like passengers who were allotted Cabins, had Cabin numbers and others do not. So converting this into a boolean field would be helpful.","5cec81a9":"Lets take another look at the datasets."}}