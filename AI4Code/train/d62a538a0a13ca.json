{"cell_type":{"81b30a7a":"code","9ae8aae7":"code","c8a570a4":"code","df5205d9":"code","e155c995":"code","30f58ffe":"code","fc2bec1d":"code","d447eada":"code","156fe659":"code","00e680e3":"code","821a5d0c":"code","7854c8f0":"code","7131d74a":"code","7f00446a":"code","0b3e5715":"code","5947f1e8":"code","a598bde9":"code","bda18852":"code","9c2df30f":"code","6573aab1":"code","79ef755d":"code","c856860f":"code","fc6c03e0":"markdown","4e647bc4":"markdown","4d9a7884":"markdown","89e4eb70":"markdown","f003a345":"markdown","1ca43568":"markdown","ca0c2c91":"markdown","dc3f76d2":"markdown","945f2ef0":"markdown","38298c56":"markdown","015ff5dc":"markdown"},"source":{"81b30a7a":"import cv2                 # working with, mainly resizing, images\nimport numpy as np         # dealing with arrays\nimport os                  # dealing with directories\nfrom random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n\ntrain_dir = '..\/input\/train'\ntest_dir = '..\/input\/test'","9ae8aae7":"def get_label(img):\n    label = img.split('.')[0]\n    if label == 'cat': \n        return [1,0]\n    elif label == 'dog': \n        return [0,1]","c8a570a4":"from tqdm import tqdm      # a nice pretty percentage bar for tasks.\n\ndef making_train_data():\n    training_data = []\n    \n    for img in tqdm(os.listdir(train_dir)):\n        label = get_label(img)\n        path = os.path.join(train_dir,img)\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (50,50))\n        training_data.append([np.array(img),np.array(label)])\n        \n    shuffle(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data","df5205d9":"def making_test_data():\n    testing_data = []\n    \n    for img in tqdm(os.listdir(test_dir)):\n        path = os.path.join(test_dir , img)\n        img_num = img.split('.')[0]\n        img = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img , (50,50))\n        testing_data.append([np.array(img), img_num])\n        \n    shuffle(testing_data)\n    np.save('test_data.npy', testing_data)\n    return testing_data","e155c995":"train_data = making_train_data()","30f58ffe":"train = train_data[0:20000]\ntest = train_data[20000:25000]","fc2bec1d":"X = np.array([i[0] for i in train]).reshape(-1,1,50,50)\nY = [i[1] for i in train]\n\ntest_x = np.array([i[0] for i in test]).reshape(-1,1,50,50)\ntest_y = [i[1] for i in test]","d447eada":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.0,  \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=False, \n        vertical_flip=False)  \n\ndatagen.fit(X)","156fe659":"Y = np.asarray(Y)\nY.reshape(len(Y) , 2)","00e680e3":"test_y = np.asarray(test_y)\ntest_y.reshape(len(test_y) , 2)","821a5d0c":"test_x = test_x.reshape(-1, 1, 50, 50)","7854c8f0":"test_x = test_x \/ 255\nX = X \/ 255","7131d74a":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom keras.layers import Convolution2D\nfrom keras.layers import Conv2D , BatchNormalization\nfrom keras.layers import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.set_image_dim_ordering('th')","7f00446a":"# Initialising the CNN\nclassifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Convolution2D(32, 3, 3, input_shape = (1,50,50), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n\n\n# Adding a third convolutional layer\nclassifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n\n\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dense(output_dim = 64, activation = 'relu'))\nclassifier.add(Dropout(0.4))\nclassifier.add(Dense(output_dim = 2, activation = 'sigmoid'))\n\n","0b3e5715":"# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","5947f1e8":"classifier.summary()","a598bde9":"batch_size = 128\nepochs = 20\n\nclassifier.compile(loss='binary_crossentropy', optimizer='adam' , metrics=['accuracy'])\nsteps_per_epoch = len(train_data) \/\/ batch_size\nvalidation_steps = len((test_x, test_y)) \/\/ batch_size","bda18852":"history = classifier.fit_generator(datagen.flow(X, Y, batch_size=batch_size),\n                    steps_per_epoch=X.shape[0] \/\/ batch_size,\n                    validation_data=(test_x, test_y),\n                    epochs = epochs, verbose = 2)","9c2df30f":"test_data = making_test_data()","6573aab1":"score = classifier.evaluate(test_x, test_y, verbose=0)\nprint('valid loss:', score[0])\nprint('valid accuracy:', score[1])","79ef755d":"with open('submission_file.csv','w') as f:\n    f.write('id,label\\n')\n            \nwith open('submission_file.csv','a') as f:\n    for data in tqdm(test_data):\n        img_num = data[1]\n        img_data = data[0]\n        orig = img_data\n        data = img_data.reshape(1,1,50,50)\n        model_out = classifier.predict([data])[0]\n        f.write('{},{}\\n'.format(img_num,model_out[1]))","c856860f":"import pandas as pd\naa = pd.read_csv('submission_file.csv')\naa\n","fc6c03e0":"****We will be using the Sequential model from Keras to form the Neural Network. Sequential Model is used to construct simple models with linear stack of layers.****\n\n****More info on Sequential model and Keras in general at https:\/\/keras.io\/getting-started\/sequential-model-guide\/ and https:\/\/github.com\/keras-team\/keras****","4e647bc4":"## Fitting on the Training set and making predcitons on the Validation set","4d9a7884":"## Summary of the Model","89e4eb70":"## importing libraries and constants for Preprocessing","f003a345":"**Split the train_data into train(having 20,000 images) and test(having 5,000 images) **","1ca43568":"## conversion to one-hot array for cat it is [1,0] and for dog it is [0,1]","ca0c2c91":"# Building a strong image classification model using keras","dc3f76d2":"## Building  another function to fully process the training images and their labels into arrays:-","945f2ef0":"## Compiling the Keras Model","38298c56":"## Data Augmentation to prevent Overfitting","015ff5dc":"## Building the ConvNet Model"}}