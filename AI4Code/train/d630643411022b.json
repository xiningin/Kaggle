{"cell_type":{"d2af1b5b":"code","165eb607":"code","ca460241":"code","8b3ee245":"code","0e66a189":"code","0e919f2e":"code","95b0310f":"code","5eaeecc1":"code","eac5d9f6":"code","696a7399":"code","c9050f66":"code","f7a3774d":"code","d8a73c11":"code","fbdf914d":"code","a36a6d18":"markdown","ab14fa1a":"markdown","5150a3c6":"markdown","cd33c823":"markdown","e7d183e9":"markdown"},"source":{"d2af1b5b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","165eb607":"dataset_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndataset_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ny_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","ca460241":"dataset_train.info()","8b3ee245":"dataset_train = dataset_train.drop(['Id','Alley','MiscFeature','Fence','PoolQC'],axis = 1)\ndataset_test = dataset_test.drop(['Id','Alley','MiscFeature','Fence','PoolQC'],axis = 1)","0e66a189":"X = dataset_train.iloc[:, :-1].values\ny = dataset_train.iloc[:, -1].values\nX_test = dataset_test.iloc[:, :].values\ny_test = y_test.iloc[:, -1].values\nprint(X)\nprint(y_test)","0e919f2e":"X_test[:,0]","95b0310f":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor i in range(0, len(dataset_train.columns)-1): #label\n    if dataset_train.dtypes[i] == 'O': \n        le.fit((np.concatenate((X_test[:,i],X[:,i]),axis = 0)))\n        X_test[:, i] = le.transform(X_test[:,i])\n        X[:,i] = le.transform(X[:,i])\n","5eaeecc1":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:,:])\nX[:, :] = imputer.transform(X[:, :])\nX_test[:, :] = imputer.transform(X_test[:, :])\nprint(X[0])","eac5d9f6":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX[:, :] = sc.fit_transform(X[:, :])\nX_test[:, :] = sc.transform(X_test[:, :])\nprint(X_test)\nprint(X)","696a7399":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly_reg = PolynomialFeatures(degree = 2)\nX_poly = poly_reg.fit_transform(X)\nlin_reg_2 = LinearRegression()\nlin_reg_2.fit(X_poly, y)\n","c9050f66":"y_pred = lin_reg_2.predict(poly_reg.transform(X_test))\n","f7a3774d":"print(y_pred[128])\nprint(y_test[128])","d8a73c11":"y_test[0]","fbdf914d":"import matplotlib.pyplot as plt\nSTART_POINT = 100\nEND_POINT = 150\n\nx = np.arange(START_POINT, END_POINT)\nplt.plot(x, y_pred[START_POINT:END_POINT],color = 'red')\nplt.scatter(x, y_test[START_POINT:END_POINT],color = 'blue')\n\nplt.show()","a36a6d18":"Drop columns with many \"nan\" values","ab14fa1a":"Fill \"NaN\" values with mean values of column","5150a3c6":"Scaling all feature","cd33c823":"Encoder all string","e7d183e9":"Load data"}}