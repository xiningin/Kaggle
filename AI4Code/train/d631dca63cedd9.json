{"cell_type":{"3c52235a":"code","10d9aace":"code","6d0eaab9":"code","00a7f405":"code","feae5118":"code","afe47425":"code","e2b466e1":"code","24d1bc11":"code","432d927a":"code","f19960c6":"code","31798e4a":"code","86ea5d28":"code","4e1467cb":"code","9fef7b12":"code","2547d019":"code","ecb30dbc":"code","be3483d4":"code","12ef3bae":"code","761edea6":"code","0a727216":"code","322932fc":"markdown","b545d266":"markdown","3271c2d5":"markdown","85361cb0":"markdown","fe32d837":"markdown","257e6fbd":"markdown","66999204":"markdown","a408e48f":"markdown","8824055c":"markdown","c6cf0128":"markdown","7ffcc2e2":"markdown"},"source":{"3c52235a":"# For linear algebra,\nimport numpy as np\n\n# Data\nimport pandas as pd\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Model building and helper libraries\nimport xgboost\nimport math\nfrom __future__ import division\nfrom scipy.stats import pearsonr\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import model_selection, tree, linear_model\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import explained_variance_score","10d9aace":"# Read the data into a data frame\ndata = pd.read_csv('..\/input\/kc_house_data.csv')","6d0eaab9":"# Check the number of data points in the data set\nprint(len(data))\n# Check the number of features in the data set\nprint(len(data.columns))\n# Check the data types\nprint(data.dtypes.unique())","00a7f405":"# Since there are Python objects in the data set, we may have some categorical features. Let's check them.\ndata.select_dtypes(include=['O']).columns.tolist()","feae5118":"# Check number of columns with NaN\nprint(data.isnull().any().sum(), ' \/ ', len(data.columns))\n# Check number of data points with NaN\nprint(data.isnull().any(axis=1).sum(), ' \/ ', len(data))","afe47425":"# Independent variables also known as features\nfeatures = data.iloc[:,3:].columns.tolist()\n# Dependent Variables also known as target\ntarget = data.iloc[:,2].name","e2b466e1":"# Dictionary to store correlations key: feature_name, value: correlation between feature and target\ncorrelations = {}\nfor f in features:\n    data_temp = data[[f,target]]\n    x1 = data_temp[f].values\n    x2 = data_temp[target].values\n    key = f + ' vs ' + target\n    correlations[key] = pearsonr(x1,x2)[0]","24d1bc11":"data_correlations = pd.DataFrame(correlations, index=['Value']).T\ndata_correlations.loc[data_correlations['Value'].abs().sort_values(ascending=False).index]","432d927a":"y = data.loc[:,['sqft_living','grade',target]].sort_values(target, ascending=True).values\nx = np.arange(y.shape[0])","f19960c6":"%matplotlib inline\nplt.subplot(3,1,1)\nplt.plot(x,y[:,0])\nplt.title('Sqft and Grade vs Price')\nplt.ylabel('Sqft')\n\nplt.subplot(3,1,2)\nplt.plot(x,y[:,1])\nplt.ylabel('Grade')\n\nplt.subplot(3,1,3)\nplt.plot(x,y[:,2],'r')\nplt.ylabel(\"Price\")\n\nplt.show()","31798e4a":"# Train a linear regression model\nregr = linear_model.LinearRegression()\nnew_data = data[['sqft_living','grade', 'sqft_above', 'sqft_living15','bathrooms','view',\n                 'sqft_basement','lat','waterfront','yr_built','bedrooms']]","86ea5d28":"# X -> Independent variables\n# y -> Dependent variable\nX = new_data.values\ny = data.price.values","4e1467cb":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n                                                                    test_size=0.2, \n                                                                    random_state=4)","9fef7b12":"# Training the model\nregr.fit(X_train, y_train)","2547d019":"# Predicting on test data\npredictions = regr.predict(X_test)\nprint(predictions)","ecb30dbc":"print(f'Mean Squared Error: {metrics.mean_squared_error(predictions,y_test)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(predictions,y_test)}')\nprint(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(predictions,y_test))}')","be3483d4":"# Let's try XGboost algorithm to see if we can get better results\nxgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=7)","12ef3bae":"traindf, testdf = train_test_split(X_train, test_size = 0.3)\nxgb.fit(X_train,y_train)","761edea6":"predictions = xgb.predict(X_test)","0a727216":"print(f'Mean Squared Error: {metrics.mean_squared_error(predictions,y_test)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(predictions,y_test)}')\nprint(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(predictions,y_test))}')","322932fc":"### The top 5 features are the most correlated features with the target \"price\"","b545d266":"# Problem Statement\n- *To Predict house prices in King County, USA.*\n- *Type: Regression*","3271c2d5":"# 2. Correlation between features and target","85361cb0":"- We only have the date column which is a time stamp which can be ignored.","fe32d837":"### As the error has dropped significantly making it an  optimal solution.","257e6fbd":"# Let us start by** Importing Libraries**","66999204":"- The data set is structured and doesn't have any NaN values. So we can jump into finding correlations between the features and the target variable","a408e48f":"### Not our best answer, let's use XGBoost.","8824055c":"# 1. Exploratory Data Analysis","c6cf0128":"# About the Data\n- The dataset contains house sale prices of King County which were sold in between May 2014 and May 2015.","7ffcc2e2":"# 3. Predicting House Prices"}}