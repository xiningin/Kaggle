{"cell_type":{"ca8548ae":"code","f92e20ef":"code","c6d5d220":"code","073f3e84":"code","4a5737c0":"code","e97248e1":"code","affd9133":"code","5f5f939f":"code","1dcebad0":"code","d5349752":"code","9099051a":"code","11853059":"markdown","ea74afea":"markdown","df2f6c42":"markdown","c3c981fc":"markdown","ac4baeec":"markdown","ef4295f0":"markdown","1c39248f":"markdown","5d1ae9bf":"markdown","15091dca":"markdown","3ed3359d":"markdown"},"source":{"ca8548ae":"import numpy\nx=[i for i in range(50)];\ny1=[];\nfor i in range(len(x)):\n    y1.append(2*x[i]+3);\n    y1[i]=y1[i]+numpy.random.normal(0,1,1);\n    y1[i]=y1[i][0] #The statement creates a numpy ndarray\n    \ny2=[];\nfor i in range(len(x)):\n    y2.append(2*x[i]+3);\n    y2[i]=y2[i]+numpy.random.normal(x[i],x[i],1);\n    y2[i]=y2[i][0]","f92e20ef":"import pandas\ny1_df=pandas.DataFrame(list(zip(x,y1)),columns=['x','y'])\ny2_df=pandas.DataFrame(list(zip(x,y2)),columns=['x','y'])","c6d5d220":"from statsmodels.formula.api import ols","073f3e84":"y1_model = ols(formula='y~x', data=y1_df).fit()\ny2_model = ols(formula='y~x', data=y2_df).fit()","4a5737c0":"print('y1_model parameters \\n', y1_model.params)\nprint('y2_model parameters \\n', y2_model.params)","e97248e1":"import matplotlib.pyplot as plt\nplt.scatter(x, y1)\nplt.plot(x, [ (float(y1_model.params.Intercept)+y1_model.params.x*i) for i in x])\nplt.xlabel('x')\nplt.ylabel('y1')\nplt.title('y1 Linear Regression Plot')","affd9133":"plt.scatter(x, y2)\nplt.plot(x, [ (float(y2_model.params.Intercept)+y2_model.params.x*i) for i in x])\nplt.xlabel('x')\nplt.ylabel('y2')\nplt.title('y2 Linear Regression Plot')","5f5f939f":"plt.scatter(x, [ y1[i]- [(float(y1_model.params.Intercept)+y1_model.params.x*i) for i in x][i] for i in range(len(x))])\nplt.xlabel('x')\nplt.ylabel('residuals')\nplt.title('y1 Residuals Plot')","1dcebad0":"plt.scatter(x, [ y2[i]- [(float(y2_model.params.Intercept)+y2_model.params.x*i) for i in x][i] for i in range(len(x))])\nplt.xlabel('x')\nplt.ylabel('residuals')\nplt.title('y2 Residuals Plot')","d5349752":"from statsmodels.stats.diagnostic import het_white\nwhite_test_y1 = het_white(y1_model.resid,  y1_model.model.exog)\nwhite_test_y2 = het_white(y2_model.resid,  y2_model.model.exog)\nlabels = ['LM-Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\nprint('y1 results', dict(zip(labels, white_test_y1)))\nprint('y2 results', dict(zip(labels, white_test_y2)))","9099051a":"from statsmodels.stats.diagnostic import het_breuschpagan\nbp_y1 = het_breuschpagan(y1_model.resid, y1_model.model.exog)\nbp_y2 = het_breuschpagan(y2_model.resid, y2_model.model.exog)\n\nlabels = ['LM-Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\nprint('y1 results', dict(zip(labels, bp_y1)))\nprint('y2 results', dict(zip(labels, bp_y2)))","11853059":"We see that F-Statistic p-value of Model 2 White Test is <0.05 and we reject the Null Hypothesis of Homoscedasity to conclude it has heteroscedasity.","ea74afea":"We will now illustrate it by creating two datasets, one that satisfies the assumption of homoscedasity and the other that does not.","df2f6c42":"### Some differences between the White Test and Breusch-Pagan Test:\n\n1. Breusch-Pagan assumes heteroskedasticity is linear, which makes it inapplicable in some cases\n2. Breusch-Pagan tests for the presence of heteroskedasticity, while White tests for bias due to heteroskedasticity. \n3. The Breusch-Pagan test can be applied to individual variables.\n4. The Breusch-Pagan test has more power.\n5. The Breusch-Pagan test is much more computationally efficient.","c3c981fc":"# Homoscedasity and Heteroscedasity - White Test and Breusch-Pagan Test\nIn the most simplest terms Homoscedasity means \"equal scatter\", and Heteroscedasity means \"unequal scatter\".\nIn more formal terms, Heteroscedasity means \"a systeamatic change in the spread of the residuals over the range of measured values.\"\nA lot of statistical methods assume homoscedasity, for example, one of the assumptions of Linear Regression is Homoscedasity of residuals. That is the residuals cannot be correlated with the explanatory variable. ","ac4baeec":"Now we plot the residuals against the x values","ef4295f0":"## White Test\nWhite\u2019s test is used to test for heteroscedastic (\u201cdifferently dispersed\u201d) errors in regression analysis. It is a special case of the (simpler) Breusch-Pagan test.\nThe null hypothesis for White\u2019s test is that the variances for the errors are equal. In math terms, that\u2019s:\n$$H_0 = \\sigma^2 _i = \\sigma^2$$\nThe alternate hypothesis (the one you\u2019re testing), is that the variances are not equal:\n$$H_1 = \\sigma^2 _i \\neq \\sigma^2$$\n\nIn cases where the White test statistic is statistically significant, heteroskedasticity may not necessarily be the cause; instead the problem could be a specification error. In other words, the White test can be a test of heteroskedasticity or specification error or both. If no cross product terms are introduced in the White test procedure, then this is a test of pure heteroskedasticity. If cross products are introduced in the model, then it is a test of both heteroskedasticity and specification bias.","1c39248f":"## Breusch-Pagan Test","5d1ae9bf":"Breusch-P test is used to test for heteroscedastic (\u201cdifferently dispersed\u201d) errors in regression analysis.\n\nThe test statistic for the Breusch-Pagan-Godfrey test is:\n$$n * \\mathbb{R}^2 \\textrm{(with k degrees of freedom)}$$\nwhere: $n$ = sample size, $R^2 =$ Coefficient of Determination of the regression of squared residuals from the original regression., and $k$ = number of independent variables.\nThe test statistic approximately follows a chi-square distribution.\n\n\nThe null hypothesis for Breusch-Pagan\u2019s test is that the variances for the errors are equal. In math terms, that\u2019s:\n$$H_0 = \\sigma^2 _i = \\sigma^2$$\nThe alternate hypothesis (the one you\u2019re testing), is that the variances are not equal:\n$$H_1 = \\sigma^2 _i \\neq \\sigma^2$$\n","15091dca":"We see that F-Statistic p-value of Model 2 White Test is <0.05 and we reject the Null Hypothesis of Homoscedasity to conclude it has heteroscedasity.","3ed3359d":"It is evident that for y1, there homscedasity and for y2 there is heteroscedasity. We further conduct statistical tests to confirm this."}}