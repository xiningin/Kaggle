{"cell_type":{"cccdd938":"code","49458014":"code","da594314":"code","057ff5b0":"code","369d21fb":"code","9893b40c":"code","18ffa824":"code","e2ad871e":"code","74127ee1":"code","b43800c0":"code","4cfebbb1":"code","6709801a":"code","582098e7":"code","cc82e6a8":"code","4434a5fd":"code","6103d963":"code","d2a3a397":"code","b608ab2c":"code","182200a7":"code","eddbfd96":"code","a7634129":"code","b773558a":"code","7932830b":"code","4f42322a":"code","7922ca70":"code","df622270":"code","25dc6658":"code","000fd9e3":"code","0b7c4fa2":"code","05cecfdf":"code","0e424942":"code","b58c51cd":"code","a673efa0":"markdown","17d16bf4":"markdown","05b526c2":"markdown","732bc9ee":"markdown","948f18ae":"markdown","bb4c4d4c":"markdown","87aa612c":"markdown","e6350c69":"markdown","b04b9a8c":"markdown","50308b1f":"markdown","4ec59834":"markdown","0b4189a1":"markdown"},"source":{"cccdd938":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport seaborn as sns\nsns.set()\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n#plt.style.use('ggplot')\nfrom sklearn.preprocessing import StandardScaler\n\n# Any results you write to the current directory are saved as output.","49458014":"data = pd.read_csv('..\/input\/Dataset_spine.csv')","da594314":"data.info()","057ff5b0":"data['Unnamed: 13'][:20]","369d21fb":"data.drop(['Unnamed: 13'],axis=1,inplace=True)","9893b40c":"data.columns = ['pelvic_incidence','pelvic tilt','lumbar_lordosis_angle','sacral_slope','pelvic_radius','degree_spondylolisthesis','pelvic_slope','Direct_tilt','thoracic_slope','cervical_tilt','sacrum_angle','scoliosis_slope','State']","18ffa824":"## Let's check how the data looks now\ndata.info()","e2ad871e":"data.describe(include=\"all\")","74127ee1":"data.State.value_counts()","b43800c0":"p = data.plot(kind='box',figsize =(30,15))","4cfebbb1":"fig,ax = plt.subplots(nrows = 3, ncols=4, figsize=(16,10))\nrow = 0\ncol = 0\nfor i in range(len(data.columns) -1):\n    if col > 3:\n        row += 1\n        col = 0\n    axes = ax[row,col]\n    sns.boxplot(x = data['State'], y = data[data.columns[i]],ax = axes)\n    col += 1\nplt.tight_layout()\n# plt.title(\"Individual Features by Class\")\nplt.show()","6709801a":"sns.countplot(y=data.dtypes ,data=data)\nplt.xlabel(\"count of each data type\")\nplt.ylabel(\"data types\")\nplt.show()","582098e7":"from sklearn.preprocessing import LabelEncoder\nlb_make = LabelEncoder()\ndata['State_Code'] = lb_make.fit_transform(data['State'])","cc82e6a8":"data.State_Code.value_counts()","4434a5fd":"data.to_csv('Dataset_spine_clean.csv')","6103d963":"data.hist(figsize=(15,12),bins = 15, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","d2a3a397":"p=sns.pairplot(data, hue = 'State')","b608ab2c":"data.columns","182200a7":"plt.figure(figsize=(15,15))\np=sns.heatmap(data.corr(), annot=True,cmap='RdYlGn') ","eddbfd96":"## null count analysis before modelling to keep check\nimport missingno as msno\np=msno.bar(data)","a7634129":"sc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(data.drop([\"State\",'State_Code'],axis = 1)), columns = ['pelvic_incidence', 'pelvic tilt', 'lumbar_lordosis_angle',\n       'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis',\n       'pelvic_slope', 'Direct_tilt', 'thoracic_slope', 'cervical_tilt',\n       'sacrum_angle', 'scoliosis_slope'])\n#X = data.drop([\"State\",'State_Code'],axis = 1)\ny = data.State_Code","b773558a":"X.head()","7932830b":"#importing train_test_split\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42, stratify=y)\n","4f42322a":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,15):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","7922ca70":"max_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))","df622270":"max_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","25dc6658":"import matplotlib\nplt.figure(figsize=(15,5))\nplt.title('k-NN Varying number of neighbors')\nplt.plot(range(1,15),test_scores,label=\"Test\", marker='*')\nplt.plot(range(1,15),train_scores,label=\"Train\",linestyle='--')\nplt.legend()\nplt.xticks(range(1,15))\nplt.show()","000fd9e3":"#Setup a knn classifier with k neighbors\nknn = KNeighborsClassifier(13)\n\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)","0b7c4fa2":"y_pred = knn.predict(X_test)","05cecfdf":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","0e424942":"#import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","b58c51cd":"from sklearn.metrics import roc_curve\ny_pred_proba = knn.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=13) ROC curve')\nplt.show()","a673efa0":"### storing the preprocessed data for future reference","17d16bf4":"#### Nice thing this column is all about metadata. We'll use the data and drop this column.","05b526c2":"#### Seems like the data has outliers which need to be removed but these could also be real exceptional cases in data. Not every outlier is bad. Let's see how we can best handle them later","732bc9ee":"## We change data type of State from object to integer by label encoding","948f18ae":"### The columns are named in an unintuitive manner. So the unnamed column is all about the column details. We'll use this column data well.\n","bb4c4d4c":"#### Okay! So the data column ranges vary largely. That calls for standardisation at a later stage!","87aa612c":"**DataFrame.describe()** method generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset\u2019s distribution, excluding NaN values. This method tells us a lot of things about a dataset. One important thing is that the describe() method deals only with numeric values. It doesn't work with any categorical values. So if there are any categorical values in a column the describe() method will ignore it and display summary for the other columns unless parameter include=\"all\" is passed.\n\nNow, let's understand the statistics that are generated by the describe() method:\n* count tells us the number of NoN-empty rows in a feature.\n* mean tells us the mean value of that feature.\n* std tells us the Standard Deviation Value of that feature.\n* min tells us the minimum value of that feature.\n* 25%, 50%, and 75% are the percentile\/quartile of each features. This quartile information helps us to detect Outliers.\n* max tells us the maximum value of that feature.","e6350c69":"## Performing KNN at k = 13 (best test score parameter and prime number)","b04b9a8c":"### Applying Stratification on the basis of y to keep the ratio of both categories in the y column maintained in training and testing parts. \n### kept the test size small to conpensate for the too small dataset","50308b1f":"### No null values to deal with. Good!","4ec59834":"### There's one column which is unnamed and has only 14 non null values. That seems rather odd. Let's check what this column is all about ","0b4189a1":"#### Most of the columns don't seem to be normally distributed"}}