{"cell_type":{"945a9e08":"code","a43dfb5b":"code","4396dbc9":"code","e228bd55":"code","e02c1747":"code","24890f69":"code","c09ca104":"code","e92ee742":"code","c3b6045a":"code","4d072a58":"code","194fa4ea":"code","e7b0bee1":"code","3abae8f6":"code","61915ba6":"code","74772cae":"code","d42b8166":"code","0282b903":"code","05f78deb":"code","f6ab4d63":"code","4ca94f12":"code","31a61fe4":"code","04dfb82f":"code","60a54c4f":"code","5cbf6e28":"code","c87a641b":"code","ba5f618c":"code","868266dd":"code","5b1e3ba5":"code","d3dfd4e5":"code","eacb28fa":"code","310a6d62":"code","fe7679c9":"code","84b69cc7":"code","a93256cb":"code","5f15674d":"code","354d0d7e":"code","6a0ec747":"markdown","13920502":"markdown","f6667db9":"markdown","f3aadef0":"markdown","08b30f65":"markdown","8645a09f":"markdown","bba8f257":"markdown","9137fa98":"markdown","054daa3b":"markdown","49a7bcc2":"markdown","6ceeec71":"markdown","1b943043":"markdown","1be5eae2":"markdown","1d491ce5":"markdown","1f1ace27":"markdown","51ce5928":"markdown","e43c6cff":"markdown","26c01909":"markdown"},"source":{"945a9e08":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport spacy\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nfrom sklearn.cluster import KMeans\nfrom sklearn import metrics\nfrom scipy.spatial.distance import cdist\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE","a43dfb5b":"nlp = spacy.load('en_core_web_lg')","4396dbc9":"data = pd.read_csv(\"\/kaggle\/input\/wikipedia-movie-plots\/wiki_movie_plots_deduped.csv\", usecols=['Release Year','Title','Plot'])\ndata.drop_duplicates(inplace=True)\ndata['Title'] = data['Title'].astype(str)\ndata['Title'] = data['Title'].apply(lambda x: x.strip())\ndata.head()","e228bd55":"imdb_titles = pd.read_csv(\"..\/input\/imdb-extensive-dataset\/IMDb movies.csv\", usecols=['title','year','genre'])\nimdb_ratings = pd.read_csv(\"..\/input\/imdb-extensive-dataset\/IMDb ratings.csv\", usecols=['weighted_average_vote'])\n\nratings = pd.DataFrame({'Title':imdb_titles.title,\n                    'Release Year':imdb_titles.year,\n                    'Rating': imdb_ratings.weighted_average_vote,\n                    'Genre':imdb_titles.genre})\nratings.drop_duplicates(subset=['Title','Release Year','Rating'], inplace=True)\nratings.head()","e02c1747":"data = data.merge(ratings, how=\"left\", on=['Title','Release Year'])","24890f69":"data.drop_duplicates(inplace=True)","c09ca104":"print(f'Movies with missing data: {data.Rating.isna().mean()*100:.1f}%')","e92ee742":"#with nlp.disable_pipes():\n#    vectors = np.array([nlp(data.Plot).vector for idx, data in data.iterrows()])\n    \n#vectors.shape","c3b6045a":"import pickle\nmodel_dir = \"\/kaggle\/input\/vector\/\"\nmodel_file = \"vectors.sav\"\n#with open(model_file,mode='wb') as model_f:\n#    pickle.dump(vectors,model_f)","4d072a58":"with open(model_dir + model_file,mode='rb') as model_f:\n    vectors = pickle.load(model_f)","194fa4ea":"data[data.Title.str.contains('Dunkirk')]","e7b0bee1":"plot = data.Plot[21598]\nplot[:500]","3abae8f6":"def cosine_similarity(a, b):\n    return np.dot(a, b)\/np.sqrt(a.dot(a)*b.dot(b))\n\nX = vectors\npca = PCA(n_components=3)\npca_result = pca.fit_transform(X)","61915ba6":"def movie_similarities(plot, **kwargs):\n        \n    # optional parameters\n    params = {'year' : 1900, # list movies after a certain date\n              'new_plot' : True, # if the plot isn't in the dataset\n              'n' : 10, # no. results\n              'rating' : 0.0, # list movies rated above a certain IMDB score\n              'nan' : True} # don't include titles without an IMDB score\n    \n    for key, value in kwargs.items():\n        params[key] = value\n    \n    x = int(params['new_plot'])\n    \n    movie_vec = nlp(plot).vector\n    vec_mean = vectors.mean(axis=0)\n    centered = vectors - vec_mean\n    sims = np.array([cosine_similarity(movie_vec - vec_mean, vec) for vec in centered])\n    \n    movie_index = []\n    movie_title = []\n    movie_year = []\n    movie_rating = []\n    movie_cosine = []\n    movie_genre = []\n    \n    pca_0 = []\n    pca_1 = []\n    pca_2 = []\n    \n    for i in sorted(sims)[-2+x::-1]:\n        if not params['nan'] and np.isnan(data.iloc[np.where(sims == i)[0][0]][\"Rating\"]):\n            pass\n        \n        elif data.iloc[np.where(sims == i)[0][0]][\"Release Year\"] >= params['year'] \\\n                and (data.iloc[np.where(sims == i)[0][0]][\"Rating\"] >= params['rating'] \\\n                or np.isnan(data.iloc[np.where(sims == i)[0][0]][\"Rating\"])):\n            \n            index = np.where(sims == i)[0][0]\n            \n            movie_index.append(index)\n            movie_title.append(data.iloc[index]['Title'])\n            movie_year.append(data.iloc[index][\"Release Year\"])\n            movie_rating.append(data.iloc[index][\"Rating\"])\n            movie_genre.append(data.iloc[index][\"Genre\"])\n            movie_cosine.append(round(i,2))\n            \n            pca_0.append(pca_result[:,0][index])\n            pca_1.append(pca_result[:,1][index])\n            pca_2.append(pca_result[:,2][index])\n                        \n            params['n'] -= 1\n            \n        if params['n'] == 0:\n            break\n            \n    return  pd.DataFrame({'Title':movie_title,\n                        'Year':movie_year,\n                        'IMDB':movie_rating,\n                        'Cosine':movie_cosine,\n                        'Genre':movie_genre,\n                        'pca_0':pca_0,\n                        'pca_1':pca_1,\n                        'pca_2':pca_2},\n                        index=movie_index)","74772cae":"movie_similarities(plot, year=1990).iloc[1:,:5]","d42b8166":"data[data.Title.str.contains('Gladiator')]","0282b903":"movie_similarities(data.Plot[13665]).iloc[1:,:5]","05f78deb":"plot = \"\"\"A young man with no options left must seek a path to glory by uncovering his great grandfather's \nchest. Revealing a time machine that transports him back to the world war 2. Here hitler and his army must \nuse exotic snakes to hypnotise dragons into obeying their command. The confusion of such events unravel to \nreveal our hero has travelled into another dimension where his dream girl awaits for him.\"\"\"","f6ab4d63":"movie_similarities(plot).iloc[:,:5]","4ca94f12":"movie_similarities(data.Plot[20779], n=40).iloc[:,:]","31a61fe4":"def plot_pca(plot, **kwargs):\n    df = movie_similarities(plot, **kwargs)\n    text = df.Title + '<br>IMDB: ' + df.IMDB.astype(str) + '<br>Cosine: ' + round(df.Cosine,2).astype(str)\n    fig = go.Figure()\n\n \n\n    fig.add_trace(go.Scatter3d(\n        x=df.pca_0[1:11],\n        y=df.pca_1[1:11],\n        z=df.pca_2[1:11],\n        name='Harry Potter Films',\n        hovertemplate='%{text}<br><extra><\/extra>',\n        text = text[1:11],\n        mode='markers',\n        marker=dict(\n            size=8,\n            opacity=0.8\n        )\n    ))\n\n    fig.add_trace(go.Scatter3d(\n        x=df.pca_0[:1],\n        y=df.pca_1[:1],\n        z=df.pca_2[:1],\n        name=df.Title.values[0],\n        hovertemplate='%{text}<br><extra><\/extra>',\n        text = text[:1],\n        mode='markers',\n        marker=dict(\n            size=8,\n            opacity=0.8\n        )\n    ))   \n        \n    fig.add_trace(go.Scatter3d(\n        x=df.pca_0[11:],\n        y=df.pca_1[11:],\n        z=df.pca_2[11:],\n        name='Other Films',\n        hovertemplate='%{text}<br><extra><\/extra>',\n        text = text[11:],\n        mode='markers',\n        marker=dict(\n            size=8,\n            opacity=0.8,\n        )\n    ))\n        \n    fig.update_layout(title=f'Movies similar to {df.Title.values[0]}')\n    \n    fig.show()\n    \nplot_pca(data.Plot[20779], n=40)","04dfb82f":"pca = PCA(n_components=0.95, random_state=42)\nX_reduced= pca.fit_transform(vectors)\nX_reduced.shape\n\n# run kmeans with many different k\ndistortions = []\nK = range(2, 50)\nfor k in K:\n    k_means = KMeans(n_clusters=k, random_state=42).fit(X_reduced)\n    k_means.fit(X_reduced)\n    distortions.append(sum(np.min(cdist(X_reduced, k_means.cluster_centers_, 'euclidean'), axis=1)) \/ X.shape[0])\n    if k % 5 == 0:\n        print('Found distortion for {} clusters'.format(k))","60a54c4f":"\n\n\nX_line = [K[0], K[-1]]\nY_line = [distortions[0], distortions[-1]]\n\n# Plot the elbow\nplt.plot(K, distortions, 'b-')\nplt.plot(X_line, Y_line, 'r')\nplt.xlabel('k')\nplt.ylabel('Distortion')plt.title('The Elbow Method showing the optimal k')\nplt.show()","5cbf6e28":"k = 10\nkmeans = KMeans(n_clusters=k, random_state=42)\ny_pred = kmeans.fit_predict(X_reduced)\ndata['y'] = y_pred","c87a641b":"df = movie_similarities(data.Plot[20779], n=100)\nx = df.merge(data['y'].to_frame(), left_index=True, right_index=True)\nx.sort_values(by='Cosine', ascending=False).head(10)","ba5f618c":"df = data\ndf['pca0'] = pca_result[:,0]\ndf['pca1'] = pca_result[:,1]\ndf.dropna(inplace=True)\ndf['y'] = df['y'].astype(str)\ntext = df.Title + '<br>IMDB: ' + df.Rating.astype(str) + '<br>Genre: ' + df.Genre\n \nfig = px.scatter(df, x=\"pca0\", y=\"pca1\", color=\"y\", hover_data=['Title','Genre'])\nfig.show()\n","868266dd":"df.Genre","5b1e3ba5":"genres_df = df['Genre'].apply(lambda x: x.split(\",\")).apply(pd.Series)","d3dfd4e5":"a = pd.DataFrame({'y':df.y, 'Genre':genres_df[0]}).reset_index()\nb = pd.DataFrame({'y':df.y, 'Genre':genres_df[1]}).reset_index()\nc = pd.DataFrame({'y':df.y, 'Genre':genres_df[2]}).reset_index()\n\ngenres_df = a.append(b).append(c).dropna()","eacb28fa":"genres_df","310a6d62":"genres_df.Genre = genres_df.Genre.apply(lambda x: x.strip())\nx = genres_df.groupby(['y','Genre']).count().reset_index()\nx","fe7679c9":"from plotly.subplots import make_subplots\ndi = {\"type\": \"Scatterpolar\"}\nfig = make_subplots(rows=5, cols=2,\n                    subplot_titles=([\"Type \"+str(i) for i in range(10)]), \n                    specs=np.array([di for i in range(10)]).reshape(5,2).tolist())\n                                          \ny=0\nfor i in range(5):\n    for j in range(2):\n        fig.add_trace(go.Scatterpolar(\n              r=x[(x.y == str(y)) & (x.Genre != 'Drama')]['index'],\n              theta=x[(x.y == str(y)) & (x.Genre != 'Drama')].Genre.unique(),\n              fill='toself',\n              name=str(y)\n        ), row=i+1, col=j+1)\n        y += 1\n\nfig.update_traces()\nfig.update_layout(height=1600)\nfig.show()","84b69cc7":"x.sort_values(by=['y','index'], ascending=False).groupby('y')['Genre'].head(10).value_counts().plot(kind='bar')","a93256cb":"x.groupby('Genre').sum().sort_values(by='index', ascending=False).plot(kind='bar')","5f15674d":"not_in = x.sort_values(by=['y','index'], ascending=False).groupby('y')['Genre'].head(10).value_counts().index[:8]","354d0d7e":"from plotly.subplots import make_subplots\ndi = {\"type\": \"Scatterpolar\"}\nfig = make_subplots(rows=5, cols=2,\n                    subplot_titles=([\"Type \"+str(i) for i in range(10)]), \n                    specs=np.array([di for i in range(10)]).reshape(5,2).tolist())\n                                          \ny=0\nfor i in range(5):\n    for j in range(2):\n        fig.add_trace(go.Scatterpolar(\n              r=x[(x.y == str(y)) & (~x.Genre.isin(not_in))]['index'],\n              theta=x[(x.y == str(y)) & (~x.Genre.isin(not_in))].Genre.unique(),\n              fill='toself',\n              name=str(y)\n        ), row=i+1, col=j+1)\n        y += 1\n\nfig.update_traces()\nfig.update_layout(height=1600)\nfig.show()","6a0ec747":"We'll save these vectors as they take an awfully long time","13920502":"The above function lists n number of films with the closest cosine similarity. I've since added optional parameters to list films released from a certain date, and to add a plot not in the original dataset.","f6667db9":"I can certainly see the similarity with Gladiator and The Legend of Hercules but sadly the latter looks like trash with a 4.2% rating on IMDB.\n\n","f3aadef0":"I'm going to take another look at the radar plots but removing the eight most common genre's to get a better insight into the shape of the ach class.","08b30f65":"From the most listed Genre's we can see these are also the ones that appear in each class.","8645a09f":"Finally, lets have some fun and write a movie plot of our own and see what film might me most similar to it.","bba8f257":"We can see the Harry Potter films (in blue) are bunched into one corner. What's interesting though is the film Gambit looks to be the closest to Harry Potter and the Sorcerer's Stone despite it being one of the last listed films on the 40 movies with the cosine similarity closest to 1.","9137fa98":"Now what I'd like to do is plot the list of movies above (based on their similarity to the first Harry Potter film) based on their PCA values. We would hope, that they are grouped closer together then the other films listed.","054daa3b":"# Recommend Movies With Similar Plots\n### Matching the plot descriptions with NLP\n\nI've written a movie recommendation notebook already which uses collaborative filtering, finding movies you might like based on your previous likes and the likes of others. But that can suffer from what's known as a cold start - you need have a list of films you have already voted on, as well as the votes of others!\n\nThis model is just another means about how we might go about finding something of interest. There's many issues with doing it this way as we're just matching the plot description. It could find a terrible with just a similar plot (think Rocky vs Rocky V). It's always fun to play around with though.","49a7bcc2":"Here we have the top ten films that are most similar to the plot of Dunkirk.\nI've not seen U-571, and it's got a fresh rating from Rotten Tomatoes. Looks just up my street, fantastic.\n\nI suppose Speed 2: Cruise Control has boats in it... We can see how this method really doesn't account for genres which is a large feature when trying to find a similiar movie we might like.","6ceeec71":"It'll certainly be useful to see what ratings these films have so lets find an IMDB dataset on here that has ratings and left join it based on the title and date of release.","1b943043":"Taking a peak at the plot for The Mad Monk shows that maybe the fact they both mention dragons is why is was listed as most similar.","1be5eae2":"The cosine similarity will measure the similarities between the text vector and the vector of the mean, giving a value between -1 and 1, with 1 being an exact match.\n\nI'm also going to use principal component analysis on the vectors because why not, and I thought it might be fun to graph these results in 3D space. Do be aware that the PCA vectors will not allign exactly with their cosine similarity. What I mean is a movie with the highest cosine to another will not neccessarily be the closest to that movie when plotting their PCA values.","1d491ce5":"Another film I like is Gladiator (2000) so lets find some similar films again.","1f1ace27":"Looking quickly at the number of rows that didn't match with the IMDB dataset shows just under half that won't have a rating. Film titles can vary greatly depeding on region and if translated to english or not. Plus there is the punctuation that might not match. The year could also be off my a margin of one or two years depending on what region it's basing it's release.","51ce5928":"Lets find a film we want to try and match. I love Dunkirk so lets see if that's in our dataframe.","e43c6cff":"For the ten highest listed genres for each class we can see Crime, Drama, Thriller, and Comedy appear in every class.","26c01909":"Excellent. Now to assign the wiki desciption to the variable plot and take a peak at it's description."}}