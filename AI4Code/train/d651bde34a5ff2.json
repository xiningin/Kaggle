{"cell_type":{"b5a2ff3e":"code","4b3f0d67":"code","45c9a296":"code","841d9c77":"code","44f800dc":"code","9f493bf6":"code","aa18e1e7":"code","56183ba3":"code","c9fa7d7e":"code","a715e5f5":"code","36b9c3b4":"code","91bfdbc4":"code","51239bc6":"code","6079e144":"code","b85abc59":"code","96f816e3":"code","7ba5286b":"code","58cd561f":"markdown","8c9c3e70":"markdown","e2ab8fc2":"markdown","3e38f38a":"markdown","53c0d2dc":"markdown","fcf5f980":"markdown","369d2c86":"markdown","0e9d28e6":"markdown","5aa42b37":"markdown","dcd735c3":"markdown","28ef6082":"markdown","25b345d6":"markdown"},"source":{"b5a2ff3e":"#%% IMPORTING LIBRARIES\n\nimport os\nimport glob\nimport shutil\nimport random\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","4b3f0d67":"#%% IMPORTING DATA\n\ndef importing_data(path):\n    sample = []\n    for filename in glob.glob(path):\n        #img = Image.open(filename,'r')\n        #IMG = np.array(img)\n        sample.append(filename)\n    return sample\n\npath1 = '\/\/kaggle\/input\/brain-tumor-detection\/no\/*.jpg'\npath2 = '\/\/kaggle\/input\/brain-tumor-detection\/yes\/*.jpg'\npath3 = '\/\/kaggle\/input\/brain-tumor-detection\/pred\/*.jpg'\n\ntrain_n = importing_data(path1)\ntrain_y = importing_data(path2)\ntest = importing_data(path3)\n\n#%% CREATION OF DATASETS\n\ndf_train_n = pd.DataFrame({'image':train_n, 'label': 'Healthy'})\ndf_train_y = pd.DataFrame({'image':train_y, 'label': 'Affected'})\ndf_test = pd.DataFrame({'image':test})\ntrain_data = pd.concat([df_train_n, df_train_y])\ntrain_data.head()","45c9a296":"#%% TRAIN-VALIDATION SPLIT (90% TRAIN - 10% VALIDATION)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val = train_test_split(train_data,\n                                  test_size = 0.1,\n                                  shuffle = True,\n                                  random_state = 42)","841d9c77":"#%% CREATING THE CNN MODEL \n\nimport keras\nfrom keras.metrics import AUC, Recall, Precision\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D , MaxPooling2D, Flatten\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import RMSprop\n\ndef build_model():\n    \n    '''Sequential Model creation'''\n    Cnn = Sequential()\n    \n    Cnn.add(Conv2D(64,(5,5), activation = 'relu', padding = 'same',\n                   strides=(2,2), input_shape = [224,224,1]))\n    Cnn.add(MaxPooling2D(2))\n    Cnn.add(Conv2D(128,(5,5), activation = 'relu', padding = 'same', strides=(2,2)))\n    Cnn.add(Conv2D(128,(5,5), activation = 'relu', padding = 'same', strides=(2,2)))\n    Cnn.add(Conv2D(256,(5,5), activation = 'relu', padding = 'same', strides=(2,2)))\n    Cnn.add(MaxPooling2D(2))\n    #Cnn.add(GlobalAveragePooling2D())\n    Cnn.add(Flatten())\n    Cnn.add(Dense(64, activation = 'relu'))\n    Cnn.add(Dropout(0.4))\n    Cnn.add(Dense(32, activation = 'relu'))\n    Cnn.add(Dropout(0.4))\n    Cnn.add(Dense(2, activation = 'softmax'))\n    \n    return Cnn\n\nkeras_model = build_model()\nkeras_model.summary()","44f800dc":"#%% FITTING THE MODEL\n\ndef Model_fit(train_data, val_data):\n    \n    keras_model = None\n    \n    keras_model = build_model()\n    \n    '''Compiling the model'''\n    \n    keras_model.compile(optimizer = RMSprop(learning_rate = 1e-4),\n                        loss='sparse_categorical_crossentropy',\n                        metrics =['acc'])\n    \n    es = EarlyStopping(monitor='val_loss', mode='min',\n                       patience=2,\n                       restore_best_weights=True,\n                       verbose=1)\n                       \n    \n    checkpoint_cb = ModelCheckpoint(\"Brain_model_best.h5\",\n                                    save_best_only=True)\n    \n    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                                  factor = 0.2,\n                                  patience = 3,\n                                  min_lr = 1e-5,\n                                  mode = 'min',\n                                  verbose=1)\n                                  \n    \n    history = keras_model.fit(train_data,\n                              validation_data = val_data,\n                              epochs= 50,\n                              batch_size = 10,\n                              callbacks=[es, checkpoint_cb, reduce_lr])\n                              \n    \n      \n    return history","9f493bf6":"from keras.preprocessing.image import ImageDataGenerator\n\nk_fold = 3\nIMG_SIZE = 224\nsize = (IMG_SIZE,IMG_SIZE)\nn_CLASS = 2\n\ndef CV_training(train_data, val_data):\n    \n    cv_histories = []\n    \n    for i in range(0,k_fold):\n    \n        datagen = ImageDataGenerator(rescale = 1.\/255)\n    \n        train_set = datagen.flow_from_dataframe(train_data,\n                                                directory = '\/\/kaggle\/input\/brain-tumor-detection\/*.jpg',\n                                                x_col = 'image',\n                                                y_col = 'label',\n                                                target_size = size,\n                                                color_mode = 'grayscale',\n                                                class_mode = 'sparse',\n                                                batch_size = 10,\n                                                shuffle = True,\n                                                interpolation = 'bilinear')\n        \n        val_set = datagen.flow_from_dataframe(val_data,\n                                              directory = '\/\/kaggle\/input\/brain-tumor-detection\/*.jpg',\n                                              x_col = 'image',\n                                              y_col = 'label',\n                                              target_size = size,\n                                              color_mode = 'grayscale',\n                                              class_mode = 'sparse',\n                                              batch_size = 10,\n                                              shuffle = True,\n                                              interpolation = 'bilinear')\n        print(\"Training on Fold: \",i+1)\n    \n        cv_histories.append(Model_fit(train_set, val_set))\n    \n    return cv_histories\n\ncv_results = CV_training(X_train,X_val)","aa18e1e7":"#%% CHEKING THE CROSS VALIDATION METRICS\n\ndef acc_results(results):\n    i = 0\n    for fold in cv_results:\n        print('Val_Acc Folder '+ str(i) + ' =', max(fold.history['val_acc']))\n        i += 1\n        \nacc_results(cv_results)","56183ba3":"#%% LOOKING AT THE ACCURACY-LOSS PLOTS FOR EACH FOLD\n\ndef Acc_Loss_Plot(results):\n    \n    for fold in results:\n        \n        acc = fold.history['acc']\n        val_acc = fold.history['val_acc']\n        loss = fold.history['loss']\n        val_loss = fold.history['val_loss']\n    \n        fig, (ax1, ax2) = plt.subplots(1,2, figsize= (10,5))\n        fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n        ax1.plot(range(1, len(acc) + 1), acc)\n        ax1.plot(range(1, len(val_acc) + 1), val_acc)\n        ax1.set_title('History of Accuracy')\n        ax1.set_xlabel('Epochs')\n        ax1.set_ylabel('Accuracy')\n        ax1.legend(['training', 'validation'])\n\n\n        ax2.plot(range(1, len(loss) + 1), loss)\n        ax2.plot(range(1, len(val_loss) + 1), val_loss)\n        ax2.set_title('History of Loss')\n        ax2.set_xlabel('Epochs')\n        ax2.set_ylabel('Loss')\n        ax2.legend(['training', 'validation'])\n        plt.show()\n    \nAcc_Loss_Plot(cv_results)","c9fa7d7e":"#%% LOADING THE MODEL\n\nimport keras\n\nkeras_model = keras.models.load_model('Brain_model_best.h5')\nkeras_model.compile(optimizer = RMSprop(learning_rate = 1e-4),\n                    loss='sparse_categorical_crossentropy', metrics =[ 'acc'])\n\n# Predictions on the test set\n\ndatagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_set = datagen.flow_from_dataframe(df_test,\n                                       directory = '\/\/kaggle\/input\/brain-tumor-detection\/*.jpg',\n                                       x_col = 'image',\n                                       y_col = None,\n                                       target_size = size,\n                                       color_mode = 'grayscale',\n                                       class_mode = None,\n                                       batch_size = 10,\n                                       shuffle = False,\n                                       interpolation = 'bilinear')\n\npredictions = keras_model.predict(test_set)\npredictions = predictions.argmax(axis=-1)\nprint(\"Where 0 = 'Affected'\")\nprint(\"Where 1 = 'Healthy'\")\nprint(predictions)\n","a715e5f5":"pred = []\n[pred.append('Healthy') if i == 1 else pred.append('Affected') for i in predictions]\nprint(pred)","36b9c3b4":"#%% OBTAINING PREDICTIONS OF THE FIRST BATCH\n    \nimages10 = [test_set[0][0],test_set[0][1],test_set[0][2],test_set[0][3],test_set[0][4],\n            test_set[0][5],test_set[0][6],test_set[0][7],test_set[0][8],test_set[0][9]]\n            \nprediction10 = pred[0:9]\nfinal_pred = zip(images10,prediction10)","91bfdbc4":"def pre_visualization(data, predictions):\n    \n    for image,pred in final_pred:\n        plt.imshow(image.reshape(224,224), cmap = 'gray')\n        plt.title(\"Model's Prediction: \" + str(pred))\n        plt.show()\n        \npre_visualization(images10,prediction10)","51239bc6":"#%% IMPORTING LIBRARIES\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.cm as cm\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image","6079e144":"layer_names = [layer.name for layer in keras_model.layers]\nlayer_names","b85abc59":"#%% CREATING THE HEATMAP FROM THE LAYERS' ACTIVATIONS\n\nimg_size = (224, 224)\nlayer_names=[layer.name for layer in keras_model.layers]\n\nlast_conv_layer_name = 'conv2d_15'\nclassifier_layer_names = [\n    'max_pooling2d_7',\n    'flatten_3',\n    'dense_9',\n    'dropout_6',\n    'dense_10',\n    'dropout_7',\n    'dense_11']\n\ndef make_gradcam_heatmap(\n    img_array, model, last_conv_layer_name, classifier_layer_names\n):\n    \n    #img_array = test_set[0][8]\n    img_array = img_array.reshape(1,224,224,1)\n    img_array = img_array[:1]\n    \n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n\n    # Second, we create a model that maps the activations of the last conv\n    # layer to the final class predictions\n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(classifier_input, x)\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        # Compute activations of the last conv layer and make the tape watch it\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        # Compute class predictions\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    # This is the gradient of the top predicted class with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1,2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap\n","96f816e3":"#%% DEFINING A FUNCTION TO DISPLAY THE HEATMAP ON THE REAL IMAGE\n\ndef display(heatmap, img):\n    heatmap = np.uint8(255 * heatmap)\n    # We use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # We use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # We create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[1]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n    \n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * 0.005 + img.reshape(224,224,1)  #img_array.reshape(224,224,1)\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n    \n    return superimposed_img","7ba5286b":"#%% OBSERVING THE RAW IMAGE, THE HEATMAP AND THE SUPERIMPOSED IMAGES TOGETHER\n\nfor img in images10:\n    heatmap = make_gradcam_heatmap(img,\n                                   keras_model,\n                                   last_conv_layer_name,\n                                   classifier_layer_names)\n    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize= (10,5))\n    \n    ax1.imshow(img.reshape(224,224), cmap = 'gray')\n    ax1.set_title('Raw MRI image')\n    ax2.matshow(heatmap)\n    ax3.imshow(display(heatmap,img))\n    ax3.set_title('Superimposed Activation Heatmap')","58cd561f":"<a id=\"subsection-one\"><\/a>\n### CREATING THE CNN MODEL","8c9c3e70":"In this second part of the notebook, the idea is to see where the network focuses its attention during decision processing. This is done by looking at the class activation maps (CAM).","e2ab8fc2":"**Part I:**\n\nThe first section of this work underlines how a simple convolutional neural network performs better than its more complex and already implemented counterparts. A result that is probably due to the easiness of the task. Considering the high similarity among the images, founding the tumoral patterns seems not too hard for the model. Then, we could say that this is a perfect example of the: \"less is more\" saying.","3e38f38a":"<a id=\"section-two\"><\/a>\n### CAM - VISUALIZATION ","53c0d2dc":"<a id=\"section-four\"><\/a>\n### Conclusion","fcf5f980":"<a id=\"section-three\"><\/a>\n### Part II: Tumor Segmentation using U-net","369d2c86":"* [Part I: Classification](#section-one)\n* [Part II: Activations' Visualization](#section-two)\n* [Part III: Segmentation with U-net](#section-three)\n* [Conclusion](#section-four)","0e9d28e6":"In this first part of the notebook, the main aim is to create a model able to distinguish between MRI images of patients affected by a brain tumor and the ones of healthy subjects. To achieve this aim, instead of using a pre-trained model, as done in the other published notebooks, I decided to build a simple Convolutional Neural Network from scratch. Considering that one of the greatest limitations of Deep learning is the interpretability of the models, I wanted to see if a simpler and more interpretable model could achieve or even overcome the results obtained in the other notebooks with deeper models.\n\nP.s: I'm still almost a novice in the field, so feel free to comment or give suggestions to improve or correct the work!","5aa42b37":"<a id=\"section-one\"><\/a>\n## Part I: Classification","dcd735c3":"WORK IN PROGRESS","28ef6082":"Code adapted from: https:\/\/keras.io\/examples\/vision\/grad_cam\/","25b345d6":"## Brain Tumor Detection\n"}}