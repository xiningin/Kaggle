{"cell_type":{"5fdc0d77":"code","7d3e9ac7":"code","27591882":"code","e98a5c3e":"code","3547f04c":"code","7318cad3":"code","f985fc4c":"code","fd131f73":"code","1ac5aea1":"code","049444bf":"code","730735fd":"code","77c0f447":"code","1b8aec28":"code","dd75a15d":"code","82a98db3":"code","6a1ecb37":"code","3aa131de":"code","d18efe81":"code","14ebe21e":"code","d02a6ebc":"code","0f43fa30":"markdown","c4a21569":"markdown","f3a1bd98":"markdown","c40e6342":"markdown","ea55fe60":"markdown"},"source":{"5fdc0d77":"# Installing TabNet through PyTorch\n!pip install pytorch-tabnet","7d3e9ac7":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","27591882":"# Libraries for pre-processing and evaluation\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","e98a5c3e":"train_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv')\ntrain_transaction = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv')","3547f04c":"test_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')\ntest_transaction = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv')","7318cad3":"pd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)","f985fc4c":"train = pd.merge(train_transaction,train_identity,on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","fd131f73":"print('train dataset shape', train.shape)\nprint('test dataset shape', test.shape)","1ac5aea1":"del train_identity, train_transaction, test_identity, test_transaction","049444bf":"# solving incosistent naming of columns\n\nfor i in range(1,39):\n    if i < 10:\n          test.rename(columns = {\"id-0\"+str(i) : \"id_0\"+str(i)}, inplace=True)\n    else:\n          test.rename(columns = {\"id-\"+str(i) : \"id_\"+str(i)}, inplace = True)","730735fd":"cols_lotof_nulls = [c for c in train.columns if (train[c].isnull().sum() \/ train.shape[0])>0.90]\ncols_lotof_nulls_test = [c for c in test.columns if (test[c].isnull().sum() \/ test.shape[0])>0.90]\n\n\ncols_to_drop = list(set(cols_lotof_nulls+ cols_lotof_nulls_test))\nlen(cols_to_drop)\n\ntrain = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)","77c0f447":"# taking categorical colums to give as paratmeter to TabNet classifier\ncat_cols = list(train.select_dtypes(['object']).columns)\n\nlen(cat_cols)\n\n","1b8aec28":"# Using Label encoder to convert categorical to numerical\nfor col in cat_cols:\n  if col in train.columns:\n    le = LabelEncoder()\n    le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n    train[col] = le.transform(list(train[col].astype('str').values))\n    test[col] = le.transform(list(test[col].astype('str').values))","dd75a15d":"# Replacing inf values if any\ntrain = train.replace([np.inf, -np.inf], np.nan)\ntest = test.replace([np.inf, -np.inf], np.nan)","82a98db3":"# Removing columns if they dont have atleast 100000 non-Nan values\ntrain = train.dropna(axis=1, thresh = 250000)\n","6a1ecb37":"# Removing Unnecessary columsn for traing data\nX = train.drop(['isFraud', 'TransactionID'], axis=1)\ny = train.isFraud\n\n# For saving memory\ndel train","3aa131de":"# Custom Loss Function\ndef log_loss_score(actual, predicted,  eps=1e-15):\n    p1 = actual * np.log(predicted+eps)\n    p0 = (1-actual) * np.log(1-predicted+eps)\n    loss = p0 + p1\n\n    return -loss.mean()","d18efe81":"# Filling Nan values with -1\nX = X.fillna(-1)","14ebe21e":"# Training model with kfold strategy\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport torch\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import TimeSeriesSplit\nstrategy = \"KFOLD\"\nnum_ensembling = 1\ndevice = 'cuda'\nEPOCHS = 5\nSPLITS = 5\nsave_name = 'tabnet'\nif strategy == \"KFOLD\":\n    oof_preds_all = []\n    oof_targets_all = []\n    scores_all =  []\n    scores_auc_all= []\n    for seed in range(num_ensembling):\n        print(\"## SEED : \", seed)\n        skf = TimeSeriesSplit(n_splits=SPLITS)\n        oof_preds = []\n        oof_targets = []\n        scores = []\n        scores_auc = []\n        for j, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n            print(\"FOLDS : \", j)\n\n            X_train = torch.tensor(X.iloc[train_idx].values)\n            y_train = torch.tensor(y[train_idx].values)\n            X_val, y_val = torch.tensor(X.iloc[val_idx].values), torch.tensor(y[val_idx].values)\n            model = TabNetClassifier(n_d=8, n_a=8, n_steps=1, gamma=1.3,\n                                     lambda_sparse=0,optimizer_fn=torch.optim.Adam,\n                                   optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n                                     mask_type='entmax', device_name=device, output_dim=1,\n                                     scheduler_params=dict(milestones=[100,150], gamma=0.9), \n                                     scheduler_fn=torch.optim.lr_scheduler.MultiStepLR)\n            #'sparsemax'\n            \n            model.fit(X_train=X_train, y_train=y_train,  eval_set=[(X_train, y_train), (X_val, y_val)],max_epochs=EPOCHS,\n                      patience=20, batch_size=1024, virtual_batch_size=128, eval_name=['train', 'valid'],)\n\n            preds = model.predict(X_val)\n            score = log_loss_score(y_val, preds)\n            name = save_name + f\"_fold{j}_{seed}\"\n            model.save_model(name)\n            ## save oof to compute the CV later\n            oof_preds.append(preds)\n            oof_targets.append(y_val)\n            scores.append(score)\n            roc_ = roc_auc_score(y_val,preds)\n            scores_auc.append(roc_)\n            print(f\"validation fold {j} : {score}, roc AUC Score: {roc_}\")\n        oof_preds_all.append(np.concatenate(oof_preds))\n        \n        oof_targets_all.append(np.concatenate(oof_targets))\n        scores_all.append(np.array(scores))\n        scores_auc_all.append(np.array(scores_auc))","d02a6ebc":"# Prediction on test set\nX_test = test[X.columns].fillna(-1)\nX_test = torch.tensor(X_test.values)\npreds = model.predict_proba(X_test)\n\nsub = pd.DataFrame({'TransactionID': test['TransactionID'].values.tolist(),\n                    'isFraud': preds[:,1].tolist()\n                   })\n\nsub.to_csv('submission.csv', index=False)","0f43fa30":"# Merging transaction data with identity data","c4a21569":"## Data loading","f3a1bd98":"## Encoding categorical variables","c40e6342":"## Feature engineering","ea55fe60":"### Droping columns having null values greater than 90%"}}