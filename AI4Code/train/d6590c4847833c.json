{"cell_type":{"60b0b261":"code","eebd76e5":"code","7eaae406":"code","de44012c":"code","232369dc":"code","c7259cd9":"code","5916c4d0":"code","a971ea47":"code","7841bbe3":"code","f6bbe0a8":"code","6b1ff07b":"code","69e423b6":"code","1a8caa09":"code","ef39443e":"markdown","7e0d88a2":"markdown","c7872a60":"markdown"},"source":{"60b0b261":"!pip install -U tensorflow_hub\n!pip install -U tensorflow_datasets","eebd76e5":"import time\nimport numpy as np\nimport matplotlib.pylab as plt\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()\n\nfrom tensorflow.keras import layers","7eaae406":"(train_examples, validation_examples), info = tfds.load(\n    'cats_vs_dogs',\n    split=['train[:80%]', 'train[80%:]'],\n    with_info=True,\n    as_supervised=True,\n)\ndef format_image(image, label):\n  # `hub` image modules exepct their data normalized to the [0,1] range.\n  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))\/255.0\n  return  image, label\n\nnum_examples = info.splits['train'].num_examples\n\nBATCH_SIZE = 32\nIMAGE_RES = 224\n\ntrain_batches      = train_examples.cache().shuffle(num_examples\/\/4).map(format_image).batch(BATCH_SIZE).prefetch(1)\nvalidation_batches = validation_examples.cache().map(format_image).batch(BATCH_SIZE).prefetch(1)","de44012c":"URL = \"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4\"\nfeature_extractor = hub.KerasLayer(URL,\n                                   input_shape=(IMAGE_RES, IMAGE_RES,3))\nfeature_extractor.trainable = False\n\nmodel = tf.keras.Sequential([\n  feature_extractor,\n  layers.Dense(2)\n])\nmodel.compile(\n  optimizer='adam', \n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n\nEPOCHS = 3\nhistory = model.fit(train_batches,\n                    epochs=EPOCHS,\n                    validation_data=validation_batches)","232369dc":"t = time.time()\n\nexport_path_keras = \".\/{}.h5\".format(int(t))\nmodel.save(export_path_keras)","c7259cd9":"reloaded = tf.keras.models.load_model(\n  export_path_keras, \n  custom_objects={'KerasLayer': hub.KerasLayer})\n\nreloaded.summary()","5916c4d0":"EPOCHS = 3\nhistory = reloaded.fit(train_batches,\n                    epochs=EPOCHS,\n                    validation_data=validation_batches)","a971ea47":"t = time.time()\nexport_path_sm = \".\/{}\".format(int(t))\ntf.saved_model.save(model, export_path_sm)","7841bbe3":"reloaded_sm = tf.saved_model.load(export_path_sm)","f6bbe0a8":"t = time.time()\n\nexport_path_sm = \".\/{}\".format(int(t))\ntf.saved_model.save(model, export_path_sm)","6b1ff07b":"reload_sm_keras = tf.keras.models.load_model(\n  export_path_sm,\n  custom_objects={'KerasLayer': hub.KerasLayer})\n\nreload_sm_keras.summary()","69e423b6":"image_batch, label_batch = next(iter(train_batches.take(1)))\nimage_batch = image_batch.numpy()\nresult_batch = model.predict(image_batch)\nreload_sm_keras_result_batch = reload_sm_keras.predict(image_batch)\n(abs(result_batch - reload_sm_keras_result_batch)).max()","1a8caa09":"!zip -r model.zip {export_path_sm}\ntry:\n  from google.colab import files\n  files.download('.\/model.zip')\nexcept ImportError:\n  pass","ef39443e":"# Export as SavedModel","7e0d88a2":"Now that we've trained the model, we can save it as an HDF5 file, which is the format used by Keras. Our HDF5 file will have the extension '.h5', and it's name will correpond to the current time stamp.","c7872a60":"# Load the Keras .h5 Model\nWe will now load the model we just saved into a new model called reloaded. We will need to provide the file path and the custom_objects parameter. This parameter tells keras how to load the hub.KerasLayer from the feature_extractor we used for transfer learning."}}