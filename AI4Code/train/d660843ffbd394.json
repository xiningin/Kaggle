{"cell_type":{"9c84a01a":"code","4a652c0c":"code","fac15ee1":"code","a68f85f5":"code","a778911d":"code","e5d7c851":"code","aa163a36":"code","478dd743":"code","d252a660":"code","b718b897":"code","ca9a58be":"code","755d3119":"code","f1c3abed":"code","3e51a062":"code","33359eb4":"code","6031cd25":"code","290da950":"code","7cfcba3f":"code","506b8321":"code","d38fd8fa":"code","2ad6a8c1":"code","0244e88a":"code","8eaa4a66":"code","a87b1b12":"code","79ba72b0":"code","33e1cdb5":"code","789c2626":"code","fce59f9d":"code","e470df74":"code","a75d2b18":"code","a8a91bfd":"code","ee23712a":"markdown","3a0f1aff":"markdown","bc6d3d1c":"markdown","12e6f7b2":"markdown","7462f27c":"markdown","5c473f29":"markdown","298f63fe":"markdown","57586769":"markdown","594c1ed2":"markdown","26d98229":"markdown"},"source":{"9c84a01a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4a652c0c":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n","fac15ee1":"data = pd.read_csv('..\/input\/handson-pima\/Hands on Exercise Feature Engineering_ pima-indians-diabetes (1).csv')\ndata.head()","a68f85f5":"#Define certain columns under features X\n\nfeature_cols = ['Preg','Plas','Pres','skin','test','mass','age']\nX = data[feature_cols]\ny = data['class']","a778911d":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state = 1)\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","e5d7c851":"y_pred_class  = logreg.predict(X_test)","aa163a36":"#How accurate is this predicted y_test\nfrom sklearn import metrics\nprint(metrics.accuracy_score(y_test, y_pred_class))","478dd743":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_logreg = confusion_matrix(y_test, y_pred_class)\ncm_logreg","d252a660":"TP = 40\nTN = 110\nFN = 29\nFP = 13","b718b897":"#Lets calculate Classification Accuracy, Misclassification rate, Sensitivity, Specificity, False Positive Rate, Precision\n\n#Classification Accuracy: Overall, how often is the classifier correct?\n\nprint((TP + TN)\/ float(TP +TN+FP+FN))\nprint(metrics.accuracy_score(y_test, y_pred_class))\n","ca9a58be":"#Classification Error: Overall, how often is the classifier incorrect?\n#Also known as \"Misclassification Rate\"\n\nprint((FP +FN)\/ float(TP +TN+FP+FN))\nprint(1 - metrics.accuracy_score(y_test, y_pred_class))","755d3119":"#Sensitivity: When the actual value is positive, how often is the prediction correct?\n\n#- How \"sensitive\" is the classifier to detecting positive instances?\n#- Also known as \"True Positive Rate\" or \"Recall\"\n\nprint(TP\/ float(TP +FN))\nprint(metrics.recall_score(y_test, y_pred_class))","f1c3abed":"#**Specificity:** When the actual value is negative, how often is the prediction correct?\n#- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n\nprint(TN\/ float(TN+FP))","3e51a062":"#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\nprint(FP\/ float(TN +FP))","33359eb4":"#Precision: When a positive value is predicted, how often is the prediction correct?\n\n#How \"precise\" is the classifier when predicting positive instances?\n\n\nprint(TP\/ float(TP +FP))\nprint(metrics.precision_score(y_test, y_pred_class))\n","6031cd25":"#print the first 10 predicted class with default threshold of .5\n\nlogreg.predict(X_test)[0:10]","290da950":"# print the first 10 predicted probabilities of class membership\n\nlogreg.predict_proba(X_test)[0:10,:]","7cfcba3f":"# print the first 10 predicted probabilities for class 1  (diabetics)\nlogreg.predict_proba(X_test)[0:10,1]","506b8321":"# store the predicted probabilities for diabetic class for all records... \ny_pred_prob = logreg.predict_proba(X_test)[:, 1]","d38fd8fa":"# predict diabetes if the predicted probability is greater than 0.3\nfrom sklearn.preprocessing import binarize\ny_pred_class = binarize([y_pred_prob], 0.3)[0]  # deciding the class of the 1st 10 records based on new threshold","2ad6a8c1":"# print the first 10 predicted probabilities\ny_pred_prob[0:10]","0244e88a":"# print the first 10 predicted classes with the lower threshold. Note the change in class...\n# with threshold of .5 (default) , the first data point would belong to 0 class i.e. non-diabetic\ny_pred_class[0:10]","8eaa4a66":"# previous confusion matrix (default threshold of 0.5)\nprint(metrics.confusion_matrix(y_test, y_pred_class))","a87b1b12":"# sensitivity has increased (used to be 0.57)\nprint(98\/float(98 + 48))","79ba72b0":"# specificity has increased (used to be 0.91)\nprint(98\/ float(98+72))","33e1cdb5":"# IMPORTANT: first argument is true values, second argument is predicted probabilities\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\nplt.plot(fpr,tpr)\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.0])\nplt.title('ROC curve for diabetes classifier')\nplt.xlabel('False Positive Rate (1-Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","789c2626":"# define a function that accepts a threshold and prints sensitivity and specificity\n\ndef evaluate_threshold(threshold):\n    print('Sensitivity:', tpr[thresholds > threshold][-1])\n    print('Specificity:', 1 - fpr[thresholds > threshold][-1])\n","fce59f9d":"evaluate_threshold(0.5)","e470df74":"evaluate_threshold(0.3)","a75d2b18":"# IMPORTANT: first argument is true values, second argument is predicted probabilities\nprint(metrics.roc_auc_score(y_test, y_pred_prob))","a8a91bfd":"#calculate cross validated AUC\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(logreg,X,y, cv = 10, scoring = 'roc_auc').mean()","ee23712a":"# 1. Load packages and observe dataset","3a0f1aff":"**Confusion matrix advantages:**\n\n- Allows you to calculate a **variety of metrics**\n- Useful for **multi-class problems** (more than two response classes)\n\n**ROC\/AUC advantages:**\n\n- Does not require you to **set a classification threshold**\n- Still useful when there is **high class imbalance**","bc6d3d1c":"### Reduce the threshold from .5 to .3 to predict the diabetics class. This will make the model sensitive to diabetic class","12e6f7b2":"# Observations:\n\n- Default threshold of .5 is not sensitive towards diabetic class. Lowering the threshold increases the sensitivity to\n- diabetic class","7462f27c":"- AUC is useful as a **single number summary** of classifier performance.\n- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation.\n- AUC is useful even when there is **high class imbalance** (unlike classification accuracy).","5c473f29":"# 4. ROC Curves and Area Under the Curve (AUC)\n\n**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n\n**Answer:** Plot the ROC curve!","298f63fe":"# 3. Adjusting classification threshold","57586769":"- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself","594c1ed2":"AUC is the **percentage** of the ROC plot that is **underneath the curve**:","26d98229":"# 2. Train Logistic Regression"}}