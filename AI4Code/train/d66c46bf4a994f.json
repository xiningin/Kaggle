{"cell_type":{"0a615652":"code","c097c332":"code","d96e72bc":"code","de5d6088":"code","ee09ea31":"code","bc75108a":"code","d272f1d6":"code","6fede398":"code","d2482b48":"code","bc41df26":"code","3322553a":"code","8ceb87be":"code","9e0ac614":"markdown","8b7bed1f":"markdown","07e32587":"markdown","6208fe36":"markdown","165ed291":"markdown","49b106d2":"markdown","181b1726":"markdown","d77b7bbd":"markdown","474c322c":"markdown","06a623be":"markdown","1484011d":"markdown"},"source":{"0a615652":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import TimeDistributed, Dense, Dropout, SimpleRNN, RepeatVector\nfrom tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n\nfrom termcolor import colored\n\nprint('Tested with tensorflow version 2.0.1')\nprint('Using tensorflow version:', tf.__version__)","c097c332":"all_chars = '0123456789+'","d96e72bc":"num_features = len(all_chars)\n\nchar_to_index = dict((c, i) for i, c in enumerate(all_chars))\nindex_to_char = dict((i, c) for i, c in enumerate(all_chars))\n\nprint('Number of features:', num_features)","de5d6088":"def generate_data():\n    first_num = np.random.randint(low=0,high=100)\n    second_num = np.random.randint(low=0,high=100)\n    example = str(first_num) + '+' + str(second_num)\n    label = str(first_num+second_num)\n    return example, label\n\ngenerate_data()","ee09ea31":"hidden_units = 128\nmax_time_steps = 5\n\nmodel = Sequential([\n    SimpleRNN(hidden_units, input_shape=(None, num_features)),\n    RepeatVector(max_time_steps),\n    SimpleRNN(hidden_units, return_sequences=True),\n    TimeDistributed(Dense(num_features, activation='softmax'))\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","bc75108a":"def vectorize_example(example, label):\n    \n    x = np.zeros((max_time_steps, num_features))\n    y = np.zeros((max_time_steps, num_features))\n    \n    diff_x = max_time_steps - len(example)\n    diff_y = max_time_steps - len(label)\n    \n    for i, c in enumerate(example):\n        x[diff_x+i, char_to_index[c]] = 1\n    for i in range(diff_x):\n        x[i, char_to_index['0']] = 1\n    for i, c in enumerate(label):\n        y[diff_y+i, char_to_index[c]] = 1\n    for i in range(diff_y):\n        y[i, char_to_index['0']] = 1\n        \n    return x, y\n\ne, l = generate_data()\nprint('Text Example and Label:', e, l)\nx, y = vectorize_example(e, l)\nprint('Vectorized Example and Label Shapes:', x.shape, y.shape)","d272f1d6":"def devectorize_example(example):\n    result = [index_to_char[np.argmax(vec)] for i, vec in enumerate(example)]\n    return ''.join(result)\n\ndevectorize_example(x)","6fede398":"def create_dataset(num_examples=2000):\n\n    x_train = np.zeros((num_examples, max_time_steps, num_features))\n    y_train = np.zeros((num_examples, max_time_steps, num_features))\n\n    for i in range(num_examples):\n        e, l = generate_data()\n        x, y = vectorize_example(e, l)\n        x_train[i] = x\n        y_train[i] = y\n    \n    return x_train, y_train\n\nx_train, y_train = create_dataset()\nprint(x_train.shape, y_train.shape)","d2482b48":"devectorize_example(x_train[0])","bc41df26":"devectorize_example(y_train[0])","3322553a":"simple_logger = LambdaCallback(\n    on_epoch_end=lambda e, l: print('{:.2f}'.format(l['val_accuracy']), end=' _ ')\n)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\n\nmodel.fit(x_train, y_train, epochs=500, validation_split=0.2, verbose=False,\n         callbacks=[simple_logger, early_stopping])","8ceb87be":"x_test, y_test = create_dataset(num_examples=20)\npreds = model.predict(x_test)\nfull_seq_acc = 0\n\nfor i, pred in enumerate(preds):\n    pred_str = devectorize_example(pred)\n    y_test_str = devectorize_example(y_test[i])\n    x_test_str = devectorize_example(x_test[i])\n    col = 'green' if pred_str == y_test_str else 'red'\n    full_seq_acc += 1\/len(preds) * int(pred_str == y_test_str)\n    outstring = 'Input: {}, Out: {}, Pred: {}'.format(x_test_str, y_test_str, pred_str)\n    print(colored(outstring, col))\nprint('\\nFull sequence accuracy: {:.3f} %'.format(100 * full_seq_acc))","9e0ac614":"**So we have generated the first data of what we would be using for this model development**","8b7bed1f":"# Loading the Libraries","07e32587":"# Create a Model\nHere we specify the input parameters for an RNN model","6208fe36":"# Workflow \n1. Loading the Libraries\n2. Generating the Dataset\n3. Create the Model\n4. Vectorize and De-Vectorize the Data\n5. Training the model and Predictions ","165ed291":"# Create Dataset","49b106d2":"# Training and Predictions","181b1726":"# Basic RNN Understanding\n\nA **recurrent neural network (RNN)** is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs.This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition\n\n![rnn](https:\/\/miro.medium.com\/max\/1254\/1*go8PHsPNbbV6qRiwpUQ5BQ.png)\n\nMore Detailed Info can be found on [Medium](https:\/\/towardsdatascience.com\/understanding-rnn-and-lstm-f7cdf6dfc14e)","d77b7bbd":"# Vectorize and De-Vectorize data\nWe convert these datasets into vectorized and de-vectorized form for the model to work efficiently as Machine Learning models require numerical values to compute","474c322c":"# Generate Dataset\nLet's start with assigning a variable to all the numbers from 0 to 9 in string format, + indicates to add","06a623be":"***So we are able to get the representation of data as shown above now our dataset is ready for model based evaluations!!***","1484011d":"# Introduction\n\n# Making the Model learn Addition!!\nGiven the string \"54+7\", the model should return a prediction: \"61\".\n\nHere is my Github repo on [this](https:\/\/github.com\/digs1998\/RNN-implementations) Do refer this and fork my repository"}}