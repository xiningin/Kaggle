{"cell_type":{"4ac082b4":"code","d8022ed2":"code","d1d48eb6":"code","09922e05":"code","9343b83f":"code","3698d848":"code","9a76ae32":"code","634b8af9":"code","74d548a5":"code","56af1d41":"code","69c74114":"code","445e623e":"code","7f2bdc43":"code","07127d2f":"code","fd72c835":"code","04188d9f":"markdown","f9091600":"markdown","070dfa5e":"markdown","54633580":"markdown","fba9c249":"markdown","df1adf31":"markdown"},"source":{"4ac082b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport re\n\nsns.set()\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8022ed2":"df_lap = pd.read_csv('\/kaggle\/input\/laptop-price\/laptop_price.csv', encoding='latin-1')\ndf_lap.head()","d1d48eb6":"df_lap.isna().sum()","09922e05":"df_lap.dtypes","9343b83f":"\ndf_lap['Weight'] = df_lap['Weight'].apply(lambda x: re.search('[+-]?([0-9]*[.])?[0-9]+', x).group())\ndf_lap['Weight'] = df_lap.Weight.astype('float')\n\ndf_lap.drop('laptop_ID', inplace=True, axis=1)","3698d848":"#split train and target data\n\ntrain, train_target = df_lap.iloc[:, :-1], df_lap.iloc[:, -1]","9a76ae32":"num_col = [x for x in train.columns if train[x].dtype != 'object']\nstr_col = [x for x in train.columns if train[x].dtype == 'object']","634b8af9":"#standardize numerical columns\n\nfor i in num_col:\n    train[i] = (train[i] - train[i].mean()) \/ train[i].std()","74d548a5":"train_target = np.log(train_target)","56af1d41":"train = pd.get_dummies(train)","69c74114":"train","445e623e":"# split train and validation\n\ntrain_inputs, train_targets = train[:int(.8 * len(train))], train_target[:int(.8 * len(train_target))]\nvalidation_inputs, validation_targets = train[int(.8 * len(train)):], train_target[int(.8 * len(train_target)):]","7f2bdc43":"#train a dnn\n\ninput_size = train_inputs.shape[1]\nhidden_size = 100\noutput_size = 1\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(input_size, kernel_initializer='he_normal'),\n    tf.keras.layers.Dropout(.1),\n    tf.keras.layers.Dense(hidden_size, activation='relu'),\n    tf.keras.layers.Dropout(.1),\n    tf.keras.layers.Dense(hidden_size, activation='relu'),\n    tf.keras.layers.Dropout(.1),\n    tf.keras.layers.Dense(output_size, activation='relu')\n])\n\nopt = tf.keras.optimizers.Adam(\n        learning_rate=.0001\n    )\n\nmodel.compile(optimizer=opt, loss='mean_absolute_percentage_error')\n\nbatch_size = 32\nmax_epochs = 50\n\nmodel.fit(\n    train_inputs,\n    train_targets,\n    epochs = max_epochs,\n    batch_size = batch_size,\n    validation_data=(validation_inputs, validation_targets),\n    verbose=2\n)\n","07127d2f":"from sklearn.ensemble import RandomForestRegressor\n\nr_reg = RandomForestRegressor()\nr_reg.fit(train_inputs, train_targets)\nr_reg.score(validation_inputs, validation_targets)","fd72c835":"from sklearn.tree import DecisionTreeRegressor \n\nd_reg = DecisionTreeRegressor()\nd_reg.fit(train_inputs, train_targets)\nd_reg.score(validation_inputs, validation_targets)","04188d9f":"## train a Deep neuaral network","f9091600":"## lets try some other regression algorithms","070dfa5e":"### we get on the first 81% and on the second 76% which is way lower than our deep netwok","54633580":"### we got a 96% on the validation set","fba9c249":"## Data Processing","df1adf31":"## Data cleaning"}}