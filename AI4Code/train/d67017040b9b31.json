{"cell_type":{"b8b4e234":"code","69e1a59c":"code","bbd7dd46":"code","70a43ee6":"code","44acd574":"code","f1f4e7b5":"code","3422c8d8":"code","08895379":"code","12cbff6f":"code","987298b5":"code","017d9780":"code","846b6ccf":"code","dc50b674":"code","eae6b76f":"code","5ebefaec":"code","fc333cca":"code","c3bb3414":"code","1688f93e":"markdown","ccc8aaa3":"markdown","aa0716d1":"markdown","f1969598":"markdown","f08a54a7":"markdown","59cbfe80":"markdown","a9b9b614":"markdown","9856647d":"markdown","fb0d2ef0":"markdown","157acd91":"markdown","b79dae52":"markdown","df7af614":"markdown","20bf10f9":"markdown","515ca395":"markdown","353b9cec":"markdown","9f3735cd":"markdown","ecfc873d":"markdown","4c27db83":"markdown"},"source":{"b8b4e234":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# for drawing graphs \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n# Classification algorithms \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","69e1a59c":"dt_train = pd.read_csv(\"..\/input\/train.csv\")\ndt_test = pd.read_csv(\"..\/input\/test.csv\")\n","bbd7dd46":"print(\"-\" * 5, \"train data:\", \"-\" * 5)\ndt_train.info()\nprint(\"-\" * 5, \"test data:\", \"-\" * 5)\ndt_test.info()","70a43ee6":"#get passenger Id of test data \ntest_PassengerId = dt_test.PassengerId.values \ndt_train.head(5)","44acd574":"# combine these datasets to run certain operations on both datasets together\ncombined =[dt_train, dt_test]\n\nfor dataset in combined:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    dataset.drop(['PassengerId', 'Name','Ticket','Cabin'], axis=1, inplace=True)\n    dataset['Fare'] = dataset['Fare'].fillna(0)\n    dataset['Sex'] = [1 if each =='female' else 0 for each in dataset.Sex ]\n    dataset['Embarked'] = [1 if each =='C' else 2 if each =='Q' else 3 if each =='S' else 0 for each in dataset.Embarked ]\n    dataset['Age'] = dataset['Age'].fillna((dataset['Age'].mean()))\n    dataset['Age'] = [1 if each <17 else 2 if each >= 18 and each <= 35 else 3 if each >= 36 and each <= 45 else 4 if each >= 36 and each <= 55 else 5 if each >= 56 and each <= 65 else 6 if each >65 else 0 for each in dataset.Age ]\n    ","f1f4e7b5":"#Convert Title to Integer\ndt_train.Title.unique()","3422c8d8":"for dataset in combined:\n    dataset['Title'] = [1 if each in('Mr','Sir') else 2 if each in('Mrs','Miss','Lady','Ms') else 3 if each in('Capt','Dr','Major') else 4 for each in dataset.Title ]","08895379":"dt_train.head(10)","12cbff6f":"plt.subplots(figsize=(8,5))\nax = sns.countplot(dt_train['Age'],hue=dt_train['Survived'],order=[1,2,3,4,5,6])\nplt.title('Distribution of Age range survived')\nplt.xlabel('Age range')\nplt.ylabel('Survived count')\nfor p in ax.patches:\n        ax.annotate(p.get_height(), (p.get_x()+0.1, p.get_height()+50))\n        \nplt.show()","987298b5":"fig1, ax1 = plt.subplots(figsize=(8,5))\nsf = dt_train['Pclass'].value_counts() #Produces Pandas Series\nexplode =()\nfor i in range(len(sf.index)):\n    if i == 0:\n        explode += (0.1,)\n    else:\n        explode += (0,)\n\nax1.pie(sf.values, explode=explode,labels=sf.index, autopct='%1.1f%%', shadow=True, startangle=90)\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.legend()\nplt.show()","017d9780":"# I want to train test split on train data \ny = dt_train.Survived.values\nX = dt_train.drop(['Survived'],axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\nprint('weights are : ', logreg.coef_)","846b6ccf":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","dc50b674":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","eae6b76f":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","5ebefaec":"y_pred = logreg.predict(dt_test)\nsurvived_test = (y_pred == 0).sum()\nnot_survived_test = (y_pred == 1).sum()\n","fc333cca":"df_result = pd.DataFrame(y_pred, index=test_PassengerId)\ndf_result","c3bb3414":"\nprint('With probabilty of %0.81, ',survived_test,' of test data passengers are survived and ',not_survived_test,' of test data passengers are not survived')","1688f93e":"[Go to top](#0)","ccc8aaa3":"## <div id=\"3\"> 3. Visualize Data<div\/>","aa0716d1":"## <div id=\"4\"> 4. Train Data<div\/>","f1969598":"## <div id=\"1\"> 1. Read and Recognize Data <div\/>","f08a54a7":"* Most passengers are between age 18 and 35 and most did not survived<br>","59cbfe80":"[Go to top](#0)","a9b9b614":"## <div id=\"5\"> 5. Predict Data<div\/>","9856647d":"[Go to top](#0)","fb0d2ef0":"55.1 % of passengers have 3rd class ticket  and 24.2 percent has 1st class ","157acd91":"<a id=\"0\"> <a\/>\n# **Titanic Disaster Data Analysis**<br><br>\n\n[1. Read and Recognize Data](#1)<br>\n[2. Cleanse Data](#2)<br>\n[3. Visualize Data](#3)<br>\n[4. Train Data](#4)<br>\n[5. Predict Data](#5)<br>\n[6. Conclusion](#6)<br>","b79dae52":"The result is telling us that we have 44+29 correct predictions and 10+7 incorrect predictions.","df7af614":"**Roc Curve**<br>\n\nThe receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner).","20bf10f9":"**Compute precision, recall, F-measure and support**\n\nThe precision is the ratio tp \/ (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n\nThe recall is the ratio tp \/ (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n\nThe F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n\nThe F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n\nThe support is the number of occurrences of each class in y_test.","515ca395":"**Confusion Matrix**","353b9cec":"## <div id=\"2\"> 2. Cleanse Data <div\/><br>\n\nWe will fo below cleaning operations fro both datasets <br>\n\n* Add Title feature before drop Name<br>\n* Drop PassengerId, Name, Ticket , Cabin<br>\n* Update Nan vaklues in Fare with zerp\n*  Convert Sex to integer<br>\n        * Sex = 'female' : 1\n        * Sex = 'male' : 2\n* Convert Embarked to integer <br>\n        * Embarked = 'C' :1 \n        * Embarked = 'Q' :2\n        * Embarked = 'S' :3 \n* Update Nan values of Age with mean value <br>\n* Convert age to age range <br>\n        * age <17 : 1\n        * age >=18  and age <= 35 : 2\n        * age >=36  and age <= 45 : 3\n        * age >=46  and age <= 55 : 4\n        * age >=56  and age <= 65 : 5\n        * age > 65: 6\n    \n* Convert Title to Integer<br>\n        * Title  in('Mr','Sir')  :1 \n        * Title in('Mrs','Miss','Lady','Ms') :2\n        * Title in('Capt','Dr','Major') :3 \n        * Else others : 4","9f3735cd":"## <div id=\"6\"> 6. Conclusion<div\/>","ecfc873d":"[Go to top](#0)","4c27db83":"[Go to top](#0)"}}