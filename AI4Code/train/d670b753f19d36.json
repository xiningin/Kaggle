{"cell_type":{"7bca3d9f":"code","6abb086b":"code","b5193697":"code","305f332e":"code","e7d89f5b":"code","9e9da1e2":"code","82b069af":"code","f23dceda":"code","f8dbecd2":"code","00f76732":"code","417f4c6f":"code","1fab3286":"code","c90061a3":"code","56564018":"code","4ab66faa":"code","3b6c6443":"code","e9f4ce54":"code","5a3271e8":"code","2cafc790":"code","634bf3e6":"code","c52b8ff1":"code","dd78784b":"code","924f8a73":"code","c7b767e0":"code","d56acaf3":"code","26c376fc":"code","404d2901":"code","3bbb44a8":"code","e9164745":"code","a8044285":"code","44449a49":"code","a3433f65":"code","be0c9e2a":"code","e066d28c":"code","ec8ed659":"code","7f878079":"code","55d6be79":"code","bf1562f8":"code","22f96e86":"markdown","f9d70d15":"markdown","13cd4d27":"markdown","77e28240":"markdown","3f4e23ca":"markdown","dcccb461":"markdown","f160ce5e":"markdown","594d697f":"markdown","f3a9d5ef":"markdown","7df85fc5":"markdown","571df1eb":"markdown","047b82fd":"markdown","cf417549":"markdown","50bea9f3":"markdown","e31d9ff3":"markdown","57b40c00":"markdown","dca238d8":"markdown","18e6b302":"markdown","cbdb0f09":"markdown","87da7c9e":"markdown","c67d7a97":"markdown","0dc11fa1":"markdown","d3ff9477":"markdown","4d073667":"markdown","6cd93379":"markdown","06c3ff64":"markdown","68f65d7e":"markdown","c4479bce":"markdown","f075142e":"markdown","ce338db4":"markdown","368b4ca1":"markdown","f45f45cf":"markdown","6287efd9":"markdown","b4c97d1b":"markdown","79f28217":"markdown","ae60734e":"markdown","2ecfe783":"markdown","b71875db":"markdown","9d2d28c0":"markdown","84e94efd":"markdown"},"source":{"7bca3d9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6abb086b":"df1=pd.read_csv('..\/input\/the-movies-dataset\/credits.csv')\ndf2=pd.read_csv('..\/input\/the-movies-dataset\/movies_metadata.csv')\n\n","b5193697":"\ndf2.head()","305f332e":"df2['id']","e7d89f5b":"df1['id']","9e9da1e2":"df2 = df2[df2.id!='1997-08-20']\ndf2 = df2[df2.id!='2012-09-29']\ndf2 = df2[df2.id!='2014-01-01']\n","82b069af":"df1.id","f23dceda":"df2['id'] = df2['id'].astype(int)","f8dbecd2":"df2.id","00f76732":"df2=df2.merge(df1, on='id')","417f4c6f":"df2.columns","1fab3286":"df2['overview'].head()","c90061a3":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english')\n\n#Replace NaN with an empty string\ndf2['overview'] = df2['overview'].fillna('')\n\n","56564018":"from sklearn.metrics.pairwise import linear_kernel\n\n\n\n","4ab66faa":"import random\nran = random.randint(25000, 30000)\ndf3 = df2.head(ran)\ntfidf_matrix = tfidf.fit_transform(df3['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","3b6c6443":"cosine_sim =  linear_kernel(tfidf_matrix, tfidf_matrix, True)","e9f4ce54":"indices = pd.Series(df3.index, index=df3['title']).drop_duplicates()","5a3271e8":"def get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return df3['title'].iloc[movie_indices]","2cafc790":"get_recommendations('Assassins')","634bf3e6":"get_recommendations('Carrington')","c52b8ff1":"df4=pd.read_csv('..\/input\/the-movies-dataset\/keywords.csv')","dd78784b":"df4.head()","924f8a73":"df2 = df2.merge(df4, on='id')","c7b767e0":"df2.head()\n","d56acaf3":"from ast import literal_eval\n\nfeatures = ['cast', 'crew', 'keywords', 'genres']\nfor feature in features:\n    df2[feature] = df2[feature].apply(literal_eval)","26c376fc":"df2.head()","404d2901":"#function to return director name from crew column\ndef get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan","3bbb44a8":"#function to get names of genres, cast and keywords from the data\ndef get_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n        if len(names) > 3:\n            names = names[:3]\n        return names\n\n    #Return empty list in case of missing\/malformed data\n    return []","e9164745":"# Define new director, cast, genres and keywords features that are in a suitable form.\ndf2['director'] = df2['crew'].apply(get_director)\n\nfeatures = ['cast', 'keywords', 'genres']\nfor feature in features:\n    df2[feature] = df2[feature].apply(get_list)","a8044285":"# Print the new features of the first 3 films\ndf2[['title', 'cast', 'director', 'keywords', 'genres']].head(3)","44449a49":"# Function to convert all strings to lower case and strip names of spaces\ndef clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        #Check if director exists. If not, return empty string\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''","a3433f65":"# Apply clean_data function to the features.\nfeatures = ['cast', 'keywords', 'director', 'genres']\n\nfor feature in features:\n    df2[feature] = df2[feature].apply(clean_data)","be0c9e2a":"def create_soup(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\ndf2['soup'] = df2.apply(create_soup, axis=1)\ndf2['soup']","e066d28c":"# Import CountVectorizer and create the count matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncount = CountVectorizer(stop_words='english')\n\n# again we take a part of dataset as our kernel cannot handle all the dataset together.\n \ndf5 = df2['soup'].head(20000)\n\ncount_matrix = count.fit_transform(df5)\n ","ec8ed659":"from sklearn.metrics.pairwise import cosine_similarity\n\ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)","7f878079":"# we just reset the index of main data\ndf2 = df2.reset_index()\nindices = pd.Series(df2.index, index=df2['title'])","55d6be79":"#finally calling the get_recommendation fucntion\nget_recommendations('Assassins', cosine_sim2)","bf1562f8":"get_recommendations('Jumanji', cosine_sim2)","22f96e86":"After experimenting with many values, I found that kaggle kernel can bear upto 35000 entries of movies dataset. Anything greater and the kernel ram exceds 16GB!! \n<br>\nSo now taking a random part of dataset to generate cosine values.","f9d70d15":"So, I am further trying to use other properties like movie genre, ratings, keywords, crew etc \n\n**Taking important features like movie genres, caste of the movie, keywords etc will help to build a much more accurate recommender system**","13cd4d27":"Now I create a *get_recommendation* function which accpets a movie title from the user and recommends similar movies to the user based on the title by taking the cosine simalarity scores of the most similar movies.\n<br>\n This function will recommend the 10 most similar movies","77e28240":"The shape of the tfid_matrix gives us the number of distinct words used to define our entries of 45538 movies. We have 75827 distinct english words used to describe the overview of the movies ","3f4e23ca":"We finally merge keywords dataset with our original dataset","dcccb461":"\n\nRefer the following link for information about the dataset:\n\nhttps:\/\/www.kaggle.com\/rounakbanik\/the-movies-dataset#movies_metadata.csv[](http:\/\/)\n\nPrinting first 5 entries of movies_metadata.csv","f160ce5e":"### **The system is now able to recommend movies which are really similar to the one mentioned i.e Assasins. It has taken into account all the important features like the director of the movie, cast, and the various keywords associated with the movie.**","594d697f":"I have tried my best to explained all the steps that I have performed in the notebook and my approach for the task as well. \n\nI always aim to create an **accurate solution ** and not just a solution. Here too I have tried to achieve the same!!","f3a9d5ef":"Another try for any romantic movie!!","7df85fc5":" Time to Test my code XD","571df1eb":"First we read the keywords.csv dataset","047b82fd":"Yeah!! We get recommendation of similar romantic movies","cf417549":"Now I wrote some functions to clean and extract  important features like directors, genres, and keywords from the data","50bea9f3":"Finally, I perform some cleaning on the data","e31d9ff3":"I calculate the **similarity scores**  for the overview of each movie entry in the dataset \n<br>\n\nfor that I  use a text encoding technique known as **word_to_vec** in order to convert each overview into numeric embeddeings. This technique is used to convert textual data into numeric vectors","57b40c00":"**WOAHH !!!!**  I gave input as a crime movie and it was able to succesfully recommend me set of similar crime movies","dca238d8":"**Jumanji being a fantasy movie, the system is able recommend movies which are of the same genre or has similar cast, and keywords**","18e6b302":"As I mentioned before that I always try my best to build an accurate solution. I therby referred a few tutorials on recommendation systems. ","cbdb0f09":"**Glad, that my code is able to succesfully recommend movies based on movie title and overview**","87da7c9e":"Removing some redundant entries from the movies_metadata.csv","c67d7a97":"Now we merge both the dataset","0dc11fa1":"Then we compute **Term Frequency-Inverse Document Frequency (TF-IDF) **vectors for each overview.","d3ff9477":"This is our new dataset with just the important parameters","4d073667":"Finally, I created a metadata string fucntion which will help to concat all the important features","6cd93379":"Now that we have our merged dataset, so I can extract important features like genres, keywords, cast etc","06c3ff64":"### Main Task:\n\n#### I  first tried to build a system which can recommend the movies according to the movie description\/overview\n\n#### **Here I use the *overview data column* for building this system**\n","68f65d7e":"### **Approach:**\n\n**So here, I aim to create a generalized solution by taking into account all the *important parameters* for a particular movie.\nThis will give the user a much more personalized experience and user can get a recommnendation according to his requirements. **","c4479bce":"Now to calculate similarity score, I did a bit of research on which are the best methods for the same. I found several techniques like euclidean, the Pearson and the cosine similarity scores. I will be using cosine similarity scores to find the similarity between two movies\n<br>\nOne advantage of cosine similarity score is that it is independent of magnitude and is relatively easy and fast to calculate. ","f075142e":"Now we can start with building our recommender system. There are three main approaches in recommender system.\n1. Demographic Filtering\n2. Content based Filtering\n3. Collaborative Filtering\n\nHere I use content based filtering technique. In content based filtering, we recommend user, similar movies based on what users have seen in the past or what users like. To achieve this, we can use various parameters like movie title, cast, genre, movie overview, votes etc","ce338db4":" As we can see that we have a huge dataset and due to lack of computational power of this kernel, the kernel keeps on dying (we just have 16GB RAM) so we cannot compute the dot product of all the 45000 movies. \n <br>\n \nSo instead I have taken a random part of data in order to generate the cosin values","368b4ca1":"Importing necessary libraries","f45f45cf":"Here we have several dataset csv files. Out of all the files, I have taken into consideration two important files:\n1. The main dataset i.e movies_metadata.csv\n2. The credits.csv file which conatins details about the cast and the crew\n\nFinally, we read the mentioned dataset i.e csv files","6287efd9":"This will give us a relative frequency of word in the document.\nTo achieve this, I use scikit-learn which gives  a built-in TfIdfVectorizer class that produces the TF-IDF matrix","b4c97d1b":"These are the columns we have finally in our dataset","79f28217":"Although the system is able to recommend similar movies, but still the quality of recommendation is not that great as we have only taken movie overview int account. ","ae60734e":"**Let's try with another movie** ","2ecfe783":"One important thing which I came to know is that here, we need to **CountVectorizer instead of tf-idf** because tf-idf only gives unique values. So if one actor has acted in many films and another actor has acted in only few, then  tf-idf gives same weightage which is tecnically not right. \n\n<br> So instead here I use CountVectorizer as it takes into account the number of occurances of a data too","b71875db":" Converting \"id\" column into integer type so we can finally combine both the dataset files[](http:\/\/) as a single dataset","9d2d28c0":"### Summary:\n\nSo, thus I have succesfully been able to develop a recommmender system which basically uses word_to_vec encodings along with tf_idf \/ CostVectorizer to determine the frequency of words and calculate the matrices\n<br>\n\nFurther I used cosine_similarity score to evaluate the simalarity of words and then accurately recommend the most 10 similar movies to the user based on the title of the movie which the user gives as an input to the system\n\n### Difficulties faced: \n\nThe most difficult part was preprocesing the data. It took me a significant amount of time to understand the data completly, before I could decide what features to include for the recommender system. I had to go through all the columns of the data and had to scrutinize the content, and remove some redundant values as they were becoming an obstacle in merging both the datasets.\n\nAlso since the kaggle kernel gives 16GB of RAM so kernel wasnt able to process the complete data. Nevertheless this has always been an issue with the kaggle kernels but still they are quite handy when it comes to performing some quick ML task :) \n\n#### Overall I enjoyed working on this task, referred some tutorials which helped me to clarify my doubts and provided me  more deeper insight into recommendation systems\n\n","84e94efd":"### Further enhancing the model and approach:"}}