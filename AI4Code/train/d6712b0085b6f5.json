{"cell_type":{"8882894f":"code","c29407db":"code","4e225c7e":"code","b7e4703e":"code","515981e1":"code","078868ce":"code","36a12c3f":"code","2a8dd29c":"code","1dd6e203":"code","faf989ad":"code","019c04f6":"code","1026a049":"code","a8a79aa8":"markdown","3592dd77":"markdown","5a204458":"markdown","6ba85de4":"markdown","f5abcc27":"markdown"},"source":{"8882894f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt # Plotting\nimport pandas as pd #Reading csv\nfrom sklearn.model_selection import train_test_split\n\n#Pytorch\nimport torch\nfrom torch.autograd import Variable\nfrom torch import nn,functional\nfrom torch.autograd import Variable\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torchvision.utils import make_grid\n\n#Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(device)","c29407db":"#file paths\ntrain_csv_path = '..\/input\/digit-recognizer\/train.csv'\ntest_csv_path = '..\/input\/digit-recognizer\/test.csv'\n\n#Read the csv and make the dataframes\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\n\n#Print dataframe structure\nn_train = len(train_df)\nn_pixels = len(train_df.columns) - 1\nn_class = len(set(train_df['label']))\nprint('M = {0}'.format(n_train))\nprint('WxH = {0}'.format(n_pixels))\nprint('# classes = {0}'.format(n_class))\n\n#Print the test dataframe structure\nn_test = len(test_df)\nn_pixels = len(test_df.columns)\nprint('Number of test samples = {0}'.format(n_test))\nprint('Test WxH = {0}'.format(n_pixels))","4e225c7e":"#Build custom data set to allow data augmentation\nclass MNISTDataset(Dataset):\n    \"\"\"MNIST data set\"\"\"\n    \n    def __init__(self, dataframe, \n                 transform = transforms.Compose([transforms.ToPILImage(),\n                                                 transforms.ToTensor(),\n                                                 transforms.Normalize(mean=(0.5,), std=(0.5,))])\n                ):\n        df = dataframe\n        #28x28 images\n        self.n_pixels = 784\n        \n        if len(df.columns) == self.n_pixels:\n            #Test data\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n        else:\n            #Training data\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n            \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.transform(self.X[idx]), self.y[idx]\n        else:\n            return self.transform(self.X[idx])","b7e4703e":"#Helper to build a dataset with a dataframe, a class dataset and composed transformations\ndef get_dataset(dataframe, dataset=MNISTDataset,\n                transform=transforms.Compose([transforms.ToPILImage(),\n                                              transforms.ToTensor(),\n                                              transforms.Normalize(mean=(0.5,), std=(0.5,))])):\n    return dataset(dataframe, transform=transform)\n\n#Split the data frmae in 2 (train - dev)\ndef split_dataframe(dataframe=None, fraction=0.9, rand_seed=1):\n    df_1 = dataframe.sample(frac=fraction, random_state=rand_seed)\n    df_2 = dataframe.drop(df_1.index)\n    return df_1, df_2","515981e1":"batch_size = 128\n\n#Train transformations include data augmentation\ntrain_transforms = transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5,), std=(0.5,))\n    ]\n)\n\n#Dev and transformations only have batch normalization\ndev_test_transforms = transforms.Compose(\n    [\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5,), std=(0.5,))\n    ]\n)\n\n#Split train and dev dataframes\ntrain_df_new, val_df = split_dataframe(dataframe=train_df, fraction=0.8)\n\n#Create train data set\ntrain_dataset = get_dataset(train_df_new, transform=train_transforms)\n#Create dev data set\ndev_dataset = get_dataset(val_df, transform=dev_test_transforms)\n\n#Create train loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n#Create dev loader\ndev_loader = torch.utils.data.DataLoader(dataset=dev_dataset, batch_size=batch_size, shuffle=False)","078868ce":"#For plotting\nprint('m =',len(train_loader)*batch_size)\nprint('m_dev =',len(dev_loader)*batch_size)\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\nprint(images.shape) # Should be (batch_size, 28x28)\n\n#Plot 10 in a row to do a sanity check over the data augmentation and train data\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(10): #Arange next 10\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[]) #Create subplot\n    ax.imshow(np.squeeze(images[idx].reshape(28,28)), cmap='gray') #Show subplot\n    ax.set_title(labels[idx]) #Set title of subplot","36a12c3f":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass ClassifierNetwork(nn.Module):\n    def __init__(self, drop_rate = 0.0):\n        super(ClassifierNetwork, self).__init__()\n        ## encoder layers ##\n        #Convolution 1st layer (Same convolution)\n        #Inputs 28x28\n        self.conv1 = nn.Conv2d(\n            1, #In channels \n            64, #Out channels (amount of filters)\n            3, #Filter size\n            padding = 1 #Padding amount\n        )\n        self.bn1 = nn.BatchNorm2d(64)\n        #Convolution 2nd layer (Same padding)\n        #Inputs 14x14\n        self.conv2 = nn.Conv2d(\n            64, #In channels\n            64, #Out channels\n            3, #Filter size\n            padding = 1 #Padding amount\n        )\n        self.bn2 = nn.BatchNorm2d(64)\n        #Convolution 3rd layer (Same padding)\n        #Inputs 7x7\n        self.conv3 = nn.Conv2d(\n            64, #In channels\n            128, #Out channels\n            3, #Filter size\n            padding = 1 #Padding amount\n        )\n        self.bn3 = nn.BatchNorm2d(128)\n        #Max pool\n        #Reduces size to half\n        self.pool = nn.MaxPool2d(\n            2, #Filter size\n            stride = 2 #Stride to reduce \n        )\n        #Linear layers\n        #3*3*64 (576 -> 256)\n        self.fc4 = nn.Linear(3*3*128, 512)\n        self.bn4 = nn.BatchNorm1d(512)\n        #256 -> 10\n        self.output = nn.Linear(512, 10)\n        #Dropout\n        self.dropout = nn.Dropout(p = drop_rate)\n        #Convolution dropout\n        self.dropout_conv = nn.Dropout2d(p = drop_rate)\n    \n    #Forward pass\n    def forward(self, x):\n        #Transform to fit the convolutional layers\n        x = x.view(-1,1,28,28)\n        # Convolutional layers\n        x = self.pool(self.bn1(F.relu(self.conv1(x)))) #Convolution then pool\n        x = self.dropout_conv(x)\n        x = self.pool(self.bn2(F.relu(self.conv2(x)))) #Convolution then pool\n        x = self.dropout_conv(x)\n        x = self.pool(self.bn3(F.relu(self.conv3(x)))) #Convolution then pool\n        x = self.dropout_conv(x)\n        #Flatten for hidden layers\n        x = x.view(-1, 3*3*128)\n        #Hidden layers\n        x = self.bn4(F.relu(self.fc4(x)))\n        x = self.dropout(x)\n        x = F.log_softmax(self.output(x), dim=1)\n        return x","2a8dd29c":"selected_l2_regularization = 0\ndropout_selected = 0\nselected_learning_rate = 0.001\nreduce_lr_every_epochs = 1\nselected_lr_decay = 0.95\nepochs = 35","1dd6e203":"#Models List\nmodels = []\n\n#Instanciate the first model\nmodel = ClassifierNetwork(drop_rate = dropout_selected)\n#Instanciate the optimizer\noptimizer = torch.optim.RMSprop(model.parameters(), lr = selected_learning_rate, weight_decay = selected_l2_regularization)\n#Instanciate the loss\ncriterion = nn.CrossEntropyLoss()\n#Reduce in epoch\nreduce_every = reduce_lr_every_epochs\n#Model label\nlabel = 'Modelo final (iteraci\u00f3n 2)'\ngamma = selected_lr_decay\n#Save in the models list\nmodels.append(( model, optimizer, criterion, label, reduce_every, gamma ))\n#Print\nprint('Label', label)\nprint('Model structure:', model)\nprint('Optimizer', optimizer)\nprint('Criterion', criterion)\nprint('Learning rate decay every', reduce_every, 'epoch')\nprint('Learning rate decay gamma', gamma)\nprint('------------------------------------------------------------------')\nprint('------------------------------------------------------------------')\n","faf989ad":"#To plot all losses\nall_models_losses = []\n#Itearte over the models list\nfor model, optimizer, criterion, label, reduce_every, gamma in models:\n    print('Model', label, 'started')\n    #Use GPU\n    model = model.float()\n    model = model.to(device)\n    criterion = criterion.to(device)\n    #Model accuracies\n    model_losses = []\n    train_accs = []\n    dev_accs = []\n    \n    #Build scheduler for learning rate decay\n    if reduce_every != 0:\n        #Exponential adaptative learning rate with gamma = 0.95\n        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = gamma)\n        print('Scheduler', scheduler)\n    \n    #Iterate the epochs\n    for epoch in range(epochs):\n        print('Epoch #'+str(epoch)+' started')\n        #Track accuracies\n        correct_train = 0\n        total_train = 0\n        #Track loss\n        epoch_loss = 0\n        #Set model mode to training\n        model.train()\n        #Iterate over the mini batchs\n        for images, labels in train_loader:\n            #Use GPU\n            images_var = images.to(device)\n            labels_var = labels.to(device)\n            #Preven gradient accumulations\n            optimizer.zero_grad()\n            #Forward propagation\n            outputs = model(images_var)\n            #Calculate \n            loss = criterion(outputs, labels_var.long())\n            #Backward propagation\n            loss.backward()\n            #Update parameters\n            optimizer.step()\n            \n            #Keep track of the minibatch loss\n            epoch_loss += loss.item()\n            \n            #Get the predicted class for each output\n            _, predicted = torch.max(outputs.data, 1)\n            #Count up the total amount of correct labels\n            #for which the predicted and true labels are equal\n            correct_train += (predicted == labels_var).sum()\n            #Track total examples\n            total_train += labels.size(0)\n        #When mini batches iteration ends\n        else:\n            #Set evaluation mode\n            model.eval()\n            #Prevent grads\n            with torch.no_grad():\n                #Track accuracies\n                correct_dev = 0\n                total_dev = 0\n                #Validate dev dataset\n                for images, labels in dev_loader:\n                    #Use GPU\n                    images_var = images.to(device)\n                    labels_var = labels.to(device)\n                    #Get output\n                    outputs = model(images_var)\n                    #Get the predicted class for each output\n                    _, predicted = torch.max(outputs.data, 1)\n                    #Count up the total amount of correct labels\n                    #for which the predicted and true labels are equal\n                    correct_dev += (predicted == labels_var).sum()\n                    #Track total examples\n                    total_dev += labels.size(0)\n                #Store epoch losses\n                model_losses.append(epoch_loss\/len(train_loader))\n                #Store epoch accuracy\n                train_accs.append(correct_train.item()\/total_train)\n                dev_accs.append(correct_dev.item()\/total_dev)\n                print('Epoch #'+str(epoch)+' ended')\n                print('Epoch loss: '+str((epoch_loss\/len(train_loader))))\n                print('- Train accuracy: '+str((correct_train.item()\/total_train)*100)+'%')\n                print('- Dev accuracy: '+str((correct_dev.item()\/total_dev)*100)+'%')\n                print('-------------------------------------------------------------------------------')\n        #Check if the model is one that reduces the learning rate\n        if reduce_every != 0:\n            #Check if the learning rate should actually be reduced\n            if (epoch+1) % reduce_every == 0:\n                scheduler.step()\n                print('Learning rate reduced')\n    \n    #Plot here\n    plt.plot(np.squeeze(train_accs), 'blue', label = label + ' - Train accuracy')\n    plt.plot(np.squeeze(dev_accs), 'red', label = label + ' - Dev accuracy')\n    plt.title('Comparaci\u00f3n de precisiones para el modelo ' + label)\n    plt.xlabel('Epochs')\n    plt.ylabel('Precisi\u00f3n')\n    plt.legend()\n    plt.show()\n    \n    #Store models losses\n    all_models_losses.append(( model_losses, label ))\n    \n    print('Model', label, 'ended')\n    print('--------------------------------------------------------------------------------')\n    print('--------------------------------------------------------------------------------')\n    print('--------------------------------------------------------------------------------')","019c04f6":"#Plot model losses\nfor losses, label in all_models_losses:\n    plt.plot(np.squeeze(losses), label = label)\n\n#Customize the plot\nplt.title('Losses del modelo')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","1026a049":"#Get the model\nmodel, _, _2, _3, _4, _5 = models[0]\nprint(model)\n#Set the evalutaion mode\nmodel.eval()\n#Predictions\ntest_pred = torch.LongTensor()\n\n#Create the test dataset with only normalization transformation\ntest_dataset = get_dataset(test_df, transform=dev_test_transforms)\n\n#Create the test loader\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n#Iterate the test data\nfor i, data in enumerate(test_loader):\n    #Check GPU\n    if torch.cuda.is_available():\n        data = data.cuda()\n\n    #Outputs\n    output = model(data)\n\n    #Get predictions\n    pred = output.cpu().data.max(1, keepdim=True)[1]\n    test_pred = torch.cat((test_pred, pred), dim=0)\n\n# tensor -> numpy.ndarray -> pandas.DataFrame\ntest_pred_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1), test_pred.numpy()], columns=['ImageId', 'Label'])\n\n# show part of prediction dataframe\nprint(test_pred_df.head())\n\n#Upload predictions\ntest_pred_df.to_csv('submission.csv', index=False)","a8a79aa8":"# Hiperparameters","3592dd77":"## Model class","5a204458":"## Library imports","6ba85de4":"## Load and visualize training and dev data","f5abcc27":"## Predictions with test data"}}