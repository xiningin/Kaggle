{"cell_type":{"ac370451":"code","1968396f":"code","19678de1":"code","f1cd3482":"code","fb1fc6aa":"code","c0c1bc21":"code","66402419":"code","42d41875":"code","1a873311":"code","34dafe0a":"code","6e4682cf":"code","2589ee64":"code","9202efa8":"code","0434d8a2":"code","beacee21":"code","3a7677ef":"code","dab66f16":"code","f1210d52":"code","7a04e644":"code","c3b702b5":"code","f2f94b4a":"markdown","a1f4b2d9":"markdown","3a54b4f9":"markdown","6f1209eb":"markdown","a82aba1b":"markdown","c6f4e099":"markdown","da8b2169":"markdown","d8ba5fb0":"markdown","f287bae2":"markdown","422989dc":"markdown","8518835f":"markdown","cbf44241":"markdown"},"source":{"ac370451":"!pip install spacy\n!python -m spacy download en_core_web_sm","1968396f":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport re\nimport spacy\nfrom collections import Counter\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport string\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom sklearn.metrics import mean_squared_error\nimport torchvision\nfrom transformers import AutoTokenizer","19678de1":"data = pd.read_csv('..\/input\/reviews-of-pink-floyds-the-dark-side-of-the-moon\/dsotm_reviews.csv')\ndata['review_length'] = data['Review'].apply(lambda x: len(str(x).split()))\ndata = data[data['Rating'].notna()]\nzero_numbering = { 0.5:0, 1:1, 1.5:2, 2:3, 2.5:4, 3:5, 3.5:6, 4:7, 4.5:8, 5:9}\ndata['Rating'] = data['Rating'].apply(lambda x: zero_numbering[x])\nprint(list(data[\"Rating\"].unique()))\ndata.sample(6)","f1cd3482":"tok = spacy.load(\"en_core_web_sm\")\ndef tokenize (text):\n    text = str(text)\n    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n    nopunct = regex.sub(\" \", text.lower())\n    return [token.text for token in tok.tokenizer(nopunct)]","fb1fc6aa":"counts =  collections.Counter()\nfor index, row in data.iterrows():\n    counts.update(tokenize(row['Review']))","c0c1bc21":"print(\"num_words before:\",len(counts.keys()))\nfor word in list(counts):\n    if counts[word] < 2:\n        del counts[word]\nprint(\"num_words after:\",len(counts.keys()))","66402419":"vocab2index = {\"\":0, \"UNK\":1}\nwords = [\"\", \"UNK\"]\nfor word in counts:\n    vocab2index[word] = len(words)\n    words.append(word)","42d41875":"def encode_sentence(text, vocab2index, N=300):\n    tokenized = tokenize(text)\n    encoded = np.zeros(N, dtype=int)\n    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n    length = min(N, len(enc1))\n    encoded[:length] = enc1[:length]\n    return encoded, length","1a873311":"data['encoded'] = data['Review'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\ndata.head()","34dafe0a":"X = list(data['encoded'])\ny = list(data['Rating'])\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)","6e4682cf":"class ReviewsDataset(Dataset):\n    def __init__(self, X, Y):\n        self.X = X\n        self.y = Y\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]","2589ee64":"train_ds = ReviewsDataset(X_train, y_train)\nvalid_ds = ReviewsDataset(X_valid, y_valid)","9202efa8":"def train_model(model, epochs=10, lr=0.001):\n    parameters = filter(lambda p: p.requires_grad, model.parameters())\n    optimizer = torch.optim.Adam(parameters, lr=lr)\n    for i in range(epochs):\n        model.train()\n        sum_loss = 0.0\n        total = 0\n        for x, y, l in train_dl:\n            x = x.long()\n            y = y.long()\n            y_pred = model(x, l)\n            optimizer.zero_grad()\n            loss = F.cross_entropy(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            sum_loss += loss.item()*y.shape[0]\n            total += y.shape[0]\n        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n        if i % 5 == 1:\n            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\"% (sum_loss\/total, val_loss, val_acc, val_rmse))\n\ndef validation_metrics (model, valid_dl):\n    model.eval()\n    correct = 0\n    total = 0\n    sum_loss = 0.0\n    sum_rmse = 0.0\n    for x, y, l in valid_dl:\n        x = x.long()\n        y = y.long()\n        y_hat = model(x, l)\n        loss = F.cross_entropy(y_hat, y)\n        pred = torch.max(y_hat, 1)[1]\n        correct += (pred == y).float().sum()\n        total += y.shape[0]\n        sum_loss += loss.item()*y.shape[0]\n        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n    return sum_loss\/total, correct\/total, sum_rmse\/total","0434d8a2":"batch_size = 5000\nvocab_size = len(words)\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_dl = DataLoader(valid_ds, batch_size=batch_size)","beacee21":"class LSTM_fixed_len(torch.nn.Module) :\n    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n        super().__init__()\n        preloaded = torchvision.models.densenet161(pretrained=True)\n        self.features = preloaded.features\n        self.classifier = nn.Linear(hidden_dim, 10, bias=True)\n        del preloaded\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.linear = nn.Linear(hidden_dim, 10)\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, x, l):\n        x = self.embeddings(x)\n        x = self.dropout(x)\n        lstm_out, (ht, ct) = self.lstm(x)\n        return self.classifier(ht[-1])","3a7677ef":"model_fixed =  LSTM_fixed_len(vocab_size, 100, 100)","dab66f16":"train_model(model_fixed, epochs=30, lr=0.01)","f1210d52":"data[\"Review\"][0]","7a04e644":"my_review = \"OMG BASED album so cool, i wish i was born in  70s\"","c3b702b5":"import warnings\nwarnings.filterwarnings('ignore')\nl = len(str(my_review).split())\nmy_token = torch.tensor([np.array(encode_sentence(my_review,vocab2index ))[0].astype(np.int32)])\ny_hat = model_fixed(my_token, l)\npred = torch.max(y_hat, 1)[1]\nprint(f\"Predicted rating: {pred[0]}\")","f2f94b4a":"# Loading data\n### Rating should be between 0 and 10 for a classifier","a1f4b2d9":"![Screenshot from 2021-10-17 21-46-09.png](attachment:bd072bc1-fc06-48f7-b670-15b1b9414693.png)","3a54b4f9":"# Loading packages and libraries","6f1209eb":"# Training model","a82aba1b":"# Training and eval functions","c6f4e099":"# Predicting rating of reviews\n#### source notebook https:\/\/jovian.ai\/aakanksha-ns\/lstm-multiclass-text-classification","da8b2169":"# Filtering most common words","d8ba5fb0":"# Preparing dataset","f287bae2":"## Thank you so much for going trough this notebook!\nLeave an upvote if you like it please \ud83d\udc49\ud83d\udc48","422989dc":"# Tokenizing","8518835f":"# Defining model\n## LSTM + DenseNet","cbf44241":"# Encoding reviews"}}