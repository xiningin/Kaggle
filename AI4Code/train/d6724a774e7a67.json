{"cell_type":{"bcfc8623":"code","789fad14":"code","4791e78a":"code","596f5cb8":"code","4f4cae0a":"code","9730ad43":"code","a4f8d2df":"code","014bb809":"code","1294c7e2":"code","357042fb":"code","c8fbe862":"code","84b9a05a":"code","0805c0c9":"code","67feebe0":"code","c0041379":"code","b1f8d81d":"markdown","fbc38329":"markdown","8fa6a62b":"markdown","91f6d05d":"markdown","84a2f22f":"markdown","6f81c11a":"markdown","9cf71495":"markdown","15537486":"markdown","7a132f79":"markdown","95fdc64e":"markdown","9ffcaea7":"markdown","4b3efdf1":"markdown"},"source":{"bcfc8623":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport cv2\nfrom skimage import io\nfrom skimage import transform\nfrom skimage import color\nimport pickle\nimport PIL\nfrom PIL import Image as im\n\nimport pathlib\nimport datetime\nimport os\nimport pickle\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\n\nimport tensorflow_addons as tfa","789fad14":"\ndata_path = r\"drive\/MyDrive\/Plant_Phenotyping_Datasets\/Plant\"\n\ndf1 = pd.read_csv(data_path+\"\/Ara2012\/Leaf_counts.csv\",names=[\"Image\",\"Count\"])\ndf1['Image'] = data_path+\"\/Ara2012\/\"+df1['Image']\n\ndf2 = pd.read_csv(data_path+\"\/Tobacco\/Leaf_counts.csv\",names=[\"Image\",\"Count\"])\ndf2['Image'] = data_path+\"\/Tobacco\/\"+df2['Image']\n\ndf3 = pd.read_csv(data_path+\"\/Ara2013-Canon\/Leaf_counts.csv\",names=[\"Image\",\"Count\"])\ndf3['Image'] = data_path+\"\/Ara2013-Canon\/\"+df3['Image']\n\ndf = pd.concat([df1,df2,df3],ignore_index=True)\n\ndf['Image'] = df['Image']+\"_rgb.png\"\nimages = df['Image']\ncounts = df['Count']\n","4791e78a":"#Total images are 810\n#Going for 80-10-10 split\n\nX_train, X_test, y_train, y_test = train_test_split(images, counts, random_state = 5, shuffle=True, test_size= 0.20)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, random_state = 5, shuffle = True, test_size = 0.50)","596f5cb8":"train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))","4f4cae0a":"segnet_model = tf.keras.models.load_model(\"drive\/MyDrive\/saved_models\/saved_segmentation_model\")\n\n# Load the images and counts from paths\n@tf.function\ndef get_images_and_counts(image_path, count):\n    image = tf.io.decode_png(tf.io.read_file(image_path), channels = 3)\n    image = tf.image.convert_image_dtype(image, tf.float64)\n    image = tf.image.resize(image, [224, 224])\n    return image, count\n\n\n# Data augmentation\n@tf.function\ndef data_augmentation_and_mask_concatenation(image, count):\n    random_number = tf.random.uniform(shape = [], maxval = 5, dtype = tf.int32)\n\n    # ==1 then apply rotation\n    if tf.equal(random_number, tf.constant(1)):\n        image = rotate_image(image)\n    \n    # ==2 then apply horizontal flip\n    elif tf.equal(random_number, tf.constant(1)):\n        image = random_horizontal_flip(image)\n        \n    # ==3 then apply vertical flip\n    elif tf.equal(random_number, tf.constant(1)):\n        image = random_vertical_flip(image)\n            \n    # ==4 then apply gaussian blur\n    elif tf.equal(random_number, tf.constant(1)):\n        #image, mask = gaussian_blur(image, mask)\n        pass # Since current environment version does not support the tf gaussian blur function\n        \n    # ==5 No augmentation\n    else:\n        pass\n    \n    #Get the mask from saved segmentation model\n    image_for_segmentation = tf.reshape(image, [1 ,224, 224, 3])\n    mask = segnet_model(image_for_segmentation, training = False)[0]      \n\n    # Convert the mask values to boolean\n    threshold = 0.5\n    cond = tf.greater(mask, tf.ones(tf.shape(mask))*threshold)\n    boolean_mask = tf.where(cond, tf.ones(tf.shape(mask)), tf.zeros(tf.shape(mask)))\n\n    # Concatenate the image with mask(as the 4th channel)\n    #combined_image = tf.concat([mask, image], axis = -1)   \n    combined_image = tf.multiply(image, boolean_mask)    \n    combined_image = tf.image.resize(combined_image, [448, 448])\n    return combined_image, count\n\n\n\n@tf.function\ndef random_horizontal_flip(image):\n    random_num = tf.random.uniform([], 0, 1.0)\n    cond_value = tf.less(random_num, 0.5)\n    image = tf.cond(cond_value, lambda: tf.image.flip_left_right(image), lambda: image)\n    return image\n\n@tf.function\ndef random_vertical_flip(image):\n    random_num = tf.random.uniform([], 0, 1.0)\n    cond_value = tf.less(random_num, 0.5)\n    image = tf.cond(cond_value, lambda: tf.image.flip_up_down(image), lambda: image)\n    return image\n\n@tf.function\ndef rotate_image(image):\n    image = tfa.image.rotate(image, 180, interpolation = \"NEAREST\")  \n    return image\n\n@tf.function\ndef mask_concatenation(image, count):\n    image_for_segmentation = tf.reshape(image, [1 ,224, 224, 3])\n    mask = segnet_model(image_for_segmentation, training = False)[0]      \n\n    threshold = 0.5\n    cond = tf.greater(mask, tf.ones(tf.shape(mask))*threshold)\n    boolean_mask = tf.where(cond, tf.ones(tf.shape(mask)), tf.zeros(tf.shape(mask)))\n\n    combined_image = tf.multiply(image, boolean_mask)    \n    combined_image = tf.image.resize(combined_image, [224, 224])\n    return combined_image, count","9730ad43":"train_dataset = train_dataset.map(get_images_and_counts).map(data_augmentation_and_mask_concatenation)\nval_dataset = val_dataset.map(get_images_and_counts).map(mask_concatenation)\ntest_dataset = test_dataset.map(get_images_and_counts).map(mask_concatenation)","a4f8d2df":"BATCH_SIZE = 32\nBUFFER_SIZE = 150\nrepeat_count = None","014bb809":"train_dataset = train_dataset.shuffle(BUFFER_SIZE).repeat(repeat_count).batch(BATCH_SIZE).prefetch(5)\nval_dataset = val_dataset.shuffle(BUFFER_SIZE).repeat(repeat_count).batch(BATCH_SIZE).prefetch(5)\ntest_dataset = test_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(5)","1294c7e2":"def Conv_LRN_relu(input_tensor, filters, kernel):\n    conv = layers.Convolution2D(filters, kernel, padding = \"valid\", strides = 1)(input_tensor)\n    #conv = layers.LayerNormalization()(conv)\n    conv = layers.BatchNormalization()(conv)\n    conv = layers.Activation(\"relu\")(conv)\n    return conv","357042fb":"input = layers.Input(shape=(448, 448, 3))\n\nconv_start = layers.Convolution2D(3, (9,9), padding=\"same\")(input)\nconv1 = Conv_LRN_relu(conv_start, 16, (9,9))   \nconv2 = Conv_LRN_relu(conv1, 16, (9,9))   \nmax_pool_1 = layers.MaxPooling2D(pool_size = (2,2), strides=(2,2))(conv2)   \n\nconv3 = Conv_LRN_relu(max_pool_1, 32, (9,9))   \nconv4 = Conv_LRN_relu(conv3, 32, (9,9))   \nmax_pool_2 = layers.MaxPooling2D(pool_size = (2,2), strides=(2,2))(conv4)   \n\nconv5 = Conv_LRN_relu(max_pool_2, 64, (5,5))   \nconv6 = Conv_LRN_relu(conv5, 64, (5,5))  \nmax_pool_3 = layers.MaxPooling2D(pool_size = (2,2), strides=(2,2))(conv6)   \nconv7 = Conv_LRN_relu(max_pool_3, 128, (5,5))   \nconv8 = Conv_LRN_relu(conv7, 128, (5,5))  \nconv9 = Conv_LRN_relu(conv8, 128, (5,5))  \nmax_pool_4 = layers.MaxPooling2D(pool_size = (2,2), strides=(2,2))(conv9)    \nconv10 = Conv_LRN_relu(max_pool_4, 256, (5,5))   \nconv11 = Conv_LRN_relu(conv10, 256, (5,5))   \nconv12 = Conv_LRN_relu(conv11, 256, (5,5))   \nconv13 = Conv_LRN_relu(conv12, 256, (5,5))   \n\nflat = layers.Flatten()(conv13)\n\nfc1 = layers.Dense(256)(flat)\nfc2 = layers.Dense(512)(fc1)\n\noutput = layers.Dense(1)(fc2)\n\nreg_model = Model(inputs=[input], outputs=[output])\nreg_model.summary()","c8fbe862":"huber_loss = tf.keras.losses.Huber(delta=1.0)","84b9a05a":"\ncheckpoint_path = \"Checkpoints\/\"\n\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath = checkpoint_path,\n    monitor = 'val_loss',\n    save_best_only = True,\n)","0805c0c9":"\nlog_dir = \"logs\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","67feebe0":"%reload_ext tensorboard\n%tensorboard --logdir logs\/fit","c0041379":"tf.keras.backend.clear_session()\nreg_model.compile(\n    loss = huber_loss,\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n    metrics= ['mse']\n)\n\nEPOCHS = 40\n\nfit_history = reg_model.fit(\n    train_dataset,\n    epochs = EPOCHS,\n    verbose = 1,\n    callbacks = [tensorboard_callback, model_checkpoint],\n    steps_per_epoch = len(X_train) \/\/ BATCH_SIZE,\n    validation_data = val_dataset,\n    validation_steps = len(X_val) \/\/ BATCH_SIZE,\n    initial_epoch = 5)","b1f8d81d":"###Creating the Dataset:\n#####I'm creating the train, validation and test datasets by mapping the above functions.","fbc38329":"## Splitting the Data:\n\n####The data is this case has been split into 80-10-10, where the Training data is 80%, Test data is 10% and Validation data is 10%\n","8fa6a62b":"### Python Project: Automatic Leaf Counting Challenge\n\nHello there,\nThis is my latest and last notebook on the autmatic leaf counting challenge, This notebook previously trained on a NVIDIA GTX 1080 Ti scored 1.48 MAE which felt pretty decent.\n\nSo to conclude - this notebook summarizes all my learning process.","91f6d05d":"##Loading the Data, performing Data Augmentation:\n####I'm loading all the images using the image path and also returning thier count.\n\n####In the data augmentation part I'm using a random number, maximum value 5, where based on the conditional statement It will apply rotation, horizontal flip, vertical flip, gaussian blur or no augmentation.\n\n####Previously when I trained my model with this augmented data I got the case of overfitting, probably I've never given the percentage odds of augmenting the data.\n\n####Then, I tried giving the function a certain percentage if it wants to augment the data. \n\n####At last, I'm getting the mask of my rgb image using the segnet model and concatenating that mask with the count.","84a2f22f":"## Regression Model:\n\n####I'm using a regression model which I moddeled using external sources for training the model in.\n\n####In the data I was surely provided with centers of the image which are the point annotations, but because of the time I was mainly experimenting with the segmentation masks and regression.","6f81c11a":"## Hyperparams, Repeat and Batching","9cf71495":"####When training the model, I have used Adam as my optimizer again I like simplicity!\n\n####And for a future reference, I would've most definetly used some better GPU, because training the model in colab was the most hardest part throught the journey mostly because a Tesla K90 is never a good choice in most cases, and colab has runtime issues if the unactive time exceeds more than 20 minutes, well I guess it's re-training again.\n\n\n\n","15537486":"# Gathering the Data:\n####The Plant Phenotyping Dataset has the required data for gathering the Leaf count csv file and the images aswell.\n\n#####The required data which should be used is available inside Ara2012, Ara2013 - Canon and Tobacco, which contains segmented masks, rgb images and counts of leaves of all the segregated images.\n\n#####In the below script I'm gathering the csv file which contains the image path data and count of it, mapping the file path to the csv file.","7a132f79":"## Loss Function and Tensorboard Setup:\n####I've marked to stick with tensorflow mainly because it was easy, that's mostly it! \n\n####For my model's compiler I sticked with using the Huber loss to keep things simple.\n\n####And for my part of checking the epoch loss and it's accuracy I've added a tensorboard integration.\n\n####And I've created a ModelCheckpoint, whenever the module notices any huber loss, it'll save the best model inside the checkpoint's directory.","95fdc64e":"# With this you have reached the end,\n#Thank you and have a awesome day :D","9ffcaea7":"## These are modules I'm using\n#####I'm using tensorflow for building the model and performing Augmentation","4b3efdf1":"## Training the model"}}