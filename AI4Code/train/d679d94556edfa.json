{"cell_type":{"143d8148":"code","1d43d440":"code","0913104e":"code","5c58eb17":"code","5e5ff9cf":"code","04eaadf0":"code","c0b39be2":"code","7ae79260":"code","e2519706":"code","f01eae0a":"code","518bf704":"code","eaa13a88":"code","1275a703":"code","21ed944c":"code","7cd09fb3":"code","6af0f11d":"code","a2aeabc9":"code","1fc18162":"code","55cc820b":"code","da9cc228":"code","6a3dd710":"code","e0fbc4c8":"code","458ebd4c":"code","a56469a6":"code","a67b1ca7":"code","48d22487":"code","d12ad5c7":"code","2f5d9b03":"code","4edb0716":"code","6854c387":"code","7be19f0a":"code","980719c4":"code","56aa264f":"code","7fe92da8":"code","964ac4f0":"code","2d40b62e":"markdown","5f740751":"markdown","8802d5b4":"markdown","ff05748f":"markdown","0db4aa4e":"markdown","a3f71133":"markdown","ebdbbc62":"markdown","5ff21762":"markdown","33437a37":"markdown","6958e01f":"markdown"},"source":{"143d8148":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d43d440":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom collections import Counter\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")","0913104e":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\",index_col=0)\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\",index_col=0)\n\ntrain_data.head()","5c58eb17":"train_data.shape","5e5ff9cf":"train_data.describe().T","04eaadf0":"train_data.info()","c0b39be2":"#survived\nsns.countplot('Survived',data=train_data);\nprint(train_data['Survived'].mean())","7ae79260":"#Sex - Survived\nsns.barplot(x=\"Sex\",y=\"Survived\",data=train_data);\nprint(train_data.groupby([\"Sex\"])['Survived'].mean())","e2519706":"#Pclass - Survived\nsns.barplot(x=\"Pclass\",y=\"Survived\",data=train_data);\nprint(train_data.groupby([\"Pclass\"])['Survived'].mean())","f01eae0a":"#Pclass - Sex- Survived\nsns.barplot(x=\"Pclass\",y=\"Survived\",hue=\"Sex\",data=train_data);\nprint(train_data.groupby(['Pclass',\"Sex\"])['Survived'].mean(),'\\n\\nWomen on the first class has chance to survive more than 90%')","518bf704":"#SibSp vs Survival\nsns.barplot(x='SibSp',y='Survived',data=train_data);\nprint(train_data.groupby(['SibSp'])['Survived'].mean())","eaa13a88":"#SibSp- Sex- Survival\nsns.barplot(x='SibSp',y='Survived',hue=\"Sex\",data=train_data);\nprint(train_data.groupby(['SibSp',\"Sex\"])['Survived'].mean())","1275a703":"#Embarked - Survived\nsns.barplot(x=\"Embarked\",y=\"Survived\",data=train_data);\nprint(train_data.groupby([\"Embarked\"])['Survived'].mean())","21ed944c":"#Embarked - Sex- Survived\nsns.barplot(x=\"Embarked\",y=\"Survived\",hue=\"Sex\",data=train_data);\nprint(train_data.groupby([\"Embarked\",\"Sex\"])['Survived'].mean())","7cd09fb3":"plt.figure(figsize=(12,8))\ntrain_data['Sex'].replace(['male','female'],[0,1],inplace=True)\ntrain_data['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\ntest_data['Sex'].replace(['male','female'],[0,1],inplace=True)\ntest_data['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\ncorr = train_data[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\",\"Fare\",\"Embarked\", \"Survived\"]].corr()\n# male: 0, female: 1\n# S:0, C:1, Q:2\nsns.heatmap(corr, annot=True);","6af0f11d":"print(train_data['Age'].describe())","a2aeabc9":"train_data.isnull().sum()","1fc18162":"test_data.isnull().sum()","55cc820b":"import missingno as msno","da9cc228":"msno.matrix(train_data);","6a3dd710":"train_data['Age'].fillna(train_data[\"Age\"].median(),inplace=True)\ntest_data['Age'].fillna(test_data[\"Age\"].median(),inplace=True)\n\n\n#train_data_age=train_data[\"Age\"].fillna(df[\"Age\"].mean())\n#test_data_age=test_data[\"Age\"].fillna(df[\"Age\"].mean())\n\n#train_data.drop([\"Age\"],axis=1,inplace=True)\n#test_data.drop([\"Age\"],axis=1,inplace=True)\n\n#train_data_full=pd.concat([train_data_age,train_data],axis=1,join=\"inner\")\n#test_data_full=pd.concat([test_data_age,test_data],axis=1,join=\"inner\")\n\ntrain_data['Embarked'].fillna(1,inplace=True)\ntest_data['Embarked'].fillna(1,inplace=True)\ntest_data['Fare'].fillna(test_data['Fare'].median(),inplace=True)\n\ntrain_data.isnull().sum()","e0fbc4c8":"#Family Size\ntrain_data[\"Family_S\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\ntest_data[\"Family_S\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1\n\ntrain_data","458ebd4c":"train_data[\"Family_Size\"] = [1 if ((i == 2) | (i == 3) | (i == 4)) else 0  for i in train_data[\"Family_S\"]]\ntrain_data[\"Family_Size\"] = train_data[\"Family_Size\"].astype(\"category\")\ntrain_data = pd.get_dummies(train_data, columns=[\"Family_Size\"])\ntrain_data.drop(labels=\"Family_S\", axis=1, inplace = True)\n\ntest_data[\"Family_Size\"] = [1 if ((i == 2) | (i == 3) | (i == 4)) else 0  for i in test_data[\"Family_S\"]]\ntest_data[\"Family_Size\"] = test_data[\"Family_Size\"].astype(\"category\")\ntest_data = pd.get_dummies(test_data, columns=[\"Family_Size\"])\ntest_data.drop(labels=\"Family_S\", axis=1, inplace = True)\n\ntrain_data.head()","a56469a6":"train_data.drop(labels=[\"Ticket\", \"Cabin\", \"Name\"], axis=1, inplace = True)\ntest_data.drop(labels=[\"Ticket\", \"Cabin\", \"Name\"], axis=1, inplace = True)\n\ntrain_data.head()","a67b1ca7":"# X ve y ayr\u0131ld\u0131\n\ny = train_data.Survived\ntrain_data.drop(['Survived'], axis=1, inplace=True)","48d22487":"# Standardizasyon \n\nfrom sklearn import preprocessing\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nscaled_df_Xtrain = min_max_scaler.fit_transform(train_data)\nscaled_df_Xtest = min_max_scaler.fit_transform(test_data)\ndf_sc_train = pd.DataFrame(scaled_df_Xtrain)\ndf_sc_test = pd.DataFrame(scaled_df_Xtest)\n\n\nX_train,X_test,y_train,y_test = train_test_split(df_sc_train,y,test_size=0.30,random_state=42)","d12ad5c7":"train_data.isnull().sum()","2f5d9b03":"test_data.isnull().sum()","4edb0716":"rf_model= RandomForestClassifier(random_state=42).fit(X_train,y_train)\n#train occuracy\nrf_model.score(X_train, y_train)\n#score\ny_pred = rf_model.predict(X_test)\nroc_auc_score(y_pred, y_test)","6854c387":"#gbm model\ngbm_model = GradientBoostingClassifier().fit(X_train,y_train)\ny_pred = gbm_model.predict(X_test)\nroc_auc_score(y_pred, y_test)","7be19f0a":"from xgboost import XGBClassifier\nxgb_model = XGBClassifier().fit(X_train,y_train)\ny_pred = gbm_model.predict(X_test)\nroc_auc_score(y_pred, y_test)","980719c4":"#light gbm model\nfrom lightgbm import LGBMClassifier\nlgbm_model = LGBMClassifier().fit(X_train,y_train)\ny_pred = lgbm_model.predict(X_test)\nroc_auc_score(y_pred, y_test)","56aa264f":"lgbm_tuned = LGBMClassifier(learning_rate= 00.1, max_depth= 35, n_estimators= 200,num_leaves=5).fit(X_train,y_train)\ny_pred = lgbm_tuned.predict(X_test)\nroc_auc_score(y_pred, y_test)","7fe92da8":"predictions = xgb_model.predict(df_sc_test).astype(int)","964ac4f0":"output = pd.DataFrame({'PassengerId': test_data.index,\n                       'Survived': predictions})\noutput.to_csv('titanic.csv', index=False)\nprint(\"Your submission was successfully saved!\")","2d40b62e":"### Filling the missing values","5f740751":"### Dropping Useless Columns","8802d5b4":"### Loading Data","ff05748f":"### Data Visulization","0db4aa4e":"### Missing Values","a3f71133":"* PassengerId : unique id number to each passenger\n* Survived : passenger survive(1) and died(0)\n* Pclass : passenger class\n* Name : name of passenger\n* Sex : gender of passenger\n* Age : age of passenger\n* SibSp : number of siblings\/spouse\n* Parch : number of parent\/children\n* Ticket : ticket number\n* Fare : amount of money spent on ticket\n* Cabin : cabin category\n* Embarked : port where passenger embarked (C= Cherbourg, Q=Quenntown, S = Southampton)\n* int64(5) : PassengerId, Survived, Pclass, SibSp and Parch\n* object(5) : Name, Sex, Ticket, Cabin and Embarked\n* float64(2) : Age and Fare","ebdbbc62":"### Modelling ","5ff21762":"### Data Exploration","33437a37":"### Adding New Features","6958e01f":"### Random Forest Regression"}}