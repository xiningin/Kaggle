{"cell_type":{"1aa3c399":"code","67498ad7":"code","efbeb2e3":"code","cb709bf0":"code","36325c6e":"code","d550c55e":"code","e0ead76d":"code","d99a63ff":"code","ce3a7e31":"code","1e937dcf":"code","350d8231":"code","ff285134":"code","87911bc1":"code","ac74ecbf":"code","76147c18":"code","3f8d9b16":"code","3ec8d2d0":"code","5e831ed2":"code","654bc6d2":"code","6d8e3bb0":"code","12defed7":"code","dc88b255":"code","84a24ec2":"code","be136aba":"code","68db28da":"code","c2e8191f":"code","e3a0507b":"code","7875d161":"markdown","962259d2":"markdown","cc64a884":"markdown","4aed6e29":"markdown","ca724216":"markdown","99a282c3":"markdown","0abb9a7d":"markdown","defa7b47":"markdown","5accda2a":"markdown"},"source":{"1aa3c399":"!pip install kaggle","67498ad7":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport gc\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import *\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_absolute_error\nfrom pickle import load\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    # for filename in filenames:\n        # print(os.path.join(dirname, filename))","efbeb2e3":"from google.colab import files\n\nuploaded = files.upload()\n\nfor fn in uploaded.keys():\n    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n        name=fn, length=len(uploaded[fn])))\n\n# Then move kaggle.json into the folder where the API expects to find it. ##\n!mkdir -p ~\/.kaggle\/ && mv kaggle.json ~\/.kaggle\/ && chmod 600 ~\/.kaggle\/kaggle.json","cb709bf0":"!kaggle competitions list","36325c6e":"!kaggle competitions download -c ventilator-pressure-prediction","d550c55e":"DEBUG = False","e0ead76d":"train = pd.read_csv(r'..\/content\/train.csv.zip')\ntest  = pd.read_csv(r'..\/content\/test.csv.zip')\nsubmission = pd.read_csv(r'..\/content\/sample_submission.csv.zip')","d99a63ff":"# train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\n# test  = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\n# submission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","ce3a7e31":"if DEBUG:\n    train = train[:80*1000]","1e937dcf":"train.shape, test.shape, submission.shape","350d8231":"train","ff285134":"train.describe()","87911bc1":"# test['pressure'] = 0","ac74ecbf":"test","76147c18":"test.describe()","3f8d9b16":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df","3ec8d2d0":"targets = train['pressure'].to_numpy().reshape(-1, 80)\ntrain.drop(labels='pressure', axis=1, inplace=True)\ntrain = add_features(train)\n# normalise the dataset\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\n\n# Reshape to group 80 timesteps for each breath ID\ntrain = train.reshape(-1, 80, train.shape[-1])","5e831ed2":"test = add_features(test)\ntest = RS.transform(test)\ntest = test.reshape(-1, 80, test.shape[-1])","654bc6d2":"train.shape, test.shape","6d8e3bb0":"# model creation\ndef create_lstm_model():\n\n    x0 = tf.keras.layers.Input(shape=(train.shape[-2], train.shape[-1]))  \n\n    lstm_layers = 4 # number of LSTM layers\n    lstm_units = [320, 305, 304, 229]\n    lstm = Bidirectional(keras.layers.LSTM(lstm_units[0], return_sequences=True))(x0)\n    for i in range(lstm_layers-1):\n        lstm = Bidirectional(keras.layers.LSTM(lstm_units[i+1], return_sequences=True))(lstm)    \n    lstm = Dropout(0.001)(lstm)\n    lstm = Dense(100, activation='relu')(lstm)\n    lstm = Dense(1)(lstm)\n\n    model = keras.Model(inputs=x0, outputs=lstm)\n    model.compile(optimizer=\"adam\", loss=\"mae\")\n    \n    return model","12defed7":"# Function to get hardware strategy\ndef get_hardware_strategy():\n    try:\n        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n        # set: this is always the case on Kaggle.\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        tf.config.optimizer.set_jit(True)\n    else:\n        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n        strategy = tf.distribute.get_strategy()\n\n    return tpu, strategy\n\ntpu, strategy = get_hardware_strategy()","dc88b255":"EPOCH = 350\nBATCH_SIZE = 512\nNFOLDS = 5\n\nwith strategy.scope():\n    kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=2021)\n    history = []\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = create_lstm_model()\n        model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n\n        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)\/BATCH_SIZE), 1e-5)\n        lr = LearningRateScheduler(scheduler, verbose=0)\n\n        history.append(model.fit(X_train, y_train, \n                                 validation_data=(X_valid, y_valid), \n                                 epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr]))\n        test_pred = model.predict(test).squeeze().reshape(-1, 1).squeeze()\n        test_preds.append(test_pred)    \n        \n        # save model\n        #model.save(\"lstm_model_fold_{}\".format(fold))\n        \n        del X_train, X_valid, y_train, y_valid, model\n        gc.collect()","84a24ec2":"colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\nplt.figure(figsize=(16,16))\nfor i in range(NFOLDS):\n    plt.plot(history[i].history['loss'], linestyle='-', color=colors[i], label='Train, fold #{}'.format(str(i)))\nfor i in range(NFOLDS):\n    plt.plot(history[i].history['val_loss'], linestyle='--', color=colors[i], label='Validation, fold #{}'.format(str(i)))\nplt.ylim(top=1)\nplt.title('Model Loss')\nplt.ylabel('MAE')\nplt.xlabel('Epoch')\nplt.legend()\nplt.grid(which='major', axis='both')\nplt.show();","be136aba":"def addlabels(x,y):\n    for i in range(len(x)):\n        plt.text(i,y[i],y[i], ha = 'center')\n\nfold_mae = np.zeros(NFOLDS, dtype=np.float)\nfor i in range(1):\n    fold_mae[i] = history[i].history['val_loss'][-1]\nplt.figure(figsize = (10, 5))\nnames = ['Fold #0', 'Fold #1', 'Fold #2', 'Fold #3', 'Fold #4']\nplt.bar(names, fold_mae, color ='royalblue', width = 0.4)\naddlabels(names, np.round(fold_mae, 3))\nplt.ylabel(\"MAE\")\nplt.title(\"Fold scores\")\nplt.show();","68db28da":"submission[\"pressure\"] = sum(test_preds)\/5\nsubmission.to_csv('submission.csv', index=False)\nprint('.\/submission.csv')","c2e8191f":"submission","e3a0507b":"!kaggle competitions submit -c ventilator-pressure-prediction -f submission.csv -m \"Message\"","7875d161":"## Model Creation","962259d2":"![sub_Keras.PNG](attachment:0b7e7951-748d-47ac-b97b-f22adc1d53f8.PNG)","cc64a884":"## Load Data","4aed6e29":"## Add Feature","ca724216":"![\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9 (2).png](attachment:8acb04c9-c999-442f-ac67-61603d64fafb.png)","99a282c3":"![\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9 (1).png](attachment:77e9872f-7630-4719-a638-eafa2de994aa.png)","0abb9a7d":"## Training","defa7b47":"## Libraries","5accda2a":"## Export && Submission"}}