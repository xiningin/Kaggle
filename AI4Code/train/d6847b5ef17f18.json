{"cell_type":{"079d0edf":"code","3b9348de":"code","bbbab7b5":"code","7bca7ca8":"code","1eb022e1":"code","8dd3c912":"code","ae75de8b":"code","82837c7a":"code","f984dc59":"code","5c52f901":"code","4cc4276f":"code","7b828d14":"code","7ab9712f":"code","4328c4ce":"code","bec7eadf":"code","c1f42504":"code","348072ee":"code","e107ae5d":"code","305b46b3":"code","22c36e73":"code","410a53c2":"code","11dc7548":"markdown","8337ce08":"markdown","489f794d":"markdown"},"source":{"079d0edf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\nfrom skimage import io\nfrom skimage.transform import resize\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.layers import Dropout, Flatten,Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport seaborn as sns\nsns.set()","3b9348de":"path = Path('\/kaggle\/input\/flowers-recognition\/flowers\/')\nbatch_size = 128\nepochs = 30","bbbab7b5":"flower_categories = []\nfeatures = []\nlabels = []\nfor dirc in path.iterdir():\n    flower_categories.append(dirc.name)\n    print(dirc.name)\n    for img_path in dirc.iterdir():\n        if img_path.name.endswith(\"jpg\"):\n            labels.append(dirc.name)\n#             img = io.imread(img_path)\n#             print(img)\n            img_array=cv2.imread(str(img_path),cv2.IMREAD_COLOR)\n            img_array=cv2.resize(img_array,(150,150))\n            features.append(img_array) # resize(img, (150, 150))","7bca7ca8":"print(type(features[100]), features[100].shape, labels[100])\nplt.imshow(features[100])\nplt.show()","1eb022e1":"labels = np.array(labels)\nfeatures = np.array(features)\n\n# Save for later\nnp.savez_compressed(\"\/kaggle\/working\/flowers.npz\", features, labels)","8dd3c912":"def preprocessing(features, labels):\n\n    features= features.reshape(len(features), 150,150,3)\/255.0\n    \n    one_hot = LabelBinarizer()\n    labels = one_hot.fit_transform(labels)\n    \n    return features, labels, one_hot\n\ndef plot_accuracy(history):\n    plt.figure(figsize=(10,5))\n    plt.plot(history.history[\"accuracy\"], label=\"Accuracy\", color=\"b\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"g\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.show()","ae75de8b":"def create_model(): \n\n    model = Sequential()\n\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(150,150,3)))\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(5, activation='softmax'))\n    \n    model.compile(optimizer=SGD(lr=0.01, momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])\n    \n    model.summary()\n    \n    return model","82837c7a":"X, y, one_hot = preprocessing(features, labels)","f984dc59":"# ideally, should split data in three parts train, test, dev\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)","5c52f901":"model = create_model()","4cc4276f":"history = model.fit(X_train,y_train, epochs = 20, validation_data = (X_test, y_test), verbose = 1, batch_size=batch_size)\n","7b828d14":"history.history.keys()","7ab9712f":"plot_accuracy(history)","4328c4ce":"aug_data= ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)","bec7eadf":"aug_model = create_model()","c1f42504":"aug_history = aug_model.fit_generator(aug_data.flow(X_train, y_train, batch_size=128), steps_per_epoch=len(X_train) \/\/ 128, epochs=30, \n                       validation_data=(X_test, y_test))","348072ee":"plot_accuracy(aug_history)","e107ae5d":"print(f\"Label: {one_hot.classes_[np.argmax(y_test[100])]} \\nPredicted: {one_hot.classes_[np.argmax(aug_model.predict(X_test[100:101]))]}\")\nplt.imshow(X_test[100])\nplt.show()","305b46b3":"aug_model.save(\".\/aug_final\")","22c36e73":"flower_categories = []\nfeatures = []\nlabels = []\nfor dirc in path.iterdir():\n    flower_categories.append(dirc.name)\n    print(dirc.name)\n    for img_path in dirc.iterdir():\n        if img_path.name.endswith(\"jpg\"):\n            labels.append(dirc.name)\n            img = io.imread(img_path)\n#             img_array=cv2.imread(str(img_path),cv2.IMREAD_COLOR)\n#             img_array=cv2.resize(img_array,(150,150))\n            features.append(resize(img, (150, 150))) # resize(img, (150, 150))","410a53c2":"labels = np.array(labels)\nfeatures = np.array(features)\n\nX, y, one_hot = preprocessing(features, labels)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n\naug_data= ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n\naug_model = create_model()\n\naug_history = aug_model.fit_generator(aug_data.flow(X_train, y_train, batch_size=batch_size),\n                                      steps_per_epoch=len(X_train) \/\/ 128,\n                                      epochs=10, \n                                      validation_data=(X_test, y_test))","11dc7548":"### all metrics remains plateaued. Why????? ","8337ce08":"# Using Skimage","489f794d":"# Using Data Augmentation"}}