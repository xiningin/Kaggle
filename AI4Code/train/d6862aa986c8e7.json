{"cell_type":{"00c57758":"code","27db6b19":"code","287ebed1":"code","61ad253e":"code","ba920214":"code","380d0287":"code","7353dd0b":"code","912c1c3e":"code","5f7bc62f":"code","222cc105":"code","e383e204":"code","ae60a244":"code","96970b32":"code","c79eccbb":"code","2e92fbf5":"code","d432836f":"code","44aaf386":"code","2815edcd":"code","01386aa0":"code","457d6ade":"code","abb88d1e":"code","0d959b0a":"code","0c0cb538":"code","8143c809":"code","ba3e311e":"code","3ec6f42b":"code","8e1f6724":"code","0f77caab":"code","ccbb4c37":"code","02c2126c":"code","aa1d2c48":"code","fd092a41":"code","31cf2bb8":"markdown","79a8c1f6":"markdown","cb6ae9d1":"markdown","58c1651c":"markdown","b6673ccc":"markdown","2cd76455":"markdown","a4abd31c":"markdown","0b9dcd96":"markdown","d6b67660":"markdown"},"source":{"00c57758":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier","27db6b19":"park = pd.read_csv(\"..\/input\/parkinson-disease-detection\/Parkinsson disease.csv\")","287ebed1":"park.head()","61ad253e":"park.shape","ba920214":"park.info()","380d0287":"park[\"status\"].value_counts()\n# there are 147 datapoints where it shows they have disease and  48 datapoints where it shows they don't have disease, \n# which means the dataset is skewed.","7353dd0b":"park[park.isnull().any(axis=1)]\n#no missing\/null data","912c1c3e":"sns.countplot(x='status',data=park)\n#Shows the distribution of status column - univariate analysis of the target column","5f7bc62f":"sns.pairplot(park)","222cc105":"park = park.drop(\"name\",axis=1)\n#Dropped name column as it doesnot contribute to model building","e383e204":"fig, ax = plt.subplots(figsize=(15,5))\npark.boxplot(['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)','HNR'],ax=ax)","ae60a244":"k=[]\nfor i in park.columns:\n    for j in park[i]:\n        if (j<1 and j>0):\n            k.append(i)\n            break\n\nfig, ax = plt.subplots(figsize=(15,5))\npark.boxplot(k,ax=ax)","96970b32":"park.describe().T","c79eccbb":"X = park.drop(\"status\",axis=1)\ny = park[\"status\"]","2e92fbf5":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=9)\nprint(X_train.shape)\nprint(X_test.shape)","d432836f":"model = DecisionTreeClassifier(criterion=\"entropy\")","44aaf386":"model.fit(X_train,y_train)","2815edcd":"preds = model.predict(X_test)\npreds","01386aa0":"model.score(X_train,y_train)\n#accuracy of the model obtained for the train data","457d6ade":"metrics.accuracy_score(y_test,preds)\n#accuracy of the model obtained for the test data","abb88d1e":"pd.crosstab(y_test,preds)","0d959b0a":"model_reg = DecisionTreeClassifier(criterion=\"entropy\",max_depth=10,min_samples_leaf=20)","0c0cb538":"model_reg.fit(X_train,y_train)","8143c809":"preds_reg = model_reg.predict(X_test)","ba3e311e":"model_reg.score(X_train,y_train)","3ec6f42b":"metrics.accuracy_score(y_test,preds_reg)","8e1f6724":"rfcl = RandomForestClassifier(n_estimators=100,max_depth=15)","0f77caab":"rfcl.fit(X_train,y_train)","ccbb4c37":"preds_rfcl = rfcl.predict(X_test)","02c2126c":"rfcl.score(X_train,y_train)","aa1d2c48":"metrics.accuracy_score(y_test,preds_rfcl)","fd092a41":"z=0\nb=0\nfor i in np.arange(10,150):\n    rfcl = RandomForestClassifier(n_estimators = i, max_depth=15)\n    rfcl.fit(X_train, y_train)\n    preds_rfcl=rfcl.predict(X_test)\n    acc=accuracy_score(y_test,preds_rfcl)\n    if acc>z:\n        z=acc\n        b=i\nprint(\"For\",b,\"number of trees,accuracy is\",z)","31cf2bb8":"                                                        OBSERVATIONS:\n\n* After regularizing, the model accuracy has decreased (for test data).\n* But the model without regularization was a overfit model as the train accuracy was 100% & there was a significant drop in test accuracy.\n* Whereas after regularization, we have managed to bring both the train and test accuracies at the same level which is not a overfit model anymore.","79a8c1f6":"### Tested the model on test data and the accuracy achieved. Captured the predicted\u00a0 values and did a crosstab. ","cb6ae9d1":"                                                    OBSERVATIONS:\n\n* After using Random forest classifier, we can see a drastic increase in test accuracy score.\n* We have used a 'for' loop to determine the optimal number of trees that gives the best result and it is shown above.","58c1651c":"                                                OBSERVATIONS FROM PAIR PLOT:\n\n* In 'status' column's pair plot, datapoints (classes) overlapped over majority region, so distinguishing between classes is difficult.\n* We can see few of the columns are normally distributed like HNR column.\n* We can see few of the columns are positively correlated like the Jitter:DDP and MDVP:Shimmer columns.","b6673ccc":"                                                OBSERVATIONS FROM BOXPLOTS:\n\n* From the box plots above, we can see that there are outliers or long tails or skewness in almost all the columns except MDVP:Fo(Hz), RPDE and DFA columns.\n* In the columns which have outliers, most of them are positively skewed except HNR which is negatively skewed.\n* In the column 'spread2', we can see the tails or outliers being present on both the sides.","2cd76455":"                                                       CHALLENGES:\n                                                        \n* In the target column, there are 48 healthy people & 147 people with Parkinson's disease i.e; one of the 2 classes is under represented or skewed for which the accuaracy at model level can be misleading. So need to consider the accuracy at class level i.e; recall using confusion matrix\n* 'name' is object and also it doesn't contribute in model building so it has to be removed from dataset\n* Large set of attributes, so building and analysing pair plot is difficult\n* In 'status' attribute's pair plot, datapoints overlapped over majority region, so distinguishing between classes is difficult.","a4abd31c":"                                            OBSERVATIONS FROM FIVE POINT SUMMARY:\n\n* A low standard deviation indicates that the data points tend to be close to the mean of the data set, while a high standard deviation indicates that the data points are spread out over a wider range of values.\n* So, from the abaove we can infer that, except MDVP:Fo(Hz), MDVP:Fhi(Hz), MDVP:Flo(Hz), rest o fthe columns have a spread closer to the mean.","0b9dcd96":"### Used regularization parameters of max_depth, min_sample_leaf to recreate the model and checked its\u00a0impact on the model accuracy.","d6b67660":"### Created the model using \u201centropy\u201d method of reducing the entropy and fitted it to training\u00a0 data."}}