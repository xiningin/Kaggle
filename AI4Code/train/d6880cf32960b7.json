{"cell_type":{"e00ee06e":"code","de544e27":"code","b1735874":"code","75771e8f":"code","59588c51":"code","2acad5f1":"code","0da21bce":"code","06aee408":"code","790fadab":"code","e0451594":"code","a34748f0":"code","d7e08e98":"code","2b7a9c38":"code","4cd9b10b":"code","ff9e4b8d":"code","5eeba33f":"code","cb098d7c":"code","0a222798":"code","ec5ccdcf":"code","3cb76b5c":"code","600b2aba":"code","87464835":"code","40b0512e":"code","a3ff2c09":"code","339c7447":"code","7dffd33c":"code","e21fc545":"code","614975c6":"code","767e34fa":"code","1463a9d5":"code","7e33af4f":"code","ebc9a4ef":"code","efcacb3e":"code","bfeb0305":"code","ba31b9a6":"code","4d290f83":"code","ad7caeea":"code","e5b1c3d6":"code","2f765578":"code","b554d919":"code","af50c3f8":"code","59f788ec":"markdown","de3e2848":"markdown","b535d296":"markdown","db5f0eb0":"markdown","a1d3e1a8":"markdown","aee4bcec":"markdown","a7361bcb":"markdown","7ac73f2d":"markdown","52ef9b4f":"markdown","8cff5915":"markdown","2d6aaf85":"markdown","cf1cfee1":"markdown","e142a291":"markdown","a572b15e":"markdown","e8f83ff1":"markdown","04537d7a":"markdown","de4f3d15":"markdown"},"source":{"e00ee06e":"# Verify installation - \nimport tensorflow as tf","de544e27":"print(f\"Tensorflow Version: {tf.__version__}\")\nprint(f\"Keras Version: {tf.keras.__version__}\")","b1735874":"tf.config.list_physical_devices('GPU')","75771e8f":"tf.config.list_physical_devices('CPU')","59588c51":"CheckList = [\"GPU\", \"CPU\"]\nfor device in CheckList:\n    out_ = tf.config.list_physical_devices(device)    \n    if len(out_) > 0:\n        print(f\"{device} is available\")        \n        print(\"details\\n\",out_)\n    else:\n        print(f\"{device} not available\")","2acad5f1":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport seaborn as sns","0da21bce":"# Keras has already contains mnist dataset \n# Loading mnist data using Keras\n\nmnist = tf.keras.datasets.mnist\n(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()","06aee408":"print(f\"data type of X_train_full: {X_train_full.dtype},\\nshape of X_train_full: {X_train_full.shape}\")","790fadab":"# create a validation data set from the full training data \n# Scale the data between 0 to 1 by dividing it by 255. as its an unsigned data between 0-255 range\nX_valid, X_train = X_train_full[:5000] \/ 255., X_train_full[5000:] \/ 255.\ny_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n\n# scale the test set as well\nX_test = X_test \/ 255.\n\n","e0451594":"# lets view the first data point of X_train\nplt.imshow(X_train[0], cmap=\"binary\")\nplt.axis('off')\nplt.show()\n","a34748f0":"plt.figure(figsize=(15,15))\nsns.heatmap(X_train[0], annot=True, cmap=\"binary\")","d7e08e98":"# actual value of y_train\ny_train[0]","2b7a9c38":"LAYERS = [tf.keras.layers.Flatten(input_shape=[28, 28], name=\"inputLayer\"),\n          tf.keras.layers.Dense(300, activation=\"relu\", name=\"hiddenLayer1\"),\n          tf.keras.layers.Dense(100, activation=\"relu\", name=\"hiddenLayer2\"),\n          tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputLayer\")]\n\nmodel_clf = tf.keras.models.Sequential(LAYERS)","4cd9b10b":"model_clf.layers","ff9e4b8d":"model_clf.summary()","5eeba33f":"# firsLayer * secondLayer + bias\n784*300 + 300, 300*100+100, 100*10+10","cb098d7c":"# Total parameters to be trained -\nsum((235500, 30100, 1010))","0a222798":"hidden1 = model_clf.layers[1]\nhidden1.name","ec5ccdcf":"model_clf.get_layer(hidden1.name) is hidden1","3cb76b5c":"# hidden1.set_weights(hidden1.get_weights()) # to set weights","600b2aba":"type(hidden1.get_weights())","87464835":"hidden1.get_weights()","40b0512e":"weights, biases = hidden1.get_weights()","a3ff2c09":"print(\"shape\\n\",weights.shape, \"\\n\")\n\nweights\n","339c7447":"print(\"shape\\n\", biases.shape)\n\nbiases","7dffd33c":"LOSS_FUNCTION = \"sparse_categorical_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\nOPTIMIZER = \"SGD\" # or use with custom learning rate=> tf.keras.optimizers.SGD(0.02)\nMETRICS = [\"accuracy\"]\n\nmodel_clf.compile(loss=LOSS_FUNCTION,\n              optimizer=OPTIMIZER,\n              metrics=METRICS)\n\n","e21fc545":"# 1719*30, X_train.shape, 55000\/32, batch size=32 by default","614975c6":"EPOCHS = 30\nVALIDATION_SET = (X_valid, y_valid)\n\nhistory = model_clf.fit(X_train, y_train, epochs=EPOCHS,\n                    validation_data=VALIDATION_SET)\n","767e34fa":"import time\nimport os\n\ndef saveModel_path(model_dir=\"SAVED_MODELS\"):\n    os.makedirs(model_dir, exist_ok=True)\n    fileName = time.strftime(\"Model_%Y_%m_%d_%H_%M_%S_.h5\")    \n    model_path = os.path.join(model_dir, fileName)\n    print(f\"your model will be saved at the following location\\n{model_path}\")\n    return model_path\n","1463a9d5":"UNIQUE_PATH = model_clf.save(saveModel_path())","7e33af4f":"history.params\n","ebc9a4ef":"pd.DataFrame(history.history)","efcacb3e":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1)\nplt.show()","bfeb0305":"model_clf.evaluate(X_test, y_test)","ba31b9a6":"X_new = X_test[:3]\ny_proba = model_clf.predict(X_new)\ny_proba.round(2)","4d290f83":"y_pred = np.argmax(model_clf.predict(X_new), axis=-1)\ny_pred","ad7caeea":"y_test_new = y_test[:3]","e5b1c3d6":"for data, pred, actual in zip(X_new, y_pred, y_test_new):\n    plt.imshow(data, cmap=\"binary\")\n    plt.title(f\"Predicted: {pred}, Actual: {actual}\")\n    plt.axis('off')\n    plt.show()\n    print(\"---\"*20)","2f765578":"weights, biases = hidden1.get_weights()\n","b554d919":"weights","af50c3f8":"biases","59f788ec":"<iframe src=\"https:\/\/slides.com\/supremecommander\/basic-neural-network\/embed\" width=\"576\" height=\"420\" scrolling=\"no\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen><\/iframe>","de3e2848":"> **pip install tensorflow==2.0.0**\n\n> To run from Anaconda Prompt\n\n> **!pip install tensorflow==2.0.0**\n\n> To run from Jupyter Notebook","b535d296":"#### Alternatively \n```python\nmodel_clf.compile(loss=tf.losses.sparse_categorical_crossentropy,\n               optimizer=tf.keras.optimizers.SGD(0.02),\n               metrics=[\"accuracy\"])\n```","db5f0eb0":"`Both Tensorflow 2.0 and Keras have been released for four years (Keras was released in March 2015, and Tensorflow was released in November of the same year). The rapid development of deep learning in the past days, we also know some problems of Tensorflow1.x and Keras:`\n\n* Using Tensorflow means programming static graphs, which is difficult and inconvenient for programs that are familiar with imperative programming\n\n* Tensorflow api is powerful and flexible, but it is more complex, confusing and difficult to use.\n\n* Keras api is productive and easy to use, but lacks flexibility for research\n","a1d3e1a8":"#### Altenative 1\n\n```python\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten(input_shape=[28, 28]))\nmodel.add(tf.keras.layers.Dense(300, activation=\"relu\"))\nmodel.add(tf.keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n\n```","aee4bcec":"`Tensorflow2.0 is a combination design of Tensorflow1.x and Keras. Considering user feedback and framework development over the past four years, it largely solves the above problems and will become the future machine learning platform.`\n\n> Tensorflow 2.0 is built on the following core ideas:\n\n\n* The coding is more pythonic, so that users can get the results immediately like they are programming in numpy\n* Retaining the characteristics of static graphs (for performance, distributed, and production deployment), this makes TensorFlow fast, scalable, and ready for production.\n* Using Keras as a high-level API for deep learning, making Tensorflow easy to use and efficient\n* Make the entire framework both high-level features (easy to use, efficient, and not flexible) and low-level features (powerful and scalable, not easy to use, but very flexible)","a7361bcb":">Eager execution is by default in TensorFlow 2.0 and, it needs no special setup.\n>The following below code can be used to find out whether a CPU or GPU is in use","7ac73f2d":"### GPU\/CPU Check","52ef9b4f":"\n## Open Source Deep Learning Frameworks\n\nDeep learnings is made accessible by a number of open source projects. Some of the most popular technologies include, but are not limited to, Deeplearning4j (DL4j), Theano, Torch, TensorFlow, and Caffe. The deciding factors on which one to use are the tech stack they target, and if they are low-level, academic, or application focused. Here\u2019s an overview of each:\n\nDL4J:\n\n   * JVM-based\n   * Distrubted\n   * Integrates with Hadoop and Spark\n   \n   \nTheano:\n\n   * Very popular in Academia\n   * Fairly low level\n   * Interfaced with via Python and Numpy\n\n\nTorch:\n\n   * Lua based\n   * In house versions used by Facebook and Twitter\n   * Contains pretrained models\n\n\nTensorFlow:\n\n   * Google written successor to Theano\n   * Interfaced with via Python and Numpy\n   * Highly parallel\n   * Can be somewhat slow for certain problem sets\n\n\n\nCaffe:\n\n   * Not general purpose. Focuses on machine-vision problems\n   * Implemented in C++ and is very fast\n   * Not easily extensible\n   * Has a Python interface","8cff5915":"### Working on mnist dataset - \n\n* This dataset contains handwritten digits. \n* It has 10 classes i.e. 0 to 9\n* Each data point is 2D array of 28x28 size.\n* Also known as hello world dataset for ANN\n\n[image source](https:\/\/en.wikipedia.org\/wiki\/MNIST_database#\/media\/File:MnistExamples.png)\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/27\/MnistExamples.png)","2d6aaf85":"#### Alternative 2\n\n```python\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=[28, 28]),\n    tf.keras.layers.Dense(300, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n```","cf1cfee1":"#### Official docs link for [DETAILED INSTALLATION STEPS](https:\/\/www.tensorflow.org\/install) for Tensorflow 2","e142a291":"## Brief installation of Tensorflow","a572b15e":">TensorFlow is tested and supported on the following 64-bit systems:\n\n>1.Ubuntu 16.04 or later\n\n>2.Windows 7 or later\n\n>3.macOS 10.12.6 (Sierra) or later (no GPU support)\n\n>4.Raspbian 9.0 or later","e8f83ff1":"<iframe src=\"https:\/\/slides.com\/supremecommander\/basic-neural-network\/embed\" width=\"576\" height=\"420\" scrolling=\"no\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen><\/iframe>","04537d7a":"### For custom weights initialiser or setting weights \nrefer [here](https:\/\/keras.io\/api\/layers\/base_layer\/#setweights-method)","de4f3d15":"## A simple classifier using Keras's Sequential API"}}