{"cell_type":{"646b3ba3":"code","3d8c0c43":"code","1f8b091b":"code","a1581622":"code","996b9055":"code","48f0384c":"code","07e3cfc4":"code","7378c30a":"code","1042cfbe":"code","ec84d1dc":"code","9d1835d0":"code","ab022d1a":"code","e93f407a":"code","0c53e165":"code","9645e297":"code","9709ead2":"code","34a06e2a":"code","a494a2e0":"code","2259afde":"code","a0999c0a":"code","3096ca9f":"code","e3afeddc":"code","117a1e72":"code","62d65f1f":"code","35b608fe":"code","1eab1a94":"code","80c52ef6":"code","7b0bef5e":"code","6db24f12":"code","6a163213":"code","c40989ab":"code","9ebd9b74":"code","74d04cc8":"code","9933ca22":"markdown","2a71dcfc":"markdown","f3404f50":"markdown"},"source":{"646b3ba3":"# install the fastai libraries and import them.  Not necessary in Kaggle because they are already installed\n#!pip install -Uqq fastbook\n#import fastbook\n#fastbook.setup_book()\n#!pip install fastai","3d8c0c43":"#from fastbook import *\nfrom fastai.vision.all import *\nfrom fastai.callback.fp16 import *","1f8b091b":"#mount google drive to store the notebook, output, etc.\n#from google.colab import drive\n#drive.mount('\/content\/drive')","a1581622":"#Conveniently, fastai knows about the data set already\nURLs.CUB_200_2011","996b9055":"# get the image dataset and unzip it\n#path = untar_data('http:\/\/s3.amazonaws.com\/fast-ai-imageclas\/CUB_200_2011.tgz')\n#path\n!tar -xvzf \/kaggle\/input\/200-bird-species-with-11788-images\/CUB_200_2011.tgz","48f0384c":"!ls \/kaggle\/working\/CUB_200_2011\/images","07e3cfc4":"# Set the bast path to the folder where the data set was upzipped\npath = Path('\/kaggle\/working\/CUB_200_2011\/images')\nPath.BASE_PATH = path","7378c30a":"#The data set includes several text files and folders.  We mainly care about the images folder\nPath.ls(path)","1042cfbe":"# For example, here's one of the folders\nfname = (path).ls()[1]\nfname","ec84d1dc":"#Within the folders we have a bunch of photos\n(path\/\"189.Red_bellied_Woodpecker\").ls()","9d1835d0":"# Come back to this later(?). Maybe use a regex to clean up the labels to remove the learning digits\nre.sub(r'^[\\d.-]+\\s*', '', fname.name)","ab022d1a":"# Create a data loader for our data set. This is a key step.  If you use \"from_folder\", fastai knows to create labels from the name of each folder\n# i.e., our 200 bird species.  I'm letting fastai determine the test and validation sets, rather than use the recommended ones \n# provided by the dataset. \ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2,seed=999, \\\n                                   item_tfms=Resize(460), batch_tfms=aug_transforms(size=224, min_scale=0.75), \\\n                                   bs=64,shuffle_train=True)","e93f407a":"# Here's an example of the training images\ndls.train_ds.items[:10]","0c53e165":"# check out some of the images in a batch\ndls.show_batch(nrows=1, ncols=5)","9645e297":"#fastai gives you a tool to find a good learning rate. This is really cool vs. guessing \nlearn = cnn_learner(dls, resnet50, metrics=error_rate)\nlr_min,lr_steep = learn.lr_find()","9709ead2":"# The recommend using something one order of magnitude less than the LR that gives the minimum loss\nprint(f\"Minimum\/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")","34a06e2a":"# Let's do a short training run.  I tried resnet34 and resnet50.\n# resnet50 did show some improvements vs. resnet34 so I'll use 50 here\n# Not bad, we're already at about 76% accuracy after just 2 epochs!\nlearn = cnn_learner(dls, resnet50, metrics=error_rate)\nlearn.fine_tune(2, base_lr=5.75e-03)","a494a2e0":"# This is a cool tool you can check which bird species tend to get confused with other species of birds.\n# e.g., Fish Crows get confused with Common Ravens\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.most_confused(min_val=3)","2259afde":"# No wonder.  Heres a sample common raven. \nPILImage.create((path\/\"107.Common_Raven\").ls()[0])","a0999c0a":"# And here's a Fish Crow.  I can't tell these things apart either. So this gives us some confidence that the model\n# is working, although I'm not sure how we're going to improve on this much. I doubt more training or a \n# slightly better model is going to help us tell these birds apart\nPILImage.create((path\/\"030.Fish_Crow\").ls()[0])","3096ca9f":"# Here's a sample Horned Grebe\nPILImage.create((path\/\"051.Horned_Grebe\").ls()[1])","e3afeddc":"# And here's an Eared Grebe.  They appear fairly similar except for the \"ears\"\n# So it's not surprising that the model sometimes gets them confused.  So again, I'm not sure how much better \n# we're going to do with a better model or more training. Some of these birds look a lot alike!\nPILImage.create((path\/\"050.Eared_Grebe\").ls()[1])","117a1e72":"# OK let's try to do a bit better.  If you use to_fp16, the GPU uses lower accuracy on its calculations\n# so training is a bit faster. Let's run training for 3 epochs with our original learning rate.\n# For these epochs,fastai keeps the resnet layers frozen, and we're focusing on the final layer which\n# is hopefully tuned to identify the birds\nlearn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\nlearn.fit_one_cycle(3,5.75e-03)","62d65f1f":"# Then unfreeze, which lets us start modifying the weights in the resnet pretrained layers\nlearn.unfreeze()","35b608fe":"# Having done dome training, and unfrozen the resnet layers, let's see what the appropriate learning rate\n# is now\nlearn.lr_find()","1eab1a94":"# There's a long flat area, where the loss is pretty low, so we'll choose a learning rate in that area (1e-4)\n# rather than take fastai's lr_min. We'll change the learning rate and run for 6 epochs \n# I seem to backslide for an epoch or two once we allow the weights in the resnet layers to change. \n# I wonder if there's a way to improve on that.  Maybe a different learning rate?\nlearn.fit_one_cycle(6, lr_max=1e-4)","80c52ef6":"# Let's see if we were wasting our time by unfreezing part-way. Here we'll just run for 9 cycles\n# without unfreezing. It looks like we did slightly better by unfreezing part-way through training\nlearn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\nlearn.fit_one_cycle(9, 5.75e-03)","7b0bef5e":"# Check the loss for the training and validation sets.  We're not overfitting badly\nlearn.recorder.plot_loss()","6db24f12":"# fastai also let's you train using the fine_tune method. It automatically picks the learning rates.\n# Let's see if it does better that what we did earlier with the fit_one_cycle method\n# Try it for 3 epochs with resnet weights frozen, and then unfreeze for 6 epochs. The results are similar, \n# fastai is smart enough to avoid the backsliding in error rate we had earlier\nlearn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\nlearn.fine_tune(6, freeze_epochs=3)","6a163213":"# Check again the species that the model confuses most often.  We've got less confusion than before\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.most_confused(min_val=3)","c40989ab":"# pick a random image in the test set\nimage_path=dls.train_ds.items[999]\nimage_path","9ebd9b74":"# Put it into a PILImage variable and look at it\nim=PILImage.create(image_path)\nim","74d04cc8":"# try a prediction.  Nice!  It got it correct (your results may vary depending on the image).\nlearn.predict(im)","9933ca22":"Most of this notebook follows the outline provided in the fastai course\nTurn on the GPU before running this. This is going to be way too slow if you try to run it on a CPU\nMake sure the Internet switch on the right hand side of Kaggle is ON","2a71dcfc":"## Caltech Bird Image Dataset fastai solution (80+% accuracy)\n","f3404f50":"I'm working on this project in order to find a good, cost-effective tool to automatically identify\nbirds near my birdfeeder. I use a Raspberry Pi to automatically detect motion, and snap pictures of\nthe birds. Previously I used the AWS Rekognition tools to identify the birds. Now I'll try \na custom model using fastai. See my blog for info on my overall system design:\nwww.mikesml.com\/2020\/11\/22\/ml-based-bird-and-squirrel-detector-with-raspberry-pi-and-aws-rekognition-lambda-s3-and-sns\/"}}