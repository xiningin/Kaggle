{"cell_type":{"62650875":"code","85c52cd8":"code","d251666c":"code","90511c13":"code","59083306":"code","53cb995f":"code","5176a35a":"code","50b661f0":"code","445af529":"code","b08f0836":"code","4be79a77":"code","7e21ca59":"code","66a5bd7c":"code","78603d2d":"code","053fb4e2":"code","5edcb94c":"code","6017ec81":"code","254bf39b":"code","fb8950e6":"code","7855afc8":"code","3e616293":"markdown","3907f026":"markdown","2bdb3d38":"markdown","29b9db0e":"markdown","7fdccbb3":"markdown","cc6757ce":"markdown","31fddfaf":"markdown","c9fa513c":"markdown","835fe568":"markdown"},"source":{"62650875":"import time\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\nimport sys\nsys.path.append(\"..\/input\/\") \nimport d2lzhpytorch as d2l\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef batch_norm(is_training, X, gamma, beta, moving_mean, moving_var, eps, momentum):\n    # \u5224\u65ad\u5f53\u524d\u6a21\u5f0f\u662f\u8bad\u7ec3\u6a21\u5f0f\u8fd8\u662f\u9884\u6d4b\u6a21\u5f0f\n    if not is_training:\n        # \u5982\u679c\u662f\u5728\u9884\u6d4b\u6a21\u5f0f\u4e0b\uff0c\u76f4\u63a5\u4f7f\u7528\u4f20\u5165\u7684\u79fb\u52a8\u5e73\u5747\u6240\u5f97\u7684\u5747\u503c\u548c\u65b9\u5dee\n        X_hat = (X - moving_mean) \/ torch.sqrt(moving_var + eps)\n    else:\n        assert len(X.shape) in (2, 4)\n        if len(X.shape) == 2:\n            # \u4f7f\u7528\u5168\u8fde\u63a5\u5c42\u7684\u60c5\u51b5\uff0c\u8ba1\u7b97\u7279\u5f81\u7ef4\u4e0a\u7684\u5747\u503c\u548c\u65b9\u5dee\n            mean = X.mean(dim=0)\n            var = ((X - mean) ** 2).mean(dim=0)\n        else:\n            # \u4f7f\u7528\u4e8c\u7ef4\u5377\u79ef\u5c42\u7684\u60c5\u51b5\uff0c\u8ba1\u7b97\u901a\u9053\u7ef4\u4e0a\uff08axis=1\uff09\u7684\u5747\u503c\u548c\u65b9\u5dee\u3002\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u4fdd\u6301\n            # X\u7684\u5f62\u72b6\u4ee5\u4fbf\u540e\u9762\u53ef\u4ee5\u505a\u5e7f\u64ad\u8fd0\u7b97\n            mean = X.mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n            var = ((X - mean) ** 2).mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n        # \u8bad\u7ec3\u6a21\u5f0f\u4e0b\u7528\u5f53\u524d\u7684\u5747\u503c\u548c\u65b9\u5dee\u505a\u6807\u51c6\u5316\n        X_hat = (X - mean) \/ torch.sqrt(var + eps)\n        # \u66f4\u65b0\u79fb\u52a8\u5e73\u5747\u7684\u5747\u503c\u548c\u65b9\u5dee\n        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n        moving_var = momentum * moving_var + (1.0 - momentum) * var\n    Y = gamma * X_hat + beta  # \u62c9\u4f38\u548c\u504f\u79fb\n    return Y, moving_mean, moving_var","85c52cd8":"class BatchNorm(nn.Module):\n    def __init__(self, num_features, num_dims):\n        super(BatchNorm, self).__init__()\n        if num_dims == 2:\n            shape = (1, num_features) #\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u795e\u7ecf\u5143\n        else:\n            shape = (1, num_features, 1, 1)  #\u901a\u9053\u6570\n        # \u53c2\u4e0e\u6c42\u68af\u5ea6\u548c\u8fed\u4ee3\u7684\u62c9\u4f38\u548c\u504f\u79fb\u53c2\u6570\uff0c\u5206\u522b\u521d\u59cb\u5316\u62100\u548c1\n        self.gamma = nn.Parameter(torch.ones(shape))\n        self.beta = nn.Parameter(torch.zeros(shape))\n        # \u4e0d\u53c2\u4e0e\u6c42\u68af\u5ea6\u548c\u8fed\u4ee3\u7684\u53d8\u91cf\uff0c\u5168\u5728\u5185\u5b58\u4e0a\u521d\u59cb\u5316\u62100\n        self.moving_mean = torch.zeros(shape)\n        self.moving_var = torch.zeros(shape)\n\n    def forward(self, X):\n        # \u5982\u679cX\u4e0d\u5728\u5185\u5b58\u4e0a\uff0c\u5c06moving_mean\u548cmoving_var\u590d\u5236\u5230X\u6240\u5728\u663e\u5b58\u4e0a\n        if self.moving_mean.device != X.device:\n            self.moving_mean = self.moving_mean.to(X.device)\n            self.moving_var = self.moving_var.to(X.device)\n        # \u4fdd\u5b58\u66f4\u65b0\u8fc7\u7684moving_mean\u548cmoving_var, Module\u5b9e\u4f8b\u7684traning\u5c5e\u6027\u9ed8\u8ba4\u4e3atrue, \u8c03\u7528.eval()\u540e\u8bbe\u6210false\n        Y, self.moving_mean, self.moving_var = batch_norm(self.training, \n            X, self.gamma, self.beta, self.moving_mean,\n            self.moving_var, eps=1e-5, momentum=0.9)\n        return Y","d251666c":"net = nn.Sequential(\n            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n            BatchNorm(6, num_dims=4),\n            nn.Sigmoid(),\n            nn.MaxPool2d(2, 2), # kernel_size, stride\n            nn.Conv2d(6, 16, 5),\n            BatchNorm(16, num_dims=4),\n            nn.Sigmoid(),\n            nn.MaxPool2d(2, 2),\n            d2l.FlattenLayer(),\n            nn.Linear(16*4*4, 120),\n            BatchNorm(120, num_dims=2),\n            nn.Sigmoid(),\n            nn.Linear(120, 84),\n            BatchNorm(84, num_dims=2),\n            nn.Sigmoid(),\n            nn.Linear(84, 10)\n        )","90511c13":"batch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n\nlr, num_epochs = 0.001, 5\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\nd2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","59083306":"net = nn.Sequential(\n            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n            nn.BatchNorm2d(6),\n            nn.Sigmoid(),\n            nn.MaxPool2d(2, 2), # kernel_size, stride\n            nn.Conv2d(6, 16, 5),\n            nn.BatchNorm2d(16),\n            nn.Sigmoid(),\n            nn.MaxPool2d(2, 2),\n            d2l.FlattenLayer(),\n            nn.Linear(16*4*4, 120),\n            nn.BatchNorm1d(120),\n            nn.Sigmoid(),\n            nn.Linear(120, 84),\n            nn.BatchNorm1d(84),\n            nn.Sigmoid(),\n            nn.Linear(84, 10)\n        )\n\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\nd2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","53cb995f":"class Residual(nn.Module):  # \u672c\u7c7b\u5df2\u4fdd\u5b58\u5728d2lzh_pytorch\u5305\u4e2d\u65b9\u4fbf\u4ee5\u540e\u4f7f\u7528\n    #\u53ef\u4ee5\u8bbe\u5b9a\u8f93\u51fa\u901a\u9053\u6570\u3001\u662f\u5426\u4f7f\u7528\u989d\u5916\u76841x1\u5377\u79ef\u5c42\u6765\u4fee\u6539\u901a\u9053\u6570\u4ee5\u53ca\u5377\u79ef\u5c42\u7684\u6b65\u5e45\u3002\n    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n        super(Residual, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        if use_1x1conv:\n            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, X):\n        Y = F.relu(self.bn1(self.conv1(X)))\n        Y = self.bn2(self.conv2(Y))\n        if self.conv3:\n            X = self.conv3(X)\n        return F.relu(Y + X)","5176a35a":"blk = Residual(3, 3)\nX = torch.rand((4, 3, 6, 6))\nblk(X).shape # torch.Size([4, 3, 6, 6])","50b661f0":"blk = Residual(3, 6, use_1x1conv=True, stride=2)\nblk(X).shape # torch.Size([4, 6, 3, 3])","445af529":"net = nn.Sequential(\n        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n        nn.BatchNorm2d(64), \n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))","b08f0836":"def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n    if first_block:\n        assert in_channels == out_channels # \u7b2c\u4e00\u4e2a\u6a21\u5757\u7684\u901a\u9053\u6570\u540c\u8f93\u5165\u901a\u9053\u6570\u4e00\u81f4\n    blk = []\n    for i in range(num_residuals):\n        if i == 0 and not first_block:\n            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n        else:\n            blk.append(Residual(out_channels, out_channels))\n    return nn.Sequential(*blk)\n\nnet.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\nnet.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\nnet.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\nnet.add_module(\"resnet_block4\", resnet_block(256, 512, 2))","4be79a77":"net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d\u7684\u8f93\u51fa: (Batch, 512, 1, 1)\nnet.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(512, 10))) ","7e21ca59":"X = torch.rand((1, 1, 224, 224))\nfor name, layer in net.named_children():\n    X = layer(X)\n    print(name, ' output shape:\\t', X.shape)","66a5bd7c":"lr, num_epochs = 0.001, 5\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\nd2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","78603d2d":"def conv_block(in_channels, out_channels):\n    blk = nn.Sequential(nn.BatchNorm2d(in_channels), \n                        nn.ReLU(),\n                        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n    return blk\n\nclass DenseBlock(nn.Module):\n    def __init__(self, num_convs, in_channels, out_channels):\n        super(DenseBlock, self).__init__()\n        net = []\n        for i in range(num_convs):\n            in_c = in_channels + i * out_channels\n            net.append(conv_block(in_c, out_channels))\n        self.net = nn.ModuleList(net)\n        self.out_channels = in_channels + num_convs * out_channels # \u8ba1\u7b97\u8f93\u51fa\u901a\u9053\u6570\n\n    def forward(self, X):\n        for blk in self.net:\n            Y = blk(X)\n            X = torch.cat((X, Y), dim=1)  # \u5728\u901a\u9053\u7ef4\u4e0a\u5c06\u8f93\u5165\u548c\u8f93\u51fa\u8fde\u7ed3\n        return X","053fb4e2":"blk = DenseBlock(2, 3, 10)\nX = torch.rand(4, 3, 8, 8)\nY = blk(X)\nY.shape # torch.Size([4, 23, 8, 8])","5edcb94c":"def transition_block(in_channels, out_channels):\n    blk = nn.Sequential(\n            nn.BatchNorm2d(in_channels), \n            nn.ReLU(),\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.AvgPool2d(kernel_size=2, stride=2))\n    return blk\n\nblk = transition_block(23, 10)\nblk(Y).shape # torch.Size([4, 10, 4, 4])","6017ec81":"net = nn.Sequential(\n        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n        nn.BatchNorm2d(64), \n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))","254bf39b":"num_channels, growth_rate = 64, 32  # num_channels\u4e3a\u5f53\u524d\u7684\u901a\u9053\u6570\nnum_convs_in_dense_blocks = [4, 4, 4, 4]\n\nfor i, num_convs in enumerate(num_convs_in_dense_blocks):\n    DB = DenseBlock(num_convs, num_channels, growth_rate)\n    net.add_module(\"DenseBlosk_%d\" % i, DB)\n    # \u4e0a\u4e00\u4e2a\u7a20\u5bc6\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\n    num_channels = DB.out_channels\n    # \u5728\u7a20\u5bc6\u5757\u4e4b\u95f4\u52a0\u5165\u901a\u9053\u6570\u51cf\u534a\u7684\u8fc7\u6e21\u5c42\n    if i != len(num_convs_in_dense_blocks) - 1:\n        net.add_module(\"transition_block_%d\" % i, transition_block(num_channels, num_channels \/\/ 2))\n        num_channels = num_channels \/\/ 2","fb8950e6":"net.add_module(\"BN\", nn.BatchNorm2d(num_channels))\nnet.add_module(\"relu\", nn.ReLU())\nnet.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d\u7684\u8f93\u51fa: (Batch, num_channels, 1, 1)\nnet.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(num_channels, 10))) \n\nX = torch.rand((1, 1, 96, 96))\nfor name, layer in net.named_children():\n    X = layer(X)\n    print(name, ' output shape:\\t', X.shape)","7855afc8":"batch_size = 256\n# \u5982\u51fa\u73b0\u201cout of memory\u201d\u7684\u62a5\u9519\u4fe1\u606f\uff0c\u53ef\u51cf\u5c0fbatch_size\u6216resize\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\nlr, num_epochs = 0.001, 5\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\nd2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","3e616293":"### \u7b80\u6d01\u5b9e\u73b0","3907f026":"### DenseNet\u6a21\u578b","2bdb3d38":"### \u8fc7\u6e21\u5c42\n$1\\times1$\u5377\u79ef\u5c42\uff1a\u6765\u51cf\u5c0f\u901a\u9053\u6570  \n\u6b65\u5e45\u4e3a2\u7684\u5e73\u5747\u6c60\u5316\u5c42\uff1a\u51cf\u534a\u9ad8\u548c\u5bbd","29b9db0e":"# \u7a20\u5bc6\u8fde\u63a5\u7f51\u7edc\uff08DenseNet\uff09\n\n![1576638871%281%29.png](attachment:1576638871%281%29.png)\n###\u4e3b\u8981\u6784\u5efa\u6a21\u5757\uff1a  \n\u7a20\u5bc6\u5757\uff08dense block\uff09\uff1a \u5b9a\u4e49\u4e86\u8f93\u5165\u548c\u8f93\u51fa\u662f\u5982\u4f55\u8fde\u7ed3\u7684\u3002  \n\u8fc7\u6e21\u5c42\uff08transition layer\uff09\uff1a\u7528\u6765\u63a7\u5236\u901a\u9053\u6570\uff0c\u4f7f\u4e4b\u4e0d\u8fc7\u5927\u3002\n### \u7a20\u5bc6\u5757","7fdccbb3":"### 1.\u5bf9\u5168\u8fde\u63a5\u5c42\u505a\u6279\u91cf\u5f52\u4e00\u5316\n\u4f4d\u7f6e\uff1a\u5168\u8fde\u63a5\u5c42\u4e2d\u7684\u4eff\u5c04\u53d8\u6362\u548c\u6fc0\u6d3b\u51fd\u6570\u4e4b\u95f4\u3002  \n**\u5168\u8fde\u63a5\uff1a**  \n$$\\boldsymbol{x} = \\boldsymbol{W\\boldsymbol{u} + \\boldsymbol{b}} \\\\\n output =\\phi(\\boldsymbol{x})$$   \n\n\n**\u6279\u91cf\u5f52\u4e00\u5316\uff1a**\n$$ \noutput=\\phi(\\text{BN}(\\boldsymbol{x}))$$\n\n\n$$\\boldsymbol{y}^{(i)} = \\text{BN}(\\boldsymbol{x}^{(i)})$$\n\n\n$$\\boldsymbol{\\mu}_\\mathcal{B} \\leftarrow \\frac{1}{m}\\sum_{i = 1}^{m} \\boldsymbol{x}^{(i)},$$ $$\\boldsymbol{\\sigma}_\\mathcal{B}^2 \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m}(\\boldsymbol{x}^{(i)} - \\boldsymbol{\\mu}_\\mathcal{B})^2,$$\n\n\n$$\\hat{\\boldsymbol{x}}^{(i)} \\leftarrow \\frac{\\boldsymbol{x}^{(i)} - \\boldsymbol{\\mu}_\\mathcal{B}}{\\sqrt{\\boldsymbol{\\sigma}_\\mathcal{B}^2 + \\epsilon}},$$\n\n\u8fd9\u2fa5\u03f5 > 0\u662f\u4e2a\u5f88\u5c0f\u7684\u5e38\u6570\uff0c\u4fdd\u8bc1\u5206\u6bcd\u5927\u4e8e0\n\n\n$${\\boldsymbol{y}}^{(i)} \\leftarrow \\boldsymbol{\\gamma} \\odot\n\\hat{\\boldsymbol{x}}^{(i)} + \\boldsymbol{\\beta}.$$\n\n\n\u5f15\u5165\u53ef\u5b66\u4e60\u53c2\u6570\uff1a\u62c9\u4f38\u53c2\u6570\u03b3\u548c\u504f\u79fb\u53c2\u6570\u03b2\u3002\u82e5$\\boldsymbol{\\gamma} = \\sqrt{\\boldsymbol{\\sigma}\\mathcal{B}^2 + \\epsilon}$\u548c$\\boldsymbol{\\beta} = \\boldsymbol{\\mu}\\mathcal{B}$\uff0c\u6279\u91cf\u5f52\u4e00\u5316\u65e0\u6548\u3002\n\n### 2.\u5bf9\u5377\u79ef\u5c42\u505a\u6279\u91cf\u5f52\u2f00\u5316\n\u4f4d\u7f6e\uff1a\u5377\u79ef\u8ba1\u7b97\u4e4b\u540e\u3001\u5e94\u2f64\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u3002  \n\u5982\u679c\u5377\u79ef\u8ba1\u7b97\u8f93\u51fa\u591a\u4e2a\u901a\u9053\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u8fd9\u4e9b\u901a\u9053\u7684\u8f93\u51fa\u5206\u522b\u505a\u6279\u91cf\u5f52\u4e00\u5316\uff0c\u4e14\u6bcf\u4e2a\u901a\u9053\u90fd\u62e5\u6709\u72ec\u7acb\u7684\u62c9\u4f38\u548c\u504f\u79fb\u53c2\u6570\u3002\n\u8ba1\u7b97\uff1a\u5bf9\u5355\u901a\u9053\uff0cbatchsize=m,\u5377\u79ef\u8ba1\u7b97\u8f93\u51fa=pxq\n\u5bf9\u8be5\u901a\u9053\u4e2dm\u00d7p\u00d7q\u4e2a\u5143\u7d20\u540c\u65f6\u505a\u6279\u91cf\u5f52\u4e00\u5316,\u4f7f\u7528\u76f8\u540c\u7684\u5747\u503c\u548c\u65b9\u5dee\u3002\n\n### 3.\u9884\u6d4b\u65f6\u7684\u6279\u91cf\u5f52\u2f00\u5316\n\u8bad\u7ec3\uff1a\u4ee5batch\u4e3a\u5355\u4f4d,\u5bf9\u6bcf\u4e2abatch\u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\u3002  \n\u9884\u6d4b\uff1a\u7528\u79fb\u52a8\u5e73\u5747\u4f30\u7b97\u6574\u4e2a\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u6837\u672c\u5747\u503c\u548c\u65b9\u5dee\u3002\n### \u4ece\u96f6\u5b9e\u73b0","cc6757ce":"# \u6279\u91cf\u5f52\u4e00\u5316\uff08BatchNormalization\uff09\n#### \u5bf9\u8f93\u5165\u7684\u6807\u51c6\u5316\uff08\u6d45\u5c42\u6a21\u578b\uff09\n\u5904\u7406\u540e\u7684\u4efb\u610f\u4e00\u4e2a\u7279\u5f81\u5728\u6570\u636e\u96c6\u4e2d\u6240\u6709\u6837\u672c\u4e0a\u7684\u5747\u503c\u4e3a0\u3001\u6807\u51c6\u5dee\u4e3a1\u3002  \n\u6807\u51c6\u5316\u5904\u7406\u8f93\u5165\u6570\u636e\u4f7f\u5404\u4e2a\u7279\u5f81\u7684\u5206\u5e03\u76f8\u8fd1\n#### \u6279\u91cf\u5f52\u4e00\u5316\uff08\u6df1\u5ea6\u6a21\u578b\uff09\n\u5229\u7528\u5c0f\u6279\u91cf\u4e0a\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u4e0d\u65ad\u8c03\u6574\u795e\u7ecf\u7f51\u7edc\u4e2d\u95f4\u8f93\u51fa\uff0c\u4ece\u800c\u4f7f\u6574\u4e2a\u795e\u7ecf\u7f51\u7edc\u5728\u5404\u5c42\u7684\u4e2d\u95f4\u8f93\u51fa\u7684\u6570\u503c\u66f4\u7a33\u5b9a\u3002","31fddfaf":"# \u6b8b\u5dee\u7f51\u7edc\uff08ResNet\uff09\n\u6df1\u5ea6\u5b66\u4e60\u7684\u95ee\u9898\uff1a\u6df1\u5ea6CNN\u7f51\u7edc\u8fbe\u5230\u4e00\u5b9a\u6df1\u5ea6\u540e\u518d\u4e00\u5473\u5730\u589e\u52a0\u5c42\u6570\u5e76\u4e0d\u80fd\u5e26\u6765\u8fdb\u4e00\u6b65\u5730\u5206\u7c7b\u6027\u80fd\u63d0\u9ad8\uff0c\u53cd\u800c\u4f1a\u62db\u81f4\u7f51\u7edc\u6536\u655b\u53d8\u5f97\u66f4\u6162\uff0c\u51c6\u786e\u7387\u4e5f\u53d8\u5f97\u66f4\u5dee\u3002\n### \u6b8b\u5dee\u5757\uff08Residual Block\uff09\n\u6052\u7b49\u6620\u5c04\uff1a  \n\u5de6\u8fb9\uff1af(x)=x                                                  \n\u53f3\u8fb9\uff1af(x)-x=0 \uff08\u6613\u4e8e\u6355\u6349\u6052\u7b49\u6620\u5c04\u7684\u7ec6\u5fae\u6ce2\u52a8\uff09\n![image.png](attachment:image.png)\n\u5728\u6b8b\u5dee\u5757\u4e2d\uff0c\u8f93\u2f0a\u53ef\u901a\u8fc7\u8de8\u5c42\u7684\u6570\u636e\u7ebf\u8def\u66f4\u5feb \u5730\u5411\u524d\u4f20\u64ad\u3002","c9fa513c":"### ResNet\u6a21\u578b\n\u5377\u79ef(64,7x7,3)  \n\u6279\u91cf\u4e00\u4f53\u5316  \n\u6700\u5927\u6c60\u5316(3x3,2)  \n\n\u6b8b\u5dee\u5757x4 (\u901a\u8fc7\u6b65\u5e45\u4e3a2\u7684\u6b8b\u5dee\u5757\u5728\u6bcf\u4e2a\u6a21\u5757\u4e4b\u95f4\u51cf\u5c0f\u9ad8\u548c\u5bbd)\n\n\u5168\u5c40\u5e73\u5747\u6c60\u5316\n\n\u5168\u8fde\u63a5","835fe568":"###\u57fa\u4e8eLeNet\u7684\u5e94\u7528"}}