{"cell_type":{"817d78d9":"code","c2705e78":"code","3da141c2":"code","074c9c75":"code","7e6fa3d1":"code","c60c7047":"code","4c84e91f":"code","d0ce6c3e":"code","f4f4316c":"code","4d1d4b4d":"code","13ff8bae":"code","28662947":"code","1b4eba59":"code","b8a33392":"code","6450b70a":"code","8cb9ae50":"code","64aa9e70":"code","b80d48fd":"code","1cae9fb4":"code","e1812d17":"code","5f080b6b":"code","bbc224e1":"code","c4ee8d6e":"code","2d7434f0":"code","616492ec":"markdown"},"source":{"817d78d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c2705e78":"df_Train = pd.read_csv(\"..\/input\/train_V2.csv\")\n\ndf_Test = pd.read_csv(\"..\/input\/test_V2.csv\")\n\nprint(\"Train data set :\\n\",df_Train.head())\nprint(\"Test data set :\\n\", df_Test.head())\n","3da141c2":"# Copied from another kernel\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","074c9c75":"df_Train = reduce_mem_usage(df_Train)\ndf_Test = reduce_mem_usage(df_Test)","7e6fa3d1":"df_Train.info()","c60c7047":"    total = df_Train.isnull().sum().sort_values(ascending= False)\n    percent_1= df_Train.isnull().sum()\/df_Train.isnull().count()*100\n    percent_2= round(percent_1,1).sort_values(ascending= False)\n    missing_data = pd.concat([total,percent_2], axis= 1, keys = ['Total', '%']) \n    print(missing_data)","4c84e91f":"df_Trial = df_Train[df_Train['winPlacePerc'].isna()==True]\nprint(df_Trial)","d0ce6c3e":"df_Train.loc[df_Train['winPlacePerc'].isna()==True, 'winPlacePerc']= 0.5","f4f4316c":"ColumnList = ['assists', 'boosts', 'damageDealt', 'DBNOs',\n       'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'maxPlace', 'numGroups', 'revives',\n       'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints',\n       'winPlacePerc']","4d1d4b4d":"# Align with maxPlace\n# Credit: https:\/\/www.kaggle.com\/anycode\/simple-nn-baseline-4\nsubset = df_Train.loc[df_Train.maxPlace > 1]\ngap = 1.0 \/ (subset.maxPlace.values - 1)\nnew_perc = np.around(subset.winPlacePerc.values \/ gap) * gap\ndf_Train.loc[df_Train.maxPlace > 1, \"winPlacePerc\"] = new_perc\n\n# Edge case\ndf_Train.loc[(df_Train.maxPlace > 1) & (df_Train.numGroups == 1), \"winPlacePerc\"] = 0\nassert df_Train[\"winPlacePerc\"].isnull().sum() == 0\n\n#df_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission_adjusted.csv\", index=False)","13ff8bae":"df_Train= df_Train.set_index(['Id'])\ndf_Test= df_Test.set_index(['Id'])\n\ndf_Train = df_Train[ColumnList]\n\n\n","28662947":"ColumnList.remove('winPlacePerc')\n","1b4eba59":"df_Test = df_Test[ColumnList]","b8a33392":"X_Column = ColumnList\nY_Column = 'winPlacePerc'\nX_Train = df_Train[X_Column]\nY_Train = df_Train[Y_Column]\nX_test = df_Test[X_Column]","6450b70a":"# Courtesy Koon-Hi-Koom\nX_Train.loc[X_Train['headshotKills'].abs()> 0,'headshotrate']= X_Train['kills']\/X_Train['headshotKills'] \nX_Train.loc[X_Train['headshotKills'].abs()== 0,'headshotrate']= 0\n\nX_test.loc[X_test['headshotKills'].abs()> 0,'headshotrate']= X_test['kills']\/X_test['headshotKills'] \nX_test.loc[X_test['headshotKills'].abs()== 0,'headshotrate']= 0\n\nX_Train.loc[X_Train['kills'].abs()> 0,'killStreakrate']= X_Train['killStreaks']\/X_Train['kills']\nX_Train.loc[X_Train['kills'].abs()== 0,'killStreakrate']= 0\n\nX_test.loc[X_test['kills'].abs()> 0,'killStreakrate']= X_test['killStreaks']\/X_test['kills']\nX_test.loc[X_test['kills'].abs()== 0,'killStreakrate']= 0\n\nX_Train['healthitems'] = X_Train['heals'] + X_Train['boosts']\nX_test['healthitems'] = X_test['heals'] + X_test['boosts']\n","8cb9ae50":"X_Train.columns","64aa9e70":"X_Train = X_Train**0.5\nX_test= X_test**0.5","b80d48fd":"ColumnList = ['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills',\n       'killPlace', 'killPoints', 'kills', 'killStreaks', 'longestKill',\n       'maxPlace', 'numGroups', 'revives', 'rideDistance', 'roadKills',\n       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n       'weaponsAcquired', 'winPoints', 'headshotrate',\n       'killStreakrate', 'healthitems']\nX_Train = X_Train[ColumnList]\nX_test = X_test[ColumnList]\n\n","1cae9fb4":"#from sklearn.preprocessing import StandardScaler\n#sc_X= StandardScaler()\n#X_Train = sc_X.fit_transform(X_Train)\n#X_test= sc_X.transform(X_test)","e1812d17":"import lightgbm as lgb","5f080b6b":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error\n\n\nimport gc\nfolds = KFold(n_splits=3,random_state=6)\noof_preds = np.zeros(X_Train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\n\nvalid_score = 0\n\nfeature_importance_df = pd.DataFrame()\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_Train, Y_Train)):\n    trn_x, trn_y = X_Train.iloc[trn_idx], Y_Train[trn_idx]\n    val_x, val_y = X_Train.iloc[val_idx], Y_Train[val_idx]    \n    \n    train_data = lgb.Dataset(data=trn_x, label=trn_y)\n    valid_data = lgb.Dataset(data=val_x, label=val_y)   \n    \n    params = {\"objective\" : \"regression\", \"metric\" : \"mae\", 'n_estimators':15000, 'early_stopping_rounds':200,\n              \"num_leaves\" : 31, \"learning_rate\" : 0.05, \"bagging_fraction\" : 0.9,\n               \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.7\n             }\n    \n    lgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=1000) \n    \n    oof_preds[val_idx] = lgb_model.predict(val_x, num_iteration=lgb_model.best_iteration)\n    oof_preds[oof_preds>1] = 1\n    oof_preds[oof_preds<0] = 0\n    sub_pred = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration) \n    sub_pred[sub_pred>1] = 1 # should be greater or equal to 1\n    sub_pred[sub_pred<0] = 0 \n    sub_preds += sub_pred\/ folds.n_splits\n    print('Fold %2d MAE : %.6f' % (n_fold + 1, mean_absolute_error(val_y, oof_preds[val_idx])))\n    valid_score += mean_absolute_error(val_y, oof_preds[val_idx])\n    \n    #fold_importance_df = pd.DataFrame()\n    #fold_importance_df[\"feature\"] = train_columns\n    #fold_importance_df[\"importance\"] = lgb_model.feature_importance()\n    #fold_importance_df[\"fold\"] = n_fold + 1\n    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    gc.collect()","bbc224e1":"#%%time\n#d_train = lgb.Dataset(X_Train, label=Y_Train)\n#params = {}\n#params['learning_rate'] = 0.05\n#params['boosting_type'] = 'gbdt'\n#params['objective'] = 'regression'\n#params['metric'] = 'mae'\n#params['sub_feature'] = 0.9\n#params['num_leaves'] = 500\n#params['min_data'] = 1\n#params['max_depth'] = 30\n#params['min_gain_to_split']= 0.00001\n#clf = lgb.train(params, d_train, 1000)\n#print('Fold %2d MAE : %.6f' % (n_fold + 1, mean_absolute_error(val_y, oof_preds[val_idx])))\n","c4ee8d6e":"df_output = df_Test\npred = sub_preds\nprint(\"fix winPlacePerc\")\ndf_output['winPlacePerc'] = pred\ndf_output.loc[df_output['maxPlace']==0, 'winPlacePerc']= 0.0\ndf_output.loc[df_output['maxPlace']==1, 'winPlacePerc']= 1.0\ndf_output.loc[df_output['winPlacePerc']<= 0.0, 'winPlacePerc']= 0.0\ndf_output.loc[df_output['winPlacePerc']>= 1.0, 'winPlacePerc']= 1.0\ndf_output.loc[(df_output['winPlacePerc']< 1.0) & (df_output['winPlacePerc']> 1.0), 'winPlacePerc']= round(df_output['winPlacePerc']\/(1.0\/(df_output['maxPlace']-1)))* (1.0\/(df_output['maxPlace']-1))\n\ndf_output= df_output[[Y_Column]]\nprint(df_output.head())","2d7434f0":"df_output= df_output.reset_index()\n\ndf_output.to_csv('submission.csv', index= False)","616492ec":"#y_pred=lgb_model.predict(X_test)\nfor i in range(len(df_Test)):\n    winPlacePerc = pred[i]\n    maxPlace = int(df_Test.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 \/ (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc \/ gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    pred[i] = winPlacePerc\n\n    if (i + 1) % 100000 == 0:\n        print(i, flush=True, end=\" \")"}}