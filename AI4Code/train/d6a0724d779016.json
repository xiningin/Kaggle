{"cell_type":{"9443c681":"code","ee8d0a93":"code","86843d8b":"code","5ca10750":"code","de2d651f":"code","2fe27a97":"code","4edea009":"code","b778886f":"code","8fd305dd":"code","b59194a6":"code","70622169":"code","b9be54d6":"code","e8b4b2eb":"code","09c8e075":"code","a7d23c8a":"code","618951be":"code","5720465d":"code","7a1067aa":"code","34da613c":"code","0425149c":"code","a05c88b6":"code","406606f4":"code","412105ce":"code","96f945d8":"code","6521a5e2":"code","4edde54a":"code","f0408cbf":"code","05759f2c":"code","6c5b5be2":"code","c2763d29":"code","1c86075a":"code","ae7e5d78":"code","8325585e":"code","b27aff4f":"code","08ddd8e8":"code","3cbe012c":"code","8ddde5db":"code","6a106ec2":"code","9914798f":"code","1bd42d12":"code","f0e45ebc":"code","d950197a":"code","cf93eb2f":"code","7cc6a3ae":"markdown","84097859":"markdown","9ed1159a":"markdown","e7db6e66":"markdown","6179b5af":"markdown","d1675359":"markdown","b1282cff":"markdown","8e1a4079":"markdown","03dedfc7":"markdown","93794c54":"markdown","346b092c":"markdown","cf613e70":"markdown","7cdc753a":"markdown","977b83b6":"markdown","f630aea8":"markdown","2e17d243":"markdown","a735f590":"markdown","5ca5ba97":"markdown","67b77d40":"markdown","8a417745":"markdown","37754afa":"markdown","d4104005":"markdown","04062ab4":"markdown","30412136":"markdown","46601020":"markdown","09116be3":"markdown","dabf7721":"markdown","b6a5bbb0":"markdown"},"source":{"9443c681":"import torch\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","ee8d0a93":"DATASET_URL = \"https:\/\/hub.jovian.ml\/wp-content\/uploads\/2020\/05\/insurance.csv\"\nDATA_FILENAME = \"insurance.csv\"\ndownload_url(DATASET_URL, '.')","86843d8b":"dataframe_raw = pd.read_csv(DATA_FILENAME)\ndataframe_raw.head()","5ca10750":"your_name = \"Vighnesh\" # at least 5 characters","de2d651f":"def customize_dataset(dataframe_raw, rand_str):\n    dataframe = dataframe_raw.copy(deep=True)\n    # drop some rows\n    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n    # scale input\n    dataframe.bmi = dataframe.bmi * ord(rand_str[1])\/100.\n    # scale target\n    dataframe.charges = dataframe.charges * ord(rand_str[2])\/100.\n    # drop column\n    if ord(rand_str[3]) % 2 == 1:\n        dataframe = dataframe.drop(['region'], axis=1)\n    return dataframe","2fe27a97":"dataframe = customize_dataset(dataframe_raw, your_name)\ndataframe.head()","4edea009":"num_rows = len(dataframe)\nprint(num_rows)","b778886f":"num_cols = len(dataframe.columns)\nprint(num_cols)","8fd305dd":"input_cols = list(dataframe.drop('charges',axis=1).columns)\ninput_cols","b59194a6":"categorical_cols = list(dataframe.select_dtypes(include='object').columns)\ncategorical_cols","70622169":"output_cols = [dataframe.columns[-1]]\noutput_cols","b9be54d6":"# Write your answer here\nimport numpy as np\n# min_charge = np.min(dataframe.charges)\nmin_charge = dataframe.charges.min()\nprint(\"Minimum charge = \",min_charge)\n# max_charge = np.max(dataframe.charges)\nmax_charge = dataframe.charges.max()\nprint(\"Maximum charge = \",max_charge)\n# avg_charge = np.mean(dataframe.charges)\navg_charge = dataframe.charges.mean()\nprint(\"Average charge = \",avg_charge)","e8b4b2eb":"# Plotting the distribution of 'charges' column\nimport seaborn as sns\nfig, axs = plt.subplots(ncols=2)\nsns.set_style(\"darkgrid\")\nplt.rcParams['font.size'] = 14\nplt.rcParams['figure.figsize'] = (9, 5)\n#plt.title(\"Distribution of charges\")\nsns.distplot(dataframe.charges, ax=axs[0]) # Skewed data\nsns.distplot(np.log(dataframe.charges),ax=axs[1]) # Trying to make data normal using log transformation","09c8e075":"def dataframe_to_arrays(dataframe):\n    # Make a copy of the original dataframe\n    dataframe1 = dataframe.copy(deep=True)\n    # Convert non-numeric categorical columns to numbers\n    for col in categorical_cols:\n        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n    # Extract input & outupts as numpy arrays\n    #inputs_array = np.array(dataframe1[input_cols])\n    inputs_array = dataframe1.drop('charges',axis=1).values\n    #targets_array = np.array(dataframe1[output_cols])\n    targets_array = dataframe1[['charges']].values\n    return inputs_array, targets_array","a7d23c8a":"inputs_array, targets_array = dataframe_to_arrays(dataframe)\nprint(inputs_array.shape, targets_array.shape)\ninputs_array, targets_array","618951be":"inputs = torch.from_numpy(inputs_array).to(torch.float32)\ntargets = torch.from_numpy(targets_array).to(torch.float32)","5720465d":"inputs.dtype, targets.dtype","7a1067aa":"print(inputs,targets)","34da613c":"dataset = TensorDataset(inputs, targets)","0425149c":"val_percent = 0.1 # between 0.1 and 0.2\nval_size = int(num_rows * val_percent)\nprint(val_size)\ntrain_size = num_rows - val_size\nprint(train_size)\n\ntrain_ds, val_ds = random_split(dataset,[train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length","a05c88b6":"print(len(train_ds))\nprint(len(val_ds))","406606f4":"batch_size = 64 # Try to experiment with different batch sizes","412105ce":"train_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)","96f945d8":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","6521a5e2":"input_size = len(input_cols)\nprint(input_size)\noutput_size = len(output_cols)\nprint(output_size)","4edde54a":"class InsuranceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size,output_size) \n        \n    def forward(self, xb):\n        out = self.linear(xb)                          \n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out, targets)                \n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out, targets)                    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 500 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","f0408cbf":"model = InsuranceModel()","05759f2c":"list(model.parameters())","6c5b5be2":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","c2763d29":"result = evaluate(model, val_loader) # Use the the evaluate function\nprint(result)","1c86075a":"# model = InsuranceModel() # In case of re-initialization","ae7e5d78":"epochs = 1000\nlr = 0.001\nhistory1 = fit(epochs, lr, model, train_loader, val_loader)","8325585e":"epochs = 1500\nlr = 0.05\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","b27aff4f":"epochs = 2000\nlr = 0.1\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","08ddd8e8":"epochs = 2500\nlr = 0.4\nhistory4 = fit(epochs, lr, model, train_loader, val_loader)","3cbe012c":"epochs = 3000\nlr = 0.8\nhistory5 = fit(epochs, lr, model, train_loader, val_loader)","8ddde5db":"val_loss = history5[-1]\nval_loss","6a106ec2":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0)\n    predictions = model(inputs)               \n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","9914798f":"input, target = val_ds[0]\npredict_single(input, target, model)","1bd42d12":"input, target = val_ds[10]\npredict_single(input, target, model)","f0e45ebc":"input, target = val_ds[13]\npredict_single(input, target, model)","d950197a":"input, target = val_ds[54]\npredict_single(input, target, model)","cf93eb2f":"input, target = val_ds[87]\npredict_single(input, target, model)","7cc6a3ae":"Read through the [Pandas documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/categorical.html) to understand how we're converting categorical variables into numbers.","84097859":"To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https:\/\/data36.com\/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection\/","9ed1159a":"## Step 2: Prepare the dataset for training\n\nWe need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays.","e7db6e66":"Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`.","6179b5af":"\nWe are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible.","d1675359":"**Q: What are the column titles of output\/target variable(s)?**","b1282cff":"**Q: What is the final validation loss of your model?**","8e1a4079":"## Step 3: Create a Linear Regression Model\n\nOur model itself is a fairly straightforward linear regression.","03dedfc7":"Finally, we can create data loaders for training & validation.\n\n**Q: Pick a batch size for the data loader.**","93794c54":"**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**","346b092c":"Let's look at a batch of data to verify everything is working fine so far.","cf613e70":"## Step 1: Download and explore the data\n\nLet us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. ","7cdc753a":"**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**","977b83b6":"Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc.","f630aea8":"# Insurance cost prediction using linear regression\n\nIn this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https:\/\/www.kaggle.com\/mirichoi0218\/insurance\n\nWe will create a model with the following steps:\n1. Download and explore the dataset\n2. Prepare the dataset for training\n3. Create a linear regression model\n4. Train the model to fit the data\n5. Make predictions using the trained model\n\nTry to experiment with the hypeparameters to get the lowest loss.\n","2e17d243":"**Q: What are the column titles of the input variables?**","a735f590":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`.","5ca5ba97":"## Step 5: Make predictions using the trained model","67b77d40":"**Q: How many columns doe the dataset have**","8a417745":"Let us answer some basic questions about the dataset. \n\n\n**Q: How many rows does the dataset have?**","37754afa":"We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. We will fill a name below as a string (at least 5 characters)","d4104005":"The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers.","04062ab4":"**Q: Which of the input columns are non-numeric or categorial variables ?**\n\nHint: `sex` is one of them. List the columns that are not numbers.","30412136":"## Step 4: Train the model to fit the data\n\nTo train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem.","46601020":"Let's check out the weights and biases of the model using `model.parameters`.","09116be3":"**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n\nHint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works.","dabf7721":"***Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. ***","b6a5bbb0":"Are you happy with your model's predictions? Try to improve them further."}}