{"cell_type":{"044f682b":"code","d208b89c":"code","ba3e3787":"code","6dfa4b68":"code","8a597400":"code","c8c622d0":"code","8fbb6f15":"code","64a2ff0b":"code","e97e170e":"code","969ca43e":"code","c9cc4a0e":"code","0cb0c16e":"code","8f33a33c":"code","d761c7ba":"code","844dcda2":"markdown","1de609b8":"markdown","13415b93":"markdown","07c00d67":"markdown","595da12d":"markdown","90a5006e":"markdown"},"source":{"044f682b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d208b89c":"from tensorflow.keras.applications import Xception \nfrom tensorflow.keras.applications import imagenet_utils\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2","ba3e3787":"# In the InceptionV3 or Xception networks, then we\n# need to set the input shape to (299x299) [rather than (224x224)]\n# and use a different image pre-processing function\n\ninputShape = (299, 299)\npreprocess = preprocess_input\n\n# load our the network weights from disk (NOTE: if this is the\nprint(\"[INFO] loading Xception...\")\nmodel = Xception(weights=\"imagenet\") # Note: On the Internet in the notebook setting to download the weights","6dfa4b68":"\nfilename = \"..\/input\/prediction-image-for-imagenettensorflow2\/parachute_complete.png\" # input image path\nimg = plt.imread(filename)\nplt.imshow(img)","8a597400":"# load the input image using the Keras helper utility while ensuring\n# the image is resized to `inputShape`, the required input dimensions\n# for the ImageNet pre-trained network\nprint(\"[INFO] loading and pre-processing image...\")\nimage = load_img(filename, target_size=inputShape) # read image\nimage = img_to_array(image)","c8c622d0":"# our input image is now represented as a NumPy array of shape\n# (inputShape[0], inputShape[1], 3) however we need to expand the\n# dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n# so we can pass it through the network\nimage = np.expand_dims(image, axis=0)\n# pre-process the image using the appropriate function based on the\n# model that has been loaded (i.e., mean subtraction, scaling, etc.)\nimage = preprocess(image)","8fbb6f15":"# classify the image\nprint(\"[INFO] classifying image with 'Xception'...\")\npreds = model.predict(image)\nP = imagenet_utils.decode_predictions(preds)\n# loop over the predictions and display the rank-5 predictions +\n# probabilities to our terminal\nfor (i, (imagenetID, label, prob)) in enumerate(P[0]):\n\tprint(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))\n","64a2ff0b":"# load the image via OpenCV, draw the top prediction on the image,\n# and display the image to our screen\norig = cv2.imread(filename)\norig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n(imagenetID, label, prob) = P[0][0]\ncv2.putText(orig, \"Label: {}, {:.2f}%\".format(label, prob * 100),\n\t(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\nplt.imshow(orig)","e97e170e":"from tensorflow.keras.applications import ResNet50 \n","969ca43e":"inputShape = (224, 224)\npreprocess = preprocess_input\n","c9cc4a0e":"# load our the network weights from disk (NOTE: if this is the\nprint(\"[INFO] loading Resnet50...\")\nmodel_resnet = ResNet50(weights=\"imagenet\")","0cb0c16e":"# load the input image using the Keras helper utility while ensuring\n# the image is resized to `inputShape`, the required input dimensions\n# for the ImageNet pre-trained network\nprint(\"[INFO] loading and pre-processing image...\")\nimage = load_img(filename, target_size=inputShape) # read image\nimage = img_to_array(image)\n# our input image is now represented as a NumPy array of shape\n# (inputShape[0], inputShape[1], 3) however we need to expand the\n# dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n# so we can pass it through the network\nimage = np.expand_dims(image, axis=0)\n# pre-process the image using the appropriate function based on the\n# model that has been loaded (i.e., mean subtraction, scaling, etc.)\nimage = preprocess(image)","8f33a33c":"# classify the image\nprint(\"[INFO] classifying image with 'Resnet60'...\")\npreds = model_resnet.predict(image)\nP = imagenet_utils.decode_predictions(preds)\n# loop over the predictions and display the rank-5 predictions +\n# probabilities to our terminal\nfor (i, (imagenetID, label, prob)) in enumerate(P[0]):\n\tprint(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))","d761c7ba":"# load the image via OpenCV, draw the top prediction on the image,\n# and display the image to our screen\norig = cv2.imread(filename)\norig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n(imagenetID, label, prob) = P[0][0]\ncv2.putText(orig, \"Label: {}, {:.2f}%\".format(label, prob * 100),\n\t(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\nplt.imshow(orig)","844dcda2":"### This is the notebook on how to use Tensorflow2 pretrained Imagenet Model and use It for classification.","1de609b8":"## Note: Make Sure Internet is On in Kaggle Notebook Setting before Using It.","13415b93":"**If it helps you. Please upvote and share to others**","07c00d67":"### You can also try with InceptionV3 Resnet50, VGG1\n* Xception, InceptionV3 takes input shape (229, 229)\n* Resnet50, VGG19 takes input shape (224, 224)\n* Xception has more accuracy compare to others\n\n### Below is the example of Resnet50\nOnly difference is in the Preprocess Input","595da12d":"### See the prediction of both architecture; You find Xception is doing well compare to others in Imagenet","90a5006e":"# Image Classification with Xception\nXception is proposed by [Franchis Chollet](http:\/\/https:\/\/twitter.com\/fchollet). Xception is an extension of the Inception architecture which replaces the standard Inception modules with depthwise separable convolutions.The original publication, Xception: Deep Learning with Depthwise Separable Convolutions can be found [here](https:\/\/arxiv.org\/abs\/1610.02357)\n![](https:\/\/cdn-images-1.medium.com\/freeze\/max\/1000\/1*hOcAEj9QzqgBXcwUzmEvSg.png?q=20).\n"}}