{"cell_type":{"cfb4071a":"code","d545c818":"code","aa4e4b49":"code","3772ef22":"code","7b5656ff":"code","e7b4012a":"code","09ca391e":"code","67009c91":"code","987bd2ea":"code","21c5744b":"code","32aef7a0":"code","b9263714":"code","756b8d13":"code","628fac25":"code","119d870d":"code","2d41aad2":"code","a9b89613":"code","ee1d6012":"code","3ff8b1b9":"code","5922a9d8":"code","54a476d3":"code","985ac32f":"code","3d5a629b":"code","edc34eaf":"code","06c38380":"code","b7917c35":"code","ec27e212":"code","f6751c4d":"code","740d93c4":"code","c2079adf":"code","c04d3a7f":"code","0dc8c2a3":"code","3ecf5c16":"code","5033d4dc":"code","e5b366c6":"code","f9f83f2e":"code","a8c88d66":"code","5da38a9f":"code","5bed07f2":"code","72c72974":"code","00a50c38":"code","e03e6bca":"code","6d2a99df":"code","535d91e0":"code","0991c342":"code","7c13be32":"code","8dd33e3d":"code","bf0ccb06":"code","ad32e09b":"code","0e4183e3":"code","00bb5246":"code","97325c96":"markdown","a5bdde32":"markdown","f5388a63":"markdown","79c4f818":"markdown","578beaf9":"markdown","0f7b7aae":"markdown","db32d273":"markdown","d228abae":"markdown","43f283dc":"markdown","a2396f3d":"markdown"},"source":{"cfb4071a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d545c818":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport itertools\nimport fnmatch\nimport random\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport cv2\nfrom scipy.misc import imresize, imread\nimport sklearn\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport keras\nfrom keras import backend as K\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, model_from_json\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n%matplotlib inline","aa4e4b49":"from os import listdir","3772ef22":"listdir('..\/input\/IDC_regular_ps50_idx5')[:10]","7b5656ff":"listdir('..\/input\/IDC_regular_ps50_idx5\/10285')","e7b4012a":"listdir('..\/input\/IDC_regular_ps50_idx5\/9036')","09ca391e":"imagePatches = glob('..\/input\/IDC_regular_ps50_idx5\/**\/*.png', recursive=True)\nfor filename in imagePatches[0:10]:\n    print(filename)","67009c91":"image = cv2.imread('..\/input\/IDC_regular_ps50_idx5\/10285\/1\/10285_idx5_x1151_y901_class1.png')","987bd2ea":"plt.figure(figsize=(16,16))\nplt.imshow(image)","21c5744b":"plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))","32aef7a0":"# Plot Multiple Images\nbunchOfImages = imagePatches\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in bunchOfImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (50, 50)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","b9263714":"def randomImages(a):\n    r = random.sample(a, 4)\n    plt.figure(figsize=(16,16))\n    plt.subplot(131)\n    plt.imshow(cv2.imread(r[0]))\n    plt.subplot(132)\n    plt.imshow(cv2.imread(r[1]))\n    plt.subplot(133)\n    plt.imshow(cv2.imread(r[2])); \nrandomImages(imagePatches)","756b8d13":"patternZero = '*class0.png'\npatternOne = '*class1.png'\nclassZero = fnmatch.filter(imagePatches, patternZero)\nclassOne = fnmatch.filter(imagePatches, patternOne)\nprint(\"IDC(-)\\n\\n\",classZero[0:5],'\\n')\nprint(\"IDC(+)\\n\\n\",classOne[0:5])","628fac25":"def proc_images(lowerIndex,upperIndex):\n    \"\"\"\n    Returns two arrays: \n        x is an array of resized images\n        y is an array of labels\n    \"\"\" \n    x = []\n    y = []\n    WIDTH = 50\n    HEIGHT = 50\n    for img in imagePatches[lowerIndex:upperIndex]:\n        full_size_image = cv2.imread(img)\n        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n        if img in classZero:\n            y.append(0)\n        elif img in classOne:\n            y.append(1)\n        else:\n            return\n    return x,y\n","119d870d":"X,Y = proc_images(0,90000)","2d41aad2":"X1 = np.array(X)","a9b89613":"X1.shape","ee1d6012":"df = pd.DataFrame()\ndf[\"images\"]=X\ndf[\"labels\"]=Y","3ff8b1b9":"X2=df[\"images\"]\nY2=df[\"labels\"]","5922a9d8":"type(X2)","54a476d3":"X2=np.array(X2)","985ac32f":"X2.shape","3d5a629b":"imgs0=[]\nimgs1=[]\nimgs0 = X2[Y2==0] # (0 = no IDC, 1 = IDC)\nimgs1 = X2[Y2==1] ","edc34eaf":"def describeData(a,b):\n    print('Total number of images: {}'.format(len(a)))\n    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))\n    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))\n    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))\n    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\ndescribeData(X2,Y2)","06c38380":"X=np.array(X)\nX=X\/255.0\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)","b7917c35":"del X","ec27e212":"del X1,X2","f6751c4d":"del Y2","740d93c4":"del imgs0,imgs1","c2079adf":"import gc\ngc.collect()","c04d3a7f":"X_train.shape","0dc8c2a3":"X_test.shape","3ecf5c16":"dist = df['labels'].value_counts()","5033d4dc":"dist","e5b366c6":"sns.countplot(df['labels'])","f9f83f2e":"del df\ngc.collect()","a8c88d66":"# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(Y_train, num_classes = 2)\ny_testHot = to_categorical(Y_test, num_classes = 2)","5da38a9f":"# Helper Functions  Learning Curves and Confusion Matrix\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/accuracy_curve.png')\n    #plt.clf()\n    # summarize history for loss\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/loss_curve.png')","5bed07f2":"batch_size = 128\nnum_classes = 2\nepochs = 8\nimg_rows,img_cols=50,50\ninput_shape = (img_rows, img_cols, 3)\ne = 2","72c72974":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape,strides=e))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])","00a50c38":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images","e03e6bca":"a = X_train\nb = y_trainHot\nc = X_test\nd = y_testHot\nepochs = 10","6d2a99df":"history = model.fit_generator(datagen.flow(a,b, batch_size=32),\n                        steps_per_epoch=len(a) \/ 32, \n                              epochs=epochs,validation_data = [c, d],\n                              callbacks = [MetricsCheckpoint('logs')])","535d91e0":"y_pred = model.predict(c)","0991c342":"Y_pred_classes = np.argmax(y_pred,axis=1) \nY_true = np.argmax(d,axis=1)","7c13be32":"dict_characters = {0: 'IDC(-)', 1: 'IDC(+)'}","8dd33e3d":"confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nplot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \nplt.show()","bf0ccb06":"plotKerasLearningCurve()\nplt.show()  ","ad32e09b":"plot_learning_curve(history)\nplt.show()","0e4183e3":"del model","00bb5246":"gc.collect()","97325c96":"# Acknowledgements","a5bdde32":"## One Hot encoding","f5388a63":"## Distribution of Labels","79c4f818":"**Paul Mooney** and **Kevin Mader** kernels","578beaf9":"# Step 1 : Import Modules","0f7b7aae":"# Preprocess data","db32d273":"# Step Two : Explore Data","d228abae":"## Train and Test Set","43f283dc":"1. # Helper Functions","a2396f3d":"# Step Two: Plot Data"}}