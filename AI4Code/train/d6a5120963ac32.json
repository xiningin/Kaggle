{"cell_type":{"ca25a1a6":"code","14a8ee88":"code","dd32e312":"code","5fb85f1c":"code","6378b54b":"code","1b4baf9b":"code","d7ffd2dc":"code","26c887bd":"code","636b628e":"code","cbbfc388":"code","e1084798":"code","99e0e45b":"code","2f583d26":"code","ab7d53d5":"code","ff1a188f":"code","e743782f":"code","cda6178c":"code","f34033e4":"code","c50994ff":"code","3fc1329b":"code","7745dd17":"code","7f2d8824":"code","787f7c38":"code","4d1d3eca":"code","810df73b":"code","4359d015":"code","ab284b83":"code","5bd01fcd":"code","3fc3daca":"code","2bf878e4":"markdown","47d84e64":"markdown","f0469614":"markdown","93708176":"markdown","6174446f":"markdown","4a27ab4a":"markdown","f949ef22":"markdown","6f3e2074":"markdown","d2fa5a31":"markdown","513fd51b":"markdown","736c5f67":"markdown","518162a7":"markdown","fcd08698":"markdown","f88f2e8a":"markdown","dae1a2b0":"markdown","78f855a8":"markdown","243249e7":"markdown","f4771d68":"markdown","4521abb1":"markdown","ec1fc94b":"markdown","17a77fa0":"markdown","4e349834":"markdown","7f8810e4":"markdown","921a9d92":"markdown"},"source":{"ca25a1a6":"%load_ext memory_profiler\n!pip install -q zhconv","14a8ee88":"import os \n\n# Packages\nimport gensim\nimport jieba\nimport zhconv\nfrom gensim.corpora import WikiCorpus\nfrom datetime import datetime as dt\nfrom typing import List\n\n\nif not os.path.isfile('dict.txt.big'):\n    !wget https:\/\/github.com\/fxsjy\/jieba\/raw\/master\/extra_dict\/dict.txt.big\njieba.set_dictionary('dict.txt.big')\n\nprint(\"gensim\", gensim.__version__)\nprint(\"jieba\", jieba.__version__)","dd32e312":"ZhWiki = \"\/kaggle\/input\/zhwiki-20210101\/zhwiki-20210101-pages-articles.xml.bz2\"\n\n!du -sh $ZhWiki\n!md5sum $ZhWiki\n!file $ZhWiki","5fb85f1c":"zhconv.convert(\"\u8fd9\u539f\u672c\u662f\u4e00\u6bb5\u7b80\u4f53\u4e2d\u6587\", \"zh-tw\")","6378b54b":"seg_list = jieba.cut(\"\u6211\u6765\u5230\u5317\u4eac\u6e05\u534e\u5927\u5b66\", cut_all=True)\nprint(\"Full Mode: \" + \"\/ \".join(seg_list))  # \u5168\u6a21\u5f0f\n\nseg_list = jieba.cut(\"\u6211\u6765\u5230\u5317\u4eac\u6e05\u534e\u5927\u5b66\", cut_all=False)\nprint(\"Default Mode: \" + \"\/ \".join(seg_list))  # \u7cbe\u78ba\u6a21\u5f0f","1b4baf9b":"print(list(jieba.cut(\"\u4e2d\u82f1\u593e\u96dc\u7684example\uff0cWord2Vec\u61c9\u8a72\u5f88interesting\u5427?\")))","d7ffd2dc":"import spacy\n\n# \u4e0b\u8f09\u8a9e\u8a00\u6a21\u7d44\nspacy.cli.download(\"zh_core_web_sm\")  # \u4e0b\u8f09 spacy \u4e2d\u6587\u6a21\u7d44\nspacy.cli.download(\"en_core_web_sm\")  # \u4e0b\u8f09 spacy \u82f1\u6587\u6a21\u7d44\n\nnlp_zh = spacy.load(\"zh_core_web_sm\") # \u8f09\u5165 spacy \u4e2d\u6587\u6a21\u7d44\nnlp_en = spacy.load(\"en_core_web_sm\") # \u8f09\u5165 spacy \u82f1\u6587\u6a21\u7d44\n\n# \u5370\u51fa\u524d20\u500b\u505c\u7528\u8a5e\nprint('--\\n')\nprint(f\"\u4e2d\u6587\u505c\u7528\u8a5e Total={len(nlp_zh.Defaults.stop_words)}: {list(nlp_zh.Defaults.stop_words)[:20]} ...\")\nprint(\"--\")\nprint(f\"\u82f1\u6587\u505c\u7528\u8a5e Total={len(nlp_en.Defaults.stop_words)}: {list(nlp_en.Defaults.stop_words)[:20]} ...\")","26c887bd":"STOPWORDS =  nlp_zh.Defaults.stop_words | \\\n             nlp_en.Defaults.stop_words | \\\n             set([\"\\n\", \"\\r\\n\", \"\\t\", \" \", \"\"])\nprint(len(STOPWORDS))\n\n# \u5c07\u7c21\u9ad4\u505c\u7528\u8a5e\u8f49\u6210\u7e41\u9ad4\uff0c\u64f4\u5145\u505c\u7528\u8a5e\u8868\nfor word in STOPWORDS.copy():\n    STOPWORDS.add(zhconv.convert(word, \"zh-tw\"))\n    \nprint(len(STOPWORDS))","636b628e":"def preprocess_and_tokenize(\n    text: str, token_min_len: int=1, token_max_len: int=15, lower: bool=True) -> List[str]:\n    if lower:\n        text  = text.lower()\n    text = zhconv.convert(text, \"zh-tw\")\n    return [\n        token for token in jieba.cut(text, cut_all=False)\n        if token_min_len <= len(token) <= token_max_len and \\\n            token not in STOPWORDS\n    ]\n","cbbfc388":"print(preprocess_and_tokenize(\"\u6b50\u5e7e\u91cc\u5f97\uff0c\u897f\u5143\u524d\u4e09\u4e16\u7d00\u7684\u53e4\u5e0c\u81d8\u6578\u5b78\u5bb6\uff0c\u73fe\u5728\u88ab\u8a8d\u70ba\u662f\u5e7e\u4f55\u4e4b\u7236\uff0c\u6b64\u756b\u70ba\u62c9\u6590\u723e\"))\nprint(preprocess_and_tokenize(\"\u6211\u6765\u5230\u5317\u4eac\u6e05\u534e\u5927\u5b66\"))\nprint(preprocess_and_tokenize(\"\u4e2d\u82f1\u593e\u96dc\u7684example\uff0cWord2Vec\u61c9\u8a72\u5f88interesting\u5427?\"))","e1084798":"%%time\n%%memit\n\nprint(f\"Parsing {ZhWiki}...\")\nwiki_corpus = WikiCorpus(ZhWiki, tokenizer_func=preprocess_and_tokenize, token_min_len=1)","99e0e45b":"g = wiki_corpus.get_texts()\nprint(next(g)[:10])\nprint(next(g)[:10])\nprint(next(g)[:10])\n\n\n# print(jieba.lcut(\"\".join(next(g))[:50]))\n# print(jieba.lcut(\"\".join(next(g))[:50]))\n","2f583d26":"WIKI_SEG_TXT = \"wiki_seg.txt\"\n\ngenerator = wiki_corpus.get_texts()\n\nwith open(WIKI_SEG_TXT, \"w\", encoding='utf-8') as output:\n    for texts_num, tokens in enumerate(generator):\n        output.write(\" \".join(tokens) + \"\\n\")\n\n        if (texts_num + 1) % 100000 == 0:\n            print(f\"[{str(dt.now()):.19}] \u5df2\u5beb\u5165 {texts_num} \u7bc7\u65b7\u8a5e\u6587\u7ae0\")","ab7d53d5":"%%time\n\nfrom gensim.models import word2vec\nimport multiprocessing\n\nmax_cpu_counts = multiprocessing.cpu_count()\nword_dim_size = 300  #  \u8a2d\u5b9a word vector \u7dad\u5ea6\nprint(f\"Use {max_cpu_counts} workers to train Word2Vec (dim={word_dim_size})\")\n\n\n# \u8b80\u53d6\u8a13\u7df4\u8a9e\u53e5\nsentences = word2vec.LineSentence(WIKI_SEG_TXT)\n\n# \u8a13\u7df4\u6a21\u578b\nmodel = word2vec.Word2Vec(sentences, size=word_dim_size, workers=max_cpu_counts)\n\n# \u5132\u5b58\u6a21\u578b\noutput_model = f\"word2vec.zh.{word_dim_size}.model\"\nmodel.save(output_model)","ff1a188f":"! ls word2vec.zh*","e743782f":"!du -sh word2vec.zh*","cda6178c":"print(model.wv.vectors.shape)\nmodel.wv.vectors","f34033e4":"print(f\"\u7e3d\u5171\u6536\u9304\u4e86 {len(model.wv.vocab)} \u500b\u8a5e\u5f59\")\n\nprint(\"\u5370\u51fa 20 \u500b\u6536\u9304\u8a5e\u5f59:\")\nprint(list(model.wv.vocab.keys())[:10])","c50994ff":"vec = model.wv['\u6578\u5b78\u5bb6']\nprint(vec.shape)\nvec ","3fc1329b":"word = \"\u9019\u80af\u5b9a\u6c92\u898b\u904e \"\n\n# \u82e5\u5f37\u884c\u53d6\u503c\u6703\u5831\u932f\ntry:\n    vec = model.wv[word]\nexcept KeyError as e:\n    print(e)","7745dd17":"model.wv.most_similar(\"\u98f2\u6599\", topn=10)","7f2d8824":"model.wv.most_similar(\"car\")","787f7c38":"model.wv.most_similar(\"facebook\")","4d1d3eca":"model.wv.most_similar(\"\u8a50\u6b3a\")","810df73b":"model.wv.most_similar(\"\u5408\u7d04\")","4359d015":"model.wv.similarity(\"\u9023\u7d50\", \"\u9375\u63a5\")","ab284b83":"model.wv.similarity(\"\u9023\u7d50\", \"\u9670\u5929\")","5bd01fcd":"print(f\"Loading {output_model}...\")\nnew_model = word2vec.Word2Vec.load(output_model)","3fc3daca":"model.wv.similarity(\"\u9023\u7d50\", \"\u9670\u5929\") == new_model.wv.similarity(\"\u9023\u7d50\", \"\u9670\u5929\")","2bf878e4":"## \u7c21\u7e41\u8f49\u63db\n\nwiki \u6587\u672c\u5176\u5be6\u647b\u96dc\u4e86\u7c21\u9ad4\u8207\u7e41\u9ad4\u4e2d\u6587\uff0c\u6bd4\u5982\u300c\u6570\u5b66\u300d\u8207\u300c\u6578\u5b78\u300d\uff0c\u9019\u6703\u88ab word2vec \u7576\u6210\u5169\u500b\u4e0d\u540c\u7684\u8a5e\u3002[[1]](http:\/\/zake7749.github.io\/2016\/08\/28\/word2vec-with-gensim\/)\n<br>\n\u6240\u4ee5\u6211\u5011\u5728\u65b7\u8a5e\u524d\uff0c\u9700\u8981\u52a0\u4e0a\u7c21\u7e41\u8f49\u63db\u7684\u624b\u7e8c\n\n---\n\n\u4ee5\u4e0b\u7bc4\u4f8b\u4f7f\u7528\u4e86\u8f03\u8f15\u91cf\u7684 Package [zhconv](https:\/\/pypi.org\/project\/zhconv\/)\uff0c\n<br>\n\u82e5\u9700\u8981\u66f4\u9ad8\u7684\u7cbe\u6e96\u5ea6\uff0c\u5247\u53ef\u4ee5\u53c3\u8003  [OpenCC](https:\/\/github.com\/BYVoid\/OpenCC)","47d84e64":"# \u6e96\u5099\u4e2d\u6587\u8a13\u7df4\u6587\u672c\n","f0469614":" # \u67e5\u770b\u6a21\u578b\u4ee5\u53ca\u8a5e\u5411\u91cf\u5be6\u9a57","93708176":"# \u4e2d\u6587\u6587\u672c\u524d\u8655\u7406\n\n\u5728\u6b63\u5f0f\u8a13\u7df4 `Word2Vec` \u4e4b\u524d\uff0c\u5176\u5be6\u6d89\u53ca\u4e86\u6587\u672c\u7684\u524d\u8655\u7406\uff0c\u672c\u7bc7\u7684\u8655\u7406\u5305\u62ec\u5982\u4e0b\u4e09\u9ede (\u800c\u5be6\u52d9\u4e0a\u5c0d\u61c9\u7684\u4e0d\u540c\u4f7f\u7528\u60c5\u5883\uff0c\u53ef\u80fd\u6703\u6709\u4e0d\u540c\u7684\u524d\u8655\u7406\u6d41\u7a0b):\n\n* \u7c21\u8f49\u7e41: [zhconv](https:\/\/pypi.org\/project\/zhconv\/)\n* \u4e2d\u6587\u65b7\u8a5e: [jieba](https:\/\/pypi.org\/project\/jieba\/)\n* \u505c\u7528\u8a5e","6174446f":" # \u8b80\u53d6\u6a21\u578b","4a27ab4a":"## \u5f15\u5165\u505c\u7528\u8a5e\u8868\n\n\u505c\u7528\u8a5e\u5c31\u662f\u50cf\u82f1\u6587\u4e2d\u7684 **the,a,this**\uff0c\u4e2d\u6587\u7684**\u4f60\u6211\u4ed6**\uff0c\u8207\u5176\u4ed6\u8a5e\u76f8\u6bd4\u986f\u5f97\u4e0d\u600e\u9ebc\u91cd\u8981\uff0c\u5c0d\u6587\u7ae0\u4e3b\u984c\u4e5f\u7121\u95dc\u7dca\u8981\u7684\uff0c\n<br>\n\u662f\u5426\u8981\u4f7f\u7528\u505c\u7528\u8a5e\u8868\uff0c\u5176\u5be6\u9084\u662f\u8981\u770b\u4f60\u7684\u61c9\u7528\uff0c\u4e5f\u6709\u53ef\u80fd\u4fdd\u7559\u9019\u4e9b\u505c\u7528\u8a5e\u66f4\u80fd\u9054\u5230\u4f60\u7684\u76ee\u6a19\u3002[[1]](http:\/\/zake7749.github.io\/2016\/08\/28\/word2vec-with-gensim\/)\n<br>\n\n\n* [Is it compulsory to remove stop words with word2vec?](https:\/\/www.quora.com\/Is-it-compulsory-to-remove-stop-words-with-word2vec)\n* [The Effect of Stopword Filtering prior to Word Embedding Training](https:\/\/stats.stackexchange.com\/questions\/201372\/the-effect-of-stopword-filtering-prior-to-word-embedding-training)\n\n---\n\n\u4ee5\u4e0b\u7bc4\u4f8b\u9084\u662f\u793a\u7bc4\u5f15\u5165\u505c\u7528\u8a5e\u8868\uff0c\u800c\u505c\u7528\u8a5e\u8868\u7db2\u8def\u4e0a\u6709\u5404\u7a2e\u5404\u6a23\u7684\u8cc7\u6e90\n<br>\n\u525b\u597d `kaggle`\uff0c\u74b0\u5883\u9810\u8a2d\u6709\u88dd [spacy](https:\/\/pypi.org\/project\/spacy\/)\uff0c\n<br>\n\u5c31\u9806\u9053\u5f15\u7528 `spacy` \u63d0\u4f9b\u7684\u505c\u7528\u8a5e\u8868\u5427 (\u5be6\u52d9\u4e0astopwords \u61c9\u70ba\u53e6\u5916\u6e96\u5099\u597d\u4e14\u6aa2\u8996\u904e\u7684\u975c\u614b\u6587\u6a94)","f949ef22":"\n## \u8a13\u7df4\u6587\u672c\u4f86\u6e90: [\u7dad\u57fa\u767e\u79d1\u8cc7\u6599\u5eab](https:\/\/zh.wikipedia.org\/wiki\/Wikipedia:%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8B%E8%BD%BD)\n> \u8981\u8a13\u7df4\u8a5e\u5411\u91cf\uff0c\u7b2c\u4e00\u6b65\u7576\u7136\u662f\u53d6\u5f97\u8cc7\u6599\u96c6\u3002\u7531\u65bc word2vec \u662f\u57fa\u65bc\u975e\u76e3\u7763\u5f0f\u5b78\u7fd2\uff0c**\u8a13\u7df4\u96c6\u4e00\u5b9a\u4e00\u5b9a\u8981\u8d8a\u5927\u8d8a\u597d\uff0c\u8a9e\u6599\u6db5\u84cb\u7684\u8d8a\u5168\u9762\uff0c\u8a13\u7df4\u51fa\u4f86\u7684\u7d50\u679c\u4e5f\u6703\u8d8a\u6f02\u4eae**\u3002[[1]](http:\/\/zake7749.github.io\/2016\/08\/28\/word2vec-with-gensim\/)\n\n- [zhwiki-20210101-pages-articles.xml.bz2](https:\/\/dumps.wikimedia.org\/zhwiki\/20210101\/zhwiki-20210101-pages-articles.xml.bz2) (1.9 GB)\n\n> ```\nwget \"https:\/\/dumps.wikimedia.org\/zhwiki\/20210101\/zhwiki-20210101-pages-articles.xml.bz2\"\n```\n\n","6f3e2074":"`model.wv.most_similar` \u7684 `topn` \u9810\u8a2d\u70ba 10","d2fa5a31":"# \u8a13\u7df4 Word2Vec","513fd51b":"## \u4e2d\u6587\u65b7\u8a5e\n\u4f7f\u7528 [jieba](https:\/\/pypi.org\/project\/jieba\/) `jieba.cut` \u4f86\u9032\u884c\u4e2d\u6587\u65b7\u8a5e\uff0c\n<br>\n\u4e26\u7c21\u55ae\u4ecb\u7d39 jieba \u7684\u5169\u7a2e\u5206\u8a5e\u6a21\u5f0f:\n* `cut_all=False` **\u7cbe\u78ba\u6a21\u5f0f**\uff0c\u8a66\u5716\u5c07\u53e5\u5b50\u6700\u7cbe\u78ba\u5730\u5207\u958b\uff0c\u9069\u5408\u6587\u672c\u5206\u6790\uff1b\n* `cut_all=True` **\u5168\u6a21\u5f0f**\uff0c\u628a\u53e5\u5b50\u4e2d\u6240\u6709\u7684\u53ef\u4ee5\u6210\u8a5e\u7684\u8a5e\u8a9e\u90fd\u6383\u63cf\u51fa\u4f86, \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u4f46\u662f\u4e0d\u80fd\u89e3\u6c7a\u6b67\u7fa9\uff1b\n\n\u800c\u672c\u7bc7\u6587\u672c\u8a13\u7df4\u63a1\u7528**\u7cbe\u78ba\u6a21\u5f0f** `cut_all=False`","736c5f67":"## \u8a08\u7b97 Cosine \u76f8\u4f3c\u5ea6","518162a7":"\u6536\u9304\u7684\u8a5e\u5f59","fcd08698":"# \u8b80\u53d6 wiki \u8a9e\u6599\u5eab\uff0c\u4e26\u4e14\u9032\u884c\u524d\u8655\u7406\u548c\u65b7\u8a5e\n\n\u7dad\u57fa\u767e\u79d1 (`wiki.xml.bz2`)\u4e0b\u8f09\u597d\u5f8c\uff0c\u5148\u5225\u6025\u8457\u89e3\u58d3\u7e2e\uff0c\u56e0\u70ba\u9019\u662f\u4e00\u4efd xml \u6587\u4ef6\uff0c\u88cf\u982d\u4f48\u6eff\u4e86\u5404\u5f0f\u5404\u6a23\u7684\u6a19\u7c64\uff0c\u6211\u5011\u5f97\u5148\u60f3\u8fa6\u6cd5\u9001\u8d70\u9019\u7fa4\u4e0d\u901f\u4e4b\u5ba2\uff0c\u4e0d\u904e\u4e5f\u5225\u592a\u64d4\u5fc3\uff0c`gensim` \u65e9\u5df2\u770b\u7a7f\u4e86\u4e00\u5207\uff0c\u85c9\u7531\u8abf\u7528 [wikiCorpus](https:\/\/radimrehurek.com\/gensim\/corpora\/wikicorpus.html)\uff0c\u6211\u5011\u80fd\u5f88\u8f15\u9b06\u7684\u53ea\u53d6\u51fa\u6587\u7ae0\u7684\u6a19\u984c\u548c\u5167\u5bb9\u3002[[1]](http:\/\/zake7749.github.io\/2016\/08\/28\/word2vec-with-gensim\/)\n\n![image.png](attachment:image.png)\n\n [[2]](https:\/\/radimrehurek.com\/gensim\/corpora\/wikicorpus.html)\n\n---\n\nSupported dump formats:\n\n- `<LANG>wiki-<YYYYMMDD>-pages-articles.xml.bz2`\n\n- `<LANG>wiki-latest-pages-articles.xml.bz2`\n\nThe documents are extracted on-the-fly, so that the whole (massive) dump can stay compressed on disk.\n","f88f2e8a":"\u5132\u5b58\u7684\u6a21\u578b\u7e3d\u5171\u6703\u7522\u751f\u4e09\u4efd\u6a94\u6848","dae1a2b0":"# Word2Vec-\u4ee5 gensim \u8a13\u7df4\u4e2d\u6587\u8a5e\u5411\u91cf\n## \u53c3\u8003\u53ca\u5f15\u7528\u8cc7\u6599\u4f86\u6e90\n\n- [1] [zake7749-\u4f7f\u7528 gensim \u8a13\u7df4\u4e2d\u6587\u8a5e\u5411\u91cf](http:\/\/zake7749.github.io\/2016\/08\/28\/word2vec-with-gensim\/)\n* [2] [gensim\/corpora\/wikicorpus](https:\/\/radimrehurek.com\/gensim\/corpora\/wikicorpus.html)\n- [Word2Vec\u7684\u7c21\u6613\u6559\u5b78\u8207\u53c3\u6578\u8abf\u6574\u6307\u5357](https:\/\/www.kaggle.com\/jerrykuo7727\/word2vec)\n* [zhconv](https:\/\/pypi.org\/project\/zhconv\/)\n* [jieba](https:\/\/pypi.org\/project\/jieba\/)\n\n\n\n","78f855a8":"\u8a5e\u5f59\u7684\u5411\u91cf","243249e7":"\u76ee\u524d\u5df2\u7d93\u4f7f\u7528\u53e6\u4e00\u4efd Notebook ([\u7dad\u57fa\u767e\u79d1\u4e2d\u6587\u8a9e\u6599\u5eab zhWiki_20210101](https:\/\/www.kaggle.com\/bbqlp33\/zhwiki-20210101)) \u4e0b\u8f09\u597d\u4e2d\u6587\u7dad\u57fa\u767e\u79d1\u8a9e\u6599\uff0c\u4e26\u53ef\u4ee5\u76f4\u63a5\u5f15\u7528","f4771d68":"## \u5c07\u8655\u7406\u5b8c\u7684\u8a9e\u6599\u96c6\u5b58\u4e0b\u4f86\uff0c\u4f9b\u5f8c\u7e8c\u4f7f\u7528","4521abb1":"\u79c0\u51fa\u524d 3 \u504f\u6587\u7ae0\u7684\u524d10 \u500b token","ec1fc94b":"\u78ba\u8a8d\u76f8\u95dc Packages","17a77fa0":"\u6a21\u578b\u5176\u5be6\u5c31\u662f\u5de8\u5927\u7684 Embedding Matrix\n","4e349834":"\u6c92\u898b\u904e\u7684\u8a5e\u5f59","7f8810e4":"\u521d\u59cb\u5316`WikiCorpus`\u5f8c\uff0c\u80fd\u85c9\u7531`get_texts()`\u53ef\u8fed\u4ee3\u6bcf\u4e00\u7bc7\u6587\u7ae0\uff0c\u5b83\u6240\u56de\u50b3\u7684\u662f\u4e00\u500b`tokens list`\uff0c\u6211\u4ee5\u7a7a\u767d\u7b26\u5c07\u9019\u4e9b `tokens` \u4e32\u63a5\u8d77\u4f86\uff0c\u7d71\u4e00\u8f38\u51fa\u5230\u540c\u4e00\u4efd\u6587\u5b57\u6a94\u88e1\u3002\u9019\u908a\u8981\u6ce8\u610f\u4e00\u4ef6\u4e8b\uff0c`get_texts()`\u53d7 `article_min_tokens` \u53c3\u6578\u7684\u9650\u5236\uff0c\u53ea\u6703\u56de\u50b3\u5167\u5bb9\u9577\u5ea6\u5927\u65bc **50** (default) \u7684\u6587\u7ae0\u3002\n\n- **article_min_tokens** *(int, optional)* \u2013 Minimum tokens in article. Article will be ignored if number of tokens is less.","921a9d92":"## \u67e5\u770b\u524d 10 \u540d\u76f8\u4f3c\u8a5e"}}