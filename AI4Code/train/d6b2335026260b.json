{"cell_type":{"f44dab7a":"code","27f25ce2":"code","206c4e87":"code","894c22a2":"code","3b41e9dc":"code","e15c9f24":"code","cb2e7159":"code","53cf3048":"code","b5710667":"code","b3c639e0":"code","6e5976b9":"code","29f0eef8":"code","38e999e8":"code","5567241b":"code","54b9b7a8":"code","3c9adcbc":"code","563808b4":"code","15c602d7":"code","5a56202b":"code","160363c5":"code","2b036fee":"code","527f93ff":"code","04927af9":"code","e8ed2e95":"code","2a21606e":"code","a25bff04":"code","a58ef3ce":"code","054c237b":"code","09d4e3ad":"code","04468b5d":"code","4197f627":"code","25f276da":"code","24ff1c4e":"code","347d3d4a":"code","21829165":"code","3c61f7d1":"code","a73062eb":"code","b3318a7c":"code","32076f0f":"code","ff6af824":"code","e1d036a7":"code","1dd6dd5c":"code","bfb549b7":"code","8e0add98":"code","d5dab74c":"code","3332986d":"code","836bdefe":"code","648308e7":"code","00d0be1d":"markdown","e3f3925b":"markdown","b825c543":"markdown","d1247d60":"markdown","01519bf1":"markdown","1fa0406c":"markdown","c57329c3":"markdown","d2fdb58c":"markdown","d42dce81":"markdown","79dad18c":"markdown","7008b590":"markdown","a60375e4":"markdown","9bff21da":"markdown","843c04cf":"markdown","8102ca52":"markdown","7e4d3f22":"markdown","c512a1c0":"markdown"},"source":{"f44dab7a":"# Importamos las librerias\nimport numpy as np\nimport pandas as pd\nimport datetime","27f25ce2":"# Cargamos el dataset desde un fichero local. Nota: Antes de su carga, se examin\u00f3 el archivo y se identificaron, columnas cuyos datos eran fechas. \n# Estas columnas las importamos como tipo datetime usando el argumento parse_dates. \n# Las columnas c_jail_in & c_jail_out, al llevar un formato distinto, las pasaremos a formato datetime a posteriori.\ncompas_raw=pd.read_csv('..\/input\/compas-scores\/compas-scores.csv', parse_dates=['compas_screening_date', 'dob', 'c_offense_date', 'c_arrest_date', 'r_offense_date', 'r_jail_in', 'r_jail_out', 'vr_offense_date'])\ncompas_raw","206c4e87":"compas_raw['c_jail_in']= pd.to_datetime(compas_raw['c_jail_in'])\ncompas_raw['c_jail_out']= pd.to_datetime(compas_raw['c_jail_out'])","894c22a2":"# Vemos de la funcion .info que no disponemos de ninguna columna de tipo \"category\" y dado que hay campos como \"sexo\" o \"raza\", este tipo de objeto es m\u00e1s conveniente.\n# Procederemos a identificar que columnas deberiamos transformar en tipo \"category\".\ncompas_raw.nunique()","3b41e9dc":"# Identificamos las columnas con un bajo n\u00famero de valores \u00fanicos y comprobamos sus valores \u00fanicos.\nfor col in ['sex', 'age_cat', 'race', 'c_charge_degree', 'is_recid', 'r_charge_degree', 'is_violent_recid', 'v_score_text', 'score_text']:\n    print(compas_raw[col].unique())","e15c9f24":"for col in ['sex', 'age_cat', 'race', 'c_charge_degree', 'is_recid', 'r_charge_degree', 'is_violent_recid', 'v_score_text', 'score_text']:\n    compas_raw[col] = compas_raw[col].astype('category')","cb2e7159":"# Ahora que las columnas estan guardadas en los formatos m\u00e1s pertinentes para su estudio, \ncompas_raw.describe(include = 'category')","53cf3048":"compas_raw.describe(include = 'object')","b5710667":"compas_raw.describe(include = np.number)","b3c639e0":"# Tras hacer esta exploraci\u00f3n inicial, a continuaci\u00f3n se empezar\u00e1 a explorar las dimensiones de la calidad de los datos.\n\n# Vemos que hay nombres que se repiten, por lo que necesitamos saber si hay un error o si son personas distintas. \ncompas_raw[compas_raw.name.duplicated(keep = False)]","6e5976b9":"#Viendo que hay 328 nombres (incl. nombre y apellido) comprobamos el m\u00e1s recurrente prar verificar si es la misma persona.\ncompas_raw.loc[compas_raw['name'] == 'michael cunningham']","29f0eef8":"# Se puede concluir de la comprobaci\u00f3n anterior que las personas que comparten nombre no son la misma persona. Esto tiene sentido ya que no se haria un registro nuevo en COMPAS sino\n# que se consideraria el evento una reincidencia.","38e999e8":"# Para tratar de entender un poco mejor el dataframe, identificaremos las filas con valores nulos\ncompas_raw.isnull().sum()","5567241b":"''' Vemos que existen campos nulos\/vacios en los d\u00edas anteriores al arresto inicial. Esta cantidad coincide con la cantidad de las fechas de ingreso en prisi\u00f3n y salida.\nEs posible que esto se deba a que hay personas que no han cometido un crimen desde el inicio del sistema COMPAS.\n'''\ncomprension = compas_raw[['compas_screening_date', 'juv_fel_count', 'priors_count', 'c_jail_in', 'is_recid', 'r_offense_date', 'is_violent_recid', 'vr_offense_date']]\ncomprension.head()","54b9b7a8":"'''En esta exploraci\u00f3n algo llamativo fue encontrar 3 valores \u00fanicos del campo \"is_recid\".\nTiene sentido que este campo sea binario. Es decir, deber\u00eda indicar si reincidi\u00f3 o no. \nEsto puede deberse a un problema con la integridad de los datos, pero esto se explorar\u00e1 m\u00e1s adelante.'''\n\n# Se procede a continuaci\u00f3n con la exploraci\u00f3n de la actualidad de los datos. \n\n# Como se describe en el enunciado no sabemos a partir de que fecha ya no se recogen datos de reincidencias, arrestos iniciales etc.\n# Tampoco se sabe cuando se empez\u00f3 a usar el sistema COMPAS.\nprint(\"Primeras fechas:\")\nprint(comprension[['compas_screening_date', 'c_jail_in', 'r_offense_date', 'vr_offense_date']].min())\nprint(\"\\n\")\nprint(\"Ultimas fechas:\")\nprint(comprension[['compas_screening_date', 'c_jail_in', 'r_offense_date', 'vr_offense_date']].max())","3c9adcbc":"comprension['is_recid'].unique()","563808b4":"negativeR= comprension.loc[comprension['is_recid'] == -1]\nnegativeR","15c602d7":"comprension.loc[comprension['is_recid'] == 0]","5a56202b":"comprension.loc[comprension['is_recid'] == 1]","160363c5":"# Antes de establecer nuestas conclusiones hacemos una \u00fatlima comprobaci\u00f3n de los casos cuyo valor de \"is_recid\" es -1 .\nfor col in ['juv_fel_count', 'priors_count', 'c_jail_in', 'r_offense_date', 'is_violent_recid', 'vr_offense_date']:\n    print(negativeR[col].unique())","2b036fee":"# Se comprueba el caso no nulo de la columna \"c_jail_in\"...\nnegativeR[negativeR['c_jail_in'].notnull()]","527f93ff":"compas_raw.loc[compas_raw['id']==7428]","04927af9":"'''Dado que se ha establecido que aquellos registros cuyo valor \"is_recid\" = -1 suponen un problema de integridad de los datos, estos se van a eliminar del dataframe\npara proceder con la evaluaci\u00f3n de las variables'''\ndf=compas_raw[(compas_raw['is_recid'] !=-1)&(compas_raw['decile_score'] !=-1)]","e8ed2e95":"# Primero necesitamos determinar desde que fecha se debe de considerar el inicio del periodo.\ndf[['c_offense_date', 'c_arrest_date', 'c_charge_desc']]","2a21606e":"# Entendemos por estos datos que para tener una \"fecha de inicio\" debemos de combinar las dos columnas. \n# Nota: c_arrest_date se cumplimenta en el caso de no haber cargos imputados.\ndf2=df.copy()\ndf2['c_offense_date'] = df2['c_offense_date'].astype(str)\ndf2['c_arrest_date'] = df2['c_arrest_date'].astype(str)\ndf2['start_date']=(df2.c_offense_date+df2.c_arrest_date)\ndf2['start_date'] = df2['start_date'].map(lambda x: x.lstrip('NaT').rstrip('NaT'))\ndf2['start_date']=pd.to_datetime(df2.start_date)","a25bff04":"# Tambi\u00e9n establecemos el periodo a considerarse mediante una columna auxiliar denominada \"end_date\". Esta la podremos fijar en funci\u00f3n de d\u00edas.\nfrom datetime import timedelta\ndef set_timeframe (timeframe_in_days):\n    df2['end_date']=df2['start_date']+timedelta(days=timeframe_in_days)\n    print(df2[['start_date','end_date']])","a58ef3ce":"# Para determinar un periodo de tiempo a considerar, creamos una columna que incluir\u00e1 el tiempo hasta la reincidencia.\ndf2['time_until_recid']=df2['r_offense_date']-df2['start_date']","054c237b":"# Calculamos la media de dias que tardaron en reincidir para cada decile score.\nfor score in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n    print('Tiempo Medio de reincidencia de decile_score=',score,(df2[(df2.time_until_recid!='NaT')&(df2.decile_score==score)]['time_until_recid']).mean())","09d4e3ad":"# Viendo que el tiempo medio excede en la mayoria de los casos excede los 300 d\u00edas, escogeremos para nuestro intervalo de tiempo, 365 d\u00edas (un a\u00f1o completo).\nset_timeframe (timeframe_in_days=365)\n# Nuestra funci\u00f3n establece los valores de la columna end_date y nos devuelve una comprobaci\u00f3n:","04468b5d":"# Se ve que la \u00faltima fecha de reincidencia es posterior a la fecha tope a considerar: \"end_date\"\ndf2[['start_date','end_date', 'r_offense_date']].max()","4197f627":"'''Se crea un dataframe alternativo en el que se ha aplicado un filtro de los datos para que solamente aparezcan aquellos casos que reincidieron durante \nel periodo o aquellos casos que no reinicdieron'''\n\ntimeframe_df=df2[(df2['r_offense_date']<df2['end_date'])|(df2['r_offense_date'].isnull())]","25f276da":"# Se ve ahora que la \u00faltima reincidencia registrada ya no es posterior a la fecha tope.\ntimeframe_df[['start_date','end_date', 'r_offense_date']].max()","24ff1c4e":"for score in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n    print('el n\u00famero de decile_score=',score,'es',len(timeframe_df[timeframe_df['decile_score'] == score]), 'de los que', len(timeframe_df[(timeframe_df.is_recid == 1) & (timeframe_df.decile_score == score)]),', un',(((len(timeframe_df[(timeframe_df.is_recid == 1) & (timeframe_df.decile_score == score)]))\/(len(timeframe_df[timeframe_df['decile_score'] == score])))*100),'%  reincidieron en menos de un a\u00f1o.')","347d3d4a":"df2['recid_within_timeframe']=np.where(df2['r_offense_date']<df2['end_date'],'YES','NO')\ndf2['violent_recid_within_timeframe']=np.where(df2['vr_offense_date']<df2['end_date'],'YES','NO')\ndf2[['recid_within_timeframe', 'violent_recid_within_timeframe']]","21829165":"# Para que el an\u00e1lisis sea correcto, se debe continuar usando los datos de reincidencia dentro de un periodo de tiempo espec\u00edfico.\ndf2['contingencia_recid']=np.where(df2['decile_score']>=7,'YES','NO')","3c61f7d1":"# Se comprueba que la columna creada asigna el valor 1 a todos aquellos casos cuyo decile score es >=7.\ndf2[['decile_score','contingencia_recid']]","a73062eb":"# Creamos la tabla de contingencia.\ntabla_contingencia = pd.crosstab(df2.contingencia_recid, df2.recid_within_timeframe)\ntabla_contingencia","b3318a7c":"import altair as alt\nalt.data_transformers.disable_max_rows()","32076f0f":"# Se elimina la columna 'time_until_recid' ya que se encontr\u00f3 que generaba problemas a la hora de la creaci\u00f3n de las tablas debido a su formato.\ndf3=df2.copy()\ndf3.drop('time_until_recid', inplace=True, axis=1)","ff6af824":"df_compare_race=df3.copy()\ndf_compare_race=df_compare_race[(df_compare_race['race']=='Caucasian')|(df_compare_race['race']=='African-American')]","e1d036a7":"# Dado que el boxplot estandar de Altair no muestra la media sino la mediana, se ha tenido que crear el boxplot de manera manual.\ndecile_by_sex = alt.LayerChart(data=df3).transform_aggregate(\n    min=\"min(decile_score)\",\n    max=\"max(decile_score)\",\n    mean=\"mean(decile_score)\",\n    q1=\"q1(decile_score)\",\n    median=\"median(decile_score)\",\n    q3=\"q3(decile_score)\",\n    groupby=['sex']\n).encode(\n    x='sex:N',\n    tooltip=['min:Q', 'q1:Q', 'median:Q','mean:Q', 'q3:Q', 'max:Q']\n).add_layers(\n    alt.Chart().mark_rule().encode(y='min:Q', y2='max:Q'),\n    alt.Chart().mark_bar(width=30).encode(y='q1:Q', y2='q3:Q'),\n    alt.Chart().mark_tick(color='white', width=30).encode(y='median:Q'),\n).properties(\n    title='Distribution of decile_score by sex',\n    width=150\n)\n\ndecile_by_race = alt.LayerChart(data=df_compare_race).transform_aggregate(\n    min=\"min(decile_score)\",\n    max=\"max(decile_score)\",\n    mean=\"mean(decile_score)\",\n    q1=\"q1(decile_score)\",\n    median=\"median(decile_score)\",\n    q3=\"q3(decile_score)\",\n    groupby=['race']\n).encode(\n    x='race:N',\n    tooltip=['min:Q', 'q1:Q', 'median:Q','mean:Q', 'q3:Q', 'max:Q']\n).add_layers(\n    alt.Chart().mark_rule().encode(y='min:Q', y2='max:Q'),\n    alt.Chart().mark_bar(width=30).encode(y='q1:Q', y2='q3:Q'),\n    alt.Chart().mark_tick(color='white', width=30).encode(y='median:Q'),\n).properties(\n    title='Distribution of decile_score by race',\n    width=150\n)\nalt.hconcat(decile_by_sex, decile_by_race)","1dd6dd5c":"recid_race_chart=alt.Chart(df_compare_race, height = 200, width = 300).mark_bar().encode(\n    alt.X('recid_within_timeframe:N'),\n    y='count()',\n    column='race:N',\n).properties(\n    title='Count of recid by race'\n)\nrecid_sex_chart=alt.Chart(df3, height = 200, width = 300).mark_bar().encode(\n    alt.X('recid_within_timeframe:N'),\n    y='count()',\n    column='sex:N',\n).properties(\n    title='Count of recid by sex'\n)\nalt.vconcat(recid_race_chart, recid_sex_chart)","bfb549b7":"# Tras observar la relaci\u00f3n de estas variables con el \"decile_score\" y si han reincidido o no. A continuaci\u00f3n veremos como influye la edad en la reincidencia\n# y en el decile score. Esto lo veremos con el dataframe df que no conteine informaci\u00f3n de raza aislada.\ndesitribution_recid_age=alt.LayerChart(data=df3).transform_aggregate(\n    min=\"min(age)\",\n    max=\"max(age)\",\n    mean=\"mean(age)\",\n    q1=\"q1(age)\",\n    median=\"median(age)\",\n    q3=\"q3(age)\",\n    groupby=['recid_within_timeframe']\n).encode(\n    x='recid_within_timeframe:N',\n    tooltip=['min:Q', 'q1:Q', 'median:Q','mean:Q', 'q3:Q', 'max:Q']\n).add_layers(\n    alt.Chart().mark_rule().encode(y='min:Q', y2='max:Q'),\n    alt.Chart().mark_bar(width=30).encode(y='q1:Q', y2='q3:Q'),\n    alt.Chart().mark_tick(color='white', width=30).encode(y='median:Q'),\n).properties(\n    title='disitribution of age by recid',\n    width=150\n)\nage_by_sex=alt.LayerChart(data=df3).transform_aggregate(\n    min=\"min(age)\",\n    max=\"max(age)\",\n    mean=\"mean(age)\",\n    q1=\"q1(age)\",\n    median=\"median(age)\",\n    q3=\"q3(age)\",\n    groupby=['sex']\n).encode(\n    x='sex:N',\n    tooltip=['min:Q', 'q1:Q', 'median:Q','mean:Q', 'q3:Q', 'max:Q']\n).add_layers(\n    alt.Chart().mark_rule().encode(y='min:Q', y2='max:Q'),\n    alt.Chart().mark_bar(width=30).encode(y='q1:Q', y2='q3:Q'),\n    alt.Chart().mark_tick(color='white', width=30).encode(y='median:Q'),\n).properties(\n    title='Age by sex',\n    width=150\n)\nage_by_race=alt.LayerChart(data=df_compare_race).transform_aggregate(\n    min=\"min(age)\",\n    max=\"max(age)\",\n    mean=\"mean(age)\",\n    q1=\"q1(age)\",\n    median=\"median(age)\",\n    q3=\"q3(age)\",\n    groupby=['race']\n).encode(\n    x='race:N',\n    tooltip=['min:Q', 'q1:Q', 'median:Q','mean:Q', 'q3:Q', 'max:Q']\n).add_layers(\n    alt.Chart().mark_rule().encode(y='min:Q', y2='max:Q'),\n    alt.Chart().mark_bar(width=30).encode(y='q1:Q', y2='q3:Q'),\n    alt.Chart().mark_tick(color='white', width=30).encode(y='median:Q'),\n).properties(\n    title='Age by race',\n    width=150\n)\nalt.hconcat(desitribution_recid_age, age_by_sex,age_by_race)","8e0add98":"# Tambi\u00e9n es interesante viualizar el tipo de crimen cometido a la hora de registrar a la persona en el sistema, donde F es Felony y M es misdemeanor. \n# Es decir, F es m\u00e1s grave que M.\ncharge_type_recid= alt.Chart(df3, height = 200, width = 300).mark_bar().encode(\n    alt.X('c_charge_degree:N'),\n    y='count()',\n    column='recid_within_timeframe:N',\n).properties(\n    title='Counts of Charge type'\n)\n\ncharge_type_race=alt.Chart(df_compare_race, height = 200, width = 300).mark_bar().encode(\n    alt.X('c_charge_degree:N'),\n    y='count()',\n    column='race:N',\n).properties(\n    title='Charge type by race'\n)\ncharge_type_sex=alt.Chart(df3, height = 200, width = 300).mark_bar().encode(\n    alt.X('c_charge_degree:N'),\n    y='count()',\n    column='sex:N',\n).properties(\n    title='Counts of Charge type'\n)","d5dab74c":"# Se muestran por separado ya que al intentar concatenar las gr\u00e1ficas nos devolvia un error.\ncharge_type_recid","3332986d":"charge_type_race","836bdefe":"charge_type_sex","648308e7":"prediccion_generales=df3.groupby('decile_score')['recid_within_timeframe'].apply(lambda x: (x == 'YES').mean())\\\n.rename('porcentaje_reincidencias')\\\n.reset_index()\n\ngeneral_chart = alt.Chart(prediccion_generales, title = 'Porcentaje de reincidencias por decile score').mark_bar()\\\n                        .encode( x = alt.X('porcentaje_reincidencias:Q', axis=alt.Axis(format='.0%'), title='Porcentaje de reincidencias en un mismo periodo de tiempo'), y = alt.Y('decile_score:N', title = 'Decile Score'))\\\n                        .resolve_scale(y = 'independent')\n\nprediccion_violentos=df3.groupby('v_decile_score')['violent_recid_within_timeframe'].apply(lambda x: (x == 'YES').mean())\\\n.rename('porcentaje_reincidencias_violentas')\\\n.reset_index()\n\nviolent_chart=alt.Chart(prediccion_violentos, title = 'Porcentaje de reincidencias violentas por v_decile score').mark_bar()\\\n                        .encode( x = alt.X('porcentaje_reincidencias_violentas:Q', axis=alt.Axis(format='.0%'),title='Porcentaje de reincidencias violentas en un mismo periodo de tiempo'), y = alt.Y('v_decile_score:N', title = 'Violent decile Score'))\\\n                        .resolve_scale(y = 'independent')\nalt.hconcat(general_chart,violent_chart)","00d0be1d":"### Investigaci\u00f3n de la integridad de los datos.","e3f3925b":"### Investigaci\u00f3n de la actualidad de los datos.","b825c543":"### Investigaci\u00f3n sobre la validez de los datos","d1247d60":"En nuestro caso consideramos un caso \"positivo\" aquel en el que s\u00ed se ponen medidas de contingencia y s\u00ed reinciden en el periodo determinado (un total de 1031 casos). Por lo tanto los errores de tipo I (o falso positivo) son aquellos en los que contingencia_recid=\"YES\" pero recid_within_timeframe=\"NO\" (un total de 1930 casos). Los errores tipo II (o falso negativo)son aquellos en los que contingencia_recid=\"NO\" pero recid_within_timeframe=\"YES\" (un total de 1405 casos). De cara a temas de seguridad ciudadana, caso los errores tipo II son m\u00e1s serios.","01519bf1":"Tras hacer este an\u00e1lisis, se puede observar que las columnas is_recid e is_violent recid, por si solas no son adecuadas para evaluar la precisi\u00f3n de las estimaciones ya que no tienen en cuenta un tiempo homogeneizado. A continuaci\u00f3n se crea una feature que s\u00ed contemple un tiempo homogeneizado.","1fa0406c":"Se puede ver por los porcentajes de las dos gr\u00e1ficas que la capacidad predicitva de los delitos generales es mucho mayor que el de los delitos violentos. Dicho esto, se desconoce cual es el periodo de tiempo contemplado para las probilidades asignadas en las columnas decile_score y v_decile_score y tampoco los porcentajes de reincidencia esperadas relativos a cada puntuaci\u00f3n. Dado que esto se desconoce no se puede hacer una valoraci\u00f3n sobre c\u00f3mo de apropiados son los valores de decile_score y v_decile_score.","c57329c3":"\n# Cargar los datos y realizar un an\u00e1lisis exploratorio y una evaluaci\u00f3n de la calidad de los datos necesarios para el resto del caso.\n## Evaluar la integridad, validez y actualidad de los datos y proponer estrategias de mitigaci\u00f3n de los posibles problemas encontrados.","d2fdb58c":"En cuanto a la validez de los datos, no se ha detectado ning\u00fan error o falta en cuanto a esta dimensi\u00f3n.","d42dce81":"# \u00bfPara qu\u00e9 tipo de riesgos, el de delitos generales o el de delitos violentos, tiene el sistema m\u00e1s capacidad predictiva?","79dad18c":"De esta comprobaci\u00f3n se puede ver que se empezaron a registrar casos en el sistema COMPAS el 01 de Enero de 2013. Por otro lado, los \u00faltimos datos registrados y que tenemos a nuestra disposici\u00f3n son del 29 de Marzo de 2016.Teniendo esto en cuenta, sabemos que no disponemos de datos de reincidiencias posteriores a esta \u00faltima fecha.\n\nPor \u00faltimo, viendo la primera y \u00faltima fecha del compas_screening_date, podemos concluir que estos datos son los casos registrados en el sistema compas de los a\u00f1os 2013 y 2014, y es por esta raz\u00f3n que a\u00fanque este dataset se ha alimentado hasta el 29 de Marzo de 2016, no hay nuevos casos registrados en el sistema m\u00e1s all\u00e1 del a\u00f1o 2014.\n\nDe estos datos sabemos que la fecha de descarga de estos datos es posterior al 29 de Marzo de 2016.","7008b590":"# \u00bfSon los campos \u201cis_recid\u201d e \u201cis_violent_recid\u201d en este conjunto de datos adecuados para evaluar la precisi\u00f3n de las estimaciones de riesgo generadas por el sistema COMPAS? Si no es as\u00ed, definir y calcular una feature que s\u00ed lo sea.","a60375e4":"# El sistema asigna, de media, evaluaciones de riesgo m\u00e1s altas a los hombres que a las mujeres, y a las personas de raza afroamericana que a las de raza cauc\u00e1sica. Sin embargo, tambi\u00e9n las tasas de reincidencia son m\u00e1s altas para esos colectivos, aunque no est\u00e1 claro que la asignaci\u00f3n de riesgo sea \u201cjusta\u201d o no.\n\n## Mostrar estas diferencias mediante representaciones gr\u00e1ficas y utilizarlas para analizar si la asignaci\u00f3n de evaluaciones es justa o no. ","9bff21da":"La primera observaci\u00f3n que se puede hacer es que desconocemos el \u00e1mbito geogr\u00e1fico o las poblaciones objetos de este estudio, haciendo que cualquier observaci\u00f3n o predicci\u00f3n que se haga ser\u00e1 afectada por los sesgos que puede presentar este dataset ya que no se tendr\u00e1n en cuenta muchos de los detalles que pueden influir en los datos.\n\nDe todas maneras, se ha visto que el campo \"is_recid\" dispone de 3 valores \u00fanicos. Esta situaci\u00f3n se comprueba a continuaci\u00f3n. ","843c04cf":"Tras aislar el dataframe seg\u00fan los tres valores de la columna \"is_recid\" se puede concluir que el valor 1 representa aquellos casos que s\u00ed reinicidieron, donde is_violent_recid indica si ha sido una reincidencia por un acto violento. Por otro lado, el valor 0 representa aquellos casos en los que no hubo reincidencia, al menos hasta la la fecha del 29 de Marzo de 2016. Por \u00faltimo, el valor -1 representa los casos que s\u00ed est\u00e1n en el sistema COMPAS pero sin haber cometido un crimen registrado. El caso anterior (ID 7428) es posible que sea un error. Tambi\u00e9n es posible que simplemente no se disponen de los datos pertinentes del resto de los casos. A\u00fan as\u00ed, dado que aparitr de los datos aportados no se puede determinar, esto supone un problema en la integridad de los datos.","8102ca52":"Se puede concluir de estas visualizaciones que una mayor decile score para los colectivos 'Hombre' y 'raza afroamericana' puede estar justificada por dos razones:\nLa primera, vemos que las reincidencias se producen a edades m\u00e1s tempranas de una manera generalizada. Se ha visto que el porcentaje de casos de personas de raza afroamericana de menor edad es m\u00e1s alta en comparaci\u00f3n con aquellos de raza cauc\u00e1sica.\nLa segunda, un mayor procentaje de casos de clase F (felony) reinciden, y la proporci\u00f3n de estos casos respeto a aquellos de calse M (misdemeanor) es mayor en los subgrupos de 'hombres' y 'raza afroamericana'.","7e4d3f22":"# El umbral para establecer medidas preventivas de la reincidencia es de 7 en adelante.\n# Dado este umbral, generar una tabla de contingencia, explicando qu\u00e9 caso se considera como \u201cpositivo\u201d (y, por lo tanto, cu\u00e1les son los errores de tipo I y los errores de tipo II).","c512a1c0":"Como se ha identificado durante la investigaci\u00f3n sobre la actualidad de los datos, es muy posible que los datos que se tienen de las reincidencias no sea completa ya que un caso puede reincidir despu\u00e9s del 29 de Marzo de 2016. Por esta raz\u00f3n, para poder evaluar los datos se tienen que homogeneizar los datos en un periodo de tiempo determinado."}}