{"cell_type":{"ef0a3b09":"code","02ce7540":"code","99b48d5d":"code","19d266a3":"code","d1220f78":"code","0836a041":"code","a15cba84":"code","c20c25c1":"code","46855275":"markdown","97386a7b":"markdown","589ee116":"markdown","265358d0":"markdown","5eba7842":"markdown"},"source":{"ef0a3b09":"import pandas as pd, numpy as np","02ce7540":"# Get the data\ntrain_df=pd.read_csv('..\/input\/tweet-sentiment-extraction\/train.csv')\ntrain_df['text']=train_df['text'].str.lower().astype(str)\ntrain_df['selected_text']=train_df['selected_text'].str.lower().astype(str)","99b48d5d":"# Keys = Unsual\/Wrong words\n# Values = Fixed words\n\ntd = {\n    \"u\":\"you\",\n    \"ur\":\"you are\",\n    \"n\":\"and\",\n    \"aww\":\"cute\",\n    \"sooo\":\"so\",\n    \"r\":\"are\",\n    \"cuz\":\"because\",\n    \"til\":\"till\",\n    \"lil\":\",little\",\n    \"b\":\"be\",\n    \"ppl\":\"people\",\n    \"yay\":\"cheer\",\n    \"nite\":\"night\",\n    \"lmao\":\"haha\",\n    \"tho\":\"though\",\n    \"btw\":\"by the way\",\n    \"yr\":\"year\",\n    \"dm\":\"message\",\n    \"idk\":\"i do not know\",\n    \"outta\":\"out of\",\n    \"jus\":\"just\",\n    \"thru\":\"through\",\n    \"wtf\":\"what the fuck\",\n    \"wit\":\"with\",\n    \"gettin\":\"getting\",\n    \"dnt\":\"dont\",\n    \"mum\":\"mom\",\n    \"mums\":\"moms\",\n    \"hun\":\"honey\",\n    \"luv\":\"love\",\n    \"hrs\":\"hours\",\n    \"chillin\":\"chilling\",\n    \"abt\":\"about\",\n    \"tha\":\"that\",\n    \"ahh\":\"ah\",\n    \"feelin\":\"feeling\",\n\n    \"tho.\":\"though\",\n    \"w\/\":\"with\",\n    \"u?\":\"you?\",\n    \"s\":\"is\",\n\n    \":O\":\"suprized\",\n    \":p\":\"lol\",\n    \"(:\":\":)\",\n    \":S\":\":(\"\n}\n\ndef cleaning_function(string):\n    # Take tweet clean and return\n    \n    cleaned_words = []\n    for word in string.split():\n        word = td.get(word, word)\n        cleaned_words.append(word)\n    \n    return \" \".join(cleaned_words)","19d266a3":"import json\nwith open('..\/input\/englishengen-synonyms-json-thesaurus\/eng_synonyms.json') as json_file:  \n    synonyms_dict = json.load(json_file)\n\n\nprint(\"\\\/  EXAMPLES  \\\/ \")    \nprint(\"system   =\", synonyms_dict[\"system\"])\nprint(\"data     =\", synonyms_dict[\"data\"])    \nprint(\"weapon   =\", synonyms_dict[\"weapon\"])\nprint(\"i        =\", synonyms_dict[\"i\"])","d1220f78":"def synonym_function(text, selected_text):\n    words = text.split()\n    \n    if len(words) >= 5:  # Dont do anything on short texts\n        # Select three word\n        word1 = words[0]\n        word2 = words[2]\n        word3 = words[4]\n        \n        # Try to get synonymed words for selected words\n        synonymed_word1 = synonyms_dict.get(word1, [])\n        synonymed_word2 = synonyms_dict.get(word2, [])\n        synonymed_word3 = synonyms_dict.get(word3, [])\n        \n        # If synonymed words is empty changed it to original word\n        if synonymed_word1 == []:\n            synonymed_word1 = [word1]\n        if synonymed_word2 == []:\n            synonymed_word2 = [word2]\n        if synonymed_word3 == []:\n            synonymed_word3 = [word3]\n            \n    else:\n        return text, selected_text\n    \n    # There can be more than one synonym for any word so we have to select one\n    synonymed_word1 = synonymed_word1[0]\n    synonymed_word2 = synonymed_word2[len(synonymed_word2)\/\/2]\n    synonymed_word3 = synonymed_word3[-1]\n    \n    # Change text's words\n    changed_text = []\n    for word in text.split():\n        if word == word1:\n            word = synonymed_word1\n        elif word == word2:\n            word = synonymed_word2\n        elif word == word3:\n            word = synonymed_word3\n        changed_text.append(word)\n    \n    # Change selected_text's words\n    changed_selected_text = []\n    for word in selected_text.split():\n        if word == word1:\n            word = synonymed_word1\n        elif word == word2:\n            word = synonymed_word2\n        elif word == word3:\n            word = synonymed_word3\n        changed_selected_text.append(word)\n            \n    # Return text, selected_text\n    return \" \".join(changed_text), \" \".join(changed_selected_text)","0836a041":"text_ids = []\ntexts = []\nselected_texts = []\nsentiments = []\n\nfor i,row in train_df.iterrows():\n    text_id = \"007\"\n    text = row[\"text\"]\n    selected_text = row[\"selected_text\"]\n    sentiment = row[\"sentiment\"]\n    \n    text = cleaning_function(text)\n    selected_text = cleaning_function(selected_text)\n    \n    text, selected_text = synonym_function(text, selected_text)\n    \n    text_ids.append(text_id)\n    texts.append(text)\n    selected_texts.append(selected_text)\n    sentiments.append(sentiment)\n    \naugmented = {'textID': text_ids, 'text': texts, 'selected_text': selected_texts, 'sentiment': sentiments}\ntrain_df_aug = pd.DataFrame(data=augmented)\n\ntrain_df_aug","a15cba84":"pd.DataFrame(data={'Original': train_df[\"text\"], 'Augmentation': texts}).head(50)","c20c25c1":"train_df = train_df.append(train_df_aug)\ntrain_df.reset_index(inplace=True,drop=True)\n\ntrain_df","46855275":"### Operation\n\nIterate over train_df to create train_df_aug","97386a7b":"### Data Augmentation Part\n\nWe get Thesaurus synonym data to make data augmentation","589ee116":"We write a function that takes text and selected_text. Then it selects three words and tries to change them with their synonyms in text and selected_text. Lastly, return changed text and selected_text.\n\nNotes:\n\nWe do not use any Randomization. We only change three words in specific locations from the original data. Different strategies can be used.","265358d0":"### Cleaning Part\n\nWe use a dictionary to fix most used wrong written words.","5eba7842":"# Hello\n\nIn this notebook, we try to clean the most used wrong words and make some data augmentation with synonyms. Thesaurus synonyms data is helpful for this operation.\n\n...hope will usefull."}}