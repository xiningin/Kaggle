{"cell_type":{"634966f3":"code","1517da2c":"code","1f813f1c":"code","a5b9f008":"code","0f2f6d1d":"code","84830bd1":"code","d0c1b893":"code","4cc399bb":"code","056a01b5":"code","05af2409":"code","1ebdfa09":"code","d3656a0d":"code","4d902e12":"code","d21f9e4c":"code","6cb1a6f0":"code","c239962d":"code","a61fed18":"markdown","4bf90d4f":"markdown","3963916e":"markdown","928c1cce":"markdown","523e5f82":"markdown","64ffcf11":"markdown","5862511e":"markdown","85fc78c3":"markdown","094f62e1":"markdown","dd5135da":"markdown","a8cf8156":"markdown","961b549c":"markdown","150c6526":"markdown","15b4ff36":"markdown","327ad816":"markdown"},"source":{"634966f3":"import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# mlxtend library\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules","1517da2c":"raw_data = pd.read_csv('..\/input\/dataset.csv', header=None, sep='^')","1f813f1c":"raw_data.head(3)","a5b9f008":"max_col_count = max([row.count(',') for row in raw_data[0]])","0f2f6d1d":"raw_data = pd.read_csv('..\/input\/dataset.csv', header=None, names=list(range(max_col_count)))","84830bd1":"for col in raw_data.columns:\n    raw_data[col] = raw_data[col].str.strip()","d0c1b893":"raw_data.head(3)","4cc399bb":"def strip_date_text(s):\n    match = re.search(r'(\\d{1,2}\/\\d{1,2}\/\\d{4})([a-z \/-]+)', s)\n    date = datetime.strptime(match.groups()[0], '%d\/%m\/%Y').date()\n    return date, match.groups()[1]","056a01b5":"transac_data = pd.concat([pd.DataFrame(raw_data[0].apply(strip_date_text).tolist()), raw_data.iloc[:, 1:]], axis=1, ignore_index=True)","05af2409":"transac_data.head(3)","1ebdfa09":"dataset = [transac_data.loc[i].dropna()[1:-1].values for i in range(len(transac_data))]\nte = TransactionEncoder()\nte_ary = te.fit(dataset).transform(dataset)\ndf = pd.DataFrame(te_ary, columns=te.columns_)","d3656a0d":"df.head()","4d902e12":"frequent_itemsets = apriori(df, min_support=0.3, use_colnames=True)\nfrequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\nfrequent_itemsets","d21f9e4c":"rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\nrules","6cb1a6f0":"min_supports = np.linspace(0.1, 1, 50, endpoint=True)\nno_of_frequent_items = []\n\nfor min_support in min_supports:\n    no_of_frequent_items.append(apriori(df, min_support=min_support).shape[0])\n    \nplt.plot(min_supports, no_of_frequent_items)\nplt.xlabel('min_support')\nplt.ylabel('number of frequent itemsets')\nplt.title('min_support vs number of frequent itemsets')","c239962d":"min_supports = np.linspace(0.1, 1, 10, endpoint=True)\nno_of_frequent_items = {}\n\nplt.figure()\nax = plt.gca()\n\nfor min_support in min_supports:\n    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n    itemset_sizewise_count = frequent_itemsets.groupby(['length']).size().tolist()\n    print(itemset_sizewise_count)\n    ax.plot(list(range(1, len(itemset_sizewise_count) + 1)), itemset_sizewise_count,\n            label='min_support=' + str(min_support))\n    \nplt.legend()\nplt.xlabel('size of itemsets')\nplt.ylabel('number of frequent itemsets')","a61fed18":"## Frequent Itemset Detection","4bf90d4f":"## Setup","3963916e":"#### min_support vs number of frequent itemsets\n Lowering the support threshold often results in more itemsets being declared as frequent. This has an adverse effect on the computational complexity of the algorithm because more candidate itemsets must be generated and counted, as shown in Figure 6.13. The maximum size of frequent itemsets also tends to increase with lower support thresholds. As the maximum size of the frequent itemsets increases, the algorithm will need to make more passes over the data set","928c1cce":"Click this [link](https:\/\/www.kaggle.com\/fanatiks\/shopping-cart) for dataset.","523e5f82":"### Confidence Based Prunning\n\n<b>Theorem<\/b>\n If a rule `X -->  Y - X` doesnot satisfy the confidence threshold, then any rule `X --> Y - X` , where `X'`, is a subset of `X`, must not satisfy the confidence threshold as well\n \n <img src=\"https:\/\/lh5.googleusercontent.com\/8NUsgNjmz63ir2dVzmMDPqG2kmwdB-2ExB5iFEg0zmrF0JEi6NhoRUKz5TOg37cjJh4VVFUplgnBE3Eg0KON=w1921-h952-rw\">","64ffcf11":"Re-read the dataset, this time also with no header but with NaN for blank items. All this tediousness for making a Pandas dataframe.","5862511e":"## Rule Generation","85fc78c3":"Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. The apriori algorithm has been designed to operate on databases containing transactions, such as purchases by customers of a store. An itemset is considered as \"frequent\" if it meets a user-specified support threshold.\n\n<img src=\"https:\/\/lh4.googleusercontent.com\/qrCw_Zjn0GoAUp3e36A4_IeaPWZAviTDEw_DHbvGIWY4TeK3CByhj7mpxxzP4HHhxicjERISm7UYyA=w1921-h952-rw\">\n\n<b>Pseudo-code<\/b> for <b>`Apriori Algorithm`<\/b>\n<img src=\"https:\/\/lh5.googleusercontent.com\/Jb57K58UfPkp8_G_y0ALVL89CmT3D5pK7KeiZ-K-U5r3eyN839dUwoQhzjB08O-JNEWyPyKgEDwgmvVbtu0_=w1921-h952-rw\">","094f62e1":"Since the provided CSV file has variable length transaction and no header, first of all we need to find the maximum number items in a transaction. So read transaction in a single columns of dataframe and use commas`(,)` to count number of items in each transaction.","dd5135da":"Encodes database transaction data in form of a Python list of lists into a NumPy array.\n\nUser guide available [here](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/preprocessing\/TransactionEncoder\/)\n\n`dataset = [['Apple', 'Beer', 'Rice', 'Chicken'],\n           ['Apple', 'Beer', 'Rice'],\n           ['Apple', 'Beer'],\n           ['Apple', 'Bananas'],\n           ['Milk', 'Beer', 'Rice', 'Chicken'],\n           ['Milk', 'Beer', 'Rice'],\n           ['Milk', 'Beer'],\n           ['Apple', 'Bananas']]\n                ||\n                || Transactional Encoder form mlxtend\n                ||\n                \\\/\narray([[ True, False,  True,  True, False,  True],\n       [ True, False,  True, False, False,  True],\n       [ True, False,  True, False, False, False],\n       [ True,  True, False, False, False, False],\n       [False, False,  True,  True,  True,  True],\n       [False, False,  True, False,  True,  True],\n       [False, False,  True, False,  True, False],\n       [ True,  True, False, False, False, False]])`\n       \n       ","a8cf8156":"Since items in `csv` file are separated by `,_` strip each item","961b549c":"Look at the first column, It is a complete mess, who made this `CSV`??\n\nSeparate date and text from first column.","150c6526":"## Data Preprocessing","15b4ff36":"# Association Analysis on Kaggle Random Shopping Cart","327ad816":"## Analysis of Algorithm"}}