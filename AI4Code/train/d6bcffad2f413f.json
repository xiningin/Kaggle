{"cell_type":{"e90450d2":"code","8fa88e84":"code","085df86d":"code","79753f5e":"code","56743612":"code","209e27c1":"code","ab45099d":"code","31c5afbb":"code","d1935ba0":"code","6ebcd472":"code","6a5e759a":"code","f1824678":"code","f7a2e11a":"code","81a837e0":"code","ef348243":"code","b5011d29":"code","de014a42":"code","f3b7caf6":"code","9f634fb5":"code","c17d3a43":"code","ba6e4a52":"code","8a727ad7":"code","0d4447c0":"code","77f9e488":"code","577b35eb":"code","140602e5":"code","3712a237":"code","e2c181dc":"code","80c252f9":"code","ccb3f997":"code","56946c84":"code","8d68d1c2":"code","3c8260c3":"code","0d988599":"code","f4445833":"code","7e7ba566":"code","42d611bd":"code","1e0970ac":"markdown","5c956a6e":"markdown","d249581d":"markdown","9b99420f":"markdown","d7d7a93d":"markdown","65241944":"markdown","2a562851":"markdown","2e372dbc":"markdown","7ac9b1b2":"markdown","24757c94":"markdown","dfae64c1":"markdown","34497407":"markdown","789abe06":"markdown","690a9052":"markdown","27095e56":"markdown","b0467060":"markdown","a1129cbb":"markdown","db81ee9b":"markdown","a0b20c9f":"markdown","2439b72c":"markdown"},"source":{"e90450d2":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import f1_score\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [10, 10]","8fa88e84":"train = pd.read_csv( '..\/input\/liverpool-ion-switching\/train.csv' , dtype={'time':'str','signal':'float','open_channels':'int'} )\ntest  = pd.read_csv( '..\/input\/liverpool-ion-switching\/test.csv'  , dtype={'time':'str','signal':'float'} )\n\n# Split trainset in groups of 100k and 500k consecutive rows\ntrain['group']  = np.arange(train.shape[0])\/\/100_000\ntrain['group2'] = np.arange(train.shape[0])\/\/500_000\n\n# Split testset in groups of 100k consecutive rows\ntest['group']   = np.arange(test.shape[0])\/\/100_000","085df86d":"train.loc[ (train.group2==4)|(train.group2==9) ,'signal'] += np.exp(1)\ntest.loc[  ( test.group ==5)|( test.group ==7) ,'signal'] += np.exp(1)\n\ntrain['signal'] += np.exp(1)\ntrain['signal'] \/= 1.25\n\ntest['signal'] += np.exp(1)\ntest['signal'] \/= 1.25","79753f5e":"MAP = {0:'1A', 1:'1A', 2:'1B', 3:'3B', 4:'10B', 5:'5B', 6:'1B', 7:'3B', 8:'5B', 9:'10B'}\ntrain['type'] = train['group2'].map( MAP )\n\nMAP = {0:'3A', 1:'3B', 2:'5B', 3:'3A', 4:'1B', 5:'10B', 6:'5B', 7:'10B', 8:'3A', 9:'3B',10:'3A', 11:'3A', 12:'4A', 13:'3A', 14:'3A', 15:'3A', 16:'3A', 17:'3A', 18:'3A', 19:'3A'}\ntest['type'] = test['group'].map( MAP )","56743612":"for i in range(10):\n    train.loc[train.group2==i].signal.plot()","209e27c1":"for i in range(20):\n    test.loc[test.group==i].signal.plot()","ab45099d":"SINE_DRIFT = 4*np.sin(  2*np.pi*np.arange(500000)\/1000000 )\nplt.plot( SINE_DRIFT )","31c5afbb":"train.loc[ train.group2==6, 'signal' ] -= SINE_DRIFT\ntrain.loc[ train.group2==7, 'signal' ] -= SINE_DRIFT\ntrain.loc[ train.group2==8, 'signal' ] -= SINE_DRIFT\ntrain.loc[ train.group2==9, 'signal' ] -= SINE_DRIFT\n\ntrain.signal.iloc[ 500000:600000 ]-= SINE_DRIFT[:100000]\n\ntest.signal.iloc[ :100000 ]       -= SINE_DRIFT[:100000]\ntest.signal.iloc[ 100000:200000 ] -= SINE_DRIFT[:100000]\ntest.signal.iloc[ 400000:500000 ] -= SINE_DRIFT[:100000]\ntest.signal.iloc[ 600000:700000 ] -= SINE_DRIFT[:100000]\ntest.signal.iloc[ 700000:800000 ] -= SINE_DRIFT[:100000]\ntest.signal.iloc[ 800000:900000 ] -= SINE_DRIFT[:100000]\n\ntest.loc[ (test.group>=10)&(test.group<=14), 'signal' ] -= SINE_DRIFT","d1935ba0":"train.groupby(['group2','type'])['signal'].agg(['mean','std'])","6ebcd472":"for i in range(50):\n    train.loc[train.group==i].signal.plot()","6a5e759a":"for i in range(20):\n    test.loc[test.group==i].signal.plot()","f1824678":"train.loc[train.group==4].signal.plot()\n\ntrain['noise'] = train['signal'] - train['open_channels']\ntrain.loc[ (train.group==4)&(train.noise>1.0), 'signal' ] = np.random.normal( 0,0.2,1 ) #Just add gaussian noise with std 0.20\n\ntrain.loc[train.group==4].signal.plot()","f7a2e11a":"# Power line 50Hz interference is that small peak at axis 500 of the plot below\n# We used Fourier Transform to remove it precisely\nf = np.fft.fft( train.loc[train.group==45].signal )\nplt.plot( np.abs(f)[1:1000] )\nplt.plot([480, 480], [0, 8000], '--', lw=1)\nplt.plot([510, 510], [0, 8000], '--', lw=1)","81a837e0":"from scipy import fftpack\n\n# Removing 100% of power line interference can remove also usefull information that lies in the 50Hz spectrum.\n# Thats why we removed only 45% of powerline interference in order to keep some useful signal present in the 50Hz.\n# Remove 50Hz in batches of 100k rows.\n\nfor g in range( train.group.max() ):\n    f = np.fft.fft( train.loc[train.group==g].signal )\n    freq = np.abs( fftpack.fftfreq( len(f) , d=0.0001) )\n    f[ (freq >= 49.8)& (freq <= 50.2) ] = 0.55*f[ (freq >= 49.8)& (freq <= 50.2) ]\n    train.loc[train.group==g,'signal'] = np.fft.ifft( f ).real\n    \nfor g in range( test.group.max() ):\n    f = np.fft.fft( test.loc[test.group==g].signal )\n    freq = np.abs( fftpack.fftfreq( len(f) , d=0.0001) )\n    f[ (freq >= 49.8)& (freq <= 50.2) ] = 0.55*f[ (freq >= 49.8)& (freq <= 50.2) ]\n    test.loc[test.group==g,'signal'] = np.fft.ifft( f ).real\n    ","ef348243":"#Note that the 50Hz frequency interference was decreased but not removed 100%.\nf = np.fft.fft( train.loc[train.group==45].signal )\nplt.plot( np.abs(f)[1:1000] )\nplt.plot([480, 480], [0, 8000], '--', lw=1)\nplt.plot([510, 510], [0, 8000], '--', lw=1)","b5011d29":"# Calculate real noise in train set.\n# This is only possible because signal and open_channels are in the same scale\ntrain['noise']       = train['signal'] - train['open_channels']\n\n# Subtracting signal from round(signal) is a pseudo way to calculate noise that can be applied both to train and test sets.\ntrain['noise_round'] = train['signal'] - train['signal'].round()\ntest ['noise_round'] = test ['signal'] - test ['signal'].round()","de014a42":"#This is the bias offset and Standard deviation of the noise added to each group type.\ntrain.groupby(['group2','type'])['noise'].agg( ['mean','std'] )","f3b7caf6":"x = np.random.normal( 0, 0.231, 1000000) + np.random.normal( 0, 0.231, 1000000)\nnp.std(x)","9f634fb5":"train.groupby(['group2','type'])['noise_round'].agg( ['mean','std'] )","c17d3a43":"test.groupby(['group','type'])['noise_round'].agg( ['mean','std'] )","ba6e4a52":"train.loc[ train.group.isin([36,37,38]) ,'signal'].plot()","8a727ad7":"test.loc[ test.type=='3B'].plot( x='time' ,y='signal' )","0d4447c0":"print( train.loc[ train.group==35 ].groupby('open_channels')['noise'].agg(['mean','std']) )\nprint( train.loc[ train.group==39 ].groupby('open_channels')['noise'].agg(['mean','std']) )","77f9e488":"tmp = train.loc[ train.group==36 ].copy()\ntmp.loc[ tmp.open_channels==0 ,'signal'] = 0 + np.random.normal(  -0.0130 , 0.2342, np.sum(tmp.open_channels==0) )\ntmp.loc[ tmp.open_channels==1 ,'signal'] = 1 + np.random.normal(  -0.0299 , 0.2356, np.sum(tmp.open_channels==1) )\ntmp.loc[ tmp.open_channels==2 ,'signal'] = 2 + np.random.normal(  -0.0460 , 0.2368, np.sum(tmp.open_channels==2) )\ntmp.loc[ tmp.open_channels==3 ,'signal'] = 3 + np.random.normal(  -0.0600 , 0.2344, np.sum(tmp.open_channels==3) )\ntrain.loc[ train.group==36 ] = tmp.copy()\n\ntmp = train.loc[ train.group==37 ].copy()\ntmp.loc[ tmp.open_channels==0 ,'signal'] = 0 + np.random.normal(  -0.0110 , 0.2307, np.sum(tmp.open_channels==0) )\ntmp.loc[ tmp.open_channels==1 ,'signal'] = 1 + np.random.normal(  -0.0299 , 0.2309, np.sum(tmp.open_channels==1) )\ntmp.loc[ tmp.open_channels==2 ,'signal'] = 2 + np.random.normal(  -0.0450 , 0.2368, np.sum(tmp.open_channels==2) )\ntmp.loc[ tmp.open_channels==3 ,'signal'] = 3 + np.random.normal(  -0.0580 , 0.2295, np.sum(tmp.open_channels==3) )\ntrain.loc[ train.group==37 ] = tmp.copy()\n\ntmp = train.loc[ train.group==38 ].copy()\ntmp.loc[ tmp.open_channels==0 ,'signal'] = 0 + np.random.normal(  -0.0100 , 0.2257, np.sum(tmp.open_channels==0) )\ntmp.loc[ tmp.open_channels==1 ,'signal'] = 1 + np.random.normal(  -0.0299 , 0.2275, np.sum(tmp.open_channels==1) )\ntmp.loc[ tmp.open_channels==2 ,'signal'] = 2 + np.random.normal(  -0.0440 , 0.2278, np.sum(tmp.open_channels==2) )\ntmp.loc[ tmp.open_channels==3 ,'signal'] = 3 + np.random.normal(  -0.0560 , 0.2245, np.sum(tmp.open_channels==3) )\ntrain.loc[ train.group==38 ] = tmp.copy()\n\ntrain['noise'] = train['signal'] - train['open_channels']","577b35eb":"# Now all train groups looks fine\nfor i in range(50):\n    train.loc[train.group==i].signal.plot()","140602e5":"# Now outlier group 7(3B) have similar statistics as group 3(3B)\ntrain.groupby(['group2','type'])['signal'].agg(['mean','std'])","3712a237":"for i in range(50):\n    train.loc[train.group2==i].noise_round.rolling(10000).mean().plot()","e2c181dc":"for i in range(20):\n    test.loc[test.group==i].noise_round.rolling(10000).mean().plot()","80c252f9":"#Remove the bias offset using an iterative loop for both train and test sets\n\ntrain['noise_round'] = train['signal'] - train['signal'].round()\ntest ['noise_round'] = test ['signal'] - test ['signal'].round()\nfor i in range( 7 ):\n    train['bias'] = train.groupby('group')['noise_round'].transform('mean')\n    test ['bias'] = test.groupby( 'group')['noise_round'].transform('mean')\n    \n    train['signal'] = train['signal'] - train['bias']\n    test ['signal'] = test ['signal'] - test ['bias']\n    train['noise_round'] = train['signal'] - train['signal'].round()\n    test ['noise_round'] = test ['signal'] - test ['signal'].round()\n    \n    print( i, 'acc:',np.mean( train.open_channels == train.signal.round() ) , 'f1:',f1_score( train.open_channels , np.clip(train.signal.round(),0,10), average='macro' ) )\n\ntrain['noise'] = train['signal'] - train['open_channels']\ntrain['noise_round'] = train['signal'] - train['signal'].round()\ntest ['noise_round'] = test ['signal'] - test ['signal'].round()","ccb3f997":"#Check bias offsets now. Must be close to zero.\ntrain.groupby(['group','type'])['noise'].agg(['mean','std'])","56946c84":"train.groupby(['group','type'])['noise_round'].agg(['mean','std'])","8d68d1c2":"test.groupby(['group','type'])['noise_round'].agg(['mean','std'])","3c8260c3":"for i in range(50):\n    train.loc[train.group==i].noise_round.rolling(10000).mean().plot()","0d988599":"# The bias offset in groups 10B in train is at the same level as in test, so don't worry about it. \nfor i in range(10):\n    test.loc[test.group==i].noise_round.rolling(10000).mean().plot()","f4445833":"print( 'ACC:', np.mean( train.open_channels == train.signal.round() )  )\nprint( 'F1:', f1_score( train.open_channels , np.clip(train.signal.round(),0,10), average='macro' ) )","7e7ba566":"#Calc ACC per group\ntrain['hit'] = train.open_channels == train.signal.round()\ntrain.groupby(['group','type'])['hit'].mean()","42d611bd":"train[['time','signal','type','open_channels']].to_csv('train_clean_giba.csv', index=False )\ntest [['time','signal','type']].to_csv('test_clean_giba.csv', index=False )","1e0970ac":"# Remove\/Decrease 50Hz power line interference","5c956a6e":"# There still some bias to be removed per group, both in train and in test","d249581d":"# Remove outlier on train 100k batch group 4\n## this outlier pattern happens only on trainset so its safe to remove it.","9b99420f":"# Remove the bias","d7d7a93d":"## to remove the outliers, lets just add a gaussian noise to open_channels with a specific std level for the specific batches.","65241944":"# Note that the std of the gaussian noise above is different for each type:\n## Type 1A sdt ~ 0.197\n## Type 1B sdt ~ 0.197\n## Type 3B sdt ~ 0.215\n## Type 5B sdt ~ 0.231\n## Type 10B sdt ~ 0.327","2a562851":"# # Removing outliers from 100k groups batches 36, 37 and 38 of trainset","2e372dbc":"# Load the train and test sets","7ac9b1b2":"# Now that signal and open_channels are in the same scale, to calculate the noise added to each row it is just a mater of subtract each other.","24757c94":"# Observe the drifts in trainset","dfae64c1":"## We can cleanly see that there is an interference in the 3B groups in trainset and the corresponding 3B groups in test doesn't have such interference.","34497407":"# Fix train and test signal levels.\n## Train 500k groups 4 and 9 and test 100k groups 5 and 7 needs to be shifted by +2*exp(1)\n## Other groups are shifted by +exp(1)\n## All groups must be rescaled by 1.25 to match open_channels scale","789abe06":"## Analyzing the signal and target statistics we classified each train and test groups as xA and xB, where x is the maximum number of simultaneous open_channels per group","690a9052":"# After deep analisys we found that all the drifts come from the same equation:\n## 4 * sin(  2 * pi * range(500000) \/ 1000000  )","27095e56":"# Adding 2x 5B std noise gives:","b0467060":"# The result above makes us think that the 10 channels groups are the sum of two 5 channels groups","a1129cbb":"# Now the bias offset are close to zero. But still a small bias offset in groups 10B.\n","db81ee9b":"# Since we can't have the real noise in test set, we can approximate the noise in test using signal-signal.round() as a proxy for the noise.","a0b20c9f":"# Remove the drift from train and test","2439b72c":"# Accuracy and F1 using only round(signal) as a predictor."}}