{"cell_type":{"84808443":"code","5bc4b500":"code","6b707a34":"code","cf3d2dc7":"code","0c4ae6fa":"code","8e7dd79c":"code","ab353fa4":"code","b658e77a":"code","85b0dffd":"code","e0ccc4c5":"code","3df82938":"code","bd0bb132":"code","3c6715b1":"code","5945b214":"code","b58eccf4":"code","88b64a42":"code","fa09c34f":"code","030e5458":"code","06e502e8":"code","0e612864":"code","8113f7c4":"code","0420a9dc":"code","56991f12":"code","b1b6e367":"code","8e39393c":"code","b18d63d1":"code","77f650b5":"code","46343ea6":"code","9a775c62":"code","146fa194":"code","7e0bd99c":"code","4aba2437":"code","96786e04":"code","939faa72":"code","387d09f0":"code","d916ae02":"code","cad4f916":"code","a3a4232e":"code","7207cfb4":"code","d24c1269":"code","1f5da724":"code","35b68138":"code","9b85fa9a":"code","51b45031":"code","ff18a59b":"code","0890b683":"code","191247e5":"code","ffb5d7b8":"code","3bb0a179":"code","66cf002d":"code","14a02375":"code","6dff228a":"code","115e19e8":"code","61a3ec8d":"code","c2121995":"code","9f9c57f0":"code","ac606765":"code","4dce88bc":"code","8f842b35":"code","4ae012e1":"code","12470081":"code","d120b034":"code","67ebede7":"code","9e156bce":"markdown","73c956cf":"markdown"},"source":{"84808443":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfiles = list()\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5bc4b500":"files[0]","6b707a34":"# import sys\n\n# def read_file(file):\n#     data = []\n#     with open(file, \"r\") as f:\n#         for line in f:\n#             data.append(line.split(','))\n#     return data\n\n# print(read_file(files[0])[1:])\n# npdata = np.array(read_file(files[0]))","cf3d2dc7":"# print(npdata[0:10])","0c4ae6fa":"# tvcount = 0 # select 'TV Show', count(type) from netflix where type = 'TV Show'\n# mvcount = 0 # select 'Movie', count(type) from netflix where type = 'Movie'\n\n# print(len(npdata))\n# for x in npdata:\n# #     print(x[1])\n#     if 'TV Show' in x:\n#         tvcount +=1\n#     elif 'Movie' in x:\n#         mvcount +=1\n\n# print(\"TV Show : \",tvcount)\n# print(\"Movies  : \",mvcount)","8e7dd79c":"pddata = pd.read_csv(files[0], parse_dates = ['date_added'])\n(pddata.head(5))\n\n# # numerical cols\n# (pddata.describe())\n\n# (pddata.info())\n\n(pddata.tail(5))","ab353fa4":"print(pddata['type'].head(10))\n\nprint(pddata['type'].describe())","b658e77a":"print(pddata[pddata['type'] == 'Movie']['type'].count)  # select 'Movie', count(type) from netflix where type = 'Movie'\nprint(pddata[pddata['type'] == 'TV Show']['type'].count)  # select 'TV Show', count(type) from netflix where type = 'TV Show'","85b0dffd":"print(pddata['director'][pddata['director'].isna()].index)\n\nprint(pddata.columns)","e0ccc4c5":"pddata.iloc[0]","3df82938":"pddata.at[0,'type']","bd0bb132":"# pd -> data structure [(1D)Series,(2D)DataFrame, (ND)Panel]\n# (2D)DataFrame Tabular\/Formated DataStructure\n\n# for label, content in pddata.items():\n#     print(label,content)","3c6715b1":"pddata['rating'].describe()","5945b214":"# select rating, count(*) as 'rating_count' from netflix group by rating\n# TV MA 2863\n# pddata.groupby('rating').describe()\n\nrating_data = pddata.groupby('rating')\n\nratings = rating_data.agg(np.size)['show_id']\nprint(len(pddata))\n\ntsize = len(pddata)\n\nfor label, content in ratings.items():\n    ratingc = int(content)\n    dataper = (ratingc \/ tsize) * 100\n    print(label, format(dataper, '0.2f'))","b58eccf4":"# get dummies categorical data into  the columns : values of data 0\/1\nrating_data = pd.get_dummies(pddata['rating'])\nrating_data.head(10)\n\n# ['G','NC', .....]\n#     G   NC  ........\n# 0   1   0  0 0 0  \n# 1   0   1  0 0 0 \n\n\n\n# for lable in rating_data.columns:\n#     print(lable, rating_data[lable].sum())","88b64a42":"pddata['director'][pddata['director'].isna()].index","fa09c34f":"directordata = pddata.drop(pddata['director'][pddata['director'].isna()].index)\nprint(directordata['director'].head())","030e5458":"director_counts = directordata.groupby('director').agg(np.size)['show_id']\ndirector_counts\n# for lable, content in director_counts.items():\n#     direc = int(content)\n#     dataper = (direc \/ tsize) * 100\n#     print(lable, format(dataper, '0.2f'))","06e502e8":"def split_genre(item):\n    return item.split(',')\n\ngenre = pddata['listed_in'].apply(split_genre)\n\nprint(genre)\n\n# not allow duplicate value\ndata_g = set()\n\nfor item in genre:\n    for g in item:\n        data_g.add(g.strip())\n\ngenere_list = list(data_g)\nprint(len(genere_list))\nprint(genere_list[0:5])","0e612864":"# genre = pd.get_dummies(genere_list) \n# genre.head(10)\n\nfor genr in genere_list:\n    pddata[genr] = np.zeros(len(pddata))\n\npddata[genere_list].tail(2)\nfor label, item in pddata['listed_in'].items():\n    for genr in genere_list:\n        if genr in item:\n            pddata.at[label, genr] = 1.0\npddata[genere_list].tail(2)\n\n\npddata[(pddata['type'] == 'TV Show') & (pddata['Comedies'] == 1)]","8113f7c4":"generes = {}\nfor genr in genere_list:\n    generes[genr.strip()] = pddata[genr].sum()\nprint(generes)\npdgenre = pd.Series(data = generes , index = genere_list)\n\n\npdgenre","0420a9dc":"\n# countrydata = pddata.drop(pddata['country'][pddata['country'].isnull()].index)\n\n# countrydata = pddata.drop(pddata['country'][pddata['country'].isna()].index)\n\ncountrydata = pddata['country'].dropna()\n\ndef split_country(item):\n    splidata = []\n    try:\n        splidata = item.split(',')\n    except:\n        splidata = np.nan\n    return splidata\n\n# inline function\n# lambda x : x > 10\n\npdcountry = countrydata.apply(split_country)\n\n\n# United States, India\nunique_country = set()\n\nfor items in pdcountry:\n    for item in items:\n        unique_country.add(item.strip())\n\nunique_country = list(unique_country)\n\nunique_country.remove('')\n\ncountry_list = {}\nfor items in countrydata:\n    for item in unique_country:\n        if item in items:\n            if item in country_list.keys():\n                country_list[item] += 1\n            else:\n                country_list[item] = 1\n\nprint(country_list)","56991f12":"for country in country_list:\n    pddata[country] = np.zeros(len(pddata))\n\npddata.drop(pddata['country'][pddata['country'].isna()].index, inplace = True)\n\nprint(len(pddata))\n# pddata[genere_list].tail(2)\nfor label, item in pddata['country'].items():\n    for country in country_list:\n        if country in item:\n            pddata.at[label, country] = 1.0\n\n","b1b6e367":"# pddata.drop(unique_country, axis=1)\n\npddata['United States'][pddata['type'] == 'TV Show'].sum()\n","8e39393c":"pddata[unique_country][pddata['type'] == 'Movie'].sum()","b18d63d1":"# Grouping Type with Duration\n\nduration = pddata['duration'].unique()","77f650b5":"grouping_type_dur = pddata.groupby(['type','duration']).agg(np.size)\ngrouping_type_dur.rename(columns={\"show_id\": \"group_by_type_dur\"}, inplace= True)\n\ngrouping_type_dur.drop(grouping_type_dur.columns[1:],axis=1,inplace = True)","46343ea6":"grouping_type_dur.head(10)","9a775c62":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['TV Show']","146fa194":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['Movie']","7e0bd99c":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['TV Show'].sort_values('group_by_type_dur',ascending = False)","4aba2437":"grouping_type_dur[grouping_type_dur['group_by_type_dur'] > 50 ].loc['Movie'].sort_values('group_by_type_dur',ascending = True)","96786e04":"grouping_type_dur['season'] = np.zeros(len(grouping_type_dur))\ngrouping_type_dur['mint'] = np.zeros(len(grouping_type_dur))\n\ngrouping_type_dur","939faa72":"grouping_type_dur.index\n\ngrouping_type_dur.reset_index(inplace=True)\ngrouping_type_dur.head()","387d09f0":"print(grouping_type_dur.head())\n\nfor index,item in grouping_type_dur['duration'].items():\n    if 'Seasons' in grouping_type_dur.at[index,'duration']:\n        grouping_type_dur.at[index, 'season'] = int(grouping_type_dur.at[index,'duration'].replace('Seasons','').strip())\n    elif 'Season' in grouping_type_dur.at[index,'duration']:\n        grouping_type_dur.at[index, 'season'] = int(grouping_type_dur.at[index,'duration'].replace('Season','').strip())\n    elif 'min' in grouping_type_dur.at[index,'duration']:\n        grouping_type_dur.at[index, 'mint'] = int(grouping_type_dur.at[index,'duration'].replace('min','').strip())","d916ae02":"grouping_type_dur\n\nprint(int(grouping_type_dur.at[index,'duration'].replace('Seasons','').strip()))\n","cad4f916":"grouping_type_dur[(grouping_type_dur['season'] >= 1) & (grouping_type_dur['season'] <= 3)].sum()\n\n# print(grouping_type_dur['group_by_type_dur'].sum())","a3a4232e":"grouping_type_dur[(grouping_type_dur['season'] == 1)]","7207cfb4":"season13 = grouping_type_dur[(grouping_type_dur['season'] >= 1) & (grouping_type_dur['season'] <= 3)].sum()['group_by_type_dur']\ntotal = grouping_type_dur[grouping_type_dur['type'] == 'TV Show']['group_by_type_dur'].sum()\n\nprint(format(season13\/total, '.2%'))","d24c1269":"season45 = grouping_type_dur[(grouping_type_dur['season'] > 3)].sum()['group_by_type_dur']\ntotal = grouping_type_dur[grouping_type_dur['type'] == 'TV Show']['group_by_type_dur'].sum()\n\nprint(format(season45\/total, '.2%'))","1f5da724":"titlegrp = pddata.groupby(['title']).agg(np.size)\n# print(titlegrp)\n\n# titlegrp[titlegrp['type'] == 'TV Show']","35b68138":"titlegrp.drop(titlegrp.columns[1:],axis=1,inplace=True)","9b85fa9a":"titlegrp.sort_values('show_id',ascending = False)","51b45031":"import matplotlib\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","ff18a59b":"plt.figure(figsize= (16, 16))\n\n# category based graphs\nxdata = (pdgenre.index)[:10]\nydata = list(map(int,pdgenre.values[:10]))\nplt.plot(xdata,ydata)\nplt.show()","0890b683":"# top 10 listed genre\ntop10genre = pdgenre.sort_values(ascending=True).head(10)\n\nx = top10genre.index\ny = top10genre.values\n\nplt.figure(figsize= (16, 16))\nplt.style.use('classic')\nplt.plot(x,y)\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\nplt.show()","191247e5":"# top 10 listed genre\ntop10genre = pdgenre.sort_values(ascending=True).head(10)\n\nx = top10genre.index\ny = top10genre.values\n\nyav = np.array(y).std()\n\nplt.figure(figsize= (16, 16))\nplt.style.use('default')\nfig, ax = plt.subplots()\nax.bar(x, y, 0.35, yerr=yav, label='Category')\nplt.xticks(x,rotation ='vertical')\n\nfig.set_figheight(20)\nfig.set_figwidth(20)\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\nplt.show()","ffb5d7b8":"fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\naxs[0].bar(x, y)\naxs[0].set_xticklabels(x,rotation ='vertical')\naxs[1].scatter(x, y)\naxs[1].set_xticklabels(x,rotation ='vertical')\naxs[2].plot(x, y)\naxs[2].set_xticklabels(x,rotation ='vertical')\n\nfig.suptitle('Categorical Plotting')\n","3bb0a179":"# country based graphs\n\ncountrydata = pd.Series(country_list)\nx = countrydata.sort_values(ascending=False).head(10).index\ny = countrydata.sort_values(ascending=False).head(10).values\n\n\n\nfig, axs = plt.subplots(1, 1, figsize=(16, 16), sharey=True)\nplt.style.use('classic')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\naxs.pie(y, labels = x,autopct='%1.2f%%')\nplt.show()\n","66cf002d":"ustv = pddata['United States'][pddata['type'] == 'TV Show'].sum()\nusmv = pddata['United States'][pddata['type'] == 'Movie'].sum()\n\nprint(ustv,usmv)","14a02375":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 16))\nfig.subplots_adjust(wspace=0)\nplt.style.use('default')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Category Vs Count\")\nax1.pie(y, labels = x,autopct='%1.2f%%')\n\nusrange = [ustv,usmv]\ncolors = [[.1, .3, .5], [.1, .3, .3]]\nxpos = 0\nbottom = 0\nwidth = 0.35\n\nfor j in range(len(usrange)):\n    height = usrange[j]\n    ax2.bar(xpos, height, width, bottom=bottom, color=colors[j])\n    ypos = bottom + ax2.patches[j].get_height() \/ 2\n    bottom += height\n    ax2.text(xpos, ypos, \"%d%%\" % ((ax2.patches[j].get_height() * 100) \/(ustv+usmv)),\n             ha='center')\n    \nax2.set_title('Type Based Data')\nax2.legend(('TV-Show', 'Movie'))\nax2.axis('off')\nax2.set_xlim(- 2.5 * width, 2.5 * width)","6dff228a":"from wordcloud import WordCloud\n\nplt.subplots(figsize =(8,8))\nwordcloud = WordCloud(\n                            background_color = 'white',\n                            width = 512,\n                            height = 384\n                        ).generate(\" \".join(pddata['listed_in']))\n\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.savefig('graph.png')\n\nplt.show()","115e19e8":"movie = pddata[pddata['type'] == 'Movie']\ntv = pddata[pddata['type'] == 'TV Show']\n\ndata = pddata[['type', 'release_year']]\ndata = data.value_counts().to_frame()\ndata.reset_index(level=[0,1], inplace=True)\ndata = data.rename(columns = {0:'count'})\ndata = pd.concat([data[data['type'] == 'Movie'][:10], data[data['type']== 'TV Show'][:10]])\n\nxmv = data[data['type'] == 'Movie'].sort_values(by=['release_year'],ascending=True)\nxtv = data[data['type'] == 'TV Show'].sort_values(by=['release_year'],ascending=True)\n\n\nfig, ax = plt.subplots()\nax.plot(xmv['release_year'], xmv['count'], label=\"Movie\")\nax.plot(xtv['release_year'], xtv['count'], label=\"TV Show\")\nax.legend()\n\nplt.show()\n","61a3ec8d":"catwithyear = pddata.groupby(['release_year']).agg(np.sum)[pdgenre.index]\ncatwithyear.sort_values(by=['release_year'],ascending=False)\n\ntop10cat = catwithyear[catwithyear.columns[:10]].sort_values(by=['release_year'],ascending=False)\n\nyear = top10cat.head(10).index\n\nfig, ax = plt.subplots()\n\nfor item in top10cat.head(10).columns[:10]:\n    #print(top10cat[item].values)\n    ax.plot(year, top10cat[item].values[:10], label=item)\n\nax.legend()\n\nplt.show()\n","c2121995":"countryyear = pddata.groupby(['release_year']).agg(np.sum)[country_list.keys()]\ncountryyear.sort_values(by=['release_year'],ascending=False)\n\ntop10country = countryyear[countryyear.columns[:10]].sort_values(by=['release_year'],ascending=False)\n\nyear = top10country.head(10).index\n\nfig, ax = plt.subplots()\n\nfor item in top10country.head(10).columns[:10]:\n    #print(top10cat[item].values)\n    ax.plot(year, top10country[item].values[:10], label=item)\n\nax.legend()\n\nplt.show()\n","9f9c57f0":"# top 10 Ratings\nratings = pddata['rating'].unique()\nratings\n\n\nratinglist = []\ndatalist = []\nfor rating in ratings:\n    rat = (pddata[pddata['rating'] == rating]['rating'].value_counts().values)\n    if bool(rat):\n        ratinglist.append(rating)\n        datalist.append(rat[0])\n\nplt.figure(figsize= (16, 16))\nplt.style.use('default')\nplt.bar(ratinglist,datalist,width=0.35)\nplt.xlabel(\"Ratings\")\nplt.ylabel(\"Count\")\nplt.title(\"Rating Vs Count\")\nplt.show()","ac606765":"# top 10 directors\nxdir = director_counts.sort_values(ascending=False)[:10].index\nydir = director_counts.sort_values(ascending=False)[:10].values\n\n\nplt.figure(figsize= (16, 16))\nplt.style.use('default')\nplt.bar(xdir,ydir,width=0.35)\nplt.xlabel(\"Director\")\nplt.ylabel(\"Count\")\nplt.title(\"Director Vs Count\")\nplt.show()","4dce88bc":"import seaborn as sns\n\n\n\nsns.heatmap(pddata[pdgenre.index[:10]].corr(),annot=True)\nplt.show()","8f842b35":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[ctlist.index[:15]].corr(),annot=True)\nplt.show()","4ae012e1":"# Recommendation system \n# user    moneyheist: Thriller\n# sumit    w : 1 visit count\n#          r : 4 rating count\n\n# market basket analysis -> Frequent Itemset Algorithm\n# sumit milk,butter,bread\n# sumit2 milk,bread,sugar\n# sumit3 bread,butter,jam\n\n\nctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'TV Show'][ctlist.index[:15]].corr(),annot=True)\nplt.show()","12470081":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'Movie'][ctlist.index[:15]].corr(),annot=True)\nplt.show()","d120b034":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'Movie'][pdgenre.index[:15]].corr(),annot=True)\nplt.show()","67ebede7":"ctlist = pd.Series(country_list)\nplt.figure(figsize= (16, 16))\n\nsns.heatmap(pddata[pddata['type'] == 'TV Show'][pdgenre.index[:15]].corr(),annot=True)\nplt.show()","9e156bce":"# Netflix Dataset Analysis","73c956cf":"# Visualisation with Matplotlib"}}