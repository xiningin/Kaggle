{"cell_type":{"e44bae70":"code","f5eeb982":"code","c795f70f":"code","fc48f7cb":"code","4e7eb08f":"code","0025ac18":"code","8547ec6c":"code","5d62c560":"code","6b2685c2":"code","387e825b":"code","03b1ba32":"code","9d14649c":"code","43d1189d":"code","1bbf01e5":"code","dbdb487f":"code","392e2c51":"code","05f3b61d":"code","3cc640c1":"code","71bf26f6":"code","eca46431":"code","5592b95a":"code","d74f18a5":"code","03e3b564":"code","d05b03e2":"code","f1e934f8":"code","e4003654":"markdown","52d131a0":"markdown","5c4fffdb":"markdown","17f6e350":"markdown"},"source":{"e44bae70":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom collections import Counter\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f5eeb982":"gender = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain.select_dtypes(include=[np.number])","c795f70f":"print('train data have {0} rows and {1} columns'.format(train.shape[0],train.shape[1]))","fc48f7cb":"train.columns[train.isnull().any()]","4e7eb08f":"train.Age.fillna((train.Age.median()),inplace=True)\ntrain.Age","0025ac18":"sns.distplot(train.Age)","8547ec6c":"feature_columns = ['Age','SibSp','Parch','Fare']\ntrain.Fare = train.Fare.map(lambda i:np.log(i) if i > 0 else 0)\nsns.distplot(train.Fare)\n#mean = train.Age.mean()\n#train.Age.fillna('mean', inplace=True)","5d62c560":"train.SibSp.skew()","6b2685c2":"sns.scatterplot(x='SibSp', y='Survived',data=train)","387e825b":"train.drop(train[train.SibSp >= 8].index, inplace=True)\ntrain.SibSp.skew()","03b1ba32":"train.Parch.skew()","9d14649c":"sns.scatterplot(x='Parch',y='Survived',data=train)","43d1189d":"X = pd.get_dummies(train[feature_columns])\nY = train['Survived']\nX_test = pd.get_dummies(test[feature_columns])\nX_test.head()","1bbf01e5":"sns.scatterplot(x='Fare', y='Survived',data=train)","dbdb487f":"train.drop(train[train.Fare > 250].index, inplace = True)\ntrain.Fare.skew()","392e2c51":"def detect_outliers(df,n,features):\n    outlier_indices = []\n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col],25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        # outlier step\n        outlier_step = 1.5 * IQR\n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index       \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    return multiple_outliers   \n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\ntrain.loc[Outliers_to_drop] # Show the outliers rows\n    ","05f3b61d":"#train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n#Dropping above outliers is not giving","3cc640c1":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X,Y)\n#predict = logreg.predict(X_test)","71bf26f6":"X","eca46431":"from sklearn.ensemble import RandomForestClassifier\n\ny = train[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_random.csv', index=False)\nprint(\"Your submission was successfully saved!\")","5592b95a":"y.shape","d74f18a5":"X_lg = pd.DataFrame(train, columns=features)\nX_lg = pd.get_dummies(X_lg)\nX_lg\nlogreg.fit(X,y)\npredictions = logreg.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_logistic.csv', index=False)","03e3b564":"from sklearn import linear_model\nlm = linear_model.LinearRegression()\nlm.fit(X_lg,y)\npredictions1 = lm.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions1})\noutput.to_csv('my_submission_linear.csv', index=False)\n","d05b03e2":"from sklearn.svm import SVC\nsv = SVC(kernel='rbf')\nsv.fit(X_lg,y)\npredict_svm = sv.predict(X_test)\noutput = pd.DataFrame({'PassengerID': test.PassengerId, 'Survived': predict_svm})\noutput.to_csv('my_submission_svm.csv',index=False)","f1e934f8":"\nVotingPredictor = VotingClassifier(estimators=[('ExtC', ExtC_best), ('GBC',GBC_best),\n('SVMC', SVMC_best), ('random_forest', random_forest_best)], voting='soft', n_jobs=4)\nVotingPredictor = VotingPredictor.fit(X_lg, y)\nVotingPredictor_predictions = VotingPredictor.predict(X_test)\ntest_Survived = pd.Series(VotingPredictor_predictions, name=\"Survived\")\nSubmission3 = pd.concat([PassengerId,test_Survived],axis=1)\noutput.to_csv('my_submission3.csv',index=False)","e4003654":"**##Prediction using SVC ##**","52d131a0":"**Prediction Using Logistic Regresstion**","5c4fffdb":"**From above diagram, we can identify that there are few outliers. Iam going to remove the outliers that are above 250 in Fare.**","17f6e350":"**We see that there is a skewness for Fares. Hence applying log function for the column Fare. After applying log function, we see that skewness has gone down. **"}}