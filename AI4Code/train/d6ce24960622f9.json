{"cell_type":{"a0bb8b68":"code","c2e8dea2":"code","e461ee35":"code","eb097eb8":"code","6f04419d":"code","c6d2d53b":"code","66126f33":"code","a1f40eec":"code","fb208fb5":"code","5073b7d1":"code","1c3ae68c":"code","17767d4c":"code","3b8c9a44":"code","dd535c58":"code","8e5bff10":"code","ef5a6020":"code","d18daaee":"code","65c14439":"code","fabcd358":"code","663deb09":"code","86aebd3e":"code","2e588c8e":"code","f6401e79":"code","f5a4ffef":"code","189cb2f8":"code","53566d1e":"code","0e876815":"code","0833decb":"code","695cd020":"code","5bdc43c9":"code","6e8353d3":"code","7f57531d":"code","d3ad3055":"code","02db2383":"code","f75424b4":"code","a6a6c8be":"code","20e1841b":"code","924e27e7":"markdown","9a97fd5c":"markdown","7d2b7e5f":"markdown","f46ebfe3":"markdown","496da9f5":"markdown","d25836bc":"markdown","d9f12b43":"markdown","18433ba9":"markdown","d3dd8b9c":"markdown","16f469c9":"markdown","111178c9":"markdown","2843f468":"markdown","991b0d05":"markdown","12f8b7be":"markdown","c4dafc46":"markdown","1201f0b2":"markdown","d2cee3b2":"markdown","821bd44b":"markdown","abf294ba":"markdown","3e4a0c1b":"markdown","7436f7c4":"markdown","62a80d3c":"markdown","571d3d58":"markdown","67a6914d":"markdown","17f09b62":"markdown","fa9dfd04":"markdown","19c18868":"markdown","b78063c3":"markdown","af1166ea":"markdown"},"source":{"a0bb8b68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2e8dea2":"import matplotlib as plt\nimport seaborn as sns\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nX = pd.read_csv('\/kaggle\/input\/electrity-prices\/electricity_prices.csv')\nX_full = X.copy()\nX.head()","e461ee35":"X.info()","eb097eb8":"X=X.replace('?', np.NaN)\nX.isnull().sum()","6f04419d":"o_list=['ForecastWindProduction','SystemLoadEA','SMPEA', 'ORKTemperature',\n'ORKWindspeed','CO2Intensity','ActualWindProduction','SystemLoadEP2', 'SMPEP2']\nX[o_list]=X[o_list].apply(pd.to_numeric)","c6d2d53b":"X.info()","66126f33":"X['DateTime']=pd.to_datetime(X['DateTime'],dayfirst=True)","a1f40eec":"X=X.dropna()","fb208fb5":"X.isnull().sum()","5073b7d1":"X_eda=X.set_index('DateTime')\nX_eda[['SMPEA','SMPEP2']].resample('M').mean().plot()","1c3ae68c":"sns.scatterplot(data=X_eda, x='WeekOfYear', y='SMPEP2')\nsns.scatterplot(data=X_eda, x='WeekOfYear', y='SMPEA')","17767d4c":"sns.scatterplot(data=X_eda, x='PeriodOfDay', y='SMPEP2')","3b8c9a44":"X_eda.loc[X_eda.SMPEP2==1000.00]","dd535c58":"X.Holiday.nunique()\none_hot = pd.get_dummies(X['Holiday'])\nX=X.drop('Holiday', axis=1)","8e5bff10":"one_hot.head()","ef5a6020":"X_merged=X.merge(one_hot, left_index=True, right_index=True)","d18daaee":"X_merged.head()","65c14439":"X_merged.loc[X_merged.SMPEP2==1000.00]","fabcd358":"X_merged=X_merged.drop([23193])","663deb09":"X_merged=X_merged.drop(['Day', 'Month', 'HolidayFlag'], axis=1)\n\nX_merged.head()","86aebd3e":"corr_data=X_merged.corr()[['SMPEP2']].sort_values(by='SMPEP2', ascending=False)","2e588c8e":"corr_data.head(10)","f6401e79":"y=X_merged.SMPEP2","f5a4ffef":"X_clean=X_merged[['SMPEA','SystemLoadEP2','SystemLoadEA', 'PeriodOfDay']]","189cb2f8":"X_train, X_valid, y_train, y_valid = train_test_split(X_clean, y)","53566d1e":"my_model = XGBRegressor(random_state=63)\nmy_model.fit(X_train, y_train)","0e876815":"predictions = my_model.predict(X_valid)","0833decb":"mae_XBG=mean_absolute_error(predictions,y_valid)\nmean_y=X_merged.SMPEP2.mean()","695cd020":"print(\"Mean Absolute Error: \" + str(mae_XBG))\nprint('prediction accuracy: ' +str(1-mae_XBG\/mean_y))","5bdc43c9":"my_model_tuned= XGBRegressor(n_estimators=600, learning_rate=0.05)\nmy_model_tuned.fit(X_train, y_train)","6e8353d3":"predictions_2=my_model_tuned.predict(X_valid)","7f57531d":"mae_XBG2=mean_absolute_error(predictions_2,y_valid)\nmean_y=X_merged.SMPEP2.mean()\nprint(\"Mean Absolute Error: \" + str(mae_XBG2))\nprint('prediction accuracy: ' +str(1-mae_XBG2\/mean_y))","d3ad3055":"forest_model = RandomForestRegressor(random_state=63)\nforest_model.fit(X_train, y_train)\nfores_preds = forest_model.predict(X_valid)\nforest_mae=mean_absolute_error(y_valid, fores_preds)\nprint(\"Mean Absolute Error: \" + str(forest_mae))\nprint('prediction accuracy: ' +str(1-forest_mae\/mean_y))","02db2383":"X_v2=X_merged.drop(['SMPEP2','DateTime'],axis=1)\nX_train, X_valid, y_train, y_valid = train_test_split(X_v2, y)\nmodel_XGB_full= XGBRegressor(random_state=63)\nmodel_XGB_full.fit(X_train, y_train)\npredictions_3= model_XGB_full.predict(X_valid)","f75424b4":"mae_XBG3=mean_absolute_error(predictions_3,y_valid)\nmean_y=X_merged.SMPEP2.mean()\nprint(\"Mean Absolute Error: \" + str(mae_XBG3))\nprint('prediction accuracy: ' +str((mean_y-mae_XBG3)\/mean_y))","a6a6c8be":"X_train, X_valid, y_train, y_valid = train_test_split(X_v2, y)\nforest_model_full = RandomForestRegressor(random_state=63)\nforest_model_full.fit(X_train, y_train)\nforest_model_full.fit(X_train, y_train)\npredictions_fmf= forest_model_full.predict(X_valid)","20e1841b":"fmf_mae=mean_absolute_error(y_valid, predictions_fmf)\nprint(\"Mean Absolute Error: \" + str(fmf_mae))\nprint('prediction accuracy: ' +str(1-fmf_mae\/mean_y))","924e27e7":"From what we can see from scatterplots that these values are pretty closely related, and only one data entry sticks out.","9a97fd5c":"To process this dataset we need hot-encode our categorical columns. Let's use hot-encoding and pd.get_dummies","7d2b7e5f":"There is a huge spike in price in february. Is there a possible outlier? Let's futher explore it through few scatter plots","f46ebfe3":"As we can see MAE equals 13.53. Lets we can tune it to lesser MAE","496da9f5":"Column 'Holiday' has been dropped, as it serves no purpose here.","d25836bc":"2. Look up info about this data set","d9f12b43":"Calculate mean absolute error of the model","18433ba9":"If we try to apply numeric functions to certain columns e.g. SMPEP2, SMPEA etc. it will throw exception. It happens because Null values  shown as '?' instead of np.NaN. Let's fix that","d3dd8b9c":"As we can see SMPEA (price prediction) is the most correlated with actual price, System load is also good predictor","16f469c9":"**Goal of this notebook is to predict electricity prices using given features.**","111178c9":"Drop SMPEP2 extreme outlier.","2843f468":"4. Because of small amount of rows with null values, so we can drop them","991b0d05":"Merging initial dataset and one-hot encoded holidays","12f8b7be":"As we can see there a few null values. Now we can change type of columns to numeric types","c4dafc46":"**6. Modelling. **","1201f0b2":"5. Exploratory data analysis. ","d2cee3b2":"Also lets drop day, month, holidayflag columns because of their redundancy","821bd44b":"Now we will use Random Forest regression model.","abf294ba":"It looks like this entry  is a mistake. So we will remove from model later","3e4a0c1b":"split our model into validation set and training set","7436f7c4":"As we can see the most accurate model is Random Forest Regression used on full dataset.","62a80d3c":"First, we will use XBG algorithm to make a price predicting model","571d3d58":"3. Change DateTime column to datetime type","67a6914d":"1. Upload data and necessary libraries","17f09b62":"Lets plot graph of SMPEP2, column that we need to predict and SMPEA which is daily price prediction given daily","fa9dfd04":"7. Model Building  ","19c18868":"Data set uploader has these explanations for the  features:\n> Column Description:\n\n    DateTime: String, defines date and time of sample\n    Holiday: String, gives name of holiday if day is a bank holiday\n    HolidayFlag: integer, 1 if day is a bank holiday, zero otherwise\n    DayOfWeek: integer (0-6), 0 monday, day of week\n    WeekOfYear: integer, running week within year of this date\n    Day integer: day of the date\n    Month integer: month of the date\n    Year integer: year of the date\n    PeriodOfDay integer: denotes half hour period of day (0-47)\n    ForecastWindProduction: the forecasted wind production for this period\n    SystemLoadEA: the national load forecast for this period\n    SMPEA: the price forecast for this period\n    ORKTemperature: the actual temperature measured at Cork airport\n    ORKWindspeed: the actual windspeed measured at Cork airport\n    CO2Intensity: the actual CO2 intensity in (g\/kWh) for the electricity produced\n    ActualWindProduction: the actual wind energy production for this period\n    SystemLoadEP2: the actual national system load for this period\n    SMPEP2: the actual price of this time period, the value to be forecasted\n\nSMPEP2 is the value that we need to build model to predict","b78063c3":"Firstly, we will build our model with only highly correlated parameters, after that we will encorporate all of the parameters.\nOur model building flow will be:\nonly highly correlated features: XGB -> XGB(tuned) -> RFR\nall the data: XGB -> XGB(tuned) -> RFR\nfor every model we will calculate mean absolute error","af1166ea":"Let's start from finding out which parameters affect our y."}}