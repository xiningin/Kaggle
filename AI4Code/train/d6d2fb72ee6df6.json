{"cell_type":{"04a600f0":"code","fbe47f35":"code","70e408f6":"code","896a658c":"code","e37759b8":"code","158d7b6b":"code","939d6ffc":"code","031dff2e":"code","54c99b6a":"code","e5959250":"markdown","10c43ad0":"markdown","80d9deb3":"markdown","92566782":"markdown","8b1f03af":"markdown","937ad8d4":"markdown","15818168":"markdown","9a81f562":"markdown"},"source":{"04a600f0":"%%time\n\nimport os\nimport logging\nimport sys\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgbm","fbe47f35":"%%time\n\nfolds_dir = \"..\/input\/tps-september-2021-skfolds\/\"\ndata_dir = \"..\/input\/tabular-playground-series-sep-2021\/\"\n\ndf_train = pd.read_csv(folds_dir + \"train_folds.csv\")\ndf_test = pd.read_csv(data_dir + \"test.csv\")\nsubmission = pd.read_csv(data_dir + \"sample_solution.csv\")\n\nfeatures = [col for col in df_test.columns if \"f\" in col]\ndf_test = df_test[features]\n\n# constants\nTARGET = \"claim\"","70e408f6":"%%time\n\ndef add_new_features(df):\n    # https:\/\/www.kaggle.com\/realtimshady\/single-simple-lightgbm\n    df[\"n_missing\"] = df[features].isna().sum(axis=1)\n    df[\"n_missing_std\"] = df.isna().std(axis=1).astype(\"float\")\n    df[\"abs_sum\"] = df[features].abs().sum(axis=1)\n    df[\"sem\"] = df[features].sem(axis=1)\n    df[\"std\"] = df[features].std(axis=1)\n    df[\"avg\"] = df[features].mean(axis=1)\n    df[\"max\"] = df[features].max(axis=1)\n    df[\"min\"] = df[features].min(axis=1)\n    \n    return df\n\ndf_train = add_new_features(df_train)\ndf_test = add_new_features(df_test)\n\nnew_features = [\"n_missing\", \"n_missing_std\", \"abs_sum\", \n             \"sem\", \"std\", \"avg\", \"max\", \"min\"]\n\nfeatures += new_features","896a658c":"fill_value_dict = {\n    \"f1\": \"Mean\", \n    \"f2\": \"Median\", \n    \"f3\": \"Median\", \n    \"f4\": \"Median\", \n    \"f5\": \"Mode\", \n    \"f6\": \"Mean\", \n    \"f7\": \"Median\", \n    \"f8\": \"Median\", \n    \"f9\": \"Median\", \n    \"f10\": \"Median\", \n    \"f11\": \"Mean\", \n    \"f12\": \"Median\", \n    \"f13\": \"Mean\", \n    \"f14\": \"Median\", \n    \"f15\": \"Mean\", \n    \"f16\": \"Median\", \n    \"f17\": \"Median\", \n    \"f18\": \"Median\", \n    \"f19\": \"Median\", \n    \"f20\": \"Median\", \n    \"f21\": \"Median\", \n    \"f22\": \"Mean\", \n    \"f23\": \"Mode\", \n    \"f24\": \"Median\", \n    \"f25\": \"Median\", \n    \"f26\": \"Median\", \n    \"f27\": \"Median\", \n    \"f28\": \"Median\", \n    \"f29\": \"Mode\", \n    \"f30\": \"Median\", \n    \"f31\": \"Median\", \n    \"f32\": \"Median\", \n    \"f33\": \"Median\", \n    \"f34\": \"Mean\", \n    \"f35\": \"Median\", \n    \"f36\": \"Mean\", \n    \"f37\": \"Median\", \n    \"f38\": \"Median\", \n    \"f39\": \"Median\", \n    \"f40\": \"Mode\", \n    \"f41\": \"Median\", \n    \"f42\": \"Mode\", \n    \"f43\": \"Mean\", \n    \"f44\": \"Median\", \n    \"f45\": \"Median\", \n    \"f46\": \"Mean\", \n    \"f47\": \"Mode\", \n    \"f48\": \"Mean\", \n    \"f49\": \"Mode\", \n    \"f50\": \"Mode\", \n    \"f51\": \"Median\", \n    \"f52\": \"Median\", \n    \"f53\": \"Median\", \n    \"f54\": \"Mean\", \n    \"f55\": \"Mean\", \n    \"f56\": \"Mode\", \n    \"f57\": \"Mean\", \n    \"f58\": \"Median\", \n    \"f59\": \"Median\", \n    \"f60\": \"Median\", \n    \"f61\": \"Median\", \n    \"f62\": \"Median\", \n    \"f63\": \"Median\", \n    \"f64\": \"Median\", \n    \"f65\": \"Mode\", \n    \"f66\": \"Median\", \n    \"f67\": \"Median\", \n    \"f68\": \"Median\", \n    \"f69\": \"Mean\", \n    \"f70\": \"Mode\", \n    \"f71\": \"Median\", \n    \"f72\": \"Median\", \n    \"f73\": \"Median\", \n    \"f74\": \"Mode\", \n    \"f75\": \"Mode\", \n    \"f76\": \"Mean\", \n    \"f77\": \"Mode\", \n    \"f78\": \"Median\", \n    \"f79\": \"Mean\", \n    \"f80\": \"Median\", \n    \"f81\": \"Mode\", \n    \"f82\": \"Median\", \n    \"f83\": \"Mode\", \n    \"f84\": \"Median\", \n    \"f85\": \"Median\", \n    \"f86\": \"Median\", \n    \"f87\": \"Median\", \n    \"f88\": \"Median\", \n    \"f89\": \"Median\", \n    \"f90\": \"Mean\", \n    \"f91\": \"Mode\", \n    \"f92\": \"Median\", \n    \"f93\": \"Median\", \n    \"f94\": \"Median\", \n    \"f95\": \"Median\", \n    \"f96\": \"Median\", \n    \"f97\": \"Mean\", \n    \"f98\": \"Median\", \n    \"f99\": \"Median\", \n    \"f100\": \"Mode\", \n    \"f101\": \"Median\", \n    \"f102\": \"Median\", \n    \"f103\": \"Median\", \n    \"f104\": \"Median\", \n    \"f105\": \"Median\", \n    \"f106\": \"Median\", \n    \"f107\": \"Median\", \n    \"f108\": \"Median\", \n    \"f109\": \"Mode\", \n    \"f110\": \"Median\", \n    \"f111\": \"Median\", \n    \"f112\": \"Median\", \n    \"f113\": \"Mean\", \n    \"f114\": \"Median\", \n    \"f115\": \"Median\", \n    \"f116\": \"Mode\", \n    \"f117\": \"Median\", \n    \"f118\": \"Mean\"\n}\n\n\nfor col in tqdm(features):\n    if fill_value_dict.get(col)==\"Mean\":\n        fill_value = df_train[col].mean()\n    elif fill_value_dict.get(col)==\"Median\":\n        fill_value = df_train[col].median()\n    elif fill_value_dict.get(col)==\"Mode\":\n        fill_value = df_train[col].mode().iloc[0]\n    \n    df_train[col].fillna(fill_value, inplace=True)\n    df_test[col].fillna(fill_value, inplace=True)","e37759b8":"%%time\n\npipe = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"constant\", missing_values=np.nan)),\n    (\"scaler\", RobustScaler())\n])\n\ndf_train[features] = pipe.fit_transform(df_train[features])\ndf_test[features] = pipe.transform(df_test[features])","158d7b6b":"def predict(model, df_train, df_test, folds=5):\n    test_preds = []\n    valid_preds = {}\n    scores = []\n    \n    params = {\n        \"random_state\": 42,        \n        \"n_estimators\" : 35000, \n        \"max_depth\" : 8,\n        \"learning_rate\" : 0.015144053813488484,\n        \"num_leaves\" : 351,\n        \"objective\" : \"binary\",\n        \"metric\" : \"auc\",\n        \"min_child_weight\" : 31.100300067957512,\n        \"subsample\" : 0.7096068189924443,\n        \"subsample_freq\" : 1,\n        \"colsample_bytree\" : 0.45821320586324304,\n        \"reg_alpha\" : 19.400000000000002,\n        \"reg_lambda\" : 5.2,\n        \"min_gain_to_split\" : 3.1\n    }\n    \n    for fold in range(folds):\n        x_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n        x_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        x_test = df_test.copy()\n        \n        valid_ids = x_valid.id.values.tolist()\n\n        y_train = x_train[TARGET]\n        y_valid = x_valid[TARGET]\n\n        x_train = x_train[features]\n        x_valid = x_valid[features]\n\n        model.fit(\n            x_train, y_train,\n            eval_set=[(x_valid, y_valid)],\n            eval_metric=\"auc\",\n            early_stopping_rounds=150,\n            verbose=1000\n        )\n        \n        valid_pred = model.predict_proba(x_valid)[:, 1]\n        test_pred = model.predict_proba(x_test)[:, 1]\n        \n        test_preds.append(test_pred)\n        valid_preds.update(dict(zip(valid_ids, valid_pred)))\n\n        score = roc_auc_score(y_valid, valid_pred)\n        print(f\"Fold {fold} | AUC: {score}\")\n        scores.append(score)\n    \n    test_preds = np.mean(np.column_stack(test_preds), axis=1)\n    valid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\n    \n    return test_preds, valid_preds, scores","939d6ffc":"lgb1_params = {\n    \"objective\": \"binary\",\n    \"n_estimators\": 10000,\n    \"random_state\": 42,\n    \"learning_rate\": 0.095,\n    \"subsample\": 0.6,\n    \"subsample_freq\": 1,\n    \"colsample_bytree\": 0.4,\n    \"reg_alpha\": 10.0,\n    \"reg_lambda\": 1e-1,\n    \"min_child_weight\": 256,\n    \"min_child_samples\": 20,\n    \"max_depth\" : 3,\n    \"num_leaves\" : 7\n}\n\nlgb2_params = {\n    \"random_state\": 0,\n    \"max_depth\" : 3,\n    \"num_leaves\" : 7,\n    \"n_estimators\" : 5000,\n    \"colsample_bytree\" : 0.3,\n    \"subsample\" : 0.5,\n    \"random_state\" : 42,\n    \"reg_alpha\" : 18,\n    \"reg_lambda\" : 17,\n    \"learning_rate\" : 0.095,\n    \"objective\" : \"binary\"\n}\n\nlgb3_params = {\n    \"random_state\": 100,\n    \"objective\": \"binary\",\n    \"learning_rate\": 0.008,\n    \"n_estimators\": 5000,\n    \"num_leaves\": 184,\n    \"min_child_samples\": 63,\n    \"feature_fraction\": 0.6864594334728974,\n    \"bagging_fraction\": 0.9497327922401265,\n    \"bagging_freq\": 1,\n    \"reg_alpha\": 19,\n    \"reg_lambda\": 19,\n}\n\nlgb4_params = {\n    \"random_state\": 7014,\n    \"n_estimators\": 6630, \n    \"objective\": \"binary\",\n    \"boosting\": \"gbdt\",\n    \"metric\" : \"auc\",\n    \"max_depth\": 3, \n    \"learning_rate\": 0.053625067203773684,\n    \"reg_alpha\": 4.618041066261469,\n    \"reg_lambda\": 7.9389723810790604,\n    \"num_leaves\": 203,\n    \"min_data_per_group\": 83, \n    \"min_child_samples\": 141, \n    \"colsample_bytree\": 0.13048987522123276   \n}","031dff2e":"models = [\n    (\"lgb1\", lgbm.LGBMClassifier(**lgb1_params)),\n    (\"lgb2\", lgbm.LGBMClassifier(**lgb2_params)),\n    (\"lgb3\", lgbm.LGBMClassifier(**lgb3_params)),\n    (\"lgb4\", lgbm.LGBMClassifier(**lgb4_params)),\n]","54c99b6a":"for name, model in models:\n    print(f\"Using model {name}...\")\n    test_preds, valid_preds, scores = predict(model, df_train, df_test)\n    print(np.mean(scores), np.std(scores))\n    \n    valid_preds.columns = [\"id\", f\"{name}_pred_5\"]\n    valid_preds.to_csv(f\"{name}_train_5.csv\", index=False)\n\n    test_preds_df = pd.DataFrame({\"id\": submission.id, f\"{name}_pred_5\": test_preds})\n    test_preds_df.to_csv(f\"{name}_test_5.csv\", index=False)\n\n    print(\"Saving...\")\n    sub = pd.DataFrame({\"id\": submission.id, \"claim\": test_preds})\n    sub.to_csv(f\"{name}_submission.csv\", index=False)","e5959250":"## Preprocessing","10c43ad0":"## Predict","80d9deb3":"## Feature engineering","92566782":"# TPS September 2021 - LightGBM Baseline","8b1f03af":"## Define models","937ad8d4":"# Import libraries","15818168":"## Predict","9a81f562":"## Load datasets"}}