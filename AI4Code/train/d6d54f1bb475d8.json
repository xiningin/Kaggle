{"cell_type":{"873cc36e":"code","271ebc88":"code","50ead004":"code","00edfc3f":"code","34958993":"code","1d941f18":"code","ea616ef8":"code","1ffae08e":"code","595d197c":"code","452e8a3e":"code","5bbebc85":"code","951d15cb":"code","1c16c998":"code","e7a930f1":"code","5f5336ec":"code","73fc2cf2":"code","2f285a02":"code","90ab4e67":"code","574b79ef":"code","d92ba346":"code","62857d4b":"code","9d802b0b":"code","e8253bfa":"code","6979fccc":"code","0560a095":"code","1f9c216a":"code","fa951fb8":"code","1070beff":"code","c9fc1deb":"code","188277d2":"code","de06f98c":"markdown","c278a1d3":"markdown","6f56a2ee":"markdown","be5b33b1":"markdown","e540ff29":"markdown","0d30ac18":"markdown","7e8d865b":"markdown","ccc6e898":"markdown","20ecc691":"markdown","eaef33af":"markdown","95ec4eaf":"markdown","ffa98b0a":"markdown","daaa2eb2":"markdown","65009e10":"markdown","1b885b4f":"markdown","9e64c69f":"markdown","07ba1bdf":"markdown","13a4d2a5":"markdown","7aec2932":"markdown","f7ed5a7a":"markdown","d3cd10ec":"markdown","ac9f5ff3":"markdown","345bd327":"markdown","46d85662":"markdown","5563e68d":"markdown","744e5766":"markdown","e827e90c":"markdown","903e9f3f":"markdown","7436c73b":"markdown","7a901f65":"markdown","32662daf":"markdown","3752fbe3":"markdown","676b07d9":"markdown","e9cfa3ab":"markdown"},"source":{"873cc36e":"#Import all the necessary packages\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\n#to scale the data using z-score \nfrom sklearn.preprocessing import StandardScaler\n\n#importing clustering algorithms\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\n\n\n#uncomment below to install the sklearn_extra library\n!pip install scikit-learn-extra\nfrom sklearn_extra.cluster import KMedoids\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","271ebc88":"data = pd.read_csv('..\/input\/credit-card-customer-data\/Credit Card Customer Data.csv')\ndata.head()","50ead004":"data.info()","00edfc3f":"data.nunique()\n#df.duplicated().sum()","34958993":"# Identify the duplicated customer keys\nduplicate_keys = data[data.duplicated('Customer Key')]\nprint(duplicate_keys)","1d941f18":"# Drop duplicated keys\n\ndata = data.drop_duplicates(subset='Customer Key', keep='first')","ea616ef8":"data.drop(columns = ['Sl_No', 'Customer Key'], inplace = True)","1ffae08e":"data[data.duplicated()]","595d197c":"data=data[~data.duplicated()]","452e8a3e":"data.shape","5bbebc85":"data.describe().T","951d15cb":"# Uncomment and complete the code by filling the blanks \n\nfor col in data.columns:\n    print(col)\n    print('Skew :',round(data[col].skew(),2))\n    plt.figure(figsize=(15,4))\n    plt.subplot(1,2,1)\n    data[col].hist(bins=10, grid=False)\n    plt.ylabel('count')\n    plt.subplot(1,2,2)\n    sns.boxplot(x=data[col])\n    plt.show()","1c16c998":"plt.figure(figsize=(8,8))\nsns.heatmap(data.corr(), annot=True, fmt='0.2f')\nplt.show()","e7a930f1":"scaler=StandardScaler()\ndata_scaled=pd.DataFrame(scaler.fit_transform(data), columns=data.columns)","5f5336ec":"data_scaled.head()","73fc2cf2":"#Creating copy of the data to store labels from each algorithm\ndata_scaled_copy = data_scaled.copy(deep=True)","2f285a02":"# step 1\nsse = {} \n\n# step 2 - iterate for a range of Ks and fit the scaled data to the algorithm. Use inertia attribute from the clustering object and \n# store the inertia value for that k \nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000, random_state=1).fit(data_scaled)\n    sse[k] = kmeans.inertia_\n\n# step 3\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()), 'bx-')\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","90ab4e67":"kmeans = KMeans(n_clusters=3, random_state=1) #Apply the K-Means algorithm\nkmeans.fit(data_scaled) #Fit the kmeans function on the scaled data\n\n#Adding predicted labels to the original data and scaled data \ndata_scaled_copy['Labels'] = kmeans.predict(data_scaled) #Save the predictions on the scaled data from K-Means\ndata['Labels'] = kmeans.predict(data_scaled) #Save the predictions on the scaled data from K-Means","574b79ef":"#Number of observations in each cluster\ndata.Labels.value_counts()","d92ba346":"#Calculating summary statistics of the original data for each label\nmean = data.groupby('Labels').mean()\nmedian = data.groupby('Labels').median()\ndf_kmeans = pd.concat([mean, median], axis=0)\ndf_kmeans.index = ['group_0 Mean', 'group_1 Mean', 'group_2 Mean', 'group_0 Median', 'group_1 Median', 'group_2 Median']\ndf_kmeans.T","62857d4b":"#Visualizing different features w.r.t K-means labels\ndata_scaled_copy.boxplot(by = 'Labels', layout = (1,5),figsize=(20,7))\nplt.show()","9d802b0b":"gmm = GaussianMixture(n_components = 3, random_state = 1) #Apply the Gaussian Mixture algorithm\ngmm.fit(data_scaled) #Fit the gmm function on the scaled data\n\ndata_scaled_copy['GmmLabels'] = gmm.predict(data_scaled)\ndata['GmmLabels'] = gmm.predict(data_scaled)","e8253bfa":"#Number of observations in each cluster\ndata.GmmLabels.value_counts()","6979fccc":"#Calculating summary statistics of the original data for each label\noriginal_features = [\"Avg_Credit_Limit\",\"Total_Credit_Cards\",\"Total_visits_bank\",\"Total_visits_online\",\"Total_calls_made\"]\n\nmean = data.groupby('GmmLabels').mean()\nmedian = data.groupby('GmmLabels').median()\ndf_gmm = pd.concat([mean, median], axis=0)\ndf_gmm.index = ['group_0 Mean', 'group_1 Mean', 'group_2 Mean', 'group_0 Median', 'group_1 Median', 'group_2 Median']\ndf_gmm[original_features].T","0560a095":"# plotting boxplots with the new GMM based labels\n\nfeatures_with_lables = [\"Avg_Credit_Limit\",\"Total_Credit_Cards\",\"Total_visits_bank\",\"Total_visits_online\",\"Total_calls_made\",\"GmmLabels\"]\n\ndata_scaled_copy[features_with_lables].boxplot(by = 'GmmLabels', layout = (1,5),figsize=(20,7))\nplt.show()","1f9c216a":"kmedo = KMedoids(n_clusters = 3, random_state=1) #Apply the K-Medoids algorithm\nkmedo.fit(data_scaled) #Fit the kmedo function on the scaled data\n\ndata_scaled_copy['kmedoLabels'] = kmedo.predict(data_scaled)\ndata['kmedoLabels'] = kmedo.predict(data_scaled)","fa951fb8":"#Number of observations in each cluster\ndata.kmedoLabels.value_counts()","1070beff":"#Calculating summary statistics of the original data for each label\nmean = data.groupby('kmedoLabels').mean()\nmedian = data.groupby('kmedoLabels').median()\ndf_kmedoids = pd.concat([mean, median], axis=0)\ndf_kmedoids.index = ['group_0 Mean', 'group_1 Mean', 'group_2 Mean', 'group_0 Median', 'group_1 Median', 'group_2 Median']\ndf_kmedoids[original_features].T","c9fc1deb":"#plotting boxplots with the new DBScan based labels\n\nfeatures_with_lables = [\"Avg_Credit_Limit\",\t\"Total_Credit_Cards\",\"Total_visits_bank\",\"Total_visits_online\",\"Total_calls_made\",\"kmedoLabels\"]\n\ndata_scaled_copy[features_with_lables].boxplot(by = 'kmedoLabels', layout = (1,5),figsize=(20,7))\nplt.show()","188277d2":"comparison = pd.concat([df_kmedoids, df_kmeans], axis=1)[original_features]\ncomparison","de06f98c":"## K-Medoids","c278a1d3":"- **Applying the K-Mediods on the scaled data with random_state=1** \n- **Create cluster profiles using the below summary statistics and box plots for each label**\n- **Compare the clusters from both algorithms - K-Means and K-Medoids**","6f56a2ee":"## Gaussian Mixture","be5b33b1":"Let us now fit k-means algorithm on our scaled data and find out the optimum number of clusters to use.\n\nWe will do this in 3 steps:\n1. Initialize a dictionary to store the SSE for each k\n2. Run for a range of Ks and store SSE for each run\n3. Plot the SSE vs K and find the elbow","e540ff29":"#### Summary Statistics","0d30ac18":"#### **Creating cluster profiles using the below summary statistics and box plots for each label**","7e8d865b":"**Cluster Profiles:\n- This looks like somewhat skewed clustering with a few observations in one cluster (49) and more than 200 in other 2.\n- Looks like Cluster 2 has the highest average credit limits and highest number of total credit cards while having only 49 memebers in the cluster. This means we can say they are the richest customers.\n- Looks like Cluster 0 has the lowest average credit limits and lowest number of total credit cards while having highest number of memebers in the cluster (374). This means we can say cluster 0 consist with poor customers.\n- Cluster 2 customers mostly do online bank visists while doing very less (~1) number of average calls and bank visits whci means rich customers tend to do online banking more.\n- Cluster 1 customers mostly do bank visits.\n- Cluster 0 customers mostly tend to call the bank for get done services  whcih means poor customers tend to call the the bank more than other customers.\n\n- Overall, this clustering solution does give us good insights into potential clusters of similar customer groupes but we see some outliers with average credit limit and total online visits in group 0 which is the biggest cluster.**\n\n**Comparing Clusters:\n- Also, k means and GMM seems to have the same cluster output. Both holds same size clusetrs with same cluster profiles.**","ccc6e898":"**Observation:\n- Average credit limits and Total online visists have higher skewed distributions\n- The distributions for the Total credit cards and Total bank visists have relatively less skewed with no outliers.\n- Total calls made also has relatively lower skewed with no outliers but it is still higher than the skewness of Total credit cards and Total bank visists distribution.\n- Average credit limit and Total online visists are skewed to the right and those have some outliers to the right end. This means most of the customers has lower average credit limit and lower online visits.\n**","20ecc691":"**Observations:**\n\n- There are 660 observations and 7 columns in the dataset.\n- All columns have 660 non-null values i.e. there are no missing values.\n- All columns are of int64 data type.","eaef33af":"## Project: Unsupervised Learning - Clustering - Credit Card Customer Spending Profiles\n----------------------------------------\n\n----------------------------\n## Objective: \n-----------------------------\n\nIdentify different segments in the existing customer based on their spending patterns as well as past interaction with the bank. Models used: K-Means, Gaussian Mixture, K-Medoid \n\n--------------------------\n## About the data:\n--------------------------\nData is of various customers of a bank with their credit limit, the total number of credit cards the customer has, and different channels through which customer has contacted the bank for any queries, different channels include visiting the bank, online and through a call centre.\n\n- Sl_no - Customer Serial Number\n- Customer Key - Customer identification\n- Avg_Credit_Limit\t- Average credit limit (currency is not specified, you can make an assumption around this)\n- Total_Credit_Cards\t- Total number of credit cards \n- Total_visits_bank\t- Total bank visits\n- Total_visits_online -\t Total online visits\n- Total_calls_made - Total calls made","95ec4eaf":"**There are no missing values. Let us now figure out the uniques in each column.** ","ffa98b0a":"**Cluster Profiles:**\n- This looks like with little skewed clustering with 2 clusters has almost similar size and 1 cluster is nearly 100 count lesser tha other 2 but all 3 cluster hold size >100.\n- Looks like Cluster 1 has the highest average credit limits and highest number of total credit cards. This means we can say they are the richest customers.\n- Looks like Cluster 0 has the lowest average credit limits and lowest number of total credit cards. This means we can say cluster 0 consist with poor customers.\n- Cluster 1 customers mostly do online bank visists while doing very less (~2) number of average calls and bank visits whci means rich customers tend to do online banking more.\n- Cluster 2 customers holds highest number of bank visits.\n- Cluster 0 customers mostly tend to call the bank for get done services  and average number of calls are almost similar for customers in cluster 1 and 2.\n\n- Overall, this clustering solution does give us good insights into potential clusters of similar customer groupes with almost similar group sizes but with some outliers.**\n\n**Comparing Clusters:**\n- **Comparing the clustor size and outcome of the cluster algorithm, we can say K-Medoid is better tha K-Means clustering for this particular problem. Both cluster algorithms defferentiate groupes as rich cutomers and poor customers but in here, K-Medoid has less skewed distribution of data than K-Means**","daaa2eb2":"**Cluster Profiles:**\n- This looks like somewhat skewed clustering with a few observations in one cluster (49) and more than 200 in other 2.\n- Looks like Cluster 2 has the highest average credit limits and highest number of total credit cards while having only 49 memebers in the cluster. This means we can say they are the richest customers.\n- Looks like Cluster 0 has the lowest average credit limits and lowest number of total credit cards while having highest number of memebers in the cluster (374). This means we can say cluster 0 consist with poor customers.\n- Cluster 2 customers mostly do online bank visists while doing very less (~1) number of average calls and bank visits whci means rich customers tend to do online banking more.\n- Cluster 1 customers mostly do bank visits.\n- Cluster 0 customers mostly tend to call the bank for get done services  whcih means poor customers tend to call the the bank more than other customers.\n\n- Overall, this clustering solution does give us good insights into potential clusters of similar customer groupes but we see some outliers with average credit limit and total online visits in group 0 which is the biggest cluster.\n**","65009e10":"Let's create clusters using Gaussian Mixture Models","1b885b4f":"We have generated the labels with k-means. Let us look at the various features based on the labels.","9e64c69f":"## K-Means","07ba1bdf":"- After removing duplicated keys and rows and unnecessary columns, there are 644 unique observations and 5 columns in our data.","13a4d2a5":"#### Now let's go ahead with the exploring each variable at hand. We will check the distribution and outliers for each variable in the data.","7aec2932":"**Now, let's check the correlation among different variables.**","f7ed5a7a":"- **Applying the Gaussian Mixture algorithm on the scaled data with random_state=1** \n- **Creating cluster profiles using the below summary statistics and box plots for each label**\n- **Comparing the clusters from both algorithms - K-means and Gaussian Mixture**","d3cd10ec":"- Looking at the plot, we can say that elbow point is achieved for k=3.\n- We will fit the k-means again with k=3 to get the labels.","ac9f5ff3":"#### Loading data","345bd327":"We can drop these duplicated rows from the data","46d85662":"## Importing libraries and overview of the dataset","5563e68d":"Let's compare the clusters from K-Means and K-Medoids ","744e5766":"**Observations:**\n\n- The average credit limit has a range from 3000 to 200000. The average of average credit limit of a customer is approx 34544.\n- The total number of credit card owned by customer has a range of 1 to 10. Average number of credeit cards holds by a cutomer is typically around 5.\n- The average total bankvisits and average total online visists by a cutomer is less than average total calls made to bank.\n- Total customer bank visits ranges between 0 to 10 and total online visists rages between 0 to 15. This means there are some customers who had never done a bank visit or an online vistit.\n- Total calls made by a customer israges between 1 and 10 which means all the customers made calls to the bank at least once.**","e827e90c":"- Customer key, which is an identifier, has repeated values. We should treat the same accordingly before applying any algorithm.","903e9f3f":"Now that we have dropped unnecessary column. We can again check for duplicates. Duplicates would mean customers with identical features.","7436c73b":"#### Scaling the data","7a901f65":"## Data Preprocessing and Exploratory Data Analysis","32662daf":"**Observation:**\n\n- Avg_Credit_Limit is positively correlated with Total_Credit_Cards Total_visits_online which can makes sense.\n- Avg_Credit_Limit is negatively correlated with Total_calls_made and Total_visits_bank.\n- Total_visits_bank, Total_visits_online, Total_calls_made are negatively correlated which implies that majority of customers use only one of these channels to contact the bank.","3752fbe3":"#### Check the info of the data","676b07d9":"We have done some basic checks. Now, let's drop the variables that are not required for our analysis.","e9cfa3ab":"- **Here, I have selected K=3 because, We can see from the plot that there is a highest drop from 1 to 3 and the a consistent dip from 3 to 9. So we may chose 3 as the number of clusters.**\n- **Fit the K-means algorithms on the scaled data with number of cluster equal to 3 (2 Mark)**\n- **Store the predictions as 'Labels' to the 'data_scaled_copy' and 'data' dataframes (2 Marks)**"}}