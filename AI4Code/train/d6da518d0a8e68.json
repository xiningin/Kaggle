{"cell_type":{"3087fcec":"code","4395e464":"code","4940ccc4":"code","8e88f1e4":"code","ff28ee6b":"code","e08b94b3":"markdown"},"source":{"3087fcec":"import numpy as np \nimport pandas as pd \nimport sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport keras\nimport matplotlib.pyplot as plt\ndf = pd.read_csv(\"..\/input\/all_data.csv\")\nn_samples = 10000\nrecent_tags = df['tags'].tail(n_samples)","4395e464":"count_vectorizer = CountVectorizer(min_df=0.01,\n                                   analyzer=lambda x: x.split(' ')\n                                  )\ncount_vectorizer.fit(recent_tags)\n\nN_CLASSES = len(count_vectorizer.vocabulary_)\n\ndef fit_generator(all_tags):\n    while True:\n        for tags in all_tags:\n            words = count_vectorizer.transform(tags.split(' ')).toarray()\n            contexts = count_vectorizer.transform([tags]).toarray().repeat(len(words), axis=0)\n            yield words, contexts\n","4940ccc4":"model = keras.models.Sequential()\nmodel.add(keras.layers.InputLayer((N_CLASSES,)))\nmodel.add(keras.layers.Dense(2))\nmodel.add(keras.layers.Activation('linear',name='embedding'))\nmodel.add(keras.layers.Dense(N_CLASSES))\nmodel.add(keras.layers.Activation('sigmoid'))\nmodel.summary()\n\nembedding = keras.models.Model(inputs=model.input, outputs=model.get_layer('embedding').output)","8e88f1e4":"model.compile(loss='binary_crossentropy',\n             optimizer=keras.optimizers.Adam(0.001),\n             metrics=[])\nmodel.fit_generator(fit_generator(recent_tags), \n                   epochs=10,\n                   steps_per_epoch=n_samples,\n                   callbacks=[keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=2, verbose=0, mode='auto')],\n                   verbose=2)","ff28ee6b":"keys = count_vectorizer.vocabulary_.keys()\ninput_vecs = count_vectorizer.transform(keys).toarray()\nlatents = embedding.predict_on_batch(input_vecs)\nplt.figure(figsize=(30,30))\ncolors = ['b','g','r','c','m','y','k']\nfor k, l in zip(keys, latents):\n    plt.scatter(latents.T[0], latents.T[1])\nfor k, l in zip(keys, latents):\n    plt.text(l[0], l[1], k,\n             alpha=0.5, \n             color=colors[np.random.randint(0, len(colors))],\n             rotation=np.random.randint(-30, 30))","e08b94b3":"One can expect that related tags like `tohou` and `alice_margatroid` should cluster together."}}