{"cell_type":{"983423bf":"code","c37b68b5":"code","51e5d473":"code","f5d3d5c6":"code","b6bede6c":"code","bcd248f3":"code","083e7ea9":"code","40220cfc":"code","75caca74":"code","e838fbb8":"code","a28d4382":"code","32e5019c":"code","68def25c":"code","8f74b146":"code","e570cae5":"code","1e959996":"code","b0ae33a2":"code","f0ad4d92":"code","8d2d5583":"code","db2dacdb":"code","c0652bd1":"code","74ed3e08":"code","b1eacaaa":"code","d73f6796":"code","bd8fcbf0":"code","3e588a14":"code","c2be303d":"code","61830f21":"code","55f92b6a":"code","e11e9c97":"code","93897786":"code","455b3b5d":"code","f42d6b67":"code","8f148245":"code","3400aa0d":"code","95cac771":"code","417ef7cc":"code","24dacf5b":"code","0b238b1f":"code","96cddd97":"code","0ab40c10":"code","2985151c":"code","393d60b1":"code","d1c7428c":"code","288338d0":"code","0a4550b3":"code","7d4e5194":"code","618e4d4b":"code","fff52920":"code","5057716d":"code","cf1b0835":"code","0e470b8e":"code","a76e7bd9":"code","780a86d2":"code","d1a1be33":"code","8c628e3a":"code","d00cd474":"code","761b826f":"code","18c894be":"code","0b08cd38":"code","825a016e":"code","37731e74":"code","d9fd6245":"code","ec27aa22":"code","b850e74b":"code","a3914de0":"code","36352a9b":"code","478e1630":"code","6af2975f":"code","0e047617":"code","af076341":"code","937b29d7":"code","914534dc":"code","64ea63ad":"code","9179519e":"code","3cabf074":"code","2b540cd8":"code","d9c6318e":"code","6a0196a6":"code","00e8b772":"code","c867415e":"code","6295c3ff":"code","f6a43093":"code","b35cd17d":"code","d3f1f942":"code","b9c71689":"code","160439cc":"code","65c4a871":"code","a37d29b0":"code","c676ba5b":"code","127babe2":"code","7af55db0":"code","63fa2335":"code","fc05f83a":"code","5af4e3ad":"code","d47cfcf8":"code","5f5115ce":"code","c9fa755a":"code","ef1ad9f4":"code","2dacf29d":"code","4f671515":"code","ebaaa7eb":"code","82cc32ea":"code","d28a9edd":"code","08322c57":"code","e0cabc90":"markdown","afcda090":"markdown","668cde59":"markdown","5b4e60b7":"markdown","81dc8b16":"markdown","d4dac5cb":"markdown","304a25c2":"markdown","095762eb":"markdown","ec7afc93":"markdown"},"source":{"983423bf":"# Imports \n\n# Imports para manipula\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados\nimport pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# Imports para manipula\u00e7\u00e3o de imagens\nimport os \nimport sklearn\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n# Imports para c\u00e1lculo de m\u00e9tricas e utilit\u00e1rios\nimport itertools\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# Imports para Deep Learning\nimport tensorflow\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPool2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom keras.utils.np_utils import to_categorical\nfrom keras.applications import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input\n\n# As novas vers\u00f5es do Pandas e Matplotlib trazem diversas mensagens de aviso ao desenvolvedor. Vamos desativar isso.\nimport sys\nimport warnings\nimport matplotlib.cbook\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=matplotlib.cbook.mplDeprecation)\n\n%matplotlib inline","c37b68b5":"metadata = pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv')","51e5d473":"metadata.head(10)","f5d3d5c6":"metadata['dx'].value_counts()","b6bede6c":"metadata = metadata[metadata['dx'] != 'df']\nmetadata = metadata[metadata['dx'] != 'vasc']\nmetadata = metadata[metadata['dx'] != 'akiec']\nmetadata = metadata[metadata['dx'] != 'bcc']","bcd248f3":"metadata['dx'].value_counts()","083e7ea9":"metadata.drop(columns=[\"lesion_id\", \"dx_type\", \"age\", \"sex\", \"localization\"], axis = 1, inplace = True)","40220cfc":"metadata.shape","75caca74":"metadata['tipo_cancer_idx'] = pd.Categorical(metadata['dx']).codes","e838fbb8":"metadata.sample(5)","a28d4382":"metadata['tipo_cancer_idx'].unique()","32e5019c":"img_part1 = os.listdir('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1\/')\nimg_part2 = os.listdir('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2\/')","68def25c":"img_part1[1:5]","8f74b146":"def extrai_path_img(x):\n    \n    file = x + '.jpg'\n    \n    if file in img_part1:\n        \n        return os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1\/', file)\n    \n    elif file in img_part2:\n        \n        return os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2\/', file)\n    \n     \n    ","e570cae5":"metadata['image'] = metadata['image_id'].apply(extrai_path_img)","1e959996":"metadata.sample(5)","b0ae33a2":"metadata.shape","f0ad4d92":"metadata['tipo_cancer_idx'].value_counts()","8d2d5583":"metadata.tipo_cancer_idx.value_counts() \/ metadata.shape[0] * 100","db2dacdb":"df_nv = metadata[metadata['dx'] == 'nv']\ndf_not_nv = metadata[metadata['dx'] != 'nv']","c0652bd1":"df_nv = shuffle(df_nv)","74ed3e08":"df_nv.count()","b1eacaaa":"df_nv = df_nv.head(1500)","d73f6796":"df_nv = df_nv.reset_index(drop = True)","bd8fcbf0":"dataset_final = pd.concat([df_nv, df_not_nv])","3e588a14":"dataset_final.shape","c2be303d":"dataset_final['dx'].value_counts()","61830f21":"dataset_final.dx.value_counts() \/ dataset_final.shape[0] * 100","55f92b6a":"df_nv = dataset_final[dataset_final['dx'] == 'nv']\ndf_nv = shuffle(df_nv)\ndf_nv = df_nv.head(100)\ndf_nv = df_nv.reset_index(drop = True)\n\ndf_mel = dataset_final[dataset_final['dx'] == 'mel']\ndf_mel = shuffle(df_mel)\ndf_mel = df_mel.head(100)\ndf_mel = df_mel.reset_index(drop = True)\n\ndf_bkl = dataset_final[dataset_final['dx'] == 'bkl']\ndf_bkl = shuffle(df_bkl)\ndf_bkl = df_bkl.head(100)\ndf_bkl = df_bkl.reset_index(drop = True)","e11e9c97":"df_test = pd.concat([df_nv, df_mel, df_bkl])","93897786":"df_test = shuffle(df_test)","455b3b5d":"df_test = df_test.reset_index(drop = True)","f42d6b67":"df_test.dx.value_counts()","8f148245":"df_treino = dataset_final","3400aa0d":"keys = list(df_treino.columns.values)","95cac771":"i1 = df_treino.set_index(keys).index\ni2 = df_test.set_index(keys).index","417ef7cc":"i2","24dacf5b":"keys","0b238b1f":"df_treino = df_treino[~i1.isin(i2)]","96cddd97":"df_treino.shape","0ab40c10":"df_test['image'][15]","2985151c":"'..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1\/ISIC_0028504.jpg' in df_treino.image.values","393d60b1":"df_treino = df_treino.reset_index(drop = True)","d1c7428c":"df_treino['image'][10]","288338d0":"caminho_imagem = df_treino['image'][10]","0a4550b3":"imagem = Image.open(caminho_imagem)","7d4e5194":"imagem.size","618e4d4b":"imagem.width","fff52920":"imagem.height","5057716d":"df_treino.head()","cf1b0835":"df_treino['imagem_res'] = df_treino['image'].map( lambda x: np.asarray(Image.open(x).resize((112, 112))))","0e470b8e":"df_treino.head()","a76e7bd9":"df_treino.set_index(\"image_id\", inplace = True)","780a86d2":"df_treino.head()","d1a1be33":"df_treino.head()","8c628e3a":"df_treino.shape","d00cd474":"df_treino.imagem_res[0].shape","761b826f":"df_test['imagem_res'] = df_test[\"image\"].map(lambda x: np.asarray(Image.open(x).resize((112, 112))))","18c894be":"df_test.head()","0b08cd38":"df_test = df_test.set_index(\"image_id\")","825a016e":"df_test.head()","37731e74":"df_test['imagem_res'][10].shape","d9fd6245":"# Plot\n\n# N\u00famero de amostras\nn_samples = 6\n\n# Figura e subplots\nfig, m_axs = plt.subplots(3, n_samples, figsize = (3 * n_samples, 2 * 5))\n\n# Loop pelos eixos\n# Retorna o nome da classe e o n\u00famero de imagens da classe\nfor n_axs, (type_name, type_rows) in zip(m_axs, df_treino.sort_values(['dx']).groupby('dx')):\n    \n    # T\u00edtulo de cada classe\n    n_axs[0].set_title(type_name, color = 'blue')\n    \n    # Loop pelas amostras \n    # Retiramos amostras rand\u00f4micas do total de imagens\n    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state = 1234).iterrows()):\n        c_ax.imshow(c_row['imagem_res'])\n        c_ax.axis('off')","ec27aa22":"# Total de amostras em treino\ndf_treino['imagem_res'].map(lambda x: x.shape).value_counts()","b850e74b":"# Total de amostras em teste\ndf_test['imagem_res'].map(lambda x: x.shape).value_counts()","a3914de0":"df_treino = shuffle(df_treino)\ndf_test = shuffle(df_test)","36352a9b":"y_treino = df_treino['tipo_cancer_idx']\ny_teste = df_test['tipo_cancer_idx']","478e1630":"y_treino.shape","6af2975f":"y_teste.shape","0e047617":"# Convertendo para o tipo categ\u00f3rico\n# o y_treino est\u00e1 como um vetor unidimensional, mas pra que ele represente\n# as 3 classes de forma correta, precisa ser categorico\ny_treino = to_categorical(y_treino, num_classes = 3)\ny_teste = to_categorical(y_teste, num_classes = 3)","af076341":"y_treino.shape","937b29d7":"y_teste.shape","914534dc":"# Extra\u00edndo apenas as imagens do dataframe, convertendo para lista e ent\u00e3o criamos um array numpy\nx_treino = np.asarray(df_treino['imagem_res'].tolist())\nx_teste = np.asarray(df_test['imagem_res'].tolist())","64ea63ad":"# Calculando a m\u00e9dia e desvio padr\u00e3o para poder aplicar a normaliza\u00e7\u00e3o nos dados\nx_treino_mean = np.mean(x_treino)\nx_treino_std = np.std(x_treino)","9179519e":"# Calculando a m\u00e9dia e desvio padr\u00e3o para poder aplicar a normaliza\u00e7\u00e3o nos dados\nx_teste_mean = np.mean(x_teste)\nx_teste_std = np.std(x_teste)","3cabf074":"# Normaliza\u00e7\u00e3o em treino\nx_treino = (x_treino - x_treino_mean) \/ x_treino_std","2b540cd8":"# Normaliza\u00e7\u00e3o em teste\nx_teste = (x_teste - x_teste_mean) \/ x_teste_std","d9c6318e":"x_treino.shape","6a0196a6":"x_teste.shape","00e8b772":"x_treino, x_valid, y_treino, y_valid = train_test_split(x_treino, y_treino,\n                                                        test_size = 0.1, random_state = 42)","c867415e":"print(\"shape de x_treino\", x_treino.shape)\nprint(\"shape de y_treino\", y_treino.shape)\nprint(\"shape de x_valid\", x_valid.shape)\nprint(\"shape de y_valid\", y_valid.shape)","6295c3ff":"# Caso n\u00e3o estivesse no formato correto, poderia ser feito o reshape.\n# x_treino = x_treino.reshape(x_treino.shape[0], *(112, 112, 3))\n# x_valid = x_valid.reshape(x_valid.shape[0], *(112, 112, 3))","f6a43093":"# Hiperpar\u00e2metros\n\n# Shape das imagens\ninput_shape = (112, 112, 3)\n\n# N\u00famero de classes a prever\nnum_classes = 3 \n\n# N\u00famero de \u00e9pocas de treinamento\nepochs = 50\n\n# Tamanho do batch\nbatch_size = 32\n\n# Taxa de aprendizado\nlr_param = 0.0001\n\n# Par\u00e2metros beta\nbeta_1_param = 0.9\nbeta_2_param = 0.999\n\n# Decay\ndecay_param = 0.0\n\n# Passos por \u00e9poca\nsteps_per_epoch_param = x_treino.shape[0] \/\/ batch_size","b35cd17d":"import tensorflow as tf\nmodel_base = tf.keras.applications.InceptionV3(weights = 'imagenet',\n                                              include_top = False,\n                                               input_shape = input_shape\n                                              )","d3f1f942":"model_base.summary()","b9c71689":"# Adicionamos nossas camadas ao modelo_base\n\n# Cria a sequ\u00eancia de camadas\nadd_model = Sequential()\n\n# Adiciona primeiro o modelo base\nadd_model.add(model_base)\n\n# Precisamos de uma camada global de Pooling\nadd_model.add(GlobalAveragePooling2D())\n\n# Dropout para regulariza\u00e7\u00e3o e evitar overfitting\nadd_model.add(Dropout(0.5))\n\n# Camada densa na camada final com ativa\u00e7\u00e3o softmax para previs\u00e3o das probabilidades das classes\nadd_model.add(Dense(num_classes, activation = 'softmax'))","160439cc":"modelo_final = add_model\nmodelo_final.summary()","65c4a871":"# Cria o otimizador\notimizador = Adam(lr = lr_param, \n                  beta_1 = beta_1_param, \n                  beta_2 = beta_2_param, \n                  epsilon = None, \n                  decay = decay_param, \n                  amsgrad = False)","a37d29b0":"# Compila o modelo com o otimizador, fun\u00e7\u00e3o de custo e m\u00e9tricas que ser\u00e3o extra\u00eddas no treinamento\nmodelo_final.compile(optimizer = otimizador, \n                     loss = \"categorical_crossentropy\", \n                     metrics = [\"accuracy\"])","c676ba5b":"# Regra para a redu\u00e7\u00e3o da taxa de aprendizado\nreduz_taxa_aprendizado = ReduceLROnPlateau(monitor = 'val_accuracy', \n                                           patience = 3, \n                                           verbose = 1, \n                                           factor = 0.5, \n                                           min_lr = 0.00001)","127babe2":"# Gerador de dados para o treinamento\ndatagen = ImageDataGenerator(featurewise_center = False,  \n                             samplewise_center = False,  \n                             featurewise_std_normalization = False,  \n                             samplewise_std_normalization = False, \n                             zca_whitening = False,  \n                             rotation_range = 10,  \n                             zoom_range = 0.1, \n                             width_shift_range = 0.1,  \n                             height_shift_range = 0.1,  \n                             horizontal_flip = False,  \n                             vertical_flip = False) ","7af55db0":"%%time\n\nprint(\"\\nIniciando o Treinamento do Modelo.\\n\")\n\nhistory = modelo_final.fit(datagen.flow(x_treino, \n                                        y_treino, \n                                        batch_size = batch_size),\n                           epochs = epochs, \n                           validation_data = (x_valid, y_valid),\n                           verbose = 1, \n                           steps_per_epoch = steps_per_epoch_param, \n                           callbacks = [reduz_taxa_aprendizado])\n\nprint(\"\\nTreinamento Conclu\u00eddo.\\n\")","63fa2335":"# Plot da Acur\u00e1cia\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Acur\u00e1cia do Modelo')\nplt.ylabel('Acur\u00e1cia')\nplt.xlabel('Epoch')\nplt.legend(['Treino', 'Valida\u00e7\u00e3o'], loc = 'upper left')\nplt.show()","fc05f83a":"# Plot do Erro\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Erro do Modelo')\nplt.ylabel('Erro')\nplt.xlabel('Epoch')\nplt.legend(['Treino', 'Valida\u00e7\u00e3o'], loc = 'upper left')\nplt.show()","5af4e3ad":"# Calcula as m\u00e9tricas com dados de valida\u00e7\u00e3o para comparar com a performance em teste\nloss_v, accuracy_v = modelo_final.evaluate(x_valid, y_valid, verbose = 1)","d47cfcf8":"# Calcula as m\u00e9tricas com dados de teste\nloss, accuracy = modelo_final.evaluate(x_teste, y_teste, verbose = 1)","5f5115ce":"# Predict in test data\nY_pred = modelo_final.predict(x_teste)","c9fa755a":"#  One-hot encoding the classes\nY_pred_classes = np.argmax(Y_pred, axis = 1) ","ef1ad9f4":"# Extracting the real label\nY_true_classes = np.argmax(y_teste, axis = 1) ","2dacf29d":"# Criamos a Matriz de Confus\u00e3o\nprint(confusion_matrix(Y_true_classes, Y_pred_classes))","4f671515":"# Gravamos a Matriz de Confus\u00e3o\nmatriz = confusion_matrix(Y_true_classes, Y_pred_classes)","ebaaa7eb":"# Lista de classes\nclasses = ['bkl','mel', 'nv']","82cc32ea":"# Fun\u00e7\u00e3o para o plot\ndef plot_confusion_matrix(cm, \n                          classes,\n                          normalize = False,\n                          title = 'Matriz de Confus\u00e3o',\n                          cmap = plt.cm.Blues):\n\n    # Verifica se criaremos matriz normalizada ou n\u00e3o\n    import itertools\n    \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Matriz de Confus\u00e3o Normalizada\")\n    else:\n        print('Matriz de Confus\u00e3o Sem Normaliza\u00e7\u00e3o')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, \n                 format(cm[i, j], fmt), \n                 horizontalalignment = \"center\", \n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('Label Real')\n    plt.xlabel('Label Previsto')\n    plt.tight_layout()","d28a9edd":"# Plot\nplot_confusion_matrix(matriz, classes = classes, normalize = True ) ","08322c57":"# Relat\u00f3rio de Classifica\u00e7\u00e3o\nprint(classification_report(Y_true_classes, Y_pred_classes))","e0cabc90":"Redimensionando as Imagens","afcda090":"Com \u00e9 possivel ver, a iamgem de teste n\u00e3o est\u00e1 presente no dataset de treino, foi retirada com sucesso.","668cde59":"Preparando as amostras de teste","5b4e60b7":"Dividindo os dados em Treino e Valida\u00e7\u00e3o.","81dc8b16":"Aplicando o Undersampling em NV (2)","d4dac5cb":"Divis\u00e3o em Dados de Treino e Valida\u00e7\u00e3o ( Teste durante o treinamento )","304a25c2":"Constru\u00e7\u00e3o do Modelo \nAs imagens s\u00e3o coloridas, portanto, \u00e9 necess\u00e1rio uma Rede Neural Convolucional Profunda\n\nSer\u00e1 utilizado a arquitetura inceptionv3 com um modelo pre-treinado oferecido pelo keras","095762eb":"Tratando agora das imagens","ec7afc93":"Preparando as amostras de Treino"}}