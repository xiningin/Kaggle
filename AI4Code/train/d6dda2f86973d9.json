{"cell_type":{"4dcc64ca":"code","f7e7b639":"code","ad286b21":"code","dc2e3745":"code","c180cb15":"code","5811fe8d":"code","84bfafe8":"code","23206629":"code","bb01eaaf":"code","b7bea311":"code","74cf30ec":"code","98aa35eb":"markdown","6d31376d":"markdown","41794624":"markdown","49131a31":"markdown","9a0244c0":"markdown","8b8c7378":"markdown","147b7f61":"markdown","3426ec59":"markdown","d927a9b2":"markdown","38ac75b2":"markdown","ed65d2f1":"markdown","b22a2c0a":"markdown","a7ba11f4":"markdown"},"source":{"4dcc64ca":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor","f7e7b639":"X_full = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_full.head()","ad286b21":"X_test_full = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\nX_test_full.head()","dc2e3745":"X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)","c180cb15":"X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, train_size=0.8, test_size=0.2, random_state=0)\ncategorical_cols = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].nunique() < 10 and \n                    X_train_full[cname].dtype == \"object\"]\n\nnumerical_cols = [cname for cname in X_train_full.columns if \n                X_train_full[cname].dtype in ['int64', 'float64']]\n\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\nX=X_full[my_cols].copy()","5811fe8d":"X_train.head()","84bfafe8":"numerical_transformer = SimpleImputer(strategy=\"constant\")\n\ncategorical_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy=\"most_frequent\")),\n                                          ('onehot', OneHotEncoder(handle_unknown=\"ignore\"))\n                                         ])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","23206629":"def modeler(N,l):\n    model = XGBRegressor(n_estimators=N, learning_rate=l)\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])\n\n    pipeline.fit(X_train, y_train)\n\n    predictions = pipeline.predict(X_valid)\n\n    mae = mean_absolute_error(y_valid,predictions)\n\n    print(\"Mean Absolute Error (N = {}): {}\".format(N , mae))\n    return mae","bb01eaaf":"model = XGBRegressor(n_estimators=3000, learning_rate=0.005)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])\npipeline.fit(X, y)","b7bea311":"predictions = pipeline.predict(X_test)","74cf30ec":"output = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)","98aa35eb":"## Pipeline ","6d31376d":"Final Model.","41794624":"First, let's drop the rows without a Sale Price.","49131a31":"## Clean Data","9a0244c0":"## Prediction ","8b8c7378":"Let's split the data and classify it.","147b7f61":"Let's first import all of the libraries.","3426ec59":"If you found this notebook helpful, please consider upvoting it. Thanks.","d927a9b2":"Saving the predictions.","38ac75b2":"Now let's import the data.","ed65d2f1":"## Import","b22a2c0a":"Model to find out the appropriate parameters.","a7ba11f4":"## Model"}}