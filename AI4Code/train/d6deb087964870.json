{"cell_type":{"0dc2093e":"code","d051afed":"code","aed0fe73":"code","161ec0ed":"code","92c8f716":"code","a3ff32a6":"code","610a080c":"code","f9962237":"code","8183858b":"code","30989d54":"code","fe802dca":"code","b6179548":"code","9da0e7b3":"code","34086f77":"code","e98bd7d8":"code","0994bf92":"code","94614193":"code","0ca0f5ec":"code","eec6315e":"code","26a99590":"code","06df10dd":"code","4962c706":"code","763a3ddb":"code","9b8bbc54":"code","d3c798fc":"code","dbb1da08":"code","87a6384d":"code","2cb1f2d3":"code","4dd194c1":"code","52702c5e":"code","a3a2abe4":"code","de747d54":"code","a86e05eb":"code","37a9654e":"code","a37b0019":"code","bb8d8bc2":"code","36db4510":"code","5c157dd2":"code","b4e22d2f":"code","0c4f1a9a":"code","1c3d02e7":"code","b6920c68":"code","149164b0":"code","6ca73c30":"code","f1759b80":"code","7102998a":"code","e60d125d":"code","25d9e840":"code","f38a7843":"code","2b2048b9":"code","af745013":"code","f735421f":"code","6a917f49":"code","9f9b20ce":"code","5106b762":"code","af9d2568":"code","41a69a24":"code","3a2fdb30":"code","42a9ed4e":"code","425d4ec9":"code","2def6b55":"code","8b4b93f3":"code","c630b94d":"markdown","5cd809d7":"markdown","eac72f31":"markdown","130b7c42":"markdown","169eb124":"markdown","f4746d88":"markdown","4a717528":"markdown","157768ce":"markdown","1c3cb3a8":"markdown","440437da":"markdown","79373cb0":"markdown","c6f3675d":"markdown","ace256cc":"markdown","996ce346":"markdown","d03c1ef7":"markdown","d8932dd7":"markdown","a88811e3":"markdown","168fcea6":"markdown","d0108967":"markdown","2b96c3cb":"markdown","1fb6a535":"markdown","2bbf94f7":"markdown","14485458":"markdown","19a0f1cb":"markdown","36ecc5e6":"markdown","3d665e85":"markdown","a0bbf70d":"markdown","f149c855":"markdown","f61e9c68":"markdown","f0a228b6":"markdown","1a73e8dc":"markdown","c1f16b2e":"markdown","6db0470c":"markdown","cddb5a55":"markdown","db5f0af9":"markdown","d4861bf5":"markdown","65ab51bc":"markdown","1f1fb1c7":"markdown","5444a4aa":"markdown","434ef492":"markdown","ccc53a3f":"markdown","d3a9beb3":"markdown","b3e1fe2d":"markdown","7cc1fc78":"markdown","75bead24":"markdown","1c86ddde":"markdown","7463a7ce":"markdown","26548136":"markdown","f27f10cd":"markdown"},"source":{"0dc2093e":"import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns, sklearn\n\nfrom scipy.stats import probplot, boxcox_normmax, norm, skew, kurtosis as kurt\nfrom scipy.special import boxcox1p\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import KFold, cross_val_score, learning_curve\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import plot_importance\n\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nimport gc,os,sys,time,pickle\nfrom datetime import datetime\nfrom itertools import product\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nsns.set_style(\"darkgrid\")\n%matplotlib inline\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d051afed":"PATH = '..\/input\/competitive-data-science-predict-future-sales\/'\n\ntrain_data = pd.read_csv(PATH+'sales_train.csv')\ntest_data = pd.read_csv(PATH+'test.csv').set_index('ID')\nitem_data = pd.read_csv(PATH+'items.csv')\nitem_category_data = pd.read_csv(PATH+'item_categories.csv')\nshop_data = pd.read_csv(PATH+'shops.csv')","aed0fe73":"print('='*50)\ntrain_data.info()\nprint('='*50)\ntest_data.info()\nprint('='*50)\nitem_data.info()\nprint('='*50)\nitem_category_data.info()\nprint('='*50)\nshop_data.info()","161ec0ed":"plt.figure(figsize=(20,5))\nplt.xlim(-100, 3000)\nsns.boxplot(x=train_data.item_cnt_day)\n\nplt.figure(figsize=(20,5))\nplt.xlim(train_data.item_price.min()*1.1, train_data.item_price.max()*1.1)\nsns.boxplot(x=train_data.item_price)","92c8f716":"train_data[train_data.item_price < 0]","a3ff32a6":"train_data = train_data[train_data.item_cnt_day < 1001]\ntrain_data = train_data[train_data.item_price < 100000]\n\nmedian = train_data[(train_data.shop_id==32)&(train_data.item_id==2973)&(train_data.date_block_num==4)&\n                    (train_data.item_price>0)].item_price.median()\ntrain_data.loc[train_data.item_price < 0, 'item_price'] = median","610a080c":"# \u042f\u043a\u0443\u0442\u0441\u043a \u041e\u0440\u0434\u0436\u043e\u043d\u0438\u043a\u0438\u0434\u0437\u0435, 56\n# 0 & 56\ntrain_data.loc[train_data.shop_id == 0, 'shop_id'] = 57\ntest_data.loc[test_data.shop_id == 0, 'shop_id'] = 57\n# \u042f\u043a\u0443\u0442\u0441\u043a \u0422\u0426 \"\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439\"\n# 1 & 58\ntrain_data.loc[train_data.shop_id == 1, 'shop_id'] = 58\ntest_data.loc[test_data.shop_id == 1, 'shop_id'] = 58\n# \u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439 \u0443\u043b. \u0427\u043a\u0430\u043b\u043e\u0432\u0430 39\u043c\u00b2\n# 10 & 11\ntrain_data.loc[train_data.shop_id == 10, 'shop_id'] = 11\ntest_data.loc[test_data.shop_id == 10, 'shop_id'] = 11","f9962237":"# \u63d0\u53d6\u57ce\u5e02\u4fe1\u606f\u5e76label encode\uff0c\u4fdd\u7559shop_id\u548ccity_code\u5373\u53ef\nshop_data.loc[shop_data.shop_name == '\u0421\u0435\u0440\u0433\u0438\u0435\u0432 \u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"', 'shop_name'] = '\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"'\nshop_data['city'] = shop_data['shop_name'].str.split(' ').map(lambda x: x[0])\nshop_data.loc[shop_data.city == '!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'\nshop_data['city_code'] = LabelEncoder().fit_transform(shop_data['city'])\nshop_data = shop_data[['shop_id','city_code']]\n\n# \u5bf9\u7c7b\u522b\u540d\u8fdb\u884c\u5207\u5206\uff0c\u63d0\u53d6type\u548csub type\uff0c\u6ca1\u6709sub type\u65f6\uff0csub type\u7b49\u4e8etype\nitem_category_data['split'] = item_category_data['item_category_name'].str.split('-')\nitem_category_data['type'] = item_category_data['split'].map(lambda x: x[0].strip())\nitem_category_data['type_code'] = LabelEncoder().fit_transform(item_category_data['type'])\nitem_category_data['subtype'] = item_category_data['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\nitem_category_data['subtype_code'] = LabelEncoder().fit_transform(item_category_data['subtype'])\nitem_category_data = item_category_data[['item_category_id','type_code', 'subtype_code']]\n\n# \u4e22\u5f03\u5546\u54c1\u540d\u5b57\u6bb5\uff0c\u6ca1\u6709\u5206\u6790\u4ef7\u503c\nitem_data.drop(['item_name'], axis=1, inplace=True)","8183858b":"# print('trans day to month data')\n\n# dates,date_block_nums,shop_ids,item_ids,item_price_means,item_price_medians,item_cnt_months = [],[],[],[],[],[],[]\n\n# tmp_data = train_data.groupby(by=['shop_id','item_id','date_block_num'])\n# for tmp in tmp_data:\n#     dates.append(tmp[1].date.iloc[0][tmp[1].date.iloc[0].find('.')+1:])\n#     date_block_nums.append(tmp[1].date_block_num.iloc[0])\n#     shop_ids.append(tmp[1].shop_id.iloc[0])\n#     item_ids.append(tmp[1].item_id.iloc[0])\n#     item_price_means.append(tmp[1].item_price.mean())\n#     item_price_medians.append(tmp[1].item_price.median())\n#     item_cnt_months.append(tmp[1].item_cnt_day.count())\n\n# train_data = pd.DataFrame({'date':dates,'date_block_num':date_block_nums,'shop_id':shop_ids,'item_id':item_ids,\n#                                  'item_price_mean':item_price_means,'item_price_median':item_price_medians,\n#                                  'item_cnt_month':item_cnt_months})\n\n# del tmp_data,dates,date_block_nums,shop_ids,item_ids,item_price_means,item_price_medians,item_cnt_months\n# gc.collect()","30989d54":"%%time\n# \u6784\u5efa\u76ee\u6807DataFrame\n# \u8fd9\u91cc\u7684matrix\u7ed3\u6784\u4e0etrain\u5b8c\u5168\u4e0d\u4e00\u6837\uff0c\u8fd9\u91cc\u5176\u5b9e\u662f\u6784\u5efa\u4e86\u4e00\u4e2ashop*item*block_num\u7684\u6392\u5217\u7ec4\u5408\u7684\u77e9\u9635\uff0c\u53ef\u4ee5\u770b\u5230\u6570\u636e\u884c\u6570\u8fbe\u5230\u4e861000w+\uff0c\u8fdc\u8fdc\u9ad8\u4e8e\n# train\u7684\u884c\u6570\uff0c\u8fd9\u91cc\u8981\u641e\u6e05\u695a\uff0c\u4e0d\u662f\u7b80\u5355\u7684\u6570\u636e\u8fc1\u79fb\uff0c\u800c\u662f\u6574\u4e2a\u7ed3\u6784\u91cd\u7ec4\uff1b\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\nfor i in range(34):# 0~33\n    sales = train_data[train_data.date_block_num==i]# \u6bcf\u4e2a\u6708\u7684\u6570\u636e\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))# \u5c06\u6bcf\u4e2ashop\u3001item\u548cnum\u8fdb\u884c\u6392\u5217\u7ec4\u5408\n    \nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\nmatrix.info()","fe802dca":"# \u9500\u552e\u989d\u7279\u5f81\ntrain_data['revenue'] = train_data['item_price'] *  train_data['item_cnt_day']","b6179548":"%%time\n# \u6c42\u6708\u9500\u552e\u6570\u91cf\uff0c\u57fa\u672c\u65b9\u6cd5\u8ddf\u539f\u6765\u7684\u4e00\u6837\uff0c\u533a\u522b\u5728\u4e8e\u8fd9\u91cc\u7528\u4e86agg\u548c\u5185\u7f6e\u51fd\u6570sum\uff0c\u6548\u7387\u66f4\u9ad8\uff0c\u6ce8\u610fclip(0,20)\uff0c\u8fd9\u4e2a\u662f\u9898\u76ee\u4e2d\u6709\u8981\u6c42\u7684\ngroup = train_data.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month']\n                                .fillna(0) # fill NaN with 0\n                                .clip(0,20) # NB clip target here\n                                .astype(np.float16)) # float16 with NaN still float16, int16 will be int64","9da0e7b3":"%%time\nnumerical_features = ['item_price','revenue']\ntransform_data = train_data\ntransform_data[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)","34086f77":"%%time\ntransform_data[numerical_features].apply(lambda x: kurt(x.dropna())).sort_values(ascending=False)","e98bd7d8":"%%time\n# \u504f\u5ea6\u6700\u4f73\u4e3a0\uff0c\u6b64\u5904\u5927\u4e8e0.5\uff0c\u5c31\u6ee1\u8db3\u9700\u8981\u5904\u7406\u7684\u6761\u4ef6\nskewed_features = {feature: skew(transform_data[feature].dropna()-transform_data[feature].min()) for feature in numerical_features if skew(transform_data[feature].dropna()-transform_data[feature].min()) >= .5}\nprint(skewed_features)\n\nboxcox1p_skews = {}\nlog1p_skews = {}\nexp_skews = {}\npower_skews = {}\nbest_skews = {}\nmethods = {}\n\ntmp = pd.DataFrame()\nfor feature in skewed_features.keys():\n    tmp[feature] = boxcox1p(transform_data[feature]-transform_data[feature].min(), boxcox_normmax(transform_data[feature]-transform_data[feature].min() + 1))\n    boxcox1p_skews[feature] = skew(tmp[feature].dropna())\n    tmp[feature] = np.log1p(transform_data[feature]-transform_data[feature].min())\n    log1p_skews[feature] = skew(tmp[feature].dropna())\n    tmp[feature] = np.exp(transform_data[feature]-transform_data[feature].min())\n    exp_skews[feature] = skew(tmp[feature].dropna())\n    tmp[feature] = (transform_data[feature]-transform_data[feature].min())**.5\n    power_skews[feature] = skew(tmp[feature].dropna())\n    best_skews[feature] = min(boxcox1p_skews[feature],log1p_skews[feature],exp_skews[feature],power_skews[feature])\n    methods[feature] = 'boxcox' if best_skews[feature]==boxcox1p_skews[feature] else ('log' if best_skews[feature]==log1p_skews[feature] else ('exp' if best_skews[feature]==exp_skews[feature] else ('power' if best_skews[feature]==power_skews[feature] else 'original')))\n\nprint(methods)\n    \ndf_skew = pd.DataFrame(index=skewed_features.keys(), columns=['Skew', 'Skew after boxcox1p'])\ndf_skew['Skew Original'] = skewed_features.values()\ndf_skew['Skew after boxcox1p'] = boxcox1p_skews.values()\ndf_skew['Skew after log1p'] = log1p_skews.values()\ndf_skew['Skew after exp'] = exp_skews.values()\ndf_skew['Skew after power'] = power_skews.values()\ndf_skew['Skew after compare'] = best_skews.values()\n\nfig = plt.figure(figsize=(22, 6))\n\nsns.pointplot(x=df_skew.index, y='Skew Original', data=df_skew, markers=['o'], linestyles=['-'], label='original')\nsns.pointplot(x=df_skew.index, y='Skew after boxcox1p', data=df_skew, markers=['x'], linestyles=['--'], color='dodgerblue', label='boxcox1p')\nsns.pointplot(x=df_skew.index, y='Skew after log1p', data=df_skew, markers=['s'], linestyles=['--'], color='peru', label='log1p')\nsns.pointplot(x=df_skew.index, y='Skew after exp', data=df_skew, markers=['*'], linestyles=['--'], color='darkorchid', label='exp')\nsns.pointplot(x=df_skew.index, y='Skew after power', data=df_skew, markers=['+'], linestyles=['--'], color='yellow', label='power0.5')\nsns.pointplot(x=df_skew.index, y='Skew after compare', data=df_skew, markers=['v'], linestyles=['--'], color='lawngreen', label='best')\n\nplt.xlabel('Skewed Features', size=20, labelpad=12.5)\nplt.ylabel('Skewness', size=20, labelpad=12.5)\nplt.tick_params(axis='x', labelsize=11)\nplt.tick_params(axis='y', labelsize=15)\nplt.xticks(rotation=70)\nplt.title('Skewed Features Before and After Several Transformation Method', size=20)\n\nplt.legend(loc='best', shadow=True)\n\nplt.show()","0994bf92":"%%time\nfor feature in numerical_features:\n    method = methods[feature]\n    if method=='boxcox':\n        transform_data[feature] = boxcox1p(transform_data[feature]-transform_data[feature].min(), boxcox_normmax(transform_data[feature]-transform_data[feature].min() + 1))\n    elif method=='log':\n        transform_data[feature] = np.log1p(transform_data[feature]-transform_data[feature].min())\n    elif method=='exp':\n        transform_data[feature] = np.exp(transform_data[feature]-transform_data[feature].min())\n    elif method=='power':\n        transform_data[feature] = (transform_data[feature]-transform_data[feature].min())**.5\n    else:# original\n        pass","94614193":"%%time\nnumerical_features = ['item_cnt_month']\ntransform_data = matrix\ntransform_data[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)","0ca0f5ec":"%%time\ntransform_data[numerical_features].apply(lambda x: kurt(x.dropna())).sort_values(ascending=False)","eec6315e":"print('After log1p transform, skew = ', skew(np.log1p(transform_data[numerical_features]).dropna()))","26a99590":"transform_data[numerical_features] = np.log1p(transform_data[numerical_features])","06df10dd":"test_data['date_block_num'] = 34\ntest_data['date_block_num'] = test_data['date_block_num'].astype(np.int8)\ntest_data['shop_id'] = test_data['shop_id'].astype(np.int8)\ntest_data['item_id'] = test_data['item_id'].astype(np.int16)","4962c706":"# \u62fc\u63a5\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\uff0c\u8fd9\u91cc\u65f6\u95f4\u4e0a\u662f\u8fde\u7eed\u7684\uff0c\u53730~34\nmatrix = pd.concat([matrix, test_data], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True) # item_cnt_month in 34 month fill 0","763a3ddb":"%%time\nmatrix = pd.merge(matrix, shop_data, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, item_data, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, item_category_data, on=['item_category_id'], how='left')\nmatrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['type_code'] = matrix['type_code'].astype(np.int8)\nmatrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)","9b8bbc54":"matrix.sample(5)","d3c798fc":"matrix.info()","dbb1da08":"def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","87a6384d":"%%time\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'item_cnt_month')","2cb1f2d3":"%%time\ngroup = matrix.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\nmatrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_avg_item_cnt')\nmatrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)","4dd194c1":"%%time\ngroup = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'date_item_avg_item_cnt')\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)","52702c5e":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_shop_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'date_shop_avg_item_cnt')\nmatrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)","a3a2abe4":"%%time\ngroup = matrix.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_cat_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\nmatrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\nmatrix.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)","de747d54":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_cat_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\nmatrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\nmatrix.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)","a86e05eb":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_type_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'type_code'], how='left')\nmatrix['date_shop_type_avg_item_cnt'] = matrix['date_shop_type_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_type_avg_item_cnt')\nmatrix.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)","37a9654e":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_subtype_avg_item_cnt')\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)","a37b0019":"%%time\ngroup = matrix.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\nmatrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)","bb8d8bc2":"%%time\ngroup = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\nmatrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)","36db4510":"%%time\ngroup = matrix.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_type_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\nmatrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\nmatrix.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)","5c157dd2":"%%time\ngroup = matrix.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_subtype_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\nmatrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\nmatrix.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)","b4e22d2f":"%%time\n# \u6bcf\u4e2a\u5546\u54c1\u7684\u5e73\u5747\u4ef7\u683c\ngroup = train_data.groupby(['item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['item_id'], how='left')\nmatrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n\n# \u6bcf\u4e2a\u5546\u54c1\u5728\u6bcf\u4e2a\u6708\u7684\u5e73\u5747\u4ef7\u683c\ngroup = train_data.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['date_item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n\n# \u5bf9\u6bcf\u4e2a\u5546\u54c1\u5728\u6bcf\u4e2a\u6708\u7684\u5e73\u5747\u4ef7\u683c\u7279\u5f81\u505alag\u5904\u7406\uff0c\u5206\u522b\u5ef6\u540e[1,2,3,4,5,6]\nlags = [1,2,3,4,5,6]\nmatrix = lag_feature(matrix, lags, 'date_item_avg_item_price')\n\n# \u75281,2,3,4,5,6\u4e2a\u6708\u524d\u7684\u6bcf\u4e2a\u5546\u54c1\u5e73\u5747\u4ef7\u683c\u4e0e\u5546\u54c1\u603b\u5e73\u5747\u4ef7\u683c\u6c42\u53d8\u5316\u91cf\uff0c\u5373delta\nfor i in lags:\n    matrix['delta_price_lag_'+str(i)] = \\\n        (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price']) \/ matrix['item_avg_item_price']\n\n# \u904d\u5386\u6bcf\u4e00\u884c\uff0c\u5982\u679c\u5bf9\u5e94delta\u6709\u503c\uff0c\u8fd4\u56de\u8be5\u503c\uff0c\u5426\u5219\u8fd4\u56de0\n# for\u5faa\u73af\u4f1a\u63d0\u524d\u7ed3\u675f\uff0c\u56e0\u6b64\u8fd9\u91cc\u53ef\u80fd\u5b58\u5728\u591a\u4e2adelta\u65f6\uff0c\u8fd4\u56de\u6700\u8fd1\u7684\u90a3\u4e2a\uff0c\u5373\u5982\u679cdelta_1\u6709\u503c\uff0c\u5219\u8fd4\u56de\uff0c\u4e0d\u4f1a\u518d\u5411\u540e\u904d\u5386\n# \u90a3\u4e48delta_price_lag\u53ef\u4ee5\u7406\u89e3\u4e3a\u6700\u8fd1\u4e3a\u4e00\u4e2a\u6708\u7684\u5546\u54c1\u4ef7\u683c\u4e0e\u5168\u671f\u7684\u5546\u54c1\u4ef7\u683c\u7684\u53d8\u5316\u91cf\ndef select_trend(row):\n    for i in lags:\n        if row['delta_price_lag_'+str(i)]:\n            return row['delta_price_lag_'+str(i)]\n    return 0\n    \nmatrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\nmatrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\nmatrix['delta_price_lag'].fillna(0, inplace=True)\n\n# \u5220\u6389\u4e4b\u524d\u6dfb\u52a0\u7684\u6bcf\u4e2a\u5546\u54c1\u5e73\u5747\u548c\u6bcf\u4e2a\u6708\u6bcf\u4e2a\u5546\u54c1\u5e73\u5747\u7684\u7279\u5f81\nfetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n    fetures_to_drop += ['delta_price_lag_'+str(i)]\n\nmatrix.drop(fetures_to_drop, axis=1, inplace=True)","0c4f1a9a":"%%time\n# \u6bcf\u4e2a\u5546\u5e97\u6bcf\u4e2a\u6708\u7684\u603b\u9500\u552e\u989d\ngroup = train_data.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\n# \u6bcf\u4e2a\u5546\u5e97\u7684\u5e73\u5747\u9500\u552e\u989d\ngroup = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['shop_id'], how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n\n# \u6bcf\u4e2a\u6708\u9500\u552e\u989d\u4e0e\u603b\u9500\u552e\u989d\u6c42\u9500\u552e\u989d\u7684\u53d8\u5316\u91cf\nmatrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) \/ matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n\n# \u53d8\u5316\u91cflag[1]\nmatrix = lag_feature(matrix, [1], 'delta_revenue')\n\nmatrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)","1c3d02e7":"# \u6708\u4efd\nmatrix['month'] = matrix['date_block_num'] % 12\n# \u6bcf\u4e2a\u6708\u5929\u6570\ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\nmatrix['days'] = matrix['month'].map(days).astype(np.int8)","b6920c68":"%%time\ncache = {}\n# \u6bcf\u4e2a\u5546\u5e97\u7684\u6bcf\u4e2a\u5546\u54c1\u4e0a\u4e00\u6b21\u552e\u51fa\u662f\u51e0\u4e2a\u6708\u524d\nmatrix['item_shop_last_sale'] = -1\nmatrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\n# for idx, row in matrix.iterrows():    \n#     key = str(row.item_id)+' '+str(row.shop_id)\n#     if key not in cache:\n#         if row.item_cnt_month!=0:\n#             cache[key] = row.date_block_num\n#     else:\n#         last_date_block_num = cache[key]\n#         matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n#         cache[key] = row.date_block_num    \n\nfor row in matrix.itertuples():\n    idx = getattr(row,'Index')\n    item_id = getattr(row,'item_id')\n    shop_id = getattr(row,'shop_id')\n    date_block_num = getattr(row,'date_block_num')\n    item_cnt_month = getattr(row,'item_cnt_month')\n    key = str(item_id)+' '+str(shop_id)\n    if key not in cache:\n        if item_cnt_month!=0:\n            cache[key] = date_block_num\n    else:\n        last_date_block_num = cache[key]\n        matrix.at[idx, 'item_shop_last_sale'] = date_block_num - last_date_block_num\n        cache[key] = date_block_num","149164b0":"%%time\ncache = {}\nmatrix['item_last_sale'] = -1\nmatrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\n# for idx, row in matrix.iterrows():    \n#     key = row.item_id\n#     if key not in cache:\n#         if row.item_cnt_month!=0:\n#             cache[key] = row.date_block_num\n#     else:\n#         last_date_block_num = cache[key]\n#         if row.date_block_num>last_date_block_num:\n#             matrix.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n#             cache[key] = row.date_block_num         \n\nfor row in matrix.itertuples():\n    idx = getattr(row,'Index')\n    key = getattr(row,'item_id')\n    date_block_num = getattr(row,'date_block_num')\n    item_cnt_month = getattr(row,'item_cnt_month')\n    if key not in cache:\n        if item_cnt_month!=0:\n            cache[key] = date_block_num\n    else:\n        last_date_block_num = cache[key]\n        if date_block_num>last_date_block_num:\n            matrix.at[idx, 'item_last_sale'] = date_block_num - last_date_block_num\n            cache[key] = date_block_num","6ca73c30":"%%time\nmatrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\nmatrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')","f1759b80":"%%time\nmatrix = matrix[matrix.date_block_num > 11]","7102998a":"%%time\ndef fill_na(df):\n    for col in df.columns:\n        if ('_lag_' in col) & (df[col].isnull().any()):\n            if ('item_cnt' in col):\n                df[col].fillna(0, inplace=True)         \n    return df\n\nmatrix = fill_na(matrix)","e60d125d":"matrix.columns","25d9e840":"matrix.info()","f38a7843":"numerical_features = [col for col in matrix.columns if (col.find('cnt')!=-1 or col.find('cnt')!=-1 or col.find('price')!=-1 or col.find('revenue')!=-1 or col.find('sale')!=-1)]\nmatrix[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)","2b2048b9":"matrix[numerical_features].apply(lambda x: kurt(x.dropna())).sort_values(ascending=False)","af745013":"matrix.to_pickle('data.pkl')\n# \u4fdd\u7559test_data\uff0c\u7528\u4ee5\u751f\u6210\u63d0\u4ea4\u6587\u4ef6\ndel matrix, cache, group, train_data, shop_data, item_data, item_category_data\ngc.collect();","f735421f":"1\/0","6a917f49":"data = pd.read_pickle('data.pkl')","9f9b20ce":"X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = data[data.date_block_num < 33]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)","5106b762":"del data\ngc.collect()","af9d2568":"%%time\nmodel = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000, # 1000\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8,\n    eta=0.3,\n    seed=10086)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 10)","41a69a24":"Y_pred = model.predict(X_valid)\nY_pred = np.expm1(Y_pred).clip(0, 20)\nprint('Expm1 after RMSE = ', np.sqrt(sklearn.metrics.mean_squared_error(np.expm1(Y_valid),Y_pred)))","3a2fdb30":"plot_features(model, (15,15))","42a9ed4e":"Y_valid_expm1 = np.expm1(Y_valid)\nY_pred_correct = Y_pred*(np.mean(Y_valid_expm1)\/np.mean(Y_pred))\nY_pred_correct_add = Y_pred+(np.mean(Y_valid_expm1-Y_pred))\n\nprint('Mean of pred - valid:', np.mean(Y_pred - Y_valid_expm1))\nprint('Mean of pred_correct - valid:', np.mean(Y_pred_correct - Y_valid_expm1))\nprint('Mean of pred_correct_add - valid:', np.mean(Y_pred_correct_add - Y_valid_expm1))","425d4ec9":"fig = plt.figure(figsize=(22, 6))\ncompare_df = pd.DataFrame({'Y_pred':Y_pred[:500], \n                           'Y_valid':Y_valid_expm1[:500], \n                          'Y_pred_correct':Y_pred_correct[:500], \n                          'Y_pred_correct_add':Y_pred_correct_add[:500]})\nsns.lineplot(data=compare_df)\nplt.show()","2def6b55":"print('Expm1 after and Correct Factor RMSE = ', np.sqrt(sklearn.metrics.mean_squared_error(Y_valid_expm1,Y_pred_correct)))\nprint('Expm1 after and Correct Add RMSE = ', np.sqrt(sklearn.metrics.mean_squared_error(Y_valid_expm1,Y_pred_correct_add)))","8b4b93f3":"Y_test = np.expm1(model.predict(X_test)).clip(0, 20)+np.mean(Y_valid_expm1-Y_pred)\n\nsubmission = pd.DataFrame({\n    \"ID\": test_data.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","c630b94d":"### \u8d8b\u52bf\u7279\u5f81","5cd809d7":"### \u8fde\u7eed\u7279\u5f81\u7684\u6570\u636e\u5206\u5e03\u8f6c\u6362\n\n\u653e\u5230\u8fd9\u91cc\u7684\u539f\u56e0\u662f\u5982\u679c\u8fde\u63a5\u4e86\u6d4b\u8bd5\u6570\u636e\uff0c\u90a3\u4e48\u5c31\u4f1a\u5e26\u6765\u5927\u91cf\u76840\u503c\uff0c\u8fd9\u4f1a\u5f71\u54cd\u8f6c\u6362\u7b97\u6cd5\u7684\u6548\u679c\uff1b","eac72f31":"## Load Data","130b7c42":"\u6bcf\u4e2a\u6708\u6bcf\u4e2asubtype\u7684\u5e73\u5747\u9500\u91cf\uff1b","169eb124":"\u6bcf\u4e2a\u6708\u6bcf\u4e2a\u7c7b\u522b\u7684\u5e73\u5747\u9500\u91cf\uff1b","f4746d88":"\u6bcf\u4e2a\u6708\u6bcf\u4e2a\u57ce\u5e02\u7684\u5e73\u5747\u9500\u91cf\uff1b","4a717528":"\u6bcf\u4e2a\u5546\u5e97\u7684\u6bcf\u4e2a\u5546\u54c1\u4e0a\u4e00\u6b21\u552e\u51fa\u662f\u51e0\u4e2a\u6708\u524d\uff1b","157768ce":"## Evaluation\n\nSubmissions are evaluated by root mean squared error (**RMSE**). True target values are clipped into [0,20] range;","1c3cb3a8":"### Shops\/Cats\/Items\n\n- \u5546\u5e97\u540d\u5b57\u90fd\u662f\u4ee5\u57ce\u5e02\u540d\u5b57\u5f00\u5934\uff1b\n- \u6bcf\u4e2a\u7c7b\u522b\u540d\u5b57\u90fd\u5305\u542btype\u548csub type\u4fe1\u606f\uff1b","440437da":"# Predict Future Sales\n\nThis challenge serves as final project for the \"How to win a data science competition\" Coursera course.\n\nIn this competition you will work with a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company. \n\nWe are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills.","79373cb0":"### \u6700\u540e\u5904\u7406","c6f3675d":"### SPLIT DATA","ace256cc":"### \u7279\u5f81\u91cd\u8981\u6027","996ce346":"## Pickle","d03c1ef7":"## OUTPUT","d8932dd7":"\u6700\u540e\u4e00\u4e2a\u6708\u7684\u5546\u54c1\u9500\u552e\u989d\u8d8b\u52bf","a88811e3":"\u6bcf\u4e2a\u6708\u6bcf\u5bb6\u5e97\u7684\u5e73\u5747\u9500\u91cf\uff1b","168fcea6":"\u6708\u4efd\u3001\u5929\u6570\uff1b","d0108967":"## Submission File\n\nFor each id in the test set, you must predict a total number of sales. The file should contain a header and have the following format:\n\n```\nID,item_cnt_month\n0,0.5\n1,0.5\n2,0.5\n3,0.5\netc.\n```","2b96c3cb":"## FEATURE ENGENEERING","1fb6a535":"## PREPROCESS","2bbf94f7":"\u6bcf\u4e2a\u6708\u6bcf\u5bb6\u5e97\u6bcf\u4e2a\u7c7b\u522b\u7684\u5e73\u5747\u9500\u91cf\uff1b","14485458":"### BASELINE MODEL - xgboost","19a0f1cb":"## MODELING","36ecc5e6":"### \u6d4b\u8bd5\u6570\u636e\u5904\u7406","3d665e85":"## Getting Started","a0bbf70d":"### Monthly Sales\n\n\u8bad\u7ec3\u6570\u636e\u6bcf\u6761\u8bb0\u5f55\u4ee3\u8868\u7684\u662f\u67d0\u4e2a\u5546\u5e97\u7684\u67d0\u4e2a\u5546\u54c1\u7684\u65e5\u9500\u91cf\u4ee5\u53ca\u4ef7\u683c\uff0c\u800c\u6d4b\u8bd5\u6570\u636e\u8981\u7684\u7ed3\u679c\u5219\u662f\u6708\u9500\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u8bad\u7ec3\u6570\u636e\u505a\u805a\u5408\uff0c\u4ee5\u4f7f\u5f97\u4e8c\u8005\u7684\u6570\u636e\u7ed3\u6784\u7ef4\u5ea6\u4e00\u81f4\uff1b","f149c855":"### \u5176\u4ed6\u7279\u5f81","f61e9c68":"### Merge item\/shop\/cat","f0a228b6":"### outliers\n\n- item_cnt_day: \u5f53\u65e5\u9500\u552e\u6570\u8d85\u8fc71001\uff0c\u5728box\u56fe\u4e2d\u770b\u5c5e\u4e8e\u4e25\u91cd\u7684\u79bb\u7fa4\u70b9\u6781\u503c\u4e86\uff0c\u9632\u6b62\u5176\u5bf9\u6b63\u5e38\u6570\u636e\u7684\u5f71\u54cd\uff0c\u53bb\u9664\uff1b\n- item_price: \u5927\u4e8e100k\uff0c\u53ea\u6709\u4e00\u4e2a\uff0c\u79bb\u7fa4\u660e\u663e\uff0c\u53bb\u9664\uff0c\u53e6\u5916\uff0citem_price\u6709\u4e00\u4e2a\u8d1f\u6570\uff0c\u5c5e\u4e8e\u5f02\u5e38\u503c\uff0c\u7528\u4e2d\u4f4d\u6570\u586b\u5145\uff1b\n- shop: \u51e0\u5bb6\u5546\u5e97\u4ece\u540d\u5b57\u4e0a\u770b\u662f\u91cd\u590d\u7684\uff0c\u4f46\u662fid\u4e0d\u4e00\u81f4\uff0c\u8fd9\u91cc\u505a\u5f52\u4e00\u5904\u7406\uff1b","1a73e8dc":"## File descriptions\n- sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n- test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n- sample_submission.csv - a sample submission file in the correct format.\n- items.csv - supplemental information about the items\/products.\n- item_categories.csv  - supplemental information about the items categories.\n- shops.csv- supplemental information about the shops.","c1f16b2e":"\u5904\u7406matrix\u6570\u636e\uff1b","6db0470c":"\u6bcf\u4e2a\u6708\u7684\u5e73\u5747\u9500\u91cf\uff1b","cddb5a55":"### \u5e73\u5747\u7f16\u7801\u7279\u5f81","db5f0af9":"\u6bcf\u4e2a\u6708\u6bcf\u5bb6\u5e97\u6bcf\u4e2asubtype\u7684\u5e73\u5747\u9500\u91cf\uff1b","d4861bf5":"\u5904\u7406train_data\u6570\u636e\uff1b","65ab51bc":"\u75280\u586b\u5145\u6708\u9500\u91cf\uff0cproduct\u64cd\u4f5c\u4ea7\u751f\u4e86\u5927\u91cf\u7684NaN\u503c\uff0c\u6708\u9500\u91cf\u4f5c\u4e3a\u76ee\u6807\u53d8\u91cf\uff0cNaN\u75280\u586b\u5145\uff1b","1f1fb1c7":"### Correct Factor","5444a4aa":"## Data fields\n- ID - an Id that represents a (Shop, Item) tuple within the test set\n- shop_id - unique identifier of a shop\n- item_id - unique identifier of a product\n- item_category_id - unique identifier of item category\n- item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n- item_price - current price of an item\n- date - date in format dd\/mm\/yyyy\n- date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n- item_name - name of item\n- shop_name - name of shop\n- item_category_name - name of item category","434ef492":"1. \u6bcf\u4e2a\u5546\u5e97\u7684\u6bcf\u4e2a\u5546\u54c1\u7b2c\u4e00\u6b21\u552e\u51fa\u662f\u51e0\u4e2a\u6708\u524d\uff1b\n2. \u6bcf\u4e2a\u5546\u54c1\u7b2c\u4e00\u6b21\u552e\u51fa\u662f\u51e0\u4e2a\u6708\u524d\uff1b","ccc53a3f":"\u6700\u540e6\u4e2a\u6708\u7684\u4ef7\u683c\u8d8b\u52bf\uff1b","d3a9beb3":"\u6bcf\u4e2a\u6708\u6bcf\u4e2a\u57ce\u5e02\u6bcf\u4e2a\u5546\u54c1\u7684\u5e73\u5747\u9500\u91cf\uff1b","b3e1fe2d":"\u6bcf\u4e2a\u6708\u6bcf\u4e2a\u5546\u54c1\u7684\u5e73\u5747\u9500\u91cf\uff1b","7cc1fc78":"\u6bcf\u4e2a\u5546\u54c1\u4e0a\u4e00\u6b21\u552e\u51fa\u662f\u51e0\u4e2a\u6708\u524d","75bead24":"### Target Lags\n\n\u65b0\u589e\u76ee\u6807\u7279\u5f81\u7684\u5ef6\u540e\u7279\u5f81\uff0c\u5206\u522b\u5ef6\u540e[1,2,3,6,12]\uff0c\u5bf9\u4e8e\u6bcf\u6761\u6570\u636e\u7684\u542b\u4e49\u5c31\u662f\u589e\u52a0\u4e865\u5217\u7279\u5f81\uff0citem_cnt_month_lag_1\u8868\u793a\u4e00\u4e2a\u6708\u524d\u8be5\u5546\u5e97\u8be5\u5546\u54c1\u7684\u6708\u9500\u552e\u91cf\uff0c2,3,6,12\u540c\u7406\uff0c\u8fd9\u6837\u64cd\u4f5c\u540e\u4f1a\u4ea7\u751f\u4e00\u4e9bNaN\u503c\uff0c\u7c7b\u4f3c\u6ed1\u7a97\u5904\u7406\u5728\u8fb9\u754c\u4e0a\u603b\u662f\u4f1a\u6709NaN\uff0c\u6b63\u5e38\u60c5\u51b5\uff1b","1c86ddde":"\u6bcf\u4e2a\u6708\u6bcf\u4e2atype\u7684\u5e73\u5747\u9500\u91cf\uff1b","7463a7ce":"\u53bb\u6389\u524d\u4e00\u5e74\u7684\u6570\u636e\uff0c\u53730~11\uff0c\u517112\u4e2a\u6708\u7684\u6570\u636e\uff0c\u539f\u56e0\u662f\u524d12\u4e2a\u6708\u7684\u6570\u636e\u5728target lag\u7279\u5f81\u4e0a\u90fd\u5b58\u5728NaN\uff0c\u56e0\u4e3atarget lag\u6700\u8fdc\u6709\u4e00\u5e74\u524d\uff0c\u56e0\u6b64\u6700\u65e9\u7684\u4e00\u5e74\u7684\u6570\u636e\u5bf9\u5e94\u7684target lag 12\u80af\u5b9a\u90fd\u662fNaN\uff0c\u8fd9\u4e9b\u6570\u636e\u65e0\u6cd5\u7528\u4e8e\u8bad\u7ec3\uff0c\u56e0\u6b64\u9700\u8981\u53bb\u6389\uff0c\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4fbf\u53bb\u6389\u4e86\u8fd9\u90e8\u5206\u6570\u636e\uff0c\u4e5f\u4e0d\u4f1a\u51cf\u5c11\u539f\u59cb\u6570\u636e\u7684\u4fe1\u606f\u91cf\uff0c\u56e0\u4e3a\u8fd9\u90e8\u5206\u6570\u636e\u7684\u4fe1\u606f\u91cf\u4f53\u73b0\u5728\u540e\u9762\u6570\u636e\u7684lag\u4e0a\uff1b","26548136":"\u6bcf\u4e2a\u6708\u6bcf\u5bb6\u5e97\u6bcf\u4e2atype\u7684\u5e73\u5747\u9500\u91cf\uff1b","f27f10cd":"\u6700\u540e\u6d4f\u89c8\u4e0b\u6570\u636e\u7ed3\u6784"}}