{"cell_type":{"56d39f1e":"code","36751ffa":"code","ea75bf06":"code","cfb28904":"code","44dbe156":"code","b9838bd0":"code","d9f3c07d":"code","ae633356":"code","a4df6381":"code","1da15558":"code","0888b278":"code","e2fba553":"code","c02b1e49":"code","5b1367d3":"code","dfd8d07a":"code","33414bb9":"code","68d245cf":"code","369e307e":"code","f46e235b":"markdown","7009c3ec":"markdown","fc271376":"markdown","0a5dac72":"markdown","8a3f65c9":"markdown","1b375e1e":"markdown","3003ab9a":"markdown"},"source":{"56d39f1e":"%config Completer.use_jedi = False","36751ffa":"import os\nos.mkdir('label_assignment')","ea75bf06":"%%capture\n!cp -r \/kaggle\/input\/gmmreglib \/kaggle\/working\/label_assignment\/gmmreg-install\n%cd \/kaggle\/working\/label_assignment\/gmmreg-install\/src\n!python setup.py install --user\n%cd \/kaggle\/working","cfb28904":"!cp -r \/kaggle\/input\/helmet-assignment-helpers\/helmet-assignment-main\/helmet_assignment \/kaggle\/working\/label_assignment\/helmet_assignment","44dbe156":"%%writefile label_assignment\/__init__.py\n\n\n","b9838bd0":"%cd \/kaggle\/working","d9f3c07d":"!ls label_assignment\/helmet_assignment","ae633356":"%%writefile label_assignment\/all.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom scipy.optimize import linear_sum_assignment\nfrom scipy.spatial.distance import cdist\nfrom gmmreg._core import run_multi_level, normalize\nfrom .helmet_assignment.features import add_track_features\nfrom functools import partial\n\n\nclass DataLoader():\n    def __init__(self, preds, is_train = True, flip_y = True, top22 = False):\n        if is_train:\n            track = pd.read_csv('\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/train_player_tracking.csv')\n        else:\n            track = pd.read_csv('\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/test_player_tracking.csv')\n        track['y'] = -track['y']\n        self.track = add_track_features(track).query('est_frame > 0').reset_index()\n        self.videos = pd.Series(list(map(lambda x: splitjoin(x, ':-1'), preds['video_frame'].unique()))).sort_values().unique()\n        \n        if 'conf' not in preds.columns:\n            print('\"conf\" column missing in \"preds\" DataFrame, filling with 1...')\n            preds['conf'] = 1\n        if 'id' not in preds.columns:\n            print('\"id\" column missing in \"preds\" DataFrame, filling with unique values...')\n            preds['id'] = range(len(preds))\n        if top22:\n            preds = preds.sort_values('conf').groupby('video_frame').head(22).sort_index().reset_index(drop = True)\n\n        self.preds = preds\n        \n    def __nearest__(self, frame):\n        idx = abs(self.track_est_frames - frame).argmin()\n        frame = self.track_est_frames[idx]\n        return self.gameplay_track.set_index('est_frame').loc[frame]\n        \n    def filter_video(self, video):\n        gameplay, view = splitjoin(video, [':-1', '-1:'])\n        self.video = video\n        self.gameplay = gameplay\n        self.view = view\n        self.gameplay_track = self.track.query(f\"game_play == '{gameplay}'\")\n        self.video_preds = self.preds.query(f\"video_frame.str.contains('{video}')\", engine='python')\n        self.track_est_frames = self.gameplay_track['est_frame'].unique()\n        self.frames = (self\n                       .video_preds['video_frame']\n                       .drop_duplicates()\n                       .apply(splitjoin, keep = '-1:')\n                       .astype('int')\n                       .sort_values()\n                       .values\n                      )\n\n    def __call__(self, frame, method = 'nearest'):\n        if not hasattr(self, 'gameplay_track'):\n            raise ValueError(\"You must call 'filter_video' before calling the generator\")\n        if method == 'nearest':\n            track = self.__nearest__(frame)\n            xy_track = track[['x', 'y']].values\n            label_track = track['player'].values\n        else:\n            #todo implement interpolation on frames\n            raise ValueError(\"Only 'nearest' method is implemented so far\")\n        \n        video_frame = splitjoin(self.video_preds['video_frame'].values[0], ':-1') + f'_{frame}'\n        video_preds = self.video_preds.set_index('video_frame').loc[video_frame]\n        xy_video = ltwh2xcyc(video_preds)\n        label_video = video_preds['id'].values\n        \n        return xy_video, xy_track, label_video, label_track\n    \n    def bbox(self, frame):\n        video_frame = splitjoin(self.video_preds['video_frame'].values[0], ':-1') + f'_{frame}'\n        bbox = (self\n                .video_preds\n                .set_index('video_frame')\n                .loc[video_frame, ['left', 'width', 'top', 'height']]\n                .values)\n        return bbox\n              \ndef rotate(xy, theta):\n    t = theta * np.pi\/180\n    R = np.array([[np.cos(t), -np.sin(t)],\n                  [np.sin(t),  np.cos(t)]])\n    return xy @ R\n\ndef normalize(xy):\n    return (xy - xy.mean(axis = 0))\/xy.std(axis = 0)\n\ndef splitjoin(string, keep):\n    splitted = string.split('_')\n    if isinstance(keep, list):\n        joint = [f\"'_'.join(splitted[{k}])\" for k in keep]\n        joint = tuple(map(eval, joint))\n    else:\n        joint = eval(f\"'_'.join(splitted[{keep}])\")\n    return joint\n\ndef ltwh2xcyc(df):\n    xc = df['left'] + df['width']\/2\n    yc = df['top'] + df['height']\/2\n    xcyc = np.vstack([xc.values, yc.values]).T\n    return xcyc\n\ndef register(xy_source, xy_target, theta, n_grid, **kwargs):\n    grid = np.linspace(-2, 2, n_grid)\n    grid = np.array(np.meshgrid(grid, grid)).T.reshape(-1,2)\n    xy_target = normalize(xy_target)\n    xy_source = normalize(xy_source)\n    xy_source = rotate(xy_source, theta)\n    xy_source = run_multi_level(xy_source, xy_target, grid, **kwargs)\n    return xy_source, xy_target\n\ndef label_matrix(matrix, label_row, label_col):\n    return pd.DataFrame(matrix, index = label_row, columns = label_col)\n\ndef get_optimal_theta(xy_video, xy_tracking, thetas, **kwargs):\n    if thetas == 'Endzone':\n        thetas = [-90, 90]\n    elif thetas == 'Sideline':\n        thetas = [0, 180]\n    scores = []\n    for theta in thetas:\n        xy_video_r, xy_tracking_r = register(xy_video, xy_tracking, theta, **kwargs)\n        dist = cdist(xy_video_r, xy_tracking_r)\n        M = linear_sum_assignment(dist)\n        score = dist.mean()\/dist[M].mean()\n        scores.append(score)\n    scores = np.array(scores)\n    return thetas[scores.argmax()]\n\nfrom statistics import mode\ndef estimate_theta(dl, frames = [1,21,41,61,81,101,121], **kwargs):\n    thetas = []\n    for frame in frames:\n        xy_video, xy_tracking, labels_video, labels_tracking = dl(frame)\n        theta = get_optimal_theta(xy_video, xy_tracking, dl.view, **kwargs) \n        thetas.append(theta)\n    theta = mode(thetas) \n    return theta\n\ndef match_video(dl, theta, **kwargs):\n    video_dist = []\n    for frame in dl.frames:\n        xy_video, xy_tracking, labels_video, labels_tracking = dl(frame) \n        xy_video, xy_tracking = register(xy_video, xy_tracking, theta, **kwargs)\n        dist = cdist(xy_video, xy_tracking)\n        dist = label_matrix(dist, labels_video, labels_tracking)\n        video_dist.append(dist)\n    return video_dist\n\ndef assign_labels(dl, video_agg_dist):\n    video_labels = []\n    idx_video = []\n    for frame in dl.frames:\n        _, _, labels_video, labels_tracking = dl(frame)\n        dist = video_agg_dist.loc[labels_video, labels_tracking]\n        M = linear_sum_assignment(dist)\n        video_labels.append(labels_tracking[M[1]])\n        idx_video.append(M[0])\n    return video_labels, idx_video\n\ndef build_submission_for_video(dl, labels, idx_video):\n    video_sub = []\n    for frame, label, idx in zip(dl.frames, labels, idx_video):\n        frame_sub = pd.DataFrame({\n            'video_frame': f'{dl.video}_{frame}',\n            'label': label,\n        })\n        frame_sub[['left', 'width', 'top', 'height']] = dl.bbox(frame)[idx]\n        video_sub.append(frame_sub)\n    video_sub = pd.concat(video_sub)\n    return video_sub\n\n\ndef track2sub(dl, **kwargs):\n    ## Estimate camera angle\n    ### Estimate camera angle by minimizing the matching distance and \n    ### get the mode of the best matches for multiple frames\n    theta = estimate_theta(dl, **kwargs)\n    \n    ## Generate a list of distance dataframes (named matrix)\n    ### register the point clouds for all frames and returns a list of named\n    ### distance matrix (row names are pseudo_labels and col names are tracking labels)\n    video_dist = match_video(dl, theta, **kwargs)\n\n    ## Aggregate the list of distance dataframes to a single distance dataframe\n    ### For now this is simple but could be replaced for a more complex function\n    video_agg_dist = pd.concat(video_dist).groupby(level=0).agg('mean')\n    \n    ## Label assignment based on aggregated distance\n    ### Uses hungarian algorithm to match based on the aggregated distance matrix\n    video_labels, idx_video = assign_labels(dl, video_agg_dist)\n    \n    ## Submission generation for a video\n    ### replace the labels on the original bbox dataframe\n    video_sub = build_submission_for_video(dl, video_labels, idx_video)\n    \n    return video_sub, theta\n\nclass Register():\n    def __init__(self, algo = 'gmmreg', **kwargs):\n        if algo == 'gmmreg':\n            if 'n_grid' in kwargs:\n                n_grid = kwargs.pop('n_grid')\n                grid = np.linspace(-2, 2, n_grid)\n                self.grid = np.array(np.meshgrid(grid, grid)).T.reshape(-1,2)\n            else:\n                self.grid = None\n            self.algo = partial(run_multi_level, **kwargs)\n        else:\n            raise ValueError('Only gmmreg is implemented')\n    def __call__(self, src, trg):\n        if self.grid is None: grid = src\n        else: grid = self.grid\n        return self.algo(src, trg, grid)\n    \n    \ndef match_videoV2(dl, theta, **kwargs):\n    \n    reg_gmm = Register(**kwargs)\n    video_dist = []\n    for frame in dl.frames:\n        xy_video, xy_tracking, labels_video, labels_tracking = dl(frame) \n        xy_tracking = normalize(xy_tracking)\n        xy_video = normalize(xy_video)\n        xy_video = rotate(xy_video, theta)\n        if frame == 1:\n            _xy_video = xy_tracking\n        xy_video = reg_gmm(xy_video, _xy_video)\n\n        dist = cdist(xy_video, xy_tracking)\n        M = linear_sum_assignment(dist)\n        _xy_video = xy_tracking[M[1]]\n        \n        d_m = dist[M].mean()\n        w_m = 1\/(1 + np.exp(-(len(M[0])-8)\/2))\n        dist = label_matrix(dist, labels_video, labels_tracking)\n        video_dist.append(dist * d_m \/ w_m)\n    return video_dist \n\ndef track2subV2(dl, **kwargs):\n    theta = estimate_theta(dl, **kwargs)\n    video_dist = match_videoV2(dl, theta, **kwargs)\n    video_agg_dist = pd.concat(video_dist).groupby(level=0).agg('mean')\n    video_labels, idx_video = assign_labels(dl, video_agg_dist)\n    video_sub = build_submission_for_video(dl, video_labels, idx_video)\n    return video_sub, theta","a4df6381":"%%writefile label_assignment\/utils.py\ndef fix_submission(sub):\n    \n    n_na = sub.isna().any(axis = 1).sum()\n    if n_na:\n        sub = sub.dropna()\n        print(f'Dropped {n_na} lines from submission')\n        \n    n_dupe_labels = sub[[\"video_frame\", \"label\"]].duplicated().sum()\n    if n_dupe_labels:\n        sub = sub.drop_duplicates(['video_frame', 'label'])\n        print(f'Dropped {n_dupe_labels} duplicated labels')\n    \n    n_dupe_bbox = sub[[\"video_frame\", \"left\", \"width\", \"top\", \"height\"]].duplicated().sum()\n    if n_dupe_bbox:\n        sub = sub.drop_duplicates(['video_frame', 'left','width','top','height'])\n        print(f'Dropped {n_dupe_bbox} duplicated bboxes')\n    \n    n_over_22 = (sub.groupby([\"video_frame\"])[\"label\"].count() > 22).sum()\n    if n_over_22:\n        sub = sub.groupby(\"video_frame\").head(22)\n        print(f'Dropped {n_over_22} extra bboxes')\n\n    n_out_of_bounds = (\n        (sub['left'] < 0) | \n        (sub['top'] < 0) | \n        ((sub['left'] + sub['width']) > 1280) | \n        ((sub['top'] + sub['height']) > 720)\n    ).sum()\n    if n_out_of_bounds:\n        sub['right'] = sub['left'] + sub['width']\n        sub['bottom'] = sub['top'] + sub['height']\n        \n        sub['left'] = sub['left'].clip(0, 1280-1)\n        sub['right'] = sub['right'].clip(1, 1280)\n        sub['top'] = sub['top'].clip(0, 720-1)\n        sub['bottom'] = sub['bottom'].clip(1, 720)\n        \n        sub['width'] = sub['right'] - sub['left']\n        sub['height'] = sub['bottom'] - sub['top']\n        sub = sub.drop(['bottom', 'right'], axis = 1)\n        print(f'Clipped {n_out_of_bounds} bboxes')\n        \n    return sub","1da15558":"import sys\nsys.path.append(\"\/kaggle\/label_assignment\")\nfrom label_assignment.all import *","0888b278":"import sys\nsys.path.append(\"\/kaggle\/input\/helmet-assignment-helpers\/helmet-assignment-main\")\nfrom helmet_assignment.score import NFLAssignmentScorer\nfrom helmet_assignment.video import video_with_predictions","e2fba553":"from tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom termcolor import colored","c02b1e49":"## GT Rotations\ngt_rotations = pd.read_csv('..\/input\/nlf-helmet-safety-camera-rotations\/NFL-rotations-plays.csv').set_index('play')\ngt_rotations = pd.DataFrame({\n    'video' : np.concatenate([(gt_rotations.index + '_Sideline').values, (gt_rotations.index + '_Endzone').values]),\n    'rotation' : np.concatenate([gt_rotations['Sideline'].values, gt_rotations['Endzone'].values])\n}).set_index('video').sort_index()\n\n## GT Labels\ngt_labels = pd.read_csv('\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/train_labels.csv')","5b1367d3":"N_VIDEOS = 6\nlabeler_cfg_Endzone = {\n    'level': 3, \n    'scales':  [1, 0.2, 0.1], \n    'lambdas': [0.1, 0.04, 0.02], \n    'iters':   [30, 20, 10],\n    'n_grid': 5\n}\nlabeler_cfg_Sideline = {\n    'level': 3, \n    'scales':  [1, 0.5, 0.25], \n    'lambdas': [1, 0.02, 0.25], \n    'iters':   [30, 20, 10],\n    'n_grid': 5\n}","dfd8d07a":"sorted_bboxes = pd.read_csv('\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/train_labels.csv').query('frame > 0')\nsorted_bboxes['id'] = sorted_bboxes['label']\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}\u00b0', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","33414bb9":"sorted_bboxes = pd.read_csv('\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/train_labels.csv').query('frame > 0')\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}\u00b0', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","68d245cf":"sorted_bboxes = pd.read_csv('\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/train_baseline_helmets.csv')\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}\u00b0', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","369e307e":"sorted_bboxes = pd.read_csv('\/kaggle\/input\/nfl-csv-dataset\/tracked_detections.csv')\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}\u00b0', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","f46e235b":"### Testing with GT bboxes (no tracking)","7009c3ec":"## Main Functions","fc271376":"### Testing with GT data","0a5dac72":"## Deepsorted","8a3f65c9":"# Point cloud matching algorithm","1b375e1e":"## Baseline helmets","3003ab9a":"# Testing"}}