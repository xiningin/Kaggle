{"cell_type":{"86e82072":"code","82bed03c":"code","6c419232":"code","4dd7bfc5":"code","221f3972":"code","58fe38f2":"code","3b91506d":"code","389b11a3":"code","ea3ca845":"code","4f62b601":"code","45eab594":"code","0886693f":"code","14c4d46c":"code","5a3a8702":"code","5b036bee":"code","cdfaa64c":"code","959519cc":"code","d626b9c4":"code","60560bf6":"code","0ad6e098":"code","efadbdd1":"code","5af566be":"markdown","2fdacdca":"markdown","82fee3bc":"markdown"},"source":{"86e82072":"pip install ttach #Test Time Augmentation","82bed03c":"# \u9996\u5148\u5bfc\u5165\u5305\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport ttach as tta\nimport os\nimport matplotlib.pyplot as plt\nimport torchvision.models as models\n# This is for the progress bar.\nfrom tqdm import tqdm","6c419232":"# \u770b\u770blabel\u6587\u4ef6\u957f\u5565\u6837\nlabels_dataframe = pd.read_csv('..\/input\/classify-leaves\/train.csv')\nlabels_dataframe.head(3)","4dd7bfc5":"# \u63d0\u53d6\u51falable\u5e76\u7edf\u8ba1\u7c7b\u522b\u4e2a\u6570 \u6392\u5e8f\nleaves_labels = sorted(list(set(labels_dataframe['label']))) #set\u5220\u6389\u91cd\u590d\u7684 sort\u6392\u5e8f\nn_classes = len(leaves_labels) #\u7c7b\u522b\u957f\u5ea6\nprint(n_classes) ","221f3972":"# \u628alabel\u8f6c\u6210\u5bf9\u5e94\u7684\u6570\u5b57\nclass_to_num = dict(zip(leaves_labels, range(n_classes)))\n# \u518d\u8f6c\u6362\u56de\u6765\uff0c\u65b9\u4fbf\u6700\u540e\u9884\u6d4b\u7684\u65f6\u5019\u4f7f\u7528\nnum_to_class = {v : k for k, v in class_to_num.items()}","58fe38f2":"# \u7ee7\u627fpytorch\u7684dataset\uff0c\u521b\u5efa\u81ea\u5df1\u7684Data\nclass LeavesData(Dataset):\n    def __init__(self, csv_path, file_path, mode='train', valid_ratio=0.2, resize_height=256, resize_width=256):\n        \"\"\"\n        Args:\n            csv_path (string): csv \u6587\u4ef6\u8def\u5f84\n            img_path (string): \u56fe\u50cf\u6587\u4ef6\u6240\u5728\u8def\u5f84\n            mode (string): \u8bad\u7ec3\u6a21\u5f0f\u8fd8\u662f\u6d4b\u8bd5\u6a21\u5f0f\n            valid_ratio (float): \u9a8c\u8bc1\u96c6\u6bd4\u4f8b\n        \"\"\"\n        \n        # \u9700\u8981\u8c03\u6574\u540e\u7684\u7167\u7247\u5c3a\u5bf8\uff0c\u6211\u8fd9\u91cc\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\u5c3a\u5bf8\u4e0d\u4e00\u81f4#\n        self.resize_height = resize_height\n        self.resize_width = resize_width\n\n        self.file_path = file_path\n        self.mode = mode\n\n        # \u8bfb\u53d6 csv \u6587\u4ef6\n        # \u5229\u7528pandas\u8bfb\u53d6csv\u6587\u4ef6\n        self.data_info = pd.read_csv(csv_path, header=None)  #header=None\u662f\u53bb\u6389\u8868\u5934\u90e8\u5206\n        # \u8ba1\u7b97 length                                        #\u4f46\u662f\u4f1a\u628a\u8868\u5934\u653e\u8fdb\u5217\u8868\n        self.data_len = len(self.data_info.index) - 1       #\u6240\u4ee5\u9700\u8981-1\n        self.train_len = int(self.data_len * (1 - valid_ratio))\n        \n        if mode == 'train':\n            # \u7b2c\u4e00\u5217\u5305\u542b\u56fe\u50cf\u6587\u4ef6\u7684\u540d\u79f0   \u4f8b\u5982images\/0.jpg\n            self.train_image = np.asarray(self.data_info.iloc[1:self.train_len, 0])  #self.data_info.iloc[1:,0]\u8868\u793a\u8bfb\u53d6\u7b2c\u4e00\u5217\uff0c\u4ece\u7b2c\u4e8c\u884c\u5f00\u59cb\u5230train_len\n            # \u7b2c\u4e8c\u5217\u662f\u56fe\u50cf\u7684 label       \u4f8b\u5982maclura_pomifera  \uff08\u53f6\u5b50\u79cd\u7c7b\uff09\n            self.train_label = np.asarray(self.data_info.iloc[1:self.train_len, 1])\n            self.image_arr = self.train_image \n            self.label_arr = self.train_label\n        elif mode == 'valid':  #\u9a8c\u8bc1\u96c6\u53ef\u4ee5\u9632\u6b62\u8fc7\u62df\u5408 \u89c2\u5bdf\u62df\u5408\u7ed3\u679c\n            self.valid_image = np.asarray(self.data_info.iloc[self.train_len:, 0])  \n            self.valid_label = np.asarray(self.data_info.iloc[self.train_len:, 1])\n            self.image_arr = self.valid_image\n            self.label_arr = self.valid_label\n        elif mode == 'test':\n            self.test_image = np.asarray(self.data_info.iloc[1:, 0])\n            self.image_arr = self.test_image\n            \n        self.real_len = len(self.image_arr)\n\n        print('Finished reading the {} set of Leaves Dataset ({} samples found)'\n              .format(mode, self.real_len))\n\n    def __getitem__(self, index):\n        # \u4ece image_arr\u4e2d\u5f97\u5230\u7d22\u5f15\u5bf9\u5e94\u7684\u6587\u4ef6\u540d\n        single_image_name = self.image_arr[index]  #self.image_arr[0]='images\/0.jpg'\n\n        # \u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\n        img_as_img = Image.open(self.file_path + single_image_name)\n\n        #\u5982\u679c\u9700\u8981\u5c06RGB\u4e09\u901a\u9053\u7684\u56fe\u7247\u8f6c\u6362\u6210\u7070\u5ea6\u56fe\u7247\u53ef\u53c2\u8003\u4e0b\u9762\u4e24\u884c\n#         if img_as_img.mode != 'L':\n#             img_as_img = img_as_img.convert('L')\n\n        #\u8bbe\u7f6e\u597d\u9700\u8981\u8f6c\u6362\u7684\u53d8\u91cf\uff0c\u8fd8\u53ef\u4ee5\u5305\u62ec\u4e00\u7cfb\u5217\u7684nomarlize\u7b49\u7b49\u64cd\u4f5c\n        if self.mode == 'train':                           #\u4e0b\u9762\u662f\u56fe\u50cf\u589e\u5e7f\n            transform = transforms.Compose([\n                #transforms.Resize(300),\n                #transforms.CenterCrop(224),\n                transforms.Resize(224),\n                transforms.RandomHorizontalFlip(p=0.5),   #\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\n                transforms.RandomVerticalFlip(p=0.5),     #\u9664\u4e86\u6c34\u5e73\u7ad6\u76f4\u53cd\u8f6c\u4e4b\u5916\u5176\u4ed6\u7684\u5904\u7406\u65b9\u6cd5\u8c8c\u4f3c\u90fd\u4f1a\u964d\u4f4eacc\n                #transforms.RandomResizedCrop((224, 224), scale=(0.7, 1)),\n                #transforms.RandomCrop((60, 120)), # \u968f\u673a\u526a\u88c1\n                # transforms.ColorJitter(0.3, 0.3, 0.2), # \u4fee\u6539\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u548c\u9971\u548c\u5ea6\n                #transforms.RandomRotation(180), # \u4f9ddegrees \u968f\u673a\u65cb\u8f6c\u4e00\u5b9a\u89d2\u5ea6   10\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                # Normalize(mean, std)\u6309\u901a\u9053\u8fdb\u884c\u6807\u51c6\u5316\uff0c\u5373\u5148\u51cf\u5747\u503c\uff0c\u518d\u9664\u4ee5\u6807\u51c6\u5deestd\n                 ])\n        else:\n            # valid\u548ctest\u4e0d\u505a\u6570\u636e\u589e\u5f3a  \u53ea\u9700\u8981\u88c1\u526a\u53d8\u6210\u5f20\u91cfTensor\n            transform = transforms.Compose([\n                transforms.Resize(224),\n                #transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n            ])\n        \n        img_as_img = transform(img_as_img)  #\u56fe\u50cf\u5904\u7406\n        \n        if self.mode == 'test':\n            return img_as_img  #\u6d4b\u8bd5\u96c6\u53ea\u9700\u8981\u8fd4\u56de\u56fe\u50cf\n        else: #\u8bad\u7ec3\u4ee5\u53ca\u6d4b\u8bd5\u6709\u6548\u6027\n            # \u5f97\u5230\u56fe\u50cf\u7684 string label\n            label = self.label_arr[index]   #\u4f8b\u5b50self.label_arr[0] = maclura_pomifera\n            # number label\n            number_label = class_to_num[label] #\u67e5\u9605\u5b57\u5178  \u5c06\u7c7b\u578b\u8f6c\u6362\u4e3a\u6570\u5b57\n\n            return img_as_img, number_label  #\u8fd4\u56de\u6bcf\u4e00\u4e2aindex\u5bf9\u5e94\u7684\u56fe\u7247\u6570\u636e\u548c\u5bf9\u5e94\u7684label\n\n    def __len__(self):\n         return self.real_len  #self.real_len = len(self.image_arr) \u8fd4\u56de\u7684\u662f\u8bad\u7ec3\/\u9a8c\u8bc1\/\u6d4b\u8bd5\/\u56fe\u50cf\u7684\u6570\u91cf","3b91506d":"#\u8bbe\u7f6e\u6587\u4ef6\u8def\u5f84\u5e76\u5f97\u5230\u6570\u636e\u96c6\ntrain_path = '..\/input\/classify-leaves\/train.csv'\ntest_path = '..\/input\/classify-leaves\/test.csv'\n# csv\u6587\u4ef6\u4e2d\u5df2\u7ecfimages\u7684\u8def\u5f84\u4e86\uff0c\u56e0\u6b64\u8fd9\u91cc\u53ea\u5230\u4e0a\u4e00\u7ea7\u76ee\u5f55\nimg_path = '..\/input\/classify-leaves\/'\n\ntrain_dataset = LeavesData(train_path, img_path, mode='train')\nval_dataset = LeavesData(train_path, img_path, mode='valid')\ntest_dataset = LeavesData(test_path, img_path, mode='test')\nprint(train_dataset)\nprint(val_dataset)\nprint(test_dataset)","389b11a3":"# \u5b9a\u4e49data loader\ntrain_loader = torch.utils.data.DataLoader(\n        dataset=train_dataset,\n        batch_size=90,      \n        shuffle=True,     #\u6253\u5f00\u4e71\u5e8f  False\n        num_workers=0\n    )\n\nval_loader = torch.utils.data.DataLoader(\n        dataset=val_dataset,\n        batch_size=90,   \n        shuffle=True,    #\u6253\u5f00\u4e71\u5e8f  False\n        num_workers=0\n    )\ntest_loader = torch.utils.data.DataLoader(\n        dataset=test_dataset,\n        batch_size=90, \n        shuffle=False,\n        num_workers=0\n    )","ea3ca845":"# GPU\u8ba1\u7b97\ndef get_device():\n    return 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndevice = get_device()\nprint(device)","4f62b601":"# \u8d85\u53c2\u6570\nlearning_rate = 1e-4   #1e-4\nweight_decay = 1e-3\nnum_epoch = 50\nbeta = 1              #cutmix\u53c2\u6570\nmodel_path = '.\/pre_res_model.ckpt' #\u4fdd\u5b58\u4e2d\u95f4\u6a21\u578b\u6570\u636e\uff0c\u65b9\u4fbf\u52a0\u8f7d","45eab594":"#\u5fae\u8c03\u5b66\u4e60\u7387 \ndef train_fine_tuning(net,learning_rate,param_group=True):\n    if param_group:\n        params_1x = [\n            param for name, param in net.named_parameters()\n            if name not in [\"fc.weight\", \"fc.bias\"]]\n        optimizer = torch.optim.Adam([{\n            'params': params_1x}, {\n                'params': net.fc.parameters(),\n                'lr': learning_rate * 10}], lr=learning_rate,  #10\n                                    weight_decay=0.001)\n    else:\n        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate* 0.2,\n                                      weight_decay=0.001)  \n    return optimizer","0886693f":"!pip install timm\n!pip install torchinfo\nimport timm                     #timm\u5e93\u6709\u66f4\u4e30\u5bcc\u7684\u9884\u8bad\u7ec3\u6a21\u578b\nfrom torchinfo import summary","14c4d46c":"model_1 = timm.create_model('seresnext50_32x4d', pretrained=True)\nmodel_1.fc = nn.Linear(model_1.fc.in_features, 176)\nnn.init.xavier_uniform_(model_1.fc.weight);\nmodel_1 = model_1.to(device) #GPU\nmodel_1.device = device","5a3a8702":"model_2 = models.resnext50_32x4d(pretrained=True)\nmodel_2.fc = nn.Linear(model_2.fc.in_features, 176)\nnn.init.xavier_uniform_(model_2.fc.weight);\nmodel_2 = model_2.to(device) #GPU\nmodel_2.device = device","5b036bee":"model_3 = models.resnext50_32x4d(pretrained=True)\nmodel_3.fc = nn.Linear(model_3.fc.in_features, 176)\nnn.init.xavier_uniform_(model_3.fc.weight);\nmodel_3 = model_3.to(device) #GPU\nmodel_3.device = device","cdfaa64c":"#cutmix\u8ba1\u7b97\u88c1\u526a\u533a\u57df\ndef rand_bbox(size, lamb):  #\u8ba1\u7b97\u81ea\u5b9a\u4e49\u88c1\u526a\u533a\u57df\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lamb)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w \/\/ 2, 0, W)\n    bby1 = np.clip(cy - cut_h \/\/ 2, 0, H)\n    bbx2 = np.clip(cx + cut_w \/\/ 2, 0, W)\n    bby2 = np.clip(cy + cut_h \/\/ 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2","959519cc":"#\u8bad\u7ec3\u51fd\u6570\ndef train_2(model): \n    optimizer = train_fine_tuning(model, learning_rate)\n    # \u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u6211\u4eec\u4f7f\u7528\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u6027\u80fd\u7684\u5ea6\u91cf\u3002\n    criterion = nn.CrossEntropyLoss()\n    # \u5b9a\u4e49\u5b66\u4e60\u7387\u8870\u51cf\n    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) #\u6309\u7167epoch\u8870\u51cf  \u4e0d\u597d\u7528\n    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=40,eta_min=0.00000001)  #\u4f59\u5f26\u53d8\u5316\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True, min_lr=0.0000001)\n    # \u521d\u59cb\u5316\u4f18\u5316\u5668\uff0c\u60a8\u53ef\u4ee5\u81ea\u884c\u5fae\u8c03\u4e00\u4e9b\u8d85\u53c2\u6570\uff0c\u5982\u5b66\u4e60\u901f\u7387\u3002\u6b64\u5904\u7528\u7684Adam\n    #optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n    \n    # \u8bad\u7ec3\u6b21\u6570\n    n_epochs = num_epoch\n    \n    best_acc = 0.0\n    for epoch in range(n_epochs):\n        # ---------- Training ----------  \u4ee5\u4e0b\u662f\u8bad\u7ec3\u6a21\u578b\n        # \u8bad\u7ec3\u524d\u786e\u4fdd\u6a21\u578b\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f\u3002\n        model.train() \n        # \u8bb0\u5f55\u8bad\u7ec3\u4fe1\u606f\n        train_loss = []\n        train_accs = []\n        # \u6309\u6279\u8fed\u4ee3\u8bad\u7ec3\u96c6\u3002\n        for batch in tqdm(train_loader):\n            # batch\u7531\u56fe\u50cf\u6570\u636e\u548c\u76f8\u5e94\u7684\u6807\u7b7e\u7ec4\u6210\u3002\n            imgs, labels = batch\n            imgs = imgs.to(device)    #\u6570\u636e\u79fb\u52a8\u5230GPU\n            labels = labels.to(device)\n            \n            #\u56fe\u7247\u88c1\u526a CUTMIX\u8bad\u7ec3\u4ee3\u7801\n            lam = np.random.beta(beta, beta) #\u751f\u6210\u968f\u673a\u88c1\u526a\u6743\u91cd\n            rand_index = torch.randperm(imgs.size()[0]).to(device) #\u6253\u4e71\u6837\u672c\u751f\u6210\u62fc\u63a5\u6837\u672c\n            labels_a = labels  #\u6b63\u5e38\u6837\u672c\u6807\u7b7e\n            labels_b = labels[rand_index]  #\u4e71\u5e8f\u6837\u672c\u6807\u7b7e\n            bbx1, bby1, bbx2, bby2 = rand_bbox(imgs.size(), lam) #\u751f\u6210\u88c1\u526a\u533a\u57df\n            #\u5c06\u539f\u6837\u672c\u4e2dbbx1:bbx2, bby1:bby2\u533a\u57df\u6539\u6210\u4e71\u5e8f\u6837\u672c\u6807\u7b7e\u5bf9\u5e94\u7684\u533a\u57df\n            imgs[:, :, bbx1:bbx2, bby1:bby2] = imgs[rand_index, :, bbx1:bbx2, bby1:bby2]\n            #\u91cd\u65b0\u8ba1\u7b97lambda\u4ee5\u7cbe\u786e\u5339\u914d\u50cf\u7d20\u6bd4\u7387\uff08\u56e0\u4e3a\u6709\u53ef\u80fd\u88c1\u526a\u8d85\u51fa\u8fb9\u754c\uff09\n            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) \/ (imgs.size()[-1] * imgs.size()[-2]))\n            # Forward the data. (Make sure data and model are on the same device.)\n            logits = model(imgs)  #\u5c06\u56fe\u5f62\u6570\u636e\u5e26\u5165\u6a21\u578b\u8ba1\u7b97\u9884\u6d4b\n            # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931(\u6ce8\u610f\u662f\u4e24\u4e2a\u6837\u672c\u7684\u635f\u5931\u6309\u7167\u5206\u5272\u6bd4\u4f8b\u52a0\u6743\u6c42\u548c)\n            loss = criterion(logits, labels_a) * lam + criterion(logits, labels_b) * (1. - lam)\n            \n            \n            # \u6e05\u9664\u4e0a\u4e00\u6b65\u4e2d\u5b58\u50a8\u5728\u53c2\u6570\u4e2d\u7684\u68af\u5ea6\u3002\n            optimizer.zero_grad()\n            # \u8ba1\u7b97\u53c2\u6570\u7684\u68af\u5ea6\u3002\n            loss.backward()\n            # \u7528\u8ba1\u7b97\u7684\u68af\u5ea6\u66f4\u65b0\u53c2\u6570\u3002\n            optimizer.step()\n        \n            # \u8ba1\u7b97\u5f53\u524d\u6279\u6b21\u7684\u7cbe\u5ea6\u3002\n            acc = (logits.argmax(dim=-1) == labels).float().mean()\n    \n            # \u8bb0\u5f55\u635f\u5931\u548c\u51c6\u786e\u5ea6\n            train_loss.append(loss.item())\n            train_accs.append(acc)\n            \n                \n            \n        # \u8bad\u7ec3\u96c6\u7684\u5e73\u5747\u635f\u5931\u548c\u7cbe\u5ea6\u662f\u8bb0\u5f55\u503c\u7684\u5e73\u5747\u503c\u3002\n        train_loss = sum(train_loss) \/ len(train_loss)\n        train_acc = sum(train_accs) \/ len(train_accs)\n        \n        \n        #\u66f4\u65b0\u5b66\u4e60\u7387\n        print(\"\u7b2c%d\u4e2aepoch\u7684\u5b66\u4e60\u7387\uff1a%f\" % (epoch, optimizer.param_groups[0]['lr']))\n        scheduler.step(train_loss)\n        \n        \n        # \u6253\u5370\u4fe1\u606f\n        print(f\"[ Train | {epoch + 1:03d}\/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n            \n            \n        # ---------- \u9a8c\u8bc1 ----------\n        #\u8fd9\u91cc\u6211\u8ba4\u4e3a\u5728\u9a8c\u8bc1\u5904\u4e5f\u52a0\u4e0aTTA\u4e5f\u8bb8\u66f4\u52a0\u5408\u7406\uff0c\u56e0\u4e3a\u524d\u9762\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e86\u53d8\u6362\uff0c\n        #\u5728\u9a8c\u8bc1\u7684\u65f6\u5019\u4e5f\u5c06\u56fe\u50cf\u8fdb\u884c\u76f8\u5bf9\u5e94\u7684\u53d8\u6362\u53ef\u80fd\u80fd\u591f\u63d0\u53d6\u66f4\u591a\u7684\u7279\u5f81\u3002\n        # \u786e\u4fdd\u6a21\u578b\u5904\u4e8eeval\u6a21\u5f0f\uff0c\u4ee5\u4fbf\u7981\u7528dropout\u7b49\u6a21\u5757\u5e76\u6b63\u5e38\u5de5\u4f5c\u3002\n        model.eval()\n        # \u8fd9\u4e9b\u7528\u4e8e\u8bb0\u5f55\u9a8c\u8bc1\u4e2d\u7684\u4fe1\u606f\n        valid_loss = []\n        valid_accs = []\n        \n        # \u9010\u6279\u8fed\u4ee3\u9a8c\u8bc1\u96c6\u3002\n        for batch in tqdm(val_loader):\n            imgs, labels = batch\n            # \u4e0d\u9700\u8981\u68af\u5ea6\u9a8c\u8bc1.\n            # Using  torch.no_grad()  accelerates the forward process.\n            with torch.no_grad():\n                logits = model(imgs.to(device))\n                  \n            # \u6211\u4eec\u4ecd\u7136\u53ef\u4ee5\u8ba1\u7b97\u635f\u5931\uff08\u4f46\u4e0d\u80fd\u8ba1\u7b97\u68af\u5ea6\uff09\u3002\n            loss = criterion(logits, labels.to(device))\n    \n            # \u8ba1\u7b97\u5f53\u524d\u6279\u6b21\u7684\u7cbe\u5ea6\u3002\n            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n    \n            # \u8bb0\u5f55\u635f\u5931\u548c\u51c6\u786e\u6027\n            valid_loss.append(loss.item())\n            valid_accs.append(acc)\n              \n        # \u6574\u4e2a\u9a8c\u8bc1\u96c6\u7684\u5e73\u5747\u635f\u5931\u548c\u51c6\u786e\u5ea6\u662f\u8bb0\u5f55\u503c\u7684\u5e73\u5747\u503c\n        valid_loss = sum(valid_loss) \/ len(valid_loss)\n        valid_acc = sum(valid_accs) \/ len(valid_accs)\n    \n        # \u6253\u5370\u4fe1\u606f.\n        print(f\"[ Valid | {epoch + 1:03d}\/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n            \n        # \u5982\u679c\u6a21\u578b\u6539\u8fdb\u4e86\uff0c\u5728\u8fd9\u4e2a\u65f6\u95f4\u70b9\u4fdd\u5b58\u4e00\u4e2a\u68c0\u67e5\u70b9\n        if valid_acc > best_acc:\n            best_acc = valid_acc\n            torch.save(model.state_dict(), model_path)\n            print('saving model with acc {:.3f}'.format(best_acc))","d626b9c4":"saveFileName = '.\/submission.csv'","60560bf6":"#\u5206\u522b\u8bad\u7ec3\u4e09\u4e2a\u6a21\u578b\u5e76\u5c06\u6700\u4f18\u53c2\u6570\u4fdd\u5b58\u5230\u76f8\u5e94\u7684\u6a21\u578b\u91cc\n#train_2(model_1)\n#model_1.load_state_dict(torch.load(model_path)) #\u52a0\u8f7d\u8bad\u7ec3\u7ed3\u679c\n#train_2(model_2)\n#model_2.load_state_dict(torch.load(model_path))\n#train_2(model_3)\n#model_3.load_state_dict(torch.load(model_path))","0ad6e098":"#\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b   \nmodel_1.load_state_dict(torch.load('..\/input\/modlesckpy\/seresnext50_32x4d_981.ckpt'))\nmodel_2.load_state_dict(torch.load('..\/input\/modlesckpy\/resnext50_32x4d_982.ckpt'))\nmodel_3.load_state_dict(torch.load('..\/input\/modlesckpy\/resnext50_32x4d_981.ckpt'))","efadbdd1":"# \u786e\u4fdd\u6a21\u578b\u5904\u4e8eeval\u6a21\u5f0f.\n# \u4e00\u4e9b\u6a21\u5757\u5982 Dropout or BatchNorm \u4f1a\u5f71\u54cd\u6027\u80fd \u5982\u679c\u6a21\u578b\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f.\nmodel_1.eval()\nmodel_2.eval()\nmodel_3.eval()\n#\u52a0\u8f7dTTA\n#tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.d4_transform(),  merge_mode='mean')\ntta_model_1 = tta.ClassificationTTAWrapper(model_1, tta.aliases.flip_transform(),  merge_mode='mean')\ntta_model_2 = tta.ClassificationTTAWrapper(model_2, tta.aliases.flip_transform(),  merge_mode='mean')\ntta_model_3 = tta.ClassificationTTAWrapper(model_3, tta.aliases.flip_transform(),  merge_mode='mean')\n\n# \u521d\u59cb\u5316\u5b58\u50a8\u9884\u6d4b\u7684\u5217\u8868\u3002\npredictions = []\n# \u9010\u6279\u8fed\u4ee3\u6d4b\u8bd5\u96c6.\nfor batch in tqdm(test_loader):\n    \n    imgs = batch\n    with torch.no_grad():\n        logits_1 = tta_model_1(imgs.to(device))  #\u9884\u6d4b\n        logits_2 = tta_model_2(imgs.to(device))\n        logits_3 = tta_model_3(imgs.to(device))\n        \n        logits = 0.5*logits_1+0.5*logits_2+0.5*logits_3\n        #logits = logits_2+logits_3\n    # \u4ee5\u6700\u5927\u7684logit\u7c7b\u4e3a\u9884\u6d4b\uff0c\u5e76\u8bb0\u5f55\u4e0b\u6765\n    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n\npreds = []\nfor i in predictions:\n    preds.append(num_to_class[i])  # \u5c06\u9884\u6d4b\u7684\u6570\u5b57\u7c7b\u522b\u8fd8\u539f\u4e3a\u7c7b\u522b\u540d\u79f0\n\ntest_data = pd.read_csv(test_path) #\u8bfb\u53d6\u9884\u6d4b\u6570\u636e\u96c6\ntest_data['label'] = pd.Series(preds)  #\u5c06\u9884\u6d4b\u7684\u7c7b\u578b\u540d\u6574\u7406\u6210\u4e00\u7ef4\u6570\u7ec4\nsubmission = pd.concat([test_data['image'], test_data['label']], axis=1)\nsubmission.to_csv(saveFileName, index=False)\nprint(\"Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")","5af566be":"Private Leaderboard 13th\n\n\u4f5c\u4e3a\u4e00\u4e2a\u96f6\u57fa\u7840\u8ddf\u674e\u6c90\u8001\u5e08\u5b66\u8fc7\u6765\u7684\u521d\u5b66\u8005\uff0c\u9996\u5148\u611f\u8c22\u6c90\u795e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b9\u4fbf\u50cf\u6211\u8fd9\u6837\u521d\u5b66\u8005\u5165\u95e8\u7684\u4f18\u8d28\u6559\u7a0b\n\n\u5176\u6b21\u91cd\u70b9\u611f\u8c22Neko Kiku\u540c\u5b66\u63d0\u4f9b\u7684baseline\uff0c\u4ee5\u53ca\u8ba8\u8bba\u533a\u7684\u5404\u4f4d\u540c\u5b66\u63d0\u4f9b\u7684\u6280\u5de7\u3002\n\n\u6ce8\uff1a\u7531\u4e8e\u6211\u662f\u5728\u7ebf\u4e0a\u8bad\u7ec3\u597d\u591a\u4e2a\u6a21\u578b\u4fdd\u5b58\u5230\u672c\u5730\u5171\u540c\u505a\u7684\u9884\u6d4b\uff0c\u76f4\u63a5\u653e\u5728\u4e00\u8d77\u8fd0\u884c\u597d\u50cf\u4f1a\u56e0\u4e3a\u8fde\u7eed\u8fd0\u884c\u65f6\u95f4\u8d85\u8fc710\u5c0f\u65f6\u800c\u81ea\u52a8\u53d6\u6d88\u8fd0\u7b97\uff0c\u6240\u4ee5\u8fd9\u91cc\u6211\u6ce8\u91ca\u6389\u4e86\u8bad\u7ec3\u6a21\u578b\u7684\u51fd\u6570\uff0c\u76f4\u63a5\u52a0\u8f7d\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002","2fdacdca":"\u8bad\u7ec3\u51fd\u6570\u8fd9\u91cc\u91c7\u7528\u4e86lr_scheduler\u6539\u53d8\u5b66\u4e60\u7387\n\n\u4e2a\u4eba\u611f\u89c9ReduceLROnPlateau\u76f8\u5bf9\u800c\u8a00\u66f4\u52a0\u65b9\u4fbf\u4e00\u4e9b","82fee3bc":"\u8fd9\u91cc\u9009\u62e9\u540c\u65f6\u8bad\u7ec3\u4e09\u4e2a\u6a21\u578b\uff0c\u4e00\u4e2aseresnext50\uff0c\u4e24\u4e2aresnext50"}}