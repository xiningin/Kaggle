{"cell_type":{"e5f5a4cf":"code","b56c0d52":"code","ea5538ed":"code","fd1deb12":"code","f1566788":"code","78a7f40a":"code","ea574afb":"code","43d0bc56":"code","9ed2f3ca":"code","b5f0bbd4":"code","9f5b1ffb":"code","5fb20aa7":"code","57e78fa6":"code","6b377da2":"code","1af0fd62":"code","4b648112":"code","4709e2a6":"code","2cda8b5d":"code","3a4898d1":"code","22195104":"code","a306da3a":"code","1cccb6d9":"code","f04ed584":"code","d2f1805a":"code","c783540c":"code","2e15781a":"code","8a88b19c":"code","f35da124":"code","52669746":"code","548e4e2a":"code","bf838225":"code","237b4876":"code","1a5b81b6":"code","00a8bf0b":"code","291f4ea8":"code","3d3f2a35":"code","9cf8a59b":"code","1e2aceca":"code","f518483f":"code","68b68d1d":"code","10236271":"code","1d99aab9":"code","e338f8ca":"code","b129db75":"code","05cd6212":"code","ced5e4dc":"code","53f572d8":"code","e29f0fc7":"code","dcaf35fb":"code","7b564461":"code","8fed3e01":"code","631b01d7":"code","f1272665":"code","ac901b01":"code","9a89074d":"code","c2022200":"code","551bb765":"code","9e993f78":"code","9fdff640":"code","d3359659":"code","5c543f07":"code","6fa7f5ed":"code","dc5d111a":"code","412ea11c":"code","4abb9f51":"code","9fdfbcee":"code","409b1df1":"code","b6e4bebd":"code","6c675a6f":"code","d3b00827":"code","ec3bc915":"code","8e29cdba":"code","81d8c258":"code","2b4dc710":"code","b0a17ec5":"code","5a3c0308":"code","6e65db15":"code","f6c80e97":"code","d805b9ac":"code","8897b70e":"code","f187e90b":"code","c4741daa":"code","58a65202":"code","1ec31b77":"code","caa05776":"code","639653a4":"code","1ca8060c":"code","264d10bf":"code","956c4d7e":"code","9da0bb7b":"code","aa9a559a":"code","36700a91":"code","3fdddb19":"code","1a8d9b33":"code","4f2bd0d6":"code","1ca65b5a":"code","9c12ebd1":"code","5e0227aa":"code","609f8e09":"code","0703b01b":"code","1657ddbf":"code","0ce7f418":"code","2cc816e6":"code","0dd47504":"code","1e801f89":"code","a4212d14":"code","92e7cf1f":"code","1f4b4d3d":"code","4e8229b1":"code","c2a0c10e":"code","c2a686b7":"code","e2ec704e":"code","aed22e23":"code","5062e945":"code","61011851":"code","f6fd9c81":"code","dcf38aad":"code","99dfec6b":"code","ddf7293d":"code","4eb6d2c9":"code","8161b7ba":"code","ddc64e53":"code","fa96b912":"code","e5777814":"code","fce9822e":"code","4b437329":"code","81033751":"markdown","b22939f3":"markdown","612a4bc1":"markdown","bbf26d32":"markdown","7428e6ea":"markdown","99d32866":"markdown","7d1c1e61":"markdown","aea3d493":"markdown","78c59d04":"markdown","06e82bae":"markdown","777ebf21":"markdown","f293ef44":"markdown","2202e6a3":"markdown","4e6eb1a6":"markdown","12b72312":"markdown","28d78a65":"markdown","3552ce4d":"markdown","e125cd51":"markdown","78feb239":"markdown","3bb1e3e7":"markdown","366d3aa2":"markdown","34b6ebee":"markdown","97ea7dca":"markdown","80dda536":"markdown","2231de74":"markdown","2fe93f86":"markdown","a123ab1a":"markdown","3a83eb66":"markdown","aa380366":"markdown","405d3178":"markdown","b627631f":"markdown","d8e826db":"markdown","0d220a35":"markdown","2553d826":"markdown","0c41c15c":"markdown","c99ebf1a":"markdown","fcfb422d":"markdown","8e77a46e":"markdown","cc2a6713":"markdown","ed35c085":"markdown","b4c3fa17":"markdown","46f3cef2":"markdown","9e16f469":"markdown","e84e94e4":"markdown","5a55df97":"markdown","ae91aa73":"markdown","9b5eaed8":"markdown","5332f713":"markdown","1ceee2ec":"markdown","1167c090":"markdown","a9492b41":"markdown","010d15e6":"markdown"},"source":{"e5f5a4cf":"!wget 'https:\/\/anaconda.org\/conda-forge\/gdcm\/2.8.9\/download\/linux-64\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q\n!conda install 'gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y","b56c0d52":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n","ea5538ed":"import matplotlib.pyplot as plt\nimport matplotlib\nimport pydicom as dicom\nimport cv2\nimport ast\nimport warnings\nwarnings.filterwarnings('ignore')","fd1deb12":"path = '\/kaggle\/input\/siim-covid19-detection\/'","f1566788":"os.listdir(path)","78a7f40a":"train_image = pd.read_csv(path+'train_image_level.csv')\ntrain_study = pd.read_csv(path+'train_study_level.csv')\nsample_submission = pd.read_csv(path+'sample_submission.csv')","ea574afb":"len(sample_submission)","43d0bc56":"train_image","9ed2f3ca":"train_study","b5f0bbd4":"temp = train_image.loc[0, 'StudyInstanceUID']\ntemp","9f5b1ffb":"temp_depth2 = os.listdir(path+'train\/'+temp)\ntemp_depth2[0]","5fb20aa7":"temp_train_path = path+'train\/'+temp+'\/'+temp_depth2[0]\ntemp_train_path","57e78fa6":"os.listdir('\/kaggle\/input\/siim-covid19-detection\/train\/5776db0cec75\/81456c9c5423')  ","6b377da2":"train_image.loc[0, 'id']","1af0fd62":"def extraction(i):\n    path_train = path + 'train\/' + train_image.loc[i, 'StudyInstanceUID']\n    last_folder_in_path = os.listdir(path_train)[0]\n    path_train = path_train + '\/{}\/'.format(last_folder_in_path)\n    img_id = train_image.loc[i, 'id'].replace('_image','.dcm')\n    print(img_id)\n    data_file = dicom.dcmread(path_train+img_id)\n    img = data_file.pixel_array\n    return img","4b648112":"sample_img = extraction(0)","4709e2a6":"sample_img","2cda8b5d":"sample_img.shape","3a4898d1":"train_image.loc[0, 'boxes']","22195104":"boxes = ast.literal_eval(train_image.loc[0, 'boxes'])\nboxes","a306da3a":"fig, ax = plt.subplots(1,1, figsize=(8,4))\nfor box in boxes:\n    p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                      box['width'], box['height'],\n                                      ec='r', fc='none', lw=1.5)\n    ax.add_patch(p)\nax.imshow(sample_img, cmap='gray')\nplt.show()\n","1cccb6d9":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\n\nfor row in range(9):\n    img = extraction(row)\n    # if (nan == nan)\n    # False\n    if (train_image.loc[row,'boxes'] == train_image.loc[row,'boxes']):\n        boxes = ast.literal_eval(train_image.loc[row,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='r', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_image.loc[row, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])","f04ed584":"train_image","d2f1805a":"OpacityCount = train_image['label'].str.count('opacity')\nOpacityCount","c783540c":"train_image['OpacityCount'] = OpacityCount.values","2e15781a":"train_image","8a88b19c":"train_image['id'].isnull().sum()","f35da124":"id_extract = lambda x : x[0]","52669746":"train_study","548e4e2a":"train_study['id'].isnull().sum()","bf838225":"train_study['id'].str.split('_')","237b4876":"train_study['id'].str.split('_').apply(id_extract)","1a5b81b6":"train_study['id'] = train_study['id'].str.split('_').apply(id_extract)","00a8bf0b":"sum(train_study['id'].str.contains(train_image['StudyInstanceUID'][0]))","291f4ea8":"train_study = train_study.rename({'id':'StudyInstanceUID'}, axis=1)","3d3f2a35":"train_study","9cf8a59b":"train_df = pd.merge(train_image, train_study, on='StudyInstanceUID')\ntrain_df","1e2aceca":"train_df['OpacityCount'].value_counts()","f518483f":"train_df.iloc[:,5:].columns","68b68d1d":"i = 5\nfor col in train_df.iloc[:,5:].columns:\n    print('The Count of {} : '.format(col), sum(train_df.iloc[:,i]))\n    i += 1","10236271":"train_df[train_df['OpacityCount'] == 0]","1d99aab9":"OCount = sorted(list(train_df['OpacityCount'].value_counts().index))\nprint(OCount)","e338f8ca":"for count in OCount:\n    print('Opacity Count = {}\\n------------------------------'.format(count))\n    print(train_df[train_df['OpacityCount'] == count].iloc[:,5:].sum())\n    print(' ')","b129db75":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","05cd6212":"for count in OCount:\n    Count_Series = train_df[train_df['OpacityCount'] == count].iloc[:,5:].sum()\n    fig = plt.figure(figsize=(12,3))\n    sns.barplot(x=Count_Series.index, y=Count_Series.values\/sum(train_df['OpacityCount']==count))\n    plt.title('OpacityCount : {} '.format(count))\n    plt.plot();","ced5e4dc":"sum(train_df['OpacityCount']==1)","53f572d8":"train_df[(train_df['OpacityCount']==1)&(train_df['Indeterminate Appearance'] == 1)]","e29f0fc7":"train_df[(train_df['OpacityCount']==1)&(train_df['Atypical Appearance'] == 1)]","dcaf35fb":"train_df[(train_df['OpacityCount']==1)&(train_df['Typical Appearance'] == 1)]","7b564461":"len(train_df[(train_df['OpacityCount']==1)&(train_df['Indeterminate Appearance'] == 1)]) + len(train_df[(train_df['OpacityCount']==1)&(train_df['Atypical Appearance'] == 1)]) + len(train_df[(train_df['OpacityCount']==1)&(train_df['Typical Appearance'] == 1)])","8fed3e01":"sum(train_df['OpacityCount']==1)","631b01d7":"sample_submission","f1272665":"train_study","ac901b01":"train_image","9a89074d":"train_df","c2022200":"len(train_df['StudyInstanceUID'])","551bb765":"len(train_df['StudyInstanceUID'].unique())","9e993f78":"train_image['StudyInstanceUID'].unique().sort() == train_study['StudyInstanceUID'].unique().sort()","9fdff640":"len(train_image['StudyInstanceUID'].unique())","d3359659":"train_image[train_image.duplicated(['StudyInstanceUID'])==True]['StudyInstanceUID']","5c543f07":"du_StudyId = train_image[train_image.duplicated(['StudyInstanceUID'])==True]['StudyInstanceUID'].values","6fa7f5ed":"du_images = train_image[train_image['StudyInstanceUID'].isin(du_StudyId)].sort_values(by=['StudyInstanceUID'])\ndu_images","dc5d111a":"train_df[train_df['StudyInstanceUID'].str.contains('74ba8f2')]","412ea11c":"os.listdir(path + 'train\/' + '74ba8f2badcb')","4abb9f51":"long_path = path + 'train\/' + '74ba8f2badcb\/'\nfor i in os.listdir(long_path):\n    print(os.listdir(long_path+i))","9fdfbcee":"os.listdir('\/kaggle\/input\/siim-covid19-detection\/train\/ff0879eb20ed\/d8a644cc4f93')","409b1df1":"def error_processed_extraction(i):\n    long_path = path + 'train\/' + train_df.loc[i, 'StudyInstanceUID'] + '\/'\n    img_id = train_df.loc[i, 'id'].replace('_image','.dcm')\n    for dcm in os.listdir(long_path):\n        dcm_path = long_path+dcm+'\/'\n        if img_id == os.listdir(dcm_path)[0]:\n            data_file = dicom.dcmread(dcm_path+img_id)\n            print('index : {} - DCM File Path :{}'.format(i, dcm_path+img_id))\n        else:\n            continue\n            \n    img = data_file.pixel_array\n    return img","b6e4bebd":"OpacityType = list(train_df.iloc[:,5:].columns)\nOpacityType","6c675a6f":"train_df[train_df[OpacityType[0]]==1]","d3b00827":"Negative_Idx = list(train_df[train_df[OpacityType[0]]==1].index)\nNegative_Idx[:9]","ec3bc915":"train_df.iloc[Negative_Idx, :]","8e29cdba":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Negative_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='r', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(str(train_df.loc[idx, 'label'].split(' ')[0])+ str(idx))\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","81d8c258":"Typical_Idx = list(train_df[train_df[OpacityType[1]]==1].index)\nTypical_Idx[:9]","2b4dc710":"train_df.iloc[Typical_Idx, :]","b0a17ec5":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Typical_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='r', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","5a3c0308":"Indeterminate_Idx = list(train_df[train_df[OpacityType[2]]==1].index)\nIndeterminate_Idx[:9]","6e65db15":"train_df.iloc[Indeterminate_Idx, :]","f6c80e97":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Indeterminate_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='b', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","d805b9ac":"Atypical_Idx = list(train_df[train_df[OpacityType[3]]==1].index)\nAtypical_Idx[:9]","8897b70e":"train_df.iloc[Atypical_Idx, :]","f187e90b":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Atypical_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='g', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","c4741daa":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1)]","58a65202":"i=0\nfig, axes = plt.subplots(nrows=1,ncols=3, figsize=(12,4))\nfor type in OpacityType[1:]:\n    sr = train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1)].loc[:,type].value_counts()\n    sns.barplot(x=sr.index, y=sr.values, ax=axes[i])\n    axes[i].set_title(type)\n    i += 1","1ec31b77":"Anom_Count = train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1)][OpacityType[1:]].sum()\nAnom_Count","caa05776":"plt.figure(figsize=(8,4))\nsns.barplot(x=Anom_Count.index, y=Anom_Count.values)\nplt.title('Count of \"label==none\"')\nplt.show()","639653a4":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Typical Appearance']==1)].head()","1ca8060c":"Outlier_Typical_Idx = list(train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Typical Appearance']==1)].index)\nOutlier_Typical_Idx[:6]","264d10bf":"fig, axes = plt.subplots(2,3, figsize=(20,10))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Outlier_Typical_Idx[:6]:\n    img = error_processed_extraction(idx)\n\n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","956c4d7e":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Indeterminate Appearance']==1)].head()","9da0bb7b":"Outlier_Indeterminate_Idx = list(train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Indeterminate Appearance']==1)].index)\nOutlier_Indeterminate_Idx[:6]","aa9a559a":"fig, axes = plt.subplots(2,3, figsize=(20,10))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Outlier_Indeterminate_Idx[:6]:\n    img = error_processed_extraction(idx)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","36700a91":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Atypical Appearance']==1)].head()","3fdddb19":"Outlier_Atypical_Idx = list(train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Atypical Appearance']==1)].index)\nOutlier_Atypical_Idx[:6]","1a8d9b33":"fig, axes = plt.subplots(2,3, figsize=(20,10))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Outlier_Atypical_Idx[:6]:\n    img = error_processed_extraction(idx)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","4f2bd0d6":"for _, row in train_df.iloc[:5].iterrows():\n    print(row)","1ca65b5a":"from glob import glob","9c12ebd1":"for _, row in train_df.iloc[:5].iterrows():\n    image_id = row['id'].split('_')[0]\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{path}\/train\/{study_id}\/*\/{image_id}.dcm')\n    print(img_path)","5e0227aa":"path_list = []\nfor _, row in train_df.iterrows():\n    image_id = row['id'].split('_')[0]\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{path}\/train\/{study_id}\/*\/{image_id}.dcm')\n    if len(img_path)==1:\n        path_list.append(img_path[0])\n    else:\n        print(img_path)","609f8e09":"len(path_list)","0703b01b":"path_list[:10]","1657ddbf":"train_df['Path'] = path_list","0ce7f418":"train_df","2cc816e6":"train_df.to_csv('train_df.csv')","0dd47504":"data_file = dicom.read_file(path_list[0])","1e801f89":"data_file.pixel_array","a4212d14":"data_file","92e7cf1f":"data_file.Rows","1f4b4d3d":"data_file.Columns","4e8229b1":"# Test function, We don't use this\ndef extract_img_size(path_list):\n    origin_img_heights = []\n    origin_img_widths = []\n    i = 0\n    for path in path_list:\n        data_file = dicom.read_file(path)\n        origin_img_heights.append(data_file.Rows)\n        origin_img_widths.append(data_file.Columns)\n        i += 1\n        if i % 100 == 0:\n            print('{}\/{}'.format(i,len(path_list)))\n            \n    return origin_img_heights, origin_img_widths","c2a0c10e":"origin_img_heights, origin_img_widths = extract_img_size(path_list[:10])","c2a686b7":"origin_img_heights","e2ec704e":"origin_img_widths","aed22e23":"# We use this function\nimport cv2\ndef extract_resized_and_origin_img_info(path_list):\n    img_list = []\n    origin_img_heights = []\n    origin_img_widths = []\n    i = 0\n    for path in path_list:\n        data_file = dicom.read_file(path)\n        img = data_file.pixel_array\n\n            \n        origin_img_heights.append(img.shape[0])\n        origin_img_widths.append(img.shape[1])\n\n        \n        # scailing to 0~255\n        img = (img - np.min(img)) \/ np.max(img)\n        img = (img * 255).astype(np.uint8)\n        \n        # resizing to 4000+ to 150 default\n        img = cv2.resize(img, (150,150))\n        img_list.append(img)\n        img_array = np.array(img_list)\n        i += 1\n        if i % 100 == 0:\n            print('{} \/ {}'.format(len(img_array),len(path_list)))\n    return img_array, origin_img_heights, origin_img_widths","5062e945":"test_imgs, origin_img_heights2, origin_img_widths2 = extract_resized_and_origin_img_info(path_list[:10])","61011851":"test_imgs.shape","f6fd9c81":"test_imgs[0].shape","dcf38aad":"test_imgs[0]","99dfec6b":"print('pixel range : ', '{} ~ {}'.format(min(test_imgs[0].reshape(-1)),max(test_imgs[0].reshape(-1))))","ddf7293d":"origin_img_heights2","4eb6d2c9":"origin_img_widths2","8161b7ba":"print((origin_img_heights == origin_img_heights2), (origin_img_widths == origin_img_widths2))","ddc64e53":"x_scale_list=[]\ny_scale_list=[]\nif len(origin_img_heights) == len(origin_img_widths):\n    for i in range(len(origin_img_heights)):\n        x_scale = 150 \/ origin_img_widths[i]\n        x_scale_list.append(x_scale)\n        print(i)\n        y_scale = 150 \/ origin_img_heights[i]\n        y_scale_list.append(y_scale)","fa96b912":"x_scale_list","e5777814":"y_scale_list","fce9822e":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in range(9):\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='b', fc='none', lw=2.)\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","4b437329":"fig, axes = plt.subplots(3,3, figsize=(16,16))\nfig.subplots_adjust(hspace=.1, wspace=.05)\naxes = axes.ravel()\nrow = 0\nfor idx in range(9):\n    img = test_imgs[idx]\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x']*x_scale_list[idx], box['y']*y_scale_list[idx]),\n                                              box['width']*x_scale_list[idx], box['height']*y_scale_list[idx],\n                                              ec='b', fc='none', lw=2.)\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","81033751":"Duplicate ID - ex. 1 ID(74ba8f2badcb) - 4 Path(in each path, All 4 Images are the same)","b22939f3":"### 6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'","612a4bc1":"## Step 6. Feature Engineering I","bbf26d32":"### 6-f. Check Duplicate Values(One row and Two Appearances)","7428e6ea":"### 9-d. Show Outliers in `Atypical Appearance`","99d32866":"Now, Let's check duplicated images(id)","7d1c1e61":"### 3-b. make image extractor(function)","aea3d493":"All Image path have been saved (6334)","78c59d04":"### Thanks for nice reference : \n\n`handling dcm file`\n- [SIIM-FISABIO-RSNA_COVID-19_Detection_Starter, DrCapa](https:\/\/www.kaggle.com\/drcapa\/siim-fisabio-rsna-covid-19-detection-starter)\n\n`Image Visualization`\n- [2. ONE STOP:Understanding+InDepth EDA+Model](https:\/\/www.kaggle.com\/harshsharma511\/one-stop-understanding-indepth-eda-model-progress)\n\n`using gdcm without internet access`\n- [pydicom_conda_helper](https:\/\/www.kaggle.com\/awsaf49\/pydicom-conda-helper)\n\n`Get the box informations`\n- [catch up on positive samples \/ plot submission.csv](https:\/\/www.kaggle.com\/yujiariyasu\/catch-up-on-positive-samples-plot-submission-csv?scriptVersionId=63394385)","06e82bae":"We can find that No duplicates in train_study(original ID) because the length of unique `StudyInstanceUID` in train_df and the length of train_study's rows are the same","777ebf21":"## Step 7. Feature Engineering II","f293ef44":"### 9-a. anomaly detection\n\n- Cases with no opacity detected but classified as symptomatic","2202e6a3":"### 6-d. Check the Relation between 'OpacityCount' and other Columes in train_study","4e6eb1a6":"### 10-c. Calculate the resize ratio(x, y) and Apply the same to the bounding box","12b72312":"### 4-a. Explore Image Data with python code","28d78a65":"## Step 5. Show Multiple Images","3552ce4d":"## 8. Visualize X-ray with bbox","e125cd51":"### 8-d. Atypical Appearance","78feb239":"### 8-a. Negative for Pneumonia","3bb1e3e7":"### 9-b. Show Outliers in `Typical Appearance`","366d3aa2":"## Step 2. Load Data","34b6ebee":"### 8-c. Indeterminate Appearance","97ea7dca":"\nSearch all paths through a loop and check whether it matches the id value.","80dda536":"So, Some of the code(function extraction) needs to be modified to accurately target the image to be extracted.","2231de74":"# SIIM: Step-by-Step Image Detection for Beginners \n## Part 1 - EDA to Preprocessing\n\n\ud83d\udc49 Part 2. [Basic Modeling (The Easiest Model using Keras)](https:\/\/www.kaggle.com\/songseungwon\/siim-covid-19-detection-10-step-tutorial-2)\n\n\ud83d\udc49 Mini Part. [Preprocessing for Multi-Output Regression that Detect Opacities](https:\/\/www.kaggle.com\/songseungwon\/siim-covid-19-detection-mini-part-preprocess)","2fe93f86":"### 10-a. Add image path to a separate column","a123ab1a":"## Step 1. Import Libraries","3a83eb66":"```\n232 original ID\n280 duplicate ID\n```\n\n- one or more duplicate Image at the same ID","aa380366":"We use this dataframe at Part 2. Let's save this to csv file.","405d3178":"exactly same result on two function","b627631f":"### 7-b. Check duplicates in dataset","d8e826db":"### 6-a. Count Opacity in Image","0d220a35":"### 3-a. explore path with python code","2553d826":"### 6-b. Simplify 'id' (study)","0c41c15c":"We need to load the gdcm package before import `pydicom`. because some of the dcm files are `jpeg lossless` type.","c99ebf1a":"The number of `StudyInstanceUID` in train_study(original id) is different from the number of `StudyInstanceUID` in train_df(==train_image)\n\nLet's check them","fcfb422d":"Before vs after resizing","8e77a46e":"## Step 10. Image Data Preprocessing","cc2a6713":"## Step 3. Read DCM File","ed35c085":"### 9-c. Show Outliers in `Indeterminate Appearance`","b4c3fa17":"## Step 4. Show Sample Image","46f3cef2":"> Index\n\n```\nStep 1. Import Libraries\nStep 2. Load Data\nStep 3. Read DCM File\n     3-a. explore path with python code\n     3-b. make image extractor(function)\nStep 4. Show Sample Image\n     4-a. explore image data with python code\n     4-b. check position to draw box\nStep 5. Show Multiple Images\nStep 6. Feature Engineering I\n     6-a. count opacity\n     6-b. simplify 'id'\n     6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'\n     6-d. check the relation between 'OpacityCount' and other columes in train_study\n     6-e. visualize the relation between 'OpacityCount' and other columes in train_study\n     6-f. check duplicate values(One row and Two Appearances)\nStep 7. Feature Engineering II\n     7-a. explore data analysis\n     7-b. check duplicates in dataset\n     7-c. modify some of the code in function that extract image(.dcm)\nStep 8. Visualize X-ray with bbox\n     8-a. negative for pneumonia\n     8-b. typical appearance\n     8-c. indeterminate appearance\n     8-d. atypical Appearance\nStep 9. Featrue Engineering III\n     9-a. anomaly detection\n     9-b. show outliers in `Typical Appearance`\n     9-c. show outliers in `Intermiate Appearance`\n     9-d. show outliers in `Atypical Appearance`\nStep 10. Image Data Preprocessing\n     10-a. add image path to a separate column\n     10-b. Resize the image (uniform to 150x150) and Scale each pixel values (uniform range 1~255)\n     10-c. Calculate the resize ratio(x, y) and Apply the same to the bounding box\n```  ","9e16f469":"### 7-a. explore data analysis","e84e94e4":"### 10-b. Resize the image (uniform to 150x150) and Scale each pixel values (uniform range 1~255)","5a55df97":"### 6-e. Visualize the Relation between 'OpacityCount' and other Columes in train_study","ae91aa73":"### 7-c. modify some of the code in function that extract image(.dcm)","9b5eaed8":"### 8-b. Typical Appearance","5332f713":"### 4-b. check position to draw box","1ceee2ec":"\nOutliers detected through above visualizations. let's check them","1167c090":"**Anomaly 304 rows : label is 'none' but Non Negative for Pneumonia**","a9492b41":"Naturally, because `train_df` is a merged data frame based on `train_image`, `train_image` has also the same result.","010d15e6":"## 9. Feature Engineering III"}}