{"cell_type":{"61daa672":"code","c7511b44":"code","f6a89483":"code","58245e70":"code","fa6507fe":"code","bd0282c9":"markdown"},"source":{"61daa672":"import warnings\nwarnings.simplefilter('ignore')\n\nimport gc\n\nimport numpy as np\nimport pandas as pd\n\npd.set_option('max_columns', None)\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GroupKFold\n\nimport joblib\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","c7511b44":"class UBIQUANT_DATASET(Dataset):\n    def __init__(self, df_data):\n        self.ids = np.array(df_data['investment_id'].values.tolist(), dtype=np.int64)\n        self.vals = np.array(df_data.iloc[:, 1:].values.tolist(), dtype=np.float64)\n        self.len = df_data.shape[0]\n        \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self, index):\n        ids_out = self.ids[index]\n        vals_out = self.vals[index]\n        return ids_out, vals_out","f6a89483":"def swish(x):\n    return x * torch.sigmoid(x)\n\n\nclass SimpleMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.emb = nn.Embedding(3774, 64)\n        self.emb_drop = nn.Dropout(0.1)\n        \n        self.bn1 = nn.BatchNorm1d(300)\n        self.lin1 = nn.Linear(64+300, 32)\n        self.lin2 = nn.Linear(32, 128)\n        self.lin3 = nn.Linear(128, 64)\n        self.lin4 = nn.Linear(64, 32)\n        self.lin_drop = nn.Dropout(0.25)\n        self.lin5 = nn.Linear(32, 1)    \n\n    def forward(self, x_cat, x_cont):\n        x1 = self.emb(x_cat)\n        x1 = self.emb_drop(x1)\n        \n        x2 = self.bn1(x_cont)\n\n        x = torch.cat([x1, x2], 1)\n        x = swish(self.lin1(x))\n        x = swish(self.lin2(x))\n        x = swish(self.lin3(x))\n        x = swish(self.lin4(x))\n        x = self.lin5(x)\n        \n        return x\n    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","58245e70":"scaler = joblib.load('..\/input\/ubiquant-simplemlp-5folds\/minmaxscaler.pkl')\ncont_feats = [f'f_{i}' for i in range(300)]\n\nmodels_list = list()\nfor fold_id in range(5):\n    model = SimpleMLP().to(device)\n    model.load_state_dict(torch.load(f'..\/input\/ubiquant-simplemlp-5folds\/simple_mlp_model_{fold_id}.pth'))\n    models_list.append(model)","fa6507fe":"import ubiquant\n\nenv = ubiquant.make_env()\niter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.drop([\"row_id\"], axis=1)\n    test_df[cont_feats] = scaler.transform(test_df[cont_feats])\n    test_set = UBIQUANT_DATASET(test_df)\n    test_dataloader = DataLoader(test_set, batch_size=1024, \n                                 num_workers=2, pin_memory=True, shuffle=False)\n    y_preds = list()\n    with torch.no_grad():\n        for i, (ids, vals) in enumerate(test_dataloader):\n            ids = ids.to(device)\n            vals = vals.to(device=device, dtype=torch.float)\n            y_pred = np.zeros((len(ids), ))\n            for model in models_list:\n                model.eval()\n                y_pred += model(ids, vals).detach().cpu().numpy().flatten() \/ 5\n            y_preds.extend(y_pred)\n    sample_prediction_df['target'] = y_preds\n    env.predict(sample_prediction_df)\n    display(sample_prediction_df)","bd0282c9":"training code: https:\/\/www.kaggle.com\/hengzheng\/nn-mlp-5folds-training"}}