{"cell_type":{"a04ada0c":"code","40f4383c":"code","89237890":"code","8fb2ace3":"code","02a6913e":"code","eb5291af":"code","a833d405":"code","d9ca06b0":"code","12e401f4":"code","686abbf2":"code","604ee1aa":"code","ccba71ad":"code","02437d7a":"code","08af83ea":"code","e037850f":"code","3e47df15":"code","51dc7174":"code","90ffaf73":"code","fbd0bf64":"code","12de97ee":"code","d9c65d26":"code","519508f4":"code","3a213466":"code","4efe6c39":"code","e6a2949a":"code","3a22654f":"code","2099ed9a":"code","2cb2c7f4":"code","80667b63":"code","87ad5a33":"code","ce18f8c0":"code","c79e681c":"code","0a814f45":"code","ed4851f4":"code","f6ddc1c7":"code","6cdb8213":"code","0a6fcfd5":"markdown","10019e40":"markdown","9a37f1de":"markdown","b60e6787":"markdown","a39b14d3":"markdown","b16f4065":"markdown","26d6ac5b":"markdown","1284d147":"markdown","f5ea87fd":"markdown","0e9cd35d":"markdown","0b11f9c4":"markdown","21a46562":"markdown","d290b006":"markdown","8a3da40c":"markdown","29fde86f":"markdown","08fe7cb4":"markdown","2d93f2df":"markdown","5b9a73de":"markdown","9a6ef672":"markdown","99bd592e":"markdown","58e230f2":"markdown","620074a0":"markdown","03912936":"markdown","934420af":"markdown","04b05107":"markdown","f585d7ca":"markdown","bdb3bc1a":"markdown","13cf80a5":"markdown","fbb727c3":"markdown","cff132e6":"markdown","3ca6810a":"markdown","bda39c43":"markdown","e6dec799":"markdown"},"source":{"a04ada0c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","40f4383c":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.regularizers import l2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","89237890":"dataset = pd.read_csv('\/kaggle\/input\/san-francisco-employee-salary-compensation\/Employee_Salary_Compensation.csv')","8fb2ace3":"dataset","02a6913e":"dataset.info()","eb5291af":"dataset.isnull().sum()","a833d405":"dataset.describe()","d9ca06b0":"import missingno as msno\nmsno.matrix(dataset)","12e401f4":"msno.bar(dataset, sort= 'descending')","686abbf2":"#Dropping because they have similar features in column.\ndataset.drop(['Organization Group','Department','Union','Job Family','Job','Employee Identifier','Total Salary','Total Benefits'], axis=1, inplace=True)","604ee1aa":"categorical = [i for i in dataset.columns if dataset[i].dtype=='object']\ncategorical","ccba71ad":"numerical = [i for i in dataset.columns if dataset[i].dtype!='object']\nnumerical","02437d7a":"dataset[categorical].isnull().sum()","08af83ea":"dataset['Department Code'].fillna(dataset['Department Code'].mode()[0], inplace=True)","e037850f":"dataset[categorical].isnull().sum()","3e47df15":"dataset[numerical].isnull().sum()","51dc7174":"dataset['Union Code'].replace(to_replace=np.nan, value=dataset['Union Code'].median(), inplace=True)","90ffaf73":"dataset.isnull().sum()","fbd0bf64":"from sklearn.preprocessing import LabelEncoder","12de97ee":"le =  LabelEncoder()\nfor i in dataset:\n    if dataset[i].dtype=='object':\n        dataset[i] = le.fit_transform(dataset[i])\n    else:\n        continue","d9c65d26":"dataset.info()","519508f4":"dataset.head()","3a213466":"dataset['Union Code'] = dataset['Union Code'].astype(int)","4efe6c39":"x = dataset.drop('Total Compensation', axis=1).values\ny = dataset['Total Compensation']","e6a2949a":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)","3a22654f":"print(\"Number transactions x_train dataset: \", x_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions x_test dataset: \", x_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","2099ed9a":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","2cb2c7f4":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.optimizers import SGD","80667b63":"ann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(units= 32, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\ntf.keras.layers.Dropout(0.6)\nann.add(tf.keras.layers.Dense(units= 32, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\ntf.keras.layers.Dropout(0.6)\nann.add(tf.keras.layers.Dense(units= 1,activation='linear'))","87ad5a33":"opt = tf.keras.optimizers.RMSprop(0.001)\nann.compile(optimizer= opt, loss= 'mean_squared_error', metrics= ['mae'])","ce18f8c0":"early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\nann_history = ann.fit(x_train, y_train, batch_size= 32, epochs= 50, validation_split= 0.2,callbacks=[early_stop])","c79e681c":"loss_train = ann_history.history['loss']\nloss_val = ann_history.history['val_loss']\nepochs = range(1,51)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","0a814f45":"loss_train = ann_history.history['mae']\nloss_val = ann_history.history['val_mae']\nepochs = range(1,51)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","ed4851f4":"from sklearn.metrics import r2_score,explained_variance_score\ny_pred = ann.predict(x_test)\ntrain_prediction = ann.predict(x_train)","f6ddc1c7":"#R2 Score\nprint(\"r_square score: \", r2_score(y_test,y_pred))\nprint(\"r_square score (train dataset): \", r2_score(y_train,train_prediction))","6cdb8213":"#Variance Score\nprint(\"explained_variance_score: \", explained_variance_score(y_test,y_pred))\nprint(\"explained_variance_score (train dataset): \", explained_variance_score(y_train,train_prediction))","0a6fcfd5":"## **Categorical Data** <a id='3.2' ><\/a>","10019e40":"## **Numerical Data** <a id='3.2' ><\/a>","9a37f1de":"\ud83d\udccc Splitting our dataset in Categorical and Numerical values.","b60e6787":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '3'><\/a>\n\n    Taking care of Missing Values \n<\/div>","a39b14d3":"\ud83d\udccc As you can see, object data type is converted to *int64* data type.","b16f4065":"## **Visualizing Training and Validation Loss** <a id='4.3' ><\/a>","26d6ac5b":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '2'><\/a>\n    \n    Importing Dataset \n<\/div>","1284d147":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '5'><\/a>\n\n    Conclusion \n<\/div>","f5ea87fd":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='1'><\/a>\n    \n    Importing Libraries \n<\/div>","0e9cd35d":"\ud83d\udccc We can see that there are no missing values present now in our dataset.","0b11f9c4":"## **Building the ANN** <a id='4.1' ><\/a>","21a46562":"\ud83d\udccc The above command *df.describe()* helps us to view the statistical properties of numerical variables. It excludes character variables.","d290b006":"\ud83d\udccc After dealing with missing values in our dataset, I took care of the categorical values with the help of Label Encoding. <br>\n\ud83d\udccc Then, I used Keras ANN to evaluate the performance of our model by tuning the parameters of our model. <br>\n\ud83d\udccc I have also visualized the model's performance with also displaying the r-square and variance score of our model, which you can see is good.","8a3da40c":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:Beige;\n           font-size:110%;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    \nHello Kagglers, <br>\n\nIn this notebook, I am going to predict the compensation of employees working at SF controller's office. But, first I am going to do deal with missing values in the dataset. Then, I am going to use Keras ANN on our dataset with fine tuning our model and also visualize it. <br>\n    So, let's get started.\n<\/p>\n<\/div> ","29fde86f":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '4'><\/a>\n\n    Keras ANN \n<\/div>","08fe7cb4":"\ud83d\udccc Replacing the missing values with the most frequent values.","2d93f2df":"\ud83d\udccc Union Code is also int64 type. Let's convert it into int64 type.","5b9a73de":"\ud83d\udccc Feature Scaling with Standard Scaler","9a6ef672":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Table of Contents\n<\/div>","99bd592e":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           border:2px solid DodgerBlue;\n           background-color:white;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n    Thank You!\n<\/div>","58e230f2":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Welcome\n<\/div>","620074a0":"## **Visualizing Training and Validation MAE** <a id='4.4' ><\/a>","03912936":"\ud83d\udccc As you can see there are no missing values in our categorical columns.","934420af":"\ud83d\udccc We have 678524 rows and 22 columns in our dataset. <br>\n\ud83d\udccc We can see that the dataset contains mixture of *categorical* and *numerical* variables. <br>\n\ud83d\udccc Also, there are some missing values in the dataset. Let's check it out.","04b05107":"## **Visualizing Missing Values** <a id='3.1' ><\/a>","f585d7ca":"\ud83d\udccc There are not many missing values in our dataset.","bdb3bc1a":"\ud83d\udccc Missing values in numerical data.","13cf80a5":"## **Train and Test Scores** <a id='4.4' ><\/a>","fbb727c3":"\ud83d\udccc Splitting Dataset into Train and Test Set","cff132e6":"1. [Importing Libraries](#1)<a href='1' ><\/a> <br>\n2. [Importing Dataset](#2)<a href='2' ><\/a> <br>\n3. [Taking care of Missing Values](#3)<a href='3' ><\/a> <br>\n    3.1. [Visualizing Missing Values](#3.1)<a href='3.1' ><\/a> <br>\n    3.2. [Categorical Data](#3.2)<a href='3.2' ><\/a> <br>\n    3.3. [Numerical Data](#3.3)<a href='3.3' ><\/a> <br>\n4. [Keras ANN](#4)<a href='4' ><\/a> <br>\n    4.1. [Building ANN](#4.1)<a href='4.1' ><\/a> <br>\n    4.2. [Training ANN](#4.2)<a href='4.2' ><\/a> <br>\n    4.3. [Visualizing Training and Validation Loss](#4.3)<a href='4.3' ><\/a> <br>\n    4.4. [Visualizing Training and Validation MAE](#4.4)<a href='4.4' ><\/a> <br>\n    4.5. [Train and Test Scores](#4.5)<a href='4.5' ><\/a> <br>\n5. [Conclusion](#5)<a href='5' ><\/a> <br>","3ca6810a":"\ud83d\udccc Missing values in categorical data.","bda39c43":"## **Training the ANN** <a id='4.2' ><\/a>","e6dec799":"\ud83d\udccc Imputing missing values in numerical data with the median."}}