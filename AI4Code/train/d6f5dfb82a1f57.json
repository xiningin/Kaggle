{"cell_type":{"4a85a62e":"code","916d0e88":"code","da9e675b":"code","d62ec93f":"code","329c5583":"code","770b4628":"code","22752360":"code","4c825f77":"code","e2711bc0":"code","623cf494":"code","20b82011":"code","8855b717":"code","5c1b73d9":"code","42f0207a":"code","203bb3b9":"code","c8ab8275":"code","2b8c5ae9":"code","a687b0d3":"code","b1426c4f":"code","2f052238":"code","490fa08f":"code","63d3f01c":"code","9037adf0":"code","89c487a9":"code","c2343db0":"code","2fc94c89":"code","9cb34c14":"code","9b8000b2":"code","d2ee4755":"code","455d3f70":"code","0dac8351":"code","1e090387":"code","24d99730":"code","233c44c8":"markdown","673cea54":"markdown","da35202c":"markdown","bcd214ff":"markdown","da08aa2a":"markdown","df73c221":"markdown","64cf8280":"markdown","7ae6eacc":"markdown","04f1a513":"markdown","14f1e017":"markdown","31b65654":"markdown","6fcb9971":"markdown","b28e4271":"markdown","a6556159":"markdown","1e91a28b":"markdown","74b379bc":"markdown","08c5f71c":"markdown","40ae3659":"markdown","57082b44":"markdown","619a2f8b":"markdown","488a7182":"markdown","81579b72":"markdown","852b2a7b":"markdown","4fac1fd5":"markdown","27ed57d2":"markdown","d5143bf8":"markdown","ae651466":"markdown","8043b552":"markdown","413aa386":"markdown","a8d3f230":"markdown","ba1c9211":"markdown"},"source":{"4a85a62e":"import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random,matplotlib\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nimport nltk as nlp\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n%matplotlib inline","916d0e88":"df=pd.read_csv('\/kaggle\/input\/real-or-fake-fake-jobposting-prediction\/fake_job_postings.csv')\ndf.head()","da9e675b":"msno.matrix(df)","d62ec93f":"msno.bar(df)","329c5583":"text = \" \".join(title for title in df.title)\nprint (\"There are {} words in the combination of all available job titles.\".format(len(text)))\nstopwords=set(STOPWORDS)\nwordcloud = WordCloud(background_color=\"black\",max_font_size=100, max_words=10000,width=1600, height=800,stopwords=stopwords,colormap=matplotlib.cm.cool).generate(text)\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")","770b4628":"#Dropping 'job_id' as it is irrelevant to fraudulent\ndf.drop('job_id', axis=1, inplace=True)\ntext_features = ['title', 'company_profile', 'description', 'requirements', 'benefits']\ncomplex_features = ['location', 'salary_range']\nbin_features = ['telecommuting', 'has_company_logo', 'has_questions']\ncat_features = ['department', 'employment_type', 'required_experience', \n                'required_education', 'industry', 'function']","22752360":"df.isnull().sum()","4c825f77":"for feature_name in text_features[1:]:\n    df[feature_name].fillna('Unspecified', inplace=True)","e2711bc0":"location = df['location'].copy()\n#splitting location\nlocation_splitted = list(location.str.split(', ').values)\nfor loc_ind, loc in enumerate(location_splitted):\n    if loc is np.nan:\n        location_splitted[loc_ind] = ['Unpecified'] * 3\n    else:\n        for el_ind, el in enumerate(loc):\n            if el == '':\n                loc[el_ind] = 'Unpecified'\n                \nlocation_splitted = list(map(lambda loc: list(loc), location_splitted))\nfor loc_ind, loc in enumerate(location_splitted):\n    if len(loc) > 3:\n        location_splitted[loc_ind] = loc[:2] + [', '.join(loc[2:])]\n    if len(loc) < 3:\n        location_splitted[loc_ind] += ['Unpecified'] * 2\n        \ndata_location = pd.DataFrame(location_splitted, columns=['country', 'state', 'city'])\ncat_features += ['country', 'state', 'city']\ndf= pd.concat([df, data_location], axis=1)\ndf.drop('location', axis=1, inplace=True)\ndf.head()","623cf494":"salary_range = df.salary_range.copy()\nsalary_range.fillna('0-0', inplace=True)\nsalary_range_sep = list(salary_range.str.split('-').values)\nsalary_range_sep[5538] = ['40000', '40000']\nerror_range_inds = []\nfor range_ind, s_range in enumerate(salary_range_sep):\n    min_value, max_value = s_range\n    if not min_value.isdigit() or not max_value.isdigit():\n        error_range_inds += [range_ind]\nfor range_ind in error_range_inds:\n    salary_range_sep[range_ind] = ['0', '0']\ndata_salary_range = pd.DataFrame(np.array(salary_range_sep, dtype='int64'), \n                                 columns=['min_salary', 'max_salary'])\n\nnum_features = ['min_salary', 'max_salary']\ndf = pd.concat([df, data_salary_range], axis=1)\ndf.drop('salary_range', axis=1, inplace=True)\ndf.head()","20b82011":"df.fillna('Unspecified', inplace=True)","8855b717":"df.info()","5c1b73d9":"def clean_text(data):\n    description_list = []\n    for description in data:\n        description = re.sub(\"[^a-zA-Z]\",\" \",description)\n        description = description.lower()\n        description = nlp.word_tokenize(description)\n        description = [word for word in description if not word in stopwords]\n        lemma = nlp.WordNetLemmatizer()\n        description = [lemma.lemmatize(word) for word in description ]\n        description =\" \".join(description)\n        description_list.append(description)\n    return description_list","42f0207a":"df['description_cleaned']= clean_text(df.description)\ndf['company_profile_cleaned']=clean_text(df.company_profile)\ndf['requirements_cleaned']= clean_text(df.requirements)\ndf['benefits_cleaned']=clean_text(df.benefits)","203bb3b9":"df['title_length']=df['title'].astype(str).str.split(' ').apply(len)\ndf['company_profile_length']=df['company_profile_cleaned'].astype(str).str.split(' ').apply(len)\ndf['benefits_length']=df['benefits_cleaned'].astype(str).str.split(' ').apply(len)\ndf['description_length']=df['description_cleaned'].astype(str).str.split(' ').apply(len)\ndf['requirements_length']=df['requirements_cleaned'].astype(str).str.split(' ').apply(len)","c8ab8275":"label=LabelEncoder()\ndf['employment_type']=label.fit_transform(df['employment_type'])\ndf['required_experience']=label.fit_transform(df['required_experience'])\ndf['required_education']=label.fit_transform(df['required_education'])\ndf['industry']=label.fit_transform(df['industry'])\ndf['function']=label.fit_transform(df['function'])\ndf['country']=label.fit_transform(df['country'])\ndf['state']=label.fit_transform(df['state'])\ndf['city']=label.fit_transform(df['city'])\n","2b8c5ae9":"plt.figure(figsize=(10, 5))\nax = sns.countplot(df.fraudulent)\nplt.title('The distribution of the target feature (fraudulent)')\nfor p in ax.patches:\n    ax.annotate(p.get_height(), (p.get_x()+0.33, p.get_height()))","a687b0d3":"data_1f = df[df.fraudulent == 1]\noriginal_data = df.copy()\ndf = pd.concat([df] + [data_1f] * 7, axis=0)","b1426c4f":"plt.figure(figsize=(10, 5))\nax = sns.countplot(df.fraudulent)\nplt.title('The distribution of the target feature (fraudulent)')\nfor p in ax.patches:\n    ax.annotate(p.get_height(), (p.get_x()+0.33, p.get_height()))\nplt.show()","2f052238":"X=check=df.drop(['title','department','company_profile','description','requirements','benefits','description_cleaned','company_profile_cleaned','requirements_cleaned','benefits_cleaned','fraudulent'],axis=1)\ny=df.fraudulent","490fa08f":"X","63d3f01c":"y","9037adf0":"scaler=MinMaxScaler()\nX=scaler.fit_transform(X)","89c487a9":"from sklearn.model_selection import train_test_split\nX_train, X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)","c2343db0":"def roc_plotter(model_object,model_name):     \n        model_object.fit(X_train, y_train)\n        y_pred=model_object.predict(X_test)\n        ns_probs = [0 for _ in range(len(y_test))]\n\n        # predict probabilities\n        model_probs = model_object.predict_proba(X_test)[:, 1]\n\n        # calculate scores\n        ns_auc = roc_auc_score(y_test, ns_probs)\n        model_auc = roc_auc_score(y_test, model_probs)\n    \n        fig = plt.figure(figsize=(12,5))\n\n        # calculate roc curves\n        ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n        lr_fpr, lr_tpr, _ = roc_curve(y_test, model_probs)\n        # plot the roc curve for the model\n        plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n        plt.plot(lr_fpr, lr_tpr, marker='.', label=model_name)\n\n        # axis labels\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        # show the legend\n        plt.legend()\n        # show the plot\n        score= accuracy_score(y_test, y_pred)\n        txt1='ROC AUC = {}'.format(round(model_auc,2))\n        txt2='Accuracy = {}%'.format(round(score*100,2))\n        \n        plt.text(0.3,0.2,model_name,fontsize=25, fontweight='bold',color='red')\n        plt.text(0.3,0.1,txt1,bbox={'facecolor': 'orange','pad': 10},fontsize=15)\n        plt.text(0.5,0.1,txt2,bbox={'facecolor': 'red', 'pad': 10},fontsize=15,color='white')\n        plt.tight_layout()","2fc94c89":"lrmodel=LogisticRegression()\nroc_plotter(lrmodel,'Logistic Regression')","9cb34c14":"svmmodel=SVC(probability=True)\nroc_plotter(svmmodel,'Support Vector Classifier')","9b8000b2":"nnmodel=MLPClassifier()\nroc_plotter(nnmodel,'MultiLayer Perceptron Classifier')","d2ee4755":"knnmodel=KNeighborsClassifier()\nroc_plotter(knnmodel,'KNN Classifier')","455d3f70":"dtmodel=DecisionTreeClassifier()\nroc_plotter(dtmodel,'Decision Tree Classifier')","0dac8351":"xgb = XGBClassifier()\nroc_plotter(xgb,'XGBoost Classifier')","1e090387":"rfmodel=RandomForestClassifier()\nroc_plotter(rfmodel,'Random Forest Classifier')","24d99730":"models=['Logistic Regression','Support Vector Classifier','MultiLayer Perceptron Classifier','KNN Classifier','Decision Tree Classifier','XGBoost Classifier','Random Forest Classifier']\naccuracies=[80.79,87.76,93.3,96.1,98.43,99.25,99.83]\nplt.figure(figsize=(18,10))\nplt.scatter(x=models, y=accuracies,s=200)\nplt.plot(models,accuracies)\nfor x,y in zip(models,accuracies):\n    label = \"{:.2f}%\".format(y)\n    plt.annotate(label, (x,y), textcoords=\"offset points\", xytext=(0,10), ha='center',fontsize=20)","233c44c8":"Preparing X and y variables by removing unwanted features","673cea54":"Calculating length of each text feature's entries and saving them into feature_length","da35202c":"# Oversampling Target Variable","bcd214ff":"*clean_text* function to receive column as argument, apply regex functions, tokenizing and lemmatizing and returning the modified dataframe","da08aa2a":"# Label Encoding","df73c221":"# XGBoost Classifier","64cf8280":"# Decision Tree Classifier","7ae6eacc":"# Visualizing Missing Values","04f1a513":"# WORDCLOUD","14f1e017":"Filling Null values from Text Features with 'Unspecified'","31b65654":"# Splitting Locations","6fcb9971":"# IMPORTING LIBRARIES","b28e4271":"# Converting Salary Ranges","a6556159":"Filling Null values from location with 'Unspecified' <br>\nSplitting location into 3 seperate columns: country, state, city<br>\nDropping location column<br>","1e91a28b":"Filling Null values from remaining features with 'Unspecified'","74b379bc":"Applying this function on text variables","08c5f71c":"X","40ae3659":"# Predicting Fraudulency based on Job Posts.\n1. Visualizing **Missing Values**\n2. **WORDCLOUD** on Job Titles\n3. **Splitting** Locations into Country, State & City\n4. Converting salary ranges into **Min & Max**\n5. **Label Encoding** Categorical Features\n6. Cleaning Text Features by removing **STOPWORDS** and **Lemmatizing** Words using **NLP**\n7. **OVERSAMPLING** Target Variable\n8. Scaling Data using **MINMAXSCALER**\n9. Plotting **AUC** and **Accuracies** of following Models:\n    * **Logistic Regression**\n    * **Support Vector Classifier**\n    * **MultiLayer Perceptron Classifier**\n    * **KNN Classifier**\n    * **Decision Tree Classifier**\n    * **XGBoost Classifier**\n    * **Random Forest Classifier**","57082b44":"# Logistic Regression","619a2f8b":"Plotting Target Variable","488a7182":"# Cleaning text using NLP","81579b72":"Creating a function 'roc_plotter' for passing model object, model name and plotting its roc auc curve with accuracy","852b2a7b":"# SCALING DATA with MINMAXSCALER","4fac1fd5":"# KNN Classifier","27ed57d2":"Filling Null values from salary_range with '0-0'\nSplitting salary_range into 2 seperate columns: min_salary and max_salary\nDropping salary_range","d5143bf8":"All the null values are cleaned.","ae651466":"# MultiLayer Perceptron Classifier","8043b552":"# Random Forest Classifier","413aa386":"# Support Vector Classifier","a8d3f230":"Plotting Barchart for Missing Values in our dataset","ba1c9211":"# MODELING\n**1. LOGISTIC REGRESSION** <br>\n**2. XGBOOST**<br>\n**3. Logistic Regression**<br>\n**4. Support Vector Classifier**<br>\n**5. MultiLayer Perceptron Classifier**<br>\n**6. KNN Classifier**<br>\n**7. Decision Tree Classifier**<br>\n**8. XGBoost Classifier**<br>\n**9. Random Forest Classifier**<br>"}}