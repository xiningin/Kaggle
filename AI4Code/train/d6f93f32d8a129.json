{"cell_type":{"5f927d8d":"code","447bc1b9":"code","6e0113e8":"code","51bb86db":"code","1a7542fd":"code","d6833ca1":"code","100dc562":"code","d8fbe5c3":"code","233a0587":"code","8eadcdb9":"code","e4239806":"code","5ec389b7":"code","ff78621a":"code","4bcab50d":"code","c69ad315":"code","bcfa3c17":"code","0e3717be":"code","cdb7441d":"code","34c25e6c":"code","d045f77e":"code","04b37f70":"markdown","41f74671":"markdown","66138ba5":"markdown","b3a3aa38":"markdown","44a6e0a8":"markdown","8098b3de":"markdown"},"source":{"5f927d8d":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nprint(f'Tensorflow version: {tf.__version__}')","447bc1b9":"SEED = 42\nfrom tensorflow.random import set_seed\nfrom numpy.random import seed\nseed(SEED)\nset_seed(SEED)","6e0113e8":"min_rock_data = pd.read_csv('..\/input\/mines-vs-rocks\/sonar.all-data.csv', header = None)\nmin_rock_data.head()","51bb86db":"min_rock_data.groupby(60).size()","1a7542fd":"# min_rock_data_v = min_rock_data.values\n# X = min_rock_data_v[:,0:60].astype(float)\n# Y = min_rock_data_v[:,60]\n# print ('X Shape :', X.shape)\n# print ('Y Shape :', Y.shape)\n# print ('Number of Unique Values in Y:', set(Y))\n\nX = min_rock_data[min_rock_data.columns[0:60]].values\nY = min_rock_data[min_rock_data.columns[60]].values","d6833ca1":"print(X[0])","100dc562":"# for i, v in enumerate(Y):\n#     if v == 'M':\n#         Y[i] = 1\n#     elif v == 'R':\n#         Y[i] = 0\n\n# Y = np.asarray(Y).astype(int)\n# print(Y)\n\n\n# from sklearn.preprocessing import LabelEncoder\n# encoder = LabelEncoder()\n# y_one = encoder.fit_transform(Y).astype(int)\n\ny = pd.get_dummies(Y, drop_first=False)","d8fbe5c3":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","233a0587":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","8eadcdb9":"model = Sequential()\nmodel.add(Dense(100, input_shape=(X_train.shape[1],), activation = 'relu'))\nmodel.add(Dense(20, activation = 'relu'))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(500, activation = 'relu'))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(500, activation = 'relu'))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(200, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(y_train.shape[1], activation = 'sigmoid'))\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.summary()","e4239806":"cl = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=50)","5ec389b7":"fig, ax = plt.subplots(figsize=(15,5))\n\nplt.plot(cl.history['accuracy'], label='accuracy')\nplt.plot(cl.history['val_accuracy'], label='val_accuracy', linestyle='--')\nplt.plot(cl.history['loss'], label='loss')\nplt.plot(cl.history['val_loss'], label='val_loss', linestyle='--')\nplt.legend()","ff78621a":"ModelLoss, ModelAccuracy = model.evaluate(X_test, y_test)\n\nprint(f'Test Loss is {ModelLoss}')\nprint(f'Test Accuracy is {ModelAccuracy}')","4bcab50d":"pred = model.predict(X_test)\npred_list = np.argmax(pred, axis=-1)\ny_test_list = y_test['R'].to_list()\n\nfor i in range(10):\n    print(f\"{pred[i][0]:.5f} - {pred[i][1]:.5f} - {pred_list[i]} \/\/ {y_test_list[i]}\")","c69ad315":"from sklearn.metrics import confusion_matrix, classification_report\n\ncr = classification_report(y_test_list, pred_list)\nprint(cr)","bcfa3c17":"cm=confusion_matrix(y_test_list, pred_list)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True, linewidths=0.01, linecolor='grey')\nplt.title('Confustion matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","0e3717be":"from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve\n\nrandom_probs = [0 for i in range(len(y_test_list))]\n\nran_fpr, ran_tpr, _ = roc_curve(y_test_list, random_probs)\nfpr, tpr, thresholds = roc_curve(y_test_list, pred_list)\n\nfig = plt.figure(figsize = (10,6))\nplt.plot(ran_fpr, ran_tpr, linestyle='--', label='Random')\nplt.plot(fpr, tpr, marker='.', label='Model')\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc='best')\n\nran_auc = roc_auc_score(y_test_list, random_probs)\nauc = roc_auc_score(y_test_list, pred_list)\nprint(f'Random: ROC AUC={ran_auc:.3f}')\nprint(f'Model: ROC AUC={auc:.3f}')","cdb7441d":"from sklearn.metrics import precision_recall_curve, f1_score, auc\n\nprecision, recall, _ = precision_recall_curve(y_test_list, pred_list)\nauc=auc(recall, precision)\nprint(f'Acu: {auc:.5f}')\n\nfig = plt.figure(figsize = (10,6))\nplt.plot(recall, precision, marker='.', label='Model')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()","34c25e6c":"# from sklearn.metrics import det_curve\n\n# fpr, fnr, thresholds = det_curve(y_test_list, pred_list)\n\n# fig = plt.figure(figsize = (10,6))\n# plt.plot(ran_fpr, ran_tpr, linestyle='--', label='Random')\n# plt.plot(fpr, tpr, marker='.', label='Model')\n# plt.title('ROC curve')\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.legend(loc='best')","d045f77e":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n\nmodels.append(('AB', AdaBoostClassifier()))\nmodels.append(('GBM', GradientBoostingClassifier()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('ET', ExtraTreesClassifier()))\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10)\n    cv_results = cross_val_score(model, X_train, y_train['R'].to_list(), cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    print(f\"{name}: {cv_results.mean()} ({cv_results.std()})\")","04b37f70":"### Split up the data to training set and test set","41f74671":"### Split up the data to X and Y ","66138ba5":"### Prepping Y ","b3a3aa38":"### Normalization of the data","44a6e0a8":"## Train the model","8098b3de":"## Loading the dataset"}}