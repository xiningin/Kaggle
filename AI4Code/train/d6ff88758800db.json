{"cell_type":{"831ea66f":"code","3bbdc8c3":"code","4ea5f35e":"code","6f2ca364":"code","b6705583":"code","8c64dcd5":"code","db35abde":"code","7f0ee95e":"code","58d1179d":"code","6f179152":"code","0d7c98cf":"code","ae37ff62":"code","ccfc232e":"code","4c660e1b":"code","719c7401":"code","a1c0e92a":"code","b784dff7":"code","1a081fa7":"code","f85a6a90":"code","b5b896b4":"code","aff7119c":"code","f1e41c7a":"markdown"},"source":{"831ea66f":"# I just started exploring sktime and figured this competition would be a good learning opportunity. \n# Obviously there is A TON you could do but this is some good boilerplate.\n\n# Feel free to reach out to work together =)\n\n# Everything in this notebook was adapted from this awesome article: \n# https:\/\/towardsdatascience.com\/a-lightgbm-autoregressor-using-sktime-6402726e0e7b","3bbdc8c3":"pip install sktime","4ea5f35e":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport warnings\nimport itertools\n\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom pylab import rcParams\nfrom sklearn.metrics import mean_squared_log_error\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n\nrcParams['figure.figsize'] = 18, 8\nrcParams['figure.figsize'] = 18, 8","6f2ca364":"from sktime.forecasting.base import ForecastingHorizon\nfrom sktime.transformations.series.detrend import Deseasonalizer, Detrender\nfrom sktime.forecasting.trend import PolynomialTrendForecaster\nfrom sktime.forecasting.model_selection import (\n    temporal_train_test_split,\n)\nfrom sktime.utils.plotting import plot_series\nfrom sktime.forecasting.compose import (\n    TransformedTargetForecaster,\n    make_reduction\n)","b6705583":"# W\/ DATE COLUMN - 'parse_dates='date' (date column)\ntrain = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/train.csv', parse_dates=['date'])\ntransactions = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/transactions.csv', parse_dates=['date'])\noil = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/oil.csv', parse_dates=['date'])\nholidays = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/holidays_events.csv', parse_dates=['date'])\ntest = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/test.csv', parse_dates=['date'])","8c64dcd5":"# NO DATE COLUMN - 'index_col=0' (index\/id column)\nstores = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/stores.csv', index_col=0)\nsample = pd.read_csv('..\/input\/store-sales-time-series-forecasting\/sample_submission.csv', index_col=0)","db35abde":"train.head()","7f0ee95e":"#For the sake of demonstration, we will train our model on monthly aggregated Sales data of a particular store# Select sales for Store 1 Only.\nstore1_agg = train.loc[train['store_nbr']==1].groupby(['date'])['sales'].sum()\nstore1_agg.index = pd.to_datetime(store1_agg.index)\n#Aggregate the Data on a Monthly basis.\nstore1_agg_monthly = store1_agg.resample('M').sum()","58d1179d":"#--------------------Visulaize Data on a Time Plot------------------\nsns.lineplot(\n    data=store1_agg_monthly, \n)\nplt.title(\"Store-1 Sales Data aggreagted at Month Level\")\nplt.show()","6f179152":"#Annual Seasonal Decomposition\nseasonal_decompose(store1_agg_monthly,model=\"multiplicative\",period=12).plot()\nplt.show()","0d7c98cf":"#--------------------Time Series Train-Test split-------------------#\nstore1_agg_monthly.index = store1_agg_monthly.index.to_period('M') \ny_train, y_test = temporal_train_test_split(store1_agg_monthly, test_size=0.2)","ae37ff62":"y_train.head()","ccfc232e":"y_train.tail()","4c660e1b":"#--------------------------Detrender-----------------------------\n\n#degree=1 for Linear\nforecaster = PolynomialTrendForecaster(degree=1) \ntransformer = Detrender(forecaster=forecaster)\n\n#Get the residuals after fitting a linear trend\ny_resid = transformer.fit_transform(y_train)\n\n# Internally, the Detrender uses the in-sample predictions\n# of the PolynomialTrendForecaster\nforecaster = PolynomialTrendForecaster(degree=1)\nfh_ins = -np.arange(len(y_train))  # in-sample forecasting horizon\ny_pred = forecaster.fit(y_train).predict(fh=fh_ins)\nplot_series(y_train, y_pred, y_resid, labels=[\"y_train\", \"fitted linear trend\", \"residuals\"]);","719c7401":"#--------------------------Deseasonalizer---------------------------\n\n#Multiplicative Deseasonalizer, period = 12(for Monthly Data)\ndeseasonalizer = Deseasonalizer(model=\"multiplicative\", sp=12)\nplot_series(deseasonalizer.fit_transform(y_train))\nseasonal = deseasonalizer.fit_transform(y_train)","a1c0e92a":"regressor = lgb.LGBMRegressor()","b784dff7":"forecaster = make_reduction(\n                    #hyper-paramter to set recursive strategy\n                    estimator=regressor, window_length=4,strategy=\"recursive\" \n)","1a081fa7":"#----------------------------Create Pipeline--------------------\n\ndef get_transformed_target_forecaster(alpha,params):\n    \n    #Initialize Light GBM Regressor   \n    regressor = lgb.LGBMRegressor(alpha = alpha,**params)\n    \n#-----------------------Forecaster Pipeline-----------------\n    \n    #1.Separate the Seasonal Component.\n    #2.Fit a forecaster for the trend.\n    #3.Fit a Autoregressor to the resdiual(autoregressing on four historic values).\n    \n    forecaster = TransformedTargetForecaster(\n        [\n            (\"deseasonalise\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n            (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n            (\n                # Recursive strategy for Multi-Step Ahead Forecast.\n                # Auto Regress on four previous values\n                \"forecast\",\n                make_reduction(\n                    estimator=regressor, window_length=4, strategy=\"recursive\",\n                ),\n            ),\n        ]\n    )\n    return forecaster","f85a6a90":"#-------------------Fitting an Auto Regressive Light-GBM------------\n\n#Setting Quantile Regression Hyper-parameter.\nparams = {\n    'objective':'quantile'\n}\n#A 10 percent and 90 percent prediction interval(0.1,0.9 respectively).\nquantiles = [.1, .5, .9] #Hyper-parameter \"alpha\" in Light GBM#Capture forecasts for 10th\/median\/90th quantile, respectively.\nforecasts = []#Iterate for each quantile.\nfor alpha in quantiles:\n    \n    forecaster = get_transformed_target_forecaster(alpha,params)\n    \n    #Initialize ForecastingHorizon class to specify the horizon of forecast\n    fh = ForecastingHorizon(y_test.index, is_relative=False)\n    \n    #Fit on Training data.\n    forecaster.fit(y_train)\n    \n    #Forecast the values.\n    y_pred = forecaster.predict(fh)\n    \n    #List of forecasts made for each quantile.\n    y_pred.index.name=\"date\"\n    y_pred.name=f\"predicted_sales_q_{alpha}\"\n    forecasts.append(y_pred)\n    \n#Append the actual data for plotting.\nstore1_agg_monthly.index.name = \"date\"\nstore1_agg_monthly.name = \"original\"\nforecasts.append(store1_agg_monthly)","b5b896b4":"error = mean_squared_log_error(y_test, y_pred)","aff7119c":"#-------------------Final Plotting of Forecasts------------------\n\nplot_data = pd.melt(pd.concat(forecasts,axis=1).reset_index(), id_vars=['date'],\\\n        value_vars=['predicted_sales_q_0.1', 'predicted_sales_q_0.5',\n                   'predicted_sales_q_0.9','original'])\nplot_data['date'] = pd.to_datetime(plot_data['date'].astype(str).to_numpy())\nplot_data['if_original'] = plot_data['variable'].apply(\n    lambda r:'original' if r=='original' else 'predicted' \n)\nsns.lineplot(data = plot_data,\n        x='date',\n        y='value',\n        hue='if_original',\n             style=\"if_original\",\n        markers=['o','o'],\n)\n\nplt.title(f\"Final Forecast - Error: {error}\")\nplt.show()","f1e41c7a":"References\n\n    Bontempi, Gianluca & Ben Taieb, Souhaib & Le Borgne, Yann-A\u00ebl. ( 2013). Machine Learning Strategies for Time Series Forecasting \u2014 https:\/\/www.researchgate.net\/publication\/236941795_Machine_Learning_Strategies_for_Time_Series_Forecasting.\n    Markus L\u00f6ning, Anthony Bagnall, Sajaysurya Ganesh, Viktor Kazakov, Jason Lines, Franz Kir\u00e1ly (2019): \u201csktime: A Unified Interface for Machine Learning with Time Series\u201d\n    LightGBM-Quantile loss \u2014 https:\/\/towardsdatascience.com\/lightgbm-for-quantile-regression-4288d0bb23fd"}}