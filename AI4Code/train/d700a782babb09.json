{"cell_type":{"eb19c2b8":"code","85016a7b":"code","aaea8178":"code","50cf019f":"code","6aea9940":"code","39cb40fc":"code","c82d02f4":"code","aa4a148d":"code","2d39eb4c":"code","4e7b66b4":"code","954015c9":"code","febbd892":"code","98da5c36":"code","dde3562e":"code","e291583e":"code","fb17b535":"code","82944304":"code","997d063e":"code","38f16cfd":"code","e8953846":"code","e9acd97d":"code","f9d7f201":"code","9c880961":"code","eac8f9ce":"code","bf8060cb":"code","8d07129f":"code","58cb5e69":"code","cb69cfee":"code","910f144c":"code","48af2519":"code","2ac4231d":"code","06f4b6eb":"code","2ed3436d":"code","726963d2":"code","7a7bcb2c":"code","a67c500d":"code","aecbe81d":"code","d729d64d":"code","602c3e3b":"code","952a4695":"code","68bcbd8f":"code","daed5a47":"markdown","e9f850c8":"markdown","5e0d235e":"markdown","0eb4dc46":"markdown","0d299403":"markdown","1d0790b3":"markdown","c280a818":"markdown","addb4a54":"markdown","1d63feb9":"markdown","4f071fc8":"markdown","dabdebd8":"markdown","cc8454c2":"markdown","77a5e1ed":"markdown","2ab352b3":"markdown","b31a06d9":"markdown","f583e324":"markdown","2a481bfe":"markdown","ec9cb332":"markdown","d5f61521":"markdown","0fbb739c":"markdown"},"source":{"eb19c2b8":"# Supressing the warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","85016a7b":"# Reading the dataset\nimport pandas as pd\nimport numpy as np\nComputerPricesData=pd.read_csv('..\/input\/computerpricedata\/ComputerPricesData.csv', encoding='latin')\nprint('Shape before deleting duplicate values:', ComputerPricesData.shape)\n\n# Removing duplicate rows if any\nComputerPricesData=ComputerPricesData.drop_duplicates()\nprint('Shape After deleting duplicate values:', ComputerPricesData.shape)\n\n# Printing sample data\n# Start observing the Quantitative\/Categorical\/Qualitative variables\nComputerPricesData.head(10)","aaea8178":"%matplotlib inline\n# Creating Bar chart as the Target variable is Continuous\nComputerPricesData['price'].hist()","50cf019f":"# Looking at sample rows in the data\nComputerPricesData.head()","6aea9940":"ComputerPricesData.info()","39cb40fc":"# Looking at the descriptive statistics of the data\nComputerPricesData.describe(include='all')","c82d02f4":"# Finging unique values for each column\n# TO understand which column is categorical and which one is Continuous\n# Typically if the numer of unique values are < 20 then the variable is likely to be a category otherwise continuous\nComputerPricesData.nunique()","aa4a148d":"def PlotBarCharts(inpData, colsToPlot):\n    %matplotlib inline\n    \n    import matplotlib.pyplot as plt\n    \n    # Generating multiple subplots\n    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))\n    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n\n    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])","2d39eb4c":"# Calling the function\nPlotBarCharts(inpData=ComputerPricesData, colsToPlot=['ram', 'screen', 'cd', 'multi'])","4e7b66b4":"# Plotting histograms of multiple columns together\nComputerPricesData.hist(['speed','hd','ads','trend'], figsize=(18,10))","954015c9":"ComputerPricesData.isnull().sum()","febbd892":"ContinuousCols=['speed','hd','ads','trend']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    ComputerPricesData.plot.scatter(x=predictor, y='price', figsize=(10,5), title=predictor+\" VS \"+ 'price')","98da5c36":"# Calculating correlation matrix\nContinuousCols=['price','speed','hd','ads','trend']\n\n# Creating the correlation matrix\nCorrelationData=ComputerPricesData[ContinuousCols].corr()\nCorrelationData","dde3562e":"# Filtering only those columns where absolute correlation > 0.5 with Target Variable\n# reduce the 0.5 threshold if no variable is selected\nCorrelationData['price'][abs(CorrelationData['price']) > 0.2 ]","e291583e":"# Box plots for Categorical Target Variable \"price\" and continuous predictors\nCategoricalColsList=['ram', 'screen', 'cd', 'multi']\n\nimport matplotlib.pyplot as plt\nfig, PlotCanvas=plt.subplots(nrows=1, ncols=len(CategoricalColsList), figsize=(18,5))\n\n# Creating box plots for each continuous predictor against the Target Variable \"price\"\nfor PredictorCol , i in zip(CategoricalColsList, range(len(CategoricalColsList))):\n    ComputerPricesData.boxplot(column='price', by=PredictorCol, figsize=(5,5), vert=True, ax=PlotCanvas[i])","fb17b535":"# Defining a function to find the statistical relationship with all the categorical variables\ndef FunctionAnova(inpData, TargetVariable, CategoricalPredictorList):\n    from scipy.stats import f_oneway\n\n    # Creating an empty list of final selected predictors\n    SelectedPredictors=[]\n    \n    print('##### ANOVA Results ##### \\n')\n    for predictor in CategoricalPredictorList:\n        CategoryGroupLists=inpData.groupby(predictor)[TargetVariable].apply(list)\n        AnovaResults = f_oneway(*CategoryGroupLists)\n        \n        # If the ANOVA P-Value is <0.05, that means we reject H0\n        if (AnovaResults[1] < 0.05):\n            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n            SelectedPredictors.append(predictor)\n        else:\n            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n    \n    return(SelectedPredictors)","82944304":"CategoricalPredictorList=['ram', 'screen', 'cd', 'multi']\nFunctionAnova(inpData=ComputerPricesData, \n              TargetVariable='price', \n              CategoricalPredictorList=CategoricalPredictorList)","997d063e":"SelectedColumns=['speed','hd','trend','ram', 'screen', 'cd']\n\n# Selecting final columns\nDataForML=ComputerPricesData[SelectedColumns]\nDataForML.head()","38f16cfd":"DataForML.to_pickle('DataForML.pkl')","e8953846":"# Converting binary nominal values to numeric \nDataForML['cd'].replace({'no':0, 'yes':1}, inplace=True)","e9acd97d":"# Treating all the nominal variables at once using dummy variables\nDataForML_Numeric=pd.get_dummies(DataForML)\n\n# Adding Target Variable to the data\nDataForML_Numeric['price']=ComputerPricesData['price']\n\n# Printing sample rows\nDataForML_Numeric.head()","f9d7f201":"DataForML_Numeric.columns","9c880961":"# Separate Target Variable and Predictor Variables\nTargetVariable='price'\nPredictors=['speed', 'hd', 'trend', 'ram', 'screen', 'cd']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)","eac8f9ce":"### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","bf8060cb":"# Sanity check for the sampled data\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","8d07129f":"# Multiple Linear Regression\nfrom sklearn.linear_model import LinearRegression\nRegModel = LinearRegression()\n\n# Printing all the parameters of Linear regression\nprint(RegModel)\n\n# Creating the model on Training Data\nLREG=RegModel.fit(X_train,y_train)\nprediction=LREG.predict(X_test)\n\n# Taking the standardized values to original scale\n\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['price']-TestingDataResults['Predictedprice']))\/TestingDataResults['price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","58cb5e69":"# Decision Trees (Multiple if-else statements!)\nfrom sklearn.tree import DecisionTreeRegressor\nRegModel = DecisionTreeRegressor(max_depth=10,criterion='mse')\n# Good Range of Max_depth = 2 to 20\n\n# Printing all the parameters of Decision Tree\nprint(RegModel)\n\n# Creating the model on Training Data\nDT=RegModel.fit(X_train,y_train)\nprediction=DT.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DT.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['price']-TestingDataResults['Predictedprice']))\/TestingDataResults['price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","cb69cfee":"# Random Forest (Bagging of multiple Decision Trees)\nfrom sklearn.ensemble import RandomForestRegressor\nRegModel = RandomForestRegressor(max_depth=10, n_estimators=100,criterion='mse')\n# Good range for max_depth: 2-10 and n_estimators: 100-1000\n\n# Printing all the parameters of Random Forest\nprint(RegModel)\n\n# Creating the model on Training Data\nRF=RegModel.fit(X_train,y_train)\nprediction=RF.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, RF.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['price']-TestingDataResults['Predictedprice']))\/TestingDataResults['price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","910f144c":"# Adaboost (Boosting of multiple Decision Trees)\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Choosing Decision Tree with 10 level as the weak learner\nDTR=DecisionTreeRegressor(max_depth=15)\nRegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=0.04)\n\n# Printing all the parameters of Adaboost\nprint(RegModel)\n\n# Creating the model on Training Data\nAB=RegModel.fit(X_train,y_train)\nprediction=AB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, AB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(AB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['price']-TestingDataResults['Predictedprice']))\/TestingDataResults['price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","48af2519":"# Xtreme Gradient Boosting (XGBoost)\nfrom xgboost import XGBRegressor\nRegModel=XGBRegressor(max_depth=15, \n                      learning_rate=0.1, \n                      n_estimators=100, \n                      objective='reg:linear', \n                      booster='gbtree')\n\n# Printing all the parameters of XGBoost\nprint(RegModel)\n\n# Creating the model on Training Data\nXGB=RegModel.fit(X_train,y_train)\nprediction=XGB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['price']-TestingDataResults['Predictedprice']))\/TestingDataResults['price'])\n\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","2ac4231d":"# K-Nearest Neighbor(KNN)\nfrom sklearn.neighbors import KNeighborsRegressor\nRegModel = KNeighborsRegressor(n_neighbors=3)\n\n# Printing all the parameters of KNN\nprint(RegModel)\n\n# Creating the model on Training Data\nKNN=RegModel.fit(X_train,y_train)\nprediction=KNN.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The variable importance chart is not available for KNN\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['price']-TestingDataResults['Predictedprice']))\/TestingDataResults['price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","06f4b6eb":"# Separate Target Variable and Predictor Variables\nTargetVariable='price'\n\n# Selecting the final set of predictors for the deployment\n# Based on the variable importance charts of multiple algorithms above\nPredictors=['trend', 'hd', 'speed', 'ram','screen']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\nprint(X.shape)\nprint(y.shape)","2ed3436d":"# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Using final hyperparameters\n# Xtreme Gradient Boosting (XGBoost)\nfrom xgboost import XGBRegressor\nRegModel=XGBRegressor(max_depth=15, \n                      learning_rate=0.1, \n                      n_estimators=100, \n                      objective='reg:linear', \n                      booster='gbtree')\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","726963d2":"Final_XGB_Model=RegModel.fit(X,y)","7a7bcb2c":"import pickle\nimport os\n\n# Saving the Python objects as serialized files can be done using pickle library\n# Here let us save the Final model\nwith open('Final_XGB_Model.pkl', 'wb') as fileWriteStream:\n    pickle.dump(Final_XGB_Model, fileWriteStream)\n    # Don't forget to close the filestream!\n    fileWriteStream.close()\n    \nprint('pickle file of Predictive Model is saved at Location:',os.getcwd())","a67c500d":"# This Function can be called from any from any front end tool\/website\ndef FunctionPredictResult(InputData):\n    import pandas as pd\n    Num_Inputs=InputData.shape[0]\n    \n    # Making sure the input data has same columns as it was used for training the model\n    # Also, if standardization\/normalization was done, then same must be done for new input\n    \n    # Appending the new data with the Training data\n    DataForML=pd.read_pickle('DataForML.pkl')\n    InputData=InputData.append(DataForML)\n    \n    # Generating dummy variables for rest of the nominal variables\n    InputData=pd.get_dummies(InputData)\n            \n    # Maintaining the same order of columns as it was during the model training\n    Predictors=['trend', 'hd', 'speed', 'ram','screen']\n    \n    # Generating the input values to the model\n    X=InputData[Predictors].values[0:Num_Inputs]\n    \n    # Generating the standardized values of X since it was done while model training also\n    X=PredictorScalerFit.transform(X)\n    \n    # Loading the Function from pickle file\n    import pickle\n    with open('Final_XGB_Model.pkl', 'rb') as fileReadStream:\n        PredictionModel=pickle.load(fileReadStream)\n        # Don't forget to close the filestream!\n        fileReadStream.close()\n            \n    # Genprice Predictions\n    Prediction=PredictionModel.predict(X)\n    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])\n    return(round(PredictionResult))","aecbe81d":"# Calling the function for some new data\nNewSampleData=pd.DataFrame(\ndata=[[1,80,14,4,14],\n     [1,170,14,4,15]],\ncolumns=['trend', 'hd', 'speed', 'ram','screen'])\n\nprint(NewSampleData)\n\n# Calling the Function for prediction\nFunctionPredictResult(InputData= NewSampleData)","d729d64d":"# Creating the function which can take inputs and return predictions\ndef FunctionGeneratePrediction(inp_trend, inp_hd, inp_speed, inp_ram, inp_screen):\n    \n    # Creating a data frame for the model input\n    SampleInputData=pd.DataFrame(\n     data=[[inp_trend, inp_hd, inp_speed, inp_ram, inp_screen]],\n     columns=['trend', 'hd', 'speed', 'ram','screen'])\n\n    # Calling the function defined above using the input parameters\n    Predictions=FunctionPredictResult(InputData= SampleInputData)\n\n    # Returning the predicted loan status\n    return(Predictions.to_json())\n\n# Function call\nFunctionGeneratePrediction(inp_trend=1, \n                           inp_hd=80, \n                           inp_speed=14, \n                           inp_ram=4, \n                           inp_screen=14\n                             )","602c3e3b":"from flask import Flask, request, jsonify\nimport pickle\nimport pandas as pd\nimport numpy","952a4695":"app = Flask(__name__)\n\n@app.route('\/prediction_api', methods=[\"GET\"])\ndef prediction_api():\n    try:\n        # Getting the paramters from API call\n        trend_value=float(request.args.get('trend'))\n        hd_value=float(request.args.get('hd'))\n        speed_value=float(request.args.get('speed'))\n        ram_value=float(request.args.get('ram'))\n        screen_value=float(request.args.get('screen'))\n                \n        # Calling the funtion to get predictions\n        prediction_from_api=FunctionGeneratePrediction(\n                                                       inp_trend=trend_value, \n                                                       inp_hd=hd_value, \n                                                       inp_speed=speed_value, \n                                                       inp_ram=ram_value, \n                                                       inp_screen=screen_value\n                                                        )\n\n        return (prediction_from_api)\n    \n    except Exception as e:\n        return('Something is not right!:'+str(e))","68bcbd8f":"import os\nif __name__ ==\"__main__\":\n    \n    # Hosting the API in localhost\n    app.run(host='127.0.0.1', port=8080, threaded=True, debug=True, use_reloader=False)\n    # Interrupt kernel to stop the API","daed5a47":"# Creating Flask API","e9f850c8":"# Decision Tree ","5e0d235e":"# Random Forest","0eb4dc46":"# KNN","0d299403":"# Looking at the distribution of Target variable","1d0790b3":"# Adaboost","c280a818":"Data description\nThe business meaning of each column in the data is as below\n\nprice: The Price of the computer\n\nspeed: The speed\n\nhd: How much hard drive is present\n\nram: How much ram is present in the computer\n\nscreen: The screen size\n\ncd: Whether CD player is present or not\n\nmulti: Are there multiple ports or not\n\npremium: If the computer premium quality\n\nads: The ads value of the computer\n\ntrend: The trend value of the computer\n","addb4a54":"# Feature Selection & Outliers","1d63feb9":"# Visual Exploratory Data Analysis","4f071fc8":"# Standardization\/Normalization of data","dabdebd8":"# Machine Learning: Splitting the data into Training and Testing sample","cc8454c2":"# Deployment of the Model","77a5e1ed":"# Starting the API engine","2ab352b3":"# Data Pre-processing for Machine Learning","b31a06d9":"I am choosing XGBOOST as the final model since it is producing the best accuracy on this data.","f583e324":"# Linear Regression","2a481bfe":"# Basic Data Exploration","ec9cb332":"# Function for predictions API","d5f61521":"# XGBoost","0fbb739c":"# Selecting final predictors for Machine Learning"}}