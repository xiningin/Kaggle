{"cell_type":{"aa518f72":"code","5dd36580":"code","2a36f2f5":"code","5ca31e7e":"code","65c0b105":"code","a3278d05":"code","916d4c6f":"code","da060335":"code","85b27cf7":"code","15c038bb":"code","da88f2ab":"code","af583f0d":"code","d0a326b8":"markdown","28c64982":"markdown","0eb7c29e":"markdown","81697b1f":"markdown","64378cde":"markdown","d524b646":"markdown","a934d1e2":"markdown"},"source":{"aa518f72":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5dd36580":"import pandas as pd\nimport sklearn\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport keras\nimport theano\nimport tensorflow\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom sklearn.metrics import confusion_matrix ,classification_report\nfrom keras.wrappers.scikit_learn import KerasClassifier\n","2a36f2f5":"# Read Data\ncust = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","5ca31e7e":"# Explore Dataset\nprint('Dimensions:{}'.format(cust.shape))\nprint(cust.dtypes)\ncust.head()\n","65c0b105":"cust.isnull().sum()","a3278d05":"null_values=cust[cust['TotalCharges'] == ' ']\nnull_values","916d4c6f":"cust.drop(cust[(cust['TotalCharges'] == ' ')].index,inplace=True)\nnull_values=cust[cust['TotalCharges'] == ' ']\nnull_values\ncust['TotalCharges']=cust['TotalCharges'].astype('float64')","da060335":"# Remove Columns Customerid.\n\ncust.drop(['customerID'],axis=1,inplace=True)\n\n\n# Encode target feature as \"Yes\"=1 and \"No\"=0\n\ncust['Churn'].replace({\"Yes\":1,\"No\":0},inplace=True)\n\n#Encoding categorical data\nd=cust.select_dtypes(include=['object'])\nd=pd.get_dummies(d,prefix_sep='_',drop_first=True)\ncust=cust.iloc[:,[1,4,17,18,19]]\ncust=pd.concat([cust,d],axis=1)\ncust['TotalCharges'].astype('float64')\n\n\n\n# Splitting the dataset into Training and Test Set\n\nX=cust.drop(['Churn'],axis=1)\ny=cust['Churn']\n\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=80)\n\nprint('Dimensions of the training feature table: {}'.format(X_train.shape))\nprint('Dimensions of the training target vector: {}'.format(y_train.shape))\nprint('Dimensions of the test feature table: {}'.format(X_test.shape))\nprint('Dimensions of the test target vector: {}'.format(y_test.shape))\n","85b27cf7":"#Feature Scaling\nscal=StandardScaler()\nX_train=scal.fit_transform(X_train)\nX_test=scal.fit_transform(X_test)\n","15c038bb":"# First Neural Network\n\ndef nn_classifier():\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\nnn = KerasClassifier(build_fn= nn_classifier,batch_size= 10,nb_epoch=100)\nacc = cross_val_score(estimator  = nn, X = X_train, y = y_train, cv = 10, n_jobs = -1)\nprint(\"Mean Accuracy : {}\".format(acc.mean()))\nprint(\"Variance : {}\".format(acc.std()))","da88f2ab":"def nn_classifier(optimizer):\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\nnn = KerasClassifier(build_fn= nn_classifier)\nparameters = {'batch_size' : [20, 33 ], \n              'nb_epoch' : [100, 300],\n              'optimizer': ['adam','rmsprop']}\ngs = GridSearchCV(estimator = nn,\n                 param_grid = parameters,\n                 scoring = 'accuracy',\n                 cv = 10)\n\n\ngs = gs.fit( X_train, y_train)\nopt_param = gs.best_params_\nopt_acc = gs.best_score_\n","af583f0d":"print(\"Optimal Parameters : {}\".format(opt_param))\nprint(\"Optimal Accuracy : {}\".format(opt_acc))","d0a326b8":"**Data Preprocessing**","28c64982":"****Tuning Neural Network parameters****","0eb7c29e":"\"Total Charges\" feature is expected to be numeric but it\nis saved as  an 'object'. Searching for null or empty values.","81697b1f":"Now, lets do some changes into the raw data set:\n\n* drop CustomerID feature \n* encode categorical features \n* split the dataset into train and test set\n* Scale all features to have the same min and max values.\n\nApplying these steps will help the classifier perform better.","64378cde":"\"Total Charges\" Feature has zero null values. Inspect if there are observations with blank values.","d524b646":"There are 'blank' values in \"Total charges\" . There are 11 observations in total. The amount of observations is small,deleting them will not cause problems in our analysis.","a934d1e2":"**Artificial Neural Networks**"}}