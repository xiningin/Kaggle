{"cell_type":{"ad371088":"code","ddc31af5":"code","338f8c07":"code","746f00ba":"code","3c14cf82":"code","5acbb997":"code","72916f1d":"code","eab2e069":"code","913d2f1a":"code","9e4bf156":"markdown","327f39c9":"markdown","10887988":"markdown","40c8dafb":"markdown","87413894":"markdown","9dc0ed71":"markdown"},"source":{"ad371088":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ddc31af5":"\nimport numpy as np\nimport tensorflow.keras as keras\nimport tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n","338f8c07":"X = pd.read_csv('C:\/Users\/sunny\/Desktop\/h_signs.csv').iloc[0:, 1:]\ny = pd.read_csv('C:\/Users\/sunny\/Desktop\/h_signs.csv').iloc[0:,0]","746f00ba":"X = X.values\ny = y.values\n","3c14cf82":"\nx_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n","5acbb997":"\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(648, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(324, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(162, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n","72916f1d":"\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n#train a neural network  on train datasets\nmodel.fit(x_train, y_train, epochs=3)\n\n","eab2e069":"#evaluate a model and print accuracy & loss for every Epoch\nval_loss, val_acc = model.evaluate(x_test, y_test)\nprint(val_loss)\nprint(val_acc)\n","913d2f1a":"for i in range(0,580):\n    y_pred.append(np.argmax(y_predict[i]))\n\n\ncm = confusion_matrix(y_test,y_pred)\nprint(accuracy_score(y_test, y_pred))\n","9e4bf156":"import all necessary libraries\n","327f39c9":"import dataset","10887988":"change it's datatype to int from DataFrame","40c8dafb":"Creating a neural Network which have 648 input nodes,\n2 hidden layers with 324 hidden units and 162 hidden units respectively and 10 output node which is same as no. of classifiactions\n","87413894":"Compile and train the nueral net on given dataset","9dc0ed71":"split data into  train and test  using cross Validation\n"}}