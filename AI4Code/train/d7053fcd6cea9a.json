{"cell_type":{"6ee1c4d2":"code","6ad71545":"code","c15fd54f":"code","ef63b94c":"code","ec85033d":"code","66dfa9eb":"code","52278bf3":"code","9bbfea15":"code","66a0f952":"code","7770d386":"code","3502462d":"code","e2420766":"code","c50fff7b":"code","8a58c91a":"code","5423774d":"code","7f4c6280":"code","3044a778":"code","6653ab8f":"code","a294296d":"code","37a2717b":"code","283d0483":"code","5e7d5858":"code","2dc32f99":"code","78f954b0":"code","a41c5813":"code","69d997ba":"code","b51cf766":"markdown","47dafd39":"markdown","7f8e3793":"markdown","c07875c8":"markdown","68777cd1":"markdown","50d01af8":"markdown","f0e4b028":"markdown","d0c189b4":"markdown","fde35a35":"markdown","bacb47ed":"markdown","2b700c6d":"markdown","f6125dc8":"markdown","19d9c5af":"markdown","d2e3d5dd":"markdown","b6c9b5c9":"markdown","175ee5b7":"markdown","ad0064cd":"markdown","32a46647":"markdown","c6b239be":"markdown","ab0a930d":"markdown","6a39b19e":"markdown","413d2a41":"markdown","d4cae854":"markdown","d7013ba5":"markdown","b43c4041":"markdown","a0bf12ca":"markdown","ea773eaa":"markdown","3db5cf61":"markdown","fcd8407e":"markdown","e6c11809":"markdown","8d3675d8":"markdown","989237a9":"markdown","580d4483":"markdown","a4fa70a4":"markdown","04d21234":"markdown","c7f78751":"markdown","d72fcdf5":"markdown","e2fbdc9e":"markdown","b2605453":"markdown","98ce6937":"markdown","6263317f":"markdown","36359fb6":"markdown","fe34b644":"markdown","910657bb":"markdown","b24b6d50":"markdown","e4202b0c":"markdown","3b290eb6":"markdown","f29a7624":"markdown","1abb7006":"markdown","0e618054":"markdown","c8471c0c":"markdown","20ec37c9":"markdown"},"source":{"6ee1c4d2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import mode\n\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.utils import to_categorical\n\nfrom matplotlib import ticker\nimport time\nimport warnings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\n\n\nRANDOM_STATE = 12 \nFOLDS = 5","6ad71545":"train = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")","c15fd54f":"train.head()","ef63b94c":"print(f'\\033[92mNumber of rows in train data: {train.shape[0]}')\nprint(f'\\033[94mNumber of columns in train data: {train.shape[1]}')\nprint(f'\\033[91mNumber of values in train data: {train.count().sum()}')\nprint(f'\\033[91mNumber missing values in train data: {sum(train.isna().sum())}')","ec85033d":"print(train.isna().sum().sort_values(ascending = False))","66dfa9eb":"train.describe()","52278bf3":"test.head()","9bbfea15":"print(f'\\033[92mNumber of rows in test data: {test.shape[0]}')\nprint(f'\\033[94mNumber of columns in test data: {test.shape[1]}')\nprint(f'\\033[91mNumber of values in train data: {test.count().sum()}')\nprint(f'\\033[91mNo of rows with missing values  in test data: {sum(test.isna().sum())}')","66a0f952":"print((test.isna().sum().sort_values(ascending = False)))","7770d386":"test.describe()","3502462d":"submission.head()","e2420766":"train.drop([\"id\"] , axis = 1 , inplace = True)\ntest.drop([\"id\"] , axis = 1 , inplace = True)\nTARGET = 'song_popularity'\nFEATURES = [col for col in train.columns if col not in ['id', TARGET]]\nRANDOM_STATE = 12 ","c50fff7b":"train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='GnBu')\\\n                     .bar(subset=[\"max\"], color='#BB0000')\\\n                     .bar(subset=[\"mean\",], color='green')","8a58c91a":"test_null = pd.DataFrame(test.isna().sum())\ntest_null = test_null.sort_values(by = 0 ,ascending = False)[:-5]\ntrain_null = pd.DataFrame(train.isna().sum())\ntrain_null = train_null.sort_values(by = 0 ,ascending = False)[:-6]\nfig, axes = plt.subplots(1,2, figsize=(18,10))\nsns.barplot( y =test_null.index ,  x  = test_null[0] ,ax = axes[1] ,palette = \"viridis\")\nsns.barplot( y =train_null.index ,  x  = train_null[0],ax = axes[0],palette = \"viridis\")\naxes[0].set_xlabel(\"TRAIN DATA COLUMNS\")\naxes[1].set_xlabel(\"TEST DATA COLUMNS\");","5423774d":"missing_train_row = train.isna().sum(axis=1)\nmissing_train_row = pd.DataFrame(missing_train_row.value_counts()\/train.shape[0]).reset_index()\nmissing_test_row = test.isna().sum(axis=1)\nmissing_test_row = pd.DataFrame(missing_test_row.value_counts()\/test.shape[0]).reset_index()\nmissing_train_row.columns = ['no', 'count']\nmissing_test_row.columns = ['no', 'count']\nmissing_train_row[\"count\"] = missing_train_row[\"count\"]*100\nmissing_test_row[\"count\"] = missing_test_row[\"count\"]*100\nfig, axes = plt.subplots(1,2, figsize=(18,6))\nsns.barplot( y =missing_train_row[\"count\"] ,  x  = missing_train_row[\"no\"],ax = axes[1] ,palette = \"viridis\")\nsns.barplot( y =missing_test_row[\"count\"] ,  x  = missing_test_row[\"no\"],ax = axes[0] ,palette = \"viridis\")\naxes[0].set_ylabel(\"Percentage of Null values\")\naxes[1].set_ylabel(\"Percentage of Null values\")\naxes[0].set_xlabel(\"TRAIN DATASET\")\naxes[1].set_xlabel(\"TEST DATASET\");","7f4c6280":"df = pd.concat([train[FEATURES], test[FEATURES]], axis=0)\n\ncat_features = [col for col in FEATURES if df[col].nunique() < 15]\ncont_features = [col for col in FEATURES if df[col].nunique() >= 15]\n\ndel df\nprint(f'Total number of features: {len(FEATURES)}')\nprint(f'\\033[92mNumber of categorical features: {len(cat_features)}')\nprint(f'\\033[96mNumber of continuos features: {len(cont_features)}')\n\nplt.pie([len(cat_features), len(cont_features)], \n        labels=['Categorical', 'Continuos'],\n        colors=['#DE3163', '#58D68D'],\n        textprops={'fontsize': 13},\n        autopct='%1.1f%%')\nplt.show()","3044a778":"ncols = 5\nnrows = int(len(cont_features) \/ ncols + (len(FEATURES) % ncols > 0))-1\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 10), facecolor='#EAEAF2')\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = cont_features[r*ncols+c]\n        sns.histplot(x=train[col], ax=axes[r, c], color='#58D68D', label='Train data' , fill =True , kde = True)\n        sns.histplot(x=test[col], ax=axes[r, c], color='#DE3163', label='Test data', fill =True, kde = True)\n        axes[r,c].legend()\n        axes[r, c].set_ylabel('')\n        axes[r, c].set_xlabel(col, fontsize=8)\n        axes[r, c].tick_params(labelsize=5, width=0.5)\n        axes[r, c].xaxis.offsetText.set_fontsize(4)\n        axes[r, c].yaxis.offsetText.set_fontsize(4)\nplt.show()","6653ab8f":"if len(cat_features) == 0 :\n    print(\"No Categorical features\")\nelse:\n    ncols = 3\n    nrows = 1\n\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 5))\n    for r in range(nrows):\n        for c in range(ncols):\n            col = cat_features[c]\n            sns.countplot(train[col],ax = axes[c] ,palette = \"viridis\", label='Train data')\n            sns.countplot(test[col],ax = axes[c] ,palette = \"magma\", label='Test data')\n            axes[c].legend()\n            axes[c].set_ylabel('')\n            axes[c].set_xlabel(col, fontsize=20)\n            axes[c].tick_params(labelsize=10, width=0.5)\n            axes[c].xaxis.offsetText.set_fontsize(4)\n            axes[c].yaxis.offsetText.set_fontsize(4)\n    plt.show()","a294296d":"target_df = pd.DataFrame(train[TARGET].value_counts()).reset_index()\ntarget_df.columns = [TARGET, 'count']\nfig = px.bar(data_frame =target_df, \n             x = TARGET,\n             y = 'count' , \n             color = \"count\",\n             color_continuous_scale=\"Emrld\") \nfig.update_layout(template = \"plotly_white\")\nprint(\"\\033[94mPercentage of song_popularity = 0: {:.2f} %\".format(target_df[\"count\"][0] *100 \/ train.shape[0]))\nprint(\"\\033[94mPercentage of song_popularity = 1: {:.2f} %\".format(target_df[\"count\"][1]* 100 \/ train.shape[0]))\nfig.show()","37a2717b":"plt.rcParams[\"figure.figsize\"] = (18,12)\ndataplot = sns.heatmap(train.corr(), cmap=\"viridis\", annot=True)\nplt.show()","283d0483":"lgb_params = {\n    'objective' : 'binary',\n    'metric' : 'auc',\n    'n_estimators' : 50,\n    \"learning_rate\" : 0.128,\n}\n\n\nlgb_predictions = 0\nlgb_scores = []\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]\n    \n    model = LGBMClassifier(**lgb_params)\n    model.fit(X_train, y_train,verbose=0)\n    \n    preds_valid = model.predict_proba(X_valid)[:, 1]\n    auc = roc_auc_score(y_valid,  preds_valid)\n    lgb_scores.append(auc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s\")\n    test_preds = model.predict_proba(test[FEATURES])[:, 1]\n    lgb_predictions += test_preds\/FOLDS\n    \nprint(\"Mean AUC :\", np.mean(lgb_scores))","5e7d5858":"catb_params = {\n    \"objective\": \"Logloss\",\n}\n\n\ncatb_predictions = 0\ncatb_scores = []\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]\n    \n    model = CatBoostClassifier(**catb_params)\n    model.fit(X_train, y_train,verbose=0)\n    \n    preds_valid = model.predict_proba(X_valid)[:, 1]\n    auc = roc_auc_score(y_valid,  preds_valid)\n    catb_scores.append(auc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s\")\n    test_preds = model.predict_proba(test[FEATURES])[:, 1]\n    catb_predictions += test_preds\/FOLDS\n    \nprint(\"Mean AUC :\", np.mean(catb_scores))","2dc32f99":"xgb_params = {\n    \"objective\":\"binary:logistic\",\n    \"eval_metric\": \"auc\",\n}\n\n\nxgb_predictions = 0\nxgb_scores = []\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]\n    \n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,verbose=0)\n    \n    preds_valid = model.predict_proba(X_valid)[:, 1]\n    auc = roc_auc_score(y_valid,  preds_valid)\n    xgb_scores.append(auc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s\")\n    test_preds = model.predict_proba(test[FEATURES])[:, 1]\n    xgb_predictions += test_preds\/FOLDS\n    \nprint(\"Mean AUC :\", np.mean(xgb_scores))","78f954b0":"lgb_submission = submission.copy()\nlgb_submission['song_popularity'] = lgb_predictions\nlgb_submission.to_csv(\"lgb-subs.csv\",index=False)\nlgb_submission.head()","a41c5813":"catb_submission = submission.copy()\ncatb_submission['song_popularity'] = catb_predictions\ncatb_submission.to_csv(\"catb-subs.csv\",index=False)\ncatb_submission.head()","69d997ba":"xgb_submission = submission.copy()\nxgb_submission['song_popularity'] = xgb_predictions\nxgb_submission.to_csv(\"xgb-subs.csv\",index=False)\nxgb_submission.head()","b51cf766":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >\u2b06\ufe0fBack to Table of Contents \u2b06\ufe0f<\/a>","47dafd39":"### Quick view of Test Data","7f8e3793":"<a id=\"4.4\"><\/a>\n## Feature Distribution of Categorical Features","c07875c8":"### Quick view of Submission File","68777cd1":"Below is the first 5 rows of train dataset:","50d01af8":"<a id=\"3.2\"><\/a>\n## Exploring Test Data","f0e4b028":"**Observations:**\n- The maximum of missing value in an observation is `6` and the lowest is `no missing value`.\n- Interestingly, the missing value distribution (row basis) is quite the same between `train` and `test` dataset.\n- There are around `44%` of the observations (row basis) that has no missing values.\n- `56.28%` of total observations with missing values have `1 to 3` missing values in the a observations. ","d0c189b4":"<a id=\"5.2\"><\/a>\n## Catboost Classifier","fde35a35":"<a id=\"4.2\"><\/a>\n## Continuos and Categorical Data Distribution","bacb47ed":"### Column Wise missing values","2b700c6d":"### Observations:\n\n* There are total of ```14``` columns : ```10``` continous , ```3``` categorical ```1``` id in ```test``` dataset\n* Train dataset contain ```122,038``` observation with ```7962```  missing values.\n* 8 differnt rows have null values with maximum missings values in ```energy``` column.","f6125dc8":"<a id=\"3\"><\/a>\n# Data Loading and Preperation","19d9c5af":"<a id=\"5.3\"><\/a>\n## XGBoost Classifier","d2e3d5dd":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >\u2b06\ufe0fBack to Table of Contents \u2b06\ufe0f<\/a>","b6c9b5c9":"<a id=\"4.6\"><\/a>\n## Correlation matrix","175ee5b7":"**The competition is organised by MLspace and is the first competition of the series.**\n\n\n**In this competition, you are supposed to predict the popularity of a song given features like acousticness, danceability, key, loudness, etc.**\n\n**Submissions are evaluated on Area Under the ROC Curve (AUC)**","ad0064cd":"<a id=\"4.2.1\"><\/a>\n### Column wise Null Value Distribution ","32a46647":"<a id=\"4.7.2\"><\/a>\n### Row wise Null Value Distribution ","c6b239be":"<a id=\"6\"><\/a>\n#  Submission","ab0a930d":"### Dealing with missing value (reference)\nSome references on how to deal with missing value:\n- [Missing Values](https:\/\/www.kaggle.com\/alexisbcook\/missing-values) by [Alexis Cook](https:\/\/www.kaggle.com\/alexisbcook)\n- [Data Cleaning Challenge: Handling missing values](https:\/\/www.kaggle.com\/rtatman\/data-cleaning-challenge-handling-missing-values) by [Rachael Tatman](https:\/\/www.kaggle.com\/rtatman)\n- [A Guide to Handling Missing values in Python ](https:\/\/www.kaggle.com\/parulpandey\/a-guide-to-handling-missing-values-in-python) by [Parul Pandey](https:\/\/www.kaggle.com\/parulpandey)\n\nSome models that have capability to handle missing value by default are:\n- XGBoost: https:\/\/xgboost.readthedocs.io\/en\/latest\/faq.html\n- LightGBM: https:\/\/lightgbm.readthedocs.io\/en\/latest\/Advanced-Topics.html\n- Catboost: https:\/\/catboost.ai\/docs\/concepts\/algorithm-missing-values-processing.html","6a39b19e":"Below is the basic statistics for each variables which contain information on `count`, `mean`, `standard deviation`, `minimum`, `1st quartile`, `median`, `3rd quartile` and `maximum`.","413d2a41":"<a id=\"1\"><\/a>\n# Introduction","d4cae854":"<a id=\"3.1\"><\/a>\n## Exploring Train Data","d7013ba5":"### Observations:\n\n* There are total of ```15``` columns : ```10``` continous , ```3``` categorical ```1``` id and ```1``` target column\n* ```song_popularity column``` is the target variable which is only available in the ```train``` dataset.\n* Train dataset contain ```527,813``` observation with ```32,178```  missing values.\n* 8 differnt rows have null values with maximum missings values in ```song_duration_ms``` column.","b43c4041":"### XGBoost Classifier Submission","a0bf12ca":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >\u2b06\ufe0fBack to Table of Contents \u2b06\ufe0f<\/a>","ea773eaa":"<a id=\"4.3\"><\/a>\n## Feature Distribution of Continous Features","3db5cf61":"<a id=\"3.3\"><\/a>\n## Submission File","fcd8407e":"### Basic statistics of training data","e6c11809":"<a id=\"4.1\"><\/a>\n## Overview of Data","8d3675d8":"**Created by Sanskar Hasija**\n\n**Song Popularity Prediction - \ud83d\udccaEDA + MODELLING\ud83d\udcca**\n\n**18 JANUARY 2022**\n","989237a9":"Below is the basic statistics for each variables which contain information on `count`, `mean`, `standard deviation`, `minimum`, `1st quartile`, `median`, `3rd quartile` and `maximum`.","580d4483":"**Observations:**\n- `LGBMClassifier` , `CatBoostClassifier` and `XGBClassifier` are proving almost similar AUC score of `0.56` mean score on 5-fold validation.\n- Further Hyperparameter tuning can imporve the results.","a4fa70a4":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >\u2b06\ufe0fBack to Table of Contents \u2b06\ufe0f<\/a>","04d21234":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >\u2b06\ufe0fBack to Table of Contents \u2b06\ufe0f<\/a>","c7f78751":"### Quick view of Train Data","d72fcdf5":"<a id=\"4.7\"><\/a>\n## Null Value Distribution ","e2fbdc9e":"# Table of Contents\n<a id=\"toc\"><\/a>\n- [1. Introduction](#1)\n- [2. Imports](#2)\n- [3. Data Loading and Preperation](#3)\n    - [3.1 Exploring Train Data](#3.1)\n    - [3.2 Exploring Test Data](#3.2)\n    - [3.3 Submission File](#3.3)\n- [4. EDA](#4)\n    - [4.1 Overview of Data](#4.1)\n    - [4.2 Null Value Distribution](#4.7)\n    - [4.3 Continuos and Categorical Data Distribution](#4.2)\n    - [4.4 Feature Distribution of Continous Features](#4.3)\n    - [4.5 Feature Distribution of Categorical Features](#4.4)\n    - [4.6 Target Distribution ](#4.5)\n    - [4.7 Correlation Matrix ](#4.6)\n- [5. Modelling](#5)\n    - [5.1 LGBM Classifier](#5.1)\n    - [5.2 Catboost Classifier](#5.2)\n    - [5.3 XGBoost Classifier](#5.3)\n- [6. Submission](#6)   ","b2605453":"### Catboost Classifier Submission","98ce6937":"# <center> SONG POPULARITY PREDICTION - \ud83d\udccaEDA + MODELLING\ud83d\udcca <\/center>\n## <center>If you find this notebook useful, support with an upvote\ud83d\udc4d<\/center>","6263317f":"<a id=\"5\"><\/a>\n#  Modelling","36359fb6":"**Observations:**\n- There are two target values - `0` and `1`.\n- Almost 2\/3rd - `63.56%` of total observations comprise of `0` target value.\n- Almost 1\/3rd - `36.44%` of total observations comprise of `1` target value.","fe34b644":"**Observations:**\n- Out of 13 features `10` features are continous and `3` features are categorical.\n- `key` feature has `11` differnt unique values\n- `time_signature` has`4` differnt unique values.\n- `audio_mode` feature is a binary cateogorical feature with `1` and `0` values.\n","910657bb":"### Basic statistics of test data","b24b6d50":"<a id=\"4.5\"><\/a>\n## Target Distribution","e4202b0c":"<a id=\"5.1\"><\/a>\n## LGBM Classifier","3b290eb6":"<a id=\"2\"><\/a>\n# Imports","f29a7624":"### Column Wise missing values","1abb7006":"### LGBM Classifier Submission","0e618054":"<a id=\"4\"><\/a>\n# EDA","c8471c0c":"### <center>Thank you for reading\ud83d\ude42<\/center>\n### <center>If you have any feedback or find anything wrong, please let me know!<\/center>\n","20ec37c9":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >\u2b06\ufe0fBack to Table of Contents \u2b06\ufe0f<\/a>"}}