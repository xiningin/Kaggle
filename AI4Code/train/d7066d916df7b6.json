{"cell_type":{"a6e13cb6":"code","b2aab884":"code","2b235ae7":"code","fafa1258":"code","185925b8":"code","77338735":"code","bb273e21":"code","53cea78a":"code","3fed9b6b":"code","166f6ddc":"markdown","5931c51f":"markdown","a1a2bc96":"markdown","350b4279":"markdown","5e083e34":"markdown"},"source":{"a6e13cb6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport os\nprint(os.listdir(\"..\/input\"))","b2aab884":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","2b235ae7":"train_df.head()","fafa1258":"test_df.head()","185925b8":"train_df.drop(columns=['ID_code', 'target'], inplace=True)\ntest_df.drop(columns=['ID_code'], inplace=True)","77338735":"train_df['is_test'] = 0\ntest_df['is_test'] = 1\ndf = pd.concat([train_df, test_df], axis = 0)\nX = df.drop(columns=['is_test'])\ny = df['is_test']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\nprint('train2 shape:', X_train.shape, 'test2 shape:', X_test.shape)","bb273e21":"#Let's use simple Random Forest as Classifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\ny_test_score = rfc.predict_proba(X_test)","53cea78a":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\nskplt.metrics.plot_roc_curve(y_test, y_test_score)\nplt.show()","3fed9b6b":"#AUC score is about 0.5\nprint('AUC score: ', round(roc_auc_score(y_true=y_test, y_score=y_test_score[:,1]), 4))","166f6ddc":"![](https:\/\/www.researchgate.net\/profile\/Patrick_Glauner\/publication\/322568228\/figure\/fig1\/AS:583987370143745@1516244847412\/Example-of-covariate-shift-training-and-test-data-having-different-distributions.png)","5931c51f":"The main idea of method is to set new label \"is_test\"=0 for train dataframe and \"is_test\"=1 for test. Than we should concat this two parts into one huge dataset (train and test with corresponding \"is_test\" label) and shuffle it randomly. \n\nNext step is splitting huge dataset into two parts: **train_2** and **test_2** (for example, in 70\/30 ratio). Than we train some classificaton algorithm on dataset **train_2**  using label 'is_test'. Finally predict 'is_test' label on dataset **test_2** and estimate some quality metric. For example, ROC AUC.\n\nIf value or AUC is about 0.5 than there is no sufficient reason to talk about differences in train and test. Otherwise, we need to conduct a deep data analysis.","a1a2bc96":"As you can see, classifier can't find any reasonable difference between train and test data. There are no evidence of non-zero covariate shift.\n\n**Links:**\n\n[1] https:\/\/towardsdatascience.com\/how-dis-similar-are-my-train-and-test-data-56af3923de9b\n\n[2] https:\/\/github.com\/hakeydotom\/Covariate-shift-prediction","350b4279":"Plot ROC curve and see how well our classifier works:","5e083e34":"Hi kagglers! Let's check if there are any differences between train and test data. It allow us to determine situation when test data has other distributions, and it is incorrect to build model directly on exisiting data split.\nFirst load train and test data into dataframes, drop columns that contain labels and not useful data:\n"}}