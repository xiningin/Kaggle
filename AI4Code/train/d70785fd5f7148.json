{"cell_type":{"c07436ea":"code","ff228ece":"code","7e5b70d4":"code","d4449b8f":"code","ea51e60d":"code","6729a36e":"code","9c1370f0":"code","484fbb16":"code","7fe7ee5e":"code","d6e4e9d1":"code","29b5ff76":"code","ccd20613":"code","1ef74653":"code","70639f4b":"code","cae8f22c":"code","cc264bdb":"code","0ded8a8f":"code","ac83673e":"code","8a199a3c":"code","da5a8d8f":"code","c6178f79":"code","7547519f":"code","8730bfde":"code","008c79f3":"code","f71441d3":"code","b0445021":"code","cd4b57a6":"code","ec0140de":"code","7a7bd6db":"code","f8bf56ec":"code","0ed36c62":"code","c81d81f2":"code","12998654":"code","0f06059a":"code","e40265c9":"code","502215d0":"code","f576e1ce":"code","d3170a05":"code","c40059e7":"code","cd3733ca":"markdown","e29da3f6":"markdown","13af8e27":"markdown","6b19b439":"markdown","c893130f":"markdown","3f5e1ae0":"markdown","47646386":"markdown","bae3835c":"markdown","485fc2b7":"markdown","fd3fca73":"markdown","c9300085":"markdown","5dc7a7c1":"markdown","6d888806":"markdown","eb27fb27":"markdown","0c29fd9b":"markdown","03115f9f":"markdown","8aca7876":"markdown","beb2640b":"markdown"},"source":{"c07436ea":"from random import randint\nimport pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt","ff228ece":"data_directory = os.path.join(os.getcwd(), '..\/input')\nprint(os.listdir(data_directory))","7e5b70d4":"!cat '..\/input\/readme.txt'","d4449b8f":"data_dictionnary = {}\n\n# columns name from readme\n# define metadata and feature\noperational_settings = ['op_setting_{}'.format(i + 1) for i in range (3)]\nsensor_columns = ['sensor_{}'.format(i + 1) for i in range(27)]\nfeatures = operational_settings + sensor_columns\nmetadata = ['engine_no', 'time_in_cycles']\nlist_columns = metadata + features\n\n\nlist_file_train = [x for x in sorted(os.listdir(data_directory)) if 'train' in x]\n\n# names of the datasets\nfor file_train in list_file_train:\n    data_set_name = file_train.replace('train_', '').replace('.txt', '')\n    file_test = 'test_' + data_set_name + '.txt'\n    rul_test = 'RUL_' + data_set_name + '.txt'\n    \n    # dictionnaries with all datasets\n    data_dictionnary[data_set_name] = {\n        'df_train': pd.read_csv(os.path.join(data_directory, file_train), sep=' ', header=-1, names=list_columns),\n        'df_test': pd.read_csv(os.path.join(data_directory, file_test), sep=' ', header=-1, names=list_columns),\n        'RUL_test' :pd.read_csv(os.path.join(data_directory, rul_test), header=-1, names=['RUL']),\n    }","ea51e60d":"data_dictionnary['FD001']['df_train'].head()","6729a36e":"# on train datasets, RUL starts at the maximum number of cycles and is decreasing down to 0\ndef add_rul(group):\n    group['RUL'] = [max(group['time_in_cycles'])] * len(group)\n    group['RUL'] = group['RUL'] - group['time_in_cycles']\n    del group['engine_no']\n    return group.reset_index()\n\nfor data_set in data_dictionnary:\n    data_dictionnary[data_set]['df_train'] = data_dictionnary[data_set]['df_train']\\\n                        .groupby('engine_no').apply(add_rul).reset_index()\n    del data_dictionnary[data_set]['df_train']['level_1']","9c1370f0":"data_dictionnary['FD001']['df_train'].head()","484fbb16":"CHOSEN_DATASET = 'FD001'\n\ndf = data_dictionnary[CHOSEN_DATASET]['df_train'].copy()\n\ndf_eval = data_dictionnary[CHOSEN_DATASET]['df_test'].copy()","7fe7ee5e":"dataset_description = df.describe()\ndataset_description","d6e4e9d1":"axes = dataset_description.T.plot.bar(subplots=True, figsize=(15,10))","29b5ff76":"############### Question 1 ###############\n# What can you conclude from the above graph?","ccd20613":"df_plot = df.copy()[features]\ndf_corr = df_plot.corr(method='pearson')\nfig, ax = plt.subplots(figsize=(15,15))\naxes = sns.heatmap(df_corr, linewidths=.2, )","1ef74653":"############### Question 2 ###############\n# Can you plot a correlation matrix with another correlation coeficient?","70639f4b":"############### Question 3 ###############\n# What can happen when you have correlated features?","cae8f22c":"nan_column = ?\nconst_columns = ?\nprint('Columns with all nan: \\n' + str(nan_column) + '\\n')\nprint('Columns with all const values: \\n' + str(const_columns) + '\\n')","cc264bdb":"############### Question 4 ###############\n# Can you find all the couples that are strongly correlated ? What can be done about them ?","0ded8a8f":"df_plot = df.copy()\ndf_plot = df_plot.sort_values(metadata)\ngraph = sns.PairGrid(data=df_plot, x_vars=\"RUL\", y_vars=features, hue=\"engine_no\", height=4, aspect=6,)\ngraph = graph.map(plt.plot, alpha=0.5)\ngraph = graph.set(xlim=(df_plot['RUL'].max(),df_plot['RUL'].min()))\n# graph = graph.add_legend()","ac83673e":"############### Question 5 ###############\n# What can you see from the graphs above?","8a199a3c":"############### Question 6 ###############\n# Would it be better to train on a smaller part?","da5a8d8f":"number_of_engine_no = len(df['engine_no'].drop_duplicates())\n\nengine_no_val = range(50, 70)\nengine_no_train = [x for x in range(number_of_engine_no) if x not in engine_no_val]","c6178f79":"selected_features = [x for x in features if x not in nan_column + const_columns]","7547519f":"data_train = df[df['engine_no'].isin(engine_no_train)]\ndata_val = df[df['engine_no'].isin(engine_no_val)]\n\nX_train, y_train = data_train[selected_features], data_train['RUL'] \nX_val, y_val = data_val[selected_features], data_val['RUL']\n\nX_eval = df_eval[selected_features]\n\n\nX_all, y_all = df[selected_features], df['RUL']","8730bfde":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train, y_train)","008c79f3":"print(\"Score on train data : \" + str(rf_reg.score(X_train, y_train)))\nprint(\"Score on test data : \" + str(rf_reg.score(X_val, y_val)))","f71441d3":"############### Question 7 ###############\n# Did you overfit? If so, what solutions could you find?","b0445021":"############### Question 8 ###############\n# Can you have the RMSE?","cd4b57a6":"from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\ncv_results = cross_validate(rf_reg, X_train, y_train, cv=10, return_estimator=True)","ec0140de":"cv_results['test_score']","7a7bd6db":"cv_results['estimator'][0].score(X_val, y_val)","f8bf56ec":"cv_results['estimator'][1].score(X_val, y_val)","0ed36c62":"cv_results['estimator'][2].score(X_val, y_val)","c81d81f2":"cv_results['estimator'][3].score(X_val, y_val)","12998654":"cv_results['estimator'][4].score(X_val, y_val)","0f06059a":"############### Question 9 ###############\n# Try to improve you model.\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train, y_train)\n\ncross_val_score(rf_reg, X_train, y_train, cv=10)","e40265c9":"y_pred = cross_val_predict(rf_reg, X_train, y_train, cv=10)","502215d0":"print(\"Score on test data : \" + str(rf_reg.score(X_val, y_val)))","f576e1ce":"df_pred = data_train.copy()\ndf_pred['pred'] = rf_reg.predict(X_train)\ndf_pred['error'] = df_pred['pred'] - df_pred['RUL']","d3170a05":"df_plot = df_pred.copy()\ndf_plot = df_plot.sort_values(['engine_no', 'time_in_cycles'])\ng = sns.PairGrid(data=df_plot, x_vars=\"RUL\", y_vars=['RUL', 'pred', 'error'], hue=\"engine_no\", height=6, aspect=6,)\ng = g.map(plt.plot, alpha=0.5)\ng = g.set(xlim=(df_plot['RUL'].max(),df_plot['RUL'].min()))","c40059e7":"df_eval['pred'] = rf_reg.predict(X_eval)\n\ndf_eval['result'] = df_eval['pred']\ndf_eval['engine_id'] = list(range(len(df_eval)))\n\ndf_eval[['engine_id','result']].to_csv('submission.csv', index=False)","cd3733ca":"### Plot a temporal vizualisation of the features","e29da3f6":"# Load DATA","13af8e27":"# Imports","6b19b439":"# Making a prediction","c893130f":"### Find columns that can be dropped ","3f5e1ae0":"### Plotting some description of the dataset","47646386":"### Correlation matrix","bae3835c":"### Splitting test \/ train data","485fc2b7":"### Score the model ","fd3fca73":"### Selecting only relevant features","c9300085":"# Prediction on test data and Output","5dc7a7c1":"### Plotting the result ","6d888806":"# Add RUL","eb27fb27":"### Training a random forest","0c29fd9b":"# Chosing a dataset ","03115f9f":"# List data directory","8aca7876":"# Data analysis","beb2640b":"### Actually making the split"}}