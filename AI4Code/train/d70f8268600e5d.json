{"cell_type":{"c1b6f3c8":"code","467ed37b":"code","d90714f5":"code","e281ca88":"code","c5e20c66":"code","72493b19":"code","5b7a8c12":"code","5e602259":"code","be46ed0f":"code","5dcda525":"code","7b3c2d54":"code","b9bb0785":"code","83ca2c5f":"code","a68a6be4":"code","f71457bb":"code","42f2e2a7":"code","8126fc83":"code","d8adcfd0":"code","0da4a041":"code","c4f8f948":"code","ad128fda":"code","8e8bb927":"code","a40e5566":"code","a2d34136":"code","f0158a71":"code","0d0a2fe6":"code","4aad2204":"code","0fc30d9f":"code","1b94c19a":"code","78ace9e2":"code","3d4c6339":"code","f847e951":"code","92b3743d":"code","90bf4764":"code","b68e1ad1":"code","85528f21":"code","7e61781f":"code","9460dc1a":"code","502a1dbe":"code","6a421efc":"code","5e645f71":"code","a9039b44":"code","938514d2":"code","c38406d7":"code","5b412522":"code","f8c71f0b":"code","0aff1484":"code","8da98f9f":"code","578644cb":"code","3f43e477":"code","b6bf34d8":"code","066c31cf":"code","c9a30913":"code","e046f094":"code","7d138e36":"code","218c8b77":"code","09c44a47":"code","49ce2998":"code","4f28eed6":"code","58f51287":"code","dbf039f7":"code","1530102a":"code","e15bbdf1":"code","71068c64":"code","19d32ab6":"code","0fdd3ae2":"code","1bf86823":"code","1bda8a7d":"code","9ed102d9":"code","db71a222":"code","74053fc3":"code","f841c4c9":"code","84f302de":"code","ac342212":"code","fe7f7204":"code","cb3990a3":"code","5a35dff5":"code","a9d65a9b":"code","f57b9498":"code","636aa362":"code","88469427":"markdown","76644384":"markdown","453160fb":"markdown","72a0c787":"markdown","8bf5eacd":"markdown","6a68e4b2":"markdown","66bdac89":"markdown","70ca1f0c":"markdown","71f37c3a":"markdown","0bd88024":"markdown","e122ef50":"markdown","bc3de68e":"markdown","3376f3c3":"markdown","dcca7d60":"markdown","f3012fb6":"markdown","bac2f4f3":"markdown","57263be0":"markdown","685ab507":"markdown","965cd1d1":"markdown","26a4760f":"markdown","19a7db6a":"markdown","0a94da91":"markdown","70962fdd":"markdown","34986cab":"markdown","07aceab5":"markdown","fd616b8a":"markdown","b43e456b":"markdown","0ab3a8a0":"markdown","630fa44d":"markdown","292a6ff0":"markdown","d522776c":"markdown","d9e28af1":"markdown","36a5d348":"markdown","e2437c0b":"markdown","f06566a1":"markdown","f4ed20a6":"markdown","633b9a09":"markdown","f279c11f":"markdown","127b025d":"markdown","f6b07ff0":"markdown","8b4edd4e":"markdown","78ecd397":"markdown","64621d6e":"markdown","4d768d7c":"markdown","9e451d53":"markdown","6ebfaddc":"markdown","b4172283":"markdown","51be8abe":"markdown","f050800b":"markdown","3eee764a":"markdown"},"source":{"c1b6f3c8":"from IPython.display import YouTubeVideo\nYouTubeVideo('BLw62AhW_Kc', width=700, height=400)","467ed37b":"!pip install lofo-importance","d90714f5":"from lofo import LOFOImportance, Dataset, plot_importance\nimport shap \nimport warnings  \nwarnings.filterwarnings('ignore')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,roc_auc_score,f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport os\nimport seaborn as sns\nprint(os.listdir(\"..\/input\"))\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\n# Any results you write to the current directory are saved as output.","e281ca88":"#Reading dataset \ndt=pd.read_csv('..\/input\/heart.csv')","c5e20c66":"dt.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']","72493b19":"\n\ndt['chest_pain_type'][dt['chest_pain_type'] == 1] = 'typical angina'\ndt['chest_pain_type'][dt['chest_pain_type'] == 2] = 'atypical angina'\ndt['chest_pain_type'][dt['chest_pain_type'] == 3] = 'non-anginal pain'\ndt['chest_pain_type'][dt['chest_pain_type'] == 4] = 'asymptomatic'\n\n\n\ndt['rest_ecg'][dt['rest_ecg'] == 0] = 'normal'\ndt['rest_ecg'][dt['rest_ecg'] == 1] = 'ST-T wave abnormality'\ndt['rest_ecg'][dt['rest_ecg'] == 2] = 'left ventricular hypertrophy'\n\n\n\ndt['st_slope'][dt['st_slope'] == 1] = 'upsloping'\ndt['st_slope'][dt['st_slope'] == 2] = 'flat'\ndt['st_slope'][dt['st_slope'] == 3] = 'downsloping'\n\ndt['thalassemia'][dt['thalassemia'] == 1] = 'normal'\ndt['thalassemia'][dt['thalassemia'] == 2] = 'fixed defect'\ndt['thalassemia'][dt['thalassemia'] == 3] = 'reversable defect'","5b7a8c12":"# Chacking datatypes of all features \ndt.dtypes","5e602259":"dt.head()","be46ed0f":"dt.describe()","5dcda525":"dt.info()","7b3c2d54":"## null count analysis\nimport missingno as msno\np=msno.bar(dt)","b9bb0785":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndt['target'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('target')\nax[0].set_ylabel('')\nsns.countplot('target',data=dt,ax=ax[1])\nax[1].set_title('target')\nplt.show()","83ca2c5f":"dataset2=dt.drop(['target'],axis=1)\np = dataset2.hist(figsize = (12,8))","a68a6be4":"sns.boxplot(data=dt,x=\"target\", y=\"cholesterol\");","f71457bb":"sns.boxplot(data=dt,x=\"target\", y=\"max_heart_rate_achieved\");","42f2e2a7":"sns.boxplot(data=dt,x=\"target\", y=\"resting_blood_pressure\");","8126fc83":"cols_drp=['age','sex','fasting_blood_sugar','exercise_induced_angina','st_depression','num_major_vessels','target']\ndt_o=dt.drop(cols_drp,axis=1)\n\nQ1 = dt_o.quantile(0.25)\nQ3 = dt_o.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","d8adcfd0":"dt_clean = dt.loc[~dt['cholesterol'].isin([63.5])]\ndt_clean= dt_clean.loc[~dt_clean['resting_blood_pressure'].isin([20.0])]\ndt_clean= dt_clean.loc[~dt_clean['max_heart_rate_achieved'].isin([32.5])]\n\ndt_clean.shape\n","0da4a041":"sns.boxplot(data=dt_clean,x=\"target\", y=\"resting_blood_pressure\");","c4f8f948":"sns.set(rc={'figure.figsize':(9,7)})\nsns.distplot(dt['age']);","ad128fda":"sns.set(rc={'figure.figsize':(9,7)})\nsns.distplot(dt['cholesterol']);","8e8bb927":"sns.set(rc={'figure.figsize':(9,7)})\nsns.distplot(dt['max_heart_rate_achieved']);","a40e5566":"sns.swarmplot(data=dt,x=\"target\", y=\"age\");","a2d34136":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(dataset2.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap","f0158a71":"dt1=pd.get_dummies(dt,drop_first=True)","0d0a2fe6":"dt1.head()","4aad2204":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(dt1.drop([\"target\"],axis = 1),),\n        columns=['age', 'resting_blood_pressure', 'cholesterol', 'max_heart_rate_achieved', 'st_depression',\n       'num_major_vessels', 'sex_male', 'chest_pain_type_atypical angina','chest_pain_type_non-anginal pain','chest_pain_type_typical angina','fasting_blood_sugar_lower than 120mg\/ml','rest_ecg_left ventricular hypertrophy','rest_ecg_normal','exercise_induced_angina_yes','st_slope_flat','st_slope_upsloping','thalassemia_fixed defect','thalassemia_normal','thalassemia_reversable defect'])","0fc30d9f":"y=dt['target']","1b94c19a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,stratify=y, random_state=5)","78ace9e2":"from sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression(random_state = 0)\nlogit.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = logit.predict(X_test)","3d4c6339":"from sklearn.model_selection import cross_val_score\nroc=roc_auc_score(y_test, y_pred)\naccuracies = cross_val_score(estimator = logit, X = X_test, y = y_test, cv = 10)\nacc = accuracies.mean()\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nresults = pd.DataFrame([['Base - Logistic Regression', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n\nresults","f847e951":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nrandom_forest = RandomForestClassifier(n_estimators=500,criterion='entropy',max_depth=5).fit(X_train, y_train)\ny_pred_random = random_forest.predict(X_test)","92b3743d":"roc=roc_auc_score(y_test, y_pred)\naccuracies = cross_val_score(estimator = random_forest, X = X_test, y = y_test, cv = 10)\nacc = accuracies.mean()\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults = results.append(model_results,sort=True)\nresults","90bf4764":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(random_forest, random_state=123).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X.columns.tolist(),top=24)","b68e1ad1":"from eli5 import explain_prediction\n\n\neli5.show_prediction(random_forest, X_test.iloc[50], \n                     feature_names=X_test.columns.tolist(), show_feature_values=True)","85528f21":"features = [c for c in X_test.columns]","7e61781f":"from pdpbox import pdp, get_dataset, info_plots\n\npdp_thal = pdp.pdp_isolate(model=random_forest, dataset=X_test, model_features=features, feature='thalassemia_reversable defect')\n\n# plot it\npdp.pdp_plot(pdp_thal, 'thalassemia_reversable defect')\n\nplt.show()","9460dc1a":"pdp_resting_bp = pdp.pdp_isolate(model=random_forest, dataset=X_test, model_features=features, feature='resting_blood_pressure')\n\n# plot it\npdp.pdp_plot(pdp_resting_bp, 'resting_blood_pressure')\n\nplt.show()","502a1dbe":"def plot_pdp(model, df, feature, cluster_flag=False, nb_clusters=None, lines_flag=False):\n    \n    # Create the data that we will plot\n    pdp_goals = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns.tolist(), feature=feature)\n\n    # plot it\n    pdp.pdp_plot(pdp_goals, feature, cluster=cluster_flag, n_cluster_centers=nb_clusters, plot_lines=lines_flag)\n    plt.show()","6a421efc":"plot_pdp(random_forest, X_train, 'thalassemia_reversable defect', cluster_flag=True, nb_clusters=24, lines_flag=True)","5e645f71":"plot_pdp(random_forest, X_train, 'resting_blood_pressure', cluster_flag=True, nb_clusters=24, lines_flag=True)","a9039b44":"plot_pdp(random_forest, X_train, 'age', cluster_flag=True, nb_clusters=24, lines_flag=True)","938514d2":"plot_pdp(random_forest, X_train, 'st_slope_flat', cluster_flag=True, nb_clusters=24, lines_flag=True)\n\n","c38406d7":"inter1  =  pdp.pdp_interact(model=random_forest, dataset=X_test, model_features=features, features=['thalassemia_reversable defect', 'resting_blood_pressure'])\n\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=['thalassemia_reversable defect', 'resting_blood_pressure'], plot_type='contour')\nplt.show()\n\n","5b412522":"inter1  =  pdp.pdp_interact(model=random_forest, dataset=X_test, model_features=features, features=['age', 'resting_blood_pressure'])\n\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=['age', 'resting_blood_pressure'], plot_type='contour')\nplt.show()","f8c71f0b":"inter1  =  pdp.pdp_interact(model=random_forest, dataset=X_test, model_features=features, features=['age', 'st_slope_flat'])\n\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=['age', 'st_slope_flat'], plot_type='contour')\nplt.show()","0aff1484":"fig, axes, summary_df = info_plots.actual_plot_interact(\n    model=random_forest, X=X_test, features=['age', 'thalassemia_reversable defect'], feature_names=['age', 'thalassemia_reversable defect']\n)","8da98f9f":"fig, axes, summary_df = info_plots.actual_plot_interact(\n    model=random_forest, X=X_test, features=['age', 'resting_blood_pressure'], feature_names=['age', 'resting_blood_pressure']\n)","578644cb":"row_to_show = 17\ndata_for_prediction = X_test.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\nrandom_forest.predict_proba(data_for_prediction_array)\n\nimport shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(random_forest)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)","3f43e477":"row_to_show = 9\ndata_for_prediction = X_test.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\nrandom_forest.predict_proba(data_for_prediction_array)\n\nimport shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(random_forest)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)","b6bf34d8":"explainer = shap.TreeExplainer(random_forest)\nshap_values = explainer.shap_values(X_test)\n\nshap.summary_plot(shap_values[1], X_test, plot_type=\"bar\")","066c31cf":"shap.summary_plot(shap_values[1], X_test)","c9a30913":"explainer = shap.TreeExplainer(random_forest)\n\n# calculate shap values. This is what we will plot.\nshap_values = explainer.shap_values(X_test)\n\n# make plot.\nshap.dependence_plot('chest_pain_type_non-anginal pain', shap_values[0], X_test, interaction_index=\"age\")","e046f094":"shap.dependence_plot('chest_pain_type_non-anginal pain', shap_values[0], X_test, interaction_index=\"resting_blood_pressure\")","7d138e36":"shap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1],plot_cmap=\"DrDb\")","218c8b77":"# extract a sample of the data\nsample_df = dt1.sample(frac=0.5, random_state=0)","09c44a47":"cv = KFold(n_splits=4, shuffle=False, random_state=0)","49ce2998":"# define the binary target and the features\ndataset = Dataset(df=sample_df, target=\"target\", features=[col for col in dt1.columns if col != 'target'])","4f28eed6":"# define the validation scheme and scorer. The default model is LightGBM\nlofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\")\n","58f51287":"# get the mean and standard deviation of the importances in pandas format\nimportance_df = lofo_imp.get_importance()","dbf039f7":"# plot the means and standard deviations of the importances\nplot_importance(importance_df, figsize=(12, 20))","1530102a":"!pip install alibi","e15bbdf1":"from alibi.explainers import AnchorTabular","71068c64":"predict_fn = lambda x: random_forest.predict_proba(x)","19d32ab6":"explainer = AnchorTabular(predict_fn, features)","0fdd3ae2":"explainer.fit(X_train.values, disc_perc=[25, 50, 75])","1bf86823":"class_names=['Healthy','Disease']\n\nidx = 3\nexplanation = explainer.explain(X_test.values[idx], threshold=0.95)\nprint('Anchor: %s' % (' AND '.join(explanation['names'])))\nprint('Precision: %.2f' % explanation['precision'])\nprint('Coverage: %.2f' % explanation['coverage'])","1bda8a7d":"idx = 19\nexplanation = explainer.explain(X_test.values[idx], threshold=0.95)\nprint('Anchor: %s' % (' AND '.join(explanation['names'])))\nprint('Precision: %.2f' % explanation['precision'])\nprint('Coverage: %.2f' % explanation['coverage'])","9ed102d9":"import lime\nimport lime.lime_tabular","db71a222":"explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=features, class_names=class_names, discretize_continuous=True)","74053fc3":"i = 12\n\nprint('Actual Label:', y_test[i])\nprint('Predicted Label:', y_pred[i])\n\nexp = explainer.explain_instance(X_test.iloc[i].values, random_forest.predict_proba).show_in_notebook()","f841c4c9":"!pip install git+https:\/\/github.com\/bondyra\/pyBreakDown.git","84f302de":"from pyBreakDown.explainer import Explainer\nfrom pyBreakDown.explanation import Explanation","ac342212":"#make explainer object\nexp = Explainer(clf=random_forest, data=X_train, colnames=features)","fe7f7204":"#make explanation object that contains all information\nexplanation = exp.explain(observation=X.iloc[302,:],direction=\"up\")","cb3990a3":"#get information in text form\nexplanation.text()","5a35dff5":"#customized text form\nexplanation.text(fwidth=40, contwidth=40, cumulwidth = 40, digits=4)","a9d65a9b":"explanation.visualize()","f57b9498":"#customize height, width and dpi of plot\nexplanation.visualize(figsize=(8,5),dpi=100)","636aa362":"explanation = exp.explain(observation=X.iloc[302,:],direction=\"up\",useIntercept=True)  # baseline==intercept\nexplanation.visualize(figsize=(8,5),dpi=100)","88469427":"## 2.b Univariate ICE plot\nICE plots are similar to PD plots but offer a more detailled view about the behavior of near similar clusters around the PD plot average curve. ICE algorithm gives the user insight into the several variants of conditional relationships estimated by the black box.","76644384":"# References\n1. [List of AWESOME Machine learning Libraries](https:\/\/github.com\/jphall663\/awesome-machine-learning-interpretability)\n\n2. [The Importance of Macine Learning Interpretability by Dipanjan Sarkar](https:\/\/towardsdatascience.com\/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476)\n\n3. [Interpretable Machine Learning by Christoph Molnar](https:\/\/christophm.github.io\/interpretable-ml-book\/)","453160fb":"## Interpretaions\nSHAP summary plot of a 19 feature Random Forest heart disease prediction. The higher the SHAP value of a feature, the higher is the  log odds of heart disease in this heart disease prediction model. Every patient in the dataset is run through the model and a dot is created for each feature attribution value, so one patient gets one dot on each feature\u2019s line. Dot\u2019s are colored by the feature\u2019s value for that patient and pile up vertically to show density. \nIn above plot we see that **chest pain type non anginal pain**  is the most important risk factor for heart disease patients. The lower values of **chest pain type non anginal pain** leads to heart disease, whereas in non heart disease patients its contribution is mixture of higher and lower values. Higher values of **thalasemia_fixed_defect** increases the risk of heart disease whereas its lower values decreases the chances of heart disease.\n","72a0c787":"# About Problem\nPreventing heart disease is important. Good data-driven systems for predicting heart disease can improve the entire research and prevention process, making sure that more people can live healthy lives.\n\nIn the United States, the Centers for Disease Control and Prevention is a good resource for information about heart disease. According to their [website](https:\/\/www.cdc.gov\/heartdisease\/facts.htm):\n\n* About 610,000 people die of heart disease in the United States every year\u2013that\u2019s 1 in every 4 deaths.\n* Heart disease is the leading cause of death for both men and women. More than half of the deaths due to heart disease in 2009 were in men.\n* Coronary heart disease (CHD) is the most common type of heart disease, killing over 370,000 people annually.\n* Every year about 735,000 Americans have a heart attack. Of these, 525,000 are a first heart attack and 210,000 happen in people who have already had a heart attack.\n* Heart disease is the leading cause of death for people of most ethnicities in the United States, including African Americans, Hispanics, and whites. For American Indians or Alaska Natives and Asians or Pacific Islanders, heart disease is second only to cancer.\n\nFor more information, you can look at the [website](https:\/\/www.cdc.gov\/heartdisease\/prevention.htm) of the Centers for Disease Control and Prevention: ","8bf5eacd":"# One hot encoding","6a68e4b2":"## SHAP Feature Importance Plot\nThe global mean(|Tree SHAP|) method applied to the heart disease prediction model. The x-axis is essentially the average magnitude change in model output when a feature is \u201chidden\u201d from the model (for this model the output has log-odds units). See [github repo](https:\/\/github.com\/slundberg\/shap) for details, but \u201chidden\u201d means integrating the variable out of the model. Since the impact of hiding a feature changes depending on what other features are also hidden, Shapley values are used to enforce consistency and accuracy.","66bdac89":"# Normalizing the data","70ca1f0c":"# Conclusion\nI have tried to implement and show the demo of really awesome machine learning explanation libraries. Some of the other great libraries which I didnt able to run on kaggle due to some dependency issuea are as follows :\n1. Microsoft's Interpret-ml\n2. Skater\n3. fairml\n4. Contrastive Explanation\n5. Skope Rules\n\nApart from that there are some other more intuitive libraries are there which can help interpret machine learning model and really assist medical practitioners in beleiving the black box model","71f37c3a":"### 2.a PDP Isolation plot","0bd88024":"# Model Building\nNow comes the most interesting part i.e., Model Building. In this step we will build different machine learning model starting from our base model which is logistic regression.","e122ef50":"From the above boxplots we have clearly seen the outliers","bc3de68e":"There are some outliers in case of cholestrol, resting bood pressure and max heart rate achieved.Further we can detect outliers using **boxplot**\n\n# Boxplot (Outlier Detection)","3376f3c3":"# Explaining Model\nIn this step we will try to explain the model by applying different techniques and algorithms such as \n\n1. [Permutation Importance (Eli5)](https:\/\/eli5.readthedocs.io\/en\/latest\/blackbox\/permutation_importance.html)<br>\n2. [Partial dependency plotting (pdpbox)](https:\/\/www.kaggle.com\/dansbecker\/partial-dependence-plots) <br>\n3. [SHapley Additive exPlanations (SHAP values)](https:\/\/shap.readthedocs.io\/en\/latest\/) <br>\n4. [LOFO Importance](https:\/\/github.com\/aerdem4\/lofo-importance) <br>\n5. [Alibi](https:\/\/github.com\/SeldonIO\/alibi) <br>\n6. [LIME](https:\/\/github.com\/marcotcr\/lime)<br>\n7. [pyBreakdown](https:\/\/github.com\/MI2DataLab\/pyBreakDown)","dcca7d60":"Here, we have converted all the categorical columns to numerical columns and keep the drop_first parameter to true to prevent from dummy variable trap.To read more about dummy variable trap visit this [blog](https:\/\/medium.com\/@saurav9786\/dummy-variable-trap-c6d4a387f10a). You can also read very good explanation of dummy variable trap from this quora question [here](https:\/\/www.quora.com\/When-do-I-fall-in-the-dummy-variable-trap)","f3012fb6":"# RandomForest\nA random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.Random Forest Classifier\n\nThe sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).","bac2f4f3":"Changing features into corresponding categories for better interpretation","57263be0":"Datatype of all the features seems relevant now check for missing entries.","685ab507":"![](https:\/\/i.ibb.co\/ypG4Cq3\/CVD-infographic-1.jpg)\n\n# About dataset\n\nThe dataset contains the following features:\n1. **age(in years)**\n2. **sex:** (1 = male; 0 = female)\n3. **cp:** chest pain type\n4. **trestbps:** resting blood pressure (in mm Hg on admission to the hospital)\n5. **chol:** serum cholestoral in mg\/dl\n6. **fbs:** (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n7. **restecg:** resting electrocardiographic results\n8. **thalach:** maximum heart rate achieved\n9. **exang:** exercise induced angina (1 = yes; 0 = no)\n10. **oldpeak:** ST depression induced by exercise relative to rest\n11. **slope:** the slope of the peak exercise ST segment\n12. **ca:** number of major vessels (0-3) colored by flourosopy\n13. **thal:** 0 = normal; 1 = fixed defect; 2 = reversable defect\n14. **target:** 1 or 0 \n\n# Problem Description\nour goal is to predict the binary class **target**, which represents whether or not a patient has heart disease:\n\n* **0** represents no heart disease present\n* **1** represents heart disease present","965cd1d1":"# Importing Essential Libraries","26a4760f":"## 6. LIME\n\n**Local Interpretable Model-agnostic Explanations (LIME)**. The overall goal of LIME is to identify an interpretable model over the interpretable representation that is locally faithful to the classifier.\n\nThe local explanation method LIME interprets an individual prediction by learning an interpretable model locally. The intuition behind LIME is that it samples instances both in the vicinity and far away from the interpretable representation of the original input. Then LIME takes the interpretable representation of these sample points, determines their predictions and builds a weighted linear model by minimizing the loss and complexity. The samples weighting is based on their distances from the original point. The points weights decrease as the points get farther away. The explanation is locally faithful, which means it represents the model prediction of vicinity instances.This is illustrated in below figure.\n\n![](https:\/\/i.ibb.co\/9Hxnb5g\/lime1.png)\n\nBy explaining a prediction\", we mean presenting textual or visual artifacts that provide qualitative understanding of the relationship between the instance\u2019s components (e.g. words in text, patches in an image) and the model\u2019s prediction. We argue that explaining predictions is an important aspect in getting humans to trust and use machine learning effectively, if the explanations are faithful and intelligible.\nThe process of explaining individual predictions is illustrated in Figure 1. It is clear that a doctor is much better positioned to make a decision with the help of a model if\nintelligible explanations are provided. In this case, an explanation is a small list of symptoms with relative weights {symptoms that either contribute to the prediction (in green) or are evidence against it (in red). Humans usually have prior knowledge about the application domain, which they can use to accept (trust) or reject a prediction if they understand the reasoning behind it.\n\n![](https:\/\/i.ibb.co\/Yc5jQhc\/LIME.png)","19a7db6a":"# Interpretations\nAbove plot shows the target plot under partial dependence library, here the bubble size is of less importance, since it pertains to the number of observations (times the incident occurred). The most important insight comes from the color of the bubble, with darker bubbles meaning higher probabilities of heart disease while lighter colors of bubble signifies healthy. This is a powerful tool to use since it has a deep insight on how much two variables of our choice affect the dependent variable","0a94da91":"## 2. Partial Dependence Plots (PDP)\nWhile permutation importance shows what variables most affect predictions, partial dependence plots show how a feature affects predictions.[Credit](https:\/\/www.kaggle.com\/dansbecker\/partial-plots).","70962fdd":"# Check for Missing Values","34986cab":"Since patients having no heart disease have 45% data & patients having heart disease have 55 % data. So, It seems to be a balanced dataset","07aceab5":"# Correlation plot","fd616b8a":"# Distplot","b43e456b":"## 7. pyBreakdown","0ab3a8a0":"It seems independent variables are not much correlated with one another.","630fa44d":"## 2.d Actual Prediction Plot","292a6ff0":"# Prepare Features & Targets\nFirst of all seperating the data into dependent(Feature) and independent(Target) variables.\n\n1. X==>>Feature\n2. y==>>Target","d522776c":"I have used Z-score normalization.\nZ-scores are linearly transformed data values having a mean of zero and a standard deviation of 1.\nZ-scores are also known as standardized scores; they are scores (or data values) that have been given a common standard.\n\nIf the population mean and population standard deviation are known, the standard score of a raw score x[1] is calculated as\n\n![zscore](https:\/\/i.ibb.co\/6wGCbbQ\/z-score-formula.jpg)","d9e28af1":"# Countplot\nIn this step we will check class distribution ","36a5d348":"## Interpretations\nThe above graph is generated when we applied SHAP algorithm on instance number 17 and 9 from our test set. In above plot, we predicted 0.80, whereas the base_value is 0.4517. Feature values causing increased predictions are in pink, and their visual size shows the magnitude of the feature's effect. Feature values decreasing the prediction are in blue. The biggest impact comes sex_male being 1.435, while chest_pain_type_non-anginal pain value has the effect of decreasing the prediction. ","e2437c0b":"## 3. SHapley Additive exPlanations (SHAP Values)","f06566a1":"changing the column names to have a clear understanding of features.","f4ed20a6":"# EDA","633b9a09":"## 1. Permutation Importance\n\neli5 provides a way to compute feature importances for any black-box estimator by measuring how score decreases when a feature is not available; the method is also known as **\u201cpermutation importance\u201d or \u201cMean Decrease Accuracy (MDA)\u201d**.\n","f279c11f":"## Summary Plot","127b025d":"## 4. LOFO Importance\n\nLOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\n\nLOFO first evaluates the performance of the model with all the input features included, then iteratively removes one feature at a time, retrains the model, and evaluates its performance on a validation set. The mean and standard deviation (across the folds) of the importance of each feature is then reported.\n\nIf a model is not passed as an argument to LOFO Importance, it will run LightGBM as a default model.\n\n### Advantages of LOFO Importance\nLOFO has several advantages compared to other importance types:\n\n1. It does not favor granular features<br>\n2. It generalises well to unseen test sets<br>\n3. It is model agnostic<br>\n4. It gives negative importance to features that hurt performance upon inclusion<br>","f6b07ff0":"**Stratify property in train test split**\nThis stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify.\nFor example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.","8b4edd4e":"Great !! There is no missing values in the dataset","78ecd397":"# Violin plot","64621d6e":"SHAP values can explain the output of any machine learning model but for complex ensemble models it can be slow. SHAP has c++ implementations supporting XGBoost, LightGBM, CatBoost, and scikit-learn tree models.\n\nSHAP (SHapley Additive exPlanations) assigns each feature an importance value for a particular prediction. Its novel components include: the identification of a new class of additive feature importance measures, and theoretical results showing there is a unique solution in this class with a set of desirable properties. Typically, SHAP values try to explain the output of a model (function) as a sum of the effects of each feature being introduced into a conditional expectation. Importantly, for non-linear functions the order in which features are introduced matters. The SHAP values result from averaging over all possible orderings. Proofs from game theory show this is the only possible consistent approach.\n\nAn intuitive way to understand the Shapley value is the following: The feature values enter a room in random order. All feature values in the room participate in the game (= contribute to the prediction). The Shapley value  \u03d5ij  is the average marginal contribution of feature value  xij  by joining whatever features already entered the room before, i.e.\n\n![](https:\/\/i.ibb.co\/m0dSM81\/shap1.png)\n\nThe following figure from the paper, [Consistent Individualized Feature Attribution for Tree Ensembles](https:\/\/arxiv.org\/pdf\/1802.03888.pdf) summarizes this in a nice way!\n\n![](https:\/\/i.ibb.co\/YZsYsjd\/shap2.png)","4d768d7c":"# Histogram of numrical features","9e451d53":"## 2.c. PDP Interact Plot","6ebfaddc":"## Interpretations\n\nTo make random forest predictions more interpretable, every prediction of the model can be presented as a sum of feature contributions (plus the bias), showing how the features lead to a particular prediction. In above plot, ELI5 does it by showing weights for each feature with their actual value depicting how influential it might have been in contributing to the final prediction decision across all trees. In the above individual prediction, the top 3 influential features seems to be, after the bias, the chest_pain_type_non-anginal pain, chest_pain_type_atypical angina and sex_male.","b4172283":"# Interpretations\nThe values towards the top which are slightly dark in color are the most important features, and those towards the bottom having lighter shade matter least. The first number in each row shows how much model performance decreased with a random shuffling (in this case, using \"accuracy\" as the performance metric).Measurement of randomness in permutation importance calculation is performed by repeating the process with multiple shuffles. The number after the \u00b1 measures how performance varied from one-reshuffling to the next. \n\nHere, thalassemia_reversable defect, resting_blood_pressure, thalassemia_fixed defect,chest_pain_type_atypical angina and st_slope_flat are top 5 important features.\n\n\n\nHere is how to calculate and show importances with the [eli5](https:\/\/eli5.readthedocs.io\/en\/latest\/) library:","51be8abe":"## 5. Alibi\nAlibi is an open source Python library aimed at machine learning model inspection and interpretation. The initial focus on the library is on black-box, instance based model explanations.\n\n## Method Used : Anchors\nThe anchor algorithm is based on the Anchors: [High-Precision Model-Agnostic Explanations](https:\/\/homes.cs.washington.edu\/~marcotcr\/aaai18.pdf) paper by Ribeiro et al. and builds on the [open source code](https:\/\/github.com\/marcotcr\/anchor) from the paper\u2019s first author.\n\nThe algorithm provides model-agnostic (black box) and human interpretable explanations suitable for classification models applied to images, text and tabular data. The idea behind anchors is to explain the behaviour of complex models with high-precision rules called anchors. These anchors are locally sufficient conditions to ensure a certain prediction with a high degree of confidence.\n\n### Goals\n\n1. Provide high quality reference implementations of black-box ML model explanation algorithms\n\n2. Define a consistent API for interpretable ML methods\n\n3. Support multiple use cases (e.g. tabular, text and image data classification, regression)\n\n4. Implement the latest model explanation, concept drift, algorithmic bias detection and other ML model monitoring and interpretation methods","f050800b":"# Train test Split","3eee764a":"## SHAP dependence plot"}}