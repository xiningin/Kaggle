{"cell_type":{"f2fcebfe":"code","d8f0a80a":"code","6371d3b2":"code","575fcc38":"code","161dd665":"code","9e5b5164":"code","9bd4150e":"code","33aaa014":"code","58d6373a":"code","f690053b":"code","52977450":"code","3f7c5d42":"code","ddfb1d19":"code","5b4dac09":"code","f686362c":"code","f79a6f01":"code","74443033":"code","daf3a9d0":"code","c1d619ee":"code","ea711817":"code","0c892f84":"code","9a857001":"code","dc97f0aa":"code","d241b3ec":"code","551312bd":"markdown"},"source":{"f2fcebfe":"# import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns","d8f0a80a":"# import scalling and clustering libraries.\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom yellowbrick.cluster import SilhouetteVisualizer","6371d3b2":"# to display all the commands result, otherwise it will display only the last command's results\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","575fcc38":"# to get rid of scientific notations\n\npd.options.display.float_format = '{:.2f}'.format","161dd665":"#set maximum columns and row to display in the output\npd.options.display.max_columns=100\npd.options.display.max_rows=100","9e5b5164":"# read the desired file\ndata = pd.read_csv(\"..\/input\/nyse\/fundamentals.csv\", index_col = 0, parse_dates=['Period Ending'])","9bd4150e":"# column cleansing\ndata.columns = data.columns.str.replace(\" \", \"_\")\ndata.columns = data.columns.str.replace(\"_&_\", \"_\")\ndata.columns = data.columns.str.replace(\"_\/_\", \"_\")\ndata.columns = data.columns.str.replace(\".\", \"\")\ndata.columns = data.columns.str.replace(\"-\", \"\")\ndata.columns = data.columns.str.replace(\"'\", \"\")\ndata.columns = data.columns.str.replace(\",\", \"\")\ndata.columns = data.columns.str.replace(\"\/\", \"_\")","33aaa014":"# data description and further removal of column with null values\ndata.shape\ndata.dropna(axis=1,inplace=True)\ndata.shape\ndata.head()","58d6373a":"# trying to divide the data into two parts\ndata.Gross_Profit.mean()\ndata[data.Gross_Profit >= data.Gross_Profit.mean()].shape\ndata[data.Gross_Profit <data.Gross_Profit.mean() ].shape\n\ndata['cluster_group'] = data['Gross_Profit'].apply(lambda x : 1 if x > data.Gross_Profit.mean() else 0)\n\ndata.head()\ndata.cluster_group.value_counts()","f690053b":"# seaborn baplot with 95% Confidende Interval\nsns.barplot('cluster_group', 'Gross_Profit', estimator = np.mean, data=data, ci=95)","52977450":"# distribution plot \nsns.distplot(data.Gross_Margin, rug=True)","3f7c5d42":"# aggregating the data\ndatagroup = data.groupby(\"Ticker_Symbol\")\nmean_dt = datagroup.aggregate('mean')\nmean_dt.reset_index(inplace=True)\nmean_dt.head()","ddfb1d19":"TopPerformer = mean_dt.sort_values(by = 'Gross_Profit', ascending=False).head(10)\n\nsns.barplot(x = 'Ticker_Symbol', y = 'Gross_Profit', data = TopPerformer)","5b4dac09":"data_remTick = data.copy() # Deep Copy\ndata_remTick.drop([\"Ticker_Symbol\",\"Period_Ending\"], axis=1, inplace=True)\ndata_remTick.head()\n","f686362c":"# removing and storing separately the custom column containing the binary values for two kinds of data\ny = data_remTick['cluster_group'].values\ndata_remTick.drop(columns = ['cluster_group'], inplace = True)","f79a6f01":"# scalling data\nss = StandardScaler()\nss.fit(data_remTick)\nX = ss.transform(data_remTick)\nX.shape","74443033":"# train and test data sets\nX_train, X_test, y_train, y_test = train_test_split( X,y, test_size = 0.25)\nX_train.shape\nX_test.shape\ny_train.shape\ny_test.shape","daf3a9d0":"# For skree ploting\nsse1 = []\nfor k in range(1,10):\n    km = KMeans(n_clusters = k)\n    km.fit(X_train)\n    sse1.append(km.inertia_)","c1d619ee":"# simple plot. For arriving at number of cluster.\nplt.plot(range(1,10), sse1, marker='*')","ea711817":"# applying KMeans algo with 2 clusters\nkm2 = KMeans(n_clusters = 2)\nkm2.fit(X_train)\nsilhouette_score(X_train, km2.labels_)","0c892f84":"# applying KMeans algo with 3 clusters\nkm1 = KMeans(n_clusters = 3)\nkm1.fit(X_train)\n#km1.cluster_centers_\n#km1.labels_\n#km1.inertia_\nsilhouette_score(X_train, km1.labels_) ","9a857001":"kmeans = KMeans(n_clusters=2)\npred_y = kmeans.fit(X)\nplt.scatter(X[:,0], X[:,1])\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red')\nplt.show()","dc97f0aa":"# predicting with 2 clusters\nclf = KMeans(n_clusters = 2)\nclf.fit(X_train)\ny_pred = clf.predict(X_test)\n#y_pred\nnp.sum(y_pred == y_test)\/y_test.size\n\n# a values of 0.78 suggests 78% correct predictions.","d241b3ec":"# Final Silhouette visualiztion \nvisualizer = SilhouetteVisualizer(clf, colors='yellowbrick')\nvisualizer.fit(X_train)        \nvisualizer.show() ","551312bd":"## Using the New York Stock Exhange data set hands on with clustering concepts.\n\n### Author: Lavesh Bhama\n"}}