{"cell_type":{"132e144b":"code","dc66d43e":"code","d47543da":"code","db14e04f":"code","ea4feeee":"code","92b20808":"code","c4aa43ff":"code","6aa61032":"code","c4f7e669":"code","19d2273c":"code","66470927":"markdown","c6640125":"markdown","b26022a9":"markdown","c44d98cf":"markdown","694f92f1":"markdown","9e5d6cdd":"markdown","90b7f25b":"markdown","5e5d0b66":"markdown","162d9936":"markdown","df1c8552":"markdown"},"source":{"132e144b":"from sklearn.datasets import load_breast_cancer\nbc = load_breast_cancer()\n\ndata = bc.data\ntarget = bc.target","dc66d43e":"print(data.shape)","d47543da":"import numpy as np\nprint(np.unique(target))","db14e04f":"# separando os dados em treino e teste\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n\n# treinando o modelo \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)","ea4feeee":"# predizendo os r\u00f3tulos com o modelo\ny_pred = knn.predict(X_test)\n\n\n\n# calculando a acur\u00e1cia sem scikit-learn\ncertos = 0\n\nfor idx, rotulo in enumerate(y_pred):\n    if rotulo == y_test[idx]:\n        certos += 1\n\nprint('Acur\u00e1cia:', certos\/y_pred.shape[0])\n\n\n\n# calculando a acur\u00e1cia de forma vetorizada\ncertos = np.sum(y_test == y_pred)\n\nprint('Acur\u00e1cia:', certos\/y_pred.shape[0])\n\n\n\n# avaliando o modelo com o scikit-learn\nfrom sklearn.metrics import accuracy_score\nprint('Acur\u00e1cia:', accuracy_score(y_test, y_pred))","92b20808":"# predizendo os r\u00f3tulos a partir do modelo\ny_pred = knn.predict(X_test)\n\n# vp = verdadeiros positivos\n# vn = verdadeiros negativos\n# fp = falsos positivos\n# fn = falsos negativos\n\nvp = 0\nvn = 0\nfp = 0\nfn = 0\n\nfor pred, true in zip(y_pred, y_test):\n    if pred == 1:\n        if pred == true:\n            vp += 1\n        else:\n            fp += 1\n    else:\n        if pred == true:\n            vn += 1\n        else:\n            fn += 1\n\nprint('VP:', vp)\nprint('FP:', fp)\nprint('VN:', vn)\nprint('FN:', fn)\n\nprint('---')\n\n# calculando a matriz utilizando scikit-learn\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\n\nprint('---')\n\n# obtendo os resultados com scikit-learn\nvn, fp, fn, vp = confusion_matrix(y_test, y_pred).ravel()\nprint('VP:', vp)\nprint('FP:', fp)\nprint('VN:', vn)\nprint('FN:', fn)","c4aa43ff":"#ACC = (VP+VN) \/ TOTAL\n#P = VP \/ (VP + FP)\n#R = VP \/ (VP + FN) \n#F = 2 * (P * R \/ (P + R))\n\ndef precisao(vp, fp):\n    return vp \/ (vp + fp)\n\ndef revocacao(vp, fn):\n    return vp \/ (vp + fn)\n\ndef fmedida(vp, fp, fn):\n    p = precisao(vp, fp)\n    r = revocacao(vp, fn)\n    return 2 * (p * r \/ (p + r))\n\nfmedida(vp, fp, fn)","6aa61032":"def medidas(vn, fp, fn, vp):\n\n    ACC = (vp+vn) \/ (vn + fp + fn + vp)\n    P = vp \/ (vp + fp)\n    R = vp \/ (vp + fn)\n    F = 2 * (P * R \/ (P + R))\n    \n    print(\"ACC: \" + str(ACC))\n    print(\"P: \" + str(P))\n    print(\"R: \" + str(R))\n    print(\"F: \" + str(F))\n    \n    return R\n\nmedidas(vn, fp, fn, vp)","c4f7e669":"# separando os dados em treino e teste\n# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n\n# treinando o modelo \n# from sklearn.neighbors import KNeighborsClassifier\n\nk_range = range(1, 10)\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n    \n    knn.fit(X_train, y_train)\n    \n    y_pred = knn.predict(X_test)\n    \n    ","19d2273c":"k_range = range(1, 51)\n\nrevocacoes = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, shuffle=True, random_state=42)\n\n    knn.fit(X_train, y_train)\n\n    #Predict testing set\n    y_pred = knn.predict(X_test)\n    \n    #Check performance using accuracy\n    scores.append({'k': k, 'accuracy': accuracy_score(y_test, y_pred)})\n\n    vn, fp, fn, vp = confusion_matrix(y_test, y_pred).ravel()\n#     print('K:', k)\n#     print('VP:', vp)\n#     print('FP:', fp)\n#     print('VN:', vn)\n#     print('FN:', fn)\n#     print('-Resultados:')\n#     medidas(vn, fp, fn, vp)\n    \n    revocacoes.append({\"R\": revocacao(vp, fn), \"K\": k})\n        \n#     print('\\n\\n------------')\n    \nprint('revocacoes', revocacoes)\n\nmaxR = max(revocacoes, key=lambda x:x['R'])\nminR = min(revocacoes, key=lambda x:x['R'])\nprint('\\n-----')\nprint('maxR', maxR)\nprint('minR', minR)","66470927":"A partir dos resultados \u00e9 poss\u00edvel perceber que o n\u00famero de verdadeiros positivos e negativos \u00e9 maior do que as ocorr\u00eancias de falsos. Isso \u00e9 um resultado bom para o modelo. As informa\u00e7\u00f5es dos erros, ou falsos positivos e negativos, ajuda a monitorar como o modelo erra e qual classe ele mais confunde. Em cima disso, decis\u00f5es podem ser tomadas. Por exemplo, pode-se optar por um modelo que erra mais uma classe do que outra, como em problemas com classes cr\u00edticas.\n\nNo problema abordado nesse notebook, do c\u00e2ncer de mama, existe uma classe cr\u00edtica. \u00c9 prefer\u00edvel um modelo que tenha taxa maior de falsos positivos ou falsos negativos? Certamente que os falsos negativos s\u00e3o mais prejudiciais (um laudo que d\u00e1 resultado negativo para uma pessoa que tem c\u00e2ncer). Uma forma de analisar a qualidade desse modelo considerando a classe cr\u00edtica \u00e9 atrav\u00e9s da revoca\u00e7\u00e3o.\n\nA revoca\u00e7\u00e3o encontra a rela\u00e7\u00e3o de todos verdadeiros positivos com os verdadeiros positivos e falsos negativos. Quanto menos falsos negativos um modelo tiver de resultado, maior ser\u00e1 a revoca\u00e7\u00e3o. No entanto, deve-se tomar cuidado com uma revoca\u00e7\u00e3o muito alta que gera um modelo in\u00fatil. Por exemplo, um modelo que classifica tudo como positivo sempre.","c6640125":"(1) Seguindo a f\u00f3rmula dos slides, calcule as medidas de precis\u00e3o, revoca\u00e7\u00e3o e f-medida utilizando as informa\u00e7\u00f5es da matriz de confus\u00e3o. Se preferir, crie uma fun\u00e7\u00e3o para isso, pois ser\u00e1 \u00fatil para o exerc\u00edcio seguinte.","b26022a9":"# Exerc\u00edcios","c44d98cf":"(2) Utilizando o conjunto de dados do c\u00e2ncer de mama, avalie os resultados obtidos no teste (em vez do treino, como foi feito at\u00e9 aqui) e verifique se consegue encontrar algum modelo melhor, considerando o conceito de revoca\u00e7\u00e3o, variando os par\u00e2metros do KNN.","694f92f1":"Ap\u00f3s o treinamento, as m\u00e9tricas de desempenho s\u00e3o obtidas ao analisar amostra por amostra a rela\u00e7\u00e3o entre o r\u00f3tulo conhecido (y_train ou y_test) e o r\u00f3tulo informado (y_pred) pelo m\u00e9todo de classifica\u00e7\u00e3o. Para identificar a acur\u00e1cia, basta encontrar a rela\u00e7\u00e3o de r\u00f3tulos corretamente predizidos.","9e5d6cdd":"Algumas informa\u00e7\u00f5es a mais sobre o desempenho do modelo podem ser extra\u00eddas da matriz de confus\u00e3o, que tra\u00e7a a rela\u00e7\u00e3o mais precisa dos erros do modelo. Assim, em vez de simplesmente observar quando um r\u00f3tulo foi corretamente predizido, registra-se tamb\u00e9m quando houve erros e quais classes foram mais confundidas. \n\n\nA matriz de confus\u00e3o \u00e9 criada a partir da rela\u00e7\u00e3o entre os r\u00f3tulos de refer\u00eancias e os r\u00f3tulos dados pelo modelo. Um problema de classifica\u00e7\u00e3o bin\u00e1rio, portanto, ter\u00e1 informa\u00e7\u00f5es a respeito das amostras rotuladas corretamente (verdadeiros positivos e negativos) e das amostras que confundiram o modelo (falsos positivos e negativos).","90b7f25b":"Inicialmente, \u00e9 necess\u00e1rio criar uma divis\u00e3o dos dados em treino e teste para analisar o desempenho de algum m\u00e9todo de classifica\u00e7\u00e3o atrav\u00e9s de alguma m\u00e9trica. Para isso, considere a divis\u00e3o de 33% para teste e o m\u00e9todo de classifica\u00e7\u00e3o k-NN.","5e5d0b66":"## M\u00e9tricas de desempenho\n\nAs m\u00e9tricas de desempenho auxiliam a entender como um determinado se comporta ao identificar padr\u00f5es de um conjunto de dados. Nem sempre identificar apenas a acur\u00e1cia de um problema \u00e9 suficiente. Muitas vezes \u00e9 necess\u00e1rio identificar se a classe cr\u00edtica de um problema (quando houver) est\u00e1 sendo considerada na escolha de um modelo.","162d9936":"Para conhecimento, depois considere pesquisar a fun\u00e7\u00e3o **classification_report** do Scikit-Learn.","df1c8552":"Utilizando o conjunto de dados de c\u00e2ncer de mama, o objetivo deste notebook \u00e9 avaliar as m\u00e9tricas de desempenho."}}