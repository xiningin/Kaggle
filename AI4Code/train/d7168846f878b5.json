{"cell_type":{"b77535c6":"code","825c4bf4":"code","cad0eccb":"code","5ed29628":"code","f92e6116":"code","fa8ee575":"code","8c99ba32":"code","2725cac6":"code","ec9f6555":"code","08103a68":"code","5528fdd0":"code","01fa5dd2":"code","6e0b9feb":"code","6228d094":"code","bc8ef1b8":"code","847eae84":"code","a95a37dd":"code","da740691":"code","d815b560":"code","0f5b7904":"code","804635c5":"code","99659366":"code","d430bcfd":"code","dd24bb49":"code","d8304136":"code","c064c5bc":"code","896b3a15":"code","7fe34607":"code","74fbb1b8":"code","a7a4cb3b":"code","92c6c824":"code","9e775b1a":"code","eb87beaf":"code","99839205":"code","dcc6d2e9":"code","88c19f07":"code","693b30d9":"code","38eb4298":"code","3e164c8a":"code","ef7d0dea":"markdown","e7b542c7":"markdown","9bbe4f12":"markdown","cb68b7c0":"markdown","deef6dbf":"markdown","e7d4daa0":"markdown","3172e979":"markdown","eadd0ac2":"markdown","1c6106cf":"markdown","a9f5d3e2":"markdown"},"source":{"b77535c6":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","825c4bf4":"data = pd.read_csv(r\"\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv\")\ndata.info()","cad0eccb":"data.describe()","5ed29628":"data.columns","f92e6116":"data.isnull().sum()","fa8ee575":"print(data[\"race\/ethnicity\"].value_counts())\nlabels = 'Group A', 'Group B','Group C','Group D', \"Group E\"\nsizes = [89,190,319,262,140]\ncolors = ['skyblue','brown','green','purple','gold']\nexplode = (0, 0,0,0,0)\nfig1, ax1 = plt.subplots(figsize =(10,10))\nax1.pie(sizes,colors = colors ,explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Race \/ Ethnicity\")\nplt.show()","8c99ba32":"print(data[\"parental level of education\"].value_counts())\nlabels = 'Some College', 'Associates Degree','High School ','Some High School', \"Bachelor's Degree\",\"Master's Degree \"\nsizes = [226,222,196,179,118,59]\ncolors = [\"red\",\"green\",\"gold\",\"blue\",\"pink\",\"cyan\"]\nexplode = (0, 0,0,0,0,0)\nfig1, ax1 = plt.subplots(figsize =(10,10))\nax1.pie(sizes,colors = colors ,explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Parentel Level of Education\")\nplt.show()","2725cac6":"print(data[\"lunch\"].value_counts())\nlabels = \"Standard\",\"Free \/ Reduced\"\nsizes = [645,355]\ncolors = [\"silver\",\"firebrick\"]\nexplode = (0, 0)\nfig1, ax1 = plt.subplots(figsize =(10,10))\nax1.pie(sizes,colors = colors ,explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Lunch\")\nplt.show()","ec9f6555":"print(data[\"test preparation course\"].value_counts())\nlabels = \"None\",\"Completed\"\nsizes = [642,358]\ncolors = [\"orchid\",\"powderblue\"]\nexplode = (0, 0)\nfig1, ax1 = plt.subplots(figsize =(10,10))\nax1.pie(sizes,colors = colors ,explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Test Preparation Course\")\nplt.show()","08103a68":"fig1, ax1 = plt.subplots(figsize =(10,10))\nplt.hist(data[\"math score\"], bins=80,color = \"darkorange\")\nplt.xlabel(\"Math Score\")\nplt.ylabel(\"Frequency\")\nplt.grid()\nplt.show()","5528fdd0":"fig1, ax1 = plt.subplots(figsize =(10,10))\nplt.hist(data[\"reading score\"], bins=80,color = \"rosybrown\")\nplt.xlabel(\"Reading Score\")\nplt.ylabel(\"Frequency\")\nplt.grid()\nplt.show()","01fa5dd2":"fig1, ax1 = plt.subplots(figsize =(10,10))\nplt.hist(data[\"writing score\"], bins=80,color = \"coral\")\nplt.xlabel(\"Writing Score\")\nplt.ylabel(\"Frequency\")\nplt.grid()\nplt.show()","6e0b9feb":"df = pd.DataFrame(data,columns=[\"math score\",\"reading score\",\"writing score\"])\nf, ax = plt.subplots(figsize =(10,10))\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","6228d094":"sns.violinplot(data=data, x=\"race\/ethnicity\", y=\"math score\",hue = \"gender\",\n               split=True, inner=\"quart\", linewidth=1,)\nsns.despine(left=True)\nplt.show()","bc8ef1b8":"sns.violinplot(data=data, x=\"race\/ethnicity\", y=\"reading score\",hue = \"gender\",\n               split=True, inner=\"quart\", linewidth=1,)\nsns.despine(left=True)\nplt.show()","847eae84":"sns.violinplot(data=data, x=\"race\/ethnicity\", y=\"writing score\",hue = \"gender\",\n               split=True, inner=\"quart\", linewidth=1,)\nsns.despine(left=True)\nplt.show()","a95a37dd":"g = sns.catplot(\n    data=data, kind=\"bar\",\n    x=\"math score\", y=\"lunch\", hue=\"gender\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6,\n)\ng.despine(left=True)\ng.set_axis_labels(\"Math Score\", \"Lunch\")\nplt.grid()\nplt.show()","da740691":"g = sns.catplot(\n    data=data, kind=\"bar\",\n    x=\"reading score\", y=\"lunch\", hue=\"gender\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6,\n)\ng.despine(left=True)\ng.set_axis_labels(\"Reading Score\", \"Lunch\")\nplt.grid()\nplt.show()","d815b560":"g = sns.catplot(\n    data=data, kind=\"bar\",\n    x=\"writing score\", y=\"lunch\", hue=\"gender\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6,\n)\ng.despine(left=True)\ng.set_axis_labels(\"Writing Score\", \"Lunch\")\nplt.grid()\nplt.show()","0f5b7904":"g = sns.jointplot(\n    data=data,\n    x=\"reading score\", y=\"writing score\", \n    kind=\"kde\",\n)\nplt.show()","804635c5":"g = sns.jointplot(\n    data=data,\n    x=\"reading score\", y=\"math score\", \n    kind=\"kde\",\n)\nplt.show()","99659366":"g = sns.jointplot(\n    data=data,\n    x=\"math score\", y=\"writing score\", \n    kind=\"kde\",\n)\nplt.show()","d430bcfd":"data.gender = [1 if each == \"female\" else 0 for each in data.gender]\ndata.gender.value_counts()","dd24bb49":"y = data.gender\ndata.drop([\"gender\"],axis = 1 , inplace = True)\ndata.columns","d8304136":"data = pd.get_dummies(data,columns = [\"race\/ethnicity\",\"lunch\",\"parental level of education\",\n                                      \"test preparation course\"])\ndata.info()","c064c5bc":"x = data.astype(int)\nx\n","896b3a15":"x= (data-np.min(data)) \/ (np.max(data)-np.min(data))","7fe34607":"x","74fbb1b8":"from sklearn.model_selection import train_test_split\nx_train , x_test , y_train, y_test = train_test_split(x,y,test_size = 0.2 , random_state = 42)","a7a4cb3b":"from sklearn.svm import SVC\nsvm1 = SVC(gamma = 0.01 , C = 500 , kernel = \"rbf\")\nsvm1.fit(x_train,y_train)\nsvm1_score = svm1.score(x_test,y_test)\nprint(\"SVM Max Score = : \", svm1_score)","92c6c824":"y_pred = svm1.predict(x_test)\ny_true = y_test\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(8,8))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","9e775b1a":"knn_list = []\nfrom sklearn.neighbors import KNeighborsClassifier\nfor each in range(1,100):\n    knn1 = KNeighborsClassifier(n_neighbors = each,weights = \"uniform\",metric = \"euclidean\" )\n    knn1.fit(x_train,y_train)\n    knn1_score = knn1.score(x_test,y_test)\n    knn_list.append(knn1_score)\nknn_max = np.max(knn_list)\nprint(\"KNN Max Score = \",knn_max)","eb87beaf":"y_pred2 = knn1.predict(x_test)\ny_true2 = y_test\nfrom sklearn.metrics import confusion_matrix\ncm2 = confusion_matrix(y_true2,y_pred2)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(8,8))\nsns.heatmap(cm2,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","99839205":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(C = 10.0, penalty = \"l2\")\nlr.fit(x_train,y_train)\nprint(\"Logistic Regression Max Score : \",lr.score(x_test,y_test))\nlr_max = lr.score(x_test,y_test)","dcc6d2e9":"y_pred3 = lr.predict(x_test)\ny_true3 = y_test\nfrom sklearn.metrics import confusion_matrix\ncm3 = confusion_matrix(y_true3,y_pred3)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(8,8))\nsns.heatmap(cm3,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","88c19f07":"score_list = []\nfrom sklearn.ensemble import RandomForestClassifier\nfor each in range (1,100):\n    rf = RandomForestClassifier(n_estimators = each,random_state = 7,bootstrap = \"False\",criterion=\"gini\",\n                                    min_samples_split = 10 , min_samples_leaf = 1)\n    rf.fit(x_train,y_train)\n    score_list.append(rf.score(x_test,y_test))\n    \nrf_max = np.max(score_list)\nprint(\"RF Max Score : \",rf_max)","693b30d9":"y_pred4 = rf.predict(x_test)\ny_true4 = y_test\nfrom sklearn.metrics import confusion_matrix\ncm4 = confusion_matrix(y_true4,y_pred4)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(8,8))\nsns.heatmap(cm4,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()\n","38eb4298":"results = {\"Support Vector Machine \" : svm1_score,\n          \"Logistic Regression\" : lr_max,\n          \"Random Forest Classifier\" : rf_max,\n          \"K-Nearest Neighbor\" : knn_max\n          }","3e164c8a":"results","ef7d0dea":"<a id = \"8\"><\/a>\n<font color ='gold'>\n# 4.4 Random Forest Classifier","e7b542c7":"<a id = \"5\"><\/a>\n<font color ='gold'>\n# 4.1 Support Vector Machine","9bbe4f12":"<a id = \"2\"><\/a>\n<font color ='gold'>\n# 2. Visualizing Data","cb68b7c0":"<font color ='brown'>\n    \nContent :\n    \n1. [Load and Check Data](#1) \n    \n2. [Visualizing Data](#2)    \n    \n3. [Feature Engineering](#3)    \n    \n4. [Prediction](#4)                \n    4.1 [Support Vector Machine](#5)          \n    4.2 [K-Nearest Neighbor](#6)          \n    4.3 [Logistic Regression](#7)           \n    4.4 [Random Forest Classifier](#8)\n        \n5. [Results](#9)    \n    ","deef6dbf":"<a id = \"4\"><\/a>\n<font color ='gold'>\n# 4. Prediction","e7d4daa0":"<a id = \"3\"><\/a>\n<font color ='gold'>\n# 3. Feature Engineering","3172e979":"<a id = \"9\"><\/a>\n<font color ='red'>\n# 5. RESULTS","eadd0ac2":"<a id = \"1\"><\/a>\n<font color ='gold'>\n# 1. Load and Check Data","1c6106cf":"<a id = \"7\"><\/a>\n<font color ='gold'>\n# 4.3 Logistic Regression","a9f5d3e2":"<a id = \"6\"><\/a>\n<font color ='gold'>\n# 4.2 K-Nearest Neighbor"}}