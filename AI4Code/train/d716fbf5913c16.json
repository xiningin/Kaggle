{"cell_type":{"75b6f1d4":"code","21a0aa9c":"code","2e25512e":"code","275a6a63":"code","f99f447f":"code","b4b5cc18":"code","4d740f19":"code","066defd7":"code","dec6bb87":"code","698f1dc8":"code","3a4c635a":"code","9779b040":"code","bc53918f":"code","2704d2d1":"code","00772fe4":"code","c0d30e49":"code","47d9cebc":"code","64ac63db":"code","ca7100be":"code","9709e419":"code","39c4a706":"code","aeed03c1":"code","f8994848":"code","f7cadcb2":"code","6a079f92":"code","2f51b734":"code","ef43e354":"code","9ee09960":"code","e70845fe":"code","b5dca7ca":"code","450dca41":"code","3d2f3ea3":"code","e19e5ba1":"code","f8abf8b4":"code","18f8e527":"code","4cbabf0f":"code","1cf0e573":"code","f8b1a600":"markdown","befe2378":"markdown","05357afd":"markdown","91b0d21e":"markdown","6b9abbd1":"markdown","0321a834":"markdown","685db3c9":"markdown","e619efe6":"markdown","6877ac6e":"markdown","87e95804":"markdown","dda4d2d7":"markdown","a34dcbcc":"markdown","8e45127f":"markdown","d19e4f8a":"markdown","a3f81985":"markdown","9648c2df":"markdown","de002f35":"markdown","0677d2e3":"markdown","6dcbd3cf":"markdown","a7ff2ca9":"markdown","4b0cb0de":"markdown","ab546c68":"markdown","d9db9203":"markdown","ec6ea75c":"markdown","061ae07f":"markdown","31ea74ce":"markdown","3c403223":"markdown","80548d97":"markdown","4181fa26":"markdown","40a343a0":"markdown","ba387942":"markdown","f9f96a4b":"markdown","5fc158a9":"markdown","74d93d5a":"markdown","a46aff8d":"markdown","12638f65":"markdown","80718ba5":"markdown"},"source":{"75b6f1d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","21a0aa9c":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# loading packages\n# basic + dates \nimport numpy as np\nimport pandas as pd\nfrom pandas import datetime\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns # advanced vizs\n%matplotlib inline\n\n# statistics\n#https:\/\/towardsdatascience.com\/what-why-and-how-to-read-empirical-cdf-123e2b922480\nfrom statsmodels.distributions.empirical_distribution import ECDF\n\n# time series analysis\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n# prophet by Facebook\nfrom fbprophet import Prophet","2e25512e":"# importing train data to learn\ntrain = pd.read_csv(\"..\/input\/rossmann-store-sales\/train.csv\", \n                    parse_dates = True, low_memory = False, index_col = 'Date')\n\n# additional store data\nstore = pd.read_csv(\"..\/input\/rossmann-store-sales\/store.csv\", \n                    low_memory = False)\n# time series as indexes\ntrain.index","275a6a63":"print(train.shape)\ntrain.head()","f99f447f":"# data extraction\ntrain['Year'] = train.index.year\ntrain['Month'] = train.index.month\ntrain['Day'] = train.index.day\ntrain['WeekOfYear'] = train.index.weekofyear\n\n# adding new variable\ntrain['SalePerCustomer'] = train['Sales']\/train['Customers']\ntrain['SalePerCustomer'].describe()","b4b5cc18":"sns.set(style = \"ticks\")# to format into seaborn \nc = '#386B7F' # basic color for plots\nplt.figure(figsize = (12, 6))\n\nplt.subplot(311)\ncdf = ECDF(train['Sales'])\nplt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\nplt.xlabel('Sales'); plt.ylabel('ECDF');\n\n# plot second ECDF  \nplt.subplot(312)\ncdf = ECDF(train['Customers'])\nplt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\nplt.xlabel('Customers');\n\n# plot second ECDF  \nplt.subplot(313)\ncdf = ECDF(train['SalePerCustomer'])\nplt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\nplt.xlabel('Sale per Customer');","4d740f19":"# closed stores\ntrain[(train.Open == 0) & (train.Sales == 0)].head()","066defd7":"train[(train.Open==0)].shape","dec6bb87":"# opened stores with zero sales\nzero_sales = train[(train.Open != 0) & (train.Sales == 0)]\nprint(\"In total: \", zero_sales.shape)\nzero_sales.head(5)","698f1dc8":"print(\"Closed stores and days which didn't have any sales won't be counted into the forecasts.\")\ntrain = train[(train[\"Open\"] != 0) & (train['Sales'] != 0)]\n\nprint(\"In total: \", train.shape)","3a4c635a":"# additional information about the stores\nstore.head()","9779b040":"#missing values\nstore.isnull().sum()","bc53918f":"# missing values in copetitin distance \nstore[pd.isnull(store.CompetitionDistance)]","2704d2d1":"# fill NaN with a median value (skewed distribuion)\nstore['CompetitionDistance'].fillna(store['CompetitionDistance'].median(), inplace = True)","00772fe4":"store[pd.isnull(store.Promo2SinceWeek)]\n","c0d30e49":"# filling NAN value with zero \nstore.fillna(0, inplace = True)","47d9cebc":"print(\"Joining train set with an additional store information.\")\n\n# by specifying inner join we make sure that only those observations \n# that are present in both train and store sets are merged together\ntrain_store = pd.merge(train, store, how = 'inner', on = 'Store')\n\nprint(\"In total: \", train_store.shape)\ntrain_store.head()","64ac63db":"train_store.groupby('StoreType')['Sales'].describe()","ca7100be":"train_store.groupby('StoreType')['Customers', 'Sales'].sum()","9709e419":"# sales trends\nsns.factorplot(data = train_store, x = 'Month', y = \"Sales\", \n               palette = 'plasma',\n               row = 'Promo',\n               hue = 'StoreType',\n               color = c)","39c4a706":"# sales trends\nsns.factorplot(data = train_store, x = 'Month', y = \"Customers\", \n               palette = 'plasma',\n               col = 'Promo',\n               hue = 'StoreType',\n               color = c) ","aeed03c1":"# sale per customer trends\nsns.factorplot(data = train_store, x = 'Month', y = \"SalePerCustomer\", \n               palette = 'plasma',\n               hue = 'StoreType',\n               col = 'Promo', # per promo in the store in rows\n               color = c) ","f8994848":"# stores which are opened on Sundays\ntrain_store[(train_store.Open == 1) & (train_store.DayOfWeek == 7)]['Store'].unique()","f7cadcb2":" #competition open time (in months)\ntrain_store['CompetitionOpen'] = 12 * (train_store.Year - train_store.CompetitionOpenSinceYear) + (train_store.Month - train_store.CompetitionOpenSinceMonth)\n# Promo open time\n# to convert weeks into momths we divided by 4\ntrain_store['PromoOpen'] = 12 * (train_store.Year - train_store.Promo2SinceYear) +(train_store.WeekOfYear - train_store.Promo2SinceWeek) \/ 4.0\n# replace NA's by 0\ntrain_store.fillna(0, inplace = True)\n# average PromoOpen time and CompetitionOpen time per store type\ntrain_store.loc[:, ['StoreType', 'Sales', 'Customers', 'PromoOpen', 'CompetitionOpen']].groupby('StoreType').mean()","6a079f92":"import seaborn as sns\n# Compute the correlation matrix \n# exclude 'Open' variable\ncorr_all = train_store.drop('Open', axis = 1).corr()\n\n # Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr_all, square = True, linewidths = .5, cmap = \"BuPu\")      \nplt.show()","2f51b734":"# sale per customer trends\nsns.factorplot(data = train_store, x = 'DayOfWeek', y = \"Sales\", \n               col = 'Promo',\n               hue = 'Promo2',\n               palette = 'copper_r') ","ef43e354":"train['Sales']","9ee09960":"sales_a = train[train.Store == 2]['Sales']\nsales_a.describe()\n#sales_a.resample('W').sum().plot(color = c)","e70845fe":"! ls ..\/input\/rossmann-store-sales","b5dca7ca":"# importing data\ndf = pd.read_csv(\"..\/input\/rossmann-store-sales\/train.csv\")\n\n# remove closed stores and those with no sales\ndf = df[(df[\"Open\"] != 0) & (df['Sales'] != 0)]\n\n# sales for the store number 1 (StoreType C)\nsales = df[df.Store == 1].loc[:, ['Date', 'Sales']]\n\n# reverse to the order: from 2013 to 2015\nsales = sales.sort_index(ascending = False)\n\n# to datetime64\nsales['Date'] = pd.DatetimeIndex(sales['Date'])\nsales.dtypes","450dca41":"# from the prophet documentation every variables should have specific names\nsales = sales.rename(columns = {'Date': 'ds',\n                                'Sales': 'y'})\nsales.head()","3d2f3ea3":"# plot daily sales\nax = sales.set_index('ds').plot(figsize = (12, 4), color = c)\nax.set_ylabel('Daily Number of Sales')\nax.set_xlabel('Date')\nplt.show()","e19e5ba1":"# set the uncertainty interval to 95% (the Prophet default is 80%)\nmy_model = Prophet(interval_width = 0.95)\nmy_model.fit(sales)\n\n# dataframe that extends into future 6 weeks \nfuture_dates = my_model.make_future_dataframe(periods = 6*7)\n\nprint(\"First week to forecast.\")\nfuture_dates.tail(7)","f8abf8b4":"# predictions\nforecast = my_model.predict(future_dates)\n\n# preditions for last week\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)","18f8e527":"fc = forecast[['ds', 'yhat']].rename(columns = {'Date': 'ds', 'Forecast': 'yhat'})","4cbabf0f":"# visualizing predicions\nmy_model.plot(forecast);","1cf0e573":"my_model.plot_components(forecast);","f8b1a600":"The highest SalePerCustomer amount is observed at the StoreType D, about 12\u20ac with Promo and 10\u20ac without. As for StoreType A and C it is about 9\u20ac.","befe2378":"from observation we find that no sales on working day ,may be due to exhibition ","05357afd":"**Time series analysis using prophet**","91b0d21e":"**Importing the librabries**","6b9abbd1":"We have few variables with missing values that we need to deal with. Let's start with the \n\n**CompetitionDistance.**","0321a834":"**we can see that Sales escalate towards Christmas holidays**","685db3c9":"StoreType D goes on the second place in both Sales and Customers.","e619efe6":"**Sales Trend**","6877ac6e":"we have a strong positive correlation between the amount of Sales and Customers of a store. \n\nWe can also observe a positive correlation between the fact that the store had a running promotion (Promo equal to 1) and amount of Customers.","87e95804":"**Amnalysis on store information **","dda4d2d7":"**Correlation**","a34dcbcc":"**Time-Series Analysis per Store Type**","8e45127f":"As we see Prophet catches the trends and most of the time gets future values right.\n\nOne other particularly strong feature of Prophet is its ability to return the components of our forecasts. This can help reveal how daily, weekly and yearly patterns of the time series.","d19e4f8a":"**Exploratory Data Analysis**","a3f81985":"There're 172817 closed stores in the data. It is about 10% of the total amount of observations. To avoid any biased forecasts we will drop these values.","9648c2df":"All store types follow the same trend but at different scales depending on the presence of the (first) promotion Promo and StoreType itself (case for B).","de002f35":"Store: a unique Id for each store\n\nStoreType: differentiates between 4 different store models: a, b, c, d\n\nAssortment: describes an assortment level: a = basic, b = extra, c = extended\n\nCompetitionDistance: distance in meters to the nearest competitor store\n\nCompetitionOpenSince[Month\/Year]: gives the approximate year and month of the time the nearest competitor was opened\n\nPromo2: Promo2 is a continuing a promotion for some stores: 0 = store is not participating, 1 = store is participating\n\nPromo2Since[Year\/Week]: describes the year and calendar week when the store started participating in Promo2\n\nPromoInterval: describes the consecutive intervals Promo2 is started, naming the months the promotion is started. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store","0677d2e3":"No Particular observation found ,hence replacing NAN values with median ","6dcbd3cf":"The most selling and crowded StoreType A doesn't appear to be the one the most exposed to competitors. Instead it's a StoreType B, which also has the longest running period of promotion","a7ff2ca9":"**What makes a time series different from a regular regression problem?**\n\nIt is time dependent. The basic assumption of a linear regression that the observations are independent doesn\u2019t hold in this case.\nAlong with an increasing or decreasing trend, most time series have some form of seasonality trends, i.e. variations specific to a particular time frame. For example, for Christmas holidays, which we will see in this dataset.","4b0cb0de":"**Missing Values**\n\nclosed and zero sales store ","ab546c68":"Still working on to add holidays effect ","d9db9203":"The first plot shows that the monthly sales of store number 1 has been linearly decreasing over time\n\nand the second shows the holiays gaps included in the model.\n\nThe third plot highlights the fact that the weekly volume of last week sales peaks towards the Monday of the next week, while the \n\nforth plot shows that the most buzy season occurs during the Christmas holidays.","ec6ea75c":"In case of no promotion, both Promo and Promo2 are equal to 0, Sales tend to peak on Sunday (!). Though we should note that StoreType C doesn't work on Sundays. So it is mainly data from StoreType A, B and D.\n\nOn the contrary, stores that run the promotion tend to make most of the Sales on Monday. This fact could be a good indicator for Rossmann marketing campaigns. The same trend follow the stores which have both promotion at the same time (Promo and Promo2 are equal to 1).\n\nPromo2 alone doesn't seem to be correlated to any significant change in the Sales amount. This can be also prooved by the blue pale area on the heatmap above","061ae07f":"**Goal:**\n\nExplore the data (ECDF, handle missing values etc).\n\nAnalysis per store type and correlational analysis of stores activity.\n\nPerform extensive Time Series Analysis (seasonal decomposition, trends, autocorrelation).\n\nPredict next 6 weeks of sales using Prophet (Facebook methodology).","31ea74ce":"Data Visualization ","3c403223":"**Short description:**\n\nSales: the turnover for any given day (target variable).\n\nCustomers: the number of customers on a given day.\n\nOpen: an indicator for whether the store was open: 0 = closed, 1 = open.\n\nPromo: indicates whether a store is running a promo on that day.\n\nStateHoliday: indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays.\n\nSchoolHoliday: indicates if the (Store, Date) was affected by the closure of public schools.","80548d97":"as soon as the store continues a consecutive promotion (Promo2 equal to 1) the number of Customers and Sales seems to stay the same or even decrease, which is described by the pale negative correlation on the heatmap. \n\nThe same negative correlation is observed between the presence of the promotion in the store and the day of a week.","4181fa26":"opened store with zero sales","40a343a0":"**ECDF: empirical cumulative distribution function**","ba387942":"StoreType B has the highest average of Sales among all others, however we have much less data for it.","f9f96a4b":"About 20% of data has zero amount of sales \/ customers that we need to deal with and almost 80% of time daily amount of sales was less than 1000.","5fc158a9":"Conclusion from EDA.\n\n1. The most selling and crowded StoreType is A.\n\n2. The best \"Sale per Customer\" StoreType D indicates to the higher Buyer Cart. To benefit from this fact, Rossmann can consider proposing bigger variety of its products.\n\n3. Low SalePerCustomer amount for StoreType B indicates to the possible fact that people shop there essentially for \"small\" things. Eventhough this StoreType generated the least amount of sales and customers over the whole period, it shows a great potential.\n\n4. Customers tends to buy more on Modays when there's one promotion (Promo) and on Sundays when there's no promotion at all (both Promo and Promo1 are equal to 0).\n\n5. Promo2 alone doesn't seem to be correlated to any significant change in the Sales amount.\n","74d93d5a":"**Importing the dataset **","a46aff8d":"Please upvote if you like the kernel ","12638f65":"**Store types**","80718ba5":"**Seasionality **\n\nWe take four stores from store types to represent their group:\n\nStore number 2 for StoreType A\n\nStore number 85 for StoreType B,\n\nStore number 1 for StoreType C\n\nStore number 13 for StoreType D."}}