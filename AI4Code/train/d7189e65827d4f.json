{"cell_type":{"f7173ba9":"code","a1e03371":"code","9df1740b":"code","6fa57b93":"code","2726d4f6":"code","cc12db6e":"code","5a00236e":"code","40bac027":"code","62eb8a0b":"code","393f5c70":"code","9f734188":"code","7ac2ffc1":"code","4cf52328":"code","498938c3":"code","ed39e4b9":"code","23f94ef3":"code","aa1d7b62":"code","cd2ba1d1":"code","d495a7ff":"code","d58dbeb4":"code","5c709d9f":"code","2e6b6e3e":"code","36d23753":"code","d67b380e":"code","0f025fe0":"code","5216cbe8":"code","6a78b02a":"code","9461ac97":"code","ec5fdd99":"code","fc99b822":"code","e5da256d":"code","0ea0c593":"code","4a904691":"code","f717b479":"code","05be0962":"code","220bf880":"code","363dbaf8":"code","8de3d2d3":"markdown","156611f9":"markdown","fc96c29a":"markdown","6b74aba7":"markdown","ca7519e3":"markdown","134cf1b4":"markdown","59871ad1":"markdown","9fcec970":"markdown","ca35a87f":"markdown","b16e4938":"markdown","0321ba20":"markdown","3e1feee7":"markdown","d07a5296":"markdown"},"source":{"f7173ba9":"\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom nltk.stem.porter import PorterStemmer\n\nimport re\n# Tutorial about Python regular expressions: https:\/\/pymotw.com\/2\/re\/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\n\nfrom tqdm import tqdm\nimport os\n\n","a1e03371":"con = sqlite3.connect(\"..\/input\/database.sqlite\")\n","9df1740b":"filtered_data=pd.read_sql_query(\"\"\"select * from Reviews where Score !=3\"\"\",con)","6fa57b93":"def partition(x):\n    if x<3:\n        return 0\n    return 1","2726d4f6":"filtered_data['Score']=filtered_data.Score.map(partition)","cc12db6e":"#Sorting data according to ProductId in ascending order\n\nsorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')","5a00236e":"\n#Deduplication of entries\nfinal=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)","40bac027":"#Checking to see how much % of data still remains\n(final['Id'].size*1.0)\/(filtered_data['Id'].size*1.0)*100","62eb8a0b":"final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]","393f5c70":"#How many positive and negative reviews are present in our dataset?\nfinal['Score'].value_counts()","9f734188":"stop = set(stopwords.words('english')) #set of stopwords\nsno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]',r' ',cleaned)\n    return  cleaned\n","7ac2ffc1":"#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n# this code takes a while to run as it needs to run on 500k sentences.\nif not os.path.isfile('final.sqlite'):\n    final_string=[]\n    all_positive_words=[] # store words from +ve reviews here\n    all_negative_words=[] # store words from -ve reviews here.\n    for i, sent in enumerate(tqdm(final['Text'].values)):\n        filtered_sentence=[]\n        #print(sent);\n        sent=cleanhtml(sent) # remove HTMl tags\n        for w in sent.split():\n            # we have used cleanpunc(w).split(), one more split function here because consider w=\"abc.def\", cleanpunc(w) will return \"abc def\"\n            # if we dont use .split() function then we will be considring \"abc def\" as a single word, but if you use .split() function we will get \"abc\", \"def\"\n            for cleaned_words in cleanpunc(w).split():\n                if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n                    if(cleaned_words.lower() not in stop):\n                        s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                        filtered_sentence.append(s)\n                        if (final['Score'].values)[i] == 1: \n                            all_positive_words.append(s) #list of all words used to describe positive reviews\n                        if(final['Score'].values)[i] == 0:\n                            all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n        str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n        #print(\"***********************************************************************\")\n        final_string.append(str1)\n\n    #############---- storing the data into .sqlite file ------########################\n    final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \n    final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")\n        # store final table into an SQlLite table for future.\n    conn = sqlite3.connect('final.sqlite')\n    c=conn.cursor()\n    conn.text_factory = str\n    final.to_sql('Reviews', conn,  schema=None, if_exists='replace', \\\n                 index=True, index_label=None, chunksize=None, dtype=None)\n    conn.close()\n    \n    \n    with open('positive_words.pkl', 'wb') as f:\n        pickle.dump(all_positive_words, f)\n    with open('negitive_words.pkl', 'wb') as f:\n        pickle.dump(all_negative_words, f)","4cf52328":"if os.path.isfile('final.sqlite'):\n    conn = sqlite3.connect('final.sqlite')\n    final = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", conn)\n    conn.close()\nelse:\n    print(\"Please the above cell\")","498938c3":"final['Score']=final.Score.map({0:'Negative',1:'Positive'})\nscore=final['Score']\nscore=score[0:3000]\nscore.shape","ed39e4b9":"\nfinal_data=final['CleanedText'].head(3000)\nprint(final_data.shape)\n\n","23f94ef3":"count_vect = CountVectorizer() #in scikit-learn\nfinal_counts = count_vect.fit_transform(final_data.values)\nprint(\"the type of count vectorizer \",type(final_counts))\nprint(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\nprint(\"the number of unique words \", final_counts.get_shape()[1])","aa1d7b62":"from sklearn.preprocessing import StandardScaler\nbow=final_counts.toarray()\nstd_data=StandardScaler().fit_transform(bow)\nstd_data.shape","cd2ba1d1":"from sklearn.manifold import TSNE\nmodel = TSNE(n_components=2, random_state=0,perplexity=50,n_iter=5000)\ntsne = model.fit_transform(std_data)\ntsne.shape","d495a7ff":"tsne = np.vstack((tsne.T, score)).T\ntsne.shape\n","d58dbeb4":"\ntsne_df = pd.DataFrame(data=tsne, columns=(\"Dim_1\", \"Dim_2\", \"Reviews\"))\n\nsns.FacetGrid(tsne_df, hue=\"Reviews\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\nplt.show()","5c709d9f":"tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\nfinal_tf_idf = tf_idf_vect.fit_transform(final_data.values)\nprint(\"the type of count vectorizer \",type(final_tf_idf))\nfinal_tf_idf.shape","2e6b6e3e":"\ntf_idf=final_tf_idf.toarray()\ntf_idf=StandardScaler().fit_transform(tf_idf)\ntf_idf.shape","36d23753":"model = TSNE(n_components=2, random_state=0,perplexity=50,n_iter=5000)\ntsne = model.fit_transform(tf_idf)\ntsne.shape","d67b380e":"tsne = np.vstack((tsne.T, score)).T\ntsne.shape","0f025fe0":"tsne_df = pd.DataFrame(data=tsne, columns=(\"Dim_1\", \"Dim_2\", \"Reviews\"))\n\nsns.FacetGrid(tsne_df, hue=\"Reviews\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\nplt.show()","5216cbe8":"i=0\nlist_of_sent=[]\nfor sent in final_data.values:\n    list_of_sent.append(sent.split())\n#print(final_data.values[0])\n#print(list_of_sent[0])\nlen(list_of_sent)\n","6a78b02a":"w2v_model=Word2Vec(list_of_sent,min_count=5,size=50, workers=4)\nw2v_words = list(w2v_model.wv.vocab)\n","9461ac97":"sent_vectors = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in tqdm(list_of_sent): # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n    if cnt_words != 0:\n        sent_vec \/= cnt_words\n    sent_vectors.append(sent_vec)\nprint(len(sent_vectors))\nprint(len(sent_vectors[0]))\n","ec5fdd99":"model = TSNE(n_components=2, random_state=0,perplexity=50,n_iter=5000)\ntsne = model.fit_transform(sent_vectors)\ntsne.shape","fc99b822":"tsne = np.vstack((tsne.T, score)).T\ntsne.shape","e5da256d":"tsne_df = pd.DataFrame(data=tsne, columns=(\"Dim_1\", \"Dim_2\", \"Reviews\"))\n\nsns.FacetGrid(tsne_df, hue=\"Reviews\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\nplt.show()","0ea0c593":"# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\nmodel = TfidfVectorizer()\ntf_idf_matrix = model.fit_transform(final_data.values)\n# we are converting a dictionary with word as a key, and the idf as a value\ndictionary = dict(zip(model.get_feature_names(), list(model.idf_)))\n","4a904691":"type(tf_idf_matrix)\n","f717b479":"# TF-IDF weighted Word2Vec\ntfidf_feat = model.get_feature_names() # tfidf words\/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors = []; # the tfidf-w2v for each sentence\/review is stored in this list\nrow=0;\nfor sent in tqdm(list_of_sent): # for each review\/sentence \n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        if word in w2v_words:\n            vec = w2v_model.wv[word]\n#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n            # to reduce the computation we are \n            # dictionary[word] = idf value of word in whole courpus\n            # sent.count(word) = tf valeus of word in this review\n            tf_idf = dictionary[word]*(sent.count(word)\/len(sent))\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n    if weight_sum != 0:\n        sent_vec \/= weight_sum\n    tfidf_sent_vectors.append(sent_vec)\n    row += 1\n\n","05be0962":"model = TSNE(n_components=2, random_state=0,perplexity=50,n_iter=5000)\ntsne = model.fit_transform(tfidf_sent_vectors)\ntsne.shape","220bf880":"tsne = np.vstack((tsne.T, score)).T\ntsne.shape","363dbaf8":"tsne_df = pd.DataFrame(data=tsne, columns=(\"Dim_1\", \"Dim_2\", \"Reviews\"))\n\nsns.FacetGrid(tsne_df, hue=\"Reviews\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\nplt.show()","8de3d2d3":"# TF-IDF weighted Word2Vec","156611f9":"changing reviews with score less than 3 to be positive and vice-versa\n","fc96c29a":"# Exploratory Data Analysis\n\n## Data Cleaning: Deduplication\n","6b74aba7":"#Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n","ca7519e3":"# t-SNE visualization of Amazon reviews with polarity based color-coding \n\n","134cf1b4":"# TF-IDF","59871ad1":"## Considering 3k Reviews.","9fcec970":"# Word2Vec","ca35a87f":"#  Text Preprocessing: Stemming, stop-word removal and Lemmatization.\n### Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n\n ###  Hence in the Preprocessing phase we do the following in the order below:-\n\n ###  Begin by removing the html tags\n ###  Remove any punctuations or limited set of special characters like , or . or # etc.\n### Check if the word is made up of english letters and is not alpha-numeric\n### Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n### Convert the word to lowercase\n###  Remove Stopwords\n### Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)\n### After which we collect the words used to describe positive and negative reviews","b16e4938":"# Avg W2V","0321ba20":"# Obsevation:\n##  * By observing plots, Most of reviews are positive.\n##  * As we can see in above plots, BoW and TF-IDF are similar in structure. Most of the positive and nagtive points are             overlapped.\n##  *  Avg W2V, TFIDF-W2V are similar vector representation.\n##  *  As compared to BoW and TF-IDF,  Avg W2V and TFIDF-W2V is better in vector representation as we can see that              points are widely spreaded in Avg W2V, TFIDF-W2V.\n","3e1feee7":"# Bag of Words (BoW)","d07a5296":"# TSNE"}}