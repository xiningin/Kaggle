{"cell_type":{"aac784a8":"code","1c84b16e":"code","49c15b93":"code","cc348b88":"code","7de63f54":"code","87174852":"code","e87c6653":"markdown"},"source":{"aac784a8":"import pandas as pd \nimport numpy as np \nimport itertools\nimport random \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nrandom.seed(0)","1c84b16e":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df =  pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n# Join the train and test dataframes so the data preprocessing \n# will be done simultaneously in both datasets \nfull_df = train_df.append(test_df, ignore_index=True)\nprint(f'There are {full_df.shape[0]} rows and {full_df.shape[1]} columns in the full dataframe.')","49c15b93":"def data_preprocessing(df):\n  \n  # Label-encode the sex of a passenger \n  df['Sex'] = df['Sex'].replace(['male'],0)\n  df['Sex'] = df['Sex'].replace(['female'],1)\n\n  # Initialize new columns \n  df['title'] = np.NaN\n  df['alone'] = np.NaN\n  df['cabin_class'] = np.NaN\n\n  # Identify if a passenger is alone in the ship \n  for i,_ in enumerate(df['alone']):\n    if df['SibSp'][i] + df['Parch'][i] == 0:\n      df['alone'][i] = 1\n    else:\n      df['alone'][i] = 0 \n\n  # Handle missing values\n  cols = ['SibSp','Parch','Fare','Age']\n  for col in cols:\n    df[col].fillna(df[col].median(), inplace = True)\n    \n  # Feature-engineer the cabin-class \n  for i,row in enumerate(df['Cabin']):\n    # Get cabin class \n    df['cabin_class'][i] =  str(row)[:1]\n\n  # Count the cabin distribution per class (if available) \n  cabin_distribution = {}\n  count = 0 \n  for row in df['cabin_class']:\n    if row != 'n':\n      count += 1 \n      if row not in cabin_distribution:\n        cabin_distribution[row] = 1 \n      else:\n        cabin_distribution[row] +=1 \n\n  # Calculate the probability of being in a sepcific cabin-class  \n  cabin_pdf = {k:v \/ count for k, v in cabin_distribution.items()}\n\n  # Calculate the cumulative probability of being in a specific cabin-class \n  keys, vals = cabin_pdf.keys(), cabin_pdf.values()\n  cabin_cdf = dict(zip(keys, itertools.accumulate(vals)))\n  cabin_cdf = sorted(cabin_cdf.items(), key=lambda x: x[1])    \n\n  # Randomly assign cabin-classes to passengers that are missing the cabin \n  # field, based on the probabilities calculated above \n  for i,row in enumerate(df['cabin_class']):\n    random_num = random.random()\n    if row == 'n':\n      if random_num < cabin_cdf[0][1]:\n        df['cabin_class'][i] =  cabin_cdf[0][0]\n      elif cabin_cdf[0][1] <= random_num < cabin_cdf[1][1]:\n        df['cabin_class'][i] =  cabin_cdf[1][0]\n\n      elif cabin_cdf[1][1] <= random_num < cabin_cdf[2][1]:\n        df['cabin_class'][i] =  cabin_cdf[2][0]\n      \n      elif cabin_cdf[2][1] <= random_num < cabin_cdf[3][1]:\n        df['cabin_class'][i] =  cabin_cdf[2][0]\n\n      elif cabin_cdf[3][1] <= random_num < cabin_cdf[4][1]:\n        df['cabin_class'][i] =  cabin_cdf[3][0]\n\n      elif cabin_cdf[3][1] <= random_num < cabin_cdf[4][1]:\n        df['cabin_class'][i] =  cabin_cdf[4][0]\n\n      elif cabin_cdf[4][1] <= random_num < cabin_cdf[5][1]:\n        df['cabin_class'][i] =  cabin_cdf[4][0]\n      \n      elif cabin_cdf[5][1] <= random_num < cabin_cdf[6][1]:\n        df['cabin_class'][i] =  cabin_cdf[5][0]\n\n      elif cabin_cdf[6][1] <= random_num < cabin_cdf[7][1]:\n        df['cabin_class'][i] =  cabin_cdf[6][0]\n      else:\n        df['cabin_class'][i] = cabin_cdf[7][0]\n\n  # Perform feature engineering to obtain additional title-info \n  for i,row in enumerate(df['Name']):\n    # Get person's title \n    df['title'][i] = row.split(',')[1].split('.')[0]\n\n  # Embarked one-hot encoding \n  embarked_dummies = pd.get_dummies(df.Embarked, prefix='Embarked')\n  df = pd.concat([df, embarked_dummies], axis=1)\n\n  # Person's title one-hot encoding \n  title_dummies = pd.get_dummies(df.title, prefix='title')\n  df = pd.concat([df, title_dummies], axis=1)\n\n  # Cabin class one-hot encoding \n  cabin_class_dummies = pd.get_dummies(df.cabin_class, prefix = 'cabin_class')\n  df = pd.concat([df, cabin_class_dummies], axis = 1)\n\n  #Remove unecessary columns \n  del df['Name']\n  del df['PassengerId']\n  del df['title']\n  del df['Embarked']\n  del df['Cabin']\n  del df['Ticket']\n  del df['cabin_class']\n\n  return df ","cc348b88":"# Preprocess the data and create the train \/ test sets \nfull_df = data_preprocessing(full_df)\nX_train = full_df[:891]\ny_train = full_df['Survived'][:891]\nX_test = full_df[891:]\ndel X_train['Survived']\ndel X_test['Survived']\n\n\nprint(f'There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the training data.\\n')\nprint(f'There are {X_test.shape[0]} rows and {X_test.shape[1]} columns in the test data.')","7de63f54":"# Stack two models for higher accuracy  \nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm \n\nLR = LogisticRegression(max_iter=1000,C=0.175,random_state=42)\nLR.fit(X_train, y_train)\nlr_training_accuracy = LR.score(X_train, y_train)\nlr_predictions = LR.predict(X_test)\nlr_predictions = [int(x) for x in lr_predictions]\n\nxgboost = XGBRegressor(learning_rate=0.005,\n                       n_estimators=6000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:squarederror',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\nxgb = xgboost.fit(X_train,y_train)\nxgb_training_accuracy = xgb.score(X_train,y_train)\nxgb_predictions = xgb.predict(X_test)\nxgb_predictions = [round(x) for x in xgb_predictions]\n\nprint(\"Logistic Regression training accuracy: %.2f%%\" % (lr_training_accuracy * 100.0))\nprint(\"\\nXGB training accuracy: %.2f%%\" % (xgb_training_accuracy * 100.0))","87174852":"# Combine the results from both models  \npredictions = [round((lr_pred + xgb_pred) \/ 2) for lr_pred,xgb_pred in zip(lr_predictions,xgb_predictions)]\n# Create submission file \nsubmission = pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':predictions})\nsubmission.to_csv('submission.csv',index = False)","e87c6653":"### My original notebook: https:\/\/www.kaggle.com\/christodoulos\/titanic-top-3-w-simple-feature-engineering"}}