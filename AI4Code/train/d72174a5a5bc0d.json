{"cell_type":{"0ceb2866":"code","04b3dca9":"code","dd640d69":"code","6e83daab":"code","f99e2010":"code","12db1a27":"code","564bb2b0":"code","ccd4c230":"code","e0e4a6af":"code","adb8d3a6":"code","82e09d20":"code","11558a8d":"code","f188cb83":"code","193a1dd6":"code","6bdfae9e":"code","0ddca83b":"code","2319da05":"code","7afeb872":"code","4df2e4b6":"code","02484dd6":"code","431fb903":"code","f0019aa6":"code","25985a8a":"code","9f400bd9":"code","49809368":"code","6301d587":"markdown","db03b63b":"markdown","487de3b7":"markdown","1fdbee2a":"markdown","e3834e58":"markdown","08347948":"markdown","24ea4abc":"markdown","53a9a2af":"markdown","3a166e3d":"markdown","2bc159ce":"markdown","d2dcdf80":"markdown","e24bd207":"markdown","56c54932":"markdown","60187d74":"markdown","f88cba80":"markdown","ab75711c":"markdown","89d2126c":"markdown","18b2ba74":"markdown","7c5c6f4c":"markdown","e8ab4e30":"markdown","31c5c7b4":"markdown","f65e6e43":"markdown","eca7611f":"markdown"},"source":{"0ceb2866":"import os\n\nimport random\nimport seaborn as sns\nimport cv2\n\n# General packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nimport IPython.display as ipd\nimport glob\nimport h5py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom PIL import Image\nfrom tempfile import mktemp\n\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, LinearAxis, Range1d\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.palettes import BuGn4\nfrom bokeh.plotting import figure, output_notebook, show\nfrom bokeh.transform import cumsum\nfrom math import pi\n\noutput_notebook()\n\nfrom IPython.display import Image, display\nimport warnings\nwarnings.filterwarnings(\"ignore\")","04b3dca9":"os.listdir('..\/input\/landmark-recognition-2020\/')","dd640d69":"BASE_PATH = '..\/input\/landmark-recognition-2020'\n\nTRAIN_DIR = f'{BASE_PATH}\/train'\nTEST_DIR = f'{BASE_PATH}\/test'\n\nprint('Reading data...')\ntrain = pd.read_csv(f'{BASE_PATH}\/train.csv')\nsubmission = pd.read_csv(f'{BASE_PATH}\/sample_submission.csv')\nprint('Reading data completed')","6e83daab":"display(train.head())\nprint(\"Shape of train_data :\", train.shape)","f99e2010":"display(submission.head())\nprint(\"Shape of submission :\", submission.shape)","12db1a27":"# displaying only top 30 landmark\nlandmark = train.landmark_id.value_counts()\nlandmark_df = pd.DataFrame({'landmark_id':landmark.index, 'frequency':landmark.values}).head(30)\n\nlandmark_df['landmark_id'] =   landmark_df.landmark_id.apply(lambda x: f'landmark_id_{x}')\n\nfig = px.bar(landmark_df, x=\"frequency\", y=\"landmark_id\",color='landmark_id', orientation='h',\n             hover_data=[\"landmark_id\", \"frequency\"],\n             height=1000,\n             title='Number of images per landmark_id (Top 30 landmark_ids)')\nfig.show()","564bb2b0":"import PIL\nfrom PIL import Image, ImageDraw\n\n\ndef display_images(images, title=None): \n    f, ax = plt.subplots(5,5, figsize=(18,22))\n    if title:\n        f.suptitle(title, fontsize = 30)\n\n    for i, image_id in enumerate(images):\n        image_path = os.path.join(TRAIN_DIR, f'{image_id[0]}\/{image_id[1]}\/{image_id[2]}\/{image_id}.jpg')\n        image = Image.open(image_path)\n        \n        ax[i\/\/5, i%5].imshow(image) \n        image.close()       \n        ax[i\/\/5, i%5].axis('off')\n\n        landmark_id = train[train.id==image_id.split('.')[0]].landmark_id.values[0]\n        ax[i\/\/5, i%5].set_title(f\"ID: {image_id.split('.')[0]}\\nLandmark_id: {landmark_id}\", fontsize=\"12\")\n\n    plt.show() ","ccd4c230":"samples = train.sample(25).id.values\ndisplay_images(samples)","e0e4a6af":"samples = train[train.landmark_id == 138982].sample(25).id.values\n\ndisplay_images(samples)","adb8d3a6":"samples = train[train.landmark_id == 126637].sample(25).id.values\n\ndisplay_images(samples)","82e09d20":"samples = train[train.landmark_id == 20409].sample(25).id.values\n\ndisplay_images(samples)","11558a8d":"samples = train[train.landmark_id == 83144].sample(25).id.values\n\ndisplay_images(samples)","f188cb83":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight') ## ???\nimport plotly_express as px\nimport plotly.graph_objects as go\nimport glob\nfrom tqdm.notebook import tqdm\nimport cv2\nimport os\nimport random\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","193a1dd6":"df_train = pd.read_csv('\/kaggle\/input\/landmark-recognition-2020\/train.csv')\ntest = glob.glob('\/kaggle\/input\/landmark-recognition-2020\/test\/*\/*\/*\/*.jpg')","6bdfae9e":"print('Total Train Images: {}'.format(len(df_train))) \nprint('Total Test Images: {}'.format(len(test)))\nprint('Total Unique Landmarks: {}'.format(df_train.landmark_id.nunique()))","0ddca83b":"landmarks = df_train.groupby('landmark_id',as_index=False)['id'].count()\\\n    .sort_values('id',ascending=False).reset_index(drop=True)\nlandmarks.rename(columns={'id':'count'},inplace=True)","2319da05":"def add_text(ax,fontsize=12):\n    for p in ax.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n        ax.annotate('{}'.format(int(y)), (x.mean(), y), ha='center', va='bottom',size=fontsize)","7afeb872":"fig, (ax1,ax2) = plt.subplots(2,1,figsize=(16,8))\nsns.barplot(data=landmarks[:50],x='landmark_id',y='count',ax=ax1,color='#30a2da',\n           order=landmarks[:50]['landmark_id'])\nadd_text(ax1,fontsize=8)\nax1.set_title('Top 50 Landmarks')\nax1.set_ylabel('Number of Images')\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=40, ha=\"right\",size=8)\nsns.barplot(data=landmarks[-50:],x='landmark_id',y='count',ax=ax2,color='#fc4f30')\nax2.set_title('Bottom 50 Landmarks')\nax2.set_ylabel('Number of Images')\nax2.set_xticklabels(ax2.get_xticklabels(), rotation=40, ha=\"right\",size=8)\nplt.tight_layout()\nprint(f\"Number of Landmarks with less than 10 images are {len(landmarks[landmarks['count']<10])}\")\nprint(f\"Number of Landmarks with less than 20 images are {len(landmarks[landmarks['count']<20])}\")\nplt.show()","4df2e4b6":"plt.figure(figsize=(16,4))\nax = sns.distplot(df_train['landmark_id'],bins=500)\nax.set_title('Distribution of Landmarks')\nplt.tight_layout()\nplt.show()","02484dd6":"def get_image(id):\n    path = os.path.join('\/kaggle\/input\/landmark-recognition-2020\/train',\n                        id[0],id[1],id[2],id+'.jpg')\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","431fb903":"def show_data(df,rows,cols):\n    df.reset_index(inplace=True,drop=True)\n    fig = plt.figure(figsize=(24,24))\n    i = 1\n    for r in range(rows):\n        for c in range(cols):\n            id = df.loc[i-1,'id']\n            label = df.loc[i-1,'landmark_id']\n            ax = fig.add_subplot(rows,cols,i)\n            img = get_image(id)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_title(label)\n            ax.imshow(img)\n            i+=1\n    return fig","f0019aa6":"# \ub79c\ub364\ud558\uac8c \uac00\uc838\uc628\ub2e4\ninds = np.random.choice(df_train.index.tolist(),20)\nfig = show_data(df_train.iloc[inds,:],4,5)\nfig.tight_layout()","25985a8a":"df_images = df_train.drop_duplicates(subset=['landmark_id'])\ndf_images = df_images.sample(n=1000,random_state=23)\ndf_images.reset_index(inplace=True,drop=True)\ndf_images['height'] = 0\ndf_images['width'] = 0\ndf_images['channels'] = 0\nfor i in tqdm(range(len(df_images))):\n    img = get_image(df_images.loc[i,'id'])\n    df_images.loc[i,'height'] = img.shape[0]\n    df_images.loc[i,'width'] = img.shape[1]\n    df_images.loc[i,'channels'] = img.shape[2]","9f400bd9":"def img_distribution(df):\n    shape = (np.min(df['width']), np.max(df['width']),\n            np.min(df['height']), np.max(df['height']))\n    fig = px.scatter(df,x='width',y='height')\n    fig.add_shape(\n        x0 = shape[0],\n        x1 = shape[1],\n        y0 = shape[2],\n        y1 = shape[3],\n        fillcolor = 'yellow',\n        opacity=0.3,\n        layer='below'\n    )\n    fig.add_trace(go.Scatter(name='mean',x=[np.mean(df['width'])],y=[np.mean(df['height'])],\n                         marker=dict(color='red',size=10)))\n    #fig.update_traces(marker_line_color='black',marker_line_width=1)\n    fig.update_layout(width=700,height=400,margin=dict(l=0,b=0,r=0,t=40),template='seaborn',\n                 title='Distribution of Image Dimensions', showlegend=False,\n                 xaxis=dict(title='Width', mirror=True, linewidth=2, linecolor='black',showgrid=False),\n                 yaxis=dict(title='Height', mirror=True, linewidth=2, linecolor='black',showgrid=False),\n                 plot_bgcolor='rgb(255,255,255)')\n    return fig","49809368":"img_distribution(df_images)","6301d587":"## \ub370\uc774\ud130\ub97c \ubd05\uc2dc\ub2e4","db03b63b":"### 4.4 Visualizing landmark with 3rd most number of images(landmark_id:20409)\n- \uadf8 \ub2e4\uc74c \ub9ce\uc740 \uc774\ubbf8\uc9c0","487de3b7":"\uc5b4\ub5a4 \uac83\uc744 \uc54c \uc218 \uc788\uc744\uae4c?\n- landmark_id\ub294 81313\uac1c\uc758 \uc720\uc77c\ud55c \uac12\ub4e4\uc774 \uc788\ub2e4.\n- 2300\uac1c \uc774\uc0c1\uc758 \uc774\ubbf8\uc9c0\ub97c \uac16\uace0 \uc788\ub294 \ub79c\ub4dc\ub9c8\ud06c\ub294 \ub2e8 \ud55c\uac1c : landmark_id= 138982\n- \ub79c\ub4dc\ub9c8\ud06c\ub2f9 \uc774\ubbf8\uc9c0\uc758 \uac1c\uc218\ub294 2\uc7a5\uc5d0\uc11c 6272\uc7a5 \uc0ac\uc774\n- 81313\uac1c\ub97c \uc81c\uc678\ud558\uace0 \ub098\uba38\uc9c0 97.5\ud37c\uc13c\ud2b8\uc758 79298\uac1c\uc758 \ub79c\ub4dc\ub9c8\ud06c\ub294 100\uc7a5 \uc774\ud558","1fdbee2a":"\ub2e4\uc74c\uacfc \uac19\uc740 \uad6c\uc131\n- ```train.csv``` : id\uc640 targets \ud3ec\ud568\n    - ```id``` : \uc774\ubbf8\uc9c0\uc758 id\n    - ```landmark_id``` : target landmark id  \n    \n- training set\uc740 ```train\/```\ud3f4\ub354\uc5d0 \uc788\uace0, landmark\uc758 label\uac12\ub4e4\uc740 ```train.csv```\uc5d0 \uc788\uc74c  \n\n- test set\uc740 ```test\/```\ud3f4\ub354\uc5d0 \uc788\uace0, \uac01 \uc774\ubbf8\uc9c0\ub294 unique\ud55c id\ub97c \uac16\uace0 \uc788\uc74c  \n\n> \uc774\ubbf8\uc9c0 \uc218\uac00 \uac81\ub098 \ub9ce\uc544\uc11c \ud30c\uc77c\uba85\uc774 abcdef.jpg\uc774\ub77c\uba74 a\/b\/c\/abcdef.jpg\uc758 \uacbd\ub85c\uc5d0 \uc800\uc7a5\ub418\uc5b4 \uc788\uc74c","e3834e58":"# 1. GLE - EDA(all you need to know)\n- https:\/\/www.kaggle.com\/rohitsingh9990\/glr-eda-all-you-need-to-know","08347948":"\uc774\uac74 \ubb50\ud558\ub294 \ubd80\ubd84\uc774\uc9c0...  \n- \ub79c\ub4dc\ub9c8\ud06c id\ub97c \ubcf5\uc0ac\ud574\uc11c \ub79c\ub364\ud558\uac8c 1000\uac1c\uc758 sample\uc744 \uc0ac\uc6a9  \n- h, w, c\ub97c 0\uc73c\ub85c \ud574\uc11c \uac01\uac01\uc758 \uceec\ub7fc \uc0dd\uc131  \n- \uadf8\ub9ac\uace0 \ub79c\ub364\ud558\uac8c \ubf51\uc740 1000\uac1c\uc758 \uc774\ubbf8\uc9c0\uc758 \uc0ac\uc774\uc988\ub97c \ub370\uc774\ud130\ud504\ub808\uc784\uc5d0 \ub123\uc5b4\uc900\ub2e4","24ea4abc":"### \ub79c\ub4dc\ub9c8\ud06c \uc774\ubbf8\uc9c0 \uc2dc\uac01\ud654","53a9a2af":"## 3. Let's perform some EDA","3a166e3d":"## \ub79c\ub4dc\ub9c8\ud06c\n### \uc774\ubbf8\uc9c0 \uac1c\uc218\uac00 \ub9ce\uc740 \uc0c1\uc704 \ub79c\ub4dc\ub9c8\ud06c\uc640 \ud558\uc704 \ub79c\ub4dc\ub9c8\ud06c\ud45c\uc2dc","2bc159ce":"### 2.1 Loading Data","d2dcdf80":"# 2. Google Landmark Recognition EDA\n- https:\/\/www.kaggle.com\/anshuls235\/google-landmark-recognition-eda","e24bd207":"---","56c54932":"## \ub77c\uc774\ube0c\ub7ec\ub9ac import","60187d74":"### 3.1 Target Distribution (Number of images per landmark_id)\n- landmark_id \ub2f9 image\uc758 \uac2f\uc218..","f88cba80":"## 2. Preliminaries","ab75711c":"### 4.2 Visualizing landmark with most number of images (landmark_id: 138982)\n- \uac00\uc7a5 \ub9ce\uc740 \uc774\ubbf8\uc9c0\ub97c \uac16\uace0 \uc788\ub294 \ub79c\ub4dc\ub9c8\ud06c \uc2dc\uac01\ud654","89d2126c":"### 4.1 Visualizing random images","18b2ba74":"### 4.5 Visualizing landmark with 4th most number of images (landmark_id: 83144)","7c5c6f4c":"### \ub79c\ub4dc\ub9c8\ud06c\uc758 \ubd84\ud3ec \ud655\uc778","e8ab4e30":"## 1. Introduction\nGoogle Landmark Recognition\uc740.. 81K\uc758 \ud074\ub798\uc2a4\uac00 \uc788\ub2e4.  \n\ud074\ub798\uc2a4\ub2f9 training examples\uac00 \ub9ce\uc9c0 \uc54a\uc544\uc11c Landmark Recognition\uc744 \ud558\ub294 \uac83\uc740 \uc5b4\ub824\uc6b4 \uc77c.","31c5c7b4":"\uc774\ubbf8\uc9c0\ub4e4\uc758 **size**\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uac83","f65e6e43":"### Visualizing landmark with 2nd most number of images (landmark_id : 126637)\n- \uc774\ubbf8\uc9c0\uac00 \ub450\ubc88\uc9f8\ub85c \ub9ce\uc740 \ub79c\ub4dc\ub9c8\ud06c \ud655\uc778","eca7611f":"## 4. Let's visualize few images"}}