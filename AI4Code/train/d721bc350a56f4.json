{"cell_type":{"48bf7817":"code","6ef704f0":"code","df5c7b06":"code","c717792e":"code","582b9d62":"code","a07ec1c9":"code","23e6d581":"code","f550c6e8":"code","b402b58b":"code","df08f942":"code","aba76c17":"code","58cd5c44":"code","d8ef1f7f":"code","629ef69c":"code","64bf63d2":"markdown","ce775136":"markdown","21593297":"markdown","064f8737":"markdown","0a134171":"markdown"},"source":{"48bf7817":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","6ef704f0":"iris_df= load_iris()\n","df5c7b06":"\nX_train,X_test,y_train,y_test=train_test_split(iris_df.data,iris_df.target,test_size=0.3,random_state=0)","c717792e":"pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=2)),\n                     ('lr_classifier',LogisticRegression(random_state=0))])","582b9d62":"pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n                     ('pca2',PCA(n_components=2)),\n                     ('dt_classifier',DecisionTreeClassifier())])","a07ec1c9":"pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n                     ('pca3',PCA(n_components=2)),\n                     ('rf_classifier',RandomForestClassifier())])","23e6d581":"## LEts make the list of pipelines\npipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]","f550c6e8":"best_accuracy=0.0\nbest_classifier=0\nbest_pipeline=\"\"","b402b58b":"# Dictionary of pipelines and classifier types for ease of reference\npipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n\n# Fit the pipelines\nfor pipe in pipelines:\n\tpipe.fit(X_train, y_train)","df08f942":"for i,model in enumerate(pipelines):\n    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_test,y_test)))","aba76c17":"for i,model in enumerate(pipelines):\n    if model.score(X_test,y_test)>best_accuracy:\n        best_accuracy=model.score(X_test,y_test)\n        best_pipeline=model\n        best_classifier=i\nprint('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))","58cd5c44":"# Import the GridSerachCV\n\nfrom sklearn.model_selection import GridSearchCV","d8ef1f7f":"# Create a pipeline\npipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n# Create dictionary with candidate learning algorithms and their hyperparameters\ngrid_param = [\n                {\"classifier\": [LogisticRegression()],\n                 \"classifier__penalty\": ['l2','l1'],\n                 \"classifier__C\": np.logspace(0, 4, 10)\n                 },\n                {\"classifier\": [LogisticRegression()],\n                 \"classifier__penalty\": ['l2'],\n                 \"classifier__C\": np.logspace(0, 4, 10),\n                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n                 },\n                {\"classifier\": [RandomForestClassifier()],\n                 \"classifier__n_estimators\": [10, 100, 1000],\n                 \"classifier__max_depth\":[5,8,15,25,30,None],\n                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n                 \"classifier__max_leaf_nodes\": [2, 5,10]}]\n\n\n# create a gridsearch of the pipeline, the fit the best model\ngridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\nbest_model = gridsearch.fit(X_train,y_train)","629ef69c":"print(best_model.best_estimator_)\nprint(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))","64bf63d2":"# Intro\n* In this notebook we will be\n        1. Creating a pipeline \n        2. Will do Hyper Parameter Tuning\n        3. Using GridSearchCV","ce775136":"# Pipelines Perform Hyperparameter Tuning Using Grid SearchCV","21593297":"## Pipelines Creation\n1. Data Preprocessing by using Standard Scaler\n2. Reduce Dimension using PCA\n3. Apply  Classifier","064f8737":"# Reference \n* [Source 1 Krish Naik github](https:\/\/github.com\/krishnaik06\/Pipelines-Using-Sklearn\/blob\/master\/SklearnPipeline.ipynb)\n* [Source 2 Krish explaining about Hyper Parameter Tuning](https:\/\/www.youtube.com\/watch?v=DHxsNrL7Zfw)","0a134171":"# Notes for Better understanding\n![pipeline1.jpg](attachment:f8d62a08-790a-4820-b620-b06f37b104ae.jpg)\n\n![pip.jpg](attachment:31c14994-a9d5-4e43-92b6-e6e7ed57b40b.jpg)\n\n## Few Key points:\n* No of n_jobs don't affect our accuracy"}}