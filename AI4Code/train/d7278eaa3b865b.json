{"cell_type":{"c8359da0":"code","65698a67":"code","15bc2da7":"code","09afb84a":"code","3b0917e0":"code","449b7aba":"code","a09ce3c5":"code","c578e46b":"code","afbd4318":"code","ba150ec5":"code","8c935032":"code","6a946e87":"code","4124638e":"code","7d191f48":"code","c4baf5bc":"code","9bc9f345":"markdown"},"source":{"c8359da0":"#%matplotlib notebook\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport statistics\n\ntrain_df = pd.read_csv(\"..\/input\/bike-sharing-demand\/train.csv\", parse_dates=True)\n\ntrain_df.head(2)","65698a67":"train_df['Day'] = pd.DatetimeIndex(train_df['datetime']).day\ntrain_df['Month'] = pd.DatetimeIndex(train_df['datetime']).month\ntrain_df['Year'] = pd.DatetimeIndex(train_df['datetime']).year\ntrain_df['HH'] = pd.DatetimeIndex(train_df['datetime']).hour\n\ntrain_df.head(1)","15bc2da7":"train_df = train_df.drop(['datetime', 'casual', 'registered'], axis=1)\n\ntrain_df.head(1)","09afb84a":"from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()\n\nfeatures_to_convert = [\"Year\"]\n\nfor i in features_to_convert:\n    train_df[i] = enc.fit_transform(train_df[i].astype('str'))\n\ntrain_df.head(1)","3b0917e0":"cols = train_df.columns.tolist()\ncols","449b7aba":"cols = ['season',\n 'holiday',\n 'workingday',\n 'weather',\n 'temp',\n 'atemp',\n 'humidity',\n 'windspeed',\n 'HH',\n 'Day',\n 'Month',\n 'Year',\n 'count']\n\ntrain_df = train_df[cols]\ntrain_df.head(2)","a09ce3c5":"from sklearn import preprocessing\n\n# Get column names first\nnames = train_df.columns\n\n# Create the Scaler object\nscaler = preprocessing.MinMaxScaler()\n\n# Fit your data on the scaler object\nscaled_df = scaler.fit_transform(train_df)\nscaled_df = pd.DataFrame(scaled_df, columns=names)\n\ntrain_df = scaled_df\ntrain_df.head(2)","c578e46b":"X = train_df.iloc[:,0:12]  #independent columns\ny = train_df.iloc[:,12]    #target column\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, random_state=101)\n\nprint(X_train.shape, X_test.shape)","afbd4318":"#Best n estimator search\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nimport statistics\n\nfor i in range(1,18):\n    model = RandomForestRegressor(n_estimators=i, random_state=101)\n    model.fit(X_train, Y_train)\n\n    y_predict = model.predict(X_test)\n\n    kfoldscore = cross_val_score(model, X_train, Y_train, cv=5)\n\n    #print(\"kFold Scores: {}\".format(kfoldscore.round(4)))\n    print(\"Estimator: \" + str(i) + \"\\tkFold Score Mean: \" + str(statistics.mean(kfoldscore).round(4)))","ba150ec5":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nimport statistics\n\n\nmodel = RandomForestRegressor(n_estimators=7)\nmodel.fit(X_train, Y_train)\n\ny_predict = model.predict(X_test)\n\nkfoldscore = cross_val_score(model, X_train, Y_train, cv=5)\n\nprint(\"kFold Scores: {}\".format(kfoldscore.round(4)))\nprint(\"kFold Score Mean: \", statistics.mean(kfoldscore).round(4))\n","8c935032":"Y = Y_test.values\nA = np.resize(Y,(1633,1)).round(6)\n\nA[100:105]","6a946e87":"B = np.resize(y_predict,(1633,1)).round(6)\nB[100:105]","4124638e":"ind = []\nfor i in range(A.size):\n    ind.append(i)\n\naccuracy = pd.DataFrame({'True': A.flatten(), 'Predict': B.flatten()}, index=ind)\naccuracy.head()","7d191f48":"acc = []\n\nfor i in range(accuracy['True'].size):\n    if accuracy['True'][i] < accuracy['Predict'][i]:\n        result = accuracy['True'][i] \/ accuracy['Predict'][i]\n        acc.append(result.round(2))\n    else: \n        result = accuracy['Predict'][i] \/ accuracy['True'][i] \n        acc.append(result.round(2))\n\naccuracy['Accuracy'] = acc\n\naccuracy","c4baf5bc":"plt.figure(figsize=(10, 7))\nplt.xlabel('True Value')\nplt.ylabel('Predictions')\nplt.scatter(accuracy['True'], accuracy['Predict'], alpha=0.5, s=55, c='r')","9bc9f345":"We are obsessed with fitting everything to an algorithm since ML concept emerged. However, it should be a rule of thumb to keep things simple and never forget that we are just trying to forecast bike renting trends, not identify life threatening cancer. \n\nThis work is based on Train.csv file to show simple measures to take and get a score of 0.49 RMS.."}}