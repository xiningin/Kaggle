{"cell_type":{"189a28d0":"code","b997a022":"code","6a767b5c":"code","b38e27a0":"code","7f814c95":"code","f0927497":"code","3b80959c":"code","59924fc0":"code","eab0a427":"code","961db242":"code","2cf867dd":"markdown","a5820cfb":"markdown","ca25b489":"markdown","26dad9aa":"markdown","fb172d39":"markdown"},"source":{"189a28d0":"import numpy as np\nimport time\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Convolution2D,BatchNormalization,ReLU,LeakyReLU,Add,Activation\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D,UpSampling2D","b997a022":"train_folder=\"\/kaggle\/input\/cityscapes-image-pairs\/cityscapes_data\/cityscapes_data\/train\/\"\nvalid_folder=\"\/kaggle\/input\/cityscapes-image-pairs\/cityscapes_data\/cityscapes_data\/val\/\"\n\ndef get_images_masks(path):\n    names=os.listdir(path)\n    img_g,img_m=[],[]\n    for name in names:\n        img=cv2.imread(path+name)\n        img=cv2.normalize(img,None,0,1,cv2.NORM_MINMAX,cv2.CV_32F)\n        img=img[:,:,::-1]\n        img_g.append(img[:,:256])\n        img_m.append(np.reshape(img[:,256:],(256*256*3)))\n        del img\n    del names\n    return img_g,img_m\n        \ntrain_imgs,train_masks=get_images_masks(train_folder)\nvalid_imgs,valid_masks=get_images_masks(valid_folder)\n\n#train_len=len(train_imgs)\n#valid_len=len(valid_imgs)\n#print(f'Train Images:{train_len}\\nValid Images:{valid_len}')","6a767b5c":"def conv_block(X,filters,block):\n    # resiudal block with dilated convolutions\n    # add skip connection at last after doing convoluion operation to input X\n    \n    b = 'block_'+str(block)+'_'\n    f1,f2,f3 = filters\n    X_skip = X\n    # block_a\n    X = Convolution2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n                      padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n    X = BatchNormalization(name=b+'batch_norm_a')(X)\n    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n    # block_b\n    X = Convolution2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n                      padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n    X = BatchNormalization(name=b+'batch_norm_b')(X)\n    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n    # block_c\n    X = Convolution2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n                      padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n    X = BatchNormalization(name=b+'batch_norm_c')(X)\n    # skip_conv\n    X_skip = Convolution2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n    # block_c + skip_conv\n    X = Add(name=b+'add')([X,X_skip])\n    X = ReLU(name=b+'relu')(X)\n    return X\n    \ndef base_feature_maps(input_layer):\n    # base covolution module to get input image feature maps \n    \n    # block_1\n    base = conv_block(input_layer,[32,32,64],'1')\n    # block_2\n    base = conv_block(base,[64,64,128],'2')\n    # block_3\n    base = conv_block(base,[128,128,256],'3')\n    return base\n\ndef pyramid_feature_maps(input_layer):\n    # pyramid pooling module\n    \n    base = base_feature_maps(input_layer)\n    # red\n    red = GlobalAveragePooling2D(name='red_pool')(base)\n    red = tf.keras.layers.Reshape((1,1,256))(red)\n    red = Convolution2D(filters=64,kernel_size=(1,1),name='red_1_by_1')(red)\n    red = UpSampling2D(size=256,interpolation='bilinear',name='red_upsampling')(red)\n    # yellow\n    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n    yellow = Convolution2D(filters=64,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n    # blue\n    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n    blue = Convolution2D(filters=64,kernel_size=(1,1),name='blue_1_by_1')(blue)\n    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n    # green\n    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n    green = Convolution2D(filters=64,kernel_size=(1,1),name='green_1_by_1')(green)\n    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n    # base + red + yellow + blue + green\n    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n\ndef last_conv_module(input_layer):\n    X = pyramid_feature_maps(input_layer)\n    X = Convolution2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n    X = Activation('sigmoid',name='last_conv_relu')(X)\n    X = tf.keras.layers.Flatten(name='last_conv_flatten')(X)\n    return X","b38e27a0":"input_layer = tf.keras.Input(shape=np.squeeze(train_imgs[0]).shape,name='input')\noutput_layer = last_conv_module(input_layer)\nmodel = tf.keras.Model(inputs=input_layer,outputs=output_layer)","7f814c95":"model.summary()","f0927497":"model.load_weights('\/kaggle\/input\/best-modelh5\/best_model.h5')","3b80959c":"'''\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='mse')\nmodel.fit(np.array(train_imgs,dtype='float16'),np.array(train_masks,dtype='float16'),\n          validation_data=(np.array(valid_imgs,dtype='float16'),np.array(valid_masks,dtype='float16')),\n          epochs=20,steps_per_epoch=297,verbose=1,batch_size=10)\n'''\n#tf.keras.models.save_model(model,'\/kaggle\/working\/best_model.h5')","59924fc0":"def plot_imgs(img,mask,pred):\n    mask = np.reshape(mask,(256,256,3))\n    pred = np.reshape(pred,(256,256,3))\n    fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,10))\n    ax1.imshow(img)\n    ax1.axis('off')\n    ax2.imshow(mask)\n    ax2.axis('off')\n    ax3.imshow(pred)\n    ax3.axis('off')","eab0a427":"pred_masks = model.predict(np.array(valid_imgs,dtype='float16'))","961db242":"print('-------------Input---------------Actual mask--------------Predicted mask-------')\nfor i in range(5):\n    x = np.random.randint(0,500,size=1)[0]\n    plot_imgs(valid_imgs[x],valid_masks[x],pred_masks[x])","2cf867dd":"<img src='https:\/\/miro.medium.com\/max\/1304\/1*IxUlWP8RBtxNS1N6hyBAxA.png' align='center'><\/img>","a5820cfb":"### Pyramid Scene Parsing Network (PSPNet)","ca25b489":"    Separate normal image and mask image in training and validation folders,\n    where each image of shape (256,512,3) of which (256,256,3) is normal image and (256,256,3) is mask image","26dad9aa":"    Model trained with checkpoints for each epochs = 20.\n    for each 20 epochs model saved and feed into model with load_weights each time.\n   \n    Also,used optimizers Adam,SGD,Nadam with learning rates [0.001,0.001].","fb172d39":"    Model trained for only 3 hrs and epoch less than 150.\n    If trained for more epochs model might converge close to true mask images."}}