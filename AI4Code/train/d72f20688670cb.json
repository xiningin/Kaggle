{"cell_type":{"6b0996b9":"code","038544d9":"code","a6fe381e":"code","e2f7a824":"code","024950f1":"code","2d0f77e2":"code","7c1d206e":"code","b8803356":"code","5580f058":"code","58bf74db":"code","904cdb60":"code","373f0d5c":"code","1622e637":"code","5602b8df":"code","4ce9d9aa":"code","5cd04914":"code","f0fc6fde":"code","34df2ede":"code","f5a706e5":"code","ebc1e2aa":"code","997e4607":"code","c89ae842":"code","9fc5583b":"code","5db73cb4":"code","0be82d6d":"code","bd706fa9":"code","298ffa31":"code","d3a35432":"code","5fe11e05":"code","cb41dbb6":"code","131e8cf1":"code","e9ff1220":"code","a78af579":"code","517e71dd":"code","70251ae0":"code","defda94e":"code","4ec39924":"code","913fb4d8":"code","17074c9f":"code","3e82e904":"code","37d86255":"code","b64eab8f":"markdown","2e4bbc92":"markdown","987624ef":"markdown","a8ef293f":"markdown"},"source":{"6b0996b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","038544d9":"train_data = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')\nprint(train_data.shape)\nprint(test_data.shape)","a6fe381e":"train_data.head()","e2f7a824":"test_ids = test_data['PassengerId'].tolist()\ntrain_survived = train_data['Survived']\ntrain_data = train_data.drop('Survived',axis = 1)\ntrain_data['split'] = 'train'\ntest_data['split'] = 'test'\ntotal_data = pd.concat([train_data,test_data[train_data.columns]],axis = 0,ignore_index = True)","024950f1":"total_data.isna().sum()","2d0f77e2":"total_data['Age'] = total_data['Age'].fillna(-999)\ntotal_data['Cabin'] = total_data['Cabin'].fillna('UNK')\ntotal_data['Ticket'] = total_data['Ticket'].fillna('UNK')\ntotal_data['Embarked'] = total_data['Embarked'].fillna('UNK')\ntotal_data['Fare'] = total_data['Fare'].fillna(-999)","7c1d206e":"total_data.head()","b8803356":"total_data = total_data.drop('PassengerId',axis = 1)","5580f058":"total_data.Pclass.unique()","58bf74db":"total_data.Sex.unique()","904cdb60":"list(total_data.Ticket.unique())","373f0d5c":"for i in range(1,4):\n    total_data['Is_Pclass_'+str(i)] = total_data['Pclass'].apply(lambda x:(x==i)*1.0)\nfor i in ['male','female']:\n    total_data['Is_sex_'+i] = total_data['Sex'].apply(lambda x: (x==i)*1.0)\nfor i in ['S','C','Q']:\n    total_data['Is_class_'+i] = total_data['Embarked'].apply(lambda x:(x==i)*1.0)\ntotal_data['Is_ticket_unknown'] = total_data['Ticket'].apply(lambda x: (x=='UNK')*1.0)\ntotal_data['Passenger_class_unknown'] = total_data['Embarked'].apply(lambda x: (x=='UNK')*1.0)\ntotal_data['No_cabin'] = total_data['Cabin'].apply(lambda x: (x=='UNK')*1.0)\ntotal_data['ticket_only_digit'] = total_data['Ticket'].apply(lambda x: x.isdigit()*1.0)\ntotal_data['paris_bound'] = total_data['Ticket'].apply(lambda x: ('Paris' in x)*1.0)\ntotal_data['soton_bound'] = total_data['Ticket'].apply(lambda x: ('SOTON' in x)*1.0+('STON' in x)*1.0)\ntotal_data['PC_in_ticket'] = total_data['Ticket'].apply(lambda x: ('PC' in x)*1.0 +('P.C.' in x)*1.0)\ntotal_data['A_in_ticket'] = total_data['Ticket'].apply(lambda x: ('A' in x)*1.0)\ntotal_data['CA_in_ticket'] = total_data['Ticket'].apply(lambda x: ('CA' in x)*1.0)\ntotal_data['wc_in_ticket'] = total_data['Ticket'].apply(lambda x: ('W.\/C.' in x)*1.0)\ntotal_data['SC_in_ticket'] = total_data['Ticket'].apply(lambda x: ('SC' in x)*1.0)\n#total_data['PP_in_ticket'] = total_data['Ticket'].apply(lambda x: ('P.P.' in x)*1.0)\n#total_data['fcc_in_ticket'] = total_data['Ticket'].apply(lambda x: ('F.C.C.' in x)*1.0)\n#total_data['soc_in_ticket'] = total_data['Ticket'].apply(lambda x: ('S.O.C.' in x)*1.0)\ntotal_data['family_number'] = total_data['SibSp'] + total_data['Parch']","1622e637":"x = 3\n((x<4) and (x>2)) *1.0","5602b8df":"cut_points = [-999,0,16,60,100]\nlabel_names = [\"Missing\",\"Child\",\"Adult\",\"Senior\"]\nfor i in range(len(label_names)):\n    total_data['Is_Age_'+label_names[i]] = total_data['Age'].apply(lambda x: ((x>=cut_points[i]) and (x<cut_points[i+1]))*1.0)","4ce9d9aa":"total_data['Age'] = total_data['Age'].replace(-999,18)","5cd04914":"total_data['first_class_female'] = total_data['Is_Pclass_1']*total_data['Is_sex_female']\ntotal_data['first_class_child'] = total_data['Is_Pclass_1']*total_data['Is_Age_Child']\ntotal_data['second_class_child'] = total_data['Is_Pclass_2']*total_data['Is_Age_Child']\ntotal_data['second_class_female'] = total_data['Is_Pclass_1']*total_data['Is_sex_female']\ntotal_data['Third_class_adult'] = total_data['Is_Pclass_3']*(1-total_data['Is_Age_Child'])\ntotal_data['male_with_family'] = total_data['Is_sex_male']*total_data['family_number']","f0fc6fde":"total_data.shape","34df2ede":"total_data.columns","f5a706e5":"total_data['Embarked'].unique()","ebc1e2aa":"total_data = total_data.drop(['Pclass','Sex','Ticket','Embarked','Cabin'],axis = 1)","997e4607":"total_data.columns","c89ae842":"list(total_data['Name'].unique())","9fc5583b":"total_data = total_data.drop('Name',axis = 1)","5db73cb4":"total_data.shape","0be82d6d":"total_data.columns","bd706fa9":"import matplotlib.pyplot as plt\nplt.hist(total_data[total_data['Age']!=-999]['Age'])","298ffa31":"train_data = total_data[total_data['split']=='train']\ntrain_data = train_data.drop('split',axis = 1)\ntest_data = total_data[total_data['split']=='test']\ntest_data = test_data.drop('split',axis = 1)","d3a35432":"train_data.columns","5fe11e05":"from sklearn.ensemble import RandomForestClassifier as RFC\nfrom sklearn.metrics import classification_report as creport\nfrom sklearn.model_selection import train_test_split as tts\nfrom xgboost import XGBClassifier as XGBC\nfrom sklearn.svm import NuSVC","cb41dbb6":"X_train,X_test,Y_train,Y_test = tts(train_data,train_survived,test_size = 0.2,random_state = 8080)","131e8cf1":"rfc = RFC(n_estimators = 128,max_depth = 6,criterion = 'entropy',\n          min_samples_split = 5, max_features = 15,\n          #class_weight = 'balanced',#commenting out as this decreased accuracy.\n          oob_score = True,n_jobs = -1)\nrfc.fit(X_train,Y_train)\nY_pred_train = rfc.predict(X_train)\nY_pred_test = rfc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))\nprint(\"the oob score is:\")\nprint(rfc.oob_score_)","e9ff1220":"from sklearn.ensemble import ExtraTreesClassifier as ETC\netc = ETC(n_estimators = 128,max_depth = 6,criterion = 'entropy',min_samples_split = 30,\n          #class_weight = 'balanced',#commenting out as this decreased accuracy.\n          bootstrap = True,\n          oob_score = True,n_jobs = -1)\netc.fit(X_train,Y_train)\nY_pred_train = etc.predict(X_train)\nY_pred_test = etc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))\nprint(\"the oob score is:\")\nprint(etc.oob_score_)","a78af579":"from lightgbm import LGBMClassifier as LGBC\nlgbc = LGBC()\nlgbc.fit(X_train,Y_train)\nY_pred_train = lgbc.predict(X_train)\nY_pred_test = lgbc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))","517e71dd":"feature_importances = pd.DataFrame()\nfeature_importances['features'] = X_train.columns\nfeature_importances['feature_importance'] = rfc.feature_importances_","70251ae0":"feature_importances","defda94e":"important_columns = feature_importances[feature_importances['feature_importance']>0.001]['features'].tolist()","4ec39924":"\"\"\"\n#commenting it out as for us random forest is the best model.\n#this is not a good model actually as this performed much worse: 0.78013.\n#probably this is caused by the fact that we reduced too many features.\nrfc = RFC(n_estimators = 128,max_depth = 10,\n          #criterion = 'entropy',\n          min_samples_split = 15,\n          #class_weight = 'balanced',#commenting out as this decreased accuracy.\n          oob_score = True,n_jobs = -1)\nrfc.fit(X_train[important_columns],Y_train)\nY_pred_train = rfc.predict(X_train[important_columns])\nY_pred_test = rfc.predict(X_test[important_columns])\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))\nprint(\"the oob score is:\")\nprint(rfc.oob_score_)\n\"\"\"","913fb4d8":"xgbc = XGBC(n_estimators=900,\n            learning_rate = 0.1,\n            max_depth = 6,\n            reg_lambda = 100,\n            reg_alpha = 5,\n            scale_pos_weight = 1.33,\n            n_jobs = -1)\nxgbc.fit(X_train,Y_train)\nY_pred_train = xgbc.predict(X_train)\nY_pred_test = xgbc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))","17074c9f":"submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\nprint(submission.columns)","3e82e904":"test_prediction = rfc.predict(test_data)\nfirst_submission = pd.DataFrame()\nfirst_submission['PassengerId'] = test_ids\nfirst_submission['Survived'] = test_prediction\nfirst_submission.to_csv('third_randomforest_submission.csv',index = False)","37d86255":"test_prediction = lgbc.predict(test_data)\nfirst_submission = pd.DataFrame()\nfirst_submission['PassengerId'] = test_ids\nfirst_submission['Survived'] = test_prediction\nfirst_submission.to_csv('first_lgbm_submission.csv',index = False)","b64eab8f":"Sex and the class interaction features are very important. So let's create them.","2e4bbc92":"sort only important features and retrain random forest model.","987624ef":"For me, It doesn't seem currently that the name feature has any valuable information. So we are going to drop it.","a8ef293f":"## Initial Data Cleaning:\nLet's do the first things first. Drop passengerid from train and store the one from test; as that is needed for sample submission. The 'Survived' is the dependent target. In this competition, variables like age and cabin, not being present is also significant; so we will have to replace them tactfully to get some information out of them. "}}