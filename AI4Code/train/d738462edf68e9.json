{"cell_type":{"e1a88d7d":"code","6410526d":"code","ceb82814":"code","8f50118b":"code","b53b716c":"code","99ed4a26":"code","c8889c85":"code","4d3dbf28":"code","4c2998a5":"code","3eaa63d6":"code","783d9b32":"code","b53db068":"code","e7fd88cf":"code","48003ea4":"code","c94e1b97":"code","9caed53f":"code","c20d317d":"markdown","e43107ea":"markdown"},"source":{"e1a88d7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6410526d":"import matplotlib.pylab as plt\n\n#Reading whole dataset\ndata = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\n\ndata.columns\n\n#drop ID column because it is not a feature\ndata.drop([\"Id\"], axis = 1, inplace = True)\n\ndata.info()","ceb82814":"#Give Species column integer values;\n#Iris-setosa = 0; Iris-versicolor = 1; Iris-virginica = 2\ndata.Species = [0 if each == \"Iris-setosa\" else 1 if each == \"Iris-versicolor\" else 2 for each in data.Species]   \n#For analyzng data it is necessary to divide data dimensions and labels(Species)\nx = data.drop([\"Species\"],axis=1)\n#Simply select first 2 features\nx = x.iloc[:,:2]\ny = data.Species.values\nx.head()","8f50118b":"# Normalize X\nmean = np.mean(x)\nstd = np.std(x)\nprint('Mean: ', mean, ' - Standard variance: ', std)\n\nx_norm = (x-mean) \/ std\nmean = np.mean(x)\nstd = np.std(x)\nprint('Normalized mean: ', mean, ' - Standard variance: ', std)\n\nx_norm.head()","b53b716c":"from sklearn.model_selection import train_test_split\n#Randomly split your data into train and test\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=1)\nx_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.4, random_state=1)\nprint(\"x_train: \", x_train.shape, \"x_val: \", x_val.shape, \"x_test: \", x_test.shape)","99ed4a26":"#For C from 10-3 to 103 (multiplying at each step by 10)\n#a. Train a linear SVM on the training set.\n#b. Plot the data and the decision boundaries\n#c. Evaluate the method on the validation set\nfrom sklearn import svm\ndef plot_contours(ax, clf, xx, yy, **params):\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    out = ax.contourf(xx, yy, Z, **params)\n    return out\n\n# I create an instance of SVM and fit out data-->model.\nc = 0.001  # SVM regularization parameter\ntitles = []\nmodels = []\nfor i in range(6):\n    clf = svm.SVC(kernel='linear', C=c)\n    model = clf.fit(x, y)\n    models.append(model)\n    title1 = \"Decision Boundaries with C=\" + str(c)\n    titles.append(title1)\n    c = c * 10    \n\n# Set-up 2x3 grid for plotting.\nfig, sub = plt.subplots(2, 3, figsize=(15,10))\nplt.subplots_adjust(wspace=0.7, hspace=0.7)\n\n#create a meshgrid to represent each data on validation set with consider max and min values on x y axises\n#why validation set because we will predict our results with validaiton set\nx0, x1 = x_val.iloc[:, 0], x_val.iloc[:, 1]\nx_min, x_max = x0.min() - 1, x0.max() + 1\ny_min, y_max = x1.min() - 1, x1.max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1))\n\nfor clf, title, ax in zip(models, titles, sub.flatten()):\n    plot_contours(ax, clf, xx, yy,cmap=plt.cm.coolwarm, alpha=0.8)\n    ax.scatter(x0, x1, c=y_val, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n    ax.set_xlabel('Sepal length')\n    ax.set_ylabel('Sepal width')\n    ax.set_xticks(())\n    ax.set_yticks(())\n    ax.set_title(title)\nplt.show()","c8889c85":"accuracy = []\n#c. Evaluate the method on the validation set\nfor clf in models:\n    pred = clf.predict(x_val)\n    \n    #Accuracy\n    accuracy1 = sum(pred==y_val) \/ y_val.shape[0] \n    accuracy.append(accuracy1)\n    print('Accuracy val set: ', accuracy1)\n\nfig1, ax1 = plt.subplots()\nax1.plot(accuracy, label=\"score\")\nax1.set_xlabel(\"C Values\")\nax1.set_ylabel(\"Accuracy\")\nax1.set_title(\"Accuracy on Validation on LinearSVM\")\nplt.show()","4d3dbf28":"#Use the best value of C and evaluate the model on the test set. How well does\n#the best c = 0.1\n#redo svm for test_split\nsvm_test = svm.SVC(kernel = 'linear', C=0.1)\nsvm_test.fit(x_train, y_train)\npredict_test = svm_test.predict(x_test)\naccuracy_test = sum(predict_test==y_test) \/ y_test.shape[0] \nprint('Accuracy test set: ', accuracy_test)","4c2998a5":"#Repeat point 4. (train, plot, etc..), but this time use an RBF kernel\n#Evaluate the best C on the test set.\n#Are there any differences compared to the linear kernel? How are the boundaries different?\n\ndef plot_contours(ax, clf, xx, yy, **params):\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    out = ax.contourf(xx, yy, Z, **params)\n    return out\n\nc = 0.001  # SVM regularization parameter\ntitles = []\nmodels = []\npredict = []\naccuracy = []\n\nfor i in range(7):\n    clf = svm.SVC(kernel='rbf', C=c)\n    model = clf.fit(x_train, y_train)\n    models.append(model)    \n    \n    title1 = \"Decision Boundaries RBF C=\" + str(c)\n    titles.append(title1)\n    c *= 10    \n\n# Set-up 2x2 grid for plotting.\nfig2, sub2 = plt.subplots(2,4, figsize=(15,10))\nplt.subplots_adjust(wspace=0.7, hspace=0.7)\n\n#create a meshgrid to represent each data on validation set with consider max and min values on x y axises\n#why validation set because we will predict our results with validaiton set\nx0, x1 = x_val.iloc[:, 0], x_val.iloc[:, 1]\nx_min, x_max = x0.min() - 1, x0.max() + 1\ny_min, y_max = x1.min() - 1, x1.max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1))\n\nfor clf, title, ax2 in zip(models, titles, sub2.flatten()):\n    plot_contours(ax2, clf, xx, yy,cmap=plt.cm.coolwarm, alpha=0.8)\n    ax2.scatter(x0, x1, c=y_val, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n    ax2.set_xlabel('Sepal length')\n    ax2.set_ylabel('Sepal width')\n    ax2.set_xticks(())\n    ax2.set_yticks(())\n    ax2.set_title(title,size='small')\nplt.show()","3eaa63d6":"accuracy = []\n#c. Evaluate the method on the validation set\nfor clf in models:\n    pred = clf.predict(x_val)\n    #Accuracy\n    accuracy1 = sum(pred==y_val) \/ y_val.shape[0] \n    accuracy.append(accuracy1)\n    print('Accuracy val set: ', accuracy1)\n\nfig3, ax3 = plt.subplots()\nax3.plot(accuracy, label=\"score\")\nax3.set_xlabel(\"C Values\")\nax3.set_ylabel(\"Accuracy\")\nax3.set_title(\"Accuracy on Validation on RBF SVM\", size='small')\nplt.show()","783d9b32":"#Use the best value of C and evaluate the model on the test set. How well does\n#the best c = 1.0\n#redo svm for test_split\nsvm_test = svm.SVC(kernel = 'rbf', C=1.0)\nsvm_test.fit(x_train, y_train)\npredict_test = svm_test.predict(x_test)\naccuracy_test = sum(predict_test==y_test) \/ y_test.shape[0] \nprint('Accuracy test set: ', accuracy_test)","b53db068":"#Perform a grid search of the best parameters for an RBF kernel: we will now tune both gamma and C at the same time. Select an appropriate range for both parameters. Train the model and score it on the validation set.\n#Show the table showing how these parameters score on the validation set.\n\ncosts = [1e-3,1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\ngammas = [1e-3,1e-2, 1e-1, 1e0, 1e1]\nkernels = ['rbf']\n\nclassifiers = []\nfor c in costs:\n    for g in gammas:\n        grid_search = svm.SVC(kernel = 'rbf', C=c, gamma=g)\n        grid_search.fit(x_train, y_train)\n        classifiers.append((c, g, grid_search))\n\nx0, x1 = x_val.iloc[:, 0], x_val.iloc[:, 1]\nx_min, x_max = x0.min() - 1, x0.max() + 1\ny_min, y_max = x1.min() - 1, x1.max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1))\n\nfor (k, (c, g, grid_search)) in enumerate(classifiers):\n    # evaluate decision function in a grid\n    Z = grid_search.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    # visualize decision function for these parameters\n    plt.subplot(len(costs), len(gammas), k + 1)\n    \n    plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(g), np.log10(c)),size='small')\n\n    # visualize parameter's effect on decision function\n    plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n    plt.scatter(x0, x1, c=y_val, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n    plt.xticks(())\n    plt.yticks(())\n    plt.axis('tight')\n    plt.show()\n\n","e7fd88cf":"#Evaluate the best parameters on the test set. Plot the decision boundaries\n#the best c = 1.0 and  gamma=0.1\n#redo svm for test_split\nsvm_test = svm.SVC(kernel = 'rbf', C=1.0, gamma=0.1)\nsvm_test.fit(x_train, y_train)\npredict_test = svm_test.predict(x_test)\naccuracy_test = sum(predict_test==y_test) \/ y_test.shape[0] \nprint('Accuracy test set: ', accuracy_test)","48003ea4":"from sklearn.model_selection import KFold\nx_train.append(x_val)\ny_train = np.append(y_train,y_val)\n\n##MAKE WITH GRIDSEARCH CV = 5 passed kf\nk_folds = KFold(n_splits = 5, shuffle=True, random_state=1)\n\ncosts = [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\ngammas = [1e-3,1e-2, 1e-1, 1e0, 1e1]\nkernels = ['rbf']\n#scores = np.empty((len(costs), len(gammas), len(k_folds), 1))\nscores = []\nacc_score = np.empty((len(costs), len(gammas)))\n\nfor i, c in enumerate(costs):\n    for j, g in enumerate(gammas):\n        k = 1\n        k_fold_avg_acc = 0\n        for train, test in k_folds.split(x_train):\n            #train and test are the index of the dataset\n            grid_search = svm.SVC(kernel = 'rbf', C=c, gamma=g)\n            grid_search.fit(x_train.iloc[train], y_train[train]) \n            score = grid_search.score(x_train.iloc[test], y_train[test])\n            scores.append((g,c,k,score))\n            k_fold_avg_acc += score\n            print(\"For gamma=\", g, \" C=\", c,\" k-fold=\",k,\" the accuracy=\",score)\n            if k == 5:\n                k_fold_avg_acc = k_fold_avg_acc \/ 5.0\n                acc_score[i,j] = np.round(k_fold_avg_acc,3)\n            k += 1\n            \n#Heatmap accuracies\nfig5, ax5 = plt.subplots()\nim = ax5.imshow(acc_score)\n\nax5.set_xticks(np.arange(len(gammas)))\nax5.set_yticks(np.arange(len(costs)))\n\nax5.set_xticklabels(gammas)\nax5.set_yticklabels(costs)\n\nax5.set_xlabel(\"Gamma Values\")\nax5.set_ylabel(\"C Values\")\n\nplt.setp(ax5.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n\n# Loop over data dimensions and create text annotations.\nfor i in range(len(costs)):\n    for j in range(len(gammas)):\n        text = ax5.text(j, i, acc_score[i, j],ha=\"center\", va=\"center\", color=\"w\", size='small')\n\nax5.set_title(\"Average Accuracies K-Fold(in C\/gamma)\")\nfig.tight_layout()\nplt.show()\n\n\n","c94e1b97":"#Evaluate the best parameters on the test set\n#the best c = 1.0 and  gamma=0.1\ngrid_search.fit(x_test, y_test)\ntest_score = grid_search.score(x_test, y_test)\nprint(\"The test accuracy = \",test_score)\n\n","9caed53f":"#Evaluate the best parameters on the test set\n#the best c = 1.0 and  gamma=0.1\nk_folds = KFold(n_splits = 5, shuffle=True, random_state=1)\nf_scores = []\n\nfor train, test in k_folds.split(x_test):\n    #train and test are the index of the dataset\n    grid_search = svm.SVC(kernel = 'rbf', C=1.0, gamma=0.1)\n    grid_search.fit(x_test.iloc[train], y_test[train]) \n    #There is an error abput x_train has 2 dimension but train value is one dimension\n    f_score = grid_search.score(x_test.iloc[test], y_test[test])\n    print(\"the accuracy = \",f_score)\n    f_scores.append(f_score)\n\nfig6, ax6 = plt.subplots()\nax6.plot(f_scores, label=\"Score\")\nax6.set_xlabel(\"K Folds\")\nax6.set_ylabel(\"Accuracy\")\nax6.set_title(\"Accuracy on KFolds\")\nplt.show()","c20d317d":"To be sure that accuracy is good, it is important to split data with validation and test. According to good accuracy predicted result with validation, that parameters can be used for testing our data. Randomly split data into train, validation and test sets in proportion 5:2:3","e43107ea":"For C from 10-3 to 103: (multiplying at each step by 10) a. Train a linear SVM on the training set. b. Plot the data and the decision boundaries c. Evaluate the method on the validation set Plot a graph showing how the accuracy on the validation set varies when changing C"}}