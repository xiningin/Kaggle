{"cell_type":{"ab1955a4":"code","1c702b14":"code","c56509dd":"code","7699096f":"code","328a0166":"code","b82a19fc":"code","0eba9362":"code","d5679bed":"code","9c030f41":"code","07ec52cb":"code","cd923d4f":"code","4ec9324d":"code","ec66bae5":"code","6e871600":"code","cdc9c647":"code","8258285a":"code","e2823b23":"code","425d90cf":"code","4006c409":"code","a93773e4":"code","9f728c7b":"code","3ea1b1d4":"code","7a5ed391":"code","19880996":"code","11f29045":"code","40e2a7e8":"code","14916bf5":"code","2370ab41":"code","67229c75":"code","669076dc":"code","2041ddd5":"code","4a34caa3":"code","638d765b":"code","41ae17fe":"code","90bc8d70":"code","2c9f845b":"code","6550c212":"code","324db5af":"code","613ed790":"code","5e0a85fa":"code","2b8208ee":"code","21b544a9":"code","b7d9cbcb":"code","d5bfa2e6":"code","316cc624":"code","1bf5f9b8":"code","2eee894e":"code","699eebf6":"code","928bb091":"code","440e3675":"code","47432242":"code","8e2a3076":"code","a4fed6fb":"code","24acc237":"code","00028500":"code","64f1505a":"code","3c80ec07":"code","e9b31624":"code","a5a86879":"code","13d86db5":"code","5677bf51":"code","c381fc9d":"code","34403ea2":"code","0bf9f324":"code","43c83e58":"code","91ed0b92":"code","2fb72248":"code","fced98dd":"code","88401272":"code","c103e28f":"code","df687752":"code","3c10ad93":"code","bba7ebed":"code","4229f539":"code","1a593b91":"code","4be4cb2a":"code","5c3fad7f":"code","1296edc0":"code","a64cacc2":"code","679db488":"code","6ffa3077":"code","8e1ec0d3":"code","8f32ddf7":"code","5cf49fb2":"code","21e5a38f":"code","b67dcf01":"code","14e2f7c8":"code","a38d39df":"code","ee6376de":"code","a64d81d2":"code","8f8f783c":"code","35261e42":"code","b48a259a":"code","0eefda81":"code","fd2fec96":"code","78653920":"code","0f27b4b7":"code","452677ed":"code","a1bae11c":"code","422901c5":"code","468730c5":"code","c54436c3":"code","a24652dd":"code","15ce1364":"code","edea2de3":"code","ef9d3002":"code","3d32bdfa":"code","89350d70":"code","ba29eb9f":"code","4061e557":"code","06e81ddb":"code","96b74789":"code","911b152c":"code","36e017d9":"code","465f723c":"code","9bf0a1fb":"code","b992a149":"code","67ba0c33":"code","9a17b6bb":"code","70a8aa2b":"code","85e17791":"code","2634019e":"code","27e9e144":"code","cd196f26":"code","e951ceba":"code","95b379bb":"code","c445588f":"code","1a35954d":"code","b23874b5":"code","6098a0d5":"code","158fbff6":"markdown","0f08a7bd":"markdown","6e8aa21d":"markdown","af415507":"markdown","0a1ad8c3":"markdown","dd50f3eb":"markdown","0b967641":"markdown","c3b8df86":"markdown","280c50fd":"markdown","51c9bc0d":"markdown","037ca1eb":"markdown","6c8b6d14":"markdown","82ac912b":"markdown","fe42b54b":"markdown","8d4fd700":"markdown","8ca3629e":"markdown","c1169463":"markdown","45b86923":"markdown","42d6d5e6":"markdown","13d866d8":"markdown","ad5fb606":"markdown","ca4e97d0":"markdown","038b058f":"markdown","f53f6f7c":"markdown","59949a67":"markdown","ac4bf942":"markdown","751a4114":"markdown","cdb36464":"markdown","be0d20ca":"markdown","25776322":"markdown","717e0ccb":"markdown","d393feb5":"markdown","ff4359fc":"markdown","0aecefdb":"markdown","cfa3b759":"markdown","e2c26608":"markdown","6c6ab178":"markdown","414e3a0e":"markdown","f6fefbc0":"markdown","56810c82":"markdown","f7c80ab1":"markdown","717dfda1":"markdown","174c9a41":"markdown","e5f270b1":"markdown","2b98457d":"markdown","231812af":"markdown","17b71d2e":"markdown","85a062e3":"markdown","154fb56b":"markdown","8f97679a":"markdown","578f3646":"markdown","edf6e86b":"markdown","e0e817a9":"markdown","15906293":"markdown","46937e6e":"markdown","22861fd3":"markdown","73a55ba1":"markdown","5067be0d":"markdown","70066020":"markdown","6d72013a":"markdown","9a2a6ee1":"markdown","77c2a80c":"markdown","8fffcf0d":"markdown","a1d1cd59":"markdown","d50679ec":"markdown","dbd0ce4d":"markdown","cba80b30":"markdown","0e4a7ac8":"markdown","4497835f":"markdown","28a34731":"markdown","3d08ff75":"markdown","3c1f5c4b":"markdown","cde2db4b":"markdown","33895a95":"markdown","ba9ab6af":"markdown","807e581c":"markdown","2546254b":"markdown","37824daf":"markdown","e563fac2":"markdown","fff5dda5":"markdown","0c856596":"markdown","79c1d079":"markdown","66011df0":"markdown","17bbd1a0":"markdown","fcd6e98c":"markdown","187b4557":"markdown","8c74c57a":"markdown","c4853bf4":"markdown","55a2007d":"markdown","50e39b0a":"markdown","63549b5b":"markdown","c75431f8":"markdown","cfb97a66":"markdown","e274928b":"markdown","570d6fad":"markdown","b29ec195":"markdown","65d36f89":"markdown","121f3e26":"markdown","5f34744f":"markdown","0f3a20a6":"markdown","d2409fe4":"markdown","e21ff9cf":"markdown","98fefd38":"markdown","5142bcd4":"markdown","3139cfe7":"markdown","40041fdd":"markdown","a7f33617":"markdown","5094693d":"markdown","51957b5b":"markdown","4366e0d0":"markdown","7c7a7e58":"markdown","9ba37295":"markdown","a0fd93ae":"markdown","261e1f01":"markdown","a31d322f":"markdown","16a07f2f":"markdown","22c8b004":"markdown","ffc24478":"markdown","ab6ddc30":"markdown","9fd43a1a":"markdown","8853441c":"markdown"},"source":{"ab1955a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt # plotting\nimport seaborn as sns # better plotting\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c702b14":"# Load the training set as a pandas dataframe\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n","c56509dd":"# Display first five rows\ntrain_data.head()","7699096f":"# Scatter plot showing variation of age with passenger class\nplt.scatter(train_data[\"Age\"], train_data[\"Pclass\"])\nplt.show()","328a0166":"# Let us look at statistical implication of the data\ntrain_data.describe()","b82a19fc":"# An overview of the dataset structure\ntrain_data.info()","0eba9362":"# heatmap for null values\nsns.heatmap(train_data.isnull(), yticklabels=False, cbar=False, cmap='flare')\n# Column-wise Null Values\nprint(f'Count of null values :\\n{train_data.isnull().sum()}')\n","d5679bed":"data_types = train_data.dtypes\ndata_idx = data_types.index\n# Indices of Numerical Data Fields\nnum_data_idx = [data_idx[i] for i in range(len(data_types)) if data_types[i]!='object'] \n# Indices of Categorical Data Fields\ncat_data_idx = [data_idx[i] for i in range(len(data_types)) if data_types[i]=='object']\nprint(f\"Numeric Data : {num_data_idx}\")\nprint()\nprint(f\"Categorical Data : {cat_data_idx}\")\n","9c030f41":"# Numeric Data\ntrain_data[num_data_idx].head()\n","07ec52cb":"# Categorical data\ntrain_data[cat_data_idx].head()\n\n","cd923d4f":"train_data[num_data_idx].isnull().sum()","4ec9324d":"# Plot of the original data\nage_dat = train_data[[\"Age\"]]\nage_dat.plot()\nage_dat.describe()","ec66bae5":"# Filling in missing values using default interpolate() method\nitp_age_dat = age_dat.interpolate()\nitp_age_dat.isnull().sum() # Check if there are anymore missing values in `Age` column","6e871600":"# Box-plot of default interpolation\n\nsns.boxplot(data=itp_age_dat)\nitp_age_dat.describe()","cdc9c647":"# Quadratic Interpolation\n\nqip_age_dat = age_dat.interpolate(method='quadratic')\nqip_age_dat.isnull().sum() # Check if there are anymore missing values in `Age` column\n\n# Box-plot of quadratic interpolation\n\nsns.boxplot(data=qip_age_dat, color='orange')\nqip_age_dat.describe()","8258285a":"# Spline interpolation of order 2\n\nsp2_age_dat = age_dat.interpolate(method='spline', order=2)\n\n# Box-plot of spline interpolation\nsns.boxplot(data=sp2_age_dat, color='lightgreen')\nsp2_age_dat.describe()","e2823b23":"# Cubic and Polynomial (order 5) methods \n\ncip_age_dat = age_dat.interpolate(method='cubic') # Cubic Interpolation\n\npl5_age_dat = age_dat.interpolate(method='polynomial', order=5) # 5th Order Polynomial Interpolation\n","425d90cf":"# Box-plot Comparison of Cubic and 5th Order Polynomial Interpolation Methods\n\nip3_age_dat = [cip_age_dat[\"Age\"], pl5_age_dat[\"Age\"]]\nage_headers = [\"Cubic Interpolation\", \"5th order Polynomial Interpolation\"]\nip3_age_dat = pd.concat(ip3_age_dat, axis=1, keys=age_headers)\n\nplt.figure(figsize=(10, 8))\nsns.boxplot(data=ip3_age_dat)","4006c409":"ip3_age_dat.describe()","a93773e4":"med_age_dat = age_dat.fillna(age_dat.median())\n\ndmi_age_dat = [itp_age_dat[\"Age\"], med_age_dat[\"Age\"]] \nheaders_dmi = [\"Default Interpolation\", \"Filling with Median\"]\n\n# A dataframe of default and median interpolation \ndmi_age_dat = pd.concat(dmi_age_dat, axis=1, keys=headers_dmi) \n\nplt.figure(figsize=(10, 8))\nsns.boxplot(data=dmi_age_dat)\ndmi_age_dat.describe()","9f728c7b":"cmp_age_dat = [itp_age_dat[\"Age\"], med_age_dat[\"Age\"], qip_age_dat[\"Age\"], sp2_age_dat[\"Age\"], \n               cip_age_dat[\"Age\"], pl5_age_dat[\"Age\"]]\ncmp_headers = [\"itp\", \"med\", \"qip\", \"sp2\", \"cip\", \"pl5\"]\n\ncmp_labels = [\"Pandas Default Interpolation\", \"Filling Missing Values with Median\", \"Quadratic Interpolation\", \n             \"2nd Order Spline Interpolation\", \"Cubic Interpolation\", \"5th Order Polynomial Interpolation\"]\n\n'''\nitp = Default Interpolation \nmed = Filling in missing values with median\nqip = Quadtratic Interpolation \nsp2 = Spline Interpolation \ncip = Cubic Interpolation\npl5 = 5th order Polynomial Interpolation\n'''\n\ncmp_age_dat = pd.concat(cmp_age_dat, axis=1, keys=cmp_headers)\n\nplt.figure(figsize=(12, 8))\nsns.boxplot(data=cmp_age_dat)\ncmp_age_dat.describe()","3ea1b1d4":"# Fill missing values with interpolation\n\ntrain_data[\"Age\"].interpolate(inplace=True)\ntrain_data[\"Age\"].isnull().sum() # Check if there are still missing values","7a5ed391":"train_data[cat_data_idx].isnull().sum()","19880996":"train_data[\"Embarked\"].value_counts()","11f29045":"# Fill null values\ntrain_data[\"Embarked\"].fillna(\"S\", inplace=True)","40e2a7e8":"train_data[\"Cabin\"].value_counts().head()","14916bf5":"# Fill null values\ntrain_data[\"Cabin\"].fillna(\"X\", inplace=True)","2370ab41":"train_data.isnull().sum()","67229c75":"train_data.describe()","669076dc":"# Analysing Pclass\n\ntrain_data[\"Pclass\"].value_counts()\n","2041ddd5":"sns.countplot(x=train_data[\"Pclass\"])\nplt.show()","4a34caa3":"# Analysing Age\n\nsns.histplot(train_data[\"Age\"])\nplt.show()","638d765b":"# Analysing SibSp\n\nsns.histplot(train_data[\"SibSp\"], discrete=True)\nplt.show()","41ae17fe":"plt.figure(figsize=(12, 8))\nsns.boxplot(data=train_data[[\"SibSp\"]])\nplt.show()","90bc8d70":"# Analysing Parch\n\nsns.histplot(train_data[\"Parch\"], discrete=True)\nplt.show()","2c9f845b":"plt.figure(figsize=(12, 8))\nsns.boxplot(data=train_data[[\"Parch\"]])\nplt.show()","6550c212":"# Analysing Fare\n\nsns.histplot(train_data[\"Fare\"], bins=15)\nplt.show()","324db5af":"# Checking for outliers\nplt.figure(figsize=(12, 8))\nsns.boxplot(data=train_data[[\"Fare\"]])\nplt.show()","613ed790":"import scipy # For Box Cox Transformation","5e0a85fa":"# Outliers in Age\n\nsns.boxplot(data=train_data[[\"Age\"]])\nplt.show()","2b8208ee":"age_fs_dat = (train_data[[\"Age\"]] - train_data[[\"Age\"]].mean()) \/ train_data[[\"Age\"]].std() # Feature Scaling\n\nsns.boxplot(data=age_fs_dat) # Box Plot for feature scaling\nage_fs_dat.describe()","21b544a9":"sns.histplot(age_fs_dat)\nplt.show()","b7d9cbcb":"age_lge_dat = np.log(train_data[[\"Age\"]])\n\nsns.boxplot(data=age_lge_dat)\nage_lge_dat.describe()","d5bfa2e6":"sns.histplot(age_lge_dat)\nplt.show()","316cc624":"age_crn_dat = (train_data[[\"Age\"]]**(1\/3)) # Cube Root Normalization\n\nsns.boxplot(data=age_crn_dat)\nage_crn_dat.describe()","1bf5f9b8":"sns.histplot(age_crn_dat)\nplt.show()","2eee894e":"age_bct_dat, fitted_lmbda_age = scipy.stats.boxcox(train_data[\"Age\"], lmbda=None)\n\nage_bct_dat = pd.DataFrame(age_bct_dat, columns=[\"Age\"])\n\nsns.boxplot(data=age_bct_dat)\nage_bct_dat.describe()","699eebf6":"sns.histplot(age_bct_dat)\nplt.show()","928bb091":"train_data[[\"AgeNorm\"]] = age_bct_dat\n\n","440e3675":"train_data[[\"Fare\"]].describe()","47432242":"far_crn_dat = (train_data[[\"Fare\"]]**(1\/3)) # Cube Root Normalization\n\nfar_lge_dat = np.log(train_data[[\"Fare\"]].replace(to_replace=float(0), value=0.001)) # Logarithmic Transform\n\nfar_bct_dat, fitted_lmbda_far = scipy.stats.boxcox(train_data[\"Fare\"].replace(to_replace=float(0), value=0.001), \n                                                   lmbda=None) # Box Transformation\n\nfar_bct_dat = pd.DataFrame(far_bct_dat, columns=[\"Fare\"])\n\n# DataFrame for comparison of different methods\n\nfar_cmp_dat = [far_lge_dat[\"Fare\"], far_crn_dat[\"Fare\"], far_bct_dat[\"Fare\"]]\n\nfar_headers = [\"Logarithmic Transformation\", \"Cube Root Normalization\", \"Box Transformation\"]\n\nfar_cmp_dat = pd.concat(far_cmp_dat, axis=1, keys=far_headers)\n\nfar_cmp_dat.describe()","8e2a3076":"plt.figure(figsize=(10, 8))\nsns.boxplot(data=far_cmp_dat)\nplt.show()","a4fed6fb":"sns.histplot(data=far_crn_dat)\nplt.show()","24acc237":"train_data[[\"FareNorm\"]] = far_crn_dat","00028500":"train_data[[\"SibSp\"]].value_counts()","64f1505a":"train_data[[\"Parch\"]].value_counts()","3c80ec07":"sns.boxplot(data=train_data[[\"SibSp\"]])\ntrain_data[[\"SibSp\"]].describe()","e9b31624":"sns.histplot(train_data[\"SibSp\"], discrete=True)\nplt.show()","a5a86879":"ssp_crn_dat = (train_data[[\"SibSp\"]]**(1\/3)) # Cube Root Normalization\n\nssp_lge_dat = np.log(train_data[[\"SibSp\"]].replace(to_replace=float(0), value=0.0001)) # Log Transformation\n\nssp_bct_dat, fitted_lambda_ssp = scipy.stats.boxcox(train_data[\"SibSp\"].replace(to_replace=float(0), \n                                                                                value=0.0001), \n                                                    lmbda=None) # Box Transformation\n\nssp_bct_dat = pd.DataFrame(ssp_bct_dat, columns=[\"SibSp\"])\n\nssp_cmp_dat = [ssp_crn_dat[\"SibSp\"], ssp_lge_dat[\"SibSp\"], ssp_bct_dat[\"SibSp\"]]\n\nssp_headers = [\"C.R.N\", \"Log_e\", \"BoxCox\"]\n\nssp_oh_dat = pd.concat(ssp_cmp_dat, axis=1, keys=ssp_headers)\n\nplt.figure(figsize=(8,5))\nsns.boxplot(data=ssp_cmp_dat)\nssp_oh_dat.describe()","13d86db5":"sns.histplot(ssp_crn_dat)\nplt.show()","5677bf51":"sns.boxplot(data=train_data[[\"Parch\"]])\ntrain_data[[\"Parch\"]].describe()","c381fc9d":"sns.histplot(train_data[[\"Parch\"]], discrete=True)\nplt.show()","34403ea2":"# Categorical data\ntrain_data[cat_data_idx].head()","0bf9f324":"# Analysing Pclass\n\ntrain_data[[\"Pclass\"]].value_counts()","43c83e58":"# Correlation between Pclass and probability of survival.\n\ntrain_data[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index=False).mean().sort_values(by=\"Survived\",\n                                                                                          ascending=False)","91ed0b92":"# Correlation between Sex and probability of survival.\n\ntrain_data[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index=False).mean().sort_values(by=\"Survived\",\n                                                                                    ascending=False)","2fb72248":"train_data[[\"Age\"]].describe()","fced98dd":"# Categorize Age\n\nage_cat_data = pd.cut(train_data[\"Age\"], bins=[0, 18, 30, 45, 60, train_data[\"Age\"].max()],\n                      labels=[0, 1, 2, 3, 4])\n\nage_cat_data = pd.DataFrame(age_cat_data, columns=[\"Age\"])\n\nage_cat_data.value_counts()\n\nagesur_concat = pd.concat([age_cat_data[\"Age\"], train_data[\"Survived\"]], axis=1, keys=[\"Age\", \"Survived\"])","88401272":"# Correlation between chances of survival and age\n\nage_concat_plt = agesur_concat[[\"Age\", \"Survived\"]].groupby([\"Age\"],\n                                                            as_index=False).mean().sort_values(by=\"Age\")\nage_concat_plt","c103e28f":"plt.figure(figsize=(8,5))\nplt.plot(age_concat_plt['Age'], age_concat_plt['Survived'])\nplt.show()","df687752":"g_age = sns.FacetGrid(train_data, col=\"Survived\", aspect=1.5)\ng_age.map(sns.histplot, \"Age\")\nplt.show()","3c10ad93":"sas_concat = pd.concat([age_cat_data[\"Age\"], train_data[\"Sex\"], train_data[\"Survived\"]], axis=1, \n                       keys=[\"Age\", \"Sex\", \"Survived\"])\n\n\ng_sas = sns.FacetGrid(sas_concat, col=\"Survived\", row=\"Sex\", hue=\"Age\", aspect=2)\ng_sas.map(sns.histplot, \"Age\", discrete=True)\ng_sas.add_legend()\nplt.show()","bba7ebed":"g_sps = sns.FacetGrid(train_data, col=\"Survived\", row=\"Pclass\", hue=\"Sex\", aspect=2)\ng_sps.map(sns.histplot, \"Sex\", discrete=True)\ng_sps.add_legend()\nplt.show()","4229f539":"g_spe = sns.FacetGrid(train_data, col=\"Survived\", row=\"Embarked\", hue=\"Pclass\", aspect=2)\ng_spe.map(sns.histplot, \"Pclass\", discrete=True)\ng_spe.add_legend()\nplt.show()","1a593b91":"g_spa = sns.FacetGrid(train_data, col=\"Survived\", row=\"Pclass\", aspect=2)\ng_spa.map(sns.histplot, \"Age\")\ng_spa.add_legend()\nplt.show()","4be4cb2a":"g_spes = sns.FacetGrid(train_data, row=\"Embarked\", aspect=2)\ng_spes.map(sns.pointplot, \"Pclass\", \"Survived\", \"Sex\", hue_order=['male', 'female'],\n           order=None, palette=\"flare\")\ng_spes.add_legend()\nplt.show()","5c3fad7f":"(train_data[\"Parch\"] + train_data[\"SibSp\"]).value_counts()\n","1296edc0":"train_data[\"Fcount\"] = train_data[\"Parch\"] + train_data[\"SibSp\"]\ntrain_data.head()","a64cacc2":"train_data[[\"Fcount\", \"Survived\"]].groupby([\"Fcount\"], as_index=False).mean().sort_values(by=\"Survived\", \n                                                                                      ascending=False)","679db488":"import re # Regular Expression\n\ndef extract_title(Name : str):\n    title_str = re.search(\"(Dr|Mrs?|Ms|Miss|Master|Rev|Capt|Mlle|Col|Major|Sir|Jonkheer|Lady|the Countess|Mme|Don)\\\\.\",\n                      Name)\n    if title_str:\n        title = title_str.group(0)\n        if (title == 'Don.' or title == 'Major.' or title == 'Capt.'):\n            title = 'Sir.'\n        if (title == 'Mlle.' or title == 'Mme.'):\n            title = 'Miss.'\n        return title\n    else:\n        return \"Other\"\n    \ntrain_data[\"Title\"] = train_data[\"Name\"].apply(extract_title)\ntrain_data.head()","6ffa3077":"# Sex-wise Division of Titles\n\npd.crosstab(train_data['Title'], train_data['Sex'])\n","8e1ec0d3":"g_ttl = sns.FacetGrid(train_data, col=\"Survived\", aspect=3.5)\ng_ttl.map(sns.histplot, \"Title\")\nplt.show()","8f32ddf7":"train_data[[\"Cabin\"]].value_counts().head()","5cf49fb2":"# Setting Cab as initial char of Cabin No.\ntrain_data[\"Cab\"] = train_data[\"Cabin\"].astype(str).str[0]\n\ntrain_data[\"Cab\"].value_counts()","21e5a38f":"g_cab = sns.FacetGrid(train_data, col=\"Survived\", aspect=1.8)\ng_cab.map(sns.histplot, \"Cab\")\nplt.show()","b67dcf01":"train_data[[\"Ticket\"]].value_counts().head()","14e2f7c8":"# Setting Tstrip as initial char of Ticket No. \ntrain_data[\"Tstrip\"] = train_data[\"Ticket\"].astype(str).str[0]\n\ntrain_data[\"Tstrip\"].value_counts()","a38d39df":"# Replacing remaining character identifiers with integers for Tstrip\ntrain_data['Tstrip'].replace({'S':10, 'P':11, 'C':12, 'A':13, 'W':14, 'F':15, 'L':16}, inplace=True)\n\ntrain_data['Tstrip'] = train_data['Tstrip'].astype(int)\n\ntrain_data['Tstrip'].value_counts()","ee6376de":"g_tst = sns.FacetGrid(train_data, col=\"Survived\", aspect=2)\n\ng_tst.map(sns.histplot, \"Tstrip\")\nplt.show()","a64d81d2":"# Relative distribution of ticket no. in each Pclass\n\npd.crosstab(train_data[\"Tstrip\"], train_data[\"Pclass\"])","8f8f783c":"# Relation between ticket no. and Embarkation Port\n\npd.crosstab(train_data[\"Tstrip\"], train_data[\"Embarked\"])","35261e42":"enc_sex = {\"male\":1, \"female\":2}\ntrain_data[\"Sex\"] = train_data[\"Sex\"].replace(to_replace=enc_sex)\n\ntrain_data.head()","b48a259a":"enc_embk = {'S':1, 'C':2, 'Q':3}\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].replace(to_replace=enc_embk)\n\ntrain_data.head()\n","0eefda81":"train_data[\"Title\"].value_counts()","fd2fec96":"uncommon_titles = {'Lady.':0, 'the Countess.':0,'Capt.':0, 'Col.':0,'Don.':0, 'Dr.':0, 'Major.':0,\n                   'Rev.':0, 'Sir.':0, 'Jonkheer.':0, 'Dona.':0}\n\ntrain_data['Title'] = train_data['Title'].replace(to_replace=uncommon_titles)\ntrain_data['Title'].value_counts()","78653920":"enc_title = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4, 'u':0, 'Ms.':0, 'Other':0}\ntrain_data['Title'] = train_data['Title'].replace(to_replace=enc_title)\n\ntrain_data['Title'].value_counts()","0f27b4b7":"train_data.head()","452677ed":"train_data[\"Cab\"].value_counts()","a1bae11c":"enc_cab = {'X':0,'C':1,'B':2,'D':3,'E':4,'A':5,'F':6,'G':7,'T':8}\ntrain_data[\"Cab\"] = train_data[\"Cab\"].replace(to_replace=enc_cab)\n\ntrain_data.head()","422901c5":"# Dropping Name and PassengerId\n\ntrain_data = train_data.drop(['Name', 'PassengerId', 'Ticket'], axis=1)\ntrain_data.head()","468730c5":"plt.figure(figsize=(16,10))\nsns.heatmap(train_data.corr(), cmap='Dark2', annot=True, linewidths=1.0, linecolor='black')\nplt.show()","c54436c3":"plt.figure(figsize=(16,10))\nsns.heatmap(np.abs(train_data.corr()), cmap='Dark2', annot=True, linewidths=1.0, linecolor='black')\nplt.show()","a24652dd":"# load the test set as a pandas dataframe\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","15ce1364":"# display first five rows of test set\ntest_data.head()","edea2de3":"test_data.info()","ef9d3002":"# Check for null values\ntest_data.isnull().sum()","3d32bdfa":"test_data[\"Age\"].interpolate(inplace=True) # Fill missing age values using interpolation\n\ntest_data[\"Fare\"].fillna(test_data[\"Fare\"].median(), inplace=True) # Fill missing Fare values with median fare\n\ntest_data[\"Cabin\"].fillna('X', inplace=True) # Fill missing Cabin values with `X`","89350d70":"test_data.isnull().sum()","ba29eb9f":"# Fitting Age using Box Cox Transform\ntest_data[\"AgeNorm\"] = pd.DataFrame(scipy.stats.boxcox(test_data[\"Age\"], lmbda=fitted_lmbda_age), columns=[\"Age\"])\n\n# Fitting Fare using Cube Root Normalization\ntest_data[[\"FareNorm\"]] = (test_data[[\"Fare\"]]**(1\/3))\n\n","4061e557":"test_data[\"Fcount\"] = test_data[\"Parch\"] + test_data[\"SibSp\"] # Combine `Parch` and `SibSp` to create `Fcount`","06e81ddb":"test_data[\"Title\"] = test_data[\"Name\"].apply(extract_title) # Find title, which is an important SES indicator","96b74789":"test_data[\"Cab\"] = test_data[\"Cabin\"].astype(str).str[0] # Stripping Cabin No. ","911b152c":"test_data[\"Tstrip\"] = test_data[\"Ticket\"].astype(str).str[0] # Stripping Ticket No.\n\n# Replacing remaining character identifiers with integers for Tstrip\ntest_data[\"Tstrip\"].replace({'S':10, 'P':11, 'C':12, 'A':13, 'W':14, 'F':15, 'L':16}, inplace=True)\n\ntest_data[\"Tstrip\"] = test_data[\"Tstrip\"].astype(int)","36e017d9":"# Handling Ticket initials that are characters\ntest_data['Tstrip'].replace({'S':10, 'P':11, 'C':12, 'A':13, 'W':14, 'F':15, 'L':16}, inplace=True)","465f723c":"test_data[\"Sex\"] = test_data[\"Sex\"].replace(to_replace=enc_sex) # Encoding Sex Column","9bf0a1fb":"test_data[\"Embarked\"] = test_data[\"Embarked\"].replace(to_replace=enc_embk) # Encoding Embarked Column","b992a149":"test_data[\"Cab\"] = test_data[\"Cab\"].replace(to_replace=enc_cab) # Encoding Cab Column\n","67ba0c33":"test_data[\"Title\"] = test_data[\"Title\"].replace(to_replace=uncommon_titles) # Handling Uncommon Titles\ntest_data[\"Title\"] = test_data[\"Title\"].replace(to_replace=enc_title) # Encoding Title Column","9a17b6bb":"test_data.head()","70a8aa2b":"test_data = test_data.drop(['Name', 'Ticket'], axis=1) # Dropping Name & Ticket No. ","85e17791":"test_data.head()","2634019e":"# Load Model & Metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","27e9e144":"# Split training and test data\ny_train = train_data[\"Survived\"]\nX_train = train_data.drop(['Survived', 'Cabin'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42)","cd196f26":"# Fit Model\nmodel = XGBClassifier(objective=\"binary:logistic\", use_label_encoder=False, eval_metric='error')\nmodel.fit(X_train, y_train)","e951ceba":"# make predictions for test data\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","95b379bb":"# evaluating performance on training set\nX_pred_train = model.predict(X_train)\npredictions_train = [round(value) for value in X_pred_train]\naccuracy_train = accuracy_score(y_train, predictions_train)\nprint(\"Accuracy: %.2f%%\" % (accuracy_train * 100.0))","c445588f":"# Dropping Cabin Column from test data\ntest_data = test_data.drop(['Cabin'], axis=1)","1a35954d":"# Predicting output of test data\npredictions = model.predict(test_data.iloc[:, 1:]) # Predicting Score excluding `PassengerId` column\n","b23874b5":"# Create DataFrame of PassengerId and Survived\nsubmission_data = pd.DataFrame({\"PassengerId\":test_data[\"PassengerId\"], \"Survived\":predictions})\n","6098a0d5":"# Submission File\nsubmission_data.to_csv('submission_data.csv', index=False)\n","158fbff6":"We know, data can be of two types, i.e **Numeric** and **Categorical**. Let us divide the dataset into these two for easy inference. ","0f08a7bd":"#### Cube Root Normalization","6e8aa21d":"#### Log Transformation","af415507":"Again, Cube Root Normalization appears to offer a better fit for the data. Let us see if we obtain a normal distribution.","0a1ad8c3":"Well, this does a pretty good job at handling outliers. Also, it has a good chance of preserving the normal distribution due to the closeness of its mean and median. Let us check.","dd50f3eb":"### Mathematical Transformations","0b967641":"Thus, `SibSp` indeed has a lot of outliers which need to be dealt with. \n\nLet us now move on to `Parch`, which, similar to `SibSp`, holds data pertaining to number of parents and\/or children aboard the Titanic. ","c3b8df86":"Let us use the following categorization : \n\n - Ages 0 to 18 (children) - Integer Label `0`\n \n - Ages 18 to 30 (youth) - Integer Label `1`\n \n - Ages 30 to 45 (adults) - Integer Label `2`\n \n - Ages 45 to 60 (middle ages) - Integer Label `3`\n \n - Age 60+ (senior citizens) -  Integer Label `4`\n \n ","280c50fd":"### Comparison of different interpolation methods","51c9bc0d":"From the above heatmap, we can conclude that the column `Survived` is highly correlated to the following columns - \n\n * Sex\n * Title\n * Pclass\n * FareNorm & Fare\n * Cab\n * Embarked\n \n ","037ca1eb":"Now, pandas provides us several methods to fill missing values using interpolation. Among these are `linear`, `quadratic`, `cubic`, `polynomial`, `spline`, to name a few. Let us check their relative performance(s). ","6c8b6d14":"Here, we have taken the Algebraic sum of `Parch` and `SibSp` as the measure of the number of family members of the passenger onboard the Titanic. We can create a new feature `Fcount` for the same.","82ac912b":"Let us finalize our method of choice by creating a new feature, `AgeNorm` ","fe42b54b":"### Interpolation to fill missing values","8d4fd700":"# Exploratory Data Analysis","8ca3629e":" - The first field, `PassengerId` merely keeps track of Serial Number of the data. So, it has no particular significance in the model and as such, doesn't have to be analyzed. \n \n - The field `Survived` is the target column, i.e whose value we have to train our model to predict. So we need not include the same in our analysis.","c1169463":"### Feature Scaling\n","45b86923":"Now, let us have a final comparison among all forms of interpolation, before deciding upon one.","42d6d5e6":"Since, the maximum repeated observation is `S`, hence we replace the missing data points with the same.","13d866d8":"#### Plotting Survival based on Age and Sex.","ad5fb606":"So, now that we have filled in missing values, let us move on to Exploratory Data Analysis.","ca4e97d0":"This looks like a relatively normal distribution. Let us finalize our choice by creating a new feature `FareNorm`.","038b058f":"## Fare","f53f6f7c":"Let us now see if there is any similar dependence on the basis of age.\n\nHowever, since `Age` is a numeric field, we need to divide it into Categories to derive any meaningful correlation. \n","59949a67":"#### Encoding Title Column","ac4bf942":"As observed, children and middle-aged people have better chances of survival as compared to passengers in their youth and adulthood years, followed by the least possibility for senior citizens. \n\nLet us now observe, using the actual numeric data, the statistics of survival based on age.","751a4114":"## Age\n","cdb36464":"### Extracting Title From Name","be0d20ca":"# Model Building ","25776322":"Let us check this field for outliers.","717e0ccb":"Now, for the `Cabin` field, there are more values missing than present, which is why we can't draw meaningful inference from the same. So, we fill missing values with a random character, let's say, `X`. ","d393feb5":"This bears a similarity to `SibSp`, and is thus better left as it is. \n","ff4359fc":"Now, the `Name`, `PassengerId` & `Ticket` columns aren't of much use, and can be dropped to reduce space of the workable dataset.","0aecefdb":"# Submission","cfa3b759":"Thus, in categorical data, we have 5 columns, consisting of the following : \n\n - `Name` : Full Name of the passengers, including their family name and title, etc. \n \n - `Sex` : Biological Seggregation into the sexes, which would either be male or female (taking into account the divisions relevant in the earlier Twentieth Century).\n \n - `Ticket` : Ticket No. of the passenger.\n \n - `Cabin` : Cabin No. of the passenger. \n \n - `Embarked` : Port from where passenger embarked.\n \n As such, `Name` and `Ticket` arguably have very little to say regarding the possibility of survival. However, these could potentially give us a better idea regarding socio-economic status, similar to `Pclass`, speaking of which, as one would recall, is a categorical field already encoded with numeric data.\n ","e2c26608":"Now let us look at numeric data, each column at a time.\n","6c6ab178":"### SibSp","414e3a0e":"We can thus conclude that the fields 'Age' and 'Cabin' have null values, which may lead to lack of adequate data for logistic regression, and hence need to be dropped \/ interpolated \/ autocompleted. The decision regarding the course of action depends upon the type of feature and its relative influence on the classifier. \n\nFirst, let us determine the type of data.","f6fefbc0":"### Other Interpolation Methods","56810c82":"Thus, we conclude that among numeric data-types, the field `Age` has 177 null values. \nLet us try to _analyse_ different methods to fill missing data.","f7c80ab1":"Let us now compute probability of survival on the basis of `Fcount`.","717dfda1":"Thus, there are a lot of outliers in `Parch`. As such, these need to be dealt with. \n\nLet us now move on to our final numeric column, i.e `Fare` which denotes the passenger fare. \n","174c9a41":"We observe that two fields, namely `Cabin` and `Embarked` have null values. While `Embarked` has comparatively negligible null values, `Cabin` has a significant proportion of null values. Let us look at the value count of each of these fields.\n","e5f270b1":"From the above data, cube root normalization method seems to offer the best fit, with non-negative minimum value, relatively lower thresholds, and closeness of mean and median, which suggests a relatively normal distribution. ","2b98457d":"Let us fill missing values with median, as it is more robust to outliers than mean.\n","231812af":"Although the Cube Root Normalization seemingly solves our problems, it fails to render a proper normal distribution, and hence, we need to explore this facet a bit more.\n","17b71d2e":"#### Plotting based on Pclass, Embarked and Sex.","85a062e3":"This method again fails with outliers below the lower limit.","154fb56b":"First, let us apply feature scaling to age and check our observations.","8f97679a":"Let us look at missing Numeric data columnwise.","578f3646":"#### Encoding Embarked Column\n","edf6e86b":"# Dataset Overview\n","e0e817a9":"The data appears to be quite trivial, with the interquartile ranges concentrated around zero and a relatively high concentration of outliers. Let us look at histogram of the corresponding data.","15906293":"### Stripping Cabin No.","46937e6e":"Hence, we see that the results of the `spline` and `quadratic` interpolation methods are quite similar as compared to the default method. Some noticeable features are the presence of outliers in either direction in the non-default plot options, while the default plot had outliers above the upper limit only.\n\nHaving tested three of the given methods, let us formulate the results from the other methods and have a comparison. ","22861fd3":"Although this preserves the normal distribution properties of the data, it fails dealing with outliers below the lower limit.","73a55ba1":"# Creating New Data","5067be0d":"Since the requirement of the problem is to predict whether a given passenger survives or not, we need to use a Binary Classifier. \n\nFor that purpose, we need the following : \n - Classification Model\n - Metrics to Calculate Accuracy\n ","70066020":"#### Scipy Box Transformation","6d72013a":"### Correlation of Absolute Values","9a2a6ee1":"We know, categorical data needs to be encoded in order to have meaningful implication for the classifier.\n\nThe data-columns that need to be encoded include - \n\n - `Sex`, \n - `Embarked`, \n - `Title`, \n - `Cab`","77c2a80c":"Although we wouldn't be too concerned with outliers in the test phase, these operations need to be repeated in order to bear similarity in results with the training set.","8fffcf0d":"# Encoding Categorical Data","a1d1cd59":"#### Finalizing Choice","d50679ec":"### Parch","dbd0ce4d":"# Introduction","cba80b30":"## Dropping Unwanted Columns","0e4a7ac8":"Let us begin by analysing the `Age` column. From the degree of closeness of mean and median, we can assume the same to be a Gaussian (Normal) Distribution. Let's see if our assumption is correct.","4497835f":"This again does a pretty good job at retaining the normal distribution. ","28a34731":"It appears that indeed our assumption was correct, the scaled features retain the normal distribution properties of the original data.\n\nLet us check other methods of handling outliers, i.e, if they can do a better job at addressing outliers while preserving the normal distribution of the original data.","3d08ff75":"Since `Parch` and `SibSp` denote similar data, with regard to family members of the passenger aboard the vessel, they could be combined algebraically to obtain new data.","3c1f5c4b":"Thus, we can infer that the `2nd order spline` interpolation method bears the closest similarity to the original dataset statistically, albeit the inclusion of new extremes and some outliers. However, there are some trivial data-points, such as negative age. So, we go for the next **feasible** closest distribution, which would be default `interpolate()` method. \n","cde2db4b":"As observed in the previous section, the fields `Age`, `SibSp`, `Parch` and `Fare` have their fair share of outliers which need to be addressed before training the model. Let us proceed with the same for individual columns, starting with `Age`.\n\n","33895a95":"#### Plotting based on Pclass and Age","ba9ab6af":"## Encoding Categorical Data","807e581c":"On average, females appear to have higher chances of survival as compared to males. \n\n","2546254b":"## Handling Outliers","37824daf":"### Correlation\n","e563fac2":"## Categorizing Data","fff5dda5":"Let us have a brief run-down of all the available methods and then compare the statistical figures.","0c856596":"#### Encoding Cab Column","79c1d079":"Now, we need to perform the same operations on the test set as we did for the training set so that we're dealing with similar types and scales of data in the training and test phases. \n\nLet us look at the data first.","66011df0":"As observed, the `Name` column contains the Titles conferred in those times. Let us try and extract the titles using regular expression.","17bbd1a0":"As observed, this doesnot do a very good job at handling outliers, however, it should preserve the property of normal distribution of the original data. Let's check our assumption with a histogram plot of the same. \n","fcd6e98c":"The sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this notebook, we aim to study the influence of various factors and their correlations and their impact on the chances of survival. ","187b4557":"## Missing Numeric Data","8c74c57a":"Now, let us check for outliers for the same.","c4853bf4":"Here's what the data looks like. ","55a2007d":"## Missing Categorical Data","50e39b0a":"Thus, this fairly looks like the characteristic Bell-shaped curve of gaussian distribution. From the previous comparison of interpolation methods, we know this field has it's fair share of outliers. We will deal with the same in the later portions of this notebook.","63549b5b":"#### Plotting based on Pclass and Embarked","c75431f8":"# Handling Missing Data","cfb97a66":"Since `X` was our interpolation to fill missing data, no useful inference can be drawn.","e274928b":"## Handling Missing Data","570d6fad":"Regardless of ticket class, chances of possibility of females are higher regardless.\n\nLet us now compare statistics for `Pclass` and `Embarked`","b29ec195":"# Performing Operations on Test Set","65d36f89":"From the given representation, we can infer that higher the class of the Ticket, higher are the passenger's chances of survival. \n\nLet's now see the correlation patterns between the sexes.","121f3e26":"Now, let us move on to `Pclass` and `Sex`, to see how socio-economic status influences the gender-bias with regard to possibility of survival. ","5f34744f":"From the observations, we can infer that higher the order of polynomial in the interpolation method, more do we get outliers on far-ends of either limits. So, we cannot opt for interpolation methods using a higher order polynomial.\n\nLet us look at another method, `fillna()` to fill in missing values using some constant value.\n","0f3a20a6":"Let us have a look at the dataset again.\n","d2409fe4":"## Name, Ticket and Cabin","e21ff9cf":"Hence, we observe that the highest possibility of survival is for passengers with 3 family members.","98fefd38":"For now, let us move on to `SibSp` column, which contains the number of siblings and\/or spouse aboard the Titanic. Since mean and median are relatively far apart, we do not expect this to be a Gaussian Distribution.\n","5142bcd4":"Columns `SibSp` and `Parch` are quite similar features, with a fairly large number of outliers (as observed before). But first let's study their value counts. ","3139cfe7":"As concluded from the data, Passengers boarding the ship from the port of Southampton (`S`), had the least chances of survival. The disparity clearly exists among different classes of passengers, except for Queenstown.","40041fdd":"## SibSp and Parch","a7f33617":"The survivability with age decreases with decreasing socio-economic status.","5094693d":"## Parch and SibSp","51957b5b":"Thus, the category-wise division of column headers is : \n\n**Categorical Data :**\n - `Name`\n - `Sex` \n - `Ticket`\n - `Cabin`\n - `Embarked`\n \n**Numeric Data :**\n - `PassengerId`\n - `Survived` \n - `Pclass` \n - `Age`\n - `SibSp`\n - `Parch`\n - `Fare`","4366e0d0":"#### Encoding Sex Column","7c7a7e58":"# Outlier Handling","9ba37295":" - Thus, `Pclass` is merely categorical data labelled in integer form.","a0fd93ae":"Now, let us see the implications of both `Age` and `Sex`.","261e1f01":"## Correlation Among Features : \n","a31d322f":"## Studying Correlations","16a07f2f":"As such, the range of values isn't too high to consider feature scaling. So, let us check other methods. ","22c8b004":"### Stripping Ticket No.","ffc24478":"So, it preserves the normal distribution as well as handles outliers in an effective way. So, box transformation seems the way to go.\n\n","ab6ddc30":"#### Plotting Survival based on Pclass and Sex.","9fd43a1a":"So, the field `Fare` also has a relatively high proportion of outliers which need to be dealt with as well. \nAll of this, along with other columns containing outliers, would be addressed in the next sections.","8853441c":"## Creating New Features"}}