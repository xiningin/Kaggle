{"cell_type":{"a3429ec6":"code","99fdc409":"code","eb66900a":"code","444514c7":"code","69ff64e4":"code","52e26d9c":"code","912f281a":"code","fa3561b2":"code","4400a66c":"code","ed5f9566":"code","5d380f59":"code","092ece13":"code","64e52eb4":"code","662c787b":"code","70cf52b3":"code","d7252bb2":"code","dd1a74e1":"code","e5318ee9":"code","036a9b9c":"code","1328f59f":"code","e87ca802":"code","584ff86f":"code","7bbb7ab3":"code","2d50118a":"code","0cb089ca":"code","cc607271":"code","8bae826c":"code","a238fd95":"code","8e0dd030":"code","6f962cff":"code","906a6aa1":"code","91bfb005":"code","f3ee8505":"markdown","6f1d8346":"markdown","a8f68d39":"markdown","a6fe9c3a":"markdown"},"source":{"a3429ec6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99fdc409":"# nltk for English text recognition\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('punkt')\nimport pandas as pd","eb66900a":"# load data (dataframe)\ndata = pd.read_csv('\/kaggle\/input\/dealed-eng\/recogniton-eng.csv')\ndata.head()","444514c7":"# \u5bf9data\u7684\u6bcf\u4e00\u53e5\u8bdd\u8fdb\u884c\u5206\u8bcd,\u5e76\u53bb\u6389\u505c\u7528\u8bcd\ndisease_List = [nltk.word_tokenize(sentence) for sentence in data.text]      #\u5206\u8bcd\nfiltered = [w for w in disease_List if(w not in stopwords.words('english'))] #\u53bb\u9664\u505c\u7528\u8bcd\nfiltered[0]","69ff64e4":"# \u5bf9filtered \u6bcf\u53e5\u8bdd\u7684\u8bcd\u8fdb\u884c\u8bcd\u6027\u5206\u6790\nR = []\nfor i,x in enumerate(filtered):\n    R.append(nltk.pos_tag(x)) #\u8fdb\u884c\u8bcd\u6027\u5206\u6790\nR[0]","52e26d9c":"# \u5bf9R\u4e2d\u8bcd\u6c47\u7559\u4e0b\u4e13\u6709\u540d\u8bcd\uff08NNP\uff09\uff0c\u540d\u8bcd\uff08NP\uff09\uff0c\u5f62\u5bb9\u8bcd\uff08ADJ\uff09\nRn = []\nfor sentence in R:\n    Rn1 = []\n    for x,y in sentence:\n        if y == 'NNP' or y == 'NN' or y =='ADJ':\n            Rn1.append(x)\n    Rn.append(Rn1)\nRn[0]","912f281a":"# \u5c06\u5904\u7406\u540e\u7684\u6570\u636e\u8f6c\u5316\u6210\u6570\u636e\u6846\nnewfile = {'type':data.type, 'word' : Rn}\ndata_new = pd.DataFrame(newfile)\ndata_new.head()","fa3561b2":"# \u5bfc\u51fa\u5904\u7406\u540e\u7684\u6570\u636e   \uff1f\uff1f\uff1f\ndata_new.to_csv('\/kaggle\/working\/eng_new.csv')","4400a66c":"# \u6570\u636e\u5206\u7c7b\ndata_1 = data_new[data_new.type == 111]\ndata_2 = data_new[data_new.type == 222]\ndata_3 = data_new[data_new.type == 333]\ndata_4 = data_new[data_new.type == 444]","ed5f9566":"# \u5bfc\u5165TF\u2014IDF\u7b97\u6cd5\u9700\u8981\u7684\u5305\nfrom collections import defaultdict\nimport math\nimport operator","5d380f59":"# \u521b\u5efa\u7b97\u6cd5\u51fd\u6570\n\"\"\"\n\u51fd\u6570\u8bf4\u660e\uff1a\u7279\u5f81\u9009\u62e9TF-IDF\u7b97\u6cd5\nParameters:\n     list_words:\u8bcd\u5217\u8868\nReturns:\n     dict_feature_select:\u7279\u5f81\u9009\u62e9\u8bcd\u5b57\u5178\n\"\"\"\ndef feature_select(list_words):\n    #\u603b\u8bcd\u9891\u7edf\u8ba1\n    doc_frequency=defaultdict(int)\n    for word_list in list_words:\n        for i in word_list:\n            doc_frequency[i]+=1\n \n    #\u8ba1\u7b97\u6bcf\u4e2a\u8bcd\u7684TF\u503c\n    word_tf={}  #\u5b58\u50a8\u6ca1\u4e2a\u8bcd\u7684tf\u503c\n    for i in doc_frequency:\n        word_tf[i]=doc_frequency[i]\/sum(doc_frequency.values())\n \n    #\u8ba1\u7b97\u6bcf\u4e2a\u8bcd\u7684IDF\u503c\n    doc_num=len(list_words)\n    word_idf={} #\u5b58\u50a8\u6bcf\u4e2a\u8bcd\u7684idf\u503c\n    word_doc=defaultdict(int) #\u5b58\u50a8\u5305\u542b\u8be5\u8bcd\u7684\u6587\u6863\u6570\n    for i in doc_frequency:\n        for j in list_words:\n            if i in j:\n                word_doc[i]+=1\n    for i in doc_frequency:\n        word_idf[i]=math.log(doc_num\/(word_doc[i]+1))\n \n    #\u8ba1\u7b97\u6bcf\u4e2a\u8bcd\u7684TF*IDF\u7684\u503c\n    word_tf_idf={}\n    for i in doc_frequency:\n        word_tf_idf[i]=word_tf[i]*word_idf[i]\n \n    # \u5bf9\u5b57\u5178\u6309\u503c\u7531\u5927\u5230\u5c0f\u6392\u5e8f\n    dict_feature_select=sorted(word_tf_idf.items(),key=operator.itemgetter(1),reverse=True)\n    return dict_feature_select\n ","092ece13":"# \u5f97\u5230\u56db\u7c7b\u7279\u5f81\u5411\u91cf\uff0c\u6bcf\u4e00\u4e2a\u8bcd\u8bed + TF-IDF\u503c\nfeature_1 = feature_select(data_1.word)\nfeature_2 = feature_select(data_2.word)\nfeature_3 = feature_select(data_3.word)\nfeature_4 = feature_select(data_4.word)","64e52eb4":"feature_1[0:11]","662c787b":"# \u8f93\u51fa\u56db\u7c7b\u8bc4\u8bba \u7279\u5f81 \u4e2a\u6570\nprint(len(feature_1),len(feature_2),len(feature_3),len(feature_4))","70cf52b3":"# \u8f93\u51fa\u56db\u7c7b\u7279\u5f81\u6bd4\u4f8b\nnumword = np.array([len(feature_1),len(feature_2),len(feature_3),len(feature_4)])\nrateword = numword\/sum(numword)\nprint(rateword)","d7252bb2":"# \u56db\u7c7b\u7279\u5f81\u6570\nnumfeature = np.around(rateword * 100)\nprint(numfeature)","dd1a74e1":"# \u63d0\u53d6 \u7279\u5f81 \nfeature_sport = feature_1[0:int(numfeature[0])]\nfeature_elec = feature_2[0:int(numfeature[1])]\nfeature_military = feature_3[0:int(numfeature[2])]\nfeature_medical = feature_4[0:int(numfeature[3])]","e5318ee9":"# \u603b\u7279\u5f81 \u6570\u636e\u6846  0 \uff1a\u7279\u5f81   1\uff1a TF-IDF\u503c\nfeature = []\nfeature = feature_sport + feature_elec + feature_military + feature_medical\nfeature = pd.DataFrame(feature)\nfeature.head()","036a9b9c":"# \u521b\u5efa\u6bcf\u4e00\u53e5\u8bdd\u7684\u7279\u5f81\u5411\u91cf\n\"\"\"\n\u51fd\u6570\u8bf4\u660e\uff1a\u751f\u6210\u6bcf\u6761\u8bc4\u8bba\u7684\u7279\u5f81\u5411\u91cf\nParameters:\n        data.text\uff1a\u8bc4\u8bba\u6570\u636e\u6587\u672c\n        feature.iloc[:,0]\uff1a\u7279\u5f81\nReturns:\n     feature_vector\uff1a\u7279\u5f81\u5411\u91cf\uff0c1\u8868\u793a\u6709\u6b64\u7279\u5f81\uff0c0\u8868\u793a\u6ca1\u6709\u6b64\u7279\u5f81\n\"\"\"\n\ndef feature_vector():\n    \n    feature_vector = []\n    for n,y in enumerate(data.text):\n        vector = []\n        for i,x in enumerate(feature.iloc[:,0]):\n            if x in y:\n                vector.append(1)\n            else:\n                vector.append(0)\n        feature_vector.append(vector)  \n    \n    return feature_vector\n\nfeature_vec = feature_vector()","1328f59f":"# \u751f\u6210\nfeavec_all = pd.DataFrame(feature_vec)","e87ca802":"# \u52a0\u4e0a\u7c7b\u522b\u6570\u636e\nfeavec_all['type'] = data.type","584ff86f":"# \u5c06\u7279\u5f81\u5411\u91cf + \u7c7b\u522b\u6807\u7b7e  \u751f\u6210\u65b0csv\u6587\u4ef6\nfeavec_all.to_csv('\/kaggle\/working\/feature_vector.csv')","7bbb7ab3":"feavec = pd.read_csv('\/kaggle\/working\/feature_vector.csv')\n# \u5206\u5272\u6570\u636e\u96c6\u4e3a \u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff084:1\uff09\nfrom sklearn.model_selection import train_test_split\n#data:\u9700\u8981\u8fdb\u884c\u5206\u5272\u7684\u6570\u636e\u96c6\n#random_state:\u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\uff0c\u4fdd\u8bc1\u6bcf\u6b21\u8fd0\u884c\u751f\u6210\u76f8\u540c\u7684\u968f\u673a\u6570\n#test_size:\u5c06\u6570\u636e\u5206\u5272\u6210\u8bad\u7ec3\u96c6\u7684\u6bd4\u4f8b\ntrain_set, test_set = train_test_split(feavec, test_size=0.2, random_state=42)","2d50118a":"train_set.head()","0cb089ca":"x_train, y_train = train_set.iloc[:,1:101], train_set.iloc[:,101]\nx_test, y_test = test_set.iloc[:,1:101], test_set.iloc[:,101]","cc607271":"# \u8bad\u7ec3\nfrom sklearn.linear_model import LogisticRegression\n\n# \u8bad\u7ec3\nlog_model = LogisticRegression(multi_class=\"ovr\", solver=\"newton-cg\", max_iter=1000)  # 1vs1 multinomial\nlog_model.fit(x_train,y_train)\n","8bae826c":"from sklearn.metrics import accuracy_score, recall_score\npred_test = log_model.predict(x_test)\nacu = accuracy_score(y_test, pred_test)  # \u51c6\u786e\u7387\nrecall = recall_score(y_test, pred_test, average=\"macro\")  # \u53ec\u56de\u7387\n","a238fd95":"print(acu,recall)","8e0dd030":"recall","6f962cff":"from sklearn import neighbors\nscore = []\nfor k in range(1,21):\n    clf = neighbors.KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n    clf.fit(x_train, y_train)\n    score.append(clf.score(x_test,y_test))\n","906a6aa1":"import matplotlib.pyplot as plt\nplt.plot(score)","91bfb005":"score[1]","f3ee8505":"## \u9009\u62e9KNN\u6a21\u578b\u8bad\u7ec3","6f1d8346":"TF-IDF\u65b9\u6cd5\u5f15\u7528[\u535a\u5ba2\uff1aTF-IDF\u7b97\u6cd5\u4ecb\u7ecd\u53ca\u5b9e\u73b0](https:\/\/blog.csdn.net\/asialee_bird\/article\/details\/81486700)\uff0c\u8be6\u60c5\u8bf7\u81ea\u884c\u67e5\u770b\n","a8f68d39":"## \u9009\u62e9\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u65b9\u6cd5","a6fe9c3a":"# \u5206\u7c7b\u6a21\u578b\n> \u7f3a\u5931\u4ea4\u53c9\u9a8c\u8bc1"}}