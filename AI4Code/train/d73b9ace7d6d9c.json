{"cell_type":{"afc5054c":"code","ea51ef9f":"code","1ac8feac":"code","deba1cb0":"code","adbf30a9":"code","f19e86a2":"code","60957005":"code","2f26c91d":"code","0d6a0ac6":"code","37bf542b":"code","a38cc2eb":"code","96ebf83d":"code","b2b27a8e":"code","fa0b3624":"code","47f08200":"code","9fbba170":"code","0270f909":"code","2544a861":"code","006bdf85":"code","a394587b":"code","36e23ff8":"code","d4bc6f1d":"markdown","595d3bfa":"markdown","c21cc0a0":"markdown","dfa1246c":"markdown","35cd69b7":"markdown","c21464cc":"markdown","a106c393":"markdown","1fb41ecf":"markdown","a453e3ff":"markdown","8c91c6b6":"markdown","6b286828":"markdown","425e5841":"markdown","2ae655b0":"markdown"},"source":{"afc5054c":"# Import libraries\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler","ea51ef9f":"# Import dataset\ntrain_df=pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')","1ac8feac":"def downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df","deba1cb0":"train_df.info()","adbf30a9":"train_df=downcast_dtypes(train_df)","f19e86a2":"train_df.info()","60957005":"train_df","2f26c91d":"train_df = train_df.T","0d6a0ac6":"train_df = train_df[6:] # because we need only sales ","37bf542b":"train_df","a38cc2eb":"sc = MinMaxScaler(feature_range = (0, 1))\ntrain_df = sc.fit_transform(train_df)","96ebf83d":"timesteps=14\nX_train = []\ny_train = []\nfor i in range(timesteps, 1913):\n    X_train.append(train_df[i-timesteps:i])\n    y_train.append(train_df[i][0:30490]) ","b2b27a8e":"X_train = np.array(X_train, dtype = 'float16')\ny_train = np.array(y_train, dtype = 'float16')","fa0b3624":"X_train.shape,y_train.shape","47f08200":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.LSTM(units =64,input_shape = (np.array(X_train).shape[1], np.array(X_train).shape[2])))\nmodel.add(tf.keras.layers.Dense(30490))\n\nmodel.compile(\n  loss='mean_squared_error',\n  optimizer=tf.keras.optimizers.Adam(0.001)\n)\nmodel.summary()","9fbba170":"model.fit(X_train, y_train, epochs = 10, batch_size = 10)","0270f909":"inputs= train_df[-timesteps:]\ninputs = sc.transform(inputs)","2544a861":"inputs","006bdf85":"X_test=[]\nX_test.append(inputs[0:timesteps])\nX_test = np.array(X_test)","a394587b":"predictions=model.predict(X_test)","36e23ff8":"predictions","d4bc6f1d":"## Test Data","595d3bfa":"![image.png](attachment:image.png)","c21cc0a0":"## Reduce memory size","dfa1246c":"## Dataset Creation","35cd69b7":"I am using Tensorflow LSTM model. The Model has one LSTM layer and one dense layer. If you wanted to know about LSTM you can refer to  this blog http:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs\/ ","c21464cc":"### After Downcasting ","a106c393":"# Time Series Forecasting using LSTM\n\nIn the challenge, We have given Sales from day1 to day1913 and we have to predict sales from day14 to day1941( next 28 days sales)","1fb41ecf":"## Model Creation ","a453e3ff":"### data scaling","8c91c6b6":"![image.png](attachment:image.png)","6b286828":"### Take Transpose of dataset","425e5841":"### Before Downcasting","2ae655b0":"### Generating X_train , Y_train"}}