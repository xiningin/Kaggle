{"cell_type":{"a5b97237":"code","db99f13d":"code","8ce203e9":"code","03f4f4cc":"code","1b40b61a":"code","e79e49d2":"code","8539a572":"code","00b638ad":"code","f93d3447":"code","af37c48d":"code","392bb6c6":"code","e049a6bf":"code","ae691a1b":"code","e06a7c4f":"code","5a66c5a6":"code","79d27bad":"code","149db1a7":"code","557f5284":"code","7577a081":"code","60cc204e":"code","5f2eea0d":"code","623db624":"code","cf4f2ceb":"code","070b8d9b":"code","67c7ada1":"code","40d9f4f1":"code","218ac02e":"code","f93ae7e5":"code","626cede0":"code","0f0cb632":"code","b58807f5":"code","80d80ef1":"code","158277ff":"code","31194d83":"code","ef048fb0":"code","43e7e739":"code","4175b8e6":"code","d72d72f9":"code","76832eaf":"code","49780b88":"code","b4a196c8":"code","e7f6e2e0":"code","5d622182":"code","be765b96":"code","7958802a":"code","76643114":"code","9ea17241":"code","54ed54d8":"code","eb8bc178":"code","c97fd062":"code","7375040a":"code","12da50b5":"code","0e77bcd8":"code","98082019":"code","4beaef67":"code","d7ad627c":"code","2e4f37f8":"code","089053cc":"code","6b955e3a":"markdown","ee44dc52":"markdown","ad79f40f":"markdown","db8f7223":"markdown","dabecefb":"markdown","b48af7b2":"markdown","e2bbe4da":"markdown","27561b4c":"markdown","0d64711c":"markdown","0f0b41dd":"markdown","9001c35e":"markdown","5177702d":"markdown","aec61659":"markdown","d5fe8f68":"markdown","13471fae":"markdown","903238ad":"markdown","af82231b":"markdown","477ade04":"markdown","e832ecd0":"markdown","712720de":"markdown","ae246647":"markdown","f283eb20":"markdown","a489090b":"markdown","688a897e":"markdown","d1f0e982":"markdown","c8d92706":"markdown","4d073fa0":"markdown","ee42be30":"markdown","494c9f19":"markdown","44863f87":"markdown","446233c4":"markdown","0fac5928":"markdown","59821b62":"markdown","f9a72e1b":"markdown","3d5c3a79":"markdown","9d3da6d3":"markdown","d2306d31":"markdown","111e16e8":"markdown","3cd56362":"markdown","a3869537":"markdown","60825d2b":"markdown","2cc600f7":"markdown","abd7581d":"markdown","b8178f0c":"markdown","8f5bd8e5":"markdown","87da5423":"markdown","464115d4":"markdown","05774b36":"markdown"},"source":{"a5b97237":"#Import packages \/libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nfrom math import sqrt\n\n#Modeling\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\nfrom fbprophet import Prophet\n\n#Evaluation\nfrom sklearn.metrics import mean_squared_error\nfrom fbprophet.diagnostics import performance_metrics\nfrom fbprophet.diagnostics import cross_validation\nfrom fbprophet.plot import plot_cross_validation_metric\n\n#Menghilangkan warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","db99f13d":"#Melihat data yang ada di directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8ce203e9":"#Load semua data\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nsales = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsubmission = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv') #ini kita tidak pakai, karena hanya untuk input kompetisi\ncategory = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')","03f4f4cc":"#Mengabungkan semua data\ndata_1 = pd.merge(items, sales, on='item_id', how='inner')\ndata_2 = pd.merge(data_1, shops, on='shop_id', how='inner')\ndata = pd.merge(data_2, category, on='item_category_id', how='inner')","1b40b61a":"#Melihat sekilas data yang telah digabung\ndata.head()","e79e49d2":"#Melihat info pada data \ndata.info()","8539a572":"#Merubah tipe data kolom item_cnt_day menjadi integer, karena inputnya adalah berapa barang yang terjual\ndata['item_cnt_day'] = data.item_cnt_day.astype('int')","00b638ad":"#Merubah kolom date menjadi index dan merubah tipe datanya menjadi date\ndata['date'] = pd.to_datetime(data.date)\ndata =  data.sort_values('date').reset_index(drop=True)","f93d3447":"#Melihat kembali dataset kita apakah kolom date sudah sesuai\ndata.head()","af37c48d":"#Melihat apakah ada input yang kosong pada data kita\ndata.isnull().sum() \/len(data) *100","392bb6c6":"#Membuat kolom total_sales untuk melihat revenue \/ pendapatan perhari\ndata['total_sales'] = data['item_price'] * data['item_cnt_day']\ndata.head()","e049a6bf":"#Kita akan menggunakan Inter Quartile Range untuk menangani outliers\n#Menentukan Limit\ndef limit(i):\n    Q1,Q3 = np.percentile(data[i] , [25,75])\n    IQR = Q3 - Q1\n    \n    #menentukan upper limit biasa dan upper limit ekstim\n    lower_limit = Q1 - (IQR * 1.5)\n    lower_limit_extreme = Q1 - (IQR * 3)\n    upper_limit = Q3 + (IQR * 1.5)\n    upper_limit_extreme = Q3 + (IQR * 3)\n    print('Lower Limit:', lower_limit)\n    print('Lower Limit Extreme:', lower_limit_extreme)\n    print('Upper Limit:', upper_limit)\n    print('Upper Limit Extreme:', upper_limit_extreme)\n\n#Mengitung persen outliers dari data    \ndef percent_outliers(i):\n    Q1,Q3 = np.percentile(data[i] , [25,75])\n    IQR = Q3 - Q1\n    \n    #menentukan upper limit biasa dan upper limit ekstim\n    lower_limit = Q1 - (IQR * 1.5)\n    lower_limit_extreme = Q1 - (IQR * 3)\n    upper_limit = Q3 + (IQR * 1.5)\n    upper_limit_extreme = Q3 + (IQR * 3)\n    #melihat persenan outliers terhadap total data\n    print('Lower Limit: {} %'.format(data[(data[i] >= lower_limit)].shape[0]\/ data.shape[0]*100))\n    print('Lower Limit Extereme: {} %'.format(data[(data[i] >= lower_limit_extreme)].shape[0]\/data.shape[0]*100))\n    print('Upper Limit: {} %'.format(data[(data[i] >= upper_limit)].shape[0]\/ data.shape[0]*100))\n    print('Upper Limit Extereme: {} %'.format(data[(data[i] >= upper_limit_extreme)].shape[0]\/data.shape[0]*100))","ae691a1b":"#Melihat outliers pada kolom item_price\nsns.boxplot(x=data[\"item_price\"])","e06a7c4f":"#Melihat apakah ada harga item yang 0 atau minus. Karena jika ada ini merupakan sebuah kesalahan\ndata[data['item_price'] <= 0].count()","5a66c5a6":"#Menghilangkan input yang <= 0\ndata = data[data['item_price'] > 0]","79d27bad":"#Melihat IQR dari kolom item_price\nprint(limit('item_price'))\nprint('-'*50)\nprint(percent_outliers('item_price'))","149db1a7":"#Melihat outliers pada kolom item_cnt_day\nsns.boxplot(x=data[\"item_cnt_day\"])","557f5284":"#Melihat IQR pada kolom itm_cnt_day\nprint(limit('item_cnt_day'))\nprint('-'*50)\nprint(percent_outliers('item_cnt_day'))","7577a081":"#Mengecek apakah ada item yang dijual dalam jumlah 0 atau kurangdari 0, karena jika ada itu merupakan kesalahan\n#Karena tida kmungkin item dijual dengan jumlah 0 (karena kita hanya mengambil yang laku) atau bahkan minus\ndata[data['item_cnt_day'] <= 0].count()","60cc204e":"#Menghilangkan input yang <= 0\ndata = data[data['item_cnt_day'] > 0]","5f2eea0d":"#Produk apa yang paling laris?\ntop_10_product_best_seller = data.groupby(['item_name'])['item_cnt_day'].sum().sort_values(ascending=False)[:10]\n\n#Visualisasi \nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_product_best_seller.index,x=top_10_product_best_seller.values)\nplt.title('Top 10 Most Selling Items',fontsize=20)\nplt.xlabel('Total Product Sold',fontsize=17)\nplt.ylabel('Item Name',fontsize=17)","623db624":"top_10_product_best_seller","cf4f2ceb":"#Produk apa yang paling tidak laris?\ntop_10_product_least_seller = data.groupby(['item_name'])['item_cnt_day'].sum().sort_values(ascending=True)[:10]\n\n#Visualisasi \nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_product_least_seller.index,x=top_10_product_least_seller.values)\nplt.title('Top 10 Least Selling Items',fontsize=20)\nplt.xlabel('Total Product Sold',fontsize=17)\nplt.ylabel('Item Name',fontsize=17)","070b8d9b":"#Toko apa yang paling laris?\ntop_10_seller = data.groupby(['shop_name'])['item_cnt_day'].sum().sort_values(ascending=False)[:10]\n\n#Visualisasi \nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_seller.index,x=top_10_seller.values)\nplt.title('Top 10 Most Selling Shop',fontsize=20)\nplt.xlabel('Total Product Sold',fontsize=17)\nplt.ylabel('Shop Name',fontsize=17)","67c7ada1":"top_10_seller","40d9f4f1":"#Toko apa yang paling tidak laris?\ntop_10_least_seller = data.groupby(['shop_name'])['item_cnt_day'].sum().sort_values(ascending=True)[:10]\n\n#Visualisasi \nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_least_seller.index,x=top_10_least_seller.values)\nplt.title('Top 10 Least Shop',fontsize=20)\nplt.xlabel('Total Product Sold',fontsize=17)\nplt.ylabel('Shop Name',fontsize=17)","218ac02e":"top_10_least_seller","f93ae7e5":"#Toko apa yang paling laris?\ntop_10_seller = data.groupby(['shop_name'])['total_sales'].sum().sort_values(ascending=False)[:10]\n\n#Visualisasi\nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_seller.index,x=top_10_seller.values)\nplt.title('Top 10 Shop Revenue',fontsize=20)\nplt.xlabel('Total Revenue',fontsize=17)\nplt.ylabel('Shop Name',fontsize=17)","626cede0":"top_10_seller","0f0cb632":"#Toko apa yang paling laris?\ntop_10_seller = data.groupby(['shop_name'])['total_sales'].sum().sort_values(ascending=True)[:10]\n\n#Visualisasi\nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_seller.index,x=top_10_seller.values)\nplt.title('Top 10 Least Shop Revenuw',fontsize=20)\nplt.xlabel('Total Revenue',fontsize=17)\nplt.ylabel('Shop Name',fontsize=17)","b58807f5":"top_10_seller","80d80ef1":"#kategori apa yang paling laris?\ntop_10_most_category = data.groupby(['item_category_name'])['item_cnt_day'].sum().sort_values(ascending=False)[:10]\n\n#Visualisasi 10 item paling laris\nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_most_category.index,x=top_10_most_category.values)\nplt.title('Top 10 Most Selling Category',fontsize=20)\nplt.xlabel('Total Product Sold',fontsize=17)\nplt.ylabel('Category Name',fontsize=17)","158277ff":"#kategori apa yang paling tidak laris?\ntop_10_least_category = data.groupby(['item_category_name'])['item_cnt_day'].sum().sort_values(ascending=True)[:10]\n\n#Visualisasi 10 item paling laris\nplt.figure(figsize=(16,9))\nsns.barplot(y=top_10_least_category.index,x=top_10_least_category.values)\nplt.title('Top 10 Least Selling Category',fontsize=20)\nplt.xlabel('Total Product Sold',fontsize=17)\nplt.ylabel('Category Name',fontsize=17)","31194d83":"#Merubah tipe data kolom date menjadi tipe date\ndata =  data.set_index('date')\ndata.head()","ef048fb0":"#Membuat data menjadi sebuah group dengan menghitung total sales setiap bulanya\ntrain_arima = data.resample(\"M\").sum() \nts_sales = train_arima[[\"total_sales\"]]\nts_sales.head()","43e7e739":"#Menghilangkan data setelah oktober 2015 karena data setelah oktober tidak relevan, hanya sedikit data yang diambil\nts_sales = ts_sales[ts_sales.index <= pd.to_datetime('2015-10-31')]","4175b8e6":"#Viasualisasi data\nplt.figure(figsize=(16,9))\nplt.title('Total Item of the company')\nplt.xlabel('Month')\nplt.ylabel('Item')\nplt.plot(ts_sales['total_sales'])","d72d72f9":"#Melihat apakah data kita stationary atau tidak dengan Dickey-Fuller Test\n#Membuat fungsi\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","76832eaf":"#Cek Stationary\ntest_stationarity(ts_sales['total_sales'])","49780b88":"#Visualisasi Trend dan Seasonlaity\nitem_cnt_dec = sm.tsa.seasonal_decompose(ts_sales['total_sales'],freq=12).plot()","b4a196c8":"#Visualisasi autocorrelation plot pada data item_cnt_day\nsales_acf = sm.graphics.tsa.plot_acf(ts_sales['total_sales'], lags=12)","e7f6e2e0":"#Visualisasi autocorrelation plot pada data item_cnt_day\nsales_acf = sm.graphics.tsa.plot_pacf(ts_sales['total_sales'], lags=12)","5d622182":"#Membuat nilai p,d,q dengan rentang 0 and 3\np = d = q = range(0, 2)\n\n#Membuat iterasi nilai p,dq\npdq = list(itertools.product(p, d, q))\n\n\n#Membuat seasonal dengan 12 bulan (karena yang paling terlihat \/ smooth)\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]","be765b96":"#Melakukan pencarian nilai p,d,q dengan parameter AIC, semakin rendah semakin baik\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(ts_sales['total_sales'],\n                                            order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=True,\n                                            enforce_invertibility=True)\n\n            results = mod.fit()\n\n            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue","7958802a":"#Kita masukkan kedalma model\nmod = sm.tsa.statespace.SARIMAX(ts_sales['total_sales'],\n                                order=(0,1,0),\n                                seasonal_order=(0, 1, 1, 12),\n                                enforce_stationarity=True,\n                                enforce_invertibility=True)\nresults = mod.fit()\nprint(results.summary().tables[1])","76643114":"results.plot_diagnostics(figsize=(16, 9))\nplt.show()","9ea17241":"#Melakukan prediksi dari bulan Desember 2014\npred = results.get_prediction(start=pd.to_datetime('2014-12-31'), dynamic=False)\npred_ci = pred.conf_int()","54ed54d8":"#Visualisasi prediksi\nax = ts_sales['2013-01-31':].plot(label = \"observed\", figsize=(16, 9))\npred.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.2)\n\nax.set_xlabel('Month')\nax.set_ylabel('Sales')\nplt.legend()\nplt.show()\n\ntrain_sarima_forecasted = pred.predicted_mean\ntrain_sarima_truth = ts_sales['2014-12-31':]\n\n#Menghiung RMSE\nrmse_sarima = sqrt(mean_squared_error(train_sarima_truth, train_sarima_forecasted))\nprint(\"Root Mean Squared Error: \", rmse_sarima)","eb8bc178":"#Prediksi 3 total sales 3 bulan kedepan\npred_uc = results.get_forecast(steps=3)\npred_ci = pred_uc.conf_int()\nax = ts_sales['2013-01-31':].plot(label='observed', figsize=(16, 9))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.2)\nax.set_xlabel('Date')\nax.set_ylabel('Amount of Sales')\nplt.legend()\nplt.show()","c97fd062":"#Reset index dulu untuk membuat date menjadi kolom\nts_sales = ts_sales.reset_index()\n#Pertama kita harus merubah dates menjadi ds dan total_sales menjadi y\nts_sales.rename(columns={'date':'ds','total_sales':'y'},inplace=True)","7375040a":"#Membuat prediksi dengan Prophet\nm_p = Prophet()\nm_p.fit(ts_sales)\nfuture = m_p.make_future_dataframe(periods = 3, freq = 'M')\nprediction = m_p.predict(future)\nprediction.tail(3)","12da50b5":"#Visualisai Prediksi\nm_p.plot(prediction)\nplt.show()","0e77bcd8":"#Visualisasi [Trends,Weekly]\nm_p.plot_components(prediction)\nplt.show()","98082019":"#Melakukan Crossvalidation dengan training data 720 (2 tahun), prediksi 120 (4 bulan) dan interval waktunya 240 (8 bulan)\ncv = cross_validation(m_p,initial='720 days', period='120 days', horizon = '240 days')","4beaef67":"#Melihat hasil cv\ncv.head()","d7ad627c":"#Melihat performance metrics\ndf_pm= performance_metrics(cv)\ndf_pm.head()","2e4f37f8":"#Visualiasi RMSE\nplot_cross_validation_metric(cv, metric='rmse')\nplt.show()","089053cc":"pred_ci","6b955e3a":"kita dapat melihat bahwa 95% data kita masuk kedalam confidence interval (area warna biru) sehingga bisa dikatakan data kita tidak memiliki autocorrelation. Kemudian dari data di atas bisa kita lihat bahwa nilai p dan q ada pada 1 atau 2","ee44dc52":"## 2.4 Exploratory Data Analysis\n\nSebelum masuk kedalama model, kita akan mencoba untuk mencari info-info apa yang menarik dari data yang kita miliki sperti item apa yang paling laku, toko mana yang paling laku, item apa yang paling mahal, toko mana yang pendapanya paling banyak, item apa yang paling tidak laku, dll. Mari kita cari info-info menarik!","ad79f40f":"## 2.3 Handling Outliers\n\nPada tahapan ini kita mencoba mencari anomali atau outliers pada data yang kita miliki dan menilai apakah outliers ini memang kesalah, wajar atau menag acak","db8f7223":"## **3.2 Trend& Seasonality**\n\nUntuk melihat apakah sebuah data memiliki trend yang cenderung naik atau turun dan juga melihat apakah ada siklus yang berulang pada waktu-waktu tertentu, contoh ketika setiap sebelum lebaran banyak orang yang belanja sehingga setiap waktu itu akan terjadi peningkatan penjualan. ","dabecefb":"# **1. KONTEKS**\n\nProject ini merupakan salah satu dari sebuah kompetisi di Kaggle. Datasetnya didapat dari penjualan produk pada perusahan di Rusia bernama 1C Company.\n\n* Tujuan: memprediksi penjualan \/ sales bulan selanjutnya\n* Data: \n\n    1. sales_train.csv (training set), data historis harian mulai dari Januari 2013 sampai Oktober 2015.\n    2. test.csv (test set) kita harus memprediksi set ini yaitu penjualan toko dan produk pada bulan November 2015.\n    3. sample_submission.csv - contoh hasil untuk dimasukkan ke dalam perlombaan\n    4. items.csv - informasi tambahan terkait item \/ produk\n    5. item_categories.csv - informasi tambahan terkait kategori item \/ produks \n    6. shops.csv- informasi tambahan terkait toko\n    \n \n* Detail Data:\n\n    1. ID - sebuah id untuk  toko dan item\n    2. shop_id - unique identifier untuk toko\n    3. item_id - unique identifier item \/ produk\n    4. item_category_id - unique identifier dari kategori itemnya\n    5. item_cnt_day - jumlah item yang terjual harian, namun kita akan memprediksi ini dalam bulanan (November 2015)\n    6. item_price - harga sebuah itemm\n    7. date - tangal\n    8. date_block_num - integer dari bulan pada kolom date untuk memudahkan, contoh: Januari 2013 itu 0, Februari 2013 itu 1, Oktober 2015 itu 33, dst\n    9. item_name - nama item \/ produk\n    10. shop_name - nama toko\n    11. item_category_name - nama kategori\n    \n\n* Metriks Evaluasi: Root Mean Squared Error (RMSE)\n\n* Manfaat: ada banyak sekali manfaat yang dapat diberikan dari prediksi ini, anatara lain,\n\n    1. Marketing: membuat promo berdasarkan season yang ada pada waktu sebuah item paling laku\n    2. Logistik: menyiapkan proses pengiriman agar tepat waktu\n    3. Sales: meningkatkan pendapatan dari produk-produk yang paling laku, untuk lebih dimaksimalkan Harga Pokok Produknya\n    4. Produksi: menyiapkan item sesuai dengan prediksi agar tidak terjadi kekurangan item saat high season atau dead stock saat low season","b48af7b2":"Bisa kita lihat, bahwa yang paling banyak penjualnya dalam hal jumlah adalah \"\u0424\u0438\u0440\u043c\u0435\u043d\u043d\u044b\u0439 \u043f\u0430\u043a\u0435\u0442 \u043c\u0430\u0439\u043a\u0430 1\u0421 \u0418\u043d\u0442\u0435\u0440\u0435\u0441 \u0431\u0435\u043b\u044b\u0439 (34*42) 45 \u043c\u043a\u043c\" sebanyak 187666. Jika dilihat di google ini adalah kantong kresek, jadi wajar saja jika dia adalah paling bannyak penjualnya dan juga perlu diingat kembali bahwa ini adalah data dari dari Januari 2013 sampai OKtober 2015. jadi hampir 3 tahun. Kemudian jika dilihat di bawahnya kebanyakan adalah video game dan juga ada Playstation 4.","e2bbe4da":"Seperti yang kita lihat di atas bahwa data memiliki p-value 0.000484 maka datanya stationary, sehingga kita tidak perlu membuatnya stationary dengan melakukan trnasformasi dengan differencing","27561b4c":"Ini adalah 10 item yang paling tidak laku, penjualanya hanya 1 dalam waktu 2 tahun 10 bulan","0d64711c":"## **====================== 10 Toko Pendapatan Paling Rendah ======================**","0f0b41dd":"# **2. DATA PREPROCESSING**\n\n\nPada tahapan ini, kita akan mencoba untuk membersikan data sebelum masuk ke dalam model dan juga melakukan Exploratory Data Analysis untuk mendapatkan info-info yang menarik dan berguna untuk perusahaan.","9001c35e":"Dari graifk residual (Normal Q-Q), Corrleogram \/ ACF PCF, histogram kde, menunjukkan bahwa model yang kita buat sudah cukup optimal dengan melihat persebaranya yang mendekati normal","5177702d":"Seperti yang sudah diperkirakan,karena 10 produk terbanyak dalam penjualan adalah kebanyakan entertainment, maka tidak heran jika kategori produk yang paling laku juga enternainment seperti pada urutan paling atas adalah kategori DVD, kemudian adajuga PS 3, PS 4 dan XBOX 360.","aec61659":"## **======================== 10 Toko Terlaris ==========================**","d5fe8f68":"Pada model SARIMA kita mendapatkan RMSE sebesar 12688719.01 yang artinya kemungkinan eror data kita dengan predikisinya seberar tersebut. Saya rasa ini sudah lumayan optimal,karena perbandingan dari besaran total sales reratanya mencapai 98 juta atau kemungkinan model kita salah prediksi dari nilai sebesar 12.8% dari nilai.","13471fae":"## **======================== 10 Item Paling Tidak Laku ==========================**","903238ad":"Seperti yang kita lihat bahwa prediksinya memang sesuia dugaan, yaitu pada akhir tahun memang akan terjadi peningkatan sales dan pada wal tahun akan terjadi penurunan sales.","af82231b":"Seperti kita lihat bahwa toko yang paling tidak laku adalah \u041d\u043e\u0432\u043e\u0441\u0438\u0431\u0438\u0440\u0441\u043a \u0422\u0420\u0426 \"\u0413\u0430\u043b\u0435\u0440\u0435\u044f \u041d\u043e\u0432\u043e\u0441\u0438\u0431\u0438\u0440\u0441\u043a\" dengan 333 item terjual dalam waktu 2 tahun 10 bulan atau sekitar 9-10 item perbulan.","477ade04":"## 2.2 Feature Engineering\n\nMelakuakn penambahan variabel pada data untuk memaksimalkan model ataupun untuk dapat mencari info-info yang menarik dari data","e832ecd0":"Toko tertinggi pendapatanya adalah \u041c\u043e\u0441\u043a\u0432\u0430 \u0422\u0426 \"\u0421\u0435\u043c\u0435\u043d\u043e\u0432\u0441\u043a\u0438\u0439\" dengan 2.356611e+08 Rubel atau setara 48.431.364.028,28 (48 Miliar). Jika kita lihat di google, memang jika diartikan adalah ini sebuah Mall yang berada di Rusia,jadi wajar saja jika keuntunganya sebesar itu, karena pendapatanya tidak hanya dari satu kategori item.","712720de":"Sebenaryya dari grafik di atas kita sudah bisa melihat bahwa data yang kita miliki kemungkinan stasionary,karena tidak ada perubahan dari mean, variance atau covariance secara kasat mata, namun kita perlu cek dengan Dickey-Fuller test.","ae246647":"Seperti yang kita lihat di atas, trend menunjukkan penurunan, hal ini sesuai dengan trend yang memang dari awal dataset ini perlihatkan seperti pada model SARIMA sebelumnya","f283eb20":"# **3. MODELING**\n\nPada tahapan ini kita akan mencoba membuat model Time Series dengan menggunakan ARIMA, SARIMA dan PROPHET","a489090b":"Ternyata dataset yang kita miliki tidak ada input yang kosong,sehingga kita tidak perlu melakukan pengisian","688a897e":"## **======================== 10 Kategori Terlaris ==========================**","d1f0e982":"## 2.1 Handling Variable\n\nMelihat apakah input data dengan tipe data sudah sesuai atau belum, melakukan sedikit transformasi jika diperlukan atau aggregasi\/grouping untuk memudahkan pada proses selanjutnya","c8d92706":"# **=============== FUTURE SALES FORECAST ==============**\n\nPada project kali ini, saya akan mencoba untuk mempredikis penjualan atau total sales setiap produk dan toko pada setiap bulanya dengan menggunakan Time Series Analysis (ARIMA, SARIMA dan PROPHET). Seperti biasa, pada notebook ini akan dibagi kedalam beberapa bagian:\n\n1. Konteks\n2. Data Preprocessing\n3. Modelling \n4. Kesimpulan\n\nPada notebook ini tidak akan secara mendalam membahas teorinya, namun saya akan menjelaskan kenapa langkah-langkah itu yang diambil. Mari kita mulai!","4d073fa0":"Jika kita rerata rmse dari model prophet maka didapatkan 23.726.608.27, sehingga model  ini lebih buruk dari SARIMA sebelumnya,hal ini mungkin bisa dilakukan tunning, dengan menambahkan holiday, dll karena prophet sangat bekerja baik jika data yang dimasukkan sangat detail.","ee42be30":"Dari pencarian di atas, kita mendapatkan paramter p,d,q terbaik adalah ARIMA(0, 1, 0)x(0, 1, 1, 12)12 - AIC:755.0370288027423 . Sekarang akan kita masukkan ke dalam model.","494c9f19":"Sebenarnya pada kolom item_cnt_day terdapat outlier yang inputnya 0 ataupun minus, ini akan kita cek di bawah dan menghilangkanya karena tidak mungkin ada penjualan yang 0(karena kita hanya akan mengambil yang laku) dan dibawah 0. Namun selain itu menurut saya bahwa mungkin saja dalam satu hari terdapat banyak sekali order dalam satu item karena mungkin ada hari-hari tertentu seperti natal, hari ibu dll yang biasanya banyak diskon yang mengakibatkan meningkatnya orderan, sehingga saya tidak menganggapnya sebagai outliers","44863f87":"# **4. KESIMPULAN**\n\n\n1. Model terbaik pada project kali ini adalah dengan menggunakan SARIMA\n2. RMSE yang didapat 12.688.719,01 atau 12.8% dari rata-rata data\n3. Perlu adanya tunning untuk model Prophet dengan menambahkan variabel lain seperti holiday\n4. Prediksi total sales 3 bulan kedepan seperti di bawah:","446233c4":"Toko terbanyak dalma penjualan item adalah \"\u041c\u043e\u0441\u043a\u0432\u0430 \u0422\u0426 \"\u0421\u0435\u043c\u0435\u043d\u043e\u0432\u0441\u043a\u0438\u0439\" \" dengan total penjualan 311230 item. Jika dilihat di google artinya adalah Semenovskiy Shopping & Entertainment Center, toko ini adalah Mall yang menjual segala macam kebutuhan, mulai dari fashion, gadget sampai makanan, sehingga wajar jika penjualanya no satu.","0fac5928":"## **3.3 Autocorrelation**\n\nAutocorrelation digunakan untuk melihat apakah ada hubungan \/ korelasi antara nilai sekarang dengan nilai sebelumnya (lag \/ lagging \/ selisih). Setiap model regressi, mengasumsikan bahwa data tida ada korelasi. Autocorrelasi juga bisa digunakna untuk melihat seasonality atau trend yang tidak terlihat pada Lag 1, 2 dst.","59821b62":"## **3.1 Stationary**\n\nTime series analysis membutuhkan data yang stationary, yaitu ketika mean, variance, dan covariance dianggap konstan sepanjang waktu agar mudah untuk dilakukan prediksinya, karena akan terlihat polanya. Untuk mengetahui apakah suatu data stationary atau tidak, disini saya menggunakan Dickey-Fuller test. Jika p-value di atas 0.05 maka datanya tidak stationary, namun jika di bawah 0.05 maka stationary.","f9a72e1b":"## **3.4 Modelling (SARIMA)**\n\n\nPada tahapan ini saya akan membuat prediksi dengan SARIMA (Seasonality Autoreggesive Integrated Moving Average) sebernarnya ini 4 metode yang dijadikan satu. Terdapat 4 parameter yaitu:\n - p: Seasonality (Autoregressive \/ AR)\n - d: Trend (Integrated \/ I)\n - q: Noice (Moving Average \/ MA)\n - s: Seasonality","3d5c3a79":"## Crossvalidation\n\nMelihat eror dari nilai yang diprediksi dengan nilai aslinya dengan meggunakan parameter:\n- initial:berapa banyak data yang digunakan untuk training\n- period : berapa banyak yang digunakan untuk prediksi\n- horizon : berapa rentang waktu yang digunakan untuk prediksi\n- Secara defalut, initial traing itu 3x dari horizon dan periode itu setengahnya horizon","9d3da6d3":"## **======================== 10 Item Terlaris ==========================**","d2306d31":"kategori yang paling sedikit penjualanya adalah \u041a\u043d\u0438\u0433\u0438 - \u041f\u043e\u0437\u043d\u0430\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043b\u0438\u0442\u0435\u0440\u0430\u0442\u0443\u0440\u0430 jika diartikan maka akan muncul buku, dan kebanyakn dari 10 ini adalah buku semua, mungkin memang kategori buku kurang diminati.","111e16e8":"Ternyata ada 1 item yang harganya 0 atau dibawah 0, maka kita akan hilangkan data tersebutkarena tidak mungkin ada harga jual 0 atau bahkan minus","3cd56362":"* Terdapat 10 kolom, 2935849 input, tipe data yang kita punya float64 ada 2, int64 ada 4, dan object ada 4.","a3869537":"Darai kedua visualisasi di atas kita dapat melihat:\n- data ini memiliki seasonality, terjadi peningkatan pada setiap akhir tahun serta penurunan di awal tahun\n- terjadi peningkatan trend di awal sampaipertengahan data dan kemudian mengalami penuruan","60825d2b":"Model dengan menggunakan Prophet bisa kita lihat cukup baik, titik yang berwarna hitam adalah nilai aktualnya dan garis yang berwarna biru adalah nilai prediksinya, bisa dilihat bahwa model kita sudah cukup baik dalam memprediksi. Seperti pada prediksi dengan menggunakan SARIMA, prediksi yang dihasilkan sama-sama menunjukkan bahwa terjadi peningkatan pada bulan November sampai Januari dan kemudian mengalami penurunan setelah bulan Januari.","2cc600f7":"## **======================== 10 Kategori Paling Tidak Laku ==========================**","abd7581d":"## **====================== 10 Toko Pendapatan Paling Tinggi ======================**","b8178f0c":"## **======================== 10 Toko Tidak Laris ==========================**","8f5bd8e5":"Toko yang memiliki pendapatan paling rendah adalah \u041d\u043e\u0432\u043e\u0441\u0438\u0431\u0438\u0440\u0441\u043a \u0422\u0420\u0426 \"\u0413\u0430\u043b\u0435\u0440\u0435\u044f \u041d\u043e\u0432\u043e\u0441\u0438\u0431\u0438\u0440\u0441\u043a\" dengan 379461.00 Rubel sekitar 77.984.078,94 (77 Juta). Toko ini juga merupakan seperti Mall \/ marketplace.","87da5423":"## **3.5 Modelling (PROPHET)**\n\nProphet adalah library yang dikeluarkan oleh facebook untuk melakukan Time Series Analysis, perbedaanya dengan yang lain adalah lebih ke praktisan dan ke akuratanya. Krena kita sudah mengecek tentang Stationary, Seasonality, Autocorrelation dll pada model sebelumnya, maka sekarang langsung melakukan model.","464115d4":"Seperti kita lihat di atas, ternyata ada 7356 input yang salah, sehingga kita akan hilangkan saja karena tidak mungkin kita gantikan secara statistik (mean\/median)","05774b36":"Saya tidak mengaggap yang melebihi upper limit \/ upper limit extreme adalah outlier karena toko yang ada pada dataset ini memiliki variasi kategori item, sehingga mungkin saja salah satu item memiliki harga yang sangat tinggi atau sangat rendah, sehingga saja tidak menganggapnya outliers. Perlu diketahui juga bahwa dataset ini merupakan kumpulan dari beberapa toko dan kategori item, sehingga sangat memungkinkan terdapat harganya yang sangat beda."}}