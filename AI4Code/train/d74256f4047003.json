{"cell_type":{"7d926106":"code","5329bd60":"code","57f3ec8e":"code","c09deb39":"code","8e776b15":"code","a633df3b":"code","50abfe28":"code","36d44131":"code","027b628a":"code","401c2092":"code","746e5bd9":"code","105955c0":"code","ee031c64":"code","09df3ea6":"code","51326c9b":"code","98c551a5":"code","2d6af207":"code","277b7b87":"code","f5ab026f":"code","c8503fe4":"code","a834d186":"code","c4851a86":"code","2957ae28":"code","818afaac":"code","84fc6cac":"code","e4fa8a1b":"code","129035b8":"code","4ec713e1":"code","5c9c593a":"code","abd2f8c5":"code","7bbcc03d":"code","e0019f06":"code","0e2d6d6e":"code","48b7078b":"code","212f5c8f":"code","efbc61f5":"code","73b5a4fe":"code","3cf299a2":"code","5895d247":"code","b2f5ee19":"code","e41d6727":"code","8766df1a":"code","52198d93":"code","ad531288":"code","c2486e02":"code","d6eee309":"markdown","c59f6937":"markdown","7f36285b":"markdown","908d54de":"markdown","8a26a25a":"markdown","c0e061bf":"markdown","e040e214":"markdown","9dea6a4c":"markdown","1bc3c975":"markdown","6e17704d":"markdown","08e6e264":"markdown","c8a6ead9":"markdown"},"source":{"7d926106":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5329bd60":"import pandas as pd","57f3ec8e":"data = pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\") \ndata.head()","c09deb39":"data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'], inplace=True, axis=1)\ndata.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], inplace=True, axis=1)","8e776b15":"data.columns","a633df3b":"data.head()","50abfe28":"data['Income_Category'].unique()","36d44131":"data = data.replace({'Unknown': 0 , 'Less than $40K':1, '$40K - $60K':2, \n                     '$80K - $120K':3, '$60K - $80K':4, '$120K +':5})","027b628a":"data['Income_Category'].unique()","401c2092":"data['Attrition_Flag'].unique()","746e5bd9":"data = data.replace({'Existing Customer':0, 'Attrited Customer':1})","105955c0":"data['Attrition_Flag'].unique()","ee031c64":"data['Gender'].unique()","09df3ea6":"data = data.replace({'M':0, 'F':1})\ndata['Gender'].unique()","51326c9b":"data['Education_Level'].unique()","98c551a5":"data = data.replace({'High School':1, 'Graduate':2, 'Uneducated':3,'College':4,'Post-Graduate':5,'Doctorate':6})\ndata['Education_Level'].unique()","2d6af207":"data['Marital_Status'].unique()","277b7b87":"data = data.replace({'Married':1, 'Single':2, 'Divorced':3})\ndata['Marital_Status'].unique()","f5ab026f":"data['Card_Category'].unique()","c8503fe4":"data = data.replace({'Blue':0, 'Gold':1, 'Silver':2, 'Platinum':3})\ndata['Card_Category'].unique()","a834d186":"import seaborn as sns\nimport plotly.express as ex\n","c4851a86":"fig = ex.pie(data, names='Attrition_Flag', title = 'Chunc clients and not chunc clients'  )\nfig.show()","2957ae28":"data.columns","818afaac":"import matplotlib.pyplot as plt","84fc6cac":"plt.figure(figsize=(20,20))\ncor = data.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","e4fa8a1b":"cor_target = abs(cor[\"Attrition_Flag\"])\nrelevant_features = cor_target\nrelevant_features","129035b8":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\n","4ec713e1":"X = pd.get_dummies(data.drop(columns=['Attrition_Flag']))\ny=data['Attrition_Flag'] \n\nmodel = ExtraTreesClassifier()\n#you can change Feature Importance\nmodel.fit(X,y)\nprint(model.feature_importances_) \n\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\n#select top 10 feature\nplt.show()","5c9c593a":"feat_importances.nlargest(10)","abd2f8c5":"X = data[['Total_Trans_Ct','Total_Trans_Amt','Total_Revolving_Bal','Total_Ct_Chng_Q4_Q1','Total_Relationship_Count','Avg_Utilization_Ratio','Contacts_Count_12_mon','Total_Amt_Chng_Q4_Q1','Months_Inactive_12_mon','Avg_Open_To_Buy']]\nX","7bbcc03d":"y=data['Attrition_Flag'] \ny","e0019f06":"from sklearn.model_selection import train_test_split","0e2d6d6e":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=20,shuffle=True)","48b7078b":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics","212f5c8f":"rf=RandomForestClassifier()\nrf.fit(X_train,y_train)\nprint('the accuracy of Test data is:',accuracy_score(y_test,rf.predict(X_test))*100,'%')","efbc61f5":"print(confusion_matrix(y_test,rf.predict(X_test)))\nprint(classification_report(y_test,rf.predict(X_test)))","73b5a4fe":"cf=metrics.confusion_matrix(y_test,rf.predict(X_test), labels=[1,0])\nsns.heatmap(cf,annot=True)","3cf299a2":"one=0\nzero=0\nfor i in data['Attrition_Flag']:\n    if i==1:\n        one+=1\n    else:\n        zero+=1\nprint('Total 1:',one)\nprint('Total 0:',zero)\n","5895d247":"data_under = []\nfor toxic_type in ['Attrition_Flag']:\n    df_class_0 = data[data['Attrition_Flag'] == 0]\n    df_class_1 = data[data['Attrition_Flag'] == 1]\n\n    df_class_0_under = df_class_0.sample(1627)\n    df_class_1_under = df_class_1.sample(1627)\n    \n    data_under.append(df_class_0_under)\n    data_under.append(df_class_1_under)\n          \ndf_train_under = pd.concat(data_under, axis=0,ignore_index=True)\nprint(df_train_under.shape)","b2f5ee19":"df_train_under","e41d6727":"sns.countplot(df_train_under['Attrition_Flag'])\nplt.title('Target repartition on training data')\nplt.show()","8766df1a":"X = df_train_under[['Total_Trans_Ct','Total_Trans_Amt','Total_Revolving_Bal','Total_Ct_Chng_Q4_Q1','Total_Relationship_Count','Avg_Utilization_Ratio','Contacts_Count_12_mon','Total_Amt_Chng_Q4_Q1','Months_Inactive_12_mon','Avg_Open_To_Buy']]\ny=df_train_under['Attrition_Flag'] \nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=20,shuffle=True)","52198d93":"rf_under=RandomForestClassifier()\nrf_under.fit(X_train,y_train)\ny_pred_under=rf_under.predict(X_test)\nprint('the accuracy of Test undersampling data is:',accuracy_score(y_test,y_pred_under)*100,'%')","ad531288":"print(confusion_matrix(y_test,y_pred_under))\nprint(classification_report(y_test,y_pred_under))","c2486e02":"cf=metrics.confusion_matrix(y_test,y_pred_under, labels=[1,0])\nsns.heatmap(cf,annot=True)","d6eee309":"# Encode","c59f6937":"# Import data set","7f36285b":"Correlation Matrix with Heatmap","908d54de":"# Train Test Split","8a26a25a":"imbalance data but I will do it without sampling","c0e061bf":"# Feature selection","e040e214":"# Find Importance Feature","9dea6a4c":"find total 1 and 0","1bc3c975":"using a Tree-Based Classifiers","6e17704d":"# Try under sampling with min value 1627","08e6e264":"# Sampling data","c8a6ead9":"# Random Forest Classifier"}}