{"cell_type":{"9e10329b":"code","a196b970":"code","9ceaaec0":"code","d2e36c9c":"code","a1b5ec6f":"code","86aa9343":"code","78e36bec":"code","a7a7cb58":"code","c7002660":"code","b91da8f1":"code","b03a993b":"code","f645cf76":"code","87f61c5c":"code","0f124812":"code","5ed696f5":"code","5e800b1b":"code","9c27f3ec":"markdown","8fb962c4":"markdown","2f898b21":"markdown","da1d0af5":"markdown","c8d4e493":"markdown","a1428de9":"markdown","c849fc45":"markdown","035f459c":"markdown","03321035":"markdown"},"source":{"9e10329b":"# Import numpy, pandas, and matplotlib using the standard aliases. \n# Import mpimg from matplotlib.image\n# Import train_test_split from sklearn\n# Import pickle. \n# Import tensorflow and all needed tools from tensorflow.keras. \nimport numpy as np\nimport pandas as pd\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport pickle\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense","a196b970":"# Load the training data into a DataFrame named 'train'. \n# Print the shape of the resulting DataFrame. \n# You do not need the test data in this notebook. \ntrain = pd.read_csv('..\/input\/mu-cifar10\/train.csv')\nprint(train.shape)","9ceaaec0":"# Display the head of the train DataFrame. \ntrain.head()","d2e36c9c":"train.label = train.label.astype(str)","a1b5ec6f":"# Display a DataFrame showing the proportion of observations with each \n# possible of the target variable (which is label). \ny_train = train.label\n(train.label.value_counts() \/ len(train)).to_frame()","86aa9343":"# Sample 16 images from the training set and display these along with their labels.\n# The images should be arranged in a 4x4 grid of subplots. \n# Please set the figure sizeto (6,6)\nsample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(6,6))\n\nfor i, row in sample.iterrows():\n    img = mpimg.imread(f'..\/input\/mu-cifar10\/train_images\/{row.filename}')\n    label = row.label\n    \n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","78e36bec":"# Split the dataframe train into two DataFrames named train_df and valid_df. \n# Use 20% of the data for the validation set. \n# Use stratified sampling so that the label proportions are preserved.\n# Set a random seed for the split. \ntrain_df, valid_df = train_test_split(train, test_size = 0.2, random_state = 34, stratify=train.label)\nprint(train_df.shape)\nprint(valid_df.shape)","a7a7cb58":"# Create image data generators for both the training set and the validation set. \n# Use the data generators to scale the pixel values by a factor of 1\/255. \ntrain_datagen = ImageDataGenerator(rescale = 1\/255)\nvalid_datagen = ImageDataGenerator(rescale = 1\/255)","c7002660":"# Complete the code for the data loaders below. \n\nBATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = '..\/input\/mu-cifar10\/train_images',\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 34,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)\n\nvalid_loader = train_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = '..\/input\/mu-cifar10\/train_images',\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 34,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)","b91da8f1":"# Run this cell to determine the number of training and validation batches. \n\nTR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","b03a993b":"# Use this cell to construct a convolutional neural network model. \n# Your model should make use of each of the following layer types:\n#    Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense\n# You can start by mimicking the architecture used in the \n# Aerial Cactus competetition, but you should explore different architectures\n# by adding more layers and\/or adding more nodes in individual layers\n\nnp.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='elu', input_shape=(32,32,3)),\n    Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='elu'),\n    #Dropout(.25),\n    MaxPooling2D(2,2),\n    BatchNormalization(),\n    \n    Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='elu'),\n    Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='elu'),\n    Dropout(.2),\n    MaxPooling2D(2,2),\n    BatchNormalization(),\n    \n    Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='elu'),\n    Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='elu'),\n    Dropout(.3),\n    MaxPooling2D(2,2),\n    BatchNormalization(),\n    \n    Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='elu'),\n    Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='elu'),\n    Dropout(.2),\n    MaxPooling2D(2,2),\n    BatchNormalization(),\n    \n    Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='elu'),\n    Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='elu'),\n    Dropout(.1),\n    MaxPooling2D(2,2),\n    BatchNormalization(),\n    \n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dense(64,  activation='relu'),\n    Dense(10, activation='softmax')\n])\n\ncnn.summary()","f645cf76":"# Define an optimizer and select a learning rate. \n# Then compile the model. \nopt = tf.keras.optimizers.Adam(.001)\ncnn.compile(loss= \"categorical_crossentropy\", optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","87f61c5c":"# Complete one or more training runs. \n# Display training curves after each run. \n\nh1 = cnn.fit(\n    x = train_loader,\n    steps_per_epoch = TR_STEPS,\n    epochs= 40,\n    validation_data = valid_loader,\n    validation_steps = VA_STEPS,\n    verbose = 1\n)","0f124812":"history = h1.history\nprint(history.keys())","5ed696f5":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label = 'Training')\nplt.plot(epoch_range, history['val_loss'], label = 'Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss by Epoch')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label = 'Training')\nplt.plot(epoch_range, history['val_accuracy'], label = 'Validation')\nplt.xlabel('Epoch'); plt.ylabel('ACC'); plt.title('ACC by Epoch')\nplt.legend()\nplt.tight_layout()\nplt.show()","5e800b1b":"# When you are satisfied with the model you have found, \n# save the model and the combined history dictionary to files.\n# Download these filesto your local device and then upload them \n# as a Kaggle dataset. \n","9c27f3ec":"# Label Distribution","8fb962c4":"# View Sample of Images","2f898b21":"# Data Generators","da1d0af5":"# CIFAR 10 Image Classification\n\nMost of the code cells below include comments explaining the task to be performed in those cells. Please delete the comments and add code to perform those tasks. There are a few code cells in which code has already been provided for you. In some cases, you will need to complete this code.\n\n\u26a0 **NOTE:** You should make use of GPU acceleration in this notebook. \n\n","c8d4e493":"# Save Model and History","a1428de9":"# Load Training DataFrame","c849fc45":"# Train Network","035f459c":"# Import Packages","03321035":"# Build Network"}}