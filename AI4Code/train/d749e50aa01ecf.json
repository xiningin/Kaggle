{"cell_type":{"6d4c0d46":"code","d3251b28":"code","2fdd55fa":"code","968274d5":"code","526bb80e":"code","7f24f79f":"code","3d1eb398":"code","e4d54489":"code","3e5c56f7":"code","567fc35d":"code","6022bdd0":"code","b8d7a4e0":"code","8de03c1e":"code","4d51498b":"code","d123c2df":"markdown","33f2b199":"markdown","9584a9c6":"markdown","6f67104e":"markdown","36624ba9":"markdown","8e0582f1":"markdown","25ef8077":"markdown","76d28132":"markdown","d7c6c0ce":"markdown","a4cb710c":"markdown","dd14440d":"markdown","6b631444":"markdown","1bc4d1a8":"markdown"},"source":{"6d4c0d46":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns #styling purpose\nsns.set_style('whitegrid')\n%matplotlib inline\n","d3251b28":"# For reading stock data from yahoofinance\nfrom pandas_datareader.data import DataReader\nimport pandas_datareader.data as web\n# For time limits\nfrom datetime import datetime\n\n#Getting the stock details from web\ndf = web.DataReader('LT.NS','yahoo', start='1951-01-23', end=datetime.now())\n#Instead of LT.NS you can use your company's ticker to find the  and you can also change the date to what you want\n\n#Show the data\ndf","2fdd55fa":"plt.figure(figsize=(16,8))\nplt.title('Close Price History', fontsize=16)\nplt.plot(df['Close'])\nplt.xlabel('Date', fontsize=16)\nplt.ylabel('Close Price', fontsize=16)\nplt.show()","968274d5":"#Creating a new dataframe with only the Close column\ndata = df.filter(['Close'])#function is used to Subset rows or columns of dataframe according to labels in the specified index.\n\n#Converting the dataframe to a numpy array\ndataset = data.values\nprint(len(dataset))#output1\n\n#Getting the number of rows to train the model on\ntraining_data_len = int(np.ceil( len(dataset) * 0.8 ))# Ceil() is basically used to round up the values specified in it. It rounds up the value to the nearest greater integer.\n\ntraining_data_len#output2","526bb80e":"#Scaling the data\nfrom sklearn.preprocessing import MinMaxScaler\n#LSTM are sensitive to the scale of the data. so we apply MinMax scaler\n\nscaler = MinMaxScaler(feature_range=(0,1))#scaling features within (0,1)\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","7f24f79f":"#Creating the scaled training data set\ntrain_data = scaled_data[0:int(training_data_len), :]#you need to select rows starting from zero till training_data_len and all the columns from your scaled_data.\n#Train Dataset: Used to fit the machine learning model.\n\n#Splitting the data into x_train and y_train data sets\nx_train = []\ny_train = []","3d1eb398":"for i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i, 0])\n    if i<= 61:\n        print(x_train)\n        print(y_train)\n        print()\n        \n# Converting the x_train and y_train to numpy arrays \nx_train, y_train = np.array(x_train), np.array(y_train)\n\n#Reshaping the data\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n\n#So basically, we're showing the the model [from 60 to last], in order, and having it make the prediction. (60 sequences of 1 element)\nx_train.shape","e4d54489":"from tensorflow import keras\nfrom keras.models import Sequential #to initialize NN as a sequnce of layers\nfrom keras.layers import Dense, LSTM  #to add fully connected layers\nfrom keras.layers import Dropout #Dropout is a technique used to prevent a model from overfitting.\n\n#Building the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(50, return_sequences=True, input_shape= (x_train.shape[1], 1)))#input layer is 3D\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(50, return_sequences= False))\n#no. of memory units-50\n#input_shape=(1, 1) means the 1st element is the time step and the 2nd element is no. of features\n#This return_sequences flag is used for when you're continuing on to another recurrent layer. If you are, then you want to return sequences. If you're not going to another recurrent-type of layer, then you don't set this to true.\n\nfrom tensorflow.keras import layers #basic building blocks of neural networks in Keras.\nfrom tensorflow.keras import activations\n\nmodel.add(layers.Dense(25, activation=activations.relu))\nmodel.add(Dense(1))\n#Built the LSTM model to have two LSTM layers with 50 neurons and two Dense layers, one with 25 neurons and the other with 1 neuron.\n\n# Compile the model\nopt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n#The learning rate(lr) controls how much to change the model in response to the estimated error each time the model weights are updated. \nmodel.compile(optimizer=opt, loss='mean_squared_error')\n\n#Train the model\nmodel.fit(x_train, y_train, batch_size=32, epochs=100, verbose=2)#Verbose=2 will just mention the number of epoch like this: 1\/100...","3e5c56f7":"#Creating a new array containing scaled values \ntest_data = scaled_data[training_data_len - 60: , :]\n#Test Dataset: Used to evaluate the fit machine learning model.\n#Setting the time step as 60 (as seen previously)\n\n#Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n#Convert the data to a numpy array\nx_test = np.array(x_test)\n\n#Reshape the data to be 3-D in the form [number of samples, number of time steps, and number of features]. This needs to be done, because the LSTM model is expecting a 3-dimensional data set.\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\n#Predicted price values \npredicted_data = model.predict(x_test)\npredicted_data = scaler.inverse_transform(predicted_data) #unscaling","567fc35d":"train = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predicted_data\n\n# Visualizing the data\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price INR', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid[['Close', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='upper left')\nplt.show()","6022bdd0":"#Show the valid and predicted prices\nprint(valid.tail())","b8d7a4e0":"# visualizing the results for testing\nplt.figure(figsize=(16,8))\nplt.plot(y_test,color='red',label='Real Stock price')\nplt.plot(predicted_data,color='blue',label='Predicted Stock price')\n\nplt.title('Stock price prediction using LSTM')\nplt.xlabel('Time')\nplt.ylabel('Stock Price')\n\nplt.legend()\nplt.show()","8de03c1e":"##Calculating Root mean square error\nimport math\nfrom sklearn.metrics import mean_squared_error\nrmse = math.sqrt(mean_squared_error(y_test, predicted_data))\nprint(rmse)\n\nprint('RMSE in terms of % of the orignal value is', round((rmse\/y_test.mean()*100), 2) , '%')\n#we take the avg because it would be a true representative of the real stock values","4d51498b":"##Calculating Mean Absolute error\nfrom sklearn.metrics import mean_absolute_error\nmae=mean_absolute_error(y_test,predicted_data)\nprint(mae)\nprint('MAE in terms of % of the orignal value is', round((mae\/y_test.mean()*100), 2) , '%')","d123c2df":"# Visualizing the comparison for testing","33f2b199":"# In this notebook we will be analysing data from  L&T(You can even copy it and enter any other stock ticker to get your preferred choice).\n# Along with this we will be predicting the price using LSTM.\n# A fully simplified notebook follows.","9584a9c6":"(3578(dynamic), 60, 1) the 2nd argument is no. of features and 3rd argument is the time step(x_train.shape)****","6f67104e":"# Creating the training data set","36624ba9":"# Plotting and Visualizing the data","8e0582f1":"# Creating the testing data set","25ef8077":"# Building the LSTM Model\nLong Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems.","76d28132":"# Mean Absolute error","d7c6c0ce":"* Creating a training data set that contains the past 60 day closing price values that we want to use to predict the 61st closing price value.\n* So the first column in the \u2018x_train\u2019 data set will contain values from the data set from index 0 to index 59 (60 values total)and the second column will contain values from the data set from index 1 to index 60 (60 values) and so on and so forth.\n* The \u2018y_train\u2019 data set will contain the 61st value located at index 60 for it\u2019s first column and the 62nd value located at index 61 of the data set for it\u2019s second value and so on and so forth.","a4cb710c":"To understand clearly about how LSTM models work in brief go through the git repository.\nhttps:\/\/github.com\/MohammadFneish7\/Keras_LSTM_Diagram","dd14440d":"# Predicting stock price of L&T:","6b631444":"# Scaling the data","1bc4d1a8":"# Root mean square error"}}