{"cell_type":{"98078aad":"code","6f1691f7":"code","29bf0f4e":"code","06678967":"code","37723fe2":"code","5ba0693c":"code","0fcc4a3d":"code","2f5d504f":"code","c9161829":"code","04f556d8":"code","51fd4207":"code","7290640c":"code","1a8be536":"code","d5856814":"code","78eb637e":"code","f87c504a":"code","8efeeb10":"code","39edc30e":"code","26a4314a":"code","cafff85b":"code","07960425":"code","89797ccf":"code","8eb304c2":"code","959a5a7f":"code","a66c1b27":"code","6760450c":"code","cf220bee":"code","7d7c8ed8":"code","8248f591":"code","695f910e":"code","c0129022":"code","d5279592":"code","885f38c5":"code","e8041231":"code","a395f33c":"code","68c55ac6":"code","d5e10d81":"code","30c0bbab":"code","87be44ae":"code","dc5c7b49":"code","4003fa87":"code","1fba8b58":"code","5f99c546":"code","06e9c4e1":"code","04bff487":"code","ef4be6d4":"code","2fb236f7":"code","49a0c3ef":"code","e86d60fd":"code","e8acd607":"code","ad663491":"code","a3abc543":"code","209ff4b9":"code","767a0baf":"code","56c40770":"code","758241e6":"markdown","ae9f675e":"markdown","365445ba":"markdown","c35b6eac":"markdown","f206be84":"markdown","9c1a48eb":"markdown","9c90f675":"markdown","2ff73aa0":"markdown","e5dc3f30":"markdown","155cbc53":"markdown","71b8271b":"markdown","aea033f1":"markdown","6ae195ef":"markdown","05ab2bff":"markdown","4fc31960":"markdown"},"source":{"98078aad":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","6f1691f7":"Face_Train_Data = Path(\"..\/input\/facial-expression-recog-image-ver-of-fercdataset\/Dataset\/train\")\nFace_Test_Data = Path(\"..\/input\/facial-expression-recog-image-ver-of-fercdataset\/Dataset\/test\")","29bf0f4e":"Train_PNG_Path = list(Face_Train_Data.glob(r\"*\/*.png\"))\nTest_PNG_Path = list(Face_Test_Data.glob(r\"*\/*.png\"))","06678967":"Train_PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Train_PNG_Path))\nTest_PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Test_PNG_Path))","37723fe2":"print(\"anger: \",Train_PNG_Labels.count(\"anger\"))\nprint(\"disgust: \",Train_PNG_Labels.count(\"disgust\"))\nprint(\"fear: \",Train_PNG_Labels.count(\"fear\"))\nprint(\"happiness: \",Train_PNG_Labels.count(\"happiness\"))\nprint(\"neutral: \",Train_PNG_Labels.count(\"neutral\"))\nprint(\"sadness: \",Train_PNG_Labels.count(\"sadness\"))\nprint(\"surprise: \",Train_PNG_Labels.count(\"surprise\"))","5ba0693c":"print(\"anger: \",Test_PNG_Labels.count(\"anger\"))\nprint(\"disgust: \",Test_PNG_Labels.count(\"disgust\"))\nprint(\"fear: \",Test_PNG_Labels.count(\"fear\"))\nprint(\"happiness: \",Test_PNG_Labels.count(\"happiness\"))\nprint(\"neutral: \",Test_PNG_Labels.count(\"neutral\"))\nprint(\"sadness: \",Test_PNG_Labels.count(\"sadness\"))\nprint(\"surprise: \",Test_PNG_Labels.count(\"surprise\"))","0fcc4a3d":"Train_PNG_Path_Series = pd.Series(Train_PNG_Path,name=\"PNG\").astype(str)\nTest_PNG_Path_Series = pd.Series(Test_PNG_Path,name=\"PNG\").astype(str)","2f5d504f":"Train_PNG_Labels_Series = pd.Series(Train_PNG_Labels,name=\"CATEGORY\")\nTest_PNG_Labels_Series = pd.Series(Test_PNG_Labels,name=\"CATEGORY\")","c9161829":"Main_Train_Data = pd.concat([Train_PNG_Path_Series,Train_PNG_Labels_Series],axis=1)\nMain_Test_Data = pd.concat([Test_PNG_Path_Series,Test_PNG_Labels_Series],axis=1)","04f556d8":"print(Main_Train_Data.head(-1))","51fd4207":"print(Main_Test_Data.head(-1))","7290640c":"Main_Train_Data = Main_Train_Data.sample(frac=1).reset_index(drop=True)\nMain_Test_Data = Main_Test_Data.sample(frac=1).reset_index(drop=True)","1a8be536":"print(Main_Train_Data.head(-1))","d5856814":"print(Main_Test_Data.head(-1))","78eb637e":"plt.style.use(\"classic\")","f87c504a":"Example_IMG = cv2.imread(Main_Train_Data[\"PNG\"][0])\nplt.xlabel(Example_IMG.shape)\nplt.ylabel(Example_IMG.size)\nplt.title(Main_Train_Data[\"CATEGORY\"][0])\nplt.imshow(Example_IMG)","8efeeb10":"Example_IMG = cv2.imread(Main_Train_Data[\"PNG\"][20])\nplt.xlabel(Example_IMG.shape)\nplt.ylabel(Example_IMG.size)\nplt.title(Main_Train_Data[\"CATEGORY\"][20])\nplt.imshow(Example_IMG)","39edc30e":"Example_IMG = cv2.imread(Main_Train_Data[\"PNG\"][3228])\nplt.xlabel(Example_IMG.shape)\nplt.ylabel(Example_IMG.size)\nplt.title(Main_Train_Data[\"CATEGORY\"][3228])\nplt.imshow(Example_IMG)","26a4314a":"figure, axes = plt.subplots(nrows=5,ncols=5,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMGs = plt.imread(Main_Train_Data[\"PNG\"][i])\n    ax.imshow(IMGs)\n    ax.set_xlabel(IMGs.shape)\n    ax.set_ylabel(IMGs.size)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","cafff85b":"figure, axes = plt.subplots(nrows=5,ncols=5,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMGs = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    ax.imshow(IMGs)\n    ax.set_xlabel(IMGs.shape)\n    ax.set_ylabel(IMGs.size)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","07960425":"Ex_I_Img = Main_Train_Data[\"PNG\"][11]\nEx_II_Img = Main_Test_Data[\"PNG\"][2333]\n\nI_Img = cv2.imread(Ex_I_Img)\nII_Img = cv2.imread(Ex_II_Img)\n\nDiff_Img = cv2.absdiff(I_Img,II_Img)\n\nIMGs_List = [I_Img,II_Img,Diff_Img]\n\n#\n\nfigure, axis = plt.subplots(nrows=1,\n                           ncols=3,\n                           figsize=(10,10))\n\n\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(IMGs_List[i])\nplt.tight_layout()\nplt.show()","89797ccf":"Ex_I_Img = Main_Train_Data[\"PNG\"][1100]\nEx_II_Img = Main_Test_Data[\"PNG\"][23]\n\nI_Img = cv2.imread(Ex_I_Img)\nII_Img = cv2.imread(Ex_II_Img)\n\nDiff_Img = cv2.absdiff(I_Img,II_Img)\n\nIMGs_List = [I_Img,II_Img,Diff_Img]\n\n#\n\nfigure, axis = plt.subplots(nrows=1,\n                           ncols=3,\n                           figsize=(10,10))\n\n\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(IMGs_List[i])\nplt.tight_layout()\nplt.show()","8eb304c2":"Ex_I_Img = Main_Train_Data[\"PNG\"][110]\nEx_II_Img = Main_Test_Data[\"PNG\"][452]\n\nI_Img = cv2.imread(Ex_I_Img)\nII_Img = cv2.imread(Ex_II_Img)\nI_Img = cv2.cvtColor(I_Img,cv2.COLOR_BGR2RGB)\nII_Img = cv2.cvtColor(II_Img,cv2.COLOR_BGR2RGB)\n\nI_Img_Canny = cv2.Canny(I_Img,90,400)\nII_Img_Canny = cv2.Canny(II_Img,90,400)\n\nDiff_Canny = cv2.absdiff(I_Img_Canny,II_Img_Canny)\n\nIMGs_List = [I_Img_Canny,II_Img_Canny,Diff_Canny]\n\n#\n\nfigure, axis = plt.subplots(nrows=1,\n                           ncols=3,\n                           figsize=(10,10))\n\n\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(IMGs_List[i])\nplt.tight_layout()\nplt.show()","959a5a7f":"Ex_I_Img = Main_Train_Data[\"PNG\"][110]\nEx_II_Img = Main_Test_Data[\"PNG\"][452]\n\nI_Img = cv2.imread(Ex_I_Img)\nII_Img = cv2.imread(Ex_II_Img)\nI_Img = cv2.cvtColor(I_Img,cv2.COLOR_BGR2RGB)\nII_Img = cv2.cvtColor(II_Img,cv2.COLOR_BGR2RGB)\n\nret,threshold_I = cv2.threshold(I_Img,180,255,cv2.THRESH_BINARY_INV)\nret,threshold_II = cv2.threshold(II_Img,180,255,cv2.THRESH_BINARY_INV)\n\nDiff_Thresh = cv2.absdiff(threshold_I,threshold_II)\n\nIMGs_List = [threshold_I,threshold_II,Diff_Thresh]\n\n#\n\nfigure, axis = plt.subplots(nrows=1,\n                           ncols=3,\n                           figsize=(10,10))\n\n\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(IMGs_List[i])\nplt.tight_layout()\nplt.show()\n\n","a66c1b27":"Ex_I_Img = Main_Train_Data[\"PNG\"][110]\nEx_II_Img = Main_Test_Data[\"PNG\"][452]\n\nI_Img = cv2.imread(Ex_I_Img,0)\nII_Img = cv2.imread(Ex_II_Img,0)\n\n\nthresh_A_I = cv2.adaptiveThreshold(I_Img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,11,2)\nthresh_A_II = cv2.adaptiveThreshold(II_Img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,11,2)\n\nDiff_Thresh_A = cv2.absdiff(thresh_A_I,thresh_A_II)\n\nIMGs_List = [thresh_A_I,thresh_A_II,Diff_Thresh_A]\n\n#\n\nfigure, axis = plt.subplots(nrows=1,\n                           ncols=3,\n                           figsize=(10,10))\n\n\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(IMGs_List[i])\nplt.tight_layout()\nplt.show()","6760450c":"xi = Main_Train_Data[\"PNG\"][22]\nxp = cv2.imread(xi)\nplt.imshow(xp)","cf220bee":"Transformated_IMG_List = []\n\nfor T_Img in Main_Train_Data[\"PNG\"]:\n    X_Img = cv2.imread(T_Img,0)\n    X_Img = cv2.resize(X_Img,(48,48)) #32,32\n    Transformated_IMG_List.append(X_Img)","7d7c8ed8":"print(Transformated_IMG_List[2].shape)","8248f591":"plt.imshow(Transformated_IMG_List[2],cmap=\"Greys_r\")","695f910e":"Array_IMG_Set = np.asarray(Transformated_IMG_List)","c0129022":"print(Array_IMG_Set.shape)","d5279592":"Array_IMG_Set = Array_IMG_Set.reshape(-1,48,48,3) #32","885f38c5":"print(Array_IMG_Set.shape)","e8041231":"Generator_Input = keras.Input(shape=(48,)) #32\nx = layers.Dense(128*24*24)(Generator_Input) #16,16\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((24,24,128))(x) #16,16\n\nx = layers.Conv2D(256,5,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2DTranspose(256,4,strides=2,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(256,5,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(3,7,padding=\"same\",activation=\"tanh\")(x)\n\nGenerator = keras.models.Model(Generator_Input,x)","a395f33c":"print(Generator.summary())","68c55ac6":"Discriminator_Input = layers.Input(shape=(48,48,3)) #32,32\nx = layers.Conv2D(128,3)(Discriminator_Input)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,3,strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,3,strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Flatten()(x)\n\nx = layers.Dense(1,activation=\"sigmoid\")(x)\n\nDiscriminator = keras.models.Model(Discriminator_Input,x)","d5e10d81":"print(Discriminator.summary())","30c0bbab":"Discriminator.compile(optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","87be44ae":"Discriminator.trainable = False\n\nGan_Input = keras.Input(shape=(48,))\nGan_Output = Discriminator(Generator(Gan_Input))\nGAN_Model = keras.models.Model(Gan_Input,Gan_Output)","dc5c7b49":"GAN_Model.compile(optimizer=RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","4003fa87":"print(GAN_Model.layers)","1fba8b58":"os.mkdir(\"face_new\")","5f99c546":"start = 0\nbatch_size = 32\niterations = 10000\nfor step in range(iterations):\n    random_noise_vector = np.random.normal(size=(batch_size,48)) #32\n    generation_images = Generator.predict(random_noise_vector)\n    \n    stop = start + batch_size\n    real_images = Array_IMG_Set[start:stop]\n    \n    combined_images = np.concatenate([generation_images,real_images])\n    \n    labels = np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size,1))])\n    labels += 0.05 * np.random.random(labels.shape)\n    \n    D_loss = Discriminator.train_on_batch(combined_images,labels)\n    \n    random_noise_vector = np.random.normal(size=(batch_size,48)) #32\n    \n    misleading_targets = np.zeros((batch_size,1))\n    \n    a_loss = GAN_Model.train_on_batch(random_noise_vector,misleading_targets)\n    \n    start += batch_size\n    \n    if start > len(Array_IMG_Set) - batch_size:\n        start = 0\n    \n    if step % 100 == 0:\n        GAN_Model.save_weights(\"GAN_ONE.h5\")\n        \n        print(\"DISC_LOSS: \", D_loss)\n        print(\"ADVERSARIAL_LOSS: \", a_loss)\n        \n        Img = image.array_to_img(generation_images[0] * 255.,scale=False)\n        Img.save(os.path.join(\".\/face_new\",\"FAKE_FACES\"+str(step)+\".png\"))\n        \n        Img = image.array_to_img(real_images[0] * 255.,scale=False)\n        Img.save(os.path.join(\".\/face_new\",\"REAL_FACES\"+str(step)+\".png\"))","06e9c4e1":"Exp_output = Path(\".\/face_new\")","04bff487":"list_output = list(Exp_output.glob(r\"*.png\"))","ef4be6d4":"list_output_series = pd.Series(list_output,name=\"PNG\").astype(str)","2fb236f7":"Exm_Out_IMG = list_output_series[7]\nx_IMG_Out = cv2.imread(Exm_Out_IMG)\nplt.imshow(x_IMG_Out)","49a0c3ef":"noise_PR = tf.random.normal(shape=[25,48])","e86d60fd":"print(noise_PR.shape)","e8acd607":"plt.imshow(noise_PR)","ad663491":"PR_Images = Generator(noise_PR)","a3abc543":"single_IMG = PR_Images[0]","209ff4b9":"plt.imshow(single_IMG)","767a0baf":"figure, axes = plt.subplots(nrows=5,ncols=5,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(PR_Images[i],cmap=\"Greys_r\")\n    ax.set_xlabel(PR_Images[i].shape)\nplt.tight_layout()\nplt.show()","56c40770":"figure, axes = plt.subplots(nrows=4,ncols=4,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    List_Gen_Image = cv2.imread(list_output_series[i])\n    ax.imshow(List_Gen_Image,cmap=\"Greys_r\")\n    ax.set_xlabel(List_Gen_Image.shape)\n    ax.set_ylabel(List_Gen_Image.size)\nplt.tight_layout()\nplt.show()","758241e6":"#### MAIN PATH","ae9f675e":"#### TRAINING","365445ba":"# VISUALIZATION","c35b6eac":"#### TO SERIES","f206be84":"#### STRUCTURE","9c1a48eb":"#### SHUFFLING","9c90f675":"#### PNG PATH","2ff73aa0":"# PATH & LABEL PROCESS","e5dc3f30":"#### DATA ENGINEERING","155cbc53":"# HISTORY","71b8271b":"# PACKAGES AND LIBRARIES","aea033f1":"# GAN - Generative Adversarial Networks","6ae195ef":"#### PNG LABELS","05ab2bff":"#### TO DATAFRAME","4fc31960":"* Facial Expression Recog Image Ver of (FERC)Dataset\n* Facial Expression Recognition: Image Only Version of the original (FERC) Dataset."}}