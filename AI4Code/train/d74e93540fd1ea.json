{"cell_type":{"4e6334e7":"code","e88008e9":"code","3d1b08ca":"code","f4ee3332":"code","0d856eb2":"code","ec3b4e3a":"markdown","8920f318":"markdown"},"source":{"4e6334e7":"PLACEHOLDER_CORPUS_FILE_PATH = \"..\/input\/santi.txt\"\nPLACEHOLDER_SPLIT_MODE = \"jieba\"\nPLACEHOLDER_START_TEXT = \"\u7a0b\u5fc3\"\nPLACEHOLDER_GEN_LEN = 200\nPLACEHOLDER_TOPN = 5\nPLACEHOLDER_NGRAM_LEN = 4","e88008e9":"## Init\nimport random\nimport jieba\n\ncorpus_file = open(PLACEHOLDER_CORPUS_FILE_PATH, \"r\", encoding=\"utf-8\")\nraw_text = corpus_file.readlines()\ntext = \"\"\nfor line in raw_text:\n    text += line.strip()\ncorpus_file.close()","3d1b08ca":"## Model Config\n\n# \u9009\u62e9\u5206\u8bcd\u6216\u8005\u662f\u5206\u5b57\nsplit_mode = PLACEHOLDER_SPLIT_MODE\nif split_mode == \"char\":\n    token_list = [char for char in text]\n# \u5229\u7528jieba\u5e93\u5206\u8bcd\nelif split_mode == \"jieba\":\n    token_list = [word for word in jieba.cut(text)]\n# \u786e\u5b9angram\u7684\u5386\u53f2\u68c0\u7d22\u957f\u5ea6\uff0c\u5373n\nngram_len = PLACEHOLDER_NGRAM_LEN","f4ee3332":"## Run\n\n# \u521d\u59cb\u5316ngram\u8bcd\u5178\nngram_dict = {}\nfor i in range(1, ngram_len): # i = 1 2 3\n    for j in range(len(token_list) - i - 1):\n        # \u4ee5\u524dn-1\u4e2a\u8bcd\u4e3a\u952e\uff0c\u7b2cn\u4e2a\u8bcd\u4e3a\u503c\uff0c\u7edf\u8ba1\u6620\u5c04\u6b21\u6570\n        key = \"\".join(token_list[j: j + i + 1])\n        value = \"\".join(token_list[j + i + 1])\n        # \u4e3a\u7b2c\u4e00\u6b21\u51fa\u73b0\u7684\u952e\u5efa\u7acb\u5b57\u5178\n        if key not in ngram_dict:\n            ngram_dict[key] = {}\n        # \u521d\u59cb\u5316\u5b57\u5178\u5185\u6bcf\u4e2a\u952e\u503c\u5bf9\u6620\u5c04\u7684\u8ba1\u6570\u5668\n        if value not in ngram_dict[key]:\n            ngram_dict[key][value] = 0\n        ngram_dict[key][value] += 1","0d856eb2":"# \u5bf9\u8f93\u5165\u8fdb\u884c\u5206\u5b57\u6216\u5206\u8bcd\nstart_text = PLACEHOLDER_START_TEXT\ngen_len = PLACEHOLDER_GEN_LEN\ntopn = PLACEHOLDER_TOPN\n\nif split_mode == \"char\":\n    word_list = [char for char in start_text]\nelif split_mode == \"jieba\":\n    word_list = [word for word in jieba.cut(start_text)]\n\n# gen_len\u662f\u6211\u4eec\u671f\u671b\u7684\u751f\u6210\u5b57\u6570\u6216\u8bcd\u6570\nfor i in range(gen_len):\n    temp_list = []\n    # \u7edf\u8ba1\u7ed9\u5b9a\u524d\u5c0f\u4e8e\u7b49\u4e8en-1\u4e2a\u8bcd\u7684\u60c5\u51b5\u4e0b\uff0c\u4e0b\u4e00\u4e2a\u8bcd\u7684\u8bcd\u9891\u5206\u5e03\n    for j in range(1, ngram_len):\n        if j >= len(word_list):\n            continue\n        prefix = \"\".join(word_list[-(j + 1):])\n        if prefix in ngram_dict:\n            temp_list.extend(ngram_dict[prefix].items())\n    # \u6309\u8bcd\u9891\u5bf9\u8bcd\u6392\u5e8f\n    temp_list = sorted(temp_list, key=lambda d: d[1], reverse=True)\n    next_word = ''\n    if len(temp_list) == 0:\n        next_word = token_list[random.randint(0, len(token_list))]\n    elif temp_list[0] == '\uff0c' or temp_list[0] == '\u3002' or temp_list[0] == '\\n':\n        # \u5982\u679c\u6700\u9ad8\u9891\u8bcd\u662f\u6807\u70b9\uff0c\u5219\u9009\u62e9\u6700\u9ad8\u9891\u8bcd\n        next_word = temp_list[0]\n    else:\n    # \u5426\u5219\u4ece\u524dtopn\u4e2d\u968f\u673a\u9009\u4e00\u4e2a\n        next_word = random.choice(sorted(temp_list, key=lambda d: d[1], reverse=True)[:topn])[0]\n    word_list.append(next_word)\n   \nprint(\"\".join(word_list))","ec3b4e3a":"# ngram","8920f318":"## Train"}}