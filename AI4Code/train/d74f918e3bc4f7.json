{"cell_type":{"6f0f7227":"code","f10f61f5":"code","8e88d6fb":"code","fa02190f":"code","42e92634":"code","bae4a1b2":"code","732dbe16":"code","eeb48e74":"code","f5b83d98":"code","fb03106a":"code","70d2c81c":"code","1a842fba":"code","f099e43a":"code","6dac7f00":"code","0d46303b":"code","36e2e3c8":"code","4f17e2de":"markdown","0967b7fa":"markdown","146cef8c":"markdown","d5ec15a9":"markdown","952b1f88":"markdown","4469fe61":"markdown"},"source":{"6f0f7227":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","f10f61f5":"torch.set_num_threads(4)","8e88d6fb":"train = pd.read_csv('..\/input\/train.csv', dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})","fa02190f":"train.head()","42e92634":"sample_freq = 100\nplt.plot(train.acoustic_data.values[::sample_freq])\nplt.plot(train.time_to_failure.values[::sample_freq]*100)","bae4a1b2":"def extract_features(z):\n    return np.c_[\n        z.mean(axis=1), \n        np.percentile(np.abs(z), q=[0, 25, 50, 75, 100], axis=1).T, \n        z.std(axis=1)\n    ]","732dbe16":"def create_X(x, window_size=1000, sequence_len=150):\n    tmp = x.reshape(sequence_len, -1)\n    return np.c_[\n        extract_features(tmp),\n        extract_features(tmp[:, -window_size \/\/ 10:]),\n        extract_features(tmp[:, -window_size \/\/ 100:])\n    ]","eeb48e74":"n_features = create_X(train.acoustic_data.values[0:150000]).shape[1]","f5b83d98":"class TrainData(Dataset):\n    def __init__(self, df, window_size=1000, sequence_len=150):\n        self.rows = df.shape[0] \/\/ (window_size*sequence_len)\n        self.data, self.labels = [], []\n        for segment in range(self.rows):\n            seg = df.iloc[segment*window_size*sequence_len: (segment+1)*window_size*sequence_len]\n            x = seg.acoustic_data.values\n            y = seg.time_to_failure.values[-1]\n            self.data.append(create_X(x))\n            self.labels.append(y)\n    \n    def __len__(self):\n        return self.rows\n    \n    def __getitem__(self, idx):\n        return (\n            torch.from_numpy(self.data[idx].astype(np.float32)),\n            self.labels[idx]\n        )","fb03106a":"train_data = TrainData(train)","70d2c81c":"batch_size = 100\nn_steps = len(train_data) \/\/ 100","1a842fba":"train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)","f099e43a":"class LSTM(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(LSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, 1)\n    \n    def forward(self, x):\n        hidden = (\n            torch.zeros(1, x.size(0), self.hidden_size),\n            torch.zeros(1, x.size(0), self.hidden_size)\n        )\n        \n        out, _ = self.lstm(x, hidden)\n        \n        out = self.fc(out[:, -1, :])\n        return out.view(-1)","6dac7f00":"input_size = n_features\nhidden_size = 32\nmodel = LSTM(input_size, hidden_size)","0d46303b":"learning_rate = 0.01\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","36e2e3c8":"for epoch in range(2):\n    for i, (data, labels) in enumerate(train_loader):\n        outputs = model(data)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if i % 10 == 0:\n            print(f'[Epoch {epoch}\/2, Step {i}\/{n_steps}]  loss: {loss.item(): .4f}')","4f17e2de":"This kernel use PyTorch to implement LSTM for [LANL Earthquake Prediction](https:\/\/www.kaggle.com\/c\/LANL-Earthquake-Prediction). The ideas and features are mainly from [RNN starter ](https:\/\/www.kaggle.com\/mayer79\/rnn-starter) with little adjustment. Because the hyperparameter has not tuned, so the model can not be used for prediction directly. It's just for demo.","0967b7fa":"Because our test data has 150000 points in each segment. we use window_size=1000 and sequence_length=150.","146cef8c":"That's all, thank's for advice!","d5ec15a9":"torch.utils.data.Dataset is a convenient tools for data loading provided by PyTorch.\n\nIt is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n\n- `__len__` so that len(dataset) returns the size of the dataset.\n- `__getitem__` to support the indexing such that dataset[i] can be used to get ith sample","952b1f88":"Extracts mean, standard deviation, and quantiles per time step.","4469fe61":"We sample 1% of the data(sample_freq=100). There are 16 earth quakes."}}