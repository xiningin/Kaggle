{"cell_type":{"1346107d":"code","9fa1eca9":"code","e4b88d6c":"code","3578d6b1":"code","30803050":"code","16666920":"code","a4e37724":"code","6c8f8a6f":"code","28374d5c":"code","ebb4f150":"code","dceaecb1":"code","65263cee":"code","20f2a06d":"code","d279e12c":"code","bec33bfc":"code","9a7c9171":"code","c246e19f":"code","90d89378":"code","0dd15c1a":"code","f81cf462":"code","abc2599b":"code","dcf8c4a7":"code","9f9ba113":"code","a744d3f3":"code","92071140":"code","dd9e6742":"code","adc1809d":"code","7591fb4d":"code","1153406a":"code","cb54db06":"code","3eae6a9f":"code","ec7e81a3":"code","95560774":"markdown"},"source":{"1346107d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n\n# Any results you write to the current directory are saved as output.","9fa1eca9":"games = pd.read_csv('..\/input\/Video_Games_Sales_as_at_22_Dec_2016.csv')\ngames.head()","e4b88d6c":"pd.isnull(games).sum() > 0","3578d6b1":"len(games)","30803050":"values = {'Critic_Score': 0, 'Critic_Count': 0, 'User_Score': 0, 'User_Count': 0}\ngames['Critic_Score'].fillna(0, inplace=True)\ngames['Critic_Count'].fillna(0, inplace=True)\ngames['User_Score'].fillna(0, inplace=True)\ngames['User_Count'].fillna(0, inplace=True)\ngames.loc[games['Publisher']=='Nintendo', ['Developer']] = 'Nintendo'\ngames.loc[games['Publisher']=='Nintendo', ['Rating']] = 'E'\ngames.loc[games['Publisher']=='Activision', ['Rating']] = 'M'\ngames.loc[games['Publisher']=='Activision', ['Developer']] = 'Treyarch'\n# the user score to 0 where user score is tbd\ngames.loc[games['User_Score']=='tbd', ['User_Score']] = 0\n#convert user score to a np.number\ngames['User_Score']=games['User_Score'].astype(np.number)","16666920":"del games['Year_of_Release']\ngames = games.dropna(how='any',axis=0)\npd.isnull(games).sum() > 0","a4e37724":"games.head()","6c8f8a6f":"# m_or_e = ['E', 'M']\n# ratingsEM = games.loc[games['Rating'].isin(m_or_e)]\n# len(ratingsEM)\nratingsEM = games.copy()","28374d5c":"ratingsEM.head()","ebb4f150":"del ratingsEM['NA_Sales']\ndel ratingsEM['EU_Sales']\ndel ratingsEM['JP_Sales']\ndel ratingsEM['Other_Sales']\nratingsEM.head()","dceaecb1":"def create_label_encoder_dict(df):\n    from sklearn.preprocessing import LabelEncoder\n\n    label_encoder_dict = {}\n    for column in df.columns:\n        # Only create encoder for categorical data types\n        if not np.issubdtype(df[column].dtype, np.number) and column != 'Age':\n            label_encoder_dict[column]= LabelEncoder().fit(df[column].astype(str))\n    return label_encoder_dict","65263cee":"label_encoders = create_label_encoder_dict(ratingsEM)\nprint(\"Encoded Values for each Label\")\nprint(\"=\"*32)\nfor column in label_encoders:\n    print(\"=\"*32)\n    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))\n    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)","20f2a06d":"ratingsEM_data = ratingsEM.copy() # create copy of initial data set\nfor column in ratingsEM_data.columns:\n    if column in label_encoders:\n        ratingsEM_data[column] = label_encoders[column].transform(ratingsEM_data[column])\nprint(\"Transformed data set\")\nprint(\"=\"*32)\nratingsEM_data.head()","d279e12c":"X_data = ratingsEM_data[['Platform', 'Genre', 'Publisher', 'Developer']]\nY_data = ratingsEM_data['Rating']","bec33bfc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30)","9a7c9171":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree","c246e19f":"# Create the classifier with a maximum depth of 2 using entropy as the criterion for choosing most significant nodes\n# to build the tree\nclf = DecisionTreeClassifier(criterion='entropy',min_samples_split=2)\n# Hint : Change the max_depth to 10 or another number to see how this affects the tree","90d89378":"clf.fit(X_train, y_train)","0dd15c1a":"pd.DataFrame([ \"%.2f%%\" % perc for perc in (clf.feature_importances_ * 100)], \\\n             index = X_data.columns, columns = ['Feature Significance in Decision Tree'])\n\n","f81cf462":"figureObject, axesObject = plt.subplots()\naxesObject.pie(clf.feature_importances_ * 100, labels=X_data.columns,autopct='%1.2f',startangle=90)\naxesObject.axis('equal')\nplt.title('Feature Significance in Decision Tree')","abc2599b":"import graphviz","dcf8c4a7":"dot_data = tree.export_graphviz(clf,out_file=None,\nfeature_names=X_data.columns,\nclass_names=label_encoders[Y_data.name].classes_,\nfilled=True, rounded=True, proportion=True,\nnode_ids=True, #impurity=False,\nspecial_characters=True)","9f9ba113":"graph = graphviz.Source(dot_data)\ngraph","a744d3f3":"def tree_to_code(tree, feature_names, label_encoders={}):\n    from sklearn.tree import _tree\n    '''\n     Outputs a decision tree model as a Python function\n     Parameters:\n     -----------\n     tree: decision tree model\n     The decision tree to represent as a function\n     feature_names: list\n     The feature names of the dataset used for building the decision tree\n     '''\n    tree_ = tree.tree_\n    feature_name = [\n        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n        for i in tree_.feature\n    ]\n    print(\"def decision_tree({}):\".format(\", \".join(feature_names)))\n    def recurse(node, depth):\n        indent = \" \" * depth\n        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n            name = feature_name[node]\n            threshold = tree_.threshold[node]\n            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n            recurse(tree_.children_left[node], depth + 1)\n            print(\"{}else: # if {} > {}\".format(indent, name, threshold))\n            recurse(tree_.children_right[node], depth + 1)\n        else:\n            #print(node)\n\n            name = tree_.feature[node]\n            if name in label_encoders:\n                if isinstance(label_encoders[name] , LabelEncoder) or True:\n                    print (\"{}-return {}\".format(indent, label_encoders[name].inverse_transform(tree_.value[node])))\n                    return\n            print(\"{}return {} # Distribution of samples in node\".format(indent, tree_.value[node]))\n    recurse(0, 1)","92071140":"print(\"Decision Tree Rules\")\nprint(\"=\"*32)\ntree_to_code(clf, X_data.columns, label_encoders)","dd9e6742":"label_encoders = create_label_encoder_dict(ratingsEM)\nprint(\"Encoded Values for each Label\")\nprint(\"=\"*32)\nfor column in label_encoders:\n    print(\"=\"*32)\n    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))\n    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)","adc1809d":"k=(clf.predict(X_test) == y_test) # Determine how many were predicted correctly","7591fb4d":"k.value_counts()","1153406a":"from sklearn.metrics import confusion_matrix","cb54db06":"cm=confusion_matrix(y_test, clf.predict(X_test), labels=y_test.unique())\ncm","3eae6a9f":"def plot_confusion_matrix(cm, classes,\n    normalize=False,\n    title='Confusion matrix',\n    cmap=plt.cm.Blues):\n    import itertools\n    \"\"\"\n     This function prints and plots the confusion matrix.\n     Normalization can be applied by setting `normalize=True`.\n     \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True Rating')\n    plt.xlabel('Predicted Rating')","ec7e81a3":"plot_confusion_matrix(cm,ratingsEM['Rating'].unique())","95560774":"**Group Members**\n\nLemar Gray: 0901213\n\nStephen Mitchell: 1401420\n\nRadcliffe Gabbidon: 0905632\n\n**Questions: **\n\n*Linear Regression*\n\nWhat attributes of the dataset relatively affects a significant amount of downloads or purchases?\n\n*Decision Tree*\n\nWhat will be the ratings of the games given the categorical attributes, platform, genre, publisher and developer?"}}