{"cell_type":{"5b90aa8d":"code","78f91d5c":"code","06db22a7":"code","e523e2f2":"code","9d3f8aa6":"code","f5024577":"code","3a77d636":"code","f9852d84":"code","d3368bcf":"code","25ce8988":"code","b9318fd2":"code","9540d197":"code","497dc389":"code","06ff8142":"code","46284d93":"code","eba8add9":"code","7f91cc95":"code","78470866":"code","f2481297":"code","03a3ac56":"code","a97795c9":"code","366e4f42":"code","438872ba":"code","bbf4621d":"code","7be3b9eb":"code","d6e505af":"code","a0bdde3b":"code","4fb89686":"code","cde77fc7":"code","7bbe9a20":"code","09dd6311":"code","9a139e78":"code","c259c781":"code","8b5b673f":"code","0eaeb4f7":"code","3c117c8e":"code","63a4ac2f":"code","180a8501":"code","ace1f081":"code","2b489c35":"code","2a53c6d1":"code","52eff332":"code","c0fe7407":"code","5f49943a":"code","d88a40d0":"code","dd3e95ff":"code","7a3a1a23":"code","22940446":"code","cffc31f1":"code","8317a11a":"code","e4ec4dfb":"code","05d8e7c2":"code","e38dc8c2":"code","9478ab3c":"code","33fa6638":"code","43ece798":"code","4f2acaa2":"code","e79335ca":"code","4c5661e4":"code","20c7cb82":"code","fc841bb7":"code","edbc6c9d":"code","35b9e317":"code","bfd174e2":"code","958b4d77":"code","9826955c":"code","948fde08":"code","80f7ad34":"code","b67950f1":"code","ec980dd3":"code","a47802fa":"code","ef4a4cbb":"code","d716d5dd":"code","f5bca6af":"code","a404fc45":"code","6110e4d1":"code","771467e9":"code","e09b9c0a":"code","8a2bc565":"code","a4888753":"code","87c6febb":"code","b55d65f0":"code","e05ae104":"code","74cdcf28":"code","dd4a2532":"code","7e566681":"code","1bbc2f15":"code","1db00425":"code","0249e9f3":"code","acdb5a5d":"code","0fa2e432":"code","4e134431":"code","97ff227c":"code","89f0009e":"code","f36156d6":"code","ed782957":"code","5e23c523":"code","888263ed":"code","2ddec3c3":"code","033cb992":"code","dbe896a9":"code","0d8f991a":"code","f6bd65e5":"code","5eb03a0e":"code","e7beac94":"code","4c2ba9a5":"code","a6929dfd":"code","6fa90b9f":"markdown","9367d51a":"markdown","75c46660":"markdown","b3c5e47b":"markdown","83780a12":"markdown","7d85760d":"markdown","529d00d1":"markdown","cc0c3ceb":"markdown","8da8f6fa":"markdown","3f186906":"markdown","966ac8fe":"markdown","d1b35ac9":"markdown","a5ecc6c5":"markdown","ed4d5063":"markdown","9f0caa21":"markdown","ccadd4d9":"markdown","0409c1ee":"markdown","e60dad6a":"markdown","0a8d3f91":"markdown","6a297122":"markdown","a69ee231":"markdown","a16062be":"markdown","3ffc1098":"markdown","3f5cf07d":"markdown","a8332768":"markdown","e777b907":"markdown","4fdcc4f2":"markdown","fec7e027":"markdown","d4f7fe69":"markdown","ccd38ef9":"markdown","a95b2186":"markdown","67f2dbde":"markdown","3671c13b":"markdown","47f71242":"markdown","70246098":"markdown","faacd1e4":"markdown","c7aca010":"markdown","e1e3fe30":"markdown","be559f35":"markdown","023dd54b":"markdown","07641be2":"markdown","422e3820":"markdown","4c2d99a1":"markdown","392e96b8":"markdown","109fb757":"markdown","e26e36bc":"markdown","fe4de9b5":"markdown","f9d2edcd":"markdown","3bb3ed42":"markdown","e8287516":"markdown","b3ad8550":"markdown","30df5d01":"markdown"},"source":{"5b90aa8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n# from pandas_profiling import ProfileReport\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","78f91d5c":"train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/submission.csv')","06db22a7":"train.head()","e523e2f2":"test.head()","9d3f8aa6":"# train_profile = ProfileReport(train, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# train_profile","f5024577":"# test_profile = ProfileReport(test, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# test_profile","3a77d636":"from plotly.offline import iplot\nfrom plotly import tools\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\npy.init_notebook_mode(connected=True)","f9852d84":"temp = train.groupby(['Date', 'Country\/Region'])['ConfirmedCases'].sum().reset_index()\ntemp['Date'] = pd.to_datetime(temp['Date']).dt.strftime('%m\/%d\/%Y')\ntemp['size'] = temp['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(temp, locations=\"Country\/Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country\/Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Cases Over Time', color_continuous_scale=\"greens\")\nfig.show()","d3368bcf":"grouped = train.groupby('Date')['Date', 'ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nfig = px.line(grouped, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Worldwide Confirmed Cases Over Time\")\nfig.show()\n\nfig = px.line(grouped, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Worldwide Confirmed Cases (Logarithmic Scale) Over Time\", \n              log_y=True)\nfig.show()","25ce8988":"latest_grouped = train.groupby('Country\/Region')['ConfirmedCases', 'Fatalities'].sum().reset_index()","b9318fd2":"fig = px.bar(latest_grouped.sort_values('ConfirmedCases', ascending=False)[:20][::-1], \n             x='ConfirmedCases', y='Country\/Region',\n             title='Confirmed Cases Worldwide', text='ConfirmedCases', height=1000, orientation='h')\nfig.show()","9540d197":"europe = list(['Austria','Belgium','Bulgaria','Croatia','Cyprus','Czechia','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Ireland',\n               'Italy', 'Latvia','Luxembourg','Lithuania','Malta','Norway','Netherlands','Poland','Portugal','Romania','Slovakia','Slovenia',\n               'Spain', 'Sweden', 'United Kingdom', 'Iceland', 'Russia', 'Switzerland', 'Serbia', 'Ukraine', 'Belarus',\n               'Albania', 'Bosnia and Herzegovina', 'Kosovo', 'Moldova', 'Montenegro', 'North Macedonia'])\neurope_grouped_latest = latest_grouped[latest_grouped['Country\/Region'].isin(europe)]","497dc389":"temp = train[train['Country\/Region'].isin(europe)]\ntemp = temp.groupby(['Date', 'Country\/Region'])['ConfirmedCases'].sum().reset_index()\ntemp['Date'] = pd.to_datetime(temp['Date']).dt.strftime('%m\/%d\/%Y')\ntemp['size'] = temp['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(temp, locations=\"Country\/Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country\/Region\", \n                     range_color=[1,100],scope='europe',\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Cases Over Time', color_continuous_scale='Cividis_r')\nfig.show()","06ff8142":"fig = px.bar(europe_grouped_latest.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Country\/Region', color_discrete_sequence=['#84DCC6'],\n             title='Confirmed Cases in Europe', text='ConfirmedCases', orientation='h')\nfig.show()","46284d93":"usa = train[train['Country\/Region'] == \"US\"]\nusa_latest = usa[usa['Date'] == max(usa['Date'])]\nusa_latest = usa_latest.groupby('Province\/State')['ConfirmedCases', 'Fatalities'].max().reset_index()\nfig = px.bar(usa_latest.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Province\/State', color_discrete_sequence=['#D63230'],\n             title='Confirmed Cases in USA', text='ConfirmedCases', orientation='h')\nfig.show()","eba8add9":"usa = train[train['Country\/Region'] == \"US\"]\nusa_latest = usa[usa['Date'] == max(usa['Date'])]\nusa_latest = usa_latest.groupby(['Province\/State','Lat','Long'])['ConfirmedCases', 'Fatalities'].max().reset_index()\nfig = go.Figure()\nlimits = [(0,10),(10,50),(50,100),(100,500),(500,1000)]\ncolors = [\"royalblue\",\"crimson\",\"lightseagreen\",\"orange\",\"lightgrey\"]\n\nfor i in range(len(limits)):\n    lim = limits[i]\n    range_usa = usa_latest[usa_latest['ConfirmedCases'].between(lim[0], lim[1])]\n    fig.add_trace(go.Scattergeo(\n        locationmode = 'USA-states',\n        lon = range_usa['Long'],\n        lat = range_usa['Lat'],\n        text = range_usa['Province\/State'],\n        marker = dict(\n            size = range_usa['ConfirmedCases'],\n            color = colors[i],\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode='area'\n        ),\n        name = '{0} - {1}'.format(lim[0],lim[1])))\n\nfig.update_layout(\n        title_text = 'COVID19 in the US',\n        showlegend = True,\n        geo = dict(\n            scope = 'usa',\n            landcolor = 'rgb(217, 217, 217)',\n        )\n    )\n\nfig.show()","7f91cc95":"usa = train[train['Country\/Region'] == \"China\"]\nusa_latest = usa[usa['Date'] == max(usa['Date'])]\nusa_latest = usa_latest.groupby('Province\/State')['ConfirmedCases', 'Fatalities'].max().reset_index()\nfig = px.bar(usa_latest.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Province\/State', color_discrete_sequence=['#D63230'],\n             title='Confirmed Cases in USA', text='ConfirmedCases', orientation='h')\nfig.show()","78470866":"province_encoded = {state:index for index, state in enumerate(train['Province\/State'].unique())}","f2481297":"train['province_encoded'] = train['Province\/State'].apply(lambda x: province_encoded[x])\ntrain.head()","03a3ac56":"country_encoded = dict(enumerate(train['Country\/Region'].unique()))\ncountry_encoded = dict(map(reversed, country_encoded.items()))","a97795c9":"train['country_encoded'] = train['Country\/Region'].apply(lambda x: country_encoded[x])\ntrain.head()","366e4f42":"from datetime import datetime\nimport time","438872ba":"# date_encoded = {}\n# for s in train['Date'].unique():\n#     date_encoded[s] = time.mktime(datetime.strptime(s, \"%Y-%m-%d\").timetuple())","bbf4621d":"# train['date_encoded'] = train['Date'].apply(lambda x: date_encoded[x])\n# train['date_encoded'] = (train['date_encoded'] - train['date_encoded'].mean()) \/ train['date_encoded'].std()\n# train.head()","7be3b9eb":"train['Mon'] = train['Date'].apply(lambda x: int(x.split('-')[1]))\ntrain['Day'] = train['Date'].apply(lambda x: int(x.split('-')[2]))","d6e505af":"train['serial'] = train['Mon'] * 30 + train['Day']\ntrain.head()","a0bdde3b":"train['serial'] = train['serial'] - train['serial'].min()","4fb89686":"train.describe()","cde77fc7":"gdp2020 = pd.read_csv('\/kaggle\/input\/gdp2020\/GDP2020.csv')\npopulation2020 = pd.read_csv('\/kaggle\/input\/population2020\/population2020.csv')","7bbe9a20":"gdp2020 = gdp2020.rename(columns={\"rank\":\"rank_gdp\"})\ngdp2020_numeric_list = [list(gdp2020)[0]] + list(gdp2020)[2:-1]\ngdp2020.head()","09dd6311":"map_state = {'US':'United States', \n             'Korea, South':'South Korea',\n             'Cote d\\'Ivoire':'Ivory Coast',\n             'Czechia':'Czech Republic',\n             'Eswatini':'Swaziland',\n             'Holy See':'Vatican City',\n             'Jersey':'United Kingdom',\n             'North Macedonia':'Macedonia',\n             'Taiwan*':'Taiwan',\n             'occupied Palestinian territory':'Palestine'\n            }\nmap_state_rev = {v: k for k, v in map_state.items()}","9a139e78":"population2020['name'] = population2020['name'].apply(lambda x: map_state_rev[x] if x in map_state_rev else x)\ngdp2020['country'] = gdp2020['country'].apply(lambda x: map_state_rev[x] if x in map_state_rev else x)","c259c781":"set(train['Country\/Region']) - set(population2020['name'])","8b5b673f":"set(train['Country\/Region']) - set(gdp2020['country'])","0eaeb4f7":"population2020 = population2020.rename(columns={\"rank\":\"rank_pop\"})\npopulation2020_numeric_list = [list(population2020)[0]] + list(gdp2020)[2:]\npopulation2020.head()","3c117c8e":"train = pd.merge(train, population2020, how='left', left_on = 'Country\/Region', right_on = 'name')\ntrain = pd.merge(train, gdp2020, how='left', left_on = 'Country\/Region', right_on = 'country')","63a4ac2f":"train.isnull().sum()","180a8501":"train = train.fillna(0)","ace1f081":"train['Country\/Region'][train.isnull()['Lat'] | train.isnull()['Long']].unique()","2b489c35":"# train.loc[:,'Lat'][train['Country\/Region']=='Aruba'] = -69.9683\n# train.loc[:,'Long'][train['Country\/Region']=='Aruba'] = 12.5211","2a53c6d1":"# numeric_features_X = ['Lat','Long', 'province_encoded' ,'country_encoded','Mon','Day']\nnumeric_features_X = ['Lat','Long', 'province_encoded' ,'country_encoded','Mon','Day'] + population2020_numeric_list + gdp2020_numeric_list\nnumeric_features_Y = ['ConfirmedCases', 'Fatalities']\ntrain_numeric_X = train[numeric_features_X]\ntrain_numeric_Y = train[numeric_features_Y]","52eff332":"test['province_encoded'] = test['Province\/State'].apply(lambda x: province_encoded[x] if x in province_encoded else max(province_encoded.values())+1)","c0fe7407":"test['country_encoded'] = test['Country\/Region'].apply(lambda x: country_encoded[x] if x in country_encoded else max(country_encoded.values())+1)","5f49943a":"test['Mon'] = test['Date'].apply(lambda x: int(x.split('-')[1]))\ntest['Day'] = test['Date'].apply(lambda x: int(x.split('-')[2]))","d88a40d0":"test['serial'] = test['Mon'] * 30 + test['Day']\ntest['serial'] = test['serial'] - test['serial'].min()","dd3e95ff":"test = pd.merge(test, population2020, how='left', left_on = 'Country\/Region', right_on = 'name')\ntest = pd.merge(test, gdp2020, how='left', left_on = 'Country\/Region', right_on = 'country')","7a3a1a23":"# date_encoded = {}\n# for s in test['Date'].unique():\n#     date_encoded[s] = time.mktime(datetime.strptime(s, \"%Y-%m-%d\").timetuple())\n# test['date_encoded'] = test['Date'].apply(lambda x: date_encoded[x])\n# test['date_encoded'] = (test['date_encoded'] - test['date_encoded'].mean()) \/ test['date_encoded'].std()\n# test.head()","22940446":"# test.loc[:,'Lat'][test['Country\/Region']=='Aruba'] = -69.9683\n# test.loc[:,'Long'][test['Country\/Region']=='Aruba'] = 12.5211","cffc31f1":"test_numeric_X = test[numeric_features_X]\ntest_numeric_X.isnull().sum()","8317a11a":"test_numeric_X = test_numeric_X.fillna(-1)","e4ec4dfb":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression","05d8e7c2":"pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', LinearRegression())])\npipeline.fit(train_numeric_X, train_numeric_Y)","e38dc8c2":"predicted = pipeline.predict(test_numeric_X)","9478ab3c":"# submission = np.vstack((test['ForecastId'], predicted[:,0],predicted[:,1])).T\n# submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('LR_submission.csv', index=False)","33fa6638":"predicted_x = pipeline.predict(train_numeric_X)\nplt.scatter(train_numeric_Y['ConfirmedCases'], train_numeric_Y['Fatalities'],  color='gray', label='sample')\nplt.plot(predicted_x[:,0], predicted_x[:,1], color='red', linewidth=2, label='pred')\nplt.title('Regression Model Result',fontsize=20)\nplt.xlabel('ConfirmedCases',fontsize=15)\nplt.ylabel('Fatalities',fontsize=15)\nplt.legend()\nplt.show()","43ece798":"from sklearn.svm import SVR","4f2acaa2":"pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', SVR())])\npipeline.fit(train_numeric_X, train_numeric_Y.values[:,0])\npipeline2 = Pipeline([('scaler', StandardScaler()), ('estimator', SVR())])\npipeline2.fit(train_numeric_X, train_numeric_Y.values[:,1])\ndiscovered, fatal = pipeline.predict(test_numeric_X), pipeline2.predict(test_numeric_X)","e79335ca":"# submission = np.vstack((test['ForecastId'], discovered, fatal)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('SVR_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","4c5661e4":"predicted_x1 = pipeline.predict(train_numeric_X)\npredicted_x2 = pipeline2.predict(train_numeric_X)\n\nplt.scatter(train_numeric_Y['ConfirmedCases'], train_numeric_Y['Fatalities'],  color='gray', label='sample')\nplt.plot(predicted_x1, predicted_x2, color='red', linewidth=2, label='pred')\nplt.title('SVR Model Result',fontsize=20)\nplt.xlabel('ConfirmedCases',fontsize=15)\nplt.ylabel('Fatalities',fontsize=15)\nplt.legend()\nplt.show()","20c7cb82":"from sklearn.neighbors import KNeighborsClassifier","fc841bb7":"pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', KNeighborsClassifier(n_jobs=4))])\npipeline.fit(train_numeric_X, train_numeric_Y)","edbc6c9d":"predicted_x = pipeline.predict(train_numeric_X)\nplt.scatter(train_numeric_Y['ConfirmedCases'], train_numeric_Y['Fatalities'],  color='gray', label='sample')\nplt.scatter(predicted_x[:,0], predicted_x[:,1], color='red', linewidth=2, label='pred')\nplt.title('KNN Model Result',fontsize=20)\nplt.xlabel('ConfirmedCases',fontsize=15)\nplt.ylabel('Fatalities',fontsize=15)\nplt.legend()\nplt.show()","35b9e317":"from sklearn.ensemble import RandomForestClassifier","bfd174e2":"RF_model = RandomForestClassifier(n_estimators=50,n_jobs=4,verbose=True)\nRF_model.fit(train_numeric_X, train_numeric_Y)","958b4d77":"# predicted = RF_model.predict(test_numeric_X)\n# submission = np.vstack((test['ForecastId'], predicted[:,0],predicted[:,1])).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('RF_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","9826955c":"predicted_x = RF_model.predict(train_numeric_X)\nplt.scatter(train_numeric_Y['ConfirmedCases'], train_numeric_Y['Fatalities'],  color='gray', label='sample',s=25)\nplt.scatter(predicted_x[:,0], predicted_x[:,1], color='red', label='pred',alpha=.4, s=10)\nplt.title('KNN Model Result',fontsize=20)\nplt.xlabel('ConfirmedCases',fontsize=15)\nplt.ylabel('Fatalities',fontsize=15)\nplt.legend()\nplt.show()","948fde08":"from sklearn.ensemble import AdaBoostClassifier","80f7ad34":"adaboost_model_for_ConfirmedCases = AdaBoostClassifier(n_estimators=15)\nadaboost_model_for_ConfirmedCases.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[0]])\nadaboost_model_for_Fatalities = AdaBoostClassifier(n_estimators=15)\nadaboost_model_for_Fatalities.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[1]])","b67950f1":"# predicted = adaboost_model_for_ConfirmedCases.predict(test_numeric_X)\n# predicted2 = adaboost_model_for_Fatalities.predict(test_numeric_X)\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('Adaboost_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","ec980dd3":"predicted_x1 = adaboost_model_for_ConfirmedCases.predict(train_numeric_X)\npredicted_x2 = adaboost_model_for_Fatalities.predict(train_numeric_X)\n\nplt.scatter(train_numeric_Y['ConfirmedCases'], train_numeric_Y['Fatalities'],  color='gray', label='sample',s=25)\nplt.scatter(predicted_x1,predicted_x2, color='red', label='pred',alpha=.4, s=10)\nplt.title('Adaboost Model Result',fontsize=20)\nplt.xlabel('ConfirmedCases',fontsize=15)\nplt.ylabel('Fatalities',fontsize=15)\nplt.legend()\nplt.show()","a47802fa":"# from sklearn.ensemble import StackingClassifier","ef4a4cbb":"# estimators = [('rf',RF_model ), ('ada', adaboost_model_for_ConfirmedCases)]\n# stacking_model_for_ConfirmedCases = StackingClassifier(estimators=estimators, n_jobs=4)\n# stacking_model_for_ConfirmedCases.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[0]])","d716d5dd":"# stacking_model_for_Fatalities = StackingClassifier(estimators=estimators, n_jobs=4)\n# stacking_model_for_Fatalities.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[1]])","f5bca6af":"# predicted = stacking_model_for_ConfirmedCases.predict(test_numeric_X)\n# predicted2 = stacking_model_for_Fatalities.predict(test_numeric_X)\n\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('stacking_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","a404fc45":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import model_selection\nfrom mlxtend.classifier import StackingCVClassifier","6110e4d1":"clf1 = KNeighborsClassifier(n_neighbors=100)\nclf2 = RandomForestClassifier(n_estimators=10)\nclf3 = GaussianNB()\n# Logit will be used for stacking\nlr = LogisticRegression(solver='lbfgs')\n# sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr, use_probas=True, cv=3)\nsclf = StackingCVClassifier(classifiers=[clf1, clf2], meta_classifier=lr, use_probas=True, cv=3)\n\n\n# Do CV\nfor clf, label in zip([clf1, clf2, clf3, sclf], \n                      ['KNN', \n                       'Random Forest', \n                       'Naive Bayes',\n                       'StackingClassifier']):\n\n    scores = model_selection.cross_val_score(clf, train_numeric_X.values, train_numeric_Y[numeric_features_Y[0]].values, cv=3, scoring='neg_mean_squared_log_error')\n    print(\"Avg_rmse: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","771467e9":"# clf1 = KNeighborsClassifier(n_neighbors=100)\n# clf1.fit(train_numeric_X.values, train_numeric_Y[numeric_features_Y[1]])\n# predicted2 = clf1.predict(test_numeric_X)\n\n# clf2 = RandomForestClassifier(n_estimators=10)\n# clf2.fit(train_numeric_X.values, train_numeric_Y[numeric_features_Y[0]])\n# predicted = clf2.predict(test_numeric_X)\n\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('opt_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","e09b9c0a":"train_y_pred = RF_model.predict(train_numeric_X)","8a2bc565":"# train_y_pred2 = clf2.predict(train_numeric_X)\n# train_y_pred =  np.stack((train_y_pred, train_y_pred2), axis=-1)","a4888753":"plt.figure(figsize=(12,8))\nplt.hist([train_numeric_Y['ConfirmedCases'],train_y_pred[:,0]],bins=100, range=(1,100), label=['ConfirmedCases_actual','ConfirmedCases_pred'],alpha=0.75)\nplt.title('ConfirmedCases Comparison',fontsize=20)\nplt.xlabel('sample',fontsize=20)\nplt.ylabel('match',fontsize=20)\nplt.legend()\nplt.show()","87c6febb":"plt.figure(figsize=(12,8))\nplt.hist([train_numeric_Y['Fatalities'],train_y_pred[:,1]],bins=100, range=(1,100), label=['Fatalities_actual','Fatalities_pred'],alpha=0.75)\nplt.title('Fatalities Comparison',fontsize=20)\nplt.xlabel('sample',fontsize=20)\nplt.ylabel('match',fontsize=20)\nplt.legend()\nplt.show()","b55d65f0":"error = np.sqrt((train_y_pred - train_numeric_Y)**2)\nerror = error.cumsum()","e05ae104":"fig,ax = plt.subplots()\n \nplt.xlabel('sample')\nplt.ylabel('error')\nplt.subplot(2, 1, 1)\nplt.plot(range(len(error)), error['ConfirmedCases'], \"x-\",label=\"ConfirmedCases\",color='orange')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(range(len(error)), error['Fatalities'], \"+-\", label=\"Fatalities\")\nplt.legend()\n\nplt.show()","74cdcf28":"from sklearn.metrics import mean_squared_error\nrmse = mean_squared_error(train_numeric_Y, train_y_pred , squared=False)\nrmse","dd4a2532":"corr = train[numeric_features_X+numeric_features_Y].corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","7e566681":"corr = train[numeric_features_X+numeric_features_Y].corr(method='spearman')\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","1bbc2f15":"corr = train[numeric_features_X+numeric_features_Y].corr(method='kendall')\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","1db00425":"RF_model.feature_importances_","0249e9f3":"plt.bar(range(len(numeric_features_X)), RF_model.feature_importances_, tick_label=numeric_features_X)\nplt.xlabel('feature')\nplt.ylabel('weight')\nplt.xticks(rotation=90)\nplt.show()","acdb5a5d":"f,ax = plt.subplots()\nax.scatter(train_numeric_Y['ConfirmedCases'], train_y_pred[:,0])\nax.scatter(train_numeric_Y['Fatalities'], train_y_pred[:,1])\n\nplt.show()","0fa2e432":"clf1 = RandomForestClassifier(n_estimators=1,n_jobs=4)\nclf3 = RandomForestClassifier(n_estimators=3,n_jobs=4)\nclf5 = RandomForestClassifier(n_estimators=5,n_jobs=4)\nclf10 = RandomForestClassifier(n_estimators=10,n_jobs=4)\nclf50 = RandomForestClassifier(n_estimators=50,n_jobs=4)","4e134431":"clf1.fit(train_numeric_X, train_numeric_Y)\nclf3.fit(train_numeric_X, train_numeric_Y)\nclf5.fit(train_numeric_X, train_numeric_Y)\nclf10.fit(train_numeric_X, train_numeric_Y)\nclf50.fit(train_numeric_X, train_numeric_Y)","97ff227c":"predicted1 = clf1.predict(train_numeric_X)\npredicted3 = clf3.predict(train_numeric_X)\npredicted5 = clf5.predict(train_numeric_X)\npredicted10 = clf10.predict(train_numeric_X)\npredicted50 = clf50.predict(train_numeric_X)","89f0009e":"a = np.sum((predicted1) - (train_numeric_Y))**2 \/ len(predicted1)\nb = np.sum((predicted3) - (train_numeric_Y))**2 \/ len(predicted3)\nc = np.sum((predicted5) - (train_numeric_Y))**2 \/ len(predicted5)\nd = np.sum((predicted10) - (train_numeric_Y))**2 \/ len(predicted10)\ne = np.sum((predicted50) - (train_numeric_Y))**2 \/ len(predicted50)","f36156d6":"dt_nums = [1,3,5,10,50]\nplt.figure(figsize=(15,10))\n\nplt.subplot(221)\nplt.title('Decision Tree Number & MSE \\n of ConfirmedCases',fontsize=20)\nplt.plot(range(len(dt_nums)), [a['ConfirmedCases'],b['ConfirmedCases'],c['ConfirmedCases'],d['ConfirmedCases'],e['ConfirmedCases']],\n         label='ConfirmedCases')\nplt.xlabel('decision tree numbers')\nplt.ylabel('mse')\nplt.xticks(range(len(dt_nums)),dt_nums)\nplt.legend()\n\nplt.subplot(222)\nplt.title('Decision Tree Number & MSE \\n of Fatalities',fontsize=20)\nplt.plot(range(len(dt_nums)), [a['Fatalities'],b['Fatalities'],c['Fatalities'],d['Fatalities'],e['Fatalities']],\n         label='Fatalities',color='y')\nplt.xlabel('decision tree numbers')\nplt.ylabel('mse')\nplt.xticks(range(len(dt_nums)),dt_nums)\nplt.legend()\n\nplt.show()","ed782957":"clf1 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=1)\nclf2 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=2)\nclf3 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=3)\nclf4 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=4)\nclf5 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=5)\nclf10 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=10)","5e23c523":"clf1.fit(train_numeric_X, train_numeric_Y)\nclf2.fit(train_numeric_X, train_numeric_Y)\nclf3.fit(train_numeric_X, train_numeric_Y)\nclf4.fit(train_numeric_X, train_numeric_Y)\nclf5.fit(train_numeric_X, train_numeric_Y)\nclf10.fit(train_numeric_X, train_numeric_Y)","888263ed":"predicted1 = clf1.predict(train_numeric_X)\npredicted2 = clf2.predict(train_numeric_X)\npredicted3 = clf3.predict(train_numeric_X)\npredicted4 = clf4.predict(train_numeric_X)\npredicted5 = clf5.predict(train_numeric_X)\npredicted10 = clf10.predict(train_numeric_X)","2ddec3c3":"a = np.sum((predicted1) - (train_numeric_Y))**2 \/ len(predicted1)\nb = np.sum((predicted2) - (train_numeric_Y))**2 \/ len(predicted2)\nc = np.sum((predicted3) - (train_numeric_Y))**2 \/ len(predicted3)\nd = np.sum((predicted4) - (train_numeric_Y))**2 \/ len(predicted4)\ne = np.sum((predicted5) - (train_numeric_Y))**2 \/ len(predicted5)\nf = np.sum((predicted10) - (train_numeric_Y))**2 \/ len(predicted10)","033cb992":"dt_nums = [1,2,3,4,5,10]\nplt.figure(figsize=(15,10))\n\nplt.subplot(221)\nplt.title('Decision Tree Depth & MSE \\n of ConfirmedCases',fontsize=20)\nplt.plot(range(len(dt_nums)), [a['ConfirmedCases'],b['ConfirmedCases'],c['ConfirmedCases'],d['ConfirmedCases'],e['ConfirmedCases'],f['ConfirmedCases']],\n         label='ConfirmedCases')\nplt.xlabel('decision tree depth')\nplt.ylabel('mse')\nplt.xticks(range(len(dt_nums)),dt_nums)\nplt.legend()\n\nplt.subplot(222)\nplt.title('Decision Tree Depth & MSE \\n of Fatalities',fontsize=20)\nplt.plot(range(len(dt_nums)), [a['Fatalities'],b['Fatalities'],c['Fatalities'],d['Fatalities'],e['Fatalities'],f['ConfirmedCases']],\n         label='Fatalities',color='y')\nplt.xlabel('decision tree depth')\nplt.ylabel('mse')\nplt.xticks(range(len(dt_nums)),dt_nums)\nplt.legend()\n\nplt.show()","dbe896a9":"from sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import GaussianNB","0d8f991a":"pipeline = Pipeline([('scale', StandardScaler()), ('pca', PCA(n_components=2))])\npca = pipeline.fit(train_numeric_X)\npca_X = pca.transform(train_numeric_X)","f6bd65e5":"fig = px.scatter(x=pca_X[:,0], y=pca_X[:,1])\nfig.show()","5eb03a0e":"fig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=pca_X[:,0],\n    y=pca_X[:,1],\n    marker=dict(color=\"crimson\", size=np.log(1 + train_numeric_Y['ConfirmedCases'])),\n    mode=\"markers\",\n    name=\"training data\",\n))\nfig.update_layout(title=\"PCA reduction scatter diagram\",\n                  xaxis_title=\"x\",\n                  yaxis_title=\"y\")\n\nfig.show()","e7beac94":" from sklearn.manifold import TSNE","4c2ba9a5":"X_embedded = TSNE(n_components=3).fit_transform(train_numeric_X)","a6929dfd":"fig = go.Figure(data=[go.Scatter3d(\n    x=X_embedded[:,0],\n    y=X_embedded[:,1],\n    z=X_embedded[:,2],\n    mode='markers',\n    marker=dict(\n        size=12,\n        color=train_numeric_Y['ConfirmedCases'],\n        colorscale='Viridis',\n        opacity=0.8\n    )\n)])\n\n# tight layout\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\nfig.show()","6fa90b9f":"## Import Data","9367d51a":"### take a look at China","75c46660":"### Country Encoding","b3c5e47b":"### Look into the depth of decision tree composed of RF - Avoiding Overfitting","83780a12":"- KNN attains the better performance than others w.r.t. Fatalities\n- RF attains the better performance than others w.r.t. ConfirmedCases","7d85760d":"### Boosting: Adaboost","529d00d1":"### SIR Model (Not yet)","cc0c3ceb":"### SVR","8da8f6fa":"#### Redefine all mismatch Country ","3f186906":"#### Losing Country in Population","966ac8fe":"The deeper depth gets the lower mse in confirmedCases but the higher fatalities","d1b35ac9":"## Evaluation","a5ecc6c5":"#### Losing Country in GDP2020","ed4d5063":"#### TSNE","9f0caa21":"## Exploratory Data Analysis","ccadd4d9":"Find out coordinate in Aruba from extra information","0409c1ee":"### Disease spread over the countries","e60dad6a":"## Ensemble","0a8d3f91":"Above diagram demostrated that with about 5 decision tree, RF had been enough good to fit in our dataset ","6a297122":"## Generate the numeric input for testing ","a69ee231":"### Look into the number of decision tree composed of RF","a16062be":"### Stacking","3ffc1098":"### Date encoding: convert `y-m-d`  to Month.and Day.","3f5cf07d":"Parameter weights corresponding to `'Lat','Long', 'province_encoded' ,'country_encoded','Mon','Day'`","a8332768":"#### Root Mean Square Error\n\n> Submissions are evaluated using the column-wise root mean squared logarithmic error.","e777b907":"### KNN","4fdcc4f2":"- KNN: -6.54\n- Random Forest: -6.90\n- Naive Bayes: -25.89\n- StackingClassifier: -4.76","fec7e027":"### Correlation Visualization","d4f7fe69":"### Bagging: Random Forest","ccd38ef9":"### Extra Dataset","a95b2186":"### Basic Model Comparasion","67f2dbde":"#### Actual Value v.s. Predicted Results","3671c13b":"### Date Encoding: sequential timestamp (poor design)","47f71242":"#### Scatter Data points ","70246098":"### Take a look at Europe","faacd1e4":"### After Model Comparing, here provide an optimal result ","c7aca010":"#### Pearson","e1e3fe30":"#### Weights","be559f35":"### Confirmed cases over time","023dd54b":"### Linear Regression","07641be2":"## Model\n#### Single Model \n1. Linear Regression\n2. SVM Regression\n3. KNN \n\n#### Ensemble \n1. Random Forest\n2. Adaboost \n\n#### SIR Model","422e3820":"Which country has `nan` coordinate ?","4c2d99a1":"#### Set extra attributes to zero","392e96b8":"## Generate the numeric input for training","109fb757":"### Date encoding: enhance by serial fetures (poor design)","e26e36bc":"### Province Encoding\nProvince is a string-type object in the dataset. To take advantage of them, we convert Province to a numeric index as shown below. `province_encoded` collects all states in the training data. Specially, `nan` cells indicate to index `0` avoiding missing data.","fe4de9b5":"## Encoding Categorical Data\n\n1. Province Encoding\n2. Country Encoding\n3. Date Encoding\n4. Extra Dataset\n5. Missing Value Imputation","f9d2edcd":"### take a look at US","3bb3ed42":"#### Kendall","e8287516":"#### Spearman","b3ad8550":"#### PCA to 2-D space","30df5d01":"### Drop Nan cells or repalce them to more suitable values"}}