{"cell_type":{"aa1efce1":"code","62c89565":"code","e5718d50":"code","e1c7cb3d":"code","08deab7b":"code","392d574e":"code","98e01d45":"code","2c10fd58":"code","bb2b55cd":"code","76fbf6e2":"code","ab1813c1":"code","69b62e74":"code","3494ca1b":"code","51339e9f":"code","5ba127f7":"code","3818aca2":"code","8214787d":"code","8e035e25":"code","c66d2257":"code","420fbd29":"code","3d5214c8":"code","91bcbf10":"code","2a68dfcd":"code","225bb171":"code","ea1389a3":"code","e82b6284":"code","369f599d":"code","e1640d91":"markdown","1ab5daf2":"markdown","b35348d7":"markdown","7b8c96c9":"markdown","fafb35ca":"markdown","915bceb3":"markdown","920f52f6":"markdown","339c13fb":"markdown","02bba7a4":"markdown","9fa530d3":"markdown","a5beceb9":"markdown"},"source":{"aa1efce1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler , StandardScaler\nimport seaborn as sns\nsns.set(color_codes = True)\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","62c89565":"df = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head() # Visualize first 5 rows of data","e5718d50":"# visualize statistical data\ndf.describe()","e1c7cb3d":"# finding out data types\ndf.dtypes","08deab7b":"# finding out null values\npd.isna(df).sum()","392d574e":"df.hist(figsize = (10, 10));","98e01d45":"plt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(df.corr(), annot = True)","2c10fd58":"cor['quality'].sort_values(ascending=False)","bb2b55cd":"sns.barplot(x = 'quality', y = 'alcohol', data = df)","76fbf6e2":"print(df.quality.describe())","ab1813c1":"def create_level(x):\n    # function to create levels basis wine quality\n    if x <= 5:\n        x = \"low\"\n    elif x > 5 and x < 7:\n        x = \"medium\"\n    else:\n        x = \"high\"\n    return x","69b62e74":"df['level'] = df['quality'].apply(lambda x: create_level(x))","3494ca1b":"from sklearn.preprocessing import LabelEncoder\nLB = LabelEncoder()\nLB_encoded = LB.fit_transform(df['level'])\nprint((LB.classes_))\nprint(LB_encoded)","51339e9f":"x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:11],LB_encoded,test_size=0.20,\n                                                    random_state=21)\n\nprint('Shape of Training Xs:{}'.format(x_train.shape))\nprint('Shape of Test Xs:{}'.format(x_test.shape))\nprint('Shape of Training y:{}'.format(y_train.shape))\nprint('Shape of Test y:{}'.format(y_test.shape))","5ba127f7":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=5)\nkf","3818aca2":"def get_score(model, x_train, x_test, y_train, y_test):\n    model.fit(x_train, y_train)\n    return model.score(x_test, y_test)","8214787d":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nget_score(LogisticRegression(max_iter=10000),x_train, x_test, y_train, y_test)","8e035e25":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nget_score(DecisionTreeClassifier(),x_train, x_test, y_train, y_test)","c66d2257":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nget_score(RandomForestClassifier(),x_train, x_test, y_train, y_test)","420fbd29":"# Support Vector Machine\nfrom sklearn.svm import SVC\nget_score(SVC(),x_train, x_test, y_train, y_test)","3d5214c8":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(criterion= \"entropy\", max_depth = 50, max_features = 'auto', n_estimators = 500)\nclf.fit(x_train, y_train)\ny_predicted = clf.predict(x_test)\nscore=clf.score(x_test,y_test)","91bcbf10":"print(score)\nprint(y_predicted)","2a68dfcd":"y_predicted_labels = LB.inverse_transform(y_predicted)\ny_predicted_labels[0:10]","225bb171":"true_labels = LB.inverse_transform(y_test)\ntrue_labels[0:10]","ea1389a3":"# Compute confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncnf_matrix = confusion_matrix(true_labels, y_predicted_labels)\nnp.set_printoptions(precision=2)\ncnf_matrix","e82b6284":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","369f599d":"#Without Normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=LB.classes_,\n                      title='Confusion matrix, without normalization')\n# With normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= LB.classes_, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","e1640d91":"## 8. Predict outcome using the Test Data","1ab5daf2":"## 5. Split Data in Training & Testing samples","b35348d7":"## 1. Load Libraries","7b8c96c9":"## 4. Preprocessing of Data","fafb35ca":"We can conclude that alcohol highest correlation with quality","915bceb3":"Random Forest observed highest score amongs other, so we can go through Random Forest Classifier","920f52f6":"## 2. Load Data","339c13fb":"## 7. Build Random Forest model","02bba7a4":"## 9. Confusion Matrix","9fa530d3":"## 3. Visualize Data","a5beceb9":"## 6. Check k-fold cross validation before builting model"}}