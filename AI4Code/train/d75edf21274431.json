{"cell_type":{"d726f9ba":"code","c8226c74":"code","61dea111":"code","d7fd0051":"code","c27a50fa":"code","412e70b8":"code","32f02ca2":"code","440396b1":"code","01dfa0eb":"code","a5f1581c":"code","fabf210d":"code","a635a405":"code","f732b645":"code","5e7f8ab2":"code","f596fc77":"code","ff99ad90":"code","112ef9f4":"code","3038b4fd":"code","4462615f":"code","e8a51264":"code","83dae793":"markdown","cfb978fb":"markdown"},"source":{"d726f9ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8226c74":"#importing libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation, Conv2D, MaxPool2D, Flatten, Dropout\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\n","61dea111":"#loading dataset\ntest = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\ntrain = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")","d7fd0051":"train.head()","c27a50fa":"#converting the dataframe into numpy array\ntrain= train.values\n\n#dividng the data set into features and target and standardising by dividing 255\nx = train[:,1:].reshape(-1,28,28,1)\/255.0 #feature\ny = train[:,0].astype(np.int32) # target","412e70b8":"outfit_names = ['T_shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","32f02ca2":"#data visulisation \n\nplt.figure(figsize=(15, 15))\nfor i in range(36):\n    plt.subplot(6, 6, i + 1)\n    plt.axis(\"off\")\n    plt.imshow(x[i].reshape((28,28)))\n    target = y[i]\n    plt.title(outfit_names[target])\nplt.show()","440396b1":"#converting into caetgorical varaible\nfrom keras.utils import to_categorical\ny = to_categorical(y)","01dfa0eb":"from keras.models import Sequential\nfrom keras.layers import Dense,Activation, Conv2D, MaxPool2D, Flatten","a5f1581c":"from tensorflow.keras.callbacks import EarlyStopping","fabf210d":"#Building a Model\nmodel = Sequential()\n\n#adding layer\nmodel.add(Conv2D(input_shape = (28,28,1), filters = 64, kernel_size = (3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D())\n\n#adding layer\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D())\n\n\n\n#flatting and adding dense layer\nmodel.add(Flatten())\nmodel.add(Dense(units=512))\nmodel.add(Activation (\"relu\"))\nmodel.add(Dropout(.5))\nmodel.add(Dense(units = 10 ))\nmodel.add(Activation (\"softmax\"))\n\n#compling model\nmodel.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n\n\nearly_stop = EarlyStopping(monitor=\"val_loss\", mode = \"min\", verbose=1, patience = 3)","a635a405":"model.fit(x,y, validation_split = 0.3, epochs = 30, batch_size=32,callbacks = [early_stop])","f732b645":"loss = pd.DataFrame(model.history.history)","5e7f8ab2":"loss","f596fc77":"plt.figure(figsize=(10, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(loss['loss'], label='Loss')\nplt.plot(loss['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(loss['accuracy'], label='Accuracy')\nplt.plot(loss['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')","ff99ad90":"#converting the dataframe into numpy array\ntest= test.values\n\n#dividng the data set into features and target and standardising by dividing 255\nx = test[:,1:].reshape(-1,28,28,1)\/255.0 #feature\ny = test[:,0].astype(np.int32) # target\n","112ef9f4":"#making predictions\npredictions = model.predict_classes(x)","3038b4fd":"#classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y, predictions,target_names = outfit_names))","4462615f":"#data visulisation with prediction and actual class label\nplt.figure(figsize=(20, 20))\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.axis(\"off\")\n    plt.imshow(x[i].reshape((28,28)))\n    plt.title(f\"Prediction Class = {predictions[i]} \\n Original_Class= {y[i]}\")\nplt.show()","e8a51264":"#data visulisation with prediction and actual class label\nplt.figure(figsize=(18, 18))\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.axis(\"off\")\n    plt.imshow(x[i].reshape((28,28)))\n    plt.title(f\"Prediction Class = {outfit_names[predictions[i]]} \\n Original_Class= {outfit_names[y[i]]}\")\nplt.show()","83dae793":"# Testing the model on test data","cfb978fb":"## Training model with dropout and early stopping"}}