{"cell_type":{"c111fddc":"code","906cd305":"code","ee528b20":"code","28079ffc":"code","63ff40b7":"code","2ef2cc96":"code","07a15a63":"code","b64c883b":"code","d450d833":"code","dd9172eb":"code","06a005f9":"code","751a3490":"code","20d59d7d":"code","11f53faf":"code","988bf87a":"code","a876bbdf":"code","84c22412":"code","f006aa2f":"code","c9bc4b8c":"code","75050237":"code","ed6e55e7":"code","51c07a49":"code","3e8ab373":"code","8a1a6f1c":"code","30eee152":"code","d8d86884":"code","dc681bbc":"code","d4041d18":"code","53c4bd92":"code","539cf5d6":"code","09018894":"code","7360c732":"code","23c194ba":"code","94fa6079":"markdown","97f22a6f":"markdown","1b121297":"markdown","8d5a6505":"markdown","d1f4e744":"markdown","50a812a8":"markdown","e118aa56":"markdown","4343cd05":"markdown","4640597f":"markdown","47e75a97":"markdown","a310b670":"markdown","f6fde700":"markdown","d8b1e69a":"markdown"},"source":{"c111fddc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","906cd305":"import pandas as pd\nimport numpy as np\n\n\nimport scipy.stats as stats\nfrom sklearn.svm import SVC\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport sklearn.metrics as metrics\nfrom time import time\nfrom sklearn.utils.fixes import loguniform\n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV","ee528b20":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","28079ffc":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","63ff40b7":"target= train_data['Survived']\ntarget.shape","2ef2cc96":"train_data.drop(['Survived'], axis=1, inplace = True)","07a15a63":"train_data.shape","b64c883b":"train1=train_data\ntest1=test_data\n\nprint('Ready to concatinate!')","d450d833":"df = pd.concat([train1, test1], axis=0,sort=False)\ndf.shape","dd9172eb":"df.isnull().sum()","06a005f9":"PassengerId=test_data.PassengerId\nPassengerId.shape","751a3490":"df.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)\n","20d59d7d":"df.shape","11f53faf":"\ndf.fillna(df.median(), inplace=True)","988bf87a":"df.describe(include='all')","a876bbdf":"df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)","84c22412":"df.isnull().sum()","f006aa2f":"df = pd.get_dummies(df, columns=['Pclass', 'Sex', 'SibSp', 'Parch','Embarked'])\n","c9bc4b8c":"df.head()","75050237":"df_train = df.iloc[:891,:]\n\ndf_test = df.iloc[891:,:]\n\nprint(\"Shape of new dataframes - {} , {}\".format(df_train.shape, df_test.shape))","ed6e55e7":"df_train = preprocessing.StandardScaler().fit(df_train).transform(df_train)\ndf_train[0:5]","51c07a49":"x_train,x_test,y_train,y_test = train_test_split(df_train,target,test_size=0.33,random_state=0)","3e8ab373":"\ndef report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n                  .format(results['mean_test_score'][candidate],\n                          results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\n\n","8a1a6f1c":" n_iter_search = 20\n\nparam_grid = {'C': loguniform(1e0, 1e3),  \n              'gamma': loguniform(1e-3, 1e-1), \n              'kernel': ['rbf'],\n             'class_weight':['balanced', None]}\n\nrandom_search = RandomizedSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n\nstart = time()\nrandom_search.fit(x_train, y_train)\n","30eee152":"print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n      \" parameter settings.\" % ((time() - start), n_iter_search))\nreport(random_search.cv_results_)","d8d86884":"print (\"Best Score: {}\".format(random_search.best_score_))\nprint (\"Best params: {}\".format(random_search.best_params_))","dc681bbc":"param_grid = {'C': [1, 10, 100, 1000],  \n              'gamma': [0.001, 0.01,0.1], \n              'kernel': ['rbf'],\n             'class_weight':['balanced', None]}\n\n\ngrid_search = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\nstart = time()\ngrid_search.fit(x_train, y_train)\n\n","d4041d18":"\nprint (\"Best Score: {}\".format(grid_search.best_score_))\nprint (\"Best params: {}\".format(grid_search.best_params_))","53c4bd92":"print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n      % (time() - start, len(grid_search.cv_results_['params'])))\nreport(grid_search.cv_results_)","539cf5d6":"SVC_model = SVC(C=10, gamma= 0.01, kernel= 'rbf')\nSVC_model.fit(x_train, y_train)\n","09018894":"\ndf_test = preprocessing.StandardScaler().fit(df_test).transform(df_test)\ndf_test[0:5]","7360c732":"SVC_model.fit(df_train,target)\nprediction=SVC_model.predict(df_test)","23c194ba":"output = pd.DataFrame({'PassengerId': PassengerId, 'Survived': prediction})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","94fa6079":"**Import the necessary libraries**","97f22a6f":"Function to report best scores","1b121297":"**Load and check the data**","8d5a6505":"A hyperparameter is a parameter whose value is used to control the learning process in contrast to (other) parameters which are learned during training.\n\nA refined regulation of certain hyperparameters can lead to enhanced performance. This process is referred to as Hyperparameter optimization or tuning. This involves choosing a mix of values which gives optimal performance for a particular learning algorithm.\n\nGrid Search has been the common way of peforming this task.\n\nRandom search evaluates a random sample of points on the grid rather than search the entire grid. This makes random search faster than Grid Search; but is it more effective? And what is the trade-off?\n\nIn this exercise, I plan to compare the output and time taken by each of Grid and Random.\n","d1f4e744":"**Train and Test sets**","50a812a8":"****","e118aa56":"**Split Datasets**\n","4343cd05":"**Categorical Features**","4640597f":"<p style=\"font-size:30px\">Hyperparameter Optimization: Grid vs Random using The Titanic dataset as a case-study <\/p>\n   ","47e75a97":"**Missing Data**","a310b670":"**Grid Search with Support Vector Machine**","f6fde700":"**Normalize data**","d8b1e69a":"**Random Search with Support Vector Machine**"}}