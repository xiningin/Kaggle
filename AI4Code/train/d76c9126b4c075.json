{"cell_type":{"ebed09a0":"code","47de1050":"code","45e88b28":"code","0f97f9b8":"code","a0dc5785":"code","df54a782":"code","55b093df":"code","bc196824":"code","fd5c977f":"code","c2cdc300":"code","af7a2777":"code","edddb0b5":"code","e266ad90":"code","1be1fb08":"code","c5de55f7":"code","e8c1b808":"code","62c28ba9":"code","500c3be1":"code","1c422ce9":"code","859d529f":"code","86d42a02":"code","184bd724":"code","14c56e93":"code","57fad812":"code","7890ba77":"code","c1053ae2":"code","5243fe59":"code","5ae073df":"code","84a25b23":"code","5f584e0a":"code","b28b3e21":"code","399dc344":"code","49340448":"code","6022509f":"code","0a985341":"code","3cbbae34":"code","922b5b09":"code","b848bd12":"code","b030c2f2":"code","857056a6":"code","2e62a72b":"code","20ca21e7":"code","70709f56":"code","d94534ba":"code","e1cd699d":"code","6a7af728":"code","d51b85ed":"code","5f62dc3d":"code","ff89c3a8":"code","6ffec6b6":"code","791667b1":"code","d4bbac6e":"code","882a26d0":"code","128acc93":"code","16c53b59":"code","4e36da8f":"code","775eea7a":"code","2fe03c84":"code","fdba9765":"code","bf0c2028":"markdown","a9e1ccb9":"markdown","9de6b397":"markdown","9cb6835f":"markdown","dee894eb":"markdown","f75782d7":"markdown","747129e4":"markdown","bfd6e360":"markdown","a4af620e":"markdown","38172bdc":"markdown","d14ae49e":"markdown","198103af":"markdown","a568d543":"markdown","8a970872":"markdown","0c70671f":"markdown","7a38694e":"markdown","d0491371":"markdown","b97df64b":"markdown","1b165af1":"markdown","aea1dc03":"markdown","072024f2":"markdown","0bdf81fe":"markdown","38d594eb":"markdown","1a08dee6":"markdown","75ed7113":"markdown","6e59d8fb":"markdown","d04483d4":"markdown","155ac97a":"markdown","2a8e98f1":"markdown"},"source":{"ebed09a0":"# packages\r\nimport pandas as pd\r\nimport matplotlib as plt\r\nimport seaborn as sns\r\nimport numpy as np\r\nfrom scipy.stats import kurtosis\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, balanced_accuracy_score\r\nfrom imblearn.over_sampling import RandomOverSampler\r\nfrom imblearn.under_sampling import RandomUnderSampler","47de1050":"# data loading\r\ndf = pd.read_csv(\"..\/input\/indian-liver-patient-records\/indian_liver_patient.csv\")","45e88b28":"df = df.dropna() # simply drop NA\r\ndf_c = df.copy()  # database copy for qualitative data","0f97f9b8":"# For df_c\r\ndf_c[\"Dataset\"] = df[\"Dataset\"].map({1: \"Sick\", 2: \"Healthy\"})\r\n\r\n# For df\r\ndf['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\r\ndf['Dataset'] = df['Dataset'].map({1: 1, 2: 0})\r\ndf.rename(columns={'Gender': 'Male'}, inplace=True)\r\ndf.rename(columns={'Dataset': 'Target'}, inplace=True)","a0dc5785":"df_c.drop(columns=['Age', 'Total_Bilirubin', 'Direct_Bilirubin',\r\n                   'Alkaline_Phosphotase', 'Alamine_Aminotransferase',\r\n                   'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin',\r\n                   'Albumin_and_Globulin_Ratio'], inplace=True)","df54a782":"df.drop(columns=[\"Target\", \"Male\"]).kurtosis()","55b093df":"plt.rcParams['figure.figsize'] = [10, 8]  # for size\r\nsns.boxplot(data=df.Aspartate_Aminotransferase, orient=\"h\").set_title(\"Aspartate_Aminotransferase\")\r\nprint(\"Min value:\", min(df.Aspartate_Aminotransferase))","bc196824":"sns.boxplot(data=df.Alamine_Aminotransferase, orient=\"h\").set_title(\"Alamine_Aminotransferase\")\r\nprint(\"Min value:\", min(df.Alamine_Aminotransferase))","fd5c977f":"def alamine(df):\r\n    if df['Alamine_Aminotransferase'] <= 55: return 0\r\n    else: return 1","c2cdc300":"def aspartate(df):\r\n    if df['Male'] == 1 and df['Aspartate_Aminotransferase'] <= 40: return 0\r\n    elif df['Male'] == 0 and df['Aspartate_Aminotransferase'] <= 32: return 0 \r\n    elif df['Male'] == 0 and df['Aspartate_Aminotransferase'] > 32: return 1\r\n    else: return 1","af7a2777":"df_1 = df.copy()","edddb0b5":"df_1['Alamine_Aminotransferase'] = df_1.apply(alamine, axis=1)\r\ndf_1['Aspartate_Aminotransferase'] = df_1.apply(aspartate, axis=1)","e266ad90":"df_1.head()","1be1fb08":"to_add = df_1.loc[:,['Alamine_Aminotransferase', 'Aspartate_Aminotransferase']]\r\ndf_c = df_c.join(to_add)","c5de55f7":"df_c.head()","e8c1b808":"df_c['Alamine_Aminotransferase'] = df_c['Alamine_Aminotransferase'].map({0: \"Normal\", 1: \"Above_Normal\"})\r\ndf_c['Aspartate_Aminotransferase'] = df_c['Aspartate_Aminotransferase'].map({0: \"Normal\", 1: \"Above_Normal\"})","62c28ba9":"df_c.head()","500c3be1":"sns.countplot(x=\"Alamine_Aminotransferase\", hue=\"Dataset\", data=df_c).set_title(\r\n    \"Liver dieses among Alamine_Aminotransferase level\")","1c422ce9":"sns.countplot(x=\"Aspartate_Aminotransferase\", hue=\"Dataset\", data=df_c).set_title(\r\n    \"Liver dieses among Aspartate_Aminotransferase level\")","859d529f":"df_c.groupby(\"Gender\").Aspartate_Aminotransferase.value_counts()","86d42a02":"df_c.groupby(\"Dataset\").Aspartate_Aminotransferase.value_counts()\r\n","184bd724":"df_c.Alamine_Aminotransferase.value_counts()","14c56e93":"df_c.Aspartate_Aminotransferase.value_counts()","57fad812":"# database for quantitative variables\r\ndf_q = df_1.drop(columns=['Male', 'Target', 'Alamine_Aminotransferase', 'Aspartate_Aminotransferase'])","7890ba77":"sns.boxplot(data=df_q, orient=\"h\").set_title(\"Outliers\")","c1053ae2":"def remove_outliers(df_in):\r\n\r\n    Q1 = df_in.quantile(0.25)\r\n    Q3 = df_in.quantile(0.75)\r\n    IQR = Q3 - Q1\r\n    upper_limit = Q3 + 1.5*IQR\r\n    lower_limit = Q1 - 1.5*IQR\r\n\r\n    df_clean = df_in[~((df_in < lower_limit) | (df_in > upper_limit)).any(axis=1)]\r\n    \r\n    return df_clean","5243fe59":"df_q = remove_outliers(df_q)","5ae073df":"print(\"Number of cases in df:\", len(df))\r\nprint(\"Number of cases in df_q:\", len(df_q))\r\nprint(\"We've removed:\", round(100-(len(df_q)*100\/len(df)),2), \"percent of rows.\")","84a25b23":"sns.heatmap(df_q.corr(), annot=True, cmap='coolwarm',\r\n            mask=np.triu(df_q.corr())).set_title(\"Correlogram\")","5f584e0a":"df_trimmed = df_1[df_1.index.isin(df_q.index)]\r\ndf_trimmed = df_trimmed.drop(columns=['Albumin', 'Total_Bilirubin'])","b28b3e21":"scaler = StandardScaler()\r\ndf_scaled = df_trimmed.copy()\r\n# scaling trimmed data\r\ndf_scaled[['Age', 'Direct_Bilirubin', 'Alkaline_Phosphotase', 'Total_Protiens', 'Albumin_and_Globulin_Ratio']] = scaler.fit_transform(\r\n    df_trimmed[['Age', 'Direct_Bilirubin', 'Alkaline_Phosphotase', 'Total_Protiens', 'Albumin_and_Globulin_Ratio']])","399dc344":"df_scaled_all = df.copy()\r\n# scaling complete data\r\ndf_scaled_all[['Age', 'Total_Bilirubin', 'Direct_Bilirubin', 'Alkaline_Phosphotase', 'Alamine_Aminotransferase', 'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin', 'Albumin_and_Globulin_Ratio']] = scaler.fit_transform(\r\n    df[['Age', 'Total_Bilirubin', 'Direct_Bilirubin', 'Alkaline_Phosphotase', 'Alamine_Aminotransferase', 'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin', 'Albumin_and_Globulin_Ratio']])\r\n","49340448":"# initial database\r\ndf.head() ","6022509f":"# scaled initial database\r\ndf_scaled_all.head()","0a985341":"# trimmed database\r\ndf_trimmed.head()","3cbbae34":"# scaled trimmed database\r\ndf_scaled.head()","922b5b09":"# for df\r\nX_df = df.loc[:, df.columns != 'Target']\r\ny_df = df.loc[:, 'Target']\r\n\r\n# for df_scaled_all\r\nX_df_scaled_all = df_scaled_all.loc[:, df_scaled_all.columns != 'Target']\r\ny_df_scaled_all = df_scaled_all.loc[:, 'Target']\r\n\r\n# for df trimmed\r\nX_df_trimmed = df_trimmed.loc[:, df_trimmed.columns != 'Target']\r\ny_df_trimmed = df_trimmed.loc[:, 'Target']\r\n\r\n# for df trimmed and scaled\r\nX_df_trimmed_scaled = df_scaled.loc[:, df_scaled.columns != 'Target']\r\ny_df_trimmed_scaled = df_scaled.loc[:, 'Target']","b848bd12":"# for df\r\nX_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X_df, y_df, test_size = 0.30, random_state = 0, stratify = y_df)\r\n\r\n# for df_scaled_all\r\nX_train_df_scaled_all, X_test_df_scaled_all, y_train_df_scaled_all, y_test_df_scaled_all = train_test_split(X_df_scaled_all, y_df_scaled_all, test_size = 0.30, random_state = 0, stratify = y_df_scaled_all)\r\n\r\n# for df trimmed\r\nX_train_df_trimmed, X_test_df_trimmed, y_train_df_trimmed, y_test_df_trimmed = train_test_split(X_df_trimmed, y_df_trimmed, test_size = 0.30, random_state = 0, stratify = y_df_trimmed)\r\n\r\n# for df trimmed and scaled\r\nX_train_df_trimmed_scaled, X_test_df_trimmed_scaled, y_train_df_trimmed_scaled, y_test_df_trimmed_scaled = train_test_split(X_df_trimmed_scaled, y_df_trimmed_scaled, test_size = 0.30, random_state = 0, stratify = y_df_trimmed_scaled)","b030c2f2":"model_1 = LogisticRegression(max_iter=1000)\r\nmodel_2 = LogisticRegression(max_iter=1000)\r\nmodel_3 = LogisticRegression(max_iter=1000)\r\nmodel_4 = LogisticRegression(max_iter=1000)","857056a6":"res_1 = model_1.fit(X_train_df, y_train_df)\r\nres_2 = model_2.fit(X_train_df_scaled_all, y_train_df_scaled_all)\r\nres_3 = model_3.fit(X_train_df_trimmed, y_train_df_trimmed)\r\nres_4 = model_4.fit(X_train_df_trimmed_scaled, y_train_df_trimmed_scaled)\r\n\r\ny_predict_1 = model_1.predict(X_test_df)\r\ny_predict_2 = model_2.predict(X_test_df_scaled_all)\r\ny_predict_3 = model_3.predict(X_test_df_trimmed)\r\ny_predict_4 = model_4.predict(X_test_df_trimmed_scaled)\r\n","2e62a72b":"def score_function(y_pred, y_test):\r\n\r\n    Acc = accuracy_score(y_test, y_pred)\r\n    Pre = precision_score(y_test, y_pred)\r\n    Rec = recall_score(y_test, y_pred)\r\n    Bal = balanced_accuracy_score(y_test, y_pred)\r\n\r\n    data = pd.DataFrame()\r\n    names = [\"Accuracy\", \"Precision\", \"Recall\", \"Balanced accuracy\"]\r\n    values = [Acc, Pre, Rec, Bal]\r\n    data[\"Names\"] = names\r\n    data['Scores'] = values\r\n\r\n    return data","20ca21e7":"scores_1 = score_function(y_predict_1, y_test_df)\r\nscores_2 = score_function(y_predict_2, y_test_df_scaled_all)\r\nscores_3 = score_function(y_predict_3, y_test_df_trimmed)\r\nscores_4 = score_function(y_predict_4, y_test_df_trimmed_scaled)","70709f56":"names = [\"Accuracy\", \"Precision\", \"Recall\", \"Balanced accuracy\"]\r\n\r\nresults = pd.DataFrame({\"Names\": names, \"df\": scores_1['Scores'], \"df_scaled_all\":scores_2['Scores'],\r\n                        \"df_trimmed\": scores_3['Scores'], \"df_trimmed_scaled\": scores_4['Scores']})\r\n","d94534ba":"results.set_index(\"Names\")","e1cd699d":"df.Target.value_counts().plot.pie(autopct='%.2f')","6a7af728":"df_trimmed.Target.value_counts().plot.pie(autopct='%.2f')","d51b85ed":"print(\"df class 0:\", len(df.Target)-df.Target.sum())\r\nprint(\"df_trimmed class 0:\", len(df_trimmed.Target)-df_trimmed.Target.sum())\r\n","5f62dc3d":"rus_1 = RandomUnderSampler(sampling_strategy=1)\r\nrus_2 = RandomUnderSampler(sampling_strategy=1)\r\nrus_3 = RandomUnderSampler(sampling_strategy=1)\r\nrus_4 = RandomUnderSampler(sampling_strategy=1)\r\n\r\nX_rus_df, y_rus_df = rus_1.fit_resample(X_df, y_df)\r\nX_rus_df_scaled_all, y_rus_df_scaled_all = rus_2.fit_resample(X_df_scaled_all, y_df_scaled_all)\r\nX_rus_df_trimmed, y_rus_df_trimmed = rus_3.fit_resample(X_df_trimmed, y_df_trimmed)\r\nX_rus_df_trimmed_scaled, y_rus_df_trimmed_scaled = rus_4.fit_resample(X_df_trimmed_scaled, y_df_trimmed_scaled)\r\n\r\n# for df\r\nX_train_df_rus, X_test_df_rus, y_train_df_rus, y_test_df_rus = train_test_split(\r\n    X_rus_df, y_rus_df, test_size=0.30, random_state=0, stratify=y_rus_df)\r\n\r\n# for df_scaled_all\r\nX_train_df_scaled_all_rus, X_test_df_scaled_all_rus, y_train_df_scaled_all_rus, y_test_df_scaled_all_rus = train_test_split(\r\n    X_rus_df_scaled_all, y_rus_df_scaled_all, test_size=0.30, random_state=0, stratify=y_rus_df_scaled_all)\r\n\r\n# for df trimmed\r\nX_train_df_trimmed_rus, X_test_df_trimmed_rus, y_train_df_trimmed_rus, y_test_df_trimmed_rus = train_test_split(\r\n    X_rus_df_trimmed, y_rus_df_trimmed, test_size=0.30, random_state=0, stratify=y_rus_df_trimmed)\r\n\r\n# for df trimmed and scaled\r\nX_train_df_trimmed_scaled_rus, X_test_df_trimmed_scaled_rus, y_train_df_trimmed_scaled_rus, y_test_df_trimmed_scaled_rus = train_test_split(\r\n    X_rus_df_trimmed_scaled, y_rus_df_trimmed_scaled, test_size=0.30, random_state=0, stratify=y_rus_df_trimmed_scaled)\r\n","ff89c3a8":"ros_1 = RandomOverSampler(sampling_strategy=1)\r\nros_2 = RandomOverSampler(sampling_strategy=1)\r\nros_3 = RandomOverSampler(sampling_strategy=1)\r\nros_4 = RandomOverSampler(sampling_strategy=1)\r\n\r\nX_ros_df, y_ros_df = ros_1.fit_resample(X_df, y_df)\r\nX_ros_df_scaled_all, y_ros_df_scaled_all = ros_2.fit_resample(X_df_scaled_all, y_df_scaled_all)\r\nX_ros_df_trimmed, y_ros_df_trimmed = ros_3.fit_resample(X_df_trimmed, y_df_trimmed)\r\nX_ros_df_trimmed_scaled, y_ros_df_trimmed_scaled = ros_4.fit_resample(X_df_trimmed_scaled, y_df_trimmed_scaled)\r\n\r\n# for df\r\nX_train_df_ros, X_test_df_ros, y_train_df_ros, y_test_df_ros = train_test_split(\r\n    X_ros_df, y_ros_df, test_size=0.30, random_state=0, stratify=y_ros_df)\r\n\r\n# for df_scaled_all\r\nX_train_df_scaled_all_ros, X_test_df_scaled_all_ros, y_train_df_scaled_all_ros, y_test_df_scaled_all_ros = train_test_split(\r\n    X_ros_df_scaled_all, y_ros_df_scaled_all, test_size=0.30, random_state=0, stratify=y_ros_df_scaled_all)\r\n\r\n# for df trimmed\r\nX_train_df_trimmed_ros, X_test_df_trimmed_ros, y_train_df_trimmed_ros, y_test_df_trimmed_ros = train_test_split(\r\n    X_ros_df_trimmed, y_ros_df_trimmed, test_size=0.30, random_state=0, stratify=y_ros_df_trimmed)\r\n\r\n# for df trimmed and scaled\r\nX_train_df_trimmed_scaled_ros, X_test_df_trimmed_scaled_ros, y_train_df_trimmed_scaled_ros, y_test_df_trimmed_scaled_ros = train_test_split(\r\n    X_ros_df_trimmed_scaled, y_ros_df_trimmed_scaled, test_size=0.30, random_state=0, stratify=y_ros_df_trimmed_scaled)\r\n","6ffec6b6":"model_1_rus = LogisticRegression(max_iter=1000)\r\nmodel_2_rus = LogisticRegression(max_iter=1000)\r\nmodel_3_rus = LogisticRegression(max_iter=1000)\r\nmodel_4_rus = LogisticRegression(max_iter=1000)","791667b1":"res_1_rus = model_1_rus.fit(X_train_df_rus, y_train_df_rus)\r\nres_2_rus = model_2_rus.fit(X_train_df_scaled_all_rus, y_train_df_scaled_all_rus)\r\nres_3_rus = model_3_rus.fit(X_train_df_trimmed_rus, y_train_df_trimmed_rus)\r\nres_4_rus = model_4_rus.fit(X_train_df_trimmed_scaled_rus, y_train_df_trimmed_scaled_rus)\r\n\r\ny_predict_1_rus = model_1_rus.predict(X_test_df_rus)\r\ny_predict_2_rus = model_2_rus.predict(X_test_df_scaled_all_rus)\r\ny_predict_3_rus = model_3_rus.predict(X_test_df_trimmed_rus)\r\ny_predict_4_rus = model_4_rus.predict(X_test_df_trimmed_scaled_rus)","d4bbac6e":"scores_1_rus = score_function(y_predict_1_rus, y_test_df_rus)\r\nscores_2_rus = score_function(y_predict_2_rus, y_test_df_scaled_all_rus)\r\nscores_3_rus = score_function(y_predict_3_rus, y_test_df_trimmed_rus)\r\nscores_4_rus = score_function(y_predict_4_rus, y_test_df_trimmed_scaled_rus)","882a26d0":"names = [\"Accuracy\", \"Precision\", \"Recall\", \"Balanced accuracy\"]\r\n\r\nresults_rus = pd.DataFrame({\"Names\": names, \"df_rus\": scores_1_rus['Scores'], \"df_scaled_all_rus\": scores_2_rus['Scores'],\r\n                          \"df_trimmed_rus\": scores_3_rus['Scores'], \"df_trimmed_scaled_rus\": scores_4_rus['Scores']})","128acc93":"results_rus.set_index(\"Names\")","16c53b59":"model_1_ros = LogisticRegression(max_iter=1000)\r\nmodel_2_ros = LogisticRegression(max_iter=1000)\r\nmodel_3_ros = LogisticRegression(max_iter=1000)\r\nmodel_4_ros = LogisticRegression(max_iter=1000)","4e36da8f":"res_1_ros = model_1_ros.fit(X_train_df_ros, y_train_df_ros)\r\nres_2_ros = model_2_ros.fit(X_train_df_scaled_all_ros, y_train_df_scaled_all_ros)\r\nres_3_ros = model_3_ros.fit(X_train_df_trimmed_ros, y_train_df_trimmed_ros)\r\nres_4_ros = model_4_ros.fit(X_train_df_trimmed_scaled_ros, y_train_df_trimmed_scaled_ros)\r\n\r\ny_predict_1_ros = model_1_ros.predict(X_test_df_ros)\r\ny_predict_2_ros = model_2_ros.predict(X_test_df_scaled_all_ros)\r\ny_predict_3_ros = model_3_ros.predict(X_test_df_trimmed_ros)\r\ny_predict_4_ros = model_4_ros.predict(X_test_df_trimmed_scaled_ros)","775eea7a":"scores_1_ros = score_function(y_predict_1_ros, y_test_df_ros)\r\nscores_2_ros = score_function(y_predict_2_ros, y_test_df_scaled_all_ros)\r\nscores_3_ros = score_function(y_predict_3_ros, y_test_df_trimmed_ros)\r\nscores_4_ros = score_function(y_predict_4_ros, y_test_df_trimmed_scaled_ros)","2fe03c84":"names = [\"Accuracy\", \"Precision\", \"Recall\", \"Balanced accuracy\"]\r\n\r\nresults_ros = pd.DataFrame({\"Names\": names, \"df_ros\": scores_1_ros['Scores'], \"df_scaled_all_ros\": scores_2_ros['Scores'],\r\n                            \"df_trimmed_ros\": scores_3_ros['Scores'], \"df_trimmed_scaled_ros\": scores_4_ros['Scores']})","fdba9765":"results_ros.set_index(\"Names\")","bf0c2028":"### For Random Oversampling","a9e1ccb9":"# Final Words\r\n\r\nIf anyone has suggestions on how to do something in the loops or improve it - feel free to write.","9de6b397":"# Standardization of quantitative variables\r\n\r\n$ z = \\frac{x-u}{s}$\r\n\r\nwhere: x - *sample*, u - *mean*, s - *std* \r\n\r\nStandardization is the process of putting different variables on the same scale; allows you to compare scores between different types of variables.","9cb6835f":"The very high value of kurtosis has two variables therefore, having medical information about normal ranges of their values in blood, we will convert them into qualitative variables.","dee894eb":"## Splitting data to X & y","f75782d7":"This is a continuation of my previous notebook about liver patients, so I will not repeat certain elements of the usual data overview here.\r\n\r\n# Contents \ud83d\udc31\u200d\ud83d\udc64\r\n\r\n1. Initial data manipulation\r\n   1. Loading data\r\n   2. Drop NA\r\n   3. Renaming values and columns\r\n2. Converting a quantitative variable to a qualitative variable\r\n   1. Kurtosis\r\n   2. Boxplots\r\n   3. Converting Aspartate and Alamine \r\n   4. Renaming values\r\n3. A look at new qualitative variables\r\n4. Outliers\r\n5. Pearson's correlation\r\n6. Standardization of quantitative variables\r\n7. Testing databases\r\n8. Logistic regression\r\n9. Performance comparison\r\n10. Conclusions\r\n11. Appendix I: balancing classes\r\n    1.  Random Undersampling\r\n    2.  Random Oversampling\r\n    3.  Logistic regression for undersampling and oversampling\r\n    4.  Conclusions II","747129e4":"### For Random Undersampling","bfd6e360":"The Alkaline variable has quite a few outliers (not as many as the two we converted to qualitative variables) so we will perform the outlier removal procedure once.","a4af620e":"## Logistic regression for undersampling and oversampling ","38172bdc":"## Model","d14ae49e":"# A look at new qualitative variables","198103af":"I don't want to make changes to the main database, so I will make copy.","a568d543":"# Initial data manipulation is discussed more fully in this [notebook](https:\/\/www.kaggle.com\/mogrim\/logistic-regression-with-all-outliers-removed).","8a970872":"# Appendix 1: balancing classes\r\n\r\nStrongly unbalanced classes can affect the performance quality of classification algorithms so we will use two solution methods. <br \/>\r\nYou can read about both of them and many more [here](https:\/\/imbalanced-learn.org\/stable\/index.html).","0c70671f":"## Conclusions II\r\n\r\nFor Random Undersampling:\r\n+ Standardizing the variables for the original database (df) has positive effects.\r\n+ Standardizing the variables for the trimmed database (df_trimmed) has negative effects.\r\n+ I do not find the effect of using Undersampling to be satisfying.\r\n\r\nFor Random Oversampling:\r\n+ Standardization of variables in both cases has positive effects.\r\n+ The df has higher Accuracy, Precision and Bananced accuracy values, but lower Recall from the trimmed dataset.\r\n\r\nIn this case, Oversampling is better than Undersampling.<br \/>\r\nStatistical treatments seem to have little effect on the final performance of the logistic regression classifier.","7a38694e":"# Performance comparison","d0491371":"## Random Oversampling","b97df64b":"# Outliers\r\n\r\nAs I mentioned in a previous notebook on this issue, **we cannot perform mathematical operations such as counting the mean or quartile on qualitative variables**. Therefore, they must be excluded.","1b165af1":"## Converting Aspartate and Alamine to qualitative varibles\r\n\r\n+ **Alamine Aminotransferase**: test result can range from 7 to 55 units per liter. \r\n+ **Aspartate_Aminotransferase**: normal ranges are: 10-40 units\/L (males), 9-32 units\/L (females). \r\n\r\nIn both cases, the minimum value of the variable is 10, so neither case is sub-normal. Hence the replacement will be to assign a value to the person:1: above normal, 0: in normal, depending on the reference values given in the medical literature. ","aea1dc03":"# Testing databases\r\n\r\nI will use four databases to perform a logistic regression model to predict whether a patient has a diseased liver or not.","072024f2":"# Pearson's correlation","0bdf81fe":"# Logistic regression","38d594eb":"Two variables correlate very strongly, so I will remove them. ","1a08dee6":"## Random Undersampling","75ed7113":"# Converting a quantitative variable to a qualitative variable","6e59d8fb":"# Conclusions\r\n\r\n## Confusion matrix\r\n<img src=\"https:\/\/i.imgur.com\/Xdtufpb.jpg\" width=\"500\">\r\n\r\n\r\n$\\operatorname{accuracy} = \\frac{t_p+t_n}{t_p+t_n+f_p+f_n}$\r\n\r\n$\\operatorname{precision} = \\frac{t_p}{t_p + f_p}$\r\n\r\n$\\operatorname{recall} = \\frac{t_p}{t_p + f_n}$\r\n\r\n$\\operatorname{balanced-accuracy} = \\frac{1}{2}\\left(\\frac{t_p}{t_p + f_n}+\\frac{t_n}{t_n+f_p}\\right)$\r\n\r\n## Summary\r\n+ Standardization of the variables has barely any effect on the results.\r\n+ For the trimmed dataset, there is a slight decrease in accuracy (about 2%), a slightly larger decrease in precision (about 8%).\r\n+ For the trimmed dataset, there is an increase in recall of approximately 6%.\r\n+ Almost zero change in balanced accuracy.","d04483d4":"**Kurtosis** is a measure of outliers. The higher its value, the more likely there are outliers in the database. ","155ac97a":"With this procedure we removed about 25% of the database which is a very good result compared to the previous 80%.","2a8e98f1":"For better readability of the quality variables, I will put them in a separate database and convert 1-0 to above normal and normal."}}