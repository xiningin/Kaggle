{"cell_type":{"bb245c05":"code","490aea29":"code","3abe3753":"code","4d0272cb":"code","baef9948":"code","b94b9892":"code","4ee39cc8":"code","7cc5b08e":"code","534ad647":"code","dcfd369d":"code","83be9db8":"code","51bd68e0":"code","aa9bdec0":"code","94a65fa4":"code","ae93d59e":"code","a2c7d592":"code","54eaf9c2":"code","56586797":"code","b1006852":"code","1622227c":"code","7bb6401c":"code","f5aea7e4":"code","c191e37f":"code","5e34631f":"code","96c2e879":"code","08635b20":"code","7135268d":"code","f1067326":"code","20023608":"code","97abf29c":"code","a0ab5b67":"code","fa9be6e1":"code","fc529d2f":"code","fe8d3517":"code","aa24eb00":"code","58aec7c5":"code","c0d13e59":"code","804aedf4":"code","c4100e42":"code","7a343ac1":"code","a46da057":"code","702fa0e5":"code","3d4205e3":"code","4cc86ad3":"code","2efd514f":"code","d064d813":"code","c18a9916":"code","636815d4":"code","fb75a4f0":"code","de949dda":"code","ea1fdd60":"code","95d1810b":"code","b6b199bf":"code","bf57ec84":"code","d3152607":"code","78c8d625":"code","45a1d637":"code","86c3bf44":"code","bb4150f9":"code","a89a596c":"code","ed84c460":"code","17d1fb40":"code","3b1db7bb":"code","106a135f":"code","607b7844":"code","6a35d8cc":"code","33a43c5d":"code","02f01309":"code","e05e2932":"code","e2d13069":"code","c1f4163e":"code","85b57a64":"code","42547cc9":"code","a8a33eb9":"code","4da62565":"code","548134f2":"code","3a5e3389":"code","8698e8c7":"code","c3192aad":"code","111b2fe6":"code","4702c3bf":"code","2e61904c":"code","e834654d":"code","47b521da":"code","2adea525":"code","9240c344":"code","118a0e85":"code","0b7e6627":"code","3f7fb453":"markdown","34df86bc":"markdown","a78d8ec2":"markdown","47424540":"markdown","17cbcc7d":"markdown","e67200dd":"markdown","fb7b89d1":"markdown","6fd4a8d8":"markdown","ba18b65a":"markdown","c1e7967c":"markdown","40b0ec35":"markdown","ea3814a8":"markdown","78c17e0a":"markdown","086fd2a5":"markdown","1e4fe824":"markdown","fddc0202":"markdown","8b68235a":"markdown","b4b7c8c0":"markdown","aa0396a3":"markdown","a831cdef":"markdown","0aeb2784":"markdown","a0e4616c":"markdown","d08df196":"markdown","74549c05":"markdown","c663c985":"markdown","02bf6200":"markdown","1f3d84af":"markdown","e0fb3f24":"markdown","f4157b0d":"markdown","6d65e23a":"markdown","e75d4cc6":"markdown","dfe37c51":"markdown","66bd92b2":"markdown","eb689969":"markdown","84914c50":"markdown","aae74afd":"markdown","7f14fc65":"markdown","f6c32a2a":"markdown","df31f6ea":"markdown","55c163e5":"markdown","ebfbd03e":"markdown","c302ae32":"markdown","4b42fc08":"markdown","ae7ff392":"markdown","c861806b":"markdown","3ace4dbe":"markdown","c746f2ff":"markdown","44bd2754":"markdown","f2f01f1a":"markdown","fbc475a3":"markdown","103a78f1":"markdown","bb460b74":"markdown","a6d18869":"markdown","b07e7da0":"markdown","c3bfd3ec":"markdown","2af765be":"markdown","061ec1be":"markdown","2d7ab379":"markdown","ee5cce35":"markdown","7a4fc9f0":"markdown","b1adc34e":"markdown","6407750f":"markdown","28427a69":"markdown","567a1135":"markdown","9f27da01":"markdown","f4609d6e":"markdown","e2c1cd42":"markdown","8aab0251":"markdown","6345418d":"markdown","84ce9e8e":"markdown","2fd16c38":"markdown","93dd5020":"markdown","905a7cce":"markdown","d30157c1":"markdown","6515c86c":"markdown","754f3c93":"markdown","6fca1850":"markdown","5f043533":"markdown","70fc972a":"markdown","7e4d8da3":"markdown","91a0af8a":"markdown","85427367":"markdown","ebbac766":"markdown","b87476d0":"markdown","5f93575d":"markdown"},"source":{"bb245c05":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","490aea29":"%matplotlib inline    \n# To make data visualisations display in Jupyter Notebooks \n\nimport numpy as np    # linear algebra \nimport pandas as pd    # Data processing, Input & Output load    \nimport matplotlib.pyplot as plt    # Visualization & plotting\nimport datetime\n\nimport xgboost as xgb\nfrom sklearn.ensemble import GradientBoostingClassifier    # GBM algorithm\nfrom sklearn.ensemble import RandomForestClassifier    # Random Forest Algorithm\nfrom sklearn.linear_model import LogisticRegression    # Logistic Regression Algorithm\n\nfrom xgboost.sklearn import XGBClassifier    # Extreme Gradient Boosting\nfrom xgboost import plot_importance    # Plotting Important Variables\n\nimport joblib  #Joblib is a set of tools to provide lightweight pipelining in Python (Avoid computing twice the same thing)\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n                                    # GridSearchCV - Implements a \u201cfit\u201d and a \u201cscore\u201d method\n                                    # train_test_split - Split arrays or matrices into random train and test subsets\n                                    # cross_val_score - Evaluate a score by cross-validation     \n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import f1_score, precision_score, accuracy_score, roc_auc_score, recall_score, roc_curve\nfrom sklearn.metrics import make_scorer, confusion_matrix, classification_report   # Differnt metrics to evaluate the model\nimport pandas_profiling as pp    # simple and fast exploratory data analysis of a Pandas Dataframe\n\nimport warnings    # To avoid warning messages in the code run\nwarnings.filterwarnings('ignore')","3abe3753":"def plot_roc_auc_curve(y_train_actual, train_pred_prob, y_test_actual, test_pred_prob, *args):\n    '''\n    Generate train and test roc curve\n    '''\n      \n    AUC_Train = roc_auc_score(y_train_actual, train_pred_prob)\n    AUC_Test = roc_auc_score(y_test_actual, test_pred_prob)\n    \n    if len(args) == 0:\n        print(\"Train AUC = \", AUC_Train)\n        print(\"Test AUC = \", AUC_Test)\n        fpr_train, tpr_train, thresholds = roc_curve(y_train_actual, train_pred_prob)\n        fpr_test, tpr_test, thresholds = roc_curve(y_test_actual, test_pred_prob)\n        roc_plot(fpr_train, tpr_train, fpr_test, tpr_test)\n        \n    else:\n        AUC_Valid = roc_auc_score(args[0], args[1])\n        print(\"Train AUC = \", AUC_Train)\n        print(\"Test AUC = \", AUC_Test)\n        print(\"Validation AUC = \", AUC_Valid)\n        fpr_train, tpr_train, thresholds = roc_curve(y_train_actual, train_pred_prob)\n        fpr_test, tpr_test, thresholds = roc_curve(y_test_actual, test_pred_prob)\n        fpr_val, tpr_val, thresholds = roc_curve(args[0], args[1])\n        roc_plot(fpr_train, tpr_train, fpr_test, tpr_test, fpr_val, tpr_val)        ","4d0272cb":"def roc_plot(fpr_train, tpr_train, fpr_test, tpr_test, *args):\n    '''\n    Generate roc plot\n    '''\n    \n    fig = plt.plot(fpr_train, tpr_train, label = 'Train')\n    fig = plt.plot(fpr_test, tpr_test, label = 'Test')\n    \n    if len(args) == 0:\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.0])\n        plt.title(\"ROC curve using \")\n        plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n        plt.ylabel(\"True Positive Rate (Sensitivity)\")\n        plt.legend(loc = 'lower right')\n        plt.grid(True)\n        plt.show()\n    \n    else:\n        fig = plt.plot(args[0], args[1], label = 'Validation')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.0])\n        plt.title(\"ROC curve using \")\n        plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n        plt.ylabel(\"True Positive Rate (Sensitivity)\")\n        plt.legend(loc = 'lower right')\n        plt.grid(True)\n        plt.show()","baef9948":"data = pd.read_csv('..\/input\/diabetes-uci-dataset\/diabetes.csv')\n\n# Copying the original data into a new python variable data object data_new\ndata_new = data.copy()\n\nprint(\"Data Shape - \", data_new.shape)\n\ndata_new.head()","b94b9892":"data_new.describe()","4ee39cc8":"data_new.describe(include = np.object).transpose()","7cc5b08e":"data_new.info()","534ad647":"pp.ProfileReport(data_new)","dcfd369d":"data_new['class'].loc[data_new['class'].isin(['Negative'])] = 0\ndata_new['class'].loc[data_new['class'].isin(['Positive'])] = 1","83be9db8":"data_new['class'] = data_new['class'].astype(int)","51bd68e0":"Target = 'class'\npd.crosstab(data_new[Target], columns = 'Normalized', normalize = True)","aa9bdec0":"data_new.isnull().sum()","94a65fa4":"pp.ProfileReport(data_new)","ae93d59e":"print('Unique values gender count: ', data_new['Gender'].nunique()) \nprint('Gender values: ', data_new['Gender'].unique())\npd.value_counts(data_new['Gender'])","a2c7d592":"print(\"Unique values Polyuria count: \", data_new['Polyuria'].nunique())\nprint(\"Polyuria values: \", data_new['Polyuria'].unique())\npd.value_counts(data_new['Polyuria'])","54eaf9c2":"print(\"Unique values Polydipsia count: \", data_new['Polydipsia'].nunique())\nprint(\"Polydipsia values: \", data_new['Polydipsia'].unique())\npd.value_counts(data_new['Polydipsia'])","56586797":"print(\"Unique values sudden weight loss count: \", data_new['sudden weight loss'].nunique())\nprint(\"sudden weight loss values: \", data_new['sudden weight loss'].unique())\npd.value_counts(data_new['sudden weight loss'])","b1006852":"print(\"Unique values weakness count: \", data_new['weakness'].nunique())\nprint(\"weakness values: \", data_new['weakness'].unique())\npd.value_counts(data_new['weakness'])","1622227c":"print(\"Unique values Polyphagia count: \", data_new['Polyphagia'].nunique())\nprint(\"Polyphagia values: \", data_new['Polyphagia'].unique())\npd.value_counts(data_new['Polyphagia'])","7bb6401c":"print(\"Unique values Genital thrush count: \", data_new['Genital thrush'].nunique())\nprint(\"Genital thrush values: \", data_new['Genital thrush'].unique())\npd.value_counts(data_new['Genital thrush'])","f5aea7e4":"print(\"Unique values visual blurring count: \", data_new['visual blurring'].nunique())\nprint(\"visual blurring values: \", data_new['visual blurring'].unique())\npd.value_counts(data_new['visual blurring'])","c191e37f":"print(\"Unique values Itching count: \", data_new['Itching'].nunique())\nprint(\"Itching values: \", data_new['Itching'].unique())\npd.value_counts(data_new['Itching'])","5e34631f":"print(\"Unique values Irritability count: \", data_new['Irritability'].nunique())\nprint(\"Irritability values: \", data_new['Irritability'].unique())\npd.value_counts(data_new['Irritability'])","96c2e879":"print(\"Unique values delayed healing count: \", data_new['delayed healing'].nunique())\nprint(\"delayed healing values: \", data_new['delayed healing'].unique())\npd.value_counts(data_new['delayed healing'])","08635b20":"print(\"Unique values partial paresis count: \", data_new['partial paresis'].nunique())\nprint(\"partial paresis values: \", data_new['partial paresis'].unique())\npd.value_counts(data_new['partial paresis'])","7135268d":"print(\"Unique values muscle stiffness count: \", data_new['muscle stiffness'].nunique())\nprint(\"muscle stiffness values: \", data_new['muscle stiffness'].unique())\npd.value_counts(data_new['muscle stiffness'])","f1067326":"print(\"Unique values Alopecia count: \", data_new['Alopecia'].nunique())\nprint(\"Alopecia values: \", data_new['Alopecia'].unique())\npd.value_counts(data_new['Alopecia'])","20023608":"print(\"Unique values Obesity count: \", data_new['Obesity'].nunique())\nprint(\"Obesity values: \", data_new['Obesity'].unique())\npd.value_counts(data_new['Obesity'])","97abf29c":"print(\"Unique values class count: \", data_new['class'].nunique())\nprint(\"class values: \", data_new['class'].unique())\npd.value_counts(data_new['class'])","a0ab5b67":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Gender']), \n        labels = ['Male','Female'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of Gender', fontsize = 18, fontweight = 'bold')\nplt.show()","fa9be6e1":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Polyuria']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Polyuria', fontsize = 18, fontweight = 'bold')\nplt.show()","fc529d2f":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Polydipsia']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Polydipsia', fontsize = 18, fontweight = 'bold')\nplt.show()","fe8d3517":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['sudden weight loss']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Sudden Weight Loss', fontsize = 18, fontweight = 'bold')\nplt.show()","aa24eb00":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['weakness']), \n        labels = ['Yes', 'No'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Weakness', fontsize = 18, fontweight = 'bold')\nplt.show()","58aec7c5":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Polyphagia']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Polyphagia', fontsize = 18, fontweight = 'bold')\nplt.show()","c0d13e59":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Genital thrush']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Genital thrush', fontsize = 18, fontweight = 'bold')\nplt.show()","804aedf4":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['visual blurring']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Visual Blurring', fontsize = 18, fontweight = 'bold')\nplt.show()","c4100e42":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Itching']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Itching', fontsize = 18, fontweight = 'bold')\nplt.show()","7a343ac1":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Irritability']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Irritability', fontsize = 18, fontweight = 'bold')\nplt.show()","a46da057":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['delayed healing']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Delayed Healing', fontsize = 18, fontweight = 'bold')\nplt.show()","702fa0e5":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['partial paresis']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Partial Paresis', fontsize = 18, fontweight = 'bold')\nplt.show()","3d4205e3":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['muscle stiffness']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Muscle Stiffness', fontsize = 18, fontweight = 'bold')\nplt.show()","4cc86ad3":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Alopecia']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Alopecia', fontsize = 18, fontweight = 'bold')\nplt.show()","2efd514f":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Obesity']), \n        labels = ['No', 'Yes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Obesity', fontsize = 18, fontweight = 'bold')\nplt.show()","d064d813":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['class']), \n        labels = [1,0],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage Of Class', fontsize = 18, fontweight = 'bold')\nplt.show()","c18a9916":"num_cols = data_new.select_dtypes(include = [np.number]).columns.tolist()\nobj_cols = data_new.select_dtypes(exclude = [np.number]).columns.tolist()","636815d4":"num_cols = data_new.drop(['class'], axis = 1).select_dtypes(include = [np.number]).columns.tolist()","fb75a4f0":"print('Numeric Columns \\n', num_cols)\nprint('Non-Numeric Columns \\n', obj_cols)","de949dda":"# We shall exclude the columns 'hypertension', 'heart_disease'\n\nnum_cols_viz = ['Age']\n\nfig, axes = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (15, 15))\ndata_new.loc[:, [Target]+num_cols_viz].boxplot(by = Target, ax = axes, return_type = 'axes');","ea1fdd60":"obj_cols_viz = obj_cols\nfig, axes = plt.subplots(len(obj_cols_viz), sharex = False, sharey = False, figsize = (15, 50))\n\nfor i in range(0, len(obj_cols_viz)):\n    pd.crosstab(data_new[obj_cols_viz[i]], data_new[Target]).plot(kind = 'bar', stacked = True, grid = False, ax = axes[i])","95d1810b":"encoding_list = ['Gender', 'Polyuria', 'Polydipsia', 'sudden weight loss', 'weakness', 'Polyphagia', 'Genital thrush',\n                 'visual blurring', 'Itching', 'Irritability', 'delayed healing', 'partial paresis', 'muscle stiffness',\n                 'Alopecia', 'Obesity']\n\nlabel_encoding_list = []\none_hot_encoding_list = []\n\nfor i in range (0, len(encoding_list)):\n    if(len(data_new[f'{encoding_list[i]}'].unique()) == 2):\n        label_encoding_list.append(encoding_list[i])\n    else:\n        one_hot_encoding_list.append(encoding_list[i])\n        \n    print(f'Unique Values for {encoding_list[i]}', data_new[f'{encoding_list[i]}'].unique())","b6b199bf":"# Numerical columns data\ndata_new_num = data_new[num_cols + ['class']]\n\n# Categorical columns data\ndata_new_cat = data_new[obj_cols]\n\n# Creating dummies\ndata_new_cat_dummies = pd.get_dummies(data_new_cat)\nprint(data_new_cat_dummies.shape)\ndata_new_cat_dummies.head()","bf57ec84":"data_new_final = pd.concat([data_new_num, data_new_cat_dummies], axis = 1)\nprint(data_new_final.shape)\ndata_new_final.head()","d3152607":"data_new_final.isnull().sum(axis = 0)","78c8d625":"X = data_new_final.drop(['class'], axis = 1)\ny = data_new_final['class']","45a1d637":"X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.3, random_state = 100) \n\nprint('Train Shape: ', X_train.shape)\nprint('Test Shape: ', X_test.shape)","86c3bf44":"model_parameters = {'n_estimators': [10, 50, 100, 200, 500, 750, 1000], 'max_depth': [3, 5, 10],\n                    'min_samples_leaf': [np.random.randint(1,10)], 'max_features': [None, 'sqrt', 'log2']}","bb4150f9":"model = GradientBoostingClassifier(random_state = 10)\ngscv_GBM = GridSearchCV(estimator = model, \n                        param_grid = model_parameters, \n                        cv = 5, \n                        verbose = 1, \n                        n_jobs = -1,\n                        scoring = 'roc_auc')\n\ngscv_GBM.fit(X_train, y_train)","a89a596c":"print('The best parameters are -', gscv_GBM.best_params_)","ed84c460":"final_mod_GBM = GradientBoostingClassifier(**gscv_GBM.best_params_)\nfinal_mod_GBM.fit(X_train, y_train)","17d1fb40":"train_pred = final_mod_GBM.predict(X_train)\ntest_pred = final_mod_GBM.predict(X_test)","3b1db7bb":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","106a135f":"final_mod_GBM.variables = X_train.columns","607b7844":"joblib.dump(final_mod_GBM, 'best_model_GBM.joblib')","6a35d8cc":"plt.subplots(figsize = (10, 5))\ntrain_prob = final_mod_GBM.predict_proba(X_train)[:, 1]\ntest_prob = final_mod_GBM.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","33a43c5d":"y_pred = final_mod_GBM.predict(X_test)\npredictions = [round(value) for value in y_pred]","02f01309":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","e05e2932":"log_reg = LogisticRegression(solver = 'liblinear')\nlog_reg.fit(X_train, y_train)","e2d13069":"train_pred = log_reg.predict(X_train)\ntest_pred = log_reg.predict(X_test)","c1f4163e":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","85b57a64":"log_reg.variables = X_train.columns","42547cc9":"joblib.dump(log_reg, 'best_model_log_reg.joblib')","a8a33eb9":"plt.subplots(figsize = (10, 5))\ntrain_prob = log_reg.predict_proba(X_train)[:, 1]\ntest_prob = log_reg.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","4da62565":"y_pred = log_reg.predict(X_test)\npredictions = [round(value) for value in y_pred]","548134f2":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","3a5e3389":"model_parameters = {'n_estimators': [10, 50, 100, 200, 500, 750, 1000], 'max_depth': [3, 5, 10],\n                    'min_samples_leaf': [np.random.randint(1,10)], 'max_features': [None, 'sqrt', 'log2']}","8698e8c7":"model = RandomForestClassifier(random_state = 10)\ngscv_randfor = GridSearchCV(estimator = model, \n                        param_grid = model_parameters, \n                        cv = 5, \n                        verbose = 1, \n                        n_jobs = -1,\n                        scoring = 'roc_auc')\n\ngscv_randfor.fit(X_train, y_train)","c3192aad":"print('The best parameters are -', gscv_randfor.best_params_)","111b2fe6":"final_mod_randfor = GradientBoostingClassifier(**gscv_randfor.best_params_)\nfinal_mod_randfor.fit(X_train, y_train)","4702c3bf":"train_pred = final_mod_randfor.predict(X_train)\ntest_pred = final_mod_randfor.predict(X_test)","2e61904c":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","e834654d":"final_mod_randfor.variables = X_train.columns","47b521da":"joblib.dump(final_mod_randfor, 'best_model_randfor.joblib')","2adea525":"plt.subplots(figsize = (10, 5))\ntrain_prob = log_reg.predict_proba(X_train)[:, 1]\ntest_prob = log_reg.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","9240c344":"y_pred = log_reg.predict(X_test)\npredictions = [round(value) for value in y_pred]","118a0e85":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","0b7e6627":"print('The best model is Gradient Boosting model')","3f7fb453":"### g) Saving the best model","34df86bc":"* We shall recategorize the categories of the variable <b>class<\/b> for easy and simple identification of <b>Diabetes<\/b> categories.","a78d8ec2":"### c) Polydipsia","47424540":"## 4. Let's Understand Our Data","17cbcc7d":"* We would categorize the existing variables of our existing dataframe into <b>numerical<\/b> and <b>categorical<\/b> variables.","e67200dd":"### a) Separating the target variable - class from the data_new_final dataframe","fb7b89d1":"### j) Evaluating prediction accuracy for test data","6fd4a8d8":"### b) Using GridSearch Cross Validation to find out the best parameters using L2 penalty","ba18b65a":"## 6. EDA(Exploratory Data Analysis)","c1e7967c":"## 8.1) Model 1 - GBM (Gradient Boosting)","40b0ec35":"### h) visual blurring","ea3814a8":"### f) Saving the variables used in the model","78c17e0a":"### b) Displaying model prediction and classification report","086fd2a5":"### n) Alopecia","1e4fe824":"## b) Analysis of percentage unique values for categorical variables of the data_new dataset.","fddc0202":"### k) delayed healing","8b68235a":"* Converting the datatype of <b>class<\/b> column from <b>object<\/b> to <b>int<\/b>.","b4b7c8c0":"### h) Model Evaluation","aa0396a3":"### j) Irritability","a831cdef":"2. Now, let's get the summary for categorical data","0aeb2784":"### i) Making predictions for test data","a0e4616c":"### a) Gender","d08df196":"### b) Polyuria","74549c05":"## a) Analysis of unique values & their counts for categorical variables of the data_new dataset.","c663c985":"### f) Polyphagia","02bf6200":"### e) weakness","1f3d84af":"### j) Evaluating prediction accuracy for test data","e0fb3f24":"### b) Using GridSearch Cross Validation to find out the best parameters using L2 penalty","f4157b0d":"## 1. Data Categorization","6d65e23a":"## 2. Analysis of each category of the numerical variables of num_cols dataframe w.r.t Target variable - class.","e75d4cc6":"## 3. Importing Dataset","dfe37c51":"### f) Saving the variables used in the model","66bd92b2":"### p) class","eb689969":"## 9) Displaying Best Model","84914c50":"## 3. Analysis of each category of the categorical variables of obj_cols dataframe w.r.t Target variable - class.","aae74afd":"### i) Making predictions for test data","7f14fc65":"### g) Evaluating prediction accuracy for test data","f6c32a2a":"## 6.2) Univariate Analysis","df31f6ea":"### c) Displaying the best parameters","55c163e5":"### d) Refitting the model with best parameters","ebfbd03e":"### m) muscle stiffness","c302ae32":"* Now we shall first do the <b>Univariate Analysis<\/b> by analysing the data w.r.t our <b>Target Variable - class<\/b>.","4b42fc08":"## 7.1) Creating Model Dataset","ae7ff392":"### a) Define model parameters to be tuned","c861806b":"### a) Define model parameters to be tuned","3ace4dbe":"### g) Saving the best model","c746f2ff":"### b) Creating Dummy Variables","44bd2754":"## 8.2) Model 2 - Logistic Regression","f2f01f1a":"### e) Displaying model prediction and classification report","fbc475a3":"### l) partial paresis","103a78f1":"### g) Genital thrush","bb460b74":"1. First, let's get the summary of the numerical data","a6d18869":"## 6.3) Bivariate Analysis","b07e7da0":"## 6.1)  Updated Data Profiling Report","c3bfd3ec":"### c) Concatenating columns - numeric and dummies","2af765be":"### e) Displaying model prediction and classification report","061ec1be":"### d) sudden weight loss","2d7ab379":"## 7.2) Splitting the newly created model data into train and test data","ee5cce35":"### e) Model Evaluation","7a4fc9f0":"### a) Finding unique values of each object variable of data_new dataframe","b1adc34e":"## 2. Defining Functions For Plotting ROC_AUC Curve & ROC_Plot","6407750f":"## 1. Importing Necessary Libraries","28427a69":"### b) Performing Train, Test & Split","567a1135":"* Let's check if there are any null variables in the <b>data_new<\/b> dataset.","9f27da01":"## 5. Data Profiling Report","f4609d6e":"* The entire dataset contains <b>520<\/b> rows and <b>17<\/b> columns.","e2c1cd42":"## 8) Applying Different Models On Train & Test Data","8aab0251":"### Following are the insights gathered from the boxplots\n\n* <b>The \"Age\" boxplot shows that greater the Age, higher the chance of a person having Diabetes<\/b>.","6345418d":"### d) Null value check in the final dataset before model run","84ce9e8e":"* We have approximately <b>38.46%<\/b> of <b>0's<\/b> and <b>61.54%<\/b> of <b>1's<\/b> classes in our data.","2fd16c38":"### c) Displaying the best parameters","93dd5020":"* Let's drop the columns which we won't be using.","905a7cce":"### Following are the insights gathered from the data_new dataframe\n\n1. <b>Maximum entries<\/b> are of <b>males<\/b> as compared to <b>females<\/b>.\n2. <b>49.62%<\/b> of the total population suffers from <b>Polyuria<\/b>.\n3. <b>44.81%<\/b> of the total population suffers from <b>Polydipsia<\/b>.\n4. <b>41.73%<\/b> of the total population suffers from <b>Sudden Weight Loss<\/b>.\n5. <b>58.65%<\/b> of the total population suffers from <b>Weakness<\/b>.\n6. <b>45.58%<\/b> of the total population suffers from <b>Polyphagia<\/b>.\n7. <b>22.31%<\/b> of the total population suffers from <b>Genital Thrush<\/b>.\n8. <b>44.81%<\/b> of the total population suffers from <b>Visual Blurring<\/b>.\n9. <b>48.65%<\/b> of the total population suffers from <b>Itching<\/b>.\n10. <b>24.23%<\/b> of the total population suffers from <b>Irritability<\/b>.\n11. <b>45.96%<\/b> of the total population suffers from <b>Delayed Healing<\/b>.\n12. <b>43.08%<\/b> of the total population suffers from <b>Partial Paresis<\/b>.\n13. <b>37.50%<\/b> of the total population suffers from <b>Muscle Stiffness<\/b>.\n14. <b>34.42%<\/b> of the total population suffers from <b>Alopecia<\/b>.\n15. <b>16.92%<\/b> of the total population suffers from <b>Obesity<\/b>.\n16. <b>61.54%<\/b> of the total population suffers from <b>Diabetes<\/b>.","d30157c1":"### c) Saving the variables used in the model","6515c86c":"### a) Applying logistic regression","754f3c93":"### o) Obesity","6fca1850":"### d) Saving the best model","5f043533":"### i) Itching","70fc972a":"### h) Model Evaluation","7e4d8da3":"### d) Refitting the model with best parameters","91a0af8a":"### f) Making predictions for test data","85427367":"## 8.3) Model 3 - Random Forest Classifier","ebbac766":"### Following are the insights gathered from the stacked bar charts\n\n* <b>Females are more prone to have Diabetes as compared to males<\/b>.\n* <b>Persons having Polyuria are more prone to have Diabetes as compared to those not having Polyuria<\/b>.\n* <b>Persons having Polydipsia are more prone to have Diabetes as compared to those not having Polydipsia<\/b>.\n* <b>Persons experiencing sudden weight loss are more prone to have Diabetes as compared to those not experiencing any kind of sudden weight loss<\/b>.\n* <b>Persons having weakness are more prone to have Diabetes as compared to those not having any weakness<\/b>.\n* <b>Persons having Polyphagia are more prone to have Diabetes as compared to those not having Polyphagia<\/b>.\n* <b>Persons experiencing Genital thrush are more prone to have Diabetes as compared to those not experiencing any kind of Genital thrush<\/b>.\n* <b>Persons experiencing visual blurring are more prone to have Diabetes as compared to those not experiencing any kind of visual blurring<\/b>.\n* <b>Persons experiencing any kind of Irritability are more prone to have Diabetes as compared to those not experiencing any kind of Irritability<\/b>.\n* <b>Persons having partial paresis are more prone to have Diabetes as compared to those not having partial paresis<\/b>.\n* <b>Persons experiencing any kind of muscle stiffness are more prone to have Diabetes as compared to those not experiencing any kind of muscle stiffness<\/b>.\n* <b>Persons having Obesity are more prone to have Diabetes as compared to those not having Obesity<\/b>.\n* <b>So, overall we can say that a person who is a Female and has either Polyuria, Polydipsia or Polyphagia, and is also experiencing weakness, Genital thrush, visual blurring, Irritability, partial paresis or muscle stiffness and also experiences either a sudden weight loss or is an Obese person is more prone to have Diabetes<\/b>.","b87476d0":"## 7. Feature Engineering","5f93575d":"* Let's first plot the boxplot of each numerical variable w.r.t our target variable."}}