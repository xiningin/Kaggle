{"cell_type":{"2c3b1cec":"code","1ccc1d5b":"code","55604b71":"code","ea3ff3d9":"code","9e1cb8d0":"code","6a68efab":"code","ccfaf1f5":"code","ea46134d":"code","43966152":"code","07c8a2a2":"code","5414891f":"code","df77e63a":"markdown","f7c40ae9":"markdown","a8dff5ae":"markdown","08ffef3a":"markdown","fad3f8c6":"markdown","ad246e52":"markdown","2f4bb8f8":"markdown","d667eee7":"markdown","a5489aee":"markdown","973e0f73":"markdown","96bd78f8":"markdown"},"source":{"2c3b1cec":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 14})\n\nfrom time import strptime\nfrom datetime import datetime, date \n\nimport re\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nimport spacy # Leading library for NLP\nnlp = spacy.load('en')\nfrom nltk.stem import SnowballStemmer #WordNetLemmatizer, \nimport string","1ccc1d5b":"# Load the dataset\nnetflix_titles = pd.read_csv('\/kaggle\/input\/netflix-shows\/netflix_titles.csv')\n\n# Only filter for TV shows\nnetflix_shows = netflix_titles[(netflix_titles.type == 'TV Show')].reset_index(drop=True)\n\ndel netflix_titles\nnetflix_shows.head()","55604b71":"netflix_shows.info()","ea3ff3d9":"netflix_shows.nunique()","9e1cb8d0":"netflix_shows.isna().sum(axis=0)","6a68efab":"# Remove unnecessary columns\nnetflix_shows.drop([\"show_id\", \"type\"], axis=1, inplace=True)","ccfaf1f5":"display(netflix_shows[['duration', 'date_added']].head().style.set_caption(\"Before correcting data format\"))\n\n# Convert duration from string format to integer and re\n# Remove keyword \"season\"\nnetflix_shows[\"duration\"] = netflix_shows.duration.apply(lambda x: x.split(' ')[0])\n# Convert to integer\nnetflix_shows[\"duration\"] = netflix_shows[\"duration\"].astype(int)\n\n\n# Split the date format into year, month, day\n# Convert to string\nnetflix_shows.date_added = netflix_shows.date_added.astype(str)\n# Clean data where first character in string is a space\nnetflix_shows.date_added = netflix_shows.date_added.apply(lambda x: x[1:] if x[0] == \" \" else x)\n\n# Get the month\nnetflix_shows['date_added_month'] = netflix_shows.date_added.apply(lambda x: x.split(\" \")[0])\n# Convert string to integer\nnetflix_shows['date_added_month'] = netflix_shows.date_added_month.apply(lambda x: strptime(x,'%B').tm_mon if ((x != \"\")&(x != \"nan\")) else np.nan)\n# Fill nan and convert to integer\nnetflix_shows['date_added_month'] = netflix_shows['date_added_month'].fillna(1).astype(int)\n\n# Get the day\nnetflix_shows['date_added_day'] = netflix_shows.date_added.apply(lambda x: x.split(\" \")[1] if len(x.split(\" \")) > 1 else np.nan)\n# Remove \",\"\nnetflix_shows['date_added_day'] = netflix_shows.date_added_day.apply(lambda x: x.split(\",\")[0] if x==x else np.nan)\n# Fill nan and convert to integer\nnetflix_shows['date_added_day'] = netflix_shows['date_added_day'].fillna(1).astype(int)\n\n# Get the year\nnetflix_shows['date_added_year'] = netflix_shows.date_added.apply(lambda x: x.split(\" \")[2] if len(x.split(\" \")) > 2 else np.nan)\n# Fill nan and convert to integer\nnetflix_shows['date_added_year'] = netflix_shows['date_added_year'].fillna(1800).astype(int)\n\n# Convert date_added to datetime format\nnetflix_shows['date_added'] = netflix_shows.apply(lambda x: datetime(x.date_added_year, x.date_added_month, x.date_added_day), axis=1)\n\ndisplay(netflix_shows[['duration', 'date_added', 'date_added_day', 'date_added_month', 'date_added_year']].head().style.set_caption(\"After correcting data format\"))","ea46134d":"display(netflix_shows[['listed_in']].head().style.set_caption(\"Before using MultiLabelBinarizer\"))\n\nmlb_columns = [\"listed_in\", \"cast\", \"director\", \"country\"]\nmlb = MultiLabelBinarizer()\n\nfor col in mlb_columns:\n    netflix_shows[col] = netflix_shows[col].fillna(\"Unknown\")\n    netflix_shows[col] = netflix_shows[col].apply(lambda x: x.split(\", \"))\n    netflix_shows = netflix_shows.join(pd.DataFrame(mlb.fit_transform(netflix_shows[col]),columns= [f\"{col}_{re.sub(' ', '', c)}\" for c in mlb.classes_]))\n\nnetflix_shows.drop(mlb_columns, axis=1, inplace=True)\n\ndisplay(netflix_shows[netflix_shows.columns[netflix_shows.columns.str.startswith('listed_in')]].head().style.set_caption(\"After using MultiLabelBinarizer\"))\n","43966152":"display(netflix_shows[['description']].head().style.set_table_attributes(\"style='display:inline'\").set_caption(\"Before creating Document-Term Matrix\"))\n\n\ndef clean_text(text):\n    # Convert text to lowercase\n    text = text.lower() \n\n    # Remove punctuation\n    text = re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)\n\n    # Remove non-Roman characters\n    text = re.sub(\"([^\\x00-\\x7F])+\", \" \", text)\n    \n    # Tokenize\n    text = nlp(text)\n\n    stemmer = SnowballStemmer(\"english\")\n\n    text_clean = \"\"\n    for token in text:\n        # Remove stop words and remove words with fewer than 3 chars\n        if (not token.is_stop) and len(token) > 3:\n            # Lemmatize and tokenize\n            text_clean += stemmer.stem(token.lemma_) + \" \"\n    \n    return text_clean\n\n\nnetflix_shows['description_clean'] = netflix_shows.description.apply(lambda x: clean_text(x))\n\ncv = CountVectorizer(ngram_range=(1,1)) # Doesn't include bigrams\ndata_cv = cv.fit_transform(netflix_shows['description_clean'])\ndata_dtm = pd.DataFrame(data_cv.toarray(), columns = cv.get_feature_names())\ndata_dtm.index = netflix_shows.index\ndata_dtm.columns = [f\"dtm_descr_{c}\" for c in data_dtm.columns]\n\nnetflix_shows = netflix_shows.join(data_dtm)\n\ncv = CountVectorizer(ngram_range=(1,1)) # Doesn't include bigrams\ndata_cv = cv.fit_transform(netflix_shows['title'])\ndata_dtm = pd.DataFrame(data_cv.toarray(), columns = cv.get_feature_names())\ndata_dtm.index = netflix_shows.index\ndata_dtm.columns = [f\"dtm_title_{c}\" for c in data_dtm.columns]\n\nnetflix_shows = netflix_shows.join(data_dtm)\n\ndisplay(netflix_shows[netflix_shows.columns[netflix_shows.columns.str.startswith('dtm_descr_')]].head().style.set_caption(\"After creating Document-Term Matrix\"))\n","07c8a2a2":"# The weekday on which the TV show was added to the library\nnetflix_shows['date_added_weekday'] = pd.DatetimeIndex(netflix_shows['date_added']).weekday\n\n# The release year of the first season of the TV show\nnetflix_shows['first_release_year'] = netflix_shows.release_year - netflix_shows.duration\n\n# The time between the original release of the TV show and the TV show being added to the Netflix library\nnetflix_shows['time_first_release_to_netflix'] = netflix_shows.date_added_year - netflix_shows.first_release_year","5414891f":"# Save current state to output\nnetflix_shows.to_csv(\"netflix_shows.csv\", index=False)","df77e63a":"## Correct Data Format\n`date_added` and `duration` are currently of the data type object and should be converted to a datetime type and numerical type respectively.","f7c40ae9":"## Remove Unnecessary Columns\n`show_id` does not contain any relevant information and should be removed. Also, `type` only has one unique value (\"TV Shows\") since we removed all movies. Therefore, this column does not contain any relevant information and should be removed.","a8dff5ae":"# Data Collection\n\nI guess this is the \"Chicken or the Egg\" problem of data journalism. Do you **start with a question\/hypothesis or do you just dive into any dataset** that looks interesting to you? This is probably a whole topic on its own and since I am not a professional data journalist, I do not feel qualified to give a good answer to this question. But my guess would be that if you have a specific question in mind that you would like to answer, it could help you focus your attention during the exploration. (If you are a data journalist, please feel free to share your thoughts on this topic in the comments.) Additionally, **gathering the data** can be another topic on its own. \n\nFor the sake of this tutorial, we will just take a fun dataset, dive in and see what stories the data is going to tell us. We will be using the popular [Netflix Movies and TV Shows](https:\/\/www.kaggle.com\/shivamb\/netflix-shows) dataset by [Shivam Bansal](https:\/\/www.kaggle.com\/shivamb) as a starting point. Therefore, the data collection step in this case is only to load the data. However, it is important to understand how the data was collected even if the dataset is already prepared for you.\n\nIn the dataset description, we can see that\n> [t]his dataset consists of **tv shows and movies available on Netflix as of 2019**. The dataset is **collected from Flixable** which is a third-party Netflix search engine. \n\nFurthermore, if you go to the 'Metadata' tab, you can see that this dataset is was **created in December 2019** and has since been **updated four times**. The last update was in January 2021.\n![Screenshot%202021-04-02%20at%2009.50.17.png](attachment:Screenshot%202021-04-02%20at%2009.50.17.png)\n\nSince we didn't prepare a question we would like to answer beforehand, we will just explore the data. To simplify the dataset a little bit for the purpose of this tutorial, we will **focus only on Netflix TV shows** and ignore Netflix movies for now.\n\nThe dataset has 12 columns, such as the title of the TV show, its director and cast, and so on, as shown below.","08ffef3a":"## Handling missing values\n\nWe have to think about how to handle the missing values in the columns `director`, `cast`, `country`, `date_added`, and `rating`.\n* For `director`, `cast`, `country`, we cann fill the missing values with \"Unknown\" since these are categorical features.\n* The missing values in `date_added` will be filled with \"January 1, 1800\", which will be our dummy date.\n* The `rating` columns rating already has a categoriy \"NR\", which means \"no rating\". We will used this category to fill missing values.","fad3f8c6":"## \ud83d\ude80 Let's continue with [Lesson 2: Exploratory Data Analysis](https:\/\/www.kaggle.com\/iamleonie\/data-journalism-exploratory-data-analysis-2-5)","ad246e52":"# Feature Engineering\nNow that we have cleaned the data, it is time to create some additional features. Feature engineering can help you gain a better understanding of your dataset, similarly to how new features can improve your performance when you are trying to model data. To keep things simple, we will only create three new features.","2f4bb8f8":"After the above checks, we already found a few cleaning steps to do:\n* **Remove unnecessary columns**\n    * `show_id` does not contain any relevant information and should be removed\n    * `type` only has one unique value (\"TV Shows\") since we removed all movies. Therefore, this column does not contain any relevant information and should be removed\n* **Handling missing values**<br>\n    We have to think about how to handle the missing values in the columns `director`, `cast`, `country`, `date_added`, and `rating`\n* **Correct data format** <br>\n    `date_added` and `duration` are currently of the data type object and should be converted to a datetime type and numerical type respectively\n* **Untangle merged columns** <br>\n    Additionally, from the first look at the dataframe we can see that `cast` and `listed_in` have names and categories that can appear in mutliple data points. We should think about how to preprocess this for easier handling.\n* **Handle Text Data**","d667eee7":"## Untangle Merged Columns\nAdditionally, from the first look at the dataframe we can see that `cast` and `listed_in` have names and categories that can appear in mutliple data points. We should think about how to preprocess this for easier handling.\n\nWith the help of the `MultiLabelBinarizer`, we can easily untangle these merged values.","a5489aee":"# Introduction\nThis is part 1 of the [Data Journalism Workflow tutorial  series](https:\/\/www.kaggle.com\/iamleonie\/data-journalism-workflow).\nIn this notebook you will learn how to clean and process the data before you begin with any exploration or visualizations.\n\n![Screenshot%202021-03-23%20at%2019.52.35.png](attachment:Screenshot%202021-03-23%20at%2019.52.35.png)","973e0f73":"# Data Cleaning & Preprocessing\nBefore we begin with the actual data analysis, we should do a little bit of data cleaning and some preprocessing of the data. According to The Guardian [2], they spend about 70% of their time on data cleaning and preprocessing and only 30% on the fun part of visualization.\n\nLet's get a quick overview of the state of the data and make a rough plan of what we have to do. We will check the data types (`.info()`), number of unique values (`.nunique()`), and number of missing values (`.isna()`) for each column as shown below.","96bd78f8":"## Handle Text Data\nText to Document-Term Matrix"}}