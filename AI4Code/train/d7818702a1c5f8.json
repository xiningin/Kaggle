{"cell_type":{"235bf907":"code","ef122e43":"code","0ec23941":"code","6502904f":"code","d396d7cb":"code","5758c68a":"code","aabc6621":"code","d5f0e496":"code","c414b356":"code","59f6fd09":"code","54989622":"code","5c478744":"code","4c276fcb":"code","0be42852":"code","f10ebc57":"code","1dcef6d0":"code","6db96144":"code","f78e8a29":"code","6c379ea5":"code","b44e98e9":"code","cf19b864":"code","feedd1ce":"code","08ad0428":"code","11e13189":"code","97edd5a4":"code","4c716b07":"code","b13b3c13":"code","e4b2d84a":"code","356fb1e8":"code","96dd88fa":"code","0e2d94f6":"code","07110a35":"code","2d4f0478":"code","3dc951c2":"code","1a7d7c79":"markdown","0532e797":"markdown","15781839":"markdown","f6f96485":"markdown","9f5b3076":"markdown"},"source":{"235bf907":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBClassifier\nfrom vecstack import stacking\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Lasso, LogisticRegression\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ef122e43":"pd.set_option('display.max_columns', None)  ","0ec23941":"df_train = pd.read_csv('\/kaggle\/input\/learn-together\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/learn-together\/test.csv')","6502904f":"df_train.head()\ndf_train.info()\ndf_train['Cover_Type'].nunique()\n","d396d7cb":"#number of occurrence of each cover type\ndf_train['Cover_Type'].value_counts()","5758c68a":"df_train['Cover_Type'].value_counts().plot(kind= 'bar')","aabc6621":"#Explore Soil Type\ndf_train['Soil_Type1'].value_counts().plot(kind= 'bar')","d5f0e496":"#Find location of columns Soil Types\nprint(df_train.columns.get_loc(\"Soil_Type1\"))\nprint(df_train.columns.get_loc(\"Soil_Type40\"))\n\n","c414b356":"df_soil= df_train.iloc[ :, 15:55]\n\n","59f6fd09":"#Find all the Soil Type columns which have all zeroes\ndf_soil.columns[(df_soil == 0).all()] # this gives columns which have all values zeroes","54989622":"#Drop those columns\ndf_train= df_train.drop(['Soil_Type7', 'Soil_Type15'], axis=1 )# Explore Wilderness Area","5c478744":"df_train['Wilderness_Area4'].value_counts()","4c276fcb":"df_train[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']].apply(pd.Series.value_counts)\n\n","0be42852":"df_train[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']].apply(pd.Series.value_counts).plot(kind='bar')\n#this shows most of forests come under wilderness area 3 or Comanche Peak Wilderness Area\n\n","f10ebc57":"#drop id \ndf_train = df_train.drop(['Id'], axis= 1)","1dcef6d0":"\ncor = df_train.corr()\nplt.figure(figsize=(14,14))\nsns.heatmap(cor, cbar= True, square = True, cmap= 'coolwarm')\n#plt.show()","6db96144":"#Correlation between the target variable Cover_Type and the other features\ndf_train[df_train.columns[1:]].corr()['Cover_Type'][:]","f78e8a29":"#Correlation with output variable\ncor_target = abs(cor[\"Cover_Type\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.10]\nrelevant_features\n\n","6c379ea5":"#We can keep all the features","b44e98e9":"y= 'Cover_Type'\nfeatures = df_train.drop(['Cover_Type'], axis=1)","cf19b864":"X= features.columns[:len(features.columns)]","feedd1ce":"X_train, X_test, y_train, y_test = train_test_split(df_train[X], df_train[y], test_size=.20, random_state =0)","08ad0428":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","11e13189":"rfc= RandomForestClassifier(n_estimators= 100)","97edd5a4":"rfc.fit(X_train, y_train)","4c716b07":"rfc_prediction = rfc.predict(X_test)","b13b3c13":"rfc_accuracy = accuracy_score(rfc_prediction, y_test)","e4b2d84a":"print('Random Forest with scaling Final prediction score: [%.8f]' % rfc_accuracy)\n\n","356fb1e8":"# Actual versus Predicted Values\n\nnew_df_pred_actual = pd.DataFrame({'Actual': y_test, 'Predicted': rfc_prediction})\nprint(new_df_pred_actual)","96dd88fa":"#Drop the columns from the test dataset too\ndf_test_final = df_test.drop(['Id','Soil_Type7', 'Soil_Type15'], axis=1 )\n","0e2d94f6":"rfc_cover_type_predicted = rfc.predict(df_test_final)","07110a35":"final =pd.DataFrame(df_test['Id'])\nfinal['Cover_Type']=rfc_cover_type_predicted","2d4f0478":"final.to_csv(\"rfc_cover_type_predicted.csv\", index=False)","3dc951c2":"final.info()","1a7d7c79":"# Using Random Forest on Test","0532e797":"# Correlation","15781839":"# EDA","f6f96485":"# Explore Wilderness Area","9f5b3076":"# Random Forest"}}