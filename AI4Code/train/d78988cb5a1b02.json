{"cell_type":{"7a365a0d":"code","56fbca2b":"code","37d15a09":"code","bd0444da":"code","f491611d":"code","76d1fcbd":"code","3b68ee87":"code","7477ede7":"code","8208ff55":"code","09c5a95e":"code","c405acfe":"code","57e70f4a":"code","cf572d54":"code","1cc535cb":"code","17ce0c0e":"code","beaa27e0":"markdown","58b2b326":"markdown","62613a78":"markdown","8f5ff937":"markdown","c1c96239":"markdown","0aa2ed9c":"markdown","714468a7":"markdown","1910d4d4":"markdown","c44e62cf":"markdown","0287737b":"markdown","fb483566":"markdown"},"source":{"7a365a0d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","56fbca2b":"from sklearn.datasets import make_classification\nx,y=make_classification(n_samples=2000,n_features=20,n_classes=2,weights=[1,1],random_state=1)","37d15a09":"x.shape","bd0444da":"y.shape","f491611d":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=1)","76d1fcbd":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","3b68ee87":"from sklearn.ensemble import RandomForestClassifier\nrfmod=RandomForestClassifier()\nrfmod.fit(xtrain,ytrain)\nytrainpred=rfmod.predict_proba(xtrain)\nprint(\"Random Forest train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=rfmod.predict_proba(xtest)\nprint(\"Random Forest train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","7477ede7":"from sklearn.linear_model import LogisticRegression\nlogmod=LogisticRegression()\nlogmod.fit(xtrain,ytrain)\nytrainpred=logmod.predict_proba(xtrain)\nprint(\"Logistic regression train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=logmod.predict_proba(xtest)\nprint(\"Logistic regression train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","8208ff55":"from sklearn.ensemble import AdaBoostClassifier\nadamod=AdaBoostClassifier()\nadamod.fit(xtrain,ytrain)\nytrainpred=adamod.predict_proba(xtrain)\nprint(\"Ada Boost train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=adamod.predict_proba(xtest)\nprint(\"Ada Boost train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","09c5a95e":"from sklearn.neighbors import KNeighborsClassifier\nknnmod=KNeighborsClassifier()\nknnmod.fit(xtrain,ytrain)\nytrainpred=knnmod.predict_proba(xtrain)\nprint(\"K Nearest Neighbor Classifier  train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=knnmod.predict_proba(xtest)\nprint(\"K Nearest Neighbor Classifier train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","c405acfe":"pred=[]\nfor model in [rfmod,logmod,adamod,knnmod]:\n    pred.append(pd.Series(model.predict_proba(xtest)[:,1]))\nfinalpred=pd.concat(pred,axis=1).mean(axis=1)\nprint(\"Ensemble models test roc-auc score {}\".format(roc_auc_score(ytest,finalpred)))","57e70f4a":"fpr,tpr,threshold= roc_curve(ytest,finalpred)\nthreshold","cf572d54":"from sklearn.metrics import accuracy_score\nacc=[]\nfor thres in threshold:\n    ypred=np.where(finalpred>thres,1,0)\n    acc.append(accuracy_score(ytest,ypred,normalize=True))\nacc=pd.concat([pd.Series(acc),pd.Series(thres)],axis=1)\nacc.columns=['Accuracy','Threshold']\nacc.sort_values(by='Accuracy',ascending=False,inplace=True)\nacc.head()","1cc535cb":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='red', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","17ce0c0e":"plot_roc_curve(fpr,tpr)","beaa27e0":"# **Train test split**","58b2b326":"**Thus we can say that the roc curve is well structured.**","62613a78":"**Now we are going to calculate the mean of all predictions of the  x test data to make a final prediction data**","8f5ff937":"# **Ada Boost Classifier**","c1c96239":"# **Logistic Regression**","0aa2ed9c":"# **ROC-AUC CURVE**\n**ROC stands for Receiver Operating Characteristic, AUC stands for area under curve. ROC-AUC  is used as a metrics for classification problems. It is used to pick the correct threshold for the classification problem. The area under curve varies between 0-1. AUC-1 is the model with high accuracy and with 0 is the worst model. 0.5 is not a good model as it will not correctly predict the classes. The higher the area under the curve, the higher the model performance**","714468a7":"# **K Nearest Neighbor Classifier**","1910d4d4":"**The roc curve gives some threshold values. We have to select the correct threshold value which gives more model accuracy.**","c44e62cf":"**We are going to create models using some algorithms**","0287737b":"# **Random Forest**","fb483566":"**Lets make a dataset to create a model for binary classification**"}}