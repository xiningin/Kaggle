{"cell_type":{"dcac0325":"code","f88342db":"code","58a48190":"code","6a7b6c77":"code","3b7a0b0a":"code","d81c6386":"code","4a71ff8c":"code","972a8ee0":"code","6c59b778":"code","cd9388ef":"code","56fc3dfc":"code","fe626d41":"code","2c33f61c":"markdown","6c6c1b9d":"markdown"},"source":{"dcac0325":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f88342db":"!pip install pyspark","58a48190":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('spark-dataframe-demo').getOrCreate()","6a7b6c77":"from pyspark.sql import *\n \nEmployee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n \nemployee1 = Employee('Basher', 'armbrust', 'bash@edureka.co', 100000)\nemployee2 = Employee('Daniel', 'meng', 'daniel@stanford.edu', 120000 )\nemployee3 = Employee('Muriel', None, 'muriel@waterloo.edu', 140000 )\nemployee4 = Employee('Rachel', 'wendell', 'rach_3@edureka.co', 160000 )\nemployee5 = Employee('Zach', 'galifianakis', 'zach_g@edureka.co', 160000 )\n \nprint(Employee[0])\n \nprint(employee3)\n \ndepartment1 = Row(id='123456', name='HR')\ndepartment2 = Row(id='789012', name='OPS')\ndepartment3 = Row(id='345678', name='FN')\ndepartment4 = Row(id='901234', name='DEV')","3b7a0b0a":"departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2, employee5])\ndepartmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\ndepartmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4, employee3])\ndepartmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])\n","d81c6386":"departmentsWithEmployees_Seq = [departmentWithEmployees1, departmentWithEmployees2]\ndframe = spark.createDataFrame(departmentsWithEmployees_Seq)\ndisplay(dframe)\ndframe.show()","4a71ff8c":"fifa_df = spark.read.csv(\"..\/input\/PlayerNames.csv\", inferSchema = True, header = True)\n \nfifa_df.show()","972a8ee0":"fifa_df.printSchema()","6c59b778":"fifa_df.columns # Column Names\n \nfifa_df.count() # Row Count\n \nlen(fifa_df.columns) # Column Count","cd9388ef":"fifa_df.describe('Name').show()\nfifa_df.describe('url').show()","56fc3dfc":"fifa_df.select('Name','url').show()","fe626d41":"fifa_df.select('Name','url').distinct().show()","2c33f61c":"**Dataframe Creation**\n\nWe\u2019ll create Employee and Department instances.","6c6c1b9d":"**DataFrame Creation from CSV File**"}}