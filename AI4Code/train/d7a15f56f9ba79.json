{"cell_type":{"96fedad0":"code","270c4dcd":"code","63652680":"code","9e921f94":"code","2c8e68d2":"code","54aaf464":"code","3233d7d3":"code","b73cb5d2":"code","68c19b9d":"code","15891db6":"markdown","86bb52f1":"markdown","5904431a":"markdown","1d55bc72":"markdown","cb94b8af":"markdown","d41a1f47":"markdown","5b3c16a5":"markdown","88838f2c":"markdown","3c7fc1f3":"markdown","118441d7":"markdown"},"source":{"96fedad0":"!pip install --upgarde pod\n!pip install combo ","270c4dcd":"from __future__ import division\nfrom __future__ import print_function\nimport os\nimport sys\nfrom time import time\nimport numpy as np\nfrom numpy import percentile\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager ","63652680":"from pyod.models.abod import ABOD\nfrom pyod.models.cblof import CBLOF\nfrom pyod.models.iforest import IForest\nfrom pyod.models.knn import KNN\nfrom pyod.models.lof import LOF\nfrom pyod.models.ocsvm import OCSVM\nfrom pyod.models.pca import PCA ","9e921f94":"num_samples = 5000\nfrom random import randrange\nout_frac=randrange(0,45)\/100\nout_frac","2c8e68d2":"clusters_separation = [0]\nx, y = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))\n\"\"\"\n(1 - fraction of outliers) will give the fraction of inliers; multiplying  it with the total number #of samples will give number of inliers\n\"\"\"\nnum_inliers = int((1. - out_frac) * num_samples)\n\"\"\"\nMultiply fraction of outliers with total number of samples to compute number of outliers\n\"\"\"\nnum_outliers = int(out_frac * num_samples)\n\"\"\"\nCreate ground truth array with 0 and 1 representing outliers and inliers respectively\n\"\"\"\nground_truth = np.zeros(num_samples, dtype=int)\nground_truth[-num_outliers:] = 1 ","54aaf464":"print('No. of inliers: %i' % num_inliers)\nprint('No. of outliers: %i' % num_outliers)\nprint('Ground truth arrayy shape is {shape}. Outlier are 1 and inlier are 0.\\n'.format(shape=ground_truth.shape))\nprint(ground_truth) ","3233d7d3":"rs = np.random.RandomState(42)  #random state\n #dictionary of classifiers\nclf = { \n    'Angle-based Outlier Detector (ABOD)': ABOD(contamination=out_frac),\n    'Cluster-based Local Outlier Factor (CBLOF)': CBLOF(contamination=out_frac,check_estimator=False, random_state=rs),\n    'Isolation Forest': IForest(contamination=out_frac,random_state=rs),\n    'K Nearest Neighbors (KNN)': KNN(contamination=out_frac),\n    'Average KNN': KNN(method='mean', contamination=out_frac),\n    'Local Outlier Factor (LOF)':LOF(n_neighbors=35, contamination=out_frac),\n    'One-class SVM (OCSVM)': OCSVM(contamination=out_frac),\n    'Principal Component Analysis (PCA)': PCA(contamination=out_frac, random_state=rs),\n} ","b73cb5d2":"for i, classifier in enumerate(clf.keys()):\n    print('Model', i + 1, classifier) ","68c19b9d":"# Fit the models with the generated data and \n# compare model performances\nfor i, offset in enumerate(clusters_separation):\n    np.random.seed(42)\n    # Data generation\n    X1 = 0.3 * np.random.randn(num_inliers \/\/ 2, 2) - offset\n    X2 = 0.3 * np.random.randn(num_inliers \/\/ 2, 2) + offset\n    X = np.r_[X1, X2]\n    # Add outliers\n    X = np.r_[X, np.random.uniform(low=-6, high=6, size=(num_outliers, 2))]\n\n    # Fit the model\n    plt.figure(figsize=(15, 60))\n    for i, (classifier_name, classifier) in enumerate(clf.items()):\n        #print(i + 1, 'fitting', classifier_name)\n        # fit the data and tag outliers\n        classifier.fit(X)\n        scores_pred = classifier.decision_function(X) * -1\n        y_pred = classifier.predict(X)\n        threshold = percentile(scores_pred, 100 * out_frac)\n        num_errors = (y_pred != ground_truth).sum()\n        # plot the levels lines and the points\n\n        Z = classifier.decision_function(np.c_[x.ravel(), y.ravel()]) * -1\n        Z = Z.reshape(x.shape)\n        subplot = plt.subplot(8, 1, i + 1)\n        subplot.contourf(x, y, Z, levels=np.linspace(Z.min(), threshold, 7),\n                         cmap=plt.cm.Blues_r)\n        a = subplot.contour(x, y, Z, levels=[threshold],\n                            linewidths=2, colors='red')\n        subplot.contourf(x, y, Z, levels=[threshold, Z.max()],\n                         colors='orange')\n        b = subplot.scatter(X[:-num_outliers, 0], X[:-num_outliers, 1], c='white',\n                            s=20, edgecolor='k')\n        c = subplot.scatter(X[-num_outliers:, 0], X[-num_outliers:, 1], c='black',\n                            s=20, edgecolor='k')\n        subplot.axis('tight')\n        subplot.legend(\n            [a.collections[0], b, c],\n            ['learned decision function', 'true inliers', 'true outliers'],\n            prop=matplotlib.font_manager.FontProperties(size=10),\n            loc='lower right')\n        subplot.set_xlabel(\"%d. %s (errors: %d)\" % (i + 1, classifier_name, num_errors))\n        subplot.set_xlim((-7, 7))\n        subplot.set_ylim((-7, 7))\n    plt.subplots_adjust(0.04, 0.1, 1.00, 0.94, 0.1, 0.26)\n    plt.suptitle(\"Outlier detection by 8 models\")\nplt.show()","15891db6":"# Display the names of classifiers used","86bb52f1":"# Import all the models to be used from pyod.models module","5904431a":"# Define a dictionary of outlier detection methods to be compared","1d55bc72":"PyOD is an open-source Python toolbox that provides over 20 outlier detection algorithms till date \u2013 ranging from traditional techniques like local outlier factor to novel neural network architectures such as adversarial models or autoencoders.","cb94b8af":"# Display the number of inliers and outliers and the ground truth array.","d41a1f47":"# Define number of inliers and outliers.","5b3c16a5":"# Install PyOD and combo toolbox","88838f2c":"# Initialize inliers and outliers data","3c7fc1f3":"# Fit the models to the data and visualize their results","118441d7":"# Import required libraries "}}