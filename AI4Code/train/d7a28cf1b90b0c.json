{"cell_type":{"83bc07ea":"code","ee5b77c4":"code","328453b4":"code","f81e7ee1":"code","98af5ba4":"code","ede24446":"code","4c882fc5":"code","d31f07cf":"code","62f7ef51":"code","fc71e1a0":"code","dce18a59":"code","434f162f":"code","fbd74cea":"code","137cfe0b":"code","d690731a":"code","610cfa92":"code","4b7ee983":"code","ddf47605":"code","8384d09a":"code","aa4ce0cd":"code","8ebe3324":"code","5100f205":"code","e2419732":"code","c92c831a":"code","68d1b629":"code","2c21bc84":"code","af9b17a7":"code","f2c96ab9":"code","d56a7b04":"code","f45b026a":"code","b1dceaef":"code","9aa53724":"code","1baf50e4":"code","9d4faf8e":"code","3d45b284":"code","70d7bbbc":"code","84ec3aec":"code","076fee4e":"code","866540ef":"code","2c62a183":"code","386eee13":"code","2269d02e":"code","6885090b":"code","664007f1":"code","fc68b1c4":"code","a5d740d0":"code","19f83679":"code","a6381d3a":"code","25d1feeb":"code","06277567":"code","e5d2e036":"code","7c54ed31":"code","044553f0":"code","203b83ab":"code","c84f3d3c":"code","9c1df091":"code","130dedc5":"code","5d56cad1":"code","dbf90784":"code","214f5c6d":"code","6fb75e60":"code","1ad46f0b":"code","318e3523":"code","2ec70645":"code","b93e1c20":"code","38ea58bc":"code","7bb095f7":"code","38fd87f6":"code","2c4c3f68":"code","5a067710":"code","202e6890":"code","aba4de2c":"code","9e0e892a":"code","7e06bc0e":"code","3f0f083d":"code","cdc61685":"code","d896533a":"code","92f29af9":"code","1d0ce2a3":"code","3857efb6":"code","239f4999":"code","248316d2":"code","d1a6641b":"code","6bc1c6fe":"code","e266ddc4":"markdown","58dffc15":"markdown","5c35f790":"markdown","500e1b9e":"markdown","722828ca":"markdown","24f92430":"markdown","7c14912f":"markdown","beed172f":"markdown","1e0f8c4d":"markdown","8a7537bb":"markdown","86f2da96":"markdown","d80189a6":"markdown","7ddaded2":"markdown","7d5c2a7f":"markdown","051ba291":"markdown","62d9d955":"markdown","67fb7e8a":"markdown","b4f7c265":"markdown","eeeaf0cf":"markdown","62492803":"markdown","c773b59b":"markdown","bb9cb505":"markdown","0f0d4d8a":"markdown","082209ec":"markdown","c606bb42":"markdown","c1bd61bd":"markdown","ba4c1f5c":"markdown","8aa159d6":"markdown","6d8e33f2":"markdown","cd8fd040":"markdown","41f110da":"markdown","13895bcf":"markdown"},"source":{"83bc07ea":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\nimport skimage\nfrom skimage.morphology import convex_hull_image, erosion\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\nZeroPadding2D, Convolution2D, ZeroPadding2D, Conv2DTranspose,ReLU, UpSampling2D, Concatenate, Conv2DTranspose\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras import backend\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","ee5b77c4":"Fossil_Data_Path = Path(\"..\/input\/fossil-segmentation-image-set-microfossil\/Fossil_Segmentation\/Fossil_Image\")\nGTs_1_Path = Path(\"..\/input\/fossil-segmentation-image-set-microfossil\/Fossil_Segmentation\/GTs 1\/GTs\")\nGTs_2_Path = Path(\"..\/input\/fossil-segmentation-image-set-microfossil\/Fossil_Segmentation\/GTs 2\/GTs\")\nGTs_3_Path = Path(\"..\/input\/fossil-segmentation-image-set-microfossil\/Fossil_Segmentation\/GTs 3\/GTs\")","328453b4":"Fossil_Tiff_Path = list(Fossil_Data_Path.glob(r\"*.tiff\"))","f81e7ee1":"GTs_1_Tiff_Path = list(GTs_1_Path.glob(r\"*.tiff\"))","98af5ba4":"GTs_2_Tiff_Path = list(GTs_2_Path.glob(r\"*.tiff\"))","ede24446":"GTs_3_Tiff_Path = list(GTs_3_Path.glob(r\"*.tiff\"))","4c882fc5":"Fossil_Series = pd.Series(Fossil_Tiff_Path,name=\"FOSSIL\").astype(str)\nGTs1_Series = pd.Series(GTs_1_Tiff_Path,name=\"GTs1\").astype(str)\nGTs2_Series = pd.Series(GTs_2_Tiff_Path,name=\"GTs2\").astype(str)\nGTs3_Series = pd.Series(GTs_3_Tiff_Path,name=\"GTs3\").astype(str)","d31f07cf":"print(Fossil_Series.head(-1))","62f7ef51":"print(GTs1_Series.head(-1))","fc71e1a0":"print(GTs2_Series.head(-1))","dce18a59":"print(GTs3_Series.head(-1))","434f162f":"Main_Fossil_Data = pd.concat([Fossil_Series,\n                             GTs1_Series,\n                             GTs2_Series,\n                             GTs3_Series],axis=1)","fbd74cea":"print(Main_Fossil_Data.head(-1))","137cfe0b":"print(Main_Fossil_Data.columns)","d690731a":"print(Main_Fossil_Data.isnull().sum())","610cfa92":"def reading_tiff(image):\n    \n    Reading_Image = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    \n    return Reading_Image","4b7ee983":"def single_display_tiff(image):\n    \n    figure = plt.figure(figsize=(8,8))\n    Reading_Image = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    \n    plt.xlabel(Reading_Image.shape)\n    plt.ylabel(Reading_Image.size)\n    plt.title(\"TIFF\")\n    plt.imshow(Reading_Image)","ddf47605":"def multi_display_tiff(image_one,mask_one,mask_two,mask_three):\n    \n    figure,axis = plt.subplots(1,4,figsize=(10,12))\n    \n    Reading_Image = cv2.cvtColor(cv2.imread(image_one),cv2.COLOR_BGR2RGB)\n    Reading_Mask_One = cv2.cvtColor(cv2.imread(mask_one),cv2.COLOR_BGR2RGB)\n    Reading_Mask_Two = cv2.cvtColor(cv2.imread(mask_two),cv2.COLOR_BGR2RGB)\n    Reading_Mask_Three = cv2.cvtColor(cv2.imread(mask_three),cv2.COLOR_BGR2RGB)\n    \n    axis[0].imshow(Reading_Image)\n    axis[0].set_xlabel(Reading_Image.shape)\n    axis[0].set_ylabel(Reading_Image.size)\n    axis[0].set_title(\"ORIGINAL_TIFF\")\n    axis[1].imshow(Reading_Mask_One)\n    axis[1].set_xlabel(Reading_Mask_One.shape)\n    axis[1].set_ylabel(Reading_Mask_One.size)\n    axis[1].set_title(\"MASK_ONE\")\n    axis[2].imshow(Reading_Mask_Two)\n    axis[2].set_xlabel(Reading_Mask_Two.shape)\n    axis[2].set_ylabel(Reading_Mask_Two.size)\n    axis[2].set_title(\"MASK_TWO\")\n    axis[3].imshow(Reading_Mask_Three)\n    axis[3].set_xlabel(Reading_Mask_Three.shape)\n    axis[3].set_ylabel(Reading_Mask_Three.size)\n    axis[3].set_title(\"MASK_THREE\")","8384d09a":"def different_type_display(image,image_one,image_two,image_three):\n    \n    figure,axis = plt.subplots(1,4,figsize=(10,12))\n    \n    axis[0].imshow(image)\n    axis[0].set_xlabel(image.shape)\n    axis[0].set_ylabel(image.size)\n    axis[0].set_title(\"image\")\n    axis[1].imshow(image_one)\n    axis[1].set_xlabel(image_one.shape)\n    axis[1].set_ylabel(image_one.size)\n    axis[1].set_title(\"image_one\")\n    axis[2].imshow(image_two)\n    axis[2].set_xlabel(image_two.shape)\n    axis[2].set_ylabel(image_two.size)\n    axis[2].set_title(\"image_two\")\n    axis[3].imshow(image_three)\n    axis[3].set_xlabel(image_three.shape)\n    axis[3].set_ylabel(image_three.size)\n    axis[3].set_title(\"image_three\")","aa4ce0cd":"def threshold_display(image):\n    \n    figure = plt.figure(figsize=(8,8))\n    Reading_Image = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    _,Threshold_Image = cv2.threshold(Reading_Image,30,255,cv2.THRESH_BINARY)\n    \n    plt.xlabel(Threshold_Image.shape)\n    plt.ylabel(Threshold_Image.size)\n    plt.title(\"THRESHOLD\")\n    plt.imshow(Threshold_Image)","8ebe3324":"def threshold_reading(image):\n    \n    Reading_Image = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    _,Threshold_Image = cv2.threshold(Reading_Image,30,255,cv2.THRESH_BINARY)\n    \n    return Threshold_Image","5100f205":"def adaptive_threshold_display(image):\n    \n    figure = plt.figure(figsize=(8,8))\n    Reading_Image = cv2.imread(image,0)\n    Adaptive_Image = cv2.adaptiveThreshold(Reading_Image,20,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,9,2)\n    \n    plt.xlabel(Adaptive_Image.shape)\n    plt.ylabel(Adaptive_Image.size)\n    plt.title(\"ADAPTIVE_THRESHOLD\")\n    plt.imshow(Adaptive_Image)","e2419732":"def adaptive_threshold_reading(image):\n    \n    Reading_Image = cv2.imread(image,0)\n    Adaptive_Image = cv2.adaptiveThreshold(Reading_Image,20,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,9,2)\n    \n    return Adaptive_Image","c92c831a":"def canny_reading(image):\n    \n    Reading_Image = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    Canny_Image = cv2.Canny(Reading_Image,5,100)\n    \n    return Canny_Image","68d1b629":"def bitwise_and_display(image):\n    \n    figure = plt.figure(figsize=(8,8))\n    Reading_Image = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    Reading_Image = cv2.resize(Reading_Image,(180,180))\n    _,Threshold_Image = cv2.threshold(Reading_Image,30,255,cv2.THRESH_BINARY)\n    Threshold_Image = cv2.resize(Threshold_Image,(180,180))\n    Mask_For_Image = cv2.inRange(Reading_Image,Reading_Image,Threshold_Image)\n    Bitwise_Image = cv2.bitwise_and(Reading_Image,Reading_Image,mask=Mask_For_Image)\n    \n    plt.xlabel(Bitwise_Image.shape)\n    plt.ylabel(Bitwise_Image.size)\n    plt.title(\"Bitwise_Image\")\n    plt.imshow(Bitwise_Image)","2c21bc84":"plt.style.use(\"dark_background\")","af9b17a7":"single_display_tiff(Main_Fossil_Data[\"FOSSIL\"][3])","f2c96ab9":"single_display_tiff(Main_Fossil_Data[\"GTs1\"][3])","d56a7b04":"single_display_tiff(Main_Fossil_Data[\"GTs2\"][3])","f45b026a":"single_display_tiff(Main_Fossil_Data[\"GTs3\"][3])","b1dceaef":"multi_display_tiff(Main_Fossil_Data[\"FOSSIL\"][30],\n                  Main_Fossil_Data[\"GTs1\"][30],\n                  Main_Fossil_Data[\"GTs2\"][30],\n                  Main_Fossil_Data[\"GTs3\"][30])","9aa53724":"multi_display_tiff(Main_Fossil_Data[\"FOSSIL\"][432],\n                  Main_Fossil_Data[\"GTs1\"][432],\n                  Main_Fossil_Data[\"GTs2\"][432],\n                  Main_Fossil_Data[\"GTs3\"][432])","1baf50e4":"multi_display_tiff(Main_Fossil_Data[\"FOSSIL\"][1000],\n                  Main_Fossil_Data[\"GTs1\"][1000],\n                  Main_Fossil_Data[\"GTs2\"][1000],\n                  Main_Fossil_Data[\"GTs3\"][1000])","9d4faf8e":"threshold_display(Main_Fossil_Data[\"FOSSIL\"][1000])","3d45b284":"threshold_display(Main_Fossil_Data[\"FOSSIL\"][342])","70d7bbbc":"threshold_display(Main_Fossil_Data[\"FOSSIL\"][42])","84ec3aec":"adaptive_threshold_display(Main_Fossil_Data[\"FOSSIL\"][12])","076fee4e":"adaptive_threshold_display(Main_Fossil_Data[\"FOSSIL\"][123])","866540ef":"adaptive_threshold_display(Main_Fossil_Data[\"GTs1\"][123])","2c62a183":"adaptive_threshold_display(Main_Fossil_Data[\"GTs2\"][123])","386eee13":"adaptive_threshold_display(Main_Fossil_Data[\"GTs3\"][123])","2269d02e":"figure,axis = plt.subplots(1,4,figsize=(10,12))\n\nCanny_Image = canny_reading(Main_Fossil_Data[\"FOSSIL\"][1])\nCanny_GTs1 = canny_reading(Main_Fossil_Data[\"GTs1\"][1])\nCanny_GTs2 = canny_reading(Main_Fossil_Data[\"GTs2\"][1])\nCanny_GTs3 = canny_reading(Main_Fossil_Data[\"GTs3\"][1])\n    \naxis[0].imshow(Canny_Image)\naxis[0].set_xlabel(Canny_Image.shape)\naxis[0].set_ylabel(Canny_Image.size)\naxis[0].set_title(\"Canny_Image\")\naxis[1].imshow(Canny_GTs1)\naxis[1].set_xlabel(Canny_GTs1.shape)\naxis[1].set_ylabel(Canny_GTs1.size)\naxis[1].set_title(\"Canny_GTs1\")\naxis[2].imshow(Canny_GTs2)\naxis[2].set_xlabel(Canny_GTs2.shape)\naxis[2].set_ylabel(Canny_GTs2.size)\naxis[2].set_title(\"Canny_GTs2\")\naxis[3].imshow(Canny_GTs3)\naxis[3].set_xlabel(Canny_GTs3.shape)\naxis[3].set_ylabel(Canny_GTs3.size)\naxis[3].set_title(\"Canny_GTs3\")","6885090b":"figure = plt.figure(figsize=(8,8))\n\nCanny_Image = canny_reading(Main_Fossil_Data[\"FOSSIL\"][1])\n\nplt.imshow(Canny_Image)\nplt.axis(\"off\")","664007f1":"figure = plt.figure(figsize=(8,8))\n\nCanny_Image = canny_reading(Main_Fossil_Data[\"GTs1\"][1])\n\nplt.imshow(Canny_Image)\nplt.axis(\"off\")","fc68b1c4":"figure = plt.figure(figsize=(8,8))\n\nCanny_Image = canny_reading(Main_Fossil_Data[\"GTs2\"][1])\n\nplt.imshow(Canny_Image)\nplt.axis(\"off\")","a5d740d0":"figure = plt.figure(figsize=(8,8))\n\nCanny_Image = canny_reading(Main_Fossil_Data[\"GTs3\"][1])\n\nplt.imshow(Canny_Image)\nplt.axis(\"off\")","19f83679":"different_type_display(reading_tiff(Main_Fossil_Data[\"FOSSIL\"][555]),\n                      threshold_reading(Main_Fossil_Data[\"GTs1\"][555]),\n                      adaptive_threshold_reading(Main_Fossil_Data[\"GTs2\"][555]),\n                      canny_reading(Main_Fossil_Data[\"GTs3\"][555]))","a6381d3a":"bitwise_and_display(Main_Fossil_Data[\"FOSSIL\"][5])","25d1feeb":"bitwise_and_display(Main_Fossil_Data[\"FOSSIL\"][55])","06277567":"bitwise_and_display(Main_Fossil_Data[\"FOSSIL\"][555])","e5d2e036":"Normal_Image = reading_tiff(Main_Fossil_Data[\"FOSSIL\"][238])\nGTs1_Image = reading_tiff(Main_Fossil_Data[\"GTs1\"][238])\nGTs2_Image = reading_tiff(Main_Fossil_Data[\"GTs2\"][238])\nGTs3_Image = reading_tiff(Main_Fossil_Data[\"GTs3\"][238])","7c54ed31":"figure,axis = plt.subplots(1,3,figsize=(12,12))\n\nBlend_Image = cv2.addWeighted(Normal_Image,0.8,GTs1_Image,0.4,0.5)\n\naxis[0].imshow(Normal_Image)\naxis[1].imshow(GTs1_Image)\naxis[2].imshow(Blend_Image)","044553f0":"figure,axis = plt.subplots(1,3,figsize=(12,12))\n\nBlend_Image = cv2.addWeighted(Normal_Image,0.8,GTs2_Image,0.4,0.5)\n\naxis[0].imshow(Normal_Image)\naxis[1].imshow(GTs2_Image)\naxis[2].imshow(Blend_Image)","203b83ab":"figure,axis = plt.subplots(1,3,figsize=(12,12))\n\nBlend_Image = cv2.addWeighted(Normal_Image,0.8,GTs3_Image,0.4,0.5)\n\naxis[0].imshow(Normal_Image)\naxis[1].imshow(GTs3_Image)\naxis[2].imshow(Blend_Image)","c84f3d3c":"figure,axis = plt.subplots(1,3,figsize=(12,12))\n\nBlend_Image_One = cv2.addWeighted(Normal_Image,0.8,GTs1_Image,0.4,0.5)\nBlend_Image_Two = cv2.addWeighted(Normal_Image,0.8,GTs2_Image,0.4,0.5)\nBlend_Image_Three = cv2.addWeighted(Normal_Image,0.8,GTs3_Image,0.4,0.5)\n\naxis[0].imshow(Blend_Image_One[:,:,0])\naxis[1].imshow(Blend_Image_Two[:,:,0])\naxis[2].imshow(Blend_Image_Three[:,:,0])","9c1df091":"Image_List = []\nMask_List = []\n\nfor fossil_i,mask_i in zip(Main_Fossil_Data.FOSSIL,Main_Fossil_Data.GTs3):\n    \n    Reading_Fossil = reading_tiff(fossil_i)\n    Reading_Fossil = cv2.resize(Reading_Fossil,(180,180))\n    \n    Reading_Mask = reading_tiff(mask_i)\n    Reading_Mask = cv2.resize(Reading_Mask,(180,180))\n    \n    Blend_Image = cv2.addWeighted(Reading_Fossil,0.8,Reading_Mask,0.4,0.5)\n    \n    Image_List.append(Reading_Fossil)\n    Mask_List.append(Blend_Image[:,:,0])","130dedc5":"print(\"FOSSIL IMG SHAPE: \",Image_List[0].shape)\nprint(\"MASK IMG SHAPE: \",Mask_List[0].shape)","5d56cad1":"print(\"FOSSIL IMG TYPE: \",Image_List[0].dtype)\nprint(\"MASK IMG TYPE: \",Mask_List[0].dtype)","dbf90784":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].imshow(Image_List[25])\naxis[1].imshow(Mask_List[25])","214f5c6d":"Image_Array = np.array(Image_List)\nMask_Array = np.array(Mask_List)","6fb75e60":"Image_Array = Image_Array.astype(\"float32\") \/ 255.\nMask_Array = Mask_Array.astype(\"float32\") \/ 255.","1ad46f0b":"print(\"FOSSIL SHAPE: \",Image_Array.shape)\nprint(\"MASK SHAPE: \",Mask_Array.shape)","318e3523":"Example_For_Non_Seen = Image_Array[1000:-2]","2ec70645":"print(\"EXAMPLE SHAPE: \",Example_For_Non_Seen.shape)","b93e1c20":"Image_Array = Image_Array[0:1000]\nMask_Array = Mask_Array[0:1000]","38ea58bc":"print(\"FOSSIL SHAPE: \",Image_Array.shape)\nprint(\"MASK SHAPE: \",Mask_Array.shape)","7bb095f7":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].imshow(Image_Array[0])\naxis[1].imshow(Mask_Array[0])","38fd87f6":"Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\nCheckpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")\nReduce_Model = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n                                                   factor=0.1,\n                                                   patience=5) # if you want","2c4c3f68":"compile_loss = \"binary_crossentropy\"\ncompile_optimizer = Adam(lr=0.0001)\ncompile_metrics = [\"accuracy\"] # if you want\ninput_dim = (Image_Array.shape[1],Image_Array.shape[2],Image_Array.shape[3]) # if you want\noutput_class = 1","5a067710":"Encoder_G = Sequential()\nEncoder_G.add(Conv2D(32,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_G.add(BatchNormalization())\nEncoder_G.add(ReLU())\n#\nEncoder_G.add(Conv2D(64,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_G.add(BatchNormalization())\nEncoder_G.add(ReLU())\n#\nEncoder_G.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_G.add(BatchNormalization())\nEncoder_G.add(ReLU())\n\nEncoder_G.add(Conv2D(256,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_G.add(BatchNormalization())\nEncoder_G.add(ReLU())","202e6890":"Decoder_G = Sequential()\nDecoder_G.add(Conv2DTranspose(128,(2,2),padding = \"same\",use_bias = True))\nDecoder_G.add(ReLU())\n#\nDecoder_G.add(Conv2DTranspose(64,(2,2),padding = \"same\",use_bias = True))\nDecoder_G.add(ReLU())\n#\nDecoder_G.add(Conv2DTranspose(32,(2,2),padding = \"same\",use_bias = True))\nDecoder_G.add(ReLU())\n#\nDecoder_G.add(Conv2DTranspose(1,(2,2),padding = \"same\",use_bias = True))\nDecoder_G.add(ReLU())","aba4de2c":"Auto_Encoder = Sequential([Encoder_G,Decoder_G])","9e0e892a":"Auto_Encoder.compile(loss=compile_loss,optimizer=compile_optimizer) # add metrics if you want","7e06bc0e":"Model_AE = Auto_Encoder.fit(Image_Array,Mask_Array,epochs=50,callbacks=[Early_Stopper,\n                                                                       Checkpoint_Model])","3f0f083d":"Prediction_IMG = Auto_Encoder.predict(Image_Array[:10])","cdc61685":"print(Prediction_IMG[1].shape)","d896533a":"plt.imshow(Prediction_IMG[9])","92f29af9":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 9\n\nOriginal_Img = Image_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"FOSSIL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","1d0ce2a3":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 2\n\nOriginal_Img = Image_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"FOSSIL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","3857efb6":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 4\n\nOriginal_Img = Image_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"FOSSIL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","239f4999":"figure,axis = plt.subplots(2,5,figsize=(10,10))\n\nfor indexing,operations in enumerate(axis.flat):\n    Predict_Mask = Prediction_IMG[indexing]\n    \n    operations.set_ylabel(Predict_Mask.shape)\n    operations.set_xlabel(round(np.mean(Predict_Mask)))\n    operations.imshow(Predict_Mask)\n    \nplt.tight_layout()\nplt.show()","248316d2":"Non_Seen_Prediction = Auto_Encoder.predict(Example_For_Non_Seen)","d1a6641b":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 1\n\nOriginal_Img = Example_For_Non_Seen[prediction_img_number]\nPredict_Mask = Non_Seen_Prediction[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"FOSSIL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","6bc1c6fe":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 0\n\nOriginal_Img = Example_For_Non_Seen[prediction_img_number]\nPredict_Mask = Non_Seen_Prediction[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"FOSSIL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","e266ddc4":"#### SIMPLE VISION","58dffc15":"# VISION PROCESS AND CONTROL","5c35f790":"#### TRAIN","500e1b9e":"#### TO ARRAY","722828ca":"#### PARAMETERS","24f92430":"# AE MODEL PROCESS","7c14912f":"#### TO SERIES","beed172f":"#### FUNCTION","1e0f8c4d":"# PATH,LABEL,TRANSFORMATION PROCESS","8a7537bb":"#### TIFF PATH","86f2da96":"![](https:\/\/i2.wp.com\/sefiks.com\/wp-content\/uploads\/2018\/03\/convolutional-autoencoder.png?fit=1818%2C608&ssl=1)","d80189a6":"![](https:\/\/www.researchgate.net\/profile\/Chris-Dunmore\/publication\/323368329\/figure\/fig1\/AS:597247645450243@1519406343453\/Cross-section-XY-plane-through-the-fossil-at-various-stages-of-segmentation-using-RCA.png)","7ddaded2":"# PACKAGES AND LIBRARIES","7d5c2a7f":"#### AE","051ba291":"#### DECODER STRUCTURE","62d9d955":"#### ADAPTIVE THRESHOLD","67fb7e8a":"#### TO DATAFRAME","b4f7c265":"#### TRANSFORMATION","eeeaf0cf":"# HISTORY\n\n\n#### Fossil Segmentation Image Set \/ Microfossil\n\n* The computational analysis applicability of paleontological images ranges from the study of animals, plants and microorganisms evolution to the simulations of the habitat that such specimens lived. It also can be applied in several niches, such as oil exploration, where there are several factors to be analyzed in order to reduce the expenses related to the oil extraction process. One factor is the environment to be explored characterization, which can occur in several ways: use of probes, extraction of samples for petrophysical components evaluation, the correlation with logs of other drilling wells and so on. In the samples extraction part the Computed Tomography (CT) is of importance because it preserves the sample and makes it available for several analyzes. Based on the CT generated images, several analyzes and simulations performed and processes, performed manually and exhaustively, automated.\n\n* A paleontologist receives a rock sample with microfossils for analysis. The time needed for the complete process of microfossils isolation, performed manually, is high and after this process the rock sample is destroyed. After this, the paleontologist will analyse the microfossil physical isolation result and classify manually each isolated microfossil based on specific features. Lastly, a report will be generated with the microfossils found into the rock sample analyzed.\n\n* The samples employed in the dataset were obtained from specialists in paleontology and, to digitalize those samples, the following micro-CT was used: Versa XRM-500, best resolution with 0.7 mu, voltage 30-160 kV, potency 2-10 W, CCD cameras 2048\u00d72048 pixel, lenses 0.4X, 4X, 10X, 20X and 40X, maximum mass capacity 15 kg and sample size limit (diameter \/ height) 80\/300 mm. The samples acquisition parameters employed were: Resolution 1.08 mm (image pixel size), image size 956x1004x983, no filtering for beam correction hardening, 10x optical lens, 30 kV \/ 2W, angular pitch 0.255\\degree and exposure time 11 seconds.\n\n* Files are formatted as a tiff.","62492803":"#### MAIN PATH","c773b59b":"#### THRESHOLD DISPLAY","bb9cb505":"# DATA PROCESS","0f0d4d8a":"#### ENCODER STRUCTURE","082209ec":"#### PREDICTION","c606bb42":"##### CANNY","c1bd61bd":"#### ADWEIGHTED","ba4c1f5c":"#### CALLBACK","8aa159d6":"#### BITWISE","6d8e33f2":"#### CHECKING","cd8fd040":"#### MULTI DISPLAY","41f110da":"#### MULTI DIFFERENT DISPLAY","13895bcf":"#### SPECIAL PREDICTION"}}