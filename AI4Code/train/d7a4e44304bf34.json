{"cell_type":{"8edfbdb6":"code","b4497779":"code","aa8a04c5":"code","9f02b9a4":"code","4e5730da":"code","e2accdd0":"code","94aa1843":"code","257ff507":"code","6eea85c2":"code","49caea74":"markdown","4c5c3a9d":"markdown","254135ed":"markdown","694ffd24":"markdown","aaed02da":"markdown","074e342f":"markdown","9c965bf0":"markdown"},"source":{"8edfbdb6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom scipy.misc import imread, imsave\nimport cv2\nimport matplotlib.pyplot as plt\nfrom scipy.misc import imread, imsave\n\n# Any results you write to the current directory are saved as output.","b4497779":"path_data = '..\/input\/train.csv'\ndata = pd.read_csv(path_data)","aa8a04c5":"data.head(10)","9f02b9a4":"# Take example\ndata_example = data.loc[0].values\n\nimg_dir = data_example[0]\nlabel = data_example[1]\n\n# Read image\npath_join = os.path.join('..\/input\/train', img_dir)\nimage = imread(path_join)\n\n# Plot image\nimgplot = plt.imshow(image)\nplt.title(label)","4e5730da":"path_join = os.path.join('..\/input\/train', '2b96cac5a.jpg')\nimage = imread(path_join)\n\nbacktorgb = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\nplt.imshow(backtorgb)","e2accdd0":"def clean_image(image):\n\n    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n\n    kernel_size = 5\n    blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n\n    low_threshold = 20\n    high_threshold = 50\n    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n\n    rho = 3  # distance resolution in pixels of the Hough grid\n    theta = np.pi \/ 180  # angular resolution in radians of the Hough grid\n    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n    min_line_length = 50  # minimum number of pixels making up a line\n    max_line_gap = 20  # maximum gap in pixels between connectable line segments\n    line_image = np.copy(image) * 0  # creating a blank to draw lines on\n\n    # Run Hough on edge detected image\n    # Output \"lines\" is an array containing endpoints of detected line segments\n    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n                        min_line_length, max_line_gap)\n    y_1 = []\n    for line in lines:\n        for x1,y1,x2,y2 in line:\n            slope  = (y2 - y1) \/ (x2 - x1)\n            if slope < 0.06 and slope > -0.06:\n                region = gray.shape[0] - (gray.shape[0] * 0.30)\n                if y1 > region:\n                    y_1.append(y1)    \n            else:\n                continue\n    return y_1","94aa1843":"\ndata_images = data['Image'].values\ndata_labels = data['Id'].values\n\nimages_preprocess = []\nlabels_preprocess = []\n\n##############################################################\n# NOTE: DELETE data_images[:10] to preprocess all images. \n##############################################################\nprint('DELETE -> [:10] \/\/ in data_images[:10] to preprocess all images')\n\ni = 0\nfor items in data_images[:10]:\n    path_join = os.path.join('..\/input\/train', items)\n    image = cv2.imread(path_join)\n    image_original = image\n\n    if len(image.shape) < 3:\n        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n\n    # Crop the image and check if has white pixels\n    bottom_percent = 0.25\n    bottom = image.shape[0] - int(np.ceil(image.shape[0] * bottom_percent))\n    img = image[bottom:image.shape[0], :]\n\n    n_white_pix = np.sum(img >= 250)\n\n    if n_white_pix >= 90000:\n        y1 = clean_image(image)\n\n        # Crop image\n        if y1:\n            min_y1 = min(y1)\n            image_original = image_original[0:min_y1, 0:image_original.shape[1]]\n            images_preprocess.append(image_original)\n            labels_preprocess.append(data_labels[i])\n    else:\n        images_preprocess.append(image_original)\n        labels_preprocess.append(data_labels[i])\n\n    i += 1\n    \nimages_preprocess = np.array(images_preprocess)\nlabels_preprocess = np.array(labels_preprocess)","257ff507":"print(images_preprocess.shape)\nprint(labels_preprocess.shape)","6eea85c2":"path_join = os.path.join('..\/input\/train', '2b96cac5a.jpg')\n# image = imread(path_join)\nimage = cv2.imread(path_join)\nimage_original = image\nplt.imshow(image)\nplt.title('BEFORE PREPROCESS')\nplt.show()\n\nif len(image.shape) < 3:\n    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n\n# Crop the image and check if has white pixels\nbottom_percent = 0.25\nbottom = image.shape[0] - int(np.ceil(image.shape[0] * bottom_percent))\nimg = image[bottom:image.shape[0], :]\n\nn_white_pix = np.sum(img >= 250)\n\nif n_white_pix >= 90000:\n    y1 = clean_image(image)\n\n    # Crop image\n    if y1:\n        min_y1 = min(y1)\n        image_original = image_original[0:min_y1, 0:image_original.shape[1]]\nelse:\n    pass\n\nplt.imshow(image_original)\nplt.title('AFTER PREPROCESS')\nplt.show()","49caea74":"#### Show Example","4c5c3a9d":"## Function to Clean Text Automatically\n\nTake the images and convert it to gray scale and we measure the number of white pixels (between 245 - 255) in the bottom of the image. Then we convert the image to blur scale and calculate the lines, if the slope of the lines is between -0.06 and 0.06 we return the values. Finally, we delete that part of the images.","254135ed":"## Read Data","694ffd24":"### Example with image","aaed02da":"We can observe that there are some images with text. We have built a function to clean automatically the text, it works at 85\/90 %, this is the first approach. I'm going to improve it. Below, an example:","074e342f":"Works in the most cases but in some images doesn't work correctly, I'm going to try to improve it. I hope this is helpful for you!!","9c965bf0":"These are the lines to apply this function for every image, take time to preprocess all images and return 2 arrays (`images_preprocess` and `labels_preprocess`). "}}