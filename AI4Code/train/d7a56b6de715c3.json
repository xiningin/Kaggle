{"cell_type":{"8334869e":"code","b6b1c127":"code","c52ec1d6":"code","5eba042d":"code","f524d8a6":"code","fb60645a":"code","3c83fa44":"code","790063fd":"code","86fc7f17":"code","1cc1513f":"code","4305fd6f":"code","c7d61a5b":"code","a7196806":"code","10bba263":"code","1999079b":"code","428e8e02":"code","a1e82379":"code","91157796":"code","1ebc458a":"code","0e2f1bef":"code","8e61bc3b":"code","2964730c":"code","f941f644":"code","171adf55":"code","a43089e9":"code","772ae356":"code","c4acd23c":"code","35c8305a":"code","033c1d30":"code","04b3a7d7":"code","8f9f39fc":"code","eee86ef2":"code","c22739fb":"code","eef99711":"code","df0464fe":"code","ef9b21e9":"code","8c77458c":"code","6ca81fb8":"code","05723480":"code","2a7b53a0":"code","a2559be4":"code","242d56dc":"code","3ec3e5c2":"code","5ac28a45":"code","cc081ed4":"code","d7c1a627":"code","a25b0fb5":"code","05ec7b7a":"code","713137d6":"code","206682ee":"code","89a1e7ef":"code","a76d8deb":"code","e0f7a65b":"code","e1bea59f":"code","19652563":"code","b9361a98":"code","c4a679e9":"code","282361e7":"code","201a6d65":"code","05301fec":"code","8ffb00e0":"code","de9daac6":"code","b5c531cf":"code","4a584949":"code","17e900d3":"code","a445453a":"code","35f6385f":"code","c9bf6639":"code","c75039ea":"code","a85968ad":"code","abba3595":"code","1a34688f":"code","c5053553":"code","5e6ef882":"code","df48eced":"code","0db56e4a":"code","212295ba":"code","c8696a7f":"code","98b9d9ea":"code","4d12d9d7":"code","fa12e6e2":"code","c2e99c37":"code","8bbf83e3":"code","702fea6b":"code","46ba21d5":"code","5a5e0ecc":"code","85c26356":"code","f6ee68a6":"code","80c04a2d":"code","cfff3a17":"code","56a8d756":"code","1c8ad089":"code","a0d3b425":"code","60adb8b7":"code","dba9a62e":"code","f73979f1":"code","ba3dd91f":"code","76a4d23b":"code","dd8b2193":"code","66d02db0":"code","5c07d517":"markdown","b4af1a14":"markdown","a95ba5b8":"markdown","5ee98817":"markdown","c8934263":"markdown","a5fb0e2f":"markdown","5feb1945":"markdown","ea695bb7":"markdown","641b28cf":"markdown","55a34785":"markdown","3972668b":"markdown","6d99de94":"markdown","912f455b":"markdown","971c75f0":"markdown","681e04aa":"markdown","9cd673ba":"markdown","2e2b8669":"markdown","f7da0c22":"markdown","80b46384":"markdown","f9af34ba":"markdown","52338eb7":"markdown","875cf179":"markdown","a5b49364":"markdown","496e6ac6":"markdown","c3d83ebd":"markdown","9b76b0a3":"markdown","d05337ce":"markdown","34237201":"markdown","430354d0":"markdown","2c665fef":"markdown","587aa923":"markdown","483fdce5":"markdown","edb8fd7c":"markdown","c9966efe":"markdown","17db453f":"markdown","7efa7344":"markdown","9cc16f74":"markdown","ba2b942e":"markdown","a66a2d47":"markdown","800d7d95":"markdown","2fec1a73":"markdown","8e4acb3e":"markdown","eed42d94":"markdown","251bfa28":"markdown","d7b6c915":"markdown","289f48db":"markdown","6646f82a":"markdown","44d3de2d":"markdown","917e3f13":"markdown","bbc47798":"markdown","08b67358":"markdown","07f876aa":"markdown","34228a95":"markdown","5fc7a204":"markdown"},"source":{"8334869e":"#Import the required Libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import date, timedelta\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.width', 5000)\n","b6b1c127":"\n#Read the data in a dataframe\ninp1= pd.read_csv(r\"..\/input\/loan-defaulter\/previous_application.csv\")\ninp2= pd.read_csv(r\"..\/input\/loan-defaulter\/application_data.csv\")\ncols_data= pd.read_csv(r\"..\/input\/loan-defaulter\/columns_description.csv\",encoding= 'unicode_escape')","c52ec1d6":"cols_data.head()","5eba042d":"cols_data.rename(columns = {'\u00ef\u00bb\u00bf':'Serial No'}, inplace = True) \ncols_data.set_index('Serial No')\n","f524d8a6":"# To know the Shape of the Dataset we are going to explore\ninp2.shape","fb60645a":"#Lets, now see the columns we have and their dataypes and stats \ninp2.info()","3c83fa44":"#View sample data to see how the data set look like \ninp2.head(10)","790063fd":"inp2.describe()","86fc7f17":"# Cleaning the data \n# Exlpore for null values \nnullcolumns=inp2.isnull().sum()\nnullcolumns","1cc1513f":"# To find the percentage of null values in the above columns we have the null counts displayed \n##To find the columns having more than 50% null values \nnullcolumns=inp2.isnull().sum()\nnullcolumns=nullcolumns[nullcolumns.values>(0.5*len(nullcolumns))]\nnullcolumns","4305fd6f":"#Drop the Null values \n\nnullcolumns = list(nullcolumns[nullcolumns.values>=0.3].index)\ninp2.drop(labels=nullcolumns,axis=1,inplace=True)\nprint(len(nullcolumns))","c7d61a5b":"#Check for percantage of null values again to ensure we have no NaN's in data set \n\nprint((100*(inp2.isnull().sum()\/len(inp2))))","a7196806":"#Box Plot check for Outliers \nsns.boxplot(inp2.AMT_ANNUITY)\nplt.show()\nplt.savefig('sample.jpg')","10bba263":"#Plot to see outliers in AMT_CREDIT \nsns.distplot(inp2.AMT_CREDIT)\nplt.show()","1999079b":"#Plot to see outliers in AMT_INCOME_TOTAL \nplt.figure(figsize=[8,2])\nsns.boxplot(inp2.AMT_INCOME_TOTAL)\nplt.show()\n\n# make boxplot with Seaborn\nbplot=sns.boxplot(inp2.AMT_INCOME_TOTAL, \n                 width=0.5,\n                 palette=\"colorblind\")\n \n# add stripplot to boxplot with Seaborn\nbplot=sns.stripplot(inp2.AMT_INCOME_TOTAL,  \n                   jitter=True, \n                   marker='o', \n                   alpha=0.5,\n                   color='black')\n","428e8e02":"#To find the median for the fiel AMT_ANNUITY\nvalues=inp2['AMT_ANNUITY'].median()\n\nvalues","a1e82379":"# Fill the above value 24903 for all the missing values in AMT_ANNUITY\ninp2.loc[inp2['AMT_ANNUITY'].isnull(),'AMT_ANNUITY']=values","91157796":"#Check for percantage of null values again to ensure we have no NaN's in data set \n\nprint((100*(inp2.isnull().sum()\/len(inp2))))","1ebc458a":"\n# Removing rows having null values greater than or equal to 50%\n\nnullrows=inp2.isnull().sum(axis=1)\nnullrows=list(nullrows[nullrows.values>=0.5*len(inp2)].index)\ninp2.drop(labels=nullrows,axis=0,inplace=True)\nprint(len(nullrows))","0e2f1bef":"#To Check the dataype of all the columns \ninp2.head(10)","8e61bc3b":"# We will remove unwanted columns from this dataset\n\nunwanted=['FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE',\n       'FLAG_PHONE', 'FLAG_EMAIL','REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY','FLAG_EMAIL','CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT',\n       'REGION_RATING_CLIENT_W_CITY','DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3','FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9','FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15','FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']\n\ninp2.drop(labels=unwanted,axis=1,inplace=True)","2964730c":"inp2.info()","f941f644":"#view Sample data frame \ninp2.head(10)","171adf55":"#To handle -ve values in the DAYS columns in the inp2 Dataframe\ninp2 = inp2.apply(lambda x: x*-1 if x.name in ['DAYS_BIRTH', 'DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH'] else x)\ninp2.head(10)","a43089e9":"inpsample=inp2.head(10)","772ae356":"#inp2.drop([Current_Date],axis=1,inplace=True)\n#inp2['date_only'] = inp2['Current_date'].dt.date\n#inp2.head(10)\n#inp2.drop(['Current_Date'], axis = 1,inplace=True) ","c4acd23c":"#Add CurrentDate value to Data frame inp2\ninp2['Current_date'] = pd.to_datetime('today',utc=False)\ninp2['Current_date'] = inp2['Current_date'].dt.date","35c8305a":"inp2.head()","033c1d30":"#Categorical columns having these 'XNA' values\n    \n#CODE_GENDER \ninp2[inp2['CODE_GENDER']=='XNA'].shape","04b3a7d7":"# Organization column\n\ninp2[inp2['ORGANIZATION_TYPE']=='XNA'].shape","8f9f39fc":"# Describing the Gender column to check the number of females and males\n\ninp2['CODE_GENDER'].value_counts()","eee86ef2":"# Updating the column 'CODE_GENDER' with \"F\" for the dataset\n\ninp2.loc[inp2['CODE_GENDER']=='XNA','CODE_GENDER']='F'\ninp2['CODE_GENDER'].value_counts()","c22739fb":"# Describing the organization type column\n\ninp2['ORGANIZATION_TYPE'].describe()","eef99711":"# Hence, dropping the rows of total 55374 have 'XNA' values in the organization type column\n\ninp2=inp2.drop(inp2.loc[inp2['ORGANIZATION_TYPE']=='XNA'].index)\ninp2[inp2['ORGANIZATION_TYPE']=='XNA'].shape","df0464fe":"\n# Casting all variable into numeric in the dataset\n\nnumeric_columns=['TARGET','CNT_CHILDREN','AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','REGION_POPULATION_RELATIVE','DAYS_BIRTH',\n                'DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH','HOUR_APPR_PROCESS_START','LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n       'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY']\n\ninp2[numeric_columns]=inp2[numeric_columns].apply(pd.to_numeric)\n\ninp2.head()","ef9b21e9":"inp2.info()","8c77458c":"#These Bins are created to explore insights by cutting the amounts into specific class intervals \n#Creating bins for income amount\n\nbins = [0,25000,50000,75000,100000,125000,150000,175000,200000,225000,250000,275000,300000,325000,350000,375000,400000,425000,450000,475000,500000,10000000000]\nslot = ['0-25000', '25000-50000','50000-75000','75000,100000','100000-125000', '125000-150000', '150000-175000','175000-200000',\n       '200000-225000','225000-250000','250000-275000','275000-300000','300000-325000','325000-350000','350000-375000',\n       '375000-400000','400000-425000','425000-450000','450000-475000','475000-500000','500000 and above']\n\ninp2['AMT_INCOME_RANGE']=pd.cut(inp2['AMT_INCOME_TOTAL'],bins,labels=slot)","6ca81fb8":"# Creating bins for Credit amount\n\nbins = [0,150000,200000,250000,300000,350000,400000,450000,500000,550000,600000,650000,700000,750000,800000,850000,900000,1000000000]\nslots = ['0-150000', '150000-200000','200000-250000', '250000-300000', '300000-350000', '350000-400000','400000-450000',\n        '450000-500000','500000-550000','550000-600000','600000-650000','650000-700000','700000-750000','750000-800000',\n        '800000-850000','850000-900000','900000 and above']\n\ninp2['AMT_CREDIT_RANGE']=pd.cut(inp2['AMT_CREDIT'],bins=bins,labels=slots)","05723480":"# Dividing the dataset into two dataset of  target=1(client with payment difficulties) and target=0(all other)\n\ntarget0=inp2.loc[inp2[\"TARGET\"]==0]\ntarget1=inp2.loc[inp2[\"TARGET\"]==1]","2a7b53a0":"target0.head(10)","a2559be4":"target1.head(10)","242d56dc":"\n# Calculating Imbalance percentage\n    \n# Since the majority is target0 and minority is target1\n\nround(len(target0)\/len(target1),2)","3ec3e5c2":"# Count plotting in logarithmic scale\n\ndef uniplot(df,col,title,hue =None):\n    \n    sns.set_style('whitegrid')\n    sns.set_context('talk')\n    plt.rcParams[\"axes.labelsize\"] = 20\n    plt.rcParams['axes.titlesize'] = 22\n    plt.rcParams['axes.titlepad'] = 30\n    \n    \n    temp = pd.Series(data = hue)\n    fig, ax = plt.subplots()\n    width = len(df[col].unique()) + 7 + 4*len(temp.unique())\n    fig.set_size_inches(width , 8)\n    plt.xticks(rotation=45)\n    plt.yscale('log')\n    plt.title(title)\n    ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue,palette='magma') \n        \n    plt.show()","5ac28a45":"# PLotting for income range\n\nuniplot(target0,col='AMT_INCOME_RANGE',title='Distribution of income range',hue='CODE_GENDER')","cc081ed4":"# Plotting for Income type\n\nuniplot(target0,col='NAME_INCOME_TYPE',title='Distribution of Income type',hue='CODE_GENDER')","d7c1a627":"\n# Plotting for Contract type\n\nuniplot(target0,col='NAME_CONTRACT_TYPE',title='Distribution of contract type',hue='CODE_GENDER')","a25b0fb5":"\n# Plotting for Organization type in logarithmic scale\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\nplt.figure(figsize=(15,30))\nplt.rcParams[\"axes.labelsize\"] = 20\nplt.rcParams['axes.titlesize'] = 22\nplt.rcParams['axes.titlepad'] = 30\n\nplt.title(\"Distribution of Organization type for target - 0\")\n\nplt.xticks(rotation=90)\nplt.xscale('log')\n\nsns.countplot(data=target0,y='ORGANIZATION_TYPE',order=target0['ORGANIZATION_TYPE'].value_counts().index,palette='cool')\n\nplt.show()\n","05ec7b7a":"# PLotting for income range\n\nuniplot(target1,col='AMT_INCOME_RANGE',title='Distribution of income range',hue='CODE_GENDER')","713137d6":"# Plotting for Income type\n\nuniplot(target1,col='NAME_INCOME_TYPE',title='Distribution of Income type',hue='CODE_GENDER')\n","206682ee":"# Plotting for Contract type\n\nuniplot(target1,col='NAME_CONTRACT_TYPE',title='Distribution of contract type',hue='CODE_GENDER')","89a1e7ef":"# Plotting for Organization type\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\nplt.figure(figsize=(15,30))\nplt.rcParams[\"axes.labelsize\"] = 20\nplt.rcParams['axes.titlesize'] = 22\nplt.rcParams['axes.titlepad'] = 30\n\nplt.title(\"Distribution of Organization type for target - 1\")\n\nplt.xticks(rotation=90)\nplt.xscale('log')\n\nsns.countplot(data=target1,y='ORGANIZATION_TYPE',order=target1['ORGANIZATION_TYPE'].value_counts().index,palette='cool')\n\nplt.show()","a76d8deb":"# Finding some correlation for numerical columns for both target 0 and 1 \n\ntarget0_corr=target0.iloc[0:,2:]\ntarget1_corr=target1.iloc[0:,2:]\n\ntarget0cr=target0_corr.corr(method='spearman')\ntarget1cr=target1_corr.corr(method='spearman')\n","e0f7a65b":"# Correlation for target 0\n\ntarget0cr","e1bea59f":"# Correlation for target 1\n\ntarget1cr","19652563":"# Now, plotting the above correlation with heat map as it is the best choice to visulaize\n\n# figure size\n\ndef targets_corr(data,title):\n    plt.figure(figsize=(15, 10))\n    plt.rcParams['axes.titlesize'] = 25\n    plt.rcParams['axes.titlepad'] = 70\n\n# heatmap with a color map of choice\n\n\n    sns.heatmap(data, cmap=\"RdYlGn\",annot=False)\n\n    plt.title(title)\n    plt.yticks(rotation=0)\n    plt.show()\n\n","b9361a98":"# For Target 0\n\ntargets_corr(data=target0cr,title='Correlation for target 0')","c4a679e9":"# For Target 1\n\ntargets_corr(data=target1cr,title='Correlation for target 1')","282361e7":"\n\n# Box plotting for univariate variables analysis in logarithmic scale\n\ndef univariate_numerical(data,col,title):\n    sns.set_style('whitegrid')\n    sns.set_context('talk')\n    plt.rcParams[\"axes.labelsize\"] = 20\n    plt.rcParams['axes.titlesize'] = 22\n    plt.rcParams['axes.titlepad'] = 30\n    \n    plt.title(title)\n    plt.yscale('log')\n    sns.boxplot(data =target0, x=col,orient='v')\n    plt.show()","201a6d65":"\n# Distribution of income amount\n\nunivariate_numerical(data=target0,col='AMT_INCOME_TOTAL',title='Distribution of income amount')","05301fec":"# Disrtibution of credit amount\n\nunivariate_numerical(data=target0,col='AMT_CREDIT',title='Distribution of credit amount')","8ffb00e0":"#Plot to see outliers in AMT_INCOME_TOTAL \nplt.figure(figsize=[8,2])\nsns.boxplot(inp2.AMT_CREDIT)\nplt.show()\n\n# make boxplot with Seaborn\nbplot=sns.boxplot(inp2.AMT_CREDIT, \n                 width=0.5,\n                 palette=\"colorblind\")\n \n# add stripplot to boxplot with Seaborn\nbplot=sns.stripplot(inp2.AMT_CREDIT,  \n                   jitter=True, \n                   marker='o', \n                   alpha=0.5,\n                   color='black')\n","de9daac6":"# Distribution of anuuity amount\n\nunivariate_numerical(data=target0,col='AMT_ANNUITY',title='Distribution of Annuity amount')","b5c531cf":"# Distribution of income amount\n\nunivariate_numerical(data=target1,col='AMT_INCOME_TOTAL',title='Distribution of income amount')","4a584949":"# Distribution of credit amount\n\nunivariate_numerical(data=target1,col='AMT_CREDIT',title='Distribution of credit amount')","17e900d3":"# Distribution of Annuity amount\n\nunivariate_numerical(data=target1,col='AMT_ANNUITY',title='Distribution of Annuity amount')","a445453a":"# Box plotting for Credit amount\n\nplt.figure(figsize=(16,12))\nplt.xticks(rotation=45)\nsns.boxplot(data =target0, x='NAME_EDUCATION_TYPE',y='AMT_CREDIT', hue ='NAME_FAMILY_STATUS',orient='v')\nplt.title('Credit amount vs Education Status')\nplt.show()","35f6385f":"# Box plotting for Income amount in logarithmic scale\n\nplt.figure(figsize=(16,12))\nplt.xticks(rotation=45)\nplt.yscale('log')\nsns.boxplot(data =target0, x='NAME_EDUCATION_TYPE',y='AMT_INCOME_TOTAL', hue ='NAME_FAMILY_STATUS',orient='v')\nplt.title('Income amount vs Education Status')\nplt.show()","c9bf6639":"# Box plotting for credit amount\n\nplt.figure(figsize=(16,12))\nplt.xticks(rotation=45)\nsns.boxplot(data =target1, x='NAME_EDUCATION_TYPE',y='AMT_CREDIT', hue ='NAME_FAMILY_STATUS',orient='v')\nplt.title('Credit Amount vs Education Status')\nplt.show()","c75039ea":"# Box plotting for Income amount in logarithmic scale\n\nplt.figure(figsize=(16,12))\nplt.xticks(rotation=45)\nplt.yscale('log')\nsns.boxplot(data =target1, x='NAME_EDUCATION_TYPE',y='AMT_INCOME_TOTAL', hue ='NAME_FAMILY_STATUS',orient='v')\nplt.title('Income amount vs Education Status')\nplt.show()","a85968ad":"#Reading the Data Dictionary for columns in previous application Data \ncols_data.rename(columns = {'Unnamed: 0':'Serial No'}, inplace = True) \ncols_data.set_index('Serial No')\n","abba3595":"#To check the shape of Previous application Dataframe \n\ninp1.shape","1a34688f":"# Check for the columns in the inp1 Dataframe (Previous application)- henceforth called as inp1\ninp1.columns","c5053553":"# Check the column stats\ninp1.info()","5e6ef882":"# Describe to see the mean and min and max value in dataframe inp1\ninp1.describe()","df48eced":"# Check for sample data from inp1\n\ninp1.head(10)","0db56e4a":"# Cleaning the missing data\n\n# listing the null values columns having more than 30%\n\nemptycol1=inp1.isnull().sum()\nemptycol1=emptycol1[emptycol1.values>(0.3*len(emptycol1))]\nlen(emptycol1)","212295ba":"# Cleaning the data \n# Exlpore for null values \nnullcolumns=inp1.isnull().sum()\nnullcolumns","c8696a7f":"#Check the percentage of null values in the columns of inp1 dataframe \nround(inp1.isnull().sum()\/len(inp1)*100,2)","98b9d9ea":"##To find the columns having more than 50% null values \nemptynullcol=inp1.isnull().sum()\nemptynullcol=emptynullcol[emptynullcol.values>(0.5*len(emptynullcol))]\nemptynullcol","4d12d9d7":"#Drop the Null values \n\nemptynullcol = list(emptynullcol[emptynullcol.values>=0.5].index)\ninp1.drop(labels=emptynullcol,axis=1,inplace=True)\nprint(len(emptynullcol))","fa12e6e2":"#Check the percentage of null values in the columns of inp1 dataframe after dropping few columns greater than 50% null\nround(inp1.isnull().sum()\/len(inp1)*100,2)","c2e99c37":"#Checck for XNA and XAP in Column NAME_CASH_LOAN_PURPOSE\ninp1.NAME_CASH_LOAN_PURPOSE.value_counts()","8bbf83e3":"# Removing the column values of 'XNA' and 'XAP'\n\ninp1=inp1.drop(inp1[inp1['NAME_CASH_LOAN_PURPOSE']=='XNA'].index)\ninp1=inp1.drop(inp1[inp1['NAME_CASH_LOAN_PURPOSE']=='XAP'].index)\n\ninp1.NAME_CASH_LOAN_PURPOSE.value_counts()","702fea6b":"# Check for shape after XNA and XAP handling \ninp1.shape","46ba21d5":"# Check for sample data in inp1\ninp1.head(20)","5a5e0ecc":"#check Column info\ninp1.info()","85c26356":"#Merging the Application dataset with previous appliaction dataset\n\nMaster=pd.merge(left=inp2,right=inp1,how='inner',on='SK_ID_CURR',suffixes='_x')","f6ee68a6":"# Renaming the column names after merging\n\nmaster1= Master.rename({'NAME_CONTRACT_TYPE_' : 'NAME_CONTRACT_TYPE','AMT_CREDIT_':'AMT_CREDIT','AMT_ANNUITY_':'AMT_ANNUITY',\n                         'WEEKDAY_APPR_PROCESS_START_' : 'WEEKDAY_APPR_PROCESS_START',\n                         'HOUR_APPR_PROCESS_START_':'HOUR_APPR_PROCESS_START','NAME_CONTRACT_TYPEx':'NAME_CONTRACT_TYPE_PREV',\n                         'AMT_CREDITx':'AMT_CREDIT_PREV','AMT_ANNUITYx':'AMT_ANNUITY_PREV',\n                         'WEEKDAY_APPR_PROCESS_STARTx':'WEEKDAY_APPR_PROCESS_START_PREV',\n                         'HOUR_APPR_PROCESS_STARTx':'HOUR_APPR_PROCESS_START_PREV'}, axis=1)","80c04a2d":"# Check Sample data in master dataframe after merge of inp1 and inp1\nMaster.head()","cfff3a17":"#check for columns in master dataframe \nMaster.columns","56a8d756":"master1.head()","1c8ad089":"master1.columns","a0d3b425":"# Removing unwanted columns for analysis\n\nmaster1.drop(['SK_ID_CURR','WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START','REG_REGION_NOT_LIVE_REGION', \n              'REG_REGION_NOT_WORK_REGION','LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n              'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY','WEEKDAY_APPR_PROCESS_START_PREV',\n              'HOUR_APPR_PROCESS_START_PREV', 'FLAG_LAST_APPL_PER_CONTRACT','NFLAG_LAST_APPL_IN_DAY'],axis=1,inplace=True)","60adb8b7":"#view sample data after dropping unwanted columns \nmaster1.head()","dba9a62e":"# View columns \nmaster1.info()","f73979f1":"master1.columns","ba3dd91f":"# Distribution of contract status in logarithmic scale\nsns.set_style('whitegrid')\nsns.set_context('talk')\n\nplt.figure(figsize=(15,30))\nplt.rcParams[\"axes.labelsize\"] = 20\nplt.rcParams['axes.titlesize'] = 22\nplt.rcParams['axes.titlepad'] = 30\nplt.xticks(rotation=90)\nplt.xscale('log')\nplt.title('Distribution of contract status with purposes')\nax = sns.countplot(data =master1, y= 'NAME_CASH_LOAN_PURPOSE', \n                   order=master1['NAME_CASH_LOAN_PURPOSE'].value_counts().index,hue ='NAME_CONTRACT_STATUS',palette='magma')","76a4d23b":"# Distribution of contract status\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\n\nplt.figure(figsize=(15,30))\nplt.rcParams[\"axes.labelsize\"] = 20\nplt.rcParams['axes.titlesize'] = 22\nplt.rcParams['axes.titlepad'] = 30\nplt.xticks(rotation=90)\nplt.xscale('log')\nplt.title('Distribution of purposes with target ')\nax = sns.countplot(data = master1, y= 'NAME_CASH_LOAN_PURPOSE', \n                   order=master1['NAME_CASH_LOAN_PURPOSE'].value_counts().index,hue = 'TARGET',palette='magma')","dd8b2193":"# Box plotting for Credit amount in logarithmic scale\n\nplt.figure(figsize=(16,12))\nplt.xticks(rotation=90)\nplt.yscale('log')\nsns.barplot(data =master1, x='NAME_CASH_LOAN_PURPOSE',hue='NAME_INCOME_TYPE',y='AMT_CREDIT_PREV',orient='v')\nplt.title('Prev Credit amount vs Loan Purpose')\nplt.show()","66d02db0":"# Box plotting for Credit amount prev vs Housing type in logarithmic scale\n\nplt.figure(figsize=(16,12))\nplt.xticks(rotation=90)\nsns.barplot(data =master1, y='AMT_CREDIT_PREV',hue='TARGET',x='NAME_HOUSING_TYPE')\nplt.title('Prev Credit amount vs Housing type')\nplt.show()","5c07d517":"### Univariate Analysis for both the targets to explore insights ","b4af1a14":"## Categoroical Univariate Analysis in logarithmic scale for target - 1 (Client with payment difficulties)","a95ba5b8":"So, there are 4 rows from Gender column and 55374 rows from Organization type column","5ee98817":"\nFrom the above we can conclude some points-\n\nThe credit amount of Loan purposes like 'Buying a holiday home','Buying a land','Buying a new car' and'Building a house' is higher.\n\nIncome type of state servants have a significant amount of credit applied\n\nMoney for third person or a Hobby is having less credits applied for.","c8934263":"This heat map for Target 1 is also having quite a same observation just like Target 0. But for few points are different. They are listed below.\n\nThe client's permanent address does not match contact address are having less children and vice-versa\n\nthe client's permanent address does not match work address are having less children and vice-versa","a5fb0e2f":"Inisghts Derived from the above plot : \n\n\nFor income type \u2018working\u2019, \u2019commercial associate\u2019, and \u2018State Servant\u2019 the number of credits are higher than others.\nFor this Females are having more number of credits than male.\nLess number of credits for income type \u2018student\u2019 ,\u2019pensioner\u2019, \u2018Businessman\u2019 and \u2018Maternity leave\u2019.","5feb1945":"### Reading the Dataset ","ea695bb7":"Here for Housing type, office appartment is having higher credit of target 0 and co-op apartment is having higher credit of target 1. So, we can conclude that bank should avoid giving loans to the housing type of co-op apartment as they are having difficulties in payment. Bank can focus mostly on housing type with parents or House\\appartment or miuncipal appartment for successful payments","641b28cf":"### To Create Bins for AMT_INCOME_TOTAL ,AMT_CREDIT,AMT_ANNUITY\n","55a34785":"Points to be concluded from the above graph.\n\nMale counts are higher than female.\nIncome range from 100000 to 200000 is having more number of credits.\nThis graph show that males are more than female in having credits for that range.\nVery less count for income range 400000 and above.","3972668b":"## Performing bivariate analysis","6d99de94":"Inferences and insights from the above Plot :\n\nFemale counts are higher than male.\n\nIncome range from 100000 to 200000 is having more number of credits.\n\nThis graph show that females are more than male in having credits for that range.\n\nVery less count for income range 400000 and above.","912f455b":"Inisghts Derived from the above plot :\n\nFor contract type \u2018cash loans\u2019 is having higher number of credits than \u2018Revolving loans\u2019 contract type.\n\nFemale is leading for applying credits.","971c75f0":"\nPoints to be concluded from above plot:\n\nMost rejection of loans came from purpose 'repairs'.\n\nFor education purposes we have equal number of approves and rejection\n\nPaying other loans and buying a new car is having significant higher rejection than approves.","681e04aa":"Since, Female is having the majority and only 4 rows are having XNA values, we can update those columns with Gender 'F'.","9cd673ba":"From the analysis of the head above, we could see the DAYS colum have the value as negative and the ORganization Type colum have XNA value . So, the Next step is to check for XNA for the variables and the -ve values need to be +ve converted for days column","2e2b8669":"# Analysis of Previous application Data ","f7da0c22":"we have total count of 307511 rows of which 55374 rows are having 'XNA' values. Which means 18% of the column is having this values. Hence if we drop the rows of total 55374, will not have any major impact on our dataset.","80b46384":"\nFew points can be concluded from the graph above.\n\n\nThe first quartile is bigger than third quartile for annuity amount which means most of the annuity clients are from first quartile.","f9af34ba":"There is a difference here when compared to Target-0 with Target 1 . \n\nOnly Married family status people in having an academic degree have higher credit than other categories.\n\nWe could see lot of outliers in other categories such as secondary,Incomplete Higher,Higher Education , Lower Secondary\n\nPeople seperated with higher education background have high credits as their third quartile is bigger when compared with other categories and their counterparts","52338eb7":"### Exploring the  Application Data Which is current data given ","875cf179":"### For Target-0  Univariate Analysis","a5b49364":"#### from the box plot we could see that the Field\/ Column has more outiers. So, Instead of imputing through mean, the field will be imputed with median . Since, we have outliers","496e6ac6":"From the Data we could see there are null values in the dataframe and also few missing values like XNA and XAP we will be handling this downstream in the code below","c3d83ebd":"Points to be concluded from the above graph.\n\nFor contract type \u2018cash loans\u2019 is having higher number of credits than \u2018Revolving loans\u2019 contract type.\nFor this also Female is leading for applying credits.\nFor type 1 : there is only Female Revolving loans.","9b76b0a3":"## CONCLUSION\n\n#### 1. Banks should focus more on contract type \u2018Student\u2019 ,\u2019pensioner\u2019 and \u2018Businessman\u2019 with housing \u2018type other than \u2018Co-op apartment\u2019 for successful payments.\n\n#### 2. Banks should focus less on income type \u2018Working\u2019 as they are having most number of unsuccessful payments.\n\n#### 3. Also with loan purpose \u2018Repair\u2019 is having higher number of unsuccessful payments on time.\n\n#### 4. Get as much as clients from housing type \u2018With parents\u2019 as they are having least number of unsuccessful payments.","d05337ce":"#### Srinivasaragavan Vijayaraghavan \n\n","34237201":"### For Target-1  Univariate Analysis","430354d0":"##### We have, now found out that the Imbalance Ratio is 10.055","2c665fef":"As we can see from above correlation heatmap, There are number of observation we can point out\n\nCredit amount is inversely proportional to the date of birth, which means Credit amount is higher for low age and vice-versa.\n\nCredit amount is inversely proportional to the number of children client have, means Credit amount is higher for less children count client have and vice-versa.\n\nIncome amount is inversely proportional to the number of children client have, means more income for less children client have and vice-versa.\n\nless children client have in densely populated area.\n\nCredit amount is higher to densely populated area.\n\nThe income is also higher in densely populated area.","587aa923":"Few points can be concluded from the graph above.\n\nSome outliers are noticed in credit amount.\nThe first quartile is bigger than third quartile for credit amount which means most of the credits of clients are present in the first quartile.","483fdce5":"From above boxplot for Education type 'Higher education' the income amount is mostly equal with family status. It does contain many outliers. Less outlier are having for Academic degree but there income amount is little higher that Higher education. Lower secondary of civil marriage family status are have less income amount than others.","edb8fd7c":"### Handling missing values(XNA)- Not Available  in the inp2 Dataframe based on the suitable techniques\n","c9966efe":"#### Now we have the descriptions for the columns in each datasets that we have. Time for exploring the Data to infer insights","17db453f":"From the above plot ,\n\nWE could see that Maried customer with Academic Degree are the once who have high income  than all other categories. \nWe also could not spot any outliers in academic degree. \n\nMost customers of different family status with lower seconday have low income when compared to all others\n\nCustomer who are Widow and of incomplete higher Education has the least income among all others. \n\n","7efa7344":"Few points can be concluded from the graph above.\n\nSome outliers are noticed in credit amount.\nThe first quartile is bigger than third quartile for credit amount which means most of the credits of clients are present in the first quartile.","9cc16f74":"Points to be concluded from the above graph.\n\nFor income type \u2018working\u2019, \u2019commercial associate\u2019, and \u2018State Servant\u2019 the number of credits are higher than other i.e. \u2018Maternity leave.\nFor this Females are having more number of credits than male.\nLess number of credits for income type \u2018Maternity leave\u2019.\nFor type 1: There is no income type for \u2018student\u2019 , \u2019pensioner\u2019 and \u2018Businessman\u2019 which means they don\u2019t do any late payments.","ba2b942e":"### Bivariate analysis for Target 0 ","a66a2d47":"### Let's see the Columns description first.","800d7d95":"## Business Understanding\n\nThe loan providing companies find it hard to give loans to the people due to their insufficient or non-existent credit history. Because of that, some consumers use it as their advantage by becoming a defaulter. Suppose you work for a consumer finance company which specialises in lending various types of loans to urban customers. You have to use EDA to analyse the patterns present in the data. This will ensure that the applicants capable of repaying the loan are not rejected.\n\n \n\nWhen the company receives a loan application, the company has to decide for loan approval based on the applicant\u2019s profile. Two types of risks are associated with the bank\u2019s decision:\n\nIf the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n\nIf the applicant is not likely to repay the loan, i.e. he\/she is likely to default, then approving the loan may lead to a financial loss for the company.\n\n \n\nThe data given below contains the information about the loan application at the time of applying for the loan. It contains two types of scenarios:\n\nThe client with payment difficulties: he\/she had late payment more than X days on at least one of the first Y instalments of the loan in our sample,\n\nAll other cases: All other cases when the payment is paid on time.\n\n \n\n \n\nWhen a client applies for a loan, there are four types of decisions that could be taken by the client\/company):\n\nApproved: The Company has approved loan Application\n\nCancelled: The client cancelled the application sometime during approval. Either the client changed her\/his mind about the loan or in some cases due to a higher risk of the client he received worse pricing which he did not want.\n\nRefused: The company had rejected the loan (because the client does not meet their requirements etc.).\n\nUnused offer:  Loan has been cancelled by the client but on different stages of the process.\n\nIn this case study, you will use EDA to understand how consumer attributes and loan attributes influence the tendency of default.","2fec1a73":"We found we have XAP-922661 and XNA-67791 We have to delte the data as it is more than 30%","8e4acb3e":"## Performing univariate analysis","eed42d94":"Now we have 22 columns without null values , now we inspect for missing values and data correction and dataype correctin for few columns","251bfa28":"## Introduction\nThis case study aims to give you an idea of applying EDA in a real business scenario. In this case study, apart from applying the techniques that you have learnt in the EDA module, you will also develop a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers.\n\n ","d7b6c915":" We, could see that AMT_ANNUITY column has few null values,hence it will be imputed","289f48db":"Insights inferred from the above plot\n\nClients which have applied for credits are from most of the organization type \u2018Business entity Type 3\u2019 , \u2018Self employed\u2019, \u2018Other\u2019 \n\nLess clients are from Industry type 4,type 8, type 5, religion and trade type 10, type 6.","6646f82a":"Few points can be concluded from the graph above.\n\nSome outliers are noticed in income amount.\n\nThe third quartiles is very slim for income amount.","44d3de2d":"Insights inferred from the above plot\n\nClients which have applied for credits are from most of the organization type \u2018Business entity Type 3\u2019 , \u2018Self employed\u2019, \u2018Other\u2019 , \u2018Medicine\u2019 and \u2018Government\u2019.\n\nLess clients are from Industry type 8,type 6, type 10, religion and trade type 5, type 4.","917e3f13":"From the above box plot we can conclude that Family status of 'civil marriage', 'marriage' and 'separated' of Academic degree education are having higher number of credits than others. Also, higher education of family status of 'marriage', 'single' and 'civil marriage' are having more outliers. Civil marriage for Academic degree is having most of the credits in the third quartile.","bbc47798":"Few points can be concluded from the graph above.\n\n\nSome outliers are noticed in income amount.\n\nThe third quartiles is very slim for income amount.\n\nMost of the clients of income are present in first quartile.\n","08b67358":"\nFew points we can conclude from abpve plot:\n\nLoan purposes with 'Repairs' are facing more difficulites in payment on time.\n\nThere are few places where loan payment is significant higher than facing difficulties. \n\nThey are 'Buying a garage', 'Business developemt', 'Buying land','Buying a new car' and 'Education'\n\nHence we can focus on these purposes for which the client is having for minimal payment difficulties.","07f876aa":"### Bivariate analysis for Target 1","34228a95":"## Univariate analysis for categories for Target - 0 ( Client with no payment difficulites )","5fc7a204":"\nFew points can be concluded from the graph above.\n\n\nSome outliers are noticed in annuity amount.\nThe first quartile is bigger than third quartile for annuity amount which means most of the annuity clients are from first quartile."}}