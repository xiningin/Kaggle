{"cell_type":{"61bb7ef3":"code","1b42c03f":"code","d5faef20":"code","ce784847":"code","10e77ee2":"code","c5bc4b9b":"code","4386c804":"code","5f3d3edb":"code","98a7d767":"code","e6074230":"code","8c21cbc7":"code","36b215b1":"code","49b506a6":"code","0dc850b2":"code","b3e41348":"code","46f0903a":"code","906c4a02":"code","24118680":"code","3254fbae":"code","41f9bc6b":"code","b234e75b":"code","1813de42":"code","4af9a655":"code","07a9edb6":"code","4b98ac7a":"code","da22e810":"code","93eec3d4":"code","a75a933b":"markdown","2fb957cb":"markdown","2b0f25b0":"markdown","4ba891c2":"markdown","292255d4":"markdown","22dde879":"markdown","6f8a197f":"markdown","1952606f":"markdown","33695071":"markdown","74b9a853":"markdown","5cc84499":"markdown","02c857c4":"markdown","3d144deb":"markdown","c4a51198":"markdown"},"source":{"61bb7ef3":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\nimport datetime\nimport matplotlib.pyplot as plt\nfrom keras.utils import plot_model","1b42c03f":"MIXED_PRECISION = True\nXLA_ACCELERATE  = False # Didn't work; Dunno Why!\n\nGPUS = tf.config.experimental.list_physical_devices('GPU')\nif GPUS:\n    try:\n        for GPU in GPUS:\n            tf.config.experimental.set_memory_growth(GPU, True)\n            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n            print(len(GPUS), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n    except RuntimeError as  RE:\n        print(RE)\n\nif MIXED_PRECISION:\n    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    tf.keras.mixed_precision.experimental.set_policy(policy)\n    print('Mixed precision enabled')\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')\n    \nstrategy = tf.distribute.get_strategy()\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}') \nprint(\"Tensorflow version \" + tf.__version__)","d5faef20":"train_dir = '..\/input\/fer2013\/train\/'\ntest_dir = '..\/input\/fer2013\/test\/'\n\nrow, col = 48, 48\nclasses = 7\n\ndef count_exp(path, set_):\n    dict_ = {}\n    for expression in os.listdir(path):\n        dir_ = path + expression\n        dict_[expression] = len(os.listdir(dir_))\n    df = pd.DataFrame(dict_, index=[set_])\n    return df\ntrain_count = count_exp(train_dir, 'train')\ntest_count = count_exp(test_dir, 'test')\nprint(train_count)\nprint(test_count)","ce784847":"\ntrain_count.transpose().plot(kind='bar', figsize=(12,10))","10e77ee2":"test_count.transpose().plot(kind='bar',figsize=(12, 10))","c5bc4b9b":"plt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(train_dir):\n    img = load_img((train_dir + expression +'\/'+ os.listdir(train_dir + expression)[1]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()","4386c804":"image_size= 48\nbatch_size= 64\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   zoom_range=0.3,\n                                   horizontal_flip=True)\n\ntraining_set = train_datagen.flow_from_directory(train_dir,\n                                                batch_size=64,\n                                                target_size=(image_size, image_size),\n                                                shuffle=True,\n                                                color_mode='grayscale',\n                                                class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_set = test_datagen.flow_from_directory(test_dir,\n                                                batch_size=64,\n                                                target_size=(image_size, image_size),\n                                                shuffle=True,\n                                                color_mode='grayscale',\n                                                class_mode='categorical')","5f3d3edb":"training_set.class_indices","98a7d767":"def model_1(input_size, classes=7):\n     \n    model = tf.keras.models.Sequential()   \n\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(2, 2))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(classes, activation='softmax'))\n\n    #Compliling the model\n    model.compile(optimizer=Adam(lr=0.0001, decay=1e-6), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    return model","e6074230":"def model_2(input_size, classes=7):\n    model= tf.keras.models.Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\n    model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n\n    model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    #Faltten the model\n    model.add(Flatten())\n    \n    \n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n    \n    \n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(classes, activation='softmax'))\n    opt = Adam(lr=0.0001 , decay=1e-6)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    model.summary\n    return model\n    ","8c21cbc7":"model_1 = model_1((row,col,1), classes)\nmodel_1.summary()","36b215b1":"model_2 = model_2((row,col,1), classes)\nmodel_2.summary()","49b506a6":"plot_model(model_1, to_file='model_1.png', show_shapes=True, show_layer_names=True)","0dc850b2":"plot_model(model_2, to_file='model_2.png', show_shapes=True, show_layer_names=True)","b3e41348":"chk_path = 'model_1.h5'\nlog_dir = \"checkpoint\/logs\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncheckpoint = ModelCheckpoint(filepath=chk_path,\n                             save_best_only=True,\n                             verbose=1,\n                             mode='min',\n                             moniter='val_loss')\n\nearlystop = EarlyStopping(monitor='val_loss', \n                          min_delta=0, \n                          patience=3, \n                          verbose=1, \n                          restore_best_weights=True)\n                        \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=6, \n                              verbose=1, \n                              min_delta=0.0001)\n\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\ncsv_logger = CSVLogger('training.log')\n\ncallbacks = [checkpoint, reduce_lr, csv_logger]","46f0903a":"steps_per_epoch = training_set.n \/\/ training_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\nhist = model_1.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=60,\n                 callbacks=callbacks,\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","906c4a02":"chk_path_2 = 'model_2.h5'\nlog_dir_2 = \"checkpoint\/logs\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncheckpoint_2 = ModelCheckpoint(filepath=chk_path_2,\n                             save_best_only=True,\n                             verbose=1,\n                             mode='min',\n                             moniter='val_loss')\n\nearlystop_2 = EarlyStopping(monitor='val_loss', \n                          min_delta=0, \n                          patience=3, \n                          verbose=1, \n                          restore_best_weights=True)\n                        \nreduce_lr_2 = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=6, \n                              verbose=1, \n                              min_delta=0.0001)\n\n\ntensorboard_callback_2 = tf.keras.callbacks.TensorBoard(log_dir=log_dir_2, histogram_freq=1)\ncsv_logger_2 = CSVLogger('training.log')\n\ncallback_2 = [checkpoint_2, reduce_lr_2, csv_logger_2]","24118680":"\n\nmodel_2_hist = model_2.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=60,\n                 callbacks=callback_2,\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","3254fbae":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,2)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.subplot(1,2,1)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","41f9bc6b":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,2)\nplt.plot(model_2_hist.history['accuracy'])\nplt.plot(model_2_hist.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.subplot(1,2,1)\nplt.plot(model_2_hist.history['loss'])\nplt.plot(model_2_hist.history['val_loss'])\nplt.title('model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","b234e75b":"def model_data(model):\n    train_loss, train_accu = model.evaluate(training_set)\n    test_loss, test_accu = model.evaluate(test_set)\n    return print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))","1813de42":"model_data(model_1)","4af9a655":"model_data(model_2)","07a9edb6":"model_1.save_weights('model_1_bestweight.h5')","4b98ac7a":"model_2.save_weights('model_2_bestweight.h5')","da22e810":"y_pred = model_2.predict(training_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm_train = confusion_matrix(training_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_train)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(training_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_train, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","93eec3d4":"y_pred = model_1.predict(test_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\n#from sklearn.metrics import classification_report, confusion_matrix\ncm_test = confusion_matrix(test_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_test)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(test_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_test, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","a75a933b":"### PLot of number of images in test set","2fb957cb":"# **Let's Use Internal GPU if there's any available**","2b0f25b0":"# **Model 2 shows best result , so we will approach that.**","4ba891c2":"## Training Model","292255d4":"### Callbacks Function","22dde879":"## Loss and Accuracy plot","6f8a197f":"## importing libraries","1952606f":"## Defining Model","33695071":"### PLot of number of images in training set","74b9a853":"# Facial Emotion Recogination","5cc84499":"# Check Model_2","02c857c4":"### Confusion Matrix and Classification on test set","3d144deb":"### Model evaluation","c4a51198":"### Confusion Matrix and Classification on training set"}}