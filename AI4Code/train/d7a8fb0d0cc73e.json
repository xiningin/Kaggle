{"cell_type":{"36c1a9ed":"code","34feeab7":"code","e6d63803":"code","ded9f8c4":"code","8416a4af":"code","589ede72":"code","a6cfcc20":"code","419184aa":"code","2e292d38":"code","f0590ce1":"code","8e4d461f":"code","341cec00":"code","7a6af4ea":"code","a6839ffa":"code","0b86087e":"code","c7568fce":"code","cc267d7e":"code","c799e02d":"code","38037182":"code","ae57c5a3":"code","797adf74":"code","20f095e3":"code","74f28111":"code","edf1eccb":"code","6f94dd53":"code","c8875173":"code","bf12df0f":"code","21422a85":"code","90c21603":"code","8cb1f331":"code","10821ca6":"code","5acae664":"code","2c3e0bcc":"code","d18ce580":"code","3b1c4680":"code","1858673b":"code","e29ff465":"code","5f718a3f":"code","304f5335":"code","907d1cf1":"code","db7aab3d":"code","0dc33fd3":"code","54439a96":"code","ae95b29a":"code","41ad935f":"code","4ba51f56":"code","c51490d1":"code","2ce4a2b5":"code","12cec65c":"code","bfc59aa5":"code","a318baa4":"code","27a22eea":"code","e87e3ee2":"code","5568f90a":"code","eb8ffd7a":"code","ad2adce2":"code","9cc7c3e5":"code","f313866e":"code","ba02654c":"code","5731c3a8":"code","4ea0e852":"markdown"},"source":{"36c1a9ed":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score","34feeab7":"train = pd.read_csv(\"..\/input\/train.csv\")","e6d63803":"train.head(10)","ded9f8c4":"train.describe()","8416a4af":"train.isnull().sum()","589ede72":"#It seems that the column \"Unnamed: 0\" is actually the Donor ID and thus, we can safely assume that it has no connection with the donation , atleast for now","a6cfcc20":"train.info()","419184aa":"train[\"DonationsPerMonth\"] = train[\"Number of Donations\"]\/(train[\"Months since First Donation\"]-train[\"Months since Last Donation\"])    \ntrain[\"DonationsPerMonth\"] = train[\"DonationsPerMonth\"].replace([np.inf, -np.inf], 2)","2e292d38":"train[\"MarchWithinInterval\"] = np.where(train[\"Months since Last Donation\"]>train[\"DonationsPerMonth\"],1,0)","f0590ce1":"train[\"MarchWithinInterval\"] = train[\"MarchWithinInterval\"].astype('object')","8e4d461f":"train.drop(\"Unnamed: 0\",axis=1, inplace=True)","341cec00":"train.info()","7a6af4ea":"for col in train.columns:\n    train.plot.scatter(x=\"Made Donation in March 2007\",y=col)\n    train.plot.hexbin(x=\"Made Donation in March 2007\",y=col,gridsize=30,sharex=False)","a6839ffa":"def bin_last_donation(month):\n    bina=\"\"\n    if month>20:\n        bina=\"Greater\"\n    elif month>10:\n        bina=\"Medium\"\n    elif month<7:\n        bina=\"Lower\"\n    else:\n        bina=\"Interm\"\n    return bina\n\ndef bin_donation_per_period(interval):\n    bina=\"\"\n    if interval<0.3:\n        bina=\"Low\"\n    elif interval<1.0:\n        bina=\"Medium\"\n    else:\n        bina=\"High\"\n    return bina\n\ndef bin_number_of_donation(num):\n    bina=\"\"\n    if num<2:\n        bina=\"Novice\"\n    elif num<4:\n        bina=\"EarlyLearner\"\n    elif num<7:\n        bina=\"Learner\"\n    elif num<10:\n        bina=\"Interm\"\n    elif num<18:\n        bina=\"New\"\n    elif num<45:\n        bina=\"Seasoned\"\n    else:\n        bina=\"Seasoned\"\n    return bina\n        \ndef bin_volume_donated(vol):\n    bina=\"\"\n    if vol<800:\n        bina=\"Novice\"\n    elif vol<2000:\n        bina=\"Learner\"\n    elif vol<4000:\n        bina=\"New\"\n    elif vol<11000:\n        bina=\"Seasoned\"\n    else:\n        bina=\"Old\"\n    return bina\n    \n    \ntrain[\"LastDonation\"] = train[\"Months since Last Donation\"].apply(bin_last_donation)\ntrain[\"Freq\"] = train[\"Number of Donations\"].apply(bin_number_of_donation)\ntrain[\"Volume\"] = train[\"Total Volume Donated (c.c.)\"].apply(bin_volume_donated)\ntrain[\"Regularity\"] = train[\"DonationsPerMonth\"].apply(bin_donation_per_period)","0b86087e":"y = train[\"Made Donation in March 2007\"]","c7568fce":"train.drop(\"Made Donation in March 2007\",axis=1,inplace=True)","cc267d7e":"from scipy.stats import skew\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics2 = []\nfor i in train.columns:\n    if train[i].dtype in numeric_dtypes: \n        numerics2.append(i)\n\nskew_features = train[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\nskews = pd.DataFrame({'skew':skew_features})\nskews","c799e02d":"from scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nhigh_skew = skew_features[skew_features > 0.5]\nhigh_skew = high_skew\nskew_index = high_skew.index\n\nfor i in skew_index:\n    train[i]= boxcox1p(train[i], boxcox_normmax(train[i]+1))\n\n        \nskew_features2 = train[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\nskews2 = pd.DataFrame({'skew':skew_features2})\nskews2","38037182":"train[\"DonationsPerMonth\"]","ae57c5a3":"train.drop(\"Total Volume Donated (c.c.)\",axis=1,inplace=True)","797adf74":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ntrain[train.select_dtypes(exclude=\"object\").columns.tolist()] = scaler.fit_transform(train[train.select_dtypes(exclude=\"object\").columns.tolist()])","20f095e3":"train.describe()","74f28111":"y.describe()","edf1eccb":"#train = pd.get_dummies(train)","6f94dd53":"test = pd.read_csv(\"..\/input\/test.csv\")","c8875173":"test.describe()","bf12df0f":"test[\"DonationsPerMonth\"] = test[\"Number of Donations\"]\/(test[\"Months since First Donation\"]-test[\"Months since Last Donation\"])    \ntest[\"DonationsPerMonth\"] = test[\"DonationsPerMonth\"].replace([np.inf, -np.inf], 2)","21422a85":"test[\"MarchWithinInterval\"] = np.where(test[\"Months since Last Donation\"]>test[\"DonationsPerMonth\"],1,0)","90c21603":"test[\"MarchWithinInterval\"] = test[\"MarchWithinInterval\"].astype('object')","8cb1f331":"test.drop(\"Unnamed: 0\",axis=1,inplace=True)\ntest[\"LastDonation\"] = test[\"Months since Last Donation\"].apply(bin_last_donation)\ntest[\"Freq\"] = test[\"Number of Donations\"].apply(bin_number_of_donation)\ntest[\"Volume\"] = test[\"Total Volume Donated (c.c.)\"].apply(bin_volume_donated)\ntest[\"Regularity\"] = test[\"DonationsPerMonth\"].apply(bin_donation_per_period)","10821ca6":"from scipy.stats import skew\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics2 = []\nfor i in test.columns:\n    if test[i].dtype in numeric_dtypes: \n        numerics2.append(i)\n\nskew_features = test[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\nskews = pd.DataFrame({'skew':skew_features})\nskews","5acae664":"from scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nhigh_skew = skew_features[skew_features > 0.5]\nhigh_skew = high_skew\nskew_index = high_skew.index\n\nfor i in skew_index:\n    test[i]= boxcox1p(test[i], boxcox_normmax(test[i]+1))\n\n        \nskew_features2 = test[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\nskews2 = pd.DataFrame({'skew':skew_features2})\nskews2","2c3e0bcc":"test.drop(\"Total Volume Donated (c.c.)\",axis=1,inplace=True)","d18ce580":"#test[test.columns.tolist()] = scaler.fit_transform(test[test.columns.tolist()])\ntest[test.select_dtypes(exclude=\"object\").columns.tolist()] = scaler.fit_transform(test[test.select_dtypes(exclude=\"object\").columns.tolist()])","3b1c4680":"#test = pd.get_dummies(test)","1858673b":"CategCols = test.select_dtypes(include=\"object\").columns.tolist()","e29ff465":"temp = pd.get_dummies(pd.concat([train,test],keys=[0,1]), columns=CategCols, drop_first=True)\ntrain,test = temp.xs(0),temp.xs(1)","5f718a3f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.25, random_state=28)","304f5335":"from sklearn.metrics import log_loss","907d1cf1":"from sklearn.svm import SVC\nsvcClassif = SVC(gamma=\"auto\")\nsvcClassif.fit(X_train,y_train)\ny_preds = svcClassif.predict(X_test)\n#log_loss(y_preds,y_test)\naccuracy_score(y_preds,y_test)","db7aab3d":"from sklearn.ensemble import RandomForestClassifier\nrfClassif = RandomForestClassifier()\nrfClassif.fit(X_train,y_train)\ny_preds = rfClassif.predict(X_test)\ny_pred_probs_rf = rfClassif.predict_proba(X_test)\nprint(log_loss(y_preds,y_test))\nprint(accuracy_score(y_preds,y_test))","0dc33fd3":"from sklearn.ensemble import AdaBoostClassifier\nadaBoostClassif = AdaBoostClassifier()\nadaBoostClassif.fit(X_train,y_train)\ny_preds = adaBoostClassif.predict(X_test)\ny_pred_probs_ab = adaBoostClassif.predict_proba(X_test)\nprint(log_loss(y_preds,y_test))\nprint(accuracy_score(y_preds,y_test))","54439a96":"from sklearn.linear_model import LogisticRegression\nLRClassif = LogisticRegression(solver=\"liblinear\")\nLRClassif.fit(X_train,y_train)\ny_preds = LRClassif.predict(X_test)\ny_pred_probs_lr = LRClassif.predict_proba(X_test)\nprint(log_loss(y_preds,y_test))\nprint(accuracy_score(y_preds,y_test))","ae95b29a":"from sklearn.ensemble import GradientBoostingClassifier\ngbClassif = GradientBoostingClassifier()\ngbClassif.fit(X_train,y_train)\ny_preds = gbClassif.predict(X_test)\ny_pred_probs_gb = gbClassif.predict_proba(X_test)\nprint(log_loss(y_preds,y_test))\nprint(accuracy_score(y_preds,y_test))","41ad935f":"from sklearn.neighbors import KNeighborsClassifier\nkNNClassif = KNeighborsClassifier(n_neighbors=20)\nkNNClassif.fit(X_train,y_train)\ny_preds = kNNClassif.predict(X_test)\ny_pred_probs_kn = kNNClassif.predict_proba(X_test)\nprint(log_loss(y_preds,y_test))\nprint(accuracy_score(y_preds,y_test))","4ba51f56":"from sklearn.model_selection import GridSearchCV\nfrom mlxtend.classifier import StackingCVClassifier\n\n# Initializing models\n\n# The StackingCVClassifier uses scikit-learn's check_cv\n# internally, which doesn't support a random seed. Thus\n# NumPy's random seed need to be specified explicitely for\n# deterministic behavior\nnp.random.seed(42)\nsclf = StackingCVClassifier(classifiers=[svcClassif,rfClassif,gbClassif,adaBoostClassif,LRClassif], \n                            meta_classifier=kNNClassif)\n\nparams = {'meta-kneighborsclassifier__n_neighbors': [1, 20],\n            'randomforestclassifier__n_estimators': [10, 50],\n          'logisticregression__C': [0.1, 10.0]}\n\ngrid = GridSearchCV(estimator=sclf, \n                    param_grid=params, \n                    cv=5,\n                    refit=True)\ngrid.fit(X_train.values, y_train.values)\n\ncv_keys = ('mean_test_score', 'std_test_score', 'params')\n\nfor r, _ in enumerate(grid.cv_results_['mean_test_score']):\n    print(\"%0.3f +\/- %0.2f %r\"\n          % (grid.cv_results_[cv_keys[0]][r],\n             grid.cv_results_[cv_keys[1]][r] \/ 2.0,\n             grid.cv_results_[cv_keys[2]][r]))\n\nprint('Best parameters: %s' % grid.best_params_)\nprint('Accuracy: %.2f' % grid.best_score_)\n","c51490d1":"y_pred_probs_stack = grid.predict_proba(X_test.values)","2ce4a2b5":"y_cum_preds = (0.2*y_pred_probs_rf) + (0.1*y_pred_probs_ab) + (0.1*y_pred_probs_gb) + (0.2*y_pred_probs_lr) + (0.1*y_pred_probs_stack) + (0.3*y_pred_probs_kn)","12cec65c":"y_cum_preds = np.where(y_cum_preds > 0.5, 1, 0)","bfc59aa5":"y_cum_preds = np.argmax(y_cum_preds,axis=1)","a318baa4":"log_loss(y_cum_preds,y_test)\naccuracy_score(y_preds,y_test)","27a22eea":"y_test_pred_probs_rf = rfClassif.predict_proba(test)\ny_test_pred_probs_ab = adaBoostClassif.predict_proba(test)\ny_test_pred_probs_gb = gbClassif.predict_proba(test)\ny_test_pred_probs_lr = LRClassif.predict_proba(test)\n#y_test_pred_probs_nn = nn2.predict_proba(test)\ny_test_pred_probs_kn = kNNClassif.predict_proba(test)\ny_test_pred_probs_stack = grid.predict_proba(test.values)","e87e3ee2":"y_true_cum_preds = (0.2*y_test_pred_probs_rf) + (0.1*y_test_pred_probs_ab) + (0.1*y_test_pred_probs_gb) + (0.2*y_test_pred_probs_lr) + (0.1*y_test_pred_probs_stack) + (0.3*y_test_pred_probs_kn)","5568f90a":"len(y_true_cum_preds)","eb8ffd7a":"y_true_cum_preds = y_true_cum_preds[:,1:]","ad2adce2":"y_true_cum_preds = y_true_cum_preds.flatten()","9cc7c3e5":"testy = pd.read_csv(\"..\/input\/test.csv\")\nsubmission = pd.DataFrame({'Unnamed: 0':testy[\"Unnamed: 0\"],'Made Donation in March 2007':y_true_cum_preds})\n#submission = pd.DataFrame({'Unnamed: 0':testy[\"Unnamed: 0\"],'Made Donation in March 2007':y_test_pred_probs_ab})","f313866e":"submission.describe()","ba02654c":"sub = submission[[\"Unnamed: 0\",\"Made Donation in March 2007\"]]","5731c3a8":"sub.to_csv(\"submission.csv\", encoding='utf-8', index=False)","4ea0e852":"Further course of action : MultiLayerPerceptrons have been added. Now, Take Averages of the models and submit and then make Stacking Classifiers and then make the next submission."}}