{"cell_type":{"b0317d2f":"code","6829f220":"code","f062cd5c":"code","3b68c694":"code","fd0ff190":"code","56a41761":"code","67a49173":"code","2510efd2":"code","94429682":"code","506dd063":"code","79a17baa":"code","d1d71fee":"code","c9bdd4bb":"code","39f5cd7b":"code","23bcee1e":"code","4c47d153":"code","c1958122":"code","c83b48d9":"code","6dc4e731":"code","aeaa7e44":"code","7280bfc9":"code","7f3ac7fe":"code","98e8c835":"code","8128d18f":"markdown","85ae3ed2":"markdown"},"source":{"b0317d2f":"!pip install autokeras -q","6829f220":"import os\nimport warnings\nfrom pathlib import Path\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pylab as plt\n\nimport autokeras as ak\nfrom tensorflow import keras\nfrom sklearn.preprocessing import LabelEncoder\nfrom skimage.transform import resize\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)","f062cd5c":"DEBUG = False\nif DEBUG:\n    max_trials = 1\n    epochs = 1\nelse:\n    max_trials = 5\n    epochs = 50","3b68c694":"ROOT_TRAIN = Path('..\/input\/data-science-spring-osaka-2021')\n\n# \u4e00\u89a7\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\ndf_train = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/test.csv')\ndf_action = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/actions.csv')","fd0ff190":"# \u5f8c\u306e\u30d5\u30a3\u30eb\u30bf\u30fc\u3068\u3057\u3066\u30d5\u30a3\u30eb\u540d\u3092\u6e96\u5099\ndf_train['filename'] = df_train['file_path'].apply(lambda x: x.split('\/', -1)[-1])","56a41761":"# \u7d50\u5408\u5bfe\u8c61\u306e\u30ea\u30b9\u30c8\u3092\u751f\u6210\n# https:\/\/stackoverflow.com\/a\/56883447\/5990952\nlist_train = sorted((ROOT_TRAIN\/'train').glob('*.csv'))\nlist_test = sorted((ROOT_TRAIN\/'test').glob('*.csv'))","67a49173":"# \u7d50\u5408\u7528\u306e\u30e1\u30bd\u30c3\u30c9\u3001\u4eca\u56de\u30d5\u30a1\u30a4\u30eb\u6570\u5c11\u306a\u3044\uff06\u30b5\u30a4\u30ba\u5c0f\u3055\u3044\u306e\u3067\u3001\u4e26\u5217\u51e6\u7406\u3092\u8003\u3048\u305a\u306b\u3059\u308b\ndef get_data(list_files):\n    dfs = []\n    for file in list_files:\n        df = pd.read_csv(file)\n        df['filename'] = file.name\n        dfs.append(df)\n    return pd.concat(dfs)","2510efd2":"%%time\ndf_train_s = get_data(list_train)\ndf_test_s = get_data(list_test)\n# train \/ test \u3092\u660e\u793a\ndf_train_s['type'] = 'train'\ndf_test_s['type'] = 'test'\nprint(\"\u5b66\u7fd2\", df_train_s.shape, \"\u30c6\u30b9\u30c8\", df_test_s.shape)\n# \u4e00\u3064\u306b\u7d50\u5408\u3059\u308b\ndf_sensor = pd.concat([df_train_s, df_test_s], ignore_index=True)\n# \u30e9\u30d9\u30eb\u3068\u7d50\u5408\ndf_sensor = pd.merge(df_sensor, df_train[['action_seq', 'filename']], on='filename', how='left')\n## \u30c6\u30b9\u30c8\u3092\"test\"\u3068\u3057\u3066\u88dc\u9593\ndf_sensor['action_seq'] = df_sensor['action_seq'].fillna('test')\nprint(\"\u5168\u4f53\", df_sensor.shape)","94429682":"# 0 ~ 5000\u306e\u533a\u9593\u3092\u5207\u308a\u51fa\u3057\u3066\u3001\u884c\u6570\u3092\u5747\u7b49\u306b\u3059\u308b\ndf_sensor = df_sensor.loc[df_sensor['Time'].between(0, 5000)].copy()\n\n# Time\u304c\u540c\u3058\u306e\u884c\u3092\u524a\u9664\ndf_sensor.drop_duplicates(subset=['filename','Time'], inplace=True)\ndf_sensor.shape\n\n# \u30a4\u30f3\u30c7\u30af\u30b9\u4f5c\u6210\nidx = np.linspace(0,5000, num=500, dtype=int)","506dd063":"%%time\ndfs = []\ndf_sensor.set_index('Time',inplace=True)\nfor group, df_group in df_sensor.groupby(by='filename'):\n    try:\n        df_temp = df_group.reindex(df_group.index.union(idx)).interpolate('values', limit_direction='backward').loc[idx]\n        df_temp.reset_index(inplace=True)\n        dfs.append(df_temp)\n    except:\n        print('group', group)\ndf_sensor = pd.concat(dfs)\n\ndf_sensor[[\"filename\",\"type\",\"action_seq\"]] = df_sensor[[\"filename\",\"type\",\"action_seq\"]].ffill()\ndf_sensor.fillna(0, inplace=True)\n\ndf_train_s = df_sensor.loc[df_sensor['type']=='train'].copy()\ndf_test_s = df_sensor.loc[df_sensor['type']=='test'].copy()","79a17baa":"# \u5148\u982d\u884c\u3092\u307f\u3066\u307f\u308b\ndf_train_s.iloc[:,1:-3].head()","d1d71fee":"# \u7279\u5fb4\u91cf\u30c7\u30fc\u30bf\u3092\u5207\u308a\u51fa\u3059\nnp_train = df_train_s.iloc[:,1:-3].to_numpy()\nnp_test = df_test_s.iloc[:,1:-3].to_numpy()\n\nprint(\"np_train.shape\", np_train.shape, \"np_test.shape\", np_test.shape)\n\n# \u30b7\u30fc\u30b1\u30f3\u30b9\u3054\u3068\u3092\u30de\u30c3\u30d7\u306b\u3059\u308b\nnp_train = np_train.reshape(int(np_train.shape[0]\/500),500,20)\nnp_test = np_test.reshape(int(np_test.shape[0]\/500),500,20)\n\n# \u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u6e96\u5099\ny_train = df_train_s.groupby('filename')['action_seq'].first()\n\nprint(\"np_train.shape\", np_train.shape, \"np_test.shape\", np_test.shape)","c9bdd4bb":"# \u884c\u3092\u30b7\u30d5\u30c8\u3059\u308b\nidx = np.random.permutation(len(np_train))\nnp_train = np_train[idx]\ny_train = y_train[idx]\n\n# \u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\uff08\u6570\u5024\u306b\u5909\u63db\uff09\u3057\u3066\u304a\u304d\u307e\u3059\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)","39f5cd7b":"# 500 x 20 \u306e\u201d\u753b\u50cf\u201d\u3092500 x 300\u306b\u3059\u308b\nnp_train_r = np.repeat(np_train, repeats=15, axis=2)\nnp_test_r = np.repeat(np_test, repeats=15, axis=2)\n\nprint(np_train_r.shape, np_test_r.shape)\n\n# \u89e3\u50cf\u5ea6\u4e0b\u3052\u3066300 x 300\u306e\u753b\u50cf\u306b\u3059\u308b\nnp_train_r_ = np.zeros((np_train_r.shape[0],300,300))\nnp_test_r_ = np.zeros((np_test_r.shape[0],300,300))\n\nfor n,i in enumerate(np_train_r):\n    np_train_r_[n,:,:] = resize(np_train_r[n,:,:], np_train_r_.shape[1:], anti_aliasing=True)\nfor n,i in enumerate(np_test_r):\n    np_test_r_[n,:,:] = resize(np_test_r[n,:,:], np_test_r_.shape[1:], anti_aliasing=True)\n\nprint(np_train_r_.shape, np_test_r_.shape)","23bcee1e":"\"\"\"\n# \u7c21\u5358\u306a\u30e2\u30c7\u30eb\u3092\u4f5c\u3063\u3066\u307f\u308b\n# \u21922epochs\u3067\u3059\u304c\u3001\u4f38\u3073\u306b\u304f\u3044\u30a4\u30e1\u30fc\u30b8\nclf = ak.ImageClassifier(overwrite=False, max_trials=1, seed=71)\n# Feed the image classifier with training data.\nclf.fit(np_train_r, y_train, epochs=1)\n\nmodel = clf.export_model()\nmodel.summary()\n\"\"\"","4c47d153":"# ResNet\u3067\u63a2\u7d22\u3057\u3066\u307f\u308b\ninput_node = ak.ImageInput()\noutput_node = ak.Normalization()(input_node)\noutput_node = ak.ImageAugmentation(horizontal_flip=False, vertical_flip=False)(input_node)\noutput_node1 = ak.ConvBlock()(output_node)\noutput_node2 = ak.ResNetBlock(version=\"v2\", pretrained=True)(output_node)\noutput_node = ak.Merge()([output_node1, output_node2])\noutput_node = ak.ClassificationHead(loss='categorical_crossentropy', metrics=['accuracy'])(output_node)\nclf = ak.AutoModel(\n    inputs=input_node, outputs=output_node, overwrite=False, max_trials=max_trials\n)\ncallbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)]\nclf.fit(np_train_r_, y_train, epochs=epochs, callbacks=callbacks)","c1958122":"model = clf.export_model()\nmodel.summary()","c83b48d9":"# \u30ed\u30fc\u30ab\u30eb\u306b\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\nmodel.save(\"model.h5\")\nfrom tensorflow.keras.models import load_model\nloaded_model = load_model(\"model.h5\", custom_objects=ak.CUSTOM_OBJECTS)","6dc4e731":"# \u4e88\u6e2c\ny_pred = model.predict(np_test_r_)\ny_pred[:2]","aeaa7e44":"y_pred_max = np.amax(y_pred, axis=1)\ny_pred_label = le.inverse_transform(np.argmax(y_pred, axis=1))","7280bfc9":"# ResNet\u30d6\u30ed\u30c3\u30af\u4f7f\u3063\u3066\u78ba\u7387\u3092\u51fa\u3059\u4ed5\u65b9\u306f\u78ba\u8a8d\u4e2d\u2192Unseen\u5bfe\u5fdc\u306f\u30b9\u30ad\u30c3\u30d7\ntest_preds_label_list = []\nfor l,m in zip(y_pred_label,y_pred_max):\n    if m > 0.5:\n        test_preds_label_list.append(l)\n    else:\n        # unseen\n        test_preds_label_list.append(\"jab-jab-bodyhook\")","7f3ac7fe":"# submission\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210\ndf_sub = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/sample_submission.csv')\ndf_sub['action_seq'] = y_pred_label\ndf_sub\n# \u51fa\u529b\u3057\u3066\u63d0\u51fa\u3057\u307e\u3059\ndf_sub.to_csv('submission.csv', index=False)","98e8c835":"df_sub['action_seq'].value_counts()","8128d18f":"# \u30c7\u30fc\u30bf\u30ed\u30fc\u30c9","85ae3ed2":"# \u30c7\u30fc\u30bf\u306e\u30b0\u30e9\u30d5\u5316"}}