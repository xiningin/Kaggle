{"cell_type":{"25a2eb9e":"code","0dd58e40":"code","b037f7db":"code","02d5056e":"code","b9c6bb8b":"code","26260eed":"code","88e76835":"code","647254d2":"code","ff1ae153":"code","02c480b9":"code","c9baee06":"code","58805477":"code","d906c4ef":"code","e6909f29":"code","38b1faab":"code","81614b3a":"code","0f31ac84":"code","608b8d77":"code","c241b84c":"code","bda950cf":"code","9ed82a57":"code","117ea906":"code","24c839a2":"code","1c6c3ec2":"markdown","de47fafc":"markdown","3719dd3f":"markdown","a963b647":"markdown","c88a01e4":"markdown","e91ca05d":"markdown","80094b46":"markdown","9b11af60":"markdown","b47774ca":"markdown","823ff26d":"markdown","ab6a6df9":"markdown","cb374f49":"markdown","4baa0511":"markdown","81d2fd72":"markdown","99ee6689":"markdown"},"source":{"25a2eb9e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport seaborn as sns","0dd58e40":"def transform_csv2pickle(path, usecols, dtype):\n    train = pd.read_csv(\n        path,\n        usecols=usecols,\n        dtype=dtypes\n    )\n    train.to_pickle('train.pkl')\n\n\npath = '..\/input\/ubiquant-market-prediction\/train.csv'\n\nbasecols = ['row_id', 'time_id', 'investment_id', 'target']\nfeatures = [f'f_{i}' for i in range(300)]\n\ndtypes = {\n    'row_id': 'str',\n    'time_id': 'uint16',\n    'investment_id': 'uint16',\n    'target': 'float32',\n}\nfor col in features:\n    dtypes[col] = 'float32'\n\n# transform_csv2pickle(path, basecols+features, dtypes)","b037f7db":"%%time\ntrain = pd.read_pickle('..\/input\/ump-train-picklefile\/train.pkl')","02d5056e":"start_mem = train.memory_usage().sum() \/ 1024**2\n\nfor col in train.columns:\n    col_type = train[col].dtype\n\n    if col_type != object:\n        c_min = train[col].min()\n        c_max = train[col].max()\n        if str(col_type)[:3] == 'int':\n            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                train[col] = train[col].astype(np.int8)\n            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                train[col] = train[col].astype(np.int16)\n            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                train[col] = train[col].astype(np.int32)\n            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                train[col] = train[col].astype(np.int64)  \n        else:\n            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                train[col] = train[col].astype(np.float16)\n            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                train[col] = train[col].astype(np.float32)\n            else:\n                train[col] = train[col].astype(np.float64)\n    else:\n        train[col] = train[col].astype('category')\n\nend_mem = train.memory_usage().sum() \/ 1024**2\nprint('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\nprint('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))","b9c6bb8b":"# DATA_PATH = Path('..\/input\/ump-train-picklefile')\n# SAMPLE_TEST_PATH = Path('..\/input\/ubiquant-market-prediction')\n# !ls $SAMPLE_TEST_PATH","26260eed":"display(train.info())\ndisplay(train.head())","88e76835":"len(train)","647254d2":"# row_id\n# time_id\n# investment_id\n# target\n# f_0 - f_299\n\ntrain.columns","ff1ae153":"# Groupby time\n# target values in Specific time[380 - 550] have large Volatility\ndic = {}\nfor i in range(0, 1220):\n    train_time = train['target'][train['time_id'] == i].mean()\n    dic[f'{i}'] = train_time\n\n\ntime_df = pd.Series(dic)\ndel dic\n\ntime_df.plot()\nplt.show()","02c480b9":"# Groupby Investment_id\ndic = {}\nfor i in list(set(list(train['investment_id']))):\n    train_invest_id = train['target'][train['investment_id'] == i].mean()\n    dic[f'{i}'] = train_invest_id\n\n\ntrain_invest_id_df = pd.Series(dic)\ndel dic\n\ntrain_invest_id_df.plot()\nplt.show()","c9baee06":"# Correlation\ndic = {}\n\nfor i in range(0, 300):\n    corr_f = train[['target', f'f_{i}']].corr().iloc[0,1]\n    print(f'target & f_{i} Correlation is {corr_f}')\n    dic[f'f_{i}'] = corr_f\n\ndel dic","58805477":"# Correlation - investment_id = 0\ndic = {}\n\nfor i in range(0, 300):\n    corr_f = train[['target', f'f_{i}']][train['investment_id'] == 0].corr().iloc[0,1]\n    #print(f'target & f_{i} Correlation is {corr_f}')\n    dic[f'f_{i}'] = corr_f\n\nsorted_dict = sorted(dic.items(), key = lambda item: item[1])\n\nplt.figure(figsize=(5,8))\nsns.heatmap(pd.DataFrame(sorted_dict[1:10]).set_index(0).head(30), annot=True)\n\ndel dic\ndel sorted_dict","d906c4ef":"# Correlation - investment_id = 1\ndic = {}\n\nfor i in range(0, 300):\n    corr_f = train[['target', f'f_{i}']][train['investment_id'] == 1].corr().iloc[0,1]\n    #print(f'target & f_{i} Correlation is {corr_f}')\n    dic[f'f_{i}'] = corr_f\n\nsorted_dict = sorted(dic.items(), key = lambda item: item[1])\n\nplt.figure(figsize=(5,8))\nsns.heatmap(pd.DataFrame(sorted_dict[1:10]).set_index(0).head(30), annot=True)\n\ndel dic\ndel sorted_dict","e6909f29":"# Correlation - investment_id = 2\ndic = {}\n\nfor i in range(0, 300):\n    corr_f = train[['target', f'f_{i}']][train['investment_id'] == 2].corr().iloc[0,1]\n    #print(f'target & f_{i} Correlation is {corr_f}')\n    dic[f'f_{i}'] = corr_f\n\nsorted_dict = sorted(dic.items(), key = lambda item: item[1])\n\nplt.figure(figsize=(5,8))\nsns.heatmap(pd.DataFrame(sorted_dict[1:10]).set_index(0).head(30), annot=True)\n\ndel dic\ndel sorted_dict","38b1faab":"target_invest = train[['target', 'investment_id']].copy()\ntarget_invest_corr = target_invest.corr()\n\nsns.set_theme()\nsns.heatmap(target_invest_corr, annot=True)\n\ndel target_invest\ndel target_invest_corr","81614b3a":"import lightgbm\nimport xgboost\nfrom sklearn.model_selection import train_test_split","0f31ac84":"x = train.drop(['row_id', 'target'], axis=1).copy()\ny = train.target\ndisplay(x.head())\ndisplay(y.head())","608b8d77":"line = len(train)\/\/10\nx_test = x[:line]\ny_test = y[:line]\nx_val = x[line:line*2]\ny_val = y[line:line*2]\nx_train = x[line*2:]\ny_train = y[line*2:]\n\nprint(f'train : {len(x_train)} \/ val : {len(x_val)} \/ test : {len(x_test)}')","c241b84c":"train_ds = lightgbm.Dataset(x_train, label = y_train) \nval_ds = lightgbm.Dataset(x_val, label = y_val) ","bda950cf":"params = {'learning_rate': 0.01, \n          'max_depth': 5, \n          'objective': 'regression', \n          'metric': 'mse', \n          'is_training_metric': True, \n          'num_leaves': 144}","9ed82a57":"model = lightgbm.train(params, train_ds, 100, val_ds)","117ea906":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\n\nprediction = model.predict(x_test)\nmse = mean_squared_error(y_test, prediction)\nprint(f'model mse is {mse}')","24c839a2":"import ubiquant\nenv = ubiquant.make_env()  \niter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df.drop(['row_id'], axis=1, inplace=True)\n    pred = model.predict(test_df)\n    sample_prediction_df['target'] = pred\n    env.predict(sample_prediction_df) ","1c6c3ec2":"Ok. Lets go to make Baseline \ud83c\udf88","de47fafc":"# **Baseline (LGBM & xgboost)**","3719dd3f":"**Target Mean**\n\nLet's see how target values change","a963b647":"# **\u2714 Data Loading & Import**","c88a01e4":"**Step 1 : just Correlation & Target**\n\n**Check Correlation target & f_0 - f_300**\n\nhumm... can't find something special variable. \nthey all have just low correlation with target","e91ca05d":"# **\ud83e\udd1e Correlation**","80094b46":"This notebook introduces dataset and code converted from train.csv to pickle file.\nIt takes less than a minute to load all the data, and the data size reduce from 18.5GB to 3.6GB.\n\ndataset URL : [https:\/\/www.kaggle.com\/columbia2131\/ump-train-picklefile](https:\/\/www.kaggle.com\/columbia2131\/ump-train-picklefile)","9b11af60":"**Step 2 : Correlation & Target -> Groupby investment_id**","b47774ca":"**LGBM model**","823ff26d":"split train\/test -> train\/val\/test","ab6a6df9":"humm... what the fuxk. \ud83d\ude2b\ud83d\ude28\ud83e\udd2f\ud83e\udd75\ud83d\ude31\ud83d\ude21\ud83d\udc7f","cb374f49":"each investment_id have different target&f_i relationship.","4baa0511":"# **\ud83d\ude44 Simple EDA**","81d2fd72":"**Step 3 : target's relationship with investment_id**","99ee6689":"**About train...**"}}