{"cell_type":{"93a24fc7":"code","f0f130ad":"code","627d1add":"code","8f6830a7":"code","c3d2a431":"code","22d09425":"code","d8d1c297":"code","e6efac07":"code","94f8ef10":"code","20a81893":"code","6fb82837":"code","2886f737":"markdown","264947a7":"markdown","c5a45737":"markdown","fa8755cb":"markdown","c0f5f233":"markdown","3dc1665e":"markdown","b2b76391":"markdown","c1b65c6d":"markdown","263a2a56":"markdown","270e184a":"markdown","2ce3e0a2":"markdown","d91d22d0":"markdown","28532d83":"markdown","ff023247":"markdown"},"source":{"93a24fc7":"# Libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as ms\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n%matplotlib inline\n\n#Data\ndf = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\n\n#Looking at the Data\ndf.head(10)","f0f130ad":"#Simple And Default Histogram\nplt.figure(figsize=(12,10))\nplt.hist(df['platelets'],bins=30)\nplt.ylabel('Frequency')\nplt.xlabel('Platelets');","627d1add":"#Improved Visualization\nplt.figure(figsize=(15,10))\n\n#Using a low alpha and orange color\nsns.distplot(df['platelets'],ax=plt.gca(),color='orange',fit=norm,kde_kws={'linewidth':2})\nplt.tick_params(axis='both', which='major', labelsize=13) #adjusting ticks \n\nmu,sigma = norm.fit(df['platelets']) # adding additional information to increase Data Ink Ratio\nplt.legend(['Normal dist. $\\mu=$ {:.2f} and $\\sigma=$ {:.2f}'.format(mu, sigma)],\n            loc='best',frameon=False,fontsize=13)\n    \nsp = plt.gca().spines\nsp['top'].set_visible(False)\nsp['right'].set_visible(False)\n\nplt.ylabel('Frequency',fontsize=14,labelpad=10)\nplt.xlabel('Platelets (Counts)',fontsize=14,labelpad=10)\nplt.title('Platelets Distribution',fontsize=17,pad=7)\n\nplt.grid( alpha=0.5,color='lightslategrey');\n# Data ink is reduced by adding a grid but in a plot like \n#this we cannot directly label the bar and hence grid","8f6830a7":"#Making Canvas\ncanv, axs = plt.subplots(1,2)\ncanv.set_size_inches(20,10)\ncanv.tight_layout(pad=4)\n\n#First 'Before' Plot\nplt.sca(axs[0])\nplt.hist(df['platelets'],bins=30)\nplt.ylabel('Frequency')\nplt.xlabel('Platelets')\nplt.title('Platelets Distribution W\/O Using Heuristics')\n\n#Second 'After' Plot \n\nplt.sca(axs[1])\nsns.distplot(df['platelets'],ax=plt.gca(),color='orange',fit=norm,kde_kws={'linewidth':2.5}) \nplt.tick_params(axis='both', which='major', labelsize=13)\n\nmu,sigma = norm.fit(df['platelets']) \nplt.legend(['Normal dist. $\\mu=$ {:.2f} and $\\sigma=$ {:.2f}'.format(mu, sigma)],\n            loc='best',frameon=False,fontsize=13)\n    \nsp = plt.gca().spines\nsp['top'].set_visible(False)\nsp['right'].set_visible(False)\n\nplt.ylabel('Frequency',fontsize=14,labelpad=10)\nplt.xlabel('Platelets (Counts)',fontsize=14,labelpad=10)\nplt.title('Platelets Distribution Using Heuristics',fontsize=17,pad=7)\n\nplt.grid( alpha=0.5,color='lightslategrey');","c3d2a431":"df.head(2)","22d09425":"from sklearn.preprocessing import MinMaxScaler\n\ncols = ['creatinine_phosphokinase','ejection_fraction','platelets','serum_sodium'] #Continous Features\ndf_cont = df[cols]\n\nscale = MinMaxScaler(feature_range=(0,12))#Scaling to range of [0,12]\nscaled = scale.fit_transform(df_cont)\n\ndf_sc = pd.DataFrame(data=scaled,columns=cols)\ndf_sc.head(5)","d8d1c297":"#Making Canvas\ncanv, axs = plt.subplots(2,2)\ncanv.set_size_inches(20,18)\ncanv.tight_layout(pad=10)\n\n#Plotting\n\ncnt = 0\nfor rw in axs:   # Little Bit of Automation is not bad right!!!\n    for ax in rw:\n        plt.sca(ax)\n        sns.distplot(df_sc[cols[cnt]],ax=plt.gca(),color='orange',\n                     fit=norm,kde_kws={'linewidth':2.5}) \n        plt.tick_params(axis='both', which='major', labelsize=13)\n\n        mu,sigma = norm.fit(df_sc[cols[cnt]])  \n        plt.legend(['Normal dist. $\\mu=$ {:.2f} and $\\sigma=$ {:.2f}'.format(mu, sigma)],\n            loc=1,frameon=False,fontsize=13)\n    \n        sp = plt.gca().spines\n        sp['top'].set_visible(False)\n        sp['right'].set_visible(False)\n\n        plt.ylabel('Frequency',fontsize=14,labelpad=10)\n        plt.xlabel('{}'.format(cols[cnt]),fontsize=14,labelpad=10)\n        plt.title('{} Distribution Using Heuristics'.format(cols[cnt]),fontsize=17,pad=10)\n\n        plt.grid( alpha=0.5,color='lightslategrey');\n        cnt += 1","e6efac07":"df['time'] = pd.cut(df['time'],bins=5)\nfrom sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder().fit(df['time'])\ndf['time'] = lbl.transform(df['time'])","94f8ef10":"ccol = ['anaemia','diabetes','high_blood_pressure','sex','smoking','time']","20a81893":"pt = pd.pivot_table(df,index='DEATH_EVENT',columns=ccol[2],values='smoking',\n                    aggfunc ='count').fillna(0)\n\n#Making Canvas\ncanv, axs = plt.subplots(1,2)\ncanv.set_size_inches(20,10)\ncanv.tight_layout(pad=4)\n\n#First 'Don't' plot\nplt.sca(axs[0])\nplt.bar(df[ccol[2]].value_counts().index-0.4,np.array(pt.query('DEATH_EVENT==[\"0\"]'))[0],\n        width=0.4,align='center',label='Not Dead')\nplt.bar(df[ccol[2]].value_counts().index,np.array(pt.query('DEATH_EVENT==[\"1\"]'))[0],\n        width=0.4,align='center',label='Dead')\nplt.xticks(df[ccol[2]].value_counts().index-0.2,df[ccol[2]].value_counts().index)\nplt.ylabel('Number of Patients',fontsize=14)\nplt.title(ccol[2],fontsize=14)\n\n#Second Do's Plot\nplt.sca(axs[1])\nplt.title(ccol[2],fontsize=14)\n        \nbars = plt.bar(df[ccol[2]].value_counts().index-0.4,\n        np.array(pt.query('DEATH_EVENT==[\"0\"]'))[0],\n      width=0.4,align='center',label='Not Dead',\n        color='lightslategrey',alpha=0.9)\n        \nfor bar,value in zip(bars,np.array(pt.query('DEATH_EVENT==[\"0\"]'))[0]):\n    plt.text((bar.get_x()+0.158),(bar.get_height()-5),'{}'.format(value),\n             color='white',fontsize=18)\n    \nbars = plt.bar(df[ccol[2]].value_counts().index,\n        np.array(pt.query('DEATH_EVENT==[\"1\"]'))[0],\n        width=0.4,align='center',label='Dead',\n        color='orange',alpha=0.8)\n        \nfor bar,value in zip(bars,np.array(pt.query('DEATH_EVENT==[\"0\"]'))[0]):\n    plt.text((bar.get_x()+0.158),(bar.get_height()-5),'{}'.format(value),\n             color='white',fontsize=18)\n        \nplt.legend(fontsize=12,frameon=False)\nplt.xticks(df[ccol[2]].value_counts().index-0.2,df[ccol[2]].value_counts().index)\nplt.ylabel('Number of Patients',fontsize=14)\n        \nfor key,spine in plt.gca().spines.items():\n    spine.set_visible(False)\n        \nplt.tick_params(axis='x', which='both',length=0,labelsize=12)\nplt.tick_params(axis='y', which='both',length=0,labelsize=0);","6fb82837":"cnt = 0\ncanv , axs = plt.subplots(2,3,sharey=False)\ncanv.set_size_inches(20,18)\ncanv.tight_layout(pad=5)\n\nfor row in axs:   # Automation is Awesome!!!!!\n    for axis in row:\n        try:\n            if ccol[cnt] != 'smoking':\n                pt = pd.pivot_table(df,index='DEATH_EVENT',columns=ccol[cnt],values='smoking'\n                                    ,aggfunc ='count').fillna(0)\n            else:\n                pt = pd.pivot_table(df,index ='DEATH_EVENT',columns=ccol[cnt],\n                                    values ='diabetes',\n                                    aggfunc ='count').fillna(0)\n        except:\n            continue\n        \n        plt.sca(axis)\n        plt.title(ccol[cnt],fontsize=14)\n        \n        bars = plt.bar(df[ccol[cnt]].value_counts().index-0.4,\n                np.array(pt.query('DEATH_EVENT==[\"0\"]'))[0],\n                width=0.4,align='center',label='Not Dead',\n                color='lightslategrey',alpha=0.9)\n        \n        for bar,value in zip(bars,np.array(pt.query('DEATH_EVENT==[\"0\"]'))[0]):\n            plt.text((bar.get_x()+0.11),(bar.get_height()+1.1),'{}'.format(value),\n                     color='k',fontsize=14)\n        \n        bars = plt.bar(df[ccol[cnt]].value_counts().index,\n                np.array(pt.query('DEATH_EVENT==[\"1\"]'))[0],\n                width=0.4,align='center',label='Dead',\n                color='orange',alpha=0.7)\n        \n        for bar,value in zip(bars,np.array(pt.query('DEATH_EVENT==[\"1\"]'))[0]):\n            plt.text((bar.get_x()+0.11),(bar.get_height()+1.1),'{}'.format(value),\n                     color='k',fontsize=14)\n        \n        plt.legend(fontsize=12,frameon=False)\n        plt.xticks(df[ccol[cnt]].value_counts().index-0.2,df[ccol[cnt]].value_counts().index)\n        if cnt == 0 or cnt == 3:\n            plt.ylabel('Number of Patients',fontsize=14)\n        \n        for key,spine in plt.gca().spines.items():\n            spine.set_visible(False)\n        \n        plt.tick_params(axis='x', which='both',length=0,labelsize=12)\n        plt.tick_params(axis='y', which='both',length=0,labelsize=0)\n        cnt+=1","2886f737":"## Making Final Visualization Of Continous Feature Distribution","264947a7":"### Comparing Do's and Don't\n### You can see why the later is better","c5a45737":"### This Dataset Contains Both Categorical and Continous Features Lets work with Continous Features\n\n## Continous Features :\n\n- First Lets take a look at the default distribution plot and then how can we improve it","fa8755cb":"### According to the Principles\n\n1. Data Ink Ratio is not bad in this Graph, Still can be Improved by adding additional and relevant Information\n2. The Whole Point of making the Visualzation easy to the eye and Beautiful is to remove any unnecessary Aspect (Like in this case 'The Boundaries') of the graph, So that viewer's attention will can focus on the Data \n3. We will remove the upper and right side boundaries and then add a grid to track values easily and lastly and some other relevant information\n4. Best way to make the Visualization easy on the eye is to use transperancy(By Using 'alpha' parameter of Matplotlib) and using a calming colors\n5. Calming colors are those colors with which humans interact regularly like light blue, orange, grey etc. ","c0f5f233":"### Converting time to Bin\n","3dc1665e":"## Data-ink ratio by Edward Tufte :\n\n- Before I dive into the \u201cFive Qualities of Great Visualizations,\u201d there\u2019s another related concept that I want to cover: data-ink ratio, introduced by Edward Tufte in The Visual Display of Quantitative Information.\n\n![Data Ink Ratio](https:\/\/miro.medium.com\/max\/2280\/1*4A4CIVrU_lJCsCJBwmTpFQ.png)\n\n- Tufte defines the data-ink ratio as the amount of data-ink divided by the total ink required to print a graphic. Now, I don\u2019t think he asks us to measure the amount of ink laid down on the page. Instead, Tufte suggests we remove those elements that don\u2019t add new information to the graphic.\n\n- Ex : (The Most Famous Example Of Data Ink Ratio was Given By [Dark Horse Analytics](https:\/\/www.darkhorseanalytics.com\/))\n     ![Data Ink](https:\/\/lukebeacon.com.au\/wp-content\/uploads\/2020\/07\/Capture-1060x299.png)","b2b76391":"## Final Categorical Visualization","c1b65c6d":"## Five Qualities of Great Visualizations By Alberto Cairo\n\n### 1. Truthful\n-> We need to advocate for true data. Truth based on data analysis can be subjective. But as data scientists, we should make our best effort to protect the truth. These methods help you achieve truthfulness\n\n### 2. Functional\n-> Consider whether your visualization is functional or not. The data-ink ratio can help increase the functionality of a visualization. There are many heuristics for increasing functionality.\n\n### 3. Beautiful\n-> It might sound like a weird quality, but beauty is important to data visualization. To achieve beauty, you need to know your audience. \u201cBeauty is in the eye of the beholder\u201d is a common but accurate expression.\n\n### 4. Insightful\n-> A good visualization doesn\u2019t merely replicate data from tables or files. It displays relevant data in a visual format that reveals trends or relationships. When insights are successfully visualized, the viewer gets an \u201caha!\u201d moment.\n\n### 5. Enlightening\nAlthough it sounds similar, enlightening is a different concept from insightful. Cairo says this quality is composed of the previous four: truthful, functional, beautiful, and insightful.","263a2a56":"# Data Visualizations\n\n### Importing Libraries and Data","270e184a":"## Categorical Features :\nUsing the same principle making plots for categorical data","2ce3e0a2":"## Looking at the Diffrence :\n### You Can Decide Which One is Better","d91d22d0":"## This Notebook is a Work in Progress, Upvote if you want to see more\n## If you have an idea, Share and I will add it as soon as possible\n## Feedback is Appreciated\n## And As Always Thank You For Scrolling","28532d83":"## Now Scaling all the Continous Variable to a common scale and plotting all distributions","ff023247":"# In this EDA, I'll Share some Principles\/Practices\/Heuristics that has gained valued feedback and Praise in the Data Science Community\n\n### All the below mentioned Heuristics are developed either by [Alberto Cairo](https:\/\/www.google.com\/search?q=alberto+cairo) or [Edward Tufte](https:\/\/www.google.com\/search?q=edward+tufte)"}}