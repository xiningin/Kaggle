{"cell_type":{"6b3cf47a":"code","0af8fb53":"code","0785bbdd":"code","9f83d2a1":"code","2f4630ff":"code","1c80f613":"code","1b883cc6":"code","b3ee4067":"code","a980fbd0":"code","c196e516":"code","db6a63d5":"code","6e874e24":"code","cdf4f230":"code","70a66c2d":"code","ab16bc6d":"code","7ac7c61c":"code","52ed43a5":"code","75d62cd2":"code","3e91525f":"code","e76754cc":"code","27848933":"code","8e0e4534":"code","ee9ebc67":"code","c45fd958":"code","f0a9a95f":"code","2f91fe34":"code","4c961667":"code","8d8ae2cf":"code","12f2f901":"code","b76e0ceb":"code","67ec7576":"code","2ec1abde":"code","1c55ba7f":"code","2d1dac6d":"code","1e2bf936":"code","7f4676f4":"code","48cdd2c0":"code","f7735563":"code","6a1631db":"code","e458fba5":"code","2643cada":"code","17dbf491":"code","2a2d6568":"code","4867c5c0":"markdown","1e6e33e3":"markdown","8c975c50":"markdown","5527e80a":"markdown","227ffaeb":"markdown","27641d99":"markdown","e088b6ed":"markdown","fbaf8bff":"markdown","6b679912":"markdown","5c8a4849":"markdown","3da712f0":"markdown","04dda556":"markdown","27851c6d":"markdown","16488f78":"markdown","0671890a":"markdown","3f2bb8f2":"markdown"},"source":{"6b3cf47a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\n\nfrom time import time\n\nfrom collections import Counter\nfrom itertools import combinations\n\nfrom sklearn.model_selection import cross_val_score,cross_validate, train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score, make_scorer\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.decomposition import PCA\n\nfrom mlxtend.classifier import StackingCVClassifier, StackingClassifier\n# import lightgbm\nfrom lightgbm import LGBMClassifier, plot_importance\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n\nfrom tqdm import tqdm\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0af8fb53":"X = pd.read_csv(\"..\/input\/learn-together\/train.csv\", index_col='Id')\nX_test = pd.read_csv(\"..\/input\/learn-together\/test.csv\", index_col='Id')\n\ny = X['Cover_Type'] # this is the target\nX = X.drop('Cover_Type', axis = 1)\n\ntest_index = X_test.index\nnum_train = len(X)\n\nprint('Train set shape : ', X.shape)\nprint('Test set shape : ', X_test.shape)\n\n#renaming to avoid long names in the feature engineering\nX.rename({'Horizontal_Distance_To_Roadways':'HDR',\n              'Horizontal_Distance_To_Hydrology':'HDH',\n              'Horizontal_Distance_To_Fire_Points':'HDF',\n              'Vertical_Distance_To_Hydrology':'VDH'}, axis=\"columns\", inplace=True)\nX_test.rename({'Horizontal_Distance_To_Roadways':'HDR',\n              'Horizontal_Distance_To_Hydrology':'HDH',\n              'Horizontal_Distance_To_Fire_Points':'HDF',\n              'Vertical_Distance_To_Hydrology':'VDH'}, axis=\"columns\", inplace=True)\n\n\ncolumns = X.columns\ncategorial_feat = [] \nX.head()\n\n","0785bbdd":"# Helper function to generate submission files.\ndef to_submission(preds, file_name):\n    output = pd.DataFrame({'Id': test_index,\n                           'Cover_Type': preds})\n    output.to_csv(file_name+'.csv', index=False)\n","9f83d2a1":"# count = { 1: 0.37062,\n#  2: 0.49657,\n#  3: 0.05947,\n#  4: 0.00106,\n#  5: 0.01287, \n#  6: 0.02698, \n#  7: 0.03238} \n# weight = [count[x]\/(sum(count.values())) for x in range(1,7+1)]\n# class_weight_lgbm = {i: v for i, v in enumerate(weight)}  #LGB uses a different way of counting..\n","2f4630ff":"# checking score with the public test distribution https:\/\/www.kaggle.com\/nadare\/eda-feature-engineering-and-modeling-4th-359\n\n# def imbalanced_accuracy_score(y_true, y_pred):\n#     return accuracy_score(y_true, y_pred, sample_weight=[weight[x] for x in y_true-1])\n\n# imbalanced_accuracy_scorer = make_scorer(imbalanced_accuracy_score, greater_is_better=True)\n\n# def imbalanced_cross_val_score(clf, X, y, cfg_args={}, fit_params={}, cv=5):\n#     return cross_val_score(clf, X, y, scoring= imbalanced_accuracy_scorer, cv=cv, n_jobs=-1, fit_params=fit_params )","1c80f613":"X.head()","1b883cc6":"X_test.head()","b3ee4067":"print('Missing Label? ', y.isnull().any())\nprint('Missing train data? ', X.isnull().any().any())\nprint('Missing test data? ', X_test.isnull().any().any())","a980fbd0":"print (X.dtypes.value_counts())\nprint (X_test.dtypes.value_counts())","c196e516":"#transform Soil_Type into categorial\ndef categorify(df, col_string_search, remove_original=False):\n    for key_str in col_string_search:\n        new_col_name = key_str+'_cat'\n        df[new_col_name]=0\n        for col in columns:\n            if ~str(col).find(key_str):\n                df[new_col_name]= df[new_col_name]+int(str(col).lstrip(key_str))*df[col]\n                if remove_original:\n                    df.drop(col, axis=1, inplace=True)\n#         df[new_col_name] = df[new_col_name].astype('category')\n    return df","db6a63d5":"cols_to_categorify = ['Soil_Type', 'Wilderness_Area']\nX = categorify(X, cols_to_categorify, remove_original=False)\nX_test = categorify(X_test, cols_to_categorify, remove_original=False)\n\n#keeping track of the categorial features\ncategorial_feat.append('Soil_Type_cat')\ncategorial_feat.append('Wilderness_Area_cat')\n\nX_test.head()","6e874e24":"X.describe()","cdf4f230":"# for col in X.columns:\nplt.figure(figsize=(15,5))\nsns.distplot(X.Hillshade_3pm)\nplt.show()","70a66c2d":"print(X.Hillshade_3pm[(X.Hillshade_3pm<130).to_numpy() &  (X.Hillshade_3pm>120).to_numpy()].value_counts())\nprint((X.Hillshade_3pm==0).sum())\nprint((X_test.Hillshade_3pm==0).sum())\n","ab16bc6d":"# checking which features correlates with Hillshade_3pm\ncorr = X[X.Hillshade_3pm!=0].corr()\nplt.figure(figsize=(12,12))\nsns.heatmap(corr,annot=True)","7ac7c61c":"#replacing the zeros for better guess, mainly to avoid zeros in the feature engineering and fake outliers. \nall_data = X.append(X_test)\n\ncols_for_HS = ['Aspect','Slope', 'Hillshade_9am','Hillshade_Noon']\nHS_zero = all_data[all_data.Hillshade_3pm==0]\nHS_zero.shape\n\nHS_train = all_data[all_data.Hillshade_3pm!=0]\n# res = cross_val_score(RandomForestRegressor(n_estimators=100), HS_train.drop('Hillshade_3pm',axis=1), HS_train.Hillshade_3pm, n_jobs=-1, verbose=True)\n# print(res) --> Output:  #[0.9996774  0.99989463 0.9999186 ]\n##actually, the CV is so close to perfect that there is actually no new information here..keeping it for .. sanity ?\n\nrf_hs = RandomForestRegressor(n_estimators=100).fit(HS_train[cols_for_HS], HS_train.Hillshade_3pm)\nout = rf_hs.predict(HS_zero[cols_for_HS]).astype(int)\nall_data.loc[HS_zero.index,'Hillshade_3pm'] = out\n\nX['Hillshade_3pm']= all_data.loc[:num_train,'Hillshade_3pm']\nX_test['Hillshade_3pm']= all_data.loc[num_train:,'Hillshade_3pm']","52ed43a5":"# Add PCA features\n\nt = time()\n\npca = PCA(n_components=0.99).fit(all_data)\ntrans = pca.transform(all_data)\nprint(trans.shape)\n\nfor i in range(trans.shape[1]):\n    col_name= 'pca'+str(i+1)\n    X[col_name] = trans[:num_train, i]\n    X_test[col_name] = trans[num_train:, i]\n\nprint('duration: '+ str(time()-t))\n","75d62cd2":"# Adding Gaussian Mixture features to perform some unsupervised learning hints from the full data\n# https:\/\/www.kaggle.com\/stevegreenau\/stacking-multiple-classifiers-clustering\n\nt = time()\ncomponents = 10 # TODO check other numbers.  with 10 labels there are a few ones with 0 importances. \ngmix = GaussianMixture(n_components=components) \ngaussian = gmix.fit_predict(StandardScaler().fit_transform(all_data))\n\nX['GM'] = gaussian[:num_train]\nX_test['GM'] = gaussian[num_train:]\n\ncategorial_feat.append('GM')\n\nfor i in range(components):\n    X['GM'+str(i)] = gaussian[:num_train]==i  \n    X_test['GM'+str(i)] = gaussian[num_train:]==i \n\nprint('duration: '+ str(time()-t))","3e91525f":"X.head()","e76754cc":"del all_data\ngc.collect()","27848933":"# Helper function to generate some basic FE\ndef quick_fe(df, cols, operations, max_combination=2):\n    \n    if max_combination>=2:\n        for col1, col2 in combinations(cols, 2):\n            for ope in operations:\n                if ope=='add': df[col1 + \"_add_\" + col2] = df[col1]+df[col2]\n                elif ope=='minus': df[col1 + \"_minus_\" + col2] = df[col1]-df[col2]\n                elif ope=='minabs': df[col1 + \"_minabs_\" + col2] = abs(df[col1]-df[col2])\n                elif ope=='time': df[col1 + \"_time_\" + col2] = df[col1]*df[col2]\n    if max_combination>=3:\n        for col1, col2, col3 in combinations(cols, 3):\n            for ope in operations:\n                if ope=='add': df[col1 + \"_add_\" + col2 + \"_add_\" + col3] = df[col1]+df[col2]+df[col3]\n                elif ope=='time': df[col1 + \"_time_\" + col2+ \"_time_\" + col3] = df[col1]*df[col2]*df[col3]\n    return df\n\nX.head()","8e0e4534":"\n# group all the FE features\ndef feature_eng(dataset):\n    # https:\/\/www.kaggle.com\/nadare\/eda-feature-engineering-and-modeling-4th-359#nadare's-kernel\n    #https:\/\/www.kaggle.com\/lukeimurfather\/adversarial-validation-train-vs-test-distribution\n    #https:\/\/www.kaggle.com\/evimarp\/top-6-roosevelt-national-forest-competition\n    \n    dataset['Distance_hyd'] = (dataset['HDH']**2+dataset['VDH']**2)**0.5\n\n    cols_to_combine = ['HDH', 'HDF', 'HDR']\n    dataset = quick_fe(dataset, cols_to_combine, ['add','time','minus', 'minabs'], max_combination=3)\n\n    cols_to_combine = ['Elevation', 'VDH']\n    dataset = quick_fe(dataset, cols_to_combine, ['add','time','minus', 'minabs'], max_combination=2)\n\n    dataset['Mean_Distance']=(dataset.HDF + \n                               dataset.Distance_hyd + \n                               dataset.HDR) \/ 3 \n    dataset['Elevation_Adj_distanceH'] = dataset['Elevation'] - 0.25*dataset['Distance_hyd']\n    dataset['Elevation_Adj_distanceV'] = dataset['Elevation'] - 0.19*dataset['HDH']\n\n    \n    # Hillshade\n    hillshade_col = [\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]\n    dataset = quick_fe(dataset,hillshade_col, ['add','minus'], max_combination=3)\n\n    dataset[\"Hillshade_std\"] = dataset[hillshade_col].std(axis=1)\n    dataset[\"Hillshade_max\"] = dataset[hillshade_col].max(axis=1)\n    dataset[\"Hillshade_min\"] = dataset[hillshade_col].min(axis=1)\n   \n    #Aspect\n    dataset['Aspect'] = dataset['Aspect'].astype(int) % 360\n    \n    from bisect import bisect\n    cardinals = [i for i in range(45, 361, 90)]\n    points = ['N', 'E', 'S', 'W']\n    dataset['Cardinal'] = dataset.Aspect.apply(lambda x: points[bisect(cardinals, x) % 4])\n    dataset.loc[:,'North']= dataset['Cardinal']=='N'\n    dataset.loc[:,'East']= dataset['Cardinal']=='E'\n    dataset.loc[:,'West']= dataset['Cardinal']=='W'\n    dataset.loc[:,'South']= dataset['Cardinal']=='S'\n    \n    dataset['Sin_Aspect'] = np.sin(np.radians(dataset['Aspect'])) # not important feature at all\n    dataset['Cos_Aspect'] = np.cos(np.radians(dataset['Aspect']))\n    \n    dataset['Slope_hyd'] = np.arctan(dataset['VDH']\/(dataset['HDH']+0.001))\n    dataset.Slope_hyd=dataset.Slope_hyd.map(lambda x: 0 if np.isinf(x) else x) # remove infinite value if any\n    \n    dataset['Sin_Slope_hyd'] = np.sin(np.radians(dataset['Slope_hyd']))\n    dataset['Cos_Slope_hyd'] = np.cos(np.radians(dataset['Slope_hyd']))\n\n    dataset['Sin_Slope'] = np.sin(np.radians(dataset['Slope'])) # not important feature at all\n    dataset['Cos_Slope'] = np.cos(np.radians(dataset['Slope']))\n    \n    # extremely stony = 4, very stony = 3, stony = 2, rubbly = 1, None = 0\n    Soil_to_stony = [4, 3, 1, 1, 1, 2, 0, 0, 3, 1,\n                1, 2, 1, 0, 0, 0, 0, 0, 0, 0,\n                0, 4, 4, 4, 4, 4, 3, 4, 4, 4, \n                4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n    dataset['Stonyness'] = [Soil_to_stony[x] for x in (dataset['Soil_Type_cat'].astype(int)-1)]\n    dataset.loc[:,'Extremely_Stony']= dataset['Stonyness']==4\n    dataset.loc[:,'Very_Stony']= dataset['Stonyness']==3\n    dataset.loc[:,'Stony']= dataset['Stonyness']==2\n    dataset.loc[:,'Rubbly']= dataset['Stonyness']==1\n    dataset.loc[:,'Stony_NA']= dataset['Stonyness']==0\n    \n    return dataset\n\ncategorial_feat.append('Stonyness')\ncategorial_feat.append('Cardinal')\n\nX = feature_eng(X)\nX_test = feature_eng(X_test)\ncolumns = X.columns","ee9ebc67":"# Frequency encoding  <- Heard it helps the LightGBM.\n#https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/108575#latest-628340\ndef freq_encoding(df_train, df_test, cols_to_encode):\n    df = pd.concat([df_train[cols_to_encode], df_test[cols_to_encode]],axis=0)\n    for col in cols_to_encode:\n        new_name = col+'_counts'\n        temp = df[col].value_counts().to_dict()\n        df[new_name] = df[col].map(temp)\n        df_train[new_name] = df.loc[:len(df_train),new_name]\n        df_test[new_name] = df.loc[len(df_train):,new_name]\n    return df_train, df_test","c45fd958":"selected_cols = categorial_feat #['Soil_Type_cat', 'Wilderness_Area_cat', 'Stonyness', 'Cardinal']\nX, X_test = freq_encoding(X, X_test, selected_cols)","f0a9a95f":"droping_list = categorial_feat# [col for col in X.columns if ~str(col).find('Soil_Type')]\n\nX.drop(droping_list, axis=1, inplace = True)\nX_test.drop(droping_list, axis=1, inplace = True)\n\ncolumns = X.columns\nX_test.head()","2f91fe34":"def mem_reduce(df):\n    for col in df.columns:\n        if df[col].dtype=='float64': \n            df[col] = df[col].astype('float32')\n        if df[col].dtype=='int64': \n            if df[col].max()<1: df[col] = df[col].astype(bool)\n            elif df[col].max()<128: df[col] = df[col].astype('int8')\n            elif df[col].max()<32768: df[col] = df[col].astype('int16')\n            else: df[col] = df[col].astype('int32')\n    return df\n\nX= mem_reduce(X)\nX_test=mem_reduce(X_test)\ngc.collect()","4c961667":"X.dtypes","8d8ae2cf":"def get_LGBC():\n    return LGBMClassifier(n_estimators=500,  \n                     learning_rate= 0.1,\n                     objective= 'multiclass', \n                     num_class=7,\n                     random_state= 2019,\n#                      class_weight=class_weight_lgbm,\n                     n_jobs=-1)\nlgbc= get_LGBC()\nlgbc.fit(X,y)\n\nplot_importance(lgbc, ignore_zero=False, figsize=(8,40))\n","12f2f901":"#checking how many features we can cut without performance loss\n# print(np.mean(cross_val_score(get_LGBC(), X, y, cv=5)))\n# print(np.mean(cross_val_score(get_LGBC(), X.drop(X.columns[lgbc.feature_importances_<100], axis=1), y, cv=5)))\n# print(np.mean(cross_val_score(get_LGBC(), X.drop(X.columns[lgbc.feature_importances_<50], axis=1), y, cv=5)))\n# print(np.mean(cross_val_score(get_LGBC(), X.drop(X.columns[lgbc.feature_importances_<10], axis=1), y, cv=5)))\n# print(np.mean(cross_val_score(get_LGBC(), X.drop(X.columns[lgbc.feature_importances_<0], axis=1), y, cv=5)))\n\n#output : \n# 0.8001322751322751\n# 0.7950396825396825\n# 0.7952380952380953\n# 0.7956349206349207\n# 0.8001322751322751","b76e0ceb":"# just to be safe I remove only the zero importance features.. if the model gets too slow we can cut more.\nzero_importance = X.columns[lgbc.feature_importances_==0]\nX.drop(zero_importance, axis=1, inplace=True)\nX_test.drop(zero_importance, axis=1, inplace=True)","67ec7576":"#prepare df to store pred proba\nId_train=X.index\nId_test=X_test.index\n\nX_train_L1=pd.DataFrame(Id_train)\nX_test_L1=pd.DataFrame(Id_test)\n","2ec1abde":"# L1 training will store the probability predictions of the train and test set both. for the train set, to avoid leakage, we use a K-fold approach (each fold predicts a part of the training set)\ndef L1_Training(clf, clf_name, X_train, X_test, cv=5, early_stop=False):\n    scores = []\n    clf_cul=[str(clf_name)+str(i+1) for i in range(7)]\n    for i in clf_cul:\n        X_train_L1.loc[:, i]=0\n        X_test_L1.loc[:, i]=0\n\n    clf_proba = np.zeros((X_test.shape[0], 7))\n    for train, val in tqdm(StratifiedKFold(n_splits=cv, shuffle=True, random_state=9999).split(X_train, y)): \n        X_train_loc = X_train.iloc[train,:]\n        X_val_loc = X_train.iloc[val,:]\n        y_train_loc = y.iloc[train]\n        y_val_loc = y.iloc[val]\n        if early_stop:\n            # fit the model  ##Do we need to reset the model in between loops??\n            clf.fit(X_train_loc, \n                    y_train_loc, \n                    verbose=False,\n                    eval_set=[(X_train_loc, y_train_loc), (X_val_loc, y_val_loc)], \n                    early_stopping_rounds=50)\n            # use this fitted model to predict Test set.\n            clf_pred_proba_test = clf.predict_proba(X_test)\n            X_test_L1.loc[:, clf_cul] +=  clf_pred_proba_test\/ cv  #average over the CV rounds\n        else :\n            # when no early stoping the prediction of the Test set will be done once for all after (better use the full training set)\n            clf.fit(X_train_loc, y_train_loc)\n            \n        #checking validation\n        clf_pred_proba_val = clf.predict_proba(X_val_loc)\n        X_train_L1.loc[val, clf_cul]= clf_pred_proba_val\n        y_pred = clf.predict(X_val_loc)\n        scores.append(accuracy_score(y_pred,y_val_loc))\n#         scores.append(imbalanced_accuracy_score(y_pred,y_val_loc))\n        \n    if ~early_stop:\n        #retrain on full data\n        clf.fit(X_train,y)\n        clf_pred_proba_test = clf.predict_proba(X_test)\n        X_test_L1.loc[:, clf_cul] = clf_pred_proba_test\n        \n    clf_pred_test = X_test_L1.loc[:,clf_cul].to_numpy().argmax(axis=1)+1\n    return scores, clf_pred_test\n","1c55ba7f":"# some constant to be low for kernel editing\/ code checking and higher for commit\/real training.\n\nMODEL_FACTOR = 10\nCV = 6","2d1dac6d":"def get_XGB():\n    return XGBClassifier( n_estimator= 50*MODEL_FACTOR, \n                    learning_rate= 0.1, \n                    max_depth= 50,  \n                    objective= 'binary:logistic',\n                    random_state= 2019,\n#                     sample_weight=count,\n                    n_jobs=-1)\ndef get_LGBM():\n    return LGBMClassifier(n_estimators=50*MODEL_FACTOR,  \n                     learning_rate= 0.1,\n                     objective= 'multiclass', \n                     num_class=7,\n                     random_state= 2019,\n#                      class_weight=class_weight_lgbm,\n                     n_jobs=-1)\ndef get_RF():\n    return RandomForestClassifier(n_estimators = 100*MODEL_FACTOR, \n                            max_features = 0.3, \n                            max_depth = 100, \n                            min_samples_split = 2, \n                            min_samples_leaf = 1,\n                            bootstrap = False,\n#                             class_weight=count,\n                            random_state=2019)\ndef get_EXT():\n    return ExtraTreesClassifier(n_estimators = 75*MODEL_FACTOR, \n                            max_features = 0.3, \n                            max_depth = None, \n                            min_samples_split = 2, \n                            min_samples_leaf = 1,\n                            bootstrap = False, \n#                             class_weight=count,\n                            random_state=2019)","1e2bf936":"selected_features = X.columns\n\nX_train_select = X[selected_features]\nX_test_select = X_test[selected_features]\n\nclf_list = [(get_LGBM(), 'lgbc', True),\n            (get_XGB(), 'xgb', True),\n            (get_EXT(), 'xtc', False),\n            (get_RF(), 'rf', False)]\n\nfor clf, clf_name, early_stop in clf_list:\n    print ('Fitting L1 : '+ clf_name)\n    score, preds = L1_Training(clf, clf_name, X_train_select, X_test_select, cv=CV, early_stop=early_stop) \n    print(str(np.mean(score)) + ' ( ' + str(np.var(score)) + ')')\n    to_submission(preds, 'L1_sub_'+clf_name)","7f4676f4":"\n# lgbc_score, lgb_preds = L1_Training(lgbc, 'lgbc', X_train_select, X_test_select, cv=CV, early_stop=True) \n# to_submission(lgb_preds, 'lgb_sub')\n# print(np.mean(lgbc_score))\n","48cdd2c0":"\n# xgb_score, xgb_preds = L1_Training(xgb, 'xgb', X_train_select, X_test_select, cv=CV, early_stop=True) \n# to_submission(xgb_preds, 'xgb_sub')\n# print(np.mean(xgb_score))\n","f7735563":"\n# rf_score, rf_preds = L1_Training(rf, 'rf', X_train_select, X_test_select, cv=CV, early_stop=False) \n# to_submission(rf_preds, 'rf_sub')\n# print(np.mean(rf_score))\n","6a1631db":"\n# xtc_score, xtc_preds = L1_Training( xtc, 'xtc', X_train_select, X_test_select, cv=CV, early_stop=False) \n# to_submission(xtc_preds, 'xtc_sub')\n# print(np.mean(xtc_score))\n","e458fba5":"X_train_L1.drop('Id', axis=1, inplace=True)\nX_test_L1.drop('Id', axis=1, inplace=True)","2643cada":"X_test_L2 = pd.DataFrame(Id_test)\n\ndef L2_Training(clf, clf_name, cv=5, early_stop=False):\n    scores = []\n    clf_proba = np.zeros((X_test.shape[0], 7))\n    \n    clf_cul=[str(clf_name)+str(i+1) for i in range(7)]\n    for i in clf_cul:\n        X_test_L2.loc[:, i]=0\n        \n    for train, val in tqdm(StratifiedKFold(n_splits=cv, shuffle=True, random_state=9999).split(X_train_L1, y)): \n        X_train_loc = X_train_L1.iloc[train,:]\n        X_val_loc = X_train_L1.iloc[val,:]\n        y_train_loc = y.iloc[train]\n        y_val_loc = y.iloc[val]\n        if early_stop:\n            # fit the model  ##Do we need to reset the model in between loops??\n            clf.fit(X_train_loc, y_train_loc, \n                verbose=False,\n                eval_set=[(X_train_loc, y_train_loc), (X_val_loc, y_val_loc)], \n                early_stopping_rounds=50)\n            # use this fitted model to predict Test set.\n            clf_pred_proba_test = clf.predict_proba(X_test_L1)\n            X_test_L2.loc[:, clf_cul] +=  clf_pred_proba_test\/ cv  #average over the CV rounds\n        else :\n            # when no early stoping the prediction of the Test set will be done once for all after (better use the full training set)\n            clf.fit(X_train_loc, y_train_loc)\n            \n        #checking validation\n        y_pred = clf.predict(X_val_loc)\n        scores.append(accuracy_score(y_pred,y_val_loc))\n#         scores.append(imbalanced_accuracy_score(y_pred,y_val_loc))\n        \n    if ~early_stop:\n        #retrain on full data\n        clf.fit(X_train_L1,y)\n        clf_pred_proba_test = clf.predict_proba(X_test_L1)\n        X_test_L2.loc[:, clf_cul] = clf_pred_proba_test\n        \n    clf_pred_test = X_test_L2.loc[:,clf_cul].to_numpy().argmax(axis=1)+1\n    return scores, clf_pred_test\n","17dbf491":"# Use a \"simple\" Logistic regression for mixing probabilities and learning the finale version. \n# TODO: try other classifiers.\nlr= LogisticRegression(max_iter=1000,#not checked at all hyper-param\n                       n_jobs=-1,\n                       solver= 'lbfgs',\n#                        class_weight=count,\n                       multi_class = 'multinomial')\n\nl2_lr_score, l2_lr_preds = L2_Training(lr, 'lr', cv=CV, early_stop=False)\nprint(l2_lr_score)  \n# this shows something surprisingly low (0.6~0.7) yet achieve 0.84 on public LB.. not sure what's happening\n\nto_submission(l2_lr_preds, 'lr_stack_preds_sub')\n\nlgbm= LGBMClassifier(n_estimators=500,  #not checked at all hyper-param\n                     learning_rate= 0.1,#not checked at all hyper-param\n                     objective= 'multiclass', \n                     num_class=7,\n                     random_state= 2019,\n#                      class_weight=class_weight_lgbm,\n                     n_jobs=-1)\n\nl2_lgbm_score, l2_lgbm_preds = L2_Training(lgbm, 'lgbm', cv=CV, early_stop=True)\nprint(l2_lgbm_score)\nto_submission(l2_lgbm_preds, 'lgbm_stack_preds_sub')\n\n#do we need a third layer ?  :D  This sounds like deep forest learning ","2a2d6568":"plot_importance(lgbm)","4867c5c0":"# Model generation","1e6e33e3":"This notebook follows my notebooks:\n* https:\/\/www.kaggle.com\/arateris\/xgb-rf-with-gridsearch-for-forest-classifier\/ that looked for hyper-paramters (although it was without all the FE so the parameters may not be ideal anymore)\n* https:\/\/www.kaggle.com\/arateris\/stacked-classifiers-for-forest-cover where I was playing with various FE and orinal stacking\n* https:\/\/www.kaggle.com\/arateris\/probing-stats\/ for the Public Test set probing\n\nThere was a lot of inspirations from other notebooks which I will mention on the way as much as I remember.","8c975c50":"scaler = StandardScaler()  #--> Standard Scaler ?\nX.loc[:,:] = scaler.fit_transform(X)\nX_test.loc[:,:] = scaler.transform(X_test)\n","5527e80a":"(Now quite old) List of classifiers and hyper-parameters\n- XGBClassifier\n-- Params: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10} ?\n-- n_estimators = 719, max_depth = 464 https:\/\/www.kaggle.com\/phsheth\/forestml-part-6-stacking-eval-selected-fets-2  https:\/\/www.kaggle.com\/joshofg\/pure-random-forest-hyperparameter-tuning\n- RFClassifier\n-- {'max_depth': 100, 'max_features': 0.3, 'n_estimators': 2000}  https:\/\/www.kaggle.com\/arateris\/xgb-rf-with-gridsearch-for-forest-classifier\/\n-- Params: {n_estimators = 719, max_features = 0.3, max_depth = 464, min_samples_split = 2, min_samples_leaf = 1, bootstrap = False} https:\/\/www.kaggle.com\/joshofg\/pure-random-forest-hyperparameter-tuning\n- ExtraTrees\n-- Params : n_estimators = 750, max_features = 0.3, max_depth = None,  https:\/\/www.kaggle.com\/arateris\/xgb-rf-with-gridsearch-for-forest-classifier\/\n- LGBM \n-- Params : n_estimators=400,  num_leaves=100  ?  https:\/\/www.kaggle.com\/stevegreenau\/stacking-multiple-classifiers-clustering\n-- {'learning_rate': 0.5, 'max_depth': 25, 'n_estimators': 500}  https:\/\/www.kaggle.com\/arateris\/xgb-rf-with-gridsearch-for-forest-classifier\/\n- ADABoost \n-- Params : {max_depth  = 464, min_samples_split = 2, min_samples_leaf = 1,}  https:\/\/www.kaggle.com\/phsheth\/forestml-part-6-stacking-eval-selected-fets-2\n\n","227ffaeb":"# Feature removal\nthis is a bit of a \"cleaning after the party\" thing but to speed up training and avoid noise data I try to check the relevant features and remove useless ones. \n\na better approach would be to check the feature one by one (or small groups) when generating them. one reason being: sometime adding a feature won't improve the model but they may share their importance and it gets hard to see if it was actually useful or not.\n","27641d99":"## L1 training\ninspired by https:\/\/www.kaggle.com\/nadare\/eda-feature-engineering-and-modeling-4th-359#ykskks's-kernel and many blending kernels in other competitions\n\nI feel, using this 2-layer model is good for the LGB and XGB that can use the early_stopping and comparison with some validation set to improve the training. I don't know if it is possible in the StackingCVClassifier.","e088b6ed":"--> No missing data.","fbaf8bff":"Note : large difference between train and test size. Will need to check input distributions.","6b679912":"## Fixing Hillshade_3pm\nPloting all the histograms I saw one weird thing in the Hillshade_3pm","5c8a4849":"# Test label distribution\nhttps:\/\/www.kaggle.com\/arateris\/probing-stats\/\nThis is to know the distribution of the labels in the (public) test set. This allows to get a better accuracy check and validation during tuning\/training phase.\nNotes: \n* this may not be a good idea if the private\/public distribution are different. In this competition, as the distribution is too flat in the train, I somehow hope the private is similar to the the public LB. \n* I have seen the full\/private distributions but prefer not to use it to keep with the competition spirit (use only available data, not the full test answers)\n\nEDIT : v5 : not using this anymore.\n","3da712f0":"## L2 training\nthis time, we train using (X_train_L1, y) (X_test_L1) as input. \nNOTE: at this stage, this only use the prediction probabilities as input, it could be good to add the original data as well.","04dda556":"# Feature engineering,\nTODO : data cleaning","27851c6d":"Hill_shade_3pm is missing ~30 values at 126. \nHill_shade_3pm has 88 values equal to 0 which probably should not. 1250 zeros in the test set. --> this is not so many values, but still prefer fixing it to avoid spreading bad data in the feature engineering and training.","16488f78":"#Import datasets","0671890a":"--> Everything in numeric. \n\nSoil_type and Wilderness_area are categorial data already put as one hot encoded.","3f2bb8f2":"## Categories vs OHE\nOriginally transformed the binary classes to categorial features but maybe not a good idea so in this version I won't keep it for training at the end. \nI keep it here to do frequency encoding and may try to use it again later."}}