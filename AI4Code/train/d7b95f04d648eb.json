{"cell_type":{"f5b87b22":"code","a0298b9c":"code","ea4c0b1c":"code","6a95593a":"code","b1c40d97":"code","b3c7cbe8":"code","344bd473":"code","8493e185":"code","a0170f8c":"code","e6adc274":"code","6f384882":"code","66ec034a":"code","79c24298":"code","b507166e":"code","5074f816":"code","ad7bd285":"code","98805a24":"code","779ff9e2":"code","60eb145e":"code","8b99e8b0":"code","16532a28":"code","9652d1db":"code","0f81487f":"code","e7d75628":"code","383f2d44":"code","99f5cec2":"code","a4c83ebe":"code","b63b4696":"code","30733f26":"code","b303625d":"code","8517a5f9":"code","d20461b0":"code","51b7c382":"code","f217f296":"code","efc9221d":"code","af5fbc23":"code","2f17e086":"code","512aa99c":"code","b07fd7d3":"code","622de6cf":"markdown","2e9be9bc":"markdown","c746c146":"markdown","e586f5f0":"markdown","af35bf81":"markdown","d126df61":"markdown","1fc1023e":"markdown","ad545574":"markdown","5a781bb8":"markdown","b9bcd564":"markdown"},"source":{"f5b87b22":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport plotly\nimport cufflinks as cf\nfrom plotly import tools\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nnp.random.seed(123)\ncf.set_config_file(theme='henanigans')","a0298b9c":"docs= pd.read_table('..\/input\/smsspamcollection\/SMSSpamCollection.csv',header=None,names=['Class','sms'])\ndocs.head()","ea4c0b1c":"docs.shape","6a95593a":"\ninit_notebook_mode(connected=True)\nnp.random.seed(123)\ncf.set_config_file(theme='henanigans')\ndf_temp =docs['Class'].value_counts()\nfig=px.bar(x=df_temp.index,y=df_temp.values,color_discrete_sequence=[['green','red']],opacity=0.5)\niplot(fig)\n","b1c40d97":"print('Spam rate is :',docs['Class'].value_counts(normalize=True)[1]*100,'%')","b3c7cbe8":"docs['Class']= docs['Class'].map({'ham':0,'spam':1})\ndocs.head()","344bd473":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nX_train, X_test, y_train, y_test = train_test_split(docs['sms'], docs['Class'], test_size=0.3, random_state=1)","8493e185":"# vectorizing the sentences; removing stop words\nvect=CountVectorizer(stop_words='english').fit(X_train)\nvect","a0170f8c":"vect.vocabulary_","e6adc274":"# vocab size\nlen(vect.vocabulary_.keys())","6f384882":"# transforming the train and test datasets\nX_train_transformed= vect.transform(X_train)\nprint(X_train_transformed)","66ec034a":"pd.DataFrame(columns=vect.get_feature_names(),data=X_train_transformed.toarray())","79c24298":"# training the NB model and making predictions\nmnb=MultinomialNB().fit(X_train_transformed,y_train)\ny_train_pred= mnb.predict(X_train_transformed)\ny_train_pred_prob = mnb.predict_proba(X_train_transformed)\nmnb # note that alpha=1 is used by default for smoothing","b507166e":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,precision_recall_curve\nfrom sklearn.metrics import roc_auc_score,roc_curve,precision_score,recall_score,f1_score,auc\n#training set evavaluaion\nprint('Accuracy Score:',accuracy_score(y_train_pred,y_train))\nprint('Precision Score:',precision_score(y_train_pred,y_train))\nprint('Recall Score:',recall_score(y_train_pred,y_train))","5074f816":"confusion_matrix(y_train_pred,y_train)","ad7bd285":"X_test_transformed=vect.transform(X_test)\ny_test_pred=mnb.predict(X_test_transformed)\n# help(metrics.confusion_matrix)","98805a24":"confusion= confusion_matrix(y_test,y_test_pred)\nconfusion","779ff9e2":"\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\nTP = confusion[1, 1]","60eb145e":"Senstivity= TP\/(TP+FN)\nprint(Senstivity)","8b99e8b0":"Specificity= TN\/(TN+FP)\nprint(Specificity)","16532a28":"Precision= TP\/(TP+FP)\nprint(Precision)\nprint(precision_score(y_test,y_test_pred))","9652d1db":"Recall= TP\/(TP+FN)\nprint(Recall)\nprint(recall_score(y_test,y_test_pred))","0f81487f":"print(\"precision\",Precision)\nprint(\"PRECISION SCORE :\",precision_score(y_test, y_test_pred))\nprint(\"RECALL SCORE :\", recall_score(y_test, y_test_pred))\nprint(\"F1 SCORE :\",f1_score(y_test, y_test_pred))","e7d75628":"y_test_pred_proba=mnb.predict_proba(X_test_transformed)\ny_test_pred_proba","383f2d44":"fp_r,tp_r,thresholds=roc_curve(y_test,y_test_pred_proba[:,1])\nroc_auc=auc(fp_r,tp_r)\nprint(roc_auc)\n","99f5cec2":"print(roc_auc_score(y_test,y_test_pred_proba[:,1]))","a4c83ebe":"# matrix of thresholds, tpr, fpr\npd.DataFrame({'Threshold': thresholds, \n              'TPR': tp_r, \n              'FPR':fp_r\n             })","b63b4696":"print(min(thresholds))\nprint(max(thresholds))\n","30733f26":"# plotting the ROC curve\n%matplotlib inline  \nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.plot(fp_r, tp_r)","b303625d":"from sklearn.naive_bayes import BernoulliNB\nbnb=BernoulliNB().fit(X_train_transformed,y_train)\ny_test_b_predict= bnb.predict(X_test_transformed)\ny_test_b_pred_proba=bnb.predict_proba(X_test_transformed)\nprint('Accuracy Score:',accuracy_score(y_train_pred,y_train))\nprint('Precision Score:',precision_score(y_train_pred,y_train))\nprint('Recall Score:',recall_score(y_train_pred,y_train))","8517a5f9":"confusion_bnb=confusion_matrix(y_test,y_test_b_predict)\nconfusion_bnb","d20461b0":"\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\nTP = confusion[1, 1]","51b7c382":"Senstivity= TP\/(TP+FN)\nprint(Senstivity)","f217f296":"Specificity= TN\/(TN+FP)\nprint(Specificity)","efc9221d":"Precision= TP\/(TP+FP)\nprint(Precision)\nprint(precision_score(y_test,y_test_b_predict))","af5fbc23":"Recall= TP\/(TP+FN)\nprint(Recall)\nprint(recall_score(y_test,y_test_b_predict))","2f17e086":"print(\"precision\",Precision)\nprint(\"PRECISION SCORE :\",precision_score(y_test, y_test_b_predict))\nprint(\"RECALL SCORE :\", recall_score(y_test, y_test_b_predict))\nprint(\"F1 SCORE :\",f1_score(y_test, y_test_b_predict))","512aa99c":"fp_r,tp_r,thresholds=roc_curve(y_test,y_test_b_pred_proba[:,1])\nroc_auc=auc(fp_r,tp_r)\nprint(roc_auc)\n","b07fd7d3":"# plotting the ROC curve\n%matplotlib inline  \nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.plot(fp_r, tp_r)","622de6cf":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#2E4053; border:0; color:#CACFD2' role=\"tab\" aria-controls=\"home\"><center>If you found this notebook helpful , some upvotes would be very much appreciated - That will keep me motivated \ud83d\ude0a<\/center><\/h2>\n","2e9be9bc":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#2E4053; border:0; color:#CACFD2' role=\"tab\" aria-controls=\"home\"><center>Spam Classifier using Bernoulli and Multinomial Naive Bayes<\/center><\/h1>","c746c146":"<a id=\"6\"><\/a>\n## SMS Spam Classifier: Bernoulli Naive Bayes\n\nThe notebook is divided into the following sections:\n1. Importing and preprocessing data\n2. Building the model: Bernoulli Naive Bayes","e586f5f0":"<a id=\"5\"><\/a>\n### Model Evaluation","af35bf81":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#2E4053; border:0; color:#CACFD2' role=\"tab\" aria-controls=\"home\"><center>Thank You \ud83d\ude4f <\/center><\/h1>\n","d126df61":"<a id=\"3\"><\/a>\n### 1. Importing and Preprocessing Data","1fc1023e":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#2E4053; border:0; color:#CACFD2' role=\"tab\" aria-controls=\"home\"><center>Table of Contents<\/center><\/h1>\n\n    \n    \n- [Import Libraries](#1)\n- [SMS Spam Classifier: Multinomial Naive Bayes](#2)\n- [Importing and Preprocessing Data](#3)     \n- [Building and Evaluating the Model](#4)\n- [Model Evaluation](#5)\n- [SMS Spam Classifier: Bernoulli Naive Bayes](#6)","ad545574":"<a id=\"4\"><\/a>\n### 2. Building and Evaluating the Model","5a781bb8":"<a id=\"1\"><\/a>\n## Import Libraries","b9bcd564":"<a id=\"2\"><\/a>\n## SMS Spam Classifier: Multinomial Naive Bayes\n\nThe notebook is divided into the following sections:\n1. Importing and preprocessing data\n2. Building the model: Multinomial Naive Bayes\n    - Model building \n    - Model evaluation"}}