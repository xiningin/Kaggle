{"cell_type":{"9d59fbe2":"code","583aa827":"code","07fa1a6b":"code","be4a38de":"code","c5972e04":"code","e309d308":"code","9815a54d":"code","f1357150":"code","c65e2d3d":"code","0de00212":"code","8da057c2":"code","fee14b5d":"code","7b83a998":"code","770049dc":"code","0a23eb5a":"code","c8b35015":"code","21f979f2":"code","5c9fd49a":"code","93d221be":"code","a21afc28":"code","d786e7d0":"code","c2273ea9":"code","a14507a3":"code","5336ed7f":"code","976cfd83":"code","4ae066f1":"code","95e25557":"code","f3931c62":"code","07c61f0f":"code","5c5732dd":"code","7846ef75":"markdown","d9f4b0da":"markdown","a771bdcd":"markdown","a708467d":"markdown","849ecdd4":"markdown","2dcb55ff":"markdown","e139f021":"markdown","8d59bffd":"markdown","bf6555b3":"markdown","02fb44f7":"markdown","144018ae":"markdown","e5f19bee":"markdown","45a3fd8b":"markdown","7d98124a":"markdown","8b60cff1":"markdown","268cc872":"markdown","ae0b7baa":"markdown","b2f29fd9":"markdown","7b3459fd":"markdown","150baefe":"markdown","fbb79fb6":"markdown","74521d58":"markdown","49297109":"markdown","9bccb216":"markdown","f3de38d2":"markdown","1ecfca32":"markdown","55888ab5":"markdown","e33c39ff":"markdown"},"source":{"9d59fbe2":"import matplotlib.pyplot as matplotlib\nimport seaborn\nimport pandas\nimport numpy\n%matplotlib inline\n\n# Fun\u00e7\u00e3o para fazer reshape de listas 1D\ndef reshape(list1D):\n     return numpy.array(list1D).reshape(-1,1)\n    \n# Fun\u00e7\u00e3o para imprimir nosso modelo de Regress\u00e3o Logistica\ndef plot_ours(model):\n    x = numpy.linspace(0,1,50)\n    y = model.predict(reshape(x))\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Our Logistic model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n    \n# Fun\u00e7\u00e3o para imprimir o modelo \"padr\u00e3o\" de Regress\u00e3o Logistica \ndef plot_lr():\n    logistical = lambda x: numpy.exp(x)\/(1+numpy.exp(x))   \n    x = numpy.linspace(-10,10,50)\n    y = logistical(x)\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Logisitc Regression model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n\nplot_lr()\n# Apresentar o que \u00e9 um notebook a = 1, ...","583aa827":"from sklearn.linear_model import LogisticRegression\n\nx = [0.0, 0.01, 0.1, 0.123, 0.12345, 0.234, 0.432, 0.6535, 0.6457457, 0.7, 0.71, 0.07, 0.8, 0.9, 1]\ny = [0  , 0   , 0  , 0    , 0      , 0    , 0    , 1     , 1        , 1  , 1   , 0   , 1  , 1  , 1]\n\nmodel = LogisticRegression()\nmodel.fit(reshape(x),y)","07fa1a6b":"plot_ours(model)\n\ntest = [0.001431256, 0.136882, 0.6345345345, 0.81234791874]\n\nresult = model.predict(reshape(test))\nprint(result)","be4a38de":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport random\n\n# Uma fun\u00e7\u00e3o para criar um dataset com 10.000 n\u00fameros entre 0 e 1 classificados como 0 ou 1 (as vezes errado)\ndef create_dataset():\n    x = [random.random() for i in range(10000)]\n    classify = lambda i: int(i > 0.5) if random.random() > 0.1 else int(not i > 0.5)\n    dataset = pandas.DataFrame(x,columns=['x'])\n    dataset['y'] = dataset['x'].apply(classify)\n    return dataset \n    \ndataset = create_dataset()\ndataset","c5972e04":"seaborn.scatterplot(data=dataset,x='x',y='y', alpha=0.01)","e309d308":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nx = dataset['x']\ny = dataset['y']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\nmodel = LogisticRegression()\nmodel.fit(reshape(x_train),y_train)\n\nresult = model.predict(reshape(x_test))\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","9815a54d":"import tree\n# Aqui mapeia os dois tipos de diagn\u00f3sticos no espa\u00e7o\ndef plot_cancer_sizes(df):\n    matplotlib.figure(figsize=(12,12))\n    seaborn.kdeplot(df[df['diagnosis']=='M'].perimeter_worst, df[df['diagnosis']=='M'].area_worst, cmap=\"Reds\",  shade=True, alpha=0.3, shade_lowest=False)\n    seaborn.kdeplot(df[df['diagnosis']=='B'].perimeter_worst, df[df['diagnosis']=='B'].area_worst, cmap=\"Greens\", shade=True, alpha=0.3, shade_lowest=False)\n    matplotlib.show()\n\n# Faz um plot do perimeter_worst para os dois diagn\u00f3sticos\ndef plot_cancer_perimeter(df):\n    fig = seaborn.FacetGrid(df, hue=\"diagnosis\", aspect=3)\n    fig.map(seaborn.kdeplot, \"perimeter_worst\", shade=True)\n    fig.add_legend()\n    matplotlib.show()\n\n# Faz um plot da \u00e1rvore de decis\u00f5es\ndef plot_tree(model,x_train):\n    matplotlib.figure(figsize=(15,15))\n    tree.plot_tree(model, feature_names=x_train.columns, class_names=['benigno','maligno'], fontsize=14, filled=True)\n    matplotlib.show()\n\n# Faz um plot das import\u00e2ncias para um Random Forest\ndef plot_importances(model,df):\n    importances = model.feature_importances_\n    indices = numpy.argsort(importances)\n    matplotlib.figure(figsize=(12,8))\n    matplotlib.barh(range(len(indices)), importances[indices], color='b', align='center')\n    matplotlib.yticks(range(len(indices)), df.columns[indices])\n    matplotlib.suptitle('Import\u00e2ncia das caracter\u00edsticas')\n    matplotlib.show()\n\ncancer = pandas.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ncancer","f1357150":"cancer = cancer.drop(['Unnamed: 32'], axis=1)","c65e2d3d":"plot_cancer_sizes(cancer)","0de00212":"x = cancer.drop(['diagnosis'],axis=1)\ny = cancer['diagnosis']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nmodel = LogisticRegression()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","8da057c2":"cancer = cancer.drop(['id'], axis=1)\nx = cancer.drop(['diagnosis'],axis=1)\ny = cancer['diagnosis']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nmodel = LogisticRegression()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","fee14b5d":"nosso_cancer = list({\n 'radius_mean': 17.99,\n 'texture_mean': 10.38,\n 'perimeter_mean': 122.8,\n 'area_mean': 1001.0,\n 'smoothness_mean': 0.1184,\n 'compactness_mean': 0.2776,\n 'concavity_mean': 0.3001,\n 'concave points_mean': 0.1471,\n 'symmetry_mean': 0.2419,\n 'fractal_dimension_mean': 0.07871,\n 'radius_se': 1.095,\n 'texture_se': 0.9053,\n 'perimeter_se': 8.589,\n 'area_se': 153.4,\n 'smoothness_se': 0.006399,\n 'compactness_se': 0.04904,\n 'concavity_se': 0.05372999999999999,\n 'concave points_se': 0.01587,\n 'symmetry_se': 0.03003,\n 'fractal_dimension_se': 0.006193,\n 'radius_worst': 25.38,\n 'texture_worst': 17.33,\n 'perimeter_worst': 184.6,\n 'area_worst': 2019.0,\n 'smoothness_worst': 0.1622,\n 'compactness_worst': 0.6656,\n 'concavity_worst': 0.7119,\n 'concave points_worst': 0.2654,\n 'symmetry_worst': 0.4601,\n 'fractal_dimension_worst': 0.1189\n}.values())\n\nmodel.predict(reshape(nosso_cancer).transpose())","7b83a998":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\nmodel = DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))\nplot_tree(model,x_train)","770049dc":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))\nplot_importances(model,cancer)","0a23eb5a":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, result))","c8b35015":"def plot_iris(df):\n    seaborn.pairplot(df, hue=\"Species\")\n    matplotlib.show()\n\niris = pandas.read_csv('..\/input\/iris\/Iris.csv')\niris","21f979f2":"plot_iris(iris)","5c9fd49a":"x = iris.drop(['Species'],axis=1)\ny = iris['Species']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nmodel = LogisticRegression()\nmodel.fit(x_train,y_train)\n\nresult = model.predict(x_test)\nprint(accuracy_score(result, y_test))\nprint(confusion_matrix(result, y_test))","93d221be":"titanic_train = pandas.read_csv(\"..\/input\/titanic\/train.csv\")\ntitanic_test = pandas.read_csv(\"..\/input\/titanic\/test.csv\")\ntitanic_train","a21afc28":"import string\nimport time\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\ndef clear_sentence(sentence):\n    sentence = sentence.replace('<br \/>', ' ')\n    sentence = sentence.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n    sentence = sentence.lower()\n    return sentence\n\nimdb = pandas.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")\nimdb","d786e7d0":"diabetes = pandas.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndiabetes","c2273ea9":"def plt_digit_from_row(row):\n    label, image = mnist_train.values[row,0], mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='hot')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n\nmnist_train = pandas.read_csv(\"..\/input\/mnist-in-csv\/mnist_train.csv\")\nmnist_test = pandas.read_csv(\"..\/input\/mnist-in-csv\/mnist_test.csv\")\nmnist_train.head()","a14507a3":"plt_digit_from_row(0)","5336ed7f":"mnist_train_labels, mnist_train_values = mnist_train.values[:,0], mnist_train.values[:,1:]\nmnist_test_labels, mnist_test_values = mnist_test.values[:,0], mnist_test.values[:,1:]","976cfd83":"model = LogisticRegression()\n\nmodel.fit(mnist_train_values, mnist_train_labels)\n\n\nprediction = model.predict(mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","4ae066f1":"def plt_clothes_from_row(row):\n    label, image = fashion_mnist_train.values[row,0], fashion_mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='gray')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n    \nfashion_mnist_train, fashion_mnist_test = pandas.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\"), pandas.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\nfashion_mnist_train.head()","95e25557":"plt_clothes_from_row(0)","f3931c62":"fashion_mnist_train_labels, fashion_mnist_train_values = fashion_mnist_train.values[:,0], fashion_mnist_train.values[:,1:]\nfashion_mnist_test_labels, fashion_mnist_test_values = fashion_mnist_test.values[:,0], fashion_mnist_test.values[:,1:]","07c61f0f":"model = LogisticRegression()\n\nmodel.fit(fashion_mnist_train_values, fashion_mnist_train_labels)\n\nprediction = model.predict(fashion_mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","5c5732dd":"from mpl_toolkits.basemap import Basemap\n\n# Precisa ter as colunas 'lat' e 'long'. Retorna o mesmo dataframe com apenas os tweets na regi\u00e3o da austr\u00e1lia.\ndef pegar_tweets_na_australia(dataframe):\n    bot_lat, top_lat, left_lon, right_lon = -44,-10,109,156\n    top = dataframe.lat <= top_lat\n    bot = dataframe.lat >= bot_lat\n    left = dataframe.long >= left_lon\n    right = dataframe.long <= right_lon\n    index = top&bot&left&right \n    return dataframe[index]\n\n# Passe seu dataframe com os dados que voc\u00ea quer plotar e uma legenda (como string).\ndef plotar_mapa(dataframe,legenda):\n    Australia_map = Basemap(llcrnrlat=-44,urcrnrlat=-10,llcrnrlon=109,urcrnrlon=156)\n    matplotlib.figure(figsize=(12,10))\n    Australia_map.bluemarble(alpha=0.9)\n    seaborn.scatterplot(x='long', y='lat', data=dataframe, alpha=1, s=200, label=legenda)\n    matplotlib.show()","7846ef75":"Agora, vamos visualizar como o tamanho do per\u00edmetro e tamanho da \u00e1rea se comportam para o tipo maligno e benigno","d9f4b0da":"# Desafio 4: MNIST - Digit Recognizer\nDataset com d\u00edgitos escritos \u00e0 m\u00e3o e seus respectivos valores. Cada linha dos datasets (tanto de treino quanto de teste) est\u00e1 estruturada da seguinte forma:\n\n| Digito representado | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores bin\u00e1rios:","a771bdcd":"Ok, neste come\u00e7o iremos apresentar o que \u00e9 um modelo, o que \u00e9 x, y, labels\/test, fit e predict. Lembre-se que toda Intelig\u00eancia Artificial \u00e9 um modelo matem\u00e1tico para y = f(x), onde x ser\u00e3o os dados de entrada, y os dados de resposta, e f a nossa fun\u00e7\u00e3o. No caso estamos estudando uma fun\u00e7\u00e3o da forma ```f(x) = exp(x)\/(1+numpy.exp(x))```. N\u00f3s n\u00e3o iremos entrar na matem\u00e1tica por tr\u00e1s disso mas basta entender que ele \u00e9 uma curva.\n\nO que faremos a seguir \u00e9 um \"arredondador\", ou um classificador de 0's e 1's. Queremos que ele fa\u00e7a 0.00231 -> 0 e 0.7987 -> 1, e assim em diante.","a708467d":"Ok, o seu desafio agora \u00e9 utilizar Machine Learning para fazer uma An\u00e1lise de Sentimentos nas reviews de filmes do IMDB. Neste dataset voc\u00ea possui 50.000 reviews de filmes classificadas como \"positiva\" e \"negativa\". Neste dataset, seu modelo pode demorar bastante (coisa de 5 minutos para cima). O qu\u00ea voc\u00ea precisa fazer:\n\n- Limpar as reviews (use a fun\u00e7\u00e3o clear_sentence para cada string do dataset)\n- Separe o treinamento e teste.\n- Vetorizar as palavras (pode usar o HashingVectorizer()). Procure no google como aplicar isso.\n- Coloque em um Machine Learning.\n\n**Objetivos**\n- Qual \u00e9 o melhor tipo de modelo de ML para esse NLP? (Dica: pense em modelos que trabalham com vetores)\n- Ultrapasse 90% de precis\u00e3o neste dataset demorando menos de 1 minuto para rodar (utilize time.time() para pegar os tempos.\n\n\n","849ecdd4":"# Desafio 3: Diabetes\nO dataset a seguir possui dados sobre a incid\u00eancia de diabetes na popula\u00e7\u00e3o do povo Pima. Seu desafio \u00e9 descobrir a coluna outcome baseado nos outros dados. Seu desafio \u00e9 ultrapassar 82% de precis\u00e3o.","2dcb55ff":"Primeiro passo: Tire a coluna in\u00fatil no final!","e139f021":"Vamos predizer cancer! O dataset a seguir \u00e9 sobre canc\u00ear de mama no estado de Wisconsin. Na coluna do 'diagnosis' podemos ver os dois diagn\u00f3sticos para cancer de mama: Maligno e Benigno. Vamos tentar adivinhar o diagn\u00f3stico baseado apenas nas informa\u00e7\u00f5es m\u00e9dicas que temos.","8d59bffd":"# Desafio Final: Predizer elei\u00e7\u00f5es com Tweets\n\nDessa vez nem preparamos o dataset para voc\u00ea. Utilizando o dataset das elei\u00e7\u00f5es australianas, voc\u00ea consegue predizer que regi\u00f5es da Austr\u00e1lia apoiam qual partido? Tente treinar seu modelo em algum dataset classificado com positivo e negativo e ent\u00e3o fa\u00e7a o .fit() no dataset das elei\u00e7\u00f5es. Voc\u00ea pode utilizar a fun\u00e7\u00e3o a seguir para plotar seus dados.","bf6555b3":"Ok, cansamos de usar Logistic Regression. Queremos modelos diferentes para fazer aprendizado de m\u00e1quina! Vamos tentar utilizar uma \u00e1rvore de decis\u00f5es, \u00e9 o mesmo \"modelo\" que o Akinator funcionava!","02fb44f7":"Veja s\u00f3 como os dados se parecem:","144018ae":"Ok, fa\u00e7a x com todas as colunas menos o diagn\u00f3stico, e y como diagn\u00f3stico! Lembre de separar os dados e aplicar a Regress\u00e3o Log\u00edstica","e5f19bee":"E agora vamos aprender um pouco sobre classifica\u00e7\u00e3o, como precis\u00e3o, recall, f1-score, e **LOSS**","45a3fd8b":"# Desafio 5: Fashion MNIST\nDataset com desenhos de tipos de roupa classificadas com labels\nCada linha dos datasets (tanto de treino quanto de teste) est\u00e1 estruturada da seguinte forma:\n\n\n| Label de cada roupa | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores bin\u00e1rios:","7d98124a":"# IRIS\n\nIris, o desafio que deu nome ao nome do nosso grupo, \u00e9 um dataset do tipo de flor Iris (e n\u00e3o o olho!). Nele, h\u00e1 tr\u00eas tipos de esp\u00e9cies, com as informa\u00e7\u00f5es sobre s\u00e9palas e p\u00e9talas.","8b60cff1":"Vamos aplicar nossa regress\u00e3o log\u00edstica.","268cc872":"Agora que sabemos como fazer o _fit_ do nosso modelo, vamos ver como ele se parece graficamente. E vamos colocar alguns n\u00fameros de entrada para ele tentar adivinhar!","ae0b7baa":"# Aprendendo a usar o Kaggle\n\nOl\u00e1, seja bem vindo ao Workshop de classificadores de ML do Iris Data Science. N\u00f3s preparamos esse notebook para que voc\u00ea possa aprender do 0 at\u00e9 o conhecimento b\u00e1sico de uso de ML. Esse material \u00e9 baseado em dados de competi\u00e7\u00f5es e nas aulas do Prof. Pascal Yim (E.C. Lille). Os slides da apresenta\u00e7\u00e3o est\u00e3o dispon\u00edveis [aqui](https:\/\/docs.google.com\/presentation\/d\/1_tE7RopalM4mJ96sh-ZBx7KKVsOyTRndLNh5KJrTjL0\/edit?usp=sharing).\n\nSe voc\u00ea nunca utilizou o Kaggle, crie sua conta e clique em \"Copy and Edit\" neste notebook e come\u00e7e a programar!\n\nSe voc\u00ea \u00e9 iniciante, comece aqui pelo come\u00e7o e siga as instru\u00e7\u00f5es. Se voc\u00ea j\u00e1 possui experi\u00eancia, pode seguir a frente e tentar os desafios!","b2f29fd9":"Ok, agora vamos ver outro tipo de modelo chamado RandomForestClassifier. Veja que o modelo de aplica\u00e7\u00e3o no c\u00f3digo \u00e9 o mesmo!","7b3459fd":"Voc\u00ea vai precisar fazer o escalamento das imagens para poder ","150baefe":"Vamos ver como cada informa\u00e7\u00e3o se comporta para cada esp\u00e9cie.","fbb79fb6":"# Desafio 1: Titanic\n\nO seu objetivo \u00e9 descobrir, dado as informa\u00e7\u00f5es de um passageiro no navio Titanic, se ele sobreviveu ou n\u00e3o o acidente (coluna survived). Neste caso, voc\u00ea perceber\u00e1 que algumas colunas podem deixar seu aprendizado pior. Outro ponto importante \u00e9 que h\u00e1 varias informa\u00e7\u00f5es faltantes (NaN).\n\n**Objetivos**\n- Voc\u00ea consegue preencher as informa\u00e7\u00f5es faltantes de alguma forma? Como?\n- Tente ultrapassar 80% de precis\u00e3o.\n\n\n","74521d58":"# Desafio 2: IMDB","49297109":"Lembre-se sempre da aplica\u00e7\u00e3o de IA: classificar coisas! Imagine que eu sou um m\u00e9dico com um paciente com essas condi\u00e7\u00f5es. O c\u00e2ncer \u00e9 maligno ou benigno?","9bccb216":"A acur\u00e1cia foi ruim, como voc\u00ea pode ver. O que aconteceu? Ser\u00e1 que tem alguma coluna que est\u00e1 fazendo nossos dados tendenciosos? (dica: tem sim)","f3de38d2":"# Mexendo com dados reais (Cancer de Mama)\n\n\n","1ecfca32":"Conseguimos ver como \u00e9 a imagem redimensionando o a matriz `1x784` para uma `28x28`:","55888ab5":"Ok, s\u00f3 que voc\u00ea nunca encontrar\u00e1 na sua vida os dados dessa forma. Eles normalmente est\u00e3o armazenados em datasets que podem ser acessados por dataframes. A forma mais comum de acessar um dataset \u00e9 utilizando a biblioteca pandas. Vamos ver esse dataset de dataset de \\[0,1\\]  que possui mais 10.000 n\u00fameros. (Aten\u00e7\u00e3o, por volta de 10% das respostas est\u00e3o erradas!)","e33c39ff":"Vamos aplicar novamente o que j\u00e1 sabemos."}}