{"cell_type":{"90668211":"code","a7b34756":"code","4ab43bea":"code","434ad84d":"code","747220d7":"code","5d7bdcc1":"code","8b9e24d2":"code","265c7706":"code","5e3ea650":"code","3f2deea8":"code","5216c9c1":"code","dee7565c":"code","85b2563a":"code","d202d6ac":"code","9b2a77cc":"code","97851618":"code","ec0f2c97":"code","c0a7747a":"code","cfe8d33b":"code","59f0f2ee":"code","6eece782":"code","3df4657c":"code","1603cfc9":"code","365eb1b3":"code","386b1e0e":"code","e1257d25":"code","b7f1516d":"code","16656244":"code","40769191":"code","e86e46fa":"code","2ce50bb1":"code","f6b085d0":"code","3974cf08":"code","f9c9b09f":"code","9b6513c4":"code","ac27de7c":"code","fc5f2f3d":"code","c8de8db3":"code","46c8511f":"code","de6125df":"code","9621d38f":"code","13aa7df1":"code","49511eca":"code","300350be":"code","ca95e826":"code","a812393f":"code","5f0805e5":"code","8079a5f7":"code","594fae6d":"code","5e4543a7":"code","41bfcb26":"code","32dd562d":"code","fa445537":"code","29e84904":"code","67d275ad":"code","60e5076a":"markdown","c7e47ab0":"markdown","5d870f41":"markdown","bd973216":"markdown","c5326ef8":"markdown","6b5df686":"markdown","0aa9b129":"markdown","05a09a10":"markdown","51813865":"markdown","6a6b77d5":"markdown","722d510e":"markdown","3e470ef4":"markdown","43c32293":"markdown","832a25a3":"markdown","6f6f0744":"markdown"},"source":{"90668211":"#loading need libraries\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n%matplotlib inline","a7b34756":"#Load data for train and test\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","4ab43bea":"train","434ad84d":"#shape of train data\ntrain.shape","747220d7":"test.shape","5d7bdcc1":"\ntrain.info()","8b9e24d2":"\ntest.info()","265c7706":"plt.subplots(figsize=(12,9))\nsns.distplot(train['SalePrice'], fit=stats.norm)\n\n# Get the fitted parameters used by the function\n\n(mu, sigma) = stats.norm.fit(train['SalePrice'])\n\n# plot with the distribution\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\n\n#Probablity plot\n\nfig = plt.figure()\nstats.probplot(train['SalePrice'], plot=plt)\nplt.show()","5e3ea650":"#we use log function which is in numpy\ntrain['SalePrice'] = np.log1p(train['SalePrice'])\n\n#Check again for more normal distribution\n\nplt.subplots(figsize=(12,9))\nsns.distplot(train['SalePrice'], fit=stats.norm)\n\n# Get the fitted parameters used by the function\n\n(mu, sigma) = stats.norm.fit(train['SalePrice'])\n\n# plot with the distribution\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\n\n#Probablity plot\n\nfig = plt.figure()\nstats.probplot(train['SalePrice'], plot=plt)\nplt.show()","3f2deea8":"def missingdata(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()\/data.isnull().count()*100).sort_values(ascending = False)\n    ms=pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    ms= ms[ms[\"Percent\"] > 0]\n    f,ax =plt.subplots(figsize=(8,6))\n    plt.xticks(rotation='90')\n    fig=sns.barplot(ms.index, ms[\"Percent\"],color=\"green\",alpha=0.8)\n    plt.xlabel('Features', fontsize=15)\n    plt.ylabel('Percent of missing values', fontsize=15)\n    plt.title('Percent missing data by feature', fontsize=15)\n    return ms","5216c9c1":"missingdata(train)","dee7565c":"missingdata(test)","85b2563a":"#missing value counts in each of these columns\n# Isnull = train.isnull().sum()\/len(train)*100\n# Isnull = Isnull[Isnull>0]\n# Isnull.sort_values(inplace=True, ascending=False)\n# Isnull","d202d6ac":"#Separate variable into new dataframe from original dataframe which has only numerical values\n#there is 38 numerical attribute from 81 attributes\ntrain_corr = train.select_dtypes(include=[np.number])","9b2a77cc":"train_corr.shape","97851618":"#Delete Id because that is not need for corralation plot\ndel train_corr['Id']","ec0f2c97":"#Coralation plot\ncorr = train_corr.corr()\nplt.subplots(figsize=(20,9))\nsns.heatmap(corr, annot=True)","c0a7747a":"top_feature = corr.index[abs(corr['SalePrice']>0.5)]\nplt.subplots(figsize=(12, 8))\ntop_corr = train[top_feature].corr()\nsns.heatmap(top_corr, annot=True)\nplt.show()","cfe8d33b":"#unique value of OverallQual\ntrain.OverallQual.unique()","59f0f2ee":"sns.barplot(train.OverallQual, train.SalePrice)","6eece782":"#boxplot\nplt.figure(figsize=(18, 8))\nsns.boxplot(x=train.OverallQual, y=train.SalePrice)","3df4657c":"col = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt']\nsns.set(style='ticks')\nsns.pairplot(train[col], size=3, kind='reg')","1603cfc9":"print(\"Find most important features relative to target\")\ncorr = train.corr()\ncorr.sort_values(['SalePrice'], ascending=False, inplace=True)\ncorr.SalePrice","365eb1b3":"# PoolQC has missing value ratio is 99%+. So, there is fill by None\ntrain['PoolQC'] = train['PoolQC'].fillna('None')\ntest['PoolQC'] = test['PoolQC'].fillna('None')","386b1e0e":"#Arround 50% missing values attributes have been fill by None\ntest['MiscFeature'] = test['MiscFeature'].fillna('None')\ntest['Alley'] = test['Alley'].fillna('None')\ntest['Fence'] = test['Fence'].fillna('None')\ntest['FireplaceQu'] = test['FireplaceQu'].fillna('None')\n\ntrain['MiscFeature'] = train['MiscFeature'].fillna('None')\ntrain['Alley'] = train['Alley'].fillna('None')\ntrain['Fence'] = train['Fence'].fillna('None')\ntrain['FireplaceQu'] = train['FireplaceQu'].fillna('None')","e1257d25":"#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\ntrain['LotFrontage'] = train.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\ntest['LotFrontage'] = test.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","b7f1516d":"#GarageType, GarageFinish, GarageQual and GarageCond these are replacing with None\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    train[col] = train[col].fillna('None')\n    \nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    test[col] = test[col].fillna('None')\n    ","16656244":"#GarageYrBlt, GarageArea and GarageCars these are replacing with zero\nfor col in ['GarageYrBlt', 'GarageArea', 'GarageCars']:\n    train[col] = train[col].fillna(int(0))\n    \nfor col in ['GarageYrBlt', 'GarageArea', 'GarageCars']:\n    test[col] = train[col].fillna(int(0))","40769191":"#BsmtFinType2, BsmtExposure, BsmtFinType1, BsmtCond, BsmtQual these are replacing with None\nfor col in ('BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtCond', 'BsmtQual'):\n    train[col] = train[col].fillna('None')\n    \nfor col in ('BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtCond', 'BsmtQual'):\n    test[col] = test[col].fillna('None')","e86e46fa":"#MasVnrArea : replace with zero\ntrain['MasVnrArea'] = train['MasVnrArea'].fillna(int(0))\n\ntest['MasVnrArea'] = test['MasVnrArea'].fillna(int(0))","2ce50bb1":"#MasVnrType : replace with None\ntrain['MasVnrType'] = train['MasVnrType'].fillna('None')\n\ntest['MasVnrType'] = test['MasVnrType'].fillna('None')","f6b085d0":"#There is put mode value \ntrain['Electrical'] = train['Electrical'].fillna(train['Electrical']).mode()[0]\n\ntest['Electrical'] = test['Electrical'].fillna(test['Electrical']).mode()[0]","3974cf08":"#There is no need of Utilities\ntrain = train.drop(['Utilities'], axis=1)\n\ntest = test.drop(['Utilities'], axis=1)\n","f9c9b09f":"#Checking there is any null value or not\nplt.figure(figsize=(10, 5))\nsns.heatmap(train.isnull())","9b6513c4":"train.isnull().sum()","ac27de7c":"test.isnull().sum()","fc5f2f3d":"cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold', 'MSZoning', 'LandContour', 'LotConfig', 'Neighborhood',\n        'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n        'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'Foundation', 'GarageType', 'MiscFeature', \n        'SaleType', 'SaleCondition', 'Electrical', 'Heating')","c8de8db3":"from sklearn.preprocessing import LabelEncoder\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(train[c].values)) \n    train[c] = lbl.transform(list(train[c].values))","46c8511f":"#Take targate variable into y\ny = train['SalePrice']","de6125df":"#Delete the saleprice\ndel train['SalePrice']","9621d38f":"#Take their values in X and y\nX = train.values\ny = y.values","13aa7df1":"# Split data into train and test formate\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","49511eca":"#Train the model\nfrom sklearn import linear_model\nmodel = linear_model.LinearRegression()","300350be":"#Fit the model\nmodel.fit(X_train, y_train)","ca95e826":"#Prediction\nprint(\"Predict value \" + str(model.predict([X_test[142]])))\nprint(\"Real value \" + str(y_test[142]))","a812393f":"#Score\/Accuracy\nprint(\"Accuracy --> \", model.score(X_test, y_test)*100)","5f0805e5":"#Train the model\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators=1000)","8079a5f7":"#Fit\nrandomforest=model.fit(X_train, y_train)","594fae6d":"Y_pred_rf=randomforest.predict(X_test)","5e4543a7":"#Score\/Accuracy\n\nprint(\"Accuracy --> \", model.score(X_test, y_test)*100)\nprint(\"Accuracy --> \", model.score(X_test, Y_pred_rf)*100)","41bfcb26":"#Train the model\nfrom sklearn.ensemble import GradientBoostingRegressor\nGBR = GradientBoostingRegressor(n_estimators=100, max_depth=4)","32dd562d":"#Fit\ngbR=GBR.fit(X_train, y_train)","fa445537":"Y_pred_gbr = gbR.predict(X_test)","29e84904":"print(\"Accuracy --> \", GBR.score(X_test, y_test)*100)\nprint(\"Accuracy --> \", GBR.score(X_test, Y_pred_gbr)*100)","67d275ad":"# predictions = model.predict(test)\n# submission = pd.DataFrame({\n    \n#         \"Id\": test[\"Id\"],\n#         \"SalePrice\": predictions})\n\n# submission.to_csv('my_submission.csv', index=False)\n# print(\"Your submission was successfully saved!\")\n","60e5076a":"### Checking the missing values","c7e47ab0":"### Linear Regression","5d870f41":"Here OverallQual is highly correlated with target feature of saleprice by 82%","bd973216":" Now, there is no any missing values","c5326ef8":"### GradientBoostingRegressor","6b5df686":"### Imputting missing values","0aa9b129":"### Target variable \nSome analysis on target variable","05a09a10":"## If someone who is going through my notebook and like my solving approach then please upvote my notebook.\n## Thank You","51813865":"#### Encoding str to int","6a6b77d5":"### Corralation between train attributes","722d510e":"This target varibale is right skewed. Now, we need to tranform this variable and make it normal distribution.\n","3e470ef4":"#### Here we use log for target variable to make more normal distribution","43c32293":"#### Top 50% Corralation  train attributes  with sale-price ","832a25a3":"#### Prepraring data for prediction","6f6f0744":"### RandomForestRegression"}}