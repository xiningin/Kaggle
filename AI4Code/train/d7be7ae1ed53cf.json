{"cell_type":{"55c5ad5f":"code","bcbbfdef":"code","ee4704e8":"code","fcb4064c":"code","49777020":"code","228a85c5":"code","a2d6c9e6":"code","fdcb938c":"code","b83031b4":"code","e3734ccc":"code","0e0afe39":"code","9c704e59":"code","50271c43":"code","59fdd7ba":"code","ffb4339d":"markdown","9f323532":"markdown","4910e37d":"markdown","c878b7ff":"markdown","5c29958b":"markdown","a94dae70":"markdown","caf1a6c3":"markdown","b50157cf":"markdown","a17532e5":"markdown","050dc316":"markdown","6317ee1d":"markdown","fc05edac":"markdown","fcf74c15":"markdown","7db76ff3":"markdown"},"source":{"55c5ad5f":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport time\nimport glob\nimport imageio\nfrom IPython import display\nimport cv2\nimport pathlib\nimport zipfile\nimport torch\nimport sys\nimport pandas as pd \n\nimport torchvision\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset\nfrom torchvision.utils import make_grid\nimport torch.optim as optim\nfrom torchvision.datasets import MNIST\n\nfrom skimage import io, transform\n\n!pip install torchsummary\nfrom torchsummary import summary\n\n!pip install torchviz\nfrom torchviz import make_dot, make_dot_from_trace","bcbbfdef":"# Decide which device we want to run on\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","ee4704e8":"class Generator(nn.Module):\n\n    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n        super(Generator, self).__init__()\n\n        self.gen = nn.Sequential(\n            self.get_generator_block(z_dim, hidden_dim),\n            self.get_generator_block(hidden_dim, hidden_dim * 2),\n            self.get_generator_block(hidden_dim * 2, hidden_dim * 4),\n            self.get_generator_block(hidden_dim * 4, hidden_dim * 8),\n\n            nn.Linear(hidden_dim * 8, im_dim),\n            nn.Sigmoid()\n\n        )\n    def get_generator_block(self, input_dim, output_dim):\n        return nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.BatchNorm1d(output_dim),\n            nn.ReLU(inplace=True),\n        )\n    \n    def forward(self, noise):\n        return self.gen(noise)\n    \nsummary(Generator(64).to(device) , (64,))","fcb4064c":"class Discriminator(nn.Module):\n\n    def __init__(self, im_dim=784, hidden_dim=128):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            self.get_discriminator_block(im_dim, hidden_dim * 4),\n            self.get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n            self.get_discriminator_block(hidden_dim * 2, hidden_dim),\n\n            nn.Linear(hidden_dim, 1)\n\n        )\n    def get_discriminator_block(self, input_dim, output_dim):\n        return nn.Sequential(\n             nn.Linear(input_dim, output_dim), \n             nn.LeakyReLU(0.2, inplace=True)\n        )\n    def forward(self, image):\n        return self.disc(image)\n    \nsummary(Discriminator().to(device) , (28*28,))","49777020":"def get_noise(n_samples, z_dim, device='cpu'):\n    return torch.randn(n_samples,z_dim,device=device)","228a85c5":"z_dim = 64\nbatch_size = 128\n\nfixed_noise = get_noise(batch_size, z_dim, device=device)\n\ntrain_transform = transforms.Compose([\n    transforms.ToTensor(),\n])\n\ndataloader = DataLoader(\n    MNIST('.', download=True, transform=train_transform),\n    batch_size=batch_size,\n    shuffle=True)","a2d6c9e6":"start = time.time()\ndataiter = iter(dataloader)\nimages,labels = dataiter.next()\nprint ('Time is {} sec'.format(time.time()-start))\n\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(make_grid(images.to(device), padding=2, normalize=True).cpu(),(1,2,0)))\n\nprint('Shape of loading one batch:', images.shape)\nprint('Total no. of batches present in trainloader:', len(dataloader))","fdcb938c":"lr = 0.00001\n\ncriterion = nn.BCEWithLogitsLoss()\n\ngen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n\ndisc = Discriminator().to(device) \ndisc_opt = torch.optim.Adam(disc.parameters(), lr=lr)","b83031b4":"def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), show_fig=False, epoch=0):\n    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.axis('off')\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    if show_fig:\n        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n        \n    plt.show()","e3734ccc":"n_epochs = 200\ncur_step = 0\nmean_generator_loss = 0\ntotal_steps = 0\nstart_time = time.time()\nmean_discriminator_loss = 0\ngen_loss = False\n\nG_losses = []\nD_losses = []\nD_mean_losses = []\nG_mean_losses = []\n\n\nfor epoch in range(n_epochs):\n    cur_step = 0\n    start = time.time()\n    for real, _ in dataloader:\n        \n        cur_batch_size = len(real)\n\n        # Flatten the batch of real images from the dataset\n        real = real.view(cur_batch_size, -1).to(device)\n\n        ## Update discriminator ##\n        disc_opt.zero_grad()\n        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n        fake = gen(fake_noise)\n        disc_fake_pred = disc(fake.detach())\n        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n        disc_real_pred = disc(real)\n        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n        disc_loss = (disc_fake_loss + disc_real_loss) \/ 2\n        \n        disc_loss.backward(retain_graph=True)\n        disc_opt.step()\n\n        ## Update generator ##\n        gen_opt.zero_grad()\n        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n        fake_2 = gen(fake_noise_2)\n        disc_fake_pred = disc(fake_2)\n        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n        \n        gen_loss.backward()\n        gen_opt.step()\n\n\n        # Keep track of the average discriminator loss\n        mean_discriminator_loss += disc_loss.item() \n\n        # Keep track of the average generator loss\n        mean_generator_loss += gen_loss.item() \n        \n        cur_step += 1\n        total_steps += 1\n        \n        D_losses.append(disc_loss.item())\n        G_losses.append(gen_loss.item())\n        \n        \n        print_val = f\"Epoch: {epoch}\/{n_epochs} Steps:{cur_step}\\t\"\n        print_val += f\"Epoch_Run_Time: {(time.time()-start):.6f}\\t\"\n        print_val += f\"Loss_D : {disc_loss.item():.6f}\\t\"\n        print_val += f\"Loss_G : {gen_loss.item():.6f}\\t\"  \n        print(print_val, end='\\r',flush = True)\n       \n    \n    print()\n    loss_D_mean = mean_discriminator_loss \/ cur_step\n    loss_G_mean = mean_generator_loss \/ cur_step\n    print_val = f\"Epoch: {epoch}\/{n_epochs} Total Steps:{total_steps}\\t\"\n    print_val += f\"Total_Time : {(time.time() - start_time):.6f}\\t\"\n    print_val += f\"Loss_D : {disc_loss.item():.6f}\\t\"\n    print_val += f\"Loss_G : {gen_loss.item():.6f}\\t\"\n    print_val += f\"Loss_D_Mean : {loss_D_mean:.6f}\\t\"\n    print_val += f\"Loss_G_Mean : {loss_G_mean:.6f}\\t\"\n    print(print_val, end='\\r',flush = True)\n    \n    D_mean_losses.append(loss_D_mean)\n    G_mean_losses.append(loss_G_mean)\n    \n    fake_noise = fixed_noise\n    fake = gen(fake_noise)\n    show_tensor_images(fake, show_fig=True,epoch=epoch)\n    mean_generator_loss = 0\n    mean_discriminator_loss = 0\n","0e0afe39":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_losses,label=\"G-Loss\")\nplt.plot(D_losses,label=\"D-Loss\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","9c704e59":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_mean_losses,label=\"G-loss-mean\")\nplt.plot(D_mean_losses,label=\"D-loss-mean\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","50271c43":"anim_file = 'Vanilla-GAN.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\n\n!pip install -q git+https:\/\/github.com\/tensorflow\/docs\nimport tensorflow_docs.vis.embed as embed\nembed.embed_file(anim_file)","59fdd7ba":"def show_new_gen_images(tensor_img, num_img=25):\n    tensor_img = (tensor_img + 1) \/ 2\n    unflat_img = tensor_img.detach().cpu()\n    img_grid = make_grid(unflat_img[:num_img], nrow=5)\n    plt.imshow(img_grid.permute(1, 2, 0).squeeze(),cmap='gray')\n    plt.show()\n\nnum_image = 25\nnoise = get_noise(num_image, z_dim, device=device)\nwith torch.no_grad():\n    fake_img = gen(noise)\n\nshow_new_gen_images(fake_img.reshape(num_image,1,28,28))","ffb4339d":"# Important Resources \n\n\n[MNIST Dataset](http:\/\/yann.lecun.com\/exdb\/mnist\/)\n\n[Generative Adversarial Networks (Ian J. Goodfellow ..)](https:\/\/arxiv.org\/abs\/1406.2661)\n\n[thispersondoesnotexist](https:\/\/www.thispersondoesnotexist.com\/)\n\n[Pre-trained Model Exploration](https:\/\/colab.research.google.com\/github\/https-deeplearning-ai\/GANs-Public\/blob\/master\/C1W1_(Colab)_Pre_trained_model_exploration.ipynb)\n\n[Inputs to a Pre-trained GAN](https:\/\/colab.research.google.com\/github\/https-deeplearning-ai\/GANs-Public\/blob\/master\/C1W1_(Colab)_Inputs_to_a_pre_trained_GAN.ipynb)\n","9f323532":"# Vanilla GAN","4910e37d":"# Model Training","c878b7ff":"# Discriminator","5c29958b":"# Generator","a94dae70":"# Loss Function & Optimizer","caf1a6c3":"# Testing Vanilla GAN","b50157cf":"# Noise Create Function","a17532e5":"# Packages ","050dc316":"# After Tranning Loss Visualization","6317ee1d":"# Animated GIF Create & Show","fc05edac":"# MNIST Dataset Load","fcf74c15":"# Device Mode","7db76ff3":"# Loaded Data Visualization"}}