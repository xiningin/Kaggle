{"cell_type":{"6572c32f":"code","b92b59f5":"code","e2442052":"code","3e45ef27":"code","190a73e5":"code","6f084688":"code","872348f8":"code","42c55659":"code","5406615b":"code","b65b37c6":"code","e3edc43e":"code","f8e39fe7":"code","5f5d02ae":"code","2106b2f7":"code","1c75663d":"code","1abbdde5":"code","84286e1e":"code","82a592a9":"code","796f791e":"code","f4c670c9":"code","9009e729":"code","86049d23":"code","b57bfcf1":"code","94ad7713":"code","fd5cc6d4":"code","d2aed4d5":"code","1ff1da55":"code","92d24690":"code","c03059e7":"code","88f8b4b7":"code","391e7824":"code","3601e80b":"code","f2f43ec4":"code","23e2ecd0":"markdown","658430dc":"markdown","f34c90b5":"markdown","1bb9d865":"markdown"},"source":{"6572c32f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b92b59f5":"# Reading the data\ntrain = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","e2442052":"# checking data types\ntrain.dtypes","3e45ef27":"# we are checking for missing values in EDA\ntrain.isnull().sum()","190a73e5":"test.isnull().sum()","6f084688":"#From EDA, we found variables with missing values in test and train\n#We implemented interpolate to deal with these values for both dataframes\n\n#Need to get rid of the missing values in train dataset\ntrain_df = train.select_dtypes(include=[np.number]).interpolate()\ntrain_df.head()","872348f8":"#we then check our work to make sure there are no more missing values\ntrain_df.isnull().sum()","42c55659":"train_df.shape","5406615b":"#Need to get rid of the missing values in test dataset as well\ntest_df = test.select_dtypes(include=[np.number]).interpolate()\ntest_df.head()","b65b37c6":"#we then check our work to make sure there are no more missing values\ntest_df.isnull().sum()","e3edc43e":"test_df.shape","f8e39fe7":"#pairplot\n#gives us a wholistic view on relationships between each of the variables\ncol = ['SalePrice', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond']\nsns.set(style='ticks')\nsns.pairplot(train_df[col], size=3, kind='reg')","5f5d02ae":"#correlation matrix\nimport matplotlib.pyplot as plt\n\ncorrmat = train.corr()\nplt.figure(figsize=(12, 12))\nsns.heatmap(corrmat, vmax=.8, square=True)","2106b2f7":"import seaborn as sns\nsns.distplot(train_df['SalePrice'])\n#Saleprice is skewed to the left; would need to be adjusted to get a better score","1c75663d":"# setting variables y and X for our Linear Regression model\ny = np.log(train_df.SalePrice) #DV\nX = train_df.drop(['SalePrice', 'Id'], axis = 1) #IVs","1abbdde5":"X.shape, y.shape","84286e1e":"#performing Linear Regression\n#splitting the data into test and train sets\n\nfrom sklearn.model_selection import train_test_split\nX, X_test, y, y_test = train_test_split(X, y, test_size=0.3)","82a592a9":"#peforming Linear Regression\n#importing LinearRegression from sklearn library\nfrom sklearn.linear_model import LinearRegression\nLinReg = LinearRegression()","796f791e":"# fitting training data to a model\nmodel = LinReg.fit(X, y)","f4c670c9":"#use the model to predict the test data\ny_predicted = LinReg.predict(X_test)\ny_predicted","9009e729":"LinReg.score(X_test, y_test)\n#R^2\n# 89.9%(this number will change each time the model is run) of the Sale Price of Houses explains the variability of te response data around it \n# mean (different features of the houses for sale (the IVS))","86049d23":"y_pred=LinReg.predict(X_test)","b57bfcf1":"#MAE: \nfrom sklearn.metrics import mean_absolute_error\nprint(mean_absolute_error(y_true = y_test, y_pred = LinReg.predict(X_test)))","94ad7713":"#MSE\nfrom sklearn.metrics import mean_squared_error\nprint(mean_squared_error(y_true = y_test, y_pred = LinReg.predict(X_test)))","fd5cc6d4":"#What is the error on the training data?\nprint(mean_squared_error(y_true = y, y_pred = LinReg.predict(X)))","d2aed4d5":"# Does the performance (error metric ) improve? Any difference between scaling and no scaling.\n# After using the training data, our error went down","1ff1da55":"#Diagnostics: Residual plot, homoscedasticity ?\nimport matplotlib.pyplot as plt\nplt.hist(y_test - y_predicted)","92d24690":"plt.scatter(y_predicted, y_test - y_predicted)","c03059e7":"plt.scatter(LinReg.predict(X), y - LinReg.predict(X))","88f8b4b7":"print(LinReg.coef_)","391e7824":"print(LinReg.intercept_)","3601e80b":"#Optional: You can compare with other models, e.g., Linear Regression using Keras\/Tensorflow or PyTorch.\n","f2f43ec4":"#Note: interpolate: generating some x values and using exp function to get y values\n#must apply np.exp to model.predict value to get better result for SalePrice\nmy_submission = pd.DataFrame()\nmy_submission['Id'] = test_df.Id\nfeatures = test_df.select_dtypes(include=[np.number]).drop(['Id'], axis=1).interpolate()\ny_predict = model.predict(features) #given a trained model, predict the label of a new set of data\ny_predict = np.exp(y_predict) #Calculate the exponential (reverts interpolate: \nmy_submission['SalePrice'] = y_predict \nmy_submission.head()\nmy_submission.to_csv('submission.csv', index=False)","23e2ecd0":"# Linear Regression","658430dc":"# Data Cleaning","f34c90b5":"# Visualizations","1bb9d865":"# Importing Libraries and Files"}}