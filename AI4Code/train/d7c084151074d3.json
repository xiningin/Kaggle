{"cell_type":{"b56c6033":"code","2a4087e1":"code","35bdcb2d":"code","90a25491":"code","85b947d2":"code","79d9abae":"code","bf8a1e6d":"code","f1a65e33":"code","0be9c5cf":"code","1b67fa44":"code","812d07bb":"code","0661dd43":"code","a37209da":"code","842f58c8":"code","04865d02":"code","4b593830":"code","47028d3c":"code","7eac8abc":"code","c4f3bbb1":"code","24437e11":"code","28a30051":"code","48eb6cf6":"code","faad9bf9":"code","15e8ca6e":"code","d655d889":"code","265f6fb5":"code","4d3069f2":"code","caca2c49":"code","eb008549":"code","037ce07c":"code","3721a7b3":"code","3340ea2d":"markdown","30596c27":"markdown","015724db":"markdown","a694a618":"markdown","5af5c9f0":"markdown","dc0bccd9":"markdown","c2bfd5ac":"markdown","d736dc2e":"markdown","b38e06c6":"markdown","592e6c66":"markdown","67f8e169":"markdown","a6fe63ed":"markdown","91f7e43d":"markdown","28a27804":"markdown","508c8f56":"markdown","8132740f":"markdown","e60d679d":"markdown","7f1d9d00":"markdown","5e8fccec":"markdown","c5d67561":"markdown","1fca3730":"markdown","7c1a2a2e":"markdown","344af846":"markdown","570e0942":"markdown","164c9107":"markdown","91cfb4ff":"markdown","f81a0df7":"markdown","a073d5a0":"markdown","e645140c":"markdown","5a363fbd":"markdown","8a9c4d63":"markdown","e532e180":"markdown","b372aad2":"markdown","c70a78b5":"markdown","2fa6be24":"markdown","2e06ffd6":"markdown","282fa567":"markdown","73075e47":"markdown","8d12f94c":"markdown","9b08597b":"markdown","0889b91c":"markdown","51190136":"markdown"},"source":{"b56c6033":"import pandas as pd\nimport numpy as np","2a4087e1":"from scipy import stats # if you want to import everything\nfrom scipy.stats import kstest # specific import","35bdcb2d":"x = np.linspace(-15, 15, 9)\nstats.kstest(x, 'norm')","90a25491":"np.random.seed(987654321) # set random seed to get the same result\nstats.kstest('norm', False, N=100)","85b947d2":"np.random.seed(987654321)\nstats.kstest(stats.norm.rvs(size=100), 'norm')","79d9abae":"np.random.seed(987654321)\nx = stats.norm.rvs(loc=0.2, size=100)\nstats.kstest(x,'norm', alternative = 'less')","bf8a1e6d":"stats.kstest(x,'norm', alternative = 'greater')","f1a65e33":"stats.kstest(x,'norm', mode='asymp')","0be9c5cf":"np.random.seed(987654321)\nstats.kstest(stats.t.rvs(100,size=100),'norm')","1b67fa44":"np.random.seed(987654321)\nstats.kstest(stats.t.rvs(3,size=100),'norm')","812d07bb":"from scipy import stats # if you want to import everything\nfrom scipy.stats import ks_2samp # specific import","0661dd43":"np.random.seed(12345678)  #fix random seed to get the same result","a37209da":"n1 = 200  # size of first sample","842f58c8":"n2 = 300  # size of second sample","04865d02":"rvs1 = stats.norm.rvs(size=n1, loc=0., scale=1)","4b593830":"rvs2 = stats.norm.rvs(size=n2, loc=0.5, scale=1.5)","47028d3c":"stats.ks_2samp(rvs1, rvs2)","7eac8abc":"rvs3 = stats.norm.rvs(size=n2, loc=0.01, scale=1.0)","c4f3bbb1":"rvs4 = stats.norm.rvs(size=n2, loc=0.0, scale=1.0)","24437e11":"stats.ks_2samp(rvs1, rvs4)","28a30051":"from scipy.stats import kstest\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nimport plotly.plotly as py\n\ninit_notebook_mode(connected=True)","48eb6cf6":"# Importing GitHub file\n\nurl =\"https:\/\/raw.githubusercontent.com\/plotly\/datasets\/master\/wind_speed_laurel_nebraska.csv\"\ndata = pd.read_csv(url, sep=',')\ndata.head()","faad9bf9":"df = data[0:10]\n\ntable = ff.create_table(df)\niplot(table)","15e8ca6e":"x = data['10 Min Sampled Avg']\n\nks_results = kstest(x, cdf='norm')\n\nmatrix_ks = [['', 'DF', 'Test Statistic', 'p-value'],\n             ['Sample Data', len(x) - 1, ks_results[0], ks_results[1]]]\n\nks_table = ff.create_table(matrix_ks, index=True)\niplot(ks_table, filename='ks-table')","d655d889":"np.random.seed(12345678)","265f6fb5":"x = np.random.normal(0, 1, 1000)","4d3069f2":"y = np.random.normal(0, 1, 1000)","caca2c49":"z = np.random.normal(1.1, 0.9, 1000)","eb008549":"ks_2samp(x, y)","037ce07c":"ks_2samp(x, z)","3721a7b3":"pd.show_versions()","3340ea2d":"Shift distribution to larger values, so that cdf_dgp(x) < norm.cdf(x):","30596c27":"***","015724db":"For a slightly different distribution, we cannot reject the null hypothesis at a 10% or lower alpha since the p-value at 0.144 is higher than 10%","a694a618":"***","5af5c9f0":"# scipy.stats.kstest","dc0bccd9":"# Introduction","c2bfd5ac":"# scipy.stats.ks_2samp","d736dc2e":"Don\u2019t reject equal distribution against alternative hypothesis: greater","b38e06c6":"***","592e6c66":"For an identical distribution, we cannot reject the null hypothesis since the p-value is high, 41%:","67f8e169":"# <p>&nbsp;<\/p>\n<h1 style=\"text-align: center;\"><strong><span lang=\"pt\">CONCLUSION<\/strong><\/span><\/h1>\n<p>&nbsp;<\/p><p>&nbsp;<\/p><p>&nbsp;<\/p>","a6fe63ed":"Importing some data from the average wind speed sampled every 10 minutes:","91f7e43d":"**Examples:**","28a27804":"***","508c8f56":"The Kolmogorov-Smirnov test (KS test) allows detecting patterns that can not be detected with the Student t test.\n\n**According to Wikipedia:**\n\n> The Kolmogorov-Smirnov statistic quantifies the distance between\n> the empirical distribution function of the sample and the cumulative\n> distribution function of the reference distribution, or between the\n> empirical functions of two-sample distribution. The null distribution\n> of this statistic is calculated under the null hypothesis that the\n> sample is withdrawn from the reference distribution (in the case of a\n> sample) or that the samples are drawn from the same distribution (in\n> the case of two samples). In each case, the distributions considered\n> under the null hypothesis are continuous distributions, but are\n> unrestricted.\n\nThe test is intended to ascertain whether a sample can be considered as coming from a population with a given distribution. The test is particularly suitable for continuous distributions and has the advantage of making no assumptions about the data distribution. \n\nIn other words:\n\n- The Student T-Test says that there is a 79.3% chance that the two samples will be of the same distribution.\n- The KS test says that there is a 1.6% chance that the two samples will be of the same distribution.","8132740f":"With 3 degrees of freedom the t distribution looks sufficiently different from the normal distribution, that we can reject the hypothesis that the sample came from the normal distribution at the 10% level:","e60d679d":"Since our p-value is read as 0.0, we have strong evidence for not rejecting the null hypothesis","7f1d9d00":"**Testing Normality:**","5e8fccec":"Testing t distributed random variables against normal distribution","c5d67561":"**Imports and Parameters:**","1fca3730":"Reject equal distribution against alternative hypothesis: less","7c1a2a2e":"For a different distribution, we can reject the null hypothesis since the pvalue is below 1%:","344af846":"**Examples:**","570e0942":"With 100 degrees of freedom the t distribution looks close to the normal distribution, and the K-S test does not reject the hypothesis that the sample came from the normal distribution:","164c9107":"***","91cfb4ff":"<p>&nbsp;<\/p>\n<\/p><h1 style=\"text-align: center;\"><strong>Kolmogorov\u2013Smirnov Test<\/strong><\/h1>\n<h2 style=\"text-align: center;\"><strong>Nonparametric Hypothesis Testing for Data Science<\/strong><\/h2>\n<p>&nbsp;<\/p><p>&nbsp;<\/p><p>&nbsp;<\/p>","f81a0df7":"The above lines are equivalent to:","a073d5a0":"**Import Data:**","e645140c":"The Kolmogorov-Smirnov test is comparing any two distributions to each other, not necessarily a distribution to a normal distribution. These tests may be unilateral or on both sides, but the latter applies only if the two distributions are continuous.","5a363fbd":"Calculating the bilateral KS test for the null hypothesis in 2 independent samples are extracted from the same continuous distribution.","8a9c4d63":"# Example I","e532e180":"**Imports and Parameters:**","b372aad2":"***","c70a78b5":"##### INSTALLED VERSIONS","2fa6be24":"Test against one-sided alternative hypothesis","2e06ffd6":"Example using the two-sample KS test with ks_2samp:","282fa567":"# Example II","73075e47":"***","8d12f94c":"In this Study Kernel, through the reference readings, I noticed that the KS Test is a very efficient way of automatically differentiating samples from different distributions. In reading the links, it is noticed that Test T Student provides a very high p-value, and when the sample mean and standard deviation are highly similar, it does not detect such a variation. The KS Test can detect the variation. This served as study for future use of the KS Test, it showed that it can be easily used in Data Science contexts.\n\n**References:**\n\n- [Kolmogorov\u2013Smirnov Test](https:\/\/en.wikipedia.org\/wiki\/Kolmogorov%E2%80%93Smirnov_test)\n- [scipy.stats.kstest](https:\/\/docs.scipy.org\/doc\/scipy-0.14.0\/reference\/generated\/scipy.stats.kstest.html)\n- [scipy.stats.ks_2samp](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.stats.ks_2samp.html)\n- [KOLMOGOROV\u2013SMIRNOV TEST](https:\/\/towardsdatascience.com\/kolmogorov-smirnov-test-84c92fb4158d)\n- [Kolmogorov-Smirnov Test](http:\/\/www.physics.csbsju.edu\/stats\/KS-test.html)\n- [6.2 - TESTE DE KOLMOGOROV-SMIRNOV](http:\/\/www.portalaction.com.br\/inferencia\/62-teste-de-kolmogorov-smirnov)\n- [Normality Test in Python](https:\/\/plot.ly\/python\/normality-test\/)\n- [Kolmogorov-Smirnov train\/test - Porto Seguro](https:\/\/www.kaggle.com\/rspadim\/kolmogorov-smirnov-train-test-porto-seguro)\n- [Two-sample Kolmogorov-Smirnov Test in Python Scipy](https:\/\/stackoverflow.com\/questions\/10884668\/two-sample-kolmogorov-smirnov-test-in-python-scipy)","9b08597b":"**Imports and Parameters:**","0889b91c":"**Imports and Parameters:**","51190136":"Kolmogorov-Smirnov test to improve fit. The KS test is valid only for continuous distributions."}}