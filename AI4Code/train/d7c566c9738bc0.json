{"cell_type":{"2f29286e":"code","86151f53":"code","f1a7d028":"code","14054ab4":"code","ac392ba8":"code","4ee0cc12":"code","a0716fde":"code","9635bd34":"code","52d45658":"markdown","87107cae":"markdown","4e100fdf":"markdown","cbf8c91c":"markdown"},"source":{"2f29286e":"# Load libraries\nimport pandas as pd\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import KFold","86151f53":"# Load in the train and test datasets\ndata_train = pd.read_csv('..\/input\/train.csv')\ndata_test = pd.read_csv('..\/input\/test.csv')","f1a7d028":"data_train.info()","14054ab4":"data_test.info()","ac392ba8":"# Mapping Sex\nSex = {\"male\": 0, \"female\": 1}\ndata_train[\"SexBinary\"] = data_train[\"Sex\"].apply(lambda e: Sex.get(e))\ndata_test[\"SexBinary\"] = data_test[\"Sex\"].apply(lambda e: Sex.get(e))\n\n# Filling missing values in Age\ndata_train['Age'] = data_train['Age'].fillna(data_train['Age'].median())\ndata_test['Age'] = data_test['Age'].fillna(data_test['Age'].median())\n\n# Filling missing values in Embarked\ndata_train['Embarked'] = data_train['Embarked'].fillna(\"S\")\n\n# Mapping Embarked\nEmbarked = {\"C\": 0, \"Q\": 1, \"S\": 2}\ndata_train[\"EmbarkedNumber\"] = data_train[\"Embarked\"].apply(lambda e: Embarked.get(e))\ndata_test[\"EmbarkedNumber\"] = data_test[\"Embarked\"].apply(lambda e: Embarked.get(e))\n\n# Filling missing values in Fare\ndata_test['Fare'] = data_test['Fare'].fillna(0.0)","4ee0cc12":"features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'SexBinary', 'EmbarkedNumber']","a0716fde":"# Predictions\n\nregr = CatBoostClassifier(\n    loss_function=\"Logloss\", \n    eval_metric='AUC', \n    use_best_model=True, \n    random_seed=1, \n    iterations = 1000,\n    learning_rate = 0.01,\n    verbose=100)\n\nkf = KFold(n_splits=5, random_state=1, shuffle=True)\n\ndata_test['Survived'] = 0\n\nidx = 0\n\nfor train_index, valid_index in kf.split(data_train):\n    idx = idx + 1\n    print( \"\\nFold:\", idx)\n    \n    train = data_train.iloc[train_index]\n    valid = data_train.iloc[valid_index]\n   \n    regr.fit(train[features], train['Survived'], eval_set=(valid[features], valid['Survived']))\n    \n    data_test['Survived'] += regr.predict_proba(data_test[features])[:,1]\n\n    \ndata_test['Survived'] \/= 5","9635bd34":"def get_0_1(x):\n    if x < 0.5: return 0\n    else: return 1\n    \ndata_test['Survived'] = data_test['Survived'].apply(lambda x: get_0_1(x))\n\ndata_test[['PassengerId', 'Survived']].to_csv(\"Titanic-step0.csv\", index=False)\n\nprint('Done')","52d45658":"### Save results","87107cae":"### CatBoostClassifier","4e100fdf":"### Load and check data","cbf8c91c":"### Introduction\n\nThis notebook is a very basic and simple example without serious Feature Engineering with CatBoostClassifier\n\nPublic LB score about 0.775."}}