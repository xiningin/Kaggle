{"cell_type":{"6e8cc79d":"code","1a3ae83d":"code","972cfaba":"code","7e7b1897":"code","dc18160e":"code","800d7a53":"code","13be509f":"code","9e404477":"code","52f15ff5":"code","79873c3c":"code","f44e8667":"code","91c074ad":"code","fc323c9b":"code","e016522d":"code","0f43e611":"code","1ce4820d":"code","454c15a0":"code","90351b05":"code","ea90136e":"code","aef88c8a":"code","dd51ba3a":"code","196d2030":"code","300d7c63":"code","95eade3a":"code","fb443510":"code","8edf35d6":"code","22643969":"code","3d5f786a":"code","0b2ff097":"code","006454db":"code","e4e48e58":"code","9dd77d77":"code","088717f3":"code","e4deac34":"code","25b77d48":"code","0ebe290c":"code","762fc6b1":"markdown","812d2491":"markdown","c2933a03":"markdown","559f27f0":"markdown","f942e55c":"markdown","81dd0ffd":"markdown","30e6fc3e":"markdown","efcbb3e2":"markdown","4fa80268":"markdown","e98a2819":"markdown","c1c1e4bf":"markdown","13e9c36c":"markdown","d75477b4":"markdown","717b58b6":"markdown","eab7a888":"markdown","e28b55dd":"markdown","94a242ce":"markdown","134deda6":"markdown","3fd233f8":"markdown","f35a311b":"markdown","5b5ff395":"markdown","18e68330":"markdown","67bdaa75":"markdown","9daed7e3":"markdown","604b137b":"markdown","d82e01ae":"markdown","2f8be0f6":"markdown","b120fb1e":"markdown","b97fe783":"markdown","65dc4aa5":"markdown","4c3b7b02":"markdown","3b25b1a4":"markdown","64ef0d37":"markdown","ccb202de":"markdown","23e3e220":"markdown","7c2d8dcb":"markdown","1ed04225":"markdown","b1a2d8a5":"markdown","71802c2b":"markdown","7bab7930":"markdown","95047133":"markdown"},"source":{"6e8cc79d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import STOPWORDS\nimport nltk\nimport string","1a3ae83d":"fake = pd.read_csv('..\/input\/fake-and-real-news-dataset\/Fake.csv')\nnews = pd.read_csv('..\/input\/fake-and-real-news-dataset\/True.csv')","972cfaba":"news","7e7b1897":"news.isna().sum()","dc18160e":"news['subject'].value_counts()","800d7a53":"fake","13be509f":"fake.isna().sum()","9e404477":"fake['subject'].value_counts()","52f15ff5":"news['is_fake'] = 0 # contains only news\nfake['is_fake'] = 1 # contains only fakes\n\n# merge them into one file\ndata = pd.concat([news, fake])\ndata = data.reset_index()\n# don't forget to shuffle them. \n# Otherwise all news are on top and all fakes are on the bottom\ndata = data.sample(frac=1)","79873c3c":"data.duplicated().sum()","f44e8667":"data = data.drop(['date', 'subject'], axis=1)\n","91c074ad":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data, test_size=0.2, random_state=42)\nX_train = train.drop('is_fake', axis=1)\ny_train = train['is_fake']\nX_test = test.drop('is_fake', axis=1)\ny_test = test['is_fake']","fc323c9b":"y_train.value_counts()","e016522d":"y_test.value_counts()","0f43e611":"train_news = X_train.loc[(y_train==0),:]\ntrain_fake = X_train.loc[(y_train==1),:]","1ce4820d":"# a very simple measure for lexical diversity\ndef lexical_diversity(data, other_data, feature):\n    # ignoare capital letters\n    column = data[feature].str.lower() \n    # create one text from the column\n    text = ' '.join(column)\n    # drop punctuation\n    exclude = set(string.punctuation)\n    words = ''.join(char for char in text if char not in exclude)\n    # create a list of wordsw instead of one huge text\n    words_splitted = words.split()\n    \n    # analogously\n    other_column = other_data[feature].str.lower() \n    other_text = ' '.join(other_column)\n    other_words = ''.join(char for char in other_text if char not in exclude)\n    other_words_splitted = other_words.split()\n    # lexical diversity measure\n    return len(set(words_splitted)) \/ (len(words_splitted) + len(other_words_splitted))\n\nprint(f'Real News: {lexical_diversity(data=train_news, other_data=train_fake, feature=\"text\")}')\nprint(f'Fake News: {lexical_diversity(data=train_fake, other_data=train_news, feature=\"text\")}')","454c15a0":"stopwords = set(STOPWORDS)\n\ndef common_tokens_title(data, feature, name):\n    column = data[feature].str.lower() \n    text = ' '.join(column)\n    exclude = set(string.punctuation)\n    words = ''.join(char for char in text if char not in exclude)\n    words_splitted = words.split()\n    words_stopped = [word for word in words_splitted if not word in stopwords]\n    print(f'{name}:\\n{pd.DataFrame(nltk.FreqDist(words_stopped).most_common(10))[0]}')\n    \ncommon_tokens_title(train_news, 'title', 'Most common descriptive words in Real News Titles')\nprint('\\n')\ncommon_tokens_title(train_fake, 'title', 'Most common descriptive words in Fake News Titles')","90351b05":"import regex as re\n\n# let's begin with a helper function to count punctuation\ndef count_punctuation(text):\n    peri = re.subn(r\"\\.\", '', text)[1]\n    comm = re.subn(r\"\\,\", '', text)[1]\n    ques = re.subn(r\"\\?\", '', text)[1]\n    excl = re.subn(r\"\\!\", '', text)[1]\n    return [peri,comm, ques, excl]\n    \ncount_punctuation('...alph!a.beta.gamma...??')","ea90136e":"# count the usage of puntuations per row in a specified feature (title and text)\n# and store the data in a dataframe\ndef create_punctuation_df(dataset, feature):\n    return dataset.apply(lambda row: pd.Series({'peri_' + feature:count_punctuation(row[feature])[0], \n                                                       'comm_' + feature:count_punctuation(row[feature])[1],\n                                                      'ques_' + feature:count_punctuation(row[feature])[2],\n                                                      'excl_' + feature:count_punctuation(row[feature])[3]}), axis=1)\n\npunctuation_train_title = create_punctuation_df(train, 'title')\npunctuation_test_title = create_punctuation_df(test, 'title')\npunctuation_train_text = create_punctuation_df(train, 'text')\npunctuation_test_text = create_punctuation_df(test, 'text')\npunctuation_train_text ","aef88c8a":"# count the text length per row for both features (title and text)\n# and store the information in a dataframe\ndef create_len_df(dataset):\n    return dataset.apply(lambda row: pd.Series({'length_title':len(row['title']),\n                                               'length_text':len(row['text'])}), axis=1)\n\nlen_train = create_len_df(train)\nlen_test = create_len_df(test)\n\nlen_train","dd51ba3a":"def create_num_words_df(dataset):\n    return dataset.apply(lambda row: pd.Series({'num_words_title':len(row['title'].split())}), axis=1)\n\nnum_words_train = create_num_words_df(train)\nnum_words_test = create_num_words_df(test)\n\nnum_words_train","196d2030":"def create_title_ratio_df(dataset):\n    return dataset.apply(lambda row: pd.Series({'title_ratio':len(row['title'])\/(len(row['title']) + len(row['text']))}), axis=1)\n\ntitle_ratio_train = create_title_ratio_df(train)\ntitle_ratio_test = create_title_ratio_df(test)\n\ntitle_ratio_train","300d7c63":"X_train_punct_len = pd.concat([punctuation_train_title, \n                               punctuation_train_text, \n                               len_train, \n                               num_words_train, \n                               title_ratio_train], \n                              axis=1)\n\nX_test_punct_len = pd.concat([punctuation_test_title, \n                              punctuation_test_text, \n                              len_test, \n                              num_words_test, \n                              title_ratio_test], \n                             axis=1)\n\nX_train_punct_len","95eade3a":"X_train_punct_len.describe()","fb443510":"from scipy import stats\nX_train_punct_len_zscore = X_train_punct_len.apply(stats.zscore, axis=0)\nmask_outliers = np.logical_not(((X_train_punct_len_zscore>5).any(axis=1)).values + ((X_train_punct_len_zscore<-5).any(axis=1)).values)\nX_train_punct_len = X_train_punct_len.loc[mask_outliers,:]\ny_train = y_train[X_train_punct_len.index]","8edf35d6":"X_train_punct_len.describe()","22643969":"import seaborn as sns\nfig, ax = plt.subplots(figsize=(8,6))\nsns.heatmap(np.abs(X_train_punct_len.corr()), annot=True)\nplt.savefig('correlation')\nplt.show()","3d5f786a":"pd.concat([X_train_punct_len, y_train], axis=1).groupby('is_fake').mean()","0b2ff097":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state=42)\npreds = cross_val_predict(rf, X_train_punct_len, y_train, cv=5)\nf1 = f1_score(y_true=y_train, y_pred=preds)\nacc = accuracy_score(y_true=y_train, y_pred=preds)\nprint(f'f1: {f1}\\nacc: {acc}')","006454db":"rf.fit(X_train_punct_len, y_train)\npd.Series(rf.feature_importances_, \n          index=X_train_punct_len.columns).sort_values(ascending=False)","e4e48e58":"from sklearn.model_selection import GridSearchCV\nparams= {'n_estimators':[200, 300],\n        'criterion':['gini', 'entropy'],\n        'max_depth':[5, None],\n        'max_features':[2,5]}\ngscv = GridSearchCV(rf, params)\ngscv.fit(X_train_punct_len, y_train)\ngscv.best_params_","9dd77d77":"rf_tuned = RandomForestClassifier(criterion='entropy', max_depth=None, max_features=2, n_estimators=200, random_state=42)\npreds = cross_val_predict(rf_tuned, X_train_punct_len, y_train, cv=5)\nf1 = f1_score(y_true=y_train, y_pred=preds)\nacc = accuracy_score(y_true=y_train, y_pred=preds)\nprint(f'f1: {f1}\\nacc: {acc}')","088717f3":"rf_tuned.fit(X_train_punct_len, y_train)\npd.Series(rf_tuned.feature_importances_, \n          index=X_train_punct_len.columns).sort_values(ascending=False)","e4deac34":"preds_test = rf_tuned.predict(X_test_punct_len) \nf1 = f1_score(y_true=y_test, y_pred=preds_test)\nacc = accuracy_score(y_true=y_test, y_pred=preds_test)\nprint(f'f1: {f1}\\nacc: {acc}')","25b77d48":"forest = RandomForestClassifier(random_state=42)\n\nbest_column = 'all'\nbest_score = 0\nfor column in X_train_punct_len.columns:\n    forest.fit(X_train_punct_len[column].values.reshape((-1,1)), y_train)\n    preds = cross_val_predict(forest, X_train_punct_len[column].values.reshape((-1,1)), y_train, cv=5)\n    f1 = f1_score(y_true=y_train, y_pred=preds)\n    \n    if(f1>best_score):\n        best_score = f1\n        best_column = column\n\nprint(f'A default RandomForest already obtains an f1-score of {f1} on validation data when trained solely on the column {column}')","0ebe290c":"forest = RandomForestClassifier(random_state=42)\npunctuation = ['peri_title', 'comm_title', 'ques_title', 'excl_title', 'peri_text', 'comm_text', 'ques_text', 'excl_text']\nlenght = ['length_title', 'length_text','num_words_title', 'title_ratio']\n\n\nforest.fit(X_train_punct_len[punctuation], y_train)\npreds = cross_val_predict(forest, X_train_punct_len[punctuation], y_train, cv=5)\nf1 = f1_score(y_true=y_train, y_pred=preds)\nprint(f'A default RandomForest already obtains an f1-score of {f1} when trained solely on punctuation-based Features')\nprint('The Feature Inportances in that approach are:')\nprint(pd.Series(forest.feature_importances_, \n          index=punctuation).sort_values(ascending=False))\n\nforest.fit(X_train_punct_len[lenght], y_train)\npreds = cross_val_predict(forest, X_train_punct_len[lenght], y_train, cv=5)\nf1 = f1_score(y_true=y_train, y_pred=preds)\nprint(f'A default RandomForest already obtains an f1-score of {f1} when trained solely on length-based Features')\nprint('The Feature Importances in that approach are:')\nprint(pd.Series(forest.feature_importances_, \n          index=lenght).sort_values(ascending=False))","762fc6b1":"## Let's take a look at Fake News","812d2491":"are there any missing values in `Fake.csv`?","c2933a03":"## Concatenate the new Datasets","559f27f0":"## Most frequently used words in Titles\nis there a difference between the most frequently used words in the titles of Real News and Fake News? This question might already reveal the topics of the Fake News articles.","f942e55c":"not a single column contains missing values!","81dd0ffd":"how are Fake News distributed among the train and the test data?","30e6fc3e":"How does our data look like now?","efcbb3e2":"## Lenght of Title Relative to the Length of the Article + Title\nOne could assume that some attention grabbing Fake News have a long title and very short texts. Is that true?","4fa80268":"## Finetune the model","e98a2819":"Before taking a closer look at the data, perform a `train_test_split` to evade **Data Snooping**!","c1c1e4bf":"Which `subjects` are contained in this file?","13e9c36c":"# Investigate the Engineered Features","d75477b4":"As we saw, even some basic feature engineering might reveal powerful features for our machine learning models. I am pretty sure that adding `Word Embeddings` will improve the performance by a lot.\n\nThank you for reading this notebook!","717b58b6":"Interestingly it seems like `Fake News` contain almost two times greater lexical diversity than real news. Their authors seem to have a wide vocabulary.","eab7a888":"# How well can we predict on subsets of the Features?","e28b55dd":"* Many Titles don't contain any form of `punctuation`!\n\n* Some texts contain suspiciously small amounts of characters. At least one of them contains only 1 chars\n\nLet's remove some extreme outliers!","94a242ce":"# What you will Learn\nNLP is one of the most important areas of data science. This notebook focuses on the detection of `Fake News`. Most people tend to use deep learning approaches based on word embeddings, word sequences and other elaborate methods to detect them. In this notebook you will learn, that you can already achieve extremely good results by focusing on easily extracted features. Even though these methods are far from perfect, they are easy to perform and they allow us to get some valuable insights into the structure of Fake News.","134deda6":"These are already pretty nice results on train! What are the most `important features`?","3fd233f8":"For this notebook, I will ignore the `dates` and `subjects`(because they are disjoint). I will probably take a look at them in a later project. Let's drop them for now.","f35a311b":"Which `subjects` are contained in this file?","5b5ff395":"Interestingly, the length of the title is way more important than e.g. `excl_title`, even though the relation between the target and `excl_title` is way stronger. This is most likely the case because only a few titles contain exclamation marks.","18e68330":"* huge correlation between `peri_text` and `length_text`\n\n* huge correlation between `comm_text` and `length_text`\n\n* huge correlation between `comm_text` and `peri_text`\n\n* huge correlation between `peri_test` and `num_words_text`\n\n...and so on\n\nWe have to find out how they interact with the target to determine what to do with them.","67bdaa75":"## Lexical Diversity of Fake News\nLet's define a measure for lexical diversity to find out how many unique vocabs are used in Fake News articles.\n\nLet's define the lexical diversity measure as $\\frac{\\text{number of unique words in one (target)category}}{\\text{number of words in both (target)categories}}$","9daed7e3":"# Get an overview of both CSVs and merge them together!\nThe data is provided in two separated csv files. One file contains real articles, the other file contains fake news. Let's get an idea of both files.","604b137b":"# A Simple Model based on Punctuation and Text Length\nLet's use a default RandomForest for our classification!","d82e01ae":"## How do they interact with each other?","2f8be0f6":"# Text Length","b120fb1e":"## Number of Words in the Title\nLet's create a feature which counts the number of words in the Title. In my **Digital Markeeting Courses** I learned, that titles are extremely important when it comes to grabbing Attention. A rule of thumbs tells us that titles should have about 5 words.","b97fe783":"# Inspect the Training data to get further insights\nTherefore we have to split the Training set into News and Fake News","65dc4aa5":"## How do they Interact with the Target?","4c3b7b02":"## Final Prediction on Test","3b25b1a4":"not a single column contains missing values!","64ef0d37":"are there any missing values in `News.csv`?","ccb202de":"-> Both CSV files contain the same variables, `title`, `text`, `subject`, and `date`. We have roughly as many real news as fake news. THis might be very supportive for fututre predictions. We don't need to oversample or undersample our dataset, because the dataset is balanced w.r.t. the target. Unfortunately, none of the files contains an explicit column for the target variable `is_fake`. Let's create such a column! Afterwards we can merge them together into one file!","23e3e220":"Are there any duplicates in the data? If yes, we would have to remove them","7c2d8dcb":"## Let's take a look at Real News","1ed04225":"**Main Findings:**\n* Titles of Fake News contain ~4 times less `periods`\n\n* Titles of Fake News contain ~10 times more `question marks`\n\n* Titles of Fake News contain ~130 times more `exclamation marks` **(wow!)**\n\n* Texts of Fake News contain ~10 times more `question marks` \n\n* Texts of Fake News contain ~10 times more `exclamation marks`\n\n* Titles of Fake News are 50% `longer`. The number of words seems to reflect that fact as well. -> The length of words in the titles of Fake News and real News don't seem to vary a lot.\n\n* $\\frac{len(title)}{len(title) + len(text)}$ is ~40% longer in Fake News\n\n* Let's ignore the high correlations we found above. A more elaborate approach would be to eliminate correlating features by dropping them or using dimensionality reduction like PCA","b1a2d8a5":"`f1-score` of about 93%! Our model is already very powerful, even though it solely focuses on punctuation and text length. Moreover, it performs even better than on train!","71802c2b":"<div class=\"alert alert-danger\" role=\"alert\">\n    <h3>This notebook is work in progress. Feel free to <span style=\"color:red\">comment<\/span> if you have any suggestions   |   motivate me with an <span style=\"color:red\">upvote<\/span> if you like this project.<\/h3>\n<\/div>","7bab7930":"# Punctutation\nPunctuation might provide some information for predictions. ","95047133":"It seems like most Fake News Articles in our Training data are about US Presidents and candidates for the latter. Besides `trump`, the real news seem to focus on more general political topics."}}