{"cell_type":{"e19d0164":"code","fb42d8ad":"code","7f788d48":"code","ecfb54aa":"code","a548d643":"code","2cf8b0bc":"code","4689ec0f":"code","f793f4c8":"code","704d1091":"code","a136c500":"code","c9153682":"code","ed39dec0":"code","d26b3fe8":"code","db38743d":"code","0472927b":"code","2d5340dd":"code","bd4c8486":"code","ef8543f8":"code","4210d73a":"code","8b29d7bb":"code","eaa0a654":"code","55e4d214":"code","4f18ddba":"code","03740f61":"code","3061f4fd":"code","a44d0e05":"code","5e158202":"code","449d6f39":"code","e266172a":"code","6975ee6d":"code","91ec1222":"code","7aeefaca":"code","32e15d39":"code","76f5c1f1":"code","8b7f0918":"code","b16d5a7b":"code","eead8f93":"code","bd9b66ce":"code","271dc998":"code","cf890bae":"code","109e4e5e":"code","6c8c36f1":"code","c952e454":"code","9fb02028":"code","243b0b12":"code","742f2036":"code","652aed25":"code","bbbc9b51":"code","5b60a20d":"code","47c4b6c0":"code","5a49c6a5":"code","6d5fa06f":"code","bf51e2db":"code","9f4954ac":"code","c6c2c8aa":"code","5a6253f7":"code","4a8ee302":"code","219aaf5d":"code","c0fdf10e":"code","1b182807":"code","00a60930":"code","6b91d763":"code","94772ec9":"code","1d9720d6":"code","6ec66f48":"code","eabed6cb":"code","7c746b44":"code","89ffdef3":"code","9068699b":"code","27b7b9b7":"code","557e0682":"code","1ef19990":"code","3877dc50":"code","11d892e9":"markdown","6fe846c8":"markdown","19f8b3be":"markdown","61c8177d":"markdown","560eeb3c":"markdown","81110539":"markdown","0a159cd1":"markdown","e69b288f":"markdown","590b40f9":"markdown","4aead1eb":"markdown","42e2bd4f":"markdown","75544c6e":"markdown","c3ee5dbd":"markdown","768f04ee":"markdown","4b8f5866":"markdown","f744016a":"markdown","0fe63170":"markdown","7af7754e":"markdown","a1356261":"markdown","6ed266f2":"markdown","1167efdc":"markdown","313a504e":"markdown","5015a2df":"markdown","617f951c":"markdown","81955a72":"markdown","ea3eca54":"markdown","c34168bf":"markdown"},"source":{"e19d0164":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sys\n\nimport keras\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Flatten, BatchNormalization\nfrom keras.layers import Conv1D, MaxPool1D, CuDNNLSTM, Reshape\nfrom keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate\nfrom keras.datasets import cifar10\nfrom keras import regularizers\nfrom keras.models import Model, Sequential\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.optimizers import SGD, Adam, RMSprop, Adadelta\nimport keras.backend as K\nfrom keras.objectives import mean_squared_error\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\n\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler, LabelBinarizer, RobustScaler, StandardScaler\n\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials","fb42d8ad":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()","7f788d48":"dict = {0:'Airplane', 1:'Automobile', 2:'Bird', 3:'Cat', 4:'Deer', 5:'Dog', 6:'Frog', 7:'Horse', 8:'Ship', 9:'Truck'}","ecfb54aa":"x_test_extra = []\ny_test_extra = []\nx_train_final = []\ny_train_final = []\ncount = [0, 0, 0]\nfor i, j in zip(x_train, y_train):\n    if (j==2):\n        if(count[0]<2000):\n            x_test_extra.append(i)\n            y_test_extra.append(j)\n            count[0]+=1\n        else:\n            x_train_final.append(i)\n            y_train_final.append(j)\n    elif (j==4):\n        if(count[1]<2000):\n            x_test_extra.append(i)\n            y_test_extra.append(j)\n            count[1]+=1\n        else:\n            x_train_final.append(i)\n            y_train_final.append(j)\n    elif (j==9):\n        if(count[2]<2000):\n            x_test_extra.append(i)\n            y_test_extra.append(j)\n            count[2]+=1\n        else:\n            x_train_final.append(i)\n            y_train_final.append(j)\n    else:\n        x_train_final.append(i)\n        y_train_final.append(j)\n        \nx_test_extra = np.array(x_test_extra)\ny_test_extra = np.array(y_test_extra)\nx_train_final = np.array(x_train_final)\ny_train_final = np.array(y_train_final)","a548d643":"x_test_final = np.append(x_test_extra, x_test, axis=0)\ny_test_final = np.append(y_test_extra, y_test, axis=0)","2cf8b0bc":"#x_train_final = x_train    ## These code were used to check model performances with balanced dataset.\n#x_test_final = x_test\n#y_train_final = y_train\n#y_test_final = y_test\nx_train_final = x_train_final.astype('float32')\nx_test_final = x_test_final.astype('float32')\nx_train_final = x_train_final \/ 255\nx_test_final = x_test_final \/ 255","4689ec0f":"from sklearn.model_selection import train_test_split\n\n# Split the data\nx_train, x_valid, y_trainf, y_validf = train_test_split(x_train_final, y_train_final, test_size=0.2, random_state=42, shuffle= True)","f793f4c8":"y_train = keras.utils.to_categorical(y_trainf, 10)\ny_valid = keras.utils.to_categorical(y_validf, 10)\ny_test_one_hot = keras.utils.to_categorical(y_test_final, 10)","704d1091":"def create_block(input, chs): ## Convolution block of 2 layers\n    x = input\n    for i in range(2):\n        x = Conv2D(chs, 3, padding=\"same\")(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n    return x\n\n##############################\n\n## Here, I compute the class weights for using in different models. \n## This is to order our model to emphasize more on classes with less training data.\nclass_weights = class_weight.compute_class_weight(\n               'balanced',\n                np.unique(y_trainf), \n                y_trainf.reshape(y_trainf.shape[0]))\n\nclass_weights\n\n##############################\n\ndef showOrigDec(orig, dec, num=10):  ## function used for visualizing original and reconstructed images of the autoencoder model\n    n = num\n    plt.figure(figsize=(20, 4))\n\n    for i in range(n):\n        # display original\n        ax = plt.subplot(2, n, i+1)\n        plt.imshow(orig[300*i].reshape(32, 32, 3))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        # display reconstruction\n        ax = plt.subplot(2, n, i +1 + n)\n        plt.imshow(dec[300*i].reshape(32, 32, 3))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n        \ndef show_test(m, d):  ## function used for visualizing the predicted and true labels of test data\n    plt.figure(figsize =(40,8))\n    for i in range(5):\n        ax = plt.subplot(1, 5, i+1)\n        test_image = np.expand_dims(d[1810*i+5], axis=0)\n        test_result = m.predict(test_image)\n        plt.imshow(x_test_final[1810*i+5])\n        index = np.argsort(test_result[0,:])\n        plt.title(\"Pred:{}, True:{}\".format(dict[index[9]], dict[y_test_final[1810*i+5][0]]))\n    plt.show()\n    \ndef show_test2(m, d):  ## function used for visualizing the predicted and true labels of test data\n    plt.figure(figsize =(40,8))\n    for i in range(5):\n        ax = plt.subplot(1, 5, i+1)\n        test_image = np.expand_dims(d[1810*i+5], axis=0)\n        test_result = m.predict(test_image)[1]\n        plt.imshow(x_test_final[1810*i+5])\n        index = np.argsort(test_result[0,:])\n        plt.title(\"Pred:{}, True:{}\".format(dict[index[9]], dict[y_test_final[1810*i+5][0]]))\n    plt.show()\n    \ndef report(predictions): ## function used for creating a classification report and confusion matrix\n    cm=confusion_matrix(y_test_one_hot.argmax(axis=1), predictions.argmax(axis=1))\n    print(\"Classification Report:\\n\")\n    cr=classification_report(y_test_one_hot.argmax(axis=1),\n                                predictions.argmax(axis=1), \n                                target_names=list(dict.values()))\n    print(cr)\n    plt.figure(figsize=(12,12))\n    sns.heatmap(cm, annot=True, xticklabels = list(dict.values()), yticklabels = list(dict.values()), fmt=\"d\")\n    \ndef loss_function(y_true, y_pred):  ## loss function for using in autoencoder models\n    mses = mean_squared_error(y_true, y_pred)\n    return K.sum(mses, axis=(1,2))","a136c500":"def full_conv():\n    input = Input((32,32,3))\n    block1 = create_block(input, 32)\n    x = MaxPool2D(2)(block1)\n    #x = Dropout(0.2)(x)\n    block2 = create_block(x, 64)\n    x = MaxPool2D(2)(block2)\n    #x = Dropout(0.3)(x)\n    block3 = create_block(x, 128)\n    #x = MaxPool2D(2)(block3)\n    x = Dropout(0.4)(block3)\n    x = Flatten()(x)\n    output = Dense(10, activation='softmax')(x)\n    return Model(input, output)\n\nconv_model = full_conv()\nconv_model.summary()","c9153682":"#training\nbatch_size = 512\nepochs=50\nopt_rms = Adadelta()\nconv_model.compile(loss='categorical_crossentropy',\n                   optimizer=opt_rms,\n                   metrics=['accuracy'])","ed39dec0":"def run_conv_model(data_aug):\n    er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\n    lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\n    callbacks = [er, lr]\n    \n    if not data_aug:\n        history = conv_model.fit(x_train, y_train, batch_size=512,\n                                 epochs=epochs,\n                                 verbose=1, callbacks=callbacks,\n                                 validation_data=(x_valid,y_valid),\n                                 class_weight=class_weights)\n    else:\n        train_datagen = ImageDataGenerator(shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n        train_set_ae = train_datagen.flow(x_train, y_train, batch_size=512)\n\n        validation_datagen = ImageDataGenerator()\n        validation_set_ae = validation_datagen.flow(x_valid, y_valid, batch_size=512)\n        \n        history = conv_model.fit_generator(train_set_ae,\n                                           epochs=epochs,\n                                           steps_per_epoch=np.ceil(x_train.shape[0]\/512),\n                                           verbose=1, callbacks=callbacks,\n                                           validation_data=(validation_set_ae),\n                                           validation_steps=np.ceil(x_valid.shape[0]\/512),\n                                           class_weight=class_weights)\n        \n        return history","d26b3fe8":"run_conv_model(1)","db38743d":"print('Test accuracy for benchmark model= {}'.format(conv_model.evaluate(x_test_final, y_test_one_hot)[1]))","0472927b":"show_test(conv_model, x_test_final)","2d5340dd":"predictions = conv_model.predict(x_test_final)\nreport(predictions)","bd4c8486":"def unet():  ## I commented several layers of the model for descreasing model complexity as the results were almost same\n    input = Input((32,32,3))\n    \n    # Encoder\n    block1 = create_block(input, 32)\n    x = MaxPool2D(2)(block1)\n    block2 = create_block(x, 64)\n    x = MaxPool2D(2)(block2)\n    #block3 = create_block(x, 64)\n    #x = MaxPool2D(2)(block3)\n    #block4 = create_block(x, 128)\n    \n    # Middle\n    #x = MaxPool2D(2)(block2)\n    middle = create_block(x, 128)\n    \n    # Decoder\n    #x = Conv2DTranspose(128, kernel_size=2, strides=2)(middle)\n    #x = Concatenate()([block4, x])\n    #x = create_block(x, 128)\n    #x = Conv2DTranspose(64, kernel_size=2, strides=2)(x)\n    #x = Concatenate()([block3, x])\n    #x = create_block(x, 64)\n    x = Conv2DTranspose(64, kernel_size=2, strides=2)(middle)\n    x = Concatenate()([block2, x])\n    x = create_block(x, 64)\n    x = Conv2DTranspose(32, kernel_size=2, strides=2)(x)\n    x = Concatenate()([block1, x])\n    x = create_block(x, 32)\n    \n    # output\n    x = Conv2D(3, 1)(x)\n    output = Activation(\"sigmoid\")(x)\n    \n    return Model(input, middle), Model(input, output)\n\ndef general_ae():\n    input = Input((32,32,3))\n    \n    # Encoder\n    block1 = create_block(input, 32)\n    x = MaxPool2D(2)(block1)\n    block2 = create_block(x, 64)\n    x = MaxPool2D(2)(block2)\n    \n    #Middle\n    middle = create_block(x, 128)\n    \n    # Decoder\n    up1 = UpSampling2D((2,2))(middle)\n    block3 = create_block(up1, 64)\n    #up1 = UpSampling2D((2,2))(block3)\n    up2 = UpSampling2D((2,2))(block3)\n    block4 = create_block(up2, 32)\n    #up2 = UpSampling2D((2,2))(block4)\n    \n    # output\n    x = Conv2D(3, 1)(up2)\n    output = Activation(\"sigmoid\")(x)\n    return Model(input, middle), Model(input, output)","ef8543f8":"def run_ae(m):  ## function for choosing unet\/general autoencoder\n    if m=='unet':\n        encoder, model = unet()\n    elif m=='ae':\n        encoder, model = general_ae()\n        \n    return encoder, model","4210d73a":"encoder_unet, model_unet = run_ae('unet')\nmodel_unet.compile(SGD(1e-3, 0.9), loss=loss_function)\nmodel_unet.summary()","8b29d7bb":"er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\nlr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [er, lr]\nhistory = model_unet.fit(x_train, x_train, \n                         batch_size=512,\n                         epochs=100,\n                         verbose=1,\n                         validation_data=(x_valid, x_valid),\n                         shuffle=True, callbacks=callbacks,\n                         class_weight=class_weights)","eaa0a654":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","55e4d214":"recon_test_unet = model_unet.predict(x_test_final)\nrecon_valid_unet = model_unet.predict(x_valid)","4f18ddba":"showOrigDec(x_valid, recon_valid_unet)","03740f61":"showOrigDec(x_test_final, recon_test_unet)","3061f4fd":"encoder_ae, model_ae = run_ae('ae')\nmodel_ae.compile(SGD(1e-3, 0.9), loss=loss_function)\nmodel_ae.summary()","a44d0e05":"er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\nlr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [er, lr]\nhistory = model_ae.fit(x_train, x_train, \n                       batch_size=512,\n                       epochs=100,\n                       verbose=1,\n                       validation_data=(x_valid, x_valid),\n                       shuffle=True, callbacks=callbacks,\n                       class_weight=class_weights)","5e158202":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","449d6f39":"recon_test_ae = model_ae.predict(x_test_final)\nrecon_valid_ae = model_ae.predict(x_valid)","e266172a":"showOrigDec(x_valid, recon_valid_ae)","6975ee6d":"showOrigDec(x_test_final, recon_test_ae)","91ec1222":"gist_train_unet = encoder_unet.predict(x_train)\ngist_valid_unet = encoder_unet.predict(x_valid)\ngist_test_unet = encoder_unet.predict(x_test_final)\n\ngist_train_ae = encoder_ae.predict(x_train)\ngist_valid_ae = encoder_ae.predict(x_valid)\ngist_test_ae = encoder_ae.predict(x_test_final)","7aeefaca":"def classifier_dense(inp):\n    input = Input((inp.shape[1], inp.shape[2], inp.shape[3]))\n    #x = MaxPool2D()(input)\n    x = Flatten()(input)\n    #x = BatchNormalization()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.64)(x)\n    x = Dense(50, activation='relu')(x)\n    #x = Reshape((-1, 1))(x)\n    #x = Conv1D(128, (3,), activation='relu', padding='same')(x)\n    #x = MaxPool1D()(x)\n    #x = CuDNNLSTM(64)(x)\n    #x = Flatten()(x)\n    x = Dropout(0.4)(x)\n    output = Dense(10, activation='softmax')(x)\n    return Model(input, output)\n\ndef classifier_conv(inp):\n    input = Input((inp.shape[1], inp.shape[2], inp.shape[3]))\n    x = Conv2D(1024, 3, padding=\"same\")(input)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(2)(x)\n    x = Dropout(0.5)(x)\n    x = Conv2D(128, 3, padding=\"same\")(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(2)(x)\n    x = Dropout(0.5)(x)\n    x = Flatten()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.35)(x)\n    x = Dense(100, activation='relu')(x)\n    x = Dropout(0.69)(x)\n    output = Dense(10, activation='softmax')(x)\n    return Model(input, output)","32e15d39":"def run_cls(m, inp):  ## function for choosing dense\/convolutional classifier model\n    if m=='dense':\n        classifier = classifier_dense(inp)\n    elif m=='conv':\n        classifier = classifier_conv(inp)\n        \n    return classifier","76f5c1f1":"decoder_ae_conv = run_cls('conv', gist_train_ae)\ndecoder_ae_conv.compile(loss='categorical_crossentropy',\n                        optimizer=Adadelta(),\n                        metrics=['accuracy'])\ndecoder_ae_conv.summary()","8b7f0918":"er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\nlr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [er, lr]\nhist1 = decoder_ae_conv.fit(gist_train_ae, y_train, batch_size=512, epochs=100, \n                            validation_data = (gist_valid_ae, y_valid),\n                            shuffle=True, callbacks=callbacks,\n                            class_weight=class_weights)","b16d5a7b":"plt.plot(hist1.history['acc'])\nplt.plot(hist1.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","eead8f93":"print('Test accuracy for AE_conv model= {}'.format(decoder_ae_conv.evaluate(gist_test_ae, y_test_one_hot)[1]))","bd9b66ce":"show_test(decoder_ae_conv, gist_test_ae)","271dc998":"predictions = decoder_ae_conv.predict(gist_test_ae)\nreport(predictions)","cf890bae":"decoder_ae_dense = run_cls('dense', gist_train_ae)\ndecoder_ae_dense.compile(loss='categorical_crossentropy',\n                         optimizer=Adadelta(),\n                         metrics=['accuracy'])\ndecoder_ae_dense.summary()","109e4e5e":"er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\nlr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [er, lr]\nhist1 = decoder_ae_dense.fit(gist_train_ae, y_train, batch_size=512, epochs=100, \n                             validation_data = (gist_valid_ae, y_valid),\n                             shuffle=True, callbacks=callbacks,\n                             class_weight=class_weights)","6c8c36f1":"plt.plot(hist1.history['acc'])\nplt.plot(hist1.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","c952e454":"print('Test accuracy for AE_dense model= {}'.format(decoder_ae_dense.evaluate(gist_test_ae, y_test_one_hot)[1]))","9fb02028":"show_test(decoder_ae_dense, gist_test_ae)","243b0b12":"predictions = decoder_ae_dense.predict(gist_test_ae)\nreport(predictions)","742f2036":"decoder_un_conv = run_cls('conv', gist_train_unet)\ndecoder_un_conv.compile(loss='categorical_crossentropy',\n                         optimizer=Adadelta(),\n                         metrics=['accuracy'])\ndecoder_un_conv.summary()","652aed25":"er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\nlr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [er, lr]\nhist1 = decoder_un_conv.fit(gist_train_unet, y_train, batch_size=512, epochs=100, \n                            validation_data = (gist_valid_unet, y_valid),\n                            shuffle=True, callbacks=callbacks,\n                            class_weight=class_weights)","bbbc9b51":"plt.plot(hist1.history['acc'])\nplt.plot(hist1.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","5b60a20d":"print('Test accuracy for Unet_conv model= {}'.format(decoder_un_conv.evaluate(gist_test_unet, y_test_one_hot)[1]))","47c4b6c0":"show_test(decoder_un_conv, gist_test_unet)","5a49c6a5":"predictions = decoder_un_conv.predict(gist_test_unet)\nreport(predictions)","6d5fa06f":"decoder_un_dense = run_cls('dense', gist_train_unet)\ndecoder_un_dense.compile(loss='categorical_crossentropy',\n                         optimizer=Adadelta(),\n                         metrics=['accuracy'])\ndecoder_un_dense.summary()","bf51e2db":"er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\nlr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [er, lr]\nhist1 = decoder_un_dense.fit(gist_train_unet, y_train, batch_size=512, epochs=100, \n                             validation_data = (gist_valid_unet, y_valid),\n                             shuffle=True, callbacks=callbacks,\n                             class_weight=class_weights)","9f4954ac":"plt.plot(hist1.history['acc'])\nplt.plot(hist1.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","c6c2c8aa":"print('Test accuracy for Unet_dense model= {}'.format(decoder_un_dense.evaluate(gist_test_unet, y_test_one_hot)[1]))","5a6253f7":"show_test(decoder_un_dense, gist_test_unet)","4a8ee302":"predictions = decoder_un_dense.predict(gist_test_unet)\nreport(predictions)","219aaf5d":"def end_to_end():  ## I commented several layers of the model for descreasing model complexity as the results were almost same\n    input = Input((32,32,3))\n    \n    # Encoder\n    block1 = create_block(input, 32)\n    x = MaxPool2D(2)(block1)\n    block2 = create_block(x, 64)\n    x = MaxPool2D(2)(block2)\n    #block3 = create_block(x, 64)\n    #x = MaxPool2D(2)(block3)\n    #block4 = create_block(x, 128)\n    \n    # Middle\n    #x = MaxPool2D(2)(block2)\n    middle = create_block(x, 128)\n    \n    # Decoder\n    #x = Conv2DTranspose(128, kernel_size=2, strides=2)(middle)\n    #x = Concatenate()([block4, x])\n    #x = create_block(x, 128)\n    #x = Conv2DTranspose(64, kernel_size=2, strides=2)(x)\n    #x = Concatenate()([block3, x])\n    #x = create_block(x, 64)\n    x = Conv2DTranspose(64, kernel_size=2, strides=2)(middle)\n    x = Concatenate()([block2, x])\n    x = create_block(x, 64)\n    x = Conv2DTranspose(32, kernel_size=2, strides=2)(x)\n    x = Concatenate()([block1, x])\n    x = create_block(x, 32)\n    \n    # reconstruction\n    x = Conv2D(3, 1)(x)\n    recon = Activation(\"sigmoid\", name='autoencoder')(x)\n    \n    #classification \n    c = Conv2D(1024, 3, padding=\"same\")(middle)\n    c = Activation('relu')(c)\n    c = BatchNormalization()(c)\n    c = MaxPool2D(2)(c)\n    c = Dropout(0.5)(c)\n    c = Conv2D(128, 3, padding=\"same\")(c)\n    c = Activation('relu')(c)\n    c = BatchNormalization()(c)\n    c = MaxPool2D(2)(c)\n    c = Dropout(0.4)(c)\n    c = Flatten()(c)\n    c = Dense(512, activation='relu')(c)\n    c = Dropout(0.35)(c)\n    c = Dense(100, activation='relu')(c)\n    c = Dropout(0.69)(c)\n    classify = Dense(10, activation='softmax', name='classification')(c)\n    \n    outputs = [recon, classify]\n    \n    return Model(input, outputs)\n","c0fdf10e":"multimodel = end_to_end()\nmultimodel.compile(loss = {'classification': 'categorical_crossentropy', 'autoencoder': loss_function}, \n                  loss_weights = {'classification': 0.9, 'autoencoder': 0.1}, \n                  optimizer = SGD(lr= 0.01, momentum= 0.9),\n                  metrics = {'classification': ['accuracy'], 'autoencoder': []})","1b182807":"er = EarlyStopping(monitor='val_classification_acc', patience=10, restore_best_weights=True)\nlr = ReduceLROnPlateau(monitor='val_classification_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [er, lr]\nhist_mul = multimodel.fit(x_train, [x_train,y_train], batch_size=512, epochs=100, \n                          validation_data = (x_valid, [x_valid,y_valid]),\n                          shuffle=True, callbacks=callbacks)\n#                           class_weight=class_weights","00a60930":"recon_test_e2e = multimodel.predict(x_test_final)[0]\nrecon_valid_e2e = multimodel.predict(x_valid)[0]","6b91d763":"showOrigDec(x_valid, recon_valid_e2e)","94772ec9":"showOrigDec(x_test_final, recon_test_e2e)","1d9720d6":"predictions = multimodel.predict(x_test_final)[1]\nreport(predictions)","6ec66f48":"show_test2(multimodel, x_test_final)","eabed6cb":"# def solvers(func):\n#     scaler_classifier = MinMaxScaler(feature_range=(0.0, 1.0))\n#     pipe = Pipeline(steps=[(\"scaler_classifier\", scaler_classifier),\n#                            (\"classifier\", func)])\n\n#     pipe = pipe.fit(gist_train.reshape(gist_train.shape[0], -1), y_trainf)\n#     acc = pipe.score(gist_test.reshape(gist_test.shape[0], -1), y_test_final)\n#     predict = pipe.predict(gist_test.reshape(gist_test.shape[0], -1))\n    \n#     return acc, predict","7c746b44":"# lr = LogisticRegression(C=5e-1, random_state=666, solver='lbfgs', multi_class='multinomial')\n# rf = RandomForestClassifier(random_state=666)\n# knn = KNeighborsClassifier()\n# svc = svm.SVC()","89ffdef3":"# acc_lr, pred_lr = solvers(lr)\n# acc_lr","9068699b":"# acc_rf, pred_rf = solvers(rf)\n# acc_rf","27b7b9b7":"# acc_knn, pred_knn = solvers(knn)\n# acc_knn","557e0682":"# acc_svc, pred_svc = solvers(svc)\n# acc_svc","1ef19990":"# space = {\n#             'units1': hp.choice('units1', [256,512,1024]),\n#             'units2': hp.choice('units2', [128,256,512]),\n#             'units4': hp.choice('units4', [256,512,1024]),\n#             'units5': hp.choice('units5', [50,64,100,128]),\n#             'dropout1': hp.uniform('dropout1', .25,.75),\n#             'dropout2': hp.uniform('dropout2', .25,.75),\n#             'batch_size' : hp.choice('batch_size', [64,128,256,512]),\n         \n#             'nb_epochs' :  200,\n#             'optimizer': hp.choice('optimizer',['adadelta','adam','rmsprop']),\n#             'activation': 'relu'\n#         }","3877dc50":"# def f_nn(params):   \n#     from keras.models import Sequential\n#     from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Flatten, BatchNormalization\n#     from keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate\n#     from keras.optimizers import Adadelta, Adam, rmsprop\n#     import sys\n\n#     print ('Params testing: ', params)\n#     model = Sequential()\n#     model.add(Conv2D(params['units1'], 3, padding=\"same\", activation=\"relu\"))\n#     model.add(BatchNormalization())\n#     model.add(MaxPool2D())\n#     model.add(Conv2D(params['units2'], 3, padding=\"same\", activation=\"relu\"))\n#     model.add(BatchNormalization())\n#     model.add(MaxPool2D())   \n\n#     model.add(Flatten())\n#     model.add(Dense(output_dim=params['units4'], activation=\"relu\"))\n#     model.add(Dropout(params['dropout1']))\n#     model.add(Dense(output_dim=params['units5'], activation=\"relu\"))\n#     model.add(Dropout(params['dropout2']))\n#     model.add(Dense(10))\n#     model.add(Activation('softmax'))\n#     model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n\n#     model.fit(gist_train, y_train, nb_epoch=params['nb_epochs'], batch_size=params['batch_size'], verbose = 0)\n\n#     acc = model.evaluate(gist_valid, y_valid)[1]\n#     print('Accuracy:', acc)\n#     sys.stdout.flush() \n#     return {'loss': -acc, 'status': STATUS_OK}\n\n\n# trials = Trials()\n# best = fmin(f_nn, space, algo=tpe.suggest, max_evals=5, trials=trials)\n# print('best: ')\n# print(best)","11d892e9":"## Convolutional AE with simple NN as classifier:","6fe846c8":"## Future Works:\n\nI have to experiment more with different classifier models and different hyperparameters. The extracted features are expected to have the most important gist of data of the images. So, I expected models with AE to outperform the baseline model. Also, although U-net model can almost perfectly reconstruct even images in the test dataset inspite of data imbalance, the bottleneck features extracted from it as input to different classifier models performed worst, which was a shock to me.","19f8b3be":"## Necessary functions:","61c8177d":"## Using sklearn models instead of neural networks:\n\nThe following code snippets were used for checking with different sklearn models as classifiers instead of neural networks. I used these to see if tree based models or svm performed better than neural networks to classify test images. But I found that neural networks performed better. Also, svm took a long time to run.","560eeb3c":"I created the following dictionary for using it later in visualizations.","81110539":"## Autoencoder Model:","0a159cd1":"## Unet with convolutional NN as classifier:","e69b288f":"## Simple Convolution Model as Classifier:\n\nHere, I have a model that uses several convolution layers stacked and followed by a dense layer with 10 output nodes and softmax activation. It is used as a single classifier model that I can use as a benchmark model. Dropout layers are used for reducing overfitting.","590b40f9":"## Validation split:\n\nI used 20% of the training data as validation set. Validation data was chosen randomly.","4aead1eb":"Here, we trained a model that learns to generate the images and also classify them at the same time. We used a multi-output model for this task. The encoder part of the autoencoder model is shared for both the task to create similarity with how we did the classification in previous models where we used autoencoders as feature extractor. Also, we used loss_weights to give emphasis on the model to learn classification better. The autoencoder part of the model uses U-net architecture.\n\nThis multi-output model performs better than models where autoencoders were used as feature extractors, but not better than simple cnn models.","42e2bd4f":"From the confusion matrix, we can see that, the model works quite good with only 50 epochs for all the classes inspite of the imbalanced data. It only had problem identifying birds correctly. I found that, the result was worse when I did not use class weights. The model accuracy is also improved by augmenting data.","75544c6e":"As we can see, unet architecture is far better in terms of reconstructing the data.","c3ee5dbd":"## Target conversion to categorical:\n\nThe target variable was converted to one-hot encoded data using the utils.to_categorical function of the keras library.","768f04ee":"## Implement Convolutional AE:","4b8f5866":"## Load Data:\n\nI used the keras datasets library to load the training and testing data.","f744016a":"## Unet with simple NN as classifier:","0fe63170":"## Implementing U-Net:","7af7754e":"# Extra:","a1356261":"## Creating imbalanced data:\n\nI just used the first 2000 images of the bird, deer and truck classes from the training data as test data. In this process, I has 3000 images in both training and test dataset for these 3 classes.","6ed266f2":"## Hyperparameter Optimization:\n\nThe following code was used for hyperparameter optimization of the classifier model. The code was updated during various iterations to suit for different types of models used.","1167efdc":"## Final Verdict:\n\n1. Although, U-net is vastly superior as autoencoder compared to the convolutional autoencoder; the bottleneck features extracted from this model performs badly while classifying. The bottleneck features extracted from the simple convolutional AE model performs better in terms of classifications.\n\n2. Convolution model with dense layer works better than stacked dense layers as classifier model.\n\n3. Multioutput model, that share the encoder part of the autoencoder, works better than learning the autoencoder first and then learning to classify.\n\n4. The baseline model without any autoencoder outperforms all the model.\n\n5. The model can not classify the classes properly that had less training data.","313a504e":"## Convolutional AE with convolutional NN as classifier:","5015a2df":"> ## Introduction:\n\nThe [CIFAR-10](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class (5000 for training and 1000 for testing purpose). In this notebook, I try to implement different autoencoders as feature extractor and using those features as inputs to a classifier model, I try to predict the different classes of images in the CIFAR-10 dataset. There is also one more handicap. I used only 50% of the images (3000 images per class) for training and the rest 50% for testing for the following 3 classes: bird, deer and truck. So, the training data is imbalanced.\n\nI used both general convolutional autoencoder and [U-net](https:\/\/arxiv.org\/pdf\/1505.04597.pdf) model as autoencoder for feature extraction purpose. For the classifier model, I used both simple stacked dense layers and also convolution layers and then dense layers. I used hyperopt library to find out the optimized hyperparameters for the classifier model. I also used the class-weight function from the sklearn.utils library for using different class weights to tackle the imbalanced training data.\n\nI found that, U-net architecture (with connector layers) is vastly superior as autoencoders compared to general convolutional autoencoders. But using the features generated from the U-net architecture resulted in low accuracy for the classifier models.","617f951c":"## Extracting bottleneck features to use as inputs in the classifier model:","81955a72":"## Data Normalization:\n\nData was normalized because neural networks work better with normalized data.","ea3eca54":"## Multi-output Model:","c34168bf":"## Classifier Models:"}}