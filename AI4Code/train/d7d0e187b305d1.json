{"cell_type":{"e14f1920":"code","e6601b82":"code","15156ccb":"code","d5c9c64e":"code","775b19f6":"code","3b10f95c":"code","9e7d3481":"code","feafae2a":"code","e93b064c":"code","c5734945":"code","3c50d465":"code","52927594":"code","74cb9dce":"code","3ece2529":"code","c70c4e39":"code","8385d495":"markdown","0bf89872":"markdown","aec78a58":"markdown","d265ff71":"markdown","e8392ebd":"markdown","036a914b":"markdown","ec20b993":"markdown","36067d25":"markdown","8c88f04e":"markdown","e3ba44b9":"markdown","45fc5311":"markdown","83c75436":"markdown","20e5706c":"markdown","97f19518":"markdown"},"source":{"e14f1920":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy import stats\nfrom scipy.stats import norm\n\nimport datetime\nimport json\nfrom math import sqrt\n\nnumeric_cols = 'views', 'likes', 'dislikes', 'comment_count'\n\n    \ndef inform(df, msg):\n    \"\"\"Prints the <msg> (<str>) about null cells in the <df> (<pd.DataFrame>).\"\"\"\n    print('NaN CELLS {}:\\n{}\\n'.format(msg, df.isna().sum()))\n\n\ndef write_dataset(df, name):\n    \"\"\"Saves the <df> (<pd.DataFrame>) with the file <name> (<str>).\"\"\"\n    path = '\/kaggle\/working\/' + name\n    df.to_csv(path, index=False)\n    print('Modified dataset saved to', path)\n\n\nwith open('\/kaggle\/input\/youtube-new\/INvideos.csv', 'r') as f:\n    df = pd.read_csv(f)\ninform(df, 'BEFORE DIRTYING')\nfor i in range(1, 36000, 3):\n    df.loc[[i], df.columns[4]] = np.nan\n    df.loc[[i], df.columns[10]] = np.nan\ninform(df, 'AFTER DIRTYING')\nwrite_dataset(df, 'dirty.csv')","e6601b82":"avg = df[df.columns[10]].mean()\nfor i in range(1, 36000, 3):\n    df.loc[[i], df.columns[10]] = avg\ndf.fillna(method='ffill', inplace=True)\ninform(df, 'AFTER CLEANING')\nwrite_dataset(df, 'clean.csv')","15156ccb":"print('Null hypothesis: Trending videos receive an average of over 1 million views each')\nprint('Alternate hypothesis: Trending videos receive less than or equal to 1 million views each')\nalpha = 0.05\nx = df['views'].mean()\nmu = 1000 * 1000\nstd = df['views'].std()\nz = (x-mu) \/ std\nprint('alpha: {}\\nmu: {}\\nx: {}\\nstd: {}\\nz: {}'.format(alpha, mu, x, std, z))\n","d5c9c64e":"def distplot():\n    sns.distplot(df['views'])\n\n    \ndef hist():\n    plt.hist(df['comment_count'], alpha=.3)\n    sns.rugplot(df['comment_count'])\n    \n    \ndistplot()","775b19f6":"hist()","3b10f95c":"def print_stats(df, is_before):\n    \"\"\"State whether this <is_before> (<bool>) the <df>'s (<pd.DataFrame>) modification.\"\"\"\n    print('{} MODIFICATION:'.format('BEFORE' if is_before else 'AFTER'))\n    for col in numeric_cols:\n        print('{0} mean = {1}\\n{0} variance = {2}'.format(col, df[col].mean(), df[col].var()))\n    print()\n\n\nprint_stats(df, is_before=True)\nfor col in numeric_cols:\n    values = df[[col]].values.astype(float)\n    df[col] = pd.DataFrame(MinMaxScaler().fit_transform(values))\nprint_stats(df, is_before=False)\nwrite_dataset(df, 'normalized.csv')","9e7d3481":"distplot()","feafae2a":"hist()","e93b064c":"pd.DataFrame({col: [df[col].mean()] for col in numeric_cols}).plot(kind='bar')","c5734945":"with open(\"\/kaggle\/input\/youtube-new\/IN_category_id.json\") as f:\n    categories = json.load(f)[\"items\"]\ncat_dict = {}\nfor cat in categories:\n    cat_dict[int(cat[\"id\"])] = cat[\"snippet\"][\"title\"]\ndf['category_name'] = df['category_id'].map(cat_dict)\ncdf = df[\"category_name\"].value_counts().to_frame().reset_index()\ncdf.rename(columns={\"index\": \"category_name\", \"category_name\": \"No_of_videos\"}, inplace=True)\nfig, ax = plt.subplots()\n_ = sns.barplot(x=\"category_name\", y=\"No_of_videos\", data=cdf, \n                palette=sns.cubehelix_palette(n_colors=16, reverse=True), ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"No. of videos\")","3c50d465":"df[\"publishing_day\"] = df[\"publish_time\"].apply(\n    lambda x: datetime.datetime.strptime(x[:10], \"%Y-%m-%d\").date().strftime('%a'))\ndf[\"publishing_hour\"] = df[\"publish_time\"].apply(lambda x: x[11:13])\ndf.drop(labels='publish_time', axis=1, inplace=True)\n\ncdf = df[\"publishing_day\"].value_counts().to_frame().reset_index().rename(\n    columns={\n        \"index\": \"publishing_day\", \n        \"publishing_day\": \"No_of_videos\"\n    }\n)\nfig, ax = plt.subplots()\n_ = sns.barplot(\n    x=\"publishing_day\", \n    y=\"No_of_videos\", \n    data=cdf, \n    palette=sns.color_palette(\n        ['#003f5c', '#374c80', '#7a5195', '#bc5090', '#ef5675', '#ff764a', '#ffa600'],\n        n_colors=7\n    ), \n    ax=ax\n)\n_ = ax.set(xlabel=\"Publishing Day\", ylabel=\"No. of videos\")\n\ncdf = df[\"publishing_hour\"].value_counts().to_frame().reset_index()\\\n        .rename(columns={\"index\": \"publishing_hour\", \"publishing_hour\": \"No_of_videos\"})\nfig, ax = plt.subplots()\n_ = sns.barplot(x=\"publishing_hour\", y=\"No_of_videos\", data=cdf, \n                palette=sns.cubehelix_palette(n_colors=24), ax=ax)\n_ = ax.set(xlabel=\"Publishing Hour\", ylabel=\"No. of videos\")","52927594":"value_counts = df[\"comments_disabled\"].value_counts().to_dict()\nfig, ax = plt.subplots()\n_ = ax.pie(x=[value_counts[False], value_counts[True]], labels=['No', 'Yes'], \n           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'})\n_ = ax.axis('equal')\n_ = ax.set_title('Comments Disabled?')\n\nvalue_counts = df[\"ratings_disabled\"].value_counts().to_dict()\nfig, ax = plt.subplots()\n_ = ax.pie([value_counts[False], value_counts[True]], labels=['No', 'Yes'], \n            colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'})\n_ = ax.axis('equal')\n_ = ax.set_title('Ratings Disabled?')","74cb9dce":"df.corr(method='pearson')","3ece2529":"df.plot.scatter(x='views', y='likes')\ndf.plot.scatter(x='views', y='dislikes')\ndf.plot.scatter(x='views', y='comment_count')","c70c4e39":"df.plot.scatter(x='comment_count', y='views')\ndf.plot.scatter(x='comment_count', y='likes')\ndf.plot.scatter(x='category_id', y='dislikes')","8385d495":"1. **Insight**\n\n    People watch more videos during the end of the week, with the highest being on Friday. Fewer videos are watched during the beginning of the week, the lowest being on Sunday.\n    \n    **Explanation**\n    \n    People usually work more during the beginning of the week, and wind down towards the beginning of the weekend.\n    \n    **Action**\n    \n    Videos should be published right before the start of the weekend.\n1. **Insight**\n\n    Indians usually watch YouTube during the afternoon or morning.\n    \n    **Explanation**\n    \n    A lot of news is watched during the morning, as well as entertainment videos while traveling to college.\n    \n    **Action**\n    \n    Live video streams should be done during the afternoons or mornings so as to to engage with the maximum number of users.","0bf89872":"## Insights From Visualizations\n\n### Which video category has the highest number of trending videos?","aec78a58":"Here's what the dataset looks like before normalization.","d265ff71":"### How many trending videos have their comments or ratings disabled?","e8392ebd":"We can see that the `views` and `likes` columns are correlated the most: the higher the number of views, the higher the number of likes.\nFrom this, we can **infer** that better videos get viewed more.","036a914b":"1. **Insight**\n\n    The most popular (by far) category was _Entertainment_.\n\n    **Explanation**\n\n    This makes sense since YouTube started out primarily as an entertainment site.\n\n    **Action**\n\n    YouTubers should aim to create entertainment videos since the majority of the audience uses YouTube during their downtime.\n1. **Insight**\n\n    The next most popular categories were _News & Politics_, _Music_, and _Comedy_. \n\n    **Explanation**\n\n    India is a boiling pot of cultures, and there is no shortage of news for avid citizens. Popular news channels such as _The Times of India_ have highly active YouTube channels where people agedr 20-60 watch regularly. Teenagers flock to YouTube for free music from around the world. It is a fact that YouTube has recognized their popularity in the music industry since they recently launced _YouTube Music_. Comedy is yet another popular category, which can be accepted as a fact since there are a great number of ads for comedians on the service.\n\n    **Action**\n\n    - News sites should maintain YouTube channels.\n    - Musicians should accompany their tracks with music videos.\n    - Stand-up comedians should embrace online platforms such as YouTube to gain extra revenue from their live shows.","ec20b993":"## Hypothesis Testing\n\n- Null hypothesis: There is one rating (1 like or dislike) for every 25 views.\n- Alternate hypothesis: There isn't one rating for every 25 views.","36067d25":"We can see that the `category_id` and `dislikes` columns have the least correlation. \nThe **reason** behind this is because certain categories of videos (e.g., entertainment) get significantly more views. Hence, the ratings such as dislikes varies widely across categories of videos.","8c88f04e":"## Cleaning the Dataset\n\nAll the NaN cells for categorical columns will be replaced with their previous row's value. All the NaN cells for numerical columns will be replaced with their column's average.","e3ba44b9":"# YouTube Statistics Analysis\n\nThis data science project analyzes Indian YouTube statistics. \nIt was created for the UE18CS203 (B. Tech CSE third semester Introduction to Data Science course) project. A few of the charts were taken from [YouTube Trending Videos Analysis (More Than 40,000 Videos)](https:\/\/www.kaggle.com\/ammar111\/youtube-trending-videos-analysis).\n\n## Dirtying the Dataset\n\nWe need 3%-5% of the cells to be NaN. Since this dataset contains a relatively negligible number of NaN cells, we'll manually dirty it by replacing 24,000 cells (4% of the cells) with NaN. 12,000 cells from column 4 (a categorical column), and 12,000 cells from column 10 (a numerical column) will be replaced. Since there are more than 36,000 rows, we'll replace a cell in every third row.","45fc5311":"Here's the dataset after normalization.","83c75436":"1. **Insight**\n\n    Disabling comments or ratings severely impacts the ability of videos to become popular.\n    \n    **Explanation**\n    \n    Viewers feel that videos with their ratings or comments disabled are untrustworthy.\n    \n    **Action**\n    \n    Have comments and ratings enabled on all your videos.\n1. **Insight**\n\n    Videos with disabled ratings or comments occasionally become popular.\n    \n    **Explanation**\n    \n    Although videos with disabled comments or ratings have a significantly lower chance of becoming popular, we still see such videos occasionally becoming popular. This can be attributed to the fact that controversial videos have their ratings or comments disabled later on. Many a times videos are viewed in large numbers simply because of the absurdity of their content, and not their actual value to the customer.\n    \n    **Action**\n    \n    Do not disable comments or ratings on your video to prevent the potential for negative publicity. Videos which have shown otherwise are an exception, not the rule.\n    \n## Correlation","20e5706c":"## Normalization and Standardization\n\nWe'll normalize the numerical columns in order to make the mean 0, and the variance 1.\n\n### Why is normalization important?\n\nNormalization is important because it brings all the values of numerical columns to a common scale.\n\n### How does normalization affect the dataset?\n\nIt affects the dataset by making all the elements lie between 0 and 1.","97f19518":"### Trending Videos and Publish Time"}}