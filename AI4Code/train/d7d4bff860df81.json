{"cell_type":{"9d59e445":"code","292a5503":"code","edfa363f":"code","50053691":"code","81894ea1":"code","75d520a0":"code","c3f293d9":"code","6a70ef1a":"code","0cd1017d":"code","80fa749a":"code","3bb5e7aa":"markdown"},"source":{"9d59e445":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","292a5503":"import random\n\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport time\nimport os\n\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess, Fourier\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\n\nfrom joblib import Parallel, delayed\nimport warnings\n\nfrom path import Path","edfa363f":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","50053691":"path = Path('..\/input\/store-sales-time-series-forecasting')","81894ea1":"def get_calendar():\n\n    events_df = create_events_df()\n \n\n    calendar = pd.DataFrame({\"date\" : pd.date_range('2013-01-01', '2017-08-31')} )\n    \n    calendar = add_events_df_columns(calendar)      \n    calendar = add_dofw_column(calendar)\n    calendar = add_wd_column(calendar)\n    calendar = add_dcoilwtico_column(calendar)\n    calendar = add_rolling_mean_oil_column(calendar, 7)\n\n    \n    calendar[\"date\"] = calendar.date.dt.to_period('D')\n    calendar = calendar.set_index(\"date\")\n    \n    \n    calendar = calendar[ [\"dofw\", \"type\", \"wd\",  \"dcoilwtico\", \"oil_ma7\"] ]\n    calendar[\"type\"] = calendar[\"type\"].fillna(\"None\")\n    \n \n    return calendar\n\n\n\n\ndef get_y():\n    df_train = pd.read_csv(path \/ 'train.csv',\n                           usecols=['store_nbr', 'family', 'date', 'sales'],\n                           dtype={'store_nbr': 'category', 'family': 'category', 'sales': 'float32'},\n                           parse_dates=['date'], infer_datetime_format=True)\n    df_train.date = df_train.date.dt.to_period('D')\n    df_train = df_train.set_index(['store_nbr', 'family', 'date']).sort_index()\n\n    y = df_train.unstack(['store_nbr', 'family'])\n    \n    \n    return y\n\n\n\n\ndef add_events_df_columns(calendar):\n    events_df = create_events_df()\n    calendar = calendar.merge(events_df, on=\"date\", how='left')\n    \n    return calendar\n\n\n\ndef add_dcoilwtico_column(calendar):\n    oil_df = create_oil_df()\n    calendar = calendar.merge(oil_df, on=\"date\", how=\"left\")\n    calendar[\"dcoilwtico\"] = calendar[\"dcoilwtico\"].fillna(method=\"ffill\")\n\n    return calendar\n    \n\ndef add_rolling_mean_oil_column(calendar, num):\n    calendar[f\"oil_ma{num}\"]  = calendar['dcoilwtico'].rolling(num).mean()\n    calendar[f\"oil_ma{num}\"]  = calendar[f\"oil_ma{num}\"].fillna(method=\"ffill\")\n    \n    return calendar\n\n\n\ndef add_dofw_column(calendar):\n    calendar['dofw'] = calendar[\"date\"].apply(lambda x: x.dayofweek)\n    return calendar\n\n\ndef add_wd_column(calendar):\n    calendar['wd'] = True\n\n    calendar.loc[calendar.dofw > 4, 'wd'] = False\n    calendar.loc[calendar.type == 'Bridge'  , 'wd'] = False\n    calendar.loc[calendar.type == 'Work Day', 'wd'] = True\n    calendar.loc[calendar.type == 'Transfer', 'wd'] = False\n    calendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == False), 'wd'] = False\n    calendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == True ), 'wd'] = True\n\n    \n    return calendar\n\n    \n    \n\ndef fill_na(calendar):\n    calendar[\"type\"] = calendar[\"type\"].fillna(\"None\")\n    return calendar\n \n\ndef create_oil_df():\n    oil_df = pd.read_csv(path \/ 'oil.csv', parse_dates=['date'], infer_datetime_format=True)\n    return oil_df\n\n\n\n\n\n\ndef create_events_df():\n    events_df = pd.read_csv(path \/ 'holidays_events.csv', parse_dates=['date'], infer_datetime_format=True)\n    events_df['date'] = events_df['date'].replace({'2013-04-29' : \n                                                 pd.to_datetime('2013-03-29')}) # 'Good Friday' mistake correction\n\n    events_df = events_df.sort_values(by=\"date\")         \n    events_df = events_df[events_df.locale == 'National'] \n    events_df = events_df.groupby(by=\"date\").first() \n\n    \n    return events_df","75d520a0":"class CustomRegressor():\n\n    def __init__(self, n_jobs=-1, verbose=0, alpha=0.6):\n\n        self.n_jobs = n_jobs\n        self.verbose = verbose\n\n        self.estimators_ = None\n            \n        self.alpha = alpha\n\n    def _estimator_(self, X_ridge, X_rf, y):\n\n        warnings.simplefilter(action='ignore', category=FutureWarning)\n\n        if y.name[2] == 'SCHOOL AND OFFICE SUPPLIES':\n            model = RandomForestRegressor(n_estimators = 300, n_jobs=-1, random_state=1)\n            X = X_rf\n            choice = 0\n        else:\n            model = Ridge(fit_intercept=True, solver='auto', alpha=self.alpha, normalize=True)\n            X = X_ridge\n            choice = 1\n\n        model.fit(X, y)\n\n        \n        return model, choice\n\n    def fit(self, X_ridge, X_rf, y):\n\n        self.estimators_ =  Parallel(n_jobs=self.n_jobs, \n                                  verbose=self.verbose,\n                                  )(delayed(self._estimator_)(X_ridge, X_rf, y.iloc[:, i]) for i in range(y.shape[1]))\n\n        return\n\n    def predict(self, X_ridge, X_rf):\n        X = [X_rf, X_ridge]\n        \n\n        y_pred = Parallel(n_jobs=self.n_jobs, \n                              verbose=self.verbose)(delayed(self.estimators_[i][0].predict)(X[self.estimators_[i][1]])  for i in range(len(self.estimators_)))\n        \n        return np.stack(y_pred, axis=1)","c3f293d9":"def get_ridge_full(order):\n    fourier = CalendarFourier(freq='W', order=order)\n    dp = DeterministicProcess(index=df.index,\n                              constant=False,\n                              order=1,\n                              seasonal=False,\n                              additional_terms=[fourier],\n                              drop=True)\n\n    X = dp.in_sample()\n    X_ridge_full = X_ridge.copy()\n    \n    for c in X.columns:\n        X_ridge_full[c] = X[c].values\n        \n\n    \n    return X_ridge_full\n\n\ndef get_rf_full():\n    fourier = CalendarFourier(freq='W', order=0)\n    dp = DeterministicProcess(index=df.index,\n                              constant=False,\n                              order=1,\n                              seasonal=False,\n                              additional_terms=[fourier],\n                              drop=True)\n\n    X = dp.in_sample()\n    \n    \n    X_rf_full = X_rf.copy()\n    \n    for c in X.columns:\n        X_rf_full[c] = X[c].values\n    \n    \n    return X_rf_full\n\n\ndef add_month_column(X, dummies=True):\n    X[\"month\"] = [x.month for x in X.index]\n    if dummies:\n        X = pd.get_dummies(X, columns=['month'], drop_first=False)\n        \n    return X\n\n\ndef add_season_column(X, dummies=True):\n    X[\"season\"] = [x.month \/\/ 3 for x in X.index]\n    X = pd.get_dummies(X, columns=['season'], drop_first=False)\n    \n    return X\n\n\n\ntrain_start = '2017-04-15'\ntrain_end = '2017-08-15'\n\n\ntest_start = '2017-08-16'\ntest_end = '2017-08-31'\n\norder = 3\nadd_rolling_mean_14 = 1\nadd_rolling_mean_30 = 0\nadd_month = 0\nadd_season = 1\nalpha = 1.125\n    \n\n\ndf = get_calendar()\ny = get_y()\n\ny = y.loc['2017-01-01':]           \ndf = df.loc['2017-01-01':]\n\n\nle = LabelEncoder()\nX_rf = df[[\"dofw\", \"wd\", \"dcoilwtico\", \"type\", \"oil_ma7\"]].copy()\nX_rf[\"type\"] = le.fit_transform(X_rf[\"type\"])\n\n\n\nX_ridge = df[[\"dofw\", \"wd\", \"dcoilwtico\", 'type', \"oil_ma7\"]].copy()\nX_ridge = pd.get_dummies(X_ridge, columns=['dofw'], drop_first=True)\nX_ridge = pd.get_dummies(X_ridge, columns=['type'])\nX_ridge = X_ridge.drop([\"type_None\"], axis=1)\n\n\nX_ridge_full = get_ridge_full(order)\nX_rf_full = get_rf_full()\n    \n        \nif add_rolling_mean_14:\n    X_ridge_full = add_rolling_mean_oil_column(X_ridge_full, 14)\n    X_rf_full = add_rolling_mean_oil_column(X_rf_full, 14)\n        \n        \nif add_rolling_mean_30:\n    X_ridge_full = add_rolling_mean_oil_column(X_ridge_full, 30)\n    X_rf_full = add_rolling_mean_oil_column(X_rf_full, 30)\n        \nif add_month:\n    X_ridge_full = add_month_column(X_ridge_full, dummies=True)\n    X_rf_full = add_month_column(X_rf_full)\n    \nif add_season:\n    X_ridge_full = add_season_column(X_ridge_full, dummies=True)\n    X_rf_full = add_season_column(X_rf_full)\n    \n    \nX_ridge_full.drop([\"dcoilwtico\"], axis=1, inplace=True)\nX_rf_full.drop([\"dcoilwtico\"], axis=1, inplace=True)\n    \n\n\nX_ridge_full_train = X_ridge_full.loc[train_start:train_end]\nX_rf_full_train = X_rf_full.loc[train_start:train_end]\n    \ny_train = y.loc[train_start:train_end]\n\n    \nX_ridge_full_test = X_ridge_full.loc[test_start:test_end]\nX_rf_full_test = X_rf_full.loc[test_start:test_end]\n","6a70ef1a":"model = CustomRegressor(n_jobs=-1, verbose=0, alpha=alpha)\nmodel.fit(X_ridge_full_train, X_rf_full_train, y_train)","0cd1017d":"y_pred = model.predict(X_ridge_full_test, X_rf_full_test)","80fa749a":"y_pred = pd.DataFrame(y_pred, index=df.loc[test_start:test_end].index, columns=y.columns)\ny_pred = y_pred.stack(['store_nbr', 'family'])\ny_pred[y_pred < 0] = 0. \n\nsubmission = pd.read_csv(path \/ 'sample_submission.csv', index_col='id')\nsubmission.sales = y_pred.values\nsubmission.to_csv('submission.csv', index=True)","3bb5e7aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}