{"cell_type":{"0724ef97":"code","113f14ed":"code","6f5ed74b":"code","3214f942":"code","f69436ac":"code","72201f37":"code","bbcddfdf":"code","a397bda4":"code","1100e12e":"code","b47dd35f":"code","d86480d1":"code","e2fedfab":"code","9f1dc8e3":"code","fca60c4d":"code","2540ab84":"code","febb2215":"code","000ae569":"code","ea3773dd":"code","ed5048a8":"code","2668fd45":"code","280e0eba":"code","76201ac3":"markdown","549f9f41":"markdown","b234a70e":"markdown","8340636b":"markdown","658ccbce":"markdown","f16e814b":"markdown","d84d9f77":"markdown","e425fe11":"markdown","fb75a71a":"markdown","167691f7":"markdown"},"source":{"0724ef97":"!pip install -U pycocotools\n!pip install -U tf_slim\n!pip install tensorflow==1.15\n!pip install tensorflow-gpu==1.15","113f14ed":"import os\nimport sys\nfrom io import BytesIO\nfrom PIL import Image\nimport pylab\nimport urllib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport shutil\nimport tensorflow as tf\nimport time\nprint(tf.__version__)\nprint(f\"GPU available? {tf.test.is_gpu_available()}\")\n\n\n# %load_ext tensorboard","6f5ed74b":"%cd \/kaggle\/working\n# Install protoc\n!wget -O protobuf.zip https:\/\/github.com\/google\/protobuf\/releases\/download\/v3.0.0\/protoc-3.0.0-linux-x86_64.zip\n!unzip -o protobuf.zip\n!rm protobuf.zip","3214f942":"#Clone TensorFlow Object Detection API v1.12.0\n%mkdir \/kaggle\/tensorflow\n%cd \/kaggle\/tensorflow\n!rm -fr models\n!git clone --depth 1 https:\/\/github.com\/tensorflow\/models.git\n!rm -fr models\/.git\n    \n# compile ProtoBuffers\n%cd models\/research\n!\/kaggle\/working\/bin\/protoc object_detection\/protos\/*.proto --python_out=.\n%cd \/kaggle\/working","f69436ac":"# Set environment variables\nos.environ['AUTOGRAPH_VERBOSITY'] = '0'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONPATH']=f\"{os.environ['PYTHONPATH']}:\/kaggle\/tensorflow\/models\/research:\/kaggle\/tensorflow\/models\/research\/slim\"\nsys.path.append(\"\/kaggle\/tensorflow\/models\/research\")\nsys.path.append(\"\/kaggle\/tensorflow\/models\/research\/slim\")","72201f37":"%cd \/kaggle\/working\n!python \/kaggle\/tensorflow\/models\/research\/object_detection\/builders\/model_builder_test.py","bbcddfdf":"# %%capture\nif os.path.exists(\"\/kaggle\/working\/dataset\"):\n    shutil.rmtree(\"\/kaggle\/working\/dataset\")\nshutil.copytree(\"\/kaggle\/input\/finding-railway-fasteners-in-image-data-prorail\/dataset_kaggle\",\n                \"\/kaggle\/working\/dataset\")\nos.environ['ROOT'] = '\/kaggle\/working'\n\n# Create tf record files with a custom script called \"generate_tfrecord\"\nfor split in ['train', 'val', 'test']:\n  os.environ['SPLIT'] = split\n  !python ${ROOT}\/dataset\/generate_tfrecord.py\\\n    --csv_input ${ROOT}\/dataset\/${SPLIT}_annotations.csv\\\n    --output_path ${ROOT}\/dataset\/${SPLIT}.record\\\n    --path_to_labels ${ROOT}\/dataset\/labelmap.pbtxt\\\n    --img_path ${ROOT}\/dataset\/${SPLIT}\n","a397bda4":"from object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_util\n\n%cd \/kaggle\/working\n\nmodel_name = \"ssd_mobilenet_v2_coco_2018_03_29\"\nos.environ['MODEL'] = model_name\n!mkdir models\n!wget -O ${MODEL}.tar.gz  http:\/\/download.tensorflow.org\/models\/object_detection\/${MODEL}.tar.gz -q\n!tar -C \/kaggle\/working\/models -xvzf ${MODEL}.tar.gz\n!rm ${MODEL}.tar.gz\n\n# download category index\n!wget -O models\/mscoco_label_map.pbtxt https:\/\/raw.githubusercontent.com\/tensorflow\/models\/master\/research\/object_detection\/data\/mscoco_label_map.pbtxt\ncategory_index_coco = label_map_util.create_category_index_from_labelmap(\"models\/mscoco_label_map.pbtxt\", use_display_name=True)","1100e12e":"## Download an image\nurl = \"https:\/\/i.pinimg.com\/474x\/4c\/e8\/04\/4ce8048a99b43441dd58e91b4c3eadcb--choo-tractors.jpg\"\ndata = BytesIO(urllib.request.urlopen(url).read())\nimage = pylab.imread(data, format='jpg').astype(np.uint8)\nImage.fromarray(image)","b47dd35f":"# Make a prediction\ng = tf.Graph()\nwith g.as_default():\n  model = tf.keras.models.load_model(os.path.join(\"\/kaggle\/working\/models\", \n                                                  model_name, \n                                                  \"saved_model\"))\n  model = model.signatures['serving_default']\n  output_dict = model(tf.convert_to_tensor(np.expand_dims(image, 0)))  # here we make the prediction\n  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\ng.finalize()\n\n# Create session and initialize.\nsession = tf.Session(graph=g)\nsession.run(init_op)\noutput_dict = session.run(output_dict)  # here we execute the graph","d86480d1":"vis_util.visualize_boxes_and_labels_on_image_array(\n  image,\n  np.array(output_dict['detection_boxes'])[0],\n  np.array(output_dict['detection_classes']).astype('int')[0],\n  np.array(output_dict['detection_scores'])[0],\n  category_index_coco,\n  use_normalized_coordinates=True,\n  line_thickness=3)\n\ndisplay(Image.fromarray(image))","e2fedfab":"steps=30\nos.environ[\"PIPELINE_CONFIG_PATH\"]=\"\/kaggle\/working\/dataset\/pipeline.config\"\nos.environ[\"MODEL_DIR\"]=f\"\/kaggle\/working\/models\/my_model\"\nos.environ[\"NUM_TRAIN_STEPS\"]=f\"{steps}\"  # 1000 steps takes about 10 minutes on a GPU and gives OK results for lightest mobilenet (ssd_mobilenet_v2)\nos.environ[\"SAMPLE_1_OF_N_EVAL_EXAMPLES\"]=\"1\"\n\n# %load_ext tensorboard\n# %tensorboard --logdir \/kaggle\/working\/models\/my_model","9f1dc8e3":"# model_dir: where the new model will be saved\n# Make sure this is different from your starting point!\nt1 = time.time()\n!python \/kaggle\/tensorflow\/models\/research\/object_detection\/model_main.py \\\n    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\n    --model_dir=${MODEL_DIR} \\\n    --num_train_steps=${NUM_TRAIN_STEPS} \\\n    --sample_1_of_n_eval_examples=${SAMPLE_1_OF_N_EVAL_EXAMPLES} \\\n    --alsologtostderr\nt2 = time.time()","fca60c4d":"# Takes about \nprint(f\"{t2 - t1:.1f}s\")","2540ab84":"export_dir=f\"\/kaggle\/working\/models\/my_model_inference\"\nos.environ['INPUT_TYPE']=\"image_tensor\"\nos.environ[\"TRAINED_CKPT_PREFIX\"]=os.path.join(os.environ[\"MODEL_DIR\"], f\"model.ckpt-{steps}\")  # extract with\nos.environ['EXPORT_DIR']=export_dir","febb2215":"%%capture\n!python \/kaggle\/tensorflow\/models\/research\/object_detection\/export_inference_graph.py \\\n    --input_type=${INPUT_TYPE} \\\n    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\n    --trained_checkpoint_prefix=${TRAINED_CKPT_PREFIX} \\\n    --output_directory=${EXPORT_DIR}","000ae569":"image = pylab.imread(\"\/kaggle\/working\/dataset\/test\/11003.jpg\", format='jpg').astype(np.uint8)\nplt.imshow(image)\nplt.show()","ea3773dd":"g = tf.Graph()\nwith g.as_default():\n  new_model = tf.keras.models.load_model(os.path.join(export_dir, \"saved_model\"))\n  new_model = new_model.signatures['serving_default']\n  output_dict = new_model(tf.convert_to_tensor(np.expand_dims(image, 0)))\n  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\ng.finalize()\n\n# Create session and initialize.\nsession = tf.Session(graph=g)\nsession.run(init_op)\noutput_dict = session.run(output_dict)","ed5048a8":"# load labels (this is some sort of a protobuf file)\ncategory_index = label_map_util.create_category_index_from_labelmap(\"\/kaggle\/working\/dataset\/labelmap.pbtxt\", use_display_name=True)","2668fd45":"image_with_box = image.copy()\nvis_util.visualize_boxes_and_labels_on_image_array(\n  image_with_box,\n  np.array(output_dict['detection_boxes'])[0],\n  np.array(output_dict['detection_classes']).astype('int')[0],\n  np.array(output_dict['detection_scores'])[0],\n  category_index,\n  use_normalized_coordinates=True,\n  line_thickness=3)\n\nf = plt.figure(figsize=(8, 8))\nplt.imshow(image_with_box)\nplt.show()","280e0eba":"# show a cropped image\nboxes = output_dict['detection_boxes']\ni=0\nheight, width = image.shape[:2]\nymin = int(boxes[0,i,0] * height)\nxmin = int(boxes[0,i,1] * width)\nymax = int(boxes[0,i,2] * height)\nxmax = int(boxes[0,i,3] * width)\ncropped_image = tf.image.crop_to_bounding_box(image, ymin, xmin, \n                                       ymax - ymin, xmax - xmin)\n\nsess = tf.Session()\nwith sess.as_default():\n  cropped_image = tf.image.crop_to_bounding_box(image, ymin, xmin, \n                                       ymax - ymin, xmax - xmin).eval()\nImage.fromarray(cropped_image)","76201ac3":"## 2. Prepare data\nMore information about how to create the tfrecord files can be found [here](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/g3doc\/using_your_own_dataset.md). It can be a a bit tedious, so we provide a script called `generate_tfrecord.py`.\n\nThe data gets split into separate sets for training, validation and testing. The model learns from the training data, but we use separate validation and test sets to make sure our model generalizes to unseen data!","549f9f41":"Next, we visualize the bounding box. Note that this tool will actually draw the box onto the array... so if you want to save it, make a copy.","b234a70e":"## 4. Train your own model\nUsing pre-trained models is fun, but it won't help to detect railway fasteners. Lets train our own!","8340636b":"## 3. Load a pretrained model","658ccbce":"## 6. Inference","f16e814b":"## Install tf-object-detection API","d84d9f77":"# Detection railway fasteners in images\nAuthor: Richard Bartels (richard.bartels [at] vantage-ai.com; richard.bartels [at] prorail.nl)\n\nNote: please run all cells one by one in order for the notebook to work properly.","e425fe11":"## Install tensorflow <= 1.15.*\nIn order to install an older version of tensorflow run the below cell and then restart the kernel (press CMD+shift+p on mac or ctrl+shift+p). This version is required for the object detection api. You won't have to rerun this cell after restarting\n\n**NOTE:** Unfortunately the GPU appears to not work properly with tf 1.14 or 1.15 in the kaggle kernel. Therefore, training will be slow.","fb75a71a":"## 5. Export your model for inference","167691f7":"Make a prediction with the pretrained model"}}