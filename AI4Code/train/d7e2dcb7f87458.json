{"cell_type":{"5d39a55f":"code","caa26a5e":"code","52fedb58":"code","3231c900":"code","322f5843":"code","c1c84a25":"code","11fc4fe8":"code","561fb07b":"code","cec2f0f8":"code","8cfdc1ac":"code","02e70dd1":"code","4bf91141":"code","0e509e1e":"code","04e3b7cc":"code","a3953c21":"code","481fdd6b":"code","f1c7a057":"code","98be5129":"code","aecda1da":"code","802a7aec":"code","6311236c":"code","8964a608":"code","99dc92f9":"code","3958c541":"code","6d896d2b":"code","dfe29759":"code","e694a545":"code","d70053c3":"code","4a283d82":"code","f39105ca":"code","2162867b":"code","4be948d2":"code","55ab22be":"code","9ac7853b":"code","e74e5357":"code","4fb400ee":"code","1bfc736f":"code","7ed78a80":"code","41b6a3fb":"code","22e35dd0":"code","3cdc9b78":"code","bed54ab5":"code","bac849b4":"code","b2340fee":"code","b8d5b4b9":"code","4c7915e9":"code","f7d5a857":"code","639577f9":"code","29f6ac71":"code","7f72a18b":"code","11845e61":"code","5398b71a":"code","2a08e4e5":"code","073b7ad1":"code","f6a0bd26":"code","389266e3":"code","200000ee":"code","b5bfa564":"code","b51914b8":"code","5b926075":"code","aea093f5":"code","083f6e68":"code","70663491":"code","a1e3e945":"code","f05c7af6":"code","033f508a":"code","4d7246bf":"code","f5a1ea1b":"code","08a8000a":"code","d144d561":"code","6a6eaf39":"code","8100f852":"code","7d279196":"code","d5c3e278":"code","805297ed":"code","fb116b28":"code","ca580180":"code","6b48f646":"markdown","90e6c8b2":"markdown","957a40f5":"markdown","003c3a9d":"markdown","068ed099":"markdown","968edcfa":"markdown","6ef13824":"markdown","7fb89cf1":"markdown","f5a8deb4":"markdown","2ec30c7f":"markdown","20193f08":"markdown","1cf01378":"markdown","9a426a54":"markdown","dec37b23":"markdown","c526596e":"markdown","61f9517d":"markdown","bb04a33f":"markdown","a96fe249":"markdown","337974cf":"markdown","40250d56":"markdown","e583bc9c":"markdown","92f532b6":"markdown","5a5f75a4":"markdown","03579283":"markdown"},"source":{"5d39a55f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n","caa26a5e":"train_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/train.csv\")\nsub_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/test.csv\")","52fedb58":"train_data.head()","3231c900":"train_data = train_data[train_data['HHS Region'] == 'United States']\ntrain_data","322f5843":"train_data = train_data.drop(axis=1, columns=['Total Deaths', 'id'])\ntrain_data","c1c84a25":"train_data.describe()","11fc4fe8":"train_data = train_data.drop(axis=1, columns=['Data As Of', 'Year', 'Group', 'Week-Ending Date', 'End Date', 'Month'])\ntrain_data","561fb07b":"train_data = train_data.drop(axis=1, columns=['HHS Region', 'Footnote'])\ntrain_data","cec2f0f8":"train_data.describe()","8cfdc1ac":"missing = train_data.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace = True)\nprint(missing)","02e70dd1":"train_data = train_data[train_data['Race and Hispanic Origin Group'] != 'Unknown']\ntrain_data","4bf91141":"train_data['Race and Hispanic Origin Group'].unique()","0e509e1e":"train_data = train_data.replace(dict.fromkeys(['Hispanic'], 0))\ntrain_data = train_data.replace(dict.fromkeys(['Non-Hispanic American Indian or Alaska Native'], 1))\ntrain_data = train_data.replace(dict.fromkeys(['Non-Hispanic Asian'], 2))\ntrain_data = train_data.replace(dict.fromkeys(['Non-Hispanic Black'], 3))\ntrain_data = train_data.replace(dict.fromkeys(['Non-Hispanic More than one race'], 4))\ntrain_data = train_data.replace(dict.fromkeys(['Non-Hispanic Native Hawaiian or Other Pacific Islander'], 5))\ntrain_data = train_data.replace(dict.fromkeys(['Non-Hispanic White'], 6))","04e3b7cc":"train_data","a3953c21":"train_data['Age Group'].unique()","481fdd6b":"train_data = train_data.replace(dict.fromkeys(['0-4 years'], 0))\ntrain_data = train_data.replace(dict.fromkeys(['5-17 years'], 5))\ntrain_data = train_data.replace(dict.fromkeys(['18-29 years'], 18))\ntrain_data = train_data.replace(dict.fromkeys(['30-39 years'], 30))\ntrain_data = train_data.replace(dict.fromkeys(['40-49 years'], 40))\ntrain_data = train_data.replace(dict.fromkeys(['50-64 years'], 50))\ntrain_data = train_data.replace(dict.fromkeys(['65-74 years'], 65))\ntrain_data = train_data.replace(dict.fromkeys(['75-84 years'], 75))\ntrain_data = train_data.replace(dict.fromkeys(['85 years and over'], 85))\n\ntrain_data","f1c7a057":"#train_data['Start Date'].unique()","98be5129":"#train_data.shape","aecda1da":"#train_data.reindex","802a7aec":"#train_data.loc[63, 'Start Date']","6311236c":"#index_marker = 0\n#curr_date = '12\/29\/2019'\n#for x in range(4663):\n#    if train_data.at[x, 'Start Date'] == curr_date:\n#        train_data.at[x, 'Start Date'] = index_marker\n#    else:\n#        curr_date = train_data.at[x, 'Start Date']\n#        index_marker = index_marker+1\n#        train_data.at[x, 'Start Date'] = index_marker","8964a608":"train_data.shape","99dc92f9":"train_data = train_data.dropna(subset=['MMWR Week'])","3958c541":"missing = train_data.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace = True)\nprint(missing)","6d896d2b":"train_data.hist(figsize=(12,5), layout=(2,3))\nplt.show()","dfe29759":"sns.boxplot(train_data['Age Group'])","e694a545":"sns.boxplot(train_data['MMWR Week'])","d70053c3":"sns.boxplot(train_data['Race and Hispanic Origin Group'])","4a283d82":"sns.boxplot(train_data['COVID-19 Deaths'])","f39105ca":"print(np.where(train_data['COVID-19 Deaths']<5))","2162867b":"fig, ax = plt.subplots(figsize = (18, 10))\nax.scatter(train_data['COVID-19 Deaths'], train_data['Age Group'])\n\nax.set_xlabel('COVID-19 Deaths in the US')\nax.set_ylabel('Age Group (# signifies youngest person in age group)')\nplt.show()","4be948d2":"fig, ax = plt.subplots(figsize = (18, 10))\nax.scatter(train_data['COVID-19 Deaths'], train_data['Race and Hispanic Origin Group'])\n\nax.set_xlabel('COVID-19 Deaths in the US')\nax.set_ylabel('Race and Hispanic Origin Group')\nplt.show()\n\n# For reference, from earlier\n#train_data = train_data.replace(dict.fromkeys(['Hispanic'], 0))\n#train_data = train_data.replace(dict.fromkeys(['Non-Hispanic American Indian or Alaska Native'], 1))\n#train_data = train_data.replace(dict.fromkeys(['Non-Hispanic Asian'], 2))\n#train_data = train_data.replace(dict.fromkeys(['Non-Hispanic Black'], 3))\n#train_data = train_data.replace(dict.fromkeys(['Non-Hispanic More than one race'], 4))\n#train_data = train_data.replace(dict.fromkeys(['Non-Hispanic Native Hawaiian or Other Pacific Islander'], 5))\n#train_data = train_data.replace(dict.fromkeys(['Non-Hispanic White'], 6))","55ab22be":"features = ['Start Date', 'MMWR Week', 'Race and Hispanic Origin Group', 'Age Group']\ntarget = ['COVID-19 Deaths']\n\nX = pd.get_dummies(train_data[features])\ny = pd.get_dummies(train_data[target])","9ac7853b":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = .60)","e74e5357":"X_train.shape","4fb400ee":"X_train.head()","1bfc736f":"X_test.shape","7ed78a80":"import statsmodels.api as sm\nfrom sklearn.metrics import accuracy_score","41b6a3fb":"ols_model = sm.OLS(y, X).fit()","22e35dd0":"#ols.fit(X, y)","3cdc9b78":"summary = ols_model.summary()","bed54ab5":"summary","bac849b4":"predOLS = ols_model.predict(X_test)","b2340fee":"print(predOLS)","b8d5b4b9":"predOLS.shape","4c7915e9":"accOLS = accuracy_score(y_test, predOLS.round())","f7d5a857":"accOLS","639577f9":"from sklearn.linear_model import Ridge","29f6ac71":"ridge_reg = Ridge()","7f72a18b":"ridge_reg.fit(X_train, y_train)","11845e61":"ridge_pred = ridge_reg.predict(X_test)","5398b71a":"ridge_pred.shape","2a08e4e5":"acc_ridge = accuracy_score(y_test, ridge_pred.round())","073b7ad1":"acc_ridge","f6a0bd26":"from sklearn.linear_model import Lasso","389266e3":"lasso_reg = Lasso(normalize=True)","200000ee":"lasso_reg.fit(X_train,y_train)","b5bfa564":"lasso_pred = lasso_reg.predict(X_test)","b51914b8":"lasso_pred.shape","5b926075":"acc_lasso = accuracy_score(y_test, lasso_pred.round())\nacc_lasso","aea093f5":"from sklearn.linear_model import ElasticNet","083f6e68":"elastic_reg = ElasticNet(alpha=1.0, l1_ratio=0.4)","70663491":"elastic_reg.fit(X_train,y_train)","a1e3e945":"elastic_pred = elastic_reg.predict(X_test)","f05c7af6":"acc_elastic = accuracy_score(y_test, elastic_pred.round())\nacc_elastic","033f508a":"#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)","4d7246bf":"#scores = cross_val_score(elastic_reg, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)","f5a1ea1b":"accOLS","08a8000a":"acc_ridge","d144d561":"acc_lasso","6a6eaf39":"acc_elastic","8100f852":"print(elastic_pred)","7d279196":"sub_data.shape","d5c3e278":"elastic_pred.shape","805297ed":"elastic_pred.resize((1152,))","fb116b28":"ridge_pred.resize((1152,))","ca580180":"output = pd.DataFrame({'id':sub_data.id, 'COVID-19 Deaths': elastic_pred})\noutput.to_csv('submission.csv', index=False)","6b48f646":"# Run elastic model on submission data","90e6c8b2":"# Train_test_split data into train & test data","957a40f5":"# Joseph Stewart, 4820862","003c3a9d":"# Elastic Net Regression","068ed099":"# Verify the drop","968edcfa":"# Convert 'Start Date' into numerical index","6ef13824":"# Scatterplots","7fb89cf1":"# Ridge Regression Model","f5a8deb4":"# Drop unknown Race and Hispanical Origin Group","2ec30c7f":"# Examine data relationships & outliers","20193f08":"# Convert Race and Hispanic Origin Group into numerical index","1cf01378":"# Convert Age Group to numerical index","9a426a54":"# Compare models","dec37b23":"# HHS Region no longer important b\/c 1 value","c526596e":"# Drop MMWR missing","61f9517d":"# Ordinary Least Squares","bb04a33f":"# Remove Date As Of, Year, and group, as they are not important. ","a96fe249":"# Run models on training data","337974cf":"# Exploratory Data Analysis","40250d56":"# Deaths in Age<17 range are most likely outliers, but will leave them for now.","e583bc9c":"# Lasso Regression Model","92f532b6":"# Restrict analysis to data with just HHS region that is United States.","5a5f75a4":"# Remove Total Deaths and ID","03579283":"# Remove Week Ending Date b\/c same as End Date.\n# Remove End Date b\/c linear to start date."}}