{"cell_type":{"488e6c2e":"code","7da6371e":"code","a53797e7":"code","ad7d1481":"code","3ae44673":"code","fc762146":"code","dd9762fb":"code","c6048682":"code","4b4d1e7d":"code","cd5611b4":"code","5ea5a279":"code","87a5fcf1":"code","35c8cc33":"code","1ebcff4f":"code","53ddd345":"code","3489a912":"code","13c0fb52":"markdown","65fff914":"markdown","edfbce73":"markdown","7ecd6c8d":"markdown","fabe9003":"markdown","128b6d00":"markdown","540a8d9d":"markdown"},"source":{"488e6c2e":"# Helper libraries\nimport os\nimport math\nimport warnings\nimport pickle\nimport re\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.corpus import stopwords","7da6371e":"# Read Data\nfiles = [(f[:-4],\"..\/input\/%s\"%f) for f in os.listdir(\"..\/input\")]\nfiles = dict(files)\nprint(os.listdir(\"..\/input\"))\n\ndef read_csv(name):\n    if name not in files:\n        print(\"error\")\n        return None    \n    return pd.read_csv(files[name])\n\n# load data\nquestions = read_csv(\"questions\")\nanswers = read_csv(\"answers\")\nprofessionals = read_csv(\"professionals\")","a53797e7":"### Read questions data\nq = questions.copy()\nq['qtext'] = list(q.apply(lambda x:'%s %s' %(x['questions_title'],x['questions_body']), axis=1))\nq = q.drop(['questions_author_id','questions_date_added','questions_body','questions_title'],axis=1)\n\n### Read answers data\na = answers.copy()\na = a.drop(['answers_date_added'],axis=1)\nuri_re = r'(?i)\\b((?:https?:\/\/|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}\/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))'\ntag_re = r'<\\\/?[a-z]+>'\n\ndef strip_html_tag(s):\n    temp = re.sub(uri_re, ' ', str(s))\n    return re.sub(tag_re, ' ', temp)\n\na['answers_body'] = a['answers_body'].apply(strip_html_tag)\na.rename(columns={'answers_question_id':'questions_id',\n                  'answers_author_id':'professionals_id',\n                  \"answers_body\":\"atext\"},inplace=True)\n          \n### Read professionals data\np = professionals.copy()\n# Connect these professionals with tags and user_tag tables\ntags = read_csv(\"tags\")\ntag_users = read_csv(\"tag_users\")\n\ntag_users = tag_users[tag_users[\"tag_users_user_id\"].isin(p['professionals_id'])]\ntag_users = tag_users.merge(tags, how=\"left\", left_on=\"tag_users_tag_id\", right_on = \"tags_tag_id\")\n\nt = tag_users.groupby([\"tag_users_user_id\"])['tags_tag_name'].apply(lambda x: ' '.join(x))\nt = t.to_frame().reset_index()\n\np = p.merge(t, how=\"left\", left_on=\"professionals_id\", right_on = \"tag_users_user_id\")\n\n# get text\ntemp = p[['professionals_location','professionals_industry','professionals_headline','tags_tag_name']].fillna('')\n\np['ptext'] = temp['professionals_location']+\" \"+temp['professionals_industry']+\" \"+\\\n             temp['professionals_headline']+\" \"+temp['tags_tag_name']\n\np = p.drop(['professionals_location','professionals_industry','professionals_headline',\\\n           'professionals_date_joined','tag_users_user_id','tags_tag_name'],axis=1)\n\nprint(\"Number of professionals: \",len(p['ptext']),\",with \",sum(p['ptext']!=\"   \"),\" of them having data\" )","ad7d1481":"# Remove general words\nnoise = ['school','would','like', 'want', 'dont', \n         'become','sure','go', 'get', 'college', \n         'career', 'wanted', 'im', 'ing', 'ive',\n         'know', 'high', 'becom', 'job', 'best',\n         'day', 'hi', 'name', 'help', 'people',\n         'year', 'years', 'next', 'interested', \n         'question', 'questions', 'take', 'even',\n         'though', 'please', 'tell']\n\nstop = stopwords.words('english')\n\ndef remove_general_words(df, col):\n    df[col] = df[col].str.lower().str.split() # convert all str to lowercase    \n    df[col] = df[col].apply(lambda x: [item for item in x if item not in stop]) # remove stopwords\n    df[col] = df[col].apply(lambda x: [item for item in x if item not in noise]) # remove general words\n    df[col] = df[col].apply(' '.join) # convert list to str\n    return df\n\nq = remove_general_words(q,'qtext')\np = remove_general_words(p,'ptext')\na = remove_general_words(a,'atext')","3ae44673":"'''\n# Save the data\npickle.dump(q, open('..\/input\/q.p', 'wb'))\npickle.dump(a, open('..\/input\/a.p', 'wb'))\npickle.dump(p, open('..\/input\/p.p', 'wb'))\n'''","fc762146":"'''\n# Read saved data\nq = pickle.load(open('..\/input\/q.p', mode='rb'))\na = pickle.load(open('..\/input\/a.p', mode='rb'))\np = pickle.load(open('..\/input\/p.p', mode='rb'))\n'''","dd9762fb":"def get_similar_docs(corpus, query_text, threshold=0.0, top=10):\n    tfidf = TfidfVectorizer(ngram_range=(1,3), stop_words = 'english', max_features = 500, max_df=0.9)\n    corpus_tfidf = tfidf.fit_transform(corpus)\n    text_tfidf = tfidf.transform([query_text])\n    sim = cosine_similarity(corpus_tfidf, text_tfidf)\n    sim_idx = (sim >= threshold).nonzero()[0]\n    result = pd.DataFrame({'similarity':sim[sim_idx].reshape(-1,),\n                          'text':corpus[sim_idx]},\n                          index=sim_idx)\n    result = result.sort_values(by=['similarity'], ascending=False).head(top)\n    return result","c6048682":"# Example\ncorpus = q['qtext']\nquery_text = corpus[2]\nprint('Example 1 Question:\\n', query_text)\nsim_questions = get_similar_docs(corpus, query_text)","4b4d1e7d":"sim_questions","cd5611b4":"def get_questions_answers(sim_questions):  \n    sim_q_a = sim_questions.merge(q, left_index=True, right_index=True).merge(a)\n    return sim_q_a","5ea5a279":"sim_q_a = get_questions_answers(sim_questions)\nsim_q_a.head()","87a5fcf1":"def get_recommendation(df, top_n=5):\n    temp_values = df['similarity']\/df['questions_id'].apply(lambda x: df.groupby('questions_id').size()[x])\n    temp_values = temp_values * df['professionals_id'].apply(lambda x: df.groupby('professionals_id').size()[x])\n    df[\"value\"] = temp_values\n    top_prof = df.groupby('professionals_id').sum().reset_index().sort_values('value', ascending = False).head(top_n)\n    top_prof = top_prof[['professionals_id', 'value']]\n    top_prof.columns = ['professional', 'recommendation_score']\n    print(top_prof)        ","35c8cc33":"get_recommendation(sim_q_a)","1ebcff4f":"# find the new professionals\npa = p.merge(a, how = \"left\")\np_new = p[pa[\"questions_id\"].isnull()]\nprint (\"There are\",p_new.shape[0],\"new professionals\")","53ddd345":"# Example\ncorpus_p = p['ptext']\nprint('Example 2 Question:\\n', query_text)\nsim_professionals = get_similar_docs(corpus_p, query_text, top=2)","3489a912":"# Recommend new professiors\nrec_new = sim_professionals.merge(p, left_index=True, right_index=True)[['professionals_id', 'similarity']]\nrec_new.columns = ['professional', 'recommendation_score']\nrec_new","13c0fb52":"# Steps for recommending a new prof","65fff914":"# Methodology\nThis noteook illustrates the idea of recommending professionals based the similairty between the question and professionals' previous answers or user information. The professional are divided into two categories.\n\n## Ref\nThe recommendation system idea based on similary is based on Daniel Becker's [Kernal](https:\/\/www.kaggle.com\/danielbecker\/careervillage-org-recommendation-engine)\n\n## Categories\n- Prof: The professor has answered questions\n- New prof: The professor is new or did not answer any question yet\n### For the Prof (provided answered before)\nThe similarity is based on their previous answers and the new question\n### For the New prof(never answered a question)\nThe similarity is based on their user information, including tags and the new question\n\n\n# Steps for recommending a Prof:\n\n1. Calculate the tf-idf for the query text and all the questions\n2. Use the cosine similiarty to get similiar questions for the query text.\n3. Get the answers and professionals for the similar questions.\n4. Make a recommendation to fit the best professionals to answer the new question.","edfbce73":"# Preprocess the data","7ecd6c8d":"### The following lines are used for preprocessing data. If no change made, you can just load the presaved data","fabe9003":"## Get the top recommended professionals based on questions","128b6d00":"## Merges the questions with the corresponding answers","540a8d9d":"When a new professor has not answered any question, the above method will not be able to pair him to the new questions. We will use prof's information and tags in this case. \n\n1. Filter out the new professionals\n2. Rank the similarity between the new question and professionals' information\n3. Make a recommendation to fit the best professionals to answer the new question."}}