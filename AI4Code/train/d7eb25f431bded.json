{"cell_type":{"2ea33791":"code","deaedc37":"code","bb4a3ddf":"code","db821d79":"code","b511ffd0":"code","371ab6c2":"code","d90ae053":"code","7239bfcc":"code","1a81b186":"code","0bc0168c":"code","1bea7c88":"code","645bd2f8":"code","a964cfca":"markdown","225727fc":"markdown","ef73a10f":"markdown","2b79c3c8":"markdown","4a6fa67f":"markdown","a275f7e3":"markdown","dd096c87":"markdown","5993a2ea":"markdown","f76aaabd":"markdown"},"source":{"2ea33791":"import os\nimport time\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.metrics import log_loss, roc_auc_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss, MSELoss\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\n\nDATA_PATH = '..\/input\/jane-street-market-prediction\/'\n\nNFOLDS = 5\n\nTRAIN = False\nCACHE_PATH = '..\/input\/mlp012003weights'\n\ndef save_pickle(dic, save_path):\n    with open(save_path, 'wb') as f:\n    # with gzip.open(save_path, 'wb') as f:\n        pickle.dump(dic, f)\n\ndef load_pickle(load_path):\n    with open(load_path, 'rb') as f:\n    # with gzip.open(load_path, 'rb') as f:\n        message_dict = pickle.load(f)\n    return message_dict\n\nfeat_cols = [f'feature_{i}' for i in range(130)]\n\ntarget_cols = ['action', 'action_1', 'action_2', 'action_3', 'action_4']\n\nf_mean = np.load(f'{CACHE_PATH}\/f_mean_online.npy')\n\n##### Making features\nall_feat_cols = [col for col in feat_cols]\nall_feat_cols.extend(['cross_41_42_43', 'cross_1_2'])\n\n##### Model&Data fnc\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\n        self.dropout0 = nn.Dropout(0.2)\n\n        dropout_rate = 0.2\n        hidden_size = 256\n        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n\n        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(dropout_rate)\n\n        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(dropout_rate)\n\n        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n\n        self.Relu = nn.ReLU(inplace=True)\n        self.PReLU = nn.PReLU()\n        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        # self.GeLU = nn.GELU()\n        self.RReLU = nn.RReLU()\n\n    def forward(self, x):\n        x = self.batch_norm0(x)\n        x = self.dropout0(x)\n\n        x1 = self.dense1(x)\n        x1 = self.batch_norm1(x1)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x1 = self.LeakyReLU(x1)\n        x1 = self.dropout1(x1)\n\n        x = torch.cat([x, x1], 1)\n\n        x2 = self.dense2(x)\n        x2 = self.batch_norm2(x2)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x2 = self.LeakyReLU(x2)\n        x2 = self.dropout2(x2)\n\n        x = torch.cat([x1, x2], 1)\n\n        x3 = self.dense3(x)\n        x3 = self.batch_norm3(x3)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x3 = self.LeakyReLU(x3)\n        x3 = self.dropout3(x3)\n\n        x = torch.cat([x2, x3], 1)\n\n        x4 = self.dense4(x)\n        x4 = self.batch_norm4(x4)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x4 = self.LeakyReLU(x4)\n        x4 = self.dropout4(x4)\n\n        x = torch.cat([x3, x4], 1)\n\n        x = self.dense5(x)\n\n        return x\n\nif True:\n    device = torch.device(\"cuda:0\")\n\n    model_list = []\n    tmp = np.zeros(len(feat_cols))\n    for _fold in range(NFOLDS):\n        torch.cuda.empty_cache()\n        model = Model()\n        model.to(device)\n        model_weights = f\"{CACHE_PATH}\/online_model{_fold}.pth\"\n        model.load_state_dict(torch.load(model_weights))\n        model.eval()\n        model_list.append(model)","deaedc37":"train = pd.read_csv(f'{DATA_PATH}\/train.csv')\nvalid = train.loc[(train.date >= 450) & (train.date < 500)].reset_index(drop=True)\nvalid.fillna(train.mean(), inplace=True)\ndel train","bb4a3ddf":"valid['action'] = (valid['resp'] > 0).astype('int')\nvalid['action_1'] = (valid['resp_1'] > 0).astype('int')\nvalid['action_2'] = (valid['resp_2'] > 0).astype('int')\nvalid['action_3'] = (valid['resp_3'] > 0).astype('int')\nvalid['action_4'] = (valid['resp_4'] > 0).astype('int')","db821d79":"valid['cross_41_42_43'] = valid['feature_41'] + valid['feature_42'] + valid['feature_43']\nvalid['cross_1_2'] = valid['feature_1'] \/ (valid['feature_2'] + 1e-5)","b511ffd0":"BATCH_SIZE = 8192\n\nclass MarketDataset:\n    def __init__(self, df):\n        self.features = df[all_feat_cols].values\n\n        self.label = df[target_cols].values.reshape(-1, len(target_cols))\n\n    def __len__(self):\n        return len(self.label)\n\n    def __getitem__(self, idx):\n        return {\n            'features': torch.tensor(self.features[idx], dtype=torch.float),\n            'label': torch.tensor(self.label[idx], dtype=torch.float)\n        }\n\nvalid_set = MarketDataset(valid)\nvalid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","371ab6c2":"def inference_fn(model, dataloader, device):\n    model.eval()\n    preds = []\n\n    for data in dataloader:\n        features = data['features'].to(device)\n\n        with torch.no_grad():\n            outputs = model(features)\n\n        preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n    preds = np.concatenate(preds).reshape(-1, len(target_cols))\n\n    return preds","d90ae053":"valid_pred = np.zeros((len(valid), len(target_cols)))\nfor model in model_list:\n    valid_pred += inference_fn(model, valid_loader, device) \/ len(model_list)","7239bfcc":"valid_pred = np.median(valid_pred, axis=1)\nvalid_pred.shape","1a81b186":"def utility_score_bincount(date, weight, resp, action):\n    count_i = len(np.unique(date))\n    # print('weight: ', weight)\n    # print('resp: ', resp)\n    # print('action: ', action)\n    # print('weight * resp * action: ', weight * resp * action)\n    Pi = np.bincount(date, weight * resp * action)\n    t = np.sum(Pi) \/ np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 \/ count_i)\n    u = np.clip(t, 0, 6) * np.sum(Pi)\n    return u","0bc0168c":"best_threshold, best_u_score = 0.5, 0\nfor i in range(4500, 5500):\n    thres = float(i) \/ 10000\n    slice_valid_pred = valid_pred.copy()\n    slice_valid_pred = np.where(slice_valid_pred >= thres, 1, 0).astype(int)\n    valid_u_score = utility_score_bincount(date=valid.date.values, weight=valid.weight.values,\n                                           resp=valid.resp.values, action=slice_valid_pred)\n    print(f'thresold={thres:.4f}, valid_u_score={valid_u_score:.4f}')\n    \n    if valid_u_score >= best_u_score:\n        best_u_score = valid_u_score\n        best_threshold = thres","1bea7c88":"print(f'Best thresold={best_threshold:.4f}, best valid u score={best_u_score:.4f}')","645bd2f8":"if True:\n    import janestreet\n    env = janestreet.make_env()\n    env_iter = env.iter_test()\n\n    for (test_df, pred_df) in tqdm(env_iter):\n        if test_df['weight'].item() > 0:\n            x_tt = test_df.loc[:, feat_cols].values\n            if np.isnan(x_tt.sum()):\n                x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean\n\n            cross_41_42_43 = x_tt[:, 41] + x_tt[:, 42] + x_tt[:, 43]\n            cross_1_2 = x_tt[:, 1] \/ (x_tt[:, 2] + 1e-5)\n            feature_inp = np.concatenate((\n                x_tt,\n                np.array(cross_41_42_43).reshape(x_tt.shape[0], 1),\n                np.array(cross_1_2).reshape(x_tt.shape[0], 1),\n            ), axis=1)\n\n            pred = np.zeros((1, len(target_cols)))\n            for model in model_list:\n                pred += model(torch.tensor(feature_inp, dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy() \/ NFOLDS\n            pred = np.median(pred)\n            pred_df.action = np.where(pred >= best_threshold, 1, 0).astype(int)\n        else:\n            pred_df.action = 0\n        env.predict(pred_df)","a964cfca":"## Upvoting if it helps\ud83d\udd25\ud83d\udd25\ud83d\udd25","225727fc":"# Predict with best threshold","ef73a10f":"For I use the last 50 date data as my offline validation data, so I use the 5 models\u2018 average prediction on last 50 date data to search for the best threshold.","2b79c3c8":"# Description","4a6fa67f":"### This code will show you a way to search for the best threshold. You can use this method searching for a better threshold instead of using 0.5 as final threshold.","a275f7e3":"# Get offline predictions","dd096c87":"# Searching for best threshold","5993a2ea":"### You can find the training code from <br\/> https:\/\/www.kaggle.com\/a763337092\/neural-network-starter-pytorch-version\/comments and <br\/> https:\/\/www.kaggle.com\/a763337092\/pytorch-resnet-starter-training","f76aaabd":"# Load models"}}