{"cell_type":{"14fa9136":"code","e08c4cd0":"code","d804212f":"code","0023857c":"code","a63ebeb6":"code","40b28cd0":"code","a39aea40":"code","d9980f39":"code","7981de71":"code","124229b7":"code","a3027153":"code","8ba23d7f":"code","1d645d81":"code","f5e85eec":"code","5d961b9f":"code","b70bf1d8":"code","ade49ea0":"code","bec75c55":"code","377ec3ed":"code","fe6084da":"markdown","06421bc2":"markdown","32f99028":"markdown","c31a6092":"markdown"},"source":{"14fa9136":"!pip uninstall opencv-python -y","e08c4cd0":"!pip install opencv-contrib-python","d804212f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport os\nfrom tqdm import tqdm\nimport json\nimport warnings\nimport pickle\nwarnings.filterwarnings('ignore')\n","0023857c":"model_path = '..\/input\/rcnn-training-part-1-finetuning\/RCNN_crop_weed_classification_model.h5'\ntest_img_path = '..\/input\/rcnn-data-preprocessing-part-2\/Test\/'\nimages_path = '..\/input\/crop-and-weed-detection-data-with-bounding-boxes\/agri_data\/data\/'\nsvm_model_path = '..\/input\/rcnn-training-part-2-cnn-svm\/svm_classifier.pkl'\nimages_name = [x for x in os.listdir(images_path) if x.endswith('.jpeg')]","a63ebeb6":"model = tf.keras.models.load_model(model_path)","40b28cd0":"model.summary()","a39aea40":"model_without_last_two_fc = tf.keras.models.Model(model.inputs,model.layers[-5].output)","d9980f39":"model_without_last_two_fc.summary()","7981de71":"with open(svm_model_path,'rb') as svm:\n    svm_model = pickle.load(svm)","124229b7":"def iou_calc(bb1 , bb2):\n  \n    true_xmin, true_ymin, true_width, true_height  = bb1\n    bb_xmin, bb_ymin,  bb_width, bb_height = bb2\n\n    true_xmax = true_xmin + true_width\n    true_ymax = true_ymin + true_height\n    bb_xmax = bb_xmin + bb_width\n    bb_ymax = bb_ymin + bb_height\n\n    #calculating area\n    true_area = true_width * true_height\n    bb_area   = bb_width * bb_height \n\n    #calculating itersection cordinates\n    inter_xmin = max(true_xmin , bb_xmin) \n    inter_ymin = max(true_ymin , bb_ymin)\n    inter_xmax = min(true_xmax , bb_xmax)\n    inter_ymax = min(true_ymax , bb_ymax)\n\n    if inter_xmax <= inter_xmin or inter_ymax <= inter_ymin:\n        iou = 0\n\n\n    else:\n        inter_area = (inter_xmax - inter_xmin) * (inter_ymax - inter_ymin)\n\n\n        iou = inter_area \/ (true_area + bb_area - inter_area)\n        \n    assert iou<=1\n    assert iou>=0\n    \n    return iou","a3027153":"def detection(img_path,confidence=0.9,iou_thresh=0.1):\n    \n    # appling selective search\n    img = plt.imread(img_path)\n    cv2.setUseOptimized(True);\n    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n    ss.setBaseImage(img)\n    ss.switchToSelectiveSearchFast()\n    rects = ss.process()\n    sel_rects = rects[:2000]\n    \n    pred_crop=[]\n    pred_weed=[]\n    for index, rect in tqdm(enumerate(sel_rects)):\n\n        x,y,w,h = rect\n        roi = img[y:y+h,x:x+w,:]\n        resized_roi = cv2.resize(roi,(224,224))\/255\n        \n        # Feature extraction\n        \n        feature = model_without_last_two_fc.predict(resized_roi.reshape(-1,224,224,3))\n        \n        # SVM prediction\n        pred = svm_model.predict_proba(feature.reshape(-1,4096))\n        pred_lab=svm_model.predict(feature.reshape(-1,4096))\n\n        if pred_lab == 'crop' and np.max(pred)>confidence:\n            pred_crop.append([list(rect),np.max(pred)])\n        elif pred_lab=='weed' and np.max(pred)>confidence:\n            pred_weed.append([list(rect),np.max(pred)])\n            \n    final = []\n    \n    # Detection for crop class\n    if len(pred_crop) != 0:\n        pred_score_crop = [x[1] for x in pred_crop]\n        pred_bb_crop = [x[0] for x in pred_crop]\n\n        for i in range(len(pred_crop)):\n            temp_bb , temp_score = pred_bb_crop.copy() , pred_score_crop.copy()\n            if len(temp_bb) !=0:\n\n                max_score_box = temp_bb[np.argmax(temp_score)]\n\n                if [max_score_box,np.max(temp_score)] not in final:\n                    final.append([max_score_box,np.max(temp_score),'crop'])\n                    index_should_del = []\n\n                    for ind,other_bb in enumerate(temp_bb):\n                        iou_score = iou_calc(max_score_box , other_bb)\n                        \n                        # Non maximum suppression(nms)\n                        \n                        if iou_score >= iou_thresh:\n                            index_should_del.append(ind)\n\n                    pred_bb_crop    = []\n                    pred_score_crop = []\n                    for bb_index ,bb_value in enumerate(temp_bb) :\n                        if bb_index not in index_should_del:\n                            pred_bb_crop.append(bb_value)\n\n                    for score_index ,score_value in enumerate(temp_score) :\n                        if score_index not in index_should_del:\n                            pred_score_crop.append(score_value)\n                else:\n                    continue\n\n            else:\n                break\n\n    # Detection for weed class\n\n    if len(pred_weed) != 0:\n        pred_score_weed = [x[1] for x in pred_weed]\n        pred_bb_weed = [x[0] for x in pred_weed]\n\n        for i in range(len(pred_weed)):\n            temp_bb , temp_score = pred_bb_weed.copy() , pred_score_weed.copy()\n            if len(temp_bb) !=0:\n\n                max_score_box = temp_bb[np.argmax(temp_score)]\n\n                if [max_score_box,np.max(temp_score)] not in final:\n                    final.append([max_score_box,np.max(temp_score),'weed'])\n                    index_should_del = []\n\n                    for ind,other_bb in enumerate(temp_bb):\n                        iou_score = iou_calc(max_score_box , other_bb)\n\n                        if iou_score >= iou_thresh:\n                            index_should_del.append(ind)\n\n                    pred_bb_weed    = []\n                    pred_score_weed = []\n                    for bb_index ,bb_value in enumerate(temp_bb) :\n                        if bb_index not in index_should_del:\n                            pred_bb_weed.append(bb_value)\n\n                    for score_index ,score_value in enumerate(temp_score) :\n                        if score_index not in index_should_del:\n                            pred_score_weed.append(score_value)\n                else:\n                    continue\n\n            else:\n                break\n    \n   \n    imOut = img.copy()\n    for rect,score,cls in final:\n        \n        x,y,w,h = rect\n        if cls == 'weed':\n            color =(255,0,0)\n        if cls == 'crop':\n            color = (0,255,0)\n\n        cv2.rectangle(imOut,(x,y),(x+w,y+h),color,2)\n\n        cv2.putText(imOut,cls+':'+str(round(score*100,2)),(x,y-8),cv2.FONT_HERSHEY_SIMPLEX,1, color, 2, cv2.LINE_AA)\n    plt.imshow(imOut)\n    cv2.imwrite('prediction.jpeg',imOut)\n   \n\n    return final ","8ba23d7f":"detection('..\/input\/sampledataweed\/data\/1 (1).jpeg')","1d645d81":"detection('..\/input\/sampledataweed\/data\/1 (2).jpeg')","f5e85eec":"detection('..\/input\/sampledataweed\/data\/1 (3).jpeg')","5d961b9f":"detection('..\/input\/sampledataweed\/data\/1 (4).jpeg')","b70bf1d8":"detection('..\/input\/sampledataweed\/data\/1 (5).jpeg')","ade49ea0":"detection(images_path+images_name[24])","bec75c55":"detection(images_path+images_name[1245])","377ec3ed":"detection(images_path+images_name[100])","fe6084da":"Part of RCNN model training. Full code in [Github](https:\/\/github.com\/ravirajsinh45\/implementation_of_RCNN).","06421bc2":"## Defining function for iou calculation","32f99028":"# Performing detection","c31a6092":"# Loading all previously trained model"}}