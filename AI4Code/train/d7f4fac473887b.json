{"cell_type":{"5d7ac131":"code","3ed6da16":"code","15a53482":"code","db9256ae":"code","34ad97dd":"code","1ef95ed5":"code","b20c0cbe":"code","d0370d06":"code","6ecbc5c9":"code","82086287":"code","ef96d3f2":"code","ffe58633":"code","7d551f7e":"code","6bca0150":"code","9d9db89a":"markdown"},"source":{"5d7ac131":"import numpy as np # linear algebra\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/view-class\/view_helper.py\", dst = \"..\/working\/view_helper.py\")\n\n# import all our functions\nimport view_helper as helper\n\n# Any results you write to the current directory are saved as output.","3ed6da16":"data_dir = '..\/input\/dogs-vs-cats-for-pytorch\/cat_dog_data\/Cat_Dog_data'\n\n# TODO: Define transforms for the training data and testing data\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\n# Pass transforms in here, then run the next cell to see how the transforms look\ntrain_data = datasets.ImageFolder(data_dir + '\/train', transform=train_transforms)\ntest_data = datasets.ImageFolder(data_dir + '\/test', transform=test_transforms)\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=64)","15a53482":"# change this to the trainloader or testloader \ndata_iter = iter(trainloader)\n\nimages, labels = next(data_iter)\nfig, axes = plt.subplots(figsize=(10,10), ncols=4)\nfor ii in range(4):\n    ax = axes[ii]\n    helper.imshow(images[ii], ax=ax, normalize=False)","db9256ae":"model = models.densenet121(pretrained=True)\n\n# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.classifier = nn.Sequential(nn.Linear(1024, 256),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(256, 2),\n                                 nn.LogSoftmax(dim=1))\n\ncriterion = nn.NLLLoss()\n\n# Only train the classifier parameters, feature parameters are frozen\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)","34ad97dd":"print(\"Our model: \\n\\n\", model, '\\n')\nprint(\"The state dict keys: \\n\\n\", model.state_dict().keys())","1ef95ed5":"state_dict = torch.load('..\/input\/cat-dog-dense121-local\/cat_dog_dense121_local.pth')\nprint(state_dict.keys())","b20c0cbe":"model.load_state_dict(state_dict)\nmodel","d0370d06":"# change this to the trainloader or testloader \ndata_iter = iter(testloader)\n\nimages, labels = next(data_iter)\nfig, axes = plt.subplots(figsize=(10,10), ncols=4)\nfor ii in range(4):\n    ax = axes[ii]\n    helper.imshow(images[ii], ax=ax, normalize=False)","6ecbc5c9":"model.to('cpu')\nmodel.eval()\n\ndata_iter = iter(testloader)\n\nimages, labels = next(data_iter)\nfig, axes = plt.subplots(figsize=(10,10), ncols=4)\n\nfor ii in range(4):\n    ax = axes[ii]\n    helper.imshow(images[ii], ax=ax, normalize=False)","82086287":"with torch.no_grad():\n    output = model.forward(images)\n\nps = torch.exp(output)","ef96d3f2":"random_img = np.random.randint(64, size=1)[0]\nrandom_img","ffe58633":"# get the probability\nprobability = ps[random_img].data.numpy().squeeze()\nprobability","7d551f7e":"helper.imshow(images[random_img], normalize=False)","6bca0150":"ind = np.arange(2)\nlabels = ['Cat', 'Dog',]\nwidth = 0.35\nlocations = ind\n\nclass_probability = plt.barh(ind, probability, width, alpha=.7, label='Cats vs Dogs')\n\nplt.yticks(np.arange(10))\nplt.title('Class Probability')\nplt.yticks(locations, labels)\n\n#legend\nplt.legend()\nplt.ylim(top=3)\nplt.ylim(bottom=-2)\nplt.show();","9d9db89a":"## Test the Network"}}