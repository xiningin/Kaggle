{"cell_type":{"a035f6ca":"code","086f06a4":"code","e42951f5":"code","c5ff3395":"code","c6fe7d5e":"code","ddce39fc":"code","2f2065c8":"code","0b089fa2":"code","ce1a3e89":"code","614c339e":"code","5de26c57":"code","faf8f031":"code","900d8a50":"code","7724dc17":"code","d09b84e2":"code","976fc17a":"code","69d36d92":"code","f3ef32c4":"code","fbf382c3":"code","844cb992":"markdown","dad99a09":"markdown","9cbacd7c":"markdown","61a26c55":"markdown","f7fb3503":"markdown","824949a5":"markdown","065c49bf":"markdown","29fbb25b":"markdown","ab1f2abc":"markdown","ed5f436c":"markdown","dba6ecfb":"markdown","037fbb2f":"markdown","07c71a39":"markdown","a8f50c23":"markdown","205db05e":"markdown"},"source":{"a035f6ca":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport warnings\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')","086f06a4":"data = pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')","e42951f5":"data.head()","c5ff3395":"data.info()","c6fe7d5e":"for i in data.columns:\n    print('Unique Values in',i,'are',data[i].unique())","ddce39fc":"data = data.drop('veil-type',axis=1)","2f2065c8":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nfor i in data.columns:\n    data[i] = label_encoder.fit_transform(data[i])\n# Print sample of dataset\ndata.head()","0b089fa2":"data.info()","ce1a3e89":"X = data.drop('class',axis=1)\n\nY = data['class']","614c339e":"from sklearn.feature_selection import SelectKBest, chi2\nfs = SelectKBest(score_func=chi2, k='all')\nfs.fit(X, Y)\nper = []\nfor m in fs.scores_:\n    per.append(round(((m\/sum(fs.scores_))*100),3))\n\nfeatures_data = pd.DataFrame({'Feature':X.columns,'Scores':fs.scores_,'Importance (%)':per}).sort_values(by=['Scores'],ascending=False)\nplt.figure(figsize=(15,12))\nsns.barplot( 'Importance (%)','Feature',orient='h',data=features_data)\nprint(features_data,'\\n')\ninsignificant = features_data.loc[features_data['Importance (%)']<0.005]['Feature'].unique()","5de26c57":"X=X.drop(insignificant,axis=1)\n#insignificant","faf8f031":"sns.countplot(data['class'])","900d8a50":"plt.figure(figsize=(17,35))\nm=1\nfor i in features_data['Feature']:\n    plt.subplot(7, 3, m)\n    sns.countplot(x=data[i],hue=data['class'],)\n    m=m+1","7724dc17":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=100)","d09b84e2":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","976fc17a":"from sklearn.metrics import accuracy_score,classification_report\n\n#XGB\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier() \n\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\n#print('Random Forest Created')\n\n# SVM\nfrom sklearn.svm import SVC\nsvc = SVC()\n#print('SVM Created')\n\n#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\naccuracy = []\nfor i in range(1,40):    \n    kn = KNeighborsClassifier(n_neighbors=i)\n    kn.fit(X_train,Y_train)\n    predK = kn.predict(X_test)\n    accuracy.append([accuracy_score(Y_test,predK),i])\n    #print('Tested for k =',i)\ntemp = accuracy[0]\nfor m in accuracy:\n    if temp[0] < m[0]:\n        temp=m\nknn = KNeighborsClassifier(n_neighbors=temp[1])","69d36d92":"model_acc = []\nmodels = [xgb,lr,rfc,knn,svc]\n#model_name = ['xgb','lr','rfc','kno','svc','grid']\nfor i in models:\n    i.fit(X_train,Y_train)\n    model_acc.append(accuracy_score(Y_test,i.predict(X_test)))\n                      \nmodels = pd.DataFrame({'Models':models,'Accuracy':model_acc})","f3ef32c4":"models = models.sort_values(by=['Accuracy'],ascending=False).reset_index().drop('index',axis=1)\nbest = models['Models'][0]\nmodels['Models']=models['Models'].astype(str).str.split(\"(\", n = 2, expand = True)[0]\nmodels","fbf382c3":"print('Hence the best model is',models['Models'][0],'with an accuracy of',round((models['Accuracy'][0]*100),2),'%')\nprint('\\nThe classification report is:')\nprint(classification_report(Y_test,best.predict(X_test)))","844cb992":"# Cardinal Encoding\n","dad99a09":"# Modelling","9cbacd7c":"## Fitting","61a26c55":"# Importing the data","f7fb3503":"# Test Train Split","824949a5":"## Evaluation","065c49bf":"### Note: A value of 1 in class represnets a poisonous mushroom (p)","29fbb25b":"## Creation","ab1f2abc":"# Importing libraries\n","ed5f436c":"Splitting into targets and features","dba6ecfb":"# Feature Evaluation","037fbb2f":"# <center> Mushroom Classification","07c71a39":"# EDA","a8f50c23":"# Feature Scaling","205db05e":"# Feature Splitting"}}