{"cell_type":{"dbb9b3aa":"code","ef7c7a77":"code","2ded9fea":"code","1b27f800":"code","a7712cb6":"code","555acdeb":"code","feaafd75":"code","7001645d":"code","3e0a8d4b":"code","094e388f":"code","6670ceb0":"code","2de80b13":"code","4bf955fb":"code","ce86ca69":"code","2eff8eb6":"code","b99743cd":"code","3089b85d":"code","0dbc674c":"code","26e5de34":"code","5f76b4e6":"code","583607df":"code","bd78287e":"code","5c1b78a8":"code","cba95201":"code","103ce054":"code","e97739fc":"markdown"},"source":{"dbb9b3aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.model_selection import cross_val_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ef7c7a77":"df=pd.read_csv(\"\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","2ded9fea":"df","1b27f800":"df.head()","a7712cb6":"df.isna().sum()","555acdeb":"df.describe()","feaafd75":"sns.barplot(df['quality'],df['fixed acidity'])","7001645d":"sns.barplot(df['quality'],df['chlorides'])","3e0a8d4b":"bins = (2, 6.5, 8)\ngroup_names = ['bad', 'good']\ndf['quality'] = pd.cut(df['quality'], bins = bins, labels = group_names)","094e388f":"df['quality'].unique()","6670ceb0":"df['quality']","2de80b13":"df.info()","4bf955fb":"from sklearn.preprocessing import StandardScaler, LabelEncoder\nencoder=LabelEncoder()\ndf['quality']=encoder.fit_transform(df['quality'])\n#df=pd.get_dummies(df,drop_first=True)","ce86ca69":"df['quality'].value_counts()","2eff8eb6":"sns.countplot(df['quality'])","b99743cd":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(df.drop('quality',axis=1),df['quality'])","3089b85d":"type(y_train)","0dbc674c":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nx_train1=scaler.fit_transform(x_train)\nx_test1=scaler.transform(x_test)","26e5de34":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nmodel=LogisticRegression()\nmodel.fit(x_train1,y_train)\nz=model.predict(x_test1)\nscores=cross_val_score(model,df.drop(\"quality\",axis=1),df['quality'],cv=7).mean()\nprint(\"Cross Validation score={}\".format(scores))\nprint(classification_report(y_test,z))\nprint(confusion_matrix(y_test,z))","5f76b4e6":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(x_train1,y_train)\nz=model.predict(x_test1)\nscores=cross_val_score(model,df.drop(\"quality\",axis=1),df['quality'],cv=7).mean()\nprint(\"Cross Validation score={}\".format(scores))\nprint(classification_report(y_test,z))\nprint(confusion_matrix(y_test,z))","583607df":"model=RandomForestClassifier()\nmodel.fit(x_train,y_train)\nz=model.predict(x_test)\nscores=cross_val_score(model,df.drop(\"quality\",axis=1),df['quality'],cv=7).mean()\nprint(\"Cross Validation score={}\".format(scores))\nprint(classification_report(y_test,z))\nprint(confusion_matrix(y_test,z))","bd78287e":"from sklearn.svm import SVC\nmodel=SVC()\nmodel.fit(x_train1,y_train)\nz=model.predict(x_test1)\nscores=cross_val_score(model,df.drop(\"quality\",axis=1),df['quality'],cv=7).mean()\nprint(\"Cross Validation score={}\".format(scores))\nprint(classification_report(y_test,z))\nprint(confusion_matrix(y_test,z))\n","5c1b78a8":"SVC?","cba95201":"param={'C':[0.01,0.05,0.1,0.5,1],\n       'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n      'kernel':['linear', 'rbf']}\nfrom sklearn.model_selection import GridSearchCV\ngrid=GridSearchCV(model,param_grid=param,scoring='accuracy',cv=10)\ngrid.fit(x_train1,y_train)\ngrid.best_params_","103ce054":"model=SVC(C=1, gamma=1, kernel='rbf')\nmodel.fit(x_train,y_train)\nz=model.predict(x_test)\nscores=cross_val_score(model,df.drop(\"quality\",axis=1),df['quality'],cv=7).mean()\nprint(\"Cross Validation score={}\".format(scores))\nprint(classification_report(y_test,z))\nprint(confusion_matrix(y_test,z))","e97739fc":"RANDOM FOREST WITHOUT SCALING"}}