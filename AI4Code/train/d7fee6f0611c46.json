{"cell_type":{"37ebef7e":"code","44a7dcf6":"code","d7d8aa2b":"code","4bea21a5":"code","c8e17a65":"code","62bf826a":"code","71388b0c":"code","7724edb6":"code","6589745f":"code","da8901f4":"code","bcaf19cc":"markdown","7c37b1ec":"markdown","a48c76e6":"markdown","94dba754":"markdown","c175697c":"markdown"},"source":{"37ebef7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44a7dcf6":"!pip install forgebox","d7d8aa2b":"DATA = \"\/kaggle\/input\/zh-wenyanwen-wikisource\/cn_wenyan.csv\"","4bea21a5":"%%time\ndf = pd.read_csv(DATA)","c8e17a65":"len(df)","62bf826a":"from forgebox.df import PandasDisplay\nshow = PandasDisplay(max_colwidth = 0,max_rows=100)","71388b0c":"with show:\n    display(df.sample(2))","7724edb6":"df[\"length\"] = df.text.apply(len)","6589745f":"bins = [-1.20,50,100,200,500,1000,\n        2000,5000,10000,20000,50000,1e8]","da8901f4":"df.groupby(pd.cut(df.length,bins))[[\"title\"]].count()","bcaf19cc":"We can see some the texts they are not punctuated yet, no stop, no comma, only ```\\n``` marking the line changer from books\/ stone tablets","7c37b1ec":"## Data preview","a48c76e6":"Total 132308 lines of data","94dba754":"# A starter kernel from the dataset author","c175697c":"## Buckets"}}