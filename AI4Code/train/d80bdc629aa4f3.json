{"cell_type":{"827c5c60":"code","1f8906e6":"code","af2f5ac0":"code","347b4bcc":"code","71688cc6":"code","e291ba40":"code","c6a98003":"code","3c6fde34":"code","d9c05357":"code","55ad885f":"code","f657f9a6":"code","29168428":"code","31e5dcde":"code","0fe9c365":"code","86fc0d00":"code","c3db8648":"code","ed904f7c":"code","b160929b":"code","0f819884":"code","6c165972":"code","7c87df7f":"code","daeb3bd3":"code","092506be":"code","a13dd792":"code","24403ab2":"markdown","a12a0e1e":"markdown","05b5c7a9":"markdown","5d2a9fa0":"markdown","442afd54":"markdown","a9f643c4":"markdown","940a72d0":"markdown","5622d457":"markdown","03d5aabc":"markdown","9b4ebcf6":"markdown","36484cfd":"markdown","6e1ac340":"markdown","b403fecb":"markdown","183fc4af":"markdown","81f213ce":"markdown","87270899":"markdown","5cdcf107":"markdown","1a3f044e":"markdown","f900d74f":"markdown","3b52f96b":"markdown","e709b170":"markdown","b3b02e23":"markdown","e2d4591f":"markdown","5c3a20fb":"markdown","ca710b02":"markdown"},"source":{"827c5c60":"# To store data\nimport pandas as pd\n\n# To do linear algebra\nimport numpy as np\n\n# To create plots\nimport matplotlib.pyplot as plt\n\n# To create interactive plots\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, plot, init_notebook_mode\ninit_notebook_mode(True)\n\n# To prepare training\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n# To gbm light\nfrom lightgbm import LGBMRegressor\n\n# To optimize the hyperparameters of the model\nfrom hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval","1f8906e6":"# Load the dataset\ndf = pd.read_csv('..\/input\/survey_results_public.csv', low_memory=False)\n\nprint('Shape Dataset:\\t{}'.format(df.shape))\ndf.sample(3)","af2f5ac0":"# Filter only good questions\ndf = df[['Country',\n         'Employment',\n         'CompanySize',\n         'DevType',\n         'YearsCoding',\n         'ConvertedSalary',\n         'Gender',\n         'Age']]\n\nprint('Shape Dataset:\\t{}'.format(df.shape))\ndf.sample(3)","347b4bcc":"# Split the jobs and count them\ndf_jobs = pd.DataFrame.from_records(df['DevType'].dropna().apply(lambda x: x.split(';')).values.tolist()).stack().reset_index(drop=True).value_counts()\n\n# Create plot\ndf_jobs.plot(kind='barh', figsize=(10,7.5))\nplt.title('Stack Overflow Survey Job-Count')\nplt.xlabel('Job-Count')\nplt.ylabel('Job')\nplt.grid()\nplt.show()","71688cc6":"# Filter for the right jobs\ndf = df[~df['DevType'].isna()]\ndf = df[df['DevType'].str.contains('Data ')].drop('DevType', axis=1)\n\nprint('Shape Dataset:\\t{}'.format(df.shape))\ndf.sample(3)","e291ba40":"# Empty values\nprint('Empty Values:\\t{}'.format(df['YearsCoding'].isna().sum()))\n\n# Create subplots\nfig, axarr = plt.subplots(2, figsize=(10,7.5))\n\n# Create histogram\ndf['ConvertedSalary'].hist(bins=100, ax=axarr[0])\naxarr[0].set_title('Salary Histogram')\naxarr[0].set_xlabel('Salary')\naxarr[0].set_ylabel('Count')\n\n# Create sorted plot\ndf['ConvertedSalary'].sort_values().reset_index(drop=True).plot(ax=axarr[1])\naxarr[1].set_title('Ordered Salaries')\naxarr[1].set_xlabel('Ordered Index')\naxarr[1].set_ylabel('Salary')\n\nplt.tight_layout()\nplt.show()","c6a98003":"# Remove suspiciously low and high salaries\ndf = df[(df['ConvertedSalary']>1000) & (df['ConvertedSalary']<490000)]\nprint('Shape Dataset:\\t{}'.format(df.shape))","3c6fde34":"# Top n countries\nn = 20\n\n# Empty values\nprint('Empty Values:\\t{}'.format(df['YearsCoding'].isna().sum()))\n\n# Create plot\ndf_country = df['Country'].value_counts().head(n)\ndf_country.plot(kind='barh', figsize=(10,7.5))\nplt.title('Count For The Top {} Countries'.format(n))\nplt.xlabel('Count')\nplt.ylabel('Country')\nplt.grid()\nplt.show()","d9c05357":"# Filter for the most frequent countries\ndf = df[ df['Country'].isin( df_country[:5].index ) ]\n\nprint('Shape Dataset:\\t{}'.format(df.shape))","55ad885f":"# Empty values\nprint('Empty Values:\\t{}'.format(df['YearsCoding'].isna().sum()))\n\n# Create plot\ndf['Employment'].value_counts().plot(kind='barh', figsize=(10,5))\nplt.title('Kind Of Employment')\nplt.xlabel('Count')\nplt.ylabel('Employment')\nplt.show()","f657f9a6":"# Impute and remove retired and unemployed colleagues\nemployment = ['Employed full-time', \n              'Employed part-time', \n              'Independent contractor, freelancer, or self-employed']\ndf = df[df['Employment'].fillna('Employed full-time').isin(employment)]\n\nprint('Shape Dataset:\\t{}'.format(df.shape))","29168428":"# Ordered company sacle\ncompany_size = ['Fewer than 10 employees', '10 to 19 employees', '20 to 99 employees', '100 to 499 employees', '500 to 999 employees', '1,000 to 4,999 employees', '5,000 to 9,999 employees', '10,000 or more employees']\n\n# Empty values\nprint('Empty Values:\\t{}'.format(df['CompanySize'].isna().sum()))\n\n# Create plot\ndf['CompanySize'].value_counts().reindex(company_size).plot(kind='barh', figsize=(10,7.5))\nplt.title('Count Of Company Sizes')\nplt.xlabel('Count')\nplt.ylabel('Company Size')\nplt.show()","31e5dcde":"# Create mapping for company size\nmapping_company_size = {key:i for i, key in enumerate(company_size)}\n\n# Drop empty values\ndf = df.dropna(subset=['CompanySize'])\n\n# Transform category to numerical column\ndf['CompanySize'] = df['CompanySize'].map(mapping_company_size)\n\nprint('Shape Dataset:\\t{}'.format(df.shape))","0fe9c365":"# Ordered years coding sacle\nyears_coding = ['0-2 years', '3-5 years', '6-8 years', '9-11 years', '12-14 years', '15-17 years', '18-20 years', '21-23 years', '24-26 years', '27-29 years', '30 or more years']\n\n# Empty values\nprint('Empty Values:\\t{}'.format(df['YearsCoding'].isna().sum()))\n\n# Create plot\ndf['YearsCoding'].value_counts().reindex(years_coding).plot(kind='barh', figsize=(10,7.5))\nplt.title('Count Of Years Coding')\nplt.xlabel('Count')\nplt.ylabel('Years Coding')\nplt.show()","86fc0d00":"# Create mapping for years coding\nmapping_years_coding = {key:i for i, key in enumerate(years_coding)}\n\n# Transform category to numerical column\ndf['YearsCoding'] = df['YearsCoding'].map(mapping_years_coding)","c3db8648":"# Empty values\nprint('Empty Values:\\t{}'.format(df['Gender'].isna().sum()))\n\n# Create plot\ndf['Gender'].value_counts().plot(kind='barh', figsize=(10,7.5))\nplt.title('Gender Count')\nplt.xlabel('Count')\nplt.ylabel('Gender')\nplt.show()","ed904f7c":"# Impute and map gender\ndf['Gender'] = df['Gender'].fillna('Male')\ndf = df[df['Gender'].isin(['Male', 'Female'])]\ndf['Gender'] = df['Gender'].map({'Male':0, 'Female':1})\n\nprint('Shape Dataset:\\t{}'.format(df.shape))","b160929b":"# Ordered age sacle\nage = ['Under 18 years old',\n       '18 - 24 years old',\n       '25 - 34 years old',\n       '35 - 44 years old',\n       '45 - 54 years old',\n       '55 - 64 years old',\n       '65 years or older']\n\n# Empty values\nprint('Empty Values:\\t{}'.format(df['Age'].isna().sum()))\n\n# Create plot\ndf['Age'].value_counts().reindex(age).plot(kind='barh', figsize=(10,7.5))\nplt.title('Age Count')\nplt.xlabel('Count')\nplt.ylabel('Age')\nplt.show()","0f819884":"# Create mapping for years coding\nmapping_age = {key:i for i, key in enumerate(age)}\n\n# Transform category to numerical column\ndf['Age'] = df['Age'].fillna('25 - 34 years old').map(mapping_age)\n\nprint('Shape Dataset:\\t{}'.format(df.shape))","6c165972":"# Create label\ny = np.log(df['ConvertedSalary'].values)\n\n# Create data\nX = pd.get_dummies(df.drop('ConvertedSalary', axis=1)).values\n\n# Create splitting of training and testing dataset\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=1)\nX_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.25, random_state=1)\n\nprint('Training examples:\\t\\t{}\\nExamples for optimization loss:\\t{}\\nFinal testing examples:\\t\\t{}'.format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))","7c87df7f":"# Define function to minimize\ndef objective(args):\n    # Create & fit model\n    model = LGBMRegressor(**args)\n    model.fit(X_train, y_train)\n    \n    # Predict testset\n    y_pred = model.predict(X_valid)\n    \n    # Compute rmse loss\n    loss = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_valid))\n    return {'loss':loss, 'status':STATUS_OK, 'model':model}\n\n\n# Setup search space\nspace = {'n_estimators': hp.choice('n_estimators', range(3000, 4500)),\n         'max_depth': hp.choice('max_depth', range(25, 50)),\n         'min_child_samples': hp.choice('min_child_samples', range(2, 10)),\n         'reg_alpha': hp.uniform('reg_alpha', 0, 10),\n         'reg_lambda': hp.uniform('reg_lambda', 1000, 3000)}\n\n\n# Minmize function\ntrials = Trials()\nbest = fmin(objective, space, algo=tpe.suggest, max_evals=1000, trials=trials, rstate=np.random.RandomState(1))\n\n# Compute final loss\nmodel = trials.best_trial['result']['model']\ny_pred = model.predict(X_test)\nloss = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_test))\n\n\n# Print training results\nfor key, value in space_eval(space, best).items():\n    print('{}:\\t{}'.format(key, value))\nprint('\\nTraining loss:\\t{}'.format(trials.best_trial['result']['loss']))\nprint('\\nFinal loss:\\t{}'.format(loss))","daeb3bd3":"# Create all possible answers\npossibilities = []\nfor a in range(len(company_size)):\n    for b in range(len(years_coding)):\n        for c in range(len(['male', 'female'])):\n            for d in range(len(age)):\n                for e in range(len(['Canada', 'Germany', 'India', 'UK', 'US'])):\n                    for f in range(len(['Fulltime', 'Parttime'])):\n                        vector = np.zeros(11)\n                        vector[0] = a\n                        vector[1] = b\n                        vector[2] = c\n                        vector[3] = d\n                        vector[4+e] = 1\n                        vector[9+f] = 1\n                        possibilities.append(vector)\npossibilities = np.array(possibilities)\n\n# Predict salaries for all answers\nall_salaries = np.round(np.exp(model.predict(possibilities)), -2)\n\n# Create data-structure for all salaries\ndf_plot = pd.DataFrame(possibilities, columns=['Size', 'Years', 'Gender', 'Age', 'Canada', 'Germany', 'India', 'UK', 'US', 'Full', 'Part'])\ndf_plot['Salary'] = all_salaries\n\n\n\n# Create template for an interactive heatmap\ndef createHeatmap(x, y, x_axis, y_axis, x_label, y_label, filename):\n    # Create hover texts & annotations\n    def getAnotations(grid):\n        hovertexts = []\n        annotations = []\n        for i, size in enumerate(y_axis):\n            row = []\n            for j, years in enumerate(x_axis):\n                salary = grid[i, j]\/1000\n                row.append('Salary: {:.1f} k$\/a<br>{}: {}<br>{}: {}<br>'.format(salary, y_label, size ,y_label, years))\n                annotations.append(dict(x=years, y=size, text='{:.1f}'.format(salary), ax=0, ay=0, font=dict(color='#000000')))\n            hovertexts.append(row)\n        return hovertexts, annotations\n\n    # Create traces\n    data = []\n    all_annotations = []\n    # Iterate countries\n    countries = ['US', 'UK', 'Germany', 'India', 'Canada']\n    for i, country in enumerate(countries):\n        # Get data\n        grid = df_plot[df_plot[country]==1].pivot_table(index=y, columns=x, values='Salary', aggfunc='median').values\n        # Get annotations\n        hovertexts, annotations = getAnotations(grid)\n        all_annotations.append(annotations)\n        # Create trace\n        trace = go.Heatmap(x = x_axis,\n                           y = y_axis,\n                           z = grid,\n                           visible = True if i==0 else False,\n                           text = hovertexts,\n                           hoverinfo = 'text',\n                           colorscale = 'Picnic',\n                           colorbar = dict(title = 'Yearly<br>Salary',\n                                           ticksuffix = '$'))\n        data.append(trace)\n\n    # Create buttons\n    buttons = []\n    # Iterate countries\n    for i, country in enumerate(countries):\n        label = country\n        title = 'Median Salary Of A Data Scientist In {}'.format(country)\n        visible = [False] * len(countries)\n        visible[i] = True\n        annotations = all_annotations[i]\n        # Create button\n        buttons.append(dict(label=label, method='update', args=[{'visible':visible},{'title':title, 'annotations':annotations}]))\n\n    updatemenus = list([dict(type = 'dropdown',\n                             active = 0,\n                             buttons = buttons)])\n\n    # Create layout\n    layout = go.Layout(title = 'Median Salary Of A Data Scientist In {}'.format(countries[0]),\n                       xaxis = dict(title = x_label,\n                                    tickangle = -30),\n                       yaxis = dict(title = y_label,\n                                    tickangle = -30),\n                       annotations = all_annotations[0],\n                       updatemenus = updatemenus)\n\n    # Create plot\n    figure = go.Figure(data=data, layout=layout)\n    plot(figure, filename=filename)\n    iplot(figure)","092506be":"x = 'Years'\ny = 'Size'\nx_axis = ['0-2', '3-5', '6-8', '9-11', '12-14', '15-17', '18-20', '21-23', '24-26', '27-29', '30 or more']\ny_axis = ['<10',  '10-19', '20-99', '100-499', '500-999', '1,000-4,999', '5,000-9,999', '10,000<']\nx_label = 'Years Coding'\ny_label = 'Employees'\n\ncreateHeatmap(x, y, x_axis, y_axis, x_label, y_label, 'Salary_Coding.html')","a13dd792":"x = 'Age'\ny = 'Size'\nx_axis = ['Under 18', '18-24', '25-34', '35-44', '45-54', '55-64', '65 years or older']\ny_axis = ['<10',  '10-19', '20-99', '100-499', '500-999', '1,000-4,999', '5,000-9,999', '10,000<']\nx_label = 'Age'\ny_label = 'Employees'\n\ncreateHeatmap(x, y, x_axis, y_axis, x_label, y_label, 'Salary_Age.html')","24403ab2":"***\n## <a id=8>8. Conclusion<\/a>\n\n**Interpretation of the data for your specific case is up to you.**<br>\nRemember the predictions are based upon a survey and could be biased. Furthermore the model does not use all the possible features and the final plots show only the median for all results. For this reason there are **plenty of uncertainties in this notebook!**\n\nI would be glad if you have some further suggestions for me.\n\n**Have a good day!**","a12a0e1e":"Unfortunately the data is very sparse except for female and male participants. Therefore I will make use of **female and male only.**<br>\nSince there are roughly ten times more men than woman I will insert \"Male\" into the missing values.","05b5c7a9":"The dataset contains roughly **100.000 survey participants and about 130 questions.**<br>\n\n***\n## <a id=3>3. Slicing The Data For The Interesting Part<\/a>\n\nSince you have to answer the questions for yourself to predict your salary, I will restrict the questions to a small number of basic ones.","5d2a9fa0":"# Estimate Data-Science Salary Around The World\n\nSince **salary negotiations are hard** and good reasons for a raise are rarely based on large datasets of colleagues, I am going to fill this gap with this notebook.\n\nUsing the [**Stack Overflow Survey Dataset**](https:\/\/www.kaggle.com\/stackoverflow\/stack-overflow-2018-developer-survey\/home) I am going to create a regression model for the salary of data scientists around the world.<br>\nFeel free to suggest further improvements or extensions.\n\nHave a good day and good luck!\n\n+ [1. Import Libraries](#1)<br>\n+ [2. Load Dataset](#2)<br>\n+ [3. Slicing The Data For The Interesting Part](#3)<br>\n+ [4. Cleaning The Data](#4)<br>\n + [4.1. Salaries](#4.1)<br>\n + [4.2. Countries](#4.2)<br>\n + [4.3. Employment](#4.3)<br>\n + [4.4. Company Size](#4.4)<br>\n + [4.5. Years Coding](#4.5)<br>\n + [4.6. Gender](#4.6)<br>\n + [4.7. Age](#4.7)<br>\n+ [5. Create Label, Train-, Valid- And Test-Set](#5)<br>\n+ [6. Train And Optimize The Regressor](#6)<br>\n+ [7. Explore Salary-Space](#7)<br>\n + [7.1. Salary By Years Coding And Company Size](#7.1)<br>\n + [7.2. Salary By Age And Company Size](#7.2)<br>\n+ [8. Conclusion](#8)<br>\n\n***\n## <a id=1>1. Import Libraries<\/a>","442afd54":"***\n## <a id=7>7. Explore Salary-Space<\/a>\n\nI will create all possible answers and will predict the salary for them. Afterwards I am going to create an **interactive heatmap for your data exploration.** Of course you can switch between the countries by yourself.","a9f643c4":"### <a id=4.6>4.6. Gender<\/a>","940a72d0":"The very low salary cluster around zero and the odd peaks at high numbers seem suspicious.<br>\nI am gonna **remove salaries lower than 1000$ per year and higher ones than 490.000$.** The model will still cover most of the variability of the data but should be more robust.","5622d457":"The **company size is an ordered category** and I will **transform it into a numerical column** instead of a dummy variable.<br>\nImputation is not straight forward in this case since there is no obvious \"right value\". To not corrupt the ordered category and to keep predicting for new users simple, I will drop all ~300 empty values.","03d5aabc":"***\n## <a id=2>2. Load Dataset<\/a>","9b4ebcf6":"***\n## <a id=5>5. Create Label, Train-, Valid- And Test-Set<\/a>\n\nThe dataset will be split into a **training, validation and testing set.**","36484cfd":"### <a id=7.2>7.2. Salary By Age And Company Size<\/a>","6e1ac340":"Right in the middle you can see **two jobs (dark blue) working with data and machine learning.** I am filtering the DataFrame for both of these jobs.","b403fecb":"The age is another **ordered category which will be converted to numeric values.** <br>\nI will insert the by far most frequent value of \"25 - 34 years old\" into the empty values.","183fc4af":"### <a id=4.4>4.4. Company Size<\/a>","81f213ce":"**Years coding is another ordered category** and I will transform it into a numerical column instead of a dummy variable again.<br>\nLuckily there are no empty values here.","87270899":"### <a id=4.7>4.7. Age<\/a>","5cdcf107":"### <a id=4.5>4.5. Years Coding<\/a>","1a3f044e":"Right now the DataFrame contains only the important questions and the responses of datadriven jobs around the world.\n\nIn the next paragraph I will clean the data and preprocess it to fit into a regression model.\n\n***\n## <a id=4>4. Cleaning The Data<\/a>\n### <a id=4.1>4.1. Salaries<\/a>","f900d74f":"### <a id=4.3>4.3. Employment<\/a>","3b52f96b":"### <a id=7.1>7.1. Salary By Years Coding And Company Size<\/a>","e709b170":"Since the model will predict the salary of a person, I am **removing the retired and unemployed colleagues** from the dataset.<br>","b3b02e23":"### <a id=4.2>4.2. Countries<\/a>","e2d4591f":"There seems to be an exponential decay in the number of participants in the different countries.<br>\nTo have a reasonable amount of data left for each country **I will restrict my model to the five most frequent countries.**<br>\nIf you like to expand the number of countries, remember the sparsity of the data increases with more countries and the inference will be less reliable.","5c3a20fb":"***\n## <a id=6>6. Train And Optimize The Regressor<\/a>\n\nNow a basic **LGBMRegressor** will be trained and **automatically optimized.**","ca710b02":"There are many **different jobs included in this survey.** Let us visualize them and filter for the interesting ones here on Kaggle."}}