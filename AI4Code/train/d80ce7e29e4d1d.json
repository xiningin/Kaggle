{"cell_type":{"7b325054":"code","927955b5":"code","4228d49a":"code","3a9e9d9d":"code","7921293a":"code","e71eb7e3":"code","3d89c134":"code","30bf284e":"code","a06833fb":"code","7a544805":"code","8bfcd32a":"code","0be4f168":"code","63e2209a":"code","fe1346fa":"code","fdc518cc":"code","6e295d16":"code","f92228b3":"code","e0595d07":"code","d0ea0834":"code","07b11851":"code","e515aa0b":"code","28684dd3":"code","9927dfb0":"code","121711a0":"code","1c802b1d":"code","e4a021c7":"code","0acef811":"code","8ae7778c":"code","9a35319c":"code","3f2b21a7":"code","d9462e82":"code","53768c32":"code","5bdc8f53":"code","d360d187":"markdown","d8e8d497":"markdown","6c402178":"markdown","49405f04":"markdown","1cfe4ad2":"markdown","c789d04a":"markdown","c4e8a5af":"markdown","46b1e853":"markdown","2dd813c6":"markdown","0e610178":"markdown","522a381b":"markdown","16ebb771":"markdown","d09404a5":"markdown","602fb09b":"markdown","f93a2e45":"markdown","32765233":"markdown","7a284dc8":"markdown","df66dcb5":"markdown","75352586":"markdown","1d97e15b":"markdown","92b8ecec":"markdown","41635788":"markdown","8e1e2628":"markdown","67c2a344":"markdown","2a8d7e32":"markdown","67579d33":"markdown","dfb28144":"markdown","6f9609ee":"markdown","06b9dd14":"markdown","614994a8":"markdown","8eb247ca":"markdown","ca15ef79":"markdown"},"source":{"7b325054":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","927955b5":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","4228d49a":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","3a9e9d9d":"for pclass in [1, 2, 3]:\n    survived = train_data.loc[train_data['Pclass'] == pclass]['Survived']\n    print(f\"{sum(survived)\/len(survived):%} of passengers in class {pclass} survived\")\n\nprint()\n\nfor gender in [\"male\", \"female\"]:\n    survived = train_data.loc[train_data['Sex'] == gender]['Survived']\n    print(f\"{sum(survived)\/len(survived):%} of {gender} passengers survived\")\n\nprint()\n\nprint(f\"Mean age of survivors: {train_data['Age'][train_data['Survived'] == 1].mean()}\")\nprint(f\"Mean age of fatalities: {train_data['Age'][train_data['Survived'] == 0].mean()}\")\n\nprint()\n\nprint(f\"Mean no. siblings\/spouses among survivors: {train_data['SibSp'][train_data['Survived'] == 1].mean()}\")\nprint(f\"Mean no. siblings\/spouses among fatalities: {train_data['SibSp'][train_data['Survived'] == 0].mean()}\")\n\nprint()\n\nprint(f\"Mean no. parents\/children among survivors: {train_data['Parch'][train_data['Survived'] == 1].mean()}\")\nprint(f\"Mean no. parents\/children among fatalities: {train_data['Parch'][train_data['Survived'] == 0].mean()}\")\n    \nprint()\n\nprint(f\"Mean fare among survivors: {train_data['Fare'][train_data['Survived'] == 1].mean()}\")\nprint(f\"Mean fare among fatalities: {train_data['Fare'][train_data['Survived'] == 0].mean()}\")\n    \nprint()\n\nknown_decks = train_data.dropna(subset=['Cabin'])\nfor deck in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\"]:\n    survived = known_decks.loc[known_decks['Cabin'].apply(lambda c: c.startswith(deck))]['Survived']\n    print(f\"{sum(survived)\/len(survived):%} of passengers on deck {deck} survived\")\n    \nprint()","7921293a":"print(f\"Median age of survivors: {train_data['Age'][train_data['Survived'] == 1].median()}\")\nprint(f\"Median age of fatalities: {train_data['Age'][train_data['Survived'] == 0].median()}\")\n\nprint()\n\nprint(f\"Median no. siblings\/spouses among survivors: {train_data['SibSp'][train_data['Survived'] == 1].median()}\")\nprint(f\"Median no. siblings\/spouses among fatalities: {train_data['SibSp'][train_data['Survived'] == 0].median()}\")\n\nprint()\n\nprint(f\"Median no. parents\/children among survivors: {train_data['Parch'][train_data['Survived'] == 1].median()}\")\nprint(f\"Median no. parents\/children among fatalities: {train_data['Parch'][train_data['Survived'] == 0].median()}\")\n    \nprint()\n\nprint(f\"Median fare among survivors: {train_data['Fare'][train_data['Survived'] == 1].median()}\")\nprint(f\"Median fare among fatalities: {train_data['Fare'][train_data['Survived'] == 0].median()}\")","e71eb7e3":"import seaborn as sns\n\nsns.swarmplot(x=train_data['Survived'],\n              y=train_data['Fare'],\n              hue=train_data['Pclass'])","3d89c134":"import matplotlib.pyplot as plt\n\nsns.kdeplot(data=train_data.loc[train_data['Survived'] == 1]['Fare'], shade=True)\nsns.kdeplot(data=train_data.loc[train_data['Survived'] == 0]['Fare'], shade=True)\nplt.legend(labels=[\"Survived\", \"Didn't\"])\nplt.show()","30bf284e":"sns.swarmplot(x=train_data['Survived'],\n              y=train_data['Age'],\n              hue=train_data['Sex'])","a06833fb":"survived = train_data.loc[train_data['Age'] < 18]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of children survived\")\nsurvived = train_data.loc[train_data['Age'] >= 18]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of adults survived\")","7a544805":"sns.swarmplot(x=train_data['Survived'],\n              y=train_data['Parch'],\n              hue=train_data['Age'] < 18)\nplt.legend(title=\"Child?\")","8bfcd32a":"survived = train_data.loc[(train_data['Age'] >= 18) & (train_data['Parch'] >= 1)]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of adults with parents or children on board survived\")\n\nsurvived = train_data.loc[(train_data['Age'] >= 18) & (train_data['Parch'] == 0)]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of adults without parents or children on board survived\")","0be4f168":"sns.swarmplot(x=train_data['Survived'],\n              y=train_data['SibSp'],\n              hue=train_data['Age'] < 18)\nplt.legend(title=\"Child?\")","63e2209a":"survived = train_data.loc[(train_data['Age'] >= 18) & (train_data['SibSp'] >= 1)]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of adults with a sibling or spouse on board survived\")\n\nsurvived = train_data.loc[(train_data['Age'] >= 18) & (train_data['SibSp'] == 0)]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of adults with no sibling or spouse on board survived\")","fe1346fa":"survived = train_data.loc[(train_data['Age'] >= 18) & (train_data['Parch'] + train_data['SibSp'] >= 1)]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of adults with a relative on board survived\")\n\nsurvived = train_data.loc[(train_data['Age'] >= 18) & (train_data['Parch'] + train_data['SibSp'] == 0)]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of adults with no relatives on board survived\")\n\nprint()\n\nsurvived = train_data.loc[train_data['Parch'] + train_data['SibSp'] >= 1]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of all passengers with a relative on board survived\")\n\nsurvived = train_data.loc[train_data['Parch'] + train_data['SibSp'] == 0]['Survived']\nprint(f\"{sum(survived)\/len(survived):%} of all passengers with no relatives on board survived\")","fdc518cc":"sns.swarmplot(x=train_data['Survived'],\n              y=train_data['Parch'] + train_data['SibSp'],\n              hue=train_data['Age'] < 18)\nplt.legend(title=\"Child?\")","6e295d16":"survivors = train_data.loc[train_data['Survived'] == 1]\nothers = train_data.loc[train_data['Survived'] == 0]\n\nsurvivor_families = survivors['Parch'] + survivors['SibSp']\nother_families = others['Parch'] + others['SibSp']\n\nsns.distplot(a=survivor_families, bins=max(survivor_families) - min(survivor_families))\nsns.distplot(a=other_families, bins=max(other_families) - min(other_families))\nplt.legend(labels=[\"Survived\", \"Didn't\"])\nplt.show()","f92228b3":"sns.swarmplot(x=train_data['Pclass'],\n              y=train_data['Parch'] + train_data['SibSp'],\n              hue=train_data['Age'] < 18)\nplt.legend(title=\"Child?\")","e0595d07":"y = train_data['Survived']\n\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin']\n\nX = pd.DataFrame(train_data[features])\nX_test = pd.DataFrame(test_data[features])\n\nX.head(10)","d0ea0834":"import string\n\nfor dataset in [X, X_test]:\n    dataset['Sex'] = dataset['Sex'].apply(lambda s: {'male': 0, 'female': 1}[s])\n    # The first letter of the cabin is the deck\n    # There's one guy in Cabin T, which feels weird; let's treat him like a NaN\n    dataset['Cabin'] = dataset['Cabin'].apply(\n        lambda c: string.ascii_uppercase.index(c[0])\n        if type(c) == type('a') and c != 'T'\n        else np.NaN\n    )\n    \nX.head()","07b11851":"for dataset in [X, X_test]:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch']\n    del dataset['SibSp']\n    del dataset['Parch']\n    \nX.head()","e515aa0b":"from sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\nmedian_imputer = SimpleImputer(strategy='median')\nmode_imputer = SimpleImputer(strategy='most_frequent')\n\nmedian_cols = ['Age', 'Fare', 'FamilySize']\nmode_cols = ['Pclass', 'Sex', 'Cabin']\n\npreprocessor = ColumnTransformer(transformers=[('median', median_imputer, median_cols),\n                                               ('mode', mode_imputer, mode_cols)])\n        \nX = pd.DataFrame(preprocessor.fit_transform(X))\nX_test = pd.DataFrame(preprocessor.transform(X_test))\n\nX.columns = median_cols + mode_cols\nX_test.columns = median_cols + mode_cols\n\nX.head()","28684dd3":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrf_params = {'bootstrap': [True, False],\n             'max_depth': [5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n             'max_features': ['auto', 'sqrt'],\n             'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n             'min_samples_split': [1, 5, 10, 15, 20, 25, 30],\n             'n_estimators': [10, 20, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n            }\n\nrf_model = RandomForestClassifier()\n\nrf_search = RandomizedSearchCV(estimator=rf_model,\n                               param_distributions=rf_params,\n                               n_iter=200,\n                               cv=3,\n                               scoring='neg_log_loss',\n                               n_jobs=-1)\n\nrf_search.fit(X, y)\n\nrf_search.best_params_","9927dfb0":"from sklearn.model_selection import cross_val_score\n\nrf_model = rf_search.best_estimator_\n\nprint(cross_val_score(rf_model, X, y, cv=3, scoring='accuracy').mean())\n\nrf_model.fit(X, y)\nrf_predictions = rf_model.predict(X_test)\n\nrf_output = pd.DataFrame({\"PassengerId\": test_data.PassengerId, \"Survived\": rf_predictions})\nrf_output.to_csv(\"random_forest.csv\", index=False)\nrf_output.head(10)","121711a0":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nxgb_model = XGBClassifier()\n\nxgb_params = {'learning_rate': [0.01, 0.02, 0.05, 0.1],\n              'n_estimators': [10, 20, 50, 100, 200],\n              'max_depth': [1, 5, 10, 15, 20]\n             }\n\nxgb_search = GridSearchCV(estimator=xgb_model,\n                          param_grid=xgb_params,\n                          cv=3,\n                          scoring='neg_log_loss',\n                          n_jobs=-1)\n\nxgb_search.fit(X, y)\n\nxgb_search.best_params_","1c802b1d":"xgb_model = xgb_search.best_estimator_\n\nprint(cross_val_score(xgb_model, X, y, cv=3, scoring='accuracy').mean())\n\nxgb_model.fit(X, y)\nxgb_predictions = xgb_model.predict(X_test)\n\nxgb_output = pd.DataFrame({\"PassengerId\": test_data.PassengerId, \"Survived\": rf_predictions})\nxgb_output.to_csv(\"xgboost.csv\", index=False)\nxgb_output.head(10)","e4a021c7":"rf_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\nprint(rf_importances)\n\nsns.barplot(x=rf_importances.index, y=rf_importances)","0acef811":"xgb_importances = pd.Series(xgb_model.feature_importances_, index=X.columns)\nprint(xgb_importances)\n\nsns.barplot(x=xgb_importances.index, y=xgb_importances)","8ae7778c":"X = X.drop('Cabin', axis='columns')\nX_test = X_test.drop('Cabin', axis='columns')\n\nX.head()","9a35319c":"xgb_model = XGBClassifier()\n\nxgb_params = {'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1],\n              'n_estimators': [1, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n              'max_depth': [1, 2, 3, 5, 10, 15, 20]\n             }\n\nxgb_search = GridSearchCV(estimator=xgb_model,\n                          param_grid=xgb_params,\n                          cv=3,\n                          scoring='neg_log_loss',\n                          n_jobs=-1)\n\nxgb_search.fit(X, y)\n\nxgb_search.best_params_","3f2b21a7":"xgb_model = xgb_search.best_estimator_\n\nprint(cross_val_score(xgb_model, X, y, cv=3, scoring='accuracy').mean())\n\nxgb_model.fit(X, y)\nxgb_predictions = xgb_model.predict(X_test)\n\nxgb_output = pd.DataFrame({\"PassengerId\": test_data.PassengerId, \"Survived\": rf_predictions})\nxgb_output.to_csv(\"xgboost2.csv\", index=False)\nxgb_output.head(10)","d9462e82":"xgb_importances = pd.Series(xgb_model.feature_importances_, index=X.columns)\nprint(xgb_importances)\n\nsns.barplot(x=xgb_importances.index, y=xgb_importances)","53768c32":"sex_only = pd.DataFrame({\"PassengerId\": test_data.PassengerId, \"Survived\": [1 if s == 'female' else 0 for s in test_data['Sex']]})\nsex_only.to_csv(\"gender.csv\", index=False)\nsex_only.head(10)","5bdc8f53":"xgb_output.loc[xgb_output['Survived'] != sex_only['Survived']]","d360d187":"# Who died?\n\nBefore we dive in, let's take a look at the data.\n\nThe dataset has several columns:\n* `PassengerId`: A unique ID, which probably had little impact on survival\n* `Survived`: Only present in the training data, this is what we want to predict. A value of `1` indicates that the passenger survived, `0` that they... well, didn't\n* `Pclass`: The passenger's ticket class, running from `1` (first class) down to `3` (third class). This should function as a good proxy for socioeconomic status.\n* `Name`: It's nice to remember that these were real people who had a *really* bad day, but there's little to learn here \u2014 unless lifeboats were loaded in alphabetical order.\n* `Sex`: The legal sex of each passenger; lifeboats were famously loaded \"women and children first\", so we'd expect this to have a significant impact on one's chances of survival\n* `Age`: Relatively self-explanatory, we'd expect to see a similar trend here, at least with those under 18 being more likely to survive than their older shipmates\n* `SibSp`: The number of siblings and spouses of the passenger who are also on board, which have for some reason been combined together. Presumably children are more likely to travel with siblings, while adults are more likely to have a spouse\n* `Parch`: The number of parents and children of the passenger who are also on board, with a different capitalisation convention for some reason\n* `Ticket`: The passenger's ticket number. Unless there's some meaning to the digits, there's unlikely to be much to learn here\n* `Fare`: How much the passenger paid for their ticket, another good indicator of wealth and class\n* `Cabin`: The passenger's cabin number. There are good reasons to expect this to correlate to survival, with those below-decks or close to the breach less likely to survive, but unfortunately this information is missing for many of the passengers in the dataset\n* `Embarked`: The port at which the passenger embarked. Perhaps those who were on board longest forged a stronger relationship with the staff guarding the lifeboats, but there's really no reason to expect a strong correlation\n\nSo, some hypotheses.\n\nThings that probably won't affect much:\n* `PassengerId`\n* `Name`\n* `Ticket`\n* `Embarked`\n\nThings likely to have a direct effect due to the lifeboat loading policies:\n* `Pclass`: First-class passengers should be more likely to survive\n* `Sex`: Women should be more likely to survive\n* `Age`: Children should be more likely to survive\n\nOther things likely to have an impact:\n* `SibSp`: Those travelling with a larger family group might have an easier time\n* `Parch`: Children and their parents should be overrepresented here, and should be more likely to survive\n* `Fare`: Wealthy passengers should be more likely to survive, even if not otherwise accounted for by their class\n* `Cabin`: Those with cabins on the lower decks should be less likely to survive\n\nLet's visualise some of this data and see if these relationships hold.","d8e8d497":"## XGBoost\n\nLet's start with the XGBoost model this time, since it performed slightly better before.","6c402178":"It seems not. If anything, large families are overrepresented in third class, but that again disappears if we remove children from our set. I'm moderately satisfied at this point that family size has an impact.\n\n## Decks\n\nFinally, let's look at decks, then we can actually get stuck in.\n\nApart from one weirdo whose cabin number is apparently just \"T\", decks in our dataset seem to run from A to G, with A being at the top of the ship and G deep in its bowels.\n\nWe saw above that the effect of a passenger's deck on their survival was surprisingly small, although it's not hard to believe a significant number of people simple weren't in their cabins at the time of the \"incident\".\n\nThere's almost certainly a relationship between deck, class, and fare, and cabin data is lacking from most of the passengers in our dataset, so the parsimonious thing to do would be to leave it out. However, I doubt that proximity to the big icy thing could have no effect at all, so I'd like to leave it in.\n\nWe'll revisit this later when we come to building our model. I'd quite like to try two versions and simply see which cross-validates best.","49405f04":"Numbers are nice, so let's convert our two non-numerical columns, `Sex` and `Cabin`.\n\nI'm going to turn the cabin numbers into a deck number, starting from 0 at the top of the ship and increasing downwards. The one guy in Cabin T gets treated as `NaN` because what even is he.","1cfe4ad2":"**0.76555** \u2014 finally, an improvement.\n\nThat puts us in the top 80%. How disappointing.","c789d04a":"That's not nothing!\n\nSince we already have multiple types of family relationship awkwardly smushed together, let's try combining them all into one big family size parameter.","c4e8a5af":"# Improving the models","46b1e853":"As you'd expect, fare is correlated with both class and survival. Among those who perished, low fares are disproportionately represented, while those who paid high fares stood a much better chance of survival.\n\nNow, let's talk about sex.\n\n## Age and sex","2dd813c6":"## XGBoost\n\nEveryone knows XGBoost is the superior technique \u2014 right?\n\nWe won't fit quite as many parameters this time, so let's do an exhaustive grid search.","0e610178":"We're seeing about 83% accuracy with this model (across 3-fold cross-validation). Not bad. Not stellar, but decent.\n\nBut on the test set, this model only scores **0.75837**. We can do better.","522a381b":"(The first time I tried to submit that file, I named it `sex.csv` and it took a suspiciously long time to process.)\n\nThat scores... **0.76555**\n\nExactly the same as our fancy XGBoost model. How depressing.\n\nPresumably they make exactly the same set of predictions?","16ebb771":"Now, about those `NaN`s. We need some way to impute those.\n\nAs we saw above, the median seems like a safe central value for this dataset, so let's use that for the continous variables: `Age`, `Fare`, and `FamilySize`.\n\nFor `Pclass`, `Sex`, and `Cabin`, I'll use the mode, even though two of those have an obvious ordering, because it's simply not obvious that most passengers would be in the median class or on the median deck.","d09404a5":"No, they just perform equally well.","602fb09b":"# Setting up\n\nFirst, let's get everything set up. This is the standard Kaggle header.","f93a2e45":"Given the importance of sex, it's reasonable to wonder if we even need the other features at all...\n\n# A Simple Benchmark","32765233":"Now let's read in the data","7a284dc8":"# Fitting a model\n\n## Random forest\n\nLet's start with a random forest model.\n\nIt's not obvious what set of hyperparameters we should use, so let's search the space. We could do a grid search, but with so many parameters to tune we're probably best off sampling a subset to begin with. So let's do a randomised search.","df66dcb5":"That KDE could do with some better smoothing, given the awkward discrete variable I've fed it, but we see a bit of a difference there. Those travelling alone are somewhat less likely to survive than those travelling with family. Overall, I think we can take overall family size as a slightly less noisy way to quantify family relationships.\n\nA thought occurs, however: Presumably the upper classes would be more likely to be travelling with families? They are in the film. Let's find out.","75352586":"This cross-validates slightly worse, but we've removed a feature so it really should. That's not necessarily a bad thing: It's possible we were overfitting before.\n\nHow does it score on the test set?","1d97e15b":"We see that, as you'd expect, only a couple of children on board had no parents with them (apparently travelling with a nanny). We also see no obvious effect of a parent-child relationship on survival.\n\nLet's take out the children, because we already know about them...","92b8ecec":"So, yes, age has an effect, but only until your 18th birthday. In fact, we see that the oldest person in our dataset, a man in his 80s, survived.\n\n## Family\n\nOn the subject of children, let's look at parent\u2013child relationships. If children are more likely to survive, are their parents allowed to survive with them?","41635788":"There are some outliers here \u2014 presumably a single large family, none of whom survived \u2014 but other than that we see that this relationship holds. Those travelling with no more than one sibling or spouse are nearly all adults, while those travelling with large numbers of siblings are all children.\n\nWe'd thus expect this to affect survival chance primarily as a proxy for age, which is already accounted for elsewhere, but let's take out the children again and see what we get.","8e1e2628":"Interesting. Of course, the mean may not be the best measure for this sort of data, given the huge income and lifestyle disparity on board the *Titanic*, so let's double-check:","67c2a344":"Interesting. Our XGBoost model seems to be sex-obsessed; while the random forest also considers it the most important feature, it gives it much less relative weight.\n\nNeither model cares very much about the deck, which we already know isn't as informative as we'd like it to be anyway, so we can probably drop it from our dataset quite safely. Let's do that now.","2a8d7e32":"With fewer parameters, we've improved our accuracy under cross-validation. Score!","67579d33":"Interesting! It seems having a child on board does help, so bear that in mind when planning your next cruise.\n\nDo we observe a similar effect for siblings and spouses?\n\nThis is a weird one, because those are quite different types of relationship. In particular, we'd expect most of those travelling with spouses to be adults, and most of those travelling with siblings to be children.","dfb28144":"Overall, having family on board improves your chances of survival from around 30% to a whopping 50%.\n\nI imagine you'd still rather not be on board, but you've got to take what you can get.","6f9609ee":"# Preprocessing the Data\n\nLet's take out the column we want to predict, and drop the ones we're not going to use from our dataset.","06b9dd14":"I've lumped it in with age here, because the difference between the sexes is so obvious it doesn't really need its own graph. Just look at all that orange.\n\nWe also see a relatively small effect of age on survival, except for the very youngest children.\n\nLet's look at children specifically.","614994a8":"Let's rewrite `SibSp` and `Parch` to something nice like `FamilySize`.","8eb247ca":"On the test set this time, we score **0.76076**. Better, but I want more.\n\nLet's look into what our models have actually done.\n\n# Exploring our models","ca15ef79":"Oh look, our trends disappeared.\n\nIt seems like the majority of people on board had no siblings, spouses, parents or children on board. That's slightly surprising.\n\nNote also that the median ages of survivors and otherwise are the same (although there is a small difference in the means). If we expected children to be more likely to survive, this is slightly odd too.\n\nThe class, sex, and fare, however, remain solid predictors.\n\nLet's see some graphs.\n\n## Class and fare"}}