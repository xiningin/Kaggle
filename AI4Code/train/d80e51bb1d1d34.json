{"cell_type":{"58855d8d":"code","a22fe4aa":"code","1971e793":"code","6609dad0":"code","b273a7fe":"code","342790da":"code","7d725fa7":"code","c6e267fe":"code","5de0850c":"code","e12fd0d6":"code","88c3439c":"code","1def34e8":"code","2a0a3489":"code","89dc9d25":"code","cb26460b":"code","f0857b9e":"code","00ec16a8":"code","22aa1e74":"code","baa47d26":"code","df960354":"code","70f6d5cd":"code","2fbb5f1d":"code","0a24d2b7":"code","0adfaaea":"code","e62c58f0":"code","f886b237":"code","2acd88f8":"code","c2246b3a":"code","a4c7988c":"code","6a956f99":"code","f363825b":"code","4620f016":"code","57a2b8c2":"code","d70bdd68":"code","4c96cc21":"code","975693d9":"code","91091b67":"code","1a739023":"markdown","24664347":"markdown","8bc29bf0":"markdown","14d6ce90":"markdown","9a9a66b2":"markdown","53c3c054":"markdown","81979b6d":"markdown","3858b2f1":"markdown","474a773b":"markdown","30fdc6a6":"markdown","63f764e1":"markdown","01339469":"markdown","b370abca":"markdown","2d9d91a4":"markdown","0488ce17":"markdown","003fdf00":"markdown","01b7297a":"markdown","a5e60128":"markdown","0c0114d6":"markdown","47349e21":"markdown","49d7ff7c":"markdown","5aef2f9c":"markdown","3e719119":"markdown","769accd4":"markdown","b07a7f16":"markdown","c70c7afb":"markdown","1b32572f":"markdown","2a1066f6":"markdown","2243aeec":"markdown","db0ee5ff":"markdown","4f513f88":"markdown"},"source":{"58855d8d":"import pandas as pd\npd.read_csv('..\/input\/traffic-signs-classification\/labels.csv')","a22fe4aa":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport seaborn as sns","1971e793":"dir_path = '..\/input\/gtsrb-german-traffic-sign'","6609dad0":"os.listdir(dir_path)","b273a7fe":"#Assigning the path for train and test images\n\ntrain_path = dir_path +'\/Train'\ntest_path = dir_path + '\/Test'","342790da":"print(sorted(os.listdir(train_path)))","7d725fa7":"sorted(os.listdir(test_path))","c6e267fe":"import random\n\nimages_path = os.listdir(test_path)\n\nplt.figure(figsize=(25,25))\n\n\nfor i in range(1,26):\n    \n    plt.subplot(5,5,i)\n    random_img_path = test_path +'\/'+ random.choice(images_path)\n    rand_img = imread(random_img_path)\n    plt.imshow(rand_img)\n    plt.xlabel(rand_img.shape[1], fontsize = 20)#width of image\n    plt.ylabel(rand_img.shape[0], fontsize = 20)#height of image\n","5de0850c":"dim1 = []\ndim2 = []\n\nfor i in range(0,43):\n    labels = train_path + '\/{0}'.format(i)\n    image_path = os.listdir(labels)\n    for x in image_path:\n        img = imread(labels + '\/' + x)\n        dim1.append(img.shape[0])\n        dim2.append(img.shape[1])","e12fd0d6":"sns.jointplot(dim1,dim2)\nplt.show()","88c3439c":"np.mean(dim1)","1def34e8":"np.mean(dim2)","2a0a3489":"image_shape = (50,50)","89dc9d25":"from PIL import Image\n\nimages = []\nlabel_id = []\n\nfor i in range(43):\n    labels = train_path + '\/{0}'.format(i)\n    image_path = os.listdir(labels)\n    for x in image_path:\n        img = Image.open(labels + '\/' + x)\n        img = img.resize(image_shape)\n        img = np.array(img)\n        images.append(img)\n        label_id.append(i)","cb26460b":"#Converting images into numpy array\nimages = np.array(images)\n#The pixel value of each image ranges between 0 and 255\n#Dividing each image by 255 will scale the values between 0 and 1. This is also known as normalization.\nimages = images\/255 ","f0857b9e":"label_id = np.array(label_id)\nlabel_id.shape","00ec16a8":"images.shape","22aa1e74":"plt.figure(figsize=(15,5))\nsns.countplot(label_id)\nplt.title('Distribution of images among different classes', fontsize = 15)\nplt.xlabel('Label_id', fontsize=12)\nplt.show()","baa47d26":"#Saving the scaled images and labels for future use\nnp.save('Training_set', images)\nnp.save('Label_Id', label_id)","df960354":"import numpy as np\nimport pandas as pd","70f6d5cd":"images = np.load('Training_set.npy')\nlabel_id = np.load('Label_Id.npy')","2fbb5f1d":"#Splitting the data\nfrom sklearn.model_selection import  train_test_split\nx_train, x_val, y_train, y_val = train_test_split(images, label_id , test_size = 0.2, random_state = 42)","0a24d2b7":"#keras has a built-in function for one-hot encoding.\nfrom tensorflow.keras.utils import to_categorical\n\ny_train_cat = to_categorical(y_train)\n\ny_val_cat = to_categorical(y_val)","0adfaaea":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D","e62c58f0":"model = Sequential()\n\n#1st layer\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), input_shape = x_train.shape[1:], activation = 'relu', padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\n#2nd layer\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\n#3rd layer\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\n#Dense layer\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.5))\n\n#Output layer\nmodel.add(Dense(43, activation = 'softmax'))","f886b237":"model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","2acd88f8":"model.summary()","c2246b3a":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 2)\n\nmodel.fit(\n    \n    x_train, y_train,\n    epochs = 25,\n    batch_size = 64,\n    validation_data = (x_val, y_val),\n    callbacks = [early_stopping],\n    verbose = 2\n\n)","a4c7988c":"#Saving the model\nmodel.save('Model.h5')","6a956f99":"evaluation = pd.DataFrame(model.history.history)\n\nevaluation[['accuracy', 'val_accuracy']].plot()\nevaluation[['loss', 'val_loss']].plot()","f363825b":"from tensorflow.keras.models import load_model\nmodel = load_model('Model.h5')","4620f016":"test_path = '..\/input\/test-images\/Test'\ntest_img = sorted(os.listdir(test_path))","57a2b8c2":"#defining a function that will scale images\nfrom PIL import Image\n\ndef scaling(test_images, test_path):\n    images = []\n\n    image_path = test_images\n    \n    for x in image_path:\n        img = Image.open(test_path + '\/' + x)\n        img = img.resize((50,50))\n        img = np.array(img)\n        images.append(img)\n\n    #Converting images into numpy array\n    images = np.array(images)\n    #The pixel value of each image ranges between 0 and 255\n    #Dividing each image by 255 will scale the values between 0 and 1. This is also known as normalization.\n    images = images\/255\n\n    return images","d70bdd68":"test_images = scaling(test_img,test_path)","4c96cc21":"test = pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Test.csv')\n\ny_test = test['ClassId'].values\n\ny_test","975693d9":"y_pred = model.predict_classes(test_images)\n\ny_pred","91091b67":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test,y_pred))","1a739023":"#### Scaling the images so that the values remain between 0 and 1","24664347":"## Splitting the train data into train and validation data","8bc29bf0":"####   ","14d6ce90":"## Testing on test data","9a9a66b2":"# Intro","53c3c054":"# Visualization","81979b6d":"#### Importing the images","3858b2f1":"#### We achieved an overall accuracy of 97% on our model. This is pretty good and we can use this model for predicting some other Traffic signs as well in future.","474a773b":"## Data Preprocessing","30fdc6a6":"# Importing Libraries","63f764e1":"### Labels Overview","01339469":"The dimensions of the images are not fixed. \n\n#### Note:\nConvolutional neural networks cannot perform on images that have various dimensions.\nWe will resize these images during our model building.\n","b370abca":"#### Test labels","2d9d91a4":"## Testing on test images","0488ce17":"#### Exploring the dimensions with a jointplot","003fdf00":"## Model Evaluation\n","01b7297a":"The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n\n1. Single-image, \n2. Multi-class classification problem\n3. More than 40 classes\n4. More than 50,000 images in total\n5. Large, lifelike database","a5e60128":"#    ","0c0114d6":"But first find the mean of the dimensions of all the images in training set.","47349e21":"#   ","49d7ff7c":"#### Visualizing 25 random sample images from test set","5aef2f9c":"#  ","3e719119":"##   ","769accd4":"**The above function can be used to scale any new traffic-sign images that can be predicted with our model. This is a general purpose function for code reusability.**","b07a7f16":"# Data Collection","c70c7afb":"Since the mean of both dimensions is around 50 , we will use (50x50) as the shape of images.","1b32572f":"##### For some unknown reason , the images in kaggle kernel is not showing in the order they are in the Test folder. Upon inspection it is seen that the images are in sorted order. So using sorted() function to sort them.","2a1066f6":"#### Note: The test images folder in the original dataset has a blank csv file which cannot be opened with the above function. So i copied that folder and deleted that csv file and uploaded the test images again seperately. These test images are same as the test images in the original dataset","2243aeec":"#### Changing target labels to categorical  using one-hot encoding technique","db0ee5ff":"#### Achieved highest accuracy of 99.50% on validation data","4f513f88":"## Model Building"}}