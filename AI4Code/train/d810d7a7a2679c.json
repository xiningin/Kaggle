{"cell_type":{"0dc4ad49":"code","85e35c62":"code","5c0461b6":"code","33bcb021":"code","e26d4d6c":"markdown","716a48d6":"markdown","e1b63f87":"markdown","1b9fef4a":"markdown","886844c3":"markdown","0c8a5594":"markdown"},"source":{"0dc4ad49":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom matplotlib import pyplot as plt\nfrom textblob import TextBlob\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport nltk","85e35c62":"# Loading the text file and organizing it into a structured dataframe\nraw_text = pd.read_csv('..\/input\/text-analysis-keep-private\/emily_texts.txt', sep='\\n', header=None)\nraw_text_df = pd.DataFrame(raw_text.iloc[::,0].str.split('\\t', expand=True))\n\n# Organizing the columns and encoded dummy data for categorical variables\norganized_text_df = raw_text_df.rename(columns={0:'date',1:'time',2:'in\/out',3:'number',4:'contact',5:'text'})\nio_data = pd.get_dummies(data=organized_text_df['in\/out'], prefix='text')\n\n# Cleaned the dataframe by dropping the unnecessary columns\ntext_df = organized_text_df.drop(columns=['number','contact','in\/out'])\ntext_df['sent_evan'],text_df['sent_emily'] = io_data['text_in'],io_data['text_out']\n\n# Deconstructed the date column to only get what I needed and added to the final dataframe\nexpanded_time_df = text_df['time'].str.split(':', expand=True)\nexpanded_time_df.rename(columns={0:'hour', 1:'minutes', 2:'seconds'}, inplace=True)\ntext_df['time'] = expanded_time_df['hour']","5c0461b6":"# Plotting the number of text messages sent by each person during the 21 day period\ntext_by_person = pd.DataFrame(text_df.groupby('date')[['sent_evan','sent_emily']].sum())\nplt.style.use('seaborn-whitegrid')\ntext_by_person.plot(kind='bar', figsize=(20,5), title='Who Texted Who More?')\nplt.legend(labels=['Evan','Emily'])\nplt.xticks(rotation=0)\nplt.xlabel('Date')\nplt.ylabel('Number of Text Messages')\nplt.savefig('TextCountPerPerson.png')\n\n# Plotting the average peak times we messaged each other during the 21 day period\nsns.set_style('whitegrid')\nplt.figure(figsize=(20,5))\nsns.distplot(text_df['time'], kde=False)\nplt.title('What Time Did We Text The Most?')\nplt.xticks(range(24))\nplt.xlabel('Hour of the Day')\nplt.ylabel('Number of Texts Exchanged')\nplt.savefig('TextsPerHour.png')","33bcb021":"# Tokenizing the text data using the NLTK module\ntoken_list = []\nfor raw_text in text_df['text']:\n    tokens = nltk.word_tokenize(raw_text)\n    token_list.append(tokens)\n\ntext_df['tokens'] = token_list\ntoken_df = text_df.drop(columns='text')\n\n# Computing the sentiment scores (polarity) and categorizing the results using the TextBlob module\nsentiment_scores_tb = [round(TextBlob(str(texts)).sentiment.polarity, 3) for texts in token_df['tokens']]\nsentiment_category_tb = ['positive' if score > 0 \n                             else 'negative' if score < 0 \n                                 else 'neutral' \n                                     for score in sentiment_scores_tb]\n\ndf = token_df.drop(columns='tokens')\nsender_list = []\nfor x in token_df['sent_evan']:\n    if x == 1:\n        sender_list.append('Evan')\n    else:\n        sender_list.append('Emily')\n\n# Creating a dataframe for the sentiment data analyzed       \ndf['Sent By'], df['Sentiment Score'], df['Sentiment Category'], df['TextBlob'] = sender_list,sentiment_scores_tb,sentiment_category_tb,token_list\nresults = df.drop(columns=['sent_evan','sent_emily'])\nfinal_results = results.rename(columns={'date':'Date','time':'Hour of the Day'})\nresults_stats = final_results.describe(include='all')\n\n# Plotting a chart showing the sentiment scores\nplt.figure(figsize=(20,6))\nsns.lineplot(x=final_results['Date'], y=final_results['Sentiment Score'])\nplt.title('The Different Levels of Kilig')\nplt.savefig('KiligLevels.png')","e26d4d6c":"### Environment Setup\n* I decided to use NLTK and TextBlob as my text analytics modules for this task, because of the ease of use. This is my first time trying to do a text\/sentiment analysis and the modules I mentioned were very fun to use even as a beginner. Also, big shoutout to Pandas for always coming through with the data cleaning section of this task.","716a48d6":"# 21 Days Later (A Romantic Story, Not the Horror Film)\n## Sentiment Analysis of 724 text messages exchanged between me and my girlfriend using NLTK and TextBlob\n**Objectives** \n* To identify what situations gave me a greater chance to be with my girlfriend now\n* To give a statistical overview of how our conversations went for the first 21 days\n\n**Author's Note** \n* This analysis was made for fun and for practice with using Natural Language Processing techniques. Please leave a comment down below if you enjoyed this, and I would appreciate it if you would leave me with suggestions on how to improve my work. ","e1b63f87":"### Data Preprocessing\n* The data set used was a text file of 724 text messages from 7 November 2017 to 26 November 2017. The data set will also remain private, if you want to do the same kind of analysis like this as well, get yourself your own girlfriend\/boyfriend (lol)","1b9fef4a":"### Hotline Bling: Identifying the distribution of messages sent and the peak hours of communication\n### Data Analysis and Visualization\n* For this section of the task, I used Pandas and Matplotlib to derive some statistical insights into our communication as an early stage startup, um, I meant couple (lol)","886844c3":"### Sentiment analysis using NLTK and TextBlob\n* I used NLTK to tokenize the text data and TextBlob to calculate the sentiment scores. \n* As you can see the code below, I used NLTK only for tokenizing the data. I chose not to filter it with stopwords, or stem, or lemmatize it, due to the combination of English, Tagalog, and Bisaya words used in the text data that would have made the results very distorted. \n* In this section, TextBlob uses polarity, subjectivity, and intensity scores based upon a certain lexicon and averages them out for each textblob, or a collection of words and phrases, and joins them together to identify patterns for sentiment scoring. \n* The visualization below also shows the sentiments scores during the 21 day period based on the TextBlob results. FYI, 'kilig' means 'romantic excitement' in english, for my non-Filipino readers out there.","0c8a5594":"### Conclusion\n* I believe with more data, and a more even distribution I could have gathered more specific results, but as a task for an NLP beginner, this was a very fun activity to do. It's amazing how we can use technology like this, to break down conversations into numbers, and numbers into insights. I would also like to acknowledge my girlfriend for finding this romantic, and for still being my girlfriend even though it's already past 21 days (lol)\n* And lastly, if you enjoyed this cringey little output of mine, please feel free to leave comments on how I can improve my work and what your thoughts are into this. Thank you!"}}