{"cell_type":{"74d5acc5":"code","d04835fb":"code","55a92bb6":"code","f8e77906":"code","f480377b":"code","3fe746fb":"code","0f7277a1":"code","e43e78fd":"code","b9fd61bc":"code","4ba6afd5":"code","f02de821":"code","01b10745":"code","2fa0864a":"code","a96aae48":"code","1a230df5":"code","a49a756d":"code","c7d1699d":"code","6c774bed":"code","cfa86cee":"code","681c3e06":"code","597b9465":"code","c8bdc780":"code","ffd3cc03":"code","8d434959":"markdown","9749c223":"markdown","66620b58":"markdown","fc389b75":"markdown","79f6bb45":"markdown","4c3a4800":"markdown","8b4a46fc":"markdown","6f4b688a":"markdown","526d5e8d":"markdown","b4e3d1a2":"markdown","8b394a42":"markdown"},"source":{"74d5acc5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/cat-and-dog\/test_set\/test_set\"))\nprint(os.listdir(\"..\/input\/cat-and-dog\/training_set\/training_set\"))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d04835fb":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nfrom PIL import Image","55a92bb6":"train_path = \"..\/input\/cat-and-dog\/training_set\/training_set\"\n\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n    rescale = 1.\/255, \n    shear_range = 0.2, \n    zoom_range = 0.2,\n    validation_split = 0.25,\n    horizontal_flip = True\n)\n\ntrain_set = train_datagen.flow_from_directory(\n    train_path, \n    target_size = (64, 64), \n    batch_size = 32,\n    class_mode = 'binary',\n    shuffle = True,\n    subset='training',\n    seed = 123 \n)\n\nvalidation_set = train_datagen.flow_from_directory(\n    train_path, \n    target_size = (64, 64), \n    batch_size = 32,\n    class_mode = 'binary',\n    shuffle = True,\n    subset='validation',\n    seed = 123\n)","f8e77906":"def catOrDog(pred):\n    if pred == 0:\n        return 'Cat'\n    else:\n        return 'Dog'","f480377b":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","3fe746fb":"imgs, labels = next(train_set)\nplotImages(imgs)\nfor i in range(10):\n    print(catOrDog(labels[i]))","0f7277a1":"model = tf.keras.models.Sequential()\n\n# Step 1 - Convolution\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (64, 64, 3)))\n# Step 2 - Pooling\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n\n# Step 3 - Flattening\nmodel.add(tf.keras.layers.Flatten())\n# Step 4 - Full Connection\nmodel.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n# Step 5 - Output Layer\nmodel.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n","e43e78fd":"model.summary()","b9fd61bc":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])","4ba6afd5":"model.fit(train_set, epochs=25)","f02de821":"val_loss, val_accuracy = model.evaluate(validation_set)","01b10745":"from keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\n\nnew_model = Sequential()\nnew_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\nnew_model.add(MaxPooling2D((2, 2)))\n\nnew_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nnew_model.add(MaxPooling2D((2, 2)))\n\nnew_model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nnew_model.add(MaxPooling2D((2, 2)))\n\nnew_model.add(Flatten())\nnew_model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nnew_model.add(Dense(1, activation='sigmoid'))","2fa0864a":"new_train_set = train_datagen.flow_from_directory(\n    train_path, \n    target_size = (224, 224), \n    class_mode = 'binary',\n    shuffle = True,\n    subset='training',\n    seed = 123 \n)\n\nnew_validation_set = train_datagen.flow_from_directory(\n    train_path, \n    target_size = (224, 224), \n    class_mode = 'binary',\n    shuffle = True,\n    subset='validation',\n    seed = 123\n)","a96aae48":"from keras.optimizers import SGD\n\n# compile model\nopt = SGD(lr=0.001, momentum=0.9)\nnew_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n\n# fit model\nhistory = new_model.fit(new_train_set, epochs = 50)","1a230df5":"new_val_loss, new_val_accuracy = new_model.evaluate(new_validation_set)","a49a756d":"def setImage(image_path, pixels):\n    # load an image from file\n    img = Image.open(image_path)\n    plt.imshow(img)\n    # resize it\n    img = img.resize((pixels, pixels))\n    # convert the image pixels to a numpy array\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    # reshape data for the model\n    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n    # prepare the image for the VGG model\n    img = tf.keras.applications.vgg16.preprocess_input(img)\n    return img","c7d1699d":"def prediction(image_path):\n    img_64 = setImage(image_path, 64)\n    img_224 = setImage(image_path, 224)\n    return 'Old model: ' + catOrDog(model.predict(img_64)) + '\\nNew model: ' + catOrDog(new_model.predict(img_224))","6c774bed":"image1_path = '..\/input\/cats-and-dogs\/beagle.webp'\np1 = prediction(image1_path)\nprint(p1)","cfa86cee":"image2_path = '..\/input\/cats-and-dogs\/dogs and cats\/gato-animais-domesticos-adocao-zoonose-gabriel-jabur--1024x683.jpg'\np2 = prediction(image2_path)\nprint(p2)","681c3e06":"image7_path = '..\/input\/new-cats-and-dos\/cat-sitter-felino.jpg'\np7 = prediction(image7_path)\nprint(p7)","597b9465":"val_path = '..\/input\/cat-and-dog\/test_set\/test_set'\n\ndatagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input)\n\nval_set = datagen.flow_from_directory(\n    val_path, \n    target_size = (64, 64), \n    batch_size = 32,\n    class_mode = 'binary',\n)\n\nnew_val_set = datagen.flow_from_directory(\n    val_path, \n    target_size = (224, 224), \n    batch_size = 32,\n    class_mode = 'binary',\n)","c8bdc780":"model.evaluate(val_set)","ffd3cc03":"new_model.evaluate(new_val_set)","8d434959":"# Here we can see that the new model have an 10% better accuracy","9749c223":"# An attempt to improve the previous model ","66620b58":"# Finally, we can compare the 2 models with the entire set of test data that we have not used","fc389b75":"# Some example of the data we are using:","79f6bb45":"# The first CNN model that we are going to use","4c3a4800":"Here is a function to set the image to fit in the old model (64x64) or in the new (224x224), and to plot the image","8b4a46fc":"# Preprocessing the training set and the validation set to match the input in the new model","6f4b688a":"# Preprocessing the training set and the validation set using the same file","526d5e8d":"Here is just a function that returns 'Dog' if the value of the prediction is 0 and 'Cat' otherwise","b4e3d1a2":"and this one just to print the prediction results of the 2 models","8b394a42":"# Lets see if the models can predict when an image is a cat or a dog"}}