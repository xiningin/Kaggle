{"cell_type":{"c9ae4327":"code","1fb942b2":"code","8d8c716c":"code","9887e4f2":"code","94de607c":"code","3471e781":"code","b35a5018":"code","19fdc318":"code","aeb7d5f0":"code","0e17e742":"code","df8b7d8d":"code","c8a4d565":"code","48d8b24b":"markdown"},"source":{"c9ae4327":"import datetime\nimport pandas as pd\nfrom time import time\n# from autograd import grad\n# import autograd.numpy as np\nimport numpy as np\nfrom numba import njit\nfrom scipy.optimize import minimize, fsolve\nimport os","1fb942b2":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score, accuracy_score","8d8c716c":"train = pd.read_csv('\/kaggle\/input\/cascade-cup-debye\/Cascade_cup\/train_age_dataset.csv')\ntest = pd.read_csv('\/kaggle\/input\/cascade-cup-debye\/Cascade_cup\/test_age_dataset.csv')\nsample = pd.read_csv('\/kaggle\/input\/cascade-cup-debye\/Cascade_cup\/sample_submission.csv')\n\ntrain = pd.get_dummies(train, columns=['tier','gender'])\ntest = pd.get_dummies(test, columns=['tier','gender'])\n\n# REMEMBER TO ADD 1 IN THE END\n\ntrain['age_group'] = train['age_group']-1\n\nfeature_cols = [col for col in train.columns.tolist() if col not in ['age_group']]\ntarget_cols = ['age_group']","9887e4f2":"# Combine oof\noof_paths = ['..\/input\/double-xgboost\/oof_xgb.npy',\n             '..\/input\/xgboost-pca\/oof_xgb.npy',\n             '..\/input\/xgboost-withunnamed-deb\/oof_xgb_8066_8100.npy',\n             '..\/input\/xgboost-withunnamed-nonzerotraining\/oof_xgb.npy',\n             '..\/input\/double-xgboost-manual-tuning\/oof_xgb.npy',\n             '..\/input\/debrf\/oof_rnd.npy',\n             '..\/input\/xgboost-withunnamed\/oof_xgb.npy',\n             '..\/input\/catboost-tuned\/oof_cat.npy',\n             '..\/input\/lightgbm\/oof_lgb.npy', \n             '..\/input\/deb-xgb\/oof_xgb_75143.npy',\n             '..\/input\/randomforest\/oof_rf.npy']\n\npred_paths = ['..\/input\/double-xgboost\/pred_xgb.npy',\n              '..\/input\/xgboost-pca\/pred_xgb.npy',\n              '..\/input\/xgboost-withunnamed-deb\/pred_xgb_8066_8100.npy',\n              '..\/input\/xgboost-withunnamed-nonzerotraining\/pred_xgb.npy',\n              '..\/input\/double-xgboost-manual-tuning\/pred_xgb.npy',\n              '..\/input\/debrf\/pred_rnd.npy',\n              '..\/input\/xgboost-withunnamed\/pred_xgb.npy',\n              '..\/input\/catboost-tuned\/pred_cat.npy', \n              '..\/input\/lightgbm\/pred_lgb.npy', \n              '..\/input\/deb-xgb\/pred_xgb_75143.npy',\n              '..\/input\/randomforest\/pred_rf.npy']\n\n\noof_comp = np.zeros((len(oof_paths), len(train[target_cols]), 4))\npred_comp = np.zeros((len(pred_paths), len(test), 4))\n\nfor i in range(len(oof_paths)):\n    oof_comp[i, :, :] = np.load(oof_paths[i])\n    \nfor i in range(len(pred_paths)):\n    pred_comp[i, :, :] = np.load(pred_paths[i])","94de607c":"import tensorflow as tf\ny_true = (train[target_cols].values).reshape(-1,1)\ny_true_hot = np.array(tf.one_hot(y_true, depth=4)).reshape(-1,4)\n\n\ndef f1score(oof):\n    predictions = oof.argmax(axis=1)\n    return f1_score(train[target_cols], predictions, average='weighted')\n\n# return negative of f1 to minimize\ndef func_numpy_metric(weights):\n    oof_blend = np.tensordot(weights, oof_comp, axes=(0,0))\n    return -f1score(oof_blend)\n\n","3471e781":"%%time\n\nf1_scores = {}\n\nfor i in range(len(oof_paths)):\n    score_oof = f1score(oof_comp[i, ...])\n    f1_scores[oof_paths[i]] = score_oof\n    print(f'{oof_paths[i]} CV:\\t\\t\\t',score_oof)\nprint('-' * 50)","b35a5018":"import scipy\n\ntol = 1e-3\nbnds = [(0, 1) for _ in range(oof_comp.shape[0])]\ninit_guess = [1 \/ oof_comp.shape[0]] * oof_comp.shape[0]\nprint('Inital Blend OOF:', func_numpy_metric(init_guess))\nstart_time = time()\n\nres_scipy = scipy.optimize.differential_evolution(func = func_numpy_metric,\n                                                 bounds=bnds,\n                                                 disp=True, \n                                                 polish=True,\n                                                 tol=tol)\n\nprint(f'[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] Optimised Blend OOF:', res_scipy.fun)\nprint('Optimised Weights:', res_scipy.x)\n\nweights = res_scipy.x","19fdc318":"def blend_preds(weights):\n    for i in range(pred_comp.shape[0]):\n        pred_blend = np.tensordot(weights, pred_comp, axes=(0,0))\n        \n    return pred_blend\n\npred_blend = blend_preds(weights)","aeb7d5f0":"final_preds = pred_blend.argmax(axis=1)+1","0e17e742":"pred_csv = pd.DataFrame(final_preds.reshape(-1), columns=['prediction'] )\npred_csv","df8b7d8d":"pred_csv.value_counts()","c8a4d565":"pred_csv.to_csv('pcawithdeb.csv', index=False)","48d8b24b":"## CV HISTORY - \n\nOOF - 75.59    \nLB - 75.27\n\n######################\n\nOOF - 0.75613   \nLB - 75.308\n\n######################\n\nOOF - 0.7571 \\\nLB - 0.7541\n\n####################\n\nOOF - 0.7579 \\\nLB - 0.7549"}}