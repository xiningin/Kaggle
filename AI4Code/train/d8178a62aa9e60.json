{"cell_type":{"e5addbb6":"code","3c7d9ac7":"code","c91f74fa":"code","b210c968":"code","b17bd634":"code","fdaa0154":"code","05a11785":"code","427b3e4e":"code","929b7d3b":"code","7a7aaae3":"code","e29a6492":"code","1210c6cb":"code","38ceb6d3":"code","9d6ff807":"code","57502677":"code","a464e7b1":"code","31b42f15":"code","23cae2db":"code","8c046a3f":"code","4f37c97a":"code","f314c1d1":"code","5478fa46":"code","4115bf80":"code","5a493e08":"code","01e1e20e":"code","4c242a61":"code","60435098":"code","e4cffa60":"code","048dc82e":"code","489a4040":"markdown","61283644":"markdown","ff1e065f":"markdown","08789a9c":"markdown","163eec2b":"markdown","4fa9b175":"markdown","6543d56f":"markdown","b3588630":"markdown","e2e00316":"markdown","3c942b58":"markdown","032e723a":"markdown","e16a32ad":"markdown"},"source":{"e5addbb6":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os","3c7d9ac7":"path = '\/kaggle\/input\/hackathon'\nfile = f'{path}\/task_1-google_search_manually_reviewed_metadata.csv'\ndf = pd.read_csv(file, encoding = \"ISO-8859-1\")","c91f74fa":"f\"There are {df.shape[0]} manually reviewed texts with metadata\"","b210c968":"df.head()","b17bd634":"df.info()","fdaa0154":"df[df['filename'].isnull()]","05a11785":"df.drop(df[df['filename'].isna()].index, inplace=True)","427b3e4e":"df['language'].value_counts()","929b7d3b":"df['is_pdf'].value_counts()","7a7aaae3":"df['is_translated'].value_counts() # All original","e29a6492":"df['is_downloaded'].value_counts() # All downloaded","1210c6cb":"df['Is Processed'].value_counts()","38ceb6d3":"df['country'].unique().size","9d6ff807":"pd.set_option('display.max_colwidth', None)","57502677":"df[df['Comments'].notna()]['Comments']","a464e7b1":"df['Snippet'].isna().mean()","31b42f15":"df.drop(df[df['Snippet'].isna()].index, inplace=True)","23cae2db":"df['snippet_len'] = df['Snippet'].astype(str).apply(len)","8c046a3f":"df['snippet_len'].hist()","4f37c97a":"def is_snippet_in_text(row):\n    code = row['alpha_2_code']\n    file = row['filename']\n    if not file.endswith('.txt'):\n        file += '.txt'\n    filename=f'{path}\/task_1-google_search_txt_files_v2\/{code}\/{file}'\n    if os.path.isfile(filename):\n        with open(filename, 'r') as file:\n            data = file.read()\n        return row['Snippet'] in data","f314c1d1":"df['snippet_in_text'] = df.apply(is_snippet_in_text, axis=1)","5478fa46":"df['snippet_in_text'].mean()","4115bf80":"def get_content_len(row):\n    code = row['alpha_2_code']\n    file = row['filename']\n    if not file.endswith('.txt'):\n        file += '.txt'\n    filename=f'{path}\/task_1-google_search_txt_files_v2\/{code}\/{file}'\n    if os.path.isfile(filename):\n        with open(filename, 'r') as file:\n            data = file.read()\n        return len(data)\n    else:\n        print(f\"Could not find file {filename} in folder {code}\")","5a493e08":"df['text_len'] = df.apply(get_content_len, axis=1)","01e1e20e":"df[df['text_len'].isna()]","4c242a61":"df.drop(df[df['text_len'].isna()].index, inplace=True)","60435098":"df.shape","e4cffa60":"df.drop(['query','language','is_translated','is_downloaded','char_number','Is Processed'], inplace=True, axis=1)","048dc82e":"df.to_csv('\/kaggle\/working\/manually_reviewed_cleaned.csv', index=False)","489a4040":"We see an issue with two entries, where the filename does not correspond to the alpha_2_code and the country. Those should be ignored.","61283644":"All reviewed texts are in English.","ff1e065f":"Comments are rare and don't seem very useful.","08789a9c":"All texts are originally in English are were downloaded sucessfully.","163eec2b":"Only 37% of snippets actually appear in the text in the respective file. However, manual inspection showed that some snippets appear in the text with slight differences in punctuation or with missing words.","4fa9b175":"34% of entries have no Snippet extracted, which seems weird and those should be ignored.","6543d56f":"### EDA + cleanup","b3588630":"All were processed, whatever that means :)","e2e00316":"Finally, the cleaned file can be modified so that the snippets are split into smaller ones which answer the specific questions required for a submission. Then it can be used as an evaluation dataset for future models.","3c942b58":"# Motivation\nThe purpose of this notebook is to analyse the metadata for some manually reviewed texts provided by the organizers.","032e723a":"We don't have a corresponding text file for those sources.","e16a32ad":"No information about query and char_number."}}