{"cell_type":{"cc5802fe":"code","ab1e268a":"code","a4fa3a09":"code","2609efb5":"code","9d168561":"code","054c279f":"code","78a2b6d7":"code","c0737928":"code","a31f66b4":"code","ec2a2794":"code","8de410ec":"code","2d49cf31":"code","7bda405a":"code","702d77e4":"code","ee89dfa0":"code","0077db5b":"code","3172062d":"code","eaca5c69":"code","8f329b15":"code","4c0ef3f0":"code","b7bb42f5":"code","651d0925":"code","6ed7c00e":"code","9e922d4c":"markdown","f5a75578":"markdown","d138b1e9":"markdown","74bdf8d8":"markdown","21c8ffae":"markdown","a9c8f59a":"markdown","36c279d0":"markdown","59afd585":"markdown","a7ae1384":"markdown","3bf173bd":"markdown"},"source":{"cc5802fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab1e268a":"maindir = \"..\/input\/vehicle-detection-image-set\/data\"\nos.listdir(maindir)","a4fa3a09":"vehicle_dir = \"..\/input\/vehicle-detection-image-set\/data\/vehicles\"\nnonvehicle_dir = \"..\/input\/vehicle-detection-image-set\/data\/non-vehicles\"\nvehicle = os.listdir(maindir+\"\/vehicles\")\nnon_vehicle = os.listdir(maindir+\"\/non-vehicles\")\n\nprint(f\"Number of Vehicle Images: {len(vehicle)}\")\nprint(f\"Number of Non Vehicle Images: {len(non_vehicle)}\")","2609efb5":"plt.figure(figsize=(12,9))\nimport cv2\nvehicle_img = np.random.choice(vehicle,5)\nnonvehicle_img = np.random.choice(non_vehicle,5)\nfor i in range(5):\n    plt.subplot(1,5,i+1)\n    img = cv2.imread(vehicle_dir+'\/'+vehicle_img[i])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.xlabel(\"Vehicle\")\n    #plt.axis(\"off\")\n    plt.tight_layout()\n    plt.imshow(img)\nplt.show()\nplt.figure(figsize=(12,9)) \nfor i in range(5):\n    plt.subplot(1,5,i+1)\n    img = cv2.imread(nonvehicle_dir+'\/'+nonvehicle_img[i])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.xlabel(\"Non Vehicle\")\n    #plt.axis(\"off\")\n    plt.imshow(img)\nplt.tight_layout()\nplt.show()","9d168561":"train = []\nlabel = []\nimport tqdm\nfrom tensorflow.keras.preprocessing import image\n\nfor i in tqdm.tqdm(vehicle):\n    img = cv2.imread(vehicle_dir+'\/'+ i)\n    img = cv2.resize(img,(150,150))\n    train.append(img)\n    label.append(\"Vehicle\")\n    \nfor i in tqdm.tqdm(non_vehicle):\n    img = cv2.imread(nonvehicle_dir+'\/'+ i)\n    img = cv2.resize(img,(150,150))\n    train.append(img)\n    label.append(\"Non Vehicle\")","054c279f":"train = np.array(train)\nlabel = np.array(label)\ntrain.shape,label.shape","78a2b6d7":"import seaborn as sns\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(12,5))\nsns.countplot(x = label)\nplt.show()","c0737928":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import shuffle\nle = LabelEncoder()\nlabel= le.fit_transform(label)","a31f66b4":"label","ec2a2794":"label = to_categorical(label)\nprint(label.shape)\ntrain,label = shuffle(train, label)","8de410ec":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(train,label,test_size=0.2,random_state = 42)","2d49cf31":"from tensorflow.keras.applications import EfficientNetB0\neffnet = EfficientNetB0(weights = \"imagenet\",include_top = False,input_shape=(150,150,3))","7bda405a":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten,Dense,Conv2D, MaxPooling2D,GlobalAveragePooling2D,Dropout\nmodel = effnet.output\nmodel = GlobalAveragePooling2D()(model)\nmodel = Dropout(0.5)(model)\nmodel = Dense(2,activation='softmax')(model)\n\nmodel = Model(inputs = effnet.input, outputs = model)","702d77e4":"model.compile(optimizer =\"adam\", loss = \"categorical_crossentropy\",metrics = ['accuracy'])","ee89dfa0":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"vehicle.h5\",monitor = \"val_accuracy\",save_best_only = True, \n                             mode='auto',verbose=1)\nearlystop = EarlyStopping(monitor = \"val_accuracy\", patience = 5,mode='auto',verbose=1)\nreducelr = ReduceLROnPlateau(monitor = \"val_accuracy\",factor = 0.3, patience = 3,\n                            min_delta = 0.001,mode = 'auto',verbose=1)","0077db5b":"history  = model.fit(x_train,y_train, epochs = 10,batch_size=32, validation_data = (x_test,y_test),\n                    verbose = 1, callbacks = [checkpoint, earlystop,reducelr])","3172062d":"model.evaluate(x_test,y_test)","eaca5c69":"y_pred = model.predict(x_test)\ny_pred = np.argmax(y_pred,axis=1)\ny_pred[:15]","8f329b15":"y_test = np.argmax(y_test,axis=1)\ny_test[:15]","4c0ef3f0":"from sklearn.metrics import accuracy_score, classification_report\nprint(classification_report(y_test,y_pred))","b7bb42f5":"from sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(conf_mat = cm,figsize=(8,7),class_names =['Non Vehicles', 'Vehicles'],\n                     show_normed = True)","651d0925":"plt.figure(figsize = (12,6))\nepochs = range(1,11)\nplt.subplot(1,2,1)\nplt.plot(epochs,history.history['accuracy'],'go--')\nplt.plot(epochs,history.history['val_accuracy'],'ro--')\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend(['Train', 'Val'],loc ='upper left')\n\nplt.subplot(1,2,2)\nplt.plot(epochs,history.history['loss'],'go--')\nplt.plot(epochs,history.history['val_loss'],'ro--')\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend(['Train', 'Val'],loc ='upper left')\nplt.show()","6ed7c00e":"plt.figure(figsize=(12,9))\nfor i in range(10):\n    sample_idx = np.random.choice(range(len(x_test)))\n    plt.subplot(2,5,i+1)\n    plt.imshow(x_test[sample_idx])\n    plt.xlabel(f\"Actual: {y_test[sample_idx]}\\n Predicted: {y_pred[sample_idx]}\")\n    \nplt.tight_layout()\nplt.show()","9e922d4c":"> Converting Images into Array:","f5a75578":"> Actual vs Predicted Result:","d138b1e9":"> Learning Curve:","74bdf8d8":"> Classification Report:","21c8ffae":"> I'm going to use EfficientNetB0 model. So let's import the model:","a9c8f59a":"- We can see that our data set is balanced. That's good for building a classification model.","36c279d0":"> Confusion Matrix:","59afd585":"> Splitting our Dataset into Train & Test set","a7ae1384":"> Sample of Train Images:","3bf173bd":"> Model Building & Training:"}}