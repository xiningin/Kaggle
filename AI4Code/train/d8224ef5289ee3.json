{"cell_type":{"644cb51d":"code","6ffdc19a":"code","87ce3c08":"code","ef4a644c":"code","2425bb57":"code","c26cdeae":"code","a0ff4f97":"code","0b2b3db1":"code","41687560":"code","ee8bef6b":"code","740c4e88":"code","e01414f4":"code","d0e01b69":"code","4044a07f":"code","78781965":"code","cb4da94d":"code","880752bd":"code","0da41994":"code","350b3742":"code","a563955d":"code","bb5a9ca2":"code","d2669896":"code","02cce3b6":"code","f4225c07":"code","a21e5289":"code","1e02d733":"code","31d1a2a6":"code","93b98230":"code","be3b8f0d":"code","5206b1ad":"code","4fae7491":"code","67b96ebf":"code","476072d3":"code","09fec4ba":"code","7e178cff":"code","81f6de94":"code","2f03bcb1":"code","acb8e1e1":"markdown","72be8e8c":"markdown","d22882ea":"markdown","c586e5ad":"markdown","7952feee":"markdown","af62e91a":"markdown","a08aa74b":"markdown","6a15c2b6":"markdown","9a3c1240":"markdown","6f220b8a":"markdown","5c81697e":"markdown","ff2c0032":"markdown","83b2b991":"markdown","b7c9d670":"markdown","944f7c20":"markdown","3990b32e":"markdown","0b206de3":"markdown","39029c01":"markdown","0775955b":"markdown","c3524897":"markdown","b59f1657":"markdown","7ab0e171":"markdown","f4099a48":"markdown","214b238e":"markdown","4adc7476":"markdown","14c6712e":"markdown","f0ef7571":"markdown","3db109f9":"markdown","8ac5c6d5":"markdown","a82865d6":"markdown","e3bbbe0c":"markdown","1d083d31":"markdown","872499d2":"markdown"},"source":{"644cb51d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.style.use('fivethirtyeight')\nfrom time import time\n%matplotlib inline\nimport seaborn as sns\nimport plotly.graph_objs as go \nfrom plotly.offline import init_notebook_mode,iplot,plot\ninit_notebook_mode(connected=True)\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE","6ffdc19a":"ctr = pd.read_csv(r\"..\/input\/olympic-games\/countries.csv\", encoding='utf-8')\ndf = pd.read_csv(r\"..\/input\/olympic-games\/athletes.csv\", encoding='utf-8', decimal='.', parse_dates=['dob'], index_col=0).dropna()\ndf.head()","87ce3c08":"df.info()","ef4a644c":"df.describe(include='all')","2425bb57":"df['Age'] = round(((pd.to_datetime('today') - df['dob']).dt.days) \/ 365 , 0)\ndf['Age'].hist()","c26cdeae":"df[df['Age'] < 0].head()","a0ff4f97":"df['Age'] = np.where(df['Age'] < 0, df['Age'] + 100, df['Age'])\ndf['Age'].hist(bins=20)","0b2b3db1":"df['medal'] = np.where(df['gold'] + df['silver'] + df['bronze'] > 0, 1, 0)","41687560":"cont = pd.read_excel(r'..\/input\/rio2016\/continents.xlsx')\ncont.head()","ee8bef6b":"ctr = ctr.merge(cont[['continent', 'name']],\n                left_on='country',\n                right_on='name',\n                how='left')\nctr.head()","740c4e88":"ctr[ctr['continent'].isna()==True]","e01414f4":"ctr.loc[40, 'continent'] = 'Asia'    # China\nctr.loc[43, 'continent'] = 'Africa'  # Congo\nctr.loc[47, 'continent'] = 'Africa'  # Cote d'Ivoire\nctr.loc[81, 'continent'] = 'Asia'    # Hong Kong\nctr.loc[88, 'continent'] = 'Europe'  # Ireland\nctr.loc[96, 'continent'] = 'Asia'    # South Korea\nctr.loc[129, 'continent'] = 'Europe' # Netherlands","d0e01b69":"df['nationality'].value_counts().head()","4044a07f":"df = df.merge(ctr[['code', 'continent', 'population', 'gdp_per_capita']],\n              left_on='nationality',\n              right_on='code',\n              how='left')","78781965":"ioc = pd.read_excel(r'..\/input\/rio2016\/IOC_joining.xlsx')\nioc.head()","cb4da94d":"df = df.merge(ioc[['code', 'IOC_year']],\n              on='code',\n              how='left')\ndf['IOC_seniority'] = 2019 - df['IOC_year']\ndf.head()","880752bd":"df = pd.concat([df,\n                pd.get_dummies(df['sex'], drop_first=False),\n                pd.get_dummies(df['continent'], drop_first=False)], axis=1)\ndf.head()","0da41994":"df2 = df.drop(['name', 'dob', 'sex', 'sport', 'continent', 'nationality',\n               'code', 'IOC_year', 'gold', 'silver', 'bronze'], axis=1).dropna()\ndf2.columns","350b3742":"plt.figure(figsize=(8, 8), facecolor='w', edgecolor='k')\nsns.scatterplot(x='height', y='weight', data=df, hue='medal')","a563955d":"plt.figure(figsize=(10, 8), facecolor='w', edgecolor='k')\nsns.boxplot(x='sex', y='Age', data=df, hue='medal')","bb5a9ca2":"plt.figure(figsize=(15, 8), facecolor='w', edgecolor='k')\nsns.violinplot(x='continent', y='gdp_per_capita', data=df, hue='medal', split=True)","d2669896":"plt.figure(figsize=(8, 8), facecolor='w', edgecolor='k')\nsns.jointplot(x='IOC_seniority', y='gdp_per_capita', data=df2)","02cce3b6":"plt.figure(figsize=(6, 6))\ncorr_matrix2 = round(df2[['medal', 'height', 'weight', 'population', 'gdp_per_capita',\n                          'Age', 'IOC_seniority']].corr(), 2)\nmask = np.zeros_like(corr_matrix2, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nplt.title('Correlation heatmap')\nsns.heatmap(corr_matrix2, center=0, vmin=-1, vmax=1, annot=True, cmap=\"RdBu_r\", mask=mask)","f4225c07":"# 1. Scale data\nscaler = StandardScaler()\nscaled = scaler.fit_transform(df2.drop(['medal', 'weight'], axis=1))\ncols = df2.drop(['medal', 'weight'], axis=1).columns\n\n# 2. Divide into X and y sets\nX = pd.DataFrame(scaled, columns=cols)\ny = df2['medal']\n\n# 3. Resample data \nRUS = RandomUnderSampler(random_state=765, sampling_strategy=0.75) # because first Olympics are dated to 765 BC\nX_res, y_res = RUS.fit_resample(X, y)\nX2 = pd.DataFrame(X_res, columns=X.columns)\ny2 = y_res\n\n# 4. Divide into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.30, random_state=765)","a21e5289":"model = SVC()\n\nparam_grid = {'C': [0.1,1, 10, 100, 1000, 10000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n              'kernel': ['rbf']} \n\ngrid = GridSearchCV(estimator = SVC(), param_grid = param_grid, refit=True, verbose=2,\n                    scoring='precision', n_jobs=4, iid=False, cv=5)\ngrid.fit(X_train, y_train)","1e02d733":"print(grid.best_params_)\nprint(grid.best_estimator_)","31d1a2a6":"y_pred = grid.best_estimator_.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification stats:\\n\", classification_report(y_test, y_pred))","93b98230":"GBC = GradientBoostingClassifier(verbose=0)\n\nparam_grid_2 = {'n_estimators': range(50, 100, 10),\n               'max_depth': [3, 4, 5, 6],\n               'min_samples_split': range(30, 60, 10), \n               'min_samples_leaf': range(20, 50, 10)}\n\ngrid_2 = GridSearchCV(estimator = GBC, refit=True, verbose=2,\n                      param_grid = param_grid_2,\n                      scoring='precision', n_jobs=4, iid=False, cv=5)\n\ngrid_2.fit(X_train, y_train)","be3b8f0d":"print(grid_2.best_params_)\nprint(grid_2.best_score_)","5206b1ad":"y_pred2 = grid_2.best_estimator_.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred2))\nprint(\"\\nClassification stats:\\n\", classification_report(y_test, y_pred2))","4fae7491":"def report_top_feat(data_set, features, top = 15):\n    indices = np.argsort(features)[::-1]\n    for f in range(top):\n        print(\"%d. %s (%f)\" % (f + 1, data_set.columns[indices[f]], features[indices[f]]))\n    \n    indices=indices[:top]\n    plt.figure(figsize=[8, 6])\n    plt.title(\"Top features for scoring a medal\")\n    plt.bar(range(top), features[indices], color=\"r\", align=\"center\")\n    plt.xticks(range(top), data_set.columns[indices], fontsize=14, rotation=90)\n    plt.xlim([-1, top])\n#     plt.savefig(\"Top %d Feature importances for %s.png\" % (top, c))\n    plt.show()\n    print(\"Mean Feature Importance %.6f\" %np.mean(features), '\\n')\n\n\nfeatures = grid_2.best_estimator_.feature_importances_\nreport_top_feat(X_test, features, X_test.columns.size)","67b96ebf":"sm = SMOTE(random_state=765, sampling_strategy='minority')\nX_res, y_res = sm.fit_resample(X, y)\nX2 = pd.DataFrame(X_res, columns=X_train.columns)\ny2 = y_res\n\nX_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.30, random_state=765)","476072d3":"X2.shape, X_train.shape","09fec4ba":"GBC_2 = GradientBoostingClassifier(verbose=0)\n\nparam_grid_3 = {'n_estimators': range(50, 100, 10),\n               'max_depth': [3, 4, 5, 6],\n               'min_samples_split': range(30, 60, 10), \n               'min_samples_leaf': range(20, 50, 10)}\n\ngrid_3 = GridSearchCV(estimator = GBC_2, refit=True, verbose=2,\n                      param_grid = param_grid_3,\n                      scoring='precision', n_jobs=4, iid=False, cv=5)\n\ngrid_3.fit(X_train, y_train)","7e178cff":"print(grid_3.best_params_)\nprint(grid_3.best_score_)","81f6de94":"y_pred3 = grid_3.best_estimator_.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred3))\nprint(\"\\nClassification stats:\\n\", classification_report(y_test, y_pred3))","2f03bcb1":"features = grid_3.best_estimator_.feature_importances_\nreport_top_feat(X_test, features, X_test.columns.size)","acb8e1e1":"Calculate seniority of countries in the IOC, which was founded in 1894. ","72be8e8c":"### Distributions","d22882ea":"### Country - continent\nThere is too many categories in the nationality column, so I will grouby them by continents. To group countries by continents I will need to map them. List of countries with continents: https:\/\/gist.github.com\/mlisovyi\/e8df5c907a8250e14cc1e5933ed53ffd","c586e5ad":"## Exploratory Analysis","7952feee":"Let's drop encoded categorical columns and the rest which is unnecessary.","af62e91a":"This beautifully named violin plot shows that most of medals (red peaks) gain countries with high GDP per capita in North America and Oceania, a little lower in Europe and rather low in Africa, Asia and South America. This dependence is not suprising nor informative, as it generally presents GDP per capita distribution among continents. ","a08aa74b":"# 3. Model: Gradient Boosting Classifier with over-sampling\n\nLet's try the same model just using different resampling method.","6a15c2b6":"### Correlation heatmap.","9a3c1240":"- 70% is better. Now let's inspect what are the most impactful features.","6f220b8a":"### Preparing final dataset\nEncoding categorical variables with [one-hot encoding](https:\/\/hackernoon.com\/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f).","5c81697e":"# 2. Model: Gradient Boosting Classifier\n\nI will procede on the same train and test datasets as above.","ff2c0032":"Let's find best parameters of SVM and fit model.","83b2b991":"Looks correct now.","b7c9d670":"Join information about countries to athlete data frame.","944f7c20":"The aim of this project is to predict winning a medal on 2016 Rio de Janeiro Olympic Games.\n\nThis project was done for \"Economics in sport\" course on SGH Warsaw School of Economics.","3990b32e":"## Prepare features\n### Age\nTransform date of birth to age in years and display histogram.","0b206de3":"## Import packages","39029c01":"This model shows Age as the most important feature, which is interesting but I leave it to another analysis to inspect why is that. ","0775955b":"Looks that in some cases date of birth is wrongly read from csv by pandas (like it was year 2050+). Quick internet research confirms that eg. **Abdelkebir Ouaddar** was born in 1962 instead of 2062. Let's fix this mistake for all athlete's.","c3524897":"Join 'continents' and 'countries' data frames. ","b59f1657":"## 0. Get data ready\n\nImport data and drop NA's, because I don't want to play in imputation of missing data this time.","7ab0e171":"- 65% accuracy is not bad, but let's try do better with another model","f4099a48":"Let's check if there aren't too many NaN and correct the most significant manually.","214b238e":"# 1. Model: Support Vector Classifier","4adc7476":"- 87% is way better! ","14c6712e":"Correlation heatmap confirms what was presented in the distributions above. Height is clearly correlated with weight. For further usage in modelling one of them should be removed. Also gdp_per_capita is quite correlated with IOC_seniority, but it is less than 70% so I think I will keep them both.","f0ef7571":"- Predict values for test set","3db109f9":"I will correct only few of these countries, as most of them don't win any medals at the Olympics","8ac5c6d5":"### Medal - target variable\nI will add information whether athlete won any medals or not, no matter what colour the medal was. This is going to be my binary target variable.","a82865d6":"Interesting but intuitive - big and rich countries have more medal winners than the poor ones. Out of features related to athlete himself height and Age are quite important, which is also reasonable. ","e3bbbe0c":"### Get some outlook on the dataset.","1d083d31":"### IOC joining date\nImport date of joining IOC (International Olimpic Committee) by each country - from Wikipedia.","872499d2":"In order to reach best result I will scale data and resample them using under-sampling to get similar number of 0 and 1 in target 'medal' column. Then I will divide dataset into train and test sets.\n- approach: [Under-sampling](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.under_sampling.RandomUnderSampler.html) "}}