{"cell_type":{"1f8e6c8e":"code","ac1445de":"code","7a3d574e":"code","249d7176":"code","dd2d1433":"code","cef2d6b8":"code","fcad867e":"code","8ade48a8":"code","fc97f126":"code","ef8eda3b":"code","cddabf76":"code","968eee90":"code","5186b2de":"code","83aa1dd0":"code","a17609ab":"markdown","03c74e83":"markdown","8ed40b6f":"markdown","52113857":"markdown","49762dc5":"markdown","d5244250":"markdown","178df581":"markdown","695e8c44":"markdown","b3515a5e":"markdown","1805831b":"markdown","c692526a":"markdown","583cbeec":"markdown"},"source":{"1f8e6c8e":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport matplotlib\nmatplotlib.rcParams['mathtext.fontset'] = 'stix'\nmatplotlib.rcParams['font.family'] = 'sans-serif'\nmatplotlib.rcParams['font.size'] = 10\n\nfrom scipy.io import loadmat\nfrom scipy.signal import stft\nfrom scipy.stats import kurtosis\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.utils import *","ac1445de":"def plotConfusionMatrix(dtrue,dpred,classes,\\\n                        cmap = plt.cm.Blues,bsize = 1.0):\n  \n    cm = confusion_matrix(dtrue,dpred,normalize = 'true')\n  \n    fig,ax = plt.subplots(figsize = (np.shape(classes)[0] * 1.25 * bsize,\\\n                                     np.shape(classes)[0] * 1.25 * bsize))\n    \n    im = ax.imshow(cm,interpolation = 'nearest',cmap = cmap)\n  \n    ax.set(xticks = np.arange(cm.shape[1]),\\\n           yticks = np.arange(cm.shape[0]),\\\n           xticklabels = classes,\\\n           yticklabels = classes,\\\n           ylabel = 'True Efficiency',\\\n           xlabel = 'Predicted Efficiency')\n  \n    plt.setp(ax.get_xticklabels(),rotation = 90,ha = 'right',\\\n             rotation_mode = 'anchor')\n\n    fmt = '.2f'\n\n    thresh = cm.max() \/ 2.0\n  \n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j,i,format(cm[i,j],fmt),ha = 'center',va = 'center',\\\n                    color = 'white' if cm[i,j] > thresh else 'black')\n      \n    fig.tight_layout()\n  \n    return ax","7a3d574e":"fname = !ls '..\/input\/wind-turbine-high-speed-bearing-prognosis-data\/data'\nfname = np.asarray(fname)\n\ndf = []\n\nfor i in fname:\n    df.append(loadmat('..\/input\/wind-turbine-high-speed-bearing-prognosis-data\/data\/' + i)['vibration'].flatten())\n    \ndf = np.asarray(df)\nfs = int(df.shape[1] \/ 6.0)\nt = np.linspace(0.0,6.0,df.shape[1])\n\nprint('Scan frequency: {:,d} Hz'.format(fs))","249d7176":"plt.subplots(figsize = (12.0,6.0))\nfor i in range(df.shape[0]):\n    plt.plot(t + i * 6.0,df[i],color = 'black',lw = 0.25)\n\nplt.xlabel('Time (in s): sample = 50 days in total, 6 seconds per day')\nplt.ylabel('Acceleration (in g)')    \nplt.show()","dd2d1433":"f = []\nfft = []\n\nwnd = 127\n\nfor i in range(df.shape[0]):\n    u,v,w = stft(df[i],fs,nperseg = wnd,noverlap = int(0.8 * wnd),nfft = int(2.0 * wnd))\n    f.append(u)\n    fft.append(kurtosis(np.abs(w),fisher = False,axis = 1))\n\nf = np.asarray(f)\nfft = np.asarray(fft)\n\nfftn = (fft - fft.min()) \/ (fft.max() - fft.min())\n\nfftn = np.asarray(fftn)\nn = np.ones_like(f[0])","cef2d6b8":"fig = plt.figure(figsize = (10.0,10.0))\nax = plt.axes(projection = '3d')\nax.view_init(30,225)\nfor i in range(f.shape[0]):\n    ax.plot(f[i] \/ 1.0e3,i * n,fftn[i],color = 'black',linewidth = 0.50)\n\nax.set_xlabel('Frequency (kHz)')\nax.set_ylabel('Sample')\nax.set_zlabel('Kurtosis')\nplt.show()","fcad867e":"X = fftn\nX = X.reshape(-1,f.shape[1],1)\ny = np.zeros(X.shape[0],dtype = int)\ny[-15:] = 1\n\nprint('Input shape: {:d} samples x {:d} registers\/sample'.format(X.shape[0],X.shape[1]))\n\nlabel = to_categorical(y)","8ade48a8":"mdl = Sequential()\nmdl.add(Conv1D(100,6,activation = 'relu',\\\n               input_shape = (f.shape[1],1)))\nmdl.add(Conv1D(100,6,activation = 'relu'))\nmdl.add(MaxPooling1D(3))\nmdl.add(Conv1D(160,6,activation = 'relu'))\nmdl.add(Conv1D(160,6,activation = 'relu'))\nmdl.add(GlobalAveragePooling1D())\nmdl.add(Dropout(0.5))\nmdl.add(Dense(2,activation = 'softmax'))\n\nprint(mdl.summary())","fc97f126":"mdl.compile(loss = 'categorical_crossentropy',\\\n            optimizer = 'adam',metrics = ['accuracy'])","ef8eda3b":"batch,epoch = 32,1000\ncw = {0: 5.0,1:75.0}\n\nXtrain,Xtest,ytrain,ytest = train_test_split(X,label,\\\n                                             random_state = 21,\\\n                                             test_size = 0.50)\n\nhist = mdl.fit(Xtrain,ytrain,batch_size = batch,\\\n               epochs = epoch,validation_split = 0.2,verbose = 0,\\\n               class_weight = cw)","cddabf76":"plt.subplots(1,2,figsize = (9.0,4.5),sharex = True)\nplt.subplot(1,2,1)\nplt.plot(hist.epoch,hist.history['accuracy'],\\\n         color = 'black',lw = 2.50)\nplt.ylabel('1D-CNN Accuracy')\nplt.xlabel('Epoch')\nplt.subplot(1,2,2)\nplt.plot(hist.epoch,hist.history['loss'],\\\n         color = 'black',lw = 2.50)\nplt.ylabel('1D-CNN Loss')\nplt.xlabel('Epoch')\nplt.tight_layout()\nplt.show()","968eee90":"print(mdl.evaluate(Xtest,ytest,verbose = 2))","5186b2de":"print(classification_report(np.where(ytest != 0)[1],\\\n                            mdl.predict_classes(Xtest)))","83aa1dd0":"plotConfusionMatrix(np.argmax(ytest,axis = 1),\\\n                    np.argmax(mdl.predict(Xtest),axis = 1),\\\n                    ['medium','short'],\\\n                    bsize = 1.75,cmap = 'binary')\nplt.title('Accuracy (RECALL)')\nplt.show()","a17609ab":"The model is trained over 50% of the samples &mdash; it is important to note that the data-set is very restrict, with just 50 samples, despite the amount of records per sample.\n\nThe training is based on 1,000 epochs &mdash; it is required to allow the model to have a good convergenge.\n\nA **cost-matrix** (variable ``cw``) is used to influence the classification result and to avoid errors associated to a misclassification associated to the **Short-life Expectancy class** &mdash; it is always preferable to classify a **medium-life** into a **short-life** and let the decision to a maintenance expert than to misclassify a **short-life** and risk a breakdown.","03c74e83":"As mentioned in the introduction, the data-base is accesible in the link https:\/\/www.kaggle.com\/luishpinto\/wind-turbine-high-speed-bearing-prognosis-data. The registers will be loaded in the ``df`` variable, according to the following command lines.\n\nThe **scan-frequency** is 97,656 Hz, and the **recording-period** is 6 seconds as previously commented.","8ed40b6f":"Despite the visible variation in the acceleration, the **number of recorded data** (6 x 97,656 = 585,936 registers per day; 29,286,800 in total), summed to the **asynchronous** condition of measurement make unfeasible the use of **conventional neural networks** do classify the bearing condition. The problem requires a different approach to transform a **sinusoidal time-domain variable** into a **non-cycling frequency-domain variable**, making possible to distinguish between the **RUL classes**.\n\nThis new variable is the **Kurtosis** computed over a **Short-Time Fourier Transform (window = 127)** shown in the 3D-chart below depicted. As can be noted, under normal condition the **Kurtosis** is very stable and follows a flat-pattern regardless the frequency (f.ex. the first five samples), but tends to increase when abnormal running-conditions cause deviations respect to a normal-distribution of the data.","52113857":"\nA more visual format of the **recall** parameter is shown throught the **Confusion Matrix** below depicted.","49762dc5":"The **Classification Report** shows the details about **precision**, **recall** and **f1-score** for each class, including the overall performance of the model.","d5244250":"The **overall-accuracy** based on the **recall** of the model is near to 90%.","178df581":"The **accuracy** and the **loss** historic are depicted in the next chart. A near-ONE accuracy is a very good convergence condition.","695e8c44":"The **1D-CNN** is defined by using the ``Sequential()`` function from the **Keras Open-Source Library**, and the summary is below depicted.","b3515a5e":"# Wind Turbine High Speed Bearing Prognosis\n\n![](https:\/\/advcloudfiles.advantech.com\/cms\/54cb3228-26c4-4db8-976e-89943507084c\/Content\/content-image-1540274502529.jpg)\n\nThis **notebook** shows a new approach to the use of **raw-data** from **vibration monitoring sensors** in the prognosis of **RUL &mdash; Remaining-Useful-Life** of bearings (and also other types of machine elements like gears, couplings, etc.).\n\nThe data used in the example were recorded by a field-sensor installed in a **high-speed bearing** of a remote **wind-turbine**. The bearing is part of the **gear-box** responsible for the coupling between the **rotor** and the **electrical-generator**, specifically on the **high-speed shaft** (i.e. generator-side). A copy of the data-base can be accessed through the link https:\/\/www.kaggle.com\/luishpinto\/wind-turbine-high-speed-bearing-prognosis-data. The recorded variable is the **acceleration** (in g) measured by the sensor during 30 days, 6 seconds per day.\n\n## Prognosis Based on Kurtosis Spectogram and CNN\n\nThe technical approach is based on the computation of a **Kurtosis Spectogram** for each of the 50 samples and the use of a **1D-CNN &mdash; One-Dimensional Convolutional Neural Network** to classify each sample in two **RUL** classes:\n\n* **Medium-life Expectancy Class** representing bearings with life-expectancy greater than 15 days (good condition);\n* **Short-life Expectancy Class** representing bearings with life-expectanncy smaller than 15 days (bad condition).\n\nBased on this assumption, the last 15 registers are labeled as **Short-life class**, and all the remaining registers as **Medium-life class**.\n\n## Keras and the CNN\n\n**Keras Open-Source Library** was used to model the **1D-CNN**.\n","1805831b":"The following chart shows the **acceleration measurements** (in g) &mdash; as can be noted, the only explicit dimension that varies according to the time-domain is the **amplitude** of the acceleration.","c692526a":"## Summary\n\nThe **1D-CNN** associated to the **Kurtosis Spectogram** shows to be a very impressive solution to the correct estimation of the **Remaining-Useful Life** of bearings based on **acceleration** data. The solution can be implemented in **alert-systems** as a support to technical decisions on **stoping and fix** or **keep-running** the component.","583cbeec":"The **Kurtosis** is used as input for the **1D-CNN** (variable ``X``) and the labels associated to the two **RUL** classes are defined throught the variable ``y`` &mdash; **Medium-life Expectancy Class (y = 0)** for the first 35 samples, and **Short-life Expectancy Class (y = 1)** for the last 15 samples. ``y`` is transformed to a **categorical** format in order to fit to the neural-network output format."}}