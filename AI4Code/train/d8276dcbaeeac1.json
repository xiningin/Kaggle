{"cell_type":{"7976cd0c":"code","b58ae61a":"code","128f493c":"code","790d90fd":"code","6251332b":"code","797e8795":"code","94fe7eeb":"code","85768e69":"code","56af69a1":"code","2e1fdbcf":"code","032ae304":"code","6d8ec0e2":"code","7739abe0":"code","3444eec8":"code","b23e2d6e":"code","a5f829f3":"code","6ba64850":"code","b9e1e4bc":"code","dcb13474":"code","ec25a794":"code","a27502a2":"code","f4e87b91":"code","9a5b3fb0":"code","9492c915":"code","3b3bdbea":"code","e0e6c564":"code","441b96bf":"code","ed5990e5":"code","11fd749c":"code","19f67fc2":"code","f9736c97":"code","b51988f7":"code","441b2d7e":"code","8812b25a":"code","bf63c437":"code","705d87cd":"code","5ef39968":"code","7d043e88":"markdown","884eb8b7":"markdown","bb8d55e2":"markdown","9bf8f314":"markdown","67b388ed":"markdown","dd2bbc93":"markdown","5b8c0ecf":"markdown","f1b885c3":"markdown","68b122fd":"markdown","d90578b0":"markdown","85036f31":"markdown","9d599216":"markdown","bb9000f2":"markdown","3ec9fb5b":"markdown","faf76eaa":"markdown","18b62ce2":"markdown","bd8fb0dc":"markdown","ed2b4c6e":"markdown","bd1f2e85":"markdown","7aeca340":"markdown"},"source":{"7976cd0c":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b58ae61a":"train = pd.read_csv('..\/input\/cat-in-the-dat\/train.csv', index_col='id')\ntest = pd.read_csv('..\/input\/cat-in-the-dat\/test.csv', index_col='id')","128f493c":"train = train.drop('bin_0', axis=1)\ntest = test.drop('bin_0', axis=1)","790d90fd":"map_bin_3_4 = {'T': 1, 'F': 0, 'Y': 1, 'N': 0}\n\ntrain['bin_3'] = train['bin_3'].map(map_bin_3_4)\ntest['bin_3'] = test['bin_3'].map(map_bin_3_4)\n\ntrain['bin_4'] = train['bin_4'].map(map_bin_3_4)\ntest['bin_4'] = test['bin_4'].map(map_bin_3_4)","6251332b":"train['ord_5_1'] = train['ord_5'].str[0]\ntrain['ord_5_2'] = train['ord_5'].str[1]\ntrain = train.drop('ord_5', axis=1)\n\ntest['ord_5_1'] = test['ord_5'].str[0]\ntest['ord_5_2'] = test['ord_5'].str[1]\ntest = test.drop('ord_5', axis=1)","797e8795":"train = train.drop('ord_5_2', axis=1)\ntest = test.drop('ord_5_2', axis=1)","94fe7eeb":"ord_1_values = ['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster']\n\nmap_ord_1 = lambda x: ord_1_values.index(x)\n\ntrain['ord_1'] = train['ord_1'].apply(map_ord_1)\ntest['ord_1'] = test['ord_1'].apply(map_ord_1)","85768e69":"ord_2_values = ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot']\n\nmap_ord_2 = lambda x: ord_2_values.index(x)\n\ntrain['ord_2'] = train['ord_2'].apply(map_ord_2)\ntest['ord_2'] = test['ord_2'].apply(map_ord_2)","56af69a1":"import string\n\n\nmap_to_ascii_index = lambda x: string.ascii_letters.index(x)\n\n# 'ord_5_2' dropped!\nfor column in ['ord_3', 'ord_4', 'ord_5_1']:\n    train[column] = train[column].apply(map_to_ascii_index)\n    test[column] = test[column].apply(map_to_ascii_index)","2e1fdbcf":"# columns_to_test = list(test.columns)\n\ncolumns_to_test = ['nom_7', 'nom_8', 'nom_9']\n\nreplace_xor = lambda x: 'xor' if x in xor_values else x\n\nfor column in columns_to_test:\n    xor_values = set(train[column].unique()) ^ set(test[column].unique())\n    if xor_values:\n        print('Column', column, 'has', len(xor_values), 'XOR values')\n        train[column] = train[column].apply(replace_xor)\n        test[column] = test[column].apply(replace_xor)\n    else:\n        print('Column', column, 'has no XOR values')","032ae304":"def get_infrequent_values(data, column, threshold):\n    value_counts = data[column].value_counts()\n    return list(value_counts[value_counts < threshold].index)","6d8ec0e2":"for column in train.columns:\n    n = len(get_infrequent_values(train, column, 3))\n    if n > 0:\n        print('Column', column, 'has', n, 'unique infrequent value(s)')","7739abe0":"thresholds = {\n    # 'nom_7': 3,\n    # 'nom_8': 3,\n    'nom_9': 3\n}\n\nfor column in thresholds.keys():\n    values_to_replace = get_infrequent_values(train, column, thresholds[column])\n    \n    replace = lambda x: 'value' if x in values_to_replace else x\n    \n    train[column] = train[column].transform(replace)\n    test[column] = test[column].transform(replace)","3444eec8":"for column in thresholds.keys():\n    print(column, ':', train[column].value_counts()['value'], 'values replaced in train dataset')","b23e2d6e":"day_map = {\n    1: 3,\n    2: 2,\n    3: 1,\n    4: 0,\n    5: 1,\n    6: 2,\n    7: 3\n}\n\ntrain['day'] = train['day'].map(day_map)\ntest['day'] = test['day'].map(day_map)","a5f829f3":"features_to_drop_most_frequent_values = ['nom_1', 'nom_3', \"day\"]\n\nmost_frequent_values = [train[column].value_counts().index[0] for column in features_to_drop_most_frequent_values]\nmost_frequent_values","6ba64850":"train.head().T","b9e1e4bc":"thermometer_features = ['ord_1', 'ord_2', 'ord_3', 'ord_4', 'month', 'ord_5_1']\n\nohe_2_features = ['nom_1', 'nom_3', 'day']\nohe_3_features = ['nom_8']\nohe_1_features = set(test.columns) - set(ohe_2_features) - set(ohe_3_features) - set(thermometer_features)","dcb13474":"y_train = train['target'].copy()\nx_train = train.drop('target', axis=1)\ndel train\n\nx_test = test.copy()\ndel test","ec25a794":"from sklearn.base import BaseEstimator, TransformerMixin\n\n\n# This implementation supports numeric features only\nclass ThermometerEncoder(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, cols=None, drop_invariant=True):\n        self.cols = cols\n        self.drop_invariant = drop_invariant\n    \n    def get_params(self, deep=True):\n        return {'cols': self.cols, 'drop_invariant': self.drop_invariant}\n    \n    def set_params(self, **parameters):\n        for parameter, value in parameters.items():\n            setattr(self, parameter, value)\n        return self\n    \n    def fit(self, X, y=None):\n        self.bars = {}\n        for c in self.cols:\n            k = np.arange(X[c].max() + 1)\n            self.bars[c] = (k[:-1] < k.reshape(-1, 1)).astype(int)\n        return self\n    \n    def transform(self, X, y=None):\n        out = pd.DataFrame(index=X.index)\n        for c in self.cols:\n            out = out.join(self.transform_one(X, c))\n        \n        if self.drop_invariant:\n            columns_to_drop = []\n            for c in out.columns:\n                if len(out[c].unique()) == 1:\n                    columns_to_drop.append(c)\n            out = out.drop(columns_to_drop, axis=1)\n        \n        return out\n    \n    def transform_one(self, X, c):\n        bars = self.bars[c]\n        out = pd.DataFrame(index=X.index, data=bars[X[c]])\n        out.columns = [c + '_' + str(k) for k in range(bars.shape[1])]\n        return out","a27502a2":"train_part = len(x_train)\ntraintest = pd.concat([x_train, x_test])","f4e87b91":"from sklearn.preprocessing import OneHotEncoder","9a5b3fb0":"ohe_1 = OneHotEncoder(dtype='uint8', handle_unknown=\"ignore\")\nohe_1_traintest = ohe_1.fit_transform(traintest[ohe_1_features])","9492c915":"ohe_2 = OneHotEncoder(drop=most_frequent_values, dtype='uint8')\nohe_2_traintest = ohe_2.fit_transform(traintest[ohe_2_features])","3b3bdbea":"ohe_3 = OneHotEncoder(drop='first', dtype='uint8')\nohe_3_traintest = ohe_3.fit_transform(traintest[ohe_3_features])","e0e6c564":"import scipy\n\n\nohe_traintest = scipy.sparse.hstack([ohe_1_traintest, ohe_2_traintest, ohe_3_traintest]).tocsr()\n\ndel ohe_1_traintest\ndel ohe_2_traintest\ndel ohe_3_traintest","441b96bf":"thermometer = ThermometerEncoder(thermometer_features)\nthermometer_traintest = thermometer.fit_transform(traintest)","ed5990e5":"import scipy\n\n\nfinal_traintest = scipy.sparse.hstack([ohe_traintest, thermometer_traintest]).tocsr()","11fd749c":"final_x_train = final_traintest[:train_part]\nfinal_x_test  = final_traintest[train_part:]","19f67fc2":"del x_train\ndel x_test","f9736c97":"final_x_train.shape","b51988f7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV","441b2d7e":"logit_param_grid = {\n    'C': [0.100, 0.150, 0.120, 0.125, 0.130, 0.135, 0.140, 0.145, 0.150]\n}\n\nlogit_grid = GridSearchCV(LogisticRegression(solver='lbfgs'), logit_param_grid,\n                          scoring='roc_auc', cv=5, n_jobs=-1, verbose=0)\n# logit_grid.fit(final_x_train, y_train)\n\n# best_C = logit_grid.best_params_['C']\nbest_C = 0.14\n\nprint('Best C:', best_C)","8812b25a":"logit = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=5000)\nlogit.fit(final_x_train, y_train)\ny_full_train = logit.predict_proba(final_x_test)[:, 1]","bf63c437":"submission = pd.read_csv('..\/input\/cat-in-the-dat\/sample_submission.csv', index_col='id')","705d87cd":"submission['target'] = y_full_train\nsubmission.to_csv('logit-full-train.csv')","5ef39968":"submission.head()","7d043e88":"Get list of most frequent values for selected columns to drop them later","884eb8b7":"Transform 'day'","bb8d55e2":"Map 'bin_3', 'bin_4'","9bf8f314":"Sort ordinal feature values","67b388ed":"Drop 'bin_0'","dd2bbc93":"### Thermometer encoding","5b8c0ecf":"### OHE","f1b885c3":"## Logistic regression","68b122fd":"Replace infrequent values with single value","d90578b0":"## Feature engineering","85036f31":"## Thermometer encoder","9d599216":"## Submit predictions","bb9000f2":"Drop 'ord_5_2'","3ec9fb5b":"## Solution","faf76eaa":"BTW: There is no reason replace 1 (or 2) infrequent values with 1 value","18b62ce2":"## Features","bd8fb0dc":"## Load data","ed2b4c6e":"Replace values that not presented in both train and test sets with single value","bd1f2e85":"Split 'ord_5'","7aeca340":"## Extract target variable"}}