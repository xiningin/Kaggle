{"cell_type":{"8886452a":"code","c09b20ed":"code","adc261c7":"code","512619bf":"code","69c52b9f":"code","e98191bb":"code","ca5b5b5b":"code","8a8f975d":"code","8b6fc94c":"code","63b7becf":"code","d5c2d11f":"code","df4043fb":"code","6a78d046":"code","c4523da3":"code","daa876c4":"code","8de15196":"code","b1e6ffaf":"code","16a89fdd":"code","e7888866":"code","717d445c":"code","ef6d56ef":"code","6bcdedcd":"code","359a550d":"code","850457cd":"code","85ef6ff9":"code","05284faa":"code","bc51c24c":"markdown","61235baf":"markdown","6309df69":"markdown","11450744":"markdown","219f17af":"markdown","be0de818":"markdown"},"source":{"8886452a":"import numpy as np","c09b20ed":"import os\nfrom glob import glob\nimport cv2\n\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\n\n%matplotlib inline\nimport matplotlib.pyplot as plt","adc261c7":"#PATH = os.path.abspath(os.path.join('..','input', 'flowers', 'flowers', 'rose'))\nPATH = os.path.abspath(os.path.join('..','input', 'roseimages', 'roseimages'))\nIMGS = glob(os.path.join(PATH, \"*.jpg\"))\n\nprint(len(IMGS)) # number of the rose images\nprint(IMGS[:10]) # rose images filenames","512619bf":"WIDTH = 28\nHEIGHT = 28\nDEPTH = 3","69c52b9f":"def procImages(images):\n    processed_images = []\n    \n    # set depth\n    depth = None\n    if DEPTH == 1:\n        depth = cv2.IMREAD_GRAYSCALE\n    elif DEPTH == 3:\n        depth = cv2.IMREAD_COLOR\n    else:\n        print('DEPTH must be set to 1 or to 3.')\n        return None\n    \n    #resize images\n    for img in images:\n        base = os.path.basename(img)\n        full_size_image = cv2.imread(img, depth)\n        processed_images.append(cv2.resize(full_size_image, (WIDTH, HEIGHT), interpolation=cv2.INTER_CUBIC))\n    processed_images = np.asarray(processed_images)\n    \n    # rescale images to [-1, 1]\n    processed_images = np.divide(processed_images, 127.5) - 1\n\n    return processed_images","e98191bb":"processed_images = procImages(IMGS)\nprocessed_images.shape","ca5b5b5b":"fig, axs = plt.subplots(5, 5)\ncount = 0\nfor i in range(5):\n    for j in range(5):\n        img = processed_images[count, :, :, :] * 127.5 + 127.5\n        img = np.asarray(img, dtype=np.uint8)\n        if DEPTH == 3:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axs[i, j].imshow(img)\n        axs[i, j].axis('off')\n        count += 1\nplt.show()","8a8f975d":"# GAN parameters\nLATENT_DIM = 100\nG_LAYERS_DIM = [256, 512, 1024]\nD_LAYERS_DIM = [1024, 512, 256]\n\nBATCH_SIZE = 16\nEPOCHS = 1000\nLR = 0.0002\nBETA_1 = 0.5","8b6fc94c":"def buildGenerator(img_shape):\n\n    def addLayer(model, dim):\n        model.add(Dense(dim))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        \n    model = Sequential()\n    model.add(Dense(G_LAYERS_DIM[0], input_dim=LATENT_DIM))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(BatchNormalization(momentum=0.8))\n    \n    for layer_dim in G_LAYERS_DIM[1:]:\n        addLayer(model, layer_dim)\n        \n    model.add(Dense(np.prod(img_shape), activation='tanh'))\n    model.add(Reshape(img_shape))\n\n    model.summary()\n\n    noise = Input(shape=(LATENT_DIM,))\n    img = model(noise)\n\n    return Model(noise, img)","63b7becf":"#g = buildGenerator(processed_images.shape[1:])","d5c2d11f":"def buildDiscriminator(img_shape):\n\n    def addLayer(model, dim):\n        model.add(Dense(dim))\n        model.add(LeakyReLU(alpha=0.2))\n\n    model = Sequential()\n    model.add(Flatten(input_shape=img_shape))\n    \n    for layer_dim in D_LAYERS_DIM:\n        addLayer(model, layer_dim)\n        \n    model.add(Dense(1, activation='sigmoid'))\n    model.summary()\n\n    img = Input(shape=img_shape)\n    classification = model(img)\n\n    return Model(img, classification)","df4043fb":"#d = buildDiscriminator(processed_images.shape[1:])","6a78d046":"def buildCombined(g, d):\n    # fix d for training g in the combined model\n    d.trainable = False\n\n    # g gets z as input and outputs fake_img\n    z = Input(shape=(LATENT_DIM,))\n    fake_img = g(z)\n\n    # gets the classification of the fake image\n    gan_output = d(fake_img)\n\n    # the combined model for training generator g to fool discriminator d\n    model = Model(z, gan_output)\n    model.summary()\n    \n    return model","c4523da3":"def sampleImages(generator):\n    rows, columns = 5, 5\n    noise = np.random.normal(0, 1, (rows * columns, LATENT_DIM))\n    generated_imgs = generator.predict(noise)\n\n    fig, axs = plt.subplots(rows, columns)\n    count = 0\n    for i in range(rows):\n        for j in range(columns):\n            img = generated_imgs[count, :, :, :] * 127.5 + 127.5\n            img = np.asarray(img, dtype=np.uint8)\n            if DEPTH == 3:\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            axs[i, j].imshow(img)\n            axs[i, j].axis('off')\n            count += 1\n    plt.show()","daa876c4":"#sampleImages(g)","8de15196":"#instantiate the optimizer\noptimizer = Adam(LR, BETA_1)","b1e6ffaf":"#build the discriminator\nd = buildDiscriminator(processed_images.shape[1:])\nd.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])","16a89fdd":"#build generator\ng = buildGenerator(processed_images.shape[1:])\ng.compile(loss='binary_crossentropy', optimizer=optimizer)","e7888866":"#build combined model\nc = buildCombined(g, d)\nc.compile(loss='binary_crossentropy', optimizer=optimizer)","717d445c":"#training\nSAMPLE_INTERVAL = WARNING_INTERVAL = 100\n\nYDis = np.zeros(2 * BATCH_SIZE)\nYDis[:BATCH_SIZE] = .9 #Label smoothing\n\nYGen = np.ones(BATCH_SIZE)\n\nfor epoch in range(EPOCHS):\n    # get a batch of real images\n    idx = np.random.randint(0, processed_images.shape[0], BATCH_SIZE)\n    real_imgs = processed_images[idx]\n\n    # generate a batch of fake images\n    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    fake_imgs = g.predict(noise)\n    \n    X = np.concatenate([real_imgs, fake_imgs])\n    \n    # Train discriminator\n    d.trainable = True\n    d_loss = d.train_on_batch(X, YDis)\n\n    # Train the generator\n    d.trainable = False\n    #noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    g_loss = c.train_on_batch(noise, YGen)\n\n    # Progress\n    if (epoch+1) % WARNING_INTERVAL == 0 or epoch == 0:\n        print (\"%d [Discriminator Loss: %f, Acc.: %.2f%%] [Generator Loss: %f]\" % (epoch, d_loss[0], 100. * d_loss[1], g_loss))\n\n    # If at save interval => save generated image samples\n    if (epoch+1) % SAMPLE_INTERVAL == 0 or epoch == 0:\n        sampleImages(g)","ef6d56ef":"def buildGeneratorDC(img_shape):\n    model = Sequential()\n\n    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=LATENT_DIM))\n    model.add(Reshape((7, 7, 128)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(DEPTH, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n\n    model.summary()\n\n    noise = Input(shape=(LATENT_DIM,))\n    img = model(noise)\n\n    return Model(noise, img)","6bcdedcd":"def buildDiscriminatorDC(img_shape):\n    model = Sequential()\n\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.summary()\n\n    img = Input(shape=img_shape)\n    classification = model(img)\n\n    return Model(img, classification)","359a550d":"#build the discriminator\ndDC = buildDiscriminatorDC(processed_images.shape[1:])\ndDC.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])","850457cd":"#build generator\ngDC = buildGeneratorDC(processed_images.shape[1:])\ngDC.compile(loss='binary_crossentropy', optimizer=optimizer)","85ef6ff9":"#build combined model\ncDC = buildCombined(gDC, dDC)\ncDC.compile(loss='binary_crossentropy', optimizer=optimizer)","05284faa":"#training DC GAN\nSAMPLE_INTERVAL = WARNING_INTERVAL = 100\n\nYDis = np.zeros(2 * BATCH_SIZE)\nYDis[:BATCH_SIZE] = .9 #Label smoothing\n\nYGen = np.ones(BATCH_SIZE)\n\nfor epoch in range(EPOCHS):\n    # get a batch of real images\n    idx = np.random.randint(0, processed_images.shape[0], BATCH_SIZE)\n    real_imgs = processed_images[idx]\n\n    # generate a batch of fake images\n    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    fake_imgs = gDC.predict(noise)\n    \n    X = np.concatenate([real_imgs, fake_imgs])\n    \n    # Train discriminator\n    dDC.trainable = True\n    for _ in range(5):\n        d_loss = dDC.train_on_batch(X, YDis)\n\n    # Train the generator\n    dDC.trainable = False\n    #noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    g_loss = cDC.train_on_batch(noise, YGen)\n\n    # Progress\n    if (epoch+1) % WARNING_INTERVAL == 0 or epoch == 0:\n        print (\"%d [Discriminator Loss: %f, Acc.: %.2f%%] [Generator Loss: %f]\" % (epoch, d_loss[0], 100. * d_loss[1], g_loss))\n\n    # If at save interval => save generated image samples\n    if (epoch+1) % SAMPLE_INTERVAL == 0 or epoch == 0:\n        sampleImages(gDC)","bc51c24c":"## The Data\n\nFirst we configure the paths and get the rose images filenames.","61235baf":"# GANs n\u00b4 Roses\n#### by Peterson Katagiri Zilli\n\nI will show how to build and train a simple _Generative Adversarial Networks (GAN)_ and a _Deep Convolutional GAN (DCGAN)_ in a dataset for generating realistic roses images.\n\nSee also:\n* https:\/\/medium.com\/@jonathan_hui\/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b\n* https:\/\/github.com\/Zackory\/Keras-MNIST-GAN\/blob\/master\/mnist_gan.py\n* https:\/\/github.com\/eriklindernoren\/Keras-GAN","6309df69":"## Building Deep Convolutional GAN Model","11450744":"Below we create functions for building simple dense generator and a discriminator modelsa","219f17af":"## Building Simple GAN Model","be0de818":"Then we resize the images to WIDTH pixels width, HEIGHT pixels height, and DEPTH color channels)"}}