{"cell_type":{"96e9b364":"code","714e1224":"code","a46dcd2b":"code","3300ce61":"code","6bb864b5":"code","ed01528e":"code","81738681":"code","3f17751f":"code","42fd4cc3":"code","2b12b9e1":"code","047f0655":"code","13542e9e":"code","ea7ccde2":"code","9c869709":"code","11f1f440":"code","756b126d":"code","666427bc":"code","4d0522f8":"code","e9ed5a9c":"code","b3a39c44":"code","2ad4ed8d":"code","963e0be5":"code","a3540f20":"code","93fd7026":"code","43bc81ff":"code","27ff7c5f":"code","dd1f4b92":"code","884cbbfa":"code","e0ee83a4":"code","de81bdb1":"code","e12d50b5":"code","2c15c668":"code","a9aaac76":"code","4dc18f03":"markdown","7c75135b":"markdown","e69e1a34":"markdown","1f787445":"markdown","d05ad612":"markdown","bcf1e6ea":"markdown","a30abfb9":"markdown","dbed7f5f":"markdown","e3eb400f":"markdown","da00a62c":"markdown","ffb92a1c":"markdown","7812eef6":"markdown","f42cd987":"markdown","8bec677d":"markdown","7d9f1eaa":"markdown","8528ba99":"markdown","767bf032":"markdown","08883d4b":"markdown","9b6cb108":"markdown","afe70a74":"markdown","e7d11233":"markdown","43575c66":"markdown","79f405de":"markdown","84870f36":"markdown","1e50fadf":"markdown","fba01f31":"markdown","ca53be29":"markdown","e891e68a":"markdown","ad8be266":"markdown","a454a953":"markdown","53ff5c79":"markdown","09136144":"markdown","b5354dd7":"markdown","af98283f":"markdown","e808106c":"markdown","1af740c4":"markdown","d8564bd8":"markdown","c37316f3":"markdown"},"source":{"96e9b364":"import numpy as np\nimport pandas as pd\nimport math\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\nfrom skimage import exposure\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\n\n%matplotlib inline","714e1224":"random_state = 3571\n\nnp.random.seed(random_state)","a46dcd2b":"# link = 'GTSRB\/Final_Training\/Images\/' # Local\nlink = '..\/input\/gtsrb-german-traffic-sign\/' # Kaggle","3300ce61":"GTSRBInfo = pd.DataFrame({\n    0:  { 'Type': 'prohibitory',  'Label': \"speed limit 20\"                         },\n    1:  { 'Type': 'prohibitory',  'Label': \"speed limit 30\"                         },\n    2:  { 'Type': 'prohibitory',  'Label': \"speed limit 50\"                         },\n    3:  { 'Type': 'prohibitory',  'Label': \"speed limit 60\"                         },\n    4:  { 'Type': 'prohibitory',  'Label': \"speed limit 70\"                         },\n    5:  { 'Type': 'prohibitory',  'Label': \"speed limit 80\"                         },\n    6:  { 'Type': 'other',        'Label': \"restriction ends 80\"                    },\n    7:  { 'Type': 'prohibitory',  'Label': \"speed limit 100\"                        },\n    8:  { 'Type': 'prohibitory',  'Label': \"speed limit 120\"                        },\n    9:  { 'Type': 'prohibitory',  'Label': \"no overtaking\"                          },\n    10: { 'Type': 'prohibitory',  'Label': \"no overtaking (trucks)\"                 },\n    11: { 'Type': 'danger',       'Label': \"priority at next intersection\"          },\n    12: { 'Type': 'other',        'Label': \"priority road\"                          },\n    13: { 'Type': 'other',        'Label': \"give way\"                               },\n    14: { 'Type': 'other',        'Label': \"stop\"                                   },\n    15: { 'Type': 'prohibitory',  'Label': \"no traffic both ways\"                   },\n    16: { 'Type': 'prohibitory',  'Label': \"no trucks\"                              },\n    17: { 'Type': 'other',        'Label': \"no entry\"                               },\n    18: { 'Type': 'danger',       'Label': \"danger\"                                 },\n    19: { 'Type': 'danger',       'Label': \"bend left\"                              },\n    20: { 'Type': 'danger',       'Label': \"bend right\"                             },\n    21: { 'Type': 'danger',       'Label': \"bend\"                                   },\n    22: { 'Type': 'danger',       'Label': \"uneven road\"                            },\n    23: { 'Type': 'danger',       'Label': \"slippery road\"                          },\n    24: { 'Type': 'danger',       'Label': \"road narrows\"                           },\n    25: { 'Type': 'danger',       'Label': \"construction\"                           },\n    26: { 'Type': 'danger',       'Label': \"traffic signal\"                         },\n    27: { 'Type': 'danger',       'Label': \"pedestrian crossing\"                    },\n    28: { 'Type': 'danger',       'Label': \"school crossing\"                        },\n    29: { 'Type': 'danger',       'Label': \"cycles crossing\"                        },\n    30: { 'Type': 'danger',       'Label': \"snow\"                                   },\n    31: { 'Type': 'danger',       'Label': \"animals\"                                },\n    32: { 'Type': 'other',        'Label': \"restriction ends\"                       },\n    33: { 'Type': 'mandatory',    'Label': \"go right\"                               },\n    34: { 'Type': 'mandatory',    'Label': \"go left\"                                },\n    35: { 'Type': 'mandatory',    'Label': \"go straight\"                            },\n    36: { 'Type': 'mandatory',    'Label': \"go right or straight\"                   },\n    37: { 'Type': 'mandatory',    'Label': \"go left or straight\"                    },\n    38: { 'Type': 'mandatory',    'Label': \"keep right\"                             },\n    39: { 'Type': 'mandatory',    'Label': \"keep left\"                              },\n    40: { 'Type': 'mandatory',    'Label': \"roundabout\"                             },\n    41: { 'Type': 'other',        'Label': \"restriction ends (overtaking)\"          },\n    42: { 'Type': 'other',        'Label': \"restriction ends (overtaking (trucks))\" },\n}).T\n\n# Adiciona ClassId como coluna da tabela\nGTSRBInfo.index.name = 'ClassId'\nGTSRBInfo.reset_index(inplace=True)\n\n# Transforma Label em valor categ\u00f3rico\nGTSRBInfo['Label'] = GTSRBInfo.Label.astype('category')\n\n# Transforma Type em valor categ\u00f3rico e ordena de acordo com a quantidade de dados\nTypes = GTSRBInfo.Type.value_counts().index\nGTSRBInfo['Type'] = GTSRBInfo.Type.astype('category').cat.reorder_categories(Types)\nGTSRBInfo['TypeId'] = GTSRBInfo.Type.cat.codes\n\nGTSRBInfo","6bb864b5":"def plotTrafficSigns(dataset, imRead=lambda classe: plt.imread(classe.Path), maxCols=5, random_state=None):\n    for Type in Types:\n        classes = dataset[dataset.Type == Type]\n        classLabels = classes.ClassId.unique()\n\n        nRows = math.ceil(classLabels.size \/ maxCols)\n        nCols = min(classLabels.size, maxCols)\n\n        fig, axs = plt.subplots(\n            nrows = nRows,\n            ncols = nCols,\n            figsize = (4*nCols, 3*nRows + 2),\n        )\n\n        for i, pos in enumerate(np.ndindex(axs.shape)):\n            try:\n                classe = dataset[dataset.ClassId == classLabels[i]].sample(1, random_state=random_state).iloc[0]\n\n                axs[pos].imshow(imRead(classe))\n                axs[pos].set_title(\"{}: {}\".format(classe.ClassId, classe.Label))\n\n            except:\n                pass\n\n            axs[pos].axis('off')\n\n        fig.suptitle(Type.capitalize(), fontsize='xx-large')\n        plt.show()","ed01528e":"# Apenas no kaggle\nmetaRead = lambda classe: plt.imread(\"..\/input\/gtsrb-german-traffic-sign\/Meta\/{}.png\".format(classe.ClassId))\n                                     \nplotTrafficSigns(dataset=GTSRBInfo, imRead=metaRead)","81738681":"sns.countplot(\n    x='Type',\n    data=GTSRBInfo,\n).set_title('Quantidade de placas de cada formato')\n\nplt.show()","3f17751f":"%%time\n\n# # Concatena os diferentes .csv em um \u00fanico DataFrame (Apenas local)\n# fileName = lambda i: link + \"{0:05d}\/GT-{0:05d}.csv\".format(int(i))\n# GTSRB = pd.concat((pd.read_csv(fileName(i), delimiter = ';') for i in GTSRBInfo.ClassId), ignore_index = True)\n\n# # Corrige o caminho das figuras\n# GTSRB.Filename = GTSRB.ClassId.map(lambda ID: link + \"{:05d}\/\".format(ID)) + GTSRB.Filename\n\n# Carrega o .csv \u00fanico dispon\u00edvel (Apenas no Kaggle)\nGTSRB = pd.read_csv(link + \"Train.csv\")\nGTSRB.Path = link + GTSRB.Path\n\n# Uni\u00e3o do dataset e das descri\u00e7\u00f5es\nGTSRB = GTSRB.merge(GTSRBInfo, on=\"ClassId\")\n\n# Cria lista ordenada das placas dispon\u00edveis\nLabels = GTSRB.Label.value_counts().index\n\nGTSRB.shape","42fd4cc3":"GTSRB.sample(5)","2b12b9e1":"GTSRB[['Width', 'Height']].describe()","047f0655":"fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharex=True)\n\nsns.distplot(\n    GTSRB.Width,\n    bins=25,\n    kde=False,\n    color='red',\n    ax=axs[0],\n)\naxs[0].set_title(\"Distribui\u00e7\u00e3o de valores de largura (em px)\")\naxs[0].set_xlabel(\"Largura\")\naxs[0].set_ylabel(\"Frequ\u00eancia\")\n\nsns.distplot(\n    GTSRB.Height,\n    bins=25,\n    kde=False,\n    color='blue',\n    ax=axs[1]\n)\naxs[1].set_title(\"Distribui\u00e7\u00e3o de valores de altura (em px)\")\naxs[1].set_xlabel(\"Altura\")\naxs[1].set_ylabel(\"Frequ\u00eancia\")\n\nplt.show()","13542e9e":"H_efet = (GTSRB['Roi.Y2'] - GTSRB['Roi.Y1']).abs()\nW_efet = (GTSRB['Roi.X2'] - GTSRB['Roi.X1']).abs()\n\nW_efet.name = 'Largura efetiva'\nH_efet.name = 'Altura efetiva'\n\npd.concat([W_efet, H_efet], axis=1, names=['a', 'b']).describe()","ea7ccde2":"fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharex=True)\n\nsns.distplot(\n    W_efet,\n    bins=25,\n    kde=False,\n    color='red',\n    ax=axs[0]\n)\naxs[0].set_title(\"Distribui\u00e7\u00e3o de valores de largura \u00fatil (em px)\")\naxs[0].set_ylabel(\"Frequ\u00eancia\")\n\nsns.distplot(\n    H_efet,\n    bins=25,\n    kde=False,\n    color='blue',\n    ax=axs[1]\n)\naxs[1].set_title(\"Distribui\u00e7\u00e3o de valores de altura \u00fatil (em px)\")\naxs[1].set_ylabel(\"Frequ\u00eancia\")\n\nplt.show()","9c869709":"sns.countplot(\n    x='Type',\n    data=GTSRB,\n).set_title(\"Quantidade de exemplos para cada tipo de placa\")\n\nplt.show()","11f1f440":"plt.figure(figsize=(15, 5))\nplt.xticks(rotation=90)\n\nLabelsType = GTSRBInfo.set_index('Label').loc[Labels].TypeId\npalette = np.asarray(sns.color_palette())[LabelsType]\n\nsns.countplot(\n    x='Label',\n    data=GTSRB,\n    palette=palette,\n    order=Labels,\n).set_title(\"Quantidades de exemplos para cada placa\")\n\nplt.legend(handles=[\n    mpatches.Patch(color=barColor, label=barType)\n    for barColor, barType\n    in zip(sns.color_palette(), Types)\n])\n\nplt.show()","756b126d":"plotTrafficSigns(GTSRB, random_state=random_state)","666427bc":"dataAugmentation = {\n    'rotation_range': 10,\n    'zoom_range': 0.15,\n    'width_shift_range': 0.1,\n    'height_shift_range': 0.1,\n    'shear_range': 0.15,\n}\n\nimageGenerator = ImageDataGenerator(**dataAugmentation)","4d0522f8":"imageShape = {\n    'height': 32,\n    'width': 32,\n    'depth': 3,\n}\n\ndef imageTreatment(image):\n    treatedImage = cv2.resize(image, (imageShape['width'], imageShape['height']))\n    treatedImage = exposure.equalize_adapthist(treatedImage, clip_limit=0.1)\n    # Corte?\n\n    return treatedImage","e9ed5a9c":"%%time\n\nImages = GTSRB.Path.map(plt.imread).map(imageTreatment)","b3a39c44":"plotTrafficSigns(GTSRB, imRead=lambda classe: Images[classe.name], random_state=random_state)","2ad4ed8d":"oneHotLabels = pd.get_dummies(GTSRB.Label)","963e0be5":"X_train, X_val, y_train, y_val = train_test_split(\n    np.stack(Images),\n    oneHotLabels,\n    test_size=0.10,\n    random_state=random_state\n)\n\nprint(\"Dados de treinamento: {:5d}\/{}\".format(len(X_train), len(GTSRB)))\nprint(\"Dados de valida\u00e7\u00e3o:   {:5d}\/{}\".format(len(X_val), len(GTSRB)))","a3540f20":"nClasses = Labels.size\ninputShape = (imageShape['height'], imageShape['width'], imageShape['depth'])\n\nTrafficSignNet = Sequential()\n\n# Primeira camada: Convolucional -> BatchNormalization -> MaxPooling\nTrafficSignNet.add(Conv2D(8, (5, 5), padding=\"same\", input_shape=inputShape))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Segunda camada: Convolucional -> Relu -> BatchNormalization -> Convolucional -> Relu -> BatchNormalization -> MaxPooling\nTrafficSignNet.add(Conv2D(16, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(Conv2D(16, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Terceira camada: Convolucional -> Relu -> BatchNormalization -> Convolucional -> Relu -> BatchNormalization -> MaxPooling\nTrafficSignNet.add(Conv2D(32, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(Conv2D(32, (3, 3), padding=\"same\"))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization(axis=-1))\nTrafficSignNet.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Quarta camada: Flatten -> Relu -> BatchNormalization -> DropOut\nTrafficSignNet.add(Flatten())\nTrafficSignNet.add(Dense(128))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization())\nTrafficSignNet.add(Dropout(0.5))\n\n# Quinta camada: Flatten -> Relu -> BatchNormalization -> DropOut\nTrafficSignNet.add(Flatten())\nTrafficSignNet.add(Dense(128))\nTrafficSignNet.add(Activation(\"relu\"))\nTrafficSignNet.add(BatchNormalization())\nTrafficSignNet.add(Dropout(0.5))\n\n# Sexta camada: Softmax\nTrafficSignNet.add(Dense(nClasses))\nTrafficSignNet.add(Activation(\"softmax\"))","93fd7026":"classTotals = y_train.sum(axis=0)\nclassWeights = classTotals.max() \/ classTotals\n\nclassWeight = {\n    i: classWeight\n    for i, classWeight in enumerate(classWeights)\n}","43bc81ff":"numEpochs = 30\nlearningRate = 1e-3\n\nTrafficSignNet.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=Adam(lr=learningRate, decay=(learningRate\/(0.5 * numEpochs))),\n    metrics=[\"accuracy\"]\n)","27ff7c5f":"%%time\n\nbatchSize = 64\n\nH = TrafficSignNet.fit_generator(\n    imageGenerator.flow(X_train, y_train, batch_size=batchSize),\n    validation_data=(X_val, y_val),\n    steps_per_epoch=(len(X_train) \/\/ batchSize),\n    epochs=numEpochs,\n    class_weight=classWeight,\n    verbose=True\n)","dd1f4b92":"plt.plot(np.arange(numEpochs), H.history['accuracy'], label='train_acc')\nplt.plot(np.arange(numEpochs), H.history['val_accuracy'], label='val_acc')\nplt.title(\"Acur\u00e1cia ao longo do treinamento.\")\nplt.xlabel(\"\u00c9poca\")\nplt.ylabel(\"Acur\u00e1cia\")\nplt.legend(loc=\"lower right\")\nplt.show()","884cbbfa":"predictions = TrafficSignNet.predict(X_val, batch_size=batchSize)\n\nreport = classification_report(\n    np.asarray(y_val).argmax(axis=1),\n    predictions.argmax(axis=1),\n    target_names=y_val.columns\n)\n\nprint(report)","e0ee83a4":"GTSRBTest = pd.read_csv(link + \"Test.csv\")\nGTSRBTest.Path = link + GTSRBTest.Path\n\n# Uni\u00e3o do dataset e das descri\u00e7\u00f5es\nGTSRBTest = GTSRBTest.merge(GTSRBInfo, on=\"ClassId\")\n\nGTSRBTest.shape","de81bdb1":"imagesTest = GTSRBTest.Path.map(plt.imread).map(imageTreatment)","e12d50b5":"predictionsTest = TrafficSignNet.predict(np.stack(imagesTest), batch_size=batchSize)\ny_test = pd.get_dummies(GTSRBTest.Label)\n\nreportTest = classification_report(\n    np.asarray(y_test).argmax(axis=1),\n    predictionsTest.argmax(axis=1),\n    target_names=y_test.columns\n)\n\nprint(reportTest)","2c15c668":"plt.figure(figsize=(22, 12))\n\nsns.heatmap(\n    confusion_matrix(predictionsTest.argmax(axis=1), np.asarray(y_test).argmax(axis=1)),\n    cmap=plt.cm.RdYlGn_r,\n    xticklabels=y_test.columns,\n    yticklabels=y_test.columns,\n    annot=True,\n    fmt='g'\n)","a9aaac76":"wrongPredicted = GTSRBTest.copy()\nwrongPredicted.Label = wrongPredicted.Label.astype(str) + '\\n' + \"Res: \" + y_test.columns[predictionsTest.argmax(axis=1)].astype(str)\n\nplotTrafficSigns(\n    wrongPredicted[predictionsTest.argmax(axis=1) != np.asarray(y_test).argmax(axis=1)],\n    imRead=lambda classe: imagesTest[classe.name],\n    random_state=random_state\n)","4dc18f03":"Ainda antes de iniciarmos o treinamento, vamos dividir o dataset em um conjunto de dados especifiamente para treinamento e outro conjunto de dados para valida\u00e7\u00e3o dos resultados. Assim, poderemos observar a qualidade do classificador com base em m\u00e9tricas de interesse e com dados que n\u00e3o foram utilizados anteriormente.","7c75135b":"### Informa\u00e7\u00f5es sobre as placas dispon\u00edveis","e69e1a34":"Vamos primeiramente carregar o dataset.","1f787445":"### Desempenho do modelo","d05ad612":"## An\u00e1lise dos dados","bcf1e6ea":"## Tratamento dos dados","a30abfb9":"Por fim, vamos definir os pesos de acordo com o n\u00famero de elementos de cada classe. Esta abordagem \u00e9 usada por conta do desbalanceamento no n\u00famero de imagens dispon\u00edveis para cada classe no dataset.","dbed7f5f":"#### Visualiza\u00e7\u00e3o dos resultados do tratamento","e3eb400f":"Outra informa\u00e7\u00e3o relacionada \u00e9 a largura e a altura efetivamente \u00fateis em cada imagem:  \n\n$$H_{efet} = |Y_2 - Y_1|$$\n$$W_{efet} = |X_2 - X_1|$$","da00a62c":"### Data Augmentation","ffb92a1c":"# Reconhecedor de Placas de Sinaliza\u00e7\u00e3o de Tr\u00e2nsito\n### PSI3571 - Pr\u00e1ticas em Reconhecimento de Padr\u00f5es, Modelagem e Intelig\u00eancia Computacional\n\nAtividade da P2 da disciplina PSI3571","7812eef6":"Vamos agora observar um exemplo de cada placa presente no dataset.","f42cd987":"Agora que j\u00e1 pudemos observar os dados dispon\u00edveis, faremos alguns tratamentos para possibilitar o uso das imagens pelo modelo e para obtermos melhores resultados.","8bec677d":"### Divis\u00e3o em dados de treinamento e de valida\u00e7\u00e3o","7d9f1eaa":"Inicialmente, vamos observar dados relativos aos valores de ```Height``` e ```Width``` das figuras dispon\u00edveis. Aqui pode-se notar que as figuras n\u00e3o s\u00e3o necessariamente quadradas e que possuem tamanhos distintos, variando, em cada eixo, de 25 pixels a at\u00e9 mais de 200 pixels.","8528ba99":"Vamos primeiramente observar o desempenho do modelo com base nos dados de valida\u00e7\u00e3o.","767bf032":"### Informa\u00e7\u00f5es sobre as figuras","08883d4b":"## Setup","9b6cb108":"## Treinamento - Classifica\u00e7\u00e3o","afe70a74":"### Resultados para os dados de teste","e7d11233":"### Treinamento do modelo","43575c66":"### Tratamento e leitura das imagens","79f405de":"### Visualiza\u00e7\u00e3o das placas","84870f36":"### Defini\u00e7\u00e3o do modelo","1e50fadf":"## Descri\u00e7\u00e3o","fba01f31":"Observando a descri\u00e7\u00e3o do dataset, \u00e9 poss\u00edvel encontrar a rela\u00e7\u00e3o entre os valores num\u00e9ricos de ```ClassId``` e as descri\u00e7\u00f5es das placas com classifica\u00e7\u00e3o e tipo de cada placa.\n\nA informa\u00e7\u00e3o de tipo \u00e9 importante pois placas de mesmo tipo t\u00eam forma similar. Por exemplo, placas do tipo ```prohibitory``` s\u00e3o circulares e com borda vermelha, enquanto placas do tipo ```danger``` s\u00e3o triangulares e tamb\u00e9m com borda vermelha. J\u00e1 as placas ```mandatory``` s\u00e3o placas circulares e preenchidas em azul. Por fim, as placas identificada como ```other``` possuem formas distintas.","ca53be29":"Vamos primeiramente criar um modelo baseado em Redes Neurais utilizando o `Keras`. Nesta etapa ser\u00e1 criada a **Rede Neural** e definiremos quais ser\u00e3o as camadas desta rede.","e891e68a":"### Matriz de confus\u00e3o","ad8be266":"Como nossos conjunto de dados n\u00e3o possui tantas imagens, uma pr\u00e1tica recomendada nos pr\u00f3prios [exemplos do keras](https:\/\/keras.io\/examples\/vision\/image_classification_from_scratch\/) \u00e9 a de usar a t\u00e9cnica de *data augmentation*. Atrav\u00e9s dela, podemos gerar novas imagens a partir das imagens presentes no dataset atrav\u00e9s da aplica\u00e7\u00e3o de pequenas transforma\u00e7\u00f5es, como por exemplos pequenas rota\u00e7\u00f5es ou transla\u00e7\u00f5es da imagem original, conforme definiremos abaixo.","a454a953":"### Visualiza\u00e7\u00e3o de classifica\u00e7\u00f5es incorretas","53ff5c79":"Outra informa\u00e7\u00e3o relevante se d\u00e1 sobre a quantidade de dados dispon\u00edveis para cada placa:","09136144":"Nesta etapa faremos um procedimento adicional para que os dados possam ser utilizados pelo nosso modelo de rede neural:\n   \n1. Aplica\u00e7\u00e3o de One-Hot Encoding nos valores de `Label`, usados como sa\u00edda do modelo\n   Este tratamento \u00e9 necess\u00e1rio pois a rede neural s\u00f3 \u00e9 capaz de fornecer resultados de ponto flutuante em um pequeno intervalo e estes valores est\u00e3o associados \u00e0 intensidade da ativa\u00e7\u00e3o de um determinado neur\u00f4nio. Assim, uma maneira de obter um resultado melhor \u00e9 utilizando a t\u00e9cnica de One-Hot Encoding e realizar a classifica\u00e7\u00e3o com base no neur\u00f4nio de sa\u00edda que ficou ativo com maior intensidade.","b5354dd7":"Agora que j\u00e1 temos todos os dados carregadores e que j\u00e1 observamos as informa\u00e7\u00f5es que temos dispon\u00edveis, vamos iniciar o treinamento de um modelo para a classifica\u00e7\u00e3o de placas de tr\u00e2nsito, ou seja, dada uma imagem de uma placa, o modelo deve nos fornecer o correto valor de `ClassId`.","af98283f":"Por fim, vamos realizar a classifica\u00e7\u00e3o dos dados de teste e, ent\u00e3o, vamos observar a qualidade da classifica\u00e7\u00e3o feita.","e808106c":"### Codifica\u00e7\u00e3o das classes de sa\u00edda","1af740c4":"## Carregando o dataset","d8564bd8":"Neste item definiremos uma s\u00e9rie de tratamentos sobre cada imagem que ser\u00e1 carregada, para que elas possam ser corretamente mapeadas para as entradas da rede neural e para que os resultados do modelo sejam melhores. Os tratamentos feitos ser\u00e3o:\n\n1. Redimensionar imagens para um mesmo tamanho  \n   O objetivo aqui \u00e9 que todas as imagens tenham o mesmo n\u00famero de valores para que eles possam ser mapeados na entrada da rede neural.\n\n1. Normalizar o contraste nas figuras  \n   O objetivo \u00e9 tornar os detalhes das placas mais n\u00edtidos e mais distintos de elementos de fundo.\n\n1. A regi\u00e3o de interesse, onde de fato a placa se encontra, n\u00e3o necessariamente equivale a toda a \u00e1rea da imagem. (TODO)","c37316f3":"Com o modelo definido, vamos agora compil\u00e1-lo e vamos tamb\u00e9m adicionar o optimizador Adam.\n\nDepois disso, vamos treinar este modelo com base nos dados de treinamento que temos dispon\u00edveis."}}