{"cell_type":{"4cf1778d":"code","9667bc02":"code","e29ab020":"code","7f576a37":"code","9124456c":"code","6f467be3":"code","3e458e24":"code","393fdd11":"code","b1d3816f":"code","97745a97":"code","cb652ed8":"code","76b6b2dd":"markdown","33a1bb19":"markdown","2d17153c":"markdown","114f77ef":"markdown","4ebfcb28":"markdown","724a9a17":"markdown","8a3137d1":"markdown","832f4e8b":"markdown"},"source":{"4cf1778d":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom PIL import Image\nfrom skimage.color import rgb2hsv\nimport os","9667bc02":"os.listdir('..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTest')","e29ab020":"img = Image.open(r'..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTest\/8006a.jpg')\nx = np.array(img)\nimshow(x)","7f576a37":"z = np.dstack((x,rgb2hsv(x)))\nz.shape","9124456c":"vectorized = np.float32(z.reshape((-1,6)))\nvectorized.shape","6f467be3":"kmeans = KMeans(random_state=0, init='random', n_clusters=8)\nlabels = kmeans.fit_predict(vectorized)","3e458e24":"labels.shape","393fdd11":"pic = labels.reshape(256,416)","b1d3816f":"f, axarr = plt.subplots(1,2,figsize=(15,15))\naxarr[0].set_xlabel('Original Image', fontsize=12)\naxarr[1].set_xlabel('Segmented Image', fontsize=12)  \naxarr[0].imshow(x)\naxarr[1].imshow(pic)","97745a97":"img = Image.open(r'..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTest\/2002a.jpg')\nx = np.array(img)\nz = np.dstack((x,rgb2hsv(x)))\nz.shape\nvectorized = np.float32(z.reshape((-1,6)))\nkmeans = KMeans(random_state=32, init='random', n_clusters=7)\njames = kmeans.fit_predict(vectorized)\npic = james.reshape(256,416)\nf, axarr = plt.subplots(1,2,figsize=(15,15))\naxarr[0].set_xlabel('Original Image', fontsize=12)\naxarr[1].set_xlabel('Segmented Image', fontsize=12)  \naxarr[0].imshow(x)\naxarr[1].imshow(pic)","cb652ed8":"img = Image.open(r'..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTest\/1005a.jpg')\nx = np.array(img)\nz = np.dstack((x,rgb2hsv(x)))\nz.shape\nvectorized = np.float32(z.reshape((-1,6)))\nkmeans = KMeans(random_state=32, init='random', n_clusters=6)\njames = kmeans.fit_predict(vectorized)\npic = james.reshape(256,416)\nf, axarr = plt.subplots(1,2,figsize=(15,15))\naxarr[0].set_xlabel('Original Image', fontsize=12)\naxarr[1].set_xlabel('Segmented Image', fontsize=12)  \naxarr[0].imshow(x)\naxarr[1].imshow(pic)","76b6b2dd":"# Results","33a1bb19":"# Load Image","2d17153c":"# Introduction\nI am going to be using the K-Means Unsupervised Clustering Algorithm to segment images of lunch trays. <br\/> This dataset is meant for supervised learning but I am going to attempt to segment the images without any labels given. <br\/>\nI am going to cluster pixels based on their spatial and color data only.","114f77ef":"Reshaping labels array back into X & Y dimensions to be able to view the images","4ebfcb28":"# K-Means\n* The K-Means clustering algorithm only takes 2 dimensional input so I am squishing the X & Y dimension into 1 spatial dimesion\n* The new dimensions are now `256*416 x 6` == `106496x6`","724a9a17":"* I am picking `K = 8` clusters for this image\n* The algorithm starts with `K` cluster centroids that are randomly initialized\n* All pixels are then assigned to their nearest cluster centroid\n* The cluster centroids are then recalculated and this process repeats until convergence\n","8a3137d1":"# HSV Color Space\n![RBG & HSV](https:\/\/miro.medium.com\/max\/1700\/1*W30TLUP9avQwyyLfwu7WYA.jpeg)\n<br\/>\n<br\/>\n<br\/>\nI'm concatenating the RGB and HSV color spaces. `256x416x3` + `256x416x3` = `256x416x6`","832f4e8b":"# More Examples"}}