{"cell_type":{"7adc8b11":"code","5ed700a6":"code","95e03ce8":"code","5831663b":"code","052167e2":"code","e0a4a4f8":"code","7824d631":"code","f8e20343":"code","bc07526e":"code","2b0a4185":"code","13474df9":"code","8836f4a2":"code","9992ebae":"code","b96e38c7":"markdown","db991749":"markdown","ad8ac4cd":"markdown","7270f0ad":"markdown","3bea8054":"markdown"},"source":{"7adc8b11":"import gc\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow_addons.optimizers import AdamW, Lookahead\nfrom tensorflow.keras.layers import Activation, Input\nfrom tensorflow.keras.layers import Embedding, Conv1D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Concatenate, Add, LSTM\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout","5ed700a6":"with open(\"..\/input\/tps-june-data-preprocess\/TPS_June_Dataset_Set1.txt\", 'rb') as handle: \n    data = handle.read()\n\nprocessed_data = pickle.loads(data)\ntrain_df = processed_data['train_df']\ntest_df = processed_data['test_df']\n\ncol_list = test_df.columns.to_list()\n\ndel processed_data\ngc.collect()","95e03ce8":"Xtrain = train_df.loc[:, train_df.columns != 'target'].copy()\nYtrain = train_df['target'].copy()\nYtrain_oh = pd.get_dummies(train_df['target']).copy()\nXtest = test_df.copy()\n\nprint(\"Xtrain: {} \\nYtrain: {} \\nYtrain_oh: {} \\nXtest: {}\".format(Xtrain.shape, Ytrain.shape, \n                                                                   Ytrain_oh.shape, Xtest.shape))\n\ndel train_df\ndel test_df\ngc.collect()","5831663b":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print(\"Running on TPU:\", tpu.master())\n    \nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")","052167e2":"mini_batch_size = strategy.num_replicas_in_sync * 32\nprint(f'batch size: {mini_batch_size}')","e0a4a4f8":"def dnn_model(n_features):\n    \n    x_input = Input(shape=(n_features,))\n    \n    x = Embedding(512, 16)(x_input)\n    \n    x = Conv1D(filters=32, kernel_size=3, \n               strides=2, padding='same', \n               kernel_regularizer=l2(0.0003),\n               kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n    \n    x = Conv1D(filters=64, kernel_size=3, \n               strides=2, padding='same', \n               kernel_regularizer=l2(0.0003),\n               kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n    \n    x = LSTM(units=96, activation='swish',\n             return_sequences=False, dropout=0.1,\n             kernel_regularizer=l2(0.0003),\n             kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    \n    x = Dense(units=16, kernel_initializer='he_uniform', \n                kernel_regularizer=l2(0.0001))(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n    x = Dropout(rate=0.1)(x)\n\n    x_output = Dense(units=9, activation='softmax', \n                     kernel_initializer='he_uniform')(x)\n\n    model = Model(inputs=x_input, outputs=x_output, \n                  name='DNN_Model')\n    return model","7824d631":"model = dnn_model(Xtrain.shape[1])\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Lookahead(AdamW(lr=1e-2, \n                                        weight_decay=1e-5, \n                                        clipvalue=700), \n                                  sync_period=10))\nmodel.summary()","f8e20343":"FOLD = 10\nNUM_SEED = 3\nVERBOSE = 0\n\nnp.random.seed(3)\nseeds = np.random.randint(0, 100, size=NUM_SEED)\n\ncounter = 0\noof_score = 0\ny_pred_meta_dnn = np.zeros((Xtrain.shape[0], 9))\ny_pred_final_dnn = np.zeros((Xtest.shape[0], 9))","bc07526e":"with strategy.scope():\n    \n    for sidx, seed in enumerate(seeds):\n        seed_score = 0\n\n        kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n\n        for idx, (train, val) in enumerate(kfold.split(Xtrain, Ytrain)):\n            counter += 1\n\n            train_x, train_y, train_y_oh = Xtrain.iloc[train], Ytrain.iloc[train], Ytrain_oh.iloc[train]\n            val_x, val_y, val_y_oh = Xtrain.iloc[val], Ytrain.iloc[val], Ytrain_oh.iloc[val]\n\n            model = dnn_model(Xtrain.shape[1])\n            model.compile(loss='categorical_crossentropy',\n                          optimizer=Lookahead(AdamW(lr=1e-2, \n                                                    weight_decay=1e-5, \n                                                    clipvalue=700), \n                                              sync_period=10))\n\n            early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n                                  restore_best_weights=True, \n                                  patience=7, verbose=VERBOSE)\n\n            reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n                                          min_lr=1e-6, patience=3, \n                                          verbose=VERBOSE, mode='min')\n            \n            save_locally = tf.saved_model.SaveOptions(experimental_io_device='\/job:localhost')\n\n            chk_point = ModelCheckpoint('.\/DNN_model.h5', options=save_locally, \n                                        monitor='val_loss', verbose=VERBOSE, \n                                        save_best_only=True, mode='min')\n\n            history = model.fit(\n                train_x, train_y_oh, \n                batch_size=mini_batch_size,\n                epochs=250, \n                verbose=VERBOSE, \n                callbacks=[reduce_lr, early, chk_point], \n                validation_data=(val_x, val_y_oh)\n            )\n            \n            load_locally = tf.saved_model.LoadOptions(experimental_io_device='\/job:localhost')\n\n            model = load_model('.\/DNN_model.h5', options=load_locally)\n\n            y_pred = model.predict(val_x)\n            y_pred_meta_dnn[val] += y_pred\n            y_pred_final_dnn += model.predict(Xtest)\n\n            score = log_loss(val_y_oh, y_pred)\n            oof_score += score\n            seed_score += score\n            print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n\n        print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score \/ FOLD)))","2b0a4185":"y_pred_meta_dnn = y_pred_meta_dnn \/ float(NUM_SEED)\ny_pred_final_dnn = y_pred_final_dnn \/ float(counter)\noof_score \/= float(counter)\nprint(\"Aggregate OOF Score: {}\".format(oof_score))","13474df9":"np.savez_compressed('.\/DNN_Meta_Features.npz',\n                    y_pred_meta_dnn=y_pred_meta_dnn, \n                    oof_score=oof_score,\n                    y_pred_final_dnn=y_pred_final_dnn)","8836f4a2":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\nsubmit_df = pd.DataFrame()\nsubmit_df['id'] = test_df['id']\nsubmit_df['Class_1'] = y_pred_final_dnn[:,1]\nsubmit_df['Class_2'] = y_pred_final_dnn[:,2]\nsubmit_df['Class_3'] = y_pred_final_dnn[:,3]\nsubmit_df['Class_4'] = y_pred_final_dnn[:,4]\nsubmit_df['Class_5'] = y_pred_final_dnn[:,5]\nsubmit_df['Class_6'] = y_pred_final_dnn[:,6]\nsubmit_df['Class_7'] = y_pred_final_dnn[:,7]\nsubmit_df['Class_8'] = y_pred_final_dnn[:,8]\nsubmit_df['Class_9'] = y_pred_final_dnn[:,0]\nsubmit_df.head()","9992ebae":"submit_df.to_csv(\".\/DNN_submission.csv\", index=False)","b96e38c7":"## Import libraries","db991749":"## Prepare data for model training","ad8ac4cd":"## Build the model","7270f0ad":"## Create submission file","3bea8054":"## Define TPU config"}}