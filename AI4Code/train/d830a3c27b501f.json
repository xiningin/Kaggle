{"cell_type":{"3ed89adb":"code","2dcab508":"code","7bd79e4b":"code","5d93f8cc":"code","f4e555a6":"code","f9046af9":"code","429294e5":"code","b9e6103f":"code","27538243":"code","5c4ba629":"code","ab01c230":"code","dca9f32f":"code","73658621":"code","02f5f7bc":"code","b7393d76":"code","a54fd069":"code","2fae89b5":"code","9cf59184":"code","14f83c0d":"code","f598f6b2":"code","b9897456":"code","66df8752":"code","707ed47e":"code","d303b51b":"code","90d7c163":"code","c5aa4598":"code","8eb612de":"code","9bf70448":"code","9511c5fd":"markdown","75349829":"markdown"},"source":{"3ed89adb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation,Conv2D,MaxPool2D,Dense,Flatten,MaxPooling2D\nimport glob\nfrom keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\nimport PIL\n#VGG16\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.layers import Input,Dense, Flatten,Dropout\nfrom keras.models import Model","2dcab508":"def dataset_prepare(path,label):\n    x=[]\n    y=[]\n    data_path=glob.glob(path+'\/*')\n    for img_path in data_path:\n        img=load_img(img_path,target_size=(150,150))\n        img=img_to_array(img)\n        img=img\/255.0\n        x.append(img)\n        y.append(label)\n        \n    return np.array(x),np.array(y)","7bd79e4b":"build_x,build_y=dataset_prepare('..\/input\/intel-image-classification\/seg_train\/seg_train\/buildings',0)\n\nforest_x,forest_y=dataset_prepare('..\/input\/intel-image-classification\/seg_train\/seg_train\/forest',1)\nglac_x,glac_y=dataset_prepare('..\/input\/intel-image-classification\/seg_train\/seg_train\/glacier',2)\nmount_x,mount_y=dataset_prepare('..\/input\/intel-image-classification\/seg_train\/seg_train\/mountain',3)\nsea_x,sea_y=dataset_prepare('..\/input\/intel-image-classification\/seg_train\/seg_train\/sea',4)\nstreet_x,street_y=dataset_prepare('..\/input\/intel-image-classification\/seg_train\/seg_train\/street',5)\n\n\n","5d93f8cc":"build_x,build_y=build_x[:800],build_y[:800]\nforest_x,forest_y=forest_x[:800],forest_y[:800]\nmount_x,mount_y=mount_x[:800],mount_y[:800]\nsea_x,sea_y=sea_x[:800],sea_y[:800]\nstreet_x,street_y=street_x[:800],street_y[:800]\nprint(build_x.shape,build_y.shape,'Buildings')\nprint(forest_x.shape,forest_y.shape,'Forest')\nprint(mount_x.shape,mount_y.shape,'Mountains')\nprint(sea_x.shape,sea_y.shape,'sea')\nprint(street_x.shape,street_y.shape,'street')","f4e555a6":"x_train=np.concatenate([build_x,forest_x,glac_x,mount_x,sea_x,street_x],axis=0)\ny_train=np.concatenate([build_y,forest_y,glac_y,mount_y,sea_y,street_y],axis=0)\n","f9046af9":"#{'building':0,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}","429294e5":"import matplotlib.pyplot as plt\nplt.imshow(x_train[0])\nplt.title(y_train[0])","b9e6103f":"#doing the same for test data\nbuild_x_test,build_y_test=dataset_prepare(\"..\/input\/intel-image-classification\/seg_test\/seg_test\/buildings\",0)\n\nforest_x_test, forest_y_test = dataset_prepare(\"..\/input\/intel-image-classification\/seg_test\/seg_test\/forest\",1)\nglac_x_test, glac_y_test = dataset_prepare(\"..\/input\/intel-image-classification\/seg_test\/seg_test\/glacier\",2)\nmount_x_test, mount_y_test = dataset_prepare('..\/input\/intel-image-classification\/seg_test\/seg_test\/mountain',3)\nsea_x_test, sea_y_test = dataset_prepare('..\/input\/intel-image-classification\/seg_test\/seg_test\/sea',4)\nstreet_x_test, street_y_test = dataset_prepare('..\/input\/intel-image-classification\/seg_test\/seg_test\/street',5)","27538243":"x_test=np.concatenate([build_x_test,forest_x_test,glac_x_test,sea_x_test,street_x_test],axis=0)\ny_test=np.concatenate([build_y_test,forest_y_test,glac_y_test,sea_y_test,street_y_test],axis=0)\n\nx_test.shape","5c4ba629":"#vgg=VGG16(input_shape=(150,150,3),include_top=False,weights='imagenet')\n","ab01c230":"#vgg.layers#layers that are invovled in VGG.since include_top =False, we are going to built the desnse netwrok oursselves,","dca9f32f":"#vgg.weights[:2]# pretrained weights of imagenet","73658621":"#since we are using pretrained weights, we should not train those wieghts again,so\n#for layer in vgg.layers:\n #   layer.trainable=False","02f5f7bc":"from tensorflow.keras.applications import VGG16\n\npretrained_model=VGG16(input_shape = (150, 150, 3), \n                        include_top = False, \n                        weights = 'imagenet')\n\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\n# pretrained_model.summary()\nlast_layer = pretrained_model.get_layer('block5_pool')\nprint('last layer of vgg : output shape: ', last_layer.output_shape)\nlast_output= last_layer.output\n\nx = Flatten()(last_output)\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.2)(x)                  \nx = Dense(6, activation='softmax')(x)           \n\nmodel_vgg = Model(pretrained_model.input, x) \n\n\nmodel_vgg.compile(optimizer = 'adam', \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\n# ","b7393d76":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n\nmodel_vgg.compile(optimizer = 'adam', \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\nhistory=model_vgg.fit(x_train,y_train,epochs=20,validation_data=(x_test,y_test),callbacks=[early_stop])\n","a54fd069":"model_loss = pd.DataFrame(model_vgg.history.history)\nmodel_loss.plot()","2fae89b5":"def dataset_prepare(path,label):\n    x=[]\n    y=[]\n    data_path=glob.glob(path+'\/*')\n    for img_path in data_path[:50]:\n        img=load_img(img_path,target_size=(150,150))\n        img=img_to_array(img)\n        img=img\/255.0\n        x.append(img)\n        y.append(label)\n        \n    return np.array(x),np.array(y)\n\npred_x,pred_y=dataset_prepare('..\/input\/intel-image-classification\/seg_pred\/seg_pred',0)","9cf59184":"predict=model_vgg.predict(pred_x)\npredict=np.argmax(predict,axis=1)\nlabels=['buildings','forest','glacier','mountain','sea','street']","14f83c0d":"plt.figure(figsize=(15,15))\nfor i in range(50):\n    plt.subplot(5,10,i+1)\n    plt.imshow(pred_x[i])\n    plt.title(labels[predict[i]])\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","f598f6b2":"\ntrain_path='..\/input\/intel-image-classification\/seg_train\/seg_train'\ntest_path='..\/input\/intel-image-classification\/seg_test\/seg_test'\npred_path='..\/input\/intel-image-classification\/seg_pred\/seg_pred'","b9897456":"model =Sequential()\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(26, activation='relu'))\nmodel.add(Dense(6,activation='softmax'))\n\n\nmodel.compile(optimizer = 'adam', \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n","66df8752":"train_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_gen=train_datagen.flow_from_directory(train_path,target_size=(150,150),batch_size=64,class_mode='sparse')\ntest_gen=test_datagen.flow_from_directory(test_path,target_size=(150,150),batch_size=64,class_mode='sparse')","707ed47e":"history = model.fit_generator(train_gen,epochs=10,validation_data=(test_gen))","d303b51b":"#Using Resnet\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input","90d7c163":"resnet=ResNet50(include_top=False,input_shape=(150,150,3))\nfor layer in resnet.layers:\n    layer.trainable=False","c5aa4598":"x =Flatten()(resnet.output)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.2)(x)                  \nx = Dense(6, activation='softmax')(x)\n\nmodel=Model(resnet.input,x)\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","8eb612de":"train_datagen=ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\n\n\ntrain_set=train_datagen.flow_from_directory(train_path,target_size=(150,150),batch_size=128,class_mode = 'sparse')\ntest_set=test_datagen.flow_from_directory(test_path,target_size=(150,150),batch_size=128,class_mode = 'sparse')","9bf70448":"history=model.fit_generator(train_set,validation_data=test_set,epochs = 5) #more epochs","9511c5fd":"RESNET","75349829":"******Using Agumentation texhnique"}}