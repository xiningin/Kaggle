{"cell_type":{"74cfd4d6":"code","ca4da9ee":"code","7ace3f5a":"code","c63a7486":"code","8dbb875d":"code","b49773fc":"code","ea78020a":"code","df693f90":"code","27eadde8":"code","67468d57":"code","05b5aa3f":"code","11ca6186":"code","586c7c5f":"code","8a9b8145":"code","8e6e1b9a":"code","42cb181b":"code","527bf266":"code","a77fee90":"code","dc5e1b75":"code","236a9469":"code","4560af00":"code","04bb0e20":"code","39bb50da":"code","39b75c7d":"code","64f998f8":"markdown","3f800801":"markdown","1631213d":"markdown","9c345866":"markdown","8a052ddb":"markdown","9367b85e":"markdown","066e7aa0":"markdown","c16d8395":"markdown"},"source":{"74cfd4d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ca4da9ee":"!pwd\n!ls \/kaggle\/input\/house-prices-advanced-regression-techniques\/\n!cp \/kaggle\/input\/house-prices-advanced-regression-techniques\/* .\n!ls","7ace3f5a":"import sys\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n#!conda install --yes xgboost\nimport xgboost\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n#features\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n\n#stats model\nfrom sklearn import datasets, linear_model\nimport statsmodels.formula.api as smf\n\n# Model Selection\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier\n#!conda install --yes lightgbm\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LassoCV, LinearRegression\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n\n# Model Accuracy\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, accuracy_score, mean_poisson_deviance, mean_squared_error \n\npd.pandas.set_option('display.max_columns', None)\npd.pandas.set_option('display.max_rows', None)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\n#warnings.simplefilter(action='ignore', category=ConvergenceWarning)","c63a7486":"train_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\ndf_train_dup = train_data.copy()\ndf_train_dup.shape","8dbb875d":"df_test_dup = test_data.copy()\ndf_test_dup.shape\n","b49773fc":"df_train_dup.head()","ea78020a":"y_train = np.log1p(df_train_dup.pop('SalePrice'))\ndf_train_dup.shape","df693f90":"all_features = pd.concat((df_train_dup,df_test_dup),axis=0)\nall_features.head()","27eadde8":"all_features = pd.get_dummies(all_features,dummy_na=True)\nall_features.shape","67468d57":"numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\nall_features[numeric_features] = all_features[numeric_features].apply(lambda x : (x- x.mean())\/(x.std()))\nall_features[numeric_features] = all_features[numeric_features].fillna(0)","05b5aa3f":"df_test_dup.index","11ca6186":"all_features.isnull().sum().sum()","586c7c5f":"\nn_train = df_train_dup.shape[0]\nX_train = torch.tensor(all_features[:n_train].values,dtype=torch.float32)\nX_test=torch.tensor(all_features[n_train:].values,dtype=torch.float32)","8a9b8145":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score","8e6e1b9a":"alphas = np.logspace(-3,2,50)\ntest_scores=[]\nfor alpha in alphas:\n    clf = Ridge(alpha)\n    test_score = np.sqrt(-cross_val_score(clf,X_train,y_train,cv=10,scoring='neg_mean_squared_error'))\n    test_scores.append(np.mean(test_score))","42cb181b":"plt.plot(alphas,test_scores)\nplt.title('Alpha vs CV error')","527bf266":"from sklearn.ensemble import RandomForestRegressor","a77fee90":"max_features = [.1,.3,.5,.7,.9,.99]\ntest_scores=[]\nfor max_feat in max_features:\n    clf=RandomForestRegressor(n_estimators=200)\n    test_score = np.sqrt(-cross_val_score(clf,X_train,y_train,cv=5,scoring='neg_mean_squared_error'))\n    test_scores.append(np.mean(test_score))","dc5e1b75":"test_scores","236a9469":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.plot(max_features,test_scores)\nplt.title('Alpha vs CV error')","4560af00":"ridge=Ridge(alpha=100)\nrf=RandomForestRegressor(n_estimators=500,max_features=.3)","04bb0e20":"ridge.fit(X_train,y_train)\nrf.fit(X_train,y_train)","39bb50da":"y_ridge=np.expm1(ridge.predict(X_test))\ny_rf=np.expm1(rf.predict(X_test))","39b75c7d":"y_final = (y_rf+y_ridge)\/2","64f998f8":"\u5904\u7406\u6570\u503c\u6570\u636e\uff0c\u6807\u51c6\u5316\u5904\u7406 \uff1a\uff08X-X')\/s","3f800801":"Random Forest","1631213d":"log1P(\uff09\u5c31\u662flog(x+1)","9c345866":"\u6570\u636e\u5904\u7406\uff0c\u53d8\u91cf\u8f6c\u5316","8a052ddb":"\u72ec\u70ed\u7f16\u7801\uff1a\u53ea\u6709\u4e00\u4e2a\u5c5e\u6027\u4e3a1\u5176\u4ed6\u4e3a0","9367b85e":"\u5efa\u7acb\u6a21\u578b","066e7aa0":"cross validation","c16d8395":"Ridge Regression"}}