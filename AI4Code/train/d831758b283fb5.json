{"cell_type":{"677f0411":"code","2cc96c26":"code","db4791ca":"code","24704f6c":"code","9d319ef6":"code","9c9628b9":"code","98608af8":"code","e4916246":"code","85048aa3":"code","3c6769a0":"code","13a051ff":"code","b7d217c0":"code","93ec0164":"markdown","f426243c":"markdown","8a5ae87b":"markdown","0ac51c85":"markdown","f7832927":"markdown","4d95901f":"markdown","9cca53a1":"markdown"},"source":{"677f0411":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cc96c26":"import pandas as pd\npd.options.display.float_format = '{:.2f}'.format","db4791ca":"sample_submission = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nsample_submission.shape","24704f6c":"#load items data \nitems = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\n#load items category data\nitemscat = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\n#load shops data\nshops = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\n#load sales train data  \ntrain = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\n#load sales test data  \ntest = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")","9d319ef6":"#merge all data \ntrain_data=train.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(itemscat, on='item_category_id', rsuffix='_').drop([\"item_id_\",\"shop_id_\",\"item_category_id_\" ], axis=1)\n#fix outliers \ntrain_data['item_cnt_day'] = np.where(train_data['item_cnt_day']>420 , 420,train_data['item_cnt_day'] )\ntrain_data['item_price'] = np.where(train_data['item_price']>45000 , 45000,train_data['item_price'] )\n#remove duplicates\ntrain_final = train_data.drop_duplicates()\ndel(train_data)\n\ntest_data=test.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(itemscat, on='item_category_id', rsuffix='_').drop([\"item_id_\",\"shop_id_\",\"item_category_id_\" ], axis=1)\n#test_data['item_cnt_day'] = np.where(test_data['item_cnt_day']>400 , 400,test_data['item_cnt_day'] )\n#test_data['item_price'] = np.where(test_data['item_price']>40000 , 40000,test_data['item_price'] )\ntest_final = test_data.drop_duplicates()\ndel(test_data)","9c9628b9":"#clean data\ntrain_final.shape, test_final.shape","98608af8":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","e4916246":"train_final.columns.T","85048aa3":"#drop original dependent var and id \nX = train_final.drop(['date', 'date_block_num',  'item_price',         'item_name', 'item_category_id', 'shop_name',       'item_category_name' ],axis=1)\n#dt.drop(['SalePrice'], axis=1)\n#id\tbreath_id\tR\tC\ttime_step\tu_in\tu_out\tpressure\tu_in_sum\tu_in_cumsum\tu_in_std\tu_in_min\tu_in_max\tu_in_cumsum_reverse\tu_in_first\tu_in_last\tu_in_lag1\tu_in_lead1\tu_in_lag1_diff\tu_in_lead1_diff\tu_out_sum\ttime_passed\n\ny=train_final.item_cnt_day\n# Split train test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)","3c6769a0":"# now we will split the data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y,shuffle = False,test_size = 0.3)\n ","13a051ff":"# now we will import linear regression\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(x_train,y_train)\n#LinearRegression()\n","b7d217c0":"from sklearn.metrics import mean_squared_error\ny_pred = model.predict(x_test)\nmean_squared_error(y_test,y_pred,squared=False)","93ec0164":"<h4> Now  we will evaluate the model <\/h4>","f426243c":"<h3 style=\"color:red;text-align:center\"> * * *  to be continued.. * * * <\/h3>","8a5ae87b":"<h3 style=\"color:red;text-align:center\"> * * * Please upvote if you like this kernel. * * *<\/h3>  \n  <h4>This is step 3 <br><br>Please visit <a href='https:\/\/www.kaggle.com\/zenstat\/notebook-for-beginners-step-1-load-the-data' > step 1 kernal code <\/a>to understand the basics of loading data. <\/h4>\n  <h4>Please visit<a href='https:\/\/www.kaggle.com\/zenstat\/notebook-for-beginners-step-2-analyze-data' > step 2 kernal code <\/a>to understand the basics of analyzing the data. <\/h4><h4>In this kernal, we will work on the third step of the anaysis which is to select variables and build model. We will learn <br><br>\n    * Feature Engineering<br><br>\n    * Model Selection<br><br>\n    We will load the data same as in <a href='https:\/\/www.kaggle.com\/zenstat\/notebook-for-beginners-step-1-load-the-data' >step 1 kernel<\/a> and <a href='https:\/\/www.kaggle.com\/zenstat\/notebook-for-beginners-step-2-analyze-data' > step 2 kernal.<\/a> Be sure to check it out if you haven't and in case any step is not clear. \n<\/h4>","0ac51c85":"submit= pd.DataFrame()\nsubmit['ID'] = test_final.ID\n#select features \ntest_features = test_final.drop(['ID', 'item_name', 'item_category_id', 'shop_name',  'item_category_name'], axis=1)\npreds = model.predict(test_features)\n#unlog\/exp the prediction  \nfinal_preds = np.exp(preds)\nprint('Original preds :\\n', preds[:5])\nprint('Final preds :\\n', final_preds[:5])\nsubmit['pressure'] = final_preds\n#final submission \nfilename= \"sales_price_\"+datetime.today().strftime('%Y-%m-%d-%H:%M:%S').replace(\"-\",\"_\").replace(\":\",\"_\")+\".csv\"\nsubmit.to_csv(filename, index=False)\nprint(filename ,\" generated\")","f7832927":"#1. linear regression \nfrom sklearn import linear_model\nlr = linear_model.LinearRegression()\nmodel = lr.fit(X_train, y_train)\n#r square \nprint(\"R-Square : \" ,model.score(X_test,y_test))\n#rmse \npreds = model.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nprint ('RMSE: ', mean_squared_error(y_test, preds))","4d95901f":"test_final.head(), train.head(10)","9cca53a1":"<div style=\"background-color: #6c3d75; align:center;color:white;border: 4px solid ; text-align:center;margin: 5px;padding:5px;font-size:20px\">Sales Price Prediction Challenge - Step 3 - Model Building<\/div>\n<div style=\"text-align: center;\">\n<img height=\"100\" width=\"800\"  src=\"https:\/\/sp-ao.shortpixel.ai\/client\/q_glossy,ret_img,w_1000\/https:\/\/www.leadsquared.com\/wp-content\/uploads\/2019\/02\/banner-4.png\" alt=\"C1 Technologies\"><\/div>"}}