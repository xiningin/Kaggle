{"cell_type":{"d75e17b9":"code","133e26d5":"code","36208916":"code","5fc3dee3":"code","7f7a7b2b":"code","ee192d85":"code","cac5b244":"code","e481534f":"code","2444c955":"code","d8f81e63":"code","d81a1641":"code","94fbf60c":"code","51d84eb2":"code","111b99ab":"code","3c06e276":"code","86566917":"code","2a31c6da":"code","74dd20f2":"code","43ba6546":"code","68b5dbd9":"code","e8e6ed97":"code","a44a6605":"code","6fa6283a":"code","4b6d3b02":"code","0888b519":"code","e81e694a":"code","9f145238":"code","61b4f6c6":"code","a0c08b0d":"code","00ad2199":"code","6ffe852a":"code","bdd028ce":"code","dab011ac":"code","1ecc6db0":"code","76262c70":"code","f6a296dd":"code","a5ccbdde":"markdown","ef1d18a0":"markdown"},"source":{"d75e17b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","133e26d5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\nfrom sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n\nfrom scipy.optimize import minimize\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\n\nfrom tqdm import tqdm_notebook\n\nfrom itertools import product\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","36208916":"import pandas as pd\nstock_prices_sample = pd.read_csv(\"..\/input\/stock_prices_sample.csv\")","5fc3dee3":"import pandas as pd\nstock_prices_sample = pd.read_csv(\"..\/input\/stock_prices_sample.csv\")\nstock_prices_samples = \"..\/input\/stock_prices_sample.csv\"","7f7a7b2b":"def mean_absolute_percentage_error(y_true, y_pred):\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","ee192d85":"data = stock_prices_sample","cac5b244":"data.head()","e481534f":"data.info()","2444c955":"data = data[data.TICKER != 'GEF']","d8f81e63":"data = pd.read_csv(stock_prices_samples,index_col=['DATE'], parse_dates=['DATE'])\ndata.head(10)","d81a1641":"data.shape","94fbf60c":"data = data[data.TICKER != 'GEF']\ndata = data[data.TYPE != 'Intraday']","51d84eb2":"data.head()","111b99ab":"drop_cols = ['SPLIT_RATIO', 'EX_DIVIDEND', 'ADJ_FACTOR', 'ADJ_VOLUME', 'ADJ_CLOSE', 'ADJ_LOW', 'ADJ_HIGH', 'ADJ_OPEN', 'VOLUME', 'FREQUENCY', 'TYPE', 'FIGI']","3c06e276":"len(drop_cols)","86566917":"data.columns","2a31c6da":"drop_cols","74dd20f2":"data.drop(drop_cols, axis=1, inplace=True)","43ba6546":"data.head()","68b5dbd9":"data.CLOSE.head()","e8e6ed97":"\nplt.figure(figsize=(17, 8))\nplt.plot(data.CLOSE)\nplt.title('Closing price of New Germany Fund Inc (GF)')\nplt.ylabel('Closing price ($)')\nplt.xlabel('Trading day')\nplt.grid(False)\nplt.show()","a44a6605":"def plot_moving_average(series, window, plot_intervals=False, scale=1.96):\n    \n\n    rolling_mean = series.rolling(window=window).mean()\n    \n    #print(rolling_mean)\n    plt.figure(figsize=(17,8))\n    plt.title('Moving average\\n window size = {}'.format(window))\n    plt.plot(rolling_mean,'r', label='Rolling mean trend')\n    \n    \n    #Plot confidence intervals for smoothed values\n    if plot_intervals:\n        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n        deviation = np.std(series[window:] - rolling_mean[window:])\n        lower_bound = rolling_mean - (mae + scale * deviation)\n        upper_bound = rolling_mean + (mae + scale * deviation)\n        plt.plot(upper_bound, 'r--', label='Upper bound \/ Lower bound')\n        plt.plot(lower_bound, 'r--')\n            \n    plt.plot(series[window:], label='Actual values')\n    plt.legend(loc='best')\n    plt.grid(True)","6fa6283a":"#Smooth by the previous 5 days (by week)\nplot_moving_average(data.CLOSE, 5)","4b6d3b02":"#Smooth by the previous 30 days (by month) WIndow size 30\nplot_moving_average(data.CLOSE, 30)","0888b519":"plot_moving_average(data.CLOSE, 90)","e81e694a":"plot_moving_average(data.CLOSE, 90, plot_intervals=True)","9f145238":"def exponential_smoothing(series, alpha):\n\n    result = [series[0]] # first value is same as series\n    for n in range(1, len(series)):\n        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n    return result","61b4f6c6":"\ndef plot_exponential_smoothing(series, alphas):\n \n    plt.figure(figsize=(17, 8))\n    for alpha in alphas:\n        plt.plot(exponential_smoothing(series, alpha), label=\"Alpha {}\".format(alpha))\n    plt.plot(series.values, \"c\", label = \"Actual\")\n    plt.legend(loc=\"best\")\n    plt.axis('tight')\n    plt.title(\"Exponential Smoothing\")\n    plt.grid(True);","a0c08b0d":"\nplot_exponential_smoothing(data.CLOSE, [0.05, 0.3])","00ad2199":"def double_exponential_smoothing(series, alpha, beta):\n\n    result = [series[0]]\n    for n in range(1, len(series)+1):\n        if n == 1:\n            level, trend = series[0], series[1] - series[0]\n        if n >= len(series): # forecasting\n            value = result[-1]\n        else:\n            value = series[n]\n        last_level, level = level, alpha * value + (1 - alpha) * (level + trend)\n        trend = beta * (level - last_level) + (1 - beta) * trend\n        result.append(level + trend)\n    return result\n\ndef plot_double_exponential_smoothing(series, alphas, betas):\n     \n    plt.figure(figsize=(17, 8))\n    for alpha in alphas:\n        for beta in betas:\n            plt.plot(double_exponential_smoothing(series, alpha, beta), label=\"Alpha {}, beta {}\".format(alpha, beta))\n    plt.plot(series.values, label = \"Actual\")\n    plt.legend(loc=\"best\")\n    plt.axis('tight')\n    plt.title(\"Double Exponential Smoothing\")\n    plt.grid(True)\n    \nplot_double_exponential_smoothing(data.CLOSE, alphas=[0.9, 0.02], betas=[0.9, 0.02])","6ffe852a":"def tsplot(y, lags=None, figsize=(12, 7), syle='bmh'):\n    \n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n        \n    with plt.style.context(style='bmh'):\n        fig = plt.figure(figsize=figsize)\n        layout = (2,2)\n        ts_ax = plt.subplot2grid(layout, (0,0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1,0))\n        pacf_ax = plt.subplot2grid(layout, (1,1))\n        \n        y.plot(ax=ts_ax)\n        p_value = sm.tsa.stattools.adfuller(y)[1]\n        ts_ax.set_title('Time Series Analysis Plots\\n Dickey-Fuller: p={0:.5f}'.format(p_value))\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n        plt.tight_layout()\n        \ntsplot(data.CLOSE, lags=30)\n\n# Take the first difference to remove to make the process stationary\ndata_diff = data.CLOSE - data.CLOSE.shift(1)\n\ntsplot(data_diff[1:], lags=30)","bdd028ce":"#Set initial values and some bounds\nps = range(0, 5)\nd = 1\nqs = range(0, 5)\nPs = range(0, 5)\nD = 1\nQs = range(0, 5)\ns = 5\n\n#Create a list with all possible combinations of parameters\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)","dab011ac":"'''\n\n\ndef optimize_SARIMA(parameters_list, d, D, s):\n    \"\"\"\n        Return dataframe with parameters and corresponding AIC\n        \n        parameters_list - list with (p, q, P, Q) tuples\n        d - integration order\n        D - seasonal integration order\n        s - length of season\n    \"\"\"\n    \n    results = []\n    best_aic = float('inf')\n    \n    for param in tqdm_notebook(parameters_list):\n        try: model = sm.tsa.statespace.SARIMAX(data.CLOSE, order=(param[0], d, param[1]),\n                                               seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)\n        except:\n            continue\n            \n        aic = model.aic\n        \n        #Save best model, AIC and parameters\n        if aic < best_aic:\n            best_model = model\n            best_aic = aic\n            best_param = param\n        results.append([param, model.aic])\n        \n    result_table = pd.DataFrame(results)\n    result_table.columns = ['parameters', 'aic']\n    #Sort in ascending order, lower AIC is better\n    result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)\n    \n    return result_table\n\nresult_table = optimize_SARIMA(parameters_list, d, D, s)\n\n\n\n'''\n","1ecc6db0":"'''def plot_SARIMA(series, model, n_steps):\n    \"\"\"\n        Plot model vs predicted values\n        \n        series - dataset with time series\n        model - fitted SARIMA model\n        n_steps - number of steps to predict in the future\n    \"\"\"\n    \n    data = series.copy().rename(columns = {'CLOSE': 'actual'})\n    data['arima_model'] = model.fittedvalues\n    #Make a shift on s+d steps, because these values were unobserved by the model due to the differentiating\n    data['arima_model'][:s+d] = np.NaN\n    \n    #Forecast on n_steps forward\n    forecast = model.predict(start=data.shape[0], end=data.shape[0] + n_steps)\n    forecast = data.arima_model.append(forecast)\n    #Calculate error\n    error = mean_absolute_percentage_error(data['actual'][s+d:], data['arima_model'][s+d:])\n    \n    plt.figure(figsize=(17, 8))\n    plt.title('Mean Absolute Percentage Error: {0:.2f}%'.format(error))\n    plt.plot(forecast, color='r', label='model')\n    plt.axvspan(data.index[-1], forecast.index[-1],alpha=0.5, color='lightgrey')\n    plt.plot(data, label='actual')\n    plt.legend()\n    plt.grid(True);\n    \n# plot_SARIMA(data, best_model, 5)\nprint(best_model.predict(start=data.CLOSE.shape[0], end=data.CLOSE.shape[0] + 5))\nprint(mean_absolute_percentage_error(data.CLOSE[s+d:], best_model.fittedvalues[s+d:]))\n\n'''","76262c70":"comparison = pd.DataFrame({'actual': [18.93, 19.23, 19.08, 19.17, 19.11, 19.12],\n                          'predicted': [18.96, 18.97, 18.96, 18.92, 18.94, 18.92]}, \n                          index = pd.date_range(start='2018-06-05', periods=6,))","f6a296dd":"plt.figure(figsize=(17, 8))\nplt.plot(comparison.actual)\nplt.plot(comparison.predicted)\nplt.title('Predicted closing price of New Germany Fund Inc (GF)')\nplt.ylabel('Closing price ($)')\nplt.xlabel('Trading day')\nplt.legend(loc='best')\nplt.grid(False)\nplt.show()","a5ccbdde":"\n# stationary, seasonality,autocorrelated \n\n\n1. # Moving average\n1. # Exponential smoothing**\n1. # SARIMA\n\nI am worked this project on Single CPU so when I try to excute the SARIMA model ran into time complexity issues from myend... I used GPU from Kernal even though some issues.\nSo I kept those codes of line in Comments.*\n\n","ef1d18a0":"I have completed this project with help of one article...\n\nTo impliment this project I have good knowledge and experience from below concepts...\n# stationary, seasonality,autocorrelated \nThere are many ways to model a time series in order to make predictions.\n\n1. # moving average\n1. # exponential smoothing\n1. # SARIMA\n\nI am worked this project on Single CPU so when I try to excute the SARIMA model ran into time complexity issues from myend... I used GPU from Kernal even though some issues.\nSo I kept those codes of line in Comments.\n\n"}}