{"cell_type":{"59fc2955":"code","3bad1a60":"code","bf95cbe9":"code","d9f93e4f":"code","78cb9cc9":"code","b48a5137":"code","9b14a25a":"code","759d9801":"code","330c9454":"code","0b7f4b53":"code","59932aaa":"code","2221b4e6":"code","7a97b427":"code","2c414110":"markdown","cd7a72e2":"markdown","5e940411":"markdown","70c58f47":"markdown","7776e548":"markdown","7217f570":"markdown","fbcae0b6":"markdown","2728d140":"markdown","de6c15a2":"markdown"},"source":{"59fc2955":"import gc\nimport os\nimport glob\nimport zipfile\nimport warnings\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport cv2\nimport PIL\nfrom PIL import ImageOps, ImageFilter, ImageDraw","3bad1a60":"DATA_PATH = '..\/input\/'\nos.listdir(DATA_PATH)","bf95cbe9":"# \uc774\ubbf8\uc9c0 \ud3f4\ub354 \uacbd\ub85c\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\n# CSV \ud30c\uc77c \uacbd\ub85c\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))","d9f93e4f":"df_train.head()","78cb9cc9":"df_test.head()","b48a5137":"def crop_boxing_img(img_name, margin=16) :\n    if img_name.split('_')[0] == \"train\" :\n        PATH = TRAIN_IMG_PATH\n        data = df_train\n    elif img_name.split('_')[0] == \"test\" :\n        PATH = TEST_IMG_PATH\n        data = df_test\n        \n    img = PIL.Image.open(os.path.join(PATH, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, \\\n                   ['bbox_x1','bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n\n    width, height = img.size\n    x1 = max(0, pos[0] - margin)\n    y1 = max(0, pos[1] - margin)\n    x2 = min(pos[2] + margin, width)\n    y2 = min(pos[3] + margin, height)\n    \n    if abs(pos[2] - pos[0]) > width or abs(pos[3] - pos[1]) > height:\n        print(f'{img_name} is wrong bounding box, img size: {img.size},  bbox_x1: {pos[0]}, bbox_x2: {pos[2]}, bbox_y1: {pos[1]}, bbox_y2: {pos[3]}')\n        return img\n\n    return img.crop((x1,y1,x2,y2))","9b14a25a":"for i, row in df_train.iterrows():\n    cropped = crop_boxing_img(row['img_file'])\n    cropped.save(row['img_file'])","759d9801":"for i, row in df_test.iterrows():\n    cropped = crop_boxing_img(row['img_file'])\n    cropped.save(row['img_file'])","330c9454":"tmp_imgs = df_train['img_file'][100:105]\nplt.figure(figsize=(12,20))\n\nfor num, f_name in enumerate(tmp_imgs):\n    img = PIL.Image.open(os.path.join(TRAIN_IMG_PATH, f_name))\n    plt.subplot(5, 2, 2*num + 1)\n    plt.title(f_name)\n    plt.imshow(img)\n    plt.axis('off')\n    \n    img_crop = PIL.Image.open(f_name)\n    plt.subplot(5, 2, 2*num + 2)\n    plt.title(f_name + ' cropped')\n    plt.imshow(img_crop)\n    plt.axis('off')","0b7f4b53":"tmp_imgs = df_test['img_file'][100:105]\nplt.figure(figsize=(12,20))\n\nfor num, f_name in enumerate(tmp_imgs):\n    img = PIL.Image.open(os.path.join(TEST_IMG_PATH, f_name))\n    plt.subplot(5, 2, 2*num + 1)\n    plt.title(f_name)\n    plt.imshow(img)\n    plt.axis('off')\n    \n    img_crop = PIL.Image.open(f_name)\n    plt.subplot(5, 2, 2*num + 2)\n    plt.title(f_name + ' cropped')\n    plt.imshow(img_crop)\n    plt.axis('off')","59932aaa":"with zipfile.ZipFile('train_crop.zip','w') as zip: \n        # writing each file one by one \n        for file in glob.glob('train*.jpg'): \n            zip.write(file)","2221b4e6":"with zipfile.ZipFile('test_crop.zip','w') as zip: \n        # writing each file one by one \n        for file in glob.glob('test*.jpg'): \n            zip.write(file)","7a97b427":"!rm -rf *.jpg","2c414110":"## Train Data","cd7a72e2":"# Image Preprocessing - Crop\n\n\uc548\ub155\ud558\uc138\uc694. \uce90\ucf54 3\ud68c \ub300\ud68c\ub294 \uc790\ub3d9\ucc28 \uc774\ubbf8\uc9c0 \ubd84\ub958 \ubb38\uc81c\uc778\ub370\uc694.\n\n\uc81c\uacf5\ub418\ub294 \ub370\uc774\ud130\ub97c \ubcf4\uba74 \uc774\ubbf8\uc9c0\uc5d0 \uc790\ub3d9\ucc28 \uc678\uc5d0 \ubc30\uacbd\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774\ubbf8\uc9c0\uc5d0\uc11c \uc774\ub7f0 \ubc30\uacbd \ubd80\ubd84\uc744 \uc5c6\uc560\uace0 \uc790\ub3d9\ucc28 \ubd80\ubd84\ub9cc \ubaa8\ub378 \ud2b8\ub808\uc774\ub2dd \ud558\ub294\ub370 \uc0ac\uc6a9\ud55c\ub2e4\uba74 \ub354 \uc88b\uc740 \uc131\ub2a5\uc744 \uc5bb\uc744 \uc218 \uc788\uc744\uac70\ub77c \uc0dd\uac01\ub418\ub294\ub370\uc694.\n\n\ub300\ud68c \uc6b4\uc601\uc9c4\uc778 \uae40\ud0dc\uc9c4\ub2d8\uc774 \uacf5\uc720\ud55c \uc544\ub798\uc758 \ubca0\uc774\uc2a4\ub77c\uc778 \ucee4\ub110\uc740 \uc81c\uacf5\ub418\ub294 \uc774\ubbf8\uc9c0\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\uace0 \uc788\uc9c0\ub9cc, \ubc14\uc6b4\ub529 \ubc15\uc2a4 \ucc98\ub9ac\uc5d0 \ub300\ud55c \uc5b8\uae09\uc744 \ud558\uc168\uc2b5\ub2c8\ub2e4.\n\nhttps:\/\/www.kaggle.com\/fulrose\/3rd-ml-month-car-model-classification-baseline\n\n\uadf8\ub798\uc11c \ubcf8 \ucee4\ub110\uc5d0\uc11c\ub294 \ub370\uc774\ud130\uc5d0\uc11c \uc81c\uacf5\ub418\ub294 \ubc14\uc6b4\ub529 \ubc15\uc2a4\ub97c \uae30\uc900\uc73c\ub85c \uc774\ubbf8\uc9c0\ub97c \uc798\ub77c \uc800\uc7a5\ud574\uc11c, \uc774 \ub370\uc774\ud130\ub97c \ubaa8\ub378\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\ub300\ubd80\ubd84\uc758 \ucf54\ub4dc\ub294 \uae40\ud0dc\uc9c4\ub2d8\uc774 \uacf5\uc720\ud55c \ucee4\ub110\uc744 \ubc14\ud0d5\uc73c\ub85c \ud588\uc2b5\ub2c8\ub2e4.","5e940411":"# Process Test Image Data Crop","70c58f47":"# Process Train Image Data Crop","7776e548":"# Zip Train, Test Image","7217f570":"# Cropped Image Eye Checking","fbcae0b6":"# Cropped Image Dataset\n\n\ubcf8 \ucee4\ub110\uc5d0\uc11c \uc0dd\uc131\ud55c Crop \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub294 \uc544\ub798 \ub9c1\ud06c\uc758 Kaggle Dataset\uc73c\ub85c \ub9cc\ub4e4\uc5c8\uc73c\ub2c8 \uc790\uc720\ub86d\uac8c \uc0ac\uc6a9\ud558\uc2dc\uba74 \ub429\ub2c8\ub2e4.\n\nhttps:\/\/www.kaggle.com\/tmheo74\/3rd-ml-month-car-image-cropping-dataset","2728d140":"# Delete Image After Zipping","de6c15a2":"## Test Data"}}