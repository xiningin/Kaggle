{"cell_type":{"bae1f7e5":"code","f1028ba1":"code","437cd1d8":"code","60a4db72":"code","337145b7":"code","82794f45":"code","79f2ac5e":"code","5819f3f7":"code","af780436":"code","c513744f":"code","4c70aea5":"code","c16b79d0":"code","9acee49d":"code","0070ed26":"code","2c0dd4f6":"code","a74dc539":"code","04a50546":"code","0a3e5b73":"code","d455de90":"code","d97e2f5b":"code","43326e33":"code","1bd6684f":"code","ebe714ea":"code","895b3aa5":"code","bc02c9f2":"code","6d32984b":"code","377a8429":"markdown","38062fdb":"markdown","6cd247d2":"markdown"},"source":{"bae1f7e5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import Imputer\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom subprocess import check_output\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# Any results you write to the current directory are saved as output.","f1028ba1":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","437cd1d8":"percent_missing = train_df.isnull().sum() * 100 \/ len(train_df)\nmissing_value_df = pd.DataFrame({'column_name': train_df.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df","60a4db72":"# Cabin variable is 77% missing. \n# Age is about 20% missing\n# Port of Embarkation is missing for two pessengers only","337145b7":"# Categorical features: Survived, Sex, and Embarked. \n# Ordinal features: Pclass.\n# Continuous features: Age, Fare. \n# Discrete: SibSp, Parch.\n# Alpha-numeric: Ticket","82794f45":"train_df[train_df['Embarked'].isnull()]","79f2ac5e":"train_df.describe()","5819f3f7":"train_df.describe(include=['O'])","af780436":"#train_df.groupby('Ticket').size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)\ntrain_df.groupby('Ticket').filter(lambda x: len(x)>1).sort_values(by=['Ticket'], ascending=False)","c513744f":"corr = train_df.corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","4c70aea5":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","c16b79d0":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","9acee49d":"train_df.groupby('Survived').size()","0070ed26":"train_df = train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n","2c0dd4f6":"cleanup_nums = {\"Sex\":     {\"male\": 1, \"female\": 2},\n                \"Embarked\": {\"C\": 1, \"Q\": 2, \"S\": 3}}\ntrain_df.replace(cleanup_nums, inplace=True)\ntest_df.replace(cleanup_nums, inplace=True)","a74dc539":"fill_NaN = Imputer(missing_values=np.nan, strategy='median', axis=1)\nimputed_train_df = pd.DataFrame(fill_NaN.fit_transform(train_df))\nimputed_train_df.columns = train_df.columns\nimputed_train_df.index = train_df.index\n\nimputed_test_df = pd.DataFrame(fill_NaN.fit_transform(test_df))\nimputed_test_df.columns = test_df.columns\nimputed_test_df.index = test_df.index","04a50546":"X_train = imputed_train_df.drop(\"Survived\", axis=1)\nY_train = imputed_train_df[\"Survived\"]\nX_test  = imputed_test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","0a3e5b73":"# Logistic Regression\n\nlogreg = LogisticRegression()\nscores = cross_val_score(logreg, X_train, Y_train, cv=10)\nacc_log = scores.mean()\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n#acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n\n\n#acc_log","d455de90":"# Support Vector Machines\n\nsvc = SVC(C=10)\n\nscores = cross_val_score(svc, X_train, Y_train, cv=10)\nacc_svc = scores.mean()\n\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\nsvc.fit(X_train, Y_train)\n\nY_pred = svc.predict(X_test)\n#acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n#acc_svc","d97e2f5b":"knn = KNeighborsClassifier(n_neighbors = 3)\nscores = cross_val_score(knn, X_train, Y_train, cv=10)\nacc_knn = scores.mean()\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\n#acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n","43326e33":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\nscores = cross_val_score(decision_tree, X_train, Y_train, cv=10)\nacc_decision_tree = scores.mean()\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\n#acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n#acc_decision_tree","1bd6684f":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nscores = cross_val_score(random_forest, X_train, Y_train, cv=10)\nacc_random_forest = scores.mean()\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\n#random_forest.score(X_train, Y_train)\n#acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n#acc_random_forest","ebe714ea":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines', 'KNN',\n              'Decision Tree', 'Random Forest'],\n    'Score': [acc_log, acc_svc, acc_knn, acc_decision_tree, \n              acc_random_forest]})\nmodels.sort_values(by='Score', ascending=False)","895b3aa5":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","bc02c9f2":"#submission.to_csv('..\/output\/submission.csv', index=False)\nsubmission.to_csv('submission.csv', index = False)","6d32984b":"#submission_file = pd.read_csv('submission.csv')","377a8429":"- All names are unique\n- Sex column has 2 values - male and female: about 65% (577\/891) of passengers are male\n- Ticket feature has high duplicate: 681 out of 891 tickets are unique - implying several passengers share ticket\n- Passengers with same Ticket pay the same fare as well\n- Cabin feature has some duplicated too - alternatively several passengers share a cabin\n","38062fdb":"- Passenger id and Names of passenger are unique. Excluding these features from classification task would be a better idea as they do not add much to overall task\n- Ticket number might be dropped too as it contains duplicates and Fare variable captures the overall essence of it\n- Cabin is 77% missing - excluding this would be a good idea too\n- We should try to correct and impute the missing values in Age column as historically it is shown to be significant\n- Fare, Age and Pclass seem to have stronger correlation with survival (below)","6cd247d2":"- All passenger ids are unique\n- Survived is a categorical feature with 0 or 1 values.\n- average age of passengers is 30 while min is less than 1 year old and max is 80 year old\n- Fares varied highly with minimum fare as 0 and  max fare as 512 dollars"}}