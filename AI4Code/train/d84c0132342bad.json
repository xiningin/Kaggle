{"cell_type":{"20023694":"code","8a0fc8f0":"code","74359a47":"code","023c218e":"code","f27b68a0":"code","176d67dc":"code","f4bc145f":"code","4761a8c2":"code","5fbf2caf":"code","d65e2333":"code","2b65c296":"code","7aedf861":"code","783d3826":"code","eb1c7ce2":"code","ee35126b":"code","4f511280":"code","c063fd5e":"code","d12f7d2b":"code","f544d63b":"code","a3dfad2b":"code","23f1d724":"code","c42e4381":"code","5b4160b7":"markdown","dcd1250d":"markdown"},"source":{"20023694":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8a0fc8f0":"import os\nimport time\nimport cv2\nimport matplotlib.pyplot as plt","74359a47":"def process_image(img):\n    \"\"\"Resize, reduce and expand image.\n\n    # Argument:\n        img: original image.\n\n    # Returns\n        image: ndarray(64, 64, 3), processed image.\n    \"\"\"\n    image = cv2.resize(img, (416, 416),\n                       interpolation=cv2.INTER_CUBIC)\n    image = np.array(image, dtype='float32')\n    image \/= 255.\n    image = np.expand_dims(image, axis=0)\n\n    return image","023c218e":"plt.imshow(plt.imread(\"..\/input\/humanvscar\/humanvscar.png\"))","f27b68a0":"img = plt.imread(\"..\/input\/humanvscar\/humanvscar.png\")\nimg.shape","176d67dc":"processed_img = process_image(img)\nprocessed_img.shape","f4bc145f":"def get_classes(file):\n    \"\"\"Get classes name.\n\n    # Argument:\n        file: classes name for database.\n\n    # Returns\n        class_names: List, classes name.\n\n    \"\"\"\n    with open(file) as f:\n        class_names = f.readlines()\n    class_names = [c.strip() for c in class_names]\n\n    return class_names","4761a8c2":"file = \"..\/input\/objects\/object_classes.txt\"\nall_classes = get_classes(file)\nall_classes","5fbf2caf":"def draw(image, boxes, scores, classes, all_classes):\n    \"\"\"Draw the boxes on the image.\n\n    # Argument:\n        image: original image.\n        boxes: ndarray, boxes of objects.\n        classes: ndarray, classes of objects.\n        scores: ndarray, scores of objects.\n        all_classes: all classes name.\n    \"\"\"\n    for box, score, cl in zip(boxes, scores, classes):\n        x, y, w, h = box\n\n        top = max(0, np.floor(x + 0.5).astype(int))\n        left = max(0, np.floor(y + 0.5).astype(int))\n        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n\n        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),\n                    (top, left - 6),\n                    cv2.FONT_HERSHEY_SIMPLEX,\n                    0.6, (0, 0, 255), 1,\n                    cv2.LINE_AA)\n\n        print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n        print('box coordinate x,y,w,h: {0}'.format(box))\n\n    print()","d65e2333":"def detect_image(image, yolo, all_classes):\n    \"\"\"Use yolo v3 to detect images.\n\n    # Argument:\n        image: original image.\n        yolo: YOLO, yolo model.\n        all_classes: all classes name.\n\n    # Returns:\n        image: processed image.\n    \"\"\"\n    pimage = process_image(image)\n\n    start = time.time()\n    boxes, classes, scores = yolo.predict(pimage, image.shape)\n    end = time.time()\n\n    print('time: {0:.2f}s'.format(end - start))\n\n    if boxes is not None:\n        draw(image, boxes, scores, classes, all_classes)\n\n    return image","2b65c296":"import numpy as np\nimport keras.backend as K\nfrom keras.models import load_model\n\nclass YOLO:\n    def __init__(self, obj_threshold, nms_threshold):\n        \"\"\"Init.\n\n        # Arguments\n            obj_threshold: Integer, threshold for object.\n            nms_threshold: Integer, threshold for box.\n        \"\"\"\n        self._t1 = obj_threshold\n        self._t2 = nms_threshold\n        self._yolo = load_model('..\/input\/yolo-weights\/yolo.h5')\n\n    def _process_feats(self, out, anchors, mask):\n        \"\"\"process output features.\n\n        # Arguments\n            out: Tensor (N, N, 3, 4 + 1 +80), output feature map of yolo.\n            anchors: List, anchors for box.\n            mask: List, mask for anchors.\n\n        # Returns\n            boxes: ndarray (N, N, 3, 4), x,y,w,h for per box.\n            box_confidence: ndarray (N, N, 3, 1), confidence for per box.\n            box_class_probs: ndarray (N, N, 3, 80), class probs for per box.\n        \"\"\"\n        grid_h, grid_w, num_boxes = map(int, out.shape[1: 4])\n\n        anchors = [anchors[i] for i in mask]\n        # Reshape to batch, height, width, num_anchors, box_params.\n        anchors_tensor = K.reshape(K.variable(anchors),\n                                   [1, 1, len(anchors), 2])\n        out = out[0]\n        box_xy = K.get_value(K.sigmoid(out[..., :2]))\n        box_wh = K.get_value(K.exp(out[..., 2:4]) * anchors_tensor)\n        box_confidence = K.get_value(K.sigmoid(out[..., 4]))\n        box_confidence = np.expand_dims(box_confidence, axis=-1)\n        box_class_probs = K.get_value(K.sigmoid(out[..., 5:]))\n\n        col = np.tile(np.arange(0, grid_w), grid_w).reshape(-1, grid_w)\n        row = np.tile(np.arange(0, grid_h).reshape(-1, 1), grid_h)\n\n        col = col.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)\n        row = row.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)\n        grid = np.concatenate((col, row), axis=-1)\n\n        box_xy += grid\n        box_xy \/= (grid_w, grid_h)\n        box_wh \/= (416, 416)\n        box_xy -= (box_wh \/ 2.)\n        boxes = np.concatenate((box_xy, box_wh), axis=-1)\n\n        return boxes, box_confidence, box_class_probs\n\n    def _filter_boxes(self, boxes, box_confidences, box_class_probs):\n        \"\"\"Filter boxes with object threshold.\n\n        # Arguments\n            boxes: ndarray, boxes of objects.\n            box_confidences: ndarray, confidences of objects.\n            box_class_probs: ndarray, class_probs of objects.\n\n        # Returns\n            boxes: ndarray, filtered boxes.\n            classes: ndarray, classes for boxes.\n            scores: ndarray, scores for boxes.\n        \"\"\"\n        box_scores = box_confidences * box_class_probs\n        box_classes = np.argmax(box_scores, axis=-1)\n        box_class_scores = np.max(box_scores, axis=-1)\n        pos = np.where(box_class_scores >= self._t1)\n\n        boxes = boxes[pos]\n        classes = box_classes[pos]\n        scores = box_class_scores[pos]\n\n        return boxes, classes, scores\n\n    def _nms_boxes(self, boxes, scores):\n        \"\"\"Suppress non-maximal boxes.\n\n        # Arguments\n            boxes: ndarray, boxes of objects.\n            scores: ndarray, scores of objects.\n\n        # Returns\n            keep: ndarray, index of effective boxes.\n        \"\"\"\n        x = boxes[:, 0]\n        y = boxes[:, 1]\n        w = boxes[:, 2]\n        h = boxes[:, 3]\n\n        areas = w * h\n        order = scores.argsort()[::-1]\n\n        keep = []\n        while order.size > 0:\n            i = order[0]\n            keep.append(i)\n\n            xx1 = np.maximum(x[i], x[order[1:]])\n            yy1 = np.maximum(y[i], y[order[1:]])\n            xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])\n            yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])\n\n            w1 = np.maximum(0.0, xx2 - xx1 + 1)\n            h1 = np.maximum(0.0, yy2 - yy1 + 1)\n            inter = w1 * h1\n\n            ovr = inter \/ (areas[i] + areas[order[1:]] - inter)\n            inds = np.where(ovr <= self._t2)[0]\n            order = order[inds + 1]\n\n        keep = np.array(keep)\n\n        return keep\n\n    def _yolo_out(self, outs, shape):\n        \"\"\"Process output of yolo base net.\n\n        # Argument:\n            outs: output of yolo base net.\n            shape: shape of original image.\n\n        # Returns:\n            boxes: ndarray, boxes of objects.\n            classes: ndarray, classes of objects.\n            scores: ndarray, scores of objects.\n        \"\"\"\n        masks = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n        anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],\n                   [59, 119], [116, 90], [156, 198], [373, 326]]\n\n        boxes, classes, scores = [], [], []\n\n        for out, mask in zip(outs, masks):\n            b, c, s = self._process_feats(out, anchors, mask)\n            b, c, s = self._filter_boxes(b, c, s)\n            boxes.append(b)\n            classes.append(c)\n            scores.append(s)\n\n        boxes = np.concatenate(boxes)\n        classes = np.concatenate(classes)\n        scores = np.concatenate(scores)\n\n        # Scale boxes back to original image shape.\n        width, height = shape[1], shape[0]\n        image_dims = [width, height, width, height]\n        boxes = boxes * image_dims\n\n        nboxes, nclasses, nscores = [], [], []\n        for c in set(classes):\n            inds = np.where(classes == c)\n            b = boxes[inds]\n            c = classes[inds]\n            s = scores[inds]\n\n            keep = self._nms_boxes(b, s)\n\n            nboxes.append(b[keep])\n            nclasses.append(c[keep])\n            nscores.append(s[keep])\n\n        if not nclasses and not nscores:\n            return None, None, None\n\n        boxes = np.concatenate(nboxes)\n        classes = np.concatenate(nclasses)\n        scores = np.concatenate(nscores)\n\n        return boxes, classes, scores\n\n    def predict(self, image, shape):\n        \"\"\"Detect the objects with yolo.\n\n        # Arguments\n            image: ndarray, processed input image.\n            shape: shape of original image.\n\n        # Returns\n            boxes: ndarray, boxes of objects.\n            classes: ndarray, classes of objects.\n            scores: ndarray, scores of objects.\n        \"\"\"\n\n        outs = self._yolo.predict(image)\n        boxes, classes, scores = self._yolo_out(outs, shape)\n\n        return boxes, classes, scores\n","7aedf861":"yolo = YOLO(0.6, 0.5)","783d3826":"plt.imshow(plt.imread(path))","eb1c7ce2":"f = \"carvshuman.jpg\"\npath = '..\/input\/carvshuman\/'+f\nimage = cv2.imread(path)\nimage = detect_image(image, yolo, all_classes)\n\nplt.imshow(image)\n\n","ee35126b":"plt.imread(\"..\/input\/jovenes\/jovenes.jpeg\").shape","4f511280":"f = \"jovenes.jpeg\"\npath = '..\/input\/jovenes\/'+f\nimage = cv2.imread(path)\nimage = detect_image(image, yolo, all_classes)\n\nplt.imshow(image)\n","c063fd5e":"plt.imshow(plt.imread(\"..\/input\/traffic2\/download (2).jfif\"))","d12f7d2b":"f = \"download (2).jfif\"\npath = '..\/input\/traffic2\/'+f\nimage = cv2.imread(path)\nimage = detect_image(image, yolo, all_classes)\n\nplt.imshow(image)","f544d63b":"plt.imshow(plt.imread(\"..\/input\/traffic5\/images.png\"))","a3dfad2b":"f = \"images.png\"\npath = '..\/input\/traffic5\/'+f\nimage = cv2.imread(path)\nimage = detect_image(image, yolo, all_classes)\n\nplt.imshow(image)","23f1d724":"def detect_video(video, yolo, all_classes):\n    \"\"\"Use yolo v3 to detect video.\n\n    # Argument:\n        video: video file.\n        yolo: YOLO, yolo model.\n        all_classes: all classes name.\n    \"\"\"\n    video_path = os.path.join(\"videos\", \"test\", video)\n    camera = cv2.VideoCapture(video_path)\n    cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n\n    # Prepare for saving the detected video\n    sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),\n        int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n    fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n\n    \n    vout = cv2.VideoWriter()\n    vout.open(os.path.join(\"videos\", \"res\", video), fourcc, 20, sz, True)\n\n    while True:\n        res, frame = camera.read()\n\n        if not res:\n            break\n\n        image = detect_image(frame, yolo, all_classes)\n        cv2.imshow(\"detection\", image)\n\n        # Save the video frame by frame\n        vout.write(image)\n\n        if cv2.waitKey(110) & 0xff == 27:\n                break\n\n    vout.release()\n    camera.release()\n    ","c42e4381":"# video = 'library1.mp4'\n# detect_video(video, yolo, all_classes)","5b4160b7":"<font color=\"green\">\nThis function takes the images and transform them with the same image shape as yolo model and makes images ready for prediction.","dcd1250d":"<font color=\"green\">\nThis function reads image classes that are trained in the yolo model."}}