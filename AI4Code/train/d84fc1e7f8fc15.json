{"cell_type":{"d36e8ce9":"code","5269f426":"code","8e2e4209":"code","3f5f0a2e":"code","582aa1f7":"code","394d5f28":"code","8094a0ea":"code","485f1b2d":"code","e35de8a4":"code","d64d395f":"code","b125e416":"code","de279c2b":"code","ab1d59fe":"code","235f9271":"code","8def0099":"code","bf460e65":"code","9c9a074c":"code","eebe30d7":"code","63ff9c73":"code","ca33afb4":"code","d2574323":"code","78b1dbc1":"code","a16893be":"code","d8070319":"code","2f9fa8c8":"code","4fe9e52e":"code","df6b3966":"code","4a7042df":"code","a3837456":"code","aa78d905":"code","70a6a43b":"code","3547628a":"code","88f6ea13":"code","e5171f01":"code","68866a6f":"code","8e74d7f0":"code","450be646":"code","04c21970":"markdown","3f5079ef":"markdown","3c48b37e":"markdown"},"source":{"d36e8ce9":"\n#### Importing Libraries ####\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sn\n%matplotlib inline","5269f426":"### Data Preprocessing ###\n\ndataset = pd.read_csv('..\/input\/financial_data.csv')","8e2e4209":"dataset.head()","3f5f0a2e":"dataset[dataset.columns[1:]].describe()","582aa1f7":"dataset.isna().any()","394d5f28":"dataset2.columns","8094a0ea":"## Histograms\n\ndataset2 = dataset.drop(columns = ['entry_id', 'pay_schedule', 'e_signed'])\n\nfig = plt.figure(figsize=(15, 12))\nplt.suptitle('Histograms of Numerical Columns', fontsize=20)\nfor i in range(dataset2.shape[1]):\n    plt.subplot(6, 3, i + 1)\n    f = plt.gca()\n    f.set_title(dataset2.columns.values[i])\n\n    vals = np.size(dataset2.iloc[:, i].unique())\n    if vals >= 100:\n        vals = 100\n    \n    plt.hist(dataset2.iloc[:, i], bins=vals, color='#3F5D7D')\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","485f1b2d":"dataset2.corrwith(dataset.e_signed).plot.bar(\n        figsize = (20, 10), title = \"Correlation with E Signed\", fontsize = 15,\n        rot = 45, grid = True)","e35de8a4":"\n## Correlation Matrix\nsn.set(style=\"white\")\n\n# Compute the correlation matrix\ncorr = dataset2.corr()","d64d395f":"corr.head()","b125e416":"# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(18, 15))\n\n# Generate a custom diverging colormap\ncmap = sn.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsn.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","de279c2b":"import pandas as pd\n#import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport random\nimport time\n\nrandom.seed(100)","ab1d59fe":"\n### Data Preprocessing ###\n\ndataset = pd.read_csv('financial_data.csv')\n","235f9271":"# Feature Engineering\n\ndataset = dataset.drop(columns = ['months_employed'])\ndataset['personal_account_months'] = (dataset.personal_account_m + (dataset.personal_account_y * 12))\ndataset[['personal_account_m', 'personal_account_y', 'personal_account_months']].head()\n\n","8def0099":"dataset = dataset.drop(columns = ['personal_account_m', 'personal_account_y'])","bf460e65":"dataset.head()","9c9a074c":"# One Hot Encoding\ndataset = pd.get_dummies(dataset)\ndataset.columns\n\n","eebe30d7":"dataset = dataset.drop(columns = ['pay_schedule_semi-monthly'])","63ff9c73":"dataset.head()","ca33afb4":"# Removing extra columns\nresponse = dataset[\"e_signed\"]\nusers = dataset['entry_id']\ndataset = dataset.drop(columns = [\"e_signed\", \"entry_id\"])\n\n","d2574323":"dataset.head()","78b1dbc1":"# Splitting into Train and Test Set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(dataset,\n                                                    response,\n                                                    test_size = 0.2,\n                                                    random_state = 0)","a16893be":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X= StandardScaler()\nX_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\nX_test2 = pd.DataFrame(sc_X.transform(X_test))\nX_train2.columns = X_train.columns.values\nX_test2.columns = X_test.columns.values\nX_train2.index = X_train.index.values\nX_test2.index = X_test.index.values\nX_train = X_train2\nX_test = X_test2","d8070319":"#### Model Building ####\n\n### Comparing Models\n\n## Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0, penalty = 'l1')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nresults = pd.DataFrame([['Linear Regression (Lasso)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n","2f9fa8c8":"## SVM (Linear)\nfrom sklearn.svm import SVC\nclassifier = SVC(random_state = 0, kernel = 'linear')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","4fe9e52e":"## SVM (rbf)\nfrom sklearn.svm import SVC\nclassifier = SVC(random_state = 0, kernel = 'rbf')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","df6b3966":"## Randomforest\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n                                    criterion = 'entropy')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest (n=100)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","4a7042df":"results","a3837456":"## K-fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X= X_train, y = y_train,\n                             cv = 10)\nprint(\"Random Forest Classifier Accuracy: %0.2f (+\/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))\n","aa78d905":"# Applying Grid Search\n\n# Round 1: Entropy\nparameters = {\"max_depth\": [3, None],\n              \"max_features\": [1, 5, 10],\n              'min_samples_split': [2, 5, 10],\n              'min_samples_leaf': [1, 5, 10],\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"entropy\"]}\n\nfrom sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n                           param_grid = parameters,\n                           scoring = \"accuracy\",\n                           cv = 10,\n                           n_jobs = -1)\n\nt0 = time.time()\ngrid_search = grid_search.fit(X_train, y_train)\nt1 = time.time()\nprint(\"Took %0.2f seconds\" % (t1 - t0))\n\nrf_best_accuracy = grid_search.best_score_\nrf_best_parameters = grid_search.best_params_\nrf_best_accuracy, rf_best_parameters","70a6a43b":"# Round 2: Entropy\nparameters = {\"max_depth\": [None],\n              \"max_features\": [3, 5, 7],\n              'min_samples_split': [8, 10, 12],\n              'min_samples_leaf': [1, 2, 3],\n              \"bootstrap\": [True],\n              \"criterion\": [\"entropy\"]}\n\nfrom sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n                           param_grid = parameters,\n                           scoring = \"accuracy\",\n                           cv = 10,\n                           n_jobs = -1)\n\nt0 = time.time()\ngrid_search = grid_search.fit(X_train, y_train)\nt1 = time.time()\nprint(\"Took %0.2f seconds\" % (t1 - t0))\n\nrf_best_accuracy = grid_search.best_score_\nrf_best_parameters = grid_search.best_params_\nrf_best_accuracy, rf_best_parameters\n","3547628a":"# Round 1: Gini\nparameters = {\"max_depth\": [3, None],\n              \"max_features\": [1, 5, 10],\n              'min_samples_split': [2, 5, 10],\n              'min_samples_leaf': [1, 5, 10],\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\"]}\n# Make sure classifier points to the RF model\nfrom sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(estimator = classifier, \n                           param_grid = parameters,\n                           scoring = \"accuracy\",\n                           cv = 10,\n                           n_jobs = -1)\n\nt0 = time.time()\ngrid_search = grid_search.fit(X_train, y_train)\nt1 = time.time()\nprint(\"Took %0.2f seconds\" % (t1 - t0))\n\nrf_best_accuracy = grid_search.best_score_\nrf_best_parameters = grid_search.best_params_\nrf_best_accuracy, rf_best_parameters","88f6ea13":"# Round 2: Gini\nparameters = {\"max_depth\": [None],\n              \"max_features\": [8, 10, 12],\n              'min_samples_split': [2, 3, 4],\n              'min_samples_leaf': [8, 10, 12],\n              \"bootstrap\": [True],\n              \"criterion\": [\"gini\"]}\n\nfrom sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n                           param_grid = parameters,\n                           scoring = \"accuracy\",\n                           cv = 10,\n                           n_jobs = -1)\n\nt0 = time.time()\ngrid_search = grid_search.fit(X_train, y_train)\nt1 = time.time()\nprint(\"Took %0.2f seconds\" % (t1 - t0))\n\nrf_best_accuracy = grid_search.best_score_\nrf_best_parameters = grid_search.best_params_\nrf_best_accuracy, rf_best_parameters\n","e5171f01":"# Predicting Test Set\ny_pred = grid_search.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest (n=100, GSx2 + Gini)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","68866a6f":"## EXTRA: Confusion Matrix\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\nplt.figure(figsize = (10,7))\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","8e74d7f0":"# Formatting Final Results\n\nfinal_results = pd.concat([y_test, users], axis = 1).dropna()\nfinal_results['predictions'] = y_pred\nfinal_results = final_results[['entry_id', 'e_signed', 'predictions']]\n","450be646":"final_results","04c21970":"# Model Evaluation","3f5079ef":"# Feature Enggineering","3c48b37e":"# EDA"}}