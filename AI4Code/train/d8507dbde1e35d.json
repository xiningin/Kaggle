{"cell_type":{"0b319030":"code","dc23d744":"code","aaf1e1b3":"code","ef9249f2":"code","c5034966":"code","7434a699":"code","83f774d0":"code","bb94c64e":"code","4b7df816":"code","a329ae35":"code","a882e6a8":"code","de63220e":"code","2f1be5e7":"code","bbf2a46e":"code","0311f124":"markdown","00446594":"markdown","77f60e00":"markdown","c34a5e22":"markdown","51af749e":"markdown","96d454ce":"markdown","1edef7e1":"markdown","7ca4e7b5":"markdown","8e50f8e5":"markdown"},"source":{"0b319030":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc23d744":"import pandas as pd\ndata=pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndata.head()","aaf1e1b3":"data=data.dropna()\ndata.columns","ef9249f2":"df=data[['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi','stroke']]\ndf.head()","c5034966":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf['gender']=le.fit_transform(data['gender'])\ndf['ever_married']=le.fit_transform(data['ever_married'])\ndf['work_type']=le.fit_transform(data['work_type'])\ndf['Residence_type']=le.fit_transform(data['Residence_type'])\ndf['smoking_status']=le.fit_transform(data['smoking_status'])\ndf.head()","7434a699":"data.shape,df.shape","83f774d0":"y=df['stroke']\nx=df.drop('stroke',axis=1)\nx.shape,y.shape","bb94c64e":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.countplot(y)\nplt.xticks([0,1],['NO','YES'])\nplt.title('COUNT PLOT')","4b7df816":"from sklearn.model_selection import train_test_split as tts\nx_train,x_test,y_train,y_test=tts(x,y,test_size=0.2)","a329ae35":"import tensorflow as tf","a882e6a8":"ann=tf.keras.Sequential()\n\nann.add(tf.keras.layers.Dense(units=25,activation='relu'))\n\nann.add(tf.keras.layers.Dense(units=25,activation='relu'))\n\nann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n\nann.compile('adam','binary_crossentropy',metrics=['accuracy'])","de63220e":"result=ann.fit(x_train,y_train,epochs=10)","2f1be5e7":"from sklearn.metrics import confusion_matrix\ny_pred=[]\nfor i in ann.predict(x_test):\n    if i>0.5:\n        y_pred.append(1)\n    if i<0.5:\n        y_pred.append(0)\nconfusion_matrix(y_test,y_pred)","bbf2a46e":"from sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_test,y_pred)\naccuracy","0311f124":"# DROPPING THE NULL VALUES","00446594":"# CREATING ARTIFICIAL NEURAL NETWORK MODEL[ANN]","77f60e00":"# PLOTTING THE COUNTS OF STROKE","c34a5e22":"# ENCODING THE NON NUMERICAL COLUMNS","51af749e":"# ACCURACY SCORE FOR TESTING DATA","96d454ce":"# IMPORTING THE DATA","1edef7e1":"# TRAINING ANN MODEL","7ca4e7b5":"# SPLITTING THE DATA INTO TRAINING AND TESTING DATA","8e50f8e5":"# CREATING CONFUSION MATRIX FOR THE ACTUAL AND PREDICTED VALUE"}}