{"cell_type":{"a65c3618":"code","b886c4c7":"code","9b3eeeed":"code","aa9bb6e0":"code","9b82d930":"code","291ef00a":"code","cdecd997":"code","e37d8934":"code","f8a9b67a":"code","a42999b7":"code","640e48b4":"code","09292d76":"code","c408af18":"code","1baf8de3":"code","eadde5a6":"markdown","2956b961":"markdown","47ce395f":"markdown","2853e6f4":"markdown","173acd4c":"markdown","bc3a96a0":"markdown","56e04e5d":"markdown"},"source":{"a65c3618":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nfrom torchvision.io import read_image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport os\nimport cProfile\nimport pstats\nfrom pstats import SortKey\nfrom PIL import Image","b886c4c7":"def process_image(im, final_size, destination, index):\n    bg = (127, 127, 127)\n    w, h = im.size\n    if w == h:\n        image = im.resize(final_size)\n        image.save(os.path.join(destination, index + \".jpg\"))\n    elif w > h:\n        image = Image.new(im.mode, (w, w), bg)\n        image.paste(im, (0, (w - h) \/\/ 2))\n        image = image.resize(final_size)\n        image.save(os.path.join(destination, index + \".jpg\"))\n    elif h > w:\n        image = Image.new(im.mode, (h, h), bg)\n        image.paste(im, ((h - w) \/\/ 2, 0))\n        image = image.resize(final_size)\n        image.save(os.path.join(destination, index + \".jpg\"))","9b3eeeed":"def preprocess_images(labels_csv, source, destination, final_size):\n    print(\"Starting image preprocessing...\")\n    if not os.path.isdir(destination):\n        os.mkdir(destination)\n    df = pd.read_csv(labels_csv)\n    indexes = df['Id']\n    i = 0\n    n = len(indexes)\n    t0 = datetime.now()\n    processed = 0\n    skipped = 0\n    for index in indexes:\n        try:\n            if (i + 1) % (n \/\/ 10) == 0:\n                print(f\"Checking image {i + 1}\/{n}\")\n        except ZeroDivisionError:\n            pass\n        if os.path.isfile(os.path.join(destination, index + \".jpg\")):\n            with Image.open(os.path.join(destination, index + \".jpg\")) as dst_im:\n                if dst_im.size == final_size:\n                    skipped += 1\n                    pass\n                else:\n                    with Image.open(os.path.join(source, index + \".jpg\")) as src_im:\n                        process_image(src_im, final_size, destination, index)\n                        processed += 1\n        else:\n            with Image.open(os.path.join(source, index + \".jpg\")) as src_im:\n                process_image(src_im, final_size, destination, index)\n                processed += 1\n        i += 1\n    print(f\"Image preprocessing took {datetime.now() - t0}, processed {processed} images, skipped {skipped}\")","aa9bb6e0":"class PawpularityDataset(Dataset):\n    def __init__(self, csv, img_dir, tr_test, split=0.8, transformations=None):\n        self.transformations = transformations\n        self.img_dir = img_dir\n        self.df = pd.read_csv(csv)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)\n        if tr_test == 'train':\n            self.df = self.df.truncate(after=np.floor(len(self.df) * split))\n        else:\n            self.df = self.df.truncate(before=np.floor(len(self.df) * split))\n        self.targets = self.df['Pawpularity']\n        self.targets = self.targets.to_numpy(dtype='float32')\n        self.indexes = self.df['Id']\n        self.metadata = self.df.drop(columns=['Pawpularity', 'Id'])\n        self.metadata = self.metadata.to_numpy(dtype=\"float32\")\n\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, item):\n        img_path = os.path.join(self.img_dir, self.indexes.iloc[item])\n        image = read_image(img_path + \".jpg\")\n        if self.transformations:\n            image = self.transformations(image)\n        image = image.type(torch.float32)\n        image = (image - torch.mean(image)) \/ torch.std(image)\n        metadata = torch.from_numpy(self.metadata[item])\n        target = torch.tensor(self.targets[item].reshape(-1))\n        data = (image, metadata)\n        return data, target","9b82d930":"class PawpularityModel(nn.Module):\n\n    def __init__(self, img_size):\n        super(PawpularityModel, self).__init__()\n        self.image_cnn = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(2),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(2),\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(2),\n            nn.Flatten()\n        )\n        self.metadata_ann = nn.Sequential(\n            nn.Linear(12, 512),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Dropout()\n        )\n        self.dense = nn.Sequential(\n            nn.Linear(img_size[0] * img_size[1] * 2 + 512, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 1024),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(1024, 1)\n        )\n\n    def forward(self, X):\n        image, metadata = X\n        image, metadata = image.to(device), metadata.to(device)\n        ann_out = self.metadata_ann(metadata)\n        cnn_out = self.image_cnn(image)\n        dense_input = torch.cat((cnn_out, ann_out), dim=1)\n        out = self.dense(dense_input)\n        return out","291ef00a":"def train(model, device, criterion, optimizer, train_batches, test_batches,\n          baseline_rmse, train_loader, test_loader, epochs):\n    train_losses = []\n    test_losses = []\n    epochs = epochs\n    t0 = datetime.now()\n    print(\"Starting training...\")\n    for epoch in range(epochs):\n        print(f\"Starting epoch {epoch + 1}.\")\n        model.train()\n        train_loss = []\n        batch = 0\n        for inputs, targets in train_loader:\n            batch += 1\n            targets = targets.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            loss.backward()\n            optimizer.step()\n\n            train_loss.append(loss.item())\n            if batch % (train_batches \/\/ 10) == 0:\n                print(f\"Processed train batch {batch}\/{int(np.ceil(train_batches))}\")\n\n        train_losses.append(np.mean(train_loss))\n\n        batch = 0\n        model.eval()\n        test_loss = []\n        for inputs, targets in test_loader:\n            batch += 1\n            targets = targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            test_loss.append(loss.item())\n            if batch % (test_batches \/\/ 10) == 0:\n                print(f\"Processed test batch {batch}\/{int(np.ceil(test_batches))}\")\n\n        test_losses.append(np.mean(test_loss))\n        dt = datetime.now() - t0\n        train_epoch_loss = train_losses[-1]\n        test_epoch_loss = test_losses[-1]\n        print(f\"Epoch:          {epoch + 1}\/{epochs}\\n\"\n              f\"Train loss:     {train_epoch_loss:.4f} (root {np.sqrt(train_epoch_loss):.4f})\\n\"\n              f\"Baseline diff:  {np.sqrt(train_epoch_loss) - baseline_rmse:.4f}\\n\"\n              f\"Test loss:      {test_epoch_loss:.4f} (root {np.sqrt(test_epoch_loss):.4f})\\n\"\n              f\"Baseline diff:  {np.sqrt(test_epoch_loss) - baseline_rmse:.4f}\\n\"\n              f\"Total duration: {dt}\")\n\n    plt.plot(train_losses, label=\"Train losses\")\n    plt.plot(test_losses, label=\"Test losses\")\n    plt.show()","cdecd997":"def grade(model, device, train_batches, test_batches, baseline_rmse, train_loader, test_loader):\n    print(\"Starting grading...\")\n    with torch.no_grad():\n        train_outputs = []\n        train_targets = []\n        model.train()\n        batch = 0\n        for inputs, targets in train_loader:\n            batch += 1\n            if batch % (train_batches \/\/ 10) == 0:\n                print(f\"Grading training batch {batch}\/{int(np.ceil(train_batches))}...\")\n            targets = targets.to(device)\n            outputs = model(inputs).cpu().numpy().flatten().tolist()\n            train_targets += targets.cpu().numpy().flatten().tolist()\n            train_outputs += outputs\n\n        train_outputs = np.array(train_outputs)\n        train_targets = np.array(train_targets)\n        train_diff = train_targets - train_outputs\n        plt.hist(train_diff, bins=range(-75, 75), label=\"Train diff\", color='blue')\n        plt.show()\n\n        train_rmse = np.sqrt(((train_targets - train_outputs) ** 2).mean())\n\n        test_outputs = []\n        test_targets = []\n        model.eval()\n        batch = 0\n        for inputs, targets in test_loader:\n            batch += 1\n            if batch % (test_batches \/\/ 10) == 0:\n                print(f\"Grading test batch {batch}\/{int(np.ceil(test_batches))}...\")\n            targets = targets.to(device)\n            outputs = model(inputs).cpu().numpy().flatten().tolist()\n            test_targets += targets.cpu().numpy().flatten().tolist()\n            test_outputs += outputs\n\n        test_outputs = np.array(test_outputs)\n        test_targets = np.array(test_targets)\n        test_diff = test_targets - test_outputs\n        plt.hist(test_diff, bins=range(-75, 75), label=\"Test diff\", color='orange')\n        plt.show()\n\n        test_rmse = np.sqrt(((test_targets - test_outputs) ** 2).mean())\n        print(f\"Train RMSE: {train_rmse:.4f}, baseline diff: {train_rmse - baseline_rmse:.4f}\\n\"\n              f\"Test RMSE:  {test_rmse:.4f}, baseline diff: {test_rmse - baseline_rmse:.4f}\")","e37d8934":"img_size = (128, 128)\npreprocess_images('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv', '\/kaggle\/input\/petfinder-pawpularity-score\/train', 'train-post', img_size)","f8a9b67a":"train_dataset = PawpularityDataset(csv='\/kaggle\/input\/petfinder-pawpularity-score\/train.csv',\n                                   img_dir='train-post',\n                                   tr_test='train',\n                                   transformations=None)\n\ntest_dataset = PawpularityDataset(csv='\/kaggle\/input\/petfinder-pawpularity-score\/train.csv',\n                                  img_dir='train-post',\n                                  tr_test='test')","a42999b7":"batch_sz = 96\nbaseline_rmse = 20.59095133915306\ntrain_batches = train_dataset.__len__() \/ batch_sz\ntest_batches = test_dataset.__len__() \/ batch_sz\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_sz, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_sz, shuffle=False)\n\nmodel = PawpularityModel(img_size)\ndevice = torch.device(\"cuda:0\")\nmodel.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-6)","640e48b4":"train(model, device, criterion, optimizer, train_batches, test_batches, baseline_rmse, train_loader, test_loader, epochs=50)\n","09292d76":"grade(model, device, train_batches, test_batches, baseline_rmse, train_loader, test_loader)","c408af18":"with torch.no_grad():\n    preprocess_images('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv', '\/kaggle\/input\/petfinder-pawpularity-score\/test', 'test-post', img_size)\n    submission = pd.DataFrame(columns=['Id', 'Pawpularity'])\n    df = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')\n    metadata_df = df.drop(columns=['Id'])\n    metadata = metadata_df.to_numpy(dtype=\"float32\")\n    indexes = df['Id']\n    ids = []\n    pawpularities = []\n    i = 0\n    for index in indexes:\n        ids.append(index)\n        image = read_image(os.path.join('test-post', index + \".jpg\"))\n        image = image.type(torch.float32)\n        image = (image - torch.mean(image)) \/ torch.std(image)\n        image = image.reshape(1, 3, img_size[0], img_size[1])\n        md = metadata[i]\n        md = md.reshape(1, 12)\n        md = torch.from_numpy(md)\n        data = (image, md)\n        output = model(data).cpu().item()\n        pawpularities.append(output)\n        i += 1\n\n    submission['Id'] = ids\n    submission['Pawpularity'] = pawpularities\n    submission.to_csv('submission.csv', index=False)\n    print(\"Saved submission.\")","1baf8de3":"!cat submission.csv","eadde5a6":"## Training parameters","2956b961":"## Image preprocessing","47ce395f":"## Grading","2853e6f4":"# Imports and definitions","173acd4c":"## Training run","bc3a96a0":"## Datasets instantiation","56e04e5d":"## Create submission"}}