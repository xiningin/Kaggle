{"cell_type":{"f7f580d7":"code","aba0e8e7":"code","e361de62":"code","0d683cb5":"code","adb39a4a":"code","bc9732be":"code","c36eaa15":"code","b89860ab":"code","0e8676b7":"code","5e2d8ad4":"code","2dae8bef":"code","f081dd7e":"code","05310880":"code","f534fff3":"code","901c23c2":"code","05fb4cdc":"code","7871524d":"markdown","d34a9365":"markdown"},"source":{"f7f580d7":"import numpy as np\nimport pandas as pd\n\nimport os\nimport gc\nimport glob\nimport random\nimport shutil\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom torch.optim.lr_scheduler import ExponentialLR\n\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nimport warnings\nwarnings.simplefilter('ignore')","aba0e8e7":"N_SPLITS = 10\nSEED = 42\n\nBATCH_SIZE = 1024\nWORKERS = 4\nEPOCHS = 100\n\nLEARNING_RATE = 2e-3\n\nMODEL_PATH = \"models\"\nTB_LOG_NAME = \"lightning_logs\"","e361de62":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    pl.utilities.seed.seed_everything(seed, workers=True)\n    \nseed_everything(SEED)","0d683cb5":"train_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')","adb39a4a":"train_df.target.value_counts(normalize=True)","bc9732be":"train_df = train_df[train_df.columns[1:]]\n\ntrain_df['fold'] = -1\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n    train_df.loc[val_idx, 'fold'] = fold","c36eaa15":"train_df","b89860ab":"!pip install -q monai-weekly","0e8676b7":"from torch.utils.data import TensorDataset, DataLoader\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom monai.metrics import ROCAUCMetric\nfrom pytorch_lightning.core.memory import ModelSummary\n\n\nclass Model(pl.LightningModule):\n    def __init__(self, in_size, learning_rate, num_targets=1, hidden_size=384):\n        super().__init__()\n        self.in_size = in_size\n        self.lr = learning_rate\n        self.num_targets = num_targets\n        self.hidden_size = hidden_size\n        \n        self.fc1 = nn.Linear(self.in_size, self.hidden_size)\n        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size\/\/2)\n        self.fc3 = nn.Linear(self.hidden_size\/\/2, self.hidden_size\/\/4)\n        self.fc4 = nn.Linear(self.hidden_size\/\/4, self.hidden_size\/\/2)\n        self.fc5 = nn.Linear(self.hidden_size\/\/2, self.hidden_size)\n        self.fc6 = nn.Linear(self.hidden_size+self.hidden_size\/\/4, 128)\n        self.fc7 = nn.Linear(128, self.num_targets)\n        self.relu = F.relu\n        self.swish = F.hardswish\n        self.flatten = nn.Flatten()\n        self.dropout1 = nn.Dropout(0.45)\n        self.dropout2 = nn.Dropout(0.35)\n        self.dropout3 = nn.Dropout(0.25)\n        self.batchnorm1 = nn.BatchNorm1d(self.hidden_size)\n        self.batchnorm2 = nn.BatchNorm1d(self.hidden_size\/\/2)\n        self.batchnorm3 = nn.BatchNorm1d(self.hidden_size\/\/4)\n        self.batchnorm4 = nn.BatchNorm1d(128)\n        self.concat = torch.cat\n        self.multiply = torch.mul\n        self.roc_auc_metric = ROCAUCMetric()\n    \n    def forward(self, x):\n        x1 = self.flatten(x)\n        x1 = self.swish(self.fc1(x1))\n        x1 = self.batchnorm1(x1)\n        x2 = self.dropout1(x1)\n        \n        x2 = self.swish(self.fc2(x2))\n        x2 = self.batchnorm2(x2)\n        x3 = self.dropout2(x2)\n\n        x3 = self.swish(self.fc3(x3))\n        x3 = self.batchnorm3(x3)\n        x3 = self.dropout3(x3)\n        \n        x4 = self.swish(self.fc4(x3))\n        x4 = self.batchnorm2(x4)\n        x4 = self.multiply(x2, x4)\n        x4 = self.dropout2(x4)\n        \n        x5 = self.swish(self.fc5(x4))\n        x5 = self.batchnorm1(x5)\n        x5 = self.multiply(x1, x5)\n        x5 = self.dropout1(x5)\n\n        x = self.concat((x3, x5), dim=1)\n        x = self.swish(self.fc6(x))\n        x = self.batchnorm4(x)\n        x = self.dropout3(x)\n        \n        x = self.fc7(x)\n        \n        return x\n    \n    def training_step(self, batch, batch_idx):\n        X, y = batch\n        y_hat = self(X).squeeze(1)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y)  \n        self.log('loss', loss)\n        return {'loss': loss}\n        \n    def validation_step(self, batch, batch_idx):\n        X, y = batch\n        y_hat = self(X).squeeze(1)\n        self.roc_auc_metric(y_hat, y)      \n    \n    def validation_epoch_end(self, training_step_outputs):\n        roc_auc = self.roc_auc_metric.aggregate()\n        self.roc_auc_metric.reset()\n        self.log('roc_auc', roc_auc)\n        \n    def predict_step(self, X, batch_idx: int, dataloader_idx: int = None):\n        return self(X[0])    \n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, eps=1e-8, weight_decay=1e-2, amsgrad=False)\n        return optimizer","5e2d8ad4":"pipes = []\n\nfor fold in range(N_SPLITS):\n    print('Fold:', fold)\n    train_data = train_df[train_df['fold']!=fold]\n    val_data = train_df[train_df['fold']==fold]\n    \n    X_train = train_data.drop(['target', 'fold'], axis=1)\n    y_train = train_data['target']\n    \n    X_val = val_data.drop(['target', 'fold'], axis=1)\n    y_val = val_data['target']\n\n    pipe = Pipeline([\n            (\"scaler\", MinMaxScaler()),\n    ])\n\n    pipe.fit(X_train)\n    pipes.append(pipe)\n    \n    X_train = pd.DataFrame(pipe.transform(X_train), columns=X_train.columns, index=X_train.index)\n    X_val = pd.DataFrame(pipe.transform(X_val), columns=X_val.columns, index=X_val.index)\n    \n    train_ds = TensorDataset(torch.FloatTensor(X_train.values), torch.FloatTensor(y_train.values))\n    val_ds = TensorDataset(torch.FloatTensor(X_val.values), torch.FloatTensor(y_val.values))\n\n    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\n    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS)\n\n    model = Model(X_train.shape[1],\n                  LEARNING_RATE,\n                  1,\n                  384,\n                 )\n\n    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n        dirpath=MODEL_PATH,\n        filename=f'model_{fold}_' + '{roc_auc:.3}',\n        monitor='roc_auc',\n        mode='max',\n        save_weights_only=True)\n\n    logger = TensorBoardLogger(\n        save_dir=os.getcwd(),\n        version=fold,\n        name=TB_LOG_NAME\n    )\n \n    early_stop_callback = EarlyStopping(\n        monitor='loss',\n        min_delta=0.00,\n        patience=3,\n        verbose=False,\n        mode='min'\n    )\n    \n    # print(ModelSummary(model))\n    trainer = pl.Trainer(\n        fast_dev_run=False,\n        max_epochs=EPOCHS,\n        gpus=1,\n        precision=32,\n        limit_train_batches=1.0,\n        limit_val_batches=1.0, \n        num_sanity_val_steps=0,\n        val_check_interval=1.0, \n        callbacks=[checkpoint_callback],\n        logger=logger\n     )\n\n    trainer.fit(model, train_dl, val_dl)\n    \n    del model, trainer, val_data, train_data, X_train, X_val, y_train, y_val, train_ds, val_ds, train_dl, val_dl\n    gc.collect()\n    torch.cuda.empty_cache()","2dae8bef":"trained_models = []\nfor i in range(N_SPLITS):\n    list = glob.glob(f\".\/models\/model_{i}_*.ckpt\")\n    list.sort()\n    trained_models.append(list[-1])","f081dd7e":"trained_models","05310880":"all_preds = []\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\ntest_df = test_df[test_df.columns[1:]]\n\nsample_df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\ntrainer = pl.Trainer(gpus=1)\n\nmodel = Model(test_df.shape[1], LEARNING_RATE)\nfor model_name in trained_models:\n    fold = int(model_name.split('_')[1])\n    pipe = pipes[fold]\n    test_data = pipe.transform(test_df)\n    \n    model.load_state_dict(torch.load(model_name)['state_dict'])\n    test_ds = TensorDataset(torch.FloatTensor(test_data))\n    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS)\n    \n    preds = trainer.predict(model, test_dl)\n    preds = torch.cat(preds).cpu().numpy().flatten()\n    \n    all_preds.append(preds)","f534fff3":"np_all_preds = np.array(all_preds)\n\nnp_all_preds[:, :4], np_all_preds[:, -4:]","901c23c2":"avg_preds = np.mean(np_all_preds, axis=0)\n\navg_preds[:4], avg_preds[-4:]","05fb4cdc":"sample_df['target'] = avg_preds\nsample_df.to_csv('submission.csv', index=False)\nsample_df","7871524d":"<h1> Network implementation <\/h1>","d34a9365":"<h1> Inference <\/h1>"}}