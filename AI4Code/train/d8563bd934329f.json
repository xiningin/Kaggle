{"cell_type":{"310c7b7d":"code","c29e105c":"code","91056c16":"code","db7230bd":"code","7b049b7b":"code","bf2707dd":"code","c30e51a0":"code","3054789c":"code","2f5b2b1c":"code","b27dc3e7":"code","21859aa6":"code","ab746a77":"code","749f3c17":"code","5ee68ae6":"code","7a46a8ba":"code","f797669d":"code","f42f0ad0":"code","520ae57f":"code","dc4ab917":"code","1ac315ba":"code","00fd70d0":"code","972e9ca0":"code","f4535981":"code","e8ab8968":"code","5ed76ff2":"code","b8bd8cdb":"code","3c543a83":"code","af8ac5f3":"code","c08d4838":"code","072fd43f":"code","db6412d5":"code","77be5f96":"code","06f1f57a":"code","5695d98c":"code","b10a19f7":"code","3da12ac2":"code","8ca57a80":"code","59a01cdb":"code","b0920eb0":"code","86e8eb1a":"code","74a7d46c":"code","19c6537d":"markdown","73a3587d":"markdown","bbeb32b4":"markdown","39c7cdc1":"markdown","5ddf6b7b":"markdown","3afc093d":"markdown","d2fe7bed":"markdown","56c08df8":"markdown","d708be74":"markdown","f4c68e44":"markdown","8566a290":"markdown","934f1ab7":"markdown","8d0f434b":"markdown","e102b798":"markdown"},"source":{"310c7b7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c29e105c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing","91056c16":"df = pd.read_csv(\"..\/input\/zomato-restaurants-data\/zomato.csv\", encoding = \"ISO-8859-1\")\ndf.head()","db7230bd":"df_num = df.drop([\"Cuisines\", \"Restaurant Name\", \"Address\", \"Locality\", \"Locality Verbose\", \"Rating color\", \"City\", \"Currency\",  \"Restaurant ID\"], axis = 1)#\"Latitude\", \"Longitude\",\ndf_num[\"Has Table booking\"] = df_num[\"Has Table booking\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Has Online delivery\"] = df_num[\"Has Online delivery\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Is delivering now\"] = df_num[\"Is delivering now\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Switch to order menu\"] = df_num[\"Switch to order menu\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Rating text\"] = df_num[\"Rating text\"].map({\"Excellent\":5, \"Very Good\":4 ,\"Good\":3, \"Average\":2, \"Poor\":1, \"Not rated\":0})","7b049b7b":"df_num.head()","bf2707dd":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u043d\u0443\u0436\u043d\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\nfrom sklearn.model_selection import train_test_split\n\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 X, y\n# X --- \u0432\u0441\u044f \u0442\u0430\u0431\u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0442\u0430\u0440\u0433\u0435\u0442\u0430\n# y --- \u0442\u0430\u0440\u0433\u0435\u0442 (\u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f)\ny = df_num['Aggregate rating'] \nX = df_num.drop('Aggregate rating', axis=1) \n\nfrom sklearn.preprocessing import StandardScaler\n# scaler = StandardScaler()\n# X = scaler.fit_transform(X)\n# \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435\n# test_size --- \u0434\u043e\u043b\u044f \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n# random_state --- \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u043b\u044c\u043d\u043e\u0435 \u0446\u0435\u043b\u043e\u0435 \u0447\u0438\u0441\u043b\u043e, \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)","c30e51a0":"from sklearn.tree import DecisionTreeRegressor #\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\ntree = DecisionTreeRegressor(max_depth=3, random_state=2019)\ntree.fit(X_train, y_train)","3054789c":"from sklearn.metrics import mean_squared_error\ny_pred = tree.predict(X_valid)#\u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435\nmean_squared_error(y_valid, y_pred)#\u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438(\u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f)","2f5b2b1c":"from sklearn.tree import export_graphviz\nexport_graphviz(tree, out_file='tree.dot', feature_names=X.columns)\nprint(open('tree.dot').read()) ","b27dc3e7":"from sklearn.model_selection import KFold\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42) ","21859aa6":"\n# \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u0438 \u043f\u043e\u0434\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\nfrom sklearn.model_selection import GridSearchCV\n\ntree_params_max_depth = {'max_depth': np.arange(2, 20)}\ntree_grid_max_depth = GridSearchCV(tree, tree_params_max_depth, cv=kf, scoring='explained_variance')\ntree_grid_max_depth.fit(X_train, y_train)","ab746a77":"max_depth1 = tree_grid_max_depth.best_params_['max_depth']\nmax_depth1 # \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430","749f3c17":"tree_grid_max_depth.best_score_","5ee68ae6":"tree = DecisionTreeRegressor(max_depth=max_depth1)\ntree_params_split = {'min_samples_split': np.arange(2, 20)}\ntree_samples_split = GridSearchCV(tree, tree_params_split, cv=kf, scoring='explained_variance')\ntree_samples_split.fit(X_train, y_train)","7a46a8ba":"min_samples_split1 = tree_samples_split.best_params_['min_samples_split']\nmin_samples_split1 #\u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044c\u0435\u043a\u0442\u043e\u0432 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435","f797669d":"tree_samples_split.best_score_","f42f0ad0":"tree = DecisionTreeRegressor(max_depth=max_depth1, min_samples_split=min_samples_split1)\ntree_params_leaf = {'min_samples_leaf': np.arange(2, 100)}\ntree_samples_leaf = GridSearchCV(tree, tree_params_leaf, cv=kf, scoring='explained_variance') \ntree_samples_leaf.fit(X_train, y_train)","520ae57f":"min_samples_leaf1 = tree_samples_leaf.best_params_['min_samples_leaf']\nmin_samples_leaf1 # \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435","dc4ab917":"tree_samples_leaf.best_score_","1ac315ba":"tree = DecisionTreeRegressor(max_depth=max_depth1, min_samples_split=min_samples_split1, min_samples_leaf=min_samples_leaf1)\ntree_params_features = {'max_features': np.arange(3, 12)}\ntree_max_features = GridSearchCV(tree, tree_params_features, cv=kf, scoring='explained_variance') \ntree_max_features.fit(X_train, y_train)","00fd70d0":"tree_max_features1 = tree_max_features.best_params_['max_features']\ntree_max_features1","972e9ca0":"tree_max_features.best_score_","f4535981":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=(8,13))\n\nax[0, 0].plot(tree_params_max_depth['max_depth'], tree_grid_max_depth.cv_results_['mean_test_score'])\nax[0, 0].set_xlabel('max_depth')\n\nax[0, 1].plot(tree_params_split['min_samples_split'], tree_samples_split.cv_results_['mean_test_score'])\nax[0, 1].set_xlabel('min_samples_split')\n\nax[1, 0].plot(tree_params_leaf['min_samples_leaf'], tree_samples_leaf.cv_results_['mean_test_score'])\nax[1, 0].set_xlabel('min_samples_leaf')\n\nax[1, 1].plot(tree_params_features['max_features'], tree_max_features.cv_results_['mean_test_score'])\nax[1, 1].set_xlabel('max_features')","e8ab8968":"best_tree = DecisionTreeRegressor(max_depth = 6, \n                                   max_features = 11, \n                                   min_samples_leaf = 36, \n                                   min_samples_split = 3)\nbest_tree.fit(X_train, y_train)\nprint(mean_squared_error(y_valid, y_pred))\nprint(best_forest.score(X_valid, y_valid))","5ed76ff2":"export_graphviz(best_tree, out_file='best_tree.dot', feature_names=X.columns)\nprint(open('best_tree.dot').read()) ","b8bd8cdb":"features = dict(zip(range(len(X.columns)), X.columns))\nfeatures","3c543a83":"importances = best_tree.feature_importances_\n\nimportances\n","af8ac5f3":"indices = np.argsort(importances)[::-1]\nindices\n","c08d4838":"\nnum = len(X.columns)\nfeature_indices = [i for i in indices[:num]]\n\nfor f in range(num_to_plot):\n    print(f+1, features[feature_indices[f]], importances[indices[f]])","072fd43f":"from sklearn.ensemble import RandomForestRegressor\nfr = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=6)\nfr.fit(X_train, y_train)\ny_pred = fr.predict(X_valid)\n\nprint(mean_squared_error(y_valid, y_pred))\nprint(fr.score(X_valid, y_valid))","db6412d5":"fr_params_estimators = {'n_estimators': [20, 50, 80, 100]}# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \nfr_n_estimators = GridSearchCV(fr, fr_params_estimators, cv=kf, scoring='explained_variance', n_jobs = -1)\nfr_n_estimators.fit(X_train, y_train)\nn_estimators1 = fr_n_estimators.best_params_['n_estimators']\nn_estimators1","77be5f96":"fr = RandomForestRegressor(n_estimators = n_estimators1)#\u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \nfr_params_depth = {'max_depth': np.arange(1, 20)}\nfr_max_depth = GridSearchCV(fr, fr_params_depth, cv=kf, scoring='explained_variance')\nfr_max_depth.fit(X_train, y_train)\nmax_depth1 = fr_max_depth.best_params_['max_depth']\nmax_depth1","06f1f57a":"fr = RandomForestRegressor(n_estimators = n_estimators1, max_depth = max_depth1)#\u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435 min_samples_split\nfr_params_split = {'min_samples_split': np.arange(3, 20)}\nfr_samples_split = GridSearchCV(fr, fr_params_split, cv=kf, scoring='explained_variance')\nfr_samples_split.fit(X_train, y_train)\nmin_samples_split1 = fr_samples_split.best_params_['min_samples_split']\nmin_samples_split1","5695d98c":"fr = RandomForestRegressor(n_estimators = n_estimators1, max_depth = max_depth1)\nfr_params_leaf = {'min_samples_leaf': np.arange(1, 20)}#\u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435 min_samples_leaf\nfr_samples_leaf = GridSearchCV(fr, fr_params_leaf, cv=kf, scoring='explained_variance')\nfr_samples_leaf.fit(X_train, y_train)\nmin_samples_leaf1 = fr_samples_leaf.best_params_['min_samples_leaf']\nmin_samples_leaf1","b10a19f7":"fr = RandomForestRegressor(n_estimators = n_estimators1, max_depth = max_depth1, min_samples_split = min_samples_split1, min_samples_leaf = min_samples_leaf1)\n#\u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0435\u043c\u044b\u0445 \u043f\u0440\u0438 \u043f\u043e\u0438\u0441\u043a\u0435 \u043b\u0443\u0447\u0448\u0435\u0433\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f\nfr_params_features = {'max_features': np.arange(1, 12)}\nfr_max_features = GridSearchCV(fr, fr_params_features, cv=kf, scoring='explained_variance')\nfr_max_features.fit(X_train, y_train)\nmax_features1 = fr_max_features.best_params_['max_features']\nmax_features1","3da12ac2":"best_forest = RandomForestRegressor(n_estimators = n_estimators1, max_depth = max_depth1, min_samples_split = min_samples_split1, min_samples_leaf = min_samples_leaf1, max_features = max_features1)\nbest_forest.fit(X_train, y_train)","8ca57a80":"y_pred = best_forest.predict(X_valid)\n\nprint(mean_squared_error(y_valid, y_pred))\nprint(best_forest.score(X_valid, y_valid))","59a01cdb":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=(8,13))\n\nax[0, 0].plot(fr_params_depth['max_depth'], fr_max_depth.cv_results_['mean_test_score'])\nax[0, 0].set_xlabel('max_depth')\n\nax[0, 1].plot(fr_params_split['min_samples_split'], fr_samples_split.cv_results_['mean_test_score'])\nax[0, 1].set_xlabel('min_samples_split')\n\nax[1, 0].plot(fr_params_leaf['min_samples_leaf'], fr_samples_leaf.cv_results_['mean_test_score'])\nax[1, 0].set_xlabel('min_samples_leaf')\n\nax[1, 1].plot(fr_params_features['max_features'], fr_max_features.cv_results_['mean_test_score'])\nax[1, 1].set_xlabel('max_features')","b0920eb0":"importances = best_forest.feature_importances_\n\nindices = np.argsort(importances)[::-1]\nnum = len(X.columns)\nfeature_indices = [i for i in indices[:num]]\n\nfor i in range(num):\n    print(i+1, features[feature_indices[i]], importances[indices[i]])","86e8eb1a":"bars = plt.bar(range(num), importances[indices[:num]])\n\nt = plt.xticks(range(num), feature_indices)\n\nplt.legend(bars, [(features[i]) for i in feature_indices]);","74a7d46c":"from sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor()# \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\nknn.fit(X_train,y_train)\ny_pred = knn.predict(X_valid) # \u0434\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u043e\u0433\u043d\u043e\u0437\nprint(mean_squared_error(y_valid, y_pred))\nprint(best_forest.score(X_valid, y_valid))","19c6537d":"\u041e\u0446\u0435\u043d\u043a\u0430 \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","73a3587d":"# \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043b\u0435\u0441","bbeb32b4":"1. \u0421\u043e\u0437\u0434\u0430\u0442\u044c \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0438\u0432\u0430\u0435\u0442 \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043f\u0435\u0440\u0435\u0434 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435\u043c \u0431\u043b\u043e\u043a\u043e\u0432","39c7cdc1":"2. \u0420\u0430\u0437\u0431\u0438\u0442\u044c \u043d\u0430\u0431\u043e\u0440 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438","5ddf6b7b":"\u0412 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0435 \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u043d\u0430\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432: max_depth=6, max_features=11, min_samples_leaf=36, min_samples_split=3.","3afc093d":"[https:\/\/dreampuf.github.io\/GraphvizOnline\/#digraph%20Tree%20%7B%0D%0Anode%20%5Bshape%3Dbox%5D%20%3B%0D%0A0%20%5Blabel%3D%22Rating%20text%20%3C%3D%200.5%5Cnmse%20%3D%202.317%5Cnsamples%20%3D%206399%5Cnvalue%20%3D%202.654%22%5D%20%3B%0D%0A1%20%5Blabel%3D%22mse%20%3D%200.0%5Cnsamples%20%3D%201458%5Cnvalue%20%3D%200.0%22%5D%20%3B%0D%0A0%20-%3E%201%20%5Blabeldistance%3D2.5%2C%20labelangle%3D45%2C%20headlabel%3D%22True%22%5D%20%3B%0D%0A2%20%5Blabel%3D%22Rating%20text%20%3C%3D%202.5%5Cnmse%20%3D%200.308%5Cnsamples%20%3D%204941%5Cnvalue%20%3D%203.438%22%5D%20%3B%0D%0A0%20-%3E%202%20%5Blabeldistance%3D2.5%2C%20labelangle%3D-45%2C%20headlabel%3D%22False%22%5D%20%3B%0D%0A3%20%5Blabel%3D%22Rating%20text%20%3C%3D%201.5%5Cnmse%20%3D%200.086%5Cnsamples%20%3D%202616%5Cnvalue%20%3D%203.009%22%5D%20%3B%0D%0A2%20-%3E%203%20%3B%0D%0A4%20%5Blabel%3D%22Votes%20%3C%3D%2055.5%5Cnmse%20%3D%200.014%5Cnsamples%20%3D%20124%5Cnvalue%20%3D%202.298%22%5D%20%3B%0D%0A3%20-%3E%204%20%3B%0D%0A5%20%5Blabel%3D%22mse%20%3D%200.006%5Cnsamples%20%3D%2066%5Cnvalue%20%3D%202.336%22%5D%20%3B%0D%0A4%20-%3E%205%20%3B%0D%0A6%20%5Blabel%3D%22mse%20%3D%200.02%5Cnsamples%20%3D%2058%5Cnvalue%20%3D%202.255%22%5D%20%3B%0D%0A4%20-%3E%206%20%3B%0D%0A7%20%5Blabel%3D%22Votes%20%3C%3D%2011.5%5Cnmse%20%3D%200.064%5Cnsamples%20%3D%202492%5Cnvalue%20%3D%203.045%22%5D%20%3B%0D%0A3%20-%3E%207%20%3B%0D%0A8%20%5Blabel%3D%22Longitude%20%3C%3D%2038.493%5Cnmse%20%3D%200.025%5Cnsamples%20%3D%20797%5Cnvalue%20%3D%202.969%22%5D%20%3B%0D%0A7%20-%3E%208%20%3B%0D%0A9%20%5Blabel%3D%22mse%20%3D%200.013%5Cnsamples%20%3D%2057%5Cnvalue%20%3D%203.075%22%5D%20%3B%0D%0A8%20-%3E%209%20%3B%0D%0A10%20%5Blabel%3D%22Has%20Online%20delivery%20%3C%3D%200.5%5Cnmse%20%3D%200.025%5Cnsamples%20%3D%20740%5Cnvalue%20%3D%202.96%22%5D%20%3B%0D%0A8%20-%3E%2010%20%3B%0D%0A11%20%5Blabel%3D%22mse%20%3D%200.018%5Cnsamples%20%3D%20609%5Cnvalue%20%3D%202.973%22%5D%20%3B%0D%0A10%20-%3E%2011%20%3B%0D%0A12%20%5Blabel%3D%22mse%20%3D%200.051%5Cnsamples%20%3D%20131%5Cnvalue%20%3D%202.899%22%5D%20%3B%0D%0A10%20-%3E%2012%20%3B%0D%0A13%20%5Blabel%3D%22Latitude%20%3C%3D%2028.349%5Cnmse%20%3D%200.078%5Cnsamples%20%3D%201695%5Cnvalue%20%3D%203.081%22%5D%20%3B%0D%0A7%20-%3E%2013%20%3B%0D%0A14%20%5Blabel%3D%22Votes%20%3C%3D%2046.5%5Cnmse%20%3D%200.027%5Cnsamples%20%3D%2083%5Cnvalue%20%3D%203.278%22%5D%20%3B%0D%0A13%20-%3E%2014%20%3B%0D%0A15%20%5Blabel%3D%22mse%20%3D%200.041%5Cnsamples%20%3D%2042%5Cnvalue%20%3D%203.233%22%5D%20%3B%0D%0A14%20-%3E%2015%20%3B%0D%0A16%20%5Blabel%3D%22mse%20%3D%200.007%5Cnsamples%20%3D%2041%5Cnvalue%20%3D%203.324%22%5D%20%3B%0D%0A14%20-%3E%2016%20%3B%0D%0A17%20%5Blabel%3D%22Longitude%20%3C%3D%2077.246%5Cnmse%20%3D%200.078%5Cnsamples%20%3D%201612%5Cnvalue%20%3D%203.071%22%5D%20%3B%0D%0A13%20-%3E%2017%20%3B%0D%0A18%20%5Blabel%3D%22mse%20%3D%200.074%5Cnsamples%20%3D%201081%5Cnvalue%20%3D%203.101%22%5D%20%3B%0D%0A17%20-%3E%2018%20%3B%0D%0A19%20%5Blabel%3D%22mse%20%3D%200.082%5Cnsamples%20%3D%20531%5Cnvalue%20%3D%203.008%22%5D%20%3B%0D%0A17%20-%3E%2019%20%3B%0D%0A20%20%5Blabel%3D%22Rating%20text%20%3C%3D%203.5%5Cnmse%20%3D%200.12%5Cnsamples%20%3D%202325%5Cnvalue%20%3D%203.919%22%5D%20%3B%0D%0A2%20-%3E%2020%20%3B%0D%0A21%20%5Blabel%3D%22Votes%20%3C%3D%2088.5%5Cnmse%20%3D%200.019%5Cnsamples%20%3D%201396%5Cnvalue%20%3D%203.683%22%5D%20%3B%0D%0A20%20-%3E%2021%20%3B%0D%0A22%20%5Blabel%3D%22Votes%20%3C%3D%2039.5%5Cnmse%20%3D%200.016%5Cnsamples%20%3D%20528%5Cnvalue%20%3D%203.633%22%5D%20%3B%0D%0A21%20-%3E%2022%20%3B%0D%0A23%20%5Blabel%3D%22Longitude%20%3C%3D%2077.084%5Cnmse%20%3D%200.015%5Cnsamples%20%3D%20218%5Cnvalue%20%3D%203.606%22%5D%20%3B%0D%0A22%20-%3E%2023%20%3B%0D%0A24%20%5Blabel%3D%22mse%20%3D%200.019%5Cnsamples%20%3D%2052%5Cnvalue%20%3D%203.66%22%5D%20%3B%0D%0A23%20-%3E%2024%20%3B%0D%0A25%20%5Blabel%3D%22mse%20%3D%200.012%5Cnsamples%20%3D%20166%5Cnvalue%20%3D%203.589%22%5D%20%3B%0D%0A23%20-%3E%2025%20%3B%0D%0A26%20%5Blabel%3D%22Latitude%20%3C%3D%2028.559%5Cnmse%20%3D%200.017%5Cnsamples%20%3D%20310%5Cnvalue%20%3D%203.651%22%5D%20%3B%0D%0A22%20-%3E%2026%20%3B%0D%0A27%20%5Blabel%3D%22mse%20%3D%200.018%5Cnsamples%20%3D%20132%5Cnvalue%20%3D%203.673%22%5D%20%3B%0D%0A26%20-%3E%2027%20%3B%0D%0A28%20%5Blabel%3D%22mse%20%3D%200.015%5Cnsamples%20%3D%20178%5Cnvalue%20%3D%203.635%22%5D%20%3B%0D%0A26%20-%3E%2028%20%3B%0D%0A29%20%5Blabel%3D%22Votes%20%3C%3D%20549.5%5Cnmse%20%3D%200.019%5Cnsamples%20%3D%20868%5Cnvalue%20%3D%203.714%22%5D%20%3B%0D%0A21%20-%3E%2029%20%3B%0D%0A30%20%5Blabel%3D%22Average%20Cost%20for%20two%20%3C%3D%20235.0%5Cnmse%20%3D%200.019%5Cnsamples%20%3D%20757%5Cnvalue%20%3D%203.707%22%5D%20%3B%0D%0A29%20-%3E%2030%20%3B%0D%0A31%20%5Blabel%3D%22mse%20%3D%200.015%5Cnsamples%20%3D%20123%5Cnvalue%20%3D%203.75%22%5D%20%3B%0D%0A30%20-%3E%2031%20%3B%0D%0A32%20%5Blabel%3D%22mse%20%3D%200.019%5Cnsamples%20%3D%20634%5Cnvalue%20%3D%203.698%22%5D%20%3B%0D%0A30%20-%3E%2032%20%3B%0D%0A33%20%5Blabel%3D%22Longitude%20%3C%3D%2077.195%5Cnmse%20%3D%200.016%5Cnsamples%20%3D%20111%5Cnvalue%20%3D%203.764%22%5D%20%3B%0D%0A29%20-%3E%2033%20%3B%0D%0A34%20%5Blabel%3D%22mse%20%3D%200.012%5Cnsamples%20%3D%2045%5Cnvalue%20%3D%203.789%22%5D%20%3B%0D%0A33%20-%3E%2034%20%3B%0D%0A35%20%5Blabel%3D%22mse%20%3D%200.017%5Cnsamples%20%3D%2066%5Cnvalue%20%3D%203.747%22%5D%20%3B%0D%0A33%20-%3E%2035%20%3B%0D%0A36%20%5Blabel%3D%22Rating%20text%20%3C%3D%204.5%5Cnmse%20%3D%200.061%5Cnsamples%20%3D%20929%5Cnvalue%20%3D%204.274%22%5D%20%3B%0D%0A20%20-%3E%2036%20%3B%0D%0A37%20%5Blabel%3D%22Votes%20%3C%3D%20600.0%5Cnmse%20%3D%200.019%5Cnsamples%20%3D%20724%5Cnvalue%20%3D%204.165%22%5D%20%3B%0D%0A36%20-%3E%2037%20%3B%0D%0A38%20%5Blabel%3D%22Latitude%20%3C%3D%2026.17%5Cnmse%20%3D%200.018%5Cnsamples%20%3D%20543%5Cnvalue%20%3D%204.152%22%5D%20%3B%0D%0A37%20-%3E%2038%20%3B%0D%0A39%20%5Blabel%3D%22mse%20%3D%200.019%5Cnsamples%20%3D%20188%5Cnvalue%20%3D%204.188%22%5D%20%3B%0D%0A38%20-%3E%2039%20%3B%0D%0A40%20%5Blabel%3D%22mse%20%3D%200.016%5Cnsamples%20%3D%20355%5Cnvalue%20%3D%204.133%22%5D%20%3B%0D%0A38%20-%3E%2040%20%3B%0D%0A41%20%5Blabel%3D%22Longitude%20%3C%3D%2076.799%5Cnmse%20%3D%200.019%5Cnsamples%20%3D%20181%5Cnvalue%20%3D%204.203%22%5D%20%3B%0D%0A37%20-%3E%2041%20%3B%0D%0A42%20%5Blabel%3D%22mse%20%3D%200.016%5Cnsamples%20%3D%2076%5Cnvalue%20%3D%204.253%22%5D%20%3B%0D%0A41%20-%3E%2042%20%3B%0D%0A43%20%5Blabel%3D%22mse%20%3D%200.018%5Cnsamples%20%3D%20105%5Cnvalue%20%3D%204.168%22%5D%20%3B%0D%0A41%20-%3E%2043%20%3B%0D%0A44%20%5Blabel%3D%22Votes%20%3C%3D%201302.0%5Cnmse%20%3D%200.022%5Cnsamples%20%3D%20205%5Cnvalue%20%3D%204.658%22%5D%20%3B%0D%0A36%20-%3E%2044%20%3B%0D%0A45%20%5Blabel%3D%22Price%20range%20%3C%3D%203.5%5Cnmse%20%3D%200.021%5Cnsamples%20%3D%20168%5Cnvalue%20%3D%204.64%22%5D%20%3B%0D%0A44%20-%3E%2045%20%3B%0D%0A46%20%5Blabel%3D%22mse%20%3D%200.019%5Cnsamples%20%3D%20124%5Cnvalue%20%3D%204.619%22%5D%20%3B%0D%0A45%20-%3E%2046%20%3B%0D%0A47%20%5Blabel%3D%22mse%20%3D%200.024%5Cnsamples%20%3D%2044%5Cnvalue%20%3D%204.702%22%5D%20%3B%0D%0A45%20-%3E%2047%20%3B%0D%0A48%20%5Blabel%3D%22mse%20%3D%200.018%5Cnsamples%20%3D%2037%5Cnvalue%20%3D%204.738%22%5D%20%3B%0D%0A44%20-%3E%2048%20%3B%0D%0A%7D%0D%0Aadd%20Codeadd%20Markdown](http:\/\/)","d2fe7bed":"4. \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0435 \u0434\u0435\u0440\u0435\u0432\u043e","56c08df8":"# \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0434\u0435\u0440\u0435\u0432\u0430","d708be74":"1. \u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f - 'Aggregate rating'. \u0426\u0435\u043b\u044c: \u0441\u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0438\u043c\u0435\u044e\u0449\u0438\u0445\u0441\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432.","f4c68e44":"4. \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0435 \u043a\u0440\u0438\u0432\u044b\u0435","8566a290":"2. \u041e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0438\u0442\u0435 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e \u043c\u043e\u0434\u0435\u043b\u0438 \u0434\u043b\u044f \u043f\u043e\u0434\u0431\u043e\u0440\u0430 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 GridSearchCV. \u0418\u043d\u0442\u0435\u0440\u0432\u0430\u043b\u044b \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0437\u0430\u0434\u0430\u0439\u0442\u0435 \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c\u043d\u043e.","934f1ab7":"3. \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438","8d0f434b":"# \u0414\u0435\u0440\u0435\u0432\u044c\u044f \u0440\u0435\u0448\u0435\u043d\u0438\u0439","e102b798":"\u0412\u044b\u0432\u043e\u0434\u044b:\n\n* \u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438 \u043c\u0435\u0442\u043e\u0434\u0430 \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0438\u0445 \u0441\u043e\u0441\u0435\u0434\u0435\u0439 \u043f\u043e \u0438\u0434\u0435\u0435 \u0445\u0443\u0434\u0448\u0435\u0435 \u0438\u0437 \u0432\u0441\u0435\u0445. \u041d\u043e \u0443 \u043c\u0435\u043d\u044f \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u043e \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u0442\u0430\u043a\u043e\u0439 \u0436\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442, \u0447\u0442\u043e \u0438 \u0434\u0435\u0440\u0435\u0432\u043e.\n* \u0414\u0435\u0440\u0435\u0432\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u0439 \u0434\u043e\u0441\u0430\u0442\u043e\u0447\u043d\u043e \u0431\u044b\u0441\u0442\u0440\u043e\u0435, \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u043a\u0430\u0437\u0430\u043b\u0430\u0441\u044c \u0447\u0443\u0442\u044c \u043b\u0443\u0447\u0448\u0435 \u0447\u0435\u043c kNN.\n* \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043b\u0435\u0441 \u043f\u043e\u043a\u0430\u0437\u0430\u043b \u043b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442. \u041c\u0438\u043d\u0443\u0441\u043e\u043c \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0434\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u043f\u0440\u0438 \u0431\u043e\u043b\u044c\u0448\u043e\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435 \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432."}}