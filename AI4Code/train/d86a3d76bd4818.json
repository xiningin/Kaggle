{"cell_type":{"3cc84d4d":"code","ea448309":"code","8f890faa":"code","fcbae0ad":"code","cd412743":"code","084e14f7":"code","f602b1fc":"code","73740bdb":"code","1f09c923":"code","6b04222e":"code","0bed6832":"code","c075490c":"code","8b242005":"code","6bf2a047":"markdown","05774125":"markdown","79bcfa83":"markdown","6ba01f5e":"markdown","b76ea24d":"markdown","d69e9a68":"markdown","ef09625e":"markdown","caf1d417":"markdown","1482024c":"markdown","899783b1":"markdown"},"source":{"3cc84d4d":"# PACKAGES\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport sys, os\nfrom IPython.core.display import *\n\n# DATA I\/O\nprint('Loading Ground Truth')\ntrain_df = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ndisplay(train_df.head())\n\n# Load prediction of Trained RoBERTa Model (5 fold ensemble, 0.712LB)\nprint('Loading Trained Model Predictions')\npreds = pd.read_csv('\/kaggle\/input\/tweeterroranalysis\/error-analysis-roberta-base-5model.csv')\npreds.drop(columns=['textID'], inplace=True)\ndisplay(preds.head())\n\n# Analmoly Statistics\nanamoly = train_df.copy().drop(columns=['textID','text','selected_text','sentiment'])","ea448309":"def jaccard(str1, str2): \n    \"\"\" Compute Jaccard Score \n    \"\"\"\n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\npreds['Jaccard'] = preds.apply(lambda x: jaccard(str(x.selected_text), str(x.prediction)), axis=1)\npreds['word_length'] = preds['prediction'].apply(lambda x: len(x.split()))\ndisplay(preds.head())","8f890faa":"dfg = preds.groupby(['sentiment'])\ndf_pos = dfg.get_group('positive')\ndf_neg = dfg.get_group('negative')\ndf_neutral = dfg.get_group('neutral')\nfig=px.histogram(df_pos, x='Jaccard',title='Positive Sentiment');fig.show();\nfig=px.histogram(df_neg, x='Jaccard',title='Negative Sentiment');fig.show();\nfig=px.histogram(df_neutral, x='Jaccard',title='Neutral Sentiment');fig.show();\n\nprint(\"All data Jaccard: \" + str(preds.Jaccard.mean()))\nprint(\"+ data Jaccard: \" + str(df_pos.Jaccard.mean()))\nprint(\"- data Jaccard: \" + str(df_neg.Jaccard.mean()))\nprint(\"= data Jaccard: \" + str(df_neutral.Jaccard.mean()))","fcbae0ad":"lonely_comma_indices = train_df.selected_text.apply(lambda x: 1 if (',' in str(x).split()) else 0)\nanamoly['lonely comma'] = lonely_comma_indices\n\nlonely_semicolon_indices = train_df.selected_text.apply(lambda x: 1 if (';' in str(x).split()) else 0)\nanamoly['lonely semicolon'] = lonely_semicolon_indices\n\nlonely_colon_indices = train_df.selected_text.apply(lambda x: 1 if (':' in str(x).split()) else 0)\nanamoly['lonely colon'] = lonely_colon_indices\n\nlonely_period_indices = train_df.selected_text.apply(lambda x: 1 if ('.' in str(x).split()) else 0)\nanamoly['lonely period'] = lonely_period_indices\n\nlonely_at_indices = train_df.selected_text.apply(lambda x: 1 if ('@' in str(x).split()) else 0)\nanamoly['lonely @'] = lonely_at_indices\n\nlonely_underscore_indices = train_df.selected_text.apply(lambda x: 1 if ('_' in str(x).split()) else 0)\nanamoly['lonely _'] = lonely_underscore_indices\n\nprint(\"Lonely Charater Statistics\")\ndisplay(pd.DataFrame(anamoly.iloc[:,:6].sum()))","cd412743":"df_all0 = df_neg[df_neg.Jaccard==0].append(df_pos[df_pos.Jaccard==0]).reset_index().drop(columns=['index'])\nprint('Missing !')\ndisplay(df_all0[df_all0.index==340])\nprint('Missing .')\ndisplay(df_all0[df_all0.index==226])\nprint('Data has missing character at the end')\ndisplay(df_all0[df_all0.index==792])\nprint('Data has missing multiple characters at the end')\ndisplay(df_all0[df_all0.index==621])\nprint('Data has words only containing last two characters')\ndisplay(df_all0[df_all0.index==1150])\ndisplay(df_all0[df_all0.index==581])\ndisplay(df_all0[df_all0.index==906])\nprint('Data has words only containing last one character')\ndisplay(df_all0[df_all0.index==181])\ndisplay(df_all0[df_all0.index==984])","084e14f7":"df_all0.sample(20) ","f602b1fc":"df = preds.copy()\n\nprint('Before')\nprint(df.Jaccard.mean())\n\ndf['prediction'] = df['prediction'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\ndf['prediction'] = df['prediction'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\ndf['prediction'] = df['prediction'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\ndf['Jaccard'] = df.apply(lambda x: jaccard(str(x.selected_text), str(x.prediction)), axis=1)\n\nprint('After')\nprint(df.Jaccard.mean())","73740bdb":"import re\n\ndef post_process(s):\n    a = re.findall('[^A-Za-z0-9]',s)\n    b = re.sub('[^A-Za-z0-9]+', '', s)\n\n    try:\n        if a.count('.')==3:\n            text = b + '. ' + b + '..'\n        elif a.count('!')==4:\n            text = b + '! ' + b + '!! ' +  b + '!!!'\n        else:\n            text = s\n        return text\n    except:\n        return text\n    ","1f09c923":"df = preds.copy()\n#df = df_all0.copy()\n\nprint('Before')\nprint(df.Jaccard.mean())\n\ndf['prediction'] = df.apply(lambda x: post_process(x['prediction']) if (len(str(x['prediction']).split())==1) else x['prediction'], axis=1)\ndf['Jaccard'] = df.apply(lambda x: jaccard(str(x.selected_text), str(x.prediction)), axis=1)\n\nprint('After')\nprint(df.Jaccard.mean())","6b04222e":"print(f'Improved {100*len(df[df.Jaccard>0])\/len(df[df.Jaccard==0])}% entries')\ndf[df.Jaccard>0]","0bed6832":"df[df.Jaccard>0]","c075490c":"df = df_all0.copy()\ndf['pred_count'] = df.apply(lambda x: x['prediction'].count('.') if ((len(x['prediction'].split())==1)&(len(x['selected_text'].split())==1)) else x['prediction'], axis=1)\ndf['gt_count'] = df.apply(lambda x: x['selected_text'].count('.') if ((len(x['prediction'].split())==1)&(len(x['selected_text'].split())==1)) else x['selected_text'], axis=1)","8b242005":"a = df[df.word_length==1]\n\nprint('1 .')\nt = a[a.pred_count==1].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();\n\nprint('2 .')\nt = a[a.pred_count==2].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();\n\nprint('3 .')\nt = a[a.pred_count==3].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();\n\nprint('4 .')\nt = a[a.pred_count==4].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();","6bf2a047":"\n#  <span style=\"color:green\"> <center> A Quick Look at ```Selected Text``` Noise\n\n### In this notebook, I am exploring the noise in the dataset. \n1. I analysed the ```selected_text``` column in the original dataset.\n2. I compared ```selected_text``` with the ```prediction``` of a reference model to find out why I am getting low performance in positive and negative sentiment predictions.\n\n\n### Reference Model\nI am using prediction of a trained model ```(5 fold ensemble of a RoBERTa-Base with public LB 0.712)``` to find out anamolies. I can identify many of them by performing error analysis. In particular, when my Jaccard score is very low, many times it's due to the inherent noise in the data.\n\n\n### <span style=\"color:orange\"> Can We Use It For Our Benefits?\n\n\n\n### <span style=\"color:green\">  If you find it useful, please upvote! Thank you! \ud83d\udd25<\/span>\n\n** N.B. I just listed a few noise. At the end of the notebook you can generate random samples to find more variety of noise. **","05774125":"# To find more noise, you can run the following code to get random samples!","79bcfa83":"## Let's Look @ my Jaccard Distribution\n\n- There are tons of errors in postive and negative sentiment predictions.\n- During prediction my model copied whole text to prediction when sentiment in ```neutral```. Looks like it is not a perfect strategy as it has a few non perfect Jaccard scores.\n- Average Jaccard values for 3 sentiments: \n``` \nPOSITIVE: 0.5814722049084579\nNEGATIVE: 0.5906752954713453\nNEUTRAL:  0.9764467881939682\n```","6ba01f5e":"## Include Prerequisites","b76ea24d":"```\nsample = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/sample_submission.csv\")\nsample.loc[:, 'selected_text'] = final_output\n\nsample['selected_text'] = sample['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\nsample['selected_text'] = sample['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\nsample['selected_text'] = sample['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n```","d69e9a68":"# Scrap","ef09625e":"# \ud83d\udc7b Warmup: Let's Look at the Lonely Characters in ```selected_text```\n\n### Not many of those!","caf1d417":"# <span style=\"color:red\"> I gained 0.001LB Just by adding following post-processing! Can you come up with more ways to improve?","1482024c":"## Estimate Jaccard Score of the Model Predictions","899783b1":"# Now Let's See Where My Model Scored Jaccard=0 for Positive and Negative Sentiments.\n\n### NOT FAIR!\ud83d\ude33 I am penalized because:\n\n### 1. Missing a ```!```  <span style=\"color:orange\">Damn! It ```hurts!!!```\n\n### 2. Missing a ```.```  <span style=\"color:orange\">It is ```stupid...```\n\n### 3. Missing ```d``` in ```good```?  <span style=\"color:orange\">LOL. It's not ```goo```\n\n### 4. Missing ```ng``` in ```amazing```?  <span style=\"color:orange\">Dude. It's not ```amazi``` at all!\n\n### 5. Words are not complete in the data! E.g. ```st jokin``` instead of ```just joking```.\n\n### ..."}}