{"cell_type":{"c71d99bc":"code","18ca1ff9":"code","5f2abb74":"code","41aa8827":"code","75bde0fe":"code","b8316326":"code","06908b7a":"code","3ef4c682":"code","ef0757f2":"code","49f3981e":"code","7055b0a6":"code","0c7bbaed":"code","d890f2ee":"code","5f19c5c4":"code","f155edad":"code","34791c1c":"code","1c66746e":"code","03e72488":"code","d9806116":"code","a63640a8":"code","7cfad384":"code","4e7271ff":"markdown","4798b738":"markdown"},"source":{"c71d99bc":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier","18ca1ff9":"%%time\nused_data_types_dict = {\n    'timestamp': 'int64',\n    'user_id': 'int32',\n    'content_id': 'int16',\n    'answered_correctly': 'int8',\n    'prior_question_elapsed_time': 'float16',\n    'prior_question_had_explanation': 'boolean'\n}\n\ndf = pd.read_csv(\n    '..\/input\/riiid-test-answer-prediction\/train.csv',\n    usecols = used_data_types_dict.keys(),\n    dtype = used_data_types_dict,\n    nrows=10**7\n)\n# Commented out nrows=10**6\n# all data runs out of memory, need to fix this\n# I think with the chunking syntax or datatable or something","5f2abb74":"'''\n\n%%time\n\n# Import the Rapids suite here - takes abot 1.5 mins\n\nimport sys\n!cp ..\/input\/rapids\/rapids.0.16.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/\n\n# Rapids Imports\nimport cudf\nimport cupy # CuPy is an open-source array library accelerated with NVIDIA CUDA.\n\n\nfrom dask.distributed import Client, wait\nfrom dask_cuda import LocalCUDACluster\n\ncluster = LocalCUDACluster()\nclient = Client(cluster)\nclient\n\n%%time\ndf = cudf.read_csv('..\/input\/riiid-test-answer-prediction\/train.csv')\ndf.info()\n'''","41aa8827":"df = df.replace([np.inf, -np.inf], np.nan)\ndf['prior_question_had_explanation'] = df['prior_question_had_explanation'].fillna(value=False).astype(bool)\ndf = df.fillna(0.5)\ndf.info()","75bde0fe":"train_questions_only_df = df[df['answered_correctly']!=-1]\ngrouped_by_user_df = train_questions_only_df.groupby('user_id')\nuser_answers_df = grouped_by_user_df.agg({\n    'answered_correctly': ['mean', 'count', 'std', 'median', 'skew']\n                                         }).copy()\nuser_answers_df.columns = [\n    'mean_user_accuracy',\n    'questions_answered',\n    'std_user_accuracy',\n    'median_user_accuracy',\n    'skew_user_accuracy'\n]\nuser_answers_df.head(5)","b8316326":"grouped_by_content_df = train_questions_only_df.groupby('content_id')\ncontent_answers_df = grouped_by_content_df.agg({\n    'answered_correctly': ['mean', 'count', 'std', 'median', 'skew']\n}).copy()\ncontent_answers_df.columns = [\n    'mean_accuracy',\n    'question_asked',\n    'std_accuracy',\n    'median_accuracy',\n    'skew_accuracy'\n]\ncontent_answers_df.head(5)","06908b7a":"df['timespend'] = df.groupby('user_id')['timestamp'].transform(lambda x: (x.max() - x.min()) \/ 1000)","3ef4c682":"q_df = pd.read_csv('..\/input\/riiid-test-answer-prediction\/questions.csv')\nq_df.info()","ef0757f2":"tags = q_df[\"tags\"].str.split(\" \", n=10, expand=True)\ntags.columns = ['tags1', 'tags2', 'tags3', 'tags4', 'tags5', 'tags6']\nq_df = pd.concat([q_df, tags], axis=1).drop(['tags'], axis=1)\nq_df['tags1'] = pd.to_numeric(q_df['tags1'],\n                              errors='coerce',\n                              downcast='integer').fillna(-1)\nq_df['tags2'] = pd.to_numeric(q_df['tags2'],\n                              errors='coerce',\n                              downcast='integer').fillna(-1)\nq_df['tags3'] = pd.to_numeric(q_df['tags3'],\n                              errors='coerce',\n                              downcast='integer').fillna(-1)\nq_df.head(3)","49f3981e":"features = [\n    'mean_user_accuracy',\n    'questions_answered',\n    'std_user_accuracy',\n    'median_user_accuracy',\n    'skew_user_accuracy',\n    'mean_accuracy',\n    'question_asked',\n    'std_accuracy',\n    'median_accuracy',\n    'prior_question_elapsed_time',\n    'prior_question_had_explanation',\n    'skew_accuracy',\n    'bundle_id',\n    'tags1',\n    'tags2',\n    'tags3',\n]\ntarget = 'answered_correctly'","7055b0a6":"df = df[df[target] != -1]","0c7bbaed":"df = df.merge(user_answers_df,\n                         how='left', on='user_id')\ndf = df.merge(content_answers_df,\n                         how='left', on='content_id')\ndf = df.merge(q_df, how='left', \n              left_on='content_id', right_on='question_id')","d890f2ee":"train_df, test_df = train_test_split(df,\n                                    random_state=42,\n                                    test_size=0.2)","5f19c5c4":"# Optuna\nparams = {\n    'bagging_fraction': 0.5817242323514327,\n    'feature_fraction': 0.6884588361650144,\n    'learning_rate': 0.42887924851375825, \n    'max_depth': 6,\n    'min_child_samples': 946, \n    'min_data_in_leaf': 47, \n    'n_estimators': 169,\n    'num_leaves': 29,\n    'random_state': 666\n}\nmodel = LGBMClassifier(**params)","f155edad":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ntrain_features = train_df[features]\ntrain_features = scaler.fit_transform(train_features)","34791c1c":"model.fit(train_features, train_df[target])","1c66746e":"test_df = test_df[test_df['answered_correctly']!=-1]\ntest_features = test_df[features]\ntest_features = scaler.transform(test_features)\npreds = model.predict(test_features)\n\nprint(roc_auc_score(test_df[target], preds))","03e72488":"# Try to remedy this with Random Oversampling\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(test_df[target], preds))","d9806116":"labels = test_df[target].value_counts()\nprint(labels[1] \/ (labels[0] + labels[1]))","a63640a8":"import riiideducation\nenv = riiideducation.make_env()\niter_test = env.iter_test()","7cfad384":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.merge(user_answers_df, how='left',\n                           on='user_id')\n    test_df = test_df.merge(content_answers_df, how='left',\n                           on='content_id')\n    test_df = test_df.merge(q_df, how='left', \n              left_on='content_id', right_on='question_id')\n    \n    test_df['timespend'] = test_df.groupby('user_id')['timestamp'].transform(lambda x: (x.max() - x.min()) \/ 1000)\n    \n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(value=False).astype(bool)\n    test_df['answered_correctly'] = model.predict_proba(test_df[features])[:,1]\n    \n    \n    \n    env.predict(test_df.loc[test_df['content_type_id'] == 0,\n                           ['row_id', 'answered_correctly']])","4e7271ff":"Learning Kaggle,thanks to Kostiantyn Isaienkov's code to help me get started!","4798b738":"Go to --> Add Data, search \"RAPIDS\", add RAPIDS\n<br \/>\n... still having trouble with this ...\nNo module found 'cudf'"}}