{"cell_type":{"64a9a40a":"code","94a03321":"code","38eabf7e":"code","57c8f1b9":"code","742a5fc2":"code","22abd357":"code","5f08475c":"code","a655630d":"code","e483a30c":"code","1684f6e3":"code","159ed3e4":"code","40206a14":"code","c8646d93":"code","d4020f0f":"code","673fa96f":"code","d5ccae37":"code","905ac865":"code","d6892faa":"code","feec0505":"code","1d13f88c":"code","7fed5f1d":"code","ce3c712e":"code","4055a630":"code","58c1f712":"code","0eeacd84":"code","2b0af56e":"code","e1df990a":"code","26f0d7fc":"code","501f4179":"markdown","7aaee82f":"markdown","3d0df713":"markdown","1469980a":"markdown","44960b98":"markdown","c0d36511":"markdown","edebfb4d":"markdown","dbcbd555":"markdown"},"source":{"64a9a40a":"import numpy as np # linear algebra\n\nimport torch \nimport matplotlib.pyplot as plt   # data visualization \nimport os\nfrom PIL import Image\nimport torch.nn as nn \nfrom glob import glob\nimport torch.optim as optim \nimport torch.nn.functional as F \nfrom torchvision import datasets, transforms \nfrom torch.utils.data.sampler import SubsetRandomSampler ","94a03321":"valid_size = 0.2 \n\ntrain_dir = '..\/input\/intel-image-classification\/seg_train\/seg_train'\ntest_dir = '..\/input\/intel-image-classification\/seg_test\/seg_test'\npred_dir =\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\"\n\nimg_size = 150 \n\n# Transform train and test data\ntransform_train = transforms.Compose([transforms.Resize((img_size, img_size)), \n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransform_test = transforms.Compose([\n                                     transforms.Resize((150, 150)),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_data = datasets.ImageFolder(train_dir, transform=transform_train)\ntest_data = datasets.ImageFolder(test_dir, transform=transform_test)\n\npred_files = [os.path.join(pred_dir, f) for f in os.listdir(pred_dir)]\nclasses=['forest', 'buildings', 'glacier', 'mountain', 'sea', 'street']\n\nlen(train_data), len(test_data)","38eabf7e":"folders = os.listdir(train_dir)\n\n\nimages = []\nlabels = []\nfor cl in folders:\n    path = os.path.join(train_dir, cl, '*.jpg')\n    for file in glob(path)[:2]:\n        with Image.open(file) as f:\n            images.append(np.array(f))\n            labels.append(cl)\n            \nfig = plt.figure(figsize=(10, 15))\n\nfor i, image in enumerate(images):\n    ax = fig.add_subplot(6, 2, i+1)\n    ax.imshow(image)\n    ax.set_title(labels[i])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \nplt.show();","57c8f1b9":"num_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\n# print(split)\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# # Define samplers for obtaining training and validation batches \ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=32, sampler=train_sampler, num_workers = 2)\nvalidloader = torch.utils.data.DataLoader(train_data, batch_size = 32, sampler = valid_sampler, num_workers = 2)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size = 32, num_workers = 2)\n","742a5fc2":"from torchvision.models import resnet50\nnet = resnet50(pretrained=True)\nnet","22abd357":"torch.manual_seed(42)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice ","5f08475c":"for param in net.parameters():\n    param.required_grad = False","a655630d":"class Model(torch.nn.Module):\n  def __init__(self, num_classes = 6, pretrained=True):\n    super().__init__()\n     \n    self.fc1 = torch.nn.Linear(1000, 512)\n    self.dropout = nn.Dropout(p=0.2)\n    self.fc2 = torch.nn.Linear(512, 256)\n    self.output_layer = torch.nn.Linear(256, num_classes)\n\n  def forward(self, x):\n    x = F.relu(self.fc1(x))\n    x = self.dropout(x)\n    x = F.relu(self.fc2(x))\n    x = self.output_layer(x)\n    return x ","e483a30c":"model = Model(pretrained = True)\nmodel.to(device)\nnet.classifier = model","1684f6e3":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(net.parameters(), lr=0.001)","159ed3e4":"def batch_accuracy(xb, yb):\n  correct = (xb.argmax(1)) == yb \n  return correct.float().mean().item()\n\ndef validate_epoch(model):\n  epoch_loss = 0 \n  accuracy = 0 \n  model.eval() \n\n  with torch.no_grad():\n    for input_batch, labels in testloader:\n      output = model(input_batch.to (device))\n      loss = criterion(output, labels.to(device))\n      epoch_loss += loss.item()\n      accuracy += batch_accuracy(output, labels.to(device))\n\n    accuracy \/= len(testloader)\n    epoch_loss \/= len(testloader)\n    return accuracy, epoch_loss \n\n\n\ndef train_model(model, num_epochs, print_every=1):\n  for i in range(num_epochs):\n    epoch_loss = 0\n    accuracy = 0 \n    model.train()\n\n    for input_batch, labels in trainloader:\n      output = model(input_batch.to(device))\n      loss = criterion(output, labels.to(device))\n      epoch_loss += loss.item()\n\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n      accuracy += batch_accuracy(output, labels.to(device))\n\n    accuracy \/= len(trainloader)\n    epoch_loss \/= len(trainloader)\n\n    if (i+1) % print_every == 0 :\n      test_acc, test_loss = validate_epoch(model)\n      print(f'|Epoch: {(i+1):02} | Train Loss: {epoch_loss:.3f} | Train Acc.: {accuracy:.3f} |'+\n                  f' Val. Loss:  {test_loss:.3f} | Val. Acc.: {test_acc:.3f} |')","40206a14":"train_model(net.to(device), num_epochs=5)","c8646d93":"# Function to pull the label\ndef predictions(image):\n    # pil_img = Image.open(image)\n    # transform images\n    transform = transform_test(image)\n    # add extra dimension in place of batch size\n    img = transform.unsqueeze(0).cuda() \n    # push to gpu\n    gpu_img = img.to(device)\n    # make prediction\n    output = net(gpu_img)\n    # convert image to numpy format in cpu and snatching max prediction score class index\n    # _, index = torch.max(output.data, 1)\n    index = output.data.cpu().numpy().argmax()    \n    return index","d4020f0f":"plt.figure(figsize=(20,20))\nfor i, images in enumerate(pred_files):\n    # just want 25 images to print\n    if i > 49:\n      break\n    # Using pil to open the image\n    img = Image.open(images)\n    # Calling prediction function on image\n    index = predictions(img)\n    # Plotting\n    plt.subplot(5,10,i+1)\n    plt.title(classes[index])\n    plt.axis('off')\n    plt.imshow(img)","673fa96f":"from torchvision.models import vgg19 \n\nvgg19 = vgg19(pretrained = True)\nvgg19","d5ccae37":"valid_size = 0.2 \n\ntrain_dir = '..\/input\/intel-image-classification\/seg_train\/seg_train'\ntest_dir = '..\/input\/intel-image-classification\/seg_test\/seg_test'\npred_dir =\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\"\n\nimg_size = 224 \n\n# Transform train and test data\ntransform_train = transforms.Compose([transforms.Resize((img_size, img_size)), \n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransform_test = transforms.Compose([\n                                     transforms.Resize((150, 150)),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_data = datasets.ImageFolder(train_dir, transform=transform_train)\ntest_data = datasets.ImageFolder(test_dir, transform=transform_test)\n\npred_files = [os.path.join(pred_dir, f) for f in os.listdir(pred_dir)]\nclasses=['forest', 'buildings', 'glacier', 'mountain', 'sea', 'street']\n\nlen(train_data), len(test_data) ","905ac865":"num_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\nprint(split)\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# # Define samplers for obtaining training and validation batches \ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=32, sampler=train_sampler, num_workers = 2)\nvalidloader = torch.utils.data.DataLoader(train_data, batch_size = 32, sampler = valid_sampler, num_workers = 2)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size = 32, num_workers = 2)","d6892faa":"torch.manual_seed(42)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice ","feec0505":"for param in vgg19.parameters():\n    param.required_grad = False","1d13f88c":"class vggModel(torch.nn.Module):\n  def __init__(self, num_classes = 6, pretrained=True):\n    super().__init__()\n     \n    self.fc1 = torch.nn.Linear(25088, 512)\n    self.dropout = nn.Dropout(p=0.2)\n    self.fc2 = torch.nn.Linear(512, 256)\n    self.output_layer = torch.nn.Linear(256, num_classes)\n\n  def forward(self, x):\n    x = F.relu(self.fc1(x))\n    x = self.dropout(x)\n    x = F.relu(self.fc2(x))\n    x = self.output_layer(x)\n    return x ","7fed5f1d":"model_v = vggModel(pretrained = True)\nmodel_v\nvgg19.classifier = model_v ","ce3c712e":"criterion = nn.CrossEntropyLoss()","4055a630":"optimizer = torch.optim.SGD(vgg19.parameters(), lr=0.001)","58c1f712":"def batch_accuracy(xb, yb):\n  correct = (xb.argmax(1)) == yb \n  return correct.float().mean().item()\n\ndef validate_epoch(model_v):\n  epoch_loss = 0 \n  accuracy = 0 \n  model_v.eval() \n\n  with torch.no_grad():\n    for input_batch, labels in testloader:\n      output = model_v(input_batch.to (device))\n      loss = criterion(output, labels.to(device))\n      epoch_loss += loss.item()\n      accuracy += batch_accuracy(output, labels.to(device))\n\n    accuracy \/= len(testloader)\n    epoch_loss \/= len(testloader)\n    return accuracy, epoch_loss \n\n\n\ndef train_model(model_v, num_epochs, print_every=1):\n  for i in range(num_epochs):\n    epoch_loss = 0\n    accuracy = 0 \n    model_v.train()\n\n    for input_batch, labels in trainloader:\n      output = model_v(input_batch.to(device))\n      loss = criterion(output, labels.to(device))\n      epoch_loss += loss.item()\n\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n      accuracy += batch_accuracy(output, labels.to(device))\n\n    accuracy \/= len(trainloader)\n    epoch_loss \/= len(trainloader)\n\n    if (i+1) % print_every == 0 :\n      test_acc, test_loss = validate_epoch(model_v)\n      print(f'|Epoch: {(i+1):02} | Train Loss: {epoch_loss:.3f} | Train Acc.: {accuracy:.3f} |'+\n                  f' Val. Loss:  {test_loss:.3f} | Val. Acc.: {test_acc:.3f} |')","0eeacd84":"train_model(vgg19.to(device), num_epochs=5)","2b0af56e":"# plt.plot(epoch_loss, label = 'Training loss')\n# plt.plot(test_loss, label='Validation loss')\n# plt.legend(frameon = False)\n# plt.show()","e1df990a":"def predictions(image):\n    # pil_img = Image.open(image)\n    # transform images\n    transform = transform_test(image)\n    # add extra dimension in place of batch size\n    img = transform.unsqueeze(0).cuda() \n    # push to gpu\n    gpu_img = img.to(device)\n    # make prediction\n    output = vgg19(gpu_img)\n    # convert image to numpy format in cpu and snatching max prediction score class index\n    # _, index = torch.max(output.data, 1)\n    index = output.data.cpu().numpy().argmax()    \n    return index","26f0d7fc":"plt.figure(figsize=(20,20))\nfor i, images in enumerate(pred_files):\n    # just want 25 images to print\n    if i > 24:\n      break\n    # Using pil to open the image\n    img = Image.open(images)\n    # Calling prediction function on image\n    index = predictions(img)\n    # Plotting\n    plt.subplot(5,5,i+1)\n    plt.title(classes[index])\n    plt.axis('off')\n    plt.imshow(img)","501f4179":"# resnet50 Pretrained Model\n\n\n","7aaee82f":"**Load the data**","3d0df713":"**Predict**","1469980a":"**Train model**","44960b98":"# vgg19 Pretrained Model\n","c0d36511":"**Check for CUDA**","edebfb4d":"**Specify Loss Function and Optimizer**","dbcbd555":"**Linear layer for pretrained resnet50**"}}