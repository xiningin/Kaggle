{"cell_type":{"7058143b":"code","27932e06":"code","d0ea6a65":"code","332fd132":"code","04f8fb20":"code","2eb67486":"code","e19140ad":"code","b564edaa":"code","a1b6862d":"code","70756e7a":"code","58254337":"code","91e949d3":"code","43c95681":"code","64594612":"code","84fbced2":"code","5146e5f4":"code","06d8f9d3":"code","86c8247c":"code","e782826a":"code","ef61dd9f":"code","3dad712f":"code","3fa5f405":"code","ad752590":"code","eeda2770":"code","6629293e":"code","88324e28":"code","86eb7c6b":"code","0727cffb":"code","a9db37cf":"code","c9793ec8":"code","15acd042":"code","caae6054":"code","5aea1db0":"code","7e379a76":"code","06b0e3e5":"code","f6ad6e4b":"code","b4373953":"code","4ebfcfd5":"code","1eea31cc":"markdown","c24c646f":"markdown"},"source":{"7058143b":"\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom nltk.tokenize import word_tokenize, TreebankWordTokenizer\nfrom nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\nimport nltk\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\n\nfrom sklearn.feature_extraction import text\n\nimport re\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nnltk.download('wordnet')\n\n\n","27932e06":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","d0ea6a65":"train_df.head()","332fd132":"test_df.head()","04f8fb20":"test_id = test_df['id']\ntest_id","2eb67486":"groups = train_df.groupby(\"type\").count()\ngroups.sort_values(\"posts\", ascending=False, inplace=True)\nprint (\"Personality types\", groups.index.values)","e19140ad":"groups[\"posts\"].plot(kind=\"bar\", title=\"Number of Users per Personality type\")","b564edaa":"def text_separator(df):\n    if 'id' not in df.columns:\n        df['id'] = df.index\n    df[\"seperate_posts\"] = df[\"posts\"].apply(lambda x: x.strip().split(\"|||\"))\n    df_temp = pd.DataFrame(df['seperate_posts'].tolist(), index=df['id']).stack().reset_index(level=1, drop=True).reset_index(name='unique_posts')\n    df = df_temp.join(df.set_index('id'), on='id', how = 'left')\n    df = df.drop(['posts', 'seperate_posts'], axis = 1)\n    return df","a1b6862d":"train_df1 = text_separator(train_df)\ntest_df1 = text_separator(test_df)","70756e7a":"train_df1.head()","58254337":"def text_cleaner(text):\n    result = re.sub(r'http[^\\s]*', 'urlweb',text)\n    result = re.sub('[0-9]+','', result).lower()\n    result = re.sub('@[a-z0-9]+', 'user', result)\n    result = ''.join([l for l in result if l not in string.punctuation])\n    return result","91e949d3":"train_df1['cleaned_post'] = train_df1['unique_posts'].apply(text_cleaner)\ntest_df1['cleaned_post'] = test_df1['unique_posts'].apply(text_cleaner)","43c95681":"train_df1.head()","64594612":"train_df1['type'].value_counts().plot(kind = 'bar')\nplt.show()","84fbced2":"def token_maker(df):\n    tokeniser = TreebankWordTokenizer()\n    df['tokens'] = df['cleaned_post'].apply(tokeniser.tokenize)\n    return df","5146e5f4":"train_df1 = token_maker(train_df1)\ntest_df1 = token_maker(test_df1)","06d8f9d3":"train_df1.head()","86c8247c":"# find the stem of each word in words\ndef stemm_maker(words):\n    stemm = SnowballStemmer('english')\n    return [stemm.stem(word) for word in words]  \n\n","e782826a":"train_df1['stem'] = train_df1['tokens'].apply(stemm_maker)\ntest_df1['stem'] = test_df1['tokens'].apply(stemm_maker)","ef61dd9f":"def lemma_maker(words):\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in words]","3dad712f":"train_df1['lemma'] = train_df1['tokens'].apply(lemma_maker)\ntest_df1['lemma'] = test_df1['tokens'].apply(lemma_maker)","3fa5f405":"train_df1.head()","ad752590":"train_df1['cleaned_lemma'] = train_df1['lemma'].apply(lambda x: ' '.join(x))\ntest_df1['cleaned_lemma'] = test_df1['lemma'].apply(lambda x: ' '.join(x))","eeda2770":"X_train = train_df1.groupby('id')['cleaned_lemma'].apply(list).reset_index()\nX_test = test_df1.groupby('id')['cleaned_lemma'].apply(list).reset_index()\n\ntrain_df['clean_post'] = X_train['cleaned_lemma'].apply(lambda x: ' '.join(x))\ntest_df['clean_post'] = X_test['cleaned_lemma'].apply(lambda x: ' '.join(x))\n","6629293e":"def mbti_classes(df):\n    mind = {\"I\": 0, \"E\": 1}\n    energy = {\"S\": 0, \"N\": 1}\n    nature = {\"F\": 0, \"T\": 1}\n    tactics = {\"P\": 0, \"J\": 1}\n    mbti = [mind, energy, nature, tactics]\n    mbti_list = ['mind', 'energy', 'nature', 'tactics']\n    for i in range(len(mbti)):\n        df[str(mbti_list[i])] = df['type'].astype(str).str[i].map(mbti[i])\n    return df","88324e28":"train_df = mbti_classes(train_df)","86eb7c6b":"words2remove = ['infj', 'entp', 'intp', 'intj', 'entj', 'enfj', 'infp', 'enfp',\n       'isfp', 'istp', 'isfj', 'istj', 'estp', 'esfp', 'estj', 'esfj', 'infjs', 'entps', 'intps', 'intjs', 'entjs', 'enfjs', 'infps', 'enfps',\n       'isfps', 'istps', 'isfjs', 'istjs', 'estps', 'esfps', 'estjs', 'esfjs', 'mbti']","0727cffb":"from sklearn.feature_extraction.text import CountVectorizer\n\nvect = CountVectorizer(lowercase=False, stop_words = words2remove, max_features=200, ngram_range= (3,3))\ntrain_vector = vect.fit_transform(train_df['clean_post'])\ntest_vector = vect.fit_transform(test_df['clean_post'])\n","a9db37cf":"tfizer = TfidfTransformer()\ntfizer.fit(train_vector)\ntrain_vector = tfizer.fit_transform(train_vector)","c9793ec8":"tfizer = TfidfTransformer()\ntfizer.fit(test_vector)\ntest_vector = tfizer.fit_transform(test_vector)","15acd042":"vect.get_feature_names()","caae6054":"X_train = train_vector\nX_test = test_vector\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\n\n","5aea1db0":"y_train1 = train_df['mind']\n\nlogreg.fit(X_train, y_train1)\ny_pred_mind = logreg.predict(X_test)","7e379a76":"y_train2 = train_df['energy']\n\nlogreg.fit(X_train, y_train2)\ny_pred_energy = logreg.predict(X_test)","06b0e3e5":"y_train3 = train_df['nature']\n\nlogreg.fit(X_train, y_train3)\ny_pred_nature = logreg.predict(X_test)","f6ad6e4b":"y_train4 = train_df['tactics']\n\nlogreg.fit(X_train, y_train4)\ny_pred_tactics = logreg.predict(X_test)","b4373953":"LogisticRegressor =pd.DataFrame({'id': test_id, 'mind': y_pred_mind, 'energy': y_pred_energy, 'nature':y_pred_nature, 'tactics': y_pred_tactics})\n","4ebfcfd5":"LogisticRegressor.to_csv('LogisticRegressor.csv', index=False)","1eea31cc":"Data Preprocessing","c24c646f":"Tokenization"}}