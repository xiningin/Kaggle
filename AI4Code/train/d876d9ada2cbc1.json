{"cell_type":{"e2d11738":"code","bcc3fdb4":"code","f60ee6ca":"code","e98cb74e":"code","83af5b96":"code","6f014f14":"code","4de1f135":"code","42809fa0":"code","39f52810":"code","2b95483d":"code","bbed02b3":"code","ccb95bcd":"code","f1c2c55d":"code","0f7e07b4":"code","e867af46":"code","9bc8cef5":"code","d0178ab8":"code","0eab46f7":"code","f6d79587":"code","d44fabbf":"code","8199ba68":"code","c4ee5817":"code","1ea0391d":"code","3c349f01":"code","fca10707":"code","8a047d22":"code","eba38bde":"code","db61c770":"code","c940fc7f":"code","0d45553d":"code","d14922f1":"code","750e150f":"code","a76c3896":"code","6da10fd3":"code","2e8bef19":"code","d5d5bea5":"code","9d661442":"code","a803bd02":"code","b360b211":"code","7e344a50":"code","154dd654":"code","e5feed74":"code","2e18da0f":"code","c46a5a16":"code","b06fb005":"code","4978e4f4":"code","25fd9d72":"code","db11d397":"code","f73dcd5d":"code","95a7111e":"code","9adfc94f":"code","b72ad545":"code","36606612":"code","a17dfd97":"code","c10daa10":"code","371030b6":"code","01d14576":"code","e9a9fe33":"code","205d46ad":"code","54176bb5":"code","2b424fff":"code","3f7f041d":"code","41a74d4c":"code","af8444d0":"code","7a7d11d9":"code","8f13263a":"code","bb7281e2":"code","5a4449c4":"code","44806800":"code","94476b85":"code","1ad2817f":"code","ac66e318":"code","e7476f4f":"code","5e732a45":"code","3f7011aa":"code","372a3794":"code","c75c7301":"markdown","4ac3e74f":"markdown","4f3220eb":"markdown","a62461dc":"markdown","233e6f46":"markdown","5bc5c62f":"markdown","bc827448":"markdown","3a82336e":"markdown","0c5fe14f":"markdown","02220e08":"markdown","201e7fb5":"markdown","b4fca9db":"markdown","98b3a273":"markdown","eee35ad4":"markdown","d776b04a":"markdown","693b49c5":"markdown","05b7521f":"markdown","0e5192a4":"markdown","a5b5b5d3":"markdown","c54cc9e5":"markdown","a863f9da":"markdown","9206f6dd":"markdown","21456dd9":"markdown","e2c4314b":"markdown","0b595697":"markdown","decef4ae":"markdown","cb2f455c":"markdown","d1a586e5":"markdown","a75dd7ac":"markdown","5207adb2":"markdown","923c0a97":"markdown","37f4427f":"markdown","a97d6f1a":"markdown","6f4e46dc":"markdown","ce71e3fd":"markdown","45e89b4d":"markdown","20a78b1f":"markdown","606a4407":"markdown","afdbd43d":"markdown","a2142d75":"markdown","5cb27124":"markdown","5723349f":"markdown","0fda0bc5":"markdown","bf39fe0b":"markdown","4bbd92be":"markdown","bc81138f":"markdown","36bdf4c8":"markdown","ff264787":"markdown","c35b023f":"markdown","c6d6dac0":"markdown","09738528":"markdown","ee76a5b9":"markdown","0c7c2f48":"markdown","aa158400":"markdown"},"source":{"e2d11738":"import pandas as pd","bcc3fdb4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f60ee6ca":"csv_path = '\/kaggle\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv'\ndf = pd.read_csv(csv_path)","e98cb74e":"df.head(3)","83af5b96":"df.shape","6f014f14":"df.info()","4de1f135":"miss = df.isnull().sum()\nmiss_= (df.isnull().sum()\/df.isnull().count())*100\n\nmissing_data = pd.concat([miss, miss_], axis=1, keys=['Total', 'Percent'])\nmissing_data","42809fa0":"df['city'].value_counts()","39f52810":"df['floor'].value_counts()","2b95483d":"df['floor'] = df['floor'].replace(['-','301'], 0)\ndf['floor'].value_counts()","bbed02b3":"df['floor'] = df['floor'].astype(int)","ccb95bcd":"df.info()","f1c2c55d":"df['floor'] = df['floor'].replace(0, df['floor'].median())\ndf['floor'].value_counts()","0f7e07b4":"ax = df['city'].value_counts().plot(kind='bar', figsize=(15,6))\nax.set_xlabel('Cities')\nax.set_title('Cities visualization', fontsize = 25)","e867af46":"ax = df['rooms'].value_counts().plot(kind='bar', figsize=(20,6))\nax.set_xlabel('Number of rooms')\nax.set_title('Rooms visualization')","9bc8cef5":"ax = df['bathroom'].value_counts().plot(kind='bar', figsize=(15,6))\nax.set_xlabel('Number of bathroom')\nax.set_title('Bathroom visualization', fontsize = 25)","d0178ab8":"df['animal'].value_counts()","0eab46f7":"df['animal'] = df['animal'].replace(['acept'], 1)\ndf['animal'] = df['animal'].replace(['not acept'], 0)","f6d79587":"df['furniture'].value_counts()","d44fabbf":"df['furniture'] = df['furniture'].replace(['furnished'], 1)\ndf['furniture'] = df['furniture'].replace(['not furnished'], 0)","8199ba68":"df.head()","c4ee5817":"df.corr()","1ea0391d":"import matplotlib.pyplot as plt\n\nx= df['city']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","3c349f01":"import matplotlib.pyplot as plt\n\nx= df['area']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","fca10707":"df.sort_values(by = 'area', ascending = False)[:2]","8a047d22":"df = df.drop(df[df['area'] == 46335].index)\ndf = df.drop(df[df['area'] == 12732].index)","eba38bde":"import matplotlib.pyplot as plt\n\nx= df['area']\ny= df['total (R$)']\n\nplt.scatter(x,y)","db61c770":"x= df['rooms']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","c940fc7f":"x= df['bathroom']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","0d45553d":"x= df['parking spaces']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","d14922f1":"import matplotlib.pyplot as plt\n\nx= df['hoa (R$)']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","750e150f":"y= df['rent amount (R$)']\nx= df['total (R$)']\n\nplt.scatter(x,y)","a76c3896":"import matplotlib.pyplot as plt\n\nx= df['property tax (R$)']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","6da10fd3":"df.sort_values(by = 'property tax (R$)', ascending = False)[:2]","2e8bef19":"df = df.drop(df[df['property tax (R$)'] == 10830].index)\n","d5d5bea5":"x= df['property tax (R$)']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","9d661442":"x= df['fire insurance (R$)']\ny= df['rent amount (R$)']\n\nplt.scatter(x,y)","a803bd02":"x = df.drop(['total (R$)','city','rent amount (R$)'], axis=1)\ny = df['rent amount (R$)']","b360b211":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","7e344a50":"algorithm = SelectKBest(score_func=chi2, k=5)\n\nbest_features = algorithm.fit_transform(x,y)","154dd654":"print('scores:',algorithm.scores_)\n#print('Resultado da transformacao:\\n',dados_das_melhores_preditoras)","e5feed74":"chi_scores = algorithm.scores_","2e18da0f":"chi_ = pd.DataFrame(data=chi_scores,columns = ['Chi^2'], index=['area','rooms','bathroom','parking spaces','floor','animal','furniture','hoa (R$)','property tax (R$)','fire insurance (R$)'])","c46a5a16":"chi_['Chi^2'].sort_values(ascending=False)","b06fb005":"from sklearn.model_selection import train_test_split","4978e4f4":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)","25fd9d72":"from sklearn.linear_model import LinearRegression","db11d397":"#lm = linear model\nlm = LinearRegression()","f73dcd5d":"lm.fit(x_train, y_train)","95a7111e":"a_lm =lm.score(x_test, y_test)\nprint('R^2=', a_lm)         ","9adfc94f":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","b72ad545":"kfold = KFold(n_splits=5,shuffle=True)","36606612":"b_lm = cross_val_score(lm,x,y,cv=kfold)\nprint(b_lm.mean())","a17dfd97":"from sklearn.linear_model import Ridge\n#rm = Ridge model\nrm = Ridge()","c10daa10":"rm.fit(x_train, y_train)","371030b6":"a_rm =rm.score(x_test, y_test)\nprint('R^2=',a_rm)","01d14576":"kfold = KFold(n_splits=5,shuffle=True)","e9a9fe33":"b_rm = cross_val_score(rm,x,y,cv=kfold)\nprint(b_rm.mean())","205d46ad":"from sklearn.linear_model import Lasso\n#lassom = lasso model\nlassom = Lasso(alpha=1000, max_iter=1000, tol=0.1)","54176bb5":"lassom.fit(x_train, y_train)\n\na_lassom = lassom.score(x_test, y_test)\nprint('R^2=',a_lassom)","2b424fff":"kfold = KFold(n_splits=5,shuffle=True)","3f7f041d":"b_lassom = cross_val_score(lassom,x,y,cv=kfold)\nprint(b_lassom.mean())","41a74d4c":"from sklearn.linear_model import ElasticNet\n#em = elastic model\nem = ElasticNet(alpha=1,max_iter=5000, l1_ratio=0.5, tol=0.2)","af8444d0":"em.fit(x_train, y_train)\n\na_em = em.score(x_test, y_test)\nprint('R^2=',a_em)","7a7d11d9":"kfold = KFold(n_splits=5,shuffle=True)","8f13263a":"b_em = cross_val_score(em,x,y,cv=kfold)\nprint(b_em.mean())","bb7281e2":"import numpy as np\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.tree import DecisionTreeRegressor","5a4449c4":"min_splits = np.array([2,3,4,5,6,7])\nmax_lever = np.array([3,4,5,6,7,9,11])\nalgorithm = ['mse', 'friedman_mse', 'mae']\n\nvalores_grid = {'min_samples_split':min_splits,\n                'max_depth':max_lever,\n                'criterion':algorithm\n               }","44806800":"tm = DecisionTreeRegressor()","94476b85":"grid_tm = GridSearchCV(estimator=tm, param_grid=valores_grid, cv=5, n_jobs=-1)\ngrid_tm.fit(x,y)","1ad2817f":"print('R2:',grid_tm.best_score_)\nprint('Min to split:',grid_tm.best_estimator_.min_samples_split)\nprint('Max depth:',grid_tm.best_estimator_.max_depth)\nprint('Algorithm:',grid_tm.best_estimator_.criterion)","ac66e318":"score_df_data = {'Linear regression':[0.9870,0.9871],\n        'Ridge regression':[0.9870,0.9872],\n        'Lasso regression':[0.9828,0.9823],\n        'ElasticNet':[0.9866,0.9866],\n        'Decision tree regression':['Nan',0.9929]}\n\n\n\nscore_df = pd.DataFrame(data=score_df_data ,index=['Train_test','Cross_val'])\n","e7476f4f":"score_df","5e732a45":"a = input('AREA:\\n')\nb = input('ROOMS:\\n')\nc = input('BATHROOM:\\n')\nd = input('PARKING SPACES:\\n')\ne = input('FLOOR:\\n')\nf = input('ANIMAL 1-YES\/0-NO:\\n')\ng = input('FORNITURE 1-YES\/0-NO:\\n')\nh = input('HOA:\\n')\ni = input('PROPERTY TAX:\\n')\nj = input('FIRE INSURANCE:\\n')","3f7011aa":"l = rm.predict([[int(a),int(b),int(c),int(d),int(e),int(f),int(g),int(h),int(i),int(j)]])","372a3794":"print('The total value suggest is R$',l[0])","c75c7301":"## 5.4 - ElasticNet","4ac3e74f":"Much better!","4f3220eb":"Easy peasy right? We created our model object, trained with the ``lm.fit()`` and then get the score; After that We did a cross validation to double check our model accuracy. If you understood how we build and train this model, understand the following ones will be easy","a62461dc":"Nice! Works weel","233e6f46":"'Enemy outliar spotter! What your orders Sir?'\n\n'Drop then all!'","5bc5c62f":"* furnished = 1\n* not furnished = 0","bc827448":"So we have 4 categorical features and 8 numerical features. That nice because, in a short future, when we will be building models, we will need that this data be all numeric","3a82336e":"### Bathroom","0c5fe14f":"Finishing our modelling work, let's compare the accuracy values for each model(using train_test_split and cross validation)","02220e08":"Again, again and again.. Hope you guys are understanding.. I'm not commenting too much now because it's much like the linear regression and the ridge regression. One more time, i could be variating parameters in the lasso regression and in the elasticnet, but we are getting good results without change then","201e7fb5":"# 4 - Feature selection\nIn this case, we have only a few features, so it's not a problem use then all to create the model. But maybe you guys can know, we have some huge datasets, some with much more then 20 features, so here we will see how to select some good predict features","b4fca9db":"# 2 - 'What do we have and waht do we want?'","98b3a273":"## 3.1 - Checking and dealing with missing values","eee35ad4":"### Area","d776b04a":"Now we have something that worth variate. To do this variation with the parameters we can use GridSearchCV","693b49c5":"## 5.5 - Decision tree regressor","05b7521f":"## 5.2 - Ridge regression","0e5192a4":"'Enemy spooted, you know what to do...'","a5b5b5d3":"* acept = 1\n* not acept = 0","c54cc9e5":"We have almost 11000 rows and 13 features, we have a lot of data and before start to plat with this deta let's define what do we wanto to predict. In this case i will be trying to predict the 'rent amount'; So we have 12 independent variables and 1 dependent variable(target). Our target is a price, so it's a continuous numeric variable, then we can conclude that we have a regression problem","a863f9da":"Now it's time for the fun step, here it is the different kinds of regression algorithms that I will use:\n* Linear regression\n* Ridge regression\n* Lasso regression\n* Elastic net\n* Decision tree regressor","9206f6dd":"### Fire insurance\nCome on, keep going, you're on fire! \n(Ok.. that has terrible...)","21456dd9":"Enemy spooted!\n\n'-' doesn't seem like a value to enumerate floors.. and I'm pretty sure that we don't have a building with 301 floors in those cities. Let's transform those values to '0', tranform these feature for numerical, get the median and replace those zeros","e2c4314b":"# 3 - Exploratory data analysis(EDA) and visualization","0b595697":"Now let's study the correlation between our features. To do that we can plor a correalation table but I think that is better visualize in a scatter plot","decef4ae":"### Total ","cb2f455c":"##### Furniture","d1a586e5":"We still have some enemys on the field, but I will let then live another day...","a75dd7ac":"## 3.3 - Turning categorical into numerical\nAs I said before, our model work with numeric values. We need to turn our categorical features into numerical features; We could use ``pd.get_dummies()`` but because we only have two possibles categories in each feature, we can simply use ``replace()`` \n\n* I will discard 'city' that why i'm not work with this feature; If our model get a poor accuracy we can go back here and transform 'city' values in numerical values too","5207adb2":"# 3.4 - Correlation","923c0a97":"And that is... strange.. what is a problem without variables missing? Let's keep searching","37f4427f":"# 6 - Predicting new values","a97d6f1a":"## 5.1 - Linear regression","6f4e46dc":"### Parking spaces","ce71e3fd":"Much like the before model right? We could variate the 'alpha' value using GridSearchCV, but as we already got a good result we don't need to do it","45e89b4d":"Our variables are numerical or categorical?","20a78b1f":"# 5 - Modelling","606a4407":"### (Highest in the )Rooms\nHope you catch the reference ;)","afdbd43d":"##### Animal","a2142d75":"Pretty!\n\nAll moodels have a realy good accuracy\n\n'If that's good?'\n\nIn the reality that give me goosebumps, because I start to think that something is wrong. ","5cb27124":"### City","5723349f":"# 1 - Importing dataframe \nIf you are some kind a moster that skip the introductions, I undestand and here we go!\n\nFirst things first, import pandas to work with dataframes and them read the .csv file with the data","0fda0bc5":"So, if we would doesnt not wanted to use all features, we could use some of those features good ranked","bf39fe0b":"One way to see if that huge accuracy are correct is inserting new values to see how the model react.\n\nI did some tests and looks that indeed we have good prediction","4bbd92be":"Classic train and test split","bc81138f":"I did some tests and looks that indeed we have decent prediction; What about you guys? What do you think about our results? We can do a lot more in EDA, what would you add? ;)\n\n\nLeave a comment!","36bdf4c8":"Now that we know what we have, let's start to search for what we don't have(wow, that's sound very philosophical), let's try to find missing values","ff264787":"### Property tax","c35b023f":"## 5.3 - Lasso regression","c6d6dac0":"Good work!","09738528":"## 3.2 - Visualization\nWe can use plots to have and idea of the way that our data are distributed. It's simple and effective.","ee76a5b9":"A good way to select a variable is using chi^2. I realy recomend that you guys search about this method,  it have a lot of math and I will not spend so much time here showing you guys how the algorithm works, but in resume, we are searching for a feature with large chi^2 value","0c7c2f48":"### HOA","aa158400":"# 0 - Introduction\nHeyy guys, my name is Gabriel Riquieri and I'm a computer science student. I started to study data science a time ago and realy like it and start to work in some projects. That one it's the first project that i share. I decided to do it in a didactic way to solidify my own knowledge.  I'm not a professor or some Phd student, so my code and explanations may contain some mistakes or maybe there is some way do do with a better performace. I hope you guys enjoy this small work, feel free to leave a comment or email me in gabriel.riquieri@ufu.br"}}