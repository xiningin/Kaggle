{"cell_type":{"eff74cbe":"code","65a6ba69":"code","4262c4ab":"code","976b4f73":"code","6ca955ef":"code","c2a6c8a1":"code","a7c73c55":"code","868c6378":"code","178664c7":"code","7ad4079a":"code","f3ff0559":"code","93cfd505":"code","799fcfec":"code","3c92fa84":"code","124078b3":"markdown","38558ff9":"markdown","5d1f7941":"markdown","6bc053ac":"markdown","9b96eb83":"markdown","75a55150":"markdown","2a156f8d":"markdown","e276820d":"markdown","6c435b5d":"markdown","9638e984":"markdown","d3c9b47c":"markdown","30b1cc8f":"markdown","f393ebeb":"markdown","e43470d0":"markdown"},"source":{"eff74cbe":"import pandas as pd\nimport numpy as np\n# Loading in Iowa housing data\nmain_file_path = '..\/input\/house-prices-advanced-regression-techniques\/train.csv' # this is the path to the Iowa data that you will use\ndata = pd.read_csv(main_file_path)","65a6ba69":"# save filepath to variable for easier access\niowa_file_path = '..\/input\/house-prices-advanced-regression-techniques\/train.csv'\n\n# read the data and store data in DataFrame titled melbourne_data\niowa_data = pd.read_csv(iowa_file_path) \n\n# print a summary of the data in Melbourne data\nprint(iowa_data.describe())","4262c4ab":"print(iowa_data.columns)","976b4f73":"iowa_price_data = iowa_data.SalePrice\n# the head command returns the top few lines of data.\nprint(iowa_price_data.head())","6ca955ef":"columns_of_interest = ['BedroomAbvGr', 'FullBath']\ntwo_columns_of_data = iowa_data[columns_of_interest]\n# We can verify that we got the columns we need with the describe command.\ntwo_columns_of_data.describe()","c2a6c8a1":"y = iowa_data.SalePrice","a7c73c55":"iowa_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF',\n                   'FullBath','BedroomAbvGr', 'TotRmsAbvGrd']\nX = iowa_data[iowa_predictors]","868c6378":"# This import would usually go at the top of our code but for illustrative\n# purposes we import skikit learn here ans subsequently later down as well.\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Define model\niowa_model = DecisionTreeRegressor()\n\n# Fit model\niowa_model.fit(X,y)\n# The output describes some parameters about the type of model you've built.","178664c7":"print('Making predictions for the following houses:')\nprint(X.head())\nprint('The predictions are:')\nprint(iowa_model.predict(X.head()))","7ad4079a":"from sklearn.metrics import mean_absolute_error\n\n# Here we are testing accuracy based on our training data, this is bad and should not be done in practice\npredicted_home_prices = iowa_model.predict(X)\nmean_absolute_error(y,predicted_home_prices)","f3ff0559":"from sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X,y,random_state=0)\n\n# Define model\niowa_model = DecisionTreeRegressor()\n# Fit model\niowa_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = iowa_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_predictions))","93cfd505":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor()\nforest_model.fit(train_X, train_y)\niowa_preds = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, iowa_preds))","799fcfec":"test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest_X = test[iowa_predictors]\n\npredicted_prices = forest_model.predict(test_X)\nprint(predicted_prices)","3c92fa84":"my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\nmy_submission.to_csv('submission.csv', index=False)","124078b3":"**we'll make predictions for the first rows of the training data to see how the predict function works.**","38558ff9":"# Now We Perform Model Validation\n\nIn most but not all applications, prediction accuracy will be the relevant measure of the quality of our model.\nFor this we will use Mean Absolute Error (MAE)\n\nThe prediction error for each house is: error=actual\u2212predicted","5d1f7941":"**Now we'll try using a Random Forest Tree on our data to see what kind of improvement we can see:**","6bc053ac":"# Introduction\n**we predict sales prices and practice feature engineering, RFs, and gradient boosting.**\n\n**This will my workspace for the [Machine Learning course](https:\/\/www.kaggle.com\/learn\/machine-learning).**","9b96eb83":"# Making our prediction for our test data","75a55150":"# Time to Choose the Prediction Target","2a156f8d":"# Selecting and Filtering Data\n\nBefore we can choose variables\/columns, it is helpful to see a list of all columns in the dataset. That is done with the columns property of the DataFrame (the bottom line of code below).","e276820d":"# Building Your Model\n\n**We are using scikit-learn library to create your models.**\nThe steps to building and using a model are:\n\n* **Define:** What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n* **Fit:** Capture patterns from provided data. This is the heart of modeling\n* **Predict:** Just what it sounds like\n* **Evaluate:** Determine how accurate the model's predictions are.","6c435b5d":"# Selecting Multiple Columns\n\nYou can select multiple columns from a DataFrame by providing a list of column names inside brackets. Remember, each item in that list should be a string (with quotes).","9638e984":"**There are many ways to select a subset of your data. We'll start with two main approaches: Selecting a single cloumn and selecting multiple columns.**\n\n# Selecting a Single Column\n\nYou can pull out any variable (or column) with dot-notation. This single column is stored in a Series, which is broadly like a DataFrame with only a single column of data. Here's an example:","d3c9b47c":"# Interpreting Data Description\nThe results show 8 numbers for each column in your original dataset. The first number, the count, shows how many rows have **non-missing values**.\n\nThe second value is the mean, which is the average. Under that, std is the standard deviation, which measures how numerically spread out the values are.\n\nTo interpret the min, 25%, 50%, 75% and max values, imagine sorting each column from lowest to highest value. The first (smallest) value is the min. If you go a quarter way through the list, you'll find a number that is bigger than 25% of the values and smaller than 75% of the values. That is the 25% value (pronounced \"25th percentile\"). The 50th and 75th percentiles are defined analgously, and the max is the largest number.","30b1cc8f":"# Choosing Predictors\n\nNext we select the predictors. Sometimes, you will want to use all of the variables except the target..\n\nIt's possible to model with non-numeric variables, but we'll start with a narrower set of numeric variables. In the example data, the predictors will be chosen as:","f393ebeb":"# Making our submission","e43470d0":"**To not use our training data, we will split the data to form a validation data set.**"}}