{"cell_type":{"f811b24d":"code","edd6359b":"code","9de2b46e":"code","1b861c5a":"code","c1409023":"code","8dfb2158":"code","f4164dd0":"code","740a8f5c":"code","1f2fe709":"code","c3474a4e":"code","6f2552a3":"code","c27e2a92":"code","09de1931":"code","695a9a53":"code","31a11055":"markdown","34489d27":"markdown","5a3fcdd1":"markdown","42c1aeb4":"markdown","fc568485":"markdown","0cbb6a88":"markdown","e5c10bfe":"markdown","f71e3d75":"markdown","9d64962d":"markdown","1f76b91f":"markdown","1bd36c6b":"markdown","7c545736":"markdown"},"source":{"f811b24d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","edd6359b":"data = pd.read_csv(\"..\/input\/company-bankruptcy-prediction\/data.csv\")\ndata.head()","9de2b46e":"data.describe()","1b861c5a":"# Compute the correlation matrix\ncorr = data.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","c1409023":"for name in data.columns:\n    ax = sns.violinplot(data=data[name], orient=\"h\", palette=\"Set2\").set_title(name)\n    plt.show()\n\n    ","8dfb2158":"# First we have to create the subsets of the data\nimport sklearn\nfrom sklearn import svm\n\ntarget = \"Bankrupt?\"\n\nshuffled_data = data.sample(frac=1)\nX = shuffled_data.drop([target], axis=1)\ny = shuffled_data[target]\nx_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.25)\n","f4164dd0":"clf = svm.SVC()\nclf.fit(x_train, y_train)","740a8f5c":"prediction = clf.predict(x_test)\nprediction","1f2fe709":"# Count how many were wrong\ny_list = y_test.tolist()\n\ncounter = 0\nfor index, val in enumerate(prediction):\n    if y_list[index] != val:\n        counter += 1\n       \n# This is how many that were wrong\ncounter","c3474a4e":"print(f\"Accuracy: {round(100*(1 - counter\/len(prediction)), 2)}%\")","6f2552a3":"# It looks like the SVM is not random like I thought it would be\n# I found another random classifier and I will use it instead\n# As you can see, I am a beginner and any advice would be appreciated!\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef train_model(X, y, x_test, y_test, random=True):\n    if random:\n        # if we want a random model generate the model like this\n        clf = RandomForestClassifier()\n    else:\n        # Otherwise generate it normally\n        clf = svm.SVC()\n    \n    # Train the model\n    clf.fit(X, y)\n    \n    # calculate the Training Accuracy\n    trainingAccuracy = scoreModel(clf, X, y)\n    \n    print(f\"\\nTraining Accuracy: {round(100*(1 - trainingAccuracy\/len(X)), 2)}%\")\n    \n    # Calculate the Validation Accuracy\n    validationAccuracy = scoreModel(clf, x_test, y_test)\n    \n    print(f\"Validation Accuracy: {round(100*(1 - validationAccuracy\/len(x_test)), 2)}%\")\n\n    # We only want the validation accuracy, training accuracy is essentially the same thing\n    return clf, validationAccuracy\n\ndef scoreModel(model, X, y):\n    # Get the Prediction\n    prediction = model.predict(X)\n    # Get the actual values\n    y_list = y.tolist()\n    \n    # count how many where wrong\n    counter = 0\n    for index, val in enumerate(prediction):\n        if y_list[index] != val:\n            counter += 1\n            \n    return counter","c27e2a92":"# Get the best model\nbestModel, bestScore = train_model(x_train, y_train, x_test, y_test, False) # Just in case all of our models are horrible\n\n# Run it multiple times\nfor i in range(15):\n    model, counter = train_model(x_train, y_train, x_test, y_test)\n    # Save the best scorer\n    if counter < bestScore:\n        bestModel, bestScore = model, counter\n\nprint(f\"\\nThe best model had an accuracy of {round(100*(1 - bestScore\/len(prediction)), 2)}%\")\n","09de1931":"# I am not sure if this works on Kaggle but if you download this file it should create a save file for the best model\nfrom joblib import dump, load\ndump(bestModel, \"best_model.joblib\")","695a9a53":"# To load from the save\nbestModelFromSave = load(\"best_model.joblib\")","31a11055":"# Hello\nIn this kernel, I will be using scikit-learn to predict if a company is bankrupt.","34489d27":"This dataset has so many categories. You can't really see much by looking at these categories. \n\nLet's take a look at the individual columns to see how they are spreadout.\n\n","5a3fcdd1":"For this dataset we are trying to predict whether a company is bankrupt. So we will have two different groups of outputs\n0. Not Bankrupt\n1. Bankrupt","42c1aeb4":"Now lets create our initial model.","fc568485":"Now lets create a function to do this automatically and select the best model from that.","0cbb6a88":"Lets score it","e5c10bfe":"Next we can run the function multiple times and save the best one.","f71e3d75":"Lets see how the data looks like.","9d64962d":"All Done!","1f76b91f":"This means that I will need to build a classifier. \n\nFor this task I will use one of sklearn's various models. I think an SVM should do the job\n\n[Support Vector Machine](https:\/\/scikit-learn.org\/stable\/modules\/svm.html)","1bd36c6b":"Well it looks like they have a ton of columns. This should be helpful when we create a model.","7c545736":"Now we can display this accuracy score as a rounded percent.\n\nThis code finds the percentage of the data points that were wrong, then converts it into the fraction of values that were right, next it converts the fraction to a percent and finally rounds it."}}