{"cell_type":{"675e6c17":"code","aa33faea":"code","dd0c3a06":"code","7908621c":"code","5c555eac":"code","768aca1c":"code","b71080be":"code","05bf2f5e":"code","0e3c8622":"code","8d7db77d":"code","1716d8bb":"code","ee7d7abf":"code","1603c13e":"code","7d4656d8":"code","7952da91":"code","a986df1a":"markdown","953c0b17":"markdown","5d812bbe":"markdown","70c49e95":"markdown","0127ce47":"markdown","0d50599e":"markdown","ecd8788c":"markdown","2d8b8179":"markdown","a16b4191":"markdown","b2f4bbf6":"markdown","47010670":"markdown","d1562b80":"markdown","3463499b":"markdown","183cca20":"markdown","f8cca886":"markdown","c6f8fe99":"markdown"},"source":{"675e6c17":"import numpy as np\nimport pandas as pd\nimport shap\nfrom sklearn.ensemble import RandomForestClassifier\ndata = pd.read_csv('..\/input\/titanic-machine-learning-from-disaster\/train.csv')\nprint('missing...')\ndfnulls = data.isnull().sum()\ncols_isnull = list(dfnulls[dfnulls.values>0].index)\nprint(dfnulls[dfnulls.values>0])","aa33faea":"data.loc[data.Sex=='male', 'Sex'] = 1\ndata.loc[data.Sex=='female', 'Sex'] = 2\ndata.Sex= pd.to_numeric(data.Sex)\n\ndata.Age.fillna(value=data.Age.median() ,inplace=True)\n\ndata.Fare.fillna(data.Fare.describe().loc['50%'], inplace = True) \ndata.Fare = data.Fare.astype('float')\n\ndata.Embarked.fillna(value='S', inplace=True)\nembark = pd.get_dummies(data.Embarked)\ndata = pd.concat([data,embark],axis=1)\n\ndata.Cabin.fillna(value='U', inplace=True)\ndata.Cabin = pd.Series([i[0] if not pd.isnull(i) else 'U' for i in data.Cabin ])\ndata.Cabin  = data.Cabin .map({\"U\":0, \"A\":1, \"B\" : 2 , \"C\":3, \"D\":4, \"E\":5, \"F\":6, \"G\":7,\"T\":0})\ndata.Cabin  = data.Cabin .astype(int)\n\ndata.Ticket = data.Ticket.apply(lambda x: x[:3].strip())\ndata.Ticket = data.Ticket.astype('category')\ndata.Ticket = data.Ticket.cat.codes\n\ndata[\"Family\"]=-1\ndata.Family = data.SibSp + data.Parch + 1\ndata.loc[(data['Family']==1),'Family'] =0\ndata.loc[(data['Family']>1),'Family'] =1\n\ndropColumns =['Name','SibSp','Parch','PassengerId','Embarked']\ndata.drop(columns=dropColumns, inplace=True)\ny = data.Survived","dd0c3a06":"data.tail(1)","7908621c":"data.isnull().sum()","5c555eac":"data.describe()","768aca1c":"x = data.drop(labels = \"Survived\", axis = 1)\ny = data.Survived\nprint(x.shape, y.shape)","b71080be":"random_state = 3\nmax_depth = 5\nn_estimators = 8 \nimport matplotlib.pyplot as plt\n#em Fibonacci  we trust eheheh\nrfc = RandomForestClassifier(max_depth=max_depth, random_state=random_state, n_estimators=n_estimators)\nrfc.fit(x, y)\nimportances = rfc.feature_importances_\nindices = np.argsort(importances)\nfeatures = x.columns\nplt.figure(figsize=(10,5))\nplt.title('Features +importante')\nplt.barh(range(len(indices)), importances[indices], color='g', align='center',linestyle=\"solid\",alpha=0.8)\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Import\u00e2ncia')\nplt.show()","05bf2f5e":"explainer = shap.KernelExplainer(rfc.predict_proba,x[:100])\nshap_values = explainer.shap_values(x[:100])\nshap.summary_plot(shap_values, x[:100])","0e3c8622":"explainer = shap.TreeExplainer(rfc)\nshap_values = explainer.shap_values(x)\nshap.summary_plot(shap_values, x)","8d7db77d":"shap.summary_plot(shap_values[1], x)\nshap.summary_plot(shap_values[0], x)\n","1716d8bb":"shap.dependence_plot(\"Age\", shap_values[1], x)","ee7d7abf":"shap.dependence_plot('Ticket', shap_values[1], x, interaction_index=\"Pclass\")","1603c13e":"shap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[0], x)","7d4656d8":"shap.initjs()\ncolumIndex= 2\nshap.force_plot(explainer.expected_value[1], shap_values[1][columIndex,:], x.iloc[columIndex,:], link=\"logit\")","7952da91":"shap.decision_plot(explainer.expected_value[1], shap_values[1], x,link=\"logit\",highlight=1)","a986df1a":"_A Demora ao executar a celula acima  nos da uma vis\u00e3o unica da for\u00e7a bruta do Kernel SHAP que enumera todo o espa\u00e7o amostral._ \n\n\ud83d\udca5\u26cf\ufe0f Observe que KernelExplainer faz uma aproxima\u00e7\u00e3o de amostragem para o valores.\n\nA importancia das features (vari\u00e1veis) por sua ordena\u00e7\u00e3o decrescente. \n_(mais acima, mais importante)_\n> * *Class 0* = Morto\n> * *Class 1* = Sobrevivente\n","953c0b17":"<a id=\"p1\"><\/a>\n# 0. Etapas em resumo para seguirmos direto ao ponto!\n> _Data Analysis,Feature Engineering, Data Clean, Preprocessing e Model.._\n<br \/>\n<img src=\"https:\/\/memegenerator.net\/img\/images\/16435405.jpg\" style=\"height:90px\" height=\"90\" \/>\n<hr \/>\n\n<i>Como esse n\u00e3o \u00e9 o foco, decidi encurtar as coisas...<\/i>","5d812bbe":"**Gr\u00e1fico de for\u00e7a individual**","70c49e95":"\u2b06\ufe0f O gr\u00e1fico de depend\u00eancia acima,  nos mostra que existe uma tend\u00eancia aproximadamente linear e positiva entre **Age** e **Sex**.\n","0127ce47":"*Contruindo um model em \u00e1rvore para verificar quais vari\u00e1veis s\u00e3o as mais importantes*\n\n<img src=\"https:\/\/instagram.fsdu6-1.fna.fbcdn.net\/v\/t51.2885-15\/e35\/105404732_609825429911783_742267563808032849_n.jpg?_nc_ht=instagram.fsdu6-1.fna.fbcdn.net&_nc_cat=111&_nc_ohc=4K2z5Oxx_mIAX8JUtax&tp=1&oh=41d867aa0932b78b070e8990aa23a17c&oe=6011B3BA\" style=\"height:200px\" \/>\n","0d50599e":"**Gr\u00e1fico de for\u00e7a coletiva**\n\nCada observa\u00e7\u00e3o tem seu pr\u00f3prio gr\u00e1fico de for\u00e7a. \nSe todos os gr\u00e1ficos de for\u00e7a s\u00e3o combinados, girados 90 graus e empilhados horizontalmente.\n\n\n","ecd8788c":"**Observa\u00e7\u00e3o:**\nQuando comparado com a sa\u00edda de nosso modelo random forest, o grafico de resumo, mostra a mesma classifica\u00e7\u00e3o de vari\u00e1vel para as primeiras quatro vari\u00e1veis, mas difere para as demais vari\u00e1veis.\n\n![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-forum-message-attachments\/o\/inbox%2F1173320%2F7a36de4343025b64c1f27a060301d63f%2F1.png?generation=1609005407405063&alt=media)","2d8b8179":"![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-forum-message-attachments\/o\/inbox%2F1173320%2F57353fe4130fbcc013272cc1313112c6%2F1.png?generation=1609000146483661&alt=media)\n###SHAP Values - Explicando os impactos das vari\u00e1veis em suas previs\u00f5es\n\nDetectar anomalias de dados \u00e9 um desafio constante, nesse \"**Kernelicle**' _(kernel + artigo)_, tentarei dar uma pequena exposi\u00e7\u00e3o ao [**SHAP**](https:\/\/shap.readthedocs.io\/en\/latest\/), um framework especializado em explica\u00e7\u00f5es aditivas aplicadas para modelos supervisionados.\n\nVamos fazer um tour pela visualiza\u00e7\u00e3o de dados e constru\u00e7\u00e3o de modelo  usando o dataset [**Titanic - Machine Learning from Disaster**](https:\/\/www.kaggle.com\/c\/titanic) por meio deste kernel. \n\nSe voc\u00ea gosta deste trabalho, por favor, mostre seu apoio por votos positivos.\n\n**Feliz Kaggling!** \ud83d\udd96\ud83d\ude0a\n\n_____\n\n##### **Conte\u00fado**\n0. [Etapas em resumo, para irmos direto ao ponto!](#p1) \ud83d\ude0f\n> * _Data Analysis_\n> * _Feature Engineering_\n> * _Data Clean_\n> * _Preprocessing_\n> * _Model_\n1. [SHAP](#p2)\n>  1. [KernelExplainer](#p3)\n>  1. [TreeExplainer](#p4)\n2. [Refer\u00eancias](#p5)\n\n","a16b4191":"**Gr\u00e1fico de depend\u00eancia**\n\nO gr\u00e1fico de depend\u00eancia \u00e9 um gr\u00e1fico de dispers\u00e3o que mostra o efeito que um \u00fanico feature (vari\u00e1vel) em suas previs\u00f5es.\n\n> * Cada ponto \u00e9 uma \u00fanica previs\u00e3o (linha) em nosso dataset.\n> * O eixo x \u00e9 o valor da feature (nosso xtest).\n> * O eixo y \u00e9 o valor SHAP para a feature especificada.\n","b2f4bbf6":"**Fim**  \n\n*SHAP \u00e9 uma ferramenta poderosa na  explora\u00e7\u00e3o de padr\u00f5es que um algoritmo de aprendizadoidentificou*","47010670":"<a id=\"p2\"><\/a>\n# 1. SHAP\n\n**SHAP** (SHapley Additive exPlanations) \u00e9 uma t\u00e9cnica usada para interpretar os \"black-box models\" para explicar a sa\u00edda de qualquer modelo de Machine Learning.\n\n![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-forum-message-attachments\/o\/inbox%2F1173320%2F4d39e3a335b20b0bb8e25d58f0e00337%2F1.png?generation=1609003097648061&alt=media) \n\nEle conecta a aloca\u00e7\u00e3o de cr\u00e9dito ideal com explica\u00e7\u00f5es locais usando os valores cl\u00e1ssicos de Shapley da teoria dos jogos e suas extens\u00f5es relacionadas ([ver artigos para detalhes e cita\u00e7\u00f5es](https:\/\/github.com\/slundberg\/shap#citations)).\n\n**Desenvolvido por** [Scott M. Lundberg](https:\/\/scottlundberg.com\/).","d1562b80":"<a id=\"p5\"><\/a>\n# Refer\u00eancias\n\n* https:\/\/www.mdeditor.tw\/pl\/paB9\n* https:\/\/www.kaggle.com\/dansbecker\/advanced-uses-of-shap-values\n* https:\/\/github.com\/slundberg\/shap#citations\n* https:\/\/www.kaggle.com\/cast42\/feature-importance-and-dependence-plot-with-shap\n* https:\/\/shap.readthedocs.io\/en\/latest\/overviews.html","3463499b":"<a id=\"p4\"><\/a>\n# 1.2 TreeExplainer\n\nO TreeExplainer foi otimizado para renderizar de forma mais eficar modelos em \u00e1rvore. Como nosso modelo \u00e9 baseado em **\u00e1rvore**, o mais apropriado seria usar o\u00a0TreeExplainer. \ud83d\ude0f\n\n> **Nota**: _Em caso de modelos profundos, ele disp\u00f5es do\u00a0\u00a0DeepExplainer._","183cca20":"<a id=\"p3\"><\/a>\n# 1.1 KernelExplainer\n\nO KernelExplainer constr\u00f3i uma regress\u00e3o linear ponderada usando os dados de treinamento.\u00a0Ele calcula os valores de import\u00e2ncia de cada feature com base nos valores de Shapley e os coeficientes de uma regress\u00e3o linear local.\n\u00a0\u00a0\n> **Desvantagem:**\u00a0eu longo tempo de execu\u00e7\u00e3o.\n\nEssa foi a raz\u00e3o de usar um n\u00famero pequeno na amostragem abaixo! \ud83d\ude05","f8cca886":"\n**O SHAP mede o impacto das vari\u00e1veis, levando em considera\u00e7\u00e3o a intera\u00e7\u00e3o com outras vari\u00e1veis.**  \n*Os valores de Shapley calculam a import\u00e2ncia de um recurso comparando o que um modelo prev\u00ea com e sem o recurso. No entanto, como a ordem na qual um modelo v\u00ea recursos pode afetar suas previs\u00f5es, isso \u00e9 feito em todas as ordens poss\u00edveis, para que os recursos sejam comparados de maneira justa.*  \n[fonte](https:\/\/medium.com\/@gabrieltseng\/interpreting-complex-models-with-shap-values-1c187db6ec83)\n\n![](https:\/\/meichenlu.com\/img\/SHAP_Clustering_XGB.png)\n\n<hr \/>\n\n**Quais s\u00e3o as vantagens?**\n> * **Interpretabilidade global** \n>> Os SHAP Values podem mostrar o quanto cada preditor contribui, positiva ou negativamente, para a vari\u00e1vel de destino.\u00a0\n>> \u00c9 como o gr\u00e1fico de import\u00e2ncia da vari\u00e1vel, mas \u00e9 capaz de mostrar a rela\u00e7\u00e3o positiva ou negativa de cada vari\u00e1vel com o destino (consulte os gr\u00e1ficos de resumo abaixo).\n> * **Interpretabilidade local**\u00a0\n>> Cada observa\u00e7\u00e3o obt\u00e9m seu pr\u00f3prio conjunto de SHAP Values.\u00a0\n>> Isso aumenta muito sua transpar\u00eancia.\u00a0\u00a0\n\n","c6f8fe99":"**Gr\u00e1fico de decis\u00e3o**\n* O eixo x representa a sa\u00edda do modelo. Nesse caso, as unidades s\u00e3o probabilidades de log.\n* O gr\u00e1fico \u00e9 centralizado no eixo x em explainer.expected_value\n>Todos os valores de SHAP s\u00e3o relativos ao valor esperado do modelo, como os efeitos de um modelo linear s\u00e3o relativos \u00e0 intercepta\u00e7\u00e3o.\n* Na parte inferior do gr\u00e1fico, as observa\u00e7\u00f5es convergem em explainer.expected_value."}}