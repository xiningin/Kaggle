{"cell_type":{"341f553c":"code","dadc712b":"code","b4355cad":"code","306715c4":"code","ebc9943b":"code","6e355fcc":"code","2f0e0ee3":"code","ce695e57":"code","8b7767a9":"code","71a4b8a6":"code","8c94cc6b":"code","1a75dc05":"code","a0cfb09f":"code","1527b0a9":"code","53b39615":"code","763803ac":"code","5f77a924":"code","b6c72c1f":"code","4feaaa9a":"code","9e07d5c3":"code","19a20047":"code","d6b19f07":"code","8fd9f29e":"code","34535629":"code","4bb7d41d":"code","94b090ee":"code","e95cdd58":"code","6509cd6a":"markdown","1003064d":"markdown","354103b9":"markdown","5a632c40":"markdown","8fa7e19b":"markdown","29aa3efd":"markdown","c609efb8":"markdown","2ec3dd63":"markdown","321fc03d":"markdown","160293b7":"markdown","57ba85bd":"markdown","5273166e":"markdown","4489b059":"markdown","1b440407":"markdown","e9bcd283":"markdown","0cfbc255":"markdown","f13791d2":"markdown","5f8c1f3d":"markdown","d89d1a46":"markdown","d5e368a1":"markdown","9972c736":"markdown","c02e4396":"markdown","e9d555f8":"markdown","b740693f":"markdown","f6fc449a":"markdown","60d5c46d":"markdown"},"source":{"341f553c":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","dadc712b":"path = '..\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv'\ndf = pd.read_csv(path)\ndf = shuffle(df)\ndf.head()","b4355cad":"unique_cities = df['city'].unique().tolist()\ncities_to_idx = {v:k for k,v in enumerate(unique_cities)}\ndf['city'].replace(cities_to_idx, inplace=True)\n\nunique_animal = df['animal'].unique().tolist()\nanimal_to_idx = {v:k for k,v in enumerate(unique_animal)}\ndf['animal'].replace(animal_to_idx, inplace=True)\n\nunique_furniture = df['furniture'].unique().tolist()\nfurniture_to_idx = {v:k for k,v in enumerate(unique_furniture)}\ndf['furniture'].replace(furniture_to_idx, inplace=True)","306715c4":"total_mean = df['total (R$)'].mean()\nprint(total_mean)","ebc9943b":"df['total (R$)'].values[df['total (R$)'].values < total_mean] = 0\ndf['total (R$)'].values[df['total (R$)'].values > total_mean] = 1","6e355fcc":"df.describe().T","2f0e0ee3":"# replace floor '-' by 0 so we can convert to integer\ndf['floor'].replace({'-': 0}, inplace=True)\n\nscaler_cols = df.columns.tolist()\n\nscaler_cols.remove('animal')\nscaler_cols.remove('furniture')\nscaler_cols.remove('total (R$)')","ce695e57":"scaler = StandardScaler()\n\ndf[scaler_cols] = scaler.fit_transform(df[scaler_cols])\ndf.head()","8b7767a9":"corr = df.corr()\n\nplt.figure(figsize=(14,8))\n\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns,\n        cmap=\"Blues\", annot=True)","71a4b8a6":"top_corr = corr['total (R$)'][corr['total (R$)'] > 0.5].index.tolist()\ntop_corr.remove('total (R$)')\nprint(top_corr)","8c94cc6b":"features = df[top_corr].values\nlabels = df['total (R$)'].values","1a75dc05":"X_train, X_test, y_train, y_test = train_test_split(\n                                    features, labels, test_size=0.3, random_state=42)","a0cfb09f":"batch_size = 4\nbatches_idx = np.array_split(shuffle(np.arange(len(X_train))), len(X_train) \/ batch_size)","1527b0a9":"def sigmoid(x):\n    z = 1. \/ (1. + np.exp(-x))\n    return z\n\ndef dsigmoid(x):\n    z = sigmoid(x) * (1. - sigmoid(x))\n    return z","53b39615":"def cross_entropy(y_hat, y):\n    return (-y.dot(np.log(y_hat)) - (1.-y).dot(np.log(1. - y_hat))).tolist()\n\ndef dcross_entropy(y_hat, y):\n    return y_hat - y","763803ac":"scale = 1\/max(1., (2+2)\/2.)\nlimit = np.sqrt(3.0 * scale)\n\nnp.random.seed(123)\n\nlr = 0.0002\nnr_features = X_train.shape[1]\nw = np.random.uniform(-limit, limit, size=(nr_features,1))","5f77a924":"def predict(x):\n    return 1 if x > 0.5 else 0","b6c72c1f":"total_mean_losses = []\ntotal_mean_accuracies = []\n\nfor e in range(20):\n    \n    losses = []\n    accuracies = []\n    for b_idx in batches_idx:\n        X = X_train[b_idx]\n        y = y_train[b_idx].reshape(1, -1)\n\n        # forward\n        l1 = sigmoid(X.dot(w))\n        loss = 1\/len(y) * cross_entropy(l1, y)[0][0]\n        losses.append(loss)\n        \n        preds = np.array([predict(l) for l in l1])\n        accs = len(np.where(preds == y)[1]) \/ len(y[0])\n        accuracies.append(accs)\n        \n        # backward\n        dcross = dcross_entropy(l1, y.T)\n        dw = X.T.dot(dcross * dsigmoid(l1))\n\n        w -= lr * dw\n    \n    if((e+1) % 2 == 0):\n        mean_losses = sum(losses) \/ len(losses)\n        total_mean_losses.append(mean_losses)\n        \n        mean_accuracies = sum(accuracies) \/ len(accuracies)\n        total_mean_accuracies.append(mean_accuracies)\n        \n        print(\"Epoch:%3d, Loss:%1.3f, Accuracy:%1.3f\" % (e+1, mean_losses, mean_accuracies))","4feaaa9a":"plt.figure(figsize=(14,8))\nplt.title(\"Mean Total Losses\")\nplt.plot(total_mean_losses)\nplt.show()","9e07d5c3":"plt.figure(figsize=(14,8))\nplt.title(\"Mean Total Accuracies\")\nplt.plot(total_mean_accuracies)\nplt.show()","19a20047":"def softmax(z):\n    exps = np.exp(z - np.max(z))\n    return exps \/ np.sum(exps, axis=1, keepdims=True)","d6b19f07":"def cross_entropy(y_hat, y):\n    return -y.T * (np.log(y_hat.T))\n\ndef dcross_entropy(y_hat, y):\n    return y_hat - y","8fd9f29e":"# one hot encoding\ny_train = np.eye(2)[y_train]\nprint(y_train[0])","34535629":"scale = 1\/max(1., (2+2)\/2.)\nlimit = np.sqrt(3.0 * scale)\n\nw1 = np.random.uniform(-limit, limit, size=(nr_features, 8))\nw2 = np.random.uniform(-limit, limit, size=(8, 2))","4bb7d41d":"total_mean_losses = []\ntotal_mean_accuracies = []\n\nfor e in range(100):\n    \n    losses = []\n    accuracies = []\n    for b_idx in batches_idx:\n        X = X_train[b_idx]\n        y = y_train[b_idx]\n\n        # forward\n        l1 = sigmoid(X.dot(w1))\n        l2 = softmax(l1.dot(w2))\n        loss = 1\/len(y) * cross_entropy(l2, y)\n        losses.append(loss.mean())\n        \n        preds = np.array([np.argmax(l) for l in l2])\n        accs = len(np.where(preds == np.argmax(y, axis=1))[0]) \/ len(y)\n        accuracies.append(accs)\n        \n        # backward\n        dl2 = dcross_entropy(l2, y)\n        dl1 = dsigmoid(l1) * (dl2).dot(w2.T)\n        \n        dw2 = l1.T.dot(dl2)\n        dw1 = X.T.dot(dl1)\n\n        w2 -= lr * dw2\n        w1 -= lr * dw1\n    \n    if((e+1) % 10 == 0):\n        mean_losses = sum(losses) \/ len(losses)\n        total_mean_losses.append(mean_losses)\n        \n        mean_accuracies = sum(accuracies) \/ len(accuracies)\n        total_mean_accuracies.append(mean_accuracies)\n        \n        print(\"Epoch:%3d, Loss:%1.3f, Accuracy:%1.3f\" % (e+1, mean_losses, mean_accuracies))","94b090ee":"plt.figure(figsize=(14,8))\nplt.title(\"Mean Total Losses\")\nplt.plot(total_mean_losses)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()","e95cdd58":"plt.figure(figsize=(14,8))\nplt.title(\"Mean Total Accuracies\")\nplt.plot(total_mean_accuracies)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.show()","6509cd6a":"<h1 id=\"dataset\" style=\"color:#37485a; background:#cfd1c7; border:0.5px dotted #37485a;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","1003064d":"## Training","354103b9":"## Features that have highest correlation with 'total (R$)'","5a632c40":"## One hot encoding for labels","8fa7e19b":"## Load data","29aa3efd":"![New Project.png](attachment:b242820f-d99f-4a37-b9c2-0aacff1559d7.png)","c609efb8":"## Features correlations","2ec3dd63":"## Results","321fc03d":"<div width=\"100%\">\n    <img width=\"100%\" src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/554905\/1010567\/1e68856640ce3d26d188e63950ce26ad\/dataset-cover.jpg\"\/>\n<\/div>","160293b7":"## Activation function with derivative","57ba85bd":"## Categorical encoding","5273166e":"## Prediction function for sigmoid","4489b059":"## Categorical cross-entropy and derivative","1b440407":"## Hyperparameters","e9bcd283":"## Results","0cfbc255":"## Loss function with derivative","f13791d2":"## Split the training\/testing set and create the batches","5f8c1f3d":"![image.png](attachment:09db9f4c-2c74-44c3-825c-8ecdbfb7b898.png)","d89d1a46":"## Softmax activation function","d5e368a1":"## Standardize the features","9972c736":"## Training","c02e4396":"## Hyperparameters","e9d555f8":"<h1 id=\"binary\" style=\"color:#37485a; background:#cfd1c7; border:0.5px dotted #37485a;\"> \n    <center>Binary Cross-Entropy\n        <a class=\"anchor-link\" href=\"#binary\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","b740693f":"<h1 id=\"categorical\" style=\"color:#37485a; background:#cfd1c7; border:0.5px dotted #37485a;\"> \n    <center>Categorial Cross-Entropy\n        <a class=\"anchor-link\" href=\"#categorical\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","f6fc449a":"## Split into cheap (0) and rich rentals (1)","60d5c46d":"## Describe each feature"}}