{"cell_type":{"f17627ef":"code","f0e1c31f":"code","a7b2fe1c":"code","27bbf592":"code","862ba9bf":"code","ea1f312f":"code","e4810c47":"code","a671fcf9":"code","be40680c":"code","08a033df":"code","c0362196":"code","ebc41982":"code","5ded52c1":"code","9fc64ce7":"code","84029fa5":"code","16b25f1a":"code","119542a6":"code","922576b1":"code","e72c33f4":"code","07daf868":"code","2194b1c8":"code","26c965c6":"code","4a4fb0f9":"code","15c4e526":"code","6217dd9a":"code","1479645b":"code","4c52f7fe":"code","155c5e06":"markdown","56047f04":"markdown","ee79ad5e":"markdown","508aadbc":"markdown","3a79b38d":"markdown","a8f78e37":"markdown","008ef564":"markdown","9854fa91":"markdown","7f5f1860":"markdown","950d77e2":"markdown","17f03b94":"markdown","ee0b06c1":"markdown","f63e2a63":"markdown","fe41ed1c":"markdown","8eaf186f":"markdown","3d2c6c4b":"markdown","574d126f":"markdown","972ebaf3":"markdown","5f97b715":"markdown"},"source":{"f17627ef":"!pip install -q torchsummary\n!pip install -q efficientnet_pytorch\n\n# from google.colab import files\n# import os\n\n# if not os.path.exists(r\"\/content\/jovian-pytorch-z2g.zip\"):\n#     print(\"Please upload you kaggle.json file\")\n#     uploaded = files.upload()\n#     for fn in uploaded.keys():\n#         print('User uploaded file \"{name}\" with length {length} bytes'.format(\n#             name=fn, length=len(uploaded[fn])))\n\n#     !mkdir ~\/.kaggle\n#     !cp kaggle.json ~\/.kaggle\/\n#     !chmod 600 \/root\/.kaggle\/kaggle.json\n#     !kaggle competitions download -c jovian-pytorch-z2g\n#     !unzip -qq  jovian-pytorch-z2g.zip -d datasets\/","f0e1c31f":"import os\nimport copy\nimport gc\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nfrom torchsummary import summary\n\nfrom PIL import Image\nfrom sklearn.metrics import f1_score\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nimport torchvision\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\n\n# pretrained models\nfrom efficientnet_pytorch import EfficientNet\n\n\nsns.set_style('whitegrid')\nplt.style.use(\"fivethirtyeight\")\npd.pandas.set_option('display.max_columns', 20)\n\n%matplotlib inline","a7b2fe1c":"THRESHOLD = 0.4","27bbf592":"DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas'\n\nTRAIN_DIR = DATA_DIR + '\/train'                           # Contains training images\nTEST_DIR = DATA_DIR + '\/test'                             # Contains test images\n\nTRAIN_CSV = DATA_DIR + '\/train.csv'                       # Contains real labels for training images\nTEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv'","862ba9bf":"data_df = pd.read_csv(TRAIN_CSV)\ndata_df.head()","ea1f312f":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","e4810c47":"def encode_label(label: list) -> list:\n    ''' This functions converts labels into one-hot encoding'''\n\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target\n\ndef decode_target(target: list, text_labels: bool = False, threshold: float = THRESHOLD) -> str:\n    ''' This function converts the labels from \n        probablities to outputs or string representations\n    '''\n\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)","a671fcf9":"class HumanProteinDataset(Dataset):\n    '''\n        Parse raw data to form a Dataset of (X, y).\n    '''\n    def __init__(self, df, root_dir, transform=None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = row['Image'], row['Label']\n        img_fname = self.root_dir + \"\/\" + str(img_id) + \".png\"\n        \n        img = Image.open(img_fname)\n        if self.transform:\n            img = self.transform(img)\n        \n        return img, encode_label(img_label)","be40680c":"from itertools import chain\nfrom collections import Counter\n\nimage_df = pd.read_csv(TRAIN_CSV)\n\n\nall_labels = list(chain.from_iterable([i.strip().split(\" \") \n                                       for i in image_df['Label'].values]))\n\nc_val = []    \nc_val = Counter(all_labels)\n\nn_keys = c_val.keys()\nmax_idx = max(n_keys)\n\ncounts = pd.DataFrame({\n    \"Labels\": [labels[int(key)] for key in c_val.keys()],\n    \"Count\": [val for val in c_val.values()]\n})\n\ncounts.plot(x=\"Labels\", y='Count', kind='barh', title='Class Imbalance')\n\ncounts.sort_values(by=\"Count\", ascending=False).style.background_gradient(cmap='Reds')","08a033df":"import matplotlib.image as mpimg\n\nplt.figure(figsize=(18, 10))\n\nimages = os.listdir(TRAIN_DIR)\n\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    rand_image = np.random.choice(images)\n    image_path = os.path.join(TRAIN_DIR, rand_image)\n    image_number = image_path.split('\/')[-1][:-4]\n    label_ = data_df.Label.loc[data_df.Image == int(image_number)].to_list()\n    image = mpimg.imread(image_path)\n    plt.title(label_[0])\n    plt.imshow(image)\n    plt.axis(\"off\")\n    \n_ = plt.suptitle(\"$Raw$ $Image$\", y=0.74, fontsize=16)","c0362196":"def image_transformations(image_size: int) -> (object, object):\n    '''\n        Return transformations to be applied.\n        Input:\n            image_size: int\n        Output:\n            train_transformations: transformations to be applied on the training set\n            valid_tfms: transformations to be applied on the validation or test set\n    '''\n\n    # imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    # https:\/\/www.kaggle.com\/ronaldokun\/multilabel-stratification-cv-and-ensemble\n    \n    mean = torch.tensor([0.05438065, 0.05291743, 0.07920227])\n    std = torch.tensor([0.39414383, 0.33547948, 0.38544176])\n    \n    train_trans = [           \n        T.Resize(image_size + 4),\n        T.CenterCrop(image_size),\n        T.RandomRotation(40),\n        T.RandomAffine(\n            degrees=10,\n            translate=(0.01, 0.12),\n            shear=(0.01, 0.03),\n        ),\n        T.RandomHorizontalFlip(), \n        T.RandomVerticalFlip(),\n        T.ToTensor(),\n        T.Normalize(mean, std, inplace=True), \n        T.RandomErasing(inplace=True)\n    ]\n\n    val_trans = [\n        T.Resize(image_size), \n        T.ToTensor(), \n        T.Normalize(mean, std, inplace=True)\n    ]\n\n    train_transformations = T.Compose(train_trans)\n    valid_tfms = T.Compose(val_trans)\n\n    return train_transformations, valid_tfms","ebc41982":"def get_train_dataset(image_size: int) -> (object, object):\n    ''' get training_dataset\n        Input:\n            image_size: int\n        output:\n            train_ds: training dataset object\n            val_ds: validation dataset object\n    '''\n\n    np.random.seed(42)  \n    msk = np.random.rand(len(data_df)) < 0.9\n    train_df = data_df[msk].reset_index()\n    val_df = data_df[~msk].reset_index()\n\n    # get transformation according to the architecture\n    train_tfms, valid_tfms = image_transformations(image_size)\n\n    # fetch dataset\n    train_ds = HumanProteinDataset(train_df, TRAIN_DIR, transform=train_tfms)\n    val_ds = HumanProteinDataset(val_df, TRAIN_DIR, transform=valid_tfms)\n    return train_ds, val_ds","5ded52c1":"def get_train_dataloader(image_size: int, batch_size: int=64) -> (object, object):\n    '''\n        Returns train and test dataloaders.\n        Input:\n            image_size: int\n            batch_size: [optional] int\n        Output:\n            train_dl: train dataloader object\n            valid_dl: validation dataloader object\n    '''\n\n    train_ds, valid_ds = get_train_dataset(image_size)\n\n    train_dl = DataLoader(train_ds, batch_size, shuffle=True, \n                      num_workers=3, pin_memory=True)\n    valid_dl = DataLoader(valid_ds, batch_size*2, \n                    num_workers=2, pin_memory=True)\n    \n    return train_dl, valid_dl","9fc64ce7":"def get_test_dataloader(image_size: int, batch_size: int=64) -> object:\n    '''\n        Returns test set dataloaders.\n        Input:\n            image_size: int\n            batch_size: [optional] int\n        Output:\n            test_dl: test dataloader object\n    '''\n\n    test_df = pd.read_csv(TEST_CSV)\n\n    # get transformations same as validation set\n    _, valid_tfms = image_transformations(image_size)\n    \n    test_dataset = HumanProteinDataset(test_df, TEST_DIR, transform=valid_tfms)\n    test_dl = DataLoader(test_dataset, batch_size, num_workers=3, pin_memory=True)\n    test_dl = DeviceDataLoader(test_dl, device)\n    return test_dl","84029fa5":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","16b25f1a":"device = get_default_device()\ndevice","119542a6":"models = {\n#     \"EfficientNet-b0\": EfficientNet.from_pretrained('efficientnet-b0'),\n    \"EfficientNet-b1\": EfficientNet.from_pretrained('efficientnet-b1'), \n#     \"EfficientNet-b2\": EfficientNet.from_pretrained('efficientnet-b2'),\n#     \"EfficientNet-b3\": EfficientNet.from_pretrained('efficientnet-b3'),\n}\n\nimage_sizes = {\n    \"EfficientNet-b0\": 224,\n    \"EfficientNet-b1\": 240,\n    \"EfficientNet-b2\": 260,\n    'EfficientNet-b3': 300,\n    'EfficientNet-b4': 380,\n}\n\nbatch_sizes = {\n    \"EfficientNet-b0\": 150,\n    \"EfficientNet-b1\": 100,\n    \"EfficientNet-b2\": 64,\n    'EfficientNet-b3': 50,\n    'EfficientNet-b4': 20\n}","922576b1":"def F_score(output: list, label: list, threshold: float=THRESHOLD, beta: float=1.0) -> float:\n    '''\n        Returns the F-score for the model\n        Input:\n            output: array of outputs\n            label: array of labels\n            treshold: optionfloat -> consider output probablity if above the index\n            beta: [optional] float\n        Output:\n            float -> F-score\n    '''\n\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)","e72c33f4":"# This class can be used for any Image Classification problem\n\nclass MultilabelImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        loss = F.binary_cross_entropy(out, targets)      \n        score = F_score(out, targets)\n        return {'loss': loss, 'score': score.detach()}\n\n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n        score = F_score(out, targets)\n        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n    \n    def get_metrics_epoch_end(self, outputs, validation=True):\n        if validation:\n            loss_ = 'val_loss'\n            score_ = 'val_score'\n        else:\n            loss_ = 'loss'\n            score_ = 'score'\n\n        batch_losses = [x[f'{loss_}'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   \n        batch_scores = [x[f'{score_}'] \n                        for x in outputs]\n        epoch_scores = torch.stack(batch_scores).mean()      \n        return {f'{loss_}': epoch_loss.item(), f'{score_}': epoch_scores.item()}\n    \n    def epoch_end(self, epoch, result, epochs):\n        print(f\"Epoch: {epoch+1}\/{epochs} -> last_lr: {result['lrs'][-1]:.4f}, train_loss: {result['loss']:.4f}, train_score: {result['score']:.4f}, val_loss: {result['val_loss']:.4f}, val_score: {result['val_score']:.4f}\")\n","07daf868":"class ProteinModel(MultilabelImageClassificationBase):\n\n    @staticmethod\n    def get_sequential(num_ftrs):\n        linear_layers = nn.Sequential(\n                nn.BatchNorm1d(num_features=num_ftrs),    \n                nn.Linear(num_ftrs, 512),\n                nn.ReLU(),\n                nn.BatchNorm1d(512),\n                nn.Linear(512, 128),\n                nn.ReLU(),\n                nn.BatchNorm1d(num_features=128),\n                nn.Dropout(0.4),\n                nn.Linear(128, 10),\n            )\n        return linear_layers\n\n    def __init__(self, model_name=None, model=None, input_size=None):\n        super().__init__()\n        \n        # Use a pretrained model\n        self.model_name = model_name\n        self.model = copy.deepcopy(model)\n        self.IS = input_size\n        \n        # Replace last layer\n        self.num_ftrs = self.model._fc.in_features\n        self.model._fc = ProteinModel.get_sequential(self.num_ftrs)\n\n    def forward(self, xb):\n        return torch.sigmoid(self.model(xb))\n\n    def freeze(self):\n        \n        # To freeze the residual layers\n        for param in self.model.parameters():\n            param.require_grad = False\n\n        for param in self.model._fc.parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.model.parameters():\n            param.require_grad = True\n\n    def __repr__(self):\n        return f\"{self.model}\"\n    \n    def __str__(self):\n        summary(self.model, (3, self.IS, self.IS))\n        text_ = \\\n        f'''\n            Model Name: {self.model_name}\n            FC Layer input: {self.num_ftrs}\n        '''\n        return text_","2194b1c8":"@torch.no_grad()\ndef evaluate(model: object, val_loader: object) -> dict:\n    '''\n        Evaluate model on the validation set\n        Input:\n            model: training model object\n            val_loder: validation data loader object\n        Output:\n            validation metrics\n    '''\n\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.get_metrics_epoch_end(outputs=outputs, validation=True)\n\n\ndef get_lr(optimizer: object) -> float:\n    ''' Returns current learning rate'''\n\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\n\ndef fit_model(model_name: str,\n              model: object, \n              epochs: int, \n              lr: float, \n              train_loader: object, \n              val_loader: object,\n              opt_func: object=torch.optim.SGD):\n    '''\n        This function is responsible for training our model.\n        We use a One Cycle learning rate policy to update our learning rate \n        with each epoch.\n        The best model is saved during each epoch.\n        Input:\n            model_name: str \n            model: object\n            epochs: int -> Max epochs\n            lr: float -> learning rate\n            train_loader: training set data loader\n            val_loader: validation set data loader\n            opt_func: optimzer object\n        Output:\n            history: list of metrics\n    '''\n\n\n    \n    torch.cuda.empty_cache()\n    BEST_VAL_SCORE = 0.0 # for keeping track of best model score\n    history = []\n\n    optimizer = opt_func(model.parameters(), lr)\n\n    # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, max_lr=max_lr,\n    #                                                 epochs=epochs, \n    #                                                 steps_per_epoch=len(train_loader))\n    \n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=1, cooldown=1)\n\n    \n    print(f\"Transfer Learning -> Model: {model_name}\") \n    for epoch in range(epochs):\n\n        # unfreeze for last 50% of epochs\n        if epoch == (epochs \/\/ 2):\n            model.unfreeze()\n            print(f\"Fine-tuning: {model_name}\")\n#             optimizer = opt_func(model.parameters(), unfreeze_max_lr, \n#                                  weight_decay=weight_decay)\n            \n#             scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,  \n#                                                             max_lr=unfreeze_max_lr, \n#                                                             epochs=epochs\/\/2,  \n#                                                             steps_per_epoch=len(train_loader))\n        \n        # log epoch metrics\n        train_history = []\n        lrs = []\n\n        # Training Phase \n        model.train()\n        \n        for batch in tqdm(train_loader, desc=f'Epoch: {epoch+1}\/{epochs}'):\n            info = model.training_step(batch)\n            loss = info['loss']\n            # contains batch loss and acc for training phase\n            train_history.append(info)\n            loss.backward()\n\n            # Gradient clipping\n            \n            nn.utils.clip_grad_value_(model.parameters(), 1e-4)\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n            lrs.append(get_lr(optimizer))\n            # scheduler.step()\n\n\n        train_result = model.get_metrics_epoch_end(train_history, validation=False)\n        val_result = evaluate(model, val_loader)\n        result = {**train_result, **val_result}\n        \n        # call scheduler to check validation loss\n        scheduler.step(result['val_score'])\n\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result, epochs)\n\n\n        # Save the best model\n        if result['val_score'] > BEST_VAL_SCORE:\n            BEST_VAL_SCORE = result['val_score']\n            save_name = f\"{model_name}_epoch-{epoch+1}_score-{round(result['val_score'], 4)}.pth\"\n            !rm -f '{model_name}'_*\n            torch.save(model.state_dict(), save_name)\n            \n            # generate predictions using the best model\n            \n            print(\"Genearating predictions on the Test set\")\n            generate_prediction(model, image_sizes[model_name])\n\n        history.append(result)\n    return history","26c965c6":"# functions to fetch test dataset and generate submission file for best model\n\ndef load_best(model_name: str) -> object:\n    '''Returns the best model'''\n\n    model = models[model_name]\n    image_size = image_sizes[model_name]\n    best_model = ProteinModel(model_name, model, image_size)\n\n    # load trained weights\n    path = r\".\/\"\n    file_path = ''\n    \n    for i in os.listdir(path):\n        if os.path.isfile(os.path.join(path,i)) and i.startswith('EfficientNet'):\n            file_path = os.path.join(path, i)\n            \n    print(f\"Loading model: {file_path[2:]}\")\n    best_model.load_state_dict(torch.load(file_path))\n    # set model to gpu\n    best_model = to_device(best_model, device)\n    return best_model   \n\n\n@torch.no_grad()\ndef generate_prediction(model: object, image_size: int) -> None:\n    '''Generate prediction on the test set and creates a csv file'''\n\n    test_dl = get_test_dataloader(image_size)\n\n    model.eval()\n    # clear cuda cache\n    torch.cuda.empty_cache()\n\n    # generate predictions\n    batch_probs = []\n    for xb, _ in test_dl:\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n    test_preds = [decode_target(x) for x in batch_probs]\n\n    # generate submistion file\n    submission_df = pd.read_csv(TEST_CSV)\n    submission_df.Label = test_preds\n    sub_fname = f'submission_{model_name}.csv'\n    submission_df.to_csv(sub_fname, index=False)\n    print(f\"Prediction file: {sub_fname} generated\\n\")","4a4fb0f9":"def end_to_end(model_name: str, parameters: dict=None) -> dict:\n    '''\n        A simple function end-to-end training and testing on the selected model.\n        Inputs:\n            model_name: str -> chosen model name\n            parameters: dict -> dictionary of hyperparameters for the model\n        Outputs:\n            history: dict -> dictionary containing model metrics(loss, score, lr)\n\n    '''\n    torch.cuda.empty_cache()\n\n    # hyperparameters\n    image_size = image_sizes[model_name]\n    BATCH_SIZE = batch_sizes[model_name]\n    epochs = parameters[\"epochs\"]\n    lr = parameters[\"lr\"]\n    opt_func = parameters[\"opt_func\"]\n\n    # get transformed dataset\n    train_dl, valid_dl = get_train_dataloader(image_size, batch_size=BATCH_SIZE)\n    # move dataset to use GPU\n    train_dl = DeviceDataLoader(train_dl, device)\n    valid_dl = DeviceDataLoader(valid_dl, device)\n\n    # get model\n    model = models[model_name]\n    model = ProteinModel(model_name, model, image_size)    \n    # convert to cuda\n    model = to_device(model, device)\n     \n\n    # move model to GPU\n    model = to_device(model, device)\n    \n    # train model\n    history = fit_model(\n                model_name,\n                model, \n                epochs, \n                lr, \n                train_dl, \n                valid_dl,\n                opt_func\n            )\n\n    # cleaning\n    torch.cuda.empty_cache()\n    \n    return history","15c4e526":"# TRAINING CONSTANTS\n\ntraining_parameters = {\n    \"epochs\": 20,\n    \"lr\": 0.001,\n    \"opt_func\": torch.optim.Adam,\n}","6217dd9a":"model_name = \"EfficientNet-b1\"\n\nhistory = end_to_end(model_name, training_parameters)","1479645b":"# plotting metrics\n\ndef plot_accuracies(history):\n    train_score = [r['score'] for r in history]\n    val_score = [r['val_score'] for r in history]\n    plt.plot(train_score, '-kx', label=\"train_score\")\n    plt.plot(val_score, '-rx', label=\"val_score\")\n    plt.legend()\n    _ = plt.xticks(ticks=range(len(train_score)), \n                   labels=[str(i) for i in range(1, len(train_score)+1)])\n    plt.xlabel('epoch')\n    plt.ylabel('F1-Score')\n    plt.title('F1-Score vs. epochs')\n\ndef plot_losses(history):\n    train_losses = [r['loss'] for r in history]\n    val_losses = [r['val_loss'] for r in history]\n    plt.plot(train_losses, '-kx', label=\"train_loss\")\n    plt.plot(val_losses, '-rx', label=\"val_loss\")\n    plt.legend()\n    _ = plt.xticks(ticks=range(len(train_losses)), \n                   labels=[str(i) for i in range(1, len(train_losses)+1)])\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.title('Loss vs. epochs')\n\ndef plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');","4c52f7fe":"# plotting score and loss\nplt.figure(figsize=(25, 6))\nplt.subplot(1, 3, 1)\nplot_accuracies(history)\nplt.subplot(1, 3, 2)\nplot_losses(history)\n\nplt.subplot(1, 3, 3)\nplot_lrs(history)","155c5e06":"## Data Augmentation","56047f04":"## Scoring mechanism","ee79ad5e":"# Train Model","508aadbc":"# Dataset Preparation","3a79b38d":"# Model building \n\n* For this problem I chose to experiment with the SOTA CNN architecture `EfficientNet-b*`.\n* EfficientNet paper: [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https:\/\/arxiv.org\/abs\/1905.11946)\n* A new technique which improves EfficientNet models: [Adversarial Examples Improve Image Recognition](https:\/\/arxiv.org\/abs\/1911.09665)\n","a8f78e37":"# Using Pytorch","008ef564":"# Plots","9854fa91":"* __Update 1:__\n    1. Changed learning rate scheduler to -> __ReduceLROnPlateau__\n    2. Reduced Linear layers","7f5f1860":"Let's first take a look at some images","950d77e2":"## Setting up GPU usage","17f03b94":"# [Zero to GANs - Human Protein Classification](https:\/\/www.kaggle.com\/c\/jovian-pytorch-z2g)\n\nIn this competition, you will develop models capable of classifying mixed patterns of proteins in microscope images. Images visualizing proteins in cells are commonly used for biomedical research, and these cells could hold the key for the next breakthrough in medicine. However, thanks to advances in high-throughput microscopy, these images are generated at a far greater pace than what can be manually evaluated. Therefore, the need is greater than ever for automating biomedical image analysis to accelerate the understanding of human cells and disease.\n\nThis is a **multilabel image classification** problem, where each image can belong to several classes. The class labels are as follows:\n0. `Mitochondria`,\n1. `Nuclear bodies`',\n2. `Nucleoli`,\n3. `Golgi apparatus`,\n4. `Nucleoplasm`,\n5. `Nucleoli fibrillar center`,\n6. `Cytosol`,\n7. `Plasma membrane`,\n8. `Centrosome`,\n9. `Nuclear speckles`\n","ee0b06c1":"* We can clearly see there class imbalance in the dataset.\n* To overcome this we can use data augmentations techniques.","f63e2a63":"## Model Class","fe41ed1c":"* We're going to apply various augmentation techniques.\n* All available transformations are listed in : [pytorch transforms](https:\/\/pytorch.org\/docs\/stable\/torchvision\/transforms.html)\n* A quick illustration on how the augmentaions affect the images: [kaggle - Image Augmentation for more train data](https:\/\/www.kaggle.com\/vishnurapps\/image-augmentation-for-more-training-data)","8eaf186f":"## Helper functions","3d2c6c4b":"## Dataset & DataLoaders\n\n* Here we are going to define functions to fetch training and testing datasets\n* The train dataset is split into training and validation set of  [90, 10].\n* The test dataset should not used until the final prediction generation.","574d126f":"## Download Dataset\n* This is for running on google colab.\n* To download the dataset you need to upload your `kaggle.json` file that contains your API keys.","972ebaf3":"**Demo Run**","5f97b715":"## Defining Model\n\n* Testing for B1 - B4"}}