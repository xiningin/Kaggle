{"cell_type":{"539c85a1":"code","155033da":"code","fc38c152":"code","5a1d5511":"code","3686c0fe":"code","8c0ec677":"code","36c0f61c":"code","88ce7da3":"code","cc9b9324":"code","3398189c":"code","2d3ac969":"code","ca1c863a":"code","93ece645":"code","50277f66":"code","0c907621":"code","3ef3ded7":"code","3896ecd4":"code","51dde1ac":"code","5fee6ba7":"code","4f880d66":"code","cc80108d":"code","ed8a9ad8":"code","dc9ca87b":"code","af7bc1ac":"code","ae377926":"code","77677a34":"code","4a361ca7":"code","a8f1179a":"code","dab3965a":"code","4429bbeb":"code","d5c1fb32":"code","396b2b38":"code","b2c994a5":"code","4717f4b2":"code","18dd8162":"code","2f8febce":"code","4511b0d5":"code","11dbd37d":"code","8f82aa0d":"code","b7c136fc":"code","e8f32ed6":"code","87972963":"code","f014c0dc":"code","19bfd1a4":"code","7543a8e8":"code","614a6a3b":"code","d6be4075":"code","c074af9e":"code","deb16785":"code","fb363826":"code","65b2c9e0":"code","f45c76ab":"code","a74162d5":"code","9ab48d16":"code","d19106a6":"code","edb6789e":"code","b0350561":"code","64b57a6f":"code","6e113811":"code","4edf36eb":"code","19aaa728":"code","763fcde1":"code","df956156":"code","d02c9317":"code","9c7f51d4":"code","8c71b043":"code","cd8e2adb":"code","eb2e6b18":"code","067e95f3":"code","0f3a6af0":"code","8fccda7f":"code","9e9c180f":"code","a2751c05":"code","83f1a9a8":"code","62a608ac":"code","dc7f3e27":"code","7050b14f":"code","fdcee458":"code","84f14b00":"code","8d35f1d6":"code","2a5accf9":"code","06057319":"code","ffa9ec5d":"code","655fe53b":"code","f552f660":"code","1ed23b77":"code","9d413e7b":"code","74523842":"markdown","62c2b333":"markdown","ee1126fb":"markdown","acf634e5":"markdown","03c04bcc":"markdown","f0d6d822":"markdown","0e463e53":"markdown","6f19abbd":"markdown","7a5b42f2":"markdown","0f6fe639":"markdown","43d2a3fe":"markdown","1940c718":"markdown","8d1d6ea2":"markdown","36c5ea50":"markdown","a90511a8":"markdown","8872c122":"markdown","00d04ed8":"markdown","d3c1b813":"markdown","b9168d17":"markdown","30af1905":"markdown","efd746bd":"markdown","380e3fd2":"markdown","4b5f70a0":"markdown","3bb906c2":"markdown","06583059":"markdown","7cba20f1":"markdown","45fda2f8":"markdown","8bc51a8e":"markdown","808a7f11":"markdown","ca051342":"markdown","69d15818":"markdown","8d1a7aa1":"markdown","f31e2db8":"markdown","42024ce2":"markdown","5fd1ea40":"markdown","5f8f782a":"markdown","94283aed":"markdown","e8dde41b":"markdown","8d401ce2":"markdown","dc8f6951":"markdown","dd823306":"markdown","9b93545b":"markdown","6baeec18":"markdown","cc0253b5":"markdown","d18e87f3":"markdown","5f44b279":"markdown","0f831086":"markdown","d0afa0c0":"markdown","e90172dd":"markdown","e4f209eb":"markdown","38be1821":"markdown","5e43a7c8":"markdown","a251f690":"markdown","13a0473c":"markdown","1f449bae":"markdown","1e0e8aca":"markdown","774f4057":"markdown","0cf99001":"markdown","ac213da2":"markdown","54e30098":"markdown","8334880b":"markdown","8d957ff8":"markdown","7be4404f":"markdown","693a0427":"markdown"},"source":{"539c85a1":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n%matplotlib inline\nplt.style.use('seaborn')","155033da":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/adultb\"]).decode(\"utf8\"))\n\ndf_train = pd.read_csv(\"..\/input\/adultb\/train_data.csv\", na_values = '?')\ndf_train.set_index('Id',inplace=True)\ndf_train.head()","fc38c152":"print('Forma do DataFrame:', df_train.shape)","5a1d5511":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = ((df_train.isnull().sum()\/df_train.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","3686c0fe":"print('occupation:\\n')\nprint(df_train['occupation'].describe())\n\nprint('\\n\\nworkclass:\\n')\nprint(df_train['workclass'].describe())\n\nprint('\\n\\nnative.country:\\n')\nprint(df_train['native.country'].describe())","8c0ec677":"value = df_train['workclass'].describe().top\ndf_train['workclass'] = df_train['workclass'].fillna(value)\n\nvalue = df_train['native.country'].describe().top\ndf_train['native.country'] = df_train['native.country'].fillna(value)\n\nvalue = df_train['occupation'].describe().top\ndf_train['occupation'] = df_train['occupation'].fillna(value)","36c0f61c":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = ((df_train.isnull().sum()\/df_train.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","88ce7da3":"cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\nsns.set()\nsns.pairplot(df_train, vars = cols, hue = 'income')","cc9b9324":"df_train.describe()","3398189c":"plt.figure(figsize=(13, 7))\ndf_train['capital.gain'].hist(color = 'coral')\nplt.xlabel('capital gain')\nplt.ylabel('quantity')\nplt.title('Capital gain histogram')","2d3ac969":"plt.figure(figsize=(13, 7))\ndf_train['capital.loss'].hist(color = 'coral')\nplt.xlabel('capital loss')\nplt.ylabel('quantity')\nplt.title('Capital loss histogram')","ca1c863a":"plt.figure(figsize=(13, 7))\ndf_train['age'].hist(color = 'coral')\nplt.xlabel('age')\nplt.ylabel('quantity')\nplt.title('Age histogram')","93ece645":"sns.set()\nplt.figure(figsize=(13,7))\nsns.distplot(df_train['age'], color = 'darkorchid', bins = 70)\nplt.ylabel('quantity')\nplt.title('Distribution of age')","50277f66":"plt.figure(figsize=(13, 7))\ndf_train['hours.per.week'].hist(color = 'coral')\nplt.xlabel('hours per week')\nplt.ylabel('quantity')\nplt.title('Hours per week histogram')","0c907621":"super_work = df_train[df_train['hours.per.week'] > 40]\nplt.figure(figsize=(13, 7))\nsuper_work['hours.per.week'].hist(color = 'coral', bins = 5)\nplt.xlabel('hours per week')\nplt.ylabel('quantity')\nplt.title('Hours per week histogram')","3ef3ded7":"mean = super_work['hours.per.week'].describe()['mean']\nprint('{0} horas por semana ({1} horas por dia com finais de semana livre). O que \u00e9 algo que j\u00e1 come\u00e7a a ser bastante desgastante para o trabalhador.'.format(int(mean), int(mean\/5)))","3896ecd4":"def compare_histogram(df, obj_var, test_var, obj_labels = None, alpha = 0.7):\n    \n    if obj_labels is None:\n        obj_labels = df[obj_var].unique()\n    \n    #obj_var = 'income'\n    #obj_labels = ['>50K', '<=50K']\n    #test_var = 'age' (for example)\n    \n    temp = []\n    n_labels = len(obj_labels)\n    for i in range(n_labels):\n        temp.append(df[df[obj_var] == obj_labels[i]])\n        temp[i] = np.array(temp[i][test_var]).reshape(-1,1)\n\n    fig = plt.figure(figsize= (13,7))\n    \n    for i in range(n_labels):\n        plt.hist(temp[i], alpha = alpha)\n    plt.xlabel(test_var)\n    plt.ylabel('quantity')\n    plt.title('Histogram over \\'' + test_var + '\\' filtered by \\'' + obj_var + '\\'')\n    plt.legend(obj_labels)","51dde1ac":"compare_histogram(df_train, 'income', 'age')","5fee6ba7":"plt.figure(figsize=(13, 7))\ndf_train['sex'].value_counts().plot(kind = 'pie')","4f880d66":"# male = qtd sex == Male\nmale = df_train[df_train['sex'] == 'Male'].count()[0]\n\n# female = qtd sex == Female\nfemale = df_train.shape[0] - male","cc80108d":"print(\"Temos {0} homens e {1} mulheres, ou seja, apenas {2:3.2f}% s\u00e3o mulheres.\".format(male, female, female*100\/(female+male)))","ed8a9ad8":"compare_histogram(df_train, 'income', 'sex')","dc9ca87b":"# male_income = [qtd > 50K, qtd <= 50K]\nmale_income = []\ntemp = df_train[df_train['sex'] == 'Male']\nmale_income.append(temp[temp['income'] == '>50K'].count()[0])\nmale_income.append(male-male_income[0])\n\n# female_income = [qtd > 50K, qtd <= 50K]\nfemale_income = []\ntemp = df_train[df_train['sex'] == 'Female']\nfemale_income.append(temp[temp['income'] == '>50K'].count()[0])\nfemale_income.append(female-female_income[0])\n\n# % of male that has >50K income:\nmale_over = male_income[0]\/male\n\n# % of female that has >50K income:\nfemale_over = female_income[0]\/female","af7bc1ac":"print('Temos que dentre os homens, {0:1.2f}% possuem renda anual superior a 50.000, j\u00e1 dentre as mulheres, temos {1:2.2f}% apenas que possuem renda anual superior a 50.000.'.format(male_over*100, female_over*100))","ae377926":"compare_histogram(df_train, 'sex', 'hours.per.week')","77677a34":"female = df_train[df_train['sex'] == 'Female']\nmale = df_train[df_train['sex'] == 'Male']","4a361ca7":"plt.figure(figsize=(13, 7))\nmale['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\nplt.ylabel('quantity')\nplt.title('Histogram of male over occupations')\n\nplt.figure(figsize=(13, 7))\nfemale['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\nplt.ylabel('quantity')\nplt.title('Histogram of female over occupations')","a8f1179a":"plt.figure(figsize=(13, 7))\ndf_train['race'].value_counts().plot(kind = 'pie')","dab3965a":"compare_histogram(df_train, 'income', 'race')","4429bbeb":"# kind = qtd race == 'unique'\nwhite = df_train[df_train['race'] == 'White'].count()[0]\nblack = df_train[df_train['race'] == 'Black'].count()[0]\namer = df_train[df_train['race'] == 'Amer-Indian-Eskimo'].count()[0]\nother = df_train[df_train['race'] == 'Other'].count()[0]\nasian = df_train[df_train['race'] == 'Asian-Pac-Islander'].count()[0]\n\n# kind_income = [qtd > 50K, qtd <= 50K]\nwhite_income = []\ntemp = df_train[df_train['race'] == 'White']\nwhite_income.append(temp[temp['income'] == '>50K'].count()[0])\nwhite_income.append(white-white_income[0])\n\nblack_income = []\ntemp = df_train[df_train['race'] == 'Black']\nblack_income.append(temp[temp['income'] == '>50K'].count()[0])\nblack_income.append(black-black_income[0])\n\namer_income = []\ntemp = df_train[df_train['race'] == 'Amer-Indian-Eskimo']\namer_income.append(temp[temp['income'] == '>50K'].count()[0])\namer_income.append(amer-amer_income[0])\n\nasian_income = []\ntemp = df_train[df_train['race'] == 'Asian-Pac-Islander']\nasian_income.append(temp[temp['income'] == '>50K'].count()[0])\nasian_income.append(asian-asian_income[0])\n\nother_income = []\ntemp = df_train[df_train['race'] == 'Other']\nother_income.append(temp[temp['income'] == '>50K'].count()[0])\nother_income.append(other-other_income[0])","d5c1fb32":"print('Brancos:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(white_income[0]*100\/white))\nprint('Negros:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(black_income[0]*100\/black))\nprint('Amer-Indian-Eskimo:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(amer_income[0]*100\/amer))\nprint('Asian-Pac-Islander:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(asian_income[0]*100\/asian))\nprint('Outros:\\n   {0:1.2f}% recebem mais de 50.000'.format(other_income[0]*100\/other))","396b2b38":"white = df_train[df_train['race'] == 'White']\nblack = df_train[df_train['race'] == 'Black']","b2c994a5":"plt.figure(figsize=(13, 7))\nwhite['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\nplt.ylabel('quantity')\nplt.title('Histogram of white people over occupations')\n\nplt.figure(figsize=(13, 7))\nblack['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\nplt.ylabel('quantity')\nplt.title('Histogram of black people over occupations')","4717f4b2":"var1 = 'race'\nvar2 = 'education.num'\n\ndata = pd.concat([df_train[var2], df_train[var1]], axis=1)\n\nf, ax = plt.subplots(figsize=(15, 7))\n\nsns.boxplot(x=var1, y=var2, data=data, notch = True)\nplt.title('Boxplot of education num over race')","18dd8162":"over_50k = df_train[df_train['income'] == '>50K']\nunder_50k = df_train[df_train['income'] == '<=50K']","2f8febce":"plt.figure(figsize=(13, 7))\nover_50k['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\nplt.ylabel('quantity')\nplt.title('Histogram of income over 50K over occupations')\n\nplt.figure(figsize=(13, 7))\nunder_50k['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\nplt.ylabel('quantity')\nplt.title('Histogram of income under 50K over occupations')","4511b0d5":"var2 = 'age'\nvar1 = 'hours.per.week'\n\ndata = pd.concat([df_train[var2], df_train[var1]], axis=1)\n\nf, ax = plt.subplots(figsize=(14, 15))\n\nsns.boxplot(x=var1, y=var2, data=data, orient = 'h')\nplt.title('Boxplot of age over hours per week')","11dbd37d":"var2 = 'education'\nvar1 = 'hours.per.week'\n\ndata = pd.concat([df_train[var2], df_train[var1]], axis=1)\n\nf, ax = plt.subplots(figsize=(13, 7))\n#ax.set_ylim(0,10000)\n\norder = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th',\n         '11th', '12th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc',\n         'Some-college', 'Bachelors', 'Masters', 'Doctorate']\nsns.boxplot(x=var1, y=var2, data=data, order = order)","8f82aa0d":"df_train['income'].value_counts()","b7c136fc":"base = df_train","e8f32ed6":"base.columns","87972963":"quantitative_columns = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\nqualitative_columns = ['education', 'marital.status', 'occupation', 'relationship', 'race',\n                       'sex', 'native.country', 'income']","f014c0dc":"def isprivate(value):\n    if value == 'Private':\n        return 1\n    return 0\n\ndef catg(value, categories, ordenation = None):\n    if ordenation is not None:\n        ordenation = np.arange(0, len(categories))\n    for pos in ordenation:\n        if value == categories[pos]:\n            return pos\n    return -1\n\ndef equals(value, x):\n    for v in x:\n        if v == value:\n            return 1\n    return 0","19bfd1a4":"base['workclass'].unique()","7543a8e8":"# privado: 1 se trabalha para o privado, 0 caso contrario\nprivate = pd.DataFrame({'private': base['workclass'].apply(isprivate)})","614a6a3b":"df_train['native.country'].value_counts()","d6be4075":"# usa: 1 se \u00e9 sul_global, 0 caso contr\u00e1rio\ncountries = ['Mexico', 'Philippines', 'Puerto-Rico', 'El-Salvador', 'India', 'Cuba', 'Jamaica',\n             'South', 'China', 'Dominican-Republic', 'Vietnam', 'Guatemala', 'Columbia', 'Taiwan',\n             'Haiti', 'Iran', 'Nicaragua', 'Peru', 'Ecuador', 'Trinadad&Tobago', 'Cambodia',\n             'Laos', 'Thailand', 'Yugoslavia', 'Outlying-US(Guam-USVI-etc)', 'Honduras']\nsul_global = pd.DataFrame({'sul.global': base['native.country'].apply(equals, args = [countries])})","c074af9e":"base['education'].unique()","deb16785":"edu_order = [15, 11, 5, 12, 10, 1, 14, 7, 2, 8, 4, 13, 0, 3, 6, 9]\nargs = [base['education'].unique(), edu_order]\neducation_classes = pd.DataFrame({'education.classes': base['education'].apply(catg, args = args)})","fb363826":"aux = pd.cut(base['hours.per.week'], bins = [-1, 25, 40, 60, 200], labels = [0, 1, 2, 3])\nhours_per_week_clusters = pd.DataFrame({'hours.per.week.clusters': aux})\nhours_per_week_clusters = hours_per_week_clusters.astype(np.int)","65b2c9e0":"median = np.median(base[base['capital.gain'] > 0]['capital.gain'])\naux = pd.cut(base['capital.gain'],\n             bins = [-1, 0, median, base['capital.gain'].max()+1],\n             labels = [0, 1, 2])\ncapital_gain_clusters = pd.DataFrame({'capital.gain.clusters': aux})\ncapital_gain_clusters = capital_gain_clusters.astype(np.int)\n\nmedian = np.median(base[base['capital.loss'] > 0]['capital.loss'])\naux = pd.cut(base['capital.loss'],\n             bins = [-1, 0, median, base['capital.loss'].max()+1],\n             labels = [0, 1, 2])\ncapital_loss_clusters = pd.DataFrame({'capital.loss.clusters': aux})\ncapital_loss_clusters = capital_loss_clusters.astype(np.int)","f45c76ab":"new_data = pd.concat([sul_global, private, education_classes, \n                      hours_per_week_clusters, capital_gain_clusters, \n                      capital_loss_clusters], axis = 1)","a74162d5":"new_data.head()","9ab48d16":"aux = base['income'].apply(equals, args = [['>50K']])\n\naux = pd.concat([new_data, pd.DataFrame({'income': aux})], axis = 1)\n\nnew = aux.astype(np.int)\naux.head()","d19106a6":"corr_mat = aux.corr()\ncorr_mat\nsns.set()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr_mat, annot=True)","edb6789e":"base = base.drop(['fnlwgt', 'education', 'sex', 'native.country', 'workclass', 'marital.status'], axis = 1)\nbase.columns","b0350561":"base = pd.concat([new_data, base], axis = 1)","64b57a6f":"base.head()","6e113811":"from sklearn import preprocessing as prep\n\nnames = ['occupation', 'relationship', 'race']\nenc_x = []\nfor i in range(len(names)):\n    enc_x.append(prep.LabelEncoder())\nenc_y = prep.LabelEncoder()","4edf36eb":"i = 0\nfor name in names:\n    base[name] = enc_x[i].fit_transform(base[name])\n    i += 1\n\nbase['income'] = enc_y.fit_transform(base['income'])","19aaa728":"base.head()","763fcde1":"aux = base.astype(np.int)\n\ncorr_mat = aux.corr()\nf, ax = plt.subplots(figsize=(20, 13))\nsns.heatmap(corr_mat, vmax=.7, square=True, cmap=\"coolwarm\", annot = True)","df956156":"unselected_columns = []\nunselected_columns.append('capital.loss')\nunselected_columns.append('capital.gain')\nunselected_columns.append('sul.global')\nunselected_columns.append('private')\nunselected_columns.append('education.classes')\nunselected_columns.append('hours.per.week.clusters')\n\nbase = base.drop(unselected_columns, axis = 1)\nbase.head()","d02c9317":"aux = base.astype(np.int)","9c7f51d4":"corr_mat = aux.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corr_mat, vmax=.7, square=True, cmap=\"coolwarm\")","8c71b043":"base.head()","cd8e2adb":"from sklearn.preprocessing import StandardScaler","eb2e6b18":"base.shape","067e95f3":"X = base.drop(['income'], axis = 1)\ny = base['income']","0f3a6af0":"scaler_x = StandardScaler()\n\nX = scaler_x.fit_transform(X)","8fccda7f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score","9e9c180f":"scores_mean = []\nscores_std = []\n\nk_lim_inf = 1\nk_lim_sup = 30\n\nfolds = 5\n\nk_max = None\nmax_std = 0\nmax_acc = 0\n\ni = 0\nprint('Finding best k...')\nfor k in range(k_lim_inf, k_lim_sup):\n    \n    KNNclf = KNeighborsClassifier(n_neighbors=k, p = 1)\n    \n    score = cross_val_score(KNNclf, X, y, cv = folds)\n    \n    scores_mean.append(score.mean())\n    scores_std.append(score.std())\n    \n    if scores_mean[i] > max_acc:\n        k_max = k\n        max_acc = scores_mean[i]\n        max_std = scores_std[i]\n    i += 1\n    if not (k%3):\n        print('   K = {0} | Best CV acc = {1:2.2f}% +\/-{3:4.2f}% (best k = {2})'.format(k, max_acc*100, k_max, max_std*100))\nprint('\\nBest k: {}'.format(k_max))","a2751c05":"plt.figure(figsize=(15, 7))\nplt.errorbar(np.arange(k_lim_inf, k_lim_sup), scores_mean, scores_std,\n             marker = 'o', markerfacecolor = 'purple' , linewidth = 3,\n             markersize = 10, color = 'coral', ecolor = 'purple', elinewidth = 1.5)\n\n\nyg = []\nx = np.arange(0, k_lim_sup+1)\nfor i in range(len(x)):\n    yg.append(max_acc)\nplt.plot(x, yg, '--', color = 'purple', linewidth = 1)\nplt.xlabel('k')\nplt.ylabel('accuracy')\nplt.title('KNN performed on several values of k')\nplt.axis([0, k_lim_sup, min(scores_mean) - max(scores_std), max(scores_mean) + 1.5*max(scores_std)])","83f1a9a8":"k = k_max\n\nKNNclf = KNeighborsClassifier(n_neighbors=k, p = 1)\nKNNclf.fit(X, y)","62a608ac":"df_test = pd.read_csv('..\/input\/adultb\/test_data.csv', na_values='?')\ndf_test.set_index('Id', inplace = True)\ndf_test.head()","dc7f3e27":"# capital.gain.cluster\nmedian = np.median(df_test[df_test['capital.gain'] > 0]['capital.gain'])\naux = pd.cut(df_test['capital.gain'],\n             bins = [-1, 0, median, df_test['capital.gain'].max()+1],\n             labels = [0, 1, 2])\ncapital_gain_clusters = pd.DataFrame({'capital.gain.clusters': aux})\ncapital_gain_clusters = capital_gain_clusters.astype(np.int)\n\n# capital.loss.cluster\nmedian = np.median(df_test[df_test['capital.loss'] > 0]['capital.loss'])\naux = pd.cut(df_test['capital.loss'],\n             bins = [-1, 0, median, df_test['capital.loss'].max()+1],\n             labels = [0, 1, 2])\ncapital_loss_clusters = pd.DataFrame({'capital.loss.clusters': aux})\ncapital_loss_clusters = capital_loss_clusters.astype(np.int)\n\nnew_data = pd.concat([capital_gain_clusters, capital_loss_clusters], axis = 1)","7050b14f":"features = ['age', 'education.num', 'occupation', 'relationship', 'race', 'hours.per.week']\n\nbase_test = pd.concat([new_data, df_test[features]], axis = 1)","fdcee458":"base_test.head()","84f14b00":"total = base_test.isnull().sum().sort_values(ascending = False)\npercent = ((base_test.isnull().sum()\/base_test.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","8d35f1d6":"value = base_test['occupation'].describe().top\nbase_test['occupation'] = base_test['occupation'].fillna(value)","2a5accf9":"total = base_test.isnull().sum().sort_values(ascending = False)\npercent = ((base_test.isnull().sum()\/base_test.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","06057319":"names = ['occupation', 'relationship', 'race']\n\ni = 0\nfor name in names:\n    base_test[name] = enc_x[i].transform(base_test[name])\n    i += 1","ffa9ec5d":"base_test.head()","655fe53b":"X_prev = scaler_x.transform(base_test.values)","f552f660":"temp = KNNclf.predict(X_prev)\n\ntemp = enc_y.inverse_transform(temp)\ntemp = {'Income': temp}\npredictions = pd.DataFrame(temp)","1ed23b77":"predictions.head()","9d413e7b":"predictions.to_csv(\"submission.csv\", index = True, index_label = 'Id')","74523842":"#### 3.1.3 *workclass*","62c2b333":"Para os tr\u00eas casos, devido a alta frequ\u00eancia da moda, utilizarei a moda como valor imputado.","ee1126fb":"Vemos que h\u00e1 nos dados, mais homens que mulheres, com rela\u00e7\u00e3o \u00e0 esses valores, temos:","acf634e5":"Ainda sobre a quest\u00e3o de g\u00eanero, temos:","03c04bcc":"Nessa primeira etapa, come\u00e7o importando algumas bibliotecas que usaremos ao longo do desenvolvimento do notebook. Al\u00e9m disso, faremos um tratamento nos **dados faltantes** com o uso da biblioteca *pandas*.","f0d6d822":"A seguir, uma simples visualiza\u00e7\u00e3o com uma matriz de correla\u00e7\u00e3o para termos uma ideia das contribui\u00e7\u00f5es sobre *income*.","0e463e53":"Conclu\u00edmos tamb\u00e9m que em maioria (e em m\u00e9dia) os indiv\u00eddos desse banco de dados trabalham 40 horas por semana (8 horas por dia e finais de semana livre) o que \u00e9 saud\u00e1vel. No entanto, h\u00e1 uma parcela significativa que excede esse n\u00famero, analiso a seguir.","6f19abbd":"### 3.3 Encoding dos dados classicat\u00f3rios\n\nUtilizo o LabelEncoder() para fazer o tratamento dos dados:","7a5b42f2":"### 3.4 Matriz de correla\u00e7\u00e3o\n\nAgora, farei uma an\u00e1lise sobre a correla\u00e7\u00e3o entre os atributos, para isso utilizarei da matriz de correla\u00e7\u00e3o do pr\u00f3prio **DataFrame** associado ao *seaborn*.","0f6fe639":"### 2.2 Compara\u00e7\u00e3o dos dados\n\nNessa subse\u00e7\u00e3o faremos uma an\u00e1lise comparativa entre os dados dos indiv\u00eddos do banco de dados. Utilizaremos histogramas, gr\u00e1ficos de pizza e boxplots.\n\nPrimeiro, crio uma fun\u00e7\u00e3o de compara\u00e7\u00e3o para histogramas.","43d2a3fe":"Vemos novamente, brancos e Asian-Pac-Islander, com uma educa\u00e7\u00e3o em m\u00e9dia superior \u00e0s demais etnias.","1940c718":"#### 3.1.6 *hours.per.week*","8d1d6ea2":"Aqui vemos que pessoas muito jovens trabalham em m\u00e9dia menos de 40 horas por semana, provavelmente pois devem trabalhar meio per\u00edodo. Assim como pessoas mais idosas, em m\u00e9dia trabalham tamb\u00e9m menos de 40 horas por dia.\n\nUma outra avalia\u00e7\u00e3o \u00e9 sobre a quantidade de tempo de trabalho por semana com rela\u00e7\u00e3o ao n\u00edvel de educa\u00e7\u00e3o das pessoas.","36c5ea50":"Observamos que aqueles que recebem acima de 50.000 em maioria s\u00e3o *Exec-managerial*, seguido por *Prof-specialty*, que s\u00e3o ocupa\u00e7\u00f5es ocupadas em maioria por homens brancos. J\u00e1 aqueles que recebem menos de 50.000 ocupam em maioria *Adm-clerical*, *Craft-repair*, *Other-service* e *Sales*, que s\u00e3o \u00e1reas que empregam maioria mulheres e negros.","a90511a8":"Observamos que h\u00e1 uma n\u00edtida diferen\u00e7a entre a empregabilidade dos homens e das mulheres. Al\u00e9m disso observamos tamb\u00e9m que n\u00e3o h\u00e1 mulheres que trabalham nas *Armed-Forces*, ser\u00e1 uma pol\u00edtica exclusiva?","8872c122":"### 1.2 Importa\u00e7\u00e3o dos dados\n\nAgora, subo o arquivo *train_data.csv* atrav\u00e9s do *pandas* na forma de **DataFrame**, considerando tamb\u00e9m valores <font color='red'>*?*<\/font> como <font color='red'>*Nan*<\/font>.","00d04ed8":"Logo vemos que h\u00e1 uma concentra\u00e7\u00e3o quase absoluta para valores pequenos, enquanto h\u00e1 poucos, bastante altos. Agora para termos uma no\u00e7\u00e3o da curva de idades do banco de dados, avalio com *.hist()*","d3c1b813":"Podemos observar que os **dados faltantes** concentram-se em 3 colunas: '*occupation*', '*workclass*' e '*native.country*'. Observo as distribui\u00e7\u00f5es das colunas, para analisarmos melhor:","b9168d17":"### 3.3 Remo\u00e7\u00e3o de atributos pouco relevantes\n\nUtilizo a matriz de correla\u00e7\u00e3o acima, para visualisar e reduzir a dimen\u00e7\u00e3o do problema excluindo atributos pouco relevantes.","30af1905":"### 5.4 Predi\u00e7\u00e3o da base teste","efd746bd":"### 3.2 Jun\u00e7\u00e3o da base com os valores constru\u00eddos e sele\u00e7\u00e3o de alguns atributos por intui\u00e7\u00e3o","380e3fd2":"#### 3.1.1 Alguns tratamentos de dados\n\nrefer\u00eancia: https:\/\/www.rdocumentation.org\/packages\/arules\/versions\/1.6-3\/topics\/Adult\n\n*education*\n\n- qualitativo ordenado\n    - Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate\n    \n*workclass*\n\n- booleano\n    - isPrivate\n    \n*age*\n *   \n- quantitativo ordenado\n     - Young (0-25) < Middle-aged (26-45) < Senior (46-65) < Old (66+)\n     \n*hours.per.week*\n\n- quantitativo ordenado\n    - Part-time (0-25) < Full-time (25-40) < Over-time (40-60) < Too-much (60+).\n\n*capital.gain* e *capital.loss*\n\n- quantitativo ordenado\n    - None (0) < Low (0 - mediana dos valores maiores que zero) and High (> mediana dos valores maiores que zero).","4b5f70a0":"### 4.1 Escalonamento dos dados\n\nPrimeiro farei um tratamento sobre os dados, de forma a escalon\u00e1-los utilizando *StandardScaler*.","3bb906c2":"Sobre o histograma acima (*age* e *income*) vemos que h\u00e1 uma distribui\u00e7\u00e3o relativamente normal sobre as pessoas que recebem *>50K* com o termo m\u00e9dio pr\u00f3ximo de 45 anos; j\u00e1 para pessoas *<=50K* , observa-se que com o aumento da idade, h\u00e1 uma redu\u00e7\u00e3o na quantidade de pessoas que recebem o valor.\n\nAgora, farei uma an\u00e1lise sobre a distribui\u00e7\u00e3o de sexo.","06583059":"### 4.3 Defini\u00e7\u00e3o do hiperpar\u00e2metro k do k-NN\n\nPrimeiro, avaliaremos o comportamento do aprenzidado para k = 1, ..., 29 para que possamos identificar o melhor valor de k para utilizarmos para prever os valores da base de teste a ser importada. Essa avalia\u00e7\u00e3o, ser\u00e1 feita com a utiliza\u00e7\u00e3o da valida\u00e7\u00e3o cruzada com 5 *folds*, e assim ser\u00e1 poss\u00edvel determinar o melhor hiperpar\u00e2metro k que se aplicar\u00e1 ao nosso problema.","7cba20f1":"### 3.1 Tratamento dos atributos\n\nAgora, farei um tratamento sobre alguns dos atributos qualitativos e quantitativos de forma a numerar aqueles orden\u00e1veis por exemplo.","45fda2f8":"## 2. An\u00e1lise explorat\u00f3ria dos dados\n\nNessa etapa, utilizarei as bibliotecas: *matplotlib*, *pandas* e *seaborn* como ferramentas para analisarmos e visualizarmos os dados, e assim tirar algumas conclus\u00f5es sobre os mesmos.","8bc51a8e":"### 1.1 Importa\u00e7\u00e3o de bibliotecas","808a7f11":"Observando o histograma acima, podemos de cara visualizar que provavelmente h\u00e1 um percentual maior de pessoas brancas que recebem mais do 50.000 sobre as pessoas negras, amer-indian-eskimo e outros. Os valores seguem abaixo.","ca051342":"Por fim, construimos essa pequena tabela de dados que podem vir a ser uteis.","69d15818":"#### 3.1.5 *education*","8d1a7aa1":"Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate","f31e2db8":"### 5.1 Adi\u00e7\u00e3o das colunas extra","42024ce2":"Sobre o histograma acima, nota-se que h\u00e1 uma grande discrep\u00e2ncia percentual (veja os valores abaixo) entre mulheres que recebem *>50K* e homens que recebem o mesmo valor, vemos que h\u00e1 muito mais homens que recebem *>50K*. Esses resultados sugerem que h\u00e1 **desigualdade de g\u00eanero** tratando-se do sal\u00e1rio.","5fd1ea40":"Enfim, predizemos as classes:","5f8f782a":"Agora, faremos algumas an\u00e1lises \u00e9tnicas.","94283aed":"### 5.5 Submiss\u00e3o do resultado\n\nPor fim, escrevo os resultados em **submission.csv**","e8dde41b":"#### 3.1.4 *native.country*","8d401ce2":"Acima vemos o gr\u00e1fico dos erros m\u00e9dios sobre a valida\u00e7\u00e3o cruzada para diferentes valores de k, em que foi poss\u00edvel determinar o melhor k que satisfaz nosso problema.","dc8f6951":"Agora, analisaremos os sal\u00e1rios das ocupa\u00e7\u00f5es, para tirarmos mais conclus\u00f5es.","dd823306":"#### 3.1.2 Fun\u00e7\u00f5es\n\nAlgumas declara\u00e7\u00f5es de fun\u00e7\u00f5es para o tratamento dos dados:","9b93545b":"Uma an\u00e1lise tamb\u00e9m interessante \u00e9 sobre as idades.","6baeec18":"Agora vou dividir os atributos quantitativos e qualitativos:","cc0253b5":"O que vemos \u00e9 que existem muito mais homens (inclusive percentualmente) que trabalham mais de 40 horas por semana, e percentualmente vemos mais mulheres trabalhando menos de 30 horas semanais. Agora analisarei as ocupa\u00e7\u00f5es.","d18e87f3":"De cara observamos que as colunas *capital.gain* e *capital.loss* possuem grupos bem definidos e distantes, para isso, veremos seu histograma:","5f44b279":"### 5.2 Verificando dados faltantes","0f831086":"### 2.1 Descri\u00e7\u00e3o dos dados\n\nObservaremos com o uso da fun\u00e7\u00e3o *.describe()* e *.hist()* do *pandas* para clarear nossas primeiras infer\u00eancias.","d0afa0c0":"E esses '*super trabalhadores*' que trabalham acima de 40 horas por semana constituem um grupo que cai exponencialmente com as horas de trabalho, no entanto, vemos por exemplo que em m\u00e9dia eles trabalham:","e90172dd":"Vemos que as pessoas com os maiores n\u00edveis de educa\u00e7\u00e3o, normalmente trabalham mais de 40 horas por dia, como aqueles que possuem t\u00edtulo de doutorado, mestrado e bacharel; como tamb\u00e9m os que concluiram uma escola profissionalizante.","e4f209eb":"#### 3.1.7 *capital.gain* e *capital.loss*","38be1821":"Como podemos observar, agora nosso banco de dados para o treino est\u00e1 limpo e pronto para ser analisado.","5e43a7c8":"## 1. Prepara\u00e7\u00e3o dos dados (*Data Prep*)","a251f690":"Novamente vemos que h\u00e1 uma grande diferen\u00e7a entre as ocupa\u00e7\u00f5es para cada etnia. Al\u00e9m disso podemos fazer uma compara\u00e7\u00e3o sobre a educa\u00e7\u00e3o.","13a0473c":"# 3. An\u00e1lise e preprocessamento dos atributos\n\nNessa se\u00e7\u00e3o usaremos bibliotecas como *skitlearn* para fazermos alguns preprocessamento dos dados, como tamb\u00e9m algumas an\u00e1lises de correla\u00e7\u00e3o entre os atributos para otimizarmos nosso aprendizado de m\u00e1quina no futuro. ","1f449bae":"Disso podemos concluir, que h\u00e1 tamb\u00e9m uma certa **desigualdade racial**, em que etinias n\u00e3o descrita em *Others*, e as etnias *Black* e *Amer-Indian-Eskimo* recebem proporcionalmente menos que as demais. Em seguida, comparemos as duas etinias em maior quantidade (brancos e negros), com rela\u00e7\u00e3o \u00e0s ocupa\u00e7\u00f5es.","1e0e8aca":"                           Escola Polit\u00e9cnica da Universidade de S\u00e3o Paulo\n                                         Data: 13\/09\/2019\n#       PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es\n### An\u00e1lise e aplica\u00e7\u00e3o do k-NN a base *adult*\n#### Autor: Lucas Nunes Sequeira","774f4057":"# 4. Agrupamento por K-NN\n\nNessa \u00faltima etapa, utilizarei a biblioteca *sklearn* para utiliza\u00e7\u00e3o do m\u00e9todo de aprendizado **k-NN**. Nesse processo, farei o uso da **valida\u00e7\u00e3o cruzada** para avaliar o desempenho do modelo.","0cf99001":"Al\u00e9m disso, podemos tamb\u00e9m avaliar com a fun\u00e7\u00e3o *.distplot()* do *seaborn* para compararmos com uma **curva de distribui\u00e7\u00e3o**.","ac213da2":"### 5.3 Encoding","54e30098":"Vemos que h\u00e1 uma grande quantidade de jovens (20 a 40 anos) nessa popula\u00e7\u00e3o.","8334880b":"O que vemos \u00e9 uma concentra\u00e7\u00e3o bastante elevada da quantidade de pessoas brancas nessa popula\u00e7\u00e3o pesquisada.","8d957ff8":"# 5. Predi\u00e7\u00e3o dos valores sem classe\n\nNessa \u00faltima etapa, utilizaremos o nosso classificador treinado para predizer sobre as classes do banco de dados teste que n\u00e3o possui valor de classe atribu\u00eddo aos indiv\u00edduos.","7be4404f":"### 1.3 Identificando os **dados faltantes** (*missing data*)\n\nNessa etapa dessa se\u00e7\u00e3o, identifico os **dados faltantes** utilizando algumas ferramentas do *pandas*. Para em seguida analisar o tipo, se \u00e9 aleat\u00f3rio ou n\u00e3o por exemplo.","693a0427":"### 4.4 Treinamento do k-NN\n\nAgora, faremos o treinamento do k-NN utilizando nossa base de treino, em seguida inferimos sobre nossa acur\u00e1cia da base de testes."}}