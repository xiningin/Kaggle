{"cell_type":{"8900c809":"code","82b16cd5":"code","e2b73fde":"code","bbc0a2a6":"code","1b2adaa7":"code","b3aed733":"code","e6351d8d":"code","bb4e8327":"code","245b2b91":"code","1f0a1848":"code","e7b1df68":"code","f16d6897":"code","577a7cec":"code","53204bc1":"code","36457192":"code","316ebcc0":"code","9e765b10":"code","da85e33d":"code","80b92cce":"code","448d9929":"code","31e34173":"code","304b1ab0":"code","307aa4c5":"code","b57bc99f":"code","a0f2c38b":"code","c6477019":"code","889c5165":"code","75ce13b1":"code","a155d663":"code","8059ec99":"code","1586d3c3":"code","72ad704e":"code","2c85ae84":"code","6631b58e":"code","0b74a3bf":"code","91d3cce6":"code","cfdcd9cb":"code","a055aeeb":"code","53143da3":"code","537c5beb":"code","12faa59a":"code","90e4b20b":"code","0f01bc49":"code","c65cbde4":"code","445b0c5c":"code","dfdb7ed0":"code","f0af9177":"code","10947796":"code","fd46f9c0":"code","bbdbf62a":"code","ce9403c5":"code","44bb6cd9":"code","783ee561":"code","cc6396c1":"markdown","983f8eb4":"markdown","5666ad1d":"markdown","2da49fe8":"markdown","cd44255c":"markdown","25e2c2b5":"markdown","633b09d9":"markdown","b1256e7b":"markdown","bdc275da":"markdown","e1ae4f68":"markdown","cce81d31":"markdown","4988fc67":"markdown","22ca6cec":"markdown","c1a6e92f":"markdown","e2487e15":"markdown","651635d1":"markdown","f680796e":"markdown","e6e54e3e":"markdown","5fed6d06":"markdown","77ce115f":"markdown","4fd58056":"markdown","8954c86c":"markdown","cce73150":"markdown","e881076c":"markdown","1c640f00":"markdown"},"source":{"8900c809":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#matplotlib inline","82b16cd5":"# read the data\nflights = pd.read_csv('..\/input\/feb-2020-us-flight-delay\/feb-20-us-flight-delay.csv')","e2b73fde":"flights.columns","bbc0a2a6":"flights.head()","1b2adaa7":"flights['Unnamed: 9'].unique()","b3aed733":"flights.drop('Unnamed: 9', axis=1, inplace=True)","e6351d8d":"flights.columns","bb4e8327":"flights.shape","245b2b91":"# Rename the DEP_DEL15 to is_dealy\nflights.rename(columns={'DEP_DEL15':'is_delay'}, inplace=True)","1f0a1848":"# Look for null values\nflights.isnull().sum()","e7b1df68":"print(f'\\'is_delay\\' missing values are {100*4951\/flights.shape[0]}%')\nprint(f'\\'DEP_TIME\\' missing values are {100*4938\/flights.shape[0]}%')","f16d6897":"data = flights.copy()","577a7cec":"data = data.dropna()","53204bc1":"data.isnull().sum()","36457192":"sns.countplot(x=data['is_delay'])","316ebcc0":"data.groupby('is_delay').size()\/len(data)","9e765b10":"sns.countplot(x='DAY_OF_WEEK', hue=\"is_delay\", data=data)","da85e33d":"print(f'Number of Origin airports is {data.ORIGIN.nunique()}')\nprint(f'Number of Dest airports is {data.DEST.nunique()}')","80b92cce":"origins = pd.DataFrame(data.groupby('ORIGIN').is_delay.count())\norigins.rename(columns={'is_delay':'flights'}, inplace=True)\norigins['delayed'] = data.groupby('ORIGIN').is_delay.sum()\norigins['delayed_perc'] = 100*origins.delayed\/origins.flights\norigins.reset_index(level=0, inplace=True)\norigins.sort_values(by=['delayed_perc'], inplace=True, ascending=False, ignore_index=True)","448d9929":"origins.head(10)","31e34173":"dests = pd.DataFrame(data.groupby('DEST').is_delay.count())\ndests.rename(columns={'is_delay':'flights'}, inplace=True)\ndests['delayed'] = data.groupby('DEST').is_delay.sum()\ndests['delayed_perc'] = 100*dests.delayed\/dests.flights\ndests.reset_index(level=0, inplace=True)\ndests.sort_values(by=['delayed_perc'], inplace=True, ascending=False, ignore_index=True)","304b1ab0":"dests.head(10)","307aa4c5":"origins.sort_values(by=['flights'], inplace=True, ascending=False, ignore_index=True)\ndests.sort_values(by=['flights'], inplace=True, ascending=False, ignore_index=True)","b57bc99f":"origins.head(10)","a0f2c38b":"dests.head(10)","c6477019":"airports = ['ATL', 'ORD', 'DFW', 'DEN', 'CLT', 'LAX', 'PHX', 'IAH', 'LAS', 'SFO']\n\ndata['ORIGIN'].loc[~data['ORIGIN'].isin(airports)] = 'others'\ndata['DEST'].loc[~data['DEST'].isin(airports)] = 'others'","889c5165":"print(f'values in \\'ORIGIN\\': {data.ORIGIN.unique()}')\nprint(f'values in \\'DEST\\': {data.DEST.unique()}')","75ce13b1":"sns.lmplot( x=\"is_delay\", y=\"DISTANCE\", data=data, fit_reg=False, hue='is_delay', legend=False)","a155d663":"sns.countplot(x='OP_UNIQUE_CARRIER', hue='is_delay', data=data)","8059ec99":"# Check coulmns types\ndata.dtypes","1586d3c3":"data.describe()","72ad704e":"data['DISTANCE'] = (data['DISTANCE']-data['DISTANCE'].mean())\/data['DISTANCE'].std()#\ndata['DEP_TIME'] = (data['DEP_TIME']\/\/100)","2c85ae84":"from sklearn.preprocessing import MinMaxScaler\n\nto_scale = ['DISTANCE', 'DAY_OF_WEEK', 'DEP_TIME', 'DAY_OF_MONTH']\nscaler = MinMaxScaler()\ndata[to_scale] = scaler.fit_transform(data[to_scale])","6631b58e":"data.describe()","0b74a3bf":"# The month is not important here as it is the same for all samples (Feb)\ndata.drop(columns=['MONTH'], axis=1, inplace=True)\n\ncategorical_columns  = ['DAY_OF_MONTH', 'DAY_OF_WEEK','OP_UNIQUE_CARRIER', \n                        'ORIGIN', 'DEST', 'is_delay']\n\ncategorical_columns.remove('is_delay') # Remove the target variable before converting to categorical\n\n# Convert them to categorical dtype\nfor c in categorical_columns:\n    data[c] = data[c].astype('category')","91d3cce6":"data.dtypes","cfdcd9cb":"data_dummies = pd.get_dummies(data[categorical_columns], drop_first=True)\ndata = pd.concat([data, data_dummies], axis = 1)\ndata.drop(categorical_columns,axis=1, inplace=True)","a055aeeb":"data.columns","53143da3":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_recall_fscore_support","537c5beb":"# Extract the target column\ntarget = data.is_delay\ndata.drop(columns=['is_delay'], axis=1, inplace=True)","12faa59a":"# Split the dataset in the ratio train 80% and test 20%\nx_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=95) ","90e4b20b":"logReg =LogisticRegression()\nlogReg.fit(x_train, y_train)\ny_pred_logReg = logReg.predict(x_test)","0f01bc49":"randForest = RandomForestClassifier()\nrandForest.fit(x_train, y_train)\ny_pred_randForest = randForest.predict(x_test)","c65cbde4":"xgb = XGBClassifier(use_label_encoder=False)\nxgb.fit(x_train, y_train)\ny_pred_xgb = xgb.predict(x_test)","445b0c5c":"# Calculate accuracy\ndef evaluate_model(labels, preds):\n    accuracy = (preds == labels).sum() \/ preds.shape[0]\n    print(f'Accuracy: {accuracy}')\n\n    auc = roc_auc_score(labels, preds)\n    print(f'AUC     : {auc}')\n\n    precision, recall, f1_score, _ = precision_recall_fscore_support(labels, preds, average = 'binary')\n    print(f'Precision: {precision}')\n    print(f'Recall: {recall}')\n    print(f'F1_score: {f1_score}')\n\n    confusion_matrix = pd.crosstab(index=labels, columns=np.round(preds), \n                                   rownames=['True'], colnames=['predictions']).astype(int)\n    plt.figure(figsize = (5,5))\n    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix') ","dfdb7ed0":"evaluate_model(y_pred_logReg, y_test)","f0af9177":"evaluate_model(y_pred_randForest, y_test)","10947796":"evaluate_model(y_pred_xgb, y_test)","fd46f9c0":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import make_scorer\n\nf1_scorer = make_scorer(f1_score, greater_is_better=True)\n\nparam_grid = [\n{'n_estimators': [10, 25],\n 'max_depth': [10, 50],\n 'min_samples_split': [5, 10, 15],\n 'bootstrap': [True, False]}\n]\n\ngrid_search_forest = GridSearchCV(randForest, param_grid, cv=10, scoring=f1_scorer)\ngrid_search_forest.fit(x_train, y_train)","bbdbf62a":"cvres = grid_search_forest.cv_results_\n\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","ce9403c5":"grid_search_forest.best_estimator_","44bb6cd9":"grid_search_forest.best_score_","783ee561":"grid_best= grid_search_forest.best_estimator_.predict(x_test)\nevaluate_model(grid_best, y_test)","cc6396c1":"## 2- Random Forest","983f8eb4":"* 'Unnamed: 9' is an extra-empty column, so we will get rid of it.","5666ad1d":"## 1 - Logistic Regression","2da49fe8":"## Check the features\n- Drop uncessary ones if exist.\n- Encoding\n- Scale if needed.","cd44255c":"### Split twice to get train, and test sets","25e2c2b5":"- Top airports for 'dest' and 'origin' are:  ['ATL', 'ORD', 'DFW', 'DEN', 'CLT', 'LAX', 'PHX', 'IAH', 'LAS', 'SFO']","633b09d9":"- Distance range is high ---> needs to be scaled.\n- Dep_TIME needs to be in 24-hour format.","b1256e7b":"### Data Format\n* **MONTH** - Month\n* **DAY_OF_MONTH** - Day of Month\n* **DAY_OF_WEEK** - Day of Week\n* **OP_UNIQUE_CARRIER** - Unique Carrier Code\n* **ORIGIN** - Origin airport location\n* **DEST** - Destination airport location\n* **DEP_TIME** - Actual Departure Time (local time: hhmm)\n* **DEP_DEL15** - Departure Delay Indicator, 15 Minutes or More (1=Yes, 0=No) [TARGET VARIABLE]\n* **DISTANCE** - Distance between airports (miles)","bdc275da":"### - Remove the missing values","e1ae4f68":"* The missing 'is_delay' values represent only 0.86%, so we can safely remove them.\n* The same thing applies for 'DEP_TIME', the missing is ~0.86%.","cce81d31":"## Final Notes:\n- The final f1-score increased slightly, but if we increased the number of trees i.e.(n_estimators), it may get better.\n- Adding more features like (weather) will result in a better performance, but it's not availble right now.","4988fc67":"**Note:** As will start to do some preprocessing and cleaning, we will make a new copy of the data to work on without changing the original one.","22ca6cec":"### Now there are some questions we need to ask:\n\n* What day of the week has the most delays?\n* Which origin and destination airports have the most delays?\n* Is flight distance a factor in the delays?\n* Which carrier has the most delays?","c1a6e92f":"### - Delay vs No Delay","e2487e15":"## 3- XGBoost","651635d1":"**We see that the data is highly imbalanced; 85.6% is 'no delay' vs 14.4% 'delay' flights.**","f680796e":"- Thre are 350 airports for both 'DEST, nad 'ORIGIN', this will result in 700 new features when doing one-hot-encoding, so we will use the top 10 airports only, and set the rest ","e6e54e3e":"- Delay happens in both short and long distances.","5fed6d06":"### since the data is unbalanced, we will look at the F1-Score.\n* f1-score of the RandomForest model is the highest one, so will go with this model.","77ce115f":"- Most delays happens at HGR airport.","4fd58056":"- We are goning to create a dataframe for 'Origin' and 'Dest' as the plot will be not clear due to the large numbers.","8954c86c":"## Visualization","cce73150":"# Model Tuning\n\n### We will use the **Grid Search**\u00b6 algorithm to tune the hyperparameters\n\n### Most important hyperparameters of Random Forest:\n\n* n_estimators = number of trees, larger --> more complex.\n* max_features =  number of maximum features provided to each tree, the default value is the best 'square root of the number of features'.\n* max_depth = max number of levels in each decision tree, if it's too large --> overfitting.\n* min_samples_split = min number of data points placed in a node before the node is split, larger values prevent overfitting.\n* max_leaf_nodes = number of leaf nodes, very small --> underfitting, and very large --> overfitting.\n* min_samples_leaf = min number of data points allowed in a leaf node, very large --> underfitting, and very small --> overfitting.\n* bootstrap = method for sampling data points (with or without replacement)","e881076c":"# Bulid the Baseline Model","1c640f00":"# Data preprocessing and visualization:"}}