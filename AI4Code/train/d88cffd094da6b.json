{"cell_type":{"0d25bc69":"code","901c35b2":"code","f8c0517a":"code","44ef4430":"code","5fa25585":"code","4939daea":"code","fbfa00e6":"code","674cbc43":"code","7b6717bd":"code","83d6e179":"code","2366e185":"code","dcf2d8e9":"code","df959e0e":"code","9248ad85":"code","7e27a8a8":"code","f275c8af":"code","b46d876e":"code","fd329336":"code","1b930d2a":"markdown","0c93a52a":"markdown","7fb03618":"markdown","31029627":"markdown","265659ab":"markdown","3123a0b9":"markdown","8351024c":"markdown","968f5ef8":"markdown","a1b6a72b":"markdown","f592c957":"markdown","7dd7adfc":"markdown","95cab679":"markdown","ab470539":"markdown"},"source":{"0d25bc69":"!pip install s2cell","901c35b2":"import numpy as np\nimport pandas as pd\nimport s2cell\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f8c0517a":"alert = pd.read_csv('\/kaggle\/input\/danthon2021\/alerts.csv')\nirregular = pd.read_csv('\/kaggle\/input\/danthon2021\/irregularities.csv')\ntrain = pd.read_csv('\/kaggle\/input\/danthon2021\/data_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/danthon2021\/data_test.csv')","44ef4430":"road_type = alert.groupby(['s2token_15'])['road_type'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\ncity = alert.groupby(['s2token_15'])['city'].agg(lambda x: x.dropna().head(1) if x.notna().any() else np.nan)\nstreet = alert.groupby(['s2token_15'])['street'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nmagvar = alert[alert.reliability >= 7].groupby(['s2token_15'])['magvar'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nalert_type = alert[alert.reliability >= 7].groupby(['s2token_15'])['type'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nalert_subtype = alert[alert.reliability >= 7].groupby(['s2token_15'])['subtype'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nis_highway = irregular.groupby(['s2token_center'])['is_highway'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nirregular_speed = irregular.groupby(['s2token_center'])['speed'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nregular_speed = irregular.groupby(['s2token_center'])['regular_speed'].agg(lambda x: x.dropna().head(1) if x.notna().any() else np.nan)\ndelay = irregular.groupby(['s2token_center'])['delay_seconds'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\ntravel_jam = irregular.groupby(['s2token_center'])['seconds'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nlength = irregular.groupby(['s2token_center'])['length'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nirregular_type = irregular.groupby(['s2token_center'])['type'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nseverity = irregular.groupby(['s2token_center'])['severity'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\njam_level = irregular.groupby(['s2token_center'])['jam_level'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\ndrivers_count = irregular.groupby(['s2token_center'])['drivers_count'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)\nalerts_count = irregular.groupby(['s2token_center'])['alerts_count'].agg(lambda x: x.mode()[0] if x.notna().any() else np.nan)","5fa25585":"train['latitude'] = train['Ids'].str[:9].apply(lambda x: s2cell.token_to_lat_lon(x)[0])\ntrain['longitude'] = train['Ids'].str[:9].apply(lambda x: s2cell.token_to_lat_lon(x)[1])\ntrain['day_of_week'] = train['Ids'].str[10:20].astype('datetime64').dt.dayofweek \/ 3.5 * np.pi\ntrain['day_of_month'] = train['Ids'].str[10:20].astype('datetime64').dt.day \/ 15.5 * np.pi\ntrain['hour'] = train['Ids'].str[21:].astype('int8') \/ 12 * np.pi\ntrain['road_type'] = train['Ids'].str[:9].apply(lambda x: road_type[x] if x in road_type.index else np.nan)\ntrain['city'] = train['Ids'].str[:9].apply(lambda x: city[x] if x in city.index else np.nan)\ntrain['street'] = train['Ids'].str[:9].apply(lambda x: street[x] if x in street.index else np.nan)\ntrain['magvar'] = train['Ids'].str[:9].apply(lambda x: magvar[x] if x in magvar.index else np.nan) \/ 180 * np.pi\ntrain['alert_type'] = train['Ids'].str[:9].apply(lambda x: alert_type[x] if x in alert_type.index else np.nan)\ntrain['alert_subtype'] = train['Ids'].str[:9].apply(lambda x: alert_subtype[x] if x in alert_subtype.index else np.nan)\ntrain['is_highway'] = train['Ids'].str[:9].apply(lambda x: is_highway[x] if x in is_highway.index else np.nan)\ntrain['irregular_speed'] = train['Ids'].str[:9].apply(lambda x: irregular_speed[x] if x in irregular_speed.index else np.nan)\ntrain['regular_speed'] = train['Ids'].str[:9].apply(lambda x: regular_speed[x] if x in regular_speed.index else np.nan)\ntrain['delay'] = train['Ids'].str[:9].apply(lambda x: delay[x] if x in delay.index else np.nan)\ntrain['travel_jam'] = train['Ids'].str[:9].apply(lambda x: travel_jam[x] if x in travel_jam.index else np.nan)\ntrain['length'] = train['Ids'].str[:9].apply(lambda x: length[x] if x in length.index else np.nan)\ntrain['irregular_type'] = train['Ids'].str[:9].apply(lambda x: irregular_type[x] if x in irregular_type.index else np.nan)\ntrain['severity'] = train['Ids'].str[:9].apply(lambda x: severity[x] if x in severity.index else np.nan)\ntrain['jam_level'] = train['Ids'].str[:9].apply(lambda x: jam_level[x] if x in jam_level.index else np.nan)\ntrain['drivers_count'] = train['Ids'].str[:9].apply(lambda x: drivers_count[x] if x in drivers_count.index else np.nan)\ntrain['alerts_count'] = train['Ids'].str[:9].apply(lambda x: alerts_count[x] if x in alerts_count.index else np.nan)","4939daea":"city_encoded = train.pivot_table(index = 'city',values = 'Labels')\nstreet_encoded = train.pivot_table(index = 'street',values = 'Labels')\nalert_type_encoded = train.pivot_table(index = 'alert_type',values = 'Labels')\nalert_subtype_encoded = train.pivot_table(index = 'alert_subtype',values = 'Labels')\nirregular_type_encoded = train.pivot_table(index = 'irregular_type',values = 'Labels')","fbfa00e6":"train['latitude'] = train['latitude'] + 6.5\ntrain['longitude'] = train['longitude'] - 107\ntrain['day_of_week_sin'] = np.sin(train['day_of_week'])\ntrain['day_of_week_cos'] = np.cos(train['day_of_week'])\ntrain['day_of_month_sin'] = np.sin(train['day_of_month'])\ntrain['day_of_month_cos'] = np.cos(train['day_of_month'])\ntrain['hour_sin'] = np.sin(train['hour'])\ntrain['hour_cos'] = np.cos(train['hour'])\ntrain['magvar_sin'] = np.sin(train['magvar'])\ntrain['magvar_cos'] = np.cos(train['magvar'])\ntrain['road_type'] = train['road_type'].replace([6,8,14],[2,5,5])\ntrain['city'] = train['city'].apply(lambda x: city_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntrain['street'] = train['street'].apply(lambda x: street_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntrain['alert_type'] = train['alert_type'].apply(lambda x: alert_type_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntrain['alert_subtype'] = train['alert_subtype'].apply(lambda x: alert_subtype_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntrain['is_highway'] = train['is_highway'].map({'t' : 1,'f' : 0})\ntrain['irregular_type'] = train['irregular_type'].apply(lambda x: irregular_type_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntrain.drop(columns = ['Ids','day_of_week','day_of_month','hour','magvar'],inplace = True)","674cbc43":"X = train.drop(columns = 'Labels')\ny = train['Labels']","7b6717bd":"imputed = KNNImputer().fit_transform(X.to_numpy())","83d6e179":"for i,j in enumerate(X.columns.to_list()):\n    if X[j].isna().any:\n        X[j] = pd.Series(imputed[:,i]).values","2366e185":"clf = RandomForestClassifier(n_estimators = 20,random_state = 42,max_depth = 10,min_samples_leaf = 5)\nscores = cross_val_score(clf,X,y,scoring='f1')\nprint('Rerata skor F',scores.mean(),'dengan simpangan baku',scores.std(),'.')\nmodel = clf.fit(X,y)","dcf2d8e9":"test['latitude'] = test['Ids'].str[:9].apply(lambda x: s2cell.token_to_lat_lon(x)[0])\ntest['longitude'] = test['Ids'].str[:9].apply(lambda x: s2cell.token_to_lat_lon(x)[1])\ntest['day_of_week'] = test['Ids'].str[10:20].astype('datetime64').dt.dayofweek \/ 3.5 * np.pi\ntest['day_of_month'] = test['Ids'].str[10:20].astype('datetime64').dt.day \/ 15.5 * np.pi\ntest['hour'] = test['Ids'].str[21:].astype('int8') \/ 12 * np.pi\ntest['road_type'] = test['Ids'].str[:9].apply(lambda x: road_type[x] if x in road_type.index else np.nan)\ntest['city'] = test['Ids'].str[:9].apply(lambda x: city[x] if x in city.index else np.nan)\ntest['street'] = test['Ids'].str[:9].apply(lambda x: street[x] if x in street.index else np.nan)\ntest['magvar'] = test['Ids'].str[:9].apply(lambda x: magvar[x] if x in magvar.index else np.nan) \/ 180 * np.pi\ntest['alert_type'] = test['Ids'].str[:9].apply(lambda x: alert_type[x] if x in alert_type.index else np.nan)\ntest['alert_subtype'] = test['Ids'].str[:9].apply(lambda x: alert_subtype[x] if x in alert_subtype.index else np.nan)\ntest['is_highway'] = test['Ids'].str[:9].apply(lambda x: is_highway[x] if x in is_highway.index else np.nan)\ntest['irregular_speed'] = test['Ids'].str[:9].apply(lambda x: irregular_speed[x] if x in irregular_speed.index else np.nan)\ntest['regular_speed'] = test['Ids'].str[:9].apply(lambda x: regular_speed[x] if x in regular_speed.index else np.nan)\ntest['delay'] = test['Ids'].str[:9].apply(lambda x: delay[x] if x in delay.index else np.nan)\ntest['travel_jam'] = test['Ids'].str[:9].apply(lambda x: travel_jam[x] if x in travel_jam.index else np.nan)\ntest['length'] = test['Ids'].str[:9].apply(lambda x: length[x] if x in length.index else np.nan)\ntest['irregular_type'] = test['Ids'].str[:9].apply(lambda x: irregular_type[x] if x in irregular_type.index else np.nan)\ntest['severity'] = test['Ids'].str[:9].apply(lambda x: severity[x] if x in severity.index else np.nan)\ntest['jam_level'] = test['Ids'].str[:9].apply(lambda x: jam_level[x] if x in jam_level.index else np.nan)\ntest['drivers_count'] = test['Ids'].str[:9].apply(lambda x: drivers_count[x] if x in drivers_count.index else np.nan)\ntest['alerts_count'] = test['Ids'].str[:9].apply(lambda x: alerts_count[x] if x in alerts_count.index else np.nan)","df959e0e":"test['latitude'] = test['latitude'] + 6.5\ntest['longitude'] = test['longitude'] - 107\ntest['day_of_week_sin'] = np.sin(test['day_of_week'])\ntest['day_of_week_cos'] = np.cos(test['day_of_week'])\ntest['day_of_month_sin'] = np.sin(test['day_of_month'])\ntest['day_of_month_cos'] = np.cos(test['day_of_month'])\ntest['hour_sin'] = np.sin(test['hour'])\ntest['hour_cos'] = np.cos(test['hour'])\ntest['magvar_sin'] = np.sin(test['magvar'])\ntest['magvar_cos'] = np.cos(test['magvar'])\ntest['road_type'] = test['road_type'].replace([6,8,14],[2,5,5])\ntest['city'] = test['city'].apply(lambda x: city_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntest['street'] = test['street'].apply(lambda x: street_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntest['alert_type'] = test['alert_type'].apply(lambda x: alert_type_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntest['alert_subtype'] = test['alert_subtype'].apply(lambda x: alert_subtype_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntest['is_highway'] = test['is_highway'].map({'t' : 1,'f' : 0})\ntest['irregular_type'] = test['irregular_type'].apply(lambda x: irregular_type_encoded.at[x,'Labels'] if pd.notna(x) else np.nan)\ntest.drop(columns = ['Ids','day_of_week','day_of_month','hour','magvar'],inplace = True)","9248ad85":"imputed = KNNImputer().fit_transform(test.to_numpy())","7e27a8a8":"for i,j in enumerate(test.columns.to_list()):\n    if test[j].isna().any:\n        test[j] = pd.Series(imputed[:,i]).values","f275c8af":"submission = pd.read_csv('\/kaggle\/input\/danthon2021\/data_test.csv')","b46d876e":"submission['Labels'] = model.predict(test)","fd329336":"submission.set_index('Ids').to_csv('submission.csv')","1b930d2a":"Mengacu pada bentuk baku berkas submisi, dataset test yang asli akan digunakan kembali dengan nama submission.","0c93a52a":"Terakhir, dataframe submission disimpan dalam berkas csv dengan kolom Ids sebagai index.","7fb03618":"Dari dataset alert dan irregularity yang disediakan, saya berniat menggunakan fitur-fitur di dalam kedua dataset tersebut sebagai fitur pada dataset train maupun test. Secara umum, saya kelompokkan dataset alert dan irregularity berdasarkan s2token terlebih dahulu. Kemudian, setiap s2token diasosiasikan dengan fitur lain, khususnya modus pada fitur tersebut. Misalnya, token 2e69e9384 bersesuaian dengan road_type 7, dst. Bisa dikatakan, kita sedang membuat suatu kamus.","31029627":"Didapati bahwa model yang dibangun memiliki keumuman yang cukup sebagaimana dikonfirmasi melalui validasi silang (cross validation). Model kemudian dilatih menggunakan keseluruhan dataset training.\n\nSetelah model selesai dibangun, dataset test akan dikondisikan sama dengan dataset train sebagai berikut.","265659ab":"Setelah tahapan imputasi missing values selesai, saya langsung menjalankan validasi silang (cross validation). Saya memilih estimator RandomForestClassifier karena kebal terhadap pencilan dan distribusi data, selain bahwa estimator tersebut bersifat ensemble.\n\nSebagai catatan, jika diperiksa melalui y.value_counts(), didapati bahwa kelas target tidaklah seimbang. Pada tahap ini, saya sudah mencoba beberapa metode supaya tercapai kelas yang seimbang, mulai dari under sampling dengan EditedNearestNeighbours, over sampling dengan RandomOverSampler, sampai dengan SMOTE. Saya juga mencoba mengatur hyperparameter class_weight pada RandomForestClassifier agar memberi bobot kelas False sekitar 2 kali bobot kelas True, sesuai dengan ketidakseimbangan proposi kelas yang disebutkan sebelumnya. Namun demikian, keempat metode tersebut ternyata tidak memberikan hasil yang optimal.","3123a0b9":"Dataframe submission kemudian disisipi kolom baru, yaitu Labels, berisi prediksi model atas dataset test.","8351024c":"Jika dataset train diperiksa, misalnya melalui train.isna().sum(), didapati bahwa beberapa fitur di dalamnya mengandung missing values. Seperti biasa, saya menggunakan metode imputasi KNNImputer untuk mengisi missing values tersebut.","968f5ef8":"Kemudian, di antara fitur-fitur tambahan pada dataset training, terdapat beberapa fitur kategorikal, baik yang sifatnya nominal maupun ordinal. Hal ini dapat diperiksa menggunakan train.info() lalu mencocokkan deskripsi fitur pada berkas berisi keterangan masing-masing fitur.\n\nUntuk mengubah fitur-fitur kategorikal tersebut, saya menyandikannya secara ordinal, di mana nilainya saya ambil dari kemungkinan Labels bernilai True untuk setiap nilai pada fitur kategorikal tersebut. Hal ini dapat dilakukan dengan kode berikut.","a1b6a72b":"Missing values pada dataset test juga diimputasi menggunakan metode KNNImputer, sama seperti pada dataset train.","f592c957":"Pada notebook ini, saya menggunakan pustaka s2cell. Untuk memasang pustaka tersebut, jalankan kode berikut.","7dd7adfc":"Hanya dari kolom Ids pada dataset train, kita bisa mengekstrak informasi latitude dan longitude, day_of_week, day_of_month, serta hour. Hal tersebut dicapai dengan 5 baris pertama kode berikut. Baris kode setelah itu bermaksud mengekstrak informasi tambahan berdasarkan s2token sehingga menghasilkan fitur road_type, city, street, dst. Ekstraksi fitur tambahan tersebut tentu saja menggunakan kamus yang telah kita susun di langkah sebelumnya.\n\nSebagai catatan, untuk fitur day_of_week, day_of_month, hour, dan magvar langsung diubah menjadi sudut dalam radian. Alasannya adalah fitur-fitur ini bersifat periodik. Misalnya, hari ke-6 dan hari ke-0 adalah dua nilai yang berurutan, atau jam ke-23 dan jam ke-0 juga adalah dua nilai yang berurutan. Dengan mengubah fitur-fitur ini ke dalam sudut, saya pikir sifat keperiodikannya bisa ditampilkan.","95cab679":"Untuk menyederhanakan fitur latitude dan longitude, saya menambahkan offset pada kedua fitur tersebut, masing-masing +6.5 dan -107. Kemudian untuk lebih menonjolkan sifat keperiodikan fitur day_of_week, day_of_month, hour, dan magvar, masing-masing dari fitur tersebut saya ubah ke dalam komponen sinus dan kosinus. Pada fitur road_type, saya juga menyederhanakan beberapa nilai karena saya anggap nilai yang saya ganti itu sama dengan nilai pengganti, di mana hal tersebut dapat dilihat pada berkas keterangan fitur yang dibagikan oleh panitia lomba.","ab470539":"Dengan menjalankan prosedur di atas, ternyata prediksi yang dibuat hanya menghasilkan skor F sebesar 0.60623 (publik) atau 0.61876 (private)."}}