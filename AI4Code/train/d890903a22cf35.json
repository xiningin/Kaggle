{"cell_type":{"9126c0e1":"code","72416652":"code","0655740d":"code","c72d2501":"code","b8a9dfb9":"code","ab4083a3":"code","546e62b1":"code","30047041":"code","c2dc53a0":"code","9ce6c5bb":"code","a924f40d":"code","18e0df53":"code","779be959":"code","34f19e1e":"code","24963e5e":"code","3afa5259":"code","371b797c":"code","4b1ee3c2":"code","af178dcc":"code","b099b300":"code","365bae82":"markdown","85391326":"markdown","9bf4795c":"markdown","62ea5d50":"markdown","ae7bdeac":"markdown"},"source":{"9126c0e1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","72416652":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten","0655740d":"from keras.datasets import mnist","c72d2501":"(X_train, y_train) , (X_test, y_test)=mnist.load_data()","b8a9dfb9":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","ab4083a3":"# Reshaping the dataset\nX_train=X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test=X_test.reshape(X_test.shape[0], 28, 28, 1)","546e62b1":"# Normalization\nX_train= X_train\/255\nX_test=X_test\/255","30047041":"y_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)","c2dc53a0":"model=Sequential()","9ce6c5bb":"# Select 6 feature convolution kernels with a size of 5 * 5 (without offset), and get 66 feature maps. The size of each feature map is 32\u22125 + 1 = 2832\u22125 + 1 = 28.\n# That is, the number of neurons has been reduced from 10241024 to 28 \u2217 28 = 784 28 \u2217 28 = 784.\n# Parameters between input layer and C1 layer: 6 \u2217 (5 \u2217 5 + 1)\n\nmodel.add(Conv2D(6, kernel_size=(5,5), activation= 'relu', input_shape = (28,28,1)))","a924f40d":"# The input of this layer is the output of the first layer, which is a 28 * 28 * 6 node matrix.\n# The size of the filter used in this layer is 2 * 2, and the step length and width are both 2, so the output matrix size of this layer is 14 * 14 * 6.\n\nmodel.add(MaxPool2D(pool_size=(2,2)))","18e0df53":"# The input matrix size of this layer is 14 * 14 * 6, the filter size used is 5 * 5, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n# The output matrix size of this layer is 10 * 10 * 16. This layer has 5 * 5 * 6 * 16 + 16 = 2416 parameters\n\nmodel.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))","779be959":"# The input matrix size of this layer is 10 * 10 * 16. The size of the filter used in this layer is 2 * 2, and the length and width steps are both 2, so the output matrix size of this layer is 5 * 5 * 16.\n\nmodel.add(MaxPool2D(pool_size=(2, 2)))","34f19e1e":"# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n\n\nmodel.add(Flatten())","24963e5e":"\n# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\nmodel.add(Dense(120, activation='relu'))\n\n# The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\nmodel.add(Dense(84, activation='relu'))\n\n# The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\nmodel.add(Dense(10, activation='softmax'))","3afa5259":"model.summary()","371b797c":"# Let's compile the model\nmodel.compile(loss='CategoricalCrossentropy', optimizer='adam', metrics = ['accuracy'])","4b1ee3c2":"model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, y_test))","af178dcc":"score=model.evaluate(X_test, y_test)","b099b300":"print(\"Train score\", score[0])\nprint(\"Test score\", score[1])","365bae82":"#### checking the shape of the dataset","85391326":"## In this notebook, we will see how LeNET works with little modifications as in 1998 when LeNET was developed, some of the activation functions like RELU were not available so we will replace tanh with ReLU to see how the model works","9bf4795c":"#### Loading the dataset","62ea5d50":"## Building the model architecture","ae7bdeac":"## Importing libraries and preprocessing"}}