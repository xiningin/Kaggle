{"cell_type":{"7548fc56":"code","142ccc2b":"code","bf0dbf8e":"code","86e4c892":"code","6c0713e1":"code","ca04b3b9":"code","b27c33be":"code","a25f9ccd":"code","fd0fa96b":"code","6f9f7202":"code","ae0ce870":"code","8f4f8a72":"code","4429b4c3":"code","876b9ee0":"code","e4d91375":"code","8f8cc1f6":"code","d163f906":"code","c21dff8d":"code","e292dde1":"code","6c019069":"code","3283bbe3":"code","6e6326bd":"code","4bc90330":"code","967a78f1":"code","0da9afe0":"code","7473ca3d":"markdown","ded232d3":"markdown","b6109d71":"markdown","ecff0ff3":"markdown","844dac22":"markdown","1cc826d7":"markdown","cf285512":"markdown","a126cdf4":"markdown","60573686":"markdown","8123cb42":"markdown","936e09f5":"markdown","187cb922":"markdown","f3ccb55f":"markdown","d1ce66d3":"markdown","355aad1c":"markdown"},"source":{"7548fc56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","142ccc2b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom matplotlib import cm","bf0dbf8e":"data = pd.read_csv('..\/input\/employee-future-prediction\/Employee.csv')\ndata.shape","86e4c892":"data.head()","6c0713e1":"data.info()","ca04b3b9":"plt.figure(figsize = (10,10))\nsns.heatmap(data.isnull())\nplt.title('Checking Null Values')\nplt.show()","b27c33be":"plt.figure(figsize = (10,8))\nplt.title('Distribution of our label whether a employee will leave or not')\ndata['LeaveOrNot'] = data['LeaveOrNot'].map({1:'Leave' ,0:'NotLeave' })\nsns.countplot(x = data['LeaveOrNot'] , palette='Accent')\nplt.show()","a25f9ccd":"plt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nlabels = data['JoiningYear'].value_counts().keys()\ncolors =cm.Accent(np.arange(7)\/7)\nplt.pie(x = data['JoiningYear'].value_counts() , \n       labels = labels,\n       explode =  (0.1,0.1,0.1,0.1,0.1,0.1,0.1),\n       shadow = True , \n       colors = colors,\n       autopct='%1.1f%%')\nplt.title('Distribution of Joining Years')\n\nplt.subplot(1,2,2)\nsns.countplot(x = data['JoiningYear'], hue = data['LeaveOrNot'] , palette='Set2')\nplt.show()","fd0fa96b":"plt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nlabels = data['Education'].value_counts().keys()\ncolors =cm.Accent(np.arange(7)\/7)\nplt.pie(x = data['Education'].value_counts() , \n       labels = labels,\n       explode =  (0.1,0.1,0.1),\n       shadow = True , \n       colors = colors,\n       autopct='%1.1f%%')\nplt.title('Distribution of Education ')\n\nplt.subplot(1,2,2)\nsns.countplot(x = data['Education'], hue = data['LeaveOrNot'] , palette='Set2')\nplt.show()","6f9f7202":"plt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nlabels = data['City'].value_counts().keys()\ncolors =cm.Accent(np.arange(7)\/7)\nplt.pie(x = data['City'].value_counts() , \n       labels = labels,\n       explode =  (0.1,0,0.05),\n       shadow = True , \n       colors = colors,\n       autopct='%1.1f%%')\nplt.title('Distribution of City of Employees ')\n\nplt.subplot(1,2,2)\nsns.countplot(x = data['City'], hue = data['LeaveOrNot'] , palette='Set2')\nplt.show()","ae0ce870":"plt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nlabels = data['PaymentTier'].value_counts().keys()\ncolors =cm.Accent(np.arange(7)\/7)\nplt.pie(x = data['PaymentTier'].value_counts() , \n       labels = labels,\n       explode =  (0.1,0.1,0.1),\n       shadow = True , \n       colors = colors,\n       autopct='%1.1f%%')\nplt.title('Payment Tier')\n\nplt.subplot(1,2,2)\nsns.countplot(x = data['PaymentTier'], hue = data['LeaveOrNot'] , palette='Set2')\nplt.show()","8f4f8a72":"plt.figure(figsize = (10,10))\ndata['Age'].plot(kind = 'hist',color = 'lightblue' , edgecolor = 'white')\nplt.title('Distribution Of Age')\nplt.show()","4429b4c3":"plt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nsns.countplot(x = data['Gender'] , palette='Accent')\nplt.title('Distribution of  Males and Female')\nplt.subplot(1,2,2)\nsns.countplot(x = data['Gender'] ,hue = data['LeaveOrNot'], palette='Set2')\nplt.show()","876b9ee0":"plt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nsns.countplot(x = data['EverBenched'] , palette='Accent')\nplt.title('Distribution of Everbenched')\nplt.subplot(1,2,2)\nsns.countplot(x = data['EverBenched'] ,hue = data['LeaveOrNot'], palette='Set2')\nplt.show()","e4d91375":"plt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nsns.countplot(x = data['ExperienceInCurrentDomain'] , palette='Accent')\nplt.title('Distribution Experience In Years')\nplt.subplot(1,2,2)\nsns.countplot(x = data['ExperienceInCurrentDomain'] ,hue = data['LeaveOrNot'], palette='Set2')\nplt.title('Distribution Experience In Years with respect to Label')\nplt.show()","8f8cc1f6":"data['Education'] = data['Education'].map({'Bachelors':0,'Masters':1 , 'PHD':2})\ndata['Gender'] = data['Gender'].map({'Female':0 ,'Male':1})\ndata['EverBenched'] = data['EverBenched'].map({'No':0 , 'Yes':1})\ndata['LeaveOrNot'] = data['LeaveOrNot'].map({'NotLeave':0 , 'Leave':1})\ndata = pd.get_dummies(data = data,columns = ['City'])","d163f906":"plt.figure(figsize = (20,10))\nsns.heatmap(data.corr(),annot =True)\nplt.show()","c21dff8d":"from sklearn.model_selection import train_test_split\nx = data.drop(columns = 'LeaveOrNot')\ny = data['LeaveOrNot']\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20,shuffle = True)","e292dde1":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLogR = LogisticRegression(solver='liblinear')\nLogR.fit(x_train,y_train)\ny_pred = LogR.predict(x_test)\n\nLogistic_Regression = LogR.score(x_test,y_test)\nprint(confusion_matrix(y_test,y_pred))\na = confusion_matrix(y_test,y_pred)\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = a,fmt='g',cmap = 'Set2')\nplt.title('Confusion Matrix for Logistic Regression')\nplt.show()\n","6c019069":"from sklearn.ensemble import RandomForestClassifier\n#from sklearn.model_selection import GridSearchCV\n\n# params ={\n#    'n_estimators':[10,50,100,200],\n#     'criterion':['gini','entropy'],\n#     'bootstrap':[True,False],\n#     'max_features':['auto', 'sqrt', 'log2']} \n\nrfr = RandomForestClassifier(bootstrap = True,\n criterion='entropy',\n max_features='log2',\n n_estimators= 200)\n\nrfr.fit(x_train,y_train)\nRandom_Forest_classifier = rfr.score(x_test,y_test)\ny_pred = rfr.predict(x_test)\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = True,fmt='g',cmap = 'Set2')\nplt.title('Confusion Matrix for Random Forest Classifier')\nplt.show()\n","3283bbe3":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(x_train,y_train)\nSupport_vector_classifier = svc.score(x_test,y_test)\ny_pred = svc.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = True,fmt='g',cmap='Set2')\nplt.title('Confusion Matrix for Support Vector Classifier')\nplt.show()","6e6326bd":"from sklearn.naive_bayes import GaussianNB\n\nGNB = GaussianNB()\nGNB.fit(x_train,y_train)\nGaussian_Naive_bayes = GNB.score(x_test,y_test)\ny_pred = GNB.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = True,fmt='g',cmap = 'Set2')\nplt.title('Confusion Matrix for Naive Bayes')\nplt.show()","4bc90330":"from sklearn.neighbors import KNeighborsClassifier\n\nKNNC = KNeighborsClassifier()\nKNNC.fit(x_train,y_train)\nKNN = KNNC.score(x_test,y_test)\ny_pred = KNNC.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = True,fmt='g',cmap = 'Set2')\nplt.title('Confusion Matrix for Naive Bayes')\nplt.show()","967a78f1":"models = ['LogisticRegression','Random Forest Classifier' , 'Support Vector Classifier', 'Naive Bayes Classifier' , 'K nearest neighbours']\nscores = [Logistic_Regression,Random_Forest_classifier,Support_vector_classifier,Gaussian_Naive_bayes,KNN]\nplt.figure(figsize = (20,10))\nsns.barplot(y = scores , x = models , palette='Set2')\nplt.title('Comparing Different Models')\nplt.show()","0da9afe0":"feature_importance = rfr.feature_importances_\nfeatures = x.columns\nplt.figure(figsize = (20,10))\nsns.barplot(x = feature_importance , y = features,palette='Set2')\nplt.title('Feature Importance')\nplt.show()\n","7473ca3d":"# ***Exploratory Data Analysis***","ded232d3":"## ***Most Number of employee joined in 2017 as shown in chart. Most number of employee who left the company were from year 2018, followed by year 2015 and 2017***","b6109d71":"## ***Joining Years and Age are the most important features which helps model to predict the Label.***","ecff0ff3":"### ***Happy Learning***","844dac22":"# ***Splitting data into train and test***","1cc826d7":"## ***47.9% employee are from Bangalore. Pune city employee are more likley to leave.***","cf285512":"# ***Checking Null Values***","a126cdf4":"## ***Female Employees are more likley to leave their job.***","60573686":"## ***Random Forest Classifier is performing well so we will use that model for our classification***","8123cb42":"# ***Training Model***","936e09f5":"## ***77.4% of the Employees are Bachelors in this dataset followed by Masters and PHD. Employees with Masters Education are more likley to leave.***","187cb922":"# ***Importing Dataset***","f3ccb55f":"## ***Most Number of Employees are between 25 to 30 years.***","d1ce66d3":"## ***About 75% of employees are having 3 Tier payment. Every 2 out of 1 Employee having 2nd Tier Payment is very likley to leave the company.***","355aad1c":"# ***Data Preprocessing***"}}