{"cell_type":{"b9cfc7c2":"code","e85e7a78":"code","7190c711":"code","99562d85":"code","e07881af":"code","7a7e6ce7":"code","d835f187":"code","ad10224f":"code","1177aab5":"code","50c20680":"code","e1ce6a8b":"code","50f60297":"code","b054a001":"code","18ed69ef":"code","30ea92c3":"code","1a450246":"code","e2eac177":"code","598c305e":"code","97cba21c":"code","97c6d97c":"code","9c0a3818":"code","d932a663":"code","56608978":"code","7f06f90a":"code","a0609af7":"code","287c3738":"code","2aa38992":"code","1d2c73a5":"code","98e6129f":"code","369f6278":"code","9cb05ded":"code","3ff3326b":"code","0ff2d463":"code","132cf3f9":"code","bfb276c5":"code","060a7efa":"code","ae2e1d16":"code","2cd38462":"code","1eeeb635":"code","6533f393":"code","9d22d228":"code","36af3b83":"markdown","ae3d2a91":"markdown","3f834aeb":"markdown","9042b07c":"markdown","ce8f20a0":"markdown","84c5c9d0":"markdown","7dc75161":"markdown","0fa6612d":"markdown","11755853":"markdown","6feb99b9":"markdown","ca3a2c3e":"markdown","ecd5bbdb":"markdown","5002b557":"markdown","0d830fbc":"markdown","1488df9e":"markdown","5ca5ce11":"markdown","5367e6ce":"markdown","33ad5d7e":"markdown","4c3f4d64":"markdown","ffc8614c":"markdown","be2fcf62":"markdown","3170761d":"markdown","f6ceb67d":"markdown","79a0e790":"markdown","d9f76941":"markdown","c9f1c639":"markdown","4230fdd9":"markdown","37e6eeea":"markdown","74602bc1":"markdown","2e14a879":"markdown","7df243dd":"markdown","e4ea1fc5":"markdown"},"source":{"b9cfc7c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e85e7a78":"# data analysis, random, wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport warnings\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nwarnings.filterwarnings(\"ignore\")\n\n\n#to create validation data set\nfrom sklearn.model_selection import train_test_split \n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n#To check the accuracy score\nfrom sklearn.metrics import make_scorer, accuracy_score \n\nfrom sklearn.model_selection import GridSearchCV","7190c711":"#problem 1,2,3 # initial analysis of the various input features and target lable \n\n#reading train_data from kaggle\nprint (\"reading train data from kaggle\")\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndisplay(train_data.head())\n\n#reading test data from kaggle\nprint (\"reading test data from kaggle\")\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndisplay(test_data.head())\n\n\n","99562d85":"#==========================================\nprint (\"preview the training data\")\ndisplay (train_data.head())\nprint ('look at the info of the data')\ntrain_data.info()\nprint('_'*50)\nprint ('look at the describe() data')\ndisplay (train_data.describe().T)\nprint('_'*50)\nprint ('find number of null')\ntrain_data.isnull().sum()","e07881af":"#==========================================\nprint (\"preview the testing data\")\ndisplay (test_data.head())\nprint ('look at the info of the data')\ntest_data.info()\nprint('_'*50)\nprint ('look at the describe() data')\ndisplay (test_data.describe().T)\nprint('_'*50)\nprint ('find number of null')\ntest_data.isnull().sum()","7a7e6ce7":"print ('the mean() between Pclass and survived')\ndisplay (train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n\nprint ('the mean() between SEX and survived')\ndisplay(train_data[['Sex', 'Survived']].groupby(['Sex'], as_index =False).mean())\n\nprint ('the mean() between SibSp and Survived')\ndisplay(train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index = False).mean())\n\nprint ('the mean() between Parch and Survived')\ndisplay(train_data[['Parch','Survived']].groupby(['Parch'], as_index = False).mean())","d835f187":"sns.pairplot(train_data)","ad10224f":"sns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)\nplt.title(\"Distribution of Survival based on Gender\")\nplt.show()","1177aab5":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Distribution of Survival Based on Class\")\nplt.show()","50c20680":"sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_data)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")\n#help(sns.barplot)","e1ce6a8b":"sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=train_data)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")","50f60297":"#the number of survival in the trining set\nprint (train_data['Survived'].value_counts(normalize=True))\nsns.countplot(train_data['Survived'])\nplt.title(\"Distribution of Survival\")\nplt.show()","b054a001":"print ('-'*50, '\\n\\nNumber of null value in testing dataset')\nprint (test_data['Age'].isnull().value_counts())\n\nprint ('-'*50, '\\n\\nNumber of null value in Training dataset')\nprint (train_data['Age'].isnull().value_counts())\n\ng = sns.FacetGrid(train_data, col ='Survived')\ng.map(plt.hist, 'Age', bins=20)\nplt.show()\n\n#after looking to the chart I would like to sbret them to 5 goups \ntrain_data['Age_group'] = pd.cut(train_data['Age'], 5) #\"cut is used to specifically define the bin edges.\"\n#print ('\\nCount number of people in each group: \\n', pd.cut(train_data['Age'],5).value_counts())\n\ntrain_data[['Age_group', 'Survived']].groupby(['Age_group'], as_index=False).mean().sort_values(by='Age_group', ascending=True)\n\n\n#print (train_data['Survived'].groupby(pd.qcut(train_data['Age'],5)).mean())\n","18ed69ef":"for i in (train_data.Age):\n    age_guess = rnd.uniform (int (30),int (15))\n#    print (int (age_guess))\n    train_data['Age'].fillna(int (age_guess), inplace = True)\n\n#print (\"Number of null value in Age in training:\\t\" , train_data['Age'].isnull().sum())\n\nfor i in (test_data.Age):\n    age_guess = rnd.uniform (int (30),int (15))\n#    print (int (age_guess))\n    test_data['Age'].fillna(int (age_guess), inplace = True)\n\n#print (\"Number of null value in Age in testing :\\t\" , test_data['Age'].isnull().sum())\n","30ea92c3":"\ntrain_data['Age_class'] = 0\ntest_data['Age_class'] = 0\n\ndef age_update(trianing, testing):\n    for update_Age in [train_data, test_data]:    \n        update_Age.loc[ update_Age['Age'] <= 16, 'Age_class'] = 1\n        update_Age.loc[(update_Age['Age'] > 16) & (update_Age['Age'] <= 32), 'Age_class'] = 2\n        update_Age.loc[(update_Age['Age'] > 32) & (update_Age['Age'] <= 48), 'Age_class'] = 3\n        update_Age.loc[(update_Age['Age'] > 48) & (update_Age['Age'] <= 64), 'Age_class'] = 4\n        update_Age.loc[ update_Age['Age'] > 64, 'Age_class'] = 5\n    return trianing, testing\n\nage_update(train_data, test_data)\n\ndisplay (train_data.head(7))\ndisplay (test_data.head(7))\n","1a450246":"print (train_data['Ticket'].head(20))\n","e2eac177":"print ('first 5 values in Date column:\\n', train_data['Fare'].head(5))\nprint ('-'* 50,'\\nSplit Fare value to 3 value grupos')\nprint (pd.qcut(train_data['Fare'],3).value_counts())\n\nprint ('-'* 50,'\\nSurvived people in each Fare group\\n')\nFare_groups = train_data['Survived'].groupby(pd.qcut(train_data['Fare'],3)).value_counts()\nprint ( Fare_groups )\n\nprint ('-'* 50,'\\nThe mean() value of Survived people in each Fare group')\ntrain_data['Fare_group'] = pd.qcut(train_data['Fare'],3)\nprint (train_data[['Fare_group','Survived']].groupby(['Fare_group'],as_index=False).mean())\n\n#create new clume to make it as index for Fare class \ntrain_data['Fare_class'] = 0\ntest_data['Fare_class'] = 0\ndisplay(train_data.head(),test_data.head())","598c305e":"display (test_data[test_data['Fare'].isnull()== True])\n\nprint (len(train_data))\n\nfor updateFare in [train_data, test_data]:\n    updateFare.loc[ updateFare['Fare'] <= 8.662, 'Fare_class'] = 1\n    updateFare.loc[(updateFare['Fare'] > 8.662) & (updateFare['Fare'] <= 26.0), 'Fare_class'] = 2\n    updateFare.loc[ updateFare['Fare'] > 26, 'Fare_class'] = 3\n    updateFare['Fare_class'] = updateFare['Fare_class'].astype(int)\n\n","97cba21c":"\n#train_data = train_data.drop(['Fare_group'], axis=1)\n\n\ndisplay (train_data.head(8))\ndisplay (test_data.head(8))\n#test_data['Fare'].isnull().sum() # check about null value in Fare","97c6d97c":"print ('-'* 50, '\\n See the non null value number in Cabin\\n')\nprint (train_data.info())\nprint ('-'* 50, '\\n See the non null value number in Cabin\\n')\nprint (test_data.info())\nprint ('-'* 50, '\\n Totlal numver of null value in cabin in training set : \\t')\nprint (train_data['Cabin'].isnull().sum())\nprint ('-'* 50, '\\n Totlal numver of null value in cabin in testing set : \\t')\nprint (test_data['Cabin'].isnull().sum())","9c0a3818":"print ('Totlal number of null value in Embarked in training set :')\nprint (train_data['Embarked'].isnull().sum())\nprint ('-'* 50, '\\n Totlal number of null value in Embarked in testing set : \\t')\nprint (test_data['Embarked'].isnull().sum())\n\nprint ('-'* 50, '\\n Total number of passenger from each embarking locations in training set : \\t')\nprint (train_data['Embarked'].value_counts())\nprint (train_data['Embarked'].value_counts(normalize = True))\nprint ('-'* 50, '\\n Total number of passenger from each embarking locations in testing set : \\t')\nprint (test_data['Embarked'].value_counts())\nprint (test_data['Embarked'].value_counts(normalize = True))\n#train['Embarked'].value_counts()\nsns.countplot(train_data['Embarked'], hue=train_data['Fare_class'])\nplt.show()\nsns.countplot(train_data['Embarked'], hue=train_data['Pclass'])\nplt.show()\n\nsns.countplot(train_data['Embarked'], hue=train_data['Survived'])\nplt.show()","d932a663":"#features = [\"Pclass\", \"Sex\", \"Age\", \"Embarked\", \"Fare\", \"FamSize\", \"IsAlone\", \"Title\"]\nfeatures = ['Pclass', 'Sex', 'SibSp', 'Parch','Age_class','Embarked','Fare_class']\n\nX_train = pd.get_dummies (train_data[features])\n#X_train = train_data[features] #define training features set\ny_train = train_data[\"Survived\"] #define training label set\nX_test = pd.get_dummies (test_data[features]) #define testing features set\n#we don't have y_test, that is what we're trying to predict with our model\n#display (X_train.head())\ndisplay (X_test.head())\n#display (y_train.head())","56608978":"from sklearn.model_selection import train_test_split #to create validation data set\n\nX_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=11) #X_valid and y_valid are the validation sets\n#display (X_training.head())\n#display (X_valid.head())\n#display (y_training.head())\n#display (y_valid.head())","7f06f90a":"X_test = pd.get_dummies(test_data[features])\ndisplay (X_training.head())\ndisplay (X_test.head())","a0609af7":"# training data and Model accuracy\nsvc_Model = SVC() \nsvc_Model.fit(X_training, y_training)\npredictive_svc = svc_Model.predict(X_valid)\nacc_svc = accuracy_score(y_valid, predictive_svc)\n\nprint(acc_svc)","287c3738":"svc_Model = SVC() \nsvc_Model.fit(X_training, y_training)\npredictive_svc = svc_Model.predict(X_test)\n\nprint(predictive_svc)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictive_svc})\noutput.to_csv('my_submission_predictive_svc.csv', index=False)\npredictive_svc_CSV = pd.read_csv('my_submission_predictive_svc.csv')\nprint(\"my submission was successfully saved!\")\npredictive_svc_CSV\n","2aa38992":"# training data and Model accuracy\nlinsvc_Model = LinearSVC()\nlinsvc_Model.fit(X_training, y_training)\n\npredictive_linsvc = linsvc_Model.predict(X_valid)\nacc_linsvc = accuracy_score(y_valid, predictive_linsvc)\n\nprint(acc_linsvc)","1d2c73a5":"#Testing data\nlinsvc_Model = LinearSVC()\nlinsvc_Model.fit(X_training, y_training)\npredictive_linsvc = linsvc_Model.predict(X_test)\n\nprint(predictive_linsvc)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictive_linsvc})\noutput.to_csv('my_submission_predictive_linsvc.csv', index=False)\npredictive_linsvc_CSV = pd.read_csv('my_submission_predictive_linsvc.csv')\nprint(\"my submission was successfully saved!\")\npredictive_linsvc_CSV\n\n","98e6129f":"# training data and Model accuracy\nrf_model = RandomForestClassifier(criterion='entropy')\nrf_model.fit(X_training, y_training)\npredict_rf = rf_model.predict(X_valid)\nacc_rf = accuracy_score(y_valid, predict_rf)\n\nprint(acc_rf)","369f6278":"rf_model = RandomForestClassifier()\nrf_model.fit(X_training, y_training)\npredict_rf = rf_model.predict(X_test)\n#acc_rf = accuracy_score(y_valid, pred_rf)\n\n#print(acc_rf)\nprint(predict_rf)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predict_rf})\noutput.to_csv('my_submission_predict_rf.csv', index=False)\npredict_rf_CSV = pd.read_csv('my_submission_predict_rf.csv')\nprint(\"my submission was successfully saved!\")\npredict_rf_CSV","9cb05ded":"# training data and Model accuracy\nlogreg_model = LogisticRegression()\nlogreg_model.fit(X_training, y_training)\npredict_logreg = logreg_model.predict(X_valid)\nacc_logreg = accuracy_score(y_valid, predict_logreg)\n\nprint(acc_logreg)","3ff3326b":"logreg_model = LogisticRegression()\nlogreg_model.fit(X_training, y_training)\npredict_logreg = logreg_model.predict(X_test)\n\nprint(predict_logreg)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predict_logreg})\noutput.to_csv('my_submission_predict_logreg.csv', index=False)\npredict_logreg_CSV = pd.read_csv('my_submission_predict_logreg.csv')\nprint(\"my submission was successfully saved!\")\npredict_logreg_CSV","0ff2d463":"# training data and Model accuracy\nknn_model = KNeighborsClassifier()\nknn_model.fit(X_training, y_training)\npredict_knn = knn_model.predict(X_valid)\nacc_knn = accuracy_score(y_valid, predict_knn)\n\nprint(acc_knn)","132cf3f9":"knn_model = KNeighborsClassifier()\nknn_model.fit(X_training, y_training)\npredict_knn = knn_model.predict(X_test)\n\nprint(predict_knn)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predict_knn})\noutput.to_csv('my_submission_predict_knn.csv', index=False)\npredict_knn_CSV = pd.read_csv('my_submission_predict_knn.csv')\nprint(\"my submission was successfully saved!\")\npredict_knn_CSV","bfb276c5":"# training data and Model accuracy\ngnb_model = GaussianNB()\ngnb_model.fit(X_training, y_training)\npredict_gnb = gnb_model.predict(X_valid)\nacc_gnb = accuracy_score(y_valid, predict_gnb)\n\nprint(acc_gnb)","060a7efa":"gnb_model = GaussianNB()\ngnb_model.fit(X_training, y_training)\npredict_gnb = gnb_model.predict(X_test)\n\nprint(predict_gnb)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predict_gnb})\noutput.to_csv('my_submission_predict_gnb.csv', index=False)\npredict_gnb_CSV = pd.read_csv('my_submission_predict_gnb.csv')\nprint(\"my submission was successfully saved!\")\npredict_gnb_CSV","ae2e1d16":"# training data and Model accuracy\ndt_model = DecisionTreeClassifier()\ndt_model.fit(X_training, y_training)\npredict_dt = dt_model.predict(X_valid)\nacc_dt = accuracy_score(y_valid, predict_dt)\n\nprint(acc_dt)","2cd38462":"dt_model = DecisionTreeClassifier()\ndt_model.fit(X_training, y_training)\npredict_dt = dt_model.predict(X_test)\n\nprint(predict_dt)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predict_dt})\noutput.to_csv('my_submission_predict_dt.csv', index=False)\npredict_dt_CSV = pd.read_csv('my_submission_predict_dt.csv')\nprint(\"my submission was successfully saved!\")\npredict_dt_CSV","1eeeb635":"# training data and Model accuracy\nfrom xgboost import XGBClassifier\n\nxg_model = XGBClassifier(objective=\"binary:logistic\", n_estimators=10, seed=123)\nxg_model.fit(X_training, y_training)\npredict_xg = xg_model.predict(X_valid)\nacc_xg = accuracy_score(y_valid, predict_xg)\n\nprint(acc_xg)","6533f393":"xg_model = XGBClassifier(objective=\"binary:logistic\", n_estimators=10, seed=123)\nxg_model.fit(X_training, y_training)\npredict_xg = xg_model.predict(X_test)\n#acc_xg = accuracy_score(y_valid, pred_xg)\n\n#print(acc_xg)\nprint(predict_xg)\n\n# after creating predicte test data , now will  present data and prapearing it to submit \noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predict_xg})\noutput.to_csv('my_submission_predict_xg.csv', index=False)\npredict_xg_CSV = pd.read_csv('my_submission_predict_xg.csv')\nprint(\"my submission was successfully saved!\")\npredict_xg_CSV","9d22d228":"model_performance = pd.DataFrame({\n    \"Model\": [\"SVC\", \"Linear SVC\", \"Random Forest\", \n              \"Logistic Regression\", \"K Nearest Neighbors\", \"Gaussian Naive Bayes\",  \n              \"Decision Tree\", \"XGBClassifier\"],\n    \"Accuracy\": [acc_svc, acc_linsvc, acc_rf, \n              acc_logreg, acc_knn, acc_gnb, acc_dt, acc_xg]\n})\n\nmodel_performance.sort_values(by=\"Accuracy\", ascending=False)","36af3b83":"\n# Cabin  \nMost of the Cabin values are null value after look at the information we can find that \n- training data has only 204 non-null value of 891 that means we had only 22.9% information and miss information about 687 value about 77%\n- test data has only 91 non-null value of 418 that means we had only 21.8% information and miss information about 327 value about 78%\nso, I will not use it in my model\n","ae3d2a91":"# Libraries  \n**Import libraries and packages**\n\nwe will use these packeges and libraries to sovle our problem:","3f834aeb":"# **Basic Information about Testing data**","9042b07c":"Defining Features in Training\/Test Set","ce8f20a0":"SVC Model","84c5c9d0":"Evaluating Model Performances","7dc75161":"Using the Fare feature to create a new ordinal value based on the Fare_group and fare.\nalso, fill **a null value** in test data as a low fare because it's in class 3 and old age","0fa6612d":"\n# Age  \nLet us use a histogram chart to understand the relationship between Age and survival rate. then we will try to include it in our models \n\nfor missing values which are about 177 values which about 20% of our data. and as we know the age is afficted our target so, we will try to fill null value in diffrent way to improve our model,\n\nour way to fill missing value:\n- A simple way to fill it is to generate random numbers between mean and standard deviation - I tried this but it not give me a good and stable result. So, I will use other way.\n- in this Notbook, I will try to group recoud by the age goupb from 1 to 5 \n\n","11755853":"### **Gender**\nshowing the percentage of the surviving people depend on this feature","6feb99b9":"### **Pclass (Ticket class)**\n\nshowing the percentage of the surviving people depend on this feature","ca3a2c3e":"GaussianNB Model","ecd5bbdb":"LogisiticRegression Model","5002b557":"# In Problem 3 - classification Model 3\n\n#### In this problem we will try to use many models to find the best and improve our data by making new features depend on old features. also, improve my model to have to get accuracy \n\nabout the features, for this time I will try to use\n\n    * Passenger     ( I think, it just index so, I will not use it in my model)\n    * Survived        ( this will be the target )\n    * Pclass          ( I will use it in my model )\n    * Name            ( I think, it also a kind of index so, I will not use it)\n    * Sex             ( I will use it in my model )\n    * Age             ( I will use it in my model after filling null value and group it )\n    * SibSp           ( I will use it in my model )\n    * Parch           ( I will use it in my model )\n    * Ticket          ( I will use the class rather than Ticket number )\n    * Fare            ( I will use it in my model after I group it )\n    * Cabin           ( I will not use it because has more than 70% missing)\n    * Embark          ( I will use it after filling in null value )\n","0d830fbc":"# new improvement\n### work more on some features\n- Age\n- Ticket\n- Fare\n- Cabin\n- Embarking","1488df9e":"## **Basic Information about Training data**","5ca5ce11":"# New Models","5367e6ce":"DecisionTree Model","33ad5d7e":"# **Loding and Viewing data**","4c3f4d64":"\n# Embarking  \nMost pasengger are from Southampton \n\nAs we can see Southampton embarking locations are the most and we have only 2 missing value in Training set\nso , we will fill in null value wiht value S (C = Cherbourg, Q = Queenstown, S = Southampton )","ffc8614c":"# Analysis various input features \n\n","be2fcf62":"**Survival Rates Based on Gender and Class**","3170761d":"Split the data to test our model","f6ceb67d":"XGBoost Model","79a0e790":"\n# Fare  \nWe don't have a null value in Fare. Also, I think it has a relationship between Passenger fare and Passenger class. \n\nI found that when you have pay high, you have a high chance to survive \nI split them into three groups and change the values to ordinal \n* 1st group 308 people and 61 people survive  \n* 2nd group 295 people and 116 people survive\n* 3rd group 288 people and 165 people survive","d9f76941":"### Fill in Age feature \nNow I would try to fill the null values of the Age column . in this time, it should be more accurate than taking only the mean age or the standard deviation age of the population\nalso, I would use that then replace Age with ordinals based on Age groups.","c9f1c639":"\n# Ticket  \nAfter looking to Ticket I would like to use pacenger class and pacenger fare reather than ticket number\n","4230fdd9":"LinearSVC Model","37e6eeea":"# Libraries for Machine learning  ","74602bc1":"<img src= \"https:\/\/www.historic-uk.com\/wp-content\/uploads\/2017\/04\/the-sinking-of-the-rms-titanic.jpg\" alt =\"Titanic\" style='width: 500px;'>\n\n\n# Data Maining \n# Calssification Model 3\n","2e14a879":"# **Sklearn Models to Test**\n\nHere I will try many models to test our data.\n I will use make_scorer and accuracy_score function from sklearn to evaluate my models.\n\n- SVC\n- Linear SVC\n- Random Forest\n- Logistic Regression\n- K Nearest Neighbors\n- Gaussian Naive Bayes \n- Decision Tree\n- XGBClassifier\n","7df243dd":"KNeighbors Model","e4ea1fc5":"## **Analyze data by visulazition**\n\nIt is very good to understand the data by visualizition data we will using it in machine learining models."}}