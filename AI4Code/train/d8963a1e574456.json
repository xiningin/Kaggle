{"cell_type":{"5395304b":"code","cd707453":"code","f10647f2":"code","bdc5ae5a":"code","2c49d56b":"code","164efc31":"code","5e477d0f":"code","8316ccae":"code","82a9f759":"code","0b0c4003":"code","780ead6f":"code","43048b6c":"code","ba898b65":"code","5e9a4c2e":"code","356eef1a":"markdown","9f0e213b":"markdown","1b67aaa9":"markdown","00f363ca":"markdown"},"source":{"5395304b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport keras\nimport os\nfrom tqdm import tqdm\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')","cd707453":"train_json = '..\/input\/region-proposals-of-crop-weed-dataset\/train.json'\ntest_json = '..\/input\/region-proposals-of-crop-weed-dataset\/test.json'\nimages_path = '..\/input\/crop-and-weed-detection-data-with-bounding-boxes\/agri_data\/data\/'","f10647f2":"with open(train_json,'r') as train:\n    train_data = json.load(train)","bdc5ae5a":"with open(test_json,'r') as test:\n    test_data = json.load(test)","2c49d56b":"train_images_list = list(train_data.keys())\ntest_images_list =list(test_data.keys())","164efc31":"os.mkdir('Train')\nos.mkdir('Test')","5e477d0f":"os.mkdir('Train\/weed')\nos.mkdir('Train\/crop')\nos.mkdir('Train\/background')\n\nos.mkdir('Test\/weed')\nos.mkdir('Test\/crop')\nos.mkdir('Test\/background')","8316ccae":"#For Training\nfor count,img_id in tqdm(enumerate(train_images_list)):\n    img = cv2.imread(images_path + img_id)\n    \n    \n    for proposal in train_data[img_id]['region_proposal']:\n        x,y,w,h = proposal[0]\n        label   = proposal[1]\n         \n        temp_img = cv2.cvtColor(cv2.resize(img[y:y+h,x:x+w,:],(224,224)),cv2.COLOR_BGR2RGB)\n        \n        cv2.imwrite('Train\/'+label+'\/'+ label+'_'+ str(len(os.listdir('Train\/'+label))) +'.jpeg',temp_img)\n        \n    \n    for background in train_data[img_id]['negative_example']:\n        x,y,w,h = background\n        label = 'background'\n        \n        temp_img = cv2.cvtColor(cv2.resize(img[y:y+h,x:x+w,:],(224,224)),cv2.COLOR_BGR2RGB)\n        \n        cv2.imwrite('Train\/'+label+'\/'+ label+'_'+ str(len(os.listdir('Train\/'+label))) + '.jpeg',temp_img)\n","82a9f759":"#For Testing\nfor count,img_id in tqdm(enumerate(test_images_list)):\n    img = cv2.imread(images_path + img_id)\n    \n    \n    for proposal in test_data[img_id]['region_proposal']:\n        x,y,w,h = proposal[0]\n        label   = proposal[1]\n         \n        temp_img = cv2.cvtColor(cv2.resize(img[y:y+h,x:x+w,:],(224,224)),cv2.COLOR_BGR2RGB)\n        \n        cv2.imwrite('Test\/'+label+'\/'+ label+'_'+ str(len(os.listdir('Test\/'+label))) +'.jpeg',temp_img)\n        \n    \n    for background in test_data[img_id]['negative_example']:\n        x,y,w,h = background\n        label = 'background'\n        \n        temp_img = cv2.cvtColor(cv2.resize(img[y:y+h,x:x+w,:],(224,224)),cv2.COLOR_BGR2RGB)\n        \n        cv2.imwrite('Test\/'+label+'\/'+ label+'_'+ str(len(os.listdir('Test\/'+label))) + '.jpeg',temp_img)\n","0b0c4003":"print('Total training weed images are {}'.format(len(os.listdir('Train\/weed'))))\nprint('Total training crop images are {}'.format(len(os.listdir('Train\/crop'))))\nprint('Total training background images are {}'.format(len(os.listdir('Train\/background'))))","780ead6f":"print('Total testing weed images are {}'.format(len(os.listdir('Test\/weed'))))\nprint('Total testing crop images are {}'.format(len(os.listdir('Test\/crop'))))\nprint('Total testing background images are {}'.format(len(os.listdir('Test\/background'))))","43048b6c":"plt.figure(figsize=(15,12))\nfor i,img in enumerate(os.listdir('Train\/background')[:16]):\n    plt.subplot(4,4,i+1)\n    plt.title('background')\n    img = cv2.imread('Train\/background\/'+img)\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis('off')\n\nplt.show()  ","ba898b65":"plt.figure(figsize=(15,12))\nfor i,img in enumerate(os.listdir('Train\/crop')[0:16]):\n    plt.subplot(4,4,i+1)\n    plt.title('crop')\n    img = cv2.imread('Train\/crop\/'+img)\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis('off')\n\nplt.show()","5e9a4c2e":"plt.figure(figsize=(15,12))\n\nfor i,img in enumerate(os.listdir('Train\/weed')[0:16]):\n    plt.subplot(4,4,i+1)\n    plt.title('weed')\n    img = cv2.imread('Train\/weed\/'+img)\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis('off')\nplt.show()    ","356eef1a":"# Creating folders","9f0e213b":"This kernal is part for training and implementation of RCNN object detection algorithm. \n\nWhole RCNN implementation code is in [Github](https:\/\/github.com\/ravirajsinh45\/implementation_of_RCNN)","1b67aaa9":"# Visualizing Images","00f363ca":"# Generating images"}}