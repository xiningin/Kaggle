{"cell_type":{"60b4e1b3":"code","5955ff62":"code","d32856b0":"code","e0464eb7":"code","162d53fa":"code","ada6df0d":"code","d51cade6":"code","71ca7c1f":"code","a32989b9":"code","47d6cf0c":"code","73c3147f":"code","79f7185d":"code","138b5a1e":"code","3e74a351":"code","416ee74e":"code","78c4b9d6":"code","28eaeaef":"code","5e753c1c":"code","f203d5f0":"markdown","9e5842fe":"markdown","583a3370":"markdown","cf3b5fea":"markdown"},"source":{"60b4e1b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom os import listdir\n\npaths=[]\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5955ff62":"!pip install Pillow","d32856b0":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import shuffle\n\nimport matplotlib.pyplot as plt\nimport time\n\nimport cv2      #open cv\n\n\nfrom PIL import Image \nfrom sklearn.preprocessing import OneHotEncoder ","e0464eb7":"def contour(image , plot = False):\n    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)                         #grayscaling the images\n    grayscale = cv2.GaussianBlur(grayscale, (5,5),0)                                 #blur the image to bring it under the threshold\n    threshold_image = cv2.threshold(grayscale, 50, 255, cv2.THRESH_BINARY)[1]   #convert these grayscaled images to binary images\n    threshold_image = cv2.erode(threshold_image, None, iterations=2)            #to remove the regions of noise\n    threshold_image = cv2.dilate(threshold_image, None, iterations=2)           #to remove all the noises around the image\n    \n    #Now we need to find the contour and clean it to get what is inside the image.\n    contour = cv2.findContours(threshold_image.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      \n    \n    #we grab the largest contour using the max.\n    contour = imutils.grab_contours(contour)\n    c = max(contour, key=cv2.contourArea)\n    \n    #Now we limit the image by finding it's extreme points.\n    ext_left = tuple(c[c[:,:,0].argmin()][0])\n    ext_right = tuple(c[c[:,:,0].argmax()][0])\n    ext_top = tuple(c[c[:,:,1].argmin()][0])\n    ext_bot = tuple(c[c[:,:,1].argmax()][0])\n    \n    processed_image = image[ext_top[1]:ext_bot[1],ext_left[0]:ext_right[0]]\n        \n    if plot:\n        plt.figure()\n        plt.subplot(1,2,1)\n        plt.imshow(image)\n        \n        plt.tick_params(axis=\"both\", which=\"both\",\n                       top= False, bottom= False,left= False,right= False,\n                        labeltop= False, labelbottom= False,\n                        labelleft= False,labelright= False)\n        plt.title(\"ORIGINAL\")\n        \n        \n        plt.subplot(1,2,2)\n        plt.imshow(processed_image)\n        \n        plt.tick_params(axis=\"both\", which=\"both\",\n                       top= False, bottom= False,left= False,right= False,\n                        labeltop= False, labelbottom= False,\n                        labelleft= False,labelright= False)\n        plt.title(\"PROCESSED\")\n        plt.show()\n        \n    return processed_image\n    ","162d53fa":"for path in paths:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    #img.save()\n    break\nimg","ada6df0d":"Image.open(paths[0])","d51cade6":"for path in paths:\n    img = cv2.imread(path)\n    img = contour(im, True)\n    \"\"\"plt.imsave(img,path)\"\"\"\n","71ca7c1f":"encoder = OneHotEncoder()\nencoder.fit([[0], [1]]) \n","a32989b9":"# This cell updates result list for images with tumor\n\ndata = []\npaths = []\nresult = []\n\nfor r, d, f in os.walk(r'..\/input\/brain-mri-images-for-brain-tumor-detection\/yes'):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r, file))\n\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[0]]).toarray())","47d6cf0c":"# This cell updates result list for images without tumor\n\npaths = []\nfor r, d, f in os.walk(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\"):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r, file))\n\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[1]]).toarray())","73c3147f":"data = np.array(data)\ndata.shape","79f7185d":"result = np.array(result)\nresult = result.reshape(139,2)","138b5a1e":"x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)","3e74a351":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\nmodel.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\nmodel.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss = \"categorical_crossentropy\", optimizer='Adamax')\nprint(model.summary())\n\nhistory = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))","416ee74e":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Test', 'Validation'], loc='upper right')\nplt.show()","78c4b9d6":"def names(cat):\n    if cat==0:\n        return 'Tumor detected'\n    else:\n        return 'No detected tumor'","28eaeaef":"from matplotlib.pyplot import imshow\nimg = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/N17.jpg\")\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres = model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))","5e753c1c":"from matplotlib.pyplot import imshow\nimg = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y3.jpg\")\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres = model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))","f203d5f0":"## Cropping image contour \nThis removes all the noises from the images making our data one step towards ready to be modelled. ","9e5842fe":"Train-test split","583a3370":"ENCODING TARGET VARIABLES WITH THE NOTION \n\n0 for image with Tumor\n\n1 for image without Tumor.","cf3b5fea":"vizualising the loss function"}}