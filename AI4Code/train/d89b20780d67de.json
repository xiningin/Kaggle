{"cell_type":{"4866f006":"code","80ed061e":"code","31786ce1":"code","c51fa6fa":"code","98d09d1f":"code","2d0b3df2":"code","a8f25850":"code","bb10b976":"code","09d239bd":"code","22e5a093":"markdown","75ed5b00":"markdown","7ae25e3a":"markdown","b76fdf76":"markdown","d38a6f21":"markdown","c5bc2220":"markdown"},"source":{"4866f006":"import keras\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom PIL import Image\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Activation, Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D, AveragePooling2D, Lambda,ZeroPadding2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\n","80ed061e":"parasitized = os.listdir('..\/input\/cell_images\/cell_images\/Parasitized\/') \nuninfected = os.listdir('..\/input\/cell_images\/cell_images\/Uninfected')\ndata = []\nlabels = []\n\nfor i in parasitized:\n    try:\n    \n        img = cv2.imread('..\/input\/cell_images\/cell_images\/Parasitized\/'+i)\n        img_array = Image.fromarray(img , 'RGB')\n        resize_img = img_array.resize((64 , 64))\n        data.append(np.array(resize_img))\n        #print(resize_img)\n        label = to_categorical(1, num_classes=2)\n        labels.append(label)\n        #print(label)\n        \n    except AttributeError:\n      pass\n        #print('')\nprint(len(data))\n\nfor i in uninfected:\n    \n    try:\n        img = cv2.imread('..\/input\/cell_images\/cell_images\/Uninfected\/'+i)\n        img_array = Image.fromarray(img , 'RGB')\n        resize_img = img_array.resize((64 , 64))\n        data.append(np.array(resize_img))\n        label = to_categorical(0, num_classes=2)\n        labels.append(label)\n        \n    except AttributeError:\n      pass\n        #print('')\n        \nprint(len(data))\n","31786ce1":"data = np.array(data)\nlabels = np.array(labels)\nprint(data.shape , labels.shape)","c51fa6fa":"n = np.arange(data.shape[0])\nnp.random.shuffle(n)\ndata = data[n]\nlabels = labels[n]\n\ndata = data.astype(np.float32)\nlabels = labels.astype(np.int32)\ndata = data\/255","98d09d1f":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n\nprint(x_train.shape, x_val.shape, x_test.shape)\nprint(y_train.shape, y_val.shape, y_test.shape)\n","2d0b3df2":"#create model\nmodel = Sequential()\n\n#add model layers\nmodel.add(Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1), input_shape=(64,64,3), activation='relu')) #128\nmodel.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n \nmodel.add(Conv2D(filters=64,kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n \nmodel.add(Conv2D(filters=128,kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n \nmodel.add(Conv2D(filters=128,kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n \nmodel.add(GlobalAveragePooling2D())\n \nmodel.add(Dense(1024,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(2,activation='softmax'))\n \nopt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\nmodel.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=4, batch_size = 32)\n\n","a8f25850":"model.summary()","bb10b976":"print(model.evaluate(x_test, y_test))","09d239bd":"from sklearn.metrics import confusion_matrix , classification_report , accuracy_score\n\npreds = model.predict(x_test)\npreds = np.argmax(preds, axis = -1)\norig = np.argmax(y_test, axis=-1)\n\nconf = confusion_matrix(orig, preds)\n\nfig, ax = plt.subplots(figsize = (7,7))\nax.matshow(conf, cmap='Pastel1')\n\nax.set_ylabel('True Values')\nax.set_xlabel('Predicted Values', labelpad = 10)\nax.xaxis.set_label_position('top') \n\nfor (i, j), z in np.ndenumerate(conf):\n    ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\nplt.show()\n","22e5a093":"# Preprocessing the Data\nWe are going to begin by **preprocessing the data.** The code below does the following: <br> \n1. Reads in the images from each of the folders (Parasitized and Uninfected)\n2. Converts the data (images) to uniform size 64x64 numpy arrays\n3. Creates labels (associated with the images) in the form of one hot vectors that represent the diagnosis \n\nAll the data is added to one list and all the labels are added to another list. We will soon split these lists into training, validation, and test sets. ","75ed5b00":"Here, we split the data into train, validation, and test sets. The train set will consist of 60% of the data and the validation and test sets will each consist of 20% of the data. ","7ae25e3a":"The code below evaluates the performance of the model on the test set. The accuracy typically ranges between 94-97% when the model is run multiple times. ","b76fdf76":"The following code shuffles the data + labels and normalizes the data. ","d38a6f21":"# Confusion Matrix\nWe will now plot a **confusion matrix**. This shows how many true positives, false positives, true negatives, and false negatives there are. ","c5bc2220":"# Creating the CNN Model\nNow, we can begin creating the model. Down below is the code for a 20 layer convolutional neural network (CNN). It uses binary cross entropy for its loss function and Adam as its optimizer."}}