{"cell_type":{"b72d84a8":"code","ec1d782b":"code","d9f22783":"code","8aafffa3":"code","71a98224":"code","4c0ac309":"code","6ecebc00":"code","b5ce1c13":"code","d722cc32":"code","1a2591be":"code","911c3aec":"code","d01ff7c9":"code","db9fa014":"code","7033e5e0":"code","0f58e3b5":"code","88398f28":"code","9d8ec2af":"code","864b09c2":"code","5c7a8458":"code","06573acd":"code","a20e0385":"code","0e5875d1":"code","8f10a2c8":"code","dde0291f":"code","7ffec12d":"code","fcd680c2":"code","f4fdd5bc":"code","d78decdf":"code","f2ec05ac":"markdown","e5750a61":"markdown","af36c95b":"markdown","e8c500c2":"markdown","08bee48e":"markdown","15e76fb1":"markdown","c1029cf4":"markdown","aa1aaea4":"markdown"},"source":{"b72d84a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\ndf = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv', encoding='ISO-8859-1')","ec1d782b":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression,PassiveAggressiveClassifier,RidgeClassifier,SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC,NuSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom time import perf_counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.display import Markdown, display\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","d9f22783":"from sklearn.preprocessing import LabelEncoder\ndef label_encoded(feat):\n    le = LabelEncoder()\n    le.fit(feat)\n    print(feat.name,le.classes_)\n#     print(le.classes_)\n    return le.transform(feat)","8aafffa3":"for col in df.columns:\n    df[str(col)] = label_encoded(df[str(col)])","71a98224":"df.head()\n","4c0ac309":"sns.heatmap(df.corr())","6ecebc00":"fig = plt.figure(figsize = (20,15))\nax = fig.gca()\ndf.hist(ax=ax)\nplt.show()","b5ce1c13":"# Change the names of the class to be more explicit\n# with \"edible\" and \"poisonous\"\ndf['class'] = df['class'].map({\"e\": \"edible\", \"p\": \"poisonous\"})\n# df.iloc[:5,:8]","d722cc32":"df.describe()\n","1a2591be":"df.shape","911c3aec":"df.isnull()","d01ff7c9":"df.isna().sum()","db9fa014":"df = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv', encoding='ISO-8859-1')\nimport seaborn as sns\nfigsize=(15,8)\n\nplt.title('cap Surface')\nsns.countplot(data = df, x='cap-surface',hue='class', order=df['cap-surface'].value_counts().index,)","7033e5e0":"plt.title('cap shape')\nsns.countplot(data = df, x='cap-shape',hue='class', order=df['cap-shape'].value_counts().index)","0f58e3b5":"plt.title('cap-color effect')\nsns.countplot(data = df, x='cap-color',hue='class', order=df['cap-color'].value_counts().index,)","88398f28":"from sklearn.preprocessing import LabelEncoder\n\nX = df.drop(\"class\", axis = 1).copy()\ny = df['class'].copy()\n\nlabel_encoder_data = X.copy()\nlabel_encoder = LabelEncoder()\nfor col in X.columns:\n    label_encoder_data[col] = label_encoder.fit_transform(label_encoder_data[col])\n    \nX = label_encoder_data","9d8ec2af":"# df.head()","864b09c2":"#Obtain total number of mushrooms for each 'cap-color' (Entire DataFrame)\ncap_colors = df['cap-color'].value_counts()\nm_height = cap_colors.values.tolist() #Provides numerical values\ncap_colors.axes #Provides row labels\ncap_color_labels = cap_colors.axes[0].tolist() #Converts index object to list\n\n#=====PLOT Preparations and Plotting====#\nind = np.arange(10)  # the x locations for the groups\nwidth = 0.7        # the width of the bars\ncolors = ['#DEB887','#778899','#DC143C','#FFFF99','#f8f8ff','#F0DC82','#FF69B4','#D22D1E','#C000C5','g']\n#FFFFF0\nfig, ax = plt.subplots(figsize=(10,7))\nmushroom_bars = ax.bar(ind, m_height , width, color=colors)\n\n#Add some text for labels, title and axes ticks\nax.set_xlabel(\"Cap Color\",fontsize=20)\nax.set_ylabel('Quantity',fontsize=20)\nax.set_title('Mushroom Cap Color Quantity',fontsize=22)\nax.set_xticks(ind) #Positioning on the x axis\nax.set_xticklabels(('brown', 'gray','red','yellow','white','buff','pink','cinnamon','purple','green'),\n                  fontsize = 12)\n\n#Auto-labels the number of mushrooms for each bar color.\ndef autolabel(rects,fontsize=14):\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()\/2., 1*height,'%d' % int(height),\n                ha='center', va='bottom',fontsize=fontsize)\nautolabel(mushroom_bars)        \nplt.show() #Display bars. ","5c7a8458":"df['class'].value_counts().plot.bar(figsize = (10,5), color = ['grey','red'])\nplt.xticks(rotation=0)\nplt.title('Quantity of each class in the dataset', fontsize = 15)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","06573acd":"#Obtain total number of mushrooms for each 'odor' (Entire DataFrame)\nodors = df['odor'].value_counts()\nodor_height = odors.values.tolist() #Provides numerical values\nodor_labels = odors.axes[0].tolist() #Converts index labels object to list\n\n#=====PLOT Preparations and Plotting====#\nwidth = 0.7 \nind = np.arange(9)  # the x locations for the groups\ncolors = ['#FFFF99','#ADFF2F','#00BFFF','#FA8072','#FFEBCD','#800000','#40E0D0','#808080','#2E8B57']\n\nfig, ax = plt.subplots(figsize=(10,7))\nodor_bars = ax.bar(ind, odor_height , width, color=colors)\n\n#Add some text for labels, title and axes ticks\nax.set_xlabel(\"Odor\",fontsize=20)\nax.set_ylabel('Quantity',fontsize=20)\nax.set_title('Mushroom Odor and Quantity',fontsize=22)\nax.set_xticks(ind) #Positioning on the x axis\nax.set_xticklabels(('none', 'foul','fishy','spicy','almond','anise','pungent','creosote','musty'),\n                  fontsize = 12)\nax.legend(odor_bars, ['none: no smell','foul: rotten eggs', 'fishy: fresh fish','spicy: pepper',\n                      'almond: nutlike kernel', 'anise: sweet herbal', 'pungent: vinegar',\n                     'creosote: smoky chimney', 'musty: mold mildew'],fontsize=17)\nautolabel(odor_bars)        \nplt.show() #Display bars. \n","a20e0385":"#Get the population types and its values for Single Pie chart\npopulations = df['population'].value_counts()\npop_size = populations.values.tolist() #Provides numerical values\npop_types = populations.axes[0].tolist() #Converts index labels object to list\nprint(pop_size)\n# Data to plot\npop_labels = 'Several', 'Solitary', 'Scattered', 'Numerous', 'Abundant', 'Clustered'\ncolors = ['#F38181','#EAFFD0','#95E1D3','#FCE38A','#BDE4F4','#9EF4E6']\nexplode = (0, 0.1, 0, 0, 0, 0)  # explode 1st slice\nfig = plt.figure(figsize=(12,8))\n# Plot\nplt.title('Mushroom Population Type Percentange', fontsize=22)\npatches, texts, autotexts = plt.pie(pop_size, explode=explode, labels=pop_labels, colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=150)\nfor text,autotext in zip(texts,autotexts):\n    text.set_fontsize(14)\n    autotext.set_fontsize(14)\n\nplt.axis('equal')\nplt.show()\n","0e5875d1":"#Get the habitat types and its values for a Single Pie chart\nhabitats = df['habitat'].value_counts()\nhab_size = habitats.values.tolist() #Provides numerical values\nhab_types = habitats.axes[0].tolist() #Converts index labels object to list\nprint(habitats)\n# Data to plot\nhab_labels = 'Woods', 'Grasses', 'Paths', 'Leaves', 'Urban', 'Meadows', 'Waste'\ncolors = ['#F5AD6F','#EAFFD0','#FFFF66','#84D9E2','#C0C0C0','#DE7E7E', '#FFB6C1']\nexplode = (0, 0, 0, 0, 0, 0,0.5)  # explode 1st slice\nfig = plt.figure(figsize=(12,8))\n# Plot\nplt.title('Mushroom Habitat Type Percentange', fontsize=22)\npatches, texts, autotexts = plt.pie(hab_size, explode=explode, labels=hab_labels, colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=360)\nfor text,autotext in zip(texts,autotexts):\n    text.set_fontsize(14)\n    autotext.set_fontsize(14)\n\nplt.axis('equal')\nplt.show()","8f10a2c8":"# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","dde0291f":"# Create a dictionary with the model which will be tested\nmodels = {\n    \"GaussianNB\":{\"model\":GaussianNB()},\n    \"PassiveAggressiveClassifier\":{\"model\":PassiveAggressiveClassifier() },\n    \"RidgeClassifier\":{\"model\":RidgeClassifier() },\n    \"SGDClassifier\":{\"model\":SGDClassifier() },\n    \"KNeighborsClassifier\":{\"model\":KNeighborsClassifier() },\n    \"DecisionTreeClassifier\":{\"model\":DecisionTreeClassifier() },\n    \"ExtraTreeClassifier\":{\"model\":ExtraTreeClassifier() },\n    \"LinearSVC\":{\"model\":LinearSVC() },\n    \"SVC\":{\"model\":SVC() },\n    \"NuSVC\":{\"model\":NuSVC() },\n    \"MLPClassifier\":{\"model\":MLPClassifier() },\n    \"RandomForestClassifier\":{\"model\":RandomForestClassifier() },\n    \"GradientBoostingClassifier\":{\"model\":GradientBoostingClassifier() },\n    \"AdaBoostClassifier\":{\"model\":AdaBoostClassifier() }\n}\n\n# Use the 10-fold cross validation for each model\n# to get the mean validation accuracy and the mean training time\nfor name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    # print(model)\n    result = cross_validate(model, X_train,y_train,cv = 10)\n    \n    # Mean accuracy and mean training time\n    mean_val_accuracy = round( sum(result['test_score']) \/ len(result['test_score']), 4)\n    mean_fit_time = round( sum(result['fit_time']) \/ len(result['fit_time']), 4)\n    \n    # Add the result to the dictionary witht he models\n    m['val_accuracy'] = mean_val_accuracy\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} accuracy : {mean_val_accuracy*100:.2f}% - mean training time {mean_fit_time} sec\")","7ffec12d":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    lst = [name, v['val_accuracy'],v['Training time (sec)']]\n    models_result.append(lst)\n\ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','val_accuracy','Training time (sec)'])\ndf_results.sort_values(by='val_accuracy', ascending=False, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","fcd680c2":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'val_accuracy', data = df_results)\nplt.title('Mean Validation Accuracy for each Model\\ny-axis between 0.8 and 1.0', fontsize = 15)\nplt.ylim(0.8,1.005)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Accuracy',fontsize=15)\nplt.xticks(rotation=90, fontsize=12)\nplt.show()","f4fdd5bc":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\nplt.title('Training time for each Model in sec', fontsize = 15)\nplt.xticks(rotation=90, fontsize=12)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Training time (sec)',fontsize=15)\nplt.show()","d78decdf":"# Get the model with the highest mean validation accuracy\nbest_model = df_results.iloc[0]\n\n# Fit the model\nmodel = models[best_model[0]]['model']\nmodel.fit(X_train,y_train)\n\n# Predict the labels with the data set\npred = model.predict(X_test)\n\n# Display the results\nprintmd(f'## Best Model: {best_model[0]} with {best_model[1]*100}% accuracy on the test set')\nprintmd(f'## Trained in: {best_model[2]} sec')\n\n# Display a confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (10,7))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)),cbar=False)\nplt.title('Normalized Confusion Matrix', fontsize = 23)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nplt.show()","f2ec05ac":"# 3. Model comparison using cross validation<a class=\"anchor\" id=\"3\"><\/a><a class=\"anchor\" id=\"3\"><\/a>","e5750a61":"# 1. Data Description <a class=\"anchor\" id=\"1\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","af36c95b":"\n\n\n\n\n# 2. Data Visualization<a class=\"anchor\" id=\"2\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","e8c500c2":"\n\n\n# 2. Data Preprocessing<a class=\"anchor\" id=\"2\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","08bee48e":"## **Krish Sukhani**\n## **TE IT**\n## **Batch D**\n## **59**\n","15e76fb1":"Mushroom Habitat\n","c1029cf4":"# 4. Prediction metrics of the best model using the test set<a class=\"anchor\" id=\"4\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","aa1aaea4":"Conclusion : Hence we compared the different models and hence  we get the output as the Decision tree classifier  to be the Best Classifier for this dataset"}}