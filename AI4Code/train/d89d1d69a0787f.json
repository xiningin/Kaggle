{"cell_type":{"9e244765":"code","9252ad01":"code","44f5ce4f":"code","cc96d8b5":"code","1f81c486":"code","5e82bb29":"code","f614b92e":"code","a4803dd8":"code","f37e6d9c":"code","9d14730e":"code","14185501":"code","69679c36":"code","2479b4cd":"code","a5fd52c5":"code","194965a0":"markdown","006b0a16":"markdown","08b90a9d":"markdown","7800d98d":"markdown","9a04d31f":"markdown","378e6139":"markdown","22b1250a":"markdown"},"source":{"9e244765":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9252ad01":"X_train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\nX_test = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nX_train.head()","44f5ce4f":"from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n","cc96d8b5":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vectorizer = CountVectorizer()\n\nexample_train_vectors = count_vectorizer.fit_transform(X_train[\"text\"][0:5])","1f81c486":"print(example_train_vectors[0].todense().shape)\nprint(example_train_vectors[0].todense())","5e82bb29":"train_vectors = count_vectorizer.fit_transform(X_train[\"text\"])\ntest_vectors = count_vectorizer.transform(X_test[\"text\"])\ny_train = X_train[\"target\"].copy()","f614b92e":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nclf = RandomForestClassifier()\ndistributions = dict(n_estimators=[200, 300, 400])\nrs = GridSearchCV(clf, distributions, cv=3)\nrs.fit(train_vectors, y_train)","a4803dd8":"rs.best_params_","f37e6d9c":"rs.cv_results_","9d14730e":"clf","14185501":"clf.fit(train_vectors, y_train)\nsample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","69679c36":"sample_submission[\"target\"] = clf.predict(test_vectors)","2479b4cd":"sample_submission.head()","a5fd52c5":"sample_submission.to_csv(\"submission.csv\", index=False)","194965a0":"# Disaster tweets with RandomForestClassifier\n<p>In this Notebook I try to get a better score on the Disaster tweets challenge by using a RandomForest<\/p>\n<p>I've completed this challenge with the tutorial before but I wanted to try to improve a bit. This includes trying to do some documentation like this. This is just to start a habit of making Notebooks pretty and public. Humble beginnings****<\/p>","006b0a16":"Saving the submission file: ","08b90a9d":"Testing out the count_vectorizer here:","7800d98d":"Checking out what the best parameters were and improve on what I look for with GridSearchCV. I hope I can find the sweet spot where the model is not overfitting yet. It turns out the sweet spot is around 300 estimators","9a04d31f":"Looking for the best Parameters on the RandomForestClassifier with GridSearchCV. The score just needs to be better than the linear model for now.","378e6139":"Creating the vectors I want to use to train the model. In the future I could add in the other features of the dataset aswell to improve the training set.","22b1250a":"This is the end of my first public Notebook. I hope, that I can get into the habit of doing these. Maybe with more graphs and dataviz. Though I doubt anyone but me ever reads this it has been a good excercise nontheless. I still think it's difficult to adapt what I've learned to situations, but with enough practice I will get there eventually."}}