{"cell_type":{"cae66804":"code","4d5ffb0d":"code","b1b43c61":"code","c318df77":"code","1f7e8efb":"code","9a392382":"code","25c558f6":"code","50de79eb":"code","0a0a9c85":"code","d131ef92":"code","50fad5f8":"code","cfaeb923":"code","76ffceab":"code","fd428012":"code","b52276a1":"code","e5c35125":"code","c1f06e70":"code","9e12b038":"code","930e3cf8":"markdown","6ffec44b":"markdown","6d954e7d":"markdown","3e35a126":"markdown","5fe7d298":"markdown","d0462a07":"markdown","49bdfcd4":"markdown","1ccdeb12":"markdown","e9bfb285":"markdown","e43c54c0":"markdown","b52ab2d2":"markdown"},"source":{"cae66804":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4d5ffb0d":"# import twitter data\ndata = pd.read_csv(\"..\/input\/gender-classifier-DFE-791531.csv\",encoding=\"latin1\")","b1b43c61":"data = pd.concat([data.gender,data.description],axis=1)\n\n#let's drop NaN values\ndata.dropna(axis=0,inplace=True)","c318df77":"data.head()","1f7e8efb":"data.shape","9a392382":"data.gender = [1 if each == \"female\" else 0 for each in data.gender]\ndata.head(10)","25c558f6":"data.description[4]","50de79eb":"# regular expression RE =>> \"[^a-zA-Z]\"\nimport re\n\nfirst_description = data.description[4]\ndescription = re.sub(\"[^a-zA-Z]\",\" \",first_description)\ndescription = description.lower() #Year year are different words\ndescription","0a0a9c85":"import nltk\nfrom nltk.corpus import stopwords\n#remove irrelavent words for e.g. and,the ...\n\n#description = description.split()\ndescription = nltk.word_tokenize(description)\n#if we use word_tokenize instead of split it will be better\n#split() = shouldn't => shouldn't\n#word_tokenize() = shouldn't => shouldn't and n't separate as two word\ndescription = [word for word in description if not word in set(stopwords.words(\"english\"))]\ndescription","d131ef92":"#Lemmatazation = loved => love\nimport nltk as nlp\n\nlemma = nlp.WordNetLemmatizer()\ndescription = [lemma.lemmatize(word) for word in description]\ndescription","50fad5f8":"description = \" \".join(description)\ndescription","cfaeb923":"description_list = []\nfor description in data.description:\n    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n    description = description.lower()\n    description = nltk.word_tokenize(description)\n    #description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n    lemma = nlp.WordNetLemmatizer()\n    description = [lemma.lemmatize(word) for word in description]\n    description = \" \".join(description)\n    description_list.append(description)\n    \n#description_list","76ffceab":"from sklearn.feature_extraction.text import CountVectorizer\n#we can define max_features \nmax_features = 1000\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\n#count_vectorizer = CountVectorizer(stop_words = \"english\")\n\nsparce_matrix = count_vectorizer.fit_transform(description_list).toarray() # x\n\nprint(\"{} most common words: {}\".format(max_features,count_vectorizer.get_feature_names()))","fd428012":"y = data.iloc[:,0].values   # male or female classes\nx = sparce_matrix\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)","b52276a1":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(x_train,y_train)\n\nprint(\"accuracy: \",nb.score(x_test,y_test))\n","e5c35125":"y_pred = nb.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_nb = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm_nb,annot=True,cmap=\"RdPu\",fmt=\".0f\",cbar=False)\nplt.show()","c1f06e70":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 100)\n\nrf.fit(x_train,y_train)\n\nprint(\"accuracy: \",rf.score(x_test,y_test))","9e12b038":"y_pred = rf.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_rf = confusion_matrix(y_true,y_pred)\n\nsns.heatmap(cm_rf,annot=True,cmap=\"RdPu\",fmt=\".0f\",cbar=False)\nplt.show()","930e3cf8":"### Lemmatazation","6ffec44b":"# Conclusion<br><br>\n**If you like it, Please upvote my kernel.**<br>\n**If you have any question, I will happy to hear it.**","6d954e7d":"### Apply Naive Bayes Machine Learning Algorithm","3e35a126":"# INTRODUCTION<br><br>\n**In this kernel, we will see Natural Language Processing(NLP).**","5fe7d298":"### Regular Expression","d0462a07":"### Bag of Words","49bdfcd4":"### Apply to All Description","1ccdeb12":"### Import Data ","e9bfb285":"### Stopwords","e43c54c0":"### Apply Random Forest Machine Learning Algorithm","b52ab2d2":"### Train and Test Split"}}