{"cell_type":{"601efba9":"code","e782a214":"code","cc6d7d29":"code","7a0ec1f7":"code","e65079cc":"code","3e3bf7a8":"code","372a6249":"code","31542d71":"code","23d74bc9":"code","926e584f":"code","60ef0721":"code","2d0623ff":"code","edd64524":"code","f259314c":"code","6aef7d9e":"markdown","3b5c99d5":"markdown","b6de383e":"markdown","87ad1a9d":"markdown","b1b6a0f1":"markdown","9ffdf1a8":"markdown","93509e98":"markdown"},"source":{"601efba9":"import os \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image","e782a214":"len(os.listdir(\"..\/input\/simpsons-faces\/cropped\")) # We have 9877 Images","cc6d7d29":"sample = image.load_img(\"..\/input\/simpsons-faces\/cropped\/1.png\")\nplt.imshow(sample)\nplt.title(\"Sample Image\")\nplt.axis('off')\nplt.show()","7a0ec1f7":"# Reading all the data\nX_train = []\nimg_dir = \"..\/input\/simpsons-faces\/cropped\"\nfor img_path in os.listdir(img_dir):\n    \n    img = image.load_img(os.path.join(img_dir, img_path))\n    img = (image.img_to_array(img, dtype='float32') - 127.5)\/127.5\n    X_train.append(img)\n    \nX_train = np.array(X_train)","e65079cc":"print(X_train.shape)","3e3bf7a8":"# Visualizing an example\nplt.imshow(X_train[1])\nplt.title(\"Image\")\nplt.axis('off')\nplt.show()","372a6249":"TOTAL_EPOCHS = 300\nBATCH_SIZE = 256\n\n# This number of batches will pass through the discriminator in 1 epoch\nNO_OF_BATCHES = int(X_train.shape[0]\/BATCH_SIZE)\n\n# Discriminator requires half fake and half real samples\nHALF_BATCH = int(BATCH_SIZE\/2)\n\n# Dimension of the RANDOM NOISE VECTOR\nNOISE_DIM = 100\n\n# Optimizer\n# adam = Adam(learning_rate=2e-4, beta_1=0.5)\nfrom keras.optimizers import Adam\nadam = Adam(learning_rate=2e-4,beta_1=0.5)","31542d71":"from keras.layers import *\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model","23d74bc9":"generator = Sequential()\n\n# upsampling of noise\ngenerator.add(Dense(25*25*128, input_shape=(NOISE_DIM,)))\n\ngenerator.add(Reshape((25,25,128)))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double Activation Size :: Upsampling ( 50 X 50 X 64 )\n# strides is required as it leads to mapping\n# Stride of 2 implies double the spatial arrangement\n# i.e (25, 25) ---> (50, 50)\n\ngenerator.add(Conv2DTranspose(64, kernel_size=(5,5), strides=(2,2), padding='same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# i.e (50 X 50 X 64) ---> (100 X 100 X 32)\ngenerator.add(Conv2DTranspose(32, kernel_size=(5,5), strides=(2,2), padding='same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double Activation Size :: Upsampling ( 200 X 200 X 3 )\ngenerator.add(Conv2DTranspose(3, kernel_size=(5,5), padding='same', strides=(2,2), activation='tanh'))\n\ngenerator.compile(loss='binary_crossentropy', optimizer=adam)\ngenerator.summary()","926e584f":"discriminator = Sequential()\n\n# INPUT : 200 X 200 X 3\ndiscriminator.add(Conv2D(32, (5,5), strides=(2,2), padding='same', input_shape=(200, 200, 3)))\ndiscriminator.add(LeakyReLU(0.2))\n\n# 100 X 100 X 32 ---> 50 X 50 X 64\ndiscriminator.add(Conv2D(64, (5,5), strides=(2,2), padding='same'))\ndiscriminator.add(LeakyReLU(0.2))\n\n# 50 X 50 X 64 ---> 25 X 25 X 128\ndiscriminator.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\ndiscriminator.add(LeakyReLU(0.2))\n\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(8192))\ndiscriminator.add(LeakyReLU(0.2))\n\ndiscriminator.add(Dense(1, activation='sigmoid'))\ndiscriminator.compile(loss='binary_crossentropy', optimizer=adam)\n\ndiscriminator.summary()","60ef0721":"# Freezing D and training G\n\ndiscriminator.trainable = False\n\ngan_input = Input(shape=(NOISE_DIM,))\ngenerated_img = generator(gan_input)\ngan_output = discriminator(generated_img)\n\n# Combining the Model :: Functional API\nmodel = Model(gan_input, gan_output)\nmodel.compile(loss='binary_crossentropy', optimizer=adam)\n","2d0623ff":"def save_imgs(epoch, samples=100):\n\n    noise = np.random.normal(0,1, size=(samples, NOISE_DIM))\n    generated_imgs = generator.predict(noise)\n    \n    # Reshaping the output\n    generated_imgs = generated_imgs.reshape(samples, 200, 200, 3)\n\n    plt.figure(figsize=(10, 10))\n\n    for i in range(samples):\n\n        plt.subplot(10, 10, i+1)\n        plt.imshow(generated_imgs[i], interpolation='nearest')\n        plt.axis(\"off\")\n        plt.tight_layout()\n\n    plt.show()","edd64524":"d_loss_list = []\ng_loss_list = []\n\nfor epoch in range(TOTAL_EPOCHS):\n\n    epoch_d_loss = 0.0\n    epoch_g_loss = 0.0\n\n    # mini-batch SGD\n\n    for step in range(NO_OF_BATCHES):\n\n        # Step-1 : Training Discriminator keeping Generator as Frozen\n        # 50% real data + 50% fake data\n\n        # Real Data\n        idx = np.random.randint(0, X_train.shape[0], HALF_BATCH)\n        real_imgs = X_train[idx]\n\n        # Fake Data ( for HALF_BATCH number of examples )\n        noise = np.random.normal(0,1,size=(HALF_BATCH, NOISE_DIM))\n        fake_imgs = generator.predict(noise)\n\n        # Labels\n        real_y = np.ones((HALF_BATCH, 1))*0.9 # One Side Label Smoothing for discriminator\n        fake_y = np.zeros((HALF_BATCH, 1))\n\n        # Training our discriminator\n        d_loss_real = discriminator.train_on_batch(real_imgs, real_y)\n        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_y)\n\n        # loss for the current batch\n        d_loss = 0.5*d_loss_real + 0.5*d_loss_fake\n\n        # This will get added in total_loss for the epoch\n        epoch_d_loss += d_loss\n\n\n        # Step-2 : Training Generator keeping Discriminator as Frozen\n\n        noise = np.random.normal(0, 1, size=(BATCH_SIZE, NOISE_DIM))\n\n        # All the fake images are treated as real\n        ground_truth_y = np.ones((BATCH_SIZE,1))\n\n        g_loss = model.train_on_batch(noise, ground_truth_y)\n\n        epoch_g_loss += g_loss\n\n    print(\"Epoch %d Discriminator Loss %.4f Generator Loss %.4f\"%((epoch+1), epoch_d_loss\/NO_OF_BATCHES, epoch_g_loss\/NO_OF_BATCHES))\n\n    d_loss_list.append(epoch_d_loss\/NO_OF_BATCHES)\n    g_loss_list.append(epoch_g_loss\/NO_OF_BATCHES)\n\n    if( epoch + 1) % 25 == 0:\n        \n        save_imgs(epoch + 1)","f259314c":"generator.save('model\/gan_generator_final.h5')","6aef7d9e":"## Training GAN\n- Step-1 is performed on the generator only\n\n- Step-2 is performed on model ( which includes both generator and discriminator [FROZEN] )","3b5c99d5":"## Generator\n- Using TRANSPOSE CONVOLUTION\n- We will use Conv2DTranspose() layer\n- This layer also increases the channels as well as performs upsampling","b6de383e":"## Some constants ","87ad1a9d":"## Discriminator","b1b6a0f1":"## Combining to Make a GAN","9ffdf1a8":"## Data Prep","93509e98":"## GAN MODEL"}}