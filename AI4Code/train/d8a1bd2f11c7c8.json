{"cell_type":{"a4fd76f5":"code","cbe049c5":"code","a4f83b98":"code","016abfc1":"code","fb9e533c":"code","b12851ec":"code","d4b5066e":"code","b17a36c3":"code","ec627ed7":"code","5910200c":"code","2a00caa9":"code","acd28f68":"code","cd864f29":"code","40c60504":"code","d5b603fe":"code","2addb3d6":"code","a9ec86a3":"code","9e012981":"code","40a0d55a":"code","77754f52":"code","9db41cb2":"code","25b47493":"code","5cec7300":"code","d3bb2e1f":"code","954c0921":"code","ad38eee2":"code","9964d580":"code","cc81e3b0":"code","3934e938":"code","5cbe375e":"code","3313f6c4":"code","d31023de":"code","d27b4e58":"code","54368899":"code","5cea95ae":"code","d9179a52":"code","3750094a":"code","9e55d90b":"markdown","0b031139":"markdown"},"source":{"a4fd76f5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\nimport matplotlib.patches as patches\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nimport json\nimport tensorflow\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom sklearn.model_selection import train_test_split\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, BatchNormalization\n# from tensorflow.keras.layers import Activation, MaxPooling2D\n# from tensorflow.keras.layers import Conv2D, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import load_model, Model\nfrom PIL import Image\nfrom mtcnn.mtcnn import MTCNN","cbe049c5":"images=os.path.join(\"\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\")\n# print(len(os.listdir(images)))\nannotations = os.path.join(\"\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/annotations\")","a4f83b98":"a=os.listdir(images)\nb=os.listdir(annotations)\na.sort()\nb.sort()\n# print(a[1698:1708])\n# print(b[:10])","016abfc1":"test_images=a[:1698]\ntrain_images=a[1698:]\ntrain_ann=b\nlen(train_images)==len(train_ann)","fb9e533c":"ann_path = \"\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/annotations\/\"\njdata = json.load(open(ann_path+train_ann[1860]))\nanns = jdata[\"Annotations\"]\n# bb = anns[0]['BoundingBox']\nbb = get_boxes('1861.jpg')\nimgpath = \"\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\/1861.jpg\"\nim = cv2.imread(imgpath)\nfig,ax = plt.subplots(1)\nax.imshow(im)\nprint(bb)\nfor box in bb:\n    print(box)\n    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n    ax.add_patch(rect)\nplt.show()","b12851ec":"%matplotlib inline\nimg=plt.imread(os.path.join(images,train_images[0]))\nplt.imshow(img)\nplt.show()","d4b5066e":"train_csv=pd.read_csv(os.path.join(\"\/kaggle\/input\/face-mask-detection-dataset\/train.csv\"))\nsubmission=pd.read_csv(os.path.join(\"\/kaggle\/input\/face-mask-detection-dataset\/submission.csv\"))","b17a36c3":"df = train_csv\nbbox=[]\nfor i in range(len(train_csv)):\n    arr=[]\n    for j in df.iloc[i][[\"x1\",'x2','y1','y2']]:\n        arr.append(j)\n    bbox.append(arr)","ec627ed7":"df[\"bbox\"]=bbox\n# df.head()","5910200c":"def get_boxes(id):\n    boxes=[]\n    for i in df[df[\"name\"]==str(id)][\"bbox\"]:\n        boxes.append(i)\n    return boxes\n# print(get_boxes('1810.jpg'))","2a00caa9":"image=train_images[11]\n\nimg=plt.imread(os.path.join(images,image))\n\nfig,ax = plt.subplots(1)\nax.imshow(img)\nboxes=get_boxes(image)\nfor box in boxes:\n    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n    ax.add_patch(rect)\nplt.show()","acd28f68":"df[df[\"name\"]==train_images[11]]","cd864f29":"path = \"\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\/\"\ntrain_features = []\ntrain_labels = []\nimg_size = 128\n\nfor image_name in range(3550):\n    img = cv2.imread(path + train_images[image_name])\n    boxes = get_boxes(train_images[image_name])\n    for idx, bb in enumerate(boxes):\n        x,y,w,h = bb\n        label = list(df[df[\"name\"]==train_images[image_name]][\"classname\"])\n        #if label[idx] == \"face_no_mask\" or label[idx] == \"face_with_mask\":\n        roi = img[y:h, x:w]\n        try:\n            roi = cv2.resize(roi, (img_size, img_size), cv2.INTER_AREA)\n            train_features.append(roi)\n            train_labels.append(label[idx])\n        except Exception as e:\n            print(\"[ERROR]\")","40c60504":"X = np.array(train_features, dtype=\"float32\")\nX \/= 255.0\ny = np.array(train_labels)","d5b603fe":"X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 3)","2addb3d6":"classes = [\"hijab_niqab\", \"mask_colorful\", \"mask_surgical\", \"face_no_mask\",\n          \"face_with_mask_incorrect\", \"face_with_mask\", \"face_other_covering\",\n          \"scarf_bandana\", \"balaclava_ski_mask\", \"face_shield\", \"gas_mask\",\n          \"turban\", \"helmet\", \"sunglasses\", \"eyeglasses\", \"hair_net\", \"hat\",\n          \"goggles\", \"hood\", \"other\"]","a9ec86a3":"le = LabelEncoder()\nle.fit(y)\ny = le.transform(y)\ny = to_categorical(y, num_classes=len(classes))","9e012981":"# X, y = shuffle(X, y, random_state=2)\n# import pickle\n# with open(\"X.pickle\",\"wb\") as f1:\n#     pickle.dump(X, f1)\n# with open(\"y.pickle\",\"wb\") as f2:\n#     pickle.dump(y, f2)","40a0d55a":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.12, random_state=42)","77754f52":"# MY CUSTOM littleVGG\n# img_size = 128\n\n# model = Sequential()\n# #1st layer\n# model.add(Conv2D(64,kernel_size=(3,3),padding=\"same\",input_shape=(img_size,img_size,)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# #2nd layer\n# model.add(Conv2D(64,kernel_size=(3,3)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.2))\n# #3rd layer\n# model.add(Conv2D(128,kernel_size=(3,3),padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# #4th layer\n# model.add(Conv2D(128,kernel_size=(3,3)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.2))\n# #5th layer\n# model.add(Conv2D(256,kernel_size=(3,3),padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# #6th layer\n# model.add(Conv2D(256,kernel_size=(3,3)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.2))\n\n# model.add(Flatten())\n# #7th layer\n# model.add(Dense(256))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# #8th layer\n# model.add(Dense(256))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# #9th layer\n# model.add(Dense(len(classes)))\n# model.add(Activation(\"softmax\"))","9db41cb2":"img_size = 128\n\nvgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\nfor layer in vgg.layers:\n    layer.trainable = False\ntop = vgg.output\ntop = GlobalAveragePooling2D()(top)\ntop = Dense(units=256, activation=\"relu\")(top)\ntop = Dense(units=128, activation=\"relu\")(top)\ntop = Dense(units=len(classes), activation=\"softmax\")(top)\n\nmodel = Model(inputs=vgg.input, outputs=top)\nprint(model.summary())","25b47493":"optimizer = Adam(lr=0.001)","5cec7300":"checkpoint = ModelCheckpoint('face_mask.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\nreduceLR = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,verbose=1,min_delta=0.0001)\n\ncallbacks = [checkpoint, reduceLR]","d3bb2e1f":"model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","954c0921":"hist = model.fit(x_train, y_train, batch_size=64, epochs=45, \n                 validation_data=(x_test, y_test), verbose=1,\n                callbacks=callbacks)","ad38eee2":"# model.save('face_mask_last.h5')\n# import pickle\n# pickle_in1 = open('X.pickle', \"rb\")\n# X = pickle.load(pickle_in1)\n# pickle_in2 = open('y.pickle', \"rb\")\n# y = pickle.load(pickle_in2)","9964d580":"model = load_model('face_mask.h5')","cc81e3b0":"# score = model.evaluate(x_test, y_test)\n# score\n# accuracy = 80.93% on 10 epochs","3934e938":"sub = \"\/kaggle\/input\/face-mask-detection-dataset\/submission.csv\"\nsubdf = pd.read_csv(sub)\nsubmission_images = list(subdf[\"name\"])\n# FILE NAMES IS INCORRECT,SHOULD BE JPEG BUT ITS JPE","5cbe375e":"path = \"\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\/\"\n\npredicted_classes = []\ncoordinates = []\nimage_names = []\n\ndetector = MTCNN()\n\nfor img_name in submission_images:\n    first = img_name.split(\".\")[0]\n    last = img_name.split(\".\")[1]\n    if last == \"jpe\":\n        img_name = first+\".\"+\"jpeg\"\n    im = cv2.imread(path+img_name)\n    color = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = np.asarray(color)\n    faces = detector.detect_faces(im)\n    for i in range(len(faces)):\n        x,y,w,h = faces[i]['box']\n        x, y = abs(x), abs(y)\n        roi = color[y:y+h, x:x+w]\n        roi = cv2.resize(roi, (128,128), cv2.INTER_AREA)\n        roi = np.array(roi).astype('float32')\n        roi = roi.reshape(1, 128, 128, 3)\n        preds = model.predict(roi)\n        pred = np.argmax(preds, axis=1)\n        predicted_classes.append(classes[int(pred)])\n        coordinates.append([x,y,w,h])\n        image_names.append(img_name)","3313f6c4":"print(\"Total size:\", len(predicted_classes))\nprint(\"Image name:\", image_names[6])\nprint(\"coordinates:\", coordinates[6])\nprint(\"predicted class:\", predicted_classes[6])","d31023de":"df_names = pd.DataFrame(image_names, columns=[\"name\"])\ndf_coord = pd.DataFrame(coordinates, columns=['x1','x2','y1','y2'], dtype=float)\ndf_class = pd.DataFrame(predicted_classes, columns=[\"classname\"])","d27b4e58":"dataframes = [df_names, df_coord, df_class]\nresult = pd.concat(dataframes, axis=1)","54368899":"result.to_csv(r'final_submission.csv')","5cea95ae":"from IPython.display import FileLink\nFileLink(r'final_submission.csv')","d9179a52":"result.head(n=20)","3750094a":"subdf.head(n=20)","9e55d90b":"# PreProcessing for training process","0b031139":"# Testing "}}