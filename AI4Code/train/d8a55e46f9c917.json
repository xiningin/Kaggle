{"cell_type":{"d9b28248":"code","6ee16f22":"code","2d782f1e":"code","8f3b6578":"code","9818598f":"code","143c9105":"code","7e00a07d":"code","1bd2d807":"code","0a344dae":"code","34bf5c94":"code","2cf2090f":"code","3845790a":"code","c953a881":"code","4cb62347":"code","7f1eeb5c":"code","d3b8ab6b":"code","ede26652":"code","d0092d39":"code","394b2247":"code","f23f2435":"code","be7403b6":"code","f7531027":"code","0c474084":"code","207f5cff":"code","b3ed851c":"markdown","5e58779b":"markdown","d6873cf2":"markdown","6b674252":"markdown","047e0f35":"markdown","fd9cab05":"markdown","70ad81da":"markdown","73d82a0b":"markdown","3ddb198a":"markdown","6b97eeda":"markdown","71e84cdf":"markdown","6c7c190c":"markdown","3a1ac203":"markdown","a73de00a":"markdown","860e83be":"markdown","9e65d2a2":"markdown","c841b687":"markdown","65503202":"markdown","ce6b3d4d":"markdown","4e3730fa":"markdown","48dd050e":"markdown","c355459a":"markdown","18fe68d4":"markdown","c15de7ae":"markdown"},"source":{"d9b28248":"import numpy as np\nimport pandas as pd\nimport scipy.stats as st\nimport statsmodels as sm\nimport warnings\n# Matplotlib e Seaborn\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"white\", palette=\"muted\", color_codes=True)\n# Plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\nimport plotly.express as px\ninit_notebook_mode()\n\n#All stat packages\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt, SARIMAX\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.arima_model import ARMA, ARIMA\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n","6ee16f22":"def read_data():\n    train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\n    test = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\n    sub = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\n    return train,test,sub","2d782f1e":"%%time\ntrain_df,test_df,sub_df = read_data()","8f3b6578":"print('train set shape:', train_df.shape)\nprint('test set shape:', test_df.shape)","9818598f":"train_df.head()","143c9105":"test_df.head()","7e00a07d":"sub_df.head()","1bd2d807":"train_df.describe()","0a344dae":"plt.figure(figsize=(12,5))\nplt.title(\"Distribution of num_sold - for each store,  and product\")\nax = sns.distplot(train_df['num_sold'])","34bf5c94":"print(\"p-value for sales distribution: {}\".format(st.normaltest(train_df.num_sold.values)[1]))\nplt.figure(figsize=(12,5))\nplt.title(\"Distribution of sales vs best fit normal distribution\")\nax = sns.distplot(train_df.num_sold, fit= st.norm, kde=True, color='g')","2cf2090f":"# Code (function) adapted from https:\/\/stackoverflow.com\/questions\/6620471\/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python\ndef best_fit_distribution(data, bins= 200):\n    \"\"\"Model data by finding best fit distribution to data\"\"\"\n    y, x = np.histogram(data, bins=bins, density=True)\n    x = (x + np.roll(x, -1))[:-1] \/ 2.0\n\n    DISTRIBUTIONS = [        \n        st.alpha,st.beta,st.chi,st.chi2, st.dgamma,st.dweibull,st.erlang,st.exponweib,\n        st.f, st.genexpon,st.gausshyper,st.gamma, st.johnsonsb,st.johnsonsu, st.norm,\n        st.rayleigh,st.rice,st.recipinvgauss, st.t, st.weibull_min,st.weibull_max\n    ]\n\n    best_distribution = st.norm\n    best_params = (0.0, 1.0)\n    best_sse = np.inf\n\n    for distribution in DISTRIBUTIONS:\n        #print(\"Testing \" + str(distribution))\n\n        # Try to fit the distribution\n        #try:\n        # Ignore warnings from data that can't be fit\n        with warnings.catch_warnings():\n            warnings.filterwarnings('ignore')\n\n            # fit dist to data\n            params = distribution.fit(data)\n\n            # Separate parts of parameters\n            arg = params[:-2]\n            loc = params[-2]\n            scale = params[-1]\n\n            # Calculate fitted PDF and error with fit in distribution\n            pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n            sse = np.sum(np.power(y - pdf, 2.0))\n\n            # identify if this distribution is better\n            if best_sse > sse > 0:\n                best_distribution = distribution\n                best_params = params\n                best_sse = sse\n        #except Exception:\n        #    pass\n\n    return (best_distribution.name, best_params)\n\ndist_name, best_params = best_fit_distribution(train_df.num_sold.values)\nprint(\"Best distribution found: {}, with parameters: {}\".format(dist_name, best_params))","3845790a":"plt.figure(figsize=(12,5))\nplt.title(\"Distribution of sales vs Johnson-SB distribution (best fit)\")\nax = sns.distplot(train_df.num_sold, fit= st.johnsonsb, kde=True, color='g')","c953a881":"store_total = train_df.groupby(['store'])['num_sold'].sum().to_frame().reset_index()\nstore_total.sort_values(by = ['num_sold'], ascending=True, inplace=True)\nlabels = ['Store {}'.format(i) for i in store_total.store]\n\ntrace = go.Bar(\n    y= store_total.num_sold, x= labels,\n    marker=dict(color='rgba(255, 65, 54, 0.6)', line=dict(color='rgba(255, 65, 54, 1.0)', width=1)),\n    name='Total sales per store', orientation='v'\n)\n\nlayout = go.Layout(autosize=True, title= 'Total sales by store')\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","4cb62347":"store_total = train_df.groupby(['country'])['num_sold'].sum().to_frame().reset_index()\nstore_total.sort_values(by = ['num_sold'], ascending=True, inplace=True)\nlabels = ['Country {}'.format(i) for i in store_total.country]\n\ntrace = go.Bar(\n    y= store_total.num_sold, x= labels,\n    marker=dict(color='rgba(255, 65, 54, 0.6)', line=dict(color='rgba(255, 65, 54, 1.0)', width=1)),\n    name='Total sales per country', orientation='v'\n)\n\nlayout = go.Layout(autosize=True, title= 'Total sales by country')\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","7f1eeb5c":"train_df['key'] = train_df['country']+'_'+ train_df['store']+'_'+train_df['product']\nstore_total = train_df.groupby(['key'])['num_sold'].sum().to_frame().reset_index()\nstore_total.sort_values(by = ['num_sold'], ascending=True, inplace=True)\nlabels = ['Key {}'.format(i) for i in store_total.key]\n\ntrace = go.Bar(\n    y= store_total.num_sold, x= labels,\n    marker=dict(color='rgba(255, 65, 54, 0.6)', line=dict(color='rgba(255, 65, 54, 1.0)', width=1)),\n    name='Total sales per country\/store\/product', orientation='v'\n)\n\nlayout = go.Layout(autosize=True, title= 'Total sales by country\/store\/product')\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","d3b8ab6b":"store_sum = train_df.groupby(['store', 'date'])['num_sold'].sum().reset_index()\ntraces = []\nfor i, col in enumerate((store_sum['store'].unique())):\n    s = store_sum[store_sum['store'] == col]\n    trace = go.Box(y= s.num_sold, name= 'Store {}'.format(col), \n                   jitter=0.8, whiskerwidth=0.2,\n                   marker=dict(size=2), line=dict(width=1))\n    traces.append(trace)\n\nlayout = go.Layout(\n    title='Sales BoxPlot for each store',\n    yaxis=dict(\n        autorange=True, showgrid=True, zeroline=True,\n        gridcolor='rgb(233,233,233)', zerolinecolor='rgb(255, 255, 255)',\n        zerolinewidth=2, gridwidth=1\n    ),\n    margin=dict(l=40, r=30, b=80, t=100), showlegend=False,\n)\n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","ede26652":"data = []\nfor i, col in enumerate((store_sum['store'].unique())):\n    s = store_sum[store_sum['store'] == col]\n    trace = go.Scatter(\n        x= s.date,\n        y= s.num_sold,\n        name = \"Store \"+str(col),\n        opacity = 0.9)\n    data.append(trace)\n\n# Buttons to select a specific store visualization\nupdate_buttons = []\nfor i, col in enumerate((store_sum['store'].unique())):\n    visible = [True if j == i else False for j in range(store_sum['store'].nunique())]\n    button= dict(label = 'Store ' + str(col), method= 'update', args= [{'visible': visible}])\n    update_buttons.append(button)\n# Button to return to all stores visualization\nupdate_buttons.append(dict(label = 'All', method= 'update', args= [{'visible': [True]*10}]))\n\nupdatemenus = list([dict(active=-1, buttons=list(update_buttons))])\n\nlayout = dict(\n    title='Sales by store and time',\n    updatemenus= updatemenus,\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(count=12, label='12m', step='month', stepmode='backward'),\n                dict(count=24, label='24m', step='month', stepmode='backward'),\n                dict(count=36, label='36m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(), type='date'\n    )\n)\n\nfig = dict(data=data, layout=layout)\niplot(fig, validate= False)","d0092d39":"data = []\nfor i, col in enumerate((train_df['key'].unique())):\n    s = train_df[train_df['key'] == col]\n    trace = go.Scatter(\n        x= s.date,\n        y= s.num_sold,\n        name = \"Key \"+str(col),\n        opacity = 0.9)\n    data.append(trace)\n\n# Buttons to select a specific store visualization\nupdate_buttons = []\nfor i, col in enumerate((train_df['key'].unique())):\n    visible = [True if j == i else False for j in range(train_df['key'].nunique())]\n    button= dict(label = 'Key ' + str(col), method= 'update', args= [{'visible': visible}])\n    update_buttons.append(button)\n# Button to return to all stores visualization\nupdate_buttons.append(dict(label = 'All', method= 'update', args= [{'visible': [True]*10}]))\n\nupdatemenus = list([dict(active=-1, buttons=list(update_buttons))])\n\nlayout = dict(\n    title='Sales by Key i.e, Country, Store and Product combination with time',\n    updatemenus= updatemenus,\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(count=12, label='12m', step='month', stepmode='backward'),\n                dict(count=24, label='24m', step='month', stepmode='backward'),\n                dict(count=36, label='36m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(), type='date'\n    )\n)\nfig = dict(data=data, layout=layout)\niplot(fig, validate= False)","394b2247":"train_df['key'].unique()","f23f2435":"# let us visualize for only one store-country-product ie., timeseries ID\nsamp_df = train_df[train_df['key'] == 'Finland_KaggleMart_Kaggle Mug'][['date', 'num_sold']].reset_index(drop=True).set_index('date')\n\ndftest = adfuller(samp_df.num_sold)\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\ndfoutput","be7403b6":"fig = px.line(samp_df,  y='num_sold', title='Target variable ')\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=3, label=\"3y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.update_layout(width=800, height=600)\nfig.show()","f7531027":"import statsmodels.api as sm\n\nresult = sm.tsa.seasonal_decompose(samp_df['num_sold'], period=12)\ntrend = result.trend\nseasonal = result.seasonal\ndf_decomposed = pd.concat([trend, seasonal], axis = 1)\ndf_decomposed.columns = ['trend', 'seasonal']\nfig = px.line(df_decomposed)\nfig.update_layout(margin={'t': 40, 'b': 100, 'l': 50, 'r': 80},\n       width=800, height=600)\nfig.show()","0c474084":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(45,35))\nplot_acf(samp_df['num_sold'],lags=25)\nplt.show()","207f5cff":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(45,35))\nplot_pacf(samp_df['num_sold'],lags=25)\nplt.show()","b3ed851c":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">4.1. Stationarity test by Key i.e., Store\/Country\/Product and Time (Dickey Fuller) <\/span>","5e58779b":"![image.png](attachment:c661cb8c-a368-4eb7-9f10-0deaa0a08506.png)","d6873cf2":"### *Submissions are evaluated on SMAPE between forecasts and actual values. We define SMAPE = 0 when the actual and predicted values are both 0.*","6b674252":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">3.4. Sales by Box plot <\/span>","047e0f35":"We reject the null hypothesis if the value of the Test Statistic is less than the Critical Value at a significance level (1% or 5% or 10%). In this case it is (for all levels) and hence we CANNOT reject the null hypothesis and conclude that the series is NOT stationary\n","fd9cab05":"## References","70ad81da":"# <span class=\"title-section w3-xxlarge\" style=\"color:#FF00FF\" id=\"codebook\">1.Load Packages <\/span>","73d82a0b":"# <span class=\"title-section w3-xxlarge\" style=\"color:#FF00FF\" id=\"codebook\">3.EDA <\/span>","3ddb198a":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">3.6. Sales by Key i.e., Store\/Country\/Product and Time <\/span>","6b97eeda":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">3.2. Sales per country - bar chart <\/span>","71e84cdf":"\n* This is a statistical test to determine the presence of a unit root in a time series data that confirms if the series is stationary or not. \n\nThe null hypothesis is the time series is not stationary and has a unit root.\nThe alternate hypothesis is the time series is stationary and doesn't have a unit root.\n\nRead more: https:\/\/en.wikipedia.org\/wiki\/Dickey%E2%80%93Fuller_test\nRead more: https:\/\/www.statsmodels.org\/stable\/generated\/statsmodels.tsa.stattools.adfuller.html","6c7c190c":"This way we can do stationarity test for all the different timeseries IDs","3a1ac203":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">3.1. Sales per store - bar chart <\/span>","a73de00a":"Now we will compare our data to the normal distribution using Scipy normaltest:","860e83be":"https:\/\/www.kaggle.com\/jsaguiar\/complete-eda-time-series-with-plotly","9e65d2a2":"# <span class=\"title-section w3-xxlarge\" style=\"color:#FF00FF\" id=\"codebook\">2.Read Data <\/span>","c841b687":"#### Let us visualize for some of the keys or timeseries Ids","65503202":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">4.2. Trend and Seasonality by Key i.e., Store\/Country\/Product and Time <\/span>","ce6b3d4d":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">3.5. Sales by Store and Time <\/span>","4e3730fa":"# <span class=\"title-section w3-xxlarge\" style=\"color:#228B22\" id=\"codebook\">5.Work In Progress!!.............. <\/span>","48dd050e":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">3.3. Sales per country\/Store\/Product - bar chart <\/span>","c355459a":"## <span class=\"title-section w3-xlarge\" style=\"color:#FF00FF\" id=\"codebook\">4.3. ACF and PACF plots by Key i.e., Store\/Country\/Product and Time <\/span>","18fe68d4":"# <span class=\"title-section w3-xxlarge\" style=\"color:#FF00FF\" id=\"codebook\">4.Stationarity Test <\/span>","c15de7ae":"## For this challenge, you will be predicting a full year worth of sales for three items at two stores located in three different countries. "}}