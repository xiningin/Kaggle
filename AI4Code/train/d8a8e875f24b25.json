{"cell_type":{"0392cdbd":"code","64b3274e":"code","f255df22":"code","4591cb3b":"code","02c67839":"code","85759b35":"code","5bfdd286":"code","dd7f05a6":"code","97b9d309":"code","5d9d72e9":"code","f0792b08":"code","a297eda5":"code","d119e8f5":"code","13ad10f8":"code","26086460":"code","68b92364":"code","30e25903":"code","caf57212":"code","0362d701":"code","6d271971":"code","ff4e2c6a":"code","ecbeb6ad":"code","979c26ad":"code","23b6cff0":"code","13e51c3a":"code","1e38eb0a":"code","f11692c6":"code","67348540":"code","b0a01a9c":"code","444f766c":"code","336a539c":"code","28a8ca0c":"code","3b2ab0d1":"code","43178b89":"code","a8dbe974":"code","613dafe5":"code","5144e0d2":"code","16cb1448":"code","37166869":"code","cd88963f":"code","7428280b":"code","c10d8be8":"code","e9d8ca96":"code","2b3d73ec":"code","c44a3a05":"code","4384c1a5":"code","a9292ace":"code","1d3a9f4d":"code","179e3be7":"code","420c1a6a":"code","499f51d8":"code","40a5d969":"code","922b960f":"code","266f563b":"code","c86ba0e7":"code","6a856f60":"code","a3b9ce00":"code","90757607":"code","63be7b7a":"code","306a1e6e":"code","99cdc587":"code","c78f3147":"code","175ee73b":"code","4199ef59":"markdown","84ba25b1":"markdown","6d575713":"markdown","ed8819f7":"markdown","84e1742a":"markdown","bd32b492":"markdown","8050b35b":"markdown","dc314941":"markdown","405d8601":"markdown","ec0b80bf":"markdown","f60c4a4b":"markdown","0486caf2":"markdown","013572d3":"markdown"},"source":{"0392cdbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64b3274e":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os\nimport random\nimport matplotlib.pyplot as plt\n# \u062a\u0644\u0643 \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0647 \u062a\u0648\u0627\u062c\u0647 \u062e\u0637\u0627 \u0644\u0630\u0644\u0643 \u0642\u0645 \u0628\u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0647 \u0627\u0644\u062a\u0627\u0644\u064a\u0647 \n#from keras.utils import to_categorical\nfrom tensorflow.keras.utils import to_categorical","f255df22":"train_data = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ntest_data = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')","4591cb3b":"#Datasets as numpy arrays\ntrain_data_np = np.array(train_data, dtype = 'float32')\ntest_data_np = np.array(test_data, dtype='float32')","02c67839":"print(train_data_np.shape)\nprint(test_data_np.shape)","85759b35":"#Define class labels for easy interpretation\nclass_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n               'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]","5bfdd286":"# \u0647\u0646\u0627 \u0627\u0642\u0648\u0645 \u0628\u0639\u0645\u0644 \u0641\u062d\u0635 \u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0648\u0630\u0644\u0643 \u0639\u0646 \u0637\u0631\u064a\u0642 \u0637\u0628\u0627\u0639\u0647 \u0628\u0639\u0636 \u0627\u0644\u0635\u0648\u0631 \u0627\u0644\u0639\u0634\u0648\u0627\u0626\u064a\u0647 \u0641\u064a \u0643\u0644 \u0645\u0631\u0647 \n#Sanity check - plot a few images and labels\ni = random.randint(1,train_data.shape[0])\nfig1, ax1 = plt.subplots(figsize=(3,3))\nplt.imshow(train_data_np[i,1:].reshape((28,28))) \nprint(\"Label for the image is: \", class_names[int(train_data_np[i,0])])","dd7f05a6":"# \u0647\u0646\u0627 \u0646\u0642\u0648\u0645 \u0628\u0631\u0633\u0645 \u062a\u0648\u0632\u064a\u0639 \u0643\u0644 \u0641\u0626\u0647 \u0645\u0646 \u0627\u0644\u0641\u0626\u0627\u062a \n# Data distribution visualization\nfig = plt.figure(figsize=(18,18))\nax1 = fig.add_subplot(221)\ntrain_data['label'].value_counts().plot(kind='bar', ax=ax1)\nax1.set_ylabel('Count')\nax1.set_title('Label')","97b9d309":"#Normalize \/ scale X values\n# \u0647\u0646\u0627 \u0642\u0645\u0646\u0627 \u0628\u0627\u0644\u062a\u062e\u0644\u064a \u0639\u0644\u064a \u0627\u0648\u0644 \u0639\u0645\u0648\u062f \u0645\u0646 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \nX_train = train_data_np[:, 1:] \/255.\nX_test = test_data_np[:, 1:] \/255.","5d9d72e9":"print(train_data_np[:, 1:])\nprint('---------------------------------------')\nprint(train_data_np[:, :])","f0792b08":"print(X_train)","a297eda5":"#Convert y to categorical if planning on using categorical cross entropy\n#No need to do this if using sparse categorical cross entropy\n# \u0647\u0646\u0627 \u0642\u0645\u0646\u0627 \u0628\u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u0627\u0644\u0639\u0645\u0648\u062f \u0627\u0644\u0627\u0648\u0644 \u0645\u0646 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0647\u0648 \u0645\u062b\u0644 \u0627\u0644\u0639\u0645\u0648\u062f \u0627\u0644\u0647\u062f\u0641 \ny_train = train_data_np[:, 0]\ny_train_cat = to_categorical(y_train, num_classes=25)","d119e8f5":"print(train_data_np[:, 0].shape)\nprint('--------------------------------')\nprint(train_data_np[:, 0])\nprint('--------------------------------')\nprint(train_data_np[:, ])","13ad10f8":"# \u0647\u0646\u0627 \u0646\u0642\u0648\u0645 \u0628\u0646\u0641\u0633 \u0627\u0644\u0627\u0645\u0631 \u0645\u0639 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \ny_test = test_data_np[:,0]\ny_test_cat = to_categorical(y_test, num_classes=25)","26086460":"print(test_data_np[:, 0].shape)\nprint('--------------------------------')\nprint(test_data_np[:, 0])\nprint('--------------------------------')\nprint(test_data_np[:, ])","68b92364":"#Reshape for the neural network\n# \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0647 \u0627\u0644\u062a\u0627\u0644\u064a\u0647 \u062c\u0645\u064a\u0644 \u062c\u062f\u0627 \u0648\u062e\u0644\u0627\u0644\u0647\u0627 \u0646\u0642\u0648\u0645 \u0628\u062a\u0639\u062f\u064a\u0644 \u0627\u0628\u0639\u0627\u062f \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0644\u0644\u062a\u062f\u0631\u064a\u0628 \u0648\u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \n# \u0627\u0644\u0628\u0639\u062f \u0627\u0644\u0627\u0633\u0627\u0633\u064a \u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0647\u0648 (27455,) \u0648\u0644\u0643\u0646\u0646\u0627 \u0633\u0646\u0639\u0645\u0644 \u0639\u0644\u064a \u0627\u0636\u0627\u0641\u0647 \u0647\u0630\u0627 \u0627\u0644\u062c\u0632\u0621 \u0646\u062a \u0627\u0644\u0627\u0628\u0639\u0627\u062f (28, 28, 1) \u0644\u0646\u062d\u0635\u0644 \u0639\u0644\u064a \u0627\u0628\u0639\u0627\u062f \u0643\u0627\u0645\u0644\u0647 \nX_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\n# \u0646\u0641\u0633 \u0627\u0644\u0627\u0645\u0631 \u0645\u0639 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \nX_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))","30e25903":"print(X_train.shape)\nprint('-----------------------')\nprint(X_test.shape)","caf57212":"from tensorflow.keras.layers import Dense,MaxPooling2D,Conv2D,Dropout,Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2,l1","0362d701":"# \u0646\u0628\u062f\u0627 \u0641\u064a \u0635\u064a\u0627\u063a\u0647 \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u0627\u0644\u0627\u0648\u0644 \n# \u0627\u0646\u0634\u0627\u0621 \u0647\u064a\u0643\u0644 \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u0641\u064a \u0627\u0644\u0628\u062f\u0627\u064a\u0647 \u0648\u0628\u0639\u062f\u0647\u0627 \u0633\u0646\u0642\u0648\u0645 \u0628\u0627\u0636\u0627\u0641\u0647 \u0627\u0644\u0637\u0628\u0642\u0627\u062a \u0627\u0644\u062f\u0627\u062e\u0644\u064a\u0647 \u0641\u064a \u062e\u0637\u0648\u0627\u062a \u0644\u0627\u062d\u0642\u0647\nmodel1 = Sequential()\nmodel1.add(Conv2D(32, (3, 3),padding=\"same\", input_shape = (28,28,1), kernel_regularizer=l2(0.0002), activation='relu'))\nmodel1.add(MaxPooling2D(pool_size = (2, 2)))\nmodel1.add(Dropout(0.2))\n\nmodel1.add(Conv2D(64, (3, 3), padding=\"same\" ,kernel_regularizer=l2(0.0002), activation='relu'))\nmodel1.add(MaxPooling2D(pool_size = (2, 2)))\nmodel1.add(Dropout(0.2))\n\nmodel1.add(Conv2D(128, (3, 3),padding=\"same\" ,kernel_regularizer=l2(0.0002),  activation='relu'))\nmodel1.add(MaxPooling2D(pool_size = (2, 2)))\nmodel1.add(Dropout(0.2))\n\nmodel1.add(Flatten())\n\nmodel1.add(Dense(128, activation = 'relu'))\nmodel1.add(Dense(25, activation = 'softmax'))","6d271971":"#model1.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics =['acc'])\nmodel1.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['acc'])\nmodel1.summary()","ff4e2c6a":"#Training the CNN model1\n#history = model1.fit(X_train, y_train, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test))\nhistory1 = model1.fit(X_train, y_train_cat, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test_cat))\n\nmodel1.save('saved_models\/model1.hdf5')","ecbeb6ad":"loss,accuracy=model1.evaluate(X_test,y_test_cat)","979c26ad":"model2 = Sequential()\n\nmodel2.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size = (2, 2)))\nmodel2.add(Dropout(0.2))\n\nmodel2.add(Conv2D(64, (3, 3), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size = (2, 2)))\nmodel2.add(Dropout(0.2))\n\nmodel2.add(Conv2D(128, (3, 3), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size = (2, 2)))\nmodel2.add(Dropout(0.2))\n\nmodel2.add(Flatten())\n\nmodel2.add(Dense(128, activation = 'relu'))\nmodel2.add(Dense(25, activation = 'softmax'))","23b6cff0":"#model1.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics =['acc'])\nmodel2.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['acc'])\nmodel2.summary()","13e51c3a":"history1 = model2.fit(X_train, y_train_cat, batch_size = 128, epochs = 20, verbose = 1, validation_data = (X_test, y_test_cat))\n\nmodel1.save('model2.hdf5')","1e38eb0a":"loss,accuracy=model2.evaluate(X_test,y_test_cat)","f11692c6":"model3 = Sequential()\n\nmodel3.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\nmodel3.add(MaxPooling2D(pool_size = (2, 2)))\nmodel3.add(Dropout(0.2))\n\nmodel3.add(Conv2D(64, (3, 3), activation='relu'))\nmodel3.add(MaxPooling2D(pool_size = (2, 2)))\nmodel3.add(Dropout(0.2))\n\nmodel3.add(Flatten())\n\nmodel3.add(Dense(25, activation = 'softmax'))","67348540":"#model1.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics =['acc'])\nmodel3.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['acc'])\nmodel3.summary()","b0a01a9c":"#Training the CNN model3\n#history = model1.fit(X_train, y_train, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test))\nhistory3 = model3.fit(X_train, y_train_cat, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test_cat))\n\nmodel3.save('model3.hdf5')","444f766c":"loss,accuracy=model3.evaluate(X_test,y_test_cat)","336a539c":"from keras.models import load_model\nfrom sklearn.metrics import accuracy_score","28a8ca0c":"model1 = load_model('.\/saved_models\/model1.hdf5')\nmodel2 = load_model('.\/model2.hdf5')\nmodel3 = load_model('.\/model3.hdf5')\n\nmodels = [model1, model2, model3]","3b2ab0d1":"# \u0646\u062a\u064a\u062c\u0647 \u0644\u0630\u0644\u0643 \u0646\u062d\u0635\u0644 \u0639\u0644\u064a 3 \u0645\u0635\u0641\u0648\u0641\u0648\u0627\u062a \u0645\u0646 \u0646\u0648\u0639 \u0646\u0627\u0645\u0628\u0627\u064a \u0648\u0647\u064a \u062a\u062d\u062a\u0648\u064a \u0639\u0644\u064a\u0647\u0627 \u0644\u0627\u0646 \u0644\u062f\u064a\u0646\u0627 3 \u0645\u0648\u062f\u064a\u0644 \u062a\u0645 \u0639\u0645\u0644 \u0627\u0644\u062a\u0646\u0628\u0624 \u0644\u0647\u0627 \npreds = [model.predict(X_test) for model in models]\n# \u0646\u0627\u062a\u062c \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0647 \u0627\u0644\u0633\u0627\u0628\u0642\u0647 \u0647\u0648 3 \u0645\u0635\u0641\u0648\u0641\u0627\u062a \u0645\u0646 \u0646\u0648\u0639 \u0646\u0627\u0645\u0628\u0627\u064a \npreds=np.array(preds)","43178b89":"print(preds.shape)\n# \u0627\u0644\u0645\u0633\u0642\u0637 \u0627\u0644\u0627\u0648\u0644 3 \u064a\u0639\u0628\u0631 \u0639\u0646 \u0627\u0644\u0645\u0635\u0641\u0648\u0641\u0627\u062a \u0627\u0644\u062b\u0644\u0627\u062b\u0647 \n# \u0627\u0644\u0645\u0633\u0642\u0637 \u0627\u0644\u062b\u0627\u0646\u064a \u0639\u062f\u062f \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u064a \u062a\u0645 \u0627\u0644\u062a\u0646\u0628\u0624 \u0628\u0647\u0627 \u0648\u0647\u064a \u0645\u0633\u0627\u0648\u064a\u0647 \u0644\u0639\u062f\u062f \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \n# \u0627\u0644\u0645\u0633\u0642\u0637 \u0627\u0644\u062b\u0627\u0644\u062b \u064a\u062f\u0644 \u0639\u0644\u064a \u0639\u062f\u062f \u0627\u0644\u0641\u0626\u0627\u062a \u0627\u0644\u0645\u0643\u0648\u0646\u0647 \u0644\u0644\u0628\u064a\u0627\u0646\u0627\u062a ","a8dbe974":"# \u0647\u0646\u0627 \u0646\u0639\u0645\u0644 \u0639\u0644\u064a \u062c\u0645\u0639 \u0627\u0644\u0646\u062a\u0627\u0626\u062c \u0627\u0648 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u0644\u0643\u0644 \u0627\u0644\u0645\u0648\u062f\u064a\u0644\u0632 \u0627\u0644\u062b\u0644\u0627\u062b\u0647 \u0645\u0639\u0627 \n# \u0628\u0645\u0639\u0646\u064a \u0627\u0646\u0647 \u064a\u062a\u0645 \u062c\u0645\u0639 \u0627\u0644\u0642\u064a\u0645\u0647 \u0627\u0644\u0627\u0648\u0644\u064a \u0644\u0643\u0644 \u0645\u0648\u062f\u064a\u0644 \n# \u062a\u0648\u0636\u064a\u062d \u0627\u0643\u062b\u0631 \n# \u0644\u062f\u064a\u0646\u0627 25 \u0642\u064a\u0645\u0647 \u0631\u0626\u064a\u0633\u064a\u0647 \u0644\u0644\u062a\u0646\u0628\u0624 \u0628\u0647\u0627 , \u0628\u0639\u062f \u0627\u0646 \u0642\u0645\u0646\u0627 \u0628\u0627\u0644\u062a\u0646\u0628\u0624 \u0627\u0635\u0628\u062d \u0644\u062f\u064a\u0646\u0627 3 \u0642\u064a\u0645 \u0645\u062e\u062a\u0644\u0641\u0647 \u0644\u0644\u0642\u064a\u0645\u0647 \u0627\u0644\u0648\u0627\u062d\u062f\u0647 \u0645\u0646 \u0627\u0635\u0644 25 \u0639\u0646\u0635\u0631 \n# \u062a\u0644\u0643 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u062b\u0644\u0627\u062b\u0647 \u0644\u0643\u0644 \u0641\u0626\u0647 \u0645\u0646 \u0627\u0644\u0641\u0626\u0627\u062a \u0642\u0645\u0646\u0627 \u0628\u062a\u062c\u0645\u064a\u0639\u0647\u0627 \u0645\u0639\u0627 .\n# \u0628\u0645\u0639\u0646\u064a \u0627\u062e\u0631 \u0627\u0646\u0627 \u0627\u0642\u0648\u0645 \u0628\u062c\u0645\u064a\u0639 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u06443 \u0644\u0643\u0644 \u0642\u064a\u0645\u0647 \u0645\u0646 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644 25 \nsummed = np.sum(preds, axis=0)","613dafe5":"# \u0641\u064a \u0627\u0644\u0646\u0627\u062a\u062c \u0646\u0644\u0627\u062d\u0638 \u0627\u0646\u0647 \u062a\u0645 \u062f\u0645\u062c \u0627\u0644\u0645\u0635\u0641\u0648\u0641\u0627\u062a \u0627\u0644\u062b\u0644\u0627\u062b\u0647 \u0639\u0646 \u0637\u0631\u064a\u0642 \u062c\u0645\u0639 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u062b\u0627\u0644\u062b\u0647 \u0644\u0644\u0641\u0626\u0647 \u0627\u0644\u0648\u0627\u062d\u062f\u0647 \u0644\u0643\u0644 \u0642\u064a\u0645\u0647 \u0645\u0646 \u0642\u064a\u0645 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \nprint(summed.shape)","5144e0d2":"# argmax across classes\n# \u0647\u0646\u0627 \u0627\u0639\u0645\u0644 \u0627\u064a\u062c\u0627\u062f \u0627\u0644\u0642\u064a\u0645\u0647 \u0627\u0644\u0627\u0642\u0635\u064a \u0644\u0643\u0644 \u0639\u0645\u0644\u064a\u0647 \u062c\u0645\u0639 \u0645\u0646 \u0627\u0644\u0642\u064a\u0645 \nensemble_prediction = np.argmax(summed, axis=1)","16cb1448":"print(ensemble_prediction.shape)\nprint('---------------')\nprint(ensemble_prediction[:20])","37166869":"# prediction3 = model3.predict_classes(X_test)\n# \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0647 \u0627\u0644\u0633\u0627\u0628\u0642\u0647 \u0645\u0631\u0641\u0648\u0636\u0647 \n# \u0641\u064a \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0627\u062a \u0627\u0644\u062a\u0627\u0644\u064a\u0647 \u0646\u0642\u0648\u0645 \u0628\u0639\u0645\u0644 \u0627\u0644\u062a\u0646\u0628\u0624 \u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \u0644\u0643\u0644 \u0645\u0648\u062f\u064a\u0644 \u0639\u0644\u064a \u062d\u062f\u0647\nprediction1 = model1.predict(X_test)\nprediction2 = model2.predict(X_test)\nprediction3 = model3.predict(X_test)","cd88963f":"# \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0647 \u062a\u0644\u0643 \u0645\u0631\u0641\u0648\u0636\u0647 accuracy1 = accuracy_score(y_test, prediction1)\n# \u0644\u0630\u0644\u0643 \u064a\u062a\u0645 \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u0647 \u0627\u0644\u062a\u0627\u0644\u064a\u0647 \n# \u0647\u0646\u0627 \u064a\u062d\u062f\u062b \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0628\u064a\u0646 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u0627\u0644\u0627\u062e\u0631\u064a \naccuracy1 = accuracy_score(y_test, np.argmax(prediction1, axis=1))\naccuracy2 = accuracy_score(y_test, np.argmax(prediction2, axis=1))\naccuracy3 = accuracy_score(y_test, np.argmax(prediction3, axis=1))\nensemble_accuracy = accuracy_score(y_test, ensemble_prediction)","7428280b":"# \u0646\u0644\u0627\u062d\u0638 \u0627\u0646 \u0627\u0644\u0646\u062a\u0627\u0626\u062c \/ \u0627\u0644\u062f\u0642\u0647 \u062a\u062d\u0633\u0646\u062a \u0642\u0644\u064a\u0644\u0627\nprint('Accuracy Score for model1 = ', accuracy1)\nprint('Accuracy Score for model2 = ', accuracy2)\nprint('Accuracy Score for model3 = ', accuracy3)\nprint('Accuracy Score for average ensemble = ', ensemble_accuracy)","c10d8be8":"# \u0647\u0646\u0627 \u0627\u0639\u0645\u0644 \u0639\u0644\u064a \u0648\u0636\u0639 \u0627\u0648\u0632\u0627\u0646 \u0644\u0643\u0644 \u0645\u0648\u062f\u064a\u0644 \u0645\u0646 \u0627\u0644\u0645\u0648\u062f\u064a\u0644\u0632 \u0627\u0644\u062a\u064a \u0642\u0645\u062a \u0628\u062a\u062f\u0631\u064a\u0628\u0647\u0627\n#Weighted average ensemble\nmodels = [model1, model2, model3]\npreds = [model.predict(X_test) for model in models]\npreds=np.array(preds)","e9d8ca96":"# \u0647\u0646\u0627 \u0627\u0636\u0639 \u0627\u0644\u0627\u0648\u0632\u0627\u0646 \u0627\u0644\u062a\u064a \u064a\u0624\u062b\u0631 \u0628\u0647\u0627 \u0643\u0644 \u0645\u0648\u062f\u064a\u0644 \u0645\u0646 \u0627\u0644\u0645\u0648\u062f\u064a\u0644\u0632 \u0627\u0644\u0627\u062e\u0631\u064a . \n# \u0648\u0627\u0639\u0646\u064a \u0627\u064a\u0636\u0627 \u0627\u0646 \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u0627\u0644\u062b\u0627\u0646\u064a \u064a\u0633\u0624\u062b\u0631 \u0628\u0646\u0633\u0628\u0647 \u0627\u0642\u0644 \u0627\u0648 \u0628\u0646\u0633\u0628\u0647 20% \u0645\u0646 \u0627\u0644\u0645\u0648\u062f\u064a\u0644\u0632 \u0627\u0644\u0627\u062e\u0631\u064a \nweights = [0.4, 0.2, 0.4]","2b3d73ec":"#Use tensordot to sum the products of all elements over specified axes.\n# \u0647\u0646\u0627 \u0627\u0639\u0645\u0644 \u0639\u0644\u064a \u0627\u0646\u0634\u0627\u0621 \u062a\u0646\u0633\u0648\u0631 \u064a\u0639\u0645\u0644 \u0639\u0644\u064a \u0636\u0631\u0628 \u0627\u0644\u0646\u062a\u0627\u0626\u062c \u0645\u0639 \u0627\u0627\u0644\u0648\u0632\u0627\u0646 \u0627\u0644\u062a\u064a \u0642\u0645\u062a \u0628\u0627\u0636\u0627\u0641\u062a\u0647\u0627 , \u0644\u064a\u062d\u062f\u062b \u0645\u0636\u0627\u0639\u0641\u0647 \u0644\u0644\u0646\u062a\u0627\u0626\u062c \nweighted_preds = np.tensordot(preds, weights, axes=((0),(0)))\nweighted_ensemble_prediction = np.argmax(weighted_preds, axis=1)","c44a3a05":"weighted_accuracy = accuracy_score(y_test, weighted_ensemble_prediction)","4384c1a5":"# \u0639\u0646\u062f \u0637\u0628\u0627\u0639\u0647 \u0627\u0644\u062f\u0642\u0647 \u0646\u0644\u0627\u062d\u0638 \u062a\u062d\u0633\u0646 \u0641\u064a\u0647\u0627 \u0645\u0644\u062d\u0648\u0638 .\n# \u0646\u0644\u0627\u062d\u0638 \u0627\u0646 \u0627\u0644\u0646\u062a\u0627\u0626\u062c \u062a\u062d\u0633\u0646\u062a \u0628\u0634\u0643\u0644 \u0636\u0639\u064a\u0641 \u062c\u062f\u0627 \nprint('Accuracy Score for model1 = ', accuracy1)\nprint('Accuracy Score for model2 = ', accuracy2)\nprint('Accuracy Score for model3 = ', accuracy3)\nprint('Accuracy Score for average ensemble = ', ensemble_accuracy)\nprint('Accuracy Score for weighted average ensemble = ', weighted_accuracy)","a9292ace":"#Grid search for the best combination of w1, w2, w3 that gives maximum acuracy\n# \u0647\u0646\u0627 \u0627\u0639\u0645\u0644 \u0639\u0644\u064a \u0627\u0644\u0628\u062d\u062b \u0639\u0646 \u0627\u0641\u0636\u0644 \u0627\u0644\u0627\u0648\u0632\u0627\u0646 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646\u0646\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644\u0647\u0627 \nmodels = [model1, model2, model3]\npreds1 = [model.predict(X_test) for model in models]\npreds1=np.array(preds1)","1d3a9f4d":"# \u0647\u0646\u0627 \u0627\u0628\u062f\u0627 \u0641\u064a \u0627\u0644\u062a\u0644\u0627\u0639\u0628 \u0628\u0627\u0644\u0627\u0648\u0632\u0627\u0646 \u0628\u063a\u0631\u0636 \u0631\u0641\u0639 \u0645\u0633\u062a\u0648\u064a \u0627\u0644\u062f\u0642\u0647 \n# \u0648\u0633\u064a\u0639\u0637\u064a \u0628\u0639\u062f\u0647\u0627 \u0627\u0646\u0633\u0628 \u0627\u0648\u0632\u0627\u0646 \u064a\u0645\u0643\u0646 \u0627\u0646 \u0646\u0643\u0648\u0646\u0647\u0627 \u0644\u0644\u0645\u0648\u062f\u064a\u0644 . \u0648\u0628\u0627\u0644\u062a\u0627\u0644\u064a \u064a\u0645\u0643\u0646\u0646\u0627 \u0627\u0644\u0639\u0648\u062f\u0647 \u0644\u062a\u063a\u064a\u064a\u0631 \u062a\u0644\u0643 \u0627\u0644\u0627\u0648\u0632\u0627\u0646 \u0641\u064a \u0627\u0644\u0627\u0639\u0644\u064a \nimport pandas as pd\ndf = pd.DataFrame([])\n\nfor w1 in range(0, 5):\n    for w2 in range(0,5):\n        for w3 in range(0,5):\n            wts = [w1\/10.,w2\/10.,w3\/10.]\n            wted_preds1 = np.tensordot(preds1, wts, axes=((0),(0)))\n            wted_ensemble_pred = np.argmax(wted_preds1, axis=1)\n            weighted_accuracy = accuracy_score(y_test, wted_ensemble_pred)\n            df = df.append(pd.DataFrame({'wt1':wts[0],'wt2':wts[1], \n                                         'wt3':wts[2], 'acc':weighted_accuracy*100}, index=[0]), ignore_index=True)","179e3be7":"# \u0647\u0646\u0627 \u0627\u0639\u0645\u0644 \u0639\u0644\u064a \u0637\u0628\u0627\u0639\u0647 \u0627\u0639\u0644\u064a \u062f\u0642\u0647 \u0648\u0635\u0644\u062a \u0627\u0644\u064a\u0647\u0627 .\nmax_acc_row = df.iloc[df['acc'].idxmax()]","420c1a6a":"# \u0639\u0646\u062f \u0637\u0628\u0627\u0639\u0647 \u062a\u0644\u0643 \u0627\u0644\u0627\u0633\u0637\u0631 \u0646\u0644\u0627\u062d\u0638 \u0627\u0646\u0647\u0627 \u0639\u0645\u0644\u062a \u0639\u0644\u064a \u062a\u062d\u0633\u064a\u0646 \u0627\u0644\u0646\u062a\u0627\u0626\u062c \u0628\u0634\u0643\u0644 \u0627\u0643\u0628\u0631 .\nprint(\"Max accuracy of \", max_acc_row[0], \" obained with w1=\", max_acc_row[1],\n      \" w2=\", max_acc_row[2], \" and w3=\", max_acc_row[3])         ","499f51d8":"### Explore metrics for the ideal weighted ensemble model. \n# \u0647\u0646\u0627 \u0639\u0645\u0644\u0646\u0627 \u0639\u0644\u064a \u062a\u063a\u064a\u064a\u0631 \u0627\u0644\u0627\u0648\u0632\u0627\u0646 \nmodels = [model1, model2, model3]\npreds = [model.predict(X_test) for model in models]\npreds=np.array(preds)\n# \u0647\u0646\u0627 \u0646\u0639\u0645\u0644 \u0639\u0644\u064a \u062a\u0639\u062f\u064a\u0644 \u0627\u0644\u0627\u0648\u0632\u0627\u0646 \nideal_weights = [0.3, 0.4, 0.4] ","40a5d969":"#Use tensordot to sum the products of all elements over specified axes.\nideal_weighted_preds = np.tensordot(preds, ideal_weights, axes=((0),(0)))\nideal_weighted_ensemble_prediction = np.argmax(ideal_weighted_preds, axis=1)","922b960f":"ideal_weighted_ensemble_prediction","266f563b":"ideal_weighted_accuracy = accuracy_score(y_test, ideal_weighted_ensemble_prediction)","c86ba0e7":"# \u0647\u0646\u0627 \u0646\u0639\u0645\u0644 \u0639\u0644\u064a \u0627\u0644\u062a\u0646\u0628\u0624 \u0628\u0628\u0639\u0636 \u0627\u0644\u0635\u0648\u0631 \u0627\u0644\u0639\u0634\u0648\u0627\u0626\u064a\u0647 \ni = random.randint(1,len(ideal_weighted_ensemble_prediction))\nplt.imshow(X_test[i,:,:,0]) \nprint(\"Predicted Label: \", class_names[int(ideal_weighted_ensemble_prediction[i])])\nprint(\"True Label: \", class_names[int(y_test[i])])","6a856f60":"prediction=ideal_weighted_ensemble_prediction","a3b9ce00":"# \u0646\u0642\u0648\u0645 \u0628\u0639\u062f\u0647\u0627 \u0628\u0637\u0628\u0627\u0639\u0647 \u0645\u0635\u0641\u0648\u0641\u0647 \u0627\u0644\u062a\u0634\u062a\u062a\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n#Print confusion matrix\ncm = confusion_matrix(y_test, ideal_weighted_ensemble_prediction)","90757607":"# \u0647\u0646\u0627 \u0646\u0639\u0645\u0644 \u0639\u0644\u064a \u0637\u0628\u0627\u0639\u0647 \u0645\u062e\u0637\u0637 \u064a\u0648\u0636\u062d \u0627\u0644\u0646\u062a\u0627\u0626\u062c \u0627\u0648 \u0646\u062a\u0627\u0626\u062c \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a\nfig, ax = plt.subplots(figsize=(20,12))\nsns.set(font_scale=1.6)\nsns.heatmap(cm, annot=True, linewidths=.5, ax=ax)","63be7b7a":"#PLot fractional incorrect misclassifications\nincorr_fraction = 1 - np.diag(cm) \/ np.sum(cm, axis=1)\nfig, ax = plt.subplots(figsize=(12,12))\nplt.bar(np.arange(24), incorr_fraction)\nplt.xlabel('True Label')\nplt.ylabel('Fraction of incorrect predictions')\nplt.xticks(np.arange(25), class_names)\n# \u0641\u064a \u0627\u0644\u0646\u062a\u0627\u0626\u062c , \u064a\u0628\u062f\u0648 \u0627\u0646 \u062d\u0631\u0641 \u0627\u0644 s\n# \u0647\u0648 \u0627\u0644\u062d\u0631\u0641 \u0627\u0644\u0630\u064a \u064a\u062d\u0645\u0644 \u0627\u0643\u062b\u0631 \u0627\u0644\u0627\u062e\u0637\u0627\u0621 ","306a1e6e":"# \u0647\u0646\u0627 \u0627\u0628\u062f\u0627 \u0628\u0627\u0646\u0634\u0627\u0621 \u0642\u0627\u0626\u0645\u062a\u064a\u0646 \u0627\u062d\u062f\u0647\u0627 \u062a\u062d\u0645\u0644 \u0627\u0644\u0635\u062d\u064a\u062d \u0648\u0627\u0644\u0627\u062e\u0631\u064a \u062a\u062d\u0645\u0644 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u0627\u0644\u062e\u0637\u0627\ncorrect_labels=[] # for storing the correct predictions\nincorrect_labels=[] # for storing the incorrect predictions\n\n\n#for testing which predictions went wrong\n# \u0647\u0646\u0627 \u062a\u0645 \u0627\u0646\u0634\u0627\u0621 \u0644\u0648\u0628 \u064a\u062f\u0648\u0631 \u0639\u0644\u064a \u0643\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0641\u064a \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u0648\u0642\u0639 \n# \u0648\u0645\u0646 \u062e\u0644\u0627\u0644 \u0642\u0631\u0627\u0621\u0647 \u0627\u0644\u0643\u0648\u062f \u0646\u0641\u0647\u0645 \u0627\u0644\u0627\u0645\u0631 \n# \u0648\u0644\u0643\u0646 \u0647\u0630\u0627 \u0645\u0646 \u0627\u062c\u0644 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u0627\u0644\u062e\u0637\u0627 \nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])!=ideal_weighted_ensemble_prediction[i]):\n        incorrect_labels.append(i)\n    if len(incorrect_labels)==10:\n        break","99cdc587":"# for testing which predictions are accurate\n# \u0647\u0630\u0627 \u0645\u0646 \u0627\u062c\u0644 \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u0627\u0644\u0635\u062d\u064a\u062d\u0647\n# \u0627\u0643\u0645\u0644 \u0642\u0631\u0627\u0621\u0647 \u0627\u0644\u062e\u0644\u064a \u0648\u0633\u064a\u0643\u0648\u0646 \u0643\u0644 \u0634\u064a\u0621 \u0628\u062e\u064a\u0631\nfor i in range(len(y_test)):\n    if (np.argmax(y_test[i])==ideal_weighted_ensemble_prediction[i]):\n        correct_labels.append(i)\n    if len(correct_labels)==10:\n        break","c78f3147":"# \u0633\u0646\u0642\u0648\u0645 \u0627\u0644\u0627\u0646 \u0628\u062a\u0635\u0648\u0631 \/\/ \u0627\u0638\u0647\u0627\u0631 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u0627\u0644\u0635\u062d\u064a\u062d\u0647\n# \u0627\u0648\u0644\u0627 \u0642\u0645\u0646\u0627 \u0628\u0627\u0646\u0634\u0627\u0621 \u0639\u062f\u0627\u062f \u0628\u0642\u064a\u0645\u0647 \u0627\u0628\u062a\u062f\u0627\u0626\u064a\u0647 \u0635\u0641\u0631 \ncount=0\n\n# \u0647\u0646\u0627 \u0642\u0645\u0646\u0627 \u0628\u0627\u0646\u0634\u0627\u0621 \u0645\u062e\u0637\u0637 \u064a\u062d\u0645\u0644 10 \u0635\u0648\u0631 \u0645\u062b\u0644 \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u0633\u0627\u0628\u0642 \nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range (5):\n    for j in range (2):\n        ax[i,j].imshow(X_test[correct_labels[count]])\n        ax[i,j].set_title(\"Predicted cell : \"+ class_names[ideal_weighted_ensemble_prediction[correct_labels[count]]] +\"\\n\"+\"Actual type of cell : \"+ class_names[np.argmax(y_test[correct_labels[count]])])\n        plt.tight_layout()\n        count+=1","175ee73b":"# \u0633\u0646\u0642\u0648\u0645 \u0627\u0644\u0627\u0646 \u0628\u062a\u0635\u0648\u0631 \/\/ \u0627\u0638\u0647\u0627\u0631 \u0627\u0644\u062a\u0648\u0642\u0639\u0627\u062a \u0627\u0644\u062e\u0627\u0637\u0626\u0647\n# \u0627\u0648\u0644\u0627 \u0642\u0645\u0646\u0627 \u0628\u0627\u0646\u0634\u0627\u0621 \u0639\u062f\u0627\u062f \u0628\u0642\u064a\u0645\u0647 \u0627\u0628\u062a\u062f\u0627\u0626\u064a\u0647 \u0635\u0641\u0631 \ncount=0\n# \u0647\u0646\u0627 \u0642\u0645\u0646\u0627 \u0628\u0627\u0646\u0634\u0627\u0621 \u0645\u062e\u0637\u0637 \u064a\u062d\u0645\u0644 10 \u0635\u0648\u0631 \u0645\u062b\u0644 \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u0633\u0627\u0628\u0642 \nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range (5):\n    for j in range (2):\n        ax[i,j].imshow(X_test[incorrect_labels[count]])\n        ax[i,j].set_title(\"Predicted cell : \"+ class_names[ideal_weighted_ensemble_prediction[incorrect_labels[count]]] +\"\\n\"+\"Actual type of cell : \"+ class_names[np.argmax(y_test[incorrect_labels[count]])])\n        plt.tight_layout()\n        count+=1","4199ef59":"# Sign language using Ensemble set of networks","84ba25b1":"**We are done with this work so far, there are some bugs, I will fix them later.**","6d575713":"# work in progress","ed8819f7":"**\u0627\u062e\u0631 \u062e\u0644\u064a\u062a\u064a\u0646 \u0628\u0647\u0645\u0627 \u062e\u0644\u0644 \u0648\u0628\u0627\u0644\u062a\u0627\u0644\u064a \u0633\u0627\u0642\u0648\u0645 \u0628\u062a\u0639\u062f\u064a\u0644\u0647\u0645 \u0641\u064a\u0645\u0627 \u0628\u0639\u062f**","84e1742a":"# importing libraries","bd32b492":"# Definition of the second model","8050b35b":"# Data importing","dc314941":"**thank you so much:**\n\n**[reference](https:\/\/github.com\/bnsreenu\/python_for_microscopists\/blob\/master\/213-ensemble_sign_language.py)**","405d8601":"# The first model","ec0b80bf":"# Ensemble","f60c4a4b":"# Improve results in predictions","0486caf2":"**\u0633\u0646\u0645\u0627\u0631\u0633 \u0641\u064a \u062a\u0644\u0643 \u0627\u0644\u0643\u064a\u0631\u0646\u064a\u0644 \u0627\u0633\u0644\u0648\u0628 \u062a\u062c\u0645\u064a\u0639 \u0639\u062f\u062f \u0645\u0646 \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u0639\u0635\u0628\u064a\u0647 , \u0648\u0628\u0639\u062f\u0647\u0627 \u0633\u0646\u0639\u0645\u0644 \u0639\u0644\u064a \u0627\u0641\u0636\u0644 \u0627\u0644\u0646\u062a\u0627\u0626\u062c \u0645\u0646 \u0628\u064a\u0646 \u062a\u0644\u0643 \u0627\u0644\u0634\u0628\u0643\u0627\u062a \u0627\u0644\u062a\u064a \u0633\u0646\u0642\u0648\u0645 \u0628\u0628\u0646\u0627\u0621\u0647\u0627**","013572d3":"# The third model"}}