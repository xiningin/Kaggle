{"cell_type":{"d9c81d16":"code","1b8e97ec":"code","a90a22fd":"code","48d131f5":"code","3f34745a":"code","51d44c5a":"code","f9a0b3c7":"code","38bc7a0a":"code","ca8d6e52":"code","3298c730":"code","4a153be6":"code","c2c6a322":"code","2cc6690a":"code","269d44c3":"code","8f47e369":"code","0ba792df":"markdown"},"source":{"d9c81d16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n# Any results you write to the current directory are saved as output.","1b8e97ec":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\n\nprint(df_train.shape)\nprint(df_test.shape)","a90a22fd":"df_train.info()","48d131f5":"df_null = pd.DataFrame(df_train.isnull().sum().tolist(),columns=['adet'])\ndf_null['columns'] = df_train.columns.tolist()\ndf_null['perc'] =(df_null.adet \/ df_train.shape[0] * 100).map(\"{:,.2f}\".format)\ndf_null.sort_values(by='adet', ascending=False)[df_null.adet > 0]","3f34745a":"df_train.drop(labels=['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'], axis=1, inplace=True)\n\nfor col in df_train.columns:\n    if df_train[col].dtypes != 'object':\n        if df_train[col].isnull().sum()>0:\n            df_train[col].fillna(value=df_train[col].mean(), inplace=True)    \n#do the same for df_test\ndf_test.drop(labels=['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'], axis=1, inplace=True)\n\nfor col in df_test.columns:\n    if df_test[col].dtypes != 'object':\n        if df_test[col].isnull().sum()>0:\n            df_test[col].fillna(value=df_test[col].mean(), inplace=True)   \n\n\n\n","51d44c5a":"from sklearn.preprocessing import OneHotEncoder\n\noht = OneHotEncoder()\n\n#check column types and if type=='object' get that. \nobj_col_list=[]\nfor col in df_train.columns:\n    if df_train[col].dtypes == 'object':\n        obj_col_list.append(col)\n        \ndf_ = pd.DataFrame(columns=obj_col_list)        \n\ndf_ = df_train[obj_col_list]\ndf_ = df_.append(df_test[obj_col_list], ignore_index=True)\n\ndf_ = pd.get_dummies(df_) #one hot encoder for all categorical columns.\n\n#after one hot encoder. we can write values to original dataframe\n\nfor col in obj_col_list:\n    df_train.drop(col, axis=1, inplace=True)\n    df_test.drop(col, axis=1, inplace=True)\n    \nfor col in df_.columns:\n    df_train[col] = df_[col].iloc[:df_train.shape[0]].values\n    df_test[col] = df_[col].iloc[-df_test.shape[0]:].values\n       \n    \nprint(df_train.shape)\nprint(df_test.shape)\nprint(df_.shape)","f9a0b3c7":"#drop Id columns in two dataframe\n\n#save ids for submission file\ntrain_ids = df_train['Id'].values\ntest_ids = df_test['Id'].values \n\ndf_train.drop('Id', axis=1, inplace=True)\ndf_test.drop('Id', axis=1, inplace=True)\n\ny = df_train.SalePrice\nx = df_train.drop('SalePrice', axis = 1)\nprint(y.shape)\nprint(x.shape)","38bc7a0a":"#split train data to test and train\ntrain_x = (x.values)[:int(x.shape[0] * 0.80),:]\ntest_x = (x.values)[int(x.shape[0] * 0.80):,:]\n\ntrain_y = (y.values)[:int(x.shape[0] * 0.80)]\ntest_y = (y.values)[int(x.shape[0] * 0.80):]\n\nprint(train_x.shape)\nprint(test_x.shape)\nprint(train_y.shape)\nprint(test_y.shape)","ca8d6e52":"#create model\nfrom sklearn.ensemble import GradientBoostingRegressor\n\ngbr = GradientBoostingRegressor(max_depth=10, n_estimators=1000, verbose=1,max_features='sqrt')\n\nmodel = gbr.fit(train_x, train_y)\n\nprint(\"%.2f\" % (model.score(test_x, test_y)*100) )","3298c730":"print(df_test.isnull().sum())\n#df_test.fillna(value=0, axis=0, inplace=True)\n#print(df_test.isnull().sum())","4a153be6":"preds = model.predict(df_test.values)","c2c6a322":"preds[:10]","2cc6690a":"example_submission = pd.read_csv('..\/input\/sample_submission.csv')\nexample_submission.head()","269d44c3":"submission = pd.DataFrame(index=range(df_test.shape[0]), columns=['Id','SalePrice'])\nsubmission.Id = test_ids\nsubmission.SalePrice = preds\n\nsubmission.head()","8f47e369":"submission.to_csv('submission.csv', index=False)","0ba792df":"There are so many null values in some columns like PoolQC, MiscFeature etc.\nWe can try fill this columns or just drop. And I select first 5 column in df_null for dropping. Others will be filled with mean. For categorical data we need to use like one hot encoder. But we have to dataset train and set, so one hot encoder converts  all categories to column. If we use one hot encode (or any encoder), we have to concat two dataset together before encoding, and fit after that. "}}