{"cell_type":{"d6cdcde2":"code","6b3dd949":"code","8f65e5e3":"code","3aa3b3ab":"code","f593cf69":"code","5b064d54":"code","0b18e23a":"code","46319e23":"code","45ccdf93":"code","e152504e":"code","84c86fb2":"code","354344ee":"code","28ea288a":"code","107adb13":"code","15392672":"code","4a8a8128":"code","4908c33a":"code","73219afe":"code","1ad043ad":"code","248f493a":"code","4d733797":"code","a083017a":"code","8d279336":"code","92f141f0":"code","6c41206e":"code","2cac9a7c":"code","f5994712":"code","101dea07":"code","6fb675a0":"code","0b072d78":"code","a2bf7500":"code","847d70ce":"code","f00b2ada":"code","e431f9b4":"code","5ef3bc9d":"code","bbedeb36":"code","a8a9b7bc":"code","3bf3521e":"code","6ba15166":"code","be0f9a4b":"code","bc4f4938":"code","fdf7f923":"code","78fe2df1":"code","fdc2ac4d":"code","8e3be8a1":"code","a4e8e0e4":"code","31d642a3":"code","6b8d7fd9":"code","c0a0cc73":"markdown"},"source":{"d6cdcde2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nX=pd.read_csv('..\/input\/titanic\/train.csv') #import data\nX.head()","6b3dd949":"X.info() #data information","8f65e5e3":"X=X.drop('Name',axis=1) #dropping Name as its of no use for EDA","3aa3b3ab":"X=X.drop('Cabin',axis=1) #dropping Cabin as its of no use for EDA","f593cf69":"X.isnull().sum() #checking null values","5b064d54":"#creating dummies for sex\ncat_var=X['Sex']\ncat_var=pd.get_dummies(cat_var,drop_first=True)\ncat_var.head()","0b18e23a":"X=pd.concat([X,cat_var],axis=1)\nX.head()","46319e23":"X=X.drop('Sex',axis=1)","45ccdf93":"X.corr()","e152504e":"import seaborn as sns","84c86fb2":"\nsns.catplot(data=X,x='Pclass',col='Survived',kind='count')\n","354344ee":"sns.pairplot(X, hue='Survived')","28ea288a":"X.head()","107adb13":"cat_var1=X['Embarked']\ncat_var1=pd.get_dummies(cat_var1,drop_first=True)\ncat_var1.head()","15392672":"X=pd.concat([X,cat_var1],axis=1)\nX.head()","4a8a8128":"X=X.drop('Embarked',axis=1) #dropping Embarked as its no of use for EDA\nX.head()","4908c33a":"X=X.drop('Ticket',axis=1)\nX.head()","73219afe":"Y=X['Survived']\nX=X.drop('Survived',axis=1)","1ad043ad":"X.isnull().sum()","248f493a":"X['Age'].fillna(X['Age'].mean(),inplace=True)\n","4d733797":"X.isnull().sum()","a083017a":"X=X.drop('PassengerId',axis=1)\nX.head()","8d279336":"#training the model\nfrom sklearn.model_selection import train_test_split","92f141f0":"X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=4)","6c41206e":"from sklearn.preprocessing import StandardScaler","2cac9a7c":"scaler=StandardScaler()\nscaler.fit(X_train)","f5994712":"scaled_X_train=scaler.transform(X_train)\nscaled_X_test=scaler.transform(X_test)","101dea07":"from sklearn.ensemble import RandomForestClassifier","6fb675a0":"clf=RandomForestClassifier(n_estimators=10,max_features='auto',random_state=4)\nclf.fit(scaled_X_train,y_train)","0b072d78":"y_pred=clf.predict(scaled_X_test)","a2bf7500":"from sklearn.metrics import confusion_matrix, classification_report","847d70ce":"confusion_matrix(y_test,y_pred)","f00b2ada":" print(classification_report(y_test,y_pred))","e431f9b4":"#grid search\nfrom sklearn.model_selection import GridSearchCV\n\nn_estimators=[20,60,80,100,120]\nmax_features=[2,3,4,5]\nbootstrap=[True, False]\n\ngrid_parameters={'n_estimators':n_estimators,\n                 'max_features':max_features,\n                'bootstrap':bootstrap}\nRandomForest_model=RandomForestClassifier()\ngrid_search=GridSearchCV(RandomForest_model,grid_parameters, cv=5 )","5ef3bc9d":"grid_search.fit(X_train,y_train)","bbedeb36":"grid_search.best_params_","a8a9b7bc":"y_pred=grid_search.predict(X_test)","3bf3521e":"y_pred","6ba15166":"confusion_matrix(y_test,y_pred)","be0f9a4b":"print(classification_report(y_test,y_pred))","bc4f4938":"#obb error\nRandomForest_model_oob=RandomForestClassifier(oob_score= True, max_features= 4, n_estimators= 80)\nRandomForest_model_oob.fit(X_train,y_train)","fdf7f923":"RandomForest_model_oob.oob_score_","78fe2df1":"df_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_test.head()\ndf_test=df_test.drop(['Name','Ticket','Cabin'],axis=1)\ndf_passengerID = df_test['PassengerId']\ndf_nume = df_test[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\nobj = df_test[['Sex','Embarked']]\nobj=pd.get_dummies(obj,drop_first=True)\ndf_test=pd.concat([df_nume,obj],axis=1)\ndf_test.head()\n\n","fdc2ac4d":"df_test[\"Age\"] = df_test[\"Age\"].fillna(np.mean(df_test[\"Age\"]), axis = 0)\ndf_test[\"Fare\"] = df_test[\"Fare\"].fillna(np.mean(df_test[\"Fare\"]), axis = 0)\ndf_test.isna().sum()","8e3be8a1":"Prediction = grid_search.predict(df_test)\nprint(Prediction)","a4e8e0e4":"Prediction = pd.DataFrame(Prediction)\nPrediction.columns = ['Survived']\nPrediction.head()","31d642a3":"Submission = pd.concat([df_passengerID, Prediction], axis = 1)\nSubmission.reset_index(drop=True)\nSubmission","6b8d7fd9":"Submission.to_csv('Submission.csv', index = False)","c0a0cc73":"## Formating the testing set"}}