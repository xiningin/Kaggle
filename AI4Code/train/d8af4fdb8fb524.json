{"cell_type":{"24ee074b":"code","703011df":"code","a59eb133":"code","f3f8ba6b":"code","292592f5":"code","7dcb1de1":"code","11774cc5":"code","c5b2231b":"code","40cdc653":"code","bcfd64ba":"code","8ca02c8a":"code","0bbbc0c8":"code","acee6ccb":"code","2675fd62":"code","1a520e84":"code","e897ca30":"code","c8083107":"code","73fe221f":"code","affc0e4d":"code","e5b424d7":"code","694e336d":"code","9c5acf9d":"code","335b03d9":"code","f579bcef":"code","281ba537":"code","235be484":"code","68d5fef7":"code","36c8f37d":"code","7ac8d2ce":"code","5de3b1b8":"markdown","65e4ef82":"markdown","5271df26":"markdown","a85b0805":"markdown","6839499a":"markdown","1512374d":"markdown","2492d87f":"markdown","af80674f":"markdown","f8501bd0":"markdown","6264152f":"markdown","b1bfe61b":"markdown"},"source":{"24ee074b":"import matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport re\nfrom bs4 import BeautifulSoup\n\nfrom gensim.parsing.preprocessing import remove_stopwords\nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split \n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nfrom nltk.stem import LancasterStemmer\nfrom nltk.tokenize import sent_tokenize, word_tokenize","703011df":"\nlancaster=LancasterStemmer()\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?:\/\/\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n    text = remove_stopwords(text)\n    token_words=word_tokenize(text)\n    token_words\n    stem_sentence=[]\n    for word in token_words:\n        stem_sentence.append(lancaster.stem(word))\n        stem_sentence.append(\" \")\n    return \"\".join(stem_sentence)\n    ","a59eb133":"FEATURE_WTS = {\n    'toxic': 0.32,\n    'severe_toxic': 1.5,\n    'obscene': 0.16, \n    'threat': 1.5,\n    'insult': 0.64,\n    'identity_hate': 1.5\n}\n\nFEATURES = list(FEATURE_WTS.keys())\nFEATURES","f3f8ba6b":"old_train = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv')\nold_train['y'] = 0\n\nold_train['y'] = old_train.loc[:, 'toxic':'identity_hate'].sum(axis=1)\n    \npos = old_train[old_train.y>0]\nneg = old_train[old_train.y==0].sample(len(pos), random_state=201)\nold_train = pd.concat([pos, neg])\nold_train","292592f5":"def read_old_test(): \n    df_test = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv')\n    df_test_labels = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test_labels.csv')\n    df = pd.merge(df_test, df_test_labels, how='left', on = 'id')\n    df = df.replace(-1, np.nan).dropna()\n    return df\n\nold_test = read_old_test()\nold_test['y'] = 0\n#for feat, wt in FEATURE_WTS.items(): \n#    old_test.y += wt * old_test[feat]\n#old_test.y = old_test.y \/ old_test.y.max()\nold_test['y'] = old_test.loc[:, 'toxic':'identity_hate'].sum(axis=1)\nold_test_pos = old_test[old_test.y>0]\n\ntrain = pd.concat([old_train, old_test_pos])","7dcb1de1":"train = train.drop('y', axis=1)\ntrain","11774cc5":"tqdm.pandas()\ntrain.comment_text = train.comment_text.progress_apply(text_cleaning)\ntrain","c5b2231b":"#vec = TfidfVectorizer(\n#        min_df=3, max_df=0.5, \n#        analyzer='char_wb', ngram_range = (3,5), \n#        lowercase=True, max_features=50000,\n#    )\n#X_train = vec.fit_transform(train['comment_text'])\n#y_train = train.loc[:, 'toxic':'identity_hate']","40cdc653":"vec = TfidfVectorizer(\n        max_df=0.5,\n        min_df=3,\n        lowercase=True, \n    )\nX_train = vec.fit_transform(train['comment_text'])\ny_train = train.loc[:, 'toxic':'identity_hate']","bcfd64ba":"#X_train, X_test, y_train, y_test = \\\n#    sklearn.model_selection.train_test_split(train['comment_text'], train.loc[:, 'toxic':'identity_hate'],\n#                                    test_size=0.20,\n#                                     random_state=0\n#                                    )\n\n#X_train = vec.fit_transform(X_train)\n#X_test = vec.transform(X_test)\n\n","8ca02c8a":"X_train,y_train","0bbbc0c8":"l_r = 0.005\n\ndef scheduler(epoch, lr):\n    return lr\/8\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n                    monitor='val_loss', min_delta=0.0001, patience=1, verbose=0,\n                    mode='auto', baseline=None, restore_best_weights=True\n                )\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\noptim = tf.keras.optimizers.Adam(learning_rate=l_r)\nmy_rnn = Sequential()\n\nmy_rnn.add(Dense(1200, activation='relu'))\nmy_rnn.add(Dense(200, activation='relu'))\nmy_rnn.add(Dense(36, activation='relu'))\nmy_rnn.add(Dense(6))\nmy_rnn.compile(loss=\"mse\", optimizer=optim, metrics=[\"mse\"])","acee6ccb":"with tf.device('\/CPU:0'):\n    model_info = my_rnn.fit(X_train.toarray(),\n                            y_train, epochs=10,\n                            batch_size=30,\n                            verbose=1,\n                            validation_split=0.2,\n                           callbacks=[lr_scheduler,early_stop])","2675fd62":"#print(\"Evaluate on test data\")\n#with tf.device('\/CPU:0'):\n#    results = my_rnn.evaluate(X_test.toarray(), y_test, batch_size=50)\n#print(\"test loss, test mse:\", results)","1a520e84":"with tf.device('\/CPU:0'):\n    print(my_rnn.predict(X_train.toarray()[0:1]))","e897ca30":"val = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')","c8083107":"val","73fe221f":"val['less_toxic'] = val['less_toxic'].progress_apply(text_cleaning)\nval['more_toxic'] = val['more_toxic'].progress_apply(text_cleaning)","affc0e4d":"val","e5b424d7":"lt_vec = vec.transform(val['less_toxic'])\nmt_vec = vec.transform(val['more_toxic'])","694e336d":"with tf.device('\/CPU:0'):\n    p1 = my_rnn.predict(lt_vec.toarray())\n    p2 = my_rnn.predict(mt_vec.toarray())\n","9c5acf9d":"p1","335b03d9":"f = np.array(list(FEATURE_WTS.values()))\nf","f579bcef":"p2","281ba537":"f1 = np.array([sum(row) for row in f*p1])\nf1","235be484":"f2 = np.array([sum(row) for row in f*p2])\nf2","68d5fef7":"(f1<f2).mean()","36c8f37d":"sub = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv')\nsub.text = sub.text.progress_apply(text_cleaning)\np = my_rnn.predict(vec.transform(sub.text).toarray())\nsub['score'] = np.array([sum(row) for row in f*p])\nsub","7ac8d2ce":"sub[['comment_id', 'score']].to_csv('submission.csv', index=False)","5de3b1b8":"## Strat\u00e9gie regression sur le vecteur donn\u00e9 directement dans le jeu d'entrainement. Puis application des scores sur la pr\u00e9diction.","65e4ef82":"### Get train datasets and pick only a sample of non toxic comments","5271df26":"### Features weights","a85b0805":"### Building rnn and callbacks","6839499a":"### Validation ...","1512374d":"### Cleaning text","2492d87f":"### Cleaning...","af80674f":"### Add the old dataset","f8501bd0":"## Prepare submission","6264152f":"### Choose a vectorizer (second is for testing)","b1bfe61b":"### Drop y"}}