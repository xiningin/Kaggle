{"cell_type":{"c555caa2":"code","c82657e1":"code","1df8b67b":"code","99e2180c":"code","e3734154":"code","959da381":"code","7edb4280":"code","5b46f57c":"code","d998850e":"code","d89eb73c":"code","30a56e05":"code","078c31de":"code","6ba92429":"code","3bcfd55d":"code","775806a5":"code","d0cc822f":"code","3c80b839":"code","d43ad9de":"code","48c347a2":"code","6bcab634":"code","f33a8f45":"code","a825b630":"code","ef6f6f71":"code","0bd3370b":"code","a33dbe4c":"code","8a97023f":"code","db45bf58":"code","01f1255d":"code","f2d16602":"code","af1f5d3f":"code","6d91ddb9":"code","01f2789a":"code","1f51a890":"code","9df85fef":"code","12205466":"code","eadd04c3":"code","4d884c95":"code","2b8481cc":"code","a10e940a":"code","9749ea81":"code","bfc36ab6":"code","f45a1123":"code","6692b8a1":"code","58632dcb":"code","e5d9b5e6":"code","82ef78a1":"code","52e0f556":"code","13e3f76f":"code","83eef4a6":"code","4ca694c8":"code","c24e82c1":"code","e689d9f9":"code","ef47b703":"code","5f5553b4":"code","c88baf7f":"code","b49fb139":"code","7fa34538":"code","7ec8aaaf":"code","2c1e89fd":"code","3815a4f6":"code","13049829":"code","99f32dfd":"code","8dc15c57":"code","80574ac7":"code","42db187d":"code","d70256db":"code","b1a9deef":"code","4df4ba9c":"code","1b54f9c6":"code","0be1e76e":"code","e2c4a56b":"code","b11255e5":"code","4f16b0e9":"code","440be5eb":"code","cb3ba7d5":"code","db176c41":"code","7fd8cacf":"code","da4c5501":"code","97bb1bae":"code","2815b643":"code","dd4547c7":"code","050a1ab8":"code","91e8130c":"code","6db7e03f":"code","561e2f1b":"code","ef987c94":"code","6a8cf9c4":"code","00899271":"code","8a5b41ad":"code","165697e6":"code","030b9d74":"code","3f6eee75":"code","d85ebba9":"code","9cf31a6e":"code","49b873ae":"code","8ffdbb11":"code","b45669e1":"code","e19195a3":"code","a496f4a4":"code","bd3192d1":"code","fb40fa19":"markdown","a7a3e751":"markdown","76069407":"markdown","20624b3c":"markdown","30dd30f9":"markdown","13c20fde":"markdown","b4c9a88a":"markdown","2ec161d3":"markdown","9c125db0":"markdown","4abf14e4":"markdown","ce36a052":"markdown","a83bf625":"markdown","59d74b23":"markdown","76a25ae3":"markdown","ce03972e":"markdown","d7433e61":"markdown","a483705c":"markdown","d1874569":"markdown","b7a93a3b":"markdown","37c896eb":"markdown","b75abbf1":"markdown","c96f8ebd":"markdown","094bd6fd":"markdown","b9819b86":"markdown","26b90f05":"markdown","a211cf33":"markdown","04243fe1":"markdown","e7fa9c12":"markdown","d9130a72":"markdown","c50809ef":"markdown","bbbc49d7":"markdown","a6dfaa62":"markdown","620ae49f":"markdown","d48933bd":"markdown","dbdca4ab":"markdown","3210a2f8":"markdown","85ce0339":"markdown","105222ce":"markdown","e9d59f24":"markdown","05183ec5":"markdown","ae9939b7":"markdown","e88af2ac":"markdown","3274a101":"markdown","256e28d4":"markdown","f3873650":"markdown","3e5d8e47":"markdown","5830b27e":"markdown","73eb2d3d":"markdown","2de9aadf":"markdown","973af2c2":"markdown","7eaf825f":"markdown","7d8aeeab":"markdown","51b5d357":"markdown","1ca77b26":"markdown"},"source":{"c555caa2":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","c82657e1":"df=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","1df8b67b":"df.head()","99e2180c":"df.info()","e3734154":"df.columns","959da381":"df.describe","7edb4280":"df.shape","5b46f57c":"df.corr()['SalePrice'].sort_values()","d998850e":"sns.scatterplot(data=df,x='OverallQual', y='SalePrice')\nplt.axhline(y=200000,color='r')\nplt.axhline(y=650000,color='r')","d89eb73c":"df[(df['OverallQual']>8) & (df['SalePrice']<200000)][['SalePrice', 'OverallQual']]\n","30a56e05":"df[(df['OverallQual']>8) & (df['SalePrice']>650000)][['SalePrice', 'OverallQual']]","078c31de":"sns.scatterplot(data=df,x='GrLivArea', y='SalePrice')\nplt.axhline(y=200000, color='r')\nplt.axvline(x=4000, color='r')","6ba92429":"df[(df['GrLivArea']>4000) & (df['SalePrice']>200000)][['SalePrice', 'GrLivArea']]","3bcfd55d":"sns.scatterplot(data=df,x='GarageCars', y='SalePrice')\nplt.axhline(y=650000, color='r')\n","775806a5":"df[df['SalePrice']>650000][['SalePrice', 'GarageCars']]","d0cc822f":"\nindex_drop=df[df['SalePrice']>650000 ].index\ndf=df.drop(index_drop, axis=0)\nindex_drop1=df[(df['OverallQual']>8) & (df['SalePrice']<200000)].index\ndf=df.drop(index_drop1, axis=0)","3c80b839":"df.corr()['SalePrice'].sort_values()","d43ad9de":"df=df.drop('Id',axis=1)","48c347a2":"df.isnull().sum().sort_values()","6bcab634":"100*(df.isnull().sum()\/len(df)).sort_values()","f33a8f45":"def missing_percent(df):\n    nan_percent= 100*(df.isnull().sum()\/len(df))\n    nan_percent= nan_percent[nan_percent>0].sort_values()\n    return nan_percent","a825b630":"nan_percent= missing_percent(df)\nnan_percent","ef6f6f71":"plt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)","0bd3370b":"plt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)\n#Set 1% threshold:\nplt.ylim(0,1)","a33dbe4c":"#columns with missing Data under 1%:\nnan_percent[nan_percent<1]","8a97023f":"100\/len(df)","db45bf58":"df[df['Electrical'].isnull()]['Electrical']","01f1255d":"df=df.dropna(axis=0, subset=['Electrical'])","f2d16602":"nan_percent= missing_percent(df)\nplt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)\n#Set 1% threshold:\nplt.ylim(0,1)","af1f5d3f":"df['MasVnrType']= df['MasVnrType'].fillna('None')\ndf['MasVnrArea']= df['MasVnrArea'].fillna(0)","6d91ddb9":"nan_percent= missing_percent(df)\nplt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)","01f2789a":"bsm=['BsmtQual','BsmtCond','BsmtFinType1','BsmtExposure','BsmtFinType2']\nfor i in bsm:\n    print(type(i))","1f51a890":"df[bsm]=df[bsm].fillna('None')\n","9df85fef":"nan_percent= missing_percent(df)\nplt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)","12205466":"garage=['GarageType','GarageFinish','GarageQual','GarageCond']\ndf[garage]=df[garage].fillna('None')","eadd04c3":"df['GarageYrBlt']=df['GarageYrBlt'].fillna(value=df['GarageYrBlt'].mean())","4d884c95":"nan_percent= missing_percent(df)\nplt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)","2b8481cc":"plt.figure(figsize=(8,12))\nsns.boxplot(data=df, x='LotFrontage', y='Neighborhood')","a10e940a":"df.groupby('Neighborhood')['LotFrontage'].mean()","9749ea81":"df['LotFrontage']=df.groupby('Neighborhood')['LotFrontage'].transform(lambda val: val.fillna(val.mean()))","bfc36ab6":"nan_percent= missing_percent(df)\nplt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)","f45a1123":"df['FireplaceQu']= df['FireplaceQu'].fillna('None')","6692b8a1":"nan_percent= missing_percent(df)\nplt.figure(figsize=(12,6),dpi=200)\nsns.barplot(x=nan_percent.index,y=nan_percent)\nplt.xticks(rotation=90)","58632dcb":"df=df.drop(['Fence','Alley','MiscFeature','PoolQC'],axis=1)","e5d9b5e6":"nan_percent= missing_percent(df)\nnan_percent","82ef78a1":"df['MSSubClass']","52e0f556":"df.info()\n","13e3f76f":"df['MSSubClass'].unique()","83eef4a6":"df['MSSubClass']= df['MSSubClass'].apply(str)","4ca694c8":"df.info()","c24e82c1":"df.select_dtypes(include='object')","e689d9f9":"df_num= df.select_dtypes(exclude='object')\ndf_obj= df.select_dtypes(include='object')","ef47b703":"df_num.info()","5f5553b4":"df_obj.info()","c88baf7f":"# Converting:\ndf_obj= pd.get_dummies(df_obj, drop_first=True)","b49fb139":"df_obj.shape","7fa34538":"Final_df= pd.concat([df_num, df_obj], axis=1)\nFinal_df.head()","7ec8aaaf":"Final_df.info()","2c1e89fd":"from scipy.stats import norm\nplt.figure(figsize=(12,6))\nsns.displot(Final_df['SalePrice'])\nplt.figure(figsize=(12,6))\nsns.displot(Final_df['SalePrice'],color='purple',bins=50)\nplt.axvline(x=(Final_df['SalePrice'].mean()), color='r')","3815a4f6":"Final_df['SalePrice'] = np.log1p(Final_df['SalePrice'])","13049829":"from scipy.stats import norm\nplt.figure(figsize=(12,6))\nsns.displot(Final_df['SalePrice'])\nplt.figure(figsize=(12,6))\nsns.displot(Final_df['SalePrice'],color='purple')\nplt.axvline(x=(Final_df['SalePrice'].mean()), color='r')","99f32dfd":"X=Final_df.drop('SalePrice',axis=1)\ny=Final_df['SalePrice']","8dc15c57":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","80574ac7":"from sklearn.linear_model import LinearRegression\nmodel=LinearRegression()\nmodel.fit(X_train, y_train)\npd.DataFrame(model.coef_ , X.columns ,columns=['coefcient'])","42db187d":"y_pred= model.predict(X_test)\npd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred})[:5]","d70256db":"from sklearn import metrics\nMAE_linear=metrics.mean_absolute_error(y_test , y_pred)\nMSE_linear=metrics.mean_squared_error(y_test , y_pred)\nRMSE_linear=np.sqrt(MSE_linear)\npd.DataFrame([MAE_linear,MSE_linear,RMSE_linear], index=['MAE_linear','MSE_linear','RMSE_linear'],columns=['Quantity'])\n","b1a9deef":"\ntest_residual=y_test-y_pred\nsns.scatterplot(x=y_test,y=y_pred,color='purple' ,s=200)\nplt.ylabel('y_pred')\nplt.xlabel('y_test')\nplt.title('bias of y')","4df4ba9c":"sns.scatterplot(x=y_test,y=test_residual,s=200)\nplt.axhline(y=0,color='red',ls='--')","1b54f9c6":"X=Final_df.drop('SalePrice',axis=1)\ny=Final_df['SalePrice']","0be1e76e":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_converter=PolynomialFeatures(degree=2, include_bias=False)\npoly_features=polynomial_converter.fit(X)\npoly_features=polynomial_converter.transform(X)\n","e2c4a56b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)","b11255e5":"from sklearn.linear_model import LinearRegression\npolymodel=LinearRegression()\npolymodel.fit(X_train, y_train)","4f16b0e9":"y_pred=polymodel.predict(X_test)\npd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred, 'Residuals':(y_test-y_pred) }).head(5)\n","440be5eb":"from sklearn import metrics\nMAE_Poly = metrics.mean_absolute_error(y_test,y_pred)\nMSE_Poly = metrics.mean_squared_error(y_test,y_pred)\nRMSE_Poly = np.sqrt(MSE_Poly)\n\npd.DataFrame([MAE_Poly, MSE_Poly, RMSE_Poly], index=['MAE_Poly', 'MSE_Poly', 'RMSE_Poly'], columns=['metrics'])\n","cb3ba7d5":"del df","db176c41":"# Adjusting Model Parameters\n# Train List of RMSE per degree\ntrain_RMSE_list=[]\n#Test List of RMSE per degree\ntest_RMSE_list=[]\n\nfor d in range(1,3):\n    \n    #Preprocessing\n    #create poly data set for degree (d)\n    polynomial_converter= PolynomialFeatures(degree=d, include_bias=False)\n    poly_features= polynomial_converter.fit(X)\n    poly_features= polynomial_converter.transform(X)\n    \n    #Split the dataset\n    X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n    \n    #Train the Model\n    polymodel=LinearRegression()\n    polymodel.fit(X_train, y_train)\n    \n    #Predicting on both Train & Test Data\n    y_train_pred=polymodel.predict(X_train)\n    y_test_pred=polymodel.predict(X_test)\n    \n    #Evaluating the Model\n    \n    #RMSE of Train set\n    train_RMSE=np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n    \n    #RMSE of Test Set\n    test_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n      #Append the RMSE to the Train and Test List\n    \n    train_RMSE_list.append(train_RMSE)\n    test_RMSE_list.append(test_RMSE)","7fd8cacf":"pd.DataFrame({'train_RMSE_list': train_RMSE_list,'test_RMSE_list':test_RMSE_list})","da4c5501":"#**Plot the Polynomial degree VS RMSE**\n\nplt.plot(range(1,3), train_RMSE_list[:13], label='Train RMSE')\nplt.plot(range(1,3), test_RMSE_list[:13], label='Test RMSE')\n\nplt.xlabel('Polynomial Degree')\nplt.ylabel('RMSE')\nplt.legend()","97bb1bae":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_converter= PolynomialFeatures(degree=1, include_bias=False)\npoly_features= polynomial_converter.fit_transform(X)","2815b643":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)","dd4547c7":"from sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\nscaler.fit(X_train)\nX_train= scaler.transform(X_train)\nX_test= scaler.transform(X_test)","050a1ab8":"from sklearn.linear_model import Ridge\nridge_model= Ridge(alpha=10)\nridge_model.fit(X_train, y_train)","91e8130c":"y_pred= ridge_model.predict(X_test)","6db7e03f":"from sklearn.metrics import mean_absolute_error, mean_squared_error\n\nMAE_Ridge= mean_absolute_error(y_test, y_pred)\nMSE_Ridge= mean_squared_error(y_test, y_pred)\nRMSE_Ridge= np.sqrt(MSE_Ridge)\npd.DataFrame([MAE_Ridge, MSE_Ridge, RMSE_Ridge], index=['MAE_Ridge', 'MSE_Ridge', 'RMSE_Ridge'], columns=['metrics'])","561e2f1b":"from sklearn.linear_model import RidgeCV\nridge_cv_model=RidgeCV(alphas=(0.1, 1.0, 10.0), scoring='neg_mean_absolute_error')\nridge_cv_model.fit(X_train, y_train)","ef987c94":"ridge_cv_model.alpha_","6a8cf9c4":"y_pred_ridge= ridge_cv_model.predict(X_test)","00899271":"MAE_ridge= mean_absolute_error(y_test, y_pred_ridge)\nMSE_ridge= mean_squared_error(y_test, y_pred_ridge)\nRMSE_ridge= np.sqrt(MSE_ridge)\npd.DataFrame([MAE_ridge, MSE_ridge, RMSE_ridge], index=['MAE_ridge_CV', 'MSE_ridge_CV', 'RMSE_ridge_CV'], columns=['Ridge Metrics'])","8a5b41ad":"ridge_cv_model.coef_","165697e6":"from sklearn.linear_model import LassoCV\nlasso_cv_model= LassoCV(eps=0.01, n_alphas=100, cv=5)\nlasso_cv_model.fit(X_train, y_train)","030b9d74":"lasso_cv_model.alpha_","3f6eee75":"y_pred_lasso= lasso_cv_model.predict(X_test)\nMAE_Lasso= mean_absolute_error(y_test, y_pred_lasso)\nMSE_Lasso= mean_squared_error(y_test, y_pred_lasso)\nRMSE_Lasso= np.sqrt(MSE_Lasso)","d85ebba9":"pd.DataFrame([MAE_Lasso, MSE_Lasso, RMSE_Lasso], index=['MAE_Lasso', 'MSE_Lasso', 'RMSE_Lasso'], columns=['Lasso Metrics'])","9cf31a6e":"lasso_cv_model.coef_","49b873ae":"from sklearn.linear_model import ElasticNetCV\nelastic_model= ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],cv=5, max_iter=100000)\nelastic_model.fit(X_train, y_train)","8ffdbb11":"elastic_model.l1_ratio_","b45669e1":"y_pred_elastic=elastic_model.predict(X_test)","e19195a3":"MAE_Elastic= mean_absolute_error(y_test, y_pred_elastic)\nMSE_Elastic= mean_squared_error(y_test, y_pred_elastic)\nRMSE_Elastic= np.sqrt(MSE_Elastic)","a496f4a4":"pd.DataFrame([MAE_Elastic, MSE_Elastic, RMSE_Elastic], index=['MAE_Elastic', 'MSE_Elastic', 'RMSE_Elastic'], columns=['Elastic Metrics'])","bd3192d1":"elastic_model.coef_","fb40fa19":"<h3>Import all necessary libraries<\/h3>","a7a3e751":"# **Import the dataset:**","76069407":"<h4>In this notbook I want to do  following steps for an Advance Price Prediction:<\/h4>\n\n* [Data overview](#Over)\n* [Data prepration](#Prep)\n    - [Handling Outliers](#outliers)\n    - [Handling Missing Data](#mis)\n* [Linear Reggresion](#Lin)\n* [polynomial Regression](#Pol)\n* [Regularization](#Reg)\n    - [Ridge](#Ridge)\n    - [Lasso](#Lasso)\n    - [ElasticNet](#Elas)\n\n","20624b3c":"<a id=\"Elas\"><\/a>\n# Elastic Net\n","30dd30f9":"<h4>Train the Model<\/h4>","13c20fde":"Cleaning the Id columns because it doesnt have important information.\n","b4c9a88a":"<a id=\"Over\"><\/a>\n# Data overview","2ec161d3":"<b>There is no more missing Data<\/b>","9c125db0":"It shows Electrical has got just 1 row missing Data.","4abf14e4":"<h3>Split the Dataset to Train & Test<\/h3>","ce36a052":"<a id=\"Prep\"><\/a>\n# Data Preparation","a83bf625":"<a id=\"Lin\"><\/a>\n# Linear Regression model","59d74b23":"<h3>Determine the Features & Target Variable<\/h3>","76a25ae3":"<h4>Evaluating the Model<\/h4>","ce03972e":"<h4>Preprocessing<\/h4>","d7433e61":"<h3>Split the Data to Train & Test<\/h3>","a483705c":"<h3>Changing Numerical Columns to Categorical<\/h3>","d1874569":"<h3>number of missing Data in each columns:<\/h3>\n","b7a93a3b":"<h3> Preprocessing<\/h3>\n","37c896eb":"<h3>removing the row with missing Data of Electrical:\n<\/h3>","b75abbf1":"<h4>Predicting Test Data<\/h4>","c96f8ebd":"<h3>Make a Function to calculate the percent of missing data in each columns (feature) and then sort it<\/h3>","094bd6fd":"<h3>replace the amount of missing Data with mean of the GarageYrBlt:<\/h3>","b9819b86":"<b>Remove the outliers:<\/b>","26b90f05":"<a id=\"outliers\"><\/a>\n# A- Dealing with Outliers","a211cf33":"<h4>Split the Data to Train & Test<\/h4>","04243fe1":"finding outliers","e7fa9c12":"<a id=\"Lasso\"><\/a>\n# Lasso\n","d9130a72":"<h4>predict Test Data<\/h4>","c50809ef":"<h3>Determine the Features & Target Variable<\/h3>","bbbc49d7":"<h3>Convert to String:<\/h3>","a6dfaa62":"<h4>Scaling the Data<\/h4>","620ae49f":"<h3> Train the Model<\/h3>\n","d48933bd":"<a id=\"mis\"><\/a>\n# B-Dealing with Missing Data","dbdca4ab":"<h3>Train the Model<\/h3>\n","3210a2f8":"<h3>We need to make this normal distributed.<\/h3>","85ce0339":"<h3>It shows polynomial can't help to redious errores<\/h3>","105222ce":"<h3> Creating Dummy Variables:<\/h3>\n","e9d59f24":"#### Now, the Dataset is Ready for any Machine Learing Model & Analysis","05183ec5":"<h3>Dealing with Categorical Data<\/h3\n","ae9939b7":"<h3>predicting Test Data<\/h3>","e88af2ac":"<h3> Evaluating the Model<\/h3>","3274a101":"<h4>Coosing an alpha value with Cross-Validation<\/h4>","256e28d4":"<h3>The percent of missing data in any feature:<\/h3>","f3873650":"<h3>Residuals:<\/h3>\n","3e5d8e47":"<a id=\"Reg\"><\/a>\n# Regularization:\n","5830b27e":"<a id=\"Pol\"><\/a>\n# Polynomial Regression model","73eb2d3d":"<h3>filling a missing Data with 0 for integer feature and None for object one:<\/h3>","2de9aadf":"<h3> Predicting Test Data<\/h3>\n","973af2c2":"<h3>The index of a row with missing Data of Electrical:<\/h3>","7eaf825f":"<h4>Train the Model<\/h4>","7d8aeeab":"<h3>Evaluating the Model<\/h3>\n","51b5d357":"<h3> As we see ,the residuals show a clear pattern.so we can say,linear regression is not suitable for this model.<\/h3>","1ca77b26":"<a id=\"Ridge\"><\/a>\n# Ridge \n"}}