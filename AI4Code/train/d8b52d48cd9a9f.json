{"cell_type":{"dcdfd0fe":"code","ec31b570":"code","f8c3ede2":"code","8b9f3b6e":"code","05299ba7":"code","3468a1a3":"code","c85ce9d5":"code","3742b4b8":"code","26b1ad87":"markdown","123e5d49":"markdown","24b27b71":"markdown","c9929f95":"markdown","76e23e7b":"markdown","475681c4":"markdown","bb788843":"markdown"},"source":{"dcdfd0fe":"import pandas as pd\nimport numpy as np","ec31b570":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\n\ncolumn_names = [ 'age', 'workclass', 'fnlwgt', 'education', 'education.num', \n                'marital.status', 'occupation', 'relationship', 'race', \n                'sex', 'capital.gain', 'capital.loss', 'hour.per.week', \n                'native.country', 'income' ]\n\ncolumns_to_encoding = [ 'workclass', 'marital.status', 'occupation',\n                        'relationship', 'race', 'sex' ]\n\ncolumns_to_normalize = [ 'age', 'education.num', 'hour.per.week', \n                         'capital.gain', 'capital.loss' ]\n\nle = LabelEncoder()\nscaler = StandardScaler()\npl = PolynomialFeatures(2, include_bias=False)\n\ndef feature_engineering(filename, train=True):\n    df = pd.read_csv(filename, index_col=False, names=column_names)\n    df.drop(['fnlwgt', 'education', 'native.country'], axis=1, inplace=True)\n    df = pd.get_dummies(df, columns=columns_to_encoding)\n    df[\"income\"] = le.fit_transform(df['income'])\n    if train:\n        X_temp = pl.fit_transform(df[columns_to_normalize])\n        X_temp = scaler.fit_transform(X_temp)\n        df.drop(columns_to_normalize, axis=1, inplace=True)\n        X_train = np.hstack((df.values, X_temp))\n        y_train = df['income']\n        return df, X_train, y_train\n    else:\n        X_temp = pl.transform(df[columns_to_normalize])\n        X_temp = scaler.transform(X_temp)\n        df.drop(columns_to_normalize, axis=1, inplace=True)\n        X_test = np.hstack((df.values, X_temp))\n        y_test = df['income']\n        return df, X_test, y_test","f8c3ede2":"df_train, X_train, y_train = feature_engineering('..\/input\/adult.data', train=True)\ndf_test, X_test, y_test = feature_engineering('..\/input\/adult.test', train=False)","8b9f3b6e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nparam_distribution = {\n    'C': np.arange(1, 15),\n}\n\nscoring = {    \n    'Accuracy': make_scorer(accuracy_score),\n    'F1_Score': make_scorer(fbeta_score, beta=1),    \n}\n\nresult = []","05299ba7":"result = []\nfor i in range(1, 13):\n    # train\n    pca = PCA(i)\n    X_t = pca.fit_transform(X_train)\n    search_cv = RandomizedSearchCV(LogisticRegression(solver='lbfgs'), param_distribution,\n                                   scoring=scoring, n_jobs=-1, \n                                   cv=StratifiedKFold(n_splits=10, shuffle=True), \n                                   refit='F1_Score') \n    search_cv.fit(X_t, y_train.values)\n    model = search_cv.best_estimator_\n\n    # test\n    X_t = pca.transform(X_test)\n    y_pred = model.predict(X_t)\n    \n    # model evaluation\n    f1 = fbeta_score(y_test.values, y_pred, beta=1)\n    acc = accuracy_score(y_test.values, y_pred)\n    print(f\"{i} {acc} {f1}\")\n    \n    result.append((i, acc, f1, pca, model))","3468a1a3":"best_f1 = 0\nbest_model = None\nfor n, acc, f1, pca, model in result:\n    if best_f1 < f1:\n        best_f1 = f1\n        best_model=(n, acc, f1, pca, model)\nbest_model","c85ce9d5":"from sklearn import metrics\n\npca, model = best_model[-2], best_model[-1]\nprobs = model.predict_proba(pca.transform(X_test))\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","3742b4b8":"from sklearn.externals import joblib\n\njoblib.dump(best_model, 'lgr.joblib')","26b1ad87":"# Save Best Model","123e5d49":"# Interface function to feature engineering data","24b27b71":"# Load Data","c9929f95":"# Get Best Model","76e23e7b":"# Import Base Packages","475681c4":"# Analyse Model Result","bb788843":"# Find Best number of components to PCA"}}