{"cell_type":{"ca5f9c4b":"code","890c76a7":"code","c67b3afe":"code","8101c44a":"code","d22ec69f":"code","dcd76d3e":"code","ff2d99bf":"code","85527aa5":"code","a072fe7b":"code","0056f62b":"code","71558633":"code","52fcc0d6":"markdown","e9b92f4c":"markdown","14e86e4a":"markdown","722dce94":"markdown","9029eb0e":"markdown"},"source":{"ca5f9c4b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","890c76a7":"train_data = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntrain_data.head()","c67b3afe":"y=train_data.target\nX=train_data.drop(['id','target'],axis=1)\nX.head()","8101c44a":"numerical_cols=[cname for cname in X.columns if X[cname].dtype in ['int64','float64','int']]\nnumerical_cols","d22ec69f":"categorical_cols=[cname for cname in X.columns if X[cname].dtype =='object']\ncategorical_cols","dcd76d3e":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nnumerical_transformer = Pipeline(steps=[\n    ('scale', StandardScaler()),\n    ('impute',SimpleImputer(strategy=\"median\"))\n])\n\ncategorical_transformer = Pipeline(steps = [\n    ('imputer',SimpleImputer(strategy='constant')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor=ColumnTransformer(transformers=[\n    ('num',numerical_transformer,numerical_cols),\n    \n    ('cat',categorical_transformer,categorical_cols),\n     \n])\nmodel=XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0)\nmy_regressor=Pipeline(steps=[\n    ('preprocessor',preprocessor),\n    ('model',model)\n])","ff2d99bf":"my_regressor.fit(X,y)","85527aa5":"X_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\nuid=X_test.id\nX_test.drop(['id'],axis=1,inplace=True)\nX_test.head()","a072fe7b":"preds_test=my_regressor.predict(X_test)\npreds_test","0056f62b":"# Save test predictions to file\noutput = pd.DataFrame({'id': uid,\n                       'target': preds_test})\noutput.to_csv('submission_1.csv', index=False)","71558633":"output.head()","52fcc0d6":"Train the model","e9b92f4c":"# Simple baseline model for beginners using sklearn pipeline","14e86e4a":"Import the test test and create submission file.","722dce94":"Get a list of numerical and categorical columns","9029eb0e":"Create sklearn pipeline"}}