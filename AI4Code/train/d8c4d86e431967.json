{"cell_type":{"135f0cee":"code","603ad9e8":"code","63fe8546":"code","c18d020c":"code","2c4e4a5b":"code","9c9fb67b":"code","3b23ae44":"code","b57bccc4":"code","19bae76e":"code","d4308c40":"code","a3fa7a5b":"code","6ba6c70e":"code","336ded34":"code","4dcea844":"code","0524e0a4":"code","ed6e3842":"code","c304a321":"code","27d9b85e":"code","be4ed6a6":"code","c34cab41":"code","0436b0a8":"code","a06a9bcd":"code","82145e9a":"code","94714d9d":"code","276b5c9b":"code","7dd4519f":"code","c020d569":"code","35fd3cb1":"code","f5b78de9":"code","62245fbd":"code","9bd7dd60":"code","a2385c00":"code","713749e8":"code","cfe294a8":"code","17e7fe54":"code","cfd27a0c":"code","a9d3a35d":"code","1654c38c":"code","39dbf925":"code","ece8c974":"code","904d219a":"code","c189b085":"code","980e202e":"markdown","bc988fb5":"markdown","aa6a30b7":"markdown","6ea6a8ec":"markdown","4069a0f5":"markdown","479c3509":"markdown","780b3ac7":"markdown"},"source":{"135f0cee":"# !pip install imutils\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport pydicom as dicom\nimport matplotlib.pylab as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom skimage import measure\n# ipywidgets for some interactive plots\nfrom ipywidgets.widgets import * \nimport ipywidgets as widgets\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras import layers\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping\nimport plotly.express as px\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\nfrom keras.utils import np_utils\nfrom sklearn.metrics import accuracy_score\nimport gc","603ad9e8":"sample_submission_file = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\ntrain_data_labels = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')","63fe8546":"print('Shape of train data:', train_data_labels.shape)\ntrain_data_labels.head()","c18d020c":"print('Number of image folders:', len(os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train')))","2c4e4a5b":"set1 = set(os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train'))\nset2 = set(train_data_labels['BraTS21ID'].unique())\nprint('Intersection between IDs in train data labels file and train data folders:', len(set1.intersection(set2)))","9c9fb67b":"# Convert folder IDs to numbers\nset1 = set([int(x) for x in list(set1)])\nprint('Intersection between IDs in train data labels file and train data folders:', len(set1.intersection(set2)))","3b23ae44":"print('Shape of test data:', sample_submission_file.shape)\nsample_submission_file.head()","b57bccc4":"# FLAIR\n# specify your image path\n# using images of a patient with brain tumor\nimage_path = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/FLAIR\/Image-101.dcm'\nds = dicom.dcmread(image_path)\n\nplt.imshow(ds.pixel_array)","19bae76e":"# T1w\nimage_path = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T1w\/Image-11.dcm'\nds = dicom.dcmread(image_path)\n\nplt.imshow(ds.pixel_array)","d4308c40":"# T1wCE\nimage_path = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T1wCE\/Image-101.dcm'\nds = dicom.dcmread(image_path)\n\nplt.imshow(ds.pixel_array)","a3fa7a5b":"# T2w\nimage_path = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T2w\/Image-101.dcm'\nds = dicom.dcmread(image_path)\n\nimg = ds.pixel_array\n\nplt.imshow(img)","6ba6c70e":"ds.pixel_array","336ded34":"ds","4dcea844":"# The unit of measurement in CT scans is the Hounsfield Unit (HU), which is a measure of radiodensity. CT scanners are carefully calibrated to accurately measure this\n# Load the scans in given folder path\ndef load_scan(path):\n    slices = [dicom.read_file(path + '\/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2])) # Sort by patient's position while scan was taken\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n    return slices\n        \n    return slices","0524e0a4":"def get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)","ed6e3842":"path = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/FLAIR\/'\n\n# slide through dicom images using a slide bar \nplt.figure(1)\ndef dicom_animation(x):\n    first_patient = load_scan(path)\n    first_patient_pixels = get_pixels_hu(first_patient)\n    plt.hist(first_patient_pixels.flatten(), bins=80, color='c')\n    plt.xlabel(\"Hounsfield Units (HU)\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n    # Show some slice in the middle\n    # cmap=plt.cm.gray\n    plt.imshow(first_patient_pixels[x], cmap=plt.cm.bone)\n    plt.show()\n    return x\ninteract(dicom_animation, x=(0, len(os.listdir(path))-1))","c304a321":"first_patient = load_scan(path)\nfirst_patient_pixels = get_pixels_hu(first_patient)\n\ndef sample_stack(stack, rows=6, cols=6, start_with=10, show_every=3):\n    fig,ax = plt.subplots(rows,cols,figsize=[12,12])\n    for i in range(rows*cols):\n        ind = start_with + i*show_every\n        ax[int(i\/rows),int(i % rows)].set_title('slice %d' % ind)\n        ax[int(i\/rows),int(i % rows)].imshow(stack[ind],cmap='gray')\n        ax[int(i\/rows),int(i % rows)].axis('off')\n    plt.show()\n\nsample_stack(first_patient_pixels)","27d9b85e":"def resize_scan(scan, new_shape):\n    # read slice as 32 bit signed integers\n    img = Image.fromarray(scan)\n    # do the resizing\n    img = img.resize(new_shape, resample=Image.LANCZOS)\n    # convert back to 16 bit integers\n    resized_scan = np.array(img, dtype=np.int16)\n    return resized_scan","be4ed6a6":"def crop_scan(scan):\n    img = Image.fromarray(scan)\n    \n    left = (scan.shape[0]-512)\/2\n    right = (scan.shape[0]+512)\/2\n    top = (scan.shape[1]-512)\/2\n    bottom = (scan.shape[1]+512)\/2\n\n    img = img.crop((left, top, right, bottom))\n    # convert back to 16 bit integers\n    cropped_scan = np.array(img, dtype=np.int16)\n    return cropped_scan","c34cab41":"def crop_and_resize(scan, new_shape):\n    img = Image.fromarray(scan)\n    \n    left = (scan.shape[0]-512)\/2\n    right = (scan.shape[0]+512)\/2\n    top = (scan.shape[1]-512)\/2\n    bottom = (scan.shape[1]+512)\/2\n    \n    img = img.crop((left, top, right, bottom))\n    img = img.resize(new_shape, resample=Image.LANCZOS)\n    \n    cropped_resized_scan = np.array(img, dtype=np.int16)\n    return cropped_resized_scan","0436b0a8":"first_patient = load_scan(path)\nfirst_patient_pixels = get_pixels_hu(first_patient)\nprocessed_img = crop_and_resize(first_patient_pixels[242,:,:], new_shape = [512,512])\nplt.imshow(processed_img, cmap=plt.cm.bone)\nplt.show()","a06a9bcd":"train_data = train_data_labels.copy()","82145e9a":"train_data['# FLAIR images'] = np.NaN\ntrain_data['# T1w images'] = np.NaN\ntrain_data['# T1wCE images'] = np.NaN\ntrain_data['# T2w images'] = np.NaN","94714d9d":"# Using a subset of the complete train data\nnum_patients = 30\ntrain_data = train_data.iloc[0:num_patients]","276b5c9b":"# Removing images with issues\ninvalid_ids = [109, 123, 709]\nprint('Train data shape before:', train_data.shape)\ntrain_data = train_data[~train_data['BraTS21ID'].isin(invalid_ids)].reset_index(drop = True)\nprint('Train data shape after:', train_data.shape)","7dd4519f":"# Create master data containing FLAIR, T1w, T1wCE, T2w for every patient\n\nflair_dict = {}\nT1w_dict = {}\nT1wCE_dict = {}\nT2w_dict = {}\n\nfor i in tqdm(range(0, len(train_data))):\n    pat_id_for_folder = str(train_data['BraTS21ID'].iloc[i]).rjust(5, \"0\")\n    \n    for image_type in ['FLAIR', 'T1w', 'T1wCE', 'T2w']:\n        image_path = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/' + pat_id_for_folder + f'\/{image_type}\/'    \n        image_list = os.listdir(image_path)\n        train_data[f'# {image_type} images'].iloc[i] = len(image_list)\n\n        all_scans_of_patient = load_scan(image_path)\n        all_scans_of_patient = get_pixels_hu(all_scans_of_patient)\n        temp_dict = {}\n        for j in range(0, len(image_list)):\n            temp_dict[image_list[j]] = np.resize(all_scans_of_patient[j], (512,512)) # Resize into same shape\n            \n        if image_type == 'FLAIR':\n            flair_dict[train_data['BraTS21ID'].iloc[i]] = temp_dict\n        elif image_type == 'T1w':\n            T1w_dict[train_data['BraTS21ID'].iloc[i]] = temp_dict\n        elif image_type == 'T1wCE':\n            T1wCE_dict[train_data['BraTS21ID'].iloc[i]] = temp_dict\n        elif image_type == 'T2w':\n            T2w_dict[train_data['BraTS21ID'].iloc[i]] = temp_dict","c020d569":"train_data.head()","35fd3cb1":"grp_data = train_data.groupby(['MGMT_value']).count().reset_index().iloc[:,0:2].rename(columns = {'BraTS21ID':'# Patients'})\nfig = px.bar(grp_data, x='MGMT_value', y='# Patients', color = 'MGMT_value')\nfig.show()","f5b78de9":"flair_avg_dict = {}\nT1w_avg_dict = {}\nT1wCE_avg_dict = {}\nT2w_avg_dict = {}\n\nfor i in tqdm(range(0, len(train_data))):\n    pat_id_for_folder = str(train_data['BraTS21ID'].iloc[i]).rjust(5, \"0\")\n    flair_avg_dict[train_data['BraTS21ID'].iloc[i]] = np.array([v for k, v in flair_dict[train_data['BraTS21ID'].iloc[i]].items()]).mean(axis = 0)\n    T1w_avg_dict[train_data['BraTS21ID'].iloc[i]] = np.array([v for k, v in T1w_dict[train_data['BraTS21ID'].iloc[i]].items()]).mean(axis = 0)\n    T1wCE_avg_dict[train_data['BraTS21ID'].iloc[i]] = np.array([v for k, v in T1wCE_dict[train_data['BraTS21ID'].iloc[i]].items()]).mean(axis = 0)\n    T2w_avg_dict[train_data['BraTS21ID'].iloc[i]] = np.array([v for k, v in T2w_dict[train_data['BraTS21ID'].iloc[i]].items()]).mean(axis = 0)","62245fbd":"del flair_dict\ndel T1w_dict\ndel T1wCE_dict\ndel T2w_dict\ndel all_scans_of_patient","9bd7dd60":"rows = 4\ncols = 5\nstack = [v for k,v in flair_avg_dict.items()]\nstack_ids = [k for k,v in flair_avg_dict.items()]\npat_with_tumor = train_data[train_data['MGMT_value']==1]['BraTS21ID'].tolist()\nfig,ax = plt.subplots(cols,rows,figsize=[12,12])\nfor i in range(rows*cols):\n    ind = stack_ids[i]\n    if ind in pat_with_tumor:\n        ax[max(int(i\/rows),0),int(i % rows)].set_title('With tumor', color = 'red')\n    else:\n        ax[max(int(i\/rows),0),int(i % rows)].set_title('No tumor', color = 'green')\n    ax[max(int(i\/rows),0),int(i % rows)].imshow(stack[i],cmap='gray')\n    ax[max(int(i\/rows),0),int(i % rows)].axis('off')\nplt.show()","a2385c00":"X_train, X_valid, y_train, y_valid = train_test_split(train_data['BraTS21ID'], train_data['MGMT_value'], test_size=0.3, random_state=42, stratify = train_data['MGMT_value'])","713749e8":"train_data['is_train_flag'] = np.where(train_data['BraTS21ID'].isin(X_train), 1, 0)","cfe294a8":"grp_data = train_data.groupby(['is_train_flag']).agg({'BraTS21ID':'count', 'MGMT_value':'sum'}).reset_index().rename(columns = {'BraTS21ID':'# Patients', 'MGMT_value':'# Patients with brain tumor'})\ngrp_data['% Patients with tumor'] = grp_data['# Patients with brain tumor']\/grp_data['# Patients'] * 100\ngrp_data","17e7fe54":"X_train_for_modelling = np.concatenate([np.array([v for k,v in flair_avg_dict.items() if k in list(X_train)]),\n         np.array([v for k,v in T1w_avg_dict.items() if k in list(X_train)]),\n         np.array([v for k,v in T1wCE_avg_dict.items() if k in list(X_train)]),\n         np.array([v for k,v in T2w_avg_dict.items() if k in list(X_train)])])\n\ny_train_for_modelling = np.array(list(train_data[train_data['BraTS21ID'].isin([k for k,v in flair_avg_dict.items() if k in list(X_train)])]['MGMT_value']) * 4)\n\nX_valid_for_modelling = np.concatenate([np.array([v for k,v in flair_avg_dict.items() if k in list(X_valid)]),\n         np.array([v for k,v in T1w_avg_dict.items() if k in list(X_valid)]),\n         np.array([v for k,v in T1wCE_avg_dict.items() if k in list(X_valid)]),\n         np.array([v for k,v in T2w_avg_dict.items() if k in list(X_valid)])])\n\ny_valid_for_modelling = np.array(list(train_data[train_data['BraTS21ID'].isin([k for k,v in flair_avg_dict.items() if k in list(X_valid)])]['MGMT_value']) * 4)\n\nprint('X train shape:', X_train_for_modelling.shape)\nprint('y train shape:', y_train_for_modelling.shape)\nprint('X validation shape:', X_valid_for_modelling.shape)\nprint('y validation shape:', y_valid_for_modelling.shape)","cfd27a0c":"# building the input vector from the 512x512 pixels\nX_train_for_modelling = X_train_for_modelling.reshape(X_train_for_modelling.shape[0], 512, 512, 1)\nX_valid_for_modelling = X_valid_for_modelling.reshape(X_valid_for_modelling.shape[0], 512, 512, 1)\nX_train_for_modelling = X_train_for_modelling.astype('float32')\nX_valid_for_modelling = X_valid_for_modelling.astype('float32')\n\n# one-hot encoding using keras' numpy-related utilities\nn_classes = 1\n# print(\"Shape before one-hot encoding: \", y_train_for_modelling.shape)\n# y_train_for_modelling = np_utils.to_categorical(y_train_for_modelling, n_classes)\n# y_test_for_modelling = np_utils.to_categorical(y_test_for_modelling, n_classes)\n# print(\"Shape after one-hot encoding: \", y_train_for_modelling.shape)\n\nprint('X train shape:', X_train_for_modelling.shape)\nprint('y train shape:', y_train_for_modelling.shape)\nprint('X validation shape:', X_valid_for_modelling.shape)\nprint('y validation shape:', y_valid_for_modelling.shape)","a9d3a35d":"gc.collect()","1654c38c":"# Transfer learning code to be updated\n# import keras\n# base_model = keras.applications.Xception(\n#     weights='imagenet',  # Load weights pre-trained on ImageNet.\n#     input_shape=(512, 512, 1),\n#     include_top=False)  # Do not include the ImageNet classifier at the top.","39dbf925":"# base_model.trainable = False","ece8c974":"# inputs = keras.Input(shape=(512, 512, 1))\n# # We make sure that the base_model is running in inference mode here,\n# # by passing `training=False`. This is important for fine-tuning, as you will\n# # learn in a few paragraphs.\n# x = base_model(inputs, training=False)\n# # Convert features of shape `base_model.output_shape[1:]` to vectors\n# x = keras.layers.GlobalAveragePooling2D()(x)\n# # A Dense classifier with a single unit (binary classification)\n# outputs = keras.layers.Dense(1)(x)\n# model = keras.Model(inputs, outputs)","904d219a":"# building a linear stack of layers with the sequential model\nmodel = Sequential()\n# convolutional layer\nmodel.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(512, 512, 1)))\nmodel.add(MaxPool2D(pool_size=(50,50)))\n# flatten output of conv\nmodel.add(Flatten())\n# hidden layer\nmodel.add(Dense(100, activation='relu'))\n# output layer\nmodel.add(Dense(n_classes, activation='sigmoid'))\n\nmodel.summary()","c189b085":"model.compile(optimizer=keras.optimizers.Adam(),\n              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=[keras.metrics.BinaryAccuracy()])\nmodel.fit(X_train_for_modelling, y_train_for_modelling, epochs=20, validation_data=(X_valid_for_modelling, y_valid_for_modelling))","980e202e":"# Modelling","bc988fb5":"# Create data for modelling","aa6a30b7":"To convert all slices to a single entry, I am averaging all the scans under the 4 types for each patient. Let's see the created image after averaging.","6ea6a8ec":"# EDA","4069a0f5":"# Load data","479c3509":"Treating all slices as a single entry through averaging makes it hard to distinguish the tumor very well","780b3ac7":"# Import packages"}}