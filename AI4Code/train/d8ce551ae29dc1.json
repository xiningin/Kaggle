{"cell_type":{"69e9d5e7":"code","91d004a1":"code","3fc13f36":"code","f6d9cc89":"code","59776de4":"code","f3b1a620":"code","33a3cecd":"code","d7304792":"code","af3643b4":"code","36a16a5f":"code","c6059918":"code","e29fc97d":"code","58a0d10b":"code","cfc1f9db":"code","7c73cef1":"code","5cba0e6d":"code","7395fbc3":"code","d9c74c06":"code","569cfef7":"code","e9ac20e7":"code","ffe9ce62":"code","ac57714d":"code","c21d2dfe":"code","9ab62256":"code","c3263621":"code","3607c4e2":"markdown","c084ed09":"markdown","a49a400b":"markdown","1f05385e":"markdown","3be1f199":"markdown","1c080962":"markdown","37440d64":"markdown","b31477bf":"markdown","0235ca84":"markdown"},"source":{"69e9d5e7":"\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom operator import itemgetter    \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, BayesianRidge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom xgboost import XGBRegressor\nimport catboost as cb\n\nimport tensorflow as tf\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\nfrom keras.utils import to_categorical\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ninput_path = Path('\/kaggle\/input\/tabular-playground-series-jan-2021\/')","91d004a1":"train = pd.read_csv(input_path \/ 'train.csv', index_col='id')\nprint(train.shape)\ntrain.head()","3fc13f36":"test = pd.read_csv(input_path \/ 'test.csv', index_col='id')\nprint(test.shape)\ntest.head()","f6d9cc89":"train.info()","59776de4":"train.describe()","f3b1a620":"# Any nulls ?\n\ntrain.isnull().sum()","33a3cecd":"# Separate target from train data\n\ntarget = train.pop('target')\nprint(target.shape)\ntarget.head()","d7304792":"train.head()","af3643b4":"trainNorm = train.copy()\nfor feature_name in train.columns:\n    mean_value = train[feature_name].mean()\n    std_value = train[feature_name].std()\n    trainNorm[feature_name] = (train[feature_name] - mean_value) \/ std_value\n    \ntrainNorm.head()","36a16a5f":"testNorm = test.copy()\nfor feature_name in test.columns:\n    mean_value = test[feature_name].mean()\n    std_value = test[feature_name].std()\n    testNorm[feature_name] = (test[feature_name] - mean_value) \/ std_value\n    \ntestNorm.head()","c6059918":"\nX_train, X_test, y_train, y_test = train_test_split(trainNorm, target, test_size=0.2, random_state=7)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","e29fc97d":"# CROSS VALIDATION\n\ndef rmse_cv(model,X,y):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n    return rmse","58a0d10b":"# Test Models and evaluation metric\n# Lin reg ALL models HYPERPARAMS NOT optimized\n\nmodels = [LinearRegression(), Ridge(), Lasso(), ElasticNet(), SGDRegressor(), BayesianRidge(),\n          cb.CatBoostRegressor(), RandomForestRegressor(), ]\nnames = [\"LR\", \"Ridge\", \"Lasso\", \"ElasticNet\", \"SGD\",\"BayesianRidge\", \"catboost\",\"RandomForestRegressor\"]","cfc1f9db":"%%time\n\n# Run the models and compare\n\nModScores = {}\n\nfor name, model in zip(names, models):\n    score = rmse_cv(model, X_train, y_train)\n    ModScores[name] = score.mean()\n    print(\"{}: {:.2f}\".format(name,score.mean()))\n\nprint(\"_\"*100)\nfor key, value in sorted(ModScores.items(), key = itemgetter(1), reverse = False):\n    print(key, round(value,3))","7c73cef1":"model = cb.CatBoostRegressor()\n\nmodel.fit(X_train, y_train)\n\nfinal_predictions = model.predict(X_test)\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse) \nprint(\"RMSE on X_test \", round(final_rmse, 4))","5cba0e6d":"# Model evaluation on test\n\nfinal_predictions = model.predict(testNorm)\nfinal_predictions.shape\n\nsubm = pd.read_csv(input_path \/ 'sample_submission.csv')\nprint(subm.shape)\nsubm.head()\n\nid_col=subm.id\nsubm=id_col.to_frame()\nsubm['target'] = final_predictions\nsubm.set_index('id',inplace=True)\nsubm.head()\n\nsubm.to_csv('CBSubmission.csv')\n\nLoadSub = pd.read_csv('CBSubmission.csv')\nLoadSub.set_index('id',inplace=True)\n\nLoadSub.head()","7395fbc3":"# NN MODEL\n\nfrom keras import models\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],))) \nmodel.add(layers.Dense(256, activation='relu')) \nmodel.add(layers.Dropout(0.2)) \nmodel.add(layers.Dense(64, activation='relu'))\n\nmodel.add(layers.Dense(1))\n\nmodel.summary()\n\nmodel.compile(optimizer=optimizers.Adam(), loss='mse', metrics=['mae'])\nprint(\"model compiled\")","d9c74c06":"# Train NN\n\nhistory = model.fit(X_train, y_train,\n                    validation_split=0.2, \n                    verbose=1,\n                   epochs=10)","569cfef7":"# Plot learning curves\n\nacc = history.history['mae']\nval_acc = history.history['val_mae']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training error')\nplt.plot(epochs, val_acc, 'r', label='Validation error')\nplt.title('Training and validation ERROR')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation LOSS')\nplt.legend()\nplt.show()","e9ac20e7":"# Model evaluation on X_test\n\nfinal_predictions = model.predict(X_test)\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse) \nprint(\"RMSE on X_test \", round(final_rmse, 4))","ffe9ce62":"# Model evaluation on test\n\nfinal_predictions = model.predict(testNorm)\nfinal_predictions.shape","ac57714d":"subm = pd.read_csv(input_path \/ 'sample_submission.csv')\nprint(subm.shape)\nsubm.head()","c21d2dfe":"id_col=subm.id\nsubm=id_col.to_frame()\nsubm['target'] = final_predictions\nsubm.set_index('id',inplace=True)\nsubm.head()","9ab62256":"subm.to_csv('NNSubmission.csv')","c3263621":"LoadSub = pd.read_csv('NNSubmission.csv')\nLoadSub.set_index('id',inplace=True)\n\nLoadSub.head()","3607c4e2":"* Simple NN, 10 epochs RMSE = 0.7175\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(64, activation='relu'))\n\nmodel.add(layers.Dense(1))","c084ed09":"### Final predict on test","a49a400b":"# Submission","1f05385e":"# Models","3be1f199":"### Split train into train and validation","1c080962":"# Data prep","37440d64":"# NN","b31477bf":"* No EDA as there are so many other nb detailing it \n* No hyperparam optimization on the shallow models ... again there are some amazing nb explaining it. I checked a couple of shallow models for the baseline\n* Just wanted to play with a NN on this issue\n;-)\n\n\n* RF = 0.7 ... NN = 0.717","0235ca84":"### Normalize train and test separately so there will be no data leakage"}}