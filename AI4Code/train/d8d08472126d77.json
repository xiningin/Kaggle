{"cell_type":{"ef73f057":"code","6337fe2c":"code","87b3307b":"code","dca3b2e4":"code","c70cae1e":"code","e53e8dd0":"code","3a987aab":"code","e87a5283":"code","546092f3":"code","4b6d8921":"code","5ca1cf04":"code","cb64111e":"code","8c6d58fb":"code","96d8281f":"code","80503c1e":"code","da55fae9":"code","d268d555":"code","f255936b":"code","5c4b9358":"code","966ae893":"code","82cbb69a":"code","2a8ad561":"code","e886c48b":"code","28036bb1":"code","de156e93":"code","c65c29ac":"code","956dd3b9":"code","22e98283":"code","3676fa84":"code","136f8d86":"code","755b9b70":"code","17b32ed5":"markdown","7852e49d":"markdown","8a651521":"markdown","94658d84":"markdown","a8b3e987":"markdown","d593f2ca":"markdown","9de59476":"markdown","bd99ab4c":"markdown","adbec473":"markdown","16939fa8":"markdown","0b33a8e0":"markdown","5eb7cdf2":"markdown","4793ff28":"markdown","084e0b78":"markdown","b83e6268":"markdown","294bfa03":"markdown","dd109c1b":"markdown","6b9722c0":"markdown","17489c69":"markdown","2544427a":"markdown","3296c143":"markdown","db118282":"markdown","aebeaef5":"markdown","f96c2697":"markdown","b4dca8ee":"markdown","287a8257":"markdown","23eb9e57":"markdown","d3da6feb":"markdown","2f61db7c":"markdown","20865a99":"markdown","39a59bf8":"markdown","419fe853":"markdown"},"source":{"ef73f057":"# This Python 3 environment comes with many helpful analytics libraries installed\n\nimport pandas as pd #linear algebra\nimport seaborn as sns #visualization tool\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom scipy import stats as sts  #data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt\nfrom collections import Counter\nimport os\n\nprint(os.listdir(\"..\/input\/\"))","6337fe2c":"data = pd.read_csv(\"..\/input\/Airplane_Crashes_and_Fatalities_Since_1908.csv\")","87b3307b":"data.head()","dca3b2e4":"data.info()","c70cae1e":"data.isnull().any()","e53e8dd0":"data['Fatalities'].fillna(0, inplace = True)\ndata['Aboard'].fillna(0, inplace = True)\ndata['Ground'].fillna(0, inplace = True)","3a987aab":"data['Date'] = pd.to_datetime(data['Date'])\ndata['Date'] = data['Date'].dt.strftime(\"%d\/%m\/%Y\")\ndata['Date'].head()","e87a5283":"data['Year'] = pd.DatetimeIndex(data['Date']).year\ndata['Year'].head()","546092f3":"data['Survived'] = data['Aboard'] - data['Fatalities']\ndata['Survived'].fillna(0, inplace = True)","4b6d8921":"data.head()","5ca1cf04":"matplotlib.rcParams['figure.figsize'] = (20, 10)\nsns.set_context('talk')\nsns.set_style('whitegrid')\nsns.set_palette('tab20')","cb64111e":"total_crashes_year = data[['Year', 'Date']].groupby('Year').count()\ntotal_crashes_year = total_crashes_year.reset_index()\ntotal_crashes_year.columns = ['Year', 'Crashes']","8c6d58fb":"sns.lineplot(x = 'Year', y = 'Crashes', data = total_crashes_year)\nplt.title('Total Airplane Crashes per Year')\nplt.xlabel('years')\nplt.ylabel('number of crashes')","96d8281f":"pcdeaths_year = data[['Year', 'Fatalities']].groupby('Year').sum()\npcdeaths_year.reset_index(inplace = True)","80503c1e":"# Plot\nsns.lineplot(x = 'Year', y = 'Fatalities', data = pcdeaths_year)\nplt.title('Total Number of Fatalities by Air Plane Crashes per Year')\nplt.xlabel('Fatalities')\nplt.xlabel('Years')","da55fae9":"# summarise\nabrd_per_year = data[['Year', 'Aboard']].groupby('Year').sum()\nabrd_per_year = abrd_per_year.reset_index()","d268d555":"# plot\nsns.lineplot(x = 'Year', y = 'Aboard', data = abrd_per_year)\nplt.title('Total of People Aboard Airplanes per Year')\nplt.xlabel('Years')\nplt.ylabel('Count')","f255936b":"#summarise\nFSG_per_year = data[['Year', 'Fatalities', 'Survived', 'Ground']].groupby('Year').sum()\nFSG_per_year = FSG_per_year.reset_index()","5c4b9358":"#plot\nsns.lineplot(x = 'Year', y = 'Fatalities', data = FSG_per_year, color = 'green')\nsns.lineplot(x = 'Year', y = 'Survived', data = FSG_per_year, color = 'blue')\nsns.lineplot(x = 'Year', y = 'Ground', data = FSG_per_year, color = 'red')\nplt.legend(['Fatalities', 'Survival', 'Ground'])\nplt.xlabel('Years')\nplt.ylabel('Count')\nplt.title('Fatalities vs Survived vs Killed on Ground per Year')","966ae893":"oper_list = Counter(data['Operator']).most_common(10)\noperators = []\ncrashes = []\nfor tpl in oper_list:\n    if 'Military' not in tpl[0]:\n        operators.append(tpl[0])\n        crashes.append(tpl[1])\nprint('Top 10 the worst operators')\npd.DataFrame({'Count of crashes' : crashes}, index=operators)","82cbb69a":"loc_list = Counter(data['Location'].dropna()).most_common(10)\nlocs = []\ncrashes = []\nfor loc in loc_list:\n    locs.append(loc[0])\n    crashes.append(loc[1])\nprint('Top 10 the most dangerous locations')\npd.DataFrame({'Crashes in this location' : crashes}, index=locs)","2a8ad561":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.metrics import adjusted_rand_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA","e886c48b":"text_data = data['Summary'].dropna()\ntext_data = pd.DataFrame(text_data)\n# for reproducibility\nrandom_state = 0 ","28036bb1":"documents = list(text_data['Summary'])\nvectorizer = TfidfVectorizer(stop_words='english') # Stop words are like \"a\", \"the\", or \"in\" which don't have significant meaning\nX = vectorizer.fit_transform(documents)","de156e93":"model = MiniBatchKMeans(n_clusters=5, random_state=random_state)\nmodel.fit(X)","c65c29ac":"model.cluster_centers_","956dd3b9":"# predict cluster labels for new dataset\nmodel.predict(X)\n\n# to get cluster labels for the dataset used while\n# training the model (used for models that does not\n# support prediction on new dataset).\nmodel.labels_","22e98283":"print ('Most Common Terms per Cluster:')\n\norder_centroids = model.cluster_centers_.argsort()[:,::-1] #sort cluster centers by proximity to centroid\nterms = vectorizer.get_feature_names()\n\nfor i in range(5):\n    print(\"\\n\")\n    print('Cluster %d:' % i)\n    for j in order_centroids[i, :10]: #replace 10 with n words per cluster\n        print ('%s' % terms[j]),\n    print","3676fa84":"# reduce the features to 2D\npca = PCA(n_components=2, random_state=random_state)\nreduced_features = pca.fit_transform(X.toarray())\n\n# reduce the cluster centers to 2D\nreduced_cluster_centers = pca.transform(model.cluster_centers_)","136f8d86":"plt.scatter(reduced_features[:,0], reduced_features[:,1], c=model.predict(X))\nplt.scatter(reduced_cluster_centers[:, 0], reduced_cluster_centers[:,1], marker='x', s=150, c='b')","755b9b70":"print(\"\\n\")\nprint(\"Prediction\")\n\nY = vectorizer.transform([\"engine failure\"])\nprediction = model.predict(Y)\nprint(prediction)\n\nY = vectorizer.transform([\"terrorism\"])\nprediction = model.predict(Y)\nprint(prediction)\n ","17b32ed5":"### 5.1 Importing needed modules","7852e49d":"Let's convert the 'Date' column to the appropriate format.","8a651521":"### 4.3 People Aboard Airplanes per Year","94658d84":"From the 40's, the number of people aboard airplanes starts to increase. From 1960 to 2000 is where we have most people aboard, the same years with most plane crashes and fatalities.","a8b3e987":"First we summarise to get the count of accidents per year","d593f2ca":"What are the cluster center vectors?","9de59476":"With data on number of fatalities and people aboard,I create a new variable with the number of people that survived the crash and call this variable 'Survived'.I also replace any NaN value with 0 on this column.","bd99ab4c":"## 1. Importing modules","adbec473":"Line plot with Seaborn.","16939fa8":"For visualization, I create a new column called Year.","0b33a8e0":"And now we fit the model. For this analysis, we'll be using the KMeans algorithm with 5 clusters.","5eb7cdf2":"### 4.1 Airplane Crashes per Year ","4793ff28":"## 5.4 Visualization\nTo visualize, we\u2019ll plot the features in a 2D space. As we know the dimension of features that we obtained from TfIdfVectorizer is quite large ( > 10,000), we need to reduce the dimension before we can plot. For this, we\u2019ll ues PCA to transform our high dimensional features into 2 dimensions.","084e0b78":"# Analysis of Airplane Crashes since 1908","b83e6268":"### 5.2 Data Preparation","294bfa03":"Now our dataframe looks like this.","dd109c1b":"See first five columns to ensure our data file read correctly","6b9722c0":"## 5.5 Prediction","17489c69":"## 3. Data Info and Manipulation","2544427a":"### 4.2 Death Toll per Year","3296c143":"## 4. Visualizations","db118282":"In the 'Summary' column, we have NaN values as well, so we're going to create a new dataframe with the 'Summary' data and dropping all rows with NaN values.","aebeaef5":"Now we visualize how the number of fatalities compare with the number of survived and those who were killed on the ground.","f96c2697":"As we can see from the outputs above, we have some NaN values. We will replace these values with 0 for the numeric values.","b4dca8ee":"KMeans normally works with numbers only: we need to have numbers.To get numbers, we do feature extraction.\n\nThe feature we\u2019ll use is TF-IDF, a numerical statistic. This statistic uses term frequency and inverse document frequency.\nThe method TfidfVectorizer() implements the TF-IDF algorithm.","287a8257":"## 5. Text Clustering with K-Means","23eb9e57":"We see that after 40's, there is a significant increase in airplane crashes. The highest peaks are between 1960 and 2000.","d3da6feb":"## 5.3 Model Fitting","2f61db7c":"## 2. Loading the data","20865a99":"Here we can see the same pattern, the years that had the most accidents are also the ones with the most fatalities","39a59bf8":"### 4.4 Fatalities vs Survived vs Killed on Ground","419fe853":"### 4.5 Worst operators and dangerous locations\n"}}