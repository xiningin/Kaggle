{"cell_type":{"f6ce8c82":"code","da57ea63":"code","0fd50d9d":"code","5665c99a":"code","7bb73cad":"code","ba985264":"code","cdce9aa8":"code","2650009f":"code","65d42dda":"code","799057b0":"code","444b6754":"code","4fdb84af":"code","2ade9e03":"code","7be30efd":"code","cd6b828a":"code","542c8204":"code","8d6f8ee5":"code","9333b99c":"code","1950933b":"code","f0c80775":"code","55db93b9":"code","bdedaa78":"code","8cb624d8":"code","98312b80":"code","47b3d961":"code","e63fa982":"code","b0aff3c6":"code","03376208":"code","a43b1aa8":"code","ec56d788":"code","8549b480":"code","8898589f":"code","b3631864":"code","f191a24a":"code","da57afbb":"code","55a69916":"code","bb4ca6bd":"code","c6e2a5f0":"code","f71b9d16":"code","eaecd6a2":"code","9ec20b4a":"code","f948a24a":"code","11dff00f":"code","a6eacfb2":"code","75ce5a05":"code","88a6510b":"code","315ba5ec":"code","d0163fdc":"code","1145763f":"code","1967d99c":"code","0cd84fb6":"code","e4d262ba":"code","f86238ad":"code","467d7d6c":"code","939b8647":"code","1917557f":"code","befc1f7c":"code","e22ae4a1":"code","3a07b83f":"code","a1439216":"code","bd8c4320":"code","4451d499":"code","8946bb9e":"code","80a7a582":"code","c9beac86":"code","b895a14c":"code","82b1ecf1":"code","df05f290":"code","cdedc737":"code","7bb6b311":"code","25fa29cb":"code","670a195f":"code","c7426507":"code","519ef33e":"code","21d00b1a":"code","5d06502c":"code","f649f983":"code","1046f4b7":"code","3acf9206":"code","aea8f595":"code","1fe59e8d":"code","8b1cf62e":"code","f3ec7d79":"code","cc44b8e3":"code","68bbf871":"code","5e7b35f4":"code","8828ce90":"code","c1a15987":"code","b057bfac":"code","f911d912":"markdown","902db1b1":"markdown","6e9f9573":"markdown","3e4babd2":"markdown","1e5c6bec":"markdown","4cbe45c2":"markdown","c12608ae":"markdown","ea335765":"markdown","b1a9e93d":"markdown","f68dad6b":"markdown","0dc70c60":"markdown","e05cff36":"markdown","ed30daae":"markdown","3d49a6ea":"markdown"},"source":{"f6ce8c82":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","da57ea63":"# Carregando os dados\ndf = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ndf.shape, test.shape","0fd50d9d":"## Separando as features:\n\nx_train = df['Id']\nx_test = test['Id']\ny_train = df['Target'] \n## y_test = test['Target'] N\u00e3o existe\n\n# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","5665c99a":"## Gr\u00e1ficos\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n## Modelos\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV\nfrom sklearn.metrics import classification_report,multilabel_confusion_matrix\n","7bb73cad":"def grafico_pizza(labels,var,titulo,legenda):\n    sizes = [df[var].value_counts()[0],df[var].value_counts()[1]]\n    explode = (0, 0.1)  \n\n    fig1, ax1 = plt.subplots()\n    ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\n    ax1.axis('equal')  \n    ax1.set_title(titulo)\n    ax1.legend(title=legenda,\n          loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\n    plt.show()","ba985264":"def grafico_barras(variaveis,eixoX,titulo):\n    eixoY = []\n    for v in variaveis: \n        eixoY.append(df[v].value_counts()[1])\n    \n    plt.figure(figsize=(20,5))\n    sns.barplot(x = eixoX,y = eixoY).set_title(titulo)\n    plt.show()","cdce9aa8":"### Super lota\u00e7\u00e3o de quartos\nlabels = 'N\u00e3o','Sim'\nvar = 'hacdor'\ntitulo = 'Superlota\u00e7\u00e3o de quartos'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","2650009f":"### Super lota\u00e7\u00e3o de espa\u00e7os\nlabels = 'N\u00e3o','Sim'\nvar = 'hacapo'\ntitulo = 'Superlota\u00e7\u00e3o de espa\u00e7os'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","65d42dda":"### Possui geladeira\nlabels = 'N\u00e3o','Sim'\nvar = 'refrig'\ntitulo = 'Possui geladeira?'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","799057b0":"### Possui tablet\nlabels = 'N\u00e3o','Sim'\nvar = 'v18q'\ntitulo = 'Possui tablet?'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","444b6754":"## Material predominante na parte de fora da casa \nvariaveis = 'paredblolad','paredzocalo','paredpreb','pareddes','paredmad','paredzinc','paredfibras','paredother'\neixoX = ['Bloco ou tijolo','Encaixe','Pr\u00e9 moldado ou Cimento','Res\u00edduo','Madeira','Zinco','Fibras Naturais','Outro']\ntitulo = 'Material predominante na parte de fora da casa'\ngrafico_barras(variaveis,eixoX,titulo)","4fdb84af":"## Material predominante no piso\nvariaveis = 'pisomoscer','pisocemento','pisoother','pisonatur','pisonotiene','pisomadera'\neixoX = ['Mosaico, Cer\u00e2mica ou Terrazo','Cimento','Outro','Natural','N\u00e3o h\u00e1 piso','Madeira']\ntitulo = 'Material predominante no piso'\ngrafico_barras(variaveis,eixoX,titulo)","2ade9e03":"## Material predominante no teto\nvariaveis = 'techozinc','techoentrepiso','techocane','techootro'\neixoX = ['Folha de metal ou zinco','Fibro Cimentou ou Mezanino','Fibras naturais','Outro']\ntitulo = 'Material predominante no teto'\ngrafico_barras(variaveis,eixoX,titulo)","7be30efd":"### Possui Teto\nlabels = 'N\u00e3o','Sim'\nvar = 'cielorazo'\ntitulo = 'Possui teto?'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","cd6b828a":"## Abastecimento de \u00e1gua\nvariaveis = 'abastaguadentro','abastaguafuera','abastaguano'\neixoX = ['Interior da casa','Fora da casa','N\u00e3o h\u00e1 abastecimento']\ntitulo = 'Abastecimento de \u00e1gua'\ngrafico_barras(variaveis,eixoX,titulo)","542c8204":"## Abastecimento de eletricidade\nvariaveis = 'public','planpri','noelec','coopele'\neixoX = ['CNFL, ICE, ESPH \/ JASEC','Privada','Sem eletricidade','Cooperativa']\ntitulo = 'Abastecimento de Eletricidade'\ngrafico_barras(variaveis,eixoX,titulo)","8d6f8ee5":"## Banheiros\nvariaveis = 'sanitario1','sanitario2','sanitario3','sanitario5','sanitario6'\neixoX = ['Sem banheiro','Banheiro com esgoto','Banheiro com fossa','Banheiro conectado a buraco','Banheiro conectado a outro sistema']\ntitulo = 'Banheiros'\ngrafico_barras(variaveis,eixoX,titulo)","9333b99c":"# Principal fonte de energia para cozinhar\nvariaveis = 'energcocinar1','energcocinar2','energcocinar3','energcocinar4'\neixoX = ['Sem cozinha','El\u00e9trica','G\u00e1s','Carv\u00e3o']\ntitulo = 'Principal fonte de energia para cozinhar'\ngrafico_barras(variaveis,eixoX,titulo)","1950933b":"# Descarte de lixo\n### elimbasu5 sempre 0!\nvariaveis = 'elimbasu1','elimbasu2','elimbasu3','elimbasu4','elimbasu6'\neixoX = ['Caminh\u00e3o Tanque','Bot\u00e2nica ou Enterrada','Queima','Terreno Baldio','Outros']\ntitulo = 'Descarte de lixo'\ngrafico_barras(variaveis,eixoX,titulo)","f0c80775":"# Situa\u00e7\u00e3o das paredes\nvariaveis = 'epared1','epared2','epared3'\neixoX = ['Parede ruim','Parede regular','Parede boa']\ntitulo = 'Situa\u00e7\u00e3o das paredes'\ngrafico_barras(variaveis,eixoX,titulo)","55db93b9":"# Situa\u00e7\u00e3o do teto\nvariaveis = 'etecho1','etecho2','etecho3'\neixoX = ['Teto ruim','Teto regular','Teto bom']\ntitulo = 'Situacao do teto'\ngrafico_barras(variaveis,eixoX,titulo)","bdedaa78":"## Situacao do ch\u00e3o\nvariaveis = 'eviv1','eviv2','eviv3'\neixoX = ['Ch\u00e3o ruim','Ch\u00e3o regular','Ch\u00e3o bom']\ntitulo = 'Situa\u00e7\u00e3o do ch\u00e3o'\ngrafico_barras(variaveis,eixoX,titulo)","8cb624d8":"### Pessoa incacitada\nlabels = 'N\u00e3o','Sim'\nvar = 'dis'\ntitulo = 'Pessoa incapacitada?'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","98312b80":"### Distribui\u00e7\u00e3o do sexo\nlabels = 'N\u00e3o','Sim'\nvar = 'male'\ntitulo = 'Distribui\u00e7\u00e3o do sexo'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","47b3d961":"titulo = 'Estado civil'\nvariaveis = 'estadocivil1','estadocivil2','estadocivil3','estadocivil4','estadocivil5','estadocivil6','estadocivil7'\neixoX = ['< 10 anos ','Free','Casado','Divorciado','Separado','vi\u00favo','Solteiro']\ngrafico_barras(variaveis,eixoX,titulo)","e63fa982":"titulo = 'Parentesco'\nvariaveis = 'parentesco1','parentesco2','parentesco3','parentesco4','parentesco5','parentesco6','parentesco7','parentesco8','parentesco9','parentesco10','parentesco11','parentesco12'\neixoX = ['Chefe de fam\u00edlia','C\u00f4njugue','Filho','Divorciado','Genro\/Nora','Neto','Pai','Sogro','Irm\u00e3o','Cunhada','Outro Familiar','Outro N\u00e3o Familiar']\ngrafico_barras(variaveis,eixoX,titulo)","b0aff3c6":"titulo = 'N\u00edvel de educa\u00e7\u00e3o'\nvariaveis = 'instlevel1','instlevel2','instlevel3','instlevel4','instlevel5','instlevel6','instlevel7','instlevel8','instlevel9'\neixoX = ['Sem n\u00edvel de educa\u00e7\u00e3o','Prim\u00e1rio Incompleto','Prim\u00e1rio Completo','Secund\u00e1rio Incompleto','Secund\u00e1rio Completo','T\u00e9cnico Incompleto','T\u00e9cnico Completo','Gradua\u00e7\u00e3o','Ensino Superior']\ngrafico_barras(variaveis,eixoX,titulo)","03376208":"titulo = 'Tipo de Moradia'\nvariaveis = 'tipovivi1','tipovivi2','tipovivi3','tipovivi4','tipovivi5'\neixoX = ['Casa pr\u00f3pria e quitada','Pr\u00f3pria e parcelada','Alugada','Prec\u00e1ria','Outro (Atribu\u00eddo \/ Empresatado)']\ngrafico_barras(variaveis,eixoX,titulo)","a43b1aa8":"### Possui Computador ?\nlabels = 'N\u00e3o','Sim'\nvar = 'computer'\ntitulo = 'Possui Computador ?'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","ec56d788":"### Possui Televis\u00e3o ?\nlabels = 'N\u00e3o','Sim'\nvar = 'television'\ntitulo = 'Possui Televis\u00e3o ?'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","8549b480":"### Possui telefone Celular ?\nlabels = 'N\u00e3o','Sim'\nvar = 'mobilephone'\ntitulo = 'Possui telefone Celular ?'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","8898589f":"titulo = 'Regi\u00e3o'\nvariaveis = 'lugar1','lugar2','lugar3','lugar4','lugar5','lugar6'\neixoX = ['Central','Chorotega','Pac\u00edfico central','Brunca','Huetar Atl\u00e2ntica','Huetar Norte']\ngrafico_barras(variaveis,eixoX,titulo)","b3631864":"### Zonas\nlabels = 'Rural','Urbana'\nvar = 'area1'\ntitulo = 'Zona Urbana \/ Rural'\nlegenda = 'Legenda'\ngrafico_pizza(labels,var,titulo,legenda)","f191a24a":"## Separando as vari\u00e1veis\nvarNumericas = ['v2a1','rooms','v18q','v18q1','r4h1','r4h2','r4h3','r4m1','r4m2','r4m3','r4t1','r4t2','r4t3','tamhog','tamviv','escolari','rez_esc','hhsize','hogar_nin','hogar_adul','hogar_mayor','hogar_total','dependency','edjefe','edjefa','meaneduc','bedrooms','overcrowding','qmobilephone','age','SQBescolari','SQBage','SQBhogar_total','SQBedjefe','SQBhogar_nin','SQBovercrowding','SQBdependency','SQBmeaned','agesq']","da57afbb":"## Correla\u00e7\u00f5es\nplt.figure(figsize=(20,20));\nsns.heatmap(df[varNumericas].corr(), square=True ,annot=True, linewidths=1,vmin=-1,vmax=1,cmap='RdYlGn')","55a69916":"naoUsar = ['idhogar','Id','Target'] # ID\nnaoUsarNumericas = ['tamhog','hogar_total','agesq','hhsize'] ## Correla\u00e7\u00e3o 1","bb4ca6bd":"## Tirando as vari\u00e1veis\nvarNumericas = np.setdiff1d(varNumericas,naoUsarNumericas)\n## Correla\u00e7\u00f5es\nplt.figure(figsize=(20,20));\nsns.heatmap(df[varNumericas].corr(), square=True ,annot=True, linewidths=1,vmin=-1,vmax=1,cmap='RdYlGn')","c6e2a5f0":"df[varNumericas].describe().transpose()","f71b9d16":"## An\u00e1lise da Vari\u00e1vel Alvo\ndf['Target'].value_counts().sort_values()","eaecd6a2":"eixoX = ['Pobreza Extrema','Pobreza Moderada','Fam\u00edlias Vulner\u00e1veis','Fam\u00edlias N\u00e3o Vulner\u00e1veis']\nplt.figure(figsize=(20,5))\nsns.barplot(x = eixoX,y = df['Target'].value_counts().sort_values()).set_title(titulo)\nplt.show()","9ec20b4a":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","f948a24a":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","11dff00f":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","a6eacfb2":"## Analisando a coluna dependency\ndf_all['dependency'].value_counts()","75ce5a05":"# Transformar 'yes' em 1 e 'no' em 0\n\nmapeamento = {'yes': 1, 'no': 0}\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","88a6510b":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","315ba5ec":"# Visualizando do comando info\ndf_all.info()","d0163fdc":"# Verificando os valores nulos\ndf_all.isnull().sum()","1145763f":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)\n# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)\n# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","1967d99c":"# Verificando os valores nulos novamente\ndf_all.isnull().sum()","0cd84fb6":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","e4d262ba":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","f86238ad":"# Instanciando o random forest classifier\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)","467d7d6c":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","939b8647":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","1917557f":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","befc1f7c":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission_1.csv', index=False)","e22ae4a1":"fig=plt.figure(figsize=(15, 20))\n\n# Avaliando a importancia de cada coluna (cada vari\u00e1vel de entrada)\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","3a07b83f":"varNaoUtilizadas = ['Id', 'idhogar', 'Target'] ## Ids e alvo\nvarNaoUtilizadasCat = ['female','area2'] ## Duplicadas\nvarNaoUtilizadasNum = ['tamhog','hogar_total','hhsize'] ## Correla\u00e7\u00e3o = 1\nvarNaoUtilizadasSQ = ['SQBescolari','SQBage','SQBhogar_total','SQBedjefe','SQBhogar_nin','SQBovercrowding','SQBdependency','SQBmeaned','agesq']\nvarNaoUtilizadas = varNaoUtilizadas + varNaoUtilizadasCat + varNaoUtilizadasNum + varNaoUtilizadasSQ\nvarNaoUtilizadas","a1439216":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in varNaoUtilizadas]","bd8c4320":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","4451d499":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","8946bb9e":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","80a7a582":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)\n# 0.36832 contra 0.36781 da primeira","c9beac86":"## Usar || Nao Usar \n## 'techozinc' || 'techoentrepiso','techocane','techootro'\n## 'abastaguadentro' || 'abastaguafuera','abastaguano'\n## 'public' || 'planpri','noelec','coopele'\n## 'sanitario3' || 'sanitario1','sanitario2', 'sanitario5','sanitario6'\n## 'energcocinar2' || 'energcocinar1', 'energcocinar3','energcocinar4'\n## 'elimbasu1'  ||  'elimbasu2','elimbasu3','elimbasu4','elimbasu6'\n## 'tipovivi1'  || 'tipovivi2','tipovivi3','tipovivi4','tipovivi5'\nvarNaoUtilizadas = ['Id', 'idhogar', 'Target'] ## Ids e alvo\nvarNaoUtilizadasCat = ['female','area2'] ## Duplicadas\nvarNaoUtilizadasNum = ['tamhog','hogar_total','hhsize'] ## Correla\u00e7\u00e3o = 1\nvarNaoUtilizadasSQ = ['SQBescolari','SQBage','SQBhogar_total','SQBedjefe','SQBhogar_nin','SQBovercrowding','SQBdependency','SQBmeaned','agesq']\nvarPoucosRegistros = ['techoentrepiso','techocane','techootro','abastaguafuera','abastaguano','sanitario1','sanitario2', 'sanitario5','sanitario6','energcocinar1', 'energcocinar3','energcocinar4','elimbasu2','elimbasu3','elimbasu4','elimbasu6','tipovivi2','tipovivi3','tipovivi4','tipovivi5']\nvarNaoUtilizadas = varNaoUtilizadas + varNaoUtilizadasCat + varNaoUtilizadasNum + varNaoUtilizadasSQ + varPoucosRegistros\nvarNaoUtilizadas","b895a14c":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in varNaoUtilizadas]","82b1ecf1":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","df05f290":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","cdedc737":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","7bb6b311":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)\n# 0.35910","25fa29cb":"rf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')","670a195f":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in varNaoUtilizadas]","c7426507":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","519ef33e":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","21d00b1a":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","5d06502c":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)\n# 0.42693","f649f983":"rf.get_params().keys()","1046f4b7":"param_grid = {'max_depth': [None,5,10],\n             'max_leaf_nodes': [None,2,6],\n             'min_impurity_decrease' : [1,1e-3],\n             'n_jobs': [-1],\n             'min_samples_leaf': [2,4],\n             'n_estimators': [100,300,700],\n             'class_weight' : [None,'balanced']}\n\ngrid = GridSearchCV(rf,param_grid=param_grid,cv=4,scoring='f1_macro')","3acf9206":"grid.fit(train[feats], train['Target'])","aea8f595":"grid_df = pd.DataFrame(grid.cv_results_)\ngrid_df","1fe59e8d":"## Modelo com melhores par\u00e2metros\ngrid_df.sort_values('rank_test_score',ascending=True).iloc[0,:]","8b1cf62e":"## acessando os melhores parametros\ngrid.best_params_","f3ec7d79":"rf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=100,max_leaf_nodes=None,\n                            min_impurity_decrease=0.001, min_samples_leaf=4,\n                            verbose=0, class_weight='balanced')","cc44b8e3":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in varNaoUtilizadas]","68bbf871":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","5e7b35f4":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","8828ce90":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","c1a15987":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)\n# 0.42100","b057bfac":"fig=plt.figure(figsize=(15, 20))\n\n# Avaliando a importancia de cada coluna (cada vari\u00e1vel de entrada)\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","f911d912":"# Considera\u00e7\u00f5es Finais","902db1b1":"# IESB - Miner II \n## Aluno: Vitor Gabriel Alves da Silva\n## 1931133123\n## Trabalho 1 - Previs\u00e3o do n\u00edvel de pobreza familiar da Costa Rica","6e9f9573":"## Vari\u00e1veis Qualitativas","3e4babd2":"## Removendo novas features...","1e5c6bec":"## Usando o GRID search para melhorar o modelo...","4cbe45c2":"## Alterando par\u00e2metros para melhorar o modelo...","c12608ae":"## Vari\u00e1veis Quantitativas","ea335765":"# **An\u00e1lise Explorat\u00f3ria**\n","b1a9e93d":"# Melhorando o modelo\n\n\n\n","f68dad6b":"O primeiro passo de todo trabalho de ci\u00eancia de dados \u00e9 uma boa an\u00e1lise explorat\u00f3ria dos dados;\n\nNeste trabalho, foram realizadas an\u00e1lises de todas as vari\u00e1veis da base, e descoberto algumas coisas, como:\n* Vari\u00e1veis duplicadas com valores duplos duplicadas (Sexo e \u00e1rea)\n* Vari\u00e1veis fortemente correlacionadas que representam duplicidade do dado\n* Vari\u00e1veis com basicamente um valor preenchido\n\nDentre as dificuldades encontradas:\n\n* A avalia\u00e7\u00e3o do modelo s\u00f3 pode ser realizada a ap\u00f3s a submiss\u00e3o no kaggle\n* A inclus\u00e3o \/ remo\u00e7\u00e3o de features pouco afetavam o resultado\n* Os melhores resultados foram encontrados com altera\u00e7\u00f5es nos par\u00e2metros da Random Forest\n* O GRID search n\u00e3o encontrou o melhor resultado, porque a m\u00e9trica utilizada era o F1_MACRO\n* Ap\u00f3s a altera\u00e7\u00e3o no Grid Search, o resultado encontrado foi de 0,42100","0dc70c60":"### Ap\u00f3s o modelo inicial, contendo as vari\u00e1veis iniciais com exce\u00e7\u00e3o dos ids e da vari\u00e1vel target, ser\u00e1 feito um novo modelo, contendo:\n\n* Remo\u00e7\u00e3o das vari\u00e1veis duplicadas. As vari\u00e1veis de valores \u00fanicos, como por exemplo Sexo (masculino e feminino) foram descartadas, area Urbana e Area Rural, mantendo apenas uma delas\n* Remo\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas com correla\u00e7\u00e3o igual a 1","e05cff36":"#### Imports","ed30daae":"### Fun\u00e7\u00f5es de gr\u00e1fico","3d49a6ea":"#### Resultado do GRID Search\n{'class_weight': 'balanced',\n 'max_depth': None,\n 'max_leaf_nodes': None,\n 'min_impurity_decrease': 0.001,\n 'min_samples_leaf': 4,\n 'n_estimators': 100,\n 'n_jobs': -1}"}}