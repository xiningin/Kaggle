{"cell_type":{"a3d4fe36":"code","e399936e":"code","187ca3e4":"code","c0778792":"code","bb2fa370":"code","f6d2f4a8":"code","4d109d9c":"code","89590b50":"code","3e7fd152":"code","a604dfa9":"code","ede79bfc":"code","5a1cdea5":"code","3439b9b3":"markdown","f8308fe2":"markdown","9f787386":"markdown","b235b1db":"markdown","633bcfba":"markdown","6d14cc2f":"markdown","104285d9":"markdown","01a4d8fc":"markdown","25da6a66":"markdown"},"source":{"a3d4fe36":"from pandas import read_csv\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nimport math\n\nurl=\"https:\/\/raw.githubusercontent.com\/jbrownlee\/Datasets\/master\/iris.csv\"\nnames=['sepal-length','sepal-width','petal-length','petal-width','class']\ndf=read_csv(url,names=names)\n#df_uni = df[ df[\"class\"] != 'Iris-virginica']\ndf_uni = df\nle = preprocessing.LabelEncoder()\nle.fit(list(df_uni[\"class\"].unique()))\ndf_uni[\"class\"] = le.transform(df_uni[\"class\"])\nprint(df_uni.shape)","e399936e":"X=df_uni.iloc[:,:df_uni.shape[1]-1]\ny=df_uni.iloc[:,df_uni.shape[1]-1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nn_inp = X.shape[1]\nn_out= len(list(df_uni[\"class\"].unique()))","187ca3e4":"def sig(arr):\n    return 1\/ (1+np.exp(-np.array(arr)))","c0778792":"#initialize\nTs=[[1,0,0],[0,1,0],[0,0,1]]\nlrs=[]\nfor e in range(1,10000,1000):\n    lrs.append(0.0001*e)\n\ntrain_errs_list = []\ntest_errs = []\nlr_list = []\nnp.random.seed()","bb2fa370":"for lr in lrs:\n    #train\n    #1.initialize\n    shape = [n_inp,2,3] ; W = [] \n    for w_random in range(len(shape)-1):\n        l = np.random.rand(shape[w_random],shape[w_random+1])\n        W.append(l)\n\n    train_err = []\n    err = 100000\n    check_err = False\n\n    for epoch in range(1000): #epochs\n        if(err < 0.0001 or math.isnan(err) ):\n            break\n        if(check_err):\n            if(np.mean(epoch_err0) == np.mean(epoch_err1)): \n                break\n        epoch_err0 = []; epoch_err1 = []\n\n        for i in range(X_train.shape[0]): # batches\n            if(math.isnan(err)):\n                break\n            #2.ForWard\n            inp = X_train.iloc[i] ; a = inp ; A = [] ; H = [] ;\n            for p in range(len(W)):\n                h = np.dot(a,W[p])\n                a = sig(h)\n                H.append(h)\n                A.append(a)\n\n            #3.BackWard\n            #3.1.const\n            T = y_train.iloc[i] \n            T = Ts[T]\n            O = A[1]\n            const = (2 * (T-O)* sig(H[1] ) * (1-sig(H[1])))\n            \n            #3.2.W[1]\n            dev1 = np.dot(const.reshape(-1,1) , (A[0]).reshape(-1,1).T ).T \n            for d in range(len(dev1)):\n                W[1][d] = W[1][d] + lr * dev1[d]\n\n            #3.3.W[0]\n            WC = np.dot(W[1] , const.reshape(-1,1))\n            l = []\n            for h in range(len(H[0])):\n                l.append((WC[h] * sig(H[0][h]) * (1- sig(H[0][h])) )[0])\n            WC_arr = np.array(l).reshape(-1,1)\n            ini = np.array(inp).reshape(-1,1)\n            W[0] = W[0] + lr * ( np.dot(WC_arr,ini.T) ).T\n\n            #3.4.error\n            err = np.sum(T-O)**2\/2\n            train_err.append(err)\n\n            if(epoch%2 ==0):\n                epoch_err0.append(err)\n            else:\n                epoch_err1.append(err)\n                check_err = True\n    \n    #test\n    err=0\n    for test in range(X_test.shape[0]): # batches\n        inp = X_test.iloc[test] \n        a = inp \n        A = [] ; H = [] \n        for j in range(len(W)):\n            h = np.dot(a,W[j])\n            a = sig(h)\n            H.append(h)\n            A.append(a)\n\n        T = y_test.iloc[test] # const\n        O = A[1]\n        if(O[0] > O[1] and O[0] > O[2]):\n            O = 0\n        elif(O[1] > O[0] and O[1] > O[2]):\n            O = 1\n        elif(O[2] > O[1] and O[2] > O[0]):\n            O = 2\n        if(T!=O):\n            err+=1\n    print(\"error at lr: \" , lr,\" : \", err\/X_test.shape[0]*100 , \" %\")\n    train_errs_list.append( train_err )\n    test_errs.append(err\/X_test.shape[0]*100)\n    lr_list.append(lr)","f6d2f4a8":"test_errs_sort = np.sort(test_errs)\ntrain_errs_list_sort = [x for _,x in sorted(zip(test_errs,train_errs_list))]\nlr_list_sort = [x for _,x in sorted(zip(test_errs,lr_list))]","4d109d9c":"train_errs_list_sort_new = []\n# take every 5 points for better view of graph\nfor i in range(len(train_errs_list_sort)):\n    train_errs_list_sort_new.append(train_errs_list_sort[i][0::5])\n\nprint(np.shape(train_errs_list_sort[0]))\nprint(np.shape(train_errs_list_sort_new[0]))","89590b50":"n=4\nfig, ax = plt.subplots(n,2,figsize=(15,15))\ncolor = ['r','b','g','k','y','r','b','g','k','y','r','b','g','k','y','r','b','g','k','y']\n\nfor i in range(n):\n    ax[i,0].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'lr: '+str(lr_list_sort[i])\n    ax[i,0].set_title(title)\n\nfor i in range(n,8):\n    ax[i-n,1].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'lr: '+str(lr_list_sort[i])\n    ax[i-n,1].set_title(title)","3e7fd152":"nodes= 10\ntrain_errs_list = []\ntest_errs = []\nnodes_list = []\nnp.random.seed()\n\nfor node in range(1,nodes+1):\n    #train\n    #1.initialize\n    shape = [n_inp,node,3] ; W = [] \n    for W_ini in range(len(shape)-1):\n        l = np.random.rand(shape[W_ini],shape[W_ini+1])\n        W.append(l)\n\n    train_err = []\n    err = 100000\n    check_err = False\n\n    for epoch in range(100): #epochs\n        if(err < 0.0001 or math.isnan(err) ):\n            break\n        if(check_err):\n            if(np.mean(epoch_err0) == np.mean(epoch_err1)):\n                break\n        epoch_err0 = []\n        epoch_err1 = []\n\n        for i in range(X_train.shape[0]): # batches\n            if(math.isnan(err)):\n                break\n            #2.ForWard\n            inp = X_train.iloc[i] ; a = inp ; A = [] ; H = [] ; lr = 0.5001\n            for p in range(len(W)):\n                h = np.dot(a,W[p])\n                a = sig(h)\n                H.append(h)\n                A.append(a)\n\n            #3.BackWard\n            #3.1.const\n            T = y_train.iloc[i] \n            T = Ts[T]\n            O = A[1]\n            const = (2 * (T-O)* sig(H[1] ) * (1-sig(H[1])))\n\n            #3.2.W[1]\n            dev1 = np.dot(const.reshape(-1,1) , (A[0]).reshape(-1,1).T ).T \n            for d in range(len(dev1)):\n                W[1][d] = W[1][d] +  lr * dev1[d]\n\n            #3.3.W[0]\n            WC = np.dot(W[1] , const.reshape(-1,1))\n            l = []\n            for h in range(len(H[0])):\n                l.append((WC[h] * sig(H[0][h]) * (1- sig(H[0][h])) )[0])\n            WC_arr = np.array(l).reshape(-1,1)\n            ini = np.array(inp).reshape(-1,1)\n            W[0] = W[0] + lr * ( np.dot(WC_arr,ini.T) ).T\n\n            #3.4.error\n            err = np.sum(T-O)**2\/2\n            train_err.append(err)\n\n            if(epoch%2 ==0):\n                epoch_err0.append(err)\n            else:\n                epoch_err1.append(err)\n                check_err = True\n    \n    #test\n    err=0\n    for j in range(X_test.shape[0]): # batches\n        inp = X_test.iloc[j] \n        a = inp \n        A = [] ; H = [] \n        for k in range(len(W)):\n            h = np.dot(a,W[k])\n            a = sig(h)\n            H.append(h)\n            A.append(a)\n\n        T = y_test.iloc[j] # const\n        O = A[1]\n        if(O[0] > O[1] and O[0] > O[2]):\n            O = 0\n        elif(O[1] > O[0] and O[1] > O[2]):\n            O = 1\n        elif(O[2] > O[1] and O[2] > O[0]):\n            O = 2\n        if(T!=O):\n            err+=1\n    print(\"error at number of nodes: \" , node,\" : \", err\/X_test.shape[0]*100)\n    train_errs_list.append( train_err )\n    test_errs.append(err\/X_test.shape[0]*100)\n    nodes_list.append(node)","a604dfa9":"test_errs_sort = np.sort(test_errs)\ntrain_errs_list_sort = [x for _,x in sorted(zip(test_errs,train_errs_list))]\nnodes_list_sort = [x for _,x in sorted(zip(test_errs,nodes_list))]","ede79bfc":"train_errs_list_sort_new = []\n# take every 50 points for better view of graph\nfor i in range(len(train_errs_list_sort)):\n    train_errs_list_sort_new.append(train_errs_list_sort[i][0::50])\n\nprint(np.shape(train_errs_list_sort))\nprint(np.shape(train_errs_list_sort_new))","5a1cdea5":"n=4\nfig, ax = plt.subplots(n,2,figsize=(15,15))\ncolor = ['r','b','g','k','y','r','b','g','k','y','r','b','g','k','y','r','b','g','k','y']\n\nfor i in range(n):\n    ax[i,0].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'node: '+str(nodes_list_sort[i])\n    ax[i,0].set_title(title)\n\nfor i in range(n,8):\n    ax[i-n,1].plot(train_errs_list_sort_new[i], color[i]) \n    title = 'node: '+str(nodes_list_sort[i])\n    ax[i-n,1].set_title(title)","3439b9b3":"### Plot best errors","f8308fe2":"## plot best error","9f787386":"# Now, choose best number of nodes","b235b1db":"## From the graph we can see that nodes = 2 is the best and the most converging choice\u00b6","633bcfba":"### Fit","6d14cc2f":"### From the graph we can see that lr = 0.5001  is the best and the most stable choice as it is converging while fluctuating","104285d9":"# First: Choose best learning rate","01a4d8fc":"### Sigmoid","25da6a66":"### Import"}}