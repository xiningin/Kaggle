{"cell_type":{"c8b81e89":"code","4b258bdf":"code","65449d68":"code","57f16e8c":"code","1ed4d090":"code","c8c4b987":"code","71da42b4":"code","6f547449":"code","95990c92":"code","dd01eeb6":"code","a1e94fb9":"code","08820919":"code","b1a2c5e5":"markdown","d0ec35d1":"markdown","029c7c23":"markdown","3ce38c84":"markdown","3f28ea99":"markdown","9dce868b":"markdown","8aea8a4c":"markdown","36cbf6e5":"markdown","6e472fcc":"markdown","46e17676":"markdown","45deed80":"markdown","c5a2b367":"markdown","c9b9694a":"markdown","1a1ed84d":"markdown","343ce029":"markdown","37c26db8":"markdown","48be04a9":"markdown","715b8e35":"markdown"},"source":{"c8b81e89":"import os\nimport time\nimport numpy as np\nimport pandas as pd \nfrom collections import Counter\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt","4b258bdf":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntrain_df.shape","65449d68":"train_df.head(10)","57f16e8c":"target_count = train_df.target.value_counts()\nprint('Class 0:', target_count[0])\nprint('Class 1:', target_count[1])\nprint('Proportion:', round(target_count[0] \/ target_count[1], 2), ': 1')\n\ntarget_count.plot(kind='bar', title='Count (target)');","1ed4d090":"import nltk\nfrom nltk.corpus import stopwords\n\ndef tokenizer(file_text):\n    tokens = nltk.word_tokenize(file_text)\n\n    stop_words = stopwords.words('english')\n    tokens = [i for i in tokens if ( i not in stop_words )]\n    \n    return ' '.join(tokens)\n\ntrain_df.question_text = train_df.question_text.apply(lambda x: tokenizer(x))\n\ntrain_df.head(10)","c8c4b987":"text = ' '.join(train_df['question_text'].str.lower().values[-1000000:])\nwordcloud = WordCloud(max_font_size=None, background_color='black',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top words in question text')\nplt.axis(\"off\")\nplt.show()","71da42b4":"train_df[train_df['target']==0].question_text.head(10)","6f547449":"text = ' '.join(train_df[train_df['target']==0].question_text.str.lower().values[-1000000:])\nwordcloud = WordCloud(max_font_size=None, background_color='black',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top words in nontoxic question text')\nplt.axis(\"off\")\nplt.show()","95990c92":"text = ' '.join(train_df[train_df['target']==1].question_text.str.lower().values[-1000000:])\nwordcloud = WordCloud(max_font_size=None, background_color='black',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top words in toxic question text')\nplt.axis(\"off\")\nplt.show()","dd01eeb6":"pd.set_option('display.max_colwidth', -1)","a1e94fb9":"train_df[(train_df['target']==1) & (train_df['question_text'].str.contains(\"Trump\"))].head(10)","08820919":"train_df[(train_df['target']==0) & (train_df['question_text'].str.contains(\"Trump\"))].head(10)","b1a2c5e5":"And look at nontoxic questions about Donald Trump","d0ec35d1":"## Load Librarys","029c7c23":"I was very surprised to find Donald Trump on top of toxic questions.\nOut of interest I decided to take a look, what kind of questions are these.","3ce38c84":"## TODO\n1. Try n-grams\n1. Try Word2Vec\n1. Try sec2seq","3f28ea99":"## Word Clouds","9dce868b":"**\u0421onclusion**\n\nThis cloud does not provide any useful information or insights.\n\nWe need to see the clouds for nontoxic toxic content in search of insight","8aea8a4c":"## Tokenize","36cbf6e5":"We will drop stop words and tokenize text.\n\n**Stop words** usually refers to the most common words in a language. Text may contain stop words like \u2018the\u2019, \u2018is\u2019, \u2018are\u2019. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp research, however the nltk module contains a list of stop words.\n\n**Tokenization** is the process of demarcating and possibly classifying sections of a string of input characters. The resulting tokens are then passed on to some other form of processing.","6e472fcc":"**\u0421onclusion**\n\nDonald Trump on top of the world\n\nThere are several words that intersect in toxic and nontoxic question text. For example: India, People.\nWe need to understand what to do about it.\n\nThen you can pay attention to the typical rasism, sexist and political question text.","46e17676":"## Load Data","45deed80":"### Nontoxic content","c5a2b367":"## Toxic content\n\nAttention, 18+ content\n\nThe text below may offend your feelings.","c9b9694a":"Our sample is very unbalanced","1a1ed84d":"![trump](https:\/\/timedotcom.files.wordpress.com\/2018\/03\/donald-trump-snl-baldwin-twitter.jpg)","343ce029":"Build our first  Word Clouds using all data.","37c26db8":"The author is not English speaking. But I think that many questions with a target = 1 should be from 0 and questions from a target = 0 should be from 1.\n\nYes, I know that in the description of the competition was:\n>  The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect.\n\nI think this can seriously affect the generalizing ability of the model.","48be04a9":"![Toxic content](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/7\/78\/RARS_18%2B.svg)","715b8e35":"**\u0421onclusion**\n\nThis cloud does not provide any useful information or insights same as previous.\n\nWe need to see the cloud of toxic content and compare them."}}