{"cell_type":{"c36e8569":"code","58dc91a1":"code","b8b1828a":"code","d1b9168e":"code","b1b506bd":"code","ce54f4ac":"code","ab258700":"markdown","e3383d35":"markdown","31d449ec":"markdown","4c6a5613":"markdown","1cbee789":"markdown","ed1a7c7c":"markdown"},"source":{"c36e8569":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport zipfile\n\nfrom sklearn import model_selection","58dc91a1":"SENTIMENT_LABELS = [\n    \"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"\n]\n\n# Add a column with readable values representing the sentiment.\ndef add_readable_labels_column(df, sentiment_value_column):\n  df[\"SentimentLabel\"] = df[sentiment_value_column].replace(\n      range(5), SENTIMENT_LABELS)\n\n# The data does not come with a validation set so we'll create one from the\n# training set.\ndef get_data(validation_set_ratio=0.01):\n  train_df = pd.read_csv(\"..\/input\/train.tsv\", sep=\"\\t\")\n  test_df = pd.read_csv(\"..\/input\/test.tsv\", sep=\"\\t\")\n\n  # Add a human readable label.\n  add_readable_labels_column(train_df, \"Sentiment\")\n\n  # We split by sentence ids, because we don't want to have phrases belonging\n  # to the same sentence in both training and validation set.\n  train_indices, validation_indices = model_selection.train_test_split(\n      np.unique(train_df[\"SentenceId\"]),\n      test_size=validation_set_ratio,\n      random_state=0)\n\n  validation_df = train_df[train_df[\"SentenceId\"].isin(validation_indices)]\n  train_df = train_df[train_df[\"SentenceId\"].isin(train_indices)]\n  print(\"Split the training data into %d training and %d validation examples.\" %\n        (len(train_df), len(validation_df)))\n\n  return train_df, validation_df, test_df\n\n\ntrain_df, validation_df, test_df = get_data()\ntrain_df.head()","b8b1828a":"# Training input on the whole training set with no limit on training epochs.\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(\n    train_df, train_df[\"Sentiment\"], num_epochs=None, shuffle=True)\n\n# Prediction on the whole training set.\npredict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n    train_df, train_df[\"Sentiment\"], shuffle=False)\n# Prediction on the validation set.\npredict_validation_input_fn = tf.estimator.inputs.pandas_input_fn(\n    validation_df, validation_df[\"Sentiment\"], shuffle=False)\n# Prediction on the test set.\npredict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n    test_df, shuffle=False)\n\nembedded_text_feature_column = hub.text_embedding_column(\n    key=\"Phrase\", \n    module_spec=\"https:\/\/tfhub.dev\/google\/nnlm-en-dim128\/1\",\n    trainable=True)\n\n# We don't need to keep many checkpoints.\nrun_config = tf.estimator.RunConfig(keep_checkpoint_max=1)\n\nestimator = tf.estimator.DNNClassifier(\n    hidden_units=[250, 50],\n    feature_columns=[embedded_text_feature_column],\n    n_classes=5,\n    config=run_config,\n    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n\nestimator.train(input_fn=train_input_fn, steps=10000);","d1b9168e":"train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\nvalidation_eval_result = estimator.evaluate(input_fn=predict_validation_input_fn)\n\nprint(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\nprint(\"Validation set accuracy: {accuracy}\".format(**validation_eval_result))","b1b506bd":"def get_predictions(estimator, input_fn):\n  return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n\n# Create a confusion matrix on training data.\nwith tf.Graph().as_default():\n  cm = tf.confusion_matrix(train_df[\"Sentiment\"],\n                           get_predictions(estimator, predict_train_input_fn))\n  with tf.Session() as session:\n    cm_out = session.run(cm)\n\n# Normalize the confusion matrix so that each row sums to 1.\ncm_out = cm_out.astype(float) \/ cm_out.sum(axis=1)[:, np.newaxis]\n\nsns.heatmap(\n    cm_out,\n    annot=True,\n    xticklabels=SENTIMENT_LABELS,\n    yticklabels=SENTIMENT_LABELS)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")","ce54f4ac":"test_df[\"Predictions\"] = get_predictions(estimator, predict_test_input_fn)\ntest_df.to_csv(\n    'submission.csv',\n    columns=[\"PhraseId\", \"Predictions\"],\n    header=[\"PhraseId\", \"Sentiment\"],\n    index=False)","ab258700":"# Getting started\n\n## Data\nWe will try to solve the [Sentiment Analysis on Movie Reviews (Kernels only)](https:\/\/www.kaggle.com\/c\/movie-review-sentiment-analysis-kernels-only\/data) task from Kaggle.  The dataset consists of syntactic subphrases of the Rotten Tomatoes movie reviews. The task is to label the phrases as **negative** or **positive** on the scale from 1 to 5.\n\nYou must accept the competition rules before you can use the API to download the data.","e3383d35":"## Training an Estimator\n\nWe will use a premade [DNN Classifier](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/estimator\/DNNClassifier) along with [text_embedding_column](https:\/\/github.com\/tensorflow\/hub\/blob\/master\/docs\/api_docs\/python\/hub\/text_embedding_column.md) that applies a TF-Hub module on the given text feature and returns the embedding vectors.\n\n*Note: We could model this task also as a regression, see [Text classification with TF-Hub](https:\/\/colab.research.google.com\/github\/tensorflow\/hub\/blob\/master\/docs\/tutorials\/text_classification_with_tf_hub.ipynb).*","31d449ec":"Generate predictions for submission,","4c6a5613":"TF-Hub is a platform to share machine learning expertise packaged in reusable resources, notably pre-trained **modules**. In this tutorial, we will use a TF-Hub text embedding module to train a simple sentiment classifier with a reasonable baseline accuracy. We will then submit the predictions to Kaggle.\n\nFor more detailed tutorial on text classification with TF-Hub and further steps for improving the accuracy, take a look at [Text classification with TF-Hub](https:\/\/colab.research.google.com\/github\/tensorflow\/hub\/blob\/master\/docs\/tutorials\/text_classification_with_tf_hub.ipynb).","1cbee789":"## Confusion matrix\n\nAnother very interesting statistic, especially for multiclass problems, is the [confusion matrix](https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix). The confusion matrix allows visualization of the proportion of correctly and incorrectly labelled examples. We can easily see how much our classifier is biased and whether the distribution of labels makes sense. Ideally the largest fraction of predictions should be distributed along the diagonal.","ed1a7c7c":"# Prediction\n\nRun predictions for the validation set and training set."}}