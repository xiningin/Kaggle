{"cell_type":{"375851e9":"code","05b8b15a":"code","c068ccf2":"code","31b6053f":"code","ecaca57d":"code","75faf419":"code","0b17499a":"code","b0f4bdb4":"code","af678fd1":"code","3d45e86e":"code","24e09ea7":"code","cdeeeafc":"code","e2d6f787":"code","bbee6f4e":"code","1fc33b6c":"code","f0b6552e":"code","174c8424":"code","fcdcd4c3":"code","189c92e1":"code","f841341b":"code","6350b32e":"code","d3692848":"code","4f2e83a9":"code","43a188c7":"code","8d7c0848":"markdown","3271a66c":"markdown","92157dd5":"markdown","e758f879":"markdown","59327312":"markdown","eaab5eef":"markdown","c963e32c":"markdown","29287c3b":"markdown"},"source":{"375851e9":"import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","05b8b15a":"df_2C = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv')\ndf_3C = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_3C_weka.csv')\ncompareScore3 =[]\ncompareScore2 =[]","c068ccf2":"print(\"column_2C_weka\")\ncolor_list = ['red' if i == 'Abnormal' else 'green' for i in df_2C.loc[:,'class']]\npd.plotting.scatter_matrix(df_2C.loc[:,df_2C.columns!='class'],\n                                        c = color_list,\n                                        figsize=[15,15],\n                                        diagonal = 'hist',\n                                        alpha = 0.5,\n                                        s = 200,\n                                        marker = '*',\n                                        edgecolor = 'black')\n\nplt.show()\n\n","31b6053f":"print(\"column_3c\")\ncolor_list2 = ['red' if i != 'Normal' else 'green' for i in df_3C.loc[:,'class']]\npd.plotting.scatter_matrix(df_3C.loc[:,df_3C.columns!='class'],\n                                      c = color_list,\n                                      figsize = [15,15],\n                                      diagonal = 'hist',\n                                      alpha = 0.5,\n                                      s = 200,\n                                      marker = '*',\n                                      edgecolor = 'black')\n\n\nplt.show()","ecaca57d":"sns.countplot(x = \"class\",data = df_2C)\ndf_2C.loc[:,'class'].value_counts()","75faf419":"sns.countplot(x = \"class\",data = df_3C)\ndf_3C.loc[:,'class'].value_counts()","0b17499a":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nx_2C,y_2C = df_2C.loc[:,df_2C.columns != 'class'], df_2C.loc[:,df_2C.columns == 'class']\nknn.fit(x_2C,y_2C)\nprediction = knn.predict(x_2C)\nprint(\"KNN score for 1. Dataset: \",knn.score(x_2C,y_2C))\n\n# confusion matrix\ny_pred = knn.predict(x_2C)\ny_true = y_2C\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_true,y_pred)\nprint(\"Confusion matrix for 1. dataset\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()\n","b0f4bdb4":"from sklearn.neighbors import KNeighborsClassifier\nknn2 = KNeighborsClassifier(n_neighbors = 3)\nx_3C, y_3C = df_3C.loc[:,df_3C.columns != 'class'], df_3C.loc[:,df_3C.columns == 'class']\nknn2.fit(x_3C,y_3C)\nprediction = knn2.predict(x_3C)\nprint(\"KNN score for 2. dataset: \",knn2.score(x_3C,y_3C))\n\n\n\ny_true = y_3C\ny_pred = knn2.predict(x_3C)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 2. dataset\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax=plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_true\")\nplt.ylabel(\"y_predict\")\nplt.show()","af678fd1":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nx2_train, x2_test, y2_train, y2_test = train_test_split(x_2C,y_2C,test_size=0.3,random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x2_train,y2_train)\nprint(\"{} nn score {}: \".format(3,knn.score(x2_test,y2_test)))\nknnScore2 = knn.score(x2_test, y2_test) * 100\ncompareScore2.append(knnScore2)\n\n# confusion-matrix\ny_true = y2_test\ny_pred = knn.predict(x2_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_true\")\nplt.ylabel(\"y_pred\")\nplt.show()","3d45e86e":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nx3_train, x3_test, y3_train, y3_test = train_test_split(x_3C,y_3C,test_size = 0.3, random_state = 42)\nknn2 = KNeighborsClassifier(n_neighbors = 3)\nknn2.fit(x3_train,y3_train)\nprint(\"{} nn score: {}\".format(3,knn2.score(x3_test,y3_test)))\nknnScore3 = knn2.score(x3_test, y3_test) * 100\ncompareScore3.append(knnScore3)\n# confusion-matrix\n\ny_true = y3_test\ny_pred = knn2.predict(x3_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","24e09ea7":"# evelation regresion model performance with R-square\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv')\n\ndata = df[df['class'] == 'Normal']\nx = np.array(data.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(data.loc[:,'sacral_slope']).reshape(-1,1)\n\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","cdeeeafc":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\npredict_space = np.linspace(min(x),max(x)).reshape(-1,1)\nlr.fit(x,y)\npredicted = lr.predict(predict_space)\n\nprint('R^2 score: ',lr.score(x, y))\n\n# Plot regression line and scatter\nplt.plot(predict_space, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","e2d6f787":"# SVM(Support Vector Machine) for 1. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv')\n\ndf_abnormal = df[df['class'] == 'Abnormal']\ndf_normal = df[df['class'] == 'Normal']\n\nsns.countplot(x = 'class', data = df)\ndf.loc[:,'class'].value_counts()","bbee6f4e":"plt.scatter(df_abnormal.sacral_slope,df_abnormal.pelvic_radius,label = 'abnormal',color=\"red\")\nplt.scatter(df_normal.sacral_slope,df_normal.pelvic_radius,label = 'normal',color=\"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","1fc33b6c":"y2 = df['class'].values.reshape(-1,1)\nx2_data = df.drop('class',axis = 1)\nx2 = ((x2_data - np.min(x2_data)) \/ (np.max(x2_data) - np.min(x2_data))).values\nfrom sklearn.model_selection import train_test_split\nx2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2,test_size=0.3,random_state=42)\n\nfrom sklearn.svm import SVC\n\nsvm = SVC(random_state=1)\nsvm.fit(x2_train,y2_train)\n\nprint(\"print accuracy of svm algo for 1. dataset: \",svm.score(x2_test,y2_test))\nsvmScore2 = svm.score(x2_test, y2_test) * 100\ncompareScore2.append(svmScore2)\n#confusion_matrix\n\ny_true = y2_test\ny_pred = svm.predict(x2_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 1. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","f0b6552e":"# SVM(Support Vector Machine) for 2. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_3C_weka.csv')\n\ndf_abnormal = df[df['class'] == 'Abnormal']\ndf_normal = df[df['class'] == 'Normal']\n\nsns.countplot(x = 'class', data = df)\ndf.loc[:,'class'].value_counts()","174c8424":"plt.scatter(df_abnormal.sacral_slope,df_abnormal.pelvic_radius,label = 'abnormal',color=\"red\")\nplt.scatter(df_normal.sacral_slope,df_normal.pelvic_radius,label = 'normal',color=\"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","fcdcd4c3":"y3 = df['class'].values.reshape(-1,1)\nx3_data = df.drop('class',axis = 1)\nx3 = ((x3_data - np.min(x3_data)) \/ (np.max(x3_data) - np.min(x3_data))).values\nfrom sklearn.model_selection import train_test_split\nx3_train, x3_test, y3_train, y3_test = train_test_split(x3,y3,test_size=0.3,random_state=42)\n\nfrom sklearn.svm import SVC\n\nsvm2 = SVC(random_state=1)\nsvm2.fit(x3_train,y3_train)\n\nprint(\"print accuracy of svm algo for 2. dataset: \",svm2.score(x3_test,y3_test))\nsvmScore3 = svm2.score(x3_test, y3_test) * 100\ncompareScore3.append(svmScore3)\n#confusion_matrix\n\ny_true = y3_test\ny_pred = svm2.predict(x3_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 2. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","189c92e1":"# Naive Bayes for 1. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv')\n\ndf_Abnormal = df[df['class'] == 'Abnormal']\ndf_Normal = df[df['class'] == 'Normal']\n\nplt.scatter(df_Abnormal.sacral_slope,df_Abnormal.pelvic_radius,label=\"Abnormal\",color = \"red\")\nplt.scatter(df_Normal.sacral_slope,df_Normal.pelvic_radius,label=\"Normal\",color = \"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","f841341b":"y2 = df['class'].values\nx2_data = df.drop('class',axis = 1)\n\nx2 = ((x2_data - np.min(x2_data)) \/ (np.max(x2_data) - np.min(x2_data))).values\n\nfrom sklearn.model_selection import train_test_split\n\nx2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2,test_size=0.3,random_state=42)\n\nfrom sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x2_train,y2_train)\n\nprint(\"accuracy on naive bayes: \",nb.score(x2_test, y2_test))\nnbScore2 = nb.score(x2_test, y2_test) * 100\ncompareScore2.append(nbScore2)\n#confusion_matrix\n\ny_true = y2_test\ny_pred = nb.predict(x2_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 1. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","6350b32e":"# Naive Bayes for 2. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_3C_weka.csv')\n\ndf_Abnormal = df[df['class'] == 'Abnormal']\ndf_Normal = df[df['class'] == 'Normal']\n\nplt.scatter(df_Abnormal.sacral_slope,df_Abnormal.pelvic_radius,label=\"Abnormal\",color = \"red\")\nplt.scatter(df_Normal.sacral_slope,df_Normal.pelvic_radius,label=\"Normal\",color = \"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","d3692848":"y3 = df['class'].values\nx3_data = df.drop('class',axis = 1)\n\nx3 = ((x3_data - np.min(x3_data)) \/ (np.max(x3_data) - np.min(x3_data))).values\n\nfrom sklearn.model_selection import train_test_split\n\nx3_train, x3_test, y3_train, y3_test = train_test_split(x3,y3,test_size=0.3,random_state=42)\n\nfrom sklearn.naive_bayes import GaussianNB\n\nnb2 = GaussianNB()\nnb2.fit(x3_train,y3_train)\n\nprint(\"accuracy on naive bayes: \",nb2.score(x3_test, y3_test))\nnbScore3 = nb2.score(x3_test, y3_test) * 100\ncompareScore3.append(nbScore3)\n#confusion_matrix\n\ny_true = y3_test\ny_pred = nb2.predict(x3_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 2. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","4f2e83a9":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nalgoList = [\"KNN\", \"SVM\", \"NaiveBayes\"]\ncomparison2 = {\"Models\" : algoList, \"Accuracy\" : compareScore2}\ndfComparison = pd.DataFrame(comparison2)\n\nnewIndex = (dfComparison.Accuracy.sort_values(ascending = False)).index.values\nsorted_dfComparison = dfComparison.reindex(newIndex)\n\n\ndata = [go.Bar(\n               x = sorted_dfComparison.Models,\n               y = sorted_dfComparison.Accuracy,\n               name = \"Scores of Models\",\n               marker = dict(color = \"rgba(116,173,209,0.8)\",\n                             line=dict(color='rgb(0,0,0)',width=1.0)))]\n\nlayout = go.Layout(xaxis= dict(title= 'Models',ticklen= 5,zeroline= False))\n\nfig = go.Figure(data = data, layout = layout)\nprint(\"Results for 1. dataset\")\niplot(fig)","43a188c7":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nalgoList = [\"KNN\", \"SVM\", \"NaiveBayes\"]\ncomparison3 = {\"Models\" : algoList, \"Accuracy\" : compareScore3}\ndfComparison = pd.DataFrame(comparison3)\n\nnewIndex = (dfComparison.Accuracy.sort_values(ascending = False)).index.values\nsorted_dfComparison = dfComparison.reindex(newIndex)\n\n\ndata = [go.Bar(\n               x = sorted_dfComparison.Models,\n               y = sorted_dfComparison.Accuracy,\n               name = \"Scores of Models\",\n               marker = dict(color = \"rgba(116,173,209,0.8)\",\n                             line=dict(color='rgb(0,0,0)',width=1.0)))]\n\nlayout = go.Layout(xaxis= dict(title= 'Models',ticklen= 5,zeroline= False))\n\nfig = go.Figure(data = data, layout = layout)\nprint(\"Results for 2. dataset\")\niplot(fig)","8d7c0848":"Conclusion:\n\nLooking the graph and confusion matrix, we can evaluate the algorithms both of the datasets.","3271a66c":"Testing KNN for our second dataset","92157dd5":"Applying KNN to first dataset","e758f879":"Testing KNN with using logistic regression for our first dataset","59327312":"Using two different confusion matrix, we can say that knn for second dataset is better fitted than first dataset eventhough it has low accuracy than first one.","eaab5eef":"In this kernel, I decided to evaluate two differeenet dataset with using different Machine Learning Techniques.","c963e32c":"Using two different confusion matrix, we can say that knn for second dataset is better fitted than first dataset eventhough it has low accuracy than first one.","29287c3b":"Applying KNN to second dataset"}}