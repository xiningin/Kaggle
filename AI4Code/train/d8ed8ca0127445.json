{"cell_type":{"a75e9f5d":"code","bb9b01c8":"code","a842d180":"code","dd4ef202":"code","47605bb2":"code","515c0519":"code","cd43ca95":"code","58bbb390":"code","8c7fab39":"code","547fa0f2":"code","36ad763e":"code","fddd2375":"code","06f2c43e":"code","5c4ef7b9":"code","252c3094":"code","1f0225c1":"markdown","a119a755":"markdown","3c03c448":"markdown","b2102867":"markdown","ec7811ba":"markdown","523ed32e":"markdown","53655594":"markdown","e4710a6a":"markdown","ca0cb14b":"markdown","6a71ef3e":"markdown","d2c84bd0":"markdown"},"source":{"a75e9f5d":"import numpy as np \nimport pandas as pd \n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","bb9b01c8":"db = pd.read_csv('\/kaggle\/input\/customer-retention\/data.csv')\ndb.head()","a842d180":"db.describe()","dd4ef202":"print(db['conversion'].value_counts().plot(kind='bar'))\n","47605bb2":"db['channel'][db['conversion'] == 0].value_counts().plot(kind='bar')","515c0519":"db['channel'][db['conversion'] == 1].value_counts().plot(kind='bar')","cd43ca95":"db['zip_code'][db['conversion'] == 0].value_counts().plot(kind='bar')","58bbb390":"db['zip_code'][db['conversion'] == 1].value_counts().plot(kind='bar')","8c7fab39":"from sklearn.model_selection import train_test_split as tts\nx_train = db.iloc[:,0:4]\ny_train = db['conversion']\nx_train,x_test, y_train, y_test = tts(x_train,y_train, test_size = 0.2, random_state = 10,stratify=db['conversion'])\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","547fa0f2":"y_train.head()","36ad763e":"from sklearn.linear_model import LogisticRegression\ny_train = np.array(y_train)\n\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train,y_train.ravel())","fddd2375":"y_predict = log_reg.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, y_predict)\n\nfrom sklearn.metrics import classification_report\nclassification_report(y_test, y_predict)\ntarget_names = ['0', '1']\nprint(classification_report(y_test, y_predict, target_names=target_names))","06f2c43e":"log_reg_param = LogisticRegression()\nfrom sklearn.model_selection import RepeatedStratifiedKFold as RSF\nfrom sklearn.model_selection import GridSearchCV\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\nc_values = [100, 10, 1.0, 0.1, 0.01]\ngrid = dict(solver=solvers,C=c_values)\ncv = RSF(n_splits=10, n_repeats=3, random_state=1)\ngrid_search = GridSearchCV(estimator=log_reg_param, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(x_train,y_train)","5c4ef7b9":"grid_result","252c3094":"y_predict_param = grid_result.predict(x_test)\n\nconfusion_matrix(y_test, y_predict_param)\n\nclassification_report(y_test, y_predict_param )\ntarget_names = ['0', '1']\nprint(classification_report(y_test, y_predict_param , target_names=target_names))","1f0225c1":"We notice the accuracy is the same, at 85%.","a119a755":"Let's try and tune the Logistic Regression's parameters with the help of Grid Search Cross Validation:","3c03c448":"Not much of a difference, so for the moment I won't encode them, I'll be using the rest of the variables.","b2102867":"Firstly, let's have a look at the data:","ec7811ba":"There are 64000 potential clients, out of which around 10000 became customers, a fact that we'll need to take into consideration when making the train and test split.","523ed32e":"What's next: maybe trying out other algorithms, like Decision Trees or SVM, in hope to achieve higher accuracy.","53655594":"This database offers information about clients that bought or not an item, and about their previous purchasing behaviour, like the amount of months since their last purchase, how much they bought or if they bought anything during promotional activities.\n\nIn the next steps I will try to understand better the profile of each customer (that bought or not a the product) and then try to predict the behaviour of future customers.","e4710a6a":"Let's split the data into train data and test data:","ca0cb14b":"Let's try as the first classification algorithm Logistic Regression:","6a71ef3e":"And we see an accuracy of 85% after using Logistic Regression without any sort of parameter tuning. ","d2c84bd0":"There are two categorical variables, zip_code that splits the location of the customer into Urban\/Suburban\/Rural, and the channel used to contact the client: Web\/Phone\/Multichannel. Let's see how different these components are between clients that purchased the item and those who didn't:"}}