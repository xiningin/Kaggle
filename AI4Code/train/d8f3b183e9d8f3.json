{"cell_type":{"1a9c1a3a":"code","0b8cd607":"code","6a9e9141":"code","1add7727":"code","9a0b41f3":"code","86a2bd9d":"code","2867c6d0":"code","167839b2":"code","e575e14a":"code","dcefeb7c":"code","3340ad90":"code","574e0354":"code","ec0b1696":"code","e59cf75d":"code","452c5083":"code","34eb6a2a":"code","f89bb92f":"code","39035bec":"code","70dbc482":"code","a6e0c199":"code","cf27020b":"code","ada1d3d4":"code","d3b89435":"code","15a18f41":"code","51fb768a":"code","ac7cec43":"code","138aceac":"code","81aca707":"code","1dfe83e6":"code","20b8c934":"code","05286b72":"code","d231e179":"code","9e8398e5":"code","ed5fa04e":"code","02137823":"code","dec8f8ec":"code","3bac3238":"code","ede950ca":"code","ebf888c8":"code","215e1e27":"code","23caf090":"code","8e7bdc12":"code","17e2c83d":"code","4efeb54d":"code","e63ab690":"markdown"},"source":{"1a9c1a3a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b8cd607":"import tensorflow as tf\nimport keras\nfrom tensorflow.keras.optimizers import Adam,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.svm import SVC","6a9e9141":"data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")  #read the training data","1add7727":"data.head()       #see the data","9a0b41f3":"data.info()           #see how many entries and type of data","86a2bd9d":"data_y = data['label']                               # get dependent variable \ndata.drop(['label'],axis=1,inplace=True)             # drop it from original dataframe\ndata_x = data                                        # store all independent variables separately\n","2867c6d0":"data_y.head()","167839b2":"data_x","e575e14a":"data_x = data_x.values.reshape(-1,28,28,1)                     # reshape to proper shape\ndata_y = data_y.values\n","dcefeb7c":"from keras.utils.np_utils import to_categorical               # turn individual numbers into categorical data\ndata_y = to_categorical(data_y)                               # Ex : [2] -> [0,0,1,0,0,0,0,0,0,0]","3340ad90":"data_x = data_x \/ 255.0                        # since values are between 0 and 255, divide by 255 to make them between 0 to 1, easier for processing","574e0354":"model = tf.keras.models.Sequential([\n        \n        tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),       # adding convolution layer with input size (28,28,1) , 1 means the images are in greyscale not rgb\n        tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),                                              # adding pooling layer\n        tf.keras.layers.Dropout(0.5),\n    \n        tf.keras.layers.Conv2D(128,(3,3),activation='relu'),  \n        tf.keras.layers.Conv2D(192,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Dropout(0.5),\n    \n    \n        tf.keras.layers.Flatten(),                                                      # flatten will flatten the input (28,28,1) to a single array\n        #tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Dense(512,activation='relu',kernel_regularizer=l2(0.01)),                                   # hidden layer with 256 units\n        #tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Dense(10,activation='softmax')                                  # output layer with 10 units, each representing the corresponding output\n])","ec0b1696":"model.summary()","e59cf75d":"model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])          ","452c5083":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \n                                            factor=0.5, min_lr=0.00001)","34eb6a2a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator                #for Data Augmentation","f89bb92f":"from sklearn.model_selection import train_test_split\ntrain_x, test_x, train_y, test_y = train_test_split(data_x,data_y,test_size=0.2,random_state=0)         # splitting data into train and test for validation later on","39035bec":"datagen = ImageDataGenerator(rotation_range=10,                                    # rotate image by 10 degrees\n      width_shift_range=0.1,                                                       # shift width focus randomly by 0.1\n      height_shift_range=0.1,                                                      #shift height focus randomly by 0.1\n      shear_range=0.1,                                                             # shear the image by a factor of 0.15\n      zoom_range=0.2,                                                              # zoom into the image by a factor of 0.25\n      fill_mode='nearest')                                                         # if pixels are missings fill them by taking their nearest pixels\n\ntrain_datagen = datagen.flow(train_x,train_y,batch_size=50)                        # flow training data in batches of 50 to the model\n\nvalidation_datagen = datagen.flow(test_x,test_y,batch_size=50)                     # flow validation data in batches of 50","70dbc482":"model.fit(train_datagen,\n          validation_data = validation_datagen,\n          steps_per_epoch=500,\n          epochs=50\n         )                                                                       # fit the model with training and validation generators\n","a6e0c199":"model.save('digitrec.h5')","cf27020b":"cur_model = tf.keras.models.load_model('\/kaggle\/input\/digitrec\/ogdigitrec1.h5')","ada1d3d4":"cur_model.summary()","d3b89435":"new_model = tf.keras.Model(inputs=cur_model.input,outputs=cur_model.get_layer('dense_1').output)\nnew_model.summary()","15a18f41":"test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","51fb768a":"test = test.values.reshape(-1,28,28,1)","ac7cec43":"test = test\/255.0","138aceac":"preds = cur_model.predict(test)                    # use model to predict for all test values","81aca707":"preds","1dfe83e6":"pred_labels = cur_model.predict_classes(test)\npred_labels","20b8c934":"submission = np.argmax(preds,axis=1)                               # since results are in categorical form, choose the highest in each and store them \nsubmission                                                         # the above cell also gives the same output, you can use either one","05286b72":"my_submission = pd.DataFrame({'ImageId': range(1,len(test)+1) ,'Label':submission })               # make dataframe with the column headders and predicted values\n\nmy_submission.to_csv(\"results.csv\",index=False)","d231e179":"my_submission.head()","9e8398e5":"import pandas as pd\nsubmission = pd.read_csv('..\/input\/digitrec\/newresults1.csv')\nsubmission.to_csv('newresults.csv',index=False)","ed5fa04e":"svm_train = new_model.predict(train_x)\nsvm_val = new_model.predict(test_x)\nsvm_test = new_model.predict(test)","02137823":"svm = SVC(kernel='rbf')\n\nsvm.fit(svm_train,np.argmax(train_y,axis=1))","dec8f8ec":"svm.score(svm_train,np.argmax(train_y,axis=1))","3bac3238":"svm.score(svm_val,np.argmax(test_y,axis=1))","ede950ca":"svm_pred = svm.predict(svm_test)","ebf888c8":"my_submission = pd.DataFrame({'ImageId': range(1,len(test)+1) ,'Label':svm_pred })               # make dataframe with the column headders and predicted values\n\nmy_submission.to_csv(\"results.csv\",index=False)","215e1e27":"import xgboost as xgb\n\nxb = xgb.XGBClassifier()\n\nxb.fit(svm_train,np.argmax(train_y,axis=1))","23caf090":"xb.score(svm_train,np.argmax(train_y,axis=1))\nxb.score(svm_val,np.argmax(test_y,axis=1))","8e7bdc12":"xb_pred = xb.predict(svm_test)","17e2c83d":"xb_pred","4efeb54d":"my_submission = pd.DataFrame({'ImageId': range(1,len(test)+1) ,'Label':xb_pred })               # make dataframe with the column headders and predicted values\n\nmy_submission.to_csv(\"fin_results.csv\",index=False)","e63ab690":"Hello All!\nThis is my first competition on Kaggle, please leave comments and let me know what should be improved.\nThank you!"}}