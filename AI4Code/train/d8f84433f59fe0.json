{"cell_type":{"0fc2f9fc":"code","3dfdd03e":"code","731b351e":"code","23772f04":"code","c75218d0":"code","f8e49acd":"code","13ce0835":"code","81b1f402":"code","bf00972e":"code","b40ac8b5":"code","549a2418":"code","9f722a67":"code","854a4355":"code","3fa300ea":"code","668ec69f":"code","48fc7142":"code","a4ebec48":"code","2beaabe9":"code","a69cc52f":"code","0f356aee":"code","d63c3dcb":"code","2e67db4e":"code","98350034":"code","b0febd44":"code","02982207":"code","1c78b963":"code","437ee336":"code","76ff377f":"code","0d1fcf62":"code","7bedd230":"code","ae3aea28":"code","1cfa3b26":"code","ff8369c3":"code","b7b5526a":"code","f95df6a7":"code","ae8b2e02":"code","ef5bbb29":"code","de912219":"code","7fbf5a0c":"markdown","54947cd7":"markdown","8707fd76":"markdown","0d2d44d3":"markdown","f35e36e4":"markdown","0bb7a4e5":"markdown","74609b58":"markdown","18b22171":"markdown","39cd1a7c":"markdown","b09b6edc":"markdown","55d663b9":"markdown","f6dcdc8f":"markdown","eae0f653":"markdown","893fdd03":"markdown","7efa7576":"markdown","44e849a9":"markdown","41643ff2":"markdown","eee4bef9":"markdown","089db7df":"markdown","a4a9acc1":"markdown","d7b31e33":"markdown","89d00a55":"markdown"},"source":{"0fc2f9fc":"import datatable as dt # for quicker loading of dataframes\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","3dfdd03e":"train_df = dt.fread('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv').to_pandas()","731b351e":"train_df.info()","23772f04":"train_df.head()","c75218d0":"train_df.drop(columns='id', inplace=True)\ntrain_df","f8e49acd":"train_df.describe().T.style.background_gradient(cmap = 'Blues')\\\n                           .bar(subset = [\"mean\",], color = 'lightgreen')\\\n                           .bar(subset = [\"std\"], color = '#ee1f5f')\\\n                           .bar(subset = [\"max\"], color = '#FFA07A')","13ce0835":"train_df.isna().any().sum()","81b1f402":"train_df.duplicated().any().sum()","bf00972e":"sns.countplot(x=train_df.target);","b40ac8b5":"# obtain a smaller subset of samples\ntrain_sample = train_df.sample(n=25000, random_state=42)\ntrain_sample","549a2418":"corr_all = train_sample.corr()\ncorr_all","9f722a67":"sns.set(style=\"white\", font_scale=1)\nmask = np.zeros_like(corr_all, dtype=np.bool) # Generate a mask for the upper triangle\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(24, 18))\nf.suptitle(\"Correlation Matrix\", fontsize = 10)\ncmap = sns.diverging_palette(220, 10, as_cmap=True) # Generate a custom diverging colormap\nsns.heatmap(corr_all, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","854a4355":"corr_all.target.sort_values(ascending=False)[0:10]","3fa300ea":"corr_all.target.sort_values()[0:10]","668ec69f":"train_sample.corrwith(train_sample.target).plot.bar(figsize=(20,5),\n                  title='Correlation with Target Variable',\n                  fontsize=10, rot=90,\n                  grid=True);","48fc7142":"fig, axes = plt.subplots(10,10,figsize = (20, 15))\naxes = axes.flatten()\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data = train_sample, x = f'f{idx}', fill = True, ax = ax)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_xlabel(''); ax.set_ylabel('')\n    ax.set_title(f'f{idx}', loc = 'right', fontsize = 12)\nfig.tight_layout()\nplt.show()","a4ebec48":"fig, axes = plt.subplots(10,10,figsize = (20, 15))\naxes = axes.flatten()\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data = train_sample, x = f'f{idx}', fill = True, ax = ax, hue='target', legend=idx==0)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_xlabel(''); ax.set_ylabel('')\n    ax.set_title(f'f{idx}', loc = 'right', fontsize = 12)\nfig.tight_layout()\nplt.show()","2beaabe9":"fig, axes = plt.subplots(20,5,figsize = (10, 20))\naxes = axes.flatten()\nfor idx, ax in enumerate(axes):\n    sns.boxplot(data = train_sample, x = f'f{idx}', ax = ax)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_xlabel(''); ax.set_ylabel('')\n    ax.set_title(f'f{idx}', loc = 'right', fontsize = 12)\nfig.tight_layout()\nplt.show()","a69cc52f":"from sklearn.model_selection import train_test_split","0f356aee":"X = train_df.drop(columns='target')\ny = train_df.target","d63c3dcb":"X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, random_state=42)","2e67db4e":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nclf = LinearDiscriminantAnalysis(n_components=1)","98350034":"X_r = clf.fit(X_train, y_train).transform(X_train)","b0febd44":"plt.figure(figsize=(20, 10))\nplt.scatter(X_r, y=np.zeros(X_r.shape[0]), c=y_train)","02982207":"X_r_positive = X_r[y_train==True]\nX_r_negative = X_r[y_train==False]","1c78b963":"plt.figure(figsize=(10, 10))\nsns.boxplot(data=[X_r_positive, X_r_negative])","437ee336":"from sklearn.metrics import roc_auc_score","76ff377f":"print(clf.score(X_train, y_train))\nprint(clf.score(X_valid, y_valid))\nprint(roc_auc_score(y_valid, clf.predict(X_valid)))","0d1fcf62":"from sklearn.metrics import roc_curve\nfpr, tpr, _ = roc_curve(y_valid, clf.predict_proba(X_valid)[:,1], pos_label=1)\nplt.figure(figsize=(6, 6))\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive rate');","7bedd230":"test_df = dt.fread('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv').to_pandas().drop(columns='id')","ae3aea28":"test_predictions = clf.predict_proba(test_df)\ntest_predictions[:, 1]","1cfa3b26":"sub_df = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\nsub_df['target'] = test_predictions[:, 1]\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","ff8369c3":"bimodals = [1,3,5,6,7,8,10,11,13,14,15,17,18,22,25,26,29,34,37,38,40,41,43,45,47,50,54,55,57,65,66,67,70,71,74,77,80,82,85,86,91,96,97]\nbimodal_features = ['f' + str(i) for i in bimodals]","b7b5526a":"X_train, X_valid, y_train, y_valid = train_test_split(X[bimodal_features], y, test_size=0.2, random_state=42)","f95df6a7":"clf.fit(X_train, y_train)","ae8b2e02":"print(clf.score(X_train, y_train))\nprint(clf.score(X_valid, y_valid))","ef5bbb29":"non_bimodals = set(bimodals)\nnon_bimodal_features = ['f' + str(i) for i in set(range(0, 100)).difference(set(bimodals))]","de912219":"# %%time\n# from sklearn.neighbors import LocalOutlierFactor\n\n# lof = LocalOutlierFactor()\n# yhat = lof.fit_predict(X_train)\n\n# mask = yhat != -1\n\n# X_train_filtered, y_train_filtered = X_train[mask], y_train[mask]\n\n# print(X_train_filtered.shape, y_train_filtered.shape)\n# clf.fit(X_train_filtered, y_train_filtered)\n\n# print(clf.score(X_train_filtered, y_train_filtered))\n# print(clf.score(X_valid, y_valid))\n# print(roc_auc_score(y_valid, clf.predict(X_valid)))","7fbf5a0c":"Check for duplicates","54947cd7":"Target is well balanced:","8707fd76":"Evaluation using only the bimodal and non-bimodal features","0d2d44d3":"What about trying to remove outliers from the training data?\n\nUsing Local Outlier Factor, it removed around 2000 samples. Results didn't improve.","f35e36e4":"# Data overview","0bb7a4e5":"Class boundary is around 0","74609b58":"Display an overview of all data","18b22171":"At first sight seems like there might be some good data separation, let's try with box plots to get a better idea","39cd1a7c":"# Dimensionality reduction analysis\n\nWill try with Linear Discriminant Analysis, given that many of the features seem to follow a normal distribution","b09b6edc":"All columns are numeric (float), except for the target.\n\nId column is not needed, so it will be dropped","55d663b9":"# Data correlations and distributions","f6dcdc8f":"Evaluate Pearson correlation (on a subset of 250000 samples)","eae0f653":"There is little correlation between the features.\n\nThere appears to be some correlation between some features and the target, however it is minimal and the graphic above might lead to some confusion. See below:","893fdd03":"Check for null\/missing values","7efa7576":"# Obtaining a prediction and submission","44e849a9":"Data distribution (on a subset of 25000 samples)","41643ff2":"Data distrubution considering the target:","eee4bef9":"With only non bimodal features, around a 58% score is obtained","089db7df":"Many of these distributions seem to be bimodal","a4a9acc1":"Box plot distributions","d7b31e33":"Get a subsample of data to proceed faster with the analysis","89d00a55":"# Description\n\n**Kaggle description for this dataset**: The original dataset deals with predicting identifying spam emails via various \nextracted features from the email. Although the features are anonymized, they have properties relating to real-world features.\n\n**Notebook description**: This is mostly an EDA notebook, adding a simple classifcation model and prediction at the end."}}