{"cell_type":{"469e8476":"code","99e58781":"code","553919a6":"code","5b097b9b":"code","365a772c":"code","66122d58":"code","6d036fe7":"code","cb1b1693":"code","95684476":"code","7d6e8b56":"code","990cc8f1":"code","653fdaa4":"code","119dcd29":"code","289f97f0":"code","d97a5328":"code","4940d201":"code","79aaaaef":"code","60c233cb":"code","8446c261":"code","87862d47":"code","3bfaa821":"code","f571e791":"code","960b6706":"code","e920f0f1":"code","f3d056a4":"code","37cd6901":"code","2b9d133d":"code","d0028cd2":"code","0de4e466":"code","9b38b6e9":"code","eafbbde0":"code","e9d36380":"code","cf9347f2":"code","0b8bd781":"code","737c294c":"code","6779795d":"code","dcd3d3f1":"code","095aeb05":"code","4957c4ff":"code","47291cd0":"code","dd1dedb0":"code","77d78c26":"code","dae5f08a":"code","40a5da44":"code","d2c70d3d":"markdown","b97911e9":"markdown","57da518e":"markdown","f10c8823":"markdown","7958bc73":"markdown","a0087467":"markdown","9f13f794":"markdown","5f9b9a02":"markdown","20fcdd87":"markdown","e4a163cd":"markdown","e02e6d66":"markdown","6ee276cf":"markdown","d1c4f44b":"markdown","99dd0fe2":"markdown","b4332b86":"markdown","fbf689b2":"markdown","bb0aa4d2":"markdown","82d3819c":"markdown","dd9411d2":"markdown","bbec6302":"markdown","18074460":"markdown","9415a934":"markdown","b70fe413":"markdown","23fcde99":"markdown","afb350ae":"markdown","5ba04255":"markdown","53b28fbd":"markdown","4fc79ce1":"markdown"},"source":{"469e8476":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.pipeline import Pipeline","99e58781":"iris = load_iris()","553919a6":"X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size= 0.2,random_state=10 )","5b097b9b":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","365a772c":"X_train[:5]","66122d58":"my_pipeline = Pipeline(\n    [\n        (\n            'scale', MinMaxScaler() # `transformers`\n        ),\n        (\n            'clf', LogisticRegression() # Estimator\n        )\n    ]\n)","6d036fe7":"my_pipeline.fit(X_train, y_train)","cb1b1693":"from sklearn import set_config\nset_config(display='diagram')\nmy_pipeline","95684476":"score = my_pipeline.score(X_test, y_test)\nprint('Logistic Regression pipeline test accuracy: %.3f' % score)","7d6e8b56":"pred = my_pipeline.predict(X_test)\nprint(accuracy_score(y_test, pred))","990cc8f1":"from sklearn.datasets import fetch_openml","653fdaa4":"# Load data from https:\/\/www.openml.org\/d\/40945\nX, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)","119dcd29":"X.dtypes\n# X['age'].dtypes","289f97f0":"# Get list of columns whose data type is object i.e. string\n# cat_f = list((X.dtypes[X.dtypes == np.object]).index)\n# cat_f = list((X.dtypes[X.dtypes != np.float]).index)\n# cat_f","d97a5328":"numeric_features = ['age', 'fare']\ncategorical_features = ['embarked', 'sex', 'pclass']","4940d201":"# Check for Null Values.\nX.isnull().sum()","79aaaaef":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder","60c233cb":"# Two ways to create the Pipeline..\n\n# numeric_transformer = Pipeline(steps = [\n#     ('imputer', SimpleImputer(strategy='median')),\n#     ('scaler', StandardScaler())])\n\n# Alternate way.\nnumeric_transformer = Pipeline(\n    [\n        (\n            'imputer', SimpleImputer(strategy='median')  \n        ),\n        (\n            'scaler', StandardScaler()\n        )\n    ]\n)","8446c261":"categorical_transformer = Pipeline(\n    [\n        (\n            'imputer', SimpleImputer(strategy='constant', fill_value='missing') \n        ),\n        (\n            'onehot', OneHotEncoder(handle_unknown='ignore')\n        )\n    ]\n)","87862d47":"from sklearn.compose import ColumnTransformer","3bfaa821":"preprocessor = ColumnTransformer(\n    [\n        (\n            'num', numeric_transformer, numeric_features\n        ),\n        (\n            'cat', categorical_transformer, categorical_features\n        )\n    ]\n)","f571e791":"my_pipeline2 = Pipeline(\n    [\n        (\n            'preprocessor', preprocessor\n        ),\n        (\n            'clf', LogisticRegression()\n        )\n    ]\n)","960b6706":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","e920f0f1":"X_train[numeric_features].head()","f3d056a4":"processed_data = numeric_transformer.fit_transform(X_train[numeric_features])\nprocessed_data[:5]","37cd6901":"X_train[categorical_features].head()","2b9d133d":"processed_data2 = categorical_transformer.fit_transform(X_train[categorical_features])\nprocessed_data2","d0028cd2":"my_pipeline2.fit(X_train, y_train)\n\nprint(\"model score: %.3f\" % my_pipeline2.score(X_test, y_test))","0de4e466":"employees = [\n    ('Matt', 34, 'Nashville', 155),\n    ('Sanjay', 31, 'Kerala', 177.5),\n    ('Rohan', 16, 'Mumbai', 81),\n    ('Karan', 31, 'Indore', 167),\n    ('Mayank', 12, 'Indore', 144),\n    ('Anjali', 35, 'Mumbai', 135),\n    ('Virginia', 35, 'Columbia', 111),\n    ('Euel', 35, 'Brazil', 113),\n    ('Carlos', 35, 'Peru', 187.44)\n]\n\n# Create a DataFrame object\ndf = pd.DataFrame(employees, columns=['Name', 'Age', 'City', 'Marks'])","9b38b6e9":"df","eafbbde0":"numeric_features = ['Age', 'Marks']\ncategorical_features = [ 'City']\ndrop_feature = ['Name']","e9d36380":"pre_process = ColumnTransformer(\n    remainder = 'passthrough',\n    transformers = [\n        ('drop_columns', 'drop', drop_feature),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n    ]\n)","cf9347f2":"processed_df = pd.DataFrame(pre_process.fit_transform(df))\nprocessed_df","0b8bd781":"import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler","737c294c":"df = pd.read_csv('https:\/\/raw.githubusercontent.com\/werowe\/tripAdvisorNeuralNetworkTensorFlow\/master\/TripAdvisor.csv',sep=',',header=0)","6779795d":"df.head()","dcd3d3f1":"df.shape","095aeb05":"cols = df.columns\ncols","4957c4ff":"cat_cols = ['User country',  'Period of stay', 'Traveler type', 'Pool', 'Gym',\n       'Tennis court', 'Spa', 'Casino', 'Free internet', 'Hotel name',\n       'User continent',\n       'Review month', 'Review weekday','Hotel stars']","47291cd0":"from sklearn.base import BaseEstimator, TransformerMixin","dd1dedb0":"class ToNumbers(BaseEstimator, TransformerMixin):\n    def __init__(self, cat_cols):\n        self.cat_cols = cat_cols\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        for c in cat_cols:\n            encoded, categories = X[c].factorize()\n            X[c] = encoded\n        return X.values","77d78c26":"pipeline = Pipeline([ \n    ('toNumbers', ToNumbers(cat_cols)),\n    ('scaler', StandardScaler())\n])\n\nprocessed_df = pipeline.fit_transform(df)","dae5f08a":"processed_df = pd.DataFrame(pipeline.fit_transform(df), columns=cols)\nprocessed_df.head()","40a5da44":"students = pd.read_csv('..\/input\/student-performance-data-set\/student-por.csv', sep=';',header=0)\nstudents.head()","d2c70d3d":"As mentioned above, the last step will just have fit() method, so it make sense that we do fit to our model or classifier.\n\nAnd all above will have both fit() and transform() methods, in our case step scale will use fit() and transform() method.","b97911e9":"# Basic and Simple Example","57da518e":"# When to use PipeLine in Machine Learning?\n\nMachine learning pipelines provide a variety of advantages, but not every data science project needs a pipeline. as mentioned earlier, PipeLine should mainly be used for continuously updating models like the applications from where continuous updates are received such as Fraud Detection ML Application; Spam Email Detection; Health Industry; Product Review; Recommendation System etc... these are the systems which keep on changing real-time; near real-time; batched; or so.\n\nAt times, we do use some data science projects for experiment with a new model, investigate a new model architecture; one time analysis on training dataset etc.. in such scenario ML Pipeline may not be much beneficial. \n\n","f10c8823":"# Working with Categorical Features with PipeLine\nMany machine learning algorithms require that their input is numerical and therefore categorical features must be transformed into numerical features before we can use any of these algorithms.\n\nOne of the most common ways to make this transformation is to `one-hot` encode the categorical features, especially when there does not exist a natural ordering between the categories (e.g. a feature \u2018City\u2019 with names of cities such as \u2018London\u2019, \u2018Lisbon\u2019, \u2018Berlin\u2019, etc.). For each unique value of a feature (say, \u2018London\u2019) one column is created (say, \u2018City_London\u2019) where the value is 1 if for that instance the original feature takes that value and 0 otherwise.","7958bc73":"## Step 2 : Load dataset\nThe next step is to load the iris data and then we split it into training and test datasets. \n\nWe will use 80% of the dataset to train the model and the remaining 20% to test the accuracy of the model. \n\nWe can use the shape function to view the dimension of the dataset.\n\nAs our focus in-here is to create PipeLine, so we will not go into EDA and Visualization part.","a0087467":"## Step 5 : Evaluate the Model or Pipeline\nThe last step is to score the model on the test dataset using the score method's","9f13f794":"# Prerequisite for building PipeLine in ML\nTo build a machine learning pipeline, the first requirement is to define the structure of the pipeline. \n\nIn other words, we must list down the exact steps which would go into our machine learning pipeline.\n\nIn order to do so, we will build a prototype machine learning model on the existing data before we create a pipeline. The main idea behind building a prototype is to understand the data and necessary preprocessing steps required before the model building process. Based on our learning from the prototype model, we will design a machine learning pipeline that covers all the essential preprocessing steps.\n\nIn here we will not focus on building a prototype considering that you already have some basic idea on how to explore the data; going through the individual variables; cleaning data; EDA; Feature Engineering; Fature Selection; Feature Extraction etc, to make it ready for the model. ","5f9b9a02":"# Whats is ML Pipeline?\n\nBefore we start, lets understad what exactly PipeLine is.\n\nGenerally, a machine learning pipeline describes or models your ML process : writing code, releasing it to production, performing data extractions, creating training models, and tuning the algorithm. \n\nAn ML pipeline should be a continuous process as a team works on their ML platform.\n\nMachine learning programs involve a series of steps to get the data ready before feeding it into the ML model. Those steps can include:\n\n* Reading the data and converting it to a Pandas dataframe\n* Dropping or adding some columns\n* Running some calculations over the columns\n* Normalizing the data\n\nWe have to be tie all the above together for an ML model to execute and produce results successfully. \n\nWe can use the Pipeline object to do this one step after another. \n\nA pipeline is a generalized but very important concept for a Data Scientist. In software engineering, people build pipelines to develop software that is exercised from source code to deployment. Similarly, in ML, a pipeline is created to allow data flow from its raw format to some useful information. It provides a mechanism to construct a multi-ML parallel pipeline system in order to compare the results of several ML methods.\n\nEach step in a pipeline is fed data processed from its preceding step; that is, the output of a processing unit is supplied as the input to the next step. \n\nWe could compare the ML Pipeline with Water flow pipeline. The data flows through the pipeline just as water flows in a pipe. \n\nMastering the pipeline concept is a powerful way to create error-free ML models, and pipelines are a crucial element of an AutoML system.\n\n","20fcdd87":"`.factorize()` method helps to get the numeric representation of an array by identifying distinct values. This method is available as both pandas.factorize() and Series.factorize().","e4a163cd":"In this simple pipeline, we will be using MinMaxScaler method to scale the input data and logistic regression as its a Classification problem, to predict the species of the Iris. \n\nThe model will then be evaluated based on the accuracy measure.","e02e6d66":"# Handling NaN \/ Blank \/ Null \/ Missing Data using PipeLine\n","6ee276cf":"# Custom Transformation and PipeLine","d1c4f44b":"## Step 1 : Import libraries","99dd0fe2":"# Working on own dataset","b4332b86":"As we can note from the following results, the accuracy of the model is 0.967, which is 96%","fbf689b2":"Alternatively, we can also use `.predict()` to predicting the test dataset.","bb0aa4d2":"Alternatively we can check the Pipeline detail or structure graphically as below","82d3819c":"On executing the `.fit()` method on pipeline object, we will get to see the pipeline details of the fitted model that was built.","dd9411d2":"# Why ML Pipeline?\n\nThe key benefit of Machine Learning Pipeline is to automate the model life cycle steps. \n\nSay at first we have gone through various steps from data validation; clean the data, pre-processing; creating or dropping features; model training etc on the training dataset.\n\nNow based on the business requirement we have to re-train our model based on new training data. \n\nGoing through the same steps manually on this new training data will be very costly, also there will be some possibility of human error.\n\nIn-short Implementing PipeLine for continuously updating models will be beneficial, as this will reduce the burden; reduce cost; reduce chance of introducing error.","bbec6302":"## Conclusion : \nIn this example, we created a pipeline with two steps, that is, Min Max Scaling and LogisticRegression(). When we executed the fit method on my_pipeline, the MinMaxScaler performed a fit and transform method on the input data, and it was passed on to the estimator, which is a logistic regression model. These intermediate steps in a pipeline are known as transformers, and the last step is an estimator.","18074460":"## Step 3 : Create PipeLine\nThe next step is to create a pipeline. \n\nThe pipeline object is in the form of (key, value) pairs. Where `Key` is a string that has the name for a particular step and value is the name of the function or actual method. \n\nIn the following code snippet, we have named the MinMaxScaler() method as scale and LogisticRegression() as clf:","9415a934":"Lets create the preprocessing pipelines for both numeric and categorical data.","b70fe413":"# Working of MP Pipeline\n\nYou stack up functions in the order that you want to run them. These are called `transformers`. \n\nOne can also create a custom transformer then use one built into scikit-learn.\n\nThe format is:\n\nPipeline constructor with tuples of (\u2018a descriptive name\u2019, a function). You can pass arguments to the function\u2019s, init() method where it says some args. \n\nEach method must implement the fit() and transform() functions. \n\nExcept the last function only implements fit(), and generally used for ML Modelling, this is called as Estimator.\n\n> pipeline = Pipeline([ \n>     ('step_1', function1(some args)),\n>     ('step_2', function2())\n> ])","23fcde99":"# Create Pipeline in Machine Learning\nThis is just a simple explaination on how to create a Pipeline in Machine Learning. In this example, we\u2019ll use the scikit-learn. Once we have a better understanding of Pipeline, we can implement it with any ML or DL models.","afb350ae":"So now we have training dataset with 4 columns and 120 rows, which equates to 80% of the Iris dataset and is as expected.\nand test dataset with 4 columns and 30 rows, which equates to 20% of the Iris dataset and is as expected.\n\n150 Total Rows : 80% of 150 is 120.","5ba04255":"We will train our classifier with the following features only:\n\n**Numeric Features:**\n\n* age: float;\n* fare: float.\n\n**Categorical Features:**\n\n* embarked: categories encoded as strings {'C', 'S', 'Q'};\n* sex: categories encoded as strings {'female', 'male'};\n* pclass: ordinal integers {1, 2, 3}.","53b28fbd":"Let\u2019s look at an basic and simple example, for this will use Iris dataaset.\n\nAs a basic step we will first import the required libraires and then load Iris dataset from scikit-learn's, refer http:\/\/scikit-learn.org\/stable\/auto_examples\/datasets\/plot_iris_dataset.html for details. \n\nThe dataset consists of four features and has 150 rows (how do i know this? its all defined on the scikit-learn site shared above). \n\nWe will be developing the following steps in a pipeline to train our model using the Iris dataset.\n\n![image.png](attachment:image.png)\n\nThe problem statement is to predict the species of an Iris data using four different features. ","4fc79ce1":"## Step 4 : Fit the PipeLine\nThen, we fit the pipeline object, my_pipeline, to the training dataset."}}