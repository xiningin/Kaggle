{"cell_type":{"b2182191":"code","2eb93913":"code","dab438ca":"code","c6d6f183":"code","1ea4c5bb":"code","171340f5":"code","f5120124":"code","8eef193c":"code","8bc9f4c4":"code","c1cb1fe0":"code","8b2d1a3e":"code","c2590127":"code","b93ebc15":"code","00b0be8d":"code","13a37652":"markdown","39487fc9":"markdown","433b126b":"markdown","5e5c9885":"markdown","19949be9":"markdown","e248d066":"markdown","e2a2663d":"markdown","7fa76d44":"markdown","7b2e9ad8":"markdown","b296154e":"markdown"},"source":{"b2182191":"import numpy as np\nimport pandas as pd \nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport zipfile\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","2eb93913":"main_dir = \"\/kaggle\/working\/\"\ntrain_dir = \"train\"\npath = os.path.join(main_dir,train_dir)\n\nfor p in os.listdir(path):\n    category = p.split(\".\")[0]\n    img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n    new_img_array = cv2.resize(img_array, dsize=(80, 80))\n    plt.imshow(new_img_array,cmap=\"gray\")\n    break","dab438ca":"X = []\ny = []\nconvert = lambda category : int(category == 'dog')\ndef create_test_data(path):\n    for p in os.listdir(path):\n        category = p.split(\".\")[0]\n        category = convert(category)\n        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n        new_img_array = cv2.resize(img_array, dsize=(150, 150))\n        X.append(new_img_array)\n        y.append(category)","c6d6f183":"create_test_data(path)\nX = np.array(X).reshape(-1, 150,150,1)\ny = np.array(y)","1ea4c5bb":"X = X\/255.0","171340f5":"relumodel = Sequential()\n\nrelumodel.add(Conv2D(128,(3,3), activation = 'relu', input_shape = X.shape[1:]))\nrelumodel.add(MaxPooling2D(pool_size = (2,2)))\n\n#relumodel.add(Conv2D(64,(3,3), activation = 'relu'))\nrelumodel.add(Conv2D(64,(3,3), activation = 'relu'))\n\nrelumodel.add(MaxPooling2D(pool_size = (2,2)))\n#relumodel.add(Conv2D(64,(3,3), activation = 'relu'))\nrelumodel.add(Conv2D(64,(3,3), activation = 'relu'))\nrelumodel.add(MaxPooling2D(pool_size = (2,2)))\nrelumodel.add(Conv2D(32,(3,3), activation = 'relu', input_shape = X.shape[1:]))\nrelumodel.add(MaxPooling2D(pool_size = (2,2)))\nrelumodel.add(Conv2D(16,(3,3), activation = 'relu', input_shape = X.shape[1:]))\nrelumodel.add(MaxPooling2D(pool_size = (2,2)))\n\nrelumodel.add(Flatten())\nrelumodel.add(Dense(64, activation = 'relu'))\n\nrelumodel.add(Dense(1, activation = 'sigmoid'))\nrelumodel.summary()","f5120124":"relumodel.compile(\n    optimizer = \"adam\",\n    loss = \"binary_crossentropy\",\n    metrics = [\"accuracy\"]\n\n)","8eef193c":"from tensorflow.keras.callbacks import EarlyStopping as estop\ncallback = estop(monitor='val_accuracy', patience=5)","8bc9f4c4":"history = relumodel.fit(X, y, epochs=30, batch_size=32, validation_split=0.2,\n                        callbacks = [callback])","c1cb1fe0":"train_dir = \"test1\"\npath = os.path.join(main_dir,train_dir)\n#os.listdir(path)\n\nX_test = []\nid_line = []\ndef create_test1_data(path):\n    for p in os.listdir(path):\n        id_line.append(p.split(\".\")[0])\n        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n        new_img_array = cv2.resize(img_array, dsize=(150, 150))\n        X_test.append(new_img_array)\ncreate_test1_data(path)\nX_test = np.array(X_test).reshape(-1,150,150,1)\nX_test = X_test\/255","8b2d1a3e":"predictions = relumodel.predict(X_test)","c2590127":"predicted_val = [int(round(p[0])) for p in predictions]","b93ebc15":"submission_df = pd.DataFrame({'id':id_line, 'label':predicted_val})","00b0be8d":"submission_df.to_csv(\"submission.csv\", index=False)","13a37652":"https:\/\/keras.io\/api\/callbacks\/early_stopping\/","39487fc9":"### **Flattening (Flatten())**\n\nFlattening is converting the output of convolutional layers into a 1 dimensional array for inputing  it to next layer. It is connected to fully connected layer.\n\n###### ![flattening](https:\/\/miro.medium.com\/max\/1732\/0*4afqrwiDydc8hw7g)","433b126b":"### **Types of layer in a CNN:**\n\n1. Convolution\n2. Pooling\n3. Fully Connected","5e5c9885":"### *Optimizers*\n\nOptimizers are used to change the attributes of a neural network such as weights and learning rate in order to reduce the losses. We will apply Adam optimizer here. There are multiple other optimizers which you can try out. Read about comparisons of different optimizers in tensorflow from [this article](https:\/\/heartbeat.fritz.ai\/an-empirical-comparison-of-optimizers-for-machine-learning-models-b86f29957050).","19949be9":"### Trying out Activation functions:\n","e248d066":"### Convolution Operation (Conv2D)\n\n* The convulution operation is one of the fundemantal building a CNN.\n* We have a input matrix(the input picture) and a filter(feature detector).\n* Filter usally is a 3x3 matrix but it is not a rule.\n* Filter detects horizantal or vertical lines and convex shape on the picture. For example in a person picture, we can find ears or noise etc.","e2a2663d":"### Test data preparation:","7fa76d44":"# Exploring CNN:\nin this notebook, we will discuss different concepts related to the cnn models. We will also build a cnn from scratch, achieving 84% around validation accuracy. For further concepts, read the [concepts of CNN](https:\/\/shyambhu20.blogspot.com\/2020\/12\/convolutional-neural-network-concepts-definition-howto.html).","7b2e9ad8":"![pooling](https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190721025744\/Screenshot-2019-07-21-at-2.57.13-AM.png)","b296154e":"## **Pooling Operation (MaxPooling2D)**\n\n We apply pooling to reduce the size of network and speed the computation. We can apply avarage pooling or max pooling. Let's suppose we have 4x4 input matrix, If we apply max pooling then the output will be 2x2 matrix. The way you do that is really simple. It has two hyperparameters, filter size(f) and stride(s).\n "}}