{"cell_type":{"20c5b373":"code","d3a14523":"code","05245f4e":"code","704689c2":"code","d795740f":"code","185d84d5":"code","c59e0218":"code","3e9a4820":"code","0a5a876f":"code","56d5232e":"code","a3316e22":"code","5fe0c4e9":"code","dab61694":"code","f5521754":"code","6d113475":"code","1c2428a1":"code","3e7e8a68":"markdown","8223eb9c":"markdown"},"source":{"20c5b373":"import pandas as pd\nimport numpy as np\nimport datatable as dt\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nimport optuna\n\nprint (xgb.__version__)","d3a14523":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","05245f4e":"%%time\n\n### Changed this from DataTable to basic pandas read_csv since I don't want any cols to be of type boolean\ntrain = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ntrain = reduce_memory_usage(train)\ntest = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\ntest = reduce_memory_usage(test)\n\nss = dt.fread('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv').to_pandas()\nss = reduce_memory_usage(ss)","704689c2":"## Based on the way this is loaded I'm expecting these to be blank\n\nbool_cols_train = []\nfor i, col in enumerate(train.columns):\n    if train[col].dtypes == bool:\n        bool_cols_train.append(i)","d795740f":"## Just checking that it was empty\nprint (bool_cols_train)","185d84d5":"## Based on the way this is loaded I'm expecting these to be blank\n\nbool_cols_test = []\nfor i, col in enumerate(test.columns):\n    if train[col].dtypes == bool:\n        bool_cols_test.append(i)","c59e0218":"## Meaningless code for this test\n# train.iloc[:, bool_cols_train] = train.iloc[:, bool_cols_train].astype(int)\n# test.iloc[:, bool_cols_test] = test.iloc[:, bool_cols_test].astype(int)","3e9a4820":"print(\"Train set shape\", train.shape, \"\\n\", \"Test set shape\", test.shape)","0a5a876f":"train.head()\n### I really just want to looks at f276 through to f284","56d5232e":"## Will need some slight changes here based on pd.read_csv and still having \"id\"\nX = train.drop(columns=[\"id\", \"target\"]).copy()\ny = train[\"target\"].copy()\n\nX_test = test.drop(columns=[\"id\"]).copy()\n\n\n# X = train.drop('target', axis=1).copy()\n# y = train['target'].copy()\n# X_test = test.copy()\n\ndel train\ndel test","a3316e22":"### I talk about this in the introduction section of version 4 of https:\/\/www.kaggle.com\/joecooper\/tps-oct-joes-sandpit\n### It is relevant here as well. \n## To be more specific I think it is also relevant to the perceived benefits of Target Encoding potentially showing improvments\n\n# For now I leave this section of code in so we can do a like for like comparison of v1 of this notebook\n\nX['std'] = X.std(axis=1)\nX['min'] = X.min(axis=1)\nX['max'] = X.max(axis=1)\n\nX_test['std'] = X_test.std(axis=1)\nX_test['min'] = X_test.min(axis=1)\nX_test['max'] = X_test.max(axis=1)","5fe0c4e9":"## My new section of code for this notebook is to add StandardScaler\n## Again I point to my commentary in  https:\/\/www.kaggle.com\/joecooper\/tps-oct-joes-sandpit where I run the scaler. I'm thinkning that the logic is similar to min\/max\/std FE\n\n## Is running a scaler as useful as TargetEncoding?\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX = pd.DataFrame (data=scaler.fit_transform(X), columns=X.columns)\nX_test = pd.DataFrame (data=scaler.transform(X_test), columns=X_test.columns)\n\n\n### And now I'm changing my mind again. I think there are a few benefits to running Scalers !\n\n### Some thought will have to go into the inclusion of the std\/min\/max features being but through a scaler \n\n","dab61694":"X.head(10)","f5521754":"params = {\n    'max_depth': 6,\n    'n_estimators': 9500,\n    'subsample': 0.7,\n    'colsample_bytree': 0.2,\n    'colsample_bylevel': 0.6000000001,\n    'min_child_weight': 56.419807345,\n    'reg_lambda': 75.5665191,\n    'reg_alpha': 0.11766876,\n    'gamma': 0.64078232264,\n    'booster': 'gbtree',\n    'eval_metric': 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'use_label_encoder': False\n    }","6d113475":"%%time\nkf = StratifiedKFold(n_splits=6, shuffle=True, random_state=13)\n\npreds = []\nscores = []\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n#     params['learning_rate']=0.007\n    params['learning_rate']=0.0011\n    model1 = XGBClassifier(**params)\n    \n    model1.fit(X_train,y_train,\n              eval_set=[(X_train, y_train),(X_valid,y_valid)],\n              early_stopping_rounds=200,\n              verbose=False)\n    \n#     params['learning_rate']=0.01\n    params['learning_rate']=0.021012\n    model2 = XGBClassifier(**params)\n    \n    model2.fit(X_train,y_train,\n              eval_set=[(X_train, y_train),(X_valid,y_valid)],\n              early_stopping_rounds=200,\n              verbose=False,\n              xgb_model=model1)\n    \n#     params['learning_rate']=0.05\n    params['learning_rate']=0.007\n    model3 = XGBClassifier(**params)\n    \n    model3.fit(X_train,y_train,\n              eval_set=[(X_train, y_train),(X_valid,y_valid)],\n              early_stopping_rounds=200,\n              verbose=False,\n              xgb_model=model2)\n    \n    pred_valid = model3.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\")\n    print('||'*40)\n    \n    test_preds = model3.predict_proba(X_test)[:,1]\n    preds.append(test_preds)\n    \nprint(f\"Overall Validation Score: {np.mean(scores)}\")","1c2428a1":"predictions = np.mean(np.column_stack(preds),axis=1)\n\nss['target'] = predictions\nss.to_csv('.\/xgb.csv', index=False)\nss.head()","3e7e8a68":"In response to https:\/\/www.kaggle.com\/c\/tabular-playground-series-oct-2021\/discussion\/280986\n\n","8223eb9c":"# Memory Reduction\n\n* This memory reduction part taken from https:\/\/www.kaggle.com\/azzamradman\/tps-10-single-xgboost\/notebook\n  amazing notebook. Please upvote it if you like this part."}}