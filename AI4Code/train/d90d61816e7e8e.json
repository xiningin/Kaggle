{"cell_type":{"efcde08e":"code","9ee9fa63":"code","bb382e8e":"code","b4ce5424":"code","48ca0b90":"code","1400e410":"code","c8ee8f12":"code","f1644475":"code","0b1db0a8":"code","49ab7b36":"code","8715d9e4":"code","d418002a":"code","e023d79a":"code","d66ffc4a":"code","f9a04674":"code","be77d3b4":"code","fb349f1e":"code","861b4a84":"code","b7105651":"code","569df42b":"code","1231e118":"code","e6541b6c":"code","b65bed18":"code","6d17fc3c":"code","d72c8fef":"code","f26af1e3":"code","93022449":"code","3a7cef57":"code","76c02be7":"code","30eb5751":"code","b9458fe8":"code","18cd146f":"markdown","c6bc8c8f":"markdown","1afa8b7c":"markdown","234ce773":"markdown","08614d18":"markdown","a5dc92bf":"markdown","757dcd42":"markdown","8a777623":"markdown"},"source":{"efcde08e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9ee9fa63":"ds_dir = '\/kaggle\/input\/kannada-mnist\/kannada_mnist_datataset_paper\/Kannada_MNIST_datataset_paper\/Kannada_MNIST_npz\/Kannada_MNIST'\n\nX_train = np.load(os.path.join(ds_dir,'X_kannada_MNIST_train.npz'))['arr_0']\nX_test = np.load(os.path.join(ds_dir,'X_kannada_MNIST_test.npz'))['arr_0']\ny_train = np.load(os.path.join(ds_dir,'y_kannada_MNIST_train.npz'))['arr_0']\ny_test = np.load(os.path.join(ds_dir,'y_kannada_MNIST_test.npz'))['arr_0']\n\nprint(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)","bb382e8e":"# Reshaping for MLPs\nX_train = X_train.astype('float32') \/ 255.\nX_test = X_test.astype('float32') \/ 255.\n\nX_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\nX_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\nprint( X_train.shape)\nprint( X_test.shape)","b4ce5424":"def plot_n(X,y, n=10, title = \"\"):\n    plt.figure(figsize=(20, 4)) \n    for i in range(n):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(X[i].reshape(28, 28))\n        plt.title(y[i])\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.suptitle(title)\n    \n\nplot_n(X_train, y_train,  5, \"Original Data\")","48ca0b90":"from keras.layers import Input, Dense, UpSampling2D, Conv2D, MaxPooling2D\nfrom keras.models import Model\nfrom keras import regularizers","1400e410":"encoding_dim = 32\ninput_img = Input(shape = (784,))\nencoded = Dense(encoding_dim, activation = 'relu', activity_regularizer=regularizers.l1(10e-5))(input_img)\ndecoded = Dense(784, activation= 'relu')(encoded)\nautoencoder = Model(input_img, decoded)","c8ee8f12":"encoder = Model(input_img, encoded)","f1644475":"encoded_input = Input(shape = (encoding_dim,) )\ndecoded_layer = Dense(784, activation = 'relu')(encoded_input)\ndecoder = Model(encoded_input, decoded_layer)","0b1db0a8":"autoencoder.summary()","49ab7b36":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","8715d9e4":"autoencoder.fit(X_train, X_train, \n               epochs = 50, \n               batch_size=256, \n               shuffle=True, \n               validation_data=(X_test, X_test))","d418002a":"regen_test_1 = autoencoder.predict(X_test)","e023d79a":"plot_n(regen_test_1, y_test, 5)\nplot_n(X_test, y_test, 5)","d66ffc4a":"encoding_dim = 32\n\ninput_img = Input(shape = (784,))\nencoded = Dense(128, activation = 'relu' )(input_img)\nencoded = Dense(64, activation = 'relu')(encoded)\nencoded = Dense(32, activation = 'relu')(encoded)\n\ndecoded = Dense(64, activation = 'relu')(encoded)\ndecoded = Dense(128, activation = 'relu')(decoded)\ndecoded = Dense(784, activation = 'relu')(decoded)\n\n\nautoencoder_2 = Model(input_img, decoded)","f9a04674":"autoencoder_2.compile(optimizer='adadelta', loss='binary_crossentropy')\nhistory_2 = autoencoder_2.fit(X_train, X_train, \n               epochs = 200, \n               batch_size=256, \n               shuffle=True, \n               validation_data=(X_test, X_test))","be77d3b4":"regen_test_2 = autoencoder_2.predict(X_test)","fb349f1e":"plot_n(regen_test_1, y_test, 5, \"Single MLP\")\nplot_n(regen_test_2, y_test, 5, \"Deep MLP\")\nplot_n(X_test, y_test, 5, \"Original Data\")","861b4a84":"encoding_dim = 32\n\ninput_img = Input(shape = (28,28,1))\n\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2,2), padding= 'same')(x)\n\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2,2))(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2,2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\n\nautoencoder_3 = Model(input_img, decoded)","b7105651":"autoencoder_3.summary()","569df42b":"X_train = np.reshape(X_train, (len(X_train), 28, 28, 1)) \nX_test = np.reshape(X_test, (len(X_test), 28, 28, 1)) ","1231e118":"autoencoder_3.compile(optimizer='adadelta', loss='binary_crossentropy')\nhistory_3 = autoencoder_3.fit(X_train, X_train, \n               epochs = 100, \n               batch_size=256, \n               shuffle=True,\n               validation_data=(X_test, X_test))","e6541b6c":"regen_test_3 = autoencoder_3.predict(X_test)","b65bed18":"plot_n(regen_test_1, y_test, 5, \"Single layer MLP\")\nplot_n(regen_test_2, y_test, 5, \"Deep MLP\")\nplot_n(regen_test_3, y_test, 5, \"CNN\")\nplot_n(X_test, y_test, 5, \"Original\")","6d17fc3c":"# Adding some normal noise to the data. \nnoise_factor = 0.3\nX_train_noise = X_train + noise_factor* np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\nX_test_noise = X_test + noise_factor* np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n\nX_train_noise = np.clip(X_train_noise, 0., 1.)\nX_test_noise = np.clip(X_test_noise, 0., 1.)","d72c8fef":"plot_n(X_train, y_train, 5, \"Original Data\")\nplot_n(X_train_noise, y_train, 5, \"Noisy Added\")","f26af1e3":"encoding_dim = 32\n\ninput_img = Input(shape = (28,28,1))\n\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2,2), padding= 'same')(x)\n\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2,2))(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx =  Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2,2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\n\nautoencoder_4 = Model(input_img, decoded)","93022449":"# autoencoder_3.summary()","3a7cef57":"X_train = np.reshape(X_train, (len(X_train), 28, 28, 1)) \nX_test = np.reshape(X_test, (len(X_test), 28, 28, 1)) ","76c02be7":"autoencoder_3.compile(optimizer='adadelta', loss='binary_crossentropy')\nhistory_3 = autoencoder_3.fit(X_train_noise, X_train, \n               epochs = 100, \n               batch_size=256, \n               shuffle=True,\n               validation_data=(X_test_noise, X_test))","30eb5751":"regen_test_3 = autoencoder_3.predict(X_test_noise)","b9458fe8":"plot_n(regen_test_3, y_test, 5, \"Regenrated denoised\")\nplot_n(X_test_noise, y_test, 5, \"Input Noisy\")\nplot_n(X_test, y_test, 5, \"Input\")","18cd146f":"Clearly adding more layers improves the model further. ","c6bc8c8f":"## Model-3 CNN AEC","1afa8b7c":"## Noisy Data","234ce773":"## Reading Data","08614d18":"## Model-2 Deep MLP","a5dc92bf":"The AEC maps noisy data to original data, hence its able to remove noise from new data. ","757dcd42":"## Model-1 Simple MLP","8a777623":"## Aim :\nAEC (autoencoders) basically maps larger input to a smaller representation and then decode it back again, Our purpose here is to find such a model which can learn our training data and if new data has some noise, the model should be able to remove that noise. ****"}}