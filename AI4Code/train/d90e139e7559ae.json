{"cell_type":{"d6df73cc":"code","014cbda9":"code","ead5f055":"code","a943b6fd":"code","011d4dc4":"code","30791001":"code","4e0c179b":"code","0db386e0":"code","1dd49bed":"code","2a68c0d9":"code","7f822aee":"code","2633bd61":"code","3f1ebe35":"code","060beeb0":"code","91859313":"code","32695b06":"code","759cd774":"code","79cc3938":"code","bf0f8bc2":"code","49986038":"code","d3ebd0cb":"code","bf8fefee":"code","a73e4327":"code","ae5a6b97":"code","4bdf2ea6":"code","0334ca5e":"markdown","d97061b8":"markdown","0deba127":"markdown","8c73daad":"markdown","20d11364":"markdown","067c56d8":"markdown","d254e299":"markdown","25ac1d34":"markdown","50e8a76e":"markdown","cfa0da06":"markdown","9e1d7b1b":"markdown","555a5415":"markdown","fef08fb0":"markdown","af515eeb":"markdown","2456388d":"markdown","90d167f3":"markdown","2677411c":"markdown","fa0050ef":"markdown","13a77309":"markdown"},"source":{"d6df73cc":"from numpy.random import seed\nseed(123)\nimport tensorflow as tf\ntf.random.set_seed(123) \nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\nfrom PIL import Image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import np_utils\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","014cbda9":"!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla\/5.0 (X11; CrOS x86_64 13816.64.0) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/90.0.4430.100 Safari\/537.36\" --header=\"Accept: text\/html,application\/xhtml+xml,application\/xml;q=0.9,image\/avif,image\/webp,image\/apng,*\/*;q=0.8,application\/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https:\/\/www.kaggle.com\/\" \"https:\/\/storage.googleapis.com\/kaggle-data-sets\/165566\/377107\/bundle\/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210516%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210516T033008Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=0c24f241675bdbfd663c545ecbfaa9340292758a029e0ddddb3aec6cd52744455d7daee5f40c4f35ebccb575b5b3a175a4922c0fbb7a25bf32d32086328de750a590c1804bf4fe87b0a8ced367b8d1142b3d2482708108fd6b7802f3a9da7bf775a43db437387db92e8ea0125412cb18d7c2ee50736023ffc50bb1e3640bb4199b6c54ac0089f1a0e8cea53c1aefa2d585f946d988f75013357018af1f126f6e133fb7bf112cb90783ea4df6d918d31cf54203032738bc2c050cf23cbbbec1ac129560b8ba7451455841eabb6d185fe381b12f50e4196e1a4b183cb7a29a20702af183428945e189a2e9815e98b53bbc7ff5c91431894895feeca7f88a1432d2\" -c -O 'archive.zip'","ead5f055":"!unzip archive.zip","a943b6fd":"yestype=os.listdir('.\/brain_tumor_dataset\/yes')\nnotype=os.listdir('.\/brain_tumor_dataset\/no')","011d4dc4":"len(yestype) ,len(notype)","30791001":"plt.figure(figsize=(15,15))\nfor i in range(5):\n  plt.subplot(1,5,i+1)\n  imageread=cv2.imread('.\/brain_tumor_dataset\/yes\/'+yestype[i])\n  plt.imshow(imageread)\n  plt.tight_layout()","4e0c179b":"plt.figure(figsize=(15,15))\nfor i in range(5):\n  plt.subplot(1,5,i+1)\n  readimage=cv2.imread('.\/brain_tumor_dataset\/no\/'+notype[i])\n  plt.imshow(readimage)\n  plt.tight_layout()","0db386e0":"!pip install split_folders\nimport splitfolders","1dd49bed":"splitfolders.ratio(\"brain_tumor_dataset\", output=\"output\", seed=1337, ratio=(.8, .1, .1))","2a68c0d9":"#setting path of folders\ntrainingdatapath='.\/output\/train'\ntestingdatapath='.\/output\/test'\nvaldatapath='.\/output\/val'","7f822aee":"train_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale = 1.0\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale = 1\/255,\n    )\nval_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale = 1\/255,\n    )","2633bd61":"train_set = train_datagen.flow_from_directory(trainingdatapath,\n                                                 target_size = (224, 224), batch_size = 32, class_mode = 'categorical',shuffle=False)\ntest_set = test_datagen.flow_from_directory(testingdatapath,target_size = (224, 224),batch_size = 32,class_mode = 'categorical',shuffle=False)\nval_set = val_datagen.flow_from_directory(valdatapath,target_size = (224, 224),batch_size = 32,class_mode = 'categorical',shuffle=False)","3f1ebe35":"#giving train folder path for checking of no of classes\nfolders = glob('.\/output\/train\/*')\nprint(len(folders))","060beeb0":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.layers import Dropout\nfrom keras import layers\nfrom keras.optimizers import RMSprop\nfrom tensorflow.keras.layers import BatchNormalization","91859313":"IMAGE_SIZE =[224,224]\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\nfor layer in vgg.layers:\n  layer.trainable = False","32695b06":"x = Flatten()(vgg.output)\nx=Dense(units =1024, activation = 'relu')(x)\nx=Dropout(0.4)(x)\nx=Dense(units =512, activation = 'relu')(x)\n#x=Dropout(0.1)(x)\nprediction = Dense(len(folders), activation='softmax')(x)\nmodel = Model(inputs=vgg.input, outputs=prediction)\nmodel.summary()","759cd774":"from keras import optimizers\n\nadam = optimizers.Adam()\nmodel.compile(loss='binary_crossentropy',\n              optimizer=adam,\n              metrics=['accuracy'])","79cc3938":"from datetime import datetime\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\n\n\ncheckpoint = ModelCheckpoint(filepath='mymodel.9017', \n                               verbose=2, save_best_only=True)\nearly_stop = EarlyStopping(monitor='val_acc',\n                           patience=6,\n                           mode='max')\n\ncallbacks = [checkpoint,early_stop]\n\nstart = datetime.now()\n\nmodel_history=model.fit_generator(\n  train_set,\n  validation_data=val_set,\n  epochs=30,callbacks=callbacks ,verbose=2,shuffle=False)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","bf0f8bc2":"#type1\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import plot_confusion_matrix\ntrue_classes = val_set.classes\nvgg_preds = model.predict(val_set)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nprint(accuracy_score(true_classes, vgg_pred_classes)*100)","49986038":"#type2\nmodel.evaluate_generator(val_set)[1]","d3ebd0cb":"from sklearn.metrics import confusion_matrix\nconfusion_mtx = confusion_matrix(true_classes, vgg_pred_classes) \nsns.heatmap(confusion_mtx,annot=True, annot_kws={\"size\": 16},xticklabels=val_set.class_indices,yticklabels=val_set.class_indices,)","bf8fefee":"true_classes1 = test_set.classes\nvgg_preds1 = model.predict(test_set)\nvgg_pred_classes1 = np.argmax(vgg_preds1, axis=1)\nprint(accuracy_score(true_classes1, vgg_pred_classes1)*100)","a73e4327":"model.evaluate_generator(test_set)[1]","ae5a6b97":"from sklearn.metrics import confusion_matrix\nconfusion_mtx1 = confusion_matrix(true_classes1, vgg_pred_classes1) \nsns.heatmap(confusion_mtx1,annot=True, annot_kws={\"size\": 16},xticklabels=test_set.class_indices,yticklabels=test_set.class_indices,)","4bdf2ea6":"# plot model performance\nacc = model_history.history['accuracy']\nval_acc = model_history.history['val_accuracy']\nloss = model_history.history['loss']\nval_loss = model_history.history['val_loss']\nepochs_range = range(1, len(model_history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","0334ca5e":"# visualization of yes and no type","d97061b8":"# loading and reading of data","0deba127":"We can clearly say there is ** stone** like shape in brain,so it is consider as yes type . For no type it is clear and clean brain","8c73daad":"Creating data argumentation for train,eval,test.\n\n**Note **only for training data we need to pass modification. for eval and test just rescale and preprocess image","20d11364":"finding of accuracy is done by two methods","067c56d8":"Here iam using curlwget chrome extension to download","d254e299":"Set shuffle=False to get same results everytime else you get different resutls every time when you run the code","25ac1d34":"# data argumentation","50e8a76e":"**yes type**","cfa0da06":"**val data prediction**","9e1d7b1b":"Folder with name as output is created which includes train,val,test folders which contains both yes and not type","555a5415":"we have 155 yes type and 98 no type and total dataset is 253","fef08fb0":"**test data prediction**","af515eeb":"# data splitting","2456388d":"you can create your own no of layers with dropout , activation functions\n\ni tried with different layers and approchs finally i end up this code gives me best results.\n\nyou can change it and check your results","90d167f3":"# model","2677411c":"Setting path to folders","fa0050ef":"**no type**","13a77309":"we are spliting data into train,evl and test.For this iam using split folders funtion . which splits data folder into train and val and test folders , this folders is further used for data argumentation"}}