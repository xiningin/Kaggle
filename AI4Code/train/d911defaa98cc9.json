{"cell_type":{"5d008dde":"code","aa1d6e2f":"code","dae22963":"code","05454866":"code","9d2962e6":"code","1cdee6bb":"code","f6dad95d":"code","1dcf9e7a":"code","bf6a75d9":"code","d6280184":"code","0f7a217e":"code","96370c2b":"code","c6d51a9c":"code","76ffdd5b":"code","23a7aed7":"code","6f57bae0":"code","3ddc4f1a":"code","4edca14d":"code","98a9c797":"code","efbc0990":"code","8453b0c9":"code","c38d7fef":"code","fafbfb4f":"code","e071af99":"code","0f41ca79":"code","4b2ca39c":"code","b49d2b41":"code","673e1492":"code","dd2afa17":"code","bfe82711":"code","0e5c5b4e":"code","5afe7bea":"code","e315d345":"code","c95e36b1":"code","00cd0dac":"code","c1ba34fe":"code","ae9fdc78":"code","d0274e12":"code","429c00d4":"code","4e71762e":"code","1cd4ecf5":"code","77ce1a00":"code","60443742":"code","398a19b5":"code","1b17429f":"code","8273fc19":"code","6f4a0721":"code","f4e67f7d":"code","067d7bfa":"code","ca92b900":"code","1efcf1f7":"code","295969b3":"code","1300f54c":"code","a48f0ff2":"code","d3f508fc":"code","05155247":"code","86cbd14a":"code","409c45de":"code","ca6d92d9":"code","70683ed3":"code","9f261ab5":"code","0dd53271":"code","f4588cf4":"code","eb700915":"code","8fbadca6":"code","30dacdae":"code","3ea408bd":"code","26cac089":"code","64733ca2":"code","a1fffd1d":"code","5342a2bf":"code","acedb096":"code","c151e949":"code","499564d2":"code","194eba09":"code","a4eb7908":"code","43d24508":"code","78267e0f":"code","734f7b75":"code","112e0007":"code","1ae9305c":"code","d4336993":"code","1de503fd":"code","8e2f3f6a":"code","4caf367e":"code","4dd3120d":"code","f0d9ba79":"code","88fdaa8f":"code","21635259":"code","4dbbd99a":"code","301c4cb2":"markdown","a0053a3a":"markdown","f3c2389f":"markdown","7e766bf8":"markdown","43b722a5":"markdown","b5e4cea5":"markdown","5d3df842":"markdown","fed27f03":"markdown","9e961ebb":"markdown","277b0943":"markdown","c0098f24":"markdown","d19fb7b8":"markdown","916b0329":"markdown","e40954ad":"markdown","355dc4cc":"markdown","76efb268":"markdown","5b943033":"markdown","df223150":"markdown","6a8efe85":"markdown","cb1f76e7":"markdown","6d26bdf6":"markdown","d80662c5":"markdown","281905b4":"markdown","6bf52430":"markdown","bc47f2c4":"markdown","a81869d2":"markdown","72a5fd57":"markdown","90fb96a1":"markdown","cd54d3ee":"markdown","a0421068":"markdown","fc7b6fa1":"markdown","6ede9328":"markdown","0f6c95f9":"markdown","aca48f15":"markdown","85171908":"markdown","40003f1b":"markdown","2f0b108e":"markdown","c04b44a8":"markdown","8fa048e6":"markdown","f4c38cba":"markdown","483b779c":"markdown","9818e14a":"markdown","23a5af4b":"markdown","94028af3":"markdown","69845321":"markdown","e597e405":"markdown","46e46c34":"markdown","c8eded2c":"markdown","7d251ac8":"markdown","d43374f0":"markdown","c859faad":"markdown","eaf9eeb6":"markdown","79c063e4":"markdown","f08877cc":"markdown","9269a51c":"markdown","503ddfc1":"markdown","ded6e859":"markdown","005efb1b":"markdown","5b76deda":"markdown","2bd40099":"markdown","8d369889":"markdown","d3694350":"markdown","bfc21276":"markdown","2824ccb5":"markdown","ebc092fa":"markdown","a1b5a915":"markdown","b484418b":"markdown","a28c8fac":"markdown","c11c723a":"markdown","914e69ae":"markdown","32dde2fa":"markdown","37c2ed13":"markdown","67a07323":"markdown","fbf7881e":"markdown","66e8f14e":"markdown","3996834f":"markdown","eb28f30e":"markdown","8b2b83fb":"markdown","75df1bd3":"markdown","f1c1007e":"markdown","ce43e0cf":"markdown","9111a025":"markdown","cc823a0e":"markdown","4aa05f2c":"markdown","928cb84d":"markdown","a980d7c0":"markdown","1d6bb30d":"markdown","8a9d11d1":"markdown","c0713354":"markdown","fdd52ec2":"markdown","391b28b3":"markdown","2c5025db":"markdown","be6e955e":"markdown","14f8dbb9":"markdown","bd9ce463":"markdown","0b51d9b6":"markdown","6e1e7139":"markdown","8be2a941":"markdown","daff00df":"markdown","709b356d":"markdown","14178335":"markdown","4d310cae":"markdown","e8f21e87":"markdown","a708ae57":"markdown","dcdeb460":"markdown","54ddf1f4":"markdown","6baa883e":"markdown","081f30c4":"markdown"},"source":{"5d008dde":"# standard imports\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pickle # dump variables\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt # datetime lib\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","aa1d6e2f":"# Colab sets some Seaborn styles by default; let's revert to the default\n# Matplotlib styles and plot again.\nplt.rcdefaults()\n\nsns.set(rc={'figure.figsize': tuple(plt.rcParams['figure.figsize'])})\nsns.set(style=\"whitegrid\", font_scale=1.75)\n\n# prettify plots\nplt.rcParams['figure.figsize'] = [20.0, 5.0]\nplt.rcParams['figure.dpi'] = 200\nsns.set_palette(sns.color_palette(\"muted\"))\n\n%matplotlib inline\n\n#\n# Increase the quality and resolution of our charts so we can copy\/paste or just\n# directly save from here.\n#\n# See https:\/\/ipython.org\/ipython-doc\/3\/api\/generated\/IPython.display.html\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina', quality=100)\n\n## You can also just do this in Colab\/Jupyter, some \"magic\":\n%config InlineBackend.figure_format='retina'","dae22963":"import os\nc = 0\nfor filename in os.listdir('\/kaggle\/input\/nab'):\n    c += 1\n    print(str(c).zfill(2), f'\/{filename}')","05454866":"plt.rcParams['figure.figsize'] = [20.0, 5.0]","9d2962e6":"cpu = pd.read_csv('\/kaggle\/input\/nab\/realAWSCloudwatch\/realAWSCloudwatch\/ec2_cpu_utilization_53ea38.csv')\ncpu.plot()","1cdee6bb":"network = pd.read_csv('\/kaggle\/input\/nab\/realAWSCloudwatch\/realAWSCloudwatch\/ec2_network_in_5abac7.csv')\nnetwork.plot()","f6dad95d":"traffic = pd.read_csv('\/kaggle\/input\/nab\/realTraffic\/realTraffic\/TravelTime_387.csv')\ntraffic.plot()","1dcf9e7a":"twitter = pd.read_csv('\/kaggle\/input\/nab\/realTweets\/realTweets\/Twitter_volume_CVS.csv')\ntwitter.plot()","bf6a75d9":"def plot_anomalies(dfs, algorithm, parameters, title=False, dumping=False):\n    '''Plot the Streaming Data (an Anomalies)'''\n    n = len(dfs)\n    lin, col = 1, 1\n    for i in range(1, n+1):\n        if lin * col < i:\n            if lin == col: col += 1\n            else: lin += 1\n    # create a subplot\n    model_name = algorithm.__name__\n    fig, axes = plt.subplots(lin, col, squeeze=False, sharex=False, sharey=False, figsize=(col*20, lin*5))\n    fig.suptitle(f'Anomaly Detection - {model_name} ({parameters})')\n    xlin, xcol = 0, 0\n    for i, df in enumerate(dfs):\n        # get data \n        get_timestamp = lambda x: dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').timestamp()\n        X = df.timestamp.apply(lambda x: int(get_timestamp(x)))\n        Y = df.value\n        # predict anomalies\n        model = algorithm(**parameters)\n        preds = [model.detect(i, v, dumping=True) for i, v in zip(X, Y)]\n        pred, values, stds = tuple(zip(*preds))\n        # plot the results\n        af  = pd.DataFrame(data={'x':X, 'value':Y, 'pred':pred})\n        af2 = pd.DataFrame(data={'x':X, 'value':values, 'pred':pred, 'std': stds})\n        af2['ymin'] = af2['value'] - af2['std']\n        af2['ymax'] = af2['value'] + af2['std']\n        size = af.pred.astype(int) * 20\n        sns.lineplot(ax=axes[xlin, xcol], data=af, x='x', y='value')\n        sns.scatterplot(ax=axes[xlin, xcol], data=af, x='x', y='value', hue='pred', s=size)\n        if dumping: axes[xlin, xcol].fill_between(af2.x, af2.value, af2.ymax, facecolor='green', alpha=0.2)\n        if title: axes[xlin, xcol].set_title(f'{title[i]}')\n        # update posix\n        xlin += 1\n        if xlin == lin: xlin,xcol = 0, xcol+1\n\n    plt.tight_layout()\n    plt.show()","d6280184":"class StreamingMovingAverage:\n    '''Moving Average algorithm'''\n    # https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.rolling.html\n\n    def __init__(self, threshold=1.5) -> None:\n        # Parameters\n        self.max_deviation_from_expected = threshold\n        self.min_nof_records_in_model = 3\n        self.max_nof_records_in_model = 3 * self.min_nof_records_in_model\n\n    def detect(self, timestamp: int, value: float, dumping: bool=False) -> bool:\n        '''Detect if is a Anomaly'''\n        self._update_state(timestamp, value)\n        expected_value = self._expected_value(timestamp)\n        # is there enough data and is not NaN value\n        response, curr_value, deviation = False, value, 0.0\n        if self._enough_data() and not np.isnan(expected_value):\n            # is the value out of the boundary? when it decrease\n            curr_value = expected_value\n            deviation = self._standard_deviation() * self.max_deviation_from_expected\n            # when it is higher than expected\n            if expected_value + deviation < value:\n                response = True\n        # dumping or not\n        if dumping: return (response, curr_value, deviation)\n        else: return response\n\n    def _update_state(self, timestamp: int, value: float) -> None:\n        '''Update the model state'''\n        # check if it is the first time the model is run or if there is a big interval between the timestamps\n        if not hasattr(self, 'previous_timestamp'):\n            self._init_state(timestamp)\n        # update the model state\n        self.previous_timestamp = timestamp\n        self.data_streaming.append(value)\n        # is there a lot of data? remove one record\n        if len(self.data_streaming) > self.max_nof_records_in_model:\n            self.data_streaming.pop(0)\n\n    def _init_state(self, timestamp: int) -> None:\n        '''Reset the parameters'''\n        self.previous_timestamp = timestamp\n        self.data_streaming = list()\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) >= self.min_nof_records_in_model\n\n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        many = self.min_nof_records_in_model\n        return data.rolling(many, min_periods=1).mean().iloc[-1]\n\n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        return np.std(data, axis=0)\n\n    def get_state(self) -> dict:\n        '''Get the state'''\n        self_dict = {key: value for key, value in self.__dict__.items()}\n        return pickle.dumps(self_dict, 4)\n\n    def set_state(self, state) -> None:\n        '''Set the state'''\n        _self = self\n        ad = pickle.loads(state)\n        for key, value in ad.items():\n            setattr(_self, key, value)","0f7a217e":"algorithm = StreamingMovingAverage\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","96370c2b":"algorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","c6d51a9c":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","76ffdd5b":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","23a7aed7":"algorithm = StreamingMovingAverage\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","6f57bae0":"class StreamingExponentialMovingAverage(StreamingMovingAverage):\n    '''Exponential Weighted Moving Average (EWMA) algorithm'''\n    # https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.Series.ewm.html\n\n    def __init__(self, threshold=1.5, alpha=0.3) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n        self.alpha = alpha\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n\n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        return data.ewm(alpha=self.alpha, adjust=True).mean().iloc[-1]","3ddc4f1a":"algorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.5, 'alpha': 0.5}\nplot_anomalies([traffic], algorithm, parameters)","4edca14d":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","98a9c797":"algorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.5, 'alpha': 0.5}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","efbc0990":"algorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.6, 'alpha': 0.5}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","8453b0c9":"algorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.8, 'alpha': 0.4}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","c38d7fef":"class StreamingMovingMedian(StreamingMovingAverage):\n    '''Moving Median - using median instead of Arithmetic Mean (or Average)'''\n\n    def __init__(self, threshold=1.5) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n    \n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        variance = data.median() - data\n        return pow(sum(variance ** 2) \/ len(data), 1\/2)\n\n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        many = self.min_nof_records_in_model\n        return data.rolling(many, min_periods=1).median().iloc[-1]","fafbfb4f":"algorithm = StreamingMovingMedian\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","e071af99":"algorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","0f41ca79":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","4b2ca39c":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","b49d2b41":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","673e1492":"algorithm = StreamingMovingMedian\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","dd2afa17":"algorithm = StreamingMovingMedian\nparameters = {'threshold': 2.5}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","bfe82711":"algorithm = StreamingMovingMedian\nparameters = {'threshold': 3}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","0e5c5b4e":"def mean_abs_dev(data):\n    deviance = sum(abs(data - data.mean()))\n    return deviance \/ len(data)","5afe7bea":"class StreamingMovingMAD(StreamingMovingAverage):\n    '''Moving Mean Absolute Deviation (M.A.D) - using M.A.D instead of Arithmetic Mean (or Average)'''\n\n    def __init__(self, threshold=1.5) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n    \n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        variance = mean_abs_dev(data) - data\n        return pow(sum(variance ** 2) \/ len(data), 1\/2)    \n\n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        return mean_abs_dev(data)","e315d345":"algorithm = StreamingMovingMAD\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","c95e36b1":"algorithm = StreamingMovingMAD\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","00cd0dac":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","c1ba34fe":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","ae9fdc78":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMAD\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","d0274e12":"algorithm = StreamingMovingMAD\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","429c00d4":"algorithm = StreamingMovingMAD\nparameters = {'threshold': 2.5}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","4e71762e":"algorithm = StreamingMovingMAD\nparameters = {'threshold': 2.75}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","1cd4ecf5":"def trimean(values):\n    return (np.quantile(values, 0.25) + (2 * np.quantile(values, 0.50)) + np.quantile(values, 0.75)) \/ 4","77ce1a00":"class StreamingMovingTrimean(StreamingMovingAverage):\n    '''Trimean - using trimean instead of Arithmetic Mean (or Average)'''\n\n    def __init__(self, threshold=1.5) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n    \n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        variance = trimean(data) - data\n        return pow(sum(variance ** 2) \/ len(data), 1\/2)       \n\n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        return trimean(data)","60443742":"algorithm = StreamingMovingTrimean\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","398a19b5":"algorithm = StreamingMovingTrimean\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","1b17429f":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","8273fc19":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","6f4a0721":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMAD\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingTrimean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","f4e67f7d":"algorithm = StreamingMovingTrimean\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","067d7bfa":"algorithm = StreamingMovingTrimean\nparameters = {'threshold': 2.5}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","ca92b900":"algorithm = StreamingMovingTrimean\nparameters = {'threshold': 2.75}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","1efcf1f7":"def geomean(data):\n    index = 0\n    N = len(data)\n    result = 1\n    for index in range(0, N):\n        result = result * data[index]\n    if N != 0:\n        return abs(result) ** (1 \/ N)\n    else:\n        raise ValueError('No distribution has been passed in, cannot compute Geometric Mean')","295969b3":"class StreamingMovingGeomean(StreamingMovingAverage):\n    '''Geomean - using Geomean instead of Arithmetic Mean (or Average)'''\n\n    def __init__(self, threshold=1.5) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n    \n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        variance = geomean(data) - data\n        return pow(sum(variance ** 2) \/ len(data), 1\/2)       \n\n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        return geomean(data)","1300f54c":"algorithm = StreamingMovingGeomean\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","a48f0ff2":"algorithm = StreamingMovingGeomean\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","d3f508fc":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","05155247":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","86cbd14a":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMAD\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingTrimean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingGeomean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","409c45de":"algorithm = StreamingMovingGeomean\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","ca6d92d9":"algorithm = StreamingMovingGeomean\nparameters = {'threshold': 2.5}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","70683ed3":"algorithm = StreamingMovingGeomean\nparameters = {'threshold': 2.75}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","9f261ab5":"def harmonic_mean(data):\n    index = 0\n    N = len(data)\n    result = 0\n    for index in range(0, N):\n        if data[index] != 0:\n            result = result + (1 \/ data[index])\n\n    if result == 0:\n        return result\n#         raise ValueError('Distribution contains one or more zeros, cannot compute Harmonic Mean')\n    else:\n        return 1 \/ result","0dd53271":"class StreamingMovingHarmonicMean(StreamingMovingAverage):\n    '''Harmonic Mean - using Harmonic Mean instead of Arithmetic Mean (or Average)'''\n\n    def __init__(self, threshold=1.5) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n    \n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        variance = harmonic_mean(data) - data\n        return pow(sum(variance ** 2) \/ len(data), 1\/2)  \n    \n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        return harmonic_mean(data)","f4588cf4":"algorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","eb700915":"algorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","8fbadca6":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","30dacdae":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","3ea408bd":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMAD\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingTrimean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingGeomean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","26cac089":"algorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","64733ca2":"algorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 2.5}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","a1fffd1d":"algorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 2.75}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","5342a2bf":"def rms(data):\n    return (sum(data ** 2) \/ len(data)) ** (1 \/ 2)","acedb096":"class StreamingMovingRMS(StreamingMovingAverage):\n    '''Root Mean Square - using Root Mean Square instead of Arithmetic Mean (or Average)'''\n\n    def __init__(self, threshold=1.5) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n    \n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        variance = rms(data) - data\n        return pow(sum(variance ** 2) \/ len(data), 1\/2)  \n    \n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        return rms(data)","c151e949":"algorithm = StreamingMovingRMS\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","499564d2":"algorithm = StreamingMovingRMS\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","194eba09":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","a4eb7908":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","43d24508":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMAD\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingTrimean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingGeomean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingRMS\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","78267e0f":"algorithm = StreamingMovingRMS\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","734f7b75":"algorithm = StreamingMovingRMS\nparameters = {'threshold': 2}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","112e0007":"algorithm = StreamingMovingRMS\nparameters = {'threshold': 2.25}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","1ae9305c":"def rmsl(data):\n    mean_value = sum(np.log(data) ** 2) \/ len(data)\n    return np.exp(mean_value ** (1 \/ 2))","d4336993":"class StreamingMovingRMSL(StreamingMovingAverage):\n    '''Root Mean Square Log - using Root Mean Square Log instead of Arithmetic Mean (or Average)'''\n\n    def __init__(self, threshold=1.5) -> None:\n        super().__init__()\n        # Parameters\n        self.max_deviation_from_expected = threshold\n\n    def _enough_data(self) -> bool:\n        '''Check if there is enough data'''\n        return len(self.data_streaming) > 0\n    \n    def _standard_deviation(self) -> float:\n        '''Return the standard deviation'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        variance = rmsl(data) - data\n        return pow(sum(variance ** 2) \/ len(data), 1\/2)  \n    \n    def _expected_value(self, timestamp: int) -> float:\n        '''Return the expected value'''\n        data = self.data_streaming\n        data = pd.Series(data=data, dtype=float)\n        return rmsl(data)","1de503fd":"algorithm = StreamingMovingRMSL\nparameters = {'threshold': 2.0}\nplot_anomalies([traffic], algorithm, parameters)","8e2f3f6a":"algorithm = StreamingMovingRMSL\nparameters = {'threshold': 1.0}\nplot_anomalies([traffic], algorithm, parameters)","4caf367e":"plot_anomalies([traffic], algorithm, parameters, dumping=True)","4dd3120d":"sample = traffic.iloc[120:150]\nplot_anomalies([sample], algorithm, parameters, dumping=True)","f0d9ba79":"sample = traffic.iloc[120:150]\n\nalgorithm = StreamingMovingAverage\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingExponentialMovingAverage\nparameters = {'threshold': 1.0, 'alpha': 0.5}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMedian\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingMAD\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingTrimean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingGeomean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingHarmonicMean\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingRMS\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)\n\nalgorithm = StreamingMovingRMSL\nparameters = {'threshold': 1.0}\nplot_anomalies([sample], algorithm, parameters, dumping=True)","88fdaa8f":"algorithm = StreamingMovingRMSL\nparameters = {'threshold': 2.0}\ntitle = ['CPU Utilization', 'Network Usage', 'Travel Time', 'Twitter Volume']\nplot_anomalies([cpu, network, traffic, twitter], algorithm, parameters, title)","21635259":"algorithm = StreamingMovingRMSL\nparameters = {'threshold': 2}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","4dbbd99a":"algorithm = StreamingMovingRMSL\nparameters = {'threshold': 2.25}\ntitle = ['Twitter Volume']\nplot_anomalies([twitter], algorithm, parameters, title)","301c4cb2":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","a0053a3a":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","f3c2389f":"-----\n<a id=\"mm\"><\/a>\n\n## Moving Median\n\n**Moving Median** is the same as the [Moving Average](#ma), except we use the Median centroid function instead of the Arithmetic Mean (or Average). And the standard deviation of the data is obtained on the basis of the median of the data. The checks are the same as in [Moving Average](#ma). The expected value range is computed using the formula `Moving Median + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\n","7e766bf8":"As the threshold has been increased, the number of True anomalies have dropped drastically.","43b722a5":"-----\n<a id=\"network\"><\/a>\n\n### Network Usage","b5e4cea5":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","5d3df842":"-----\n<a id=\"travel\"><\/a>\n\n### Travel Time","fed27f03":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","9e961ebb":"-----\n<a id=\"exploring-hm\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving Harmonic Mean is not smoothing the expected values for most of the problems","277b0943":"-----\n<a id=\"exploring-rms\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving RMS is not smoothing the expected values for most of the problems","c0098f24":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","d19fb7b8":"-----\n<a id=\"tm\"><\/a>\n\n## Moving Trimean\n\n**Moving Trimean** is the same as the [Moving Average](#ma), except we calculate the Trimean instead of the Arithmetic Mean (or Average). And the standard deviation of the data is obtained on the basis of the trimean of the data. The checks are the same as in [Moving Average](#ma). The expected value range is computed using the formula `Moving Trimean + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\n        \nReferences to Trimean:\n- https:\/\/gandysoft.com\/support\/faqs\/what-is-statistical-trimean\n- https:\/\/en.wikipedia.org\/wiki\/Trimean\n","916b0329":"Let's zoom in on a sample of traffic data.","e40954ad":"Let's zoom in on a sample of traffic data.","355dc4cc":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","76efb268":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","5b943033":"Let's try to reproduce the Moving Average anomalies in Travel Time dataset.\n\n- In this case, we found the parameters `threshold=1.5` and `alpha=0.5`","df223150":"-----\n<a id=\"data\"><\/a>\n## Data Exploration\n\nWe are using [Numenta Anomaly Benchmark (NAB)](https:\/\/www.kaggle.com\/boltzmannbrain\/nab) data source that presents a corpus of 58 timeseries data files, designed to provide data for research in streaming anomaly detection. We are going to explore four kinds of data, they are: (1) cpu utilization; (2) network usage; (3) travel time between two cities; and (4) volume of messages sent in Twitter.","6a8efe85":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies","cb1f76e7":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","6d26bdf6":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","d80662c5":"Comparing _Moving Average_ with _Exponential Moving Average_, we can noticed that Exponential smoothes the expected value and avoids detecting unnecessary outliers.","281905b4":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies","6bf52430":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","bc47f2c4":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","a81869d2":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","72a5fd57":"-----\n<a id=\"ema\"><\/a>\n\n## Exponential Moving Average\n\n**Exponential Moving Average** focuses more on recent data by assigning more weight to new data points; so, they are weigted by timestamp - most recent has more importance. Further, we simple check if the new record is far from the expected value. The expected value range is computed using the formula `Exponential Moving Average + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\nAlso, the Exponential Moving Average needs a parameter called `alpha` that determines the importance of the last record, and its value is decreased for the next records. For example, if `alpha=0.5`: the record-1 has 50% of importance, the record-2 has 30% of importance, and so on. Thus, this weighted algorithm enables smooth the expected value.","90fb96a1":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","cd54d3ee":"-----\n<a id=\"rmsl\"><\/a>\n\n## Moving Root Mean Square Log\n\n**Moving Root Mean Square Log** is the same as the [Moving Average](#ma), except we calculate the Root Mean Square Log instead of the Arithmetic Mean (or Average). And the standard deviation of the data is obtained on the basis of the Root Mean Square Log of the data. The checks are the same as in [Moving Average](#ma). The expected value range is computed using the formula `Moving Root Mean Square Log + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\n        \nRoot Mean Square Log is similar to how we do Root Mean Square, except we use log in the equation to help with scaling big and small values.\n\n```python\ndef rmsl(data):\n    mean_value = sum( (np.log(data) ** 2) ) \/ len(data)\n    return np.exp(mean_value ** (1 \/ 2))\n```\n\n","a0421068":"As the threshold has been increased, the number of True anomalies have dropped drastically.","fc7b6fa1":"-----\n<a id=\"exploring-tm\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving Trimean is not smoothing the expected values for most of the problems","6ede9328":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","0f6c95f9":"-----\n<a id=\"exploring-ma\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving Average is not smoothing the expected values for most of the problems","aca48f15":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","85171908":"As the threshold has been increased, the number of True anomalies have dropped drastically.","40003f1b":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","2f0b108e":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","c04b44a8":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","8fa048e6":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies","f4c38cba":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","483b779c":"-----\n<a id=\"exploring-mmad\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving Mean Absolute Deviation is not smoothing the expected values for most of the problems","9818e14a":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","23a5af4b":"<a id='ToC'><\/a>\n\n----------\n\n# <div class=\"toc h2\">Table of content\n    \n> **Note** - Some codes and outputs are hidden, to highlight the most important content.\n\nThe notebook is organized as:\n\n\n- [Introduction](#introduction)\n- [Data Exploration](#data)\n  - [CPU Utilization](#cpu)\n  - [Network Usage](#network)\n  - [Travel Time](#travel)\n  - [Twitter Volume](#twitter)\n- [Streaming Anomaly Detection](#anomaly)\n    - [Moving Average](#ma)\n        - [Exploring All Data](#exploring-ma)\n    - [Exponential Moving Average](#ema)\n        - [Exploring All Data](#exploring-ema)\n    - [Moving Median](#mm)\n        - [Exploring All Data](#exploring-mm)\n    - [Moving M.A.D](#mmad)\n        - [Exploring All Data](#exploring-mmad)\n    - [Moving Trimean](#tm)\n        - [Exploring All Data](#exploring-tm)\n    - [Moving Geomean](#gm)\n        - [Exploring All Data](#exploring-gm)\n    - [Moving Harmonic Mean](#hm)\n        - [Exploring All Data](#exploring-hm)\n    - [Moving Root Mean Square](#rms)\n        - [Exploring All Data](#exploring-rms)\n    - [Moving Root Mean Square Log](#rmsl)\n        - [Exploring All Data](#exploring-rmsl)\n- [Credits](#credits)\n- References\n    - [LinkedIn post](https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:6887813156639391745\/?commentUrn=urn%3Ali%3Acomment%3A(activity%3A6887813156639391745%2C6888481636896251904))\n    - [Medium post](https:\/\/medium.com\/wearesinch\/simple-anomaly-detection-algorithms-for-streaming-data-machine-learning-92cfaeb6f43b) by **<a href=https:\/\/www.kaggle.com\/leomauro\/>Leonardo Mauro<\/a>** ","94028af3":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","69845321":"As the threshold has been increased, the number of True anomalies have dropped drastically.\n\nBut from all above observations it appear M.A.D seem to deviate a bit more from the others so far. It's left to be seen if it is a better measurement as compared to the others so far. Maybe the ones to come later on will decide the fate of all of them.","e597e405":"Let's zoom in on a sample of traffic data.","46e46c34":"-----\n<a id=\"ma\"><\/a>\n\n## Moving Average\n\n**Moving Average** is the most common type of average used in Time Series problems. We perform the sum of recent data points and divide them by the time period. Further, we simply check if the new record is far from the expected value. The expected value range is computed using the formula `Moving Average + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.","c8eded2c":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","7d251ac8":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","d43374f0":"<a id='introduction'><\/a>\n\n----------\n\n    \n## <div class=\"section_title\"> Introduction\n\nThis notebook presents a few unsupervised algorithms to detect anomaly in real streaming data, such as CPU utilization, network usage or travel time. \"Streaming data is data that is continuously generated by different sources. Such data should be processed incrementally using stream processing techniques without having access to all of the data\" [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Streaming_data). We are going to experiment Anomaly Detection in [Numenta Anomaly Benchmark (NAB)](https:\/\/www.kaggle.com\/boltzmannbrain\/nab). In the end, I hope you are going to be able to apply this family of algorithms.\n\n> **Summary** - Unsupervised Anomaly Detection in real Streaming Data.   \n> Content for intermediate level in Machine Learning and Data Science!\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*Kh3wXbIA2oKHc8qiIy3v0g.png)\n    \n# [Click here to go to the Medium blog post by <a href=https:\/\/www.kaggle.com\/leomauro\/>Leonardo Mauro<\/a>](https:\/\/medium.com\/wearesinch\/simple-anomaly-detection-algorithms-for-streaming-data-machine-learning-92cfaeb6f43b)","c859faad":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","eaf9eeb6":"-----\n<a id=\"twitter\"><\/a>\n\n### Twitter Volume","79c063e4":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","f08877cc":"<a id='credits'><\/a>\n\n----------\n\n    \n## <div class=\"section_title\"> Credits\n    \nThanks to **<a href=https:\/\/www.kaggle.com\/leomauro\/>Leonardo Mauro<\/a>** for creating the original notebook **<a href=https:\/\/www.kaggle.com\/leomauro\/anomaly-detection-streaming-data>Anomaly Detection - Streaming Data<\/a>** and for agreeing to extend it with enhancements.\n\nWe agreed to use these two notebooks are our starting point of inspiration:\n- [Normalising a distribution](https:\/\/www.kaggle.com\/neomatrix369\/normalising-a-distribution)\n- [Studying the limitations of stats measurements](https:\/\/www.kaggle.com\/neomatrix369\/studying-the-limitations-of-stats-measurements)\n\nAny other recommendations are welcome, please share them in the comments section with enough details that can be used to implement further enhancements.","9269a51c":"Let's zoom in on a sample of traffic data.","503ddfc1":"-----\n<a id=\"exploring-gm\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving Geomean is not smoothing the expected values for most of the problems","ded6e859":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies","005efb1b":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","5b76deda":"-----\n<a id=\"gm\"><\/a>\n\n## Moving Geomean\n\n**Moving Geomean** is the same as the [Moving Average](#ma), except we calculate the Geomean instead of the Arithmetic Mean (or Average). And the standard deviation of the data is obtained on the basis of the Geometric mean of the data. The checks are the same as in [Moving Average](#ma). The expected value range is computed using the formula `Moving Geomean + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\n        \nReferences to Geomean:\n- https:\/\/en.wikipedia.org\/wiki\/Geometric_mean\n","2bd40099":"Let's zoom in on a sample of traffic data.","8d369889":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","d3694350":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","bfc21276":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","2824ccb5":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","ebc092fa":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","a1b5a915":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","b484418b":"-----\n<a id=\"cpu\"><\/a>\n\n### CPU Utilization","a28c8fac":"-----\n<a id=\"hm\"><\/a>\n\n## Moving Harmonic Mean\n\n**Moving Harmonic Mean** is the same as the [Moving Average](#ma), except we calculate the Harmonic Mean instead of the Arithmetic Mean (or Average). And the standard deviation of the data is obtained on the basis of the Harmonic Mean of the data. The checks are the same as in [Moving Average](#ma). The expected value range is computed using the formula `Moving Harmonic Mean + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\n        \nReferences to Harmonic Mean:\n- https:\/\/en.wikipedia.org\/wiki\/Harmonic_mean\n","c11c723a":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","914e69ae":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","32dde2fa":"-----\n<a id=\"anomaly\"><\/a>\n# Streaming Anomaly Detection\n\nDo you want to monitor your computer metrics and detect anomalies in your existing streaming data? We are going to see a some algorithms for that:\n\n- Streaming Moving Average\n- Streaming Exponential Average\n- Streaming Moving Median\n- Streaming Moving MAD (Mean Absolute Deviation)\n- Streaming Moving Trimean\n- Streaming Moving Geomean\n- Streaming Moving Harmonic Mean\n- Streaming Moving Root Mean Square (RMS)\n- Streaming Moving Root Mean Square Log (RMSL)","37c2ed13":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies","67a07323":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","fbf7881e":"-----\n<a id=\"rms\"><\/a>\n\n## Moving Root Mean Square\n\n**Moving Root Mean Square** is the same as the [Moving Average](#ma), except we calculate the Root Mean Square instead of the Arithmetic Mean (or Average). And the standard deviation of the data is obtained on the basis of the Root Mean Square of the data. The checks are the same as in [Moving Average](#ma). The expected value range is computed using the formula `Moving Root Mean Square + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\n        \nReferences to Root Mean Square:\n- https:\/\/en.wikipedia.org\/wiki\/Root_mean_square\n","66e8f14e":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","3996834f":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","eb28f30e":"Let's zoom in on a sample of traffic data.","8b2b83fb":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","75df1bd3":"-----\n<a id=\"exploring-ema\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Exponential Moving Average is smoothing the expected values\n- Thus, the algorithm highlights only anomalies with gross changes","f1c1007e":"-----\n<a id=\"exploring-rmsl\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving RMSL is not smoothing the expected values for most of the problems","ce43e0cf":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies","9111a025":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","cc823a0e":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","4aa05f2c":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","928cb84d":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","a980d7c0":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","1d6bb30d":"Let's zoom in on a sample of traffic data.","8a9d11d1":"How many anomalies we can find with $\\sigma = 2.0$ (standard deviation)?\n- This is a decent number for initial guess","c0713354":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","fdd52ec2":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","391b28b3":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","2c5025db":"As the threshold has been increased, the number of True anomalies have dropped drastically.","be6e955e":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","14f8dbb9":"Let's zoom in on a sample of traffic data.","bd9ce463":"We can also `dumping` to see the expected value range, see:\n- **Note** - the value is an anomaly if it is larger than expected","0b51d9b6":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","6e1e7139":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","8be2a941":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","daff00df":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","709b356d":"## Plot Function","14178335":"-----\n<a id=\"exploring-mm\"><\/a>\n\n## Exploring All Data\n\n- You can see that the Moving Median is not smoothing the expected values for most of the problems","4d310cae":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies; or\n- We can raise the `threshold` and decrease the `alpha`, to increase the smoothness","e8f21e87":"As the threshold has been increased, the number of True anomalies have dropped drastically.","a708ae57":"How many anomalies we can find with $\\sigma = 1.0$ (standard deviation)?\n- You can see that we guess more anomalies","dcdeb460":"Unfortunatelly, this algorithms presented a lot of anomalies in Twitter Volume data. This is happening because the volume decrease and increase quicklly - causing this confusion in the algorithm. What can we do?\n- We can raise the `threshold`, to increase limit for the anomalies","54ddf1f4":"-----\n<a id=\"mmad\"><\/a>\n\n## Moving Mean Absolute Deviation (M.A.D)\n\n**Moving Mean Absolute Deviation (M.A.D)** is the same as the [Moving Average](#ma), except we calculate the Mean Absolute Deviation (M.A.D) instead of the Arithmetic Mean (or Average). And the standard deviation of the data is obtained on the basis of the M.A.D of the data. The checks are the same as in [Moving Average](#ma). The expected value range is computed using the formula `Moving Mean Absolute Deviation (M.A.D) + standard deviation * threshold`; if it is out of the expected value range, we report as an anomaly.\n\n        \nReferences to Mean Absolute Deviation (M.A.D):\n- https:\/\/en.wikipedia.org\/wiki\/Average_absolute_deviation\n- https:\/\/www.statology.org\/how-to-easily-calculate-the-mean-absolute-deviation-in-excel\/\n- https:\/\/www.khanacademy.org\/math\/cc-sixth-grade-math\/cc-6th-data-statistics\/cc-6-mad\/v\/mean-absolute-deviation\n","6baa883e":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","081f30c4":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>"}}