{"cell_type":{"e4e5939a":"code","fd87f951":"code","75777822":"code","2a57d19f":"code","c4047cc9":"code","1a57a0c9":"code","f2517322":"code","f9c545a8":"code","a28f6dc0":"code","7d70d79e":"code","a704e76e":"code","76640dee":"code","8b206935":"code","b0f90ed2":"code","2725ced8":"code","bf1eefe9":"code","047f0e1f":"code","412df2b0":"code","87f55d07":"code","58986b50":"code","85b6147a":"code","7d4616a9":"code","5125ceee":"code","ca405108":"code","2a5d8abb":"code","16c372e1":"code","d6bffd4e":"code","bab694f9":"code","01f86260":"code","5e73fd36":"code","400444c6":"code","480ff6b2":"code","9ca897b8":"code","ad96ced6":"code","09512790":"code","d71030fa":"markdown","9420dbf1":"markdown","7b5140b3":"markdown","e4cfaaf0":"markdown","42abb920":"markdown","81c2bde0":"markdown","b9fb89f9":"markdown","46078439":"markdown","77638be3":"markdown","6b729c57":"markdown","c9e07e96":"markdown","d1f7dfae":"markdown"},"source":{"e4e5939a":"import os\nprint(os.listdir(\"..\/input\"))","fd87f951":"!ls ..\/input\/embeddings","75777822":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport nltk\nfrom sklearn.pipeline import Pipeline\nfrom nltk.corpus import stopwords\nfrom string import punctuation as str_pun\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn import model_selection\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score","2a57d19f":"train = pd.read_csv('..\/input\/train.csv')\nprint(train.shape)\ntrain.head()","c4047cc9":"test = pd.read_csv('..\/input\/test.csv')\nprint(test.shape)\ntest.head()","1a57a0c9":"insincere  = train[train['target']==1]\nprint(\"length of the INSINCERE : \",len(insincere))\nsincere = train[train['target']==0]\nprint(\"length of the SINCERE :\",len(sincere))","f2517322":"sns.countplot(data=train,hue=train['target'],x=train['target'])","f9c545a8":"train[\"num_words\"] = train[\"question_text\"].apply(lambda x: len(str(x).split()))\ntest[\"num_words\"] = test[\"question_text\"].apply(lambda x: len(str(x).split()))","a28f6dc0":"train[\"num_unique_words\"] = train[\"question_text\"].apply(lambda x: len(set(str(x).split())))\ntest[\"num_unique_words\"] = test[\"question_text\"].apply(lambda x: len(set(str(x).split())))","7d70d79e":"train[\"num_chars\"] = train[\"question_text\"].apply(lambda x: len(str(x)))\ntest[\"num_chars\"] = test[\"question_text\"].apply(lambda x: len(str(x)))","a704e76e":"w = stopwords.words('english')","76640dee":"train['num_stopwords'] = train['question_text'].apply(lambda x : len([nw for nw in str(x).split() if nw.lower() in w]))\ntest['num_stopwords'] = test['question_text'].apply(lambda x : len([nw for nw in str(x).split() if nw.lower() in w]))","8b206935":"train['num_punctuation'] = train['question_text'].apply(lambda x : len([np for np in str(x) if np in str_pun]))\ntest['num_punctuation'] = test['question_text'].apply(lambda x : len([np for np in str(x) if np in str_pun]))","b0f90ed2":"train['num_uppercase'] = train['question_text'].apply(lambda x : len([nu for nu in str(x).split() if nu.isupper()]))\ntest['num_uppercase'] = test['question_text'].apply(lambda x : len([nu for nu in str(x).split() if nu.isupper()]))","2725ced8":"train['num_lowercase'] = train['question_text'].apply(lambda x : len([nl for nl in str(x).split() if nl.islower()]))\ntest['num_lowercase'] = test['question_text'].apply(lambda x : len([nl for nl in str(x).split() if nl.islower()]))","bf1eefe9":"train['num_title'] = train['question_text'].apply(lambda x : len([nl for nl in str(x).split() if nl.istitle()]))\ntest['num_title'] = test['question_text'].apply(lambda x : len([nl for nl in str(x).split() if nl.istitle()]))","047f0e1f":"train[train['target']==1].describe()","412df2b0":"train[train['target']==0].describe()","87f55d07":"sns.violinplot(x=train['target'],y=train['num_chars'],data=train)","58986b50":"sns.violinplot(x=train['target'],y=train['num_words'],data=train,split=True)","85b6147a":"sns.violinplot(x='target',y='num_unique_words',data=train,split=True)","7d4616a9":"plt.figure(figsize=(20,15))\nsns.stripplot(x='num_words',y='num_unique_words',data=train, hue='target',jitter=False)#, split=True)","5125ceee":"sns.stripplot(x='target',y='num_stopwords',data=train, jitter=False)","ca405108":"def text_process(question):\n    nopunc = [char for char in question if char not in str_pun]\n    nopunc = \"\".join(nopunc)\n    meaning = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n    return( \" \".join( meaning )) ","2a5d8abb":"print(\"Processing ...\")\ntrain['question_text'].apply(text_process)","16c372e1":"print(\"processing ...\")\ntest['question_text'].apply(text_process)","d6bffd4e":"train.head()","bab694f9":"pipeline = Pipeline([('cv',CountVectorizer(analyzer='word',ngram_range=(1,4),max_df=0.9)),\n                     ('clf',LogisticRegression(solver='saga',class_weight='balanced',C=0.45,max_iter=250, verbose=1))])","01f86260":"pipeline.get_params().keys()","5e73fd36":"X_train = train['question_text'].values\ny_train = train['target']\nX_test = test['question_text'].values","400444c6":"pipeline.fit(X_train,y_train)","480ff6b2":"prediction = pipeline.predict(X_test)","9ca897b8":"insincere = prediction[prediction == 1]\nprint(\"Length of INSINCERE after Prediction : \",len(insincere))\nsincere = prediction[prediction == 0]\nprint(\"Length of SINCERE after Prediction : \",len(sincere))","ad96ced6":"submit = pd.DataFrame({'qid':test['qid'],'prediction':prediction})\nsubmit.head()","09512790":"submit.to_csv('submission.csv',index=False)","d71030fa":"### Get the Count , Mean,Min,Max of the train target","9420dbf1":"### Number of words in the text\n","7b5140b3":"### Number of Stopwords in text","e4cfaaf0":">> #### Predict the Model","42abb920":"## Pipeline Model\n> ### Logistic Regression and CountVectorizer using Hyperparameter Tuning","81c2bde0":"### Number of title in text","b9fb89f9":"### Number of Upper case and Lower case in text","46078439":"### Number of unique words in the text \n","77638be3":"### Number of punctuations in text","6b729c57":"### Number of characters in the text \n","c9e07e96":"### Submit the File","d1f7dfae":"## Remove Stopwords and Punctuation"}}